<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.024002">
<title confidence="0.992538">
UPV-WSD : Combining different WSD Methods
by means of Fuzzy Borda Voting
</title>
<author confidence="0.903241">
Davide Buscaldi and Paolo Rosso
</author>
<affiliation confidence="0.835689">
DSIC, Dpto. Sistemas Informiticos y Computaci´on
</affiliation>
<address confidence="0.7472415">
Universidad Polit´ecnica de Valencia
Valencia, Spain
</address>
<email confidence="0.997186">
{dbuscaldi,prosso}@dsic.upv.es
</email>
<sectionHeader confidence="0.998584" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999856842105263">
This paper describes the WSD system devel-
oped for our participation to the SemEval-1.
It combines various methods by means of a
fuzzy Borda voting. The fuzzy Borda vote-
counting scheme is one of the best known
methods in the field of collective decision
making. In our system the different disam-
biguation methods are considered as experts
that give a preference ranking for the senses
a word can be assigned. Then the prefer-
ences are evaluated using the fuzzy Borda
scheme in order to select the best sense. The
methods we considered are the sense fre-
quency probability calculated over SemCor,
the Conceptual Density calculated over both
hyperonyms and meronyms hyerarchies in
WordNet, the extended Lesk by Banerjee
and Pedersen, and finally a method based on
WordNet domains.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999302">
One of the lessons learned from our previous experi-
ence at Senseval-31 (Buscaldi et al., 2004; Vazquez
et al., 2004) is that the integration of different sys-
tems usually works better than a standalone system.
In our opinion this reflects the reality where humans
do not apply always the same rule in order to disam-
biguate the same ambigue word; for instance, if we
consider the sentences “He hit a home run” and “The
thermometer hit 100 degrees”, in the first case the
sport domain helps in determining the right sense for
</bodyText>
<footnote confidence="0.977186">
1http://www.senseval.org
</footnote>
<bodyText confidence="0.999691428571429">
hit, whereas in the latter the disambiguation is car-
ried out mostly depending on the fact that the subject
of the sentence is an object.
The combination of distinct methods represents
itself a major problem. If the methods return dif-
ferent answers, how can we select the best one? In
this sense the available choices are the following:
</bodyText>
<listItem confidence="0.9879275">
• Rule-based selection: a set of rules that can be
both hand-made or automatically learned from
examples;
• Probability-based: the output of the methods is
normalized in the range [0, 1] and is considered
as a probability. Then the values are multiplied
in order to obtain the sense with a maximum
probability.
• Vote-based: the output of the methods is con-
sidered as a weighted vote. Then a voting
scheme is used in order to obtain the most voted
sense.
</listItem>
<bodyText confidence="0.999318153846154">
In our previous participation with the R2D2 project
(Vazquez et al., 2004) the selection was rule-based,
with hand-made rules that attempted to take into ac-
count the reliability of the various method. We sub-
sequently attempted to learn automatically the rules,
but the results of these experiments did not allow to
determine clearly which method was to be used in
each context.
Working with probabilities can be problematic
due to the null probabilities that make necessary the
adoption of smoothing techniques. Therefore, we
opted for a voting scheme, in this case the fuzzy
Borda (Nurmi, 2001; Garcia Lapresta and Martinez
</bodyText>
<page confidence="0.988066">
434
</page>
<bodyText confidence="0.979867866666667">
Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 434–437,
Prague, June 2007. c�2007 Association for Computational Linguistics
Panero, 2002), one of the best known methods in
the field of collective decision making. With this
scheme the disambiguation methods are considered
as experts providing a preference ranking over the
sense of the word.
The methods we choose as experts are the sense
probability calculated over SemCor, the Conceptual
Density algorithm by (Rosso et al., 2003), the ex-
tended Lesk by (Banerjee and Pedersen, 2002), and
an algorithm that takes into account the domains of
the word to be disambiguated and the context words.
In the following sections we describe in detail the
fuzzy Borda scheme and each WSD expert.
</bodyText>
<sectionHeader confidence="0.916259" genericHeader="method">
2 The Fuzzy Borda voting scheme
</sectionHeader>
<bodyText confidence="0.9895234375">
The original Borda vote-counting scheme was in-
troduced in 1770 by Jean Charles de Borda, and
adopted by the French Academy of Sciences with
the purpose of selecting its members. In the classical
Borda count each expert gives a mark to each alter-
native, according to the number of alternatives worse
than it. The fuzzy variant (Nurmi, 2001; Garcia
Lapresta and Martinez Panero, 2002) is a natural ex-
tension that allows the experts to show numerically
how much some alternatives are preferred to the oth-
ers, evaluating their preference intensities from 0 to
1.
Let R1, R2, ... , Rm be the fuzzy prefer-
ence relations of m experts over n alternatives
x1, x2, ... , xn. For each expert k we obtain a
matrix of preference intensities:
</bodyText>
<equation confidence="0.9144588">
rk 11 rk 12 . . . rk 1n
k kk
r21 r22 ... r2n
. . . . . . . . . . . .
rk n1 rk n2 . . . rk nn
</equation>
<bodyText confidence="0.999649166666667">
where each rk ij = µRk(xi, xj), with µRk : XxX �
[0, 1] being the membership function of Rk. The
number rk ij E [0, 1] is considered as the degree of
confidence with which the expert k prefers xi to xj.
The final value assigned by the expert k to each al-
ternative xi is:
</bodyText>
<equation confidence="0.861725666666667">
n
rk(xi) = E rk ij (1)
j=1,rk��&gt;0.5
</equation>
<bodyText confidence="0.99864375">
which coincides with the sum of the entries greater
than 0.5 in the i-th row in the preference matrix. The
threshold 0.5 ensure the relation Rkto be an ordinary
preference relation (Garcia Lapresta and Martinez
Panero, 2002).
Therefore, the definitive fuzzy Borda count for an
alternative xi is obtained as the sum of the values
assigned by each expert:
</bodyText>
<equation confidence="0.941934333333333">
m
r(xi) = E rk(xi) (2)
k=1
</equation>
<bodyText confidence="0.9978972">
In order to fill the preference matrix with the
correct confidence values, the output weights
w1, w2,. . . , wn of each expert k are transformed to
fuzzy confidence values by means of the following
transformation:
</bodyText>
<equation confidence="0.993196">
rkij = wi (3)
wi + wj
</equation>
<bodyText confidence="0.999900666666667">
An example of how fuzzy Borda is used to combine
the votes in order to obtain the right sense of the
target word is shown in Section 4.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="method">
3 WSD Experts
</sectionHeader>
<bodyText confidence="0.99998525">
We considered five experts in order to carry out
the disambiguation process. Sense probability and
the extended lesk were available for every word,
while the Conceptual Density was calculated only
for nouns. Therefore, all the experts were available
only for the nouns. For each expert different con-
texts were taken into account, depending on the spe-
cific characteristics of each expert.
</bodyText>
<subsectionHeader confidence="0.997303">
3.1 Sense Probability
</subsectionHeader>
<bodyText confidence="0.9999455">
This expert is the simplest one: its votes are calcu-
lated using only the frequency count in SemCor of
the WordNet senses of the word. The transformation
of the frequency counts to the preference ranking is
done according to Formula (3). Zero frequency are
normalized to 1.
</bodyText>
<subsectionHeader confidence="0.997659">
3.2 Conceptual Density
</subsectionHeader>
<bodyText confidence="0.998970166666667">
Conceptual Density (CD) was originally introduced
by (Agirre and Rigau, 1996). It is computed on
WordNet subhierarchies, determined by the hyper-
nymy (or is-a) relationship. Our formulation (Rosso
et al., 2003) of the Conceptual Density of a WordNet
subhierarchy s is:
</bodyText>
<equation confidence="0.981021375">
�
� � � �
�
� � � �
CD(m, f, n) = mα
�m �
n
(4)
</equation>
<page confidence="0.982671">
435
</page>
<bodyText confidence="0.999894038461539">
Where m are the relevant synsets in the subhierar-
chy, n is the total number of synsets in the subhierar-
chy.The relevant synsets are both the synsets of the
word to be disambiguated and those of the context
words.
The WSD system based on this formula par-
ticipated at the Senseval-3 competition as the
CIAOSENSO system (Buscaldi et al., 2004), ob-
taining 75.3% in precision over nouns in the all-
words task (baseline: 70.1%). These results were
obtained with a context window of two nouns, the
one preceding and the one following the word. In
Senseval-3 the WSD system took also into account
the frequency of senses depending on their rank. In
SemEval-1 we do not, because of the presence of the
Sense Probability expert.
The CD-based expert uses a context of two nouns
for the disambiguation process too. The weights
from Formula (4) are used for computing the fuzzy
confidence values that are used to fill the preference
matrix after they are transformed according to For-
mula (3).
A second CD-based expert exploits the holonymy,
or part-of relationship instead of hyperonymy. This
expert uses as context all the nouns in the sentence
of the word to be disambiguated.
</bodyText>
<subsectionHeader confidence="0.995219">
3.3 Extended Lesk
</subsectionHeader>
<bodyText confidence="0.999508409090909">
This expert is based on the algorithm by (Banerjee
and Pedersen, 2002), a WordNet-enhanced version
of the well-known dictionary-based algorithm pro-
posed by (Lesk, 1986). The original Lesk was based
on the comparison of the gloss of the word to be dis-
ambiguated with the context words and their glosses.
This enhancement consists in taking into account
also the glosses of concepts related to the word to
be disambiguated by means of various WordNet re-
lationships. Then similarity between a sense of the
word and the context is calculated by means of over-
laps. The word is assigned the sense obtaining the
best overlap match with the glosses of the context
words and their related synsets.
The weights used as input for Formula (3) are the
similarity values between the senses of the world
and the context words. The context for this ex-
pert consists of 4 WordNet words (disregarding their
Part-Of-Speech) located in the same sentence of the
word to be disambiguated, i.e., words with POS
noun, verb, adjective or adverb that can be found in
WordNet.
</bodyText>
<subsectionHeader confidence="0.970245">
3.4 WordNet Domains
</subsectionHeader>
<bodyText confidence="0.999676888888889">
This expert uses WordNet Domains (Magnini and
Cavagli`a, 2000) in order to provide the system with
domain-awareness. All WordNet words in the same
sentence of the target word are used as context. The
weight for each sense is obtained by counting the
number of times the same domain of the sense ap-
pears in the context (all senses of context words are
considered). We decided to not take into account the
“factotum” domain.
</bodyText>
<sectionHeader confidence="0.998833" genericHeader="method">
4 Example
</sectionHeader>
<bodyText confidence="0.996573533333333">
In this example we will consider only the sense
probability and extended Lesk experts for simplic-
ity.
Let us consider the following phrase: “And he has
kept mum on how his decision might affect a bid
for United Airlines , which includes a big stake by
British Airways PLC.” with affect as target word.
We can observe that in WordNet the verb affect has
5 senses. The sense count values are 43 for the first
sense, 11 for the second, 4 for both the third and the
fourth one, and 0 for the last one. We decided to nor-
malize the cases with 0 occurrences to 1. After ap-
plying the transformation (3) to the sense counts, we
obtain the following preference matrix for the sense
probability expert:
</bodyText>
<table confidence="0.998866142857143">
0.5 0.80 0.91 0.91 0.98
�
� 0.20 0.5 0.73 0.73 0.92
0.09 0.27 0.5 0.5 0.8
� � � � 0.27 0.5 0.5 0.8
0.09 I
� 0.02 0.08 0.2 0.2 0.5
</table>
<bodyText confidence="0.999766818181818">
Therefore, the final fuzzy Borda counts by the
sense probability expert are 3.60 for affect(1),
2.38 for affect(2), 0.8 for affect(3) and
affect(4), and 0 for affect(5), obtained
from the sum of the rows where the value is greater
than 0.5.
The extended Lesk expert calculates the following
similarity scores for thesenses of affect, with context
words decision, might, bid and include: respectively
107, 70, 35, 63 and 71 for senses 1 to 5. After apply-
ing the transformation (3) to the weights, we obtain
</bodyText>
<page confidence="0.998278">
436
</page>
<table confidence="0.9960225">
the preference matrix for this expert:
0.5 0.60 0.75 0.63 0.60
�
� 0.40 0.5 0.67 0.53 0.49
0.25 0.33 0.5 0.36 0.33
� � � � 0.47 0.64 0.5 0.47
0.37
� 0.40 0.51 0.67 0.53 0.5
</table>
<bodyText confidence="0.998593333333333">
In this case the final fuzzy Borda counts are 2.58 for
the first sense, 1.2 for sense 2, 0 for sense 3, 0.64
and 1.71 for senses 4 and 5 respectively.
Finally, the sum of Borda counts of every expert
for each sense (see Table 4) are used to disambiguate
the word.
</bodyText>
<table confidence="0.99313025">
sense no: 1 2 3 4 5
expert 1 3.60 2.38 0.80 0.80 0
expert 2 2.58 1.20 0 0.64 1.71
total: 6.18 3.58 0.80 1.44 1.71
</table>
<tableCaption confidence="0.99359">
Table 1: Borda Count for the verb affect in the ex-
ample phrase.
</tableCaption>
<sectionHeader confidence="0.999933" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.9764110625">
The system was not tested before SemEval. Our par-
ticipation was limited to the All-Word and Coarse-
Grained tasks (without the sense inventory provided
by the organizers). The results are compared to the
best system and the MFS (Most Frequent Sense)
baseline. We calculated also the partial results over
nouns in the all word task, obtaining that the MFS
baseline in this case is about 0.633, whereas our sys-
tem obtains 0.520.
task upv-wsd MFS best system
coarse-grained 0.786 0.789 0.832
awt 0.420 0.471 0.537
Table 2: Recall obtained by our system (upv-wsd)
in each task we participated in, compared with the
most frequent sense baseline and the best system in
the task.
</bodyText>
<sectionHeader confidence="0.999705" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999975222222222">
The combination of different systems allowed us to
attain higher recall than with our previous system
used in Senseval-3. However, overall results were
not as good as expected. Partial results over the
nouns show that the CD expert did not perform as
in the Senseval-3 and that the CD formula needs to
include sense frequency ranking in order to achieve
a good performance. As a further work we plan to
add a weight reflecting the reliability of each expert.
</bodyText>
<sectionHeader confidence="0.98146" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99931125">
We would like to thank the TIN2006-15265-C06-04 research
project for partially supporting this work. We would also like to
thank Prof. Eugene Levner of the Holon Institute of Technology
for inspiring us to use the fuzzy Borda voting scheme.
</bodyText>
<sectionHeader confidence="0.999667" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999803971428572">
Eneko Agirre and German Rigau. 1996. Word sense dis-
ambiguation using conceptual density. In COLING,
pages 16–22.
Satanjeev Banerjee and Ted Pedersen. 2002. An adapted
lesk algorithm for word sense disambiguation using
wordnet. In Proceedings of CICLing 2002, pages 136–
145, London, UK. Springer-Verlag.
Davide Buscaldi, Paolo Rosso, and Francesco Masulli.
2004. The upv-unige-CIAOSENSO WSD System.
In Proc. of Senseval-3 Workshop, Barcelona (Spain),
July. ACL.
Jos´e Luis Garcia Lapresta and Miguel Martinez Panero.
2002. Borda Count Versus Approval Voting: A Fuzzy
Approach. Public Choice, 112(1-2):167–184.
Michael Lesk. 1986. Automatic sense disambiguation
using machine readable dictionaries: how to tell a pine
cone from an ice cream cone. In Proc. of SIGDOC
’86, pages 24–26.
Bernardo Magnini and Gabriela Cavagli`a. 2000. Inte-
grating Subject Field Codes into WordNet. In Proc. of
the 2nd LREC Conference, pages 1413–1418, Athens,
Greece.
Hannu Nurmi. 2001. Resolving Group Choice Para-
doxes Using Probabilistic and Fuzzy Concepts. Group
Decision and Negotiation, 10(2):177–199.
Paolo Rosso, Francesco Masulli, Davide Buscaldi, Fer-
ran Pla, and Antonio Molina. 2003. Automatic noun
sense disambiguation. In Proc. of CICLing 2003,
pages 273–276.
Sonia Vazquez, Rafael Romero, Armando Suarez, An-
dres Montoyo, Manuel Garcia, M. Teresa Martin,
M. Angel Garcia, Alfonso Ure˜na, Davide Buscaldi,
Paolo Rosso, Antonio Molina, Ferran Pla, and Encarna
Segarra. 2004. The R2D2 Team at SENSEVAL-3. In
Proc. of Senseval-3 Workshop.
</reference>
<figure confidence="0.491928">
I
</figure>
<page confidence="0.986366">
437
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.507710">
<title confidence="0.999686">UPV-WSD : Combining different WSD Methods</title>
<author confidence="0.835967">by means of Fuzzy Borda Voting Buscaldi Rosso</author>
<affiliation confidence="0.992903">DSIC, Dpto. Sistemas Informiticos y Computaci´on Universidad Polit´ecnica de Valencia</affiliation>
<address confidence="0.876321">Valencia, Spain</address>
<abstract confidence="0.99291475">This paper describes the WSD system developed for our participation to the SemEval-1. It combines various methods by means of a fuzzy Borda voting. The fuzzy Borda votecounting scheme is one of the best known methods in the field of collective decision making. In our system the different disambiguation methods are considered as experts that give a preference ranking for the senses a word can be assigned. Then the preferences are evaluated using the fuzzy Borda scheme in order to select the best sense. The methods we considered are the sense frequency probability calculated over SemCor, the Conceptual Density calculated over both hyperonyms and meronyms hyerarchies in WordNet, the extended Lesk by Banerjee and Pedersen, and finally a method based on WordNet domains.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>German Rigau</author>
</authors>
<title>Word sense disambiguation using conceptual density.</title>
<date>1996</date>
<booktitle>In COLING,</booktitle>
<pages>16--22</pages>
<contexts>
<context position="6497" citStr="Agirre and Rigau, 1996" startWordPosition="1111" endWordPosition="1114">nceptual Density was calculated only for nouns. Therefore, all the experts were available only for the nouns. For each expert different contexts were taken into account, depending on the specific characteristics of each expert. 3.1 Sense Probability This expert is the simplest one: its votes are calculated using only the frequency count in SemCor of the WordNet senses of the word. The transformation of the frequency counts to the preference ranking is done according to Formula (3). Zero frequency are normalized to 1. 3.2 Conceptual Density Conceptual Density (CD) was originally introduced by (Agirre and Rigau, 1996). It is computed on WordNet subhierarchies, determined by the hypernymy (or is-a) relationship. Our formulation (Rosso et al., 2003) of the Conceptual Density of a WordNet subhierarchy s is: � � � � � � � � � � CD(m, f, n) = mα �m � n (4) 435 Where m are the relevant synsets in the subhierarchy, n is the total number of synsets in the subhierarchy.The relevant synsets are both the synsets of the word to be disambiguated and those of the context words. The WSD system based on this formula participated at the Senseval-3 competition as the CIAOSENSO system (Buscaldi et al., 2004), obtaining 75.3%</context>
</contexts>
<marker>Agirre, Rigau, 1996</marker>
<rawString>Eneko Agirre and German Rigau. 1996. Word sense disambiguation using conceptual density. In COLING, pages 16–22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satanjeev Banerjee</author>
<author>Ted Pedersen</author>
</authors>
<title>An adapted lesk algorithm for word sense disambiguation using wordnet.</title>
<date>2002</date>
<booktitle>In Proceedings of CICLing 2002,</booktitle>
<pages>136--145</pages>
<publisher>Springer-Verlag.</publisher>
<location>London, UK.</location>
<contexts>
<context position="3584" citStr="Banerjee and Pedersen, 2002" startWordPosition="575" endWordPosition="578">da (Nurmi, 2001; Garcia Lapresta and Martinez 434 Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 434–437, Prague, June 2007. c�2007 Association for Computational Linguistics Panero, 2002), one of the best known methods in the field of collective decision making. With this scheme the disambiguation methods are considered as experts providing a preference ranking over the sense of the word. The methods we choose as experts are the sense probability calculated over SemCor, the Conceptual Density algorithm by (Rosso et al., 2003), the extended Lesk by (Banerjee and Pedersen, 2002), and an algorithm that takes into account the domains of the word to be disambiguated and the context words. In the following sections we describe in detail the fuzzy Borda scheme and each WSD expert. 2 The Fuzzy Borda voting scheme The original Borda vote-counting scheme was introduced in 1770 by Jean Charles de Borda, and adopted by the French Academy of Sciences with the purpose of selecting its members. In the classical Borda count each expert gives a mark to each alternative, according to the number of alternatives worse than it. The fuzzy variant (Nurmi, 2001; Garcia Lapresta and Martin</context>
<context position="7993" citStr="Banerjee and Pedersen, 2002" startWordPosition="1375" endWordPosition="1378">their rank. In SemEval-1 we do not, because of the presence of the Sense Probability expert. The CD-based expert uses a context of two nouns for the disambiguation process too. The weights from Formula (4) are used for computing the fuzzy confidence values that are used to fill the preference matrix after they are transformed according to Formula (3). A second CD-based expert exploits the holonymy, or part-of relationship instead of hyperonymy. This expert uses as context all the nouns in the sentence of the word to be disambiguated. 3.3 Extended Lesk This expert is based on the algorithm by (Banerjee and Pedersen, 2002), a WordNet-enhanced version of the well-known dictionary-based algorithm proposed by (Lesk, 1986). The original Lesk was based on the comparison of the gloss of the word to be disambiguated with the context words and their glosses. This enhancement consists in taking into account also the glosses of concepts related to the word to be disambiguated by means of various WordNet relationships. Then similarity between a sense of the word and the context is calculated by means of overlaps. The word is assigned the sense obtaining the best overlap match with the glosses of the context words and thei</context>
</contexts>
<marker>Banerjee, Pedersen, 2002</marker>
<rawString>Satanjeev Banerjee and Ted Pedersen. 2002. An adapted lesk algorithm for word sense disambiguation using wordnet. In Proceedings of CICLing 2002, pages 136– 145, London, UK. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Davide Buscaldi</author>
<author>Paolo Rosso</author>
<author>Francesco Masulli</author>
</authors>
<title>The upv-unige-CIAOSENSO WSD System. In</title>
<date>2004</date>
<booktitle>Proc. of Senseval-3 Workshop,</booktitle>
<publisher>ACL.</publisher>
<location>Barcelona</location>
<contexts>
<context position="1131" citStr="Buscaldi et al., 2004" startWordPosition="173" endWordPosition="176"> our system the different disambiguation methods are considered as experts that give a preference ranking for the senses a word can be assigned. Then the preferences are evaluated using the fuzzy Borda scheme in order to select the best sense. The methods we considered are the sense frequency probability calculated over SemCor, the Conceptual Density calculated over both hyperonyms and meronyms hyerarchies in WordNet, the extended Lesk by Banerjee and Pedersen, and finally a method based on WordNet domains. 1 Introduction One of the lessons learned from our previous experience at Senseval-31 (Buscaldi et al., 2004; Vazquez et al., 2004) is that the integration of different systems usually works better than a standalone system. In our opinion this reflects the reality where humans do not apply always the same rule in order to disambiguate the same ambigue word; for instance, if we consider the sentences “He hit a home run” and “The thermometer hit 100 degrees”, in the first case the sport domain helps in determining the right sense for 1http://www.senseval.org hit, whereas in the latter the disambiguation is carried out mostly depending on the fact that the subject of the sentence is an object. The comb</context>
<context position="7080" citStr="Buscaldi et al., 2004" startWordPosition="1221" endWordPosition="1224"> introduced by (Agirre and Rigau, 1996). It is computed on WordNet subhierarchies, determined by the hypernymy (or is-a) relationship. Our formulation (Rosso et al., 2003) of the Conceptual Density of a WordNet subhierarchy s is: � � � � � � � � � � CD(m, f, n) = mα �m � n (4) 435 Where m are the relevant synsets in the subhierarchy, n is the total number of synsets in the subhierarchy.The relevant synsets are both the synsets of the word to be disambiguated and those of the context words. The WSD system based on this formula participated at the Senseval-3 competition as the CIAOSENSO system (Buscaldi et al., 2004), obtaining 75.3% in precision over nouns in the allwords task (baseline: 70.1%). These results were obtained with a context window of two nouns, the one preceding and the one following the word. In Senseval-3 the WSD system took also into account the frequency of senses depending on their rank. In SemEval-1 we do not, because of the presence of the Sense Probability expert. The CD-based expert uses a context of two nouns for the disambiguation process too. The weights from Formula (4) are used for computing the fuzzy confidence values that are used to fill the preference matrix after they are</context>
</contexts>
<marker>Buscaldi, Rosso, Masulli, 2004</marker>
<rawString>Davide Buscaldi, Paolo Rosso, and Francesco Masulli. 2004. The upv-unige-CIAOSENSO WSD System. In Proc. of Senseval-3 Workshop, Barcelona (Spain), July. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jos´e Luis Garcia Lapresta</author>
<author>Miguel Martinez Panero</author>
</authors>
<title>Borda Count Versus Approval Voting: A Fuzzy Approach. Public Choice,</title>
<date>2002</date>
<pages>112--1</pages>
<marker>Lapresta, Panero, 2002</marker>
<rawString>Jos´e Luis Garcia Lapresta and Miguel Martinez Panero. 2002. Borda Count Versus Approval Voting: A Fuzzy Approach. Public Choice, 112(1-2):167–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Lesk</author>
</authors>
<title>Automatic sense disambiguation using machine readable dictionaries: how to tell a pine cone from an ice cream cone.</title>
<date>1986</date>
<booktitle>In Proc. of SIGDOC ’86,</booktitle>
<pages>24--26</pages>
<contexts>
<context position="8091" citStr="Lesk, 1986" startWordPosition="1390" endWordPosition="1391">es a context of two nouns for the disambiguation process too. The weights from Formula (4) are used for computing the fuzzy confidence values that are used to fill the preference matrix after they are transformed according to Formula (3). A second CD-based expert exploits the holonymy, or part-of relationship instead of hyperonymy. This expert uses as context all the nouns in the sentence of the word to be disambiguated. 3.3 Extended Lesk This expert is based on the algorithm by (Banerjee and Pedersen, 2002), a WordNet-enhanced version of the well-known dictionary-based algorithm proposed by (Lesk, 1986). The original Lesk was based on the comparison of the gloss of the word to be disambiguated with the context words and their glosses. This enhancement consists in taking into account also the glosses of concepts related to the word to be disambiguated by means of various WordNet relationships. Then similarity between a sense of the word and the context is calculated by means of overlaps. The word is assigned the sense obtaining the best overlap match with the glosses of the context words and their related synsets. The weights used as input for Formula (3) are the similarity values between the</context>
</contexts>
<marker>Lesk, 1986</marker>
<rawString>Michael Lesk. 1986. Automatic sense disambiguation using machine readable dictionaries: how to tell a pine cone from an ice cream cone. In Proc. of SIGDOC ’86, pages 24–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernardo Magnini</author>
<author>Gabriela Cavagli`a</author>
</authors>
<title>Integrating Subject Field Codes into WordNet.</title>
<date>2000</date>
<booktitle>In Proc. of the 2nd LREC Conference,</booktitle>
<pages>1413--1418</pages>
<location>Athens, Greece.</location>
<marker>Magnini, Cavagli`a, 2000</marker>
<rawString>Bernardo Magnini and Gabriela Cavagli`a. 2000. Integrating Subject Field Codes into WordNet. In Proc. of the 2nd LREC Conference, pages 1413–1418, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hannu Nurmi</author>
</authors>
<title>Resolving Group Choice Paradoxes Using Probabilistic and Fuzzy Concepts. Group Decision and</title>
<date>2001</date>
<journal>Negotiation,</journal>
<volume>10</volume>
<issue>2</issue>
<contexts>
<context position="2971" citStr="Nurmi, 2001" startWordPosition="486" endWordPosition="487">ost voted sense. In our previous participation with the R2D2 project (Vazquez et al., 2004) the selection was rule-based, with hand-made rules that attempted to take into account the reliability of the various method. We subsequently attempted to learn automatically the rules, but the results of these experiments did not allow to determine clearly which method was to be used in each context. Working with probabilities can be problematic due to the null probabilities that make necessary the adoption of smoothing techniques. Therefore, we opted for a voting scheme, in this case the fuzzy Borda (Nurmi, 2001; Garcia Lapresta and Martinez 434 Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 434–437, Prague, June 2007. c�2007 Association for Computational Linguistics Panero, 2002), one of the best known methods in the field of collective decision making. With this scheme the disambiguation methods are considered as experts providing a preference ranking over the sense of the word. The methods we choose as experts are the sense probability calculated over SemCor, the Conceptual Density algorithm by (Rosso et al., 2003), the extended Lesk by (Banerjee and Pe</context>
</contexts>
<marker>Nurmi, 2001</marker>
<rawString>Hannu Nurmi. 2001. Resolving Group Choice Paradoxes Using Probabilistic and Fuzzy Concepts. Group Decision and Negotiation, 10(2):177–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paolo Rosso</author>
<author>Francesco Masulli</author>
<author>Davide Buscaldi</author>
<author>Ferran Pla</author>
<author>Antonio Molina</author>
</authors>
<title>Automatic noun sense disambiguation.</title>
<date>2003</date>
<booktitle>In Proc. of CICLing</booktitle>
<pages>273--276</pages>
<contexts>
<context position="3532" citStr="Rosso et al., 2003" startWordPosition="566" endWordPosition="569">a voting scheme, in this case the fuzzy Borda (Nurmi, 2001; Garcia Lapresta and Martinez 434 Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 434–437, Prague, June 2007. c�2007 Association for Computational Linguistics Panero, 2002), one of the best known methods in the field of collective decision making. With this scheme the disambiguation methods are considered as experts providing a preference ranking over the sense of the word. The methods we choose as experts are the sense probability calculated over SemCor, the Conceptual Density algorithm by (Rosso et al., 2003), the extended Lesk by (Banerjee and Pedersen, 2002), and an algorithm that takes into account the domains of the word to be disambiguated and the context words. In the following sections we describe in detail the fuzzy Borda scheme and each WSD expert. 2 The Fuzzy Borda voting scheme The original Borda vote-counting scheme was introduced in 1770 by Jean Charles de Borda, and adopted by the French Academy of Sciences with the purpose of selecting its members. In the classical Borda count each expert gives a mark to each alternative, according to the number of alternatives worse than it. The fu</context>
<context position="6629" citStr="Rosso et al., 2003" startWordPosition="1131" endWordPosition="1134">contexts were taken into account, depending on the specific characteristics of each expert. 3.1 Sense Probability This expert is the simplest one: its votes are calculated using only the frequency count in SemCor of the WordNet senses of the word. The transformation of the frequency counts to the preference ranking is done according to Formula (3). Zero frequency are normalized to 1. 3.2 Conceptual Density Conceptual Density (CD) was originally introduced by (Agirre and Rigau, 1996). It is computed on WordNet subhierarchies, determined by the hypernymy (or is-a) relationship. Our formulation (Rosso et al., 2003) of the Conceptual Density of a WordNet subhierarchy s is: � � � � � � � � � � CD(m, f, n) = mα �m � n (4) 435 Where m are the relevant synsets in the subhierarchy, n is the total number of synsets in the subhierarchy.The relevant synsets are both the synsets of the word to be disambiguated and those of the context words. The WSD system based on this formula participated at the Senseval-3 competition as the CIAOSENSO system (Buscaldi et al., 2004), obtaining 75.3% in precision over nouns in the allwords task (baseline: 70.1%). These results were obtained with a context window of two nouns, the</context>
</contexts>
<marker>Rosso, Masulli, Buscaldi, Pla, Molina, 2003</marker>
<rawString>Paolo Rosso, Francesco Masulli, Davide Buscaldi, Ferran Pla, and Antonio Molina. 2003. Automatic noun sense disambiguation. In Proc. of CICLing 2003, pages 273–276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sonia Vazquez</author>
<author>Rafael Romero</author>
<author>Armando Suarez</author>
<author>Andres Montoyo</author>
<author>Manuel Garcia</author>
<author>M Teresa Martin</author>
<author>M Angel Garcia</author>
</authors>
<date>2004</date>
<booktitle>The R2D2 Team at SENSEVAL-3. In Proc. of Senseval-3 Workshop.</booktitle>
<location>Alfonso Ure˜na, Davide Buscaldi, Paolo Rosso, Antonio Molina, Ferran</location>
<contexts>
<context position="1154" citStr="Vazquez et al., 2004" startWordPosition="177" endWordPosition="180">nt disambiguation methods are considered as experts that give a preference ranking for the senses a word can be assigned. Then the preferences are evaluated using the fuzzy Borda scheme in order to select the best sense. The methods we considered are the sense frequency probability calculated over SemCor, the Conceptual Density calculated over both hyperonyms and meronyms hyerarchies in WordNet, the extended Lesk by Banerjee and Pedersen, and finally a method based on WordNet domains. 1 Introduction One of the lessons learned from our previous experience at Senseval-31 (Buscaldi et al., 2004; Vazquez et al., 2004) is that the integration of different systems usually works better than a standalone system. In our opinion this reflects the reality where humans do not apply always the same rule in order to disambiguate the same ambigue word; for instance, if we consider the sentences “He hit a home run” and “The thermometer hit 100 degrees”, in the first case the sport domain helps in determining the right sense for 1http://www.senseval.org hit, whereas in the latter the disambiguation is carried out mostly depending on the fact that the subject of the sentence is an object. The combination of distinct met</context>
<context position="2451" citStr="Vazquez et al., 2004" startWordPosition="400" endWordPosition="403">ers, how can we select the best one? In this sense the available choices are the following: • Rule-based selection: a set of rules that can be both hand-made or automatically learned from examples; • Probability-based: the output of the methods is normalized in the range [0, 1] and is considered as a probability. Then the values are multiplied in order to obtain the sense with a maximum probability. • Vote-based: the output of the methods is considered as a weighted vote. Then a voting scheme is used in order to obtain the most voted sense. In our previous participation with the R2D2 project (Vazquez et al., 2004) the selection was rule-based, with hand-made rules that attempted to take into account the reliability of the various method. We subsequently attempted to learn automatically the rules, but the results of these experiments did not allow to determine clearly which method was to be used in each context. Working with probabilities can be problematic due to the null probabilities that make necessary the adoption of smoothing techniques. Therefore, we opted for a voting scheme, in this case the fuzzy Borda (Nurmi, 2001; Garcia Lapresta and Martinez 434 Proceedings of the 4th International Workshop</context>
</contexts>
<marker>Vazquez, Romero, Suarez, Montoyo, Garcia, Martin, Garcia, 2004</marker>
<rawString>Sonia Vazquez, Rafael Romero, Armando Suarez, Andres Montoyo, Manuel Garcia, M. Teresa Martin, M. Angel Garcia, Alfonso Ure˜na, Davide Buscaldi, Paolo Rosso, Antonio Molina, Ferran Pla, and Encarna Segarra. 2004. The R2D2 Team at SENSEVAL-3. In Proc. of Senseval-3 Workshop.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>