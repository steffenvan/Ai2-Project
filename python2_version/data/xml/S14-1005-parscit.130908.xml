<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.9984325">
An Iterative ‘Sudoku Style’ Approach to Subgraph-based
Word Sense Disambiguation
</title>
<author confidence="0.996952">
Steve L. Manion
</author>
<affiliation confidence="0.712796">
University of Canterbury
Christchurch, New Zealand
steve.manion
</affiliation>
<email confidence="0.983516">
@pg.canterbury.ac.nz
</email>
<sectionHeader confidence="0.997118" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999869416666667">
We introduce an iterative approach to
subgraph-based Word Sense Disambigua-
tion (WSD). Inspired by the Sudoku puz-
zle, it significantly improves the precision
and recall of disambiguation. We describe
how conventional subgraph-based WSD
treats the two steps of (1) subgraph con-
struction and (2) disambiguation via graph
centrality measures as ordered and atomic.
Consequently, researchers tend to focus on
improving either of these two steps indi-
vidually, overlooking the fact that these
steps can complement each other if they
are allowed to interact in an iterative man-
ner. We tested our iterative approach
against the conventional approach for a
range of well-known graph centrality mea-
sures and subgraph types, at the sentence
and document level. The results demon-
strated that an average performing WSD
system which embraces the iterative ap-
proach, can easily compete with state-of-
the-art. This alone warrants further inves-
tigation.
</bodyText>
<sectionHeader confidence="0.999465" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999607375">
Explicit WSD is a two-step process of analysing a
word’s contextual use then deducing its intended
sense. When Kilgarriff (1998) established SEN-
SEVAL, the collaborative framework and forum to
evaluate WSD, unsupervised systems performed
poorly in comparison to their supervised counter-
parts (Palmer et al., 2001; Snyder and Palmer,
2004). A review of the literature shows there
</bodyText>
<footnote confidence="0.9597762">
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence de-
tails: http://creativecommons.org/licenses/
by/4.0/
</footnote>
<author confidence="0.728318">
Raazesh Sainudiin
</author>
<affiliation confidence="0.9065135">
University of Canterbury
Christchurch, New Zealand
</affiliation>
<email confidence="0.5960265">
r.sainudiin
@math.canterbury.ac.nz
</email>
<bodyText confidence="0.999983414634146">
has been a healthy rivalry between the two, in
which proponents of unsupervised WSD have long
sought to vindicate its potential since two decades
ago (Yarowsky, 1995) to even more recent times
(Ponzetto and Navigli, 2010).
As Pedersen (2007) rightly states, supervised
systems are bound by their training data, and
therefore are limited in portability and flexibility
in the face of new domains, changing applications,
or different languages. This knowledge acquisi-
tion bottleneck, coined by Gale et al. (1992), can
be alleviated by unsupervised systems that exploit
the portability and flexibility of Lexical Knowl-
edge Bases (LKBs). As of 2007, SENSEVAL be-
came SEMEVAL, offering a more diverse range of
semantic tasks. Unsupervised knowledge-based
WSD has since had its performance evaluated in
terms of granularity (Navigli et al., 2007), domain
(Agirre et al., 2010), and cross/multi-linguality
(Lefever and Hoste, 2010; Lefever and Hoste,
2013; Navigli et al., 2013). Results from these
tasks have demonstrated unsupervised systems are
now a competitive and robust alternative to super-
vised systems, especially given the ever changing
task-orientated settings WSD is evaluated in.
One such class of unsupervised knowledge-
based WSD systems that we seek to improve
in this paper constructs semantic subgraphs from
LKBs, and then runs graph-based centrality mea-
sures such as PageRank (Brin and Page, 1998)
over them to finally select the senses (as nodes)
ranked as the most relevant. This class is known
as subgraph-based WSD, characterised over the
last decade by performing the two key steps of (1)
subgraph construction and (2) disambiguation via
graph centrality measures, in an ordered atomic
sequence. We refer to this characteristic as the
conventional approach to subgraph-based WSD.
We propose an iterative approach to subgraph-
based WSD that allows for interaction between
the two major steps in an incremental manner
</bodyText>
<page confidence="0.984235">
40
</page>
<note confidence="0.9808815">
Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 40–50,
Dublin, Ireland, August 23-24 2014.
</note>
<bodyText confidence="0.999518">
and demonstrate its effectiveness across a range
of graph-based centrality measures and subgraph
construction methods at the sentence and docu-
ment levels of disambiguation.
</bodyText>
<sectionHeader confidence="0.974748" genericHeader="method">
2 The Conventional Subgraph Approach
</sectionHeader>
<bodyText confidence="0.9985115">
The conventional approach to subgraph WSD
firstly benefits from some preprocessing, in which
words in a sequence W, are mapped to their lem-
matisations1 in a set L, such that (w1, ..., wm) 7→
{`1, ..., `m}. This facilitates better lexical align-
ment with the LKB to be exploited. Let this LKB
be a large semantic graph G = (S, E), such that
S is a set of vertices representing all known word
senses, and E be a set of edges defining seman-
tic relationships that exist between senses. Now
given we wish to disambiguate `i ∈ L, let R(`i)
be a function that Retrieves from G, all the senses,
{si,1, si,2, ..., si,k}, that `i could refer to, noting
that i is an anchor to the original word wi.
</bodyText>
<subsectionHeader confidence="0.962876">
2.1 Step 1: Subgraph Construction
</subsectionHeader>
<bodyText confidence="0.999733857142857">
For unsupervised subgraph-based WSD, the key
publications that have advanced the field broadly
construct subgraph, GL, as either a union of sub-
tree paths, shortest paths, or local edges2. First
we initialise GL, by setting SL := Uni=1 R(`i) and
EL := ∅. Next we add edges to EL, depending on
the desired subgraph type, by adding either the:
</bodyText>
<listItem confidence="0.997723">
(a) Subtree paths of up to length L, via a Depth-
First Search (DFS) of G. In brief, for each
sense sa ∈ SL, if a new sense sb ∈ SL,
i.e. sb =6 sa, is encountered along a path
Pa,b = {{sa, s}, ..., {s&apos;, sb}} with path-
length |Pa,b |≤ L, then add Pa,b to GL.
[cf. Navigli and Velardi (2005), Navigli and
Lapata (2007), or Navigli and Lapata (2010)]
(b) Shortest paths, via a Breadth-First Search
(BFS) of G. In brief, for each sense pair
sa, sb ∈ SL, find the shortest path Pa,b =
{{sa, s},..., {s&apos;, sb}}; if such a path Pa,b ex-
ists and (optionally) |Pa,b |≤ L, then add
Pa,b to GL [cf. Agirre and Soroa (2008),
Agirre and Soroa (2009), or Gutiérrez et al.
(2013)]
</listItem>
<footnote confidence="0.9943695">
1For a detailed explanation of the processes leading up to
lemmatisation (and beyond), see Navigli (2009, p12)
2‘Local’ describes the local context, typically this is the 2
or 3 words either side of a word, see Yarowsky (1993)
</footnote>
<listItem confidence="0.862133125">
(c) Local edges up to a local distance D. In brief,
for each sense pair sa, sb ∈ SL, if the distance
in the text |b − a |between the corresponding
words wa and wb satisfies |b − a |≤ D, then
add edge {sa, sb} to GL (preferably with edge-
weights). [cf. Mihalcea (2005) or Sinha and
Mihalcea (2007)] (Note that this subgraph is a
hybrid, because only its vertices belong to G)
</listItem>
<bodyText confidence="0.994822">
In practice, subgraph edges may be directed,
weighted, collapsed, or filtered. However to keep
the distinctions between subgraph types simple,
we do not include this in our formalisation.
</bodyText>
<subsectionHeader confidence="0.998345">
2.2 Step 2: Disambiguation
</subsectionHeader>
<bodyText confidence="0.999874333333333">
To disambiguate each lemma `i ∈ L, its cor-
responding senses, R(`i) = {si,1, si,2, ..., si,k},
are scored by a graph-based centrality measure φ,
over subgraph GL, to estimate the most appropri-
ate sense, ˆsi,* = arg maxsjjER(`j) φ(si,j). The
estimated sense ˆsi,* is then assigned to word wi.
</bodyText>
<subsectionHeader confidence="0.977224">
2.3 Algorithm for Conventional Approach
</subsectionHeader>
<bodyText confidence="0.998895">
With both steps formalised, we can now illus-
trate the conventional subgraph approach in Algo-
rithm 1. Let L be taken as input, and let the disam-
biguation results D = {ˆs1,*, ..., ˆsm,*} be produced
as output to assign to W = (w1, ..., wm).
</bodyText>
<equation confidence="0.923511125">
Algorithm 1: Conventional Approach
Input: L
Output: D
D ← ∅;
GL ← ConstructSubGraph (L);
foreach `i ∈ L do
ˆsi,* ← arg maxsj�,ER(`j) φ(si,j);
put ˆsi,* in D;
</equation>
<bodyText confidence="0.999946833333333">
To begin with, D is initialised as an empty set
and ConstructSubGraph(L) constructs one
of the three subgraphs described in section 2.1.
Next for each `i ∈ L, by running a graph based
centrality measure φ over GL, the most appropriate
sense ˆsi,* is estimated, and placed in set D. Effec-
tively, L is a context window based on document
or sentence size, therefore this algorithm is run
for each context window division. Note that Al-
gorithm 1 would require a little extra complexity
to handle local edge subgraphs, due to its context
window needing to satisfy L = {`i_D, ..., `i+D}.
</bodyText>
<page confidence="0.998451">
41
</page>
<figure confidence="0.999354870967742">
(a) 1st Row/Column Elimination
(b) 2nd Row/Column Elimination
6
1
8
1
7
9
8
4
7
4 9 7
1 2 6
6 9 8 4
2 5
3 2 9
2
5
6 9
1 2 3
4 5 6
7 8 9
1 5
3
3
8
6
1 2 3
4 5 6
7 8 9
1 2 3
4 5 6
7 8 9
1
7
1 6 4 9 7
8 1 2 6
1 6 9 8 4
9 7 2 5
8 4 3 2 9
1 2 3
6 9 4 5 6 1 5
7 8 9
3
8
1 2 3
4 5 6
7 8 9
5 2
1
3
8 6
4 3 9 7 2 6 1 5 8
2 1 6 8 3 5 4 9 7
5 7 8 1 9 4 3 2 6
1 2 3 6 5 9 7 8 4
9 6 7 4 1 8 2 3 5
8 4 5 3 7 2 6 1 9
6 9 4 2 8 1 5 7 3
3 5 2 9 4 7 8 6 1
7 8 1 5 6 3 9 4 2
(c) Row/Column/Box Completion
</figure>
<figureCaption confidence="0.999898">
Figure 1: Iterative Solving of Sudoku Grids
</figureCaption>
<sectionHeader confidence="0.981456" genericHeader="method">
3 The Iterative Subgraph Approach
</sectionHeader>
<subsectionHeader confidence="0.996278">
3.1 What is Iterative WSD?
</subsectionHeader>
<bodyText confidence="0.999938846153846">
The key observation to make about the conven-
tional approach in Algorithm 1, is for input L,
constructing subgraph GL and performing disam-
biguation are two ordered atomic steps. Notice
that there is no iteration between them, because
the first step of subgraph construction is never re-
visited for each L. For the conventional process
to be iterative, then for Ea, Eb ∈ L a previous dis-
ambiguation of Ea, would need to influence a con-
secutive disambiguation of Eb, through an iterative
re-construction of GL between each disambigua-
tion. This key difference illustrated by Figure 2, is
the level of iterative WSD we aspire to.
</bodyText>
<figure confidence="0.9130845">
reconstruct
(b) Interactively Iterative Approach
</figure>
<figureCaption confidence="0.999964">
Figure 2: The Key Difference In Approach
</figureCaption>
<bodyText confidence="0.972693238095238">
It is important to note, the term iterative can al-
ready be found in WSD literature, therefore we
take the opportunity here to make a distinction.
Firstly, a graph based centrality measure 0 may
be iterative, such as PageRank (Brin and Page,
1998) or Hyperlink-Induced Topic Search (HITS)
(Kleinberg, 1999). In the experiments by Mihal-
cea (2005) in which PageRank was run over local
edge subgraphs (as described in 2.1 (c)), it is easy
to perceive the WSD process itself as iterative.
Iteration can again be taken further, as observed
with Personalised PageRank in which Agirre and
Soroa (2009) apply the idea of biasing values in
the random surfing vector, v, (see (Haveliwala,
2003)). For their run labelled “Ppr_w2w”, in or-
der to avoid senses anchored to the same lemma
assisting each other’s 0 score, the random surfing
vector v is iteratively updated as Ei changes, to en-
sure context senses sa,j ∈ v such that a =6 i are
the only senses that receive probability mass.
update
</bodyText>
<figureCaption confidence="0.999186">
Figure 3: Atomically Iterative Approach
</figureCaption>
<bodyText confidence="0.999823285714286">
In summary, iteration in the literature either de-
scribes 0 as being iterative or being iteratively ad-
justed, both of which are contained in the disam-
biguation step alone as shown in Figure 3. This is
iteration at the atomic level and should not be con-
flated with the interactive level of iteration that we
propose as seen in Figure 2 (b).
</bodyText>
<subsectionHeader confidence="0.999658">
3.2 Iteratively Solving a Sudoku Grid
</subsectionHeader>
<bodyText confidence="0.999918454545455">
In Figures 1 (a), (b), and (c), we observe the solv-
ing of a Sudoku puzzle, in which the numbers
from 1 to 9 must be assigned only once to each
column, row, and 3x3 square. Each time a number
is assigned and the Sudoku grid is updated, this
is an iteration. For example, in the south west
square of grid (a) (i.e. Figure 1 (a)) unknown
cells can be assigned {1, 4, 7, 8}. Given that 1
has already been assigned to the 7th row and the
1st and 2nd columns, this singles it down to one
cell it can be assigned to. The iteration of grid
</bodyText>
<figure confidence="0.899879244444445">
(a) Conventional Approach
disambiguate
construct assign
L GL φ D
construct disambiguate
L GL
assign
φ
D
L GL
construct
disambiguate assign
φ D
42
• m b1 •
m • • •
• • • a2 •
d1 m c2
• • • m • m
• •
• • • • •
m d2 d3 •
• • • • d4
• •
m b2
• • •
(a) x2 Bi-semous Eliminations
• m b1 •
m • • •
• a2 •
• m c2
c1 • m • m
• • •
• • • •
m c3
• • • •
(b) x1 Tri-semous Elimination
(c) (ρm .)-semous Completion
• m b1 •
• m • • •
a1 • a2
• • m •
• m •
•
m
</figure>
<figureCaption confidence="0.999965">
Figure 4: Iterative Disambiguating of Subgraphs
</figureCaption>
<bodyText confidence="0.99998545">
(a), now makes possible the iteration of grid (b) to
eliminate the number 8 as the only possibility for
its assigned cell. This iterative process continues
until we reach the completed puzzle in grid (c).
Therefore in WSD terminology, with each cell we
disambiguate, a new grid is constructed, in which
knowledge is passed on to each consecutive itera-
tion.
Continuing with this line of thought, each un-
solved cell is ambiguous, with a degree of pol-
ysemy p, such that pmax &lt; 9. Again, the ini-
tial Sudoku grid has pre-solved cells, of which are
monosemous. This brings us to another key ob-
servation. Typically in Sudoku, it is necessary to
solve the least polysemous cells first, before you
can solve the more polysemous cells with a cer-
tainty. As the conventional approach exhibits no
Sudoku-like iteration, cells are solved without re-
gard to the p value of the cell, or any interactive
exploitation of previously solved cells.
</bodyText>
<subsectionHeader confidence="0.998041">
3.3 Iteratively Constructing a Subgraph
</subsectionHeader>
<bodyText confidence="0.998252571428571">
In our ‘Sudoku style’ approach, we propose dis-
ambiguating each ii in order of increasing poly-
semy p, iteratively reconstructing subgraph GL to
reflect 1) previous disambiguations and 2) the p
value of lemmas being disambiguated in the cur-
rent iteration. This is illustrated in Figures 4 (a),
(b), and (c) above.
Let m-labelled vertices describe monosemous
lemmas. In graph (a) (i.e. Figure 4) we observe
two bi-semous lemmas, a and b, in which our ar-
bitrary graph-based centrality measure 0 has se-
lected the second sense of a (i.e. a2) and the first
sense of b (i.e. b1) to be placed in D. For the next
iteration, you will notice the alternative senses for
a and b are removed from GL for the disambigua-
tion of tri-semous lemma c. The second sense of
lemma c manages to be selected by 0 with the help
of the previous disambiguation of lemma a. This
interactive and iterative process continues until we
reach the most polysemous lemma, which in our
example is d with pmax = 4 in graph (c).
</bodyText>
<sectionHeader confidence="0.524651" genericHeader="method">
3.4 Algorithm for Iterative Approach
</sectionHeader>
<bodyText confidence="0.913876">
We can formally describe what is happening in
Figure 4 with Algorithm 2. Effectively, this is a
recreation of Algorithm 1, which highlights the
differences in the conventional and iterative ap-
proach.
</bodyText>
<figure confidence="0.934396714285714">
Algorithm 2: Iterative Approach
Input: L
Output: D
D ← GetMonosemous (L);
A ← ∅;
for p ← 2 to pmax do
A ← AddPolysemous (L, p);
</figure>
<equation confidence="0.851662666666667">
GL ← ConstructSubGraph (A,D);
foreach ii E A do
ˆsi,* ← arg maxsjjES(tj) 0(si,j);
</equation>
<bodyText confidence="0.950771">
if ˆsi,* exists then
remove ii from A;
put ˆsi,* in D;
Firstly, as it reads GetMonosemous(L)
places all the senses of the monosemous lemmas
into the set of disambiguated lemmas D. This is
the equivalent of copying out an unsolved Sudoku
grid onto a piece of paper and adding in all the
initial hint numbers. Next the set A which holds
all ambiguous lemmas of polysemy &lt; p is ini-
tialised as an empty set. Now we are ready to
iterate through values of p, beginning from the
first iteration, by adding all bi-semous lemmas to
</bodyText>
<page confidence="0.998956">
43
</page>
<bodyText confidence="0.999984173913043">
A with the function AddPolysemous(L, ρ), no-
tice ρ places a restriction on the degree of poly-
semy a lemma ii E L can have before being added
to A.
We are now ready to create the first subgraph GL
with function ConstructSubGraph(A, D).
This previously used function in Algorithm 1, is
now modified to take the ambiguous lemmas of
polysemy G ρ in set A and previously disam-
biguated lemma senses in set D. The resulting
graph has a limited degree of polysemy and is con-
structed based on previous disambiguations.
From this point on the given graph centrality
measure 0 is run over GL. For the lemmas that
are disambiguated, they are removed from A and
the selected sense is added to D. For those lemmas
that are not (i.e. ˆsi,∗ does not exist3) they remain in
A to be involved in reattempted disambiguations
in consecutive iterations. As more lemmas are dis-
ambiguated, it is more likely that previously diffi-
cult to disambiguate lemmas become much easier
to solve, just like at the end of a Sudoku puzzle it
gets easier as you get closer to completing it.
</bodyText>
<sectionHeader confidence="0.999364" genericHeader="method">
4 Evaluations
</sectionHeader>
<bodyText confidence="0.999971181818182">
In our evaluations we set out to understand a num-
ber of aspects. The first evaluation is a proof of
concept, to understand whether an iterative ap-
proach to subgraph WSD can in fact achieve better
performance than the conventional approach. The
second set of experiments seeks to understand how
the iterative approach works and the performance
benefits and penalties of implementing the itera-
tive approach. Finally the third experiment is an
elementary attempt at optimising the iterative ap-
proach to defeat the MFS baseline.
</bodyText>
<subsectionHeader confidence="0.994669">
4.1 LKB &amp; Dataset
</subsectionHeader>
<bodyText confidence="0.999367">
For an evaluation, we have chosen the multi-
lingual LKB known as BabelNet (Navigli and
Ponzetto, 2012a). It weaves together several other
LKBs, most notably WordNet (Fellbaum, 1998)
and Wikipedia. It also can be easily accessed with
the BabelNet API, of which we have built our code
base around. All experiments are conducted on
the most recent SemEval WSD dataset, of which
is the SemEval 2013 Task 12 Multilingual WSD
(English) data set.
</bodyText>
<footnote confidence="0.884688">
3This can happen if Bi does not map to any senses, or
alternatively all the senses that are mapped to are filtered out
of the subgraph before disambiguation (explained later).
</footnote>
<subsectionHeader confidence="0.98535">
4.2 Graph Centrality Measures Evaluated
</subsectionHeader>
<bodyText confidence="0.99928175">
To demonstrate the effectiveness of our iterative
approach, we selected a range of WSD graph-
based centrality measures often experimented with
in the literature. Firstly 0 does not need to be a
complicated measure, this is demonstrated by the
success of ranking senses by their number of in-
coming and outgoing edges. Even though it is very
simple, it performs surprisingly well against others
for both In-Degree (Navigli and Lapata, 2007) and
Out-Degree (Navigli and Ponzetto, 2012a)
Next we employ graph centrality measures
that are primarily used to disambiguate the se-
mantic web, such as PageRank (Brin and Page,
1998), HITS Kleinberg (1999), and apersonalised
PageRank (Haveliwala, 2003); which have since
been applied to WSD by Mihalcea (2005), Navigli
and Lapata (2007), and Agirre and Soroa (2009)
respectively. We also include Betweeness Central-
ity (Freeman, 1979) which is taken from the anal-
ysis of social networks.
These methods are well known and applied
across many disciplines, therefore we will leave it
to the reader to follow up on the specifics of these
graph centrality measures. However we do ex-
plicitly define our last measure, Sum Inverse Path
Length (Navigli and Ponzetto, 2012a; Navigli and
Ponzetto, 2012b) in Equation (1) which was de-
signed with WSD in mind, thus is less well known.
</bodyText>
<equation confidence="0.913044">
e|p 1-1 (1)
</equation>
<bodyText confidence="0.9999401">
This measure scores a sense by summing up the
scores of all paths that connect to other senses in
GL (i.e. senses that are not intermediate nodes, but
have a mapping back to a lemma in the context
window L). In the words of Navigli and Ponzetto
(2012a), Ps→c is the set of paths connecting s
to other senses of context words, with |p |as the
number of edges in the path p and each path is
scored with the exponential inverse decay of the
path length.
</bodyText>
<subsectionHeader confidence="0.9951555">
4.3 Experiment 1: Proof of Concept
4.3.1 Experiment 1: Setup
</subsectionHeader>
<bodyText confidence="0.998489">
For this experiment we simply set out to see how
the iterative approach performed compared to the
conventional approach in a range of experimental
conditions. Directed and unweighted subgraphs
were used, namely subtree paths and shortest paths
subgraphs with L = 2. To address the issue of
</bodyText>
<equation confidence="0.810765333333333">
1:
0(s) =
pEPs→c
</equation>
<page confidence="0.996014">
44
</page>
<table confidence="0.998539823529412">
Conventional Doc Iterative Doc Improvement
P R F P R F OP OR OF
φ
In-Degree 61.70 55.51 58.44 65.39 63.74 64.55 +3.69 +8.23 +6.11
Out-Degree 54.23 48.78 51.36 57.70 56.23 56.96 +3.47 +7.45 +5.60
Betweenness Centrality 59.29 53.34 56.15 63.43 61.82 62.61 +4.14 +8.48 +6.46
Sum Inverse Path Length 56.58 50.90 53.59 58.86 57.37 58.11 +2.28 +6.47 +4.52
HITS(hub) 54.69 49.20 51.80 59.71 58.20 58.95 +5.02 +9.00 +7.15
HITS(authority) 57.45 51.68 54.41 61.62 60.06 60.83 +4.17 +8.38 +6.42
PageRank 60.09 54.06 56.91 64.07 62.44 63.24 +3.98 +8.38 +6.33
In-Degree 63.06 56.08 59.36 65.36 63.06 64.19 +2.30 +6.98 +4.83
Out-Degree 57.07 50.75 53.72 61.14 58.90 60.01 +4.07 +8.15 +6.29
Betweenness Centrality 60.33 53.65 56.79 65.52 63.22 64.35 +5.19 +9.57 +7.56
Sum Inverse Path Length 57.53 51.16 54.16 61.19 58.98 60.06 +3.66 +7.82 +5.90
HITS(hub) 57.48 51.11 54.11 62.14 59.96 61.03 +4.66 +8.85 +6.92
HITS(authority) 60.91 54.16 57.34 63.54 61.30 62.40 +2.63 +7.14 +5.06
PageRank 61.14 54.37 57.55 65.25 62.96 64.09 +4.11 +8.59 +6.54
</table>
<tableCaption confidence="0.995953">
Table 1: Improvements of using the Iterative Approach at the Document Level
</tableCaption>
<table confidence="0.996936368421053">
SubTree Paths
Shortest Paths
Conventional Sent Iterative Sent Improvement
P R F P R F OP OR OF
φ
In-Degree 60.83 50.70 55.30 61.80 56.23 58.88 +0.97 +5.53 +3.58
Out-Degree 56.18 46.82 51.07 59.64 54.11 56.74 +3.46 +7.29 +5.67
Betweenness Centrality 59.40 49.51 54.01 61.66 56.08 58.74 +2.26 +6.57 +4.73
Sum Inverse Path Length 56.68 47.23 51.52 59.45 54.00 56.60 +2.77 +6.77 +5.08
HITS(hub) 55.49 46.25 50.45 59.51 54.06 56.65 +4.02 +7.81 +6.20
HITS(authority) 56.80 47.34 51.64 60.30 54.84 57.44 +3.50 +7.50 +5.80
PageRank 59.71 49.77 54.29 60.56 55.04 57.67 +0.85 +5.27 +3.38
In-Degree 58.13 32.75 41.89 63.79 42.11 50.73 +5.66 +9.36 +8.84
Out-Degree 54.64 30.78 39.38 61.79 40.66 49.05 +7.15 +9.88 +9.67
Betweenness Centrality 57.94 32.64 41.76 64.11 42.32 50.98 +6.17 +9.68 +9.22
Sum Inverse Path Length 55.65 31.35 40.11 62.39 41.02 49.50 +6.74 +9.67 +9.39
HITS(hub) 56.11 31.61 40.44 62.74 41.28 49.80 +6.63 +9.67 +9.36
HITS(authority) 55.74 31.40 40.17 62.74 41.28 49.80 +7.00 +9.88 +9.36
PageRank 57.58 32.44 41.50 63.82 42.16 50.78 +6.24 +9.72 +9.28
</table>
<tableCaption confidence="0.994852">
Table 2: Improvements of using the Iterative Approach at the Sentence Level
</tableCaption>
<figure confidence="0.7586865">
SubTree Paths
Shortest Paths
</figure>
<bodyText confidence="0.999224928571429">
senses anchored to the same lemma assisting each
other’s φ score (as discussed in Section 3.1), the
SENSE_SHIFTS filter that is provided by the Ba-
belNet API was also applied. This filter removes
any path Pa→b such that sa, sb ∈ R( i). Disam-
biguation was attempted at the document and sen-
tence level, making use of the eight well-known
graph centrality measures listed in section 4.2. For
this experiment no means of optimisation were ap-
plied. Therefore Personalised PageRank was not
used, and traditional PageRank took on a uniform
random surfing vector. Default values of 0.85 and
30 for damping factor and maximum iterations
were set respectively.
</bodyText>
<subsectionHeader confidence="0.769728">
4.3.2 Experiment 1: Observations
</subsectionHeader>
<bodyText confidence="0.999958181818182">
First and foremost, it is clear from Table 1 and 2
that the iterative approach outperforms the con-
ventional approach, regardless of the subgraph
used, level of disambiguation, or the graph central-
ity measure employed. Since no graph centrality
measure or subgraph were optimised, let this ex-
periment prove that the iterative approach has the
potential to improve any WSD system that imple-
ments it.
At the document level for both subgraphs the F-
Scores were very close to the Most Frequent Sense
(MFS) baseline for this task of 66.50. It is noto-
riously hard to beat and only one team (Gutiérrez
et al., 2013) managed to beat it for this task. For
all subtree subgraphs, we observe that In-Degree is
clearly the best choice of centrality measure, while
HITS (hub) enjoys the most improvement. We
also observe that applying the iterative approach
to Betweenness Centrality on shortest paths is a
great combination at both the document and sen-
tence level, most probably due to the measure be-
ing based on shortest paths. Furthermore it is
</bodyText>
<page confidence="0.998431">
45
</page>
<bodyText confidence="0.9995609375">
worth noting, the results at the sentence level for
all graph centrality measures on shortest path sub-
graphs are quite poor, but highly improved, this
is likely to our restriction of L = 2 causing the
subgraphs to be much sparser and broken up into
many components.
We also provide here an example from the data
set in which the incorrect disambiguation of the
lemma cup via the conventional approach was
corrected by the iterative approach. This example
is the seventh sentence in the eleventh document
(d011.s007). Each word’s degree of polysemy
is denoted in square brackets.
“Spanish [1]football players playing in the All-Star
[4]League and in powerful [12]clubs of the [2]Premier
League of [9]England are during the [5]year very ac-
tive in [4]league and local [8]cup [7]competitions and
there are high-level [25]shocks in the [10]European
Cups and [2]European Champions League.”
The potential graph constructed from this sen-
tence is illustrated in Figure 5 as a shortest paths
subgraph. The darker edges portray the subgraph
iteratively constructed up to a polysemy p ≤ 8
(in order to disambiguate cup), whereas the lighter
edges portray the greater subgraph constructed if
the conventional approach is employed. Note that
although the lemma cup has eight senses, only
three are shown due to the application of the previ-
ously mentioned SENSE_SHIFTS filter. The re-
maining five senses of cup were filtered out since
they were not able to link to a sense up to L = 2
hops away that is anchored to an alterative lemma.
</bodyText>
<listItem confidence="0.981926714285714">
• cup#1 - A small open container usually used for
drinking; usually has a handle.
• cup#7 - The hole (or metal container in the hole)
on a golf green.
• cup#8 - A large metal vessel with two handles that
is awarded as a trophy to the winner of a competi-
tion.
</listItem>
<bodyText confidence="0.9997204">
Given the context, the eighth sense of cup is the
correct sense, the type we know as a trophy. For
the conventional approach, if 0 is a centrality mea-
sure of Out-Degree then the eighth sense of cup is
easily chosen by having one extra outgoing edge
than the other two senses for cup. Yet if 0 is a cen-
trality measure of In-Degree or Betweenness Cen-
trality, all three senses of cup now have the same
score, zero. Therefore in our results the first sense
is chosen which is incorrect. On the other hand, if
</bodyText>
<figure confidence="0.572145">
handle#1
golf#1 [7]contest#1
</figure>
<figureCaption confidence="0.999741">
Figure 5: Conventional vs Iterative Subgraph
</figureCaption>
<bodyText confidence="0.999967461538462">
the subgraph was constructed iteratively with dis-
ambiguation results providing feedback to consec-
utive constructions, this could have been avoided.
The shortest paths cup#1→handle#1→golf_club#2
and cup#7→golf#1→golf_club#2 only exist because
the sense golf_club#2 (anchored to the more poly-
semous lemma club) is present, if it was not then
the SENSE_SHIFTS filter would have removed
these alternative senses. This demonstrates that if
the senses of more polysemous lemmas are intro-
duced into the subgraph too soon, they can inter-
fere rather than help with disambiguation.
Secondly with each disambiguation at lower
levels of polysemy, a more stable context is con-
structed to perform the disambiguation of much
more polysemous lemmas later. Therefore in Fig-
ure 5 an iteratively constructed subgraph with cup
already disambiguated, would mean the other two
senses of cup would no longer be present. This en-
sures that club#2 (the correct answer) would have
a much stronger chance of being selected than
golf_club#2, which would have only one incoming
edge from handle#1. Note the conventional ap-
proach would lend golf_club#2 one extra incoming
edge than club#2 has, which could be problematic
if 0 is a centrality measure of In-Degree.
</bodyText>
<figure confidence="0.994863631578948">
[8]cup#8
[8]cup#1
[12]golf_club#2
[12]baseball_club#1
[4]league#2
[7]competition#1
baseball_league#1
[8]cup#7
association#1
tournament#1
[4]league#1
match#2
[9]England#1
Australia#1
[5]year#1
sport#1
[12]club#2
monopoly#1
[7]competition#3
</figure>
<page confidence="0.780438">
46
</page>
<figure confidence="0.9990649375">
F-Score
F-Score
70
60
50
40
0 10 20 30 40
Disambiguation Time (sec)
(a) φ = Betweenness Centrality
70
60
50
40
0 10 20 30 40
Disambiguation Time (sec)
(b) φ = PageRank
</figure>
<figureCaption confidence="0.6302075">
Figure 6: For each of the 13 documents, performance (F-Score) is plotted against time to disambiguate,
for GL = Shortest Paths. The squares (PageRank) and circles (Betweenness Centrality) plot the conven-
tional approach. The arrows show the effect caused by applying the iterative approach, with the arrow
head marking its F-Score and time to disambiguate.
</figureCaption>
<subsectionHeader confidence="0.996102">
4.4 Experiment 2: Performance
4.4.1 Experiment 2: Setup
</subsectionHeader>
<bodyText confidence="0.999946076923077">
An obvious caveat of the iterative approach is that
it requires the construction of several subgraphs
as p increases, which of course will require extra
computation and time which is a penalty for the
improved precision and recall. We decided to in-
vestigate the extent to which this happens. We se-
lected Betweenness Centrality and PageRank from
Experiment 1, in which both use shortest path sub-
graphs at the document level. This is because a)
they acquired good results at the document level
and b) with only 13 documents there are less data
points on the plots making it easier to read as op-
posed to the hundreds of sentences.
</bodyText>
<subsectionHeader confidence="0.887582">
4.4.2 Experiment 2: Observations
</subsectionHeader>
<bodyText confidence="0.999123697674419">
Firstly from Figures 6(a) and (b) we see that
there is a substantial improvement in F-Score
for almost all documents, except for two for 0 =
Betweenness Centrality and one for 0 = PageR-
ank. With some exceptions, for most documents
the increased amount of time to disambiguate is
not unreasonable. For this experiment, applying
the iterative approach to Betweenness Centrality
resulted in a mean 231% increase in processing
time, from 3.54 to 11.73 seconds to acquire a
mean F-Score improvement of +8.85. Again for
PageRank, a mean increase of 343% in processing
time, from 1.95 to 8.64 seconds to acquire a
F-Score improvement of +7.16 was observed.
We wanted to investigate why in some cases, the
iterative approach can produce poorer results than
the conventional approach. We looked at aspects
of the subgraphs such as order, size, density, and
number of components. Eventually we came to
the conclusion that, just like in a Sudoku puzzle, if
there are not enough hints to start with, the possi-
bility of finishing the puzzle becomes slim.
Therefore we suspected that if there were not
enough monosemous lemmas, to construct the ini-
tial GL, then the effectiveness of the iterative ap-
proach could be negated. It turns out, as observed
in Figures 7(a) and (b) on the following page that
this does effect the outcome. On the horizontal
axis, document monosemy represents the percent-
age of lemmas in a document, not counting dupli-
cates, that are monosemous. The vertical axis on
the other hand represents the difference in F-Score
between the conventional and iterative approach.
Through a simple linear regression of the scatter
plot, we observe an increased effectiveness of the
iterative approach. This observation is important,
because a WSD system may decide on which ap-
proach to use based on a document’s monosemy.
With m representing document monosemy, and
OF representing the change in F-Score induced
by the iterative approach, the slopes observed in
Figures 7(a) and (b) are denoted by Equations (2)
and (3) respectively.
</bodyText>
<equation confidence="0.6616095">
OF = 0.53m − 0.11
OF = 0.60m − 3.07
</equation>
<page confidence="0.997467">
47
</page>
<figure confidence="0.9995438125">
ΔF-Score
ΔF-Score
20
10
0
5 10 15 20 25 30 35
Document Monosemy (%)
(a) φ = Betweenness Centrality
20
15
10
5
0
5 10 15 20 25 30 35
Document Monosemy (%)
(b) φ = PageRank
</figure>
<figureCaption confidence="0.939922">
Figure 7: Both PageRank (squares) and Betweenness Centrality (circles) are plotted. Each data plot
represents the change in F-Score when the iterative approach replaces the conventional approach with
respect to the monosemy of the document.
</figureCaption>
<subsectionHeader confidence="0.923138">
4.5 Experiment 3: A Little Optimisation
</subsectionHeader>
<bodyText confidence="0.98358975">
Briefly, we made an effort into optimising the iter-
ative approach with subtree subgraphs, and com-
pared these results with systems from SemEval
2013 Task 12 (Navigli et al., 2013) in Table 3.
</bodyText>
<table confidence="0.999658153846154">
Team System P R F
UMCC-DLSI Run-2+ 68.50 68.50 68.50
UMCC-DLSI Run-3+ 68.00 68.00 68.00
UMCC-DLSI Run-1+ 67.70 67.70 67.70
SUDOKU It-PPR[M]+ 67.41 67.30 67.36
MACHINE MFS 66.50 66.50 66.50
SUDOKU It-PPR[M] 67.20 65.49 66.33
SUDOKU It-PR[U] 64.07 62.44 63.24
SUDOKU It-PD 63.58 61.47 62.51
DAEBAK! PD+ 60.50 60.40 60.40
GETALP BN-1+ 58.30 58.30 58.30
SUDOKU PR[U] 60.09 54.06 56.91
GETALP BN-2+ 56.80 56.80 56.80
</table>
<tableCaption confidence="0.999969">
Table 3: Comparison to SemEval 2013 Task 12
</tableCaption>
<bodyText confidence="0.977835125">
Firstly, we were able to marginally improve our
original result as team DAEBAK! (Manion and
Sainudiin, 2013), by applying the iterative ap-
proach to our Peripheral Diversity centrality mea-
sure (It-PD). Next we tried Personalised PageRank
(It-PPR[M]) with a surfing vector biased towards
only Monosemous senses. We also included reg-
ular PageRank (It-/PR[U]) with a Uniform surfing
vector as a reference point. It-PPR[M] almost de-
feated the MFS baseline of 66.50, but lacked re-
call. To rectify this, the MFS baseline was used as
a back-off strategy (It-PPR[M]+)4, which then led
4Note that plus+ implies the use of a back-off strategy.
to us beating the MFS baseline. As for the other
teams, GETALP (Schwab et al., 2013) made use
of an Ant Colony algorithm, while UMCC-DLSI
(Gutiérrez et al., 2013) also made use of PPR,
except they based the surfing vector on SemCor
(Miller et al., 1993) sense frequencies, set L = 5
for shortest paths subgraphs, and disambiguated
using resources external to BabelNet. Since their
implementation of PPR beats ours, it would be
interesting to see how effective the iterative ap-
proach could be on their results.
</bodyText>
<sectionHeader confidence="0.998704" genericHeader="method">
5 Conclusion &amp; Future Work
</sectionHeader>
<bodyText confidence="0.999484636363636">
In this paper we have shown that the iterative ap-
proach can substantially improve the results of
regular subgraph-based WSD, even to the point
of defeating the MFS baseline without doing any-
thing complicated. This is regardless of the sub-
graph, graph centrality measure, or level of disam-
biguation. This research can still be extended fur-
ther, and we encourage other researchers to rethink
their own approaches to unsupervised knowledge-
based WSD, particularly in regards to the interac-
tion of subgraphs and centrality measures.
</bodyText>
<sectionHeader confidence="0.840236" genericHeader="conclusions">
Resources
</sectionHeader>
<bodyText confidence="0.9858485">
Codebase and resources are at first author’s home-
page: http://www.stevemanion.com.
</bodyText>
<sectionHeader confidence="0.998841" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.813565666666667">
This research was completed with the help of the
Korean Foundation Graduate Studies Fellowship:
http://en.kf.or.kr/
</bodyText>
<page confidence="0.998874">
48
</page>
<sectionHeader confidence="0.996248" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999748723214286">
Eneko Agirre and Aitor Soroa. 2008. Using the Mul-
tilingual Central Repository for Graph-Based Word
Sense Disambiguation. In Proceedings of LREC,
pages 1388–1392, Marrakech, Morocco. European
Language Resources Association.
Eneko Agirre and Aitor Soroa. 2009. Personalizing
PageRank for Word Sense Disambiguation. In Pro-
ceedings of the 12th Conference of the European
Chapter of the ACL, pages 33–41, Athens, Greece.
Association for Computational Linguistics.
Eneko Agirre, Oier Lopez De Lacalle, Christiane Fell-
baum, Maurizio Tesconi, Monica Monachini, Piek
Vossen, and Roxanne Segers. 2010. SemEval-2010
Task 17: All-words Word Sense Disambiguation on
a Specific Domain. In Proceedings of the 5th Inter-
national Workshop on Semantic Evaluation, pages
75–80, Uppsala, Sweden. Association for Computa-
tional Linguistics.
Sergey Brin and Lawrence Page. 1998. The Anatomy
of a Large-scale Hypertextual Web Search Engine.
Computer Networks and ISDN Systems, 30:107 –
117.
Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. MIT Press, Cambridge, MA.
Linton C. Freeman. 1979. Centrality in Social Net-
works Conceptual Clarification. Social Networks,
1(3):215–239.
William A Gale, Kenneth W Church, and David
Yarowsky. 1992. A Method for Disambiguating
Word Senses in a Large Corpus. Computers and the
Humanities, 26:415 – 439.
Yoan Gutiérrez, Antonio Fernández Orquín, Andy
González, Andrés Montoyo, Rafael Muñoz, Rainel
Estrada, Dennys D Piug, Jose I Abreu, and Roger
Pérez. 2013. UMCC_DLSI: Reinforcing a Rank-
ing Algorithm with Sense Frequencies and Multi-
dimensional Semantic Resources to solve Multilin-
gual Word Sense Disambiguation. In Proceedings of
the 7th International Workshop on Semantic Evalu-
ation (SemEval 2013), in conjunction with the Sec-
ond Joint Conference on Lexical and Computational
Semantics (*SEM 2013), pages 241–249, Atlanta,
Georgia. Association for Computational Linguistics.
T.H. Haveliwala. 2003. Topic-Sensitive Pagerank:
A Context-Sensitive Ranking Algorithm for Web
Search. IEEE Transactions on Knowledge and Data
Engineering, 15(4):784–796.
Adam Kilgarriff. 1998. SENSEVAL: An Exercise in
Evaluating Word Sense Disambiguation Programs.
In Conference Proceedings of LREC, pages 581–
585, Granada, Spain.
Jon M. Kleinberg. 1999. Authoritative Sources in
a Hyperlinked Environment. Journal of the ACM,
46(5):604–632.
Els Lefever and Veronique Hoste. 2010. SemEval-
2010 Task 3: Cross-lingual Word Sense Disam-
biguation. In Proceedings of the 5th International
Workshop on Semantic Evaluation, pages 82–87,
Boulder, Colorado. Association for Computational
Linguistics.
Els Lefever and Veronique Hoste. 2013. SemEval-
2013 Task 10: Cross-lingual Word Sense Disam-
biguation. In Proceedings of the 7th International
Workshop on Semantic Evaluation (SemEval 2013),
in conjunction with the Second Joint Conference
on Lexical and Computational Semantics (*SEM
2013), Atlanta, Georgia. Association for Computa-
tional Linguistics.
Steve L. Manion and Raazesh Sainudiin. 2013. DAE-
BAK!: Peripheral Diversity for Multilingual Word
Sense Disambiguation. In Proceedings of the 7th In-
ternational Workshop on Semantic Evaluation (Se-
mEval 2013), in conjunction with the Second Joint
Conference on Lexical and Computational Seman-
tics (*SEM 2013), pages 250–254, Atlanta, Georgia.
Association for Computational Linguistics.
Rada Mihalcea. 2005. Unsupervised Large-
Vocabulary Word Sense Disambiguation with
Graph-based Algorithms for Sequence Data Label-
ing. In Proceedings of the conference on Human
Language Technology and Empirical Methods in
Natural Language Processing, pages 411–418, Van-
couver, Canada. Association for Computational Lin-
guistics.
George A. Miller, Claudia Leacock, Randee Tengi, and
Ross T. Bunker. 1993. A Semantic Concordance. In
Proceedings of the Workshop on Human Language
Technology - HLT ’93, pages 303–308, Morristown,
NJ, USA. Association for Computational Linguis-
tics.
Roberto Navigli and Mirella Lapata. 2007. Graph
Connectivity Measures for Unsupervised Word
Sense Disambiguation. In Proceedings of the 20th
International Joint Conference on Artificial Intelli-
gence (IJCAI), pages 1683–1688.
Roberto Navigli and Mirella Lapata. 2010. An Exper-
imental Study of Graph Connectivity for Unsuper-
vised Word Sense Disambiguation. IEEE Transac-
tions on Pattern Analysis and Machine Intelligence,
32(4):678 – 692.
Roberto Navigli and Simone Paolo Ponzetto. 2012a.
BabelNet: The Automatic Construction, Evaluation
and Application of a Wide-Coverage Multilingual
Semantic Network. Artificial Intelligence, 193:217–
250.
Roberto Navigli and Simone Paolo Ponzetto. 2012b.
Joining Forces Pays Off: Multilingual Joint Word
Sense Disambiguation. In Proceedings of the 2012
Joint Conference on Empirical Methods in Natural
Language Processing and Computational Natural
Language Learning, pages 1399–1410, Jeju Island,
Korea. Association for Computational Linguistics.
</reference>
<page confidence="0.987969">
49
</page>
<reference confidence="0.99989268115942">
Roberto Navigli and Paola Velardi. 2005. Struc-
tural Semantic Interconnections: A Knowledge-
based Approach to Word Sense Disambiguation.
IEEE Transactions on Pattern Analysis and Machine
Intelligence, 27(7):1075–1086.
Roberto Navigli, Kenneth C Litkowski, and Orin Har-
graves. 2007. SemEval-2007 Task 07: Coarse-
Grained English All-Words Task. In Proceedings of
the 4th International Workshop on Semantic Evalu-
ations, pages 30–35, Prague, Czech Republic. Asso-
ciation for Computational Linguistics.
Roberto Navigli, David Jurgens, and Daniele Vannella.
2013. SemEval-2013 Task 12: Multilingual Word
Sense Disambiguation. In Proceedings of the 7th In-
ternational Workshop on Semantic Evaluation (Se-
mEval 2013), in conjunction with the Second Joint
Conference on Lexical and Computational Seman-
tics (*SEM 2013). Association for Computational
Linguistics.
Roberto Navigli. 2009. Word Sense Disambiguation:
A Survey. ACM Computing Surveys, 41(2):10:1 –
10:69.
Martha Palmer, Christiane Fellbaum, Scott Cotton,
Lauren Delfs, and Hoa Trang Dang. 2001. En-
glish Tasks: All-Words and Verb Lexical Sample. In
Proceedings of SENSEVAL-2 Second International
Workshop on Evaluating Word Sense Disambigua-
tion Systems, pages 21–24, Toulouse, France. Asso-
ciation for Computational Linguistics.
Ted Pedersen. 2007. Unsupervised Corpus-Based
Methods for WSD. In Eneko Agirre and Philip Ed-
monds, editors, Word Sense Disambiguation: Algo-
rithms and Applications, chapter 6, pages 133–166.
Springer, New York.
Simone Paolo Ponzetto and Roberto Navigli. 2010.
Knowledge-rich Word Sense Disambiguation Rival-
ing Supervised Systems. Proceedings of the 48th
Annual Meeting of the ACL, pages 1522–1531.
Didier Schwab, Andon Tchechmedjiev, Jérôme Gou-
lian, Mohammad Nasiruddin, Gilles Sérasset, and
Hervé Blanchon. 2013. GETALP: Propagation of
a Lesk Measure through an Ant Colony Algorithm.
In Proceedings of the 7th International Workshop on
Semantic Evaluation (SemEval 2013), in conjunc-
tion with the Second Joint Conference on Lexical
and Computational Semantics (*SEM 2013), pages
232–240, Atlanta, Georgia. Association for Compu-
tational Linguistics.
Ravi Sinha and Rada Mihalcea. 2007. Unsuper-
vised Graph-based Word Sense Disambiguation Us-
ing Measures of Word Semantic Similarity. In Pro-
ceedings of the International Conference on Seman-
tic Computing, pages 363 – 369. IEEE.
Benjamin Snyder and Martha Palmer. 2004. The En-
glish All-Words Task. In Proceedings of the Third
International Workshop on the Evaluation of Sys-
tems for the Semantic Analysis of Text, pages 41–43,
Barcelona, Spain. Association for Computational
Linguistics.
David Yarowsky. 1993. One Sense Per Collocation. In
Proceedings of the workshop on Human Language
Technology - HLT ’93, pages 266–271, Morristown,
NJ, USA. Association for Computational Linguis-
tics.
David Yarowsky. 1995. Unsupervised Word Sense
Disambiguation Rivaling Supervised Methods. In
Proceedings of the 33rd Annual Meeting of the ACL,
pages 189–196, Cambridge, MA. Association for
Computational Linguistics.
</reference>
<page confidence="0.997684">
50
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.735766">
<title confidence="0.9995275">An Iterative ‘Sudoku Style’ Approach to Word Sense Disambiguation</title>
<author confidence="0.999509">L Steve</author>
<affiliation confidence="0.999861">University of</affiliation>
<address confidence="0.969057">Christchurch, New</address>
<email confidence="0.982198">@pg.canterbury.ac.nz</email>
<abstract confidence="0.99069912">introduce an to subgraph-based Word Sense Disambiguation (WSD). Inspired by the Sudoku puzit significantly improves the disambiguation. We describe WSD treats the two steps of (1) subgraph construction and (2) disambiguation via graph centrality measures as ordered and atomic. Consequently, researchers tend to focus on improving either of these two steps individually, overlooking the fact that these steps can complement each other if they are allowed to interact in an iterative manner. We tested our iterative approach against the conventional approach for a range of well-known graph centrality measures and subgraph types, at the sentence and document level. The results demonstrated that an average performing WSD system which embraces the iterative approach, can easily compete with state-ofthe-art. This alone warrants further investigation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Aitor Soroa</author>
</authors>
<title>Using the Multilingual Central Repository for Graph-Based Word Sense Disambiguation.</title>
<date>2008</date>
<journal>European Language Resources Association.</journal>
<booktitle>In Proceedings of LREC,</booktitle>
<pages>1388--1392</pages>
<location>Marrakech,</location>
<contexts>
<context position="5789" citStr="Agirre and Soroa (2008)" startWordPosition="923" endWordPosition="926">ding either the: (a) Subtree paths of up to length L, via a DepthFirst Search (DFS) of G. In brief, for each sense sa ∈ SL, if a new sense sb ∈ SL, i.e. sb =6 sa, is encountered along a path Pa,b = {{sa, s}, ..., {s&apos;, sb}} with pathlength |Pa,b |≤ L, then add Pa,b to GL. [cf. Navigli and Velardi (2005), Navigli and Lapata (2007), or Navigli and Lapata (2010)] (b) Shortest paths, via a Breadth-First Search (BFS) of G. In brief, for each sense pair sa, sb ∈ SL, find the shortest path Pa,b = {{sa, s},..., {s&apos;, sb}}; if such a path Pa,b exists and (optionally) |Pa,b |≤ L, then add Pa,b to GL [cf. Agirre and Soroa (2008), Agirre and Soroa (2009), or Gutiérrez et al. (2013)] 1For a detailed explanation of the processes leading up to lemmatisation (and beyond), see Navigli (2009, p12) 2‘Local’ describes the local context, typically this is the 2 or 3 words either side of a word, see Yarowsky (1993) (c) Local edges up to a local distance D. In brief, for each sense pair sa, sb ∈ SL, if the distance in the text |b − a |between the corresponding words wa and wb satisfies |b − a |≤ D, then add edge {sa, sb} to GL (preferably with edgeweights). [cf. Mihalcea (2005) or Sinha and Mihalcea (2007)] (Note that this subgr</context>
</contexts>
<marker>Agirre, Soroa, 2008</marker>
<rawString>Eneko Agirre and Aitor Soroa. 2008. Using the Multilingual Central Repository for Graph-Based Word Sense Disambiguation. In Proceedings of LREC, pages 1388–1392, Marrakech, Morocco. European Language Resources Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Aitor Soroa</author>
</authors>
<title>Personalizing PageRank for Word Sense Disambiguation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the ACL,</booktitle>
<pages>33--41</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Athens, Greece.</location>
<contexts>
<context position="5814" citStr="Agirre and Soroa (2009)" startWordPosition="927" endWordPosition="930">ree paths of up to length L, via a DepthFirst Search (DFS) of G. In brief, for each sense sa ∈ SL, if a new sense sb ∈ SL, i.e. sb =6 sa, is encountered along a path Pa,b = {{sa, s}, ..., {s&apos;, sb}} with pathlength |Pa,b |≤ L, then add Pa,b to GL. [cf. Navigli and Velardi (2005), Navigli and Lapata (2007), or Navigli and Lapata (2010)] (b) Shortest paths, via a Breadth-First Search (BFS) of G. In brief, for each sense pair sa, sb ∈ SL, find the shortest path Pa,b = {{sa, s},..., {s&apos;, sb}}; if such a path Pa,b exists and (optionally) |Pa,b |≤ L, then add Pa,b to GL [cf. Agirre and Soroa (2008), Agirre and Soroa (2009), or Gutiérrez et al. (2013)] 1For a detailed explanation of the processes leading up to lemmatisation (and beyond), see Navigli (2009, p12) 2‘Local’ describes the local context, typically this is the 2 or 3 words either side of a word, see Yarowsky (1993) (c) Local edges up to a local distance D. In brief, for each sense pair sa, sb ∈ SL, if the distance in the text |b − a |between the corresponding words wa and wb satisfies |b − a |≤ D, then add edge {sa, sb} to GL (preferably with edgeweights). [cf. Mihalcea (2005) or Sinha and Mihalcea (2007)] (Note that this subgraph is a hybrid, because </context>
<context position="9870" citStr="Agirre and Soroa (2009)" startWordPosition="1751" endWordPosition="1754">he Key Difference In Approach It is important to note, the term iterative can already be found in WSD literature, therefore we take the opportunity here to make a distinction. Firstly, a graph based centrality measure 0 may be iterative, such as PageRank (Brin and Page, 1998) or Hyperlink-Induced Topic Search (HITS) (Kleinberg, 1999). In the experiments by Mihalcea (2005) in which PageRank was run over local edge subgraphs (as described in 2.1 (c)), it is easy to perceive the WSD process itself as iterative. Iteration can again be taken further, as observed with Personalised PageRank in which Agirre and Soroa (2009) apply the idea of biasing values in the random surfing vector, v, (see (Haveliwala, 2003)). For their run labelled “Ppr_w2w”, in order to avoid senses anchored to the same lemma assisting each other’s 0 score, the random surfing vector v is iteratively updated as Ei changes, to ensure context senses sa,j ∈ v such that a =6 i are the only senses that receive probability mass. update Figure 3: Atomically Iterative Approach In summary, iteration in the literature either describes 0 as being iterative or being iteratively adjusted, both of which are contained in the disambiguation step alone as s</context>
<context position="17696" citStr="Agirre and Soroa (2009)" startWordPosition="3176" endWordPosition="3179">need to be a complicated measure, this is demonstrated by the success of ranking senses by their number of incoming and outgoing edges. Even though it is very simple, it performs surprisingly well against others for both In-Degree (Navigli and Lapata, 2007) and Out-Degree (Navigli and Ponzetto, 2012a) Next we employ graph centrality measures that are primarily used to disambiguate the semantic web, such as PageRank (Brin and Page, 1998), HITS Kleinberg (1999), and apersonalised PageRank (Haveliwala, 2003); which have since been applied to WSD by Mihalcea (2005), Navigli and Lapata (2007), and Agirre and Soroa (2009) respectively. We also include Betweeness Centrality (Freeman, 1979) which is taken from the analysis of social networks. These methods are well known and applied across many disciplines, therefore we will leave it to the reader to follow up on the specifics of these graph centrality measures. However we do explicitly define our last measure, Sum Inverse Path Length (Navigli and Ponzetto, 2012a; Navigli and Ponzetto, 2012b) in Equation (1) which was designed with WSD in mind, thus is less well known. e|p 1-1 (1) This measure scores a sense by summing up the scores of all paths that connect to </context>
</contexts>
<marker>Agirre, Soroa, 2009</marker>
<rawString>Eneko Agirre and Aitor Soroa. 2009. Personalizing PageRank for Word Sense Disambiguation. In Proceedings of the 12th Conference of the European Chapter of the ACL, pages 33–41, Athens, Greece. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Oier Lopez De Lacalle</author>
<author>Christiane Fellbaum</author>
<author>Maurizio Tesconi</author>
<author>Monica Monachini</author>
<author>Piek Vossen</author>
<author>Roxanne Segers</author>
</authors>
<title>SemEval-2010 Task 17: All-words Word Sense Disambiguation on a Specific Domain.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<pages>75--80</pages>
<institution>Uppsala, Sweden. Association for Computational Linguistics.</institution>
<marker>Agirre, De Lacalle, Fellbaum, Tesconi, Monachini, Vossen, Segers, 2010</marker>
<rawString>Eneko Agirre, Oier Lopez De Lacalle, Christiane Fellbaum, Maurizio Tesconi, Monica Monachini, Piek Vossen, and Roxanne Segers. 2010. SemEval-2010 Task 17: All-words Word Sense Disambiguation on a Specific Domain. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 75–80, Uppsala, Sweden. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergey Brin</author>
<author>Lawrence Page</author>
</authors>
<title>The Anatomy of a Large-scale Hypertextual Web Search Engine.</title>
<date>1998</date>
<journal>Computer Networks and ISDN Systems,</journal>
<pages>30--107</pages>
<contexts>
<context position="3242" citStr="Brin and Page, 1998" startWordPosition="473" endWordPosition="476">luated in terms of granularity (Navigli et al., 2007), domain (Agirre et al., 2010), and cross/multi-linguality (Lefever and Hoste, 2010; Lefever and Hoste, 2013; Navigli et al., 2013). Results from these tasks have demonstrated unsupervised systems are now a competitive and robust alternative to supervised systems, especially given the ever changing task-orientated settings WSD is evaluated in. One such class of unsupervised knowledgebased WSD systems that we seek to improve in this paper constructs semantic subgraphs from LKBs, and then runs graph-based centrality measures such as PageRank (Brin and Page, 1998) over them to finally select the senses (as nodes) ranked as the most relevant. This class is known as subgraph-based WSD, characterised over the last decade by performing the two key steps of (1) subgraph construction and (2) disambiguation via graph centrality measures, in an ordered atomic sequence. We refer to this characteristic as the conventional approach to subgraph-based WSD. We propose an iterative approach to subgraphbased WSD that allows for interaction between the two major steps in an incremental manner 40 Proceedings of the Third Joint Conference on Lexical and Computational Sem</context>
<context position="9523" citStr="Brin and Page, 1998" startWordPosition="1695" endWordPosition="1698">terative, then for Ea, Eb ∈ L a previous disambiguation of Ea, would need to influence a consecutive disambiguation of Eb, through an iterative re-construction of GL between each disambiguation. This key difference illustrated by Figure 2, is the level of iterative WSD we aspire to. reconstruct (b) Interactively Iterative Approach Figure 2: The Key Difference In Approach It is important to note, the term iterative can already be found in WSD literature, therefore we take the opportunity here to make a distinction. Firstly, a graph based centrality measure 0 may be iterative, such as PageRank (Brin and Page, 1998) or Hyperlink-Induced Topic Search (HITS) (Kleinberg, 1999). In the experiments by Mihalcea (2005) in which PageRank was run over local edge subgraphs (as described in 2.1 (c)), it is easy to perceive the WSD process itself as iterative. Iteration can again be taken further, as observed with Personalised PageRank in which Agirre and Soroa (2009) apply the idea of biasing values in the random surfing vector, v, (see (Haveliwala, 2003)). For their run labelled “Ppr_w2w”, in order to avoid senses anchored to the same lemma assisting each other’s 0 score, the random surfing vector v is iteratively</context>
<context position="17513" citStr="Brin and Page, 1998" startWordPosition="3149" endWordPosition="3152">To demonstrate the effectiveness of our iterative approach, we selected a range of WSD graphbased centrality measures often experimented with in the literature. Firstly 0 does not need to be a complicated measure, this is demonstrated by the success of ranking senses by their number of incoming and outgoing edges. Even though it is very simple, it performs surprisingly well against others for both In-Degree (Navigli and Lapata, 2007) and Out-Degree (Navigli and Ponzetto, 2012a) Next we employ graph centrality measures that are primarily used to disambiguate the semantic web, such as PageRank (Brin and Page, 1998), HITS Kleinberg (1999), and apersonalised PageRank (Haveliwala, 2003); which have since been applied to WSD by Mihalcea (2005), Navigli and Lapata (2007), and Agirre and Soroa (2009) respectively. We also include Betweeness Centrality (Freeman, 1979) which is taken from the analysis of social networks. These methods are well known and applied across many disciplines, therefore we will leave it to the reader to follow up on the specifics of these graph centrality measures. However we do explicitly define our last measure, Sum Inverse Path Length (Navigli and Ponzetto, 2012a; Navigli and Ponzet</context>
</contexts>
<marker>Brin, Page, 1998</marker>
<rawString>Sergey Brin and Lawrence Page. 1998. The Anatomy of a Large-scale Hypertextual Web Search Engine. Computer Networks and ISDN Systems, 30:107 – 117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="16418" citStr="Fellbaum, 1998" startWordPosition="2971" endWordPosition="2972"> to understand whether an iterative approach to subgraph WSD can in fact achieve better performance than the conventional approach. The second set of experiments seeks to understand how the iterative approach works and the performance benefits and penalties of implementing the iterative approach. Finally the third experiment is an elementary attempt at optimising the iterative approach to defeat the MFS baseline. 4.1 LKB &amp; Dataset For an evaluation, we have chosen the multilingual LKB known as BabelNet (Navigli and Ponzetto, 2012a). It weaves together several other LKBs, most notably WordNet (Fellbaum, 1998) and Wikipedia. It also can be easily accessed with the BabelNet API, of which we have built our code base around. All experiments are conducted on the most recent SemEval WSD dataset, of which is the SemEval 2013 Task 12 Multilingual WSD (English) data set. 3This can happen if Bi does not map to any senses, or alternatively all the senses that are mapped to are filtered out of the subgraph before disambiguation (explained later). 4.2 Graph Centrality Measures Evaluated To demonstrate the effectiveness of our iterative approach, we selected a range of WSD graphbased centrality measures often e</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Linton C Freeman</author>
</authors>
<date>1979</date>
<journal>Centrality in Social Networks Conceptual Clarification. Social Networks,</journal>
<volume>1</volume>
<issue>3</issue>
<contexts>
<context position="17764" citStr="Freeman, 1979" startWordPosition="3187" endWordPosition="3188">ing senses by their number of incoming and outgoing edges. Even though it is very simple, it performs surprisingly well against others for both In-Degree (Navigli and Lapata, 2007) and Out-Degree (Navigli and Ponzetto, 2012a) Next we employ graph centrality measures that are primarily used to disambiguate the semantic web, such as PageRank (Brin and Page, 1998), HITS Kleinberg (1999), and apersonalised PageRank (Haveliwala, 2003); which have since been applied to WSD by Mihalcea (2005), Navigli and Lapata (2007), and Agirre and Soroa (2009) respectively. We also include Betweeness Centrality (Freeman, 1979) which is taken from the analysis of social networks. These methods are well known and applied across many disciplines, therefore we will leave it to the reader to follow up on the specifics of these graph centrality measures. However we do explicitly define our last measure, Sum Inverse Path Length (Navigli and Ponzetto, 2012a; Navigli and Ponzetto, 2012b) in Equation (1) which was designed with WSD in mind, thus is less well known. e|p 1-1 (1) This measure scores a sense by summing up the scores of all paths that connect to other senses in GL (i.e. senses that are not intermediate nodes, but</context>
</contexts>
<marker>Freeman, 1979</marker>
<rawString>Linton C. Freeman. 1979. Centrality in Social Networks Conceptual Clarification. Social Networks, 1(3):215–239.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
<author>David Yarowsky</author>
</authors>
<title>A Method for Disambiguating Word Senses in a Large Corpus. Computers and the Humanities,</title>
<date>1992</date>
<pages>26--415</pages>
<contexts>
<context position="2346" citStr="Gale et al. (1992)" startWordPosition="338" endWordPosition="341">.0/ Raazesh Sainudiin University of Canterbury Christchurch, New Zealand r.sainudiin @math.canterbury.ac.nz has been a healthy rivalry between the two, in which proponents of unsupervised WSD have long sought to vindicate its potential since two decades ago (Yarowsky, 1995) to even more recent times (Ponzetto and Navigli, 2010). As Pedersen (2007) rightly states, supervised systems are bound by their training data, and therefore are limited in portability and flexibility in the face of new domains, changing applications, or different languages. This knowledge acquisition bottleneck, coined by Gale et al. (1992), can be alleviated by unsupervised systems that exploit the portability and flexibility of Lexical Knowledge Bases (LKBs). As of 2007, SENSEVAL became SEMEVAL, offering a more diverse range of semantic tasks. Unsupervised knowledge-based WSD has since had its performance evaluated in terms of granularity (Navigli et al., 2007), domain (Agirre et al., 2010), and cross/multi-linguality (Lefever and Hoste, 2010; Lefever and Hoste, 2013; Navigli et al., 2013). Results from these tasks have demonstrated unsupervised systems are now a competitive and robust alternative to supervised systems, especi</context>
</contexts>
<marker>Gale, Church, Yarowsky, 1992</marker>
<rawString>William A Gale, Kenneth W Church, and David Yarowsky. 1992. A Method for Disambiguating Word Senses in a Large Corpus. Computers and the Humanities, 26:415 – 439.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Yoan Gutiérrez</author>
<author>Antonio Fernández Orquín</author>
<author>Andy González</author>
<author>Andrés Montoyo</author>
<author>Rafael Muñoz</author>
<author>Rainel Estrada</author>
<author>Dennys D Piug</author>
<author>Jose I Abreu</author>
<author>Roger Pérez</author>
</authors>
<title>UMCC_DLSI: Reinforcing a Ranking Algorithm with Sense Frequencies and Multidimensional Semantic Resources to solve Multilingual Word Sense Disambiguation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013), in conjunction with the Second Joint Conference on Lexical and Computational Semantics (*SEM</booktitle>
<pages>241--249</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta,</location>
<contexts>
<context position="5842" citStr="Gutiérrez et al. (2013)" startWordPosition="932" endWordPosition="935"> via a DepthFirst Search (DFS) of G. In brief, for each sense sa ∈ SL, if a new sense sb ∈ SL, i.e. sb =6 sa, is encountered along a path Pa,b = {{sa, s}, ..., {s&apos;, sb}} with pathlength |Pa,b |≤ L, then add Pa,b to GL. [cf. Navigli and Velardi (2005), Navigli and Lapata (2007), or Navigli and Lapata (2010)] (b) Shortest paths, via a Breadth-First Search (BFS) of G. In brief, for each sense pair sa, sb ∈ SL, find the shortest path Pa,b = {{sa, s},..., {s&apos;, sb}}; if such a path Pa,b exists and (optionally) |Pa,b |≤ L, then add Pa,b to GL [cf. Agirre and Soroa (2008), Agirre and Soroa (2009), or Gutiérrez et al. (2013)] 1For a detailed explanation of the processes leading up to lemmatisation (and beyond), see Navigli (2009, p12) 2‘Local’ describes the local context, typically this is the 2 or 3 words either side of a word, see Yarowsky (1993) (c) Local edges up to a local distance D. In brief, for each sense pair sa, sb ∈ SL, if the distance in the text |b − a |between the corresponding words wa and wb satisfies |b − a |≤ D, then add edge {sa, sb} to GL (preferably with edgeweights). [cf. Mihalcea (2005) or Sinha and Mihalcea (2007)] (Note that this subgraph is a hybrid, because only its vertices belong to </context>
<context position="22593" citStr="Gutiérrez et al., 2013" startWordPosition="3988" endWordPosition="3991"> 1: Observations First and foremost, it is clear from Table 1 and 2 that the iterative approach outperforms the conventional approach, regardless of the subgraph used, level of disambiguation, or the graph centrality measure employed. Since no graph centrality measure or subgraph were optimised, let this experiment prove that the iterative approach has the potential to improve any WSD system that implements it. At the document level for both subgraphs the FScores were very close to the Most Frequent Sense (MFS) baseline for this task of 66.50. It is notoriously hard to beat and only one team (Gutiérrez et al., 2013) managed to beat it for this task. For all subtree subgraphs, we observe that In-Degree is clearly the best choice of centrality measure, while HITS (hub) enjoys the most improvement. We also observe that applying the iterative approach to Betweenness Centrality on shortest paths is a great combination at both the document and sentence level, most probably due to the measure being based on shortest paths. Furthermore it is 45 worth noting, the results at the sentence level for all graph centrality measures on shortest path subgraphs are quite poor, but highly improved, this is likely to our re</context>
<context position="32060" citStr="Gutiérrez et al., 2013" startWordPosition="5553" endWordPosition="5556"> centrality measure (It-PD). Next we tried Personalised PageRank (It-PPR[M]) with a surfing vector biased towards only Monosemous senses. We also included regular PageRank (It-/PR[U]) with a Uniform surfing vector as a reference point. It-PPR[M] almost defeated the MFS baseline of 66.50, but lacked recall. To rectify this, the MFS baseline was used as a back-off strategy (It-PPR[M]+)4, which then led 4Note that plus+ implies the use of a back-off strategy. to us beating the MFS baseline. As for the other teams, GETALP (Schwab et al., 2013) made use of an Ant Colony algorithm, while UMCC-DLSI (Gutiérrez et al., 2013) also made use of PPR, except they based the surfing vector on SemCor (Miller et al., 1993) sense frequencies, set L = 5 for shortest paths subgraphs, and disambiguated using resources external to BabelNet. Since their implementation of PPR beats ours, it would be interesting to see how effective the iterative approach could be on their results. 5 Conclusion &amp; Future Work In this paper we have shown that the iterative approach can substantially improve the results of regular subgraph-based WSD, even to the point of defeating the MFS baseline without doing anything complicated. This is regardle</context>
</contexts>
<marker>Gutiérrez, Orquín, González, Montoyo, Muñoz, Estrada, Piug, Abreu, Pérez, 2013</marker>
<rawString>Yoan Gutiérrez, Antonio Fernández Orquín, Andy González, Andrés Montoyo, Rafael Muñoz, Rainel Estrada, Dennys D Piug, Jose I Abreu, and Roger Pérez. 2013. UMCC_DLSI: Reinforcing a Ranking Algorithm with Sense Frequencies and Multidimensional Semantic Resources to solve Multilingual Word Sense Disambiguation. In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013), in conjunction with the Second Joint Conference on Lexical and Computational Semantics (*SEM 2013), pages 241–249, Atlanta, Georgia. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T H Haveliwala</author>
</authors>
<title>Topic-Sensitive Pagerank: A Context-Sensitive Ranking Algorithm for Web Search.</title>
<date>2003</date>
<journal>IEEE Transactions on Knowledge and Data Engineering,</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context position="9960" citStr="Haveliwala, 2003" startWordPosition="1768" endWordPosition="1769">n WSD literature, therefore we take the opportunity here to make a distinction. Firstly, a graph based centrality measure 0 may be iterative, such as PageRank (Brin and Page, 1998) or Hyperlink-Induced Topic Search (HITS) (Kleinberg, 1999). In the experiments by Mihalcea (2005) in which PageRank was run over local edge subgraphs (as described in 2.1 (c)), it is easy to perceive the WSD process itself as iterative. Iteration can again be taken further, as observed with Personalised PageRank in which Agirre and Soroa (2009) apply the idea of biasing values in the random surfing vector, v, (see (Haveliwala, 2003)). For their run labelled “Ppr_w2w”, in order to avoid senses anchored to the same lemma assisting each other’s 0 score, the random surfing vector v is iteratively updated as Ei changes, to ensure context senses sa,j ∈ v such that a =6 i are the only senses that receive probability mass. update Figure 3: Atomically Iterative Approach In summary, iteration in the literature either describes 0 as being iterative or being iteratively adjusted, both of which are contained in the disambiguation step alone as shown in Figure 3. This is iteration at the atomic level and should not be conflated with t</context>
<context position="17583" citStr="Haveliwala, 2003" startWordPosition="3159" endWordPosition="3160"> range of WSD graphbased centrality measures often experimented with in the literature. Firstly 0 does not need to be a complicated measure, this is demonstrated by the success of ranking senses by their number of incoming and outgoing edges. Even though it is very simple, it performs surprisingly well against others for both In-Degree (Navigli and Lapata, 2007) and Out-Degree (Navigli and Ponzetto, 2012a) Next we employ graph centrality measures that are primarily used to disambiguate the semantic web, such as PageRank (Brin and Page, 1998), HITS Kleinberg (1999), and apersonalised PageRank (Haveliwala, 2003); which have since been applied to WSD by Mihalcea (2005), Navigli and Lapata (2007), and Agirre and Soroa (2009) respectively. We also include Betweeness Centrality (Freeman, 1979) which is taken from the analysis of social networks. These methods are well known and applied across many disciplines, therefore we will leave it to the reader to follow up on the specifics of these graph centrality measures. However we do explicitly define our last measure, Sum Inverse Path Length (Navigli and Ponzetto, 2012a; Navigli and Ponzetto, 2012b) in Equation (1) which was designed with WSD in mind, thus i</context>
</contexts>
<marker>Haveliwala, 2003</marker>
<rawString>T.H. Haveliwala. 2003. Topic-Sensitive Pagerank: A Context-Sensitive Ranking Algorithm for Web Search. IEEE Transactions on Knowledge and Data Engineering, 15(4):784–796.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
</authors>
<title>SENSEVAL: An Exercise in Evaluating Word Sense Disambiguation Programs.</title>
<date>1998</date>
<booktitle>In Conference Proceedings of LREC,</booktitle>
<pages>581--585</pages>
<location>Granada,</location>
<contexts>
<context position="1269" citStr="Kilgarriff (1998)" startWordPosition="185" endWordPosition="186">king the fact that these steps can complement each other if they are allowed to interact in an iterative manner. We tested our iterative approach against the conventional approach for a range of well-known graph centrality measures and subgraph types, at the sentence and document level. The results demonstrated that an average performing WSD system which embraces the iterative approach, can easily compete with state-ofthe-art. This alone warrants further investigation. 1 Introduction Explicit WSD is a two-step process of analysing a word’s contextual use then deducing its intended sense. When Kilgarriff (1998) established SENSEVAL, the collaborative framework and forum to evaluate WSD, unsupervised systems performed poorly in comparison to their supervised counterparts (Palmer et al., 2001; Snyder and Palmer, 2004). A review of the literature shows there This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/ by/4.0/ Raazesh Sainudiin University of Canterbury Christchurch, New Zealand r.sainudiin @math.canterbury.ac.nz has been a healthy rivalry betwee</context>
</contexts>
<marker>Kilgarriff, 1998</marker>
<rawString>Adam Kilgarriff. 1998. SENSEVAL: An Exercise in Evaluating Word Sense Disambiguation Programs. In Conference Proceedings of LREC, pages 581– 585, Granada, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon M Kleinberg</author>
</authors>
<title>Authoritative Sources in a Hyperlinked Environment.</title>
<date>1999</date>
<journal>Journal of the ACM,</journal>
<volume>46</volume>
<issue>5</issue>
<contexts>
<context position="9582" citStr="Kleinberg, 1999" startWordPosition="1704" endWordPosition="1705">would need to influence a consecutive disambiguation of Eb, through an iterative re-construction of GL between each disambiguation. This key difference illustrated by Figure 2, is the level of iterative WSD we aspire to. reconstruct (b) Interactively Iterative Approach Figure 2: The Key Difference In Approach It is important to note, the term iterative can already be found in WSD literature, therefore we take the opportunity here to make a distinction. Firstly, a graph based centrality measure 0 may be iterative, such as PageRank (Brin and Page, 1998) or Hyperlink-Induced Topic Search (HITS) (Kleinberg, 1999). In the experiments by Mihalcea (2005) in which PageRank was run over local edge subgraphs (as described in 2.1 (c)), it is easy to perceive the WSD process itself as iterative. Iteration can again be taken further, as observed with Personalised PageRank in which Agirre and Soroa (2009) apply the idea of biasing values in the random surfing vector, v, (see (Haveliwala, 2003)). For their run labelled “Ppr_w2w”, in order to avoid senses anchored to the same lemma assisting each other’s 0 score, the random surfing vector v is iteratively updated as Ei changes, to ensure context senses sa,j ∈ v s</context>
<context position="17536" citStr="Kleinberg (1999)" startWordPosition="3154" endWordPosition="3155">eness of our iterative approach, we selected a range of WSD graphbased centrality measures often experimented with in the literature. Firstly 0 does not need to be a complicated measure, this is demonstrated by the success of ranking senses by their number of incoming and outgoing edges. Even though it is very simple, it performs surprisingly well against others for both In-Degree (Navigli and Lapata, 2007) and Out-Degree (Navigli and Ponzetto, 2012a) Next we employ graph centrality measures that are primarily used to disambiguate the semantic web, such as PageRank (Brin and Page, 1998), HITS Kleinberg (1999), and apersonalised PageRank (Haveliwala, 2003); which have since been applied to WSD by Mihalcea (2005), Navigli and Lapata (2007), and Agirre and Soroa (2009) respectively. We also include Betweeness Centrality (Freeman, 1979) which is taken from the analysis of social networks. These methods are well known and applied across many disciplines, therefore we will leave it to the reader to follow up on the specifics of these graph centrality measures. However we do explicitly define our last measure, Sum Inverse Path Length (Navigli and Ponzetto, 2012a; Navigli and Ponzetto, 2012b) in Equation </context>
</contexts>
<marker>Kleinberg, 1999</marker>
<rawString>Jon M. Kleinberg. 1999. Authoritative Sources in a Hyperlinked Environment. Journal of the ACM, 46(5):604–632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Els Lefever</author>
<author>Veronique Hoste</author>
</authors>
<title>SemEval2010 Task 3: Cross-lingual Word Sense Disambiguation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<pages>82--87</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, Colorado.</location>
<contexts>
<context position="2758" citStr="Lefever and Hoste, 2010" startWordPosition="399" endWordPosition="402">ining data, and therefore are limited in portability and flexibility in the face of new domains, changing applications, or different languages. This knowledge acquisition bottleneck, coined by Gale et al. (1992), can be alleviated by unsupervised systems that exploit the portability and flexibility of Lexical Knowledge Bases (LKBs). As of 2007, SENSEVAL became SEMEVAL, offering a more diverse range of semantic tasks. Unsupervised knowledge-based WSD has since had its performance evaluated in terms of granularity (Navigli et al., 2007), domain (Agirre et al., 2010), and cross/multi-linguality (Lefever and Hoste, 2010; Lefever and Hoste, 2013; Navigli et al., 2013). Results from these tasks have demonstrated unsupervised systems are now a competitive and robust alternative to supervised systems, especially given the ever changing task-orientated settings WSD is evaluated in. One such class of unsupervised knowledgebased WSD systems that we seek to improve in this paper constructs semantic subgraphs from LKBs, and then runs graph-based centrality measures such as PageRank (Brin and Page, 1998) over them to finally select the senses (as nodes) ranked as the most relevant. This class is known as subgraph-base</context>
</contexts>
<marker>Lefever, Hoste, 2010</marker>
<rawString>Els Lefever and Veronique Hoste. 2010. SemEval2010 Task 3: Cross-lingual Word Sense Disambiguation. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 82–87, Boulder, Colorado. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Els Lefever</author>
<author>Veronique Hoste</author>
</authors>
<title>SemEval2013 Task 10: Cross-lingual Word Sense Disambiguation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013), in conjunction with the Second Joint Conference on Lexical and Computational Semantics (*SEM 2013),</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta,</location>
<contexts>
<context position="2783" citStr="Lefever and Hoste, 2013" startWordPosition="403" endWordPosition="406"> are limited in portability and flexibility in the face of new domains, changing applications, or different languages. This knowledge acquisition bottleneck, coined by Gale et al. (1992), can be alleviated by unsupervised systems that exploit the portability and flexibility of Lexical Knowledge Bases (LKBs). As of 2007, SENSEVAL became SEMEVAL, offering a more diverse range of semantic tasks. Unsupervised knowledge-based WSD has since had its performance evaluated in terms of granularity (Navigli et al., 2007), domain (Agirre et al., 2010), and cross/multi-linguality (Lefever and Hoste, 2010; Lefever and Hoste, 2013; Navigli et al., 2013). Results from these tasks have demonstrated unsupervised systems are now a competitive and robust alternative to supervised systems, especially given the ever changing task-orientated settings WSD is evaluated in. One such class of unsupervised knowledgebased WSD systems that we seek to improve in this paper constructs semantic subgraphs from LKBs, and then runs graph-based centrality measures such as PageRank (Brin and Page, 1998) over them to finally select the senses (as nodes) ranked as the most relevant. This class is known as subgraph-based WSD, characterised over</context>
</contexts>
<marker>Lefever, Hoste, 2013</marker>
<rawString>Els Lefever and Veronique Hoste. 2013. SemEval2013 Task 10: Cross-lingual Word Sense Disambiguation. In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013), in conjunction with the Second Joint Conference on Lexical and Computational Semantics (*SEM 2013), Atlanta, Georgia. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve L Manion</author>
<author>Raazesh Sainudiin</author>
</authors>
<title>DAEBAK!: Peripheral Diversity for Multilingual Word Sense Disambiguation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013), in conjunction with the Second Joint Conference on Lexical and Computational Semantics (*SEM</booktitle>
<pages>250--254</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta,</location>
<contexts>
<context position="31373" citStr="Manion and Sainudiin, 2013" startWordPosition="5440" endWordPosition="5443">s from SemEval 2013 Task 12 (Navigli et al., 2013) in Table 3. Team System P R F UMCC-DLSI Run-2+ 68.50 68.50 68.50 UMCC-DLSI Run-3+ 68.00 68.00 68.00 UMCC-DLSI Run-1+ 67.70 67.70 67.70 SUDOKU It-PPR[M]+ 67.41 67.30 67.36 MACHINE MFS 66.50 66.50 66.50 SUDOKU It-PPR[M] 67.20 65.49 66.33 SUDOKU It-PR[U] 64.07 62.44 63.24 SUDOKU It-PD 63.58 61.47 62.51 DAEBAK! PD+ 60.50 60.40 60.40 GETALP BN-1+ 58.30 58.30 58.30 SUDOKU PR[U] 60.09 54.06 56.91 GETALP BN-2+ 56.80 56.80 56.80 Table 3: Comparison to SemEval 2013 Task 12 Firstly, we were able to marginally improve our original result as team DAEBAK! (Manion and Sainudiin, 2013), by applying the iterative approach to our Peripheral Diversity centrality measure (It-PD). Next we tried Personalised PageRank (It-PPR[M]) with a surfing vector biased towards only Monosemous senses. We also included regular PageRank (It-/PR[U]) with a Uniform surfing vector as a reference point. It-PPR[M] almost defeated the MFS baseline of 66.50, but lacked recall. To rectify this, the MFS baseline was used as a back-off strategy (It-PPR[M]+)4, which then led 4Note that plus+ implies the use of a back-off strategy. to us beating the MFS baseline. As for the other teams, GETALP (Schwab et a</context>
</contexts>
<marker>Manion, Sainudiin, 2013</marker>
<rawString>Steve L. Manion and Raazesh Sainudiin. 2013. DAEBAK!: Peripheral Diversity for Multilingual Word Sense Disambiguation. In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013), in conjunction with the Second Joint Conference on Lexical and Computational Semantics (*SEM 2013), pages 250–254, Atlanta, Georgia. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
</authors>
<title>Unsupervised LargeVocabulary Word Sense Disambiguation with Graph-based Algorithms for Sequence Data Labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>411--418</pages>
<publisher>Association for</publisher>
<institution>Computational Linguistics.</institution>
<location>Vancouver, Canada.</location>
<contexts>
<context position="6337" citStr="Mihalcea (2005)" startWordPosition="1027" endWordPosition="1028">nally) |Pa,b |≤ L, then add Pa,b to GL [cf. Agirre and Soroa (2008), Agirre and Soroa (2009), or Gutiérrez et al. (2013)] 1For a detailed explanation of the processes leading up to lemmatisation (and beyond), see Navigli (2009, p12) 2‘Local’ describes the local context, typically this is the 2 or 3 words either side of a word, see Yarowsky (1993) (c) Local edges up to a local distance D. In brief, for each sense pair sa, sb ∈ SL, if the distance in the text |b − a |between the corresponding words wa and wb satisfies |b − a |≤ D, then add edge {sa, sb} to GL (preferably with edgeweights). [cf. Mihalcea (2005) or Sinha and Mihalcea (2007)] (Note that this subgraph is a hybrid, because only its vertices belong to G) In practice, subgraph edges may be directed, weighted, collapsed, or filtered. However to keep the distinctions between subgraph types simple, we do not include this in our formalisation. 2.2 Step 2: Disambiguation To disambiguate each lemma `i ∈ L, its corresponding senses, R(`i) = {si,1, si,2, ..., si,k}, are scored by a graph-based centrality measure φ, over subgraph GL, to estimate the most appropriate sense, ˆsi,* = arg maxsjjER(`j) φ(si,j). The estimated sense ˆsi,* is then assigne</context>
<context position="9621" citStr="Mihalcea (2005)" startWordPosition="1710" endWordPosition="1712">sambiguation of Eb, through an iterative re-construction of GL between each disambiguation. This key difference illustrated by Figure 2, is the level of iterative WSD we aspire to. reconstruct (b) Interactively Iterative Approach Figure 2: The Key Difference In Approach It is important to note, the term iterative can already be found in WSD literature, therefore we take the opportunity here to make a distinction. Firstly, a graph based centrality measure 0 may be iterative, such as PageRank (Brin and Page, 1998) or Hyperlink-Induced Topic Search (HITS) (Kleinberg, 1999). In the experiments by Mihalcea (2005) in which PageRank was run over local edge subgraphs (as described in 2.1 (c)), it is easy to perceive the WSD process itself as iterative. Iteration can again be taken further, as observed with Personalised PageRank in which Agirre and Soroa (2009) apply the idea of biasing values in the random surfing vector, v, (see (Haveliwala, 2003)). For their run labelled “Ppr_w2w”, in order to avoid senses anchored to the same lemma assisting each other’s 0 score, the random surfing vector v is iteratively updated as Ei changes, to ensure context senses sa,j ∈ v such that a =6 i are the only senses tha</context>
<context position="17640" citStr="Mihalcea (2005)" startWordPosition="3169" endWordPosition="3170">nted with in the literature. Firstly 0 does not need to be a complicated measure, this is demonstrated by the success of ranking senses by their number of incoming and outgoing edges. Even though it is very simple, it performs surprisingly well against others for both In-Degree (Navigli and Lapata, 2007) and Out-Degree (Navigli and Ponzetto, 2012a) Next we employ graph centrality measures that are primarily used to disambiguate the semantic web, such as PageRank (Brin and Page, 1998), HITS Kleinberg (1999), and apersonalised PageRank (Haveliwala, 2003); which have since been applied to WSD by Mihalcea (2005), Navigli and Lapata (2007), and Agirre and Soroa (2009) respectively. We also include Betweeness Centrality (Freeman, 1979) which is taken from the analysis of social networks. These methods are well known and applied across many disciplines, therefore we will leave it to the reader to follow up on the specifics of these graph centrality measures. However we do explicitly define our last measure, Sum Inverse Path Length (Navigli and Ponzetto, 2012a; Navigli and Ponzetto, 2012b) in Equation (1) which was designed with WSD in mind, thus is less well known. e|p 1-1 (1) This measure scores a sens</context>
</contexts>
<marker>Mihalcea, 2005</marker>
<rawString>Rada Mihalcea. 2005. Unsupervised LargeVocabulary Word Sense Disambiguation with Graph-based Algorithms for Sequence Data Labeling. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 411–418, Vancouver, Canada. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Claudia Leacock</author>
<author>Randee Tengi</author>
<author>Ross T Bunker</author>
</authors>
<title>A Semantic Concordance.</title>
<date>1993</date>
<booktitle>In Proceedings of the Workshop on Human Language Technology - HLT ’93,</booktitle>
<pages>303--308</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="32151" citStr="Miller et al., 1993" startWordPosition="5570" endWordPosition="5573">ctor biased towards only Monosemous senses. We also included regular PageRank (It-/PR[U]) with a Uniform surfing vector as a reference point. It-PPR[M] almost defeated the MFS baseline of 66.50, but lacked recall. To rectify this, the MFS baseline was used as a back-off strategy (It-PPR[M]+)4, which then led 4Note that plus+ implies the use of a back-off strategy. to us beating the MFS baseline. As for the other teams, GETALP (Schwab et al., 2013) made use of an Ant Colony algorithm, while UMCC-DLSI (Gutiérrez et al., 2013) also made use of PPR, except they based the surfing vector on SemCor (Miller et al., 1993) sense frequencies, set L = 5 for shortest paths subgraphs, and disambiguated using resources external to BabelNet. Since their implementation of PPR beats ours, it would be interesting to see how effective the iterative approach could be on their results. 5 Conclusion &amp; Future Work In this paper we have shown that the iterative approach can substantially improve the results of regular subgraph-based WSD, even to the point of defeating the MFS baseline without doing anything complicated. This is regardless of the subgraph, graph centrality measure, or level of disambiguation. This research can</context>
</contexts>
<marker>Miller, Leacock, Tengi, Bunker, 1993</marker>
<rawString>George A. Miller, Claudia Leacock, Randee Tengi, and Ross T. Bunker. 1993. A Semantic Concordance. In Proceedings of the Workshop on Human Language Technology - HLT ’93, pages 303–308, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Mirella Lapata</author>
</authors>
<title>Graph Connectivity Measures for Unsupervised Word Sense Disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI),</booktitle>
<pages>1683--1688</pages>
<contexts>
<context position="5496" citStr="Navigli and Lapata (2007)" startWordPosition="866" endWordPosition="869">ed WSD, the key publications that have advanced the field broadly construct subgraph, GL, as either a union of subtree paths, shortest paths, or local edges2. First we initialise GL, by setting SL := Uni=1 R(`i) and EL := ∅. Next we add edges to EL, depending on the desired subgraph type, by adding either the: (a) Subtree paths of up to length L, via a DepthFirst Search (DFS) of G. In brief, for each sense sa ∈ SL, if a new sense sb ∈ SL, i.e. sb =6 sa, is encountered along a path Pa,b = {{sa, s}, ..., {s&apos;, sb}} with pathlength |Pa,b |≤ L, then add Pa,b to GL. [cf. Navigli and Velardi (2005), Navigli and Lapata (2007), or Navigli and Lapata (2010)] (b) Shortest paths, via a Breadth-First Search (BFS) of G. In brief, for each sense pair sa, sb ∈ SL, find the shortest path Pa,b = {{sa, s},..., {s&apos;, sb}}; if such a path Pa,b exists and (optionally) |Pa,b |≤ L, then add Pa,b to GL [cf. Agirre and Soroa (2008), Agirre and Soroa (2009), or Gutiérrez et al. (2013)] 1For a detailed explanation of the processes leading up to lemmatisation (and beyond), see Navigli (2009, p12) 2‘Local’ describes the local context, typically this is the 2 or 3 words either side of a word, see Yarowsky (1993) (c) Local edges up to a l</context>
<context position="17330" citStr="Navigli and Lapata, 2007" startWordPosition="3120" endWordPosition="3123">not map to any senses, or alternatively all the senses that are mapped to are filtered out of the subgraph before disambiguation (explained later). 4.2 Graph Centrality Measures Evaluated To demonstrate the effectiveness of our iterative approach, we selected a range of WSD graphbased centrality measures often experimented with in the literature. Firstly 0 does not need to be a complicated measure, this is demonstrated by the success of ranking senses by their number of incoming and outgoing edges. Even though it is very simple, it performs surprisingly well against others for both In-Degree (Navigli and Lapata, 2007) and Out-Degree (Navigli and Ponzetto, 2012a) Next we employ graph centrality measures that are primarily used to disambiguate the semantic web, such as PageRank (Brin and Page, 1998), HITS Kleinberg (1999), and apersonalised PageRank (Haveliwala, 2003); which have since been applied to WSD by Mihalcea (2005), Navigli and Lapata (2007), and Agirre and Soroa (2009) respectively. We also include Betweeness Centrality (Freeman, 1979) which is taken from the analysis of social networks. These methods are well known and applied across many disciplines, therefore we will leave it to the reader to fo</context>
</contexts>
<marker>Navigli, Lapata, 2007</marker>
<rawString>Roberto Navigli and Mirella Lapata. 2007. Graph Connectivity Measures for Unsupervised Word Sense Disambiguation. In Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI), pages 1683–1688.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Mirella Lapata</author>
</authors>
<title>An Experimental Study of Graph Connectivity for Unsupervised Word Sense Disambiguation.</title>
<date>2010</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>32</volume>
<issue>4</issue>
<pages>692</pages>
<contexts>
<context position="5526" citStr="Navigli and Lapata (2010)" startWordPosition="871" endWordPosition="874">hat have advanced the field broadly construct subgraph, GL, as either a union of subtree paths, shortest paths, or local edges2. First we initialise GL, by setting SL := Uni=1 R(`i) and EL := ∅. Next we add edges to EL, depending on the desired subgraph type, by adding either the: (a) Subtree paths of up to length L, via a DepthFirst Search (DFS) of G. In brief, for each sense sa ∈ SL, if a new sense sb ∈ SL, i.e. sb =6 sa, is encountered along a path Pa,b = {{sa, s}, ..., {s&apos;, sb}} with pathlength |Pa,b |≤ L, then add Pa,b to GL. [cf. Navigli and Velardi (2005), Navigli and Lapata (2007), or Navigli and Lapata (2010)] (b) Shortest paths, via a Breadth-First Search (BFS) of G. In brief, for each sense pair sa, sb ∈ SL, find the shortest path Pa,b = {{sa, s},..., {s&apos;, sb}}; if such a path Pa,b exists and (optionally) |Pa,b |≤ L, then add Pa,b to GL [cf. Agirre and Soroa (2008), Agirre and Soroa (2009), or Gutiérrez et al. (2013)] 1For a detailed explanation of the processes leading up to lemmatisation (and beyond), see Navigli (2009, p12) 2‘Local’ describes the local context, typically this is the 2 or 3 words either side of a word, see Yarowsky (1993) (c) Local edges up to a local distance D. In brief, for</context>
</contexts>
<marker>Navigli, Lapata, 2010</marker>
<rawString>Roberto Navigli and Mirella Lapata. 2010. An Experimental Study of Graph Connectivity for Unsupervised Word Sense Disambiguation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(4):678 – 692.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>BabelNet: The Automatic Construction, Evaluation and Application of a Wide-Coverage Multilingual Semantic Network.</title>
<date>2012</date>
<journal>Artificial Intelligence,</journal>
<volume>193</volume>
<pages>250</pages>
<contexts>
<context position="16338" citStr="Navigli and Ponzetto, 2012" startWordPosition="2958" endWordPosition="2961">s we set out to understand a number of aspects. The first evaluation is a proof of concept, to understand whether an iterative approach to subgraph WSD can in fact achieve better performance than the conventional approach. The second set of experiments seeks to understand how the iterative approach works and the performance benefits and penalties of implementing the iterative approach. Finally the third experiment is an elementary attempt at optimising the iterative approach to defeat the MFS baseline. 4.1 LKB &amp; Dataset For an evaluation, we have chosen the multilingual LKB known as BabelNet (Navigli and Ponzetto, 2012a). It weaves together several other LKBs, most notably WordNet (Fellbaum, 1998) and Wikipedia. It also can be easily accessed with the BabelNet API, of which we have built our code base around. All experiments are conducted on the most recent SemEval WSD dataset, of which is the SemEval 2013 Task 12 Multilingual WSD (English) data set. 3This can happen if Bi does not map to any senses, or alternatively all the senses that are mapped to are filtered out of the subgraph before disambiguation (explained later). 4.2 Graph Centrality Measures Evaluated To demonstrate the effectiveness of our itera</context>
<context position="18092" citStr="Navigli and Ponzetto, 2012" startWordPosition="3241" endWordPosition="3244">tic web, such as PageRank (Brin and Page, 1998), HITS Kleinberg (1999), and apersonalised PageRank (Haveliwala, 2003); which have since been applied to WSD by Mihalcea (2005), Navigli and Lapata (2007), and Agirre and Soroa (2009) respectively. We also include Betweeness Centrality (Freeman, 1979) which is taken from the analysis of social networks. These methods are well known and applied across many disciplines, therefore we will leave it to the reader to follow up on the specifics of these graph centrality measures. However we do explicitly define our last measure, Sum Inverse Path Length (Navigli and Ponzetto, 2012a; Navigli and Ponzetto, 2012b) in Equation (1) which was designed with WSD in mind, thus is less well known. e|p 1-1 (1) This measure scores a sense by summing up the scores of all paths that connect to other senses in GL (i.e. senses that are not intermediate nodes, but have a mapping back to a lemma in the context window L). In the words of Navigli and Ponzetto (2012a), Ps→c is the set of paths connecting s to other senses of context words, with |p |as the number of edges in the path p and each path is scored with the exponential inverse decay of the path length. 4.3 Experiment 1: Proof of </context>
</contexts>
<marker>Navigli, Ponzetto, 2012</marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2012a. BabelNet: The Automatic Construction, Evaluation and Application of a Wide-Coverage Multilingual Semantic Network. Artificial Intelligence, 193:217– 250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>Joining Forces Pays Off: Multilingual Joint Word Sense Disambiguation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>1399--1410</pages>
<institution>Jeju Island, Korea. Association for Computational Linguistics.</institution>
<contexts>
<context position="16338" citStr="Navigli and Ponzetto, 2012" startWordPosition="2958" endWordPosition="2961">s we set out to understand a number of aspects. The first evaluation is a proof of concept, to understand whether an iterative approach to subgraph WSD can in fact achieve better performance than the conventional approach. The second set of experiments seeks to understand how the iterative approach works and the performance benefits and penalties of implementing the iterative approach. Finally the third experiment is an elementary attempt at optimising the iterative approach to defeat the MFS baseline. 4.1 LKB &amp; Dataset For an evaluation, we have chosen the multilingual LKB known as BabelNet (Navigli and Ponzetto, 2012a). It weaves together several other LKBs, most notably WordNet (Fellbaum, 1998) and Wikipedia. It also can be easily accessed with the BabelNet API, of which we have built our code base around. All experiments are conducted on the most recent SemEval WSD dataset, of which is the SemEval 2013 Task 12 Multilingual WSD (English) data set. 3This can happen if Bi does not map to any senses, or alternatively all the senses that are mapped to are filtered out of the subgraph before disambiguation (explained later). 4.2 Graph Centrality Measures Evaluated To demonstrate the effectiveness of our itera</context>
<context position="18092" citStr="Navigli and Ponzetto, 2012" startWordPosition="3241" endWordPosition="3244">tic web, such as PageRank (Brin and Page, 1998), HITS Kleinberg (1999), and apersonalised PageRank (Haveliwala, 2003); which have since been applied to WSD by Mihalcea (2005), Navigli and Lapata (2007), and Agirre and Soroa (2009) respectively. We also include Betweeness Centrality (Freeman, 1979) which is taken from the analysis of social networks. These methods are well known and applied across many disciplines, therefore we will leave it to the reader to follow up on the specifics of these graph centrality measures. However we do explicitly define our last measure, Sum Inverse Path Length (Navigli and Ponzetto, 2012a; Navigli and Ponzetto, 2012b) in Equation (1) which was designed with WSD in mind, thus is less well known. e|p 1-1 (1) This measure scores a sense by summing up the scores of all paths that connect to other senses in GL (i.e. senses that are not intermediate nodes, but have a mapping back to a lemma in the context window L). In the words of Navigli and Ponzetto (2012a), Ps→c is the set of paths connecting s to other senses of context words, with |p |as the number of edges in the path p and each path is scored with the exponential inverse decay of the path length. 4.3 Experiment 1: Proof of </context>
</contexts>
<marker>Navigli, Ponzetto, 2012</marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2012b. Joining Forces Pays Off: Multilingual Joint Word Sense Disambiguation. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1399–1410, Jeju Island, Korea. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Paola Velardi</author>
</authors>
<title>Structural Semantic Interconnections: A Knowledgebased Approach to Word Sense Disambiguation.</title>
<date>2005</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>27</volume>
<issue>7</issue>
<contexts>
<context position="5469" citStr="Navigli and Velardi (2005)" startWordPosition="862" endWordPosition="865">or unsupervised subgraph-based WSD, the key publications that have advanced the field broadly construct subgraph, GL, as either a union of subtree paths, shortest paths, or local edges2. First we initialise GL, by setting SL := Uni=1 R(`i) and EL := ∅. Next we add edges to EL, depending on the desired subgraph type, by adding either the: (a) Subtree paths of up to length L, via a DepthFirst Search (DFS) of G. In brief, for each sense sa ∈ SL, if a new sense sb ∈ SL, i.e. sb =6 sa, is encountered along a path Pa,b = {{sa, s}, ..., {s&apos;, sb}} with pathlength |Pa,b |≤ L, then add Pa,b to GL. [cf. Navigli and Velardi (2005), Navigli and Lapata (2007), or Navigli and Lapata (2010)] (b) Shortest paths, via a Breadth-First Search (BFS) of G. In brief, for each sense pair sa, sb ∈ SL, find the shortest path Pa,b = {{sa, s},..., {s&apos;, sb}}; if such a path Pa,b exists and (optionally) |Pa,b |≤ L, then add Pa,b to GL [cf. Agirre and Soroa (2008), Agirre and Soroa (2009), or Gutiérrez et al. (2013)] 1For a detailed explanation of the processes leading up to lemmatisation (and beyond), see Navigli (2009, p12) 2‘Local’ describes the local context, typically this is the 2 or 3 words either side of a word, see Yarowsky (1993</context>
</contexts>
<marker>Navigli, Velardi, 2005</marker>
<rawString>Roberto Navigli and Paola Velardi. 2005. Structural Semantic Interconnections: A Knowledgebased Approach to Word Sense Disambiguation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(7):1075–1086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Kenneth C Litkowski</author>
<author>Orin Hargraves</author>
</authors>
<title>SemEval-2007 Task 07: CoarseGrained English All-Words Task.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations,</booktitle>
<pages>30--35</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="2675" citStr="Navigli et al., 2007" startWordPosition="388" endWordPosition="391">10). As Pedersen (2007) rightly states, supervised systems are bound by their training data, and therefore are limited in portability and flexibility in the face of new domains, changing applications, or different languages. This knowledge acquisition bottleneck, coined by Gale et al. (1992), can be alleviated by unsupervised systems that exploit the portability and flexibility of Lexical Knowledge Bases (LKBs). As of 2007, SENSEVAL became SEMEVAL, offering a more diverse range of semantic tasks. Unsupervised knowledge-based WSD has since had its performance evaluated in terms of granularity (Navigli et al., 2007), domain (Agirre et al., 2010), and cross/multi-linguality (Lefever and Hoste, 2010; Lefever and Hoste, 2013; Navigli et al., 2013). Results from these tasks have demonstrated unsupervised systems are now a competitive and robust alternative to supervised systems, especially given the ever changing task-orientated settings WSD is evaluated in. One such class of unsupervised knowledgebased WSD systems that we seek to improve in this paper constructs semantic subgraphs from LKBs, and then runs graph-based centrality measures such as PageRank (Brin and Page, 1998) over them to finally select the </context>
</contexts>
<marker>Navigli, Litkowski, Hargraves, 2007</marker>
<rawString>Roberto Navigli, Kenneth C Litkowski, and Orin Hargraves. 2007. SemEval-2007 Task 07: CoarseGrained English All-Words Task. In Proceedings of the 4th International Workshop on Semantic Evaluations, pages 30–35, Prague, Czech Republic. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>David Jurgens</author>
<author>Daniele Vannella</author>
</authors>
<title>SemEval-2013 Task 12: Multilingual Word Sense Disambiguation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013), in conjunction with the Second Joint Conference on Lexical and Computational Semantics (*SEM 2013). Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2806" citStr="Navigli et al., 2013" startWordPosition="407" endWordPosition="410">ty and flexibility in the face of new domains, changing applications, or different languages. This knowledge acquisition bottleneck, coined by Gale et al. (1992), can be alleviated by unsupervised systems that exploit the portability and flexibility of Lexical Knowledge Bases (LKBs). As of 2007, SENSEVAL became SEMEVAL, offering a more diverse range of semantic tasks. Unsupervised knowledge-based WSD has since had its performance evaluated in terms of granularity (Navigli et al., 2007), domain (Agirre et al., 2010), and cross/multi-linguality (Lefever and Hoste, 2010; Lefever and Hoste, 2013; Navigli et al., 2013). Results from these tasks have demonstrated unsupervised systems are now a competitive and robust alternative to supervised systems, especially given the ever changing task-orientated settings WSD is evaluated in. One such class of unsupervised knowledgebased WSD systems that we seek to improve in this paper constructs semantic subgraphs from LKBs, and then runs graph-based centrality measures such as PageRank (Brin and Page, 1998) over them to finally select the senses (as nodes) ranked as the most relevant. This class is known as subgraph-based WSD, characterised over the last decade by per</context>
<context position="30796" citStr="Navigli et al., 2013" startWordPosition="5347" endWordPosition="5350">ΔF-Score 20 10 0 5 10 15 20 25 30 35 Document Monosemy (%) (a) φ = Betweenness Centrality 20 15 10 5 0 5 10 15 20 25 30 35 Document Monosemy (%) (b) φ = PageRank Figure 7: Both PageRank (squares) and Betweenness Centrality (circles) are plotted. Each data plot represents the change in F-Score when the iterative approach replaces the conventional approach with respect to the monosemy of the document. 4.5 Experiment 3: A Little Optimisation Briefly, we made an effort into optimising the iterative approach with subtree subgraphs, and compared these results with systems from SemEval 2013 Task 12 (Navigli et al., 2013) in Table 3. Team System P R F UMCC-DLSI Run-2+ 68.50 68.50 68.50 UMCC-DLSI Run-3+ 68.00 68.00 68.00 UMCC-DLSI Run-1+ 67.70 67.70 67.70 SUDOKU It-PPR[M]+ 67.41 67.30 67.36 MACHINE MFS 66.50 66.50 66.50 SUDOKU It-PPR[M] 67.20 65.49 66.33 SUDOKU It-PR[U] 64.07 62.44 63.24 SUDOKU It-PD 63.58 61.47 62.51 DAEBAK! PD+ 60.50 60.40 60.40 GETALP BN-1+ 58.30 58.30 58.30 SUDOKU PR[U] 60.09 54.06 56.91 GETALP BN-2+ 56.80 56.80 56.80 Table 3: Comparison to SemEval 2013 Task 12 Firstly, we were able to marginally improve our original result as team DAEBAK! (Manion and Sainudiin, 2013), by applying the itera</context>
</contexts>
<marker>Navigli, Jurgens, Vannella, 2013</marker>
<rawString>Roberto Navigli, David Jurgens, and Daniele Vannella. 2013. SemEval-2013 Task 12: Multilingual Word Sense Disambiguation. In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013), in conjunction with the Second Joint Conference on Lexical and Computational Semantics (*SEM 2013). Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Word Sense Disambiguation: A Survey.</title>
<date>2009</date>
<journal>ACM Computing Surveys,</journal>
<volume>41</volume>
<issue>2</issue>
<pages>10--69</pages>
<contexts>
<context position="5948" citStr="Navigli (2009" startWordPosition="950" endWordPosition="951">ountered along a path Pa,b = {{sa, s}, ..., {s&apos;, sb}} with pathlength |Pa,b |≤ L, then add Pa,b to GL. [cf. Navigli and Velardi (2005), Navigli and Lapata (2007), or Navigli and Lapata (2010)] (b) Shortest paths, via a Breadth-First Search (BFS) of G. In brief, for each sense pair sa, sb ∈ SL, find the shortest path Pa,b = {{sa, s},..., {s&apos;, sb}}; if such a path Pa,b exists and (optionally) |Pa,b |≤ L, then add Pa,b to GL [cf. Agirre and Soroa (2008), Agirre and Soroa (2009), or Gutiérrez et al. (2013)] 1For a detailed explanation of the processes leading up to lemmatisation (and beyond), see Navigli (2009, p12) 2‘Local’ describes the local context, typically this is the 2 or 3 words either side of a word, see Yarowsky (1993) (c) Local edges up to a local distance D. In brief, for each sense pair sa, sb ∈ SL, if the distance in the text |b − a |between the corresponding words wa and wb satisfies |b − a |≤ D, then add edge {sa, sb} to GL (preferably with edgeweights). [cf. Mihalcea (2005) or Sinha and Mihalcea (2007)] (Note that this subgraph is a hybrid, because only its vertices belong to G) In practice, subgraph edges may be directed, weighted, collapsed, or filtered. However to keep the dist</context>
</contexts>
<marker>Navigli, 2009</marker>
<rawString>Roberto Navigli. 2009. Word Sense Disambiguation: A Survey. ACM Computing Surveys, 41(2):10:1 – 10:69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Christiane Fellbaum</author>
<author>Scott Cotton</author>
<author>Lauren Delfs</author>
<author>Hoa Trang Dang</author>
</authors>
<title>English Tasks: All-Words and Verb Lexical Sample.</title>
<date>2001</date>
<booktitle>In Proceedings of SENSEVAL-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems,</booktitle>
<pages>21--24</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Toulouse, France.</location>
<contexts>
<context position="1452" citStr="Palmer et al., 2001" startWordPosition="209" endWordPosition="212">or a range of well-known graph centrality measures and subgraph types, at the sentence and document level. The results demonstrated that an average performing WSD system which embraces the iterative approach, can easily compete with state-ofthe-art. This alone warrants further investigation. 1 Introduction Explicit WSD is a two-step process of analysing a word’s contextual use then deducing its intended sense. When Kilgarriff (1998) established SENSEVAL, the collaborative framework and forum to evaluate WSD, unsupervised systems performed poorly in comparison to their supervised counterparts (Palmer et al., 2001; Snyder and Palmer, 2004). A review of the literature shows there This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/ by/4.0/ Raazesh Sainudiin University of Canterbury Christchurch, New Zealand r.sainudiin @math.canterbury.ac.nz has been a healthy rivalry between the two, in which proponents of unsupervised WSD have long sought to vindicate its potential since two decades ago (Yarowsky, 1995) to even more recent times (Ponzetto and Navigli, </context>
</contexts>
<marker>Palmer, Fellbaum, Cotton, Delfs, Dang, 2001</marker>
<rawString>Martha Palmer, Christiane Fellbaum, Scott Cotton, Lauren Delfs, and Hoa Trang Dang. 2001. English Tasks: All-Words and Verb Lexical Sample. In Proceedings of SENSEVAL-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems, pages 21–24, Toulouse, France. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
</authors>
<title>Unsupervised Corpus-Based Methods for WSD.</title>
<date>2007</date>
<booktitle>Word Sense Disambiguation: Algorithms and Applications, chapter 6,</booktitle>
<pages>133--166</pages>
<editor>In Eneko Agirre and Philip Edmonds, editors,</editor>
<publisher>Springer,</publisher>
<location>New York.</location>
<contexts>
<context position="2077" citStr="Pedersen (2007)" startWordPosition="300" endWordPosition="301">nd Palmer, 2004). A review of the literature shows there This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/ by/4.0/ Raazesh Sainudiin University of Canterbury Christchurch, New Zealand r.sainudiin @math.canterbury.ac.nz has been a healthy rivalry between the two, in which proponents of unsupervised WSD have long sought to vindicate its potential since two decades ago (Yarowsky, 1995) to even more recent times (Ponzetto and Navigli, 2010). As Pedersen (2007) rightly states, supervised systems are bound by their training data, and therefore are limited in portability and flexibility in the face of new domains, changing applications, or different languages. This knowledge acquisition bottleneck, coined by Gale et al. (1992), can be alleviated by unsupervised systems that exploit the portability and flexibility of Lexical Knowledge Bases (LKBs). As of 2007, SENSEVAL became SEMEVAL, offering a more diverse range of semantic tasks. Unsupervised knowledge-based WSD has since had its performance evaluated in terms of granularity (Navigli et al., 2007), </context>
</contexts>
<marker>Pedersen, 2007</marker>
<rawString>Ted Pedersen. 2007. Unsupervised Corpus-Based Methods for WSD. In Eneko Agirre and Philip Edmonds, editors, Word Sense Disambiguation: Algorithms and Applications, chapter 6, pages 133–166. Springer, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simone Paolo Ponzetto</author>
<author>Roberto Navigli</author>
</authors>
<title>Knowledge-rich Word Sense Disambiguation Rivaling Supervised Systems.</title>
<date>2010</date>
<booktitle>Proceedings of the 48th Annual Meeting of the ACL,</booktitle>
<pages>1522--1531</pages>
<contexts>
<context position="2057" citStr="Ponzetto and Navigli, 2010" startWordPosition="295" endWordPosition="298">s (Palmer et al., 2001; Snyder and Palmer, 2004). A review of the literature shows there This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/ by/4.0/ Raazesh Sainudiin University of Canterbury Christchurch, New Zealand r.sainudiin @math.canterbury.ac.nz has been a healthy rivalry between the two, in which proponents of unsupervised WSD have long sought to vindicate its potential since two decades ago (Yarowsky, 1995) to even more recent times (Ponzetto and Navigli, 2010). As Pedersen (2007) rightly states, supervised systems are bound by their training data, and therefore are limited in portability and flexibility in the face of new domains, changing applications, or different languages. This knowledge acquisition bottleneck, coined by Gale et al. (1992), can be alleviated by unsupervised systems that exploit the portability and flexibility of Lexical Knowledge Bases (LKBs). As of 2007, SENSEVAL became SEMEVAL, offering a more diverse range of semantic tasks. Unsupervised knowledge-based WSD has since had its performance evaluated in terms of granularity (Nav</context>
</contexts>
<marker>Ponzetto, Navigli, 2010</marker>
<rawString>Simone Paolo Ponzetto and Roberto Navigli. 2010. Knowledge-rich Word Sense Disambiguation Rivaling Supervised Systems. Proceedings of the 48th Annual Meeting of the ACL, pages 1522–1531.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Didier Schwab</author>
<author>Andon Tchechmedjiev</author>
<author>Jérôme Goulian</author>
<author>Mohammad Nasiruddin</author>
<author>Gilles Sérasset</author>
<author>Hervé Blanchon</author>
</authors>
<title>GETALP: Propagation of a Lesk Measure through an Ant Colony Algorithm.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013), in conjunction with the Second Joint Conference on Lexical and Computational Semantics (*SEM</booktitle>
<pages>232--240</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta,</location>
<contexts>
<context position="31982" citStr="Schwab et al., 2013" startWordPosition="5540" endWordPosition="5543">diin, 2013), by applying the iterative approach to our Peripheral Diversity centrality measure (It-PD). Next we tried Personalised PageRank (It-PPR[M]) with a surfing vector biased towards only Monosemous senses. We also included regular PageRank (It-/PR[U]) with a Uniform surfing vector as a reference point. It-PPR[M] almost defeated the MFS baseline of 66.50, but lacked recall. To rectify this, the MFS baseline was used as a back-off strategy (It-PPR[M]+)4, which then led 4Note that plus+ implies the use of a back-off strategy. to us beating the MFS baseline. As for the other teams, GETALP (Schwab et al., 2013) made use of an Ant Colony algorithm, while UMCC-DLSI (Gutiérrez et al., 2013) also made use of PPR, except they based the surfing vector on SemCor (Miller et al., 1993) sense frequencies, set L = 5 for shortest paths subgraphs, and disambiguated using resources external to BabelNet. Since their implementation of PPR beats ours, it would be interesting to see how effective the iterative approach could be on their results. 5 Conclusion &amp; Future Work In this paper we have shown that the iterative approach can substantially improve the results of regular subgraph-based WSD, even to the point of d</context>
</contexts>
<marker>Schwab, Tchechmedjiev, Goulian, Nasiruddin, Sérasset, Blanchon, 2013</marker>
<rawString>Didier Schwab, Andon Tchechmedjiev, Jérôme Goulian, Mohammad Nasiruddin, Gilles Sérasset, and Hervé Blanchon. 2013. GETALP: Propagation of a Lesk Measure through an Ant Colony Algorithm. In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013), in conjunction with the Second Joint Conference on Lexical and Computational Semantics (*SEM 2013), pages 232–240, Atlanta, Georgia. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ravi Sinha</author>
<author>Rada Mihalcea</author>
</authors>
<title>Unsupervised Graph-based Word Sense Disambiguation Using Measures of Word Semantic Similarity.</title>
<date>2007</date>
<booktitle>In Proceedings of the International Conference on Semantic Computing,</booktitle>
<pages>363--369</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="6366" citStr="Sinha and Mihalcea (2007)" startWordPosition="1030" endWordPosition="1033">then add Pa,b to GL [cf. Agirre and Soroa (2008), Agirre and Soroa (2009), or Gutiérrez et al. (2013)] 1For a detailed explanation of the processes leading up to lemmatisation (and beyond), see Navigli (2009, p12) 2‘Local’ describes the local context, typically this is the 2 or 3 words either side of a word, see Yarowsky (1993) (c) Local edges up to a local distance D. In brief, for each sense pair sa, sb ∈ SL, if the distance in the text |b − a |between the corresponding words wa and wb satisfies |b − a |≤ D, then add edge {sa, sb} to GL (preferably with edgeweights). [cf. Mihalcea (2005) or Sinha and Mihalcea (2007)] (Note that this subgraph is a hybrid, because only its vertices belong to G) In practice, subgraph edges may be directed, weighted, collapsed, or filtered. However to keep the distinctions between subgraph types simple, we do not include this in our formalisation. 2.2 Step 2: Disambiguation To disambiguate each lemma `i ∈ L, its corresponding senses, R(`i) = {si,1, si,2, ..., si,k}, are scored by a graph-based centrality measure φ, over subgraph GL, to estimate the most appropriate sense, ˆsi,* = arg maxsjjER(`j) φ(si,j). The estimated sense ˆsi,* is then assigned to word wi. 2.3 Algorithm f</context>
</contexts>
<marker>Sinha, Mihalcea, 2007</marker>
<rawString>Ravi Sinha and Rada Mihalcea. 2007. Unsupervised Graph-based Word Sense Disambiguation Using Measures of Word Semantic Similarity. In Proceedings of the International Conference on Semantic Computing, pages 363 – 369. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Martha Palmer</author>
</authors>
<title>The English All-Words Task.</title>
<date>2004</date>
<booktitle>In Proceedings of the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text,</booktitle>
<pages>41--43</pages>
<contexts>
<context position="1478" citStr="Snyder and Palmer, 2004" startWordPosition="213" endWordPosition="216">own graph centrality measures and subgraph types, at the sentence and document level. The results demonstrated that an average performing WSD system which embraces the iterative approach, can easily compete with state-ofthe-art. This alone warrants further investigation. 1 Introduction Explicit WSD is a two-step process of analysing a word’s contextual use then deducing its intended sense. When Kilgarriff (1998) established SENSEVAL, the collaborative framework and forum to evaluate WSD, unsupervised systems performed poorly in comparison to their supervised counterparts (Palmer et al., 2001; Snyder and Palmer, 2004). A review of the literature shows there This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/ by/4.0/ Raazesh Sainudiin University of Canterbury Christchurch, New Zealand r.sainudiin @math.canterbury.ac.nz has been a healthy rivalry between the two, in which proponents of unsupervised WSD have long sought to vindicate its potential since two decades ago (Yarowsky, 1995) to even more recent times (Ponzetto and Navigli, 2010). As Pedersen (2007) </context>
</contexts>
<marker>Snyder, Palmer, 2004</marker>
<rawString>Benjamin Snyder and Martha Palmer. 2004. The English All-Words Task. In Proceedings of the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, pages 41–43,</rawString>
</citation>
<citation valid="false">
<authors>
<author>Spain Barcelona</author>
</authors>
<title>Association for Computational Linguistics.</title>
<marker>Barcelona, </marker>
<rawString>Barcelona, Spain. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>One Sense Per Collocation.</title>
<date>1993</date>
<booktitle>In Proceedings of the workshop on Human Language Technology - HLT ’93,</booktitle>
<pages>266--271</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="6070" citStr="Yarowsky (1993)" startWordPosition="972" endWordPosition="973">Velardi (2005), Navigli and Lapata (2007), or Navigli and Lapata (2010)] (b) Shortest paths, via a Breadth-First Search (BFS) of G. In brief, for each sense pair sa, sb ∈ SL, find the shortest path Pa,b = {{sa, s},..., {s&apos;, sb}}; if such a path Pa,b exists and (optionally) |Pa,b |≤ L, then add Pa,b to GL [cf. Agirre and Soroa (2008), Agirre and Soroa (2009), or Gutiérrez et al. (2013)] 1For a detailed explanation of the processes leading up to lemmatisation (and beyond), see Navigli (2009, p12) 2‘Local’ describes the local context, typically this is the 2 or 3 words either side of a word, see Yarowsky (1993) (c) Local edges up to a local distance D. In brief, for each sense pair sa, sb ∈ SL, if the distance in the text |b − a |between the corresponding words wa and wb satisfies |b − a |≤ D, then add edge {sa, sb} to GL (preferably with edgeweights). [cf. Mihalcea (2005) or Sinha and Mihalcea (2007)] (Note that this subgraph is a hybrid, because only its vertices belong to G) In practice, subgraph edges may be directed, weighted, collapsed, or filtered. However to keep the distinctions between subgraph types simple, we do not include this in our formalisation. 2.2 Step 2: Disambiguation To disambi</context>
</contexts>
<marker>Yarowsky, 1993</marker>
<rawString>David Yarowsky. 1993. One Sense Per Collocation. In Proceedings of the workshop on Human Language Technology - HLT ’93, pages 266–271, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Unsupervised Word Sense Disambiguation Rivaling Supervised Methods.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the ACL,</booktitle>
<pages>189--196</pages>
<publisher>Association for</publisher>
<institution>Computational Linguistics.</institution>
<location>Cambridge, MA.</location>
<contexts>
<context position="2002" citStr="Yarowsky, 1995" startWordPosition="288" endWordPosition="289"> comparison to their supervised counterparts (Palmer et al., 2001; Snyder and Palmer, 2004). A review of the literature shows there This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/ by/4.0/ Raazesh Sainudiin University of Canterbury Christchurch, New Zealand r.sainudiin @math.canterbury.ac.nz has been a healthy rivalry between the two, in which proponents of unsupervised WSD have long sought to vindicate its potential since two decades ago (Yarowsky, 1995) to even more recent times (Ponzetto and Navigli, 2010). As Pedersen (2007) rightly states, supervised systems are bound by their training data, and therefore are limited in portability and flexibility in the face of new domains, changing applications, or different languages. This knowledge acquisition bottleneck, coined by Gale et al. (1992), can be alleviated by unsupervised systems that exploit the portability and flexibility of Lexical Knowledge Bases (LKBs). As of 2007, SENSEVAL became SEMEVAL, offering a more diverse range of semantic tasks. Unsupervised knowledge-based WSD has since had</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>David Yarowsky. 1995. Unsupervised Word Sense Disambiguation Rivaling Supervised Methods. In Proceedings of the 33rd Annual Meeting of the ACL, pages 189–196, Cambridge, MA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>