<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.576049">
Two Constraints on Speech Act Ambiguity
Elizabeth A. Hinkelman and James F. Allen
Computer Science Department
The University of Rochester
Rochester, New York 14627
</title>
<sectionHeader confidence="0.89273" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999915076923077">
Existing plan-based theories of speech act
interpretation do not account for the conventional
aspect of speech acts. We use patterns of linguistic
features (e.g. mood, verb form, sentence adverbials,
thematic roles) to suggest a range of speech act
interpretations for the utterance. These are filtered
using plan-based conversational implicatures to
eliminate inappropriate ones. Extended plan
reasoning is available but not necessary for familiar
forms. Taking speech act ambiguity seriously, with
these two constraints, explains how &amp;quot;Can you pass
the salt?&amp;quot; is a typical indirect request while &amp;quot;Are you
able to pass the salt?&amp;quot; is not.
</bodyText>
<sectionHeader confidence="0.98913" genericHeader="method">
1. The Problem
</sectionHeader>
<bodyText confidence="0.998681833333333">
Full natural language systems must recognize
speakers&apos; intentions in an utterance. They must know
when the speaker is asserting, asking, or making a
social or official gesture [Searle 69, Searle 75], in
addition to its content. For instance, the ordinary
sentence
</bodyText>
<listItem confidence="0.919951">
(1) Can you open the door?
</listItem>
<bodyText confidence="0.998533333333333">
might in context be a question, a request, or even an
offer. Several kinds of information complicate the
recognition process. Literal meaning, lexical and
syntactic choices, agents&apos; beliefs, the immediate
situation, and general knowledge about human
behavior all clarify what the ordinary speaker is after.
Given an utterance and context, we model how the
utterance changes the hearer&apos;s state. Previous work
falls roughly into three approaches, each with
characteristic weaknesses: the idiom approach, the
plan based approach, and the descriptive approach.
The idiom approach is motivated by pat phrases like:
</bodyText>
<listItem confidence="0.9661638">
(2) a: Can you please X?
b: Would you kindly X?
c: I&apos;d like X.
d: May I X?
e: How about X?
</listItem>
<bodyText confidence="0.999815076923077">
They are literally questions or statements, but often
used as requests or in (e), suggestions. The system
could look for these particular strings, and build the
corresponding speech act using the complement as a
parameter value. But such sentences are not true
idioms, because the literal meaning is also possible in
many contexts. Also, one can respond to the literal
and nonliteral acts: &amp;quot;Sure, it&apos;s the 9th.&amp;quot; The idiom
approaches are too inflexible to choose the literal
reading or to accommodate ambiguity. They lack a
theory connecting the nonliteral and literal readings.
Another problem is that some classic examples are
not even pat phrases:
</bodyText>
<listItem confidence="0.915872">
(3) a: It&apos;s cold in here.
b: Do you have a watch on?
</listItem>
<bodyText confidence="0.998776333333333">
In context, (a) may be a request to close the window.
Sentence (b) may be asking what time it is or
requesting to borrow the watch. The idiom approach
allows neither for context nor the reasoning
connecting utterance and desired action.
The plan based approach
[Allen 83, McCafferty 86, Perrault 80, Sidner 81]
presumes a mechanism modelling human problem
solving abilities, including reasoning about other
agents and inferring their intentions. The system has
a model of the current situation and the ability to
choose a course of action. It can relate uttered
propositions to the current situation: being cold in
here is a bad state, and so you probably want me to
do something about it; the obvious solution is for me
to close the window, so, I understand, you mean for
me to close the window. The plan based approach
provides a tidy, independently motivated theory for
speech act interpretation.
It does not use language-specific information,
however. Consider
</bodyText>
<listItem confidence="0.99804">
(4) a: Can you speak Spanish?
b: Can you speak Spanish, please?
</listItem>
<bodyText confidence="0.692616">
Here the addition of a word alters an utterance which
is a yes/no question in typical circumstances to a
request. This is not peculiar to &amp;quot;please&amp;quot;:
</bodyText>
<listItem confidence="0.951894">
(5) a: Can you open the door?
b: Are you able to open the door?
</listItem>
<bodyText confidence="0.999667833333333">
Here two sentences, generally considered to have the
same semantics, differ in force: the first may be a
question, an offer, or a request, the second, only a
question. Further, different languages realize speech
acts in different ways: greetings, for example (or see
[Horn 84]).
</bodyText>
<listItem confidence="0.872619">
(6) a: You want to cook dinner.
b: You wanna toss your coats in there?
</listItem>
<bodyText confidence="0.9999245625">
The declarative sentence (a) can be a request,
idiomatic to Hebrew, while the nearest American
expression is interrogative (b). Neither is a request in
British English. The plan based approach has
nothing to say about these differences. Neither does it
explain the psycholinguistic [Gibbs 84] finding that
people access idiomatic interpretations in context
more quickly than literal ones. Psycholinguistically
plausible models cannot derive idiomatic meanings
from literal meanings.
Descriptive approaches cover large amounts of data.
[Brown 80] recognized the diversity of speech act
phenomena and included the first computational
model with wide coverage, but lacked theoretical
claims and did not handle the language-specific cases
well. [Gordon 75] expresses some very nice
</bodyText>
<page confidence="0.880088">
21 2
</page>
<bodyText confidence="0.999585044444445">
generalizations, but lacks motivation and sufficient
detail. It does not account for examples like numbers
3, 4, 6 or 7. In number 3, for example, one asks a
question by asking literally whether the hearer knows
the answer. A plan-based approach would argue that
knowing the answer is a precondition for stating it,
and this logical connection enables identification of
the real question. But Gordon and Lakoff write off
this one, because their sincerity conditions are
inadequate.
We augment the plan-based approach with a
linguistic component: compositional rules
associating linguistic features with partial speech act
descriptions. The rules express linguistic
conventions that are often motivated by planning
theory, but they also allow for an element of
arbitrariness in just which forms are idiomatic to a
language, and just which words and features mark it.
For this reason, conventions of use cannot be handled
directly by the plan reasoning mechanism. They
require an interpretation process paralleling syntactic
and semantic interpretation, with the same provisions
for merging of partial interpretations and
postponement of ambiguity resolution. The
compositionality of partial speech act interpretations
and use of ambiguity are both original to our
approach.
Once the utterances have been interpreted by our
conventional rules to produce a set of candidate
conventional interpretations, these interpretations are
filtered by the plan reasoner. Plan reasoning
processes unconventional forms in the same spirit as
earlier plan-based models, finding non-conventional
interpretations and motivating many conventional
ones. We propose a limited version of plan
reasoning, based on an original claim about
conversational implicature, which is adequate for
filtering conventional interpretations.
Section 2 will explain the linguistic computation
which interprets linguistic features as speech act
descriptions. Section 3 describes plan reasoning
techniques that are useful for speech act
interpretation and presents our view of plan
reasoning. Section 4 presents the overall process
combining these two parts.
</bodyText>
<sectionHeader confidence="0.975797" genericHeader="method">
2. Linguistic Constraints
</sectionHeader>
<bodyText confidence="0.999838076923077">
Speech act interpretation has many similarities to the
plan recognition problem. Its goal is, given a
situation and an utterance, to understand what the
speaker was doing with that utterance, and to find a
basis for an appropriate response. In our case this
will mean identifying a set of plan structures
representing speech acts, which are possible
interpretations of the utterance. In this section we
show how to use compositional, language-specific
rules to provide evidence for a set of partial speech
act interpretations, and how to merge them. Later, we
use plan reasoning to constrain, supplement, and
decide among this set.
</bodyText>
<subsectionHeader confidence="0.987902">
2.1. Notational Aside
</subsectionHeader>
<bodyText confidence="0.999337533333333">
Our notation is based on that of [Allen 871. Its
essential form is (category &lt;slot filler&gt; &lt;slot
filler&gt;...). Categories may be syntactic, semantic, or
from the knowledge base. A filler may be a word, a
feature, a knowledge-base object (referent) or
another (category...) structure.
Two slots associated with syntactic categories may
seem unusual: SEM and REF. They contain the
unit&apos;s semantic interpretation, divided into two
components. The SEM slot contains a structural-
semantic representation of this instance, based on a
small, finite set of thematic roles for verbs and noun
phrases. It captures the linguistic generalities of verb
subcategorization and noun phrase structure.
Selectional restrictions, identification of referents,
and other phenomena involving world knowledge are
captured in the REF slot. It contains a translation of
the SEM slot&apos;s logical form into a framelike
knowledge representation language, in which richer
and more specific role assignments can be made.
SEM thematic roles correspond to different
knowledge base roles according to the event class
being described, and in REF the corresponding event
and argument instances are identified if possible.
Distinguishing logical form from knowledge
representation is an experiment intended to clarify
the notion of semantic roles in logical form, and to
reduce the complexity of the interpretation process.
The sentence &amp;quot;Can you speak Spanish?&amp;quot; is shown
below.
</bodyText>
<equation confidence="0.2768625">
(S MOOD YES-NO-0
VOICE ACT
</equation>
<sectionHeader confidence="0.857611" genericHeader="method">
SUBJ (NP HEAD you
SEM (HUMAN hl)
REF Suzanne)
AUXS can
MAIN-V speak
TENSE PRES
OBJ (NP HEAD Spanish
SEM (LANG ID Si)
REF 1s1)
SEM (CAPABLE
TENSE PRES
AGENT hl
THEME (SPEAK OBJECT Si))
REF (ABLE-STATE
AGENT Suzanne
ACTION (USE-LANGUAGE
AGENT Suzanne
LANG 181)))
</sectionHeader>
<bodyText confidence="0.9614479">
The outermost category is the syntactic category,
sentence. It has many ordinary syntactic features,
subject, object, and verbs. The subject is a noun
phrase that describes a human and refers to a person
2 1 3
named Suzanne, the object a language, Spanish. The
semantic structure concerns the capability of the
person to speak a language. In the knowledge base,
this becomes Suzanne&apos;s ability to use Spanish as a
language.
</bodyText>
<subsectionHeader confidence="0.851492">
2.2. Evidence for Interpretations
</subsectionHeader>
<bodyText confidence="0.98100730952381">
The utterance provides clues to the hearer, but we
have already seen that its relation to its purpose may
be complex. We need to make use of lexical and
syntactic as well as semantic and referential
information. In this section we will look at rules
using all of these kinds of information, introducing
the notation for rules as we go. Rules consist of a set
of features on the left-hand side, and a set of partial
speech act descriptions on the other. The rule should
be interpreted as saying that any structure matching
the left hand side must be interpreted as one of the
speech acts indicated on the right hand side. The
speech act descriptions themselves are also in
(category &lt;slot filler&gt; ... &lt;slot filler&gt;) notation. Their
categories are simply their types in the knowledge
base&apos;s abstraction hierarchy, in which the category
SPEECH-ACT abstracts all speech act types. Slot
names and filler types also are defined by the
abstraction hierarchy, but a given rule need not
specify all slot values. Here is a lexical rule: the
adverb &amp;quot;please&amp;quot; occurring in any syntactic unit
signals a request, command, or other act in the
directive class.
(? ADV please) —(l)=&gt;
(DIRECTIVE-ACT)
Although this is a very simple rule, its correctness
has been established by examination of some 43
million words of Associated Press news stories. This
corpus contains several hundred occurrences of
&amp;quot;please&amp;quot;, the most common form being the preverbal
adverb in a directive utterance.
A number of useful generalizations are based on the
syntactic mood of sentences. As we use the term,
mood is an aggregate of several syntactic features
taking the values DECLARATIVE, IMPERATIVE,
YES-NO-Q, WH-Q. Many different speech act types
occur with each of these values, but in the absence of
other evidence an imperative is likely to be a
command and a declarative, an Inform. An
interrogative sentence may be a question or possibly
another speech act.
(S MOOD YES -NO -Q) =(2)=&gt;
</bodyText>
<sectionHeader confidence="0.876267" genericHeader="method">
((ASK-ACT PROP V(REF))
(SPEECH-ACT))
</sectionHeader>
<bodyText confidence="0.999401777777778">
The value function v returns the value of the
specified slot of the sentence. Thus rule 2 has the
proposition slot PROP filled with the value of the
REF slot of the sentence. It matches sentences whose
mood is that of a yes/no question, and interprets them
as asking for the truth value of their explicit
propositional content. Thus matching this rule
against the structure for &amp;quot;Can you speak Spanish?&amp;quot;
would produce the interpretations
</bodyText>
<sectionHeader confidence="0.931373666666667" genericHeader="method">
((ASK-ACT
PROP (ABLE-STATE AGENT Suzanne
ACTION (USE-LANGUAGE
</sectionHeader>
<figure confidence="0.970827461538462">
AGENT Suzanne
LANG lel)))
(SPEECH-ACT))
Interrogative sentences with modal verbs and a
subject &amp;quot;you&amp;quot; are typically requests, but may be some
other act: .
(S MOOD YES-NO-Q --(3)=&gt;
VOICE ACT
SUBJ (NP PRO you)
AUXS (can could will would might}
MAIN-V +action)
((REQUEST-ACT ACTION V(ACTION REF))
(SPEECH-ACT))
</figure>
<bodyText confidence="0.964465588235294">
Rule 3 interprets &amp;quot;Can you...?&amp;quot; questions as requests,
looking for the subject &amp;quot;you&amp;quot; and any of these modal
verbs. Lists in curly brackets (e.g. (can could will
would might)) signify disjunctions; one of the
members must be matched. In this rule, the value
function v follows a chain of slots to find a value.
Thus V (ACTION REF) is the value of the
ACTION slot in the structure that is the value of the
REF slot. Note that an unspecified speech act is also
included as a possibility in both rules. This is
because it is also possible that the utterance might
have a different interpretation, not suggested by the
mood.
Some rules are based in the semantic level. For
example, the presence of a benefactive case may
mark a request, or it may simply occur in a statement
or question.
</bodyText>
<sectionHeader confidence="0.62007925" genericHeader="method">
(S MAIN-V +action
SEM (? BENEF ? ) ) = ( 4 ) =&gt;
((DIRECTIVE-ACT ACT V(REF))
(SPEECH-ACT))
</sectionHeader>
<bodyText confidence="0.948244">
Recall that we distinguish the semantic level from the
reference level, inasmuch as the semantic level is
simplified by a strong theory of thematic roles, or
cases, a small standard set of which may prove
adequate to explain verb subcategorization
phenomena [Jackendoff 72] The reference level, by
</bodyText>
<page confidence="0.635137">
21 4
</page>
<bodyText confidence="0.999012142857143">
contrast, is the language of the knowledge base, in
which very specific domain roles are possible. To the
extent that referents can be identified in the
knowledge base (often as skolem functions) they
appear at the reference level. This rule says that any
way of stating a desire may be a request for the
object of the want.
</bodyText>
<table confidence="0.7257112">
(S MOOD DECL =(5)=&gt;
VOICE ACT
TENSE PRES
REF (WANT-ACT ACTOR !s))
(REQUEST-ACT
</table>
<sectionHeader confidence="0.869632" genericHeader="method">
ACT V(DESID WANT-ACT REF))
</sectionHeader>
<bodyText confidence="0.9543085">
It will match any sentence that can be interpreted as
asserting a want or desire of the agent, such as
</bodyText>
<listItem confidence="0.3847805">
(7) a: I need a napkin.
b: I would like two ice creams.
</listItem>
<bodyText confidence="0.999382125">
The object of the request is the WANT-ACT&apos;s
desideratum. (The desideratum is already filled by
reference processing.) One may prefer an account
that handles generalizations from the REF level by
plan reasoning; we will discuss this point later. For
now, it is sufficient to note that rules of this type are
capable of representing the conventions of language
use that we are after.
</bodyText>
<subsectionHeader confidence="0.997573">
2.3. Applying the Rules
</subsectionHeader>
<bodyText confidence="0.9997739375">
We now consider in detail how to apply the rules.
For now, assume that the utterance is completely
parsed and semantically interpreted, unambiguously,
like the sentence &amp;quot;Can you speak Spanish?&amp;quot; as it
appeared in Sect. 2.1.
Interpretation of this sentence begins by finding rules
that match with it. The matching algorithm is a
standard unification or graph matcher. It requires that
the category in the rule match the syntactic structure
given. All slots present in the rule must be found on
the category, and have equal values, and so on
recursively. Slots not present in the rule are ignored.
If the rule matches, the structures on the right hand
side are filled out and become partial interpretations.
We need a few general rules to fill in information
about the conversation:
</bodyText>
<equation confidence="0.41791">
(?) ( 6) &amp;quot;•&gt; ( (SPEECH-ACT AGENT ! s) )
</equation>
<bodyText confidence="0.997053142857143">
Rule 6 says that an utterance of any syntactic
category maps to a speech act with agent specified by
the global variable !s. (The processes of identifying
speaker and hearer are assumed to be contextually
defined.) The partial interpretation it yields for the
Spanish sentence is a speech act with agent Mrs. de
Prado:
</bodyText>
<sectionHeader confidence="0.87961" genericHeader="method">
((SPEECH-ACT AGENT Mrs. de Prado))
</sectionHeader>
<bodyText confidence="0.939388">
The second rule is analogous, filling in the hearer.
</bodyText>
<equation confidence="0.600534">
( ? ) = ( 7)=&gt; ( (SPEECH-ACT HEARER ! h) )
</equation>
<bodyText confidence="0.9568575">
For our example sentence, it yields a speech act with
hearer Suzanne.
</bodyText>
<sectionHeader confidence="0.821062" genericHeader="method">
((SPEECH-ACT HEARER Suzanne))
</sectionHeader>
<bodyText confidence="0.4473225">
Rule no. 2 given earlier, for yes/no questions,
produces these interpretations:
</bodyText>
<sectionHeader confidence="0.796582" genericHeader="method">
((ASK-ACT
PROP(ABLE -STATE
AGENT Suzanne
ACTION (USE-LANGUAGE
AGENT Suzanne
LANG 1s1)))
</sectionHeader>
<bodyText confidence="0.9624278">
(SPEECH-ACT) )
The indirect request comes from rule no. 3 above.
To apply it, we match the subject &amp;quot;you&amp;quot; and the
modal auxialiary &amp;quot;can&amp;quot;, and the features of yes/no
mood and active voice.
</bodyText>
<sectionHeader confidence="0.8369635" genericHeader="method">
((REQUEST-ACT
ACTION (USE-LANGUAGE
AGENT Suzanne
LANG 181)))
</sectionHeader>
<bodyText confidence="0.938065666666667">
(SPEECH-ACT) )
We now have four sets of partial descriptions, which
must be merged.
</bodyText>
<subsectionHeader confidence="0.987682">
2.4. Combining Partial Descriptions
</subsectionHeader>
<bodyText confidence="0.9999237">
The combining operation can be thought of as taking
the cross product of the sets, merging partial
interpretations within each resulting set, and
returning those combinations that are consistent
internally. We expect that psycholinguistic studies
will provide additional constraints on this set, e.g.
commitment to interpretations triggered early in the
sentence.
The operation of merging partial interpretations is
again unification or graph matching; when the
operation succeeds the result contains all the
information from the contributing partial
interpretations. The cross product of our first two
sets is simple; it is the pair consisting of the
interpretation for speaker and hearer. These two can
be merged to form a set containing the single speech
act with speaker Mrs. de Prado and hearer Suzanne.
The cross product of this with the results of the mood
rule contains two pairs. Within the first pair, the
ASK-ACT is a subtype of SPEECH-ACT and
</bodyText>
<page confidence="0.995007">
215
</page>
<bodyText confidence="0.9977810625">
therefore matches, resulting in a request with the
proper speaker and hearer. The second pair results in
no new information, just the SPEECH-ACT with
speaker and hearer. (Recall that the mood rule must
allow for other interpretations of yes/no questions,
and here we simply propagate that fact.)
Now we must take the cross product of two sets of
two interpretations, yielding four pairs. One pair is
inconsistent because REQUEST-ACT and ASK-
ACT do not unify. The REQUEST-ACT gets
speaker and hearer by merging with the SPEECH-
ACT, and the ASK-ACT slides through by merging
with the other SPEECH-ACT. Likewise the two
SPEECH-ACTs match, so in the end we have an
ASK-ACT, REQUEST-ACT, and the simple
SPEECH-ACT.
</bodyText>
<figure confidence="0.8039156875">
((REQUEST-ACT
AGENT Mrs. de Prado
HEARER Suzanne
ACTION (USE-LANGUAGE
AGENT Suzanne
LANG 1s1)))
(ASK-ACT
AGENT Mrs. de Prado
HEARER Suzanne
PROP (ABLE-STATE
AGENT Suzanne
ACTION (USE
AGENT Suzanne
OBJECT 1s1)))
(SPEECH-ACT AGENT Mrs. de Prado)
HEARER Suzanne))
</figure>
<bodyText confidence="0.9994406">
At this stage, the utterance is ambiguous among these
three interpretations. Consider their classifications in
the speech act hierarchy. The third abstracts the
other two, and signals that there may be other
possibilities, those it also abstracts. Its significance is
that it allows the plan reasoner to suggest these
further interpretations, and it will be discussed later.
If there are any expectations generated by top-down
plan recognition mechanisms, say, the answer in a
question/answer pair, they can be merged in here.
</bodyText>
<subsectionHeader confidence="0.95826">
2.5. Further Linguistic Considerations
</subsectionHeader>
<bodyText confidence="0.981784892857143">
We have used a set of compositional rules to build up
multiple interpretations of an utterance, based on
linguistic features. They can incorporate lexical,
syntactic, semantic and referential distinctions. Why
does the yes/no question interpretation seem to be
favored in the Spanish example? We hypothesize
that for utterances taken out of context, people make
pure frequency judgements. And questions about
one&apos;s language ability are much more common than
requests to speak one. Such a single-utterance
request is possible only in contexts where the
intended content of the Spanish-speaking is clear or
clearly irrelevant, since &amp;quot;speak&amp;quot; doesn&apos;t
subcategorize for this crucial information. (cf. &amp;quot;Can
you read Spanish? I have this great article ....&amp;quot;)
The statistical base can be overridden by lexical
information. Recall 5(b) &amp;quot;Can you speak Spanish,
please?&amp;quot; The &amp;quot;please&amp;quot; rule (above) yields only the
request interpretation, and fails to merge with the
ASK-ACT. It also merges with the SPEECH-ACT,
but the result is again a request, merely adding the
possibility that the request could be for some other
action. No such action is likely to be identified. The
&amp;quot;please&amp;quot; rule is very strong, because it can override
our expectations. The final interpretations for &amp;quot;Can
you speak Spanish, please?&amp;quot; do not include the literal
interpretation:
((REQUEST-ACT
</bodyText>
<sectionHeader confidence="0.791910857142857" genericHeader="method">
AGENT Mrs. de Prado
HEARER Suzanne
ACTION (USE-LANGUAGE
AGENT Suzanne
LANG 151)))
((REQUEST-ACT AGENT Mrs. de Prado
HEARER Suzanne)
</sectionHeader>
<bodyText confidence="0.9968544">
Here Suzanne is probably being asked to continue the
present dialogue in Spanish.
Some linguistic features are as powerful as &amp;quot;please&amp;quot;,
as can be seen by the incoherence of the following,
where each sentence contains contradictory features.
</bodyText>
<listItem confidence="0.981575">
(8) a: *Should you go home, please?
b: *Shouldn&apos;t you go home, please?
c: *Why not go home, please?
</listItem>
<figureCaption confidence="0.663428181818182">
Modal verbs can be quite strong, and intonation as
well. Other features are more suggestive than
definitive. The presence of a benefactive case (rule
above) may be evidence for an offer or request, or
just happen to appear in an inform or question.
Sentence mood is weak evidence: it is often
overridden, but in the absence of other evidence it it
becomes important. The adverbs &amp;quot;kindly&amp;quot; and
&amp;quot;possibly&amp;quot; are also weak evidence for a request, and
large class of sentential adverbs is associated
primarily with Inform acts.
</figureCaption>
<listItem confidence="0.974147666666667">
(9) a: *Unfortunately, I promise to obey orders.
b: Surprisingly, I&apos;m leaving next week.
c: Actually, I&apos;m pleased to see you.
</listItem>
<bodyText confidence="0.99890175">
Explicit performative utterances [Austin 621 are
declarative, active, utterances whose main verb
identifies the action explicitly. The sentence meaning
corresponds exactly to the action performed.
</bodyText>
<sectionHeader confidence="0.7165618" genericHeader="method">
(S MOOD DECL
VOICE ACT
SUBJ (NP HEAD i)
MAIN-V +performative
TENSE PRES)
</sectionHeader>
<page confidence="0.993719">
216
</page>
<sectionHeader confidence="0.361519" genericHeader="method">
=(8)=&gt; V (REF )
</sectionHeader>
<bodyText confidence="0.999824">
Note that the rule is not merely triggering off a
keyword. Presence of a performative verb without
the accompanying syntactic features will not satisfy
the performative rule.
</bodyText>
<subsectionHeader confidence="0.996165">
2.6. The Limits of Conventionality
</subsectionHeader>
<bodyText confidence="0.99965675">
We do not claim that all speech acts are
conventional. There are variations in convention
across languages, of course, and dialects, but
idiolects also vary greatly. Some people, even very
cooperative ones, do not recognize many types of
indirect requests. Too, there is a form of request for
which the generalization is obvious but only special
cases seem idiomatic:
</bodyText>
<listItem confidence="0.9860518">
(10) a: Got a light?
b: Got a dime?
c: Got a donut? (odd request)
d: Do you have the time?
e: Do you have a watch on?
</listItem>
<bodyText confidence="0.992715555555556">
There are other forms for which the generalization is
obvious but no instance seems idiomatic: if someone
was assigned a task, asking whether it&apos;s done is as
good as a request.
(11) Did you wash the dishes?
In the next examples, there is a clear logical
connection between the utterance and the requested
action. We could write a rule for the surface pattern,
but the rule is useless because it cannot verify the
logical connection. This must be done by plan
reasoning, because it depends on world knowledge.
The first sentences can request the actions they are
preconditions of. The second set can request actions
they are effects of. Because these requests operate
via the conditions on the domain plan rather than the
speech act itself, they are beyond the reach of
theories like Gordon&amp;Lakoff &apos;s, which have very
simple notions of what a sincerity condition can be.
</bodyText>
<listItem confidence="0.9848512">
(12) a: Is the garage open?
b: Did the dryer stop?
c: The mailman came.
d: Are you planning to take out the garbage?
(13) a: Is the car fixed?
</listItem>
<bodyText confidence="0.939897583333334">
b: Have you fixed the car?
c: Did you fix the car?
Plan reasoning provides an account for all of these
examples. The fact that certain examples can be
handled by either mechanism we regard as a strength
of the theory: it leads to robust natural language
processing systems, and explains why &amp;quot;Can you X?&amp;quot;
is such a successful construction. Both mechanisms
work well for such utterances, so the hearer has two
ways to understand it correctly. These last examples,
along with &amp;quot;It&apos;s cold in here&amp;quot;, really require plan
reasoning.
</bodyText>
<subsectionHeader confidence="0.471796">
3. Role of Plan Reasoning
</subsectionHeader>
<bodyText confidence="0.984741394736842">
Plan reasoning constitutes our second constraint on
speech act recognition. There are four roles for plan
reasoning in the recognition process. Specifically,
plan reasoning
1) eliminates speech act interpretations proposed
by the linguistic mechanism, if they contradict
known intentions and beliefs of the agent.
2) elaborates and makes inferences based on the
remaining interpretations, allowing for
non-conventional speech act interpretations.
3) can propose interpretations of its own, when
there is enough context information to guess
what the speaker might do next.
4) provides a competence theory motivating many of
the conventions we have described.
Plan reasoning rules are based on the causal and
structural links used in plan construction. For
instance, in planning start with a desired goal
proposition, plan an action with that effect, and then
plan for its preconditions. There are also recognition
schemas for attributing plans: having observed that
an agent wants an effect, believe that they may plan
an action with that effect, and so on. For modelling
communication, it is necessary to complicate these
rules by embedding the antecedent and consequent in
one-sided mutual belief operators [Allen 83]. In the
Allen approach, our Spanish example hinges on the
acts&apos; preconditions: Suzanne will not attribute a
question to Mrs. de Prado if she believes she already
knows the answer, but this knowledge could be the
basis for a request. Sentences like &amp;quot;It&apos;s cold in here&amp;quot;
are also interpreted by extended reasoning about the
intentions an agent could plausibly have. We use
extended reasoning for difficult cases, and the more
restricted plan-based conversational implicature
heuristic [Hinkelman 87], [Hinkelman forthcoming]
as a plausibility filter adequate for most common
cases.
</bodyText>
<sectionHeader confidence="0.946106" genericHeader="method">
4. Two Constraints Integrated
</sectionHeader>
<bodyText confidence="0.999948571428571">
Section 2 showed how to compute a set of possible
speech act interpretations compositionally, from
conventions of language use. Section 3 showed how
plan reasoning, which motivates the conventions, can
be used to further develop and restrict the
interpretations. The time has come to integrate the
two into a complete system.
</bodyText>
<subsectionHeader confidence="0.996173">
4.1. Interaction of the Constraints
</subsectionHeader>
<bodyText confidence="0.999935714285714">
The plan reasoning phase constrains the results of the
lingtigtic computation by eliminating interpretations,
and reinterpreting others. The linguistic computation
constrains plan reasoning by providing the input; the
final interpretation must be in the range specified, and
only if there is no plausible interpretation is extended
inference explicitly invoked. Recall that the
</bodyText>
<page confidence="0.99119">
217
</page>
<bodyText confidence="0.99957475">
linguistic rules control ambiguity: because the right
hand side of the rule must express all the possibilities
for this pattern, a single rule can limit the range of
interpretations sharply. Consider
</bodyText>
<listItem confidence="0.9051405">
(14) a: I hereby inform you that it&apos;s cold in here.
b: It&apos;s cold in here.
</listItem>
<bodyText confidence="0.99997616">
The explicit performative rules, triggered by
&amp;quot;hereby&amp;quot; and by a performative verb in the
appropriate syntactic context, each allow for only an
explicit performative interpretation. (a) is
unambiguous, and if it is consistent with context no
extended reasoning is needed for speech act
identification purposes. (In fact the hearer will
probably find the formality implausible, and try to
explain that.) By contrast, the declarative rule
proposes two speech acts for (b), the Inform and the
generic speech act. The ambiguity allows the plan
reasoner to identify other interpretations, particularly
if in context the Inform interpretation is implausible.
The entire speech act interpretation process is now as
follows. Along with the usual compositional
linguistic processes, we build up and merge
hypotheses about speech act interpretations. The
resulting interpretations are passed to the implicature
module. The conversational implicatures are
computed, discounting interpretations if they are in
conflict with contextual knowledge. If a plausible,
non-contradictory interpretation results, it can be
accepted. Allen-style plan reasoning is invoked to
identify the speech act only if remaining ambiguity
interferes with planning or if no completely plausible
interpretations remain. After that, plan reasoning
may proceed to elaborate the interpretation or to plan
a response.
Consider the central example of this paper. Three
interpretations were were proposed for &amp;quot;Can you
speak Spanish?&amp;quot;, in Section 2.
As they become available, the next step in processing
is to check plausibility by attempting to verify the
act&apos;s conversational implicatures. We showed how
the Ask act is ruled out by its irnplicatures, when the
answer is known. Likewise, in circumstances where
Suzanne is known not to speak Spanish, the Request
is eliminated.
The generic speech act is present under most
circumstances, but adds little information except to
allow for other possibilities. Because in any of these
contexts a specific interpretation is acceptable, no
further inference is necessary for identifying the
speech act. If it is merely somewhat likely that
Suzanne speaks Spanish, both specific interpretations
are possible and both may even be intended by Mrs.
de Prado. Further plan reasoning may elaborate or
eliminate possibilities, or plan a response. But it is
not required for the main effort of speech act
identification.
</bodyText>
<subsectionHeader confidence="0.974699">
4.2. The Role of Ambiguity
</subsectionHeader>
<bodyText confidence="0.999701384615385">
If no interpretations remain after the plausibility
check, then the extended plan reasoning may be
invoked to resolve a possible misunderstanding or
mistaken belief. If several remain, it may not be
necessary to disambiguate. Genuine ambiguity of
intentions is quite common in speech and often not a
problem. For instance, the speaker may mention
plans to go to the store, and leave unclear whether
this constitutes a promise.
In cases of genuine ambiguity, it is possible for the
hearer to respond to each of the proposed
interpretations, and indeed, politeness may even
require it. Consider (b)-(g) as responses to (a).
</bodyText>
<listItem confidence="0.786027285714286">
(15) a: Do you have our grades yet?
b: No, not yet.
c: Yes, I&apos;m going to announce them in class.
d: Sure, here&apos;s your paper. (hands paper.)
e: Here you go. (hands paper.)
f: *No.
g: *Yes.
</listItem>
<bodyText confidence="0.9996035">
The main thing to note is that it is infelicitous to
ignore the Request interpretation; the polite responses
acknowledge that the speaker wants the grades.
Note that within the framework of &amp;quot;speaker-based&amp;quot;
meaning, we emphasize the role of the hearer in the
final understanding of an utterance. An important
point is that while the speech act attempted depends
on the speaker&apos;s intentions, the speech act
accomplished also depends on the hearer&apos;s ability to
recognize the intentions, and to some extent their
own desires in the matter. Consider an example from
[Clark 88]:
</bodyText>
<listItem confidence="0.99876675">
(16) a: Have some asparagus.
b: No, thanks,
(17) a: Have some asparagus.
b: OK, if! have to....
</listItem>
<bodyText confidence="0.999256666666667">
The first hearer treats the sentence as an offer, the
second as a command. If the speaker intended
otherwise, it must be corrected quickly or be lost.
</bodyText>
<subsectionHeader confidence="0.961531">
4.3. The Implementation
</subsectionHeader>
<bodyText confidence="0.9999373125">
Our system is implemented using common lisp and
the Rhetorical knowledge representation system
[Miller 87], which provides among other things a
hierarchy of belief spaces. The linguistic speech act
interpretation module been implemented, with
merging, as well as the implicature calculation and
checking module. So given the appropriate contexts,
the Spanish example runs. Extended plan reasoning
will eventually be added.
There are of course open problems. One would like
to experiment with large interpretation rule sets, and
with the constraints from other modules. The
projection problem, both for conversational
implicature and for speech act interpretation, has not
been examined directly. If a property like
conversational implicature or presupposition is
</bodyText>
<page confidence="0.993815">
218
</page>
<bodyText confidence="0.999950125">
computed at the clause level, one wants to know
whether the property survives negation, conjunction,
or any other syntactic embedding. [Horton 87] has a
result for projection of presuppositions, which may
be generalizable. The other relevant work is
[Hirschberg 85] and [Gazdar 79]. Plan recognition
for discourse, and the processing of cue words, are
related areas.
</bodyText>
<sectionHeader confidence="0.999193" genericHeader="conclusions">
5. Conclusion
</sectionHeader>
<bodyText confidence="0.999991789473684">
To determine what an agent is doing by making an
utterance, we must make use of not only general
reasoning about actions in context, but also the
linguistic features which by convention are
associated with specific speech act types. To do this,
we match patterns of linguistic features as part of the
standard linguistic processing. The resulting partial
interpretations are merged, and then filtered by
determining the plausibility of their conversational
implicatures. Assuming no errors on the part of the
speaker, the final interpretation is constrained to lie
within the range so specified.
If there is not a plausible interpretation, full plan
reasoning is called to determine the speaker&apos;s
intentions. Remaining ambiguity is not a problem but
simply a more complex basis for the hearer&apos;s
planning processes. Linguistic patterns and plan
reasoning together constrain speech act interpretation
sufficiently for discourse purposes.
</bodyText>
<sectionHeader confidence="0.995755" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99993225">
This work was supported in part by NSF research
grants no. DCR-8502481, IST-8504726, and US
Army Engineering Topographic Laboratories
research contract no. DACA76-85-C-0001.
</bodyText>
<sectionHeader confidence="0.999347" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999877919354839">
[Allen 83] Allen, J., &amp;quot;Recognizing Intentions From
Natural Language Utterances,&amp;quot; in Computational
Models of Discourse, Brady, M. and Berwick, B.
(ed.), MIT Press, Cambridge, MA, 1983, 107-166.
[Allen 87] Allen, J., Natural Language
Understanding, Benjamin Cummings Publishing Co.,
1987.
[Austin 62] Austin, J. L., How to Do Things with
Words, Harvard University Press, Cambridge, MA,
1962.
[Brown 80] Brown, G. P., &amp;quot;Characterizing Indirect
Speech Acts,&amp;quot; American Journal of Computational
Linguistics 6:3-4, July-December 1980, 150-166.
[Clark 88] Clark, H., Collective Actions in Language
Use, Invited Talk, September 21, 1988.
[Gazdar 79] Gazdar, G., Pragmatics: Implicative,
Presupposition and Logical Form, Academic Press,
New York, 1979.
[Gibbs 84] Gibbs, R., &amp;quot;Literal Meaning and
Psychological Theory,&amp;quot; Cognitive Science 8, 1984,
275-304.
[Gordon 75] Gordon, D. and Lakoff, G.,
&amp;quot;Conversational Postulates,&amp;quot; in Syntax and Semantics
V. 3, Cole, P. and Morgan, J. L. (ed.), Academic
Press, New York, 1975.
[Hinkelman 87] Hinkelman, E., &amp;quot;Thesis Proposal: A
Plan-Based Approach to Conversational
Implicature,&amp;quot; TR 202, Dept. Computer Science,
University of Rochester, June 1987.
[Hirschberg 85] Hirschberg, J., &amp;quot;A Theory of Scalar
of Implicature,&amp;quot; MS-CIS-85-56, PhD Thesis,
Department of Computer and Information Science,
University of Pennsylvania, December 1985.
[Horn 84] Horn, L. R. and Bayer, S., Short-Circuited
Implicature: A Negative Contribution, Vol. 7, 1984.
[Horton 87] Horton, D. L., &amp;quot;Incorporating Agents&apos;
Beliefs in a Model of Presupposition,&amp;quot; Technical
Report CSRI-201, Computer Systems Research
Institute, University of Toronto, Toronto, Canada,
August 1987.
[Jackendoff 72] Jackendoff, R. S., Semantic
Interpretation in Generative Grammar, MIT Press,
Cambridge, 1972.
[McCafferty 86] McCafferty, A. S., Explaining
Implicatures, 23 October 1986.
[Miller 87] Miller, B. and Allen, J., The Rhetorical
Knowledge Representation System: A User&apos;s Manual,
forthcoming technical report, Department of
Computer Science, University of Rochester, 1987.
[Perrault 80] Perrault, C. R. and Allen, J. F., &amp;quot;A
Plan-Based Analysis of Indirect Speech Acts,&amp;quot;
American Journal of Computational Linguistics 6:3-
4, July-December 1980, 167-82.
[Searle 69] Searle, J., in Speech Acts, Cambridge
University Press, New York, 1969.
[Searle 75] Searle, J., &amp;quot;Indirect Speech Acts,&amp;quot; in
Syntax and Semantics, v3: Speech Acts, Cole and
Morgan (ed.), Academic Press, New York, NY,
1975.
[Sidner 81] Sidner, C. L. and Israel, D. J.,
&amp;quot;Recognizing Intended , Meaning and Speakers&apos;
Plans,&amp;quot; Proc. IJCAI &apos;81, 1981, 203-208.
</reference>
<page confidence="0.999215">
219
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.003505">
<title confidence="0.995344">Two Constraints on Speech Act Ambiguity</title>
<author confidence="0.999887">Elizabeth A Hinkelman</author>
<author confidence="0.999887">James F Allen</author>
<affiliation confidence="0.9998255">Computer Science Department The University of Rochester</affiliation>
<address confidence="0.999716">Rochester, New York 14627</address>
<abstract confidence="0.999737426395939">Existing plan-based theories of speech act interpretation do not account for the conventional aspect of speech acts. We use patterns of linguistic features (e.g. mood, verb form, sentence adverbials, thematic roles) to suggest a range of speech act interpretations for the utterance. These are filtered using plan-based conversational implicatures to eliminate inappropriate ones. Extended plan reasoning is available but not necessary for familiar forms. Taking speech act ambiguity seriously, with these two constraints, explains how &amp;quot;Can you pass the salt?&amp;quot; is a typical indirect request while &amp;quot;Are you able to pass the salt?&amp;quot; is not. 1. The Problem Full natural language systems must recognize speakers&apos; intentions in an utterance. They must know when the speaker is asserting, asking, or making a social or official gesture [Searle 69, Searle 75], in addition to its content. For instance, the ordinary sentence (1) Can you open the door? might in context be a question, a request, or even an offer. Several kinds of information complicate the recognition process. Literal meaning, lexical and syntactic choices, agents&apos; beliefs, the immediate situation, and general knowledge about human behavior all clarify what the ordinary speaker is after. Given an utterance and context, we model how the utterance changes the hearer&apos;s state. Previous work falls roughly into three approaches, each with characteristic weaknesses: the idiom approach, the plan based approach, and the descriptive approach. The idiom approach is motivated by pat phrases like: (2) a: Can you please X? b: Would you kindly X? c: I&apos;d like X. d: May I X? e: How about X? They are literally questions or statements, but often used as requests or in (e), suggestions. The system could look for these particular strings, and build the corresponding speech act using the complement as a parameter value. But such sentences are not true idioms, because the literal meaning is also possible in many contexts. Also, one can respond to the literal acts: &amp;quot;Sure, it&apos;s the 9th.&amp;quot; The idiom approaches are too inflexible to choose the literal reading or to accommodate ambiguity. They lack a theory connecting the nonliteral and literal readings. Another problem is that some classic examples are not even pat phrases: (3) a: It&apos;s cold in here. b: Do you have a watch on? In context, (a) may be a request to close the window. Sentence (b) may be asking what time it is or requesting to borrow the watch. The idiom approach allows neither for context nor the reasoning connecting utterance and desired action. The plan based approach [Allen 83, McCafferty 86, Perrault 80, Sidner 81] presumes a mechanism modelling human problem solving abilities, including reasoning about other agents and inferring their intentions. The system has a model of the current situation and the ability to choose a course of action. It can relate uttered propositions to the current situation: being cold in here is a bad state, and so you probably want me to do something about it; the obvious solution is for me to close the window, so, I understand, you mean for me to close the window. The plan based approach provides a tidy, independently motivated theory for speech act interpretation. It does not use language-specific information, however. Consider (4) a: Can you speak Spanish? b: Can you speak Spanish, please? Here the addition of a word alters an utterance which is a yes/no question in typical circumstances to a request. This is not peculiar to &amp;quot;please&amp;quot;: (5) a: Can you open the door? b: Are you able to open the door? Here two sentences, generally considered to have the same semantics, differ in force: the first may be a question, an offer, or a request, the second, only a question. Further, different languages realize speech acts in different ways: greetings, for example (or see [Horn 84]). (6) a: You want to cook dinner. b: You wanna toss your coats in there? The declarative sentence (a) can be a request, idiomatic to Hebrew, while the nearest American expression is interrogative (b). Neither is a request in British English. The plan based approach has nothing to say about these differences. Neither does it explain the psycholinguistic [Gibbs 84] finding that people access idiomatic interpretations in context more quickly than literal ones. Psycholinguistically plausible models cannot derive idiomatic meanings from literal meanings. Descriptive approaches cover large amounts of data. [Brown 80] recognized the diversity of speech act phenomena and included the first computational model with wide coverage, but lacked theoretical claims and did not handle the language-specific cases well. [Gordon 75] expresses some very nice 21 2 but and sufficient detail. It does not account for examples like numbers 3, 4, 6 or 7. In number 3, for example, one asks a question by asking literally whether the hearer knows the answer. A plan-based approach would argue that knowing the answer is a precondition for stating it, and this logical connection enables identification of the real question. But Gordon and Lakoff write off this one, because their sincerity conditions are inadequate. We augment the plan-based approach with a linguistic component: compositional rules associating linguistic features with partial speech act descriptions. The rules express linguistic conventions that are often motivated by planning theory, but they also allow for an element of arbitrariness in just which forms are idiomatic to a language, and just which words and features mark it. For this reason, conventions of use cannot be handled directly by the plan reasoning mechanism. They require an interpretation process paralleling syntactic and semantic interpretation, with the same provisions for merging of partial interpretations and postponement of ambiguity resolution. The compositionality of partial speech act interpretations and use of ambiguity are both original to our approach. Once the utterances have been interpreted by our conventional rules to produce a set of candidate conventional interpretations, these interpretations are filtered by the plan reasoner. Plan reasoning processes unconventional forms in the same spirit as earlier plan-based models, finding non-conventional interpretations and motivating many conventional ones. We propose a limited version of plan reasoning, based on an original claim about conversational implicature, which is adequate for filtering conventional interpretations. Section 2 will explain the linguistic computation which interprets linguistic features as speech act descriptions. Section 3 describes plan reasoning techniques that are useful for speech act interpretation and presents our view of plan reasoning. Section 4 presents the overall process combining these two parts. 2. Linguistic Constraints Speech act interpretation has many similarities to the plan recognition problem. Its goal is, given a situation and an utterance, to understand what the speaker was doing with that utterance, and to find a basis for an appropriate response. In our case this will mean identifying a set of plan structures representing speech acts, which are possible interpretations of the utterance. In this section we show how to use compositional, language-specific rules to provide evidence for a set of partial speech act interpretations, and how to merge them. Later, we use plan reasoning to constrain, supplement, and decide among this set. 2.1. Notational Aside Our notation is based on that of [Allen 871. Its essential form is (category &lt;slot filler&gt; &lt;slot filler&gt;...). Categories may be syntactic, semantic, or from the knowledge base. A filler may be a word, a feature, a knowledge-base object (referent) or another (category...) structure. Two slots associated with syntactic categories may unusual: contain the unit&apos;s semantic interpretation, divided into two components. The SEM slot contains a structuralsemantic representation of this instance, based on a small, finite set of thematic roles for verbs and noun phrases. It captures the linguistic generalities of verb subcategorization and noun phrase structure. Selectional restrictions, identification of referents, and other phenomena involving world knowledge are in the It contains a translation of logical form into a framelike knowledge representation language, in which richer and more specific role assignments can be made. SEM thematic roles correspond to different knowledge base roles according to the event class described, and in corresponding event and argument instances are identified if possible. Distinguishing logical form from knowledge representation is an experiment intended to clarify the notion of semantic roles in logical form, and to reduce the complexity of the interpretation process. The sentence &amp;quot;Can you speak Spanish?&amp;quot; is shown below.</abstract>
<title confidence="0.717342555555555">MOOD (NP HEAD (HUMAN (NP HEAD (LANG ID SEM (CAPABLE (SPEAK OBJECT REF (ABLE-STATE ACTION (USE-LANGUAGE</title>
<abstract confidence="0.989685509191178">The outermost category is the syntactic category, sentence. It has many ordinary syntactic features, subject, object, and verbs. The subject is a noun phrase that describes a human and refers to a person 1 named Suzanne, the object a language, Spanish. The semantic structure concerns the capability of the person to speak a language. In the knowledge base, this becomes Suzanne&apos;s ability to use Spanish as a language. for Interpretations provides clues to the hearer, but we have already seen that its relation to its purpose may be complex. We need to make use of lexical and syntactic as well as semantic and referential information. In this section we will look at rules using all of these kinds of information, introducing the notation for rules as we go. Rules consist of a set of features on the left-hand side, and a set of partial speech act descriptions on the other. The rule should be interpreted as saying that any structure matching left hand side interpreted as one of the speech acts indicated on the right hand side. The speech act descriptions themselves are also in (category &lt;slot filler&gt; ... &lt;slot filler&gt;) notation. Their categories are simply their types in the knowledge base&apos;s abstraction hierarchy, in which the category all speech act Slot names and filler types also are defined by the abstraction hierarchy, but a given rule need not specify all slot values. Here is a lexical rule: the adverb &amp;quot;please&amp;quot; occurring in any syntactic unit signals a request, command, or other act in the directive class. ADV (DIRECTIVE-ACT) Although this is a very simple rule, its correctness has been established by examination of some 43 words of Press stories. This corpus contains several hundred occurrences of &amp;quot;please&amp;quot;, the most common form being the preverbal adverb in a directive utterance. A number of useful generalizations are based on the syntactic mood of sentences. As we use the term, mood is an aggregate of several syntactic features taking the values DECLARATIVE, IMPERATIVE, YES-NO-Q, WH-Q. Many different speech act types occur with each of these values, but in the absence of other evidence an imperative is likely to be a command and a declarative, an Inform. An interrogative sentence may be a question or possibly another speech act. MOOD -NO -Q) =(2)=&gt; ((ASK-ACT PROP V(REF)) (SPEECH-ACT)) The value function v returns the value of the slot of the sentence. Thus rule the slot with the value of the of the sentence. matches sentences whose mood is that of a yes/no question, and interprets them as asking for the truth value of their explicit propositional content. Thus matching this rule against the structure for &amp;quot;Can you speak Spanish?&amp;quot; would produce the interpretations ((ASK-ACT (ABLE-STATE AGENT ACTION (USE-LANGUAGE (SPEECH-ACT)) Interrogative sentences with modal verbs and a subject &amp;quot;you&amp;quot; are typically requests, but may be some other act: . MOOD --(3)=&gt; VOICE ACT could will would might} ((REQUEST-ACT ACTION V(ACTION REF)) (SPEECH-ACT)) Rule 3 interprets &amp;quot;Can you...?&amp;quot; questions as requests, looking for the subject &amp;quot;you&amp;quot; and any of these modal verbs. Lists in curly brackets (e.g. (can could will would might)) signify disjunctions; one of the members must be matched. In this rule, the value function v follows a chain of slots to find a value. (ACTION REF) the value of the in the structure that is the value of the Note that an unspecified speech act is also included as a possibility in both rules. This is because it is also possible that the utterance might have a different interpretation, not suggested by the mood. Some rules are based in the semantic level. For example, the presence of a benefactive case may mark a request, or it may simply occur in a statement or question. MAIN-V SEM (? BENEF ? ) ) = ( 4 ) =&gt; ((DIRECTIVE-ACT ACT V(REF)) (SPEECH-ACT)) Recall that we distinguish the semantic level from the reference level, inasmuch as the semantic level is simplified by a strong theory of thematic roles, or cases, a small standard set of which may prove adequate to explain verb subcategorization [Jackendoff reference level, by contrast, is the language of the knowledge base, in which very specific domain roles are possible. To the extent that referents can be identified in the knowledge base (often as skolem functions) they appear at the reference level. This rule says that any way of stating a desire may be a request for the object of the want. MOOD =(5)=&gt; VOICE ACT (WANT-ACT ACTOR (REQUEST-ACT ACT V(DESID WANT-ACT REF)) It will match any sentence that can be interpreted as asserting a want or desire of the agent, such as (7) a: I need a napkin. b: I would like two ice creams. The object of the request is the WANT-ACT&apos;s desideratum. (The desideratum is already filled by reference processing.) One may prefer an account handles generalizations from the by plan reasoning; we will discuss this point later. For now, it is sufficient to note that rules of this type are capable of representing the conventions of language use that we are after. 2.3. Applying the Rules We now consider in detail how to apply the rules. For now, assume that the utterance is completely parsed and semantically interpreted, unambiguously, like the sentence &amp;quot;Can you speak Spanish?&amp;quot; as it appeared in Sect. 2.1. Interpretation of this sentence begins by finding rules that match with it. The matching algorithm is a standard unification or graph matcher. It requires that the category in the rule match the syntactic structure given. All slots present in the rule must be found on the category, and have equal values, and so on recursively. Slots not present in the rule are ignored. If the rule matches, the structures on the right hand side are filled out and become partial interpretations. We need a few general rules to fill in information about the conversation: ( 6) &amp;quot;•&gt; ( AGENT ! s) Rule 6 says that an utterance of any syntactic category maps to a speech act with agent specified by the global variable !s. (The processes of identifying speaker and hearer are assumed to be contextually defined.) The partial interpretation it yields for the Spanish sentence is a speech act with agent Mrs. de Prado: AGENT de Prado)) The second rule is analogous, filling in the hearer. ? ) = ( ( HEARER h) ) For our example sentence, it yields a speech act with hearer Suzanne. HEARER Rule no. 2 given earlier, for yes/no questions, produces these interpretations: ((ASK-ACT PROP(ABLE -STATE ACTION (USE-LANGUAGE (SPEECH-ACT) ) The indirect request comes from rule no. 3 above. To apply it, we match the subject &amp;quot;you&amp;quot; and the modal auxialiary &amp;quot;can&amp;quot;, and the features of yes/no mood and active voice. ((REQUEST-ACT ACTION (USE-LANGUAGE (SPEECH-ACT) ) now have four sets of partial which must be merged. 2.4. Combining Partial Descriptions The combining operation can be thought of as taking the cross product of the sets, merging partial interpretations within each resulting set, and returning those combinations that are consistent internally. We expect that psycholinguistic studies will provide additional constraints on this set, e.g. commitment to interpretations triggered early in the sentence. The operation of merging partial interpretations is again unification or graph matching; when the operation succeeds the result contains all the information from the contributing partial interpretations. The cross product of our first two sets is simple; it is the pair consisting of the interpretation for speaker and hearer. These two can be merged to form a set containing the single speech act with speaker Mrs. de Prado and hearer Suzanne. The cross product of this with the results of the mood rule contains two pairs. Within the first pair, the a subtype of 215 therefore matches, resulting in a request with the proper speaker and hearer. The second pair results in new information, just the speaker and hearer. (Recall that the mood rule must allow for other interpretations of yes/no questions, and here we simply propagate that fact.) Now we must take the cross product of two sets of two interpretations, yielding four pairs. One pair is because ASKnot unify. The speaker and hearer by merging with the SPEECHthe through by merging the other the two so the end we have an REQUEST-ACT, the simple SPEECH-ACT. ((REQUEST-ACT de Prado ACTION (USE-LANGUAGE LANG 1s1))) (ASK-ACT de Prado PROP (ABLE-STATE ACTION (USE OBJECT 1s1))) AGENT de Prado) At this stage, the utterance is ambiguous among these three interpretations. Consider their classifications in the speech act hierarchy. The third abstracts the other two, and signals that there may be other possibilities, those it also abstracts. Its significance is that it allows the plan reasoner to suggest these further interpretations, and it will be discussed later. If there are any expectations generated by top-down plan recognition mechanisms, say, the answer in a question/answer pair, they can be merged in here. 2.5. Further Linguistic Considerations We have used a set of compositional rules to build up multiple interpretations of an utterance, based on linguistic features. They can incorporate lexical, syntactic, semantic and referential distinctions. Why does the yes/no question interpretation seem to be favored in the Spanish example? We hypothesize that for utterances taken out of context, people make pure frequency judgements. And questions about one&apos;s language ability are much more common than requests to speak one. Such a single-utterance request is possible only in contexts where the the Spanish-speaking is clear or clearly irrelevant, since &amp;quot;speak&amp;quot; doesn&apos;t subcategorize for this crucial information. (cf. &amp;quot;Can you read Spanish? I have this great article ....&amp;quot;) The statistical base can be overridden by lexical information. Recall 5(b) &amp;quot;Can you speak Spanish, please?&amp;quot; The &amp;quot;please&amp;quot; rule (above) yields only the request interpretation, and fails to merge with the also merges with the but the result is again a request, merely adding the possibility that the request could be for some other action. No such action is likely to be identified. The &amp;quot;please&amp;quot; rule is very strong, because it can override our expectations. The final interpretations for &amp;quot;Can you speak Spanish, please?&amp;quot; do not include the literal interpretation: ((REQUEST-ACT de Prado ACTION (USE-LANGUAGE AGENT de Prado Here Suzanne is probably being asked to continue the present dialogue in Spanish. Some linguistic features are as powerful as &amp;quot;please&amp;quot;, as can be seen by the incoherence of the following, where each sentence contains contradictory features. (8) a: *Should you go home, please? b: *Shouldn&apos;t you go home, please? c: *Why not go home, please? verbs can strong, and intonation as well. Other features are more suggestive than definitive. The presence of a benefactive case (rule above) may be evidence for an offer or request, or just happen to appear in an inform or question. Sentence mood is weak evidence: it is often overridden, but in the absence of other evidence it it becomes important. The adverbs &amp;quot;kindly&amp;quot; and &amp;quot;possibly&amp;quot; are also weak evidence for a request, and large class of sentential adverbs is associated primarily with Inform acts. (9) a: *Unfortunately, I promise to obey orders. b: Surprisingly, I&apos;m leaving next week. c: Actually, I&apos;m pleased to see you. Explicit performative utterances [Austin 621 are declarative, active, utterances whose main verb identifies the action explicitly. The sentence meaning corresponds exactly to the action performed. MOOD (NP HEAD 216 =(8)=&gt; V (REF ) Note that the rule is not merely triggering off a Presence of a performative verb the accompanying syntactic features will not satisfy the performative rule. 2.6. The Limits of Conventionality We do not claim that all speech acts are conventional. There are variations in convention across languages, of course, and dialects, but idiolects also vary greatly. Some people, even very cooperative ones, do not recognize many types of indirect requests. Too, there is a form of request for which the generalization is obvious but only special cases seem idiomatic: (10) a: Got a light? b: Got a dime? c: Got a donut? (odd request) d: Do you have the time? e: Do you have a watch on? There are other forms for which the generalization is obvious but no instance seems idiomatic: if someone was assigned a task, asking whether it&apos;s done is as good as a request. (11) Did you wash the dishes? In the next examples, there is a clear logical connection between the utterance and the requested action. We could write a rule for the surface pattern, but the rule is useless because it cannot verify the logical connection. This must be done by plan reasoning, because it depends on world knowledge. The first sentences can request the actions they are preconditions of. The second set can request actions they are effects of. Because these requests operate via the conditions on the domain plan rather than the speech act itself, they are beyond the reach of theories like Gordon&amp;Lakoff &apos;s, which have very simple notions of what a sincerity condition can be. (12) a: Is the garage open? b: Did the dryer stop? c: The mailman came. d: Are you planning to take out the garbage? (13) a: Is the car fixed? b: Have you fixed the car? c: Did you fix the car? Plan reasoning provides an account for all of these examples. The fact that certain examples can be handled by either mechanism we regard as a strength of the theory: it leads to robust natural language processing systems, and explains why &amp;quot;Can you X?&amp;quot; is such a successful construction. Both mechanisms for such utterances, so the hearer has two ways to understand it correctly. These last examples, along with &amp;quot;It&apos;s cold in here&amp;quot;, really require plan reasoning. 3. Role of Plan Reasoning Plan reasoning constitutes our second constraint on speech act recognition. There are four roles for plan reasoning in the recognition process. Specifically, plan reasoning 1) eliminates speech act interpretations proposed by the linguistic mechanism, if they contradict known intentions and beliefs of the agent. 2) elaborates and makes inferences based on the remaining interpretations, allowing for non-conventional speech act interpretations. 3) can propose interpretations of its own, when there is enough context information to guess what the speaker might do next. 4) provides a competence theory motivating many of the conventions we have described. Plan reasoning rules are based on the causal and structural links used in plan construction. For instance, in planning start with a desired goal proposition, plan an action with that effect, and then plan for its preconditions. There are also recognition schemas for attributing plans: having observed that an agent wants an effect, believe that they may plan an action with that effect, and so on. For modelling communication, it is necessary to complicate these rules by embedding the antecedent and consequent in one-sided mutual belief operators [Allen 83]. In the Allen approach, our Spanish example hinges on the acts&apos; preconditions: Suzanne will not attribute a to Mrs. if she believes she already knows the answer, but this knowledge could be the basis for a request. Sentences like &amp;quot;It&apos;s cold in here&amp;quot; are also interpreted by extended reasoning about the intentions an agent could plausibly have. We use extended reasoning for difficult cases, and the more restricted plan-based conversational implicature heuristic [Hinkelman 87], [Hinkelman forthcoming] as a plausibility filter adequate for most common cases. 4. Two Constraints Integrated Section 2 showed how to compute a set of possible speech act interpretations compositionally, from conventions of language use. Section 3 showed how plan reasoning, which motivates the conventions, can be used to further develop and restrict the interpretations. The time has come to integrate the two into a complete system. 4.1. Interaction of the Constraints The plan reasoning phase constrains the results of the lingtigtic computation by eliminating interpretations, and reinterpreting others. The linguistic computation constrains plan reasoning by providing the input; the final interpretation must be in the range specified, and if there is interpretation is inference explicitly invoked. Recall that the 217 linguistic rules control ambiguity: because the right side of the rule must express possibilities for this pattern, a single rule can limit the range of interpretations sharply. Consider (14) a: I hereby inform you that it&apos;s cold in here. b: It&apos;s cold in here. The explicit performative rules, triggered by &amp;quot;hereby&amp;quot; and by a performative verb in the appropriate syntactic context, each allow for only an explicit performative interpretation. (a) is unambiguous, and if it is consistent with context no extended reasoning is needed for speech act identification purposes. (In fact the hearer will probably find the formality implausible, and try to explain that.) By contrast, the declarative rule proposes two speech acts for (b), the Inform and the generic speech act. The ambiguity allows the plan reasoner to identify other interpretations, particularly if in context the Inform interpretation is implausible. The entire speech act interpretation process is now as follows. Along with the usual compositional linguistic processes, we build up and merge hypotheses about speech act interpretations. The resulting interpretations are passed to the implicature module. The conversational implicatures are computed, discounting interpretations if they are in conflict with contextual knowledge. If a plausible, non-contradictory interpretation results, it can be accepted. Allen-style plan reasoning is invoked to identify the speech act only if remaining ambiguity interferes with planning or if no completely plausible interpretations remain. After that, plan reasoning may proceed to elaborate the interpretation or to plan a response. Consider the central example of this paper. Three interpretations were were proposed for &amp;quot;Can you speak Spanish?&amp;quot;, in Section 2. As they become available, the next step in processing is to check plausibility by attempting to verify the act&apos;s conversational implicatures. We showed how act ruled out by its irnplicatures, when the answer is known. Likewise, in circumstances where Suzanne is known not to speak Spanish, the Request is eliminated. The generic speech act is present under most circumstances, but adds little information except to allow for other possibilities. Because in any of these contexts a specific interpretation is acceptable, no further inference is necessary for identifying the speech act. If it is merely somewhat likely that Suzanne speaks Spanish, both specific interpretations are possible and both may even be intended by Mrs. de Prado. Further plan reasoning may elaborate or eliminate possibilities, or plan a response. But it is not required for the main effort of speech act identification. 4.2. The Role of Ambiguity If no interpretations remain after the plausibility check, then the extended plan reasoning may be invoked to resolve a possible misunderstanding or mistaken belief. If several remain, it may not be necessary to disambiguate. Genuine ambiguity of intentions is quite common in speech and often not a problem. For instance, the speaker may mention plans to go to the store, and leave unclear whether this constitutes a promise. In cases of genuine ambiguity, it is possible for the hearer to respond to each of the proposed interpretations, and indeed, politeness may even require it. Consider (b)-(g) as responses to (a). (15) a: Do you have our grades yet? b: No, not yet. c: Yes, I&apos;m going to announce them in class. d: Sure, here&apos;s your paper. (hands paper.) e: Here you go. (hands paper.) f: *No. g: *Yes. The main thing to note is that it is infelicitous to ignore the Request interpretation; the polite responses acknowledge that the speaker wants the grades. Note that within the framework of &amp;quot;speaker-based&amp;quot; meaning, we emphasize the role of the hearer in the final understanding of an utterance. An important is that while the speech act on the speaker&apos;s intentions, the speech act depends on the hearer&apos;s ability to recognize the intentions, and to some extent their own desires in the matter. Consider an example from [Clark 88]: (16) a: Have some asparagus. b: No, thanks, (17) a: Have some asparagus. OK, to.... The first hearer treats the sentence as an offer, the second as a command. If the speaker intended otherwise, it must be corrected quickly or be lost. 4.3. The Implementation Our system is implemented using common lisp and the Rhetorical knowledge representation system [Miller 87], which provides among other things a hierarchy of belief spaces. The linguistic speech act interpretation module been implemented, with merging, as well as the implicature calculation and checking module. So given the appropriate contexts, the Spanish example runs. Extended plan reasoning will eventually be added. There are of course open problems. One would like to experiment with large interpretation rule sets, and with the constraints from other modules. The projection problem, both for conversational implicature and for speech act interpretation, has not been examined directly. If a property like conversational implicature or presupposition is 218 computed at the clause level, one wants to know whether the property survives negation, conjunction, or any other syntactic embedding. [Horton 87] has a result for projection of presuppositions, which may be generalizable. The other relevant work is [Hirschberg 85] and [Gazdar 79]. Plan recognition for discourse, and the processing of cue words, are related areas. 5. Conclusion To determine what an agent is doing by making an utterance, we must make use of not only general reasoning about actions in context, but also the linguistic features which by convention are associated with specific speech act types. To do this, we match patterns of linguistic features as part of the standard linguistic processing. The resulting partial interpretations are merged, and then filtered by determining the plausibility of their conversational implicatures. Assuming no errors on the part of the speaker, the final interpretation is constrained to lie within the range so specified. If there is not a plausible interpretation, full plan reasoning is called to determine the speaker&apos;s intentions. Remaining ambiguity is not a problem but simply a more complex basis for the hearer&apos;s planning processes. Linguistic patterns and plan reasoning together constrain speech act interpretation sufficiently for discourse purposes.</abstract>
<note confidence="0.970177783783784">Acknowledgements This work was supported in part by NSF research grants no. DCR-8502481, IST-8504726, and US Army Engineering Topographic Laboratories research contract no. DACA76-85-C-0001. References [Allen 83] Allen, J., &amp;quot;Recognizing Intentions From Language Utterances,&amp;quot; in of Discourse, M. and Berwick, B. (ed.), MIT Press, Cambridge, MA, 1983, 107-166. 87] Allen, Natural Language Cummings Publishing Co., 1987. 62] Austin, J. L., to Do Things with University Press, Cambridge, MA, 1962. [Brown 80] Brown, G. P., &amp;quot;Characterizing Indirect Acts,&amp;quot; Journal of Computational July-December 1980, 150-166. [Clark 88] Clark, H., Collective Actions in Language Use, Invited Talk, September 21, 1988. 79] Gazdar, G., Implicative, and Logical Form, Press, New York, 1979. [Gibbs 84] Gibbs, R., &amp;quot;Literal Meaning and Theory,&amp;quot; Science 8, 275-304. [Gordon 75] Gordon, D. and Lakoff, G., Postulates,&amp;quot; Syntax and Semantics 3, P. and Morgan, J. L. (ed.), Academic Press, New York, 1975. [Hinkelman 87] Hinkelman, E., &amp;quot;Thesis Proposal: A Plan-Based Approach to Conversational Implicature,&amp;quot; TR 202, Dept. Computer Science, University of Rochester, June 1987. [Hirschberg 85] Hirschberg, J., &amp;quot;A Theory of Scalar of Implicature,&amp;quot; MS-CIS-85-56, PhD Thesis,</note>
<affiliation confidence="0.930582">Department of Computer and Information Science,</affiliation>
<note confidence="0.956401580645161">University of Pennsylvania, December 1985. [Horn 84] Horn, L. R. and Bayer, S., Short-Circuited Implicature: A Negative Contribution, Vol. 7, 1984. [Horton 87] Horton, D. L., &amp;quot;Incorporating Agents&apos; Beliefs in a Model of Presupposition,&amp;quot; Technical Report CSRI-201, Computer Systems Research Institute, University of Toronto, Toronto, Canada, August 1987. 72] Jackendoff, R. S., in Generative Grammar, Press, Cambridge, 1972. [McCafferty 86] McCafferty, A. S., Explaining Implicatures, 23 October 1986. 87] Miller, B. and Allen, The Rhetorical Knowledge Representation System: A User&apos;s Manual, forthcoming technical report, Department of Computer Science, University of Rochester, 1987. [Perrault 80] Perrault, C. R. and Allen, J. F., &amp;quot;A Plan-Based Analysis of Indirect Speech Acts,&amp;quot; Journal of Computational Linguistics 6:3- 4, July-December 1980, 167-82. 69] Searle, J., in Acts, University Press, New York, 1969. 75] Searle, J., &amp;quot;Indirect Speech Acts,&amp;quot; and Semantics, v3: Speech Acts, and Morgan (ed.), Academic Press, New York, NY, 1975. [Sidner 81] Sidner, C. L. and Israel, D. J., &amp;quot;Recognizing Intended , Meaning and Speakers&apos; IJCAI &apos;81, 203-208. 219</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Allen</author>
</authors>
<title>Recognizing Intentions From Natural Language Utterances,&amp;quot;</title>
<date>1983</date>
<booktitle>in Computational Models of Discourse,</booktitle>
<pages>107--166</pages>
<editor>Brady, M. and Berwick, B. (ed.),</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA,</location>
<marker>[Allen 83]</marker>
<rawString>Allen, J., &amp;quot;Recognizing Intentions From Natural Language Utterances,&amp;quot; in Computational Models of Discourse, Brady, M. and Berwick, B. (ed.), MIT Press, Cambridge, MA, 1983, 107-166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Allen</author>
</authors>
<title>Natural Language Understanding,</title>
<date>1987</date>
<publisher>Cummings Publishing Co.,</publisher>
<location>Benjamin</location>
<marker>[Allen 87]</marker>
<rawString>Allen, J., Natural Language Understanding, Benjamin Cummings Publishing Co., 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Austin</author>
</authors>
<title>How to Do Things with Words,</title>
<date>1962</date>
<publisher>Harvard University Press,</publisher>
<location>Cambridge, MA,</location>
<marker>[Austin 62]</marker>
<rawString>Austin, J. L., How to Do Things with Words, Harvard University Press, Cambridge, MA, 1962.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G P Brown</author>
</authors>
<title>Characterizing Indirect Speech Acts,&amp;quot;</title>
<date>1980</date>
<journal>American Journal of Computational Linguistics</journal>
<pages>6--3</pages>
<marker>[Brown 80]</marker>
<rawString>Brown, G. P., &amp;quot;Characterizing Indirect Speech Acts,&amp;quot; American Journal of Computational Linguistics 6:3-4, July-December 1980, 150-166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Clark</author>
</authors>
<title>Collective Actions in Language Use,</title>
<date>1988</date>
<location>Invited Talk,</location>
<marker>[Clark 88]</marker>
<rawString>Clark, H., Collective Actions in Language Use, Invited Talk, September 21, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gazdar</author>
</authors>
<title>Pragmatics: Implicative, Presupposition and Logical Form,</title>
<date>1979</date>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<marker>[Gazdar 79]</marker>
<rawString>Gazdar, G., Pragmatics: Implicative, Presupposition and Logical Form, Academic Press, New York, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Gibbs</author>
</authors>
<title>Literal Meaning and Psychological Theory,&amp;quot;</title>
<date>1984</date>
<journal>Cognitive Science</journal>
<volume>8</volume>
<pages>275--304</pages>
<marker>[Gibbs 84]</marker>
<rawString>Gibbs, R., &amp;quot;Literal Meaning and Psychological Theory,&amp;quot; Cognitive Science 8, 1984, 275-304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gordon</author>
<author>G Lakoff</author>
</authors>
<title>Conversational Postulates,&amp;quot;</title>
<date>1975</date>
<booktitle>in Syntax and Semantics V.</booktitle>
<editor>3, Cole, P. and Morgan, J. L. (ed.),</editor>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<marker>[Gordon 75]</marker>
<rawString>Gordon, D. and Lakoff, G., &amp;quot;Conversational Postulates,&amp;quot; in Syntax and Semantics V. 3, Cole, P. and Morgan, J. L. (ed.), Academic Press, New York, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hinkelman</author>
</authors>
<title>Thesis Proposal: A Plan-Based Approach to Conversational Implicature,&amp;quot;</title>
<date>1987</date>
<tech>TR 202,</tech>
<institution>Dept. Computer Science, University of Rochester,</institution>
<marker>[Hinkelman 87]</marker>
<rawString>Hinkelman, E., &amp;quot;Thesis Proposal: A Plan-Based Approach to Conversational Implicature,&amp;quot; TR 202, Dept. Computer Science, University of Rochester, June 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hirschberg</author>
</authors>
<title>A Theory of Scalar of Implicature,&amp;quot;</title>
<date>1985</date>
<tech>MS-CIS-85-56, PhD Thesis,</tech>
<institution>Department of Computer and Information Science, University of Pennsylvania,</institution>
<marker>[Hirschberg 85]</marker>
<rawString>Hirschberg, J., &amp;quot;A Theory of Scalar of Implicature,&amp;quot; MS-CIS-85-56, PhD Thesis, Department of Computer and Information Science, University of Pennsylvania, December 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L R Horn</author>
<author>S Bayer</author>
</authors>
<title>Short-Circuited Implicature:</title>
<date>1984</date>
<journal>A Negative Contribution,</journal>
<volume>7</volume>
<marker>[Horn 84]</marker>
<rawString>Horn, L. R. and Bayer, S., Short-Circuited Implicature: A Negative Contribution, Vol. 7, 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D L Horton</author>
</authors>
<title>Incorporating Agents&apos; Beliefs in a Model of Presupposition,&amp;quot;</title>
<date>1987</date>
<tech>Technical Report CSRI-201,</tech>
<institution>Computer Systems Research Institute, University of Toronto,</institution>
<location>Toronto, Canada,</location>
<marker>[Horton 87]</marker>
<rawString>Horton, D. L., &amp;quot;Incorporating Agents&apos; Beliefs in a Model of Presupposition,&amp;quot; Technical Report CSRI-201, Computer Systems Research Institute, University of Toronto, Toronto, Canada, August 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R S Jackendoff</author>
</authors>
<title>Semantic Interpretation in Generative Grammar,</title>
<date>1972</date>
<publisher>MIT Press,</publisher>
<location>Cambridge,</location>
<marker>[Jackendoff 72]</marker>
<rawString>Jackendoff, R. S., Semantic Interpretation in Generative Grammar, MIT Press, Cambridge, 1972.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A S McCafferty</author>
</authors>
<title>Explaining Implicatures,</title>
<date>1986</date>
<marker>[McCafferty 86]</marker>
<rawString>McCafferty, A. S., Explaining Implicatures, 23 October 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Miller</author>
<author>J Allen</author>
</authors>
<title>The Rhetorical Knowledge Representation System: A User&apos;s Manual, forthcoming technical report,</title>
<date>1987</date>
<institution>Department of Computer Science, University of Rochester,</institution>
<marker>[Miller 87]</marker>
<rawString>Miller, B. and Allen, J., The Rhetorical Knowledge Representation System: A User&apos;s Manual, forthcoming technical report, Department of Computer Science, University of Rochester, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C R Perrault</author>
<author>J F Allen</author>
</authors>
<title>A Plan-Based Analysis of Indirect Speech Acts,&amp;quot;</title>
<date>1980</date>
<journal>American Journal of Computational Linguistics</journal>
<pages>6--3</pages>
<marker>[Perrault 80]</marker>
<rawString>Perrault, C. R. and Allen, J. F., &amp;quot;A Plan-Based Analysis of Indirect Speech Acts,&amp;quot; American Journal of Computational Linguistics 6:3-4, July-December 1980, 167-82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Searle</author>
</authors>
<title>in Speech Acts,</title>
<date>1969</date>
<publisher>Cambridge University Press,</publisher>
<location>New York,</location>
<marker>[Searle 69]</marker>
<rawString>Searle, J., in Speech Acts, Cambridge University Press, New York, 1969.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Searle</author>
</authors>
<title>Indirect Speech Acts,&amp;quot;</title>
<date>1975</date>
<booktitle>in Syntax and Semantics, v3: Speech Acts, Cole and</booktitle>
<editor>Morgan (ed.),</editor>
<publisher>Academic Press,</publisher>
<location>New York, NY,</location>
<marker>[Searle 75]</marker>
<rawString>Searle, J., &amp;quot;Indirect Speech Acts,&amp;quot; in Syntax and Semantics, v3: Speech Acts, Cole and Morgan (ed.), Academic Press, New York, NY, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Sidner</author>
<author>D J Israel</author>
</authors>
<title>Recognizing Intended , Meaning and Speakers&apos; Plans,&amp;quot;</title>
<date>1981</date>
<booktitle>Proc. IJCAI &apos;81,</booktitle>
<pages>203--208</pages>
<marker>[Sidner 81]</marker>
<rawString>Sidner, C. L. and Israel, D. J., &amp;quot;Recognizing Intended , Meaning and Speakers&apos; Plans,&amp;quot; Proc. IJCAI &apos;81, 1981, 203-208.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>