<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000029">
<title confidence="0.9294315">
Using Syntax to Improve Word Alignment Precision for Syntax-Based
Machine Translation
</title>
<author confidence="0.997316">
Victoria Fossum
</author>
<affiliation confidence="0.998314">
Dept. of Computer Science
University of Michigan
</affiliation>
<address confidence="0.98683">
Ann Arbor, MI 48104
</address>
<email confidence="0.998822">
vfossum@umich.edu
</email>
<author confidence="0.998209">
Kevin Knight
</author>
<affiliation confidence="0.838938">
Information Sciences Institute
University of Southern California
Marina del Rey, CA 90292
</affiliation>
<email confidence="0.995404">
knight@isi.edu
</email>
<author confidence="0.99742">
Steven Abney
</author>
<affiliation confidence="0.9980995">
Dept. of Linguistics
University of Michigan
</affiliation>
<address confidence="0.986874">
Ann Arbor, MI 48104
</address>
<email confidence="0.999196">
abney@umich.edu
</email>
<sectionHeader confidence="0.998545" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.992344454545454">
Word alignments that violate syntactic cor-
respondences interfere with the extraction
of string-to-tree transducer rules for syntax-
based machine translation. We present an
algorithm for identifying and deleting incor-
rect word alignment links, using features of
the extracted rules. We obtain gains in both
alignment quality and translation quality in
Chinese-English and Arabic-English transla-
tion experiments relative to a GIZA++ union
baseline.
</bodyText>
<sectionHeader confidence="0.999302" genericHeader="introduction">
1 Introduction
</sectionHeader>
<subsectionHeader confidence="0.972899">
1.1 Motivation
</subsectionHeader>
<bodyText confidence="0.999912229166667">
Word alignment typically constitutes the first stage
of the statistical machine translation pipeline.
GIZA++ (Och and Ney, 2003), an implementation
of the IBM (Brown et al., 1993) and HMM (?)
alignment models, is the most widely-used align-
ment system. GIZA++ union alignments have been
used in the state-of-the-art syntax-based statistical
MT system described in (Galley et al., 2006) and in
the hierarchical phrase-based system Hiero (Chiang,
2007). GIZA++ refined alignments have been used
in state-of-the-art phrase-based statistical MT sys-
tems such as (Och, 2004); variations on the refined
heuristic have been used by (Koehn et al., 2003)
(diag and diag-and) and by the phrase-based system
Moses (grow-diag-final) (Koehn et al., 2007).
GIZA++ union alignments have high recall but
low precision, while intersection or refined align-
ments have high precision but low recall.1 There are
two natural approaches to improving upon GIZA++
alignments, then: deleting links from union align-
ments, or adding links to intersection or refined
alignments. In this work, we delete links from
GIZA++ union alignments to improve precision.
The low precision of GIZA++ union alignments
poses a particular problem for syntax-based rule ex-
traction algorithms such as (Quirk et al., 2005; Gal-
ley et al., 2006; Huang et al., 2006; Liu et al.,
2006): if the incorrect links violate syntactic corre-
spondences, they force the rule extraction algorithm
to extract rules that are large in size, few in number,
and poor in generalization ability.
Figure 1 illustrates this problem: the dotted line
represents an incorrect link in the GIZA++ union
alignment. Using the rule extraction algorithm de-
scribed in (Galley et al., 2004), we extract the rules
shown in the leftmost column (R1–R4). Rule R1 is
large and unlikely to generalize well. If we delete
the incorrect link in Figure 1, we can extract the
rules shown in the rightmost column (R2–R9): Rule
R1, the largest rule from the initial set, disappears,
and several smaller, more modular rules (R5–R9) re-
place it.
In this work, we present a supervised algorithm
that uses these two features of the extracted rules
(size of largest rule and total number of rules), as
well as a handful of structural and lexical features,
to automatically identify and delete incorrect links
from GIZA++ union alignments. We show that link
</bodyText>
<footnote confidence="0.955087333333333">
1For a complete discussion of alignment symmetrization
heuristics, including union, intersection, and refined, refer to
(Och and Ney, 2003).
</footnote>
<page confidence="0.984649">
44
</page>
<note confidence="0.734893">
Proceedings of the Third Workshop on Statistical Machine Translation, pages 44–52,
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</note>
<figure confidence="0.915379469879518">
VP
� �� �� ��
FROM OWN-COUNTRY NEEDS STARTS-OUT
VBZ
starts
PRT
RP
out
from
IN
DT
the
NP
PP
NNS
needs
NP
IN
of
PRP
its
PP
own
JJ
NP
NN
country
Rules Extracted Using GIZA++ Union Alignments
Rules Extracted After Deleting Dotted Link
R1: VP
→x0 x1xg�`hyQ
R2: IN →K
from
R3: PP → x0
IN x0:NP
of
R4: NP →��
R2: IN
from
R3: PP
→�
→ x0
VBZ
starts
PRT
RP
out
PP
x0:IN NP
x1:PP
NP
DT
the
NNS
needs
own
JJ
IN
of
x0:NP
PRP
its
NN
country
R5: PP
x0:IN x1:NP
R6: NP
x0:NP x1:PP
→ x1 x0
→x0 x1
R7: NP → x0
DT x0:NNS
the
R8: NNS →��
needs
R9: VP
→ x0LhYQ
x0:PP
PRT
RP
out
VBZ
starts
</figure>
<figureCaption confidence="0.8946946">
Figure 1: The impact of incorrect alignment links upon rule extraction. Using the original alignment (including all
links shown) leads to the extraction of the tree-to-string transducer rules whose left hand sides are rooted at the solid
boxed nodes in the parse tree (R1, R2, R3, and R4). Deleting the dotted alignment link leads to the omission of rule
R1, the extraction of R9 in its place, the extraction of R2, R3, and R4 as before, and the extraction of additional rules
whose left hand sides are rooted at the dotted boxed nodes in the parse tree (R5, R6, R7, R8).
</figureCaption>
<figure confidence="0.707741857142857">
R4: NP →��
PRP
its
JJ
own
NN
country
</figure>
<page confidence="0.99604">
45
</page>
<bodyText confidence="0.9998335">
deletion improves alignment quality and translation
quality in Chinese-English and Arabic-English MT,
relative to a strong baseline. Our link deletion al-
gorithm is easy to implement, runs quickly, and has
been used by a top-scoring MT system in the Chi-
nese newswire track of the 2008 NIST evaluation.
</bodyText>
<sectionHeader confidence="0.75361" genericHeader="related work">
1.2 Related Work
</sectionHeader>
<bodyText confidence="0.999809122807018">
Recently, discriminative methods for alignment
have rivaled the quality of IBM Model 4 alignments
(Liu et al., 2005; Ittycheriah and Roukos, 2005;
Taskar et al., 2005; Moore et al., 2006; Fraser and
Marcu, 2007b). However, except for (Fraser and
Marcu, 2007b), none of these advances in align-
ment quality has improved translation quality of a
state-of-the-art system. We use a discriminatively
trained model to identify and delete incorrect links,
and demonstrate that these gains in alignment qual-
ity lead to gains in translation quality in a state-
of-the-art syntax-based MT system. In contrast to
the semi-supervised LEAF alignment algorithm of
(Fraser and Marcu, 2007b), which requires 1,500-
2,000 CPU days per iteration to align 8.4M Chinese-
English sentences (anonymous, p.c.), link deletion
requires only 450 CPU hours to re-align such a cor-
pus (after initial alignment by GIZA++, which re-
quires 20-24 CPU days).
Several recent works incorporate syntactic fea-
tures into alignment. (May and Knight, 2007) use
syntactic constraints to re-align a parallel corpus that
has been aligned by GIZA++ as follows: they extract
string-to-tree transducer rules from the corpus, the
target parse trees, and the alignment; discard the ini-
tial alignment; use the extracted rules to construct a
forest of possible string-to-tree derivations for each
string/tree pair in the corpus; use EM to select the
Viterbi derivation tree for each pair; and finally, in-
duce a new alignment from the Viterbi derivations,
using the re-aligned corpus to train a syntax-based
MT system. (May and Knight, 2007) differs from
our approach in two ways: first, the set of possible
re-alignments they consider for each sentence pair is
limited by the initial GIZA++ alignments seen over
the training corpus, while we consider all alignments
that can be reached by deleting links from the ini-
tial GIZA++ alignment for that sentence pair. Sec-
ond, (May and Knight, 2007) use a time-intensive
training algorithm to select the best re-alignment
for each sentence pair, while we use a fast greedy
search to determine which links to delete; in con-
trast to (May and Knight, 2007), who require 400
CPU hours to re-align 330k Chinese-English sen-
tence pairs (anonymous, p.c), link deletion requires
only 18 CPU hours to re-align such a corpus.
(Lopez and Resnik, 2005) and (Denero and Klein,
2007) modify the distortion model of the HMM
alignment model (Vogel et al., 1996) to reflect tree
distance rather than string distance; (Cherry and
Lin, 2006) modify an ITG aligner by introducing
a penalty for induced parses that violate syntac-
tic bracketing constraints. Similarly to these ap-
proaches, we use syntactic bracketing to constrain
alignment, but our work extends beyond improving
alignment quality to improve translation quality as
well.
</bodyText>
<sectionHeader confidence="0.951495" genericHeader="method">
2 Link Deletion
</sectionHeader>
<bodyText confidence="0.99989825">
We propose an algorithm to re-align a parallel bitext
that has been aligned by GIZA++ (IBM Model 4),
then symmetrized using the union heuristic. We then
train a syntax-based translation system on the re-
aligned bitext, and evaluate whether the re-aligned
bitext yields a better translation model than a base-
line system trained on the GIZA++ union aligned
bitext.
</bodyText>
<subsectionHeader confidence="0.99713">
2.1 Link Deletion Algorithm
</subsectionHeader>
<bodyText confidence="0.999451111111111">
Our algorithm for re-alignment proceeds as follows.
We make a single pass over the corpus. For each sen-
tence pair, we initialize the alignment A = Ainitial
(the GIZA++ union alignment for that sentence
pair). We represent the score of A as a weighted
linear combination of features hi of the alignment
A, the target parse tree parse(e) (a phrase-structure
syntactic representation of e), and the source string
f:
</bodyText>
<equation confidence="0.941002">
n
score(A) = E Ai · hi(A, parse(e), f)
i=0
</equation>
<bodyText confidence="0.999199">
We define a branch of links to be a contiguous 1-
to-many alignment.2 We define two alignments, A
</bodyText>
<footnote confidence="0.55203825">
2In Figure 1, the 1-to-many alignment formed by { * Q-
its, * Q- own,* Q-country} constitutes a branch, but the
1-to-many alignment formed by { ii; &amp;-starts, ii; &amp;-out,ii;&amp;-
needs} does not.
</footnote>
<page confidence="0.997914">
46
</page>
<bodyText confidence="0.999650444444445">
and A′, to be neighbors if they differ only by the
deletion of a link or branch of links. We consider all
alignments A′ in the neighborhood of A, greedily
deleting the link l or branch of links b maximizing
the score of the resulting alignment A′ = A \ l or
A′ = A \ b. We delete links until no further increase
in the score of A is possible.3
In section 2.2 we describe the features hi, and in
section 2.4 we describe how to set the weights Ai.
</bodyText>
<subsectionHeader confidence="0.933027">
2.2 Features
</subsectionHeader>
<subsubsectionHeader confidence="0.508872">
2.2.1 Syntactic Features
</subsubsectionHeader>
<bodyText confidence="0.9706702">
We use two features of the string-to-tree trans-
ducer rules extracted from A, parse(e), and f ac-
cording to the rule extraction algorithm described in
(Galley et al., 2004):
ruleCount: Total number of rules extracted from
A, parse(e), and f. As Figure 1 illustrates, in-
correct links violating syntactic brackets tend to de-
crease ruleCount; ruleCount increases from 4 to 8
after deleting the incorrect link.
sizeOfLargestRule: The size, measured in terms
of internal nodes in the target parse tree, of the single
largest rule extracted from A, parse(e), and f. In
Figure 1, the largest rules in the leftmost and right-
most columns are R1 (with 9 internal nodes) and R9
(with 4 internal nodes), respectively.
</bodyText>
<subsubsectionHeader confidence="0.80165">
2.2.2 Structural Features
</subsubsectionHeader>
<bodyText confidence="0.998462166666667">
wordsUnaligned: Total number of unaligned
words.
1-to-many Links: Total number of links for which
one word is aligned to multiple words, in either di-
rection. In Figure 1, the links {ffla-starts,fflA-
out,fflA-needs} represent a 1-to-many alignment.
1-to-many links appear more frequently in GIZA++
union alignments than in gold alignments, and are
therefore good candidates for deletion. The cate-
gory of 1-to-many links is further subdivided, de-
pending on the degree of contiguity that the link ex-
hibits with its neighbors.4 Each link in a 1-to-many
</bodyText>
<footnote confidence="0.979107333333333">
3While using a dynamic programming algorithm would
likely improve search efficiency and allow link deletion to find
an optimal solution, in practice, the greedy search runs quickly
and improves alignment quality.
4(Deng and Byrne, 2005) observe that, in a manually aligned
Chinese-English corpus, 82% of the Chinese words that are
</footnote>
<bodyText confidence="0.974119">
alignment can have 0, 1, or 2 neighbors, according
to how many links are adjacent to it in the 1-to-many
alignment:
zeroNeighbors: In Figure 1, the linkffla-needs
has 0 neighbors.
oneNeighbor: In Figure 1, the linksffla-starts
andffla-out each have 1 neighbor–namely, each
other.
twoNeighbors: In Figure 1, in the 1-to-many
alignment formed by {* )-its,* )-own,* )-
country}, the link * )-own has 2 neighbors,
namely *)-it and *)-country.
</bodyText>
<subsubsectionHeader confidence="0.683639">
2.2.3 Lexical Features
</subsubsectionHeader>
<bodyText confidence="0.999516214285714">
highestLexProbRank: A link ei-fj is “max-
probable from ei to fj” if p(fj|ei) &gt; p(fj′|ei) for
all alternative words fj′ with which ei is aligned
in Ainitial. In Figure 1, p(M W  |needs) &gt; p(ffl
a |needs), so M W-needs is max-probable for
“needs”. The definition of “max-probable from fj to
ei” is analogous, and a link is max-probable (nondi-
rectionally) if it is max-probable in either direction.
The value of highestLexProbRank is the total num-
ber of max-probable links. The conditional lexical
probabilities p(ei|fj) and p(fj|ei) are estimated us-
ing frequencies of aligned word pairs in the high-
precision GIZA++ intersection alignments for the
training corpus.
</bodyText>
<subsubsectionHeader confidence="0.676207">
2.2.4 History Features
</subsubsectionHeader>
<bodyText confidence="0.7022186">
In addition to the above syntactic, structural,
and lexical features of A, we also incorporate
two features of the link deletion history itself into
5core(A):
linksDeleted: Total number of links deleted
Ainitial thus far. At each iteration, either a link or
a branch of links is deleted.
aligned to multiple English words are aligned to a contiguous
block of English words; similarly, 88% of the English words
that are aligned to multiple Chinese words are aligned to a con-
tiguous block of Chinese words. Thus, if a Chinese word is cor-
rectly aligned to multiple English words, those English words
are likely to be “neighbors” of each other, and if an English
word is correctly aligned to multiple Chinese words, those Chi-
nese words are likely to be “neighbors” of each other.
</bodyText>
<page confidence="0.997774">
47
</page>
<bodyText confidence="0.999521">
stepsTaken: Total number of iterations thus far in
the search; at each iteration, either a link or a branch
is deleted. This feature serves as a constant cost
function per step taken during link deletion.
</bodyText>
<subsectionHeader confidence="0.982311">
2.3 Constraints
</subsectionHeader>
<bodyText confidence="0.993949733333333">
Protecting Refined Links from Deletion: Since
GIZA++ refined links have higher precision than
union links5, we do not consider any GIZA++ re-
fined links for deletion.6
Stoplist: In our Chinese-English corpora, the 10
most common English words (excluding punc-
tuation marks) include {a,in,to,of,and,the}, while
the 10 most common Chinese words include
{_f,a,AL,TH,A}. Of these, {a,the} and {f,A}
have no explicit translational equivalent in the other
language. These words are aligned with each other
frequently (and erroneously) by GIZA++ union, but
rarely in the gold standard. We delete all links in
the set {a, an, the} x { in, , _f } from Ainitial as a
preprocessing step.7
</bodyText>
<subsectionHeader confidence="0.994969">
2.4 Perceptron Training
</subsectionHeader>
<bodyText confidence="0.9283043">
We set the feature weights A using a modified ver-
sion of averaged perceptron learning with structured
outputs (Collins, 2002). Following (Moore, 2005),
we initialize the value of our expected most infor-
mative feature (ruleCount) to 1.0, and initialize all
other feature weights to 0. During each pass over the
discriminative training set, we “decode” each sen-
tence pair by greedily deleting links from Ainitial in
order to maximize the score of the resulting align-
ment using the current settings of A (for details, refer
to section 2.1).
5On a 400-sentence-pair Chinese-English data set, GIZA++
union alignments have a precision of 77.32 while GIZA++ re-
fined alignments have a precision of 85.26.
6To see how GIZA++ refined alignments compare to
GIZA++ union alignments for syntax-based translation, we
compare systems trained on each set of alignments for Chinese-
English translation task A. Union alignments result in a test set
BLEU score of 41.17, as compared to only 36.99 for refined.
7The impact upon alignment f-measure of deleting these
stoplist links is small; on Chinese-English Data Set A, the f-
measure of the baseline GIZA++ union alignments on the test
set increases from 63.44 to 63.81 after deleting stoplist links,
while the remaining increase in f-measure from 63.81 to 75.14
(shown in Table 3) is due to the link deletion algorithm itself.
We construct a set of candidate alignments
Acandidates for use in reranking as follows. Starting
with A = Ainitial, we iteratively explore all align-
ments A′ in the neighborhood of A, adding each
neighbor to Acandidates, then selecting the neigh-
bor that maximizes Score(A′). When it is no
longer possible to increase Score(A) by deleting
any links, link deletion concludes and returns the
highest-scoring alignment, A1-best.
In general, Agold V Acandidates; following
(Collins, 2000) and (Charniak and Johnson, 2005)
for parse reranking and (Liang et al., 2006) for trans-
lation reranking, we define Aoracle as alignment in
Acandidates that is most similar to Agold.8 We up-
date each feature weight Ai as follows: Ai = Ai +
</bodyText>
<equation confidence="0.937848">
hAoracle _ hAl-best .9
i i
</equation>
<bodyText confidence="0.9999903">
Following (Moore, 2005), after each training
pass, we average all the feature weight vectors seen
during the pass, and decode the discriminative train-
ing set using the vector of averaged feature weights.
When alignment quality stops increasing on the dis-
criminative training set, perceptron training ends.10
The weight vector returned by perceptron training is
the average over the training set of all weight vectors
seen during all iterations; averaging reduces overfit-
ting on the training set (Collins, 2002).
</bodyText>
<sectionHeader confidence="0.998294" genericHeader="method">
3 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.996102">
3.1 Data Sets
</subsectionHeader>
<bodyText confidence="0.998915818181818">
We evaluate the effect of link deletion upon align-
ment quality and translation quality for two Chinese-
English data sets, and one Arabic-English data set.
Each data set consists of newswire, and contains a
small subset of manually aligned sentence pairs. We
divide the manually aligned subset into a training set
(used to discriminatively set the feature weights for
link deletion) and a test set (used to evaluate the im-
pact of link deletion upon alignment quality). Table
1 lists the source and the size of the manually aligned
training and test sets used for each alignment task.
</bodyText>
<footnote confidence="0.993864">
8We discuss alignment similarity metrics in detail in Section
3.2.
9(Liang et al., 2006) report that, for translation reranking,
such local updates (towards the oracle) outperform bold updates
(towards the gold standard).
10We discuss alignment quality metrics in detail in Section
3.2.
</footnote>
<page confidence="0.999412">
48
</page>
<bodyText confidence="0.993207222222222">
Using the feature weights learned on the manually
aligned training set, we then apply link deletion to
the remainder (non-manually aligned) of each bilin-
gual data set, and train a full syntax-based statistical
MT system on these sentence pairs. After maximum
BLEU tuning (Och, 2003a) on a held-out tuning set,
we evaluate translation quality on a held-out test set.
Table 2 lists the source and the size of the training,
tuning, and test sets used for each translation task.
</bodyText>
<subsectionHeader confidence="0.997513">
3.2 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.999904827586207">
AER (Alignment Error Rate) (Och and Ney, 2003)
is the most widely used metric of alignment qual-
ity, but requires gold-standard alignments labelled
with “sure/possible” annotations to compute; lack-
ing such annotations, we can compute alignment f-
measure instead.
However, (Fraser and Marcu, 2007a) show that,
in phrase-based translation, improvements in AER
or f-measure do not necessarily correlate with im-
provements in BLEU score. They propose two mod-
ifications to f-measure: varying the precision/recall
tradeoff, and fully-connecting the alignment links
before computing f-measure.11
Weighted Fully-Connected F-Measure Given a
hypothesized set of alignment links H and a gold-
standard set of alignment links G, we define H+ =
fullyConnect(H) and G+ = fullyConnect(G),
and then compute:
For phrase-based Chinese-English and Arabic-
English translation tasks, (Fraser and Marcu, 2007a)
obtain the closest correlation between weighted
fully-connected alignment f-measure and BLEU
score using a=0.5 and a=0.1, respectively. We
use weighted fully-connected alignment f-measure
as the training criterion for link deletion, and to eval-
uate alignment quality on training and test sets.
Rule F-Measure To evaluate the impact of link
deletion upon rule quality, we compare the rule pre-
cision, recall, and f-measure of the rule set extracted
</bodyText>
<footnote confidence="0.5734015">
11In Figure 1, the fully-connected version of the alignments
shown would include the linksr -starts andr - out.
</footnote>
<table confidence="0.99827475">
Language Train Test
Chinese-English A 400 400
Chinese-English B 1500 1500
Arabic-English 1500 1500
</table>
<tableCaption confidence="0.9856545">
Table 1: Size (sentence pairs) of data sets used in align-
ment link deletion tasks
</tableCaption>
<bodyText confidence="0.9418665">
from our hypothesized alignments and a Collins-
style parser against the rule set extracted from gold
alignments and gold parses.
BLEU For all translation tasks, we report case-
insensitive NIST BLEU scores (Papineni et al.,
2002) using 4 references per sentence.
</bodyText>
<subsectionHeader confidence="0.97794">
3.3 Experiments
</subsectionHeader>
<bodyText confidence="0.999994516129032">
Starting with GIZA++ union (IBM Model 4) align-
ments, we use perceptron training to set the weights
of each feature used in link deletion in order to opti-
mize weighted fully-connected alignment f-measure
(a=0.5 for Chinese-English and a=0.1 for Arabic-
English) on a manually aligned discriminative train-
ing set. We report the (fully-connected) precision,
recall, and weighted alignment f-measure on a held-
out test set after running perceptron training, relative
to the baseline GIZA++ union alignments. Using
the learned feature weights, we then perform link
deletion over the GIZA++ union alignments for the
entire training corpus for each translation task. Us-
ing these alignments, which we refer to as “GIZA++
union + link deletion”, we train a syntax-based trans-
lation system similar to that described in (Galley et
al., 2006). After extracting string-to-tree translation
rules from the aligned, parsed training corpus, the
system assigns weights to each rule via frequency
estimation with smoothing. The rule probabilities,
as well as trigram language model probabilities and
a handful of additional features of each rule, are used
as features during decoding. The feature weights are
tuned using minimum error rate training (Och and
Ney, 2003) to optimize BLEU score on a held-out
development set. We then compare the BLEU score
of this system against a baseline system trained us-
ing GIZA++ union alignments.
To determine which value of a is most effective
as a training criterion for link deletion, we set a=0.4
(favoring recall), 0.5, and 0.6 (favoring precision),
</bodyText>
<equation confidence="0.9946524">
1
f-measure(H+) =
precision(H+) + �−�
�
recall(H+)
</equation>
<page confidence="0.99717">
49
</page>
<table confidence="0.99932975">
Language Train Tune Test1 Test2
Chinese-English A 9.8M/newswire 25.9k/NIST02 29.0k/NIST03 –
Chinese-English B 12.3M/newswire 42.9k/newswire 42.1k/newswire –
Arabic-English 174.8M/newswire 35.8k/NIST04-05 40.3k/NIST04-05 53.0k/newswire
</table>
<tableCaption confidence="0.999573">
Table 2: Size (English words) and source of data sets used in translation tasks
</tableCaption>
<bodyText confidence="0.918733">
and compare the effect on translation quality for
Chinese-English data set A.
</bodyText>
<sectionHeader confidence="0.999869" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999884">
For each translation task, link deletion improves
translation quality relative to a GIZA++ union base-
line. For each alignment task, link deletion tends to
improve fully-connected alignment precision more
than it decreases fully-connected alignment recall,
increasing weighted fully-connected alignment f-
measure overall.
</bodyText>
<subsectionHeader confidence="0.999137">
4.1 Chinese-English
</subsectionHeader>
<bodyText confidence="0.999870833333333">
On Chinese-English translation task A, link deletion
increases BLEU score by 1.26 points on tuning and
0.76 points on test (Table 3); on Chinese-English
translation task B, link deletion increases BLEU
score by 1.38 points on tuning and 0.49 points on
test (Table 3).
</bodyText>
<subsectionHeader confidence="0.998959">
4.2 Arabic-English
</subsectionHeader>
<bodyText confidence="0.999974133333334">
On the Arabic-English translation task, link dele-
tion improves BLEU score by 0.84 points on tuning,
0.18 points on test1, and 0.56 points on test2 (Ta-
ble 3). Note that the training criterion for Arabic-
English link deletion uses α=0.1; because this pe-
nalizes a loss in recall more heavily than it re-
wards an increase in precision, it is more difficult
to increase weighted fully-connected alignment f-
measure using link deletion for Arabic-English than
for Chinese-English. This difference is reflected in
the average number of links deleted per sentence:
4.19 for Chinese-English B (Table 3), but only 1.35
for Arabic-English (Table 3). Despite this differ-
ence, link deletion improves translation results for
Arabic-English as well.
</bodyText>
<subsectionHeader confidence="0.98524">
4.3 Varying α
</subsectionHeader>
<bodyText confidence="0.989111">
On Chinese-English data set A, we explore the ef-
fect of varying α in the weighted fully-connected
</bodyText>
<subsectionHeader confidence="0.31853">
Training Sentence Pairs
</subsectionHeader>
<figureCaption confidence="0.9878585">
Figure 2: Effect of discriminative training set size on link
deletion accuracy for Chinese-English B, α=0.5
</figureCaption>
<bodyText confidence="0.9992508">
alignment f-measure used as the training criterion
for link deletion. Using α=0.5 leads to a higher gain
in BLEU score on the test set relative to the base-
line (+0.76 points) than either α=0.4 (+0.70 points)
or α=0.6 (+0.67 points).
</bodyText>
<subsectionHeader confidence="0.998941">
4.4 Size of Discriminative Training Set
</subsectionHeader>
<bodyText confidence="0.999793">
To examine how many manually aligned sentence
pairs are required to set the feature weights reli-
ably, we vary the size of the discriminative training
set from 2-1500 sentence pairs while holding test
set size constant at 1500 sentence pairs; run per-
ceptron training; and record the resulting weighted
fully-connected alignment f-measure on the test set.
Figure 2 illustrates that using 100-200 manually
aligned sentence pairs of training data is sufficient
for Chinese-English; a similarly-sized training set is
also sufficient for Arabic-English.
</bodyText>
<subsectionHeader confidence="0.999096">
4.5 Effect of Link Deletion on Extracted Rules
</subsectionHeader>
<bodyText confidence="0.998541">
Link deletion increases the size of the extracted
grammar. To determine how the quality of the ex-
tracted grammar changes, we compute the rule pre-
</bodyText>
<figure confidence="0.950132142857143">
64
Test Set Weighted Fully−Connected Alignment F−Measure
GIZA++ union
GIZA++ union + link deletion
46
93 187 375 750 1500
62
60
58
56
54
52
50
48
</figure>
<page confidence="0.939242">
50
</page>
<table confidence="0.99955725">
Language Alignment Prec Rec α F-measure Links Del/ Grammar BLEU
Sent Size Tune Test1 Test2
Chi-Eng A GIZA++ union 54.76 75.38 0.5 63.44 – 23.4M 41.80 41.17 –
Chi-Eng A GIZA++ union + 79.59 71.16 0.5 75.14 4.77 59.7M 43.06 41.93 –
link deletion
Chi-Eng B GIZA++ union 36.61 66.28 0.5 47.16 – 28.9M 39.59 41.39 –
Chi-Eng B GIZA++ union + 65.52 59.28 0.5 62.24 4.19 73.0M 40.97 41.88 –
link deletion
Ara-Eng GIZA++ union 35.34 84.05 0.1 73.87 – 52.4M 54.73 50.9 38.16
Ara-Eng 52.68 79.75 0.1 75.85 1.35 64.9M 55.57 51.08 38.72
GIZA++ union +
link deletion
</table>
<tableCaption confidence="0.999079">
Table 3: Results of link deletion. Weighted fully-connected alignment f-measure is computed on alignment test sets
(Table 1); BLEU score is computed on translation test sets (Table 2).
</tableCaption>
<table confidence="0.999551833333333">
Alignment Parse Precision Recall Rule Total Non-Unique
F-measure
gold gold 100.00 100.00 100.00 12,809
giza++ union collins 50.49 44.23 47.15 11,021
giza++ union+link deletion, α=0.5 collins 47.51 53.20 50.20 13,987
giza++ refined collins 44.20 54.06 48.64 15,182
</table>
<tableCaption confidence="0.999878">
Table 4: Rule precision, recall, and f-measure of rules extracted from 400 sentence pairs of Chinese-English data
</tableCaption>
<bodyText confidence="0.999884166666667">
cision, recall, and f-measure of the GIZA++ union
alignments and various link deletion alignments on
a held-out Chinese-English test set of 400 sentence
pairs. Table 4 indicates the total (non-unique) num-
ber of rules extracted for each alignment/parse pair-
ing, as well as the rule precision, recall, and f-
measure of each pair. As more links are deleted,
more rules are extracted–but of those, some are of
good quality and others are of bad quality. Link-
deleted alignments produce rule sets with higher rule
f-measure than either GIZA++ union or GIZA++ re-
fined.
</bodyText>
<sectionHeader confidence="0.9993" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999966363636364">
We have presented a link deletion algorithm that im-
proves the precision of GIZA++ union alignments
without notably decreasing recall. In addition to lex-
ical and structural features, we use features of the ex-
tracted syntax-based translation rules. Our method
improves alignment quality and translation quality
on Chinese-English and Arabic-English translation
tasks, relative to a GIZA++ union baseline. The
algorithm runs quickly, and is easily applicable to
other language pairs with limited amounts (100-200
sentence pairs) of manually aligned data available.
</bodyText>
<sectionHeader confidence="0.99863" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999977">
We thank Steven DeNeefe and Wei Wang for assis-
tance with experiments, and Alexander Fraser and
Liang Huang for helpful discussions. This research
was supported by DARPA (contract HR0011-06-C-
0022) and by a fellowship from AT&amp;T Labs.
</bodyText>
<page confidence="0.998004">
51
</page>
<sectionHeader confidence="0.996245" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99986084">
Peter F. Brown, Stephen Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. The Mathematics ofSta-
tistical Machine Translation: Parameter Estimation.
Computational Linguistics, Vol. 19, No. 2, 1993.
Eugene Charniak and Mark Johnson. Coarse-to-fine n-
best parsing and MaxEnt discriminative reranking.
Proceedings of ACL, 2005.
Colin Cherry and Dekang Lin. Soft Syntactic Constraints
for Word Alignment through Discriminative Training.
Proceedings of ACL (Poster), 2006.
David Chiang. A Hierarchical Phrase-Based Model for
Statistical Machine Translation. Proceedings of ACL,
2005.
David Chiang. Hierarchical phrase-based translation.
Computational Linguistics, 2007.
Michael Collins. Discriminative Reranking for Natural
Language Parsing. Proceedings of ICML, 2000.
Michael Collins. Discriminative training methods for
hidden Markov models: theory and experiments with
perceptron algorithms. Proceedings of EMNLP,
2002.
John DeNero and Dan Klein. Tailoring Word Align-
ments to Syntactic Machine Translation. Proceedings
of ACL, 2007.
Yonggang Deng and William Byrne. HMM word and
phrase alignment for statistical machine translation.
Proceedings of HLT/EMNLP, 2005.
Alexander Fraser and Daniel Marcu. Measuring Word
Alignment Qualityfor Statistical Machine Translation.
Computational Linguistics, Vol. 33, No. 3, 2007.
Alexander Fraser and Daniel Marcu. Getting the Struc-
ture Rightfor Word Alignment: LEAF. Proceedings of
EMNLP, 2007.
Michel Galley, Mark Hopkins, Kevin Knight, and Daniel
Marcu. What’s in a Translation Rule? Proceedings of
HLT/NAACL-04, 2004.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. Scalable Inference and Training of Context-
Rich Syntactic Translation Models. Proceedings of
ACL, 2006.
Liang Huang, Kevin Knight, and Aravind Joshi. Statis-
tical Syntax-Directed Translation with Extended Do-
main ofLocality. Proceedings of AMTA, 2006.
Abraham Ittycheriah and Salim Roukos. A Maximum En-
tropy Word Alignerfor Arabic-English Machine Trans-
lation. Proceedings of HLT/EMNLP, 2005.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
Statistical Phrase-Based Translation. Proceedings of
HLT/NAACL, 2003.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, Evan Herbst. Moses: Open Source Toolkit for
Statistical Machine Translation. Proceedings of ACL
(demo), 2007.
Percy Liang, Alexandre Bouchard-Cote, Dan Klein, and
Ben Taskar. An end-to-end discriminative approach to
machine translation. Proceedings of COLING/ACL,
2006.
Yang Liu, Qun Liu, and Shouxun Lin. Log-linear Models
for Word Alignment. Proceedings of ACL, 2005.
Yang Liu, Qun Liu, and Shouxun Lin. Tree-to-String
Alignment Template for Statistical Machine Transla-
tion. Proceedings of ACL, 2006.
Adam Lopez and Philip Resnik. Improved HMM Align-
ment Models for Languages with Scarce Resources.
Proceedings of the ACL Workshop on Parallel Text,
2005.
Jonathan May and Kevin Knight. Syntactic Re-Alignment
Models for Machine Translation. Proceedings of
EMNLP-CoNLL, 2007.
Robert C. Moore. A Discriminative Frameworkfor Bilin-
gual Word Alignment. Proceedings of HLT/EMNLP,
2005.
Robert C. Moore, Wen-tau Yih, and Andreas Bode. Im-
proved discriminative bilingual word alignment. Pro-
ceedings of ACL, 2006.
Franz Josef Och. Minimum Error Rate Training in Sta-
tistical Machine Translation. Proceedings of ACL,
2003.
Franz Josef Och and Hermann Ney. A Systematic
Comparison of Various Statistical Alignment Models.
Computational Linguistics, Vol. 29, No. 1, 2003.
Franz Josef Och and Hermann Ney. The alignment
template approach to statistical machine translation.
Computational Linguistics, 2004.
K. Papineni, S. Roukos, T. Ward, and W. J. Zhu. BLEU:
a Methodfor Automatic Evaluation ofMachine Trans-
lation. Proceedings of ACL, 2002.
Chris Quirk, Arul Menezes, and Colin Cherry. De-
pendency Treelet Translation: Syntactically Informed
Phrasal SMT. Proceedings of ACL, 2005.
Ben Taskar, Simon Lacoste-Julien, and Dan Klein. A
Discriminative Matching Approach to Word Align-
ment. Proceedings of HTL/EMNLP, 2005.
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
HMM-Based Word Alignment in Statistical Transla-
tion Proceedings of COLING, 1996.
</reference>
<page confidence="0.998851">
52
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.386016">
<title confidence="0.999268">Using Syntax to Improve Word Alignment Precision for Machine Translation</title>
<author confidence="0.978082">Victoria</author>
<affiliation confidence="0.999093">Dept. of Computer University of</affiliation>
<address confidence="0.66993">Ann Arbor, MI</address>
<email confidence="0.997323">vfossum@umich.edu</email>
<author confidence="0.953433">Kevin</author>
<affiliation confidence="0.9995815">Information Sciences University of Southern</affiliation>
<author confidence="0.688018">Marina del Rey</author>
<author confidence="0.688018">CA</author>
<email confidence="0.99909">knight@isi.edu</email>
<author confidence="0.999813">Steven Abney</author>
<affiliation confidence="0.9999635">Dept. of Linguistics University of Michigan</affiliation>
<address confidence="0.999146">Ann Arbor, MI 48104</address>
<email confidence="0.999438">abney@umich.edu</email>
<abstract confidence="0.99183875">Word alignments that violate syntactic correspondences interfere with the extraction of string-to-tree transducer rules for syntaxbased machine translation. We present an algorithm for identifying and deleting incorrect word alignment links, using features of the extracted rules. We obtain gains in both alignment quality and translation quality in Chinese-English and Arabic-English translation experiments relative to a GIZA++ union baseline.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The Mathematics ofStatistical Machine Translation: Parameter Estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<contexts>
<context position="1064" citStr="Brown et al., 1993" startWordPosition="143" endWordPosition="146">ic correspondences interfere with the extraction of string-to-tree transducer rules for syntaxbased machine translation. We present an algorithm for identifying and deleting incorrect word alignment links, using features of the extracted rules. We obtain gains in both alignment quality and translation quality in Chinese-English and Arabic-English translation experiments relative to a GIZA++ union baseline. 1 Introduction 1.1 Motivation Word alignment typically constitutes the first stage of the statistical machine translation pipeline. GIZA++ (Och and Ney, 2003), an implementation of the IBM (Brown et al., 1993) and HMM (?) alignment models, is the most widely-used alignment system. GIZA++ union alignments have been used in the state-of-the-art syntax-based statistical MT system described in (Galley et al., 2006) and in the hierarchical phrase-based system Hiero (Chiang, 2007). GIZA++ refined alignments have been used in state-of-the-art phrase-based statistical MT systems such as (Och, 2004); variations on the refined heuristic have been used by (Koehn et al., 2003) (diag and diag-and) and by the phrase-based system Moses (grow-diag-final) (Koehn et al., 2007). GIZA++ union alignments have high reca</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. The Mathematics ofStatistical Machine Translation: Parameter Estimation. Computational Linguistics, Vol. 19, No. 2, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarse-to-fine nbest parsing and MaxEnt discriminative reranking.</title>
<date>2005</date>
<booktitle>Proceedings of ACL,</booktitle>
<contexts>
<context position="15808" citStr="Charniak and Johnson, 2005" startWordPosition="2576" endWordPosition="2579">ning increase in f-measure from 63.81 to 75.14 (shown in Table 3) is due to the link deletion algorithm itself. We construct a set of candidate alignments Acandidates for use in reranking as follows. Starting with A = Ainitial, we iteratively explore all alignments A′ in the neighborhood of A, adding each neighbor to Acandidates, then selecting the neighbor that maximizes Score(A′). When it is no longer possible to increase Score(A) by deleting any links, link deletion concludes and returns the highest-scoring alignment, A1-best. In general, Agold V Acandidates; following (Collins, 2000) and (Charniak and Johnson, 2005) for parse reranking and (Liang et al., 2006) for translation reranking, we define Aoracle as alignment in Acandidates that is most similar to Agold.8 We update each feature weight Ai as follows: Ai = Ai + hAoracle _ hAl-best .9 i i Following (Moore, 2005), after each training pass, we average all the feature weight vectors seen during the pass, and decode the discriminative training set using the vector of averaged feature weights. When alignment quality stops increasing on the discriminative training set, perceptron training ends.10 The weight vector returned by perceptron training is the av</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Eugene Charniak and Mark Johnson. Coarse-to-fine nbest parsing and MaxEnt discriminative reranking. Proceedings of ACL, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
<author>Dekang Lin</author>
</authors>
<title>Soft Syntactic Constraints for Word Alignment through Discriminative Training.</title>
<date>2006</date>
<booktitle>Proceedings of ACL (Poster),</booktitle>
<contexts>
<context position="7552" citStr="Cherry and Lin, 2006" startWordPosition="1224" endWordPosition="1227">hat sentence pair. Second, (May and Knight, 2007) use a time-intensive training algorithm to select the best re-alignment for each sentence pair, while we use a fast greedy search to determine which links to delete; in contrast to (May and Knight, 2007), who require 400 CPU hours to re-align 330k Chinese-English sentence pairs (anonymous, p.c), link deletion requires only 18 CPU hours to re-align such a corpus. (Lopez and Resnik, 2005) and (Denero and Klein, 2007) modify the distortion model of the HMM alignment model (Vogel et al., 1996) to reflect tree distance rather than string distance; (Cherry and Lin, 2006) modify an ITG aligner by introducing a penalty for induced parses that violate syntactic bracketing constraints. Similarly to these approaches, we use syntactic bracketing to constrain alignment, but our work extends beyond improving alignment quality to improve translation quality as well. 2 Link Deletion We propose an algorithm to re-align a parallel bitext that has been aligned by GIZA++ (IBM Model 4), then symmetrized using the union heuristic. We then train a syntax-based translation system on the realigned bitext, and evaluate whether the re-aligned bitext yields a better translation mo</context>
</contexts>
<marker>Cherry, Lin, 2006</marker>
<rawString>Colin Cherry and Dekang Lin. Soft Syntactic Constraints for Word Alignment through Discriminative Training. Proceedings of ACL (Poster), 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A Hierarchical Phrase-Based Model for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>Proceedings of ACL,</booktitle>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. A Hierarchical Phrase-Based Model for Statistical Machine Translation. Proceedings of ACL, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation. Computational Linguistics,</title>
<date>2007</date>
<contexts>
<context position="1334" citStr="Chiang, 2007" startWordPosition="185" endWordPosition="186">nt quality and translation quality in Chinese-English and Arabic-English translation experiments relative to a GIZA++ union baseline. 1 Introduction 1.1 Motivation Word alignment typically constitutes the first stage of the statistical machine translation pipeline. GIZA++ (Och and Ney, 2003), an implementation of the IBM (Brown et al., 1993) and HMM (?) alignment models, is the most widely-used alignment system. GIZA++ union alignments have been used in the state-of-the-art syntax-based statistical MT system described in (Galley et al., 2006) and in the hierarchical phrase-based system Hiero (Chiang, 2007). GIZA++ refined alignments have been used in state-of-the-art phrase-based statistical MT systems such as (Och, 2004); variations on the refined heuristic have been used by (Koehn et al., 2003) (diag and diag-and) and by the phrase-based system Moses (grow-diag-final) (Koehn et al., 2007). GIZA++ union alignments have high recall but low precision, while intersection or refined alignments have high precision but low recall.1 There are two natural approaches to improving upon GIZA++ alignments, then: deleting links from union alignments, or adding links to intersection or refined alignments. I</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. Hierarchical phrase-based translation. Computational Linguistics, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative Reranking for Natural Language Parsing.</title>
<date>2000</date>
<booktitle>Proceedings of ICML,</booktitle>
<contexts>
<context position="15775" citStr="Collins, 2000" startWordPosition="2573" endWordPosition="2574">nks, while the remaining increase in f-measure from 63.81 to 75.14 (shown in Table 3) is due to the link deletion algorithm itself. We construct a set of candidate alignments Acandidates for use in reranking as follows. Starting with A = Ainitial, we iteratively explore all alignments A′ in the neighborhood of A, adding each neighbor to Acandidates, then selecting the neighbor that maximizes Score(A′). When it is no longer possible to increase Score(A) by deleting any links, link deletion concludes and returns the highest-scoring alignment, A1-best. In general, Agold V Acandidates; following (Collins, 2000) and (Charniak and Johnson, 2005) for parse reranking and (Liang et al., 2006) for translation reranking, we define Aoracle as alignment in Acandidates that is most similar to Agold.8 We update each feature weight Ai as follows: Ai = Ai + hAoracle _ hAl-best .9 i i Following (Moore, 2005), after each training pass, we average all the feature weight vectors seen during the pass, and decode the discriminative training set using the vector of averaged feature weights. When alignment quality stops increasing on the discriminative training set, perceptron training ends.10 The weight vector returned</context>
</contexts>
<marker>Collins, 2000</marker>
<rawString>Michael Collins. Discriminative Reranking for Natural Language Parsing. Proceedings of ICML, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden Markov models: theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>Proceedings of EMNLP,</booktitle>
<contexts>
<context position="14060" citStr="Collins, 2002" startWordPosition="2299" endWordPosition="2300">e 10 most common English words (excluding punctuation marks) include {a,in,to,of,and,the}, while the 10 most common Chinese words include {_f,a,AL,TH,A}. Of these, {a,the} and {f,A} have no explicit translational equivalent in the other language. These words are aligned with each other frequently (and erroneously) by GIZA++ union, but rarely in the gold standard. We delete all links in the set {a, an, the} x { in, , _f } from Ainitial as a preprocessing step.7 2.4 Perceptron Training We set the feature weights A using a modified version of averaged perceptron learning with structured outputs (Collins, 2002). Following (Moore, 2005), we initialize the value of our expected most informative feature (ruleCount) to 1.0, and initialize all other feature weights to 0. During each pass over the discriminative training set, we “decode” each sentence pair by greedily deleting links from Ainitial in order to maximize the score of the resulting alignment using the current settings of A (for details, refer to section 2.1). 5On a 400-sentence-pair Chinese-English data set, GIZA++ union alignments have a precision of 77.32 while GIZA++ refined alignments have a precision of 85.26. 6To see how GIZA++ refined a</context>
<context position="16551" citStr="Collins, 2002" startWordPosition="2700" endWordPosition="2701">st similar to Agold.8 We update each feature weight Ai as follows: Ai = Ai + hAoracle _ hAl-best .9 i i Following (Moore, 2005), after each training pass, we average all the feature weight vectors seen during the pass, and decode the discriminative training set using the vector of averaged feature weights. When alignment quality stops increasing on the discriminative training set, perceptron training ends.10 The weight vector returned by perceptron training is the average over the training set of all weight vectors seen during all iterations; averaging reduces overfitting on the training set (Collins, 2002). 3 Experimental Setup 3.1 Data Sets We evaluate the effect of link deletion upon alignment quality and translation quality for two ChineseEnglish data sets, and one Arabic-English data set. Each data set consists of newswire, and contains a small subset of manually aligned sentence pairs. We divide the manually aligned subset into a training set (used to discriminatively set the feature weights for link deletion) and a test set (used to evaluate the impact of link deletion upon alignment quality). Table 1 lists the source and the size of the manually aligned training and test sets used for ea</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. Discriminative training methods for hidden Markov models: theory and experiments with perceptron algorithms. Proceedings of EMNLP, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Tailoring Word Alignments to Syntactic Machine Translation.</title>
<date>2007</date>
<booktitle>Proceedings of ACL,</booktitle>
<marker>DeNero, Klein, 2007</marker>
<rawString>John DeNero and Dan Klein. Tailoring Word Alignments to Syntactic Machine Translation. Proceedings of ACL, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yonggang Deng</author>
<author>William Byrne</author>
</authors>
<title>HMM word and phrase alignment for statistical machine translation.</title>
<date>2005</date>
<booktitle>Proceedings of HLT/EMNLP,</booktitle>
<contexts>
<context position="10995" citStr="Deng and Byrne, 2005" startWordPosition="1800" endWordPosition="1803">gure 1, the links {ffla-starts,fflAout,fflA-needs} represent a 1-to-many alignment. 1-to-many links appear more frequently in GIZA++ union alignments than in gold alignments, and are therefore good candidates for deletion. The category of 1-to-many links is further subdivided, depending on the degree of contiguity that the link exhibits with its neighbors.4 Each link in a 1-to-many 3While using a dynamic programming algorithm would likely improve search efficiency and allow link deletion to find an optimal solution, in practice, the greedy search runs quickly and improves alignment quality. 4(Deng and Byrne, 2005) observe that, in a manually aligned Chinese-English corpus, 82% of the Chinese words that are alignment can have 0, 1, or 2 neighbors, according to how many links are adjacent to it in the 1-to-many alignment: zeroNeighbors: In Figure 1, the linkffla-needs has 0 neighbors. oneNeighbor: In Figure 1, the linksffla-starts andffla-out each have 1 neighbor–namely, each other. twoNeighbors: In Figure 1, in the 1-to-many alignment formed by {* )-its,* )-own,* )- country}, the link * )-own has 2 neighbors, namely *)-it and *)-country. 2.2.3 Lexical Features highestLexProbRank: A link ei-fj is “maxpro</context>
</contexts>
<marker>Deng, Byrne, 2005</marker>
<rawString>Yonggang Deng and William Byrne. HMM word and phrase alignment for statistical machine translation. Proceedings of HLT/EMNLP, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Fraser</author>
<author>Daniel Marcu</author>
</authors>
<title>Measuring Word Alignment Qualityfor Statistical Machine Translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<contexts>
<context position="5255" citStr="Fraser and Marcu, 2007" startWordPosition="856" endWordPosition="859">otted boxed nodes in the parse tree (R5, R6, R7, R8). R4: NP →�� PRP its JJ own NN country 45 deletion improves alignment quality and translation quality in Chinese-English and Arabic-English MT, relative to a strong baseline. Our link deletion algorithm is easy to implement, runs quickly, and has been used by a top-scoring MT system in the Chinese newswire track of the 2008 NIST evaluation. 1.2 Related Work Recently, discriminative methods for alignment have rivaled the quality of IBM Model 4 alignments (Liu et al., 2005; Ittycheriah and Roukos, 2005; Taskar et al., 2005; Moore et al., 2006; Fraser and Marcu, 2007b). However, except for (Fraser and Marcu, 2007b), none of these advances in alignment quality has improved translation quality of a state-of-the-art system. We use a discriminatively trained model to identify and delete incorrect links, and demonstrate that these gains in alignment quality lead to gains in translation quality in a stateof-the-art syntax-based MT system. In contrast to the semi-supervised LEAF alignment algorithm of (Fraser and Marcu, 2007b), which requires 1,500- 2,000 CPU days per iteration to align 8.4M ChineseEnglish sentences (anonymous, p.c.), link deletion requires only</context>
<context position="18251" citStr="Fraser and Marcu, 2007" startWordPosition="2971" endWordPosition="2974">nd train a full syntax-based statistical MT system on these sentence pairs. After maximum BLEU tuning (Och, 2003a) on a held-out tuning set, we evaluate translation quality on a held-out test set. Table 2 lists the source and the size of the training, tuning, and test sets used for each translation task. 3.2 Evaluation Metrics AER (Alignment Error Rate) (Och and Ney, 2003) is the most widely used metric of alignment quality, but requires gold-standard alignments labelled with “sure/possible” annotations to compute; lacking such annotations, we can compute alignment fmeasure instead. However, (Fraser and Marcu, 2007a) show that, in phrase-based translation, improvements in AER or f-measure do not necessarily correlate with improvements in BLEU score. They propose two modifications to f-measure: varying the precision/recall tradeoff, and fully-connecting the alignment links before computing f-measure.11 Weighted Fully-Connected F-Measure Given a hypothesized set of alignment links H and a goldstandard set of alignment links G, we define H+ = fullyConnect(H) and G+ = fullyConnect(G), and then compute: For phrase-based Chinese-English and ArabicEnglish translation tasks, (Fraser and Marcu, 2007a) obtain the</context>
</contexts>
<marker>Fraser, Marcu, 2007</marker>
<rawString>Alexander Fraser and Daniel Marcu. Measuring Word Alignment Qualityfor Statistical Machine Translation. Computational Linguistics, Vol. 33, No. 3, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Fraser</author>
<author>Daniel Marcu</author>
</authors>
<title>Getting the Structure Rightfor Word Alignment: LEAF.</title>
<date>2007</date>
<booktitle>Proceedings of EMNLP,</booktitle>
<contexts>
<context position="5255" citStr="Fraser and Marcu, 2007" startWordPosition="856" endWordPosition="859">otted boxed nodes in the parse tree (R5, R6, R7, R8). R4: NP →�� PRP its JJ own NN country 45 deletion improves alignment quality and translation quality in Chinese-English and Arabic-English MT, relative to a strong baseline. Our link deletion algorithm is easy to implement, runs quickly, and has been used by a top-scoring MT system in the Chinese newswire track of the 2008 NIST evaluation. 1.2 Related Work Recently, discriminative methods for alignment have rivaled the quality of IBM Model 4 alignments (Liu et al., 2005; Ittycheriah and Roukos, 2005; Taskar et al., 2005; Moore et al., 2006; Fraser and Marcu, 2007b). However, except for (Fraser and Marcu, 2007b), none of these advances in alignment quality has improved translation quality of a state-of-the-art system. We use a discriminatively trained model to identify and delete incorrect links, and demonstrate that these gains in alignment quality lead to gains in translation quality in a stateof-the-art syntax-based MT system. In contrast to the semi-supervised LEAF alignment algorithm of (Fraser and Marcu, 2007b), which requires 1,500- 2,000 CPU days per iteration to align 8.4M ChineseEnglish sentences (anonymous, p.c.), link deletion requires only</context>
<context position="18251" citStr="Fraser and Marcu, 2007" startWordPosition="2971" endWordPosition="2974">nd train a full syntax-based statistical MT system on these sentence pairs. After maximum BLEU tuning (Och, 2003a) on a held-out tuning set, we evaluate translation quality on a held-out test set. Table 2 lists the source and the size of the training, tuning, and test sets used for each translation task. 3.2 Evaluation Metrics AER (Alignment Error Rate) (Och and Ney, 2003) is the most widely used metric of alignment quality, but requires gold-standard alignments labelled with “sure/possible” annotations to compute; lacking such annotations, we can compute alignment fmeasure instead. However, (Fraser and Marcu, 2007a) show that, in phrase-based translation, improvements in AER or f-measure do not necessarily correlate with improvements in BLEU score. They propose two modifications to f-measure: varying the precision/recall tradeoff, and fully-connecting the alignment links before computing f-measure.11 Weighted Fully-Connected F-Measure Given a hypothesized set of alignment links H and a goldstandard set of alignment links G, we define H+ = fullyConnect(H) and G+ = fullyConnect(G), and then compute: For phrase-based Chinese-English and ArabicEnglish translation tasks, (Fraser and Marcu, 2007a) obtain the</context>
</contexts>
<marker>Fraser, Marcu, 2007</marker>
<rawString>Alexander Fraser and Daniel Marcu. Getting the Structure Rightfor Word Alignment: LEAF. Proceedings of EMNLP, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Mark Hopkins</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>What’s in a Translation Rule?</title>
<date>2004</date>
<booktitle>Proceedings of HLT/NAACL-04,</booktitle>
<contexts>
<context position="2591" citStr="Galley et al., 2004" startWordPosition="381" endWordPosition="384">A++ union alignments to improve precision. The low precision of GIZA++ union alignments poses a particular problem for syntax-based rule extraction algorithms such as (Quirk et al., 2005; Galley et al., 2006; Huang et al., 2006; Liu et al., 2006): if the incorrect links violate syntactic correspondences, they force the rule extraction algorithm to extract rules that are large in size, few in number, and poor in generalization ability. Figure 1 illustrates this problem: the dotted line represents an incorrect link in the GIZA++ union alignment. Using the rule extraction algorithm described in (Galley et al., 2004), we extract the rules shown in the leftmost column (R1–R4). Rule R1 is large and unlikely to generalize well. If we delete the incorrect link in Figure 1, we can extract the rules shown in the rightmost column (R2–R9): Rule R1, the largest rule from the initial set, disappears, and several smaller, more modular rules (R5–R9) replace it. In this work, we present a supervised algorithm that uses these two features of the extracted rules (size of largest rule and total number of rules), as well as a handful of structural and lexical features, to automatically identify and delete incorrect links </context>
<context position="9651" citStr="Galley et al., 2004" startWordPosition="1589" endWordPosition="1592">ffer only by the deletion of a link or branch of links. We consider all alignments A′ in the neighborhood of A, greedily deleting the link l or branch of links b maximizing the score of the resulting alignment A′ = A \ l or A′ = A \ b. We delete links until no further increase in the score of A is possible.3 In section 2.2 we describe the features hi, and in section 2.4 we describe how to set the weights Ai. 2.2 Features 2.2.1 Syntactic Features We use two features of the string-to-tree transducer rules extracted from A, parse(e), and f according to the rule extraction algorithm described in (Galley et al., 2004): ruleCount: Total number of rules extracted from A, parse(e), and f. As Figure 1 illustrates, incorrect links violating syntactic brackets tend to decrease ruleCount; ruleCount increases from 4 to 8 after deleting the incorrect link. sizeOfLargestRule: The size, measured in terms of internal nodes in the target parse tree, of the single largest rule extracted from A, parse(e), and f. In Figure 1, the largest rules in the leftmost and rightmost columns are R1 (with 9 internal nodes) and R9 (with 4 internal nodes), respectively. 2.2.2 Structural Features wordsUnaligned: Total number of unaligne</context>
</contexts>
<marker>Galley, Hopkins, Knight, Marcu, 2004</marker>
<rawString>Michel Galley, Mark Hopkins, Kevin Knight, and Daniel Marcu. What’s in a Translation Rule? Proceedings of HLT/NAACL-04, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
<author>Steve DeNeefe</author>
<author>Wei Wang</author>
<author>Ignacio Thayer</author>
</authors>
<title>Scalable Inference and Training of ContextRich Syntactic Translation Models.</title>
<date>2006</date>
<booktitle>Proceedings of ACL,</booktitle>
<contexts>
<context position="1269" citStr="Galley et al., 2006" startWordPosition="174" endWordPosition="177">, using features of the extracted rules. We obtain gains in both alignment quality and translation quality in Chinese-English and Arabic-English translation experiments relative to a GIZA++ union baseline. 1 Introduction 1.1 Motivation Word alignment typically constitutes the first stage of the statistical machine translation pipeline. GIZA++ (Och and Ney, 2003), an implementation of the IBM (Brown et al., 1993) and HMM (?) alignment models, is the most widely-used alignment system. GIZA++ union alignments have been used in the state-of-the-art syntax-based statistical MT system described in (Galley et al., 2006) and in the hierarchical phrase-based system Hiero (Chiang, 2007). GIZA++ refined alignments have been used in state-of-the-art phrase-based statistical MT systems such as (Och, 2004); variations on the refined heuristic have been used by (Koehn et al., 2003) (diag and diag-and) and by the phrase-based system Moses (grow-diag-final) (Koehn et al., 2007). GIZA++ union alignments have high recall but low precision, while intersection or refined alignments have high precision but low recall.1 There are two natural approaches to improving upon GIZA++ alignments, then: deleting links from union ali</context>
<context position="20684" citStr="Galley et al., 2006" startWordPosition="3341" endWordPosition="3344">.5 for Chinese-English and a=0.1 for ArabicEnglish) on a manually aligned discriminative training set. We report the (fully-connected) precision, recall, and weighted alignment f-measure on a heldout test set after running perceptron training, relative to the baseline GIZA++ union alignments. Using the learned feature weights, we then perform link deletion over the GIZA++ union alignments for the entire training corpus for each translation task. Using these alignments, which we refer to as “GIZA++ union + link deletion”, we train a syntax-based translation system similar to that described in (Galley et al., 2006). After extracting string-to-tree translation rules from the aligned, parsed training corpus, the system assigns weights to each rule via frequency estimation with smoothing. The rule probabilities, as well as trigram language model probabilities and a handful of additional features of each rule, are used as features during decoding. The feature weights are tuned using minimum error rate training (Och and Ney, 2003) to optimize BLEU score on a held-out development set. We then compare the BLEU score of this system against a baseline system trained using GIZA++ union alignments. To determine wh</context>
</contexts>
<marker>Galley, Graehl, Knight, Marcu, DeNeefe, Wang, Thayer, 2006</marker>
<rawString>Michel Galley, Jonathan Graehl, Kevin Knight, Daniel Marcu, Steve DeNeefe, Wei Wang, and Ignacio Thayer. Scalable Inference and Training of ContextRich Syntactic Translation Models. Proceedings of ACL, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Kevin Knight</author>
<author>Aravind Joshi</author>
</authors>
<title>Statistical Syntax-Directed Translation with Extended Domain ofLocality.</title>
<date>2006</date>
<booktitle>Proceedings of AMTA,</booktitle>
<contexts>
<context position="2198" citStr="Huang et al., 2006" startWordPosition="318" endWordPosition="321">Moses (grow-diag-final) (Koehn et al., 2007). GIZA++ union alignments have high recall but low precision, while intersection or refined alignments have high precision but low recall.1 There are two natural approaches to improving upon GIZA++ alignments, then: deleting links from union alignments, or adding links to intersection or refined alignments. In this work, we delete links from GIZA++ union alignments to improve precision. The low precision of GIZA++ union alignments poses a particular problem for syntax-based rule extraction algorithms such as (Quirk et al., 2005; Galley et al., 2006; Huang et al., 2006; Liu et al., 2006): if the incorrect links violate syntactic correspondences, they force the rule extraction algorithm to extract rules that are large in size, few in number, and poor in generalization ability. Figure 1 illustrates this problem: the dotted line represents an incorrect link in the GIZA++ union alignment. Using the rule extraction algorithm described in (Galley et al., 2004), we extract the rules shown in the leftmost column (R1–R4). Rule R1 is large and unlikely to generalize well. If we delete the incorrect link in Figure 1, we can extract the rules shown in the rightmost col</context>
</contexts>
<marker>Huang, Knight, Joshi, 2006</marker>
<rawString>Liang Huang, Kevin Knight, and Aravind Joshi. Statistical Syntax-Directed Translation with Extended Domain ofLocality. Proceedings of AMTA, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abraham Ittycheriah</author>
<author>Salim Roukos</author>
</authors>
<title>A Maximum Entropy Word Alignerfor Arabic-English Machine Translation.</title>
<date>2005</date>
<booktitle>Proceedings of HLT/EMNLP,</booktitle>
<contexts>
<context position="5190" citStr="Ittycheriah and Roukos, 2005" startWordPosition="844" endWordPosition="847">xtraction of additional rules whose left hand sides are rooted at the dotted boxed nodes in the parse tree (R5, R6, R7, R8). R4: NP →�� PRP its JJ own NN country 45 deletion improves alignment quality and translation quality in Chinese-English and Arabic-English MT, relative to a strong baseline. Our link deletion algorithm is easy to implement, runs quickly, and has been used by a top-scoring MT system in the Chinese newswire track of the 2008 NIST evaluation. 1.2 Related Work Recently, discriminative methods for alignment have rivaled the quality of IBM Model 4 alignments (Liu et al., 2005; Ittycheriah and Roukos, 2005; Taskar et al., 2005; Moore et al., 2006; Fraser and Marcu, 2007b). However, except for (Fraser and Marcu, 2007b), none of these advances in alignment quality has improved translation quality of a state-of-the-art system. We use a discriminatively trained model to identify and delete incorrect links, and demonstrate that these gains in alignment quality lead to gains in translation quality in a stateof-the-art syntax-based MT system. In contrast to the semi-supervised LEAF alignment algorithm of (Fraser and Marcu, 2007b), which requires 1,500- 2,000 CPU days per iteration to align 8.4M Chines</context>
</contexts>
<marker>Ittycheriah, Roukos, 2005</marker>
<rawString>Abraham Ittycheriah and Salim Roukos. A Maximum Entropy Word Alignerfor Arabic-English Machine Translation. Proceedings of HLT/EMNLP, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical Phrase-Based Translation.</title>
<date>2003</date>
<booktitle>Proceedings of HLT/NAACL,</booktitle>
<contexts>
<context position="1528" citStr="Koehn et al., 2003" startWordPosition="213" endWordPosition="216"> constitutes the first stage of the statistical machine translation pipeline. GIZA++ (Och and Ney, 2003), an implementation of the IBM (Brown et al., 1993) and HMM (?) alignment models, is the most widely-used alignment system. GIZA++ union alignments have been used in the state-of-the-art syntax-based statistical MT system described in (Galley et al., 2006) and in the hierarchical phrase-based system Hiero (Chiang, 2007). GIZA++ refined alignments have been used in state-of-the-art phrase-based statistical MT systems such as (Och, 2004); variations on the refined heuristic have been used by (Koehn et al., 2003) (diag and diag-and) and by the phrase-based system Moses (grow-diag-final) (Koehn et al., 2007). GIZA++ union alignments have high recall but low precision, while intersection or refined alignments have high precision but low recall.1 There are two natural approaches to improving upon GIZA++ alignments, then: deleting links from union alignments, or adding links to intersection or refined alignments. In this work, we delete links from GIZA++ union alignments to improve precision. The low precision of GIZA++ union alignments poses a particular problem for syntax-based rule extraction algorithm</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. Statistical Phrase-Based Translation. Proceedings of HLT/NAACL, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>Proceedings of ACL (demo),</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="1624" citStr="Koehn et al., 2007" startWordPosition="227" endWordPosition="230">y, 2003), an implementation of the IBM (Brown et al., 1993) and HMM (?) alignment models, is the most widely-used alignment system. GIZA++ union alignments have been used in the state-of-the-art syntax-based statistical MT system described in (Galley et al., 2006) and in the hierarchical phrase-based system Hiero (Chiang, 2007). GIZA++ refined alignments have been used in state-of-the-art phrase-based statistical MT systems such as (Och, 2004); variations on the refined heuristic have been used by (Koehn et al., 2003) (diag and diag-and) and by the phrase-based system Moses (grow-diag-final) (Koehn et al., 2007). GIZA++ union alignments have high recall but low precision, while intersection or refined alignments have high precision but low recall.1 There are two natural approaches to improving upon GIZA++ alignments, then: deleting links from union alignments, or adding links to intersection or refined alignments. In this work, we delete links from GIZA++ union alignments to improve precision. The low precision of GIZA++ union alignments poses a particular problem for syntax-based rule extraction algorithms such as (Quirk et al., 2005; Galley et al., 2006; Huang et al., 2006; Liu et al., 2006): if th</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, Evan Herbst. Moses: Open Source Toolkit for Statistical Machine Translation. Proceedings of ACL (demo), 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Alexandre Bouchard-Cote</author>
<author>Dan Klein</author>
<author>Ben Taskar</author>
</authors>
<title>An end-to-end discriminative approach to machine translation.</title>
<date>2006</date>
<booktitle>Proceedings of COLING/ACL,</booktitle>
<contexts>
<context position="15853" citStr="Liang et al., 2006" startWordPosition="2584" endWordPosition="2587"> in Table 3) is due to the link deletion algorithm itself. We construct a set of candidate alignments Acandidates for use in reranking as follows. Starting with A = Ainitial, we iteratively explore all alignments A′ in the neighborhood of A, adding each neighbor to Acandidates, then selecting the neighbor that maximizes Score(A′). When it is no longer possible to increase Score(A) by deleting any links, link deletion concludes and returns the highest-scoring alignment, A1-best. In general, Agold V Acandidates; following (Collins, 2000) and (Charniak and Johnson, 2005) for parse reranking and (Liang et al., 2006) for translation reranking, we define Aoracle as alignment in Acandidates that is most similar to Agold.8 We update each feature weight Ai as follows: Ai = Ai + hAoracle _ hAl-best .9 i i Following (Moore, 2005), after each training pass, we average all the feature weight vectors seen during the pass, and decode the discriminative training set using the vector of averaged feature weights. When alignment quality stops increasing on the discriminative training set, perceptron training ends.10 The weight vector returned by perceptron training is the average over the training set of all weight vec</context>
<context position="17258" citStr="Liang et al., 2006" startWordPosition="2816" endWordPosition="2819">ent quality and translation quality for two ChineseEnglish data sets, and one Arabic-English data set. Each data set consists of newswire, and contains a small subset of manually aligned sentence pairs. We divide the manually aligned subset into a training set (used to discriminatively set the feature weights for link deletion) and a test set (used to evaluate the impact of link deletion upon alignment quality). Table 1 lists the source and the size of the manually aligned training and test sets used for each alignment task. 8We discuss alignment similarity metrics in detail in Section 3.2. 9(Liang et al., 2006) report that, for translation reranking, such local updates (towards the oracle) outperform bold updates (towards the gold standard). 10We discuss alignment quality metrics in detail in Section 3.2. 48 Using the feature weights learned on the manually aligned training set, we then apply link deletion to the remainder (non-manually aligned) of each bilingual data set, and train a full syntax-based statistical MT system on these sentence pairs. After maximum BLEU tuning (Och, 2003a) on a held-out tuning set, we evaluate translation quality on a held-out test set. Table 2 lists the source and the</context>
</contexts>
<marker>Liang, Bouchard-Cote, Klein, Taskar, 2006</marker>
<rawString>Percy Liang, Alexandre Bouchard-Cote, Dan Klein, and Ben Taskar. An end-to-end discriminative approach to machine translation. Proceedings of COLING/ACL, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Log-linear Models for Word Alignment.</title>
<date>2005</date>
<booktitle>Proceedings of ACL,</booktitle>
<contexts>
<context position="5160" citStr="Liu et al., 2005" startWordPosition="840" endWordPosition="843"> before, and the extraction of additional rules whose left hand sides are rooted at the dotted boxed nodes in the parse tree (R5, R6, R7, R8). R4: NP →�� PRP its JJ own NN country 45 deletion improves alignment quality and translation quality in Chinese-English and Arabic-English MT, relative to a strong baseline. Our link deletion algorithm is easy to implement, runs quickly, and has been used by a top-scoring MT system in the Chinese newswire track of the 2008 NIST evaluation. 1.2 Related Work Recently, discriminative methods for alignment have rivaled the quality of IBM Model 4 alignments (Liu et al., 2005; Ittycheriah and Roukos, 2005; Taskar et al., 2005; Moore et al., 2006; Fraser and Marcu, 2007b). However, except for (Fraser and Marcu, 2007b), none of these advances in alignment quality has improved translation quality of a state-of-the-art system. We use a discriminatively trained model to identify and delete incorrect links, and demonstrate that these gains in alignment quality lead to gains in translation quality in a stateof-the-art syntax-based MT system. In contrast to the semi-supervised LEAF alignment algorithm of (Fraser and Marcu, 2007b), which requires 1,500- 2,000 CPU days per </context>
</contexts>
<marker>Liu, Liu, Lin, 2005</marker>
<rawString>Yang Liu, Qun Liu, and Shouxun Lin. Log-linear Models for Word Alignment. Proceedings of ACL, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Tree-to-String Alignment Template for Statistical Machine Translation.</title>
<date>2006</date>
<booktitle>Proceedings of ACL,</booktitle>
<contexts>
<context position="2217" citStr="Liu et al., 2006" startWordPosition="322" endWordPosition="325">al) (Koehn et al., 2007). GIZA++ union alignments have high recall but low precision, while intersection or refined alignments have high precision but low recall.1 There are two natural approaches to improving upon GIZA++ alignments, then: deleting links from union alignments, or adding links to intersection or refined alignments. In this work, we delete links from GIZA++ union alignments to improve precision. The low precision of GIZA++ union alignments poses a particular problem for syntax-based rule extraction algorithms such as (Quirk et al., 2005; Galley et al., 2006; Huang et al., 2006; Liu et al., 2006): if the incorrect links violate syntactic correspondences, they force the rule extraction algorithm to extract rules that are large in size, few in number, and poor in generalization ability. Figure 1 illustrates this problem: the dotted line represents an incorrect link in the GIZA++ union alignment. Using the rule extraction algorithm described in (Galley et al., 2004), we extract the rules shown in the leftmost column (R1–R4). Rule R1 is large and unlikely to generalize well. If we delete the incorrect link in Figure 1, we can extract the rules shown in the rightmost column (R2–R9): Rule R</context>
</contexts>
<marker>Liu, Liu, Lin, 2006</marker>
<rawString>Yang Liu, Qun Liu, and Shouxun Lin. Tree-to-String Alignment Template for Statistical Machine Translation. Proceedings of ACL, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Lopez</author>
<author>Philip Resnik</author>
</authors>
<title>Improved HMM Alignment Models for Languages with Scarce Resources.</title>
<date>2005</date>
<booktitle>Proceedings of the ACL Workshop on Parallel Text,</booktitle>
<contexts>
<context position="7370" citStr="Lopez and Resnik, 2005" startWordPosition="1194" endWordPosition="1197">s limited by the initial GIZA++ alignments seen over the training corpus, while we consider all alignments that can be reached by deleting links from the initial GIZA++ alignment for that sentence pair. Second, (May and Knight, 2007) use a time-intensive training algorithm to select the best re-alignment for each sentence pair, while we use a fast greedy search to determine which links to delete; in contrast to (May and Knight, 2007), who require 400 CPU hours to re-align 330k Chinese-English sentence pairs (anonymous, p.c), link deletion requires only 18 CPU hours to re-align such a corpus. (Lopez and Resnik, 2005) and (Denero and Klein, 2007) modify the distortion model of the HMM alignment model (Vogel et al., 1996) to reflect tree distance rather than string distance; (Cherry and Lin, 2006) modify an ITG aligner by introducing a penalty for induced parses that violate syntactic bracketing constraints. Similarly to these approaches, we use syntactic bracketing to constrain alignment, but our work extends beyond improving alignment quality to improve translation quality as well. 2 Link Deletion We propose an algorithm to re-align a parallel bitext that has been aligned by GIZA++ (IBM Model 4), then sym</context>
</contexts>
<marker>Lopez, Resnik, 2005</marker>
<rawString>Adam Lopez and Philip Resnik. Improved HMM Alignment Models for Languages with Scarce Resources. Proceedings of the ACL Workshop on Parallel Text, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan May</author>
<author>Kevin Knight</author>
</authors>
<title>Syntactic Re-Alignment Models for Machine Translation.</title>
<date>2007</date>
<booktitle>Proceedings of EMNLP-CoNLL,</booktitle>
<contexts>
<context position="6054" citStr="May and Knight, 2007" startWordPosition="979" endWordPosition="982">ively trained model to identify and delete incorrect links, and demonstrate that these gains in alignment quality lead to gains in translation quality in a stateof-the-art syntax-based MT system. In contrast to the semi-supervised LEAF alignment algorithm of (Fraser and Marcu, 2007b), which requires 1,500- 2,000 CPU days per iteration to align 8.4M ChineseEnglish sentences (anonymous, p.c.), link deletion requires only 450 CPU hours to re-align such a corpus (after initial alignment by GIZA++, which requires 20-24 CPU days). Several recent works incorporate syntactic features into alignment. (May and Knight, 2007) use syntactic constraints to re-align a parallel corpus that has been aligned by GIZA++ as follows: they extract string-to-tree transducer rules from the corpus, the target parse trees, and the alignment; discard the initial alignment; use the extracted rules to construct a forest of possible string-to-tree derivations for each string/tree pair in the corpus; use EM to select the Viterbi derivation tree for each pair; and finally, induce a new alignment from the Viterbi derivations, using the re-aligned corpus to train a syntax-based MT system. (May and Knight, 2007) differs from our approach</context>
</contexts>
<marker>May, Knight, 2007</marker>
<rawString>Jonathan May and Kevin Knight. Syntactic Re-Alignment Models for Machine Translation. Proceedings of EMNLP-CoNLL, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>A Discriminative Frameworkfor Bilingual Word Alignment.</title>
<date>2005</date>
<booktitle>Proceedings of HLT/EMNLP,</booktitle>
<contexts>
<context position="14085" citStr="Moore, 2005" startWordPosition="2302" endWordPosition="2303">rds (excluding punctuation marks) include {a,in,to,of,and,the}, while the 10 most common Chinese words include {_f,a,AL,TH,A}. Of these, {a,the} and {f,A} have no explicit translational equivalent in the other language. These words are aligned with each other frequently (and erroneously) by GIZA++ union, but rarely in the gold standard. We delete all links in the set {a, an, the} x { in, , _f } from Ainitial as a preprocessing step.7 2.4 Perceptron Training We set the feature weights A using a modified version of averaged perceptron learning with structured outputs (Collins, 2002). Following (Moore, 2005), we initialize the value of our expected most informative feature (ruleCount) to 1.0, and initialize all other feature weights to 0. During each pass over the discriminative training set, we “decode” each sentence pair by greedily deleting links from Ainitial in order to maximize the score of the resulting alignment using the current settings of A (for details, refer to section 2.1). 5On a 400-sentence-pair Chinese-English data set, GIZA++ union alignments have a precision of 77.32 while GIZA++ refined alignments have a precision of 85.26. 6To see how GIZA++ refined alignments compare to GIZA</context>
<context position="16064" citStr="Moore, 2005" startWordPosition="2625" endWordPosition="2626"> the neighborhood of A, adding each neighbor to Acandidates, then selecting the neighbor that maximizes Score(A′). When it is no longer possible to increase Score(A) by deleting any links, link deletion concludes and returns the highest-scoring alignment, A1-best. In general, Agold V Acandidates; following (Collins, 2000) and (Charniak and Johnson, 2005) for parse reranking and (Liang et al., 2006) for translation reranking, we define Aoracle as alignment in Acandidates that is most similar to Agold.8 We update each feature weight Ai as follows: Ai = Ai + hAoracle _ hAl-best .9 i i Following (Moore, 2005), after each training pass, we average all the feature weight vectors seen during the pass, and decode the discriminative training set using the vector of averaged feature weights. When alignment quality stops increasing on the discriminative training set, perceptron training ends.10 The weight vector returned by perceptron training is the average over the training set of all weight vectors seen during all iterations; averaging reduces overfitting on the training set (Collins, 2002). 3 Experimental Setup 3.1 Data Sets We evaluate the effect of link deletion upon alignment quality and translati</context>
</contexts>
<marker>Moore, 2005</marker>
<rawString>Robert C. Moore. A Discriminative Frameworkfor Bilingual Word Alignment. Proceedings of HLT/EMNLP, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
<author>Wen-tau Yih</author>
<author>Andreas Bode</author>
</authors>
<title>Improved discriminative bilingual word alignment.</title>
<date>2006</date>
<booktitle>Proceedings of ACL,</booktitle>
<contexts>
<context position="5231" citStr="Moore et al., 2006" startWordPosition="852" endWordPosition="855"> are rooted at the dotted boxed nodes in the parse tree (R5, R6, R7, R8). R4: NP →�� PRP its JJ own NN country 45 deletion improves alignment quality and translation quality in Chinese-English and Arabic-English MT, relative to a strong baseline. Our link deletion algorithm is easy to implement, runs quickly, and has been used by a top-scoring MT system in the Chinese newswire track of the 2008 NIST evaluation. 1.2 Related Work Recently, discriminative methods for alignment have rivaled the quality of IBM Model 4 alignments (Liu et al., 2005; Ittycheriah and Roukos, 2005; Taskar et al., 2005; Moore et al., 2006; Fraser and Marcu, 2007b). However, except for (Fraser and Marcu, 2007b), none of these advances in alignment quality has improved translation quality of a state-of-the-art system. We use a discriminatively trained model to identify and delete incorrect links, and demonstrate that these gains in alignment quality lead to gains in translation quality in a stateof-the-art syntax-based MT system. In contrast to the semi-supervised LEAF alignment algorithm of (Fraser and Marcu, 2007b), which requires 1,500- 2,000 CPU days per iteration to align 8.4M ChineseEnglish sentences (anonymous, p.c.), lin</context>
</contexts>
<marker>Moore, Yih, Bode, 2006</marker>
<rawString>Robert C. Moore, Wen-tau Yih, and Andreas Bode. Improved discriminative bilingual word alignment. Proceedings of ACL, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum Error Rate Training in Statistical Machine Translation.</title>
<date>2003</date>
<booktitle>Proceedings of ACL,</booktitle>
<contexts>
<context position="17741" citStr="Och, 2003" startWordPosition="2892" endWordPosition="2893">st sets used for each alignment task. 8We discuss alignment similarity metrics in detail in Section 3.2. 9(Liang et al., 2006) report that, for translation reranking, such local updates (towards the oracle) outperform bold updates (towards the gold standard). 10We discuss alignment quality metrics in detail in Section 3.2. 48 Using the feature weights learned on the manually aligned training set, we then apply link deletion to the remainder (non-manually aligned) of each bilingual data set, and train a full syntax-based statistical MT system on these sentence pairs. After maximum BLEU tuning (Och, 2003a) on a held-out tuning set, we evaluate translation quality on a held-out test set. Table 2 lists the source and the size of the training, tuning, and test sets used for each translation task. 3.2 Evaluation Metrics AER (Alignment Error Rate) (Och and Ney, 2003) is the most widely used metric of alignment quality, but requires gold-standard alignments labelled with “sure/possible” annotations to compute; lacking such annotations, we can compute alignment fmeasure instead. However, (Fraser and Marcu, 2007a) show that, in phrase-based translation, improvements in AER or f-measure do not necessa</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. Minimum Error Rate Training in Statistical Machine Translation. Proceedings of ACL, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<contexts>
<context position="1013" citStr="Och and Ney, 2003" startWordPosition="134" endWordPosition="137">.edu Abstract Word alignments that violate syntactic correspondences interfere with the extraction of string-to-tree transducer rules for syntaxbased machine translation. We present an algorithm for identifying and deleting incorrect word alignment links, using features of the extracted rules. We obtain gains in both alignment quality and translation quality in Chinese-English and Arabic-English translation experiments relative to a GIZA++ union baseline. 1 Introduction 1.1 Motivation Word alignment typically constitutes the first stage of the statistical machine translation pipeline. GIZA++ (Och and Ney, 2003), an implementation of the IBM (Brown et al., 1993) and HMM (?) alignment models, is the most widely-used alignment system. GIZA++ union alignments have been used in the state-of-the-art syntax-based statistical MT system described in (Galley et al., 2006) and in the hierarchical phrase-based system Hiero (Chiang, 2007). GIZA++ refined alignments have been used in state-of-the-art phrase-based statistical MT systems such as (Och, 2004); variations on the refined heuristic have been used by (Koehn et al., 2003) (diag and diag-and) and by the phrase-based system Moses (grow-diag-final) (Koehn et</context>
<context position="3378" citStr="Och and Ney, 2003" startWordPosition="510" endWordPosition="513">t the rules shown in the rightmost column (R2–R9): Rule R1, the largest rule from the initial set, disappears, and several smaller, more modular rules (R5–R9) replace it. In this work, we present a supervised algorithm that uses these two features of the extracted rules (size of largest rule and total number of rules), as well as a handful of structural and lexical features, to automatically identify and delete incorrect links from GIZA++ union alignments. We show that link 1For a complete discussion of alignment symmetrization heuristics, including union, intersection, and refined, refer to (Och and Ney, 2003). 44 Proceedings of the Third Workshop on Statistical Machine Translation, pages 44–52, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics VP � �� �� �� FROM OWN-COUNTRY NEEDS STARTS-OUT VBZ starts PRT RP out from IN DT the NP PP NNS needs NP IN of PRP its PP own JJ NP NN country Rules Extracted Using GIZA++ Union Alignments Rules Extracted After Deleting Dotted Link R1: VP →x0 x1xg�`hyQ R2: IN →K from R3: PP → x0 IN x0:NP of R4: NP →�� R2: IN from R3: PP →� → x0 VBZ starts PRT RP out PP x0:IN NP x1:PP NP DT the NNS needs own JJ IN of x0:NP PRP its NN country R5: </context>
<context position="18004" citStr="Och and Ney, 2003" startWordPosition="2935" endWordPosition="2938">ard). 10We discuss alignment quality metrics in detail in Section 3.2. 48 Using the feature weights learned on the manually aligned training set, we then apply link deletion to the remainder (non-manually aligned) of each bilingual data set, and train a full syntax-based statistical MT system on these sentence pairs. After maximum BLEU tuning (Och, 2003a) on a held-out tuning set, we evaluate translation quality on a held-out test set. Table 2 lists the source and the size of the training, tuning, and test sets used for each translation task. 3.2 Evaluation Metrics AER (Alignment Error Rate) (Och and Ney, 2003) is the most widely used metric of alignment quality, but requires gold-standard alignments labelled with “sure/possible” annotations to compute; lacking such annotations, we can compute alignment fmeasure instead. However, (Fraser and Marcu, 2007a) show that, in phrase-based translation, improvements in AER or f-measure do not necessarily correlate with improvements in BLEU score. They propose two modifications to f-measure: varying the precision/recall tradeoff, and fully-connecting the alignment links before computing f-measure.11 Weighted Fully-Connected F-Measure Given a hypothesized set </context>
<context position="21103" citStr="Och and Ney, 2003" startWordPosition="3403" endWordPosition="3406">s for each translation task. Using these alignments, which we refer to as “GIZA++ union + link deletion”, we train a syntax-based translation system similar to that described in (Galley et al., 2006). After extracting string-to-tree translation rules from the aligned, parsed training corpus, the system assigns weights to each rule via frequency estimation with smoothing. The rule probabilities, as well as trigram language model probabilities and a handful of additional features of each rule, are used as features during decoding. The feature weights are tuned using minimum error rate training (Och and Ney, 2003) to optimize BLEU score on a held-out development set. We then compare the BLEU score of this system against a baseline system trained using GIZA++ union alignments. To determine which value of a is most effective as a training criterion for link deletion, we set a=0.4 (favoring recall), 0.5, and 0.6 (favoring precision), 1 f-measure(H+) = precision(H+) + �−� � recall(H+) 49 Language Train Tune Test1 Test2 Chinese-English A 9.8M/newswire 25.9k/NIST02 29.0k/NIST03 – Chinese-English B 12.3M/newswire 42.9k/newswire 42.1k/newswire – Arabic-English 174.8M/newswire 35.8k/NIST04-05 40.3k/NIST04-05 53</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics, Vol. 29, No. 1, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>The alignment template approach to statistical machine translation. Computational Linguistics,</title>
<date>2004</date>
<marker>Och, Ney, 2004</marker>
<rawString>Franz Josef Och and Hermann Ney. The alignment template approach to statistical machine translation. Computational Linguistics, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W J Zhu</author>
</authors>
<title>BLEU: a Methodfor Automatic Evaluation ofMachine Translation.</title>
<date>2002</date>
<booktitle>Proceedings of ACL,</booktitle>
<contexts>
<context position="19807" citStr="Papineni et al., 2002" startWordPosition="3204" endWordPosition="3207">tion upon rule quality, we compare the rule precision, recall, and f-measure of the rule set extracted 11In Figure 1, the fully-connected version of the alignments shown would include the linksr -starts andr - out. Language Train Test Chinese-English A 400 400 Chinese-English B 1500 1500 Arabic-English 1500 1500 Table 1: Size (sentence pairs) of data sets used in alignment link deletion tasks from our hypothesized alignments and a Collinsstyle parser against the rule set extracted from gold alignments and gold parses. BLEU For all translation tasks, we report caseinsensitive NIST BLEU scores (Papineni et al., 2002) using 4 references per sentence. 3.3 Experiments Starting with GIZA++ union (IBM Model 4) alignments, we use perceptron training to set the weights of each feature used in link deletion in order to optimize weighted fully-connected alignment f-measure (a=0.5 for Chinese-English and a=0.1 for ArabicEnglish) on a manually aligned discriminative training set. We report the (fully-connected) precision, recall, and weighted alignment f-measure on a heldout test set after running perceptron training, relative to the baseline GIZA++ union alignments. Using the learned feature weights, we then perfor</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W. J. Zhu. BLEU: a Methodfor Automatic Evaluation ofMachine Translation. Proceedings of ACL, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Quirk</author>
<author>Arul Menezes</author>
<author>Colin Cherry</author>
</authors>
<title>Dependency Treelet Translation: Syntactically Informed Phrasal SMT.</title>
<date>2005</date>
<booktitle>Proceedings of ACL,</booktitle>
<contexts>
<context position="2157" citStr="Quirk et al., 2005" startWordPosition="309" endWordPosition="312">diag-and) and by the phrase-based system Moses (grow-diag-final) (Koehn et al., 2007). GIZA++ union alignments have high recall but low precision, while intersection or refined alignments have high precision but low recall.1 There are two natural approaches to improving upon GIZA++ alignments, then: deleting links from union alignments, or adding links to intersection or refined alignments. In this work, we delete links from GIZA++ union alignments to improve precision. The low precision of GIZA++ union alignments poses a particular problem for syntax-based rule extraction algorithms such as (Quirk et al., 2005; Galley et al., 2006; Huang et al., 2006; Liu et al., 2006): if the incorrect links violate syntactic correspondences, they force the rule extraction algorithm to extract rules that are large in size, few in number, and poor in generalization ability. Figure 1 illustrates this problem: the dotted line represents an incorrect link in the GIZA++ union alignment. Using the rule extraction algorithm described in (Galley et al., 2004), we extract the rules shown in the leftmost column (R1–R4). Rule R1 is large and unlikely to generalize well. If we delete the incorrect link in Figure 1, we can ext</context>
</contexts>
<marker>Quirk, Menezes, Cherry, 2005</marker>
<rawString>Chris Quirk, Arul Menezes, and Colin Cherry. Dependency Treelet Translation: Syntactically Informed Phrasal SMT. Proceedings of ACL, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Taskar</author>
<author>Simon Lacoste-Julien</author>
<author>Dan Klein</author>
</authors>
<title>A Discriminative Matching Approach to Word Alignment.</title>
<date>2005</date>
<booktitle>Proceedings of HTL/EMNLP,</booktitle>
<contexts>
<context position="5211" citStr="Taskar et al., 2005" startWordPosition="848" endWordPosition="851">whose left hand sides are rooted at the dotted boxed nodes in the parse tree (R5, R6, R7, R8). R4: NP →�� PRP its JJ own NN country 45 deletion improves alignment quality and translation quality in Chinese-English and Arabic-English MT, relative to a strong baseline. Our link deletion algorithm is easy to implement, runs quickly, and has been used by a top-scoring MT system in the Chinese newswire track of the 2008 NIST evaluation. 1.2 Related Work Recently, discriminative methods for alignment have rivaled the quality of IBM Model 4 alignments (Liu et al., 2005; Ittycheriah and Roukos, 2005; Taskar et al., 2005; Moore et al., 2006; Fraser and Marcu, 2007b). However, except for (Fraser and Marcu, 2007b), none of these advances in alignment quality has improved translation quality of a state-of-the-art system. We use a discriminatively trained model to identify and delete incorrect links, and demonstrate that these gains in alignment quality lead to gains in translation quality in a stateof-the-art syntax-based MT system. In contrast to the semi-supervised LEAF alignment algorithm of (Fraser and Marcu, 2007b), which requires 1,500- 2,000 CPU days per iteration to align 8.4M ChineseEnglish sentences (a</context>
</contexts>
<marker>Taskar, Lacoste-Julien, Klein, 2005</marker>
<rawString>Ben Taskar, Simon Lacoste-Julien, and Dan Klein. A Discriminative Matching Approach to Word Alignment. Proceedings of HTL/EMNLP, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Hermann Ney</author>
<author>Christoph Tillmann</author>
</authors>
<title>HMM-Based Word Alignment in Statistical Translation</title>
<date>1996</date>
<booktitle>Proceedings of COLING,</booktitle>
<contexts>
<context position="7475" citStr="Vogel et al., 1996" startWordPosition="1212" endWordPosition="1215">at can be reached by deleting links from the initial GIZA++ alignment for that sentence pair. Second, (May and Knight, 2007) use a time-intensive training algorithm to select the best re-alignment for each sentence pair, while we use a fast greedy search to determine which links to delete; in contrast to (May and Knight, 2007), who require 400 CPU hours to re-align 330k Chinese-English sentence pairs (anonymous, p.c), link deletion requires only 18 CPU hours to re-align such a corpus. (Lopez and Resnik, 2005) and (Denero and Klein, 2007) modify the distortion model of the HMM alignment model (Vogel et al., 1996) to reflect tree distance rather than string distance; (Cherry and Lin, 2006) modify an ITG aligner by introducing a penalty for induced parses that violate syntactic bracketing constraints. Similarly to these approaches, we use syntactic bracketing to constrain alignment, but our work extends beyond improving alignment quality to improve translation quality as well. 2 Link Deletion We propose an algorithm to re-align a parallel bitext that has been aligned by GIZA++ (IBM Model 4), then symmetrized using the union heuristic. We then train a syntax-based translation system on the realigned bite</context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>Stephan Vogel, Hermann Ney, and Christoph Tillmann. HMM-Based Word Alignment in Statistical Translation Proceedings of COLING, 1996.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>