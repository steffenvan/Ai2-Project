<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000013">
<title confidence="0.7262205">
Deeper spoken language understanding for man-machine dialogue on
broader application domains: a logical alternative to concept spotting
</title>
<author confidence="0.505524">
Jeanne Villaneau Jean-Yves Antoine
</author>
<affiliation confidence="0.345309">
UEB (Universit´e Europ´eenne de Bretagne) Universit´e Franc¸ois Rabelais - Tours
</affiliation>
<address confidence="0.358109">
VALORIA LI
France France
</address>
<email confidence="0.766108">
villanea@univ-ubs.fr Jean-Yves.Antoine@univ-tours.fr
</email>
<sectionHeader confidence="0.987141" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999834625">
LOGUS is a French-speaking spoken lan-
guage understanding (SLU) system which
carries out a deeper analysis than those
achieved by standard concept spotters. It
is designed for multi-domain conversa-
tional systems or for systems that are
working on complex application domains.
Based on a logical approach, the sys-
tem adapts the ideas of incremental ro-
bust parsing to the issue of SLU. The pa-
per provides a detailed description of the
system as well as results from two evalu-
ation campaigns that concerned all of cur-
rent French-speaking SLU systems. The
observed error rates suggest that our log-
ical approach can stand comparison with
concept spotters on restricted application
domains, but also that its behaviour is
promising for larger domains. The ques-
tion of the generality of the approach is
precisely addressed by our current inves-
tigations on a new task: SLU for an emo-
tional robot companion for young hospital
patents.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.972574723404255">
Despite the indisputable advances of automatic
speech recognition (ASR), highly spontaneous
speech remains an important barrier to the wide
spreading of speech based applications. The goal
of spontaneous speech understanding remains fea-
sible, provided the interaction between the user
and the system is restricted to a task-oriented di-
alogue (restricted vocabulary). Present research is
investigating mixed or user initiated dialogue for
less restricted tasks. It is the purpose of this paper,
which focuses on spontaneous speech understand-
ing in such complex applications.
Generally speaking, information speech dia-
logue systems are based on the same architecture.
At first, a speech recognizer processes the speech
signal and provides a string (or a lattice) of words
that should correspond to the spoken sentence.
Then, this string is parsed by a spoken language
understanding module (SLU) in order to build a
semantic representation that represents its propo-
sitional meaning. Finally, this semantic structure
is sent to a dialogue manager which controls the
interaction with the user (database interrogation,
dialogue management, answer generation). The
answers to the user can be displayed on screen
and/or through a message generated by a text-to-
speech synthesis. This paper focuses on the SLU
module of such a dialogue system. On the whole,
SLU has to cope with two main difficulties:
• speech recognition errors: highly sponta-
neous speech remains hard to recognize for
current ASR systems (Zue et al., 2000).
Therefore, the SLU module has to work on
a strongly corrupted string of words.
• spoken disfluencies: filled pauses, repetitions
and repairs make the parsing of conversa-
tional spoken language significantly harder to
achieve (Heeman, Allen, 2001).
In order to overcome those difficulties, most SLU
systems follow a selective strategy which comes
down to a simple concept spotting: they restrict
the semantic analysis to a mapping of the sentence
with the main expectations of the user in relation
with the task (Minker W. et al., 1999; Bangalore S.
et al., 2006). Consider, for instance, an air trans-
port information system and the following spoken
utterance:
</bodyText>
<listItem confidence="0.512341666666667">
(1) Cou- could you list me the flights uh the
scheduled flights for Tenerife Tenerife Tenerife
North please
</listItem>
<bodyText confidence="0.937468666666667">
Satisfying the speaker’s goals only requires de-
tecting the nature of their requests (list flights) and
the required destination (Tenerife North). Those
</bodyText>
<note confidence="0.899165">
Proceedings of EACL 2009 Workshop on Semantic Representation of Spoken Language - SRSL 2009, pages 50–57,
Athens, Greece, 30 March 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.996527">
50
</page>
<bodyText confidence="0.998785615384615">
two concepts (list, Tenerife North) will fill a shal-
low semantic frame which is supposed to repre-
sent the useful meaning of the sentence. Such
task-driven approaches meet, to a great extent, the
needs of SLU in terms of robustness, since they
only involve a partial analysis of the sentence.
Whether the processing is based on a statistical or
a knowledge-based approach, several evaluation
campaigns proved that concept spotting is suitable
for spoken language understanding, provided the
application task is sufficiently restricted. How-
ever, concept spotters suffer from noticeable limi-
tations:
</bodyText>
<listItem confidence="0.79396025">
• Although they resist gracefully speech recog-
nition errors, they are not able to detect their
eventual presence, since they do not consider
the global structure of the sentence. This lim-
</listItem>
<bodyText confidence="0.859776">
itation can be particularly penalizing when
the error is related to a key element, for ex-
ample when the error prevents the system to
determine the type (dialogue act) of the ut-
terance. Indeed, concept spotters often base
SLU on the initial characterization of the
question type. When analyzing the errors
of his statistical concept spotter, Minker has
shown that the correct identification of the
question type is a key issue in terms of final
robustness (Minker W. et al., 1999).
</bodyText>
<listItem confidence="0.711595842105263">
• Since they are based on the identification of
rather flat semantic frames, these approaches
hardly succeed in representing complex syn-
tactic relations such as overlapping coordi-
nate phrases or negations.
• Although it is well known that generality is
an important issue for SLU, this question
is generally approached in term of technical
portability from one (narrow) task to another.
Now, one should wonder whether concept
spotting is still suitable on larger application
domains. It seems that the robustness of the
spotting process depends strongly on the de-
gree of lexical ambiguity of the considered
task. For instance, Bousquet has shown that
the concept error rate of her stochastic spot-
ter is two times higher on ambiguous words
than on non ambiguous ones (Bousquet et al.,
2003).
</listItem>
<bodyText confidence="0.989373">
Such considerations tend to show that to apply
concept spotting to more complex tasks could be
difficult. Such observations are well known (Zech-
ner K., 1998; Van Noord et al., 1999), and no-
ticeable attempts have already been done to reach
a deeper semantic analysis. However, statistical
or knowledge-based concept spotting remains the
prevailing paradigm in SLU, mainly because of
engineering motivations (quick and easy build-
ing). On the contrary, we have decided to de-
velop a SLU system (LOGUS1) which carries out
a complete analysis of the utterance while keep-
ing the robustness of standard concept spotting ap-
proaches. The system, which is based on a logi-
cal approach, adapts the ideas of incremental ro-
bust parsing (A¨ıt-Mokhtar S., 2002; Basili, 2003)
to the issue of speech conversational systems. In
section 2, we will describe the system into de-
tail. Then, section 3 will present results from dif-
ferent evaluation campaigns in which we partici-
pated. These experiments concerned standard re-
stricted tasks (hotel reservation for instance) for
which concept spotting is well adapted. As a re-
sult, this section does not aim to prove a supe-
riority of our approach, but simply to show that
this deeper processing is able to keep a satisfac-
tory robustness, by comparison with prevailing ap-
proaches. Finally, we give in section 4 a brief de-
scription on our present work concerning the inte-
gration of LOGUS in a conversational robot which
is dedicated to general interaction with children
who are in hospital for a long-stay. This exam-
ple will illustrate the portability abilities of our ap-
proach on complex application tasks, in addition
with our previous works on general tourism infor-
mation.
2 Description of the LOGUS system
The task of a SLU is to turn a sequence or a graph
of words into a semantic representation; so a SLU
system has to perform a translation from natural
language to a formal target language. This section
begins with the description of the formal language
chosen for the LOGUS system. We then explain
the basic principles of parsing and its main steps.
</bodyText>
<subsectionHeader confidence="0.994403">
2.1 Semantic representation
</subsectionHeader>
<bodyText confidence="0.999737666666667">
When it comes to the choice of a target language
for the system, the following points must be taken
into account.
</bodyText>
<listItem confidence="0.874729">
• We want to implement automatic understand-
ing in application domains where predefined
</listItem>
<footnote confidence="0.529631">
1LOGical Understanding System.
</footnote>
<page confidence="0.994673">
51
</page>
<bodyText confidence="0.963965928571429">
semantic frames are not sufficient to repre-
sent all the possible queries (Van Noord et al.,
1999). Furthermore, any SLU aims at pro-
viding results usable by a dialogue manager:
the target language must reconcile simplicity
with precision.
• This semantic representation must obviously
extend to a pragmatic one. That means that it
should involve the characterization of the di-
alogue acts related to the speech turn (Austin
J.-L., 1962).
We have chosen a formalism compatible with
these constraints and inspired by the illocutionary
logic of D. Vanderveken (Vanderveken D., 1981).
In this formalism, the form of an elementary illo-
cutionary act is F(P) where F is the illocutionary
force, and P its propositional content.
The LOGUS system thus provides a logical for-
mula as the semantic representation of an utter-
ance. A language act contains clues about the in-
tentions of the speaker: it is labelled illocutionary
force, while the propositional content is a structure
built with the domain objects and their properties
which is called an object string.
The following example shows a single speech
turn uttered for a tourism information system:
(2) j’ai r´eserv´e une chambre dans un deux
´etoiles l’hˆotel euh l’hˆotel Rex pour y aller d’ici
comment est-ce que je peux faire (I booked a room
in a two-star hotel in the hotel hum in the Rex hotel
from here how can Igo at there)
This turn expresses two different language acts,
which is quite usual in conversational speech:
a piece of information (I booked a room...) is
followed by the user question (... how can I go....
Such complex speech turns are difficult to analyze
for concept spotters, since they usually base
the parsing on one language act detection. The
logical formula LOGUS provides is split into two
language acts: (information act) and (question
how). The second act is interpreted by the system
in the context of the first one:
((information act)
(of (reservation [J)
(hotel [(ident. (name ”Rex”)),(star (int 2))J)))
((question how)
(to go [(to (contextual location [J)),
(from (hotel [(ident. (name ”Rex”))J))J))
In the formula, reservation, hotel and to go are
object labels; (ident. (name ”Rex”)), (star (int 2))
are properties. The two objects of labels reserva-
tion and hotel are linked with the generic relation
of, which indicates a subordination relation. It is
the main relation, (in addition with logical coordi-
nations and, or and not) which is used for building
complex object strings.
</bodyText>
<subsectionHeader confidence="0.994622">
2.2 General system architecture
</subsectionHeader>
<bodyText confidence="0.999724581395349">
Incremental parsing methodology is used for text
parsing in order to combine efficiency with robust-
ness (Ait-Mokhtar S., 2002). With LOGUS, we
tried to show that such methods can be extended
to spoken language parsing.
The system has to parse out-of-grammar con-
structions but spoken language studies have shown
that minimal syntactic structures are generally pre-
served in repairs and false-starts (Mc Kelvie D.,
1998). We have thus chosen to carry out an
incremental bottom-up parsing, where words are
gradually combined. At the beginning, the parser
groups words according to mainly syntactic rules
in order to form minimal chunks that correspond
to basic concepts of the application domain. Then,
as word group size increases, their meaning be-
comes more precise, enough to relax syntactic cri-
teria and thereby overcome the problem of out-of-
grammar sentences.
The general architecture of the system is shown
in Figure 1. The parsing is essentially split into
three stages. The first stage is chunking (Ab-
ney S., 1991) where grammatical words are linked
to the lexical words to which they are referred.
The following stage gradually builds links be-
tween the chunks in order to detect semantic re-
lations between the corresponding concepts, and
the last one achieves a contextual interpretation
(anaphoric resolution for instance). The process
of building links between chunks and contextual
understanding uses a domain ontology.
Only one formalism is used during these pars-
ing stages. It is designed to distinguish syntax and
semantics and to preserve genericity of the pars-
ing rules. Each component is specified by a list
of what we can call definitions; each of them is a
triplet &lt; C, R, T &gt; where
C: is a syntactic label, called syntactic category:
for example adjective, (verb 1 present).
R: points out the semantic function of the compo-
nent. It is called semantic role: for example
object, (prop price) where prop is for prop-
erty.
</bodyText>
<page confidence="0.990796">
52
</page>
<bodyText confidence="0.998529">
In the following example only one definition is
shown for each component (gn is for nominal
group).
</bodyText>
<equation confidence="0.931295857142857">
trois (three) ´etoiles (stars)
C adj num adj num\gn
R (prop nb) (prop nb)\(prop nb star)
− level 1
− level 2
− level 3
− semantic kernel
</equation>
<figure confidence="0.961572">
dependencies
logical formula
domain
ontology
word sequence
lexicon
chunking
chunk dependencies
contextual understanding
</figure>
<figureCaption confidence="0.999709">
Figure 1: General architecture of the LOGUS sys- S (int 3) Ax.(star x)
</figureCaption>
<bodyText confidence="0.9802243">
tem
T: is the semantic translation. It is an element
of the logical formula built by the system. It
belongs thus to the target language.
The first two triplet elements, C and R, are
widely domain independent. A basic principle is
to define parsing rules from these elements in or-
der to preserve the genericity of the system. Each
parsing rule combines two or three triplets in order
to build a new result triplet.
</bodyText>
<subsectionHeader confidence="0.993824">
2.3 Chunking
</subsectionHeader>
<bodyText confidence="0.999939260869565">
Our experiments with LOGUS have clearly shown
that chunking is effective for spoken language,
provided the chunks are very short: more pre-
cisely, errors made at the speech recognition level
make it dangerous to link objects or properties ac-
cording to pure syntactic criteria, without check-
ing these links with semantic criteria. Therefore
the chunks built by LOGUS include only one con-
tent word: we call them minimal chunks. Chunk-
ing is based on the principle of linking function
words to the near content word.
The formalism used in this step is inspired by
Categorial Grammars of the AB type2, whose
rules are generalized from the first two elements of
the constituent triplets. Function words have def-
initions in which syntactic category and semantic
role are fractional. In such definitions, the seman-
tic translation is a A-abstraction (in the A-calculus
meaning)3. The semantic translation of the re-
sult triplet is achieved by applying this abstrac-
tion to the semantic translation of the un-fractional
triplet. Formally, the following two rules are ap-
plied, where F is an abstraction:
</bodyText>
<construct confidence="0.997817">
&lt; CA/CB, RA/RB, F &gt;, &lt; CB, RB, SB &gt;
→ &lt; CA, RA, (F SB) &gt;
&lt; CB, RB, SB &gt;, &lt; CB\CA, RB\RA, F &gt;
→ &lt; CA, RA, (F SB) &gt;
</construct>
<footnote confidence="0.98795425">
2The formalism can be expressed in terms of pregroup
formalism too (Lambek J., 1999).
3LOGUS is implemented in λProlog, a logic programming
language whose terms are λ-terms with simple types.
</footnote>
<bodyText confidence="0.927519142857143">
By applying the second rule, we obtain the fol-
lowing chunk:
“trois ´etoiles” (three stars)
&lt;gn, (prop nb star), (star (int 3))&gt;.
The semantic translation of the result triplet
is obtained by Q-reduction of the A-term
(Ax. (star x) (int 3)). For example, the utterance
</bodyText>
<listItem confidence="0.945875333333333">
(3) “A` l’hˆotel Caumartin quels sont le les tar-
ifs pour pour une chambre double” (In Caumartin
hotel what are the the prices forfor a double room)
is segmented into six chunks during the chunking
stage. Their semantic translations are:
[1] (hotel []),
[2] (identity (name “Caumartin”))]),
[3] (what (interrogation)), [4] (price []),
[5] (room []), [6] (size double).
</listItem>
<bodyText confidence="0.9994798">
At the end of the chunking process, the deter-
miner le and the first occurrence of the preposition
pour are deleted because they are fragments with-
out semantic content. Deletions such as these are
a first way of dealing with repairs.
</bodyText>
<subsectionHeader confidence="0.994324">
2.4 Domain ontology
</subsectionHeader>
<bodyText confidence="0.999984933333333">
The limited scope of the application domain
makes it possible to describe exhaustively the
pragmatic and semantic domain knowledge. A do-
main ontology specifies how objects and proper-
ties can be compounded. The handled processings
are expected to be generic while using a domain
dependent ontology: to achieve that, the ontology
is defined by generic predicates whose domain ob-
jects and domain properties are the arguments.
For example, the possibility of building the con-
ceptual relation of between two objects (cf. 2.1)
is defined by the predicate is sub object whose
arguments are two object labels: so the relation
is sub object(room, hotel) expresses a part-whole
relation possibility between such two objects.
</bodyText>
<subsectionHeader confidence="0.980325">
2.5 Chunk dependencies
</subsectionHeader>
<bodyText confidence="0.998695">
Chunk dependencies are built by an incremental
process which is compound of several successive
stages. Each stage is based on rewriting rules
</bodyText>
<page confidence="0.99418">
53
</page>
<bodyText confidence="0.999665125">
which are specified from the first two components
of the constituent triplets and from the generic on-
tology predicates. They are thus not specific to the
domain of application, what assures, to a certain
extent, the genericity of the process.
Consider for instance the following rule, which
leads to the binding of two consecutive chunks
which share a meronomic (part of) relation:
</bodyText>
<equation confidence="0.5485376">
&lt; C1, object, O1 &gt;, &lt; C2, object, O2 &gt;
- O1 simple object of label Et1
- O2 object string of label Et2
- is sub object(Et1, Et2)
&lt; C, object, (of O1 O2) &gt;
</equation>
<bodyText confidence="0.997845159090909">
where C is obtained by composing C1 and C2.
As an illustration, this rule will form a com-
plex object (of (price []) (room [(size double)]))
from the initial two chunks (price []) and (room
(size double)). This rule is completely generic and
should apply on any task. The knowledge spe-
cific to the task intervenes only on the definition of
the predicate is sub object. As a result, one could
speak of procedural genericity to qualify our sys-
tem.
As long as possible, the first processing stages
try to respect syntactic criteria. However, in pres-
ence of spoken disfluencies or speech recogni-
tion errors, it is likely that the utterance is out-
of-grammar. Therefore, since the detected links
between chunks make the meaning of the linked
chunks more specific, the next stage tries to detect
chunk dependencies more on more on semantic or
pragmatic features only. Subsequently, studying
dependencies between the components makes it
possible to eliminate some components, especially
in the case of word recognition errors.
As an illustration, Figure 2 shows how links are
gradually built during the parsing stage of utter-
ance (3) (cf. section 2.3). The chunks are in rect-
angular boxes in dotted lines.
The first step of chunk binding links the first two
chunks into the object:
(hotel [(ident. (name “Caumartin”))]).
The second step links the object (room []) with
the property (size (double)) to obtain the object
(room [(size double)]). Then, the two objects price
and room are linked with the conceptual relation of
to obtain (of (price []) (room [(size double)])) and
this object string is connected to the language act:
(question what). The position of the prepositional
phrase a` l’hotel Caumartin is not usual in French
syntagmatic ordering. It is indeed an example of
extraposition which is not accepted by the syn-
tactic constraints considered by the system. As a
result, the conceptual relation of, which links the
object of label room with the object (hotel [ident.
(name “Caumartin”)]) is built later, when these
constraints are relaxed.
</bodyText>
<subsectionHeader confidence="0.996383">
2.6 Contextual understanding
</subsectionHeader>
<bodyText confidence="0.99996265625">
Many sentences are elliptical and incomplete in a
dialogue. Therefore, it is necessary to use the cur-
rent context of the task and the dialogue history
in order to complete their understanding. The ob-
jectives of the contextual understanding in LOGUS
are thus close to the objectives of the authors of the
OntoSem system (McShane M., 2005): the com-
pletion of semantic fragments. Reference resolu-
tion is thereby extended to a more general comple-
tion of the semantic representation.
While syntactic anaphora criteria are generally
respected in texts, anaphora gender and number
are frequently broken in spoken language. More-
over, gender and number morphological marks are
hardly perceptible in spoken French. They are
therefore very often corrupted by speech recogni-
tion errors. So, in the LOGUS system, anaphora
resolution is based on the same principles as the
rest of the parsing: combining syntactic and se-
mantic criteria. Both nominal and pronominal
anaphora (with definite expressions) are consid-
ered during this contextual interpretation stage.
Completion is based on the concept of object
string. A property or an object may be completed
by an “over-object” of the context, if the ontology
makes it possible to do so. For example, the ob-
ject price of the sentence “quel est le tarif” (what
is the price) is automatically completed in
(of (price []) (of (room []) (hotel [(name “Rex”)]))
if the object string (of (room []) (hotel [(name
“Rex”)])) is an object string which is part of the
previous utterance.
</bodyText>
<sectionHeader confidence="0.98359" genericHeader="introduction">
3 Evaluations and results
</sectionHeader>
<bodyText confidence="0.9999398">
LOGUS is a French-speaking system. It took part
in the two evaluation campaigns that were carried
out in the last year designed for French spoken
language understanding: the GDR-I3 challenge-
based campaign and the MEDIA project.
</bodyText>
<subsectionHeader confidence="0.998531">
3.1 The GDR-I3 campaign
</subsectionHeader>
<bodyText confidence="0.997244">
LOGUS took part in the challenge-based cam-
paign, held by the GDR-I3 consortium of the
</bodyText>
<page confidence="0.989456">
54
</page>
<figure confidence="0.9994344">
After chunking process
[a l hotel] [Caumartin] [quels sont]
hotel
chunk conceptual relation
name
&amp;quot;Caumartin&amp;quot;
identity
and elimination of
of
question
what
concept
le and pour
[les tarifs]
price
of
[pour une
chambre]
room
[double]
double
size
: level 1
: level2
:level 3
</figure>
<figureCaption confidence="0.994043">
Figure 2: Characterization of chunk dependencies: example on the utterance “ a` l’hotel Caumartin quels
sont le les tarifs pour pour une chambre double” (in Caumartin hotel what are the the prices for for a
double room.
</figureCaption>
<bodyText confidence="0.994581513513513">
French CNRS research agency (Antoine et al.,
2002). We won’t describe here in detail the re-
sults of this campaign, since it concerned a for-
mer version of LOGUS. It seems however in-
teresting to analyse the distribution of the errors
made by LOGUS to have an idea of the benefits
of our approach. The evaluation corpus was di-
vided among several tests which were respectively
related to a specific difficulty: speech recognition
errors, speech repairs and other disfluences, and fi-
nally messages of a structural complexity (embed-
ded coordination or subordination, for instance)
significantly higher than those usually met in stan-
dard ATIS-like application domains.
The distribution of the concept error rates of the
LOGUS SLU system is the following:
Speech recognition: 9.5%
Complex structures: 9.8%
Repairs: 15%
It should be noted here that the robustness of
LOGUS decreases rather gracefully on complex
messages, while SLU systems based on concept
spotting meet real difficulties on such utterances.
For instance, Cacao (Bousquet-Vernhettes et al.,
1999; Bousquet-Vernhettes et al., 2003) is a con-
cept spotter which participated to the GDR-I3
campaign. It has been shown that most of its er-
rors resulted from its difficulties to resolve lexical
ambiguities in complex sentences. This observa-
tion suggests that our logical deep parsing should
fulfill better than concept spotting the needs of
complex application domains such as general pur-
pose tourist information or collaborative plan-
ning (Allen J. et al., 2002), or even multi-domain
applications (Dzikovska M. et al., 2005). Unfortu-
natedly, French evaluation campaigns have never
investigated such difficult tasks.
</bodyText>
<subsectionHeader confidence="0.990418">
3.2 The MEDIA project
</subsectionHeader>
<bodyText confidence="0.999955451612903">
MEDIA-EVALDA was an evaluation campaign
hold by the French Ministry of Research. It con-
cerned all the French laboratory working on SLU.
Once again, this evaluation investigated a rather
restricted application domain: hotel reservation.
It is well known that concept spotters fit succes-
fully such simple tasks. Nevertheless, we decided
to take part in this evaluation in order to see to
which extent LOGUS should be compared to stan-
dard concept spotters in such disavantageous con-
ditions.
Participants defined reservation scenarios which
were used to build a corpus made up of 1250
recorded dialogues. Recording used a WOZ sys-
tem simulating vocal tourist phone server (Dev-
illers et al., 2004). The MEDIA corpus, which
is made up of real-life French spontaneous dia-
logues, is surely to become a benchmark reference
for French contextual SLU.
The evaluation paradigm forced every partici-
pant to convert his own semantic representation
into a common reference, which relies-on an at-
tribute/value frame: each utterance is divided into
semantic segments, aligned on the sentence, and
each segment is represented by a triplet: (mode,
attribute, value). Relations between attributes are
represented by their order in the representation and
the composed attribute names.
Nine systems participated to this first campaign.
An error was count for any difference with one
of the elements of the reference (mode, attribute
</bodyText>
<page confidence="0.997372">
55
</page>
<table confidence="0.99954225">
System 1 2 3 4 (LOGUS) 5
Approach concept concept syntactic logical concept
spotting spotting deep parsing deep parsing spotting
Error rate 29.0% 30.3% 36.3% 37.8% 41.3%
</table>
<tableCaption confidence="0.999794">
Table 1: MEDIA results.
</tableCaption>
<bodyText confidence="0.999784576923077">
or value). Table 1 summarises the results of the
best five systems. At first glance, one should find
the reported error rates rather deceptive. How-
ever, one must realize that the test corpus involved
highly spontaneous conversational speech, with
very frequent speech disfluences. As a result,
these results should be compared, for instance,
to ASR errors rates observed on the SWITCH-
BOARD corpus (Greenberg S. et al., 2000).
LOGUS was ranked fourth and its robustness
was rather close to the best participants. Now,
if you consider that the systems ranked 1st, 2nd
and 5th were using a concept spotter, these re-
sults shows that our approach can bear compar-
ison with standard approaches even on this task.
These encouraging performances suggest that it is
possible to achieve a deep understanding of con-
versational speech while respecting at the same
time some robustness requirements: our approach
seems indeed competitive even in a domain where
concept spotters are known to be very efficient. To
our mind, the interest of our approach is that this
robustness should remain on larger application do-
mains. We are precisely trying to test this gener-
icity by adapting LOGUS to a wider application
domain in the framework of the Emotirob project.
</bodyText>
<sectionHeader confidence="0.993083" genericHeader="related work">
4 Genericity and portability experiment
</sectionHeader>
<bodyText confidence="0.999903224489796">
We are currently testing the portability of our
approach by adapting LOGUS to a really differ-
ent task, which corresponds to an unrestricted
application domain, general purpose understand-
ing of child language, with additional emotional
state detection. The whole project, supported by
ANR (National French Research Agency), aims
at achieving a robot companion which can inter-
act with sick or disabled young children with the
help of facial expressions. Although the robot
does not have to react to every speech act of the
child, we have to deal with spoken understanding
in an unrestricted domain. Fortunately, the age of
the children involved (3-5) implies a restricted vo-
cabulary. This work is still in progress. Our first
investigations suggest however that LOGUS is a
suitable understanding system for the pursued pur-
pose: since there will never be significant corpora
related to this kind of task, we can’t use statisti-
cal methods. Moreover, because of the generic-
ity of LOGUS, the main part of the analysis can
be reused without important changes. Thus, three-
month work was enough to build a first prototype
of the system and the problem is restricted to the
main problem of this project: building an ontology
which models the cognitive and emotional world
of young children.
The generality of the used formalism makes it
possible to include an emotional component by
turning the triplet structure into a quadruplet struc-
ture. Of course, composition rules have to in-
clude this new component. We are currently work-
ing on the computation of the emotional states
from both prosodic and lexical cues. Whereas
many works have investigated a prosodic-based
detection (Devillers et al., 2005), word-based ap-
proaches remain quite original. Our hypothesis is
that emotion is compositional, e.g. that is pos-
sible to compute the global emotion carried by a
sentence from the emotion of every content word.
This calculation depends obviously of the seman-
tic structure of the utterance: our system will
precisely benefit from the characterization of the
chunk dependencies carried on by LOGUS. For the
moment being, we are working on the definition of
a complete lexical norm of emotional values from
children of 3, 5 and 7 years. This norm will be
established in collaboration with psycholinguists
from Montpellier University, France.
</bodyText>
<sectionHeader confidence="0.999259" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999925777777778">
When we started implementing the LOGUS sys-
tem, one of our objectives was to achieve robust
parsing of spontaneous spoken language while
making the application domain much wider than
is currently done. Logical formalisms are not usu-
ally viewed as efficient tools for pragmatic appli-
cations. The promising results of LOGUS show
that they can be brought into interesting new ap-
proaches.
</bodyText>
<page confidence="0.988575">
56
</page>
<bodyText confidence="0.99987">
Another objective was to have a rather generic
system, despite the use of a domain-based seman-
tic knowledge. We have fulfilled this constraint
through the definition of generic predicates as
well as generic rules working on semantic triplets
or quadruplets which makes it possible to have
generic chunk linking rules. The performances of
LOGUS show that a deeper understanding can bear
comparison with concept spotting approaches.
</bodyText>
<sectionHeader confidence="0.99919" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999829354166667">
Abney S. 1991. Parsing by Chunks. Principle Based
Parsing. R. Berwick, S. Abney and C. Tenny Eds.
Kluwer Academix Publishers.
A¨ıt-Mokhtar S., Chanod J.-P. and Roux C. 2002.
Robustness beyond Shallowness: Incremental Deep
Parsing. Natural Language Engineering, 8 (2-3):
p. 121–144.
Allen J. and Ferguson G. 2002. Human-Machine Col-
laborative Planning. Proc. of the 3rd International
NASA Workshop on Planning and Scheduling for
Space, Houston, TX.
Antoine J.-Y. et al. 2002. Predictive and Ob-
jective Evaluation of Speech Understanding: the
”challenge” evaluation campaign of the I3 speech
workgroup of the french CNRS. Proceedings of
the LREC 2002, 3Td International Conference on
Language Resources and Evaluation, Las Palmas,
Spain.
Austin J.-L. 1962. How to do things with words. Ox-
ford.
Bangalore S., Hakkani-T¨ur D. and T¨ur G. 2006. Spe-
cial issue on Spoken Language Understanding in
Conversational Systems. Speech Communication.
48.
Basili R. and Zanzotto F.M. 2003. Parsing engineering
and empirical robustness. Natural Language Engi-
neering. 8 (2-3).
Bousquet-Vernhettes C., Bouraoui J.-L. and
Vigouroux N. 2003. Language Model Study for
Speech Understanding. Proc. Internationnal Work-
shop on Speech and Computer (SPECOM’2003) ,
Moscow, Russia, p. 205–208.
Bousquet-Vernhettes C., Privat R. and Vigouroux N.
2003. Error handling in spoken dialogue systems:
toward corrective dialogue. ISCA workshop on Er-
ror Handling in Spoken Dialogue Systems, Chteau-
d’Oex-Vaud, Suisse, p. 41–45.
Bousquet-Vernhettes C., Vigouroux N. and P´erennou
G. 1999. Stochastic Conceptual Model for Spo-
ken Language Understanding. Proc. Internationnal
Workshop on Speech and Computer (SPECOM’99) ,
Moscow, Russia, p. 71–74.
Devillers L. et al. 2004. The French Evalda-Media
project: the evaluation of the understanding ca-
pabilities of Spoken Language Dialogue Systems.
Proceedings of the LREC 2004, 4Td International
Conference on Language Resources and Evaluation,
Lisboa, Portugal.
Devillers L., Vidrascu, L. and Lamel, L. 2005. Chal-
lenges in real-life emotion annotation and machine
learning based detection. Neural Networks, 18, p.
407-422.
Dzikovska M., Swift M. and Allen J. and de Beau-
mont W. 2005. Generic parsing for multi-domain
semantic interpretation. Proc. 9th International
Workshop on Parsing Technologies (IWPT05)), Van-
couver BC.
Greenberg S. and Chang, S. 2000. Linguistic dissec-
tion of switchboard-corpus automatic speech recog-
nition systems. Proc. ISCA Workshop on Automatic
Speech Recognition: Challenges for the New Mil-
lennium, Paris, France.
Heeman P. and Allen J. 2001. Improving robustness
by modeling spontaneous events. Robustness in lan-
guage and speech technology, Kluwer Academics.
Dordrecht, NL. p. 123–152.
Lambek J. 1999. Type grammars revisited. Logical
Aspects of Computational Linguistics, A. Lecomte,
F. Lamarche and G. Perrier (eds), LNAI 1582,
Springer, Berlin, p. 1–27.
Mc Kelvie D. 1998. The syntax of disfluency in spon-
taneous spoken language. HCRC Research Paper,
HCRC/RP-95.
McShane M. 2005. Semantics-based resolution of
fragments and underspecified structures. Traitement
Automatique des Langues, 46(1): p. 163–184.
Minker W., Waibel A. and Mariani J.. 1999. Stochas-
tically based semantic analysis. Kluwer Ac., Ams-
terdam, The Netherlands.
Vanderveken D. 2001. Universal Grammar and
Speech act Theory. Essays in Speech Act The-
ory. Eds J. Benjamin, D. Vanderveken and S. Kubo,
p. 25–62.
van Noord G., Bouma G. and Koeling R. and Nederhof
M. 1999. Robust grammatical analysis for spoken
dialogue systems. Natural Language Engineering.
5(1): p. 45–93.
Zechner K. 1998. Automatic construction of frame
representations for spontaneous speech in unre-
stricted domains. COLING-ACL’1998. Montreal,
Canada. p. 1448–1452.
Zue V., Seneff S., Glass J., Polifrini J., Pao C., Hazen
T.J. and Hetherington L. 2000. Jupiter: a telephone-
based conversational interface for weather informa-
tion. IEEE Transactions on speech and audio pro-
cessing. 8(1).
</reference>
<page confidence="0.999138">
57
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.386017">
<title confidence="0.9573385">Deeper spoken language understanding for man-machine dialogue on broader application domains: a logical alternative to concept spotting</title>
<author confidence="0.965613">Jeanne Villaneau Jean-Yves Antoine</author>
<affiliation confidence="0.839809333333333">(Universit´e Europ´eenne de Bretagne) Universit´e Rabelais - Tours VALORIA LI France France</affiliation>
<email confidence="0.674524">villanea@univ-ubs.frJean-Yves.Antoine@univ-tours.fr</email>
<abstract confidence="0.99750876">a French-speaking spoken language understanding (SLU) system which carries out a deeper analysis than those achieved by standard concept spotters. It is designed for multi-domain conversational systems or for systems that are working on complex application domains. Based on a logical approach, the system adapts the ideas of incremental robust parsing to the issue of SLU. The paper provides a detailed description of the system as well as results from two evaluation campaigns that concerned all of current French-speaking SLU systems. The observed error rates suggest that our logical approach can stand comparison with concept spotters on restricted application domains, but also that its behaviour is promising for larger domains. The question of the generality of the approach is precisely addressed by our current investigations on a new task: SLU for an emotional robot companion for young hospital patents.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Abney</author>
</authors>
<title>Parsing by Chunks. Principle Based Parsing.</title>
<date>1991</date>
<publisher>Kluwer Academix Publishers.</publisher>
<marker>Abney, 1991</marker>
<rawString>Abney S. 1991. Parsing by Chunks. Principle Based Parsing. R. Berwick, S. Abney and C. Tenny Eds. Kluwer Academix Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S A¨ıt-Mokhtar</author>
<author>J-P Chanod</author>
<author>C Roux</author>
</authors>
<title>Robustness beyond Shallowness: Incremental Deep Parsing.</title>
<date>2002</date>
<journal>Natural Language Engineering,</journal>
<volume>8</volume>
<pages>2--3</pages>
<marker>A¨ıt-Mokhtar, Chanod, Roux, 2002</marker>
<rawString>A¨ıt-Mokhtar S., Chanod J.-P. and Roux C. 2002. Robustness beyond Shallowness: Incremental Deep Parsing. Natural Language Engineering, 8 (2-3): p. 121–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Allen</author>
<author>G Ferguson</author>
</authors>
<title>Human-Machine Collaborative Planning.</title>
<date>2002</date>
<booktitle>Proc. of the 3rd International NASA Workshop on Planning and Scheduling for Space,</booktitle>
<location>Houston, TX.</location>
<marker>Allen, Ferguson, 2002</marker>
<rawString>Allen J. and Ferguson G. 2002. Human-Machine Collaborative Planning. Proc. of the 3rd International NASA Workshop on Planning and Scheduling for Space, Houston, TX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-Y Antoine</author>
</authors>
<title>Predictive and Objective Evaluation of Speech Understanding: the ”challenge” evaluation campaign of the I3 speech workgroup of the french CNRS.</title>
<date>2002</date>
<booktitle>Proceedings of the LREC 2002, 3Td International Conference on Language Resources and Evaluation,</booktitle>
<location>Las Palmas,</location>
<marker>Antoine, 2002</marker>
<rawString>Antoine J.-Y. et al. 2002. Predictive and Objective Evaluation of Speech Understanding: the ”challenge” evaluation campaign of the I3 speech workgroup of the french CNRS. Proceedings of the LREC 2002, 3Td International Conference on Language Resources and Evaluation, Las Palmas, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-L Austin</author>
</authors>
<title>How to do things with words.</title>
<date>1962</date>
<location>Oxford.</location>
<marker>Austin, 1962</marker>
<rawString>Austin J.-L. 1962. How to do things with words. Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bangalore</author>
<author>D Hakkani-T¨ur</author>
<author>G T¨ur</author>
</authors>
<title>Special issue on Spoken Language Understanding in Conversational Systems.</title>
<date>2006</date>
<journal>Speech Communication.</journal>
<volume>48</volume>
<marker>Bangalore, Hakkani-T¨ur, T¨ur, 2006</marker>
<rawString>Bangalore S., Hakkani-T¨ur D. and T¨ur G. 2006. Special issue on Spoken Language Understanding in Conversational Systems. Speech Communication. 48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Basili</author>
<author>F M Zanzotto</author>
</authors>
<title>Parsing engineering and empirical robustness.</title>
<date>2003</date>
<journal>Natural Language Engineering.</journal>
<volume>8</volume>
<pages>2--3</pages>
<marker>Basili, Zanzotto, 2003</marker>
<rawString>Basili R. and Zanzotto F.M. 2003. Parsing engineering and empirical robustness. Natural Language Engineering. 8 (2-3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Bousquet-Vernhettes</author>
<author>J-L Bouraoui</author>
<author>N Vigouroux</author>
</authors>
<title>Language Model Study for Speech Understanding.</title>
<date>2003</date>
<booktitle>Proc. Internationnal Workshop on Speech and Computer (SPECOM’2003) ,</booktitle>
<pages>205--208</pages>
<location>Moscow, Russia,</location>
<contexts>
<context position="22822" citStr="Bousquet-Vernhettes et al., 2003" startWordPosition="3704" endWordPosition="3707">her disfluences, and finally messages of a structural complexity (embedded coordination or subordination, for instance) significantly higher than those usually met in standard ATIS-like application domains. The distribution of the concept error rates of the LOGUS SLU system is the following: Speech recognition: 9.5% Complex structures: 9.8% Repairs: 15% It should be noted here that the robustness of LOGUS decreases rather gracefully on complex messages, while SLU systems based on concept spotting meet real difficulties on such utterances. For instance, Cacao (Bousquet-Vernhettes et al., 1999; Bousquet-Vernhettes et al., 2003) is a concept spotter which participated to the GDR-I3 campaign. It has been shown that most of its errors resulted from its difficulties to resolve lexical ambiguities in complex sentences. This observation suggests that our logical deep parsing should fulfill better than concept spotting the needs of complex application domains such as general purpose tourist information or collaborative planning (Allen J. et al., 2002), or even multi-domain applications (Dzikovska M. et al., 2005). Unfortunatedly, French evaluation campaigns have never investigated such difficult tasks. 3.2 The MEDIA projec</context>
</contexts>
<marker>Bousquet-Vernhettes, Bouraoui, Vigouroux, 2003</marker>
<rawString>Bousquet-Vernhettes C., Bouraoui J.-L. and Vigouroux N. 2003. Language Model Study for Speech Understanding. Proc. Internationnal Workshop on Speech and Computer (SPECOM’2003) , Moscow, Russia, p. 205–208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Bousquet-Vernhettes</author>
<author>R Privat</author>
<author>N Vigouroux</author>
</authors>
<title>Error handling in spoken dialogue systems: toward corrective dialogue.</title>
<date>2003</date>
<booktitle>ISCA workshop on Error Handling in Spoken Dialogue Systems, Chteaud’Oex-Vaud, Suisse,</booktitle>
<pages>41--45</pages>
<contexts>
<context position="22822" citStr="Bousquet-Vernhettes et al., 2003" startWordPosition="3704" endWordPosition="3707">her disfluences, and finally messages of a structural complexity (embedded coordination or subordination, for instance) significantly higher than those usually met in standard ATIS-like application domains. The distribution of the concept error rates of the LOGUS SLU system is the following: Speech recognition: 9.5% Complex structures: 9.8% Repairs: 15% It should be noted here that the robustness of LOGUS decreases rather gracefully on complex messages, while SLU systems based on concept spotting meet real difficulties on such utterances. For instance, Cacao (Bousquet-Vernhettes et al., 1999; Bousquet-Vernhettes et al., 2003) is a concept spotter which participated to the GDR-I3 campaign. It has been shown that most of its errors resulted from its difficulties to resolve lexical ambiguities in complex sentences. This observation suggests that our logical deep parsing should fulfill better than concept spotting the needs of complex application domains such as general purpose tourist information or collaborative planning (Allen J. et al., 2002), or even multi-domain applications (Dzikovska M. et al., 2005). Unfortunatedly, French evaluation campaigns have never investigated such difficult tasks. 3.2 The MEDIA projec</context>
</contexts>
<marker>Bousquet-Vernhettes, Privat, Vigouroux, 2003</marker>
<rawString>Bousquet-Vernhettes C., Privat R. and Vigouroux N. 2003. Error handling in spoken dialogue systems: toward corrective dialogue. ISCA workshop on Error Handling in Spoken Dialogue Systems, Chteaud’Oex-Vaud, Suisse, p. 41–45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Bousquet-Vernhettes</author>
<author>N Vigouroux</author>
<author>G P´erennou</author>
</authors>
<title>Stochastic Conceptual Model for Spoken Language Understanding.</title>
<date>1999</date>
<booktitle>Proc. Internationnal Workshop on Speech and Computer (SPECOM’99) ,</booktitle>
<pages>71--74</pages>
<location>Moscow, Russia,</location>
<marker>Bousquet-Vernhettes, Vigouroux, P´erennou, 1999</marker>
<rawString>Bousquet-Vernhettes C., Vigouroux N. and P´erennou G. 1999. Stochastic Conceptual Model for Spoken Language Understanding. Proc. Internationnal Workshop on Speech and Computer (SPECOM’99) , Moscow, Russia, p. 71–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Devillers</author>
</authors>
<title>The French Evalda-Media project: the evaluation of the understanding capabilities of Spoken Language Dialogue Systems.</title>
<date>2004</date>
<booktitle>Proceedings of the LREC 2004, 4Td International Conference on Language Resources and Evaluation,</booktitle>
<location>Lisboa, Portugal.</location>
<marker>Devillers, 2004</marker>
<rawString>Devillers L. et al. 2004. The French Evalda-Media project: the evaluation of the understanding capabilities of Spoken Language Dialogue Systems. Proceedings of the LREC 2004, 4Td International Conference on Language Resources and Evaluation, Lisboa, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Devillers</author>
<author>L Vidrascu</author>
<author>L Lamel</author>
</authors>
<title>Challenges in real-life emotion annotation and machine learning based detection.</title>
<date>2005</date>
<journal>Neural Networks,</journal>
<volume>18</volume>
<pages>407--422</pages>
<contexts>
<context position="28005" citStr="Devillers et al., 2005" startWordPosition="4531" endWordPosition="4534">th work was enough to build a first prototype of the system and the problem is restricted to the main problem of this project: building an ontology which models the cognitive and emotional world of young children. The generality of the used formalism makes it possible to include an emotional component by turning the triplet structure into a quadruplet structure. Of course, composition rules have to include this new component. We are currently working on the computation of the emotional states from both prosodic and lexical cues. Whereas many works have investigated a prosodic-based detection (Devillers et al., 2005), word-based approaches remain quite original. Our hypothesis is that emotion is compositional, e.g. that is possible to compute the global emotion carried by a sentence from the emotion of every content word. This calculation depends obviously of the semantic structure of the utterance: our system will precisely benefit from the characterization of the chunk dependencies carried on by LOGUS. For the moment being, we are working on the definition of a complete lexical norm of emotional values from children of 3, 5 and 7 years. This norm will be established in collaboration with psycholinguists</context>
</contexts>
<marker>Devillers, Vidrascu, Lamel, 2005</marker>
<rawString>Devillers L., Vidrascu, L. and Lamel, L. 2005. Challenges in real-life emotion annotation and machine learning based detection. Neural Networks, 18, p. 407-422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dzikovska</author>
<author>M Swift</author>
<author>J Allen</author>
<author>W de Beaumont</author>
</authors>
<title>Generic parsing for multi-domain semantic interpretation.</title>
<date>2005</date>
<booktitle>Proc. 9th International Workshop on Parsing Technologies (IWPT05)),</booktitle>
<location>Vancouver BC.</location>
<marker>Dzikovska, Swift, Allen, de Beaumont, 2005</marker>
<rawString>Dzikovska M., Swift M. and Allen J. and de Beaumont W. 2005. Generic parsing for multi-domain semantic interpretation. Proc. 9th International Workshop on Parsing Technologies (IWPT05)), Vancouver BC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Greenberg</author>
<author>S Chang</author>
</authors>
<title>Linguistic dissection of switchboard-corpus automatic speech recognition systems.</title>
<date>2000</date>
<booktitle>Proc. ISCA Workshop on Automatic Speech Recognition: Challenges for the</booktitle>
<location>New Millennium, Paris, France.</location>
<marker>Greenberg, Chang, 2000</marker>
<rawString>Greenberg S. and Chang, S. 2000. Linguistic dissection of switchboard-corpus automatic speech recognition systems. Proc. ISCA Workshop on Automatic Speech Recognition: Challenges for the New Millennium, Paris, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Heeman</author>
<author>J Allen</author>
</authors>
<title>Improving robustness by modeling spontaneous events. Robustness in language and speech technology, Kluwer Academics.</title>
<date>2001</date>
<pages>123--152</pages>
<location>Dordrecht, NL.</location>
<marker>Heeman, Allen, 2001</marker>
<rawString>Heeman P. and Allen J. 2001. Improving robustness by modeling spontaneous events. Robustness in language and speech technology, Kluwer Academics. Dordrecht, NL. p. 123–152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lambek</author>
</authors>
<title>Type grammars revisited. Logical Aspects of Computational Linguistics,</title>
<date>1999</date>
<volume>LNAI</volume>
<pages>1582</pages>
<publisher>Springer,</publisher>
<location>Berlin,</location>
<marker>Lambek, 1999</marker>
<rawString>Lambek J. 1999. Type grammars revisited. Logical Aspects of Computational Linguistics, A. Lecomte, F. Lamarche and G. Perrier (eds), LNAI 1582, Springer, Berlin, p. 1–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mc Kelvie D</author>
</authors>
<title>The syntax of disfluency in spontaneous spoken language.</title>
<date>1998</date>
<journal>HCRC Research Paper,</journal>
<pages>95</pages>
<marker>D, 1998</marker>
<rawString>Mc Kelvie D. 1998. The syntax of disfluency in spontaneous spoken language. HCRC Research Paper, HCRC/RP-95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M McShane</author>
</authors>
<title>Semantics-based resolution of fragments and underspecified structures.</title>
<date>2005</date>
<booktitle>Traitement Automatique des Langues,</booktitle>
<volume>46</volume>
<issue>1</issue>
<pages>163--184</pages>
<marker>McShane, 2005</marker>
<rawString>McShane M. 2005. Semantics-based resolution of fragments and underspecified structures. Traitement Automatique des Langues, 46(1): p. 163–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Minker</author>
<author>A Waibel</author>
<author>J Mariani</author>
</authors>
<title>Stochastically based semantic analysis. Kluwer Ac.,</title>
<date>1999</date>
<location>Amsterdam, The Netherlands.</location>
<marker>Minker, Waibel, Mariani, 1999</marker>
<rawString>Minker W., Waibel A. and Mariani J.. 1999. Stochastically based semantic analysis. Kluwer Ac., Amsterdam, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Vanderveken</author>
</authors>
<title>Universal Grammar and Speech act Theory. Essays in Speech Act Theory. Eds</title>
<date>2001</date>
<pages>25--62</pages>
<marker>Vanderveken, 2001</marker>
<rawString>Vanderveken D. 2001. Universal Grammar and Speech act Theory. Essays in Speech Act Theory. Eds J. Benjamin, D. Vanderveken and S. Kubo, p. 25–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G van Noord</author>
<author>G Bouma</author>
<author>R Koeling</author>
<author>M Nederhof</author>
</authors>
<title>Robust grammatical analysis for spoken dialogue systems.</title>
<date>1999</date>
<journal>Natural Language Engineering.</journal>
<volume>5</volume>
<issue>1</issue>
<pages>45--93</pages>
<marker>van Noord, Bouma, Koeling, Nederhof, 1999</marker>
<rawString>van Noord G., Bouma G. and Koeling R. and Nederhof M. 1999. Robust grammatical analysis for spoken dialogue systems. Natural Language Engineering. 5(1): p. 45–93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Zechner</author>
</authors>
<title>Automatic construction of frame representations for spontaneous speech in unrestricted domains.</title>
<date>1998</date>
<booktitle>COLING-ACL’1998.</booktitle>
<pages>1448--1452</pages>
<location>Montreal,</location>
<marker>Zechner, 1998</marker>
<rawString>Zechner K. 1998. Automatic construction of frame representations for spontaneous speech in unrestricted domains. COLING-ACL’1998. Montreal, Canada. p. 1448–1452.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Zue</author>
<author>S Seneff</author>
<author>J Glass</author>
<author>J Polifrini</author>
<author>C Pao</author>
<author>T J Hazen</author>
<author>L Hetherington</author>
</authors>
<title>Jupiter: a telephonebased conversational interface for weather information.</title>
<date>2000</date>
<journal>IEEE Transactions on speech and</journal>
<contexts>
<context position="2794" citStr="Zue et al., 2000" startWordPosition="419" endWordPosition="422">der to build a semantic representation that represents its propositional meaning. Finally, this semantic structure is sent to a dialogue manager which controls the interaction with the user (database interrogation, dialogue management, answer generation). The answers to the user can be displayed on screen and/or through a message generated by a text-tospeech synthesis. This paper focuses on the SLU module of such a dialogue system. On the whole, SLU has to cope with two main difficulties: • speech recognition errors: highly spontaneous speech remains hard to recognize for current ASR systems (Zue et al., 2000). Therefore, the SLU module has to work on a strongly corrupted string of words. • spoken disfluencies: filled pauses, repetitions and repairs make the parsing of conversational spoken language significantly harder to achieve (Heeman, Allen, 2001). In order to overcome those difficulties, most SLU systems follow a selective strategy which comes down to a simple concept spotting: they restrict the semantic analysis to a mapping of the sentence with the main expectations of the user in relation with the task (Minker W. et al., 1999; Bangalore S. et al., 2006). Consider, for instance, an air tran</context>
</contexts>
<marker>Zue, Seneff, Glass, Polifrini, Pao, Hazen, Hetherington, 2000</marker>
<rawString>Zue V., Seneff S., Glass J., Polifrini J., Pao C., Hazen T.J. and Hetherington L. 2000. Jupiter: a telephonebased conversational interface for weather information. IEEE Transactions on speech and audio processing. 8(1).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>