<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000934">
<title confidence="0.935385">
Linköping: Cubic-Time Graph Parsing with a Simple Scoring Scheme
</title>
<author confidence="0.996329">
Marco Kuhlmann
</author>
<affiliation confidence="0.9714735">
Dept. of Computer and Information Science
Linköping University, Sweden
</affiliation>
<email confidence="0.996214">
marco.kuhlmann@liu.se
</email>
<sectionHeader confidence="0.997352" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999638111111111">
We turn the Eisner algorithm for parsing
to projective dependency trees into a cubic-
time algorithm for parsing to a restricted
class of directed graphs. To extend the algo-
rithm into a data-driven parser, we combine
it with an edge-factored feature model and
online learning. We report and discuss re-
sults on the SemEval-2014 Task 8 data sets
(Oepen et al., 2014).
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999982904761905">
This paper describes the system that we submit-
ted to the closed track of the SemEval-2014 Task
on Broad-Coverage Semantic Dependency Parsing
(Oepen et al., 2014).1 However, the main contribu-
tion of the paper is not the system as such (which
had the lowest score among all systems submitted
to the task), but the general approach for which it
is a proof of concept.
Graphs support natural representations of lin-
guistic structure. For this reason, algorithms that
can learn, process and transform graphs are of cen-
tral importance to language technology. Yet, most
of the algorithms that are used in natural language
processing today focus on the restricted case of
trees, and do so for a reason: Computation on gen-
eral graphs is hard or even intractable, and efficient
processing is possible only for restricted classes (cf.
Courcelle and Engelfriet (2012)). The task then
is to identify classes of graphs that are both ex-
pressive enough to cover the linguistic data, and
restricted enough to facilitate efficient processing.
</bodyText>
<footnote confidence="0.922991">
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
1https://github.com/liu-nlp/gamma
</footnote>
<bodyText confidence="0.9999558">
This paper shows that there are graphs that sat-
isfy both of these desiderata. Our system is based
on a new algorithm for parsing to a restricted class
of directed graphs (Section 2). This class is re-
stricted in so far as our algorithm runs in cubic
time with respect to the length of the sentence; it
thus has the same asymptotic complexity as parsing
with context-free phrase structure grammars. The
class of graphs defined by our algorithm is also
expressive, in so far that it covers more than 98%
of the SemEval data.
To demonstrate that our parsing algorithm can be
turned into a practical system, we combine it with
two techniques taken straight from the literature on
data-driven syntactic dependency parsing:
</bodyText>
<listItem confidence="0.9693046">
• an edge-factored scoring model, as it has been
used as the core of practical parsers since the
seminal work of McDonald et al. (2005), and
• online learning using the structured percep-
tron, in the style of Collins (2002).
</listItem>
<bodyText confidence="0.999905888888889">
State-of-the-art parsers use considerably more ad-
vanced (and computationally more demanding)
techniques, and therefore our system cannot be
expected to deliver competitive results. (Its results
on the SemEval data are reported in Section 4.)
Instead, the main point of our contribution to the
SemEval Task is to provide evidence that research
on classes of graphs that balance linguistic cover-
age and parsing efficiency holds a lot of potential.
</bodyText>
<sectionHeader confidence="0.939186" genericHeader="method">
2 Parsing Algorithm
</sectionHeader>
<bodyText confidence="0.9997105">
We start the description of our system with the
description of our cubic-time parsing algorithm.
The remaining components of our system will be
described in Section 3.
</bodyText>
<page confidence="0.989037">
395
</page>
<note confidence="0.7354735">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 395–399,
Dublin, Ireland, August 23-24, 2014.
</note>
<bodyText confidence="0.476010333333333">
Items: 1 &lt; i &lt; j &lt; n Axioms: Goal:
i j i j i j i j i i i i 1 n
i j � 1 jk i j j k
</bodyText>
<figure confidence="0.475981">
Rules: ATTACH-R COMPLETE-R
i k i k
</figure>
<figureCaption confidence="0.9698205">
Figure 1: The Eisner algorithm for building the packed forest of all projective dependency trees with n
nodes. Only the rightward versions of ATTACH and COMPLETE are shown here.
</figureCaption>
<subsectionHeader confidence="0.998737">
2.1 The Eisner Algorithm
</subsectionHeader>
<bodyText confidence="0.961043210526316">
We recall the algorithm for projective dependency
parsing by Eisner and Satta (1999). The declara-
tive specification of this algorithm in terms of a
deduction system (Shieber et al., 1995) is given in
Figure 1. The algorithm uses four types of items,
, , , and , and two types of inference rules
called ATTACH and COMPLETE. These rules can be
interpreted as operations on graphs: An ATTACH
rule concatenates two graphs and adds one of two
possible edges—from the left endpoint of the first
graph to the right endpoint of the second graph, or
vice versa. Similarly, a COMPLETE rule fuses two
graphs by unifying the right endpoint of the first
with the left endpoint of the second. The algorithm
by Eisner and Satta (1999) produces a compact
representation of the set of all dependency graphs
over the input sentence that can be built using these
operations. This is exactly the set of projective
dependency trees for the input sentence.
</bodyText>
<subsectionHeader confidence="0.999757">
2.2 The Graph-Parsing Algorithm
</subsectionHeader>
<bodyText confidence="0.899765052631579">
To parse to dependency graphs rather than trees,
we modify the Eisner algorithm as follows:
• We give up the distinction between and .
This distinction is essential for ensuring that
the parser builds a tree. Since our goal is to
parse to graphs, we do not need it.
• We allow ATTACH to add one, zero, or several
edges. This modification makes it possible to
parse graphs with reentrancies (several incom-
ing edges) and isolated nodes.
To implement the first modification, we introduce
a new type of items, , that subsumes and .
To implement the second modification, we
parametrize the ATTACH rule by a set ! that spec-
ifies the edges that are added during the concate-
nation. We refer to the left and right endpoints of
a graph as its ports and number the ports of the
antecedents of the ATTACH rule left-to-right from 1
to 4. A set ! then takes the form
! c ({1; 21 x {3; 4}) U ({3; 41 x {1; 21):
The rule ATTACH! adds an edge u --* v if and
only if u and v are nodes corresponding to ports
s and t, respectively, and .s; t/ E !. For example,
the ATTACH rule in Figure 1 is specified by the
set ! = {.1; 4/}: it adds one edge, from the left
endpoint of the graph corresponding to the first
antecedent to the right endpoint of the other graph.
The complete parsing algorithm is specified in
Figure 2, where the rule CONC (for concatenation)
corresponds to the two conflated ATTACH rules and
FUSE corresponds to the two COMPLETE rules. In-
specting the specification, we find that the algo-
rithm runs in time O.mn3/ where n is the number
of nodes and m is the number of concatenation
rules. Note that, because each concatenation rule
is determined by a set ! as defined above, each
parser in our framework can use at most 28 = 256
different CONC rules.2
</bodyText>
<sectionHeader confidence="0.999245" genericHeader="method">
3 Data-Driven Parsing
</sectionHeader>
<bodyText confidence="0.9998035">
We now extend our parsing algorithm into a simple
parser for data-driven parsing. We cast parsing
as an optimization problem over a parametrized
scoring function: Given a sentence x we compute
</bodyText>
<equation confidence="0.989973">
y� = arg max s.x; y/ (1)
y2Y.x/
</equation>
<bodyText confidence="0.999215166666667">
where 2J.x/ is the set of candidate graphs for x and
the scoring function is decomposed as s.x; y/ =
B • f .x; y/. The function f returns a high-dimen-
sional feature vector that describes characteristic
properties of the sentence–graph pair .x; y/, and
the vector B assigns to each feature a weight.
</bodyText>
<footnote confidence="0.9842165">
2This is because a set ! specifies up to 2 x 2 + 2 x 2 = 8
different concatenation operations.
</footnote>
<page confidence="0.99433">
396
</page>
<figure confidence="0.9662628">
Items: 1 &lt; i &lt; j &lt; n Axioms: Goal:
i j i j i j i i i i 1 n
i j - 1 j k i j j k i j j k
Rules: CONC! FUSE-L FUSE-R
i k i k i k
</figure>
<figureCaption confidence="0.9862585">
Figure 2: The parsing algorithm used in this paper. The concatenation rules (CONC) are parametrized with
respect to an edge specification w (see Section 2.2).
</figureCaption>
<subsectionHeader confidence="0.999428">
3.1 Candidate Graphs
</subsectionHeader>
<bodyText confidence="0.999970958333333">
Our set of candidate graphs is the set of all graphs
that can be built using the operations of our pars-
ing algorithm. The size of this set and hence the
maximal coverage of our parser is determined by
the set of CONC rules: The more different concate-
nation operations we use, the more graphs we can
build. At the same time, increasing the number of
operations also increases the runtime of our parser.
This means that we need to find a good trade-off
between coverage and parsing efficiency.
To obtain upper bounds on the coverage of our
parser we compute, for each graph G in the Sem-
Eval test data, a graph G that maximizes the set
of edges that it has in common with G. This can
be done using a Viterbi-style variant of our parsing
algorithm that scores an item by the number of
edges that it has in common with G. The results are
reported in Table 1. As we can see, our approach
has the potential to achieve more than 98% labelled
recall (LR) on all three representation types used
in the task. This figure is obtained for the full set
of concatenation operations. For our submission
we chose to optimize for parsing speed and used a
parser with a reduced set of only three operations:
</bodyText>
<equation confidence="0.964378">
w1 = {(1, 4/}, w2 = {(4, 1/}, w3 = {} :
</equation>
<bodyText confidence="0.9964028">
These are the two operations that correspond to
the ATTACH rules of the algorithm by Eisner and
Satta (w1, w2), together with the operation that
concatenates two graphs without adding any edges
at all (w3). The latter is required to produce graphs
</bodyText>
<table confidence="0.590300333333333">
DM PAS PCEDT
full 98.25/75.74 98.13/69.81 98.19/ 83.23
reduced 95.70/52.15 93.06/23.66 93.51/54.75
</table>
<tableCaption confidence="0.9544295">
Table 1: Upper bounds for recall (LR/LM) on the
test data for two different sets of operations.
</tableCaption>
<bodyText confidence="0.999953571428571">
where a node has no incoming edges. As can be
seen in Table 1, the upper bounds for the reduced
set of operations are still surprisingly high when
measured in terms of LR: 95.70% for DM, 93.06%
for PAS, and 93.51% for PCEDT. However, there
is a significant loss when coverage is measured in
terms of labelled exact match (LM).
</bodyText>
<subsectionHeader confidence="0.999759">
3.2 Scoring Function
</subsectionHeader>
<bodyText confidence="0.999839583333333">
We use the same features as in the first-order model
implemented in the MSTParser system for syntac-
tic dependency parsing (McDonald et al., 2005).3
Under this model, the feature vector for a depen-
dency graph is the sum of the feature vectors of
its edges, which take into account atomic features
such as the word forms and part-of-speech tags of
the tokens connected by the edge, the length of the
edge, the edge label, as well as combinations of
those atomic features. To set the feature weights
we use averaged perceptron training in the style of
Collins (2002).
</bodyText>
<subsectionHeader confidence="0.998934">
3.3 Top-Node Tagger
</subsectionHeader>
<bodyText confidence="0.999891357142857">
The final component in our system is a simple tag-
ger that is used to annotate the output of our parser
with information about top nodes (as defined in the
task’s data format). It is based on Matthew Honni-
bal’s part-of-speech tagger4 and uses features based
on the word form and part-of-speech of the node
to be tagged, as well as the labels of the edges in-
cident to that node; these features were selected
based on tagging accuracy with the recommended
development train/dev-split. The tagger is a se-
quence model without global constraints; in partic-
ular, it does not enforce unique top nodes. Tagging
accuracy on the final test set was 98.50% for DM,
99.21% for PAS, and 99.94% for PCEDT.
</bodyText>
<footnote confidence="0.9999135">
3http://sourceforge.net/projects/mstparser/
4http://honnibal.wordpress.com/
</footnote>
<page confidence="0.988561">
397
</page>
<table confidence="0.996791333333333">
DM PAS PCEDT
LP LR LF LP LR LF LP LR LF
Baseline 83.20% 40.73% 54.68% 88.34% 35.74% 50.89% 74.82% 62.08% 67.84%
Linköping 78.54% 78.05% 78.29% 76.16% 75.55% 75.85% 60.66% 64.35% 62.45%
Task average 84.21% 81.29% 82.69% 87.95% 83.57% 85.65% 72.17% 68.44% 70.21%
Peking 90.27% 88.54% 89.40% 93.44% 90.69% 92.04% 78.75% 73.96% 76.28%
</table>
<tableCaption confidence="0.991475">
Table 2: Labelled precision (LP), labelled recall (LR), and labelled F1 (LF) scores of our own system
</tableCaption>
<bodyText confidence="0.503015">
(Linköping) and three points of comparison on the SemEval-2014 Task 8 test data: baseline, task average,
and the best-performing system from Peking University (Du et al., 2014).
</bodyText>
<sectionHeader confidence="0.998441" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999980466666667">
We report experimental results on the SemEval data
sets (closed track). We trained one parser for each
representation (DM, PAS, PCEDT). Averaged per-
ceptron training can be parametrized by the number
N of iterations over the training data; to determine
the value of this parameter, for each representation
type and each 1 &lt; N &lt; 10 we trained a develop-
ment system using the recommended development
train/dev-split and selected that value of N which
gave the highest accuracy on the held-out data. The
selected values and the number of (binary) features
in the resulting systems are reported in Table 3.
Training took around 8 minutes per iteration on an
iMac computer (Late 2013, 3,4 GHz Intel Core i5)
with a 6 GB Java heap size.
</bodyText>
<subsectionHeader confidence="0.840059">
4.1 Results
</subsectionHeader>
<bodyText confidence="0.9997470625">
Table 2 reports the labelled precision (LP) and la-
belled recall (LR) of our system on the final test
data. Compared to the tree-based baseline, our
system has substantially lower precision (between
4.66 and 14.16 points) but substantially higher re-
call (between 2.27 and 39.81 points). Compared to
the top-scoring system, our system is way behind
in terms of both scores (11.11–16.19 points). The
scores of our system are also substantially below
the task average, which resulted in it being ranked
last of all six systems participating in the closed
track. Given these results, we have refrained from
doing a detailed error analysis. It may be interest-
ing to note, however, that our system is the only
one in the task for which labelled F1 is higher on
the DM data than on the PAS data.
</bodyText>
<table confidence="0.903723333333333">
DM PAS PCEDT
# iterations 4 1 9
# features 7.3M 8.7M 8.1M
</table>
<tableCaption confidence="0.999829">
Table 3: Characteristics of the trained models.
</tableCaption>
<subsectionHeader confidence="0.87568">
4.2 Discussion
</subsectionHeader>
<bodyText confidence="0.9999663125">
The comparatively low scores of our system do not
come unexpected. Our parser uses a very simple
scoring model and learning method, whereas even
the baseline relies on a state-of-the-art syntactic de-
pendency parser (Bohnet, 2010). Also, we did not
do any feature engineering (on the parser), but just
used the feature extraction procedure of MSTParser.
Regarding both of these points, the potential for
improving the system is apparent. Finally, our post-
hoc prediction of top nodes is extremely simplistic.
It would have been much more desirable to inte-
grate this prediction into the parser, for example
by adding virtual incoming dependencies to all top
nodes. However, preliminary experiments showed
that this particular strategy had a severely negative
impact on coverage.
</bodyText>
<sectionHeader confidence="0.999449" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.99998880952381">
We have presented a new algorithm for parsing to
a restricted class of digraphs and shown how to
extend this algorithm into a system for data-driven
dependency parsing. Our main goal was to show
that it is possible to develop algorithms for direct
parsing to directed graphs that are both efficient
and achieve good coverage on practical data sets:
Our algorithm runs in cubic time in the length of
the sentence, and has more than 98% coverage on
each of the three data sets.
Our future work will address both theoretical and
practical issues. On the theoretical side, we feel
that it is important to obtain a better understanding
of the specific graph-structural properties that char-
acterise the linguistic data. Our parser provides an
operational definition of a class of graphs (those
graphs that can be built by the parser); it would be
more satisfying to obtain a declarative characteri-
sation that does not depend on a specific algorithm.
Such a characterisation would be interesting even
for a restricted set of operations.
</bodyText>
<page confidence="0.996">
398
</page>
<bodyText confidence="0.999918285714286">
On the practical side, we would like to extend
our approach into a more competitive system for
semantic dependency parsing. In particular, we
would like to use a more powerful scoring function
(incorporating second- and third-order features)
and a more predicative learning method (such as
max-margin training).
</bodyText>
<sectionHeader confidence="0.9964" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999911">
We thank the two anonymous reviewers of this
paper for their detailed and constructive comments.
</bodyText>
<sectionHeader confidence="0.999427" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999898720930232">
Bernd Bohnet. 2010. Very high accuracy and fast de-
pendency parsing is not a contradiction. In Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics (COLING), pages 89–97, Bei-
jing, China.
Michael Collins. 2002. Discriminative training meth-
ods for Hidden Markov Models: Theory and ex-
periments with perceptron algorithms. In Proceed-
ings of the Conference on Empirical Methods in
Natural Language Processing (EMNLP), pages 1–8,
Philadelphia, USA.
Bruno Courcelle and Joost Engelfriet. 2012. Graph
Structure and Monadic Second-Order Logic, volume
138 of Encyclopedia of Mathematics and itsApplica-
tions. Cambridge University Press.
Yantao Du, Fan Zhang, Weiwei Sun, and Xiaojun Wan.
2014. Peking: Profiling syntactic tree parsing tech-
niques for semantic graph parsing. In Proceedings
of the Eighth International Workshop on Semantic
Evaluation (SemEval 2014), Dublin, Republic of Ire-
land.
Jason Eisner and Giorgio Satta. 1999. Efficient pars-
ing for bilexical context-free grammars and Head
Automaton Grammars. In Proceedings of the 37th
Annual Meeting of the Association for Computa-
tional Linguistics (ACL), pages 457–464, College
Park, MD, USA.
Ryan McDonald, Koby Crammer, and Fernando
Pereira. 2005. Online large-margin training of de-
pendency parsers. In Proceedings of the 43rd An-
nual Meeting of the Association for Computational
Linguistics (ACL), pages 91–98, Ann Arbor, USA.
Stephan Oepen, Marco Kuhlmann, Yusuke Miyao,
Daniel Zeman, Dan Flickinger, Jan Hajiˇc, Angelina
Ivanova, and Yi Zhang. 2014. SemEval 2014 Task
8: Broad-coverage semantic dependency parsing. In
Proceedings of the Eighth International Workshop
on Semantic Evaluation (SemEval 2014), Dublin,
Republic of Ireland.
Stuart M. Shieber, Yves Schabes, and Fernando Pereira.
1995. Principles and implementation of deductive
parsing. Journal of Logic Programming, 24(1–2):3–
36.
</reference>
<page confidence="0.999156">
399
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.635874">
<title confidence="0.99724">Linköping: Cubic-Time Graph Parsing with a Simple Scoring Scheme</title>
<author confidence="0.992109">Marco</author>
<affiliation confidence="0.9998805">Dept. of Computer and Information Linköping University,</affiliation>
<email confidence="0.967557">marco.kuhlmann@liu.se</email>
<abstract confidence="0.985358222222222">We turn the Eisner algorithm for parsing to projective dependency trees into a cubictime algorithm for parsing to a restricted class of directed graphs. To extend the algorithm into a data-driven parser, we combine it with an edge-factored feature model and online learning. We report and discuss results on the SemEval-2014 Task 8 data sets</abstract>
<note confidence="0.790095">(Oepen et al., 2014).</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
</authors>
<title>Very high accuracy and fast dependency parsing is not a contradiction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (COLING),</booktitle>
<pages>89--97</pages>
<location>Beijing, China.</location>
<contexts>
<context position="13412" citStr="Bohnet, 2010" startWordPosition="2333" endWordPosition="2334">rticipating in the closed track. Given these results, we have refrained from doing a detailed error analysis. It may be interesting to note, however, that our system is the only one in the task for which labelled F1 is higher on the DM data than on the PAS data. DM PAS PCEDT # iterations 4 1 9 # features 7.3M 8.7M 8.1M Table 3: Characteristics of the trained models. 4.2 Discussion The comparatively low scores of our system do not come unexpected. Our parser uses a very simple scoring model and learning method, whereas even the baseline relies on a state-of-the-art syntactic dependency parser (Bohnet, 2010). Also, we did not do any feature engineering (on the parser), but just used the feature extraction procedure of MSTParser. Regarding both of these points, the potential for improving the system is apparent. Finally, our posthoc prediction of top nodes is extremely simplistic. It would have been much more desirable to integrate this prediction into the parser, for example by adding virtual incoming dependencies to all top nodes. However, preliminary experiments showed that this particular strategy had a severely negative impact on coverage. 5 Conclusion We have presented a new algorithm for pa</context>
</contexts>
<marker>Bohnet, 2010</marker>
<rawString>Bernd Bohnet. 2010. Very high accuracy and fast dependency parsing is not a contradiction. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING), pages 89–97, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for Hidden Markov Models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1--8</pages>
<location>Philadelphia, USA.</location>
<contexts>
<context position="2770" citStr="Collins (2002)" startWordPosition="443" endWordPosition="444">otic complexity as parsing with context-free phrase structure grammars. The class of graphs defined by our algorithm is also expressive, in so far that it covers more than 98% of the SemEval data. To demonstrate that our parsing algorithm can be turned into a practical system, we combine it with two techniques taken straight from the literature on data-driven syntactic dependency parsing: • an edge-factored scoring model, as it has been used as the core of practical parsers since the seminal work of McDonald et al. (2005), and • online learning using the structured perceptron, in the style of Collins (2002). State-of-the-art parsers use considerably more advanced (and computationally more demanding) techniques, and therefore our system cannot be expected to deliver competitive results. (Its results on the SemEval data are reported in Section 4.) Instead, the main point of our contribution to the SemEval Task is to provide evidence that research on classes of graphs that balance linguistic coverage and parsing efficiency holds a lot of potential. 2 Parsing Algorithm We start the description of our system with the description of our cubic-time parsing algorithm. The remaining components of our sys</context>
<context position="10116" citStr="Collins (2002)" startWordPosition="1785" endWordPosition="1786">of labelled exact match (LM). 3.2 Scoring Function We use the same features as in the first-order model implemented in the MSTParser system for syntactic dependency parsing (McDonald et al., 2005).3 Under this model, the feature vector for a dependency graph is the sum of the feature vectors of its edges, which take into account atomic features such as the word forms and part-of-speech tags of the tokens connected by the edge, the length of the edge, the edge label, as well as combinations of those atomic features. To set the feature weights we use averaged perceptron training in the style of Collins (2002). 3.3 Top-Node Tagger The final component in our system is a simple tagger that is used to annotate the output of our parser with information about top nodes (as defined in the task’s data format). It is based on Matthew Honnibal’s part-of-speech tagger4 and uses features based on the word form and part-of-speech of the node to be tagged, as well as the labels of the edges incident to that node; these features were selected based on tagging accuracy with the recommended development train/dev-split. The tagger is a sequence model without global constraints; in particular, it does not enforce un</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for Hidden Markov Models: Theory and experiments with perceptron algorithms. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1–8, Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruno Courcelle</author>
<author>Joost Engelfriet</author>
</authors>
<title>Graph Structure and Monadic Second-Order Logic,</title>
<date>2012</date>
<volume>138</volume>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1415" citStr="Courcelle and Engelfriet (2012)" startWordPosition="223" endWordPosition="226">em as such (which had the lowest score among all systems submitted to the task), but the general approach for which it is a proof of concept. Graphs support natural representations of linguistic structure. For this reason, algorithms that can learn, process and transform graphs are of central importance to language technology. Yet, most of the algorithms that are used in natural language processing today focus on the restricted case of trees, and do so for a reason: Computation on general graphs is hard or even intractable, and efficient processing is possible only for restricted classes (cf. Courcelle and Engelfriet (2012)). The task then is to identify classes of graphs that are both expressive enough to cover the linguistic data, and restricted enough to facilitate efficient processing. This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ 1https://github.com/liu-nlp/gamma This paper shows that there are graphs that satisfy both of these desiderata. Our system is based on a new algorithm for parsing to a restricted class of directed graphs (Section 2). T</context>
</contexts>
<marker>Courcelle, Engelfriet, 2012</marker>
<rawString>Bruno Courcelle and Joost Engelfriet. 2012. Graph Structure and Monadic Second-Order Logic, volume 138 of Encyclopedia of Mathematics and itsApplications. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yantao Du</author>
<author>Fan Zhang</author>
<author>Weiwei Sun</author>
<author>Xiaojun Wan</author>
</authors>
<title>Peking: Profiling syntactic tree parsing techniques for semantic graph parsing.</title>
<date>2014</date>
<booktitle>In Proceedings of the Eighth International Workshop on Semantic Evaluation (SemEval 2014),</booktitle>
<location>Dublin, Republic of</location>
<contexts>
<context position="11517" citStr="Du et al., 2014" startWordPosition="2008" endWordPosition="2011">m/ 397 DM PAS PCEDT LP LR LF LP LR LF LP LR LF Baseline 83.20% 40.73% 54.68% 88.34% 35.74% 50.89% 74.82% 62.08% 67.84% Linköping 78.54% 78.05% 78.29% 76.16% 75.55% 75.85% 60.66% 64.35% 62.45% Task average 84.21% 81.29% 82.69% 87.95% 83.57% 85.65% 72.17% 68.44% 70.21% Peking 90.27% 88.54% 89.40% 93.44% 90.69% 92.04% 78.75% 73.96% 76.28% Table 2: Labelled precision (LP), labelled recall (LR), and labelled F1 (LF) scores of our own system (Linköping) and three points of comparison on the SemEval-2014 Task 8 test data: baseline, task average, and the best-performing system from Peking University (Du et al., 2014). 4 Experiments We report experimental results on the SemEval data sets (closed track). We trained one parser for each representation (DM, PAS, PCEDT). Averaged perceptron training can be parametrized by the number N of iterations over the training data; to determine the value of this parameter, for each representation type and each 1 &lt; N &lt; 10 we trained a development system using the recommended development train/dev-split and selected that value of N which gave the highest accuracy on the held-out data. The selected values and the number of (binary) features in the resulting systems are repo</context>
</contexts>
<marker>Du, Zhang, Sun, Wan, 2014</marker>
<rawString>Yantao Du, Fan Zhang, Weiwei Sun, and Xiaojun Wan. 2014. Peking: Profiling syntactic tree parsing techniques for semantic graph parsing. In Proceedings of the Eighth International Workshop on Semantic Evaluation (SemEval 2014), Dublin, Republic of Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
<author>Giorgio Satta</author>
</authors>
<title>Efficient parsing for bilexical context-free grammars and Head Automaton Grammars.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>457--464</pages>
<location>College Park, MD, USA.</location>
<contexts>
<context position="3951" citStr="Eisner and Satta (1999)" startWordPosition="644" endWordPosition="647">rithm. The remaining components of our system will be described in Section 3. 395 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 395–399, Dublin, Ireland, August 23-24, 2014. Items: 1 &lt; i &lt; j &lt; n Axioms: Goal: i j i j i j i j i i i i 1 n i j � 1 jk i j j k Rules: ATTACH-R COMPLETE-R i k i k Figure 1: The Eisner algorithm for building the packed forest of all projective dependency trees with n nodes. Only the rightward versions of ATTACH and COMPLETE are shown here. 2.1 The Eisner Algorithm We recall the algorithm for projective dependency parsing by Eisner and Satta (1999). The declarative specification of this algorithm in terms of a deduction system (Shieber et al., 1995) is given in Figure 1. The algorithm uses four types of items, , , , and , and two types of inference rules called ATTACH and COMPLETE. These rules can be interpreted as operations on graphs: An ATTACH rule concatenates two graphs and adds one of two possible edges—from the left endpoint of the first graph to the right endpoint of the second graph, or vice versa. Similarly, a COMPLETE rule fuses two graphs by unifying the right endpoint of the first with the left endpoint of the second. The a</context>
</contexts>
<marker>Eisner, Satta, 1999</marker>
<rawString>Jason Eisner and Giorgio Satta. 1999. Efficient parsing for bilexical context-free grammars and Head Automaton Grammars. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL), pages 457–464, College Park, MD, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>91--98</pages>
<location>Ann Arbor, USA.</location>
<contexts>
<context position="2683" citStr="McDonald et al. (2005)" startWordPosition="426" endWordPosition="429">ithm runs in cubic time with respect to the length of the sentence; it thus has the same asymptotic complexity as parsing with context-free phrase structure grammars. The class of graphs defined by our algorithm is also expressive, in so far that it covers more than 98% of the SemEval data. To demonstrate that our parsing algorithm can be turned into a practical system, we combine it with two techniques taken straight from the literature on data-driven syntactic dependency parsing: • an edge-factored scoring model, as it has been used as the core of practical parsers since the seminal work of McDonald et al. (2005), and • online learning using the structured perceptron, in the style of Collins (2002). State-of-the-art parsers use considerably more advanced (and computationally more demanding) techniques, and therefore our system cannot be expected to deliver competitive results. (Its results on the SemEval data are reported in Section 4.) Instead, the main point of our contribution to the SemEval Task is to provide evidence that research on classes of graphs that balance linguistic coverage and parsing efficiency holds a lot of potential. 2 Parsing Algorithm We start the description of our system with t</context>
<context position="9698" citStr="McDonald et al., 2005" startWordPosition="1709" endWordPosition="1712">70/52.15 93.06/23.66 93.51/54.75 Table 1: Upper bounds for recall (LR/LM) on the test data for two different sets of operations. where a node has no incoming edges. As can be seen in Table 1, the upper bounds for the reduced set of operations are still surprisingly high when measured in terms of LR: 95.70% for DM, 93.06% for PAS, and 93.51% for PCEDT. However, there is a significant loss when coverage is measured in terms of labelled exact match (LM). 3.2 Scoring Function We use the same features as in the first-order model implemented in the MSTParser system for syntactic dependency parsing (McDonald et al., 2005).3 Under this model, the feature vector for a dependency graph is the sum of the feature vectors of its edges, which take into account atomic features such as the word forms and part-of-speech tags of the tokens connected by the edge, the length of the edge, the edge label, as well as combinations of those atomic features. To set the feature weights we use averaged perceptron training in the style of Collins (2002). 3.3 Top-Node Tagger The final component in our system is a simple tagger that is used to annotate the output of our parser with information about top nodes (as defined in the task’</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>Ryan McDonald, Koby Crammer, and Fernando Pereira. 2005. Online large-margin training of dependency parsers. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL), pages 91–98, Ann Arbor, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Oepen</author>
<author>Marco Kuhlmann</author>
<author>Yusuke Miyao</author>
<author>Daniel Zeman</author>
<author>Dan Flickinger</author>
<author>Jan Hajiˇc</author>
<author>Angelina Ivanova</author>
<author>Yi Zhang</author>
</authors>
<title>Task 8: Broad-coverage semantic dependency parsing.</title>
<date>2014</date>
<booktitle>In Proceedings of the Eighth International Workshop on Semantic Evaluation (SemEval 2014),</booktitle>
<location>Dublin, Republic of</location>
<note>SemEval</note>
<marker>Oepen, Kuhlmann, Miyao, Zeman, Flickinger, Hajiˇc, Ivanova, Zhang, 2014</marker>
<rawString>Stephan Oepen, Marco Kuhlmann, Yusuke Miyao, Daniel Zeman, Dan Flickinger, Jan Hajiˇc, Angelina Ivanova, and Yi Zhang. 2014. SemEval 2014 Task 8: Broad-coverage semantic dependency parsing. In Proceedings of the Eighth International Workshop on Semantic Evaluation (SemEval 2014), Dublin, Republic of Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
<author>Yves Schabes</author>
<author>Fernando Pereira</author>
</authors>
<title>Principles and implementation of deductive parsing.</title>
<date>1995</date>
<journal>Journal of Logic Programming,</journal>
<volume>24</volume>
<issue>1</issue>
<pages>36</pages>
<contexts>
<context position="4054" citStr="Shieber et al., 1995" startWordPosition="661" endWordPosition="664">International Workshop on Semantic Evaluation (SemEval 2014), pages 395–399, Dublin, Ireland, August 23-24, 2014. Items: 1 &lt; i &lt; j &lt; n Axioms: Goal: i j i j i j i j i i i i 1 n i j � 1 jk i j j k Rules: ATTACH-R COMPLETE-R i k i k Figure 1: The Eisner algorithm for building the packed forest of all projective dependency trees with n nodes. Only the rightward versions of ATTACH and COMPLETE are shown here. 2.1 The Eisner Algorithm We recall the algorithm for projective dependency parsing by Eisner and Satta (1999). The declarative specification of this algorithm in terms of a deduction system (Shieber et al., 1995) is given in Figure 1. The algorithm uses four types of items, , , , and , and two types of inference rules called ATTACH and COMPLETE. These rules can be interpreted as operations on graphs: An ATTACH rule concatenates two graphs and adds one of two possible edges—from the left endpoint of the first graph to the right endpoint of the second graph, or vice versa. Similarly, a COMPLETE rule fuses two graphs by unifying the right endpoint of the first with the left endpoint of the second. The algorithm by Eisner and Satta (1999) produces a compact representation of the set of all dependency grap</context>
</contexts>
<marker>Shieber, Schabes, Pereira, 1995</marker>
<rawString>Stuart M. Shieber, Yves Schabes, and Fernando Pereira. 1995. Principles and implementation of deductive parsing. Journal of Logic Programming, 24(1–2):3– 36.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>