<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<note confidence="0.749489666666667">
Phrase-Based SMT with Shallow Tree-Phrases
Philippe Langlais and Fabrizio Gotti
RALI – DIRO
</note>
<address confidence="0.804149333333333">
Universit´e de Montr´eal,
C.P. 6128 Succ. Centre-Ville
H3C 3J7, Montr´eal, Canada
</address>
<email confidence="0.999204">
{felipe,gottif}@iro.umontreal.ca
</email>
<sectionHeader confidence="0.996666" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999661692307692">
In this article, we present a translation
system which builds translations by glu-
ing together Tree-Phrases, i.e. associ-
ations between simple syntactic depen-
dency treelets in a source language and
their corresponding phrases in a target
language. The Tree-Phrases we use in
this study are syntactically informed and
present the advantage of gathering source
and target material whose words do not
have to be adjacent. We show that the
phrase-based translation engine we imple-
mented benefits from Tree-Phrases.
</bodyText>
<sectionHeader confidence="0.998781" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99987834">
Phrase-based machine translation is now a popular
paradigm. It has the advantage of naturally cap-
turing local reorderings and is shown to outper-
form word-based machine translation (Koehn et al.,
2003). The underlying unit (a pair of phrases), how-
ever, does not handle well languages with very dif-
ferent word orders and fails to derive generalizations
from the training corpus.
Several alternatives have been recently proposed
to tackle some of these weaknesses. (Matusov et
al., 2005) propose to reorder the source text in or-
der to mimic the target word order, and then let a
phrase-based model do what it is good at. (Simard
et al., 2005) detail an approach where the standard
phrases are extended to account for “gaps” either on
the target or source side. They show that this repre-
sentation has the potential to better exploit the train-
ing corpus and to nicely handle differences such as
negations in French and English that are poorly han-
dled by standard phrase-based models.
Others are considering translation as a syn-
chronous parsing process e.g. (Melamed, 2004;
Ding and Palmer, 2005)) and several algorithms
have been proposed to learn the underlying produc-
tion rule probabilities (Graehl and Knight, 2004;
Ding and Palmer, 2004). (Chiang, 2005) proposes
an heuristic way of acquiring context free transfer
rules that significantly improves upon a standard
phrase-based model.
As mentioned in (Ding and Palmer, 2005), most
of these approaches require some assumptions on
the level of isomorphism (lexical and/or structural)
between two languages. In this work, we consider
a simple kind of unit: a Tree-Phrase (TP), a com-
bination of a fully lexicalized treelet (TL) and an
elastic phrase (EP), the tokens of which may be in
non-contiguous positions. TPs capture some syntac-
tic information between two languages and can eas-
ily be merged with standard phrase-based engines.
A TP can be seen as a simplification of the treelet
pairs manipulated in (Quirk et al., 2005). In particu-
lar, we do not address the issue of projecting a source
treelet into a target one, but take the bet that collect-
ing (without structure) the target words associated
with the words encoded in the nodes of a treelet will
suffice to allow translation. This set of target words
is what we call an elastic phrase.
We show that these units lead to (modest) im-
provements in translation quality as measured by au-
tomatic metrics. We conducted all our experiments
</bodyText>
<page confidence="0.993131">
39
</page>
<note confidence="0.883236">
Proceedings of the Workshop on Statistical Machine Translation, pages 39–46,
New York City, June 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.9994341">
on an in-house version of the French-English Cana-
dian Hansards.
This paper is organized as follows. We first define
a Tree-Phrase in Section 2, the unit with which we
built our system. Then, we describe in Section 3
the phrase-based MT decoder that we designed to
handle TPs. We report in Section 4 the experiments
we conducted combining standard phrase pairs and
TPs. We discuss this work in Section 5 and then
conclude in Section 6.
</bodyText>
<sectionHeader confidence="0.955706" genericHeader="introduction">
2 Tree-Phrases
</sectionHeader>
<bodyText confidence="0.999681181818182">
We call tree-phrase (TP) a bilingual unit consisting
of a source, fully-lexicalized treelet (TL) and a tar-
get phrase (EP), that is, the target words associated
with the nodes of the treelet, in order. A treelet can
be an arbitrary, fully-lexicalized subtree of the parse
tree associated with a source sentence. A phrase can
be an arbitrary sequence of words. This includes
the standard notion of phrase, popular with phrased-
based SMT (Koehn et al., 2003; Vogel et al., 2003)
as well as sequences of words that contain gaps (pos-
sibly of arbitrary size).
In this study, we collected a repository of tree-
phrases using a robust syntactic parser called SYN-
TEX (Bourigault and Fabre, 2000). SYNTEX identi-
fies syntactic dependency relations between words.
It takes as input a text processed by the TREETAG-
GER part-of-speech tagger.1 An example of the out-
put SYNTEX produces for the source (French) sen-
tence “on a demand´e des cr´edits f´ed´eraux” (request
for federal funding) is presented in Figure 1.
We parsed with SYNTEX the source (French) part
of our training bitext (see Section 4.1). From this
material, we extracted all dependency subtrees of
depth 1 from the complete dependency trees found
by SYNTEX. An elastic phrase is simply the list of
tokens aligned with the words of the corresponding
treelet as well as the respective offsets at which they
were found in the target sentence (the first token of
an elastic phrase always has an offset of 0).
For instance, the two treelets in Figure 2 will be
collected out of the parse tree in Figure 1, yielding
2 tree-phrases. Note that the TLs as well as the EPs
might not be contiguous as is for instance the case
</bodyText>
<footnote confidence="0.9483605">
1www.ims.uni-stuttgart.de/projekte/
corplex/.
</footnote>
<figure confidence="0.7427395">
on cr´edits
���������� ADJ
����������
DET
</figure>
<figureCaption confidence="0.999285">
Figure 1: Parse of the sentence
</figureCaption>
<figure confidence="0.88956425">
a
des
(request for federal funding). Note
that the 2 words
and
(literally
and
from the ori
“on
demand´e
cr´editsf´ed´eraux”
“a”
“demand´e”
“have”
“asked”)
ginal sentence have been
</figure>
<bodyText confidence="0.987495333333333">
merged together by SYNTEX to form a single token.
These tokens are the ones we use in this study.
with the first pair of structures listed in the example.
</bodyText>
<sectionHeader confidence="0.987592" genericHeader="method">
3 The Translation Engine
</sectionHeader>
<equation confidence="0.910611777777778">
under the constraints that for all i E
u],
&lt;
, bn E
for a source treelet (similar con-
straints apply on the target side), and
=
+
1, bn E [1,
</equation>
<bodyText confidence="0.84981375">
for a source phrase. The way the
hypotheses are built imposes additional constraints
between units that will be described in Section 3.3.
Note that, at decoding time,
</bodyText>
<equation confidence="0.983661111111111">
[1,
jin
jin+1
[1,ni[
jin+1
jin
ni[
|e|, the number of words
des f´ed´eraux
</equation>
<bodyText confidence="0.974285444444444">
We built a translation engine very similar to the sta-
tistical phrase-based engine PHARAOH described in
(Koehn, 2004) that we extended to use tree-phrases.
Not only does our decoder differ from PHARAOH by
using TPs, it also uses direct translation models. We
know from (Och and Ney, 2002) that not using the
noisy-channel approach does not impact the quality
of the tran
slation produced.
</bodyText>
<subsectionHeader confidence="0.873578666666667">
3.1 The maximization setting
For a source sentence f, our engine incrementally
generates a set of translation hypotheses
</subsectionHeader>
<bodyText confidence="0.799259">
by com-
bining tree-phrase (TP) units and phrase-phrase (PP)
units.2 We define a hypothesis in this set ash =
a set of u pairs of source
and target sequences
of
and mi
</bodyText>
<equation confidence="0.98919695">
H
{Ui=(Fi,Ei)}iE[1,-],
(Fi)
(Ei)
ni
words
respectively:
=
�
E
=
�
E
Fi
{fji�
jin
[1,|f|]}nE[1,ni]Ei
{eii�
lim
[1,|e|]}mE[1,mi]
</equation>
<bodyText confidence="0.7201915">
we call here aphrase-phrase unit is simply a pair of
sourc
</bodyText>
<page confidence="0.257121">
2What
</page>
<tableCaption confidence="0.333685">
e/target sequences of words.
</tableCaption>
<figure confidence="0.684492818181818">
���������� ������������������
OBJ
a demand´e
SUB
40
alignment:
tree-phrases:
TL? {{on@-1} a_demand´e {cr´edits@2}}
EP? |request@0||for@1||funding@3|
TL {{des@-1} cr´edits {f´ed´eraux@1}}
EP |federal@0||funding@1|
</figure>
<figureCaption confidence="0.912253">
Figure 2: The Tree-Phrases collected out of the
</figureCaption>
<bodyText confidence="0.996193642857143">
SYNTEX parse for the sentence pair of Figure 1.
Non-contiguous structures are marked with a star.
Each dependent node of a given governor token is
displayed as a list surrounding the governor node,
e.g. {governor {right-dependent}}. Along with the
tokens of each node, we present their respective off-
set (the governor/root node has the offset 0 by defi-
nition). The format we use to represent the treelets
is similar to the one proposed in (Quirk et al., 2005).
of the translation is unknown, but is bounded accord-
ing to |f |(in our case, |e|max = 2 × |f |+ 5).
We define the source and target projection of a
hypothesis h by the proj operator which collects in
order the words of a hypothesis along one language:
</bodyText>
<equation confidence="0.998994">
projF(h) = I rn fp : p ∈ Si=1{A -E[1,ni] o
projE(h) = S ep : p ∈ Si=1{lim}mE[1,mi]o
</equation>
<bodyText confidence="0.991238333333333">
If we denote by Hf the set of hypotheses that
have f as a source projection (that is, Hf = {h :
projF(h) ≡ f}), then our translation engine seeks
</bodyText>
<equation confidence="0.936853333333333">
e� = projE(h) where:
h = argmax s(h)
hEWf
</equation>
<bodyText confidence="0.999459888888889">
The function we seek to maximize s(h) is a log-
linear combination of 9 components, and might be
better understood as the numerator of a maximum
entropy model popular in several statistical MT sys-
tems (Och and Ney, 2002; Bertoldi et al., 2004; Zens
and Ney, 2004; Simard et al., 2005; Quirk et al.,
2005). The components are the so-called feature
functions (described below) and the weighting co-
efficients (λ) are the parameters of the model:
</bodyText>
<equation confidence="0.998201333333333">
s(h) = λpprf log ppprf (h) + λp|h|+
λtprf log ptprf (h) + λt|h|+
λppibm log pppibm(h)+
λtpibm log ptpibm(h)+
λlm log plm(projE(h))+
λd d(h) + λw|projE(h)|
</equation>
<subsectionHeader confidence="0.998046">
3.2 The components of the scoring function
</subsectionHeader>
<bodyText confidence="0.999830083333333">
We briefly enumerate the features used in this study.
Translation models Even if a tree-phrase is a gen-
eralization of a standard phrase-phrase unit, for in-
vestigation purposes, we differentiate in our MT
system between two kinds of models: a TP-based
model ptp and a phrase-phrase model ppp. Both rely
on conditional distributions whose parameters are
learned over a corpus. Thus, each model is assigned
its own weighting coefficient, allowing the tuning
process to bias the engine toward a special kind of
unit (TP or PP).
We have, for k ∈ {rf, ibm}:
</bodyText>
<equation confidence="0.999954">
pppk(h) = Qu i=1 ppp(Ei|Fi)
ptpk(h) = Qui=1 ptp(Ei|Fi)
</equation>
<bodyText confidence="0.9996222">
with p•rf standing for a model trained by rel-
ative frequency, whereas p•ibm designates a non-
normalized score computed by an IBM model-1
translation model p, where f0 designates the so-
called NULL word:
</bodyText>
<equation confidence="0.999617">
p•ibm(Ei|Fi) = mi ni p(elim|fjin) + p(ekim|f0)
Y X
m=1 n=1
</equation>
<bodyText confidence="0.999918888888889">
Note that by setting λtprf and λtpibm to zero, we
revert back to a standard phrase-based translation
engine. This will serve as a reference system in the
experiments reported (see Section 4).
The language model Following a standard prac-
tice, we use a trigram target language model
plm(projE(h)) to control the fluency of the trans-
lation produced. See Section 3.3 for technical sub-
tleties related to their use in our engine.
</bodyText>
<figure confidence="0.996328666666667">
a demand´e ≡ request for, f´ed´eraux ≡ federal,
cr´edits ≡ funding
treelets: cr´edits
a demand´e ������� �������
������� ������� des f´ed´eraux
on cr´edits
</figure>
<page confidence="0.996805">
41
</page>
<bodyText confidence="0.9983256">
Distortion model d This feature is very similar to
the one described in (Koehn, 2004) and only de-
pends on the offsets of the source units. The only
difference here arises when TPs are used to build a
translation hypothesis:
</bodyText>
<equation confidence="0.992231777777778">
n
d(h) = — abs(1 + Fi_1 — Fi)
i=1
where:
� EnE[1,nz] ji n/ni if Fi is a treelet
Fi = ji
otherwise
n�
Fi = ji1
</equation>
<bodyText confidence="0.999840153846154">
This score encourages the decoder to produce a
monotonous translation, unless the language model
strongly privileges the opposite.
Global bias features Finally, three simple fea-
tures help control the translation produced. Each
TP (resp. PP) unit used to produce a hypothesis
receives a fixed weight At (resp. Ap). This allows
the introduction of an artificial bias favoring either
PPs or TPs during decoding. Each target word pro-
duced is furthermore given a so-called word penalty
A,,, which provides a weak way of controlling the
preference of the decoder for long or short transla-
tions.
</bodyText>
<subsectionHeader confidence="0.984519">
3.3 The search procedure
</subsectionHeader>
<bodyText confidence="0.999737777777778">
The search procedure is described by the algorithm
in Figure 3. The first stage of the search consists in
collecting all the units (TPs or PPs) whose source
part matches the source sentence f. We call U the
set of those matching units.
In this study, we apply a simple match policy that
we call exact match policy. A TL t matches a source
sentence f if its root matches f at a source position
denoted r and if all the other words w of t satisfy:
</bodyText>
<equation confidence="0.816748">
fo.+T = w
</equation>
<bodyText confidence="0.999418666666667">
where o,,, designates the offset of w in t.
Hypotheses are built synchronously along with
the target side (by appending the target material to
the right of the translation being produced) by pro-
gressively covering the positions of the source sen-
tence f being translated.
</bodyText>
<equation confidence="0.948129875">
Require: a source sentence f
U +— {u : s-match(u, f)}
FUTURECOST(U)
fors+— 1 to |f |do
5[s] +— 0
5[0] +— {(0, E, 0)}
for s +— 0 to |f |- 1 do
PRUNE(5[s], Q)
</equation>
<bodyText confidence="0.947404666666667">
for all hypotheses alive h E 5[s] do
for all u E U do
if EXTENDS(u, h) then
</bodyText>
<equation confidence="0.985943">
h&apos; +— UPDATE(u, h)
k +— |projF(h&apos;)|
5[k] +— 5[k] U {h&apos;}
return argmaxhES[|f|] p : h —* (ps, t, p)
</equation>
<figureCaption confidence="0.890983333333333">
Figure 3: The search algorithm. The symbol +— is
used in place of assignments, while —* denotes uni-
fication (as in languages such as Prolog).
</figureCaption>
<bodyText confidence="0.999920916666667">
The search space is organized into a set 5 of |f|
stacks, where a stack 5[s] (s E [1, |f|]) contains all
the hypotheses covering exactly s source words. A
hypothesis h = (ps, t, p) is composed of its target
material t, the source positions covered ps as well as
its score p. The search space is initialized with an
empty hypothesis: 5[0] = {(0, E, 0)}.
The search procedure consists in extending each
partial hypothesis h with every unit that can con-
tinue it. This process ends when all partial hypothe-
ses have been expanded. The translation returned is
the best one contained in 5[|f|]:
</bodyText>
<equation confidence="0.953807666666667">
e = projE(argmax p : h —* (ps, t, p))
hES[|f|]
PRUNE — In order to make the search tractable,
</equation>
<bodyText confidence="0.994437">
each stack 5[s] is pruned before being expanded.
Only the hypotheses whose scores are within a frac-
tion (controlled by a meta-parameter Q which typi-
cally is 0.0001 in our experiments) of the score of
the best hypothesis in that stack are considered for
expansion. We also limit the number of hypotheses
maintained in a given stack to the top maxStack
ones (maxStack is typically set to 500).
Because beam-pruning tends to promote in a stack
partial hypotheses that translate easy parts (i.e. parts
</bodyText>
<page confidence="0.998041">
42
</page>
<bodyText confidence="0.999923846153846">
that are highly scored by the translation and lan-
guage models), the score considered while pruning
not only involves the cost of a partial hypothesis so
far, but also an estimation of the future cost that will
be incurred by fully expanding it.
FUTURECOST — We followed the heuristic de-
scribed in (Koehn, 2004), which consists in comput-
ing for each source range [i, j] the minimum cost
c(i, j) with which we can translate the source se-
quence fji . This is pre-computed efficiently at an
early stage of the decoding (second line of the algo-
rithm in Figure 3) by a bottom-up dynamic program-
ming scheme relying on the following recursion:
</bodyText>
<equation confidence="0.975351">
minkE[i,j[c(i, k) + c(k, j)
I
c(i, j) =min minuEU/usnf;z =usscore(us)
</equation>
<bodyText confidence="0.999914432432432">
where us stands for the projection of u on the tar-
get side (us - projE(u)), and score(u) is com-
puted by considering the language model and the
translation components ppp of the s(h) score. The
future cost of h is then computed by summing the
cost c(i, j) of all its empty source ranges [i, j].
EXTENDS — When we simply deal with standard
(contiguous) phrases, extending a hypothesis h by a
unit u basically requires that the source positions of
u be empty in h. Then, the target material of u is
appended to the current hypothesis h.
Because we work with treelets here, things are
a little more intricate. Conceptually, we are con-
fronted with the construction of a (partial) source
dependency tree while collecting the target mate-
rial in order. Therefore, the decoder needs to check
whether a given TL (the source part of u) is compati-
ble with the TLs belonging to h. Since we decided in
this study to use depth-one treelets, we consider that
two TLs are compatible if either they do not share
any source word, or, if they do, this shared word
must be the governor of one TL and a dependent in
the other TL.
So, for instance, in the case of Figure 2, the
two treelets are deemed compatible (they obviously
should be since they both belong to the same orig-
inal parse tree) because cr´edit is the governor
in the right-hand treelet while being the depen-
dent in the left-hand one. On the other hand, the
two treelets in Figure 4 are not, since pr´esident
is the governor of both treelets, even though mr.
le pr´esident suppl´eant would be a valid
source phrase. Note that it might be the case that
the treelet {{mr.@-2} {le@-1} pr´esident
{suppl´eant@1}} has been observed during
training, in which case it will compete with the
treelets in Figure 2.
</bodyText>
<figure confidence="0.772785666666667">
pr´esident
������� �������
le suppl´eant
</figure>
<figureCaption confidence="0.672427333333333">
Figure 4: Example of two incompatible treelets.
mr. speaker and the acting speaker
are their respective English translations.
</figureCaption>
<bodyText confidence="0.986944363636364">
Therefore, extending a hypothesis containing a
treelet with a new treelet consists in merging the two
treelets (if they are compatible) and combining the
target material accordingly. This operation is more
complicated than in a standard phrase-based decoder
since we allow gaps on the target side as well. More-
over, the target material of two compatible treelets
may intersect. This is for instance the case for the
two TPs in Figure 2 where the word funding is
common to both phrases.
UPDATE — Whenever u extends h, we add a
new hypothesis h&apos; in the corresponding stack
S[|projF(h&apos;)|]. Its score is computed by adding to
that of h the score of each component involved in
s(h). For all but the one language model compo-
nent, this is straightforward. However, care must be
taken to update the language model score since the
target material of u does not come necessarily right
after that of h as would be the case if we only ma-
nipulated PP units.
Figure 5 illustrates the kind of bookkeeping
required. In practice, the target material of
a hypothesis is encoded as a vector of triplets
{(wi,log plm(wi|ci), li)}iE[1,|e|maa] where wi is the
word at position i in the translation, log plm(wi|ci)
is its score as given by the language model, ci de-
notes the largest conditioning context possible, and
li indicates the length (in words) of ci (0 means a
unigram probability, 1 a bigram probability and 2 a
trigram probability). This vector is updated at each
extension.
pr´esident
mr.
</bodyText>
<page confidence="0.998706">
43
</page>
<table confidence="0.994488266666667">
TRAIN DEV TEST
sentences 1699 592 500 8000
e-toks 27 717 389 8160 130192
f-toks 30 425 066 8 946 143 089
e-toks/sent 16.3 (± 9.0) 16.3 (± 9.1) 16.3 (± 9.0)
f-toks/sent 17.9 (± 9.5) 17.9 (± 9.5) 17.9 (± 9.5)
e-types 164 255 2 224 12 591
f-types 210 085 2 481 15 008
e-hapax 68 506 1469 6 887
f-hapax 90 747 1704 8 612
h request for funding S[3]
U B F U
on a_demandé des crédits fédéraux
TL: [on@−1} a_demandé [crédits@2}
EP: request@0 for@1 funding@3
</table>
<figure confidence="0.754849166666667">
u
h’ request for federal funding S[4]
U B T T
on a_demandé des crédits fédéraux
u EP: federal@0 funding@1
TL: [des@−1} crédits [fédéraux@1}
</figure>
<figureCaption confidence="0.958480714285714">
Figure 5: Illustration of the language model up-
dates that must be made when a new target unit
(circles with arrows represent dependency links) ex-
tends an existing hypothesis (rectangles). The tag
inside each occupied target position shows whether
this word has been scored by a Unigram, a Bigram
or a Trigram probability.
</figureCaption>
<sectionHeader confidence="0.979447" genericHeader="method">
4 Experimental Setting
</sectionHeader>
<subsectionHeader confidence="0.979358">
4.1 Corpora
</subsectionHeader>
<bodyText confidence="0.98420644">
We conducted our experiments on an in-house ver-
sion of the Canadian Hansards focussing on the
translation of French into English. The split of this
material into train, development and test corpora is
detailed in Table 1. The TEST corpus is subdivided
in 16 (disjoints) slices of 500 sentences each that
we translated separately. The vocabulary is atypi-
cally large since some tokens are being merged by
SYNTEX, such as ´etaient#financ´ees (were
financed in English).
The training corpus has been aligned at the
word level by two Viterbi word-alignments
(French2English and English2French) that we
combined in a heuristic way similar to the refined
method described in (Och and Ney, 2003). The
parameters of the word models (IBM model 2) were
trained with the GIZA++ package (Och and Ney,
2000).
Table 1: Main characteristics of the corpora used in
this study. For each language l, l-toks is the number
of tokens, l-toks/sent is the average number of to-
kens per sentence (f the standard deviation), l-types
is the number of different token forms and l-hapax
is the number of tokens that appear only once in the
corpus.
</bodyText>
<subsectionHeader confidence="0.994799">
4.2 Models
</subsectionHeader>
<bodyText confidence="0.999930769230769">
Tree-phrases Out of 1.7 million pairs of sen-
tences, we collected more than 3 million different
kinds of TLs from which we projected 6.5 million
different kinds of EPs. Slightly less than half of
the treelets are contiguous ones (i.e. involving a se-
quence of adjacent words); 40% of the EPs are con-
tiguous. When the respective frequency of each TL
or EP is factored in, we have approximately 11 mil-
lion TLs and 10 million EPs. Roughly half of the
treelets collected have exactly two dependents (three
word long treelets).
Since the word alignment of non-contiguous
phrases is likely to be less accurate than the align-
ment of adjacent word sequences, we further filter
the repository of TPs by keeping the most likely EPs
for each TL according to an estimate of p(EP|TL)
that do not take into account the offsets of the EP or
the TL.
PP-model We collected the PP parameters by sim-
ply reading the alignment matrices resulting from
the word alignment, in a way similar to the one
described in (Koehn et al., 2003). We use an in-
house tool to collect pairs of phrases of up to 8
words. Freely available packages such as THOT
(Ortiz-Martinez et al., 2005) could be used as well
for that purpose.
</bodyText>
<page confidence="0.997117">
44
</page>
<bodyText confidence="0.997714">
Language model We trained a Kneser-Ney tri-
gram language model using the SRILM toolkit (Stol-
cke, 2002).
</bodyText>
<subsectionHeader confidence="0.991269">
4.3 Protocol
</subsectionHeader>
<bodyText confidence="0.999815028571428">
We compared the performances of two versions of
our engine: one which employs TPs ans PPs (TP-
ENGINE hereafter), and one which only uses PPs
(PP-ENGINE). We translated the 16 disjoint sub-
corpora of the TEST corpus with and without TPs.
We measure the quality of the translation pro-
duced with three automatic metrics. Two error
rates: the sentence error rate (SER) and the word
error rate (WER) that we seek to minimize, and
BLEU (Papineni et al., 2002), that we seek to
maximize. This last metric was computed with
the multi-bleu.perl script available at www.
statmt.org/wmt06/shared-task/.
We separately tuned both systems on the DEV cor-
pus by applying a brute force strategy, i.e. by sam-
pling uniformly the range of each parameter (A) and
picking the configuration which led to the best BLEU
score. This strategy is inelegant, but in early experi-
ments we conducted, we found better configurations
this way than by applying the Simplex method with
multiple starting points. The tuning roughly takes
24 hours of computation on a cluster of 16 comput-
ers clocked at 3 GHz, but, in practice, we found that
one hour of computation is sufficient to get a con-
figuration whose performances, while subobptimal,
are close enough to the best one reachable by an ex-
haustive search.
Both configurations were set up to avoid distor-
tions exceeding 3 (maxDist = 3). Stacks were
allowed to contain no more than 500 hypotheses
(maxStack = 500) and we further restrained the
number of hypotheses considered by keeping for
each matching unit (treelet or phrase) the 5 best
ranked target associations. This setting has been
fixed experimentally on the DEV corpus.
</bodyText>
<sectionHeader confidence="0.631161" genericHeader="evaluation">
4.4 Results
</sectionHeader>
<bodyText confidence="0.999965416666667">
The scores for the 16 slices of the test corpus are re-
ported in Table 2. TP-ENGINE shows slightly better
figures for all metrics.
For each system and for each metric, we had
16 scores (from each of the 16 slices of the test cor-
pus) and were therefore able to test the statistical sig-
nicance of the difference between the TP-ENGINE
and PP-ENGINE using a Wilcoxon signed-rank test
for paired samples. This test showed that the dif-
ference observed between the two systems is signif-
icant at the 95% probability level for BLEU and sig-
nificant at the 99% level for WER and SER.
</bodyText>
<table confidence="0.999115333333333">
Engine WER% SER% BLEU%
PP 52.80 ± 1.2 94.32 ± 0.9 29.95 ± 1.2
TP 51.98 ± 1.2 92.83 ± 1.3 30.47 ± 1.4
</table>
<tableCaption confidence="0.98887">
Table 2: Median WER, SER and BLEU scores
</tableCaption>
<bodyText confidence="0.989425555555555">
(± value range) of the translations produced by the
two engines on a test set of 16 disjoint corpora of
500 sentences each. The figures reported are per-
centages.
On the DEV corpus, we measured that, on aver-
age, each source sentence is covered by 39 TPs (their
source part, naturally), yielding a source coverage of
approximately 70%. In contrast, the average number
of covering PPs per sentence is 233.
</bodyText>
<sectionHeader confidence="0.999608" genericHeader="evaluation">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999898944444445">
On a comparable test set (Canadian Hansard texts),
(Simard et al., 2005) report improvements by adding
non-contiguous bi-phrases to their engine without
requiring a parser at all. At the same time, they also
report negative results when adding non-contiguous
phrases computed from the refined alignment tech-
nique that we used here.
Although the results are not directly comparable,
(Quirk et al., 2005) report much larger improve-
ments over a phrase-based statistical engine with
their translation engine that employs a source parser.
The fact that we consider only depth-one treelets in
this work, coupled with the absence of any particular
treelet projection algorithm (which prevents us from
training a syntactically motivated reordering model
as they do) are other possible explanations for the
modest yet significant improvements we observe in
this study.
</bodyText>
<sectionHeader confidence="0.999331" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.998989">
We presented a pilot study aimed at appreciating the
potential of Tree-Phrases as base units for example-
based machine translation.
</bodyText>
<page confidence="0.99761">
45
</page>
<bodyText confidence="0.999954">
We developed a translation engine which makes
use of tree-phrases on top of pairs of source/target
sequences of words. The experiments we conducted
suggest that TPs have the potential to improve trans-
lation quality, although the improvements we mea-
sured are modest, yet statistically significant.
We considered only one simple form of tree in this
study: depth-one subtrees. We plan to test our en-
gine on a repository of treelets of arbitrary depth. In
theory, there is not much to change in our engine
to account for such units and it would offer an al-
ternative to the system proposed recently by (Liu et
al., 2005), which performs translations by recycling
a collection of tree-string-correspondence (TSC) ex-
amples.
</bodyText>
<sectionHeader confidence="0.999201" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9998629125">
Nicola Bertoldi, Roldano Cattoni, Mauro Cettolo, and
Marcello Federico. 2004. The ITC-irst statistical ma-
chine translation system for IWSLT-2004. In IWSLT,
pages 51–58, Kyoto, Japan.
Didier Bourigault and C´ecile Fabre. 2000. Ap-
proche linguistique pour l’analyse syntaxique de cor-
pus. Cahiers de Grammaire, (25):131–151. Toulouse
le Mirail.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In 43rd ACL, pages
263–270, Ann Arbor, Michigan, USA.
Yuang Ding and Martha Palmer. 2004. Automatic learn-
ing of parallel dependency treelet pairs. In Proceed-
ings of the first International Joint Conference on NLP.
Yuan Ding and Martha Palmer. 2005. Machine trans-
lation using probabilistic synchronous dependency in-
sertion grammars. In 43rd ACL, pages 541–548, Ann
Arbor, Michigan, June.
Jonathan Graehl and Kevin Knight. 2004. Training tree
transducers. In HLT-NAACL 2004, pages 105–112,
Boston, Massachusetts, USA, May 2 - May 7. Asso-
ciation for Computational Linguistics.
Philipp Koehn, Franz Joseph Och, and Daniel Marcu.
2003. Statistical Phrase-Based Translation. In Pro-
ceedings of HLT, pages 127–133.
Philipp Koehn. 2004. Pharaoh: a Beam Search Decoder
for Phrase-Based SMT. In Proceedings of AMTA,
pages 115–124.
Zhanyi Liu, Haifeng Wang, and Hua Wu. 2005.
Example-based machine translation based on tsc and
statistical generation. In Proceedings of MT Summit
X, pages 25–32, Phuket, Thailand.
Evgeny Matusov, Stephan Kanthak, and Hermann Ney.
2005. Efficient statistical machine translation with
constraint reordering. In 10th EAMT, pages 181–188,
Budapest, Hongary, May 30-31.
I. Dan Melamed. 2004. Statistical machine translation
by parsing. In 42nd ACL, pages 653–660, Barcelona,
Spain.
Franz Joseph Och and Hermann Ney. 2000. Improved
Statistical Alignment Models. In Proceedings of ACL,
pages 440–447, Hongkong, China.
Franz Joseph Och and Hermann Ney. 2002. Discrimina-
tive training and maximum entropy models for statis-
tical machine translation. In Proceedings of the ACL,
pages 295–302.
Franz Joseph Och and Hermann Ney. 2003. A Sys-
tematic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29:19–51.
Daniel Ortiz-Martinez, Ismael Garci´a-Varea, and Fran-
cisco Casacuberta. 2005. Thot: a toolkit to train
phrase-based statistical translation models. In Pro-
ceedings of MT Summit X, pages 141–148, Phuket,
Thailand, Sep.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic evalua-
tion of machine translation. In 40th ACL, pages 311–
318, Philadelphia, Pennsylvania.
Chris Quirk, Arul Menezes, and Colin Cherry. 2005. De-
pendency treelet translation: Syntactically informed
phrasal SMT. In 43rd ACL, pages 271–279, Ann Ar-
bor, Michigan, June.
Michel Simard, Nicola Cancedda, Bruno Cavestro,
Marc Dymetman, Eric Gaussier, Cyril Goutte,
Kenji Yamada, Philippe Langlais, and Arne Mauser.
2005. Translating with non-contiguous phrases. In
HLT/EMNLP, pages 755–762, Vancouver, British
Columbia, Canada, Oct.
Andreas Stolcke. 2002. Srilm - an Extensible Language
Modeling Toolkit. In Proceedings of ICSLP, Denver,
Colorado, Sept.
Stephan Vogel, Ying Zhang, Fei Huang, Alicai Trib-
ble, Ashish Venugopal, Bing Zao, and Alex Waibel.
2003. The CMU Statistical Machine Translation Sys-
tem. In Machine Translation Summit IX, New Orleans,
Louisina, USA, Sep.
Richard Zens and Hermann Ney. 2004. Improvements in
phrase-based statistical machine translation. In Pro-
ceedings of the HLT/NAACL, pages 257–264, Boston,
MA, May.
</reference>
<page confidence="0.999611">
46
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.723345">
<title confidence="0.998957">Phrase-Based SMT with Shallow Tree-Phrases</title>
<author confidence="0.996182">Philippe Langlais</author>
<author confidence="0.996182">Fabrizio</author>
<affiliation confidence="0.9944955">RALI – DIRO Universit´e de Montr´eal,</affiliation>
<address confidence="0.9089195">C.P. 6128 Succ. H3C 3J7, Montr´eal, Canada</address>
<abstract confidence="0.990628857142857">In this article, we present a translation system which builds translations by gluing together Tree-Phrases, i.e. associations between simple syntactic dependency treelets in a source language and their corresponding phrases in a target language. The Tree-Phrases we use in this study are syntactically informed and present the advantage of gathering source and target material whose words do not have to be adjacent. We show that the phrase-based translation engine we implemented benefits from Tree-Phrases.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nicola Bertoldi</author>
<author>Roldano Cattoni</author>
<author>Mauro Cettolo</author>
<author>Marcello Federico</author>
</authors>
<title>The ITC-irst statistical machine translation system for IWSLT-2004. In</title>
<date>2004</date>
<booktitle>IWSLT,</booktitle>
<pages>51--58</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="8689" citStr="Bertoldi et al., 2004" startWordPosition="1445" endWordPosition="1448">of a hypothesis h by the proj operator which collects in order the words of a hypothesis along one language: projF(h) = I rn fp : p ∈ Si=1{A -E[1,ni] o projE(h) = S ep : p ∈ Si=1{lim}mE[1,mi]o If we denote by Hf the set of hypotheses that have f as a source projection (that is, Hf = {h : projF(h) ≡ f}), then our translation engine seeks e� = projE(h) where: h = argmax s(h) hEWf The function we seek to maximize s(h) is a loglinear combination of 9 components, and might be better understood as the numerator of a maximum entropy model popular in several statistical MT systems (Och and Ney, 2002; Bertoldi et al., 2004; Zens and Ney, 2004; Simard et al., 2005; Quirk et al., 2005). The components are the so-called feature functions (described below) and the weighting coefficients (λ) are the parameters of the model: s(h) = λpprf log ppprf (h) + λp|h|+ λtprf log ptprf (h) + λt|h|+ λppibm log pppibm(h)+ λtpibm log ptpibm(h)+ λlm log plm(projE(h))+ λd d(h) + λw|projE(h)| 3.2 The components of the scoring function We briefly enumerate the features used in this study. Translation models Even if a tree-phrase is a generalization of a standard phrase-phrase unit, for investigation purposes, we differentiate in our </context>
</contexts>
<marker>Bertoldi, Cattoni, Cettolo, Federico, 2004</marker>
<rawString>Nicola Bertoldi, Roldano Cattoni, Mauro Cettolo, and Marcello Federico. 2004. The ITC-irst statistical machine translation system for IWSLT-2004. In IWSLT, pages 51–58, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Didier Bourigault</author>
<author>C´ecile Fabre</author>
</authors>
<title>Approche linguistique pour l’analyse syntaxique de corpus. Cahiers de Grammaire, (25):131–151. Toulouse le Mirail.</title>
<date>2000</date>
<contexts>
<context position="4465" citStr="Bourigault and Fabre, 2000" startWordPosition="720" endWordPosition="723">a source, fully-lexicalized treelet (TL) and a target phrase (EP), that is, the target words associated with the nodes of the treelet, in order. A treelet can be an arbitrary, fully-lexicalized subtree of the parse tree associated with a source sentence. A phrase can be an arbitrary sequence of words. This includes the standard notion of phrase, popular with phrasedbased SMT (Koehn et al., 2003; Vogel et al., 2003) as well as sequences of words that contain gaps (possibly of arbitrary size). In this study, we collected a repository of treephrases using a robust syntactic parser called SYNTEX (Bourigault and Fabre, 2000). SYNTEX identifies syntactic dependency relations between words. It takes as input a text processed by the TREETAGGER part-of-speech tagger.1 An example of the output SYNTEX produces for the source (French) sentence “on a demand´e des cr´edits f´ed´eraux” (request for federal funding) is presented in Figure 1. We parsed with SYNTEX the source (French) part of our training bitext (see Section 4.1). From this material, we extracted all dependency subtrees of depth 1 from the complete dependency trees found by SYNTEX. An elastic phrase is simply the list of tokens aligned with the words of the c</context>
</contexts>
<marker>Bourigault, Fabre, 2000</marker>
<rawString>Didier Bourigault and C´ecile Fabre. 2000. Approche linguistique pour l’analyse syntaxique de corpus. Cahiers de Grammaire, (25):131–151. Toulouse le Mirail.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In 43rd ACL,</booktitle>
<pages>263--270</pages>
<location>Ann Arbor, Michigan, USA.</location>
<contexts>
<context position="1992" citStr="Chiang, 2005" startWordPosition="309" endWordPosition="310"> detail an approach where the standard phrases are extended to account for “gaps” either on the target or source side. They show that this representation has the potential to better exploit the training corpus and to nicely handle differences such as negations in French and English that are poorly handled by standard phrase-based models. Others are considering translation as a synchronous parsing process e.g. (Melamed, 2004; Ding and Palmer, 2005)) and several algorithms have been proposed to learn the underlying production rule probabilities (Graehl and Knight, 2004; Ding and Palmer, 2004). (Chiang, 2005) proposes an heuristic way of acquiring context free transfer rules that significantly improves upon a standard phrase-based model. As mentioned in (Ding and Palmer, 2005), most of these approaches require some assumptions on the level of isomorphism (lexical and/or structural) between two languages. In this work, we consider a simple kind of unit: a Tree-Phrase (TP), a combination of a fully lexicalized treelet (TL) and an elastic phrase (EP), the tokens of which may be in non-contiguous positions. TPs capture some syntactic information between two languages and can easily be merged with stan</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A hierarchical phrase-based model for statistical machine translation. In 43rd ACL, pages 263–270, Ann Arbor, Michigan, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuang Ding</author>
<author>Martha Palmer</author>
</authors>
<title>Automatic learning of parallel dependency treelet pairs.</title>
<date>2004</date>
<booktitle>In Proceedings of the first International Joint Conference on NLP.</booktitle>
<contexts>
<context position="1976" citStr="Ding and Palmer, 2004" startWordPosition="305" endWordPosition="308">at. (Simard et al., 2005) detail an approach where the standard phrases are extended to account for “gaps” either on the target or source side. They show that this representation has the potential to better exploit the training corpus and to nicely handle differences such as negations in French and English that are poorly handled by standard phrase-based models. Others are considering translation as a synchronous parsing process e.g. (Melamed, 2004; Ding and Palmer, 2005)) and several algorithms have been proposed to learn the underlying production rule probabilities (Graehl and Knight, 2004; Ding and Palmer, 2004). (Chiang, 2005) proposes an heuristic way of acquiring context free transfer rules that significantly improves upon a standard phrase-based model. As mentioned in (Ding and Palmer, 2005), most of these approaches require some assumptions on the level of isomorphism (lexical and/or structural) between two languages. In this work, we consider a simple kind of unit: a Tree-Phrase (TP), a combination of a fully lexicalized treelet (TL) and an elastic phrase (EP), the tokens of which may be in non-contiguous positions. TPs capture some syntactic information between two languages and can easily be </context>
</contexts>
<marker>Ding, Palmer, 2004</marker>
<rawString>Yuang Ding and Martha Palmer. 2004. Automatic learning of parallel dependency treelet pairs. In Proceedings of the first International Joint Conference on NLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuan Ding</author>
<author>Martha Palmer</author>
</authors>
<title>Machine translation using probabilistic synchronous dependency insertion grammars.</title>
<date>2005</date>
<booktitle>In 43rd ACL,</booktitle>
<pages>541--548</pages>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="1830" citStr="Ding and Palmer, 2005" startWordPosition="283" endWordPosition="286">ov et al., 2005) propose to reorder the source text in order to mimic the target word order, and then let a phrase-based model do what it is good at. (Simard et al., 2005) detail an approach where the standard phrases are extended to account for “gaps” either on the target or source side. They show that this representation has the potential to better exploit the training corpus and to nicely handle differences such as negations in French and English that are poorly handled by standard phrase-based models. Others are considering translation as a synchronous parsing process e.g. (Melamed, 2004; Ding and Palmer, 2005)) and several algorithms have been proposed to learn the underlying production rule probabilities (Graehl and Knight, 2004; Ding and Palmer, 2004). (Chiang, 2005) proposes an heuristic way of acquiring context free transfer rules that significantly improves upon a standard phrase-based model. As mentioned in (Ding and Palmer, 2005), most of these approaches require some assumptions on the level of isomorphism (lexical and/or structural) between two languages. In this work, we consider a simple kind of unit: a Tree-Phrase (TP), a combination of a fully lexicalized treelet (TL) and an elastic ph</context>
</contexts>
<marker>Ding, Palmer, 2005</marker>
<rawString>Yuan Ding and Martha Palmer. 2005. Machine translation using probabilistic synchronous dependency insertion grammars. In 43rd ACL, pages 541–548, Ann Arbor, Michigan, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
</authors>
<title>Training tree transducers.</title>
<date>2004</date>
<booktitle>In HLT-NAACL 2004,</booktitle>
<pages>105--112</pages>
<location>Boston, Massachusetts, USA,</location>
<contexts>
<context position="1952" citStr="Graehl and Knight, 2004" startWordPosition="301" endWordPosition="304">model do what it is good at. (Simard et al., 2005) detail an approach where the standard phrases are extended to account for “gaps” either on the target or source side. They show that this representation has the potential to better exploit the training corpus and to nicely handle differences such as negations in French and English that are poorly handled by standard phrase-based models. Others are considering translation as a synchronous parsing process e.g. (Melamed, 2004; Ding and Palmer, 2005)) and several algorithms have been proposed to learn the underlying production rule probabilities (Graehl and Knight, 2004; Ding and Palmer, 2004). (Chiang, 2005) proposes an heuristic way of acquiring context free transfer rules that significantly improves upon a standard phrase-based model. As mentioned in (Ding and Palmer, 2005), most of these approaches require some assumptions on the level of isomorphism (lexical and/or structural) between two languages. In this work, we consider a simple kind of unit: a Tree-Phrase (TP), a combination of a fully lexicalized treelet (TL) and an elastic phrase (EP), the tokens of which may be in non-contiguous positions. TPs capture some syntactic information between two lang</context>
</contexts>
<marker>Graehl, Knight, 2004</marker>
<rawString>Jonathan Graehl and Kevin Knight. 2004. Training tree transducers. In HLT-NAACL 2004, pages 105–112, Boston, Massachusetts, USA, May 2 - May 7. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Joseph Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical Phrase-Based Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT,</booktitle>
<pages>127--133</pages>
<contexts>
<context position="940" citStr="Koehn et al., 2003" startWordPosition="133" endWordPosition="136">s, i.e. associations between simple syntactic dependency treelets in a source language and their corresponding phrases in a target language. The Tree-Phrases we use in this study are syntactically informed and present the advantage of gathering source and target material whose words do not have to be adjacent. We show that the phrase-based translation engine we implemented benefits from Tree-Phrases. 1 Introduction Phrase-based machine translation is now a popular paradigm. It has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (Koehn et al., 2003). The underlying unit (a pair of phrases), however, does not handle well languages with very different word orders and fails to derive generalizations from the training corpus. Several alternatives have been recently proposed to tackle some of these weaknesses. (Matusov et al., 2005) propose to reorder the source text in order to mimic the target word order, and then let a phrase-based model do what it is good at. (Simard et al., 2005) detail an approach where the standard phrases are extended to account for “gaps” either on the target or source side. They show that this representation has the</context>
<context position="4235" citStr="Koehn et al., 2003" startWordPosition="680" endWordPosition="683"> in Section 4 the experiments we conducted combining standard phrase pairs and TPs. We discuss this work in Section 5 and then conclude in Section 6. 2 Tree-Phrases We call tree-phrase (TP) a bilingual unit consisting of a source, fully-lexicalized treelet (TL) and a target phrase (EP), that is, the target words associated with the nodes of the treelet, in order. A treelet can be an arbitrary, fully-lexicalized subtree of the parse tree associated with a source sentence. A phrase can be an arbitrary sequence of words. This includes the standard notion of phrase, popular with phrasedbased SMT (Koehn et al., 2003; Vogel et al., 2003) as well as sequences of words that contain gaps (possibly of arbitrary size). In this study, we collected a repository of treephrases using a robust syntactic parser called SYNTEX (Bourigault and Fabre, 2000). SYNTEX identifies syntactic dependency relations between words. It takes as input a text processed by the TREETAGGER part-of-speech tagger.1 An example of the output SYNTEX produces for the source (French) sentence “on a demand´e des cr´edits f´ed´eraux” (request for federal funding) is presented in Figure 1. We parsed with SYNTEX the source (French) part of our tra</context>
<context position="21056" citStr="Koehn et al., 2003" startWordPosition="3624" endWordPosition="3627"> 11 million TLs and 10 million EPs. Roughly half of the treelets collected have exactly two dependents (three word long treelets). Since the word alignment of non-contiguous phrases is likely to be less accurate than the alignment of adjacent word sequences, we further filter the repository of TPs by keeping the most likely EPs for each TL according to an estimate of p(EP|TL) that do not take into account the offsets of the EP or the TL. PP-model We collected the PP parameters by simply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (Koehn et al., 2003). We use an inhouse tool to collect pairs of phrases of up to 8 words. Freely available packages such as THOT (Ortiz-Martinez et al., 2005) could be used as well for that purpose. 44 Language model We trained a Kneser-Ney trigram language model using the SRILM toolkit (Stolcke, 2002). 4.3 Protocol We compared the performances of two versions of our engine: one which employs TPs ans PPs (TPENGINE hereafter), and one which only uses PPs (PP-ENGINE). We translated the 16 disjoint subcorpora of the TEST corpus with and without TPs. We measure the quality of the translation produced with three auto</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Joseph Och, and Daniel Marcu. 2003. Statistical Phrase-Based Translation. In Proceedings of HLT, pages 127–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Pharaoh: a Beam Search Decoder for Phrase-Based SMT.</title>
<date>2004</date>
<booktitle>In Proceedings of AMTA,</booktitle>
<pages>115--124</pages>
<contexts>
<context position="6423" citStr="Koehn, 2004" startWordPosition="1058" endWordPosition="1059">the ones we use in this study. with the first pair of structures listed in the example. 3 The Translation Engine under the constraints that for all i E u], &lt; , bn E for a source treelet (similar constraints apply on the target side), and = + 1, bn E [1, for a source phrase. The way the hypotheses are built imposes additional constraints between units that will be described in Section 3.3. Note that, at decoding time, [1, jin jin+1 [1,ni[ jin+1 jin ni[ |e|, the number of words des f´ed´eraux We built a translation engine very similar to the statistical phrase-based engine PHARAOH described in (Koehn, 2004) that we extended to use tree-phrases. Not only does our decoder differ from PHARAOH by using TPs, it also uses direct translation models. We know from (Och and Ney, 2002) that not using the noisy-channel approach does not impact the quality of the tran slation produced. 3.1 The maximization setting For a source sentence f, our engine incrementally generates a set of translation hypotheses by combining tree-phrase (TP) units and phrase-phrase (PP) units.2 We define a hypothesis in this set ash = a set of u pairs of source and target sequences of and mi H {Ui=(Fi,Ei)}iE[1,-], (Fi) (Ei) ni words</context>
<context position="10623" citStr="Koehn, 2004" startWordPosition="1771" endWordPosition="1772"> back to a standard phrase-based translation engine. This will serve as a reference system in the experiments reported (see Section 4). The language model Following a standard practice, we use a trigram target language model plm(projE(h)) to control the fluency of the translation produced. See Section 3.3 for technical subtleties related to their use in our engine. a demand´e ≡ request for, f´ed´eraux ≡ federal, cr´edits ≡ funding treelets: cr´edits a demand´e ������� ������� ������� ������� des f´ed´eraux on cr´edits 41 Distortion model d This feature is very similar to the one described in (Koehn, 2004) and only depends on the offsets of the source units. The only difference here arises when TPs are used to build a translation hypothesis: n d(h) = — abs(1 + Fi_1 — Fi) i=1 where: � EnE[1,nz] ji n/ni if Fi is a treelet Fi = ji otherwise n� Fi = ji1 This score encourages the decoder to produce a monotonous translation, unless the language model strongly privileges the opposite. Global bias features Finally, three simple features help control the translation produced. Each TP (resp. PP) unit used to produce a hypothesis receives a fixed weight At (resp. Ap). This allows the introduction of an ar</context>
<context position="14179" citStr="Koehn, 2004" startWordPosition="2423" endWordPosition="2424"> the best hypothesis in that stack are considered for expansion. We also limit the number of hypotheses maintained in a given stack to the top maxStack ones (maxStack is typically set to 500). Because beam-pruning tends to promote in a stack partial hypotheses that translate easy parts (i.e. parts 42 that are highly scored by the translation and language models), the score considered while pruning not only involves the cost of a partial hypothesis so far, but also an estimation of the future cost that will be incurred by fully expanding it. FUTURECOST — We followed the heuristic described in (Koehn, 2004), which consists in computing for each source range [i, j] the minimum cost c(i, j) with which we can translate the source sequence fji . This is pre-computed efficiently at an early stage of the decoding (second line of the algorithm in Figure 3) by a bottom-up dynamic programming scheme relying on the following recursion: minkE[i,j[c(i, k) + c(k, j) I c(i, j) =min minuEU/usnf;z =usscore(us) where us stands for the projection of u on the target side (us - projE(u)), and score(u) is computed by considering the language model and the translation components ppp of the s(h) score. The future cost</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Pharaoh: a Beam Search Decoder for Phrase-Based SMT. In Proceedings of AMTA, pages 115–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhanyi Liu</author>
<author>Haifeng Wang</author>
<author>Hua Wu</author>
</authors>
<title>Example-based machine translation based on tsc and statistical generation.</title>
<date>2005</date>
<booktitle>In Proceedings of MT Summit X,</booktitle>
<pages>25--32</pages>
<location>Phuket, Thailand.</location>
<marker>Liu, Wang, Wu, 2005</marker>
<rawString>Zhanyi Liu, Haifeng Wang, and Hua Wu. 2005. Example-based machine translation based on tsc and statistical generation. In Proceedings of MT Summit X, pages 25–32, Phuket, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeny Matusov</author>
<author>Stephan Kanthak</author>
<author>Hermann Ney</author>
</authors>
<title>Efficient statistical machine translation with constraint reordering.</title>
<date>2005</date>
<booktitle>In 10th EAMT,</booktitle>
<pages>181--188</pages>
<location>Budapest, Hongary,</location>
<contexts>
<context position="1224" citStr="Matusov et al., 2005" startWordPosition="178" endWordPosition="181">s do not have to be adjacent. We show that the phrase-based translation engine we implemented benefits from Tree-Phrases. 1 Introduction Phrase-based machine translation is now a popular paradigm. It has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (Koehn et al., 2003). The underlying unit (a pair of phrases), however, does not handle well languages with very different word orders and fails to derive generalizations from the training corpus. Several alternatives have been recently proposed to tackle some of these weaknesses. (Matusov et al., 2005) propose to reorder the source text in order to mimic the target word order, and then let a phrase-based model do what it is good at. (Simard et al., 2005) detail an approach where the standard phrases are extended to account for “gaps” either on the target or source side. They show that this representation has the potential to better exploit the training corpus and to nicely handle differences such as negations in French and English that are poorly handled by standard phrase-based models. Others are considering translation as a synchronous parsing process e.g. (Melamed, 2004; Ding and Palmer,</context>
</contexts>
<marker>Matusov, Kanthak, Ney, 2005</marker>
<rawString>Evgeny Matusov, Stephan Kanthak, and Hermann Ney. 2005. Efficient statistical machine translation with constraint reordering. In 10th EAMT, pages 181–188, Budapest, Hongary, May 30-31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Statistical machine translation by parsing.</title>
<date>2004</date>
<booktitle>In 42nd ACL,</booktitle>
<pages>653--660</pages>
<location>Barcelona,</location>
<contexts>
<context position="1806" citStr="Melamed, 2004" startWordPosition="281" endWordPosition="282">knesses. (Matusov et al., 2005) propose to reorder the source text in order to mimic the target word order, and then let a phrase-based model do what it is good at. (Simard et al., 2005) detail an approach where the standard phrases are extended to account for “gaps” either on the target or source side. They show that this representation has the potential to better exploit the training corpus and to nicely handle differences such as negations in French and English that are poorly handled by standard phrase-based models. Others are considering translation as a synchronous parsing process e.g. (Melamed, 2004; Ding and Palmer, 2005)) and several algorithms have been proposed to learn the underlying production rule probabilities (Graehl and Knight, 2004; Ding and Palmer, 2004). (Chiang, 2005) proposes an heuristic way of acquiring context free transfer rules that significantly improves upon a standard phrase-based model. As mentioned in (Ding and Palmer, 2005), most of these approaches require some assumptions on the level of isomorphism (lexical and/or structural) between two languages. In this work, we consider a simple kind of unit: a Tree-Phrase (TP), a combination of a fully lexicalized treele</context>
</contexts>
<marker>Melamed, 2004</marker>
<rawString>I. Dan Melamed. 2004. Statistical machine translation by parsing. In 42nd ACL, pages 653–660, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Joseph Och</author>
<author>Hermann Ney</author>
</authors>
<title>Improved Statistical Alignment Models.</title>
<date>2000</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>440--447</pages>
<location>Hongkong, China.</location>
<contexts>
<context position="19711" citStr="Och and Ney, 2000" startWordPosition="3386" endWordPosition="3389">pment and test corpora is detailed in Table 1. The TEST corpus is subdivided in 16 (disjoints) slices of 500 sentences each that we translated separately. The vocabulary is atypically large since some tokens are being merged by SYNTEX, such as ´etaient#financ´ees (were financed in English). The training corpus has been aligned at the word level by two Viterbi word-alignments (French2English and English2French) that we combined in a heuristic way similar to the refined method described in (Och and Ney, 2003). The parameters of the word models (IBM model 2) were trained with the GIZA++ package (Och and Ney, 2000). Table 1: Main characteristics of the corpora used in this study. For each language l, l-toks is the number of tokens, l-toks/sent is the average number of tokens per sentence (f the standard deviation), l-types is the number of different token forms and l-hapax is the number of tokens that appear only once in the corpus. 4.2 Models Tree-phrases Out of 1.7 million pairs of sentences, we collected more than 3 million different kinds of TLs from which we projected 6.5 million different kinds of EPs. Slightly less than half of the treelets are contiguous ones (i.e. involving a sequence of adjace</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>Franz Joseph Och and Hermann Ney. 2000. Improved Statistical Alignment Models. In Proceedings of ACL, pages 440–447, Hongkong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Joseph Och</author>
<author>Hermann Ney</author>
</authors>
<title>Discriminative training and maximum entropy models for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>295--302</pages>
<contexts>
<context position="6594" citStr="Och and Ney, 2002" startWordPosition="1086" endWordPosition="1089">for a source treelet (similar constraints apply on the target side), and = + 1, bn E [1, for a source phrase. The way the hypotheses are built imposes additional constraints between units that will be described in Section 3.3. Note that, at decoding time, [1, jin jin+1 [1,ni[ jin+1 jin ni[ |e|, the number of words des f´ed´eraux We built a translation engine very similar to the statistical phrase-based engine PHARAOH described in (Koehn, 2004) that we extended to use tree-phrases. Not only does our decoder differ from PHARAOH by using TPs, it also uses direct translation models. We know from (Och and Ney, 2002) that not using the noisy-channel approach does not impact the quality of the tran slation produced. 3.1 The maximization setting For a source sentence f, our engine incrementally generates a set of translation hypotheses by combining tree-phrase (TP) units and phrase-phrase (PP) units.2 We define a hypothesis in this set ash = a set of u pairs of source and target sequences of and mi H {Ui=(Fi,Ei)}iE[1,-], (Fi) (Ei) ni words respectively: = � E = � E Fi {fji� jin [1,|f|]}nE[1,ni]Ei {eii� lim [1,|e|]}mE[1,mi] we call here aphrase-phrase unit is simply a pair of sourc 2What e/target sequences o</context>
<context position="8666" citStr="Och and Ney, 2002" startWordPosition="1441" endWordPosition="1444"> target projection of a hypothesis h by the proj operator which collects in order the words of a hypothesis along one language: projF(h) = I rn fp : p ∈ Si=1{A -E[1,ni] o projE(h) = S ep : p ∈ Si=1{lim}mE[1,mi]o If we denote by Hf the set of hypotheses that have f as a source projection (that is, Hf = {h : projF(h) ≡ f}), then our translation engine seeks e� = projE(h) where: h = argmax s(h) hEWf The function we seek to maximize s(h) is a loglinear combination of 9 components, and might be better understood as the numerator of a maximum entropy model popular in several statistical MT systems (Och and Ney, 2002; Bertoldi et al., 2004; Zens and Ney, 2004; Simard et al., 2005; Quirk et al., 2005). The components are the so-called feature functions (described below) and the weighting coefficients (λ) are the parameters of the model: s(h) = λpprf log ppprf (h) + λp|h|+ λtprf log ptprf (h) + λt|h|+ λppibm log pppibm(h)+ λtpibm log ptpibm(h)+ λlm log plm(projE(h))+ λd d(h) + λw|projE(h)| 3.2 The components of the scoring function We briefly enumerate the features used in this study. Translation models Even if a tree-phrase is a generalization of a standard phrase-phrase unit, for investigation purposes, w</context>
</contexts>
<marker>Och, Ney, 2002</marker>
<rawString>Franz Joseph Och and Hermann Ney. 2002. Discriminative training and maximum entropy models for statistical machine translation. In Proceedings of the ACL, pages 295–302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Joseph Och</author>
<author>Hermann Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics,</title>
<date>2003</date>
<pages>29--19</pages>
<contexts>
<context position="19605" citStr="Och and Ney, 2003" startWordPosition="3367" endWordPosition="3370">ansards focussing on the translation of French into English. The split of this material into train, development and test corpora is detailed in Table 1. The TEST corpus is subdivided in 16 (disjoints) slices of 500 sentences each that we translated separately. The vocabulary is atypically large since some tokens are being merged by SYNTEX, such as ´etaient#financ´ees (were financed in English). The training corpus has been aligned at the word level by two Viterbi word-alignments (French2English and English2French) that we combined in a heuristic way similar to the refined method described in (Och and Ney, 2003). The parameters of the word models (IBM model 2) were trained with the GIZA++ package (Och and Ney, 2000). Table 1: Main characteristics of the corpora used in this study. For each language l, l-toks is the number of tokens, l-toks/sent is the average number of tokens per sentence (f the standard deviation), l-types is the number of different token forms and l-hapax is the number of tokens that appear only once in the corpus. 4.2 Models Tree-phrases Out of 1.7 million pairs of sentences, we collected more than 3 million different kinds of TLs from which we projected 6.5 million different kind</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Joseph Och and Hermann Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics, 29:19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Ortiz-Martinez</author>
<author>Ismael Garci´a-Varea</author>
<author>Francisco Casacuberta</author>
</authors>
<title>Thot: a toolkit to train phrase-based statistical translation models.</title>
<date>2005</date>
<booktitle>In Proceedings of MT Summit X,</booktitle>
<pages>141--148</pages>
<location>Phuket, Thailand,</location>
<marker>Ortiz-Martinez, Garci´a-Varea, Casacuberta, 2005</marker>
<rawString>Daniel Ortiz-Martinez, Ismael Garci´a-Varea, and Francisco Casacuberta. 2005. Thot: a toolkit to train phrase-based statistical translation models. In Proceedings of MT Summit X, pages 141–148, Phuket, Thailand, Sep.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In 40th ACL,</booktitle>
<pages>311--318</pages>
<location>Philadelphia, Pennsylvania.</location>
<contexts>
<context position="21806" citStr="Papineni et al., 2002" startWordPosition="3757" endWordPosition="3760"> al., 2005) could be used as well for that purpose. 44 Language model We trained a Kneser-Ney trigram language model using the SRILM toolkit (Stolcke, 2002). 4.3 Protocol We compared the performances of two versions of our engine: one which employs TPs ans PPs (TPENGINE hereafter), and one which only uses PPs (PP-ENGINE). We translated the 16 disjoint subcorpora of the TEST corpus with and without TPs. We measure the quality of the translation produced with three automatic metrics. Two error rates: the sentence error rate (SER) and the word error rate (WER) that we seek to minimize, and BLEU (Papineni et al., 2002), that we seek to maximize. This last metric was computed with the multi-bleu.perl script available at www. statmt.org/wmt06/shared-task/. We separately tuned both systems on the DEV corpus by applying a brute force strategy, i.e. by sampling uniformly the range of each parameter (A) and picking the configuration which led to the best BLEU score. This strategy is inelegant, but in early experiments we conducted, we found better configurations this way than by applying the Simplex method with multiple starting points. The tuning roughly takes 24 hours of computation on a cluster of 16 computers</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In 40th ACL, pages 311– 318, Philadelphia, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Quirk</author>
<author>Arul Menezes</author>
<author>Colin Cherry</author>
</authors>
<title>Dependency treelet translation: Syntactically informed phrasal SMT.</title>
<date>2005</date>
<booktitle>In 43rd ACL,</booktitle>
<pages>271--279</pages>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="2712" citStr="Quirk et al., 2005" startWordPosition="423" endWordPosition="426">a standard phrase-based model. As mentioned in (Ding and Palmer, 2005), most of these approaches require some assumptions on the level of isomorphism (lexical and/or structural) between two languages. In this work, we consider a simple kind of unit: a Tree-Phrase (TP), a combination of a fully lexicalized treelet (TL) and an elastic phrase (EP), the tokens of which may be in non-contiguous positions. TPs capture some syntactic information between two languages and can easily be merged with standard phrase-based engines. A TP can be seen as a simplification of the treelet pairs manipulated in (Quirk et al., 2005). In particular, we do not address the issue of projecting a source treelet into a target one, but take the bet that collecting (without structure) the target words associated with the words encoded in the nodes of a treelet will suffice to allow translation. This set of target words is what we call an elastic phrase. We show that these units lead to (modest) improvements in translation quality as measured by automatic metrics. We conducted all our experiments 39 Proceedings of the Workshop on Statistical Machine Translation, pages 39–46, New York City, June 2006. c�2006 Association for Comput</context>
<context position="7923" citStr="Quirk et al., 2005" startWordPosition="1295" endWordPosition="1298">{cr´edits@2}} EP? |request@0||for@1||funding@3| TL {{des@-1} cr´edits {f´ed´eraux@1}} EP |federal@0||funding@1| Figure 2: The Tree-Phrases collected out of the SYNTEX parse for the sentence pair of Figure 1. Non-contiguous structures are marked with a star. Each dependent node of a given governor token is displayed as a list surrounding the governor node, e.g. {governor {right-dependent}}. Along with the tokens of each node, we present their respective offset (the governor/root node has the offset 0 by definition). The format we use to represent the treelets is similar to the one proposed in (Quirk et al., 2005). of the translation is unknown, but is bounded according to |f |(in our case, |e|max = 2 × |f |+ 5). We define the source and target projection of a hypothesis h by the proj operator which collects in order the words of a hypothesis along one language: projF(h) = I rn fp : p ∈ Si=1{A -E[1,ni] o projE(h) = S ep : p ∈ Si=1{lim}mE[1,mi]o If we denote by Hf the set of hypotheses that have f as a source projection (that is, Hf = {h : projF(h) ≡ f}), then our translation engine seeks e� = projE(h) where: h = argmax s(h) hEWf The function we seek to maximize s(h) is a loglinear combination of 9 comp</context>
<context position="24542" citStr="Quirk et al., 2005" startWordPosition="4227" endWordPosition="4230">on average, each source sentence is covered by 39 TPs (their source part, naturally), yielding a source coverage of approximately 70%. In contrast, the average number of covering PPs per sentence is 233. 5 Discussion On a comparable test set (Canadian Hansard texts), (Simard et al., 2005) report improvements by adding non-contiguous bi-phrases to their engine without requiring a parser at all. At the same time, they also report negative results when adding non-contiguous phrases computed from the refined alignment technique that we used here. Although the results are not directly comparable, (Quirk et al., 2005) report much larger improvements over a phrase-based statistical engine with their translation engine that employs a source parser. The fact that we consider only depth-one treelets in this work, coupled with the absence of any particular treelet projection algorithm (which prevents us from training a syntactically motivated reordering model as they do) are other possible explanations for the modest yet significant improvements we observe in this study. 6 Conclusion We presented a pilot study aimed at appreciating the potential of Tree-Phrases as base units for examplebased machine translation</context>
</contexts>
<marker>Quirk, Menezes, Cherry, 2005</marker>
<rawString>Chris Quirk, Arul Menezes, and Colin Cherry. 2005. Dependency treelet translation: Syntactically informed phrasal SMT. In 43rd ACL, pages 271–279, Ann Arbor, Michigan, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Simard</author>
<author>Nicola Cancedda</author>
<author>Bruno Cavestro</author>
<author>Marc Dymetman</author>
</authors>
<title>Eric Gaussier, Cyril Goutte,</title>
<date>2005</date>
<booktitle>In HLT/EMNLP,</booktitle>
<pages>755--762</pages>
<location>Kenji Yamada, Philippe</location>
<contexts>
<context position="1379" citStr="Simard et al., 2005" startWordPosition="209" endWordPosition="212">e translation is now a popular paradigm. It has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (Koehn et al., 2003). The underlying unit (a pair of phrases), however, does not handle well languages with very different word orders and fails to derive generalizations from the training corpus. Several alternatives have been recently proposed to tackle some of these weaknesses. (Matusov et al., 2005) propose to reorder the source text in order to mimic the target word order, and then let a phrase-based model do what it is good at. (Simard et al., 2005) detail an approach where the standard phrases are extended to account for “gaps” either on the target or source side. They show that this representation has the potential to better exploit the training corpus and to nicely handle differences such as negations in French and English that are poorly handled by standard phrase-based models. Others are considering translation as a synchronous parsing process e.g. (Melamed, 2004; Ding and Palmer, 2005)) and several algorithms have been proposed to learn the underlying production rule probabilities (Graehl and Knight, 2004; Ding and Palmer, 2004). (</context>
<context position="8730" citStr="Simard et al., 2005" startWordPosition="1453" endWordPosition="1456">h collects in order the words of a hypothesis along one language: projF(h) = I rn fp : p ∈ Si=1{A -E[1,ni] o projE(h) = S ep : p ∈ Si=1{lim}mE[1,mi]o If we denote by Hf the set of hypotheses that have f as a source projection (that is, Hf = {h : projF(h) ≡ f}), then our translation engine seeks e� = projE(h) where: h = argmax s(h) hEWf The function we seek to maximize s(h) is a loglinear combination of 9 components, and might be better understood as the numerator of a maximum entropy model popular in several statistical MT systems (Och and Ney, 2002; Bertoldi et al., 2004; Zens and Ney, 2004; Simard et al., 2005; Quirk et al., 2005). The components are the so-called feature functions (described below) and the weighting coefficients (λ) are the parameters of the model: s(h) = λpprf log ppprf (h) + λp|h|+ λtprf log ptprf (h) + λt|h|+ λppibm log pppibm(h)+ λtpibm log ptpibm(h)+ λlm log plm(projE(h))+ λd d(h) + λw|projE(h)| 3.2 The components of the scoring function We briefly enumerate the features used in this study. Translation models Even if a tree-phrase is a generalization of a standard phrase-phrase unit, for investigation purposes, we differentiate in our MT system between two kinds of models: a </context>
<context position="24212" citStr="Simard et al., 2005" startWordPosition="4177" endWordPosition="4180">% SER% BLEU% PP 52.80 ± 1.2 94.32 ± 0.9 29.95 ± 1.2 TP 51.98 ± 1.2 92.83 ± 1.3 30.47 ± 1.4 Table 2: Median WER, SER and BLEU scores (± value range) of the translations produced by the two engines on a test set of 16 disjoint corpora of 500 sentences each. The figures reported are percentages. On the DEV corpus, we measured that, on average, each source sentence is covered by 39 TPs (their source part, naturally), yielding a source coverage of approximately 70%. In contrast, the average number of covering PPs per sentence is 233. 5 Discussion On a comparable test set (Canadian Hansard texts), (Simard et al., 2005) report improvements by adding non-contiguous bi-phrases to their engine without requiring a parser at all. At the same time, they also report negative results when adding non-contiguous phrases computed from the refined alignment technique that we used here. Although the results are not directly comparable, (Quirk et al., 2005) report much larger improvements over a phrase-based statistical engine with their translation engine that employs a source parser. The fact that we consider only depth-one treelets in this work, coupled with the absence of any particular treelet projection algorithm (w</context>
</contexts>
<marker>Simard, Cancedda, Cavestro, Dymetman, 2005</marker>
<rawString>Michel Simard, Nicola Cancedda, Bruno Cavestro, Marc Dymetman, Eric Gaussier, Cyril Goutte, Kenji Yamada, Philippe Langlais, and Arne Mauser. 2005. Translating with non-contiguous phrases. In HLT/EMNLP, pages 755–762, Vancouver, British Columbia, Canada, Oct.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>Srilm - an Extensible Language Modeling Toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of ICSLP,</booktitle>
<location>Denver, Colorado,</location>
<contexts>
<context position="21340" citStr="Stolcke, 2002" startWordPosition="3677" endWordPosition="3679">ry of TPs by keeping the most likely EPs for each TL according to an estimate of p(EP|TL) that do not take into account the offsets of the EP or the TL. PP-model We collected the PP parameters by simply reading the alignment matrices resulting from the word alignment, in a way similar to the one described in (Koehn et al., 2003). We use an inhouse tool to collect pairs of phrases of up to 8 words. Freely available packages such as THOT (Ortiz-Martinez et al., 2005) could be used as well for that purpose. 44 Language model We trained a Kneser-Ney trigram language model using the SRILM toolkit (Stolcke, 2002). 4.3 Protocol We compared the performances of two versions of our engine: one which employs TPs ans PPs (TPENGINE hereafter), and one which only uses PPs (PP-ENGINE). We translated the 16 disjoint subcorpora of the TEST corpus with and without TPs. We measure the quality of the translation produced with three automatic metrics. Two error rates: the sentence error rate (SER) and the word error rate (WER) that we seek to minimize, and BLEU (Papineni et al., 2002), that we seek to maximize. This last metric was computed with the multi-bleu.perl script available at www. statmt.org/wmt06/shared-ta</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. Srilm - an Extensible Language Modeling Toolkit. In Proceedings of ICSLP, Denver, Colorado, Sept.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Ying Zhang</author>
<author>Fei Huang</author>
<author>Alicai Tribble</author>
<author>Ashish Venugopal</author>
<author>Bing Zao</author>
<author>Alex Waibel</author>
</authors>
<date>2003</date>
<booktitle>The CMU Statistical Machine Translation System. In Machine Translation Summit IX,</booktitle>
<location>New Orleans, Louisina, USA,</location>
<contexts>
<context position="4256" citStr="Vogel et al., 2003" startWordPosition="684" endWordPosition="687">periments we conducted combining standard phrase pairs and TPs. We discuss this work in Section 5 and then conclude in Section 6. 2 Tree-Phrases We call tree-phrase (TP) a bilingual unit consisting of a source, fully-lexicalized treelet (TL) and a target phrase (EP), that is, the target words associated with the nodes of the treelet, in order. A treelet can be an arbitrary, fully-lexicalized subtree of the parse tree associated with a source sentence. A phrase can be an arbitrary sequence of words. This includes the standard notion of phrase, popular with phrasedbased SMT (Koehn et al., 2003; Vogel et al., 2003) as well as sequences of words that contain gaps (possibly of arbitrary size). In this study, we collected a repository of treephrases using a robust syntactic parser called SYNTEX (Bourigault and Fabre, 2000). SYNTEX identifies syntactic dependency relations between words. It takes as input a text processed by the TREETAGGER part-of-speech tagger.1 An example of the output SYNTEX produces for the source (French) sentence “on a demand´e des cr´edits f´ed´eraux” (request for federal funding) is presented in Figure 1. We parsed with SYNTEX the source (French) part of our training bitext (see Sec</context>
</contexts>
<marker>Vogel, Zhang, Huang, Tribble, Venugopal, Zao, Waibel, 2003</marker>
<rawString>Stephan Vogel, Ying Zhang, Fei Huang, Alicai Tribble, Ashish Venugopal, Bing Zao, and Alex Waibel. 2003. The CMU Statistical Machine Translation System. In Machine Translation Summit IX, New Orleans, Louisina, USA, Sep.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Zens</author>
<author>Hermann Ney</author>
</authors>
<title>Improvements in phrase-based statistical machine translation.</title>
<date>2004</date>
<booktitle>In Proceedings of the HLT/NAACL,</booktitle>
<pages>257--264</pages>
<location>Boston, MA,</location>
<contexts>
<context position="8709" citStr="Zens and Ney, 2004" startWordPosition="1449" endWordPosition="1452">e proj operator which collects in order the words of a hypothesis along one language: projF(h) = I rn fp : p ∈ Si=1{A -E[1,ni] o projE(h) = S ep : p ∈ Si=1{lim}mE[1,mi]o If we denote by Hf the set of hypotheses that have f as a source projection (that is, Hf = {h : projF(h) ≡ f}), then our translation engine seeks e� = projE(h) where: h = argmax s(h) hEWf The function we seek to maximize s(h) is a loglinear combination of 9 components, and might be better understood as the numerator of a maximum entropy model popular in several statistical MT systems (Och and Ney, 2002; Bertoldi et al., 2004; Zens and Ney, 2004; Simard et al., 2005; Quirk et al., 2005). The components are the so-called feature functions (described below) and the weighting coefficients (λ) are the parameters of the model: s(h) = λpprf log ppprf (h) + λp|h|+ λtprf log ptprf (h) + λt|h|+ λppibm log pppibm(h)+ λtpibm log ptpibm(h)+ λlm log plm(projE(h))+ λd d(h) + λw|projE(h)| 3.2 The components of the scoring function We briefly enumerate the features used in this study. Translation models Even if a tree-phrase is a generalization of a standard phrase-phrase unit, for investigation purposes, we differentiate in our MT system between tw</context>
</contexts>
<marker>Zens, Ney, 2004</marker>
<rawString>Richard Zens and Hermann Ney. 2004. Improvements in phrase-based statistical machine translation. In Proceedings of the HLT/NAACL, pages 257–264, Boston, MA, May.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>