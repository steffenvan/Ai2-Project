<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.9847465">
Towards the Generation of Rebuttals in a Bayesian
Argumentation System
</title>
<author confidence="0.960068">
Nathalie Jitnah, Ingrid Zukerman, Richard McConachy and Sarah George
</author>
<affiliation confidence="0.9944295">
School of Computer Science and Software Engineering
Monash University
</affiliation>
<address confidence="0.693167">
Clayton, Victoria 3800, AUSTRALIA
</address>
<email confidence="0.826193">
email: Inj itnah, ingrid, ricky , sarahgl@cs se . monash edu . au
</email>
<sectionHeader confidence="0.975982" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999946230769231">
We describe a mechanism which generates rebuttals
to a user&apos;s rejoinders in the context of arguments
generated from Bayesian networks. This mechanism
is implemented in an interactive argumentation sys-
tem. Given an argument generated by the system
and an interpretation of a user&apos;s rejoinder, the gener-
ation of the rebuttal takes into account the intended
effect of the user&apos;s rejoinder, determined on a model
of the user&apos;s beliefs, and its actual effect, determined
on a model of the system&apos;s beliefs. We consider three
main rebuttal strategies: refute the user&apos;s rejoinder,
strengthen the argument goal, and dismiss the user&apos;s
line of reasoning.
</bodyText>
<sectionHeader confidence="0.993774" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.986907344262295">
During argumentation, conversational partners of-
ten use expressions of doubt, such as &amp;quot;But the vic-
tim was stabbed&amp;quot;, and requests for the considera-
tion of additional facts they consider relevant, such
as &amp;quot;What about the fingerprints found on the gun?&amp;quot;.
In this paper, we describe a mechanism which gen-
erates rebuttals to such rejoinders in the context of
arguments generated from Bayesian networks (BNs)
(Pearl, 1988). This mechanism is implemented in
a system called BIAS (Bayesian Interactive Argu-
mentation System). Given an argument produced
by BIAS and a follow-up rejoinder posed by a user,
our mechanism generates a rebuttal on the basis of a
line of reasoning identified by BIAS from the user&apos;s
rejoinder. These capabilities constitute a significant
step towards allowing a user to interact freely with
an argumentation system and to improve the expla-
nation capability of Bayesian systerns.
Normal arguments are unconstrained in the sense
that they can use whatever means are available to
justify a goal proposition.&apos;&apos; -In--contrast, rebuttals
are constrained, since they must address the point
through which the conversational partner attempted
to undermine or question a previous argument. To
illustrate the operation of BIAS and its rebuttal ca-
pability, consider the exchange in Figure 1, which
consists of a preamble that contains background in-
formation. followed by an argument generated by
BIAS, a user&apos;s rejoinder and BIAS&apos; rebuttal.&apos; The
domain of implementation is a murder investigation
where the question under consideration (the goal
proposition) is &amp;quot;Did Mr Green murder Mr Body?&amp;quot;,
and both the user and the system have access to evi-
dence. After the presentation of the argument where
BIAS contends Mr Green&apos;s possible innocence,2 the
user presents a rejoinder which requests that BIAS
consider a fact that was omitted from the argument:
The found gun is available only to Mr Green. BIAS
infers from this rejoinder that the user is adding sup-
port to Mr Green having the means to kill Mr Body,
and hence to Mr Green&apos;s guilt, through the following
line of reasoning, which is determined as described
in (Zukerman et al., 2000): The gun being available
only to Mr Green —&gt; The gun was fired by Mr Green
-4 Mr Green had the means to kill Mr Body -4 Mr
Green killed Mr Body. BIAS finds that it does not
share the user&apos;s belief in the rejoinder proposition,
and that in addition, the effect of this proposition on
the goal is rather weak. This prompts the genera-
tion of a rebuttal of the form Deny-Dismiss-Follow,
whereby the rejoinder proposition is denied, its effect
on the goal proposition is dismissed, and its impli-
cations are followed hypothetically until they break
down due to the marginal effect of the rejoinder on
Mr Green&apos;s guilt.
In the next section, we present our knowledge rep-
resentation formalism, followed by an outline of our
procedure for determining a user&apos;s line of reasoning.
In Section 4, we describe our algorithm for rebuttal
generation and discuss our results. We then review
related work and present concluding remarks.
</bodyText>
<sectionHeader confidence="0.801167" genericHeader="introduction">
2 - Knowledge Representation
</sectionHeader>
<bodyText confidence="0.999753">
During the argumentation process, BIAS maintains
two models of belief: a normative model and a user
model, each -of-which is represented as a BN. The
normative model contains information gathered di-
rectly by BIAS from the murder scenario, while the
user model stores propositions that are presumed to
</bodyText>
<footnote confidence="0.94580125">
&apos;The argument and rebuttals shown in this paper are re-
alized in English as described in (Zukerman et al., 1999).
2The mechanism which generates this argument is de-
scribed in (Zukerman et al., 1998).
</footnote>
<page confidence="0.997654">
39
</page>
<figureCaption confidence="0.559428909090909">
Preamble:
Mr. Body was found dead in his bedroom, which is in the second .story of his house. Bullet wounds
were found in Mr. Body&apos;s body. The bedroom window was broken and broken glass was found inside
the window. A gun was found on the premises, and some fingerprints were found on the gun. In
addition, inspection of the grounds revealed footprints in the garden and circular indentations in the
ground outside the bedroom window.
BIAS&apos; argument:
Bullets being found in Mr Body&apos;s body implies Mr Body was almost certainly shot. This implies he
was almost certainly murdered.
Forensics matching the bullets with the found gun implies the gun is almost certainly the murder
weapon. Forensics matching the fingerprints .with Mr Green implies Mr Green probably fired the gun.
</figureCaption>
<bodyText confidence="0.902192363636364">
This together with the gun almost certainly being the murder weapon implies Mr Green probably
fired the murder weapon, which implies he very probably had the means to murder Mr Body.
The Bayesian Times reporting Mr Body took Mr Green&apos;s girlfriend implies Mr Green and Mr Body
possibly were enemies, which implies Mr Green possibly had a motive to murder Mr Body.
The neighbour reporting Mr Green not being in the garden at 11 implies Mr Green very probably
wasn&apos;t in the garden at 11.
Forensics reporting the time of death being 11 and the forensic analysis of the time of death being
reliable implies the time of death was probably 11, which together with Mr Green very probably not
being in the garden at 11 implies he probably wasn&apos;t in the garden at the time of death. This implies
he probably didn&apos;t have the opportunity to murder Mr Body.
Even though Mr Green very probably had the means to murder Mr Body and he possibly had a
motive to murder Mr Body, Mr Green probably not having the opportunity to murder Mr Body
implies he probably didn&apos;t murder Mr Body.
User&apos;s rejoinder: Consider that the found gun is available only to Mr Green.
BIAS&apos; rebuttal:
Actually, it is very improbable that the found gun is available only to Mr Green. However, even if it
was available only to Mr Green, this would have only a small effect on the likelihood that Mr Green
murdered Mr Body. This is for the following reason.
The found gun being available only to Mr Green implies it is more likely that Mr Green fired the gun,
making it almost certain. This implies it is more likely that he fired the murder weapon, making it
almost certain, which implies it is even more likely that he had the means to murder Mr Body. This
implies it is only slightly more likely that he murdered Mr Body.
</bodyText>
<figureCaption confidence="0.99955">
Figure 1: Sample Argument, Rejoinder and Rebuttal
</figureCaption>
<bodyText confidence="0.999774913043478">
be believed by the user. These propositions may be
obtained from a variety of sources, e.g., they may
have been inspected by the user in the murder sce-
nario (by means of a WWW interface), or appear in
BIAS&apos; previous arguments or the user&apos;s rejoinders.
Arguments generated by BIAS are represented by
means of an Argument Graph — a sub-network of
the normative model BN which ideally also contains
nodes from the user model BN.
The interpretation process, where BIAS identifies
the reasoning path intended by the user, takes place
in the user model; since BIAS tries. to .`.&apos;make sense&amp;quot;-
of what the user is saying according to the system&apos;s
view of the user&apos;s beliefs (Zukerman et al., 2000).
In contrast, the processes for generating the initial
argument and the rebuttals consult both the user
model and the normative model to produce argu-
ments that rely on beliefs held by both BIAS and
the user if possible. Further, during rebuttal gener-
ation, the choice of a rebuttal strategy depends on
the intended effect of the user&apos;s argument (according
to the user model) and its actual effect (according
to the normative model).
</bodyText>
<sectionHeader confidence="0.982199" genericHeader="method">
3 Determining a User&apos;s Line of
Reasoning
</sectionHeader>
<bodyText confidence="0.99874425">
Our procedure for recognizing a user&apos;s intended line
of reasoning from his/her rejoinder receives two in-
puts: a linguistic clue (&amp;quot;but&amp;quot; or &amp;quot;consider&amp;quot;) and a
rejoinder proposition (R), e.g., &amp;quot;but Mr Green was
in the garden&amp;quot;: It then-finds-paths in the user model
BN that connect R to the goal proposition (Zuker-
man et al., 2000). During this process, BIAS copes
with inference patterns that are different from its
own by allowing inferred paths to contain a small
&amp;quot;gap&amp;quot; composed of propositions that did not ex-
ist previously in the user model. Figure 2(a) il-
lustrates an Argument Graph, a rejoinder R, and
</bodyText>
<page confidence="0.987061">
40
</page>
<figure confidence="0.975582444444444">
(a) Argument Graph and userPath (b) Refute R:
R = user Val has large effect on G;
BIAS and the user disagree on R
(c) Dismiss userPath:
R = userVal has small effect on G
for BIAS
(d)Strengthen G:
R = user Val has large effect on G;
BIAS and the user agree on R
</figure>
<figureCaption confidence="0.999838">
Figure 2: Sample Argument Graph and Rejoinder Strategies
</figureCaption>
<bodyText confidence="0.999945842105263">
path R-I-M-E-A-G between them (composed of grey
nodes). This path, called userPath, represents the
line of reasoning intended by the user. The gap in
this path contains nodes land M (in italics), which
means that the user inferred E directly from R.
Each path is assigned a score based on the fol-
lowing factors: the impact of R on BIAS&apos; argu-
ment along this path, whether path nodes are in
the user&apos;s attentional focus, and BIAS&apos; confidence in
this path (determined from the information source
of the nodes in this path, e.g., whether the user has
seen the propositions in the path, asserted a be-
lief about them or read them in BIAS&apos; arguments).
BIAS then selects the highest-scoring path. If sev-
eral paths have a high score, the user is asked to
choose one of them. Typically, BIAS returns a single
path, and sometimes it returns two or three paths.
Hence, presenting them to the user for selection is a
reasonable course of action.
</bodyText>
<sectionHeader confidence="0.992407" genericHeader="method">
4 Rebuttal Generation
</sectionHeader>
<bodyText confidence="0.999966076923077">
Given a user&apos;s rejoinder proposition R. we consider
three main types of rebuttals: (1) refute R, (2) dis-
miss the line of reasoning intended by the user (user-
Path), and (3) strengthen the argument goal G. Di-
agrammatic representations of these rebuttal strate-
gies and abridged versions of their applicability con-
ditions appear in Figure 2(b-d). These conditions,
which are specified in the following sections, depend
on (1) whether the rejoinder affects the system&apos;s ar-
gument directly or indirectly, (2) the beliefs in R in
the normative and user models, and (3) the impact
of R on the goal proposition along userPath in the
normative and user models.
</bodyText>
<subsectionHeader confidence="0.997384">
4.1 Refute the rejoinder
</subsectionHeader>
<bodyText confidence="0.978158">
This strategy consists of generating an argument
against the user&apos;s belief in the rejoinder proposition&apos;
R. This strategy .is applicable under .the following
conditions:
</bodyText>
<listItem confidence="0.9350955">
(R1) The beliefs in R in the user model and the
normative model differ significantly (the user&apos;s
belief in R contradicts BIAS&apos; belief); and
(R2) Either
(a) R was stated or implied in BIAS&apos; argument
(R appears in the Argument Graph), or
</listItem>
<page confidence="0.995219">
41
</page>
<bodyText confidence="0.998442071428571">
(b) The belief in R stated by the user has a
significant effect on the goal G in the nor-
mative model in the same direction as its
effect on G in the user model.
For example, if the user&apos;s rejoinder to the argu-
ment in Figure 1 was &amp;quot;But Mr Green and Mr Body
were not enemies&amp;quot;, then conditions R1 and R2a
would be satisfied, since the rejoinder directly con-
tradicts what was stated by BIAS in the argument.
If the user&apos;s rejoinder was &amp;quot;But the neighbour saw
Mr Green shoot Mr- Bodyr3.-then conditions R.1
and R2b would be satisfied, since an inference from
this rejoinder contradicts BIAS&apos; belief in Mr Green&apos;s
lack of opportunity to kill Mr Body (and conse-
quently in Mr Green&apos;s guilt). The argument schema
for the refute the rejoinder strategy and a sample
rebuttal produced with this schema are shown in
Figure 3.3 The sub-argument that argues against
the rejoinder proposition is generated by activating
our Bayesian argument generator (Zukerman et al.,
1998) with the proposition Mr Green and Mr Body
were enemies as the goal. In this case, the belief in
the rejoinder node resulting from the sub-argument
differs from that stated in the initial argument, ow-
ing to the additional information included in the
sub-argument. Hence, the implications from the re-
joinder node are followed. The procedure for follow-
ing these implications is described in Section 4.2.
</bodyText>
<subsectionHeader confidence="0.998147">
4.2 Dismiss the user&apos;s line of reasoning
</subsectionHeader>
<bodyText confidence="0.999691565217391">
This strategy consists of showing the user how
his/her argument fails to achieve its intended ef-
fect. We distinguish between concessive and con-
tradictory dismissals. The former is used when the
system agrees with the rejoinder proposition R, and
the latter when the system disagrees with R. This
strategy is applicable under the following condition:
(D) R does not significantly affect the belief in G
in the normative model.
This condition is illustrated by the rejoinder to the
argument in Figure 1, &amp;quot;Consider that the found gun
was available only to Mr Green&amp;quot;, which purports to
increase the belief in Mr Green&apos;s means to kill Mr
Body, and hence Mr Green&apos;s guilt. However, since
this increment is quite small, BIAS adopts the dis7.
missal strategy, which follows the effect of the user&apos;s
rejoinder through the user&apos;s line of reasoning, point-
ing out how the effect of the rejoinder differs from its
intended effect. It is worth noting that the main dif-
ference between a dismissal and a strengthening of
the goal is that BIAS decides to generate a dismissal
when its current beliefs are sufficient to invalidate
the user&apos;s line of reasoning, whereas it decides to
</bodyText>
<footnote confidence="0.897979">
3The rejoinders shown in this paper are posed by the user
immediately after the argument in Figure I.
</footnote>
<note confidence="0.356646">
Refute R:
</note>
<listItem confidence="0.9990415">
• 1. Deny the belief in R stated by the user.
2. Present a sub-argument for the normative
belief in R.
3. If R is not in the Argument Graph or the
belief in R as a result of the sub-argument
differs from that originally stated by BIAS,
then follow the effect of R along userPath
up to the first node in the Argument Graph
_whose belief is the same .as that stated in
the initial argument.
</listItem>
<sectionHeader confidence="0.883124" genericHeader="method">
Rejoinder:
</sectionHeader>
<subsectionHeader confidence="0.58161">
But Mr Green and Mr Body were not enemies.
Rebuttal:
</subsectionHeader>
<bodyText confidence="0.999631741935484">
Actually, it is quite likely that Mr Green and
Mr Body were enemies. This is for the following
reason.
The forensic analysis of the blue paint being
reliable and forensics having found some blue
paint which they estimate is one week old im-
plies a blue car was here last week. This to-
gether with Mr Green having a blue car implies
Mr Green&apos;s car was almost certainly here last
week, which implies Mr Green almost certainly
visited Mr Body last week.
The neighbour being sober implies she is very
probably reliable. This together with the neigh-
bour reporting Mr Green arguing with Mr Body
last week implies the neighbour very probably
heard Mr Green arguing with Mr Body last
week, which together with Mr Green almost
certainly visiting Mr Body last week implies he
almost certainly argued with Mr Body.
The Bayesian Times reporting Mr Body took
Mr Green&apos;s girlfriend implies Mr Body prob-
ably seduced Mr Green&apos;s girlfriend. This to-
gether with Mr Green almost certainly arguing
with Mr Body implies Mr Green and Mr Body
probably were enemies.
Let&apos;s now go back to the main argument.
Mr Green and Mr Body probably being enemies
implies it is more likely that Mr Green had a
motive to murder Mr Body, making it rather
likely. This implies it is only slightly more likely
that he murdered Mr Body.
</bodyText>
<figureCaption confidence="0.993744">
Figure 3: Refute the rejoinder Schema and Example
</figureCaption>
<bodyText confidence="0.998388571428571">
strengthen the goal when additional information is
required to defeat the impact of the user&apos;s rejoinder.
Our algorithm for dismissing the user&apos;s line of rea-
soning follows userPath until it reaches a point where
the user&apos;s line of reasoning fails, i.e., it has no ef-
fect on a proposition on userPath in the Argument
Graph. It is necessary for the rebuttal to reach the
</bodyText>
<page confidence="0.995801">
42
</page>
<bodyText confidence="0.99980265">
Argument Graph even if the failure of the rejoinder
occurs earlier in userPath,. because the user&apos;s rejoin-
der refers to the argument, hence at least one propo-
sition in the argument must be mentioned when ad-
dressing the impact of this rejoinder.
The user&apos;s line of reasoning may fail due to the
following factors: (1) s/he did not consider propo-
sitions that have a significant effect on the propo-
sitions in userPath; or (2) his/her belief in one or
more of the propositions s/he did consider differs
significantly from that..th..the normative model, And
this proposition has a substantial effect on a propo-
sition in userPath. Propositions of the first type are
included in a set called SIGneighbours, and proposi-
tions of the second type are included in DIFFneigh-
bours. Our dismissal algorithm calls our Bayesian ar-
gument generator to generate sub-arguments for the
propositions in DIFFneighbours, but simply presents
the propositions in SIGneighbours without arguing
for them.
</bodyText>
<sectionHeader confidence="0.850366" genericHeader="method">
Algorithm DismissUserReasoning(userPath)
</sectionHeader>
<bodyText confidence="0.970581">
Let userPath be composed of propositions
</bodyText>
<listItem confidence="0.990524052631579">
1. For i 1 to n do:
(a) Set SIGneighbours(Pi) to the nodes that
are linked to Pi in the normative model but
not in the user model and have a significant
effect on the belief in P.
(b) If the belief in Pi in the user model
differs significantly from the belief in
Pi in the normative model, then set
DIFFneighbours(Pi) to the nodes that are
linked to Pi in both the user model and the
normative model and which have a differ-
ent belief in the user model from that in
the normative model.
(c) For each node Pi E DIFFneighbours(Pi)
generate a sub-argument for the normative
belief in Pi.
2. Present the resulting rebuttal using the appro-
priate schema, DismissContradict or Dismiss-
Concede (Figures 4 and 5 and respectively).
</listItem>
<bodyText confidence="0.9989395">
Our concessive schema differs from our contradic-
tory schema in two respects. Firstly, the former ac-
knowledges the user&apos;s rejoinder, while the latter de-
nies it. In addition, the concessive schema follows
the user&apos;s line of reasoning starting-from the nor-
mative belief in the rejoinder proposition (which is
close to the belief indicated by the user), while the
contradictory schema follows a hypothetical line of
reasoning starting from the user&apos;s belief in the re-
joinder proposition (which differs substantially from
the normative belief). In both cases the user&apos;s line
of reasoning fizzles out, clue to its small effect on the
</bodyText>
<listItem confidence="0.931186625">
DismissContradict userPath:
• -Deny t he- beliefin ft stated -.by the user,
and dismiss its hypothetical effect on the
goal proposition.
2. Present the sub-arguments for the nodes in
DIFFneighbours.
3. FollowPath userPath from the rejoinder
proposition to the goal.
</listItem>
<subsectionHeader confidence="0.604348">
FollowPath userPath
</subsectionHeader>
<bodyText confidence="0.880627666666667">
For 4= 0 to n,— 1.(whereJi is the-number of
nodes in userPath) do:
1. If P1+1 is not in the Argument Graph or
DIFFneighbours(P1+1)$0, then present an
implication from Pi to P1.4.1 which includes
the nodes linked to Pi+i in the user model
plus the nodes in SIGneighbours(Pz+i).
Else present an implication which reflects
only the relative impact of Pz on P,±1.
</bodyText>
<listItem confidence="0.845813666666667">
2. If the resulting belief in Pi is the same
as that stated in the initial argument, then
stop.
</listItem>
<figureCaption confidence="0.860871">
Figure 4: DismissContradict Schema and Follow-
Path Procedure
</figureCaption>
<bodyText confidence="0.998620275862069">
goal according to the normative model irrespective
of its truth value.
Both schemas follow userPath from the rejoinder
proposition to the goal using procedure FollowPath
(Figure 4). This procedure distinguishes between
propositions in userPath for which the main influ-
encing factors (DIFFneighbours and SIGneighbours)
should be presented, and those which require only
information regarding the relative impact of the pre-
ceding proposition in userPath. The latter proposi-
tions are characterized as follows: (1) they appear
in the Argument Graph; and (2) the user&apos;s beliefs in
the nodes outside userPath that have a significant
effect on these propositions are consistent with the
normative beliefs in these nodes. For instance. the
rebuttal in Figure 1, which is generated by means of
the DismissContradict schema, presents the relative
influence of Mr Green fired the gun on Mr Green
fired the murder weapon, since the user and BIAS
hold consistent beliefs regarding the gun being the
murder weapon.
- To illustrate theoperation of the dismissal algo-
rithm, let us consider the rejoinder &amp;quot;But the time of
death was 11&amp;quot;, which yields the following line of rea-
soning: The time of death was II (e4 Mr Green was
in the garden at II) -4 Mr Green was in the garden
at the time of death -4 Mr Green had the opportu-
nity to kill Mr Body -4 Mr Green killed Mr Body.
DIFFneighbours includes only one proposition. Mr
</bodyText>
<page confidence="0.999104">
43
</page>
<listItem confidence="0.8475698">
DismissConcede userPath:
1. Acknowledge the.belief in -R stated by the
user, and dismiss its effect on the goal
proposition.
2. Present the sub-arguments for the nodes in
DIFFneighbours.
3. FollowPath userPath from the rejoinder
proposition to the goal.
Rejoinder: But the time of death was 11.
Rebuttal:
</listItem>
<bodyText confidence="0.998285413793104">
Indeed, it is quite likely but not entirely certain
that the time of death was 11. However, this
has only a small effect on the likelihood that
Mr Green murdered Mr Body.
I will show that Mr Green almost certainly
wasn&apos;t in the garden at 11.
Mr Green&apos;s witness not being related to Mr
Green implies she is very probably reliable.
This together with Mr Green&apos;s witness report-
ing Mr Green being at the football at 10:30
implies Mr Green was almost certainly at the
football at 10:30.
The neighbour being sober implies she is almost
certainly reliable. This together with the neigh-
bour reporting Mr Green not being in the gar-
den at 11 implies the neighbour never saw Mr
Green in the garden at 11, which together with
Mr Green almost certainly being at the football
at 10:30 implies he almost certainly wasn&apos;t in
the garden at 11.
Let&apos;s now go back to the main argument.
Even though the time of death was probably
11, Mr Green almost certainly not being in the
garden at 11 implies it is only slightly less likely
that he was in the garden at the time of death.
This implies it is only slightly less likely that
he had the opportunity to murder Mr Body,
which implies it is only slightly less likely that
he murdered Mr Body.
</bodyText>
<figureCaption confidence="0.993981">
Figure 5: DismissConcede Schema and Example
</figureCaption>
<bodyText confidence="0.999957461538461">
Green was in the garden at 11, since the belief in it
in the normative model differs from that in the user
model, thereby prompting the generation of a sub-
argument for this proposition.. This sub-argument
is stronger than that incorporated in the initial ar-
gument, yielding a belief in:MI...Green...being in the
garden at 11 that is lower than the belief indicated
in the original argument, which in turn reduces the
belief in Mr Green being in the garden at the time of
death, Mr Green having the opportunity to kill Mr
Body, and Mr Green actually murdering Mr Body.
The resulting rebuttal. which is presented by means
of the DismissConcede schema. appears in Figure 5.
</bodyText>
<subsectionHeader confidence="0.90799">
4.3 Strengthen the goal
</subsectionHeader>
<bodyText confidence="0.825041666666667">
. This strategy. consista-ofgenerating a stronger argu-
ment for the original goal proposition G, bringing to
bear information that did not appear in the initial
argument (either because BIAS was unaware of it
or because BIAS chose to exclude it from the argu-
ment). This strategy is applicable under the follow-
ing conditions:
(G1) The beliefs in R in the normative and user
models are consistent; and
</bodyText>
<listItem confidence="0.87793575">
• (G2) R has a substantial detrimental effect on the
belief in G in the normative model. This change
in belief should be in the same direction as the
change occurring in the user model.
</listItem>
<bodyText confidence="0.999614258064516">
These conditions represent a situation where the
system did not take into account a particular fact,
but when this fact comes to its attention the sys-
tem realizes the effect of this fact on the goal. For
instance, if the user discovers new evidence that
places Mr Green in the garden at 11, a rejoinder
which presents this proposition will increase the be-
lief in Mr Green&apos;s opportunity to kill Mr Body along
the following line of reasoning: Mr Green was in
the garden at II Mr Green was in the garden at
the time of death —&gt; Mr Green had the opportunity
to kill Mr Body --+ Mr Green killed Mr Body. In
this case, BIAS tries to strengthen the argument for
Mr Green&apos;s innocence by arguing separately against
propositions along this line of reasoning (other than
the rejoinder node, which is true in this example).
If no sub-argument can be generated for these nodes
or the generated sub-arguments do not significantly
affect the goal, then BIAS agrees with the user.
Our algorithm for strengthening the goal searches
along userPath for propositions that have been af-
fected by the rejoinder, but that will reinforce BIAS&apos;
goal proposition if their belief is changed. It then
tries to generate sub-arguments that change the be-
liefs in these propositions. In order to localize the
effect of the user&apos;s rejoinder, the search and sub-
argument generation processes start at R and pro-
ceed towards the goal. The presentation of the re-
buttal is also done in this order, using a procedure
which is similar to the FollowPath procedure de-
scribed in Section 4.2.
</bodyText>
<subsectionHeader confidence="0.519607">
Algorithm StrengthenGoal(userPath)
</subsectionHeader>
<bodyText confidence="0.7364025">
Let userPath be composed of propositions
R= P0 -+ P1 -4 P2 . . . Pr, -----G G.
</bodyText>
<listItem confidence="0.997339142857143">
1. For i = 1 to n, while the belief in G is not as
intended by BIAS, do:
(a) Determine which belief in P, will move the
belief in G in the normative model in the
direction intended by BIAS.
(b) If tins belief in P, differs from the current
belief in P„ then
</listItem>
<page confidence="0.96218">
44
</page>
<listItem confidence="0.654237">
i. Generate a sub-argument for the de-
sired belief in P,.
</listItem>
<bodyText confidence="0.960455518518519">
ii. If the sub-argument yields a significant
change in the belief in P, or in the be-
lief in G then store the sub-argument in
SubAG(Pi).
2. Present the resulting rebuttal (composed of the
user&apos;s line of reasoning and intervening sub-
arguments) using the StrengthenGoal schema
in Figure 6.
To illustrate the operation of this algorithm, let
us reconsider the rejoinder &amp;quot;Consider Mr Green was
in the garden at 11&amp;quot;, and let us assume that the re-
joinder proposition is true. Inspection of the prop-
ositions affected by this rejoinder reveals that if Mr
Green was not in the garden at the time of death,
then the belief in the goal would be closer to that
intended by BIAS. However, an argument for this
proposition cannot be generated. Hence, BIAS pro-
ceeds to the next proposition, Mr Green had the op-
portunity to murder Mr Body, and calls our Bayesian
argument generator to generate an argument that
contradicts this proposition. The Bayesian genera-
tor produces an argument which reduces the belief
in this proposition. However, this belief cannot be
reduced to the extent that it exculpates Mr Green.
Thus, BIAS attempts to generate an argument for
the goal node (by trying to reduce the belief in Mr
Green&apos;s means and motive to kill Mr Body). How-
ever, this attempt also fails, leaving BIAS with a
moderate belief in Mr Green&apos;s guilt.&apos;
It is important to note that although BIAS&apos; im-
mediate objective is to strengthen its belief in the
goal proposition, its primary purpose is to &amp;quot;tell the
truth&amp;quot; to the best of its knowledge (which may con-
tradict its initial beliefs), rather than to win the ar-
gument at all costs. Our algorithm supports this
attitude by retaining any sub-argument which has
a significant impact on the goal or on a proposi-
tion on userPath. We use this disjunctive condition
on impacts in order to address a situation where a
proposition P„ on userPath has been affected by a
sub-argument, but does not affect the goal because
of an inaccurate belief in a proposition Pk which ap-
pears later on userPath (recall that the propositions
are inspected from R towards the goal). However,
once a sub-argument for Pk.is presented, then P, af-
fects the goal. If BIAS accepted only sub-arguments
for propositions which have a significant impact on
the goal, then in this case it would miss the oppor-
tunity to strengthen the goal.
&apos;The resulting argument has not been included owing to
space limitations.
St rengthenGoal userPath:
F. -Acknowledge the--beliefin-R stated by the
user, and set lastProposition to R.
</bodyText>
<figure confidence="0.9752761">
2. Until the goal proposition is reached do:
(a) If after lastProposition there is a
proposition Pi EuserPath for which
a sub-argument was generated
(SubAG(P2) 0), then
i. Follow userPath from lastProposi-
tion
ii. Present the sub-argument for P,.
iii. Set lastProposition to P2.
(b) Else follow the remainder of userPath.
</figure>
<figureCaption confidence="0.999733">
Figure 6: Strengthen the goal Schema
</figureCaption>
<sectionHeader confidence="0.995636" genericHeader="method">
5 Related Research
</sectionHeader>
<bodyText confidence="0.999970648648649">
Our research builds on work described in (Zukerman
et al., 1998), which generated arguments from BNs,
and (Zukerman et al., 1999), which enabled a user
to explore the impact of different propositions on
the generated arguments. The former system only
generated arguments, while the latter received in-
structions from a user (through a menu) about mod-
ifications to be performed to a previously generated
argument, e.g., including or excluding a proposition,
and then generated a new argument in response to
these instructions. Neither of these systems gener-
ates rebuttals which take into account a user&apos;s in-
tentions, as done by BIAS.
Several researchers have dealt with different as-
pects of argumentation, e.g., (Flowers et al., 1982;
Quilici, 1992; Chu-Carroll and Carberry, 1995; Car-
berry and Lambert, 1999). Like BIAS, the system
described in Carberry and Lambert (1999) combined
linguistic and contextual knowledge to recognize a
user&apos;s intentions from rejoinders. However, their
system did not generate rebuttals. Chu-Carroll and
Carberry (1995) provided a comprehensive approach
for proposal evaluation which focused on dialogue
strategies rather than argumentation strategies. In
addition, they considered exchanges where each par-
ticipant utters one or two propositions in each con-
versational turn. In contrast, we focus on strategies
for the generation of extended probabilistic rebuttals
to individual rejoinders. In the future, our strategies
will botombined with -dialogue strategies in a com-
plete argumentation system.
Flowers et al. (1982) presented a partial theory
of argumentation which advocated the combination
of distinct knowledge sources; their implementation
focused on recognizing and providing episodic justi-
fications to historical events. Our focus on the gen-
eration of rebuttals in the context of BNs allows us
</bodyText>
<page confidence="0.997609">
45
</page>
<bodyText confidence="0.999855333333333">
to provide an operational definition for the broad
argumentation strategies discussed in the literature,_
e.g., attack the main point directly or attack the
supporting evidence (Flowers et al., 1982).5
The argumentation system described in (Quilici,
1992) used a plan-based model of the user&apos;s beliefs to
recognize the justification for a user&apos;s proposal and
provide its own justifications. However, the rebut-
tals generated by this system were based on a single
strategy: applying backwards chaining using a set of
justification rules. This strategy is a special case of
the more general rebuttal schemas presented here.
</bodyText>
<sectionHeader confidence="0.994715" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999123974358974">
We have offered a mechanism for generating rebut-
tals to a user&apos;s rejoinders in the context of argu-
ments generated by a Bayesian argumentation sys-
tem. We have implemented three main argumenta-
tion strategies: refuting the rejoinder, strengthening
the argument goal, and dismissing the user&apos;s line of
reasoning. For each strategy we have identified ap-
plicability conditions, proposed a procedure which
determines the information to be included in a re-
buttal, and defined a presentation schema.
An interesting area of future research pertains
to the omission of information from an argument.
There are different types of information which may
be omitted from an argument, such as (1) easily
inferred information and information which has a
small effect on the argument; (2) information which
is required for representational reasons, but makes
the resulting argument more confusing; (3) proba-
bilistic information which, although correct, makes
the resulting argument more tedious; and (4) pre-
viously stated information. Our previous research
deals with the first type of information (Zukerman
et al., 1998), and in this paper we have identified
some conditions for the omission of previously stated
information when expressing the relative impact of
a proposition. Another factor that affects the omis-
sion of information is the trade off between accuracy
and conciseness. The omission of information affects
the belief in the conclusion(s) presented in an argu-
ment. Stating beliefs that differ from a system&apos;s own
beliefs may cause the system to appear inconsistent
or even deceitful, while presenting all the relevant
factors may yield a verbose argument. A mecha-
nism which addresses these issues will support the
generation of better arguments and rebuttals.
The evaluation of this sesearch,encompasses-sev-
eral components: (1) the WWW interface, (2) the
path-finding mechanism. and (3) the rebuttal-
generation mechanism. A preliminary evaluation of
</bodyText>
<footnote confidence="0.98239525">
5We do not handle the &amp;quot;attack the claim that the evidence
gives support for the main point&amp;quot; strategy, as this involves
inferring Conditional Probability Matrices for the user model,
which is outside the scope of this research.
</footnote>
<bodyText confidence="0.999523909090909">
the path-finding mechanism has yielded encourag-
ing results (Zukerman al., .2000)., Twotypes of
evaluation are envisaged for the rebuttal-generation
mechanism. A whole-system evaluation, where users
interact freely with BIAS, may be used to deter-
mine whether users are satisfied with the system as
a whole. In contrast, a specific evaluation of rebut-
tals would be restricted to showing users rejoinder-
rebuttal pairs (after showing an initial argument),
and eliciting the users&apos; reactions regarding the ap-
propriateness of the rebuttals.
</bodyText>
<sectionHeader confidence="0.9985" genericHeader="acknowledgments">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.7982705">
This work was supported in part by Australian Re-
search Council grant A49927212.
</bodyText>
<sectionHeader confidence="0.994098" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999555820512821">
Carberry, S. and Lambert, L. (1999). A pro-
cess model for recognizing communicative acts
and modeling negotiation subdialogues. Compu-
tational Linguistics, 25(1):1-53.
Chu-Carroll, J. and Carberry, S. (1995). Generat-
ing information-sharing subdialogues in expert-
user consultation. In IJCAI95 - Proceedings of
the Fourteenth International Joint Conference on
Artificial Intelligence, pages 1243-1250.
Flowers, M., McGuire, R., and Birnbaum, L. (1982).
Adversary arguments and the logic of personal
attack. In Strategies for Natural Language Pro-
cessing, pages 275-294. Lawrence Erlbaum Asso-
ciates, Hillsdale, New Jersey.
Pearl, J. (1988). Probabilistic Reasoning in Intelli-
gent Systems. Morgan Kaufmann Publishers, San
Mateo, California.
Quilici, A. (1992). Arguing about planning al-
ternatives. In COLING-92 - Proceedings of the
Fourteenth International Conference on Computa-
tional Linguistics, pages 906-910, Nantes, France.
Zukerman, I., Jitnah, N., McConachy, R., and
George, S. (2000). Recognizing intentions from re-
joinders in a Bayesian interactive argumentation
system. To appear in PRICAI2000 - Proceedings
of the Sixth Pacific Rim International Conference
on Artificial Intelligence, Melbourne, Australia.
Zukerman, I., McConachy, R., and Korb, K. B.
(1998). Bayesian reasoning in an abductive mech-
anism for argument generation and analysis. In
AAA198 - Proceedings of the Fifteenth National
Conference on Artificial Intelligence, pages 833-
• 838,, Madison Wisconsin.
Zukerman, I., McConachy, R., Korb, K. B., and
Pickett, D. A. (1999). Exploratory interaction
with a Bayesian argumentation system. In If-
CA 199 - Proceedings of the Sixteenth Interna-
tional Joint Conference on Artificial Intelligence,
pages 1294-1299, Stockholm, Sweden.
</reference>
<page confidence="0.999611">
46
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.323491">
<title confidence="0.9980185">Towards the Generation of Rebuttals in a Argumentation System</title>
<author confidence="0.98708">Nathalie Jitnah</author>
<author confidence="0.98708">Ingrid Zukerman</author>
<author confidence="0.98708">Richard McConachy</author>
<author confidence="0.98708">Sarah</author>
<affiliation confidence="0.850478">School of Computer Science and Software Monash</affiliation>
<address confidence="0.714687">Clayton, Victoria 3800, Inj ingrid, ricky , sarahgl@cs se . monash edu . au</address>
<abstract confidence="0.999609285714286">We describe a mechanism which generates rebuttals to a user&apos;s rejoinders in the context of arguments generated from Bayesian networks. This mechanism is implemented in an interactive argumentation system. Given an argument generated by the system and an interpretation of a user&apos;s rejoinder, the generation of the rebuttal takes into account the intended effect of the user&apos;s rejoinder, determined on a model of the user&apos;s beliefs, and its actual effect, determined on a model of the system&apos;s beliefs. We consider three main rebuttal strategies: refute the user&apos;s rejoinder, strengthen the argument goal, and dismiss the user&apos;s line of reasoning.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Carberry</author>
<author>L Lambert</author>
</authors>
<title>A process model for recognizing communicative acts and modeling negotiation subdialogues.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<pages>25--1</pages>
<contexts>
<context position="29295" citStr="Carberry and Lambert, 1999" startWordPosition="4987" endWordPosition="4991">ferent propositions on the generated arguments. The former system only generated arguments, while the latter received instructions from a user (through a menu) about modifications to be performed to a previously generated argument, e.g., including or excluding a proposition, and then generated a new argument in response to these instructions. Neither of these systems generates rebuttals which take into account a user&apos;s intentions, as done by BIAS. Several researchers have dealt with different aspects of argumentation, e.g., (Flowers et al., 1982; Quilici, 1992; Chu-Carroll and Carberry, 1995; Carberry and Lambert, 1999). Like BIAS, the system described in Carberry and Lambert (1999) combined linguistic and contextual knowledge to recognize a user&apos;s intentions from rejoinders. However, their system did not generate rebuttals. Chu-Carroll and Carberry (1995) provided a comprehensive approach for proposal evaluation which focused on dialogue strategies rather than argumentation strategies. In addition, they considered exchanges where each participant utters one or two propositions in each conversational turn. In contrast, we focus on strategies for the generation of extended probabilistic rebuttals to individua</context>
</contexts>
<marker>Carberry, Lambert, 1999</marker>
<rawString>Carberry, S. and Lambert, L. (1999). A process model for recognizing communicative acts and modeling negotiation subdialogues. Computational Linguistics, 25(1):1-53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Chu-Carroll</author>
<author>S Carberry</author>
</authors>
<title>Generating information-sharing subdialogues in expertuser consultation.</title>
<date>1995</date>
<booktitle>In IJCAI95 - Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1243--1250</pages>
<contexts>
<context position="29266" citStr="Chu-Carroll and Carberry, 1995" startWordPosition="4983" endWordPosition="4986">ser to explore the impact of different propositions on the generated arguments. The former system only generated arguments, while the latter received instructions from a user (through a menu) about modifications to be performed to a previously generated argument, e.g., including or excluding a proposition, and then generated a new argument in response to these instructions. Neither of these systems generates rebuttals which take into account a user&apos;s intentions, as done by BIAS. Several researchers have dealt with different aspects of argumentation, e.g., (Flowers et al., 1982; Quilici, 1992; Chu-Carroll and Carberry, 1995; Carberry and Lambert, 1999). Like BIAS, the system described in Carberry and Lambert (1999) combined linguistic and contextual knowledge to recognize a user&apos;s intentions from rejoinders. However, their system did not generate rebuttals. Chu-Carroll and Carberry (1995) provided a comprehensive approach for proposal evaluation which focused on dialogue strategies rather than argumentation strategies. In addition, they considered exchanges where each participant utters one or two propositions in each conversational turn. In contrast, we focus on strategies for the generation of extended probabi</context>
</contexts>
<marker>Chu-Carroll, Carberry, 1995</marker>
<rawString>Chu-Carroll, J. and Carberry, S. (1995). Generating information-sharing subdialogues in expertuser consultation. In IJCAI95 - Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, pages 1243-1250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Flowers</author>
<author>R McGuire</author>
<author>L Birnbaum</author>
</authors>
<title>Adversary arguments and the logic of personal attack.</title>
<date>1982</date>
<booktitle>In Strategies for Natural Language Processing,</booktitle>
<pages>275--294</pages>
<location>Hillsdale, New Jersey.</location>
<contexts>
<context position="29219" citStr="Flowers et al., 1982" startWordPosition="4977" endWordPosition="4980">rman et al., 1999), which enabled a user to explore the impact of different propositions on the generated arguments. The former system only generated arguments, while the latter received instructions from a user (through a menu) about modifications to be performed to a previously generated argument, e.g., including or excluding a proposition, and then generated a new argument in response to these instructions. Neither of these systems generates rebuttals which take into account a user&apos;s intentions, as done by BIAS. Several researchers have dealt with different aspects of argumentation, e.g., (Flowers et al., 1982; Quilici, 1992; Chu-Carroll and Carberry, 1995; Carberry and Lambert, 1999). Like BIAS, the system described in Carberry and Lambert (1999) combined linguistic and contextual knowledge to recognize a user&apos;s intentions from rejoinders. However, their system did not generate rebuttals. Chu-Carroll and Carberry (1995) provided a comprehensive approach for proposal evaluation which focused on dialogue strategies rather than argumentation strategies. In addition, they considered exchanges where each participant utters one or two propositions in each conversational turn. In contrast, we focus on st</context>
<context position="30525" citStr="Flowers et al., 1982" startWordPosition="5164" endWordPosition="5167">ers. In the future, our strategies will botombined with -dialogue strategies in a complete argumentation system. Flowers et al. (1982) presented a partial theory of argumentation which advocated the combination of distinct knowledge sources; their implementation focused on recognizing and providing episodic justifications to historical events. Our focus on the generation of rebuttals in the context of BNs allows us 45 to provide an operational definition for the broad argumentation strategies discussed in the literature,_ e.g., attack the main point directly or attack the supporting evidence (Flowers et al., 1982).5 The argumentation system described in (Quilici, 1992) used a plan-based model of the user&apos;s beliefs to recognize the justification for a user&apos;s proposal and provide its own justifications. However, the rebuttals generated by this system were based on a single strategy: applying backwards chaining using a set of justification rules. This strategy is a special case of the more general rebuttal schemas presented here. 6 Conclusion and Future Work We have offered a mechanism for generating rebuttals to a user&apos;s rejoinders in the context of arguments generated by a Bayesian argumentation system.</context>
</contexts>
<marker>Flowers, McGuire, Birnbaum, 1982</marker>
<rawString>Flowers, M., McGuire, R., and Birnbaum, L. (1982). Adversary arguments and the logic of personal attack. In Strategies for Natural Language Processing, pages 275-294. Lawrence Erlbaum Associates, Hillsdale, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pearl</author>
</authors>
<title>Probabilistic Reasoning in Intelligent Systems.</title>
<date>1988</date>
<publisher>Morgan Kaufmann Publishers,</publisher>
<location>San Mateo, California.</location>
<contexts>
<context position="1397" citStr="Pearl, 1988" startWordPosition="213" endWordPosition="214">on a model of the system&apos;s beliefs. We consider three main rebuttal strategies: refute the user&apos;s rejoinder, strengthen the argument goal, and dismiss the user&apos;s line of reasoning. 1 Introduction During argumentation, conversational partners often use expressions of doubt, such as &amp;quot;But the victim was stabbed&amp;quot;, and requests for the consideration of additional facts they consider relevant, such as &amp;quot;What about the fingerprints found on the gun?&amp;quot;. In this paper, we describe a mechanism which generates rebuttals to such rejoinders in the context of arguments generated from Bayesian networks (BNs) (Pearl, 1988). This mechanism is implemented in a system called BIAS (Bayesian Interactive Argumentation System). Given an argument produced by BIAS and a follow-up rejoinder posed by a user, our mechanism generates a rebuttal on the basis of a line of reasoning identified by BIAS from the user&apos;s rejoinder. These capabilities constitute a significant step towards allowing a user to interact freely with an argumentation system and to improve the explanation capability of Bayesian systerns. Normal arguments are unconstrained in the sense that they can use whatever means are available to justify a goal propos</context>
</contexts>
<marker>Pearl, 1988</marker>
<rawString>Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems. Morgan Kaufmann Publishers, San Mateo, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Quilici</author>
</authors>
<title>Arguing about planning alternatives.</title>
<date>1992</date>
<booktitle>In COLING-92 - Proceedings of the Fourteenth International Conference on Computational Linguistics,</booktitle>
<pages>906--910</pages>
<location>Nantes, France.</location>
<contexts>
<context position="29234" citStr="Quilici, 1992" startWordPosition="4981" endWordPosition="4982">ich enabled a user to explore the impact of different propositions on the generated arguments. The former system only generated arguments, while the latter received instructions from a user (through a menu) about modifications to be performed to a previously generated argument, e.g., including or excluding a proposition, and then generated a new argument in response to these instructions. Neither of these systems generates rebuttals which take into account a user&apos;s intentions, as done by BIAS. Several researchers have dealt with different aspects of argumentation, e.g., (Flowers et al., 1982; Quilici, 1992; Chu-Carroll and Carberry, 1995; Carberry and Lambert, 1999). Like BIAS, the system described in Carberry and Lambert (1999) combined linguistic and contextual knowledge to recognize a user&apos;s intentions from rejoinders. However, their system did not generate rebuttals. Chu-Carroll and Carberry (1995) provided a comprehensive approach for proposal evaluation which focused on dialogue strategies rather than argumentation strategies. In addition, they considered exchanges where each participant utters one or two propositions in each conversational turn. In contrast, we focus on strategies for th</context>
<context position="30581" citStr="Quilici, 1992" startWordPosition="5173" endWordPosition="5174">ue strategies in a complete argumentation system. Flowers et al. (1982) presented a partial theory of argumentation which advocated the combination of distinct knowledge sources; their implementation focused on recognizing and providing episodic justifications to historical events. Our focus on the generation of rebuttals in the context of BNs allows us 45 to provide an operational definition for the broad argumentation strategies discussed in the literature,_ e.g., attack the main point directly or attack the supporting evidence (Flowers et al., 1982).5 The argumentation system described in (Quilici, 1992) used a plan-based model of the user&apos;s beliefs to recognize the justification for a user&apos;s proposal and provide its own justifications. However, the rebuttals generated by this system were based on a single strategy: applying backwards chaining using a set of justification rules. This strategy is a special case of the more general rebuttal schemas presented here. 6 Conclusion and Future Work We have offered a mechanism for generating rebuttals to a user&apos;s rejoinders in the context of arguments generated by a Bayesian argumentation system. We have implemented three main argumentation strategies</context>
</contexts>
<marker>Quilici, 1992</marker>
<rawString>Quilici, A. (1992). Arguing about planning alternatives. In COLING-92 - Proceedings of the Fourteenth International Conference on Computational Linguistics, pages 906-910, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Zukerman</author>
<author>N Jitnah</author>
<author>R McConachy</author>
<author>S George</author>
</authors>
<title>Recognizing intentions from rejoinders in a Bayesian interactive argumentation system.</title>
<date>2000</date>
<booktitle>PRICAI2000 - Proceedings of the Sixth Pacific Rim International Conference on Artificial Intelligence,</booktitle>
<location>Melbourne, Australia.</location>
<note>To appear in</note>
<contexts>
<context position="3123" citStr="Zukerman et al., 2000" startWordPosition="488" endWordPosition="491">n under consideration (the goal proposition) is &amp;quot;Did Mr Green murder Mr Body?&amp;quot;, and both the user and the system have access to evidence. After the presentation of the argument where BIAS contends Mr Green&apos;s possible innocence,2 the user presents a rejoinder which requests that BIAS consider a fact that was omitted from the argument: The found gun is available only to Mr Green. BIAS infers from this rejoinder that the user is adding support to Mr Green having the means to kill Mr Body, and hence to Mr Green&apos;s guilt, through the following line of reasoning, which is determined as described in (Zukerman et al., 2000): The gun being available only to Mr Green —&gt; The gun was fired by Mr Green -4 Mr Green had the means to kill Mr Body -4 Mr Green killed Mr Body. BIAS finds that it does not share the user&apos;s belief in the rejoinder proposition, and that in addition, the effect of this proposition on the goal is rather weak. This prompts the generation of a rebuttal of the form Deny-Dismiss-Follow, whereby the rejoinder proposition is denied, its effect on the goal proposition is dismissed, and its implications are followed hypothetically until they break down due to the marginal effect of the rejoinder on Mr G</context>
<context position="7868" citStr="Zukerman et al., 2000" startWordPosition="1310" endWordPosition="1313">variety of sources, e.g., they may have been inspected by the user in the murder scenario (by means of a WWW interface), or appear in BIAS&apos; previous arguments or the user&apos;s rejoinders. Arguments generated by BIAS are represented by means of an Argument Graph — a sub-network of the normative model BN which ideally also contains nodes from the user model BN. The interpretation process, where BIAS identifies the reasoning path intended by the user, takes place in the user model; since BIAS tries. to .`.&apos;make sense&amp;quot;- of what the user is saying according to the system&apos;s view of the user&apos;s beliefs (Zukerman et al., 2000). In contrast, the processes for generating the initial argument and the rebuttals consult both the user model and the normative model to produce arguments that rely on beliefs held by both BIAS and the user if possible. Further, during rebuttal generation, the choice of a rebuttal strategy depends on the intended effect of the user&apos;s argument (according to the user model) and its actual effect (according to the normative model). 3 Determining a User&apos;s Line of Reasoning Our procedure for recognizing a user&apos;s intended line of reasoning from his/her rejoinder receives two inputs: a linguistic cl</context>
</contexts>
<marker>Zukerman, Jitnah, McConachy, George, 2000</marker>
<rawString>Zukerman, I., Jitnah, N., McConachy, R., and George, S. (2000). Recognizing intentions from rejoinders in a Bayesian interactive argumentation system. To appear in PRICAI2000 - Proceedings of the Sixth Pacific Rim International Conference on Artificial Intelligence, Melbourne, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Zukerman</author>
<author>R McConachy</author>
<author>K B Korb</author>
</authors>
<title>Bayesian reasoning in an abductive mechanism for argument generation and analysis.</title>
<date>1998</date>
<booktitle>In AAA198 - Proceedings of the Fifteenth National Conference on Artificial Intelligence,</booktitle>
<pages>833--838</pages>
<location>Madison Wisconsin.</location>
<contexts>
<context position="4569" citStr="Zukerman et al., 1998" startWordPosition="732" endWordPosition="735">eneration and discuss our results. We then review related work and present concluding remarks. 2 - Knowledge Representation During the argumentation process, BIAS maintains two models of belief: a normative model and a user model, each -of-which is represented as a BN. The normative model contains information gathered directly by BIAS from the murder scenario, while the user model stores propositions that are presumed to &apos;The argument and rebuttals shown in this paper are realized in English as described in (Zukerman et al., 1999). 2The mechanism which generates this argument is described in (Zukerman et al., 1998). 39 Preamble: Mr. Body was found dead in his bedroom, which is in the second .story of his house. Bullet wounds were found in Mr. Body&apos;s body. The bedroom window was broken and broken glass was found inside the window. A gun was found on the premises, and some fingerprints were found on the gun. In addition, inspection of the grounds revealed footprints in the garden and circular indentations in the ground outside the bedroom window. BIAS&apos; argument: Bullets being found in Mr Body&apos;s body implies Mr Body was almost certainly shot. This implies he was almost certainly murdered. Forensics matchin</context>
<context position="12266" citStr="Zukerman et al., 1998" startWordPosition="2071" endWordPosition="2074">nder directly contradicts what was stated by BIAS in the argument. If the user&apos;s rejoinder was &amp;quot;But the neighbour saw Mr Green shoot Mr- Bodyr3.-then conditions R.1 and R2b would be satisfied, since an inference from this rejoinder contradicts BIAS&apos; belief in Mr Green&apos;s lack of opportunity to kill Mr Body (and consequently in Mr Green&apos;s guilt). The argument schema for the refute the rejoinder strategy and a sample rebuttal produced with this schema are shown in Figure 3.3 The sub-argument that argues against the rejoinder proposition is generated by activating our Bayesian argument generator (Zukerman et al., 1998) with the proposition Mr Green and Mr Body were enemies as the goal. In this case, the belief in the rejoinder node resulting from the sub-argument differs from that stated in the initial argument, owing to the additional information included in the sub-argument. Hence, the implications from the rejoinder node are followed. The procedure for following these implications is described in Section 4.2. 4.2 Dismiss the user&apos;s line of reasoning This strategy consists of showing the user how his/her argument fails to achieve its intended effect. We distinguish between concessive and contradictory dis</context>
<context position="28552" citStr="Zukerman et al., 1998" startWordPosition="4872" endWordPosition="4875">The resulting argument has not been included owing to space limitations. St rengthenGoal userPath: F. -Acknowledge the--beliefin-R stated by the user, and set lastProposition to R. 2. Until the goal proposition is reached do: (a) If after lastProposition there is a proposition Pi EuserPath for which a sub-argument was generated (SubAG(P2) 0), then i. Follow userPath from lastProposition ii. Present the sub-argument for P,. iii. Set lastProposition to P2. (b) Else follow the remainder of userPath. Figure 6: Strengthen the goal Schema 5 Related Research Our research builds on work described in (Zukerman et al., 1998), which generated arguments from BNs, and (Zukerman et al., 1999), which enabled a user to explore the impact of different propositions on the generated arguments. The former system only generated arguments, while the latter received instructions from a user (through a menu) about modifications to be performed to a previously generated argument, e.g., including or excluding a proposition, and then generated a new argument in response to these instructions. Neither of these systems generates rebuttals which take into account a user&apos;s intentions, as done by BIAS. Several researchers have dealt w</context>
<context position="32078" citStr="Zukerman et al., 1998" startWordPosition="5402" endWordPosition="5405">on schema. An interesting area of future research pertains to the omission of information from an argument. There are different types of information which may be omitted from an argument, such as (1) easily inferred information and information which has a small effect on the argument; (2) information which is required for representational reasons, but makes the resulting argument more confusing; (3) probabilistic information which, although correct, makes the resulting argument more tedious; and (4) previously stated information. Our previous research deals with the first type of information (Zukerman et al., 1998), and in this paper we have identified some conditions for the omission of previously stated information when expressing the relative impact of a proposition. Another factor that affects the omission of information is the trade off between accuracy and conciseness. The omission of information affects the belief in the conclusion(s) presented in an argument. Stating beliefs that differ from a system&apos;s own beliefs may cause the system to appear inconsistent or even deceitful, while presenting all the relevant factors may yield a verbose argument. A mechanism which addresses these issues will sup</context>
</contexts>
<marker>Zukerman, McConachy, Korb, 1998</marker>
<rawString>Zukerman, I., McConachy, R., and Korb, K. B. (1998). Bayesian reasoning in an abductive mechanism for argument generation and analysis. In AAA198 - Proceedings of the Fifteenth National Conference on Artificial Intelligence, pages 833-• 838,, Madison Wisconsin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Zukerman</author>
<author>R McConachy</author>
<author>K B Korb</author>
<author>D A Pickett</author>
</authors>
<title>Exploratory interaction with a Bayesian argumentation system.</title>
<date>1999</date>
<booktitle>In IfCA 199 - Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1294--1299</pages>
<location>Stockholm,</location>
<contexts>
<context position="4483" citStr="Zukerman et al., 1999" startWordPosition="718" endWordPosition="721">ing a user&apos;s line of reasoning. In Section 4, we describe our algorithm for rebuttal generation and discuss our results. We then review related work and present concluding remarks. 2 - Knowledge Representation During the argumentation process, BIAS maintains two models of belief: a normative model and a user model, each -of-which is represented as a BN. The normative model contains information gathered directly by BIAS from the murder scenario, while the user model stores propositions that are presumed to &apos;The argument and rebuttals shown in this paper are realized in English as described in (Zukerman et al., 1999). 2The mechanism which generates this argument is described in (Zukerman et al., 1998). 39 Preamble: Mr. Body was found dead in his bedroom, which is in the second .story of his house. Bullet wounds were found in Mr. Body&apos;s body. The bedroom window was broken and broken glass was found inside the window. A gun was found on the premises, and some fingerprints were found on the gun. In addition, inspection of the grounds revealed footprints in the garden and circular indentations in the ground outside the bedroom window. BIAS&apos; argument: Bullets being found in Mr Body&apos;s body implies Mr Body was a</context>
<context position="28617" citStr="Zukerman et al., 1999" startWordPosition="4882" endWordPosition="4885">ations. St rengthenGoal userPath: F. -Acknowledge the--beliefin-R stated by the user, and set lastProposition to R. 2. Until the goal proposition is reached do: (a) If after lastProposition there is a proposition Pi EuserPath for which a sub-argument was generated (SubAG(P2) 0), then i. Follow userPath from lastProposition ii. Present the sub-argument for P,. iii. Set lastProposition to P2. (b) Else follow the remainder of userPath. Figure 6: Strengthen the goal Schema 5 Related Research Our research builds on work described in (Zukerman et al., 1998), which generated arguments from BNs, and (Zukerman et al., 1999), which enabled a user to explore the impact of different propositions on the generated arguments. The former system only generated arguments, while the latter received instructions from a user (through a menu) about modifications to be performed to a previously generated argument, e.g., including or excluding a proposition, and then generated a new argument in response to these instructions. Neither of these systems generates rebuttals which take into account a user&apos;s intentions, as done by BIAS. Several researchers have dealt with different aspects of argumentation, e.g., (Flowers et al., 19</context>
</contexts>
<marker>Zukerman, McConachy, Korb, Pickett, 1999</marker>
<rawString>Zukerman, I., McConachy, R., Korb, K. B., and Pickett, D. A. (1999). Exploratory interaction with a Bayesian argumentation system. In IfCA 199 - Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence, pages 1294-1299, Stockholm, Sweden.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>