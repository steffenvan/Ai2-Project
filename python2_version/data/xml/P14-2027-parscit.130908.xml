<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.035239">
<title confidence="0.989639">
Generalized Character-Level Spelling Error Correction
</title>
<author confidence="0.978771">
Noura Farra, Nadi Tomeh†, Alla Rozovskaya, Nizar Habash
</author>
<affiliation confidence="0.967501">
Center for Computational Learning Systems, Columbia University
</affiliation>
<email confidence="0.949801">
{noura,alla,habash}@ccls.columbia.edu
</email>
<note confidence="0.736077">
†LIPN, Université Paris 13, Sorbonne Paris Cité
</note>
<email confidence="0.963773">
nadi.tomeh@lipn.univ-paris13.fr
</email>
<sectionHeader confidence="0.992528" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999989866666667">
We present a generalized discrimina-
tive model for spelling error correction
which targets character-level transforma-
tions. While operating at the charac-
ter level, the model makes use of word-
level and contextual information. In con-
trast to previous work, the proposed ap-
proach learns to correct a variety of er-
ror types without guidance of manually-
selected constraints or language-specific
features. We apply the model to cor-
rect errors in Egyptian Arabic dialect text,
achieving 65% reduction in word error
rate over the input baseline, and improv-
ing over the earlier state-of-the-art system.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.985085956521739">
Spelling error correction is a longstanding Natural
Language Processing (NLP) problem, and it has
recently become especially relevant because of the
many potential applications to the large amount
of informal and unedited text generated online,
including web forums, tweets, blogs, and email.
Misspellings in such text can lead to increased
sparsity and errors, posing a challenge for many
NLP applications such as text summarization, sen-
timent analysis and machine translation.
In this work, we present GSEC, a Generalized
character-level Spelling Error Correction model,
which uses supervised learning to map input char-
acters into output characters in context. The ap-
proach has the following characteristics:
Character-level Corrections are learned at the
character-level1 using a supervised sequence la-
beling approach.
Generalized The input space consists of all
characters, and a single classifier is used to learn
1We use the term ‘character’ strictly in the alphabetic
sense, not the logographic sense (as in the Chinese script).
common error patterns over all the training data,
without guidance of specific rules.
Context-sensitive The model looks beyond the
context of the current word, when making a deci-
sion at the character-level.
Discriminative The model provides the free-
dom of adding a number of different features,
which may or may not be language-specific.
Language-Independent In this work, we in-
tegrate only language-independent features, and
therefore do not consider morphological or lin-
guistic features. However, we apply the model
to correct errors in Egyptian Arabic dialect text,
following a conventional orthography standard,
CODA (Habash et al., 2012).
Using the described approach, we demonstrate
a word-error-rate (WER) reduction of 65% over a
do-nothing input baseline, and we improve over
a state-of-the-art system (Eskander et al., 2013)
which relies heavily on language-specific and
manually-selected constraints. We present a de-
tailed analysis of mistakes and demonstrate that
the proposed model indeed learns to correct a
wider variety of errors.
</bodyText>
<sectionHeader confidence="0.999833" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.994715733333333">
Most earlier work on automatic error correction
addressed spelling errors in English and built mod-
els of correct usage on native English data (Ku-
kich, 1992; Golding and Roth, 1999; Carlson
and Fette, 2007; Banko and Brill, 2001). Ara-
bic spelling correction has also received consider-
able interest (Ben Othmane Zribi and Ben Ahmed,
2003; Haddad and Yaseen, 2007; Hassan et al.,
2008; Shaalan et al., 2010; Alkanhal et al., 2012;
Eskander et al., 2013; Zaghouani et al., 2014).
Supervised spelling correction approaches
trained on paired examples of errors and their cor-
rections have recently been applied for non-native
English correction (van Delden et al., 2004; Li et
al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012;
</bodyText>
<page confidence="0.976409">
161
</page>
<bodyText confidence="0.986042678571428">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
Rozovskaya and Roth, 2011). Discriminative
models have been proposed at the word-level for
error correction (Duan et al., 2012) and for error
detection (Habash and Roth, 2011).
In addition, there has been growing work on lex-
ical normalization of social media data, a some-
what related problem to that considered in this pa-
per (Han and Baldwin, 2011; Han et al., 2013;
Subramaniam et al., 2009; Ling et al., 2013).
The work of Eskander et al. (2013) is the
most relevant to the present study: it presents
a character-edit classification model (CEC) using
the same dataset we use in this paper.2 Eskan-
der et al. (2013) analyzed the data to identify the
seven most common types of errors. They devel-
oped seven classifiers and applied them to the data
in succession. This makes the approach tailored to
the specific data set in use and limited to a specific
set of errors. In this work, a single model is con-
sidered for all types of errors. The model consid-
ers every character in the input text for a possible
spelling error, as opposed to looking only at cer-
tain input characters and contexts in which they
appear. Moreover, in contrast to Eskander et al.
(2013), it looks beyond the boundary of the cur-
rent word.
</bodyText>
<sectionHeader confidence="0.998762" genericHeader="method">
3 The GSEC Approach
</sectionHeader>
<subsectionHeader confidence="0.9997895">
3.1 Modeling Spelling Correction at the
Character Level
</subsectionHeader>
<bodyText confidence="0.9999322">
We recast the problem of spelling correction into
a sequence labeling problem, where for each input
character, we predict an action label describing
how to transform it to obtain the correct charac-
ter. The proposed model therefore transforms a
given input sentence e = el, ... , en of n char-
acters that possibly include errors, to a corrected
sentence c of m characters, where corrected char-
acters are produced by one of the following four
actions applied to each input character ei :
</bodyText>
<listItem confidence="0.999898428571429">
• ok: ei is passed without transformation.
• substitute − with(c): ei is substituted with
a character c where c could be any character
encountered in the training data.
• delete: ei is deleted.
• insert(c): A character c is inserted before
ei. To address errors occurring at the end
</listItem>
<footnote confidence="0.9776595">
2Eskander et al. (2013) also considered a slower, more
expensive, and more language-specific method using a mor-
phological tagger (Habash et al., 2013) that outperformed the
CEC model; however, we do not compare to it in this paper.
</footnote>
<table confidence="0.9954585">
Input Action Label
k substitute-with(c)
o ok
r insert(r)
e ok
c ok
t ok
d delete
</table>
<tableCaption confidence="0.99708">
Table 1: Character-level spelling error correction process
on the input word korectd, with the reference word correct
</tableCaption>
<table confidence="0.999374">
Train Dev Test
Sentences 10.3K 1.67K 1.73K
Characters 675K 106K 103K
Words 134K 21.1K 20.6K
</table>
<tableCaption confidence="0.999451">
Table 2: ARZ Egyptian dialect corpus statistics
</tableCaption>
<bodyText confidence="0.9998735">
of the sentence, we assume the presence of a
dummy sentence-final stop character.
We use a multi-class SVM classifier to predict the
action labels for each input character ei E e. A
decoding process is then applied to transform the
input characters accordingly to produce the cor-
rected sentence. Note that we consider the space
character as a character like any other, which gives
us the ability to correct word merge errors with
space character insertion actions and word split er-
rors with space character deletion actions. Table 1
shows an example of the spelling correction pro-
cess.
In this paper, we only model single-edit actions
and ignore cases where a character requires mul-
tiple edits (henceforth, complex actions), such as
multiple insertions or a combination of insertions
and substitutions. This choice was motivated by
the need to reduce the number of output labels, as
many infrequent labels are generated by complex
actions. An error analysis of the training data, de-
scribed in detail in section 3.2, showed that com-
plex errors are relatively infrequent (4% of data).
We plan to address these errors in future work.
Finally, in order to generate the training data
in the described form, we require a parallel cor-
pus of erroneous and corrected reference text (de-
scribed below), which we align at the character
level. We use the alignment tool Sclite (Fiscus,
1998), which is part of the SCTK Toolkit.
</bodyText>
<subsectionHeader confidence="0.999967">
3.2 Description of Data
</subsectionHeader>
<bodyText confidence="0.99995475">
We apply our model to correcting Egyptian Ara-
bic dialect text. Since there is no standard dialect
orthography adopted by native speakers of Ara-
bic dialects, it is common to encounter multiple
</bodyText>
<page confidence="0.994161">
162
</page>
<table confidence="0.999843">
Action % Errors Example Error ⇒ Reference
Substitute 80.9 ���
ˇA/¯A) 33.3 AHdhm ⇒ ÂHdhm ÑëYg@ ⇒ ÑëYg@
E Alif A@ forms (@/@/@�/@AÂ/
EYa ø 26.7 ςly ⇒ ςlý ú
/ø forms ( y/ý) Î« ⇒úÎ«
Eh/h è/�è , h/w è/ð forms 14.9 kfrh ⇒ kfrh èQ�®»⇒ �èQ�®»
Eh/H è/h forms 2.2 htςmlhA ⇒ HtςmlhA AêÊÒª:ë ⇒ AêÊÒª�Jk
Other substitutions 3.8 AltAnyh ⇒ AlθAnyh �éJ��KA�JË@ ⇒ �éJ��KA�JË@ ; dA ⇒ dh @X ⇒ èX
Insert 10.5
EPInsert {A} 3.0 ktbw ⇒ ktbwA ñJ.�J»⇒ @ñJ.:»
EPInsert {space} 2.9 mAtzςlš ⇒ mA tzςlš �yAÓ ⇒ i•Ê«�Q�K AÓ
Other insertion actions 4.4 Aly ⇒ Ally ú�Í@ ⇒ ú�ÎU@
Delete 4.7
E Del{A} 2.4 whmA ⇒ whm AÒëð⇒ Ñëð
Other deletion actions 2.3 wfyh ⇒ wfy éJ��¯ð ⇒ ú
¯ð
Complex 4.0 mykwnš ⇒ mA ykwnš �•��ñºJ�Ó ⇒ �•��ñºK� AÓ
</table>
<tableCaption confidence="0.6520735">
Table 3: Character-level distribution of correction labels. We model all types of transformations except complex actions, and
rare Insert labels with counts below a tuned threshold. The Delete label is a single label that comprises all deletion actions.
Labels modeled by Eskander et al. (2013) are marked with E, and EP for cases modeled partially, for example, the Insert{A}
would only be applied at certain positions such as the end of the word.
</tableCaption>
<bodyText confidence="0.9999584">
spellings of the same word. The CODA orthogra-
phy was proposed by Habash et al. (2012) in an
attempt to standardize dialectal writing, and we
use it as a reference of correct text for spelling
correction following the previous work by Eskan-
der et al. (2013). We use the same corpus (la-
beled &amp;quot;ARZ&amp;quot;) and experimental setup splits used
by them. The ARZ corpus was developed by
the Linguistic Data Consortium (Maamouri et al.,
2012a-e). See Table 2 for corpus statistics.
Error Distribution Table 3 presents the distri-
bution of correction action labels that correspond
to spelling errors in the training data together with
examples of these errors.3 We group the ac-
tions into: Substitute, Insert, Delete, and Complex,
and also list common transformations within each
group. We further distinguish between the phe-
nomena modeled by our system and by Eskander
et al. (2013). At least 10% of all generated action
labels are not handled by Eskander et al. (2013).
</bodyText>
<subsectionHeader confidence="0.978228">
3.3 Features
</subsectionHeader>
<bodyText confidence="0.961971608695652">
Each input character is represented by a feature
vector. We include a set of basic features inspired
by Eskander et al. (2013) in their CEC system and
additional features for further improvement.
Basic features We use a set of nine basic fea-
tures: the given character, the preceding and fol-
lowing two characters, and the first two and last
3Arabic transliteration is presented in the Habash-Soudi-
Buckwalter scheme (Habash et al., 2007). For more informa-
tion on Arabic orthography in NLP, see (Habash, 2010).
two characters in the word. These are the same
features used by CEC, except that CEC does
not include characters beyond the word boundary,
while we consider space characters as well as char-
acters from the previous and next words.
Ngram features We extract sequences of char-
acters corresponding to the current character and
the following and previous two, three, or four
characters. We refer to these sequences as bi-
grams, trigrams, or 4-grams, respectively. These
are an extension of the basic features and allow
the model to look beyond the context of the cur-
rent word.
</bodyText>
<subsectionHeader confidence="0.974758">
3.4 Maximum Likelihood Estimate (MLE)
</subsectionHeader>
<bodyText confidence="0.999992875">
We implemented another approach for error cor-
rection based on a word-level maximum likeli-
hood model. The MLE method uses a unigram
model which replaces each input word with its
most likely correct word based on counts from the
training data. The intuition behind MLE is that it
can easily correct frequent errors; however, it is
quite dependent on the training data.
</bodyText>
<sectionHeader confidence="0.999944" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999326">
4.1 Model Evaluation
</subsectionHeader>
<bodyText confidence="0.9991618">
Setup The training data was extracted to gener-
ate the form described in Section 3.1, using the
Sclite tool (Fiscus, 1998) to align the input and
reference sentences. A speech effect handling step
was applied as a preprocessing step to all models.
</bodyText>
<page confidence="0.995732">
163
</page>
<bodyText confidence="0.999606469387755">
This step removes redundant repetitions of charac-
ters in sequence, e.g., Sktyyyyyr ‘veeeeery’.
The same speech effect handling was applied by
Eskander et al. (2013).
For classification, we used the SVM implemen-
tation in YamCha (Kudo and Matsumoto, 2001),
and trained with different variations of the fea-
tures described above. Default parameters were
selected for training (c=1, quadratic kernel, and
context window of +/- 2).
In all results listed below, the baseline corre-
sponds to the do-nothing baseline of the input text.
Metrics Three evaluation metrics are used. The
word-error-rate WER metric is computed by sum-
ming the total number of word-level substitution
errors, insertion errors, and deletion errors in the
output, and dividing by the number of words in the
reference. The correct-rate Corr metric is com-
puted by dividing the number of correct output
words by the total number of words in the refer-
ence. These two metrics are produced by Sclite
(Fiscus, 1998), using automatic alignment. Fi-
nally, the accuracy Acc metric, used by Eskander
et al. (2013), is a simple string matching metric
which enforces a word alignment that pairs words
in the reference to those of the output. It is cal-
culated by dividing the number of correct output
words by the number of words in the input. This
metric assumes no split errors in the data (a word
incorrectly split into two words), which is the case
in the data we are working with.
Character-level Model Evaluation The per-
formance of the generalized spelling correction
model (GSEC) on the dev data is presented in the
first half of Table 4. The results of the Eskan-
der et al. (2013) CEC system are also presented
for the purpose of comparison. We can see that
using a single classifier, the generalized model is
able to outperform CEC, which relies on a cascade
of classifiers (p = 0.03 for the basic model and
p &lt; 0.0001 for the best model, GSEC+4grams).4
Model Combination Evaluation Here we
present results on combining GSEC with the
MLE component (GSEC+MLE). We combine the
two models in cascade: the MLE component is
applied to the output of GSEC. To train the MLE
model, we use the word pairs obtained from the
original training data, rather than from the output
of GSEC. We found that this configuration allows
</bodyText>
<footnote confidence="0.769594">
4Significance results are obtained using McNemar’s test.
</footnote>
<table confidence="0.9998871">
Approach Corr%/WER Acc%
Baseline 75.9/24.2 76.8
CEC 88.7/11.4 90.0
GSEC 89.7/10.4* 90.3*
GSEC+2grams 90.6/9.5* 91.2*
GSEC+4grams 91.0/9.2* 91.6*
MLE 89.7/10.4 90.5
CEC + MLE 90.8/9.4 91.5
GSEC+MLE 91.0/9.2 91.3
GSEC+4grams+MLE 91.7/8.3* 92.2*
</table>
<tableCaption confidence="0.987854166666667">
Table 4: Model Evaluation. GSEC represents the gener-
alized character-level model. CEC represents the character-
level-edit classification model of Eskander et al. (2013).
Rows marked with an asterisk (*) are statistically signifi-
cant compared to CEC (for the first half of the table) or
CEC+MLE (for the second half of the table), with P &lt; 0.05.
</tableCaption>
<bodyText confidence="0.99971664516129">
us to include a larger sample of word pair errors
for learning, because our model corrects many
errors, leaving fewer example pairs to train an
MLE post-processor. The results are shown in the
second half of Table 4.
We first observe that MLE improves the per-
formance of both CEC and GSEC. In fact,
CEC+MLE and GSEC+MLE perform similarly
(p = 0.36, not statistically significant). When
adding features that go beyond the word bound-
ary, we achieve an improvement over MLE,
GSEC+MLE, and CEC+MLE, all of which are
mostly restricted within the boundary of the word.
The best GSEC model outperforms CEC+MLE
(p &lt; 0.0001), achieving a WER of 8.3%, corre-
sponding to 65% reduction compared to the base-
line. It is worth noting that adding the MLE com-
ponent allows Eskander’s CEC to recover various
types of errors that were not modeled previously.
However, the contribution of MLE is limited to
words that are in the training data. On the other
hand, because GSEC is trained on character trans-
formations, it is likely to generalize better to words
unseen in the training data.
Results on Test Data Table 5 presents the re-
sults of our best model (GSEC+4grams), and best
model+MLE. The latter achieves a 92.1% Acc
score. The Acc score reported by Eskander et al.
(2013) for CEC+MLE is 91.3% . The two results
are statistically significant (p &lt; 0.0001) with re-
spect to CEC and CEC+MLE respectively.
</bodyText>
<table confidence="0.99824625">
Approach Corr%/WER Acc%
Baseline 74.5/25.5 75.5
GSEC+4grams 90.9/9.1 91.5
GSEC+4grams+ MLE 91.8/8.3 92.1
</table>
<tableCaption confidence="0.999911">
Table 5: Evaluation on test data.
</tableCaption>
<page confidence="0.997882">
164
</page>
<subsectionHeader confidence="0.740277">
4.2 Error Analysis
</subsectionHeader>
<bodyText confidence="0.999829333333333">
To gain a better understanding of the performance
of the models on different types of errors and their
interaction with the MLE component, we separate
the words in the dev data into: (1) words seen in
the training data, or in-vocabulary words (IV), and
(2) out-of-vocabulary (OOV) words not seen in
the training data. Because the MLE model maps
every input word to its most likely gold word seen
in the training data, we expect the MLE compo-
nent to recover a large portion of errors in the IV
category (but not all, since an input word can have
multiple correct readings depending on the con-
text). On the other hand, the recovery of errors in
OOV words indicates how well the character-level
model is doing independently of the MLE compo-
nent. Table 6 presents the performance, using the
Acc metric, on each of these types of words. Here
our best model (GSEC+4grams) is considered.
</bodyText>
<table confidence="0.99808">
#Inp Words Baseline CEC+MLE GSEC+MLE
OOV 3,289 (17.2%) 70.7 76.5 80.5
IV 15,832 (82.8%) 78.6 94.6 94.6
Total 19,121 (100%) 77.2 91.5 92.2
</table>
<tableCaption confidence="0.98432">
Table 6: Accuracy of character-level models shown sepa-
rately on out-of-vocabulary and in-vocabulary words.
</tableCaption>
<bodyText confidence="0.996142038461538">
When considering words seen in the training
data, CEC and GSEC have the same performance.
However, when considering OOV words, GSEC
performs significantly better (p &lt; 0.0001), veri-
fying our hypothesis that a generalized model re-
duces dependency on training data. The data is
heavily skewed towards IV words (83%), which
explains the generally high performance of MLE.
We performed a manual error analysis on a sam-
ple of 50 word errors from the IV set and found
that all of the errors came from gold annotation er-
rors and inconsistencies, either in the dev or train.
We then divided the character transformations in
the OOV words into four groups: (1) characters
that were unchanged by the gold (X-X transforma-
tions), (2) character transformations modeled by
CEC (X-Y CEC), (3) character transformations not
modeled by CEC, and which include all phenom-
ena that were only partially modeled by CEC (X-Y
not CEC), and (4) complex errors. The character-
level accuracy on each of these groups is shown in
Table 7.
Both CEC and GSEC do much better on the
second group of character transformations (that
is, X-Y CEC) than on the third group (X-Y not
CEC). This is not surprising because the former
</bodyText>
<table confidence="0.998958285714286">
Type #Chars Example CEC GSEC
X-X 16502 m-m, space-space 99.25 99.33
X-Y 609 h-h, h-lx ˇA-A 80.62 83.09
(CEC) A- ˇA, y-ý
X-Y 161 t-θ , del{w} 31.68 43.48
(not CEC) n-ins{space}
Complex 32 n-ins{A}{m} 37.5 15.63
</table>
<tableCaption confidence="0.9768395">
Table 7: Character-level accuracy on different transforma-
tion types for out-of-vocabulary words. For complex trans-
formations, the accuracy represents the complex category
recognition rate, and not the actual correction accuracy.
</tableCaption>
<bodyText confidence="0.99973">
transformations correspond to phenomena that are
most common in the training data. For GSEC,
they are learned automatically, while for CEC they
are selected and modeled explicitly. Despite this
fact, GSEC generalizes better to OOV words. As
for the third group, both CEC and GSEC per-
form more poorly, but GSEC corrects more errors
(43.48% vs. 31.68% accuracy). Finally, CEC is
better at recognizing complex errors, which, al-
though are not modeled explicitly by CEC, can
sometimes be corrected as a result of applying
multiple classifiers in cascade. Dealing with com-
plex errors, though there are few of them in this
dataset, is an important direction for future work,
and for generalizing to other datasets, e.g., (Za-
ghouani et al., 2014).
</bodyText>
<sectionHeader confidence="0.996564" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9999925625">
We showed that a generalized character-level
spelling error correction model can improve
spelling error correction on Egyptian Arabic data.
This model learns common spelling error patterns
automatically, without guidance of manually se-
lected or language-specific constraints. We also
demonstrate that the model outperforms existing
methods, especially on out-of-vocabulary words.
In the future, we plan to extend the model to use
word-level language models to select between top
character predictions in the output. We also plan
to apply the model to different datasets and differ-
ent languages. Finally, we plan to experiment with
more features that can also be tailored to specific
languages by using morphological and linguistic
information, which was not explored in this paper.
</bodyText>
<sectionHeader confidence="0.989776" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999402">
This publication was made possible by grant
NPRP-4-1058-1-168 from the Qatar National Re-
search Fund (a member of the Qatar Foundation).
The statements made herein are solely the respon-
sibility of the authors.
</bodyText>
<page confidence="0.998325">
165
</page>
<sectionHeader confidence="0.856258" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994192145299145">
Mohamed I. Alkanhal, Mohammed A. Al-Badrashiny,
Mansour M. Alghamdi, and Abdulaziz O. Al-
Qabbany. 2012. Automatic Stochastic Arabic
Spelling Correction With Emphasis on Space Inser-
tions and Deletions. IEEE Transactions on Audio,
Speech &amp; Language Processing, 20:2111–2122.
Michele Banko and Eric Brill. 2001. Scaling to very
very large corpora for natural language disambigua-
tion. In Proceedings of 39th Annual Meeting of the
Association for Computational Linguistics, pages
26–33, Toulouse, France, July.
Chiraz Ben Othmane Zribi and Mohammed Ben
Ahmed. 2003. Efficient Automatic Correction
of Misspelled Arabic Words Based on Contextual
Information. In Proceedings of the Knowledge-
Based Intelligent Information and Engineering Sys-
tems Conference, Oxford, UK.
Andrew Carlson and Ian Fette. 2007. Memory-based
context-sensitive spelling correction at web scale. In
Proceedings of the IEEE International Conference
on Machine Learning and Applications (ICMLA).
Daniel Dahlmeier and Hwee Tou Ng. 2012. A beam-
search decoder for grammatical error correction. In
Proceedings of the 2012 Joint Conference on Empir-
ical Methods in Natural Language Processing and
Computational Natural Language Learning, pages
568–578.
Huizhong Duan, Yanen Li, ChengXiang Zhai, and
Dan Roth. 2012. A discriminative model for
query spelling correction with latent structural svm.
In Proceedings of the 2012 Joint Conference on
Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning,
EMNLP-CoNLL ’12, pages 1511–1521, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Ramy Eskander, Nizar Habash, Owen Rambow, and
Nadi Tomeh. 2013. Processing spontaneous orthog-
raphy. In The Conference of the North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies, NAACL
HLT ’13.
Jon Fiscus. 1998. Sclite scoring package ver-
sion 1.5. US National Institute of Standard
Technology (NIST), URL http://www. itl. nist.
gov/iaui/894.01/tools.
Michael Gamon. 2010. Using mostly native data to
correct errors in learners’ writing. In Human Lan-
guage Technologies: The 2010 Annual Conference
of the North American Chapter of the Association
for Computational Linguistics, pages 163–171, Los
Angeles, California, June.
Andrew R. Golding and Dan Roth. 1999. A Winnow
based approach to context-sensitive spelling correc-
tion. Machine Learning, 34(1-3):107–130.
Nizar Habash and Ryan M. Roth. 2011. Using deep
morphology to improve automatic error detection in
arabic handwriting recognition. In Proceedings of
the 49th Annual Meeting of the Association for Com-
putational Linguistics: Human Language Technolo-
gies - Volume 1, HLT ’11, pages 875–884, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter.
2007. On Arabic Transliteration. In A. van den
Bosch and A. Soudi, editors, Arabic Computa-
tional Morphology: Knowledge-based and Empiri-
cal Methods. Springer.
Nizar Habash, Mona Diab, and Owen Rambow.
2012. Conventional orthography for dialectal Ara-
bic. In Nicoletta Calzolari (Conference Chair),
Khalid Choukri, Thierry Declerck, Mehmet U˘gur
Do˘gan, Bente Maegaard, Joseph Mariani, Jan
Odijk, and Stelios Piperidis, editors, Proceedings
of the Eight International Conference on Language
Resources and Evaluation (LREC’12), Istanbul,
Turkey, may. European Language Resources Asso-
ciation (ELRA).
Nizar Habash, Ryan Roth, Owen Rambow, Ramy Es-
kander, and Nadi Tomeh. 2013. Morphological
Analysis and Disambiguation for Dialectal Arabic.
In Proceedings of the 2013 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies
(NAACL-HLT), Atlanta, GA.
Nizar Habash. 2010. Introduction to Arabic Natural
Language Processing. Morgan &amp; Claypool Publish-
ers.
Bassam Haddad and Mustafa Yaseen. 2007. Detection
and Correction of Non-Words in Arabic: A Hybrid
Approach. International Journal of Computer Pro-
cessing Of Languages (IJCPOL).
Bo Han and Timothy Baldwin. 2011. Lexical normali-
sation of short text messages: Makn sens a# twitter.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies-Volume 1, pages 368–378.
Association for Computational Linguistics.
Bo Han, Paul Cook, and Timothy Baldwin. 2013.
Lexical normalization for social media text. ACM
Transactions on Intelligent Systems and Technology
(TIST), 4(1):5.
Ahmed Hassan, Sara Noeman, and Hany Hassan.
2008. Language Independent Text Correction us-
ing Finite State Automata. In Proceedings of the In-
ternational Joint Conference on Natural Language
Processing (IJCNLP 2008).
Taku Kudo and Yuji Matsumoto. 2001. Chunking
with support vector machines. In Proceedings of
the second meeting of the North American Chap-
ter of the Association for Computational Linguistics
on Language technologies, NAACL ’01, pages 1–
8, Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Karen Kukich. 1992. Techniques for Automatically
Correcting Words in Text. ACM Computing Sur-
veys, 24(4).
</reference>
<page confidence="0.98533">
166
</page>
<reference confidence="0.999393316666667">
Yanen Li, Huizhong Duan, and ChengXiang Zhai.
2012. A generalized hidden markov model with dis-
criminative training for query spelling correction. In
Proceedings of the 35th international ACM SIGIR
conference on Research and development in infor-
mation retrieval, SIGIR ’12, pages 611–620, New
York, NY, USA. ACM.
Wang Ling, Chris Dyer, Alan W Black, and Isabel
Trancoso. 2013. Paraphrasing 4 microblog normal-
ization. In Proceedings of the 2013 Conference on
Empirical Methods in Natural Language Process-
ing, pages 73–84, Seattle, Washington, USA, Octo-
ber. Association for Computational Linguistics.
Mohamed Maamouri, Ann Bies, Seth Kulick, Sondos
Krouna, Dalila Tabassi, and Michael Ciul. 2012a.
Egyptian Arabic Treebank DF Part 1 V2.0. LDC
catalog number LDC2012E93.
Mohamed Maamouri, Ann Bies, Seth Kulick, Sondos
Krouna, Dalila Tabassi, and Michael Ciul. 2012b.
Egyptian Arabic Treebank DF Part 2 V2.0. LDC
catalog number LDC2012E98.
Mohamed Maamouri, Ann Bies, Seth Kulick, Sondos
Krouna, Dalila Tabassi, and Michael Ciul. 2012c.
Egyptian Arabic Treebank DF Part 3 V2.0. LDC
catalog number LDC2012E89.
Mohamed Maamouri, Ann Bies, Seth Kulick, Sondos
Krouna, Dalila Tabassi, and Michael Ciul. 2012d.
Egyptian Arabic Treebank DF Part 4 V2.0. LDC
catalog number LDC2012E99.
Mohamed Maamouri, Ann Bies, Seth Kulick, Sondos
Krouna, Dalila Tabassi, and Michael Ciul. 2012e.
Egyptian Arabic Treebank DF Part 5 V2.0. LDC
catalog number LDC2012E107.
Alla Rozovskaya and Dan Roth. 2011. Algorithm se-
lection and model adaptation for esl correction tasks.
In Proc. of the Annual Meeting of the Association of
Computational Linguistics (ACL), Portland, Oregon,
6. Association for Computational Linguistics.
Khaled Shaalan, Rana Aref, and Aly Fahmy. 2010. An
approach for analyzing and correcting spelling er-
rors for non-native Arabic learners. Proceedings of
Informatics and Systems (INFOS).
L Venkata Subramaniam, Shourya Roy, Tanveer A
Faruquie, and Sumit Negi. 2009. A survey of types
of text noise and techniques to handle noisy text.
In Proceedings of The Third Workshop on Analytics
for Noisy Unstructured Text Data, pages 115–122.
ACM.
Sebastian van Delden, David B. Bracewell, and Fer-
nando Gomez. 2004. Supervised and unsupervised
automatic spelling correction algorithms. In Infor-
mation Reuse and Integration, 2004. Proceedings of
the 2004 IEEE International Conference on, pages
530–535.
Wajdi Zaghouani, Behrang Mohit, Nizar Habash, Os-
sama Obeid, Nadi Tomeh, Alla Rozovskaya, Noura
Farra, Sarah Alkuhlani, and Kemal Oflazer. 2014.
Large scale Arabic error annotation: Guidelines and
framework. In Proceedings of the 9th edition of the
Language Resources and Evaluation Conference.
</reference>
<page confidence="0.997705">
167
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.759061">
<title confidence="0.99798">Generalized Character-Level Spelling Error Correction</title>
<author confidence="0.991893">Nadi Alla Rozovskaya Farra</author>
<author confidence="0.991893">Nizar Habash</author>
<affiliation confidence="0.997941">Center for Computational Learning Systems, Columbia</affiliation>
<address confidence="0.830636">Université Paris 13, Sorbonne Paris</address>
<email confidence="0.920461">nadi.tomeh@lipn.univ-paris13.fr</email>
<abstract confidence="0.9976921875">We present a generalized discriminative model for spelling error correction which targets character-level transformations. While operating at the character level, the model makes use of wordlevel and contextual information. In contrast to previous work, the proposed approach learns to correct a variety of error types without guidance of manuallyselected constraints or language-specific features. We apply the model to correct errors in Egyptian Arabic dialect text, achieving 65% reduction in word error rate over the input baseline, and improving over the earlier state-of-the-art system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mohamed I Alkanhal</author>
<author>Mohammed A Al-Badrashiny</author>
<author>Mansour M Alghamdi</author>
<author>Abdulaziz O AlQabbany</author>
</authors>
<title>Automatic Stochastic Arabic Spelling Correction With Emphasis on Space Insertions and Deletions.</title>
<date>2012</date>
<journal>IEEE Transactions on Audio, Speech &amp; Language Processing,</journal>
<pages>20--2111</pages>
<contexts>
<context position="3431" citStr="Alkanhal et al., 2012" startWordPosition="503" endWordPosition="506">-specific and manually-selected constraints. We present a detailed analysis of mistakes and demonstrate that the proposed model indeed learns to correct a wider variety of errors. 2 Related Work Most earlier work on automatic error correction addressed spelling errors in English and built models of correct usage on native English data (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest (Ben Othmane Zribi and Ben Ahmed, 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012; Eskander et al., 2013; Zaghouani et al., 2014). Supervised spelling correction approaches trained on paired examples of errors and their corrections have recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics Rozovskaya and Roth, 2011). Discriminative models have been proposed at the word-level for er</context>
</contexts>
<marker>Alkanhal, Al-Badrashiny, Alghamdi, AlQabbany, 2012</marker>
<rawString>Mohamed I. Alkanhal, Mohammed A. Al-Badrashiny, Mansour M. Alghamdi, and Abdulaziz O. AlQabbany. 2012. Automatic Stochastic Arabic Spelling Correction With Emphasis on Space Insertions and Deletions. IEEE Transactions on Audio, Speech &amp; Language Processing, 20:2111–2122.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Eric Brill</author>
</authors>
<title>Scaling to very very large corpora for natural language disambiguation.</title>
<date>2001</date>
<booktitle>In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>26--33</pages>
<location>Toulouse, France,</location>
<contexts>
<context position="3233" citStr="Banko and Brill, 2001" startWordPosition="470" endWordPosition="473">roach, we demonstrate a word-error-rate (WER) reduction of 65% over a do-nothing input baseline, and we improve over a state-of-the-art system (Eskander et al., 2013) which relies heavily on language-specific and manually-selected constraints. We present a detailed analysis of mistakes and demonstrate that the proposed model indeed learns to correct a wider variety of errors. 2 Related Work Most earlier work on automatic error correction addressed spelling errors in English and built models of correct usage on native English data (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest (Ben Othmane Zribi and Ben Ahmed, 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012; Eskander et al., 2013; Zaghouani et al., 2014). Supervised spelling correction approaches trained on paired examples of errors and their corrections have recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pa</context>
</contexts>
<marker>Banko, Brill, 2001</marker>
<rawString>Michele Banko and Eric Brill. 2001. Scaling to very very large corpora for natural language disambiguation. In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics, pages 26–33, Toulouse, France, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chiraz Ben Othmane Zribi</author>
<author>Mohammed Ben Ahmed</author>
</authors>
<title>Efficient Automatic Correction of Misspelled Arabic Words Based on Contextual Information.</title>
<date>2003</date>
<booktitle>In Proceedings of the KnowledgeBased Intelligent Information and Engineering Systems Conference,</booktitle>
<location>Oxford, UK.</location>
<marker>Zribi, Ahmed, 2003</marker>
<rawString>Chiraz Ben Othmane Zribi and Mohammed Ben Ahmed. 2003. Efficient Automatic Correction of Misspelled Arabic Words Based on Contextual Information. In Proceedings of the KnowledgeBased Intelligent Information and Engineering Systems Conference, Oxford, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Carlson</author>
<author>Ian Fette</author>
</authors>
<title>Memory-based context-sensitive spelling correction at web scale.</title>
<date>2007</date>
<booktitle>In Proceedings of the IEEE International Conference on Machine Learning and Applications (ICMLA).</booktitle>
<contexts>
<context position="3209" citStr="Carlson and Fette, 2007" startWordPosition="466" endWordPosition="469">. Using the described approach, we demonstrate a word-error-rate (WER) reduction of 65% over a do-nothing input baseline, and we improve over a state-of-the-art system (Eskander et al., 2013) which relies heavily on language-specific and manually-selected constraints. We present a detailed analysis of mistakes and demonstrate that the proposed model indeed learns to correct a wider variety of errors. 2 Related Work Most earlier work on automatic error correction addressed spelling errors in English and built models of correct usage on native English data (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest (Ben Othmane Zribi and Ben Ahmed, 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012; Eskander et al., 2013; Zaghouani et al., 2014). Supervised spelling correction approaches trained on paired examples of errors and their corrections have recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Lingui</context>
</contexts>
<marker>Carlson, Fette, 2007</marker>
<rawString>Andrew Carlson and Ian Fette. 2007. Memory-based context-sensitive spelling correction at web scale. In Proceedings of the IEEE International Conference on Machine Learning and Applications (ICMLA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Dahlmeier</author>
<author>Hwee Tou Ng</author>
</authors>
<title>A beamsearch decoder for grammatical error correction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>568--578</pages>
<contexts>
<context position="3721" citStr="Dahlmeier and Ng, 2012" startWordPosition="548" endWordPosition="551"> models of correct usage on native English data (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest (Ben Othmane Zribi and Ben Ahmed, 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012; Eskander et al., 2013; Zaghouani et al., 2014). Supervised spelling correction approaches trained on paired examples of errors and their corrections have recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics Rozovskaya and Roth, 2011). Discriminative models have been proposed at the word-level for error correction (Duan et al., 2012) and for error detection (Habash and Roth, 2011). In addition, there has been growing work on lexical normalization of social media data, a somewhat related problem to that considered in this paper (Han and Baldwin, 2011; Han et al., 2013; Subramaniam et a</context>
</contexts>
<marker>Dahlmeier, Ng, 2012</marker>
<rawString>Daniel Dahlmeier and Hwee Tou Ng. 2012. A beamsearch decoder for grammatical error correction. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 568–578.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huizhong Duan</author>
<author>Yanen Li</author>
<author>ChengXiang Zhai</author>
<author>Dan Roth</author>
</authors>
<title>A discriminative model for query spelling correction with latent structural svm.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL ’12,</booktitle>
<pages>1511--1521</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4065" citStr="Duan et al., 2012" startWordPosition="595" endWordPosition="598">., 2013; Zaghouani et al., 2014). Supervised spelling correction approaches trained on paired examples of errors and their corrections have recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics Rozovskaya and Roth, 2011). Discriminative models have been proposed at the word-level for error correction (Duan et al., 2012) and for error detection (Habash and Roth, 2011). In addition, there has been growing work on lexical normalization of social media data, a somewhat related problem to that considered in this paper (Han and Baldwin, 2011; Han et al., 2013; Subramaniam et al., 2009; Ling et al., 2013). The work of Eskander et al. (2013) is the most relevant to the present study: it presents a character-edit classification model (CEC) using the same dataset we use in this paper.2 Eskander et al. (2013) analyzed the data to identify the seven most common types of errors. They developed seven classifiers and appli</context>
</contexts>
<marker>Duan, Li, Zhai, Roth, 2012</marker>
<rawString>Huizhong Duan, Yanen Li, ChengXiang Zhai, and Dan Roth. 2012. A discriminative model for query spelling correction with latent structural svm. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL ’12, pages 1511–1521, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ramy Eskander</author>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
<author>Nadi Tomeh</author>
</authors>
<title>Processing spontaneous orthography.</title>
<date>2013</date>
<booktitle>In The Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT ’13.</booktitle>
<contexts>
<context position="2777" citStr="Eskander et al., 2013" startWordPosition="398" endWordPosition="401">riminative The model provides the freedom of adding a number of different features, which may or may not be language-specific. Language-Independent In this work, we integrate only language-independent features, and therefore do not consider morphological or linguistic features. However, we apply the model to correct errors in Egyptian Arabic dialect text, following a conventional orthography standard, CODA (Habash et al., 2012). Using the described approach, we demonstrate a word-error-rate (WER) reduction of 65% over a do-nothing input baseline, and we improve over a state-of-the-art system (Eskander et al., 2013) which relies heavily on language-specific and manually-selected constraints. We present a detailed analysis of mistakes and demonstrate that the proposed model indeed learns to correct a wider variety of errors. 2 Related Work Most earlier work on automatic error correction addressed spelling errors in English and built models of correct usage on native English data (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest (Ben Othmane Zribi and Ben Ahmed, 2003; Haddad and Yaseen, 2007; Hassan et </context>
<context position="4385" citStr="Eskander et al. (2013)" startWordPosition="653" endWordPosition="656">ng of the Association for Computational Linguistics (Short Papers), pages 161–167, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics Rozovskaya and Roth, 2011). Discriminative models have been proposed at the word-level for error correction (Duan et al., 2012) and for error detection (Habash and Roth, 2011). In addition, there has been growing work on lexical normalization of social media data, a somewhat related problem to that considered in this paper (Han and Baldwin, 2011; Han et al., 2013; Subramaniam et al., 2009; Ling et al., 2013). The work of Eskander et al. (2013) is the most relevant to the present study: it presents a character-edit classification model (CEC) using the same dataset we use in this paper.2 Eskander et al. (2013) analyzed the data to identify the seven most common types of errors. They developed seven classifiers and applied them to the data in succession. This makes the approach tailored to the specific data set in use and limited to a specific set of errors. In this work, a single model is considered for all types of errors. The model considers every character in the input text for a possible spelling error, as opposed to looking only</context>
<context position="6015" citStr="Eskander et al. (2013)" startWordPosition="940" endWordPosition="943">to obtain the correct character. The proposed model therefore transforms a given input sentence e = el, ... , en of n characters that possibly include errors, to a corrected sentence c of m characters, where corrected characters are produced by one of the following four actions applied to each input character ei : • ok: ei is passed without transformation. • substitute − with(c): ei is substituted with a character c where c could be any character encountered in the training data. • delete: ei is deleted. • insert(c): A character c is inserted before ei. To address errors occurring at the end 2Eskander et al. (2013) also considered a slower, more expensive, and more language-specific method using a morphological tagger (Habash et al., 2013) that outperformed the CEC model; however, we do not compare to it in this paper. Input Action Label k substitute-with(c) o ok r insert(r) e ok c ok t ok d delete Table 1: Character-level spelling error correction process on the input word korectd, with the reference word correct Train Dev Test Sentences 10.3K 1.67K 1.73K Characters 675K 106K 103K Words 134K 21.1K 20.6K Table 2: ARZ Egyptian dialect corpus statistics of the sentence, we assume the presence of a dummy s</context>
<context position="9188" citStr="Eskander et al. (2013)" startWordPosition="1484" endWordPosition="1487"> @X ⇒ èX Insert 10.5 EPInsert {A} 3.0 ktbw ⇒ ktbwA ñJ.�J»⇒ @ñJ.:» EPInsert {space} 2.9 mAtzςlš ⇒ mA tzςlš �yAÓ ⇒ i•Ê«�Q�K AÓ Other insertion actions 4.4 Aly ⇒ Ally ú�Í@ ⇒ ú�ÎU@ Delete 4.7 E Del{A} 2.4 whmA ⇒ whm AÒëð⇒ Ñëð Other deletion actions 2.3 wfyh ⇒ wfy éJ��¯ð ⇒ ú ¯ð Complex 4.0 mykwnš ⇒ mA ykwnš �•��ñºJ�Ó ⇒ �•��ñºK� AÓ Table 3: Character-level distribution of correction labels. We model all types of transformations except complex actions, and rare Insert labels with counts below a tuned threshold. The Delete label is a single label that comprises all deletion actions. Labels modeled by Eskander et al. (2013) are marked with E, and EP for cases modeled partially, for example, the Insert{A} would only be applied at certain positions such as the end of the word. spellings of the same word. The CODA orthography was proposed by Habash et al. (2012) in an attempt to standardize dialectal writing, and we use it as a reference of correct text for spelling correction following the previous work by Eskander et al. (2013). We use the same corpus (labeled &amp;quot;ARZ&amp;quot;) and experimental setup splits used by them. The ARZ corpus was developed by the Linguistic Data Consortium (Maamouri et al., 2012a-e). See Table 2 f</context>
<context position="10436" citStr="Eskander et al. (2013)" startWordPosition="1696" endWordPosition="1699">r Distribution Table 3 presents the distribution of correction action labels that correspond to spelling errors in the training data together with examples of these errors.3 We group the actions into: Substitute, Insert, Delete, and Complex, and also list common transformations within each group. We further distinguish between the phenomena modeled by our system and by Eskander et al. (2013). At least 10% of all generated action labels are not handled by Eskander et al. (2013). 3.3 Features Each input character is represented by a feature vector. We include a set of basic features inspired by Eskander et al. (2013) in their CEC system and additional features for further improvement. Basic features We use a set of nine basic features: the given character, the preceding and following two characters, and the first two and last 3Arabic transliteration is presented in the Habash-SoudiBuckwalter scheme (Habash et al., 2007). For more information on Arabic orthography in NLP, see (Habash, 2010). two characters in the word. These are the same features used by CEC, except that CEC does not include characters beyond the word boundary, while we consider space characters as well as characters from the previous and </context>
<context position="12244" citStr="Eskander et al. (2013)" startWordPosition="1995" endWordPosition="1998">t word based on counts from the training data. The intuition behind MLE is that it can easily correct frequent errors; however, it is quite dependent on the training data. 4 Experiments 4.1 Model Evaluation Setup The training data was extracted to generate the form described in Section 3.1, using the Sclite tool (Fiscus, 1998) to align the input and reference sentences. A speech effect handling step was applied as a preprocessing step to all models. 163 This step removes redundant repetitions of characters in sequence, e.g., Sktyyyyyr ‘veeeeery’. The same speech effect handling was applied by Eskander et al. (2013). For classification, we used the SVM implementation in YamCha (Kudo and Matsumoto, 2001), and trained with different variations of the features described above. Default parameters were selected for training (c=1, quadratic kernel, and context window of +/- 2). In all results listed below, the baseline corresponds to the do-nothing baseline of the input text. Metrics Three evaluation metrics are used. The word-error-rate WER metric is computed by summing the total number of word-level substitution errors, insertion errors, and deletion errors in the output, and dividing by the number of words </context>
<context position="13716" citStr="Eskander et al. (2013)" startWordPosition="2244" endWordPosition="2248">accuracy Acc metric, used by Eskander et al. (2013), is a simple string matching metric which enforces a word alignment that pairs words in the reference to those of the output. It is calculated by dividing the number of correct output words by the number of words in the input. This metric assumes no split errors in the data (a word incorrectly split into two words), which is the case in the data we are working with. Character-level Model Evaluation The performance of the generalized spelling correction model (GSEC) on the dev data is presented in the first half of Table 4. The results of the Eskander et al. (2013) CEC system are also presented for the purpose of comparison. We can see that using a single classifier, the generalized model is able to outperform CEC, which relies on a cascade of classifiers (p = 0.03 for the basic model and p &lt; 0.0001 for the best model, GSEC+4grams).4 Model Combination Evaluation Here we present results on combining GSEC with the MLE component (GSEC+MLE). We combine the two models in cascade: the MLE component is applied to the output of GSEC. To train the MLE model, we use the word pairs obtained from the original training data, rather than from the output of GSEC. We f</context>
<context position="16254" citStr="Eskander et al. (2013)" startWordPosition="2668" endWordPosition="2671">8.3%, corresponding to 65% reduction compared to the baseline. It is worth noting that adding the MLE component allows Eskander’s CEC to recover various types of errors that were not modeled previously. However, the contribution of MLE is limited to words that are in the training data. On the other hand, because GSEC is trained on character transformations, it is likely to generalize better to words unseen in the training data. Results on Test Data Table 5 presents the results of our best model (GSEC+4grams), and best model+MLE. The latter achieves a 92.1% Acc score. The Acc score reported by Eskander et al. (2013) for CEC+MLE is 91.3% . The two results are statistically significant (p &lt; 0.0001) with respect to CEC and CEC+MLE respectively. Approach Corr%/WER Acc% Baseline 74.5/25.5 75.5 GSEC+4grams 90.9/9.1 91.5 GSEC+4grams+ MLE 91.8/8.3 92.1 Table 5: Evaluation on test data. 164 4.2 Error Analysis To gain a better understanding of the performance of the models on different types of errors and their interaction with the MLE component, we separate the words in the dev data into: (1) words seen in the training data, or in-vocabulary words (IV), and (2) out-of-vocabulary (OOV) words not seen in the traini</context>
</contexts>
<marker>Eskander, Habash, Rambow, Tomeh, 2013</marker>
<rawString>Ramy Eskander, Nizar Habash, Owen Rambow, and Nadi Tomeh. 2013. Processing spontaneous orthography. In The Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT ’13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Fiscus</author>
</authors>
<title>Sclite scoring package version 1.5.</title>
<date>1998</date>
<institution>US National Institute of Standard</institution>
<note>Technology (NIST), URL http://www. itl. nist. gov/iaui/894.01/tools.</note>
<contexts>
<context position="7941" citStr="Fiscus, 1998" startWordPosition="1261" endWordPosition="1262">tion of insertions and substitutions. This choice was motivated by the need to reduce the number of output labels, as many infrequent labels are generated by complex actions. An error analysis of the training data, described in detail in section 3.2, showed that complex errors are relatively infrequent (4% of data). We plan to address these errors in future work. Finally, in order to generate the training data in the described form, we require a parallel corpus of erroneous and corrected reference text (described below), which we align at the character level. We use the alignment tool Sclite (Fiscus, 1998), which is part of the SCTK Toolkit. 3.2 Description of Data We apply our model to correcting Egyptian Arabic dialect text. Since there is no standard dialect orthography adopted by native speakers of Arabic dialects, it is common to encounter multiple 162 Action % Errors Example Error ⇒ Reference Substitute 80.9 ��� ˇA/¯A) 33.3 AHdhm ⇒ ÂHdhm ÑëYg@ ⇒ ÑëYg@ E Alif A@ forms (@/@/@�/@AÂ/ EYa ø 26.7 ςly ⇒ ςlý ú /ø forms ( y/ý) Î« ⇒úÎ« Eh/h è/�è , h/w è/ð forms 14.9 kfrh ⇒ kfrh èQ�®»⇒ �èQ�®» Eh/H è/h forms 2.2 htςmlhA ⇒ HtςmlhA AêÊÒª:ë ⇒ AêÊÒª�Jk Other substitutions 3.8 AltAnyh ⇒ AlθAnyh �éJ��KA�JË</context>
<context position="11950" citStr="Fiscus, 1998" startWordPosition="1950" endWordPosition="1951">del to look beyond the context of the current word. 3.4 Maximum Likelihood Estimate (MLE) We implemented another approach for error correction based on a word-level maximum likelihood model. The MLE method uses a unigram model which replaces each input word with its most likely correct word based on counts from the training data. The intuition behind MLE is that it can easily correct frequent errors; however, it is quite dependent on the training data. 4 Experiments 4.1 Model Evaluation Setup The training data was extracted to generate the form described in Section 3.1, using the Sclite tool (Fiscus, 1998) to align the input and reference sentences. A speech effect handling step was applied as a preprocessing step to all models. 163 This step removes redundant repetitions of characters in sequence, e.g., Sktyyyyyr ‘veeeeery’. The same speech effect handling was applied by Eskander et al. (2013). For classification, we used the SVM implementation in YamCha (Kudo and Matsumoto, 2001), and trained with different variations of the features described above. Default parameters were selected for training (c=1, quadratic kernel, and context window of +/- 2). In all results listed below, the baseline co</context>
</contexts>
<marker>Fiscus, 1998</marker>
<rawString>Jon Fiscus. 1998. Sclite scoring package version 1.5. US National Institute of Standard Technology (NIST), URL http://www. itl. nist. gov/iaui/894.01/tools.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Gamon</author>
</authors>
<title>Using mostly native data to correct errors in learners’ writing.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>163--171</pages>
<location>Los Angeles, California,</location>
<contexts>
<context position="3697" citStr="Gamon, 2010" startWordPosition="546" endWordPosition="547">ish and built models of correct usage on native English data (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest (Ben Othmane Zribi and Ben Ahmed, 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012; Eskander et al., 2013; Zaghouani et al., 2014). Supervised spelling correction approaches trained on paired examples of errors and their corrections have recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics Rozovskaya and Roth, 2011). Discriminative models have been proposed at the word-level for error correction (Duan et al., 2012) and for error detection (Habash and Roth, 2011). In addition, there has been growing work on lexical normalization of social media data, a somewhat related problem to that considered in this paper (Han and Baldwin, 2011; Han et al.</context>
</contexts>
<marker>Gamon, 2010</marker>
<rawString>Michael Gamon. 2010. Using mostly native data to correct errors in learners’ writing. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 163–171, Los Angeles, California, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew R Golding</author>
<author>Dan Roth</author>
</authors>
<title>A Winnow based approach to context-sensitive spelling correction.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<pages>34--1</pages>
<contexts>
<context position="3184" citStr="Golding and Roth, 1999" startWordPosition="462" endWordPosition="465">DA (Habash et al., 2012). Using the described approach, we demonstrate a word-error-rate (WER) reduction of 65% over a do-nothing input baseline, and we improve over a state-of-the-art system (Eskander et al., 2013) which relies heavily on language-specific and manually-selected constraints. We present a detailed analysis of mistakes and demonstrate that the proposed model indeed learns to correct a wider variety of errors. 2 Related Work Most earlier work on automatic error correction addressed spelling errors in English and built models of correct usage on native English data (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest (Ben Othmane Zribi and Ben Ahmed, 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012; Eskander et al., 2013; Zaghouani et al., 2014). Supervised spelling correction approaches trained on paired examples of errors and their corrections have recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 161 Proceedings of the 52nd Annual Meeting of the Association</context>
</contexts>
<marker>Golding, Roth, 1999</marker>
<rawString>Andrew R. Golding and Dan Roth. 1999. A Winnow based approach to context-sensitive spelling correction. Machine Learning, 34(1-3):107–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Ryan M Roth</author>
</authors>
<title>Using deep morphology to improve automatic error detection in arabic handwriting recognition.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>875--884</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4113" citStr="Habash and Roth, 2011" startWordPosition="603" endWordPosition="606"> spelling correction approaches trained on paired examples of errors and their corrections have recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics Rozovskaya and Roth, 2011). Discriminative models have been proposed at the word-level for error correction (Duan et al., 2012) and for error detection (Habash and Roth, 2011). In addition, there has been growing work on lexical normalization of social media data, a somewhat related problem to that considered in this paper (Han and Baldwin, 2011; Han et al., 2013; Subramaniam et al., 2009; Ling et al., 2013). The work of Eskander et al. (2013) is the most relevant to the present study: it presents a character-edit classification model (CEC) using the same dataset we use in this paper.2 Eskander et al. (2013) analyzed the data to identify the seven most common types of errors. They developed seven classifiers and applied them to the data in succession. This makes th</context>
</contexts>
<marker>Habash, Roth, 2011</marker>
<rawString>Nizar Habash and Ryan M. Roth. 2011. Using deep morphology to improve automatic error detection in arabic handwriting recognition. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 875–884, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Abdelhadi Soudi</author>
<author>Tim Buckwalter</author>
</authors>
<title>On Arabic Transliteration.</title>
<date>2007</date>
<booktitle>Arabic Computational Morphology: Knowledge-based and Empirical Methods.</booktitle>
<editor>In A. van den Bosch and A. Soudi, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="10745" citStr="Habash et al., 2007" startWordPosition="1746" endWordPosition="1749">stinguish between the phenomena modeled by our system and by Eskander et al. (2013). At least 10% of all generated action labels are not handled by Eskander et al. (2013). 3.3 Features Each input character is represented by a feature vector. We include a set of basic features inspired by Eskander et al. (2013) in their CEC system and additional features for further improvement. Basic features We use a set of nine basic features: the given character, the preceding and following two characters, and the first two and last 3Arabic transliteration is presented in the Habash-SoudiBuckwalter scheme (Habash et al., 2007). For more information on Arabic orthography in NLP, see (Habash, 2010). two characters in the word. These are the same features used by CEC, except that CEC does not include characters beyond the word boundary, while we consider space characters as well as characters from the previous and next words. Ngram features We extract sequences of characters corresponding to the current character and the following and previous two, three, or four characters. We refer to these sequences as bigrams, trigrams, or 4-grams, respectively. These are an extension of the basic features and allow the model to l</context>
</contexts>
<marker>Habash, Soudi, Buckwalter, 2007</marker>
<rawString>Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter. 2007. On Arabic Transliteration. In A. van den Bosch and A. Soudi, editors, Arabic Computational Morphology: Knowledge-based and Empirical Methods. Springer.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Nizar Habash</author>
<author>Mona Diab</author>
<author>Owen Rambow</author>
</authors>
<title>Conventional orthography for dialectal Arabic. In</title>
<date>2012</date>
<booktitle>Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12),</booktitle>
<editor>Nicoletta Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet U˘gur Do˘gan, Bente Maegaard, Joseph Mariani, Jan Odijk, and Stelios Piperidis, editors,</editor>
<location>Istanbul, Turkey,</location>
<contexts>
<context position="2586" citStr="Habash et al., 2012" startWordPosition="370" endWordPosition="373">over all the training data, without guidance of specific rules. Context-sensitive The model looks beyond the context of the current word, when making a decision at the character-level. Discriminative The model provides the freedom of adding a number of different features, which may or may not be language-specific. Language-Independent In this work, we integrate only language-independent features, and therefore do not consider morphological or linguistic features. However, we apply the model to correct errors in Egyptian Arabic dialect text, following a conventional orthography standard, CODA (Habash et al., 2012). Using the described approach, we demonstrate a word-error-rate (WER) reduction of 65% over a do-nothing input baseline, and we improve over a state-of-the-art system (Eskander et al., 2013) which relies heavily on language-specific and manually-selected constraints. We present a detailed analysis of mistakes and demonstrate that the proposed model indeed learns to correct a wider variety of errors. 2 Related Work Most earlier work on automatic error correction addressed spelling errors in English and built models of correct usage on native English data (Kukich, 1992; Golding and Roth, 1999; </context>
<context position="9428" citStr="Habash et al. (2012)" startWordPosition="1528" endWordPosition="1531">ns 2.3 wfyh ⇒ wfy éJ��¯ð ⇒ ú ¯ð Complex 4.0 mykwnš ⇒ mA ykwnš �•��ñºJ�Ó ⇒ �•��ñºK� AÓ Table 3: Character-level distribution of correction labels. We model all types of transformations except complex actions, and rare Insert labels with counts below a tuned threshold. The Delete label is a single label that comprises all deletion actions. Labels modeled by Eskander et al. (2013) are marked with E, and EP for cases modeled partially, for example, the Insert{A} would only be applied at certain positions such as the end of the word. spellings of the same word. The CODA orthography was proposed by Habash et al. (2012) in an attempt to standardize dialectal writing, and we use it as a reference of correct text for spelling correction following the previous work by Eskander et al. (2013). We use the same corpus (labeled &amp;quot;ARZ&amp;quot;) and experimental setup splits used by them. The ARZ corpus was developed by the Linguistic Data Consortium (Maamouri et al., 2012a-e). See Table 2 for corpus statistics. Error Distribution Table 3 presents the distribution of correction action labels that correspond to spelling errors in the training data together with examples of these errors.3 We group the actions into: Substitute, I</context>
</contexts>
<marker>Habash, Diab, Rambow, 2012</marker>
<rawString>Nizar Habash, Mona Diab, and Owen Rambow. 2012. Conventional orthography for dialectal Arabic. In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet U˘gur Do˘gan, Bente Maegaard, Joseph Mariani, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12), Istanbul, Turkey, may. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Ryan Roth</author>
<author>Owen Rambow</author>
<author>Ramy Eskander</author>
<author>Nadi Tomeh</author>
</authors>
<title>Morphological Analysis and Disambiguation for Dialectal Arabic.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT),</booktitle>
<location>Atlanta, GA.</location>
<contexts>
<context position="6142" citStr="Habash et al., 2013" startWordPosition="959" endWordPosition="962">that possibly include errors, to a corrected sentence c of m characters, where corrected characters are produced by one of the following four actions applied to each input character ei : • ok: ei is passed without transformation. • substitute − with(c): ei is substituted with a character c where c could be any character encountered in the training data. • delete: ei is deleted. • insert(c): A character c is inserted before ei. To address errors occurring at the end 2Eskander et al. (2013) also considered a slower, more expensive, and more language-specific method using a morphological tagger (Habash et al., 2013) that outperformed the CEC model; however, we do not compare to it in this paper. Input Action Label k substitute-with(c) o ok r insert(r) e ok c ok t ok d delete Table 1: Character-level spelling error correction process on the input word korectd, with the reference word correct Train Dev Test Sentences 10.3K 1.67K 1.73K Characters 675K 106K 103K Words 134K 21.1K 20.6K Table 2: ARZ Egyptian dialect corpus statistics of the sentence, we assume the presence of a dummy sentence-final stop character. We use a multi-class SVM classifier to predict the action labels for each input character ei E e.</context>
</contexts>
<marker>Habash, Roth, Rambow, Eskander, Tomeh, 2013</marker>
<rawString>Nizar Habash, Ryan Roth, Owen Rambow, Ramy Eskander, and Nadi Tomeh. 2013. Morphological Analysis and Disambiguation for Dialectal Arabic. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), Atlanta, GA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Introduction to Arabic Natural Language Processing.</title>
<date>2010</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="10816" citStr="Habash, 2010" startWordPosition="1760" endWordPosition="1761">2013). At least 10% of all generated action labels are not handled by Eskander et al. (2013). 3.3 Features Each input character is represented by a feature vector. We include a set of basic features inspired by Eskander et al. (2013) in their CEC system and additional features for further improvement. Basic features We use a set of nine basic features: the given character, the preceding and following two characters, and the first two and last 3Arabic transliteration is presented in the Habash-SoudiBuckwalter scheme (Habash et al., 2007). For more information on Arabic orthography in NLP, see (Habash, 2010). two characters in the word. These are the same features used by CEC, except that CEC does not include characters beyond the word boundary, while we consider space characters as well as characters from the previous and next words. Ngram features We extract sequences of characters corresponding to the current character and the following and previous two, three, or four characters. We refer to these sequences as bigrams, trigrams, or 4-grams, respectively. These are an extension of the basic features and allow the model to look beyond the context of the current word. 3.4 Maximum Likelihood Esti</context>
</contexts>
<marker>Habash, 2010</marker>
<rawString>Nizar Habash. 2010. Introduction to Arabic Natural Language Processing. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bassam Haddad</author>
<author>Mustafa Yaseen</author>
</authors>
<title>Detection and Correction of Non-Words in Arabic: A Hybrid Approach.</title>
<date>2007</date>
<journal>International Journal of Computer Processing Of Languages (IJCPOL).</journal>
<contexts>
<context position="3365" citStr="Haddad and Yaseen, 2007" startWordPosition="491" endWordPosition="494">-art system (Eskander et al., 2013) which relies heavily on language-specific and manually-selected constraints. We present a detailed analysis of mistakes and demonstrate that the proposed model indeed learns to correct a wider variety of errors. 2 Related Work Most earlier work on automatic error correction addressed spelling errors in English and built models of correct usage on native English data (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest (Ben Othmane Zribi and Ben Ahmed, 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012; Eskander et al., 2013; Zaghouani et al., 2014). Supervised spelling correction approaches trained on paired examples of errors and their corrections have recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics Rozovskaya and Roth, 2011).</context>
</contexts>
<marker>Haddad, Yaseen, 2007</marker>
<rawString>Bassam Haddad and Mustafa Yaseen. 2007. Detection and Correction of Non-Words in Arabic: A Hybrid Approach. International Journal of Computer Processing Of Languages (IJCPOL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Han</author>
<author>Timothy Baldwin</author>
</authors>
<title>Lexical normalisation of short text messages: Makn sens a# twitter.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1,</booktitle>
<pages>368--378</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4285" citStr="Han and Baldwin, 2011" startWordPosition="634" endWordPosition="637">004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics Rozovskaya and Roth, 2011). Discriminative models have been proposed at the word-level for error correction (Duan et al., 2012) and for error detection (Habash and Roth, 2011). In addition, there has been growing work on lexical normalization of social media data, a somewhat related problem to that considered in this paper (Han and Baldwin, 2011; Han et al., 2013; Subramaniam et al., 2009; Ling et al., 2013). The work of Eskander et al. (2013) is the most relevant to the present study: it presents a character-edit classification model (CEC) using the same dataset we use in this paper.2 Eskander et al. (2013) analyzed the data to identify the seven most common types of errors. They developed seven classifiers and applied them to the data in succession. This makes the approach tailored to the specific data set in use and limited to a specific set of errors. In this work, a single model is considered for all types of errors. The model c</context>
</contexts>
<marker>Han, Baldwin, 2011</marker>
<rawString>Bo Han and Timothy Baldwin. 2011. Lexical normalisation of short text messages: Makn sens a# twitter. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 368–378. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Han</author>
<author>Paul Cook</author>
<author>Timothy Baldwin</author>
</authors>
<title>Lexical normalization for social media text.</title>
<date>2013</date>
<booktitle>ACM Transactions on Intelligent Systems and Technology (TIST),</booktitle>
<pages>4--1</pages>
<contexts>
<context position="4303" citStr="Han et al., 2013" startWordPosition="638" endWordPosition="641">amon, 2010; Dahlmeier and Ng, 2012; 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics Rozovskaya and Roth, 2011). Discriminative models have been proposed at the word-level for error correction (Duan et al., 2012) and for error detection (Habash and Roth, 2011). In addition, there has been growing work on lexical normalization of social media data, a somewhat related problem to that considered in this paper (Han and Baldwin, 2011; Han et al., 2013; Subramaniam et al., 2009; Ling et al., 2013). The work of Eskander et al. (2013) is the most relevant to the present study: it presents a character-edit classification model (CEC) using the same dataset we use in this paper.2 Eskander et al. (2013) analyzed the data to identify the seven most common types of errors. They developed seven classifiers and applied them to the data in succession. This makes the approach tailored to the specific data set in use and limited to a specific set of errors. In this work, a single model is considered for all types of errors. The model considers every cha</context>
</contexts>
<marker>Han, Cook, Baldwin, 2013</marker>
<rawString>Bo Han, Paul Cook, and Timothy Baldwin. 2013. Lexical normalization for social media text. ACM Transactions on Intelligent Systems and Technology (TIST), 4(1):5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed Hassan</author>
<author>Sara Noeman</author>
<author>Hany Hassan</author>
</authors>
<title>Language Independent Text Correction using Finite State Automata.</title>
<date>2008</date>
<booktitle>In Proceedings of the International Joint Conference on Natural Language Processing (IJCNLP</booktitle>
<contexts>
<context position="3386" citStr="Hassan et al., 2008" startWordPosition="495" endWordPosition="498">al., 2013) which relies heavily on language-specific and manually-selected constraints. We present a detailed analysis of mistakes and demonstrate that the proposed model indeed learns to correct a wider variety of errors. 2 Related Work Most earlier work on automatic error correction addressed spelling errors in English and built models of correct usage on native English data (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest (Ben Othmane Zribi and Ben Ahmed, 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012; Eskander et al., 2013; Zaghouani et al., 2014). Supervised spelling correction approaches trained on paired examples of errors and their corrections have recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics Rozovskaya and Roth, 2011). Discriminative model</context>
</contexts>
<marker>Hassan, Noeman, Hassan, 2008</marker>
<rawString>Ahmed Hassan, Sara Noeman, and Hany Hassan. 2008. Language Independent Text Correction using Finite State Automata. In Proceedings of the International Joint Conference on Natural Language Processing (IJCNLP 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Chunking with support vector machines.</title>
<date>2001</date>
<booktitle>In Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies, NAACL ’01,</booktitle>
<volume>1</volume>
<pages>pages</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="12333" citStr="Kudo and Matsumoto, 2001" startWordPosition="2009" endWordPosition="2012"> easily correct frequent errors; however, it is quite dependent on the training data. 4 Experiments 4.1 Model Evaluation Setup The training data was extracted to generate the form described in Section 3.1, using the Sclite tool (Fiscus, 1998) to align the input and reference sentences. A speech effect handling step was applied as a preprocessing step to all models. 163 This step removes redundant repetitions of characters in sequence, e.g., Sktyyyyyr ‘veeeeery’. The same speech effect handling was applied by Eskander et al. (2013). For classification, we used the SVM implementation in YamCha (Kudo and Matsumoto, 2001), and trained with different variations of the features described above. Default parameters were selected for training (c=1, quadratic kernel, and context window of +/- 2). In all results listed below, the baseline corresponds to the do-nothing baseline of the input text. Metrics Three evaluation metrics are used. The word-error-rate WER metric is computed by summing the total number of word-level substitution errors, insertion errors, and deletion errors in the output, and dividing by the number of words in the reference. The correct-rate Corr metric is computed by dividing the number of corr</context>
</contexts>
<marker>Kudo, Matsumoto, 2001</marker>
<rawString>Taku Kudo and Yuji Matsumoto. 2001. Chunking with support vector machines. In Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies, NAACL ’01, pages 1– 8, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Kukich</author>
</authors>
<title>Techniques for Automatically Correcting Words in Text.</title>
<date>1992</date>
<journal>ACM Computing Surveys,</journal>
<volume>24</volume>
<issue>4</issue>
<contexts>
<context position="3160" citStr="Kukich, 1992" startWordPosition="459" endWordPosition="461">y standard, CODA (Habash et al., 2012). Using the described approach, we demonstrate a word-error-rate (WER) reduction of 65% over a do-nothing input baseline, and we improve over a state-of-the-art system (Eskander et al., 2013) which relies heavily on language-specific and manually-selected constraints. We present a detailed analysis of mistakes and demonstrate that the proposed model indeed learns to correct a wider variety of errors. 2 Related Work Most earlier work on automatic error correction addressed spelling errors in English and built models of correct usage on native English data (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest (Ben Othmane Zribi and Ben Ahmed, 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012; Eskander et al., 2013; Zaghouani et al., 2014). Supervised spelling correction approaches trained on paired examples of errors and their corrections have recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 161 Proceedings of the 52nd Annual Me</context>
</contexts>
<marker>Kukich, 1992</marker>
<rawString>Karen Kukich. 1992. Techniques for Automatically Correcting Words in Text. ACM Computing Surveys, 24(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yanen Li</author>
<author>Huizhong Duan</author>
<author>ChengXiang Zhai</author>
</authors>
<title>A generalized hidden markov model with discriminative training for query spelling correction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’12,</booktitle>
<pages>611--620</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="3684" citStr="Li et al., 2012" startWordPosition="542" endWordPosition="545">ng errors in English and built models of correct usage on native English data (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest (Ben Othmane Zribi and Ben Ahmed, 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012; Eskander et al., 2013; Zaghouani et al., 2014). Supervised spelling correction approaches trained on paired examples of errors and their corrections have recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics Rozovskaya and Roth, 2011). Discriminative models have been proposed at the word-level for error correction (Duan et al., 2012) and for error detection (Habash and Roth, 2011). In addition, there has been growing work on lexical normalization of social media data, a somewhat related problem to that considered in this paper (Han and Baldwin, 201</context>
</contexts>
<marker>Li, Duan, Zhai, 2012</marker>
<rawString>Yanen Li, Huizhong Duan, and ChengXiang Zhai. 2012. A generalized hidden markov model with discriminative training for query spelling correction. In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’12, pages 611–620, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wang Ling</author>
<author>Chris Dyer</author>
<author>Alan W Black</author>
<author>Isabel Trancoso</author>
</authors>
<title>Paraphrasing 4 microblog normalization.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>73--84</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="4349" citStr="Ling et al., 2013" startWordPosition="646" endWordPosition="649">eedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics Rozovskaya and Roth, 2011). Discriminative models have been proposed at the word-level for error correction (Duan et al., 2012) and for error detection (Habash and Roth, 2011). In addition, there has been growing work on lexical normalization of social media data, a somewhat related problem to that considered in this paper (Han and Baldwin, 2011; Han et al., 2013; Subramaniam et al., 2009; Ling et al., 2013). The work of Eskander et al. (2013) is the most relevant to the present study: it presents a character-edit classification model (CEC) using the same dataset we use in this paper.2 Eskander et al. (2013) analyzed the data to identify the seven most common types of errors. They developed seven classifiers and applied them to the data in succession. This makes the approach tailored to the specific data set in use and limited to a specific set of errors. In this work, a single model is considered for all types of errors. The model considers every character in the input text for a possible spelli</context>
</contexts>
<marker>Ling, Dyer, Black, Trancoso, 2013</marker>
<rawString>Wang Ling, Chris Dyer, Alan W Black, and Isabel Trancoso. 2013. Paraphrasing 4 microblog normalization. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 73–84, Seattle, Washington, USA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Seth Kulick</author>
<author>Sondos Krouna</author>
<author>Dalila Tabassi</author>
<author>Michael Ciul</author>
</authors>
<booktitle>2012a. Egyptian Arabic Treebank DF Part 1 V2.0. LDC catalog number LDC2012E93.</booktitle>
<marker>Maamouri, Bies, Kulick, Krouna, Tabassi, Ciul, </marker>
<rawString>Mohamed Maamouri, Ann Bies, Seth Kulick, Sondos Krouna, Dalila Tabassi, and Michael Ciul. 2012a. Egyptian Arabic Treebank DF Part 1 V2.0. LDC catalog number LDC2012E93.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Seth Kulick</author>
<author>Sondos Krouna</author>
<author>Dalila Tabassi</author>
<author>Michael Ciul</author>
</authors>
<booktitle>2012b. Egyptian Arabic Treebank DF Part 2 V2.0. LDC catalog number LDC2012E98.</booktitle>
<marker>Maamouri, Bies, Kulick, Krouna, Tabassi, Ciul, </marker>
<rawString>Mohamed Maamouri, Ann Bies, Seth Kulick, Sondos Krouna, Dalila Tabassi, and Michael Ciul. 2012b. Egyptian Arabic Treebank DF Part 2 V2.0. LDC catalog number LDC2012E98.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Seth Kulick</author>
<author>Sondos Krouna</author>
<author>Dalila Tabassi</author>
<author>Michael Ciul</author>
</authors>
<booktitle>2012c. Egyptian Arabic Treebank DF Part 3 V2.0. LDC catalog number LDC2012E89.</booktitle>
<marker>Maamouri, Bies, Kulick, Krouna, Tabassi, Ciul, </marker>
<rawString>Mohamed Maamouri, Ann Bies, Seth Kulick, Sondos Krouna, Dalila Tabassi, and Michael Ciul. 2012c. Egyptian Arabic Treebank DF Part 3 V2.0. LDC catalog number LDC2012E89.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Seth Kulick</author>
<author>Sondos Krouna</author>
<author>Dalila Tabassi</author>
<author>Michael Ciul</author>
</authors>
<booktitle>2012d. Egyptian Arabic Treebank DF Part 4 V2.0. LDC catalog number LDC2012E99.</booktitle>
<marker>Maamouri, Bies, Kulick, Krouna, Tabassi, Ciul, </marker>
<rawString>Mohamed Maamouri, Ann Bies, Seth Kulick, Sondos Krouna, Dalila Tabassi, and Michael Ciul. 2012d. Egyptian Arabic Treebank DF Part 4 V2.0. LDC catalog number LDC2012E99.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Seth Kulick</author>
<author>Sondos Krouna</author>
<author>Dalila Tabassi</author>
<author>Michael Ciul</author>
</authors>
<booktitle>2012e. Egyptian Arabic Treebank DF Part 5 V2.0. LDC catalog number LDC2012E107.</booktitle>
<marker>Maamouri, Bies, Kulick, Krouna, Tabassi, Ciul, </marker>
<rawString>Mohamed Maamouri, Ann Bies, Seth Kulick, Sondos Krouna, Dalila Tabassi, and Michael Ciul. 2012e. Egyptian Arabic Treebank DF Part 5 V2.0. LDC catalog number LDC2012E107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alla Rozovskaya</author>
<author>Dan Roth</author>
</authors>
<title>Algorithm selection and model adaptation for esl correction tasks.</title>
<date>2011</date>
<booktitle>In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL),</booktitle>
<location>Portland, Oregon,</location>
<contexts>
<context position="3964" citStr="Rozovskaya and Roth, 2011" startWordPosition="580" endWordPosition="583">03; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012; Eskander et al., 2013; Zaghouani et al., 2014). Supervised spelling correction approaches trained on paired examples of errors and their corrections have recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics Rozovskaya and Roth, 2011). Discriminative models have been proposed at the word-level for error correction (Duan et al., 2012) and for error detection (Habash and Roth, 2011). In addition, there has been growing work on lexical normalization of social media data, a somewhat related problem to that considered in this paper (Han and Baldwin, 2011; Han et al., 2013; Subramaniam et al., 2009; Ling et al., 2013). The work of Eskander et al. (2013) is the most relevant to the present study: it presents a character-edit classification model (CEC) using the same dataset we use in this paper.2 Eskander et al. (2013) analyzed t</context>
</contexts>
<marker>Rozovskaya, Roth, 2011</marker>
<rawString>Alla Rozovskaya and Dan Roth. 2011. Algorithm selection and model adaptation for esl correction tasks. In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL), Portland, Oregon, 6. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Khaled Shaalan</author>
<author>Rana Aref</author>
<author>Aly Fahmy</author>
</authors>
<title>An approach for analyzing and correcting spelling errors for non-native Arabic learners.</title>
<date>2010</date>
<booktitle>Proceedings of Informatics and Systems (INFOS).</booktitle>
<contexts>
<context position="3408" citStr="Shaalan et al., 2010" startWordPosition="499" endWordPosition="502">es heavily on language-specific and manually-selected constraints. We present a detailed analysis of mistakes and demonstrate that the proposed model indeed learns to correct a wider variety of errors. 2 Related Work Most earlier work on automatic error correction addressed spelling errors in English and built models of correct usage on native English data (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest (Ben Othmane Zribi and Ben Ahmed, 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012; Eskander et al., 2013; Zaghouani et al., 2014). Supervised spelling correction approaches trained on paired examples of errors and their corrections have recently been applied for non-native English correction (van Delden et al., 2004; Li et al., 2012; Gamon, 2010; Dahlmeier and Ng, 2012; 161 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 161–167, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics Rozovskaya and Roth, 2011). Discriminative models have been proposed a</context>
</contexts>
<marker>Shaalan, Aref, Fahmy, 2010</marker>
<rawString>Khaled Shaalan, Rana Aref, and Aly Fahmy. 2010. An approach for analyzing and correcting spelling errors for non-native Arabic learners. Proceedings of Informatics and Systems (INFOS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Venkata Subramaniam</author>
<author>Shourya Roy</author>
</authors>
<title>Tanveer A Faruquie, and Sumit Negi.</title>
<date>2009</date>
<booktitle>In Proceedings of The Third Workshop on Analytics for Noisy Unstructured Text Data,</booktitle>
<pages>115--122</pages>
<publisher>ACM.</publisher>
<marker>Subramaniam, Roy, 2009</marker>
<rawString>L Venkata Subramaniam, Shourya Roy, Tanveer A Faruquie, and Sumit Negi. 2009. A survey of types of text noise and techniques to handle noisy text. In Proceedings of The Third Workshop on Analytics for Noisy Unstructured Text Data, pages 115–122. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian van Delden</author>
<author>David B Bracewell</author>
<author>Fernando Gomez</author>
</authors>
<title>Supervised and unsupervised automatic spelling correction algorithms.</title>
<date>2004</date>
<booktitle>In Information Reuse and Integration,</booktitle>
<pages>530--535</pages>
<marker>van Delden, Bracewell, Gomez, 2004</marker>
<rawString>Sebastian van Delden, David B. Bracewell, and Fernando Gomez. 2004. Supervised and unsupervised automatic spelling correction algorithms. In Information Reuse and Integration, 2004. Proceedings of the 2004 IEEE International Conference on, pages 530–535.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wajdi Zaghouani</author>
</authors>
<title>Behrang Mohit, Nizar Habash, Ossama Obeid, Nadi Tomeh, Alla Rozovskaya, Noura Farra, Sarah Alkuhlani, and Kemal Oflazer.</title>
<date>2014</date>
<booktitle>In Proceedings of the 9th edition of the Language Resources and Evaluation Conference.</booktitle>
<marker>Zaghouani, 2014</marker>
<rawString>Wajdi Zaghouani, Behrang Mohit, Nizar Habash, Ossama Obeid, Nadi Tomeh, Alla Rozovskaya, Noura Farra, Sarah Alkuhlani, and Kemal Oflazer. 2014. Large scale Arabic error annotation: Guidelines and framework. In Proceedings of the 9th edition of the Language Resources and Evaluation Conference.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>