<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.991237">
NE Tagging for Urdu based on Bootstrap POS Learning
</title>
<author confidence="0.995238">
Smruthi Mukund Rohini K. Srihari
</author>
<affiliation confidence="0.859645">
Dept. of Computer Science and Engineering Dept. of Computer Science and Engineering
University at Buffalo, SUNY University at Buffalo, SUNY
</affiliation>
<address confidence="0.717945">
Amherst, NY, USA Amherst, NY, USA
</address>
<email confidence="0.998865">
smukund@buffalo.edu rohini@cedar.buffalo.edu
</email>
<sectionHeader confidence="0.994084" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99663792">
Part of Speech (POS) tagging and Named Ent-
ity (NE) tagging have become important com-
ponents of effective text analysis. In this
paper, we propose a bootstrapped model that
involves four levels of text processing for Ur-
du. We show that increasing the training data
for POS learning by applying bootstrapping
techniques improves NE tagging results. Our
model overcomes the limitation imposed by
the availability of limited ground truth data
required for training a learning model. Both
our POS tagging and NE tagging models are
based on the Conditional Random Field
(CRF) learning approach. To further enhance
the performance, grammar rules and lexicon
lookups are applied on the final output to cor-
rect any spurious tag assignments. We also
propose a model for word boundary segmen-
tation where a bigram HMM model is trained
for character transitions among all positions in
each word. The generated words are further
processed using a probabilistic language mod-
el. All models use a hybrid approach that
combines statistical models with hand crafted
grammar rules.
</bodyText>
<sectionHeader confidence="0.999192" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999776714285714">
The work here is motivated by a desire to under-
stand human sentiment and social behavior through
analysis of verbal communication. Newspapers
reflect the collective sentiments and emotions of
the people and in turn the society to which they
cater to. Not only do they portray an event that has
taken place as is, but they also reveal details about
</bodyText>
<page confidence="0.988881">
61
</page>
<bodyText confidence="0.999952727272727">
the intensity of fear, imagination, happiness and
other emotions that people express in relation to
that event. Newspaper write ups, when analyzed
over these factors - emotions, reactions and beha-
vior - can give a broader perspective on the culture,
beliefs and the extent to which the people in the
region are tolerant towards other religions. Our
final goal is to automate this kind of behavioral
analysis on newspaper articles for the Urdu lan-
guage. Annotated corpus that tag six basic human
emotions, “happy”, “fear”, “sad”, “surprise”, “an-
ger” and “disgust”, based on the code book devel-
oped using the MPQA standards as guideline, is
currently being developed. Articles from two lead-
ing Urdu newswires, BBC Urdu1 and Jung Daily2
form our corpus.
In order to achieve our goal, it was required to
generate the basic tools needed for efficient text
analysis. This includes NE tagging and its precur-
sor, POS tagging. However, Urdu, despite being
spoken by over 100 million people, (Gordon,
2005) is still a less privileged language when it
comes to the availability of resources on the inter-
net. Developing tools for a language with limited
resources is a challenge, but necessary, as the vo-
lume of Urdu text on the internet is rising. Huda
(2001) shows that Urdu has now gained impor-
tance on the web, making it the right time to tackle
these issues.
It is useful to first examine some basic proper-
ties of Urdu and how they affect the cascade of
NLP steps in text analysis. Urdu has the nastaleeq
and nasq style of writing that is similar to Arabic
</bodyText>
<footnote confidence="0.99737">
1 http://www.bbc.co.uk/urdu/
2 http://www.jang.net/urdu/
</footnote>
<note confidence="0.9847045">
Proceedings of CLIAWS3, Third International Cross Lingual Information Access Workshop, pages 61–69,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.998303733333333">
and flows from right to left (Ahmad et al., 2001). It
also adopts some of its vocabulary from Arabic.
However, the grammar and semantics of the lan-
guage is similar to Hindi and this makes it very
different from Arabic. For effective text analysis, a
thorough syntactic and semantic understanding of
the language is required. Detailed grammatical
analysis provided by Platts (1909) and Schmidt
(1999) can be used for this purpose. The first step
in the information retrieval pipeline is tokeniza-
tion. Unlike English, where the word delimiter is
mostly a space, Urdu is more complex. There are
space insertion as well as space deletion problems.
This makes tokenization a difficult task. The word
segmentation model that we propose here com-
bines the statistical approach that considers bigram
transition of characters based on their positions in a
word and morphological rules with lexicon loo-
kups.
POS tagging comes next in the NLP text analy-
sis pipeline. The accuracy of the tagging model
varies, depending on the tagsets used and the do-
main of the ground truth data. There are two main
tagsets designed for Urdu, the CRULP tagset3 and
the U1-tagset (Hardie 2003). The U1-tagset, re-
leased as a part of EMILLE4 corpus, is based on
the EAGLES standards (Leech and Wilson 1999).
We decided to use the standards proposed by
CRULP for the following reasons.
1. The tagset, though not as detailed as the
one proposed in U1-tagset, covers all the
basic requirements needed to achieve our
final goal.
2. The tagged corpus provided by CRULP is
newswire material, similar to our final
corpus.
A person, when asked to identify an NE tagged
word in a sentence would typically try to first find
the word associated with a proper noun or a noun,
and then assign a suitable NE tag based on the con-
text. A similar approach is used in our model,
where the learning happens on the data that is POS
tagged as well as NE tagged. Features are learnt
from the POS tags as well as the NE tags. The final
output of our complete model returns the POS tags
</bodyText>
<page confidence="0.866813">
3
</page>
<footnote confidence="0.784120666666667">
http://www.crulp.org/Downloads/ling_resources/parallelcorpu
s/Urdu POS Tagset.pdf
4 http://www.emille.lancs.ac.uk/
</footnote>
<bodyText confidence="0.9997448125">
and NE tags associated with each word. Since we
have limited data for training both the POS as well
as the NE models, we propose a technique called
bootstrapping that helps in maximizing the learn-
ing for efficient tagging.
The remainder of the paper is organized as fol-
lows. Section 2 discusses the resources assimilated
for the work followed by tokenization and word
segmentation in Section 3. Section 4 gives a de-
tailed explanation of our model starting with a
brief introduction of the learning approach used.
Rules used for POS tagging and NE tagging are
mentioned in subsections of Section 4. Section 5
presents the results and Section 6 concludes the
paper. In each section, wherever relevant, previous
work and drawbacks are presented.
</bodyText>
<sectionHeader confidence="0.996479" genericHeader="introduction">
2 Resources
</sectionHeader>
<bodyText confidence="0.9995417">
Based on the style of writing for Urdu, different
encoding standards have been proposed. Urdu
Zabta Takthi - the national standard code page for
Urdu and Unicode - international standard for mul-
tilingual characters are the two proposed and wide-
ly used encoding standards. BBC Urdu and Jung
Daily are both encoded with Unicode standards
and are good sources of data. The availability of
online resources for Urdu is not as extensive as
other Asian languages like Chinese and Hindi.
However, Hussain (2008) has done a good job in
assimilating most of the resources available on the
internet. The lexicon provided as a part of the
EMILLE (2003) data set for Urdu has about
200,000 words. CRL5 has released a lexicon of
8000 words as a part of their Urdu data collection.
They also provide an NE tagged data set mostly
used for morphological analysis. The lexicon in-
cludes POS information as well. CRULP6 has also
provided a lexicon of 149,466 words that contains
places, organizations and names of people. As part
of the Urdu morphological analyzer provided by
Humayoun (2007), a lexicon of about 4,500 unique
words is made available. There are a few Urdu-
English dictionaries available online and the first
online dictionary, compiled by Siddiqi (2008),
provides about 24,000 words with their meanings
in English.
Getting all the resources into one single compi-
lation is a challenge. These resources were brought
</bodyText>
<footnote confidence="0.991192">
5 http://crl.nmsu.edu/Resources/lang_res/urdu.html
6 http://www.crulp.org/software/ling_resources/wordlist.htm
</footnote>
<page confidence="0.999388">
62
</page>
<bodyText confidence="0.999807357142857">
together and suitably compiled into a format that
can be easily processed by Semantex (Srihari,
2008), a text extraction platform provided by Janya
Inc7. Lists of places, organizations and names of
famous personalities in Pakistan were also com-
piled using the Urdu-Wikipedia8 and NationalMas-
ter9. A list of most common names in Pakistan was
composed by retrieving data from the various
name databases available on the internet.
The word segmentation model uses the Urdu
corpus released by CRULP as the training data.
This dataset is well segmented. POS tagging model
uses data provided by CRULP and NE tagging
model uses data provided by CRL.
</bodyText>
<sectionHeader confidence="0.908882" genericHeader="method">
3 Word Segmentation and Tokenization
</sectionHeader>
<bodyText confidence="0.999981806451613">
Urdu is a language that has both the space inser-
tion and space deletion problems. The Urdu word
segmentation problem as mentioned by Durrani
(2007) is triggered by its orthographic rules and
confusions about the definition of a word. Durrani
summarizes effectively, all the problems associated
with Urdu word segmentation. Of all the different
techniques explored to achieve this objective, tra-
ditional techniques like longest and maximum
matching depend mostly on the availability of a
lexicon that holds all the morphological forms of a
word. Such a lexicon is difficult to obtain. It is
shown by Theeramunkong et al., (2001), that for a
Thai segmentation system, the efficiency drops
considerably (from 97% to 82%) making this ap-
proach highly lexicon dependent.
Statistical based techniques have applied proba-
bilistic models to solve the problem of word seg-
mentation. Bigram and trigram models are most
commonly employed. Using feature based tech-
niques for POS tagging is also very common.
These techniques overcome the limitations of sta-
tistical models by considering the context around
the word for specific words and collocations. There
are other models that generate segments by consi-
dering word level collation as well as syllable level
collocation.
However, for a language like Urdu, a model that
is purely statistical will fail to yield good segmen-
tation results. A mixed model that considers the
morphological as well as semantic features of the
</bodyText>
<footnote confidence="0.993824">
7 http://www.janyainc.com/
8 http://ur.wikipedia.com/wiki/
9 http://www.nationmaster.com/index.php
</footnote>
<bodyText confidence="0.987807708333334">
language facilitates better performance as shown
by Durrani (2007) where the word segmentation
model uses a lexicon for proper nouns and a statis-
tical model that trains over the n-gram probability
of morphemes. Maximum matching technique is
used to generate word boundaries of the ortho-
graphic words that are formed and these are later
verified using the POS information. The segments
thus generated are ranked and the best ones are
accepted. Statistical models that consider character
based, syllable based and word based probabilities
have shown to perform reasonably well. The Thai
segmentation problem was solved by Pornprasert-
kul (1994) using the character based approach. In
our model, we use a combination of character
based statistical approach and grammar rules with
lexicon lookups to generate word boundaries.
Urdu segmentation problem can be looked at as
an issue of inserting spaces between characters. All
letters in Urdu, with a few exceptions, have three
forms - initial, medial and final. (We do not con-
sider the detached form for word formation).
Words are written by joining the letters together
and based on the position of the letter in the word,
suitable forms are applied. This property of word
formation is the crux of our model. The bigram
probability of occurrences of each of these charac-
ters, based on their positions, is obtained by train-
ing over a properly segmented training set. For
unknown characters, unknown character models
for all the three position of occurrences are also
trained. The probability of word occurrence is
noted. Along with this, a lexicon rich enough to
hold all possible common words is maintained.
However, this lexicon does not contain proper
nouns. A new incoming sentence that is not seg-
mented correctly is taken and suitable word boun-
daries are generated by using a combination of
morphological rules, lexicon lookups, bigram word
probabilities and bigram HMM character model.
The following probabilities are estimated and max-
imized at character level using the Viterbi algo-
rithm. The following are the calculated
probabilities:
(i) P(chk(medial)  |ch k−1(initial)) - is the prob-
bility of character k being in medial
form given character k-1 is in initial
form.
</bodyText>
<page confidence="0.993958">
63
</page>
<bodyText confidence="0.7967085">
(ii) P(chk(final)  |ch k−1(initial)) - is the proba-
bility of character k being in final form
given character k-1 is in initial form.
(iii) P(chk(final)  |chk−1(medial) ) - is the proba-
bility of character k being in final form
given character k-1 is in medial form.
(iv) P(ch k(medial)  |ch k−1(medial)) - is the proba-
bility of character k being in medial
form given character k-1 is in medial
form.
</bodyText>
<listItem confidence="0.471394">
(v) P(chk(initial)  |chk−1(final) ) - is the proba-
</listItem>
<bodyText confidence="0.999606368421053">
bility of character k being in initial
form given character k-1 is in final
form.
Each word thus formed successfully is then veri-
fied for morphological correctness. If the word is
not valid morphologically, then the window is
moved back over 3 characters and at every step the
validity of occurrence of the word is noted. Simi-
larly, the window is moved 3 characters ahead and
the validity of the word is verified. All words
formed successfully are taken and further
processed using a language model that considers
the bigram occurrence for each word. The un-
known word probability is considered here as well.
The word with maximum probability is taken as
valid in the given context.
Let &lt; w1w2w3 &gt; be the word formed by the
moving window. Then, the word selected, ws, is
given by
</bodyText>
<equation confidence="0.998967">
P(wO  |P(wprev)
P(w2)  |P(wprev)
P(w3)  |P(wprev)
</equation>
<bodyText confidence="0.97765175">
where wprev is the previous word.
It is also noted that the number of times a transi-
tion happens from a syllable set with consonants to
a syllable set with vowels, in a word, is no longer
than four in most cases as noted below. This factor
is also considered for terminating the Viterbi algo-
rithm for each word.
Ir  |aad  |ah - three transitions
</bodyText>
<subsectionHeader confidence="0.978373">
4.1 Conditional Random Fields (CRF)
</subsectionHeader>
<bodyText confidence="0.973774666666667">
Some of the morphological rules considered
while deciding the word boundaries are given be-
low. Word boundary is formed when
</bodyText>
<figure confidence="0.849731888888889">
1. The word ends with &apos;&apos;ں” - Nun Gunna
2. The character transitions over to digits
3. Punctuations marks are encountered (&apos;-&apos; is
also included)
4. No two &apos;ye&apos; - choti ye come back to back
5. No characters occur in detached form un-
less they are initials or abbreviations fol-
lowed by a period
6. If current character is &apos;alif&apos; and the pre-
</figure>
<bodyText confidence="0.964169192307692">
vious character is &apos;ee&apos; - bari ye then the
word boundary occurs after &apos;alif&apos;
Some of the drawbacks seen in this model are
mainly on account of improper identification of
proper nouns. If a proper noun is not well seg-
mented, the error propagates through the sentence
and typically the next two or three words fail to get
segmented correctly. Also, in Urdu, some words
can be written in more than one ways. This mostly
depends on the diacritics and ambiguity between
bari and choti &apos;ye&apos;. The training data as well as the
test data were not normalized before training. The
model shows a precision of 83%. We realized that
the efficiency of this model can be improved if
phoneme level transitions were taken into consid-
eration. Training has to be increased over more
proper nouns and a lexicon for proper nouns loo-
kup has to be maintained. Diacritics that are typi-
cally used for beautification should be removed.
Words across the documents need to be normalized
to one accepted format to assure uniqueness. This
involves considerable amount of work and hence,
in order to prevent the propagation of error into the
NLP text analysis pipeline, we decided to test our
subsequent models using pre-segmented data, in-
dependent of our word segmentation model.
</bodyText>
<sectionHeader confidence="0.968673" genericHeader="method">
4 Learning Approaches
</sectionHeader>
<bodyText confidence="0.998329625">
A Conditional Random Field (CRF), is an undi-
rected graphical model used for sequential learn-
ing. The tasks of POS tagging and NE tagging are
both sequential learning tasks and hence this learn-
ing approach is a reasonable choice. What follows
is a brief outline about CRF. Interested readers are
referred to Lafferty et al., (2001), for more infor-
mation on CRF.
</bodyText>
<figure confidence="0.980560555555555">
(vi) ws � max �
I
�
I�
I
�
�
I
�
</figure>
<page confidence="0.98972">
64
</page>
<bodyText confidence="0.997667666666667">
A linear chain CRF defines a single log-linear
probabilistic distribution over the possible tag se-
quences y for a sentence x
</bodyText>
<equation confidence="0.658368">
p(y  |x) = Z1 exp
</equation>
<bodyText confidence="0.999962333333333">
where fk(t, yt, yt-1, xt) is typically a binary function
indicating the presence of feature k, λk is the weight
of the feature, and Z(x) is a normalization function.
</bodyText>
<equation confidence="0.9899425">
T K
Z(x) exp
= ∑ ∑∑ λk fk (t, yt , yt−1 , xt
y t=1 k=1
</equation>
<bodyText confidence="0.999582">
This modeling allows us to define features on
states (the POS/NE tags) and edges (pairs of adja-
cent POS/NE tags) combined with observations
(eg. words and POS tags for NE estimation). The
weights of the features are determined such that
they maximize the conditional log-likelihood of the
training data:
</bodyText>
<equation confidence="0.90386">
L (θ) = ∑N1log(pθ(y(i)  |x(i)))
i .
</equation>
<bodyText confidence="0.995957">
For the actual implementation, CRF++10, an
open source tool that uses the CRF learning algo-
rithm is used. The L-BFGS algorithm11 is used for
optimization.
</bodyText>
<subsectionHeader confidence="0.961442">
4.2 NE Tagging using POS information
</subsectionHeader>
<bodyText confidence="0.998669428571429">
POS tagging is a precursor for all text analysis
tasks. Assigning POS tags to words without any
ambiguity depends on contextual information and
extracting this information is a challenge. For a
language like English, several techniques have
been proposed that can be broadly classified into
statistical, rule based and hybrid approaches (Ek-
bal, 2007). The general consensus is that ap-
proaches like MEMM and HMM, that work well
for Hindi, would work well for Urdu as well, since
Urdu is grammatically similar to Hindi (Platts,
1909). However, the linguistic and morphological
rules used in the post processing steps differ from
Hindi because of Urdu’s borrowed vocabulary and
</bodyText>
<footnote confidence="0.934726">
10 http://crfpp.sourceforge.net/
11 http://www.mcs.anl.gov/index.php
</footnote>
<bodyText confidence="0.99995442">
style of writing from Arabic. Also, the requirement
for such models to work well is the availability of
large training data.
Building NE recognizers for languages like Ur-
du is difficult as there are no concepts like capitali-
zation of characters. Also, most names of people
have specific meanings associated with them and
can easily be found in a dictionary with different
associated meanings. Various learning approaches
have been proposed for this task, HMM based
learning approach (Bikel et al., 1999), Maximum
Entropy Approach (Borthwick, 1999) and CRF
approach (McCallum, 2003) are the most popular.
Ashish et al., (2009) show an SVM based approach
also works well for such tasks. To overcome the
problem of limited data availability, we present a
method to increase the amount of training data that
is available, by using a technique called bootstrap-
ping.
We do not have a training corpus that is manual-
ly tagged for both POS and NE. Our training data
consists of two different datasets. The dataset used
for POS tagging is provided by CRULP and is
tagged using their tagset. The dataset used for NE
tagging is provided by CRL as a part of their Urdu
resource package. The CRL tagset consists of
LOCATION, PERSON, ORGANIZATION, DATE
and TIME tags. We use only the first three tags in
this work.
Our aim is to achieve effective POS tagging and
NE tagging by maximizing the use of the available
training data. The CRULP dataset (which we call
datasetPOS) is a corpus of 150,000 words that are
only POS tagged and the CRL dataset (which we
call datasetNE) is a corpus of 50,000 words that are
only NE tagged. First, we trained a CRF model on
datasetNE that uses only the NE information to per-
form NE recognition. This one stage model was
not effective due to the sparseness of the NE tags
in the dataset. The model requires more data while
training. The obvious and frequently tried ap-
proach (Thamar, 2004) is to use the POS informa-
tion.
Figure 1 shows a two stage model that uses POS
information to perform NE tagging. The first stage
POSA performs POS tagging by using a CRF
trained model to assign POS tags to each word in a
sentence of datasetNE. The second stage NEA per-
forms NE tagging by using another CRF trained
model that uses both the POS information as well
</bodyText>
<equation confidence="0.9950314">
T K
∑∑ λkfk (t, yt , yt−
t=1 k=1
)
1 , xt
</equation>
<page confidence="0.994834">
65
</page>
<bodyText confidence="0.98817">
as the NE information, to perform effective NE
tagging.
</bodyText>
<figureCaption confidence="0.9686975">
Figure 1. Two stage model for NE tagging using POS
information
</figureCaption>
<bodyText confidence="0.999334903225807">
However, although the accuracy of NE tagging
improved over the one stage model, there was
scope for further improvement. It is obvious that
all the NE tagged words should have the proper
noun (NNP) POS tag associated. But, when POS
tags were generated for the NE tagged ground truth
data in datasetNE, most of the words were either
tagged as adjectives (JJ) or common nouns (NN).
Most tags that come after case markers (CM) were
adjectives (JJ) in the training data. Very few ac-
counted for proper nouns after case markers. This
adversely affected the NE tagger output. It was
also noticed that the POS tagger tagged most of the
proper nouns (NNP) as common nouns (NN) be-
cause of the sparseness of the proper noun tag in
the POS ground truth data set datasetPOS. This ob-
servation made us look to bootstrapping techniques
for effective learning.
We propose a four stage model as shown in Fig-
ure 2, for NE tagging. Three of the stages are
trained using the CRF learning approach and one
stage uses a rule based approach. All four stages
are trained using unigram features on tags and
words and bigram features on tags. The POS
tagged dataset, datasetPOS, consists of words and
associated POS tags and the NE tagged dataset,
datasetNE, consists of words and associated NE
tags. We divide both datasets into training and test-
ing partitions. datasetPOS is divided into trainsetPOS
and testsetPOS and datasetNE is divided into train-
setNE and testsetNE.
</bodyText>
<figureCaption confidence="0.9953015">
Figure 2. Four stage model for NE tagging using POS
information with bootstrapping
</figureCaption>
<bodyText confidence="0.999964083333333">
In the model shown in Figure 2, POSA stage is a
CRF based stage that is trained using trainsetPOS.
Once trained, the POSA stage takes as input a sen-
tence and generates the associated POS tag for
each word in that sentence.
In order to increase the NNP tag associations to
improve NE tagging, we generate POS tags for the
NE training data in trainsetNE using the POSA
stage. The POS tags generated at the POSA stage
are called POSint. The POScorrection stage takes as
input trainsetNE along with its associated POS tags,
POSint. At this stage, correction rules - that change
the POS tags of NE associated words to proper
noun (NNP), assign Case Markers (CM) before
and after the NE tags and verify proper tagging of
Cardinals (CD) - are applied. The corrected POS
tags are called POScorrected. A consolidated POS
training set consisting of entries from both train-
setPOS and trainsetNE (with POScorrected generated as
output from the POScorrection stage) is used to train
the CRF based POSB stage. This stage is the final
POS tagging stage. Test data consisting of sen-
tences (words) from testsetNE is sent as input to
stage POSB and the output generated at stage POSB
is the POS tag associated with each input word of a
sentence. The NEB stage is a CRF based NE tagger
that is trained on a dataset consisting of word and
associated NE tags from trainsetNE and associated
POS tags from POScorrected. This stage learns from
the POS information and the NE information pro-
vided in the training data. Once trained, the NEB
stage takes as input words from testsetNE and asso-
ciated POS tags (obtained at stage POSB) and ge-
nerates NE tags.
The domain we are interested in is newswire
material, and these articles are written in the “jour-
</bodyText>
<page confidence="0.977979">
66
</page>
<bodyText confidence="0.999468769230769">
nalistic” or “news writing” style12. The articles are
objective and follow a Subject-Object-Verb struc-
ture. Related information is usually presented with-
in close sentence proximity. This makes it possible
to hand-craft grammar rules for the discovery of
NE tags with fine granularity. The final POS
tagged and NE tagged data generated as outputs at
stage POSB and stage NEB respectively of the four
stage model, are processed using rules and lexicon
lookups to further improve the overall tagging ac-
curacy of the model. Rules used are mostly domain
specific. The rules were applied to the model using
Semantex.
</bodyText>
<subsectionHeader confidence="0.869103">
4.3 Rules for POS Tagging
</subsectionHeader>
<bodyText confidence="0.8292552">
1. Our model tags all the Question Words
(QW) like ‘1i�’ - kya as pronoun (PR). All
such occurrences are assigned QW tag.
2. If the word is ‘W – kya and the previous
tag is an adjective (JJ) and the next tag is a
phrase marker (PM) then assign a light
verb tag (VBL) else assign a verb (VB) tag
to the word.
3. It was observed that there were spurious
instances of proper nouns getting tagged as
nouns. In order to correct this error, if a
word ends with any of the characters
shown below, and the word was tagged as
a noun, then the tag on the word was
changed to a proper noun.
rsrr rIrr rLrr r�rr rL_�rr
r�rr r�9rr r 0LS rr r�ur
4. All valid cardinals were tagged as nouns or
proper nouns by the model. This was re-
solved by looking for a digit in the string.
</bodyText>
<subsectionHeader confidence="0.950735">
4.4 Rules for NE Tagging
</subsectionHeader>
<bodyText confidence="0.9848152">
1. Words like “ٹر}S” (court), “ور9i?” (bu-
reau), “جte” (army) etc. are looked up. If
there are any nouns or proper nouns above
these within a window of two, then the tag
on this word is ORGANIZATION.
</bodyText>
<listItem confidence="0.922226666666667">
2. Words like “�i ��” (organization), “��رآ”
are marked ORGANIZATION if the pre-
vious word is a proper noun.
3. Lexicon look up for names of places is per-
formed and the POS tag of the next word
that is found is checked. If this tag is a
</listItem>
<subsectionHeader confidence="0.750708">
12 http://en.wikipedia.org/wiki/News_writing
</subsectionHeader>
<bodyText confidence="0.999354625">
Case Marker (CM) with a feminine gend-
er, like “,=V (main) or “ui�”, then the
word is marked with a LOCATION tag.
4. If a proper noun that is selected ends with
a suffix “pur”, “bad, “dad” and has the
same constraint as mentioned in rule 3,
then the LOCATION tag is assigned to it
as well.
</bodyText>
<sectionHeader confidence="0.999797" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.9960754">
The NE tagging performance, for both the two
stage model and the four stage model, are eva-
luated using Precision (P), Recall (R) and F-Score
(FS) metrics, the equations for which are given
below.
</bodyText>
<figure confidence="0.88530125">
No. of correctly tagged NEs
(vii) P =
No. of tagged NEs
No. of tagged NEs
Total no. of NEs in test set
(ix) FS = 2
RP
R+P
</figure>
<bodyText confidence="0.999966444444444">
We performed a 10 fold cross validation test to
determine the performance of the model. The data-
set is divided into 10 subsets of approximately
equal size. One subset is withheld for testing and
the remaining 9 subsets are used for training. This
process is repeated for all 10 subsets and an aver-
age result is computed. The 10 fold validation test
for NE tagging was performed for both the two
stage as well as the four stage models.
</bodyText>
<table confidence="0.998178076923077">
Set Two Stage Model Four Stage Model
P R FS P R FS
1 48.09 73.25 58.06 60.54 78.7 68.44
2 38.94 72.42 50.65 60.29 80.46 68.93
3 56.98 74.38 64.53 60.54 79.74 68.83
4 38.44 78.05 51.51 60.54 80.79 69.21
5 32.29 75.91 45.31 60.79 80.34 69.21
6 44.82 88.02 59.4 59.31 79.93 68.09
7 45.75 69.75 55.26 61.04 81.73 69.89
8 43.52 71.5 54.11 60.05 80.36 68.74
9 44.64 81.97 57.8 59.93 81.09 68.92
10 44.17 78.18 56.45 60.67 79.22 68.72
Avg 43.764 76.343 55.308 60.37 80.236 68.898
</table>
<tableCaption confidence="0.979363">
Table 1. NE tagging results for the two stage and four
stage models
</tableCaption>
<bodyText confidence="0.9080455">
It can be seen from Table 1 that the four stage
model outperforms the two stage model with the
</bodyText>
<equation confidence="0.808532">
(viii) R=
</equation>
<page confidence="0.992747">
67
</page>
<bodyText confidence="0.999751">
average F-Score being 55.31% for the two stage
model and 68.89% for the four stage model.
Table 2 shows the POS tagging results for stages
POSA and POSB. The POSB stage performs margi-
nally better than the POSA stage.
</bodyText>
<table confidence="0.996688384615385">
POSA Results POSB Results
Set P Set P
1 84.38 1 83.97
2 89.32 2 89.84
3 88.09 3 88.48
4 89.45 4 89.66
5 89.66 5 89.76
6 90.57 6 90.63
7 81.1 7 89.24
8 89.47 8 89.5
9 89 9 89.12
10 89.12 10 89.25
Avg 88.016 Avg 88.945
</table>
<tableCaption confidence="0.9896685">
Table 2. POS tagging results for the two stage (POSA)
and four stage (POSB) models
</tableCaption>
<bodyText confidence="0.985696933333333">
Although for POS tagging, the improvement is
not very significant between the two models, tags
like light verbs (VBLI), auxiliary verbs (AUXA
and AUXT), adjectives (JJ), demonstratives (DM)
and nouns (NN, NNC, NNCM, NNCR) get tagged
with higher accuracy in the four stage model as
shown in Table 3. This improvement becomes evi-
dent in the NE test set. Unfortunately, since this
data has no associated POS tagged ground truth,
the results cannot be quantified. The trainsetPOS
training data had very few instances of proper
nouns (NNP) occurring after case markers (CM)
and so most of the proper nouns were getting
tagged as either adjectives (JJ) or common nouns
(NN). After providing more training data to stage
POSB, the model could effectively learn proper
nouns. Spurious tagging of adjectives (JJ) and
common nouns (NN) reduced while more proper
nouns (NNP, NNPC) were tagged accurately and
this allowed the NE stage to apply its learning effi-
ciently to the NE test set thereby improving the NE
tagging results.
The two stage model tagged 238 NE tagged
words as proper nouns out of 403 NE words. The
four stage model tagged 340 NE tagged words as
proper nouns out of 403 NE words. The four stage
model shows an improvement of 25.3% over the
two stage model. The results reported for NE and
POS tagging models are without considering rules
or lexicon lookups.
</bodyText>
<table confidence="0.999649846153846">
POSA Output POSB Output
Tag FS Tag FS
AUXA 0.801 AUXA 0.816
AUXT 0.872 AUXT 0.898
DM 0.48 DM 0.521
JJ 0.751 JJ 0.765
NN 0.85 NN 0.858
NNC 0.537 NNC 0.549
NNCM 0.909 NNCM 0.923
NNCR 0.496 NNCR 0.51
RB 0.785 RB 0.834
VBLI 0.67 VBLI 0.693
VBT 0.553 VBT 0.586
</table>
<tableCaption confidence="0.999776">
Table 3. POS tagging results for stages POSA and POSB
</tableCaption>
<bodyText confidence="0.9997344">
In order to further improve the POS tagged re-
sults and NE tagged results, the rules mentioned in
sections 4.3 and 4.4 and lexicon lookups were ap-
plied. Table 4 shows the result for NE tagging with
an overall F-Score of 74.67%
</bodyText>
<table confidence="0.9129608">
NEA Output
Tag P R FS
LOCATION 0.78 0.793 0.786
ORGANIZATION 0.775 0.731 0.752
PERSON 0.894 0.595 0.714
</table>
<tableCaption confidence="0.9881765">
Table 4. NE tagging results after applying rules for test
results in Table 1
</tableCaption>
<sectionHeader confidence="0.983817" genericHeader="conclusions">
6. Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999875411764706">
This work was undertaken as a precursor to
achieve our final objective as discussed in Section
1. The basic idea here is to increase the size of the
available training data, by using bootstrapping, so
as to maximize learning for NE tagging. The pro-
posed four stage model shows an F-Score of 68.9%
for NE tagging which is much higher than that ob-
tained by the simple two stage model.
A lot of avenues remain to be explored to fur-
ther improve the performance of the model. One
approach would be to use the bootstrapping tech-
nique for NE data as well. However, the rules re-
quired can be complicated. More hand crafted rules
and detailed lexicon lookups can result in better
NE tagging. We have also noticed certain ambigui-
ties in tagging PERSON and LOCATION. Rules
that resolve this ambiguity can be explored.
</bodyText>
<page confidence="0.99916">
68
</page>
<sectionHeader confidence="0.994242" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999760241758242">
Raymond G. Gordon Jr. (ed.). 2005. Ethnologue: Lan-
guages of the World, Fifteenth edition. Dallas, TX.:
SIL International
Kashif Huda. 2001. An Overview of Urdu on the Web.
Annual of Urdu Studies Vol 20.
Zaheer Ahmad, Jehanzeb Khan Orakzai, Inam Shamsh-
er, Awais Adnan. 2007. Urdu Nastaleeq Character
Recognition. Proceedings of World Academy of
Science, Engineering and Technology. Volume 26,
ISSN 2070-3740.
John T. Platts. 1967. A grammar of the Hindustani or
Urdu language. Munshiram Manoharlal Delhi.
R. L. Schmidt. 1999. Urdu: an essential grammar.
London: Routledge.
Sarmad Hussain. 2008. Resources for Urdu Language
Processing. The 6th Workshop on Asian Language
Resources.
P. Baker, A. Hardie, T. McEnery, B.D. Jayaram. 2003.
Corpus Data for South Asian Language Processing.
Proceedings of the 10th Annual Workshop for South
Asian Language Processing, EACL.
M. Humayoun, H. Hammarstrm, A. Ranta. 2007. Urdu
Morphology, Orthography and Lexicon Extraction.
CAASL-2: The Second Workshop on Computational
Approaches to Arabic Script-based Languages, LSA
2007 Linguistic Institute, Stanford University.
Waseem Siddiqi, Shahab Alam. 2008. Online Urdu-
English and English-Urdu dictionary.
N. Durrani. 2007. Typology of Word and Automatic
Word Segmentation in Urdu Text Corpus. National
University of Computer and Emerging Sciences, La-
hore, Pakistan.
T. Theeramunkong, S. Usanavasin. 2001. Non-
Dictionary Based Thai Word Segmentation Using
decision trees. In proceedings of the First Interna-
tional Conference on Human Language Technology
Research, San Diego, California, USA.
A. Pornprasertkul. 1994. Thai Syntactic Analysis. Ph.D
Thesis, Asian Institute of Technology.
Ismat Javed. 1981.ef ودرا ��ا��. Taraqqi Urdu Bureau,
New Delhi.
Abdul M. Haq. 1987.ودرا فya و ���. Amjuman-e-
Taraqqi Urdu (Hindi).
Hassan Sajjad. 2007. Statistical Part of Speech Tagger
for Urdu. National University of Computer and
Emerging Sciences, Lahore, Pakistan.
John D. Lafferty, Andrew McCallum, Fernando C.N.
Pereira. 2001. Conditional Random Fields: Probabi-
listicModels for Segmenting and Labeling Sequence
Data. Proceedings of the Eighteenth International
Conference on Machine Learning, pp. 282-289.
John Chen. 2006. How to use Sequence Tagger. Seman-
tex Documentation, Janya Inc.
Bikel, D.M., Schwartz, R.L., Weischedel, R.M.1999.
An Algorithm that Learns What’s in a Name. Ma-
chine Learning 34(1-3), pp. 211–231.
Borthwick, A. 1999. Maximum Entropy Approach to
Named Entity Recognition. PhD thesis, New York
University.
McCallum, A., Li, W. 2003. Early results for Named
Entity Recognition with Conditional Random Fields,
Feature Induction and Web-enhanced Lexicons. In
Proceedings of CoNLL.
A. Hardie. 2003. Developing a tagset for automated
part-of-speech tagging in Urdu. Department of Lin-
guistics and Modern English Language, University
of Lancaster.
Leech, G and Wilson, A. 1999. Standards for tagsets.
Edited version of EAGLES Recommendations for the
Morphosyntactic Annotation of Corpora. In van Hal-
teren, H (ed.) Syntactic wordclass tagging. Dor-
drecht: Kluwer Academic Publishers.
Awaghad Ashish Krishnarao, Himanshu Gahlot, Amit
Srinet and D. S. Kushwaha. 2009. A Comparative
Study of Named Entity Recognition for Hindi Using
Sequential Learning Algorithms. In IEEE Interna-
tional Advance Computing Conference (IACC &apos;09),
Thapar University, India. March 6-7.
Thamar Solario. 2004. Improvement of Named Entity
Tagging by Machine Learning, Technical Report
CCC-04-004, Coordinacin de Ciencias Computatio-
nales.
Ekbal, A. and Bandyopadhyay, S. 2007. A Hidden
Markov Model Based Named Entity Recognition Sys-
tem: Bengali and Hindi as Case Studies. Springer
LNCS, Vol. 4815, pp. 545.
R. K. Srihari, W. Li, C. Niu and T. Cornell,&amp;quot;InfoXtract:
A Customizable Intermediate Level Information Ex-
traction Engine,&amp;quot; Journal of Natural Language En-
gineering, Cambridge U. Press, 14(1), 2008, pp..33-
69.
</reference>
<page confidence="0.999308">
69
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.759583">
<title confidence="0.999202">NE Tagging for Urdu based on Bootstrap POS Learning</title>
<author confidence="0.99912">Smruthi Mukund Rohini K Srihari</author>
<affiliation confidence="0.999797">Dept. of Computer Science and Engineering Dept. of Computer Science and Engineering</affiliation>
<address confidence="0.900182">University at Buffalo, SUNY University at Buffalo, SUNY Amherst, NY, USA Amherst, NY, USA</address>
<email confidence="0.999806">smukund@buffalo.edurohini@cedar.buffalo.edu</email>
<abstract confidence="0.998074153846154">Part of Speech (POS) tagging and Named Entity (NE) tagging have become important components of effective text analysis. In this paper, we propose a bootstrapped model that involves four levels of text processing for Urdu. We show that increasing the training data for POS learning by applying bootstrapping techniques improves NE tagging results. Our model overcomes the limitation imposed by the availability of limited ground truth data required for training a learning model. Both our POS tagging and NE tagging models are based on the Conditional Random Field (CRF) learning approach. To further enhance the performance, grammar rules and lexicon lookups are applied on the final output to correct any spurious tag assignments. We also propose a model for word boundary segmentation where a bigram HMM model is trained for character transitions among all positions in each word. The generated words are further processed using a probabilistic language model. All models use a hybrid approach that combines statistical models with hand crafted grammar rules.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<date>2005</date>
<booktitle>Ethnologue: Languages of the World, Fifteenth edition.</booktitle>
<publisher>SIL International</publisher>
<location>Dallas, TX.:</location>
<marker>2005</marker>
<rawString>Raymond G. Gordon Jr. (ed.). 2005. Ethnologue: Languages of the World, Fifteenth edition. Dallas, TX.: SIL International</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kashif Huda</author>
</authors>
<title>An Overview of Urdu on the Web.</title>
<date>2001</date>
<journal>Annual of Urdu Studies Vol</journal>
<volume>20</volume>
<contexts>
<context position="2989" citStr="Huda (2001)" startWordPosition="483" endWordPosition="484">s currently being developed. Articles from two leading Urdu newswires, BBC Urdu1 and Jung Daily2 form our corpus. In order to achieve our goal, it was required to generate the basic tools needed for efficient text analysis. This includes NE tagging and its precursor, POS tagging. However, Urdu, despite being spoken by over 100 million people, (Gordon, 2005) is still a less privileged language when it comes to the availability of resources on the internet. Developing tools for a language with limited resources is a challenge, but necessary, as the volume of Urdu text on the internet is rising. Huda (2001) shows that Urdu has now gained importance on the web, making it the right time to tackle these issues. It is useful to first examine some basic properties of Urdu and how they affect the cascade of NLP steps in text analysis. Urdu has the nastaleeq and nasq style of writing that is similar to Arabic 1 http://www.bbc.co.uk/urdu/ 2 http://www.jang.net/urdu/ Proceedings of CLIAWS3, Third International Cross Lingual Information Access Workshop, pages 61–69, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics and flows from right to left (Ahmad et al., 2001). It also ado</context>
</contexts>
<marker>Huda, 2001</marker>
<rawString>Kashif Huda. 2001. An Overview of Urdu on the Web. Annual of Urdu Studies Vol 20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zaheer Ahmad</author>
</authors>
<title>Jehanzeb Khan Orakzai, Inam Shamsher, Awais Adnan.</title>
<date>2007</date>
<booktitle>Proceedings of World Academy of Science, Engineering and Technology. Volume 26, ISSN</booktitle>
<pages>2070--3740</pages>
<marker>Ahmad, 2007</marker>
<rawString>Zaheer Ahmad, Jehanzeb Khan Orakzai, Inam Shamsher, Awais Adnan. 2007. Urdu Nastaleeq Character Recognition. Proceedings of World Academy of Science, Engineering and Technology. Volume 26, ISSN 2070-3740.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John T Platts</author>
</authors>
<title>A grammar of the Hindustani or Urdu language. Munshiram Manoharlal Delhi.</title>
<date>1967</date>
<marker>Platts, 1967</marker>
<rawString>John T. Platts. 1967. A grammar of the Hindustani or Urdu language. Munshiram Manoharlal Delhi.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R L Schmidt</author>
</authors>
<title>Urdu: an essential grammar.</title>
<date>1999</date>
<location>London: Routledge.</location>
<contexts>
<context position="3926" citStr="Schmidt (1999)" startWordPosition="631" endWordPosition="632">k/urdu/ 2 http://www.jang.net/urdu/ Proceedings of CLIAWS3, Third International Cross Lingual Information Access Workshop, pages 61–69, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics and flows from right to left (Ahmad et al., 2001). It also adopts some of its vocabulary from Arabic. However, the grammar and semantics of the language is similar to Hindi and this makes it very different from Arabic. For effective text analysis, a thorough syntactic and semantic understanding of the language is required. Detailed grammatical analysis provided by Platts (1909) and Schmidt (1999) can be used for this purpose. The first step in the information retrieval pipeline is tokenization. Unlike English, where the word delimiter is mostly a space, Urdu is more complex. There are space insertion as well as space deletion problems. This makes tokenization a difficult task. The word segmentation model that we propose here combines the statistical approach that considers bigram transition of characters based on their positions in a word and morphological rules with lexicon lookups. POS tagging comes next in the NLP text analysis pipeline. The accuracy of the tagging model varies, de</context>
</contexts>
<marker>Schmidt, 1999</marker>
<rawString>R. L. Schmidt. 1999. Urdu: an essential grammar. London: Routledge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sarmad Hussain</author>
</authors>
<title>Resources for Urdu Language Processing. The 6th Workshop on Asian Language Resources.</title>
<date>2008</date>
<contexts>
<context position="6934" citStr="Hussain (2008)" startWordPosition="1136" endWordPosition="1137">ncludes the paper. In each section, wherever relevant, previous work and drawbacks are presented. 2 Resources Based on the style of writing for Urdu, different encoding standards have been proposed. Urdu Zabta Takthi - the national standard code page for Urdu and Unicode - international standard for multilingual characters are the two proposed and widely used encoding standards. BBC Urdu and Jung Daily are both encoded with Unicode standards and are good sources of data. The availability of online resources for Urdu is not as extensive as other Asian languages like Chinese and Hindi. However, Hussain (2008) has done a good job in assimilating most of the resources available on the internet. The lexicon provided as a part of the EMILLE (2003) data set for Urdu has about 200,000 words. CRL5 has released a lexicon of 8000 words as a part of their Urdu data collection. They also provide an NE tagged data set mostly used for morphological analysis. The lexicon includes POS information as well. CRULP6 has also provided a lexicon of 149,466 words that contains places, organizations and names of people. As part of the Urdu morphological analyzer provided by Humayoun (2007), a lexicon of about 4,500 uniq</context>
</contexts>
<marker>Hussain, 2008</marker>
<rawString>Sarmad Hussain. 2008. Resources for Urdu Language Processing. The 6th Workshop on Asian Language Resources.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Baker</author>
<author>A Hardie</author>
<author>T McEnery</author>
<author>B D Jayaram</author>
</authors>
<title>Corpus Data for South Asian Language Processing.</title>
<date>2003</date>
<booktitle>Proceedings of the 10th Annual Workshop for South Asian Language Processing, EACL.</booktitle>
<marker>Baker, Hardie, McEnery, Jayaram, 2003</marker>
<rawString>P. Baker, A. Hardie, T. McEnery, B.D. Jayaram. 2003. Corpus Data for South Asian Language Processing. Proceedings of the 10th Annual Workshop for South Asian Language Processing, EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Humayoun</author>
<author>H Hammarstrm</author>
<author>A Ranta</author>
</authors>
<title>Urdu Morphology, Orthography and Lexicon Extraction.</title>
<date>2007</date>
<booktitle>CAASL-2: The Second Workshop on Computational Approaches to Arabic Script-based Languages, LSA</booktitle>
<institution>Linguistic Institute, Stanford University.</institution>
<marker>Humayoun, Hammarstrm, Ranta, 2007</marker>
<rawString>M. Humayoun, H. Hammarstrm, A. Ranta. 2007. Urdu Morphology, Orthography and Lexicon Extraction. CAASL-2: The Second Workshop on Computational Approaches to Arabic Script-based Languages, LSA 2007 Linguistic Institute, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Waseem Siddiqi</author>
<author>Shahab Alam</author>
</authors>
<date>2008</date>
<booktitle>Online UrduEnglish and English-Urdu dictionary.</booktitle>
<marker>Siddiqi, Alam, 2008</marker>
<rawString>Waseem Siddiqi, Shahab Alam. 2008. Online UrduEnglish and English-Urdu dictionary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Durrani</author>
</authors>
<title>Typology of Word and Automatic Word Segmentation in</title>
<date>2007</date>
<institution>Urdu Text Corpus. National University of Computer and Emerging Sciences,</institution>
<location>Lahore, Pakistan.</location>
<contexts>
<context position="8781" citStr="Durrani (2007)" startWordPosition="1426" endWordPosition="1427">ities in Pakistan were also compiled using the Urdu-Wikipedia8 and NationalMaster9. A list of most common names in Pakistan was composed by retrieving data from the various name databases available on the internet. The word segmentation model uses the Urdu corpus released by CRULP as the training data. This dataset is well segmented. POS tagging model uses data provided by CRULP and NE tagging model uses data provided by CRL. 3 Word Segmentation and Tokenization Urdu is a language that has both the space insertion and space deletion problems. The Urdu word segmentation problem as mentioned by Durrani (2007) is triggered by its orthographic rules and confusions about the definition of a word. Durrani summarizes effectively, all the problems associated with Urdu word segmentation. Of all the different techniques explored to achieve this objective, traditional techniques like longest and maximum matching depend mostly on the availability of a lexicon that holds all the morphological forms of a word. Such a lexicon is difficult to obtain. It is shown by Theeramunkong et al., (2001), that for a Thai segmentation system, the efficiency drops considerably (from 97% to 82%) making this approach highly l</context>
<context position="10256" citStr="Durrani (2007)" startWordPosition="1647" endWordPosition="1648">s overcome the limitations of statistical models by considering the context around the word for specific words and collocations. There are other models that generate segments by considering word level collation as well as syllable level collocation. However, for a language like Urdu, a model that is purely statistical will fail to yield good segmentation results. A mixed model that considers the morphological as well as semantic features of the 7 http://www.janyainc.com/ 8 http://ur.wikipedia.com/wiki/ 9 http://www.nationmaster.com/index.php language facilitates better performance as shown by Durrani (2007) where the word segmentation model uses a lexicon for proper nouns and a statistical model that trains over the n-gram probability of morphemes. Maximum matching technique is used to generate word boundaries of the orthographic words that are formed and these are later verified using the POS information. The segments thus generated are ranked and the best ones are accepted. Statistical models that consider character based, syllable based and word based probabilities have shown to perform reasonably well. The Thai segmentation problem was solved by Pornprasertkul (1994) using the character base</context>
</contexts>
<marker>Durrani, 2007</marker>
<rawString>N. Durrani. 2007. Typology of Word and Automatic Word Segmentation in Urdu Text Corpus. National University of Computer and Emerging Sciences, Lahore, Pakistan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Theeramunkong</author>
<author>S Usanavasin</author>
</authors>
<title>NonDictionary Based Thai Word Segmentation Using decision trees.</title>
<date>2001</date>
<booktitle>In proceedings of the First International Conference on Human Language Technology Research,</booktitle>
<location>San Diego, California, USA.</location>
<marker>Theeramunkong, Usanavasin, 2001</marker>
<rawString>T. Theeramunkong, S. Usanavasin. 2001. NonDictionary Based Thai Word Segmentation Using decision trees. In proceedings of the First International Conference on Human Language Technology Research, San Diego, California, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Pornprasertkul</author>
</authors>
<title>Thai Syntactic Analysis.</title>
<date>1994</date>
<tech>Ph.D Thesis,</tech>
<institution>Asian Institute of Technology.</institution>
<contexts>
<context position="10831" citStr="Pornprasertkul (1994)" startWordPosition="1736" endWordPosition="1738"> better performance as shown by Durrani (2007) where the word segmentation model uses a lexicon for proper nouns and a statistical model that trains over the n-gram probability of morphemes. Maximum matching technique is used to generate word boundaries of the orthographic words that are formed and these are later verified using the POS information. The segments thus generated are ranked and the best ones are accepted. Statistical models that consider character based, syllable based and word based probabilities have shown to perform reasonably well. The Thai segmentation problem was solved by Pornprasertkul (1994) using the character based approach. In our model, we use a combination of character based statistical approach and grammar rules with lexicon lookups to generate word boundaries. Urdu segmentation problem can be looked at as an issue of inserting spaces between characters. All letters in Urdu, with a few exceptions, have three forms - initial, medial and final. (We do not consider the detached form for word formation). Words are written by joining the letters together and based on the position of the letter in the word, suitable forms are applied. This property of word formation is the crux o</context>
</contexts>
<marker>Pornprasertkul, 1994</marker>
<rawString>A. Pornprasertkul. 1994. Thai Syntactic Analysis. Ph.D Thesis, Asian Institute of Technology.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ismat Javed</author>
</authors>
<title>1981.ef ودرا ��ا��. Taraqqi Urdu Bureau,</title>
<location>New Delhi.</location>
<marker>Javed, </marker>
<rawString>Ismat Javed. 1981.ef ودرا ��ا��. Taraqqi Urdu Bureau, New Delhi.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abdul M Haq</author>
</authors>
<title>ya و ���. Amjuman-eTaraqqi Urdu (Hindi).</title>
<date>1987</date>
<marker>Haq, 1987</marker>
<rawString>Abdul M. Haq. 1987.ودرا فya و ���. Amjuman-eTaraqqi Urdu (Hindi).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hassan Sajjad</author>
</authors>
<title>Statistical Part of Speech Tagger for Urdu.</title>
<date>2007</date>
<institution>National University of Computer and Emerging Sciences,</institution>
<location>Lahore, Pakistan.</location>
<marker>Sajjad, 2007</marker>
<rawString>Hassan Sajjad. 2007. Statistical Part of Speech Tagger for Urdu. National University of Computer and Emerging Sciences, Lahore, Pakistan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Conditional Random Fields: ProbabilisticModels for Segmenting and Labeling Sequence Data.</title>
<date>2001</date>
<booktitle>Proceedings of the Eighteenth International Conference on Machine Learning,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="16125" citStr="Lafferty et al., (2001)" startWordPosition="2639" endWordPosition="2642">at to assure uniqueness. This involves considerable amount of work and hence, in order to prevent the propagation of error into the NLP text analysis pipeline, we decided to test our subsequent models using pre-segmented data, independent of our word segmentation model. 4 Learning Approaches A Conditional Random Field (CRF), is an undirected graphical model used for sequential learning. The tasks of POS tagging and NE tagging are both sequential learning tasks and hence this learning approach is a reasonable choice. What follows is a brief outline about CRF. Interested readers are referred to Lafferty et al., (2001), for more information on CRF. (vi) ws � max � I � I� I � � I � 64 A linear chain CRF defines a single log-linear probabilistic distribution over the possible tag sequences y for a sentence x p(y |x) = Z1 exp where fk(t, yt, yt-1, xt) is typically a binary function indicating the presence of feature k, λk is the weight of the feature, and Z(x) is a normalization function. T K Z(x) exp = ∑ ∑∑ λk fk (t, yt , yt−1 , xt y t=1 k=1 This modeling allows us to define features on states (the POS/NE tags) and edges (pairs of adjacent POS/NE tags) combined with observations (eg. words and POS tags for NE</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John D. Lafferty, Andrew McCallum, Fernando C.N. Pereira. 2001. Conditional Random Fields: ProbabilisticModels for Segmenting and Labeling Sequence Data. Proceedings of the Eighteenth International Conference on Machine Learning, pp. 282-289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Chen</author>
</authors>
<title>How to use Sequence Tagger. Semantex Documentation,</title>
<date>2006</date>
<publisher>Janya Inc.</publisher>
<marker>Chen, 2006</marker>
<rawString>John Chen. 2006. How to use Sequence Tagger. Semantex Documentation, Janya Inc.</rawString>
</citation>
<citation valid="false">
<authors>
<author>D M Bikel</author>
<author>R L Schwartz</author>
<author>R M 1999 Weischedel</author>
</authors>
<title>An Algorithm that Learns What’s in a Name.</title>
<journal>Machine Learning</journal>
<volume>34</volume>
<issue>1</issue>
<pages>211--231</pages>
<marker>Bikel, Schwartz, Weischedel, </marker>
<rawString>Bikel, D.M., Schwartz, R.L., Weischedel, R.M.1999. An Algorithm that Learns What’s in a Name. Machine Learning 34(1-3), pp. 211–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Borthwick</author>
</authors>
<title>Maximum Entropy Approach to Named Entity Recognition.</title>
<date>1999</date>
<tech>PhD thesis,</tech>
<institution>New York University.</institution>
<contexts>
<context position="18377" citStr="Borthwick, 1999" startWordPosition="3018" endWordPosition="3019">10 http://crfpp.sourceforge.net/ 11 http://www.mcs.anl.gov/index.php style of writing from Arabic. Also, the requirement for such models to work well is the availability of large training data. Building NE recognizers for languages like Urdu is difficult as there are no concepts like capitalization of characters. Also, most names of people have specific meanings associated with them and can easily be found in a dictionary with different associated meanings. Various learning approaches have been proposed for this task, HMM based learning approach (Bikel et al., 1999), Maximum Entropy Approach (Borthwick, 1999) and CRF approach (McCallum, 2003) are the most popular. Ashish et al., (2009) show an SVM based approach also works well for such tasks. To overcome the problem of limited data availability, we present a method to increase the amount of training data that is available, by using a technique called bootstrapping. We do not have a training corpus that is manually tagged for both POS and NE. Our training data consists of two different datasets. The dataset used for POS tagging is provided by CRULP and is tagged using their tagset. The dataset used for NE tagging is provided by CRL as a part of th</context>
</contexts>
<marker>Borthwick, 1999</marker>
<rawString>Borthwick, A. 1999. Maximum Entropy Approach to Named Entity Recognition. PhD thesis, New York University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
<author>W Li</author>
</authors>
<title>Early results for Named Entity Recognition with Conditional Random Fields, Feature Induction and Web-enhanced Lexicons.</title>
<date>2003</date>
<booktitle>In Proceedings of CoNLL.</booktitle>
<marker>McCallum, Li, 2003</marker>
<rawString>McCallum, A., Li, W. 2003. Early results for Named Entity Recognition with Conditional Random Fields, Feature Induction and Web-enhanced Lexicons. In Proceedings of CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Hardie</author>
</authors>
<title>Developing a tagset for automated part-of-speech tagging in Urdu.</title>
<date>2003</date>
<institution>Department of Linguistics and Modern English Language, University of Lancaster.</institution>
<contexts>
<context position="4690" citStr="Hardie 2003" startWordPosition="759" endWordPosition="760">a space, Urdu is more complex. There are space insertion as well as space deletion problems. This makes tokenization a difficult task. The word segmentation model that we propose here combines the statistical approach that considers bigram transition of characters based on their positions in a word and morphological rules with lexicon lookups. POS tagging comes next in the NLP text analysis pipeline. The accuracy of the tagging model varies, depending on the tagsets used and the domain of the ground truth data. There are two main tagsets designed for Urdu, the CRULP tagset3 and the U1-tagset (Hardie 2003). The U1-tagset, released as a part of EMILLE4 corpus, is based on the EAGLES standards (Leech and Wilson 1999). We decided to use the standards proposed by CRULP for the following reasons. 1. The tagset, though not as detailed as the one proposed in U1-tagset, covers all the basic requirements needed to achieve our final goal. 2. The tagged corpus provided by CRULP is newswire material, similar to our final corpus. A person, when asked to identify an NE tagged word in a sentence would typically try to first find the word associated with a proper noun or a noun, and then assign a suitable NE t</context>
</contexts>
<marker>Hardie, 2003</marker>
<rawString>A. Hardie. 2003. Developing a tagset for automated part-of-speech tagging in Urdu. Department of Linguistics and Modern English Language, University of Lancaster.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Leech</author>
<author>A Wilson</author>
</authors>
<title>Standards for tagsets. Edited version of EAGLES Recommendations for the Morphosyntactic Annotation of Corpora. In</title>
<date>1999</date>
<booktitle>Syntactic wordclass tagging.</booktitle>
<editor>van Halteren, H (ed.)</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<location>Dordrecht:</location>
<contexts>
<context position="4801" citStr="Leech and Wilson 1999" startWordPosition="777" endWordPosition="780">es tokenization a difficult task. The word segmentation model that we propose here combines the statistical approach that considers bigram transition of characters based on their positions in a word and morphological rules with lexicon lookups. POS tagging comes next in the NLP text analysis pipeline. The accuracy of the tagging model varies, depending on the tagsets used and the domain of the ground truth data. There are two main tagsets designed for Urdu, the CRULP tagset3 and the U1-tagset (Hardie 2003). The U1-tagset, released as a part of EMILLE4 corpus, is based on the EAGLES standards (Leech and Wilson 1999). We decided to use the standards proposed by CRULP for the following reasons. 1. The tagset, though not as detailed as the one proposed in U1-tagset, covers all the basic requirements needed to achieve our final goal. 2. The tagged corpus provided by CRULP is newswire material, similar to our final corpus. A person, when asked to identify an NE tagged word in a sentence would typically try to first find the word associated with a proper noun or a noun, and then assign a suitable NE tag based on the context. A similar approach is used in our model, where the learning happens on the data that i</context>
</contexts>
<marker>Leech, Wilson, 1999</marker>
<rawString>Leech, G and Wilson, A. 1999. Standards for tagsets. Edited version of EAGLES Recommendations for the Morphosyntactic Annotation of Corpora. In van Halteren, H (ed.) Syntactic wordclass tagging. Dordrecht: Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Awaghad Ashish Krishnarao</author>
<author>Himanshu Gahlot</author>
<author>Amit Srinet</author>
<author>D S Kushwaha</author>
</authors>
<title>A Comparative Study of Named Entity Recognition for Hindi Using Sequential Learning Algorithms.</title>
<date>2009</date>
<booktitle>In IEEE International Advance Computing Conference (IACC &apos;09),</booktitle>
<pages>6--7</pages>
<institution>Thapar University, India.</institution>
<marker>Krishnarao, Gahlot, Srinet, Kushwaha, 2009</marker>
<rawString>Awaghad Ashish Krishnarao, Himanshu Gahlot, Amit Srinet and D. S. Kushwaha. 2009. A Comparative Study of Named Entity Recognition for Hindi Using Sequential Learning Algorithms. In IEEE International Advance Computing Conference (IACC &apos;09), Thapar University, India. March 6-7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thamar Solario</author>
</authors>
<title>Improvement of Named Entity Tagging by Machine Learning,</title>
<date>2004</date>
<tech>Technical Report CCC-04-004, Coordinacin de Ciencias Computationales.</tech>
<marker>Solario, 2004</marker>
<rawString>Thamar Solario. 2004. Improvement of Named Entity Tagging by Machine Learning, Technical Report CCC-04-004, Coordinacin de Ciencias Computationales.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ekbal</author>
<author>S Bandyopadhyay</author>
</authors>
<title>A Hidden Markov Model Based Named Entity Recognition System:</title>
<date>2007</date>
<booktitle>Bengali and Hindi as Case Studies. Springer LNCS,</booktitle>
<volume>4815</volume>
<pages>545</pages>
<marker>Ekbal, Bandyopadhyay, 2007</marker>
<rawString>Ekbal, A. and Bandyopadhyay, S. 2007. A Hidden Markov Model Based Named Entity Recognition System: Bengali and Hindi as Case Studies. Springer LNCS, Vol. 4815, pp. 545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R K Srihari</author>
<author>W Li</author>
<author>C Niu</author>
<author>T Cornell</author>
<author>InfoXtract</author>
</authors>
<title>A Customizable Intermediate Level Information Extraction Engine,&amp;quot;</title>
<date>2008</date>
<journal>Journal of Natural Language Engineering, Cambridge U. Press,</journal>
<volume>14</volume>
<issue>1</issue>
<pages>33--69</pages>
<marker>Srihari, Li, Niu, Cornell, InfoXtract, 2008</marker>
<rawString>R. K. Srihari, W. Li, C. Niu and T. Cornell,&amp;quot;InfoXtract: A Customizable Intermediate Level Information Extraction Engine,&amp;quot; Journal of Natural Language Engineering, Cambridge U. Press, 14(1), 2008, pp..33-69.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>