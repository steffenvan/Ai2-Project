<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.118927">
<title confidence="0.976862">
Linguistic Knowledge and Question Answering
</title>
<author confidence="0.992148">
Gosse Bouma
</author>
<affiliation confidence="0.9928505">
Information Science
Groningen University
</affiliation>
<email confidence="0.99609">
{g.bouma}@rug.nl
</email>
<sectionHeader confidence="0.995588" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999853833333333">
The availability of robust and deep syntac-
tic parsing can improve the performance
of Question Answering systems. This is
illustrated using examples from Joost, a
Dutch QA system which has been used for
both open (CLEF) and closed domain QA.
</bodyText>
<sectionHeader confidence="0.835474" genericHeader="method">
1 Linguistically Informed IR
</sectionHeader>
<bodyText confidence="0.9997065">
Information retrieval is used in most QA systems
to filter out relevant passages from large docu-
ment collections to narrow down the search for an-
swer extraction modules in a QA system. Given
a full syntactic analysis of the text collection, it
becomes feasible to exploit linguistic information
as a knowledge source for IR. Using Apache’s IR
system Lucene, we can index the document col-
lection along various linguistic dimensions, such
as part of speech tags, named entity classes, and
dependency relations. Tiedemann (2005) uses a
genetic algorithm to optimize the use of such an
extended IR index, and shows that it leads to sig-
nificant improvements of IR performance.
</bodyText>
<subsectionHeader confidence="0.523763">
2 Acquisition of Lexical Knowledge
</subsectionHeader>
<bodyText confidence="0.9963298">
Syntactic similarity measures can be used for au-
tomatic acquisition of lexical knowledge required
for QA, as well as for answer extraction and rank-
ing. For instance, in van der Plas and Bouma
(2005) it is shown that automatically acquired
class-labels for named entities improve the ac-
curacy of answering general WH-questions (i.e.
Which ferry sank in the Baltic Sea?) and questions
which ask for the definition of a named entity (i.e.
Who is Nelson Mandela? or What is MTV?).
</bodyText>
<sectionHeader confidence="0.961687" genericHeader="method">
3 Off-line answer extraction
</sectionHeader>
<bodyText confidence="0.999879681818182">
Off-line extraction of answers to frequent ques-
tion types can be based on dependency patterns
and coreference resolution (Bouma et al., 2005;
Mur and van der Plas, 2006), leading to higher
recall (compared to systems using surface pat-
terns). Closed-domain (medical) QA can bene-
fit from the fact that dependency relations allow
answers to be identified for questions which are
not restricted to specific named entity classes, i.e.
definitions, causes, symptoms, etc. Answering
definition questions, for instance, is a task which
has motivated approaches that go well beyond the
techniques used for answering factoid questions.
In Fahmi and Bouma (2006) it is shown that syn-
tactic patterns can be used to extract potential def-
inition sentences from Wikipedia, and that syn-
tactic features of these sentences (in combination
with obvious clues such as the position of the sen-
tence in the document) can be used to improve the
accuracy of an automatic classifier which distin-
guishes definitions from non-definitions in the ex-
tracted data set.
</bodyText>
<sectionHeader confidence="0.997734" genericHeader="method">
4 Joost
</sectionHeader>
<bodyText confidence="0.999815916666667">
Joost is a QA system for Dutch which incorporates
the features mentioned above, using the Alpino
parser for Dutch to parse (offline) the document
collections as well as (interactively) user ques-
tions. It has been used for the open-domain mono-
lingual QA task of CLEF 2005, as well as for
closed domain medical QA. For CLEF, the full
Dutch text collection (4 years of newspaper text,
approximately 80 million words) has been parsed.
For the medical QA system, we have been using
a mixture of texts from general and medical ency-
clopedia, medical reference works, and web pages
</bodyText>
<page confidence="0.39712">
2 KRAQ06
</page>
<bodyText confidence="0.9997458">
dedicated to medical topics. The medical data are
from mixed sources and contain a fair amount of
domain specific terminology. Although the Alpino
system is robust enough to deal with such material,
we believe that the accuracy of linguistic analysis
on this task can be further improved by incorporat-
ing domain specific terminological resources. We
are currently investigating methods for acquiring
such knowledge automatically from the encyclo-
pedia sources.
</bodyText>
<sectionHeader confidence="0.998412" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999185608695652">
Gosse Bouma, Jori Mur, and Gertjan van Noord. 2005.
Reasoning over dependency relations for QA. In
Proceedings of the IJCAI workshop on Knowledge
and Reasoning for Answering Questions (KRAQ),
pages 15–21, Edinburgh.
Ismail Fahmi and Gosse Bouma. 2006. Learning
to identify definitions using syntactic features. In
Roberto Basili and Alessandro Moschitti, editors,
Proceedings of the EACL workshop on Learning
Structured Information in Natural Language Appli-
cations, Trento, Italy.
Jori Mur and Lonneke van der Plas. 2006. Anaphora
resolution for off-line answer extraction using in-
stances. submitted.
J¨org Tiedemann. 2005. Integrating linguistic knowl-
edge in passage retrieval for question answering. In
Proceedings of EMNLP 2005, pages 939–946, Van-
couver.
Lonneke van der Plas and Gosse Bouma. 2005. Auto-
matic acquisition of lexico-semantic knowledge for
question answering. In Proceedings of Ontolex 2005
– Ontologies and Lexical Resources, Jeju Island,
South Korea.
</reference>
<page confidence="0.783607">
3 KRAQ06
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.013309">
<title confidence="0.813512666666667">Linguistic Knowledge and Question Answering Gosse Information</title>
<author confidence="0.49446">Groningen</author>
<abstract confidence="0.9994958375">The availability of robust and deep syntactic parsing can improve the performance of Question Answering systems. This is illustrated using examples from Joost, a Dutch QA system which has been used for both open (CLEF) and closed domain QA. 1 Linguistically Informed IR Information retrieval is used in most QA systems to filter out relevant passages from large document collections to narrow down the search for answer extraction modules in a QA system. Given a full syntactic analysis of the text collection, it becomes feasible to exploit linguistic information as a knowledge source for IR. Using Apache’s IR system Lucene, we can index the document collection along various linguistic dimensions, such as part of speech tags, named entity classes, and dependency relations. Tiedemann (2005) uses a genetic algorithm to optimize the use of such an extended IR index, and shows that it leads to significant improvements of IR performance. 2 Acquisition of Lexical Knowledge Syntactic similarity measures can be used for automatic acquisition of lexical knowledge required for QA, as well as for answer extraction and ranking. For instance, in van der Plas and Bouma (2005) it is shown that automatically acquired class-labels for named entities improve the acof answering general (i.e. ferry sank in the Baltic and questions which ask for the definition of a named entity (i.e. is Nelson Mandela? is 3 Off-line answer extraction Off-line extraction of answers to frequent question types can be based on dependency patterns and coreference resolution (Bouma et al., 2005; Mur and van der Plas, 2006), leading to higher recall (compared to systems using surface patterns). Closed-domain (medical) QA can benefit from the fact that dependency relations allow answers to be identified for questions which are not restricted to specific named entity classes, i.e. definitions, causes, symptoms, etc. Answering definition questions, for instance, is a task which has motivated approaches that go well beyond the techniques used for answering factoid questions. In Fahmi and Bouma (2006) it is shown that syntactic patterns can be used to extract potential definition sentences from Wikipedia, and that syntactic features of these sentences (in combination with obvious clues such as the position of the sentence in the document) can be used to improve the accuracy of an automatic classifier which distinguishes definitions from non-definitions in the extracted data set. 4 Joost Joost is a QA system for Dutch which incorporates the features mentioned above, using the Alpino parser for Dutch to parse (offline) the document collections as well as (interactively) user questions. It has been used for the open-domain monolingual QA task of CLEF 2005, as well as for closed domain medical QA. For CLEF, the full Dutch text collection (4 years of newspaper text, approximately 80 million words) has been parsed. For the medical QA system, we have been using a mixture of texts from general and medical encyclopedia, medical reference works, and web pages 2 KRAQ06 dedicated to medical topics. The medical data are from mixed sources and contain a fair amount of domain specific terminology. Although the Alpino system is robust enough to deal with such material, we believe that the accuracy of linguistic analysis on this task can be further improved by incorporating domain specific terminological resources. We are currently investigating methods for acquiring such knowledge automatically from the encyclopedia sources.</abstract>
<note confidence="0.975703166666667">References Gosse Bouma, Jori Mur, and Gertjan van Noord. 2005. Reasoning over dependency relations for QA. In Proceedings of the IJCAI workshop on Knowledge Reasoning for Answering Questions pages 15–21, Edinburgh.</note>
<author confidence="0.433264">Learning to identify definitions using syntactic features In Roberto Basili</author>
<author confidence="0.433264">Alessandro Moschitti</author>
<author confidence="0.433264">editors</author>
<affiliation confidence="0.800774">Proceedings of the EACL workshop on Learning Structured Information in Natural Language Appli-</affiliation>
<address confidence="0.905266">Trento, Italy.</address>
<author confidence="0.541975">Anaphora</author>
<abstract confidence="0.905266818181818">resolution for off-line answer extraction using instances. submitted. J¨org Tiedemann. 2005. Integrating linguistic knowledge in passage retrieval for question answering. In of EMNLP pages 939–946, Vancouver. Lonneke van der Plas and Gosse Bouma. 2005. Automatic acquisition of lexico-semantic knowledge for answering. In of Ontolex 2005 Ontologies and Lexical Jeju Island, South Korea.</abstract>
<intro confidence="0.690549">3 KRAQ06</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Gosse Bouma</author>
<author>Jori Mur</author>
<author>Gertjan van Noord</author>
</authors>
<title>Reasoning over dependency relations for QA.</title>
<date>2005</date>
<booktitle>In Proceedings of the IJCAI workshop on Knowledge and Reasoning for Answering Questions (KRAQ),</booktitle>
<pages>15--21</pages>
<location>Edinburgh.</location>
<marker>Bouma, Mur, van Noord, 2005</marker>
<rawString>Gosse Bouma, Jori Mur, and Gertjan van Noord. 2005. Reasoning over dependency relations for QA. In Proceedings of the IJCAI workshop on Knowledge and Reasoning for Answering Questions (KRAQ), pages 15–21, Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ismail Fahmi</author>
<author>Gosse Bouma</author>
</authors>
<title>Learning to identify definitions using syntactic features.</title>
<date>2006</date>
<booktitle>In Roberto Basili and Alessandro Moschitti, editors, Proceedings of the EACL workshop on Learning Structured Information in Natural Language Applications,</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="2257" citStr="Fahmi and Bouma (2006)" startWordPosition="352" endWordPosition="355">s to frequent question types can be based on dependency patterns and coreference resolution (Bouma et al., 2005; Mur and van der Plas, 2006), leading to higher recall (compared to systems using surface patterns). Closed-domain (medical) QA can benefit from the fact that dependency relations allow answers to be identified for questions which are not restricted to specific named entity classes, i.e. definitions, causes, symptoms, etc. Answering definition questions, for instance, is a task which has motivated approaches that go well beyond the techniques used for answering factoid questions. In Fahmi and Bouma (2006) it is shown that syntactic patterns can be used to extract potential definition sentences from Wikipedia, and that syntactic features of these sentences (in combination with obvious clues such as the position of the sentence in the document) can be used to improve the accuracy of an automatic classifier which distinguishes definitions from non-definitions in the extracted data set. 4 Joost Joost is a QA system for Dutch which incorporates the features mentioned above, using the Alpino parser for Dutch to parse (offline) the document collections as well as (interactively) user questions. It ha</context>
</contexts>
<marker>Fahmi, Bouma, 2006</marker>
<rawString>Ismail Fahmi and Gosse Bouma. 2006. Learning to identify definitions using syntactic features. In Roberto Basili and Alessandro Moschitti, editors, Proceedings of the EACL workshop on Learning Structured Information in Natural Language Applications, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jori Mur</author>
<author>Lonneke van der Plas</author>
</authors>
<title>Anaphora resolution for off-line answer extraction using instances.</title>
<date>2006</date>
<note>submitted.</note>
<marker>Mur, van der Plas, 2006</marker>
<rawString>Jori Mur and Lonneke van der Plas. 2006. Anaphora resolution for off-line answer extraction using instances. submitted.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Tiedemann</author>
</authors>
<title>Integrating linguistic knowledge in passage retrieval for question answering.</title>
<date>2005</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<pages>939--946</pages>
<location>Vancouver.</location>
<contexts>
<context position="918" citStr="Tiedemann (2005)" startWordPosition="139" endWordPosition="140">hich has been used for both open (CLEF) and closed domain QA. 1 Linguistically Informed IR Information retrieval is used in most QA systems to filter out relevant passages from large document collections to narrow down the search for answer extraction modules in a QA system. Given a full syntactic analysis of the text collection, it becomes feasible to exploit linguistic information as a knowledge source for IR. Using Apache’s IR system Lucene, we can index the document collection along various linguistic dimensions, such as part of speech tags, named entity classes, and dependency relations. Tiedemann (2005) uses a genetic algorithm to optimize the use of such an extended IR index, and shows that it leads to significant improvements of IR performance. 2 Acquisition of Lexical Knowledge Syntactic similarity measures can be used for automatic acquisition of lexical knowledge required for QA, as well as for answer extraction and ranking. For instance, in van der Plas and Bouma (2005) it is shown that automatically acquired class-labels for named entities improve the accuracy of answering general WH-questions (i.e. Which ferry sank in the Baltic Sea?) and questions which ask for the definition of a n</context>
</contexts>
<marker>Tiedemann, 2005</marker>
<rawString>J¨org Tiedemann. 2005. Integrating linguistic knowledge in passage retrieval for question answering. In Proceedings of EMNLP 2005, pages 939–946, Vancouver.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lonneke van der Plas</author>
<author>Gosse Bouma</author>
</authors>
<title>Automatic acquisition of lexico-semantic knowledge for question answering.</title>
<date>2005</date>
<booktitle>In Proceedings of Ontolex 2005 – Ontologies and Lexical Resources,</booktitle>
<location>Jeju Island, South</location>
<marker>van der Plas, Bouma, 2005</marker>
<rawString>Lonneke van der Plas and Gosse Bouma. 2005. Automatic acquisition of lexico-semantic knowledge for question answering. In Proceedings of Ontolex 2005 – Ontologies and Lexical Resources, Jeju Island, South Korea.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>