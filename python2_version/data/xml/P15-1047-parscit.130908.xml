<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.9995655">
Matrix Factorization with Knowledge Graph Propagation
for Unsupervised Spoken Language Understanding
</title>
<author confidence="0.998871">
Yun-Nung Chen, William Yang Wang, Anatole Gershman, and Alexander I. Rudnicky
</author>
<affiliation confidence="0.8524005">
School of Computer Science, Carnegie Mellon University
5000 Forbes Aveue, Pittsburgh, PA 15213-3891, USA
</affiliation>
<email confidence="0.992048">
{yvchen, yww, anatoleg, air}@cs.cmu.edu
</email>
<sectionHeader confidence="0.99731" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999896964285714">
Spoken dialogue systems (SDS) typically
require a predefined semantic ontology
to train a spoken language understanding
(SLU) module. In addition to the anno-
tation cost, a key challenge for design-
ing such an ontology is to define a coher-
ent slot set while considering their com-
plex relations. This paper introduces a
novel matrix factorization (MF) approach
to learn latent feature vectors for utter-
ances and semantic elements without the
need of corpus annotations. Specifically,
our model learns the semantic slots for a
domain-specific SDS in an unsupervised
fashion, and carries out semantic pars-
ing using latent MF techniques. To fur-
ther consider the global semantic struc-
ture, such as inter-word and inter-slot re-
lations, we augment the latent MF-based
model with a knowledge graph propaga-
tion model based on a slot-based seman-
tic graph and a word-based lexical graph.
Our experiments show that the proposed
MF approaches produce better SLU mod-
els that are able to predict semantic slots
and word patterns taking into account their
relations and domain-specificity in a joint
manner.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999963222222222">
A key component of a spoken dialogue sys-
tem (SDS) is the spoken language understand-
ing (SLU) module—it parses the users’ utterances
into semantic representations; for example, the ut-
terance “find a cheap restaurant” can be parsed
into (price=cheap, target=restaurant) (Pieraccini
et al., 1992). To design the SLU module of a SDS,
most previous studies relied on predefined slots1
for training the decoder (Seneff, 1992; Dowding
</bodyText>
<footnote confidence="0.743595">
1A slot is defined as a basic semantic unit in SLU, such as
“price” and “target” in the example.
</footnote>
<bodyText confidence="0.999959604651163">
et al., 1993; Gupta et al., 2006; Bohus and Rud-
nicky, 2009). However, these predefined semantic
slots may bias the subsequent data collection pro-
cess, and the cost of manually labeling utterances
for updating the ontology is expensive (Wang et
al., 2012).
In recent years, this problem led to the devel-
opment of unsupervised SLU techniques (Heck
and Hakkani-T¨ur, 2012; Heck et al., 2013; Chen
et al., 2013b; Chen et al., 2014b). In particular,
Chen et al. (2013b) proposed a frame-semantics
based framework for automatically inducing se-
mantic slots given raw audios. However, these ap-
proaches generally do not explicitly learn the la-
tent factor representations to model the measure-
ment errors (Skrondal and Rabe-Hesketh, 2004),
nor do they jointly consider the complex lexical,
syntactic, and semantic relations among words,
slots, and utterances.
Another challenge of SLU is the inference of
the hidden semantics. Considering the user utter-
ance “can i have a cheap restaurant”, from its sur-
face patterns, we can see that it includes explicit
semantic information about “price (cheap)” and
“target (restaurant)”; however, it also includes
hidden semantic information, such as “food” and
“seeking”, since the SDS needs to infer that the
user wants to “find” some cheap “food”, even
though they are not directly observed in the sur-
face patterns. Nonetheless, these implicit seman-
tics are important semantic concepts for domain-
specific SDSs. Traditional SLU models use dis-
criminative classifiers (Henderson et al., 2012) to
predict whether the predefined slots occur in the
utterances or not, ignoring the unobserved con-
cepts and the hidden semantic information.
In this paper, we take a rather radical approach:
we propose a novel matrix factorization (MF)
model for learning latent features for SLU, tak-
ing account of additional information such as the
word relations, the induced slots, and the slot re-
lations. To further consider the global coherence
of induced slots, we combine the MF model with
</bodyText>
<page confidence="0.990274">
483
</page>
<note confidence="0.978350333333333">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 483–494,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.9998424">
a knowledge graph propagation based model, fus-
ing both a word-based lexical knowledge graph
and a slot-based semantic graph. In fact, as it
is shown in the Netflix challenge, MF is cred-
ited as the most useful technique for recommen-
dation systems (Koren et al., 2009). Also, the MF
model considers the unobserved patterns and esti-
mates their probabilities instead of viewing them
as negative examples. However, to the best of our
knowledge, the MF technique is not yet well un-
derstood in the SLU and SDS communities, and
it is not very straight-forward to use MF methods
to learn latent feature representations for semantic
parsing in SLU. To evaluate the performance of
our model, we compare it to standard discrimina-
tive SLU baselines, and show that our MF-based
model is able to produce strong results in seman-
tic decoding, and the knowledge graph propaga-
tion model further improves the performance. Our
contributions are three-fold:
</bodyText>
<listItem confidence="0.923127454545455">
• We are among the first to study matrix fac-
torization techniques for unsupervised SLU,
taking account of additional information;
• We augment the MF model with a knowl-
edge graph propagation model, increasing the
global coherence of semantic decoding using
induced slots;
• Our experimental results show that the MF-
based unsupervised SLU outperforms strong
discriminative baselines, obtaining promis-
ing results.
</listItem>
<bodyText confidence="0.999863">
In the next section, we outline the related work
in unsupervised SLU and latent variable model-
ing for spoken language processing. Section 3
introduces our framework. The detailed MF ap-
proach is explained in Section 4. We then intro-
duce the global knowledge graphs for MF in Sec-
tion 5. Section 6 shows the experimental results,
and Section 7 concludes.
</bodyText>
<sectionHeader confidence="0.999946" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99853996">
Unsupervised SLU Tur et al. (2011; 2012) were
among the first to consider unsupervised ap-
proaches for SLU, where they exploited query logs
for slot-filling. In a subsequent study, Heck and
Hakkani-T¨ur (2012) studied the Semantic Web for
an unsupervised intent detection problem in SLU,
showing that results obtained from the unsuper-
vised training process align well with the perfor-
mance of traditional supervised learning. Fol-
lowing their success of unsupervised SLU, recent
studies have also obtained interesting results on
the tasks of relation detection (Hakkani-T¨ur et al.,
2013; Chen et al., 2014a), entity extraction (Wang
et al., 2014), and extending domain coverage (El-
Kahky et al., 2014; Chen and Rudnicky, 2014).
However, most of the studies above do not ex-
plicitly learn latent factor representations from the
data—while we hypothesize that the better robust-
ness in noisy data can be achieved by explicitly
modeling the measurement errors (usually pro-
duced by automatic speech recognizers (ASR)) us-
ing latent variable models and taking additional lo-
cal and global semantic constraints into account.
Latent Variable Modeling in SLU Early stud-
ies on latent variable modeling in speech included
the classic hidden Markov model for statistical
speech recognition (Jelinek, 1997). Recently, Ce-
likyilmaz et al. (2011) were the first to study the
intent detection problem using query logs and a
discrete Bayesian latent variable model. In the
field of dialogue modeling, the partially observ-
able Markov decision process (POMDP) (Young
et al., 2013) model is a popular technique for di-
alogue management, reducing the cost of hand-
crafted dialogue managers while producing ro-
bustness against speech recognition errors. More
recently, Tur et al. (2013) used a semi-supervised
LDA model to show improvement on the slot fill-
ing task. Also, Zhai and Williams (2014) proposed
an unsupervised model for connecting words with
latent states in HMMs using topic models, obtain-
ing interesting qualitative and quantitative results.
However, for unsupervised learning for SLU, it is
not obvious how to incorporate additional infor-
mation in the HMMs. To the best of our knowl-
edge, this paper is the first to consider MF tech-
niques for learning latent feature representations
in unsupervised SLU, taking various local and
global lexical, syntactic, and semantic information
into account.
</bodyText>
<sectionHeader confidence="0.991799" genericHeader="method">
3 The Proposed Framework
</sectionHeader>
<bodyText confidence="0.999967866666667">
This paper introduces a matrix factorization tech-
nique for unsupervised SLU,. The proposed
framework is shown in Figure 1(a). Given the
utterances, the task of the SLU model is to de-
code their surface patterns into semantic forms
and differentiate the target semantic concepts from
the generic semantic space for task-oriented SDSs
simultaneously. Note that our model does not
require any human-defined slots and domain-
specific semantic representations for utterances.
In the proposed model, we first build a feature
matrix to represent the training utterances, where
each row represents an utterance, and each column
refers to an observed surface pattern or a induced
slot candidate. Figure 1(b) illustrates an example
</bodyText>
<page confidence="0.997799">
484
</page>
<figure confidence="0.999595196428571">
Unlabeled
Collection
SLU Model Training by Matrix Factorization
Slot Relation Model
Word Relation Model
Slot Induction
Knowledge
Graph
Construction
Frame-
Semantic
Parsing
Semantic KG
Lexical KG
food cheap restaurant food expensiveness
Word Observation Slot Candidate
Feature Model
Fw
Fs
.
Knowledge Graph
Propagation Model
Rw
Rs
“can I have a cheap restaurant”
Semantic
Representation
SLU
Model
locale_by_use
Word Relation Model Slot Induction Slot Relation Model
.90
1 1
1
.05
1
1 1
Reasoning with Matrix Factorization
.93
1
.85
.98
1 1
.97
.05
1
.95
.92
1
Train
Test
Utterance 1
i would like a cheap restaurant
Utterance 2
find a restaurant with chinese food
... ... ...
</figure>
<figureCaption confidence="0.99991">
Figure 1: (a): The proposed framework. (b): Our matrix factorization method completes a partially-
</figureCaption>
<bodyText confidence="0.998827282608696">
missing matrix for implicit semantic parsing. Dark circles are observed facts, shaded circles are inferred
facts. The slot induction maps (yellow arrow) observed surface patterns to semantic slot candidates.
The word relation model (blue arrow) constructs correlations between surface patterns. The slot relation
model (pink arrow) learns the slot-level correlations based on propagating the automatically derived
semantic knowledge graphs. Reasoning with matrix factorization (gray arrow) incorporates these models
jointly, and produces a coherent, domain-specific SLU model.
of the matrix. Given a testing utterance, we con-
vert it into a vector based on the observed surface
patterns, and then fill in the missing values of the
slots. In the first utterance in the figure, although
the semantic slot food is not observed, the utter-
ance implies the meaning facet food. The MF ap-
proach is able to learn the latent feature vectors for
utterances and semantic elements, inferring im-
plicit semantic concepts to improve the decoding
process—namely, by filling the matrix with prob-
abilities (lower part of the matrix).
The feature model is built on the observed word
patterns and slot candidates, where the slot candi-
dates are obtained from the slot induction compo-
nent through frame-semantic parsing (the yellow
block in Figure 1(a)) (Chen et al., 2013b). Sec-
tion 4.1 explains the detail of the feature model.
In order to consider the additional inter-word
and inter-slot relations, we propose a knowledge
graph propagation model based on two knowl-
edge graphs, which includes a word relation model
(blue block) and a slot relation model (pink block),
described in Section 4.2. The method of auto-
matic knowledge graph construction is introduced
in Section 5, where we leverage distributed word
embeddings associated with typed syntactic de-
pendencies to model the relations (Mikolov et al.,
2013b; Mikolov et al., 2013c; Levy and Goldberg,
2014; Chen et al., 2015).
Finally, we train the SLU model by learning
latent feature vectors for utterances and slot can-
didates through MF techniques. Combining with
a knowledge graph propagation model based on
word/slot relations, the trained SLU model esti-
mates the probability that each semantic slot oc-
curs in the testing utterance, and how likely each
slot is domain-specific simultaneously. In other
words, the SLU model is able to transform the test-
ing utterances into domain-specific semantic rep-
resentations without human involvement.
</bodyText>
<sectionHeader confidence="0.992667" genericHeader="method">
4 The Matrix Factorization Approach
</sectionHeader>
<bodyText confidence="0.999927666666667">
Considering the benefits brought by MF tech-
niques, including 1) modeling the noisy data, 2)
modeling hidden semantics, and 3) modeling the
</bodyText>
<page confidence="0.994782">
485
</page>
<bodyText confidence="0.923451043478261">
can i have a cheap restaurant
Figure 2: An example of probabilistic frame-
semantic parsing on ASR output. FT: frame target.
FE: frame element. LU: lexical unit.
long-range dependencies between observations, in
this work we apply an MF approach to SLU mod-
eling for SDSs. In our model, we use U to de-
note the set of input utterances, W as the set of
word patterns, and 5 as the set of semantic slots
that we would like to predict. The pair of an ut-
terance u E U and a word pattern/semantic slot
x E {W + 5}, (u, x), is a fact. The input to
our model is a set of observed facts O, and the
observed facts for a given utterance is denoted by
{(u, x) E O}. The goal of our model is to esti-
mate, for a given utterance u and a given word pat-
tern/semantic slot x, the probability, p(Mu,x = 1),
where Mu,x is a binary random variable that is true
if and only if x is the word pattern/domain-specific
semantic slot in the utterance u. We introduce a
series of exponential family models that estimate
the probability using a natural parameter 8u,x and
the logistic sigmoid function:
</bodyText>
<equation confidence="0.9935745">
1 + exp (−8u,x)
(1)
</equation>
<bodyText confidence="0.999605">
We construct a matrix M|U|×(|W|+|S|) as observed
facts for MF by integrating a feature model and a
knowledge graph propagation model below.
</bodyText>
<subsectionHeader confidence="0.914515">
4.1 Feature Model
</subsectionHeader>
<bodyText confidence="0.9985345">
First, we build a word pattern matrix Fw with
binary values based on observations, where each
row represents an utterance and each column
refers to an observed unigram. In other words, Fw
carries the basic word vectors for the utterances,
which is illustrated as the left part of the matrix in
Figure 1(b).
To induce the semantic elements, we parse all
ASR-decoded utterances in our corpus using SE-
MAFOR2, a state-of-the-art semantic parser for
frame-semantic parsing (Das et al., 2010; Das et
al., 2013), and extract all frames from seman-
tic parsing results as slot candidates (Chen et al.,
2013b; Dinarelli et al., 2009). Figure 2 shows
an example of an ASR-decoded output parsed
by SEMAFOR. Three FrameNet-defined frames
</bodyText>
<footnote confidence="0.739178">
2http://www.ark.cs.cmu.edu/SEMAFOR/
</footnote>
<bodyText confidence="0.998277">
(capability, expensiveness, and locale by use)
are generated for the utterance, which we consider
as slot candidates for a domain-specific dialogue
system (Baker et al., 1998). Then we build a slot
matrix Fs with binary values based on the induced
slots, which also denotes the slot features for the
utterances (right part of the matrix in Figure 1(b)).
To build the feature model MF, we concatenate
two matrices:
</bodyText>
<equation confidence="0.9879">
MF = [ Fw Fs ], (2)
</equation>
<bodyText confidence="0.9998475">
which is the upper part of the matrix in Fig-
ure 1(b) for training utterances. Note that we do
not use any annotations, so all slot candidates are
included.
</bodyText>
<subsectionHeader confidence="0.996698">
4.2 Knowledge Graph Propagation Model
</subsectionHeader>
<bodyText confidence="0.999993136363637">
Since SEMAFOR was trained on FrameNet anno-
tation, which has a more generic frame-semantic
context, not all the frames from the parsing re-
sults can be used as the actual slots in the domain-
specific dialogue systems. For instance, in Fig-
ure 2, we see that the frames “expensiveness”
and “locale by use” are essentially the key slots
for the purpose of understanding in the restaurant
query domain, whereas the “capability” frame
does not convey particularly valuable information
for SLU.
Assuming that domain-specific concepts are
usually related to each other, considering global
relations between semantic slots induces a more
coherent slot set. It is shown that the relations
on knowledge graphs help make decisions on
domain-specific slots (Chen et al., 2015). Con-
sidering two directed graphs, semantic and lexi-
cal knowledge graphs, each node in the semantic
knowledge graph is a slot candidate si generated
by the frame-semantic parser, and each node in the
lexical knowledge graph is a word wj.
</bodyText>
<listItem confidence="0.985640166666667">
• Slot-based semantic knowledge graph is
built as Gs = (Vs, Ess), where Vs = {si E
5} and Ess = {eij  |si, sj E Vs}.
• Word-based lexical knowledge graph is
built as Gw = (Vw, Eww), where Vw =
{wi E W} and Eww = {eij  |wi, wj E Vw}.
</listItem>
<bodyText confidence="0.999731857142857">
The edges connect two nodes in the graphs if there
is a typed dependency between them. Figure 3
is a simplified example of a slot-based semantic
knowledge graph. The structured graph helps de-
fine a coherent slot set. To model the relations be-
tween words/slots based on the knowledge graphs,
we define two relation models below.
</bodyText>
<figure confidence="0.5471675">
Frame: expensiveness
FT LU: cheap
Frame: capability Frame: locale by use
FT LU: can FE Filler: i FT/FE LU: restaurant
1
p(Mu,x = 1  |8u,x) = σ(8u,x) =
</figure>
<page confidence="0.956192">
486
</page>
<figureCaption confidence="0.98347">
Figure 3: A simplified example of the automati-
cally derived knowledge graph.
</figureCaption>
<listItem confidence="0.96786">
• Semantic Relation
</listItem>
<bodyText confidence="0.997600333333333">
For modeling word semantic rela-
tions, we compute a matrix RSw =
[Sim(wi,wj)]|W|×|W|, where Sim(wi,wj)
is the cosine similarity between the de-
pendency embeddings of the word pat-
terns wi and wj after normalization.
For slot semantic relations, we compute
RSs = [Sim(si, sj)]|S|×|S |similarly3. The
matrices RSw and RSs model not only the
semantic but functional similarity since we
use dependency-based embeddings (Levy
and Goldberg, 2014).
</bodyText>
<listItem confidence="0.98609">
• Dependency Relation
</listItem>
<bodyText confidence="0.999571444444445">
Assuming that important semantic slots are
usually mutually related to each other, that
is, connected by syntactic dependencies, our
automatically derived knowledge graphs are
able to help model the dependency relations.
For word dependency relations, we compute
a matrix RD w = [ˆr(wi, wj)]|W |×|W |, where
ˆr(wi, wj) measures the dependency between
two word patterns wi and wj based on the
word-based lexical knowledge graph, and the
detail is described in Section 5. For slot
dependency relations, we similarly compute
RDs = [ˆr(si,sj)]|S|×|S |based on the slot-
based semantic knowledge graph.
With the built word relation models (RSw and RDw)
and slot relation models (RSs and RDs ), we com-
bine them as a knowledge graph propagation ma-
trix MR4.
</bodyText>
<equation confidence="0.64596">
f RSD 0
MR = L , (3)
0 RSD
s
</equation>
<footnote confidence="0.9787176">
3For each column in RSw and RSs , we only keep top 10
highest values, which correspond the top 10 semantically
similar nodes.
4The values in the diagonal of MR are 0 to model the
propagation from other entries.
</footnote>
<bodyText confidence="0.88436">
where RSD w= RS w + RDw and RSD
</bodyText>
<equation confidence="0.844128">
s = RSs + RDs to
</equation>
<bodyText confidence="0.999591">
integrate semantic and dependency relations. The
goal of this matrix is to propagate scores between
nodes according to different types of relations in
the knowledge graphs (Chen and Metze, 2012).
</bodyText>
<subsectionHeader confidence="0.829791">
4.3 Integrated Model
</subsectionHeader>
<bodyText confidence="0.999166666666667">
With a feature model MF and a knowledge graph
propagation model MR, we integrate them into a
single matrix.
</bodyText>
<equation confidence="0.996224333333333">
M = MF · (αI + βMR) (4)
= f αFw + βFwRw 0 l
L 0 αFs + βFsRs J&apos;
</equation>
<bodyText confidence="0.999987333333333">
where M is the final matrix and I is the iden-
tity matrix. α and β are the weights for balanc-
ing original values and propagated values, where
α + β = 1. The matrix M is similar to MF,
but some weights are enhanced through the knowl-
edge graph propagation model, MR. The word
relations are built by FwRw, which is the ma-
trix with internal weight propagation on the lexical
knowledge graph (the blue arrow in Figure 1(b)).
Similarly, FsRs models the slot correlations, and
can be treated as the matrix with internal weight
propagation on the semantic knowledge graph (the
pink arrow in Figure 1(b)). The propagation mod-
els can be treated as running a random walk algo-
rithm on the graphs.
Fs contains all slot candidates generated by
SEMAFOR, which may include some generic
slots (such as capability), so the original feature
model cannot differentiate the domain-specific
and generic concepts. By integrating with Rs, the
semantic and dependency relations can be propa-
gated via the knowledge graph, and the domain-
specific concepts may have higher weights based
on the assumption that the slots for dialogue sys-
tems are often mutually related (Chen et al., 2015).
Hence, the structure information can be automati-
cally involved in the matrix. Also, the word rela-
tion model brings the same function, but now on
the word level. In conclusion, for each utterance,
the integrated model not only predicts the proba-
bility that semantic slots occur but also considers
whether the slots are domain-specific. The follow-
ing sections describe the learning process.
</bodyText>
<subsectionHeader confidence="0.992174">
4.4 Parameter Estimation
</subsectionHeader>
<bodyText confidence="0.999626333333333">
The proposed model is parameterized through
weights and latent component vectors, where the
parameters are estimated by maximizing the log
</bodyText>
<figure confidence="0.944492">
food AMOD expensiveness
AMOD
NN
locale_by_use
relational_quantity
AMOD
PREP_FOR
PREP_FOR
seeking
487
likelihood of observed data (Collins et al., 2001).
θ* = arg max
θ ri
uEU
= arg max
θ
ri
uEU
can i have a cheap restaurant
capability expensiveness locale_by_use
</figure>
<figureCaption confidence="0.999425">
Figure 4: The dependency parsing result.
</figureCaption>
<table confidence="0.646839333333333">
ccomp
nsubj dobj det
amod
p(θ  |Mu) (5)
p(Mu  |θ)p(θ)
� ln p(Mu  |θ) − λθ, 5 Knowledge Graph Construction
= arg max
θ
uEU
</table>
<bodyText confidence="0.998832923076923">
where Mu is the vector corresponding to the utter-
ance u from Mu,x in (1), because we assume that
each utterance is independent of others.
To avoid treating unobserved facts as designed
negative facts, we consider our positive-only data
as implicit feedback. Bayesian Personalized Rank-
ing (BPR) is an optimization criterion that learns
from implicit feedback for MF, which uses a vari-
ant of the ranking: giving observed true facts
higher scores than unobserved (true or false)
facts (Rendle et al., 2009). Riedel et al. (2013)
also showed that BPR learns the implicit relations
for improving the relation extraction task.
</bodyText>
<subsectionHeader confidence="0.509327">
4.4.1 Objective Function
</subsectionHeader>
<bodyText confidence="0.97111495">
To estimate the parameters in (5), we create a
dataset of ranked pairs from M in (4): for each
utterance u and each observed fact f+ = (u, x+),
where Mu,x &gt; δ, we choose each word pat-
tern/slot x− such that f− = (u, x−), where
Mu,x &lt; δ, which refers to the word pattern/slot we
have not observed to be in utterance u. That is, we
construct the observed data O from M. Then for
each pair of facts f+ and f−, we want to model
p(f+) &gt; p(f−) and hence θf+ &gt; θf− accord-
ing to (1). BPR maximizes the summation of each
ranked pair, where the objective is
This section introduces the procedure of con-
structing knowledge graphs in order to estimate
ˆr(wi, wj) for building RDw and ˆr(si, sj) for RDs
in Section 4.2. Considering the relations in the
knowledge graphs, the edge weights for Eww and
Ess are measured as ˆr(wi, wj) and ˆr(si, sj) based
on the dependency parsing results respectively.
The example utterance “can i have a cheap
restaurant” and its dependency parsing result are
illustrated in Figure 4. The arrows denote the
dependency relations from headwords to their
dependents, and words on arcs denote types of the
dependencies. All typed dependencies between
two words are encoded in triples and form a
word-based dependency set Tw = {(wi, t, wj)},
where t is the typed dependency between the
headword wi and the dependent wj. For example,
Figure 4 generates (restaurant, AMOD, cheap),
(restaurant, DOBJ, have), etc. for Tw, Sim-
ilarly, we build a slot-based dependency set
Ts = {(si, t, sj)} by transforming dependen-
cies between slot-fillers into ones between
slots. For example, (restaurant, AMOD, cheap)
from Tw
is transformed into
(locale by use, AMOD, expensiveness) for
building Ts, because both sides of the non-dotted
line are parsed as slot-fillers by SEMAFOR.
</bodyText>
<equation confidence="0.91196">
� ln p(Mu  |θ) = � � lnσ(θf+ − θf−). (6)
uEU f+EO f−0O 5.1 Relation Weight Estimation
</equation>
<bodyText confidence="0.99989975">
The BPR objective is an approximation to the
per utterance AUC (area under the ROC curve),
which directly correlates to what we want to
achieve – well-ranked semantic slots per utterance.
</bodyText>
<subsectionHeader confidence="0.760172">
4.4.2 Optimization
</subsectionHeader>
<bodyText confidence="0.9751297">
To maximize the objective in (6), we employ a
stochastic gradient descent (SGD) algorithm (Ren-
dle et al., 2009). For each randomly sampled ob-
served fact (u, x+), we sample an unobserved fact
(u, x− ), which results in |O |fact pairs (f−, f+).
For each pair, we perform an SGD update using
the gradient of the corresponding objective func-
tion for matrix factorization (Gantner et al., 2011).
For the edges in the knowledge graphs, we model
the relations between two connected nodes xi and
xj as ˆr(xi, xj), where x is either a slot s or a word
pattern w. Since the weights are measured based
on the relations between nodes regardless of the
directions, we combine the scores of two direc-
tional dependencies:
ˆr(xi, xj) = r(xi -* xj) + r(xj -* xi), (7)
where r(xi -* xj) is the score estimating the de-
pendency including xi as a head and xj as a de-
pendent. We propose a scoring function for r(·)
using dependency-based embeddings.
</bodyText>
<page confidence="0.999562">
488
</page>
<tableCaption confidence="0.999904">
Table 1: The example contexts extracted for training dependency-based word/slot embeddings.
</tableCaption>
<table confidence="0.9328658">
Typed Dependency Relation Target Word Contexts
Word hrestaurant, AMOD, cheapi restaurant cheap/AMOD
cheap restaurant/AMOD−1
Slot hlocale by use, AMOD, expensivenessi locale by use expensiveness/AMOD
expansiveness locale by use/AMOD−1
</table>
<subsubsectionHeader confidence="0.71294">
5.1.1 Dependency-Based Embeddings
</subsubsectionHeader>
<bodyText confidence="0.98371178125">
Most neural embeddings use linear bag-of-words
contexts, where a window size is defined to pro-
duce contexts of the target words (Mikolov et
al., 2013c; Mikolov et al., 2013b; Mikolov et
al., 2013a). However, some important contexts
may be missing due to smaller windows, while
larger windows capture broad topical content. A
dependency-based embedding approach was pro-
posed to derive contexts based on the syntactic re-
lations the word participates in for training embed-
dings, where the embeddings are less topical but
offer more functional similarity compared to orig-
inal embeddings (Levy and Goldberg, 2014).
Table 1 shows the extracted dependency-based
contexts for each target word from the example in
Figure 4, where headwords and their dependents
can form the contexts by following the arc on a
word in the dependency tree, and −1 denotes the
directionality of the dependency. After replacing
original bag-of-words contexts with dependency-
based contexts, we can train dependency-based
embeddings for all target words (Yih et al., 2014;
Bordes et al., 2011; Bordes et al., 2013).
For training dependency-based word embed-
dings, each target x is associated with a vector
vx ∈ Rd and each context c is represented as a
context vector vc ∈ Rd, where d is the embed-
ding dimensionality. We learn vector representa-
tions for both targets and contexts such that the
dot product vx · vc associated with “good” target-
context pairs belonging to the training data D is
maximized, leading to the objective function:
</bodyText>
<equation confidence="0.997991">
1
log 1 + exp(−vc · vx), (8)
</equation>
<bodyText confidence="0.95660225">
which can be trained using stochastic-gradient up-
dates (Levy and Goldberg, 2014). Then we can
obtain the dependency-based slot and word em-
beddings using Ts and Tw respectively.
</bodyText>
<subsubsectionHeader confidence="0.943516">
5.1.2 Embedding-Based Scoring Function
</subsubsectionHeader>
<bodyText confidence="0.93897425">
With trained dependency-based embeddings, we
estimate the probability that xi is the headword
and xj is its dependent via the typed dependency t
as
</bodyText>
<equation confidence="0.998845">
5im(xi, xj/t) + 5im(xj, xi/t−1)
xj) =
</equation>
<bodyText confidence="0.999969333333333">
where 5im(xi, xj/t) is the cosine similarity be-
tween word/slot embeddings vxi and context em-
beddings vxj/t after normalizing to [0, 1].
Based on the dependency set Tx, we use t∗ xi→xj
to denote the most possible typed dependency with
xi as a head and xj as a dependent.
</bodyText>
<equation confidence="0.9991185">
t∗ xi→xj = arg max C(xi →−xj ), (10)
t t
</equation>
<bodyText confidence="0.911231">
xj) counts how many times the
dependency hxi, t, xji occurs in the dependency
set Tx. Then the scoring function r(·) in (7) that
estimates the dependency xi → xj is measured as
</bodyText>
<equation confidence="0.938469">
r(xi → xj) = C(xi −−−−→xj)·P(xi −−−−→ xj),
t∗ t∗
xi→xj xi→xj
(11)
</equation>
<bodyText confidence="0.999938666666667">
which is equal to the highest observed frequency
of the dependency xi → xj among all types from
Tx and additionally weighted by the estimated
probability. The estimated probability smoothes
the observed frequency to avoid overfitting due to
the smaller dataset. Figure 3 is a simplified exam-
ple of an automatically derived semantic knowl-
edge graph with the most possible typed depen-
dencies as edges based on the estimated weights.
Then the relation weights ˆr(xi, xj) can be ob-
tained by (7) in order to build RDw and RDs ma-
trices.
</bodyText>
<sectionHeader confidence="0.999933" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<subsectionHeader confidence="0.997507">
6.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.998885">
In this experiment, we used the Cambridge Uni-
versity SLU corpus, previously used on several
other SLU tasks (Henderson et al., 2012; Chen et
al., 2013a). The domain of the corpus is about
restaurant recommendation in Cambridge; sub-
jects were asked to interact with multiple SDSs
in an in-car setting. The corpus contains a to-
tal number of 2,166 dialogues, including 15,453
utterances (10,571 for self-training and 4,882 for
</bodyText>
<equation confidence="0.6810464">
�arg max
vx,vc
(w,c)∈D
P(xi →−
t
,
2
(9)
where C(xi →−
t
</equation>
<page confidence="0.999069">
489
</page>
<tableCaption confidence="0.9903815">
Table 2: The MAP of predicted slots (%); † indicates that the result is significantly better than the Logistic
Regression (row (b)) with p &lt; 0.05 in t-test.
</tableCaption>
<table confidence="0.993141625">
Approach ASR Manual
w/o w/ Explicit w/o w/ Explicit
Explicit SVM 32.48 36.62
MLR 33.96 38.78
Implicit Baseline Random 3.43 22.45 2.63 25.09
Majority 15.37 32.88 16.43 38.41
MF Feature 24.24 37.61† 22.55 45.34†
Feature + KGP 40.46† 43.51† 52.14† 53.40†
</table>
<figure confidence="0.97661316">
locale by use
building
food
origin
speak on topic
seeking
desiring
locating
commerce scenario
expensiveness
range
part orientational
direction
locale
part inner outer
contacting
sending
type
food
addr
task
price range
area
phone
postcode
</figure>
<figureCaption confidence="0.966554333333333">
Figure 5: The mappings from induced slots
(within blocks) to reference slots (right sides of
arrows).
</figureCaption>
<bodyText confidence="0.999890588235294">
testing). The data is gender-balanced, with slightly
more native than non-native speakers. The vocab-
ulary size is 1868. An ASR system was used to
transcribe the speech; the word error rate was re-
ported as 37%. There are 10 slots created by do-
main experts: addr, area, food, name, phone,
postcode, price range, signature, task, and
type.
For parameter setting, the weights for balanc-
ing feature models and propagation models, α and
Q, are set as 0.5 to give the same influence, and
the threshold for defining the unobserved facts δ
is set as 0.5 for all experiments. We use the Stan-
ford Parser5 to obtain the collapsed typed syntac-
tic dependencies (Socher et al., 2013) and set the
dimensionality of embeddings d = 300 in all ex-
periments.
</bodyText>
<subsectionHeader confidence="0.999576">
6.2 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.9999025">
To evaluate the accuracy of the automatically
decoded slots, we measure their quality as the
proximity between predicted slots and reference
slots. Figure 5 shows the mappings that indicate
semantically related induced slots and reference
slots (Chen et al., 2013b).
To eliminate the influence of threshold selection
when predicting semantic slots, in the following
</bodyText>
<footnote confidence="0.8999055">
5http://nlp.stanford.edu/software/lex-parser.
shtml
</footnote>
<bodyText confidence="0.999973285714286">
metrics, we take the whole ranking list into ac-
count and evaluate the performance by the met-
rics that are independent of the selected threshold.
For each utterance, with the predicted probabilities
of all slot candidates, we can compute an average
precision (AP) to evaluate the performance of SLU
by treating the slots with mappings as positive. AP
scores the ranking result higher if the correct slots
are ranked higher, which also approximates to the
area under the precision-recall curve (Boyd et al.,
2012). Mean average precision (MAP) is the met-
ric for evaluating all utterances. For all experi-
ments, we perform a paired t-test on the AP scores
of the results to test the significance.
</bodyText>
<subsectionHeader confidence="0.999734">
6.3 Evaluation Results
</subsectionHeader>
<bodyText confidence="0.999979038461538">
Table 2 shows the MAP performance of predicted
slots for all experiments on ASR and manual tran-
scripts. For the first baseline using explicit seman-
tics, we use the observed data to self-train mod-
els for predicting the probability of each seman-
tic slot by support vector machine (SVM) with a
linear kernel and multinomial logistic regression
(MLR) (row (a)-(b)) (Pedregosa et al., 2011; Hen-
derson et al., 2012). It is shown that SVM and
MLR perform similarly, and MLR is slightly bet-
ter than SVM because it has better capability of
estimating probabilities. For modeling implicit
semantics, two baselines are performed as refer-
ences, Random (row (c)) and Majority (row (d)),
where the former assigns random probabilities for
all slots, and the later assigns probabilities for the
slots based on their frequency distribution. To im-
prove probability estimation, we further integrate
the results from implicit semantics with the better
result from explicit approaches, MLR (row (b)),
by averaging the probability distribution from two
results.
Two baselines, Random and Majority, cannot
model the implicit semantics, producing poor re-
sults. The results of Random integrated with
MLR significantly degrades the performance of
</bodyText>
<page confidence="0.999224">
490
</page>
<tableCaption confidence="0.79402">
Table 3: The MAP of predicted slots using different types of relation models in MR (%); † indicates that
the result is significantly better than the feature model (column (a)) with p &lt; 0.05 in t-test.
</tableCaption>
<table confidence="0.997579571428571">
Model Feature Knowledge Graph Propagation Model
Rel. (a) None (b) Semantic (c) Dependency (d) Word (e) Slot (f) All
MR _ f Rw 0 l f RD 0 l f RwD 0 l f 0 0 l f RSD 0 l
L 0 R3 J L 0 RDJ L 0 0 J L 0 RSD J L 0 RS J
s s
ASR 37.61 41.39† 41.63† 39.19† 42.10† 43.51†
Manual 45.34 51.55† 49.04† 45.18 49.91† 53.40†
</table>
<bodyText confidence="0.99444452173913">
MLR for both ASR and manual transcripts. Also,
the results of Majority integrated with MLR does
not produce any difference compared to the MLR
baseline. Among the proposed MF approaches,
only using feature model for building the ma-
trix (row (e)) achieves 24.2% and 22.6% of MAP
for ASR and manual results respectively, which
are worse than two baselines using explicit se-
mantics. However, with the combination of ex-
plicit semantics, using only the feature model sig-
nificantly outperforms the baselines, where the
performance comes from about 34.0% to 37.6%
and from 38.8% to 45.3% for ASR and manual
results respectively. Additionally integrating a
knowledge graph propagation (KGP) model (row
(e)) outperforms the baselines for both ASR and
manual transcripts, and the performance is fur-
ther improved by combining with explicit seman-
tics (achieving MAP of 43.5% and 53.4%). The
experiments show that the proposed MF models
successfully learn the implicit semantics and con-
sider the relations and domain-specificity simulta-
neously.
</bodyText>
<subsectionHeader confidence="0.992193">
6.4 Discussion and Analysis
</subsectionHeader>
<bodyText confidence="0.999960666666667">
With promising results obtained by the proposed
models, we analyze the detailed difference be-
tween different relation models in Table 3.
</bodyText>
<subsectionHeader confidence="0.7125125">
6.4.1 Effectiveness of Semantic and
Dependency Relation Models
</subsectionHeader>
<bodyText confidence="0.999912875">
To evaluate the effectiveness of semantic and de-
pendency relations, we consider each of them in-
dividually in MR of (3) (columns (b) and (c) in Ta-
ble 3). Comparing to the original model (column
(a)), both modeling semantic relations and mod-
eling dependency relations significantly improve
the performance for ASR and manual results. It is
shown that semantic relations help the SLU model
infer the implicit meaning, and then the predic-
tion becomes more accurate. Also, dependency re-
lations successfully differentiate the generic con-
cepts from the domain-specific concepts, so that
the SLU model is able to predict more coherent
set of semantic slots (Chen et al., 2015). Integrat-
ing two types of relations (column (f)) further im-
proves the performance.
</bodyText>
<subsectionHeader confidence="0.931841">
6.4.2 Comparing Word/ Slot Relation Models
</subsectionHeader>
<bodyText confidence="0.999995555555556">
To analyze the performance results from inter-
word and inter-slot relations, the columns (d) and
(e) show the results considering only word rela-
tions and only slot relations respectively. It can
be seen that the inter-slot relation model signif-
icantly improves the performance for both ASR
and manual results. However, the inter-word re-
lation model only performs slightly better results
for ASR output (from 37.6% to 39.2%), and there
is no difference after applying the inter-word rela-
tion model on manual transcripts. The reason may
be that inter-slot relations carry high-level seman-
tics that align well with the structure of SDSs, but
inter-word relations do not. Nevertheless, combin-
ing two relations (column (f)) outperforms both re-
sults for ASR and manual transcripts, showing that
different types of relations can compensate each
other and then benefit the SLU performance.
</bodyText>
<sectionHeader confidence="0.999459" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.9999381">
This paper presents an MF approach to self-train
the SLU model for semantic decoding in an unsu-
pervised way. The purpose of the proposed model
is not only to predict the probability of each se-
mantic slot but also to distinguish between generic
semantic concepts and domain-specific concepts
that are related to an SDS. The experiments show
that the MF-based model obtains promising re-
sults, outperforming strong discriminative base-
lines.
</bodyText>
<sectionHeader confidence="0.998811" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999882857142857">
We thank anonymous reviewers for their useful
comments and Prof. Manfred Stede for his men-
toring. We are also grateful to MetLife’s support.
Any opinions, findings, and conclusions expressed
in this publication are those of the authors and do
not necessarily reflect the views of funding agen-
cies.
</bodyText>
<page confidence="0.998474">
491
</page>
<sectionHeader confidence="0.996343" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.990473220183486">
Collin F Baker, Charles J Fillmore, and John B Lowe.
1998. The Berkeley FrameNet project. In Proceed-
ings of COLING, pages 86–90.
Dan Bohus and Alexander I Rudnicky. 2009. The
RavenClaw dialog management framework: Archi-
tecture and systems. Computer Speech &amp; Language,
23(3):332–361.
Antoine Bordes, Jason Weston, Ronan Collobert,
Yoshua Bengio, et al. 2011. Learning structured
embeddings of knowledge bases. In Proceedings of
AAAI.
Antoine Bordes, Nicolas Usunier, Alberto Garcia-
Duran, Jason Weston, and Oksana Yakhnenko.
2013. Translating embeddings for modeling multi-
relational data. In Proceedings of Advances in Neu-
ral Information Processing Systems, pages 2787–
2795.
Kendrick Boyd, Vitor Santos Costa, Jesse Davis, and
C David Page. 2012. Unachievable region in
precision-recall space and its effect on empirical
evaluation. In Machine learning: proceedings of the
International Conference. International Conference
on Machine Learning, volume 2012, page 349. NIH
Public Access.
Asli Celikyilmaz, Dilek Hakkani-T¨ur, and Gokhan T¨ur.
2011. Leveraging web query logs to learn user in-
tent via bayesian discrete latent variable model. In
Proceedings of ICML.
Yun-Nung Chen and Florian Metze. 2012. Two-
layer mutually reinforced random walk for improved
multi-party meeting summarization. In Proceedings
of The 4th IEEE Workshop on Spoken Language
Tachnology, pages 461–466.
Yun-Nung Chen and Alexander I. Rudnicky. 2014.
Dynamically supporting unexplored domains in
conversational interactions by enriching semantics
with neural word embeddings. In Proceedings of
2014 IEEE Spoken Language Technology Workshop
(SLT), pages 590–595. IEEE.
Yun-Nung Chen, William Yang Wang, and Alexan-
der I. Rudnicky. 2013a. An empirical investigation
of sparse log-linear models for improved dialogue
act classification. In Proceedings of ICASSP, pages
8317–8321.
Yun-Nung Chen, William Yang Wang, and Alexander I
Rudnicky. 2013b. Unsupervised induction and fill-
ing of semantic slots for spoken dialogue systems
using frame-semantic parsing. In Proceedings of
2013 IEEE Workshop on Automatic Speech Recog-
nition and Understanding (ASRU), pages 120–125.
IEEE.
Yun-Nung Chen, Dilek Hakkani-T¨ur, and Gokan Tur.
2014a. Deriving local relational surface forms from
dependency-based entity embeddings for unsuper-
vised spoken language understanding. In Proceed-
ings of 2014 IEEE Spoken Language Technology
Workshop (SLT), pages 242–247. IEEE.
Yun-Nung Chen, William Yang Wang, and Alexan-
der I. Rudnicky. 2014b. Leveraging frame se-
mantics and distributional semantics for unsuper-
vised semantic slot induction in spoken dialogue
systems. In Proceedings of 2014 IEEE Spoken Lan-
guage Technology Workshop (SLT), pages 584–589.
IEEE.
Yun-Nung Chen, William Yang Wang, and Alexan-
der I. Rudnicky. 2015. Jointly modeling inter-slot
relations by random walk on knowledge graphs for
unsupervised spoken language understanding. In
Proceedings of the 2015 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics - Human Language Technologies.
ACL.
Michael Collins, Sanjoy Dasgupta, and Robert E
Schapire. 2001. A generalization of principal com-
ponents analysis to the exponential family. In Pro-
ceedings of Advances in Neural Information Pro-
cessing Systems, pages 617–624.
Dipanjan Das, Nathan Schneider, Desai Chen, and
Noah A Smith. 2010. Probabilistic frame-semantic
parsing. In Proceedings of The Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, pages 948–956.
Dipanjan Das, Desai Chen, Andr´e F. T. Martins,
Nathan Schneider, and Noah A. Smith. 2013.
Frame-semantic parsing. Computational Linguis-
tics.
Marco Dinarelli, Silvia Quarteroni, Sara Tonelli,
Alessandro Moschitti, and Giuseppe Riccardi.
2009. Annotating spoken dialogs: from speech seg-
ments to dialog acts and frame semantics. In Pro-
ceedings of the 2nd Workshop on Semantic Repre-
sentation of Spoken Language, pages 34–41. ACL.
John Dowding, Jean Mark Gawron, Doug Appelt, John
Bear, Lynn Cherny, Robert Moore, and Douglas
Moran. 1993. Gemini: A natural language system
for spoken-language understanding. In Proceedings
ofACL, pages 54–61.
Ali El-Kahky, Derek Liu, Ruhi Sarikaya, G¨okhan T¨ur,
Dilek Hakkani-T¨ur, and Larry Heck. 2014. Ex-
tending domain coverage of language understanding
systems via intent transfer between domains using
knowledge graphs and search query click logs. In
Proceedings of ICASSP.
Zeno Gantner, Steffen Rendle, Christoph Freuden-
thaler, and Lars Schmidt-Thieme. 2011. Mymedi-
alite: A free recommender system library. In Pro-
ceedings of the fifth ACM conference on Recom-
mender systems, pages 305–308. ACM.
</reference>
<page confidence="0.981341">
492
</page>
<reference confidence="0.99993390825688">
Narendra Gupta, G¨okhan T¨ur, Dilek Hakkani-T¨ur,
Srinivas Bangalore, Giuseppe Riccardi, and Mazin
Gilbert. 2006. The AT&amp;T spoken language un-
derstanding system. IEEE Transactions on Audio,
Speech, and Language Processing, 14(1):213–222.
Dilek Hakkani-T¨ur, Larry Heck, and Gokhan Tur.
2013. Using a knowledge graph and query click logs
for unsupervised learning of relation detection. In
Proceedings of ICASSP, pages 8327–8331.
Larry Heck and Dilek Hakkani-T¨ur. 2012. Exploiting
the semantic web for unsupervised spoken language
understanding. In Proceedings of SLT, pages 228–
233.
Larry P Heck, Dilek Hakkani-T¨ur, and Gokhan Tur.
2013. Leveraging knowledge graphs for web-scale
unsupervised semantic parsing. In Proceedings of
INTERSPEECH, pages 1594–1598.
Matthew Henderson, Milica Gasic, Blaise Thomson,
Pirros Tsiakoulis, Kai Yu, and Steve Young. 2012.
Discriminative spoken language understanding us-
ing word confusion networks. In Proceedings of
SLT, pages 176–181.
Frederick Jelinek. 1997. Statistical methods for speech
recognition. MIT press.
Yehuda Koren, Robert Bell, and Chris Volinsky. 2009.
Matrix factorization techniques for recommender
systems. Computer, (8):30–37.
Omer Levy and Yoav Goldberg. 2014. Dependency-
based word embeddings. In Proceedings of ACL.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013a. Efficient estimation of word represen-
tations in vector space. In Proceedings of Workshop
at ICLR.
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013b. Distributed representa-
tions of words and phrases and their compositional-
ity. In Proceedings of Advances in Neural Informa-
tion Processing Systems, pages 3111–3119.
Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013c. Linguistic regularities in continuous space
word representations. In HLT-NAACL, pages 746–
751. Citeseer.
Fabian Pedregosa, Ga¨el Varoquaux, Alexandre Gram-
fort, Vincent Michel, Bertrand Thirion, Olivier
Grisel, Mathieu Blondel, Peter Prettenhofer, Ron
Weiss, Vincent Dubourg, et al. 2011. Scikit-learn:
Machine learning in python. The Journal of Ma-
chine Learning Research, 12:2825–2830.
Roberto Pieraccini, Evelyne Tzoukermann, Zakhar
Gorelov, J Gauvain, Esther Levin, Chin-Hui Lee,
and Jay G Wilpon. 1992. A speech understand-
ing system based on statistical representation of se-
mantics. In Proceedings of 1992 IEEE International
Conference on Acoustics, Speech, and Signal Pro-
cessing (ICASSP), volume 1, pages 193–196. IEEE.
Steffen Rendle, Christoph Freudenthaler, Zeno Gant-
ner, and Lars Schmidt-Thieme. 2009. BPR:
Bayesian personalized ranking from implicit feed-
back. In Proceedings of the Twenty-Fifth Confer-
ence on Uncertainty in Artificial Intelligence, pages
452–461. AUAI Press.
Sebastian Riedel, Limin Yao, Andrew McCallum, and
Benjamin M Marlin. 2013. Relation extraction with
matrix factorization and universal schemas. In Pro-
ceedings of NAACL-HLT, pages 74–84.
Stephanie Seneff. 1992. TINA: A natural language
system for spoken language applications. Computa-
tional linguistics, 18(1):61–86.
Anders Skrondal and Sophia Rabe-Hesketh. 2004.
Generalized latent variable modeling: Multilevel,
longitudinal, and structural equation models. Crc
Press.
Richard Socher, John Bauer, Christopher D Manning,
and Andrew Y Ng. 2013. Parsing with composi-
tional vector grammars. In Proceedings of the ACL
conference. Citeseer.
Gokhan Tur, Dilek Z Hakkani-T¨ur, Dustin Hillard, and
Asli Celikyilmaz. 2011. Towards unsupervised
spoken language understanding: Exploiting query
click logs for slot filling. In Proceedings of INTER-
SPEECH, pages 1293–1296.
Gokhan Tur, Minwoo Jeong, Ye-Yi Wang, Dilek
Hakkani-T¨ur, and Larry P Heck. 2012. Exploit-
ing the semantic web for unsupervised natural lan-
guage semantic parsing. In Proceedings of INTER-
SPEECH.
Gokhan Tur, Asli Celikyilmaz, and Dilek Hakkani-
Tur. 2013. Latent semantic modeling for slot fill-
ing in conversational understanding. In Proceedings
of 2013 IEEE International Conference on Acous-
tics, Speech and Signal Processing (ICASSP), pages
8307–8311. IEEE.
William Yang Wang, Dan Bohus, Ece Kamar, and Eric
Horvitz. 2012. Crowdsourcing the acquisition of
natural language corpora: Methods and observa-
tions. In Proceedings of SLT, pages 73–78.
Lu Wang, Dilek Hakkani-T¨ur, and Larry Heck. 2014.
Leveraging semantic web search and browse ses-
sions for multi-turn spoken dialog systems. In Pro-
ceedings of 2014 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP),
pages 4082–4086. IEEE.
Wen-tau Yih, Xiaodong He, and Christopher Meek.
2014. Semantic parsing for single-relation question
answering. In Proceedings of ACL.
Steve Young, Milica Gasic, Blaise Thomson, and Ja-
son D Williams. 2013. POMDP-based statistical
spoken dialog systems: A review. Proceedings of
the IEEE, 101(5):1160–1179.
</reference>
<page confidence="0.993205">
493
</page>
<reference confidence="0.764011">
Ke Zhai and Jason D Williams. 2014. Discovering
latent structure in task-oriented dialogues. In Pro-
ceedings of the Association for Computational Lin-
guistics.
</reference>
<page confidence="0.99888">
494
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.891068">
<title confidence="0.999697">Matrix Factorization with Knowledge Graph for Unsupervised Spoken Language Understanding</title>
<author confidence="0.99744">Yun-Nung Chen</author>
<author confidence="0.99744">William Yang Wang</author>
<author confidence="0.99744">Anatole Gershman</author>
<author confidence="0.99744">I Alexander</author>
<affiliation confidence="0.999524">School of Computer Science, Carnegie Mellon</affiliation>
<address confidence="0.999811">5000 Forbes Aveue, Pittsburgh, PA 15213-3891,</address>
<email confidence="0.937426">yww,anatoleg,</email>
<abstract confidence="0.998407344827586">Spoken dialogue systems (SDS) typically require a predefined semantic ontology to train a spoken language understanding (SLU) module. In addition to the annotation cost, a key challenge for designing such an ontology is to define a coherent slot set while considering their complex relations. This paper introduces a novel matrix factorization (MF) approach to learn latent feature vectors for utterances and semantic elements without the need of corpus annotations. Specifically, our model learns the semantic slots for a domain-specific SDS in an unsupervised fashion, and carries out semantic parsing using latent MF techniques. To further consider the global semantic structure, such as inter-word and inter-slot relations, we augment the latent MF-based model with a knowledge graph propagation model based on a slot-based semantic graph and a word-based lexical graph. Our experiments show that the proposed MF approaches produce better SLU models that are able to predict semantic slots and word patterns taking into account their relations and domain-specificity in a joint manner.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley FrameNet project.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>86--90</pages>
<contexts>
<context position="14678" citStr="Baker et al., 1998" startWordPosition="2330" endWordPosition="2333"> the semantic elements, we parse all ASR-decoded utterances in our corpus using SEMAFOR2, a state-of-the-art semantic parser for frame-semantic parsing (Das et al., 2010; Das et al., 2013), and extract all frames from semantic parsing results as slot candidates (Chen et al., 2013b; Dinarelli et al., 2009). Figure 2 shows an example of an ASR-decoded output parsed by SEMAFOR. Three FrameNet-defined frames 2http://www.ark.cs.cmu.edu/SEMAFOR/ (capability, expensiveness, and locale by use) are generated for the utterance, which we consider as slot candidates for a domain-specific dialogue system (Baker et al., 1998). Then we build a slot matrix Fs with binary values based on the induced slots, which also denotes the slot features for the utterances (right part of the matrix in Figure 1(b)). To build the feature model MF, we concatenate two matrices: MF = [ Fw Fs ], (2) which is the upper part of the matrix in Figure 1(b) for training utterances. Note that we do not use any annotations, so all slot candidates are included. 4.2 Knowledge Graph Propagation Model Since SEMAFOR was trained on FrameNet annotation, which has a more generic frame-semantic context, not all the frames from the parsing results can </context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F Baker, Charles J Fillmore, and John B Lowe. 1998. The Berkeley FrameNet project. In Proceedings of COLING, pages 86–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Bohus</author>
<author>Alexander I Rudnicky</author>
</authors>
<title>The RavenClaw dialog management framework: Architecture and systems.</title>
<date>2009</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="2022" citStr="Bohus and Rudnicky, 2009" startWordPosition="309" endWordPosition="313">ficity in a joint manner. 1 Introduction A key component of a spoken dialogue system (SDS) is the spoken language understanding (SLU) module—it parses the users’ utterances into semantic representations; for example, the utterance “find a cheap restaurant” can be parsed into (price=cheap, target=restaurant) (Pieraccini et al., 1992). To design the SLU module of a SDS, most previous studies relied on predefined slots1 for training the decoder (Seneff, 1992; Dowding 1A slot is defined as a basic semantic unit in SLU, such as “price” and “target” in the example. et al., 1993; Gupta et al., 2006; Bohus and Rudnicky, 2009). However, these predefined semantic slots may bias the subsequent data collection process, and the cost of manually labeling utterances for updating the ontology is expensive (Wang et al., 2012). In recent years, this problem led to the development of unsupervised SLU techniques (Heck and Hakkani-T¨ur, 2012; Heck et al., 2013; Chen et al., 2013b; Chen et al., 2014b). In particular, Chen et al. (2013b) proposed a frame-semantics based framework for automatically inducing semantic slots given raw audios. However, these approaches generally do not explicitly learn the latent factor representatio</context>
</contexts>
<marker>Bohus, Rudnicky, 2009</marker>
<rawString>Dan Bohus and Alexander I Rudnicky. 2009. The RavenClaw dialog management framework: Architecture and systems. Computer Speech &amp; Language, 23(3):332–361.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antoine Bordes</author>
<author>Jason Weston</author>
<author>Ronan Collobert</author>
<author>Yoshua Bengio</author>
</authors>
<title>Learning structured embeddings of knowledge bases.</title>
<date>2011</date>
<booktitle>In Proceedings of AAAI.</booktitle>
<contexts>
<context position="26026" citStr="Bordes et al., 2011" startWordPosition="4253" endWordPosition="4256">ipates in for training embeddings, where the embeddings are less topical but offer more functional similarity compared to original embeddings (Levy and Goldberg, 2014). Table 1 shows the extracted dependency-based contexts for each target word from the example in Figure 4, where headwords and their dependents can form the contexts by following the arc on a word in the dependency tree, and −1 denotes the directionality of the dependency. After replacing original bag-of-words contexts with dependencybased contexts, we can train dependency-based embeddings for all target words (Yih et al., 2014; Bordes et al., 2011; Bordes et al., 2013). For training dependency-based word embeddings, each target x is associated with a vector vx ∈ Rd and each context c is represented as a context vector vc ∈ Rd, where d is the embedding dimensionality. We learn vector representations for both targets and contexts such that the dot product vx · vc associated with “good” targetcontext pairs belonging to the training data D is maximized, leading to the objective function: 1 log 1 + exp(−vc · vx), (8) which can be trained using stochastic-gradient updates (Levy and Goldberg, 2014). Then we can obtain the dependency-based slo</context>
</contexts>
<marker>Bordes, Weston, Collobert, Bengio, 2011</marker>
<rawString>Antoine Bordes, Jason Weston, Ronan Collobert, Yoshua Bengio, et al. 2011. Learning structured embeddings of knowledge bases. In Proceedings of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antoine Bordes</author>
<author>Nicolas Usunier</author>
<author>Alberto GarciaDuran</author>
<author>Jason Weston</author>
<author>Oksana Yakhnenko</author>
</authors>
<title>Translating embeddings for modeling multirelational data.</title>
<date>2013</date>
<booktitle>In Proceedings of Advances in Neural Information Processing Systems,</booktitle>
<pages>2787--2795</pages>
<contexts>
<context position="26048" citStr="Bordes et al., 2013" startWordPosition="4257" endWordPosition="4260">g embeddings, where the embeddings are less topical but offer more functional similarity compared to original embeddings (Levy and Goldberg, 2014). Table 1 shows the extracted dependency-based contexts for each target word from the example in Figure 4, where headwords and their dependents can form the contexts by following the arc on a word in the dependency tree, and −1 denotes the directionality of the dependency. After replacing original bag-of-words contexts with dependencybased contexts, we can train dependency-based embeddings for all target words (Yih et al., 2014; Bordes et al., 2011; Bordes et al., 2013). For training dependency-based word embeddings, each target x is associated with a vector vx ∈ Rd and each context c is represented as a context vector vc ∈ Rd, where d is the embedding dimensionality. We learn vector representations for both targets and contexts such that the dot product vx · vc associated with “good” targetcontext pairs belonging to the training data D is maximized, leading to the objective function: 1 log 1 + exp(−vc · vx), (8) which can be trained using stochastic-gradient updates (Levy and Goldberg, 2014). Then we can obtain the dependency-based slot and word embeddings </context>
</contexts>
<marker>Bordes, Usunier, GarciaDuran, Weston, Yakhnenko, 2013</marker>
<rawString>Antoine Bordes, Nicolas Usunier, Alberto GarciaDuran, Jason Weston, and Oksana Yakhnenko. 2013. Translating embeddings for modeling multirelational data. In Proceedings of Advances in Neural Information Processing Systems, pages 2787– 2795.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kendrick Boyd</author>
<author>Vitor Santos Costa</author>
<author>Jesse Davis</author>
<author>C David Page</author>
</authors>
<title>Unachievable region in precision-recall space and its effect on empirical evaluation.</title>
<date>2012</date>
<booktitle>In Machine learning: proceedings of the International Conference. International Conference on Machine Learning,</booktitle>
<volume>2012</volume>
<pages>349</pages>
<publisher>NIH Public Access.</publisher>
<contexts>
<context position="30949" citStr="Boyd et al., 2012" startWordPosition="5079" endWordPosition="5082">ction when predicting semantic slots, in the following 5http://nlp.stanford.edu/software/lex-parser. shtml metrics, we take the whole ranking list into account and evaluate the performance by the metrics that are independent of the selected threshold. For each utterance, with the predicted probabilities of all slot candidates, we can compute an average precision (AP) to evaluate the performance of SLU by treating the slots with mappings as positive. AP scores the ranking result higher if the correct slots are ranked higher, which also approximates to the area under the precision-recall curve (Boyd et al., 2012). Mean average precision (MAP) is the metric for evaluating all utterances. For all experiments, we perform a paired t-test on the AP scores of the results to test the significance. 6.3 Evaluation Results Table 2 shows the MAP performance of predicted slots for all experiments on ASR and manual transcripts. For the first baseline using explicit semantics, we use the observed data to self-train models for predicting the probability of each semantic slot by support vector machine (SVM) with a linear kernel and multinomial logistic regression (MLR) (row (a)-(b)) (Pedregosa et al., 2011; Henderson</context>
</contexts>
<marker>Boyd, Costa, Davis, Page, 2012</marker>
<rawString>Kendrick Boyd, Vitor Santos Costa, Jesse Davis, and C David Page. 2012. Unachievable region in precision-recall space and its effect on empirical evaluation. In Machine learning: proceedings of the International Conference. International Conference on Machine Learning, volume 2012, page 349. NIH Public Access.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asli Celikyilmaz</author>
<author>Dilek Hakkani-T¨ur</author>
<author>Gokhan T¨ur</author>
</authors>
<title>Leveraging web query logs to learn user intent via bayesian discrete latent variable model.</title>
<date>2011</date>
<booktitle>In Proceedings of ICML.</booktitle>
<marker>Celikyilmaz, Hakkani-T¨ur, T¨ur, 2011</marker>
<rawString>Asli Celikyilmaz, Dilek Hakkani-T¨ur, and Gokhan T¨ur. 2011. Leveraging web query logs to learn user intent via bayesian discrete latent variable model. In Proceedings of ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yun-Nung Chen</author>
<author>Florian Metze</author>
</authors>
<title>Twolayer mutually reinforced random walk for improved multi-party meeting summarization.</title>
<date>2012</date>
<booktitle>In Proceedings of The 4th IEEE Workshop on Spoken Language Tachnology,</booktitle>
<pages>461--466</pages>
<contexts>
<context position="18632" citStr="Chen and Metze, 2012" startWordPosition="3012" endWordPosition="3015"> word relation models (RSw and RDw) and slot relation models (RSs and RDs ), we combine them as a knowledge graph propagation matrix MR4. f RSD 0 MR = L , (3) 0 RSD s 3For each column in RSw and RSs , we only keep top 10 highest values, which correspond the top 10 semantically similar nodes. 4The values in the diagonal of MR are 0 to model the propagation from other entries. where RSD w= RS w + RDw and RSD s = RSs + RDs to integrate semantic and dependency relations. The goal of this matrix is to propagate scores between nodes according to different types of relations in the knowledge graphs (Chen and Metze, 2012). 4.3 Integrated Model With a feature model MF and a knowledge graph propagation model MR, we integrate them into a single matrix. M = MF · (αI + βMR) (4) = f αFw + βFwRw 0 l L 0 αFs + βFsRs J&apos; where M is the final matrix and I is the identity matrix. α and β are the weights for balancing original values and propagated values, where α + β = 1. The matrix M is similar to MF, but some weights are enhanced through the knowledge graph propagation model, MR. The word relations are built by FwRw, which is the matrix with internal weight propagation on the lexical knowledge graph (the blue arrow in F</context>
</contexts>
<marker>Chen, Metze, 2012</marker>
<rawString>Yun-Nung Chen and Florian Metze. 2012. Twolayer mutually reinforced random walk for improved multi-party meeting summarization. In Proceedings of The 4th IEEE Workshop on Spoken Language Tachnology, pages 461–466.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yun-Nung Chen</author>
<author>Alexander I Rudnicky</author>
</authors>
<title>Dynamically supporting unexplored domains in conversational interactions by enriching semantics with neural word embeddings.</title>
<date>2014</date>
<booktitle>In Proceedings of 2014 IEEE Spoken Language Technology Workshop (SLT),</booktitle>
<pages>590--595</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="6666" citStr="Chen and Rudnicky, 2014" startWordPosition="1042" endWordPosition="1045">or SLU, where they exploited query logs for slot-filling. In a subsequent study, Heck and Hakkani-T¨ur (2012) studied the Semantic Web for an unsupervised intent detection problem in SLU, showing that results obtained from the unsupervised training process align well with the performance of traditional supervised learning. Following their success of unsupervised SLU, recent studies have also obtained interesting results on the tasks of relation detection (Hakkani-T¨ur et al., 2013; Chen et al., 2014a), entity extraction (Wang et al., 2014), and extending domain coverage (ElKahky et al., 2014; Chen and Rudnicky, 2014). However, most of the studies above do not explicitly learn latent factor representations from the data—while we hypothesize that the better robustness in noisy data can be achieved by explicitly modeling the measurement errors (usually produced by automatic speech recognizers (ASR)) using latent variable models and taking additional local and global semantic constraints into account. Latent Variable Modeling in SLU Early studies on latent variable modeling in speech included the classic hidden Markov model for statistical speech recognition (Jelinek, 1997). Recently, Celikyilmaz et al. (2011</context>
</contexts>
<marker>Chen, Rudnicky, 2014</marker>
<rawString>Yun-Nung Chen and Alexander I. Rudnicky. 2014. Dynamically supporting unexplored domains in conversational interactions by enriching semantics with neural word embeddings. In Proceedings of 2014 IEEE Spoken Language Technology Workshop (SLT), pages 590–595. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yun-Nung Chen</author>
<author>William Yang Wang</author>
<author>Alexander I Rudnicky</author>
</authors>
<title>An empirical investigation of sparse log-linear models for improved dialogue act classification.</title>
<date>2013</date>
<booktitle>In Proceedings of ICASSP,</booktitle>
<pages>8317--8321</pages>
<contexts>
<context position="2369" citStr="Chen et al., 2013" startWordPosition="366" endWordPosition="369">odule of a SDS, most previous studies relied on predefined slots1 for training the decoder (Seneff, 1992; Dowding 1A slot is defined as a basic semantic unit in SLU, such as “price” and “target” in the example. et al., 1993; Gupta et al., 2006; Bohus and Rudnicky, 2009). However, these predefined semantic slots may bias the subsequent data collection process, and the cost of manually labeling utterances for updating the ontology is expensive (Wang et al., 2012). In recent years, this problem led to the development of unsupervised SLU techniques (Heck and Hakkani-T¨ur, 2012; Heck et al., 2013; Chen et al., 2013b; Chen et al., 2014b). In particular, Chen et al. (2013b) proposed a frame-semantics based framework for automatically inducing semantic slots given raw audios. However, these approaches generally do not explicitly learn the latent factor representations to model the measurement errors (Skrondal and Rabe-Hesketh, 2004), nor do they jointly consider the complex lexical, syntactic, and semantic relations among words, slots, and utterances. Another challenge of SLU is the inference of the hidden semantics. Considering the user utterance “can i have a cheap restaurant”, from its surface patterns,</context>
<context position="11186" citStr="Chen et al., 2013" startWordPosition="1745" endWordPosition="1748">lots. In the first utterance in the figure, although the semantic slot food is not observed, the utterance implies the meaning facet food. The MF approach is able to learn the latent feature vectors for utterances and semantic elements, inferring implicit semantic concepts to improve the decoding process—namely, by filling the matrix with probabilities (lower part of the matrix). The feature model is built on the observed word patterns and slot candidates, where the slot candidates are obtained from the slot induction component through frame-semantic parsing (the yellow block in Figure 1(a)) (Chen et al., 2013b). Section 4.1 explains the detail of the feature model. In order to consider the additional inter-word and inter-slot relations, we propose a knowledge graph propagation model based on two knowledge graphs, which includes a word relation model (blue block) and a slot relation model (pink block), described in Section 4.2. The method of automatic knowledge graph construction is introduced in Section 5, where we leverage distributed word embeddings associated with typed syntactic dependencies to model the relations (Mikolov et al., 2013b; Mikolov et al., 2013c; Levy and Goldberg, 2014; Chen et </context>
<context position="14339" citStr="Chen et al., 2013" startWordPosition="2284" endWordPosition="2287">w. 4.1 Feature Model First, we build a word pattern matrix Fw with binary values based on observations, where each row represents an utterance and each column refers to an observed unigram. In other words, Fw carries the basic word vectors for the utterances, which is illustrated as the left part of the matrix in Figure 1(b). To induce the semantic elements, we parse all ASR-decoded utterances in our corpus using SEMAFOR2, a state-of-the-art semantic parser for frame-semantic parsing (Das et al., 2010; Das et al., 2013), and extract all frames from semantic parsing results as slot candidates (Chen et al., 2013b; Dinarelli et al., 2009). Figure 2 shows an example of an ASR-decoded output parsed by SEMAFOR. Three FrameNet-defined frames 2http://www.ark.cs.cmu.edu/SEMAFOR/ (capability, expensiveness, and locale by use) are generated for the utterance, which we consider as slot candidates for a domain-specific dialogue system (Baker et al., 1998). Then we build a slot matrix Fs with binary values based on the induced slots, which also denotes the slot features for the utterances (right part of the matrix in Figure 1(b)). To build the feature model MF, we concatenate two matrices: MF = [ Fw Fs ], (2) wh</context>
<context position="28175" citStr="Chen et al., 2013" startWordPosition="4630" endWordPosition="4633">d additionally weighted by the estimated probability. The estimated probability smoothes the observed frequency to avoid overfitting due to the smaller dataset. Figure 3 is a simplified example of an automatically derived semantic knowledge graph with the most possible typed dependencies as edges based on the estimated weights. Then the relation weights ˆr(xi, xj) can be obtained by (7) in order to build RDw and RDs matrices. 6 Experiments 6.1 Experimental Setup In this experiment, we used the Cambridge University SLU corpus, previously used on several other SLU tasks (Henderson et al., 2012; Chen et al., 2013a). The domain of the corpus is about restaurant recommendation in Cambridge; subjects were asked to interact with multiple SDSs in an in-car setting. The corpus contains a total number of 2,166 dialogues, including 15,453 utterances (10,571 for self-training and 4,882 for �arg max vx,vc (w,c)∈D P(xi →− t , 2 (9) where C(xi →− t 489 Table 2: The MAP of predicted slots (%); † indicates that the result is significantly better than the Logistic Regression (row (b)) with p &lt; 0.05 in t-test. Approach ASR Manual w/o w/ Explicit w/o w/ Explicit Explicit SVM 32.48 36.62 MLR 33.96 38.78 Implicit Baseli</context>
<context position="30283" citStr="Chen et al., 2013" startWordPosition="4979" endWordPosition="4982">opagation models, α and Q, are set as 0.5 to give the same influence, and the threshold for defining the unobserved facts δ is set as 0.5 for all experiments. We use the Stanford Parser5 to obtain the collapsed typed syntactic dependencies (Socher et al., 2013) and set the dimensionality of embeddings d = 300 in all experiments. 6.2 Evaluation Metrics To evaluate the accuracy of the automatically decoded slots, we measure their quality as the proximity between predicted slots and reference slots. Figure 5 shows the mappings that indicate semantically related induced slots and reference slots (Chen et al., 2013b). To eliminate the influence of threshold selection when predicting semantic slots, in the following 5http://nlp.stanford.edu/software/lex-parser. shtml metrics, we take the whole ranking list into account and evaluate the performance by the metrics that are independent of the selected threshold. For each utterance, with the predicted probabilities of all slot candidates, we can compute an average precision (AP) to evaluate the performance of SLU by treating the slots with mappings as positive. AP scores the ranking result higher if the correct slots are ranked higher, which also approximate</context>
</contexts>
<marker>Chen, Wang, Rudnicky, 2013</marker>
<rawString>Yun-Nung Chen, William Yang Wang, and Alexander I. Rudnicky. 2013a. An empirical investigation of sparse log-linear models for improved dialogue act classification. In Proceedings of ICASSP, pages 8317–8321.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yun-Nung Chen</author>
<author>William Yang Wang</author>
<author>Alexander I Rudnicky</author>
</authors>
<title>Unsupervised induction and filling of semantic slots for spoken dialogue systems using frame-semantic parsing.</title>
<date>2013</date>
<booktitle>In Proceedings of 2013 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU),</booktitle>
<pages>120--125</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="2369" citStr="Chen et al., 2013" startWordPosition="366" endWordPosition="369">odule of a SDS, most previous studies relied on predefined slots1 for training the decoder (Seneff, 1992; Dowding 1A slot is defined as a basic semantic unit in SLU, such as “price” and “target” in the example. et al., 1993; Gupta et al., 2006; Bohus and Rudnicky, 2009). However, these predefined semantic slots may bias the subsequent data collection process, and the cost of manually labeling utterances for updating the ontology is expensive (Wang et al., 2012). In recent years, this problem led to the development of unsupervised SLU techniques (Heck and Hakkani-T¨ur, 2012; Heck et al., 2013; Chen et al., 2013b; Chen et al., 2014b). In particular, Chen et al. (2013b) proposed a frame-semantics based framework for automatically inducing semantic slots given raw audios. However, these approaches generally do not explicitly learn the latent factor representations to model the measurement errors (Skrondal and Rabe-Hesketh, 2004), nor do they jointly consider the complex lexical, syntactic, and semantic relations among words, slots, and utterances. Another challenge of SLU is the inference of the hidden semantics. Considering the user utterance “can i have a cheap restaurant”, from its surface patterns,</context>
<context position="11186" citStr="Chen et al., 2013" startWordPosition="1745" endWordPosition="1748">lots. In the first utterance in the figure, although the semantic slot food is not observed, the utterance implies the meaning facet food. The MF approach is able to learn the latent feature vectors for utterances and semantic elements, inferring implicit semantic concepts to improve the decoding process—namely, by filling the matrix with probabilities (lower part of the matrix). The feature model is built on the observed word patterns and slot candidates, where the slot candidates are obtained from the slot induction component through frame-semantic parsing (the yellow block in Figure 1(a)) (Chen et al., 2013b). Section 4.1 explains the detail of the feature model. In order to consider the additional inter-word and inter-slot relations, we propose a knowledge graph propagation model based on two knowledge graphs, which includes a word relation model (blue block) and a slot relation model (pink block), described in Section 4.2. The method of automatic knowledge graph construction is introduced in Section 5, where we leverage distributed word embeddings associated with typed syntactic dependencies to model the relations (Mikolov et al., 2013b; Mikolov et al., 2013c; Levy and Goldberg, 2014; Chen et </context>
<context position="14339" citStr="Chen et al., 2013" startWordPosition="2284" endWordPosition="2287">w. 4.1 Feature Model First, we build a word pattern matrix Fw with binary values based on observations, where each row represents an utterance and each column refers to an observed unigram. In other words, Fw carries the basic word vectors for the utterances, which is illustrated as the left part of the matrix in Figure 1(b). To induce the semantic elements, we parse all ASR-decoded utterances in our corpus using SEMAFOR2, a state-of-the-art semantic parser for frame-semantic parsing (Das et al., 2010; Das et al., 2013), and extract all frames from semantic parsing results as slot candidates (Chen et al., 2013b; Dinarelli et al., 2009). Figure 2 shows an example of an ASR-decoded output parsed by SEMAFOR. Three FrameNet-defined frames 2http://www.ark.cs.cmu.edu/SEMAFOR/ (capability, expensiveness, and locale by use) are generated for the utterance, which we consider as slot candidates for a domain-specific dialogue system (Baker et al., 1998). Then we build a slot matrix Fs with binary values based on the induced slots, which also denotes the slot features for the utterances (right part of the matrix in Figure 1(b)). To build the feature model MF, we concatenate two matrices: MF = [ Fw Fs ], (2) wh</context>
<context position="28175" citStr="Chen et al., 2013" startWordPosition="4630" endWordPosition="4633">d additionally weighted by the estimated probability. The estimated probability smoothes the observed frequency to avoid overfitting due to the smaller dataset. Figure 3 is a simplified example of an automatically derived semantic knowledge graph with the most possible typed dependencies as edges based on the estimated weights. Then the relation weights ˆr(xi, xj) can be obtained by (7) in order to build RDw and RDs matrices. 6 Experiments 6.1 Experimental Setup In this experiment, we used the Cambridge University SLU corpus, previously used on several other SLU tasks (Henderson et al., 2012; Chen et al., 2013a). The domain of the corpus is about restaurant recommendation in Cambridge; subjects were asked to interact with multiple SDSs in an in-car setting. The corpus contains a total number of 2,166 dialogues, including 15,453 utterances (10,571 for self-training and 4,882 for �arg max vx,vc (w,c)∈D P(xi →− t , 2 (9) where C(xi →− t 489 Table 2: The MAP of predicted slots (%); † indicates that the result is significantly better than the Logistic Regression (row (b)) with p &lt; 0.05 in t-test. Approach ASR Manual w/o w/ Explicit w/o w/ Explicit Explicit SVM 32.48 36.62 MLR 33.96 38.78 Implicit Baseli</context>
<context position="30283" citStr="Chen et al., 2013" startWordPosition="4979" endWordPosition="4982">opagation models, α and Q, are set as 0.5 to give the same influence, and the threshold for defining the unobserved facts δ is set as 0.5 for all experiments. We use the Stanford Parser5 to obtain the collapsed typed syntactic dependencies (Socher et al., 2013) and set the dimensionality of embeddings d = 300 in all experiments. 6.2 Evaluation Metrics To evaluate the accuracy of the automatically decoded slots, we measure their quality as the proximity between predicted slots and reference slots. Figure 5 shows the mappings that indicate semantically related induced slots and reference slots (Chen et al., 2013b). To eliminate the influence of threshold selection when predicting semantic slots, in the following 5http://nlp.stanford.edu/software/lex-parser. shtml metrics, we take the whole ranking list into account and evaluate the performance by the metrics that are independent of the selected threshold. For each utterance, with the predicted probabilities of all slot candidates, we can compute an average precision (AP) to evaluate the performance of SLU by treating the slots with mappings as positive. AP scores the ranking result higher if the correct slots are ranked higher, which also approximate</context>
</contexts>
<marker>Chen, Wang, Rudnicky, 2013</marker>
<rawString>Yun-Nung Chen, William Yang Wang, and Alexander I Rudnicky. 2013b. Unsupervised induction and filling of semantic slots for spoken dialogue systems using frame-semantic parsing. In Proceedings of 2013 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), pages 120–125. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yun-Nung Chen</author>
<author>Dilek Hakkani-T¨ur</author>
<author>Gokan Tur</author>
</authors>
<title>Deriving local relational surface forms from dependency-based entity embeddings for unsupervised spoken language understanding.</title>
<date>2014</date>
<booktitle>In Proceedings of 2014 IEEE Spoken Language Technology Workshop (SLT),</booktitle>
<pages>242--247</pages>
<publisher>IEEE.</publisher>
<marker>Chen, Hakkani-T¨ur, Tur, 2014</marker>
<rawString>Yun-Nung Chen, Dilek Hakkani-T¨ur, and Gokan Tur. 2014a. Deriving local relational surface forms from dependency-based entity embeddings for unsupervised spoken language understanding. In Proceedings of 2014 IEEE Spoken Language Technology Workshop (SLT), pages 242–247. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yun-Nung Chen</author>
<author>William Yang Wang</author>
<author>Alexander I Rudnicky</author>
</authors>
<title>Leveraging frame semantics and distributional semantics for unsupervised semantic slot induction in spoken dialogue systems.</title>
<date>2014</date>
<booktitle>In Proceedings of 2014 IEEE Spoken Language Technology Workshop (SLT),</booktitle>
<pages>584--589</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="2389" citStr="Chen et al., 2014" startWordPosition="370" endWordPosition="373"> previous studies relied on predefined slots1 for training the decoder (Seneff, 1992; Dowding 1A slot is defined as a basic semantic unit in SLU, such as “price” and “target” in the example. et al., 1993; Gupta et al., 2006; Bohus and Rudnicky, 2009). However, these predefined semantic slots may bias the subsequent data collection process, and the cost of manually labeling utterances for updating the ontology is expensive (Wang et al., 2012). In recent years, this problem led to the development of unsupervised SLU techniques (Heck and Hakkani-T¨ur, 2012; Heck et al., 2013; Chen et al., 2013b; Chen et al., 2014b). In particular, Chen et al. (2013b) proposed a frame-semantics based framework for automatically inducing semantic slots given raw audios. However, these approaches generally do not explicitly learn the latent factor representations to model the measurement errors (Skrondal and Rabe-Hesketh, 2004), nor do they jointly consider the complex lexical, syntactic, and semantic relations among words, slots, and utterances. Another challenge of SLU is the inference of the hidden semantics. Considering the user utterance “can i have a cheap restaurant”, from its surface patterns, we can see that it </context>
<context position="6546" citStr="Chen et al., 2014" startWordPosition="1023" endWordPosition="1026"> Related Work Unsupervised SLU Tur et al. (2011; 2012) were among the first to consider unsupervised approaches for SLU, where they exploited query logs for slot-filling. In a subsequent study, Heck and Hakkani-T¨ur (2012) studied the Semantic Web for an unsupervised intent detection problem in SLU, showing that results obtained from the unsupervised training process align well with the performance of traditional supervised learning. Following their success of unsupervised SLU, recent studies have also obtained interesting results on the tasks of relation detection (Hakkani-T¨ur et al., 2013; Chen et al., 2014a), entity extraction (Wang et al., 2014), and extending domain coverage (ElKahky et al., 2014; Chen and Rudnicky, 2014). However, most of the studies above do not explicitly learn latent factor representations from the data—while we hypothesize that the better robustness in noisy data can be achieved by explicitly modeling the measurement errors (usually produced by automatic speech recognizers (ASR)) using latent variable models and taking additional local and global semantic constraints into account. Latent Variable Modeling in SLU Early studies on latent variable modeling in speech include</context>
</contexts>
<marker>Chen, Wang, Rudnicky, 2014</marker>
<rawString>Yun-Nung Chen, William Yang Wang, and Alexander I. Rudnicky. 2014b. Leveraging frame semantics and distributional semantics for unsupervised semantic slot induction in spoken dialogue systems. In Proceedings of 2014 IEEE Spoken Language Technology Workshop (SLT), pages 584–589. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yun-Nung Chen</author>
<author>William Yang Wang</author>
<author>Alexander I Rudnicky</author>
</authors>
<title>Jointly modeling inter-slot relations by random walk on knowledge graphs for unsupervised spoken language understanding.</title>
<date>2015</date>
<booktitle>In Proceedings of the 2015 Conference of the North American Chapter of</booktitle>
<publisher>ACL.</publisher>
<contexts>
<context position="11796" citStr="Chen et al., 2015" startWordPosition="1842" endWordPosition="1845">l., 2013b). Section 4.1 explains the detail of the feature model. In order to consider the additional inter-word and inter-slot relations, we propose a knowledge graph propagation model based on two knowledge graphs, which includes a word relation model (blue block) and a slot relation model (pink block), described in Section 4.2. The method of automatic knowledge graph construction is introduced in Section 5, where we leverage distributed word embeddings associated with typed syntactic dependencies to model the relations (Mikolov et al., 2013b; Mikolov et al., 2013c; Levy and Goldberg, 2014; Chen et al., 2015). Finally, we train the SLU model by learning latent feature vectors for utterances and slot candidates through MF techniques. Combining with a knowledge graph propagation model based on word/slot relations, the trained SLU model estimates the probability that each semantic slot occurs in the testing utterance, and how likely each slot is domain-specific simultaneously. In other words, the SLU model is able to transform the testing utterances into domain-specific semantic representations without human involvement. 4 The Matrix Factorization Approach Considering the benefits brought by MF techn</context>
<context position="15892" citStr="Chen et al., 2015" startWordPosition="2534" endWordPosition="2537">can be used as the actual slots in the domainspecific dialogue systems. For instance, in Figure 2, we see that the frames “expensiveness” and “locale by use” are essentially the key slots for the purpose of understanding in the restaurant query domain, whereas the “capability” frame does not convey particularly valuable information for SLU. Assuming that domain-specific concepts are usually related to each other, considering global relations between semantic slots induces a more coherent slot set. It is shown that the relations on knowledge graphs help make decisions on domain-specific slots (Chen et al., 2015). Considering two directed graphs, semantic and lexical knowledge graphs, each node in the semantic knowledge graph is a slot candidate si generated by the frame-semantic parser, and each node in the lexical knowledge graph is a word wj. • Slot-based semantic knowledge graph is built as Gs = (Vs, Ess), where Vs = {si E 5} and Ess = {eij |si, sj E Vs}. • Word-based lexical knowledge graph is built as Gw = (Vw, Eww), where Vw = {wi E W} and Eww = {eij |wi, wj E Vw}. The edges connect two nodes in the graphs if there is a typed dependency between them. Figure 3 is a simplified example of a slot-b</context>
<context position="19983" citStr="Chen et al., 2015" startWordPosition="3254" endWordPosition="3257">emantic knowledge graph (the pink arrow in Figure 1(b)). The propagation models can be treated as running a random walk algorithm on the graphs. Fs contains all slot candidates generated by SEMAFOR, which may include some generic slots (such as capability), so the original feature model cannot differentiate the domain-specific and generic concepts. By integrating with Rs, the semantic and dependency relations can be propagated via the knowledge graph, and the domainspecific concepts may have higher weights based on the assumption that the slots for dialogue systems are often mutually related (Chen et al., 2015). Hence, the structure information can be automatically involved in the matrix. Also, the word relation model brings the same function, but now on the word level. In conclusion, for each utterance, the integrated model not only predicts the probability that semantic slots occur but also considers whether the slots are domain-specific. The following sections describe the learning process. 4.4 Parameter Estimation The proposed model is parameterized through weights and latent component vectors, where the parameters are estimated by maximizing the log food AMOD expensiveness AMOD NN locale_by_use</context>
<context position="34815" citStr="Chen et al., 2015" startWordPosition="5721" endWordPosition="5724">ndency relations, we consider each of them individually in MR of (3) (columns (b) and (c) in Table 3). Comparing to the original model (column (a)), both modeling semantic relations and modeling dependency relations significantly improve the performance for ASR and manual results. It is shown that semantic relations help the SLU model infer the implicit meaning, and then the prediction becomes more accurate. Also, dependency relations successfully differentiate the generic concepts from the domain-specific concepts, so that the SLU model is able to predict more coherent set of semantic slots (Chen et al., 2015). Integrating two types of relations (column (f)) further improves the performance. 6.4.2 Comparing Word/ Slot Relation Models To analyze the performance results from interword and inter-slot relations, the columns (d) and (e) show the results considering only word relations and only slot relations respectively. It can be seen that the inter-slot relation model significantly improves the performance for both ASR and manual results. However, the inter-word relation model only performs slightly better results for ASR output (from 37.6% to 39.2%), and there is no difference after applying the int</context>
</contexts>
<marker>Chen, Wang, Rudnicky, 2015</marker>
<rawString>Yun-Nung Chen, William Yang Wang, and Alexander I. Rudnicky. 2015. Jointly modeling inter-slot relations by random walk on knowledge graphs for unsupervised spoken language understanding. In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics - Human Language Technologies. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Sanjoy Dasgupta</author>
<author>Robert E Schapire</author>
</authors>
<title>A generalization of principal components analysis to the exponential family.</title>
<date>2001</date>
<booktitle>In Proceedings of Advances in Neural Information Processing Systems,</booktitle>
<pages>617--624</pages>
<contexts>
<context position="20689" citStr="Collins et al., 2001" startWordPosition="3359" endWordPosition="3362"> the word relation model brings the same function, but now on the word level. In conclusion, for each utterance, the integrated model not only predicts the probability that semantic slots occur but also considers whether the slots are domain-specific. The following sections describe the learning process. 4.4 Parameter Estimation The proposed model is parameterized through weights and latent component vectors, where the parameters are estimated by maximizing the log food AMOD expensiveness AMOD NN locale_by_use relational_quantity AMOD PREP_FOR PREP_FOR seeking 487 likelihood of observed data (Collins et al., 2001). θ* = arg max θ ri uEU = arg max θ ri uEU can i have a cheap restaurant capability expensiveness locale_by_use Figure 4: The dependency parsing result. ccomp nsubj dobj det amod p(θ |Mu) (5) p(Mu |θ)p(θ) � ln p(Mu |θ) − λθ, 5 Knowledge Graph Construction = arg max θ uEU where Mu is the vector corresponding to the utterance u from Mu,x in (1), because we assume that each utterance is independent of others. To avoid treating unobserved facts as designed negative facts, we consider our positive-only data as implicit feedback. Bayesian Personalized Ranking (BPR) is an optimization criterion that </context>
</contexts>
<marker>Collins, Dasgupta, Schapire, 2001</marker>
<rawString>Michael Collins, Sanjoy Dasgupta, and Robert E Schapire. 2001. A generalization of principal components analysis to the exponential family. In Proceedings of Advances in Neural Information Processing Systems, pages 617–624.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Nathan Schneider</author>
<author>Desai Chen</author>
<author>Noah A Smith</author>
</authors>
<title>Probabilistic frame-semantic parsing.</title>
<date>2010</date>
<booktitle>In Proceedings of The Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>948--956</pages>
<contexts>
<context position="14228" citStr="Das et al., 2010" startWordPosition="2264" endWordPosition="2267">(|W|+|S|) as observed facts for MF by integrating a feature model and a knowledge graph propagation model below. 4.1 Feature Model First, we build a word pattern matrix Fw with binary values based on observations, where each row represents an utterance and each column refers to an observed unigram. In other words, Fw carries the basic word vectors for the utterances, which is illustrated as the left part of the matrix in Figure 1(b). To induce the semantic elements, we parse all ASR-decoded utterances in our corpus using SEMAFOR2, a state-of-the-art semantic parser for frame-semantic parsing (Das et al., 2010; Das et al., 2013), and extract all frames from semantic parsing results as slot candidates (Chen et al., 2013b; Dinarelli et al., 2009). Figure 2 shows an example of an ASR-decoded output parsed by SEMAFOR. Three FrameNet-defined frames 2http://www.ark.cs.cmu.edu/SEMAFOR/ (capability, expensiveness, and locale by use) are generated for the utterance, which we consider as slot candidates for a domain-specific dialogue system (Baker et al., 1998). Then we build a slot matrix Fs with binary values based on the induced slots, which also denotes the slot features for the utterances (right part of</context>
</contexts>
<marker>Das, Schneider, Chen, Smith, 2010</marker>
<rawString>Dipanjan Das, Nathan Schneider, Desai Chen, and Noah A Smith. 2010. Probabilistic frame-semantic parsing. In Proceedings of The Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 948–956.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Desai Chen</author>
<author>Andr´e F T Martins</author>
<author>Nathan Schneider</author>
<author>Noah A Smith</author>
</authors>
<title>Frame-semantic parsing. Computational Linguistics.</title>
<date>2013</date>
<contexts>
<context position="14247" citStr="Das et al., 2013" startWordPosition="2268" endWordPosition="2271">ved facts for MF by integrating a feature model and a knowledge graph propagation model below. 4.1 Feature Model First, we build a word pattern matrix Fw with binary values based on observations, where each row represents an utterance and each column refers to an observed unigram. In other words, Fw carries the basic word vectors for the utterances, which is illustrated as the left part of the matrix in Figure 1(b). To induce the semantic elements, we parse all ASR-decoded utterances in our corpus using SEMAFOR2, a state-of-the-art semantic parser for frame-semantic parsing (Das et al., 2010; Das et al., 2013), and extract all frames from semantic parsing results as slot candidates (Chen et al., 2013b; Dinarelli et al., 2009). Figure 2 shows an example of an ASR-decoded output parsed by SEMAFOR. Three FrameNet-defined frames 2http://www.ark.cs.cmu.edu/SEMAFOR/ (capability, expensiveness, and locale by use) are generated for the utterance, which we consider as slot candidates for a domain-specific dialogue system (Baker et al., 1998). Then we build a slot matrix Fs with binary values based on the induced slots, which also denotes the slot features for the utterances (right part of the matrix in Figu</context>
</contexts>
<marker>Das, Chen, Martins, Schneider, Smith, 2013</marker>
<rawString>Dipanjan Das, Desai Chen, Andr´e F. T. Martins, Nathan Schneider, and Noah A. Smith. 2013. Frame-semantic parsing. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Dinarelli</author>
<author>Silvia Quarteroni</author>
<author>Sara Tonelli</author>
<author>Alessandro Moschitti</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Annotating spoken dialogs: from speech segments to dialog acts and frame semantics.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2nd Workshop on Semantic Representation of Spoken Language,</booktitle>
<pages>34--41</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="14365" citStr="Dinarelli et al., 2009" startWordPosition="2288" endWordPosition="2291"> First, we build a word pattern matrix Fw with binary values based on observations, where each row represents an utterance and each column refers to an observed unigram. In other words, Fw carries the basic word vectors for the utterances, which is illustrated as the left part of the matrix in Figure 1(b). To induce the semantic elements, we parse all ASR-decoded utterances in our corpus using SEMAFOR2, a state-of-the-art semantic parser for frame-semantic parsing (Das et al., 2010; Das et al., 2013), and extract all frames from semantic parsing results as slot candidates (Chen et al., 2013b; Dinarelli et al., 2009). Figure 2 shows an example of an ASR-decoded output parsed by SEMAFOR. Three FrameNet-defined frames 2http://www.ark.cs.cmu.edu/SEMAFOR/ (capability, expensiveness, and locale by use) are generated for the utterance, which we consider as slot candidates for a domain-specific dialogue system (Baker et al., 1998). Then we build a slot matrix Fs with binary values based on the induced slots, which also denotes the slot features for the utterances (right part of the matrix in Figure 1(b)). To build the feature model MF, we concatenate two matrices: MF = [ Fw Fs ], (2) which is the upper part of t</context>
</contexts>
<marker>Dinarelli, Quarteroni, Tonelli, Moschitti, Riccardi, 2009</marker>
<rawString>Marco Dinarelli, Silvia Quarteroni, Sara Tonelli, Alessandro Moschitti, and Giuseppe Riccardi. 2009. Annotating spoken dialogs: from speech segments to dialog acts and frame semantics. In Proceedings of the 2nd Workshop on Semantic Representation of Spoken Language, pages 34–41. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Dowding</author>
<author>Jean Mark Gawron</author>
<author>Doug Appelt</author>
<author>John Bear</author>
<author>Lynn Cherny</author>
<author>Robert Moore</author>
<author>Douglas Moran</author>
</authors>
<title>Gemini: A natural language system for spoken-language understanding.</title>
<date>1993</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>54--61</pages>
<marker>Dowding, Gawron, Appelt, Bear, Cherny, Moore, Moran, 1993</marker>
<rawString>John Dowding, Jean Mark Gawron, Doug Appelt, John Bear, Lynn Cherny, Robert Moore, and Douglas Moran. 1993. Gemini: A natural language system for spoken-language understanding. In Proceedings ofACL, pages 54–61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ali El-Kahky</author>
<author>Derek Liu</author>
<author>Ruhi Sarikaya</author>
<author>G¨okhan T¨ur</author>
<author>Dilek Hakkani-T¨ur</author>
<author>Larry Heck</author>
</authors>
<title>Extending domain coverage of language understanding systems via intent transfer between domains using knowledge graphs and search query click logs.</title>
<date>2014</date>
<booktitle>In Proceedings of ICASSP.</booktitle>
<marker>El-Kahky, Liu, Sarikaya, T¨ur, Hakkani-T¨ur, Heck, 2014</marker>
<rawString>Ali El-Kahky, Derek Liu, Ruhi Sarikaya, G¨okhan T¨ur, Dilek Hakkani-T¨ur, and Larry Heck. 2014. Extending domain coverage of language understanding systems via intent transfer between domains using knowledge graphs and search query click logs. In Proceedings of ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zeno Gantner</author>
<author>Steffen Rendle</author>
<author>Christoph Freudenthaler</author>
<author>Lars Schmidt-Thieme</author>
</authors>
<title>Mymedialite: A free recommender system library.</title>
<date>2011</date>
<booktitle>In Proceedings of the fifth ACM conference on Recommender systems,</booktitle>
<pages>305--308</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="24063" citStr="Gantner et al., 2011" startWordPosition="3944" endWordPosition="3947">lation Weight Estimation The BPR objective is an approximation to the per utterance AUC (area under the ROC curve), which directly correlates to what we want to achieve – well-ranked semantic slots per utterance. 4.4.2 Optimization To maximize the objective in (6), we employ a stochastic gradient descent (SGD) algorithm (Rendle et al., 2009). For each randomly sampled observed fact (u, x+), we sample an unobserved fact (u, x− ), which results in |O |fact pairs (f−, f+). For each pair, we perform an SGD update using the gradient of the corresponding objective function for matrix factorization (Gantner et al., 2011). For the edges in the knowledge graphs, we model the relations between two connected nodes xi and xj as ˆr(xi, xj), where x is either a slot s or a word pattern w. Since the weights are measured based on the relations between nodes regardless of the directions, we combine the scores of two directional dependencies: ˆr(xi, xj) = r(xi -* xj) + r(xj -* xi), (7) where r(xi -* xj) is the score estimating the dependency including xi as a head and xj as a dependent. We propose a scoring function for r(·) using dependency-based embeddings. 488 Table 1: The example contexts extracted for training depe</context>
</contexts>
<marker>Gantner, Rendle, Freudenthaler, Schmidt-Thieme, 2011</marker>
<rawString>Zeno Gantner, Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2011. Mymedialite: A free recommender system library. In Proceedings of the fifth ACM conference on Recommender systems, pages 305–308. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Narendra Gupta</author>
<author>G¨okhan T¨ur</author>
<author>Dilek Hakkani-T¨ur</author>
<author>Srinivas Bangalore</author>
<author>Giuseppe Riccardi</author>
<author>Mazin Gilbert</author>
</authors>
<title>The AT&amp;T spoken language understanding system.</title>
<date>2006</date>
<journal>IEEE Transactions on Audio, Speech, and Language Processing,</journal>
<volume>14</volume>
<issue>1</issue>
<marker>Gupta, T¨ur, Hakkani-T¨ur, Bangalore, Riccardi, Gilbert, 2006</marker>
<rawString>Narendra Gupta, G¨okhan T¨ur, Dilek Hakkani-T¨ur, Srinivas Bangalore, Giuseppe Riccardi, and Mazin Gilbert. 2006. The AT&amp;T spoken language understanding system. IEEE Transactions on Audio, Speech, and Language Processing, 14(1):213–222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dilek Hakkani-T¨ur</author>
<author>Larry Heck</author>
<author>Gokhan Tur</author>
</authors>
<title>Using a knowledge graph and query click logs for unsupervised learning of relation detection.</title>
<date>2013</date>
<booktitle>In Proceedings of ICASSP,</booktitle>
<pages>8327--8331</pages>
<marker>Hakkani-T¨ur, Heck, Tur, 2013</marker>
<rawString>Dilek Hakkani-T¨ur, Larry Heck, and Gokhan Tur. 2013. Using a knowledge graph and query click logs for unsupervised learning of relation detection. In Proceedings of ICASSP, pages 8327–8331.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Larry Heck</author>
<author>Dilek Hakkani-T¨ur</author>
</authors>
<title>Exploiting the semantic web for unsupervised spoken language understanding.</title>
<date>2012</date>
<booktitle>In Proceedings of SLT,</booktitle>
<pages>228--233</pages>
<marker>Heck, Hakkani-T¨ur, 2012</marker>
<rawString>Larry Heck and Dilek Hakkani-T¨ur. 2012. Exploiting the semantic web for unsupervised spoken language understanding. In Proceedings of SLT, pages 228– 233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Larry P Heck</author>
<author>Dilek Hakkani-T¨ur</author>
<author>Gokhan Tur</author>
</authors>
<title>Leveraging knowledge graphs for web-scale unsupervised semantic parsing.</title>
<date>2013</date>
<booktitle>In Proceedings of INTERSPEECH,</booktitle>
<pages>1594--1598</pages>
<marker>Heck, Hakkani-T¨ur, Tur, 2013</marker>
<rawString>Larry P Heck, Dilek Hakkani-T¨ur, and Gokhan Tur. 2013. Leveraging knowledge graphs for web-scale unsupervised semantic parsing. In Proceedings of INTERSPEECH, pages 1594–1598.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Henderson</author>
<author>Milica Gasic</author>
<author>Blaise Thomson</author>
<author>Pirros Tsiakoulis</author>
<author>Kai Yu</author>
<author>Steve Young</author>
</authors>
<title>Discriminative spoken language understanding using word confusion networks.</title>
<date>2012</date>
<booktitle>In Proceedings of SLT,</booktitle>
<pages>176--181</pages>
<contexts>
<context position="3481" citStr="Henderson et al., 2012" startWordPosition="536" endWordPosition="539">he hidden semantics. Considering the user utterance “can i have a cheap restaurant”, from its surface patterns, we can see that it includes explicit semantic information about “price (cheap)” and “target (restaurant)”; however, it also includes hidden semantic information, such as “food” and “seeking”, since the SDS needs to infer that the user wants to “find” some cheap “food”, even though they are not directly observed in the surface patterns. Nonetheless, these implicit semantics are important semantic concepts for domainspecific SDSs. Traditional SLU models use discriminative classifiers (Henderson et al., 2012) to predict whether the predefined slots occur in the utterances or not, ignoring the unobserved concepts and the hidden semantic information. In this paper, we take a rather radical approach: we propose a novel matrix factorization (MF) model for learning latent features for SLU, taking account of additional information such as the word relations, the induced slots, and the slot relations. To further consider the global coherence of induced slots, we combine the MF model with 483 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International </context>
<context position="28156" citStr="Henderson et al., 2012" startWordPosition="4626" endWordPosition="4629">ong all types from Tx and additionally weighted by the estimated probability. The estimated probability smoothes the observed frequency to avoid overfitting due to the smaller dataset. Figure 3 is a simplified example of an automatically derived semantic knowledge graph with the most possible typed dependencies as edges based on the estimated weights. Then the relation weights ˆr(xi, xj) can be obtained by (7) in order to build RDw and RDs matrices. 6 Experiments 6.1 Experimental Setup In this experiment, we used the Cambridge University SLU corpus, previously used on several other SLU tasks (Henderson et al., 2012; Chen et al., 2013a). The domain of the corpus is about restaurant recommendation in Cambridge; subjects were asked to interact with multiple SDSs in an in-car setting. The corpus contains a total number of 2,166 dialogues, including 15,453 utterances (10,571 for self-training and 4,882 for �arg max vx,vc (w,c)∈D P(xi →− t , 2 (9) where C(xi →− t 489 Table 2: The MAP of predicted slots (%); † indicates that the result is significantly better than the Logistic Regression (row (b)) with p &lt; 0.05 in t-test. Approach ASR Manual w/o w/ Explicit w/o w/ Explicit Explicit SVM 32.48 36.62 MLR 33.96 38</context>
<context position="31563" citStr="Henderson et al., 2012" startWordPosition="5182" endWordPosition="5186">l., 2012). Mean average precision (MAP) is the metric for evaluating all utterances. For all experiments, we perform a paired t-test on the AP scores of the results to test the significance. 6.3 Evaluation Results Table 2 shows the MAP performance of predicted slots for all experiments on ASR and manual transcripts. For the first baseline using explicit semantics, we use the observed data to self-train models for predicting the probability of each semantic slot by support vector machine (SVM) with a linear kernel and multinomial logistic regression (MLR) (row (a)-(b)) (Pedregosa et al., 2011; Henderson et al., 2012). It is shown that SVM and MLR perform similarly, and MLR is slightly better than SVM because it has better capability of estimating probabilities. For modeling implicit semantics, two baselines are performed as references, Random (row (c)) and Majority (row (d)), where the former assigns random probabilities for all slots, and the later assigns probabilities for the slots based on their frequency distribution. To improve probability estimation, we further integrate the results from implicit semantics with the better result from explicit approaches, MLR (row (b)), by averaging the probability </context>
</contexts>
<marker>Henderson, Gasic, Thomson, Tsiakoulis, Yu, Young, 2012</marker>
<rawString>Matthew Henderson, Milica Gasic, Blaise Thomson, Pirros Tsiakoulis, Kai Yu, and Steve Young. 2012. Discriminative spoken language understanding using word confusion networks. In Proceedings of SLT, pages 176–181.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frederick Jelinek</author>
</authors>
<title>Statistical methods for speech recognition.</title>
<date>1997</date>
<publisher>MIT press.</publisher>
<contexts>
<context position="7230" citStr="Jelinek, 1997" startWordPosition="1130" endWordPosition="1131">ge (ElKahky et al., 2014; Chen and Rudnicky, 2014). However, most of the studies above do not explicitly learn latent factor representations from the data—while we hypothesize that the better robustness in noisy data can be achieved by explicitly modeling the measurement errors (usually produced by automatic speech recognizers (ASR)) using latent variable models and taking additional local and global semantic constraints into account. Latent Variable Modeling in SLU Early studies on latent variable modeling in speech included the classic hidden Markov model for statistical speech recognition (Jelinek, 1997). Recently, Celikyilmaz et al. (2011) were the first to study the intent detection problem using query logs and a discrete Bayesian latent variable model. In the field of dialogue modeling, the partially observable Markov decision process (POMDP) (Young et al., 2013) model is a popular technique for dialogue management, reducing the cost of handcrafted dialogue managers while producing robustness against speech recognition errors. More recently, Tur et al. (2013) used a semi-supervised LDA model to show improvement on the slot filling task. Also, Zhai and Williams (2014) proposed an unsupervis</context>
</contexts>
<marker>Jelinek, 1997</marker>
<rawString>Frederick Jelinek. 1997. Statistical methods for speech recognition. MIT press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yehuda Koren</author>
<author>Robert Bell</author>
<author>Chris Volinsky</author>
</authors>
<title>Matrix factorization techniques for recommender systems.</title>
<date>2009</date>
<journal>Computer,</journal>
<pages>8--30</pages>
<contexts>
<context position="4494" citStr="Koren et al., 2009" startWordPosition="696" endWordPosition="699">To further consider the global coherence of induced slots, we combine the MF model with 483 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 483–494, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics a knowledge graph propagation based model, fusing both a word-based lexical knowledge graph and a slot-based semantic graph. In fact, as it is shown in the Netflix challenge, MF is credited as the most useful technique for recommendation systems (Koren et al., 2009). Also, the MF model considers the unobserved patterns and estimates their probabilities instead of viewing them as negative examples. However, to the best of our knowledge, the MF technique is not yet well understood in the SLU and SDS communities, and it is not very straight-forward to use MF methods to learn latent feature representations for semantic parsing in SLU. To evaluate the performance of our model, we compare it to standard discriminative SLU baselines, and show that our MF-based model is able to produce strong results in semantic decoding, and the knowledge graph propagation mode</context>
</contexts>
<marker>Koren, Bell, Volinsky, 2009</marker>
<rawString>Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization techniques for recommender systems. Computer, (8):30–37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Omer Levy</author>
<author>Yoav Goldberg</author>
</authors>
<title>Dependencybased word embeddings.</title>
<date>2014</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="11776" citStr="Levy and Goldberg, 2014" startWordPosition="1838" endWordPosition="1841">n Figure 1(a)) (Chen et al., 2013b). Section 4.1 explains the detail of the feature model. In order to consider the additional inter-word and inter-slot relations, we propose a knowledge graph propagation model based on two knowledge graphs, which includes a word relation model (blue block) and a slot relation model (pink block), described in Section 4.2. The method of automatic knowledge graph construction is introduced in Section 5, where we leverage distributed word embeddings associated with typed syntactic dependencies to model the relations (Mikolov et al., 2013b; Mikolov et al., 2013c; Levy and Goldberg, 2014; Chen et al., 2015). Finally, we train the SLU model by learning latent feature vectors for utterances and slot candidates through MF techniques. Combining with a knowledge graph propagation model based on word/slot relations, the trained SLU model estimates the probability that each semantic slot occurs in the testing utterance, and how likely each slot is domain-specific simultaneously. In other words, the SLU model is able to transform the testing utterances into domain-specific semantic representations without human involvement. 4 The Matrix Factorization Approach Considering the benefits</context>
<context position="17377" citStr="Levy and Goldberg, 2014" startWordPosition="2793" endWordPosition="2796">e by use FT LU: can FE Filler: i FT/FE LU: restaurant 1 p(Mu,x = 1 |8u,x) = σ(8u,x) = 486 Figure 3: A simplified example of the automatically derived knowledge graph. • Semantic Relation For modeling word semantic relations, we compute a matrix RSw = [Sim(wi,wj)]|W|×|W|, where Sim(wi,wj) is the cosine similarity between the dependency embeddings of the word patterns wi and wj after normalization. For slot semantic relations, we compute RSs = [Sim(si, sj)]|S|×|S |similarly3. The matrices RSw and RSs model not only the semantic but functional similarity since we use dependency-based embeddings (Levy and Goldberg, 2014). • Dependency Relation Assuming that important semantic slots are usually mutually related to each other, that is, connected by syntactic dependencies, our automatically derived knowledge graphs are able to help model the dependency relations. For word dependency relations, we compute a matrix RD w = [ˆr(wi, wj)]|W |×|W |, where ˆr(wi, wj) measures the dependency between two word patterns wi and wj based on the word-based lexical knowledge graph, and the detail is described in Section 5. For slot dependency relations, we similarly compute RDs = [ˆr(si,sj)]|S|×|S |based on the slotbased semant</context>
<context position="25574" citStr="Levy and Goldberg, 2014" startWordPosition="4182" endWordPosition="4185">ased Embeddings Most neural embeddings use linear bag-of-words contexts, where a window size is defined to produce contexts of the target words (Mikolov et al., 2013c; Mikolov et al., 2013b; Mikolov et al., 2013a). However, some important contexts may be missing due to smaller windows, while larger windows capture broad topical content. A dependency-based embedding approach was proposed to derive contexts based on the syntactic relations the word participates in for training embeddings, where the embeddings are less topical but offer more functional similarity compared to original embeddings (Levy and Goldberg, 2014). Table 1 shows the extracted dependency-based contexts for each target word from the example in Figure 4, where headwords and their dependents can form the contexts by following the arc on a word in the dependency tree, and −1 denotes the directionality of the dependency. After replacing original bag-of-words contexts with dependencybased contexts, we can train dependency-based embeddings for all target words (Yih et al., 2014; Bordes et al., 2011; Bordes et al., 2013). For training dependency-based word embeddings, each target x is associated with a vector vx ∈ Rd and each context c is repre</context>
</contexts>
<marker>Levy, Goldberg, 2014</marker>
<rawString>Omer Levy and Yoav Goldberg. 2014. Dependencybased word embeddings. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Kai Chen</author>
<author>Greg Corrado</author>
<author>Jeffrey Dean</author>
</authors>
<title>Efficient estimation of word representations in vector space.</title>
<date>2013</date>
<booktitle>In Proceedings of Workshop at ICLR.</booktitle>
<contexts>
<context position="11727" citStr="Mikolov et al., 2013" startWordPosition="1830" endWordPosition="1833">ugh frame-semantic parsing (the yellow block in Figure 1(a)) (Chen et al., 2013b). Section 4.1 explains the detail of the feature model. In order to consider the additional inter-word and inter-slot relations, we propose a knowledge graph propagation model based on two knowledge graphs, which includes a word relation model (blue block) and a slot relation model (pink block), described in Section 4.2. The method of automatic knowledge graph construction is introduced in Section 5, where we leverage distributed word embeddings associated with typed syntactic dependencies to model the relations (Mikolov et al., 2013b; Mikolov et al., 2013c; Levy and Goldberg, 2014; Chen et al., 2015). Finally, we train the SLU model by learning latent feature vectors for utterances and slot candidates through MF techniques. Combining with a knowledge graph propagation model based on word/slot relations, the trained SLU model estimates the probability that each semantic slot occurs in the testing utterance, and how likely each slot is domain-specific simultaneously. In other words, the SLU model is able to transform the testing utterances into domain-specific semantic representations without human involvement. 4 The Matri</context>
<context position="25115" citStr="Mikolov et al., 2013" startWordPosition="4112" endWordPosition="4115">as a head and xj as a dependent. We propose a scoring function for r(·) using dependency-based embeddings. 488 Table 1: The example contexts extracted for training dependency-based word/slot embeddings. Typed Dependency Relation Target Word Contexts Word hrestaurant, AMOD, cheapi restaurant cheap/AMOD cheap restaurant/AMOD−1 Slot hlocale by use, AMOD, expensivenessi locale by use expensiveness/AMOD expansiveness locale by use/AMOD−1 5.1.1 Dependency-Based Embeddings Most neural embeddings use linear bag-of-words contexts, where a window size is defined to produce contexts of the target words (Mikolov et al., 2013c; Mikolov et al., 2013b; Mikolov et al., 2013a). However, some important contexts may be missing due to smaller windows, while larger windows capture broad topical content. A dependency-based embedding approach was proposed to derive contexts based on the syntactic relations the word participates in for training embeddings, where the embeddings are less topical but offer more functional similarity compared to original embeddings (Levy and Goldberg, 2014). Table 1 shows the extracted dependency-based contexts for each target word from the example in Figure 4, where headwords and their dependen</context>
</contexts>
<marker>Mikolov, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013a. Efficient estimation of word representations in vector space. In Proceedings of Workshop at ICLR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Ilya Sutskever</author>
<author>Kai Chen</author>
<author>Greg S Corrado</author>
<author>Jeff Dean</author>
</authors>
<title>Distributed representations of words and phrases and their compositionality.</title>
<date>2013</date>
<booktitle>In Proceedings of Advances in Neural Information Processing Systems,</booktitle>
<pages>3111--3119</pages>
<contexts>
<context position="11727" citStr="Mikolov et al., 2013" startWordPosition="1830" endWordPosition="1833">ugh frame-semantic parsing (the yellow block in Figure 1(a)) (Chen et al., 2013b). Section 4.1 explains the detail of the feature model. In order to consider the additional inter-word and inter-slot relations, we propose a knowledge graph propagation model based on two knowledge graphs, which includes a word relation model (blue block) and a slot relation model (pink block), described in Section 4.2. The method of automatic knowledge graph construction is introduced in Section 5, where we leverage distributed word embeddings associated with typed syntactic dependencies to model the relations (Mikolov et al., 2013b; Mikolov et al., 2013c; Levy and Goldberg, 2014; Chen et al., 2015). Finally, we train the SLU model by learning latent feature vectors for utterances and slot candidates through MF techniques. Combining with a knowledge graph propagation model based on word/slot relations, the trained SLU model estimates the probability that each semantic slot occurs in the testing utterance, and how likely each slot is domain-specific simultaneously. In other words, the SLU model is able to transform the testing utterances into domain-specific semantic representations without human involvement. 4 The Matri</context>
<context position="25115" citStr="Mikolov et al., 2013" startWordPosition="4112" endWordPosition="4115">as a head and xj as a dependent. We propose a scoring function for r(·) using dependency-based embeddings. 488 Table 1: The example contexts extracted for training dependency-based word/slot embeddings. Typed Dependency Relation Target Word Contexts Word hrestaurant, AMOD, cheapi restaurant cheap/AMOD cheap restaurant/AMOD−1 Slot hlocale by use, AMOD, expensivenessi locale by use expensiveness/AMOD expansiveness locale by use/AMOD−1 5.1.1 Dependency-Based Embeddings Most neural embeddings use linear bag-of-words contexts, where a window size is defined to produce contexts of the target words (Mikolov et al., 2013c; Mikolov et al., 2013b; Mikolov et al., 2013a). However, some important contexts may be missing due to smaller windows, while larger windows capture broad topical content. A dependency-based embedding approach was proposed to derive contexts based on the syntactic relations the word participates in for training embeddings, where the embeddings are less topical but offer more functional similarity compared to original embeddings (Levy and Goldberg, 2014). Table 1 shows the extracted dependency-based contexts for each target word from the example in Figure 4, where headwords and their dependen</context>
</contexts>
<marker>Mikolov, Sutskever, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013b. Distributed representations of words and phrases and their compositionality. In Proceedings of Advances in Neural Information Processing Systems, pages 3111–3119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Wen-tau Yih</author>
<author>Geoffrey Zweig</author>
</authors>
<title>Linguistic regularities in continuous space word representations.</title>
<date>2013</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>746--751</pages>
<publisher>Citeseer.</publisher>
<contexts>
<context position="11727" citStr="Mikolov et al., 2013" startWordPosition="1830" endWordPosition="1833">ugh frame-semantic parsing (the yellow block in Figure 1(a)) (Chen et al., 2013b). Section 4.1 explains the detail of the feature model. In order to consider the additional inter-word and inter-slot relations, we propose a knowledge graph propagation model based on two knowledge graphs, which includes a word relation model (blue block) and a slot relation model (pink block), described in Section 4.2. The method of automatic knowledge graph construction is introduced in Section 5, where we leverage distributed word embeddings associated with typed syntactic dependencies to model the relations (Mikolov et al., 2013b; Mikolov et al., 2013c; Levy and Goldberg, 2014; Chen et al., 2015). Finally, we train the SLU model by learning latent feature vectors for utterances and slot candidates through MF techniques. Combining with a knowledge graph propagation model based on word/slot relations, the trained SLU model estimates the probability that each semantic slot occurs in the testing utterance, and how likely each slot is domain-specific simultaneously. In other words, the SLU model is able to transform the testing utterances into domain-specific semantic representations without human involvement. 4 The Matri</context>
<context position="25115" citStr="Mikolov et al., 2013" startWordPosition="4112" endWordPosition="4115">as a head and xj as a dependent. We propose a scoring function for r(·) using dependency-based embeddings. 488 Table 1: The example contexts extracted for training dependency-based word/slot embeddings. Typed Dependency Relation Target Word Contexts Word hrestaurant, AMOD, cheapi restaurant cheap/AMOD cheap restaurant/AMOD−1 Slot hlocale by use, AMOD, expensivenessi locale by use expensiveness/AMOD expansiveness locale by use/AMOD−1 5.1.1 Dependency-Based Embeddings Most neural embeddings use linear bag-of-words contexts, where a window size is defined to produce contexts of the target words (Mikolov et al., 2013c; Mikolov et al., 2013b; Mikolov et al., 2013a). However, some important contexts may be missing due to smaller windows, while larger windows capture broad topical content. A dependency-based embedding approach was proposed to derive contexts based on the syntactic relations the word participates in for training embeddings, where the embeddings are less topical but offer more functional similarity compared to original embeddings (Levy and Goldberg, 2014). Table 1 shows the extracted dependency-based contexts for each target word from the example in Figure 4, where headwords and their dependen</context>
</contexts>
<marker>Mikolov, Yih, Zweig, 2013</marker>
<rawString>Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig. 2013c. Linguistic regularities in continuous space word representations. In HLT-NAACL, pages 746– 751. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian Pedregosa</author>
<author>Alexandre Gramfort Ga¨el Varoquaux</author>
<author>Vincent Michel</author>
<author>Bertrand</author>
</authors>
<title>Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer,</title>
<date>2011</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>12--2825</pages>
<location>Ron Weiss, Vincent Dubourg, et</location>
<marker>Pedregosa, Ga¨el Varoquaux, Michel, Bertrand, 2011</marker>
<rawString>Fabian Pedregosa, Ga¨el Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. 2011. Scikit-learn: Machine learning in python. The Journal of Machine Learning Research, 12:2825–2830.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Pieraccini</author>
<author>Evelyne Tzoukermann</author>
<author>Zakhar Gorelov</author>
<author>J Gauvain</author>
<author>Esther Levin</author>
<author>Chin-Hui Lee</author>
<author>Jay G Wilpon</author>
</authors>
<title>A speech understanding system based on statistical representation of semantics.</title>
<date>1992</date>
<booktitle>In Proceedings of 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP),</booktitle>
<volume>1</volume>
<pages>193--196</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="1731" citStr="Pieraccini et al., 1992" startWordPosition="257" endWordPosition="260">owledge graph propagation model based on a slot-based semantic graph and a word-based lexical graph. Our experiments show that the proposed MF approaches produce better SLU models that are able to predict semantic slots and word patterns taking into account their relations and domain-specificity in a joint manner. 1 Introduction A key component of a spoken dialogue system (SDS) is the spoken language understanding (SLU) module—it parses the users’ utterances into semantic representations; for example, the utterance “find a cheap restaurant” can be parsed into (price=cheap, target=restaurant) (Pieraccini et al., 1992). To design the SLU module of a SDS, most previous studies relied on predefined slots1 for training the decoder (Seneff, 1992; Dowding 1A slot is defined as a basic semantic unit in SLU, such as “price” and “target” in the example. et al., 1993; Gupta et al., 2006; Bohus and Rudnicky, 2009). However, these predefined semantic slots may bias the subsequent data collection process, and the cost of manually labeling utterances for updating the ontology is expensive (Wang et al., 2012). In recent years, this problem led to the development of unsupervised SLU techniques (Heck and Hakkani-T¨ur, 2012</context>
</contexts>
<marker>Pieraccini, Tzoukermann, Gorelov, Gauvain, Levin, Lee, Wilpon, 1992</marker>
<rawString>Roberto Pieraccini, Evelyne Tzoukermann, Zakhar Gorelov, J Gauvain, Esther Levin, Chin-Hui Lee, and Jay G Wilpon. 1992. A speech understanding system based on statistical representation of semantics. In Proceedings of 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), volume 1, pages 193–196. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steffen Rendle</author>
<author>Christoph Freudenthaler</author>
<author>Zeno Gantner</author>
<author>Lars Schmidt-Thieme</author>
</authors>
<title>BPR: Bayesian personalized ranking from implicit feedback.</title>
<date>2009</date>
<booktitle>In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence,</booktitle>
<pages>452--461</pages>
<publisher>AUAI Press.</publisher>
<contexts>
<context position="21464" citStr="Rendle et al., 2009" startWordPosition="3494" endWordPosition="3497">omp nsubj dobj det amod p(θ |Mu) (5) p(Mu |θ)p(θ) � ln p(Mu |θ) − λθ, 5 Knowledge Graph Construction = arg max θ uEU where Mu is the vector corresponding to the utterance u from Mu,x in (1), because we assume that each utterance is independent of others. To avoid treating unobserved facts as designed negative facts, we consider our positive-only data as implicit feedback. Bayesian Personalized Ranking (BPR) is an optimization criterion that learns from implicit feedback for MF, which uses a variant of the ranking: giving observed true facts higher scores than unobserved (true or false) facts (Rendle et al., 2009). Riedel et al. (2013) also showed that BPR learns the implicit relations for improving the relation extraction task. 4.4.1 Objective Function To estimate the parameters in (5), we create a dataset of ranked pairs from M in (4): for each utterance u and each observed fact f+ = (u, x+), where Mu,x &gt; δ, we choose each word pattern/slot x− such that f− = (u, x−), where Mu,x &lt; δ, which refers to the word pattern/slot we have not observed to be in utterance u. That is, we construct the observed data O from M. Then for each pair of facts f+ and f−, we want to model p(f+) &gt; p(f−) and hence θf+ &gt; θf− </context>
<context position="23785" citStr="Rendle et al., 2009" startWordPosition="3894" endWordPosition="3898">between slots. For example, (restaurant, AMOD, cheap) from Tw is transformed into (locale by use, AMOD, expensiveness) for building Ts, because both sides of the non-dotted line are parsed as slot-fillers by SEMAFOR. � ln p(Mu |θ) = � � lnσ(θf+ − θf−). (6) uEU f+EO f−0O 5.1 Relation Weight Estimation The BPR objective is an approximation to the per utterance AUC (area under the ROC curve), which directly correlates to what we want to achieve – well-ranked semantic slots per utterance. 4.4.2 Optimization To maximize the objective in (6), we employ a stochastic gradient descent (SGD) algorithm (Rendle et al., 2009). For each randomly sampled observed fact (u, x+), we sample an unobserved fact (u, x− ), which results in |O |fact pairs (f−, f+). For each pair, we perform an SGD update using the gradient of the corresponding objective function for matrix factorization (Gantner et al., 2011). For the edges in the knowledge graphs, we model the relations between two connected nodes xi and xj as ˆr(xi, xj), where x is either a slot s or a word pattern w. Since the weights are measured based on the relations between nodes regardless of the directions, we combine the scores of two directional dependencies: ˆr(x</context>
</contexts>
<marker>Rendle, Freudenthaler, Gantner, Schmidt-Thieme, 2009</marker>
<rawString>Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian personalized ranking from implicit feedback. In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, pages 452–461. AUAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Limin Yao</author>
<author>Andrew McCallum</author>
<author>Benjamin M Marlin</author>
</authors>
<title>Relation extraction with matrix factorization and universal schemas.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<pages>74--84</pages>
<contexts>
<context position="21486" citStr="Riedel et al. (2013)" startWordPosition="3498" endWordPosition="3501">d p(θ |Mu) (5) p(Mu |θ)p(θ) � ln p(Mu |θ) − λθ, 5 Knowledge Graph Construction = arg max θ uEU where Mu is the vector corresponding to the utterance u from Mu,x in (1), because we assume that each utterance is independent of others. To avoid treating unobserved facts as designed negative facts, we consider our positive-only data as implicit feedback. Bayesian Personalized Ranking (BPR) is an optimization criterion that learns from implicit feedback for MF, which uses a variant of the ranking: giving observed true facts higher scores than unobserved (true or false) facts (Rendle et al., 2009). Riedel et al. (2013) also showed that BPR learns the implicit relations for improving the relation extraction task. 4.4.1 Objective Function To estimate the parameters in (5), we create a dataset of ranked pairs from M in (4): for each utterance u and each observed fact f+ = (u, x+), where Mu,x &gt; δ, we choose each word pattern/slot x− such that f− = (u, x−), where Mu,x &lt; δ, which refers to the word pattern/slot we have not observed to be in utterance u. That is, we construct the observed data O from M. Then for each pair of facts f+ and f−, we want to model p(f+) &gt; p(f−) and hence θf+ &gt; θf− according to (1). BPR </context>
</contexts>
<marker>Riedel, Yao, McCallum, Marlin, 2013</marker>
<rawString>Sebastian Riedel, Limin Yao, Andrew McCallum, and Benjamin M Marlin. 2013. Relation extraction with matrix factorization and universal schemas. In Proceedings of NAACL-HLT, pages 74–84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephanie Seneff</author>
</authors>
<title>TINA: A natural language system for spoken language applications.</title>
<date>1992</date>
<booktitle>Computational linguistics,</booktitle>
<pages>18--1</pages>
<contexts>
<context position="1856" citStr="Seneff, 1992" startWordPosition="280" endWordPosition="281">ed MF approaches produce better SLU models that are able to predict semantic slots and word patterns taking into account their relations and domain-specificity in a joint manner. 1 Introduction A key component of a spoken dialogue system (SDS) is the spoken language understanding (SLU) module—it parses the users’ utterances into semantic representations; for example, the utterance “find a cheap restaurant” can be parsed into (price=cheap, target=restaurant) (Pieraccini et al., 1992). To design the SLU module of a SDS, most previous studies relied on predefined slots1 for training the decoder (Seneff, 1992; Dowding 1A slot is defined as a basic semantic unit in SLU, such as “price” and “target” in the example. et al., 1993; Gupta et al., 2006; Bohus and Rudnicky, 2009). However, these predefined semantic slots may bias the subsequent data collection process, and the cost of manually labeling utterances for updating the ontology is expensive (Wang et al., 2012). In recent years, this problem led to the development of unsupervised SLU techniques (Heck and Hakkani-T¨ur, 2012; Heck et al., 2013; Chen et al., 2013b; Chen et al., 2014b). In particular, Chen et al. (2013b) proposed a frame-semantics b</context>
</contexts>
<marker>Seneff, 1992</marker>
<rawString>Stephanie Seneff. 1992. TINA: A natural language system for spoken language applications. Computational linguistics, 18(1):61–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Skrondal</author>
<author>Sophia Rabe-Hesketh</author>
</authors>
<title>Generalized latent variable modeling: Multilevel, longitudinal, and structural equation models.</title>
<date>2004</date>
<publisher>Crc Press.</publisher>
<contexts>
<context position="2690" citStr="Skrondal and Rabe-Hesketh, 2004" startWordPosition="414" endWordPosition="417"> slots may bias the subsequent data collection process, and the cost of manually labeling utterances for updating the ontology is expensive (Wang et al., 2012). In recent years, this problem led to the development of unsupervised SLU techniques (Heck and Hakkani-T¨ur, 2012; Heck et al., 2013; Chen et al., 2013b; Chen et al., 2014b). In particular, Chen et al. (2013b) proposed a frame-semantics based framework for automatically inducing semantic slots given raw audios. However, these approaches generally do not explicitly learn the latent factor representations to model the measurement errors (Skrondal and Rabe-Hesketh, 2004), nor do they jointly consider the complex lexical, syntactic, and semantic relations among words, slots, and utterances. Another challenge of SLU is the inference of the hidden semantics. Considering the user utterance “can i have a cheap restaurant”, from its surface patterns, we can see that it includes explicit semantic information about “price (cheap)” and “target (restaurant)”; however, it also includes hidden semantic information, such as “food” and “seeking”, since the SDS needs to infer that the user wants to “find” some cheap “food”, even though they are not directly observed in the </context>
</contexts>
<marker>Skrondal, Rabe-Hesketh, 2004</marker>
<rawString>Anders Skrondal and Sophia Rabe-Hesketh. 2004. Generalized latent variable modeling: Multilevel, longitudinal, and structural equation models. Crc Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>John Bauer</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Parsing with compositional vector grammars.</title>
<date>2013</date>
<booktitle>In Proceedings of the ACL conference. Citeseer.</booktitle>
<contexts>
<context position="29927" citStr="Socher et al., 2013" startWordPosition="4923" endWordPosition="4926">htly more native than non-native speakers. The vocabulary size is 1868. An ASR system was used to transcribe the speech; the word error rate was reported as 37%. There are 10 slots created by domain experts: addr, area, food, name, phone, postcode, price range, signature, task, and type. For parameter setting, the weights for balancing feature models and propagation models, α and Q, are set as 0.5 to give the same influence, and the threshold for defining the unobserved facts δ is set as 0.5 for all experiments. We use the Stanford Parser5 to obtain the collapsed typed syntactic dependencies (Socher et al., 2013) and set the dimensionality of embeddings d = 300 in all experiments. 6.2 Evaluation Metrics To evaluate the accuracy of the automatically decoded slots, we measure their quality as the proximity between predicted slots and reference slots. Figure 5 shows the mappings that indicate semantically related induced slots and reference slots (Chen et al., 2013b). To eliminate the influence of threshold selection when predicting semantic slots, in the following 5http://nlp.stanford.edu/software/lex-parser. shtml metrics, we take the whole ranking list into account and evaluate the performance by the </context>
</contexts>
<marker>Socher, Bauer, Manning, Ng, 2013</marker>
<rawString>Richard Socher, John Bauer, Christopher D Manning, and Andrew Y Ng. 2013. Parsing with compositional vector grammars. In Proceedings of the ACL conference. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gokhan Tur</author>
<author>Dilek Z Hakkani-T¨ur</author>
<author>Dustin Hillard</author>
<author>Asli Celikyilmaz</author>
</authors>
<title>Towards unsupervised spoken language understanding: Exploiting query click logs for slot filling.</title>
<date>2011</date>
<booktitle>In Proceedings of INTERSPEECH,</booktitle>
<pages>1293--1296</pages>
<marker>Tur, Hakkani-T¨ur, Hillard, Celikyilmaz, 2011</marker>
<rawString>Gokhan Tur, Dilek Z Hakkani-T¨ur, Dustin Hillard, and Asli Celikyilmaz. 2011. Towards unsupervised spoken language understanding: Exploiting query click logs for slot filling. In Proceedings of INTERSPEECH, pages 1293–1296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gokhan Tur</author>
<author>Minwoo Jeong</author>
<author>Ye-Yi Wang</author>
<author>Dilek Hakkani-T¨ur</author>
<author>Larry P Heck</author>
</authors>
<title>Exploiting the semantic web for unsupervised natural language semantic parsing.</title>
<date>2012</date>
<booktitle>In Proceedings of INTERSPEECH.</booktitle>
<marker>Tur, Jeong, Wang, Hakkani-T¨ur, Heck, 2012</marker>
<rawString>Gokhan Tur, Minwoo Jeong, Ye-Yi Wang, Dilek Hakkani-T¨ur, and Larry P Heck. 2012. Exploiting the semantic web for unsupervised natural language semantic parsing. In Proceedings of INTERSPEECH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gokhan Tur</author>
<author>Asli Celikyilmaz</author>
<author>Dilek HakkaniTur</author>
</authors>
<title>Latent semantic modeling for slot filling in conversational understanding.</title>
<date>2013</date>
<booktitle>In Proceedings of 2013 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),</booktitle>
<pages>8307--8311</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="7697" citStr="Tur et al. (2013)" startWordPosition="1202" endWordPosition="1205">in SLU Early studies on latent variable modeling in speech included the classic hidden Markov model for statistical speech recognition (Jelinek, 1997). Recently, Celikyilmaz et al. (2011) were the first to study the intent detection problem using query logs and a discrete Bayesian latent variable model. In the field of dialogue modeling, the partially observable Markov decision process (POMDP) (Young et al., 2013) model is a popular technique for dialogue management, reducing the cost of handcrafted dialogue managers while producing robustness against speech recognition errors. More recently, Tur et al. (2013) used a semi-supervised LDA model to show improvement on the slot filling task. Also, Zhai and Williams (2014) proposed an unsupervised model for connecting words with latent states in HMMs using topic models, obtaining interesting qualitative and quantitative results. However, for unsupervised learning for SLU, it is not obvious how to incorporate additional information in the HMMs. To the best of our knowledge, this paper is the first to consider MF techniques for learning latent feature representations in unsupervised SLU, taking various local and global lexical, syntactic, and semantic inf</context>
</contexts>
<marker>Tur, Celikyilmaz, HakkaniTur, 2013</marker>
<rawString>Gokhan Tur, Asli Celikyilmaz, and Dilek HakkaniTur. 2013. Latent semantic modeling for slot filling in conversational understanding. In Proceedings of 2013 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 8307–8311. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Yang Wang</author>
<author>Dan Bohus</author>
<author>Ece Kamar</author>
<author>Eric Horvitz</author>
</authors>
<title>Crowdsourcing the acquisition of natural language corpora: Methods and observations.</title>
<date>2012</date>
<booktitle>In Proceedings of SLT,</booktitle>
<pages>73--78</pages>
<contexts>
<context position="2217" citStr="Wang et al., 2012" startWordPosition="340" endWordPosition="343">; for example, the utterance “find a cheap restaurant” can be parsed into (price=cheap, target=restaurant) (Pieraccini et al., 1992). To design the SLU module of a SDS, most previous studies relied on predefined slots1 for training the decoder (Seneff, 1992; Dowding 1A slot is defined as a basic semantic unit in SLU, such as “price” and “target” in the example. et al., 1993; Gupta et al., 2006; Bohus and Rudnicky, 2009). However, these predefined semantic slots may bias the subsequent data collection process, and the cost of manually labeling utterances for updating the ontology is expensive (Wang et al., 2012). In recent years, this problem led to the development of unsupervised SLU techniques (Heck and Hakkani-T¨ur, 2012; Heck et al., 2013; Chen et al., 2013b; Chen et al., 2014b). In particular, Chen et al. (2013b) proposed a frame-semantics based framework for automatically inducing semantic slots given raw audios. However, these approaches generally do not explicitly learn the latent factor representations to model the measurement errors (Skrondal and Rabe-Hesketh, 2004), nor do they jointly consider the complex lexical, syntactic, and semantic relations among words, slots, and utterances. Anoth</context>
</contexts>
<marker>Wang, Bohus, Kamar, Horvitz, 2012</marker>
<rawString>William Yang Wang, Dan Bohus, Ece Kamar, and Eric Horvitz. 2012. Crowdsourcing the acquisition of natural language corpora: Methods and observations. In Proceedings of SLT, pages 73–78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lu Wang</author>
<author>Dilek Hakkani-T¨ur</author>
<author>Larry Heck</author>
</authors>
<title>Leveraging semantic web search and browse sessions for multi-turn spoken dialog systems.</title>
<date>2014</date>
<booktitle>In Proceedings of 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),</booktitle>
<pages>4082--4086</pages>
<publisher>IEEE.</publisher>
<marker>Wang, Hakkani-T¨ur, Heck, 2014</marker>
<rawString>Lu Wang, Dilek Hakkani-T¨ur, and Larry Heck. 2014. Leveraging semantic web search and browse sessions for multi-turn spoken dialog systems. In Proceedings of 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 4082–4086. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wen-tau Yih</author>
<author>Xiaodong He</author>
<author>Christopher Meek</author>
</authors>
<title>Semantic parsing for single-relation question answering.</title>
<date>2014</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="26005" citStr="Yih et al., 2014" startWordPosition="4249" endWordPosition="4252">ns the word participates in for training embeddings, where the embeddings are less topical but offer more functional similarity compared to original embeddings (Levy and Goldberg, 2014). Table 1 shows the extracted dependency-based contexts for each target word from the example in Figure 4, where headwords and their dependents can form the contexts by following the arc on a word in the dependency tree, and −1 denotes the directionality of the dependency. After replacing original bag-of-words contexts with dependencybased contexts, we can train dependency-based embeddings for all target words (Yih et al., 2014; Bordes et al., 2011; Bordes et al., 2013). For training dependency-based word embeddings, each target x is associated with a vector vx ∈ Rd and each context c is represented as a context vector vc ∈ Rd, where d is the embedding dimensionality. We learn vector representations for both targets and contexts such that the dot product vx · vc associated with “good” targetcontext pairs belonging to the training data D is maximized, leading to the objective function: 1 log 1 + exp(−vc · vx), (8) which can be trained using stochastic-gradient updates (Levy and Goldberg, 2014). Then we can obtain the</context>
</contexts>
<marker>Yih, He, Meek, 2014</marker>
<rawString>Wen-tau Yih, Xiaodong He, and Christopher Meek. 2014. Semantic parsing for single-relation question answering. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve Young</author>
<author>Milica Gasic</author>
<author>Blaise Thomson</author>
<author>Jason D Williams</author>
</authors>
<title>POMDP-based statistical spoken dialog systems: A review.</title>
<date>2013</date>
<booktitle>Proceedings of the IEEE,</booktitle>
<volume>101</volume>
<issue>5</issue>
<contexts>
<context position="7497" citStr="Young et al., 2013" startWordPosition="1171" endWordPosition="1174">asurement errors (usually produced by automatic speech recognizers (ASR)) using latent variable models and taking additional local and global semantic constraints into account. Latent Variable Modeling in SLU Early studies on latent variable modeling in speech included the classic hidden Markov model for statistical speech recognition (Jelinek, 1997). Recently, Celikyilmaz et al. (2011) were the first to study the intent detection problem using query logs and a discrete Bayesian latent variable model. In the field of dialogue modeling, the partially observable Markov decision process (POMDP) (Young et al., 2013) model is a popular technique for dialogue management, reducing the cost of handcrafted dialogue managers while producing robustness against speech recognition errors. More recently, Tur et al. (2013) used a semi-supervised LDA model to show improvement on the slot filling task. Also, Zhai and Williams (2014) proposed an unsupervised model for connecting words with latent states in HMMs using topic models, obtaining interesting qualitative and quantitative results. However, for unsupervised learning for SLU, it is not obvious how to incorporate additional information in the HMMs. To the best o</context>
</contexts>
<marker>Young, Gasic, Thomson, Williams, 2013</marker>
<rawString>Steve Young, Milica Gasic, Blaise Thomson, and Jason D Williams. 2013. POMDP-based statistical spoken dialog systems: A review. Proceedings of the IEEE, 101(5):1160–1179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ke Zhai</author>
<author>Jason D Williams</author>
</authors>
<title>Discovering latent structure in task-oriented dialogues.</title>
<date>2014</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="7807" citStr="Zhai and Williams (2014)" startWordPosition="1221" endWordPosition="1224"> statistical speech recognition (Jelinek, 1997). Recently, Celikyilmaz et al. (2011) were the first to study the intent detection problem using query logs and a discrete Bayesian latent variable model. In the field of dialogue modeling, the partially observable Markov decision process (POMDP) (Young et al., 2013) model is a popular technique for dialogue management, reducing the cost of handcrafted dialogue managers while producing robustness against speech recognition errors. More recently, Tur et al. (2013) used a semi-supervised LDA model to show improvement on the slot filling task. Also, Zhai and Williams (2014) proposed an unsupervised model for connecting words with latent states in HMMs using topic models, obtaining interesting qualitative and quantitative results. However, for unsupervised learning for SLU, it is not obvious how to incorporate additional information in the HMMs. To the best of our knowledge, this paper is the first to consider MF techniques for learning latent feature representations in unsupervised SLU, taking various local and global lexical, syntactic, and semantic information into account. 3 The Proposed Framework This paper introduces a matrix factorization technique for uns</context>
</contexts>
<marker>Zhai, Williams, 2014</marker>
<rawString>Ke Zhai and Jason D Williams. 2014. Discovering latent structure in task-oriented dialogues. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>