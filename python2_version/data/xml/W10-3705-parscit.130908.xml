<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002972">
<title confidence="0.966773">
Sentence Analysis and Collocation Identification
</title>
<author confidence="0.99915">
Eric Wehrli, Violeta Seretan, Luka Nerima
</author>
<affiliation confidence="0.997923">
Language Technology Laboratory
University of Geneva
</affiliation>
<email confidence="0.983793">
{Eric.Wehrli, Violeta.Seretan, Luka.Nerima}@unige.ch
</email>
<sectionHeader confidence="0.993583" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999902285714286">
Identifying collocations in a sentence, in
order to ensure their proper processing in
subsequent applications, and performing
the syntactic analysis of the sentence are
interrelated processes. Syntactic informa-
tion is crucial for detecting collocations,
and vice versa, collocational information
is useful for parsing. This article describes
an original approach in which collocations
are identified in a sentence as soon as pos-
sible during the analysis of that sentence,
rather than at the end of the analysis, as in
our previous work. In this way, priority is
given to parsing alternatives involving col-
locations, and collocational information
guide the parser through the maze of alter-
natives. This solution was shown to lead
to substantial improvements in the perfor-
mance of both tasks (collocation identifi-
cation and parsing), and in that of a sub-
sequent task (machine translation).
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.986261790697674">
Collocations1 constitute a central language phe-
nomenon and an impressive amount of work has
been devoted over the past decades to the automa-
tic acquisition of collocational resources – as at-
tested, among others, by initiatives like the MWE
2008 shared task aimed at creating a repository of
reference data (Gr´egoire et al., 2008). However,
little or no reference exist in the literature about
1We adopt the lexicographic understanding for the term
collocation (Benson et al., 1986), as opposed to the British
contextualist tradition focused on statistical co-occurrence
(Firth, 1957; Sinclair, 1991).
the actual use made of these resources in other
NLP applications.
In this paper, we consider the particular appli-
cation of syntactic parsing. Just as other types of
multi-word expressions (henceforth, MWEs), col-
locations are problematic for parsing because they
have to be recognised and treated as a whole, ra-
ther than compositionally, i.e., in a word by word
fashion (Sag et al., 2002). The standard approach
in dealing with MWEs in parsing is to apply
a “words-with-spaces” preprocessing step, which
marks the MWEs in the input sentence as units
which will later be integrated as single blocks in
the parse tree built during analysis.
We argue that such an approach, albeit suffi-
ciently appropriate for some subtypes of MWEs2,
is not really adequate for processing colloca-
tions. Unlike other expressions that are fixed or
semi-fixed3, collocations do not allow a “words-
with-spaces” treatment because they have a high
morpho-syntactic flexibility.
There is no systematic restriction, for instance,
on the number of forms a lexical item (such as a
verb) may have in a collocation, on the order of
items in a collocation, or on the number of words
that may intervene between these items. Collo-
cations are situated at the intersection of lexicon
and grammar; therefore, they cannot be accounted
for merely by the lexical component of a parsing
system, but have to be integrated to the grammati-
cal component as well, as the parser has to consi-
</bodyText>
<footnote confidence="0.892342">
2Sag et al. (2002) thoroughly discusses the extend to
which a “words-with-spaces” approach is appropriate for dif-
ferent kinds of MWEs.
3For instance, compound words: by and large, ad hoc;
named entities: New York City; and non-decomposable
idioms: shoot the breeze.
</footnote>
<page confidence="0.973167">
28
</page>
<note confidence="0.8650935">
Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 28–36,
Beijing, August 2010
</note>
<bodyText confidence="0.999845325581396">
der all the possible syntactic realisations of collo-
cations.
Alternatively, a post-processing approach (such
as the one we pursued previously in Wehrli et
al. (2009b)) would identify collocations after the
syntactic analysis has been performed, and out-
put a parse tree in which collocational relations
are highlighted between the composing items, in
order to inform the subsequent processing appli-
cations (e.g., a machine translation application).
Again, this solution is not fully appropriate, and
the reason lies with the important observation that
prior collocational knowledge is highly relevant
for parsing. Collocational restrictions are, along
with other types of information like selectional
preferences and subcategorization frames, a major
means of structural disambiguation. Collocational
relations between the words in a sentence proved
very helpful in selecting the most plausible among
all the possible parse trees for a sentence (Hindle
and Rooth, 1993; Alshawi and Carter, 1994; Ber-
thouzoz and Merlo, 1997; Wehrli, 2000). Hence,
the question whether collocations should be iden-
tified in a sentence before or after parsing is not an
easy one. The previous literature on parsing and
collocations fails to provide insightful details on
how this circular issue is (or can be) solved.
In this paper, we argue that the identification of
collocations and the construction of a parse tree
are interrelated processes, that must be accounted
for simultaneously. We present a processing mo-
del in which collocations, if present in a lexicon,
are identified in the input sentence during the ana-
lysis of that sentence. At the same time, they are
used to rank competing parsing hypotheses.
The paper is organised as follows. Section 2
reviews the previous work on the interrelation
between parsing and processing of collocations
(or, more generally, MWEs). Section 3 introduces
our approach, and section 4 evaluates it by compa-
ring it against the standard non-simultaneous ap-
proach. Section 5 provides concluding remarks
and presents directions for future work.
</bodyText>
<sectionHeader confidence="0.999804" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999973411764706">
Extending the lexical component of a parser with
MWEs was proved to contribute to a significant
improvement of the coverage and accuracy of par-
sing results. For instance, Brun (1998) compared
the coverage of a French parser with and wi-
thout terminology recognition in the preproces-
sing stage. She found that the integration of 210
nominal terms in the preprocessing components of
the parser resulted in a significant reduction of the
number of alternative parses (from an average of
4.21 to 2.79). The eliminated parses were found
to be semantically undesirable. No valid analy-
sis were ruled out. Similarly, Zhang and Kor-
doni (2006) extended a lexicon with 373 additio-
nal MWE lexical entries and obtained a significant
increase in the coverage of an English grammar
(14.4%, from 4.3% to 18.7%).
In the cases mentioned above, a “words-with-
spaces” approach was used. In contrast, Ale-
gria et al. (2004) and Villavicencio et al. (2007)
adopted a compositional approach to the enco-
ding of MWEs, able to capture more morpho-
syntactically flexible MWEs. Alegria et al. (2004)
showed that by using a MWE processor in the pre-
processing stage of their parser (in development)
for Basque, a significant improvement in the POS-
tagging precision is obtained. Villavicencio et al.
(2007) found that the addition of 21 new MWEs
to the lexicon led to a significant increase in the
grammar coverage (from 7.1% to 22.7%), without
altering the grammar accuracy.
An area of intensive research in parsing is
concerned with the use of lexical preferences, co-
occurrence frequencies, collocations, and contex-
tually similar words for PP attachment disambi-
guation. Thus, an important number of unsupervi-
sed (Hindle and Rooth, 1993; Ratnaparkhi, 1998;
Pantel and Lin, 2000), supervised (Alshawi and
Carter, 1994; Berthouzoz and Merlo, 1997), and
combined (Volk, 2002) methods have been deve-
loped to this end.
However, as Hindle and Rooth (1993) pointed
out, the parsers used by such methods lack pre-
cisely the kind of corpus-based information that
is required to resolve ambiguity, because many
of the existing attachments may be missing or
wrong. The current literature provides no indi-
cation about the manner in which this circular
problem can be circumvented, and on whether
flexible MWEs should be processed before, du-
ring or after the sentence analysis takes place.
</bodyText>
<page confidence="0.999166">
29
</page>
<sectionHeader confidence="0.972479" genericHeader="method">
3 Parsing and Collocations
</sectionHeader>
<bodyText confidence="0.996373338461538">
As argued by many researchers – e.g., Heid (1994)
– collocation identification is best performed on
the basis of parsed material. This is due to the
fact that collocations are co-occurrences of lexi-
cal items in a specific syntactic configuration. The
collocation break record, for instance, is obtained
only in the configurations where break is a verb
whose direct object is (semantically) headed by
the lexical item record. In other words, the collo-
cation is not defined in terms of linear proximity,
but in terms of a specific grammatical relation.
As the examples in this section show, the rela-
tive order of the two items is not relevant, nor is
the distance between the two terms, which is unli-
mited as long as the grammatical relation holds4.
In our system, the grammatical relations are com-
puted by a syntactic parser, namely, Fips (Wehrli,
2007; Wehrli and Nerima, 2009). Until now, the
collocation identification process took place at the
end of the parse in a so-called “interpretation”
procedure applied to the complete parse trees. Al-
though quite successful, this way of doing pre-
sents a major drawback: it happens too late to
help the parser. This section discusses this point
and describes the alternative that we are currently
developing, which consists in identifying colloca-
tions as soon as possible during the parse.
One of the major hurdles for non-deterministic
parsers is the huge number of alternatives that
must be considered. Given the high fre-
quency of lexical ambiguities, the high level of
non-determinism of natural language grammars,
grammar-based parsers are faced with a number
of alternatives which grows exponentially with the
length of the input sentence. Various methods
have been proposed to reduce that number, and
in most cases heuristics are added to the parsing
algorithm to limit the number of alternatives. Wi-
thout such heuristics, the performance of a parser
might not be satisfactory enough for large scale
applications such as machine translation or other
tasks involving large corpora.
We would like to argue, along the lines of
previous work (section 2), that collocations can
4Goldman et al. (2001) report examples in which the dis-
tance between the two terms of a collocation can exceed 30
words.
contribute to the disambiguation process so cru-
cial for parsing. To put it differently, identifying
collocations should not be seen as a burden, as an
additional task the parser should perform, but on
the contrary as a process which may help the par-
ser through the maze of alternatives. Collocations,
in their vast majority, are made of frequently used
terms, often highly ambiguous (e.g., break record,
loose change). Identifying them and giving them
high priority over alternatives is an efficient way
to reduce the ambiguity level. Ambiguity reduc-
tion through the identification of collocations is
not limited to lexical ambiguities, but also applies
to attachment ambiguities, and in particular to the
well-known problem of PP attachment. Consider
the following French examples in which the pre-
positions are highlighted:
(1)a. ligne de partage des eaux (“watershed”)
</bodyText>
<listItem confidence="0.969504142857143">
b. syst`eme de gestion de base de donn´ees (“da-
tabase management system”)
c. force de maintien de la paix (“peacekeeping
force”)
d. organisation de protection de
l’environnement (“environmental protection
agency”)
</listItem>
<bodyText confidence="0.99976275">
In such cases, the identification of a noun-
preposition-noun collocation will prevent or dis-
courage any other type of prepositional attach-
ment that the parser would otherwise consider.
</bodyText>
<subsectionHeader confidence="0.998832">
3.1 The Method
</subsectionHeader>
<bodyText confidence="0.999979125">
To fulfill the goal of interconnecting the parsing
procedure and the identification of collocations,
we have incorporated the collocation identifica-
tion mechanism within the constituent attachment
procedure of our parser Fips (Wehrli, 2007). This
parser, like many grammar-based parsers, uses
left attachment and right attachment rules to build
respectively left subconstituents and right sub-
constituents. Given the fact that Fips’ rules always
involve exactly two constituents – see Wehrli
(2007) for details – it is easy to add to the attach-
ment mechanism the task of collocation identifica-
tion. To take a very simple example, when the rule
attaching a prenominal adjective to a noun applies,
the collocation identification procedure is invo-
ked. It first verifies that both terms bear the lexical
</bodyText>
<page confidence="0.990194">
30
</page>
<bodyText confidence="0.999914153846154">
feature [+partOfCollocation], which signals that a
given word is associated in our lexical database to
one or several collocations, and then searches the
collocation database for an adjective-noun collo-
cation with those two terms. If successful, the cor-
responding parse tree will be given a high priority.
With examples such as loose change, the iden-
tification of the collocation will immediately re-
legate any (partial) analysis based on the verbal
reading of either terms.
To take a somewhat more complex example,
consider a verb-object collocation such as break
record, as in example (2)5.
</bodyText>
<equation confidence="0.721444333333333">
(2)a. John broke a record.
b. [ [ John ] broke [ a [ record ] ] ]
TP DP DP NP
</equation>
<bodyText confidence="0.996925935483871">
Here, it is a right attachment rule which will
trigger the identification procedure. To be precise,
the right attachment rule in this case concerns the
attachment of the noun record as complement
of the indefinite determiner (head of the DP
direct object of the verb). The identification
procedure considers, in turn, all the governing
nodes dominating the noun record, halting at the
first node of category Noun6, Verb or Adjective.
In our example, the determiner node and then
the verb node will be considered. Notice that the
procedure will, quite correctly, identify a colloca-
tion in the French example (3a), but not in (3b),
although both structures are identical. The reason
has to do with the fact that the noun governing
record in the first example is a [+number] noun,
that is a classifier noun which is transparent for
the identification procedure7.
(3)a. Jean a battu un grand nombre de records.
“Jean broke a large number of records”
5We use the following labels in our phrase-structure re-
presentations: TP-Tense phrase, for simple sentence (the S of
standard CFG), CP-Complementizer phrase, for a sentence
with a conjunction or a complementizer, DP-Determiner
phrase for standard noun phrases (we assume the DP hy-
pothesis, whereby the determiner constitutes the syntac-
tic head of a noun phrase), NP-Noun phrase for nominal
projections (nouns with their modifiers/complements), VP-
Verb phrase, PP-Prepositional phrase, AP-Adjectival phrase,
AdvP-Adverbial phrase, FP-Functional phrase (used for se-
condary predicates).
</bodyText>
<footnote confidence="0.75491275">
6Unless the node it marked [+number], as we will see
shortly.
7See Fontenelle (1999) for a detailed account of transpa-
rent nouns.
</footnote>
<bodyText confidence="0.9885211">
b. Jean a battu le d´etenteur du record.
“Jean has beaten the holder of the record”
As in the other examples, an analysis in which
a collocation has been found is given high prio-
rity over alternatives. In the case of (2), this will
relegate potential analyses based on the adjectival
reading of broke or the verbal reading of record.
Notice that exactly the same procedure applies
when the trace of an extraposed element is (right)
inserted, as in the examples (4), which illustrate
the case of wh-interrogative (a), relative clause
(b), tough-movement (c).
(4)a. Which record will Paul try to break ?
b. The record Paul broke was very old.
c. This record is difficult to break.
In all such cases, that is, when the right inserted
element is a trace, the identification procedure
will consider its antecedent, or to be more precise,
the semantic head of its antecedent. Finally, the
grammatical processes involved in example (4a,c)
can combine as in the more complex example (5),
for which we give the slightly simplified structure
with the chain of elements with index i extending
from the fronted wh-phrase which record to the
direct object position of the verb break, via the
direct object position of the verb consider and the
subject position of the secondary predicate (FP)
headed by the [+tough] adjective difficult.
(5)a. Which record did Paul consider difficult to
break ?
</bodyText>
<equation confidence="0.751464">
b. [ CP [ DP which record]i [ TP did [ DP Paul
] [ VP consider ][ DP e]i [ FP [ DP e]i [ AP
difficult [ to [ break [ e]i ] ] ] ] ] ]
TP VP DP
</equation>
<subsectionHeader confidence="0.997584">
3.2 Complex Collocations
</subsectionHeader>
<bodyText confidence="0.9941654">
As stated, for instance, by (Heid, 1994), colloca-
tions can involve more than two (main) terms and
it is possible to adopt a recursive definition of col-
locations, i.e., complex collocations can be vie-
wed as collocations of collocations. The colloca-
tion identification procedure has been extended to
handle such cases. Consider examples (6) below.
(6)a. La voiture tombera probablement en panne
d’essence.
“the car will probably run out of gas”
</bodyText>
<page confidence="0.999302">
31
</page>
<bodyText confidence="0.96945365">
b. natural language processing
c. He broke a world record.
In the French sentence (6a), panne d’essence
(literally, “breakdown of gas”, “out of gas”) is
a collocation of type Noun+Prep+Noun, which
combines with the verb tomber (literally, “to
fall”) to form a larger collocation of type
Verb+PrepObject tomber en panne d’essence (“to
run out of gas”). Given the strict left to right
processing order assumed by the parser, it will
first identify the collocation tomber en panne (“to
break down”) when attaching the word panne.
Then, reading the last word, essence (“gas”), the
parser will first identify the collocation panne
d’essence. Since that collocation bears the lexi-
cal feature [+partOfCollocation], the identifica-
tion procedure goes on, through the governors
of that item. The search succeeds with the verb
tomber, and the collocation tomber en panne
d’essence (“run out of gas”) is identified.
</bodyText>
<sectionHeader confidence="0.997217" genericHeader="method">
4 Evaluation Experiments
</sectionHeader>
<bodyText confidence="0.9999634">
In this section, we describe the experiments we
performed in order to evaluate the precision and
recall of the method introduced in section 3, and
to compare it against the previous method (fully
described in Wehrli et al. (2009b)). We extend
this comparison by performing a task-based eva-
luation, which investigates the impact that the new
method has on the quality of translations produ-
ced by a machine translation system relying on
our parser (Wehrli et al., 2009a).
</bodyText>
<subsectionHeader confidence="0.992429">
4.1 Precision Evaluation
</subsectionHeader>
<bodyText confidence="0.9998744">
The data considered in this experiment consist of
a subpart of a corpus of newspaper articles collec-
ted from the on-line version of The Economist8,
containing slightly more that 0.5 million words.
On these data, we run two versions of our parser:
</bodyText>
<listItem confidence="0.9967235">
• V1: a version implementing the previous me-
thod of collocation identification,
• V2: a version implementing the new method
described in section 3.
</listItem>
<footnote confidence="0.8917885">
8URL:http://www.economist.com/
(accessed June, 2010).
</footnote>
<bodyText confidence="0.999851666666667">
The lexicon of the parser was kept constant,
which is to say that both versions used the same
lexicon (which contains slightly more than 7500
English collocation entries), only the parsing mo-
dule handling collocations was different. From
the output of each parser version, we collected
statistics on the number of collocations (present
in the lexicon) that were identified in the test cor-
pus. More precisely, we traversed the output trees
and counted the items that were marked as col-
location heads, each time this was the case (note
that an item may participate in several colloca-
tions, not only one). Table 1 presents the num-
ber of collocations identified, both with respect to
collocation instances and collocation types.
</bodyText>
<table confidence="0.97429">
V1 V2 common V1 only V2 only
Tokens 4716 5412 4347 399 1003
Types 1218 1301 1182 143 368
</table>
<tableCaption confidence="0.999813">
Table 1. Collocation identification results.
</tableCaption>
<bodyText confidence="0.999989888888889">
As the results show, the new method (column
V2) is more efficient in retrieving collocation ins-
tances. It detects 696 more instances, which cor-
respond to an increase of 14.8% relative to the
previous method (column V1). As we lack the
means to compare on a large scale the correspon-
ding syntactic trees, we can only speculate that the
increase is mainly due to the fact that more appro-
priate analyses are produced by the new method.
A large number of instances are found by both
versions of the parser. The difference between
the two methods is more visible for some syn-
tactic types than for others. Table 2 details the
number of instances of each syntactic type which
are retrieved exclusively by one method or by the
other.
To measure the precision of the two methods,
we randomly selected 20 collocation instances
among those identified by each version of the par-
ser, V1 and V2, and manually checked whether
these instances are correct. Correctness means
that in the given context (i.e., the sentence in
which they were identified), the word combina-
tion marked as instance of a lexicalized colloca-
tion is indeed an instance of that collocation. A
counterexample would be, for instance, to mark
the pair decision - make in the sentence in (7) as
</bodyText>
<page confidence="0.997305">
32
</page>
<table confidence="0.9997863">
Syntactic type V1 V2 Difference V2-V1
A-N 72 152 80
N-N 63 270 207
V-O 22 190 168
V-P-N 6 10 4
N-P-N 1 62 61
V-A 25 166 141
P-N 200 142 -58
N&amp;N 6 2 -4
Adv-Adv 4 9 5
</table>
<tableCaption confidence="0.990335">
Table 2. Differences between the two methods:
</tableCaption>
<bodyText confidence="0.987765846153846">
number of tokens retrieved exclusively by each
method.
an instance of the verb-object collocation to make
a decision, which is an entry in our lexicon.
(7)a. The decision to make an offer to buy or sell
property at price is a management decision
that cannot be delegated to staff.
Since judging the correctness of a collocation ins-
tance in context is a rather straightforward task,
we do not require multiple judges for this evalua-
tion. The precision obtained is 90% for V1, and
100% for V2.
The small size of test set is motivated by the
fact that the precision is expected to be very high,
since the presence of both collocation components
in a sentence in the relevant syntactic relation al-
most certainly means that the recognition of the
corresponding collocation is justified. Exceptions
would correspond to a minority of cases in which
the parser either wrongly establishes a relation
between two items which happen to belong to an
entry in the lexicon, or the two items are related
but the combination corresponds to a literal usage
(examples are provided later in this section).
The errors of V1 correspond, in fact, to cases in
which a combination of words used literally was
wrongly attributed to a collocation: in example
(8a), V1 assigned the words on and business to
the lexical entry on business, and in example (8b),
it assigned in and country to the entry in the coun-
try9.
(8)a. It is not, by any means, specific to the
countryside, but it falls especially heavily on
small businesses.
9V1 makes the same error on (8a), but does better on (8b).
These expressions are frozen and should not be treated as
standard collocations.
b. Industrial labour costs in western Germany
are higher than in any other country.
To better pinpoint the difference between V1
and V2, we performed a similar evaluation on an
additional set of 20 instances, randomly selected
among the collocations identified exclusively by
each method. Thus, the precision of V1, when
measured on the tokens in ”V1 only”, was 65%.
The precision of V2 on ”V2 only” was 90%. The
2 errors of V2 concern the pair in country, found
in contexts similar to the one shown in example
(8b). The errors of V1 also concerned the same
pair, with one exception – the identification of the
collocation world trade from the context the des-
truction of the World Trade Centre. Since World
Trade Centre is not in the parser lexicon, V1 ana-
lysed it and assigned the first two words to the en-
try world trade. World was wrongly attached to
Trade, rather than to Centre.
When reported on the totality of the instances
tested, the precision of V1 is 77.5% and that of
V2 is 95%. Besides the increase in the precision
of identified collocations, the new method also
contributes to an increase in the parser coverage10,
from 81.7% to 83.3%. The V1 parser version suc-
ceeds in building a complete parse tree for 23187
of the total 28375 sentences in the corpus, while
V2 does so for 23629 sentences.
</bodyText>
<subsectionHeader confidence="0.995651">
4.2 Recall Evaluation
</subsectionHeader>
<bodyText confidence="0.977974294117647">
To compare the recall of two methods we perfor-
med a similar experiment, in which we run the two
versions of the parser, V1 and V2, on a small col-
lection of sentences containing annotated colloca-
tion instances. These sentences were randomly
selected from the Europarl corpus (Koehn, 2005).
The collocations they contain are all verb-object
collocations. We limit our present investigation
to this syntactic type for two reasons: a) anno-
tating a corpus with all instances of collocation
entries in the lexicon would be a time-consuming
task; and b) verb-object collocations are among
the most syntactically flexible and therefore diffi-
cult to detect in real texts. Thus, this test set pro-
vides realistic information on recall.
10Coverage refers more precisely to the ratio of sentences
for which a complete parse tree could be built.
</bodyText>
<page confidence="0.99821">
33
</page>
<bodyText confidence="0.999318666666667">
The test set is divided in two parts: 100 sen-
tences are in English, and 100 other in Italian,
which allows for a cross-linguistic evaluation of
the two methods. Each sentence contains one an-
notated collocation instance, and there are 10 ins-
tances for a collocation type. Table 3 lists the col-
location types in the test set (the even rows in co-
lumn 2 display the glosses for the words in the
Italian collocations).
</bodyText>
<subsectionHeader confidence="0.685081">
English Italian
</subsectionHeader>
<table confidence="0.72436185">
bridge gap assumere atteggiamento
‘assume’ ‘attitude’
draw distinction attuare politica
‘carry out’ ‘policy’
foot bill avanzare proposta
‘advance’ ‘proposal’
give support avviare dialogo
‘start’ ‘dialogue’
hold presidency compiere sforzo
‘commit’ ‘effort’
meet condition dare contributo
‘give’ ‘contribution’
pose threat dedicare attenzione
‘dedicate’ ‘attention’
reach compromise operare scelta
‘operate’ ‘choice’
shoulder responsibility porgere benvenuto
‘give’ ‘welcome’
strike balance raggiungere intesa
‘reach’ ‘understanding’
</table>
<tableCaption confidence="0.996121">
Table 3. Collocation types in the test set.
</tableCaption>
<bodyText confidence="0.999887263157895">
The evaluation results are presented in table 4.
V1 achieves 63% recall performance on the En-
glish data, and 44% on the Italian data. V2 shows
considerably better results: 76% on English and
66% on Italian data. The poorer performance
of both methods on Italian data is explained by
the difference in performance between the English
and Italian parsers, and more precisely, by the dif-
ference in their grammatical coverage. The En-
glish parser succeeds in building a complete parse
tree for more than 70% of the sentences in the test
set, while the Italian parser only for about 60%.
As found in the previous experiment (presen-
ted in section 4.1), for both languages considered
in this experiment, the new method of processing
collocations contributes to improving the parsing
coverage. The coverage of the English parser in-
creases from 71% to 76%, and that of the Italian
parser from 57% to 61%.
</bodyText>
<table confidence="0.881367666666667">
V1 V2 Common V1 only V2 only
English 63 76 61 2 15
Italian 44 66 42 2 24
</table>
<tableCaption confidence="0.984834">
Table 4. Recall evaluation results: number of cor-
rect collocation instances identified.
</tableCaption>
<subsectionHeader confidence="0.998099">
4.3 Task-based Evaluation
</subsectionHeader>
<bodyText confidence="0.999969475">
In addition to reporting the performance results by
using the standard measures of precision and re-
call, we performed a task-based performance eva-
luation, in which we quantified the impact that the
newly-proposed method has on the quality of the
output of a machine translation system. As the
examples in table 3 suggest, a literal translation of
collocations is rarely the most appropriate. In fact,
as stated by Orliac and Dillinger (2003), know-
ledge of collocations is crucial for machine trans-
lation systems. An important purpose in iden-
tifying collocations with our parser is to enable
their proper treatment in our translation system, a
rule-based system that performs syntactic transfer
by relying on the structures produced by the par-
ser.
In this system, the translation of a collocation
takes place as follows. When the parser identi-
fies a collocation in the source sentence, its com-
ponent words are marked as collocation mem-
bers, in order to prevent their literal translation.
When the transfer module processes the collo-
cation head, the system checks in the bilingual
lexicon whether an entry exists for that colloca-
tion. If not, the literal translation will apply;
otherwise, the transfer module projects a target-
language structure as specified in the correspon-
ding target lexical entry. More precisely, the trans-
fer yields a target language abstract representa-
tion, to which grammatical transformations and
morphological generation will apply to create the
target sentence. The identification of collocations
in the source text is a necessary, yet not a sufficient
condition for their successful translation.
In this experiment, we considered the test set
described in section 4.2 and we manually eva-
luated the translation obtained for each colloca-
tion instance. Both subsets (100 English sen-
tences and 100 Italian sentences) were translated
into French. We compared the translations obtai-
</bodyText>
<page confidence="0.995389">
34
</page>
<table confidence="0.999624454545455">
Task Measure Test set Language Increase
Collocation identification precision 40 instances English 17.5%
recall 200 instances English, Italian 17.5%
100 instances English 13%
100 instances Italian 22%
Collocation translation precision 200 instances {English, Italian}-French 13%
100 instances English-French 10%
100 instances Italian-French 16%
Parsing coverage 28375 sentences English 1.6%
200 sentences English 5%
200 sentences Italian 4%
</table>
<tableCaption confidence="0.99952">
Table 5. Summary of evaluation results.
</tableCaption>
<bodyText confidence="0.99993248">
ned by relying on the versions V1 and V2 of our
parser (recall that V2 corresponds to the newly-
proposed method and V1 to the previous method).
The use of automatic metrics for evaluating the
translation output was not considered appropriate
in this context, since such n-gram based metrics
underestimate the effect that the substitution of a
single word (like in our case, the verb in a verb-
object collocation) has on the fluency, adequacy,
and even on the interpretability of the output sen-
tence.
The comparison showed that, for both language
pairs considered (English-French and Italian-
French), the version of parser which integrates the
new method is indeed more useful for the ma-
chine translation system than the previous version.
When V2 was used, 10 more collocation instances
were correctly translated from English to French
than when using V1. For the Italian-French pair,
V2 helped correctly translating 16 more colloca-
tion instances in comparison with V1. This cor-
responds to an increase in precision of 13% on the
whole test set of 200 sentences. The increase in
performance obtained in all the experiments des-
cribed in this section is summarized in table 5.
</bodyText>
<sectionHeader confidence="0.998954" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999978954545455">
In this paper, we addressed the issue of the inter-
connection between collocation identification and
syntactic parsing, and we proposed an original so-
lution for identifying collocations in a sentence as
soon as possible during the analysis (rather than at
the end of the parsing process). The major advan-
tage of this approach is that collocational informa-
tion may be used to guide the parser through the
maze of alternatives.
The experimental results performed showed
that the proposed method, which couples parsing
and collocation identification, leads to substan-
tial improvements in terms of precision and re-
call over the standard identification method, while
contributing to augment the coverage of the par-
ser. In addition, it was shown that it has a posi-
tive impact on the results of a subsequent appli-
cation, namely, machine translation. Future work
will concentrate on improving our method so that
it accounts for all the possible syntactic configu-
rations of collocational attachments, and on exten-
ding its recall evaluation to other syntactic types.
</bodyText>
<sectionHeader confidence="0.994728" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999877">
Thanks to Lorenza Russo and Paola Merlo for a
thorough reading and comments. Part of the re-
search described in this paper has been supported
by a grant from the Swiss National Science Foun-
dation, grant no 100015-117944.
</bodyText>
<sectionHeader confidence="0.998595" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99699">
Alegria, I˜naki, Olatz Ansa, Xabier Artola, Nerea
Ezeiza, Koldo Gojenola, and Ruben Urizar. 2004.
Representation and treatment of multiword expres-
sions in basque. In Second ACL Workshop on Mul-
tiword Expressions: Integrating Processing, pages
48–55, Barcelona, Spain.
Alshawi, Hiyan and David Carter. 1994. Training
and scaling preference functions for disambigua-
tion. Computational Linguistics, 20(4):635–648.
Benson, Morton, Evelyn Benson, and Robert Ilson.
1986. The BBI Dictionary of English Word Combi-
nations. John Benjamins, Amsterdam/Philadelphia.
Berthouzoz, Cathy and Paola Merlo. 1997. Statis-
tical ambiguity resolution for principle-based par-
sing. In Nicolov, Nicolas and Ruslan Mitkov, edi-
</reference>
<page confidence="0.993204">
35
</page>
<reference confidence="0.999480028846153">
tors, Recent Advances in Natural Language Pro-
cessing: Selected Papers from RANLP’97, Current
Issues in Linguistic Theory, pages 179–186. John
Benjamins, Amsterdam/Philadelphia.
Brun, Caroline. 1998. Terminology finite-state pre-
processing for computational LFG. In Proceedings
of the 36th Annual Meeting of the Association for
Computational Linguistics and 17th International
Conference on Computational Linguistics, pages
196–200, Morristown, NJ, USA.
Firth, John R. 1957. Papers in Linguistics 1934-1951.
Oxford Univ. Press, Oxford.
Fontenelle, Thierry. 1999. Semantic resources for
word sense disambiguation: a sine qua non? Lin-
guistica e Filologia, (9):25–43. Dipartimento di
Linguistica e Letterature Comparate, Universit`a de-
gli Studi di Bergamo.
Goldman, Jean-Philippe, Luka Nerima, and Eric
Wehrli. 2001. Collocation extraction using a syn-
tactic parser. In Proceedings of the ACL Work-
shop on Collocation: Computational Extraction,
Analysis and Exploitation, pages 61–66, Toulouse,
France.
Gr´egoire, Nicole, Stefan Evert, and Brigitte Krenn,
editors. 2008. Proceedings of the LREC Workshop
Towards a Shared Task for Multiword Expressions
(MWE 2008). European Language Resources Asso-
ciation (ELRA), Marrakech, Morocco.
Heid, Ulrich. 1994. On ways words work together
– research topics in lexical combinatorics. In Pro-
ceedings of the 6th Euralex International Congress
on Lexicography (EURALEX ’94), pages 226–257,
Amsterdam, The Netherlands.
Hindle, Donald and Mats Rooth. 1993. Structural am-
biguity and lexical relations. Computational Lin-
guistics, 19(1):103–120.
Koehn, Philipp. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proceedings of
The Tenth Machine Translation Summit (MT Sum-
mit X), pages 79–86, Phuket, Thailand, September.
Orliac, Brigitte and Mike Dillinger. 2003. Collocation
extraction for machine translation. In Proceedings
of Machine Translation Summit IX, pages 292–298,
New Orleans, Lousiana, USA.
Pantel, Patrick and Dekang Lin. 2000. An unsuper-
vised approach to prepositional phrase attachment
using contextually similar words. In Proceedings
of the 38th Annual Meeting of the Association for
Computational Linguistics, pages 101–108, Hong
Kong, China.
Ratnaparkhi, Adwait. 1998. Statistical models for un-
supervised prepositional phrase attachment. In Pro-
ceedings of the 36th Annual Meeting of the Associa-
tion for Computational Linguistics and 17th Inter-
national Conference on Computational Linguistics,
pages 1079–1085, Montreal, Quebec, Canada.
Sag, Ivan A., Timothy Baldwin, Francis Bond, Ann
Copestake, and Dan Flickinger. 2002. Multiword
expressions: A pain in the neck for NLP. In Pro-
ceedings of the Third International Conference on
Intelligent Text Processing and Computational Lin-
guistics (CICLING 2002), pages 1–15, Mexico City.
Sinclair, John. 1991. Corpus, Concordance, Colloca-
tion. Oxford University Press, Oxford.
Villavicencio, Aline, Valia Kordoni, Yi Zhang, Marco
Idiart, and Carlos Ramisch. 2007. Validation and
evaluation of automatically acquired multiword ex-
pressions for grammar engineering. In Proceedings
of the 2007 Joint Conference on Empirical Methods
in Natural Language Processing and Computatio-
nal Natural Language Learning (EMNLP-CoNLL),
pages 1034–1043, Prague, Czech Republic, June.
Volk, Martin. 2002. Combining unsupervised and
supervised methods for PP attachment disambi-
guation. In Proceedings of the 19th Internatio-
nal Conference on Computational Linguistics (CO-
LING’02), pages 25–32, Taipei, Taiwan.
Wehrli, Eric and Luka Nerima. 2009. L’analyseur
syntaxique Fips. In Proceedings of the IWPT 2009
ATALA Workshop: What French parsing systems?,
Paris, France.
Wehrli, Eric, Luka Nerima, and Yves Scherrer. 2009a.
Deep linguistic multilingual translation and bilin-
gual dictionaries. In Proceedings of the Fourth
Workshop on Statistical Machine Translation, pages
90–94, Athens, Greece. Association for Computa-
tional Linguistics.
Wehrli, Eric, Violeta Seretan, Luka Nerima, and Lo-
renza Russo. 2009b. Collocations in a rule-based
MT system: A case study evaluation of their trans-
lation adequacy. In Proceedings of the 13th Annual
Meeting of the European Association for Machine
Translation, pages 128–135, Barcelona, Spain.
Wehrli, Eric. 2000. Parsing and collocations. In
Christodoulakis, D., editor, Natural Language Pro-
cessing, pages 272–282. Springer Verlag.
Wehrli, Eric. 2007. Fips, a “deep” linguistic multilin-
gual parser. In ACL 2007 Workshop on Deep Lin-
guistic Processing, pages 120–127, Prague, Czech
Republic.
Zhang, Yi and Valia Kordoni. 2006. Automated deep
lexical acquisition for robust open texts processing.
In Proceedings of LREC-2006, pages 275–280, Ge-
noa, Italy.
</reference>
<page confidence="0.998935">
36
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.409294">
<title confidence="0.999937">Sentence Analysis and Collocation Identification</title>
<author confidence="0.999488">Eric Wehrli</author>
<author confidence="0.999488">Violeta Seretan</author>
<author confidence="0.999488">Luka</author>
<affiliation confidence="0.807247">Language Technology University of Violeta.Seretan,</affiliation>
<abstract confidence="0.998329863636364">Identifying collocations in a sentence, in order to ensure their proper processing in subsequent applications, and performing the syntactic analysis of the sentence are interrelated processes. Syntactic information is crucial for detecting collocations, and vice versa, collocational information is useful for parsing. This article describes an original approach in which collocations are identified in a sentence as soon as possible during the analysis of that sentence, rather than at the end of the analysis, as in our previous work. In this way, priority is given to parsing alternatives involving collocations, and collocational information guide the parser through the maze of alternatives. This solution was shown to lead to substantial improvements in the performance of both tasks (collocation identification and parsing), and in that of a subsequent task (machine translation).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>I˜naki Alegria</author>
<author>Olatz Ansa</author>
<author>Xabier Artola</author>
<author>Nerea Ezeiza</author>
<author>Koldo Gojenola</author>
<author>Ruben Urizar</author>
</authors>
<title>Representation and treatment of multiword expressions in basque.</title>
<date>2004</date>
<booktitle>In Second ACL Workshop on Multiword Expressions: Integrating Processing,</booktitle>
<pages>48--55</pages>
<location>Barcelona,</location>
<contexts>
<context position="6513" citStr="Alegria et al. (2004)" startWordPosition="1009" endWordPosition="1013">cessing stage. She found that the integration of 210 nominal terms in the preprocessing components of the parser resulted in a significant reduction of the number of alternative parses (from an average of 4.21 to 2.79). The eliminated parses were found to be semantically undesirable. No valid analysis were ruled out. Similarly, Zhang and Kordoni (2006) extended a lexicon with 373 additional MWE lexical entries and obtained a significant increase in the coverage of an English grammar (14.4%, from 4.3% to 18.7%). In the cases mentioned above, a “words-withspaces” approach was used. In contrast, Alegria et al. (2004) and Villavicencio et al. (2007) adopted a compositional approach to the encoding of MWEs, able to capture more morphosyntactically flexible MWEs. Alegria et al. (2004) showed that by using a MWE processor in the preprocessing stage of their parser (in development) for Basque, a significant improvement in the POStagging precision is obtained. Villavicencio et al. (2007) found that the addition of 21 new MWEs to the lexicon led to a significant increase in the grammar coverage (from 7.1% to 22.7%), without altering the grammar accuracy. An area of intensive research in parsing is concerned with</context>
</contexts>
<marker>Alegria, Ansa, Artola, Ezeiza, Gojenola, Urizar, 2004</marker>
<rawString>Alegria, I˜naki, Olatz Ansa, Xabier Artola, Nerea Ezeiza, Koldo Gojenola, and Ruben Urizar. 2004. Representation and treatment of multiword expressions in basque. In Second ACL Workshop on Multiword Expressions: Integrating Processing, pages 48–55, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiyan Alshawi</author>
<author>David Carter</author>
</authors>
<title>Training and scaling preference functions for disambiguation.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="4529" citStr="Alshawi and Carter, 1994" startWordPosition="687" endWordPosition="690"> subsequent processing applications (e.g., a machine translation application). Again, this solution is not fully appropriate, and the reason lies with the important observation that prior collocational knowledge is highly relevant for parsing. Collocational restrictions are, along with other types of information like selectional preferences and subcategorization frames, a major means of structural disambiguation. Collocational relations between the words in a sentence proved very helpful in selecting the most plausible among all the possible parse trees for a sentence (Hindle and Rooth, 1993; Alshawi and Carter, 1994; Berthouzoz and Merlo, 1997; Wehrli, 2000). Hence, the question whether collocations should be identified in a sentence before or after parsing is not an easy one. The previous literature on parsing and collocations fails to provide insightful details on how this circular issue is (or can be) solved. In this paper, we argue that the identification of collocations and the construction of a parse tree are interrelated processes, that must be accounted for simultaneously. We present a processing model in which collocations, if present in a lexicon, are identified in the input sentence during the</context>
<context position="7396" citStr="Alshawi and Carter, 1994" startWordPosition="1150" endWordPosition="1153">pment) for Basque, a significant improvement in the POStagging precision is obtained. Villavicencio et al. (2007) found that the addition of 21 new MWEs to the lexicon led to a significant increase in the grammar coverage (from 7.1% to 22.7%), without altering the grammar accuracy. An area of intensive research in parsing is concerned with the use of lexical preferences, cooccurrence frequencies, collocations, and contextually similar words for PP attachment disambiguation. Thus, an important number of unsupervised (Hindle and Rooth, 1993; Ratnaparkhi, 1998; Pantel and Lin, 2000), supervised (Alshawi and Carter, 1994; Berthouzoz and Merlo, 1997), and combined (Volk, 2002) methods have been developed to this end. However, as Hindle and Rooth (1993) pointed out, the parsers used by such methods lack precisely the kind of corpus-based information that is required to resolve ambiguity, because many of the existing attachments may be missing or wrong. The current literature provides no indication about the manner in which this circular problem can be circumvented, and on whether flexible MWEs should be processed before, during or after the sentence analysis takes place. 29 3 Parsing and Collocations As argued </context>
</contexts>
<marker>Alshawi, Carter, 1994</marker>
<rawString>Alshawi, Hiyan and David Carter. 1994. Training and scaling preference functions for disambiguation. Computational Linguistics, 20(4):635–648.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Morton Benson</author>
<author>Evelyn Benson</author>
<author>Robert Ilson</author>
</authors>
<date>1986</date>
<journal>The BBI Dictionary of English Word Combinations. John Benjamins, Amsterdam/Philadelphia.</journal>
<contexts>
<context position="1590" citStr="Benson et al., 1986" startWordPosition="232" endWordPosition="235">erformance of both tasks (collocation identification and parsing), and in that of a subsequent task (machine translation). 1 Introduction Collocations1 constitute a central language phenomenon and an impressive amount of work has been devoted over the past decades to the automatic acquisition of collocational resources – as attested, among others, by initiatives like the MWE 2008 shared task aimed at creating a repository of reference data (Gr´egoire et al., 2008). However, little or no reference exist in the literature about 1We adopt the lexicographic understanding for the term collocation (Benson et al., 1986), as opposed to the British contextualist tradition focused on statistical co-occurrence (Firth, 1957; Sinclair, 1991). the actual use made of these resources in other NLP applications. In this paper, we consider the particular application of syntactic parsing. Just as other types of multi-word expressions (henceforth, MWEs), collocations are problematic for parsing because they have to be recognised and treated as a whole, rather than compositionally, i.e., in a word by word fashion (Sag et al., 2002). The standard approach in dealing with MWEs in parsing is to apply a “words-with-spaces” pre</context>
</contexts>
<marker>Benson, Benson, Ilson, 1986</marker>
<rawString>Benson, Morton, Evelyn Benson, and Robert Ilson. 1986. The BBI Dictionary of English Word Combinations. John Benjamins, Amsterdam/Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cathy Berthouzoz</author>
<author>Paola Merlo</author>
</authors>
<title>Statistical ambiguity resolution for principle-based parsing.</title>
<date>1997</date>
<booktitle>Recent Advances in Natural Language Processing: Selected Papers from RANLP’97, Current Issues in Linguistic Theory,</booktitle>
<pages>179--186</pages>
<editor>In Nicolov, Nicolas and Ruslan Mitkov, editors,</editor>
<publisher>John Benjamins, Amsterdam/Philadelphia.</publisher>
<contexts>
<context position="4557" citStr="Berthouzoz and Merlo, 1997" startWordPosition="691" endWordPosition="695">lications (e.g., a machine translation application). Again, this solution is not fully appropriate, and the reason lies with the important observation that prior collocational knowledge is highly relevant for parsing. Collocational restrictions are, along with other types of information like selectional preferences and subcategorization frames, a major means of structural disambiguation. Collocational relations between the words in a sentence proved very helpful in selecting the most plausible among all the possible parse trees for a sentence (Hindle and Rooth, 1993; Alshawi and Carter, 1994; Berthouzoz and Merlo, 1997; Wehrli, 2000). Hence, the question whether collocations should be identified in a sentence before or after parsing is not an easy one. The previous literature on parsing and collocations fails to provide insightful details on how this circular issue is (or can be) solved. In this paper, we argue that the identification of collocations and the construction of a parse tree are interrelated processes, that must be accounted for simultaneously. We present a processing model in which collocations, if present in a lexicon, are identified in the input sentence during the analysis of that sentence. </context>
<context position="7425" citStr="Berthouzoz and Merlo, 1997" startWordPosition="1154" endWordPosition="1157">ficant improvement in the POStagging precision is obtained. Villavicencio et al. (2007) found that the addition of 21 new MWEs to the lexicon led to a significant increase in the grammar coverage (from 7.1% to 22.7%), without altering the grammar accuracy. An area of intensive research in parsing is concerned with the use of lexical preferences, cooccurrence frequencies, collocations, and contextually similar words for PP attachment disambiguation. Thus, an important number of unsupervised (Hindle and Rooth, 1993; Ratnaparkhi, 1998; Pantel and Lin, 2000), supervised (Alshawi and Carter, 1994; Berthouzoz and Merlo, 1997), and combined (Volk, 2002) methods have been developed to this end. However, as Hindle and Rooth (1993) pointed out, the parsers used by such methods lack precisely the kind of corpus-based information that is required to resolve ambiguity, because many of the existing attachments may be missing or wrong. The current literature provides no indication about the manner in which this circular problem can be circumvented, and on whether flexible MWEs should be processed before, during or after the sentence analysis takes place. 29 3 Parsing and Collocations As argued by many researchers – e.g., H</context>
</contexts>
<marker>Berthouzoz, Merlo, 1997</marker>
<rawString>Berthouzoz, Cathy and Paola Merlo. 1997. Statistical ambiguity resolution for principle-based parsing. In Nicolov, Nicolas and Ruslan Mitkov, editors, Recent Advances in Natural Language Processing: Selected Papers from RANLP’97, Current Issues in Linguistic Theory, pages 179–186. John Benjamins, Amsterdam/Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Caroline Brun</author>
</authors>
<title>Terminology finite-state preprocessing for computational LFG.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics,</booktitle>
<pages>196--200</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="5796" citStr="Brun (1998)" startWordPosition="893" endWordPosition="894">sed to rank competing parsing hypotheses. The paper is organised as follows. Section 2 reviews the previous work on the interrelation between parsing and processing of collocations (or, more generally, MWEs). Section 3 introduces our approach, and section 4 evaluates it by comparing it against the standard non-simultaneous approach. Section 5 provides concluding remarks and presents directions for future work. 2 Related Work Extending the lexical component of a parser with MWEs was proved to contribute to a significant improvement of the coverage and accuracy of parsing results. For instance, Brun (1998) compared the coverage of a French parser with and without terminology recognition in the preprocessing stage. She found that the integration of 210 nominal terms in the preprocessing components of the parser resulted in a significant reduction of the number of alternative parses (from an average of 4.21 to 2.79). The eliminated parses were found to be semantically undesirable. No valid analysis were ruled out. Similarly, Zhang and Kordoni (2006) extended a lexicon with 373 additional MWE lexical entries and obtained a significant increase in the coverage of an English grammar (14.4%, from 4.3</context>
</contexts>
<marker>Brun, 1998</marker>
<rawString>Brun, Caroline. 1998. Terminology finite-state preprocessing for computational LFG. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, pages 196–200, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John R Firth</author>
</authors>
<title>Papers in Linguistics 1934-1951.</title>
<date>1957</date>
<publisher>Univ. Press,</publisher>
<location>Oxford</location>
<contexts>
<context position="1691" citStr="Firth, 1957" startWordPosition="247" endWordPosition="248">ranslation). 1 Introduction Collocations1 constitute a central language phenomenon and an impressive amount of work has been devoted over the past decades to the automatic acquisition of collocational resources – as attested, among others, by initiatives like the MWE 2008 shared task aimed at creating a repository of reference data (Gr´egoire et al., 2008). However, little or no reference exist in the literature about 1We adopt the lexicographic understanding for the term collocation (Benson et al., 1986), as opposed to the British contextualist tradition focused on statistical co-occurrence (Firth, 1957; Sinclair, 1991). the actual use made of these resources in other NLP applications. In this paper, we consider the particular application of syntactic parsing. Just as other types of multi-word expressions (henceforth, MWEs), collocations are problematic for parsing because they have to be recognised and treated as a whole, rather than compositionally, i.e., in a word by word fashion (Sag et al., 2002). The standard approach in dealing with MWEs in parsing is to apply a “words-with-spaces” preprocessing step, which marks the MWEs in the input sentence as units which will later be integrated a</context>
</contexts>
<marker>Firth, 1957</marker>
<rawString>Firth, John R. 1957. Papers in Linguistics 1934-1951. Oxford Univ. Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thierry Fontenelle</author>
</authors>
<title>Semantic resources for word sense disambiguation: a sine qua non?</title>
<date>1999</date>
<booktitle>Linguistica e Filologia, (9):25–43. Dipartimento di Linguistica e Letterature Comparate, Universit`a degli Studi</booktitle>
<location>di Bergamo.</location>
<contexts>
<context position="14599" citStr="Fontenelle (1999)" startWordPosition="2301" endWordPosition="2302">re representations: TP-Tense phrase, for simple sentence (the S of standard CFG), CP-Complementizer phrase, for a sentence with a conjunction or a complementizer, DP-Determiner phrase for standard noun phrases (we assume the DP hypothesis, whereby the determiner constitutes the syntactic head of a noun phrase), NP-Noun phrase for nominal projections (nouns with their modifiers/complements), VPVerb phrase, PP-Prepositional phrase, AP-Adjectival phrase, AdvP-Adverbial phrase, FP-Functional phrase (used for secondary predicates). 6Unless the node it marked [+number], as we will see shortly. 7See Fontenelle (1999) for a detailed account of transparent nouns. b. Jean a battu le d´etenteur du record. “Jean has beaten the holder of the record” As in the other examples, an analysis in which a collocation has been found is given high priority over alternatives. In the case of (2), this will relegate potential analyses based on the adjectival reading of broke or the verbal reading of record. Notice that exactly the same procedure applies when the trace of an extraposed element is (right) inserted, as in the examples (4), which illustrate the case of wh-interrogative (a), relative clause (b), tough-movement (</context>
</contexts>
<marker>Fontenelle, 1999</marker>
<rawString>Fontenelle, Thierry. 1999. Semantic resources for word sense disambiguation: a sine qua non? Linguistica e Filologia, (9):25–43. Dipartimento di Linguistica e Letterature Comparate, Universit`a degli Studi di Bergamo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean-Philippe Goldman</author>
<author>Luka Nerima</author>
<author>Eric Wehrli</author>
</authors>
<title>Collocation extraction using a syntactic parser.</title>
<date>2001</date>
<booktitle>In Proceedings of the ACL Workshop on Collocation: Computational Extraction, Analysis and Exploitation,</booktitle>
<pages>61--66</pages>
<location>Toulouse, France.</location>
<contexts>
<context position="10131" citStr="Goldman et al. (2001)" startWordPosition="1595" endWordPosition="1598">rminism of natural language grammars, grammar-based parsers are faced with a number of alternatives which grows exponentially with the length of the input sentence. Various methods have been proposed to reduce that number, and in most cases heuristics are added to the parsing algorithm to limit the number of alternatives. Without such heuristics, the performance of a parser might not be satisfactory enough for large scale applications such as machine translation or other tasks involving large corpora. We would like to argue, along the lines of previous work (section 2), that collocations can 4Goldman et al. (2001) report examples in which the distance between the two terms of a collocation can exceed 30 words. contribute to the disambiguation process so crucial for parsing. To put it differently, identifying collocations should not be seen as a burden, as an additional task the parser should perform, but on the contrary as a process which may help the parser through the maze of alternatives. Collocations, in their vast majority, are made of frequently used terms, often highly ambiguous (e.g., break record, loose change). Identifying them and giving them high priority over alternatives is an efficient w</context>
</contexts>
<marker>Goldman, Nerima, Wehrli, 2001</marker>
<rawString>Goldman, Jean-Philippe, Luka Nerima, and Eric Wehrli. 2001. Collocation extraction using a syntactic parser. In Proceedings of the ACL Workshop on Collocation: Computational Extraction, Analysis and Exploitation, pages 61–66, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<date>2008</date>
<booktitle>Proceedings of the LREC Workshop Towards a Shared Task for Multiword Expressions (MWE 2008). European Language Resources Association (ELRA),</booktitle>
<editor>Gr´egoire, Nicole, Stefan Evert, and Brigitte Krenn, editors.</editor>
<location>Marrakech, Morocco.</location>
<marker>2008</marker>
<rawString>Gr´egoire, Nicole, Stefan Evert, and Brigitte Krenn, editors. 2008. Proceedings of the LREC Workshop Towards a Shared Task for Multiword Expressions (MWE 2008). European Language Resources Association (ELRA), Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Heid</author>
</authors>
<title>On ways words work together – research topics in lexical combinatorics.</title>
<date>1994</date>
<booktitle>In Proceedings of the 6th Euralex International Congress on Lexicography (EURALEX ’94),</booktitle>
<pages>226--257</pages>
<location>Amsterdam, The Netherlands.</location>
<contexts>
<context position="8035" citStr="Heid (1994)" startWordPosition="1257" endWordPosition="1258">), and combined (Volk, 2002) methods have been developed to this end. However, as Hindle and Rooth (1993) pointed out, the parsers used by such methods lack precisely the kind of corpus-based information that is required to resolve ambiguity, because many of the existing attachments may be missing or wrong. The current literature provides no indication about the manner in which this circular problem can be circumvented, and on whether flexible MWEs should be processed before, during or after the sentence analysis takes place. 29 3 Parsing and Collocations As argued by many researchers – e.g., Heid (1994) – collocation identification is best performed on the basis of parsed material. This is due to the fact that collocations are co-occurrences of lexical items in a specific syntactic configuration. The collocation break record, for instance, is obtained only in the configurations where break is a verb whose direct object is (semantically) headed by the lexical item record. In other words, the collocation is not defined in terms of linear proximity, but in terms of a specific grammatical relation. As the examples in this section show, the relative order of the two items is not relevant, nor is </context>
<context position="16234" citStr="Heid, 1994" startWordPosition="2595" endWordPosition="2596">, for which we give the slightly simplified structure with the chain of elements with index i extending from the fronted wh-phrase which record to the direct object position of the verb break, via the direct object position of the verb consider and the subject position of the secondary predicate (FP) headed by the [+tough] adjective difficult. (5)a. Which record did Paul consider difficult to break ? b. [ CP [ DP which record]i [ TP did [ DP Paul ] [ VP consider ][ DP e]i [ FP [ DP e]i [ AP difficult [ to [ break [ e]i ] ] ] ] ] ] TP VP DP 3.2 Complex Collocations As stated, for instance, by (Heid, 1994), collocations can involve more than two (main) terms and it is possible to adopt a recursive definition of collocations, i.e., complex collocations can be viewed as collocations of collocations. The collocation identification procedure has been extended to handle such cases. Consider examples (6) below. (6)a. La voiture tombera probablement en panne d’essence. “the car will probably run out of gas” 31 b. natural language processing c. He broke a world record. In the French sentence (6a), panne d’essence (literally, “breakdown of gas”, “out of gas”) is a collocation of type Noun+Prep+Noun, whi</context>
</contexts>
<marker>Heid, 1994</marker>
<rawString>Heid, Ulrich. 1994. On ways words work together – research topics in lexical combinatorics. In Proceedings of the 6th Euralex International Congress on Lexicography (EURALEX ’94), pages 226–257, Amsterdam, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Hindle</author>
<author>Mats Rooth</author>
</authors>
<title>Structural ambiguity and lexical relations.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="4503" citStr="Hindle and Rooth, 1993" startWordPosition="683" endWordPosition="686">, in order to inform the subsequent processing applications (e.g., a machine translation application). Again, this solution is not fully appropriate, and the reason lies with the important observation that prior collocational knowledge is highly relevant for parsing. Collocational restrictions are, along with other types of information like selectional preferences and subcategorization frames, a major means of structural disambiguation. Collocational relations between the words in a sentence proved very helpful in selecting the most plausible among all the possible parse trees for a sentence (Hindle and Rooth, 1993; Alshawi and Carter, 1994; Berthouzoz and Merlo, 1997; Wehrli, 2000). Hence, the question whether collocations should be identified in a sentence before or after parsing is not an easy one. The previous literature on parsing and collocations fails to provide insightful details on how this circular issue is (or can be) solved. In this paper, we argue that the identification of collocations and the construction of a parse tree are interrelated processes, that must be accounted for simultaneously. We present a processing model in which collocations, if present in a lexicon, are identified in the</context>
<context position="7316" citStr="Hindle and Rooth, 1993" startWordPosition="1139" endWordPosition="1142">by using a MWE processor in the preprocessing stage of their parser (in development) for Basque, a significant improvement in the POStagging precision is obtained. Villavicencio et al. (2007) found that the addition of 21 new MWEs to the lexicon led to a significant increase in the grammar coverage (from 7.1% to 22.7%), without altering the grammar accuracy. An area of intensive research in parsing is concerned with the use of lexical preferences, cooccurrence frequencies, collocations, and contextually similar words for PP attachment disambiguation. Thus, an important number of unsupervised (Hindle and Rooth, 1993; Ratnaparkhi, 1998; Pantel and Lin, 2000), supervised (Alshawi and Carter, 1994; Berthouzoz and Merlo, 1997), and combined (Volk, 2002) methods have been developed to this end. However, as Hindle and Rooth (1993) pointed out, the parsers used by such methods lack precisely the kind of corpus-based information that is required to resolve ambiguity, because many of the existing attachments may be missing or wrong. The current literature provides no indication about the manner in which this circular problem can be circumvented, and on whether flexible MWEs should be processed before, during or a</context>
</contexts>
<marker>Hindle, Rooth, 1993</marker>
<rawString>Hindle, Donald and Mats Rooth. 1993. Structural ambiguity and lexical relations. Computational Linguistics, 19(1):103–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of The Tenth Machine Translation Summit (MT Summit X),</booktitle>
<pages>79--86</pages>
<location>Phuket, Thailand,</location>
<contexts>
<context position="24093" citStr="Koehn, 2005" startWordPosition="3933" endWordPosition="3934">crease in the precision of identified collocations, the new method also contributes to an increase in the parser coverage10, from 81.7% to 83.3%. The V1 parser version succeeds in building a complete parse tree for 23187 of the total 28375 sentences in the corpus, while V2 does so for 23629 sentences. 4.2 Recall Evaluation To compare the recall of two methods we performed a similar experiment, in which we run the two versions of the parser, V1 and V2, on a small collection of sentences containing annotated collocation instances. These sentences were randomly selected from the Europarl corpus (Koehn, 2005). The collocations they contain are all verb-object collocations. We limit our present investigation to this syntactic type for two reasons: a) annotating a corpus with all instances of collocation entries in the lexicon would be a time-consuming task; and b) verb-object collocations are among the most syntactically flexible and therefore difficult to detect in real texts. Thus, this test set provides realistic information on recall. 10Coverage refers more precisely to the ratio of sentences for which a complete parse tree could be built. 33 The test set is divided in two parts: 100 sentences </context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Koehn, Philipp. 2005. Europarl: A parallel corpus for statistical machine translation. In Proceedings of The Tenth Machine Translation Summit (MT Summit X), pages 79–86, Phuket, Thailand, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Orliac</author>
<author>Mike Dillinger</author>
</authors>
<title>Collocation extraction for machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of Machine Translation Summit IX,</booktitle>
<pages>292--298</pages>
<location>New Orleans, Lousiana, USA.</location>
<contexts>
<context position="27170" citStr="Orliac and Dillinger (2003)" startWordPosition="4422" endWordPosition="4425">1 V2 Common V1 only V2 only English 63 76 61 2 15 Italian 44 66 42 2 24 Table 4. Recall evaluation results: number of correct collocation instances identified. 4.3 Task-based Evaluation In addition to reporting the performance results by using the standard measures of precision and recall, we performed a task-based performance evaluation, in which we quantified the impact that the newly-proposed method has on the quality of the output of a machine translation system. As the examples in table 3 suggest, a literal translation of collocations is rarely the most appropriate. In fact, as stated by Orliac and Dillinger (2003), knowledge of collocations is crucial for machine translation systems. An important purpose in identifying collocations with our parser is to enable their proper treatment in our translation system, a rule-based system that performs syntactic transfer by relying on the structures produced by the parser. In this system, the translation of a collocation takes place as follows. When the parser identifies a collocation in the source sentence, its component words are marked as collocation members, in order to prevent their literal translation. When the transfer module processes the collocation hea</context>
</contexts>
<marker>Orliac, Dillinger, 2003</marker>
<rawString>Orliac, Brigitte and Mike Dillinger. 2003. Collocation extraction for machine translation. In Proceedings of Machine Translation Summit IX, pages 292–298, New Orleans, Lousiana, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Dekang Lin</author>
</authors>
<title>An unsupervised approach to prepositional phrase attachment using contextually similar words.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>101--108</pages>
<location>Hong Kong, China.</location>
<contexts>
<context position="7358" citStr="Pantel and Lin, 2000" startWordPosition="1145" endWordPosition="1148">ng stage of their parser (in development) for Basque, a significant improvement in the POStagging precision is obtained. Villavicencio et al. (2007) found that the addition of 21 new MWEs to the lexicon led to a significant increase in the grammar coverage (from 7.1% to 22.7%), without altering the grammar accuracy. An area of intensive research in parsing is concerned with the use of lexical preferences, cooccurrence frequencies, collocations, and contextually similar words for PP attachment disambiguation. Thus, an important number of unsupervised (Hindle and Rooth, 1993; Ratnaparkhi, 1998; Pantel and Lin, 2000), supervised (Alshawi and Carter, 1994; Berthouzoz and Merlo, 1997), and combined (Volk, 2002) methods have been developed to this end. However, as Hindle and Rooth (1993) pointed out, the parsers used by such methods lack precisely the kind of corpus-based information that is required to resolve ambiguity, because many of the existing attachments may be missing or wrong. The current literature provides no indication about the manner in which this circular problem can be circumvented, and on whether flexible MWEs should be processed before, during or after the sentence analysis takes place. 29</context>
</contexts>
<marker>Pantel, Lin, 2000</marker>
<rawString>Pantel, Patrick and Dekang Lin. 2000. An unsupervised approach to prepositional phrase attachment using contextually similar words. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, pages 101–108, Hong Kong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>Statistical models for unsupervised prepositional phrase attachment.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics,</booktitle>
<pages>1079--1085</pages>
<location>Montreal, Quebec, Canada.</location>
<contexts>
<context position="7335" citStr="Ratnaparkhi, 1998" startWordPosition="1143" endWordPosition="1144"> in the preprocessing stage of their parser (in development) for Basque, a significant improvement in the POStagging precision is obtained. Villavicencio et al. (2007) found that the addition of 21 new MWEs to the lexicon led to a significant increase in the grammar coverage (from 7.1% to 22.7%), without altering the grammar accuracy. An area of intensive research in parsing is concerned with the use of lexical preferences, cooccurrence frequencies, collocations, and contextually similar words for PP attachment disambiguation. Thus, an important number of unsupervised (Hindle and Rooth, 1993; Ratnaparkhi, 1998; Pantel and Lin, 2000), supervised (Alshawi and Carter, 1994; Berthouzoz and Merlo, 1997), and combined (Volk, 2002) methods have been developed to this end. However, as Hindle and Rooth (1993) pointed out, the parsers used by such methods lack precisely the kind of corpus-based information that is required to resolve ambiguity, because many of the existing attachments may be missing or wrong. The current literature provides no indication about the manner in which this circular problem can be circumvented, and on whether flexible MWEs should be processed before, during or after the sentence a</context>
</contexts>
<marker>Ratnaparkhi, 1998</marker>
<rawString>Ratnaparkhi, Adwait. 1998. Statistical models for unsupervised prepositional phrase attachment. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, pages 1079–1085, Montreal, Quebec, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan A Sag</author>
<author>Timothy Baldwin</author>
<author>Francis Bond</author>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third International Conference on Intelligent Text Processing and Computational Linguistics (CICLING</booktitle>
<pages>1--15</pages>
<location>Mexico City.</location>
<contexts>
<context position="2097" citStr="Sag et al., 2002" startWordPosition="311" endWordPosition="314"> the literature about 1We adopt the lexicographic understanding for the term collocation (Benson et al., 1986), as opposed to the British contextualist tradition focused on statistical co-occurrence (Firth, 1957; Sinclair, 1991). the actual use made of these resources in other NLP applications. In this paper, we consider the particular application of syntactic parsing. Just as other types of multi-word expressions (henceforth, MWEs), collocations are problematic for parsing because they have to be recognised and treated as a whole, rather than compositionally, i.e., in a word by word fashion (Sag et al., 2002). The standard approach in dealing with MWEs in parsing is to apply a “words-with-spaces” preprocessing step, which marks the MWEs in the input sentence as units which will later be integrated as single blocks in the parse tree built during analysis. We argue that such an approach, albeit sufficiently appropriate for some subtypes of MWEs2, is not really adequate for processing collocations. Unlike other expressions that are fixed or semi-fixed3, collocations do not allow a “wordswith-spaces” treatment because they have a high morpho-syntactic flexibility. There is no systematic restriction, f</context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>Sag, Ivan A., Timothy Baldwin, Francis Bond, Ann Copestake, and Dan Flickinger. 2002. Multiword expressions: A pain in the neck for NLP. In Proceedings of the Third International Conference on Intelligent Text Processing and Computational Linguistics (CICLING 2002), pages 1–15, Mexico City.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Sinclair</author>
</authors>
<title>Corpus, Concordance, Collocation.</title>
<date>1991</date>
<publisher>Oxford University Press,</publisher>
<location>Oxford.</location>
<contexts>
<context position="1708" citStr="Sinclair, 1991" startWordPosition="249" endWordPosition="250">1 Introduction Collocations1 constitute a central language phenomenon and an impressive amount of work has been devoted over the past decades to the automatic acquisition of collocational resources – as attested, among others, by initiatives like the MWE 2008 shared task aimed at creating a repository of reference data (Gr´egoire et al., 2008). However, little or no reference exist in the literature about 1We adopt the lexicographic understanding for the term collocation (Benson et al., 1986), as opposed to the British contextualist tradition focused on statistical co-occurrence (Firth, 1957; Sinclair, 1991). the actual use made of these resources in other NLP applications. In this paper, we consider the particular application of syntactic parsing. Just as other types of multi-word expressions (henceforth, MWEs), collocations are problematic for parsing because they have to be recognised and treated as a whole, rather than compositionally, i.e., in a word by word fashion (Sag et al., 2002). The standard approach in dealing with MWEs in parsing is to apply a “words-with-spaces” preprocessing step, which marks the MWEs in the input sentence as units which will later be integrated as single blocks i</context>
</contexts>
<marker>Sinclair, 1991</marker>
<rawString>Sinclair, John. 1991. Corpus, Concordance, Collocation. Oxford University Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aline Villavicencio</author>
<author>Valia Kordoni</author>
<author>Yi Zhang</author>
<author>Marco Idiart</author>
<author>Carlos Ramisch</author>
</authors>
<title>Validation and evaluation of automatically acquired multiword expressions for grammar engineering.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>1034--1043</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="6545" citStr="Villavicencio et al. (2007)" startWordPosition="1015" endWordPosition="1018">hat the integration of 210 nominal terms in the preprocessing components of the parser resulted in a significant reduction of the number of alternative parses (from an average of 4.21 to 2.79). The eliminated parses were found to be semantically undesirable. No valid analysis were ruled out. Similarly, Zhang and Kordoni (2006) extended a lexicon with 373 additional MWE lexical entries and obtained a significant increase in the coverage of an English grammar (14.4%, from 4.3% to 18.7%). In the cases mentioned above, a “words-withspaces” approach was used. In contrast, Alegria et al. (2004) and Villavicencio et al. (2007) adopted a compositional approach to the encoding of MWEs, able to capture more morphosyntactically flexible MWEs. Alegria et al. (2004) showed that by using a MWE processor in the preprocessing stage of their parser (in development) for Basque, a significant improvement in the POStagging precision is obtained. Villavicencio et al. (2007) found that the addition of 21 new MWEs to the lexicon led to a significant increase in the grammar coverage (from 7.1% to 22.7%), without altering the grammar accuracy. An area of intensive research in parsing is concerned with the use of lexical preferences,</context>
</contexts>
<marker>Villavicencio, Kordoni, Zhang, Idiart, Ramisch, 2007</marker>
<rawString>Villavicencio, Aline, Valia Kordoni, Yi Zhang, Marco Idiart, and Carlos Ramisch. 2007. Validation and evaluation of automatically acquired multiword expressions for grammar engineering. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 1034–1043, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Volk</author>
</authors>
<title>Combining unsupervised and supervised methods for PP attachment disambiguation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics (COLING’02),</booktitle>
<pages>25--32</pages>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="7452" citStr="Volk, 2002" startWordPosition="1160" endWordPosition="1161">ion is obtained. Villavicencio et al. (2007) found that the addition of 21 new MWEs to the lexicon led to a significant increase in the grammar coverage (from 7.1% to 22.7%), without altering the grammar accuracy. An area of intensive research in parsing is concerned with the use of lexical preferences, cooccurrence frequencies, collocations, and contextually similar words for PP attachment disambiguation. Thus, an important number of unsupervised (Hindle and Rooth, 1993; Ratnaparkhi, 1998; Pantel and Lin, 2000), supervised (Alshawi and Carter, 1994; Berthouzoz and Merlo, 1997), and combined (Volk, 2002) methods have been developed to this end. However, as Hindle and Rooth (1993) pointed out, the parsers used by such methods lack precisely the kind of corpus-based information that is required to resolve ambiguity, because many of the existing attachments may be missing or wrong. The current literature provides no indication about the manner in which this circular problem can be circumvented, and on whether flexible MWEs should be processed before, during or after the sentence analysis takes place. 29 3 Parsing and Collocations As argued by many researchers – e.g., Heid (1994) – collocation id</context>
</contexts>
<marker>Volk, 2002</marker>
<rawString>Volk, Martin. 2002. Combining unsupervised and supervised methods for PP attachment disambiguation. In Proceedings of the 19th International Conference on Computational Linguistics (COLING’02), pages 25–32, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Wehrli</author>
<author>Luka Nerima</author>
</authors>
<title>L’analyseur syntaxique Fips.</title>
<date>2009</date>
<booktitle>In Proceedings of the IWPT</booktitle>
<location>Paris, France.</location>
<contexts>
<context position="8863" citStr="Wehrli and Nerima, 2009" startWordPosition="1394" endWordPosition="1397">llocation break record, for instance, is obtained only in the configurations where break is a verb whose direct object is (semantically) headed by the lexical item record. In other words, the collocation is not defined in terms of linear proximity, but in terms of a specific grammatical relation. As the examples in this section show, the relative order of the two items is not relevant, nor is the distance between the two terms, which is unlimited as long as the grammatical relation holds4. In our system, the grammatical relations are computed by a syntactic parser, namely, Fips (Wehrli, 2007; Wehrli and Nerima, 2009). Until now, the collocation identification process took place at the end of the parse in a so-called “interpretation” procedure applied to the complete parse trees. Although quite successful, this way of doing presents a major drawback: it happens too late to help the parser. This section discusses this point and describes the alternative that we are currently developing, which consists in identifying collocations as soon as possible during the parse. One of the major hurdles for non-deterministic parsers is the huge number of alternatives that must be considered. Given the high frequency of </context>
</contexts>
<marker>Wehrli, Nerima, 2009</marker>
<rawString>Wehrli, Eric and Luka Nerima. 2009. L’analyseur syntaxique Fips. In Proceedings of the IWPT 2009 ATALA Workshop: What French parsing systems?, Paris, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Wehrli</author>
<author>Luka Nerima</author>
<author>Yves Scherrer</author>
</authors>
<title>Deep linguistic multilingual translation and bilingual dictionaries.</title>
<date>2009</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Machine Translation,</booktitle>
<pages>90--94</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Athens, Greece.</location>
<contexts>
<context position="3700" citStr="Wehrli et al. (2009" startWordPosition="569" endWordPosition="572">rated to the grammatical component as well, as the parser has to consi2Sag et al. (2002) thoroughly discusses the extend to which a “words-with-spaces” approach is appropriate for different kinds of MWEs. 3For instance, compound words: by and large, ad hoc; named entities: New York City; and non-decomposable idioms: shoot the breeze. 28 Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 28–36, Beijing, August 2010 der all the possible syntactic realisations of collocations. Alternatively, a post-processing approach (such as the one we pursued previously in Wehrli et al. (2009b)) would identify collocations after the syntactic analysis has been performed, and output a parse tree in which collocational relations are highlighted between the composing items, in order to inform the subsequent processing applications (e.g., a machine translation application). Again, this solution is not fully appropriate, and the reason lies with the important observation that prior collocational knowledge is highly relevant for parsing. Collocational restrictions are, along with other types of information like selectional preferences and subcategorization frames, a major means of struc</context>
<context position="17797" citStr="Wehrli et al. (2009" startWordPosition="2842" endWordPosition="2845">ng the last word, essence (“gas”), the parser will first identify the collocation panne d’essence. Since that collocation bears the lexical feature [+partOfCollocation], the identification procedure goes on, through the governors of that item. The search succeeds with the verb tomber, and the collocation tomber en panne d’essence (“run out of gas”) is identified. 4 Evaluation Experiments In this section, we describe the experiments we performed in order to evaluate the precision and recall of the method introduced in section 3, and to compare it against the previous method (fully described in Wehrli et al. (2009b)). We extend this comparison by performing a task-based evaluation, which investigates the impact that the new method has on the quality of translations produced by a machine translation system relying on our parser (Wehrli et al., 2009a). 4.1 Precision Evaluation The data considered in this experiment consist of a subpart of a corpus of newspaper articles collected from the on-line version of The Economist8, containing slightly more that 0.5 million words. On these data, we run two versions of our parser: • V1: a version implementing the previous method of collocation identification, • V2: </context>
</contexts>
<marker>Wehrli, Nerima, Scherrer, 2009</marker>
<rawString>Wehrli, Eric, Luka Nerima, and Yves Scherrer. 2009a. Deep linguistic multilingual translation and bilingual dictionaries. In Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 90–94, Athens, Greece. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Wehrli</author>
<author>Violeta Seretan</author>
<author>Luka Nerima</author>
<author>Lorenza Russo</author>
</authors>
<title>Collocations in a rule-based MT system: A case study evaluation of their translation adequacy.</title>
<date>2009</date>
<booktitle>In Proceedings of the 13th Annual Meeting of the European Association for Machine Translation,</booktitle>
<pages>128--135</pages>
<location>Barcelona,</location>
<contexts>
<context position="3700" citStr="Wehrli et al. (2009" startWordPosition="569" endWordPosition="572">rated to the grammatical component as well, as the parser has to consi2Sag et al. (2002) thoroughly discusses the extend to which a “words-with-spaces” approach is appropriate for different kinds of MWEs. 3For instance, compound words: by and large, ad hoc; named entities: New York City; and non-decomposable idioms: shoot the breeze. 28 Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 28–36, Beijing, August 2010 der all the possible syntactic realisations of collocations. Alternatively, a post-processing approach (such as the one we pursued previously in Wehrli et al. (2009b)) would identify collocations after the syntactic analysis has been performed, and output a parse tree in which collocational relations are highlighted between the composing items, in order to inform the subsequent processing applications (e.g., a machine translation application). Again, this solution is not fully appropriate, and the reason lies with the important observation that prior collocational knowledge is highly relevant for parsing. Collocational restrictions are, along with other types of information like selectional preferences and subcategorization frames, a major means of struc</context>
<context position="17797" citStr="Wehrli et al. (2009" startWordPosition="2842" endWordPosition="2845">ng the last word, essence (“gas”), the parser will first identify the collocation panne d’essence. Since that collocation bears the lexical feature [+partOfCollocation], the identification procedure goes on, through the governors of that item. The search succeeds with the verb tomber, and the collocation tomber en panne d’essence (“run out of gas”) is identified. 4 Evaluation Experiments In this section, we describe the experiments we performed in order to evaluate the precision and recall of the method introduced in section 3, and to compare it against the previous method (fully described in Wehrli et al. (2009b)). We extend this comparison by performing a task-based evaluation, which investigates the impact that the new method has on the quality of translations produced by a machine translation system relying on our parser (Wehrli et al., 2009a). 4.1 Precision Evaluation The data considered in this experiment consist of a subpart of a corpus of newspaper articles collected from the on-line version of The Economist8, containing slightly more that 0.5 million words. On these data, we run two versions of our parser: • V1: a version implementing the previous method of collocation identification, • V2: </context>
</contexts>
<marker>Wehrli, Seretan, Nerima, Russo, 2009</marker>
<rawString>Wehrli, Eric, Violeta Seretan, Luka Nerima, and Lorenza Russo. 2009b. Collocations in a rule-based MT system: A case study evaluation of their translation adequacy. In Proceedings of the 13th Annual Meeting of the European Association for Machine Translation, pages 128–135, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Wehrli</author>
</authors>
<title>Parsing and collocations.</title>
<date>2000</date>
<booktitle>Natural Language Processing,</booktitle>
<pages>272--282</pages>
<editor>In Christodoulakis, D., editor,</editor>
<publisher>Springer Verlag.</publisher>
<contexts>
<context position="4572" citStr="Wehrli, 2000" startWordPosition="696" endWordPosition="697">ranslation application). Again, this solution is not fully appropriate, and the reason lies with the important observation that prior collocational knowledge is highly relevant for parsing. Collocational restrictions are, along with other types of information like selectional preferences and subcategorization frames, a major means of structural disambiguation. Collocational relations between the words in a sentence proved very helpful in selecting the most plausible among all the possible parse trees for a sentence (Hindle and Rooth, 1993; Alshawi and Carter, 1994; Berthouzoz and Merlo, 1997; Wehrli, 2000). Hence, the question whether collocations should be identified in a sentence before or after parsing is not an easy one. The previous literature on parsing and collocations fails to provide insightful details on how this circular issue is (or can be) solved. In this paper, we argue that the identification of collocations and the construction of a parse tree are interrelated processes, that must be accounted for simultaneously. We present a processing model in which collocations, if present in a lexicon, are identified in the input sentence during the analysis of that sentence. At the same tim</context>
</contexts>
<marker>Wehrli, 2000</marker>
<rawString>Wehrli, Eric. 2000. Parsing and collocations. In Christodoulakis, D., editor, Natural Language Processing, pages 272–282. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Wehrli</author>
</authors>
<title>Fips, a “deep” linguistic multilingual parser.</title>
<date>2007</date>
<booktitle>In ACL 2007 Workshop on Deep Linguistic Processing,</booktitle>
<pages>120--127</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="8837" citStr="Wehrli, 2007" startWordPosition="1392" endWordPosition="1393">ration. The collocation break record, for instance, is obtained only in the configurations where break is a verb whose direct object is (semantically) headed by the lexical item record. In other words, the collocation is not defined in terms of linear proximity, but in terms of a specific grammatical relation. As the examples in this section show, the relative order of the two items is not relevant, nor is the distance between the two terms, which is unlimited as long as the grammatical relation holds4. In our system, the grammatical relations are computed by a syntactic parser, namely, Fips (Wehrli, 2007; Wehrli and Nerima, 2009). Until now, the collocation identification process took place at the end of the parse in a so-called “interpretation” procedure applied to the complete parse trees. Although quite successful, this way of doing presents a major drawback: it happens too late to help the parser. This section discusses this point and describes the alternative that we are currently developing, which consists in identifying collocations as soon as possible during the parse. One of the major hurdles for non-deterministic parsers is the huge number of alternatives that must be considered. Gi</context>
<context position="11754" citStr="Wehrli, 2007" startWordPosition="1844" endWordPosition="1845">es (“database management system”) c. force de maintien de la paix (“peacekeeping force”) d. organisation de protection de l’environnement (“environmental protection agency”) In such cases, the identification of a nounpreposition-noun collocation will prevent or discourage any other type of prepositional attachment that the parser would otherwise consider. 3.1 The Method To fulfill the goal of interconnecting the parsing procedure and the identification of collocations, we have incorporated the collocation identification mechanism within the constituent attachment procedure of our parser Fips (Wehrli, 2007). This parser, like many grammar-based parsers, uses left attachment and right attachment rules to build respectively left subconstituents and right subconstituents. Given the fact that Fips’ rules always involve exactly two constituents – see Wehrli (2007) for details – it is easy to add to the attachment mechanism the task of collocation identification. To take a very simple example, when the rule attaching a prenominal adjective to a noun applies, the collocation identification procedure is invoked. It first verifies that both terms bear the lexical 30 feature [+partOfCollocation], which si</context>
</contexts>
<marker>Wehrli, 2007</marker>
<rawString>Wehrli, Eric. 2007. Fips, a “deep” linguistic multilingual parser. In ACL 2007 Workshop on Deep Linguistic Processing, pages 120–127, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Zhang</author>
<author>Valia Kordoni</author>
</authors>
<title>Automated deep lexical acquisition for robust open texts processing.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC-2006,</booktitle>
<pages>275--280</pages>
<location>Genoa, Italy.</location>
<contexts>
<context position="6246" citStr="Zhang and Kordoni (2006)" startWordPosition="964" endWordPosition="968">g the lexical component of a parser with MWEs was proved to contribute to a significant improvement of the coverage and accuracy of parsing results. For instance, Brun (1998) compared the coverage of a French parser with and without terminology recognition in the preprocessing stage. She found that the integration of 210 nominal terms in the preprocessing components of the parser resulted in a significant reduction of the number of alternative parses (from an average of 4.21 to 2.79). The eliminated parses were found to be semantically undesirable. No valid analysis were ruled out. Similarly, Zhang and Kordoni (2006) extended a lexicon with 373 additional MWE lexical entries and obtained a significant increase in the coverage of an English grammar (14.4%, from 4.3% to 18.7%). In the cases mentioned above, a “words-withspaces” approach was used. In contrast, Alegria et al. (2004) and Villavicencio et al. (2007) adopted a compositional approach to the encoding of MWEs, able to capture more morphosyntactically flexible MWEs. Alegria et al. (2004) showed that by using a MWE processor in the preprocessing stage of their parser (in development) for Basque, a significant improvement in the POStagging precision i</context>
</contexts>
<marker>Zhang, Kordoni, 2006</marker>
<rawString>Zhang, Yi and Valia Kordoni. 2006. Automated deep lexical acquisition for robust open texts processing. In Proceedings of LREC-2006, pages 275–280, Genoa, Italy.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>