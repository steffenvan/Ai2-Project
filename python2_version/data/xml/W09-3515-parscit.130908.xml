<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000179">
<title confidence="0.9984755">
Combining a Two-step Conditional Random Field Model and a Joint
Source Channel Model for Machine Transliteration
</title>
<author confidence="0.979318">
Dong Yang, Paul Dixon, Yi-Cheng Pan, Tasuku Oonishi
Masanobu Nakamura and Sadaoki Furui
</author>
<affiliation confidence="0.9994365">
Department of Computer Science
Tokyo Institute of Techonology
</affiliation>
<email confidence="0.999141">
{raymond,dixonp,thomas,oonishi,masa,furui}@furui.cs.titech.ac.jp
</email>
<sectionHeader confidence="0.997393" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999177269230769">
This paper describes our system for
“NEWS 2009 Machine Transliteration
Shared Task” (NEWS 2009). We only par-
ticipated in the standard run, which is a
direct orthographical mapping (DOP) be-
tween two languages without using any
intermediate phonemic mapping. We
propose a new two-step conditional ran-
dom field (CRF) model for DOP machine
transliteration, in which the first CRF seg-
ments a source word into chunks and the
second CRF maps the chunks to a word
in the target language. The two-step CRF
model obtains a slightly lower top-1 ac-
curacy when compared to a state-of-the-
art n-gram joint source-channel model.
The combination of the CRF model with
the joint source-channel leads to improve-
ments in all the tasks. The official re-
sult of our system in the NEWS 2009
shared task confirms the effectiveness of
our system; where we achieved 0.627 top-
1 accuracy for Japanese transliterated to
Japanese Kanji(JJ), 0.713 for English-to-
Chinese(E2C) and 0.510 for English-to-
Japanese Katakana(E2J) .
</bodyText>
<sectionHeader confidence="0.999463" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999032909090909">
With the increasing demand for machine transla-
tion, the out-of-vocabulary (OOV) problem caused
by named entities is becoming more serious.
The translation of named entities from an alpha-
betic language (like English, French and Spanish)
to a non-alphabetic language (like Chinese and
Japanese) is usually performed through transliter-
ation, which tries to preserve the pronunciation in
the source language.
For example, in Japanese, foreign words im-
ported from other languages are usually written
</bodyText>
<subsectionHeader confidence="0.61815">
Source Name Target Name Note
T i m o t h y 㩖 㥿 㽓 English-to-Chinese
</subsectionHeader>
<bodyText confidence="0.703487">
ti mo xi Chinese Romanized writing
</bodyText>
<subsectionHeader confidence="0.449985">
H a r r i n g t o n 䊊 䊥 J 䊃 J English-to-Japanese
</subsectionHeader>
<bodyText confidence="0.608123">
ha ri n to n Japanese Romanized writing
</bodyText>
<figureCaption confidence="0.999571">
Figure 1: Transliteration examples
</figureCaption>
<bodyText confidence="0.999930575757576">
in a special syllabary called Katakana; in Chi-
nese, foreign words accepted to Chinese are al-
ways written by Chinese characters; examples are
given in Figure 1.
An intuitive transliteration method is to first
convert a source word into phonemes, then find the
corresponding phonemes in the target language,
and finally convert to the target language’s writ-
ing system (Knight and Graehl, 1998; Oh et al.,
2006). One major limitation of this method is that
the named entities are usually OOVs with diverse
origins and this makes the grapheme-to-phoneme
conversion very difficult.
DOP is gaining more attention in the transliter-
ation research community which is also the stan-
dard evaluation of NEWS 2009.
The source channel and joint source-channel
models (Li et al., 2004) have been proposed for
DOP, which try to model P(T |5) and P(T, 5) re-
spectively, where T and 5 denotes the words in
the target and source languages. (Ekbal et al.,
2006) modified the joint source-channel model to
incorporate different context information into the
model for the Indian languages. Here we propose
a two-step CRF model for transliteration, and the
idea is to make use of the discriminative ability of
CRF. For example, in E2C transliteration, the first
step is to segment an English name into alphabet
chunks and after this step the number of Chinese
characters is decided. The second step is to per-
form a context-dependent mapping from each En-
glish chunk into one Chinese character. Figure 1
shows that this method is applicable to many other
</bodyText>
<page confidence="0.987741">
72
</page>
<note confidence="0.983912">
Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 72–75,
Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.9973285">
transliteration tasks including E2C and E2J.
Our CRF method and the n-gram joint source-
channel model use different information in pre-
dicting the corresponding Chinese characters and
therefore in combination better results are ex-
pected. We interpolate the two models linearly
and use this as our final system for NEWS 2009.
The rest of the paper is organized as follows: Sec-
tion 2 introduces our system in detail including the
alignment and decoding modules, Section 3 ex-
plains our experiments and finally Section 4 de-
scribes conclusions and future work.
</bodyText>
<sectionHeader confidence="0.973337" genericHeader="method">
2 System Description
</sectionHeader>
<bodyText confidence="0.998902375">
Our system starts from a joint source channel
alignment to train the CRF segmenter. The CRF
is used to re-segment and align the training data,
and from this alignment we create a Weighted Fi-
nite State Transducer (WFST) based n-gram joint
source-channel decoder and a CRF E2C converter.
The following subsections explain the structure of
our system shown in Figure 2.
</bodyText>
<figureCaption confidence="0.994205">
Figure 2: System structure
</figureCaption>
<subsectionHeader confidence="0.9643875">
2.1 Theoretical background
2.1.1 Joint source channel model
</subsectionHeader>
<bodyText confidence="0.9999434">
The source channel model represents the condi-
tional probability of target names given a source
name P(T |S). The joint source channel model
calculates how the source words and target names
are generated simultaneously (Li et al., 2004):
</bodyText>
<equation confidence="0.947907428571429">
P(S, T) = P(s1, s2, ...,sk, t1, t2, ..., tk)
= P(&lt; s, t &gt;1, &lt; s, t &gt;2, ..., &lt; s, t &gt;k)
P(&lt; s, t &gt;k I &lt; s, t &gt;k−1
1 ) (1)
where, S = (s1, s2, ..., sk) and T =
(t1, t2, ..., tk).
2.1.2 CRF
</equation>
<bodyText confidence="0.998261333333333">
A CRF (Lafferty et al., 2001) is an undirected
graphical model which assigns a probability to a
label sequence L = l1l2 ... lT, given an input se-
</bodyText>
<equation confidence="0.9840255">
quence C = c1c2 ... cT,
T
P(L|C) = Z(C) exp(1:1:λkfk(lt, lt−1, C, t))
t=1 k
</equation>
<bodyText confidence="0.992998333333333">
(2)
For the kth feature, fk denotes the feature function
and λk is the parameter which controls the weight-
ing. Z(C) is a normalization term that ensure the
distribution sums to one. CRF training is usually
performed through the L-BFGS algorithm (Wal-
lach, 2002) and decoding is performed by Viterbi
algorithm (Viterbi, 1967). In this paper, we use an
open source toolkit “crf++”1.
</bodyText>
<subsectionHeader confidence="0.989386">
2.2 N-gram joint source-channel alignment
</subsectionHeader>
<bodyText confidence="0.9999316">
To calculate the probability in Equation 1, the
training corpus needs to be aligned first. We use
the Expectation-Maximization(EM) algorithm to
optimize the alignment A between the source S
and target T pairs, that is:
</bodyText>
<equation confidence="0.6204255">
A = arg max P(S, T, A) (3)
A
</equation>
<bodyText confidence="0.936108">
The procedure is summarized as follows:
</bodyText>
<listItem confidence="0.927676333333333">
1. Initialize a random alignment
2. E-step: update n-gram probability
3. M-step: apply the n-gram model to realign
each entry in corpus
4. Go to step 2 until the alignment converges
2.3 CRF alignment &amp; segmentation
</listItem>
<bodyText confidence="0.999115818181818">
The performance of EM algorithm is often af-
fected by the initialization. Fortunately, we can
correct mis-alignments by using the discriminative
ability of the CRF. The alignment problem is con-
verted into a tagging problem that doesn’t require
the use of the target words at all. Figure 3 is an
example of a segmentation and alignment, where
the labels B and N indicate whether the character
is in the starting position of the chunk or not.
In the CRF method the feature function de-
scribes a co-occurrence relation, and it is formally
</bodyText>
<table confidence="0.921650466666667">
1crfpp.sourceforge.net
Each pair in the training corpus
N-gram joint source-channel Alignment
CRF segmenter
New Alignment
Each source name in the test corpus
N-gram WFST decoder
CRF segmenter
CRF E2C converter
Linear combination
Output
CRF E2C converter
N-gram WFST decoder
Training
Testing
</table>
<equation confidence="0.399851">
K
= H
k=1
73
T i m o t h y 3% A
T/B i/N m/B o/N t/B h/N y/N
Ti/ mo/3% thy/A
</equation>
<figureCaption confidence="0.9791475">
Figure 3: An example of the CRF segmenter for-
mat and E2C converter
</figureCaption>
<bodyText confidence="0.9936916">
defined as fk(lt, lt−1, C, t) (Eq. 2). fk is usually a
binary function, and takes the value 1 when both
observation ct and transition lt−1 —* lt are ob-
served. In our segmentation tool, we use the fol-
lowing features
</bodyText>
<listItem confidence="0.992856">
• 1. Unigram features: C−2, C−1, C0, C1, C2
• 2. Bigram features:C−1C0, C0C1
</listItem>
<bodyText confidence="0.9996839375">
Here, C0 is the current character, C−1 and C1 de-
note the previous and next characters and C−2 and
C2 are the characters two positions to the left and
right of C0.
In the alignment process, we use the CRF seg-
menter to split each English word into chunks.
Sometimes a problem occurs in which the num-
ber of chunks in the segmented output will not be
equal to the number of Chinese characters. In such
cases our solution is to choose from the n-best list
the top scoring segmentation which contains the
correct number of chunks.
In the testing process, we use the segmenter in
the similar way, but only take top-1 output seg-
mented English chunks for use in the following
CRF E2C conversion.
</bodyText>
<subsectionHeader confidence="0.992898">
2.4 CRF E2C converter
</subsectionHeader>
<bodyText confidence="0.999987666666667">
Similar to the CRF segmenter, the CRF E2C con-
verter has the format shown in Figure 3. For this
CRF, we use the following features:
</bodyText>
<listItem confidence="0.9961925">
• 1. Unigram features: C−1, C0, C1
• 2. Bigram features:C−1C0, C0C1
</listItem>
<bodyText confidence="0.998330333333333">
where C represents the English chunks and the
subscript notation is the same as the CRF seg-
menter.
</bodyText>
<subsectionHeader confidence="0.5004395">
2.5 N-gram WFST decoder for joint source
channel model
</subsectionHeader>
<bodyText confidence="0.999979324324324">
Our decoding approach makes use of WFSTs to
represent the models and simplify the develop-
ment by utilizing standard operations such as com-
position and shortest path algorithms.
After the alignments are generated, the first
step is to build a corpus to train the translit-
eration WFST. Each aligned word is converted
to a sequence of transliteration alignment pairs
(s, t)1 , (s, t)2 , ... (s, t)k, where each s can be a
chunk of one or more characters and t is assumed
to be a single character. Each of the pairs is
treated as a word and the entire set of alignments is
used to train an n-gram language model. In these
evaluations we used the MITLM toolkit (Hsu and
Glass, 2008) to build a trigram model with modi-
fied Kneser-Ney smoothing.
We then use the procedure described in (Caseiro
et al., 2002) and convert the n-gram to a weighted
acceptor representation where each input label be-
longs to the set of transliteration alignment pairs.
Next the pairs labels are broken down into the in-
put and output parts and the acceptor is converted
to a transducer M. To allow transliteration from a
sequence of individual characters, a second WFST
T is constructed. T has a single state and for each
s a path is added to allow a mapping from the
string of individual characters.
To perform the actual transliteration, the input
word is converted to an acceptor I which has one
arc for each of the characters in the word. I is
then combined with T and M according to O =
I o T o M where o denotes the composition opera-
tor. The n–best paths are extracted from O by pro-
jecting the output, removing the epsilon labels and
applying the n-shortest paths algorithm with de-
terminization from the OpenFst Toolkit(Allauzen
et al., 2007).
</bodyText>
<subsectionHeader confidence="0.995465">
2.6 Linear combination
</subsectionHeader>
<bodyText confidence="0.999996833333333">
We notice that there is a significant difference be-
tween the correct answers of the n-gram WFST
and CRF decoders. The reason may be due to
the different information utilized in the two de-
coding methods. Since their performance levels
are similar, the overall performance is expected
to be improved by the combination. From the
CRF we compute the probability PCRF (T |S) and
from the list of scores output from the n-gram de-
coder we calculate the conditional probability of
Pn−gram(T|S). These are used in our combina-
tion method according to:
</bodyText>
<equation confidence="0.752296">
P(T|S) = APCRF(T|S)+(1−A)Pn−gram(T|S)
(4)
</equation>
<bodyText confidence="0.8864895">
where A denotes the interpolation weight (0.3 in
this paper).
</bodyText>
<page confidence="0.998685">
74
</page>
<sectionHeader confidence="0.999211" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.9999816">
We use the training and development sets of
NEWS 2009 data in our experiments as detailed
in Table 12. There are several measure metrics in
the shared task and due to limited space in this pa-
per we provide the results for top-1 accuracy.
</bodyText>
<table confidence="0.970941">
Task Training data size Test data size
E2C 31961 2896
E2J 23808 1509
</table>
<tableCaption confidence="0.988091">
Table 1: Corpus introduction
</tableCaption>
<table confidence="0.9994702">
Task n-gram+CRF interpolation
Alignment
WFST CRF
E2C 70.3 67.3 71.5
E2J 44.9 44.8 46.7
</table>
<tableCaption confidence="0.997502">
Table 2: Top-1 accuracies(%)
</tableCaption>
<bodyText confidence="0.999898875">
The results are listed in Table 2. For E2C
task the top-1 accuracy of the joint source-channel
model is 70.3% and 67.3% for the two-step CRF
model. After combining the two results together
the top-1 accuracy increases to 71.5% correspond-
ing to a 1.2% absolute improvement over the state-
of-the-art joint source-channel model. Similarly,
we get 1.8% absolute improvement for E2J task.
</bodyText>
<sectionHeader confidence="0.997978" genericHeader="conclusions">
4 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999578266666667">
In this paper we have presented our new hybrid
method for machine transliteration which com-
bines a new two-step CRF model with a state-of-
the-art joint source-channel model. In compari-
son to the joint source-channel model the combi-
nation approach achieved 1.2% and 1.8% absolute
improvements for E2C and E2J task respectively.
In the first step of the CRF method we only
use the top-1 segmentation, which may propagate
transliteration errors to the following step. In fu-
ture work we would like to optimize the 2-step
CRF jointly. Currently, we are also investigating
minimum classification error (MCE) discriminant
training as a method to further improve the joint
source channel model.
</bodyText>
<footnote confidence="0.8983575">
2For the JJ task the submitted results
are only based on the joint source
channel model. Unfortunately, we were
unable to submit a combination result
because the training time for the CRF
was too long.
</footnote>
<sectionHeader confidence="0.996907" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.783353">
The corpora used in this paper are from ”NEWS
2009 Machine Transliteration Shared Task” (Li et
al., 2004; CJK, website)
</bodyText>
<sectionHeader confidence="0.975061" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994727642857143">
Kevin Knight and Jonathan Graehl. 1998. Machine
Transliteration, 1998 Association for Computa-
tional Linguistics.
Li Haizhou, Zhang Min and Su Jian. 2004. A joint
source-channel model for machine transliteration,
2004 Proceedings of the 42nd Annual Meeting on
Association for Computational Linguistics.
Asif Ekbal, Sudip Kumar Naskar and Sivaji Bandy-
opadhyay. 2006. A modified joint source-channel
model for transliteration, Proceedings of the COL-
ING/ACL, pages 191-198.
Jong-Hoon Oh, Key-Sun Choi and Hitoshi Isahara.
2006. A comparison of different machine transliter-
ation models , Journal of Artificial Intelligence Re-
search, 27, pages 119-151.
John Lafferty, Andrew McCallum, and Fernando
Pereira 2001. Conditional Random Fields: Prob-
abilistic Models for Segmenting and Labeling Se-
quence Data., Proceedings of International Confer-
ence on Machine Learning, 2001, pages 282-289.
Hanna Wallach 2002. Efficient Training of Condi-
tional Random Fields. M. Thesis, University of Ed-
inburgh, 2002.
Andrew J. Viterbi 1967. Error Bounds for Convolu-
tional Codes and an Asymptotically Optimum De-
coding Algorithm. IEEE Transactions on Informa-
tion Theory, Volume IT-13, 1967,pages 260-269.
Bo-June Hsu and James Glass 2008. Iterative Lan-
guage Model Estimation: Efficient Data Structure
&amp; Algorithms. Proceedings Interspeech, pages 841-
844.
Diamantino Caseiro, Isabel Trancosoo, Luis Oliveira
and Ceu Viana 2002. Grapheme-to-phone using
finite state transducers. Proceedings 2002 IEEE
Workshop on Speech Synthesis.
Cyril Allauzen, Michael Riley, Johan Schalkwyk, Wo-
jciech Skut and Mehryar Mohri 2002. OpenFst: A
General and Efficient Weighted Finite-State Trans-
ducer Library. Proceedings of the Ninth Interna-
tional Conference on Implementation and Applica-
tion of Automata, (CIAA 2007), pages 11-23.
http://www.cjk.org
</reference>
<page confidence="0.998707">
75
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.514538">
<title confidence="0.9976405">Combining a Two-step Conditional Random Field Model and a Source Channel Model for Machine Transliteration</title>
<author confidence="0.950128">Dong Yang</author>
<author confidence="0.950128">Paul Dixon</author>
<author confidence="0.950128">Yi-Cheng Pan</author>
<author confidence="0.950128">Tasuku Masanobu Nakamura</author>
<author confidence="0.950128">Sadaoki</author>
<affiliation confidence="0.9847645">Department of Computer Tokyo Institute of</affiliation>
<abstract confidence="0.99847447826087">This paper describes our system for “NEWS 2009 Machine Transliteration Shared Task” (NEWS 2009). We only participated in the standard run, which is a direct orthographical mapping (DOP) between two languages without using any intermediate phonemic mapping. We propose a new two-step conditional random field (CRF) model for DOP machine transliteration, in which the first CRF segments a source word into chunks and the second CRF maps the chunks to a word in the target language. The two-step CRF model obtains a slightly lower top-1 accuracy when compared to a state-of-theart n-gram joint source-channel model. The combination of the CRF model with the joint source-channel leads to improvements in all the tasks. The official result of our system in the NEWS 2009 shared task confirms the effectiveness of our system; where we achieved 0.627 top-</abstract>
<note confidence="0.80920525">1 accuracy for Japanese transliterated to Japanese Kanji(JJ), 0.713 for English-to- Chinese(E2C) and 0.510 for English-to- Japanese Katakana(E2J) .</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Jonathan Graehl</author>
</authors>
<title>Association for Computational Linguistics.</title>
<date>1998</date>
<booktitle>Machine Transliteration,</booktitle>
<contexts>
<context position="2457" citStr="Knight and Graehl, 1998" startWordPosition="385" endWordPosition="388">tten Source Name Target Name Note T i m o t h y 㩖 㥿 㽓 English-to-Chinese ti mo xi Chinese Romanized writing H a r r i n g t o n 䊊 䊥 J 䊃 J English-to-Japanese ha ri n to n Japanese Romanized writing Figure 1: Transliteration examples in a special syllabary called Katakana; in Chinese, foreign words accepted to Chinese are always written by Chinese characters; examples are given in Figure 1. An intuitive transliteration method is to first convert a source word into phonemes, then find the corresponding phonemes in the target language, and finally convert to the target language’s writing system (Knight and Graehl, 1998; Oh et al., 2006). One major limitation of this method is that the named entities are usually OOVs with diverse origins and this makes the grapheme-to-phoneme conversion very difficult. DOP is gaining more attention in the transliteration research community which is also the standard evaluation of NEWS 2009. The source channel and joint source-channel models (Li et al., 2004) have been proposed for DOP, which try to model P(T |5) and P(T, 5) respectively, where T and 5 denotes the words in the target and source languages. (Ekbal et al., 2006) modified the joint source-channel model to incorpo</context>
</contexts>
<marker>Knight, Graehl, 1998</marker>
<rawString>Kevin Knight and Jonathan Graehl. 1998. Machine Transliteration, 1998 Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Haizhou</author>
<author>Zhang Min</author>
<author>Su Jian</author>
</authors>
<title>A joint source-channel model for machine transliteration,</title>
<date>2004</date>
<booktitle>Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics.</booktitle>
<marker>Haizhou, Min, Jian, 2004</marker>
<rawString>Li Haizhou, Zhang Min and Su Jian. 2004. A joint source-channel model for machine transliteration, 2004 Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asif Ekbal</author>
</authors>
<title>Sudip Kumar Naskar and Sivaji Bandyopadhyay.</title>
<date>2006</date>
<booktitle>Proceedings of the COLING/ACL,</booktitle>
<pages>191--198</pages>
<marker>Ekbal, 2006</marker>
<rawString>Asif Ekbal, Sudip Kumar Naskar and Sivaji Bandyopadhyay. 2006. A modified joint source-channel model for transliteration, Proceedings of the COLING/ACL, pages 191-198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jong-Hoon Oh</author>
<author>Key-Sun Choi</author>
<author>Hitoshi Isahara</author>
</authors>
<title>A comparison of different machine transliteration models ,</title>
<date>2006</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>27</volume>
<pages>119--151</pages>
<contexts>
<context position="2475" citStr="Oh et al., 2006" startWordPosition="389" endWordPosition="392">ame Note T i m o t h y 㩖 㥿 㽓 English-to-Chinese ti mo xi Chinese Romanized writing H a r r i n g t o n 䊊 䊥 J 䊃 J English-to-Japanese ha ri n to n Japanese Romanized writing Figure 1: Transliteration examples in a special syllabary called Katakana; in Chinese, foreign words accepted to Chinese are always written by Chinese characters; examples are given in Figure 1. An intuitive transliteration method is to first convert a source word into phonemes, then find the corresponding phonemes in the target language, and finally convert to the target language’s writing system (Knight and Graehl, 1998; Oh et al., 2006). One major limitation of this method is that the named entities are usually OOVs with diverse origins and this makes the grapheme-to-phoneme conversion very difficult. DOP is gaining more attention in the transliteration research community which is also the standard evaluation of NEWS 2009. The source channel and joint source-channel models (Li et al., 2004) have been proposed for DOP, which try to model P(T |5) and P(T, 5) respectively, where T and 5 denotes the words in the target and source languages. (Ekbal et al., 2006) modified the joint source-channel model to incorporate different con</context>
</contexts>
<marker>Oh, Choi, Isahara, 2006</marker>
<rawString>Jong-Hoon Oh, Key-Sun Choi and Hitoshi Isahara. 2006. A comparison of different machine transliteration models , Journal of Artificial Intelligence Research, 27, pages 119-151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data.,</title>
<date>2001</date>
<booktitle>Proceedings of International Conference on Machine Learning,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="5214" citStr="Lafferty et al., 2001" startWordPosition="859" endWordPosition="862"> The following subsections explain the structure of our system shown in Figure 2. Figure 2: System structure 2.1 Theoretical background 2.1.1 Joint source channel model The source channel model represents the conditional probability of target names given a source name P(T |S). The joint source channel model calculates how the source words and target names are generated simultaneously (Li et al., 2004): P(S, T) = P(s1, s2, ...,sk, t1, t2, ..., tk) = P(&lt; s, t &gt;1, &lt; s, t &gt;2, ..., &lt; s, t &gt;k) P(&lt; s, t &gt;k I &lt; s, t &gt;k−1 1 ) (1) where, S = (s1, s2, ..., sk) and T = (t1, t2, ..., tk). 2.1.2 CRF A CRF (Lafferty et al., 2001) is an undirected graphical model which assigns a probability to a label sequence L = l1l2 ... lT, given an input sequence C = c1c2 ... cT, T P(L|C) = Z(C) exp(1:1:λkfk(lt, lt−1, C, t)) t=1 k (2) For the kth feature, fk denotes the feature function and λk is the parameter which controls the weighting. Z(C) is a normalization term that ensure the distribution sums to one. CRF training is usually performed through the L-BFGS algorithm (Wallach, 2002) and decoding is performed by Viterbi algorithm (Viterbi, 1967). In this paper, we use an open source toolkit “crf++”1. 2.2 N-gram joint source-chan</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira 2001. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data., Proceedings of International Conference on Machine Learning, 2001, pages 282-289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hanna Wallach</author>
</authors>
<title>Efficient Training of Conditional Random Fields.</title>
<date>2002</date>
<tech>M. Thesis,</tech>
<institution>University of Edinburgh,</institution>
<contexts>
<context position="5666" citStr="Wallach, 2002" startWordPosition="942" endWordPosition="944">t &gt;1, &lt; s, t &gt;2, ..., &lt; s, t &gt;k) P(&lt; s, t &gt;k I &lt; s, t &gt;k−1 1 ) (1) where, S = (s1, s2, ..., sk) and T = (t1, t2, ..., tk). 2.1.2 CRF A CRF (Lafferty et al., 2001) is an undirected graphical model which assigns a probability to a label sequence L = l1l2 ... lT, given an input sequence C = c1c2 ... cT, T P(L|C) = Z(C) exp(1:1:λkfk(lt, lt−1, C, t)) t=1 k (2) For the kth feature, fk denotes the feature function and λk is the parameter which controls the weighting. Z(C) is a normalization term that ensure the distribution sums to one. CRF training is usually performed through the L-BFGS algorithm (Wallach, 2002) and decoding is performed by Viterbi algorithm (Viterbi, 1967). In this paper, we use an open source toolkit “crf++”1. 2.2 N-gram joint source-channel alignment To calculate the probability in Equation 1, the training corpus needs to be aligned first. We use the Expectation-Maximization(EM) algorithm to optimize the alignment A between the source S and target T pairs, that is: A = arg max P(S, T, A) (3) A The procedure is summarized as follows: 1. Initialize a random alignment 2. E-step: update n-gram probability 3. M-step: apply the n-gram model to realign each entry in corpus 4. Go to step </context>
</contexts>
<marker>Wallach, 2002</marker>
<rawString>Hanna Wallach 2002. Efficient Training of Conditional Random Fields. M. Thesis, University of Edinburgh, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew J Viterbi</author>
</authors>
<title>Error Bounds for Convolutional Codes and an Asymptotically Optimum Decoding Algorithm.</title>
<date>1967</date>
<journal>IEEE Transactions on Information Theory,</journal>
<volume>13</volume>
<pages>1967--260</pages>
<contexts>
<context position="5729" citStr="Viterbi, 1967" startWordPosition="952" endWordPosition="953">(1) where, S = (s1, s2, ..., sk) and T = (t1, t2, ..., tk). 2.1.2 CRF A CRF (Lafferty et al., 2001) is an undirected graphical model which assigns a probability to a label sequence L = l1l2 ... lT, given an input sequence C = c1c2 ... cT, T P(L|C) = Z(C) exp(1:1:λkfk(lt, lt−1, C, t)) t=1 k (2) For the kth feature, fk denotes the feature function and λk is the parameter which controls the weighting. Z(C) is a normalization term that ensure the distribution sums to one. CRF training is usually performed through the L-BFGS algorithm (Wallach, 2002) and decoding is performed by Viterbi algorithm (Viterbi, 1967). In this paper, we use an open source toolkit “crf++”1. 2.2 N-gram joint source-channel alignment To calculate the probability in Equation 1, the training corpus needs to be aligned first. We use the Expectation-Maximization(EM) algorithm to optimize the alignment A between the source S and target T pairs, that is: A = arg max P(S, T, A) (3) A The procedure is summarized as follows: 1. Initialize a random alignment 2. E-step: update n-gram probability 3. M-step: apply the n-gram model to realign each entry in corpus 4. Go to step 2 until the alignment converges 2.3 CRF alignment &amp; segmentatio</context>
</contexts>
<marker>Viterbi, 1967</marker>
<rawString>Andrew J. Viterbi 1967. Error Bounds for Convolutional Codes and an Asymptotically Optimum Decoding Algorithm. IEEE Transactions on Information Theory, Volume IT-13, 1967,pages 260-269.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo-June Hsu</author>
<author>James Glass</author>
</authors>
<title>Iterative Language Model Estimation: Efficient Data Structure &amp; Algorithms.</title>
<date>2008</date>
<booktitle>Proceedings Interspeech,</booktitle>
<pages>841--844</pages>
<contexts>
<context position="9330" citStr="Hsu and Glass, 2008" startWordPosition="1594" endWordPosition="1597"> models and simplify the development by utilizing standard operations such as composition and shortest path algorithms. After the alignments are generated, the first step is to build a corpus to train the transliteration WFST. Each aligned word is converted to a sequence of transliteration alignment pairs (s, t)1 , (s, t)2 , ... (s, t)k, where each s can be a chunk of one or more characters and t is assumed to be a single character. Each of the pairs is treated as a word and the entire set of alignments is used to train an n-gram language model. In these evaluations we used the MITLM toolkit (Hsu and Glass, 2008) to build a trigram model with modified Kneser-Ney smoothing. We then use the procedure described in (Caseiro et al., 2002) and convert the n-gram to a weighted acceptor representation where each input label belongs to the set of transliteration alignment pairs. Next the pairs labels are broken down into the input and output parts and the acceptor is converted to a transducer M. To allow transliteration from a sequence of individual characters, a second WFST T is constructed. T has a single state and for each s a path is added to allow a mapping from the string of individual characters. To per</context>
</contexts>
<marker>Hsu, Glass, 2008</marker>
<rawString>Bo-June Hsu and James Glass 2008. Iterative Language Model Estimation: Efficient Data Structure &amp; Algorithms. Proceedings Interspeech, pages 841-844.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diamantino Caseiro</author>
</authors>
<title>Isabel Trancosoo, Luis Oliveira and Ceu</title>
<date>2002</date>
<booktitle>Proceedings 2002 IEEE Workshop on Speech Synthesis.</booktitle>
<location>Viana</location>
<marker>Caseiro, 2002</marker>
<rawString>Diamantino Caseiro, Isabel Trancosoo, Luis Oliveira and Ceu Viana 2002. Grapheme-to-phone using finite state transducers. Proceedings 2002 IEEE Workshop on Speech Synthesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cyril Allauzen</author>
<author>Michael Riley</author>
<author>Johan Schalkwyk</author>
</authors>
<title>Wojciech Skut and Mehryar Mohri</title>
<date>2002</date>
<booktitle>Proceedings of the Ninth International Conference on Implementation and Application of Automata,</booktitle>
<pages>11--23</pages>
<location>CIAA</location>
<marker>Allauzen, Riley, Schalkwyk, 2002</marker>
<rawString>Cyril Allauzen, Michael Riley, Johan Schalkwyk, Wojciech Skut and Mehryar Mohri 2002. OpenFst: A General and Efficient Weighted Finite-State Transducer Library. Proceedings of the Ninth International Conference on Implementation and Application of Automata, (CIAA 2007), pages 11-23.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>