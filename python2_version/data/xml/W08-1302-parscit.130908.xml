<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001477">
<title confidence="0.999265">
Exploring an Auxiliary Distribution based approach to
Domain Adaptation of a Syntactic Disambiguation Model
</title>
<author confidence="0.987383">
Barbara Plank Gertjan van Noord
</author>
<affiliation confidence="0.9640475">
University of Groningen University of Groningen
The Netherlands The Netherlands
</affiliation>
<email confidence="0.996939">
B.Plank@rug.nl G.J.M.van.Noord@rug.nl
</email>
<sectionHeader confidence="0.993833" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999944533333333">
We investigate auxiliary distribu-
tions (Johnson and Riezler, 2000) for
domain adaptation of a supervised parsing
system of Dutch. To overcome the limited
target domain training data, we exploit an
original and larger out-of-domain model
as auxiliary distribution. However, our
empirical results exhibit that the auxiliary
distribution does not help: even when very
little target training data is available the
incorporation of the out-of-domain model
does not contribute to parsing accuracy on
the target domain; instead, better results
are achieved either without adaptation or
by simple model combination.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999108">
Modern statistical parsers are trained on large an-
notated corpora (treebanks) and their parameters
are estimated to reflect properties of the training
data. Therefore, a disambiguation component will
be successful as long as the treebank it was trained
on is representative for the input the model gets.
However, as soon as the model is applied to an-
other domain, or text genre (Lease et al., 2006),
accuracy degrades considerably. For example, the
performance of a parser trained on the Wall Street
Journal (newspaper text) significantly drops when
evaluated on the more varied Brown (fiction/non-
fiction) corpus (Gildea, 2001).
A simple solution to improve performance on
a new domain is to construct a parser specifically
</bodyText>
<note confidence="0.72325">
© 2008. Licensed under the Creative Commons
</note>
<footnote confidence="0.967149333333333">
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
</footnote>
<bodyText confidence="0.99998296875">
for that domain. However, this amounts to hand-
labeling a considerable amount of training data
which is clearly very expensive and leads to an un-
satisfactory solution. In alternative, techniques for
domain adaptation, also known as parser adap-
tation (McClosky et al., 2006) or genre porta-
bility (Lease et al., 2006), try to leverage ei-
ther a small amount of already existing annotated
data (Hara et al., 2005) or unlabeled data (Mc-
Closky et al., 2006) of one domain to parse data
from a different domain. In this study we examine
an approach that assumes a limited amount of al-
ready annotated in-domain data.
We explore auxiliary distributions (Johnson and
Riezler, 2000) for domain adaptation, originally
suggested for the incorporation of lexical selec-
tional preferences into a parsing system. We gauge
the effect of exploiting a more general, out-of-
domain model for parser adaptation to overcome
the limited amount of in-domain training data. The
approach is examined on two application domains,
question answering and spoken data.
For the empirical trials, we use Alpino (van No-
ord and Malouf, 2005; van Noord, 2006), a ro-
bust computational analyzer for Dutch. Alpino
employs a discriminative approach to parse selec-
tion that bases its decision on a Maximum Entropy
(MaxEnt) model. Section 2 introduces the MaxEnt
framework. Section 3 describes our approach of
exploring auxiliary distributions for domain adap-
tation. In section 4 the experimental design and
empirical results are presented and discussed.
</bodyText>
<sectionHeader confidence="0.981518" genericHeader="method">
2 Background: MaxEnt Models
</sectionHeader>
<bodyText confidence="0.91463425">
Maximum Entropy (MaxEnt) models are widely
used in Natural Language Processing (Berger et
al., 1996; Ratnaparkhi, 1997; Abney, 1997). In
this framework, a disambiguation model is speci-
</bodyText>
<page confidence="0.964438">
9
</page>
<note confidence="0.8475205">
Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation, pages 9–16
Manchester, August 2008
</note>
<bodyText confidence="0.999692418604651">
fied by a set of feature functions describing prop-
erties of the data, together with their associated
weights. The weights are learned during the train-
ing procedure so that their estimated value deter-
mines the contribution of each feature. In the task
of parsing, features appearing in correct parses are
given increasing weight, while features in incorrect
parses are given decreasing weight. Once a model
is trained, it can be applied to parse selection that
chooses the parse with the highest sum of feature
weights.
During the training procedure, the weights vec-
tor is estimated to best fit the training data. In
more detail, given m features with their corre-
sponding empirical expectation E˜p[fj] and a de-
fault model q0, we seek a model p that has mini-
mum Kullback-Leibler (KL) divergence from the
default model q0, subject to the expected-value
constraints: Ep[fj] = E˜p[fj], where j E 1, ..., m.
In MaxEnt estimation, the default model q0 is
often only implicit (Velldal and Oepen, 2005) and
not stated in the model equation, since the model
is assumed to be uniform (e.g. the constant func-
tion 1
Ω(s) for sentence s, where Q(s) is the set of
parse trees associated with s). Thus, we seek the
model with minimum KL divergence from the uni-
form distribution, which means we search model
p with maximum entropy (uncertainty) subject to
given constraints (Abney, 1997).
In alternative, if q0 is not uniform then p is
called a minimum divergence model (according
to (Berger and Printz, 1998)). In the statistical
parsing literature, the default model q0 that can
be used to incorporate prior knowledge is also re-
ferred to as base model (Berger and Printz, 1998),
default or reference distribution (Hara et al., 2005;
Johnson et al., 1999; Velldal and Oepen, 2005).
The solution to the estimation problem of find-
ing distribution p, that satisfies the expected-
value constraints and minimally diverges from
q0, has been shown to take a specific parametric
form (Berger and Printz, 1998):
</bodyText>
<equation confidence="0.992339">
1 pθ(ω, s) = Z g0expP&apos; 1 θjfj(ω) (1)
B
</equation>
<bodyText confidence="0.988584333333333">
with m feature functions, s being the input sen-
tence, ω a corresponding parse tree, and Zθ the
normalization equation:
</bodyText>
<equation confidence="0.9922745">
�Zθ = Pm j=1 θjfj(ω′)
ω′∈Ω q0exp (2)
</equation>
<bodyText confidence="0.9999855">
Since the sum in equation 2 ranges over all pos-
sible parse trees ω′ E Q admitted by the gram-
mar, calculating the normalization constant ren-
ders the estimation process expensive or even in-
tractable (Johnson et al., 1999). To tackle this
problem, Johnson et al. (1999) redefine the esti-
mation procedure by considering the conditional
rather than the joint probability.
</bodyText>
<equation confidence="0.983626">
Pθ (ω s) = Z g0expPj=1 θj fj (ω) (3)
e
</equation>
<bodyText confidence="0.998911411764706">
with Zθ as in equation 2, but instead, summing
over ω′ E Q(s), where Q(s) is the set of parse
trees associated with sentence s. Thus, the proba-
bility of a parse tree is estimated by summing only
over the possible parses of a specific sentence.
Still, calculating Q(s) is computationally very
expensive (Osborne, 2000), because the number of
parses is in the worst case exponential with respect
to sentence length. Therefore, Osborne (2000) pro-
poses a solution based on informative samples. He
shows that is suffices to train on an informative
subset of available training data to accurately es-
timate the model parameters. Alpino implements
the Osborne-style approach to Maximum Entropy
parsing. The standard version of the Alpino parser
is trained on the Alpino newspaper Treebank (van
Noord, 2006).
</bodyText>
<sectionHeader confidence="0.987009" genericHeader="method">
3 Exploring auxiliary distributions for
domain adaptation
</sectionHeader>
<subsectionHeader confidence="0.999872">
3.1 Auxiliary distributions
</subsectionHeader>
<bodyText confidence="0.999739333333333">
Auxiliary distributions (Johnson and Riezler,
2000) offer the possibility to incorporate informa-
tion from additional sources into a MaxEnt Model.
In more detail, auxiliary distributions are inte-
grated by considering the logarithm of the proba-
bility given by an auxiliary distribution as an addi-
tional, real-valued feature. More formally, given k
auxiliary distributions Qi(ω), then k new auxiliary
features fm+1, ..., fm+k are added such that
</bodyText>
<equation confidence="0.998919">
fm+i(ω) = logQi(ω) (4)
</equation>
<bodyText confidence="0.999758">
where Qi(ω) do not need to be proper probability
distributions, however they must strictly be posi-
tive Vω E Q (Johnson and Riezler, 2000).
The auxiliary distributions resemble a reference
distribution, but instead of considering a single
reference distribution they have the advantage
that several auxiliary distributions can be inte-
grated and weighted against each other. John-
</bodyText>
<page confidence="0.996948">
10
</page>
<bodyText confidence="0.974080333333333">
son establishes the following equivalence between
the two (Johnson and Riezler, 2000; Velldal and
Oepen, 2005):
</bodyText>
<equation confidence="0.997899">
k
Q(ω) = Qi(ω)θm+i (5)
i=1
</equation>
<bodyText confidence="0.999906857142857">
where Q(ω) is the reference distribution and
Qi(ω) is an auxiliary distribution. Hence, the con-
tribution of each auxiliary distribution is regulated
through the estimated feature weight. In general,
a model that includes k auxiliary features as given
in equation (4) takes the following form (Johnson
and Riezler, 2000):
</bodyText>
<equation confidence="0.976728">
Pθ(ω |s) = Hki=1 QZBω)θm+i expPT 1 θjfj(ω) (6)
</equation>
<bodyText confidence="0.6203188">
Due to the equivalence relation in equation (5)
we can restate the equation to explicitly show that
auxiliary distributions are additional features1.
1 Zθ expEj=1k θj fj (ω)
with fj(w) = logQ(w) for m &lt; j ≤ (m + k)
</bodyText>
<subsectionHeader confidence="0.999644">
3.2 Auxiliary distributions for adaptation
</subsectionHeader>
<bodyText confidence="0.9982759">
While (Johnson and Riezler, 2000; van Noord,
2007) focus on incorporating several auxiliary dis-
tributions for lexical selectional preferences, in
this study we explore auxiliary distributions for do-
main adaptation.
We exploit the information of the more gen-
eral model, estimated from a larger, out-of-domain
treebank, for parsing data from a particular tar-
get domain, where only a small amount of train-
ing data is available. A related study is Hara
et al. (2005). While they also assume a limited
amount of in-domain training data, their approach
1Note that the step from equation (6) to (7) holds by re-
stating equation (4) as Qi(w) = expfm+i(ω)
differs from ours in that they incorporate an origi-
nal model as a reference distribution, and their es-
timation procedure is based on parse forests (Hara
et al., 2005; van Noord, 2006), rather than infor-
mative samples. In this study, we want to gauge
the effect of auxiliary distributions, which have the
advantage that the contribution of the additional
source is regulated.
More specifically, we extend the target model
to include (besides the original integer-valued fea-
tures) one additional real-valued feature (k=1)2.
Its value is defined to be the negative logarithm
of the conditional probability given by OUT, the
original, out-of-domain, Alpino model. Hence, the
general model is ’merged’ into a single auxiliary
feature:
</bodyText>
<equation confidence="0.994646">
fm+1 = −logPOUT(ω|s) (11)
</equation>
<bodyText confidence="0.999978384615385">
The parameter of the new feature is estimated us-
ing the same estimation procedure as for the re-
maining model parameters. Intuitively, our auxil-
iary feature models dispreferences of the general
model for certain parse trees. When the Alpino
model assigns a high probability to a parse candi-
date, the auxiliary feature value will be small, close
to zero. In contrast, a low probability parse tree in
the general model gets a higher feature value. To-
gether with the estimated feature weight expected
to be negative, this has the effect that a low prob-
ability parse in the Alpino model will reduce the
probability of a parse in the target domain.
</bodyText>
<subsectionHeader confidence="0.999555">
3.3 Model combination
</subsectionHeader>
<bodyText confidence="0.9999916">
In this section we sketch an alternative approach
where we keep only two features under the Max-
Ent framework: one is the log probability assigned
by the out-domain model, the other the log proba-
bility assigned by the in-domain model:
</bodyText>
<equation confidence="0.924329">
f1 = −logPOUT(ω|s), f2 = −logPIN(ω|s)
</equation>
<bodyText confidence="0.999937333333333">
The contribution of each feature is again scaled
through the estimated feature weights θ1, θ2.
We can see this as a simple instantiation of model
combination. In alternative, data combination is
a domain adaptation method where IN and OUT-
domain data is simply concatenated and a new
model trained on the union of data. A potential and
well known disadvantage of data combination is
that the usually larger amount of out-domain data
</bodyText>
<equation confidence="0.987952625">
2Or alternatively, k ≥ 1 (see section 4.3.1).
Pθ(w|s) rr77k ex fm+i(w) em+% m
= lid=1 7� expEj=1 θj fj (ω)
Zθ
(7)
Em
expfm+i(ω)∗θm+iexp j=1 θjfj(ω) (8)
1 Ek Em j=1 θjfj(ω)
= exp i=1 fm+i(ω)∗θm+iexp
Z
θ
1
=
Zθ
k
i=1
</equation>
<page confidence="0.978294">
11
</page>
<bodyText confidence="0.99988175">
’overwhelms’ the small amount of in-domain data.
Instead, Model combination interpolates the two
models in a linear fashion by scaling their contri-
bution. Note that if we skip the parameter esti-
mation step and simply assign the two parameters
equal values (equal weights), the method reduces
to POUT (W s) × PIN(W s), i.e. just multiplying
the respective model probabilities.
</bodyText>
<sectionHeader confidence="0.998103" genericHeader="evaluation">
4 Experiments and Results
</sectionHeader>
<subsectionHeader confidence="0.958837">
4.1 Experimental design
</subsectionHeader>
<bodyText confidence="0.999991846153846">
The general model is trained on the Alpino Tree-
bank (van Noord, 2006) (newspaper text; approx-
imately 7,000 sentences). For the domain-specific
corpora, in the first set of experiments (section 4.3)
we consider the Alpino CLEF Treebank (ques-
tions; approximately 1,800 sentences). In the sec-
ond part (section 4.4) we evaluate the approach
on the Spoken Dutch corpus (Oostdijk, 2000)
(CGN, ’Corpus Gesproken Nederlands’; spoken
data; size varies, ranging from 17 to 1,193 sen-
tences). The CGN corpus contains a variety of
components/subdomains to account for the various
dimensions of language use (Oostdijk, 2000).
</bodyText>
<subsectionHeader confidence="0.964838">
4.2 Evaluation metric
</subsectionHeader>
<bodyText confidence="0.999985764705882">
The output of the parser is evaluated by comparing
the generated dependency structure for a corpus
sentence to the gold standard dependency structure
in a treebank. For this comparison, we represent
the dependency structure (a directed acyclic graph)
as a set of named dependency relations. To com-
pare such sets of dependency relations, we count
the number of dependencies that are identical in
the generated parse and the stored structure, which
is expressed traditionally using precision, recall
and f-score (Briscoe et al., 2002).
Let Dip be the number of dependencies produced
by the parser for sentence i, Dig is the number of
dependencies in the treebank parse, and Dio is the
number of correct dependencies produced by the
parser. If no superscript is used, we aggregate over
all sentences of the test set, i.e.,:
</bodyText>
<equation confidence="0.889358">
� � � Di
Dp = Di p Do = Di o Dg = g
i i i
</equation>
<bodyText confidence="0.999971864864865">
Precision is the total number of correct dependen-
cies returned by the parser, divided by the over-
all number of dependencies returned by the parser
(precision = Do/Dp); recall is the number of
correct system dependencies divided by the total
number of dependencies in the treebank (recall =
Do/Dg). As usual, precision and recall can be
combined in a single f-score metric.
An alternative similarity score for dependency
structures is based on the observation that for a
given sentence of n words, a parser would be ex-
pected to return n dependencies. In such cases,
we can simply use the percentage of correct de-
pendencies as a measure of accuracy. Such a la-
beled dependency accuracy is used, for instance,
in the CoNLL shared task on dependency parsing
(“labeled attachment score”).
Our evaluation metric is a variant of labeled
dependency accuracy, in which we do allow for
some discrepancy between the number of returned
dependencies. Such a discrepancy can occur,
for instance, because in the syntactic annotations
of Alpino (inherited from the CGN) words can
sometimes be dependent on more than a single
head (called ‘secondary edges’ in CGN). A fur-
ther cause is parsing failure, in which case a parser
might not produce any dependencies. We argue
elsewhere (van Noord, In preparation) that a metric
based on f-score can be misleading in such cases.
The resulting metric is called concept accuracy, in,
for instance, Boros et al. (1996).3
The concept accuracy metric can be characterized
as the mean of a per-sentence minimum of recall
and precision. The resulting CA score therefore
is typically slightly lower than the corresponding
f-score, and, for the purposes of this paper, equiv-
alent to labeled dependency accuracy.
</bodyText>
<subsectionHeader confidence="0.994181">
4.3 Experiments with the QA data
</subsectionHeader>
<bodyText confidence="0.998541">
In the first set of experiments we focus on the
Question Answering (QA) domain (CLEF corpus).
Besides evaluating our auxiliary based approach
(section 3), we conduct separate baseline experi-
ments:
</bodyText>
<listItem confidence="0.9953345">
• In-domain (CLEF): train on CLEF (baseline)
• Out-domain (Alpino): train on Alpino
• Data Combination (CLEF+Alpino): train a model on
the combination of data, CLEF U Alpino
</listItem>
<footnote confidence="0.949559">
3In previous publications and implementations defini-
tions were sometimes used that are equivalent to: CA =
max(Dg,Dp) which is slightly different; in practice the dif-
Do
</footnote>
<table confidence="0.874705909090909">
ferences can be ignored.
CA = Do
Ei max(Dig, Dip)
12
Dataset In-dom. Out-dom. Data Combination Aux.distribution Model Combination equal weights
size (#sents) CLEF Alpino CLEF+Alpino CLEF+Alpino aux CLEF aux+Alpino aux
CLEF 2003 (446) 97.01 94.02 97.21 97.01 97.14 97.46
CLEF 2004 (700) 96.60 89.88 95.14 96.60 97.12 97.23
CLEF 2005 (200) 97.65 87.98 93.62 97.72 97.99 98.19
CLEF 2006 (200) 97.06 88.92 95.16 97.06 97.00 96.45
CLEF 2007 (200) 96.20 92.48 97.30 96.33 96.33 96.46
</table>
<tableCaption confidence="0.99978">
Table 1: Results on the CLEF test data; underlined scores indicate results &gt; in-domain baseline (CLEF)
</tableCaption>
<listItem confidence="0.9923095">
• Auxiliary distribution (CLEF+Alpino aux): adding
the original Alpino model as auxiliary feature to CLEF
• Model Combination: keep only two features
POUT(ω|s) and PIN(ω|s). Two variants: i) estimate
</listItem>
<bodyText confidence="0.9868575">
the parameters θ1, θ2 (CLEF aux+Alpino aux); ii)
give them equal values, i.e. θ1=θ2=−1 (equal weights)
We assess the performance of all of these mod-
els on the CLEF data by using 5-fold cross-
validation. The results are given in table 1.
The CLEF model performs significantly better
than the out-of-domain (Alpino) model, despite of
the smaller size of the in-domain training data.
In contrast, the simple data combination results
in a model (CLEF+Alpino) whose performance is
somewhere in between. It is able to contribute in
some cases to disambiguate questions, while lead-
ing to wrong decisions in other cases.
However, for our auxiliary based approach
(CLEF+Alpino aux) with its regulated contribu-
tion of the general model, the results show that
adding the feature does not help. On most datasets
the same performance was achieved as by the in-
domain model, while on only two datasets (CLEF
2005, 2007) the use of the auxiliary feature results
in an insignificant improvement.
In contrast, simple model combination works
surprisingly well. On two datasets (CLEF 2004
and 2005) this simple technique reaches a sub-
stantial improvement over all other models. On
only one dataset (CLEF 2006) it falls slightly off
the in-domain baseline, but still considerably out-
performs data combination. This is true for both
model combination methods, with estimated and
equal weights. In general, the results show that
model combination usually outperforms data com-
bination (with the exception of one dataset, CLEF
2007), where, interestingly, the simplest model
combination (equal weights) often performs best.
Contrary to expectations, the auxiliary based ap-
proach performs poorly and could often not even
come close to the results obtained by simple model
combination. In the following we will explore pos-
sible reasons for this result.
Examining possible causes One possible point
of failure could be that the auxiliary feature was
simply ignored. If the estimated weight would be
close to zero the feature would indeed not con-
tribute to the disambiguation task. Therefore, we
examined the estimated weights for that feature.
From that analysis we saw that, compared to the
other features, the auxiliary feature got a weight
relatively far from zero. It got on average a weight
of −0.0905 in our datasets and as such is among
the most influential weights, suggesting it to be im-
portant for disambiguation.
Another question that needs to be asked, how-
ever, is whether the feature is modeling properly
the original Alpino model. For this sanity check,
we create a model that contains only the single
auxiliary feature and no other features. The fea-
ture’s weight is set to a constant negative value4.
The resulting model’s performance is assessed on
the complete CLEF data. The results (0% column
in table 3) show that the auxiliary feature is indeed
properly modeling the general Alpino model, as
the two result in identical performance.
</bodyText>
<subsectionHeader confidence="0.846315">
4.3.1 Feature template class models
</subsectionHeader>
<bodyText confidence="0.995361157894737">
In the experiments so far the general model was
’packed’ into a single feature value. To check
whether the feature alone is too weak, we exam-
ine the inclusion of several auxiliary distributions
(k &gt; 1). Each auxiliary feature we add represents
a ’submodel’ corresponding to an actual feature
template class used in the original model. The fea-
ture’s value is the negative log-probability as de-
fined in equation 11, where OUT corresponds to
the respective Alpino submodel.
The current Disambiguation Model of Alpino
uses the 21 feature templates (van Noord and Mal-
ouf, 2005). Out of this given feature templates,
we create two models that vary in the number of
classes used. In the first model (’5 class’), we cre-
ate five (k = 5) auxiliary distributions correspond-
ing to five clusters of feature templates. They are
4Alternatively, we may estimate its weight, but as it does
not have competing features we are safe to assume it constant.
</bodyText>
<page confidence="0.997926">
13
</page>
<bodyText confidence="0.999522083333333">
defined manually and correspond to submodels for
Part-of-Speech, dependencies, grammar rule ap-
plications, bilexical preferences and the remaining
Alpino features. In the second model (’21 class’),
we simply take every single feature template as its
own cluster (k = 21).
We test the two models and compare them to
our baseline. The results of this experiment are
given in table 2. We see that both the 5 class and
the 21 class model do not achieve any considerable
improvement over the baseline (CLEF), nor over
the single auxiliary model (CLEF+Alpino aux).
</bodyText>
<table confidence="0.9998915">
Dataset (#sents) 5class 21class CLEF+Alpino aux CLEF
CLEF2003 (446) 97.01 97.04 97.01 97.01
CLEF2004 (700) 96.57 96.60 96.60 96.60
CLEF2005 (200) 97.72 97.72 97.72 97.65
CLEF2006 (200) 97.06 97.06 97.06 97.06
CLEF2007 (200) 96.20 96.27 96.33 96.20
</table>
<tableCaption confidence="0.9949245">
Table 2: Results on CLEF including several auxil-
iary features corresponding to Alpino submodels
</tableCaption>
<figure confidence="0.788246666666667">
Varying amount of training data (CLEF 2004)
0 10 20 30 40 50 60
% training data
</figure>
<figureCaption confidence="0.9669588">
Figure 1: Amount of in-domain training data ver-
sus concept accuracy (Similar figures result from
the other CLEF datasets) - note that we depict only
aux.distr. as its performance is nearly indistin-
guishable from the in-domain (CLEF) baseline
</figureCaption>
<figure confidence="0.985923">
CA
98
96
94
92
90
88
86
Aux.distr. (CLEF+Alp_aux)
Out-dom (Alpino)
Mod.Comb. (CLEF_aux+Alpino_aux)
</figure>
<subsectionHeader confidence="0.90134">
4.3.2 Varying amount of training data
</subsectionHeader>
<bodyText confidence="0.996848241935484">
Our expectation is that the auxiliary feature is at
least helpful in the case very little in-domain train-
ing data is available. Therefore, we evaluate the
approach with smaller amounts of training data.
We sample (without replacement) a specific
amount of training instances from the original QA
data files and train models on the reduced train-
ing data. The resulting models are tested with and
without the additional feature as well as model
combination on the complete data set by using
cross validation. Table 3 reports the results of these
experiments for models trained on a proportion of
up to 10% CLEF data. Figure 1 illustrates the over-
all change in performance.
Obviously, an increasing amount of in-domain
training data improves the accuracy of the models.
However, for our auxiliary feature, the results in
table 3 show that the models with and without the
auxiliary feature result in an overall almost iden-
tical performance (thus in figure 1 we depict only
one of the lines). Hence, the inclusion of the aux-
iliary feature does not help in this case either. The
models achieve similar performance even indepen-
dently of the available amount of in-domain train-
ing data.
Thus, even on models trained on very little in-
domain training data (e.g. 1% CLEF training data)
the auxiliary based approach does not work. It
even hurts performance, i.e. depending on the spe-
cific dataset, the inclusion of the auxiliary feature
results in a model whose performance lies even be-
low the original Alpino model accuracy, for up to a
certain percentage of training data (varying on the
dataset from 1% up to 10%).
In contrast, simple model combination is much
more beneficial. It is able to outperform almost
constantly the in-domain baseline (CLEF) and
our auxiliary based approach (CLEF+Alpino aux).
Furthermore, in contrast to the auxiliary based ap-
proach, model combination never falls below the
out-of-domain (Alpino) baseline, not even in the
case a tiny amount of training data is available.
This is true for both model combinations (esti-
mated versus equal weights).
We would have expected the auxiliary feature to
be useful at least when very little in-domain train-
ing data is available. However, the empirical re-
sults reveal the contrary5. We believe the reason
for this drop in performance is the amount of avail-
able in-domain training data and the corresponding
scaling of the auxiliary feature’s weight. When
little training data is available, the weight cannot
be estimated reliably and hence is not contributing
enough compared to the other features (exempli-
fied in the drop of performance from 0% to 1%
5As suspected by a reviewer, the (non-auxiliary) features
may overwhelm the single auxiliary feature, such that possi-
ble improvements by increasing the feature space on such a
small scale might be invisible. We believe this is not the case.
Other studies have shown that including just a few features
might indeed help (Johnson and Riezler, 2000; van Noord,
2007). (e.g., the former just added 3 features).
</bodyText>
<page confidence="0.994529">
14
</page>
<table confidence="0.999401">
Dataset 0% = Alp. no aux +aux 1% eq.w. no aux 5% m.c. eq.w. no aux 10% eq.w.
no aux m.c. +aux +aux m.c.
CLEF2003 94.02 94.02 91.93 91.93 95.59 93.65 93.83 93.83 95.74 95.17 94.80 94.77 95.72 95.72
CLEF2004 89.88 89.88 86.59 86.59 90.97 91.06 93.62 93.62 93.42 92.95 94.79 94.82 96.26 95.85
CLEF2005 87.98 87.98 87.34 87.41 91.35 89.15 95.90 95.90 97.92 97.52 96.31 96.37 98.19 97.25
CLEF2006 88.92 88.92 89.64 89.64 92.16 91.17 92.77 92.77 94.98 94.55 95.04 95.04 95.04 95.47
CLEF2007 92.48 92.48 91.07 91.13 95.44 93.32 94.60 94.60 95.63 95.69 94.21 94.21 95.95 95.43
</table>
<tableCaption confidence="0.999919">
Table 3: Results on the CLEF data with varying amount of training data
</tableCaption>
<bodyText confidence="0.934651666666667">
training data in table 3). In such cases it is more
beneficial to just apply the original Alpino model
or the simple model combination technique.
</bodyText>
<subsectionHeader confidence="0.994804">
4.4 Experiments with CGN
</subsectionHeader>
<bodyText confidence="0.999986484848485">
One might argue that the question domain is
rather ’easy’, given the already high baseline per-
formance and the fact that few hand-annotated
questions are enough to obtain a reasonable
model. Therefore, we examine our approach on
CGN (Oostdijk, 2000).
The empirical results of testing using cross-
validation within a subset of CGN subdomains
are given in table 4. The baseline accuracies
are much lower on this more heterogeneous, spo-
ken, data, leaving more room for potential im-
provements over the in-domain model. How-
ever, the results show that the auxiliary based ap-
proach does not work on the CGN subdomains ei-
ther. The approach is not able to improve even on
datasets where very little training data is available
(e.g. comp-l), thus confirming our previous find-
ing. Moreover, in some cases the auxiliary fea-
ture rather, although only slightly, degrades perfor-
mance (indicated in italic in table 4) and performs
worse than the counterpart model without the ad-
ditional feature.
Depending on the different characteristics of
data/domain and its size, the best model adapta-
tion method varies on CGN. On some subdomains
simple model combination performs best, while on
others it is more beneficial to just apply the origi-
nal, out-of-domain Alpino model.
To conclude, model combination achieves in most
cases a modest improvement, while we have
shown empirically that our domain adaptation
method based on auxiliary distributions performs
just similar to a model trained on in-domain data.
</bodyText>
<sectionHeader confidence="0.999634" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999982260869565">
We examined auxiliary distributions (Johnson and
Riezler, 2000) for domain adaptation. While
the auxiliary approach has been successfully ap-
plied to lexical selectional preferences (Johnson
and Riezler, 2000; van Noord, 2007), our empir-
ical results show that integrating a more general
into a domain-specific model through the auxil-
iary feature approach does not help. The auxil-
iary approach needs training data to estimate the
weight(s) of the auxiliary feature(s). When little
training data is available, the weight cannot be es-
timated appropriately and hence is not contributing
enough compared to the other features. This re-
sult was confirmed on both examined domains. We
conclude that the auxiliary feature approach is not
appropriate for integrating information of a more
general model to leverage limited in-domain data.
Better results were achieved either without adapta-
tion or by simple model combination.
Future work will consist in investigating other pos-
sibilities for parser adaptation, especially semi-
supervised domain adaptation, where no labeled
in-domain data is available.
</bodyText>
<sectionHeader confidence="0.998594" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99951912">
Abney, Steven P. 1997. Stochastic attribute-value grammars.
Computational Linguistics, 23:597–618.
Berger, A. and H. Printz. 1998. A comparison of criteria
for maximum entropy / minimum divergence feature selec-
tion. In In Proceedings of the 3nd Conference on Empir-
ical Methods in Natural Language Processing (EMNLP),
pages 97–106, Granada, Spain.
Berger, Adam, Stephen Della Pietra, and Vincent Della Pietra.
1996. A maximum entropy approach to natural language
processing. Computational Linguistics, 22(1):39–72.
Boros, M., W. Eckert, F. Gallwitz, G. G¨orz, G. Hanrieder, and
H. Niemann. 1996. Towards understanding spontaneous
speech: Word accuracy vs. concept accuracy. In Pro-
ceedings of the Fourth International Conference on Spoken
Language Processing (ICSLP 96), Philadelphia.
Briscoe, Ted, John Carroll, Jonathan Graham, and Ann
Copestake. 2002. Relational evaluation schemes. In Pro-
ceedings of the Beyond PARSEVAL Workshop at the 3rd In-
ternational Conference on Language Resources and Eval-
uation, pages 4–8, Las Palmas, Gran Canaria.
Gildea, Daniel. 2001. Corpus variation and parser perfor-
mance. In Proceedings of the 2001 Conference on Empir-
ical Methods in Natural Language Processing (EMNLP).
Hara, Tadayoshi, Miyao Yusuke, and Jun’ichi Tsujii. 2005.
Adapting a probabilistic disambiguation model of an hpsg
</reference>
<page confidence="0.993958">
15
</page>
<table confidence="0.999351230769231">
comp-a (1,193) - Spontaneous Alpino conversations comp-b (525) - Interviews with teachers of Dutch
DataSet no aux + aux (’face-to-face’) Dataset no aux + aux Alpino Mod.Comb. Mod.Comb
Mod.Comb. Mod.Comb. eq.weights
eq.weights
fn000250 63.20 63.28 62.90 63.91 63.99 fn000081 66.20 66.39 66.45 67.26 66.85
fn000252 64.74 64.74 64.06 64.87 64.96 fn000089 62.41 62.41 63.88 64.35 64.01
fn000254 66.03 66.00 65.78 66.39 66.44 fn000086 62.60 62.76 63.17 63.59 63.77
comp-l (116) - Commentaries/columns/reviews (broadcast) comp-m (267) - Ceremonious speeches/sermons
DataSet no aux + aux Alpino Mod.Comb. Model.Comb. Dataset no aux + aux Alpino Mod.Comb. Mod.Comb
eq.weights eq.weights
fn000002 67.63 67.63 77.30 76.96 72.40 fn000271 59.25 59.25 63.78 64.94 61.76
fn000017 64.51 64.33 66.42 66.30 65.74 fn000298 70.33 70.19 74.55 74.83 72.70
fn000021 61.54 61.54 64.30 64.10 63.24 fn000781 72.26 72.37 73.55 73.55 73.04
</table>
<tableCaption confidence="0.998488">
Table 4: Excerpt of results on various CGN subdomains (# of sentences in parenthesis).
</tableCaption>
<reference confidence="0.995056314814815">
parser to a new domain. In Proceedings of the Interna-
tional Joint Conference on Natural Language Processing.
Johnson, Mark and Stefan Riezler. 2000. Exploiting auxiliary
distributions in stochastic unification-based grammars. In
Proceedings of the first conference on North American
chapter of the Association for Computational Linguistics,
pages 154–161, San Francisco, CA, USA. Morgan Kauf-
mann Publishers Inc.
Johnson, Mark, Stuart Geman, Stephen Canon, Zhiyi Chi,
and Stefan Riezler. 1999. Estimators for stochastic
“unification-based” grammars. In Proceedings of the 37th
Annual Meeting of the ACL.
Lease, Matthew, Eugene Charniak, Mark Johnson, and David
McClosky. 2006. A look at parsing and its applications.
In Proceedings of the Twenty-FirstNational Conference on
Artificial Intelligence (AAAI-06), Boston, Massachusetts,
16–20 July.
McClosky, David, Eugene Charniak, and Mark Johnson.
2006. Effective self-training for parsing. In Proceed-
ings of the Human Language Technology Conference of
the NAACL, Main Conference, pages 152–159, New York
City, USA, June. Association for Computational Linguis-
tics.
Oostdijk, Nelleke. 2000. The Spoken Dutch Corpus:
Overview and first evaluation. In Proceedings of Sec-
ond International Conference on Language Resources and
Evaluation (LREC), pages 887–894.
Osborne, Miles. 2000. Estimation of stochastic attribute-
value grammars using an informative sample. In Proceed-
ings of the Eighteenth International Conference on Com-
putational Linguistics (COLING 2000).
Ratnaparkhi, A. 1997. A simple introduction to maximum
entropy models for natural language processing. Technical
report, Institute for Research in Cognitive Science, Univer-
sity of Pennsylvania.
van Noord, Gertjan and Robert Malouf. 2005. Wide coverage
parsing with stochastic attribute value grammars. Draft
available from http://www.let.rug.nl/˜vannoord. A prelim-
inary version of this paper was published in the Proceed-
ings of the IJCNLP workshop Beyond Shallow Analyses,
Hainan China, 2004.
van Noord, Gertjan. 2006. At Last Parsing Is Now
Operational. In TALN 2006 Verbum Ex Machina, Actes
De La 13e Conference sur Le Traitement Automatique des
Langues naturelles, pages 20–42, Leuven.
van Noord, Gertjan. 2007. Using self-trained bilexical
preferences to improve disambiguation accuracy. In Pro-
ceedings of the Tenth International Conference on Parsing
Technologies. IWPT2007, Prague., pages 1–10, Prague.
van Noord, Gertjan. In preparation. Learning efficient pars-
ing.
Velldal, E. and S. Oepen. 2005. Maximum entropy mod-
els for realization ranking. In Proceedings ofMT-Summit,
Phuket, Thailand.
</reference>
<page confidence="0.998697">
16
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.869034">
<title confidence="0.96824">Exploring an Auxiliary Distribution based approach Domain Adaptation of a Syntactic Disambiguation Model</title>
<author confidence="0.999125">Barbara Plank Gertjan van_Noord</author>
<affiliation confidence="0.999822">University of Groningen University of Groningen</affiliation>
<address confidence="0.964208">The Netherlands The Netherlands</address>
<email confidence="0.969259">B.Plank@rug.nlG.J.M.van.Noord@rug.nl</email>
<abstract confidence="0.999250125">We investigate auxiliary distributions (Johnson and Riezler, 2000) for domain adaptation of a supervised parsing system of Dutch. To overcome the limited target domain training data, we exploit an original and larger out-of-domain model as auxiliary distribution. However, our empirical results exhibit that the auxiliary distribution does not help: even when very little target training data is available the incorporation of the out-of-domain model does not contribute to parsing accuracy on the target domain; instead, better results are achieved either without adaptation or by simple model combination.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven P Abney</author>
</authors>
<title>Stochastic attribute-value grammars.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<pages>23--597</pages>
<contexts>
<context position="3461" citStr="Abney, 1997" startWordPosition="514" endWordPosition="515">s, we use Alpino (van Noord and Malouf, 2005; van Noord, 2006), a robust computational analyzer for Dutch. Alpino employs a discriminative approach to parse selection that bases its decision on a Maximum Entropy (MaxEnt) model. Section 2 introduces the MaxEnt framework. Section 3 describes our approach of exploring auxiliary distributions for domain adaptation. In section 4 the experimental design and empirical results are presented and discussed. 2 Background: MaxEnt Models Maximum Entropy (MaxEnt) models are widely used in Natural Language Processing (Berger et al., 1996; Ratnaparkhi, 1997; Abney, 1997). In this framework, a disambiguation model is speci9 Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation, pages 9–16 Manchester, August 2008 fied by a set of feature functions describing properties of the data, together with their associated weights. The weights are learned during the training procedure so that their estimated value determines the contribution of each feature. In the task of parsing, features appearing in correct parses are given increasing weight, while features in incorrect parses are given decreasing weight. Once a model is traine</context>
<context position="5016" citStr="Abney, 1997" startWordPosition="772" endWordPosition="773">m Kullback-Leibler (KL) divergence from the default model q0, subject to the expected-value constraints: Ep[fj] = E˜p[fj], where j E 1, ..., m. In MaxEnt estimation, the default model q0 is often only implicit (Velldal and Oepen, 2005) and not stated in the model equation, since the model is assumed to be uniform (e.g. the constant function 1 Ω(s) for sentence s, where Q(s) is the set of parse trees associated with s). Thus, we seek the model with minimum KL divergence from the uniform distribution, which means we search model p with maximum entropy (uncertainty) subject to given constraints (Abney, 1997). In alternative, if q0 is not uniform then p is called a minimum divergence model (according to (Berger and Printz, 1998)). In the statistical parsing literature, the default model q0 that can be used to incorporate prior knowledge is also referred to as base model (Berger and Printz, 1998), default or reference distribution (Hara et al., 2005; Johnson et al., 1999; Velldal and Oepen, 2005). The solution to the estimation problem of finding distribution p, that satisfies the expectedvalue constraints and minimally diverges from q0, has been shown to take a specific parametric form (Berger and</context>
</contexts>
<marker>Abney, 1997</marker>
<rawString>Abney, Steven P. 1997. Stochastic attribute-value grammars. Computational Linguistics, 23:597–618.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Berger</author>
<author>H Printz</author>
</authors>
<title>A comparison of criteria for maximum entropy / minimum divergence feature selection. In</title>
<date>1998</date>
<booktitle>In Proceedings of the 3nd Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>97--106</pages>
<location>Granada,</location>
<contexts>
<context position="5138" citStr="Berger and Printz, 1998" startWordPosition="791" endWordPosition="794">] = E˜p[fj], where j E 1, ..., m. In MaxEnt estimation, the default model q0 is often only implicit (Velldal and Oepen, 2005) and not stated in the model equation, since the model is assumed to be uniform (e.g. the constant function 1 Ω(s) for sentence s, where Q(s) is the set of parse trees associated with s). Thus, we seek the model with minimum KL divergence from the uniform distribution, which means we search model p with maximum entropy (uncertainty) subject to given constraints (Abney, 1997). In alternative, if q0 is not uniform then p is called a minimum divergence model (according to (Berger and Printz, 1998)). In the statistical parsing literature, the default model q0 that can be used to incorporate prior knowledge is also referred to as base model (Berger and Printz, 1998), default or reference distribution (Hara et al., 2005; Johnson et al., 1999; Velldal and Oepen, 2005). The solution to the estimation problem of finding distribution p, that satisfies the expectedvalue constraints and minimally diverges from q0, has been shown to take a specific parametric form (Berger and Printz, 1998): 1 pθ(ω, s) = Z g0expP&apos; 1 θjfj(ω) (1) B with m feature functions, s being the input sentence, ω a correspon</context>
</contexts>
<marker>Berger, Printz, 1998</marker>
<rawString>Berger, A. and H. Printz. 1998. A comparison of criteria for maximum entropy / minimum divergence feature selection. In In Proceedings of the 3nd Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 97–106, Granada, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Berger</author>
<author>Stephen Della Pietra</author>
<author>Vincent Della Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="3428" citStr="Berger et al., 1996" startWordPosition="508" endWordPosition="511">and spoken data. For the empirical trials, we use Alpino (van Noord and Malouf, 2005; van Noord, 2006), a robust computational analyzer for Dutch. Alpino employs a discriminative approach to parse selection that bases its decision on a Maximum Entropy (MaxEnt) model. Section 2 introduces the MaxEnt framework. Section 3 describes our approach of exploring auxiliary distributions for domain adaptation. In section 4 the experimental design and empirical results are presented and discussed. 2 Background: MaxEnt Models Maximum Entropy (MaxEnt) models are widely used in Natural Language Processing (Berger et al., 1996; Ratnaparkhi, 1997; Abney, 1997). In this framework, a disambiguation model is speci9 Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation, pages 9–16 Manchester, August 2008 fied by a set of feature functions describing properties of the data, together with their associated weights. The weights are learned during the training procedure so that their estimated value determines the contribution of each feature. In the task of parsing, features appearing in correct parses are given increasing weight, while features in incorrect parses are given decreasi</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Berger, Adam, Stephen Della Pietra, and Vincent Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):39–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Boros</author>
<author>W Eckert</author>
<author>F Gallwitz</author>
<author>G G¨orz</author>
<author>G Hanrieder</author>
<author>H Niemann</author>
</authors>
<title>Towards understanding spontaneous speech: Word accuracy vs. concept accuracy.</title>
<date>1996</date>
<booktitle>In Proceedings of the Fourth International Conference on Spoken Language Processing (ICSLP 96),</booktitle>
<location>Philadelphia.</location>
<marker>Boros, Eckert, Gallwitz, G¨orz, Hanrieder, Niemann, 1996</marker>
<rawString>Boros, M., W. Eckert, F. Gallwitz, G. G¨orz, G. Hanrieder, and H. Niemann. 1996. Towards understanding spontaneous speech: Word accuracy vs. concept accuracy. In Proceedings of the Fourth International Conference on Spoken Language Processing (ICSLP 96), Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
<author>Jonathan Graham</author>
<author>Ann Copestake</author>
</authors>
<title>Relational evaluation schemes.</title>
<date>2002</date>
<booktitle>In Proceedings of the Beyond PARSEVAL Workshop at the 3rd International Conference on Language Resources and Evaluation,</booktitle>
<pages>4--8</pages>
<location>Las Palmas, Gran Canaria.</location>
<contexts>
<context position="13311" citStr="Briscoe et al., 2002" startWordPosition="2122" endWordPosition="2125">count for the various dimensions of language use (Oostdijk, 2000). 4.2 Evaluation metric The output of the parser is evaluated by comparing the generated dependency structure for a corpus sentence to the gold standard dependency structure in a treebank. For this comparison, we represent the dependency structure (a directed acyclic graph) as a set of named dependency relations. To compare such sets of dependency relations, we count the number of dependencies that are identical in the generated parse and the stored structure, which is expressed traditionally using precision, recall and f-score (Briscoe et al., 2002). Let Dip be the number of dependencies produced by the parser for sentence i, Dig is the number of dependencies in the treebank parse, and Dio is the number of correct dependencies produced by the parser. If no superscript is used, we aggregate over all sentences of the test set, i.e.,: � � � Di Dp = Di p Do = Di o Dg = g i i i Precision is the total number of correct dependencies returned by the parser, divided by the overall number of dependencies returned by the parser (precision = Do/Dp); recall is the number of correct system dependencies divided by the total number of dependencies in th</context>
</contexts>
<marker>Briscoe, Carroll, Graham, Copestake, 2002</marker>
<rawString>Briscoe, Ted, John Carroll, Jonathan Graham, and Ann Copestake. 2002. Relational evaluation schemes. In Proceedings of the Beyond PARSEVAL Workshop at the 3rd International Conference on Language Resources and Evaluation, pages 4–8, Las Palmas, Gran Canaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
</authors>
<title>Corpus variation and parser performance.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="1517" citStr="Gildea, 2001" startWordPosition="218" endWordPosition="219">ical parsers are trained on large annotated corpora (treebanks) and their parameters are estimated to reflect properties of the training data. Therefore, a disambiguation component will be successful as long as the treebank it was trained on is representative for the input the model gets. However, as soon as the model is applied to another domain, or text genre (Lease et al., 2006), accuracy degrades considerably. For example, the performance of a parser trained on the Wall Street Journal (newspaper text) significantly drops when evaluated on the more varied Brown (fiction/nonfiction) corpus (Gildea, 2001). A simple solution to improve performance on a new domain is to construct a parser specifically © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. for that domain. However, this amounts to handlabeling a considerable amount of training data which is clearly very expensive and leads to an unsatisfactory solution. In alternative, techniques for domain adaptation, also known as parser adaptation (McClosky et al., 2006) or genre portability (Lease et al., 2006), try to le</context>
</contexts>
<marker>Gildea, 2001</marker>
<rawString>Gildea, Daniel. 2001. Corpus variation and parser performance. In Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tadayoshi Hara</author>
<author>Miyao Yusuke</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Adapting a probabilistic disambiguation model of an hpsg parser to a new domain.</title>
<date>2005</date>
<booktitle>In Proceedings of the International Joint Conference on Natural Language Processing.</booktitle>
<contexts>
<context position="2200" citStr="Hara et al., 2005" startWordPosition="317" endWordPosition="320">construct a parser specifically © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. for that domain. However, this amounts to handlabeling a considerable amount of training data which is clearly very expensive and leads to an unsatisfactory solution. In alternative, techniques for domain adaptation, also known as parser adaptation (McClosky et al., 2006) or genre portability (Lease et al., 2006), try to leverage either a small amount of already existing annotated data (Hara et al., 2005) or unlabeled data (McClosky et al., 2006) of one domain to parse data from a different domain. In this study we examine an approach that assumes a limited amount of already annotated in-domain data. We explore auxiliary distributions (Johnson and Riezler, 2000) for domain adaptation, originally suggested for the incorporation of lexical selectional preferences into a parsing system. We gauge the effect of exploiting a more general, out-ofdomain model for parser adaptation to overcome the limited amount of in-domain training data. The approach is examined on two application domains, question a</context>
<context position="5362" citStr="Hara et al., 2005" startWordPosition="828" endWordPosition="831">n 1 Ω(s) for sentence s, where Q(s) is the set of parse trees associated with s). Thus, we seek the model with minimum KL divergence from the uniform distribution, which means we search model p with maximum entropy (uncertainty) subject to given constraints (Abney, 1997). In alternative, if q0 is not uniform then p is called a minimum divergence model (according to (Berger and Printz, 1998)). In the statistical parsing literature, the default model q0 that can be used to incorporate prior knowledge is also referred to as base model (Berger and Printz, 1998), default or reference distribution (Hara et al., 2005; Johnson et al., 1999; Velldal and Oepen, 2005). The solution to the estimation problem of finding distribution p, that satisfies the expectedvalue constraints and minimally diverges from q0, has been shown to take a specific parametric form (Berger and Printz, 1998): 1 pθ(ω, s) = Z g0expP&apos; 1 θjfj(ω) (1) B with m feature functions, s being the input sentence, ω a corresponding parse tree, and Zθ the normalization equation: �Zθ = Pm j=1 θjfj(ω′) ω′∈Ω q0exp (2) Since the sum in equation 2 ranges over all possible parse trees ω′ E Q admitted by the grammar, calculating the normalization constant</context>
<context position="9192" citStr="Hara et al. (2005)" startWordPosition="1448" endWordPosition="1451">xiliary distributions are additional features1. 1 Zθ expEj=1k θj fj (ω) with fj(w) = logQ(w) for m &lt; j ≤ (m + k) 3.2 Auxiliary distributions for adaptation While (Johnson and Riezler, 2000; van Noord, 2007) focus on incorporating several auxiliary distributions for lexical selectional preferences, in this study we explore auxiliary distributions for domain adaptation. We exploit the information of the more general model, estimated from a larger, out-of-domain treebank, for parsing data from a particular target domain, where only a small amount of training data is available. A related study is Hara et al. (2005). While they also assume a limited amount of in-domain training data, their approach 1Note that the step from equation (6) to (7) holds by restating equation (4) as Qi(w) = expfm+i(ω) differs from ours in that they incorporate an original model as a reference distribution, and their estimation procedure is based on parse forests (Hara et al., 2005; van Noord, 2006), rather than informative samples. In this study, we want to gauge the effect of auxiliary distributions, which have the advantage that the contribution of the additional source is regulated. More specifically, we extend the target m</context>
</contexts>
<marker>Hara, Yusuke, Tsujii, 2005</marker>
<rawString>Hara, Tadayoshi, Miyao Yusuke, and Jun’ichi Tsujii. 2005. Adapting a probabilistic disambiguation model of an hpsg parser to a new domain. In Proceedings of the International Joint Conference on Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
<author>Stefan Riezler</author>
</authors>
<title>Exploiting auxiliary distributions in stochastic unification-based grammars.</title>
<date>2000</date>
<booktitle>In Proceedings of the first conference on North American chapter of the Association for Computational Linguistics,</booktitle>
<pages>154--161</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="2462" citStr="Johnson and Riezler, 2000" startWordPosition="361" endWordPosition="364">ndlabeling a considerable amount of training data which is clearly very expensive and leads to an unsatisfactory solution. In alternative, techniques for domain adaptation, also known as parser adaptation (McClosky et al., 2006) or genre portability (Lease et al., 2006), try to leverage either a small amount of already existing annotated data (Hara et al., 2005) or unlabeled data (McClosky et al., 2006) of one domain to parse data from a different domain. In this study we examine an approach that assumes a limited amount of already annotated in-domain data. We explore auxiliary distributions (Johnson and Riezler, 2000) for domain adaptation, originally suggested for the incorporation of lexical selectional preferences into a parsing system. We gauge the effect of exploiting a more general, out-ofdomain model for parser adaptation to overcome the limited amount of in-domain training data. The approach is examined on two application domains, question answering and spoken data. For the empirical trials, we use Alpino (van Noord and Malouf, 2005; van Noord, 2006), a robust computational analyzer for Dutch. Alpino employs a discriminative approach to parse selection that bases its decision on a Maximum Entropy (</context>
<context position="7170" citStr="Johnson and Riezler, 2000" startWordPosition="1127" endWordPosition="1130"> 2000), because the number of parses is in the worst case exponential with respect to sentence length. Therefore, Osborne (2000) proposes a solution based on informative samples. He shows that is suffices to train on an informative subset of available training data to accurately estimate the model parameters. Alpino implements the Osborne-style approach to Maximum Entropy parsing. The standard version of the Alpino parser is trained on the Alpino newspaper Treebank (van Noord, 2006). 3 Exploring auxiliary distributions for domain adaptation 3.1 Auxiliary distributions Auxiliary distributions (Johnson and Riezler, 2000) offer the possibility to incorporate information from additional sources into a MaxEnt Model. In more detail, auxiliary distributions are integrated by considering the logarithm of the probability given by an auxiliary distribution as an additional, real-valued feature. More formally, given k auxiliary distributions Qi(ω), then k new auxiliary features fm+1, ..., fm+k are added such that fm+i(ω) = logQi(ω) (4) where Qi(ω) do not need to be proper probability distributions, however they must strictly be positive Vω E Q (Johnson and Riezler, 2000). The auxiliary distributions resemble a referen</context>
<context position="8423" citStr="Johnson and Riezler, 2000" startWordPosition="1320" endWordPosition="1323">d of considering a single reference distribution they have the advantage that several auxiliary distributions can be integrated and weighted against each other. John10 son establishes the following equivalence between the two (Johnson and Riezler, 2000; Velldal and Oepen, 2005): k Q(ω) = Qi(ω)θm+i (5) i=1 where Q(ω) is the reference distribution and Qi(ω) is an auxiliary distribution. Hence, the contribution of each auxiliary distribution is regulated through the estimated feature weight. In general, a model that includes k auxiliary features as given in equation (4) takes the following form (Johnson and Riezler, 2000): Pθ(ω |s) = Hki=1 QZBω)θm+i expPT 1 θjfj(ω) (6) Due to the equivalence relation in equation (5) we can restate the equation to explicitly show that auxiliary distributions are additional features1. 1 Zθ expEj=1k θj fj (ω) with fj(w) = logQ(w) for m &lt; j ≤ (m + k) 3.2 Auxiliary distributions for adaptation While (Johnson and Riezler, 2000; van Noord, 2007) focus on incorporating several auxiliary distributions for lexical selectional preferences, in this study we explore auxiliary distributions for domain adaptation. We exploit the information of the more general model, estimated from a larger,</context>
<context position="24940" citStr="Johnson and Riezler, 2000" startWordPosition="4026" endWordPosition="4029">raining data and the corresponding scaling of the auxiliary feature’s weight. When little training data is available, the weight cannot be estimated reliably and hence is not contributing enough compared to the other features (exemplified in the drop of performance from 0% to 1% 5As suspected by a reviewer, the (non-auxiliary) features may overwhelm the single auxiliary feature, such that possible improvements by increasing the feature space on such a small scale might be invisible. We believe this is not the case. Other studies have shown that including just a few features might indeed help (Johnson and Riezler, 2000; van Noord, 2007). (e.g., the former just added 3 features). 14 Dataset 0% = Alp. no aux +aux 1% eq.w. no aux 5% m.c. eq.w. no aux 10% eq.w. no aux m.c. +aux +aux m.c. CLEF2003 94.02 94.02 91.93 91.93 95.59 93.65 93.83 93.83 95.74 95.17 94.80 94.77 95.72 95.72 CLEF2004 89.88 89.88 86.59 86.59 90.97 91.06 93.62 93.62 93.42 92.95 94.79 94.82 96.26 95.85 CLEF2005 87.98 87.98 87.34 87.41 91.35 89.15 95.90 95.90 97.92 97.52 96.31 96.37 98.19 97.25 CLEF2006 88.92 88.92 89.64 89.64 92.16 91.17 92.77 92.77 94.98 94.55 95.04 95.04 95.04 95.47 CLEF2007 92.48 92.48 91.07 91.13 95.44 93.32 94.60 94.60 95</context>
<context position="27380" citStr="Johnson and Riezler, 2000" startWordPosition="4427" endWordPosition="4430">rt model without the additional feature. Depending on the different characteristics of data/domain and its size, the best model adaptation method varies on CGN. On some subdomains simple model combination performs best, while on others it is more beneficial to just apply the original, out-of-domain Alpino model. To conclude, model combination achieves in most cases a modest improvement, while we have shown empirically that our domain adaptation method based on auxiliary distributions performs just similar to a model trained on in-domain data. 5 Conclusions We examined auxiliary distributions (Johnson and Riezler, 2000) for domain adaptation. While the auxiliary approach has been successfully applied to lexical selectional preferences (Johnson and Riezler, 2000; van Noord, 2007), our empirical results show that integrating a more general into a domain-specific model through the auxiliary feature approach does not help. The auxiliary approach needs training data to estimate the weight(s) of the auxiliary feature(s). When little training data is available, the weight cannot be estimated appropriately and hence is not contributing enough compared to the other features. This result was confirmed on both examined</context>
</contexts>
<marker>Johnson, Riezler, 2000</marker>
<rawString>Johnson, Mark and Stefan Riezler. 2000. Exploiting auxiliary distributions in stochastic unification-based grammars. In Proceedings of the first conference on North American chapter of the Association for Computational Linguistics, pages 154–161, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
<author>Stuart Geman</author>
<author>Stephen Canon</author>
<author>Zhiyi Chi</author>
<author>Stefan Riezler</author>
</authors>
<title>Estimators for stochastic “unification-based” grammars.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the ACL.</booktitle>
<contexts>
<context position="5384" citStr="Johnson et al., 1999" startWordPosition="832" endWordPosition="835">ce s, where Q(s) is the set of parse trees associated with s). Thus, we seek the model with minimum KL divergence from the uniform distribution, which means we search model p with maximum entropy (uncertainty) subject to given constraints (Abney, 1997). In alternative, if q0 is not uniform then p is called a minimum divergence model (according to (Berger and Printz, 1998)). In the statistical parsing literature, the default model q0 that can be used to incorporate prior knowledge is also referred to as base model (Berger and Printz, 1998), default or reference distribution (Hara et al., 2005; Johnson et al., 1999; Velldal and Oepen, 2005). The solution to the estimation problem of finding distribution p, that satisfies the expectedvalue constraints and minimally diverges from q0, has been shown to take a specific parametric form (Berger and Printz, 1998): 1 pθ(ω, s) = Z g0expP&apos; 1 θjfj(ω) (1) B with m feature functions, s being the input sentence, ω a corresponding parse tree, and Zθ the normalization equation: �Zθ = Pm j=1 θjfj(ω′) ω′∈Ω q0exp (2) Since the sum in equation 2 ranges over all possible parse trees ω′ E Q admitted by the grammar, calculating the normalization constant renders the estimatio</context>
</contexts>
<marker>Johnson, Geman, Canon, Chi, Riezler, 1999</marker>
<rawString>Johnson, Mark, Stuart Geman, Stephen Canon, Zhiyi Chi, and Stefan Riezler. 1999. Estimators for stochastic “unification-based” grammars. In Proceedings of the 37th Annual Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Lease</author>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
<author>David McClosky</author>
</authors>
<title>A look at parsing and its applications.</title>
<date>2006</date>
<booktitle>In Proceedings of the Twenty-FirstNational Conference on Artificial Intelligence (AAAI-06),</booktitle>
<location>Boston, Massachusetts,</location>
<contexts>
<context position="1288" citStr="Lease et al., 2006" startWordPosition="184" endWordPosition="187">ble the incorporation of the out-of-domain model does not contribute to parsing accuracy on the target domain; instead, better results are achieved either without adaptation or by simple model combination. 1 Introduction Modern statistical parsers are trained on large annotated corpora (treebanks) and their parameters are estimated to reflect properties of the training data. Therefore, a disambiguation component will be successful as long as the treebank it was trained on is representative for the input the model gets. However, as soon as the model is applied to another domain, or text genre (Lease et al., 2006), accuracy degrades considerably. For example, the performance of a parser trained on the Wall Street Journal (newspaper text) significantly drops when evaluated on the more varied Brown (fiction/nonfiction) corpus (Gildea, 2001). A simple solution to improve performance on a new domain is to construct a parser specifically © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. for that domain. However, this amounts to handlabeling a considerable amount of training data wh</context>
</contexts>
<marker>Lease, Charniak, Johnson, McClosky, 2006</marker>
<rawString>Lease, Matthew, Eugene Charniak, Mark Johnson, and David McClosky. 2006. A look at parsing and its applications. In Proceedings of the Twenty-FirstNational Conference on Artificial Intelligence (AAAI-06), Boston, Massachusetts, 16–20 July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David McClosky</author>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Effective self-training for parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference,</booktitle>
<pages>152--159</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York City, USA,</location>
<contexts>
<context position="2064" citStr="McClosky et al., 2006" startWordPosition="292" endWordPosition="295">aluated on the more varied Brown (fiction/nonfiction) corpus (Gildea, 2001). A simple solution to improve performance on a new domain is to construct a parser specifically © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. for that domain. However, this amounts to handlabeling a considerable amount of training data which is clearly very expensive and leads to an unsatisfactory solution. In alternative, techniques for domain adaptation, also known as parser adaptation (McClosky et al., 2006) or genre portability (Lease et al., 2006), try to leverage either a small amount of already existing annotated data (Hara et al., 2005) or unlabeled data (McClosky et al., 2006) of one domain to parse data from a different domain. In this study we examine an approach that assumes a limited amount of already annotated in-domain data. We explore auxiliary distributions (Johnson and Riezler, 2000) for domain adaptation, originally suggested for the incorporation of lexical selectional preferences into a parsing system. We gauge the effect of exploiting a more general, out-ofdomain model for pars</context>
</contexts>
<marker>McClosky, Charniak, Johnson, 2006</marker>
<rawString>McClosky, David, Eugene Charniak, and Mark Johnson. 2006. Effective self-training for parsing. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 152–159, New York City, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nelleke Oostdijk</author>
</authors>
<title>The Spoken Dutch Corpus: Overview and first evaluation.</title>
<date>2000</date>
<booktitle>In Proceedings of Second International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>887--894</pages>
<contexts>
<context position="12525" citStr="Oostdijk, 2000" startWordPosition="2004" endWordPosition="2005">stimation step and simply assign the two parameters equal values (equal weights), the method reduces to POUT (W s) × PIN(W s), i.e. just multiplying the respective model probabilities. 4 Experiments and Results 4.1 Experimental design The general model is trained on the Alpino Treebank (van Noord, 2006) (newspaper text; approximately 7,000 sentences). For the domain-specific corpora, in the first set of experiments (section 4.3) we consider the Alpino CLEF Treebank (questions; approximately 1,800 sentences). In the second part (section 4.4) we evaluate the approach on the Spoken Dutch corpus (Oostdijk, 2000) (CGN, ’Corpus Gesproken Nederlands’; spoken data; size varies, ranging from 17 to 1,193 sentences). The CGN corpus contains a variety of components/subdomains to account for the various dimensions of language use (Oostdijk, 2000). 4.2 Evaluation metric The output of the parser is evaluated by comparing the generated dependency structure for a corpus sentence to the gold standard dependency structure in a treebank. For this comparison, we represent the dependency structure (a directed acyclic graph) as a set of named dependency relations. To compare such sets of dependency relations, we count </context>
<context position="26065" citStr="Oostdijk, 2000" startWordPosition="4220" endWordPosition="4221"> 94.55 95.04 95.04 95.04 95.47 CLEF2007 92.48 92.48 91.07 91.13 95.44 93.32 94.60 94.60 95.63 95.69 94.21 94.21 95.95 95.43 Table 3: Results on the CLEF data with varying amount of training data training data in table 3). In such cases it is more beneficial to just apply the original Alpino model or the simple model combination technique. 4.4 Experiments with CGN One might argue that the question domain is rather ’easy’, given the already high baseline performance and the fact that few hand-annotated questions are enough to obtain a reasonable model. Therefore, we examine our approach on CGN (Oostdijk, 2000). The empirical results of testing using crossvalidation within a subset of CGN subdomains are given in table 4. The baseline accuracies are much lower on this more heterogeneous, spoken, data, leaving more room for potential improvements over the in-domain model. However, the results show that the auxiliary based approach does not work on the CGN subdomains either. The approach is not able to improve even on datasets where very little training data is available (e.g. comp-l), thus confirming our previous finding. Moreover, in some cases the auxiliary feature rather, although only slightly, de</context>
</contexts>
<marker>Oostdijk, 2000</marker>
<rawString>Oostdijk, Nelleke. 2000. The Spoken Dutch Corpus: Overview and first evaluation. In Proceedings of Second International Conference on Language Resources and Evaluation (LREC), pages 887–894.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miles Osborne</author>
</authors>
<title>Estimation of stochastic attributevalue grammars using an informative sample.</title>
<date>2000</date>
<booktitle>In Proceedings of the Eighteenth International Conference on Computational Linguistics (COLING</booktitle>
<contexts>
<context position="6550" citStr="Osborne, 2000" startWordPosition="1038" endWordPosition="1039">the normalization constant renders the estimation process expensive or even intractable (Johnson et al., 1999). To tackle this problem, Johnson et al. (1999) redefine the estimation procedure by considering the conditional rather than the joint probability. Pθ (ω s) = Z g0expPj=1 θj fj (ω) (3) e with Zθ as in equation 2, but instead, summing over ω′ E Q(s), where Q(s) is the set of parse trees associated with sentence s. Thus, the probability of a parse tree is estimated by summing only over the possible parses of a specific sentence. Still, calculating Q(s) is computationally very expensive (Osborne, 2000), because the number of parses is in the worst case exponential with respect to sentence length. Therefore, Osborne (2000) proposes a solution based on informative samples. He shows that is suffices to train on an informative subset of available training data to accurately estimate the model parameters. Alpino implements the Osborne-style approach to Maximum Entropy parsing. The standard version of the Alpino parser is trained on the Alpino newspaper Treebank (van Noord, 2006). 3 Exploring auxiliary distributions for domain adaptation 3.1 Auxiliary distributions Auxiliary distributions (Johnso</context>
</contexts>
<marker>Osborne, 2000</marker>
<rawString>Osborne, Miles. 2000. Estimation of stochastic attributevalue grammars using an informative sample. In Proceedings of the Eighteenth International Conference on Computational Linguistics (COLING 2000).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>A simple introduction to maximum entropy models for natural language processing.</title>
<date>1997</date>
<tech>Technical report,</tech>
<institution>Institute for Research in Cognitive Science, University of Pennsylvania.</institution>
<contexts>
<context position="3447" citStr="Ratnaparkhi, 1997" startWordPosition="512" endWordPosition="513">the empirical trials, we use Alpino (van Noord and Malouf, 2005; van Noord, 2006), a robust computational analyzer for Dutch. Alpino employs a discriminative approach to parse selection that bases its decision on a Maximum Entropy (MaxEnt) model. Section 2 introduces the MaxEnt framework. Section 3 describes our approach of exploring auxiliary distributions for domain adaptation. In section 4 the experimental design and empirical results are presented and discussed. 2 Background: MaxEnt Models Maximum Entropy (MaxEnt) models are widely used in Natural Language Processing (Berger et al., 1996; Ratnaparkhi, 1997; Abney, 1997). In this framework, a disambiguation model is speci9 Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation, pages 9–16 Manchester, August 2008 fied by a set of feature functions describing properties of the data, together with their associated weights. The weights are learned during the training procedure so that their estimated value determines the contribution of each feature. In the task of parsing, features appearing in correct parses are given increasing weight, while features in incorrect parses are given decreasing weight. Once a m</context>
</contexts>
<marker>Ratnaparkhi, 1997</marker>
<rawString>Ratnaparkhi, A. 1997. A simple introduction to maximum entropy models for natural language processing. Technical report, Institute for Research in Cognitive Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gertjan van Noord</author>
<author>Robert Malouf</author>
</authors>
<title>Wide coverage parsing with stochastic attribute value grammars. Draft available from http://www.let.rug.nl/˜vannoord. A preliminary version of this paper was published</title>
<date>2005</date>
<booktitle>in the Proceedings of the IJCNLP workshop Beyond Shallow Analyses,</booktitle>
<location>Hainan</location>
<marker>van Noord, Malouf, 2005</marker>
<rawString>van Noord, Gertjan and Robert Malouf. 2005. Wide coverage parsing with stochastic attribute value grammars. Draft available from http://www.let.rug.nl/˜vannoord. A preliminary version of this paper was published in the Proceedings of the IJCNLP workshop Beyond Shallow Analyses, Hainan China, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gertjan van Noord</author>
</authors>
<title>At Last Parsing Is Now Operational.</title>
<date>2006</date>
<booktitle>In TALN 2006 Verbum Ex Machina, Actes De La 13e Conference sur Le Traitement Automatique des Langues naturelles,</booktitle>
<pages>20--42</pages>
<location>Leuven.</location>
<marker>van Noord, 2006</marker>
<rawString>van Noord, Gertjan. 2006. At Last Parsing Is Now Operational. In TALN 2006 Verbum Ex Machina, Actes De La 13e Conference sur Le Traitement Automatique des Langues naturelles, pages 20–42, Leuven.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gertjan van Noord</author>
</authors>
<title>Using self-trained bilexical preferences to improve disambiguation accuracy.</title>
<date>2007</date>
<booktitle>In Proceedings of the Tenth International Conference on Parsing Technologies. IWPT2007, Prague.,</booktitle>
<pages>1--10</pages>
<location>Prague.</location>
<marker>van Noord, 2007</marker>
<rawString>van Noord, Gertjan. 2007. Using self-trained bilexical preferences to improve disambiguation accuracy. In Proceedings of the Tenth International Conference on Parsing Technologies. IWPT2007, Prague., pages 1–10, Prague.</rawString>
</citation>
<citation valid="false">
<authors>
<author>van Noord</author>
</authors>
<title>Gertjan. In preparation. Learning efficient parsing.</title>
<marker>van Noord, </marker>
<rawString>van Noord, Gertjan. In preparation. Learning efficient parsing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Velldal</author>
<author>S Oepen</author>
</authors>
<title>Maximum entropy models for realization ranking.</title>
<date>2005</date>
<booktitle>In Proceedings ofMT-Summit,</booktitle>
<location>Phuket, Thailand.</location>
<contexts>
<context position="4639" citStr="Velldal and Oepen, 2005" startWordPosition="704" endWordPosition="707">iven decreasing weight. Once a model is trained, it can be applied to parse selection that chooses the parse with the highest sum of feature weights. During the training procedure, the weights vector is estimated to best fit the training data. In more detail, given m features with their corresponding empirical expectation E˜p[fj] and a default model q0, we seek a model p that has minimum Kullback-Leibler (KL) divergence from the default model q0, subject to the expected-value constraints: Ep[fj] = E˜p[fj], where j E 1, ..., m. In MaxEnt estimation, the default model q0 is often only implicit (Velldal and Oepen, 2005) and not stated in the model equation, since the model is assumed to be uniform (e.g. the constant function 1 Ω(s) for sentence s, where Q(s) is the set of parse trees associated with s). Thus, we seek the model with minimum KL divergence from the uniform distribution, which means we search model p with maximum entropy (uncertainty) subject to given constraints (Abney, 1997). In alternative, if q0 is not uniform then p is called a minimum divergence model (according to (Berger and Printz, 1998)). In the statistical parsing literature, the default model q0 that can be used to incorporate prior </context>
<context position="8075" citStr="Velldal and Oepen, 2005" startWordPosition="1265" endWordPosition="1268">ally, given k auxiliary distributions Qi(ω), then k new auxiliary features fm+1, ..., fm+k are added such that fm+i(ω) = logQi(ω) (4) where Qi(ω) do not need to be proper probability distributions, however they must strictly be positive Vω E Q (Johnson and Riezler, 2000). The auxiliary distributions resemble a reference distribution, but instead of considering a single reference distribution they have the advantage that several auxiliary distributions can be integrated and weighted against each other. John10 son establishes the following equivalence between the two (Johnson and Riezler, 2000; Velldal and Oepen, 2005): k Q(ω) = Qi(ω)θm+i (5) i=1 where Q(ω) is the reference distribution and Qi(ω) is an auxiliary distribution. Hence, the contribution of each auxiliary distribution is regulated through the estimated feature weight. In general, a model that includes k auxiliary features as given in equation (4) takes the following form (Johnson and Riezler, 2000): Pθ(ω |s) = Hki=1 QZBω)θm+i expPT 1 θjfj(ω) (6) Due to the equivalence relation in equation (5) we can restate the equation to explicitly show that auxiliary distributions are additional features1. 1 Zθ expEj=1k θj fj (ω) with fj(w) = logQ(w) for m &lt; </context>
</contexts>
<marker>Velldal, Oepen, 2005</marker>
<rawString>Velldal, E. and S. Oepen. 2005. Maximum entropy models for realization ranking. In Proceedings ofMT-Summit, Phuket, Thailand.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>