<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000019">
<title confidence="0.977641">
Casting Implicit Role Linking as an Anaphora Resolution Task
</title>
<author confidence="0.983106">
Carina Silberer*
</author>
<affiliation confidence="0.847362666666667">
School of Informatics
University of Edinburgh
Edinburgh, UK
</affiliation>
<email confidence="0.996494">
c.silberer@ed.ac.uk
</email>
<author confidence="0.985588">
Anette Frank
</author>
<affiliation confidence="0.9895955">
Department of Computational Linguistics
Heidelberg University
</affiliation>
<address confidence="0.822015">
Heidelberg, Germany
</address>
<email confidence="0.997863">
frank@cl.uni-heidelberg.de
</email>
<sectionHeader confidence="0.995634" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998805166666667">
Linking implicit semantic roles is a challeng-
ing problem in discourse processing. Unlike
prior work inspired by SRL, we cast this prob-
lem as an anaphora resolution task and embed
it in an entity-based coreference resolution
(CR) architecture. Our experiments clearly
show that CR-oriented features yield strongest
performance exceeding a strong baseline. We
address the problem of data sparsity by apply-
ing heuristic labeling techniques, guided by
the anaphoric nature of the phenomenon. We
achieve performance beyond state-of-the art.
</bodyText>
<sectionHeader confidence="0.998986" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999991">
A widespread phenomenon that is still poorly stud-
ied in NLP is the meaning contribution of unfilled
semantic roles of predicates in discourse interpreta-
tion. Such roles, while linguistically unexpressed,
can often be anaphorically bound to antecedent ref-
erents in the discourse context. Capturing such im-
plicit semantic roles and linking them to their an-
tecedents is a challenging problem. But it bears im-
mense potential for establishing discourse coherence
and for getting closer to the aim of true NLU.
Linking of implicit semantic roles in discourse
has recently been introduced as a shared task in
the SemEval 2010 competition Linking Events and
Their Participants in Discourse (Ruppenhofer et al.,
2009, 2010). The task consists in detecting un-
filled semantic roles of events and determining an-
tecedents in the discourse context that these roles
</bodyText>
<footnote confidence="0.419737">
* The work reported in this paper is based on a Master’s
Thesis conducted at Heidelberg University (Silberer, 2011).
</footnote>
<page confidence="0.882056">
1
</page>
<bodyText confidence="0.9997204">
can be understood to refer to. In (1), e.g., the pred-
icate jealousy introduces two implicit roles, one for
the experiencer, the other for the object of jealousy
involved. These roles can be bound to Watson and
the speaker (I) in the non-local preceding context.
</bodyText>
<listItem confidence="0.99680225">
(1) Watson won’t allow that I know anything of art but
that is mere jealousy because our views upon the
subject differ.
(2) IRe,,,d,, was sitting reading in the chairPl,,,,.
</listItem>
<bodyText confidence="0.999896555555556">
In contrast to implicit roles that can be discourse-
bound to an antecedent as in (1), roles can be inter-
preted existentially, as in (2), with an unfilled TEXT
role of the READING frame that cannot be anchored
in prior discourse. The FrameNet paradigm (Fill-
more et al., 2003) that was used for annotation in
the SemEval task classifies these interpretation dif-
ferences as definite (DNI) vs. indefinite (INI) null
instantiations (NI) of roles, respectively.
</bodyText>
<sectionHeader confidence="0.924416" genericHeader="method">
2 Implicit Role Reference: A Short History
</sectionHeader>
<bodyText confidence="0.999881384615385">
Early studies. The phenomenon of implicit role re-
ference is not new. It has been studied in a number
of early approaches. Palmer et al. (1986) treated un-
filled semantic roles as special cases of anaphora and
coreference resolution (CR). Resolution was guided
by domain knowledge encoded in a knowledge-
based system. Similarly, Whittemore et al. (1991)
analyzed the resolution of unexpressed event roles
as a special case of CR. A formalization in DRT was
fully worked out, but automation was not addressed.
Later studies emphasize the role of implicit role
reference in a frame-semantic discourse analysis.
Fillmore and Baker (2001) provide an analysis of
</bodyText>
<note confidence="0.956727">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 1–10,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999383193181818">
a newspaper text that indicates the importance of
frames and roles in establishing discourse coher-
ence. Burchardt et al. (2005) offer a formalization
of the involved factors: the interplay of frames and
frame relations with factors of contextual contigu-
ity. The work includes no automation, but suggests a
corpus-based approach using antecedent-role coref-
erence patterns collected from corpora.
Tetreault (2002), finally, offers an automated anal-
ysis for resolving implicit role reference. The small-
scale study is embedded in a rule-based CR setup.
SemEval 2010 Task 10: Linking Roles. Trig-
gered by the SemEval 2010 competition (Ruppen-
hofer et al., 2010), research on resolving implicit
role reference has gained momentum again, in a field
where both semantic role labeling (SRL) and coref-
erence resolution have seen tremendous progress.
However, the systems that participated in the NI-
only task on implicit role resolution achieved mod-
erate success in the initial subtasks: (i) recog-
nition of implicit roles and (ii) classification as
discourse-bound vs. existential interpretation (DNI
vs. INI). Yet, (iii) identification of role antecedents
was bluntly unsuccessful, with around 1% F-score.
Ruppenhofer et al. clearly relate the task to
coreference resolution. The participating systems,
though, framed the task as a special case of SRL.
Chen et al. (2010) participated with their SRL sys-
tem SEMAFOR (Das et al., 2010). They cast the task
as one of extended SRL, by admitting constituents
from a larger context. To overcome the lack and
sparsity of syntactic path features, they include lex-
ical association and similarity scores for semantic
roles and role fillers; classical SRL order and dis-
tance features are adapted to larger distances.
VENSES++ by Tonelli and Delmonte (2010) is
a semantic processing system that includes lexico-
semantic processing, anaphora resolution and deep
semantic resolution components. Anaphora resolu-
tion is performed in a rule-based manner; pronom-
inals are replaced with their antecedents’ lexical
information. For role linking, the system applies
diverse heuristics including search for predicate-
argument structures with compatible arguments, as
well as semantic relatedness scores between poten-
tial fillers of (overt and implicit) semantic roles.
More recently Tonelli and Delmonte (2011) recur
to a leaner approach for role binding, estimating a
relevance score for potential antecedents from role
fillers observed in training. They report an F-score
of 8 points for role binding on SemEval data. How-
ever, being strongly lexicalized, their trained model
seems heavily dependent on the training data.
Ruppenhofer et al. (2011) use semantic types for
identifying DNI role antecedents, reporting an error
reduction of 14% on Chen et al. (2010)’s results.
The poor performance results in the SemEval task
clearly indicate the difficulty of resolving implicit
role reference. A major factor seems to relate to data
sparsity: the training set covers only 245 DNI anno-
tations linked to an antecedent.
Linking implicit arguments of nominals. Ger-
ber and Chai (2010) (G&amp;C henceforth) investigate a
closely related task of argument binding, tied to the
linking of implicit arguments for nominal predicates
using the PropBank role labeling scheme. In con-
trast to the SemEval task, which focuses on a verbs
and nouns, their system is only applied to nouns and
is restricted to 10 predicates with substantial training
set sizes (avg: 125, median: 103).
G&amp;C propose a discriminative model that selects
an antecedent for an implicit role from an extended
context window. The approach incorporates some
aspects relating to CR that go beyond the SRL-
oriented SemEval systems: A candidate represen-
tation includes information about all the candidates’
coreferent mentions (determined by automatic CR),
in particular their semantic roles (provided by gold
annotations) and WordNet synsets. Patterns of se-
mantic associations between filler candidates and
implicit roles are learned for all mentions contained
in the candidate’s entity chain. They achieve an F-
score of 42.3, against a baseline of 26.5.
Gerber (2011) presents an extended model that in-
corporates strategies suggested in Burchardt et al.
(2005): using frame relations as well as coreference
patterns acquired from large corpora. This model
achieves an F-score of 50.3 (baseline: 28.9).
</bodyText>
<sectionHeader confidence="0.993161" genericHeader="method">
3 Casting Implicit Role Linking as an
Anaphora Resolution Task
</sectionHeader>
<subsectionHeader confidence="0.999318">
3.1 Implicit role = anaphora resolution
</subsectionHeader>
<bodyText confidence="0.8394995">
Recent models for role binding mainly draw on tech-
niques from SRL, enriched with concepts from CR.
</bodyText>
<page confidence="0.989514">
2
</page>
<bodyText confidence="0.97547667032967">
In this paper, we explicitly formulate implicit role
linking as an anaphora resolution task. This is in
line with the predominant conception in early work,
and also highlights the close relationship with zero
anaphora (Kameyama, 1985). Computational treat-
ments of zero anaphora (e.g., Imamura et al. (2009))
are in fact employing techniques well-known from
SRL. Recent work by Iida and Poesio (2011), by
contrast, offers an analysis of zero anaphora in a
CR architecture. Further support comes from psy-
cholinguistic studies in Garrod and Terras (2000),
who establish commonalities between implicit role
reference and other types of anaphora resolution.
The contributions of our work are as follows:
i. We cast implicit role binding as a CR task, us-
ing an entity-mention model and discriminative
classification for antecedent selection.
ii. We examine the effectiveness of model features
for classical SRL vs. CR features to clarify the
nature of this special phenomenon.
iii. We automatically acquire heuristically labeled
data to address the sparse data problem.
i. An entity-mention model for anaphoric role
resolution. In our model implicit roles that are
discourse-bound (i.e. classified as DNI) are treated
as anaphoric, similar to zero anaphora: the implicit
role will be bound to a discourse antecedent.
In line with recent research in CR, we adopt an
entity-mention model, where an entity is represented
by all mentions pertaining to a coreference chain
(see i.a. Rahman and Ng (2011), Cai and Strube
(2010)). Our model is based on binary classifier de-
cisions that take as input the anaphoric role and an
entity candidate from the preceding discourse. The
final classification of a role linking to an entity is ob-
tained by discriminative ranking of the binary clas-
sifiers’ probability estimates. Details on the system
architecture are given in Section 3.2.
ii. SRL vs. CR: Analysis of feature sets. The
linking of implicit semantic roles represents an inter-
esting mixture of SRL and CR that displays excep-
tional characteristics of both types of phenomena.
In contrast to classical SRL, the relation between
a predicate’s semantic role and a candidate role filler
– being realized outside the local syntactic context –
cannot be characterized by syntactic path features.
But similar to SRL we can compute a semantic class
type expected by the role and determine which can-
didate is most appropriate to fill the semantic role.
Anaphoric binding of unfilled roles also diverges
from classical CR in that the anaphoric element is
not overtly expressed. This excludes typical CR fea-
tures that refer to overt realization, such as agree-
ment or string overlap. Again, we can make use of a
semantic characterization of role fillers to determine
the role’s most appropriate antecedent entity in the
discourse. This closely relates to semantic class fea-
tures employed in CR (e.g., Rahman and Ng (2011)).
Thus, semantic association features are important
modeling aspects, but they do not contribute to clari-
fying the nature of the phenomenon. We will include
additional properties that are considered characteris-
tic for CR, such as the semantics of an entity (as op-
posed to individual mentions), or salience properties
of antecedents (cf. Section 4.3). Thus, the model we
propose substantially differs from prior work.
We classify the features of our models as SRL vs.
CR features, plus a mixture class that relates to both
phenomena. We examine which type of features is
most effective for resolving implicit role reference.
iii. Heuristic data acquisition. In response to the
sparse data problem encountered with the SemEval
data set and the general lack of annotated resources
for implicit role binding, we experiment with tech-
niques for heuristic data acquisition. The strategy
we apply builds on our working hypothesis that im-
plicit role reference is best understood as a special
case of (zero) anaphora resolution.
We process manually annotated coreference data
sets that are jointly labeled with semantic roles.
From these we extract entity chains that contain
anaphoric pronouns that fill a predicate’s semantic
role. We artificially delete the pronoun’s role label
and transfer it to its closest antecedent in its chain.
In this way, we convert the example to an instance
that is structurally similar to one involving a locally
unfilled semantic role that is bound to an overt an-
tecedent. An example is given below: in (3.a) we
identify a pronoun that fills the SPEAKER role of the
frame STATEMENT. We transfer this role label to its
closest antecedent (3.b).
</bodyText>
<page confidence="0.986419">
3
</page>
<listItem confidence="0.648461">
(3) a. Riadyk spoke in hisk 21-story office building
on the outskirts of Jakarta. [...] The timing of
hisk,Speaker statementStatement is important.
b. Riadyk spoke in hisk,Speaker 21-story office
building on the outskirts of Jakarta. [...] The tim-
ing of Ql statementStatement is important.
</listItem>
<bodyText confidence="0.999767833333333">
Clearly such artificially created annotation instances
are only approximations of naturally occurring cases
of implicit role binding. But we expect to acquire
numerous data points for relevant features: semantic
class information for the antecedent entity, the pred-
icate’s frame and roles and coherence properties.
</bodyText>
<subsectionHeader confidence="0.999819">
3.2 System Architecture
</subsectionHeader>
<bodyText confidence="0.997588181818182">
Our approach is embedded in an architecture for su-
pervised CR using an entity-mention model. The
main processing steps of the system include: (1) en-
tity detection, (2) instance creation with feature ex-
traction and (3) classification. As we are focusing
on the resolution of implicit DNI roles, we assume
that the text is already augmented with standard CR
information (we make use of gold data and automati-
cally assigned coreference chains). Accordingly, the
description of modules focuses exclusively on the
resolution of DNIs.
</bodyText>
<listItem confidence="0.7934654">
(1) Entity Detection. We first collect the entire
entity set £ mentioned in the discourse. This set
forms the overall set of candidates to consider for
DNI linking. For each DNI dk to be linked, a subset
of candidates £k C £ is chosen as candidate search
space for resolving dk. We experiment with differ-
ent strategies for constructing £k (cf. Section 4).
(2) Instance Creation. The next step consists in
the creation of (training) instances for classification
including the extraction of features for all instances.
</listItem>
<bodyText confidence="0.996547407407407">
An instance instej,dk consists of the active DNI
dk, its frame and a candidate entity ej E £k. In-
stance creation follows an entity-based adaption of
the standard procedure of Soon et al. (2001), which
has been applied by Yang et al. (2004, 2008). Pro-
cessing the discourse from left to right, for each DNI
dk, instances Zk are created by processing £k from
right to left according to each entity’s most recent
mention, starting with the entity closest to dk. Note
that, as entities instead of mentions are considered,
only one instance is created for an entity which is
mentioned several times in the search space.
In training, the instance creation stops when the
correct antecedent, i.e. a positive instance, as well as
at least one negative instance have been found.1
(3) Classification. From the acquired training in-
stances we learn a binary classifier that predicts for
an instance instej,dk whether it is positive, i.e. en-
tity ej is a correct antecedent for DNI dk. Fur-
ther, the classifier provides a probability estimate for
instej,dk being positive. We obtain classifications
for all instances in Zk. Among the positive classified
instances, we select the antecedent e with the high-
est estimate. That is, we apply the best-irst strategy
(Ng and Cardie, 2002). In case of a tie, we choose
the antecedent which is closer to the target. If no
instance is classified as positive, dk is left unfilled.
</bodyText>
<sectionHeader confidence="0.994121" genericHeader="method">
4 Data and Experiments
</sectionHeader>
<subsectionHeader confidence="0.993046">
4.1 SEMEVAL 2010 task and data set
</subsectionHeader>
<bodyText confidence="0.999905785714286">
We adhere to the SemEval 2010 task by Ruppen-
hofer et al. (2009) as test bed for our experiments.
The main focus of our work is on part (iii), the iden-
tification of antecedents for DNIs. Subtasks (i) and
(ii), the recognition and interpretation of NIs will be
only tackled to enable comparison to the participat-
ing systems of the SemEval NI-only task.
The SemEval task is based on fiction stories by
A. C. Doyle, one story as training data and another
two chapters as test set, enriched with coreference
and FrameNet-style frame annotations. Information
about the training section is found in Table 1. The
test data comprise 710 NIs (349 DNIs, 361 INIs), of
which 259 DNIs are linked.
</bodyText>
<subsectionHeader confidence="0.99286">
4.2 Heuristic data acquisition
</subsectionHeader>
<bodyText confidence="0.999331090909091">
Since the training data has a critically small amount
of linked DNIs, we heuristically labeled training
data on the basis of data sets with manually anno-
tated coreference information: OntoNotes 3.0 (Hovy
et al., 2006), as well as ACE-2 (Mitchell et al., 2003)
and MUC-6 (Chinchor and Sundheim, 2003).
OntoNotes 3.0 was merged with gold SRL an-
notations from the CoNLL-2005 shared task. By
means of SemLink-1.1 (Loper et al., 2007) and a
mapping included in the SemEval data, these Prop-
Bank (PB, Palmer et al. (2005)) annotations were
</bodyText>
<footnote confidence="0.990668">
1We additionally impose several restrictions, e.g., a valid
candidate must not already fill another role of the active frame.
</footnote>
<page confidence="0.97599">
4
</page>
<table confidence="0.9502513">
#ent avg avg #frames #frame#DNI #DNI
#ent/doc size types types
141 141 9 1,370 317 245 155
7899 23 3 12,770 258 2,220 270
3564 11 4 58,204 757 4,265 578
1841 15 3 20,140 654 997 310
corpus coref semantic roles
ONotes manual manual PB CoNLL05, ported to FN
ACE-2 manual automatic FN (Semafor)
MUC-6 manual automatic FN (Semafor)
</table>
<tableCaption confidence="0.999926">
Table 1: SemEval vs. heuristically acquired data
</tableCaption>
<bodyText confidence="0.999698">
mapped to their FrameNet (FN) counterparts, if ex-
istent. For the ACE-2 and MUC-6 corpora, we used
Semafor (Das and Smith, 2011) for automatic anno-
tation with FN semantic roles. From these data sets
we acquired heuristically annotated instances of role
linking using the strategy explained in 3.1.
Table 1 summarizes the resulting training data.
The heuristically labeled data extends the manually
labeled DNI instances by an order of magnitude.
</bodyText>
<subsectionHeader confidence="0.999509">
4.3 Model parameters
</subsectionHeader>
<bodyText confidence="0.977010388888889">
Entity sets Edni. For definition of the set of can-
didate entities to consider for DNI linking, Edni,
we determined different parameter settings with re-
strictions on the types, distances and prominence of
candidate antecedents. For instance, unlike in noun
phrase CR, antecedents for a DNI can be realized by
a wide range of constituents other than NPs, such as
prepositional (PP), adverbial (ADVP), verb phrases
(VP) and even sentences (S) referring to proposi-
tions.
These settings, stated in Table 2, were inferred by
experiments on the training data and by examining
its statistics: AllChains is motivated by the fact that
72% of the DNIs are linked to referents with non-
singleton chains. On the other hand, the majority of
DNI antecedents – not only non-singletons, but also
phrases of a certain type or terminals that overtly
fill other roles – are located in the current and the
two preceding sentences (69.6%), which motivates
SentWin. However, antecedents are also located far
beyond this window span which is probably due to
the nature of the SemEval texts, with prominent en-
tities being accessible over longer stretches of dis-
course. Chains+Win is designed by taking into ac-
AllChains This set contains all the entities repre-
sented by non-singleton coreference chains that
were introduced in the discourse up to the cur-
rent DNI position, assuming that this way only
more salient entities are considered.
SentWin Comprises constituents with a certain
phrase type2 or terminals that overtly fill a role,
occurring within the current or the preceding
two sentences.
Chain+Win This set comprises SentWin plus all
entities mentioned at least five times up to the
current DNI position (i.e. salient entities).
</bodyText>
<tableCaption confidence="0.9002535">
Table 2: Entity set settings Ed, ,i
count all previous observations.
</tableCaption>
<bodyText confidence="0.88154475">
Training data sets. We made use of different mix-
tures of training data: SemEval plus different exten-
sions using the heuristically acquired data summa-
rized in Table 1.
</bodyText>
<subsectionHeader confidence="0.977981">
4.4 Feature sets: SRL, mixed and CR-oriented
</subsectionHeader>
<bodyText confidence="0.9692563125">
Table 3 lists the most important features used for
training our models. Features 1-13 were used in the
best model and are ordered by their strength based
on feature ablation experiments (cf. Section 5). All
features are marked for their general type; the last
column marks features employed by G&amp;C.3
Below we give some details for selected features.
Feat. 1: Prominence. We first compute average
prominence of an entity e (Eq. 2) by summing over
the size (= nb. of mentions) of all entities e in a win-
dow w4 of preceding sentences and dividing by the
nb. of entities E in w. Prominence of e (Eq. 1) is
set to the difference between its size in w and the
average prominence score.5 The final feature value
records the relative rank of e’s prominence score
compared to the scores of the other candidates.
</bodyText>
<equation confidence="0.891065333333333">
prom(e, w) = #mentions(e, w) − avg prom(w) (1)
avg prom(w) = EICE #mentions(e, w) (2)
JEJ
</equation>
<footnote confidence="0.9865">
2The phrase type must be NPB, S, VP, SBAR, or SG.
3_ marks features that are similar to G&amp;C features. Note
that their only CR features are distance features.
4We set w = 2 based on experiments on the training data.
5This prominence score was proposed by Dolata (2010)
within an entity grid approach to role linking.
</footnote>
<figure confidence="0.966824083333333">
SemEval
ONotes
ACE-2
MUC-6
5
nr feature type G&amp;C
1 prominence prominence score of the entity in the current discourse position CR -
2 pos.dist mention PoS or phrase type of the most recent explicit mention (CR) -
concatenated with sentence distance to the target
3 dist mentions minimum distance between DNI and entity in mentions CR -
4 dist sentences minimum distance between DNI and entity in sentences CR +
5 vnroles dni.entity the counterparts of the DNI in VerbNet (VN, Kipper et al. (2000)) mixed +
concatenated with the VN roles the entity already instantiates
6 roles dni.entity concatenation of the DNI with the FN roles the entity already instantiates mixed �
7 semType dni.entity semantic type of the DNI concatenated with mixed -
the semantic types of the roles the entity already instantiates
8 avgDist sentences average sentence distance between the entity and the DNI CR +
9 sp supersense agreement of the selectional preferences for the DNI mixed -
and the most frequent supersense of the entity
10 function (target) grammatical function of the target SRL -
11 wnss ent.st dni pointwise mutual information between the entity’s WN supersense ss and mixed -
the DNI’s FN semantic type st: pmi(ss, st) = lo92P(ss|st)/P(ss)
12 nbRoles dni.entity like feature 5, but with NomBank arguments 0 and 1 mixed �
13 frame.dni frame name concatenated with the DNI SRL -
</figure>
<tableCaption confidence="0.973466">
Table 3: Best features used for training. Feat. 11 was computed on the FN dataset and the SemEval training data.
</tableCaption>
<bodyText confidence="0.969207846153846">
Feat. 9: SelPrefs. We compute selectional prefer-
ences following the information-theoretic approach
of Resnik (1993, 1996). Similar to Erk (2007), we
used an adapted version which we computed for se-
mantic roles by means of the FN database rather than
for verb argument positions. The WordNet classes
over which the preferences are defined are WordNet
lexicographer’s files (supersenses).
The selectional association values A(dni, ss) of
the DNI’s selectional preferences are retrieved for
the supersense ss of each candidate antecedent’s
head. As for Feat. 1, we define a candidate’s fea-
ture value by its rank in the ordered list of these As.
</bodyText>
<subsectionHeader confidence="0.876329">
4.5 Experiments
</subsectionHeader>
<bodyText confidence="0.910646583333333">
Evaluation measures. We adopt the precision (P),
recall (R) and Fi measures in Ruppenhofer et al.
(2010). A true positive is a DNI which has been
linked to the correct entity as given by the gold data.
Classifiers and feature selection. For DNI link-
ing, we use BayesNet (Cooper and Herskovits,
1992) as classifier, implemented in Weka (Witten
and Frank, 2000).6 For each parameter combination,
we perform feature selection by means of leave-one-
out 10-fold cross-validation on the SemEval train-
ing data with successively removing/determining the
6We experimented with different learners and selected the
algorithm that performed best for the different subtasks.
best features. The resulting models Mi are then eval-
uated on the SemEval test data in different setups:
Exp1: Linking DNIs. Exp1 evaluates our models
on the DNI linking task proper (NI-only step (iii)).
This setting uses the gold coreference, SRL and DNI
information in the test data.
Exp2: Full NI-only. For benchmarking on the
SemEval task, we perform the complete NI-only
task. Here, the test data is only enriched w/ SRL la-
beling. Each frame f in the test corpus is processed,
involving the following steps:
</bodyText>
<listItem confidence="0.997628285714286">
(i) Recognition of NIs is performed by consulting
the FN database7 and determining the FN core roles
that are unfilled. From this NI set, roles that are
conceptually redundant or competing with f’s overt
roles are rejected as they don’t need to or must not
be linked, respectively.
(ii) For predicting the interpretation of an NI, we
use LibSVM (Chang and Lin, 2001) as classifier
which further assigns each NI a probability estimate
of the NI being definite. We use a small set of fea-
tures: the FN semantic type of the NI and a boolean
feature indicating whether the target is in passive
voice and the agent (object) not realized. Further,
we use a statistical feature which gives the relative
</listItem>
<footnote confidence="0.963711">
7We used the FrameNetAPI by Reiter (2010).
</footnote>
<page confidence="0.99873">
6
</page>
<table confidence="0.944953777777778">
model add. entity frame DNI Linking (%)
data set anno. P R F1
M0 - AllChains gold 25.6 25.1 25.3
M1 ON2-10 Chains+Win proj 30.8 25.1 27.7
M1, ON2-24 AllChains proj 35.6 20.1 25.7
M1,, ON2-24 SentWin proj 23.3 22.4 22.8
M2 MUC Chains+Win auto 26.1 24.3 25.3
M3 ACE AllChains auto 24.0 21.2 22.5
Prom – Chains+Win – 20.5 20.5 20.5
</table>
<tableCaption confidence="0.9981765">
Table 4: Exp1: Best performing models for different en-
tity and data settings. Test data contain gold CR chains.
</tableCaption>
<bodyText confidence="0.999749857142857">
frequency of the role’s realization as DNI and INI,
respectively, in the training data.
(iii) DNI linking is performed for each of f’s pre-
dicted DNIs Df in descending order of their prob-
ability estimates. If an antecedent em can be de-
termined for a predicted DNI, the role is labeled
as such and linked to em. As the DNI’s role has
been filled now, competing or redundant DNIs are
removed from Df before moving to the next pre-
dicted DNI. Only DNIs for which an antecedent is
found are labeled as such.
Exp2 is evaluated on both gold coreference an-
notation and automatically assigned coreference
chains, using the CR system of Cai et al. (2011).
</bodyText>
<sectionHeader confidence="0.995438" genericHeader="evaluation">
5 Evaluation and Results
</sectionHeader>
<subsectionHeader confidence="0.969751">
5.1 Exp1: DNI linking evaluation
</subsectionHeader>
<bodyText confidence="0.9532086">
Table 4 shows the best performing models for DNI
linking for each parameter setting8. We compare
them to a strong baseline Prom (last row) that links
each DNI to the antecedent candidate with highest
prominence score. Its F1-score is beaten by the other
models, with a gain of 7.2 points for model M1. The
high performance of the baseline can be taken as ev-
idence that salience factors are crucial for this task.
The best performing model M1 (27.7 F1) uses
about a fifth of the ON data with Chains+Win. When
using SentWin as entity set, F1 drops to 18.5 (not
shown). The best performing model using SentWin
(M1��) performs 4.9 points below M1. Hence, re-
liance on the Chains+Win set seems beneficial. Per-
formance of the AllChains setting varies over the
8We consider the 3 types of entity sets and different train-
ing setups f additional data (Section 4.3); additional data with
gold, projected or automatic frame annotations. The ON data
was also evaluated with roughly a fifth of ON to evaluate the
effect of different amounts of data of the same type of data.
</bodyText>
<table confidence="0.99954">
Features P ( %) R (%) F1 (%)
all 30.8 25.1 27.7
- 1-4,8 (CR) 21.6 8.1 11.8
- 10,13 (SRL) 31.0 25.9 28.2
- 5-7,9,11-12 (mixed) 20.6 20.5 20.5
</table>
<tableCaption confidence="0.999833">
Table 5: Results of ablation study.
</tableCaption>
<bodyText confidence="0.99985255">
different data sets: the strongest model is M0 with-
out additional data. An explanation could be the dif-
ferent data domains (story vs. news), leading to a
different nature (length and number) of the entities.
In general, the models seem to profit from heuris-
tically labeled training data. We note strong gains
(up to 10 pts) in precision for 3 of these 5 best mod-
els, compared to M0. Finally, we observe higher
performance when using additional data with gold/
projected semantic frame annotations (M1, M1e).
Analysis of the best model. Table 5 states the re-
sults for M1 when leaving out one of the feature
types at a time. The serious drop of F1 from 27.7%
to 11.8% when omitting CR features clearly demon-
strates that this feature type has by far the greatest
impact on the task performance. Rejection of the
mixed features decreases F1 to a score equal to the
prominence baseline, whereas leaving out the SRL-
features even slightly increases F1. The weakness of
Feature 13 could still be attributed to data sparsity.
</bodyText>
<subsectionHeader confidence="0.997409">
5.2 Exp2: Full NI-only evaluation
</subsectionHeader>
<bodyText confidence="0.999766533333333">
Table 6 lists the results for the full NI-only task ob-
tained with the presented models with different addi-
tional training data sets (lines 2-5). When perform-
ing all three steps, the F1-score of the best model
M1 drops to 10.1% (-17.6 pts, col. 10) under us-
age of automatic coreference annotations in the test
data (i.e. under the real task conditions). When us-
ing gold coreference annotations, the F1-score is
at 18.1% (col. 11), which can be seen as an upper
bound for our current models on this task. The dif-
ference of 9.6 points between only performing DNI
linking (Table 4) and the full NI-only task reflects
the fact that recognizing (step i) and interpreting
(step ii) NIs bear difficulties on their own.9
Comparison of our models with the two SemEval
</bodyText>
<footnote confidence="0.9949505">
9When not performing step (iii), NI recognition achieves
77.6% recall and 67% relative precision.
</footnote>
<page confidence="0.999025">
7
</page>
<table confidence="0.994216090909091">
model add. entity frame Null Instantiations (%) P DNI Linking ( %)
data set anno. recogn. interpret. (precision) R F1 F1(crf)
recall relative absolute
M0 - AllChains gold 58 68 40 6.0 8.9 7.1 12.5
M1 ON2-10 Chains+Win proj 56 69 38 9.2 11.2 10.1 18.1
M2 MUC Chains+Win auto 52 70 36 7.0 8.5 7.6 11.0
M3 ACE AllChains auto 56 68 38 5.9 8.1 6.8 11.3
M31 ACE Chains+Win auto 56 68 38 6.9 9.7 8.0 9.5
SEMAFOR – 63 55 35 1.40
VENSES++ – 8 64 5 1.21
T&amp;D – 54 75 40 13.0 6.0 8
</table>
<tableCaption confidence="0.9984625">
Table 6: Exp2 results obtained for our models (lines 1-5) and comparable systems (lines 6-8). Column 5 gives the
score for correctly recognized NIs. Cols. 6 and 7 report precision for correctly interpreted NIs on the basis of the
correctly recognized (relative) vs. all gold NIs to be recognized (absolute). The scores in the last column (F1(crf))
were obtained with gold CR annotations.
</tableCaption>
<bodyText confidence="0.999166375">
task participants10 (lines 7-8) shows that our models
clearly outperform these systems – with a gain of
+5.7 and +8.89 points in F1-score in DNI linking.11
Compared to Tonelli and Delmonte (2011)
(T&amp;D), M1 has a higher F1-score in linking of
+2.1 points. In contrast to our method, their link-
ing approach is (admittedly) heavily lexicalized and
strongly tailored to the domain of the used data.
</bodyText>
<sectionHeader confidence="0.995337" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9998281875">
We cast the problem of linking implicit semantic
roles as a special case of (zero) anaphora resolution,
drawing on insights from earlier work and parallels
observed with zero anaphora. Our results strongly
support this analysis: (i) Feature selection clearly
determines CR-related features as strongest support
for DNI linking. (ii) Our models beat a strong base-
line using a prominence score to determine DNI ref-
erence. (iii) We devise a method for heuristically la-
beling training data that simulates implicit role refer-
ence. Using this data we obtain system performance
beyond state-of-the-art, with high gains in precision.
While these findings clearly corroborate our con-
ceptual approach, overall performance is still mea-
ger. Comparison to G&amp;C’s setting suggests that
training data is a serious issue. We addressed the
</bodyText>
<footnote confidence="0.749013142857143">
10The Fl-scores are from http://semeval2.fbk.eu/
semeval2.php?location=Rankings/ranking10.html
11Moreover, note that Ruppenhofer et al. describe a weaker
evaluation, that judges DNI linkings as correct if the span of the
linked referent contains the gold referent. Further, they consider
14 linked INIs in the test data, although linking INIs conflicts
with the definition of INIs.
</footnote>
<bodyText confidence="0.999831666666667">
problem of training set size using heuristic data ac-
quisition. The nature of semantic role annotations
may be another problem, as FrameNet-style roles do
not generalize well. Finally, implicit roles pertaining
to nominalizations tend to be more local than those
pertaining to verbs12 and might be less diverse.
Our model is closer in spirit to G&amp;C than the Se-
mEval systems, but differs by being embedded in
an entity-based CR architecture using discriminative
antecedent selection. Also, we address a more prin-
cipled issue, by exploring the nature of the task using
a qualitative feature analysis. Our system compares
favorably to related work. Benchmarking against
the SemEval participants and T&amp;D shows clear im-
provements. Also, T&amp;D’s model is closely tied to
domain data, while ours is enhanced with out-of-
domain data. Exact comparison to G&amp;C needs to be
conducted on the same data set and labeling scheme.
In sum, within the chosen setting we can show
that implicit role reference is best modeled as a spe-
cial case of anaphora resolution. We observe that
models trained on cleaner data perform better than
on larger, but more noisy data sets. Thus, it is es-
sential to further enhance the quality of heuristically
labeled data. Applying the classifiers for steps (i)
and (ii) as a filter could help to better constrain the
data to the target phenomenon.
</bodyText>
<footnote confidence="0.8625268">
Acknowledgements. We would like to thank Mateusz
Dolata for his help with salience and coherence features,
and Michael Roth for his server support.
12This is confirmed by analysis of the SemEval vs. NomBank
corpus of G&amp;C.
</footnote>
<page confidence="0.998046">
8
</page>
<sectionHeader confidence="0.989981" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.967530409523809">
Aljoscha Burchardt, Anette Frank, and Manfred Pinkal.
2005. Building Text Meaning Representations from
Contextually Related Frames – A Case Study. In Pro-
ceedings of the 6th International Workshop on Com-
putational Semantics, IWCS-6, pages 66–77, Tilburg,
The Netherlands.
Jie Cai and Michael Strube. 2010. End-to-end coref-
erence resolution via hypergraph partitioning. In
Proceedings of the 23rd International Conference on
Computational Linguistics, pages 143–151, Beijing,
China.
Jie Cai, Eva M´ujdricza-Maydt, and Michael Strube.
2011. Unrestricted coreference resolution via global
hypergraph partitioning. In Proceedings of the Shared
Task of 15th Conference on Computational Natural
Language Learning, pages 56–60, Portland, Oregon.
Chih-Chung Chang and Chih-Jen Lin, 2001. LIB-
SVM: a Library for Support Vector Machines. Soft-
ware available at http://www.csie.ntu.edu.
tw/-cjlin/libsvm.
Desai Chen, Nathan Schneider, Dipanjan Das, and
Noah A. Smith. 2010. SEMAFOR: Frame Argument
Resolution with Log-Linear Models. In Proceedings
of the 5th International Workshop on Semantic Evalu-
ation, pages 264–267, Uppsala, Sweden, July.
Nancy Chinchor and Beth Sundheim, 2003. Message
Understanding Conference (MUC) 6. Linguistic Data
Consortium, Philadelphia.
Gregory F. Cooper and Edward Herskovits. 1992. A
Bayesian Method for the Induction of Probabilistic
Networks from Data. Machine Learning, 9(4):309–
347.
Dipanjan Das and Noah A. Smith. 2011. Semi-
supervised frame-semantic parsing for unknown pred-
icates. In Dekang Lin, Yuji Matsumoto, and Rada Mi-
halcea, editors, ACL, pages 1435–1444. The Associa-
tion for Computer Linguistics.
Dipanjan Das, Nathan Schneider, Desai Chen, and
Noah A. Smith. 2010. Probabilistic Frame-Semantic
Parsing. In Human Language Technologies: The 2010
Annual Conference of the North American Chapter of
the Association for Computational Linguistics, pages
948–956, Los Angeles, California, June.
Mateusz Dolata. 2010. Extending the Entity-Grid Model
for the Processing of Implicit Roles in Discourse.
Bachelor’s thesis, Department of Computational Lin-
guistics, Heidelberg University, Germany.
Katrin Erk. 2007. A Simple, Similarity-based Model for
Selectional Preferences. In Proceedings of the 45th
Annual Meeting of the Association for Computational
Linguistics, ACL ’07, pages 216–223, Prague, Czech
Republic, June.
Charles J. Fillmore and Collin F. Baker. 2001. Frame Se-
mantics for Text Understanding. In Proceedings of the
NAACL 2001 Workshop on WordNet and Other Lexical
Resources, Pittsburgh, June.
Charles J. Fillmore, Christopher R. Johnson, and Miriam
R. L. Petruck. 2003. Background to Framenet. Inter-
national Journal of Lexicography, 16(3):235–250.
Simon Garrod and Melody Terras. 2000. The Contribu-
tion of Lexical and Situational Knowledge to Resolv-
ing Discourse Roles: Bonding and Resolution. Jour-
nal of Memory and Language, 42(4):526–544.
Matthew Gerber and Joyce Chai. 2010. Beyond Nom-
Bank: A Study of Implicit Arguments for Nominal
Predicates. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguistics,
pages 1583–1592, Uppsala, Sweden, July.
Matthew Steven Gerber. 2011. Semantic Role Labeling
of Implicit Arguments for Nominal Predicates. Ph.D.
thesis, Michigan State University.
Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance
Ramshaw, and Ralph Weischedel. 2006. OntoNotes:
The 90% Solution. In Proceedings of the Human Lan-
guage Technology Conference of the North American
Chapter of the Association for Computational Linguis-
tics, HLT-NAACL ’06, pages 57–60, New York, New
York, June.
Ryu Iida and Massimo Poesio. 2011. A Cross-Lingual
ILP Solution to Zero Anaphora Resolution. In Pro-
ceedings of the 49th Annual Meeting of the Associ-
ation for Computational Linguistics, pages 804–813,
Portland, Oregon.
Kenji Imamura, Kuniko Saito, and Tomoko Izumi.
2009. Discriminative Approach to Predicate-
Argument Structure Analysis with Zero-Anaphora
Resolution. In Proceedings of the Joint Conference
of the 47th Annual Meeting of the Association for
Computational Linguistics and the 4th International
Joint Conference on Natural Language Processing of
the Asian Federation of Natural Language Processing,
ACL-IJCNLP ’09, pages 85–88, Suntec, Singapore,
August.
Megumi Kameyama. 1985. Zero Anaphora: The case of
Japanese. Ph.D. thesis, Stanford University.
Karin Kipper, Hoa Trang Dang, and Martha Palmer.
2000. Class-Based Construction of a Verb Lexicon.
In Proceedings of the 17th National Conference
on Artificial Intelligence and 12th Conference
on Innovative Applications of Artificial Intelli-
gence, pages 691–696, Austin, Texas. AAAI Press.
http://verbs.colorado.edu/-mpalmer/
projects/verbnet.html.
Edward Loper, Szu ting Yi, and Martha Palmer. 2007.
Combining Lexical Resources: Mapping between
</reference>
<page confidence="0.944621">
9
</page>
<reference confidence="0.999910945652174">
PropBank and VerbNet. In Proceedings of the 7th In-
ternational Workshop on Computational Linguistics.
Alexis Mitchell, Stephanie Strassel, Mark Przybocki,
JK Davis, George Doddington, Ralph Grishman,
Adam Meyers, Ada Brunstein, Lisa Ferro, and Beth
Sundheim, 2003. ACE-2 Version 1.0. Linguistic Data
Consortium, Philadelphia.
Vincent Ng and Claire Cardie. 2002. Improving Ma-
chine Learning Approaches to Coreference Resolu-
tion. In Proceedings of the 40th Annual Meeting of the
Association for Computational Linguistics, ACL ’02,
pages 104–111, Philadelphia, Pennsylvania.
Martha S. Palmer, Deborah A. Dahl, Rebecca J. Schiff-
man, Lynette Hirschman, Marcia Linebarger, and John
Dowding. 1986. Recovering Implicit Information. In
Proceedings of the 24th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 10–19,
New York, New York, USA.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The Proposition Bank: An Annotated Cor-
pus of Semantic Roles. Computational Linguistics,
31(1):71–106, March.
Altaf Rahman and Vincent Ng. 2011. Narrowing the
modeling gap: A cluster-ranking approach to corefer-
ence resolution. Journal of Artificial Intelligence Re-
search, 40:469–521.
Nils Reiter. 2010. FrameNet API. http://www.cl.
uni-heidelberg.de/trac/FrameNetAPI.
Philip Resnik. 1996. Selectional Constraints: an
Information-theoretic Model and its Computational
Realization. Cognition, 61(1-2):127–159, November.
Josef Ruppenhofer, Caroline Sporleder, Roser Morante,
Collin Baker, and Martha Palmer. 2009. SemEval-
2010 Task 10: Linking Events and Their Participants
in Discourse. In Proceedings of the NAACL-HLT 2009
Workshop on Semantic Evaluations: Recent Achieve-
ments and Future Directions (SEW-09), pages 106–
111, Boulder, Colorado, June.
Josef Ruppenhofer, Caroline Sporleder, Roser Morante,
Collin Baker, and Martha Palmer. 2010. SemEval-
2010 Task 10: Linking Events and Their Participants
in Discourse. In Proceedings of the 5th International
Workshop on Semantic Evaluations, pages 45–50, Up-
psala, Sweden, July.
Josef Ruppenhofer, Philip Gorinski, and Caroline
Sporleder. 2011. In Search of Missing Arguments:
A Linguistic Approach. In Proceedings of the Inter-
national Conference Recent Advances in Natural Lan-
guage Processing, pages 331–338, Hissar, Bulgaria,
September.
Carina Silberer. 2011. Linking Implicit Semantic Roles
in Discourese Using Coreference Resolution Methods.
Master’s thesis, Department of Computational Lin-
guistics, Heidelberg University, Germany.
Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong
Lim. 2001. A Machine Learning Approach to Coref-
erence Resolution of Noun Phrases. Computational
Linguistics, 27:521–544, December.
Joel R. Tetreault. 2002. Implicit Role Reference. In
International Symposium on Reference Resolution for
Natural Language Processing, pages 109–115, Ali-
cante, Spain.
Sara Tonelli and Rodolfo Delmonte. 2010. VENSES++:
Adapting a Deep Semantic Processing System to the
Identification of Null Instantiations. In Proceedings of
the 5th International Workshop on Semantic Evalua-
tions, pages 296–299, Uppsala, Sweden, July.
Sara Tonelli and Rodolfo Delmonte. 2011. Desperately
Seeking Implicit Arguments in Text. In Proceedings of
the ACL 2011 Workshop on Relational Models of Se-
mantics, pages 54–62, Portland, Oregon, USA, June.
G. Whittemore, M. Macpherson, and G. Carlson. 1991.
Event-building through role filling and anaphora reso-
lution. In Proceedings of the 29th Annual Meeting on
Association for Computational Linguistics, pages 17–
24, Morristown, NJ, USA.
Ian H. Witten and Eibe Frank. 2000. Data Mining: Prac-
tical Machine Learning Tools and Techniques with
Java Implementations. Morgan Kaufmann, San Fran-
cisco, CA, USA.
Xiaofeng Yang, Jian Su, Guodong Zhou, and Chew Lim
Tan. 2004. An NP-cluster Based Approach to Coref-
erence Resolution. In Proceedings of the 20th In-
ternational Conference on Computational Linguistics,
COLING ’04, pages 226–232, Geneva, Switzerland.
Xiaofeng Yang, Jian Su, Jun Lang, Chew Lim Tan, Ting
Liu, and Sheng Li. 2008. An Entity-Mention Model
for Coreference Resolution with Inductive Logic Pro-
gramming. In Proceedings of the 46th Annual Meet-
ing of the Association for Computational Linguistics:
Human Language Technologies, ACL ’08:HLT, pages
843–851, Columbus, Ohio, June.
</reference>
<page confidence="0.997801">
10
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.239006">
<title confidence="0.91826">Casting Implicit Role Linking as an Anaphora Resolution Task</title>
<affiliation confidence="0.901251333333333">School of University of Edinburgh,</affiliation>
<email confidence="0.997451">c.silberer@ed.ac.uk</email>
<author confidence="0.809511">Anette</author>
<affiliation confidence="0.998654">Department of Computational</affiliation>
<address confidence="0.69285">Heidelberg Heidelberg,</address>
<email confidence="0.999663">frank@cl.uni-heidelberg.de</email>
<abstract confidence="0.998708384615385">Linking implicit semantic roles is a challenging problem in discourse processing. Unlike prior work inspired by SRL, we cast this problem as an anaphora resolution task and embed it in an entity-based coreference resolution (CR) architecture. Our experiments clearly show that CR-oriented features yield strongest performance exceeding a strong baseline. We address the problem of data sparsity by applying heuristic labeling techniques, guided by the anaphoric nature of the phenomenon. We achieve performance beyond state-of-the art.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Aljoscha Burchardt</author>
<author>Anette Frank</author>
<author>Manfred Pinkal</author>
</authors>
<title>Building Text Meaning Representations from Contextually Related Frames – A Case Study.</title>
<date>2005</date>
<booktitle>In Proceedings of the 6th International Workshop on Computational Semantics, IWCS-6,</booktitle>
<pages>66--77</pages>
<location>Tilburg, The Netherlands.</location>
<contexts>
<context position="3692" citStr="Burchardt et al. (2005)" startWordPosition="566" endWordPosition="569"> Whittemore et al. (1991) analyzed the resolution of unexpressed event roles as a special case of CR. A formalization in DRT was fully worked out, but automation was not addressed. Later studies emphasize the role of implicit role reference in a frame-semantic discourse analysis. Fillmore and Baker (2001) provide an analysis of First Joint Conference on Lexical and Computational Semantics (*SEM), pages 1–10, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics a newspaper text that indicates the importance of frames and roles in establishing discourse coherence. Burchardt et al. (2005) offer a formalization of the involved factors: the interplay of frames and frame relations with factors of contextual contiguity. The work includes no automation, but suggests a corpus-based approach using antecedent-role coreference patterns collected from corpora. Tetreault (2002), finally, offers an automated analysis for resolving implicit role reference. The smallscale study is embedded in a rule-based CR setup. SemEval 2010 Task 10: Linking Roles. Triggered by the SemEval 2010 competition (Ruppenhofer et al., 2010), research on resolving implicit role reference has gained momentum again</context>
<context position="7787" citStr="Burchardt et al. (2005)" startWordPosition="1191" endWordPosition="1194">roach incorporates some aspects relating to CR that go beyond the SRLoriented SemEval systems: A candidate representation includes information about all the candidates’ coreferent mentions (determined by automatic CR), in particular their semantic roles (provided by gold annotations) and WordNet synsets. Patterns of semantic associations between filler candidates and implicit roles are learned for all mentions contained in the candidate’s entity chain. They achieve an Fscore of 42.3, against a baseline of 26.5. Gerber (2011) presents an extended model that incorporates strategies suggested in Burchardt et al. (2005): using frame relations as well as coreference patterns acquired from large corpora. This model achieves an F-score of 50.3 (baseline: 28.9). 3 Casting Implicit Role Linking as an Anaphora Resolution Task 3.1 Implicit role = anaphora resolution Recent models for role binding mainly draw on techniques from SRL, enriched with concepts from CR. 2 In this paper, we explicitly formulate implicit role linking as an anaphora resolution task. This is in line with the predominant conception in early work, and also highlights the close relationship with zero anaphora (Kameyama, 1985). Computational trea</context>
</contexts>
<marker>Burchardt, Frank, Pinkal, 2005</marker>
<rawString>Aljoscha Burchardt, Anette Frank, and Manfred Pinkal. 2005. Building Text Meaning Representations from Contextually Related Frames – A Case Study. In Proceedings of the 6th International Workshop on Computational Semantics, IWCS-6, pages 66–77, Tilburg, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jie Cai</author>
<author>Michael Strube</author>
</authors>
<title>End-to-end coreference resolution via hypergraph partitioning.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>143--151</pages>
<location>Beijing, China.</location>
<contexts>
<context position="9648" citStr="Cai and Strube (2010)" startWordPosition="1482" endWordPosition="1485">ssical SRL vs. CR features to clarify the nature of this special phenomenon. iii. We automatically acquire heuristically labeled data to address the sparse data problem. i. An entity-mention model for anaphoric role resolution. In our model implicit roles that are discourse-bound (i.e. classified as DNI) are treated as anaphoric, similar to zero anaphora: the implicit role will be bound to a discourse antecedent. In line with recent research in CR, we adopt an entity-mention model, where an entity is represented by all mentions pertaining to a coreference chain (see i.a. Rahman and Ng (2011), Cai and Strube (2010)). Our model is based on binary classifier decisions that take as input the anaphoric role and an entity candidate from the preceding discourse. The final classification of a role linking to an entity is obtained by discriminative ranking of the binary classifiers’ probability estimates. Details on the system architecture are given in Section 3.2. ii. SRL vs. CR: Analysis of feature sets. The linking of implicit semantic roles represents an interesting mixture of SRL and CR that displays exceptional characteristics of both types of phenomena. In contrast to classical SRL, the relation between </context>
</contexts>
<marker>Cai, Strube, 2010</marker>
<rawString>Jie Cai and Michael Strube. 2010. End-to-end coreference resolution via hypergraph partitioning. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 143–151, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jie Cai</author>
<author>Eva M´ujdricza-Maydt</author>
<author>Michael Strube</author>
</authors>
<title>Unrestricted coreference resolution via global hypergraph partitioning.</title>
<date>2011</date>
<booktitle>In Proceedings of the Shared Task of 15th Conference on Computational Natural Language Learning,</booktitle>
<pages>56--60</pages>
<location>Portland, Oregon.</location>
<marker>Cai, M´ujdricza-Maydt, Strube, 2011</marker>
<rawString>Jie Cai, Eva M´ujdricza-Maydt, and Michael Strube. 2011. Unrestricted coreference resolution via global hypergraph partitioning. In Proceedings of the Shared Task of 15th Conference on Computational Natural Language Learning, pages 56–60, Portland, Oregon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: a Library for Support Vector Machines. Software available at http://www.csie.ntu.edu.</title>
<date>2001</date>
<tech>tw/-cjlin/libsvm.</tech>
<contexts>
<context position="24942" citStr="Chang and Lin, 2001" startWordPosition="4008" endWordPosition="4011">ormation in the test data. Exp2: Full NI-only. For benchmarking on the SemEval task, we perform the complete NI-only task. Here, the test data is only enriched w/ SRL labeling. Each frame f in the test corpus is processed, involving the following steps: (i) Recognition of NIs is performed by consulting the FN database7 and determining the FN core roles that are unfilled. From this NI set, roles that are conceptually redundant or competing with f’s overt roles are rejected as they don’t need to or must not be linked, respectively. (ii) For predicting the interpretation of an NI, we use LibSVM (Chang and Lin, 2001) as classifier which further assigns each NI a probability estimate of the NI being definite. We use a small set of features: the FN semantic type of the NI and a boolean feature indicating whether the target is in passive voice and the agent (object) not realized. Further, we use a statistical feature which gives the relative 7We used the FrameNetAPI by Reiter (2010). 6 model add. entity frame DNI Linking (%) data set anno. P R F1 M0 - AllChains gold 25.6 25.1 25.3 M1 ON2-10 Chains+Win proj 30.8 25.1 27.7 M1, ON2-24 AllChains proj 35.6 20.1 25.7 M1,, ON2-24 SentWin proj 23.3 22.4 22.8 M2 MUC </context>
</contexts>
<marker>Chang, Lin, 2001</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin, 2001. LIBSVM: a Library for Support Vector Machines. Software available at http://www.csie.ntu.edu. tw/-cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Desai Chen</author>
<author>Nathan Schneider</author>
<author>Dipanjan Das</author>
<author>Noah A Smith</author>
</authors>
<title>SEMAFOR: Frame Argument Resolution with Log-Linear Models.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<pages>264--267</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="4924" citStr="Chen et al. (2010)" startWordPosition="752" endWordPosition="755">here both semantic role labeling (SRL) and coreference resolution have seen tremendous progress. However, the systems that participated in the NIonly task on implicit role resolution achieved moderate success in the initial subtasks: (i) recognition of implicit roles and (ii) classification as discourse-bound vs. existential interpretation (DNI vs. INI). Yet, (iii) identification of role antecedents was bluntly unsuccessful, with around 1% F-score. Ruppenhofer et al. clearly relate the task to coreference resolution. The participating systems, though, framed the task as a special case of SRL. Chen et al. (2010) participated with their SRL system SEMAFOR (Das et al., 2010). They cast the task as one of extended SRL, by admitting constituents from a larger context. To overcome the lack and sparsity of syntactic path features, they include lexical association and similarity scores for semantic roles and role fillers; classical SRL order and distance features are adapted to larger distances. VENSES++ by Tonelli and Delmonte (2010) is a semantic processing system that includes lexicosemantic processing, anaphora resolution and deep semantic resolution components. Anaphora resolution is performed in a rul</context>
<context position="6342" citStr="Chen et al. (2010)" startWordPosition="967" endWordPosition="970">patible arguments, as well as semantic relatedness scores between potential fillers of (overt and implicit) semantic roles. More recently Tonelli and Delmonte (2011) recur to a leaner approach for role binding, estimating a relevance score for potential antecedents from role fillers observed in training. They report an F-score of 8 points for role binding on SemEval data. However, being strongly lexicalized, their trained model seems heavily dependent on the training data. Ruppenhofer et al. (2011) use semantic types for identifying DNI role antecedents, reporting an error reduction of 14% on Chen et al. (2010)’s results. The poor performance results in the SemEval task clearly indicate the difficulty of resolving implicit role reference. A major factor seems to relate to data sparsity: the training set covers only 245 DNI annotations linked to an antecedent. Linking implicit arguments of nominals. Gerber and Chai (2010) (G&amp;C henceforth) investigate a closely related task of argument binding, tied to the linking of implicit arguments for nominal predicates using the PropBank role labeling scheme. In contrast to the SemEval task, which focuses on a verbs and nouns, their system is only applied to nou</context>
</contexts>
<marker>Chen, Schneider, Das, Smith, 2010</marker>
<rawString>Desai Chen, Nathan Schneider, Dipanjan Das, and Noah A. Smith. 2010. SEMAFOR: Frame Argument Resolution with Log-Linear Models. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 264–267, Uppsala, Sweden, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Chinchor</author>
<author>Beth Sundheim</author>
</authors>
<date>2003</date>
<booktitle>Message Understanding Conference (MUC) 6. Linguistic Data Consortium,</booktitle>
<location>Philadelphia.</location>
<contexts>
<context position="16851" citStr="Chinchor and Sundheim, 2003" startWordPosition="2661" endWordPosition="2664">n stories by A. C. Doyle, one story as training data and another two chapters as test set, enriched with coreference and FrameNet-style frame annotations. Information about the training section is found in Table 1. The test data comprise 710 NIs (349 DNIs, 361 INIs), of which 259 DNIs are linked. 4.2 Heuristic data acquisition Since the training data has a critically small amount of linked DNIs, we heuristically labeled training data on the basis of data sets with manually annotated coreference information: OntoNotes 3.0 (Hovy et al., 2006), as well as ACE-2 (Mitchell et al., 2003) and MUC-6 (Chinchor and Sundheim, 2003). OntoNotes 3.0 was merged with gold SRL annotations from the CoNLL-2005 shared task. By means of SemLink-1.1 (Loper et al., 2007) and a mapping included in the SemEval data, these PropBank (PB, Palmer et al. (2005)) annotations were 1We additionally impose several restrictions, e.g., a valid candidate must not already fill another role of the active frame. 4 #ent avg avg #frames #frame#DNI #DNI #ent/doc size types types 141 141 9 1,370 317 245 155 7899 23 3 12,770 258 2,220 270 3564 11 4 58,204 757 4,265 578 1841 15 3 20,140 654 997 310 corpus coref semantic roles ONotes manual manual PB CoNL</context>
</contexts>
<marker>Chinchor, Sundheim, 2003</marker>
<rawString>Nancy Chinchor and Beth Sundheim, 2003. Message Understanding Conference (MUC) 6. Linguistic Data Consortium, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory F Cooper</author>
<author>Edward Herskovits</author>
</authors>
<title>A Bayesian Method for the Induction of Probabilistic Networks from Data.</title>
<date>1992</date>
<booktitle>Machine Learning,</booktitle>
<volume>9</volume>
<issue>4</issue>
<pages>347</pages>
<contexts>
<context position="23702" citStr="Cooper and Herskovits, 1992" startWordPosition="3808" endWordPosition="3811"> defined are WordNet lexicographer’s files (supersenses). The selectional association values A(dni, ss) of the DNI’s selectional preferences are retrieved for the supersense ss of each candidate antecedent’s head. As for Feat. 1, we define a candidate’s feature value by its rank in the ordered list of these As. 4.5 Experiments Evaluation measures. We adopt the precision (P), recall (R) and Fi measures in Ruppenhofer et al. (2010). A true positive is a DNI which has been linked to the correct entity as given by the gold data. Classifiers and feature selection. For DNI linking, we use BayesNet (Cooper and Herskovits, 1992) as classifier, implemented in Weka (Witten and Frank, 2000).6 For each parameter combination, we perform feature selection by means of leave-oneout 10-fold cross-validation on the SemEval training data with successively removing/determining the 6We experimented with different learners and selected the algorithm that performed best for the different subtasks. best features. The resulting models Mi are then evaluated on the SemEval test data in different setups: Exp1: Linking DNIs. Exp1 evaluates our models on the DNI linking task proper (NI-only step (iii)). This setting uses the gold corefere</context>
</contexts>
<marker>Cooper, Herskovits, 1992</marker>
<rawString>Gregory F. Cooper and Edward Herskovits. 1992. A Bayesian Method for the Induction of Probabilistic Networks from Data. Machine Learning, 9(4):309– 347.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Noah A Smith</author>
</authors>
<title>Semisupervised frame-semantic parsing for unknown predicates.</title>
<date>2011</date>
<pages>1435--1444</pages>
<editor>In Dekang Lin, Yuji Matsumoto, and Rada Mihalcea, editors, ACL,</editor>
<publisher>The Association for Computer Linguistics.</publisher>
<contexts>
<context position="17717" citStr="Das and Smith, 2011" startWordPosition="2810" endWordPosition="2813">ally impose several restrictions, e.g., a valid candidate must not already fill another role of the active frame. 4 #ent avg avg #frames #frame#DNI #DNI #ent/doc size types types 141 141 9 1,370 317 245 155 7899 23 3 12,770 258 2,220 270 3564 11 4 58,204 757 4,265 578 1841 15 3 20,140 654 997 310 corpus coref semantic roles ONotes manual manual PB CoNLL05, ported to FN ACE-2 manual automatic FN (Semafor) MUC-6 manual automatic FN (Semafor) Table 1: SemEval vs. heuristically acquired data mapped to their FrameNet (FN) counterparts, if existent. For the ACE-2 and MUC-6 corpora, we used Semafor (Das and Smith, 2011) for automatic annotation with FN semantic roles. From these data sets we acquired heuristically annotated instances of role linking using the strategy explained in 3.1. Table 1 summarizes the resulting training data. The heuristically labeled data extends the manually labeled DNI instances by an order of magnitude. 4.3 Model parameters Entity sets Edni. For definition of the set of candidate entities to consider for DNI linking, Edni, we determined different parameter settings with restrictions on the types, distances and prominence of candidate antecedents. For instance, unlike in noun phras</context>
</contexts>
<marker>Das, Smith, 2011</marker>
<rawString>Dipanjan Das and Noah A. Smith. 2011. Semisupervised frame-semantic parsing for unknown predicates. In Dekang Lin, Yuji Matsumoto, and Rada Mihalcea, editors, ACL, pages 1435–1444. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Nathan Schneider</author>
<author>Desai Chen</author>
<author>Noah A Smith</author>
</authors>
<title>Probabilistic Frame-Semantic Parsing. In Human Language Technologies: The</title>
<date>2010</date>
<booktitle>Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>948--956</pages>
<location>Los Angeles, California,</location>
<contexts>
<context position="4986" citStr="Das et al., 2010" startWordPosition="763" endWordPosition="766">on have seen tremendous progress. However, the systems that participated in the NIonly task on implicit role resolution achieved moderate success in the initial subtasks: (i) recognition of implicit roles and (ii) classification as discourse-bound vs. existential interpretation (DNI vs. INI). Yet, (iii) identification of role antecedents was bluntly unsuccessful, with around 1% F-score. Ruppenhofer et al. clearly relate the task to coreference resolution. The participating systems, though, framed the task as a special case of SRL. Chen et al. (2010) participated with their SRL system SEMAFOR (Das et al., 2010). They cast the task as one of extended SRL, by admitting constituents from a larger context. To overcome the lack and sparsity of syntactic path features, they include lexical association and similarity scores for semantic roles and role fillers; classical SRL order and distance features are adapted to larger distances. VENSES++ by Tonelli and Delmonte (2010) is a semantic processing system that includes lexicosemantic processing, anaphora resolution and deep semantic resolution components. Anaphora resolution is performed in a rule-based manner; pronominals are replaced with their antecedent</context>
</contexts>
<marker>Das, Schneider, Chen, Smith, 2010</marker>
<rawString>Dipanjan Das, Nathan Schneider, Desai Chen, and Noah A. Smith. 2010. Probabilistic Frame-Semantic Parsing. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 948–956, Los Angeles, California, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mateusz Dolata</author>
</authors>
<title>Extending the Entity-Grid Model for the Processing of Implicit Roles</title>
<date>2010</date>
<booktitle>in Discourse. Bachelor’s thesis, Department of Computational Linguistics,</booktitle>
<location>Heidelberg University, Germany.</location>
<contexts>
<context position="21209" citStr="Dolata (2010)" startWordPosition="3395" endWordPosition="3396">the nb. of entities E in w. Prominence of e (Eq. 1) is set to the difference between its size in w and the average prominence score.5 The final feature value records the relative rank of e’s prominence score compared to the scores of the other candidates. prom(e, w) = #mentions(e, w) − avg prom(w) (1) avg prom(w) = EICE #mentions(e, w) (2) JEJ 2The phrase type must be NPB, S, VP, SBAR, or SG. 3_ marks features that are similar to G&amp;C features. Note that their only CR features are distance features. 4We set w = 2 based on experiments on the training data. 5This prominence score was proposed by Dolata (2010) within an entity grid approach to role linking. SemEval ONotes ACE-2 MUC-6 5 nr feature type G&amp;C 1 prominence prominence score of the entity in the current discourse position CR - 2 pos.dist mention PoS or phrase type of the most recent explicit mention (CR) - concatenated with sentence distance to the target 3 dist mentions minimum distance between DNI and entity in mentions CR - 4 dist sentences minimum distance between DNI and entity in sentences CR + 5 vnroles dni.entity the counterparts of the DNI in VerbNet (VN, Kipper et al. (2000)) mixed + concatenated with the VN roles the entity alr</context>
</contexts>
<marker>Dolata, 2010</marker>
<rawString>Mateusz Dolata. 2010. Extending the Entity-Grid Model for the Processing of Implicit Roles in Discourse. Bachelor’s thesis, Department of Computational Linguistics, Heidelberg University, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
</authors>
<title>A Simple, Similarity-based Model for Selectional Preferences.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, ACL ’07,</booktitle>
<pages>216--223</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="22889" citStr="Erk (2007)" startWordPosition="3675" endWordPosition="3676">ion (target) grammatical function of the target SRL - 11 wnss ent.st dni pointwise mutual information between the entity’s WN supersense ss and mixed - the DNI’s FN semantic type st: pmi(ss, st) = lo92P(ss|st)/P(ss) 12 nbRoles dni.entity like feature 5, but with NomBank arguments 0 and 1 mixed � 13 frame.dni frame name concatenated with the DNI SRL - Table 3: Best features used for training. Feat. 11 was computed on the FN dataset and the SemEval training data. Feat. 9: SelPrefs. We compute selectional preferences following the information-theoretic approach of Resnik (1993, 1996). Similar to Erk (2007), we used an adapted version which we computed for semantic roles by means of the FN database rather than for verb argument positions. The WordNet classes over which the preferences are defined are WordNet lexicographer’s files (supersenses). The selectional association values A(dni, ss) of the DNI’s selectional preferences are retrieved for the supersense ss of each candidate antecedent’s head. As for Feat. 1, we define a candidate’s feature value by its rank in the ordered list of these As. 4.5 Experiments Evaluation measures. We adopt the precision (P), recall (R) and Fi measures in Ruppenh</context>
</contexts>
<marker>Erk, 2007</marker>
<rawString>Katrin Erk. 2007. A Simple, Similarity-based Model for Selectional Preferences. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, ACL ’07, pages 216–223, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
<author>Collin F Baker</author>
</authors>
<title>Frame Semantics for Text Understanding.</title>
<date>2001</date>
<booktitle>In Proceedings of the NAACL 2001 Workshop on WordNet and Other Lexical Resources,</booktitle>
<location>Pittsburgh,</location>
<contexts>
<context position="3375" citStr="Fillmore and Baker (2001)" startWordPosition="521" endWordPosition="524">studies. The phenomenon of implicit role reference is not new. It has been studied in a number of early approaches. Palmer et al. (1986) treated unfilled semantic roles as special cases of anaphora and coreference resolution (CR). Resolution was guided by domain knowledge encoded in a knowledgebased system. Similarly, Whittemore et al. (1991) analyzed the resolution of unexpressed event roles as a special case of CR. A formalization in DRT was fully worked out, but automation was not addressed. Later studies emphasize the role of implicit role reference in a frame-semantic discourse analysis. Fillmore and Baker (2001) provide an analysis of First Joint Conference on Lexical and Computational Semantics (*SEM), pages 1–10, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics a newspaper text that indicates the importance of frames and roles in establishing discourse coherence. Burchardt et al. (2005) offer a formalization of the involved factors: the interplay of frames and frame relations with factors of contextual contiguity. The work includes no automation, but suggests a corpus-based approach using antecedent-role coreference patterns collected from corpora. Tetreault (2002</context>
</contexts>
<marker>Fillmore, Baker, 2001</marker>
<rawString>Charles J. Fillmore and Collin F. Baker. 2001. Frame Semantics for Text Understanding. In Proceedings of the NAACL 2001 Workshop on WordNet and Other Lexical Resources, Pittsburgh, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
<author>Christopher R Johnson</author>
<author>Miriam R L Petruck</author>
</authors>
<title>Background to Framenet.</title>
<date>2003</date>
<journal>International Journal of Lexicography,</journal>
<volume>16</volume>
<issue>3</issue>
<contexts>
<context position="2519" citStr="Fillmore et al., 2003" startWordPosition="386" endWordPosition="390">icit roles, one for the experiencer, the other for the object of jealousy involved. These roles can be bound to Watson and the speaker (I) in the non-local preceding context. (1) Watson won’t allow that I know anything of art but that is mere jealousy because our views upon the subject differ. (2) IRe,,,d,, was sitting reading in the chairPl,,,,. In contrast to implicit roles that can be discoursebound to an antecedent as in (1), roles can be interpreted existentially, as in (2), with an unfilled TEXT role of the READING frame that cannot be anchored in prior discourse. The FrameNet paradigm (Fillmore et al., 2003) that was used for annotation in the SemEval task classifies these interpretation differences as definite (DNI) vs. indefinite (INI) null instantiations (NI) of roles, respectively. 2 Implicit Role Reference: A Short History Early studies. The phenomenon of implicit role reference is not new. It has been studied in a number of early approaches. Palmer et al. (1986) treated unfilled semantic roles as special cases of anaphora and coreference resolution (CR). Resolution was guided by domain knowledge encoded in a knowledgebased system. Similarly, Whittemore et al. (1991) analyzed the resolution </context>
</contexts>
<marker>Fillmore, Johnson, Petruck, 2003</marker>
<rawString>Charles J. Fillmore, Christopher R. Johnson, and Miriam R. L. Petruck. 2003. Background to Framenet. International Journal of Lexicography, 16(3):235–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Garrod</author>
<author>Melody Terras</author>
</authors>
<title>The Contribution of Lexical and Situational Knowledge to Resolving Discourse Roles: Bonding and Resolution.</title>
<date>2000</date>
<journal>Journal of Memory and Language,</journal>
<volume>42</volume>
<issue>4</issue>
<contexts>
<context position="8684" citStr="Garrod and Terras (2000)" startWordPosition="1332" endWordPosition="1335">ng mainly draw on techniques from SRL, enriched with concepts from CR. 2 In this paper, we explicitly formulate implicit role linking as an anaphora resolution task. This is in line with the predominant conception in early work, and also highlights the close relationship with zero anaphora (Kameyama, 1985). Computational treatments of zero anaphora (e.g., Imamura et al. (2009)) are in fact employing techniques well-known from SRL. Recent work by Iida and Poesio (2011), by contrast, offers an analysis of zero anaphora in a CR architecture. Further support comes from psycholinguistic studies in Garrod and Terras (2000), who establish commonalities between implicit role reference and other types of anaphora resolution. The contributions of our work are as follows: i. We cast implicit role binding as a CR task, using an entity-mention model and discriminative classification for antecedent selection. ii. We examine the effectiveness of model features for classical SRL vs. CR features to clarify the nature of this special phenomenon. iii. We automatically acquire heuristically labeled data to address the sparse data problem. i. An entity-mention model for anaphoric role resolution. In our model implicit roles t</context>
</contexts>
<marker>Garrod, Terras, 2000</marker>
<rawString>Simon Garrod and Melody Terras. 2000. The Contribution of Lexical and Situational Knowledge to Resolving Discourse Roles: Bonding and Resolution. Journal of Memory and Language, 42(4):526–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Gerber</author>
<author>Joyce Chai</author>
</authors>
<title>Beyond NomBank: A Study of Implicit Arguments for Nominal Predicates.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1583--1592</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="6658" citStr="Gerber and Chai (2010)" startWordPosition="1016" endWordPosition="1020">eport an F-score of 8 points for role binding on SemEval data. However, being strongly lexicalized, their trained model seems heavily dependent on the training data. Ruppenhofer et al. (2011) use semantic types for identifying DNI role antecedents, reporting an error reduction of 14% on Chen et al. (2010)’s results. The poor performance results in the SemEval task clearly indicate the difficulty of resolving implicit role reference. A major factor seems to relate to data sparsity: the training set covers only 245 DNI annotations linked to an antecedent. Linking implicit arguments of nominals. Gerber and Chai (2010) (G&amp;C henceforth) investigate a closely related task of argument binding, tied to the linking of implicit arguments for nominal predicates using the PropBank role labeling scheme. In contrast to the SemEval task, which focuses on a verbs and nouns, their system is only applied to nouns and is restricted to 10 predicates with substantial training set sizes (avg: 125, median: 103). G&amp;C propose a discriminative model that selects an antecedent for an implicit role from an extended context window. The approach incorporates some aspects relating to CR that go beyond the SRLoriented SemEval systems:</context>
</contexts>
<marker>Gerber, Chai, 2010</marker>
<rawString>Matthew Gerber and Joyce Chai. 2010. Beyond NomBank: A Study of Implicit Arguments for Nominal Predicates. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1583–1592, Uppsala, Sweden, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Steven Gerber</author>
</authors>
<title>Semantic Role Labeling of Implicit Arguments for Nominal Predicates.</title>
<date>2011</date>
<tech>Ph.D. thesis,</tech>
<institution>Michigan State University.</institution>
<contexts>
<context position="7694" citStr="Gerber (2011)" startWordPosition="1179" endWordPosition="1180">selects an antecedent for an implicit role from an extended context window. The approach incorporates some aspects relating to CR that go beyond the SRLoriented SemEval systems: A candidate representation includes information about all the candidates’ coreferent mentions (determined by automatic CR), in particular their semantic roles (provided by gold annotations) and WordNet synsets. Patterns of semantic associations between filler candidates and implicit roles are learned for all mentions contained in the candidate’s entity chain. They achieve an Fscore of 42.3, against a baseline of 26.5. Gerber (2011) presents an extended model that incorporates strategies suggested in Burchardt et al. (2005): using frame relations as well as coreference patterns acquired from large corpora. This model achieves an F-score of 50.3 (baseline: 28.9). 3 Casting Implicit Role Linking as an Anaphora Resolution Task 3.1 Implicit role = anaphora resolution Recent models for role binding mainly draw on techniques from SRL, enriched with concepts from CR. 2 In this paper, we explicitly formulate implicit role linking as an anaphora resolution task. This is in line with the predominant conception in early work, and a</context>
</contexts>
<marker>Gerber, 2011</marker>
<rawString>Matthew Steven Gerber. 2011. Semantic Role Labeling of Implicit Arguments for Nominal Predicates. Ph.D. thesis, Michigan State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard Hovy</author>
<author>Mitchell Marcus</author>
<author>Martha Palmer</author>
<author>Lance Ramshaw</author>
<author>Ralph Weischedel</author>
</authors>
<title>OntoNotes: The 90% Solution.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, HLT-NAACL ’06,</booktitle>
<pages>57--60</pages>
<location>New York, New York,</location>
<contexts>
<context position="16769" citStr="Hovy et al., 2006" startWordPosition="2647" endWordPosition="2650">systems of the SemEval NI-only task. The SemEval task is based on fiction stories by A. C. Doyle, one story as training data and another two chapters as test set, enriched with coreference and FrameNet-style frame annotations. Information about the training section is found in Table 1. The test data comprise 710 NIs (349 DNIs, 361 INIs), of which 259 DNIs are linked. 4.2 Heuristic data acquisition Since the training data has a critically small amount of linked DNIs, we heuristically labeled training data on the basis of data sets with manually annotated coreference information: OntoNotes 3.0 (Hovy et al., 2006), as well as ACE-2 (Mitchell et al., 2003) and MUC-6 (Chinchor and Sundheim, 2003). OntoNotes 3.0 was merged with gold SRL annotations from the CoNLL-2005 shared task. By means of SemLink-1.1 (Loper et al., 2007) and a mapping included in the SemEval data, these PropBank (PB, Palmer et al. (2005)) annotations were 1We additionally impose several restrictions, e.g., a valid candidate must not already fill another role of the active frame. 4 #ent avg avg #frames #frame#DNI #DNI #ent/doc size types types 141 141 9 1,370 317 245 155 7899 23 3 12,770 258 2,220 270 3564 11 4 58,204 757 4,265 578 184</context>
</contexts>
<marker>Hovy, Marcus, Palmer, Ramshaw, Weischedel, 2006</marker>
<rawString>Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance Ramshaw, and Ralph Weischedel. 2006. OntoNotes: The 90% Solution. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, HLT-NAACL ’06, pages 57–60, New York, New York, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryu Iida</author>
<author>Massimo Poesio</author>
</authors>
<title>A Cross-Lingual ILP Solution to Zero Anaphora Resolution.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>804--813</pages>
<location>Portland, Oregon.</location>
<contexts>
<context position="8532" citStr="Iida and Poesio (2011)" startWordPosition="1308" endWordPosition="1311"> (baseline: 28.9). 3 Casting Implicit Role Linking as an Anaphora Resolution Task 3.1 Implicit role = anaphora resolution Recent models for role binding mainly draw on techniques from SRL, enriched with concepts from CR. 2 In this paper, we explicitly formulate implicit role linking as an anaphora resolution task. This is in line with the predominant conception in early work, and also highlights the close relationship with zero anaphora (Kameyama, 1985). Computational treatments of zero anaphora (e.g., Imamura et al. (2009)) are in fact employing techniques well-known from SRL. Recent work by Iida and Poesio (2011), by contrast, offers an analysis of zero anaphora in a CR architecture. Further support comes from psycholinguistic studies in Garrod and Terras (2000), who establish commonalities between implicit role reference and other types of anaphora resolution. The contributions of our work are as follows: i. We cast implicit role binding as a CR task, using an entity-mention model and discriminative classification for antecedent selection. ii. We examine the effectiveness of model features for classical SRL vs. CR features to clarify the nature of this special phenomenon. iii. We automatically acquir</context>
</contexts>
<marker>Iida, Poesio, 2011</marker>
<rawString>Ryu Iida and Massimo Poesio. 2011. A Cross-Lingual ILP Solution to Zero Anaphora Resolution. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 804–813, Portland, Oregon.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Kenji Imamura</author>
<author>Kuniko Saito</author>
<author>Tomoko Izumi</author>
</authors>
<title>Discriminative Approach to PredicateArgument Structure Analysis with Zero-Anaphora Resolution.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL-IJCNLP ’09,</booktitle>
<pages>85--88</pages>
<location>Suntec, Singapore,</location>
<contexts>
<context position="8439" citStr="Imamura et al. (2009)" startWordPosition="1293" endWordPosition="1296"> as coreference patterns acquired from large corpora. This model achieves an F-score of 50.3 (baseline: 28.9). 3 Casting Implicit Role Linking as an Anaphora Resolution Task 3.1 Implicit role = anaphora resolution Recent models for role binding mainly draw on techniques from SRL, enriched with concepts from CR. 2 In this paper, we explicitly formulate implicit role linking as an anaphora resolution task. This is in line with the predominant conception in early work, and also highlights the close relationship with zero anaphora (Kameyama, 1985). Computational treatments of zero anaphora (e.g., Imamura et al. (2009)) are in fact employing techniques well-known from SRL. Recent work by Iida and Poesio (2011), by contrast, offers an analysis of zero anaphora in a CR architecture. Further support comes from psycholinguistic studies in Garrod and Terras (2000), who establish commonalities between implicit role reference and other types of anaphora resolution. The contributions of our work are as follows: i. We cast implicit role binding as a CR task, using an entity-mention model and discriminative classification for antecedent selection. ii. We examine the effectiveness of model features for classical SRL v</context>
</contexts>
<marker>Imamura, Saito, Izumi, 2009</marker>
<rawString>Kenji Imamura, Kuniko Saito, and Tomoko Izumi. 2009. Discriminative Approach to PredicateArgument Structure Analysis with Zero-Anaphora Resolution. In Proceedings of the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL-IJCNLP ’09, pages 85–88, Suntec, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Megumi Kameyama</author>
</authors>
<title>Zero Anaphora: The case of Japanese.</title>
<date>1985</date>
<tech>Ph.D. thesis,</tech>
<institution>Stanford University.</institution>
<contexts>
<context position="8367" citStr="Kameyama, 1985" startWordPosition="1284" endWordPosition="1285">uggested in Burchardt et al. (2005): using frame relations as well as coreference patterns acquired from large corpora. This model achieves an F-score of 50.3 (baseline: 28.9). 3 Casting Implicit Role Linking as an Anaphora Resolution Task 3.1 Implicit role = anaphora resolution Recent models for role binding mainly draw on techniques from SRL, enriched with concepts from CR. 2 In this paper, we explicitly formulate implicit role linking as an anaphora resolution task. This is in line with the predominant conception in early work, and also highlights the close relationship with zero anaphora (Kameyama, 1985). Computational treatments of zero anaphora (e.g., Imamura et al. (2009)) are in fact employing techniques well-known from SRL. Recent work by Iida and Poesio (2011), by contrast, offers an analysis of zero anaphora in a CR architecture. Further support comes from psycholinguistic studies in Garrod and Terras (2000), who establish commonalities between implicit role reference and other types of anaphora resolution. The contributions of our work are as follows: i. We cast implicit role binding as a CR task, using an entity-mention model and discriminative classification for antecedent selection</context>
</contexts>
<marker>Kameyama, 1985</marker>
<rawString>Megumi Kameyama. 1985. Zero Anaphora: The case of Japanese. Ph.D. thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Kipper</author>
<author>Hoa Trang Dang</author>
<author>Martha Palmer</author>
</authors>
<title>Class-Based Construction of a Verb Lexicon.</title>
<date>2000</date>
<booktitle>In Proceedings of the 17th National Conference on Artificial Intelligence and 12th Conference on Innovative Applications of Artificial Intelligence,</booktitle>
<pages>691--696</pages>
<publisher>AAAI Press.</publisher>
<location>Austin, Texas.</location>
<note>http://verbs.colorado.edu/-mpalmer/ projects/verbnet.html.</note>
<contexts>
<context position="21754" citStr="Kipper et al. (2000)" startWordPosition="3487" endWordPosition="3490"> on the training data. 5This prominence score was proposed by Dolata (2010) within an entity grid approach to role linking. SemEval ONotes ACE-2 MUC-6 5 nr feature type G&amp;C 1 prominence prominence score of the entity in the current discourse position CR - 2 pos.dist mention PoS or phrase type of the most recent explicit mention (CR) - concatenated with sentence distance to the target 3 dist mentions minimum distance between DNI and entity in mentions CR - 4 dist sentences minimum distance between DNI and entity in sentences CR + 5 vnroles dni.entity the counterparts of the DNI in VerbNet (VN, Kipper et al. (2000)) mixed + concatenated with the VN roles the entity already instantiates 6 roles dni.entity concatenation of the DNI with the FN roles the entity already instantiates mixed � 7 semType dni.entity semantic type of the DNI concatenated with mixed - the semantic types of the roles the entity already instantiates 8 avgDist sentences average sentence distance between the entity and the DNI CR + 9 sp supersense agreement of the selectional preferences for the DNI mixed - and the most frequent supersense of the entity 10 function (target) grammatical function of the target SRL - 11 wnss ent.st dni po</context>
</contexts>
<marker>Kipper, Dang, Palmer, 2000</marker>
<rawString>Karin Kipper, Hoa Trang Dang, and Martha Palmer. 2000. Class-Based Construction of a Verb Lexicon. In Proceedings of the 17th National Conference on Artificial Intelligence and 12th Conference on Innovative Applications of Artificial Intelligence, pages 691–696, Austin, Texas. AAAI Press. http://verbs.colorado.edu/-mpalmer/ projects/verbnet.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Loper</author>
<author>Szu ting Yi</author>
<author>Martha Palmer</author>
</authors>
<title>Combining Lexical Resources: Mapping between PropBank and VerbNet.</title>
<date>2007</date>
<booktitle>In Proceedings of the 7th International Workshop on Computational Linguistics.</booktitle>
<contexts>
<context position="16981" citStr="Loper et al., 2007" startWordPosition="2683" endWordPosition="2686">me annotations. Information about the training section is found in Table 1. The test data comprise 710 NIs (349 DNIs, 361 INIs), of which 259 DNIs are linked. 4.2 Heuristic data acquisition Since the training data has a critically small amount of linked DNIs, we heuristically labeled training data on the basis of data sets with manually annotated coreference information: OntoNotes 3.0 (Hovy et al., 2006), as well as ACE-2 (Mitchell et al., 2003) and MUC-6 (Chinchor and Sundheim, 2003). OntoNotes 3.0 was merged with gold SRL annotations from the CoNLL-2005 shared task. By means of SemLink-1.1 (Loper et al., 2007) and a mapping included in the SemEval data, these PropBank (PB, Palmer et al. (2005)) annotations were 1We additionally impose several restrictions, e.g., a valid candidate must not already fill another role of the active frame. 4 #ent avg avg #frames #frame#DNI #DNI #ent/doc size types types 141 141 9 1,370 317 245 155 7899 23 3 12,770 258 2,220 270 3564 11 4 58,204 757 4,265 578 1841 15 3 20,140 654 997 310 corpus coref semantic roles ONotes manual manual PB CoNLL05, ported to FN ACE-2 manual automatic FN (Semafor) MUC-6 manual automatic FN (Semafor) Table 1: SemEval vs. heuristically acqui</context>
</contexts>
<marker>Loper, Yi, Palmer, 2007</marker>
<rawString>Edward Loper, Szu ting Yi, and Martha Palmer. 2007. Combining Lexical Resources: Mapping between PropBank and VerbNet. In Proceedings of the 7th International Workshop on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexis Mitchell</author>
<author>Stephanie Strassel</author>
<author>Mark Przybocki</author>
<author>JK Davis</author>
<author>George Doddington</author>
<author>Ralph Grishman</author>
<author>Adam Meyers</author>
<author>Ada Brunstein</author>
<author>Lisa Ferro</author>
<author>Beth Sundheim</author>
</authors>
<date>2003</date>
<booktitle>ACE-2 Version 1.0. Linguistic Data Consortium,</booktitle>
<location>Philadelphia.</location>
<contexts>
<context position="16811" citStr="Mitchell et al., 2003" startWordPosition="2655" endWordPosition="2658">he SemEval task is based on fiction stories by A. C. Doyle, one story as training data and another two chapters as test set, enriched with coreference and FrameNet-style frame annotations. Information about the training section is found in Table 1. The test data comprise 710 NIs (349 DNIs, 361 INIs), of which 259 DNIs are linked. 4.2 Heuristic data acquisition Since the training data has a critically small amount of linked DNIs, we heuristically labeled training data on the basis of data sets with manually annotated coreference information: OntoNotes 3.0 (Hovy et al., 2006), as well as ACE-2 (Mitchell et al., 2003) and MUC-6 (Chinchor and Sundheim, 2003). OntoNotes 3.0 was merged with gold SRL annotations from the CoNLL-2005 shared task. By means of SemLink-1.1 (Loper et al., 2007) and a mapping included in the SemEval data, these PropBank (PB, Palmer et al. (2005)) annotations were 1We additionally impose several restrictions, e.g., a valid candidate must not already fill another role of the active frame. 4 #ent avg avg #frames #frame#DNI #DNI #ent/doc size types types 141 141 9 1,370 317 245 155 7899 23 3 12,770 258 2,220 270 3564 11 4 58,204 757 4,265 578 1841 15 3 20,140 654 997 310 corpus coref sem</context>
</contexts>
<marker>Mitchell, Strassel, Przybocki, Davis, Doddington, Grishman, Meyers, Brunstein, Ferro, Sundheim, 2003</marker>
<rawString>Alexis Mitchell, Stephanie Strassel, Mark Przybocki, JK Davis, George Doddington, Ralph Grishman, Adam Meyers, Ada Brunstein, Lisa Ferro, and Beth Sundheim, 2003. ACE-2 Version 1.0. Linguistic Data Consortium, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
<author>Claire Cardie</author>
</authors>
<title>Improving Machine Learning Approaches to Coreference Resolution.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, ACL ’02,</booktitle>
<pages>104--111</pages>
<location>Philadelphia, Pennsylvania.</location>
<contexts>
<context position="15640" citStr="Ng and Cardie, 2002" startWordPosition="2451" endWordPosition="2454">ion stops when the correct antecedent, i.e. a positive instance, as well as at least one negative instance have been found.1 (3) Classification. From the acquired training instances we learn a binary classifier that predicts for an instance instej,dk whether it is positive, i.e. entity ej is a correct antecedent for DNI dk. Further, the classifier provides a probability estimate for instej,dk being positive. We obtain classifications for all instances in Zk. Among the positive classified instances, we select the antecedent e with the highest estimate. That is, we apply the best-irst strategy (Ng and Cardie, 2002). In case of a tie, we choose the antecedent which is closer to the target. If no instance is classified as positive, dk is left unfilled. 4 Data and Experiments 4.1 SEMEVAL 2010 task and data set We adhere to the SemEval 2010 task by Ruppenhofer et al. (2009) as test bed for our experiments. The main focus of our work is on part (iii), the identification of antecedents for DNIs. Subtasks (i) and (ii), the recognition and interpretation of NIs will be only tackled to enable comparison to the participating systems of the SemEval NI-only task. The SemEval task is based on fiction stories by A. C</context>
</contexts>
<marker>Ng, Cardie, 2002</marker>
<rawString>Vincent Ng and Claire Cardie. 2002. Improving Machine Learning Approaches to Coreference Resolution. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, ACL ’02, pages 104–111, Philadelphia, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha S Palmer</author>
<author>Deborah A Dahl</author>
<author>Rebecca J Schiffman</author>
<author>Lynette Hirschman</author>
<author>Marcia Linebarger</author>
<author>John Dowding</author>
</authors>
<title>Recovering Implicit Information.</title>
<date>1986</date>
<booktitle>In Proceedings of the 24th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>10--19</pages>
<location>New York, New York, USA.</location>
<contexts>
<context position="2886" citStr="Palmer et al. (1986)" startWordPosition="446" endWordPosition="449">cit roles that can be discoursebound to an antecedent as in (1), roles can be interpreted existentially, as in (2), with an unfilled TEXT role of the READING frame that cannot be anchored in prior discourse. The FrameNet paradigm (Fillmore et al., 2003) that was used for annotation in the SemEval task classifies these interpretation differences as definite (DNI) vs. indefinite (INI) null instantiations (NI) of roles, respectively. 2 Implicit Role Reference: A Short History Early studies. The phenomenon of implicit role reference is not new. It has been studied in a number of early approaches. Palmer et al. (1986) treated unfilled semantic roles as special cases of anaphora and coreference resolution (CR). Resolution was guided by domain knowledge encoded in a knowledgebased system. Similarly, Whittemore et al. (1991) analyzed the resolution of unexpressed event roles as a special case of CR. A formalization in DRT was fully worked out, but automation was not addressed. Later studies emphasize the role of implicit role reference in a frame-semantic discourse analysis. Fillmore and Baker (2001) provide an analysis of First Joint Conference on Lexical and Computational Semantics (*SEM), pages 1–10, Montr</context>
</contexts>
<marker>Palmer, Dahl, Schiffman, Hirschman, Linebarger, Dowding, 1986</marker>
<rawString>Martha S. Palmer, Deborah A. Dahl, Rebecca J. Schiffman, Lynette Hirschman, Marcia Linebarger, and John Dowding. 1986. Recovering Implicit Information. In Proceedings of the 24th Annual Meeting of the Association for Computational Linguistics, pages 10–19, New York, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The Proposition Bank: An Annotated Corpus of Semantic Roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="17066" citStr="Palmer et al. (2005)" startWordPosition="2699" endWordPosition="2702"> data comprise 710 NIs (349 DNIs, 361 INIs), of which 259 DNIs are linked. 4.2 Heuristic data acquisition Since the training data has a critically small amount of linked DNIs, we heuristically labeled training data on the basis of data sets with manually annotated coreference information: OntoNotes 3.0 (Hovy et al., 2006), as well as ACE-2 (Mitchell et al., 2003) and MUC-6 (Chinchor and Sundheim, 2003). OntoNotes 3.0 was merged with gold SRL annotations from the CoNLL-2005 shared task. By means of SemLink-1.1 (Loper et al., 2007) and a mapping included in the SemEval data, these PropBank (PB, Palmer et al. (2005)) annotations were 1We additionally impose several restrictions, e.g., a valid candidate must not already fill another role of the active frame. 4 #ent avg avg #frames #frame#DNI #DNI #ent/doc size types types 141 141 9 1,370 317 245 155 7899 23 3 12,770 258 2,220 270 3564 11 4 58,204 757 4,265 578 1841 15 3 20,140 654 997 310 corpus coref semantic roles ONotes manual manual PB CoNLL05, ported to FN ACE-2 manual automatic FN (Semafor) MUC-6 manual automatic FN (Semafor) Table 1: SemEval vs. heuristically acquired data mapped to their FrameNet (FN) counterparts, if existent. For the ACE-2 and M</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The Proposition Bank: An Annotated Corpus of Semantic Roles. Computational Linguistics, 31(1):71–106, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Altaf Rahman</author>
<author>Vincent Ng</author>
</authors>
<title>Narrowing the modeling gap: A cluster-ranking approach to coreference resolution.</title>
<date>2011</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>40--469</pages>
<contexts>
<context position="9625" citStr="Rahman and Ng (2011)" startWordPosition="1478" endWordPosition="1481">model features for classical SRL vs. CR features to clarify the nature of this special phenomenon. iii. We automatically acquire heuristically labeled data to address the sparse data problem. i. An entity-mention model for anaphoric role resolution. In our model implicit roles that are discourse-bound (i.e. classified as DNI) are treated as anaphoric, similar to zero anaphora: the implicit role will be bound to a discourse antecedent. In line with recent research in CR, we adopt an entity-mention model, where an entity is represented by all mentions pertaining to a coreference chain (see i.a. Rahman and Ng (2011), Cai and Strube (2010)). Our model is based on binary classifier decisions that take as input the anaphoric role and an entity candidate from the preceding discourse. The final classification of a role linking to an entity is obtained by discriminative ranking of the binary classifiers’ probability estimates. Details on the system architecture are given in Section 3.2. ii. SRL vs. CR: Analysis of feature sets. The linking of implicit semantic roles represents an interesting mixture of SRL and CR that displays exceptional characteristics of both types of phenomena. In contrast to classical SRL</context>
<context position="11030" citStr="Rahman and Ng (2011)" startWordPosition="1709" endWordPosition="1712"> But similar to SRL we can compute a semantic class type expected by the role and determine which candidate is most appropriate to fill the semantic role. Anaphoric binding of unfilled roles also diverges from classical CR in that the anaphoric element is not overtly expressed. This excludes typical CR features that refer to overt realization, such as agreement or string overlap. Again, we can make use of a semantic characterization of role fillers to determine the role’s most appropriate antecedent entity in the discourse. This closely relates to semantic class features employed in CR (e.g., Rahman and Ng (2011)). Thus, semantic association features are important modeling aspects, but they do not contribute to clarifying the nature of the phenomenon. We will include additional properties that are considered characteristic for CR, such as the semantics of an entity (as opposed to individual mentions), or salience properties of antecedents (cf. Section 4.3). Thus, the model we propose substantially differs from prior work. We classify the features of our models as SRL vs. CR features, plus a mixture class that relates to both phenomena. We examine which type of features is most effective for resolving </context>
</contexts>
<marker>Rahman, Ng, 2011</marker>
<rawString>Altaf Rahman and Vincent Ng. 2011. Narrowing the modeling gap: A cluster-ranking approach to coreference resolution. Journal of Artificial Intelligence Research, 40:469–521.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nils Reiter</author>
</authors>
<title>FrameNet API.</title>
<date>2010</date>
<note>http://www.cl. uni-heidelberg.de/trac/FrameNetAPI.</note>
<contexts>
<context position="25312" citStr="Reiter (2010)" startWordPosition="4075" endWordPosition="4076">m this NI set, roles that are conceptually redundant or competing with f’s overt roles are rejected as they don’t need to or must not be linked, respectively. (ii) For predicting the interpretation of an NI, we use LibSVM (Chang and Lin, 2001) as classifier which further assigns each NI a probability estimate of the NI being definite. We use a small set of features: the FN semantic type of the NI and a boolean feature indicating whether the target is in passive voice and the agent (object) not realized. Further, we use a statistical feature which gives the relative 7We used the FrameNetAPI by Reiter (2010). 6 model add. entity frame DNI Linking (%) data set anno. P R F1 M0 - AllChains gold 25.6 25.1 25.3 M1 ON2-10 Chains+Win proj 30.8 25.1 27.7 M1, ON2-24 AllChains proj 35.6 20.1 25.7 M1,, ON2-24 SentWin proj 23.3 22.4 22.8 M2 MUC Chains+Win auto 26.1 24.3 25.3 M3 ACE AllChains auto 24.0 21.2 22.5 Prom – Chains+Win – 20.5 20.5 20.5 Table 4: Exp1: Best performing models for different entity and data settings. Test data contain gold CR chains. frequency of the role’s realization as DNI and INI, respectively, in the training data. (iii) DNI linking is performed for each of f’s predicted DNIs Df in</context>
</contexts>
<marker>Reiter, 2010</marker>
<rawString>Nils Reiter. 2010. FrameNet API. http://www.cl. uni-heidelberg.de/trac/FrameNetAPI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Selectional Constraints: an Information-theoretic Model and its Computational Realization.</title>
<date>1996</date>
<journal>Cognition,</journal>
<pages>61--1</pages>
<marker>Resnik, 1996</marker>
<rawString>Philip Resnik. 1996. Selectional Constraints: an Information-theoretic Model and its Computational Realization. Cognition, 61(1-2):127–159, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josef Ruppenhofer</author>
<author>Caroline Sporleder</author>
<author>Roser Morante</author>
<author>Collin Baker</author>
<author>Martha Palmer</author>
</authors>
<title>SemEval2010 Task 10: Linking Events and Their Participants in Discourse.</title>
<date>2009</date>
<booktitle>In Proceedings of the NAACL-HLT 2009 Workshop on Semantic Evaluations: Recent Achievements and Future Directions (SEW-09),</booktitle>
<pages>106--111</pages>
<location>Boulder, Colorado,</location>
<contexts>
<context position="1547" citStr="Ruppenhofer et al., 2009" startWordPosition="220" endWordPosition="223">tion of unfilled semantic roles of predicates in discourse interpretation. Such roles, while linguistically unexpressed, can often be anaphorically bound to antecedent referents in the discourse context. Capturing such implicit semantic roles and linking them to their antecedents is a challenging problem. But it bears immense potential for establishing discourse coherence and for getting closer to the aim of true NLU. Linking of implicit semantic roles in discourse has recently been introduced as a shared task in the SemEval 2010 competition Linking Events and Their Participants in Discourse (Ruppenhofer et al., 2009, 2010). The task consists in detecting unfilled semantic roles of events and determining antecedents in the discourse context that these roles * The work reported in this paper is based on a Master’s Thesis conducted at Heidelberg University (Silberer, 2011). 1 can be understood to refer to. In (1), e.g., the predicate jealousy introduces two implicit roles, one for the experiencer, the other for the object of jealousy involved. These roles can be bound to Watson and the speaker (I) in the non-local preceding context. (1) Watson won’t allow that I know anything of art but that is mere jealous</context>
<context position="15900" citStr="Ruppenhofer et al. (2009)" startWordPosition="2500" endWordPosition="2504">her it is positive, i.e. entity ej is a correct antecedent for DNI dk. Further, the classifier provides a probability estimate for instej,dk being positive. We obtain classifications for all instances in Zk. Among the positive classified instances, we select the antecedent e with the highest estimate. That is, we apply the best-irst strategy (Ng and Cardie, 2002). In case of a tie, we choose the antecedent which is closer to the target. If no instance is classified as positive, dk is left unfilled. 4 Data and Experiments 4.1 SEMEVAL 2010 task and data set We adhere to the SemEval 2010 task by Ruppenhofer et al. (2009) as test bed for our experiments. The main focus of our work is on part (iii), the identification of antecedents for DNIs. Subtasks (i) and (ii), the recognition and interpretation of NIs will be only tackled to enable comparison to the participating systems of the SemEval NI-only task. The SemEval task is based on fiction stories by A. C. Doyle, one story as training data and another two chapters as test set, enriched with coreference and FrameNet-style frame annotations. Information about the training section is found in Table 1. The test data comprise 710 NIs (349 DNIs, 361 INIs), of which </context>
</contexts>
<marker>Ruppenhofer, Sporleder, Morante, Baker, Palmer, 2009</marker>
<rawString>Josef Ruppenhofer, Caroline Sporleder, Roser Morante, Collin Baker, and Martha Palmer. 2009. SemEval2010 Task 10: Linking Events and Their Participants in Discourse. In Proceedings of the NAACL-HLT 2009 Workshop on Semantic Evaluations: Recent Achievements and Future Directions (SEW-09), pages 106– 111, Boulder, Colorado, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josef Ruppenhofer</author>
<author>Caroline Sporleder</author>
<author>Roser Morante</author>
<author>Collin Baker</author>
<author>Martha Palmer</author>
</authors>
<title>SemEval2010 Task 10: Linking Events and Their Participants in Discourse.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluations,</booktitle>
<pages>45--50</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="4219" citStr="Ruppenhofer et al., 2010" startWordPosition="645" endWordPosition="649">es the importance of frames and roles in establishing discourse coherence. Burchardt et al. (2005) offer a formalization of the involved factors: the interplay of frames and frame relations with factors of contextual contiguity. The work includes no automation, but suggests a corpus-based approach using antecedent-role coreference patterns collected from corpora. Tetreault (2002), finally, offers an automated analysis for resolving implicit role reference. The smallscale study is embedded in a rule-based CR setup. SemEval 2010 Task 10: Linking Roles. Triggered by the SemEval 2010 competition (Ruppenhofer et al., 2010), research on resolving implicit role reference has gained momentum again, in a field where both semantic role labeling (SRL) and coreference resolution have seen tremendous progress. However, the systems that participated in the NIonly task on implicit role resolution achieved moderate success in the initial subtasks: (i) recognition of implicit roles and (ii) classification as discourse-bound vs. existential interpretation (DNI vs. INI). Yet, (iii) identification of role antecedents was bluntly unsuccessful, with around 1% F-score. Ruppenhofer et al. clearly relate the task to coreference re</context>
<context position="23507" citStr="Ruppenhofer et al. (2010)" startWordPosition="3773" endWordPosition="3776"> (2007), we used an adapted version which we computed for semantic roles by means of the FN database rather than for verb argument positions. The WordNet classes over which the preferences are defined are WordNet lexicographer’s files (supersenses). The selectional association values A(dni, ss) of the DNI’s selectional preferences are retrieved for the supersense ss of each candidate antecedent’s head. As for Feat. 1, we define a candidate’s feature value by its rank in the ordered list of these As. 4.5 Experiments Evaluation measures. We adopt the precision (P), recall (R) and Fi measures in Ruppenhofer et al. (2010). A true positive is a DNI which has been linked to the correct entity as given by the gold data. Classifiers and feature selection. For DNI linking, we use BayesNet (Cooper and Herskovits, 1992) as classifier, implemented in Weka (Witten and Frank, 2000).6 For each parameter combination, we perform feature selection by means of leave-oneout 10-fold cross-validation on the SemEval training data with successively removing/determining the 6We experimented with different learners and selected the algorithm that performed best for the different subtasks. best features. The resulting models Mi are </context>
</contexts>
<marker>Ruppenhofer, Sporleder, Morante, Baker, Palmer, 2010</marker>
<rawString>Josef Ruppenhofer, Caroline Sporleder, Roser Morante, Collin Baker, and Martha Palmer. 2010. SemEval2010 Task 10: Linking Events and Their Participants in Discourse. In Proceedings of the 5th International Workshop on Semantic Evaluations, pages 45–50, Uppsala, Sweden, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josef Ruppenhofer</author>
<author>Philip Gorinski</author>
<author>Caroline Sporleder</author>
</authors>
<title>In Search of Missing Arguments: A Linguistic Approach.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Conference Recent Advances in Natural Language Processing,</booktitle>
<pages>331--338</pages>
<location>Hissar, Bulgaria,</location>
<contexts>
<context position="6227" citStr="Ruppenhofer et al. (2011)" startWordPosition="948" endWordPosition="951">mation. For role linking, the system applies diverse heuristics including search for predicateargument structures with compatible arguments, as well as semantic relatedness scores between potential fillers of (overt and implicit) semantic roles. More recently Tonelli and Delmonte (2011) recur to a leaner approach for role binding, estimating a relevance score for potential antecedents from role fillers observed in training. They report an F-score of 8 points for role binding on SemEval data. However, being strongly lexicalized, their trained model seems heavily dependent on the training data. Ruppenhofer et al. (2011) use semantic types for identifying DNI role antecedents, reporting an error reduction of 14% on Chen et al. (2010)’s results. The poor performance results in the SemEval task clearly indicate the difficulty of resolving implicit role reference. A major factor seems to relate to data sparsity: the training set covers only 245 DNI annotations linked to an antecedent. Linking implicit arguments of nominals. Gerber and Chai (2010) (G&amp;C henceforth) investigate a closely related task of argument binding, tied to the linking of implicit arguments for nominal predicates using the PropBank role labeli</context>
</contexts>
<marker>Ruppenhofer, Gorinski, Sporleder, 2011</marker>
<rawString>Josef Ruppenhofer, Philip Gorinski, and Caroline Sporleder. 2011. In Search of Missing Arguments: A Linguistic Approach. In Proceedings of the International Conference Recent Advances in Natural Language Processing, pages 331–338, Hissar, Bulgaria, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carina Silberer</author>
</authors>
<title>Linking Implicit Semantic Roles in Discourese Using Coreference Resolution Methods.</title>
<date>2011</date>
<tech>Master’s thesis,</tech>
<institution>Department of Computational Linguistics, Heidelberg University,</institution>
<contexts>
<context position="1806" citStr="Silberer, 2011" startWordPosition="264" endWordPosition="265"> antecedents is a challenging problem. But it bears immense potential for establishing discourse coherence and for getting closer to the aim of true NLU. Linking of implicit semantic roles in discourse has recently been introduced as a shared task in the SemEval 2010 competition Linking Events and Their Participants in Discourse (Ruppenhofer et al., 2009, 2010). The task consists in detecting unfilled semantic roles of events and determining antecedents in the discourse context that these roles * The work reported in this paper is based on a Master’s Thesis conducted at Heidelberg University (Silberer, 2011). 1 can be understood to refer to. In (1), e.g., the predicate jealousy introduces two implicit roles, one for the experiencer, the other for the object of jealousy involved. These roles can be bound to Watson and the speaker (I) in the non-local preceding context. (1) Watson won’t allow that I know anything of art but that is mere jealousy because our views upon the subject differ. (2) IRe,,,d,, was sitting reading in the chairPl,,,,. In contrast to implicit roles that can be discoursebound to an antecedent as in (1), roles can be interpreted existentially, as in (2), with an unfilled TEXT ro</context>
</contexts>
<marker>Silberer, 2011</marker>
<rawString>Carina Silberer. 2011. Linking Implicit Semantic Roles in Discourese Using Coreference Resolution Methods. Master’s thesis, Department of Computational Linguistics, Heidelberg University, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wee Meng Soon</author>
<author>Hwee Tou Ng</author>
<author>Daniel Chung Yong Lim</author>
</authors>
<title>A Machine Learning Approach to Coreference Resolution of Noun Phrases.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<pages>27--521</pages>
<contexts>
<context position="14568" citStr="Soon et al. (2001)" startWordPosition="2273" endWordPosition="2276">his set forms the overall set of candidates to consider for DNI linking. For each DNI dk to be linked, a subset of candidates £k C £ is chosen as candidate search space for resolving dk. We experiment with different strategies for constructing £k (cf. Section 4). (2) Instance Creation. The next step consists in the creation of (training) instances for classification including the extraction of features for all instances. An instance instej,dk consists of the active DNI dk, its frame and a candidate entity ej E £k. Instance creation follows an entity-based adaption of the standard procedure of Soon et al. (2001), which has been applied by Yang et al. (2004, 2008). Processing the discourse from left to right, for each DNI dk, instances Zk are created by processing £k from right to left according to each entity’s most recent mention, starting with the entity closest to dk. Note that, as entities instead of mentions are considered, only one instance is created for an entity which is mentioned several times in the search space. In training, the instance creation stops when the correct antecedent, i.e. a positive instance, as well as at least one negative instance have been found.1 (3) Classification. Fro</context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong Lim. 2001. A Machine Learning Approach to Coreference Resolution of Noun Phrases. Computational Linguistics, 27:521–544, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel R Tetreault</author>
</authors>
<title>Implicit Role Reference.</title>
<date>2002</date>
<booktitle>In International Symposium on Reference Resolution for Natural Language Processing,</booktitle>
<pages>109--115</pages>
<location>Alicante,</location>
<contexts>
<context position="3976" citStr="Tetreault (2002)" startWordPosition="608" endWordPosition="609">nd Baker (2001) provide an analysis of First Joint Conference on Lexical and Computational Semantics (*SEM), pages 1–10, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics a newspaper text that indicates the importance of frames and roles in establishing discourse coherence. Burchardt et al. (2005) offer a formalization of the involved factors: the interplay of frames and frame relations with factors of contextual contiguity. The work includes no automation, but suggests a corpus-based approach using antecedent-role coreference patterns collected from corpora. Tetreault (2002), finally, offers an automated analysis for resolving implicit role reference. The smallscale study is embedded in a rule-based CR setup. SemEval 2010 Task 10: Linking Roles. Triggered by the SemEval 2010 competition (Ruppenhofer et al., 2010), research on resolving implicit role reference has gained momentum again, in a field where both semantic role labeling (SRL) and coreference resolution have seen tremendous progress. However, the systems that participated in the NIonly task on implicit role resolution achieved moderate success in the initial subtasks: (i) recognition of implicit roles an</context>
</contexts>
<marker>Tetreault, 2002</marker>
<rawString>Joel R. Tetreault. 2002. Implicit Role Reference. In International Symposium on Reference Resolution for Natural Language Processing, pages 109–115, Alicante, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Tonelli</author>
<author>Rodolfo Delmonte</author>
</authors>
<title>VENSES++: Adapting a Deep Semantic Processing System to the Identification of Null Instantiations.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluations,</booktitle>
<pages>296--299</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="5348" citStr="Tonelli and Delmonte (2010)" startWordPosition="821" endWordPosition="824">unsuccessful, with around 1% F-score. Ruppenhofer et al. clearly relate the task to coreference resolution. The participating systems, though, framed the task as a special case of SRL. Chen et al. (2010) participated with their SRL system SEMAFOR (Das et al., 2010). They cast the task as one of extended SRL, by admitting constituents from a larger context. To overcome the lack and sparsity of syntactic path features, they include lexical association and similarity scores for semantic roles and role fillers; classical SRL order and distance features are adapted to larger distances. VENSES++ by Tonelli and Delmonte (2010) is a semantic processing system that includes lexicosemantic processing, anaphora resolution and deep semantic resolution components. Anaphora resolution is performed in a rule-based manner; pronominals are replaced with their antecedents’ lexical information. For role linking, the system applies diverse heuristics including search for predicateargument structures with compatible arguments, as well as semantic relatedness scores between potential fillers of (overt and implicit) semantic roles. More recently Tonelli and Delmonte (2011) recur to a leaner approach for role binding, estimating a </context>
</contexts>
<marker>Tonelli, Delmonte, 2010</marker>
<rawString>Sara Tonelli and Rodolfo Delmonte. 2010. VENSES++: Adapting a Deep Semantic Processing System to the Identification of Null Instantiations. In Proceedings of the 5th International Workshop on Semantic Evaluations, pages 296–299, Uppsala, Sweden, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Tonelli</author>
<author>Rodolfo Delmonte</author>
</authors>
<title>Desperately Seeking Implicit Arguments in Text.</title>
<date>2011</date>
<booktitle>In Proceedings of the ACL 2011 Workshop on Relational Models of Semantics,</booktitle>
<pages>54--62</pages>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="5889" citStr="Tonelli and Delmonte (2011)" startWordPosition="895" endWordPosition="898">ance features are adapted to larger distances. VENSES++ by Tonelli and Delmonte (2010) is a semantic processing system that includes lexicosemantic processing, anaphora resolution and deep semantic resolution components. Anaphora resolution is performed in a rule-based manner; pronominals are replaced with their antecedents’ lexical information. For role linking, the system applies diverse heuristics including search for predicateargument structures with compatible arguments, as well as semantic relatedness scores between potential fillers of (overt and implicit) semantic roles. More recently Tonelli and Delmonte (2011) recur to a leaner approach for role binding, estimating a relevance score for potential antecedents from role fillers observed in training. They report an F-score of 8 points for role binding on SemEval data. However, being strongly lexicalized, their trained model seems heavily dependent on the training data. Ruppenhofer et al. (2011) use semantic types for identifying DNI role antecedents, reporting an error reduction of 14% on Chen et al. (2010)’s results. The poor performance results in the SemEval task clearly indicate the difficulty of resolving implicit role reference. A major factor s</context>
<context position="30660" citStr="Tonelli and Delmonte (2011)" startWordPosition="5026" endWordPosition="5029">S++ – 8 64 5 1.21 T&amp;D – 54 75 40 13.0 6.0 8 Table 6: Exp2 results obtained for our models (lines 1-5) and comparable systems (lines 6-8). Column 5 gives the score for correctly recognized NIs. Cols. 6 and 7 report precision for correctly interpreted NIs on the basis of the correctly recognized (relative) vs. all gold NIs to be recognized (absolute). The scores in the last column (F1(crf)) were obtained with gold CR annotations. task participants10 (lines 7-8) shows that our models clearly outperform these systems – with a gain of +5.7 and +8.89 points in F1-score in DNI linking.11 Compared to Tonelli and Delmonte (2011) (T&amp;D), M1 has a higher F1-score in linking of +2.1 points. In contrast to our method, their linking approach is (admittedly) heavily lexicalized and strongly tailored to the domain of the used data. 6 Conclusion We cast the problem of linking implicit semantic roles as a special case of (zero) anaphora resolution, drawing on insights from earlier work and parallels observed with zero anaphora. Our results strongly support this analysis: (i) Feature selection clearly determines CR-related features as strongest support for DNI linking. (ii) Our models beat a strong baseline using a prominence s</context>
</contexts>
<marker>Tonelli, Delmonte, 2011</marker>
<rawString>Sara Tonelli and Rodolfo Delmonte. 2011. Desperately Seeking Implicit Arguments in Text. In Proceedings of the ACL 2011 Workshop on Relational Models of Semantics, pages 54–62, Portland, Oregon, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Whittemore</author>
<author>M Macpherson</author>
<author>G Carlson</author>
</authors>
<title>Event-building through role filling and anaphora resolution.</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>17--24</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="3094" citStr="Whittemore et al. (1991)" startWordPosition="477" endWordPosition="480">se. The FrameNet paradigm (Fillmore et al., 2003) that was used for annotation in the SemEval task classifies these interpretation differences as definite (DNI) vs. indefinite (INI) null instantiations (NI) of roles, respectively. 2 Implicit Role Reference: A Short History Early studies. The phenomenon of implicit role reference is not new. It has been studied in a number of early approaches. Palmer et al. (1986) treated unfilled semantic roles as special cases of anaphora and coreference resolution (CR). Resolution was guided by domain knowledge encoded in a knowledgebased system. Similarly, Whittemore et al. (1991) analyzed the resolution of unexpressed event roles as a special case of CR. A formalization in DRT was fully worked out, but automation was not addressed. Later studies emphasize the role of implicit role reference in a frame-semantic discourse analysis. Fillmore and Baker (2001) provide an analysis of First Joint Conference on Lexical and Computational Semantics (*SEM), pages 1–10, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics a newspaper text that indicates the importance of frames and roles in establishing discourse coherence. Burchardt et al. (2005) o</context>
</contexts>
<marker>Whittemore, Macpherson, Carlson, 1991</marker>
<rawString>G. Whittemore, M. Macpherson, and G. Carlson. 1991. Event-building through role filling and anaphora resolution. In Proceedings of the 29th Annual Meeting on Association for Computational Linguistics, pages 17– 24, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Eibe Frank</author>
</authors>
<date>2000</date>
<booktitle>Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.</booktitle>
<publisher>Morgan Kaufmann,</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="23762" citStr="Witten and Frank, 2000" startWordPosition="3817" endWordPosition="3820">ectional association values A(dni, ss) of the DNI’s selectional preferences are retrieved for the supersense ss of each candidate antecedent’s head. As for Feat. 1, we define a candidate’s feature value by its rank in the ordered list of these As. 4.5 Experiments Evaluation measures. We adopt the precision (P), recall (R) and Fi measures in Ruppenhofer et al. (2010). A true positive is a DNI which has been linked to the correct entity as given by the gold data. Classifiers and feature selection. For DNI linking, we use BayesNet (Cooper and Herskovits, 1992) as classifier, implemented in Weka (Witten and Frank, 2000).6 For each parameter combination, we perform feature selection by means of leave-oneout 10-fold cross-validation on the SemEval training data with successively removing/determining the 6We experimented with different learners and selected the algorithm that performed best for the different subtasks. best features. The resulting models Mi are then evaluated on the SemEval test data in different setups: Exp1: Linking DNIs. Exp1 evaluates our models on the DNI linking task proper (NI-only step (iii)). This setting uses the gold coreference, SRL and DNI information in the test data. Exp2: Full NI</context>
</contexts>
<marker>Witten, Frank, 2000</marker>
<rawString>Ian H. Witten and Eibe Frank. 2000. Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations. Morgan Kaufmann, San Francisco, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaofeng Yang</author>
<author>Jian Su</author>
<author>Guodong Zhou</author>
<author>Chew Lim Tan</author>
</authors>
<title>An NP-cluster Based Approach to Coreference Resolution.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics, COLING ’04,</booktitle>
<pages>226--232</pages>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="14613" citStr="Yang et al. (2004" startWordPosition="2282" endWordPosition="2285"> consider for DNI linking. For each DNI dk to be linked, a subset of candidates £k C £ is chosen as candidate search space for resolving dk. We experiment with different strategies for constructing £k (cf. Section 4). (2) Instance Creation. The next step consists in the creation of (training) instances for classification including the extraction of features for all instances. An instance instej,dk consists of the active DNI dk, its frame and a candidate entity ej E £k. Instance creation follows an entity-based adaption of the standard procedure of Soon et al. (2001), which has been applied by Yang et al. (2004, 2008). Processing the discourse from left to right, for each DNI dk, instances Zk are created by processing £k from right to left according to each entity’s most recent mention, starting with the entity closest to dk. Note that, as entities instead of mentions are considered, only one instance is created for an entity which is mentioned several times in the search space. In training, the instance creation stops when the correct antecedent, i.e. a positive instance, as well as at least one negative instance have been found.1 (3) Classification. From the acquired training instances we learn a </context>
</contexts>
<marker>Yang, Su, Zhou, Tan, 2004</marker>
<rawString>Xiaofeng Yang, Jian Su, Guodong Zhou, and Chew Lim Tan. 2004. An NP-cluster Based Approach to Coreference Resolution. In Proceedings of the 20th International Conference on Computational Linguistics, COLING ’04, pages 226–232, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaofeng Yang</author>
<author>Jian Su</author>
<author>Jun Lang</author>
<author>Chew Lim Tan</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>An Entity-Mention Model for Coreference Resolution with Inductive Logic Programming.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, ACL ’08:HLT,</booktitle>
<pages>843--851</pages>
<location>Columbus, Ohio,</location>
<marker>Yang, Su, Lang, Tan, Liu, Li, 2008</marker>
<rawString>Xiaofeng Yang, Jian Su, Jun Lang, Chew Lim Tan, Ting Liu, and Sheng Li. 2008. An Entity-Mention Model for Coreference Resolution with Inductive Logic Programming. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, ACL ’08:HLT, pages 843–851, Columbus, Ohio, June.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>