<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000027">
<title confidence="0.997658">
Morpho-syntactic Clues for Terminological Processing in Serbian
</title>
<author confidence="0.995246">
Goran Nenadić Irena Spasić Sophia Ananiadou
</author>
<affiliation confidence="0.99232">
Department of Computing Computer Science Computer Science
UMIST, UK University of Salford, UK University of Salford, UK
</affiliation>
<email confidence="0.980019">
G.Nenadic@umist.ac.uk I.Spasic@salford.ac.uk S.Ananiadou@salford.ac.uk
</email>
<sectionHeader confidence="0.993588" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99939975">
In this paper we discuss morpho-syntactic
clues that can be used to facilitate termi-
nological processing in Serbian. A
method (called SRCE) for automatic ex-
traction of multiword terms is presented.
The approach incorporates a set of ge-
neric morpho-syntactic filters for recogni-
tion of term candidates, a method for
conflation of morphological variants and
a module for foreign word recognition.
Morpho-syntactic filters describe general
term formation patterns, and are imple-
mented as generic regular expressions.
The inner structure together with the
agreements within term candidates are
used as clues to discover the boundaries
of nested terms. The results of the termi-
nological processing of a textbook corpus
in the domains of mathematics and com-
puter science are presented.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999974020833333">
An overwhelming amount of textual information
presented in newswire, scientific literature, legal
texts, etc., makes it difficult for a human to effi-
ciently localise the information of interest. In
particular, it is doubtful that anybody could proc-
ess such huge amount of information without an
automated help, especially when the information
content spans across domains. The amount of e-
documents and their fuzzy structure require
effective tools that can help users to
systematically gather and make use of the
information encoded in text documents. For these
reasons, different text and/or literature mining
techniques have been developed recently (e.g.
(Hearst et al., 2000; Grobelnik et al., 2000)) in
order to facilitate efficient discovery of knowl-
cient discovery of knowledge contained in large
scientific or legal text collections. The main goal
is to retrieve the knowledge &amp;quot;buried&amp;quot; in a text
and to present it to users in a digested form.
The discovery (and transfer) of knowledge re-
lies heavily on the identification of relevant con-
cepts, which are linguistically represented by
domain specific terms. Terms represent the most
important notions in a domain and characterise
documents semantically, and thus should be used
as a basis for sophisticated knowledge acquisi-
tion. Still, few text-mining systems incorporate
deep and dynamic terminology processing, al-
though there is an increasing amount of new
terms that represent newly created concepts in
rapidly developing fields. Existing term diction-
aries and standardised terminologies offer only a
partial solution, as they are almost never up-to-
date. Although naming conventions do exist for
some types of concepts (e.g. gene and protein
names in biomedicine), these are only guidelines
and as such do not impose restrictions to domain
experts, who frequently introduce ad-hoc terms.
Thus, the lack of clear naming conventions
makes the automatic term recognition (ATR) task
difficult even for languages that are not morpho-
logically and derivationally rich.
ATR tools have been developed for English
(Frantzi et al., 2000), French (Jacquemin, 2001),
Japanese (Nakagawa and Mori, 2000), etc. Some
methods rely purely on linguistic information,
namely morpho-syntactic features of term candi-
dates (Ananiadou, 1994). Hybrid approaches
combining linguistic patterns and statistical
measures (e.g. (Frantzi et al., 2000)) and ma-
chine-learning techniques (e.g. (Hatzivassiloglou
et al., 2001)) have been also used.
However, few studies have been done for
morphologically rich Slavic languages. For ex-
ample, Vintar (2000) presented two methods for
extraction of terminological collocations in order
to assist the translation process in Slovene. The
statistical approach was based on the mutual ex-
pectation and LocalMax measures, and involved
collocation extraction from raw text. The ex-
tracted collocations were filtered with a stop-
word list, and only collocations containing sin-
gle-word terms (devised previously by bilingual
alignment) were accepted as relevant. In another
approach, she used regular expression patterns to
extract term collocations from a morpho-
syntactically tagged corpus. However, these pat-
terns are too general, and consequently not all
extracted phrases were terminologically relevant.
In this paper we discuss automatic terminology
recognition in Serbian, in particular, the extrac-
tion of multiword terms, which are very frequent1
in certain domains (e.g. natural sciences, mathe-
matics, etc.). Since Serbian is a highly inflective
and morphologically and derivationally rich lan-
guage, morpho-syntactic clues are indispensable
in the ATR process. Our hybrid approach (called
SRCE — Serbian C-value) combines morpho-
syntactic features of term candidates and statisti-
cal analysis of their occurrences in text. In addi-
tion, since terms appear in texts in many different
forms due to their morphological and derivational
variations, the necessity of taking these variations
into account becomes particularly apparent.
Therefore, the SRCE method incorporates generic
morpho-syntactic patterns, a term normalisation
approach and a foreign word detection method.
The paper is organised as follows: in Section 2
we present an overview of the core term extrac-
tion method, called the C-value method. In Sec-
tion 3 we discuss morpho-syntactic clues, the
normalisation approach and the foreign word
recognition that are used for singling out terms in
Serbian. The experiments and evaluation are de-
scribed in Section 4.
</bodyText>
<sectionHeader confidence="0.741388" genericHeader="method">
2 Automatic Term Recognition: the core
C-value method
</sectionHeader>
<bodyText confidence="0.997753666666667">
Our approach to ATR is based on the C-value
method (Frantzi et al., 2000), which extracts
multi-word terms. It is a general term recognition
approach in the sense that it is not limited to spe-
cific classes of concepts. The approach is hybrid:
the method combines linguistic knowledge (term
</bodyText>
<footnote confidence="0.8344135">
1 In English, more than 85% of domain-specific terms are
multi-words (Nakagawa and Mori, 2000).
</footnote>
<bodyText confidence="0.999147">
formation patterns) and statistical analysis. Lin-
guistic knowledge is used to single out term can-
didates, while their statistical features are used to
measure the likelihood of term candidates being
&amp;quot;real&amp;quot; terms. The method uses a POS tagged text
as input, and outputs a list of extracted terms
ranked according to their termhoods. Termhood
is a numeric estimation of the degree to which a
given linguistic unit (a multiword compound) is
related to a domain-specific concept. However,
the values are not normalised in the sense that a
multiword, having a termhood value 10, is 10
times more likely to be a term than a term candi-
date with a termhood value 1.
In general, the C-value method enhances the
commonly used baseline method that extracts
most frequent term candidates (assuming that
termhoods directly correspond to frequencies of
occurrence) by making it sensitive to a particular
type of terms � nested terms2.
The method is implemented as a two-step pro-
cedure. In the first step, term candidates are ex-
tracted using a set of morpho-syntactic filters,
which describe general term formation patterns in
a given language. As a rule, terms form a proper
subset of noun phrases (NPs). For example, a set
of general filters for English may include the fol-
lowing patterns:3
</bodyText>
<equation confidence="0.976657333333333">
Noun+ Noun
(Adj  |Noun)+ Noun
(Adj  |Noun)+ |((Adj  |Noun)* Prep?) (Adj  |Noun)* Noun
</equation>
<bodyText confidence="0.999426545454546">
Although these patterns are regular expressions,
the filters are implemented as unification-like
LR(1) rules (Mima et al., 1995) in order to facili-
tate processing of grammatical agreements (if
any) within term candidates.
For each term candidate extracted by a filter, a
set of nested term candidates is generated (see
Table 1 for an example in English). The proce-
dure for the generation of nested term candidates
is implemented via transformation rules for each
morpho-syntactic filter that is used to extract
</bodyText>
<footnote confidence="0.9931355">
2 For example, nuclear receptor is a nested term in hormone
nuclear receptor. Similarly, baza podataka (Engl. database)
is a nested term in aiuriranje baze podataka (Engl. update of
database).
3 Noun, Adj and Prep denote POS tags that correspond to
nouns, adjectives and prepositions respectively. These filters
were used for ATR from newswire corpora and in biomedi-
cine (Frantzi et al., 2000; Nenadić et al., 2002).
</footnote>
<bodyText confidence="0.818752333333333">
term candidates. The main indicator that a nested
term candidate might be a real term is that it also
appears on its own in the corpus.
</bodyText>
<table confidence="0.999298666666667">
Term candidate: Term
steroid hormone receptor factor
+
Nested term candidates:
steroid hormone receptor +
hormone receptor factor -
steroid hormone +
hormone receptor +
receptor factor -
</table>
<tableCaption confidence="0.999879">
Table 1: Nested term candidates
</tableCaption>
<bodyText confidence="0.999915125">
In the second step, the term candidates are as-
signed termhoods (referred to as C-values) ac-
cording to a statistical measure. The measure
amalgamates four numerical corpus-based char-
acteristic of a candidate term, namely the fre-
quency of occurrence, the frequency of occurring
as nested within other candidate terms, the num-
ber of candidate terms inside which the given
candidate term is nested, and the number of
words contained in the candidate term. Formally,
where a denotes a term candidate, f(a) corre-
sponds to its frequency, |a |denotes the number of
words in a, and Ta is a set of terms that contain
term a as a nested term. Term candidates are
ranked according to their C-values, and terms
whose C-values are higher than a chosen thresh-
old are presented as terms.
Evaluation of the C-value method for English
has shown that using additional statistical infor-
mation (frequency of &amp;quot;nestedness&amp;quot;) improves the
precision with slight loss on recall (Frantzi et al.,
2000). Also, systematic term normalisation may
further improve precision and recall of the
method (Nenadić et al., 2002).
</bodyText>
<sectionHeader confidence="0.793526" genericHeader="method">
3 Morpho-syntactic clues for extraction
</sectionHeader>
<subsectionHeader confidence="0.427826">
of terms in Serbian
</subsectionHeader>
<bodyText confidence="0.9999822">
In order to adjust the core C-value method for
Serbian, we have defined an appropriate set of
morpho-syntactic filters and rules for inflectional
normalisation of term candidates, and, addition-
ally, a module for foreign word recognition.
</bodyText>
<subsectionHeader confidence="0.996696">
3.1 Term formation patterns
</subsectionHeader>
<bodyText confidence="0.998374">
As a rule, the vast majority of multiword terms in
Serbian match the following general formation
pattern:4
</bodyText>
<listItem confidence="0.840302">
(1) (Adj  |ProAdj  |Num  |Noun )+ Noun
</listItem>
<bodyText confidence="0.913333790697675">
which has been used for recognition of NPs in
Serbian (Nenadić and Vitas, 1998a). Of course,
not all NPs that follow this pattern are terms.5
Moreover, when applied to an initially POS
tagged text6, this pattern may be too general even
for description of NPs, as not all word sequences
in a text that match this pattern are valid NPs. For
example, in a sequence koji se naziva relacioni
model (Engl. which is called the relational
model), a word naziva can be initially tagged ei-
ther as a noun naziv (Engl. name) or a verb na-
zivati (Engl. call), although, in this sentence, only
the latter is correct. Thus, without further POS
disambiguation, the string naziva relacioni model
follows the pattern (1), although it is not a valid
NP. This means that classical regular expressions
are not sufficient for the representation of such
constraints, and that we need more expressive
means to model constraints related to the NP
structure and agreements of multiword constitu-
ents on case, number and gender. We used the
notion of generic patterns as an extension of
regular expressions (Nenadić and Vitas, 1998b).
For example, a generic pattern
(2) Adj.x1y1z1 Noun.x1y1z1 Adj.x2y2g Noun.x2y2g
models obligatory agreements that each NP from
a specific class has to fulfil: both first and second
pairs of adjectives and nouns must have the same
values for certain morphological features (i.e.
values for gender, number and case denoted by xi,
4 ProAdj and Num denote possessive adjectives and numbers
respectively.
5 For example, ovaj način (Engl. this way), veliki deo (Engl.
large part), etc. This is a reason why we need additional
processing to recognise semantically relevant NPs.
6 Initially (or lexically) tagged POS text is a text in which
every word occurrence is associated with all of its possible
lexical and grammatical interpretations. The initial POS
tagging is intrinsically ambiguous as each word is analysed
separately, without considering neighbouring words (Ne-
nadić and Vitas, 1998a). Thus, as a result of initial tagging, a
lot of lexical ambiguities arise resulting in highly ambiguous
word sequences. See Section 4 for further discussion.
</bodyText>
<figure confidence="0.524552">
� log 2 I a |7(a), a is not nested,
C C value (a) C log Z  |a  |( f (a) F 1LOTa f (b)), a
I otherwise
�
�
</figure>
<bodyText confidence="0.999646740740741">
yi and zi respectively), while these values may be
different for each respective pair. The last adjec-
tive and noun are &amp;quot;frozen&amp;quot; in the genitive case
(g), while the case (z1) in the first pair is &amp;quot;free&amp;quot;.
By defining generic patterns one can model the
agreements within various lexical structures in a
highly inflective language such as Serbian (Ne-
nadić and Vitas, 1998b). As a result, these
agreements can be used to detect the boundaries
of the structures in questions.
A set of generic patterns has been used to
model the most frequent term formation patterns
in Serbian. The set is mainly based on patterns
used to model NPs in Serbian. Table 2 presents
some of them. First four patterns describe NPs
containing a nested NP whose lexical properties
(such as case and/or number) are invariant in all
inflected forms of the host NP. As a rule, the fro-
zen part is in genitive. Depending on NP con-
stituents, some agreements are obligatory within
frozen part (see, for example, the third pattern —
agreements between an adjective and the corre-
sponding noun), or not (see the fourth pattern —
no necessary agreement between the last two
nouns in gender, number). The fifth pattern (Ta-
ble 2) corresponds to NPs that do not have in-
variant parts.
</bodyText>
<table confidence="0.999261727272727">
Generic patterns Examples
1 N1 N gen baza podataka
nejednakost trougla
2 A1 N1 N gen manipulativni aspekt modela
granična vrednost niza
3 N1 A gen N gen operacija prirodnog spajanja
niz realnih brojeva
4 N1 N 2;gen N gen integritet baze podataka
kriterijum konvergencije niza
5 A1+ N1 proireni relacioni model
kompletan metrički prostor
</table>
<tableCaption confidence="0.999248">
Table 2: Frequent term formation patterns
</tableCaption>
<bodyText confidence="0.9969522">
While these patterns are used to single out
term candidates from an initially tagged text,
agreements within NPs are used to generate pos-
sible nested structures. While the rules for nested
structures are more &amp;quot;blurred&amp;quot; in English (since
</bodyText>
<footnote confidence="0.814640166666667">
7 In order to improve readability of filters, the generic pat-
terns in this table are encoded using the following syntax: A
and N stand for Adj and Noun respectively, while X1 stands
for X.x1y1z1 , Xgen stands for X.xyg and X2;gen stands for
X.x2y2g (for X ∈ {A, N)). Also, invariant parts are underlined
in the given examples.
</footnote>
<bodyText confidence="0.997738375">
nouns are usually used as modifiers), &amp;quot;nested-
ness&amp;quot; in Serbian has to preserve the necessary
structure and inner agreements, which are spe-
cific for the NP class in question. Therefore, gen-
eration of nested term candidates depends on the
type of host term candidates (consider examples
in Table 3). Nested structures that are not them-
selves NPs are not considered as term candidates.
</bodyText>
<table confidence="0.991762461538461">
Nested term candidates NP Term
2 manipulativni aspekt modela + +
manipulativni aspekt + -
aspekt modela + -
3 operacija prirodnog spajanja + +
operacija prirodnog - -
prirodnog spajanja + +
4 integritet baze podataka + +
integritet baze + -
baze podataka + +
5 kompletan metrički prostor + +
kompletan metrički - -
metrički prostor + +
</table>
<tableCaption confidence="0.999487">
Table 3: Nested term candidates (in Serbian)
</tableCaption>
<subsectionHeader confidence="0.999595">
3.2 Conflating morphological variants
</subsectionHeader>
<bodyText confidence="0.998619276595745">
If we aim at systematic recognition of terms, then
handling term variation has to be treated as an
essential part of terminology retrieval. Term
variation ranges from simple orthographic (e.g.
oestrogen  estrogen, vitamin  vitamine) and
morphological variants (e.g. clone – clones) to
more complex semantic variation (e.g. eye sur-
gery  ophthalmologic surgery).
Several methods for term variation manage-
ment have been developed. For example, the
BLAST system (Krauthammer et al., 2000) used
approximate text string matching techniques and
dictionaries to recognise spelling variations in
gene and protein names. FASTR (Jacquemin,
2001) handles morphological and syntactic varia-
tions by means of meta-rules used to describe
term normalisation, while semantic variants are
handled via WordNet.
The necessity of taking term variants into ac-
count as part of ATR process becomes particu-
larly apparent in highly inflective languages. In
Serbian, for example, the simplest morphological
variations generally give rise to 14 possible vari-
ants of a single term (seven cases and two num-
bers (singular and plural) — see Table 4). If the
core C-value method were to be applied without
conflating morphological variants, then term-
hoods would be distributed across different mor-
phological variants providing separate
frequencies for individual variants instead of a
single frequency calculated for a term candidate
unifying all of its variants. In addition, the &amp;quot;nest-
ing&amp;quot; factor of the C-value method would cause
skewed results, since the case property of nested
terms does not have normal distribution. Namely,
as indicated previously (see Table 2), the major-
ity of nested terms in Serbian are in genitive case,
which means that the termhood for a term candi-
date in genitive case would differ significantly
from its counterparts in other cases. Moreover,
this deviation cannot be remedied later by sum-
ming up individual termhoods, since C-value is
not an additive measure. Hence, in order for the
C-value method to be applied correctly in a
highly inflective language, term candidates must
be (at least inflectionally) normalised prior to the
calculation of termhoods.
</bodyText>
<figure confidence="0.706204666666667">
Canonical form:
operacija prirodnog spajanja (nom. sing. = ns)
Morphological variants:
</figure>
<figureCaption confidence="0.942170142857143">
operacija prirodnog spajanja (ns;gp)
operacije prirodnog spajanja (gs;np;ap;vp)
operaciji prirodnog spajanja (ds;ls)
operaciju prirodnog spajanja (as)
operacijo prirodnog spajanja (vs)
operacijom prirodnog spajanja (is)
operacijama prirodnog spajanja (dp;ip;lp)
</figureCaption>
<table confidence="0.5900755">
Normalised form:
operacija (ns) prirodno (nsm) spajanje (ns)
</table>
<tableCaption confidence="0.77938">
Table 4: Variants and normalisation of term
candidates — an example for term operacija prirod-
nog spajanja (Engl. natural join operation)
</tableCaption>
<bodyText confidence="0.99989732">
Our approach to morphological normalisation
of term variants is based on the normalisation of
individual term constituents. Namely, each word
that is a part of a term candidate is mapped onto
its lemma, and term candidates are treated as se-
quences of lemmas. At the end of the ATR proc-
ess, terms are converted into their canonical form
(singular, nominative case), which is not neces-
sarily identical to the normalised form (the se-
quence of the corresponding singular words in
singular, nominative case). The normalisation
process is illustrated in Table 4.
At this point, the usage of generic patterns in
order to check the agreements in case, number
and gender during the phase of filtering of term
candidates might seem unnecessary, since all
these features are subsequently normalised. How-
ever, in order to enhance the precision of the
SRCE method, it is important for term candidates
to be correctly recognised prior to the statistical
analysis. This means that the necessary agree-
ments between NP constituents have to be
checked. Once the term candidates are identified,
they are normalised in order to make the most of
the statistical part of the method.
</bodyText>
<subsectionHeader confidence="0.98371">
3.3 Foreign word detection
</subsectionHeader>
<bodyText confidence="0.959222702380952">
Despite the efforts to rely mostly on Serbian vo-
cabulary when building a terminology, many of
the terms used in specific scientific domains bor-
row some of their building blocks from lan-
guages other than Serbian at various levels. For
example, at morphological level, foreign suffixes,
mostly originating from Latin and Greek, are of-
ten &amp;quot;preferred&amp;quot; to their Serbian counterparts in,
for example, the biomedical domain, even when
they are used to modify a root that is in fact Ser-
bian (e.g. amino-kiselina (Engl. amino acid)).
Similarly, at lexical level, words of foreign origin
are used to form multi-word terms (e.g. redun-
dantan atribut (Engl. redundant attribute)). This
is particularly obvious in fairly recently expanded
disciplines such as computer science, where, for
many of the original terms used in English, it has
not been simple to adapt new terms in Serbian.
Consequently, many of the terms have been sim-
ply transcribed into Serbian or, even worse, they
are still used in their original form. Not only do
foreign words appear as &amp;quot;valid&amp;quot; parts of terms,
but they have also proved to be good indicators
of terms. It is, thus, necessary to develop proce-
dures for their detection.
In our approach, the recognition of foreign
words has been integrated into the ATR process
for Serbian. The following morphological fea-
tures are used to indicate occurrences of potential
foreign words (Spasić, 1996):
❑❑ characters (e.g. x, y, q) that do not belong to
Serbian graphemic system,
❑❑ successive vowel occurrences,
❑❑ exception to the palatalisation rule,
− exception to the assimilation rules,
− occurrence of atypical consonant bi/tri-grams
− occurrence of bi-grams or tri-grams typical
for other languages (especially Latin and
English), and
− foreign affixes.
The words satisfying some of the above crite-
ria are not necessarily foreign words. The preci-
sion of these rules varies from one to another. For
example, the first rule is the strongest indicator of
the presence of foreign words, since the alpha-
betical system used is not Serbian. Other rules
may be tuned to a certain extent in order to in-
crease their precision.
Let us, for instance, consider the second rule.
The successive usage of vowels is fairly frequent
in Serbian, but the majority of such cases follow
certain restrictions$ under which they can occur.
Moreover, these restrictions can be described by
regular expressions. Any other occurrence of
successive vowels can be used to indicate a po-
tential foreign word.
Foreign word detection has been incorporated
into the ATR process in two ways: during the
selection of term candidates and for the calcula-
tion of termhoods. First, it is used before the ini-
tial POS tagging process in order to locate
foreign words, which are tagged accordingly.
Otherwise, foreign words would be typically
considered as unknown. As explained earlier, it is
very likely for foreign words in Serbian scientific
and technical texts to be related to domain-
specific concepts, and their mishandling would
significantly decrease the recall of the ATR
method. This information is used by the linguistic
part of the SRCE-method, where we introduced a
special category corresponding to foreign words.
In the second step, that is - once the term can-
didates have been selected - the information
about foreign origin is used to increase the term-
hood of term candidates containing such words.
This time, foreign word recognition is used to
improve the precision of the ATR method.
8 For example, verbs in the paste tense, masculine gender
always end with a pair of vowels (e.g. ispitivao (Engl. exam-
ined)). Further, some adjectives in masculine gender (e.g.
beo (Engl. white)), as well as some nouns in masculine gen-
der (e.g. smisao (Engl. sense)) also end with a pair of vow-
els. The usage of prefixes is another example where vowels
may occur successively (e.g. za+ustaviti (Engl. to stop)).
</bodyText>
<sectionHeader confidence="0.952222" genericHeader="evaluation">
4 Experiments and discussion
</sectionHeader>
<bodyText confidence="0.988355023255814">
The preliminary ATR experiments were con-
ducted using the SRCE system on a corpus con-
taining samples from university textbooks in
mathematics9 and computer science10 (altogether
120k words).
Texts were pre-processed, i.e. initially tagged,
by a system of electronic dictionaries (e-
dictionaries) containing simple nominal words
for Serbian (Vitas, 1993). E-dictionaries contain
exhaustive description of morpho-syntactic
characteristics and are used for lexical
recognition and initial lemmatisation of words
that occur in a text. This process is realised by e-
dictionary look-up, which results in an initially
tagged text: each textual word is associated with
its lemma(s) and corresponding morpho-syntactic
categories (tags) retrieved from the
e-dictionary. In general, e-dictionaries cannot
resolve lexical ambiguities that result from the
fact that there is no one-to-one correspondence
between word forms and their morpho-syntactic
features. There are different methods to resolve
ambiguities (e.g. cache-dictionaries or local
grammars), but in our experiments no disam-
biguation techniques were applied.
In order to extract a list of term candidates, the
set of morpho-syntactic filters described in 3.1
was applied to the initially tagged corpus. We
performed two sets of experiments.
In the first experiment, we did not use any
stoplist to discard unwanted constituents of term
candidates. For each term candidate, we gener-
ated a canonical form (nominative, singular), a
morphologically normalised form (list of normal-
ised words comprising the term candidate) and a
list of nested term candidates (see Table 3 for
examples). In the next step, C-values for term
candidates were calculated using statistics based
on occurrences of normalised forms, and all term
candidates with C-values above an empirically
chosen threshold were selected as terms.
Table 5 gives some examples of the recognised
terms. In order to calculate the precision, we ex-
</bodyText>
<page confidence="0.999448">
9 N. Lazetić, Matematika II/1, NauNna knjiga, Beograd,
1994
10 G. Pavlović-Lazetić, Osnove relacionih baza podataka,
</page>
<bodyText confidence="0.977628714285714">
Vesta - MatematiNki fakultet, Beograd, 1996. We would like
to thank the authors of both textbooks for giving us permis-
sion to use their texts for experiments.
amined separately interval precisions in sub-
corpora in mathematical analysis and computer
science (see Table 6). Intervals are sets of recog-
nised terms that are placed at certain positions
within the list. For example, interval 1-50 con-
tains top 50 terms, while the interval over 150
contains all terms whose positions in the list are
above 150. Terms have been inspected by the
first two authors, who are Serbian native speakers
and are specialists in both computer science and
mathematics.
</bodyText>
<table confidence="0.998042083333333">
Term C-value
metricki prostor 633.55
topoloski prostor 175.13
otvoren skup 93.20
normiran prostor 88.00
Kosijev niz 68.11
zatvoren skup 59.20
vektorski prostor 53.13
prirodan broj 44.41
nejednakost trougla 33.98
neprekidnost preslikavanja 28.02
Hausdorfov topoloski prostor 19.43
</table>
<tableCaption confidence="0.991284">
Table 5: Top ranked terms in the domain of
mathematical analysis
</tableCaption>
<table confidence="0.999181">
Interval Mathematical Computer
analysis science
1 - 50 98% 90%
50 - 100 88% 70%
100 - 150 52% 58%
&gt; 150 69% 68%
</table>
<tableCaption confidence="0.9357995">
Table 6: Precision of the ATR method
(without the usage of a stoplist)
</tableCaption>
<bodyText confidence="0.999955076923077">
In the first 50 terms for the domain of mathe-
matical analysis, there was only one false term
candidate (specijalna klasa neprekidnih pres-
likavanja), which contained an &amp;quot;unwanted&amp;quot; adjec-
tive specijalna (Engl. special). The reason for the
significant drop in the precision in the second and
third intervals is mainly the same: apart from few
true negatives11, the majority of false term candi-
dates contained common &amp;quot;unwanted&amp;quot; constitu-
ents, which are sampled in Table 7. The results
for the computer science sub-corpus were slightly
worse since the mathematical language seems to
be more consistent and restricted.
</bodyText>
<footnote confidence="0.4266395">
11 Such as: toploska tacka gledista, kompletnost prostora igra,
kod preslikavnja.
</footnote>
<bodyText confidence="0.9986505">
In the second experiment, we used a stoplist
containing the words detected as frequent
&amp;quot;wrong&amp;quot; constituents in the previous experi-
ments. The results are summarised in Table 8.
</bodyText>
<table confidence="0.880408833333333">
prozvoljan opsti pojam
trazen dokazan specificnost
specijalan globalan svojstvo
vazan jedinstven slucaj
odgovarajuci poznat posledica
definisan veliki glediste
</table>
<tableCaption confidence="0.988971">
Table 7: A sample of normalised stop-words
</tableCaption>
<table confidence="0.9991875">
Interval Mathematical Computer
analysis science
1 - 50 100% 94%
50 - 100 92% 92%
100 - 150 80% 74%
&gt; 150 74% 70%
</table>
<tableCaption confidence="0.9294545">
Table 8: Precision of the ATR method
(with the usage of a stoplist)
</tableCaption>
<bodyText confidence="0.999876555555556">
The majority of remaining errors originate
from the ambiguous POS tagging (more than
50%, problematic words being naziv(a), igra,
kod, etc.). Since no further processing of text has
been performed, another source of problems is
the detection of boundaries of frozen parts in
prepositional phrases (e.g. na osnovu (Engl.
based on), u slucaju (Engl. in the case of)),
which may be resolved by using a set of corre-
sponding local grammars (Nenadić and Vitas,
1998b). In addition, for the computer science
domain, some of the false terms were related to a
specific application area (the text intensively
used examples from a university information sys-
tem, so candidates such as zvanje nastavnika
(Engl. lecturer position), godina studija (Engl.
year of study), etc. were wrongly suggested as
computer science terms).
</bodyText>
<sectionHeader confidence="0.999265" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999786857142857">
In this paper we have presented an approach to
automatic extraction of terminology in a morpho-
logically rich language, such as Serbian. Terms
extracted automatically may be used as semantic
indicators for a range of classic IR/IE tasks.
The approach is hybrid: it combines morpho-
syntactic filters for extraction of term candidates,
and statistical analysis that ranks term candidates
according to their termhood.
Extraction of term candidates is based on the
recognition of proper NPs. In order to enhance
both the precision and recall of the ATR method,
it is inevitable to incorporate significant linguistic
knowledge. Since describing NPs by means of
regular expressions is not sufficient for modelling
agreements between NP constituents, we have
used generic morpho-syntactic patterns. Further,
since not all NPs are terms that semantically
characterise documents, we have used a statisti-
cal measure in order to estimate semantic signifi-
cance of term candidates. Also, once the term
candidates are correctly identified, they are nor-
malised in order to make the most of the statisti-
cal part of the method. Term candidates
suggested as terms by the statistical part of the
SRCE method are finally mapped into the canoni-
cal form of the original term.
The preliminary experiments show that the
precision is in line with the results for English,
and that for the top ranked terms the precision is
well above 90%. The analysis of errors shows
that the majority of them appear due to lexical
ambiguity of the input text. Certainly, if the cor-
pora were lexically disambiguated, we would
have better precision.
In order to improve the recall, additional mor-
pho-syntactic filters need to be identified. In par-
ticular, we plan to study terms that contain
prepositions, as this is a common formation pat-
tern in many domains. Further, the broader han-
dling of term variants (e.g. dialectic variants,
acronyms, derivational variants) may also im-
prove both precision and recall. Currently we
deal only with inflectional variants by mapping
them to a canonical form. Term variants unifica-
tion and normalisation also provide a broader
basis for further IR and IE tasks, as queries can
be expanded by referring to a class of synony-
mous terms as opposed to a single term.
</bodyText>
<sectionHeader confidence="0.999477" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999922905660377">
Ananiadou S. 1994. Methodology for Automatic Term
Recognition. In Proceedings of COLING-94,
Kyoto, Japan
Frantzi K.T., Ananiadou S. and Mima H. 2000. Auto-
matic Recognition of Multi-word Terms: the C-
value/NC-value Method. Int. J. on Digital Libraries,
3/2, pp. 115-130.
Grobelnik M., Mladenic D. and Milic-Frayling N.
2000. Text Mining as Integration of Several Re-
lated Research Areas, KDD 2000 Workshop on
Text Mining, Boston, USA
Hatzivassiloglou V., Duboue P. and Rzetsky A. 2001.
Disambiguating Proteins, Genes, and RNA in Text:
A Machine Learning Approach. Bioinformatics,
17/1, pp. S97-S106
Hearst M. 2000. Text Mining Tools: Instruments for
Scientific Discovery, in IMA Text Mining Work-
shop, Institute for Mathematics and its Applica-
tions, Minneapolis, USA, 2000
Jacquemin C. 2001. Spotting and discovering terms
through NLP. MIT Press, Cambridge MA, 378 p.
Krauthammer M., Rzhetsky A., Morozov P. and
Friedman C. 2000. Using BLAST for identifying
gene and protein names in journal articles. Gene,
259, pp. 245-252.
Mima H., Ando K. and Aoe J. 1995: Incremental
Generation of LR(1) Parse Tables. In Proceedings
of NLPRS&apos;95, Pacific-Rim Symp., Seoul, Korea
Nakagawa H. and Mori T. 2000. Nested Collocation
and Compound Noun for Term Recognition. Proc.
of COMPUTERM 98, pp. 6470
Nenadic G. and Vitas D. 1998a. Formal Model of
Noun Phrases in Serbo-Croatian. BULAG 23,
Universite Franche-Compte, Besangon, France.
Nenadic G. and Vitas D. 1998b. Using Local Gram-
mars for Agreement Modelling in Highly Inflective
Languages. In Proceedings of TSD 98. Masaryk
University, Brno, pp. 91-96.
Nenadic G., Mima H., Spasic I., Ananiadou S. and
Tsujii J. 2002. Terminology-driven Literature Min-
ing and Knowledge Acquisition in Biomedicine. In-
ternational Journal of Medical Informatics, 1-16.
Spasic I. 1996. Automatic Foreign Words Recognition
in a Serbian Scientific or Technical Text. In Pro-
ceedings of Standardisation of Terminology, Bel-
grade, Yugoslavia, 1996
Vintar 9. 2000. Extracting Terms and Terminological
Collocations from the ELAN Slovene-English Par-
allel Corpus. In Proceedings of the 5th EAMT
Workshop, Ljubljana, Slovenia, 2000
Vitas D. 1993. Mathematical Model of Serbo-
Croatian Morphology (Nominal Inflection). PhD
thesis. Faculty of Mathematics, Belgrade.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.001549">
<title confidence="0.995055">Morpho-syntactic Clues for Terminological Processing in Serbian</title>
<author confidence="0.863178">Ananiadou</author>
<affiliation confidence="0.999657">Department of Computing Computer Science Computer Science</affiliation>
<address confidence="0.517487">UMIST, UK University of Salford, UK University of Salford, UK</address>
<email confidence="0.950224">G.Nenadic@umist.ac.ukI.Spasic@salford.ac.ukS.Ananiadou@salford.ac.uk</email>
<abstract confidence="0.996404227338131">In this paper we discuss morpho-syntactic clues that can be used to facilitate terminological processing in Serbian. A (called for automatic extraction of multiword terms is presented. The approach incorporates a set of generic morpho-syntactic filters for recognition of term candidates, a method for conflation of morphological variants and a module for foreign word recognition. Morpho-syntactic filters describe general term formation patterns, and are implemented as generic regular expressions. The inner structure together with the agreements within term candidates are used as clues to discover the boundaries of nested terms. The results of the terminological processing of a textbook corpus in the domains of mathematics and computer science are presented. An overwhelming amount of textual information presented in newswire, scientific literature, legal texts, etc., makes it difficult for a human to efficiently localise the information of interest. In particular, it is doubtful that anybody could process such huge amount of information without an automated help, especially when the information content spans across domains. The amount of edocuments and their fuzzy structure require effective tools that can help users to systematically gather and make use of the information encoded in text documents. For these reasons, different text and/or literature mining techniques have been developed recently (e.g. (Hearst et al., 2000; Grobelnik et al., 2000)) in to facilitate efficient discovery of knowlcient discovery of knowledge contained in large scientific or legal text collections. The main goal is to retrieve the knowledge &amp;quot;buried&amp;quot; in a text and to present it to users in a digested form. The discovery (and transfer) of knowledge relies heavily on the identification of relevant concepts, which are linguistically represented by specific terms. the most important notions in a domain and characterise documents semantically, and thus should be used as a basis for sophisticated knowledge acquisition. Still, few text-mining systems incorporate deep and dynamic terminology processing, although there is an increasing amount of new terms that represent newly created concepts in rapidly developing fields. Existing term dictionaries and standardised terminologies offer only a partial solution, as they are almost never up-todate. Although naming conventions do exist for some types of concepts (e.g. gene and protein names in biomedicine), these are only guidelines and as such do not impose restrictions to domain experts, who frequently introduce ad-hoc terms. Thus, the lack of clear naming conventions makes the automatic term recognition (ATR) task difficult even for languages that are not morphologically and derivationally rich. ATR tools have been developed for English (Frantzi et al., 2000), French (Jacquemin, 2001), Japanese (Nakagawa and Mori, 2000), etc. Some methods rely purely on linguistic information, namely morpho-syntactic features of term candidates (Ananiadou, 1994). Hybrid approaches combining linguistic patterns and statistical measures (e.g. (Frantzi et al., 2000)) and machine-learning techniques (e.g. (Hatzivassiloglou et al., 2001)) have been also used. However, few studies have been done for morphologically rich Slavic languages. For example, Vintar (2000) presented two methods for extraction of terminological collocations in order to assist the translation process in Slovene. The statistical approach was based on the mutual expectation and LocalMax measures, and involved collocation extraction from raw text. The extracted collocations were filtered with a stopword list, and only collocations containing single-word terms (devised previously by bilingual alignment) were accepted as relevant. In another approach, she used regular expression patterns to extract term collocations from a morphosyntactically tagged corpus. However, these patterns are too general, and consequently not all extracted phrases were terminologically relevant. In this paper we discuss automatic terminology recognition in Serbian, in particular, the extracof multiword terms, which are very in certain domains (e.g. natural sciences, mathematics, etc.). Since Serbian is a highly inflective and morphologically and derivationally rich language, morpho-syntactic clues are indispensable in the ATR process. Our hybrid approach (called Serbian C-value) combines morphosyntactic features of term candidates and statistical analysis of their occurrences in text. In addition, since terms appear in texts in many different forms due to their morphological and derivational variations, the necessity of taking these variations into account becomes particularly apparent. the incorporates generic morpho-syntactic patterns, a term normalisation approach and a foreign word detection method. The paper is organised as follows: in Section 2 we present an overview of the core term extraction method, called the C-value method. In Section 3 we discuss morpho-syntactic clues, the normalisation approach and the foreign word recognition that are used for singling out terms in Serbian. The experiments and evaluation are described in Section 4. 2 Automatic Term Recognition: the core C-value method Our approach to ATR is based on the C-value method (Frantzi et al., 2000), which extracts multi-word terms. It is a general term recognition approach in the sense that it is not limited to specific classes of concepts. The approach is hybrid: the method combines linguistic knowledge (term English, more than 85% of domain-specific terms are multi-words (Nakagawa and Mori, 2000). formation patterns) and statistical analysis. Linguistic knowledge is used to single out term candidates, while their statistical features are used to measure the likelihood of term candidates being &amp;quot;real&amp;quot; terms. The method uses a POS tagged text as input, and outputs a list of extracted terms according to their termhoods. is a numeric estimation of the degree to which a given linguistic unit (a multiword compound) is related to a domain-specific concept. However, the values are not normalised in the sense that a multiword, having a termhood value 10, is 10 times more likely to be a term than a term candidate with a termhood value 1. In general, the C-value method enhances the commonly used baseline method that extracts most frequent term candidates (assuming that termhoods directly correspond to frequencies of occurrence) by making it sensitive to a particular of terms � nested The method is implemented as a two-step pro- In the first step, candidates extracted using a set of morpho-syntactic filters, which describe general term formation patterns in a given language. As a rule, terms form a proper subset of noun phrases (NPs). For example, a set of general filters for English may include the fol- Noun  |Noun  |((Adj  |Noun)* Prep?) (Adj  |Noun)* Noun Although these patterns are regular expressions, the filters are implemented as unification-like LR(1) rules (Mima et al., 1995) in order to facilitate processing of grammatical agreements (if any) within term candidates. For each term candidate extracted by a filter, a set of nested term candidates is generated (see Table 1 for an example in English). The procedure for the generation of nested term candidates is implemented via transformation rules for each morpho-syntactic filter that is used to extract example, receptor a nested term in Similarly, podataka a nested term in baze podataka of POS tags that correspond to nouns, adjectives and prepositions respectively. These filters were used for ATR from newswire corpora and in biomedi- (Frantzi et al., 2000; al., 2002). term candidates. The main indicator that a nested term candidate might be a real term is that it also appears on its own in the corpus. Term candidate: Term steroid hormone receptor factor + Nested term candidates: steroid hormone receptor + hormone receptor factor steroid hormone + hormone receptor + receptor factor - Nested term candidates In the second step, the term candidates are astermhoods (referred to as according to a statistical measure. The measure amalgamates four numerical corpus-based characteristic of a candidate term, namely the frequency of occurrence, the frequency of occurring as nested within other candidate terms, the number of candidate terms inside which the given candidate term is nested, and the number of words contained in the candidate term. Formally, a term candidate, correto its frequency, denotes the number of in and is a set of terms that contain a nested term. Term candidates are ranked according to their C-values, and terms whose C-values are higher than a chosen threshold are presented as terms. Evaluation of the C-value method for English has shown that using additional statistical information (frequency of &amp;quot;nestedness&amp;quot;) improves the precision with slight loss on recall (Frantzi et al., 2000). Also, systematic term normalisation may further improve precision and recall of the al., 2002). 3 Morpho-syntactic clues for extraction of terms in Serbian In order to adjust the core C-value method for Serbian, we have defined an appropriate set of morpho-syntactic filters and rules for inflectional normalisation of term candidates, and, additionally, a module for foreign word recognition. formation patterns As a rule, the vast majority of multiword terms in Serbian match the following general formation (1)  |ProAdj  |Num  |Noun which has been used for recognition of NPs in Vitas, 1998a). Of course, all NPs that follow this pattern are Moreover, when applied to an initially POS this pattern may be too general even for description of NPs, as not all word sequences in a text that match this pattern are valid NPs. For in a sequence se naziva relacioni is called the relational a word be initially tagged eias a noun or a verb naalthough, in this sentence, only the latter is correct. Thus, without further POS the string relacioni model follows the pattern (1), although it is not a valid NP. This means that classical regular expressions are not sufficient for the representation of such constraints, and that we need more expressive means to model constraints related to the NP structure and agreements of multiword constituents on case, number and gender. We used the notion of generic patterns as an extension of expressions Vitas, 1998b). For example, a generic pattern (2) models obligatory agreements that each NP from a specific class has to fulfil: both first and second pairs of adjectives and nouns must have the same values for certain morphological features (i.e. for gender, number and case denoted by possessive adjectives and numbers respectively. example, way), veliki deo etc. This is a reason why we need additional processing to recognise semantically relevant NPs. (or lexically) tagged POS text is a text in which word occurrence is associated with its possible lexical and grammatical interpretations. The initial POS tagging is intrinsically ambiguous as each word is analysed separately, without considering neighbouring words (Ne- Vitas, 1998a). Thus, as a result of initial tagging, a of ambiguities resulting in highly ambiguous word sequences. See Section 4 for further discussion. not nested, Z  |( � � while these values may be different for each respective pair. The last adjective and noun are &amp;quot;frozen&amp;quot; in the genitive case while the case in the first pair is &amp;quot;free&amp;quot;. By defining generic patterns one can model the agreements within various lexical structures in a highly inflective language such as Serbian (Ne- Vitas, 1998b). As a result, these agreements can be used to detect the boundaries of the structures in questions. A set of generic patterns has been used to model the most frequent term formation patterns in Serbian. The set is mainly based on patterns used to model NPs in Serbian. Table 2 presents some of them. First four patterns describe NPs containing a nested NP whose lexical properties (such as case and/or number) are invariant in all inflected forms of the host NP. As a rule, the frozen part is in genitive. Depending on NP constituents, some agreements are obligatory within frozen part (see, for example, the third pattern — agreements between an adjective and the corresponding noun), or not (see the fourth pattern — no necessary agreement between the last two nouns in gender, number). The fifth pattern (Table 2) corresponds to NPs that do not have invariant parts. Generic patterns Examples 1 baza podataka nejednakost trougla 2 manipulativni aspekt modela vrednost niza 3 genN operacija prirodnog spajanja niz realnih brojeva 4 2;genN integritet baze podataka kriterijum konvergencije niza 5 proireni relacioni model prostor Frequent term formation patterns While these patterns are used to single out term candidates from an initially tagged text, agreements within NPs are used to generate possible nested structures. While the rules for nested structures are more &amp;quot;blurred&amp;quot; in English (since order to improve readability of filters, the generic patin this table are encoded using the following syntax: for while , stands for stands for Also, invariant parts are underlined in the given examples. nouns are usually used as modifiers), &amp;quot;nestedness&amp;quot; in Serbian has to preserve the necessary structure and inner agreements, which are specific for the NP class in question. Therefore, generation of nested term candidates depends on the type of host term candidates (consider examples in Table 3). Nested structures that are not themselves NPs are not considered as term candidates. Nested term candidates NP Term 2 manipulativni aspekt modela manipulativni aspekt aspekt modela + + + - + - 3 operacija prirodnog spajanja operacija prirodnog prirodnog spajanja + + - - + + 4 integritet baze podataka integritet baze baze podataka + + + - + + 5 prostor prostor + + - - + + Nested term candidates (in Serbian) 3.2 Conflating morphological variants If we aim at systematic recognition of terms, then handling term variation has to be treated as an essential part of terminology retrieval. Term variation ranges from simple orthographic (e.g.   and variants (e.g. – to complex semantic variation (e.g. sur-  ophthalmologic Several methods for term variation management have been developed. For example, the BLAST system (Krauthammer et al., 2000) used approximate text string matching techniques and dictionaries to recognise spelling variations in gene and protein names. FASTR (Jacquemin, 2001) handles morphological and syntactic variations by means of meta-rules used to describe term normalisation, while semantic variants are handled via WordNet. The necessity of taking term variants into account as part of ATR process becomes particularly apparent in highly inflective languages. In Serbian, for example, the simplest morphological variations generally give rise to 14 possible variants of a single term (seven cases and two numbers (singular and plural) — see Table 4). If the core C-value method were to be applied without conflating morphological variants, then termhoods would be distributed across different morphological variants providing separate frequencies for individual variants instead of a single frequency calculated for a term candidate unifying all of its variants. In addition, the &amp;quot;nesting&amp;quot; factor of the C-value method would cause skewed results, since the case property of nested terms does not have normal distribution. Namely, as indicated previously (see Table 2), the majority of nested terms in Serbian are in genitive case, which means that the termhood for a term candidate in genitive case would differ significantly from its counterparts in other cases. Moreover, this deviation cannot be remedied later by summing up individual termhoods, since C-value is not an additive measure. Hence, in order for the C-value method to be applied correctly in a highly inflective language, term candidates must (at least inflectionally) normalised the calculation of termhoods. Canonical form: spajanja(nom. sing. = ns) Morphological variants: spajanja(ns;gp) spajanja(gs;np;ap;vp) spajanja(ds;ls) spajanja(as) spajanja(vs) spajanja(is) spajanja(dp;ip;lp) Normalised form: Variants and normalisation of term — an example for term prirodspajanja join Our approach to morphological normalisation of term variants is based on the normalisation of individual term constituents. Namely, each word that is a part of a term candidate is mapped onto its lemma, and term candidates are treated as sequences of lemmas. At the end of the ATR process, terms are converted into their canonical form (singular, nominative case), which is not necessarily identical to the normalised form (the sequence of the corresponding singular words in singular, nominative case). The normalisation process is illustrated in Table 4. At this point, the usage of generic patterns in order to check the agreements in case, number and gender during the phase of filtering of term candidates might seem unnecessary, since all these features are subsequently normalised. However, in order to enhance the precision of the it is important for term candidates to be correctly recognised prior to the statistical analysis. This means that the necessary agreements between NP constituents have to be checked. Once the term candidates are identified, they are normalised in order to make the most of the statistical part of the method. 3.3 Foreign word detection Despite the efforts to rely mostly on Serbian vocabulary when building a terminology, many of the terms used in specific scientific domains borrow some of their building blocks from languages other than Serbian at various levels. For example, at morphological level, foreign suffixes, mostly originating from Latin and Greek, are often &amp;quot;preferred&amp;quot; to their Serbian counterparts in, for example, the biomedical domain, even when they are used to modify a root that is in fact Ser- (e.g. Similarly, at lexical level, words of foreign origin used to form multi-word terms (e.g. redunatribut This is particularly obvious in fairly recently expanded disciplines such as computer science, where, for many of the original terms used in English, it has not been simple to adapt new terms in Serbian. Consequently, many of the terms have been simply transcribed into Serbian or, even worse, they are still used in their original form. Not only do foreign words appear as &amp;quot;valid&amp;quot; parts of terms, but they have also proved to be good indicators of terms. It is, thus, necessary to develop procedures for their detection. In our approach, the recognition of foreign words has been integrated into the ATR process for Serbian. The following morphological features are used to indicate occurrences of potential words 1996): (e.g. that do not belong to Serbian graphemic system, vowel occurrences, to the palatalisation rule, to the assimilation rules, of atypical consonant bi/tri-grams of bi-grams or tri-grams typical for other languages (especially Latin and English), and affixes. The words satisfying some of the above criteria are not necessarily foreign words. The precision of these rules varies from one to another. For example, the first rule is the strongest indicator of the presence of foreign words, since the alphabetical system used is not Serbian. Other rules may be tuned to a certain extent in order to increase their precision. Let us, for instance, consider the second rule. The successive usage of vowels is fairly frequent in Serbian, but the majority of such cases follow under which they can occur. Moreover, these restrictions can be described by regular expressions. Any other occurrence of successive vowels can be used to indicate a potential foreign word. Foreign word detection has been incorporated into the ATR process in two ways: during the selection of term candidates and for the calculation of termhoods. First, it is used before the initial POS tagging process in order to locate foreign words, which are tagged accordingly. Otherwise, foreign words would be typically considered as unknown. As explained earlier, it is very likely for foreign words in Serbian scientific and technical texts to be related to domainspecific concepts, and their mishandling would significantly decrease the recall of the ATR method. This information is used by the linguistic of the where we introduced a special category corresponding to foreign words. In the second step, that is once the term candidates have been selected the information about foreign origin is used to increase the termhood of term candidates containing such words. This time, foreign word recognition is used to improve the precision of the ATR method. example, verbs in the paste tense, masculine gender end with a pair of vowels (e.g. exam- Further, some adjectives in masculine gender (e.g. as well as some nouns in masculine gen- (e.g. also end with a pair of vowels. The usage of prefixes is another example where vowels occur successively (e.g. 4 Experiments and discussion The preliminary ATR experiments were conusing the on a corpus containing samples from university textbooks in and computer (altogether 120k words). Texts were pre-processed, i.e. initially tagged, by a system of electronic dictionaries (edictionaries) containing simple nominal words for Serbian (Vitas, 1993). E-dictionaries contain exhaustive description of morpho-syntactic characteristics and are used for lexical recognition and initial lemmatisation of words that occur in a text. This process is realised by edictionary look-up, which results in an initially tagged text: each textual word is associated with its lemma(s) and corresponding morpho-syntactic categories (tags) retrieved from the e-dictionary. In general, e-dictionaries cannot resolve lexical ambiguities that result from the fact that there is no one-to-one correspondence between word forms and their morpho-syntactic features. There are different methods to resolve ambiguities (e.g. cache-dictionaries or local grammars), but in our experiments no disambiguation techniques were applied. In order to extract a list of term candidates, the set of morpho-syntactic filters described in 3.1 was applied to the initially tagged corpus. We performed two sets of experiments. In the first experiment, we did not use any stoplist to discard unwanted constituents of term candidates. For each term candidate, we generated a canonical form (nominative, singular), a morphologically normalised form (list of normalised words comprising the term candidate) and a list of nested term candidates (see Table 3 for examples). In the next step, C-values for term candidates were calculated using statistics based on occurrences of normalised forms, and all term candidates with C-values above an empirically chosen threshold were selected as terms. Table 5 gives some examples of the recognised In order to calculate the precision, we exknjiga, Beograd, 1994 relacionih baza fakultet, Beograd, 1996. We would like to thank the authors of both textbooks for giving us permission to use their texts for experiments. amined separately interval precisions in subcorpora in mathematical analysis and computer science (see Table 6). Intervals are sets of recognised terms that are placed at certain positions the list. For example, interval contop 50 terms, while the interval 150 contains all terms whose positions in the list are above 150. Terms have been inspected by the first two authors, who are Serbian native speakers and are specialists in both computer science and mathematics. Term C-value prostor 633.55 topoloski prostor 175.13 otvoren skup 93.20 normiran prostor 88.00 Kosijev niz 68.11 zatvoren skup 59.20 vektorski prostor 53.13 prirodan broj 44.41 nejednakost trougla 33.98 neprekidnost preslikavanja 28.02 Hausdorfov topoloski prostor 19.43 Top ranked terms in the domain mathematical analysis Interval Mathematical analysis science 1 - 50 98% 90% 50 - 100 88% 70% 100 - 150 52% 58% &gt; 150 69% 68% Precision of the ATR method (without the usage of a stoplist) In the first 50 terms for the domain of mathematical analysis, there was only one false term klasa neprekidnih preswhich contained an &amp;quot;unwanted&amp;quot; adjec- The reason for the significant drop in the precision in the second and third intervals is mainly the same: apart from few the majority of false term candidates contained common &amp;quot;unwanted&amp;quot; constituents, which are sampled in Table 7. The results for the computer science sub-corpus were slightly worse since the mathematical language seems to be more consistent and restricted. as: gledista, kompletnost prostora igra, In the second experiment, we used a stoplist containing the words detected as frequent &amp;quot;wrong&amp;quot; constituents in the previous experiments. The results are summarised in Table 8. prozvoljan opsti pojam trazen dokazan specijalan globalan svojstvo vazan jedinstven poznat posledica definisan veliki glediste A sample of normalised stop-words Interval analysis science 1 - 50 100% 94% 50 - 100 92% 92% 100 - 150 80% 74% &gt; 150 74% 70% Precision of the ATR (with the usage of a stoplist) The majority of remaining errors originate from the ambiguous POS tagging (more than problematic words being igra, Since no further processing of text has been performed, another source of problems is the detection of boundaries of frozen parts in phrases (e.g. osnovu u the case which may be resolved by using a set of correlocal grammars Vitas, 1998b). In addition, for the computer science domain, some of the false terms were related to a specific application area (the text intensively used examples from a university information sysso candidates such as nastavnika studija of etc. were wrongly suggested as computer science terms). 5 Conclusion In this paper we have presented an approach to automatic extraction of terminology in a morphologically rich language, such as Serbian. Terms extracted automatically may be used as semantic indicators for a range of classic IR/IE tasks. The approach is hybrid: it combines morphosyntactic filters for extraction of term candidates, and statistical analysis that ranks term candidates according to their termhood. Extraction of term candidates is based on the recognition of proper NPs. In order to enhance both the precision and recall of the ATR method, it is inevitable to incorporate significant linguistic knowledge. Since describing NPs by means of regular expressions is not sufficient for modelling agreements between NP constituents, we have used generic morpho-syntactic patterns. Further, since not all NPs are terms that semantically characterise documents, we have used a statistical measure in order to estimate semantic significance of term candidates. Also, once the term candidates are correctly identified, they are normalised in order to make the most of the statistical part of the method. Term candidates suggested as terms by the statistical part of the are finally mapped into the canonical form of the original term. The preliminary experiments show that the precision is in line with the results for English, and that for the top ranked terms the precision is well above 90%. The analysis of errors shows that the majority of them appear due to lexical ambiguity of the input text. Certainly, if the corpora were lexically disambiguated, we would have better precision. In order to improve the recall, additional morpho-syntactic filters need to be identified. In particular, we plan to study terms that contain prepositions, as this is a common formation pattern in many domains. Further, the broader handling of term variants (e.g. dialectic variants, acronyms, derivational variants) may also improve both precision and recall. Currently we deal only with inflectional variants by mapping them to a canonical form. Term variants unification and normalisation also provide a broader basis for further IR and IE tasks, as queries can be expanded by referring to a class of synonymous terms as opposed to a single term.</abstract>
<note confidence="0.928863214285714">References S. 1994. for Automatic Term In Proceedings of COLING-94, Kyoto, Japan K.T., Ananiadou S. and Mima H. 2000. matic Recognition of Multi-word Terms: the C- Int. J. on Digital Libraries, 3/2, pp. 115-130. M., and N. Mining as Integration of Several Re- Research KDD 2000 Workshop on Text Mining, Boston, USA Hatzivassiloglou V., Duboue P. and Rzetsky A. 2001. Disambiguating Proteins, Genes, and RNA in Text:</note>
<affiliation confidence="0.762732">Machine Learning Bioinformatics,</affiliation>
<address confidence="0.878373">17/1, pp. S97-S106</address>
<author confidence="0.870645">Mining Tools Instruments for in IMA Text Mining Work-</author>
<affiliation confidence="0.983861">shop, Institute for Mathematics and its Applica-</affiliation>
<address confidence="0.975218">tions, Minneapolis, USA, 2000</address>
<note confidence="0.854251826086956">C. 2001. and discovering terms MIT Press, Cambridge MA, 378 p. Krauthammer M., Rzhetsky A., Morozov P. and C. 2000. BLAST for identifying and protein names in journal Gene, 259, pp. 245-252. H., Ando K. and Aoe J. 1995: of LR(1) Parse In Proceedings of NLPRS&apos;95, Pacific-Rim Symp., Seoul, Korea H. and Mori T. 2000. Collocation Compound Noun for Term Proc. of COMPUTERM 98, pp. 6470 and Vitas D. 1998a. Model of Phrases in BULAG 23, Universite Franche-Compte, Besangon, France. and Vitas D. 1998b. Local Grammars for Agreement Modelling in Highly Inflective In Proceedings of TSD 98. Masaryk University, Brno, pp. 91-96. Mima H., Ananiadou S. and J. 2002. Literature Minand Knowledge Acquisition in International Journal of Medical Informatics, 1-16.</note>
<title confidence="0.7241">1996. Foreign Words Recognition</title>
<author confidence="0.737908">a Serbian Scientific or Technical In Pro-</author>
<affiliation confidence="0.707904">ceedings of Standardisation of Terminology, Bel-</affiliation>
<address confidence="0.564851">grade, Yugoslavia, 1996</address>
<note confidence="0.910392857142857">9. 2000. Terms and Terminological Collocations from the ELAN Slovene-English Par- Corpus. Proceedings of the EAMT Workshop, Ljubljana, Slovenia, 2000 D. 1993. Model of Serbo- Morphology (Nominal PhD thesis. Faculty of Mathematics, Belgrade.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Ananiadou</author>
</authors>
<title>Methodology for Automatic Term Recognition.</title>
<date>1994</date>
<booktitle>In Proceedings of COLING-94,</booktitle>
<location>Kyoto, Japan</location>
<contexts>
<context position="3379" citStr="Ananiadou, 1994" startWordPosition="497" endWordPosition="498"> types of concepts (e.g. gene and protein names in biomedicine), these are only guidelines and as such do not impose restrictions to domain experts, who frequently introduce ad-hoc terms. Thus, the lack of clear naming conventions makes the automatic term recognition (ATR) task difficult even for languages that are not morphologically and derivationally rich. ATR tools have been developed for English (Frantzi et al., 2000), French (Jacquemin, 2001), Japanese (Nakagawa and Mori, 2000), etc. Some methods rely purely on linguistic information, namely morpho-syntactic features of term candidates (Ananiadou, 1994). Hybrid approaches combining linguistic patterns and statistical measures (e.g. (Frantzi et al., 2000)) and machine-learning techniques (e.g. (Hatzivassiloglou et al., 2001)) have been also used. However, few studies have been done for morphologically rich Slavic languages. For example, Vintar (2000) presented two methods for extraction of terminological collocations in order to assist the translation process in Slovene. The statistical approach was based on the mutual expectation and LocalMax measures, and involved collocation extraction from raw text. The extracted collocations were filtere</context>
</contexts>
<marker>Ananiadou, 1994</marker>
<rawString>Ananiadou S. 1994. Methodology for Automatic Term Recognition. In Proceedings of COLING-94, Kyoto, Japan</rawString>
</citation>
<citation valid="true">
<authors>
<author>K T Frantzi</author>
<author>S Ananiadou</author>
<author>H Mima</author>
</authors>
<title>Automatic Recognition of Multi-word Terms: the Cvalue/NC-value Method.</title>
<date>2000</date>
<journal>Int. J. on Digital Libraries,</journal>
<volume>3</volume>
<pages>115--130</pages>
<contexts>
<context position="3189" citStr="Frantzi et al., 2000" startWordPosition="470" endWordPosition="473">pidly developing fields. Existing term dictionaries and standardised terminologies offer only a partial solution, as they are almost never up-todate. Although naming conventions do exist for some types of concepts (e.g. gene and protein names in biomedicine), these are only guidelines and as such do not impose restrictions to domain experts, who frequently introduce ad-hoc terms. Thus, the lack of clear naming conventions makes the automatic term recognition (ATR) task difficult even for languages that are not morphologically and derivationally rich. ATR tools have been developed for English (Frantzi et al., 2000), French (Jacquemin, 2001), Japanese (Nakagawa and Mori, 2000), etc. Some methods rely purely on linguistic information, namely morpho-syntactic features of term candidates (Ananiadou, 1994). Hybrid approaches combining linguistic patterns and statistical measures (e.g. (Frantzi et al., 2000)) and machine-learning techniques (e.g. (Hatzivassiloglou et al., 2001)) have been also used. However, few studies have been done for morphologically rich Slavic languages. For example, Vintar (2000) presented two methods for extraction of terminological collocations in order to assist the translation proc</context>
<context position="5716" citStr="Frantzi et al., 2000" startWordPosition="840" endWordPosition="843">. Therefore, the SRCE method incorporates generic morpho-syntactic patterns, a term normalisation approach and a foreign word detection method. The paper is organised as follows: in Section 2 we present an overview of the core term extraction method, called the C-value method. In Section 3 we discuss morpho-syntactic clues, the normalisation approach and the foreign word recognition that are used for singling out terms in Serbian. The experiments and evaluation are described in Section 4. 2 Automatic Term Recognition: the core C-value method Our approach to ATR is based on the C-value method (Frantzi et al., 2000), which extracts multi-word terms. It is a general term recognition approach in the sense that it is not limited to specific classes of concepts. The approach is hybrid: the method combines linguistic knowledge (term 1 In English, more than 85% of domain-specific terms are multi-words (Nakagawa and Mori, 2000). formation patterns) and statistical analysis. Linguistic knowledge is used to single out term candidates, while their statistical features are used to measure the likelihood of term candidates being &amp;quot;real&amp;quot; terms. The method uses a POS tagged text as input, and outputs a list of extracte</context>
<context position="8292" citStr="Frantzi et al., 2000" startWordPosition="1258" endWordPosition="1261">d term candidates is generated (see Table 1 for an example in English). The procedure for the generation of nested term candidates is implemented via transformation rules for each morpho-syntactic filter that is used to extract 2 For example, nuclear receptor is a nested term in hormone nuclear receptor. Similarly, baza podataka (Engl. database) is a nested term in aiuriranje baze podataka (Engl. update of database). 3 Noun, Adj and Prep denote POS tags that correspond to nouns, adjectives and prepositions respectively. These filters were used for ATR from newswire corpora and in biomedicine (Frantzi et al., 2000; Nenadić et al., 2002). term candidates. The main indicator that a nested term candidate might be a real term is that it also appears on its own in the corpus. Term candidate: Term steroid hormone receptor factor + Nested term candidates: steroid hormone receptor + hormone receptor factor - steroid hormone + hormone receptor + receptor factor - Table 1: Nested term candidates In the second step, the term candidates are assigned termhoods (referred to as C-values) according to a statistical measure. The measure amalgamates four numerical corpus-based characteristic of a candidate term, namely </context>
<context position="9645" citStr="Frantzi et al., 2000" startWordPosition="1483" endWordPosition="1486"> which the given candidate term is nested, and the number of words contained in the candidate term. Formally, where a denotes a term candidate, f(a) corresponds to its frequency, |a |denotes the number of words in a, and Ta is a set of terms that contain term a as a nested term. Term candidates are ranked according to their C-values, and terms whose C-values are higher than a chosen threshold are presented as terms. Evaluation of the C-value method for English has shown that using additional statistical information (frequency of &amp;quot;nestedness&amp;quot;) improves the precision with slight loss on recall (Frantzi et al., 2000). Also, systematic term normalisation may further improve precision and recall of the method (Nenadić et al., 2002). 3 Morpho-syntactic clues for extraction of terms in Serbian In order to adjust the core C-value method for Serbian, we have defined an appropriate set of morpho-syntactic filters and rules for inflectional normalisation of term candidates, and, additionally, a module for foreign word recognition. 3.1 Term formation patterns As a rule, the vast majority of multiword terms in Serbian match the following general formation pattern:4 (1) (Adj |ProAdj |Num |Noun )+ Noun which has been</context>
</contexts>
<marker>Frantzi, Ananiadou, Mima, 2000</marker>
<rawString>Frantzi K.T., Ananiadou S. and Mima H. 2000. Automatic Recognition of Multi-word Terms: the Cvalue/NC-value Method. Int. J. on Digital Libraries, 3/2, pp. 115-130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Grobelnik</author>
<author>D Mladenic</author>
<author>N Milic-Frayling</author>
</authors>
<date>2000</date>
<booktitle>Text Mining as Integration of Several Related Research Areas, KDD 2000 Workshop on Text Mining,</booktitle>
<location>Boston, USA</location>
<contexts>
<context position="1805" citStr="Grobelnik et al., 2000" startWordPosition="257" endWordPosition="260"> literature, legal texts, etc., makes it difficult for a human to efficiently localise the information of interest. In particular, it is doubtful that anybody could process such huge amount of information without an automated help, especially when the information content spans across domains. The amount of edocuments and their fuzzy structure require effective tools that can help users to systematically gather and make use of the information encoded in text documents. For these reasons, different text and/or literature mining techniques have been developed recently (e.g. (Hearst et al., 2000; Grobelnik et al., 2000)) in order to facilitate efficient discovery of knowlcient discovery of knowledge contained in large scientific or legal text collections. The main goal is to retrieve the knowledge &amp;quot;buried&amp;quot; in a text and to present it to users in a digested form. The discovery (and transfer) of knowledge relies heavily on the identification of relevant concepts, which are linguistically represented by domain specific terms. Terms represent the most important notions in a domain and characterise documents semantically, and thus should be used as a basis for sophisticated knowledge acquisition. Still, few text-</context>
</contexts>
<marker>Grobelnik, Mladenic, Milic-Frayling, 2000</marker>
<rawString>Grobelnik M., Mladenic D. and Milic-Frayling N. 2000. Text Mining as Integration of Several Related Research Areas, KDD 2000 Workshop on Text Mining, Boston, USA</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Hatzivassiloglou</author>
<author>P Duboue</author>
<author>A Rzetsky</author>
</authors>
<title>Disambiguating Proteins, Genes,</title>
<date>2001</date>
<journal>and RNA in Text: A Machine Learning Approach. Bioinformatics,</journal>
<volume>17</volume>
<pages>97--106</pages>
<contexts>
<context position="3553" citStr="Hatzivassiloglou et al., 2001" startWordPosition="517" endWordPosition="520">tly introduce ad-hoc terms. Thus, the lack of clear naming conventions makes the automatic term recognition (ATR) task difficult even for languages that are not morphologically and derivationally rich. ATR tools have been developed for English (Frantzi et al., 2000), French (Jacquemin, 2001), Japanese (Nakagawa and Mori, 2000), etc. Some methods rely purely on linguistic information, namely morpho-syntactic features of term candidates (Ananiadou, 1994). Hybrid approaches combining linguistic patterns and statistical measures (e.g. (Frantzi et al., 2000)) and machine-learning techniques (e.g. (Hatzivassiloglou et al., 2001)) have been also used. However, few studies have been done for morphologically rich Slavic languages. For example, Vintar (2000) presented two methods for extraction of terminological collocations in order to assist the translation process in Slovene. The statistical approach was based on the mutual expectation and LocalMax measures, and involved collocation extraction from raw text. The extracted collocations were filtered with a stopword list, and only collocations containing single-word terms (devised previously by bilingual alignment) were accepted as relevant. In another approach, she use</context>
</contexts>
<marker>Hatzivassiloglou, Duboue, Rzetsky, 2001</marker>
<rawString>Hatzivassiloglou V., Duboue P. and Rzetsky A. 2001. Disambiguating Proteins, Genes, and RNA in Text: A Machine Learning Approach. Bioinformatics, 17/1, pp. S97-S106</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hearst</author>
</authors>
<title>Text Mining Tools: Instruments for Scientific Discovery, in IMA Text Mining Workshop, Institute for Mathematics and its Applications,</title>
<date>2000</date>
<location>Minneapolis, USA,</location>
<marker>Hearst, 2000</marker>
<rawString>Hearst M. 2000. Text Mining Tools: Instruments for Scientific Discovery, in IMA Text Mining Workshop, Institute for Mathematics and its Applications, Minneapolis, USA, 2000</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Jacquemin</author>
</authors>
<title>Spotting and discovering terms through NLP.</title>
<date>2001</date>
<volume>378</volume>
<pages>p.</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge MA,</location>
<contexts>
<context position="3215" citStr="Jacquemin, 2001" startWordPosition="475" endWordPosition="476">ng term dictionaries and standardised terminologies offer only a partial solution, as they are almost never up-todate. Although naming conventions do exist for some types of concepts (e.g. gene and protein names in biomedicine), these are only guidelines and as such do not impose restrictions to domain experts, who frequently introduce ad-hoc terms. Thus, the lack of clear naming conventions makes the automatic term recognition (ATR) task difficult even for languages that are not morphologically and derivationally rich. ATR tools have been developed for English (Frantzi et al., 2000), French (Jacquemin, 2001), Japanese (Nakagawa and Mori, 2000), etc. Some methods rely purely on linguistic information, namely morpho-syntactic features of term candidates (Ananiadou, 1994). Hybrid approaches combining linguistic patterns and statistical measures (e.g. (Frantzi et al., 2000)) and machine-learning techniques (e.g. (Hatzivassiloglou et al., 2001)) have been also used. However, few studies have been done for morphologically rich Slavic languages. For example, Vintar (2000) presented two methods for extraction of terminological collocations in order to assist the translation process in Slovene. The statis</context>
<context position="16109" citStr="Jacquemin, 2001" startWordPosition="2557" endWordPosition="2558">ic recognition of terms, then handling term variation has to be treated as an essential part of terminology retrieval. Term variation ranges from simple orthographic (e.g. oestrogen  estrogen, vitamin  vitamine) and morphological variants (e.g. clone – clones) to more complex semantic variation (e.g. eye surgery  ophthalmologic surgery). Several methods for term variation management have been developed. For example, the BLAST system (Krauthammer et al., 2000) used approximate text string matching techniques and dictionaries to recognise spelling variations in gene and protein names. FASTR (Jacquemin, 2001) handles morphological and syntactic variations by means of meta-rules used to describe term normalisation, while semantic variants are handled via WordNet. The necessity of taking term variants into account as part of ATR process becomes particularly apparent in highly inflective languages. In Serbian, for example, the simplest morphological variations generally give rise to 14 possible variants of a single term (seven cases and two numbers (singular and plural) — see Table 4). If the core C-value method were to be applied without conflating morphological variants, then termhoods would be dis</context>
</contexts>
<marker>Jacquemin, 2001</marker>
<rawString>Jacquemin C. 2001. Spotting and discovering terms through NLP. MIT Press, Cambridge MA, 378 p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Krauthammer</author>
<author>A Rzhetsky</author>
<author>P Morozov</author>
<author>C Friedman</author>
</authors>
<title>Using BLAST for identifying gene and protein names in journal articles.</title>
<date>2000</date>
<journal>Gene,</journal>
<volume>259</volume>
<pages>245--252</pages>
<contexts>
<context position="15959" citStr="Krauthammer et al., 2000" startWordPosition="2535" endWordPosition="2538">rostor + + kompletan metrički - - metrički prostor + + Table 3: Nested term candidates (in Serbian) 3.2 Conflating morphological variants If we aim at systematic recognition of terms, then handling term variation has to be treated as an essential part of terminology retrieval. Term variation ranges from simple orthographic (e.g. oestrogen  estrogen, vitamin  vitamine) and morphological variants (e.g. clone – clones) to more complex semantic variation (e.g. eye surgery  ophthalmologic surgery). Several methods for term variation management have been developed. For example, the BLAST system (Krauthammer et al., 2000) used approximate text string matching techniques and dictionaries to recognise spelling variations in gene and protein names. FASTR (Jacquemin, 2001) handles morphological and syntactic variations by means of meta-rules used to describe term normalisation, while semantic variants are handled via WordNet. The necessity of taking term variants into account as part of ATR process becomes particularly apparent in highly inflective languages. In Serbian, for example, the simplest morphological variations generally give rise to 14 possible variants of a single term (seven cases and two numbers (sin</context>
</contexts>
<marker>Krauthammer, Rzhetsky, Morozov, Friedman, 2000</marker>
<rawString>Krauthammer M., Rzhetsky A., Morozov P. and Friedman C. 2000. Using BLAST for identifying gene and protein names in journal articles. Gene, 259, pp. 245-252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Mima</author>
<author>K Ando</author>
<author>J Aoe</author>
</authors>
<title>Incremental Generation of LR(1) Parse Tables.</title>
<date>1995</date>
<booktitle>In Proceedings of NLPRS&apos;95, Pacific-Rim Symp.,</booktitle>
<location>Seoul,</location>
<contexts>
<context position="7517" citStr="Mima et al., 1995" startWordPosition="1133" endWordPosition="1136">ive to a particular type of terms � nested terms2. The method is implemented as a two-step procedure. In the first step, term candidates are extracted using a set of morpho-syntactic filters, which describe general term formation patterns in a given language. As a rule, terms form a proper subset of noun phrases (NPs). For example, a set of general filters for English may include the following patterns:3 Noun+ Noun (Adj |Noun)+ Noun (Adj |Noun)+ |((Adj |Noun)* Prep?) (Adj |Noun)* Noun Although these patterns are regular expressions, the filters are implemented as unification-like LR(1) rules (Mima et al., 1995) in order to facilitate processing of grammatical agreements (if any) within term candidates. For each term candidate extracted by a filter, a set of nested term candidates is generated (see Table 1 for an example in English). The procedure for the generation of nested term candidates is implemented via transformation rules for each morpho-syntactic filter that is used to extract 2 For example, nuclear receptor is a nested term in hormone nuclear receptor. Similarly, baza podataka (Engl. database) is a nested term in aiuriranje baze podataka (Engl. update of database). 3 Noun, Adj and Prep den</context>
</contexts>
<marker>Mima, Ando, Aoe, 1995</marker>
<rawString>Mima H., Ando K. and Aoe J. 1995: Incremental Generation of LR(1) Parse Tables. In Proceedings of NLPRS&apos;95, Pacific-Rim Symp., Seoul, Korea</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Nakagawa</author>
<author>T Mori</author>
</authors>
<title>Nested Collocation and Compound Noun for Term Recognition.</title>
<date>2000</date>
<booktitle>Proc. of COMPUTERM 98,</booktitle>
<pages>64--70</pages>
<contexts>
<context position="3251" citStr="Nakagawa and Mori, 2000" startWordPosition="478" endWordPosition="481">ndardised terminologies offer only a partial solution, as they are almost never up-todate. Although naming conventions do exist for some types of concepts (e.g. gene and protein names in biomedicine), these are only guidelines and as such do not impose restrictions to domain experts, who frequently introduce ad-hoc terms. Thus, the lack of clear naming conventions makes the automatic term recognition (ATR) task difficult even for languages that are not morphologically and derivationally rich. ATR tools have been developed for English (Frantzi et al., 2000), French (Jacquemin, 2001), Japanese (Nakagawa and Mori, 2000), etc. Some methods rely purely on linguistic information, namely morpho-syntactic features of term candidates (Ananiadou, 1994). Hybrid approaches combining linguistic patterns and statistical measures (e.g. (Frantzi et al., 2000)) and machine-learning techniques (e.g. (Hatzivassiloglou et al., 2001)) have been also used. However, few studies have been done for morphologically rich Slavic languages. For example, Vintar (2000) presented two methods for extraction of terminological collocations in order to assist the translation process in Slovene. The statistical approach was based on the mutu</context>
<context position="6027" citStr="Nakagawa and Mori, 2000" startWordPosition="890" endWordPosition="893">-syntactic clues, the normalisation approach and the foreign word recognition that are used for singling out terms in Serbian. The experiments and evaluation are described in Section 4. 2 Automatic Term Recognition: the core C-value method Our approach to ATR is based on the C-value method (Frantzi et al., 2000), which extracts multi-word terms. It is a general term recognition approach in the sense that it is not limited to specific classes of concepts. The approach is hybrid: the method combines linguistic knowledge (term 1 In English, more than 85% of domain-specific terms are multi-words (Nakagawa and Mori, 2000). formation patterns) and statistical analysis. Linguistic knowledge is used to single out term candidates, while their statistical features are used to measure the likelihood of term candidates being &amp;quot;real&amp;quot; terms. The method uses a POS tagged text as input, and outputs a list of extracted terms ranked according to their termhoods. Termhood is a numeric estimation of the degree to which a given linguistic unit (a multiword compound) is related to a domain-specific concept. However, the values are not normalised in the sense that a multiword, having a termhood value 10, is 10 times more likely </context>
</contexts>
<marker>Nakagawa, Mori, 2000</marker>
<rawString>Nakagawa H. and Mori T. 2000. Nested Collocation and Compound Noun for Term Recognition. Proc. of COMPUTERM 98, pp. 6470</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Nenadic</author>
<author>D Vitas</author>
</authors>
<date>1998</date>
<booktitle>Formal Model of Noun Phrases in Serbo-Croatian. BULAG 23, Universite Franche-Compte,</booktitle>
<location>Besangon, France.</location>
<marker>Nenadic, Vitas, 1998</marker>
<rawString>Nenadic G. and Vitas D. 1998a. Formal Model of Noun Phrases in Serbo-Croatian. BULAG 23, Universite Franche-Compte, Besangon, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Nenadic</author>
<author>D Vitas</author>
</authors>
<title>Using Local Grammars for Agreement Modelling in Highly Inflective Languages.</title>
<date>1998</date>
<booktitle>In Proceedings of TSD 98.</booktitle>
<pages>91--96</pages>
<institution>Masaryk University,</institution>
<location>Brno,</location>
<marker>Nenadic, Vitas, 1998</marker>
<rawString>Nenadic G. and Vitas D. 1998b. Using Local Grammars for Agreement Modelling in Highly Inflective Languages. In Proceedings of TSD 98. Masaryk University, Brno, pp. 91-96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Nenadic</author>
<author>H Mima</author>
<author>I Spasic</author>
<author>S Ananiadou</author>
<author>J Tsujii</author>
</authors>
<title>Terminology-driven Literature Mining and Knowledge Acquisition in Biomedicine.</title>
<date>2002</date>
<journal>International Journal of Medical Informatics,</journal>
<pages>1--16</pages>
<marker>Nenadic, Mima, Spasic, Ananiadou, Tsujii, 2002</marker>
<rawString>Nenadic G., Mima H., Spasic I., Ananiadou S. and Tsujii J. 2002. Terminology-driven Literature Mining and Knowledge Acquisition in Biomedicine. International Journal of Medical Informatics, 1-16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Spasic</author>
</authors>
<title>Automatic Foreign Words Recognition in a Serbian Scientific or Technical Text.</title>
<date>1996</date>
<booktitle>In Proceedings of Standardisation of Terminology,</booktitle>
<location>Belgrade, Yugoslavia,</location>
<marker>Spasic, 1996</marker>
<rawString>Spasic I. 1996. Automatic Foreign Words Recognition in a Serbian Scientific or Technical Text. In Proceedings of Standardisation of Terminology, Belgrade, Yugoslavia, 1996</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vintar</author>
</authors>
<title>Extracting Terms and Terminological Collocations from the ELAN Slovene-English Parallel Corpus.</title>
<date>2000</date>
<booktitle>In Proceedings of the 5th EAMT Workshop,</booktitle>
<location>Ljubljana, Slovenia,</location>
<contexts>
<context position="3681" citStr="Vintar (2000)" startWordPosition="539" endWordPosition="540">es that are not morphologically and derivationally rich. ATR tools have been developed for English (Frantzi et al., 2000), French (Jacquemin, 2001), Japanese (Nakagawa and Mori, 2000), etc. Some methods rely purely on linguistic information, namely morpho-syntactic features of term candidates (Ananiadou, 1994). Hybrid approaches combining linguistic patterns and statistical measures (e.g. (Frantzi et al., 2000)) and machine-learning techniques (e.g. (Hatzivassiloglou et al., 2001)) have been also used. However, few studies have been done for morphologically rich Slavic languages. For example, Vintar (2000) presented two methods for extraction of terminological collocations in order to assist the translation process in Slovene. The statistical approach was based on the mutual expectation and LocalMax measures, and involved collocation extraction from raw text. The extracted collocations were filtered with a stopword list, and only collocations containing single-word terms (devised previously by bilingual alignment) were accepted as relevant. In another approach, she used regular expression patterns to extract term collocations from a morphosyntactically tagged corpus. However, these patterns are</context>
</contexts>
<marker>Vintar, 2000</marker>
<rawString>Vintar 9. 2000. Extracting Terms and Terminological Collocations from the ELAN Slovene-English Parallel Corpus. In Proceedings of the 5th EAMT Workshop, Ljubljana, Slovenia, 2000</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Vitas</author>
</authors>
<title>Mathematical Model of SerboCroatian Morphology (Nominal Inflection). PhD thesis. Faculty of Mathematics,</title>
<date>1993</date>
<location>Belgrade.</location>
<contexts>
<context position="23629" citStr="Vitas, 1993" startWordPosition="3750" endWordPosition="3751"> (Engl. white)), as well as some nouns in masculine gender (e.g. smisao (Engl. sense)) also end with a pair of vowels. The usage of prefixes is another example where vowels may occur successively (e.g. za+ustaviti (Engl. to stop)). 4 Experiments and discussion The preliminary ATR experiments were conducted using the SRCE system on a corpus containing samples from university textbooks in mathematics9 and computer science10 (altogether 120k words). Texts were pre-processed, i.e. initially tagged, by a system of electronic dictionaries (edictionaries) containing simple nominal words for Serbian (Vitas, 1993). E-dictionaries contain exhaustive description of morpho-syntactic characteristics and are used for lexical recognition and initial lemmatisation of words that occur in a text. This process is realised by edictionary look-up, which results in an initially tagged text: each textual word is associated with its lemma(s) and corresponding morpho-syntactic categories (tags) retrieved from the e-dictionary. In general, e-dictionaries cannot resolve lexical ambiguities that result from the fact that there is no one-to-one correspondence between word forms and their morpho-syntactic features. There a</context>
</contexts>
<marker>Vitas, 1993</marker>
<rawString>Vitas D. 1993. Mathematical Model of SerboCroatian Morphology (Nominal Inflection). PhD thesis. Faculty of Mathematics, Belgrade.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>