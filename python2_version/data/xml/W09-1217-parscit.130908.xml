<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.033684">
<title confidence="0.999244">
A Joint Syntactic and Semantic Dependency Parsing System based on
Maximum Entropy Models
</title>
<author confidence="0.998176">
Buzhou Tang1 Lu Li2 Xinxin Li1 Xuan Wang2 Xiaolong Wang2
</author>
<affiliation confidence="0.950764">
Shenzhen Graduate School
Harbin Institute of Technology
</affiliation>
<address confidence="0.840723">
Shenzhen,518055, China
</address>
<email confidence="0.977834">
1{tangbuzhou,lixxin2}@gmail.com
2{lli,wangxuan,wangxl}@insun.hit.edu.cn
</email>
<sectionHeader confidence="0.998548" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999328388888889">
A joint syntactic and semantic dependency
parsing system submitted to the CoNLL-2009
shared task is presented in this paper. The
system is composed of three components: a
syntactic dependency parser, a predicate clas-
sifier and a semantic parser. The first-order
MSTParser is used as our syntactic depen-
dency pasrser. Projective and non-projective
MSTParsers are compared with each other on
seven languages. Predicate classification and
semantic parsing are both recognized as clas-
sification problem, and the Maximum Entropy
Models are used for them in our system. For
semantic parsing and predicate classifying, we
focus on finding optimized features on multi-
ple languages. The average Macro F1 Score
of our system is 73.97 for joint task in closed
challenge.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99998703125">
The task for CoNLL-2009 is an extension of the
CoNLL-2008 shared task to multiple languages: En-
glish (Surdeanu et al., 2008), Catalan plus Span-
ish (Mariona Taul´e et al., 2008), Chinese (Martha
Palmer et al., 2009), Czech (Jan Hajiˇc et al.,
2006), German (Aljoscha Burchardt et al., 2006) and
Japanese (Daisuke Kawahara et al., 2002). Com-
pared to the CoNLL-2008 shared task, the predi-
cates are given for us in semantic dependencies task.
Therefore, we have only need to label the semantic
roles of nouns and verbs, and the frames of predi-
cates.
In this paper, a joint syntactic and semantic de-
pendency parsing system submitted to the CoNLL-
2009 shared task is presented. The system is com-
posed of three components: a syntactic dependency
parser, a predicate classifier and a semantic parser.
The first-order MSTParser is used as our syntactic
dependency parser. Projective and non-projective
MSTParsers are compared with each other on seven
languages. The predicate classifier labeling the
frames of predicates and the semantic parser label-
ing the semantic roles of nouns and verbs for each
predicate are both recognized as classification prob-
lem, and the Maximum Entropy Models (MEs) are
used for them in our system. Among three com-
ponents, we mainly focus on the predicate classifier
and the semantic parser.
For semantic parsing and predicate classifying,
features of different types are selected to our sys-
tem. The effect of them on multiple languages will
be described in the following sections in detail.
</bodyText>
<sectionHeader confidence="0.978156" genericHeader="method">
2 System Description
</sectionHeader>
<bodyText confidence="0.997205285714286">
Generally Speaking, a syntactic and semantic de-
pendency parsing system is usually divided into four
separate subtasks: syntactic parsing, predicate iden-
tification, predicate classification, and semantic role
labeling. In the CoNLL-2009 shared task, the pred-
icate identification is not required, since the pred-
icates are given for us. Therefore, the system we
present is only composed of three components: a
syntactic dependency parser, a predicate classifier
and a semantic parser. The syntactic dependencies
are processed with the MSTParser 0.4.3b. The pred-
icates identification and semantic role label are pro-
cessed with MEs-based classifier respectively. Un-
like conventional systems, the predicates identifica-
</bodyText>
<page confidence="0.987992">
109
</page>
<note confidence="0.765966">
Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task, pages 109–113,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.980606333333333">
tion and the semantic parser are independent with
each other. Figure 1 is the architecture of our sys-
tem.
</bodyText>
<figureCaption confidence="0.997527">
Figure 1: System Architecture
</figureCaption>
<table confidence="0.9998874">
No Features No Features
1 w0 20 Lemma
2 p0 21 DEPREL
3 p−1 22 CHD POS
4 p1 23 CHD POS U
5 p−1p0 24 CHD REL
6 p0p1 25 CHD REL U
7 p−2p0 26 SIB REL
8 p0p2 27 SIB REL U
9 p−3p0 28 SIB POS
10 p0p3 29 SIB POS U
11 p−1p0p1 30 VERB V
12 w0p0 31 4+11
13 w0p−1p0 32 Indegree
14 w0p0p1 33 Outdegree
15 w0p−2p0 34 Degree
16 w0p0p2 35 ARG IN
17 w0p−3p0 36 ARG OUT
18 w0p0p3 37 ARG Degree
19 w0p−1p0p1 38 Span
</table>
<tableCaption confidence="0.9873">
Table 1: Features for Predicate Classification.
</tableCaption>
<bodyText confidence="0.999958571428571">
In our system, we firstly select an appropriate
mode (projective or non-projective) of Graph-based
Parser (MSTParser) for each language, then con-
struct the MEs-based predicates classification and
the MEs-based semantic parser with syntactic de-
pendency relationships and predicate classification
respectively.
</bodyText>
<subsectionHeader confidence="0.995024">
2.1 Syntactic Dependency Parsing
</subsectionHeader>
<bodyText confidence="0.999911125">
MSTParser (McDonald, 2008) is used as our syn-
tactic dependency parser. It is a state-of-the-art de-
pendency parser that searches for maximum span-
ning trees (MST) over directed graph. Both of pro-
jective and non-projective are supported by MST-
Parser. Our system employs the first-order frame-
work with projective and non-projective modes on
seven given languages.
</bodyText>
<subsectionHeader confidence="0.997497">
2.2 Predicate Classification
</subsectionHeader>
<bodyText confidence="0.9998818">
In this phase, we label the sense of each predicate
and the MEs are adopted for classification. Features
of different types are extracted for each predicate,
and an optimized combination of them is adopted in
our final system. Table 1 lists all features. 1-20 are
the features used in Li’s system (Lu Li et al., 2008),
and 21-31 are a part of the optimized features pre-
sented in Che’s system (Wanxiang Che et al., 2008)
In Table 1, ”w” denotes the word and ”p” de-
notes POS of the words. Features in the form of
part1 part2 denote the part2 of the part1, while fea-
tures in the form of part1+part2 denote the combi-
nation of the part1 and part2. ”CHD” and ”SIB” de-
note a sequence of the child and the sibling words
respectively, ”REL” denotes the type of relations,
”U” denotes the result after reducing the adjacent
duplicate tags to one, ”V” denotes whether the part
is a voice, ”In” and ”OUT” denote the in degree and
out degree, which denotes how many dependency
relations coming into this word and going away from
this word,and ”ARG” denotes the semantic roles of
the predicate. The ”Span” denotes the maximum
length between the predicate and its arguments. The
final optimized feature combination is :1-31 and 33-
37.
</bodyText>
<subsectionHeader confidence="0.999129">
2.3 Semantic Role Labeling
</subsectionHeader>
<bodyText confidence="0.999884666666667">
The semantic role labeling usually contains two sub-
tasks: argument identification and argument classi-
fication. In our system, we perform them in a single
</bodyText>
<page confidence="0.989531">
110
</page>
<bodyText confidence="0.9999128">
stage through one classifier, which specifies a par-
ticular role label to the argument candidates directly
and assigns ”NONE” label to the argument candi-
dates with no role. MEs are also adopted for classifi-
cation. For each word in a sentence, MEs gives each
candidate label (including semantic role labels and
none label) a probability for the predicate. The fea-
tures except for the feature (lemma plus sense num-
ber of the predicate in (Lu Li et al., 2008)) and the
features 32-38 in Table 1 are selected in our system.
</bodyText>
<sectionHeader confidence="0.99891" genericHeader="evaluation">
3 Experiments and Results
</sectionHeader>
<bodyText confidence="0.9999019">
We train the first-order MSTParser 1 with projective
and non-projective modes in terms of default param-
eters respectively. Our maximum entropy classifiers
are implemented with the Maximum Entropy Mod-
eling Toolkit 2 . The default classifier parameters are
used in our system except for iterations. All mod-
els are trained using all training data, and tested on
the whole development data and test data, with 64-
bit 3.00GHz Intel(R) Pentium(R) D CPU and 4.0G
memory.
</bodyText>
<subsectionHeader confidence="0.998456">
3.1 Syntactic Dependency Parsing
</subsectionHeader>
<bodyText confidence="0.999882">
Table 2 is a performance comparison between pro-
jective parser and non-projective parser on the devel-
opment data of seven languages. In Table 2, ”LAS”,
”ULAS” and ”LCS” denote as Labeled attachment
score, Unlabeled attachment score and Label accu-
racy score respectively.
The experiments show that Catalan, Chinese and
Spanish have projective property and others have
non-projective property.
</bodyText>
<subsectionHeader confidence="0.997955">
3.2 Predicate Classification
</subsectionHeader>
<bodyText confidence="0.996898">
To get the optimized system, three group features are
used for comparison.
</bodyText>
<listItem confidence="0.999851">
• group 1: features 1-20 in Table 1.
• group 2: features 1-31 in Table 1.
• group 3: all features in Table 1.
</listItem>
<bodyText confidence="0.995505666666667">
The performance of predicate classification on the
development data of the six languages, which con-
tain this subtask, are given in Table 3. The results
</bodyText>
<footnote confidence="0.999424">
1http://sourceforge.net/projects/mstparser.
2http://homepages.inf.ed.ac.uk/s0450736/maxent toolkit.html.
</footnote>
<table confidence="0.9999286">
LAS(%) ULAS(%) LCS(%)
Catalan 84.18 88.18 91.76
83.69 87.74 91.59
Chinese 72.58 77.06 82.07
62.85 69.47 73.00
Czech 72.79 81.40 80.93
73.18 81.86 81.30
English 86.89 90.29 91.50
86.88 90.34 91.58
German 83.43 86.89 90.24
84.00 87.40 90.61
Japanese 92.23 93.16 98.38
92.23 93.14 98.45
Spanish 83.88 87.93 91.36
83.46 87.46 91.37
</table>
<tableCaption confidence="0.995629">
Table 2: Performance of Syntactic Dependency
</tableCaption>
<bodyText confidence="0.6854675">
Parsing with different modes. The above line is the
performance of projective mode, while the below
one is the performance of non-projective mode for
each language.
</bodyText>
<table confidence="0.987358714285714">
group 1 group 2 group 3
Catalan 75.51 80.90 82.23
Chinese 93.79 94.99 94.75
Czech 91.83 91.77 91.86
English 92.12 92.48 93.20
German 74.49 74.14 75.85
Spanish 74.01 76.22 76.53
</table>
<tableCaption confidence="0.997184">
Table 3: Performance of predicate classification (F1
</tableCaption>
<bodyText confidence="0.9084095">
scores) for different group features on the develop-
ment data of the six languages.
show that Che’s features and the degrees of the pred-
icate and its arguments are useful for all languages,
the former improves the labeled F1 measure by 0.3%
to 5.4%, and the latter by 0.3% to 1.7%.
</bodyText>
<subsectionHeader confidence="0.998693">
3.3 Semantic Role Labeling
</subsectionHeader>
<bodyText confidence="0.999694666666667">
In this phase, feature selection and performance lose
caused by P-columns are studied. Firstly, we com-
pare the following two group features:
</bodyText>
<listItem confidence="0.936746">
• group 1: The features except for the lemma
plus sense number of the predicate in (Lu Li
et al., 2008).
</listItem>
<page confidence="0.995814">
111
</page>
<table confidence="0.984758681818182">
LF1 ULF1 PF1
Catalan 73.25 92.69 38.41
72.71 91.93 35.22
83.23 100.00 61.88
Chinese 69.60 82.15 28.35
71.49 81.71 29.41
85.44 95.21 58.20
Czech 80.62 92.49 70.04
79.10 91.44 68.34
85.42 96.93 77.78
English 73.91 87.26 33.16
76.10 88.58 36.28
79.35 91.74 43.32
German 64.85 88.05 27.21
65.36 88.63 26.70
72.78 94.54 41.50
Japanese 69.43 82.79 29.27
69.87 83.31 29.69
72.80 87.13 34.96
Spanish 73.49 93.15 39.64
78.18 91.68 33.57
81.96 99.98 59.20
</table>
<tableCaption confidence="0.729882">
Table 4: Performance of Semantic Role Labeling
(F1 score) with different features.
</tableCaption>
<listItem confidence="0.827219">
• group 2: group1+the degrees of the predicate
and its arguments presented in the last section.
</listItem>
<bodyText confidence="0.996427625">
Secondly, features extracted from golden-columns
and P-columns are both used for testing.
The performance of them are given in Table 4,
where ”LF1”, ”ULF1” and ”PF1” denote as Labeled
F1 score, Unlabeled F1 score and Proposition F1
score respectively. The above line is the F1 scores of
Semantic Role Labeling with different features. The
uppermost line is the result of group1 features, the
middle line is the result of group2 features extracted
from P-columns, and the downmost one is the result
of group2 features extracted from golden-columns
for each language.
The results show that the features of degree also
improves the labeled F1 measure by 3.4% to 15.8%,
the different labeled F1 between golden-columns
and P-columns is about 2.9%–13.9%.
</bodyText>
<table confidence="0.999931388888889">
LAS LF1 M LF1
Catalan 84.18 72.71 81.46
75.68 66.95 71.32
Chinese 72.58 71.49 72.20
63.95 67.06 65.53
Czech 73.18 79.10 76.37
72.60 79.08 75.85
Czech-ood 69.81 79.80 74.81
English 86.88 76.10 82.89
86.61 77.17 81.92
English-ood 80.09 67.21 73.69
German 84.00 65.36 83.06
79.85 61.98 70.93
German-ood 71.86 61.83 66.86
Japanese 92.23 69.87 83.77
91.26 69.58 80.49
Spanish 83.88 71.18 80.74
77.21 66.23 71.72
</table>
<tableCaption confidence="0.971057">
Table 5: Overall performance of our final joint sys-
tem.
</tableCaption>
<subsectionHeader confidence="0.995437">
3.4 Overall Performance
</subsectionHeader>
<bodyText confidence="0.999978666666667">
In the final system, we select the optimized feature
subset discussed in the former sections. The overall
performance of the system on the development data,
test data and Out-of-domain data are shown in Table
5 (all features are extracted from P-columns). The
average Macro F1 Scores of our system are 73.97
on test data and 71.79 on Out-of-domain data.
In Table 5, ”LAS”, ”LF1” and ”M LF1” denote
as Labeled accuracy score for Syntactic Dependency
Parsing, Labeled F1 score for Semantic Role Label-
ing, and Overall Macro Labeled F1 score respec-
tively. The topmost line is the result on the devel-
opment data, the middle one is the result on the test
data for each language and the downmost one is the
result on the Out-of-domain data if the data exist.
</bodyText>
<sectionHeader confidence="0.998209" genericHeader="conclusions">
4 Conclusion and Discussion
</sectionHeader>
<bodyText confidence="0.999975428571429">
We present a joint syntactic and semantic depen-
dency parsing system for CoNLL2009 Shared Task,
which composed of three components: a syntac-
tic dependency parser, a predicate classifier and a
semantic parser. All of them are built with some
state-of-the-art methods. For the predicate classifier
and the semantic parser, a new kind of features—
</bodyText>
<page confidence="0.994439">
112
</page>
<bodyText confidence="0.999944714285714">
degrees, which reflect the activeness of the words
in a sentence improves their performance. In order
to improve the performance further, we will study
new machine learning methods for semantic depen-
dency parsing, especially the joint learning methods,
which can avoid the information loss problem of our
system.
</bodyText>
<sectionHeader confidence="0.99809" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999932571428571">
We would like to thank McDonald for providing
the MSTParser program, to Zhang Le for provid-
ing the Maxent program. This research has been
partially supported by the National Natural Science
Foundation of China(No.60703015) and the Na-
tional 863 Program of China (No.2006AA01Z197,
No.2007AA01Z194).
</bodyText>
<sectionHeader confidence="0.999263" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.992190824561403">
Jan Hajiˇc and Massimiliano Ciaramita and Richard Jo-
hansson and Daisuke Kawahara and Maria Ant`onia
Martfand Llufs M`arquez and Adam Meyers and
Joakim Nivre and Sebastian Pad´o and Jan ˇStˇep´anek
and Pavel Straˇn´ak and Miahi Surdeanu and Nianwen
Xue and Yi Zhang. 2009. The CoNLL-2009 Shared
Task: Syntactic and Semantic Dependencies in Multi-
ple Languages. Proceedings of the 13th Conference on
Computational Natural Language Learning (CoNLL-
2009), June 4-5. Boulder, Colorado, USA.
Mariona Taul´e and Maria Ant`onia Martfand Marta Re-
casens. 2008. AnCora: Multilevel Annotated Cor-
pora for Catalan and Spanish. Proceedings of the 6th
International Conference on Language Resources and
Evaluation (LREC-2008). Marrakesh, Morroco.
Martha Palmer and Nianwen Xue. 2009. Adding seman-
tic roles to the Chinese Treebank. Natural Language
Engineering, 15(1),pages 143–172.
Jan Hajiˇc and Jarmila Panevov´a and Eva Hajiˇcov´a and
Petr Sgall and Petr Pajas and Jan ˇStˇep´anek and JiˇrfHavelka and Marie Mikulov´a and Zdenˇek ˇZabokrtsk´y.
2006. Prague Dependency Treebank 2.0. CD-ROM,
Cat. No. LDC2006T01, ISBN 1-58563-370-4. Lin-
guistic Data Consortium, Philadelphia, Pennsylvania,
USA. URL: http://ldc.upenn.edu.
Surdeanu, Mihai and Johansson, Richard and Meyers,
Adam and M`arquez, Llufs and Nivre, Joakim. 2008.
The CoNLL-2008 Shared Task on Joint Parsing of
Syntactic and Semantic Dependencies. Proceedings of
the 12th Conference on Computational Natural Lan-
guage Learning(CoNLL-2008).
Aljoscha Burchardt and Katrin Erk and Anette Frank and
Andrea Kowalski and Sebastian Pad´o and Manfred
Pinkal. 2006. The SALSA corpus: a German corpus
resource for lexical semantics. Proceedings of the 5rd
International Conference on Language Resources and
Evaluation (LREC-2006), pages 2008–2013. Genoa,
Italy.
Daisuke Kawahara and Sadao Kurohashi and Kˆoiti
Hasida. 2002. Construction of a Japanese Relevance-
tagged Corpus. Proceedings of the 3rd International
Conference on Language Resources and Evaluation
(LREC-2002), pages 2008–2013. Las Palmas, Canary
Islands.
McDonald and Ryan. 2006. Discriminative Learning
and Spanning Tree Algorithms for Dependency Pars-
ing, Ph.D. thesis. University of Pennsylvania.
Lu Li, Shixi Fan, Xuan Wang, XiaolongWang. 2008.
Discriminative Learning of Syntactic and Semantic
Dependencies. CoNLL 2008: Proceedings of the
12th Conference on Computational Natural Language
Learning, pages 218–222. Manchester.
Wanxiang Che, Zhenghua Li, Yuxuan Hu, Yongqiang Li,
Bing Qin, Ting Liu, Sheng Li. 2008. A Cascaded
Syntactic and Semantic Dependency Parsing System.
CoNLL 2008: Proceedings of the 12th Conference
on Computational Natural Language Learning, pages
238–242. Manchester.
</reference>
<page confidence="0.999319">
113
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.346213">
<title confidence="0.997055">A Joint Syntactic and Semantic Dependency Parsing System based Maximum Entropy Models</title>
<author confidence="0.99466">Lu Xinxin Xuan Xiaolong</author>
<affiliation confidence="0.9509895">Shenzhen Graduate Harbin Institute of</affiliation>
<address confidence="0.431084">Shenzhen,518055,</address>
<abstract confidence="0.993541315789474">A joint syntactic and semantic dependency parsing system submitted to the CoNLL-2009 shared task is presented in this paper. The system is composed of three components: a syntactic dependency parser, a predicate classifier and a semantic parser. The first-order MSTParser is used as our syntactic dependency pasrser. Projective and non-projective MSTParsers are compared with each other on seven languages. Predicate classification and semantic parsing are both recognized as classification problem, and the Maximum Entropy Models are used for them in our system. For semantic parsing and predicate classifying, we focus on finding optimized features on multiple languages. The average Macro F1 Score of our system is 73.97 for joint task in closed challenge.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Jan Hajiˇc</author>
<author>Massimiliano Ciaramita</author>
<author>Richard Johansson</author>
<author>Daisuke Kawahara</author>
<author>Maria Ant`onia</author>
</authors>
<title>Martfand Llufs M`arquez and Adam Meyers and</title>
<date>2009</date>
<booktitle>Joakim Nivre and Sebastian Pad´o and Jan ˇStˇep´anek and Pavel Straˇn´ak and Miahi Surdeanu and Nianwen Xue and</booktitle>
<pages>4--5</pages>
<location>Boulder, Colorado, USA.</location>
<marker>Hajiˇc, Ciaramita, Johansson, Kawahara, Ant`onia, 2009</marker>
<rawString>Jan Hajiˇc and Massimiliano Ciaramita and Richard Johansson and Daisuke Kawahara and Maria Ant`onia Martfand Llufs M`arquez and Adam Meyers and Joakim Nivre and Sebastian Pad´o and Jan ˇStˇep´anek and Pavel Straˇn´ak and Miahi Surdeanu and Nianwen Xue and Yi Zhang. 2009. The CoNLL-2009 Shared Task: Syntactic and Semantic Dependencies in Multiple Languages. Proceedings of the 13th Conference on Computational Natural Language Learning (CoNLL2009), June 4-5. Boulder, Colorado, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mariona Taul´e</author>
<author>Maria Ant`onia Martfand Marta Recasens</author>
</authors>
<title>AnCora: Multilevel Annotated Corpora for Catalan and Spanish.</title>
<date>2008</date>
<booktitle>Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC-2008). Marrakesh,</booktitle>
<location>Morroco.</location>
<marker>Taul´e, Recasens, 2008</marker>
<rawString>Mariona Taul´e and Maria Ant`onia Martfand Marta Recasens. 2008. AnCora: Multilevel Annotated Corpora for Catalan and Spanish. Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC-2008). Marrakesh, Morroco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Nianwen Xue</author>
</authors>
<title>Adding semantic roles to the Chinese Treebank.</title>
<date>2009</date>
<journal>Natural Language Engineering,</journal>
<volume>15</volume>
<issue>1</issue>
<pages>143--172</pages>
<marker>Palmer, Xue, 2009</marker>
<rawString>Martha Palmer and Nianwen Xue. 2009. Adding semantic roles to the Chinese Treebank. Natural Language Engineering, 15(1),pages 143–172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Jarmila Panevov´a</author>
<author>Eva Hajiˇcov´a</author>
<author>Petr Sgall</author>
<author>Petr Pajas</author>
<author>Jan ˇStˇep´anek</author>
<author>JiˇrfHavelka</author>
<author>Marie Mikulov´a</author>
<author>Zdenˇek ˇZabokrtsk´y</author>
</authors>
<date>2006</date>
<booktitle>Prague Dependency Treebank 2.0. CD-ROM, Cat. No. LDC2006T01, ISBN 1-58563-370-4. Linguistic Data Consortium,</booktitle>
<location>Philadelphia, Pennsylvania, USA. URL: http://ldc.upenn.edu.</location>
<marker>Hajiˇc, Panevov´a, Hajiˇcov´a, Sgall, Pajas, ˇStˇep´anek, JiˇrfHavelka, Mikulov´a, ˇZabokrtsk´y, 2006</marker>
<rawString>Jan Hajiˇc and Jarmila Panevov´a and Eva Hajiˇcov´a and Petr Sgall and Petr Pajas and Jan ˇStˇep´anek and JiˇrfHavelka and Marie Mikulov´a and Zdenˇek ˇZabokrtsk´y. 2006. Prague Dependency Treebank 2.0. CD-ROM, Cat. No. LDC2006T01, ISBN 1-58563-370-4. Linguistic Data Consortium, Philadelphia, Pennsylvania, USA. URL: http://ldc.upenn.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Richard Johansson</author>
<author>Adam Meyers</author>
<author>Llufs M`arquez</author>
<author>Joakim Nivre</author>
</authors>
<date>2008</date>
<booktitle>The CoNLL-2008 Shared Task on Joint Parsing of Syntactic and Semantic Dependencies. Proceedings of the 12th Conference on Computational Natural Language Learning(CoNLL-2008).</booktitle>
<marker>Surdeanu, Johansson, Meyers, M`arquez, Nivre, 2008</marker>
<rawString>Surdeanu, Mihai and Johansson, Richard and Meyers, Adam and M`arquez, Llufs and Nivre, Joakim. 2008. The CoNLL-2008 Shared Task on Joint Parsing of Syntactic and Semantic Dependencies. Proceedings of the 12th Conference on Computational Natural Language Learning(CoNLL-2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aljoscha Burchardt</author>
<author>Katrin Erk</author>
<author>Anette Frank</author>
<author>Andrea Kowalski</author>
<author>Sebastian Pad´o</author>
<author>Manfred Pinkal</author>
</authors>
<title>The SALSA corpus: a German corpus resource for lexical semantics.</title>
<date>2006</date>
<booktitle>Proceedings of the 5rd International Conference on Language Resources and Evaluation (LREC-2006),</booktitle>
<pages>2008--2013</pages>
<location>Genoa, Italy.</location>
<marker>Burchardt, Erk, Frank, Kowalski, Pad´o, Pinkal, 2006</marker>
<rawString>Aljoscha Burchardt and Katrin Erk and Anette Frank and Andrea Kowalski and Sebastian Pad´o and Manfred Pinkal. 2006. The SALSA corpus: a German corpus resource for lexical semantics. Proceedings of the 5rd International Conference on Language Resources and Evaluation (LREC-2006), pages 2008–2013. Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daisuke Kawahara</author>
<author>Sadao Kurohashi</author>
<author>Kˆoiti Hasida</author>
</authors>
<title>Construction of a Japanese Relevancetagged Corpus.</title>
<date>2002</date>
<booktitle>Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC-2002),</booktitle>
<pages>2008--2013</pages>
<location>Las Palmas, Canary Islands.</location>
<contexts>
<context position="1415" citStr="Kawahara et al., 2002" startWordPosition="205" endWordPosition="208">ion problem, and the Maximum Entropy Models are used for them in our system. For semantic parsing and predicate classifying, we focus on finding optimized features on multiple languages. The average Macro F1 Score of our system is 73.97 for joint task in closed challenge. 1 Introduction The task for CoNLL-2009 is an extension of the CoNLL-2008 shared task to multiple languages: English (Surdeanu et al., 2008), Catalan plus Spanish (Mariona Taul´e et al., 2008), Chinese (Martha Palmer et al., 2009), Czech (Jan Hajiˇc et al., 2006), German (Aljoscha Burchardt et al., 2006) and Japanese (Daisuke Kawahara et al., 2002). Compared to the CoNLL-2008 shared task, the predicates are given for us in semantic dependencies task. Therefore, we have only need to label the semantic roles of nouns and verbs, and the frames of predicates. In this paper, a joint syntactic and semantic dependency parsing system submitted to the CoNLL2009 shared task is presented. The system is composed of three components: a syntactic dependency parser, a predicate classifier and a semantic parser. The first-order MSTParser is used as our syntactic dependency parser. Projective and non-projective MSTParsers are compared with each other on</context>
</contexts>
<marker>Kawahara, Kurohashi, Hasida, 2002</marker>
<rawString>Daisuke Kawahara and Sadao Kurohashi and Kˆoiti Hasida. 2002. Construction of a Japanese Relevancetagged Corpus. Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC-2002), pages 2008–2013. Las Palmas, Canary Islands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>McDonald</author>
<author>Ryan</author>
</authors>
<title>Discriminative Learning and Spanning Tree Algorithms for Dependency Parsing,</title>
<date>2006</date>
<tech>Ph.D. thesis.</tech>
<institution>University of Pennsylvania.</institution>
<marker>McDonald, Ryan, 2006</marker>
<rawString>McDonald and Ryan. 2006. Discriminative Learning and Spanning Tree Algorithms for Dependency Parsing, Ph.D. thesis. University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lu Li</author>
<author>Shixi Fan</author>
<author>Xuan Wang</author>
<author>XiaolongWang</author>
</authors>
<title>Discriminative Learning of Syntactic and Semantic Dependencies. CoNLL</title>
<date>2008</date>
<booktitle>Proceedings of the 12th Conference on Computational Natural Language Learning,</booktitle>
<pages>218--222</pages>
<location>Manchester.</location>
<contexts>
<context position="5158" citStr="Li et al., 2008" startWordPosition="809" endWordPosition="812">e-art dependency parser that searches for maximum spanning trees (MST) over directed graph. Both of projective and non-projective are supported by MSTParser. Our system employs the first-order framework with projective and non-projective modes on seven given languages. 2.2 Predicate Classification In this phase, we label the sense of each predicate and the MEs are adopted for classification. Features of different types are extracted for each predicate, and an optimized combination of them is adopted in our final system. Table 1 lists all features. 1-20 are the features used in Li’s system (Lu Li et al., 2008), and 21-31 are a part of the optimized features presented in Che’s system (Wanxiang Che et al., 2008) In Table 1, ”w” denotes the word and ”p” denotes POS of the words. Features in the form of part1 part2 denote the part2 of the part1, while features in the form of part1+part2 denote the combination of the part1 and part2. ”CHD” and ”SIB” denote a sequence of the child and the sibling words respectively, ”REL” denotes the type of relations, ”U” denotes the result after reducing the adjacent duplicate tags to one, ”V” denotes whether the part is a voice, ”In” and ”OUT” denote the in degree and</context>
<context position="6702" citStr="Li et al., 2008" startWordPosition="1078" endWordPosition="1081">ng The semantic role labeling usually contains two subtasks: argument identification and argument classification. In our system, we perform them in a single 110 stage through one classifier, which specifies a particular role label to the argument candidates directly and assigns ”NONE” label to the argument candidates with no role. MEs are also adopted for classification. For each word in a sentence, MEs gives each candidate label (including semantic role labels and none label) a probability for the predicate. The features except for the feature (lemma plus sense number of the predicate in (Lu Li et al., 2008)) and the features 32-38 in Table 1 are selected in our system. 3 Experiments and Results We train the first-order MSTParser 1 with projective and non-projective modes in terms of default parameters respectively. Our maximum entropy classifiers are implemented with the Maximum Entropy Modeling Toolkit 2 . The default classifier parameters are used in our system except for iterations. All models are trained using all training data, and tested on the whole development data and test data, with 64- bit 3.00GHz Intel(R) Pentium(R) D CPU and 4.0G memory. 3.1 Syntactic Dependency Parsing Table 2 is a</context>
<context position="9472" citStr="Li et al., 2008" startWordPosition="1517" endWordPosition="1520">6.22 76.53 Table 3: Performance of predicate classification (F1 scores) for different group features on the development data of the six languages. show that Che’s features and the degrees of the predicate and its arguments are useful for all languages, the former improves the labeled F1 measure by 0.3% to 5.4%, and the latter by 0.3% to 1.7%. 3.3 Semantic Role Labeling In this phase, feature selection and performance lose caused by P-columns are studied. Firstly, we compare the following two group features: • group 1: The features except for the lemma plus sense number of the predicate in (Lu Li et al., 2008). 111 LF1 ULF1 PF1 Catalan 73.25 92.69 38.41 72.71 91.93 35.22 83.23 100.00 61.88 Chinese 69.60 82.15 28.35 71.49 81.71 29.41 85.44 95.21 58.20 Czech 80.62 92.49 70.04 79.10 91.44 68.34 85.42 96.93 77.78 English 73.91 87.26 33.16 76.10 88.58 36.28 79.35 91.74 43.32 German 64.85 88.05 27.21 65.36 88.63 26.70 72.78 94.54 41.50 Japanese 69.43 82.79 29.27 69.87 83.31 29.69 72.80 87.13 34.96 Spanish 73.49 93.15 39.64 78.18 91.68 33.57 81.96 99.98 59.20 Table 4: Performance of Semantic Role Labeling (F1 score) with different features. • group 2: group1+the degrees of the predicate and its arguments </context>
</contexts>
<marker>Li, Fan, Wang, XiaolongWang, 2008</marker>
<rawString>Lu Li, Shixi Fan, Xuan Wang, XiaolongWang. 2008. Discriminative Learning of Syntactic and Semantic Dependencies. CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 218–222. Manchester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wanxiang Che</author>
<author>Zhenghua Li</author>
<author>Yuxuan Hu</author>
<author>Yongqiang Li</author>
<author>Bing Qin</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>A Cascaded Syntactic and Semantic Dependency Parsing System. CoNLL</title>
<date>2008</date>
<booktitle>Proceedings of the 12th Conference on Computational Natural Language Learning,</booktitle>
<pages>238--242</pages>
<location>Manchester.</location>
<contexts>
<context position="5260" citStr="Che et al., 2008" startWordPosition="828" endWordPosition="831">rojective and non-projective are supported by MSTParser. Our system employs the first-order framework with projective and non-projective modes on seven given languages. 2.2 Predicate Classification In this phase, we label the sense of each predicate and the MEs are adopted for classification. Features of different types are extracted for each predicate, and an optimized combination of them is adopted in our final system. Table 1 lists all features. 1-20 are the features used in Li’s system (Lu Li et al., 2008), and 21-31 are a part of the optimized features presented in Che’s system (Wanxiang Che et al., 2008) In Table 1, ”w” denotes the word and ”p” denotes POS of the words. Features in the form of part1 part2 denote the part2 of the part1, while features in the form of part1+part2 denote the combination of the part1 and part2. ”CHD” and ”SIB” denote a sequence of the child and the sibling words respectively, ”REL” denotes the type of relations, ”U” denotes the result after reducing the adjacent duplicate tags to one, ”V” denotes whether the part is a voice, ”In” and ”OUT” denote the in degree and out degree, which denotes how many dependency relations coming into this word and going away from thi</context>
</contexts>
<marker>Che, Li, Hu, Li, Qin, Liu, Li, 2008</marker>
<rawString>Wanxiang Che, Zhenghua Li, Yuxuan Hu, Yongqiang Li, Bing Qin, Ting Liu, Sheng Li. 2008. A Cascaded Syntactic and Semantic Dependency Parsing System. CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 238–242. Manchester.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>