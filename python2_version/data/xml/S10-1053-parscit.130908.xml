<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.028692">
<title confidence="0.918579">
UvT-WSD1: a Cross-Lingual Word Sense Disambiguation system
</title>
<author confidence="0.888776">
Maarten van Gompel
</author>
<affiliation confidence="0.955024">
Tilburg centre for Cognition and Communication
Tilburg University
</affiliation>
<email confidence="0.979483">
proycon@anaproy.nl
</email>
<sectionHeader confidence="0.99341" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999930947368421">
This paper describes the Cross-Lingual
Word Sense Disambiguation system UvT-
WSD1, developed at Tilburg University,
for participation in two SemEval-2 tasks:
the Cross-Lingual Word Sense Disam-
biguation task and the Cross-Lingual Lex-
ical Substitution task. The UvT-WSD1
system makes use of k-nearest neighbour
classifiers, in the form of single-word ex-
perts for each target word to be disam-
biguated. These classifiers can be con-
structed using a variety of local and global
context features, and these are mapped
onto the translations, i.e. the senses,
of the words. The system works for a
given language-pair, either English-Dutch
or English-Spanish in the current imple-
mentation, and takes a word-aligned par-
allel corpus as its input.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999810684210527">
The UvT-WSD1 system described in this paper
took part in two similar SemEval-2 tasks: Cross-
Lingual Word Sense Disambiguation (Lefever and
Hoste, 2010) and Cross-Lingual Lexical Substitu-
tion (Mihalcea et al., 2010). In each task, a num-
ber of words is selected for which the senses are to
be determined for a number of instances of these
words. For each word, a number of samples in
context is provided, where each sample consists of
one sentence, with the word to be disambiguated
marked.
Because of the cross-lingual nature of the tasks,
a word sense corresponds to a translation in an-
other language, rather than a sense description in
the same language. In the Cross-lingual Lexical
Substitution task, the target language is Spanish.
The task is to find Spanish substitutes for the En-
glish words marked in the test samples. In the
Cross-Lingual Word Sense Disambiguation task,
we participate for English-Dutch and English-
Spanish. The Word Sense Disambiguation task
provides training data for all five languages, in the
form of the sentence-aligned EuroParl parallel cor-
pus (Koehn, 2005). This is the source of training
data the UvT-WSD1 system uses for both tasks.
The system may output several senses per in-
stance, rather than producing just one sense pre-
diction. These are evaluated in two different ways.
The scoring type “best” expects that the system
outputs the best senses, in the order of its con-
fidence. The scoring type “out of five/ten” ex-
pects five or ten guesses, and each answer weighs
the same. These metrics are more extensively
described in (Mihalcea et al., 2010). The UvT-
WSD1 system participates in both scoring types,
for both tasks. The system put forth in this paper
follows a similar approach as described in earlier
research by (Hoste et al., 2002).
</bodyText>
<sectionHeader confidence="0.978542" genericHeader="method">
2 System Description
</sectionHeader>
<bodyText confidence="0.999918105263158">
The UvT-WSD1 system uses machine learning
techniques to learn what senses/translations are as-
sociated with any of the target words. It does
so on the basis of a variety of local and global
context features, discussed in Section 2.2. At the
core of the system are the classifiers, or so called
“word experts”, one per target word. These are
built using the Tilburg Memory Based Learner
(TiMBL) (Daelemans et al., 2009), making use
of the IB1 algorithm, an implementation of the k-
nearest neighbour classifier.
The core of the system can be subdivided into
roughly three stages. In the first stage, the word-
aligned parallel corpus is read and for each found
instance of one of the target words, features are ex-
tracted to be used in the classifier. The class con-
sists of the word aligned to the found instance of
the target word, i.e. the translation/sense. In this
way a word expert is built for each of the target
</bodyText>
<page confidence="0.958431">
238
</page>
<bodyText confidence="0.963757782608696">
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 238–241,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
words in the task, yielding a total amount of clas-
sifiers equal to the total amount of target words.
The test data is processed in a similar way, for
each marked occurrence of any of the target words,
features are extracted and test instances are cre-
ated. Subsequently, the word experts are trained
and tested, and on the basis of the training data, a
parameter search algorithm (Van den Bosch, 2004)
determines the optimal set of classifier parameters
for each word expert, including for example the
value of k and the distance weighting metric used.
In the last phase, the classifier output of each
word expert is parsed. The classifiers yield a dis-
tribution of classes per test instance, and these are
converted to the appropriate formats for “best” and
“out of five/ten” evaluation. For the latter scor-
ing type, the five/ten highest scoring senses are
selected, for the former scoring type, all classes
scoring above a certain threshold are considered
“best”. The threshold is set at 90% of the score of
the highest scoring class.
</bodyText>
<subsectionHeader confidence="0.973730333333333">
2.1 Word-Alignment, Tokenisation,
Lemmatisation and
Part-of-Speech-tagging
</subsectionHeader>
<bodyText confidence="0.986674777777778">
The Europarl parallel corpus, English-Spanish and
English-Dutch, is delivered as a sentence-aligned
parallel corpus. We subsequently run GIZA++
(Och and Ney, 2000) to compute a word-aligned
parallel corpus.
This, however, is not the sole input. The tar-
get words in both tasks are actually specified as
a lemma and part-of-speech tag pair, rather than
words. In the Word Sense Disambiguation task, all
target lemmas are simply nouns, but in the Cross-
Lingual Lexical Substitution task, they can also be
verbs, adjectives or adverbs. Likewise, both tasks
expect the sense/translation output to also be in the
form of lemmas. Therefore the system internally
has to be aware of the lemma and part-of-speech
tag of each word in the parallel corpus and test
data, only then can it successfully find all occur-
rences of the target words. In order to get this
information, both sides of the word-aligned paral-
lel corpus are run through tokenisers, lemmatisers
and Part-of-Speech taggers, and the tokenised out-
put is realigned with the untokenised input so the
word alignments are retained. The test data is also
processed this way. For English and Spanish, the
software suite Freeling (Atserias et al., 2006) per-
formed all these tasks, and for Dutch it was done
by Tadpole (Van den Bosch et al., 2007).
</bodyText>
<subsectionHeader confidence="0.998103">
2.2 Feature Extraction
</subsectionHeader>
<bodyText confidence="0.9999894375">
The system can extract a variety of features to be
used in training and testing. A distinction can be
made between local context features and global
context features. Local context features are ex-
tracted from the immediate neighbours of the oc-
currence of the target word. One or more of the
following local context features are extractable by
the UvT-WSD1 system: word features, lemma
features, and part-of-speech tag features. In each
case, n features both to the right and left of the
focus word are selected. Moreover, the system
also supports the extraction of bigram features, but
these did not perform well in the experiments.
The global context features are made up of a
bag-of-words representation of keywords that may
be indicative for a given word to sense/translation
mapping. The idea is that words are collected
which have a certain power of discrimination for
the specific target word with a specific sense,
and all such words are then put in a bag-of-word
representation, yielding as many features as the
amount of keywords found. A global count over
the full corpus is needed to find these keywords.
Each keyword acts as a binary feature, indicating
whether or not that particular keyword is found in
the context of the occurrence of the target word.
The context in which these keywords are searched
for is exactly one sentence, i.e. the sentence in
which the target word occurs. This is due to the
test data simply not supplying a wider context.
The method used to extract these keywords (k)
is proposed by (Ng and Lee, 1996) and used also
in the research of (Hoste et al., 2002). Assume we
have a focus word f, more precisely, a lemma and
part-of-speech tag pair of one of the target words.
We also have one of its aligned translations/senses
s, which in this implementation is also a lemma.
We can now estimate P(slk), the probability of
sense s, given a keyword k, by dividing Ns,k,oca,.
(the number of occurrences of a possible local
context word k with particular focus word lemma-
PoS combination and with a particular sense s) by
Nk,o,a, (the number of occurrences of a possible
local context keyword kloc with a particular focus
word-PoS combination regardless of its sense). If
we also take into account the frequency of a pos-
sible keyword k in the complete training corpus
(Nk,o,,,,), we get:
</bodyText>
<page confidence="0.932137">
239
</page>
<equation confidence="0.833388666666667">
(  |) — N3 klocal ( 1 ) l )
Psk — 1
Nklocal Nkcorpus
</equation>
<bodyText confidence="0.998646692307692">
(Hoste et al., 2002) select a keyword k for in-
clusion in the bag-of-words representation if that
keyword occurs more than T1 times in that sense
s, and if P(s|k) ≥ T2. Both T1 and T2 are pre-
defined thresholds, which by default were set to 3
and 0.001 respectively. In addition, UvT-WSD1
contains an extra parameter which can be enabled
to automatically adjust the T1 threshold when it
yields too many or too few keywords. The selec-
tion of bag-of-word features is computed prior to
the extraction of the training instances, as this in-
formation is a prerequisite for the successful gen-
eration of both training and test instances.
</bodyText>
<subsectionHeader confidence="0.999683">
2.3 Voting system
</subsectionHeader>
<bodyText confidence="0.999991">
The local and global context features, and the var-
ious parameters that can be configured for extrac-
tion, yield a lot of possible classifier combinations.
Rather than merging all local context and global
context features together in a single classifier, they
can also be split over several classifiers and have
an arbiter voting system do the final classification
step. UvT-WSD1 also supports this approach. A
voter is constructed by taking as features the class
output of up to three different classifiers, trained
and tested on the training data, and mapping these
features onto the actual correct sense in the train-
ing data. For testing, the same approach is taken:
up to three classifiers run on the test data; their out-
put is taken as feature vector, and the voting sys-
tem predicts a sense. This approach may be useful
in boosting results and smoothing out errors. In
our experiments we see that a voter combination
often performs better than taking all features to-
gether in one single classifier. Finally, also in the
voter system there is a stage of automatic parame-
ter optimisation for TiMBL.
</bodyText>
<sectionHeader confidence="0.997934" genericHeader="evaluation">
3 Experiments and Results
</sectionHeader>
<bodyText confidence="0.999867333333333">
Both SemEval-2 tasks have provided trial data
upon which the system could be tested during the
development stage. Considering the high config-
urability of the various parameters for feature ex-
traction, the search space in possible configura-
tions and classifier parameters is vast, also due
to fact that the TiMBL classifier used may take a
wealth of possible parameters. As already men-
tioned, for the latter an automatic algorithm of pa-
</bodyText>
<table confidence="0.999472875">
BEST UvT-WSD1-v UvT-WSD1-g
Precision &amp; Recall 21.09 19.59
Mode Prec. &amp; Rec. 43.76 41.02
Ranking (out of 14) 6 9
OUT OF TEN UvT-WSD1-v UvT-WSD1-g
Precision &amp; Recall 58.91 55.29
Mode Prec. &amp; Rec. 62.96 73.94
Ranking 3 4
</table>
<tableCaption confidence="0.8031865">
Table 1: UvT-WSD1 results in the Cross-Lingual Lexical
Substitution task
</tableCaption>
<bodyText confidence="0.999481888888889">
rameter optimisation was used (Van den Bosch,
2004), but optimisation of the feature extraction
parameters has not been automated. Rather, a se-
lection of configurations has been manually cho-
sen and tested during the development stage.
The following two configurations of features
were found to perform amongst the best on the
trial data. Therefore they have been selected and
submitted for the contest:
</bodyText>
<listItem confidence="0.9028733">
1. UvT-WSD1-v (aka UvT-v) – An arbiter-
voting system over three classifiers: 1) Word
experts with two word features and lemma
features on both sides of the focus word.
2)Word experts with global features1. 3)
Word experts with two word features, two
lemma features and two part-of-speech tag
features.
2. UvT-WSD1-g (aka UvT-g) – Word experts
with global features only.
</listItem>
<bodyText confidence="0.9997698">
Table 1 shows a condensed view of the results
for the Cross-Lingual Lexical Substitution task.
Table 2 shows the final results for the Word-Sense
Disambiguation task. Note that UvT-WSD1-v and
UvT-WSD1-g are two different configurations of
the UvT-WSD1 system, and to conserve space
these are abbreviated as UvT-v and UvT-g respec-
tively. These are also the names used in both tasks
(Lefever and Hoste, 2010; Mihalcea et al., 2010)
to refer to our system.
</bodyText>
<sectionHeader confidence="0.946716" genericHeader="conclusions">
4 Discussion and Conclusion
</sectionHeader>
<bodyText confidence="0.685494">
Cross-Lingual Word Sense Disambiguation and
Cross-Lingual Lexical Substitution have proven to
be hard tasks, with scores that are relatively close
to baseline. This can be attributed to a noticeable
trait in the system output to be inclined to assign
the same majority sense to all instances.
</bodyText>
<footnote confidence="0.997676">
1For the Cross-Lingual Lexical Substitution task only, the
parameter to recompute the Tl threshold automatically was
enabled.
</footnote>
<page confidence="0.978162">
240
</page>
<table confidence="0.999882583333333">
Dutch BEST UvT-v UvT-g T3-COLEUR
Precision &amp; Recall 17.7 15.93 10.72 &amp; 10.56
Mode Prec. &amp; Rec. 12.06 10.54 6.18 &amp; 6.16
Dutch OUT OF FIVE UvT-v UvT-g T3-COLEUR
Precision &amp; Recall 34.95 34.92 21.54 &amp; 21.22
Mode Prec. &amp; Rec. 24.62 19.72 12.05 &amp; 12.03
Spanish BEST UvT-v UHD-1 UvT-g T3-COLEUR FCC-WSD1
Precision &amp; Recall 23.42 20.48 &amp; 16.33 19.92 19.78 &amp; 19.59 15.09
Mode Prec. &amp; Rec. 24.98 28.48 &amp; 22.19 24.17 24.59 14.31
Spanish OUT OF FIVE UvT-g UvT-v FCC-WSD2 UHD-1 T3-COLEUR
Precision &amp; Recall 43.12 42.17 40.76 38.78 &amp; 31.81 35.84 &amp; 35.46
Mode Prec. &amp; Rec. 43.94 40.62 44.84 40.68 &amp; 32.38 39.01 &amp; 38.78
</table>
<tableCaption confidence="0.998195">
Table 2: UvT-WSD1 results in comparison to other participants in the Word-Sense Disambiguation task
</tableCaption>
<bodyText confidence="0.999957103448276">
In our system, we used the same configuration
of feature extraction, or a voter over a set of con-
figurations, for all word experts. The actual classi-
fier parameters however, do differ per word expert,
as they are the result of the automatic parameter
optimisation algorithm. Selecting different feature
extraction configurations per word expert would
be a logical next step to attempt to boost results
even further, as been done in (Decadt et al., 2004).
Keeping in mind the fact that different word ex-
perts may perform differently, some general con-
clusions can be drawn from the experiments on
the trial data. It appears to be beneficial to in-
clude lemma features, rather than just word fea-
tures. However, adding Part-of-speech features
tends to have a negative impact. For these lo-
cal context features, the optimum context size is
often two features to the left and two features to
the right of the focus word, cf. (Hendrickx et al.,
2002). The global keyword features perform well,
but best results are achieved if they are not mixed
with the local context features in one classifier.
An arbiter voting approach over multiple clas-
sifiers helps to smooth out errors and yields the
highest scores (see Tables 1 and 2). When com-
pared to the other participants, the UvT-WSD1
system, in the voting configuration, ranks first in
the Word Sense Disambiguation task, for the two
language pairs in which we participated.
</bodyText>
<sectionHeader confidence="0.998924" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998739767857143">
Jordi Atserias, Bernardino Casas, Elisabet Comelles, Mer-
itxell Gonzlez, Llu´ıs Padr´o, and Muntsa Padr´o. 2006.
FreeLing 1.3: Syntactic and semantic services in an open-
source NLP library . In Proceedings of the Fifth Interna-
tional Conference on Language Resources and Evaluation
(LREC 2006), Genoa, Italy. ELRA.
W. Daelemans, J. Zavrel, K. Van der Sloot, and A. Van den
Bosch. 2009. TiMBL: Tilburg memory based learner, ver-
sion 6.2, reference guide. Technical Report ILK 09-01,
ILK Research Group, Tilburg University.
B. Decadt, V. Hoste, W. Daelemans, and A. Van den
Bosch. 2004. GAMBL, genetic algorithm optimization
of memory-based WSD. In R. Mihalcea and P. Edmonds,
editors, Proceedings of the Third International Workshop
on the Evaluation of Systems for the Semantic Analysis of
Text (Senseval-3), pages 108–112, New Brunswick, NJ.
ACL.
I. Hendrickx, A. Van den Bosch, V. Hoste, and W. Daele-
mans. 2002. Dutch word sense disambiguation: Optimiz-
ing the localness of context. In Proceedings of the Work-
shop on word sense disambiguation: Recent successes and
future directions, pages 61–65, Philadelphia, PA.
V. Hoste, I. Hendrickx, W. Daelemans, and A. Van den
Bosch. 2002. Parameter optimization for machine learn-
ing of word sense disambiguation. Natural Language En-
gineering, 8(4):311–325.
Philipp Koehn. 2005. Europarl: A parallel corpus for statisti-
cal machine translation. In In Proceedings of the Machine
Translation Summit X ([MT]’05)., pages 79–86.
Els Lefever and Veronique Hoste. 2010. Semeval 2010 task
3: Cross-lingual word sense disambiguation. In Proceed-
ings of the 5th International Workshop on Semantic Eval-
uations (SemEval-2010), Uppsala, Sweden.
Rada Mihalcea, Ravi Sinha, and Diana McCarthy. 2010. Se-
meval 2010 task 2: Cross-lingual lexical substitution. In
Proceedings of the 5th International Workshop on Seman-
tic Evaluations (SemEval-2010), Uppsala, Sweden.
Hwee Tou Ng and Hian Beng Lee. 1996. Integrating mul-
tiple knowledge sources to disambiguate word sense: An
exemplar-based approach. In ACL, pages 40–47.
F.J. Och and H. Ney. 2000. Giza++: Training of statisti-
cal translation models. Technical report, RWTH Aachen,
University of Technology.
A. Van den Bosch, G.J. Busser, S. Canisius, and W. Daele-
mans. 2007. An efficient memory-based morpho-
syntactic tagger and parser for Dutch. In P. Dirix, I. Schu-
urman, V. Vandeghinste, , and F. Van Eynde, editors, Com-
putational Linguistics in the Netherlands: Selected Papers
from the Seventeenth CLIN Meeting, pages 99–114, Leu-
ven, Belgium.
A. Van den Bosch. 2004. Wrapped progressive sampling
search for optimizing learning algorithm parameters. In
R. Verbrugge, N. Taatgen, and L. Schomaker, editors,
Proceedings of the Sixteenth Belgian-Dutch Conference
on Artificial Intelligence, pages 219–226, Groningen, The
Netherlands.
</reference>
<page confidence="0.99809">
241
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.789096">
<title confidence="0.983832">UvT-WSD1: a Cross-Lingual Word Sense Disambiguation system</title>
<author confidence="0.999314">Maarten van_Gompel</author>
<affiliation confidence="0.9936655">Tilburg centre for Cognition and Communication Tilburg University</affiliation>
<email confidence="0.968503">proycon@anaproy.nl</email>
<abstract confidence="0.98264815">This paper describes the Cross-Lingual Word Sense Disambiguation system UvT- WSD1, developed at Tilburg University, for participation in two SemEval-2 tasks: the Cross-Lingual Word Sense Disambiguation task and the Cross-Lingual Lexical Substitution task. The UvT-WSD1 system makes use of k-nearest neighbour classifiers, in the form of single-word experts for each target word to be disambiguated. These classifiers can be constructed using a variety of local and global context features, and these are mapped onto the translations, i.e. the senses, of the words. The system works for a given language-pair, either English-Dutch or English-Spanish in the current implementation, and takes a word-aligned parallel corpus as its input.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jordi Atserias</author>
<author>Bernardino Casas</author>
<author>Elisabet Comelles</author>
<author>Meritxell Gonzlez</author>
<author>Llu´ıs Padr´o</author>
<author>Muntsa Padr´o</author>
</authors>
<title>FreeLing 1.3: Syntactic and semantic services in an opensource NLP library .</title>
<date>2006</date>
<booktitle>In Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC</booktitle>
<location>Genoa, Italy. ELRA.</location>
<marker>Atserias, Casas, Comelles, Gonzlez, Padr´o, Padr´o, 2006</marker>
<rawString>Jordi Atserias, Bernardino Casas, Elisabet Comelles, Meritxell Gonzlez, Llu´ıs Padr´o, and Muntsa Padr´o. 2006. FreeLing 1.3: Syntactic and semantic services in an opensource NLP library . In Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC 2006), Genoa, Italy. ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Daelemans</author>
<author>J Zavrel</author>
<author>K Van der Sloot</author>
<author>A Van den Bosch</author>
</authors>
<title>TiMBL: Tilburg memory based learner, version 6.2, reference guide.</title>
<date>2009</date>
<tech>Technical Report ILK 09-01,</tech>
<institution>ILK Research Group, Tilburg University.</institution>
<marker>Daelemans, Zavrel, Van der Sloot, Van den Bosch, 2009</marker>
<rawString>W. Daelemans, J. Zavrel, K. Van der Sloot, and A. Van den Bosch. 2009. TiMBL: Tilburg memory based learner, version 6.2, reference guide. Technical Report ILK 09-01, ILK Research Group, Tilburg University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Decadt</author>
<author>V Hoste</author>
<author>W Daelemans</author>
<author>A Van den Bosch</author>
</authors>
<title>GAMBL, genetic algorithm optimization of memory-based WSD.</title>
<date>2004</date>
<booktitle>Proceedings of the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text (Senseval-3),</booktitle>
<pages>108--112</pages>
<editor>In R. Mihalcea and P. Edmonds, editors,</editor>
<publisher>ACL.</publisher>
<location>New Brunswick, NJ.</location>
<marker>Decadt, Hoste, Daelemans, Van den Bosch, 2004</marker>
<rawString>B. Decadt, V. Hoste, W. Daelemans, and A. Van den Bosch. 2004. GAMBL, genetic algorithm optimization of memory-based WSD. In R. Mihalcea and P. Edmonds, editors, Proceedings of the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text (Senseval-3), pages 108–112, New Brunswick, NJ. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Hendrickx</author>
<author>A Van den Bosch</author>
<author>V Hoste</author>
<author>W Daelemans</author>
</authors>
<title>Dutch word sense disambiguation: Optimizing the localness of context.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on</booktitle>
<pages>61--65</pages>
<location>Philadelphia, PA.</location>
<marker>Hendrickx, Van den Bosch, Hoste, Daelemans, 2002</marker>
<rawString>I. Hendrickx, A. Van den Bosch, V. Hoste, and W. Daelemans. 2002. Dutch word sense disambiguation: Optimizing the localness of context. In Proceedings of the Workshop on word sense disambiguation: Recent successes and future directions, pages 61–65, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Hoste</author>
<author>I Hendrickx</author>
<author>W Daelemans</author>
<author>A Van den Bosch</author>
</authors>
<title>Parameter optimization for machine learning of word sense disambiguation.</title>
<date>2002</date>
<journal>Natural Language Engineering,</journal>
<volume>8</volume>
<issue>4</issue>
<marker>Hoste, Hendrickx, Daelemans, Van den Bosch, 2002</marker>
<rawString>V. Hoste, I. Hendrickx, W. Daelemans, and A. Van den Bosch. 2002. Parameter optimization for machine learning of word sense disambiguation. Natural Language Engineering, 8(4):311–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation. In</title>
<date>2005</date>
<booktitle>In Proceedings of the Machine Translation Summit X ([MT]’05).,</booktitle>
<pages>79--86</pages>
<contexts>
<context position="2007" citStr="Koehn, 2005" startWordPosition="310" endWordPosition="311">ated marked. Because of the cross-lingual nature of the tasks, a word sense corresponds to a translation in another language, rather than a sense description in the same language. In the Cross-lingual Lexical Substitution task, the target language is Spanish. The task is to find Spanish substitutes for the English words marked in the test samples. In the Cross-Lingual Word Sense Disambiguation task, we participate for English-Dutch and EnglishSpanish. The Word Sense Disambiguation task provides training data for all five languages, in the form of the sentence-aligned EuroParl parallel corpus (Koehn, 2005). This is the source of training data the UvT-WSD1 system uses for both tasks. The system may output several senses per instance, rather than producing just one sense prediction. These are evaluated in two different ways. The scoring type “best” expects that the system outputs the best senses, in the order of its confidence. The scoring type “out of five/ten” expects five or ten guesses, and each answer weighs the same. These metrics are more extensively described in (Mihalcea et al., 2010). The UvTWSD1 system participates in both scoring types, for both tasks. The system put forth in this pap</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In In Proceedings of the Machine Translation Summit X ([MT]’05)., pages 79–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Els Lefever</author>
<author>Veronique Hoste</author>
</authors>
<title>Semeval</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010),</booktitle>
<location>Uppsala,</location>
<contexts>
<context position="1070" citStr="Lefever and Hoste, 2010" startWordPosition="154" endWordPosition="157">makes use of k-nearest neighbour classifiers, in the form of single-word experts for each target word to be disambiguated. These classifiers can be constructed using a variety of local and global context features, and these are mapped onto the translations, i.e. the senses, of the words. The system works for a given language-pair, either English-Dutch or English-Spanish in the current implementation, and takes a word-aligned parallel corpus as its input. 1 Introduction The UvT-WSD1 system described in this paper took part in two similar SemEval-2 tasks: CrossLingual Word Sense Disambiguation (Lefever and Hoste, 2010) and Cross-Lingual Lexical Substitution (Mihalcea et al., 2010). In each task, a number of words is selected for which the senses are to be determined for a number of instances of these words. For each word, a number of samples in context is provided, where each sample consists of one sentence, with the word to be disambiguated marked. Because of the cross-lingual nature of the tasks, a word sense corresponds to a translation in another language, rather than a sense description in the same language. In the Cross-lingual Lexical Substitution task, the target language is Spanish. The task is to </context>
<context position="12285" citStr="Lefever and Hoste, 2010" startWordPosition="2036" endWordPosition="2039">the focus word. 2)Word experts with global features1. 3) Word experts with two word features, two lemma features and two part-of-speech tag features. 2. UvT-WSD1-g (aka UvT-g) – Word experts with global features only. Table 1 shows a condensed view of the results for the Cross-Lingual Lexical Substitution task. Table 2 shows the final results for the Word-Sense Disambiguation task. Note that UvT-WSD1-v and UvT-WSD1-g are two different configurations of the UvT-WSD1 system, and to conserve space these are abbreviated as UvT-v and UvT-g respectively. These are also the names used in both tasks (Lefever and Hoste, 2010; Mihalcea et al., 2010) to refer to our system. 4 Discussion and Conclusion Cross-Lingual Word Sense Disambiguation and Cross-Lingual Lexical Substitution have proven to be hard tasks, with scores that are relatively close to baseline. This can be attributed to a noticeable trait in the system output to be inclined to assign the same majority sense to all instances. 1For the Cross-Lingual Lexical Substitution task only, the parameter to recompute the Tl threshold automatically was enabled. 240 Dutch BEST UvT-v UvT-g T3-COLEUR Precision &amp; Recall 17.7 15.93 10.72 &amp; 10.56 Mode Prec. &amp; Rec. 12.06</context>
</contexts>
<marker>Lefever, Hoste, 2010</marker>
<rawString>Els Lefever and Veronique Hoste. 2010. Semeval 2010 task 3: Cross-lingual word sense disambiguation. In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010), Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Ravi Sinha</author>
<author>Diana McCarthy</author>
</authors>
<title>task 2: Cross-lingual lexical substitution.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010),</booktitle>
<location>Uppsala,</location>
<note>Semeval</note>
<contexts>
<context position="1133" citStr="Mihalcea et al., 2010" startWordPosition="163" endWordPosition="166">le-word experts for each target word to be disambiguated. These classifiers can be constructed using a variety of local and global context features, and these are mapped onto the translations, i.e. the senses, of the words. The system works for a given language-pair, either English-Dutch or English-Spanish in the current implementation, and takes a word-aligned parallel corpus as its input. 1 Introduction The UvT-WSD1 system described in this paper took part in two similar SemEval-2 tasks: CrossLingual Word Sense Disambiguation (Lefever and Hoste, 2010) and Cross-Lingual Lexical Substitution (Mihalcea et al., 2010). In each task, a number of words is selected for which the senses are to be determined for a number of instances of these words. For each word, a number of samples in context is provided, where each sample consists of one sentence, with the word to be disambiguated marked. Because of the cross-lingual nature of the tasks, a word sense corresponds to a translation in another language, rather than a sense description in the same language. In the Cross-lingual Lexical Substitution task, the target language is Spanish. The task is to find Spanish substitutes for the English words marked in the te</context>
<context position="2502" citStr="Mihalcea et al., 2010" startWordPosition="394" endWordPosition="397"> task provides training data for all five languages, in the form of the sentence-aligned EuroParl parallel corpus (Koehn, 2005). This is the source of training data the UvT-WSD1 system uses for both tasks. The system may output several senses per instance, rather than producing just one sense prediction. These are evaluated in two different ways. The scoring type “best” expects that the system outputs the best senses, in the order of its confidence. The scoring type “out of five/ten” expects five or ten guesses, and each answer weighs the same. These metrics are more extensively described in (Mihalcea et al., 2010). The UvTWSD1 system participates in both scoring types, for both tasks. The system put forth in this paper follows a similar approach as described in earlier research by (Hoste et al., 2002). 2 System Description The UvT-WSD1 system uses machine learning techniques to learn what senses/translations are associated with any of the target words. It does so on the basis of a variety of local and global context features, discussed in Section 2.2. At the core of the system are the classifiers, or so called “word experts”, one per target word. These are built using the Tilburg Memory Based Learner (</context>
<context position="12309" citStr="Mihalcea et al., 2010" startWordPosition="2040" endWordPosition="2043">perts with global features1. 3) Word experts with two word features, two lemma features and two part-of-speech tag features. 2. UvT-WSD1-g (aka UvT-g) – Word experts with global features only. Table 1 shows a condensed view of the results for the Cross-Lingual Lexical Substitution task. Table 2 shows the final results for the Word-Sense Disambiguation task. Note that UvT-WSD1-v and UvT-WSD1-g are two different configurations of the UvT-WSD1 system, and to conserve space these are abbreviated as UvT-v and UvT-g respectively. These are also the names used in both tasks (Lefever and Hoste, 2010; Mihalcea et al., 2010) to refer to our system. 4 Discussion and Conclusion Cross-Lingual Word Sense Disambiguation and Cross-Lingual Lexical Substitution have proven to be hard tasks, with scores that are relatively close to baseline. This can be attributed to a noticeable trait in the system output to be inclined to assign the same majority sense to all instances. 1For the Cross-Lingual Lexical Substitution task only, the parameter to recompute the Tl threshold automatically was enabled. 240 Dutch BEST UvT-v UvT-g T3-COLEUR Precision &amp; Recall 17.7 15.93 10.72 &amp; 10.56 Mode Prec. &amp; Rec. 12.06 10.54 6.18 &amp; 6.16 Dutch</context>
</contexts>
<marker>Mihalcea, Sinha, McCarthy, 2010</marker>
<rawString>Rada Mihalcea, Ravi Sinha, and Diana McCarthy. 2010. Semeval 2010 task 2: Cross-lingual lexical substitution. In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010), Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hwee Tou Ng</author>
<author>Hian Beng Lee</author>
</authors>
<title>Integrating multiple knowledge sources to disambiguate word sense: An exemplar-based approach.</title>
<date>1996</date>
<booktitle>In ACL,</booktitle>
<pages>40--47</pages>
<contexts>
<context position="7778" citStr="Ng and Lee, 1996" startWordPosition="1275" endWordPosition="1278"> all such words are then put in a bag-of-word representation, yielding as many features as the amount of keywords found. A global count over the full corpus is needed to find these keywords. Each keyword acts as a binary feature, indicating whether or not that particular keyword is found in the context of the occurrence of the target word. The context in which these keywords are searched for is exactly one sentence, i.e. the sentence in which the target word occurs. This is due to the test data simply not supplying a wider context. The method used to extract these keywords (k) is proposed by (Ng and Lee, 1996) and used also in the research of (Hoste et al., 2002). Assume we have a focus word f, more precisely, a lemma and part-of-speech tag pair of one of the target words. We also have one of its aligned translations/senses s, which in this implementation is also a lemma. We can now estimate P(slk), the probability of sense s, given a keyword k, by dividing Ns,k,oca,. (the number of occurrences of a possible local context word k with particular focus word lemmaPoS combination and with a particular sense s) by Nk,o,a, (the number of occurrences of a possible local context keyword kloc with a particu</context>
</contexts>
<marker>Ng, Lee, 1996</marker>
<rawString>Hwee Tou Ng and Hian Beng Lee. 1996. Integrating multiple knowledge sources to disambiguate word sense: An exemplar-based approach. In ACL, pages 40–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Giza++: Training of statistical translation models.</title>
<date>2000</date>
<tech>Technical report,</tech>
<institution>RWTH Aachen, University of Technology.</institution>
<contexts>
<context position="5083" citStr="Och and Ney, 2000" startWordPosition="819" endWordPosition="822">ution of classes per test instance, and these are converted to the appropriate formats for “best” and “out of five/ten” evaluation. For the latter scoring type, the five/ten highest scoring senses are selected, for the former scoring type, all classes scoring above a certain threshold are considered “best”. The threshold is set at 90% of the score of the highest scoring class. 2.1 Word-Alignment, Tokenisation, Lemmatisation and Part-of-Speech-tagging The Europarl parallel corpus, English-Spanish and English-Dutch, is delivered as a sentence-aligned parallel corpus. We subsequently run GIZA++ (Och and Ney, 2000) to compute a word-aligned parallel corpus. This, however, is not the sole input. The target words in both tasks are actually specified as a lemma and part-of-speech tag pair, rather than words. In the Word Sense Disambiguation task, all target lemmas are simply nouns, but in the CrossLingual Lexical Substitution task, they can also be verbs, adjectives or adverbs. Likewise, both tasks expect the sense/translation output to also be in the form of lemmas. Therefore the system internally has to be aware of the lemma and part-of-speech tag of each word in the parallel corpus and test data, only t</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>F.J. Och and H. Ney. 2000. Giza++: Training of statistical translation models. Technical report, RWTH Aachen, University of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Van den Bosch</author>
<author>G J Busser</author>
<author>S Canisius</author>
<author>W Daelemans</author>
</authors>
<title>An efficient memory-based morphosyntactic tagger and parser for Dutch. In</title>
<date>2007</date>
<booktitle>Computational Linguistics in the Netherlands: Selected Papers from the Seventeenth CLIN Meeting,</booktitle>
<pages>99--114</pages>
<editor>P. Dirix, I. Schuurman, V. Vandeghinste, , and F. Van Eynde, editors,</editor>
<location>Leuven, Belgium.</location>
<marker>Van den Bosch, Busser, Canisius, Daelemans, 2007</marker>
<rawString>A. Van den Bosch, G.J. Busser, S. Canisius, and W. Daelemans. 2007. An efficient memory-based morphosyntactic tagger and parser for Dutch. In P. Dirix, I. Schuurman, V. Vandeghinste, , and F. Van Eynde, editors, Computational Linguistics in the Netherlands: Selected Papers from the Seventeenth CLIN Meeting, pages 99–114, Leuven, Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Van den Bosch</author>
</authors>
<title>Wrapped progressive sampling search for optimizing learning algorithm parameters. In</title>
<date>2004</date>
<booktitle>Proceedings of the Sixteenth Belgian-Dutch Conference on Artificial Intelligence,</booktitle>
<pages>219--226</pages>
<editor>R. Verbrugge, N. Taatgen, and L. Schomaker, editors,</editor>
<location>Groningen, The Netherlands.</location>
<marker>Van den Bosch, 2004</marker>
<rawString>A. Van den Bosch. 2004. Wrapped progressive sampling search for optimizing learning algorithm parameters. In R. Verbrugge, N. Taatgen, and L. Schomaker, editors, Proceedings of the Sixteenth Belgian-Dutch Conference on Artificial Intelligence, pages 219–226, Groningen, The Netherlands.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>