<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.519478666666667">
TRANSLATING ENGLISH INTO LOGICAL FORM&apos;
Stanley J. Rosenschein
Stuart M. Shieber
</note>
<sectionHeader confidence="0.6699624" genericHeader="method">
Artificial Intelligence Center
SRI International
333 Ravenswood Avenue
Menlo Park, CA 94025
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999225375">
A scheme for syntax-directed translation that mirrors com-
positional model-theoretic semantics is discussed. The scheme is the
basis for an English translation system called PATR and was used to
specify a semantically interesting fragment of English, including such
constructs as tense, aspect, modals, and various lexically controlled verb
complement structures. PATR was embedded in a question-answering
system that replied appropriately to questions requiring the computa-
tion of logical entailments.
</bodyText>
<sectionHeader confidence="0.968473" genericHeader="method">
I INTRODUCTION
</sectionHeader>
<bodyText confidence="0.993560695121952">
When contemporary linguists and philosophers speak
of &amp;quot;semantics,&apos; they usually mean model-theoretic semantics—
mathematical devices for associating truth conditions with sentences.
Computational linguists, on the other hand, often use the term
&amp;quot;semantics&amp;quot; to denote a phase of processing in which a data structure
(e.g., a formula or network) is constructed to represent the meaning
of a sentence and serve as input to later phases of processing. (A bet-
ter name for this process might be &amp;quot;translation&amp;quot; or &amp;quot;transduction.&amp;quot;)
Whether one takes &amp;quot;semantics&apos; to be about model theory or translation,
the fact remains that natural languages are marked by a wealth of com-
plex constructions—such as tense, aspect, moods, plurals, modality, ad-
verbials, degree terms, and sentential complements—that make seman-
tic specification a complex and challenging endeavor.
Computer scientists faced with the problem of managing
software complexity have developed strict design disciplines in their
programming methodologies. One might speculate that a similar re-
quirement for manageability has led linguists (since Montague, at least)
to follow a discipline of strict compositionality in semantic specification,
even though model-theoretic semantics per se does not demand it.
Compositionality requires that the meaning of a phrase be a function
of the meanings of its immediate constituents, a property that allows
the grammar writer to correlate syntax and semantics on a rule-by-rule
basis and keep the specification modular. Clearly, the natural analogue
to compositionality in the case of translation is syntax-directed trans-
lation; it is this analogy that we seek to exploit.
We describe a syntax-directed translation scheme that bears
a close resemblance to model-theoretic approaches and achieves a level
of perspicuity suitable for the development of large and complex gram-
mars by using a declarative format for specifying grammar rules. In our
formalism, translation types are associated with the phrasal categories
of English in much the way that logical-denotation types are associated
&apos;This research was supported by the Defense Advanced Research Projects Agency
under Contract N00039.130-C-0575 with the Naval Electronic Systems Command.
The views and conclusions contained in this document are those of the authors and
should not be interpreted as representative of the official policies, either expressed
or implied, of the Defense Advanced Research Projects Agency or the United States
Government.
with phrasal categories in model-theoretic semantics. The translation
&apos; types are classes of data objects rather than abstract denotations, yet
they play much the same role in the translation process that denotation
types play in formal semantics.
In addition to this parallel between logical types and trans-
lation types, we have intentionally designed the language in which
translation rules are stated to emphasize parallels between the syntax-
directed translation and corresponding model-theoretic interpretation
rules found in, say, the GPSG literature IGazdar, forthcoming). In
the GPSG approach, each syntax rule has an associated semantic rule
(typically involving functional application) that specifies how to com-
pose the meaning of a phrase from the meanings of its constituents.
In an analogous fashion, we provide for the translation of a phrase
to be synthesized from the translations of its immediate constituents
according to a local rule, typically involving symbolic application and
X-conversion.
It should be noted in passing that doing translation rather
than model theoretic interpretation offers the temptation to abuse the
formalism by having the &amp;quot;meaning&apos; (translation) of a phrase depend
on syntactic properties of the translations of its constituents—for in-
stance, on the order of conjuncts in a logical expression. There are
several points to be made in this regard. First, without severe a priori
restrictions on what kinds of objects can be translations (coupled with
the associated strong theoretical claims that such restrictions would
embody) it seems impossible to prevent such abuses. Second, as in the
case of programming languages, it is reasonable to assume that there
would emerge a set of stylistic practices that would govern the actual
form of grammars for reasons of manageability and esthetics. Third, it
is still an open question whether the model-theoretic program of strong
compositionality will actually succeed. Indeed, whether it succeeds or
not is of little concern to the computational linguist, whose systems, in
any event, have no direct way of using the sort of abstract model being
proposed and whose systems must, in general, be based on deduction
(and hence translation).
The rest of the paper discusses our work in more detail.
Section II presents the grammar formalism and describes PATR, an
implemented parsing and translation system that can accept a gram-
mar in our formalism and uses it to process sentences. Examples of
the system&apos;s operation, including its application in a simple deductive
question-answering system, are found in Section M. Finally, Section
IV describes further extensions of the formalism and the parsing sys-
tem. Three appendices are included: the first contains sample gram-
mar rules; the second contains meaning postulates (axioms) used by
the question-answering system; the third presents a sample dialogue
session.
</bodyText>
<page confidence="0.988459">
1
</page>
<sectionHeader confidence="0.96893" genericHeader="method">
II A GRAMMAR FORMALISM
</sectionHeader>
<subsectionHeader confidence="0.557668">
A General Characterization
</subsectionHeader>
<bodyText confidence="0.988935736842105">
Our grammar formalism is best characterized as a specialized
type of augmented context-free grammar. That is, we take a grammar
to be a set of context-free rules that define a language and associate
structural descriptions (parse trees) for each sentence in that language
in the usual way. Nodes in the parse tree are assumed to have a set of
features which may assume binary values (True or False), and there is
a distinguished attribute—the &amp;quot;translation&amp;quot;—whose values range over
a potentially infinite set of objects, i.e., the translations of English
phrases.
Viewed more abstractly, we regard translation as a binary
relation between word sequences and logical formulas. The use of
a relation is intended to incorporate the fact that many word se-
quences have several logical forms, while some have none at all.
Furthermore, we view this relation as being composed (in the mathe-
matical sense) of four simpler relations corresponding to the conceptual
phases of analysis: (1) LEX (lexical analysis), (2) PARSE (parsing), (3)
ANNOTATE (assignment of attribute values, syntactic filtering), and
(4) TRANSLATE (translation proper, i.e., synthesis of logical form).
The domains and ranges of these relations are as follows:
</bodyText>
<subsectionHeader confidence="0.8124832">
Word Sequences -LEX-.
Morpheme Sequences -PARSE—
Phrase Structure Trees -ANNOTATE-.
Annotated Trees -TRANSLATE-0
Logical Form
</subsectionHeader>
<bodyText confidence="0.999963214285714">
The relational composition of these four relations is the full translation
relation associating word sequences with logical forms. The subphases
too are viewed as relations to reflect the inherent nondeterminism of
each stage of the process. For example, the sentence &amp;quot;a hat by every
designer sent from Paris was felt&amp;quot; is easily seen to be nondeterminis-
tic in LEX (&amp;quot;felt&amp;quot;), PARSE (postnominal modifier attachment), and
TRANSLATE (quantifier scoping).
It should be emphasized that the correspondence between
processing phases and these conceptual phases is loose. The goal of
the separation is to make specification of the process perspicous and to
allow simple, clean implementations. An actual system could achieve
the net effect of the various stages in many ways, and numerous op-
timizations could be envisioned that would have the effect of folding
back later phases to increase efficiency.
</bodyText>
<subsectionHeader confidence="0.935207">
B The Relations LEX, PARSE, and ANNOTATE
</subsectionHeader>
<bodyText confidence="0.992794">
We now describe a characteristic form of specification ap-
</bodyText>
<figure confidence="0.7906686875">
RULES:
Constant corr. (A? (A 11 ()% 4))))
S SP VP
Trans: VI&amp;quot; DIP&apos;)
VP TENSE V
Anne: -tTransitivo (V) ]
Trans: { COIP&apos; ITE/P3E }
LEXICON:
?JP John
Anne: Proper(NP)
Trans: ( John )
IENSE &amp;past
Trans: { (X X (past X)) }
V go
Anna: -1Transitivern
Trans: { (X X (go X)) )
</figure>
<figureCaption confidence="0.843036666666667">
Figure 1: Sample specification of augmented phrase structure
grammar
propriate to each phase and illustrate how the word sequence &amp;quot;John
went&amp;quot; is analyzed by stages as standing in the translation relation
to &amp;quot;(past (go john))&amp;quot; according to the (trivial) grammar presented in
Figure 1.
</figureCaption>
<bodyText confidence="0.998333666666667">
Lexical analysis is specified by giving a kernel relation between
individual words and morpheme sequences&apos; (or equivalently, a mapping
from words to sets of morpheme sequences), for example:
</bodyText>
<subsectionHeader confidence="0.5119745">
John -a (John):
went --• (kpast go);
</subsectionHeader>
<bodyText confidence="0.874158">
persuaded -4. (kpast persuade).
(kppl parsuads): •
The kernel relation is extended in a standard fashion to the
full LEX relation. For example, &apos;went&amp;quot; is mapped onto the single
morpheme sequence (Smut go), and &amp;quot;John&amp;quot; is mapped to (john). Thus,
by extension, &amp;quot;John went* is transformed to (John &amp;past go) by the
lexical analysis phase.
Parsing is specified in the usual manner by a context-free
grammar. Utilizing the context-free rules presented in the sample
system specification shown in Figure 1, (John &amp;past go) is transformed
into the parse tree
</bodyText>
<equation confidence="0.606963">
(S (NP John)
(VP (TEVSEkpast)
(V go))) •
</equation>
<bodyText confidence="0.997633">
Every node in the parse tree has a set of associated features.
The purpose of ANNOTATE is to relate the bare parse tree to one
that has been enhanced with attribute values, filtering out those that
do not satisfy stated syntactic restrictions. These restrictions are given
as Boolean expressions associated with the context-free rules; a tree is
properly annotated only if all the Boolean expressions corresponding
to the rules used in the analysis are simultaneously true. Again, using
the rules of Figure 1,
&apos;or course, more sophisticated approaches to morphological analysis would seek
to analyse the LEX relation more fully. See, for example, liCartunnen, 10821 and
!Kaplan, 18811.
</bodyText>
<page confidence="0.965907">
2
</page>
<figure confidence="0.903364818181818">
(s (NP John)
(VP (TENSE kpast)
(V go)))
is transformed into
(S (NP: Proper
John)
(VP: -.Transitive
(TEM kpaet)
(V: °I Transitive
go))) .
C The Relation TRANSLATE
</figure>
<bodyText confidence="0.993144666666667">
Logical-form synthesis rules are specified as augments to the
context-free grammar. There is a language whose expressions denote
translations (syntactic formulas); an expression from this language is
attached to each context-free rule and serves to define the composite
translation at a node in terms of the translations of its immediate
constituents. In the sample sentence, TENSE&apos; and V&apos; (the translations
of TENSE and V respectively) would denote the X-expressions specified
in their respective translation rules. VP&apos; (the translation of the VP)
is defined to be the value of (SAP (SAP COMP&apos; TENSE&apos;) V&apos;), where
COMP&apos; is a constant X-expression and SAP is the symbolic-application
operator. This works out to be (X X (past (go X))). Finally, the symbolic
application of VP&apos; to NP&apos; yields (past (go John)). (For convenience we
shall henceforth use square brackets for SAP and designate (SAP a )9)
by alfil.)
Before describing the symbolic-application operator in more
detail, it is necessary to explain the exact nature of the data objects
serving as translations. At one level, it is convenient to think of
the translations as X-expressions, since X-expressions are a convenient
notation for specifying how fragments of a translation are substituted
into their appropriate operator-operand positions in the formula being
assembled-especially when the composition rules follow the syntactic
structure as encoded in the parse tree. There are several phenomena,
however, that require the storage of more information at a node than
can be represented in a bare X-expression. Two of the most conspicuous
phenonema of this type are quantifier scoping and unbounded depen-
dencies (&amp;quot;gaps&amp;quot;).
Our approach to quantifier scoping has been to take a version
of Cooper&apos;s storage technique, originally proposed in the context of
model-theoretic semantics, (Cooper, forthcoming and adapt it to the
needs of translation. For the time being, let us take translations to
be ordered pairs whose first component (the head) is an expression
in the target language, characteristically a X-expression. The second
component of the pair is an object called storage, a structured collection
of sentential operators that can be applied to a sentence matrix in such a
way as to introduce a quantifier and &amp;quot;capture&amp;quot; a free variable occurring
in that sentence matrix.2
For example, the translation of &amp;quot;a happy man&amp;quot; might be &lt;
m , (X S (some m (and (man m)(happy m)) S)) &gt;.3 Here the head is m
(simply a free variable), and storage consists of the )-expression (X S
</bodyText>
<footnote confidence="0.56642075">
2In the sample grammar presented in Appendix A, the storage-forming operation
is notated mk.mbd.
3Following (Moore, 1084 a quantified expression is of the form (quantifier, variable,
restriction, body)
</footnote>
<bodyText confidence="0.998487515151515">
...). If the verb phrase &amp;quot;sleeps&amp;quot; were to receive the translation &lt; (X X
(sleep X)), 0 &gt; (i.e., a unary predicate as head and no storage), then
the symbolic application of the verb phrase translation to the noun
phrase translation would compose the heads in the usual way and take
the &amp;quot;union&amp;quot; of the storage yielding &lt; (sleep m), (X S (some m (and
(man m)(happy rn)) S)) &gt;.
We define an operation called &amp;quot;pull.s,&amp;quot; which has the effect
of &amp;quot;pulling&amp;quot; the sentence operator out of storage and applying it to
the head. There is another pull operation, pull.v, which operates on
heads representing unary predicates rather than sentence matrices.
When pull.s is applied in our example, it yields &lt; (some m (and (man
m)(happy m)) (sleep m)), &gt;, corresponding to the translation of the
clause &amp;quot;a happy man sleeps.&amp;quot; Note that in the process the free vari-
able m has been &amp;quot;captured.&amp;quot; In model-theoretic semantics this cap-
ture would ordinarily be meaningless, although one can complicate the
mathematical machinery to achieve the same effect. Since translation
is fundamentally a syntactic process, however, this operation is well-
defined and quite natural.
To handle gaps, we enriched the translations with a third com-
ponent: a variable corresponding to the gapped position. For example,
the translation of the relative clause &amp;quot;...(thati the man saw&amp;quot; would be
a triple: &lt; (past (see X Y)), Y, (X S (the X (man X) S))&gt;, where
the second component, Y, tracks the free variable corresponding to the
gap. At the node at which the gap was to be discharged, )-abstraction
would occur (as specified in the grammar by the operation &amp;quot;ungap&amp;quot;)
producing the unary predicate (X Y (past (see X Y))), which would
ultimately be applied to the variable corresponding to the head of the
noun phrase.
It turns out that triples consisting of &lt;head, var, storage&gt;
are adequate to serve as translations of a large class of phrases, but
that the application operator needs to distinguish two subcases (which
we call type A and type B objects). Until now we have been discussing
type A objects, whose application rule is given (roughly) as
</bodyText>
<equation confidence="0.5103365">
&lt; hd,var,sto&gt; &lt; hd&apos;,var&apos;,sto&apos; &gt;)
&lt;(hd hnvar U var&apos;, sto U sto&apos;&gt;
</equation>
<bodyText confidence="0.976384210526316">
where one of var or var&apos; must be null. In the case of type B objects,
which are assigned primarily as translations of determiners, the rule is
&lt;hd,var,sto&gt;i&lt;hd&apos;,var&apos;,sto&apos;&gt;1
&lt;var, var&apos;, hd(hd&apos;) U sto U sto&apos;&gt;
For example, if the meaning of &amp;quot;every&amp;quot; is
every&apos; = &lt;(X P (X S (every X (P X) S))), X, 0&gt;
and the meaning of &amp;quot;man&amp;quot; is
man&apos; = &lt; man, 0, &gt;
then the meaning of &amp;quot;every man&amp;quot; is
every&apos;lman&apos;i &lt; X , 0, (X S (man X) S)&gt;
as expected.
Nondeterminism enters in two ways. First, since pull opera-
tions can be invoked nondeterministically at various nodes in the parse
tree (as specified by the grammar), there exists the possibility of com-
puting multiple scopings for a single context-free parse tree. (See
Section III.B for an example of this phenomenon.) In addition, the
grammar writer can specify explicit nondeterminism by associating
several distinct translation rules with a single context-free production.
In this case, he can control the application of a translation schema by
</bodyText>
<page confidence="0.993547">
3
</page>
<bodyText confidence="0.993881473684211">
specifying for each schema a guard, a Boolean combination of features
that the nodes analyzed by the production must satisfy in order for the
translation schema to be applicable.
D Implementation of a Translation System
The techniques presented in Sections 11.13 and ILC were imple-
mented in a parsing and translation system called PATR which was
used as a component in a dialogue system discussed in Section III.B.
The input to the system is a sentence, which is preprocessed by a
lexical analyzer. Parsing is performed by a simple recursive descent
parser, augmented to add annotations to the nodes of the parse tree.
Translation is then done in a separate pass over the annotated parse
tree. Thus the four conceptual phases are implemented as three actual
processing phases. This folding of two phases into one was done purely
for reasons of efficiency and has no effect on the actual results obtained
by the system. Functions to perform the storage manipulation, gap
handling, and the other features of translation presented earlier have
all been realized in the translation component of the running system.
The next section describes an actual grammar that has been used in
conjunction with this translation system.
</bodyText>
<sectionHeader confidence="0.9733135" genericHeader="method">
Ill EXPERIMENTS IN PRODUCING AND USING
LOGICAL FORM
</sectionHeader>
<subsectionHeader confidence="0.441031">
A A Working Grammar
</subsectionHeader>
<bodyText confidence="0.999976090909091">
To illustrate the ease with which diverse semantic features
could be handled, a grammar was written that defines a semantically
interesting fragment of English along with its translation into logical
form [Moore, 19811. The grammar for the fragment illustrated in this
dialogue is compact occupying only a few pages, yet it gives both syntax
and semantics for modals, tense, aspect, passives, and lexically control-
led infinitival complements. (A portion of the grammar is included
as Appendix A.)4 The full test grammar, loosely based on DIAGRAM
[Robinson, 19821 but restricted and modified to reflect changes in ap-
proach, was the grammar used to specify the translations of the sen-
tences in the sample dialogue of Appendix C.
</bodyText>
<subsectionHeader confidence="0.7985">
B An Example of the System&apos;s Operation
</subsectionHeader>
<bodyText confidence="0.961395">
The grammar presented in Appendix A encodes a relation
between sentences and expressions in logical form. We now present a
sample of this relation, as well as its derivation, with a sample sentence:
&amp;quot;Every man persuaded a woman to go.&amp;quot;
Lexical analysis relates the sample sentence to two morpheme
streams:
o every man &amp;ppl persuade a woman to go
</bodyText>
<footnote confidence="0.77424">
4Since this is just a small portion of the actual grammar selected for expository
</footnote>
<bodyText confidence="0.552477333333333">
purposes, many of the phrasal categories and annotations will seem unmotivated
and needlessly complex. These categories and annotations are utilized elsewhere
in the test grammar.
every man &amp;past persuade a woman to go.
The first is immediately eliminated because there is no context-free
parse for it in the grammar. The second, however, is parsed as
</bodyText>
<table confidence="0.928234">
ES (SDEC (HP (DETP (MET (DET every)))
(NON (HOMED (NOUN (N nan)))))
(PREDICATE (AUX? (TENSE *past))
(VP? (VP (VP? (V persuade)))
(NP (DETP s))
(NON (NONHD (NOUN (N woaan)))))
(INFINITIVE (TO to)
(VP? (VP (VP? (V go]
</table>
<bodyText confidence="0.954655818181818">
While parsing is being done, annotations are added to each
node of the parse tree. For instance, the NP DETP NOM rule
includes the annotation rule AGREE( NP, DETP, Definite). AGREE
is one of a set of macros defined for the convenience of the grammar
writer. This particular macro invocation is equivalent to the Boolean
expression Definite(NP) Definite(DETP). Since the DETP node itself
has the annotation Definite as a result of the preceding annotation
process, the NP node now gets the annotation Definite as well. At
the bottom level, the Definite annotation was derived from the lexical
entry for the word &amp;quot;every&amp;quot;.5 The whole parse tree receives the following
annotation:
</bodyText>
<figure confidence="0.945836823529412">
(S (SDEC (NP: Definite
(DEW: Definite
(DDE?: Definite
(DET: Definite
every)))
(NON (NOIHD (NOUN (Naau)))))
(PREDICATE (AUXP (TENSE &amp;past))
(VP? (VP: Active
(VP?: Active,Transitive,TalresInt
(V: Active,Transitive,TakesInt
persuade)))
(HP (DETP (A a))
(NON (NOIHD (NOUN (N soaan)))))
(INFINITIVE (TO to)
(VP? (VP: Active
(VP?: Active
(v: Active
</figure>
<bodyText confidence="0.842979571428571">
Finally, the entire annotated parse tree is traversed to assign
translations to the nodes through a direct implementation of the process
described in Section II.C. (Type A and B objects in the following
examples are marked with a prefix A:&apos; or `B:&apos;.) For instance, the
VP node covering (persuade a woman to go), has the translation rule
VPTINFIIINFINITIVE1 When this is applied to the translations of
the node&apos;s constituents, we have
</bodyText>
<equation confidence="0.878962333333333">
(s: (X X (X P (X T (persuade T X (P X))),
[(A: 12, 0, (X S (some 12 (mass X2) S)),]
(cA: (X X (go X)))3
</equation>
<bodyText confidence="0.637569333333333">
which, after the appropriate applications are performed, yields
.ca: (X P (X Y (persuade Y X2 (P X2)) )) . 4.
()s S (some 12 (woman X2) 5)),
5Note that, although the annotation phase was described and is implemented pro-
cedurally, the process actually used guarantees that the resulting annotation is
ex- -tly the one specified declaratively by the annotation rules.
</bodyText>
<page confidence="0.976713">
4
</page>
<figure confidence="0.924592833333333">
[&lt;A: (X X (go X)),1
&lt;A: (X T (persuade T X2 (go X2))) .
(X S (sone X2 (Inman X2) S))s .
After the past operator has been applied, we have
&lt;A: (X Y (past (persuade Y X2 (go X2)))) . q.
(X S (some X2 (woman X2) S))s .
</figure>
<bodyText confidence="0.9388862">
At this point, the pull operator (pull.v) can be used to bring the
quantifier out of storage, yielding.
&lt;A: (X Y (some X2 (woman X2) (past (persuade TX2 (go 12))))).
This will ultimately result in &amp;quot;a woman&amp;quot; getting narrow scope. The
other alternative is for the quantifier to remain in storage, to be pulled
only at the full sentence level, resulting in the other scoping. hi Figure
2, we have added the translations to all the nodes of the parse tree.
Nodes with the same translations as their parents were left unmarked.
From examination of the S node translations, the original sentence is
given the fully-scoped translations
(every 12 (man 12)
(mai. (woman X1) (past (persuade 12 X1 (gall)))))
and
(some Xi (woman X1)
(every X2 (man X2) (past (persuade X2 X1 (go X1))))) .
</bodyText>
<sectionHeader confidence="0.657553" genericHeader="method">
C A Simple Question-Answering System
</sectionHeader>
<bodyText confidence="0.99997535">
As mentioned in Section I, we were able to demonstrate the
semantic capabilities of our language system by assembling a small
question-answering system. Our strategy was to first translate English
into logical formulas of the type discussed in [Moore, 1981], which
were then postprocessed into a form suitable for a first-order deduc-
tion system? (Another possible approach would have been to translate
directly into first-order logic, or to develop direct proof procedures for
the non-first-order language.) Thus, we were able to integrate all the
components into a question-answering system by providing a simple
control structure that accepted an input, translated it into logical form,
reduced the translation to first-order logic, and then either asserted the
translation in the case of declarative sentences or attempted to prove it
in the case of interrogatives. (Only yes/no questions have been imple-
mented.)
The main point of interest is that our question-answering
system was able to handle complex semantic entailments involving
tense, modality, and so on—that, moreover, it was not restricted to
extensional evaluation in a data base, as with conventional question.
answering systems. For example, our system was able to handle the
entailments of sentences like
</bodyText>
<listItem confidence="0.94218">
• John could not have been persuaded to go.
(The transcript of a sample dialogue is included as Appendix C.)
</listItem>
<footnote confidence="0.8538715">
6For convenience, when a final constituent of a translation is id it is often not
written. Thus we could have written &lt;A: (X Y (some in this cue.
7We used a connection graph theorem prover written by Mark Stickel [Stickel,
forthcoming].
</footnote>
<table confidence="0.99538717948718">
(S: &lt;A: (past (persuade X1 12 (go n))) .
CX S (every X1 (man Xi) S))
(X S (some 12 (woman 12) 5))s,
&lt;A: (some 12 (woman 12) (past (persuade X112 (go X2)))).
(X S (every X1 (man X1) S)))
&lt;A: (every 12 (mann)
(some XI (woman X1) (past (persuade 12 X1 (go 12))))),
&lt;A: (some Xi (woman X1)
(every 12 (man 12) (past (persuade X2 Xi (go X2))))),
(SDEc
(NP: &lt;A: Xi, (X S (every X1 (man X1) 5)),
(DEW: 413: (X P (X S (every X (P X) S))).
Xs
(DDET (DET every)))
(NON: &lt;A: (XX (man Ins
MEM (NOUN (N man)))))
(PREDICATE: &lt;A: (X X (past (persuade T X2 (go X2)))).
(X S (some 12 (woman X2) 5))S.
&lt;A: (X X (some X2 (woo= X2)
(past (persuade T X2 (go X2)))))
46. 0
(AU: &lt;A: (X P (X X (past (P X))))s
(TENSE kpast))
(VP?: &lt;A: (X Y (persuade I&apos; X2 (go X2))).
(X S (some X2 (woman X2) S))10
(VP (VPT: &lt;A: (XX
(X P
(X T (persuade TX (PT))))
(V persuade)))
(NP: &lt;A: 12. If). (X S (some 12 (woman X2) S)))
(DEW: &lt;13: (X P (X S (some X (P S)))
Xs
(A a))
(NMI: &lt;A: (X X (rattan 1)))
(110110 (NOUN (N woman)))))
(INFINITIVE (TO: none
to)
MP: &lt;A: (X X (go X)),
(VP (VPT (V go]
</table>
<figureCaption confidence="0.939893">
Figure 2: Node-by-node translation of a sample sentence
</figureCaption>
<bodyText confidence="0.9906466875">
The reduction of logical form to first-order logic (FOL) was
parameterized by a set of recursive expansions for the syntactic ele-
ments of logical form in a manner similar to Moore&apos;s use of an
axiomatization of a modal language of belief. [Moore, 19801 For ex-
ample, (past 11 is expanded, with respect to a possible world w, as
(some w2 (and (past w2 w) &lt;P,w2&gt;))
where &amp;quot;&lt;P,w2&gt;&amp;quot; denotes the recursive FOL reduction of P relative
to the world w2. The logical form that was derived for the sample
sentence &amp;quot;John went&amp;quot; therefore reduces to the first-order sentence
(some w (and (past w REALWORLD)(go w John))).
More complicated illustrations of the results of translation and reduc-
tion are shown in Figure 3. Note, for example, the use of restricted
quantification in LF and ordinary quantification in FOL.
To compute the correct semantic entailments, the deduction
system was preloaded with a set of meaning postulates (axioms) giving
inferential substance to the predicates associated with lexical items (see
</bodyText>
<page confidence="0.991539">
5
</page>
<table confidence="0.896909058823529">
INPUT: every man must be happy
LF: (every X (man X)
(necessary (and (happy X)
(thing X))))
FOL: (every 20172
(implies (man REALVORLD 10172)
(every .0173
(implies (pose REALVORLD v3173)
(and (happy v0173 .0172)
(thing e0173 20172))))))
INPUT: bill persuaded John to go
LF: (past (persuade bill John (go John)))
FOL: (some .0175
(and (past v0175 REALIORLD)
(some v0170
(and (persuade .0175 bill john v0170)
(go .0175 john)))))
</table>
<figureCaption confidence="0.983278">
Figure 3: Translation to LF and Reduction to FOL
</figureCaption>
<sectionHeader confidence="0.810693" genericHeader="method">
Appendix B).
IV FURTHER EXTENSIONS
</sectionHeader>
<bodyText confidence="0.99739375">
We are continuing to refine the grammar formalism and im-
prove the implementation. Some of the refinements are intended to
make the annotations and translations easier to write. Examples in-
clude:
</bodyText>
<listItem confidence="0.904851">
• Allowing nonbinary features, including sets of values, in the
annotations and guards (extending the language to include
equality and set operations).
• Generalizing the language used to specify synthesis of logi-
cal forms and developing a more uniform treatment of
translation types.
• Generalizing the &amp;quot;gap&amp;quot; variable feature to handle ar-
</listItem>
<bodyText confidence="0.979906916666667">
bitrary collections of designated variables by using an
&amp;quot;environment&amp;quot; mechanism. This is useful in achieving a
uniform treatment of free word order in verb complements
and modifiers.
In addition, we are working on extensions of the syntactic
machinery, including phrase-linking grammars to handle displacement
phenomena [Peters, 19811, and methods for generating the augmented
phrase structure grammar through a metarule formalism similar to
that of [Konolige, 19801. We have also experimented with alternative
parsing algorithms, including a chart parser [Bear, 19791 adapted to
carry out annotation and translation in the manner described in this
paper.
</bodyText>
<sectionHeader confidence="0.999775" genericHeader="method">
REFERENCES
</sectionHeader>
<reference confidence="0.998226925925926">
Bear, John, and Lauri Karttunen. PSG: A Simple Phrase Structure
Parser. Texas Linguistic Forum, vol. 19. 1979.
Cooper, Robin. Quantification and Syntactic Theory. Forthcoming.
Reidel, Dordrecht.
Gazdar, Gerald. Phrase Structure Grammar. To appear in Jacobson,
0. and G. K. Pullum (eds.) On the Nature of Syntactic
Representation.
Kaplan, R. M., and Martin Kay. Personal communication. 1981.
Karttunen, Lauri, Rebecca Root, and Hans Uszkoreit. Morphological
analysis of Finnish by computer. Paper presented at the ACL
session of the 1981 LSA Annual Meeting, New York, December
1981.
Konolige, Kurt. Capturing linguistic generalizations with metarules in
an annotat,d phrase-structure grammar. Proceedings of the 18th
Annual Meeting of the Association for Computational Linguistics,
University of Pennsylvania, Philadelphia, June 1980.
Moore, Robert C. Problems in Logical Form. Proceedings of the 19th
Annual Meeting of the Association for Computational Linguistics,
Stanford University, Palo Alto, June, 1981.
Moore, Robert C. Reasoning About Knowledge and Action. SRI
International, Technical Note 191. October, 1980.
Peters, Stanley, and Robert W. Ritchie. Phrase Linking Grammars.
December 1981. Unpublished manuscript.
Robinson, Jane. DIAGRAM: A Grammar for Dialogues.
Communications of the ACM, 25:1 (January, 1982) 27-47.
Stickel, Mark. A Non-Clausal Connection Graph Resolution Theorem
Proving Program. Forthcoming.
</reference>
<sectionHeader confidence="0.960999" genericHeader="method">
APPENDIX A. Sample Grammar Rules
</sectionHeader>
<bodyText confidence="0.999521333333333">
The following is a portion of a test grammar for the PATR
English translation system. Only those portions of the grammar uti-
lized in analyzing the sample sentences in the text were included.
The full grammar handles the following constructs: modals, adjec-
tivals, tense, predicative and nonpredicative copulatives, adverbials,
quantified noun phrases, aspect, NP, PP, and infinitival complements,
relative clauses, yes/no questions, restricted wh-questions, noun-noun
compounds, passives, and prepositional phrases as predicates and ad-
jectivals.
</bodyText>
<table confidence="0.842990875">
mos===========.*: Grammar galas UUSUMMUSIOUMWMIVAMOMMISIM
Constant EQ&apos; m curry (LAMBDA (X T) (equal X Y))
Constant PASS&apos; *
&lt;A: (LAMBDA P (LAMBDA X UP X) Y))). NIL.
(MK.MBD (QUOTE (LAMBDA S (sons Y (thing Y) S)))) a
Constant PASSINF&apos; •
(A: (LAMBDA P (LAMBDA I (LAMBDA X MP X) I) Y)))). NIL.
(IMOD (QUOTE (LAMBDA S (sons 7 (thing 7) S)))) a
</table>
<sectionHeader confidence="0.90819975" genericHeader="method">
AUXP TENSE;
Translation:
TENSE&apos;
DDET DET:
Annotation:
Definite(DDET) ]
Translation:
DET&apos;
</sectionHeader>
<page confidence="0.99773">
6
</page>
<table confidence="0.801062916666667">
DETP A; I -,(GaPPY(NP) &amp; Gappy(PREDICATE)) 3
Annotation: Translation:
[ ,Definite(DETP) ] pull.s(PREDICATETW1)
Translation:
A&apos; VP -) VPT;
Annotation:
DETP -) DDET; [ ,Transitive(VPT) 3
Annotation: [ ,TakesInf(VPT) ]
I AGREE(DETP. DDET, Definite) 3 [ Active(VPT) ]
Translation: ( Active(VP) 3
DUET&apos; Translation:
VPT&apos;
INFINITIVE -) TO VPP:
Annotation: VP -) VPT NP INFINITIVE;
[ AGREE(INFINITIVE. VPP, Gappy. MA) 3 Annotation:
Translation: [ TakesInf(VPT) 3
pull.v(VPP&apos;) [ Transitive(VPT)
[ ,Predicative(NP) ]
NOM NOM; [ AGREE(VP. VPT, Active) 3
Annotation: [ Vh(NP) \/ VA(INFINITIVE) &lt;me 111(VP)
[ AGREE(NOM. NOMHD. Gappy) I [ IF(Active(VPT).
Translation: UGappy(le) 1/ Gappy(INFINITIVE)) &lt;a&gt; GappY(VP)).
NOIRD &amp; ,(Gappy(NP) A Gappy(INFINITIVE)),
(,Gappy(VPT) &amp; Gappy(NP)))
NOKHD NOUN; Translation:
Translation: Active(VP): pull..(VPT&apos;ENP&apos;HINFINITIVE1)
NOUN&apos; ,Active(VP): pull.v(PASSINF&apos;EVFNEINFINITIVE1)
NOUN -&gt; N; VP? -&gt; VP;
Translation: Annotation:
N. I AGREE(VPP, VP, Gappy. litt) I
[ Active(VP) ]
NP -) DETP NOM; Translation:
Annotation: VP&apos;
[ AGREE(NP. NOM, Gappy) 1
[ Predicative(NP) \/ ,Predicative(NP) ] VPT -e V;
[ AGREE(NP. DETP, Definite) 1 Annotation:
</table>
<reference confidence="0.990400086956522">
Translation: [ AGREE(VPT. V. Active, Transitive. TakesInf) 1
-,Predicatise(HP): DETP&apos;ENOM1 Translation:
Definite(NP) A Predicative(NP): EIVIDETP&apos;ENOM&apos;ll V&apos;
,Definite(NP) I Predicative(NP): NOM&apos;
PREDICATE -) AUXP VP?; seaccec.....cemeeftecrc=c-....., Lexicon sessmemonswssssusssmoss
Annotation:
man;
[AGREE(PREDICATE.VPP. Active. GaPPY. VA) I N -)
Translation: Translation:
pu1l.v(AUXP&apos;EVPP1) &lt;a: man, NIL, NIL &gt;
S -&gt; SDEC; N -&gt; woman;
Annotation: Translation:
,Gappy(SDEC) I (A: woman. NIL. NIL &gt;
( &amp;quot;Arh(SDEC) 1
Translation: DET -) every;
SDEC&apos; Annotation:
[ Definite(DET) ]
SDEC -) NP PREDICATE: Translation:
Annotation: &lt;B: (LAMBDA P (LAMBDA S (every I OP I) S))). X, NIL &gt;
[ Gappy(NP) \/ Gappy(PREDICATE) (ma GappylEDEC) ]
( ,Predicative(NP) I A -)
102(NP) \/ Tb(PREDICATE) &lt;=&gt; 1h(SDEC) 3 Translation:
&lt;9: (LAMBDA P (LAMBDA S (some X (P X) S))). X. NIL
</reference>
<page confidence="0.999279">
7
</page>
<table confidence="0.973529">
V -&gt; persuade; &gt;&gt; is John a happy man
Annotation: Yes.
( Transitive(Y) ] &gt;&gt; no man could have hidden a book
C Active(V) 1/ -,Active(V) 1 OK.
I TakesInf(V) &gt;&gt; did john hide a book
Translation: No.
curry (LANBDA (X P Y) (persuade Y X GP lap
</table>
<figure confidence="0.953829171428571">
V -&gt; go;
Annotation: &gt;, bill hid a book
( ,Transitive(V) ] OK.
-eratesIni(V) 3
setise(V) I ) is bill a man
Translation: No.
&lt;A: go, NIL. NIL &gt;
&gt;&gt; was John a man
TENSE -&gt; kpast; I don&apos;t know.
Translation:
curry (LAMA (P X) (past CP X))) ), every man will be a man
OK.
&gt;a will John be a man
APPENDIX B. Meaning Postulates i.e.
(every • (every u (iff (past w u) )&gt; bill persuaded john to go
(not (past u w] OK.
(every v (some u (Past w u)))
(every w (every a (every y (every z (implies (promise w a y z) &gt;&gt; could John have been persuaded to go
(past r z] Yes.
[every v (every z (every y (every z (implies (persuade w z y z)
)&gt; will john be persuaded to go
(past m z3 I don&apos;t know.
(every w (every a (thing w z)))
(every • (every z (every z (implies (want w z z)
(past • z]
(every w (pose w w))
[every * (every u (implies (past v u)
(pose m u]
(every w (every u (every • (implies (and (pasti • u)
(pasti u
(past2 w v]
[every v (every z (implies (past2 w z)
(past w
(every v (every z (iff (past w z)
(pasti w
</figure>
<sectionHeader confidence="0.392231" genericHeader="method">
APPENDIX C. Transcript of Sample Dialogue
</sectionHeader>
<reference confidence="0.431058125">
ee john is happy
OK.
&gt;e is john happy
Yes.
» is John a happy man
I don&apos;t know.
), john is a man
nK.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.974713">
<title confidence="0.997742">TRANSLATING ENGLISH INTO LOGICAL FORM&apos;</title>
<author confidence="0.99994">Stanley J Rosenschein Stuart M Shieber</author>
<affiliation confidence="0.999759">Artificial Intelligence Center SRI International</affiliation>
<address confidence="0.998429">333 Ravenswood Avenue Menlo Park, CA 94025</address>
<abstract confidence="0.997822888888889">A scheme for syntax-directed translation that mirrors compositional model-theoretic semantics is discussed. The scheme is the basis for an English translation system called PATR and was used to specify a semantically interesting fragment of English, including such constructs as tense, aspect, modals, and various lexically controlled verb complement structures. PATR was embedded in a question-answering system that replied appropriately to questions requiring the computation of logical entailments.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John Bear</author>
<author>Lauri Karttunen</author>
</authors>
<title>PSG: A Simple Phrase Structure Parser. Texas Linguistic Forum,</title>
<date>1979</date>
<volume>19</volume>
<marker>Bear, Karttunen, 1979</marker>
<rawString>Bear, John, and Lauri Karttunen. PSG: A Simple Phrase Structure Parser. Texas Linguistic Forum, vol. 19. 1979.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Robin Cooper</author>
</authors>
<title>Quantification and Syntactic Theory.</title>
<location>Forthcoming. Reidel, Dordrecht.</location>
<marker>Cooper, </marker>
<rawString>Cooper, Robin. Quantification and Syntactic Theory. Forthcoming. Reidel, Dordrecht.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Gerald Gazdar</author>
</authors>
<title>Phrase Structure Grammar. To appear</title>
<booktitle>On the Nature of Syntactic Representation.</booktitle>
<editor>in Jacobson, 0. and G. K. Pullum (eds.)</editor>
<marker>Gazdar, </marker>
<rawString>Gazdar, Gerald. Phrase Structure Grammar. To appear in Jacobson, 0. and G. K. Pullum (eds.) On the Nature of Syntactic Representation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Kaplan</author>
<author>Martin Kay</author>
</authors>
<title>Personal communication.</title>
<date>1981</date>
<booktitle>Paper presented at the ACL session of the 1981 LSA Annual Meeting,</booktitle>
<location>New York,</location>
<marker>Kaplan, Kay, 1981</marker>
<rawString>Kaplan, R. M., and Martin Kay. Personal communication. 1981. Karttunen, Lauri, Rebecca Root, and Hans Uszkoreit. Morphological analysis of Finnish by computer. Paper presented at the ACL session of the 1981 LSA Annual Meeting, New York, December 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kurt Konolige</author>
</authors>
<title>Capturing linguistic generalizations with metarules in an annotat,d phrase-structure grammar.</title>
<date>1980</date>
<booktitle>Proceedings of the 18th Annual Meeting of the Association</booktitle>
<institution>for Computational Linguistics, University of Pennsylvania,</institution>
<location>Philadelphia,</location>
<marker>Konolige, 1980</marker>
<rawString>Konolige, Kurt. Capturing linguistic generalizations with metarules in an annotat,d phrase-structure grammar. Proceedings of the 18th Annual Meeting of the Association for Computational Linguistics, University of Pennsylvania, Philadelphia, June 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>Problems in Logical Form.</title>
<date>1981</date>
<booktitle>Proceedings of the 19th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<institution>Stanford University,</institution>
<location>Palo Alto,</location>
<contexts>
<context position="18098" citStr="Moore, 1981" startWordPosition="2854" endWordPosition="2855">ained by the system. Functions to perform the storage manipulation, gap handling, and the other features of translation presented earlier have all been realized in the translation component of the running system. The next section describes an actual grammar that has been used in conjunction with this translation system. Ill EXPERIMENTS IN PRODUCING AND USING LOGICAL FORM A A Working Grammar To illustrate the ease with which diverse semantic features could be handled, a grammar was written that defines a semantically interesting fragment of English along with its translation into logical form [Moore, 19811. The grammar for the fragment illustrated in this dialogue is compact occupying only a few pages, yet it gives both syntax and semantics for modals, tense, aspect, passives, and lexically controlled infinitival complements. (A portion of the grammar is included as Appendix A.)4 The full test grammar, loosely based on DIAGRAM [Robinson, 19821 but restricted and modified to reflect changes in approach, was the grammar used to specify the translations of the sentences in the sample dialogue of Appendix C. B An Example of the System&apos;s Operation The grammar presented in Appendix A encodes a relat</context>
<context position="22855" citStr="Moore, 1981" startWordPosition="3655" endWordPosition="3656">with the same translations as their parents were left unmarked. From examination of the S node translations, the original sentence is given the fully-scoped translations (every 12 (man 12) (mai. (woman X1) (past (persuade 12 X1 (gall))))) and (some Xi (woman X1) (every X2 (man X2) (past (persuade X2 X1 (go X1))))) . C A Simple Question-Answering System As mentioned in Section I, we were able to demonstrate the semantic capabilities of our language system by assembling a small question-answering system. Our strategy was to first translate English into logical formulas of the type discussed in [Moore, 1981], which were then postprocessed into a form suitable for a first-order deduction system? (Another possible approach would have been to translate directly into first-order logic, or to develop direct proof procedures for the non-first-order language.) Thus, we were able to integrate all the components into a question-answering system by providing a simple control structure that accepted an input, translated it into logical form, reduced the translation to first-order logic, and then either asserted the translation in the case of declarative sentences or attempted to prove it in the case of int</context>
</contexts>
<marker>Moore, 1981</marker>
<rawString>Moore, Robert C. Problems in Logical Form. Proceedings of the 19th Annual Meeting of the Association for Computational Linguistics, Stanford University, Palo Alto, June, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>Reasoning About Knowledge and Action.</title>
<date>1980</date>
<journal>SRI International, Technical Note</journal>
<contexts>
<context position="25576" citStr="Moore, 1980" startWordPosition="4144" endWordPosition="4145">(some X2 (woman X2) S))10 (VP (VPT: &lt;A: (XX (X P (X T (persuade TX (PT)))) (V persuade))) (NP: &lt;A: 12. If). (X S (some 12 (woman X2) S))) (DEW: &lt;13: (X P (X S (some X (P S))) Xs (A a)) (NMI: &lt;A: (X X (rattan 1))) (110110 (NOUN (N woman))))) (INFINITIVE (TO: none to) MP: &lt;A: (X X (go X)), (VP (VPT (V go] Figure 2: Node-by-node translation of a sample sentence The reduction of logical form to first-order logic (FOL) was parameterized by a set of recursive expansions for the syntactic elements of logical form in a manner similar to Moore&apos;s use of an axiomatization of a modal language of belief. [Moore, 19801 For example, (past 11 is expanded, with respect to a possible world w, as (some w2 (and (past w2 w) &lt;P,w2&gt;)) where &amp;quot;&lt;P,w2&gt;&amp;quot; denotes the recursive FOL reduction of P relative to the world w2. The logical form that was derived for the sample sentence &amp;quot;John went&amp;quot; therefore reduces to the first-order sentence (some w (and (past w REALWORLD)(go w John))). More complicated illustrations of the results of translation and reduction are shown in Figure 3. Note, for example, the use of restricted quantification in LF and ordinary quantification in FOL. To compute the correct semantic entailments, the </context>
</contexts>
<marker>Moore, 1980</marker>
<rawString>Moore, Robert C. Reasoning About Knowledge and Action. SRI International, Technical Note 191. October, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley Peters</author>
<author>Robert W Ritchie</author>
</authors>
<title>Phrase Linking Grammars.</title>
<date>1981</date>
<note>Unpublished manuscript.</note>
<marker>Peters, Ritchie, 1981</marker>
<rawString>Peters, Stanley, and Robert W. Ritchie. Phrase Linking Grammars. December 1981. Unpublished manuscript.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jane Robinson</author>
</authors>
<title>DIAGRAM: A Grammar for Dialogues.</title>
<date>1982</date>
<journal>Communications of the ACM,</journal>
<volume>25</volume>
<pages>27--47</pages>
<contexts>
<context position="18442" citStr="Robinson, 1982" startWordPosition="2908" endWordPosition="2909">PRODUCING AND USING LOGICAL FORM A A Working Grammar To illustrate the ease with which diverse semantic features could be handled, a grammar was written that defines a semantically interesting fragment of English along with its translation into logical form [Moore, 19811. The grammar for the fragment illustrated in this dialogue is compact occupying only a few pages, yet it gives both syntax and semantics for modals, tense, aspect, passives, and lexically controlled infinitival complements. (A portion of the grammar is included as Appendix A.)4 The full test grammar, loosely based on DIAGRAM [Robinson, 19821 but restricted and modified to reflect changes in approach, was the grammar used to specify the translations of the sentences in the sample dialogue of Appendix C. B An Example of the System&apos;s Operation The grammar presented in Appendix A encodes a relation between sentences and expressions in logical form. We now present a sample of this relation, as well as its derivation, with a sample sentence: &amp;quot;Every man persuaded a woman to go.&amp;quot; Lexical analysis relates the sample sentence to two morpheme streams: o every man &amp;ppl persuade a woman to go 4Since this is just a small portion of the actual</context>
</contexts>
<marker>Robinson, 1982</marker>
<rawString>Robinson, Jane. DIAGRAM: A Grammar for Dialogues. Communications of the ACM, 25:1 (January, 1982) 27-47.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Mark Stickel</author>
</authors>
<title>A Non-Clausal Connection Graph Resolution Theorem Proving Program.</title>
<publisher>Forthcoming.</publisher>
<marker>Stickel, </marker>
<rawString>Stickel, Mark. A Non-Clausal Connection Graph Resolution Theorem Proving Program. Forthcoming.</rawString>
</citation>
<citation valid="false">
<authors>
<author>V Active</author>
<author>Transitive</author>
</authors>
<title>TakesInf) 1 -,Predicatise(HP): DETP&apos;ENOM1 Translation: Definite(NP) A Predicative(NP): EIVIDETP&apos;ENOM&apos;ll V&apos; ,Definite(NP) I Predicative(NP): NOM&apos;</title>
<marker>Active, Transitive, </marker>
<rawString>Translation: [ AGREE(VPT. V. Active, Transitive. TakesInf) 1 -,Predicatise(HP): DETP&apos;ENOM1 Translation: Definite(NP) A Predicative(NP): EIVIDETP&apos;ENOM&apos;ll V&apos; ,Definite(NP) I Predicative(NP): NOM&apos;</rawString>
</citation>
<citation valid="false">
<title>AUXP VP?; seaccec.....cemeeftecrc=c-....., Lexicon sessmemonswssssusssmoss Annotation: man;</title>
<marker></marker>
<rawString>PREDICATE -) AUXP VP?; seaccec.....cemeeftecrc=c-....., Lexicon sessmemonswssssusssmoss Annotation: man;</rawString>
</citation>
<citation valid="false">
<authors>
<author>Active GaPPY</author>
</authors>
<title>VA) I N -) Translation: Translation: pu1l.v(AUXP&apos;EVPP1) man,</title>
<journal>NIL, NIL &gt; S -&gt; SDEC; N -&gt; woman; Annotation: Translation: ,Gappy(SDEC) I (A: woman. NIL. NIL &gt; ( &amp;quot;Arh(SDEC)</journal>
<volume>1</volume>
<marker>GaPPY, </marker>
<rawString>[AGREE(PREDICATE.VPP. Active. GaPPY. VA) I N -) Translation: Translation: pu1l.v(AUXP&apos;EVPP1) &lt;a: man, NIL, NIL &gt; S -&gt; SDEC; N -&gt; woman; Annotation: Translation: ,Gappy(SDEC) I (A: woman. NIL. NIL &gt; ( &amp;quot;Arh(SDEC) 1</rawString>
</citation>
<citation valid="false">
<title>Translation: DET -) every; SDEC&apos; Annotation:</title>
<journal>Definite(DET) ] SDEC -) NP PREDICATE: Translation:</journal>
<marker></marker>
<rawString>Translation: DET -) every; SDEC&apos; Annotation: [ Definite(DET) ] SDEC -) NP PREDICATE: Translation:</rawString>
</citation>
<citation valid="false">
<journal>Annotation: (LAMBDA P (LAMBDA S (every I OP I) S))). X, NIL &gt; [ Gappy(NP) \/ Gappy(PREDICATE) (ma GappylEDEC) ] ( ,Predicative(NP) I A -) 102(NP) \/ Tb(PREDICATE) &lt;=&gt;</journal>
<volume>1</volume>
<marker></marker>
<rawString>Annotation: &lt;B: (LAMBDA P (LAMBDA S (every I OP I) S))). X, NIL &gt; [ Gappy(NP) \/ Gappy(PREDICATE) (ma GappylEDEC) ] ( ,Predicative(NP) I A -) 102(NP) \/ Tb(PREDICATE) &lt;=&gt; 1h(SDEC) 3 Translation: &lt;9: (LAMBDA P (LAMBDA S (some X (P X) S))). X. NIL ee john is happy OK.</rawString>
</citation>
<citation valid="false">
<title>e is john happy Yes.</title>
<marker></marker>
<rawString>&gt;e is john happy Yes.</rawString>
</citation>
<citation valid="false">
<title>is John a happy man I don&apos;t know.</title>
<marker></marker>
<rawString>» is John a happy man I don&apos;t know.</rawString>
</citation>
<citation valid="false">
<authors>
<author>john</author>
</authors>
<title>is a man nK.</title>
<marker>john, </marker>
<rawString>), john is a man nK.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>