<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.74944">
A CASE FOR RULE-DRIVEN SEMANTIC PROCESSING
</title>
<author confidence="0.769669">
Martha Palmer
</author>
<affiliation confidence="0.852373">
Department of Computer and Information Science
University of Pennsylania
</affiliation>
<sectionHeader confidence="0.970048" genericHeader="abstract">
0.0 INTRODUCTION
</sectionHeader>
<bodyText confidence="0.999755703703704">
The primary task of semantic processing
is to provide an appropriate mapping between
the syntactic constituents of a parsed
sentence and the arguments of the semantic
predicates implied by the verb. This is
known as the Alignment Problem. (Levin)
Section One of this paper gives an
overview of a generally accepted approach to
semantic processing that goes through several
levels of representation to achieve this
mapping. Although somewhat inflexible and
cumbersome, the different levels succeed in
preserving the context sensitive information
provided by verb semantics. Section Two
presents the author&apos;s rule-driven approach
which is more uniform and flexible yet still
accommodates context sensitive constraints.
This approach is based on general underlying
principles for syntactic methods of
introducing semantic arguments and has
interesting implications for linguistic
theories about case. These implications are
dicussed in Section Three. A system that
implements this approach has been designed
for and tested on pulley problem statements
gathered from several physics text
books. (Palmer)
</bodyText>
<sectionHeader confidence="0.673326" genericHeader="method">
1.0 MULTI-STAGE SEMANTIC ANALYSIS
</sectionHeader>
<bodyText confidence="0.994818887323944">
A popular approach (Woods), (Simmons),
(Novak) for assigning semantic roles to
syntactic constituents can be described with
three levels of representation - a schema
level, a canonical level, and a predicate
level. These levels are used to bridge the
gap between the surface syntactic
representation and the &amp;quot;deep&amp;quot; conceptual
representation necessary for communicating
with the internal database. While the
following description of these levels may not
correspond to any one implementation in
particular, it will give the flavor of the
overall approach.
1.1 Schema Level The first level corresponds
to the possible surface order configurations
a verb can appear in. In a domain of
equilibrium problems the sentence
&amp;quot;A rope supports one end of a scaffold.&amp;quot;
could match a schema like &amp;quot;&lt;physobj&gt; SUPPORTS
&lt;locpart&gt; of &lt;physobj&gt;&amp;quot;. The word ordering
here implies that the first &lt;physobj&gt; is the
SUBJ and the &lt;locpart&gt; is the OBJ. Other
likely schemes for sentences involving the
SUPPORT verbs are &amp;quot;&lt;physobj&gt; SUPPORTS
&lt;physobj&gt; AT &lt;locpart&gt;,&amp;quot; &amp;quot;&lt;physobj&gt; SUPPORTS
&lt;force&gt;,&amp;quot; &amp;quot;&lt;physobj&gt; IS SUPPORTED,&amp;quot; and
&amp;quot;&lt;locpart&gt; IS SUPPORTED.&amp;quot;(Novak) Once a
particular sentence has matched a schema, it
is useful to rephrase the information in a
more &amp;quot;canonical&amp;quot; form, so that a single of
inference rules can apply to a group of
schemes.
1.2 Canonical Level This intermediate level
of representation usually consists of the
verb itself, (or perhaps a more primitive
semantic predicate chosen to represent the
verb) and a list of possible roles, e.g.
arguments to the predicate. These roles
correspond loosely to a union of the various
semantic types indicated in the schemes. The
schemes above could all easily map into:
SUPPORTS(&lt;physobj&gt;1,&lt;physobj&gt;2,
&lt;locpart&gt;,&lt;force&gt;).
The &amp;quot;canonical&amp;quot; verb representation
found at this level bears certain
similarities to a standard verb case frame,
(Simmons, Bruce) in the roles played by the
arguments to that predicate. There has been
some controversy over whether or not any
benefits are gained by labeling these
arguments &amp;quot;cases&amp;quot; and attempting to apply
linguistic generalities about case.
(Fillmore) The possible benefits do not seem
to have been realized, with a resulting shift
away from explicit ties to case in recent
work. (Charniak), (Wilke)
1.3 Predicate Level However, the implied
relationships between the arguments still
have to be spelled out, and this is the
function of our third and final level of
representation. This level necessarily makes
use of predicates that can be found in the
data base, and for the purposes of the
program is effectively a &amp;quot;deep&amp;quot; semantic
representation. A verb such as SUPPORT would
require several predicates in an equilibrium
domain. For example, the &apos;scaffold&apos; sentence
above could result in the following list
corresponding to the general predicates
listed immediately below.
</bodyText>
<subsectionHeader confidence="0.512351">
&apos;Scaffold Example
</subsectionHeader>
<bodyText confidence="0.8372434">
SUPPORT(rope,scaffold)
UP(Fl,rope)
DOWN(F2,scaffold)
CONTACT(rope,scaffold)
LOCPT(rtendl,rope)
LOCPT(rtend2,scaffold)
SAMEPLACE(rtendl,rtend2)
General Predicates
SUPPORT(&lt;physobj&gt;1,&lt;physobj&gt;2)
UP(&lt;force&gt;1,&lt;physobj&gt;1)
DOWN(&lt;force&gt;2,&lt;physobj&gt;2)
CONTACT(&lt;physobj&gt;1,&lt;physobj&gt;2)
LOCPT(&lt;locpart&gt;I,&lt;physobj&gt;1)
LOCPT(&lt;locpart&gt;2,&lt;physobj&gt;2)
SAMEPLACE(&lt;locpart&gt;1,&lt;locpart&gt;2)
</bodyText>
<page confidence="0.997841">
125
</page>
<bodyText confidence="0.965176949152542">
Producing the above list requires common
sense deductions (Bundy] about the existence
of objects filling arguments that do not
correspond directly to the canonical
arguments, i.e. the two &lt;locpt&gt;s, and any
arguments that were missing from the explicit
sentence. For instance, in our scaffold
example, no &lt;force&gt; was mentioned, and must
be inferred. The usefulness of the canonical
form is illustrated here, as it prevents
tedious duplication of inference rules for
slightly varying schemes.
The relevant information from the
sentence has now been expressed in a form
compatible with some internal database. The
goal of this semantic analysis has been to
provide a mapping between the original
syntactic constituents and the predicate
arguments in the final representation. For
our scaffold example the following mapping
has been achieved. The filling in of gaps in
the final representation, although motivated
by the needs of the database, also serves to
test and expand the mapping of the syntactic
constituents.
SUBJ &lt;- rope (physobj&gt;1
OBJ &lt;- end &lt;physobj&gt;2
OPPP&lt;- scaffold &lt;locpart&gt;2
An obvious question at this point is
whether or not the mappings from syntactic
constituents to predicate arguments can be
achieved directly, since the above
multi-stage approach has at least three major
disadvantages:
1) It is tedious for the programmer to
produce the original schemes, and the
resulting amount of special purpose code is
cumbersome. It is difficult for the
programmer to guarantee that all schemes have
been accounted for.
2) This type of system is not very
robust. A schema that has been left out
simply cannot be matched no matter how much
it has in common with stored schemes.
3) Because of the inflexibility of the
system it is frequently desirable to add new
information. Adding just one schema, much
less an entire verb, can be time consuming.
Row much of a hindrance this will be is
dependent on the extent to which the semantic
information has been embedded in the code.
The LUNAR project&apos;s use of a meaning
representation language greatly increased the
efficiency of adding new information.
The following section presents a system
that uses syntactic cues at the semantic
predicate level to find mappings directly.
This method has interesting implications for
theories about cases.
</bodyText>
<sectionHeader confidence="0.523134" genericHeader="method">
2.0 RULE-DRIVEN SEMANTIC ANALYSIS
</sectionHeader>
<bodyText confidence="0.999001904761905">
This section presents a system for
semantic processing that maps syntactic
constituents directly onto the arguments of
the semantic predicates suggested by the
verb. In order Co make these assignments,
the possible syntactic mappings must be
associated with each argument place in the
original semantic predicates. For instance,
the only possible syntactic constituent that
can be assigned to the &lt;physobj&gt;1 place of a
SUPPORT predicate is the SUBJ, and a
&lt;physobj&gt;2 can only be filled by an OBJ. But
a &lt;locpart&gt; might be an OBJ or the object of
an AT preposition, as in &amp;quot;The scaffold is
supported at one end.&amp;quot; (The scaffold in this
example is the syntactic subject of a passive
sentence, so it is also considered the
logical object. For our purposes we will
look on it as an OBJ). It might seem at
first glance that we would want to allow our
&lt;physobj&gt;2 to be the object of an . OF
preposition, as in &amp;quot;The rope supports one and
of the scaffold.&amp;quot; But that is only true if
the OFPP follows something like a &lt;locpart&gt;
which can be an OBJ in a sentence about
SUPPORT. (Of course, just any OFPP will not
supply a &lt;physobj&gt;2. In &amp;quot;The rope supports
the end of greatest weight.&amp;quot;, the object of
the OFPP is not a &lt;physobj&gt; so could not
satisfy &lt;physobj&gt;2. The &lt;physobj&gt;2 in this
case must be provided by the previous
context.)
It is this very dependency on the
existence of other specific types of
syntactic constituents that was captured by
the schemes mentioned above. It is necessary
for an alternative system to also handle
context sensitive constraints.
2.1 Decision Trees The three levels of
representation mentioned in Section One can
be viewed as the bottom, middle and top of a
tree.
</bodyText>
<figure confidence="0.4507615">
SUPPORT(pl,p2)
CONTACT(pl,p2)
LOCPT(Iptl,p1)
LOCPT(Ipt2,p2)
SUPPORT(pl,p2,1pt,force)
/ \
/ \
SUBJ OBJ OFPP
&lt;physobj&gt; SUPPORTS &lt;locpart&gt; OF &lt;physobj&gt;
&amp;quot;The rope supports one end of the scaffold.&amp;quot;
</figure>
<page confidence="0.99047">
126
</page>
<bodyText confidence="0.999990770833333">
The inference rules that link the three
levels deal mainly with any necessary
renaming of the role an argument plays. The
SUBJ of the schema level is renamed
&lt;physobj&gt;1 or pl at the canonical level, and
is still pl at the predicate level.
One way of viewing the schemes is as
leaf nodes produced by a decision tree that
starts at the predicate level. The levels of
the tree correspond to the different
syntactic constituents that can map onto the
arguments of the original set of predicates.
Since more than one argument can be renamed
as a particular syntactic constituent, there
can be more than one branch at each level.
If a semantic argument might not be mentioned
explicitly in the syntactic configuration,
this also has to be expressed as a rule, ex.
pl -&gt; NULL. (Ex. &amp;quot;The scaffold is
supported.&amp;quot;) When all of the branches have
been taken, each terminal node represents the
set of decisions corresponding to a
particular schema. (See Appendix A.) Note
that the canonical level never has to be
expressed explicitly. By working top down
instead of bottom up unnecessary duplication
of inference rules is automatically avoided.
The information in the original three
levels can be stored equivalently as the top
node of the decision tree along with the
renaming rules for the semantic arguments
(rewrite rules). This would reverse the
order of analysis from the bottom-up mode
suggested in section one to a top-down mode.
This uses a more compact representation, but
would be computationally less efficient.
Growing the entire decision tree every time a
sentence needed to be matched would be quite
cumbersome. However, if only the path to the
correct terminal node needed to be generated,
this approach would be computationally
competitive. By ordering the decisions
according to syntactic precedence, and by
using the data from the sentence in question
to prune the tree WHILE it is being
generated, the correct decisions can usuallly
be made, with the only path explored being
the path to the correct schema.
</bodyText>
<subsectionHeader confidence="0.895699">
2.2 Context Sensitive Constraints Context
</subsectionHeader>
<bodyText confidence="0.97449172972973">
sensitivity can be preserved by only allowing
the p2-&gt;OFPP rule to apply after a mapping
for Iptl has been found, evidence that an
lptl-&gt;OBJ rule could have already applied.
To test whether such a mapping has been made
given a LOCPT predicate, it is only necessary
to see if the lptl argument has been renamed
by a syntactic constituent. The renaming
process can be thought of as an instantiation
of typed variables, - the semantic arguments
- by syntactic constituents. [Palmer,
Gallier, and Weiner] Then the following
preconditions must be satisfied before
applying the p2-&gt;OPPP rule: ( A stands for
AND)
p2-&gt;OFPP/ LOCPT(Iptl,p2)
not(variable(lpt1))
These preconditions will still need to
be satisfied when a LOCPT predicate is part
of another verb representation. Anytime a
&lt;locpart&gt; is mentioned it can be followed by
an OFPP introducing the &lt;physobj&gt; of which it
is a location part. This relationship
between a &lt;locpart&gt; and a &lt;physobj&gt; is just
as valid when the verb is &apos;hang&apos; or
&apos;connect.&apos; Ex. &amp;quot;The pulley is connected to
the right end of the string.&amp;quot; &amp;quot; The particle
is hung from the right end of the string.&amp;quot;
These particular constraints are general to
the domain rather than being restricted to
&apos;support&apos;. This illustates the efficiency of
associating constraints with semantic
predicates rather than verbs, allowing for
more advantage to be taken of generalities.
There is an obvious resemblance here to
the notation used for Local Constraints
grammars (Joshi and Levy]:
</bodyText>
<equation confidence="0.4947585">
p2-&gt;OPPP/ DOM(LOCPT)
LMS(Iptl) not(var(lpt1))
DOM - DOMinate,
LMS - Left Most Sister
</equation>
<bodyText confidence="0.998691837837838">
It can be demonstrated that the context
sensitive constraints presented here are a
Simple special case of their Local
Constraints, since the dominating node is
limited to being the immediate predicate
head. Whether or not such a restricted local
context will prove sufficient for more
complex domains remains to be proven.
2.3 Overview As illustrated above, our
mappings from syntactic constituents to
semantic arguments can be found directly,
thus gaining flexibility and uniformity
without losing context sensitivity. Once the
verb has been recognized, the semantic
predicates representing the verb can drive
the selection of renaming rules directly,
avoiding the necessity of an intermediate
level of representation. The contextual
dependencies originally captured by the
schemes are preserved in preconditions that
are associated with the application of the
renaming rules. Since the renaming rules and
the preconditions refer only to semantic
predicates and arguments to the predicates,
there is a sense in which they are
independent of individual verbs. By applying
only those rules that are relevant to the
sentence in question, the correct mappings
can be found quickly and efficiently. The
resulting system is highly flexible, since
the same predicates are used in the
representation of all the verbs, and many of
the preconditions are general to the domain.&apos;
This facillitates the addition of similar
verbs since most of the necessary semantic
predicates with the appropriate renaming
rules will already be present.
</bodyText>
<page confidence="0.994128">
127
</page>
<sectionHeader confidence="0.88561" genericHeader="method">
3.0 THE ROLE OF CASE INFORMATION
</sectionHeader>
<bodyText confidence="0.9558054375">
Although the canonical level has often
been viewed as the case frame level, doing
away with the canonical level does not
necessarily imply that cases are no longer
relevant to semantic processing. On the
contrary, the importance here of syntactic
cues for introducing semantic arguments
places even more emphasis on the traditional
notion of case. The suggestion is that the
appropriate level for case information is in
fact the predicate level, and that most
traditional cases should be seen as arguments
to clearly defined semantic predicates.
These predicates are not merely the
simple set of flat predicates indicated in
the previous sections. There is an implicit
structuring to that set of predicates
indicated by the implications holding between
them. A SUPPORT relationship implies the
existence of UP and DOWN forces and a CONTACT
relationship. A CONTACT relationship implies
the existence of LOCPT&apos;s and a SAMEPLACE
relationship between them. The set of
predicates describing &apos;support&apos; can be
produced by expanding the implications of the
SUPPORT(pl,p2) predicate into UP(fl,p1) and
DOWN(f2,p2) and CONTACT(pl,p2).
CONTACT(pl,p2) is in turn expanded into
LOCPT(Iptl,p1) and LOCPT(lpt2,p2) and
SAMEPLACE(1p1,1pt2). These definitions, or
expansions, are represented as the following
rewrite rules:
</bodyText>
<figure confidence="0.920425857142857">
support&lt;-&gt;SUPPORT(p1,p2)
SUPPORT (p
UP(fl,p1)/\DOWN(f2,p2)
ACONTACT(pl,p2)
CONTACT(p1,p2)&lt;-&gt;
LOCPT(lpt1,p1)/\LOCPT(lpt2,p2)
ASAMEPLACE(pl,p2)
</figure>
<bodyText confidence="0.99742996969697">
When &apos;support&apos; has been recognized as
the verb, these rules can be applied, to
build up the set of semantic predicates
needed to represent support. If there were
expansions for UP and DOWN they could be
applied as well. As the rules are being
applied the mappings of syntactic
constituents to predicate arguments can be
made at the same time, as each argument is
introduced. The case information is not
merely the set of semantic predicates or just
the SUPPORT(pl,p2) predicate alone. Rather,
the case information is represented by the
set of predicates, the dependencies indicated
by the expansions for the predicates, and the
renaming rules that are needed to find the
appropriate mappings. The renaming rules
correspond to the traditional syntactic cues
for introducing particular cases. They are
further restricted by being associated with
the predicate context of an argument rather
than the argument in isolation.
When this structured case information is
used to drive semantic processing, it is not
a passive frame that waits for its slots to
be filled, but rather an active structure
that goes in search of fillers for its
arguments. If these instantiations are not
indicated explicitly by syntax, they must be
inferred from a world model. The following
example illustrates how the active case
structure can also supply cases not mentioned
explicitly in the sentence.
</bodyText>
<subsectionHeader confidence="0.993698">
3.1 Example Given a pair of sentences like
</subsectionHeader>
<bodyText confidence="0.999825571428571">
&amp;quot;Two men are lifting a dresser. A rope
supports the end of greatest weight.&amp;quot;
we will assume that the first sentence
has already been processed. Having
recognized that the verb of the second
sentence is &apos;support&apos;, the appropriate
expansion can be applied to produce:
</bodyText>
<equation confidence="0.7703414">
SUPPORT(rope,p2)
This would in turn be expanded to:
UP(fl,rope)
DOWN(f2,p2)
CONTACT(rope,p2)
</equation>
<bodyText confidence="0.99995508">
In expanding the CONTACT relationship,
an lptl for &apos;rope&apos; and a p2 for &apos;end&apos; need to
be found. (See Section Two) Since the
sentence does not supply an ATPP that might
introduce an lptl for the &apos;rope&apos; and since
there are no more expansions that can be
applied, a plausible inference must be made.
The Iptl is likely to be an endpoint that is
not already in contact with something
else.This implicit object corresponding to
the free end of the rope can be name
&apos;ropend2.&apos; The p2 is more difficult. The
OFPP does not introduce a &lt;physobj&gt;, although
it does specify the &apos;end&apos; more precisely.
The &apos;end&apos; must first be recognized as
belonging to the d , and then as being
its heaviest end, &apos;dreseerand2.&apos; This is
really an anaphora problem that cannot be
decided by the verb, and could in fact have
already been handled. Given &apos;d sssss rend2&apos;,
it only remains for the &apos;dresser&apos; to be
inferred as the p2 of the LOCPT relationship,
using the same principles that allow an OFPP
to introduce a p2. The final set of
predicates would be
</bodyText>
<equation confidence="0.620662272727273">
SUPPORT(rope,dresser)
/I\
/ I.\
/ I \
UP(fl,rope) 1 DOWN(f2,dresser)
CONTACT(rope,dresser)
&apos;I&apos;
/ I \
/ I \
LOCPT(ropend2,rope)LOCPT(dresserend2,dresser)
SAMEPLACE(ropend2,dresserend2)
</equation>
<bodyText confidence="0.999796125">
Both the ropend2 and &apos;dresser&apos; were
supplied by plausible reasoning using the
context and a world model. There are always
many inferences that can be drawn when
processing a single sentence. The detailed
nature of the case structure presented above
gives one method of regulating this
inferencing.
</bodyText>
<page confidence="0.995271">
128
</page>
<subsectionHeader confidence="0.994693">
3.2 Associations with linguistics A recent
</subsectionHeader>
<bodyText confidence="0.999714384615385">
trend in linguistics to consider cases as
arguments to thematic relations offers a
surprising amount of support for this
position. Without denying the extremely
useful ties between syntactic constituents
and semantic cases, Jackendoff questions the
ability of case to capture complex semantic
relationships. (Jackendoff) His main
objection is that standard case theory does
not allow a noun phrase to be assigned more
than one case. In examples like &amp;quot;Esau traded
his birthright (to Jacob) for a mess of
pottage,&amp;quot; Jackendoff sees two related
actions: &amp;quot;The first is the change of hands
of the birthright from Esau to Jacob. The
direct object is Theme, the subject is
Source, and the to-object is Goal. Also
there is what I will call the secondary
action, the changing of hands of the mess of
pottage in the other direction. In this
action, the for-phrase is Secondary Theme,
the subject is Secondary Goal, and the
to-phrase is Secondary Source.&amp;quot; (p.35] This,
of course, could not be captured by a
Fillmore-like case frame. Jackendoff
concludes that, &amp;quot;A theory of case grammar in
which each noun phrase has exactly one
semantic function in deep structure cannot
provide deep structures which satisfy the
strong Katz-Postal Hypothesis, that is, which
provide all semantic information about the
sentence.&amp;quot; Jackendoff is not completely
discarding case information, but rather
suggesting a new level of semantic
representation that tries to incorporate some
of the advantages of case. Making
constructive use of Gruber&apos;s system of
thematic relationships [Gruber], Jackendoff
postulates &amp;quot;The thematic relations can now be
defined in terms of (these] semantic
subfunctions. Agent is the argument of CAUSE
that is an individual; Theme is the argument
of CHANGE that is an individual; Source and
Goal are the initial and final state
arguments of CHANGE. Location will be
defined in terms of a further semantic
function BE that takes an individual (the
Theme) and a state (the Location).[P-39]
Indeed, Jackendoff is one example of a
trend noted by Janet Fodor She points out
that &amp;quot;it may be more revealing to regard the
noun phrases which are associated in a
variety of case relations with the LEXICAL
verb as the arguments of the primitive
SEMANTIC predicates into which it is
analyzed. These semantic predicates
typically have very few arguments, perhaps
three at the most, but there are a lot of
them and hence there will be a lot of
distinguishable &apos;case categories.&apos;(Those
which Fillmore has identified appear to be
those associated with semantic components
that are particularly frequent or prominent,
such as CAUSE, USE, BECOME, AT.)&amp;quot; (17.93]
Fodor summarizes with, &amp;quot;As a contribution to
semantics, therefore, it seems best to regard
Fillmore&apos;s analyses as merely stepping stones
on the way to a more complete specification
of the meanings of verbs.&amp;quot; The one loose end
in this neat summation of case is its
relation to syntax. Fodor continues,
&amp;quot;Whether there are any SYNTACTIC properties
of case categories that Fillmore&apos;s theory
predicts but which are missed by the semantic
approach is another question....&amp;quot;
It is the thesis of this paper that
these syntactic properties of case categories
are the very cues that are used to drive the
filling of semantic arguments by syntactic
constituents. This system also allows the
same syntactic constituent to fill more than
one argument, e.g. case category. The
following section presents further evidence
that this system could have direct
implications for linguistic theories about
case. Although it may at first seem that the
analysis of the INSTRUMENT case contradicts
certain assumptions that have been made, it
actually serves to preserve a useful
disctinction between marked and unmarked
INSTRUMENTS.
</bodyText>
<subsectionHeader confidence="0.995288">
3.3 The INSTRUMENT Case
</subsectionHeader>
<bodyText confidence="0.98303003125">
The cases necessary for &apos;support&apos; were
all accomodated as arguments to semantic
primitives. This does not imply, however,
that cases can never play a more important
role in the semantic representation. It is
possible for a case to have its own expansion
which contains information about how semantic
predicates should be structured. There is
quite convincing evidence in the pulley
domain for the influential effect of one
particular case.
In this domain INSTRUMENTS are
essentially &apos;intermediaries&apos; in &apos;hang&apos; and
&apos;connect&apos; relationships. An &lt;inter&gt;mediary
is a flexible line segment that effects a
LOCATION or CONTACT relationship respectively
between two physical objects. Example
sentences are &amp;quot;A particle is hung by a string
from .a pulley,&amp;quot; and &amp;quot;A particle is connected
to another particle by a string.&amp;quot; The
following rewrite rules are the expansions
for the &apos;hang&apos; and &apos;connect&apos; verbs, where the
EFFECT predicate will have its own expansion
corresponding to the definition of an
intermediary.
hang &lt;-&gt; EFFECT(inter,LOCATION(pl,loc))
connect &lt;-&gt; EFFECT(inter,CONTACT(pl,p2))
Application of these rules repectivelY
results in the following representation for
the example sentences:
EFFECT(string,LOCATION(particlel,pulley1))
EFFECT(string,CONTACT(particlel,particle2))
</bodyText>
<page confidence="0.994621">
129
</page>
<bodyText confidence="0.960126333333333">
The expansion of EFFECT itself is:
That the distinction between marked and
unmarked INSTRUMENTS can be captured by the
EFFECT relationship is illustrated by the
processing of the following two sentences:
EFFECT(inter, REL(argl,arg2)) &lt;-&gt;
REL(argl,inter),
REL(inter,arg2))
where REL stands for any semantic
predicate. The application of this expansion
to the above representations results in:
LOCATION(particlel,string)
LOCATION(string,pulley1)
and
CONTACT(particlel,string)
CONTACT(string,particle2)
These predicates can then be expanded,
with LOCATION bringing in SUPPORT and
CONTACT, and CONTACT bringing in LOCPT.
3.4 Possible Implications There seems to be a
direct connection between the previous
expansion of intermediary and the analysis of
the INSTRUMENT case done by Beth Levin at
MIT.[Levin) She pointed out a distinct
difference in the use of the same INSTRUMENT
in the following two sentences:
&amp;quot;John cut his foot with a rock.&amp;quot;
&amp;quot;John cut his foot on a rock.&amp;quot;
In the first sentence there is an
implication that John was in some way
controlling&apos; the cutting of his foot, and
using the rock to do so. In the second
sentence there is no such implication, and
John probably cut his foot accidentally. The
use of the &apos;with&apos; preposition marks the rock
as an INSTRUMENT. that is being manipulated
by John, whereas &apos;on&apos; introduces an unmarked
INSTRUMENT with no implied relationshion to
John. It would seem that something like the
expansion for EFFECT could help to capture
part of what is being implied by the
&apos;control&apos; relationship. Bringing in the
transitivity relationship makes explicit a
connection between John and the rock as well
as between the foot and the rock. In the
second sentence only the connection between
the foot and the rock is implied. The
connection implied here is certainly more
complicated than a simple CONTACT
relationship, and would neccessitate a more
detailed understanding of &apos;cut.&apos; But the
suggestion of &apos;control&apos; is at least indicated
by the embedding of the CUT predicate within
EFFECT and CAUSE.
CAUSE(John,EFFECT(rock,(CUT(foot-of-John)))
The tie between the AGENT and the
INSTRUMENT is another implication of
&apos;control&apos; that should be explored.
&amp;quot;The particle is hung from a pulley by a
S tring.&amp;quot;
&amp;quot;The particle is hung on a string.&amp;quot;
In the first sentence an &apos;inter&apos; (a
marked INSTRUMENT) is supplied by the BYPP,
and the following representation is produced:
EFFECT(string,LOCATION(particle,pulley))
In the second sentence no &apos;inter&apos; is
found, and in the absence of an &apos;inter&apos; the
EFFECT relationship cannot be expanded. The
LOCATION(particle,string) predicate is left
to stand alone and is in turn expanded. (The
ONFP can indicate a &apos;loc.&apos;)
The intriguing possibility of verb
independent definitions for cases requires
much more exploration.(Charniak) The
suggestion here is that a deeper level of
representation, the predicate level, is
appropriate for investigating case
implications, and that important cases like
AGENTS and INSTRUMENTS have implications for
meta-level structuring of those predicates.
3.5 Summary In summary, there is a surprising
amount of information at â€¢ the semantic
predicate level that allows syntactic
constituents to be mapped directly onto
semantic arguments. This results in a
semantic processer that has the advantage of
being easy to build and more flexible than
existing processers. It also brings to light
substantial evidence that cases should not be
discarded but should be reexamined with
respect to the roles they play as arguments
to semantic predicates. The INTERMEDIARY
case is seen to play a particularly important
role having to do not with any particular
semantic predicate, but with the choice of
semantic predicates in general.
</bodyText>
<sectionHeader confidence="0.999107" genericHeader="method">
References
</sectionHeader>
<reference confidence="0.999928736842105">
(1) Bruce, B., Case system for natural
language, &amp;quot;Artificial Intelligence,&amp;quot; Vol. 6,
No. 4, Winter, pp. 327-360.
(2] Bundy, et-al, Solving Mechanics Problems
Using Meta-Level Inference, Expert Systems in
the Micro-Electronic ALI, Michie, D.(ed),
Edinburgh University Press, Edinburgh, U.K.,
1979.
(31 Charniak, E., A brief on case, Working
Paper No.22, (Castagnola: Institute for
Semantics and Cognitive Studies), 1975.
(41 Fillmore, C., The case for case,
Universals in Linguistic Theory, Bach and
Harms (eds.) New York; Rolt, Rinehart and
Winston, pp. 1-88.
(5) Fodor, Janet D., Semantics: Theories of
Meaning in Generative Grammar, Language and
Thought Series, Thomas Y. Crowell Co., Inc.,
1977, p. 93
</reference>
<page confidence="0.970879">
130
</page>
<reference confidence="0.993278823529412">
(6) Gruber, J.S., Lexical Structures in
Syntax and Semantics, North-Holland Pub.
Co., 1976.
[7) Jackendoff, R.S., Semantic Interpreter in
Generative Grammar, MIT Press, Cambridge, MA,
1972, P. 39.
(8) Levin, B. &amp;quot;Instrumental With and the
Control Relation in English,&amp;quot; MIT Master&apos;s
Thesis, 1979.
(91 Novak, G.S., Computer Understanding of
Physics Problems Stated in Natural
Language,American Journal of Computational
Linguistics, Microfiche 53, 1976.
(10) Palmer, M., Where to Connect? Solving
Problems in Semantics, DAI Working Paper No.
22, University of Edinburgh, July 1977.
(111 Palmer, M., &amp;quot;Driving Semantics for a
Limited Domain,&amp;quot; Ph.D. Thesis, forthcoming,
University of Edinburgh.
(12) Palmer, M., Gallier, J., and Weiner, J.,
Implementations as Program Specifications: A
Semantic Processer in Prolog, (submitted
IJCAI, Vancouver, August 1981).
(13) Simmons, R.F., Semantic Networks: Their
Computation and Use for Understanding English
Sentences, Computer Models of Thought and
Language, Schank and Colby (eds.) San
Francisco: W.H. Freeman and Co., 1973.
(14) Wilks, Y., Processing Case, &amp;quot;American
Journal of Computational Linguistics,&amp;quot; 1976.
[15) Woods, W.A., Semantics and
Quantification in Natural Language Question
Answering, BBN Report 3687, Cambridge, Mass,
November 1977.
</reference>
<sectionHeader confidence="0.738078" genericHeader="method">
APPENDIX A
</sectionHeader>
<figure confidence="0.9516271875">
SUPPORT(pl,p2) CONTACT(Pl.P2)
LOCPT(lptl,p1) LOCPT(lpt2,p2)
pl -&gt; SUBJ pl -&gt; NULL
SUPPORT(SUBJ,p2) A CONTACT(SUBJ,p2) SUPPORT(pl,p2) CONTACT(pl,p2)
A LOCPT(lptl,SUBJ) LOCPT(Ipt2,p2) LOCPT(lptl,p1) LOCPT(Ipt2,p2)
p2 -&gt; OBJ/ Ipt2 -&gt; OBJ /.
etc. etc.
SUPPORT(SUBJ,OBJ) SUPPORT(SUBJ,p2)
CONTACT(SUBJ,OBJ) CONTACT(SUBJ,p2)
LOCPT(lptl,SUBJ) LOCPT(lptl,SUBJ)
LOCPT(Ipt2,OBJ) LOCPT(OBJ,p2)
lpt2 -&gt; ATPP \ p2 -&gt; OFPP
SUPPORT(SUBJ,OBJ) SUPPORT(SUBJ,OFTP)
CONTACT(SUBJ,OBJ) CONTACT(SUBJ,OFPP)
LOCPT(lptl,SUBJ) LOCPT(lptl,SUBJ)
/\ LOCPT(ATPP,OBJ) LOCPT(OBJ,OPPP)
</figure>
<sectionHeader confidence="0.964572333333333" genericHeader="method">
SUBJ OBJ ATPP
&lt;physobj&gt; SUPPORTS &lt;physobj&gt; AT &lt;locpart&gt; \
SUBJ OBJ OFPP
</sectionHeader>
<reference confidence="0.734724">
&lt;physobj&gt; SUPPORTS &lt;locpart&gt; OF &lt;physobj&gt;
</reference>
<page confidence="0.998065">
131
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000007">
<title confidence="0.998214">A CASE FOR RULE-DRIVEN SEMANTIC PROCESSING</title>
<author confidence="0.999986">Martha Palmer</author>
<affiliation confidence="0.9969695">Department of Computer and Information Science University of Pennsylania</affiliation>
<abstract confidence="0.9835626">The primary task of semantic processing is to provide an appropriate mapping between the syntactic constituents of a parsed sentence and the arguments of the semantic predicates implied by the verb. This is known as the Alignment Problem. (Levin) Section One of this paper gives an overview of a generally accepted approach to semantic processing that goes through several levels of representation to achieve this mapping. Although somewhat inflexible and cumbersome, the different levels succeed in preserving the context sensitive information provided by verb semantics. Section Two presents the author&apos;s rule-driven approach which is more uniform and flexible yet still accommodates context sensitive constraints. This approach is based on general underlying principles for syntactic methods of introducing semantic arguments and has interesting implications for linguistic theories about case. These implications are dicussed in Section Three. A system that implements this approach has been designed for and tested on pulley problem statements gathered from several physics text books. (Palmer) SEMANTIC ANALYSIS A popular approach (Woods), (Simmons), (Novak) for assigning semantic roles to syntactic constituents can be described with three levels of representation a schema level, a canonical level, and a predicate level. These levels are used to bridge the gap between the surface syntactic representation and the &amp;quot;deep&amp;quot; conceptual representation necessary for communicating with the internal database. While the following description of these levels may not correspond to any one implementation in particular, it will give the flavor of the overall approach. 1.1 Schema Level The first level corresponds to the possible surface order configurations a verb can appear in. In a domain of equilibrium problems the sentence &amp;quot;A rope supports one end of a scaffold.&amp;quot; could match a schema like &amp;quot;&lt;physobj&gt; SUPPORTS &lt;locpart&gt; of &lt;physobj&gt;&amp;quot;. The word ordering here implies that the first &lt;physobj&gt; is the SUBJ and the &lt;locpart&gt; is the OBJ. Other likely schemes for sentences involving the SUPPORT verbs are &amp;quot;&lt;physobj&gt; SUPPORTS &lt;physobj&gt; AT &lt;locpart&gt;,&amp;quot; &amp;quot;&lt;physobj&gt; SUPPORTS &lt;force&gt;,&amp;quot; &amp;quot;&lt;physobj&gt; IS SUPPORTED,&amp;quot; and &amp;quot;&lt;locpart&gt; IS SUPPORTED.&amp;quot;(Novak) Once a particular sentence has matched a schema, it is useful to rephrase the information in a more &amp;quot;canonical&amp;quot; form, so that a single of inference rules can apply to a group of schemes. CanonicalLevel This intermediate level of representation usually consists of the verb itself, (or perhaps a more primitive semantic predicate chosen to represent the verb) and a list of possible roles, e.g. arguments to the predicate. These roles correspond loosely to a union of the various semantic types indicated in the schemes. The schemes above could all easily map into: SUPPORTS(&lt;physobj&gt;1,&lt;physobj&gt;2, &lt;locpart&gt;,&lt;force&gt;). The &amp;quot;canonical&amp;quot; verb representation found at this level bears certain similarities to a standard verb case frame, (Simmons, Bruce) in the roles played by the arguments to that predicate. There has been some controversy over whether or not any benefits are gained by labeling these arguments &amp;quot;cases&amp;quot; and attempting to apply linguistic generalities about case. (Fillmore) The possible benefits do not seem to have been realized, with a resulting shift away from explicit ties to case in recent work. (Charniak), (Wilke) PredicateLevel However, the implied relationships between the arguments still have to be spelled out, and this is the function of our third and final level of representation. This level necessarily makes use of predicates that can be found in the data base, and for the purposes of the program is effectively a &amp;quot;deep&amp;quot; semantic representation. A verb such as SUPPORT would require several predicates in an equilibrium domain. For example, the &apos;scaffold&apos; sentence above could result in the following list corresponding to the general predicates listed immediately below. &apos;Scaffold Example SUPPORT(rope,scaffold) UP(Fl,rope) DOWN(F2,scaffold) CONTACT(rope,scaffold) LOCPT(rtendl,rope)</abstract>
<note confidence="0.873851363636364">LOCPT(rtend2,scaffold) SAMEPLACE(rtendl,rtend2) General Predicates SUPPORT(&lt;physobj&gt;1,&lt;physobj&gt;2) UP(&lt;force&gt;1,&lt;physobj&gt;1) DOWN(&lt;force&gt;2,&lt;physobj&gt;2) CONTACT(&lt;physobj&gt;1,&lt;physobj&gt;2) LOCPT(&lt;locpart&gt;I,&lt;physobj&gt;1) LOCPT(&lt;locpart&gt;2,&lt;physobj&gt;2) SAMEPLACE(&lt;locpart&gt;1,&lt;locpart&gt;2) 125</note>
<abstract confidence="0.987542844856663">Producing the above list requires common sense deductions (Bundy] about the existence objects filling do not correspond directly to the canonical arguments, i.e. the two &lt;locpt&gt;s, and any arguments that were missing from the explicit sentence. For instance, in our scaffold example, no &lt;force&gt; was mentioned, and must be inferred. The usefulness of the canonical form is illustrated here, as it prevents tedious duplication of inference rules for slightly varying schemes. The relevant information from the sentence has now been expressed in a form compatible with some internal database. The goal of this semantic analysis has been to provide a mapping between the original syntactic constituents and the predicate arguments in the final representation. For our scaffold example the following mapping has been achieved. The filling in of gaps in the final representation, although motivated by the needs of the database, also serves to test and expand the mapping of the syntactic constituents. SUBJ &lt;rope (physobj&gt;1 OBJ &lt;end &lt;physobj&gt;2 OPPP&lt;scaffold &lt;locpart&gt;2 An obvious question at this point is whether or not the mappings from syntactic constituents to predicate arguments can be achieved directly, since the above multi-stage approach has at least three major disadvantages: 1) It is tedious for the programmer to produce the original schemes, and the resulting amount of special purpose code is cumbersome. It is difficult for the programmer to guarantee that all schemes have been accounted for. 2) This type of system is not very robust. A schema that has been left out cannot be matched no matter how it has in common with stored schemes. 3) Because of the inflexibility of the system it is frequently desirable to add new information. Adding just one schema, much less an entire verb, can be time consuming. Row much of a hindrance this will be is dependent on the extent to which the semantic information has been embedded in the code. The LUNAR project&apos;s use of a meaning representation language greatly increased the efficiency of adding new information. The following section presents a system that uses syntactic cues at the semantic predicate level to find mappings directly. This method has interesting implications for theories about cases. SEMANTIC ANALYSIS This section presents a system for semantic processing that maps syntactic constituents directly onto the arguments of the semantic predicates suggested by the verb. In order Co make these assignments, the possible syntactic mappings must be associated with each argument place in the original semantic predicates. For instance, the only possible syntactic constituent that can be assigned to the &lt;physobj&gt;1 place of a SUPPORT predicate is the SUBJ, and a &lt;physobj&gt;2 can only be filled by an OBJ. But a &lt;locpart&gt; might be an OBJ or the object of an AT preposition, as in &amp;quot;The scaffold is supported at one end.&amp;quot; (The scaffold in this example is the syntactic subject of a passive sentence, so it is also considered the logical object. For our purposes we will look on it as an OBJ). It might seem at first glance that we would want to allow our &lt;physobj&gt;2 to be the object of an . OF preposition, as in &amp;quot;The rope supports one and of the scaffold.&amp;quot; But that is only true if the OFPP follows something like a &lt;locpart&gt; which can be an OBJ in a sentence about SUPPORT. (Of course, just any OFPP will not supply a &lt;physobj&gt;2. In &amp;quot;The rope supports the end of greatest weight.&amp;quot;, the object of the OFPP is not a &lt;physobj&gt; so could not satisfy &lt;physobj&gt;2. The &lt;physobj&gt;2 in this case must be provided by the previous context.) It is this very dependency on the existence of other specific types of syntactic constituents that was captured by the schemes mentioned above. It is necessary for an alternative system to also handle context sensitive constraints. DecisionTrees The three levels of representation mentioned in Section One can be viewed as the bottom, middle and top of a tree. SUPPORT(pl,p2) CONTACT(pl,p2) LOCPT(Iptl,p1) LOCPT(Ipt2,p2) SUPPORT(pl,p2,1pt,force) / \ / \ SUBJ OBJ OFPP &lt;physobj&gt; SUPPORTS &lt;locpart&gt; OF &lt;physobj&gt; &amp;quot;The rope supports one end of the scaffold.&amp;quot; 126 The inference rules that link the three levels deal mainly with any necessary renaming of the role an argument plays. The SUBJ of the schema level is renamed &lt;physobj&gt;1 or pl at the canonical level, and is still pl at the predicate level. One way of viewing the schemes is as leaf nodes produced by a decision tree that starts at the predicate level. The levels of the tree correspond to the different syntactic constituents that can map onto the arguments of the original set of predicates. Since more than one argument can be renamed as a particular syntactic constituent, there can be more than one branch at each level. If a semantic argument might not be mentioned the configuration, this also has to be expressed as a rule, ex. pl -&gt; NULL. (Ex. &amp;quot;The scaffold is supported.&amp;quot;) When all of the branches have been taken, each terminal node represents the set of decisions corresponding to a particular schema. (See Appendix A.) Note that the canonical level never has to be expressed explicitly. By working top down instead of bottom up unnecessary duplication of inference rules is automatically avoided. The information in the original three levels can be stored equivalently as the top node of the decision tree along with the renaming rules for the semantic arguments (rewrite rules). This would reverse the order of analysis from the bottom-up mode suggested in section one to a top-down mode. This uses a more compact representation, but would be computationally less efficient. Growing the entire decision tree every time a sentence needed to be matched would be quite cumbersome. However, if only the path to the correct terminal node needed to be generated, this approach would be computationally competitive. By ordering the decisions according to syntactic precedence, and by using the data from the sentence in question to prune the tree WHILE it is being generated, the correct decisions can usuallly be made, with the only path explored being the path to the correct schema. Sensitive ConstraintsContext sensitivity can be preserved by only allowing the p2-&gt;OFPP rule to apply after a mapping for Iptl has been found, evidence that an lptl-&gt;OBJ rule could have already applied. To test whether such a mapping has been made given a LOCPT predicate, it is only necessary to see if the lptl argument has been renamed by a syntactic constituent. The renaming process can be thought of as an instantiation of typed variables, the semantic arguments by syntactic constituents. [Palmer, Gallier, and Weiner] Then the following preconditions must be satisfied before applying the p2-&gt;OPPP rule: ( A stands for AND) p2-&gt;OFPP/ LOCPT(Iptl,p2) not(variable(lpt1)) These preconditions will still need to be satisfied when a LOCPT predicate is part of another verb representation. Anytime a &lt;locpart&gt; is mentioned it can be followed by an OFPP introducing the &lt;physobj&gt; of which it is a location part. This relationship between a &lt;locpart&gt; and a &lt;physobj&gt; is just as valid when the verb is &apos;hang&apos; or &apos;connect.&apos; Ex. &amp;quot;The pulley is connected to the right end of the string.&amp;quot; &amp;quot; The particle is hung from the right end of the string.&amp;quot; These particular constraints are general to the domain rather than being restricted to &apos;support&apos;. This illustates the efficiency of associating constraints with semantic predicates rather than verbs, allowing for more advantage to be taken of generalities. There is an obvious resemblance here to the notation used for Local Constraints grammars (Joshi and Levy]: p2-&gt;OPPP/ DOM(LOCPT) LMS(Iptl) not(var(lpt1)) DOM - DOMinate, LMS - Left Most Sister It can be demonstrated that the context sensitive constraints presented here are a Simple special case of their Local Constraints, since the dominating node is limited to being the immediate predicate head. Whether or not such a restricted local context will prove sufficient for more complex domains remains to be proven. OverviewAs illustrated above, our mappings from syntactic constituents to semantic arguments can be found directly, thus gaining flexibility and uniformity without losing context sensitivity. Once the verb has been recognized, the semantic predicates representing the verb can drive the selection of renaming rules directly, avoiding the necessity of an intermediate level of representation. The contextual dependencies originally captured by the schemes are preserved in preconditions that are associated with the application of the renaming rules. Since the renaming rules and the preconditions refer only to semantic predicates and arguments to the predicates, there is a sense in which they are independent of individual verbs. By applying only those rules that are relevant to the sentence in question, the correct mappings can be found quickly and efficiently. The resulting system is highly flexible, since the same predicates are used in the representation of all the verbs, and many of the preconditions are general to the domain.&apos; This facillitates the addition of similar verbs since most of the necessary semantic predicates with the appropriate renaming rules will already be present. 127 THE ROLE OF CASE Although the canonical level has often been viewed as the case frame level, doing away with the canonical level does not necessarily imply that cases are no longer relevant to semantic processing. On the contrary, the importance here of syntactic cues for introducing semantic arguments places even more emphasis on the traditional notion of case. The suggestion is that the appropriate level for case information is in fact the predicate level, and that most traditional cases should be seen as arguments to clearly defined semantic predicates. predicates merely the simple set of flat predicates indicated in the previous sections. There is an implicit structuring to that set of predicates indicated by the implications holding between them. A SUPPORT relationship implies the existence of UP and DOWN forces and a CONTACT relationship. A CONTACT relationship implies the existence of LOCPT&apos;s and a SAMEPLACE relationship between them. The set of predicates describing &apos;support&apos; can be the implications of the SUPPORT(pl,p2) predicate into UP(fl,p1) and DOWN(f2,p2) and CONTACT(pl,p2). turn expanded into LOCPT(Iptl,p1) and LOCPT(lpt2,p2) and SAMEPLACE(1p1,1pt2). These definitions, or expansions,are represented as the following rewrite rules: support&lt;-&gt;SUPPORT(p1,p2) SUPPORT (p UP(fl,p1)/\DOWN(f2,p2) ACONTACT(pl,p2) CONTACT(p1,p2)&lt;-&gt; LOCPT(lpt1,p1)/\LOCPT(lpt2,p2) ASAMEPLACE(pl,p2) &apos;support&apos; has been recognized the verb, these rules can be applied, to build up the set of semantic predicates needed to represent support. If there were expansions for UP and DOWN they could be applied as well. As the rules are being applied the mappings of syntactic constituents to predicate arguments can be made at the same time, as each argument is introduced. The case information is not merely the set of semantic predicates or just the SUPPORT(pl,p2) predicate alone. Rather, the case information is represented by the set of predicates, the dependencies indicated by the expansions for the predicates, and the renaming rules that are needed to find the appropriate mappings. The renaming rules correspond to the traditional syntactic cues introducing particular are further restricted by being associated with the predicate context of an argument rather than the argument in isolation. When this structured case information is used to drive semantic processing, it is not a passive frame that waits for its slots to be filled, but rather an active structure that goes in search of fillers for its arguments. If these instantiations are not indicated explicitly by syntax, they must be inferred from a world model. The following example illustrates how the active case structure can also supply cases not mentioned explicitly in the sentence. ExampleGiven a pair of sentences like &amp;quot;Two men are lifting a dresser. A rope supports the end of greatest weight.&amp;quot; we will assume that the first sentence has already been processed. Having recognized that the verb of the second sentence is &apos;support&apos;, the appropriate expansion can be applied to produce: SUPPORT(rope,p2) This would in turn be expanded to: UP(fl,rope) DOWN(f2,p2) CONTACT(rope,p2) In expanding the CONTACT relationship, an lptl for &apos;rope&apos; and a p2 for &apos;end&apos; need to be found. (See Section Two) Since the sentence does not supply an ATPP that might introduce an lptl for the &apos;rope&apos; and since there are no more expansions that can be applied, a plausible inference must be made. The Iptl is likely to be an endpoint that is not already in contact with something else.This implicit object corresponding to the free end of the rope can be name &apos;ropend2.&apos; The p2 is more difficult. The OFPP does not introduce a &lt;physobj&gt;, although it does specify the &apos;end&apos; more precisely. The &apos;end&apos; must first be recognized as belonging to the d , and then as being its heaviest end, &apos;dreseerand2.&apos; This is really an anaphora problem that cannot be decided by the verb, and could in fact have already been handled. Given &apos;d sssss rend2&apos;, it only remains for the &apos;dresser&apos; to be inferred as the p2 of the LOCPT relationship, using the same principles that allow an OFPP to introduce a p2. The final set of predicates would be SUPPORT(rope,dresser) /I\ / I.\ / I \ UP(fl,rope) 1 DOWN(f2,dresser) CONTACT(rope,dresser) &apos;I&apos; / I \ / I \ LOCPT(ropend2,rope)LOCPT(dresserend2,dresser) SAMEPLACE(ropend2,dresserend2) Both the ropend2 and &apos;dresser&apos; were supplied by plausible reasoning using the context and a world model. There are always many inferences that can be drawn when processing a single sentence. The detailed of the case structure presented gives one method of regulating this inferencing. 128 Associationswith linguisticsA recent trend in linguistics to consider cases as arguments to thematic relations offers a surprising amount of support for this position. Without denying the extremely useful ties between syntactic constituents and semantic cases, Jackendoff questions the ability of case to capture complex semantic relationships. (Jackendoff) His main objection is that standard case theory does not allow a noun phrase to be assigned more than one case. In examples like &amp;quot;Esau traded birthright (to Jacob) for a mess pottage,&amp;quot; Jackendoff sees two related actions: &amp;quot;The first is the change of hands of the birthright from Esau to Jacob. The direct object is Theme, the subject is Source, and the to-object is Goal. Also there is what I will call the secondary the changing of hands of the mess pottage in the other direction. In this action, the for-phrase is Secondary Theme, the subject is Secondary Goal, and the to-phrase is Secondary Source.&amp;quot; (p.35] This, of course, could not be captured by a Fillmore-like case frame. Jackendoff concludes that, &amp;quot;A theory of case grammar in which each noun phrase has exactly one semantic function in deep structure cannot provide deep structures which satisfy the strong Katz-Postal Hypothesis, that is, which provide all semantic information about the sentence.&amp;quot; Jackendoff is not completely discarding case information, but rather suggesting a new level of semantic representation that tries to incorporate some the advantages Making constructive use of Gruber&apos;s system of thematic relationships [Gruber], Jackendoff postulates &amp;quot;The thematic relations can now be defined in terms of (these] semantic subfunctions. Agent is the argument of CAUSE is individual; Theme is the argument of CHANGE that is an individual; Source and Goal are the initial and final state arguments of CHANGE. Location will be defined in terms of a further semantic function BE that takes an individual (the a state (the Indeed, Jackendoff is one example of a trend noted by Janet Fodor She points out that &amp;quot;it may be more revealing to regard the noun phrases which are associated in a variety of case relations with the LEXICAL verb as the arguments of the primitive SEMANTIC predicates into which it is analyzed. These semantic predicates typically have very few arguments, perhaps three at the most, but there are a lot of them and hence there will be a lot of which Fillmore has identified appear to be those associated with semantic components that are particularly frequent or prominent, such as CAUSE, USE, BECOME, AT.)&amp;quot; (17.93] Fodor summarizes with, &amp;quot;As a contribution to semantics, therefore, it seems best to regard Fillmore&apos;s analyses as merely stepping stones on the way to a more complete specification of the meanings of verbs.&amp;quot; The one loose end in this neat summation of case is its relation to syntax. Fodor continues, &amp;quot;Whether there are any SYNTACTIC properties of case categories that Fillmore&apos;s theory predicts but which are missed by the semantic approach is another question....&amp;quot; is the thesis of that these syntactic properties of case categories are the very cues that are used to drive the filling of semantic arguments by syntactic constituents. This system also allows the same syntactic constituent to fill more than one argument, e.g. case category. The following section presents further evidence that this system could have direct implications for linguistic theories about case. Although it may at first seem that the analysis of the INSTRUMENT case contradicts certain assumptions that have been made, it actually serves to preserve a useful disctinction between marked and unmarked INSTRUMENTS. The INSTRUMENTCase The cases necessary for &apos;support&apos; were all accomodated as arguments to semantic primitives. This does not imply, however, that cases can never play a more important role in the semantic representation. It is possible for a case to have its own expansion which contains information about how semantic predicates should be structured. There is quite convincing evidence in the pulley domain for the influential effect of one particular case. INSTRUMENTS are essentially &apos;intermediaries&apos; in &apos;hang&apos; and &apos;connect&apos; relationships. An &lt;inter&gt;mediary is a flexible line segment that effects a LOCATION or CONTACT relationship respectively between two physical objects. Example sentences are &amp;quot;A particle is hung by a string pulley,&amp;quot; and &amp;quot;A particle is connected to another particle by a string.&amp;quot; The following rewrite rules are the expansions for the &apos;hang&apos; and &apos;connect&apos; verbs, where the EFFECT predicate will have its own expansion corresponding to the definition of an intermediary. hang &lt;-&gt; EFFECT(inter,LOCATION(pl,loc)) connect &lt;-&gt; EFFECT(inter,CONTACT(pl,p2)) Application of these rules repectivelY results in the following representation for the example sentences: EFFECT(string,LOCATION(particlel,pulley1)) EFFECT(string,CONTACT(particlel,particle2)) 129 expansion itself is: That the distinction between marked and unmarked INSTRUMENTS can be captured by the EFFECT relationship is illustrated by the processing of the following two sentences: EFFECT(inter, REL(argl,arg2)) &lt;-&gt; REL(argl,inter), REL(inter,arg2)) where REL stands for any semantic predicate. The application of this expansion to the above representations results in: LOCATION(particlel,string) LOCATION(string,pulley1) and CONTACT(particlel,string) CONTACT(string,particle2) These predicates can then be expanded, with LOCATION bringing in SUPPORT and CONTACT, and CONTACT bringing in LOCPT. ImplicationsThere seems to be a direct connection between the previous expansion of intermediary and the analysis of the INSTRUMENT case done by Beth Levin at MIT.[Levin) She pointed out a distinct difference in the use of the same INSTRUMENT in the following two sentences: &amp;quot;John cut his foot with a rock.&amp;quot; &amp;quot;John cut his foot on a rock.&amp;quot; In the first sentence there is an implication that John was in some way controlling&apos; the cutting of his foot, and using the rock to do so. In the second sentence there is no such implication, and John probably cut his foot accidentally. The use of the &apos;with&apos; preposition marks the rock as an INSTRUMENT. that is being manipulated John, whereas &apos;on&apos; introduces an INSTRUMENT with no implied relationshion to John. It would seem that something like the expansion for EFFECT could help to capture part of what is being implied by the &apos;control&apos; relationship. Bringing in the transitivity relationship makes explicit a connection between John and the rock as well as between the foot and the rock. In the second sentence only the connection between the foot and the rock is implied. The connection implied here is certainly more complicated than a simple CONTACT relationship, and would neccessitate a more detailed understanding of &apos;cut.&apos; But the suggestion of &apos;control&apos; is at least indicated by the embedding of the CUT predicate within EFFECT and CAUSE. CAUSE(John,EFFECT(rock,(CUT(foot-of-John))) The tie between the AGENT and the implication of that should &amp;quot;The particle is hung from a pulley by a S tring.&amp;quot; &amp;quot;The particle is hung on a string.&amp;quot; In the first sentence an &apos;inter&apos; (a marked INSTRUMENT) is supplied by the BYPP, and the following representation is produced: EFFECT(string,LOCATION(particle,pulley)) In the second sentence no &apos;inter&apos; is found, and in the absence of an &apos;inter&apos; the EFFECT relationship cannot be expanded. The predicate is to stand alone and is in turn expanded. (The ONFP can indicate a &apos;loc.&apos;) The intriguing possibility of verb independent definitions for cases requires much more exploration.(Charniak) The suggestion here is that a deeper level of representation, the predicate level, is for investigating case implications, and that important cases like AGENTS and INSTRUMENTS have implications for meta-level structuring of those predicates. SummaryIn summary, there is a surprising amount of information at â€¢ the semantic predicate level that allows syntactic constituents to be mapped directly onto semantic arguments. This results in a semantic processer that has the advantage of being easy to build and more flexible than existing processers. It also brings to light substantial evidence that cases should not be discarded but should be reexamined with respect to the roles they play as arguments to semantic predicates. The INTERMEDIARY case is seen to play a particularly important role having to do not with any particular semantic predicate, but with the choice of semantic predicates in general.</abstract>
<note confidence="0.841370555555555">References (1) Bruce, B., Case system for natural language, &amp;quot;Artificial Intelligence,&amp;quot; Vol. 6, No. 4, Winter, pp. 327-360. (2] Bundy, et-al, Solving Mechanics Problems Meta-Level Inference, Systemsin Micro-ElectronicALI, D.(ed), Edinburgh University Press, Edinburgh, U.K., 1979. (31 Charniak, E., A brief on case, Working Paper No.22, (Castagnola: Institute for Semantics and Cognitive Studies), 1975. Fillmore, C., The case for Universalsin Theory,Bach and Harms (eds.) New York; Rolt, Rinehart and Winston, pp. 1-88. Fodor, Janet D., Theoriesof Meaningin Grammar,Language and Thought Series, Thomas Y. Crowell Co., Inc., 1977, p. 93 130 Gruber, J.S., Structuresin Syntaxand Semantics,North-Holland Pub. Co., 1976. Jackendoff, R.S., Interpreterin Grammar,MIT Press, Cambridge, MA, P.39. (8) Levin, B. &amp;quot;Instrumental With and the Control Relation in English,&amp;quot; MIT Master&apos;s Thesis, 1979. (91 Novak, G.S., Computer Understanding of Physics Problems Stated in Natural Journalof Linguistics,Microfiche 53, 1976. (10) Palmer, M., Where to Connect? Solving Problems in Semantics, DAI Working Paper No. 22, University of Edinburgh, July 1977. (111 Palmer, M., &amp;quot;Driving Semantics for a Limited Domain,&amp;quot; Ph.D. Thesis, forthcoming, University of Edinburgh. (12) Palmer, M., Gallier, J., and Weiner, J., Implementations as Program Specifications: A Semantic Processer in Prolog, (submitted IJCAI, Vancouver, August 1981). (13) Simmons, R.F., Semantic Networks: Their</note>
<title confidence="0.8674445">Computation and Use for Understanding English Modelsof Thoughtand</title>
<note confidence="0.886779375">Language,Schank and Colby (eds.) San Francisco: W.H. Freeman and Co., 1973. (14) Wilks, Y., Processing Case, &amp;quot;American Journal of Computational Linguistics,&amp;quot; 1976. [15) Woods, W.A., Semantics and Quantification in Natural Language Question Answering, BBN Report 3687, Cambridge, Mass, November 1977.</note>
<affiliation confidence="0.47048">APPENDIX A</affiliation>
<abstract confidence="0.944612157894737">LOCPT(lptl,p1) LOCPT(lpt2,p2) pl -&gt; SUBJ pl -&gt; NULL SUPPORT(SUBJ,p2) A CONTACT(SUBJ,p2) SUPPORT(pl,p2) CONTACT(pl,p2) A LOCPT(lptl,SUBJ) LOCPT(Ipt2,p2) LOCPT(lptl,p1) LOCPT(Ipt2,p2) -&gt; OBJ/ -&gt; OBJ /. etc. etc. SUPPORT(SUBJ,OBJ) SUPPORT(SUBJ,p2) CONTACT(SUBJ,OBJ) CONTACT(SUBJ,p2) LOCPT(lptl,SUBJ) LOCPT(lptl,SUBJ) LOCPT(Ipt2,OBJ) LOCPT(OBJ,p2) lpt2 -&gt; ATPP \ p2 -&gt; OFPP SUPPORT(SUBJ,OBJ) SUPPORT(SUBJ,OFTP) CONTACT(SUBJ,OBJ) CONTACT(SUBJ,OFPP) LOCPT(lptl,SUBJ) LOCPT(lptl,SUBJ) /\ LOCPT(ATPP,OBJ) LOCPT(OBJ,OPPP) ATPP SUPPORTS &lt;physobj&gt; \ SUBJ OBJ OFPP &lt;physobj&gt; SUPPORTS &lt;locpart&gt; OF &lt;physobj&gt;</abstract>
<intro confidence="0.686339">131</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>B Bruce</author>
</authors>
<title>Case system for natural language, &amp;quot;Artificial Intelligence,&amp;quot;</title>
<date>1979</date>
<booktitle>Expert Systems in the Micro-Electronic</booktitle>
<volume>6</volume>
<pages>327--360</pages>
<editor>ALI, Michie, D.(ed),</editor>
<publisher>Edinburgh University Press,</publisher>
<location>Edinburgh, U.K.,</location>
<marker>(1)</marker>
<rawString>Bruce, B., Case system for natural language, &amp;quot;Artificial Intelligence,&amp;quot; Vol. 6, No. 4, Winter, pp. 327-360. (2] Bundy, et-al, Solving Mechanics Problems Using Meta-Level Inference, Expert Systems in the Micro-Electronic ALI, Michie, D.(ed), Edinburgh University Press, Edinburgh, U.K., 1979. (31 Charniak, E., A brief on case, Working Paper No.22, (Castagnola: Institute for Semantics and Cognitive Studies), 1975. (41 Fillmore, C., The case for case, Universals in Linguistic Theory, Bach and Harms (eds.) New York; Rolt, Rinehart and Winston, pp. 1-88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janet D Fodor</author>
</authors>
<title>Semantics: Theories of Meaning in Generative Grammar, Language and Thought Series, Thomas Y.</title>
<date>1977</date>
<pages>93</pages>
<publisher>Crowell Co., Inc.,</publisher>
<marker>(5)</marker>
<rawString>Fodor, Janet D., Semantics: Theories of Meaning in Generative Grammar, Language and Thought Series, Thomas Y. Crowell Co., Inc., 1977, p. 93</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Gruber</author>
</authors>
<title>Lexical Structures in Syntax</title>
<date>1976</date>
<booktitle>[7) Jackendoff, R.S., Semantic Interpreter in Generative Grammar,</booktitle>
<pages>39</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA,</location>
<marker>(6)</marker>
<rawString>Gruber, J.S., Lexical Structures in Syntax and Semantics, North-Holland Pub. Co., 1976. [7) Jackendoff, R.S., Semantic Interpreter in Generative Grammar, MIT Press, Cambridge, MA, 1972, P. 39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Levin</author>
</authors>
<title>Instrumental With and the Control Relation in English,&amp;quot; MIT Master&apos;s Thesis,</title>
<date>1979</date>
<journal>91 Novak, G.S., Computer Understanding of Physics Problems Stated in Natural Language,American Journal of Computational Linguistics, Microfiche</journal>
<volume>53</volume>
<marker>(8)</marker>
<rawString>Levin, B. &amp;quot;Instrumental With and the Control Relation in English,&amp;quot; MIT Master&apos;s Thesis, 1979. (91 Novak, G.S., Computer Understanding of Physics Problems Stated in Natural Language,American Journal of Computational Linguistics, Microfiche 53, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
</authors>
<title>Where to Connect? Solving Problems in Semantics,</title>
<date>1977</date>
<tech>DAI Working Paper No. 22,</tech>
<pages>111</pages>
<institution>University of Edinburgh,</institution>
<marker>(10)</marker>
<rawString>Palmer, M., Where to Connect? Solving Problems in Semantics, DAI Working Paper No. 22, University of Edinburgh, July 1977. (111 Palmer, M., &amp;quot;Driving Semantics for a Limited Domain,&amp;quot; Ph.D. Thesis, forthcoming, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>J Gallier</author>
<author>J Weiner</author>
</authors>
<date>1981</date>
<booktitle>Implementations as Program Specifications: A Semantic Processer in Prolog, (submitted IJCAI,</booktitle>
<location>Vancouver,</location>
<marker>(12)</marker>
<rawString>Palmer, M., Gallier, J., and Weiner, J., Implementations as Program Specifications: A Semantic Processer in Prolog, (submitted IJCAI, Vancouver, August 1981).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R F Simmons</author>
</authors>
<title>Semantic Networks: Their Computation and Use for Understanding English Sentences,</title>
<date>1973</date>
<booktitle>Computer Models of Thought and Language, Schank and Colby</booktitle>
<editor>(eds.) San Francisco: W.H. Freeman and Co.,</editor>
<marker>(13)</marker>
<rawString>Simmons, R.F., Semantic Networks: Their Computation and Use for Understanding English Sentences, Computer Models of Thought and Language, Schank and Colby (eds.) San Francisco: W.H. Freeman and Co., 1973.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wilks</author>
<author>Processing Case</author>
</authors>
<title>American Journal of Computational Linguistics,&amp;quot;</title>
<date>1976</date>
<publisher>SUPPORTS OF</publisher>
<location>Cambridge, Mass,</location>
<marker>(14)</marker>
<rawString>Wilks, Y., Processing Case, &amp;quot;American Journal of Computational Linguistics,&amp;quot; 1976. [15) Woods, W.A., Semantics and Quantification in Natural Language Question Answering, BBN Report 3687, Cambridge, Mass, November 1977. &lt;physobj&gt; SUPPORTS &lt;locpart&gt; OF &lt;physobj&gt;</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>