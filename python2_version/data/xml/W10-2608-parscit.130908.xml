<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000612">
<title confidence="0.987975">
Frustratingly Easy Semi-Supervised Domain Adaptation
</title>
<author confidence="0.741003">
Hal Daum´e III Abhishek Kumar Avishek Saha
</author>
<affiliation confidence="0.815625">
School Of Computing School Of Computing School Of Computing
University of Utah University of Utah University of Utah
</affiliation>
<email confidence="0.996448">
hal@cs.utah.edu abhik@cs.utah.edu avishek@cs.utah.edu
</email>
<sectionHeader confidence="0.997366" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999972333333333">
In this work, we propose a semi-
supervised extension to a well-known
supervised domain adaptation approach
(EA) (Daum´e III, 2007). Our proposed
approach (EA++) builds on the notion
of augmented space (introduced in EA)
and harnesses unlabeled data in target do-
main to ameliorate the transfer of infor-
mation from source to target. This semi-
supervised approach to domain adaptation
is extremely simple to implement, and can
be applied as a pre-processing step to any
supervised learner. Experimental results
on sequential labeling tasks demonstrate
the efficacy of the proposed method.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999768333333333">
A domain adaptation approach for sequential la-
beling tasks in NLP was proposed in (Daum´e
III, 2007). The proposed approach, termed
EASYADAPT (EA), augments the source domain
feature space using features from labeled data in
target domain. EA is simple, easy to extend and
implement as a preprocessing step and most im-
portantly is agnostic of the underlying classifier.
However, EA requires labeled data in the target
and hence applies to fully supervised (labeled data
in source and target) domain adaptation settings
only. In this paper, we propose a semi-supervised1
(labeled data in source, and both labeled and un-
labeled data in target) approach to leverage unla-
beled data for EASYADAPT (which we call EA++)
and empirically demonstrate its superior perfor-
mance over EA as well as few other existing ap-
proaches.
</bodyText>
<footnote confidence="0.9840175">
1We refer, labeled data in source and only unlabeled data
in target, as the unsupervised domain adaptation setting.
</footnote>
<bodyText confidence="0.99972352631579">
There exists prior work on supervised domain
adaptation (or multi-task learning) that can be re-
lated to EASYADAPT. An algorithm for multi-
task learning using shared parameters was pro-
posed (Evgeniou and Pontil, 2004) for multi-task
regularization where each task parameter was rep-
resented as sum of a mean parameter (that stays
same for all tasks) and its deviation from this
mean. SVM was used as the base classifier
and the algorithm was formulated in the standard
SVM dual optimization setting. Subsequently,
this framework (Evgeniou and Pontil, 2004) was
extended (Dredze et al., 2010) to online multi-
domain setting. Prior work on semi-supervised
approaches to domain adaptation also exists in lit-
erature. Extraction of specific features from the
available dataset was proposed (Arnold and Co-
hen, 2008; Blitzer et al., 2006) to facilitate the
task of domain adaptation. Co-adaptation (Tur,
2009), a combination of co-training and domain
adaptation, can also be considered as a semi-
supervised approach to domain adaptation. A
semi-supervised EM algorithm for domain adap-
tation was proposed in (Dai et al., 2007). Sim-
ilar to graph based semi-supervised approaches,
a label propagation method was proposed (Xing
et al., 2007) to facilitate domain adaptation. The
recently proposed Domain Adaptation Machine
(DAM) (Duan et al., 2009) is a semi-supervised
extension of SVMs for domain adaptation and
presents extensive empirical results. However, in
almost all of the above cases, the proposed meth-
ods either use specifics of the datasets or are cus-
tomized for some particular base classifier and
hence it is not clear how the proposed methods
can be extended to other existing classifiers.
EA, on the other hand, is remarkably general in
the sense that it can be used as a pre-processing
</bodyText>
<page confidence="0.992744">
53
</page>
<note confidence="0.6297815">
Proceedings of the 2010 Workshop on Domain Adaptation for Natural Language Processing, ACL 2010, pages 53–59,
Uppsala, Sweden, 15 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999974071428571">
step in conjunction with any base classifier. How-
ever, one of the prime limitations of EA is its inca-
pability to leverage unlabeled data. Given its sim-
plicity and generality, it would be interesting to
extend EA to semi-supervised settings. In this pa-
per we propose EA++, a co-regularization based
semi-supervised extension to EA. We present our
approach and results for a single pair of source
and target domain. However, we note that EA++
can also be extended to multiple source settings.
If we have k sources and a single target domain
then we can introduce a co-regularizer for each
source-target pair. Due to space constraints, we
defer details to a full version.
</bodyText>
<sectionHeader confidence="0.998765" genericHeader="introduction">
2 Background
</sectionHeader>
<subsectionHeader confidence="0.999807">
2.1 Problem Setup and Notations
</subsectionHeader>
<bodyText confidence="0.9992505">
Let X ⊂ Rd denote the instance space and Y
= {−1, +1} denote the label space. We have a set
of source labeled examples Ls(∼ Ds(x, y)) and
a set of target labeled examples Lt(∼ Dt(x, y)),
where |Ls |= ls ≫ |Lt |= lt. We also have target
unlabeled data denoted by Ut(∼ Dt(x)), where
|Ut |= ut. Our goal is to learn a hypothesis h :
X 7→ Y having low expected error with respect to
the target domain. In this paper, we consider lin-
ear hypotheses only. However, the proposed tech-
niques extend to non-linear hypotheses, as men-
tioned in (Daum´e III, 2007). Source and target
empirical errors for hypothesis h are denoted by
Es(h, fs) and Et(h, ft) respectively, where fs and
ft are source and target labeling functions. Sim-
ilarly, the corresponding expected errors are de-
noted by Es(h, fs) and Et(h, ft). Shorthand no-
tions of Es, Et, Es and Et have also been used.
</bodyText>
<subsectionHeader confidence="0.997052">
2.2 EasyAdapt (EA)
</subsectionHeader>
<bodyText confidence="0.999484470588236">
In this section, we give a brief overview of
EASYADAPT proposed in (Daum´e III, 2007). Let
us denote Rd as the original space. EA operates
in an augmented space denoted by X� ⊂ Rad (for a
single pair of source and target domain). For k do-
mains, the augmented space blows up to R(k+1)d.
The augmented feature maps V, V : X 7→ X� for
source and target domains are defined as,
where x and 0 are vectors in Rd, and 0 de-
notes a zero vector of dimension d. The first d-
dimensional segment corresponds to commonality
between source and target, second d-dimensional
segment corresponds to the source domain while
the last segment corresponds to the target domain.
Source and target domain features are transformed
using these feature maps and the augmented fea-
ture space so constructed is passed onto the un-
derlying supervised classifier. One of the most ap-
pealing properties of EASYADAPT is that it is ag-
nostic of the underlying supervised classifier be-
ing used to learn in the augmented space. Al-
most any standard supervised learning approach
for linear classifiers (for e.g., SVMs, perceptrons)
can be used to learn a linear hypothesis h� ∈ Rad
in the augmented space. As mentioned earlier,
this work considers linear hypotheses only and the
the proposed techniques can be extended (Daum´e
III, 2007) to non-linear hypotheses. Let us denote
h� = hhc, hs, hti, where each of hc, hs, ht is of
dimension d and represent the common, source-
specific and target-specific components of h, re-
spectively. During prediction on target data, the
incoming target feature x is transformed to obtain
V(x) and h� is applied on this transformed fea-
ture. This is equivalent to applying (hc + ht) on
x.
A good intuitive insight into why this simple
algorithm works so well in practice and outper-
forms most state-of-the-art algorithms is given
in (Daum´e III, 2007). Briefly, it can be thought to
be simultaneously training two hypotheses: ws =
(hc + hs) for source domain and wt = (hc + gt)
for target domain. The commonality between the
domains is represented by hc whereas the source
and target domain specific information is captured
by hs and ht, respectively. This technique can
be easily extended to a multi-domain scenario by
making more copies of the original feature space
((K + 1) copies in case of K domains). A kernel-
ized version of the algorithm has also been pre-
sented in (Daum´e III, 2007).
</bodyText>
<sectionHeader confidence="0.809794" genericHeader="method">
3 Using Unlabeled data
</sectionHeader>
<bodyText confidence="0.999334">
As discussed in the previous section, the
EASYADAPT algorithm is attractive because it
performs very well empirically and can be used in
conjunction with any underlying supervised clas-
</bodyText>
<equation confidence="0.96083">
(2.1)
.bt(x) = hx, 0, xi
V(x) = hx, x, 0i
</equation>
<page confidence="0.979879">
54
</page>
<bodyText confidence="0.999885285714286">
sifier. One drawback of EASYADAPT is that it
does not make use of unlabeled target data which
is generally available in large quantity in most
practical problems. In this section, we propose a
semi-supervised extension of this algorithm while
maintaining the desirable classifier-agnostic prop-
erty.
</bodyText>
<subsectionHeader confidence="0.998775">
3.1 Motivation
</subsectionHeader>
<bodyText confidence="0.999938588235294">
In multi-view approach for semi-supervised learn-
ing algorithms (Sindhwani et al., 2005), different
hypotheses are learned in different views. There-
after, unlabeled data is utilized to co-regularize
these learned hypotheses by making them agree
on unlabeled samples. In domain adaptation, the
source and target data come from two different
distributions. However, if the source and tar-
get domains are reasonably close to each other,
we can employ a similar form of regularization
using unlabeled data. A similar co-regularizer
based approach for unlabeled data was previously
shown (Duan et al., 2009) to give improved empir-
ical results for domain adaptation task. However,
their technique applies for the particular base clas-
sifier they consider and hence does not extend to
EASYADAPT.
</bodyText>
<subsectionHeader confidence="0.956539">
3.2 EA++: EASYADAPT with unlabeled data
</subsectionHeader>
<bodyText confidence="0.961489222222223">
In our proposed semi-supervised extension to
EASYADAPT, the source and target hypothesis are
made to agree on unlabeled data. We refer to
this algorithm as EA++. Recall that EASYADAPT
learns a linear hypothesis h˘ E Rad in the aug-
mented space. The hypothesis h˘ contains com-
mon, source and target sub-hypotheses and is ex-
pressed as h˘ = (hc, hs, ht). In original space
(ref. section 2.2), this is equivalent to learning a
source specific hypothesis ws = (hc + hs) and a
target specific hypothesis wt = (hc + ht).
In EA++, we want source hypothesis ws and
target hypothesis wt to agree on unlabeled data.
For some unlabeled target sample xi E Ut C Rd,
EA++ would implicitly want to make the predic-
tions of wt and wt on xi to agree. Formally, it
aims to achieve the following condition:
ws · xi Pz wt · xi
</bodyText>
<equation confidence="0.994623">
�� (hc + hs) · xi Pz (hc + ht) · xi
�(hs − ht) · xi Pz 0 (3.1)
�� (hc, hs, ht) · (0, xi, −xi) Pz 0.
</equation>
<bodyText confidence="0.994396">
We define another feature map Φu : X H X˜ for
unlabeled data as below:
</bodyText>
<equation confidence="0.993484">
Φu(x) = (0, x, −x). (3.2)
</equation>
<bodyText confidence="0.999373857142857">
Every unlabeled sample is transformed using the
map Φu(.). The augmented feature space that re-
sults from the application of three feature maps,
namely, Φs : X H ˘X,Φt : X H ˘X, Φu : X H
˘X, on source labeled samples, target labeled sam-
pled and target unlabeled samples is summarized
in Figure 1.
As shown in Eq. 3.1, during the training phase,
EA++ assigns a predicted value close to 0 for each
unlabeled sample. However, it is worth noting
that, during the test phase, EA++ predicts labels
from two classes: +1 and −1. This warrants
further exposition of the implementation specifics
which is deferred until the next subsection.
</bodyText>
<figureCaption confidence="0.9895485">
Figure 1: Diagrammatic representation of feature
augmentation in EA and EA++
</figureCaption>
<bodyText confidence="0.8924045">
Algorithm 1 presents the EA++ approach in de-
tail.
</bodyText>
<subsectionHeader confidence="0.986683">
3.3 Implementation
</subsectionHeader>
<bodyText confidence="0.99924">
In this section, we present implementation specific
details of EA++. We consider SVM as our base
supervised learner (LEARN in Algorithm 1).
However, these details hold for other supervised
</bodyText>
<table confidence="0.948504">
EA++
EA
ut
ls
lt
Ls Ls 0
Lt 0 Lt
0 ������������������������������������� −Ut
�������������������������������������
�������������������������������������
�������������������������������������
�������������������������������������
�������������������������������������
�������������������������������������
�������������������������������������
�������������������������������������
�������������������������������������
�������������������������������������
�������������������������������������
�������������������������������������
�������������������������������������
������������������������������������
������������������������������������
Ut
d d d
</table>
<page confidence="0.87292">
55
</page>
<bodyText confidence="0.655029">
Algorithm 1 EA++
Input: L3; Lt; Ut; LEARN: supervised clas-
sifier
Output: h� : classifier learned in augmented
space
/* initialize augmented training set */
</bodyText>
<listItem confidence="0.954756714285714">
1: P := {}
/* construct augmented training set */
2: b(x, y) ∈ L3, P := P U {-3(x), y}
3: b(x, y) ∈ Lt, P := P U {-bt(x), y}
4: bx ∈ Ut, P := P U {-bu(x), 0}
/* output learned classifier */
5: h� = LEARN(P)
</listItem>
<bodyText confidence="0.987761941176471">
classifiers too. In the dual form of SVM optimiza-
tion function, the labels are multiplied with the in-
ner product of features. This can make the un-
labeled samples redundant since we want their la-
bels to be 0 according to Eq. 3.1. To avoid this, we
create as many copies of 4bu(x) as there are labels
and assign each label to one copy. For the case of
binary classification, we create two copies of ev-
ery augmented unlabeled sample, and assign +1
label to one copy and −1 to the other. The learner
attempts to balance the loss of the two copies, and
tries to make the prediction on unlabeled sample
equal to 0. Figure 2 shows the curves of the hinge
loss for class +1, class −1 and their sum. The ef-
fective loss for each unlabeled sample is similar to
the sum of losses for +1 and −1 classes (shown in
Figure 2c).
</bodyText>
<sectionHeader confidence="0.999705" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999671">
In this section, we demonstrate the empirical per-
formance of EA augmented with unlabeled data.
</bodyText>
<subsectionHeader confidence="0.983746">
4.1 Setup
</subsectionHeader>
<bodyText confidence="0.9992081">
We follow the same experimental setup used
in (Daum´e III, 2007) and perform two sequence
labelling tasks (a) named-entity-recognition
(NER), and (b) part-of-speech-tagging (POS )on
the following datasets:
PubMed-POS: Introduced by (Blitzer et al.,
2006), this dataset consists of two domains.
The WSJ portion of the Penn Treebank
serves as the source domain and the PubMed
abstracts serve as the target domain. The
</bodyText>
<figureCaption confidence="0.8934384">
Figure 2: Loss functions for class +1, class −1
and unlabeled samples.
task is to perform part-of-speech tagging on
unlabeled PubMed abstracts with a classifier
trained on labeled WSJ and PubMed data.
</figureCaption>
<bodyText confidence="0.996249434782609">
Treebank-Brown. Treebank-Chunk data consists
of the following domains: the standard WSJ
domain (the same data as for CoNLL 2000),
the ATIS switchboard domain and the Brown
corpus. The Brown corpus consists of data
combined from six subdomains. Treebank-
Chunk is a shallow parsing task based on
the data from the Penn Treebank. Treebank-
Brown is identical to the Treebank-Chunk
task, However, in Treebank-Brown we con-
sider all of the Brown corpus to be a single
domain.
Table 1 presents a summary of the datasets
used. All datasets use roughly the same feature
set which are lexical information (words, stems,
capitalization, prefixes and suffixes), membership
on gazetteers, etc. We use an averaged perceptron
classifier from the Megam framework (implemen-
tation due to (Daum´e III, 2004)) for all the afore-
mentioned tasks. The training sample size varies
from 1k to 16k. In all cases, the amount of unla-
beled target data was equal to the total amount of
labeled source and target data.
</bodyText>
<figure confidence="0.967046666666667">
Loss
Loss
Loss
</figure>
<page confidence="0.976195">
56
</page>
<table confidence="0.998713384615385">
Task Dom #Tr #De #Te #Ft
PubMed src 950,028 - - 571k
POS tgt 11,264 1,987 14,554 39k
wsj 191,209 29,455 38,440 94k
swbd3 45,282 5,596 41,840 55k
br-cf 58,201 8,307 7,607 144k
Tree br-cg 67,429 9,444 6,897 149k
bank- br-ck 51,379 6,061 9,451 121k
Chunk br-cl 47,382 5,101 5,880 95k
br-cm 11,696 1,324 1,594 51k
br-cn 56,057 6,751 7,847 115k
br-cp 55,318 7,477 5,977 112k
br-cr 16,742 2,522 2,712 65k
</table>
<tableCaption confidence="0.999227">
Table 1: Summary of Datasets. The columns de-
</tableCaption>
<bodyText confidence="0.871916666666667">
note task, domain, size of training, development
and test data sets, and the number of unique fea-
tures in the training data.
</bodyText>
<sectionHeader confidence="0.52168" genericHeader="evaluation">
4.2 Results
</sectionHeader>
<bodyText confidence="0.949586">
We compare the empirical performance of
EA++ with a few other baselines, namely, (a)
SOURCEONLY (classifier trained on source la-
beled samples), (b) TARGETONLY-FULL (classi-
fier trained on the same number of target labeled
samples as the number of source labeled samples
in SOURCEONLY), (c) TARGETONLY (classifier
trained on small amount of target labeled sam-
ples, roughly one-tenth of the amount of source la-
beled samples in SOURCEONLY), (d) ALL (clas-
sifier trained on combined labeled samples of
SOURCEONLY and TARGETONLY), (e) EA (clas-
sifier trained in augmented feature space on the
same input training set as ALL), (f) EA++ (clas-
sifier trained in augmented feature space on the
same input training set as EA and an equal amount
of unlabeled target data). All these approaches
were tested on the entire amount of available tar-
get test data.
Figure 3 presents the learning curves for
(a) SOURCEONLY, (b) TARGETONLY-FULL, (c)
TARGETONLY, (d) ALL, (e) EA, and (f) EA++
(EA with unlabeled data). The x-axis repre-
sents the number of training samples on which
the predictor has been trained. At this point,
we note that the number of training samples
vary depending on the particular approach being
used. For SOURCEONLY, TARGETONLY-FULL
and TARGETONLY, it is just the corresponding
number of labeled source or target samples, re-
spectively. For ALL and EA, it is the summa-
tion of labeled source and target samples. For
4000 8000 12000 16000
number of samples
4000 8000 12000 16000
number of samples
</bodyText>
<figureCaption confidence="0.75904575">
Figure 3: Test accuracy of (a) PubMed-POS and
(b) Treebank-Brown for, SOURCEONLY, TARGE-
TONLY-FULL, TARGETONLY, ALL, EA and
EA++.
</figureCaption>
<bodyText confidence="0.999798944444445">
EA++, the x-value plotted denotes the amount of
unlabeled target data used (in addition to an equal
amount of source+target labeled data, as in ALL
or EA). We plot this number for EA++, just to
compare its improvement over EA when using an
additional (and equal) amount of unlabeled target
data. This accounts for the different x values plot-
ted for the different curves. In all cases, the y-axis
denotes the error rate.
As can be seen in Figure 3(a), EA++ performs
better than the normal EA (which uses labeled
data only). The labeled and unlabeled case start
together but with increase in number of samples
their gap increases with the unlabeled case result-
ing in much lower error as compared to the labeled
case. Similar trends were observed in other data
sets as can be seen in Figure 3(b). We also note
that EA performs poorly for some cases, as was
</bodyText>
<figure confidence="0.998738458333334">
0.5
0.4
0.3
0.2
0.1
SrcOnly
TgtOnly-Full
TgtOnly
All
EA
EA++
error rate
0.5
0.4
0.3
0.2
0.1
SrcOnly
TgtOnly-Full
TgtOnly
All
EA
EA++
error rate
</figure>
<page confidence="0.959955">
57
</page>
<bodyText confidence="0.661944">
shown (Daum´e III, 2007) earlier.
</bodyText>
<sectionHeader confidence="0.994829" genericHeader="evaluation">
5 Summary
</sectionHeader>
<bodyText confidence="0.999948666666666">
In this paper, we have proposed a semi-supervised
extension to an existing domain adaptation tech-
nique (EA). Our approach EA++, leverages the
unlabeled data to improve the performance of EA.
Empirical results demonstrate improved accuracy
for sequential labeling tasks performed on stan-
dardized datasets. The previously proposed EA
could be applied exclusively to fully supervised
domain adaptation problems only. However, with
the current extension, EA++ applies to both fully
supervised and semi-supervised domain adapta-
tion problems.
</bodyText>
<sectionHeader confidence="0.999901" genericHeader="discussions">
6 Future Work
</sectionHeader>
<bodyText confidence="0.999862769230769">
In both EA and EA++, we use features from
source and target space to construct an augmented
feature space. In other words, we are sharing fea-
tures across source and target labeled data. We
term such algorithms as Feature Sharing Algo-
rithms. Feature sharing algorithms are effective
for domain adaptation because they are simple,
easy to implement as a preprocessing step and out-
perform many existing state-of-the-art techniques
(shown previously for domain adaptation (Daum´e
III, 2007)). However, despite their simplicity and
empirical success, it is not theoretically apparent
why these algorithms perform so well. Prior work
provides some intuitions but is mostly empirical
and a formal theoretical analysis to justify FSAs
(for domain adaptation) is clearly missing. Prior
work (Maurer, 2006) analyzes the multi-task reg-
ularization approach (Evgeniou and Pontil, 2004)
(which is related to EA) but they consider a cumu-
lative loss in multi-task (or multi-domain) setting.
This does not apply to domain adaptation setting
where we are mainly interested in loss in the target
domain only.
Theoretically analyzing the superior perfor-
mance of EA and EA++ and providing gener-
alization guarantees is an interesting line of fu-
ture work. One approach would be to model
the feature sharing approach in terms of co-
regularization; an idea that originated in the
context of multiview learning and for which
some theoretical analysis has already been done
(Rosenberg and Bartlett, 2007; Sindhwani and
Rosenberg, 2008). Additionally, the afore-
mentioned techniques, namely, SOURCEONLY,
TARGETONLY, ALL have been empirically com-
pared to EA and EA++. It would be interest-
ing to formally frame these approaches and see
whether their empirical performance can be justi-
fied within a theoretical framework.
</bodyText>
<sectionHeader confidence="0.999428" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999800473684211">
Andrew Arnold and William W. Cohen. 2008. Intra-
document structural frequency features for semi-
supervised domain adaptation. In CIKM’08, pages
1291–1300, Napa Valley, California, USA.
John Blitzer, Ryan Mcdonald, and Fernando Pereira.
2006. Domain adaptation with structural correspon-
dence learning. In EMNLP’06, pages 120–128,
Sydney, Australia.
Wenyuan Dai, Gui-Rong Xue, Qiang Yang, and Yong
Yu. 2007. Transferring Naive Bayes classifiers
for text classification. In AAAI’07, pages 540–545,
Vancouver, B.C.
Hal Daum´e III. 2004. Notes on CG and LM-BFGS
optimization of logistic regression. August.
Hal Daum´e III. 2007. Frustratingly easy domain adap-
tation. In ACL’07, pages 256–263, Prague, Czech
Republic.
Mark Dredze, Alex Kulesza, and Koby Crammer.
2010. Multi-domain learning by confidence-
weighted parameter combination. Machine Learn-
ing, 79.
Lixin Duan, Ivor W. Tsang, Dong Xu, and Tat-Seng
Chua. 2009. Domain adaptation from multiple
sources via auxiliary classifiers. In ICML’09, pages
289–296, Montreal, Quebec.
Theodoros Evgeniou and Massimiliano Pontil. 2004.
Regularized multitask learning. In KDD’04, pages
109–117, Seattle, WA, USA.
Andreas Maurer. 2006. The Rademacher complexity
of linear transformation classes. In COLT’06, pages
65–78, Pittsburgh, Pennsylvania.
D. S. Rosenberg and P. L. Bartlett. 2007. The
Rademacher complexity of co-regularized kernel
classes. In AISTATS’07, San Juan, Puerto Rico.
Vikas Sindhwani and David S. Rosenberg. 2008.
An RKHS for multi-view learning and manifold
co-regularization. In ICML’08, pages 976–983,
Helsinki, Finland.
</reference>
<page confidence="0.984034">
58
</page>
<reference confidence="0.995267818181818">
Vikas Sindhwani, Partha Niyogi, and Mikhail Belkin.
2005. A co-regularization approach to semi-
supervised learning with multiple views. In ICML
Workshop on Learning with Multiple Views, pages
824–831, Bonn, Germany.
Gokhan Tur. 2009. Co-adaptation: Adaptive
co-training for semi-supervised learning. In
ICASSP’09, pages 3721–3724, Taipei, Taiwan.
Dikan Xing, Wenyuan Dai, Gui-Rong Xue, and Yong
Yu. 2007. Bridged refinement for transfer learning.
In PKDD’07, pages 324–335, Warsaw, Poland.
</reference>
<page confidence="0.999256">
59
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.972084">
<title confidence="0.999858">Frustratingly Easy Semi-Supervised Domain Adaptation</title>
<author confidence="0.999419">Hal Daum´e Abhishek Kumar Avishek Saha</author>
<affiliation confidence="0.999634">School Of Computing School Of Computing School Of Computing University of Utah University of Utah University of</affiliation>
<email confidence="0.997063">hal@cs.utah.eduabhik@cs.utah.eduavishek@cs.utah.edu</email>
<abstract confidence="0.9985081875">In this work, we propose a semisupervised extension to a well-known supervised domain adaptation approach (EA) (Daum´e III, 2007). Our proposed approach (EA++) builds on the notion of augmented space (introduced in EA) and harnesses unlabeled data in target domain to ameliorate the transfer of inforfrom This semisupervised approach to domain adaptation is extremely simple to implement, and can be applied as a pre-processing step to any supervised learner. Experimental results on sequential labeling tasks demonstrate the efficacy of the proposed method.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Andrew Arnold</author>
<author>William W Cohen</author>
</authors>
<title>Intradocument structural frequency features for semisupervised domain adaptation.</title>
<date>2008</date>
<booktitle>In CIKM’08,</booktitle>
<pages>1291--1300</pages>
<location>Napa Valley, California, USA.</location>
<contexts>
<context position="2611" citStr="Arnold and Cohen, 2008" startWordPosition="398" endWordPosition="402">posed (Evgeniou and Pontil, 2004) for multi-task regularization where each task parameter was represented as sum of a mean parameter (that stays same for all tasks) and its deviation from this mean. SVM was used as the base classifier and the algorithm was formulated in the standard SVM dual optimization setting. Subsequently, this framework (Evgeniou and Pontil, 2004) was extended (Dredze et al., 2010) to online multidomain setting. Prior work on semi-supervised approaches to domain adaptation also exists in literature. Extraction of specific features from the available dataset was proposed (Arnold and Cohen, 2008; Blitzer et al., 2006) to facilitate the task of domain adaptation. Co-adaptation (Tur, 2009), a combination of co-training and domain adaptation, can also be considered as a semisupervised approach to domain adaptation. A semi-supervised EM algorithm for domain adaptation was proposed in (Dai et al., 2007). Similar to graph based semi-supervised approaches, a label propagation method was proposed (Xing et al., 2007) to facilitate domain adaptation. The recently proposed Domain Adaptation Machine (DAM) (Duan et al., 2009) is a semi-supervised extension of SVMs for domain adaptation and presen</context>
</contexts>
<marker>Arnold, Cohen, 2008</marker>
<rawString>Andrew Arnold and William W. Cohen. 2008. Intradocument structural frequency features for semisupervised domain adaptation. In CIKM’08, pages 1291–1300, Napa Valley, California, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Blitzer</author>
<author>Ryan Mcdonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Domain adaptation with structural correspondence learning.</title>
<date>2006</date>
<booktitle>In EMNLP’06,</booktitle>
<pages>120--128</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="2634" citStr="Blitzer et al., 2006" startWordPosition="403" endWordPosition="406">il, 2004) for multi-task regularization where each task parameter was represented as sum of a mean parameter (that stays same for all tasks) and its deviation from this mean. SVM was used as the base classifier and the algorithm was formulated in the standard SVM dual optimization setting. Subsequently, this framework (Evgeniou and Pontil, 2004) was extended (Dredze et al., 2010) to online multidomain setting. Prior work on semi-supervised approaches to domain adaptation also exists in literature. Extraction of specific features from the available dataset was proposed (Arnold and Cohen, 2008; Blitzer et al., 2006) to facilitate the task of domain adaptation. Co-adaptation (Tur, 2009), a combination of co-training and domain adaptation, can also be considered as a semisupervised approach to domain adaptation. A semi-supervised EM algorithm for domain adaptation was proposed in (Dai et al., 2007). Similar to graph based semi-supervised approaches, a label propagation method was proposed (Xing et al., 2007) to facilitate domain adaptation. The recently proposed Domain Adaptation Machine (DAM) (Duan et al., 2009) is a semi-supervised extension of SVMs for domain adaptation and presents extensive empirical </context>
<context position="13322" citStr="Blitzer et al., 2006" startWordPosition="2179" endWordPosition="2182">e prediction on unlabeled sample equal to 0. Figure 2 shows the curves of the hinge loss for class +1, class −1 and their sum. The effective loss for each unlabeled sample is similar to the sum of losses for +1 and −1 classes (shown in Figure 2c). 4 Experiments In this section, we demonstrate the empirical performance of EA augmented with unlabeled data. 4.1 Setup We follow the same experimental setup used in (Daum´e III, 2007) and perform two sequence labelling tasks (a) named-entity-recognition (NER), and (b) part-of-speech-tagging (POS )on the following datasets: PubMed-POS: Introduced by (Blitzer et al., 2006), this dataset consists of two domains. The WSJ portion of the Penn Treebank serves as the source domain and the PubMed abstracts serve as the target domain. The Figure 2: Loss functions for class +1, class −1 and unlabeled samples. task is to perform part-of-speech tagging on unlabeled PubMed abstracts with a classifier trained on labeled WSJ and PubMed data. Treebank-Brown. Treebank-Chunk data consists of the following domains: the standard WSJ domain (the same data as for CoNLL 2000), the ATIS switchboard domain and the Brown corpus. The Brown corpus consists of data combined from six subdo</context>
</contexts>
<marker>Blitzer, Mcdonald, Pereira, 2006</marker>
<rawString>John Blitzer, Ryan Mcdonald, and Fernando Pereira. 2006. Domain adaptation with structural correspondence learning. In EMNLP’06, pages 120–128, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenyuan Dai</author>
<author>Gui-Rong Xue</author>
<author>Qiang Yang</author>
<author>Yong Yu</author>
</authors>
<title>Transferring Naive Bayes classifiers for text classification.</title>
<date>2007</date>
<booktitle>In AAAI’07,</booktitle>
<pages>540--545</pages>
<location>Vancouver, B.C.</location>
<contexts>
<context position="2920" citStr="Dai et al., 2007" startWordPosition="447" endWordPosition="450"> Subsequently, this framework (Evgeniou and Pontil, 2004) was extended (Dredze et al., 2010) to online multidomain setting. Prior work on semi-supervised approaches to domain adaptation also exists in literature. Extraction of specific features from the available dataset was proposed (Arnold and Cohen, 2008; Blitzer et al., 2006) to facilitate the task of domain adaptation. Co-adaptation (Tur, 2009), a combination of co-training and domain adaptation, can also be considered as a semisupervised approach to domain adaptation. A semi-supervised EM algorithm for domain adaptation was proposed in (Dai et al., 2007). Similar to graph based semi-supervised approaches, a label propagation method was proposed (Xing et al., 2007) to facilitate domain adaptation. The recently proposed Domain Adaptation Machine (DAM) (Duan et al., 2009) is a semi-supervised extension of SVMs for domain adaptation and presents extensive empirical results. However, in almost all of the above cases, the proposed methods either use specifics of the datasets or are customized for some particular base classifier and hence it is not clear how the proposed methods can be extended to other existing classifiers. EA, on the other hand, i</context>
</contexts>
<marker>Dai, Xue, Yang, Yu, 2007</marker>
<rawString>Wenyuan Dai, Gui-Rong Xue, Qiang Yang, and Yong Yu. 2007. Transferring Naive Bayes classifiers for text classification. In AAAI’07, pages 540–545, Vancouver, B.C.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
</authors>
<date>2004</date>
<booktitle>Notes on CG and LM-BFGS optimization of logistic regression.</booktitle>
<marker>Daum´e, 2004</marker>
<rawString>Hal Daum´e III. 2004. Notes on CG and LM-BFGS optimization of logistic regression. August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
</authors>
<title>Frustratingly easy domain adaptation.</title>
<date>2007</date>
<booktitle>In ACL’07,</booktitle>
<pages>256--263</pages>
<location>Prague, Czech Republic.</location>
<marker>Daum´e, 2007</marker>
<rawString>Hal Daum´e III. 2007. Frustratingly easy domain adaptation. In ACL’07, pages 256–263, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Dredze</author>
<author>Alex Kulesza</author>
<author>Koby Crammer</author>
</authors>
<title>Multi-domain learning by confidenceweighted parameter combination.</title>
<date>2010</date>
<booktitle>Machine Learning,</booktitle>
<volume>79</volume>
<contexts>
<context position="2395" citStr="Dredze et al., 2010" startWordPosition="366" endWordPosition="369">ised domain adaptation setting. There exists prior work on supervised domain adaptation (or multi-task learning) that can be related to EASYADAPT. An algorithm for multitask learning using shared parameters was proposed (Evgeniou and Pontil, 2004) for multi-task regularization where each task parameter was represented as sum of a mean parameter (that stays same for all tasks) and its deviation from this mean. SVM was used as the base classifier and the algorithm was formulated in the standard SVM dual optimization setting. Subsequently, this framework (Evgeniou and Pontil, 2004) was extended (Dredze et al., 2010) to online multidomain setting. Prior work on semi-supervised approaches to domain adaptation also exists in literature. Extraction of specific features from the available dataset was proposed (Arnold and Cohen, 2008; Blitzer et al., 2006) to facilitate the task of domain adaptation. Co-adaptation (Tur, 2009), a combination of co-training and domain adaptation, can also be considered as a semisupervised approach to domain adaptation. A semi-supervised EM algorithm for domain adaptation was proposed in (Dai et al., 2007). Similar to graph based semi-supervised approaches, a label propagation me</context>
</contexts>
<marker>Dredze, Kulesza, Crammer, 2010</marker>
<rawString>Mark Dredze, Alex Kulesza, and Koby Crammer. 2010. Multi-domain learning by confidenceweighted parameter combination. Machine Learning, 79.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lixin Duan</author>
<author>Ivor W Tsang</author>
<author>Dong Xu</author>
<author>Tat-Seng Chua</author>
</authors>
<title>Domain adaptation from multiple sources via auxiliary classifiers.</title>
<date>2009</date>
<booktitle>In ICML’09,</booktitle>
<pages>289--296</pages>
<location>Montreal, Quebec.</location>
<contexts>
<context position="3139" citStr="Duan et al., 2009" startWordPosition="479" endWordPosition="482">ction of specific features from the available dataset was proposed (Arnold and Cohen, 2008; Blitzer et al., 2006) to facilitate the task of domain adaptation. Co-adaptation (Tur, 2009), a combination of co-training and domain adaptation, can also be considered as a semisupervised approach to domain adaptation. A semi-supervised EM algorithm for domain adaptation was proposed in (Dai et al., 2007). Similar to graph based semi-supervised approaches, a label propagation method was proposed (Xing et al., 2007) to facilitate domain adaptation. The recently proposed Domain Adaptation Machine (DAM) (Duan et al., 2009) is a semi-supervised extension of SVMs for domain adaptation and presents extensive empirical results. However, in almost all of the above cases, the proposed methods either use specifics of the datasets or are customized for some particular base classifier and hence it is not clear how the proposed methods can be extended to other existing classifiers. EA, on the other hand, is remarkably general in the sense that it can be used as a pre-processing 53 Proceedings of the 2010 Workshop on Domain Adaptation for Natural Language Processing, ACL 2010, pages 53–59, Uppsala, Sweden, 15 July 2010. c</context>
<context position="8925" citStr="Duan et al., 2009" startWordPosition="1463" endWordPosition="1466">y. 3.1 Motivation In multi-view approach for semi-supervised learning algorithms (Sindhwani et al., 2005), different hypotheses are learned in different views. Thereafter, unlabeled data is utilized to co-regularize these learned hypotheses by making them agree on unlabeled samples. In domain adaptation, the source and target data come from two different distributions. However, if the source and target domains are reasonably close to each other, we can employ a similar form of regularization using unlabeled data. A similar co-regularizer based approach for unlabeled data was previously shown (Duan et al., 2009) to give improved empirical results for domain adaptation task. However, their technique applies for the particular base classifier they consider and hence does not extend to EASYADAPT. 3.2 EA++: EASYADAPT with unlabeled data In our proposed semi-supervised extension to EASYADAPT, the source and target hypothesis are made to agree on unlabeled data. We refer to this algorithm as EA++. Recall that EASYADAPT learns a linear hypothesis h˘ E Rad in the augmented space. The hypothesis h˘ contains common, source and target sub-hypotheses and is expressed as h˘ = (hc, hs, ht). In original space (ref.</context>
</contexts>
<marker>Duan, Tsang, Xu, Chua, 2009</marker>
<rawString>Lixin Duan, Ivor W. Tsang, Dong Xu, and Tat-Seng Chua. 2009. Domain adaptation from multiple sources via auxiliary classifiers. In ICML’09, pages 289–296, Montreal, Quebec.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theodoros Evgeniou</author>
<author>Massimiliano Pontil</author>
</authors>
<title>Regularized multitask learning.</title>
<date>2004</date>
<booktitle>In KDD’04,</booktitle>
<pages>109--117</pages>
<location>Seattle, WA, USA.</location>
<contexts>
<context position="2022" citStr="Evgeniou and Pontil, 2004" startWordPosition="306" endWordPosition="309">ly. In this paper, we propose a semi-supervised1 (labeled data in source, and both labeled and unlabeled data in target) approach to leverage unlabeled data for EASYADAPT (which we call EA++) and empirically demonstrate its superior performance over EA as well as few other existing approaches. 1We refer, labeled data in source and only unlabeled data in target, as the unsupervised domain adaptation setting. There exists prior work on supervised domain adaptation (or multi-task learning) that can be related to EASYADAPT. An algorithm for multitask learning using shared parameters was proposed (Evgeniou and Pontil, 2004) for multi-task regularization where each task parameter was represented as sum of a mean parameter (that stays same for all tasks) and its deviation from this mean. SVM was used as the base classifier and the algorithm was formulated in the standard SVM dual optimization setting. Subsequently, this framework (Evgeniou and Pontil, 2004) was extended (Dredze et al., 2010) to online multidomain setting. Prior work on semi-supervised approaches to domain adaptation also exists in literature. Extraction of specific features from the available dataset was proposed (Arnold and Cohen, 2008; Blitzer e</context>
<context position="19358" citStr="Evgeniou and Pontil, 2004" startWordPosition="3168" endWordPosition="3171">re sharing algorithms are effective for domain adaptation because they are simple, easy to implement as a preprocessing step and outperform many existing state-of-the-art techniques (shown previously for domain adaptation (Daum´e III, 2007)). However, despite their simplicity and empirical success, it is not theoretically apparent why these algorithms perform so well. Prior work provides some intuitions but is mostly empirical and a formal theoretical analysis to justify FSAs (for domain adaptation) is clearly missing. Prior work (Maurer, 2006) analyzes the multi-task regularization approach (Evgeniou and Pontil, 2004) (which is related to EA) but they consider a cumulative loss in multi-task (or multi-domain) setting. This does not apply to domain adaptation setting where we are mainly interested in loss in the target domain only. Theoretically analyzing the superior performance of EA and EA++ and providing generalization guarantees is an interesting line of future work. One approach would be to model the feature sharing approach in terms of coregularization; an idea that originated in the context of multiview learning and for which some theoretical analysis has already been done (Rosenberg and Bartlett, 2</context>
</contexts>
<marker>Evgeniou, Pontil, 2004</marker>
<rawString>Theodoros Evgeniou and Massimiliano Pontil. 2004. Regularized multitask learning. In KDD’04, pages 109–117, Seattle, WA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Maurer</author>
</authors>
<title>The Rademacher complexity of linear transformation classes. In</title>
<date>2006</date>
<booktitle>COLT’06,</booktitle>
<pages>65--78</pages>
<location>Pittsburgh, Pennsylvania.</location>
<contexts>
<context position="19282" citStr="Maurer, 2006" startWordPosition="3160" endWordPosition="3161">a. We term such algorithms as Feature Sharing Algorithms. Feature sharing algorithms are effective for domain adaptation because they are simple, easy to implement as a preprocessing step and outperform many existing state-of-the-art techniques (shown previously for domain adaptation (Daum´e III, 2007)). However, despite their simplicity and empirical success, it is not theoretically apparent why these algorithms perform so well. Prior work provides some intuitions but is mostly empirical and a formal theoretical analysis to justify FSAs (for domain adaptation) is clearly missing. Prior work (Maurer, 2006) analyzes the multi-task regularization approach (Evgeniou and Pontil, 2004) (which is related to EA) but they consider a cumulative loss in multi-task (or multi-domain) setting. This does not apply to domain adaptation setting where we are mainly interested in loss in the target domain only. Theoretically analyzing the superior performance of EA and EA++ and providing generalization guarantees is an interesting line of future work. One approach would be to model the feature sharing approach in terms of coregularization; an idea that originated in the context of multiview learning and for whic</context>
</contexts>
<marker>Maurer, 2006</marker>
<rawString>Andreas Maurer. 2006. The Rademacher complexity of linear transformation classes. In COLT’06, pages 65–78, Pittsburgh, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D S Rosenberg</author>
<author>P L Bartlett</author>
</authors>
<title>The Rademacher complexity of co-regularized kernel classes.</title>
<date>2007</date>
<booktitle>In AISTATS’07,</booktitle>
<location>San Juan, Puerto Rico.</location>
<marker>Rosenberg, Bartlett, 2007</marker>
<rawString>D. S. Rosenberg and P. L. Bartlett. 2007. The Rademacher complexity of co-regularized kernel classes. In AISTATS’07, San Juan, Puerto Rico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vikas Sindhwani</author>
<author>David S Rosenberg</author>
</authors>
<title>An RKHS for multi-view learning and manifold co-regularization.</title>
<date>2008</date>
<booktitle>In ICML’08,</booktitle>
<pages>976--983</pages>
<location>Helsinki, Finland.</location>
<marker>Sindhwani, Rosenberg, 2008</marker>
<rawString>Vikas Sindhwani and David S. Rosenberg. 2008. An RKHS for multi-view learning and manifold co-regularization. In ICML’08, pages 976–983, Helsinki, Finland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vikas Sindhwani</author>
<author>Partha Niyogi</author>
<author>Mikhail Belkin</author>
</authors>
<title>A co-regularization approach to semisupervised learning with multiple views.</title>
<date>2005</date>
<booktitle>In ICML Workshop on Learning with Multiple Views,</booktitle>
<pages>824--831</pages>
<location>Bonn, Germany.</location>
<contexts>
<context position="8412" citStr="Sindhwani et al., 2005" startWordPosition="1385" endWordPosition="1388">ussed in the previous section, the EASYADAPT algorithm is attractive because it performs very well empirically and can be used in conjunction with any underlying supervised clas(2.1) .bt(x) = hx, 0, xi V(x) = hx, x, 0i 54 sifier. One drawback of EASYADAPT is that it does not make use of unlabeled target data which is generally available in large quantity in most practical problems. In this section, we propose a semi-supervised extension of this algorithm while maintaining the desirable classifier-agnostic property. 3.1 Motivation In multi-view approach for semi-supervised learning algorithms (Sindhwani et al., 2005), different hypotheses are learned in different views. Thereafter, unlabeled data is utilized to co-regularize these learned hypotheses by making them agree on unlabeled samples. In domain adaptation, the source and target data come from two different distributions. However, if the source and target domains are reasonably close to each other, we can employ a similar form of regularization using unlabeled data. A similar co-regularizer based approach for unlabeled data was previously shown (Duan et al., 2009) to give improved empirical results for domain adaptation task. However, their techniqu</context>
</contexts>
<marker>Sindhwani, Niyogi, Belkin, 2005</marker>
<rawString>Vikas Sindhwani, Partha Niyogi, and Mikhail Belkin. 2005. A co-regularization approach to semisupervised learning with multiple views. In ICML Workshop on Learning with Multiple Views, pages 824–831, Bonn, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gokhan Tur</author>
</authors>
<title>Co-adaptation: Adaptive co-training for semi-supervised learning.</title>
<date>2009</date>
<booktitle>In ICASSP’09,</booktitle>
<pages>3721--3724</pages>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="2705" citStr="Tur, 2009" startWordPosition="415" endWordPosition="416">as sum of a mean parameter (that stays same for all tasks) and its deviation from this mean. SVM was used as the base classifier and the algorithm was formulated in the standard SVM dual optimization setting. Subsequently, this framework (Evgeniou and Pontil, 2004) was extended (Dredze et al., 2010) to online multidomain setting. Prior work on semi-supervised approaches to domain adaptation also exists in literature. Extraction of specific features from the available dataset was proposed (Arnold and Cohen, 2008; Blitzer et al., 2006) to facilitate the task of domain adaptation. Co-adaptation (Tur, 2009), a combination of co-training and domain adaptation, can also be considered as a semisupervised approach to domain adaptation. A semi-supervised EM algorithm for domain adaptation was proposed in (Dai et al., 2007). Similar to graph based semi-supervised approaches, a label propagation method was proposed (Xing et al., 2007) to facilitate domain adaptation. The recently proposed Domain Adaptation Machine (DAM) (Duan et al., 2009) is a semi-supervised extension of SVMs for domain adaptation and presents extensive empirical results. However, in almost all of the above cases, the proposed method</context>
</contexts>
<marker>Tur, 2009</marker>
<rawString>Gokhan Tur. 2009. Co-adaptation: Adaptive co-training for semi-supervised learning. In ICASSP’09, pages 3721–3724, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dikan Xing</author>
<author>Wenyuan Dai</author>
<author>Gui-Rong Xue</author>
<author>Yong Yu</author>
</authors>
<title>Bridged refinement for transfer learning.</title>
<date>2007</date>
<booktitle>In PKDD’07,</booktitle>
<pages>324--335</pages>
<location>Warsaw,</location>
<contexts>
<context position="3032" citStr="Xing et al., 2007" startWordPosition="464" endWordPosition="467">ain setting. Prior work on semi-supervised approaches to domain adaptation also exists in literature. Extraction of specific features from the available dataset was proposed (Arnold and Cohen, 2008; Blitzer et al., 2006) to facilitate the task of domain adaptation. Co-adaptation (Tur, 2009), a combination of co-training and domain adaptation, can also be considered as a semisupervised approach to domain adaptation. A semi-supervised EM algorithm for domain adaptation was proposed in (Dai et al., 2007). Similar to graph based semi-supervised approaches, a label propagation method was proposed (Xing et al., 2007) to facilitate domain adaptation. The recently proposed Domain Adaptation Machine (DAM) (Duan et al., 2009) is a semi-supervised extension of SVMs for domain adaptation and presents extensive empirical results. However, in almost all of the above cases, the proposed methods either use specifics of the datasets or are customized for some particular base classifier and hence it is not clear how the proposed methods can be extended to other existing classifiers. EA, on the other hand, is remarkably general in the sense that it can be used as a pre-processing 53 Proceedings of the 2010 Workshop on</context>
</contexts>
<marker>Xing, Dai, Xue, Yu, 2007</marker>
<rawString>Dikan Xing, Wenyuan Dai, Gui-Rong Xue, and Yong Yu. 2007. Bridged refinement for transfer learning. In PKDD’07, pages 324–335, Warsaw, Poland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>