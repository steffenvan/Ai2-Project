<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001103">
<title confidence="0.994816">
Optimizing Segmentation Strategies for Simultaneous Speech Translation
</title>
<author confidence="0.995273">
Yusuke Oda Graham Neubig Sakriani Sakti Tomoki Toda Satoshi Nakamura
</author>
<affiliation confidence="0.99853">
Graduate School of Information Science
Nara Institute of Science and Technology
</affiliation>
<address confidence="0.585747">
Takayama, Ikoma, Nara 630-0192, Japan
</address>
<email confidence="0.963205">
{oda.yusuke.on9, neubig, ssakti, tomoki, s-nakamura}@is.naist.jp
</email>
<sectionHeader confidence="0.996936" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9996440625">
In this paper, we propose new algorithms
for learning segmentation strategies for si-
multaneous speech translation. In contrast
to previously proposed heuristic methods,
our method finds a segmentation that di-
rectly maximizes the performance of the
machine translation system. We describe
two methods based on greedy search and
dynamic programming that search for the
optimal segmentation strategy. An experi-
mental evaluation finds that our algorithm
is able to segment the input two to three
times more frequently than conventional
methods in terms of number of words,
while maintaining the same score of auto-
matic evaluation.1
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997532947368421">
The performance of speech translation systems
has greatly improved in the past several years,
and these systems are starting to find wide use in
a number of applications. Simultaneous speech
translation, which translates speech from the
source language into the target language in real
time, is one example of such an application. When
translating dialogue, the length of each utterance
will usually be short, so the system can simply
start the translation process when it detects the end
of an utterance. However, in the case of lectures,
for example, there is often no obvious boundary
between utterances. Thus, translation systems re-
quire a method of deciding the timing at which
to start the translation process. Using estimated
ends of sentences as the timing with which to start
translation, in the same way as a normal text trans-
lation, is a straightforward solution to this problem
(Matusov et al., 2006). However, this approach
</bodyText>
<footnote confidence="0.9739465">
1The implementation is available at
http://odaemon.com/docs/codes/greedyseg.html.
</footnote>
<bodyText confidence="0.999807605263158">
impairs the simultaneity of translation because the
system needs to wait too long until the appearance
of a estimated sentence boundary. For this reason,
segmentation strategies, which separate the input
at appropriate positions other than end of the sen-
tence, have been studied.
A number of segmentation strategies for simul-
taneous speech translation have been proposed in
recent years. F¨ugen et al. (2007) and Bangalore et
al. (2012) propose using prosodic pauses in speech
recognition to denote segmentation boundaries,
but this method strongly depends on characteris-
tics of the speech, such as the speed of speaking.
There is also research on methods that depend on
linguistic or non-linguistic heuristics over recog-
nized text (Rangarajan Sridhar et al., 2013), and it
was found that a method that predicts the location
of commas or periods achieves the highest perfor-
mance. Methods have also been proposed using
the phrase table (Yarmohammadi et al., 2013) or
the right probability (RP) of phrases (Fujita et al.,
2013), which indicates whether a phrase reorder-
ing occurs or not.
However, each of the previously mentioned
methods decides the segmentation on the basis
of heuristics, so the impact of each segmenta-
tion strategy on translation performance is not di-
rectly considered. In addition, the mean number
of words in the translation unit, which strongly af-
fects the delay of translation, cannot be directly
controlled by these methods.2
In this paper, we propose new segmentation al-
gorithms that directly optimize translation perfor-
mance given the mean number of words in the
translation unit. Our approaches find appropri-
ate segmentation boundaries incrementally using
greedy search and dynamic programming. Each
boundary is selected to explicitly maximize trans-
</bodyText>
<footnote confidence="0.996612666666667">
2The method using RP can decide relative frequency of
segmentation by changing a parameter, but guessing the
length of a translation unit from this parameter is not trivial.
</footnote>
<page confidence="0.967414">
551
</page>
<bodyText confidence="0.956164555555555">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 551–556,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
lation accuracy as measured by BLEU or another
evaluation measure.
We evaluate our methods on a speech transla-
tion task, and we confirm that our approaches can
achieve translation units two to three times as fine-
grained as other methods, while maintaining the
same accuracy.
</bodyText>
<sectionHeader confidence="0.988605" genericHeader="method">
2 Optimization Framework
</sectionHeader>
<bodyText confidence="0.999654095238095">
Our methods use the outputs of an existing ma-
chine translation system to learn a segmentation
strategy. We define F = {fj : 1 G j G N},
£ = {ej : 1 G j G N} as a parallel corpus
of source and target language sentences used to
train the segmentation strategy. N represents the
number of sentences in the corpus. In this work,
we consider sub-sentential segmentation, where
the input is already separated into sentences, and
we want to further segment these sentences into
shorter units. In an actual speech translation sys-
tem, these sentence boundaries can be estimated
automatically using a method like the period es-
timation mentioned in Rangarajan Sridhar et al.
(2013). We also assume the machine translation
system is defined by a function MT (f) that takes
a string of source words f as an argument and re-
turns the translation result e.3
We will introduce individual methods in the fol-
lowing sections, but all follow the general frame-
work shown below:
</bodyText>
<listItem confidence="0.992695666666667">
1. Decide the mean number of words µ and the
machine translation evaluation measure EV
as parameters of algorithm. We can use an
automatic evaluation measure such as BLEU
(Papineni et al., 2002) as EV . Then, we cal-
culate the number of sub-sentential segmen-
tation boundaries K that we will need to in-
sert into F to achieve an average segment
length µ:
</listItem>
<equation confidence="0.955995">
K := max 0, LEf E.T  |f  |J − N) . (1)
µ
</equation>
<listItem confidence="0.9831482">
2. Define S as a set of positions in F in which
we will insert segmentation boundaries. For
example, if we will segment the first sentence
after the third word and the third sentence af-
ter the fifth word, then S = {(1, 3) , (3, 5)}.
</listItem>
<footnote confidence="0.99930275">
3In this work, we do not use the history of the language
model mentioned in Bangalore et al. (2012). Considering this
information improves the MT performance and we plan to
include this in our approach in future work.
</footnote>
<figureCaption confidence="0.999913">
Figure 1: Concatenated translation MT (f, S).
</figureCaption>
<bodyText confidence="0.9992045">
Based on this representation, choose K seg-
mentation boundaries in F to make the set
S* that maximizes an evaluation function w
as below:
</bodyText>
<equation confidence="0.9693125">
S* := arg max w(S; F, £, EV, MT).
SE{S′:jS′j=K}
</equation>
<bodyText confidence="0.9689665">
(2)
In this work, we define w as the sum of the
evaluation measure for each parallel sentence
pair (fj, ej):
</bodyText>
<equation confidence="0.996554333333333">
N
w(S) := EV (MT (fj, S), ej), (3)
j=1
</equation>
<bodyText confidence="0.999752272727273">
where MT (f, S) represents the concatena-
tion of all partial translations {MT (f(n))}
given the segments S as shown in Figure 1.
Equation (3) indicates that we assume all
parallel sentences to be independent of each
other, and the evaluation measure is calcu-
lated for each sentence separately. This lo-
cality assumption eases efficient implementa-
tion of our algorithm, and can be realized us-
ing a sentence-level evaluation measure such
as BLEU+1 (Lin and Och, 2004).
</bodyText>
<listItem confidence="0.910587333333333">
3. Make a segmentation model MS* by treating
the obtained segmentation boundaries S* as
positive labels, all other positions as negative
labels, and training a classifier to distinguish
between them. This classifier is used to de-
tect segmentation boundaries at test time.
</listItem>
<bodyText confidence="0.999753181818182">
Steps 1. and 3. of the above procedure are triv-
ial. In contrast, choosing a good segmentation ac-
cording to Equation (2) is difficult and the focus
of the rest of this paper. In order to exactly solve
Equation (2), we must perform brute-force search
over all possible segmentations unless we make
some assumptions about the relation between the
w yielded by different segmentations. However,
the number of possible segmentations is exponen-
tially large, so brute-force search is obviously in-
tractable. In the following sections, we propose 2
</bodyText>
<page confidence="0.994902">
552
</page>
<figureCaption confidence="0.998604">
Figure 2: Example of greedy search.
</figureCaption>
<equation confidence="0.54126825">
Algorithm 1 Greedy segmentation search
S* ← ∅
fork= 1toKdo
� �
S* ← S* ∪ arg maxw(S* ∪ {s})
sXS*
end for
return S*
</equation>
<bodyText confidence="0.8338775">
methods that approximately search for a solution
to Equation (2).
</bodyText>
<subsectionHeader confidence="0.951249">
2.1 Greedy Search
</subsectionHeader>
<bodyText confidence="0.999990833333333">
Our first approximation is a greedy algorithm that
selects segmentation boundaries one-by-one. In
this method, k already-selected boundaries are left
unchanged when deciding the (k+1)-th boundary.
We find the unselected boundary that maximizes w
and add it to S:
</bodyText>
<equation confidence="0.966812666666667">
� �
Sk+1 = Sk ∪ arg maxw(Sk ∪ {s}) (4)
s�Sk
</equation>
<bodyText confidence="0.989022666666667">
Figure 2 shows an example of this process for a
single sentence, and Algorithm 1 shows the algo-
rithm for calculating K boundaries.
</bodyText>
<subsectionHeader confidence="0.8430555">
2.2 Greedy Search with Feature Grouping
and Dynamic Programming
</subsectionHeader>
<bodyText confidence="0.999996294117647">
The method described in the previous section
finds segments that achieve high translation per-
formance for the training data. However, because
the translation system MT and evaluation mea-
sure EV are both complex, the evaluation function
w includes a certain amount of noise. As a result,
the greedy algorithm that uses only w may find a
segmentation that achieves high translation perfor-
mance in the training data by chance. However,
these segmentations will not generalize, reducing
the performance for other data.
We can assume that this problem can be solved
by selecting more consistent segmentations of the
training data. To achieve this, we introduce a con-
straint that all positions that have similar charac-
teristics must be selected at the same time. Specif-
ically, we first group all positions in the source
</bodyText>
<figure confidence="0.9569775">
Group
DT+NN
</figure>
<figureCaption confidence="0.999651">
Figure 3: Grouping segments by POS bigrams.
</figureCaption>
<bodyText confidence="0.999209114285714">
sentences using features of the position, and intro-
duce a constraint that all positions with identical
features must be selected at the same time. Figure
3 shows an example of how this grouping works
when we use the POS bigram surrounding each
potential boundary as our feature set.
By introducing this constraint, we can expect
that features which have good performance over-
all will be selected, while features that have rela-
tively bad performance will not be selected even if
good performance is obtained when segmenting at
a specific location. In addition, because all posi-
tions can be classified as either segmented or not
by evaluating whether the corresponding feature is
in the learned feature set or not, it is not necessary
to train an additional classifier for the segmenta-
tion model when using this algorithm. In other
words, this constraint conducts a kind of feature
selection for greedy search.
In contrast to Algorithm 1, which only selected
one segmentation boundary at once, in our new
setting there are multiple positions selected at one
time. Thus, we need to update our search algo-
rithm to handle this setting. To do so, we use
dynamic programming (DP) together with greedy
search. Algorithm 2 shows our Greedy+DP search
algorithm. Here, c(ϕ; F) represents the number
of appearances of ϕ in the set of source sentences
F, and S(F, 4b) represents the set of segments de-
fined by both F and the set of features 4b.
The outer loop of the algorithm, like Greedy,
iterates over all S of size 1 to K. The inner loop
examines all features that appear exactly j times
in F, and measures the effect of adding them to
the best segmentation with (k − j) boundaries.
</bodyText>
<subsectionHeader confidence="0.99586">
2.3 Regularization by Feature Count
</subsectionHeader>
<bodyText confidence="0.9470155">
Even after we apply grouping by features, it
is likely that noise will still remain in the less
frequently-seen features. To avoid this problem,
we introduce regularization into the Greedy+DP
algorithm, with the evaluation function w rewrit-
Segments already selected at the k-th iteration
</bodyText>
<figure confidence="0.9670539">
I ate lunch but she left
Co = 0.5 Co = 0.8
(k+1)-th segment
Co = 0.7
WORD: I
POS: PRP
Group
NN+CC
Group
PRP+VBD
ate lunch
VBD NN
but
CC
she
PRP
left
VBD
WORD: I ate an apple and an orange
POS: PRP VBD DT NN CC DT NN
</figure>
<page confidence="0.954343">
553
</page>
<equation confidence="0.9669955">
Algorithm 2 Greedy+DP segmentation search
4b0 +— ∅
fork= 1 to K do
for j = 0 to k − 1 do
4b′ +—10 : c(0;F) = k − j ∧ 00 4bj} ll
4bk j +— 4bjU {arg ma �E�′xw(S(F1&apos;Dj U
J �ϕ���
end for
4bk +— arg max w(S(F, 4b))
4DE{Dkj:0&lt;j&lt;k}
end for
return S(F, 4bK)
ten as below:
wα(4b) := w(S(F,4b)) − α|4b|. (5)
</equation>
<bodyText confidence="0.999791">
The coefficient α is the strength of the regulariza-
tion with regards to the number of selected fea-
tures. A larger α will result in a larger penalty
against adding new features into the model. As
a result, the Greedy+DP algorithm will value fre-
quently appearing features. Note that the method
described in the previous section is equal to the
case of α = 0 in this section.
</bodyText>
<subsectionHeader confidence="0.993865">
2.4 Implementation Details
</subsectionHeader>
<bodyText confidence="0.999987555555556">
Our Greedy and Greedy+DP search algorithms
are completely described in Algorithms 1 and 2.
However, these algorithms require a large amount
of computation and simple implementations of
them are too slow to finish in realistic time. Be-
cause the heaviest parts of the algorithm are the
calculation of MT and EV , we can greatly im-
prove efficiency by memoizing the results of these
functions, only recalculating on new input.
</bodyText>
<sectionHeader confidence="0.999948" genericHeader="method">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999465">
3.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.999785">
We evaluated the performance of our segmentation
strategies by applying them to English-German
and English-Japanese TED speech translation data
from WIT3 (Cettolo et al., 2012). For English-
German, we used the TED data and splits from
the IWSLT2013 evaluation campaign (Cettolo et
al., 2013), as well as 1M sentences selected from
the out-of-domain training data using the method
of Duh et al. (2013). For English-Japanese, we
used TED data and the dictionary entries and sen-
tences from EIJIRO.4 Table 1 shows summaries of
the datasets we used.
</bodyText>
<footnote confidence="0.954557">
4http://eowp.alc.co.jp/info2/
</footnote>
<table confidence="0.999614625">
f-e Type #words
f e
Train MT 21.8M 20.3M
En-De Train Seg. 424k 390k
Test 27.6k 25.4k
Train MT 13.7M 19.7M
En-Ja Train Seg. 401k 550k
Test 8.20k 11.9k
</table>
<tableCaption confidence="0.9947145">
Table 1: Size of MT training, segmentation train-
ing and testing datasets.
</tableCaption>
<bodyText confidence="0.999382923076923">
We use the Stanford POS Tagger (Toutanova
et al., 2003) to tokenize and POS tag English
and German sentences, and KyTea (Neubig et al.,
2011) to tokenize Japanese sentences. A phrase-
based machine translation (PBMT) system learned
by Moses (Koehn et al., 2007) is used as the trans-
lation system MT. We use BLEU+1 as the eval-
uation measure EV in the proposed method. The
results on the test data are evaluated by BLEU and
RIBES (Isozaki et al., 2010), which is an evalu-
ation measure more sensitive to global reordering
than BLEU.
We evaluated our algorithm and two conven-
tional methods listed below:
Greedy is our first method that uses simple greedy
search and a linear SVM (using surrounding
word/POS 1, 2 and 3-grams as features) to
learn the segmentation model.
Greedy+DP is the algorithm that introduces
grouping the positions in the source sentence
by POS bigrams.
Punct-Predict is the method using predicted po-
sitions of punctuation (Rangarajan Sridhar et
al., 2013).
RP is the method using right probability (Fujita et
al., 2013).
</bodyText>
<subsectionHeader confidence="0.990146">
3.2 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.999514076923077">
Figures 4 and 5 show the results of evaluation for
each segmentation strategy measured by BLEU
and RIBES respectively. The horizontal axis is the
mean number of words in the generated transla-
tion units. This value is proportional to the delay
experienced during simultaneous speech transla-
tion (Rangarajan Sridhar et al., 2013) and thus a
smaller value is desirable.
RP, Greedy, and Greedy+DP methods have
multiple results in these graphs because these
methods have a parameter that controls segmen-
tation frequency. We move this parameter from
no segmentation (sentence-based translation) to
</bodyText>
<page confidence="0.996502">
554
</page>
<figure confidence="0.900117">
#words/segment
</figure>
<figureCaption confidence="0.999675">
Figure 4: BLEU score of test set.
</figureCaption>
<bodyText confidence="0.999060875">
segmenting every possible boundary (word-based
translation) and evaluate the results.
First, focusing on the Greedy method, we can
see that it underperforms the other methods. This
is a result of over-fitting as will be described in
detail later. In contrast, the proposed Greedy+DP
method shows high performance compared to the
other methods. Especially, the result of BLEU on
the English-German and the RIBES on both lan-
guage pairs show higher performance than RP at
all speed settings. Punct-Predict does not have
an adjustable parameter, so we can only show
one point. We can see that Greedy+DP can be-
gin translation about two to three times faster than
Punct-Predict while maintaining the same perfor-
mance.
Figure 6 shows the BLEU on the training data.
From this figure, it is clear that Greedy achieves
much higher performance than Greedy+DP. From
this result, we can see that the Greedy algorithm is
choosing a segmentation that achieves high accu-
racy on the training data but does not generalize to
the test data. In contrast, the grouping constraint in
the Greedy+DP algorithm is effectively suppress-
ing this overfitting.
The mean number of words µ can be decided
independently from other information, but a con-
figuration of µ affects tradeoff relation between
translation accuracy and simultaneity. For exam-
ple, smaller µ makes faster translation speed but
it also makes less translation accuracy. Basically,
we should choose µ by considering this tradeoff.
</bodyText>
<sectionHeader confidence="0.998872" genericHeader="conclusions">
4 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999083">
We proposed new algorithms for learning a seg-
mentation strategy in simultaneous speech trans-
</bodyText>
<figure confidence="0.707387">
#words/segment
</figure>
<figureCaption confidence="0.993746">
Figure 5: RIBES score of test set.
</figureCaption>
<figure confidence="0.878591">
#words/segment
</figure>
<figureCaption confidence="0.99962">
Figure 6: BLEU score of training set.
</figureCaption>
<bodyText confidence="0.999824736842105">
lation. Our algorithms directly optimize the per-
formance of a machine translation system accord-
ing to an evaluation measure, and are calculated by
greedy search and dynamic programming. Exper-
iments show our Greedy+DP method effectively
separates the source sentence into smaller units
while maintaining translation performance.
With regards to future work, it has been
noted that translation performance can be im-
proved by considering the previously translated
segment when calculating LM probabilities (Ran-
garajan Sridhar et al., 2013). We would like to ex-
pand our method to this framework, although in-
corporation of context-sensitive translations is not
trivial. In addition, the Greedy+DP algorithm uses
only one feature per a position in this paper. Using
a variety of features is also possible, so we plan to
examine expansions of our algorithm to multiple
overlapping features in future work.
</bodyText>
<sectionHeader confidence="0.999167" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.4523505">
Part of this work was supported by JSPS KAK-
ENHI Grant Number 24240032.
</bodyText>
<figure confidence="0.999099565217391">
20
18
16
14
12
10
0 5 10 15
En-De
En-Ja
Punct-Predict
RP
Greedy
Greedy+DP
Greedy+DP(α=0.5)
45
0 5 10 15
80
75
70
65
60
55
50
En-De
En-Ja
Punct-Predict
RP
Greedy
Greedy+DP
Greedy+DP(α=0.5)
BLEU
25
20
35
30
15
10
5
0 5 10 15
Greedy
Greedy+DP
Greedy+DP(α=0.5)
En-De
En-Ja
BLEU
RTBES
</figure>
<page confidence="0.994512">
555
</page>
<sectionHeader confidence="0.998072" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999915080645161">
Srinivas Bangalore, Vivek Kumar Rangarajan Srid-
har, Prakash Kolan, Ladan Golipour, and Aura
Jimenez. 2012. Real-time incremental speech-to-
speech translation of dialogs. In Proc. NAACL HLT,
pages 437–445.
Mauro Cettolo, Christian Girardi, and Marcello Fed-
erico. 2012. Wit3: Web inventory of transcribed and
translated talks. In Proc. EAMT, pages 261–268.
Mauro Cettolo, Jan Niehues, Sebastian St¨uker, Luisa
Bentivogli, and Marcello Federico. 2013. Report on
the 10th iwslt evaluation campaign. In Proc. IWSLT.
Kevin Duh, Graham Neubig, Katsuhito Sudoh, and Ha-
jime Tsukada. 2013. Adaptation data selection us-
ing neural language models: Experiments in ma-
chine translation. In Proc. ACL, pages 678–683.
Christian F¨ugen, Alex Waibel, and Muntsin Kolss.
2007. Simultaneous translation of lectures and
speeches. Machine Translation, 21(4):209–252.
Tomoki Fujita, Graham Neubig, Sakriani Sakti,
Tomoki Toda, and Satoshi Nakamura. 2013. Sim-
ple, lexicalized choice of translation timing for si-
multaneous speech translation. In InterSpeech.
Hideki Isozaki, Tsutomu Hirao, Kevin Duh, Katsuhito
Sudoh, and Hajime Tsukada. 2010. Automatic
evaluation of translation quality for distant language
pairs. In Proc. EMNLP, pages 944–952.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proc. ACL, pages 177–180.
Chin-Yew Lin and Franz Josef Och. 2004. Orange: A
method for evaluating automatic evaluation metrics
for machine translation. In Proc. COLING.
Evgeny Matusov, Arne Mauser, and Hermann Ney.
2006. Automatic sentence segmentation and punc-
tuation prediction for spoken language translation.
In Proc. IWSLT, pages 158–165.
Graham Neubig, Yosuke Nakata, and Shinsuke Mori.
2011. Pointwise prediction for robust, adaptable
japanese morphological analysis. In Proc. NAACL
HLT, pages 529–533.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: A method for automatic eval-
uation of machine translation. In Proc. ACL, pages
311–318.
Vivek Kumar Rangarajan Sridhar, John Chen, Srinivas
Bangalore, Andrej Ljolje, and Rathinavelu Chengal-
varayan. 2013. Segmentation strategies for stream-
ing speech translation. In Proc. NAACL HLT, pages
230–238.
Kristina Toutanova, Dan Klein, Christopher D. Man-
ning, and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network.
In Proc. NAACL, pages 173–180.
Mahsa Yarmohammadi, Vivek Kumar Rangara-
jan Sridhar, Srinivas Bangalore, and Baskaran
Sankaran. 2013. Incremental segmentation and
decoding strategies for simultaneous translation. In
Proc. IJCNLP, pages 1032–1036.
</reference>
<page confidence="0.998558">
556
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.825052">
<title confidence="0.999898">Optimizing Segmentation Strategies for Simultaneous Speech Translation</title>
<author confidence="0.980978">Yusuke Oda Graham Neubig Sakriani Sakti Tomoki Toda Satoshi Nakamura</author>
<affiliation confidence="0.9994055">Graduate School of Information Science Nara Institute of Science and Technology</affiliation>
<address confidence="0.999646">Takayama, Ikoma, Nara 630-0192, Japan</address>
<email confidence="0.9583">neubig,ssakti,tomoki,</email>
<abstract confidence="0.99239275">In this paper, we propose new algorithms for learning segmentation strategies for simultaneous speech translation. In contrast to previously proposed heuristic methods, our method finds a segmentation that directly maximizes the performance of the machine translation system. We describe two methods based on greedy search and dynamic programming that search for the optimal segmentation strategy. An experimental evaluation finds that our algorithm is able to segment the input two to three times more frequently than conventional methods in terms of number of words, while maintaining the same score of auto-</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
</authors>
<title>Vivek Kumar Rangarajan Sridhar, Prakash Kolan,</title>
<date>2012</date>
<booktitle>In Proc. NAACL HLT,</booktitle>
<pages>437--445</pages>
<location>Ladan</location>
<marker>Bangalore, 2012</marker>
<rawString>Srinivas Bangalore, Vivek Kumar Rangarajan Sridhar, Prakash Kolan, Ladan Golipour, and Aura Jimenez. 2012. Real-time incremental speech-tospeech translation of dialogs. In Proc. NAACL HLT, pages 437–445.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mauro Cettolo</author>
<author>Christian Girardi</author>
<author>Marcello Federico</author>
</authors>
<title>Wit3: Web inventory of transcribed and translated talks.</title>
<date>2012</date>
<booktitle>In Proc. EAMT,</booktitle>
<pages>261--268</pages>
<contexts>
<context position="13078" citStr="Cettolo et al., 2012" startWordPosition="2176" endWordPosition="2179">edy+DP search algorithms are completely described in Algorithms 1 and 2. However, these algorithms require a large amount of computation and simple implementations of them are too slow to finish in realistic time. Because the heaviest parts of the algorithm are the calculation of MT and EV , we can greatly improve efficiency by memoizing the results of these functions, only recalculating on new input. 3 Experiments 3.1 Experimental Settings We evaluated the performance of our segmentation strategies by applying them to English-German and English-Japanese TED speech translation data from WIT3 (Cettolo et al., 2012). For EnglishGerman, we used the TED data and splits from the IWSLT2013 evaluation campaign (Cettolo et al., 2013), as well as 1M sentences selected from the out-of-domain training data using the method of Duh et al. (2013). For English-Japanese, we used TED data and the dictionary entries and sentences from EIJIRO.4 Table 1 shows summaries of the datasets we used. 4http://eowp.alc.co.jp/info2/ f-e Type #words f e Train MT 21.8M 20.3M En-De Train Seg. 424k 390k Test 27.6k 25.4k Train MT 13.7M 19.7M En-Ja Train Seg. 401k 550k Test 8.20k 11.9k Table 1: Size of MT training, segmentation training </context>
</contexts>
<marker>Cettolo, Girardi, Federico, 2012</marker>
<rawString>Mauro Cettolo, Christian Girardi, and Marcello Federico. 2012. Wit3: Web inventory of transcribed and translated talks. In Proc. EAMT, pages 261–268.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mauro Cettolo</author>
<author>Jan Niehues</author>
<author>Sebastian St¨uker</author>
<author>Luisa Bentivogli</author>
<author>Marcello Federico</author>
</authors>
<title>Report on the 10th iwslt evaluation campaign.</title>
<date>2013</date>
<booktitle>In Proc. IWSLT.</booktitle>
<marker>Cettolo, Niehues, St¨uker, Bentivogli, Federico, 2013</marker>
<rawString>Mauro Cettolo, Jan Niehues, Sebastian St¨uker, Luisa Bentivogli, and Marcello Federico. 2013. Report on the 10th iwslt evaluation campaign. In Proc. IWSLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Duh</author>
<author>Graham Neubig</author>
<author>Katsuhito Sudoh</author>
<author>Hajime Tsukada</author>
</authors>
<title>Adaptation data selection using neural language models: Experiments in machine translation.</title>
<date>2013</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>678--683</pages>
<contexts>
<context position="13301" citStr="Duh et al. (2013)" startWordPosition="2214" endWordPosition="2217">eaviest parts of the algorithm are the calculation of MT and EV , we can greatly improve efficiency by memoizing the results of these functions, only recalculating on new input. 3 Experiments 3.1 Experimental Settings We evaluated the performance of our segmentation strategies by applying them to English-German and English-Japanese TED speech translation data from WIT3 (Cettolo et al., 2012). For EnglishGerman, we used the TED data and splits from the IWSLT2013 evaluation campaign (Cettolo et al., 2013), as well as 1M sentences selected from the out-of-domain training data using the method of Duh et al. (2013). For English-Japanese, we used TED data and the dictionary entries and sentences from EIJIRO.4 Table 1 shows summaries of the datasets we used. 4http://eowp.alc.co.jp/info2/ f-e Type #words f e Train MT 21.8M 20.3M En-De Train Seg. 424k 390k Test 27.6k 25.4k Train MT 13.7M 19.7M En-Ja Train Seg. 401k 550k Test 8.20k 11.9k Table 1: Size of MT training, segmentation training and testing datasets. We use the Stanford POS Tagger (Toutanova et al., 2003) to tokenize and POS tag English and German sentences, and KyTea (Neubig et al., 2011) to tokenize Japanese sentences. A phrasebased machine trans</context>
</contexts>
<marker>Duh, Neubig, Sudoh, Tsukada, 2013</marker>
<rawString>Kevin Duh, Graham Neubig, Katsuhito Sudoh, and Hajime Tsukada. 2013. Adaptation data selection using neural language models: Experiments in machine translation. In Proc. ACL, pages 678–683.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian F¨ugen</author>
<author>Alex Waibel</author>
<author>Muntsin Kolss</author>
</authors>
<title>Simultaneous translation of lectures and speeches.</title>
<date>2007</date>
<journal>Machine Translation,</journal>
<volume>21</volume>
<issue>4</issue>
<marker>F¨ugen, Waibel, Kolss, 2007</marker>
<rawString>Christian F¨ugen, Alex Waibel, and Muntsin Kolss. 2007. Simultaneous translation of lectures and speeches. Machine Translation, 21(4):209–252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomoki Fujita</author>
<author>Graham Neubig</author>
<author>Sakriani Sakti</author>
<author>Tomoki Toda</author>
<author>Satoshi Nakamura</author>
</authors>
<title>Simple, lexicalized choice of translation timing for simultaneous speech translation.</title>
<date>2013</date>
<booktitle>In InterSpeech.</booktitle>
<contexts>
<context position="3019" citStr="Fujita et al., 2013" startWordPosition="452" endWordPosition="455">07) and Bangalore et al. (2012) propose using prosodic pauses in speech recognition to denote segmentation boundaries, but this method strongly depends on characteristics of the speech, such as the speed of speaking. There is also research on methods that depend on linguistic or non-linguistic heuristics over recognized text (Rangarajan Sridhar et al., 2013), and it was found that a method that predicts the location of commas or periods achieves the highest performance. Methods have also been proposed using the phrase table (Yarmohammadi et al., 2013) or the right probability (RP) of phrases (Fujita et al., 2013), which indicates whether a phrase reordering occurs or not. However, each of the previously mentioned methods decides the segmentation on the basis of heuristics, so the impact of each segmentation strategy on translation performance is not directly considered. In addition, the mean number of words in the translation unit, which strongly affects the delay of translation, cannot be directly controlled by these methods.2 In this paper, we propose new segmentation algorithms that directly optimize translation performance given the mean number of words in the translation unit. Our approaches find</context>
<context position="14735" citStr="Fujita et al., 2013" startWordPosition="2454" endWordPosition="2457"> and RIBES (Isozaki et al., 2010), which is an evaluation measure more sensitive to global reordering than BLEU. We evaluated our algorithm and two conventional methods listed below: Greedy is our first method that uses simple greedy search and a linear SVM (using surrounding word/POS 1, 2 and 3-grams as features) to learn the segmentation model. Greedy+DP is the algorithm that introduces grouping the positions in the source sentence by POS bigrams. Punct-Predict is the method using predicted positions of punctuation (Rangarajan Sridhar et al., 2013). RP is the method using right probability (Fujita et al., 2013). 3.2 Results and Discussion Figures 4 and 5 show the results of evaluation for each segmentation strategy measured by BLEU and RIBES respectively. The horizontal axis is the mean number of words in the generated translation units. This value is proportional to the delay experienced during simultaneous speech translation (Rangarajan Sridhar et al., 2013) and thus a smaller value is desirable. RP, Greedy, and Greedy+DP methods have multiple results in these graphs because these methods have a parameter that controls segmentation frequency. We move this parameter from no segmentation (sentence-b</context>
</contexts>
<marker>Fujita, Neubig, Sakti, Toda, Nakamura, 2013</marker>
<rawString>Tomoki Fujita, Graham Neubig, Sakriani Sakti, Tomoki Toda, and Satoshi Nakamura. 2013. Simple, lexicalized choice of translation timing for simultaneous speech translation. In InterSpeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hideki Isozaki</author>
<author>Tsutomu Hirao</author>
<author>Kevin Duh</author>
<author>Katsuhito Sudoh</author>
<author>Hajime Tsukada</author>
</authors>
<title>Automatic evaluation of translation quality for distant language pairs.</title>
<date>2010</date>
<booktitle>In Proc. EMNLP,</booktitle>
<pages>944--952</pages>
<contexts>
<context position="14148" citStr="Isozaki et al., 2010" startWordPosition="2360" endWordPosition="2363">n Seg. 424k 390k Test 27.6k 25.4k Train MT 13.7M 19.7M En-Ja Train Seg. 401k 550k Test 8.20k 11.9k Table 1: Size of MT training, segmentation training and testing datasets. We use the Stanford POS Tagger (Toutanova et al., 2003) to tokenize and POS tag English and German sentences, and KyTea (Neubig et al., 2011) to tokenize Japanese sentences. A phrasebased machine translation (PBMT) system learned by Moses (Koehn et al., 2007) is used as the translation system MT. We use BLEU+1 as the evaluation measure EV in the proposed method. The results on the test data are evaluated by BLEU and RIBES (Isozaki et al., 2010), which is an evaluation measure more sensitive to global reordering than BLEU. We evaluated our algorithm and two conventional methods listed below: Greedy is our first method that uses simple greedy search and a linear SVM (using surrounding word/POS 1, 2 and 3-grams as features) to learn the segmentation model. Greedy+DP is the algorithm that introduces grouping the positions in the source sentence by POS bigrams. Punct-Predict is the method using predicted positions of punctuation (Rangarajan Sridhar et al., 2013). RP is the method using right probability (Fujita et al., 2013). 3.2 Results</context>
</contexts>
<marker>Isozaki, Hirao, Duh, Sudoh, Tsukada, 2010</marker>
<rawString>Hideki Isozaki, Tsutomu Hirao, Kevin Duh, Katsuhito Sudoh, and Hajime Tsukada. 2010. Automatic evaluation of translation quality for distant language pairs. In Proc. EMNLP, pages 944–952.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>177--180</pages>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra</location>
<contexts>
<context position="13959" citStr="Koehn et al., 2007" startWordPosition="2323" endWordPosition="2326">a and the dictionary entries and sentences from EIJIRO.4 Table 1 shows summaries of the datasets we used. 4http://eowp.alc.co.jp/info2/ f-e Type #words f e Train MT 21.8M 20.3M En-De Train Seg. 424k 390k Test 27.6k 25.4k Train MT 13.7M 19.7M En-Ja Train Seg. 401k 550k Test 8.20k 11.9k Table 1: Size of MT training, segmentation training and testing datasets. We use the Stanford POS Tagger (Toutanova et al., 2003) to tokenize and POS tag English and German sentences, and KyTea (Neubig et al., 2011) to tokenize Japanese sentences. A phrasebased machine translation (PBMT) system learned by Moses (Koehn et al., 2007) is used as the translation system MT. We use BLEU+1 as the evaluation measure EV in the proposed method. The results on the test data are evaluated by BLEU and RIBES (Isozaki et al., 2010), which is an evaluation measure more sensitive to global reordering than BLEU. We evaluated our algorithm and two conventional methods listed below: Greedy is our first method that uses simple greedy search and a linear SVM (using surrounding word/POS 1, 2 and 3-grams as features) to learn the segmentation model. Greedy+DP is the algorithm that introduces grouping the positions in the source sentence by POS</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proc. ACL, pages 177–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
<author>Franz Josef Och</author>
</authors>
<title>Orange: A method for evaluating automatic evaluation metrics for machine translation. In</title>
<date>2004</date>
<booktitle>Proc. COLING.</booktitle>
<contexts>
<context position="7098" citStr="Lin and Och, 2004" startWordPosition="1149" endWordPosition="1152">S′j=K} (2) In this work, we define w as the sum of the evaluation measure for each parallel sentence pair (fj, ej): N w(S) := EV (MT (fj, S), ej), (3) j=1 where MT (f, S) represents the concatenation of all partial translations {MT (f(n))} given the segments S as shown in Figure 1. Equation (3) indicates that we assume all parallel sentences to be independent of each other, and the evaluation measure is calculated for each sentence separately. This locality assumption eases efficient implementation of our algorithm, and can be realized using a sentence-level evaluation measure such as BLEU+1 (Lin and Och, 2004). 3. Make a segmentation model MS* by treating the obtained segmentation boundaries S* as positive labels, all other positions as negative labels, and training a classifier to distinguish between them. This classifier is used to detect segmentation boundaries at test time. Steps 1. and 3. of the above procedure are trivial. In contrast, choosing a good segmentation according to Equation (2) is difficult and the focus of the rest of this paper. In order to exactly solve Equation (2), we must perform brute-force search over all possible segmentations unless we make some assumptions about the rel</context>
</contexts>
<marker>Lin, Och, 2004</marker>
<rawString>Chin-Yew Lin and Franz Josef Och. 2004. Orange: A method for evaluating automatic evaluation metrics for machine translation. In Proc. COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeny Matusov</author>
<author>Arne Mauser</author>
<author>Hermann Ney</author>
</authors>
<title>Automatic sentence segmentation and punctuation prediction for spoken language translation.</title>
<date>2006</date>
<booktitle>In Proc. IWSLT,</booktitle>
<pages>158--165</pages>
<contexts>
<context position="1887" citStr="Matusov et al., 2006" startWordPosition="281" endWordPosition="284"> is one example of such an application. When translating dialogue, the length of each utterance will usually be short, so the system can simply start the translation process when it detects the end of an utterance. However, in the case of lectures, for example, there is often no obvious boundary between utterances. Thus, translation systems require a method of deciding the timing at which to start the translation process. Using estimated ends of sentences as the timing with which to start translation, in the same way as a normal text translation, is a straightforward solution to this problem (Matusov et al., 2006). However, this approach 1The implementation is available at http://odaemon.com/docs/codes/greedyseg.html. impairs the simultaneity of translation because the system needs to wait too long until the appearance of a estimated sentence boundary. For this reason, segmentation strategies, which separate the input at appropriate positions other than end of the sentence, have been studied. A number of segmentation strategies for simultaneous speech translation have been proposed in recent years. F¨ugen et al. (2007) and Bangalore et al. (2012) propose using prosodic pauses in speech recognition to d</context>
</contexts>
<marker>Matusov, Mauser, Ney, 2006</marker>
<rawString>Evgeny Matusov, Arne Mauser, and Hermann Ney. 2006. Automatic sentence segmentation and punctuation prediction for spoken language translation. In Proc. IWSLT, pages 158–165.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Neubig</author>
<author>Yosuke Nakata</author>
<author>Shinsuke Mori</author>
</authors>
<title>Pointwise prediction for robust, adaptable japanese morphological analysis.</title>
<date>2011</date>
<booktitle>In Proc. NAACL HLT,</booktitle>
<pages>529--533</pages>
<contexts>
<context position="13841" citStr="Neubig et al., 2011" startWordPosition="2305" endWordPosition="2308">ected from the out-of-domain training data using the method of Duh et al. (2013). For English-Japanese, we used TED data and the dictionary entries and sentences from EIJIRO.4 Table 1 shows summaries of the datasets we used. 4http://eowp.alc.co.jp/info2/ f-e Type #words f e Train MT 21.8M 20.3M En-De Train Seg. 424k 390k Test 27.6k 25.4k Train MT 13.7M 19.7M En-Ja Train Seg. 401k 550k Test 8.20k 11.9k Table 1: Size of MT training, segmentation training and testing datasets. We use the Stanford POS Tagger (Toutanova et al., 2003) to tokenize and POS tag English and German sentences, and KyTea (Neubig et al., 2011) to tokenize Japanese sentences. A phrasebased machine translation (PBMT) system learned by Moses (Koehn et al., 2007) is used as the translation system MT. We use BLEU+1 as the evaluation measure EV in the proposed method. The results on the test data are evaluated by BLEU and RIBES (Isozaki et al., 2010), which is an evaluation measure more sensitive to global reordering than BLEU. We evaluated our algorithm and two conventional methods listed below: Greedy is our first method that uses simple greedy search and a linear SVM (using surrounding word/POS 1, 2 and 3-grams as features) to learn t</context>
</contexts>
<marker>Neubig, Nakata, Mori, 2011</marker>
<rawString>Graham Neubig, Yosuke Nakata, and Shinsuke Mori. 2011. Pointwise prediction for robust, adaptable japanese morphological analysis. In Proc. NAACL HLT, pages 529–533.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: A method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="5608" citStr="Papineni et al., 2002" startWordPosition="871" endWordPosition="874">ese sentence boundaries can be estimated automatically using a method like the period estimation mentioned in Rangarajan Sridhar et al. (2013). We also assume the machine translation system is defined by a function MT (f) that takes a string of source words f as an argument and returns the translation result e.3 We will introduce individual methods in the following sections, but all follow the general framework shown below: 1. Decide the mean number of words µ and the machine translation evaluation measure EV as parameters of algorithm. We can use an automatic evaluation measure such as BLEU (Papineni et al., 2002) as EV . Then, we calculate the number of sub-sentential segmentation boundaries K that we will need to insert into F to achieve an average segment length µ: K := max 0, LEf E.T |f |J − N) . (1) µ 2. Define S as a set of positions in F in which we will insert segmentation boundaries. For example, if we will segment the first sentence after the third word and the third sentence after the fifth word, then S = {(1, 3) , (3, 5)}. 3In this work, we do not use the history of the language model mentioned in Bangalore et al. (2012). Considering this information improves the MT performance and we plan </context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: A method for automatic evaluation of machine translation. In Proc. ACL, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivek Kumar Rangarajan Sridhar</author>
<author>John Chen</author>
<author>Srinivas Bangalore</author>
<author>Andrej Ljolje</author>
<author>Rathinavelu Chengalvarayan</author>
</authors>
<title>Segmentation strategies for streaming speech translation.</title>
<date>2013</date>
<booktitle>In Proc. NAACL HLT,</booktitle>
<pages>230--238</pages>
<contexts>
<context position="2759" citStr="Sridhar et al., 2013" startWordPosition="408" endWordPosition="411">s reason, segmentation strategies, which separate the input at appropriate positions other than end of the sentence, have been studied. A number of segmentation strategies for simultaneous speech translation have been proposed in recent years. F¨ugen et al. (2007) and Bangalore et al. (2012) propose using prosodic pauses in speech recognition to denote segmentation boundaries, but this method strongly depends on characteristics of the speech, such as the speed of speaking. There is also research on methods that depend on linguistic or non-linguistic heuristics over recognized text (Rangarajan Sridhar et al., 2013), and it was found that a method that predicts the location of commas or periods achieves the highest performance. Methods have also been proposed using the phrase table (Yarmohammadi et al., 2013) or the right probability (RP) of phrases (Fujita et al., 2013), which indicates whether a phrase reordering occurs or not. However, each of the previously mentioned methods decides the segmentation on the basis of heuristics, so the impact of each segmentation strategy on translation performance is not directly considered. In addition, the mean number of words in the translation unit, which strongly</context>
<context position="5128" citStr="Sridhar et al. (2013)" startWordPosition="787" endWordPosition="790">e translation system to learn a segmentation strategy. We define F = {fj : 1 G j G N}, £ = {ej : 1 G j G N} as a parallel corpus of source and target language sentences used to train the segmentation strategy. N represents the number of sentences in the corpus. In this work, we consider sub-sentential segmentation, where the input is already separated into sentences, and we want to further segment these sentences into shorter units. In an actual speech translation system, these sentence boundaries can be estimated automatically using a method like the period estimation mentioned in Rangarajan Sridhar et al. (2013). We also assume the machine translation system is defined by a function MT (f) that takes a string of source words f as an argument and returns the translation result e.3 We will introduce individual methods in the following sections, but all follow the general framework shown below: 1. Decide the mean number of words µ and the machine translation evaluation measure EV as parameters of algorithm. We can use an automatic evaluation measure such as BLEU (Papineni et al., 2002) as EV . Then, we calculate the number of sub-sentential segmentation boundaries K that we will need to insert into F to</context>
<context position="14671" citStr="Sridhar et al., 2013" startWordPosition="2443" endWordPosition="2446">oposed method. The results on the test data are evaluated by BLEU and RIBES (Isozaki et al., 2010), which is an evaluation measure more sensitive to global reordering than BLEU. We evaluated our algorithm and two conventional methods listed below: Greedy is our first method that uses simple greedy search and a linear SVM (using surrounding word/POS 1, 2 and 3-grams as features) to learn the segmentation model. Greedy+DP is the algorithm that introduces grouping the positions in the source sentence by POS bigrams. Punct-Predict is the method using predicted positions of punctuation (Rangarajan Sridhar et al., 2013). RP is the method using right probability (Fujita et al., 2013). 3.2 Results and Discussion Figures 4 and 5 show the results of evaluation for each segmentation strategy measured by BLEU and RIBES respectively. The horizontal axis is the mean number of words in the generated translation units. This value is proportional to the delay experienced during simultaneous speech translation (Rangarajan Sridhar et al., 2013) and thus a smaller value is desirable. RP, Greedy, and Greedy+DP methods have multiple results in these graphs because these methods have a parameter that controls segmentation fr</context>
<context position="17637" citStr="Sridhar et al., 2013" startWordPosition="2906" endWordPosition="2909">ure 5: RIBES score of test set. #words/segment Figure 6: BLEU score of training set. lation. Our algorithms directly optimize the performance of a machine translation system according to an evaluation measure, and are calculated by greedy search and dynamic programming. Experiments show our Greedy+DP method effectively separates the source sentence into smaller units while maintaining translation performance. With regards to future work, it has been noted that translation performance can be improved by considering the previously translated segment when calculating LM probabilities (Rangarajan Sridhar et al., 2013). We would like to expand our method to this framework, although incorporation of context-sensitive translations is not trivial. In addition, the Greedy+DP algorithm uses only one feature per a position in this paper. Using a variety of features is also possible, so we plan to examine expansions of our algorithm to multiple overlapping features in future work. Acknowledgements Part of this work was supported by JSPS KAKENHI Grant Number 24240032. 20 18 16 14 12 10 0 5 10 15 En-De En-Ja Punct-Predict RP Greedy Greedy+DP Greedy+DP(α=0.5) 45 0 5 10 15 80 75 70 65 60 55 50 En-De En-Ja Punct-Predic</context>
</contexts>
<marker>Sridhar, Chen, Bangalore, Ljolje, Chengalvarayan, 2013</marker>
<rawString>Vivek Kumar Rangarajan Sridhar, John Chen, Srinivas Bangalore, Andrej Ljolje, and Rathinavelu Chengalvarayan. 2013. Segmentation strategies for streaming speech translation. In Proc. NAACL HLT, pages 230–238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-ofspeech tagging with a cyclic dependency network. In</title>
<date>2003</date>
<booktitle>Proc. NAACL,</booktitle>
<pages>173--180</pages>
<contexts>
<context position="13755" citStr="Toutanova et al., 2003" startWordPosition="2290" endWordPosition="2293">rom the IWSLT2013 evaluation campaign (Cettolo et al., 2013), as well as 1M sentences selected from the out-of-domain training data using the method of Duh et al. (2013). For English-Japanese, we used TED data and the dictionary entries and sentences from EIJIRO.4 Table 1 shows summaries of the datasets we used. 4http://eowp.alc.co.jp/info2/ f-e Type #words f e Train MT 21.8M 20.3M En-De Train Seg. 424k 390k Test 27.6k 25.4k Train MT 13.7M 19.7M En-Ja Train Seg. 401k 550k Test 8.20k 11.9k Table 1: Size of MT training, segmentation training and testing datasets. We use the Stanford POS Tagger (Toutanova et al., 2003) to tokenize and POS tag English and German sentences, and KyTea (Neubig et al., 2011) to tokenize Japanese sentences. A phrasebased machine translation (PBMT) system learned by Moses (Koehn et al., 2007) is used as the translation system MT. We use BLEU+1 as the evaluation measure EV in the proposed method. The results on the test data are evaluated by BLEU and RIBES (Isozaki et al., 2010), which is an evaluation measure more sensitive to global reordering than BLEU. We evaluated our algorithm and two conventional methods listed below: Greedy is our first method that uses simple greedy search</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher D. Manning, and Yoram Singer. 2003. Feature-rich part-ofspeech tagging with a cyclic dependency network. In Proc. NAACL, pages 173–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mahsa Yarmohammadi</author>
</authors>
<title>Vivek Kumar Rangarajan Sridhar, Srinivas Bangalore, and Baskaran Sankaran.</title>
<date>2013</date>
<booktitle>In Proc. IJCNLP,</booktitle>
<pages>1032--1036</pages>
<marker>Yarmohammadi, 2013</marker>
<rawString>Mahsa Yarmohammadi, Vivek Kumar Rangarajan Sridhar, Srinivas Bangalore, and Baskaran Sankaran. 2013. Incremental segmentation and decoding strategies for simultaneous translation. In Proc. IJCNLP, pages 1032–1036.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>