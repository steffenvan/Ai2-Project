<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.033305">
<title confidence="0.991728">
ClaC: Semantic Relatedness of Words and Phrases
</title>
<author confidence="0.996688">
Reda Siblini
</author>
<affiliation confidence="0.71991">
Concordia University
1400 de Maisonneuve Blvd. West
Montreal, Quebec, Canada, H3G 1M8
</affiliation>
<email confidence="0.993407">
r_sibl@encs.concordia.ca
</email>
<author confidence="0.993103">
Leila Kosseim
</author>
<affiliation confidence="0.718898">
Concordia University
1400 de Maisonneuve Blvd. West
Montreal, Quebec, Canada, H3G 1M8
</affiliation>
<email confidence="0.996647">
kosseim@encs.concordia.ca
</email>
<sectionHeader confidence="0.995624" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999622636363636">
The measurement of phrasal semantic relat-
edness is an important metric for many nat-
ural language processing applications. In this
paper, we present three approaches for mea-
suring phrasal semantics, one based on a se-
mantic network model, another on a distribu-
tional similarity model, and a hybrid between
the two. Our hybrid approach achieved an F-
measure of 77.4% on the task of evaluating
the semantic similarity of words and compo-
sitional phrases.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999956555555556">
Phrasal semantic relatedness is a measurement of
how multiword expressions are related in meaning.
Many natural language processing applications
such as textual entailment, question answering, or
information retrieval require a robust measurement
of phrasal semantic relatedness. Current approaches
to address this problem can be categorized into three
main categories: those that rely on a knowledge
base and its structure, those that use the distribu-
tional hypothesis on a large corpus, and hybrid
approaches. In this paper, we propose supervised
approaches for comparing phrasal semantics that are
based on a semantic network model, a distributional
similarity model, and a hybrid between the two.
Those approaches have been evaluated on the task
of semantic similarity of words and compositional
phrases and on the task of evaluating the composi-
tionality of phrases in context.
</bodyText>
<sectionHeader confidence="0.9738985" genericHeader="method">
2 Semantic Similarity of Words and
Compositional Phrases
</sectionHeader>
<bodyText confidence="0.9999487">
The semantic similarity of words and compositional
phrases is the task of evaluating the similarity of a
word and a short phrase of two or more words; for
example, the word Interview and the phrase Formal
Meeting. In the next section we present our seman-
tic network model for computing phrasal semantic
relatedness between a word and a phrase, followed
by a distributional similarity model, that we evalu-
ate on the task of semantic similarity of words and
compositional phrases.
</bodyText>
<subsectionHeader confidence="0.862156">
2.1 Semantic Network Model
</subsectionHeader>
<bodyText confidence="0.99992745">
Knowledge-based approaches to semantic related-
ness use the features of the knowledge base to mea-
sure the relatedness. One of most frequently used
semantic network is the Princeton’s WordNet (Fell-
baum, 1998) which groups words into synonyms
sets (called synsets) and includes 26 semantic rela-
tions between those synsets, including: hypernymy,
hyponymy, meronymy, entailment ...
To measure relatedness, most of those approaches
rely on the structure of the semantic network, such
as the semantic link path, depth (Leacock and
Chodorow, 1998; Wu and Palmer, 1994), direction
(Hirst and St-Onge, 1998), or type (Tsatsaronis et
al., 2010). Our phrasal semantic relatedness ap-
proach is inspired from those methods. However,
our approach is based on the idea that the combi-
nation of the least costly types of relations that re-
late one concept to a set of concepts are a suitable
indicator of their semantic relatedness. The type
of relations considered includes not only the hy-
</bodyText>
<page confidence="0.910372">
108
</page>
<bodyText confidence="0.347401">
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 108–113, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
</bodyText>
<figureCaption confidence="0.999622">
Figure 1: Example of the semantic network around the word car.
</figureCaption>
<bodyText confidence="0.999976714285714">
ponym/hypernym relations but also all 26 available
semantic relations found in WordNet in addition to
relations extracted from each of the eXtended Word-
Net (Harabagiu et al., 1999) synset’s logical form.
To implement our idea, we created a weighted and
directed semantic network based on the relations of
WordNet and eXtended WordNet. We used Word-
Net’s words and synsets as the nodes of the network.
Each word is connected by an edge to its synsets,
and each synset is in turn connected to other synsets
based on the semantic relations included in Word-
Net. In addition each synset is connected by a la-
beled edge to the predicate arguments that are ex-
tracted from the eXtended WordNet synset’s logical
form. Every synset in the eXtended WordNet is re-
lated to a logical form, which contains a set of pred-
icate relations that relates the synset to set of words.
Each predicate in this representation is added as an
edge to the graph connecting the synset to a word.
For example, Figure 1 shows part of the semantic
network created around the word car. In this graph,
single-line ovals represent words, while double-line
ovals represent synsets.
To compute the semantic relatedness between
nodes in the semantic network, it is necessary to take
into consideration the semantic relation involved be-
tween two nodes. Indeed, WordNet’s 26 semantic
relations are not equally distributed nor do they con-
tribute equally to the semantic relatedness between
concept. In order to indicate the contribution of each
relation, we have classified them into seven cate-
gories: Similar, Hypernym, Sense, Predicate, Part,
Instance, and Other. By classifying WordNet’s re-
lations into these classes, we are able to weight
the contribution of a relation based on the class it
belongs to, as opposed to assigning a contributory
weight to each relations. The weights were assigned
by manually comparing the semantic features of a
set of concepts that are related by a specific seman-
tic relations. Table 1 shows the seven semantic cat-
egories that we defined, their corresponding weight,
and the relations they include. For example the cat-
egory Similar includes WordNet’s relations of en-
tailment, cause, verb group, similar to, participle of
verb, antonym, and pertainym. This class of rela-
tions has the most common semantic features when
comparing two concepts related with any of those
relations and hence was assigned the lowest weight1
of 1. All the 26 relations in the table are the ones
found in WordNet, for the exception of the predicate
(and inverse predicate) relations which are the predi-
cate relations extracted from the eXtended WordNet.
This can be seen in Figure 1, for example, where the
word car is related to the word Engine with the Pred-
icate relation extracted from the eXtended WordNet
logical form and more specifically the predicate pro-
pel by.
The computation of semantic relatedness be-
tween a word and a compositional phrase is then
the combination of weights of the shortest weighted
path2 in the weighted semantic network between
that word and every word in that phrase, normalized
by the maximum path cost.
</bodyText>
<footnote confidence="0.7734716">
1The weight can be seen as the cost of traversing an edge;
hence a lower weight is assigned to a highly contributory rela-
tion.
2The shortest path is based on an implementation of Dijk-
stras graph search algorithm (Dijkstra, 1959)
</footnote>
<page confidence="0.99039">
109
</page>
<table confidence="0.996113583333333">
Category Weight Semantic Relations in WordNet or xWordnet
Similar 1 similar to, pertainym, participle of verb, entailment, cause,
antonym, verb group
Hypernym 2 hypernym, instance hypernym, derivationally related
Sense 4 lemma-synset
Predicate 6 predicate (extracted from Extended WordNet)
Part 8 holonym (instance, member, substance), meronym (instance,
member, substance), inverse predicate (extracted from Extended
WordNet)
Instance 10 hyponym, instance hyponym
Other 12 attribute, also see, domain of synset (topic, region, usage), member
of this domain (topic, region, usage)
</table>
<tableCaption confidence="0.999853">
Table 1: Relations Categories and Corresponding Weights.
</tableCaption>
<bodyText confidence="0.99967016">
Figure 2 shows an extract of the network involv-
ing the words Interview and the phrase Formal Meet-
ing. For the shortest path from Interview to Formal,
the word Interview is connected with a Sense rela-
tion to the synset #107210735 [Interview]. As in-
dicated in Table 1, the weight of this relation is de-
fined as 4, This synset is connected to the synset Ex-
amination through a Hypernym relation type with a
weight of 2, which is connected to the word Formal
with a predicate (IS) relation of weight 6. Overall,
the sum of the shortest path from Interview to For-
mal Meeting is hence equal to the sum of the edges
shown in Figure 1 (4+2+6+4+6+4+6 = 32). By nor-
malizing the sum to the maximum, In our approach,
24 is maximum path cost after which we assume
that two words are not related (which we assume to
be traversing two times maximum weighted path, 2
* maximum path weight of 12) and 8 is the mini-
mum number of edges between 2 words (which is
equal to traversing from the word to itself, 2 * sense
weight of 4)). Taking into consideration the number
of words in the phrase, the semantic relatedness will
be (24*2 - (32-8*2))/24*2 = 66.7%. In the next sec-
tion, we will introduce our distributional similarity
model.
</bodyText>
<subsectionHeader confidence="0.979145">
2.2 Distributional Similarity Model
</subsectionHeader>
<bodyText confidence="0.999978382352941">
Distributional similarity models rely on the distribu-
tional hypothesis (Harris, 1954) to represent a word
by its context in order to compare word semantics.
There are various approach for the selection, repre-
sentation, and comparison of contextual data. Most
use the vector space model to represent the context
as dimensions in a vector space, where the feature
are frequency of co-occurrence of the context words,
and the comparison is usually the cosine similar-
ity. To go beyond lexical semantics and to repre-
sent phrases, a compositional model is created, some
use the addition or multiplication of vectors such
as Mitchell and Lapata (2008), or the use of tensor
product to account for word order as in the work of
Widdows (2008), or a more complex model as the
work of Grefenstette and Sadrzadeh (2011). In our
model, we are inspired by those various work, and
more specifically by the work of Mitchell and Lapata
(2008). The compositional model is based on phrase
words vectors addition, where each vector is com-
posed of the collocation pointwise mutual informa-
tion of the word up to a window of 3 words left and
right of the main word. The corpus used to collect
the features and their frequencies is the Web 1TB
corpus (Brants and Franz, 2006). For the Interview
to Formal Meeting example, the vector of the word
interview is first created from the corpus of the top
1000 words collocating interview between the win-
dow of 1 to 3 words with their frequencies. A similar
vector is created for the word Formal and the word
Meeting, the vector representing Formal Meeting is
then the addition of vector Formal to vector Meet-
ing. The comparison of vector Interview to vector
Formal Meeting is then the cosine of both vectors.
</bodyText>
<page confidence="0.994552">
110
</page>
<subsectionHeader confidence="0.973425">
2.3 Evaluation
</subsectionHeader>
<bodyText confidence="0.99999425862069">
We evaluated our approaches for word-phrase se-
mantic relatedness on the SemEval task of evalu-
ating phrasal semantics, and more specifically on
the sub-task of evaluating the semantic similarity
between words and phrases. The task provided an
English dataset of 15,628 word-phrases, 60% an-
notated for training and 40% for testing, with the
goal of classifying each word-phrase as either pos-
itive or negative. To transform the semantic relat-
edness measure to a semantic similarity classifica-
tion one, we first calculated the semantic relatedness
of each word-phrase in the training set, and used
JRip, WEKA’s (Witten et al., 1999) implementation
of Cohen’s RIPPER rule learning algorithm (Cohen
and Singer, 1999), in order to learn a set of rules that
can differentiate between a positive semantic simi-
larity and a negative one. The classifier resulted in
rules for the semantic network model based related-
ness that could be summarized as follows: If the se-
mantic relatedness of the word-phrase is over 61%
then the similarity is positive, otherwise it is nega-
tive. So for the example Interview - Formal meeting,
which resulted in a semantic relatedness of 66.7% in
the semantic network approach, it will be classified
positively by the generated rule. This method was
our first submitted test run to this task, which re-
sulted in a recall of 63.79%, a precision of 91.01%,
and an F-measure of 75.00% on the testing set.
For the second run, we trained the distributional
similarity model using the same classifier. This re-
sulted with the following rule that could be summa-
rized as follows: If the semantic relatedness of the
word-phrase is over 40% then the similarity is pos-
itive, otherwise it is negative. It was obvious from
the training set that the semantic network model
was more accurate than the distributional similarity
model, but the distributional model had more cover-
age. So for our second submitted test run, we used
the semantic network approach as the main result,
but used the distributional model as a backup ap-
proach if one of the words in the phrase was not
available in WordNet, thus combining the precision
and coverage of both approaches. This method re-
sulted in a recall of 69.48%, a precision of 86.70%,
and an F-measure of 77.14% on the testing set.
For the last run, we used the same classifier
but this time we training it using two features:
the semantic network model relatedness measure
(SN), and the distributional similarity model (DS).
This training resulted in a set of rules that could
be summarized as follows: if SN &gt; 61% then the
similarity is positive, else if DS &gt; 40% then the
similarity is also positive, and lastly if SN &gt; 53%
and DS &gt; 31% then also in this case the similarity
is positive, otherwise the similarity is negative. This
was our third submitted test run, which resulted a
recall of 70.66%, a precision of 85.55%, and an
F-measure of 77.39% on the testing set.
</bodyText>
<sectionHeader confidence="0.904918" genericHeader="method">
3 Semantic Compositionality in Context
</sectionHeader>
<bodyText confidence="0.999674875">
The semantic compositional in context is the task of
evaluating if a phrase is used literally or figuratively
in context. For example, the phrase big picture is
used literally in the sentence Click here for a bigger
picture and figuratively in To solve this problem, you
have to look at the bigger picture.
Our approach for this task is a supervised ap-
proached based on two main components: first, the
availability of the phrases most frequent collocating
expressions in a large corpus, and more specifically
the top 1000 phrases by frequency in Web 1TB cor-
pus (Brants and Franz, 2006). For example, for the
phrase big picture, we collect the top 1000 phrases
that come before and after the phrase in a corpus,
those includes look at the, see the, understand the
..... If the context contain any of those phrase, then
this component returns 1, indicating that the phrase
is most probably used figuratively. The intuition is
that, the use of phrases figuratively is more frequent
than their use in a literal meaning, and hence the
most frequent use will be collocated with phrases
that indicate this use.
The second component, is the phrase compositional-
ity. We calculate the semantic relatedness using the
semantic network model relatedness measure, that
was explained in Section 2.1, between the phrase
and the first content word before it and after it. The
intuition here is that the semantic relatedness of the
figurative use of the phrase to its context should be
different than the relatedness to its literal use. So
for the example, the phrase old school in the con-
text he is one of the old school versus the hall of
</bodyText>
<page confidence="0.997518">
111
</page>
<figureCaption confidence="0.998663">
Figure 2: Shortest Path Between the Word Interview and the Phrase Formal Meeting.
</figureCaption>
<bodyText confidence="0.9999576">
the old school, we can notice that hall will be more
related to old school than the word one. This compo-
nent will result in two features: the relatedness to the
word before the phrase (SRB) and the relatedness to
word after the phrase in context (SRA).
To combine both componenets, we evaluated our
approaches on the data set presented by the Se-
mEval task of evaluating phrasal semantics, and
more specifically on the sub task of evaluating se-
mantic compositionality in context. The data set
contains a total of 1114 training instances, and 518
test instances. We use the training data and com-
puted the three features (Frequent Collocation (FC),
Semantic Relatedness word Before (SRB), and Se-
mantic Relatedness word After (SRA), and used
JRip, WEKA’s (Witten et al., 1999) implementation
of Cohen’s RIPPER rule learning algorithm (Cohen
and Singer, 1999) to learn a set of rule that differen-
tiate between a figurative and literal phrase use. This
method resulted in a set of rules that can be summa-
rized as follows: if FC is equal to 0 and SRB &lt; 75%
then it is used literally in this context, else if FC is
equal to 0 and SRA &lt; 75% then it is is also used lit-
erally, otherwise it is used figuratively. This method
resulted in an accuracy of 55.01% on the testing set.
</bodyText>
<sectionHeader confidence="0.999539" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.99947815">
In this paper we have presented state of the art
word-phrase semantic relatedness approaches that
are based on a semantic network model, a distribu-
tional model, and a combination of the two. The
novelty of the semantic network model approach is
the use of the sum of the shortest path between a
word and a phrase from a weighted semantic net-
work to calculate word-phrase semantic relatedness.
We evaluated the approach on the SemEval task of
evaluating phrasal semantics, once in a supervised
standalone configuration, another with a backup dis-
tributional similarity model, and last in a hybrid con-
figuration with the distributional model. The hy-
brid model achieved the highest f-measure in those
three configuration of 77.4% on the task of evaluat-
ing the semantic similarity of words and composi-
tional phrases. We also evaluated this approach on
the subtask of evaluating the semantic composition-
ality in context with less success, and an accuracy of
of 55.01%.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999527">
We would like to thank the reviewers for their sug-
gestions and valuable comments.
</bodyText>
<sectionHeader confidence="0.999266" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999168111111111">
Thorsten Brants and Alex Franz. 2006. Web 1t 5-gram
version 1.
William W Cohen and Yoram Singer. 1999. A simple,
fast, and effective rule learner. In Proceedings of the
National Conference on Artificial Intelligence, pages
335–342. John Wiley &amp; Sons Ltd.
Edsger W Dijkstra. 1959. A note on two problems
in connexion with graphs. Numerische mathematik,
1(1):269–271.
</reference>
<page confidence="0.982129">
112
</page>
<reference confidence="0.999822725">
Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. MIT Press.
Edward Grefenstette and Mehrnoosh Sadrzadeh. 2011.
Experimental support for a categorical compositional
distributional model of meaning. In Proceedings of
the Conference on Empirical Methods in Natural Lan-
guage Processing, pages 1394–1404. Association for
Computational Linguistics.
Sanda Harabagiu, George Miller, and Dan Moldovan.
1999. Wordnet 2- a morphologically and semantically
enhanced resource. In Proceedings of SIGLEX, vol-
ume 99, pages 1–8.
Zellig S Harris. 1954. Distributional structure. Word.
Graeme Hirst and David St-Onge. 1998. Lexical chains
as representations of context for the detection and cor-
rection of malapropisms. WordNet An electronic lexi-
cal database, pages 305–332, April.
Claudia Leacock and Martin Chodorow. 1998. Com-
bining local context and wordnet similarity for word
sense identification. WordNet: An electronic lexical
database, 49(2):265–283.
Jeff Mitchell and Mirella Lapata. 2008. Vector-based
models of semantic composition. proceedings ofACL-
08: HLT, pages 236–244.
George Tsatsaronis, Iraklis Varlamis, and Michalis Vazir-
giannis. 2010. Text relatedness based on a word
thesaurus. Journal of Artificial Intelligence Research,
37(1):1–40.
Dominic Widdows. 2008. Semantic vector products:
Some initial investigations. In To appear in Second
AAAI Symposium on Quantum Interaction, volume 26,
page 28th. Citeseer.
Ian H Witten, Eibe Frank, Leonard E Trigg, Mark A Hall,
Geoffrey Holmes, and Sally Jo Cunningham. 1999.
Weka: Practical machine learning tools and techniques
with java implementations.
Zhibiao Wu and Martha Palmer. 1994. Verbs seman-
tics and lexical selection. In Proceedings of the 32nd
annual meeting on Association for Computational Lin-
guistics, pages 133–138, New Mexico, June.
</reference>
<page confidence="0.999318">
113
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.381557">
<title confidence="0.986697">ClaC: Semantic Relatedness of Words and Phrases</title>
<address confidence="0.9089165">Reda Concordia 1400 de Maisonneuve Blvd. Montreal, Quebec, Canada, H3G</address>
<email confidence="0.985557">r_sibl@encs.concordia.ca</email>
<affiliation confidence="0.660019">Leila</affiliation>
<address confidence="0.910620666666667">Concordia 1400 de Maisonneuve Blvd. Montreal, Quebec, Canada, H3G</address>
<email confidence="0.994478">kosseim@encs.concordia.ca</email>
<abstract confidence="0.996930166666667">The measurement of phrasal semantic relatedness is an important metric for many natural language processing applications. In this paper, we present three approaches for measuring phrasal semantics, one based on a semantic network model, another on a distributional similarity model, and a hybrid between the two. Our hybrid approach achieved an Fmeasure of 77.4% on the task of evaluating the semantic similarity of words and compositional phrases.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<title>Web 1t 5-gram version 1.</title>
<date>2006</date>
<contexts>
<context position="9981" citStr="Brants and Franz, 2006" startWordPosition="1613" endWordPosition="1616">nd Lapata (2008), or the use of tensor product to account for word order as in the work of Widdows (2008), or a more complex model as the work of Grefenstette and Sadrzadeh (2011). In our model, we are inspired by those various work, and more specifically by the work of Mitchell and Lapata (2008). The compositional model is based on phrase words vectors addition, where each vector is composed of the collocation pointwise mutual information of the word up to a window of 3 words left and right of the main word. The corpus used to collect the features and their frequencies is the Web 1TB corpus (Brants and Franz, 2006). For the Interview to Formal Meeting example, the vector of the word interview is first created from the corpus of the top 1000 words collocating interview between the window of 1 to 3 words with their frequencies. A similar vector is created for the word Formal and the word Meeting, the vector representing Formal Meeting is then the addition of vector Formal to vector Meeting. The comparison of vector Interview to vector Formal Meeting is then the cosine of both vectors. 110 2.3 Evaluation We evaluated our approaches for word-phrase semantic relatedness on the SemEval task of evaluating phra</context>
<context position="14016" citStr="Brants and Franz, 2006" startWordPosition="2299" endWordPosition="2302"> Semantic Compositionality in Context The semantic compositional in context is the task of evaluating if a phrase is used literally or figuratively in context. For example, the phrase big picture is used literally in the sentence Click here for a bigger picture and figuratively in To solve this problem, you have to look at the bigger picture. Our approach for this task is a supervised approached based on two main components: first, the availability of the phrases most frequent collocating expressions in a large corpus, and more specifically the top 1000 phrases by frequency in Web 1TB corpus (Brants and Franz, 2006). For example, for the phrase big picture, we collect the top 1000 phrases that come before and after the phrase in a corpus, those includes look at the, see the, understand the ..... If the context contain any of those phrase, then this component returns 1, indicating that the phrase is most probably used figuratively. The intuition is that, the use of phrases figuratively is more frequent than their use in a literal meaning, and hence the most frequent use will be collocated with phrases that indicate this use. The second component, is the phrase compositionality. We calculate the semantic r</context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>Thorsten Brants and Alex Franz. 2006. Web 1t 5-gram version 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William W Cohen</author>
<author>Yoram Singer</author>
</authors>
<title>A simple, fast, and effective rule learner.</title>
<date>1999</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence,</booktitle>
<pages>335--342</pages>
<publisher>John Wiley &amp; Sons Ltd.</publisher>
<contexts>
<context position="11188" citStr="Cohen and Singer, 1999" startWordPosition="1809" endWordPosition="1812"> evaluating phrasal semantics, and more specifically on the sub-task of evaluating the semantic similarity between words and phrases. The task provided an English dataset of 15,628 word-phrases, 60% annotated for training and 40% for testing, with the goal of classifying each word-phrase as either positive or negative. To transform the semantic relatedness measure to a semantic similarity classification one, we first calculated the semantic relatedness of each word-phrase in the training set, and used JRip, WEKA’s (Witten et al., 1999) implementation of Cohen’s RIPPER rule learning algorithm (Cohen and Singer, 1999), in order to learn a set of rules that can differentiate between a positive semantic similarity and a negative one. The classifier resulted in rules for the semantic network model based relatedness that could be summarized as follows: If the semantic relatedness of the word-phrase is over 61% then the similarity is positive, otherwise it is negative. So for the example Interview - Formal meeting, which resulted in a semantic relatedness of 66.7% in the semantic network approach, it will be classified positively by the generated rule. This method was our first submitted test run to this task, </context>
<context position="15994" citStr="Cohen and Singer, 1999" startWordPosition="2634" endWordPosition="2637">ase in context (SRA). To combine both componenets, we evaluated our approaches on the data set presented by the SemEval task of evaluating phrasal semantics, and more specifically on the sub task of evaluating semantic compositionality in context. The data set contains a total of 1114 training instances, and 518 test instances. We use the training data and computed the three features (Frequent Collocation (FC), Semantic Relatedness word Before (SRB), and Semantic Relatedness word After (SRA), and used JRip, WEKA’s (Witten et al., 1999) implementation of Cohen’s RIPPER rule learning algorithm (Cohen and Singer, 1999) to learn a set of rule that differentiate between a figurative and literal phrase use. This method resulted in a set of rules that can be summarized as follows: if FC is equal to 0 and SRB &lt; 75% then it is used literally in this context, else if FC is equal to 0 and SRA &lt; 75% then it is is also used literally, otherwise it is used figuratively. This method resulted in an accuracy of 55.01% on the testing set. 4 Conclusion In this paper we have presented state of the art word-phrase semantic relatedness approaches that are based on a semantic network model, a distributional model, and a combin</context>
</contexts>
<marker>Cohen, Singer, 1999</marker>
<rawString>William W Cohen and Yoram Singer. 1999. A simple, fast, and effective rule learner. In Proceedings of the National Conference on Artificial Intelligence, pages 335–342. John Wiley &amp; Sons Ltd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edsger W Dijkstra</author>
</authors>
<title>A note on two problems in connexion with graphs.</title>
<date>1959</date>
<journal>Numerische mathematik,</journal>
<volume>1</volume>
<issue>1</issue>
<contexts>
<context position="6837" citStr="Dijkstra, 1959" startWordPosition="1087" endWordPosition="1088"> the Predicate relation extracted from the eXtended WordNet logical form and more specifically the predicate propel by. The computation of semantic relatedness between a word and a compositional phrase is then the combination of weights of the shortest weighted path2 in the weighted semantic network between that word and every word in that phrase, normalized by the maximum path cost. 1The weight can be seen as the cost of traversing an edge; hence a lower weight is assigned to a highly contributory relation. 2The shortest path is based on an implementation of Dijkstras graph search algorithm (Dijkstra, 1959) 109 Category Weight Semantic Relations in WordNet or xWordnet Similar 1 similar to, pertainym, participle of verb, entailment, cause, antonym, verb group Hypernym 2 hypernym, instance hypernym, derivationally related Sense 4 lemma-synset Predicate 6 predicate (extracted from Extended WordNet) Part 8 holonym (instance, member, substance), meronym (instance, member, substance), inverse predicate (extracted from Extended WordNet) Instance 10 hyponym, instance hyponym Other 12 attribute, also see, domain of synset (topic, region, usage), member of this domain (topic, region, usage) Table 1: Relat</context>
</contexts>
<marker>Dijkstra, 1959</marker>
<rawString>Edsger W Dijkstra. 1959. A note on two problems in connexion with graphs. Numerische mathematik, 1(1):269–271.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="2422" citStr="Fellbaum, 1998" startWordPosition="366" endWordPosition="368">ty of a word and a short phrase of two or more words; for example, the word Interview and the phrase Formal Meeting. In the next section we present our semantic network model for computing phrasal semantic relatedness between a word and a phrase, followed by a distributional similarity model, that we evaluate on the task of semantic similarity of words and compositional phrases. 2.1 Semantic Network Model Knowledge-based approaches to semantic relatedness use the features of the knowledge base to measure the relatedness. One of most frequently used semantic network is the Princeton’s WordNet (Fellbaum, 1998) which groups words into synonyms sets (called synsets) and includes 26 semantic relations between those synsets, including: hypernymy, hyponymy, meronymy, entailment ... To measure relatedness, most of those approaches rely on the structure of the semantic network, such as the semantic link path, depth (Leacock and Chodorow, 1998; Wu and Palmer, 1994), direction (Hirst and St-Onge, 1998), or type (Tsatsaronis et al., 2010). Our phrasal semantic relatedness approach is inspired from those methods. However, our approach is based on the idea that the combination of the least costly types of rela</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Grefenstette</author>
<author>Mehrnoosh Sadrzadeh</author>
</authors>
<title>Experimental support for a categorical compositional distributional model of meaning.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1394--1404</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9537" citStr="Grefenstette and Sadrzadeh (2011)" startWordPosition="1533" endWordPosition="1536"> approach for the selection, representation, and comparison of contextual data. Most use the vector space model to represent the context as dimensions in a vector space, where the feature are frequency of co-occurrence of the context words, and the comparison is usually the cosine similarity. To go beyond lexical semantics and to represent phrases, a compositional model is created, some use the addition or multiplication of vectors such as Mitchell and Lapata (2008), or the use of tensor product to account for word order as in the work of Widdows (2008), or a more complex model as the work of Grefenstette and Sadrzadeh (2011). In our model, we are inspired by those various work, and more specifically by the work of Mitchell and Lapata (2008). The compositional model is based on phrase words vectors addition, where each vector is composed of the collocation pointwise mutual information of the word up to a window of 3 words left and right of the main word. The corpus used to collect the features and their frequencies is the Web 1TB corpus (Brants and Franz, 2006). For the Interview to Formal Meeting example, the vector of the word interview is first created from the corpus of the top 1000 words collocating interview</context>
</contexts>
<marker>Grefenstette, Sadrzadeh, 2011</marker>
<rawString>Edward Grefenstette and Mehrnoosh Sadrzadeh. 2011. Experimental support for a categorical compositional distributional model of meaning. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1394–1404. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda Harabagiu</author>
<author>George Miller</author>
<author>Dan Moldovan</author>
</authors>
<title>Wordnet 2- a morphologically and semantically enhanced resource.</title>
<date>1999</date>
<booktitle>In Proceedings of SIGLEX,</booktitle>
<volume>99</volume>
<pages>1--8</pages>
<contexts>
<context position="3684" citStr="Harabagiu et al., 1999" startWordPosition="558" endWordPosition="561">of concepts are a suitable indicator of their semantic relatedness. The type of relations considered includes not only the hy108 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 108–113, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics Figure 1: Example of the semantic network around the word car. ponym/hypernym relations but also all 26 available semantic relations found in WordNet in addition to relations extracted from each of the eXtended WordNet (Harabagiu et al., 1999) synset’s logical form. To implement our idea, we created a weighted and directed semantic network based on the relations of WordNet and eXtended WordNet. We used WordNet’s words and synsets as the nodes of the network. Each word is connected by an edge to its synsets, and each synset is in turn connected to other synsets based on the semantic relations included in WordNet. In addition each synset is connected by a labeled edge to the predicate arguments that are extracted from the eXtended WordNet synset’s logical form. Every synset in the eXtended WordNet is related to a logical form, which </context>
</contexts>
<marker>Harabagiu, Miller, Moldovan, 1999</marker>
<rawString>Sanda Harabagiu, George Miller, and Dan Moldovan. 1999. Wordnet 2- a morphologically and semantically enhanced resource. In Proceedings of SIGLEX, volume 99, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig S Harris</author>
</authors>
<date>1954</date>
<note>Distributional structure. Word.</note>
<contexts>
<context position="8815" citStr="Harris, 1954" startWordPosition="1412" endWordPosition="1413"> cost after which we assume that two words are not related (which we assume to be traversing two times maximum weighted path, 2 * maximum path weight of 12) and 8 is the minimum number of edges between 2 words (which is equal to traversing from the word to itself, 2 * sense weight of 4)). Taking into consideration the number of words in the phrase, the semantic relatedness will be (24*2 - (32-8*2))/24*2 = 66.7%. In the next section, we will introduce our distributional similarity model. 2.2 Distributional Similarity Model Distributional similarity models rely on the distributional hypothesis (Harris, 1954) to represent a word by its context in order to compare word semantics. There are various approach for the selection, representation, and comparison of contextual data. Most use the vector space model to represent the context as dimensions in a vector space, where the feature are frequency of co-occurrence of the context words, and the comparison is usually the cosine similarity. To go beyond lexical semantics and to represent phrases, a compositional model is created, some use the addition or multiplication of vectors such as Mitchell and Lapata (2008), or the use of tensor product to account</context>
</contexts>
<marker>Harris, 1954</marker>
<rawString>Zellig S Harris. 1954. Distributional structure. Word.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Hirst</author>
<author>David St-Onge</author>
</authors>
<title>Lexical chains as representations of context for the detection and correction of malapropisms. WordNet An electronic lexical database,</title>
<date>1998</date>
<pages>305--332</pages>
<contexts>
<context position="2813" citStr="Hirst and St-Onge, 1998" startWordPosition="423" endWordPosition="426">2.1 Semantic Network Model Knowledge-based approaches to semantic relatedness use the features of the knowledge base to measure the relatedness. One of most frequently used semantic network is the Princeton’s WordNet (Fellbaum, 1998) which groups words into synonyms sets (called synsets) and includes 26 semantic relations between those synsets, including: hypernymy, hyponymy, meronymy, entailment ... To measure relatedness, most of those approaches rely on the structure of the semantic network, such as the semantic link path, depth (Leacock and Chodorow, 1998; Wu and Palmer, 1994), direction (Hirst and St-Onge, 1998), or type (Tsatsaronis et al., 2010). Our phrasal semantic relatedness approach is inspired from those methods. However, our approach is based on the idea that the combination of the least costly types of relations that relate one concept to a set of concepts are a suitable indicator of their semantic relatedness. The type of relations considered includes not only the hy108 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 108–113, Atlanta, Georgia, June 14-15, 2013. c�2013 Association fo</context>
</contexts>
<marker>Hirst, St-Onge, 1998</marker>
<rawString>Graeme Hirst and David St-Onge. 1998. Lexical chains as representations of context for the detection and correction of malapropisms. WordNet An electronic lexical database, pages 305–332, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudia Leacock</author>
<author>Martin Chodorow</author>
</authors>
<title>Combining local context and wordnet similarity for word sense identification. WordNet: An electronic lexical database,</title>
<date>1998</date>
<pages>49--2</pages>
<contexts>
<context position="2754" citStr="Leacock and Chodorow, 1998" startWordPosition="414" endWordPosition="417">k of semantic similarity of words and compositional phrases. 2.1 Semantic Network Model Knowledge-based approaches to semantic relatedness use the features of the knowledge base to measure the relatedness. One of most frequently used semantic network is the Princeton’s WordNet (Fellbaum, 1998) which groups words into synonyms sets (called synsets) and includes 26 semantic relations between those synsets, including: hypernymy, hyponymy, meronymy, entailment ... To measure relatedness, most of those approaches rely on the structure of the semantic network, such as the semantic link path, depth (Leacock and Chodorow, 1998; Wu and Palmer, 1994), direction (Hirst and St-Onge, 1998), or type (Tsatsaronis et al., 2010). Our phrasal semantic relatedness approach is inspired from those methods. However, our approach is based on the idea that the combination of the least costly types of relations that relate one concept to a set of concepts are a suitable indicator of their semantic relatedness. The type of relations considered includes not only the hy108 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 108–113</context>
</contexts>
<marker>Leacock, Chodorow, 1998</marker>
<rawString>Claudia Leacock and Martin Chodorow. 1998. Combining local context and wordnet similarity for word sense identification. WordNet: An electronic lexical database, 49(2):265–283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Mitchell</author>
<author>Mirella Lapata</author>
</authors>
<title>Vector-based models of semantic composition. proceedings ofACL08: HLT,</title>
<date>2008</date>
<pages>236--244</pages>
<contexts>
<context position="9374" citStr="Mitchell and Lapata (2008)" startWordPosition="1502" endWordPosition="1505">ilarity models rely on the distributional hypothesis (Harris, 1954) to represent a word by its context in order to compare word semantics. There are various approach for the selection, representation, and comparison of contextual data. Most use the vector space model to represent the context as dimensions in a vector space, where the feature are frequency of co-occurrence of the context words, and the comparison is usually the cosine similarity. To go beyond lexical semantics and to represent phrases, a compositional model is created, some use the addition or multiplication of vectors such as Mitchell and Lapata (2008), or the use of tensor product to account for word order as in the work of Widdows (2008), or a more complex model as the work of Grefenstette and Sadrzadeh (2011). In our model, we are inspired by those various work, and more specifically by the work of Mitchell and Lapata (2008). The compositional model is based on phrase words vectors addition, where each vector is composed of the collocation pointwise mutual information of the word up to a window of 3 words left and right of the main word. The corpus used to collect the features and their frequencies is the Web 1TB corpus (Brants and Franz</context>
</contexts>
<marker>Mitchell, Lapata, 2008</marker>
<rawString>Jeff Mitchell and Mirella Lapata. 2008. Vector-based models of semantic composition. proceedings ofACL08: HLT, pages 236–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Tsatsaronis</author>
</authors>
<title>Iraklis Varlamis, and Michalis Vazirgiannis.</title>
<date>2010</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>37</volume>
<issue>1</issue>
<marker>Tsatsaronis, 2010</marker>
<rawString>George Tsatsaronis, Iraklis Varlamis, and Michalis Vazirgiannis. 2010. Text relatedness based on a word thesaurus. Journal of Artificial Intelligence Research, 37(1):1–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominic Widdows</author>
</authors>
<title>Semantic vector products: Some initial investigations.</title>
<date>2008</date>
<booktitle>In To appear in Second AAAI Symposium on Quantum Interaction,</booktitle>
<volume>26</volume>
<pages>28</pages>
<publisher>Citeseer.</publisher>
<contexts>
<context position="9463" citStr="Widdows (2008)" startWordPosition="1522" endWordPosition="1523">t in order to compare word semantics. There are various approach for the selection, representation, and comparison of contextual data. Most use the vector space model to represent the context as dimensions in a vector space, where the feature are frequency of co-occurrence of the context words, and the comparison is usually the cosine similarity. To go beyond lexical semantics and to represent phrases, a compositional model is created, some use the addition or multiplication of vectors such as Mitchell and Lapata (2008), or the use of tensor product to account for word order as in the work of Widdows (2008), or a more complex model as the work of Grefenstette and Sadrzadeh (2011). In our model, we are inspired by those various work, and more specifically by the work of Mitchell and Lapata (2008). The compositional model is based on phrase words vectors addition, where each vector is composed of the collocation pointwise mutual information of the word up to a window of 3 words left and right of the main word. The corpus used to collect the features and their frequencies is the Web 1TB corpus (Brants and Franz, 2006). For the Interview to Formal Meeting example, the vector of the word interview is</context>
</contexts>
<marker>Widdows, 2008</marker>
<rawString>Dominic Widdows. 2008. Semantic vector products: Some initial investigations. In To appear in Second AAAI Symposium on Quantum Interaction, volume 26, page 28th. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Eibe Frank</author>
<author>Leonard E Trigg</author>
<author>Mark A Hall</author>
<author>Geoffrey Holmes</author>
<author>Sally Jo Cunningham</author>
</authors>
<title>Weka: Practical machine learning tools and techniques with java implementations.</title>
<date>1999</date>
<contexts>
<context position="11106" citStr="Witten et al., 1999" startWordPosition="1798" endWordPosition="1801">ated our approaches for word-phrase semantic relatedness on the SemEval task of evaluating phrasal semantics, and more specifically on the sub-task of evaluating the semantic similarity between words and phrases. The task provided an English dataset of 15,628 word-phrases, 60% annotated for training and 40% for testing, with the goal of classifying each word-phrase as either positive or negative. To transform the semantic relatedness measure to a semantic similarity classification one, we first calculated the semantic relatedness of each word-phrase in the training set, and used JRip, WEKA’s (Witten et al., 1999) implementation of Cohen’s RIPPER rule learning algorithm (Cohen and Singer, 1999), in order to learn a set of rules that can differentiate between a positive semantic similarity and a negative one. The classifier resulted in rules for the semantic network model based relatedness that could be summarized as follows: If the semantic relatedness of the word-phrase is over 61% then the similarity is positive, otherwise it is negative. So for the example Interview - Formal meeting, which resulted in a semantic relatedness of 66.7% in the semantic network approach, it will be classified positively </context>
<context position="15912" citStr="Witten et al., 1999" startWordPosition="2623" endWordPosition="2626">s to the word before the phrase (SRB) and the relatedness to word after the phrase in context (SRA). To combine both componenets, we evaluated our approaches on the data set presented by the SemEval task of evaluating phrasal semantics, and more specifically on the sub task of evaluating semantic compositionality in context. The data set contains a total of 1114 training instances, and 518 test instances. We use the training data and computed the three features (Frequent Collocation (FC), Semantic Relatedness word Before (SRB), and Semantic Relatedness word After (SRA), and used JRip, WEKA’s (Witten et al., 1999) implementation of Cohen’s RIPPER rule learning algorithm (Cohen and Singer, 1999) to learn a set of rule that differentiate between a figurative and literal phrase use. This method resulted in a set of rules that can be summarized as follows: if FC is equal to 0 and SRB &lt; 75% then it is used literally in this context, else if FC is equal to 0 and SRA &lt; 75% then it is is also used literally, otherwise it is used figuratively. This method resulted in an accuracy of 55.01% on the testing set. 4 Conclusion In this paper we have presented state of the art word-phrase semantic relatedness approache</context>
</contexts>
<marker>Witten, Frank, Trigg, Hall, Holmes, Cunningham, 1999</marker>
<rawString>Ian H Witten, Eibe Frank, Leonard E Trigg, Mark A Hall, Geoffrey Holmes, and Sally Jo Cunningham. 1999. Weka: Practical machine learning tools and techniques with java implementations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhibiao Wu</author>
<author>Martha Palmer</author>
</authors>
<title>Verbs semantics and lexical selection.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd annual meeting on Association for Computational Linguistics,</booktitle>
<pages>133--138</pages>
<location>New Mexico,</location>
<contexts>
<context position="2776" citStr="Wu and Palmer, 1994" startWordPosition="418" endWordPosition="421">words and compositional phrases. 2.1 Semantic Network Model Knowledge-based approaches to semantic relatedness use the features of the knowledge base to measure the relatedness. One of most frequently used semantic network is the Princeton’s WordNet (Fellbaum, 1998) which groups words into synonyms sets (called synsets) and includes 26 semantic relations between those synsets, including: hypernymy, hyponymy, meronymy, entailment ... To measure relatedness, most of those approaches rely on the structure of the semantic network, such as the semantic link path, depth (Leacock and Chodorow, 1998; Wu and Palmer, 1994), direction (Hirst and St-Onge, 1998), or type (Tsatsaronis et al., 2010). Our phrasal semantic relatedness approach is inspired from those methods. However, our approach is based on the idea that the combination of the least costly types of relations that relate one concept to a set of concepts are a suitable indicator of their semantic relatedness. The type of relations considered includes not only the hy108 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 108–113, Atlanta, Georgia, Ju</context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Zhibiao Wu and Martha Palmer. 1994. Verbs semantics and lexical selection. In Proceedings of the 32nd annual meeting on Association for Computational Linguistics, pages 133–138, New Mexico, June.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>