<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.015293">
<title confidence="0.996227">
IS-G: The Comparison of Different Learning Techniques for the Selection of
the Main Subject References
</title>
<author confidence="0.996114">
Bernd Bohnet
</author>
<affiliation confidence="0.8498555">
University of Stuttgart
Visualization and Interactive Systems Group
</affiliation>
<address confidence="0.862381">
Universit¨atstr. 58, 70569 Stuttgart, Germany
</address>
<email confidence="0.995546">
bohnet@informatik.uni-stuttgart.de
</email>
<sectionHeader confidence="0.99555" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997395">
The GREC task of the Referring Expression
Generation Challenge 2008 is to select appro-
priate references to the main subject in given
texts. This means to select the correct type of
the referring expressions such as name, pro-
noun, common, or elision (empty). We employ
for the selection different learning techniques
with the aim to find the most appropriate one
for the task and the used attributes. As train-
ing data, we use the syntactic category of the
searched referring expressions and addition-
ally gathered data from the text itself.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999975647058824">
The training data of the GREC task consists of
Wikipedia articles from five domains. The arti-
cles are about People, Cities, Countries, Rivers, and
Mountains. An XML annotation replaces the orig-
inal referring expressions in the articles with a set
of alternative experssions which could be inserted in
the empty space in order to complete the text. The
training data additionally consists of the original re-
ferring expressions. From the annotations, we use
for the training the syntactic category (SYNCAT) for
the searched referring expression.
The annotation allows us easily to access addi-
tional data. One of the values that we calculate is
the distance (DIST) to the last referring expression.
The idea behind this value is that the references be-
comes with increasing distance unclear because of
other content in the text and therefore, to provide a
short form such as a pronoun is not enough or would
be even misleading. Of cause there might be other
reasons to use the name too. The next information,
we use is the count (POS) of the referring expres-
sion in the text. Because we expect that the first re-
ferring expression is in most cases the name of the
main subject and at the end of a text, it might be
used less frequent. Then we use the type of the last
(LAST) used referring expression in the text. This
might be a good candidate because people want to
avoid consecutive repetitions of the same word. The
disadvantage of this attribute is that it is based itself
on the classification of its predecessor and therefore,
on insecure information. Finally, we use a second
distance measure which provides the information if
the last referring expression was in the same sen-
tence (SENT).
</bodyText>
<sectionHeader confidence="0.548187" genericHeader="method">
2 Comparison of Learning Techniques
</sectionHeader>
<bodyText confidence="0.999441941176471">
We tried several machine learning techniques and
selected among them the three bests that are
Bayesian Networks with the attribute selection
method K2 (Cooper and Herskovits, 1992), decision
trees C4.5 (Quinlan, 1993), and Multi Layer Percep-
trons with a sigmoid function (Minsky and Papert,
1969). For the comparison with the three machine
learning techniques, we provide in Table 1 a base
line where we chose the type with the most occur-
rences in the training data of the domain.
Table 2 shows the results for the Bayesian Net-
work. The results are significant better then the base
line results. Table 3 shows the results of C4.5. The
results are close to the results of the Bayesian Net-
work. An advantage of decision trees is that they
provide some explanation. A part of the decision
tree is shown in Figure 1. The part selects a refer-
</bodyText>
<page confidence="0.97955">
192
</page>
<table confidence="0.999905857142857">
Set Most frequent type Accuracy
Cities name 0.47
Countries name 0.45
Mountains name 0.39
People pronoun 0.61
Rivers name 0.43
Total – 0.47
</table>
<tableCaption confidence="0.991391">
Table 1: Base Line
</tableCaption>
<table confidence="0.992024">
Set Cities Cou. Mount. Peo. Ri. Total
Acc 0.48 0.62 0.63 0.673 0.7 0.62
</table>
<tableCaption confidence="0.984622">
Table 2: Results for Bayesian Networks (K2)
</tableCaption>
<bodyText confidence="0.922164">
ring expression in the case that the last expression
was already within the same sentences.
</bodyText>
<table confidence="0.7376145">
Set Cities Cou. Mount. Peo. Ri. Total
Acc 0.545 0.63 0.641 0.673 0.7 0.638
</table>
<tableCaption confidence="0.994016">
Table 3: Results for C4.5
</tableCaption>
<bodyText confidence="0.999938333333333">
The uppercase words are the attributes followed
by the value for the branch. If the value of a distinct
instance is in the range of the value then the algo-
rithms chooses the branch until it reaches a leaf. The
leafs are labelled with the result of the decision and
with information of an evaluation that provides the
information how many training instances (cases) are
classified correct / wrong. Interesting for the case
are the following observations:
</bodyText>
<equation confidence="0.8394864375">
SENT = true
— SYNCAT = subj-det
— — DIST &lt;= 158: pronoun (103.0/8.0)
— — DIST &gt; 158: common (4.0/1.0)
— SYNCAT = np-subj
— — DIST &lt;= 33: pronoun (32.0/15.0)
— — DIST &gt; 33
— — —LAST = common
— — — —DIST &lt;= 123: empty (25.0/5.0)
— — — —DIST &gt; 123: common (2.0/1.0)
— — — LAST = pronoun: empty (69.0/22.0)
— — — LAST = name
— — — —POS &lt;= 2: empty (17.0/2.0)
— — — —POS &gt; 2
POS &lt;= 15
DIST &lt;= 79
DIST &lt;= 39: pronoun (3.0)
DIST &gt; 39: empty (46.0/15.0)
DIST &gt; 79
POS &lt;= 5: pronoun (3.0)
POS &gt; 5
POS &lt;= 11
DIST &lt;= 113: common (4.0/1.0)
DIST &gt; 113: name (2.0/1.0)
POS &gt; 11: pronoun (2.0)
POS &gt; 15: common (2.0)
— — —LAST = empty: pronoun (5.0/1.0)
— SYNCAT = np-obj
— — DIST &lt;= 109
— — —POS &lt;= 9: pronoun (23.0/12.0)
— — —POS &gt; 9: common (10.0/4.0)
— — DIST &gt; 109: common (17.0/3.0)
</equation>
<figure confidence="0.526719">
SENT = false
...
</figure>
<figureCaption confidence="0.999605">
Figure 1: Part of the decision tree
</figureCaption>
<listItem confidence="0.865793666666667">
• The text writers chose nearly always (&gt;99%)
an other referring expression than the name.
• They select more frequent pronouns and an eli-
sions (empty) compared to common names.
• The writers select common names in case of a
high distance to the last referring expression.
</listItem>
<bodyText confidence="0.999091333333333">
Table 4 shows the results for the Multi Layer
Perceptron, which performed best compared to the
other learning techniques.
</bodyText>
<sectionHeader confidence="0.999519" genericHeader="conclusions">
3 Conclusion
</sectionHeader>
<bodyText confidence="0.9999452">
We calculated the information gain of each attribute
to get an overview of the relevance of the attributes.
The most releveant attribute is DIST (0.32) followed
by POS (0.24), LAST (0.239), SENT (0.227), and
SYNCAT (0.19).
The results of all three learning techniques are
significant better than the base line which has in av-
erage an accuracy of 0.47. The multi layer percep-
tron provides the best results with an average accu-
racy of 0.66.
</bodyText>
<sectionHeader confidence="0.999278" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.930872875">
G. F. Cooper and E. Herskovits. 1992. A Bayesian
Method for the Induction of Probabilistic Networks
from Data. In Machine Learning 9.
M. Minsky and S. Papert. 1969. Perceptrons. MIT Press.
J. R. Quinlan. 1993. C4.5 Programs for Machine Learn-
ing. Morgan Kaufmann, California.
Set Cities Cou. Mount. Peo. Ri. Total
Acc 0.545 0.64 0.65 0.668 0.8 0.66
</reference>
<tableCaption confidence="0.889481">
Table 4: IS-G: Multi Layer Perceptron
</tableCaption>
<page confidence="0.998701">
193
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.397017">
<title confidence="0.9200825">IS-G: The Comparison of Different Learning Techniques for the Selection of the Main Subject References</title>
<author confidence="0.937679">Bernd</author>
<affiliation confidence="0.97552">University of</affiliation>
<title confidence="0.810729">Visualization and Interactive Systems</title>
<address confidence="0.678783">Universit¨atstr. 58, 70569 Stuttgart,</address>
<email confidence="0.99849">bohnet@informatik.uni-stuttgart.de</email>
<abstract confidence="0.995730384615385">The GREC task of the Referring Expression Generation Challenge 2008 is to select appropriate references to the main subject in given texts. This means to select the correct type of referring expressions such as proor We employ for the selection different learning techniques with the aim to find the most appropriate one for the task and the used attributes. As training data, we use the syntactic category of the searched referring expressions and additionally gathered data from the text itself.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G F Cooper</author>
<author>E Herskovits</author>
</authors>
<title>A Bayesian Method for the Induction of Probabilistic Networks from Data.</title>
<date>1992</date>
<booktitle>In Machine Learning 9.</booktitle>
<contexts>
<context position="2737" citStr="Cooper and Herskovits, 1992" startWordPosition="442" endWordPosition="445">ing expression in the text. This might be a good candidate because people want to avoid consecutive repetitions of the same word. The disadvantage of this attribute is that it is based itself on the classification of its predecessor and therefore, on insecure information. Finally, we use a second distance measure which provides the information if the last referring expression was in the same sentence (SENT). 2 Comparison of Learning Techniques We tried several machine learning techniques and selected among them the three bests that are Bayesian Networks with the attribute selection method K2 (Cooper and Herskovits, 1992), decision trees C4.5 (Quinlan, 1993), and Multi Layer Perceptrons with a sigmoid function (Minsky and Papert, 1969). For the comparison with the three machine learning techniques, we provide in Table 1 a base line where we chose the type with the most occurrences in the training data of the domain. Table 2 shows the results for the Bayesian Network. The results are significant better then the base line results. Table 3 shows the results of C4.5. The results are close to the results of the Bayesian Network. An advantage of decision trees is that they provide some explanation. A part of the dec</context>
</contexts>
<marker>Cooper, Herskovits, 1992</marker>
<rawString>G. F. Cooper and E. Herskovits. 1992. A Bayesian Method for the Induction of Probabilistic Networks from Data. In Machine Learning 9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Minsky</author>
<author>S Papert</author>
</authors>
<date>1969</date>
<booktitle>C4.5 Programs for Machine Learning.</booktitle>
<publisher>Perceptrons. MIT</publisher>
<location>California.</location>
<contexts>
<context position="2853" citStr="Minsky and Papert, 1969" startWordPosition="460" endWordPosition="463">ame word. The disadvantage of this attribute is that it is based itself on the classification of its predecessor and therefore, on insecure information. Finally, we use a second distance measure which provides the information if the last referring expression was in the same sentence (SENT). 2 Comparison of Learning Techniques We tried several machine learning techniques and selected among them the three bests that are Bayesian Networks with the attribute selection method K2 (Cooper and Herskovits, 1992), decision trees C4.5 (Quinlan, 1993), and Multi Layer Perceptrons with a sigmoid function (Minsky and Papert, 1969). For the comparison with the three machine learning techniques, we provide in Table 1 a base line where we chose the type with the most occurrences in the training data of the domain. Table 2 shows the results for the Bayesian Network. The results are significant better then the base line results. Table 3 shows the results of C4.5. The results are close to the results of the Bayesian Network. An advantage of decision trees is that they provide some explanation. A part of the decision tree is shown in Figure 1. The part selects a refer192 Set Most frequent type Accuracy Cities name 0.47 Countr</context>
</contexts>
<marker>Minsky, Papert, 1969</marker>
<rawString>M. Minsky and S. Papert. 1969. Perceptrons. MIT Press. J. R. Quinlan. 1993. C4.5 Programs for Machine Learning. Morgan Kaufmann, California.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>