<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000359">
<bodyText confidence="0.7633855">
Word lookup on the basis of associations:
from an idea to a roadmap
</bodyText>
<note confidence="0.775084">
Michael ZOCK
LIMSI-CNRS
B.P. 133, 91403 Orsay,
France
</note>
<email confidence="0.985944">
zock@limsi.fr
</email>
<author confidence="0.9701">
Slaven BILAC
</author>
<affiliation confidence="0.980883">
Tokyo Institute of Technology
</affiliation>
<address confidence="0.4740535">
Ookayama 2-12-1, Meguro 152-8552,
Japan
</address>
<email confidence="0.994822">
sbilac@cl.cs.titech.ac.jp
</email>
<sectionHeader confidence="0.979776" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999948265306123">
Word access is an obligatory step in language
production. In order to achieve his communica-
tive goal, a speaker/writer needs not only to
have something to say, he must also find the
corresponding word(s). Yet, knowing a word,
i.e. having it stored in a data-base or memory
(human mind or electronic device) does not im-
ply that one is able to access it in time. This
is a clearly a case where computers (electronic
dictionaries) can be of great help.
In this paper we present our ideas of how
an enhanced electronic dictionary can help peo-
ple to find the word they are looking for. The
yet-to-be-built resource is based on the age-old
notion of association: every idea, concept or
word is connected. In other words, we assume
that people have a highly connected conceptual-
lexical network in their mind. Finding a word
amounts thus to entering the network at any
point by giving the word or concept coming to
their mind (source word) and then following the
links (associations) leading to the word they are
looking for(target word).
Obviously, in order to allow for this kind
of access, the resource has to be built accord-
ingly. This requires at least two things: (a) in-
dexing words by the associations they evoke,
(b) identification and labeling of the most fre-
quent/useful associations. This is precisely our
goal. Actually, we propose to build an associa-
tive network by enriching an existing electronic
dictionary (essentially) with (syntagmatic) as-
sociations coming from a corpus, representing
the average citizen’s shared, basic knowledge of
the world (encyclopedia). Such an enhanced
electronic database resembles in many respects
our mental dictionary. Combining the power of
computers and the flexibility of the human mind
(omnidirectional navigation and quick jumps),
it emulates to some extent the latter in its ca-
pacity to navigate quickly and efficiently in a
large data base.
While the notions of association and spread-
ing activation are fairly old, their use to support
word access via computer is new. The resource
still needs to be built, and this is not a trivial
task. We discuss here some of the strategies and
problems involved in accomplishing it with the
help of people and computers (automation).
</bodyText>
<sectionHeader confidence="0.995511" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.994352">
We all experience now and then the problem
of being unable to find the word expressing the
idea we have in our mind. It we care and have
time we may reach for a dictionary. Yet, this
kind of resource may be of little help, if it ex-
pects from us precisely what we are looking for:
a perfectly spelled word, expressing the idea we
try to convey. While perfect input may be rea-
sonable in the case of analysis (comprehension),
it certainly is not in the case of synthesis (gener-
ation) where the starting point is conceptual in
nature: a message, the (partial) definition of a
word, a concept or a word related to the target
word. The language producer needs a dictio-
nary allowing for reverse access. A thesaurus
does that, but only in a very limited way: the
entry points are basically topical.
People use various methods to initiate search
in their mind : words, concepts, partial descrip-
tions, etc. If we want to mimic these functional-
ities by a computer, we must build the resource
accordingly. Let us assume that the text pro-
ducer is looking for a word that he cannot ac-
cess. Instead he comes up with another word
(or concept)1 somehow related to the former.
He may not know precisely how the two relate,
but he knows that they are related. He may also
know to some extent how close their relation-
ship is, whether a given link is relevant or not,
that is, whether it can lead directly (synonym,
&apos;We will comment below on the difference between
concepts and words.
antonym, hyperonym) or indirectly to the tar-
get word. Since the relationship between the
source- and the target word is often indirect,
several lookups may be necessary: each one of
them having the potential to contain either the
target word (direct lookup), or a word leading
towards it (indirect lookup).
2 How reasonable is it to expect
perfect input?
The expectation of perfect input is unrealistic
even in analysis,2 but clearly more so in gener-
ation. The user may well be unable to provide
the required information: be it because he can-
not access in time the word he is looking for,
even though he knows it,3 or because he does
not know the word yet expressing the idea he
wants to convey. This latter case typically oc-
curs when using a foreign language or when try-
ing to use a very technical term. Yet, not being
able to find a word, does not imply that one
does not know anything concerning the word.
Actually, quite often the contrary is the case.
Suppose, you were looking for a word ex-
pressing the following ideas: domesticated ani-
mal, producing milk suitable for making cheese.
Suppose further that you knew that the target
word was neither cow nor sheep. While none
of this information is sufficient to guarantee the
access of the intended word goat, the informa-
tion at hand (part of the definition) could cer-
tainly be used. For some concrete proposals go-
ing in this direction, see (Bilac et al., 2004), or
the OneLook reverse dictionary.4 Besides the
definition information, people often have other
kind of knowledge concerning the target word.
In particular, they know how the latter relates
to other words. For example, they know that
goats and sheep are somehow connected, that
both of them are animals, that sheep are appre-
ciated for their wool and meet, that sheep tend
to follow each other blindly, while goats man-
age to survive, while hardly eating anything,
etc. In sum, people have in their mind lexi-
cal networks: all words, concepts or ideas they
express are highly interconnected. As a result,
any one of the words or concepts has the po-
tential to evoke each other. The likelihood for
</bodyText>
<footnote confidence="0.992709285714286">
2Obviously, looking for ”pseudonym” under the letter
”S” in a dictionary won’t be of great help.
3Temporary amnesia, known as the TOT, or tip-of-
the-tongue problem (Brown and McNeill, 1996; Zock and
Fournier, 2001; Zock, 2002)
4http://www.onelook.com/reverse-dictionary.
shtml
</footnote>
<bodyText confidence="0.99965075">
this to happen depends, among other things, on
such factors as frequency (associative strength),
saliency and distance (direct vs. indirect ac-
cess). As one can see, associations are a very
general and powerful mechanism. No matter
what we hear, read or say, any idea is likely to
remind us of something else.5 This being so, we
should make use of it.6
</bodyText>
<listItem confidence="0.5945795">
3 Search based on the relations
between concepts and words
</listItem>
<bodyText confidence="0.990487843137255">
If one agrees with what we have just said, one
could view the mental dictionary as a huge se-
mantic network composed of nodes (words and
concepts) and links (associations), with either
being able to activate the other.7 Finding a
5The idea according to which the mental dictionary
(or encyclopedia) is basically an associative network,
composed of nodes (words or concepts) and links (as-
sociations) is not new, neither is the idea of spreading
activation. Actually the very notion of association goes
back at least to Aristotle (350BC), but it is also inher-
ent in work done by philosophers (Locke, Hume), phys-
iologists (James &amp; Stuart Mills), psychologists (Galton,
1880; Freud, 1901; Jung and Riklin, 1906) and psycholin-
guists (Deese, 1965; Jenkins, 1970; Schvaneveldt, 1989).
For surveys in psycholinguistics see (H¨ormann, 1972), or
more recent work (Spitzer, 1999). The notion of associa-
tion is also implicit in work on semantic networks (Quil-
lian, 1968), hypertext (Bush, 1945), the web (Nelson,
1967), connectionism (Dell et al., 1999) and, of course,
in WordNet (Miller et al., 1993; Fellbaum, 1998).
6In the preceding sections we used several times the
terms words and concepts interchangeably, as if they were
the same. Of course, they are very different. Yet, not
knowing what a concept looks like (a single node, or
every node, i.e. headword of the word’s definition?), we
think it is safer to assume that the user can communicate
with the computer (dictionary) only via words. Hence,
concepts are represented by words, yet, since the two
are connected, one can be accessed via the other, which
addresses the interface problem with the computer. An-
other point worth mentionning is the fact that associa-
tions may depend on the nature of the arguments (words
vs. concepts). While in theory anything can be associ-
ated with anything (words with words, words with con-
cepts, concepts with concepts, etc.), in practice words
tend to trigger a different set of associations than con-
cepts. Also, the connectivity between words and con-
cepts explains to some extent the power and the flexi-
bility of the human mind. Words are shorthand labels
for concepts, and given the fact that the two are linked,
one can make big leaps in no time and easily move from
one plane (let’s say the conceptual level) to the other
(the linguistic counterpart). Words can be reached via
concepts, but the latter can also serve as starting point
to find a word. Compared to the links between concepts
which are a superhighway, associations between words
are more like countryroads.
7Actually, one could question the very notion of men-
tal dictionary which is convenient, but misleading in as
it supposes a dedicated part for this task in our brain. A
</bodyText>
<figureCaption confidence="0.997526">
Figure 1: Search based on propagation in a network (internal representation)
</figureCaption>
<bodyText confidence="0.971685065217392">
word amounts thus to entering the network and
following the links leading from the source node
(the first word that comes to your mind) to the
target word (the one you are looking for). Sup-
pose you wanted to find the word “nurse” (target
word), yet the only token coming to your mind
were “hospital”. In this case the system would
generate internally a graph with the source word
at the center and all the associated words at
the periphery. Put differently, the system would
build internally a semantic network with “hos-
pital” in the center and all its associated words
as satellites (figure 1).8
Obviously, the greater the number of associ-
ations, the more complex the graph. Given the
diversity of situations in which a given object
may occur we are likely to build many associa-
tions. In other words, lexical graphs tend to be-
multiply indexed mental encyclopedia, composed of poly-
morph information (concepts, words, meta-linguistic in-
formation) seems much more plausible to us.
8AKO: a kind of; ISA: subtype; TIORA: typically
involved object, relation or actor.
come complex, too complex to be a good repre-
sentation to support navigation. Readability is
hampered by at least two factors: high connec-
tivity (the great number of links or associations
emanating from each word), and distribution:
conceptually related nodes, that is, nodes acti-
vated by the same kind of assocation are scat-
tered around, that is, they do not necessarily
occur next to each other, which is quite confus-
ing for the user. In order to solve this problem
we suggest to display by category (chunks) all
the words linked by the same kind of association
to the source word (see figure 2). Hence, rather
than displaying all the connected words as a flat
list, we suggest to present them in chunks to al-
low for categorial search. Having chosen a cat-
egory, the user will be presented a list of words
or categories from which he must choose. If the
target word is in the category chosen by the user
(suppose he looked for a hyperonyme, hence he
checked the ISA-bag), search stops, otherwise it
goes on. The user could choose either another
category (eg. AKO or TIORA), or a word in
</bodyText>
<figureCaption confidence="0.972673">
Figure 2: Proposed candidates, grouped accord-
ing to the nature of the link
</figureCaption>
<bodyText confidence="0.994671">
the current list, which would then become the
new starting point.
</bodyText>
<sectionHeader confidence="0.940461" genericHeader="method">
4 A resource still to be built
</sectionHeader>
<bodyText confidence="0.999993222222222">
The fact that the links are labeled has some very
important consequences. (a) While maintaining
the power of a highly connected graph (possible
cyclic navigation), it has at the interface level
the simplicity of a tree: each node points only
to data of the same type, i.e. same kind of asso-
ciation. (b) Words being presented in clusters,
navigation can be accomplished by clicking on
the appropriate category. The assumption be-
ing that the user generally knows to which cate-
gory the target word belongs (or at least, he can
recognize within which of the listed categories it
falls), and that categorical search is in principle
faster than search in a huge list of unordered
(or, alphabetically ordered) words.
Word access, as described here, amounts to
navigating in a huge associative network. Of
course, such a network has to be built. The
question is how. Our proposal is to build
it automatically by parsing an existing corpus
containing sufficient amount of information on
world knowledge (for example, an encyclope-
dia). This would yield a set of associations
(see below),9 which still need to be labeled. A
rich ontology should be helpful in determining
the adequate label for many, if not most of the
links. Unlike private information,10 which by
</bodyText>
<footnote confidence="0.4874216">
9The assumption being that every word co-occurring
with another word in the same sentence is a candidate of
an association. The more frequently two words co-occur
in a given corpus, the greater their associative strength.
10For example, the word elephant may remind you of a
</footnote>
<bodyText confidence="0.999907463414634">
definition cannot and should not be put into a
public dictionary,11 encyclopedic knowledge can
be added in terms of associations, as this infor-
mation expresses commonly shared knowledge,
that is, the kind of associations most people
have when encountering a given word. Take for
example the word elephant. An electronic dic-
tionary like Word Net associates the following
gloss with the headword: large, gray, four-legged
mammal, while Webster gives the following in-
formation:
A mammal of the order Proboscidia,
of which two living species, Elephas
Indicus and E. Africanus, and several
fossil species, are known. They have
a proboscis or trunk, and two large
ivory tusks proceeding from the ex-
tremity of the upper jaw, and curving
upwards. The molar teeth are large
and have transverse folds. Elephants
are the largest land animals now ex-
isting.
While this latter entry is already quite rich
(trunk, ivory tusk, size), an encyclopedia con-
tains even more information.12 If all this in-
formation were added to an electronic resource,
it would enable us to access the same word
(e.g. elephant) via many more associations than
ever before. By looking at the definition here
above, one will notice that many associations
are quite straightforward (color, size, origin,
etc.), and since most of them appear frequently
in a pattern-like manner it should be possible
to extract them automatically (see footnote 18
below). If one agrees with these views, the re-
maining question is how to extract this encyclo-
pedic information and to add it to an existing
electronic resource. Below we will outline some
methods for extracting associated words and
discuss the feasibility of using current method-
ology to achieve this goal.
</bodyText>
<sectionHeader confidence="0.9020415" genericHeader="method">
5 Automatic extraction of word
associations
</sectionHeader>
<bodyText confidence="0.9998526">
Above we outlined the need for obtaining asso-
ciations between words and using them to im-
prove dictionary accessibility. While the associ-
ations can be obtained through association ex-
periments with human subjects, this strategy is
</bodyText>
<footnote confidence="0.9822388">
specific animal, trip or location (zoo, country in Africa).
11This does not (and should not) preclude the possi-
bility to add it to one’s personal dictionary.
12You may consider taking a look at Wikipedia (http:
//en.wikipedia.org/wiki/) which is free.
</footnote>
<bodyText confidence="0.999741010204082">
not very satisfying due to the high cost of run-
ning the experiments (time and money), and
due to its static nature. Indeed, given the costs,
it is impossible to repeat these experiments to
take into account the evolution of a society.
Hence, the goal is to automatically extract asso-
ciations from large corpora. This problem was
addressed by a large number of researchers, but
in most cases it was reduced to extraction of col-
locations which are a proper subset of the set of
associated words. While hard to define, colloca-
tions appear often enough in corpora to be ex-
tractable by statistical and information-theory
based methods.
There are several basic methods for evalu-
ating associations between words: based on
frequency counts (Choueka, 1988; Wettler and
Rapp, 1993), information theoretic (Church
and Hanks, 1990) and statistical significance
(Smadja, 1993). The statistical significance
often evaluate whether two words are inde-
pendant using hypothesis tests such as t-score
(Church et al., 1991), the X2, the log-likelihood
(Dunning, 1993) and Fisher’s exact test (Peder-
sen, 1996). Extracted sets for associated words
are further pruned using numerical methods, or
linguistic knowledge to obtain a subset of collo-
cations.
The various extraction measures have been
discussed in great detail in the literature (Man-
ning and Sch¨utze, 1999; McKeown and Radev,
2000), their performance has been compared
(Dunning, 1993; Pedersen, 1996; Evert and
Krenn, 2001), and the methods have been com-
bined to improve overall performance (Inkpen
and Hirst, 2002). Most of these methods were
originally applied in large text corpora, but
more recently the web has been used as a cor-
pus (Pearce, 2001; Inkpen and Hirst, 2002).
Collocation extraction methods have been used
not only for English, but for many other lan-
guages: French (Ferret, 2002), German (Ev-
ert and Krenn, 2001) and Japanese (Nagao and
Mori, 1994), to cite but those.
The most obvious question in this context
is to clarify to what extent available colloca-
tion extraction techniques fulfill our needs of ex-
tracting and labeling word associations. Since
collocations are a subset of association, it is pos-
sible to apply collocation extraction techniques
to obtain related words, ordered in terms of the
relative strength of association.
The result of this kind of numerical extraction
would be a large set of numerically weighted
word pairs. The problem with this approach is
that the links are only labeled in terms of their
relative associative strength, but not categori-
cally, which makes it impossible to group and
present them in a meaningful way for the dic-
tionary user. Clusters based only on the notion
of association strength are inadequate for the
kind of navigation described here above. Hence
another step is necessary: qualification of the
links according to their types. Only once this
is done, a human being could use it to navi-
gate through a large conceptual-lexical network
(the dictionary) as described above. Unfortu-
nately, research on automatic link identification
has been rather sparse. Most attempts have
been devoted to the extraction of certain types
of links (usually syntactic type (Lin, 1998) or
on extensions of WordNet with topical informa-
tion contained in a thesaurus (Stevenson, 2002)
or on the WWW (Agirre et al., 2000). Addi-
tional methods need to be considered in order
to reveal (automatically) the kind of associa-
tions holding between words and/or concepts.
Earlier in this paper we have suggested the use
of an encyclopedia as a source of general world
knowledge. It should be noted, though, that
there are important differences between large
corpora and encyclopedias. Large corpora usu-
ally contain a lot of repetitive texts on a lim-
ited number of topics (e.g. newspaper articles)
which makes them very suitable for statistical
methods. On the other hand, while being max-
imally informative and comprehensive, encyclo-
pedias are written in a highly controlled lan-
guage, and their content is continually updated
and re-edited, with the goal to avoid unneces-
sary repetition. While most of the information
contained in an entry is important, there is a
lack of redundancy. Hence, measures capable of
handling word pairs with low appearance counts
(e.g. log-likelihood or Fisher’s exact test) should
be favored. Also, rather than looking at indi-
vidual words, one might want to look at word
patterns instead.
</bodyText>
<sectionHeader confidence="0.985787" genericHeader="conclusions">
6 Discussion and Conclusion
</sectionHeader>
<bodyText confidence="0.99998038">
We have raised and partially answered the ques-
tion of how a dictionary should be indexed in
order to support word access. We were partic-
ularly concerned with the language producer,
as his needs (and knowledge at the onset) are
quite different from the ones of the language re-
ceiver (listener/reader). It seems that, in order
to achieve our goal, we need to do two things:
add to an existing electronic dictionary informa-
tion that people tend to associate with a word,
that is, build and enrich a semantic network,
and provide a tool to navigate in it. To this
end we have suggested to label the links, as this
would reduce the graph complexity and allow
for type-based navigation. Actually our basic
proposal is to extend a resource like WordNet
by adding certain links, in particular on the hor-
izontal axis (syntagmatic relations). These links
are associations, and their role consists in help-
ing the encoder to find ideas (concepts/words)
related to a given stimulus (brainstorming), or
to find the word he is thinking of (word access).
One problem that we are confronted with is to
identify possible associations. Ideally we would
need a complete list, but unfortunately, this
does not exist. Yet, there is a lot of highly
relevant information out there. For exam-
ple, Mel’cuk’s lexical functions (Mel’cuk, 1992),
Fillmore’s FRAMENET13, work on ontolo-
gies (CYC), thesaurus (Roget), WordNets (the
original version from Princeton, divers Euro-
WordNets, BalkaNet), HowNet14, the work
done by MICRA, the FACTOTUM project15
or the Wordsmyth dictionary/thesaurus combi-
nation16. Of course, one would need to make
choices here and probably add links. Another
problem is to identify useful associations. Not
every possible association is necessarily plausi-
ble. Hence, the idea to take as corpus some-
thing that expresses shared knowledge, for ex-
ample, an encyclopedia. The associations it
contains can be considered as being plausible.
We could also collect data by watching peo-
ple using a dictionary and identify search pat-
terns.17 Next, we could run psycholinguistic ex-
periments.18 While the typical paradigm has
been to ask people to produce a response (red)
to some stimulus (rose), we could ask them to
identify or label the links between words (e.g.
apple-fruit, lemon-yellow, etc.). The ease of la-
</bodyText>
<footnote confidence="0.837655">
13http://www.icsi.berkeley.edu/~framenet/
14http://www.keenage.com/html/e_index.html
15http://humanities.uchicago.edu/homes/MICRA/
16http://www.wordsmyth.com/
17One such pattern could be: give me the word for a
bird with yellow feet and a long beak, that can swim.
Actually, word access problems frequently come under
the form of questions like: What is the word for X that
Y?, where X is usually a hypernym and Y a stereotypical,
possibly partial functional/relational/case description of
the target word.
18Actually, this has been done for decades, but with
a different goal in mind (Nelson, 1967), http://cyber.
acomp.usf.edu/FreeAssociation/.
</footnote>
<bodyText confidence="0.999914391304348">
beling will probably depend upon the origin of
the words (the person asked to label the link or
somebody else).
Another approach would be to extract col-
locations from a corpus and label them auto-
matically. There are tools for extracting co-
occurrences (see section 5.5), and ontologies
could be used to qualify some of the links be-
tween collocational elements. While this ap-
proach might work fine for couples like coffee-
strong, or wine-red (since an ontology would re-
veal that red is a kind of color, which is precisely
the link type: i.e. association), one may doubt
that it could reveal the nature of the link be-
tween smoke and fire. Yet, most humans would
immediately recognize this as a causal link. As
one can see, there are still quite a few serious
problems to be solved. Nevertheless, we do be-
lieve that these obstacles can be removed, and
that the approach presented here has the poten-
tial to improve word access, making the whole
process more powerful, natural and intuitive,
hence efficient.
</bodyText>
<sectionHeader confidence="0.984022" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.922451440944882">
E. Agirre, E. Hovy O. Ansa, and D. Mar-
tinez. 2000. Enriching very large ontologies
using the WWW. In Proc. of ECAI Ontology
Learning Workshop.
S. Bilac, W. Watanabe, T. Hashimoto, T. Toku-
naga, and H. Tanaka. 2004. Dictionary
search based on the target word description.
In Proc. of the Tenth Annual Meeting of The
Association for Natural Language Processing
(NLP2004), pages 556–559.
R. Brown and D. McNeill. 1996. The tip of
the tonuge phenomenon. Journal of Verbal
Learning and Verbal Behaviour, 5:325–337.
V. Bush. 1945. As we may think. The Atlantic
Monthly, 176:101–108.
Y. Choueka. 1988. Looking for needles in a
haystack. In Proc. of the RIAO Conference
on User-Oriented Context Based Text and
Image Handling, pages 609–623.
K. Church and P. Hanks. 1990. Word associa-
tion norms, mutual information and lexicog-
raphy. Computational Linguistics, 16:22–29.
K. Church, W. Gale, P. Hanks, and D. Hin-
dle. 1991. Using statistics in lexical analysis.
In U. Zernik, editor, Lexical Acquisition: Ex-
ploiting On-Line Resources to Build a Lexi-
con. Lawrance Erlbaum Associates.
J. Deese. 1965. The structure of associations in
language and thought. Johns Hopkins Press.
G. S. Dell, F. Chang, and Z. M. Griffin. 1999.
Connectionist models of language produc-
tion: Lexical access and grammatical encod-
ing. Cognitive Science, 23:517–542.
T. Dunning. 1993. Accurate methods for statis-
tics of surprise and coincidence. Computa-
tional Linguistics, 19:61–74.
S. Evert and B. Krenn. 2001. Methods for the
qualitative evaluation of lexical association
measures. In Proc. of the 39th Annual meet-
ing of Association of Computational Linguis-
tics (ACL 2001), pages 188–195.
C. Fellbaum. 1998. WordNet: An Electronic
Lexical Database and some of its Applica-
tions. MIT Press.
O. Ferret. 2002. Using collocations for topic
segmentation and link detection. In Proc. of
the 19th International Conference on Compu-
tational Linguistics, pages 261–266.
S. Freud. 1901. Psychopathology of everyday
life. Payot, 1997 edition.
F. Galton. 1880. Psychometric experiments.
Brain, 2:149–162.
H. H¨ormann. 1972. Introduction a` la psycholin-
quistique. Larousse.
D. Z. Inkpen and G. Hirst. 2002. Acquiring
collocations for lexical choice between near-
synonyms. In Proc. of Unsupervised Lexical
Acquisition Workshop of the ACL SIGLEX,
pages 67–76.
J. J. Jenkins. 1970. The 1952 minnesota
word association norms. In L. Postman and
G. Kepper, editors, Norms of Word Associa-
tion, pages 1–38. Academic Press.
C. G. Jung and F. Riklin. 1906. Experimentelle
unter-suchungen ¨uber assoziationene gesun-
der. In C. G. Jung, editor, Diagnostische As-
soziationsstudien, pages 7–145. Barth.
D. Lin. 1998. Extracting collocations from text
corpor. In First Workshop on Computational
Terminology.
C. D. Manning and H. Sch¨utze. 1999. Foun-
dations of Statistical Natural Language Pro-
cessing. The MIT Press, Cambridge, Mas-
sachusetts.
K. R. McKeown and Dragomir R. Radev.
2000. Collocations. In H. Moisl R. Dale
and H. Somers, editors, Handbook of Natural
Language Processing, pages 507–523. Marcel
Dekker.
I. Mel’cuk. 1992. Dictionnaire Explicatif
et Combinatoire du fran¸cais contemporain:
recherche lexicos´emantique III. Les presses de
l’universit´e de Montr´eal.
G. A. Miller, R. Beckwith, C. Fellbaum,
D. Gross, and Katherine Miller, editors.
1993. Introduction to WordNet: An On-line
Lexical Database. Cognitive Science Labora-
tory, Princeton University.
M. Nagao and S. Mori. 1994. A new method of
n-gram statistics for large number of n and
automatic extraction of words and phrases
from large text data of Japanese. In Proc. of
the 15th International Conference on Compu-
tational Linguistics (COLING 1994), pages
611–615.
T. Nelson. 1967. Xanadu projet hypertextuel.
D. Pearce. 2001. Synonymy in collocation
extraction. In Proc. of NAACL’01 Work-
shop on WordNet and Other Lexical Re-
sources: Applications, Extensions and Cus-
tomizations.
Ted Pedersen. 1996. Fishing for exactness. In
Proc. of the South-Central SAS Users Group
Conference, pages 188–195.
R. Quillian. 1968. Semantic memory. In M.
Minsky, editor, Semantic Information Pro-
cessing, pages 216–270.The MIT Press. Cam-
bridge, MA.
R. Schvaneveldt, editor. 1989. Pathfinder As-
sociative Networks: studies in knowledge or-
ganization. Norwood.
F. Smadja. 1993. Retrieving collocations from
text: Xtract. Computational Linguistics,
19:143–177.
M. Spitzer. 1999. The mind within the net:
models of learning, thinking and acting. MIT
Press.
M. Stevenson. 2002. Augmenting noun tax-
onomies by combining lexical similarity met-
rics. In Proc. of the 19th International Con-
ference on Computational Linguistics (COL-
ING 2002), pages 953–959.
M. Wettler and R. Rapp. 1993. Computation of
word associations based on the co-occurrences
of words in large corpora. In Proc. of the 1st
Workshop on Very Large Corpora: Academic
and Industrial Perspectives.
</reference>
<bodyText confidence="0.729635222222222">
M. Zock and J.-P. Fournier. 2001. How can
computers help the writer/speaker experienc-
ing the tip-of-the-tongue problem ? In Proc.
of RANLP, pages 300–302.
M. Zock. 2002. Sorry, what was your name
again, or how to overcome the tip-of-the
tongue problem with the help of a com-
puter? In Proc. of the SemaNet workshop
COLING2002.
</bodyText>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.116444">
<title confidence="0.8107225">Word lookup on the basis of from an idea to a roadmap</title>
<author confidence="0.800585">Michael</author>
<address confidence="0.522726">B.P. 133, 91403</address>
<email confidence="0.886811">zock@limsi.fr</email>
<author confidence="0.725958">Slaven</author>
<affiliation confidence="0.821875">Tokyo Institute of</affiliation>
<address confidence="0.334964">Ookayama 2-12-1, Meguro</address>
<email confidence="0.587563">sbilac@cl.cs.titech.ac.jp</email>
<abstract confidence="0.999429551020408">Word access is an obligatory step in language production. In order to achieve his communicative goal, a speaker/writer needs not only to have something to say, he must also find the corresponding word(s). Yet, knowing a word, i.e. having it stored in a data-base or memory (human mind or electronic device) does not imply that one is able to access it in time. This is a clearly a case where computers (electronic dictionaries) can be of great help. In this paper we present our ideas of how an enhanced electronic dictionary can help people to find the word they are looking for. The yet-to-be-built resource is based on the age-old notion of association: every idea, concept or word is connected. In other words, we assume that people have a highly connected conceptuallexical network in their mind. Finding a word amounts thus to entering the network at any point by giving the word or concept coming to mind and then following the links (associations) leading to the word they are Obviously, in order to allow for this kind of access, the resource has to be built accordingly. This requires at least two things: (a) indexing words by the associations they evoke, (b) identification and labeling of the most frequent/useful associations. This is precisely our goal. Actually, we propose to build an associative network by enriching an existing electronic dictionary (essentially) with (syntagmatic) associations coming from a corpus, representing the average citizen’s shared, basic knowledge of the world (encyclopedia). Such an enhanced electronic database resembles in many respects our mental dictionary. Combining the power of computers and the flexibility of the human mind (omnidirectional navigation and quick jumps), it emulates to some extent the latter in its capacity to navigate quickly and efficiently in a large data base. the notions of spreadactivation fairly old, their use to support word access via computer is new. The resource still needs to be built, and this is not a trivial task. We discuss here some of the strategies and problems involved in accomplishing it with the help of people and computers (automation).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>E Hovy O Ansa</author>
<author>D Martinez</author>
</authors>
<title>Enriching very large ontologies using the WWW.</title>
<date>2000</date>
<booktitle>In Proc. of ECAI Ontology Learning Workshop.</booktitle>
<contexts>
<context position="18946" citStr="Agirre et al., 2000" startWordPosition="3162" endWordPosition="3165">th are inadequate for the kind of navigation described here above. Hence another step is necessary: qualification of the links according to their types. Only once this is done, a human being could use it to navigate through a large conceptual-lexical network (the dictionary) as described above. Unfortunately, research on automatic link identification has been rather sparse. Most attempts have been devoted to the extraction of certain types of links (usually syntactic type (Lin, 1998) or on extensions of WordNet with topical information contained in a thesaurus (Stevenson, 2002) or on the WWW (Agirre et al., 2000). Additional methods need to be considered in order to reveal (automatically) the kind of associations holding between words and/or concepts. Earlier in this paper we have suggested the use of an encyclopedia as a source of general world knowledge. It should be noted, though, that there are important differences between large corpora and encyclopedias. Large corpora usually contain a lot of repetitive texts on a limited number of topics (e.g. newspaper articles) which makes them very suitable for statistical methods. On the other hand, while being maximally informative and comprehensive, encyc</context>
</contexts>
<marker>Agirre, Ansa, Martinez, 2000</marker>
<rawString>E. Agirre, E. Hovy O. Ansa, and D. Martinez. 2000. Enriching very large ontologies using the WWW. In Proc. of ECAI Ontology Learning Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bilac</author>
<author>W Watanabe</author>
<author>T Hashimoto</author>
<author>T Tokunaga</author>
<author>H Tanaka</author>
</authors>
<title>Dictionary search based on the target word description.</title>
<date>2004</date>
<booktitle>In Proc. of the Tenth Annual Meeting of The Association for Natural Language Processing (NLP2004),</booktitle>
<pages>556--559</pages>
<contexts>
<context position="5366" citStr="Bilac et al., 2004" startWordPosition="921" endWordPosition="924">al term. Yet, not being able to find a word, does not imply that one does not know anything concerning the word. Actually, quite often the contrary is the case. Suppose, you were looking for a word expressing the following ideas: domesticated animal, producing milk suitable for making cheese. Suppose further that you knew that the target word was neither cow nor sheep. While none of this information is sufficient to guarantee the access of the intended word goat, the information at hand (part of the definition) could certainly be used. For some concrete proposals going in this direction, see (Bilac et al., 2004), or the OneLook reverse dictionary.4 Besides the definition information, people often have other kind of knowledge concerning the target word. In particular, they know how the latter relates to other words. For example, they know that goats and sheep are somehow connected, that both of them are animals, that sheep are appreciated for their wool and meet, that sheep tend to follow each other blindly, while goats manage to survive, while hardly eating anything, etc. In sum, people have in their mind lexical networks: all words, concepts or ideas they express are highly interconnected. As a resu</context>
</contexts>
<marker>Bilac, Watanabe, Hashimoto, Tokunaga, Tanaka, 2004</marker>
<rawString>S. Bilac, W. Watanabe, T. Hashimoto, T. Tokunaga, and H. Tanaka. 2004. Dictionary search based on the target word description. In Proc. of the Tenth Annual Meeting of The Association for Natural Language Processing (NLP2004), pages 556–559.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Brown</author>
<author>D McNeill</author>
</authors>
<title>The tip of the tonuge phenomenon.</title>
<date>1996</date>
<journal>Journal of Verbal Learning and Verbal Behaviour,</journal>
<pages>5--325</pages>
<contexts>
<context position="6248" citStr="Brown and McNeill, 1996" startWordPosition="1069" endWordPosition="1072">ehow connected, that both of them are animals, that sheep are appreciated for their wool and meet, that sheep tend to follow each other blindly, while goats manage to survive, while hardly eating anything, etc. In sum, people have in their mind lexical networks: all words, concepts or ideas they express are highly interconnected. As a result, any one of the words or concepts has the potential to evoke each other. The likelihood for 2Obviously, looking for ”pseudonym” under the letter ”S” in a dictionary won’t be of great help. 3Temporary amnesia, known as the TOT, or tip-ofthe-tongue problem (Brown and McNeill, 1996; Zock and Fournier, 2001; Zock, 2002) 4http://www.onelook.com/reverse-dictionary. shtml this to happen depends, among other things, on such factors as frequency (associative strength), saliency and distance (direct vs. indirect access). As one can see, associations are a very general and powerful mechanism. No matter what we hear, read or say, any idea is likely to remind us of something else.5 This being so, we should make use of it.6 3 Search based on the relations between concepts and words If one agrees with what we have just said, one could view the mental dictionary as a huge semantic n</context>
</contexts>
<marker>Brown, McNeill, 1996</marker>
<rawString>R. Brown and D. McNeill. 1996. The tip of the tonuge phenomenon. Journal of Verbal Learning and Verbal Behaviour, 5:325–337.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Bush</author>
</authors>
<title>As we may think. The Atlantic Monthly,</title>
<date>1945</date>
<pages>176--101</pages>
<contexts>
<context position="7729" citStr="Bush, 1945" startWordPosition="1307" endWordPosition="1308">s) and links (associations) is not new, neither is the idea of spreading activation. Actually the very notion of association goes back at least to Aristotle (350BC), but it is also inherent in work done by philosophers (Locke, Hume), physiologists (James &amp; Stuart Mills), psychologists (Galton, 1880; Freud, 1901; Jung and Riklin, 1906) and psycholinguists (Deese, 1965; Jenkins, 1970; Schvaneveldt, 1989). For surveys in psycholinguistics see (H¨ormann, 1972), or more recent work (Spitzer, 1999). The notion of association is also implicit in work on semantic networks (Quillian, 1968), hypertext (Bush, 1945), the web (Nelson, 1967), connectionism (Dell et al., 1999) and, of course, in WordNet (Miller et al., 1993; Fellbaum, 1998). 6In the preceding sections we used several times the terms words and concepts interchangeably, as if they were the same. Of course, they are very different. Yet, not knowing what a concept looks like (a single node, or every node, i.e. headword of the word’s definition?), we think it is safer to assume that the user can communicate with the computer (dictionary) only via words. Hence, concepts are represented by words, yet, since the two are connected, one can be access</context>
</contexts>
<marker>Bush, 1945</marker>
<rawString>V. Bush. 1945. As we may think. The Atlantic Monthly, 176:101–108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Choueka</author>
</authors>
<title>Looking for needles in a haystack.</title>
<date>1988</date>
<booktitle>In Proc. of the RIAO Conference on User-Oriented Context Based Text and Image Handling,</booktitle>
<pages>609--623</pages>
<contexts>
<context position="16385" citStr="Choueka, 1988" startWordPosition="2756" endWordPosition="2757"> costs, it is impossible to repeat these experiments to take into account the evolution of a society. Hence, the goal is to automatically extract associations from large corpora. This problem was addressed by a large number of researchers, but in most cases it was reduced to extraction of collocations which are a proper subset of the set of associated words. While hard to define, collocations appear often enough in corpora to be extractable by statistical and information-theory based methods. There are several basic methods for evaluating associations between words: based on frequency counts (Choueka, 1988; Wettler and Rapp, 1993), information theoretic (Church and Hanks, 1990) and statistical significance (Smadja, 1993). The statistical significance often evaluate whether two words are independant using hypothesis tests such as t-score (Church et al., 1991), the X2, the log-likelihood (Dunning, 1993) and Fisher’s exact test (Pedersen, 1996). Extracted sets for associated words are further pruned using numerical methods, or linguistic knowledge to obtain a subset of collocations. The various extraction measures have been discussed in great detail in the literature (Manning and Sch¨utze, 1999; M</context>
</contexts>
<marker>Choueka, 1988</marker>
<rawString>Y. Choueka. 1988. Looking for needles in a haystack. In Proc. of the RIAO Conference on User-Oriented Context Based Text and Image Handling, pages 609–623.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
<author>P Hanks</author>
</authors>
<title>Word association norms, mutual information and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<pages>16--22</pages>
<contexts>
<context position="16458" citStr="Church and Hanks, 1990" startWordPosition="2764" endWordPosition="2767">to account the evolution of a society. Hence, the goal is to automatically extract associations from large corpora. This problem was addressed by a large number of researchers, but in most cases it was reduced to extraction of collocations which are a proper subset of the set of associated words. While hard to define, collocations appear often enough in corpora to be extractable by statistical and information-theory based methods. There are several basic methods for evaluating associations between words: based on frequency counts (Choueka, 1988; Wettler and Rapp, 1993), information theoretic (Church and Hanks, 1990) and statistical significance (Smadja, 1993). The statistical significance often evaluate whether two words are independant using hypothesis tests such as t-score (Church et al., 1991), the X2, the log-likelihood (Dunning, 1993) and Fisher’s exact test (Pedersen, 1996). Extracted sets for associated words are further pruned using numerical methods, or linguistic knowledge to obtain a subset of collocations. The various extraction measures have been discussed in great detail in the literature (Manning and Sch¨utze, 1999; McKeown and Radev, 2000), their performance has been compared (Dunning, 19</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>K. Church and P. Hanks. 1990. Word association norms, mutual information and lexicography. Computational Linguistics, 16:22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
<author>W Gale</author>
<author>P Hanks</author>
<author>D Hindle</author>
</authors>
<title>Using statistics in lexical analysis.</title>
<date>1991</date>
<editor>In U. Zernik, editor, Lexical</editor>
<contexts>
<context position="16642" citStr="Church et al., 1991" startWordPosition="2790" endWordPosition="2793">t cases it was reduced to extraction of collocations which are a proper subset of the set of associated words. While hard to define, collocations appear often enough in corpora to be extractable by statistical and information-theory based methods. There are several basic methods for evaluating associations between words: based on frequency counts (Choueka, 1988; Wettler and Rapp, 1993), information theoretic (Church and Hanks, 1990) and statistical significance (Smadja, 1993). The statistical significance often evaluate whether two words are independant using hypothesis tests such as t-score (Church et al., 1991), the X2, the log-likelihood (Dunning, 1993) and Fisher’s exact test (Pedersen, 1996). Extracted sets for associated words are further pruned using numerical methods, or linguistic knowledge to obtain a subset of collocations. The various extraction measures have been discussed in great detail in the literature (Manning and Sch¨utze, 1999; McKeown and Radev, 2000), their performance has been compared (Dunning, 1993; Pedersen, 1996; Evert and Krenn, 2001), and the methods have been combined to improve overall performance (Inkpen and Hirst, 2002). Most of these methods were originally applied in</context>
</contexts>
<marker>Church, Gale, Hanks, Hindle, 1991</marker>
<rawString>K. Church, W. Gale, P. Hanks, and D. Hindle. 1991. Using statistics in lexical analysis. In U. Zernik, editor, Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon. Lawrance Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Deese</author>
</authors>
<title>The structure of associations in language and thought.</title>
<date>1965</date>
<publisher>Johns Hopkins Press.</publisher>
<contexts>
<context position="7487" citStr="Deese, 1965" startWordPosition="1271" endWordPosition="1272">rds and concepts) and links (associations), with either being able to activate the other.7 Finding a 5The idea according to which the mental dictionary (or encyclopedia) is basically an associative network, composed of nodes (words or concepts) and links (associations) is not new, neither is the idea of spreading activation. Actually the very notion of association goes back at least to Aristotle (350BC), but it is also inherent in work done by philosophers (Locke, Hume), physiologists (James &amp; Stuart Mills), psychologists (Galton, 1880; Freud, 1901; Jung and Riklin, 1906) and psycholinguists (Deese, 1965; Jenkins, 1970; Schvaneveldt, 1989). For surveys in psycholinguistics see (H¨ormann, 1972), or more recent work (Spitzer, 1999). The notion of association is also implicit in work on semantic networks (Quillian, 1968), hypertext (Bush, 1945), the web (Nelson, 1967), connectionism (Dell et al., 1999) and, of course, in WordNet (Miller et al., 1993; Fellbaum, 1998). 6In the preceding sections we used several times the terms words and concepts interchangeably, as if they were the same. Of course, they are very different. Yet, not knowing what a concept looks like (a single node, or every node, i</context>
</contexts>
<marker>Deese, 1965</marker>
<rawString>J. Deese. 1965. The structure of associations in language and thought. Johns Hopkins Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G S Dell</author>
<author>F Chang</author>
<author>Z M Griffin</author>
</authors>
<title>Connectionist models of language production: Lexical access and grammatical encoding.</title>
<date>1999</date>
<journal>Cognitive Science,</journal>
<pages>23--517</pages>
<contexts>
<context position="7788" citStr="Dell et al., 1999" startWordPosition="1314" endWordPosition="1317">he idea of spreading activation. Actually the very notion of association goes back at least to Aristotle (350BC), but it is also inherent in work done by philosophers (Locke, Hume), physiologists (James &amp; Stuart Mills), psychologists (Galton, 1880; Freud, 1901; Jung and Riklin, 1906) and psycholinguists (Deese, 1965; Jenkins, 1970; Schvaneveldt, 1989). For surveys in psycholinguistics see (H¨ormann, 1972), or more recent work (Spitzer, 1999). The notion of association is also implicit in work on semantic networks (Quillian, 1968), hypertext (Bush, 1945), the web (Nelson, 1967), connectionism (Dell et al., 1999) and, of course, in WordNet (Miller et al., 1993; Fellbaum, 1998). 6In the preceding sections we used several times the terms words and concepts interchangeably, as if they were the same. Of course, they are very different. Yet, not knowing what a concept looks like (a single node, or every node, i.e. headword of the word’s definition?), we think it is safer to assume that the user can communicate with the computer (dictionary) only via words. Hence, concepts are represented by words, yet, since the two are connected, one can be accessed via the other, which addresses the interface problem wit</context>
</contexts>
<marker>Dell, Chang, Griffin, 1999</marker>
<rawString>G. S. Dell, F. Chang, and Z. M. Griffin. 1999. Connectionist models of language production: Lexical access and grammatical encoding. Cognitive Science, 23:517–542.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dunning</author>
</authors>
<title>Accurate methods for statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--61</pages>
<contexts>
<context position="16686" citStr="Dunning, 1993" startWordPosition="2798" endWordPosition="2799">ns which are a proper subset of the set of associated words. While hard to define, collocations appear often enough in corpora to be extractable by statistical and information-theory based methods. There are several basic methods for evaluating associations between words: based on frequency counts (Choueka, 1988; Wettler and Rapp, 1993), information theoretic (Church and Hanks, 1990) and statistical significance (Smadja, 1993). The statistical significance often evaluate whether two words are independant using hypothesis tests such as t-score (Church et al., 1991), the X2, the log-likelihood (Dunning, 1993) and Fisher’s exact test (Pedersen, 1996). Extracted sets for associated words are further pruned using numerical methods, or linguistic knowledge to obtain a subset of collocations. The various extraction measures have been discussed in great detail in the literature (Manning and Sch¨utze, 1999; McKeown and Radev, 2000), their performance has been compared (Dunning, 1993; Pedersen, 1996; Evert and Krenn, 2001), and the methods have been combined to improve overall performance (Inkpen and Hirst, 2002). Most of these methods were originally applied in large text corpora, but more recently the w</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>T. Dunning. 1993. Accurate methods for statistics of surprise and coincidence. Computational Linguistics, 19:61–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Evert</author>
<author>B Krenn</author>
</authors>
<title>Methods for the qualitative evaluation of lexical association measures.</title>
<date>2001</date>
<booktitle>In Proc. of the 39th Annual meeting of Association of Computational Linguistics (ACL</booktitle>
<pages>188--195</pages>
<contexts>
<context position="17100" citStr="Evert and Krenn, 2001" startWordPosition="2859" endWordPosition="2862">nificance (Smadja, 1993). The statistical significance often evaluate whether two words are independant using hypothesis tests such as t-score (Church et al., 1991), the X2, the log-likelihood (Dunning, 1993) and Fisher’s exact test (Pedersen, 1996). Extracted sets for associated words are further pruned using numerical methods, or linguistic knowledge to obtain a subset of collocations. The various extraction measures have been discussed in great detail in the literature (Manning and Sch¨utze, 1999; McKeown and Radev, 2000), their performance has been compared (Dunning, 1993; Pedersen, 1996; Evert and Krenn, 2001), and the methods have been combined to improve overall performance (Inkpen and Hirst, 2002). Most of these methods were originally applied in large text corpora, but more recently the web has been used as a corpus (Pearce, 2001; Inkpen and Hirst, 2002). Collocation extraction methods have been used not only for English, but for many other languages: French (Ferret, 2002), German (Evert and Krenn, 2001) and Japanese (Nagao and Mori, 1994), to cite but those. The most obvious question in this context is to clarify to what extent available collocation extraction techniques fulfill our needs of e</context>
</contexts>
<marker>Evert, Krenn, 2001</marker>
<rawString>S. Evert and B. Krenn. 2001. Methods for the qualitative evaluation of lexical association measures. In Proc. of the 39th Annual meeting of Association of Computational Linguistics (ACL 2001), pages 188–195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database and some of its Applications.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="7853" citStr="Fellbaum, 1998" startWordPosition="1327" endWordPosition="1328">tion goes back at least to Aristotle (350BC), but it is also inherent in work done by philosophers (Locke, Hume), physiologists (James &amp; Stuart Mills), psychologists (Galton, 1880; Freud, 1901; Jung and Riklin, 1906) and psycholinguists (Deese, 1965; Jenkins, 1970; Schvaneveldt, 1989). For surveys in psycholinguistics see (H¨ormann, 1972), or more recent work (Spitzer, 1999). The notion of association is also implicit in work on semantic networks (Quillian, 1968), hypertext (Bush, 1945), the web (Nelson, 1967), connectionism (Dell et al., 1999) and, of course, in WordNet (Miller et al., 1993; Fellbaum, 1998). 6In the preceding sections we used several times the terms words and concepts interchangeably, as if they were the same. Of course, they are very different. Yet, not knowing what a concept looks like (a single node, or every node, i.e. headword of the word’s definition?), we think it is safer to assume that the user can communicate with the computer (dictionary) only via words. Hence, concepts are represented by words, yet, since the two are connected, one can be accessed via the other, which addresses the interface problem with the computer. Another point worth mentionning is the fact that </context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>C. Fellbaum. 1998. WordNet: An Electronic Lexical Database and some of its Applications. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Ferret</author>
</authors>
<title>Using collocations for topic segmentation and link detection.</title>
<date>2002</date>
<booktitle>In Proc. of the 19th International Conference on Computational Linguistics,</booktitle>
<pages>261--266</pages>
<contexts>
<context position="17474" citStr="Ferret, 2002" startWordPosition="2924" endWordPosition="2925">ations. The various extraction measures have been discussed in great detail in the literature (Manning and Sch¨utze, 1999; McKeown and Radev, 2000), their performance has been compared (Dunning, 1993; Pedersen, 1996; Evert and Krenn, 2001), and the methods have been combined to improve overall performance (Inkpen and Hirst, 2002). Most of these methods were originally applied in large text corpora, but more recently the web has been used as a corpus (Pearce, 2001; Inkpen and Hirst, 2002). Collocation extraction methods have been used not only for English, but for many other languages: French (Ferret, 2002), German (Evert and Krenn, 2001) and Japanese (Nagao and Mori, 1994), to cite but those. The most obvious question in this context is to clarify to what extent available collocation extraction techniques fulfill our needs of extracting and labeling word associations. Since collocations are a subset of association, it is possible to apply collocation extraction techniques to obtain related words, ordered in terms of the relative strength of association. The result of this kind of numerical extraction would be a large set of numerically weighted word pairs. The problem with this approach is that</context>
</contexts>
<marker>Ferret, 2002</marker>
<rawString>O. Ferret. 2002. Using collocations for topic segmentation and link detection. In Proc. of the 19th International Conference on Computational Linguistics, pages 261–266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Freud</author>
</authors>
<title>Psychopathology of everyday life. Payot,</title>
<date>1901</date>
<note>edition.</note>
<contexts>
<context position="7430" citStr="Freud, 1901" startWordPosition="1262" endWordPosition="1263">ctionary as a huge semantic network composed of nodes (words and concepts) and links (associations), with either being able to activate the other.7 Finding a 5The idea according to which the mental dictionary (or encyclopedia) is basically an associative network, composed of nodes (words or concepts) and links (associations) is not new, neither is the idea of spreading activation. Actually the very notion of association goes back at least to Aristotle (350BC), but it is also inherent in work done by philosophers (Locke, Hume), physiologists (James &amp; Stuart Mills), psychologists (Galton, 1880; Freud, 1901; Jung and Riklin, 1906) and psycholinguists (Deese, 1965; Jenkins, 1970; Schvaneveldt, 1989). For surveys in psycholinguistics see (H¨ormann, 1972), or more recent work (Spitzer, 1999). The notion of association is also implicit in work on semantic networks (Quillian, 1968), hypertext (Bush, 1945), the web (Nelson, 1967), connectionism (Dell et al., 1999) and, of course, in WordNet (Miller et al., 1993; Fellbaum, 1998). 6In the preceding sections we used several times the terms words and concepts interchangeably, as if they were the same. Of course, they are very different. Yet, not knowing w</context>
</contexts>
<marker>Freud, 1901</marker>
<rawString>S. Freud. 1901. Psychopathology of everyday life. Payot, 1997 edition.</rawString>
</citation>
<citation valid="false">
<title>Psychometric experiments.</title>
<journal>Brain,</journal>
<pages>2--149</pages>
<marker></marker>
<rawString>F. Galton. 1880. Psychometric experiments. Brain, 2:149–162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H H¨ormann</author>
</authors>
<title>Introduction a` la psycholinquistique.</title>
<date>1972</date>
<location>Larousse.</location>
<marker>H¨ormann, 1972</marker>
<rawString>H. H¨ormann. 1972. Introduction a` la psycholinquistique. Larousse.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Z Inkpen</author>
<author>G Hirst</author>
</authors>
<title>Acquiring collocations for lexical choice between nearsynonyms.</title>
<date>2002</date>
<booktitle>In Proc. of Unsupervised Lexical Acquisition Workshop of the ACL SIGLEX,</booktitle>
<pages>67--76</pages>
<contexts>
<context position="17192" citStr="Inkpen and Hirst, 2002" startWordPosition="2874" endWordPosition="2877"> independant using hypothesis tests such as t-score (Church et al., 1991), the X2, the log-likelihood (Dunning, 1993) and Fisher’s exact test (Pedersen, 1996). Extracted sets for associated words are further pruned using numerical methods, or linguistic knowledge to obtain a subset of collocations. The various extraction measures have been discussed in great detail in the literature (Manning and Sch¨utze, 1999; McKeown and Radev, 2000), their performance has been compared (Dunning, 1993; Pedersen, 1996; Evert and Krenn, 2001), and the methods have been combined to improve overall performance (Inkpen and Hirst, 2002). Most of these methods were originally applied in large text corpora, but more recently the web has been used as a corpus (Pearce, 2001; Inkpen and Hirst, 2002). Collocation extraction methods have been used not only for English, but for many other languages: French (Ferret, 2002), German (Evert and Krenn, 2001) and Japanese (Nagao and Mori, 1994), to cite but those. The most obvious question in this context is to clarify to what extent available collocation extraction techniques fulfill our needs of extracting and labeling word associations. Since collocations are a subset of association, it</context>
</contexts>
<marker>Inkpen, Hirst, 2002</marker>
<rawString>D. Z. Inkpen and G. Hirst. 2002. Acquiring collocations for lexical choice between nearsynonyms. In Proc. of Unsupervised Lexical Acquisition Workshop of the ACL SIGLEX, pages 67–76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J Jenkins</author>
</authors>
<title>The 1952 minnesota word association norms.</title>
<date>1970</date>
<booktitle>Norms of Word Association,</booktitle>
<pages>1--38</pages>
<editor>In L. Postman and G. Kepper, editors,</editor>
<publisher>Academic Press.</publisher>
<contexts>
<context position="7502" citStr="Jenkins, 1970" startWordPosition="1273" endWordPosition="1274">pts) and links (associations), with either being able to activate the other.7 Finding a 5The idea according to which the mental dictionary (or encyclopedia) is basically an associative network, composed of nodes (words or concepts) and links (associations) is not new, neither is the idea of spreading activation. Actually the very notion of association goes back at least to Aristotle (350BC), but it is also inherent in work done by philosophers (Locke, Hume), physiologists (James &amp; Stuart Mills), psychologists (Galton, 1880; Freud, 1901; Jung and Riklin, 1906) and psycholinguists (Deese, 1965; Jenkins, 1970; Schvaneveldt, 1989). For surveys in psycholinguistics see (H¨ormann, 1972), or more recent work (Spitzer, 1999). The notion of association is also implicit in work on semantic networks (Quillian, 1968), hypertext (Bush, 1945), the web (Nelson, 1967), connectionism (Dell et al., 1999) and, of course, in WordNet (Miller et al., 1993; Fellbaum, 1998). 6In the preceding sections we used several times the terms words and concepts interchangeably, as if they were the same. Of course, they are very different. Yet, not knowing what a concept looks like (a single node, or every node, i.e. headword of</context>
</contexts>
<marker>Jenkins, 1970</marker>
<rawString>J. J. Jenkins. 1970. The 1952 minnesota word association norms. In L. Postman and G. Kepper, editors, Norms of Word Association, pages 1–38. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C G Jung</author>
<author>F Riklin</author>
</authors>
<title>Experimentelle unter-suchungen ¨uber assoziationene gesunder.</title>
<date>1906</date>
<booktitle>Diagnostische Assoziationsstudien,</booktitle>
<pages>7--145</pages>
<editor>In C. G. Jung, editor,</editor>
<publisher>Barth.</publisher>
<contexts>
<context position="7454" citStr="Jung and Riklin, 1906" startWordPosition="1264" endWordPosition="1267"> huge semantic network composed of nodes (words and concepts) and links (associations), with either being able to activate the other.7 Finding a 5The idea according to which the mental dictionary (or encyclopedia) is basically an associative network, composed of nodes (words or concepts) and links (associations) is not new, neither is the idea of spreading activation. Actually the very notion of association goes back at least to Aristotle (350BC), but it is also inherent in work done by philosophers (Locke, Hume), physiologists (James &amp; Stuart Mills), psychologists (Galton, 1880; Freud, 1901; Jung and Riklin, 1906) and psycholinguists (Deese, 1965; Jenkins, 1970; Schvaneveldt, 1989). For surveys in psycholinguistics see (H¨ormann, 1972), or more recent work (Spitzer, 1999). The notion of association is also implicit in work on semantic networks (Quillian, 1968), hypertext (Bush, 1945), the web (Nelson, 1967), connectionism (Dell et al., 1999) and, of course, in WordNet (Miller et al., 1993; Fellbaum, 1998). 6In the preceding sections we used several times the terms words and concepts interchangeably, as if they were the same. Of course, they are very different. Yet, not knowing what a concept looks like</context>
</contexts>
<marker>Jung, Riklin, 1906</marker>
<rawString>C. G. Jung and F. Riklin. 1906. Experimentelle unter-suchungen ¨uber assoziationene gesunder. In C. G. Jung, editor, Diagnostische Assoziationsstudien, pages 7–145. Barth.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>Extracting collocations from text corpor.</title>
<date>1998</date>
<booktitle>In First Workshop on Computational Terminology.</booktitle>
<contexts>
<context position="18814" citStr="Lin, 1998" startWordPosition="3141" endWordPosition="3142">roup and present them in a meaningful way for the dictionary user. Clusters based only on the notion of association strength are inadequate for the kind of navigation described here above. Hence another step is necessary: qualification of the links according to their types. Only once this is done, a human being could use it to navigate through a large conceptual-lexical network (the dictionary) as described above. Unfortunately, research on automatic link identification has been rather sparse. Most attempts have been devoted to the extraction of certain types of links (usually syntactic type (Lin, 1998) or on extensions of WordNet with topical information contained in a thesaurus (Stevenson, 2002) or on the WWW (Agirre et al., 2000). Additional methods need to be considered in order to reveal (automatically) the kind of associations holding between words and/or concepts. Earlier in this paper we have suggested the use of an encyclopedia as a source of general world knowledge. It should be noted, though, that there are important differences between large corpora and encyclopedias. Large corpora usually contain a lot of repetitive texts on a limited number of topics (e.g. newspaper articles) w</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>D. Lin. 1998. Extracting collocations from text corpor. In First Workshop on Computational Terminology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Manning</author>
<author>H Sch¨utze</author>
</authors>
<title>Foundations of Statistical Natural Language Processing.</title>
<date>1999</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<marker>Manning, Sch¨utze, 1999</marker>
<rawString>C. D. Manning and H. Sch¨utze. 1999. Foundations of Statistical Natural Language Processing. The MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K R McKeown</author>
<author>Dragomir R Radev</author>
</authors>
<date>2000</date>
<booktitle>Handbook of Natural Language Processing,</booktitle>
<pages>507--523</pages>
<editor>Collocations. In H. Moisl R. Dale and H. Somers, editors,</editor>
<publisher>Marcel Dekker.</publisher>
<contexts>
<context position="17008" citStr="McKeown and Radev, 2000" startWordPosition="2846" endWordPosition="2849">8; Wettler and Rapp, 1993), information theoretic (Church and Hanks, 1990) and statistical significance (Smadja, 1993). The statistical significance often evaluate whether two words are independant using hypothesis tests such as t-score (Church et al., 1991), the X2, the log-likelihood (Dunning, 1993) and Fisher’s exact test (Pedersen, 1996). Extracted sets for associated words are further pruned using numerical methods, or linguistic knowledge to obtain a subset of collocations. The various extraction measures have been discussed in great detail in the literature (Manning and Sch¨utze, 1999; McKeown and Radev, 2000), their performance has been compared (Dunning, 1993; Pedersen, 1996; Evert and Krenn, 2001), and the methods have been combined to improve overall performance (Inkpen and Hirst, 2002). Most of these methods were originally applied in large text corpora, but more recently the web has been used as a corpus (Pearce, 2001; Inkpen and Hirst, 2002). Collocation extraction methods have been used not only for English, but for many other languages: French (Ferret, 2002), German (Evert and Krenn, 2001) and Japanese (Nagao and Mori, 1994), to cite but those. The most obvious question in this context is </context>
</contexts>
<marker>McKeown, Radev, 2000</marker>
<rawString>K. R. McKeown and Dragomir R. Radev. 2000. Collocations. In H. Moisl R. Dale and H. Somers, editors, Handbook of Natural Language Processing, pages 507–523. Marcel Dekker.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mel’cuk</author>
</authors>
<title>Dictionnaire Explicatif et Combinatoire du fran¸cais contemporain: recherche lexicos´emantique III. Les presses de l’universit´e de Montr´eal.</title>
<date>1992</date>
<marker>Mel’cuk, 1992</marker>
<rawString>I. Mel’cuk. 1992. Dictionnaire Explicatif et Combinatoire du fran¸cais contemporain: recherche lexicos´emantique III. Les presses de l’universit´e de Montr´eal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
<author>R Beckwith</author>
<author>C Fellbaum</author>
</authors>
<title>Introduction to WordNet: An On-line Lexical Database.</title>
<date>1993</date>
<editor>D. Gross, and Katherine Miller, editors.</editor>
<institution>Cognitive Science Laboratory, Princeton University.</institution>
<contexts>
<context position="7836" citStr="Miller et al., 1993" startWordPosition="1323" endWordPosition="1326">ery notion of association goes back at least to Aristotle (350BC), but it is also inherent in work done by philosophers (Locke, Hume), physiologists (James &amp; Stuart Mills), psychologists (Galton, 1880; Freud, 1901; Jung and Riklin, 1906) and psycholinguists (Deese, 1965; Jenkins, 1970; Schvaneveldt, 1989). For surveys in psycholinguistics see (H¨ormann, 1972), or more recent work (Spitzer, 1999). The notion of association is also implicit in work on semantic networks (Quillian, 1968), hypertext (Bush, 1945), the web (Nelson, 1967), connectionism (Dell et al., 1999) and, of course, in WordNet (Miller et al., 1993; Fellbaum, 1998). 6In the preceding sections we used several times the terms words and concepts interchangeably, as if they were the same. Of course, they are very different. Yet, not knowing what a concept looks like (a single node, or every node, i.e. headword of the word’s definition?), we think it is safer to assume that the user can communicate with the computer (dictionary) only via words. Hence, concepts are represented by words, yet, since the two are connected, one can be accessed via the other, which addresses the interface problem with the computer. Another point worth mentionning </context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, 1993</marker>
<rawString>G. A. Miller, R. Beckwith, C. Fellbaum, D. Gross, and Katherine Miller, editors. 1993. Introduction to WordNet: An On-line Lexical Database. Cognitive Science Laboratory, Princeton University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Nagao</author>
<author>S Mori</author>
</authors>
<title>A new method of n-gram statistics for large number of n and automatic extraction of words and phrases from large text data of Japanese.</title>
<date>1994</date>
<booktitle>In Proc. of the 15th International Conference on Computational Linguistics (COLING</booktitle>
<pages>611--615</pages>
<contexts>
<context position="17542" citStr="Nagao and Mori, 1994" startWordPosition="2934" endWordPosition="2937">in great detail in the literature (Manning and Sch¨utze, 1999; McKeown and Radev, 2000), their performance has been compared (Dunning, 1993; Pedersen, 1996; Evert and Krenn, 2001), and the methods have been combined to improve overall performance (Inkpen and Hirst, 2002). Most of these methods were originally applied in large text corpora, but more recently the web has been used as a corpus (Pearce, 2001; Inkpen and Hirst, 2002). Collocation extraction methods have been used not only for English, but for many other languages: French (Ferret, 2002), German (Evert and Krenn, 2001) and Japanese (Nagao and Mori, 1994), to cite but those. The most obvious question in this context is to clarify to what extent available collocation extraction techniques fulfill our needs of extracting and labeling word associations. Since collocations are a subset of association, it is possible to apply collocation extraction techniques to obtain related words, ordered in terms of the relative strength of association. The result of this kind of numerical extraction would be a large set of numerically weighted word pairs. The problem with this approach is that the links are only labeled in terms of their relative associative s</context>
</contexts>
<marker>Nagao, Mori, 1994</marker>
<rawString>M. Nagao and S. Mori. 1994. A new method of n-gram statistics for large number of n and automatic extraction of words and phrases from large text data of Japanese. In Proc. of the 15th International Conference on Computational Linguistics (COLING 1994), pages 611–615.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Nelson</author>
</authors>
<date>1967</date>
<note>Xanadu projet hypertextuel.</note>
<contexts>
<context position="7753" citStr="Nelson, 1967" startWordPosition="1311" endWordPosition="1312">ions) is not new, neither is the idea of spreading activation. Actually the very notion of association goes back at least to Aristotle (350BC), but it is also inherent in work done by philosophers (Locke, Hume), physiologists (James &amp; Stuart Mills), psychologists (Galton, 1880; Freud, 1901; Jung and Riklin, 1906) and psycholinguists (Deese, 1965; Jenkins, 1970; Schvaneveldt, 1989). For surveys in psycholinguistics see (H¨ormann, 1972), or more recent work (Spitzer, 1999). The notion of association is also implicit in work on semantic networks (Quillian, 1968), hypertext (Bush, 1945), the web (Nelson, 1967), connectionism (Dell et al., 1999) and, of course, in WordNet (Miller et al., 1993; Fellbaum, 1998). 6In the preceding sections we used several times the terms words and concepts interchangeably, as if they were the same. Of course, they are very different. Yet, not knowing what a concept looks like (a single node, or every node, i.e. headword of the word’s definition?), we think it is safer to assume that the user can communicate with the computer (dictionary) only via words. Hence, concepts are represented by words, yet, since the two are connected, one can be accessed via the other, which </context>
<context position="22956" citStr="Nelson, 1967" startWordPosition="3797" endWordPosition="3798">The ease of la13http://www.icsi.berkeley.edu/~framenet/ 14http://www.keenage.com/html/e_index.html 15http://humanities.uchicago.edu/homes/MICRA/ 16http://www.wordsmyth.com/ 17One such pattern could be: give me the word for a bird with yellow feet and a long beak, that can swim. Actually, word access problems frequently come under the form of questions like: What is the word for X that Y?, where X is usually a hypernym and Y a stereotypical, possibly partial functional/relational/case description of the target word. 18Actually, this has been done for decades, but with a different goal in mind (Nelson, 1967), http://cyber. acomp.usf.edu/FreeAssociation/. beling will probably depend upon the origin of the words (the person asked to label the link or somebody else). Another approach would be to extract collocations from a corpus and label them automatically. There are tools for extracting cooccurrences (see section 5.5), and ontologies could be used to qualify some of the links between collocational elements. While this approach might work fine for couples like coffeestrong, or wine-red (since an ontology would reveal that red is a kind of color, which is precisely the link type: i.e. association),</context>
</contexts>
<marker>Nelson, 1967</marker>
<rawString>T. Nelson. 1967. Xanadu projet hypertextuel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Pearce</author>
</authors>
<title>Synonymy in collocation extraction.</title>
<date>2001</date>
<booktitle>In Proc. of NAACL’01 Workshop on WordNet and Other Lexical Resources: Applications, Extensions and Customizations.</booktitle>
<contexts>
<context position="17328" citStr="Pearce, 2001" startWordPosition="2901" endWordPosition="2902">rsen, 1996). Extracted sets for associated words are further pruned using numerical methods, or linguistic knowledge to obtain a subset of collocations. The various extraction measures have been discussed in great detail in the literature (Manning and Sch¨utze, 1999; McKeown and Radev, 2000), their performance has been compared (Dunning, 1993; Pedersen, 1996; Evert and Krenn, 2001), and the methods have been combined to improve overall performance (Inkpen and Hirst, 2002). Most of these methods were originally applied in large text corpora, but more recently the web has been used as a corpus (Pearce, 2001; Inkpen and Hirst, 2002). Collocation extraction methods have been used not only for English, but for many other languages: French (Ferret, 2002), German (Evert and Krenn, 2001) and Japanese (Nagao and Mori, 1994), to cite but those. The most obvious question in this context is to clarify to what extent available collocation extraction techniques fulfill our needs of extracting and labeling word associations. Since collocations are a subset of association, it is possible to apply collocation extraction techniques to obtain related words, ordered in terms of the relative strength of associatio</context>
</contexts>
<marker>Pearce, 2001</marker>
<rawString>D. Pearce. 2001. Synonymy in collocation extraction. In Proc. of NAACL’01 Workshop on WordNet and Other Lexical Resources: Applications, Extensions and Customizations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
</authors>
<title>Fishing for exactness.</title>
<date>1996</date>
<booktitle>In Proc. of the South-Central SAS Users Group Conference,</booktitle>
<pages>188--195</pages>
<contexts>
<context position="16727" citStr="Pedersen, 1996" startWordPosition="2804" endWordPosition="2806">of associated words. While hard to define, collocations appear often enough in corpora to be extractable by statistical and information-theory based methods. There are several basic methods for evaluating associations between words: based on frequency counts (Choueka, 1988; Wettler and Rapp, 1993), information theoretic (Church and Hanks, 1990) and statistical significance (Smadja, 1993). The statistical significance often evaluate whether two words are independant using hypothesis tests such as t-score (Church et al., 1991), the X2, the log-likelihood (Dunning, 1993) and Fisher’s exact test (Pedersen, 1996). Extracted sets for associated words are further pruned using numerical methods, or linguistic knowledge to obtain a subset of collocations. The various extraction measures have been discussed in great detail in the literature (Manning and Sch¨utze, 1999; McKeown and Radev, 2000), their performance has been compared (Dunning, 1993; Pedersen, 1996; Evert and Krenn, 2001), and the methods have been combined to improve overall performance (Inkpen and Hirst, 2002). Most of these methods were originally applied in large text corpora, but more recently the web has been used as a corpus (Pearce, 200</context>
</contexts>
<marker>Pedersen, 1996</marker>
<rawString>Ted Pedersen. 1996. Fishing for exactness. In Proc. of the South-Central SAS Users Group Conference, pages 188–195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Quillian</author>
</authors>
<title>Semantic memory.</title>
<date>1968</date>
<booktitle>Semantic Information Processing,</booktitle>
<pages>216--270</pages>
<editor>In M. Minsky, editor,</editor>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="7705" citStr="Quillian, 1968" startWordPosition="1303" endWordPosition="1305">d of nodes (words or concepts) and links (associations) is not new, neither is the idea of spreading activation. Actually the very notion of association goes back at least to Aristotle (350BC), but it is also inherent in work done by philosophers (Locke, Hume), physiologists (James &amp; Stuart Mills), psychologists (Galton, 1880; Freud, 1901; Jung and Riklin, 1906) and psycholinguists (Deese, 1965; Jenkins, 1970; Schvaneveldt, 1989). For surveys in psycholinguistics see (H¨ormann, 1972), or more recent work (Spitzer, 1999). The notion of association is also implicit in work on semantic networks (Quillian, 1968), hypertext (Bush, 1945), the web (Nelson, 1967), connectionism (Dell et al., 1999) and, of course, in WordNet (Miller et al., 1993; Fellbaum, 1998). 6In the preceding sections we used several times the terms words and concepts interchangeably, as if they were the same. Of course, they are very different. Yet, not knowing what a concept looks like (a single node, or every node, i.e. headword of the word’s definition?), we think it is safer to assume that the user can communicate with the computer (dictionary) only via words. Hence, concepts are represented by words, yet, since the two are conn</context>
</contexts>
<marker>Quillian, 1968</marker>
<rawString>R. Quillian. 1968. Semantic memory. In M. Minsky, editor, Semantic Information Processing, pages 216–270.The MIT Press. Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<title>Pathfinder Associative Networks: studies in knowledge organization.</title>
<date>1989</date>
<editor>R. Schvaneveldt, editor.</editor>
<publisher>Norwood.</publisher>
<marker>1989</marker>
<rawString>R. Schvaneveldt, editor. 1989. Pathfinder Associative Networks: studies in knowledge organization. Norwood.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Smadja</author>
</authors>
<title>Retrieving collocations from text: Xtract. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="16502" citStr="Smadja, 1993" startWordPosition="2771" endWordPosition="2772"> is to automatically extract associations from large corpora. This problem was addressed by a large number of researchers, but in most cases it was reduced to extraction of collocations which are a proper subset of the set of associated words. While hard to define, collocations appear often enough in corpora to be extractable by statistical and information-theory based methods. There are several basic methods for evaluating associations between words: based on frequency counts (Choueka, 1988; Wettler and Rapp, 1993), information theoretic (Church and Hanks, 1990) and statistical significance (Smadja, 1993). The statistical significance often evaluate whether two words are independant using hypothesis tests such as t-score (Church et al., 1991), the X2, the log-likelihood (Dunning, 1993) and Fisher’s exact test (Pedersen, 1996). Extracted sets for associated words are further pruned using numerical methods, or linguistic knowledge to obtain a subset of collocations. The various extraction measures have been discussed in great detail in the literature (Manning and Sch¨utze, 1999; McKeown and Radev, 2000), their performance has been compared (Dunning, 1993; Pedersen, 1996; Evert and Krenn, 2001), </context>
</contexts>
<marker>Smadja, 1993</marker>
<rawString>F. Smadja. 1993. Retrieving collocations from text: Xtract. Computational Linguistics, 19:143–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Spitzer</author>
</authors>
<title>The mind within the net: models of learning, thinking and acting.</title>
<date>1999</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="7615" citStr="Spitzer, 1999" startWordPosition="1288" endWordPosition="1289">hich the mental dictionary (or encyclopedia) is basically an associative network, composed of nodes (words or concepts) and links (associations) is not new, neither is the idea of spreading activation. Actually the very notion of association goes back at least to Aristotle (350BC), but it is also inherent in work done by philosophers (Locke, Hume), physiologists (James &amp; Stuart Mills), psychologists (Galton, 1880; Freud, 1901; Jung and Riklin, 1906) and psycholinguists (Deese, 1965; Jenkins, 1970; Schvaneveldt, 1989). For surveys in psycholinguistics see (H¨ormann, 1972), or more recent work (Spitzer, 1999). The notion of association is also implicit in work on semantic networks (Quillian, 1968), hypertext (Bush, 1945), the web (Nelson, 1967), connectionism (Dell et al., 1999) and, of course, in WordNet (Miller et al., 1993; Fellbaum, 1998). 6In the preceding sections we used several times the terms words and concepts interchangeably, as if they were the same. Of course, they are very different. Yet, not knowing what a concept looks like (a single node, or every node, i.e. headword of the word’s definition?), we think it is safer to assume that the user can communicate with the computer (diction</context>
</contexts>
<marker>Spitzer, 1999</marker>
<rawString>M. Spitzer. 1999. The mind within the net: models of learning, thinking and acting. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Stevenson</author>
</authors>
<title>Augmenting noun taxonomies by combining lexical similarity metrics.</title>
<date>2002</date>
<booktitle>In Proc. of the 19th International Conference on Computational Linguistics (COLING</booktitle>
<pages>953--959</pages>
<contexts>
<context position="18910" citStr="Stevenson, 2002" startWordPosition="3156" endWordPosition="3157">the notion of association strength are inadequate for the kind of navigation described here above. Hence another step is necessary: qualification of the links according to their types. Only once this is done, a human being could use it to navigate through a large conceptual-lexical network (the dictionary) as described above. Unfortunately, research on automatic link identification has been rather sparse. Most attempts have been devoted to the extraction of certain types of links (usually syntactic type (Lin, 1998) or on extensions of WordNet with topical information contained in a thesaurus (Stevenson, 2002) or on the WWW (Agirre et al., 2000). Additional methods need to be considered in order to reveal (automatically) the kind of associations holding between words and/or concepts. Earlier in this paper we have suggested the use of an encyclopedia as a source of general world knowledge. It should be noted, though, that there are important differences between large corpora and encyclopedias. Large corpora usually contain a lot of repetitive texts on a limited number of topics (e.g. newspaper articles) which makes them very suitable for statistical methods. On the other hand, while being maximally </context>
</contexts>
<marker>Stevenson, 2002</marker>
<rawString>M. Stevenson. 2002. Augmenting noun taxonomies by combining lexical similarity metrics. In Proc. of the 19th International Conference on Computational Linguistics (COLING 2002), pages 953–959.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Wettler</author>
<author>R Rapp</author>
</authors>
<title>Computation of word associations based on the co-occurrences of words in large corpora.</title>
<date>1993</date>
<booktitle>In Proc. of the 1st Workshop on Very Large Corpora: Academic and Industrial Perspectives.</booktitle>
<contexts>
<context position="16410" citStr="Wettler and Rapp, 1993" startWordPosition="2758" endWordPosition="2761">mpossible to repeat these experiments to take into account the evolution of a society. Hence, the goal is to automatically extract associations from large corpora. This problem was addressed by a large number of researchers, but in most cases it was reduced to extraction of collocations which are a proper subset of the set of associated words. While hard to define, collocations appear often enough in corpora to be extractable by statistical and information-theory based methods. There are several basic methods for evaluating associations between words: based on frequency counts (Choueka, 1988; Wettler and Rapp, 1993), information theoretic (Church and Hanks, 1990) and statistical significance (Smadja, 1993). The statistical significance often evaluate whether two words are independant using hypothesis tests such as t-score (Church et al., 1991), the X2, the log-likelihood (Dunning, 1993) and Fisher’s exact test (Pedersen, 1996). Extracted sets for associated words are further pruned using numerical methods, or linguistic knowledge to obtain a subset of collocations. The various extraction measures have been discussed in great detail in the literature (Manning and Sch¨utze, 1999; McKeown and Radev, 2000), </context>
</contexts>
<marker>Wettler, Rapp, 1993</marker>
<rawString>M. Wettler and R. Rapp. 1993. Computation of word associations based on the co-occurrences of words in large corpora. In Proc. of the 1st Workshop on Very Large Corpora: Academic and Industrial Perspectives.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>