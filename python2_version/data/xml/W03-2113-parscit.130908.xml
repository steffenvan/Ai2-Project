<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9165025">
Some empirical findings on dialogue management and domain ontologies in
dialogue systems – Implications from an evaluation of BIRDQUEST
</title>
<author confidence="0.970177">
Annika Flycht-Eriksson
</author>
<affiliation confidence="0.946452">
Department of Computer and
Information Science
Link¨oping University, Sweden
</affiliation>
<email confidence="0.992224">
annfl@ida.liu.se
</email>
<author confidence="0.974845">
Arne J¨onsson
</author>
<affiliation confidence="0.946296333333333">
Department of Computer and
Information Science
Link¨oping University, Sweden
</affiliation>
<email confidence="0.994791">
arnjo@ida.liu.se
</email>
<sectionHeader confidence="0.996613" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9989986">
In this paper we present implications
for development of dialogue systems,
based on an evaluation of the system
BIRDQUEST which combine dialogue in-
teraction with information extraction. A
number of issues detected during the
evaluation concerning primarily dialogue
management, and domain knowledge rep-
resentation and use are presented and dis-
cussed.
</bodyText>
<sectionHeader confidence="0.998786" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.983731804347826">
In the field of Question Answering (Q&amp;A), Infor-
mation extraction (IE) techniques have been used
successfully when it comes to handling simple fac-
toid questions, but the Q&amp;A approach has yet not
reached the level of sophistication for handling con-
nected dialogue as is present in dialogue systems tai-
lored to background systems with structured data.
Dialogue capabilities allow for more precise formu-
lation of information requests and more natural in-
teraction. The challenge is to combine the IE tech-
niques and some of the features of Q&amp; approaches
with dialogue systems (Burger et al., 2001). By a
successful combination of these techniques, users
would be allowed to access information derived
from a large set of, initially unstructured, docu-
ments, using dialogue functionalities, such as a di-
alogue history and clarification requests.
We have developed a first version of such a com-
bined system, BIRDQUEST (J¨onsson and Merkel,
2003), which supports dialogue interaction to access
textual data in a bird encyclopaedia. The source data
is initially provided as unstructured text but refined
with IE techniques to be used within a dialogue sys-
tem framework. As a basis for many of the tasks
in the system domain knowledge represented in an
ontology is utilised.
To assess the approach and get insights into what
areas need further improvement an evaluation of the
system has been carried out. In this paper the results
of this evaluation are presented together with a dis-
cussion of implications for development of dialogue
systems with focus on dialogue management and the
use of domain ontologies.
2 Combining IE with dialogue interaction
in a system
Combining dialogue interaction with information
extraction has several benefits; dialogue is a natural
and efficient means of interaction and with IE tech-
niques information can be retrieved from unstruc-
tured information sources that are otherwise hard to
manage and search for a user. A possible way of
merging these two in a practical system is to have
two components, an information processing compo-
nent and an interaction component that, as a basis
for their tasks, use a set of shared knowledge sources
that define the scope of the language and domain.
</bodyText>
<subsectionHeader confidence="0.761697">
2.1 The Information Processing Component
</subsectionHeader>
<bodyText confidence="0.99991">
The Information Processing Component takes col-
lections of unstructured or semistructured docu-
ments and transforms them into structured informa-
tion that can be used by the Interaction Component
in the interaction with the user. The transforma-
tion utilise IE techniques, and the documents are
analysed in several ways going through lexical and
morphological, syntactical, and semantical analy-
sis (Sullivan, 2001).
A wide variety of pattern extraction rules are
used to identify the relevant information as slots and
fillers. The objective is to fill the database with rel-
evant information and ignore text segments that do
not meet the needs of the users. Figure 1 illustrates
how unstructured text is transformed into slot and
filler type information in the database.
</bodyText>
<subsectionHeader confidence="0.410843">
Original text
</subsectionHeader>
<bodyText confidence="0.958260571428571">
Black-throated diver
Gavia arctica
58-73 cm, wingspan 110-130 cm.
In breeding plumage the head is gray
and the throat is black, the sides
of the throat striped in black and
white. [...]
</bodyText>
<subsectionHeader confidence="0.405625">
Extracted information
</subsectionHeader>
<bodyText confidence="0.8901002">
Black-throated diver
Gavia arctica
130
110
73
58
”the head is gray and the
throat is black, the sides
of the throat striped in
black and white.”
</bodyText>
<figureCaption confidence="0.943069333333333">
Figure 1: Original text passage from the text book
and the corresponding entry in the database (trans-
lated from Swedish).
</figureCaption>
<subsectionHeader confidence="0.943769">
2.2 The Interaction Component
</subsectionHeader>
<bodyText confidence="0.999965977777778">
The Interaction Component is responsible for the di-
alogue with the user. It collaborates with the user
to produce a query and access the structured infor-
mation sources to retrieve an answer to the query.
The interaction component in BIRDQUEST is based
on the MALIN framework (Dahlb¨ack et al., 1999).
MALIN is a modularised dialogue system and it
separates dialogue management (DM) from domain
knowledge management (DKM) (Flycht-Eriksson
and J¨onsson, 2000). The former handles the dia-
logue whereas the latter handles access to various
background information sources.
The Dialogue Manager is responsible for control-
ling the flow of the dialogue by deciding how the
system should respond to a user utterance. This
is done by inspecting and contextually specifying
the information structure produced by an interpreta-
tion module. The MALIN dialogue model classifies
the discourse segments by general speech act cate-
gories, such as question (Q) and answer (A), rather
than specialised (cf. (Hagen, 1999)), or domain re-
lated (Alexandersson and Reithinger, 1995). The di-
alogue manager instead utilise the focal parameters
to control interaction (cf. (Jokinen et al., 1998; De-
necke, 1997; J¨onsson, 1995)). In MALIN dialogue
history is represented in dialogue objects with a pa-
rameter termed Objects, which identify a set of pri-
mary referents, and the parameter Properties which
denote a complex predicate ascribed to this set. In
BIRDQUEST Objects are normally birds and Proper-
ties model information about the birds, such as ap-
pearance, number of eggs and feed.
The Domain knowledge manager receives re-
quests from the dialogue manager and process them
further using domain knowledge, for example, dis-
ambiguation and mapping of vague concepts to ones
more suitable for database access. It then retrieves
and coordinates information from available informa-
tion sources, such as data and knowledge bases. If
a request is under-specified or contains inconsisten-
cies from the domain knowledge manager’s point of
view, a specification of what clarifying information
is needed will be returned to the dialogue manager
to help the formulation of a clarification question to
the user.
</bodyText>
<subsectionHeader confidence="0.998567">
2.3 Knowledge sources
</subsectionHeader>
<bodyText confidence="0.999856818181818">
As a basis for the processing of documents and user
queries a number of knowledge sources are utilised.
Some are highly specialised and only used by one or
a few submodules of a component, for example the
dialogue model in the Interaction Component, while
others are more general and used for several tasks in
both components. These shared knowledge sources
comprise lexicon, grammar, and domain ontologies.
Building lexicon and grammars to be used for dif-
ferent tasks also involves several challenges but will
not be further discussed in this paper.
</bodyText>
<listItem confidence="0.996993285714286">
NAME:
LATIN NAME:
MAX WING:
MIN WING:
MAX HEIGHT:
MIN HEIGHT:
BR PLUMAGE:
</listItem>
<bodyText confidence="0.999896428571428">
The term ontology is used very differently in var-
ious areas of computer science, ranging from sim-
ple taxonomies, meta data schemes, to logical the-
ories. A general and commonly used definition
given by Gruber (1993) is that ”An ontology is a
formal, explicit specification of a shared conceptu-
alisation”. A more practical view is to consider
an ontology as ”a world model used as a com-
putational resource for solving a particular set of
problems” (Mahesh and Nirenburg, 1995), i.e. a
database with information about what categories (or
concepts) exist in the world/domain, what properties
they have, and how they are related to one another.
An ontology provides a common vocabulary that
can be used to state facts and formulate questions
about the domain. Constructing an ontology that can
be shared by the Information Processing Component
and the Interaction Component then gives us a pos-
sible way to bridge users’ expression and queries to
the information contained in the unstructured docu-
ments.
</bodyText>
<sectionHeader confidence="0.908012" genericHeader="method">
3 Constructing the domain ontology
</sectionHeader>
<bodyText confidence="0.999948">
A challenge when constructing a shared domain on-
tology lies in capturing and including two different
conceptualisations of the domain, the one present in
the information sources and the one users have. The
shared ontology for the BIRDQUEST system was de-
veloped based on the analysis of two different types
of empirical material, a bird encyclopaedia and a
question corpus. The corpus consists of more than
250 questions about birds. It was collected by The
Swedish Public Service Television Company on a
web site for one of their nature programs, where the
public could send in questions, i.e. it is not a dia-
logue corpus.
The analysis of the empirical material focused
on identifying objects and properties, which in turn
were organised using hyponym relations. From
the encyclopaedia a conceptualisation underlying
the structure and presentation of information that
were to be extracted by the Information Process-
ing Component was constructed. The result was a
system-oriented domain ontology representing ex-
perts’ view of the domain. The question corpus
yielded a user-oriented conceptualisation of the do-
main, thus providing a non-expert view of the do-
main useful for the interaction component. These
two conceptualisations were then merged to form a
shared domain ontology for all components of the
system.
The users’ view of the domain as reflected in the
questions seemed to correspond to the one found in
the reference book, most objects and properties were
the same, but there were two aspects that deviated.
The first concerned the classification of birds and the
second the granularity of the properties of birds.
</bodyText>
<listItem confidence="0.8842395">
• Users sometimes utilised another way of cat-
egorising birds from the biologically oriented
taxonomy in the reference book, talking about
”Spring birds”, ”Small birds”, ”Migratory
birds”, and ”Birds of prey” instead of orders,
families, kins etc.
• In many cases the properties of the birds were
more general than the terms used in the book,
for example questions about a bird’s appear-
ance, e.g. What does a European Robin look
</listItem>
<bodyText confidence="0.991049736842105">
like? which includes plumage, size, body
shape, description of beak and feet, etc.
Since the two conceptualisations had many ob-
jects and properties in common and these were re-
lated in similar ways they could be integrated in the
following way (cf. figure 2). Taking the system-
oriented ontology as a starting point the new cate-
gories of birds found in the question corpora were
added. Allowing multiple inheritance new links be-
tween existing categories and new categories were
added. Note, for example, how the new category
”Small bird” is introduced and a new link is added to
”Finches” in figure 2. In a similar manner the vague
properties were introduced and linked to the exist-
ing properties. This is illustrated in figure 2 where
two new levels are introduced, ”Wingspan” and
”Length” are sub-properties of the property ”Size”,
which in turn is a sub-property of the property ”Ap-
pearance”.
</bodyText>
<sectionHeader confidence="0.986624" genericHeader="method">
4 Evaluating BIRDQUEST
</sectionHeader>
<bodyText confidence="0.9999022">
As stated above BIRDQUEST was developed based
on a corpus of questions. For further development
of BIRDQUEST, we needed to assess its strengths
and limitations during dialogues with real users. An
evaluation of the system was thus performed with
</bodyText>
<figure confidence="0.998871866666667">
OBJECTS
Domain: Bird
PROPERTIES Appearance
Range: Value
Length
Small bird
Size
Wingspan
Bird
Range:Number Range: String
Plumage
Cardinality: 0..N
Cardinality: 0..1
Migratory
bird
Pine
Grosbeak
Species
Winter
plumage
Finches
Family
Summer
plumage
Songbirds
Order
Eclipse
plumage
Hyponym/Meronym
User concept
Instance Of
Object instance
System concept
RELATIONS
Distribution
Range:
Geographic location
Domain: Bird
Range
Breeding
distribution
Cardinality: 0..N
Winter
distribution
Domain: Migratory bird
</figure>
<figureCaption confidence="0.99431">
Figure 2: A part of the integrated ontology representing the conceptualisations of both bird encyclopaedia
and users.
</figureCaption>
<bodyText confidence="0.832023666666667">
the goal of detecting problems concerning inter-
pretation, dialogue management, and representation
and use of domain knowledge.
</bodyText>
<subsectionHeader confidence="0.992088">
4.1 Data collection
</subsectionHeader>
<bodyText confidence="0.999982428571429">
BIRDQUEST is intended to be used by casual users
without previous experience of dialogue systems or
extensive knowledge of birds. It was therefore eval-
uated in a walk-up and use situation similar to a real
use situation during a day when the public was in-
vited to the university. In that respect the situation
resembles that of Gustafson and Bell (2000), though
slightly more controlled.
We had six machines running BIRDQUEST during
2 hours and 30 minutes and collected dialogues from
27 users. They received minimal instructions in ad-
vance, they were only told that the system can an-
swer questions on Nordic birds, that it understands
Swedish, and that the dialogue would be recorded.
The resulting corpus consisting of 27 dialogues
have a total number of 518 user utterances, with a
mean of 19 for each user. However, with individ-
ual differences, for instance, three users posing more
than 40 utterances to the system and three users pos-
ing less than 5.
Personal data about age, gender, interest in birds,
and knowledge of birds were collected together with
each dialogue. The users where of varying age, 5
female and 22 male. Most of them had no inter-
est in birds, nor any knowledge of birds. Thus, de-
spite having no interest in birds, they were fairly
representative of the intended users. Besides the
logged dialogue, the users were also asked to fill
out a small questionnaire on how they liked to use
the system. Most users thought the system was fun
to use, on a 10-graded scale we had a mean of 7.1.
The users also though that it was fairly easy to use
BIRDQUEST, mean 6.1. On the question how they
liked the system we had a score of 4.7, i.e. the users
neither disliked nor liked BIRDQUEST.
</bodyText>
<subsectionHeader confidence="0.999277">
4.2 Corpus annotation and initial analysis
</subsectionHeader>
<bodyText confidence="0.910077533333333">
As we had no predefined tasks we did not have
a situation that allowed for a controlled evalua-
tion, as e.g. PARADISE (Walker et al., 1998) or
PROMISE (Beringer et al., 2002). Instead we used
a combination of quantitative and qualitative ap-
proaches to analyse the collected dialogue corpus.
The dialogues were tagged in order to provide statis-
tics over successful and problematic information ex-
changes.
The user utterances were categorised as in Ta-
ble 1 and the categorisation of responses from
BIRDQUEST is presented in Table 2.
Table 1 shows that approximately half of the users
utterances (48%) were involved in successful infor-
mation exchanges where the user initiated an infor-
</bodyText>
<tableCaption confidence="0.996674">
Table 1: User utterances
</tableCaption>
<table confidence="0.9999483">
No of Percentage of
utterances user utterances
Interpretable
Requests 189 37%
Cooperative CR
Responses 55 11%
Uncooperative
CR responses 11 2%
Out of scope 121 23%
Mis-interpreted 141 27%
</table>
<tableCaption confidence="0.735163">
Table 2: System utterances
</tableCaption>
<table confidence="0.999196285714286">
No of Percentage of
utterances system utterances
Successful resp. 180 35%
Clarification req. 70 13%
Incorrect resp. 15 3%
Incorrect focus 16 3%
Error message 240 46%
</table>
<bodyText confidence="0.998992142857143">
mation request or answered a clarification request
from the system. We also see that 25% of the
user´s utterances are erroneous in some way and that
BIRDQUEST failed on 141 utterances, as will be fur-
ther discussed in section 5.
From Table 2 we see that BIRDQUEST presented
180 successful responses. A successful response
is a response where BIRDQUEST presents infor-
mation found in the database. A response where
the bird encyclopaedia does not include the infor-
mation and BIRDQUEST responds e.g. Information
on wing span is missing for magpie. is, however,
also considered successful. The reason being that
BIRDQUEST successfully accessed the database and
presented whatever information was there, includ-
ing cases where there was no information in the
database. Among the 180 there are 55 such re-
sponses, so they are not rare, and shows one of the
many interesting problems we encountered in the
development of a dialogue system based on infor-
mation extraction from a text book.
</bodyText>
<subsubsectionHeader confidence="0.341133">
4.2.1 Clarifications
</subsubsectionHeader>
<bodyText confidence="0.9809838">
Notable is that a fair amount of the dialogue
moves involve clarifications. The system initiates
70 clarification sub-dialogues in order to transform a
vague information request to a specific question, as
exemplified by the excerpt below 1.
</bodyText>
<table confidence="0.397383083333333">
U17: What do water fowls look like?
S18: Choose one of the following Water fowls: Barnacle
Goose, Tufted Duck, Bean Goose, Whooper Swan,
Gadwall,...
U19: gadwall
S20: You can receive information about the size and
plumage of a Gadwall. Please specify what you are
interested in.
U21: size
S22: A Gadwall has a length of 56 cm from beak tip to
tail.
Information about wingspan is missing for Gadwall
</table>
<bodyText confidence="0.988437676470588">
The basis for this type of clarification is domain
knowledge collected from the domain ontology. Ut-
terance U17 is under specified since the object, the
bird family ”Water fowls”, can refer to a number of
different species of birds, and the property ”Appear-
ance”, is vague. To pose clarification question S18,
information about which species belong to the given
family is gathered from the ontology and the user is
asked to chose one of them. Next, in S20, the ontol-
ogy is accessed to retrieve the sub-properties of ap-
pearance. When the user has chosen a specific prop-
erty (U21) the request is sufficiently specified. The
ontology is used to find the sub-properties of ”Size”
and these are then used to access the database and
the result is presented to the user (S22).
The users responded cooperatively to 55 clarifi-
cation requests from the system and incorrectly 11
times. A typical example of the latter is seen below.
S22: You can receive information about size and
plumage of a Blue Tit. Please specify what you are
interested in.
U23: blue tit
Dialogue management, such as clarification sub-
dialogues, thus plays an important role for the per-
formance of BIRDQUEST.
Contextual interpretation and dialogue history
management are other important dialogue phenom-
ena from MALIN that are frequently utilised in the
dialogues. Managing dialogue history is, however,
not trivial. There are 16 cases in the corpus, termed
Incorrect focus in Table 2, when BIRDQUEST
presents doubtful responses because of how dia-
logue history is handled, as will be further discussed
in section 5.1.
</bodyText>
<footnote confidence="0.954942">
1All examples are translations of excerpts from the Swedish
dialogue corpus.
</footnote>
<subsubsectionHeader confidence="0.452516">
4.2.2 Utterances out of scope for BIRDQUEST
</subsubsectionHeader>
<bodyText confidence="0.998167">
Approximately half of the non-successful user ut-
terances (23% of all user utterances) were ques-
tions that BIRDQUEST will never be able to an-
swer. Beringer et al. (2002) use the term incooper-
ative user for users who ”fall out of the role or pur-
posely misuse the system.”, and propose to exclude
them in evaluations. We include such users in our
corpus, but group them together in a wider category
called Out of scope.
Out of Scope utterances include user requests for
information that is outside the scope of the applica-
tion, such as How do you kill crows?, or socialisation
utterances (Gustafson and Bell, 2000) such as How
are you?. Utterances can also be out of the database’
scope, e.g. How high does a magpie fly? is such an
utterance since there is no information on how high
birds fly in the Bird encyclopaedia. These type of
requests are further discussed in section 5.5
The reason for grouping such utterances together
is that BIRDQUEST can never present information
to them. Instead, we need to add a number of
well-designed responses informing the user on the
system’s abilities. Utterances that are out of the
system’s scope require different types of responses
from the system, and the corpus gave us valuable in-
sights on the importance of system help messages
describing what BIRDQUEST can and cannot do.
</bodyText>
<subsubsectionHeader confidence="0.87087">
4.2.3 Utterances where BIRDQUEST fails
</subsubsectionHeader>
<bodyText confidence="0.998003055555555">
Finally, there are those utterances where the sys-
tem failed, i.e. those where an answer can be found
in the encyclopaedia, but where BIRDQUEST fails
to present a successful response for various reasons.
Such utterances comprise 27% of the users’ input.
We have further analysed these and categorised
them as being 1) spelling mistakes, 2) lexical gaps,
or 3) grammatically out of scope, as seen in Table 3.
Table 3 includes only utterances that can be success-
fully responded to, not, for instance, misspellings in
utterances that are out of the systems’ scope.
Table 3 only gives a very brief indication on the
nature of non-interpretable utterances in the corpus.
For instance, each utterance is tagged as being of one
type only, with misspellings having highest priority
and missing grammar rules the lowest. Furthermore,
there could be several misspellings in one utterance.
It is also the case that the categories overlap, i.e.
</bodyText>
<tableCaption confidence="0.8536645">
Table 3: User utterances not interpreted by
BIRDQUEST
</tableCaption>
<table confidence="0.8602154">
Percentage of
system utterances
Misspelled 28 5%
Not in lexicon 64 12%
Not in grammar 50 10%
</table>
<bodyText confidence="0.9952877">
utterances can belong to more than one category, e.g.
a misspelled word can also be missed in the lexi-
con. There are three such utterances tagged mis-
spelled that also contain words not in the lexicon. 11
of the utterances tagged misspelled cannot be han-
dled because of missing grammar rules. Thus, with
a spelling checker, BIRDQUEST can handle another
14 utterances, i.e. misspelling on its own only ac-
counts for 2,5% of the utterances that BIRDQUEST
cannot handle.
</bodyText>
<sectionHeader confidence="0.99959" genericHeader="method">
5 Implications for development
</sectionHeader>
<bodyText confidence="0.9999764">
Our main goal was to collect data for further de-
velopment. Utterances in the categories involving
unsuccessful information exchanges, such as incor-
rect responses and mis-interpretations, were there-
fore analysed more closely.
</bodyText>
<subsectionHeader confidence="0.900917">
5.1 Problematic focus management
</subsectionHeader>
<bodyText confidence="0.999613">
Focus management and methods to determine topic
shifts play an important role in many dialogue sys-
tems. Our corpus includes a variety of problematic
cases, that need further consideration, both on how
focus is handled in the dialogue manager and how
the grammar rules are constructed.
When a user poses a question that gives rise to
a partially interpreted request the dialogue manager
seeks the dialogue history to see if it can be contex-
tually specified. This works well in most cases when
utterances are elliptic but in some cases, especially
when the interpreter has failed to produce a complete
interpretation, it can cause faulty responses, see the
example below.
</bodyText>
<footnote confidence="0.772431142857143">
U35: How old does a common gull get?
S36: Information about the greatest age of a Common
Gull:
Greatest age: 29 years and 7 months
U37: What migratory birds exist?
S38: Information about range is missing for Common
Gull.
</footnote>
<bodyText confidence="0.999798130434783">
The reason for not being able to correctly inter-
preting U37 is that migratory birds is not a well de-
fined concept in the bird encyclopaedia2. Thus, only
a partial interpretation with the property ”Range”,
based on interpreting ”exist” as connected to a loca-
tion, is produced. The partial interpretation is then
combined with the object ”Common gull” from U35
and an incorrect response is produced in S38.
A more difficult problem to handle is when there
has been a long segment of uninterpreted user ut-
terances often after sequences of misspellings or re-
quests outside the scope of the system. Normally,
such sequences of utterances are contextually inter-
preted utilising the dialogue history and a successful
response can be presented to the user. There are,
however, also ”faulty” cases, as seen in the dialogue
fragment below3. Here, the user is trying to shift
focus and thus the property ”Feed” should not have
been inherited from the previous question (U11). A
more appropriate response in S18 would have been
You can receive information about a song thrush’s
flight, feed, breeding location, appearance,... Please
specify what you are interested in.
</bodyText>
<tableCaption confidence="0.71234075">
U11: What do the honey buzzard eat
S12: Information about feed for a Honey Buzzard:
Main feed consists of Honeycomb,[...]
U13: What birds can imitate speech
S14: Failed to interpret the question. Please try again
U15: Talking birds
S16: Failed to interpret the question. Please try again
U17: Song thrush
</tableCaption>
<bodyText confidence="0.956033214285714">
S18: Information about feed for a Song Thrush:
Worms, larvas and mollusc etc[...]
The problem of dialogue history and fo-
cus shifts does not have a simple solution.
Leceuche et al. (2000) use focus rules based on re-
lations between the various things in the domain
to track focus shifts. A similar approach is to en-
code the domain in a type hierarchy and use under-
specified feature structures to determine clarification
requests (Denecke, 1997). Jokinen et al. (1998) use
a topic model based on a tree organisation of domain
knowledge to detect topic shifts. Such approaches
would correctly handle the dialogue above and start
a new focus space after U13, as there is no relation
</bodyText>
<footnote confidence="0.9989">
2Many bird species do not migrate every year and often
some exemplars stay when most birds of that specie migrate
etc. cf. section 5.4.
3The Swedish name of Song thrush, (Sw. taltrast), can be
literally translated as ”Talking thrush”
</footnote>
<note confidence="0.8165075">
No of
utterances
</note>
<bodyText confidence="0.999955052631579">
between the items in U11-S12 and U13. However,
as we assume that it is a good idea to keep items
in focus even after user utterances with no previous
relation to the current focus (J¨onsson, 1995), such
mechanisms are not applicable here. For instance, if
the user instead typed ”U13b: magpi”, we would not
have a relation between the items in the utterances,
and can then not be able to correctly respond if the
user corrected that to ”U15b: magpie”.
Another approach is proposed by
Chu-Carroll (2000) who distinguish between task
initiatives and discourse initiatives that are identified
based on cues. These are then utilised to adopt
different interaction strategies. In BIRDQUEST
one solution could be to keep focus for discourse
initiatives and drop focus for new task initiatives.
In the dialogue above, U13, is to be considered a
new task initiative whereas U13b is not a new task
initiative and focus is maintained.
</bodyText>
<subsectionHeader confidence="0.999465">
5.2 Unnecessary clarifications
</subsectionHeader>
<bodyText confidence="0.98145202173913">
Since information extraction is used to populate the
database with information there can be holes in
it, i.e. for some properties values are missing due
to shortcomings in the information extraction com-
ponent or lack of information in the original text
source. This causes unnecessary clarifications. In
the example below a more appropriate answer to
U19 would have been to give information about size
instead of making a clarification since there is no in-
formation about plumage in the database.
U19: What does a mute swan look like?
S20: You can receive information about the size and
plumage of a Mute Swan. Please specify what you
are interested in.
U21: What do the plumage of a mute swan look like?
S22: Information about eclipse plumage is missing for
Mute Swan.
Information about winter plumage is missing for
Mute Swan.
Information about summer plumage is missing for
Mute Swan.
Information about breeding plumage is missing for
Mute Swan.
The database has many such missing values as
very often there was no information in the informa-
tion source. It is, thus, not possible to adopt general
dialogue strategies, for instance, for clarification re-
quests. Instead, the domain knowledge base must be
consulted to decide on a proper dialogue strategy for
each property.
In BIRDQUEST the unnecessary clarifications can
be dealt with through extended co-operation be-
tween the dialogue manager and the domain knowl-
edge manager. When a vague property is encoun-
tered the dialogue manager can send the request to
the domain knowledge manager for information on
suitable clarifications. By traversal of the ontology
the DKM can produce a set of sub-properties which
can be used to access the database. Should there
be only a few pieces of information these can be
returned directly as an answer to the request. Oth-
erwise the proper clarification is decided based on
the relation between the given property and the sub-
properties which produced the values.
Note, however, that such a strategy can violate the
learning aspect discussed below.
</bodyText>
<subsectionHeader confidence="0.961097">
5.3 Partial and empty answers
</subsectionHeader>
<bodyText confidence="0.999165115384615">
A problem related to unnecessary clarifications are
how partial and empty answers should be presented
to the user when a vague property has been mapped
to several sub-properties, for example ”Plumage” in
S22 in the example above, or ”Size” in the example
below.
S2: You can receive information about the size and
plumage of a Magpie. Please specify what you are
interested in.
U3: size
S4: Information about wingspan is missing for Magpie.
A Magpie has a length of 46 cm from beak tip to
tail.
In the case of empty answers, S22 above, an alter-
native could be to just state that Information about
plumage is missing for mute swan, and for partial
answers the sub-properties with missing information
could be omitted. However, including all the sub-
properties have a point in so far as it helps the user
learn what type of information the system can pro-
vide. A solution is to make a compromise and make
the system adaptive. This means that the first time a
vague property is mapped to a set of sub-properties
all of them are presented regardless of whether they
have values or not, thereafter empty answers can be
omitted.
</bodyText>
<subsectionHeader confidence="0.746018">
5.4 Ontological interpretation failures
</subsectionHeader>
<bodyText confidence="0.997875882352941">
Some seemingly simple interpretation failures that
have been tagged as missing information in the lexi-
con are actually more complicated and relates to the
representation of domain knowledge in the ontology.
For example, users tend to ask what colour a spe-
cific bird have, see U1 below4. However, in the bird
encyclopaedia colour is linked to the body parts of
a bird. The complex relation between the concept
”Bird” and the property ”Colour” via the body parts
thus have to be captured in the ontology so that this
knowledge can be used for interpretation and dia-
logue management.
U1: What colour is a blue tit?
S2: Failed to interpret the question. Please try again
With more information about how concepts and
properties are related, for example, through a chain
of hypernym and meronym relations, requests like
U1 could be dealt with. Since a bird consists of body
parts and body parts have colours the missing link in
the request is a body part and based on this a clarifi-
cation could be produced A bird has several colours
for different body parts. What part of the blue tit are
you interested in?
Migratory birds, as discussed in section 5.1, is
another example when the ontology can be used to
stipulate a certain interpretation. With the help of
an ornithologist, we can define what migrating be-
haviour constitutes a migratory bird and add that to
the ontology. Used by the information extraction
component, we can easily pick those birds that are
migratory birds, and as we utilise the same ontology
for the interaction component, we can interpret such
requests. Note, however, that this goes beyond our
initial goal of only utilising the bird encyclopaedia.
</bodyText>
<subsectionHeader confidence="0.996783">
5.5 Questions outside database coverage
</subsectionHeader>
<bodyText confidence="0.999939">
Users often posed questions that were outside the
database coverage. A successful interpretation of
such a request and an appropriate response is seen
in the dialogue below:
</bodyText>
<footnote confidence="0.68684275">
U1: What is the wingspan of an Albatross?
S2: There is no information on non-Nordic birds. The
available birds are listed in the menu ”Birds a-¨o”.
Please try again
</footnote>
<bodyText confidence="0.973710285714285">
The same strategy could be used to handle similar
questions concerning non-Nordic birds like canaries
and ostriches. However, that would require addition
of information of non-Nordic birds to the ontology
4Many of the requests for appearance can be handled by pre-
senting a picture of the bird. However, the pictures in our bird
encyclopaedia are copyrighted and can therefore not be pre-
sented.
collected from other sources than the bird encyclo-
pedia.
However, in most cases the requests concerned
properties that are not covered by the database but
users often ask about, for example ”Weight” and
”Flight-speed” as in How much does a Sea Gull
weigh? or How fast can an Eagle fly?. The common
response to these types of questions were Failed to
interpret the question. Please try again or in some
cases a partial interpretation was made which led to
inappropriate responses. A more desirable response
would be to give more informative error messages
and explain to the user that it cannot answer ques-
tions about these topics.
Extending the ontology could help give informa-
tive answers when the questions are outside database
coverage. The properties similar to those in the
database, such as ”Weight”, ”Flight-speed”, could
be added to the ontology as user-oriented proper-
ties. Since the DKM always have to map this type
of properties to the system-oriented sub-properties
before database access it could conclude that, if a
user-oriented property do not have any user-oriented
sub-properties, it is outside database coverage and
an appropriate answer can be given. If these prop-
erties were related to others, for example, ”Weight”
is a sub-property of ”Appearance”, the system could
even suggest some of the sibling properties, in this
case ”Size” and ”Plumage”.
Another strategy is to have BIRDQUEST respond
with help phrases explaining how to pose valid re-
quests, as is done in Targeted Help (Gorrell et al.,
2002). Targeted help is used for improving user be-
haviour in speech interfaces. It utilises the SLM-
based recognition and categorised help message
templates to present targeted help when the gram-
mar based recogniser fails. Thus, a system must
learn the most common types of mistakes which in
turn must be classified to provide a targeted help.
Unfortunately, we do not yet have a large enough
BIRDQUEST corpus for such classification.
</bodyText>
<sectionHeader confidence="0.998964" genericHeader="evaluation">
6 Summary
</sectionHeader>
<bodyText confidence="0.999795428571429">
In this paper we have presented an evaluation of
a dialogue system that was developed to access a
database built from information automatically ex-
tracted from a text book. The results from our eval-
uation show that it is possible to develop such a sys-
tem and that users staying within the boundaries of
the application will get useful information.
Dialogue is important for the interaction as well
as a shared ontology for both information extraction
and interaction. The evaluation also revealed a num-
ber of challenging issues, especially regarding, sys-
tem help messages, dialogue management, problems
with gaps in the database due to incomplete informa-
tion and how to utilise a domain ontology.
</bodyText>
<sectionHeader confidence="0.997554" genericHeader="conclusions">
7 Acknowledgement
</sectionHeader>
<bodyText confidence="0.9955964">
Many thanks to Frida And´en, Lars Degerstedt and
Sara Norberg for interesting discussions and work
on the development and implementation of the
BIRDQUEST system. This research is financed by
Vinnova, Swedish Agency for Innovation Systems
</bodyText>
<sectionHeader confidence="0.998342" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999315155844156">
Jan Alexandersson and Norbert Reithinger. 1995. De-
signing the dialogue component in a speech translation
system. In Proceedings of the Ninth Twente Workshop
on Language Technology (TWLT-9), pages 35–43.
Nicole Beringer, Ute Kartal, Katerina Louka, Florian
Schiel, and Uli T¨urk. 2002. Promise - a procedure
for multimodal interactive system evaluation. In Pro-
ceedings of the Workshop ’Multimodal Resources and
Multimodal Systems Evaluation’. Las Palmas, Gran
Canaria, Spain.
J. Burger, C. Cardie, V. Chaudhri, R. Gaizauskas,
S. Harabagiu, D. Israel, C. Jacquemin, C. Y. Lin,
S. Maiorano, G. Miller, D. Moldovan, B. Og-
den, J. Prager, E. Riloff, A. Singhal, R. Shrihari,
T. Strzalkowski, E. Voorhees, and R. Weishedel.
2001. Issues, tasks and program structures to
roadmap research in question &amp; answering (Q&amp;A).
http://wwwnlpir.nist.gov/projects/duc/papers/qa.
Roadmap-paper v2.doc.
Jennifer Chu-Carroll. 2000. MIMIC: An adaptive
mixed initiative spoken dialogue system for informa-
tion queries. In Proceedings of 6th Applied Natural
Language Processing Conference, pages 97–104.
Nils Dahlb¨ack, Annika Flycht-Eriksson, Arne J¨onsson,
and Pernilla Qvarfordt. 1999. An architecture for
multi-modal natural dialogue systems. In Proceedings
of ESCA Tutorial and Research Workshop (ETRW)
on Interactive Dialogue in Multi-Modal Systems, Ger-
many.
Matthias Denecke. 1997. An information-based ap-
proach for guiding multi-modal human-computer-
interaction. In IJCAI´97, Nagoya, Japan, pages 1036–
1041.
Annika Flycht-Eriksson and Arne J¨onsson. 2000. Dia-
logue and domain knowledge management in dialogue
systems. In 1st SIGdial Workshop on Discourse and
Dialogue, Hong Kong.
Genevieve Gorrell, Ian Lewin, and Manny Rainer. 2002.
Adding intelligent help to mixed initiative spoken dia-
logue systems. In Proceedings ofICSLP 2002.
Tom R. Gruber. 1993. A translation approach to
portable ontology specification. Knowledge Acquisi-
tion, 5:199–220.
Joakim Gustafson and Linda Bell. 2000. Speech tech-
nology on trial: Experiences from the august system.
Natural Language Engineering, 6(3-4):273–286.
Eli Hagen. 1999. An approach to mixed initiative spo-
ken information retrieval dialogue. User modeling and
User-Adapted Interaction, 9(1-2):167–213.
Arne J¨onsson and Magnus Merkel. 2003. Some issues in
dialogue-based question-answering. In Working Notes
from AAAI Spring Symposium, Stanford.
Kristiina Jokinen, Hideki Tanaka, and Akio Yokoo.
1998. Context management with topics for spoken di-
alogue systems. In Proceedings of the 36th Annual
Meeting of the Association of Computational Linguis-
tics and 17th International Conference on Computa-
tional Linguistics, COLING-ACL’98, Montreal, pages
631–637.
Arne J¨onsson. 1995. Dialogue actions for natural
language interfaces. In Proceedings of IJCAI-95,
Montr´eal, Canada.
Renaud Leceuche, Dave Robertson, Catherine Barry,
and Chris Mellish. 2000. Evaluating focus theories
for dialogue management. International Journal on
Human-Computer Studies, 52:23–76.
Kavi Mahesh and Sergei Nirenburg. 1995. A situated on-
tology for practical NLP. In Proceedings of IJCA’95
Workshop on Basic Ontological Issues in Knowledge
Sharing, Montreal, Canada.
Dan Sullivan. 2001. Document Warehousing and Text
Mining. John Wiley &amp; Sons.
Marilyn A. Walker, Diane J. Litman, Candace A. Kamm,
and Alicia Abella. 1998. Paradise: A framework for
evaluating spoken dialogue agents. In Mark Maybury
&amp; Wolfgang Wahlster, editor, Readings in Intelligent
User Interfaces. Morgan Kaufmann.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.433578">
<title confidence="0.9427145">Some empirical findings on dialogue management and domain ontologies in systems – Implications from an evaluation of</title>
<author confidence="0.760122">Annika</author>
<affiliation confidence="0.996767333333333">Department of Computer Information Link¨oping University,</affiliation>
<email confidence="0.886412">annfl@ida.liu.se</email>
<author confidence="0.967057">Arne</author>
<affiliation confidence="0.998148666666667">Department of Computer Information Link¨oping University,</affiliation>
<email confidence="0.971615">arnjo@ida.liu.se</email>
<abstract confidence="0.972495181818182">In this paper we present implications for development of dialogue systems, based on an evaluation of the system combine dialogue interaction with information extraction. A number of issues detected during the evaluation concerning primarily dialogue management, and domain knowledge representation and use are presented and discussed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jan Alexandersson</author>
<author>Norbert Reithinger</author>
</authors>
<title>Designing the dialogue component in a speech translation system.</title>
<date>1995</date>
<booktitle>In Proceedings of the Ninth Twente Workshop on Language Technology (TWLT-9),</booktitle>
<pages>35--43</pages>
<contexts>
<context position="5328" citStr="Alexandersson and Reithinger, 1995" startWordPosition="825" endWordPosition="828">(Flycht-Eriksson and J¨onsson, 2000). The former handles the dialogue whereas the latter handles access to various background information sources. The Dialogue Manager is responsible for controlling the flow of the dialogue by deciding how the system should respond to a user utterance. This is done by inspecting and contextually specifying the information structure produced by an interpretation module. The MALIN dialogue model classifies the discourse segments by general speech act categories, such as question (Q) and answer (A), rather than specialised (cf. (Hagen, 1999)), or domain related (Alexandersson and Reithinger, 1995). The dialogue manager instead utilise the focal parameters to control interaction (cf. (Jokinen et al., 1998; Denecke, 1997; J¨onsson, 1995)). In MALIN dialogue history is represented in dialogue objects with a parameter termed Objects, which identify a set of primary referents, and the parameter Properties which denote a complex predicate ascribed to this set. In BIRDQUEST Objects are normally birds and Properties model information about the birds, such as appearance, number of eggs and feed. The Domain knowledge manager receives requests from the dialogue manager and process them further us</context>
</contexts>
<marker>Alexandersson, Reithinger, 1995</marker>
<rawString>Jan Alexandersson and Norbert Reithinger. 1995. Designing the dialogue component in a speech translation system. In Proceedings of the Ninth Twente Workshop on Language Technology (TWLT-9), pages 35–43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicole Beringer</author>
<author>Ute Kartal</author>
<author>Katerina Louka</author>
<author>Florian Schiel</author>
<author>Uli T¨urk</author>
</authors>
<title>Promise - a procedure for multimodal interactive system evaluation.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop ’Multimodal Resources and Multimodal Systems Evaluation’. Las</booktitle>
<location>Palmas, Gran Canaria,</location>
<marker>Beringer, Kartal, Louka, Schiel, T¨urk, 2002</marker>
<rawString>Nicole Beringer, Ute Kartal, Katerina Louka, Florian Schiel, and Uli T¨urk. 2002. Promise - a procedure for multimodal interactive system evaluation. In Proceedings of the Workshop ’Multimodal Resources and Multimodal Systems Evaluation’. Las Palmas, Gran Canaria, Spain.</rawString>
</citation>
<citation valid="false">
<authors>
<author>J Burger</author>
<author>C Cardie</author>
<author>V Chaudhri</author>
<author>R Gaizauskas</author>
<author>S Harabagiu</author>
<author>D Israel</author>
<author>C Jacquemin</author>
<author>C Y Lin</author>
<author>S Maiorano</author>
<author>G Miller</author>
<author>D Moldovan</author>
<author>B Ogden</author>
<author>J Prager</author>
<author>E Riloff</author>
<author>A Singhal</author>
<author>R Shrihari</author>
<author>T Strzalkowski</author>
<author>E Voorhees</author>
<author>R Weishedel</author>
</authors>
<marker>Burger, Cardie, Chaudhri, Gaizauskas, Harabagiu, Israel, Jacquemin, Lin, Maiorano, Miller, Moldovan, Ogden, Prager, Riloff, Singhal, Shrihari, Strzalkowski, Voorhees, Weishedel, </marker>
<rawString>J. Burger, C. Cardie, V. Chaudhri, R. Gaizauskas, S. Harabagiu, D. Israel, C. Jacquemin, C. Y. Lin, S. Maiorano, G. Miller, D. Moldovan, B. Ogden, J. Prager, E. Riloff, A. Singhal, R. Shrihari, T. Strzalkowski, E. Voorhees, and R. Weishedel.</rawString>
</citation>
<citation valid="true">
<title>Issues, tasks and program structures to roadmap research</title>
<date>2001</date>
<booktitle>in question &amp; answering (Q&amp;A). http://wwwnlpir.nist.gov/projects/duc/papers/qa. Roadmap-paper v2.doc.</booktitle>
<marker>2001</marker>
<rawString>2001. Issues, tasks and program structures to roadmap research in question &amp; answering (Q&amp;A). http://wwwnlpir.nist.gov/projects/duc/papers/qa. Roadmap-paper v2.doc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer Chu-Carroll</author>
</authors>
<title>MIMIC: An adaptive mixed initiative spoken dialogue system for information queries.</title>
<date>2000</date>
<booktitle>In Proceedings of 6th Applied Natural Language Processing Conference,</booktitle>
<pages>97--104</pages>
<contexts>
<context position="25247" citStr="Chu-Carroll (2000)" startWordPosition="4089" endWordPosition="4090"> 3The Swedish name of Song thrush, (Sw. taltrast), can be literally translated as ”Talking thrush” No of utterances between the items in U11-S12 and U13. However, as we assume that it is a good idea to keep items in focus even after user utterances with no previous relation to the current focus (J¨onsson, 1995), such mechanisms are not applicable here. For instance, if the user instead typed ”U13b: magpi”, we would not have a relation between the items in the utterances, and can then not be able to correctly respond if the user corrected that to ”U15b: magpie”. Another approach is proposed by Chu-Carroll (2000) who distinguish between task initiatives and discourse initiatives that are identified based on cues. These are then utilised to adopt different interaction strategies. In BIRDQUEST one solution could be to keep focus for discourse initiatives and drop focus for new task initiatives. In the dialogue above, U13, is to be considered a new task initiative whereas U13b is not a new task initiative and focus is maintained. 5.2 Unnecessary clarifications Since information extraction is used to populate the database with information there can be holes in it, i.e. for some properties values are missi</context>
</contexts>
<marker>Chu-Carroll, 2000</marker>
<rawString>Jennifer Chu-Carroll. 2000. MIMIC: An adaptive mixed initiative spoken dialogue system for information queries. In Proceedings of 6th Applied Natural Language Processing Conference, pages 97–104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nils Dahlb¨ack</author>
<author>Annika Flycht-Eriksson</author>
<author>Arne J¨onsson</author>
<author>Pernilla Qvarfordt</author>
</authors>
<title>An architecture for multi-modal natural dialogue systems.</title>
<date>1999</date>
<booktitle>In Proceedings of ESCA Tutorial and Research Workshop (ETRW) on Interactive Dialogue in Multi-Modal Systems,</booktitle>
<location>Germany.</location>
<marker>Dahlb¨ack, Flycht-Eriksson, J¨onsson, Qvarfordt, 1999</marker>
<rawString>Nils Dahlb¨ack, Annika Flycht-Eriksson, Arne J¨onsson, and Pernilla Qvarfordt. 1999. An architecture for multi-modal natural dialogue systems. In Proceedings of ESCA Tutorial and Research Workshop (ETRW) on Interactive Dialogue in Multi-Modal Systems, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias Denecke</author>
</authors>
<title>An information-based approach for guiding multi-modal human-computerinteraction.</title>
<date>1997</date>
<booktitle>In IJCAI´97,</booktitle>
<pages>1036--1041</pages>
<location>Nagoya, Japan,</location>
<contexts>
<context position="5452" citStr="Denecke, 1997" startWordPosition="846" endWordPosition="848"> The Dialogue Manager is responsible for controlling the flow of the dialogue by deciding how the system should respond to a user utterance. This is done by inspecting and contextually specifying the information structure produced by an interpretation module. The MALIN dialogue model classifies the discourse segments by general speech act categories, such as question (Q) and answer (A), rather than specialised (cf. (Hagen, 1999)), or domain related (Alexandersson and Reithinger, 1995). The dialogue manager instead utilise the focal parameters to control interaction (cf. (Jokinen et al., 1998; Denecke, 1997; J¨onsson, 1995)). In MALIN dialogue history is represented in dialogue objects with a parameter termed Objects, which identify a set of primary referents, and the parameter Properties which denote a complex predicate ascribed to this set. In BIRDQUEST Objects are normally birds and Properties model information about the birds, such as appearance, number of eggs and feed. The Domain knowledge manager receives requests from the dialogue manager and process them further using domain knowledge, for example, disambiguation and mapping of vague concepts to ones more suitable for database access. I</context>
<context position="24258" citStr="Denecke, 1997" startWordPosition="3919" endWordPosition="3920">irds can imitate speech S14: Failed to interpret the question. Please try again U15: Talking birds S16: Failed to interpret the question. Please try again U17: Song thrush S18: Information about feed for a Song Thrush: Worms, larvas and mollusc etc[...] The problem of dialogue history and focus shifts does not have a simple solution. Leceuche et al. (2000) use focus rules based on relations between the various things in the domain to track focus shifts. A similar approach is to encode the domain in a type hierarchy and use underspecified feature structures to determine clarification requests (Denecke, 1997). Jokinen et al. (1998) use a topic model based on a tree organisation of domain knowledge to detect topic shifts. Such approaches would correctly handle the dialogue above and start a new focus space after U13, as there is no relation 2Many bird species do not migrate every year and often some exemplars stay when most birds of that specie migrate etc. cf. section 5.4. 3The Swedish name of Song thrush, (Sw. taltrast), can be literally translated as ”Talking thrush” No of utterances between the items in U11-S12 and U13. However, as we assume that it is a good idea to keep items in focus even af</context>
</contexts>
<marker>Denecke, 1997</marker>
<rawString>Matthias Denecke. 1997. An information-based approach for guiding multi-modal human-computerinteraction. In IJCAI´97, Nagoya, Japan, pages 1036– 1041.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annika Flycht-Eriksson</author>
<author>Arne J¨onsson</author>
</authors>
<title>Dialogue and domain knowledge management in dialogue systems.</title>
<date>2000</date>
<booktitle>In 1st SIGdial Workshop on Discourse and Dialogue,</booktitle>
<location>Hong Kong.</location>
<marker>Flycht-Eriksson, J¨onsson, 2000</marker>
<rawString>Annika Flycht-Eriksson and Arne J¨onsson. 2000. Dialogue and domain knowledge management in dialogue systems. In 1st SIGdial Workshop on Discourse and Dialogue, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Genevieve Gorrell</author>
<author>Ian Lewin</author>
<author>Manny Rainer</author>
</authors>
<title>Adding intelligent help to mixed initiative spoken dialogue systems.</title>
<date>2002</date>
<booktitle>In Proceedings ofICSLP</booktitle>
<contexts>
<context position="32892" citStr="Gorrell et al., 2002" startWordPosition="5352" endWordPosition="5355">ys have to map this type of properties to the system-oriented sub-properties before database access it could conclude that, if a user-oriented property do not have any user-oriented sub-properties, it is outside database coverage and an appropriate answer can be given. If these properties were related to others, for example, ”Weight” is a sub-property of ”Appearance”, the system could even suggest some of the sibling properties, in this case ”Size” and ”Plumage”. Another strategy is to have BIRDQUEST respond with help phrases explaining how to pose valid requests, as is done in Targeted Help (Gorrell et al., 2002). Targeted help is used for improving user behaviour in speech interfaces. It utilises the SLMbased recognition and categorised help message templates to present targeted help when the grammar based recogniser fails. Thus, a system must learn the most common types of mistakes which in turn must be classified to provide a targeted help. Unfortunately, we do not yet have a large enough BIRDQUEST corpus for such classification. 6 Summary In this paper we have presented an evaluation of a dialogue system that was developed to access a database built from information automatically extracted from a </context>
</contexts>
<marker>Gorrell, Lewin, Rainer, 2002</marker>
<rawString>Genevieve Gorrell, Ian Lewin, and Manny Rainer. 2002. Adding intelligent help to mixed initiative spoken dialogue systems. In Proceedings ofICSLP 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom R Gruber</author>
</authors>
<title>A translation approach to portable ontology specification.</title>
<date>1993</date>
<journal>Knowledge Acquisition,</journal>
<pages>5--199</pages>
<contexts>
<context position="7302" citStr="Gruber (1993)" startWordPosition="1144" endWordPosition="1145"> Interaction Component, while others are more general and used for several tasks in both components. These shared knowledge sources comprise lexicon, grammar, and domain ontologies. Building lexicon and grammars to be used for different tasks also involves several challenges but will not be further discussed in this paper. NAME: LATIN NAME: MAX WING: MIN WING: MAX HEIGHT: MIN HEIGHT: BR PLUMAGE: The term ontology is used very differently in various areas of computer science, ranging from simple taxonomies, meta data schemes, to logical theories. A general and commonly used definition given by Gruber (1993) is that ”An ontology is a formal, explicit specification of a shared conceptualisation”. A more practical view is to consider an ontology as ”a world model used as a computational resource for solving a particular set of problems” (Mahesh and Nirenburg, 1995), i.e. a database with information about what categories (or concepts) exist in the world/domain, what properties they have, and how they are related to one another. An ontology provides a common vocabulary that can be used to state facts and formulate questions about the domain. Constructing an ontology that can be shared by the Informat</context>
</contexts>
<marker>Gruber, 1993</marker>
<rawString>Tom R. Gruber. 1993. A translation approach to portable ontology specification. Knowledge Acquisition, 5:199–220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Gustafson</author>
<author>Linda Bell</author>
</authors>
<title>Speech technology on trial: Experiences from the august system.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<pages>6--3</pages>
<contexts>
<context position="12457" citStr="Gustafson and Bell (2000)" startWordPosition="1957" endWordPosition="1960">y bird Figure 2: A part of the integrated ontology representing the conceptualisations of both bird encyclopaedia and users. the goal of detecting problems concerning interpretation, dialogue management, and representation and use of domain knowledge. 4.1 Data collection BIRDQUEST is intended to be used by casual users without previous experience of dialogue systems or extensive knowledge of birds. It was therefore evaluated in a walk-up and use situation similar to a real use situation during a day when the public was invited to the university. In that respect the situation resembles that of Gustafson and Bell (2000), though slightly more controlled. We had six machines running BIRDQUEST during 2 hours and 30 minutes and collected dialogues from 27 users. They received minimal instructions in advance, they were only told that the system can answer questions on Nordic birds, that it understands Swedish, and that the dialogue would be recorded. The resulting corpus consisting of 27 dialogues have a total number of 518 user utterances, with a mean of 19 for each user. However, with individual differences, for instance, three users posing more than 40 utterances to the system and three users posing less than </context>
<context position="18883" citStr="Gustafson and Bell, 2000" startWordPosition="3033" endWordPosition="3036">for BIRDQUEST Approximately half of the non-successful user utterances (23% of all user utterances) were questions that BIRDQUEST will never be able to answer. Beringer et al. (2002) use the term incooperative user for users who ”fall out of the role or purposely misuse the system.”, and propose to exclude them in evaluations. We include such users in our corpus, but group them together in a wider category called Out of scope. Out of Scope utterances include user requests for information that is outside the scope of the application, such as How do you kill crows?, or socialisation utterances (Gustafson and Bell, 2000) such as How are you?. Utterances can also be out of the database’ scope, e.g. How high does a magpie fly? is such an utterance since there is no information on how high birds fly in the Bird encyclopaedia. These type of requests are further discussed in section 5.5 The reason for grouping such utterances together is that BIRDQUEST can never present information to them. Instead, we need to add a number of well-designed responses informing the user on the system’s abilities. Utterances that are out of the system’s scope require different types of responses from the system, and the corpus gave u</context>
</contexts>
<marker>Gustafson, Bell, 2000</marker>
<rawString>Joakim Gustafson and Linda Bell. 2000. Speech technology on trial: Experiences from the august system. Natural Language Engineering, 6(3-4):273–286.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eli Hagen</author>
</authors>
<title>An approach to mixed initiative spoken information retrieval dialogue. User modeling and User-Adapted Interaction,</title>
<date>1999</date>
<pages>9--1</pages>
<contexts>
<context position="5271" citStr="Hagen, 1999" startWordPosition="819" endWordPosition="820">domain knowledge management (DKM) (Flycht-Eriksson and J¨onsson, 2000). The former handles the dialogue whereas the latter handles access to various background information sources. The Dialogue Manager is responsible for controlling the flow of the dialogue by deciding how the system should respond to a user utterance. This is done by inspecting and contextually specifying the information structure produced by an interpretation module. The MALIN dialogue model classifies the discourse segments by general speech act categories, such as question (Q) and answer (A), rather than specialised (cf. (Hagen, 1999)), or domain related (Alexandersson and Reithinger, 1995). The dialogue manager instead utilise the focal parameters to control interaction (cf. (Jokinen et al., 1998; Denecke, 1997; J¨onsson, 1995)). In MALIN dialogue history is represented in dialogue objects with a parameter termed Objects, which identify a set of primary referents, and the parameter Properties which denote a complex predicate ascribed to this set. In BIRDQUEST Objects are normally birds and Properties model information about the birds, such as appearance, number of eggs and feed. The Domain knowledge manager receives reque</context>
</contexts>
<marker>Hagen, 1999</marker>
<rawString>Eli Hagen. 1999. An approach to mixed initiative spoken information retrieval dialogue. User modeling and User-Adapted Interaction, 9(1-2):167–213.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arne J¨onsson</author>
<author>Magnus Merkel</author>
</authors>
<title>Some issues in dialogue-based question-answering.</title>
<date>2003</date>
<booktitle>In Working Notes from AAAI Spring Symposium,</booktitle>
<location>Stanford.</location>
<marker>J¨onsson, Merkel, 2003</marker>
<rawString>Arne J¨onsson and Magnus Merkel. 2003. Some issues in dialogue-based question-answering. In Working Notes from AAAI Spring Symposium, Stanford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristiina Jokinen</author>
<author>Hideki Tanaka</author>
<author>Akio Yokoo</author>
</authors>
<title>Context management with topics for spoken dialogue systems.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association of Computational Linguistics and 17th International Conference on Computational Linguistics, COLING-ACL’98,</booktitle>
<pages>631--637</pages>
<location>Montreal,</location>
<contexts>
<context position="5437" citStr="Jokinen et al., 1998" startWordPosition="842" endWordPosition="845">d information sources. The Dialogue Manager is responsible for controlling the flow of the dialogue by deciding how the system should respond to a user utterance. This is done by inspecting and contextually specifying the information structure produced by an interpretation module. The MALIN dialogue model classifies the discourse segments by general speech act categories, such as question (Q) and answer (A), rather than specialised (cf. (Hagen, 1999)), or domain related (Alexandersson and Reithinger, 1995). The dialogue manager instead utilise the focal parameters to control interaction (cf. (Jokinen et al., 1998; Denecke, 1997; J¨onsson, 1995)). In MALIN dialogue history is represented in dialogue objects with a parameter termed Objects, which identify a set of primary referents, and the parameter Properties which denote a complex predicate ascribed to this set. In BIRDQUEST Objects are normally birds and Properties model information about the birds, such as appearance, number of eggs and feed. The Domain knowledge manager receives requests from the dialogue manager and process them further using domain knowledge, for example, disambiguation and mapping of vague concepts to ones more suitable for dat</context>
<context position="24281" citStr="Jokinen et al. (1998)" startWordPosition="3921" endWordPosition="3924"> speech S14: Failed to interpret the question. Please try again U15: Talking birds S16: Failed to interpret the question. Please try again U17: Song thrush S18: Information about feed for a Song Thrush: Worms, larvas and mollusc etc[...] The problem of dialogue history and focus shifts does not have a simple solution. Leceuche et al. (2000) use focus rules based on relations between the various things in the domain to track focus shifts. A similar approach is to encode the domain in a type hierarchy and use underspecified feature structures to determine clarification requests (Denecke, 1997). Jokinen et al. (1998) use a topic model based on a tree organisation of domain knowledge to detect topic shifts. Such approaches would correctly handle the dialogue above and start a new focus space after U13, as there is no relation 2Many bird species do not migrate every year and often some exemplars stay when most birds of that specie migrate etc. cf. section 5.4. 3The Swedish name of Song thrush, (Sw. taltrast), can be literally translated as ”Talking thrush” No of utterances between the items in U11-S12 and U13. However, as we assume that it is a good idea to keep items in focus even after user utterances wit</context>
</contexts>
<marker>Jokinen, Tanaka, Yokoo, 1998</marker>
<rawString>Kristiina Jokinen, Hideki Tanaka, and Akio Yokoo. 1998. Context management with topics for spoken dialogue systems. In Proceedings of the 36th Annual Meeting of the Association of Computational Linguistics and 17th International Conference on Computational Linguistics, COLING-ACL’98, Montreal, pages 631–637.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arne J¨onsson</author>
</authors>
<title>Dialogue actions for natural language interfaces.</title>
<date>1995</date>
<booktitle>In Proceedings of IJCAI-95,</booktitle>
<location>Montr´eal, Canada.</location>
<marker>J¨onsson, 1995</marker>
<rawString>Arne J¨onsson. 1995. Dialogue actions for natural language interfaces. In Proceedings of IJCAI-95, Montr´eal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Renaud Leceuche</author>
<author>Dave Robertson</author>
<author>Catherine Barry</author>
<author>Chris Mellish</author>
</authors>
<title>Evaluating focus theories for dialogue management.</title>
<date>2000</date>
<journal>International Journal on Human-Computer Studies,</journal>
<pages>52--23</pages>
<contexts>
<context position="24002" citStr="Leceuche et al. (2000)" startWordPosition="3874" endWordPosition="3877">ceive information about a song thrush’s flight, feed, breeding location, appearance,... Please specify what you are interested in. U11: What do the honey buzzard eat S12: Information about feed for a Honey Buzzard: Main feed consists of Honeycomb,[...] U13: What birds can imitate speech S14: Failed to interpret the question. Please try again U15: Talking birds S16: Failed to interpret the question. Please try again U17: Song thrush S18: Information about feed for a Song Thrush: Worms, larvas and mollusc etc[...] The problem of dialogue history and focus shifts does not have a simple solution. Leceuche et al. (2000) use focus rules based on relations between the various things in the domain to track focus shifts. A similar approach is to encode the domain in a type hierarchy and use underspecified feature structures to determine clarification requests (Denecke, 1997). Jokinen et al. (1998) use a topic model based on a tree organisation of domain knowledge to detect topic shifts. Such approaches would correctly handle the dialogue above and start a new focus space after U13, as there is no relation 2Many bird species do not migrate every year and often some exemplars stay when most birds of that specie mi</context>
</contexts>
<marker>Leceuche, Robertson, Barry, Mellish, 2000</marker>
<rawString>Renaud Leceuche, Dave Robertson, Catherine Barry, and Chris Mellish. 2000. Evaluating focus theories for dialogue management. International Journal on Human-Computer Studies, 52:23–76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kavi Mahesh</author>
<author>Sergei Nirenburg</author>
</authors>
<title>A situated ontology for practical NLP.</title>
<date>1995</date>
<booktitle>In Proceedings of IJCA’95 Workshop on Basic Ontological Issues in Knowledge Sharing,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="7562" citStr="Mahesh and Nirenburg, 1995" startWordPosition="1186" endWordPosition="1189">o involves several challenges but will not be further discussed in this paper. NAME: LATIN NAME: MAX WING: MIN WING: MAX HEIGHT: MIN HEIGHT: BR PLUMAGE: The term ontology is used very differently in various areas of computer science, ranging from simple taxonomies, meta data schemes, to logical theories. A general and commonly used definition given by Gruber (1993) is that ”An ontology is a formal, explicit specification of a shared conceptualisation”. A more practical view is to consider an ontology as ”a world model used as a computational resource for solving a particular set of problems” (Mahesh and Nirenburg, 1995), i.e. a database with information about what categories (or concepts) exist in the world/domain, what properties they have, and how they are related to one another. An ontology provides a common vocabulary that can be used to state facts and formulate questions about the domain. Constructing an ontology that can be shared by the Information Processing Component and the Interaction Component then gives us a possible way to bridge users’ expression and queries to the information contained in the unstructured documents. 3 Constructing the domain ontology A challenge when constructing a shared do</context>
</contexts>
<marker>Mahesh, Nirenburg, 1995</marker>
<rawString>Kavi Mahesh and Sergei Nirenburg. 1995. A situated ontology for practical NLP. In Proceedings of IJCA’95 Workshop on Basic Ontological Issues in Knowledge Sharing, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Sullivan</author>
</authors>
<title>Document Warehousing and Text Mining.</title>
<date>2001</date>
<publisher>John Wiley &amp; Sons.</publisher>
<contexts>
<context position="3397" citStr="Sullivan, 2001" startWordPosition="518" endWordPosition="519">ng component and an interaction component that, as a basis for their tasks, use a set of shared knowledge sources that define the scope of the language and domain. 2.1 The Information Processing Component The Information Processing Component takes collections of unstructured or semistructured documents and transforms them into structured information that can be used by the Interaction Component in the interaction with the user. The transformation utilise IE techniques, and the documents are analysed in several ways going through lexical and morphological, syntactical, and semantical analysis (Sullivan, 2001). A wide variety of pattern extraction rules are used to identify the relevant information as slots and fillers. The objective is to fill the database with relevant information and ignore text segments that do not meet the needs of the users. Figure 1 illustrates how unstructured text is transformed into slot and filler type information in the database. Original text Black-throated diver Gavia arctica 58-73 cm, wingspan 110-130 cm. In breeding plumage the head is gray and the throat is black, the sides of the throat striped in black and white. [...] Extracted information Black-throated diver G</context>
</contexts>
<marker>Sullivan, 2001</marker>
<rawString>Dan Sullivan. 2001. Document Warehousing and Text Mining. John Wiley &amp; Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
<author>Diane J Litman</author>
<author>Candace A Kamm</author>
<author>Alicia Abella</author>
</authors>
<title>Paradise: A framework for evaluating spoken dialogue agents.</title>
<date>1998</date>
<booktitle>Readings in Intelligent User Interfaces.</booktitle>
<editor>In Mark Maybury &amp; Wolfgang Wahlster, editor,</editor>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="13986" citStr="Walker et al., 1998" startWordPosition="2228" endWordPosition="2231">entative of the intended users. Besides the logged dialogue, the users were also asked to fill out a small questionnaire on how they liked to use the system. Most users thought the system was fun to use, on a 10-graded scale we had a mean of 7.1. The users also though that it was fairly easy to use BIRDQUEST, mean 6.1. On the question how they liked the system we had a score of 4.7, i.e. the users neither disliked nor liked BIRDQUEST. 4.2 Corpus annotation and initial analysis As we had no predefined tasks we did not have a situation that allowed for a controlled evaluation, as e.g. PARADISE (Walker et al., 1998) or PROMISE (Beringer et al., 2002). Instead we used a combination of quantitative and qualitative approaches to analyse the collected dialogue corpus. The dialogues were tagged in order to provide statistics over successful and problematic information exchanges. The user utterances were categorised as in Table 1 and the categorisation of responses from BIRDQUEST is presented in Table 2. Table 1 shows that approximately half of the users utterances (48%) were involved in successful information exchanges where the user initiated an inforTable 1: User utterances No of Percentage of utterances us</context>
</contexts>
<marker>Walker, Litman, Kamm, Abella, 1998</marker>
<rawString>Marilyn A. Walker, Diane J. Litman, Candace A. Kamm, and Alicia Abella. 1998. Paradise: A framework for evaluating spoken dialogue agents. In Mark Maybury &amp; Wolfgang Wahlster, editor, Readings in Intelligent User Interfaces. Morgan Kaufmann.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>