<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.998492">
Implicit Role Linking on Chinese Discourse:
Exploiting Explicit Roles and Frame-to-Frame Relations
</title>
<author confidence="0.998005">
Ru Li&apos; 2, Juan Wu&apos;, Zhiqiang Wang&apos; and Qinghua Chai3
</author>
<affiliation confidence="0.998116666666667">
1School of Computer and Information Technology
2Key Laboratory of Ministry of Education for Computation Intelligence and Chinese Information Processing
3School of Foreign Languages, Shanxi University, Taiyuan, China
</affiliation>
<email confidence="0.996364">
{liru,charles}@sxu.edu.cn, {wujuan_0922,zhiq.wang}@163.com
</email>
<sectionHeader confidence="0.997374" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999886">
There is a growing interest in research-
ing null instantiations, which are those
implicit semantic arguments. Many of
these implicit arguments can be linked to
referents in context, and their discoveries
are of great benefits to semantic process-
ing. We address the issue of automat-
ically identifying and resolving implicit
arguments in Chinese discourse. For their
resolutions, we present an approach that
combines the information about overtly la-
beled arguments and frame-to-frame rela-
tions defined by FrameNet. Experimental
results on our created corpus demonstrate
the effectiveness of our approach.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999901815789474">
In natural discourse, only a small proportion of
the theoretically possible semantic arguments of
predicates tend to be locally instantiated. Other
locally unrealized semantic roles are called null
instantiations (NIs). Nevertheless, many of these
implicit roles, while linguistically unexpressed,
can often be bound to antecedent referents in
the discourse context. What’s more, capturing
such implicit semantic roles and linking them
to their antecedents can dramatically help text
understanding.
Example (1) shows an analyzed result (Li,
2012) by employing Chinese FrameNet (Liu,
2011), which is a lexical semantic knowledge base
based on the frame semantics of Fillmore (1982)
and takes Berkeley’s FrameNet Project (Baker et
al., 1998) as the reference. In Chinese FrameNet,
the predicates, called lexical units (LU), evoke
frames which roughly correspond to different
events or scenarios. Each frame defines a set of
arguments called Frame Elements (FE). The set
of FEs is further split into core FEs and non-core
FEs. Particularly, the core FEs are the essential
components of a frame and can be defined by
themselves. However, not all core FEs of a frame
can be realized simultaneously in a sentence.
These non-instantiated FEs are considered as null
instantiations of the frame elements. Depending
on the interpretation type of the omission, Chinese
FrameNet divides the NIs into two categories: 1)
Indefinite Null Instantiations (INIs), the missing
element which can be understood given interpre-
tational conventions and do not need resolution,
and 2) Definite Null Instantiations (DNIs), the
missing element which is something that can be
understood in the linguistic or discourse context,
and the fillers need to be inferred from the context
through resolutions.
</bodyText>
<equation confidence="0.423965">
(1) [U ¥(]Entityt+´ át,_J [Ait¥(]Category, 4&amp;quot;
��¥(�Ï&amp;¥(���¥(�Óá�_Jo
</equation>
<bodyText confidence="0.6984665">
[The celestial burial satellite]Entity is Being-in-category
[artificial satellite]Category , and belongs to the same
category with reconnaissance, communications and
meteorological satellite.
</bodyText>
<footnote confidence="0.577616">
�ÓbS´&gt;llå���´�i7&gt;ll t� Ix�bS;rkÝ
7rT-Ó,—f&amp;A* ¦6 [5&apos;1,YP/**_if43000õ�kY_k
0-*&amp;quot;A--E]Goalo[Theme DNI] [Agent INI]
</footnote>
<bodyText confidence="0.9664574">
The purpose is different, specially used for storing
the urn; due to the different heights, generally
launched Cause-motion into [the orbit over 3000 kilo-
meters away from the surface of earth]Goal. [Theme
DNI] [Agent INI]
Particularly, in example (1), lexical unit (or
target) launched/u* evokes the semantic frame
Cause_motion, which has nine core FEs,
namely Agent, Theme, Source, Path, Goal, Area,
Cause, Result, Initial_State, but only one of them
is instantiated, i.e. Goal, whose filler is [the orbit
over 3000 kilometers away from the surface of
earth/5å/¥L¡3000 õ���������].
For another core FE Theme, it is filled by [The
celestial burial satellite/U ¥(] that occurs in
</bodyText>
<page confidence="0.69477">
1263
</page>
<note confidence="0.966277666666667">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 1263–1271,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.998588571428571">
the previous sentence.
Clearly, human beings have no problem to
infer these uninstantiated roles and find the cor-
responding fillers based on the relevant context
information, but this is beyond the capacity of
state-of-the-art semantic role labeling systems.
Next, we formalize the problem as follows:
given a discourse D = {51, 52, ..., 5n}, where
5k (k E [1, n]) is the k-th sentence in D. The
lexical unit set in 5k is Tk = {Tk1, Tk2, ...,Tkp},
and Fk = {Fk1, Fk2,..., Fkp} is relevant frame
set. For a particular frame Fki (i E [1, p]), its core
FE set is Eki = {e1, e2,..., em}, but it is possible
that only part of core FEs Cki appears in 5k,
i.e. Cki ⊆ Eki. Apparently the set Eki − Cki
includes the uninstantiated core FEs. Thus, we
need to determine which elements in Eki − Cki
are null instantiations. If em (em E Eki −Cki) has
been identified as a null instantiated FE, we should
determine whether em is a DNI. If so, we need to
find the corresponding antecedent dm in context.
The major contributions of this paper can be
summarized as follows:
(i) We have created a null instantiation (NI)
annotations corpus, consisting of 164 Chinese
discourses across different fields.
(ii) We use frame-to-frame relations to find
antecedents from those explicit semantic roles.
</bodyText>
<sectionHeader confidence="0.999892" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999666152777778">
Among the researches of null instantiation on
English, the most representative work is the
task “Linking Events and Their Participants in
Discourse” shared by the SemEval-2010 (Ruppen-
hofer et al., 2010). The two systems participated
in the NI resolution task, VENSES++ and SE-
MAFOR, took very different approaches.
Tonelli and Delmonte (2010) develop a
knowledge-based system called VENSES++,
and describe two strategies depending on the
predicate class (either nominal or verbal). For
verbal predicates, they try to map the predicate
argument structure extracted by VENSES with
the valence patterns generated from FrameNet
data, to identify missing arguments. And NIs
are resolved by reasoning about the semantic
similarity between an NI and a potential filler
using WordNet. For nominal predicates, they
resolve NIs by utilizing a common sense reasoning
module that builds on ConceptNet (Liu and Singh,
2004). The final Precision and Recall are 4.62%
and 0.86% respectively.
Later on, Tonelli and Delmonte (2011) propose
a simpler role linking strategy that based on
computing a relevancy score for the nominal head
of each potential antecedent. The intuition is that
heads which often serve as role fillers and occur
close to the target NI are more likely to function
as antecedents for the NI. Finally they reported an
F-score of 8% for role linking. However, being
strongly lexicalized, their trained model seems
heavily dependent on the training data.
The second system (Chen et al., 2010) is
statistical based and extends an existing semantic
role labeler (Das et al., 2010). Resolving DNIs
is modeled in the same way as labeling overt
arguments, with the search space being extended
to nouns, pronouns, and noun phrases from the
previous three sentences. When evaluating a
potential filler, the syntactic features used in
argument labeling of overt arguments are replaced
by two semantic features: firstly the system checks
whether a potential filler fills the null instantiated
role overtly in at least one of the FrameNet sen-
tences and train data, if not, the system calculates
the distributional similarity between filler and role.
While this system achieved 5% in F-score, data
sparseness is a potential limiting factor.
Also closely related studies are as follows.
Silberer and Frank (2012) cast NI resolution as
a coreference resolution (CR) task, and employ
an entity-mention model. They experiment with
features of SRL and CR, and automatically expand
the training set with examples generated from
coreference corpus to avoid data sparseness, ulti-
mately achieving F-score of 7.1%.
Gorinski et al. (2013) present a weakly su-
pervised approach that investigates and combines
a number of linguistically motivated strategies,
which consist of four basic NI resolvers that
exploit different types of linguistic knowledge,
and achieve F-score of 12%.
Wang et al. (2013) conduct DNI resolution
on SemEval2010 task10 data. They considered
the task as a classified problem, by adding new
features such as the information of head word
and frame to traditional features, proposed a
rule to choose the best candidate words set and
combination of features, achieving F-score of
14.65% finally.
Laparra and Rigau (2013) present an attempt to
apply a set of features that have been traditionally
</bodyText>
<page confidence="0.989848">
1264
</page>
<bodyText confidence="0.999956465116279">
used to model anaphora and coreference resolu-
tion tasks to implicit argument resolution, and got
the best results: F-score of 18%.
For nominal predicates, Gerber and Chai (2010)
investigate the linking of implicit arguments using
the PropBank role labeling scheme. In contrast to
the SemEval task, which focuses on a verbs and
nouns, their system is only applied to nouns and
is restricted to 10 predicates with 120 annotated
instances per predicate on average. They propose
a discriminative model that selects an antecedent
for an implicit role from an extended context
window. The approach incorporates some aspects
relating to CR that go beyond the SRL oriented
SemEval systems: A candidate representation
includes information about all the candidates’
coreferent mentions (determined by automatic
CR), in particular their semantic roles (provid-
ed by gold annotations) and WordNet synsets.
Patterns of semantic associations between filler
candidates and implicit roles are learned for all
mentions contained in the candidate’s entity chain.
They achieve an F-score of 42.3%, which is
noticeably higher than those obtained on the
SemEval data.
And Gerber (2011) presents an extended model
that incorporates strategies suggested in Burchardt
et al. (2005): using frame relations as well as
coreference patterns acquired from large corpora.
This model achieves an F-score of 50.3%.
Lei et al. (2013) conduct DNI identification on
SemEval2010 task10 data. They adopt the method
of combining rules and machine learning. Differ-
ent from them, we conduct two-level identifying
for NI detection and use more features on Chinese
data. Wang et al. (2013) take noun phrases and
pronoun as candidate words for DNI filler. We use
several similar features with them. The differences
are that 1) we take the fillers of overt instantiated
FE as candidate words and 2) we use Frame-to-
Frame relations. And Gerber (2011) also used
frame relations. Different from them, we limit
relation paths to 2.
</bodyText>
<sectionHeader confidence="0.997443" genericHeader="method">
3 Null Instantiation Detection
</sectionHeader>
<bodyText confidence="0.99996">
Now, we are ready to address the first subtask, i.e.
null instantiation detection.
</bodyText>
<subsectionHeader confidence="0.996841">
3.1 Frame element relations
</subsectionHeader>
<bodyText confidence="0.99962488">
Not all core arguments of all frames can be
realized simultaneously. Some frames involve
core FEs that are mutually exclusive. In example
(2), in the Amalgamation frame, there are
four core FEs, namely Part_], Part_2, Parts and
Whole, in which the first two FEs are mutually
exclusive with Parts, thus formed an Excludes
relation (relation 1). At the same time, Part_]
and Part_2 are in a Requires relation (relation
2), which means that if one of these two core
FEs is present, then the other must occur as well.
FE Whole, the result of the Amalgamation,
is only existentially bound within the discourse,
annotated as NI.
CoreSet (relation 3) specifies that at least one
of the set must be instantiated overtly, though
more of them can also be instantiated. As shown
in example (3), in the Awareness frame, the
two FEs Content and Topic are in one CoreSet.
As Content is overtly realized, we consider Topic
is not annotated as NI. The frame owning this
relation is complicated. Sometimes, if one FE of
this set is explicit, the absence of the other FEs in
the set is not annotated as NI, but sometimes it is
not true.
</bodyText>
<figure confidence="0.260007571428571">
(2) [1EJ**]]Part_1 �-[***1]Part_2 o g#g _—Ag�o
[Whole INI]
[The old system]Part_1 and [the new system]Part_2
are combined Amalgamation together. [Whole INI]
(3) [4*� K]Cognizer ¢vx [41t0*4-]Contento
[Your boss]Cognizer is awareAwareness [of your com-
mitment ]Content .
</figure>
<subsectionHeader confidence="0.999733">
3.2 Modeling Null Instantiation detection
</subsectionHeader>
<bodyText confidence="0.999981947368421">
As shown in example (1), given a frame Fki
(e.g. Cause—motion evoked by launched/k
At), NI detector needs to determine whether core
FEs in EFki − subEFki are missing, relying on
information about the three types of the relations
among core FEs: CoreSetFki, ExcludesFki,
RequiresFki (as discussed in Section 3.1). In
Cause—motion, the core FEs Initial_State,
Goal, Path, Source and Result belong to the
same CoreSet, and Goal is instantiated, thus
Initial_State, Path, Source and Result are not
annotated as NIs. Meanwhile core FEs Goal and
Area are connected by the Excludes relation, so
do Cause and Agent. Therefore, according to the
context, Area and Cause are not annotated as NIs.
Our approach for performing this detection
is described as follows. For the first-level of
detection, we make full use of the three types of
relations, and adopt a rule-based strategy proposed
</bodyText>
<page confidence="0.941588">
1265
</page>
<bodyText confidence="0.999449315789474">
by Lei et al. (2013) to detect NIs. As for CoreSet
relation, in particular, as long as one of the FEs in
this set is expressed overtly, NIs are not annotated
for the absence of the other FEs in the set. If
none of CoreSet is expressed, the contextually
most relevant one should be annotated as a NI.
However, this is difficult for automatic detector,
which inevitably introduces some false detected
NIs.
Thus, we conduct a second-level identifying. To
be specific, for the current lexical unit, i.e. the
target word, we collect its frame element patterns
from the training dataset. Frame element patterns
are annotated semantic roles, which include the
roles annotated as NIs. Taking lexical unit
launched/uAt as an example, Table 1 shows its
frame element patterns in our data. Depending on
this kind of patterns, we are able to filter out some
false NIs effectively.
</bodyText>
<table confidence="0.893413">
Patte1 Time AgentINI Theme GoalINI
Patte2 Agent Theme GoalINI
</table>
<tableCaption confidence="0.9750145">
Table 1: Frame element patterns for the target A
At /launched in our data
</tableCaption>
<sectionHeader confidence="0.994472" genericHeader="method">
4 Definite Null Instantiation
Identification
</sectionHeader>
<bodyText confidence="0.999870727272727">
In this section, we focus on our second task of
definite null instantiation (DNI) identification.
Before performing the implicit argument reso-
lution in discourse, we have to decide which null
instantiated frame elements should be selected, i.e.
which null instantiations are definite. As shown
in example (1) above, assuming one detected null
instantiated FE in the previous step is em (e.g.
Theme), we should determine whether em needs
to be filled or not, that is, we should determine em
as DNI or INI.
</bodyText>
<subsectionHeader confidence="0.281048">
Num Feature names Feature Descriptions
</subsectionHeader>
<tableCaption confidence="0.861825333333333">
T1 Target Target predicate
T2 Pos The part of speech of target
T3 Frame The frame that target evokes
T4 FENI NI of frame elements
T5 FE Overtly expressed FEs
Table 2: Features description in DNI Identification
</tableCaption>
<bodyText confidence="0.99993575">
We treat this issue as a classification problem,
and build a binary maximum entropy model to
predict the null instantiation type of em. Table
2 lists all features used for training our models.
In addition, we employ some similar features that
were used in Lei et al. (2013). Meanwhile, we
choose to learn a SVM classifier for comparison
purpose.
</bodyText>
<sectionHeader confidence="0.995671" genericHeader="method">
5 Definite Null Instantiation Resolution
</sectionHeader>
<bodyText confidence="0.99715">
In this section, we tackle the last subtask, namely
definite null instantiation resolution.
</bodyText>
<subsectionHeader confidence="0.981158">
5.1 Frame-to-Frame Relations
</subsectionHeader>
<bodyText confidence="0.999827285714286">
The relations of Frame-to-Frame and FE-to-FE in
FrameNet, serve as important information sources,
to be leveraged for DNI resolutions.
FrameNet arranges frames into a net by defining
frame-to-frame relations, including Inheritance,
Inchoative Of, Subframe, Causative Of, Precedes,
Using, See_also and Perspective On. In the case
of Inheritance relation, it defines two frames,
i.e. one more general frame and the other more
specific frame. The specific frame Commerce
buy, for example, is inherited from the general
frame Getting.
As Figure 1 shows, the inheritance relation
allows a general frame (e.g., Getting) to be
specialized with a particular semantic interpreta-
tion (e.g., Commerce buy). Also the inheritance
relation exists between the frame elements of two
related frames. Each of the inheriting FEs contains
all semantic properties of the inherited general
frame elements and also owns its additional pri-
vate properties.
</bodyText>
<figureCaption confidence="0.998195">
Figure 1: FE-FE relations of frame Getting and
</figureCaption>
<figure confidence="0.990904355555555">
Commerce buy
Ncore
Ncore
Ncore
Ncore
Ncore
Ncore
Ncore
Ncore
Core
Core
Getting
Explanation
Recipient
Purpose
Manner
Theme
Source
Means
Result
Time
Place
Ncore
Ncore
Ncore
Ncore
Commerce buy
Ncore
Ncore
Ncore
Ncore
Ncore
Core
Core
Explanation
Purpose
Manner
Money
Means
Goods
Buyer
Seller
Time
Place
Rate
</figure>
<page confidence="0.888112">
1266
</page>
<table confidence="0.9922235">
Number Features Name Features Description
T1 F1 DistCT The number of sentences between candidate FE content and target
F2 CanFEcon Candidate frame element content
F3 CanFEpt The phrase type or POS of candidate frame element content
T2 F4 Frame The frame that target predicate evokes
F5 FEDNI DNI frame element
F6 Target Target predicate
F7 TargetPOS The part of speech of target
</table>
<tableCaption confidence="0.9939">
Table 3: Features description in Overt Frame Elements Based Resolver
</tableCaption>
<subsectionHeader confidence="0.918705">
5.2 Modeling Definite Null Instantiation
Resolution
</subsectionHeader>
<bodyText confidence="0.984865666666667">
After accomplishing the previous processes, we
can perform DNI resolutions. If the uninstantiated
FE em (e.g., Theme in example (1)) has been
identified as DNI previously, we need to find the
corresponding antecedent mention dm (e.g., [The
celestial burial satellite/�k A 17. �K] in example
(1)). Due to having fine-grained frame semantic
role labeled for each sentence, we think the filler
of DNI maybe also instantiates the FE of other
annotated frames in the context. Therefore, we
collect the overt FE content set cp instantiated in
the discourse, and this set forms the overall set of
candidates for DNI linking. Then, for DNI em, a
subset of candidates cpm (cpm ⊆ cp) is chosen as
candidate search space for resolving em.
We implement two semantic resolvers based
on different methods. For either of these two
resolvers, if two or more candidates score equally
well, the one closest to the target predicate is
chosen.
OvertFE is based on machine learning, and FFR
is an inference method. As the inherent difficulty
of task, it’s difficult to find all fillers for DNIs only
using one of them. Thus finally we simultaneously
employ OvertFE and FFR to find as many fillers
for DNIs as possible.
Overt Frame Elements Based Resolver
(OvertFE)
This resolver is based on the assumption that the
filler of DNI can be found among the overt FE
content set in context. Given a DNI em , DNI
linking can be treated as a classification problem
to judge whether a candidate overt FE content
d (d ∈ cpm) could be taken as filler of a DNI.
Therefore, we employ a classification method to
solve the problem. Clearly, the performance of
classifiers largely depends on constructed features.
Since corresponding antecedent of DNI is not
overtly expressed, it is difficult to get some
information from context to describe them. What
we take as features is the information of candidate
frame element contents and frame information.
Table 3 lists all features used for training our
models. Some similar features were employed
by Wang et al. (2013) where they also considered
DNI linking as a classification problem.
Then maximum entropy models, widely used
in natural language processing (such as Chinese
word segmentation and machine translation), are
employed to predict whether a candidate FE
content is the filler of DNI.
</bodyText>
<sectionHeader confidence="0.7824955" genericHeader="method">
Frame-to-Frame Relations Based Resolver (F-
FR)
</sectionHeader>
<bodyText confidence="0.98442252">
Another way of finding the correct filler is through
searching Frame-to-Frame relations in a given
context window. This is because Frame-to-Frame
relations and FE-to-FE relations can provide rel-
evant information for finding DNI filler among
candidate frame element contents. Specifically,
for one frame f1 that contains a DNI, firstly we
need to find related frame f2 with it from context.
Then, if DNI frame element in f1 has relation with
the frame element (marked with fe2) of f2, the
filler of fe2 is the corresponding filler of this DNI.
The detailed steps are reported in Algorithm 1.
If frame names are the same, we think they
are related, and Figure 2 illustrates this case.
As the frames evoked in two sentences are both
Arriving, we link the antecedent of Goal in
the second sentence to [Tiananmen Square/US
f])-Vii], which is the content of Goal in the first
sentence.
For other cases, we use the related frames
which at most contain two relation paths (e.g.,
the paths from Event to Process_start to
Activity_start in Figure 3). As shown in
Figure 3, the target initiated/k 4—e in the first
sentence evokes the Activity_start frame,
</bodyText>
<page confidence="0.984981">
1267
</page>
<bodyText confidence="0.98499124">
in which the two frame elements (Agent, Place) is
expressed in a single constituent [our country/A
PJ], i.e. the phenomenon of frame element
fusion arises. Frame Event is evoked by the
target happened/t4 AX in the second sentence,
where Time and Event FEs are expressed overt-
ly, except the core FE Place. In the net of
FrameNet, frame Activity_start inherits
from the frame Process_start which further
inherits from the Event frame. These inheritance
relationships also hold between the frame ele-
ments of the related frames. According to the FE-
to-FE relations, the content of FE Place in the first
sentence, [our country/·I], is the corresponding
filler of implicit FE Place in the second sentence.
Algorithm 1 : Frame-to-Frame Relations Based
Resolver
Input: The frame set in discourse is F =
{f1, f2, ..., fn}; overt core frame element set
for frame fi is Ei = {e1, e2, ..., em}, its corre-
sponding filler set is Ai = {a1, a2, ..., am}; one
frame that contains DNI e* is f*, target t evokes
the frame f*; dis (ai, t) is the distance between
DNI filler ai and target t; relationpath (fi, f*)
are the relation paths from fi to f*; Atemp is
</bodyText>
<equation confidence="0.61325275">
temporary DNI filler set
Output: the filler a* of DNI e*
Atemp = 0
for each fi E F do
</equation>
<bodyText confidence="0.7423665">
if fi has frame relation with f* AND
relationpath (fi, f*) G 2 then
</bodyText>
<equation confidence="0.747761647058824">
for each ei E Ei, ai E Ai do
if ei has relation with e* then
ai E Atemp
end if
end for
else if fi = f* then
ai E Atemp
end if
end for
if Atemp =� 0 then
for ai E Atemp do
if dis (ai, t) is minimum then
a* = ai
end if
end for
end if
return a* ;
</equation>
<figureCaption confidence="0.9988345">
Figure 2: Two consecutive sentences owning the
same frame. Bold fonts represent lexical units or
frames. Dashed boxes represent FEs.
Figure 3: Two consecutive sentences owing related
frames. Bold fonts represent lexical units or frames.
Dashed boxes represent FEs.
</figureCaption>
<sectionHeader confidence="0.998645" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<subsectionHeader confidence="0.998845">
6.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.998356">
Data: Experimental data set comes from Semantic
Computing and Chinese FrameNet Research Cen-
tor of Shanxi University1. Because of the current
low performance of CFN automatic semantic anal-
ysis systems, all discourses are labeled semantic
roles manually, and the process is similar with the
FrameNet annotation.
First, the ICTCLAS are used for part-of-speech
tagging (omitted in examples), and we treat verbs,
adjectives and nouns in each sentence as potential
targets. As not all potential targets can be
annotated, it is necessary to identify those targets
which can evoke frames.
Then, we choose corresponding frames for
those targets. For one verb target launched/k
* in example (1), we find its evoked frame
Cause_motion.
Then annotate semantic roles for those con-
stituents which share syntactical relations with this
target, so the span [the orbit over 3000 kilometers
away from the surface of earth/5å/¥L¡3000
�a`&apos;it �] is annotated as role Goal,
which is, however, the only one instantiated, out
of nine Cause_motion’s core frame elements.
So according to the context and frame element
relations, we need to determine whether each
</bodyText>
<footnote confidence="0.935917">
1http://sccfn.sxu.edu.cn/
</footnote>
<bodyText confidence="0.440417">
On October 3rd , we
Within only three to five minutes, a dozen people all arri,ed .
</bodyText>
<figure confidence="0.995638923076923">
t0䊣3㦶䎃㳍 ᷍㸳㗨 ➕kiZ㬒iq ㎕⭞ T㳍➓㗦⺄⧂o
Time Thm Goal
Arriving
䐜㧞㹆⳷䐴䐏㚻᷍
Time Thm
came to Tiananmen Square at the appointed time.
㬏゙⷗㦬 䄜⷗⤜㩺㦌 ⭞ To
Arriving
Goal DNI
Time
Event
Event
㹆㬏㛋⫛ ᷍ 㸳⺛ 䋙 ⳃ㡑 ➲ 㕊㦙 䔘㸋 㯥⼇ ㎕ 㼜㘑 ⭥ 䊬Ⱀ᱄
In the 50&apos;s, our country initiated
Time Agent Place
the movement of killing sparrows.
Activity
Activity_start
Process_start
Time Place Event
Place DNI
However, in the years after the vastly killing of sparrows,
a plague of insects happened.
Abri,
A #L kk -ML zt1r.- 0 )L$Y. ,
- pt T)&apos;*0*eco
</figure>
<page confidence="0.984035">
1268
</page>
<bodyText confidence="0.999361176470588">
missing frame element should be annotated as
DNI or INI.
Next, we generate the XML format for our
annotated corpus, which is similar to the data
format in SemEval-10 Task 10.
Our 164 discourses had been annotated by one
person (to make it consistent), and they consist
of 57 discourses from People’s Daily and 107
discourses from Chinese reading comprehension,
which cover technology, health care, social, geog-
raphy and other fields. Each discourse contains
10 sentences in average. The data set contains
about 37526 words in 1618 sentences; it has
175 frame types, including 2283 annotated frame
instances. Table 4 shows the detailed statistics
of our data set. we’ll share our data in the
website(http://sccfn.sxu.edu.cn/).
</bodyText>
<figure confidence="0.39392525">
frame frame
discourses sentences INIs DNIs
inst. types
164 1618 2283 175 213 212
</figure>
<tableCaption confidence="0.979819">
Table 4: Corpus Statistics
</tableCaption>
<bodyText confidence="0.982926857142857">
Definite Null Instantiation identification and
resolution model: Our maximum entropy classi-
fication model uses the toolkit from Zhang (2005)
with the default parameter values. The SVM
classifier for comparison was trained via SVM
toolkit LIBSVM with the default parameter values
too.
</bodyText>
<subsectionHeader confidence="0.999195">
6.2 Experimental Results
</subsectionHeader>
<bodyText confidence="0.9994938">
Based on the experimental methods described
in the previous section, we have systematically
evaluated our approach on the constructed Chinese
null instantiation corpus. Note all the perfor-
mances are achieved using 5-fold cross validation.
</bodyText>
<subsubsectionHeader confidence="0.684446">
Null Instantiation Detection
</subsubsectionHeader>
<bodyText confidence="0.999739">
Table 5 gives the performance of NI detection,
which achieves 72.71%, 86.12% and 78.84% in
precision, recall and F-score, respectively. Here,
the relatively lower precision is mainly due to the
heuristic rules used to detect NIs. However, it is
worth to point out that lower precision and higher
recall is highly beneficial, as higher recall means
less filtering of true NIs.
</bodyText>
<table confidence="0.956373333333333">
P% R% F%
Ours 72.71 86.12 78.84
Lei et al. 56.18 90.57 69.34
</table>
<tableCaption confidence="0.999683">
Table 5: Performance of NI Detection
</tableCaption>
<bodyText confidence="0.999967857142857">
To illustrate the effectiveness of our method,
we compare it with the Lei et al.’s method on
our data, as shown in the Table 5. The F-score
of our method is 78.84%, which is 9% higher
than that of Lei et al.’s method. Clearly, these
experimental results further prove that our second-
level identification is very effective.
</bodyText>
<subsubsectionHeader confidence="0.967602">
Definite Null Instantiation Identification
</subsubsectionHeader>
<bodyText confidence="0.999602722222222">
Table 6 provides the performance of DNI iden-
tification on our automatic NI detection results.
It shows that DNI identification based on max-
imum entropy model achieves the performance
of 67.86%, 69.93% and 68.88% in terms of
precision, recall and F-score respectively, which
are better than the results using SVM classifier, as
well as the results employing Lei et al.’s method
on our data.
We observe, from Table 6, that the performance
of DNI identification is not high, possibly due to
the poorer results of NI detection in the previous
step. Moreover, because of the diversity of
NI distribution, the difference of frames, and
target words or missing core frame elements, the
interpretation of NI types may be quite different.
Thus it is difficult to build a suitable and accurate
uniform classification model.
</bodyText>
<table confidence="0.99923975">
P% R% F%
DNI IdenME 67.86 69.93 68.88
DNI IdenSVM 67.25 62.02 64.53
Lei et al. 64.58 67.73 66.12
</table>
<tableCaption confidence="0.999156">
Table 6: Performance of DNI Identification
</tableCaption>
<bodyText confidence="0.988404277777778">
Resolution on golden Definite Null Instantiation
In order to select the most effective features
for OvertFE resolver and choose the best search
space, we assume perfect results for the first
two steps, that is, we perform DNI resolution
experiment just with the correct DNIs in discourse.
After extensive experiments employing different
sets of features in different window sizes, we
conclude that combining all features can achieve
the best performance. Table 7 shows the results
on correct DNIs using the best feature set in the
window of 2, 3 and 4 sentences containing and
before the target predicate (Win2, Win3, Win4 for
short).
For OvertFE resolver, it shows that the F-score
with Win2 is higher than that in other windows,
because the bigger the window size, the more the
candidate fillers for DNI, and the more difficult for
</bodyText>
<page confidence="0.971271">
1269
</page>
<table confidence="0.9992188">
Win2 Win3 Win4
P% R% F% P% R% F% P% R% F%
OvertFE 45.22 18.20 25.95 43.04 17.64 25.02 38.63 15.23 21.84
FFR 65.56 16.29 26.11 63.50 16.81 26.58 58.53 17.32 26.72
OvertFE+FFR 51.17 31.59 39.06 52.41 32.02 39.75 45.88 31.10 37.07
</table>
<tableCaption confidence="0.999808">
Table 7: Results on golden DNI
</tableCaption>
<bodyText confidence="0.985868571428571">
OvertFE classifier to find right fillers.
For FFR resolver, it needs to find related frames,
and we find that its resolved DNIs are less than that
by OvertFE resolver, thereby resulting in the lower
precision of OvertFE than FFR.
Though performances of OvertFE and FFR both
are relatively low, FFR can resolve several DNIs
that OvertFE can not. Figures 2 and 3 both
are such cases. So when combining the two
resolvers, the final result of OvertFE+FFR outper-
forms that of each individual resolver. Meanwhile,
as shown in Table 7, for the combined resolver
OvertFE+FFR, the F-score is the highest when the
window size is 3 (i.e. Win3).
</bodyText>
<subsubsectionHeader confidence="0.92844">
Overall: Null Instantiation Resolution
</subsubsectionHeader>
<bodyText confidence="0.999840090909091">
Table 8 gives the performance of overall null
instantiations resolution with automatic NI detec-
tion and automatic DNI determination. It shows
that our resolver OvertFE+FFR achieves 40.53%,
21.54% and 28.13% in terms of precision, recall
and F-score. In comparison with the results
(52.41%, 32.02% and 39.75% in P, R and F) in
Win3 of Table 7, it shows that the errors caused
by automatic NI detection and automatic DNI
determination decrease the performance of overall
NI resolution by about 11% in terms of F-score.
</bodyText>
<table confidence="0.999526">
P% R% F%
OvertFE 33.28 13.78 19.49
FFR 52.95 9.71 16.41
OvertFE+FFR 40.53 21.54 28.13
Wang et al. 31.93 12.76 18.23
</table>
<tableCaption confidence="0.9385285">
Table 8: Performance of NI resolution for our models
and comparative systems
</tableCaption>
<bodyText confidence="0.999971235294118">
For comparison, we also conduct DNI reso-
lution on our constructed corpus employing the
method proposed by Wang et al. (2013). Since our
corpus does not contain annotation of head words,
the results are obtained by using their features
without head word information. As the last line of
Table 8 shows, the performance behaves similarly
with our OvertFE resolver. In addition, we
notice current state-of-the-art approach of Laparra
and Rigau (2013) employs coreference models,
although our corpus does not contain coreference
annotation information. As such, we are not able
to conduct experiments on our dataset using their
method for comparison purpose.
Overall, the relatively low performance of res-
olution reflects the inherent difficulty of this task,
also reveals that further research is needed.
</bodyText>
<sectionHeader confidence="0.997369" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.9999888125">
Apparently, linking implicit participants of a pred-
icate is a challenging problem. We have presented
a study for identifying implicit arguments and
finding their antecedents in Chinese discourse.
As shown in this paper, we split the difficult
task into three subtasks: null instantiation detec-
tion, definite null instantiation identification and
definite null instantiation resolution. Among the
three subtasks, the third is our major focus. For the
third subtask, we build two different resolvers: 1)
OvertFE resolver, which represents that the filler
of a DNI can be found among those overt FE
content set in context, by employing classification
methods; 2) FFR resolver, which is the frame-
related search, leverages rich network of frame-
frame relations to find antecedents. We have
proved that these two resolvers are very useful
for the third subtask, and a combination of two
resolvers produced the best results.
In the near future, we plan to create and
release a larger null instantiation corpus. As null
instantiation detection and definite null instantia-
tion identification are the foundation of resolving
definite null instantiation, it is critical to improve
the performance of both subtasks. Moreover, as
different information sources have been used in
our study, we cannot directly compare with some
of the existing methods. For our future work, we
plan to manually annotate coreference information
so that we can compare with more methods.
Finally, we hope to exploit some additional knowl-
edge resources, such as HowNet, which could
</bodyText>
<page confidence="0.953683">
1270
</page>
<bodyText confidence="0.9976615">
potentially further improve the performance of our
proposed method.
</bodyText>
<sectionHeader confidence="0.998643" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9765594">
We would like to thank anonymous reviewers and
the mentor Jacob Eisenstein for their valuable
comments and suggestions, and Xiaoli Li for help-
ing us polish the paper. This work was supported
by the National Natural Science Foundation of
</bodyText>
<reference confidence="0.623208">
China (No.61373082, 61432011, U1435212), Na-
tional 863 Project of China(No.2015AA015407),
Shanxi Platform Project(2014091004-0103) and
Scholarship Council(2013-015), and Open Project
Foundation of Information Security Evaluation
Center of Civil Aviation, Civil Aviation University
of China(No.CAAC-ISECCA-201402).
</reference>
<sectionHeader confidence="0.972167" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999761162790698">
Collin F. Baker, Charles J. Fillmore, and John B.
Lowe. 1998. The berkeley framenet project. In
Proceedings of COLING/ACL.
Aljoscha Burchardt, Anette Frank, and Manfred
Pinkal. 2005. Building text meaning representa-
tions from contextually related frames–a case study.
Proceedings of the 6th International Workshop on
Computational Semantics (IWCS-6), pages 66–77.
Desai Chen, Nathan Schneider, Dipanjan Das, and
Noah A Smith. 2010. Semafor: Frame argument
resolution with log-linear models. In Proceedings
of the 5th international workshop on semantic
evaluation, pages 264–267.
Dipanjan Das, Nathan Schneider, Desai Chen, and
Noah A Smith. 2010. Probabilistic frame-semantic
parsing. In Human language technologies: The
2010 annual conference of the North American
chapter of the association for computational linguis-
tics, pages 948–956.
Charles J. Fillmore. 1982. Frame semantics.
Linguistics in the morning calm, pages 111–137.
Matthew Gerber and Joyce Y. Chai. 2010. Beyond
nombank: a study of implicit arguments for nominal
predicates. In Proceedings of the 48th Annual
Meeting of the Association for Computational
Linguistics, pages 1583–1592.
Matthew Steven Gerber. 2011. Semantic Role Label-
ing of Implicit Arguments for Nominal Predicates.
Ph.D. thesis, Michigan State University.
Philip Gorinski, Josef Ruppenhofer, and Caroline
Sporleder. 2013. Towards weakly supervised
resolution of null instantiations. In Proceedings of
the 10th International Conference on Computational
Semantics (IWCS 2013)–Long Papers, pages 119–
130.
Egoitz Laparra and German Rigau. 2013. Sources
of evidence for implicit argument resolution. In
Proceedings of the 10th International Conference
on Computational Semantics (IWCS 2013)–Long
Papers, pages 155–166.
Zhangzhang Lei, Ning Wang, Ru Li, and Zhiqiang
Wang. 2013. Definite null instantiation recognizing
in framenet. Journal of Chinese Information,
27(3):107–112.
Ru Li. 2012. Research on Frame Semantic Structure
Analysis Technology for Chinese Sentences. Ph.D.
thesis, ShanXi university.
Hugo Liu and Push Singh. 2004. Conceptnet:
a practical commonsense reasoning tool-kit. BT
technology journal, 22(4):211–226.
Kaiying Liu. 2011. Research on chinese framenet
construction and application technologies. Journal
of Chinese Information Processing, 6:006.
Josef Ruppenhofer, Caroline Sporleder, Roser
Morante, Collin Baker, and Martha Palmer. 2010.
Semeval-2010 task 10: Linking events and their
participants in discourse. In Proceedings of the 5th
International Workshop on Semantic Evaluation,
pages 45–50.
Carina Silberer and Anette Frank. 2012. Casting
implicit role linking as an anaphora resolution task.
In Proceedings of the First Joint Conference on
Lexical and Computational Semantics-Volume 1:
Proceedings of the main conference and the shared
task, and Volume 2: Proceedings of the Sixth
International Workshop on Semantic Evaluation,
pages 1–10.
Sara Tonelli and Rodolfo Delmonte. 2010. Venses++:
Adapting a deep semantic processing system to the
identification of null instantiations. In Proceedings
of the 5th international workshop on semantic
evaluation, pages 296–299.
Sara Tonelli and Rodolfo Delmonte. 2011. Desperate-
ly seeking implicit arguments in text. In Proceed-
ings of the ACL 2011 workshop on relational models
of semantics, pages 54–62.
Ning Wang, Ru Li, Zhangzhang Lei, Zhiqiang Wang,
and Jingpan Jin. 2013. Document oriented gap
filling of definite null instantiation in framenet.
In Chinese Computational Linguistics and Natural
Language Processing Based on Naturally Annotated
Big Data, pages 85–96.
Le Zhang. 2005. Maximum entropy modeling
toolkit for python and c++. http:
//homepages.inf.ed.ac.uk/lzhang10/
maxent_toolkit.html.
</reference>
<page confidence="0.991271">
1271
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.890648">
<title confidence="0.9994805">Implicit Role Linking on Chinese Exploiting Explicit Roles and Frame-to-Frame Relations</title>
<author confidence="0.999856">Juan Zhiqiang Qinghua</author>
<affiliation confidence="0.983252">of Computer and Information Laboratory of Ministry of Education for Computation Intelligence and Chinese Information of Foreign Languages, Shanxi University, Taiyuan,</affiliation>
<email confidence="0.963729">liru@163.com</email>
<email confidence="0.963729">charles}@sxu.edu.cn@163.com</email>
<email confidence="0.963729">{wujuan_0922@163.com</email>
<email confidence="0.963729">zhiq.wang@163.com</email>
<abstract confidence="0.9981896875">There is a growing interest in researchwhich are those implicit semantic arguments. Many of these implicit arguments can be linked to referents in context, and their discoveries are of great benefits to semantic processing. We address the issue of automatically identifying and resolving implicit arguments in Chinese discourse. For their resolutions, we present an approach that combines the information about overtly labeled arguments and frame-to-frame relations defined by FrameNet. Experimental results on our created corpus demonstrate the effectiveness of our approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<date></date>
<booktitle>(No.61373082, 61432011, U1435212), National 863 Project of China(No.2015AA015407), Shanxi Platform Project(2014091004-0103) and Scholarship Council(2013-015), and Open Project Foundation of Information Security Evaluation</booktitle>
<institution>Center of Civil Aviation, Civil Aviation University of China(No.CAAC-ISECCA-201402).</institution>
<marker></marker>
<rawString>China (No.61373082, 61432011, U1435212), National 863 Project of China(No.2015AA015407), Shanxi Platform Project(2014091004-0103) and Scholarship Council(2013-015), and Open Project Foundation of Information Security Evaluation Center of Civil Aviation, Civil Aviation University of China(No.CAAC-ISECCA-201402).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The berkeley framenet project.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING/ACL.</booktitle>
<contexts>
<context position="1792" citStr="Baker et al., 1998" startWordPosition="245" endWordPosition="248">locally instantiated. Other locally unrealized semantic roles are called null instantiations (NIs). Nevertheless, many of these implicit roles, while linguistically unexpressed, can often be bound to antecedent referents in the discourse context. What’s more, capturing such implicit semantic roles and linking them to their antecedents can dramatically help text understanding. Example (1) shows an analyzed result (Li, 2012) by employing Chinese FrameNet (Liu, 2011), which is a lexical semantic knowledge base based on the frame semantics of Fillmore (1982) and takes Berkeley’s FrameNet Project (Baker et al., 1998) as the reference. In Chinese FrameNet, the predicates, called lexical units (LU), evoke frames which roughly correspond to different events or scenarios. Each frame defines a set of arguments called Frame Elements (FE). The set of FEs is further split into core FEs and non-core FEs. Particularly, the core FEs are the essential components of a frame and can be defined by themselves. However, not all core FEs of a frame can be realized simultaneously in a sentence. These non-instantiated FEs are considered as null instantiations of the frame elements. Depending on the interpretation type of the</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The berkeley framenet project. In Proceedings of COLING/ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aljoscha Burchardt</author>
<author>Anette Frank</author>
<author>Manfred Pinkal</author>
</authors>
<title>Building text meaning representations from contextually related frames–a case study.</title>
<date>2005</date>
<booktitle>Proceedings of the 6th International Workshop on Computational Semantics (IWCS-6),</booktitle>
<pages>66--77</pages>
<contexts>
<context position="9993" citStr="Burchardt et al. (2005)" startWordPosition="1518" endWordPosition="1521">that go beyond the SRL oriented SemEval systems: A candidate representation includes information about all the candidates’ coreferent mentions (determined by automatic CR), in particular their semantic roles (provided by gold annotations) and WordNet synsets. Patterns of semantic associations between filler candidates and implicit roles are learned for all mentions contained in the candidate’s entity chain. They achieve an F-score of 42.3%, which is noticeably higher than those obtained on the SemEval data. And Gerber (2011) presents an extended model that incorporates strategies suggested in Burchardt et al. (2005): using frame relations as well as coreference patterns acquired from large corpora. This model achieves an F-score of 50.3%. Lei et al. (2013) conduct DNI identification on SemEval2010 task10 data. They adopt the method of combining rules and machine learning. Different from them, we conduct two-level identifying for NI detection and use more features on Chinese data. Wang et al. (2013) take noun phrases and pronoun as candidate words for DNI filler. We use several similar features with them. The differences are that 1) we take the fillers of overt instantiated FE as candidate words and 2) we</context>
</contexts>
<marker>Burchardt, Frank, Pinkal, 2005</marker>
<rawString>Aljoscha Burchardt, Anette Frank, and Manfred Pinkal. 2005. Building text meaning representations from contextually related frames–a case study. Proceedings of the 6th International Workshop on Computational Semantics (IWCS-6), pages 66–77.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Desai Chen</author>
<author>Nathan Schneider</author>
<author>Dipanjan Das</author>
<author>Noah A Smith</author>
</authors>
<title>Semafor: Frame argument resolution with log-linear models.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th international workshop on semantic evaluation,</booktitle>
<pages>264--267</pages>
<contexts>
<context position="6931" citStr="Chen et al., 2010" startWordPosition="1046" endWordPosition="1049"> ConceptNet (Liu and Singh, 2004). The final Precision and Recall are 4.62% and 0.86% respectively. Later on, Tonelli and Delmonte (2011) propose a simpler role linking strategy that based on computing a relevancy score for the nominal head of each potential antecedent. The intuition is that heads which often serve as role fillers and occur close to the target NI are more likely to function as antecedents for the NI. Finally they reported an F-score of 8% for role linking. However, being strongly lexicalized, their trained model seems heavily dependent on the training data. The second system (Chen et al., 2010) is statistical based and extends an existing semantic role labeler (Das et al., 2010). Resolving DNIs is modeled in the same way as labeling overt arguments, with the search space being extended to nouns, pronouns, and noun phrases from the previous three sentences. When evaluating a potential filler, the syntactic features used in argument labeling of overt arguments are replaced by two semantic features: firstly the system checks whether a potential filler fills the null instantiated role overtly in at least one of the FrameNet sentences and train data, if not, the system calculates the dis</context>
</contexts>
<marker>Chen, Schneider, Das, Smith, 2010</marker>
<rawString>Desai Chen, Nathan Schneider, Dipanjan Das, and Noah A Smith. 2010. Semafor: Frame argument resolution with log-linear models. In Proceedings of the 5th international workshop on semantic evaluation, pages 264–267.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Nathan Schneider</author>
<author>Desai Chen</author>
<author>Noah A Smith</author>
</authors>
<title>Probabilistic frame-semantic parsing. In Human language technologies: The</title>
<date>2010</date>
<pages>948--956</pages>
<contexts>
<context position="7017" citStr="Das et al., 2010" startWordPosition="1060" endWordPosition="1063">espectively. Later on, Tonelli and Delmonte (2011) propose a simpler role linking strategy that based on computing a relevancy score for the nominal head of each potential antecedent. The intuition is that heads which often serve as role fillers and occur close to the target NI are more likely to function as antecedents for the NI. Finally they reported an F-score of 8% for role linking. However, being strongly lexicalized, their trained model seems heavily dependent on the training data. The second system (Chen et al., 2010) is statistical based and extends an existing semantic role labeler (Das et al., 2010). Resolving DNIs is modeled in the same way as labeling overt arguments, with the search space being extended to nouns, pronouns, and noun phrases from the previous three sentences. When evaluating a potential filler, the syntactic features used in argument labeling of overt arguments are replaced by two semantic features: firstly the system checks whether a potential filler fills the null instantiated role overtly in at least one of the FrameNet sentences and train data, if not, the system calculates the distributional similarity between filler and role. While this system achieved 5% in F-sco</context>
</contexts>
<marker>Das, Schneider, Chen, Smith, 2010</marker>
<rawString>Dipanjan Das, Nathan Schneider, Desai Chen, and Noah A Smith. 2010. Probabilistic frame-semantic parsing. In Human language technologies: The 2010 annual conference of the North American chapter of the association for computational linguistics, pages 948–956.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
</authors>
<title>Frame semantics. Linguistics in the morning calm,</title>
<date>1982</date>
<pages>111--137</pages>
<contexts>
<context position="1733" citStr="Fillmore (1982)" startWordPosition="238" endWordPosition="239">y possible semantic arguments of predicates tend to be locally instantiated. Other locally unrealized semantic roles are called null instantiations (NIs). Nevertheless, many of these implicit roles, while linguistically unexpressed, can often be bound to antecedent referents in the discourse context. What’s more, capturing such implicit semantic roles and linking them to their antecedents can dramatically help text understanding. Example (1) shows an analyzed result (Li, 2012) by employing Chinese FrameNet (Liu, 2011), which is a lexical semantic knowledge base based on the frame semantics of Fillmore (1982) and takes Berkeley’s FrameNet Project (Baker et al., 1998) as the reference. In Chinese FrameNet, the predicates, called lexical units (LU), evoke frames which roughly correspond to different events or scenarios. Each frame defines a set of arguments called Frame Elements (FE). The set of FEs is further split into core FEs and non-core FEs. Particularly, the core FEs are the essential components of a frame and can be defined by themselves. However, not all core FEs of a frame can be realized simultaneously in a sentence. These non-instantiated FEs are considered as null instantiations of the </context>
</contexts>
<marker>Fillmore, 1982</marker>
<rawString>Charles J. Fillmore. 1982. Frame semantics. Linguistics in the morning calm, pages 111–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Gerber</author>
<author>Joyce Y Chai</author>
</authors>
<title>Beyond nombank: a study of implicit arguments for nominal predicates.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1583--1592</pages>
<contexts>
<context position="8914" citStr="Gerber and Chai (2010)" startWordPosition="1356" endWordPosition="1359">2%. Wang et al. (2013) conduct DNI resolution on SemEval2010 task10 data. They considered the task as a classified problem, by adding new features such as the information of head word and frame to traditional features, proposed a rule to choose the best candidate words set and combination of features, achieving F-score of 14.65% finally. Laparra and Rigau (2013) present an attempt to apply a set of features that have been traditionally 1264 used to model anaphora and coreference resolution tasks to implicit argument resolution, and got the best results: F-score of 18%. For nominal predicates, Gerber and Chai (2010) investigate the linking of implicit arguments using the PropBank role labeling scheme. In contrast to the SemEval task, which focuses on a verbs and nouns, their system is only applied to nouns and is restricted to 10 predicates with 120 annotated instances per predicate on average. They propose a discriminative model that selects an antecedent for an implicit role from an extended context window. The approach incorporates some aspects relating to CR that go beyond the SRL oriented SemEval systems: A candidate representation includes information about all the candidates’ coreferent mentions (</context>
</contexts>
<marker>Gerber, Chai, 2010</marker>
<rawString>Matthew Gerber and Joyce Y. Chai. 2010. Beyond nombank: a study of implicit arguments for nominal predicates. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1583–1592.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Steven Gerber</author>
</authors>
<title>Semantic Role Labeling of Implicit Arguments for Nominal Predicates.</title>
<date>2011</date>
<tech>Ph.D. thesis,</tech>
<institution>Michigan State University.</institution>
<contexts>
<context position="9900" citStr="Gerber (2011)" startWordPosition="1507" endWordPosition="1508"> an extended context window. The approach incorporates some aspects relating to CR that go beyond the SRL oriented SemEval systems: A candidate representation includes information about all the candidates’ coreferent mentions (determined by automatic CR), in particular their semantic roles (provided by gold annotations) and WordNet synsets. Patterns of semantic associations between filler candidates and implicit roles are learned for all mentions contained in the candidate’s entity chain. They achieve an F-score of 42.3%, which is noticeably higher than those obtained on the SemEval data. And Gerber (2011) presents an extended model that incorporates strategies suggested in Burchardt et al. (2005): using frame relations as well as coreference patterns acquired from large corpora. This model achieves an F-score of 50.3%. Lei et al. (2013) conduct DNI identification on SemEval2010 task10 data. They adopt the method of combining rules and machine learning. Different from them, we conduct two-level identifying for NI detection and use more features on Chinese data. Wang et al. (2013) take noun phrases and pronoun as candidate words for DNI filler. We use several similar features with them. The diff</context>
</contexts>
<marker>Gerber, 2011</marker>
<rawString>Matthew Steven Gerber. 2011. Semantic Role Labeling of Implicit Arguments for Nominal Predicates. Ph.D. thesis, Michigan State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Gorinski</author>
<author>Josef Ruppenhofer</author>
<author>Caroline Sporleder</author>
</authors>
<title>Towards weakly supervised resolution of null instantiations.</title>
<date>2013</date>
<booktitle>In Proceedings of the 10th International Conference on Computational Semantics (IWCS 2013)–Long Papers,</booktitle>
<pages>119--130</pages>
<contexts>
<context position="8055" citStr="Gorinski et al. (2013)" startWordPosition="1221" endWordPosition="1224">ly in at least one of the FrameNet sentences and train data, if not, the system calculates the distributional similarity between filler and role. While this system achieved 5% in F-score, data sparseness is a potential limiting factor. Also closely related studies are as follows. Silberer and Frank (2012) cast NI resolution as a coreference resolution (CR) task, and employ an entity-mention model. They experiment with features of SRL and CR, and automatically expand the training set with examples generated from coreference corpus to avoid data sparseness, ultimately achieving F-score of 7.1%. Gorinski et al. (2013) present a weakly supervised approach that investigates and combines a number of linguistically motivated strategies, which consist of four basic NI resolvers that exploit different types of linguistic knowledge, and achieve F-score of 12%. Wang et al. (2013) conduct DNI resolution on SemEval2010 task10 data. They considered the task as a classified problem, by adding new features such as the information of head word and frame to traditional features, proposed a rule to choose the best candidate words set and combination of features, achieving F-score of 14.65% finally. Laparra and Rigau (2013</context>
</contexts>
<marker>Gorinski, Ruppenhofer, Sporleder, 2013</marker>
<rawString>Philip Gorinski, Josef Ruppenhofer, and Caroline Sporleder. 2013. Towards weakly supervised resolution of null instantiations. In Proceedings of the 10th International Conference on Computational Semantics (IWCS 2013)–Long Papers, pages 119– 130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Egoitz Laparra</author>
<author>German Rigau</author>
</authors>
<title>Sources of evidence for implicit argument resolution.</title>
<date>2013</date>
<booktitle>In Proceedings of the 10th International Conference on Computational Semantics (IWCS 2013)–Long Papers,</booktitle>
<pages>155--166</pages>
<contexts>
<context position="8656" citStr="Laparra and Rigau (2013)" startWordPosition="1314" endWordPosition="1317"> Gorinski et al. (2013) present a weakly supervised approach that investigates and combines a number of linguistically motivated strategies, which consist of four basic NI resolvers that exploit different types of linguistic knowledge, and achieve F-score of 12%. Wang et al. (2013) conduct DNI resolution on SemEval2010 task10 data. They considered the task as a classified problem, by adding new features such as the information of head word and frame to traditional features, proposed a rule to choose the best candidate words set and combination of features, achieving F-score of 14.65% finally. Laparra and Rigau (2013) present an attempt to apply a set of features that have been traditionally 1264 used to model anaphora and coreference resolution tasks to implicit argument resolution, and got the best results: F-score of 18%. For nominal predicates, Gerber and Chai (2010) investigate the linking of implicit arguments using the PropBank role labeling scheme. In contrast to the SemEval task, which focuses on a verbs and nouns, their system is only applied to nouns and is restricted to 10 predicates with 120 annotated instances per predicate on average. They propose a discriminative model that selects an antec</context>
<context position="30503" citStr="Laparra and Rigau (2013)" startWordPosition="4904" endWordPosition="4907">E 33.28 13.78 19.49 FFR 52.95 9.71 16.41 OvertFE+FFR 40.53 21.54 28.13 Wang et al. 31.93 12.76 18.23 Table 8: Performance of NI resolution for our models and comparative systems For comparison, we also conduct DNI resolution on our constructed corpus employing the method proposed by Wang et al. (2013). Since our corpus does not contain annotation of head words, the results are obtained by using their features without head word information. As the last line of Table 8 shows, the performance behaves similarly with our OvertFE resolver. In addition, we notice current state-of-the-art approach of Laparra and Rigau (2013) employs coreference models, although our corpus does not contain coreference annotation information. As such, we are not able to conduct experiments on our dataset using their method for comparison purpose. Overall, the relatively low performance of resolution reflects the inherent difficulty of this task, also reveals that further research is needed. 7 Conclusion and Future Work Apparently, linking implicit participants of a predicate is a challenging problem. We have presented a study for identifying implicit arguments and finding their antecedents in Chinese discourse. As shown in this pap</context>
</contexts>
<marker>Laparra, Rigau, 2013</marker>
<rawString>Egoitz Laparra and German Rigau. 2013. Sources of evidence for implicit argument resolution. In Proceedings of the 10th International Conference on Computational Semantics (IWCS 2013)–Long Papers, pages 155–166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhangzhang Lei</author>
<author>Ning Wang</author>
<author>Ru Li</author>
<author>Zhiqiang Wang</author>
</authors>
<title>Definite null instantiation recognizing in framenet.</title>
<date>2013</date>
<journal>Journal of Chinese Information,</journal>
<volume>27</volume>
<issue>3</issue>
<contexts>
<context position="10136" citStr="Lei et al. (2013)" startWordPosition="1541" endWordPosition="1544">mined by automatic CR), in particular their semantic roles (provided by gold annotations) and WordNet synsets. Patterns of semantic associations between filler candidates and implicit roles are learned for all mentions contained in the candidate’s entity chain. They achieve an F-score of 42.3%, which is noticeably higher than those obtained on the SemEval data. And Gerber (2011) presents an extended model that incorporates strategies suggested in Burchardt et al. (2005): using frame relations as well as coreference patterns acquired from large corpora. This model achieves an F-score of 50.3%. Lei et al. (2013) conduct DNI identification on SemEval2010 task10 data. They adopt the method of combining rules and machine learning. Different from them, we conduct two-level identifying for NI detection and use more features on Chinese data. Wang et al. (2013) take noun phrases and pronoun as candidate words for DNI filler. We use several similar features with them. The differences are that 1) we take the fillers of overt instantiated FE as candidate words and 2) we use Frame-toFrame relations. And Gerber (2011) also used frame relations. Different from them, we limit relation paths to 2. 3 Null Instantiat</context>
<context position="13194" citStr="Lei et al. (2013)" startWordPosition="2044" endWordPosition="2047">iscussed in Section 3.1). In Cause—motion, the core FEs Initial_State, Goal, Path, Source and Result belong to the same CoreSet, and Goal is instantiated, thus Initial_State, Path, Source and Result are not annotated as NIs. Meanwhile core FEs Goal and Area are connected by the Excludes relation, so do Cause and Agent. Therefore, according to the context, Area and Cause are not annotated as NIs. Our approach for performing this detection is described as follows. For the first-level of detection, we make full use of the three types of relations, and adopt a rule-based strategy proposed 1265 by Lei et al. (2013) to detect NIs. As for CoreSet relation, in particular, as long as one of the FEs in this set is expressed overtly, NIs are not annotated for the absence of the other FEs in the set. If none of CoreSet is expressed, the contextually most relevant one should be annotated as a NI. However, this is difficult for automatic detector, which inevitably introduces some false detected NIs. Thus, we conduct a second-level identifying. To be specific, for the current lexical unit, i.e. the target word, we collect its frame element patterns from the training dataset. Frame element patterns are annotated s</context>
<context position="15251" citStr="Lei et al. (2013)" startWordPosition="2387" endWordPosition="2390">determine whether em needs to be filled or not, that is, we should determine em as DNI or INI. Num Feature names Feature Descriptions T1 Target Target predicate T2 Pos The part of speech of target T3 Frame The frame that target evokes T4 FENI NI of frame elements T5 FE Overtly expressed FEs Table 2: Features description in DNI Identification We treat this issue as a classification problem, and build a binary maximum entropy model to predict the null instantiation type of em. Table 2 lists all features used for training our models. In addition, we employ some similar features that were used in Lei et al. (2013). Meanwhile, we choose to learn a SVM classifier for comparison purpose. 5 Definite Null Instantiation Resolution In this section, we tackle the last subtask, namely definite null instantiation resolution. 5.1 Frame-to-Frame Relations The relations of Frame-to-Frame and FE-to-FE in FrameNet, serve as important information sources, to be leveraged for DNI resolutions. FrameNet arranges frames into a net by defining frame-to-frame relations, including Inheritance, Inchoative Of, Subframe, Causative Of, Precedes, Using, See_also and Perspective On. In the case of Inheritance relation, it defines </context>
</contexts>
<marker>Lei, Wang, Li, Wang, 2013</marker>
<rawString>Zhangzhang Lei, Ning Wang, Ru Li, and Zhiqiang Wang. 2013. Definite null instantiation recognizing in framenet. Journal of Chinese Information, 27(3):107–112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ru Li</author>
</authors>
<title>Research on Frame Semantic Structure Analysis Technology for Chinese Sentences.</title>
<date>2012</date>
<tech>Ph.D. thesis,</tech>
<institution>ShanXi university.</institution>
<contexts>
<context position="1599" citStr="Li, 2012" startWordPosition="217" endWordPosition="218"> demonstrate the effectiveness of our approach. 1 Introduction In natural discourse, only a small proportion of the theoretically possible semantic arguments of predicates tend to be locally instantiated. Other locally unrealized semantic roles are called null instantiations (NIs). Nevertheless, many of these implicit roles, while linguistically unexpressed, can often be bound to antecedent referents in the discourse context. What’s more, capturing such implicit semantic roles and linking them to their antecedents can dramatically help text understanding. Example (1) shows an analyzed result (Li, 2012) by employing Chinese FrameNet (Liu, 2011), which is a lexical semantic knowledge base based on the frame semantics of Fillmore (1982) and takes Berkeley’s FrameNet Project (Baker et al., 1998) as the reference. In Chinese FrameNet, the predicates, called lexical units (LU), evoke frames which roughly correspond to different events or scenarios. Each frame defines a set of arguments called Frame Elements (FE). The set of FEs is further split into core FEs and non-core FEs. Particularly, the core FEs are the essential components of a frame and can be defined by themselves. However, not all core</context>
</contexts>
<marker>Li, 2012</marker>
<rawString>Ru Li. 2012. Research on Frame Semantic Structure Analysis Technology for Chinese Sentences. Ph.D. thesis, ShanXi university.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hugo Liu</author>
<author>Push Singh</author>
</authors>
<title>Conceptnet: a practical commonsense reasoning tool-kit.</title>
<date>2004</date>
<booktitle>BT technology journal,</booktitle>
<pages>22--4</pages>
<contexts>
<context position="6346" citStr="Liu and Singh, 2004" startWordPosition="950" endWordPosition="953">ry different approaches. Tonelli and Delmonte (2010) develop a knowledge-based system called VENSES++, and describe two strategies depending on the predicate class (either nominal or verbal). For verbal predicates, they try to map the predicate argument structure extracted by VENSES with the valence patterns generated from FrameNet data, to identify missing arguments. And NIs are resolved by reasoning about the semantic similarity between an NI and a potential filler using WordNet. For nominal predicates, they resolve NIs by utilizing a common sense reasoning module that builds on ConceptNet (Liu and Singh, 2004). The final Precision and Recall are 4.62% and 0.86% respectively. Later on, Tonelli and Delmonte (2011) propose a simpler role linking strategy that based on computing a relevancy score for the nominal head of each potential antecedent. The intuition is that heads which often serve as role fillers and occur close to the target NI are more likely to function as antecedents for the NI. Finally they reported an F-score of 8% for role linking. However, being strongly lexicalized, their trained model seems heavily dependent on the training data. The second system (Chen et al., 2010) is statistical</context>
</contexts>
<marker>Liu, Singh, 2004</marker>
<rawString>Hugo Liu and Push Singh. 2004. Conceptnet: a practical commonsense reasoning tool-kit. BT technology journal, 22(4):211–226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kaiying Liu</author>
</authors>
<title>Research on chinese framenet construction and application technologies.</title>
<date>2011</date>
<journal>Journal of Chinese Information Processing,</journal>
<pages>6--006</pages>
<contexts>
<context position="1641" citStr="Liu, 2011" startWordPosition="223" endWordPosition="224">roach. 1 Introduction In natural discourse, only a small proportion of the theoretically possible semantic arguments of predicates tend to be locally instantiated. Other locally unrealized semantic roles are called null instantiations (NIs). Nevertheless, many of these implicit roles, while linguistically unexpressed, can often be bound to antecedent referents in the discourse context. What’s more, capturing such implicit semantic roles and linking them to their antecedents can dramatically help text understanding. Example (1) shows an analyzed result (Li, 2012) by employing Chinese FrameNet (Liu, 2011), which is a lexical semantic knowledge base based on the frame semantics of Fillmore (1982) and takes Berkeley’s FrameNet Project (Baker et al., 1998) as the reference. In Chinese FrameNet, the predicates, called lexical units (LU), evoke frames which roughly correspond to different events or scenarios. Each frame defines a set of arguments called Frame Elements (FE). The set of FEs is further split into core FEs and non-core FEs. Particularly, the core FEs are the essential components of a frame and can be defined by themselves. However, not all core FEs of a frame can be realized simultaneo</context>
</contexts>
<marker>Liu, 2011</marker>
<rawString>Kaiying Liu. 2011. Research on chinese framenet construction and application technologies. Journal of Chinese Information Processing, 6:006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josef Ruppenhofer</author>
<author>Caroline Sporleder</author>
<author>Roser Morante</author>
<author>Collin Baker</author>
<author>Martha Palmer</author>
</authors>
<title>Semeval-2010 task 10: Linking events and their participants in discourse.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<pages>45--50</pages>
<contexts>
<context position="5639" citStr="Ruppenhofer et al., 2010" startWordPosition="843" endWordPosition="847">tiated FE, we should determine whether em is a DNI. If so, we need to find the corresponding antecedent dm in context. The major contributions of this paper can be summarized as follows: (i) We have created a null instantiation (NI) annotations corpus, consisting of 164 Chinese discourses across different fields. (ii) We use frame-to-frame relations to find antecedents from those explicit semantic roles. 2 Related Work Among the researches of null instantiation on English, the most representative work is the task “Linking Events and Their Participants in Discourse” shared by the SemEval-2010 (Ruppenhofer et al., 2010). The two systems participated in the NI resolution task, VENSES++ and SEMAFOR, took very different approaches. Tonelli and Delmonte (2010) develop a knowledge-based system called VENSES++, and describe two strategies depending on the predicate class (either nominal or verbal). For verbal predicates, they try to map the predicate argument structure extracted by VENSES with the valence patterns generated from FrameNet data, to identify missing arguments. And NIs are resolved by reasoning about the semantic similarity between an NI and a potential filler using WordNet. For nominal predicates, th</context>
</contexts>
<marker>Ruppenhofer, Sporleder, Morante, Baker, Palmer, 2010</marker>
<rawString>Josef Ruppenhofer, Caroline Sporleder, Roser Morante, Collin Baker, and Martha Palmer. 2010. Semeval-2010 task 10: Linking events and their participants in discourse. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 45–50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carina Silberer</author>
<author>Anette Frank</author>
</authors>
<title>Casting implicit role linking as an anaphora resolution task.</title>
<date>2012</date>
<booktitle>In Proceedings of the First Joint Conference on Lexical and Computational Semantics-Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation,</booktitle>
<pages>1--10</pages>
<contexts>
<context position="7739" citStr="Silberer and Frank (2012)" startWordPosition="1173" endWordPosition="1176">ing extended to nouns, pronouns, and noun phrases from the previous three sentences. When evaluating a potential filler, the syntactic features used in argument labeling of overt arguments are replaced by two semantic features: firstly the system checks whether a potential filler fills the null instantiated role overtly in at least one of the FrameNet sentences and train data, if not, the system calculates the distributional similarity between filler and role. While this system achieved 5% in F-score, data sparseness is a potential limiting factor. Also closely related studies are as follows. Silberer and Frank (2012) cast NI resolution as a coreference resolution (CR) task, and employ an entity-mention model. They experiment with features of SRL and CR, and automatically expand the training set with examples generated from coreference corpus to avoid data sparseness, ultimately achieving F-score of 7.1%. Gorinski et al. (2013) present a weakly supervised approach that investigates and combines a number of linguistically motivated strategies, which consist of four basic NI resolvers that exploit different types of linguistic knowledge, and achieve F-score of 12%. Wang et al. (2013) conduct DNI resolution o</context>
</contexts>
<marker>Silberer, Frank, 2012</marker>
<rawString>Carina Silberer and Anette Frank. 2012. Casting implicit role linking as an anaphora resolution task. In Proceedings of the First Joint Conference on Lexical and Computational Semantics-Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation, pages 1–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Tonelli</author>
<author>Rodolfo Delmonte</author>
</authors>
<title>Venses++: Adapting a deep semantic processing system to the identification of null instantiations.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th international workshop on semantic evaluation,</booktitle>
<pages>296--299</pages>
<contexts>
<context position="5778" citStr="Tonelli and Delmonte (2010)" startWordPosition="865" endWordPosition="868">tions of this paper can be summarized as follows: (i) We have created a null instantiation (NI) annotations corpus, consisting of 164 Chinese discourses across different fields. (ii) We use frame-to-frame relations to find antecedents from those explicit semantic roles. 2 Related Work Among the researches of null instantiation on English, the most representative work is the task “Linking Events and Their Participants in Discourse” shared by the SemEval-2010 (Ruppenhofer et al., 2010). The two systems participated in the NI resolution task, VENSES++ and SEMAFOR, took very different approaches. Tonelli and Delmonte (2010) develop a knowledge-based system called VENSES++, and describe two strategies depending on the predicate class (either nominal or verbal). For verbal predicates, they try to map the predicate argument structure extracted by VENSES with the valence patterns generated from FrameNet data, to identify missing arguments. And NIs are resolved by reasoning about the semantic similarity between an NI and a potential filler using WordNet. For nominal predicates, they resolve NIs by utilizing a common sense reasoning module that builds on ConceptNet (Liu and Singh, 2004). The final Precision and Recall</context>
</contexts>
<marker>Tonelli, Delmonte, 2010</marker>
<rawString>Sara Tonelli and Rodolfo Delmonte. 2010. Venses++: Adapting a deep semantic processing system to the identification of null instantiations. In Proceedings of the 5th international workshop on semantic evaluation, pages 296–299.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Tonelli</author>
<author>Rodolfo Delmonte</author>
</authors>
<title>Desperately seeking implicit arguments in text.</title>
<date>2011</date>
<booktitle>In Proceedings of the ACL</booktitle>
<pages>54--62</pages>
<contexts>
<context position="6450" citStr="Tonelli and Delmonte (2011)" startWordPosition="966" endWordPosition="969">ES++, and describe two strategies depending on the predicate class (either nominal or verbal). For verbal predicates, they try to map the predicate argument structure extracted by VENSES with the valence patterns generated from FrameNet data, to identify missing arguments. And NIs are resolved by reasoning about the semantic similarity between an NI and a potential filler using WordNet. For nominal predicates, they resolve NIs by utilizing a common sense reasoning module that builds on ConceptNet (Liu and Singh, 2004). The final Precision and Recall are 4.62% and 0.86% respectively. Later on, Tonelli and Delmonte (2011) propose a simpler role linking strategy that based on computing a relevancy score for the nominal head of each potential antecedent. The intuition is that heads which often serve as role fillers and occur close to the target NI are more likely to function as antecedents for the NI. Finally they reported an F-score of 8% for role linking. However, being strongly lexicalized, their trained model seems heavily dependent on the training data. The second system (Chen et al., 2010) is statistical based and extends an existing semantic role labeler (Das et al., 2010). Resolving DNIs is modeled in th</context>
</contexts>
<marker>Tonelli, Delmonte, 2011</marker>
<rawString>Sara Tonelli and Rodolfo Delmonte. 2011. Desperately seeking implicit arguments in text. In Proceedings of the ACL 2011 workshop on relational models of semantics, pages 54–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ning Wang</author>
<author>Ru Li</author>
<author>Zhangzhang Lei</author>
<author>Zhiqiang Wang</author>
<author>Jingpan Jin</author>
</authors>
<title>Document oriented gap filling of definite null instantiation in framenet.</title>
<date>2013</date>
<booktitle>In Chinese Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data,</booktitle>
<pages>85--96</pages>
<contexts>
<context position="8314" citStr="Wang et al. (2013)" startWordPosition="1260" endWordPosition="1263">s are as follows. Silberer and Frank (2012) cast NI resolution as a coreference resolution (CR) task, and employ an entity-mention model. They experiment with features of SRL and CR, and automatically expand the training set with examples generated from coreference corpus to avoid data sparseness, ultimately achieving F-score of 7.1%. Gorinski et al. (2013) present a weakly supervised approach that investigates and combines a number of linguistically motivated strategies, which consist of four basic NI resolvers that exploit different types of linguistic knowledge, and achieve F-score of 12%. Wang et al. (2013) conduct DNI resolution on SemEval2010 task10 data. They considered the task as a classified problem, by adding new features such as the information of head word and frame to traditional features, proposed a rule to choose the best candidate words set and combination of features, achieving F-score of 14.65% finally. Laparra and Rigau (2013) present an attempt to apply a set of features that have been traditionally 1264 used to model anaphora and coreference resolution tasks to implicit argument resolution, and got the best results: F-score of 18%. For nominal predicates, Gerber and Chai (2010)</context>
<context position="10383" citStr="Wang et al. (2013)" startWordPosition="1580" endWordPosition="1583">s entity chain. They achieve an F-score of 42.3%, which is noticeably higher than those obtained on the SemEval data. And Gerber (2011) presents an extended model that incorporates strategies suggested in Burchardt et al. (2005): using frame relations as well as coreference patterns acquired from large corpora. This model achieves an F-score of 50.3%. Lei et al. (2013) conduct DNI identification on SemEval2010 task10 data. They adopt the method of combining rules and machine learning. Different from them, we conduct two-level identifying for NI detection and use more features on Chinese data. Wang et al. (2013) take noun phrases and pronoun as candidate words for DNI filler. We use several similar features with them. The differences are that 1) we take the fillers of overt instantiated FE as candidate words and 2) we use Frame-toFrame relations. And Gerber (2011) also used frame relations. Different from them, we limit relation paths to 2. 3 Null Instantiation Detection Now, we are ready to address the first subtask, i.e. null instantiation detection. 3.1 Frame element relations Not all core arguments of all frames can be realized simultaneously. Some frames involve core FEs that are mutually exclus</context>
<context position="19303" citStr="Wang et al. (2013)" startWordPosition="3032" endWordPosition="3035">a classification problem to judge whether a candidate overt FE content d (d ∈ cpm) could be taken as filler of a DNI. Therefore, we employ a classification method to solve the problem. Clearly, the performance of classifiers largely depends on constructed features. Since corresponding antecedent of DNI is not overtly expressed, it is difficult to get some information from context to describe them. What we take as features is the information of candidate frame element contents and frame information. Table 3 lists all features used for training our models. Some similar features were employed by Wang et al. (2013) where they also considered DNI linking as a classification problem. Then maximum entropy models, widely used in natural language processing (such as Chinese word segmentation and machine translation), are employed to predict whether a candidate FE content is the filler of DNI. Frame-to-Frame Relations Based Resolver (FFR) Another way of finding the correct filler is through searching Frame-to-Frame relations in a given context window. This is because Frame-to-Frame relations and FE-to-FE relations can provide relevant information for finding DNI filler among candidate frame element contents. </context>
<context position="30181" citStr="Wang et al. (2013)" startWordPosition="4854" endWordPosition="4857">of precision, recall and F-score. In comparison with the results (52.41%, 32.02% and 39.75% in P, R and F) in Win3 of Table 7, it shows that the errors caused by automatic NI detection and automatic DNI determination decrease the performance of overall NI resolution by about 11% in terms of F-score. P% R% F% OvertFE 33.28 13.78 19.49 FFR 52.95 9.71 16.41 OvertFE+FFR 40.53 21.54 28.13 Wang et al. 31.93 12.76 18.23 Table 8: Performance of NI resolution for our models and comparative systems For comparison, we also conduct DNI resolution on our constructed corpus employing the method proposed by Wang et al. (2013). Since our corpus does not contain annotation of head words, the results are obtained by using their features without head word information. As the last line of Table 8 shows, the performance behaves similarly with our OvertFE resolver. In addition, we notice current state-of-the-art approach of Laparra and Rigau (2013) employs coreference models, although our corpus does not contain coreference annotation information. As such, we are not able to conduct experiments on our dataset using their method for comparison purpose. Overall, the relatively low performance of resolution reflects the inh</context>
</contexts>
<marker>Wang, Li, Lei, Wang, Jin, 2013</marker>
<rawString>Ning Wang, Ru Li, Zhangzhang Lei, Zhiqiang Wang, and Jingpan Jin. 2013. Document oriented gap filling of definite null instantiation in framenet. In Chinese Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data, pages 85–96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Le Zhang</author>
</authors>
<title>Maximum entropy modeling toolkit for python and c++.</title>
<date>2005</date>
<note>http: //homepages.inf.ed.ac.uk/lzhang10/ maxent_toolkit.html.</note>
<marker>Le Zhang, 2005</marker>
<rawString>Le Zhang. 2005. Maximum entropy modeling toolkit for python and c++. http: //homepages.inf.ed.ac.uk/lzhang10/ maxent_toolkit.html.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>