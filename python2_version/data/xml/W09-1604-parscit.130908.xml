<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.078720">
<title confidence="0.977132">
Cross-lingual Alignment and Completion of Wikipedia Templates
</title>
<author confidence="0.994594">
Gosse Bouma Sergio Duarte Zahurul Islam
</author>
<affiliation confidence="0.9958615">
Information Science Information Science Information Science
University of Groningen University of Groningen University of Groningen
</affiliation>
<email confidence="0.997403">
g.bouma@rug.nl sergio.duarte@gmail.com zaisdb@gmail.com
</email>
<sectionHeader confidence="0.995621" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99948525">
For many languages, the size of Wikipedia is
an order of magnitude smaller than the En-
glish Wikipedia. We present a method for
cross-lingual alignment of template and in-
fobox attributes in Wikipedia. The alignment
is used to add and complete templates and
infoboxes in one language with information
derived from Wikipedia in another language.
We show that alignment between English and
Dutch Wikipedia is accurate and that the re-
sult can be used to expand the number of tem-
plate attribute-value pairs in Dutch Wikipedia
by 50%. Furthermore, the alignment pro-
vides valuable information for normalization
of template and attribute names and can be
used to detect potential inconsistencies.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999599533333333">
One of the more interesting aspects of Wikipedia
is that it has grown into a multilingual resource,
with Wikipedia’s for many languages, and system-
atic (cross-language) links between the information
in different language versions. Eventhough English
has the largest Wikipedia for any given language, the
amount of information present in Wikipedia exceeds
that of any single Wikipedia. One of the reasons for
this is that each language version of Wikipedia has
its own cultural and regional bias. It is likely, for
instance, that information about the Netherlands is
better represented in Dutch Wikipedia than in other
Wikipedia’s. Some indication that this is indeed
the case comes from the fact a Google search for
’Pim Fortuyn’ in the Dutch Wikipedia gives 498 hits,
</bodyText>
<page confidence="0.985923">
21
</page>
<bodyText confidence="0.999907735294118">
whereas the English Wikipedia gives only 292 hits.
Also, 21,697 pages in Dutch Wikipedia fall in a cate-
gory matching ’Nederlands(e)’, whereas only 9,494
pages in English Wikipedia fall in a category match-
ing ’Dutch’. This indicates that, apart from the ob-
vious fact that smaller Wikipedia’s can be expanded
with information found in the larger Wikipedia’s,
it is also true that even the larger Wikipedia’s can
be supplemented with information harvested from
smaller Wikipedia’s.
Wikipedia infoboxes are tabular summaries of the
most relevant facts contained in an article. They
represent an important source of information for
general users of the encyclopedia. Infoboxes (see
figure 1) encode facts using attributes and values,
and therefore are easy to collect and process au-
tomatically. For this reason, they are extremely
valuable for systems that harvest information from
Wikipedia automatically, such as DbPedia (Auer et
al., 2008). However, as Wu and Weld (2007) note,
infoboxes are missing for many pages, and not all
infoboxes are complete. This is particularly true for
Wikipedia’s in languages other than English.
Infoboxes are a subclass of Wikipedia templates,
which are used by authors of Wikipedia pages to ex-
press information in a systematic way, and to en-
sure that formatting of this information is consistent
across Wikipedia. Templates exist for referring to
multimedia content, external websites, news stories,
scientific sources, other on-line repositories (such as
the Internet Movie Database (IMDB), medical clas-
sification systems (ICD9 and ICD10), coordinates on
Google Maps, etc. Although we are primarily inter-
ested in infoboxes, in the experiments below we take
</bodyText>
<note confidence="0.966318">
Proceedings of CLIAWS3, Third International Cross Lingual Information Access Workshop, pages 21–29,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<table confidence="0.964011153846154">
{{Infobox Philosopher |
region = Western Philosophy |
era = [[19th-century philosophy]] |
image_name = George Boole.jpg|
image_caption = George Boole |
name = George Lawlor Boole |
birth = November 2, 1815 |
death = December 8, 1864 |
school = Mathematical foundations
of [[computer science]] |
main_interests = [[Mathematics]], [[Logic]] |
ideas = [[Boolean algebra]]
}}
</table>
<figureCaption confidence="0.998885">
Figure 1: Infobox and (simplified) Wikimedia source
</figureCaption>
<bodyText confidence="0.995819454545455">
all templates into account.
We plan to use information mined from Wikipedia
for Question Answering and related tasks. In 2007
and 2008, the CLEF question answering track1 used
Wikipedia as text collection. While the usual ap-
proach to open domain question answering relies on
information retrieval for selecting relevant text snip-
pets, and natural language processing techniques for
answer extraction, an alternative stream of research
has focussed on the potential of on-line data-sets for
question answering (Lita et al., 2004; Katz et al.,
2005). In Bouma et al. (2008) it is suggested that
information harvested from infoboxes can be used
for question answering in CLEF. For instance, the
answer to questions such as How high is the Matter-
horn?, Where was Piet Mondriaan born?, and What
is the area of the country Suriname? can in princi-
ple be found in infoboxes. However, in practice the
number of questions that is answered by their Dutch
QA-system by means information from infoboxes is
small. One reason for this is the lack of coverage of
infoboxes in Dutch Wikipedia.
</bodyText>
<footnote confidence="0.890824">
1http://clef-qa.itc.it
</footnote>
<bodyText confidence="0.999410428571428">
In the recent GIKICLEF task2 systems have to find
Wikipedia pages in a number of languages which
match descriptions such as Which Australian moun-
tains are higher than 2000 m?, French bridges which
were in construction between 1980 and 1990, and
African capitals with a population of two million
inhabitants or more. The emphasis in this task is
less on answer extraction from text (as in QA) and
more on accurate interpretation of (geographical)
facts known about an entity. GIKICLEF is closely
related to the entity ranking task for Wikipedia, as
organized by INEX.3 We believe systems partici-
pating in tasks like this could profit from large col-
lections of (entity,attribute,value) triples harvested
from Wikipedia templates.
In this paper, we propose a method for automati-
cally expanding the amount of information present
in the form of templates. In our experiments,
we used English and Dutch Wikipedia as sources.
Given a page in English, and a matching page in
Dutch, we first find all English-Dutch attribute-value
</bodyText>
<footnote confidence="0.997542333333333">
2http://www.linguateca.pt/GikiCLEF
3http://inex.is.informatik.uni-duisburg.
de
</footnote>
<page confidence="0.999284">
22
</page>
<bodyText confidence="0.9999535">
tuples which have a matching value. Based on the
frequency with which attributes match, we create
a bidirectional, intersective, alignment of English-
Dutch attribute pairs. Finally, we use the set of
aligned attributes to expand the number of attribute-
value pairs in Dutch Wikipedia with information ob-
tained from matching English pages. We also show
that aligned attributes can be used to normalize at-
tribute names and to detect formatting issues and po-
tential inconsistencies in attribute values.
</bodyText>
<sectionHeader confidence="0.993414" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999891830188679">
DbPedia (Auer et al., 2008) is a large, on-going,
project which concentrates on harvesting informa-
tion from Wikipedia automatically, on normaliza-
tion of the extracted information, on linking the in-
formation with other on-line data repositories, and
on interactive access. It contains 274M facts about
2.6M entities (November, 2008). An important com-
ponent of DbPedia is harvesting of the information
present in infoboxes. However, as Wu and Weld
(2007) note, not all relevant pages have (complete)
infoboxes. The information present in infoboxes
is typically also present in the running text of a
page. One line of research has concentrated on
using the information obtained from infoboxes as
seeds for systems that learn relation extraction pat-
terns (Nguyen et al., 2007). Wu and Weld (2007)
go one step further, and concentrate on learning to
complete the infoboxes themselves. They present
a system which first learns to predict the appropri-
ate infobox for a page (using text classification).
Next, they learn relation extraction patterns using
the information obtained from existing infoboxes as
seeds. Finally, the learned patterns are applied to
text of pages for which a new infobox has been pre-
dicted, to assign values to infobox attributes. A re-
cent paper by Adar et al. (2009) (which only came
to our attention at the time of writing) starts from the
same observation as we do. It presents a system for
completing infoboxes for English, German, French,
and Spanish Wikipedia, which is based on learning a
mapping between infoboxes and attributes in multi-
ple languages. A more detailed comparison between
their approach and ours is given in section 6
The potential of the multilingual nature of
Wikipedia has been explored previously by several
researchers. Adafre and de Rijke (2006) explore ma-
chine translation and (cross-lingual) link structure
to find sentences in English and Dutch Wikipedia
which express the same content. Bouma et al. (2006)
discuss a system for the English-Dutch QA task
of CLEF. They basically use a Dutch QA-system,
which takes questions automatically translated from
English (by the on-line Babelfish translation ser-
vice). To improve the quality of the translation
of named entities, they use, among others, cross-
language links obtained from Wikipedia. Erdmann
et al. (2008) explore the potential of Wikipedia for
the extraction of bilingual terminology. They note
that apart from the cross-language links, page redi-
rects and anchor texts (i.e. the text that is used to
label a hypertext reference to another (wikipedia)
page) can be used to obtain large and accurate bilin-
gual term lists.
</bodyText>
<sectionHeader confidence="0.827994" genericHeader="method">
3 Data collection and Preparation
</sectionHeader>
<bodyText confidence="0.9999695">
We used a dump of Dutch Wikipedia (June 2008)
and English Wikipedia (August 2007) made avail-
able by the University of Amsterdam4 and converted
to an XML-format particularly suitable for informa-
tion extraction tasks.
From these two collections, for each page, we
extracted all attribute-value pairs found in all tem-
plates. Results were stored as quadruples of the
form (Page, TemplateName, Attribute, Value). Each
TemplateName∼Attribute pair expresses a specific
semantic relation between the entity or concept de-
scribed by the Page and a Value. Values can be
anything, but often refer to another Wikipedia page
(i.e. (George Boole, Philosopher, notable ideas,
Boolean algebra), where Boolean algebra is a link
to another page) or to numeric values, amounts, and
dates. Note that attributes by themselves tend to be
highly ambiguous, and often can only be interpreted
in the context of a given template. The attribute pe-
riod, for instance, is used to describe chemical el-
ements, royal dynasties, countries, and (historical)
means of transportation. Another source of attribute
ambiguity is the fact that many templates simply
number their attributes. As we are interested in find-
ing an alignment between semantically meaningful
relations in the two collections, we will therefore
</bodyText>
<footnote confidence="0.943927">
4http://ilps.science.uva.nl/WikiXML
</footnote>
<page confidence="0.98831">
23
</page>
<table confidence="0.998981">
Dutch English
June 2008 August 2007
715,992 3,840,950
290,964 757,379
126,555
550,548 1,074,935
4,357,653 5,436,033
2,350 7,783
7,510 19,378
23,399 81,671
</table>
<tableCaption confidence="0.941828">
Table 1: Statistics for the version of Dutch and English
Wikipedia used in the experiment.
</tableCaption>
<bodyText confidence="0.999622016949153">
concentrate on the problem of finding an alignment
between TemplateName—Attribute pairs in English
and Dutch Wikipedia.
Some statistics for the two collections are given
in table 1. The number of pages is the count for all
pages in the collection. It should be noted that these
contain a fair number of administrative pages, pages
for multimedia content, redirect pages, page stubs,
etc. The number of pages which contains content
that is useful for our purposes is therefore probably
a good deal lower, and is maybe closer to the num-
ber of pages containing at least one template. Cross-
language links (i.e. links from an English page to
the corresponding Dutch page) where extracted from
English Wikipedia. The fact that 0.5M templates in
Dutch give rise to 4.3M tuples, whereas 1.0M tem-
plates in English give rise to only 5.4M tuples is per-
haps a consequence of the fact that the two collec-
tions are not from the same date, and thus may re-
flect different stages of the development of the tem-
plate system.
We did spend some time on normalization of the
values found in extracted tuples. Our alignment
method relies on the fact that for a sufficient num-
ber of matching pages, tuples can be found with
matching values. Apart from identity and Wikipedia
cross-language links, we rely on the fact that dates,
amounts, and numerical values can often be rec-
ognized and normalized easily, thus increasing the
number of tuples which can be used for alignment.
Normalization addresses the fact that the use of
comma’s and periods (and spaces) in numbers is
different in English and Dutch Wikipedia, and that
dates need to be converted to a standard. English
Wikipedia expresses distances and heights in miles
and feet, weights in pounds, etc., whereas Dutch
Wikipedia uses kilometres, metres, and kilograms.
Where English Wikipedia mentions both miles and
kilometres we preserve only the kilometres. In other
situations we convert miles to kilometres. In spite
of this effort, we noted that there are still quite a
few situations which are not covered by our normal-
ization patterns. Sometimes numbers are followed
or preceded by additional text (approx.14.5 MB, 44
minutes per episode), sometimes there is irregular
formatting (October 101988), and some units sim-
ply are not handled by our normalization yet (i.e.
converting square miles to square kilometres). We
come back to this issue in section 6.
Kr¨otzsch et al. (2007) have aslo boserved that
there is little structure in the way numeric values,
units, dates, etc. are represented in Wikipedia. They
suggest a tagging system similar to the way links to
other Wikipedia pages are annotated, but now with
the aim of representing numeric and temporal values
systematically. If such a system was to be adopted
by the Wikipedia community, it would greatly fa-
cilitate the processing of such values found in in-
foboxes.
</bodyText>
<sectionHeader confidence="0.998202" genericHeader="method">
4 Alignment
</sectionHeader>
<bodyText confidence="0.990435277777778">
In this section we present our method for aligning
English Template—Attribute pairs with correspond-
ing pairs in Dutch.
The first step is creating a list of matching tuples.
Step 1. Extract all matching template
tuples.
An English (Page,, Templ,—Attr,,
Val,) tuple matches a Dutch (Paged,
Templd—Attrd, Vald) tuple if Page,
matches Paged and Val, matches Vald and
there is no other tuple for either Page, or
Paged with value Val, or Vald.
Two pages or values E and D match if
there exists a cross-language link which
links E and D, or if E=D.
We only take into account tuples for which there
is a unique (non-ambiguous) match between English
and Dutch. Many infoboxes contain attributes which
</bodyText>
<figure confidence="0.990394333333333">
date
pages
pages with template
cross-language links
templates
tuples
template names
attribute names
templ—attr pairs
</figure>
<page confidence="0.99237">
24
</page>
<bodyText confidence="0.995347076923077">
often take the same value (i.e. title and imdb title
for movies). Other cases of ambiguity are caused
by numerical values which incidentally may take
on identical values. Such ambiguous cases are ig-
nored. Step 1 gives rise to 149,825 matching tu-
ples.5 It might seem that we find matching tuples
for only about 3-4% of the tuples present in Dutch
Wikipedia. Note, however, that while there are 290K
pages with a template in Dutch Wikipedia, there are
only 126K cross-language links. The total numer
of tuples on Dutch pages for which a cross-language
link to English exists is 837K. If all these tuples have
a counterpart in English Wikipedia (which is highly
unlikely), our method finds a match for 18% of the
relevant template tuples.6
The second step consists of extracting matching
English-Dutch Template—Attribute pairs from the
list of matching tuples constructed in step 1.
Step 2. For each matching pair of tuples
(Pagee, Temple—Attre, Vale) and (Paged,
Templd—Attrd, Vald), extract the English-
Dutch pair of Template—Attributes
(Temple—Attre,Templd—Attrd).
In total, we extracted 7,772 different English-
Dutch (Temple—Attre,Templd—Attrd) tuples. In
547 cases Temple—Attre=Templd—Attrd. In 915
cases, Attre=Attrd. In the remaining 6,310 cases,
Attre 7�Attrd. The matches are mostly accurate. We
evaluated 5% of the matching template—attribute
pairs, that had been found at least 2 times. For 27%
of these (55 out 205), it was not immediately clear
whether the match was correct, because one of the
attributes was a number. Among the remaing 150
cases, the only clear error seemed to be a match be-
tween the attributes trainer and manager (for soc-
cer club templates). Other cases which are perhaps
not always correct were mappings between succes-
sor, successor1, successor2 on the one hand and af-
ter/next on the other hand. The attributes with a
</bodyText>
<footnote confidence="0.987325666666667">
5It is interesting to note that 51K of these matching tuples
are for pages that have an identical name in English and Dutch,
but were absent in the table of cross-language links. As a result,
we find 32K pages with an identical name in English and Dutch,
and at least one pair of matching tuples. We suspect that these
newly discovered cross-language links are highly accurate.
6If we also include English pages with a name identical to a
Dutch page, the maximum number of matching tuples is 1.1M,
and we find a match for 14% of the data
</footnote>
<table confidence="0.475362545454545">
101 cite web title
27 voetnoot web titel
12 film titel
10 commons 1
7 acteur naam
6 game naam
5 ster naam
4 taxobox zoogdier w-naam
4 plaats naam
4 band band naam
3 taxobox w-naam
</table>
<tableCaption confidence="0.893565">
Table 2: Dutch template—attribute pairs matching En-
glish cite web—title. Counts refer to the number of pages
with a matching value.
</tableCaption>
<bodyText confidence="0.995296166666667">
number suffix probably refer to the nth successor,
whereas the attributes without suffix probably refer
to the immediate successor.
On the other hand, for some frequent
template—attribute pairs, ambiguity is clearly
an issue. For the English pair cite web—title for
instance, 51 different mappings are found. The
most frequent cases are shown in table 2. Note that
it would be incorrect to conclude from this that, for
every English page which contains a cite web—title
pair, the corresponding Dutch page should include,
for instance, a taxobox—w-naam tuple.
In the third and final step, the actual alignment
between English-Dutch template—attribute pairs is
established, and ambiguity is eliminated.
Step 3. Given the list of matching
template—attribute pairs computed in step
2 with a frequency &gt;5, find for each En-
glish Temple—Attre pair the most frequent
matching Dutch pair Templd—Attrd. Simi-
larly, for each Dutch pair Templd—Attrd,
find the most frequent English pair
Temple—Attre. Return the intersection of
both lists.
2,070 matching template—attribute tuples are
seen at least 5 times. Preference for the
most frequent bidirectional match leaves 1,305
template—attribute tuples. Examples of aligned tu-
ples are given in table 3. We evaluated 10% of
the tuples containing meaningful attributes (i.e. not
</bodyText>
<page confidence="0.995492">
25
</page>
<table confidence="0.91389625">
English Dutch Attribute
Template Attribute Template
actor spouse acteur partner
book series boek reeks
casino owner casino eigenaar
csi character portrayed csi personage acteur
dogbreed country hond land
football club ground voetbal club stadion
film writer film schrijver
mountain range berg gebergte
radio station airdate radiozender lancering
pages triples
50,099 253,829
11,526 43,449
321,069 1,931,277
382,694 2,228,555
existing pages
new cross-links
new dutch pages
total
</table>
<tableCaption confidence="0.9998405">
Table 4: Newly inferred template tuples
Table 3: Aligned template—attribute pairs
</tableCaption>
<bodyText confidence="0.998632833333333">
numbers or single letters). In 117 tuples, we dis-
covered two errors: (aircraft specification—number
of props, gevechtsvliegtuig—bemanning) aligns the
number of engines with the number of crew
members (based on 10 matching tuples), and
(book—country, film—land) involves a mismatch of
templates as it links the country attribute for a book
to the country attribute for a movie.
Note that step 3 is similar to bidirectional inter-
sective word alignment as used in statistical machine
translation (see Ma et al. (2008), for instance). This
method is known for giving highly precise results.
</bodyText>
<sectionHeader confidence="0.998646" genericHeader="method">
5 Expansion
</sectionHeader>
<bodyText confidence="0.999087418181818">
We can use the output of step 3 of the alignment
method to check for each English tuple whether a
corresponding Dutch tuple can be predicted. If the
tuple does not exist yet, we add it. In total, this
gives rise to 2.2M new tuples for 382K pages for
Dutch Wikipedia (see table 4). We generate almost
300K new tuples for existing Dutch pages (250K for
pages for which a cross-language link already ex-
isted). This means we exand the total number of
tuples for existing pages by 27%. Most tuples, how-
ever, are generated for pages which do not yet exist
in Dutch Wikipedia. These are perhaps less useful,
although one could use the results as knowledge for
a QA-system, or to generate stubs for new Wikipedia
pages which already contain an infobox and other
relevant templates.
The 100 most frequenty added template—attribute
pairs (ranging from music album—genre (added
31,392 times) to single—producer (added 5605
times)) are dominated by templates for music al-
bums, geographical places, actors, movies, and tax-
onomy infoboxes.
We evaluated the accuracy of the newly gener-
ated tuples for 100 random existing Dutch wikipedia
pages, to which at least one new tuple was added.
The pages contained 802 existing tuples. 876
tuples were added by our automatic expansion
method. Of these newly added tuples, 62 con-
tained a value which was identical to the value of
an already existing tuple (i.e. we add the tuple
(Reuzenhaai, taxobox—naam, Reuzenhaai) where
there was already an existing tuple (Reuzenhaai,
taxobox begin—name, Reuzenhaai) tuple – note that
we add a properly translated attribute name, where
the original tuple contains a name copied from En-
glish!). The newly added tuples contained 60 tu-
ples of the form (Aegna, plaats—lat dir, N (letter)),
where the value should have been N (the symbol for
latitude on the Northern hemisphere in geographical
coordinates), and not the letter N. One page (Akira)
was expanded with an incoherent set of tuples, based
on tuples for the manga, anime, and music producer
with the same name. Apart from this failure, there
were only 5 other clearly incorrect tuples (adding
o.a. place—name to Albinism, adding name in Dutch
with an English value to Macedonian, and adding
community—name to Christopher Columbus). In
many cases, added tuples are based on a different
template for the same entity, often leading to almost
identical values (i.e. adding geographical coordi-
nates using slightly different notation). In one case,
Battle of Dogger Bank (1915), the system added new
tuples based on a template that was already in use for
the Dutch page as well, thus automatically updating
and expanding an existing template.
</bodyText>
<page confidence="0.990836">
26
</page>
<table confidence="0.998013181818182">
geboren population
23 birth date 49 inwoners
16 date of birth 9 population
8 date of birth 5 bevolking
8 dateofbirth 4 inwonersaantal
2 born 3 inwoneraantal
2 birth 2 town pop
1 date birth 2 population total
1 birthdate 1 townpop
1 inw.
1 einwohner
</table>
<tableCaption confidence="0.990175">
Table 6: One-to-many aligned attribute names. Counts
are for the number of (aligned) infoboxes that contain the
attribute.
</tableCaption>
<sectionHeader confidence="0.998941" genericHeader="method">
6 Discussion
</sectionHeader>
<subsectionHeader confidence="0.999823">
6.1 Detecting Irregularities
</subsectionHeader>
<bodyText confidence="0.999957714285714">
Instead of adding new information, one may also
search for attribute-value pairs in two Wikipedia’s
that are expected to have the same value, but do
not. Given an English page with attribute-value
pair (Attre, Vale), and a matching Dutch page with
(Attrd, Vald), where Attre and Attrd have been
aligned, one expects Vale and Vald to match as
well. If this is not the case, something irregular
is observed. We have applied the above rule to
our dataset, and detected 79K irregularities. An
overview of the various types of irregularities is
given in table 5. Most of the non-matching values
are the result of formatting issues, lack of transla-
tions, one value being more specific than the other,
and finally, inconsistencies. Note that inconsisten-
cies may also mean that one value is more recent
than the other (population, (stadium) capacity, latest
release data, spouse, etc.). A number of formatting
issues (of numbers, dates, periods, amounts, etc.)
can be fixed easily, using the current list of irregu-
larities as starting point.
</bodyText>
<subsectionHeader confidence="0.999766">
6.2 Normalizing Templates
</subsectionHeader>
<bodyText confidence="0.99992044">
It is interesting to note that alignment can also be
used to normalize template attribute names. Table 6
illustrates this for the Dutch attribute geboren and
the English attribute population. Both are aligned
with a range of attribute names in the other language.
Such information is extremely valuable for ap-
plications that attempt to harvest knowledge from
Wikipedia, and merge the result in an ontology, or
attempt to use the harvested information in an ap-
plication. For instance, a QA-system that has to an-
swer questions about birth dates or populations, has
to know which attributes are used to express this in-
formation. Alternatively, one can also use this infor-
mation to normalize attribute-names. In that case,
all attributes which express the birth date property
could be replaced by birth date (the most frequent
attribute currently in use for this relation).
This type of normalization can greatly reduce the
noisy character of the current infoboxes. For in-
stance, there are many infoboxes in use for geo-
graphic locations, people, works of art, etc. These
infoboxes often contain information about the same
properties, but, as illustrated above, there is no guar-
antee that these are always expressed by the same
attribute.
</bodyText>
<subsectionHeader confidence="0.997002">
6.3 Alignment by means of translation
</subsectionHeader>
<bodyText confidence="0.999842529411765">
Template and attribute names in Dutch often are
straightforward translations of the English name,
e.g. luchtvaartmaatschappij/airline, voetbal-
club/football club, hoofdstad/capital, naam/name,
postcode/postalcode, netnummer/area code and
opgericht/founded. One might use this information
as an alternative for determining whether two
template∼attribute pairs express the same relation.
We performed a small experiment on in-
foboxes expressing geographical information, using
Wikipedia cross-language links and an on-line dic-
tionary as multilingual dictionaries. We found that
10 to 15% of the attribute names (depending on the
exact subset of infoboxes taken into consideration)
could be connected using dictionaries. When com-
bined with the attributes found by means of align-
ment, coverage went up to maximally 38%.
</bodyText>
<subsectionHeader confidence="0.941522">
6.4 Comparison
</subsectionHeader>
<bodyText confidence="0.999965571428572">
It is hard to compare our results with those of Adar
et al. (2009). Their method uses a Boolean classi-
fier which is trained using a range of features to de-
termine whether two values are likely to be equiva-
lent (including identity, string overlap, link relations,
translation features, and correlation of numeric val-
ues). Training data is collected automatically by
</bodyText>
<page confidence="0.993266">
27
</page>
<table confidence="0.999928066666667">
Attributes Values Dutch Type
English Dutch English
capacity capaciteit 23,400 23 400 formatting
nm lat min 04 4 formatting
date date 1775-1783 1775–1783 formatting
name naam African baobab Afrikaanse baobab translation
artist artiest Various Artists Verschillende artiesten translation
regnum rijk Plantae Plantae (Planten) specificity
city naam, Comune di Adrara San Martino Adrara San Martino specificity
birth date geboren 1934 1934-8-25 specificity
imagepath coa wapenafbeelding coa missing.jpg Alvaneu wappen.svg specificity
population inwonersaantal 5345 5369 inconsistent
capacity capaciteit 13,152 14 400 inconsistent
dateofbirth geboortedatum 2 February 1978 1978-1-2 inconsistent
elevation hoogte 300 228 inconsistent
</table>
<tableCaption confidence="0.999572">
Table 5: Irregular values in aligned attributes on matching pages
</tableCaption>
<bodyText confidence="0.999982093023256">
selecting highly similar tuples (i.e. with identical
template and attribute names) as positive data, and a
random tuple from the same page as negative data.
The accuracy of the classifier is 90.7%. Next, for
each potential pairing of template—attribute pairs
from two languages, random tuples are presented
to the classifier. If the ratio of positively clas-
sified tuples exceeds a certain threshold, the two
template—attribute pairs are assumed to express the
same relation. The accuracy of result varies, with
matchings of template—attribute pairs that are based
on the most frequent tuple matches having an accu-
racy score of 60%. They also evaluate their system
by determining how well the system is able to pre-
dict known tuples. Here, recall is 40% and precision
is 54%. The recall figure could be compared to the
18% tuples (for pages related by means of a cross-
language link) for which we find a match. If we
use only properly aligned template—attribute pairs,
however, coverage will certainly go down some-
what. Precision could be compared to our obser-
vation that we find 149K matching tuples, and, af-
ter alignment, predict an equivalence for 79K tuples
which in the data collecting do not have a matching
value. Thus, for 228K tuples we predict an equiva-
lent values, whereas this is only the case for 149K
tuples. We would not like to conclude from this,
however, that the precision of our method is 65%, as
we observed in section 5 that most of the conflict-
ing values are not inconsistencies, but more often
the consequence of formatting irregularities, transla-
tions, variation in specificity, etc. It is clear that the
system of Adar et al. (2009) has a higher recall than
ours. This appears to be mainly due to the fact that
their feature based approach to determining match-
ing values considers much more data to be equiva-
lent than our approach which normalizes values and
then requires identity or a matching cross-language
link. In future work, we would like to explore more
rigorous normalization (taking the data discussed in
section 5 as starting point) and inclusion of features
to determine approximate matching to increase re-
call.
</bodyText>
<sectionHeader confidence="0.999613" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.9999495">
We have presented a method for automatically com-
pleting Wikipedia templates which relies on the mul-
tilingual nature of Wikipedia and on the fact that
systematic links exist between pages in various lan-
guages. We have shown that matching template tu-
ples can be found automatically, and that an accu-
rate set of matching template—attribute pairs can be
derived from this by using intersective bidirectional
alignment. The method extends the number of tu-
ples by 51% (27% for existing Dutch pages).
In future work, we hope to include more lan-
guages, investigate the value of (automatic) transla-
tion for template and attribute alignment, investigate
alternative alignment methods (using more features
and other weighting scheme’s), and incorporate the
expanded data set in our QA-system for Dutch.
</bodyText>
<page confidence="0.997818">
28
</page>
<sectionHeader confidence="0.995884" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999228764705883">
S.F. Adafre and M. de Rijke. 2006. Finding similar
sentences across multiple languages in wikipedia. In
Proceedings of the 11th Conference of the European
Chapter of the Association for Computational Linguis-
tics, pages 62–69.
E. Adar, M. Skinner, and D.S. Weld. 2009. Informa-
tion arbitrage across multi-lingual Wikipedia. In Pro-
ceedings of the Second ACM International Conference
on Web Search and Data Mining, pages 94–103. ACM
New York, NY, USA.
S¨oren Auer, Christian Bizer, Georgi Kobilarov, Jens
Lehmann, Richard Cyganiak, and Zachary Ives. 2008.
Dbpedia: A nucleus for a web of open data. The Se-
mantic Web, pages 722–735.
Gosse Bouma, Ismail Fahmi, Jori Mur, Gertjan van No-
ord, Lonneke van der Plas, and J¨org Tiedemann. 2006.
The University of Groningen at QA@CLEF 2006: Us-
ing syntactic knowledge for QA. In Working Notes for
the CLEF 2006 Workshop, Alicante.
Gosse Bouma, Jori Mur, Gertjan van Noord, Lonneke
van der Plas, and J¨org Tiedemann. 2008. Question
answering with Joost at QA@CLEF 2008. In Working
Notes for the CLEF 2008 Workshop, Aarhus.
M. Erdmann, K. Nakayama, T. Hara, and S. Nishio.
2008. An approach for extracting bilingual terminol-
ogy from wikipedia. Lecture Notes in Computer Sci-
ence, 4947:380.
B. Katz, G. Marton, G. Borchardt, A. Brownell,
S. Felshin, D. Loreto, J. Louis-Rosenberg, B. Lu,
F. Mora, S. Stiller, et al. 2005. External knowledge
sources for question answering. In Proceedings of the
14th Annual Text REtrieval Conference (TREC’2005),
November.
M. Kr¨otzsch, D. Vrandeˇci´c, M. V¨olkel, H. Haller, and
R. Studer. 2007. Semantic wikipedia. Web Semantics:
Science, Services and Agents on the World Wide Web.
L.V. Lita, W.A. Hunt, and E. Nyberg. 2004. Resource
analysis for question answering. In Association for
Computational Linguistics Conference (ACL).
Y. Ma, S. Ozdowska, Y. Sun, and A. Way. 2008. Improv-
ing word alignment using syntactic dependencies. In
Proceedings of the ACL-08: HLT Second Workshop on
Syntax and Structure in Statistical Translation (SSST-
2), pages 69–77.
D.P.T. Nguyen, Y. Matsuo, and M. Ishizuka. 2007. Rela-
tion extraction from wikipedia using subtree mining.
In PROCEEDINGS OF THE NATIONAL CONFER-
ENCE ON ARTIFICIAL INTELLIGENCE, page 1414.
AAAI Press.
Fei Wu and Daniel S. Weld. 2007. Autonomously se-
mantifying wikipedia. In CIKM ’07: Proceedings of
</reference>
<bodyText confidence="0.935961">
the sixteenth ACM conference on Conference on in-
formation and knowledge management, pages 41–50,
New York, NY, USA. ACM.
</bodyText>
<page confidence="0.998591">
29
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.916112">
<title confidence="0.998212">Cross-lingual Alignment and Completion of Wikipedia Templates</title>
<author confidence="0.991478">Gosse Bouma Sergio Duarte Zahurul Islam</author>
<affiliation confidence="0.9993485">Information Science Information Science Information Science University of Groningen University of Groningen University of</affiliation>
<email confidence="0.942262">g.bouma@rug.nlsergio.duarte@gmail.comzaisdb@gmail.com</email>
<abstract confidence="0.998990117647059">For many languages, the size of Wikipedia is an order of magnitude smaller than the English Wikipedia. We present a method for cross-lingual alignment of template and infobox attributes in Wikipedia. The alignment is used to add and complete templates and infoboxes in one language with information derived from Wikipedia in another language. We show that alignment between English and Dutch Wikipedia is accurate and that the result can be used to expand the number of template attribute-value pairs in Dutch Wikipedia by 50%. Furthermore, the alignment provides valuable information for normalization of template and attribute names and can be used to detect potential inconsistencies.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S F Adafre</author>
<author>M de Rijke</author>
</authors>
<title>Finding similar sentences across multiple languages in wikipedia.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>62--69</pages>
<marker>Adafre, de Rijke, 2006</marker>
<rawString>S.F. Adafre and M. de Rijke. 2006. Finding similar sentences across multiple languages in wikipedia. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, pages 62–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Adar</author>
<author>M Skinner</author>
<author>D S Weld</author>
</authors>
<title>Information arbitrage across multi-lingual Wikipedia.</title>
<date>2009</date>
<booktitle>In Proceedings of the Second ACM International Conference on Web Search and Data Mining,</booktitle>
<pages>94--103</pages>
<publisher>ACM</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="8070" citStr="Adar et al. (2009)" startWordPosition="1240" endWordPosition="1243">tained from infoboxes as seeds for systems that learn relation extraction patterns (Nguyen et al., 2007). Wu and Weld (2007) go one step further, and concentrate on learning to complete the infoboxes themselves. They present a system which first learns to predict the appropriate infobox for a page (using text classification). Next, they learn relation extraction patterns using the information obtained from existing infoboxes as seeds. Finally, the learned patterns are applied to text of pages for which a new infobox has been predicted, to assign values to infobox attributes. A recent paper by Adar et al. (2009) (which only came to our attention at the time of writing) starts from the same observation as we do. It presents a system for completing infoboxes for English, German, French, and Spanish Wikipedia, which is based on learning a mapping between infoboxes and attributes in multiple languages. A more detailed comparison between their approach and ours is given in section 6 The potential of the multilingual nature of Wikipedia has been explored previously by several researchers. Adafre and de Rijke (2006) explore machine translation and (cross-lingual) link structure to find sentences in English </context>
<context position="26164" citStr="Adar et al. (2009)" startWordPosition="4140" endWordPosition="4143">formation as an alternative for determining whether two template∼attribute pairs express the same relation. We performed a small experiment on infoboxes expressing geographical information, using Wikipedia cross-language links and an on-line dictionary as multilingual dictionaries. We found that 10 to 15% of the attribute names (depending on the exact subset of infoboxes taken into consideration) could be connected using dictionaries. When combined with the attributes found by means of alignment, coverage went up to maximally 38%. 6.4 Comparison It is hard to compare our results with those of Adar et al. (2009). Their method uses a Boolean classifier which is trained using a range of features to determine whether two values are likely to be equivalent (including identity, string overlap, link relations, translation features, and correlation of numeric values). Training data is collected automatically by 27 Attributes Values Dutch Type English Dutch English capacity capaciteit 23,400 23 400 formatting nm lat min 04 4 formatting date date 1775-1783 1775–1783 formatting name naam African baobab Afrikaanse baobab translation artist artiest Various Artists Verschillende artiesten translation regnum rijk </context>
<context position="28915" citStr="Adar et al. (2009)" startWordPosition="4569" endWordPosition="4572">ompared to our observation that we find 149K matching tuples, and, after alignment, predict an equivalence for 79K tuples which in the data collecting do not have a matching value. Thus, for 228K tuples we predict an equivalent values, whereas this is only the case for 149K tuples. We would not like to conclude from this, however, that the precision of our method is 65%, as we observed in section 5 that most of the conflicting values are not inconsistencies, but more often the consequence of formatting irregularities, translations, variation in specificity, etc. It is clear that the system of Adar et al. (2009) has a higher recall than ours. This appears to be mainly due to the fact that their feature based approach to determining matching values considers much more data to be equivalent than our approach which normalizes values and then requires identity or a matching cross-language link. In future work, we would like to explore more rigorous normalization (taking the data discussed in section 5 as starting point) and inclusion of features to determine approximate matching to increase recall. 7 Conclusions We have presented a method for automatically completing Wikipedia templates which relies on t</context>
</contexts>
<marker>Adar, Skinner, Weld, 2009</marker>
<rawString>E. Adar, M. Skinner, and D.S. Weld. 2009. Information arbitrage across multi-lingual Wikipedia. In Proceedings of the Second ACM International Conference on Web Search and Data Mining, pages 94–103. ACM New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S¨oren Auer</author>
<author>Christian Bizer</author>
<author>Georgi Kobilarov</author>
<author>Jens Lehmann</author>
<author>Richard Cyganiak</author>
<author>Zachary Ives</author>
</authors>
<title>Dbpedia: A nucleus for a web of open data. The Semantic Web,</title>
<date>2008</date>
<pages>722--735</pages>
<contexts>
<context position="2711" citStr="Auer et al., 2008" startWordPosition="407" endWordPosition="410">tion found in the larger Wikipedia’s, it is also true that even the larger Wikipedia’s can be supplemented with information harvested from smaller Wikipedia’s. Wikipedia infoboxes are tabular summaries of the most relevant facts contained in an article. They represent an important source of information for general users of the encyclopedia. Infoboxes (see figure 1) encode facts using attributes and values, and therefore are easy to collect and process automatically. For this reason, they are extremely valuable for systems that harvest information from Wikipedia automatically, such as DbPedia (Auer et al., 2008). However, as Wu and Weld (2007) note, infoboxes are missing for many pages, and not all infoboxes are complete. This is particularly true for Wikipedia’s in languages other than English. Infoboxes are a subclass of Wikipedia templates, which are used by authors of Wikipedia pages to express information in a systematic way, and to ensure that formatting of this information is consistent across Wikipedia. Templates exist for referring to multimedia content, external websites, news stories, scientific sources, other on-line repositories (such as the Internet Movie Database (IMDB), medical classi</context>
<context position="6811" citStr="Auer et al., 2008" startWordPosition="1040" endWordPosition="1043">://www.linguateca.pt/GikiCLEF 3http://inex.is.informatik.uni-duisburg. de 22 tuples which have a matching value. Based on the frequency with which attributes match, we create a bidirectional, intersective, alignment of EnglishDutch attribute pairs. Finally, we use the set of aligned attributes to expand the number of attributevalue pairs in Dutch Wikipedia with information obtained from matching English pages. We also show that aligned attributes can be used to normalize attribute names and to detect formatting issues and potential inconsistencies in attribute values. 2 Previous Work DbPedia (Auer et al., 2008) is a large, on-going, project which concentrates on harvesting information from Wikipedia automatically, on normalization of the extracted information, on linking the information with other on-line data repositories, and on interactive access. It contains 274M facts about 2.6M entities (November, 2008). An important component of DbPedia is harvesting of the information present in infoboxes. However, as Wu and Weld (2007) note, not all relevant pages have (complete) infoboxes. The information present in infoboxes is typically also present in the running text of a page. One line of research has</context>
</contexts>
<marker>Auer, Bizer, Kobilarov, Lehmann, Cyganiak, Ives, 2008</marker>
<rawString>S¨oren Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary Ives. 2008. Dbpedia: A nucleus for a web of open data. The Semantic Web, pages 722–735.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gosse Bouma</author>
<author>Ismail Fahmi</author>
<author>Jori Mur</author>
<author>Gertjan van Noord</author>
<author>Lonneke van der Plas</author>
<author>J¨org Tiedemann</author>
</authors>
<title>Using syntactic knowledge for QA.</title>
<date>2006</date>
<booktitle>In Working Notes for the CLEF 2006 Workshop,</booktitle>
<institution>The University of Groningen at QA@CLEF</institution>
<location>Alicante.</location>
<marker>Bouma, Fahmi, Mur, van Noord, van der Plas, Tiedemann, 2006</marker>
<rawString>Gosse Bouma, Ismail Fahmi, Jori Mur, Gertjan van Noord, Lonneke van der Plas, and J¨org Tiedemann. 2006. The University of Groningen at QA@CLEF 2006: Using syntactic knowledge for QA. In Working Notes for the CLEF 2006 Workshop, Alicante.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gosse Bouma</author>
<author>Jori Mur</author>
<author>Gertjan van Noord</author>
<author>Lonneke van der Plas</author>
<author>J¨org Tiedemann</author>
</authors>
<title>Question answering with Joost at QA@CLEF</title>
<date>2008</date>
<booktitle>In Working Notes for the CLEF</booktitle>
<location>Workshop, Aarhus.</location>
<marker>Bouma, Mur, van Noord, van der Plas, Tiedemann, 2008</marker>
<rawString>Gosse Bouma, Jori Mur, Gertjan van Noord, Lonneke van der Plas, and J¨org Tiedemann. 2008. Question answering with Joost at QA@CLEF 2008. In Working Notes for the CLEF 2008 Workshop, Aarhus.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Erdmann</author>
<author>K Nakayama</author>
<author>T Hara</author>
<author>S Nishio</author>
</authors>
<title>An approach for extracting bilingual terminology from wikipedia.</title>
<date>2008</date>
<booktitle>Lecture Notes in Computer Science,</booktitle>
<pages>4947--380</pages>
<contexts>
<context position="9095" citStr="Erdmann et al. (2008)" startWordPosition="1401" endWordPosition="1404">ual nature of Wikipedia has been explored previously by several researchers. Adafre and de Rijke (2006) explore machine translation and (cross-lingual) link structure to find sentences in English and Dutch Wikipedia which express the same content. Bouma et al. (2006) discuss a system for the English-Dutch QA task of CLEF. They basically use a Dutch QA-system, which takes questions automatically translated from English (by the on-line Babelfish translation service). To improve the quality of the translation of named entities, they use, among others, crosslanguage links obtained from Wikipedia. Erdmann et al. (2008) explore the potential of Wikipedia for the extraction of bilingual terminology. They note that apart from the cross-language links, page redirects and anchor texts (i.e. the text that is used to label a hypertext reference to another (wikipedia) page) can be used to obtain large and accurate bilingual term lists. 3 Data collection and Preparation We used a dump of Dutch Wikipedia (June 2008) and English Wikipedia (August 2007) made available by the University of Amsterdam4 and converted to an XML-format particularly suitable for information extraction tasks. From these two collections, for ea</context>
</contexts>
<marker>Erdmann, Nakayama, Hara, Nishio, 2008</marker>
<rawString>M. Erdmann, K. Nakayama, T. Hara, and S. Nishio. 2008. An approach for extracting bilingual terminology from wikipedia. Lecture Notes in Computer Science, 4947:380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Katz</author>
<author>G Marton</author>
<author>G Borchardt</author>
<author>A Brownell</author>
<author>S Felshin</author>
<author>D Loreto</author>
<author>J Louis-Rosenberg</author>
<author>B Lu</author>
<author>F Mora</author>
<author>S Stiller</author>
</authors>
<title>External knowledge sources for question answering.</title>
<date>2005</date>
<booktitle>In Proceedings of the 14th Annual Text REtrieval Conference (TREC’2005),</booktitle>
<contexts>
<context position="4613" citStr="Katz et al., 2005" startWordPosition="692" endWordPosition="695">olean algebra]] }} Figure 1: Infobox and (simplified) Wikimedia source all templates into account. We plan to use information mined from Wikipedia for Question Answering and related tasks. In 2007 and 2008, the CLEF question answering track1 used Wikipedia as text collection. While the usual approach to open domain question answering relies on information retrieval for selecting relevant text snippets, and natural language processing techniques for answer extraction, an alternative stream of research has focussed on the potential of on-line data-sets for question answering (Lita et al., 2004; Katz et al., 2005). In Bouma et al. (2008) it is suggested that information harvested from infoboxes can be used for question answering in CLEF. For instance, the answer to questions such as How high is the Matterhorn?, Where was Piet Mondriaan born?, and What is the area of the country Suriname? can in principle be found in infoboxes. However, in practice the number of questions that is answered by their Dutch QA-system by means information from infoboxes is small. One reason for this is the lack of coverage of infoboxes in Dutch Wikipedia. 1http://clef-qa.itc.it In the recent GIKICLEF task2 systems have to fi</context>
</contexts>
<marker>Katz, Marton, Borchardt, Brownell, Felshin, Loreto, Louis-Rosenberg, Lu, Mora, Stiller, 2005</marker>
<rawString>B. Katz, G. Marton, G. Borchardt, A. Brownell, S. Felshin, D. Loreto, J. Louis-Rosenberg, B. Lu, F. Mora, S. Stiller, et al. 2005. External knowledge sources for question answering. In Proceedings of the 14th Annual Text REtrieval Conference (TREC’2005), November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kr¨otzsch</author>
<author>D Vrandeˇci´c</author>
<author>M V¨olkel</author>
<author>H Haller</author>
<author>R Studer</author>
</authors>
<title>Semantic wikipedia. Web Semantics: Science, Services and Agents on the World Wide Web.</title>
<date>2007</date>
<marker>Kr¨otzsch, Vrandeˇci´c, V¨olkel, Haller, Studer, 2007</marker>
<rawString>M. Kr¨otzsch, D. Vrandeˇci´c, M. V¨olkel, H. Haller, and R. Studer. 2007. Semantic wikipedia. Web Semantics: Science, Services and Agents on the World Wide Web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L V Lita</author>
<author>W A Hunt</author>
<author>E Nyberg</author>
</authors>
<title>Resource analysis for question answering.</title>
<date>2004</date>
<booktitle>In Association for Computational Linguistics Conference (ACL).</booktitle>
<contexts>
<context position="4593" citStr="Lita et al., 2004" startWordPosition="688" endWordPosition="691">ic]] | ideas = [[Boolean algebra]] }} Figure 1: Infobox and (simplified) Wikimedia source all templates into account. We plan to use information mined from Wikipedia for Question Answering and related tasks. In 2007 and 2008, the CLEF question answering track1 used Wikipedia as text collection. While the usual approach to open domain question answering relies on information retrieval for selecting relevant text snippets, and natural language processing techniques for answer extraction, an alternative stream of research has focussed on the potential of on-line data-sets for question answering (Lita et al., 2004; Katz et al., 2005). In Bouma et al. (2008) it is suggested that information harvested from infoboxes can be used for question answering in CLEF. For instance, the answer to questions such as How high is the Matterhorn?, Where was Piet Mondriaan born?, and What is the area of the country Suriname? can in principle be found in infoboxes. However, in practice the number of questions that is answered by their Dutch QA-system by means information from infoboxes is small. One reason for this is the lack of coverage of infoboxes in Dutch Wikipedia. 1http://clef-qa.itc.it In the recent GIKICLEF task</context>
</contexts>
<marker>Lita, Hunt, Nyberg, 2004</marker>
<rawString>L.V. Lita, W.A. Hunt, and E. Nyberg. 2004. Resource analysis for question answering. In Association for Computational Linguistics Conference (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Ma</author>
<author>S Ozdowska</author>
<author>Y Sun</author>
<author>A Way</author>
</authors>
<title>Improving word alignment using syntactic dependencies.</title>
<date>2008</date>
<booktitle>In Proceedings of the ACL-08: HLT Second Workshop on Syntax and Structure in Statistical Translation (SSST2),</booktitle>
<pages>69--77</pages>
<contexts>
<context position="19779" citStr="Ma et al. (2008)" startWordPosition="3113" endWordPosition="3116">w dutch pages total Table 4: Newly inferred template tuples Table 3: Aligned template—attribute pairs numbers or single letters). In 117 tuples, we discovered two errors: (aircraft specification—number of props, gevechtsvliegtuig—bemanning) aligns the number of engines with the number of crew members (based on 10 matching tuples), and (book—country, film—land) involves a mismatch of templates as it links the country attribute for a book to the country attribute for a movie. Note that step 3 is similar to bidirectional intersective word alignment as used in statistical machine translation (see Ma et al. (2008), for instance). This method is known for giving highly precise results. 5 Expansion We can use the output of step 3 of the alignment method to check for each English tuple whether a corresponding Dutch tuple can be predicted. If the tuple does not exist yet, we add it. In total, this gives rise to 2.2M new tuples for 382K pages for Dutch Wikipedia (see table 4). We generate almost 300K new tuples for existing Dutch pages (250K for pages for which a cross-language link already existed). This means we exand the total number of tuples for existing pages by 27%. Most tuples, however, are generate</context>
</contexts>
<marker>Ma, Ozdowska, Sun, Way, 2008</marker>
<rawString>Y. Ma, S. Ozdowska, Y. Sun, and A. Way. 2008. Improving word alignment using syntactic dependencies. In Proceedings of the ACL-08: HLT Second Workshop on Syntax and Structure in Statistical Translation (SSST2), pages 69–77.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D P T Nguyen</author>
<author>Y Matsuo</author>
<author>M Ishizuka</author>
</authors>
<title>Relation extraction from wikipedia using subtree mining.</title>
<date>2007</date>
<booktitle>In PROCEEDINGS OF THE NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE,</booktitle>
<pages>1414</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="7556" citStr="Nguyen et al., 2007" startWordPosition="1155" endWordPosition="1158"> the extracted information, on linking the information with other on-line data repositories, and on interactive access. It contains 274M facts about 2.6M entities (November, 2008). An important component of DbPedia is harvesting of the information present in infoboxes. However, as Wu and Weld (2007) note, not all relevant pages have (complete) infoboxes. The information present in infoboxes is typically also present in the running text of a page. One line of research has concentrated on using the information obtained from infoboxes as seeds for systems that learn relation extraction patterns (Nguyen et al., 2007). Wu and Weld (2007) go one step further, and concentrate on learning to complete the infoboxes themselves. They present a system which first learns to predict the appropriate infobox for a page (using text classification). Next, they learn relation extraction patterns using the information obtained from existing infoboxes as seeds. Finally, the learned patterns are applied to text of pages for which a new infobox has been predicted, to assign values to infobox attributes. A recent paper by Adar et al. (2009) (which only came to our attention at the time of writing) starts from the same observ</context>
</contexts>
<marker>Nguyen, Matsuo, Ishizuka, 2007</marker>
<rawString>D.P.T. Nguyen, Y. Matsuo, and M. Ishizuka. 2007. Relation extraction from wikipedia using subtree mining. In PROCEEDINGS OF THE NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, page 1414. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Wu</author>
<author>Daniel S Weld</author>
</authors>
<title>Autonomously semantifying wikipedia.</title>
<date>2007</date>
<booktitle>In CIKM ’07: Proceedings of</booktitle>
<contexts>
<context position="2743" citStr="Wu and Weld (2007)" startWordPosition="413" endWordPosition="416">ia’s, it is also true that even the larger Wikipedia’s can be supplemented with information harvested from smaller Wikipedia’s. Wikipedia infoboxes are tabular summaries of the most relevant facts contained in an article. They represent an important source of information for general users of the encyclopedia. Infoboxes (see figure 1) encode facts using attributes and values, and therefore are easy to collect and process automatically. For this reason, they are extremely valuable for systems that harvest information from Wikipedia automatically, such as DbPedia (Auer et al., 2008). However, as Wu and Weld (2007) note, infoboxes are missing for many pages, and not all infoboxes are complete. This is particularly true for Wikipedia’s in languages other than English. Infoboxes are a subclass of Wikipedia templates, which are used by authors of Wikipedia pages to express information in a systematic way, and to ensure that formatting of this information is consistent across Wikipedia. Templates exist for referring to multimedia content, external websites, news stories, scientific sources, other on-line repositories (such as the Internet Movie Database (IMDB), medical classification systems (ICD9 and ICD10</context>
<context position="7236" citStr="Wu and Weld (2007)" startWordPosition="1104" endWordPosition="1107">w that aligned attributes can be used to normalize attribute names and to detect formatting issues and potential inconsistencies in attribute values. 2 Previous Work DbPedia (Auer et al., 2008) is a large, on-going, project which concentrates on harvesting information from Wikipedia automatically, on normalization of the extracted information, on linking the information with other on-line data repositories, and on interactive access. It contains 274M facts about 2.6M entities (November, 2008). An important component of DbPedia is harvesting of the information present in infoboxes. However, as Wu and Weld (2007) note, not all relevant pages have (complete) infoboxes. The information present in infoboxes is typically also present in the running text of a page. One line of research has concentrated on using the information obtained from infoboxes as seeds for systems that learn relation extraction patterns (Nguyen et al., 2007). Wu and Weld (2007) go one step further, and concentrate on learning to complete the infoboxes themselves. They present a system which first learns to predict the appropriate infobox for a page (using text classification). Next, they learn relation extraction patterns using the </context>
</contexts>
<marker>Wu, Weld, 2007</marker>
<rawString>Fei Wu and Daniel S. Weld. 2007. Autonomously semantifying wikipedia. In CIKM ’07: Proceedings of</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>