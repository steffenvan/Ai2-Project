<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006559">
<title confidence="0.9270525">
Asymmetry in Parsing and Generating with Unification Grammars:
Case Studies From ELU
</title>
<author confidence="0.769468">
Graham Russell,* Susan Warwick,* and John Carrolit
</author>
<address confidence="0.4329425">
*ISSCO, 54 rte. des Acacias t Cambridge University Computer Laboratory
1227 Geneva, Switzerland New Museums Site, Pembroke Street
</address>
<email confidence="0.782234">
russell@divsun.unige.ch Cambridge CB2 3Q0
</email>
<sectionHeader confidence="0.9847" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9994835625">
Recent developments in generation algorithms have
enabled work in unification-based computational
linguistics to approach more closely the ideal of
grammars as declarative statements of linguistic
facts, neutral between analysis and synthesis. From
this perspective, however, the situation is still far
from perfect; all known methods of generation
impose constraints on the grammars they assume.
We briefly consider a number of proposals for
generation, outlining their consequences for the
form of grammars, and then report on experience
arising from the addition of a generator to an exist-
ing unification environment. The algorithm in
question (based on that of Shieber et al. (1989)),
though among the most permissive currently avail-
able, excludes certain classes of parsable analyses.
</bodyText>
<sectionHeader confidence="0.96764" genericHeader="method">
I. Introduction
</sectionHeader>
<bodyText confidence="0.989784207792208">
Parsing and generation are both concerned with the
relation between texts and representations, and in
so far as a grammar defines this relation without
reference to direction, it may be regarded as rever-
sible. Yet, in practice, dre program which &apos;applies&apos;
a grammar for the purpose of parsing is quite dis-
tinct from the one which performs generation.&apos;
The essential difference between parsing and
generating lies in the nature of the input. The text,
as a string of words, traditionally establishes the
starting point of parsing whether the processing is
top-down or bottom-up, the basis for selecting
grammar rules is information associated with words
in the lexicon. In the case of generation, there is in
general no guarantee that the constituents of an
input representation correspond to words; a portion
of the input may be related directly to a given word,
or it may be the result of combining representations
associated to some sequence of rules, portions of
which are ultimately related to lexical items. For
example, if the sentence John kicked the bucket
receives the semantic representation die(John), it is
Parsing and generation need not employ dif-
ferent algorithms or control strategies; see Shieber
(1988) for discussion. However, a truly reversible
program would be an entirely different undertaking
fi.ren what is described here. One such project is
currently under way at New Mexico State Universi-
ty (Yorick Wilks, p.c.). 205
relatively easy to see how during parsing the recog-
nition of kicked and the bucket will provide the
necessary information (from the lexical entry for
kick) to build that representation. The representa-
tion and the lexical items are in general related not
directly, but rather via intermediate syntactic rules,
any of which is able to manipulate the representa-
tion in arbitrary ways; in generation, it is not possi-
ble to identify the correct lexical item without con-
sidering the syntactic rules which may intervene.
The generation problem, then, consists in bow
to build a syntactic structure from an initial
representation, taking it as the root, and extending
the Monte &apos;downward&apos; to the lexicon by select-
ing rules from the grammar and attaching them at
the appropriate points.
Though unification based systems have been in
use for parsing for a number of years, generation
has until recently not attracted comparable atten-
tion, Wedekind (1988), Dymetmano &amp; Isabelle
(1988) and Shieber (1988) describe three systems
of note. Not surprisingly, given the relative infancy
of these explorations, none of these systems is
without problems. The most permissive of the
current proposals appears to be Shieber et al.&apos;s
(1989) revision of the Shieber (1988) algorithm, yet
several plausible grammatical analyses handled by
the parser are beyond the capacity of even this
approach.
This paper reports on experience arising from
the addition of a generator component to the ELU2
environment; the algorithm is a variant of that pro-
posed in Shieber et al. (1989). We first consider
general aspects of adapting unification grammars
initially developed for parsing to their use in gen-
eration. A brief description of the generator in FLU
highlights the differences and improvements we
have adopted. We then demonstrate shoncornings
2 &amp;quot;Environnement Linguinique d &apos;Unification&amp;quot;.
Cf. Johnson &amp; Rosner (1989) for a description of
UD (Unification Device) which includes the parser
and facilities such as procedural abstractions and
extended data types (lists and trees) and Estival et
al. (1989) for a description of the extended ELU
system which incorporates the original UD plus a
generation and translation component.
of this class of generation algorithms on the basis of
two case studies.
</bodyText>
<sectionHeader confidence="0.851011" genericHeader="method">
2. Generating with Unification Gram-
mars
</sectionHeader>
<bodyText confidence="0.999937958333333">
The goal of employing a single, minimally aug-
mented, grammar for both parsing and generation
has become more accessible with the introduction
of declarative grammar formalisms (cf. Kay, 1985).
In the context of machine translation, for which the
ELU system has been developed, the use of the
same grammar for both tasks is highly desirable;
indeed much of the work on bidirectional grammars
has been carried out in centres working on MT (cf.
Busemann, 1987; van Noord, to appear; Dyrnet-
mann &amp; Isabelle, 1988; and Wedekind-. 1988).
Regardless of the application, however, the ability
to generate with a grammar is extremely useful as a
method of checking its adequacy.
Despite the objective of reversibility, all of the
systems mentioned here impose generation-specific
restrictions on their grammars, either by limiting
the form of possible rules or by augmenting them
with annotations. Dymetmann &amp; Isabelle (1988)
require the grammar writer to specify for each rule
the order in which daughters should be generated;
however, an order that might be correct when gen-
erating from one structure can lead to non-
terminating search with another. Busemann (1987)
and Saint-Dizier (1989) describe methods of gen-
eration which rely on the parsing of a control struc-
ture using a specialized grammar to build the syn-
tax of a sentence; it is questionable to what extent
the latter two systems can be considered to operate
with bidirectional grammars.
Constraints imposed by Wedekind (1988) and
van Noord (to appear) exclude certain linguistic
analyses from generation. In order to overcome the
high degree of non-determinism inherent in the
top-down approach, Wedekind stipulates that a
daughter of a rule must be &apos;connected&apos; (i.e. that its
semantics must be instantiated) before it can be
generated from. Less restrictively, van Noord
stipulates similar constraints on rules, i.e. that if the
semantics of the mother node is known, then the
semantics of the head daughter is instantiated, and
additionally that if the syntax of the semantic head
is known, then the semantics of each daughter is
known. These restrictions limit the class of possi-
ble analyses, excluding accounts appropriate to
LFG (Kaplan and Bresnan, 1982), HPSG (Pollard
&amp; Sag, 1987) and UCG (Zeevat et al., 1987).
The disparate state of progress in parsing and
generation raises important issues concerning the
adequacy of grammatical descriptions and the com-
putational tools that interpret them. A situation
exists in which a grammar may be &apos;correct&apos; for
analysis, but &apos;incorrect&apos; for generation.
Significantly, this may be the case even when the
restrictions and annotations mentioned above are
taken into account. Grammatical analyses
developed in a purely parsing environment cannot
always be transferred straightforwardly into a for-
mat suitable for generation. Two types of conclu-
sion may be drawn from this: failures may be
ascribed to inadequacies of current generator tech-
nology, or the grammatical analyses in question
may be re-evaluated. Practical remedies will
involve two related strands of research; improving
methods of generation so as to minimize restric-
tions on the form of grammars that can be gen-
erated from, and identifying problematic properties
of grammars. It is the second of these which the
present paper chiefly addresses, though we also
remark, in the next section, on some enhancements
to the Shieber et al. (1989) algorithm that have been
incorporated in the ELU generator.
</bodyText>
<subsectionHeader confidence="0.573481">
3. The Generator in ELU
</subsectionHeader>
<bodyText confidence="0.998188926829269">
In this section we describe the generation algorithm
in FLU, and discuss in what respects it differs from
that described by Shieber et al. (1989).3 Two
notions central to this method of generation are that
of the &apos;pivot&apos;, and that of partitioning the grammar
into &apos;chaining&apos; and &apos;non-chaining&apos; rules. Loosely,
the &apos;pivot&apos; of a structure to be generated from is the
lowest node in a path down semantic heads of rules
at which the semantics of the cunent generation
root structure remains unchanged. A chaining rule
is one in which the semantics of the object associ-
ated with the right-hand side category that has been
declared as the head unifies with that of the left-
hand side category. Other rules are non-chaining
rules. Rules that apply between the root and the
pivot are, by definition, chaining rules; further, any
rule which can be attached below the pivot is, by
definition, a non-chaining rule. Rules are parti-
tioned into these two groups during grammar com-
pilation.
Once the chaining rules have been identifed, the
grammar compiler computes the possible sequences
of such rules along a path through their mothers and
semantic heads. The result is a &apos;reachabffity table&apos;,
each of whose elements is a pair of restrictor value
sets4 representing classes of FSs which can occur at
the top and bottom of such a path; in each case, the
&apos;bottom&apos; restrictor set characterizes a pivot. A res-
trictor set is also computed for each lexical stem, in
order to retrieve words efficiently during genera-
tion.
The generation algorithm uses the distinction
between chaining and non-chaining rules as well as
3 Our discussion will therefore assume familiari-
ty with this paper.
4 Restrictors are attributes selected by the writer
of a grammar as being maximally distinctive; when
two FSs are to be unified, their respective restrictor
values are first checked for compatibility, so as to
eliminate the cost of an attempted unification which
is bound to fail. See Shieber (1985).
</bodyText>
<page confidence="0.992148">
206
</page>
<bodyText confidence="0.978674454545455">
that between head and non-head daughters, the
rea.drability table for chaining rules, the semantic
portion of the FS to be generated from5, and the
restrictors for lexicon stems. The algorithm is:
1. Take all grammar rules declared as &apos;initial&apos; (or
all rules in the grammar if no such declaration
has been made); for each of these rules whose
mother unifies with the input FS, apply the rule
top-down, building FSs for each of the
daughters, and, starting with the head daughter,
execute step 2 for each one. If generation from
the daughters is successful, compute all possible
word-forms (as constrained by the locally avail-
able syntactic information) for each lexical stem
generated.
2. Create a pivot consisting of just the semantic
portion of the current FS. Non-deterministic-
ally perform steps 2a and 2b:
a. find a lexical stem which unifies with the
pivot, making sure (by checking with the
reachability table) that the FS resulting from
the unification can be linked through seman-
tic heads of just chaining rules up to the
current FS.
b. Find a non-chaining rule which can have the
pivot as mother, similarly making sure that
the FS resulting from the unification of the
pivot and the mother can be linked up to the
current FS. Recursively (through 2) gen-
erate the rule&apos;s daughters, starting with the
head daughter.
3. Link the pivot up to the current FS through
semantic heads of just chaining rules (at each
stage, before adding a new rule in the chain,
checking with the leachability table that further
linking will be possible) and then recursively
(through 2) generate the non-bead daughters of
these rules.
In this algorithm non-chaining rules are used top-
down, while chaining rules are used bottom-up.
Linking information is used both to check the appli-
cability of a lexical stem or a non-chaining rule
when generating top-down from a pivot, and also to
control search when generating bottom-up, by
ensuring that the left-hand side of any rule con-
sidered still lies on a possible path through chaining
rules to the current FS.
One innovation of the MX generator is that the
notion &apos;semantic head&apos; is interpreted rather dif-
ferently; whereas the earlier work simply defines
the semantic head of a rule as the daughter whose
semantics unifies with that of the left-hand side, and
thus leaves the notion undefined for non-chaining
rules, that described here permits the grammar
writer to identify one daughter in each rule as the
</bodyText>
<sectionHeader confidence="0.713318" genericHeader="method">
5 The relevant paths being determined by the
user&apos;s declaration
</sectionHeader>
<bodyText confidence="0.999969705882353">
semantic head. A rule in which a daughter shares
the semantics of the mother can thus be made into a
chaining rule or a non-chaining rule, according to
whether that daughter is identified as the semantic
head, and a rule that would otherwise have multiple
semantic heads can be assigned just one.6 A rule in
which there is no such daughter will remain a non-
chaining rule, but may nevertheless be annotated
with a similar specification. The rationale is two-
fold: the ability to coerce what would otherwise be
a draining rule to a non-chaining rule grants the
grammar writer more control over generation, and
the ability to specify one daughter as semantically
more significant than the others may be exploited in
order to direct the attention of the generator
towards that daughter.
A second difference is the order of events in
bottom-up generation. Instead of generating from
the non-head daughters of each chaining rule as it is
attached, the pivot is first linked to the root, so that,
if backtracking is famed, effort will not have been
spent on processing structure that must be dis-
carded.
Finally, on each occasion that top-down genera-
tion is initiated, an attempt is made to add a lexical
item below the current root, rather than extending
the path by application of non-chaining rules until
no such rule is applicable. Here, the motivation is
that lexical information may be made available as
soon as possible without forcing the grammar
writer to adopt analyses that will produce bottom-
up generation. This is important because global
syntactic properties of a sentence are often deter-
mined by lexical information.
</bodyText>
<sectionHeader confidence="0.9892575" genericHeader="method">
4. Grammars for Generation
4.1. Introduction
</sectionHeader>
<bodyText confidence="0.9997431">
In this section we examine more closely interac-
tions between generator and grammar. These fall
under two headings: (i) the presence of non-
determinism in the grammar, and (ii) the role of
lexicalism.
One aspect of non-determinism in generation,
that of the ordering of rule application, is partially
overcome in ELI) by the user specification of the
head daughter. Non-determinism with respect to
the order of solving constraint equations is less well
understood. The use of restrictors helps to reduce
the number of feature structures to be considered.
6 Thus circumventing a problem noted by
Shieber et al. (1989, fn. 4) in connection with such
rules. Van Noord (p.c.) stipulates that any daughter
which has the same semantics as the mother, but is
not the semantic head, may not branch: this con-
straint is clearly too strong, precluding, among oth-
er things, linguistically motivated accounts of coor-
dination.
</bodyText>
<page confidence="0.988274">
207
</page>
<bodyText confidence="0.999994538461539">
However, in ELU, the use of relational abstractions
as a generalization of template facilities increases
the problem considerably! Relational abstractions
permit the grammar writer to augment the phrase
structure rules with statements which may receive
multiple definitions in terms of constraint equa-
tions; the &apos;Linear Precedence&apos; definition in (2)
below is an example. This facility is a standard
ELU device for collapsing what would in an unex-
tended PATR-like formalism be several distinct
rules, thereby capturing linguistic generalizations
that would otherwise go unexpressed.
It is particularly important to control non-
determinism in generation, since, at least when pro-
cessing is initiated, there is relatively little informa-
tion available to direct the search. Expanding multi-
ple definitions as they are encountered would give
rise to an unacceptable number of alternatives,
many of which might be identical, and often the
information from the abstraction is not required
until all but one of the alternatives have been
excluded by other factors. This is not always the
case, however, and when exceptions occur their
effect may be drastic. We now describe one such
exception to demonstrate how an elegant analysis
for parsing is unsuitable for generation.
</bodyText>
<subsectionHeader confidence="0.986506">
4.2. A grammar for French chtics
</subsectionHeader>
<bodyText confidence="0.988104868421053">
A common technique in modem lexically-oriented
grammars, and one which reflects and extends the
traditional notion of &apos;valency&apos;, is to encode infor-
mation about the various phrases with which a verb
combines in items on a subcategorization list. The
grammar then enforces a match between a member
of the list and a phrase which is to combine with
some projection of the verb and removes the item
from the list. When a sentence is complete, i.e. the
verb has &apos;found&apos; all necessary phrases, a grammar
may require that the list be empty, or perhaps that
any remaining item is in some way specified as
optional. See e.g. Shieber (1986) and Pollard and
Sag (1987) for applications of this method.
A complete grammar of French must account
for the position and ordering of ethic pronouns.
These precede the verb, while other complement
phrases follow. Moreover, they appear in a fixed
order, as shown in (1):
(1) me le lui y en
te 1 a leur
se les
nous
vous
Up to three ethics may occur, but for the sake of
this discussion, we consider only the simpler case
7 Cf. Johnson &amp; Rosner (1989) for a fuller
description of relational abstractions.
of two clitics as complement phrases to the verb.8
There are of course many ways of accounting for
their distributioe the subcategorizarion list device
seems a natural solution, since any complement
phrase may be realized as a elide. The grammar
rule in (2) introduces up to two elides before the
verb, their relative order determined by a relational
abstraction which is defined by a number of
clauses, each clause licensing one of the possible
clitic sequences.
</bodyText>
<figure confidence="0.9707006">
(2) vplus -&gt; C11 C12 HV
Ihecede(C11,02)
List = r.HV subcar&gt; C11
r-vplus subcat&gt; = List -- C12
Preeede(X,Y)
r..X person&gt; = lust/second
rY person&gt; = third
Precede(X,Y)
&lt;X case&gt; = accusative
rY case&gt; = dative
</figure>
<bodyText confidence="0.997713861111111">
Some remarks on notation will be helpful: calls to
relational abstractions are indicated by the exclama-
tion mark, feature-value disjunction is indicated by
the slash, and an equation of the form
= Y Z&apos;, where X and Y are lists, unifies X
non-deterministically with the result of extracting
one instance of Z from Y.
The effect of this rule, then, is to associate a
pair of clitic:s with a verb, checking that they are
correctly ordered, and unifying the subcategoriza-
tion list of the left-band side category with a copy
of that of the head verb from which objects unify-
ing with each of the elides have been removed.
The problem emerges when information
assumed to be held in the subcategorization list of
`vplus&apos; is required in order to control further gen-
eration. For example, if `vpIus&apos; appears as sister to
another complement phrase, and the same pro-
cedure of unifying the latter with an item on the list
takes place, then because the generator has
suspended expansion of non-deterministic abstrac-
tions, the subcategorization list itself will be unin-
stantiated, and therefore no information regarding
the semantics of the complement phrase will be
available to restrict top-down generation.
8 This is something of an oversimplification, as
not only complement phrases, but also adverbials
and parts of complement phrases are realized as cli-
tics. See Grimshaw (1982) for a partial LFG ac-
count of these phenomena. We also ignore the is-
sue of negation, which considerably complicates
the clitic-aux-verb structure.
9 The categorial treatment proposed in Baschung
et al. (1987) not only makes use of order of argu-
ments, but also codes each ethic for all possible
combinations.
</bodyText>
<page confidence="0.996327">
208
</page>
<bodyText confidence="0.999688764705882">
Modifications to the syntactic constituency
assumed here do not affect the principle; as long as
the instantiation of so central an element of the
grammar as the subcategorization list is delayed,
the problem will remain. An alternative type of
analysis would remove the non-detemiinism from
the grammar by factoring it out into a larger
number of rules. This solution is not without its
own disadvantages; the number of distinct rules
needed by a full treatment of French clues,
integrated with the placement of the various nega-
tive particles and auxiliaries, should not be underes-
timated. We postpone further discussion of non-
determinism and delay until the conclusion and turn
now to the problem of empty semantic beads, an
important problem for bead-driven generation algo-
rithms.10
</bodyText>
<subsectionHeader confidence="0.997257">
4.3. Empty Semantic Heads
</subsectionHeader>
<bodyText confidence="0.999340956521739">
In German and Dutch, there are two positions in a
sentence where tensed verbs may appear: in second
position of a main clause, and in final position of a
subordinate clause. Once again, a multitude of ana-
lyses an possible within ELU grammars. One
approach is to control the distribution of verbs with
grammar rules specific to clause-type; this solution
gives rise to what might be felt to be an unaccept-
able degree of duplication in the grammar. A more
elegant approach, successful for parsing, exploits
the possibility of associating a word or phrase
appearing in one position within a sentence with a
&apos;gap&apos; elsewhere.
The latter analysis will be recognized as a vari-
ant of a standard Government-Binding treatment, in
which a tensed verb in a main clause is &apos;raised&apos;
from an &apos;underlying&apos; sentence-final position to a
&apos;surface&apos; second position (see e.g. Haider (1985),
Platzack (1985) for discussion of this class of ana-
lyses). The dependency may be implemented by
the use of a feature, say `v2&apos;, whose value in a
verb-second construction is a feature structure
representing the verb to be raised, and in other con-
structions an atomic constant such as &apos;none&apos;, which
serves to block the dependency. At the extraction
site, any value of `v2&apos; other than &apos;none&apos; may be
cashed out as an empty production. Information
regarding the various syntactic properties of the
raised verb is passed in the normal fashion between
the verb&apos;s true position and the extraction site,
where it is able to exert the same constraints upon
complement phrases that a lexically-realized verb
would.
The simplified rule set given in (3) will serve as
a basis for discussion. Recall that the generator
operates by partitioning the rules of the grammar
1° This problem is alluded to in Shieber et al.
(1989, fn.4) and is discussed in a draft of an ex-
panded version of the paper.
into classes to be applied top-down (non-chaining
rules — here &apos;5-gap&apos; and &apos;VT) and bottom-up
(chaining rules — here &apos;TOP&apos;, &apos;5&apos; and &apos;V),
Bottom-up generation is only practical if the input
structure to that phase of generation contains
sufficient information, e.g. the verb with its sub-
categorization list.
</bodyText>
<table confidence="0.884408222222222">
(3) # Rule TOP
TOP -&gt; XP H_S
&lt;10 cat&gt; = top &lt;4. head&gt; = &lt;H_S head&gt;
&lt;XP cat&gt; = op &lt;H_S subcat&gt; = [XP)
&lt;H_S cat&gt; = sbar
# Rule V2
Sbar -&gt; H_V2 S
&lt;ilk cat&gt; sbar &lt;1I_V2 cat&gt; is v
&lt;5 cat&gt; = s &lt;* subcat&gt; &lt;5 subcat&gt;
•S v2&gt; H_V2 &lt;4, head&gt; = head&gt;.
&lt;H_V2 head syn vfonn&gt; = finite
# Rule S
S -&gt; XP H_S
rS cat&gt; = s
&lt;* head&gt; := r.H_V head&gt;
&lt;4, subcat&gt;4= e.H_V subcat&gt;
&lt;S head&gt; ss &lt;V2 head&gt;
rS subcat&gt; = &lt;V2 subcat&gt;
</table>
<bodyText confidence="0.994292384615384">
The verb-raising analysis sketched here has the
unfortunate property of supplying the generator
with a semantic head (the verb gap) about which
nothing is known. Al the stage when top-down
processing has identified the verb gap as the start-
ing point for bottom-up generation, the input
feature structure is undetspecified. In particular,
the subcategorizadon list of the missing verb is
unin.stantiated, and in the grammar in question, it is
the length of this list which controls invocation of
the recursive rule 45&apos;. No bindings can be found,
and the generator suspends evaluation of that equa-
tion in the hope, ill-founded on this occasion, that
information not yet present will later allow its solu-
tion. The result is that &apos;5&apos; is repeatedly added
above &apos;S-gap&apos;, in a non-terminating attempt to
ensure completeness of the search.
Van Noord (1989) describes two solutions to
this problem, both of which are additions to the ori-
ginal program, and whose only motivation (so far)
is to overcome this specific problem. The first,
somewhat ad-hoc, solution allows the verb to have
as one of its morphological realbation.s the empty
string. Since word forms are generated at the end
of processing by a morphological front-end, the
generator can posit the same word in both positions
</bodyText>
<figure confidence="0.998611583333333">
&lt;XP cat&gt; .c up
&lt;H_S cat&gt; = s &lt;e• v2.&gt; = cji_s v2&gt;
&lt;4. subcat&gt; = &lt;H_S subcat&gt; XP
&lt;4. head&gt; = &lt;H_S head&gt;
# Rule V
S -&gt; H_V
,eS Cal&gt; = s
&lt;H_V cat&gt; v
# Rule S-gap
-&gt; —
&lt;S cat&gt; s
&lt;S v2&gt; V2
</figure>
<page confidence="0.995237">
209
</page>
<bodyText confidence="0.999958419354839">
Given that work OD this type of generation is in
its early gages, it is to be hoped that continuing
research will enable less restricted grammars to be
written. Nevertheless, the currently available facili-
ties have been employed successfully in general,
making it possible to envisage defining the &apos;ade-
quacy&apos; of a grammar in terms of its behavior both
in parsing and in generation.
(for the purpose of retrieving its subcategraization
behaviour from the lexicon, for example). The
morphological component then generates one
empty siring and one full word according to the
position of the verb (i.e. in a main or subordinate
clause). This mechanism is not available in &amp;U.
The second solution adds an additional &apos;connect&apos;
clause in the Prolog program, specific to gaps, in
order to assure that the gap is first instantiated
before further processing; this solution raises the
issue of tuning programs to treat specific problems
as they are encountered.
There are other constructions which raise the
same kind of problem; the fronting of apparently
non-constituent verbal sequences in German (Ner-
bonne, 1986) introduces more complex dependen-
cies, while in English the phenomena of Gapping
and Verb-Phrase Ellipsis both manifest themselves
syntactically in the absence from a sentence of a
verb and possibly other material. Here, the
difficulty is, if anything, greater, as the dependen-
cies in question are anaphoric in nature, rather than
syntactic.
</bodyText>
<sectionHeader confidence="0.997993" genericHeader="conclusions">
5. Conclusion
</sectionHeader>
<bodyText confidence="0.999807666666667">
We have seen, in the preceding section, how in
order to write grammars suitable for use with the
generator, one must either modify the technical
aspects of the grammar or dispense with certain
classes of grammatical analysis (losing the benefits
of relational abstraction on one hand, and lexical-
ism on the other, for example). Both of these may
be interpreted as restricting the freedom of the
grammar writer. The problematic case illustrated in
section 4.2 raises the issue of non-determinism, a
potential pitfall for all unification-based systems.
In parsing, the result may be long processing times,
but when generating with algorithms of this class,
the consequence is often non-tenningion. As
Shieber et al. (1989, fn.4) observe, failure to choose
the right daughter as the starting point for recursive
generation may prevent termination.
The desire to exploit the power of unification by
using the lexicon as a repository of essentially syn-
tactic (beyond pure semantic) information is
natural, and has been encouraged by the success in
theoretical linguistics of grammatical formalisms
which employ such techniques. Yet the use of
these techniques in grammar writing, which are
highly attractive from the point of view of economy
and expressive power, deprives the generator of
information that is, strictly speaking, syntactic.
Semantic heads alone are not sufficient to drive the
generation process, if syntactic information cannot
also be made available. Our interim conclusion is
that strong versions of the lexicalist position do not
appear to be compatible with our current generator,
at least for a number of cases. This is not to say
that it should be abandoned — the benefits in terms
of clarity and economy are probably too great — but
some care is needed if it is to be exploited effec- 210
</bodyText>
<sectionHeader confidence="0.996057" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998897358695653">
Baschung, K, G.G. Bes, A. Coduy, and T. Guillotin
(1987) &amp;quot;Auxiliaries and Clines in French UCG
Grammar&amp;quot;. Proceedings of the Third Confer-
ence of the European Chapter of the Associa-
tion for Computational linguistics, Copen-
hagen, Denmark, April 1st-3rd 1987: 173-178.
Bresnan, J. (ed.) (1982) The Mental Representation
of Grammatical Relations. Cambridge, MA:
MIT Press.
Busemann, S. (1987) &amp;quot;Generierung nut GPSG&amp;quot;.
KIT-Report 49, Technische Univenitlit Berlin.
Dymetman, M. &amp; P. Isabelle (1988) &amp;quot;Reversible
Logic Grammars for Machine Translation&amp;quot;.
Proceedings of the 2nd International Coher-
ence on Theoretical and Methodological Issues
in Machine Translation of Natural Languages,
Carnegie-Mellon University, Pittsburgh, USA.
Estival, II, A. Salim, G. Russell, and S. Warwick
(1989) &amp;quot;A Syntax and Semantics for Feature-
Structure Transfer&amp;quot;. MS, 1SSCO.
Grimshaw, J. (1982) &amp;quot;On the Lexical Representa-
tion of Romance Reflexive Clitics&amp;quot;, in Bits=
(ed.): 87— 148.
Haider, H. (1985) &amp;quot;V-Second in Getman&amp;quot;, in H.
Haider and M. Prinz.hom (eds.) Verb Second
Phenomena in Germanic Languages: 49 — 75.
Dordrecht: Foris.
Johnson, R. and M. Rosner (1989) &amp;quot;A Rich
Environment for Experimentation with
Unification Grammars&amp;quot;. Proceedings of the
Fourth Coherence of the European Chapter of
the Association for Computational Linguistics,
Manchester, UK, April Ifith-12th 1989:
182-189.
Kaplan, R.M. and J. Bresnan (1982) &amp;quot;Lexical-
Functional Grammar A Formal System for
Grammatical Representation&amp;quot;, in Bresnan (ed.):
173-281.
Kay, M. (1985) &amp;quot;Parsing in Functional Unification
Grammar&amp;quot;, in D. Dowty, L. Kamunen, and A.
Zwicky (eds.) Natural Language Parsing.
Cambridge: Cambridge University Press:
251-278.
Nerbonne, J. (1986) &amp;quot;&apos;Phantoms&apos; and German
Fronting: Poltergeist Constituents?&amp;quot;, Linguis-
tics 24-5, 857-870.
van Noord, G. (to appear) &amp;quot;Bottom Up Generation
in Unification-based Formalisms&amp;quot;, in C. Mell-
ish, R. Dale, and M. Zock (eds.) Proceedings of
the Second European Workshop on Natural
Language Generation.
Platza.ck, C. (1985) &amp;quot;A Survey of Generative Ana-
lyses of the Verb Second Phenomenon in Ger-
manic&amp;quot;. Nordic Journal of linguistics 8:
49-73.
Pollard, C. and IA. Sag (1987) Information-Based
Syntax and Semantics, Volume 1: Fundamen-
tals. CSLI Lecture Notes no. 13
Saint-Diner, P. (1989) &amp;quot;A Generation Method
Based on Principles of Government-Binding
Theory&amp;quot;. Paper presented at the Second Euro-
pea.n Natural Language Generation Workshop,
Edinburgh, April 1989.
Shieber, S.M. (1985) &amp;quot;Using ReSiliCti011 to Extend
Parsing Algorithms for Complex-Feature-Based
Formalisms&amp;quot;. Proceedings of the 23rd Annual
Meeting of the Association for Computational
Linguistics: 145-152.
Shieber, S.M.. (1986) An Introduction to
Unification-Based Approaches to Grammar.
CSLI Lecture Notes no. 4.
Shieber, S.M. (1988) &amp;quot;A Uniform Architecture for
Parsing and Generation&amp;quot;. Proceedings of the
12th International Conference on Computa-
tional Linguistics, Budapest, Hungary:
614-619.
Shieber, S.M., van Noord, G., R.C. Moore, and
F.C.N. Pereira (1989) &amp;quot;A Semantic-Head-
Driven Algorithm for Unification-Based For-
malisms&amp;quot;. Proceedings of the 27th Annual
Meeting of the Association for Computational
Linguistics :7-17.
Wedekind, J. (1988) &amp;quot;Generation as Structure-
Driven Derivation&amp;quot;. Proceedings of the 12th
International Conference on Computational
Linguistics, Budapest, Hungary: 732-737.
Zeevat, IL, E. Klein, and J. Calder (1987)
&amp;quot;Unification Caftgorial Grammar&amp;quot;. Categorial
Grammar, Unification Grammar, and Parsing,
Edinburgh Working Papers in Cognitive Sci-
ence, Volume 1. Centre for Cognitive Science,
University of Edinburgh: 195-222
</reference>
<page confidence="0.998771">
211
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.615607">
<title confidence="0.9151615">Asymmetry in Parsing and Generating with Unification Grammars: Case Studies From ELU</title>
<author confidence="0.999672">Graham Russell</author>
<author confidence="0.999672">Susan Warwick</author>
<author confidence="0.999672">John Carrolit</author>
<affiliation confidence="0.989284">ISSCO, 54 rte. des Acacias t Cambridge University Computer Laboratory</affiliation>
<address confidence="0.879748">1227 Geneva, Switzerland New Museums Site, Pembroke Street russell@divsun.unige.ch Cambridge CB2 3Q0</address>
<abstract confidence="0.998967705882353">Recent developments in generation algorithms have enabled work in unification-based computational linguistics to approach more closely the ideal of grammars as declarative statements of linguistic facts, neutral between analysis and synthesis. From this perspective, however, the situation is still far from perfect; all known methods of generation impose constraints on the grammars they assume. We briefly consider a number of proposals for generation, outlining their consequences for the form of grammars, and then report on experience arising from the addition of a generator to an existing unification environment. The algorithm in question (based on that of Shieber et al. (1989)), though among the most permissive currently available, excludes certain classes of parsable analyses.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Baschung</author>
<author>G G Bes</author>
<author>A Coduy</author>
<author>T Guillotin</author>
</authors>
<title>Auxiliaries and Clines in French UCG Grammar&amp;quot;.</title>
<date>1987</date>
<booktitle>Proceedings of the Third Conference of the European Chapter of the Association for Computational linguistics,</booktitle>
<pages>173--178</pages>
<location>Copenhagen, Denmark,</location>
<contexts>
<context position="20102" citStr="Baschung et al. (1987)" startWordPosition="3249" endWordPosition="3252">spended expansion of non-deterministic abstractions, the subcategorization list itself will be uninstantiated, and therefore no information regarding the semantics of the complement phrase will be available to restrict top-down generation. 8 This is something of an oversimplification, as not only complement phrases, but also adverbials and parts of complement phrases are realized as clitics. See Grimshaw (1982) for a partial LFG account of these phenomena. We also ignore the issue of negation, which considerably complicates the clitic-aux-verb structure. 9 The categorial treatment proposed in Baschung et al. (1987) not only makes use of order of arguments, but also codes each ethic for all possible combinations. 208 Modifications to the syntactic constituency assumed here do not affect the principle; as long as the instantiation of so central an element of the grammar as the subcategorization list is delayed, the problem will remain. An alternative type of analysis would remove the non-detemiinism from the grammar by factoring it out into a larger number of rules. This solution is not without its own disadvantages; the number of distinct rules needed by a full treatment of French clues, integrated with </context>
</contexts>
<marker>Baschung, Bes, Coduy, Guillotin, 1987</marker>
<rawString>Baschung, K, G.G. Bes, A. Coduy, and T. Guillotin (1987) &amp;quot;Auxiliaries and Clines in French UCG Grammar&amp;quot;. Proceedings of the Third Conference of the European Chapter of the Association for Computational linguistics, Copenhagen, Denmark, April 1st-3rd 1987: 173-178.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Bresnan</author>
</authors>
<title>The Mental Representation of Grammatical Relations.</title>
<date>1982</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="7093" citStr="Bresnan, 1982" startWordPosition="1106" endWordPosition="1107">on-determinism inherent in the top-down approach, Wedekind stipulates that a daughter of a rule must be &apos;connected&apos; (i.e. that its semantics must be instantiated) before it can be generated from. Less restrictively, van Noord stipulates similar constraints on rules, i.e. that if the semantics of the mother node is known, then the semantics of the head daughter is instantiated, and additionally that if the syntax of the semantic head is known, then the semantics of each daughter is known. These restrictions limit the class of possible analyses, excluding accounts appropriate to LFG (Kaplan and Bresnan, 1982), HPSG (Pollard &amp; Sag, 1987) and UCG (Zeevat et al., 1987). The disparate state of progress in parsing and generation raises important issues concerning the adequacy of grammatical descriptions and the computational tools that interpret them. A situation exists in which a grammar may be &apos;correct&apos; for analysis, but &apos;incorrect&apos; for generation. Significantly, this may be the case even when the restrictions and annotations mentioned above are taken into account. Grammatical analyses developed in a purely parsing environment cannot always be transferred straightforwardly into a format suitable for </context>
</contexts>
<marker>Bresnan, 1982</marker>
<rawString>Bresnan, J. (ed.) (1982) The Mental Representation of Grammatical Relations. Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Busemann</author>
</authors>
<title>Generierung nut GPSG&amp;quot;.</title>
<date>1987</date>
<tech>KIT-Report 49,</tech>
<institution>Technische Univenitlit Berlin.</institution>
<contexts>
<context position="5338" citStr="Busemann, 1987" startWordPosition="828" endWordPosition="829">plus a generation and translation component. of this class of generation algorithms on the basis of two case studies. 2. Generating with Unification Grammars The goal of employing a single, minimally augmented, grammar for both parsing and generation has become more accessible with the introduction of declarative grammar formalisms (cf. Kay, 1985). In the context of machine translation, for which the ELU system has been developed, the use of the same grammar for both tasks is highly desirable; indeed much of the work on bidirectional grammars has been carried out in centres working on MT (cf. Busemann, 1987; van Noord, to appear; Dyrnetmann &amp; Isabelle, 1988; and Wedekind-. 1988). Regardless of the application, however, the ability to generate with a grammar is extremely useful as a method of checking its adequacy. Despite the objective of reversibility, all of the systems mentioned here impose generation-specific restrictions on their grammars, either by limiting the form of possible rules or by augmenting them with annotations. Dymetmann &amp; Isabelle (1988) require the grammar writer to specify for each rule the order in which daughters should be generated; however, an order that might be correct</context>
</contexts>
<marker>Busemann, 1987</marker>
<rawString>Busemann, S. (1987) &amp;quot;Generierung nut GPSG&amp;quot;. KIT-Report 49, Technische Univenitlit Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dymetman</author>
<author>P Isabelle</author>
</authors>
<title>Reversible Logic Grammars for Machine Translation&amp;quot;.</title>
<date>1988</date>
<booktitle>Proceedings of the 2nd International Coherence on Theoretical and Methodological Issues in Machine Translation of Natural Languages,</booktitle>
<institution>Carnegie-Mellon University,</institution>
<location>Pittsburgh, USA.</location>
<marker>Dymetman, Isabelle, 1988</marker>
<rawString>Dymetman, M. &amp; P. Isabelle (1988) &amp;quot;Reversible Logic Grammars for Machine Translation&amp;quot;. Proceedings of the 2nd International Coherence on Theoretical and Methodological Issues in Machine Translation of Natural Languages, Carnegie-Mellon University, Pittsburgh, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Salim Estival</author>
<author>G Russell</author>
<author>S Warwick</author>
</authors>
<title>A Syntax and Semantics for FeatureStructure Transfer&amp;quot;.</title>
<date>1989</date>
<tech>MS, 1SSCO.</tech>
<contexts>
<context position="4643" citStr="Estival et al. (1989)" startWordPosition="713" endWordPosition="716">t to the ELU2 environment; the algorithm is a variant of that proposed in Shieber et al. (1989). We first consider general aspects of adapting unification grammars initially developed for parsing to their use in generation. A brief description of the generator in FLU highlights the differences and improvements we have adopted. We then demonstrate shoncornings 2 &amp;quot;Environnement Linguinique d &apos;Unification&amp;quot;. Cf. Johnson &amp; Rosner (1989) for a description of UD (Unification Device) which includes the parser and facilities such as procedural abstractions and extended data types (lists and trees) and Estival et al. (1989) for a description of the extended ELU system which incorporates the original UD plus a generation and translation component. of this class of generation algorithms on the basis of two case studies. 2. Generating with Unification Grammars The goal of employing a single, minimally augmented, grammar for both parsing and generation has become more accessible with the introduction of declarative grammar formalisms (cf. Kay, 1985). In the context of machine translation, for which the ELU system has been developed, the use of the same grammar for both tasks is highly desirable; indeed much of the w</context>
</contexts>
<marker>Estival, Russell, Warwick, 1989</marker>
<rawString>Estival, II, A. Salim, G. Russell, and S. Warwick (1989) &amp;quot;A Syntax and Semantics for FeatureStructure Transfer&amp;quot;. MS, 1SSCO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Grimshaw</author>
</authors>
<title>On the Lexical Representation of Romance Reflexive Clitics&amp;quot;,</title>
<date>1982</date>
<volume>87</volume>
<pages>148</pages>
<editor>in Bits= (ed.):</editor>
<contexts>
<context position="19894" citStr="Grimshaw (1982)" startWordPosition="3218" endWordPosition="3219">generation. For example, if `vpIus&apos; appears as sister to another complement phrase, and the same procedure of unifying the latter with an item on the list takes place, then because the generator has suspended expansion of non-deterministic abstractions, the subcategorization list itself will be uninstantiated, and therefore no information regarding the semantics of the complement phrase will be available to restrict top-down generation. 8 This is something of an oversimplification, as not only complement phrases, but also adverbials and parts of complement phrases are realized as clitics. See Grimshaw (1982) for a partial LFG account of these phenomena. We also ignore the issue of negation, which considerably complicates the clitic-aux-verb structure. 9 The categorial treatment proposed in Baschung et al. (1987) not only makes use of order of arguments, but also codes each ethic for all possible combinations. 208 Modifications to the syntactic constituency assumed here do not affect the principle; as long as the instantiation of so central an element of the grammar as the subcategorization list is delayed, the problem will remain. An alternative type of analysis would remove the non-detemiinism f</context>
</contexts>
<marker>Grimshaw, 1982</marker>
<rawString>Grimshaw, J. (1982) &amp;quot;On the Lexical Representation of Romance Reflexive Clitics&amp;quot;, in Bits= (ed.): 87— 148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Haider</author>
</authors>
<title>V-Second in Getman&amp;quot;,</title>
<date>1985</date>
<booktitle>Verb Second Phenomena in Germanic Languages: 49 — 75.</booktitle>
<editor>in H. Haider and M. Prinz.hom (eds.)</editor>
<location>Dordrecht: Foris.</location>
<contexts>
<context position="21886" citStr="Haider (1985)" startWordPosition="3544" endWordPosition="3545"> is to control the distribution of verbs with grammar rules specific to clause-type; this solution gives rise to what might be felt to be an unacceptable degree of duplication in the grammar. A more elegant approach, successful for parsing, exploits the possibility of associating a word or phrase appearing in one position within a sentence with a &apos;gap&apos; elsewhere. The latter analysis will be recognized as a variant of a standard Government-Binding treatment, in which a tensed verb in a main clause is &apos;raised&apos; from an &apos;underlying&apos; sentence-final position to a &apos;surface&apos; second position (see e.g. Haider (1985), Platzack (1985) for discussion of this class of analyses). The dependency may be implemented by the use of a feature, say `v2&apos;, whose value in a verb-second construction is a feature structure representing the verb to be raised, and in other constructions an atomic constant such as &apos;none&apos;, which serves to block the dependency. At the extraction site, any value of `v2&apos; other than &apos;none&apos; may be cashed out as an empty production. Information regarding the various syntactic properties of the raised verb is passed in the normal fashion between the verb&apos;s true position and the extraction site, whe</context>
</contexts>
<marker>Haider, 1985</marker>
<rawString>Haider, H. (1985) &amp;quot;V-Second in Getman&amp;quot;, in H. Haider and M. Prinz.hom (eds.) Verb Second Phenomena in Germanic Languages: 49 — 75. Dordrecht: Foris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Johnson</author>
<author>M Rosner</author>
</authors>
<title>A Rich Environment for Experimentation with Unification Grammars&amp;quot;.</title>
<date>1989</date>
<booktitle>Proceedings of the Fourth Coherence of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>182--189</pages>
<location>Manchester, UK,</location>
<contexts>
<context position="4457" citStr="Johnson &amp; Rosner (1989)" startWordPosition="684" endWordPosition="687">veral plausible grammatical analyses handled by the parser are beyond the capacity of even this approach. This paper reports on experience arising from the addition of a generator component to the ELU2 environment; the algorithm is a variant of that proposed in Shieber et al. (1989). We first consider general aspects of adapting unification grammars initially developed for parsing to their use in generation. A brief description of the generator in FLU highlights the differences and improvements we have adopted. We then demonstrate shoncornings 2 &amp;quot;Environnement Linguinique d &apos;Unification&amp;quot;. Cf. Johnson &amp; Rosner (1989) for a description of UD (Unification Device) which includes the parser and facilities such as procedural abstractions and extended data types (lists and trees) and Estival et al. (1989) for a description of the extended ELU system which incorporates the original UD plus a generation and translation component. of this class of generation algorithms on the basis of two case studies. 2. Generating with Unification Grammars The goal of employing a single, minimally augmented, grammar for both parsing and generation has become more accessible with the introduction of declarative grammar formalisms</context>
<context position="17802" citStr="Johnson &amp; Rosner (1989)" startWordPosition="2871" endWordPosition="2874">&apos;found&apos; all necessary phrases, a grammar may require that the list be empty, or perhaps that any remaining item is in some way specified as optional. See e.g. Shieber (1986) and Pollard and Sag (1987) for applications of this method. A complete grammar of French must account for the position and ordering of ethic pronouns. These precede the verb, while other complement phrases follow. Moreover, they appear in a fixed order, as shown in (1): (1) me le lui y en te 1 a leur se les nous vous Up to three ethics may occur, but for the sake of this discussion, we consider only the simpler case 7 Cf. Johnson &amp; Rosner (1989) for a fuller description of relational abstractions. of two clitics as complement phrases to the verb.8 There are of course many ways of accounting for their distributioe the subcategorizarion list device seems a natural solution, since any complement phrase may be realized as a elide. The grammar rule in (2) introduces up to two elides before the verb, their relative order determined by a relational abstraction which is defined by a number of clauses, each clause licensing one of the possible clitic sequences. (2) vplus -&gt; C11 C12 HV Ihecede(C11,02) List = r.HV subcar&gt; C11 r-vplus subcat&gt; = </context>
</contexts>
<marker>Johnson, Rosner, 1989</marker>
<rawString>Johnson, R. and M. Rosner (1989) &amp;quot;A Rich Environment for Experimentation with Unification Grammars&amp;quot;. Proceedings of the Fourth Coherence of the European Chapter of the Association for Computational Linguistics, Manchester, UK, April Ifith-12th 1989: 182-189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Kaplan</author>
<author>J Bresnan</author>
</authors>
<title>LexicalFunctional Grammar A Formal System for Grammatical Representation&amp;quot;,</title>
<date>1982</date>
<pages>173--281</pages>
<editor>in Bresnan (ed.):</editor>
<contexts>
<context position="7093" citStr="Kaplan and Bresnan, 1982" startWordPosition="1104" endWordPosition="1107">degree of non-determinism inherent in the top-down approach, Wedekind stipulates that a daughter of a rule must be &apos;connected&apos; (i.e. that its semantics must be instantiated) before it can be generated from. Less restrictively, van Noord stipulates similar constraints on rules, i.e. that if the semantics of the mother node is known, then the semantics of the head daughter is instantiated, and additionally that if the syntax of the semantic head is known, then the semantics of each daughter is known. These restrictions limit the class of possible analyses, excluding accounts appropriate to LFG (Kaplan and Bresnan, 1982), HPSG (Pollard &amp; Sag, 1987) and UCG (Zeevat et al., 1987). The disparate state of progress in parsing and generation raises important issues concerning the adequacy of grammatical descriptions and the computational tools that interpret them. A situation exists in which a grammar may be &apos;correct&apos; for analysis, but &apos;incorrect&apos; for generation. Significantly, this may be the case even when the restrictions and annotations mentioned above are taken into account. Grammatical analyses developed in a purely parsing environment cannot always be transferred straightforwardly into a format suitable for </context>
</contexts>
<marker>Kaplan, Bresnan, 1982</marker>
<rawString>Kaplan, R.M. and J. Bresnan (1982) &amp;quot;LexicalFunctional Grammar A Formal System for Grammatical Representation&amp;quot;, in Bresnan (ed.): 173-281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
</authors>
<title>Parsing in Functional Unification Grammar&amp;quot;,</title>
<date>1985</date>
<pages>251--278</pages>
<editor>in D. Dowty, L. Kamunen, and A. Zwicky (eds.)</editor>
<publisher>Cambridge University Press:</publisher>
<contexts>
<context position="5073" citStr="Kay, 1985" startWordPosition="782" endWordPosition="783"> description of UD (Unification Device) which includes the parser and facilities such as procedural abstractions and extended data types (lists and trees) and Estival et al. (1989) for a description of the extended ELU system which incorporates the original UD plus a generation and translation component. of this class of generation algorithms on the basis of two case studies. 2. Generating with Unification Grammars The goal of employing a single, minimally augmented, grammar for both parsing and generation has become more accessible with the introduction of declarative grammar formalisms (cf. Kay, 1985). In the context of machine translation, for which the ELU system has been developed, the use of the same grammar for both tasks is highly desirable; indeed much of the work on bidirectional grammars has been carried out in centres working on MT (cf. Busemann, 1987; van Noord, to appear; Dyrnetmann &amp; Isabelle, 1988; and Wedekind-. 1988). Regardless of the application, however, the ability to generate with a grammar is extremely useful as a method of checking its adequacy. Despite the objective of reversibility, all of the systems mentioned here impose generation-specific restrictions on their </context>
</contexts>
<marker>Kay, 1985</marker>
<rawString>Kay, M. (1985) &amp;quot;Parsing in Functional Unification Grammar&amp;quot;, in D. Dowty, L. Kamunen, and A. Zwicky (eds.) Natural Language Parsing. Cambridge: Cambridge University Press: 251-278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nerbonne</author>
</authors>
<title>Phantoms&apos; and German Fronting: Poltergeist Constituents?&amp;quot;,</title>
<date>1986</date>
<journal>Linguistics</journal>
<volume>24</volume>
<pages>857--870</pages>
<contexts>
<context position="26151" citStr="Nerbonne, 1986" startWordPosition="4288" endWordPosition="4290">cal component then generates one empty siring and one full word according to the position of the verb (i.e. in a main or subordinate clause). This mechanism is not available in &amp;U. The second solution adds an additional &apos;connect&apos; clause in the Prolog program, specific to gaps, in order to assure that the gap is first instantiated before further processing; this solution raises the issue of tuning programs to treat specific problems as they are encountered. There are other constructions which raise the same kind of problem; the fronting of apparently non-constituent verbal sequences in German (Nerbonne, 1986) introduces more complex dependencies, while in English the phenomena of Gapping and Verb-Phrase Ellipsis both manifest themselves syntactically in the absence from a sentence of a verb and possibly other material. Here, the difficulty is, if anything, greater, as the dependencies in question are anaphoric in nature, rather than syntactic. 5. Conclusion We have seen, in the preceding section, how in order to write grammars suitable for use with the generator, one must either modify the technical aspects of the grammar or dispense with certain classes of grammatical analysis (losing the benefit</context>
</contexts>
<marker>Nerbonne, 1986</marker>
<rawString>Nerbonne, J. (1986) &amp;quot;&apos;Phantoms&apos; and German Fronting: Poltergeist Constituents?&amp;quot;, Linguistics 24-5, 857-870.</rawString>
</citation>
<citation valid="false">
<authors>
<author>G van Noord</author>
</authors>
<title>(to appear) &amp;quot;Bottom Up Generation in Unification-based Formalisms&amp;quot;,</title>
<booktitle>Proceedings of the Second European Workshop on Natural Language Generation.</booktitle>
<editor>in C. Mellish, R. Dale, and M. Zock (eds.)</editor>
<marker>van Noord, </marker>
<rawString>van Noord, G. (to appear) &amp;quot;Bottom Up Generation in Unification-based Formalisms&amp;quot;, in C. Mellish, R. Dale, and M. Zock (eds.) Proceedings of the Second European Workshop on Natural Language Generation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Platza ck</author>
</authors>
<title>A Survey of Generative Analyses of the Verb Second Phenomenon in Germanic&amp;quot;.</title>
<date>1985</date>
<journal>Nordic Journal of linguistics</journal>
<volume>8</volume>
<pages>49--73</pages>
<contexts>
<context position="21903" citStr="ck (1985)" startWordPosition="3546" endWordPosition="3547">stribution of verbs with grammar rules specific to clause-type; this solution gives rise to what might be felt to be an unacceptable degree of duplication in the grammar. A more elegant approach, successful for parsing, exploits the possibility of associating a word or phrase appearing in one position within a sentence with a &apos;gap&apos; elsewhere. The latter analysis will be recognized as a variant of a standard Government-Binding treatment, in which a tensed verb in a main clause is &apos;raised&apos; from an &apos;underlying&apos; sentence-final position to a &apos;surface&apos; second position (see e.g. Haider (1985), Platzack (1985) for discussion of this class of analyses). The dependency may be implemented by the use of a feature, say `v2&apos;, whose value in a verb-second construction is a feature structure representing the verb to be raised, and in other constructions an atomic constant such as &apos;none&apos;, which serves to block the dependency. At the extraction site, any value of `v2&apos; other than &apos;none&apos; may be cashed out as an empty production. Information regarding the various syntactic properties of the raised verb is passed in the normal fashion between the verb&apos;s true position and the extraction site, where it is able to </context>
</contexts>
<marker>ck, 1985</marker>
<rawString>Platza.ck, C. (1985) &amp;quot;A Survey of Generative Analyses of the Verb Second Phenomenon in Germanic&amp;quot;. Nordic Journal of linguistics 8: 49-73.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sag</author>
</authors>
<date>1987</date>
<booktitle>Information-Based Syntax and Semantics, Volume 1: Fundamentals. CSLI Lecture Notes no. 13</booktitle>
<contexts>
<context position="7121" citStr="Sag, 1987" startWordPosition="1111" endWordPosition="1112">op-down approach, Wedekind stipulates that a daughter of a rule must be &apos;connected&apos; (i.e. that its semantics must be instantiated) before it can be generated from. Less restrictively, van Noord stipulates similar constraints on rules, i.e. that if the semantics of the mother node is known, then the semantics of the head daughter is instantiated, and additionally that if the syntax of the semantic head is known, then the semantics of each daughter is known. These restrictions limit the class of possible analyses, excluding accounts appropriate to LFG (Kaplan and Bresnan, 1982), HPSG (Pollard &amp; Sag, 1987) and UCG (Zeevat et al., 1987). The disparate state of progress in parsing and generation raises important issues concerning the adequacy of grammatical descriptions and the computational tools that interpret them. A situation exists in which a grammar may be &apos;correct&apos; for analysis, but &apos;incorrect&apos; for generation. Significantly, this may be the case even when the restrictions and annotations mentioned above are taken into account. Grammatical analyses developed in a purely parsing environment cannot always be transferred straightforwardly into a format suitable for generation. Two types of con</context>
<context position="17379" citStr="Sag (1987)" startWordPosition="2794" endWordPosition="2795">grammars, and one which reflects and extends the traditional notion of &apos;valency&apos;, is to encode information about the various phrases with which a verb combines in items on a subcategorization list. The grammar then enforces a match between a member of the list and a phrase which is to combine with some projection of the verb and removes the item from the list. When a sentence is complete, i.e. the verb has &apos;found&apos; all necessary phrases, a grammar may require that the list be empty, or perhaps that any remaining item is in some way specified as optional. See e.g. Shieber (1986) and Pollard and Sag (1987) for applications of this method. A complete grammar of French must account for the position and ordering of ethic pronouns. These precede the verb, while other complement phrases follow. Moreover, they appear in a fixed order, as shown in (1): (1) me le lui y en te 1 a leur se les nous vous Up to three ethics may occur, but for the sake of this discussion, we consider only the simpler case 7 Cf. Johnson &amp; Rosner (1989) for a fuller description of relational abstractions. of two clitics as complement phrases to the verb.8 There are of course many ways of accounting for their distributioe the s</context>
</contexts>
<marker>Sag, 1987</marker>
<rawString>Pollard, C. and IA. Sag (1987) Information-Based Syntax and Semantics, Volume 1: Fundamentals. CSLI Lecture Notes no. 13</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Saint-Diner</author>
</authors>
<title>A Generation Method Based on Principles of Government-Binding Theory&amp;quot;. Paper presented at the Second Europea.n Natural Language Generation Workshop,</title>
<date>1989</date>
<location>Edinburgh,</location>
<marker>Saint-Diner, 1989</marker>
<rawString>Saint-Diner, P. (1989) &amp;quot;A Generation Method Based on Principles of Government-Binding Theory&amp;quot;. Paper presented at the Second Europea.n Natural Language Generation Workshop, Edinburgh, April 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>Using ReSiliCti011 to Extend Parsing Algorithms for Complex-Feature-Based Formalisms&amp;quot;.</title>
<date>1985</date>
<booktitle>Proceedings of the 23rd Annual Meeting of the Association for Computational Linguistics:</booktitle>
<pages>145--152</pages>
<contexts>
<context position="10332" citStr="Shieber (1985)" startWordPosition="1634" endWordPosition="1635">trictor set characterizes a pivot. A restrictor set is also computed for each lexical stem, in order to retrieve words efficiently during generation. The generation algorithm uses the distinction between chaining and non-chaining rules as well as 3 Our discussion will therefore assume familiarity with this paper. 4 Restrictors are attributes selected by the writer of a grammar as being maximally distinctive; when two FSs are to be unified, their respective restrictor values are first checked for compatibility, so as to eliminate the cost of an attempted unification which is bound to fail. See Shieber (1985). 206 that between head and non-head daughters, the rea.drability table for chaining rules, the semantic portion of the FS to be generated from5, and the restrictors for lexicon stems. The algorithm is: 1. Take all grammar rules declared as &apos;initial&apos; (or all rules in the grammar if no such declaration has been made); for each of these rules whose mother unifies with the input FS, apply the rule top-down, building FSs for each of the daughters, and, starting with the head daughter, execute step 2 for each one. If generation from the daughters is successful, compute all possible word-forms (as c</context>
</contexts>
<marker>Shieber, 1985</marker>
<rawString>Shieber, S.M. (1985) &amp;quot;Using ReSiliCti011 to Extend Parsing Algorithms for Complex-Feature-Based Formalisms&amp;quot;. Proceedings of the 23rd Annual Meeting of the Association for Computational Linguistics: 145-152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>An Introduction to Unification-Based Approaches to Grammar.</title>
<date>1986</date>
<journal>CSLI Lecture Notes</journal>
<volume>4</volume>
<contexts>
<context position="17352" citStr="Shieber (1986)" startWordPosition="2789" endWordPosition="2790">ue in modem lexically-oriented grammars, and one which reflects and extends the traditional notion of &apos;valency&apos;, is to encode information about the various phrases with which a verb combines in items on a subcategorization list. The grammar then enforces a match between a member of the list and a phrase which is to combine with some projection of the verb and removes the item from the list. When a sentence is complete, i.e. the verb has &apos;found&apos; all necessary phrases, a grammar may require that the list be empty, or perhaps that any remaining item is in some way specified as optional. See e.g. Shieber (1986) and Pollard and Sag (1987) for applications of this method. A complete grammar of French must account for the position and ordering of ethic pronouns. These precede the verb, while other complement phrases follow. Moreover, they appear in a fixed order, as shown in (1): (1) me le lui y en te 1 a leur se les nous vous Up to three ethics may occur, but for the sake of this discussion, we consider only the simpler case 7 Cf. Johnson &amp; Rosner (1989) for a fuller description of relational abstractions. of two clitics as complement phrases to the verb.8 There are of course many ways of accounting f</context>
</contexts>
<marker>Shieber, 1986</marker>
<rawString>Shieber, S.M.. (1986) An Introduction to Unification-Based Approaches to Grammar. CSLI Lecture Notes no. 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>A Uniform Architecture for Parsing and Generation&amp;quot;.</title>
<date>1988</date>
<booktitle>Proceedings of the 12th International Conference on Computational Linguistics,</booktitle>
<pages>614--619</pages>
<location>Budapest, Hungary:</location>
<contexts>
<context position="2343" citStr="Shieber (1988)" startWordPosition="353" endWordPosition="354">mar rules is information associated with words in the lexicon. In the case of generation, there is in general no guarantee that the constituents of an input representation correspond to words; a portion of the input may be related directly to a given word, or it may be the result of combining representations associated to some sequence of rules, portions of which are ultimately related to lexical items. For example, if the sentence John kicked the bucket receives the semantic representation die(John), it is Parsing and generation need not employ different algorithms or control strategies; see Shieber (1988) for discussion. However, a truly reversible program would be an entirely different undertaking fi.ren what is described here. One such project is currently under way at New Mexico State University (Yorick Wilks, p.c.). 205 relatively easy to see how during parsing the recognition of kicked and the bucket will provide the necessary information (from the lexical entry for kick) to build that representation. The representation and the lexical items are in general related not directly, but rather via intermediate syntactic rules, any of which is able to manipulate the representation in arbitrary </context>
<context position="3559" citStr="Shieber (1988)" startWordPosition="548" endWordPosition="549">ys; in generation, it is not possible to identify the correct lexical item without considering the syntactic rules which may intervene. The generation problem, then, consists in bow to build a syntactic structure from an initial representation, taking it as the root, and extending the Monte &apos;downward&apos; to the lexicon by selecting rules from the grammar and attaching them at the appropriate points. Though unification based systems have been in use for parsing for a number of years, generation has until recently not attracted comparable attention, Wedekind (1988), Dymetmano &amp; Isabelle (1988) and Shieber (1988) describe three systems of note. Not surprisingly, given the relative infancy of these explorations, none of these systems is without problems. The most permissive of the current proposals appears to be Shieber et al.&apos;s (1989) revision of the Shieber (1988) algorithm, yet several plausible grammatical analyses handled by the parser are beyond the capacity of even this approach. This paper reports on experience arising from the addition of a generator component to the ELU2 environment; the algorithm is a variant of that proposed in Shieber et al. (1989). We first consider general aspects of ada</context>
</contexts>
<marker>Shieber, 1988</marker>
<rawString>Shieber, S.M. (1988) &amp;quot;A Uniform Architecture for Parsing and Generation&amp;quot;. Proceedings of the 12th International Conference on Computational Linguistics, Budapest, Hungary: 614-619.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
<author>G van Noord</author>
<author>R C Moore</author>
<author>F C N Pereira</author>
</authors>
<title>A Semantic-HeadDriven Algorithm for Unification-Based Formalisms&amp;quot;.</title>
<date>1989</date>
<booktitle>Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics</booktitle>
<pages>7--17</pages>
<marker>Shieber, van Noord, Moore, Pereira, 1989</marker>
<rawString>Shieber, S.M., van Noord, G., R.C. Moore, and F.C.N. Pereira (1989) &amp;quot;A Semantic-HeadDriven Algorithm for Unification-Based Formalisms&amp;quot;. Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics :7-17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Wedekind</author>
</authors>
<title>Generation as StructureDriven Derivation&amp;quot;.</title>
<date>1988</date>
<booktitle>Proceedings of the 12th International Conference on Computational Linguistics,</booktitle>
<pages>732--737</pages>
<location>Budapest, Hungary:</location>
<contexts>
<context position="3511" citStr="Wedekind (1988)" startWordPosition="541" endWordPosition="542"> to manipulate the representation in arbitrary ways; in generation, it is not possible to identify the correct lexical item without considering the syntactic rules which may intervene. The generation problem, then, consists in bow to build a syntactic structure from an initial representation, taking it as the root, and extending the Monte &apos;downward&apos; to the lexicon by selecting rules from the grammar and attaching them at the appropriate points. Though unification based systems have been in use for parsing for a number of years, generation has until recently not attracted comparable attention, Wedekind (1988), Dymetmano &amp; Isabelle (1988) and Shieber (1988) describe three systems of note. Not surprisingly, given the relative infancy of these explorations, none of these systems is without problems. The most permissive of the current proposals appears to be Shieber et al.&apos;s (1989) revision of the Shieber (1988) algorithm, yet several plausible grammatical analyses handled by the parser are beyond the capacity of even this approach. This paper reports on experience arising from the addition of a generator component to the ELU2 environment; the algorithm is a variant of that proposed in Shieber et al. </context>
<context position="6358" citStr="Wedekind (1988)" startWordPosition="990" endWordPosition="991">ng them with annotations. Dymetmann &amp; Isabelle (1988) require the grammar writer to specify for each rule the order in which daughters should be generated; however, an order that might be correct when generating from one structure can lead to nonterminating search with another. Busemann (1987) and Saint-Dizier (1989) describe methods of generation which rely on the parsing of a control structure using a specialized grammar to build the syntax of a sentence; it is questionable to what extent the latter two systems can be considered to operate with bidirectional grammars. Constraints imposed by Wedekind (1988) and van Noord (to appear) exclude certain linguistic analyses from generation. In order to overcome the high degree of non-determinism inherent in the top-down approach, Wedekind stipulates that a daughter of a rule must be &apos;connected&apos; (i.e. that its semantics must be instantiated) before it can be generated from. Less restrictively, van Noord stipulates similar constraints on rules, i.e. that if the semantics of the mother node is known, then the semantics of the head daughter is instantiated, and additionally that if the syntax of the semantic head is known, then the semantics of each daugh</context>
</contexts>
<marker>Wedekind, 1988</marker>
<rawString>Wedekind, J. (1988) &amp;quot;Generation as StructureDriven Derivation&amp;quot;. Proceedings of the 12th International Conference on Computational Linguistics, Budapest, Hungary: 732-737.</rawString>
</citation>
<citation valid="true">
<authors>
<author>IL Zeevat</author>
<author>E Klein</author>
<author>J Calder</author>
</authors>
<title>Unification Caftgorial Grammar&amp;quot;. Categorial Grammar, Unification Grammar, and Parsing, Edinburgh Working Papers in Cognitive Science,</title>
<date>1987</date>
<volume>1</volume>
<pages>195--222</pages>
<institution>Centre for Cognitive Science, University of Edinburgh:</institution>
<contexts>
<context position="7151" citStr="Zeevat et al., 1987" startWordPosition="1115" endWordPosition="1118">dekind stipulates that a daughter of a rule must be &apos;connected&apos; (i.e. that its semantics must be instantiated) before it can be generated from. Less restrictively, van Noord stipulates similar constraints on rules, i.e. that if the semantics of the mother node is known, then the semantics of the head daughter is instantiated, and additionally that if the syntax of the semantic head is known, then the semantics of each daughter is known. These restrictions limit the class of possible analyses, excluding accounts appropriate to LFG (Kaplan and Bresnan, 1982), HPSG (Pollard &amp; Sag, 1987) and UCG (Zeevat et al., 1987). The disparate state of progress in parsing and generation raises important issues concerning the adequacy of grammatical descriptions and the computational tools that interpret them. A situation exists in which a grammar may be &apos;correct&apos; for analysis, but &apos;incorrect&apos; for generation. Significantly, this may be the case even when the restrictions and annotations mentioned above are taken into account. Grammatical analyses developed in a purely parsing environment cannot always be transferred straightforwardly into a format suitable for generation. Two types of conclusion may be drawn from this</context>
</contexts>
<marker>Zeevat, Klein, Calder, 1987</marker>
<rawString>Zeevat, IL, E. Klein, and J. Calder (1987) &amp;quot;Unification Caftgorial Grammar&amp;quot;. Categorial Grammar, Unification Grammar, and Parsing, Edinburgh Working Papers in Cognitive Science, Volume 1. Centre for Cognitive Science, University of Edinburgh: 195-222</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>