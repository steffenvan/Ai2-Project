<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.022216">
<title confidence="0.9997065">
A Word Segmentation System for Handling Space Omission Problem
in Urdu Script
</title>
<author confidence="0.990022">
Gurpreet Singh Lehal
</author>
<affiliation confidence="0.9697535">
Department of Computer Science
Punjabi University, Patiala
</affiliation>
<email confidence="0.996202">
gslehal@gmail.com
</email>
<sectionHeader confidence="0.999555" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999821538461539">
Word segmentation is the foremost obligatory
task in all NLP application, where the initial
phase requires tokenization of input into words.
For languages like English, French and Spanish
etc. tokenization is considered trivial because the
white space or punctuation marks between
words is a good approximation of where a word
boundary is. Whilst in various Asian languages
such as Chinese, Thai and Myanmar, white
spaces is rarely or never used to determine the
word boundaries, so one must resort to higher
levels of information such as: information of
morphology, syntax and statistical analysis to
reconstruct the word boundary information
(Papageorgiou, 1994; Nie et al, 1995; Wang et
al, 2000; Xu et al, 2005).
Though the Urdu word segmentation problem is
not as severe as some of the other Asian
language, since space is used for word
delimitation, but the space is not consistently
used, which gives rise to both space omission
and space insertion errors in Urdu.
Durrani(2007) and Durrani and Hussain(2010)
have discussed in detail the various Urdu word
segmentation issues while Jawaid and
Ahmed(2009) and Abbas et al(2009) have
discussed the Hindi-Urdu transliteration issues.
A word segmentation system for handling space
insertion problem in Urdu script has been
presented by Lehal(2009).
Hindi and Urdu are variants of the same
language characterized by extreme digraphia:
Hindi is written in the Devanagari script from
left to right, Urdu in a script derived from a
Persian modification of Arabic script written
from right to left. Hindi and Urdu share
grammar, morphology, vocabulary, history,
classical literature etc. Because of their identical
grammar and nearly identical core vocabularies,
</bodyText>
<sectionHeader confidence="0.645509" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.999530378378379">
Word Segmentation is the foremost
obligatory task in almost all the NLP
applications, where the initial phase requires
tokenization of input into words. Like other
Asian languages such as Chinese, Thai and
Myanmar, Urdu also faces word
segmentation challenges. Though the Urdu
word segmentation problem is not as severe
as the other Asian language, since space is
used for word delimitation, but the space is
not consistently used, which gives rise to
both space omission and space insertion
errors in Urdu. In this paper we present a
word segmentation system for handling
space omission problem in Urdu script with
application to Urdu-Devnagri Transliteration
system. Instead of using manually
segmented monolingual corpora to train
segmenters, we make use of bilingual
corpora and statistical word disambiguation
techniques. Though our approach is adapted
for the specific transliteration task at hand by
taking the corresponding target (Hindi)
language into account, the techniques
suggested can be adapted to independently
solve the space omission Urdu word
segmentation problems. The two major
components of our system are :
identification of merged words for
segmentation and proper segmentation of the
merged words. The system was tested on
1.61 million word Urdu test data. The recall
and precision for the merged word
recognition component were found to be
99.29% and 99.38% respectively. The
words are correctly segmented with 99.15%
accuracy.
</bodyText>
<page confidence="0.996338">
43
</page>
<bodyText confidence="0.8174725">
Proceedings of the 1st Workshop on South and Southeast Asian Natural Language Processing (WSSANLP), pages 43–50,
the 23rd International Conference on Computational Linguistics (COLING), Beijing, August 2010
</bodyText>
<equation confidence="0.97781">
ڑ ر
ذ ڈ د اآ
</equation>
<bodyText confidence="0.996745510638298">
most linguists do not distinguish between Urdu
and Hindi as separate languages. The difference
in the two scripts has created a script wedge as
majority of Urdu speaking people in Pakistan
cannot read Devnagri, and similarly the majority
of Hindi speaking people in India cannot
comprehend Urdu script. To break this script
barrier an Urdu-Devnagri transliteration system
has been developed. The transliteration system
faced many problems related to word
segmentation of Urdu script as discussed above.
In this paper we present a word segmentation
system for handling space omission problem in
Urdu script with application to Urdu-Devnagri
Transliteration system. Instead of using
manually segmented monolingual corpora to
train segmenters, we make use of bilingual
corpora and statistical word disambiguation
techniques. Though our approach is adapted for
the specific transliteration task at hand by taking
the corresponding target (Hindi) language into
account, the techniques suggested can be
adapted to independently solve the space
omission Urdu word segmentation problems.
2 Urdu script: a brief overview
Urdu is a Central Indo-Aryan language of the
Indo-Iranian branch, belonging to the Indo-
European family of languages. It is the national
language of Pakistan. It is also one of the 22
scheduled languages of India and is an official
language of five Indian states.
Urdu script has 35 simple consonants, 15
aspirated consonants, one character for nasal
sound and 15 diacritical marks. Urdu characters
change their shapes depending upon neighboring
context. But generally they acquire one of these
four shapes, namely isolated, initial, medial and
final. Urdu characters can be divided into two
groups, non-joiners and joiners. The non-joiners
can acquire only isolated and final shape and do
not join with the next character. On contrary
joiners can acquire all the four shapes and get
merged with the following character. A group of
joiners and/or non-joiner joined together form a
ligature. A word in Urdu is a collection of one or
more ligatures. The isolated form of joiners and
non-joiners is shown in figures 1-2.
</bodyText>
<equation confidence="0.88459">
ے و ژ ز
</equation>
<figureCaption confidence="0.990201">
Figure 1. Non-Joiners in Urdu
</figureCaption>
<bodyText confidence="0.999962954545454">
The space character is used in Urdu both to
generate correct shaping and also to separate
words. Though for words ending with non-
joiners correct shaping is generated even when
space is not typed and thus, many times a user
omits the space. The sequence of Urdu words
written together without space is still readable
because of the character joining property in
Urdu. As for example, consider the word cluster
ےہايدرکراکنا , which is composed of four words
راکنا, رک , ايد and ےہ. The Urdu readers can very
easily segment and read the four words
separately, but the computer will read them as a
single word since there is no space in between.
Similarly, the word cluster ےہايگايدروزرپ is
composed of five words(رپ, روز, ايد, ايگ and ےہ ),
which can be easily read as five separate words
by Urdu readers but will be considered as a
single word by the computer.
Another unique feature of Urdu is that the
Urdu words are usually written without short
vowels or diacritic symbols. Any machine
transliteration or text to speech synthesis system
has to automatically guess and insert these
missing symbols. This is a non-trivial problem
and requires an in-depth statistical analysis.
An Urdu word is a combination of ligatures
(characters which join together) and isolated
characters. For example راکنا is composed of
isolated characters ا and ر and ligature اکن . A
ligature or isolated character will be called as
Urdu character cluster (UCC) in this paper. A
Urdu word is thus a combination of UCCs . As
for example, the word راکنا is composed of three
UCCs ا , اکن and ر . We borrow the term,
Orthographic Word used by Durrani and
Hussain(2010) to define our segmentation
process. An Orthographic Word (OW) is a
combination of UCCs separated by spaces or
punctuation marks. An OW may contain single
or multiple Urdu words. Our task is to identify if
an OW contains multiple words and in that case
properly segment the words.
As for example, consider the sentence:
</bodyText>
<equation confidence="0.992517333333333">
ايکادارادرکاکوريہ ےن شيرن مار ےس بناج یک ميٹ نابزيم
ض ص ش س خ ح چ ج
ه ی ه ن م ل گ
</equation>
<figureCaption confidence="0.877062">
Figure 2. Joiners in Urdu
</figureCaption>
<equation confidence="0.771497714285714">
ظ ط
ک ق
ف غ ع
ب
ٹ ت
ث
پ
</equation>
<page confidence="0.969186">
44
</page>
<bodyText confidence="0.93327">
It contains nine OWs
</bodyText>
<listItem confidence="0.998325888888889">
1. نابزيم
2. ميٹ
3. یک
4. بناج
5. ےس
6. مار
7. شيرن
8. ےن
9. ايکادارادرکاکوريہ
</listItem>
<bodyText confidence="0.999332333333333">
The first eight OWs contain single Urdu
words, while the last OW contains 5 Urdu
words(وريہ, اک, رادرک, ادا and ايک)
</bodyText>
<sectionHeader confidence="0.991921" genericHeader="introduction">
3 Segmentation Model for Urdu
</sectionHeader>
<bodyText confidence="0.999973454545454">
There are three major issues in the automatic
Urdu word segmentation. The first problem is to
decide if the orthographic word represents a
single word or a multiple word cluster. The
second is the ambiguity issue. Since a word
cluster can be segmented into words in multiple
ways, the correct word boundary detection
becomes a challenge. As for example the OW
ےسانايگ can be segmented as نايگ + ےسا or ايگ + ان
+ ےس. The third problem is the segmentation of
unknown word. Unknown word refers to word
that does not exist in the dictionary or corpus.
Unknown words can be categorized into the
different types such as error words, abbreviation,
proper names, derived words, foreign words,
compounds etc. The unknown word causes
segmentation error since the word does not exist
in the dictionary, it could be incorrectly
segmented into shorter words. For example, the
word, یجولاٹيمر ڈ , which is a foreign word, gets
segmented into four words (رڈ , اٹيم , ول and یج )
after dictionary look-up as the word یجولاٹيمرڈ is
not present in the corpus.
The input is an Urdu Orthographic Word and
the system first makes the decision if the OW
contains single or multiple Urdu words. In case
the OW contains multiple words, the individual
Urdu words are extracted from the OW. These
different stages are discussed in detail in
following sections. As can be seen from the
figure, at each stage we make use of lexical
resources both from Urdu and Hindi languages.
The details of the resources used are in Table 1.
</bodyText>
<figureCaption confidence="0.992641">
Figure 3. System Architecture
</figureCaption>
<tableCaption confidence="0.876369">
Table 1. Lexical resources used in system
</tableCaption>
<table confidence="0.736563714285714">
Resource Count
Urdu Word Frequency 121,367 words
List
Hindi Word Frequency 159,426 words
List
Hindi Word Bigram List 2,382,511
bigrams
</table>
<sectionHeader confidence="0.9728" genericHeader="method">
4 Decision Stage
</sectionHeader>
<bodyText confidence="0.980628866666667">
In the decision stage, the system decides if the
OW contains single or multiple Urdu words. It
could so happen that the OW contains single
word only and we may break up into smaller
words. The decision is based on Urdu and Hindi,
word frequency lists analysis as well as
Urdu/English/Hindi Morphological rules. To
decide if the word cluster is containing multiple
words, we first search for OW in the Urdu word
list. If it is found then it means that the OW is a
valid Urdu word and does not need any further
segmentation and quit over there.
It could happen that the OW could be an
inflection, whose root form maybe present in the
The system architecture is shown in Fig. 3.
</bodyText>
<page confidence="0.997224">
45
</page>
<bodyText confidence="0.999697810344828">
Urdu word list. Even though the Urdu word list
contains inflected forms, but for many words all
the inflections may not be present. This problem
is more pronounced for English terms, which
have become part of Urdu language. For such
words, the inflections could follow both rules of
English and Urdu. For example plural of
یٹسروينوي
(university) could be both universitiyon
ینویٹѧسرویںو as well as universities زيٹسروينوي.
The first form follows the Urdu infection rules
while the second form follows the English
inflection rules. Similarly we found both the
Urdu and English inflections for the English
word secretary in Urdu text (ںويرٹرکيس and
زيرٹرکيس) . Thus if the OW is not found in the
Urdu word list, we use both Urdu and English
morphological rules to generate its root form and
search for the root form in the Urdu word list. If
the root form is found, we assume the word to be
a valid Urdu word and quit there.
It is widely reported in word segmentation
papers, that the greatest barrier to accurate word
Segmentation is in recognizing words that are
not in the lexicon of the segmenter. Thus if a
word or its root form is not present in the Urdu
word list it will be wrongly presumed to be a
multi word cluster. To alleviate this problem, the
Urdu corpus has been supplemented with Hindi
corpus, which has helped in increasing the word
segmentation as well as multi-word recognition
accuracy. It was found many times that the Urdu
word may be a proper noun, foreign word or
some valid out of vocabulary word, which is not
present in Urdu corpus but present in the Hindi
word list. Another advantage of checking in the
Hindi corpus is that many of the Hindi words,
which are written as single word are usually
written as two words in Urdu. For example,
اگےرک (करेगा), ےتليھک (खेलते), یرادناميا
(ईमानदारȣ), نيمريئچ (चेयरमैन) etc. These Urdu
words are many times written as a single word
and in that case if passed to Hindi word list
would still report as correct. For checking the
OW in Hindi word list, we first transliterate it to
Hindi and then search for it in the Hindi
wordlist. If the transliterated word is found, then
the OW is not considered for segmentation. Like
Urdu, it may also happen that the root word of
OW may be present in the Hindi word list. So
like Urdu, we use both Urdu and English
morphological rules to generate its root form and
search for the root form in the Hindi word list. If
the root form is found, we assume the word to be
a valid Urdu word and quit there. If the OW
passes all the above stages, then it is considered
a candidate for segmentation.
The steps in brief are :
</bodyText>
<listItem confidence="0.99049368">
• Search for OW in Urdu List. If OW is
present in the list then quit. example :
قباطم
• Determine the root form of OW using
Urdu Morphological rules and search for
the root form in Urdu List. If found then
quit. example : ںويرٹرکيس
• Determine the root form of OW using
English Morphological rules and search
for the root form in Urdu List. If found
then quit. example : سٹنمانروٹ
• Let HW = Transliteration of OW in
Hindi. Search for HW in the Hindi Word
List. If HW is present in the list then
quit. example : یرادناميا
• Determine the root form of HW using
Hindi Morphological rules and search
for the root form in the Hindi List. If
found then quit. example : ںونيمرئيچ
• Determine the root form of HW using
English Morphological rules and search
for the root form in the Hindi List. If
found then quit. example : زرڈلوہ
• Go to the segmentation stage. example :
سااھت
</listItem>
<sectionHeader confidence="0.935983" genericHeader="method">
5 Segmenting the Orthographic Word
</sectionHeader>
<bodyText confidence="0.996870857142857">
The Urdu orthographic word is next broken into
Urdu Character Combinations (UCC) using
Urdu orthographic rules. Unlike word
segmentation that is a difficult task, segmenting
a text into UCCs is easily achieved by applying
the set of rules. These adjacent UCCs are then
combined to form a sequence of Urdu words.
We need to list all possible segmentations and
design a strategy to select the most probable
correct segmentation from them.
As for example, consider the OW باوجوت: It is
segmented into four UCCs : وت, وج. ا and ب . The
adjacent clusters can be combined to form 6
word segmentations:
</bodyText>
<listItem confidence="0.9974175">
• وت + باوج
• وجوت + با
</listItem>
<page confidence="0.955012">
46
</page>
<listItem confidence="0.9998225">
• اوجوت + ب
• وت + وج + با
• وجوت + ا + ب
• وت + وج + ا + ب
</listItem>
<subsectionHeader confidence="0.997357">
5.1 Longest Matching
</subsectionHeader>
<bodyText confidence="0.9999507">
The method scans an input sentence from left to
right, and select the longest match with a
dictionary entry at each point. In case that the
selected match cannot lead the algorithm to find
the rest of the words in the sentence, the
algorithm will backtrack to find the next longest
one and continue finding the rest and so on. This
algorithm fails to find the correct segmentation
in many cases because of its greedy
characteristic.
</bodyText>
<subsectionHeader confidence="0.997566">
5.2 Maximum Matching
</subsectionHeader>
<bodyText confidence="0.999829264705882">
This method first generates all possible
segmentations for a sentence and then selects the
one that contain the fewest words, which can be
done efficiently by using dynamic programming
technique. When the alternatives have the same
number of words, the algorithm cannot
determine the best candidate and some other
heuristics have to be applied.
We tried both longest matching and maximum
matching and the smallest unit taken for
combining is UCC. But we found shortcomings
in both the matchings. For example the OW
ےہاہرارک gets segmented as رارک+ اہ+ےہ using
longest matching, while it should be ارک+اہر+ےہ .
Similarly the OW ندوکراوتازورب gets segmented
as زورب+راوتا+ندوک using maximum matching
while it should be زورب+راوتا+وک+ند.
Thus we see that both longest string match and
smallest words fail sometimes. If these
algorithms are supplemented by statistical
information such as frequency analysis and n-
grams then these failures can be avoided. So in
our present work, we apply maximal matching
algorithm along with these statistics. Initially we
used unigram frequency of occurrence for
deciding the best word combination. Each Urdu
word in the combination is formed by joining
adjacent UCCs. In each of the combination, we
first convert each of the Urdu word to Hindi.
The combination with highest combined product
of the unigram frequency of occurrences is
finally selected. Thus in the above example, the
OW باوجوت: will be segmented as وت + باوج, as
shown in Table 2.
</bodyText>
<tableCaption confidence="0.999063">
Table 2. Product of Frequency of Occurrence
</tableCaption>
<table confidence="0.99648">
Urdu Hindi Frequency
Combination Combination Product
(Frequency
of
occurrence)
وت तो 1.34221E-06
باوج (0.005161)
जवाब
(0.00026)
وجوت तोजो 6.75557E-10
با (4.16E-07)
अब
(0.001623)
اوجوت तोजवा (0) 0
ب
ब (4.48E-
05)
وت तो 2.18028E-08
وج (0.005161)
با
जो
(0.002602)
अब
(0.001623)
وجوت तोजो 6.69866E-16
ا (4.16E-07)
ب
अ (3.6E-05)
ब (4.48E-
05)
وت तो 2.16191E-14
وج (0.005161)
ا जो
ب
(0.002602)
अ (3.6E-05)
ब (4.48E-
05)
</table>
<bodyText confidence="0.98817075">
It is interesting to see that for segmentation of
Urdu words, we used Hindi language statistical
analysis instead of Urdu language statistical
analysis. Since the current system is part of
</bodyText>
<page confidence="0.998445">
47
</page>
<bodyText confidence="0.999861361445783">
Urdu-Hindi transliteration system, we prefer the
output to be segmented according to Hindi rules.
There are many words which are otherwise
joined in Hindi but written as separate words in
Urdu. So if we use the Urdu language modeling
for segmentation, the word gets broken. Some of
the examples are:
راکاوغا is written as combination of two words
اوغا+ راک in Urdu but its equivalent Hindi word
3TWMTWT� is written as a single word. Similarly,
in Hindi text the verbs are concatenated with the
future auxiliaries “gaa”, “gii” and “ge”, while
they are written separately in Urdu. Thus نيرک
+ےگ are written separately, but their equivalent
Hindi form Wl* is written as single word. So
the advantage of using Hindi training data is that
the words get segmented according to the
desired Hindi rules. Another problem with Urdu
training data was that the Urdu training itself
contains merged words. So the words had to be
manually separated, though fortunately the Urdu
corpus compiled by CRULP (www.crulp.org)
has been quite clean, but many words were
missing particularly English ones. Another
problem is that the words are broken even in the
cleaned Urdu corpus. On the other hand when
we used the Hindi training data for word
segmentation, the problems of merged or broken
words in the training text were not encountered.
Also the Hindi corpus compiled by us had much
larger vocabulary coverage, while the Urdu
corpus we used for training purpose had many
common words such as امابوا, ےرطخ , یھدناگ,
نسکيج etc. missing. Thus the word segmentation
algorithm which used the Hindi training set had
much better segmentation accuracy as compared
to the Urdu training set.
We observed that though the above scheme
worked fine in majority of the cases, but in a few
cases it failed to segment properly as it did not
take care of the context or adjacent words. As
for example consider the OW : تروعايدرم. It
contains six CCs: رم, د, اي, وع, ر and ت. The word
combination selected by above methodology is :
رم + ايد + تروع , though the correct
combination is درم + اي + تروع. It was observed
that as we did not take care about adjacent
words, thus wrong combination was selected. If
the bigram information is added, then such
problems were reduced.
We thus use both unigram and bigram
frequency analysis for deciding the best word
combination. Each Urdu word in the
combination is formed by joining adjacent
UCCs. In each of the combination, we first
convert each of the Urdu word to Hindi. Next we
find the unigram and bigram frequency of
occurrence of each Hindi word and Hindi word
pair in the combination. The bigram frequencies
are normalized to avoid multiplication by zero.
The combination with highest combined product
of the unigram and bigram frequencies of
occurrences is finally selected. Using this
methodology we were able to generate the
sequence combination is درم + اي + تروع in
above example.
As we are using Hindi training data, it was
observed that sometimes we had merged words
which did not had equivalent transliterated
words in our Hindi frequency list. As example,
the OW سيلبازارت had to be segmented as زارت +
سيلبا, but the equivalent transliterated Hindi
terms of زارت and سيلبا, were not found in the
Hindi frequency list. As a result, the OW is not
segmented. To take care of such situations, if we
cannot segment using the Hindi frequency list,
our system then goes for maximal matching
using the Urdu training data. Thus in above
example, after search fails in Hindi training set,
the system searches for the minimum word
combination and on finding the above two words
in the Urdu training set segments the OW into
these words.
</bodyText>
<sectionHeader confidence="0.997159" genericHeader="method">
6 Over Segmentation
</sectionHeader>
<bodyText confidence="0.999815428571429">
For wrongly spelled or OOV (out of vocabulary)
Urdu words, the system may forcibly break the
word into smaller words. As for example, our
system forcibly broke the OW رہودرگ into رگ + ود
+رہ . This problem proved difficult to tackle,
though we were able to partially solve it. It was
found that usually the OOV words were broken
into small unrelated words. So we put the
condition on the system to accept only those
word segments which contained at least one
word of length greater than three or at least one
bigram pair was present in the Hindi bigram list.
The presence of at least one bigram pair ensured
that all the words were not unrelated. Thus in the
</bodyText>
<page confidence="0.99726">
48
</page>
<bodyText confidence="0.997588285714286">
above example, the OW gets split into three
words, all of length two. These words when
transliterated to Hindi get converted to PtT + zr
+ F. On searching the bigram list, it was found
that neither of the bigram pair &lt; PtT, i�r &gt; and &lt;
�r , F &gt; was present and thus this word
segmentation was rejected.
</bodyText>
<sectionHeader confidence="0.999594" genericHeader="evaluation">
7 Experiments
</sectionHeader>
<bodyText confidence="0.999993409090909">
We tested our system on a test data of 1,613,991
Urdu words. In the decision stage, it was found
that 116,078 words, which make 7.19% of
original text were not found in the Urdu corpus
and were considered candidates for
segmentation. After morphological analysis of
these words, 2851 Urdu words were found to be
valid Uru words and were removed from the
segmentation candidate list. After converting the
remaining Urdu words to Hindi and checking
them in Hindi corpus, only 35,226 words were
left which were not present in Hindi corpus.
Therefore from original 16,13,991 only 35,226
(2.19%) were passed onto segmentation stage
for checking for merged words.
In the segmentation stage it was found that out
of 35,226 words, 24,001 words (68.13%) had
merged words. The number of merged words
varied from 2 to 6. Table 3 show the frequency
of number of merged words found in word
clusters. As can be seen from the table 96.71%
of merged word clusters had two merged words.
</bodyText>
<tableCaption confidence="0.983917">
Table 3. Frequency of Merged Words
</tableCaption>
<figure confidence="0.490137857142857">
Number of merged Frequency
words Percentage
2 96.71%
3 2.99%
4 0.25%
5 0.037%
6 0.004%
</figure>
<bodyText confidence="0.999597857142857">
The recall and precision for the decision
stage, which decides if the OW needs to be
segmented, were found to be 99.29% and
99.38% respectively.
The word segmentation algorithm was able to
correctly segment the words with 99.15%
accuracy.
</bodyText>
<sectionHeader confidence="0.998946" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.9999048125">
In this paper, we have presented a system for
solving the space omission problem in Urdu text.
This system is part of the larger system designed
for transliteration of Urdu text to Hindi. We
have combined statistical language modeling of
both Urdu and Hindi languages in development
of the system. We have presented a new scheme
of using Hindi for segmenting Urdu text after
transliteration, because Hindi uses spaces
consistently versus Urdu which has both space
omission and insertion problems. This is the first
time such a segmentation scheme for handling
Urdu space omission problem has been
presented. The word segmentation algorithm
was able to correctly segment the words with
99.15% accuracy.
</bodyText>
<sectionHeader confidence="0.997597" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999805">
The author will like to acknowledge the support
provided by ISIF grants for carrying out this
research.
</bodyText>
<sectionHeader confidence="0.999019" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9997391">
Durrani N. 2007. Typology of Word and Automatic
Word Segmentation in Urdu Text Corpus. National
University of Computer and Emerging Sciences,
Lahore, Pakistan.
Durrani N. and Hussain Sarmad. 2010. Urdu Word
Segmentation.http://www.crulp.org/Publication/pa
pers/2010/Urdu Word Segmentation NAACL.pdf
(accessed on 5th July 2010).
Jawaid Bushra and Ahmed Tafseer. 2009. Hindi to
Urdu Conversion: Beyond Simple Transliteration.
Proceedings of the Conference on Language &amp;
Technology, Lahore,.Pakistan, 24-31.
Lehal G. S. 2009. A Two Stage Word Segmentation
System For Handling Space Insertion Problem In
Urdu Script. Proceedings of World Academy of
Science, Engineering and Technology, Bangkok,
Thailand, 60: 321-324.
Malik Abbas, Besacier Laurent, Boitet Christian and
Bhattacharyya Pushpak. 2009. A hybrid Model for
Urdu Hindi Transliteration. Proceedings of the
</reference>
<page confidence="0.988023">
49
</page>
<reference confidence="0.999300238095238">
2009 Named Entities Workshop, ACL-IJCNLP
2009, Singapore, 177-185.
Nie, J.Y., Hannan, M.L. &amp; Jin, W. 1995. Combining
dictionary, rules and statistical information in
segmentation of Chinese. Computer Processing of
Chinese and Oriental Languages, 9(2): 125-143.
Papageorgiou Constantine P. 1994. Japanese word
segmentation by hidden Markov model. Proc. of
the HLT Workshop, 283–288.
Wang Xiaolong, , Fu Guohong, Yeung Danial S., Liu
James N.K., and Luk Robert. 2000. Models and
algorithms of Chinese word segmentation.
Proceedings of the International Conference on
Artificial Intelligence (IC-AI’2000), Las Vegas,
Nevada, USA, 1279-1284.
Xu Jia, Matusov Evgeny, Zens Richard, and Ney.
2005. Hermann.Integrated Chinese word
segmentation in statistical machine translation.
Proceedings of the International Workshop on
Spoken Language Translation, Pittsburgh, PA,
141-147.
</reference>
<page confidence="0.997675">
50
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.968653">
<title confidence="0.9916295">A Word Segmentation System for Handling Space Omission Problem in Urdu Script</title>
<author confidence="0.999108">Gurpreet Singh</author>
<affiliation confidence="0.9999535">Department of Computer Punjabi University,</affiliation>
<email confidence="0.986017">gslehal@gmail.com</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>N Durrani</author>
</authors>
<title>Typology of Word and Automatic Word Segmentation in</title>
<date>2007</date>
<institution>Urdu Text Corpus. National University of Computer and Emerging Sciences,</institution>
<location>Lahore, Pakistan.</location>
<marker>Durrani, 2007</marker>
<rawString>Durrani N. 2007. Typology of Word and Automatic Word Segmentation in Urdu Text Corpus. National University of Computer and Emerging Sciences, Lahore, Pakistan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Durrani</author>
<author>Hussain Sarmad</author>
</authors>
<date>2010</date>
<booktitle>Urdu Word Segmentation.http://www.crulp.org/Publication/pa pers/2010/Urdu Word Segmentation NAACL.pdf (accessed on 5th</booktitle>
<marker>Durrani, Sarmad, 2010</marker>
<rawString>Durrani N. and Hussain Sarmad. 2010. Urdu Word Segmentation.http://www.crulp.org/Publication/pa pers/2010/Urdu Word Segmentation NAACL.pdf (accessed on 5th July 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jawaid Bushra</author>
<author>Ahmed Tafseer</author>
</authors>
<title>Hindi to Urdu Conversion: Beyond Simple Transliteration.</title>
<date>2009</date>
<booktitle>Proceedings of the Conference on Language &amp; Technology, Lahore,.Pakistan,</booktitle>
<pages>24--31</pages>
<marker>Bushra, Tafseer, 2009</marker>
<rawString>Jawaid Bushra and Ahmed Tafseer. 2009. Hindi to Urdu Conversion: Beyond Simple Transliteration. Proceedings of the Conference on Language &amp; Technology, Lahore,.Pakistan, 24-31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G S Lehal</author>
</authors>
<title>A Two Stage Word Segmentation System For Handling Space Insertion Problem In Urdu Script.</title>
<date>2009</date>
<booktitle>Proceedings of World Academy of Science, Engineering and Technology,</booktitle>
<volume>60</volume>
<pages>321--324</pages>
<location>Bangkok, Thailand,</location>
<marker>Lehal, 2009</marker>
<rawString>Lehal G. S. 2009. A Two Stage Word Segmentation System For Handling Space Insertion Problem In Urdu Script. Proceedings of World Academy of Science, Engineering and Technology, Bangkok, Thailand, 60: 321-324.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Malik Abbas</author>
<author>Besacier Laurent</author>
<author>Boitet Christian</author>
<author>Bhattacharyya Pushpak</author>
</authors>
<title>A hybrid Model for Urdu Hindi Transliteration.</title>
<date>2009</date>
<booktitle>Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, Singapore,</booktitle>
<pages>177--185</pages>
<marker>Abbas, Laurent, Christian, Pushpak, 2009</marker>
<rawString>Malik Abbas, Besacier Laurent, Boitet Christian and Bhattacharyya Pushpak. 2009. A hybrid Model for Urdu Hindi Transliteration. Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, Singapore, 177-185.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Y Nie</author>
<author>M L Hannan</author>
<author>W Jin</author>
</authors>
<title>Combining dictionary, rules and statistical information in segmentation of Chinese.</title>
<date>1995</date>
<booktitle>Computer Processing of Chinese and Oriental Languages,</booktitle>
<volume>9</volume>
<issue>2</issue>
<pages>125--143</pages>
<contexts>
<context position="871" citStr="Nie et al, 1995" startWordPosition="126" endWordPosition="129">ication, where the initial phase requires tokenization of input into words. For languages like English, French and Spanish etc. tokenization is considered trivial because the white space or punctuation marks between words is a good approximation of where a word boundary is. Whilst in various Asian languages such as Chinese, Thai and Myanmar, white spaces is rarely or never used to determine the word boundaries, so one must resort to higher levels of information such as: information of morphology, syntax and statistical analysis to reconstruct the word boundary information (Papageorgiou, 1994; Nie et al, 1995; Wang et al, 2000; Xu et al, 2005). Though the Urdu word segmentation problem is not as severe as some of the other Asian language, since space is used for word delimitation, but the space is not consistently used, which gives rise to both space omission and space insertion errors in Urdu. Durrani(2007) and Durrani and Hussain(2010) have discussed in detail the various Urdu word segmentation issues while Jawaid and Ahmed(2009) and Abbas et al(2009) have discussed the Hindi-Urdu transliteration issues. A word segmentation system for handling space insertion problem in Urdu script has been pres</context>
</contexts>
<marker>Nie, Hannan, Jin, 1995</marker>
<rawString>Nie, J.Y., Hannan, M.L. &amp; Jin, W. 1995. Combining dictionary, rules and statistical information in segmentation of Chinese. Computer Processing of Chinese and Oriental Languages, 9(2): 125-143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Papageorgiou Constantine P</author>
</authors>
<title>Japanese word segmentation by hidden Markov model.</title>
<date>1994</date>
<booktitle>Proc. of the HLT Workshop,</booktitle>
<pages>283--288</pages>
<marker>P, 1994</marker>
<rawString>Papageorgiou Constantine P. 1994. Japanese word segmentation by hidden Markov model. Proc. of the HLT Workshop, 283–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fu Guohong</author>
<author>Yeung Danial S</author>
<author>Liu James N K</author>
<author>Luk Robert</author>
</authors>
<title>Models and algorithms of Chinese word segmentation.</title>
<date>2000</date>
<booktitle>Proceedings of the International Conference on Artificial Intelligence (IC-AI’2000),</booktitle>
<pages>1279--1284</pages>
<location>Las Vegas, Nevada, USA,</location>
<marker>Guohong, S, K, Robert, 2000</marker>
<rawString>Wang Xiaolong, , Fu Guohong, Yeung Danial S., Liu James N.K., and Luk Robert. 2000. Models and algorithms of Chinese word segmentation. Proceedings of the International Conference on Artificial Intelligence (IC-AI’2000), Las Vegas, Nevada, USA, 1279-1284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xu Jia</author>
<author>Matusov Evgeny</author>
<author>Zens Richard</author>
<author>Ney</author>
</authors>
<title>Hermann.Integrated Chinese word segmentation in statistical machine translation.</title>
<date>2005</date>
<booktitle>Proceedings of the International Workshop on Spoken Language Translation,</booktitle>
<pages>141--147</pages>
<location>Pittsburgh, PA,</location>
<marker>Jia, Evgeny, Richard, Ney, 2005</marker>
<rawString>Xu Jia, Matusov Evgeny, Zens Richard, and Ney. 2005. Hermann.Integrated Chinese word segmentation in statistical machine translation. Proceedings of the International Workshop on Spoken Language Translation, Pittsburgh, PA, 141-147.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>