<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002604">
<title confidence="0.984624">
XML-Based NLP Tools for Analysing and Annotating Medical Language
</title>
<author confidence="0.958643">
Claire Grover, Ewan Klein, Mirella Lapata and Alex Lascarides
</author>
<affiliation confidence="0.889677">
Division of Informatics
The University of Edinburgh
</affiliation>
<address confidence="0.755352">
2 Buccleuch Place
Edinburgh EH8 9LW, UK
</address>
<email confidence="0.980273">
{C.Grover, E.Klein, M.Lapata, A.Lascarides}@ed.ac.uk
</email>
<sectionHeader confidence="0.993491" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999855625">
We describe the use of a suite of highly flexible
XML-based NLP tools in a project for processing and
interpreting text in the medical domain. The main
aim of the paper is to demonstrate the central role
that XML mark-up and XML NLP tools have played
in the analysis process and to describe the resultant
annotated corpus of MEDLINE abstracts. In addition
to the XML tools, we have succeeded in integrating
a variety of non-XML ‘off the shelf’ NLP tools into
our pipelines, so that their output is added into the
mark-up. We demonstrate the utility of the anno-
tations that result in two ways. First, we investigate
how they can be used to improve parse coverage of a
hand-crafted grammar that generates logical forms.
And second, we investigate how they contribute to
automatic lexical semantic acquisition processes.
</bodyText>
<sectionHeader confidence="0.998996" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999892754385965">
In this paper we describe our use of XML for an anal-
ysis of medical language which involves a number
of complex linguistic processing stages. The ulti-
mate aim of the project is to to acquire lexical se-
mantic information from MEDLINE through parsing,
however, a fundamental tenet of our approach is that
higher-level NLP activities benefit hugely from be-
ing based on a reliable and well-considerered initial
stage of tokenisation. This is particularly true for
language tasks in the biomedical and other technical
domains since general purpose NLP technology may
stumble at the first hurdle when confronted with
character strings that represent specialised techni-
cal vocabulary. Once firm foundations are laid then
one can achieve better performance from e.g. chun-
kers and parsers than might otherwise be the case.
We show how well-founded tools, especially XML-
based ones, can enable a variety of NLP components
to be bundled together in different ways to achieve
different types of analysis. Note that in fields such
as information extraction (IE) it is common to use
statistical text classification methods for data anal-
ysis. Our more linguistic approach may be of as-
sistence in IE: see Craven and Kumlien (1999) for
discussion of methods for IE from MEDLINE.
Our processing paradigm is XML-based. As a
mark-up language for NLP tasks, XML is expres-
sive and flexible yet constrainable. Furthermore,
there exist a wide range of XML-based tools for NLP
applications which lend themselves to a modular,
pipelined approach to processing whereby linguis-
tic knowledge is computed and added as XML an-
notations in an incremental fashion. In processing
MEDLINE abstracts we have built a number of such
pipelines using as key components the programs
distributed with the LT TTT and LT XML toolsets
(Grover et al., 2000; Thompson et al., 1997). We
have also successfully integrated non-XML public-
domain tools into our pipelines and incorporated
their output into the XML mark-up using the LT XML
program xmlperl (McKelvie, 2000).
In Section 2 we describe our use of XML-based
tokenisation tools and techniques and in Sections 3
and 4 we describe two different approaches to
analysing MEDLINE data which are built on top of
the tokenisation. The first approach uses a hand-
coded grammar to give complete syntactic and se-
mantic analyses of sentences. The second approach
performs a shallower statistically-based analysis
which yields ‘grammatical relations’ rather than
full logical forms. This information about gram-
matical relations is used in a statistically-trained
model which disambiguates the semantic relations
in noun compounds headed by deverbal nominali-
sations. For this second approach we compare two
separate methods of shallow analysis which require
the use of two different part-of-speech taggers.
</bodyText>
<sectionHeader confidence="0.623608" genericHeader="method">
2 Pre-parsing of Medline Abstracts
</sectionHeader>
<bodyText confidence="0.9136685">
For the work reported here, we have used the
OHSUMED corpus of MEDLINE abstracts (Hersh et
</bodyText>
<figure confidence="0.994948190476191">
&lt;RECORD&gt;
&lt;ID&gt;395&lt;/ID&gt;
&lt;MEDLINE-ID&gt;87052477&lt;/MEDLINE-ID&gt;
&lt;SOURCE&gt;Clin Pediatr (Phila) 8703; 25(12):617-9 &lt;/SOURCE&gt;
&lt;MESH&gt;
Adolescence; Alcoholic Intoxication/BL/*EP; Blood Glucose/AN; Canada; Child; Child, Preschool;
Electrolytes/BL; Female; Human; Hypoglycemia/ET; Infant; Male; Retrospective Studies.
&lt;/MESH&gt;
&lt;TITLE&gt;Ethyl alcohol ingestion in children. A 15-year review.&lt;/TITLE&gt;
&lt;PTYPE&gt;JOURNAL ARTICLE.&lt;/PTYPE&gt;
&lt;ABSTRACT&gt;
&lt;SENT&gt;&lt;W P=’DT’&gt;A&lt;/W&gt; &lt;W P=’JJ’&gt;retrospective&lt;/W&gt;
&lt;W P=’NN’ LM=’study’&gt;study&lt;/W&gt; &lt;W P=’VBD’ LM=’be’&gt;was&lt;/W&gt;
&lt;W P=’VBN’ LM=’conduct’&gt;conducted&lt;/W&gt; &lt;W P=’IN’&gt;by&lt;/W&gt; &lt;W P=’NN’ LM=’chart’&gt;chart&lt;/W&gt;
&lt;W P=’NNS’ LM=’review’&gt;reviews&lt;/W&gt; &lt;W P=’IN’ &gt;of&lt;/W&gt; &lt;W P=’CD’&gt;27&lt;/W&gt;
&lt;W P=’NNS’ LM=’patient’&gt;patients&lt;/W&gt; &lt;W P=’IN’&gt;with&lt;/W&gt; &lt;W P=’JJ’&gt;documented&lt;/W&gt;
&lt;W P=’NN’ LM=’ethanol’&gt;ethanol&lt;/W&gt; &lt;W P=’NN’ LM=’ingestion’&gt;ingestion&lt;/W&gt;&lt;W P=’.’&gt;.&lt;/W&gt;
&lt;/SENT&gt; &lt;SENT&gt; ... &lt;/SENT&gt; &lt;SENT&gt; ... &lt;/SENT&gt;
&lt;/ABSTRACT&gt;
&lt;AUTHOR&gt;Leung AK.&lt;/AUTHOR&gt;
&lt;/RECORD&gt;
</figure>
<figureCaption confidence="0.999989">
Figure 1: A sample from the XML-marked-up OHSUMED Corpus
</figureCaption>
<bodyText confidence="0.9910413">
al., 1994) which contains 348,566 references taken
from the years 1987–1991. Not every reference
contains an abstract, thus the total number of ab-
stracts in the corpus is 233,443. The total number of
words in those abstracts is 38,708,745 and the ab-
stracts contain approximately 1,691,383 sentences
with an average length of 22.89 words.
By pre-parsing we mean identification of word
tokens and sentence boundaries and other lower-
level processing tasks such as part-of-speech (POS)
tagging and lemmatisation. These initial stages of
processing form the foundation of our NLP work
with MEDLINE abstracts and our methods are flex-
ible enough that the representation of pre-parsing
can be easily tailored to suit the input needs of sub-
sequent higher-level processors. We start by con-
verting the OHSUMED corpus from its original for-
mat to an XML format (see Figure 1). From this
point on we pass the data through pipelines which
are composed of calls to a variety of XML-based
tools from the LT TTT and LT XML toolsets. The
core program in our pipelines is the LT TTT program
fsgmatch, a general purpose transducer which pro-
cesses an input stream and rewrites it using rules
provided in a hand-written grammar file, where the
rewrite usually takes the form of the addition of
XML mark-up. Typically, fsgmatch rules specify
patterns over sequences of XML elements and use a
regular expression language to identify patterns in-
side the character strings (PCDATA) which are the
content of elements. For example, the following
rule for decimals such as “.25” is searching for a
sequence of two S elements where the first contains
the string “.” as its PCDATA content and the second
has been identified as a cardinal number (C=‘CD’,
e.g. any sequence of digits). When these two S el-
ements are found, they are wrapped in a W element
with the attribute C=‘CD’ (targ sg). (Here S ele-
ments encode character sequences, see below, and
W elements encode words.)
</bodyText>
<equation confidence="0.9163295">
&lt;RULE name=&amp;quot;decimal&amp;quot; targ_sg=&amp;quot;W[C=‘CD’]&amp;quot;&gt;
&lt;REL match=&amp;quot;S/#[\.]$&amp;quot;&gt;&lt;/REL&gt;
&lt;REL match=&amp;quot;S[C=‘CD’]&amp;quot;&gt;&lt;/REL&gt;
&lt;/RULE&gt;
</equation>
<bodyText confidence="0.947011666666667">
Subparts of a pipeline can be thought of as dis-
tinct modules so that pipelines can be configured to
different tasks. A typical pipeline starts with a two-
</bodyText>
<equation confidence="0.943422">
&lt;S C=’UCA’&gt;A&lt;/S&gt;&lt;S C=’LCA’&gt;rterial&lt;/S&gt;
&lt;S C=’WS’&gt; &lt;/S&gt;&lt;S C=’UCA’&gt;P&lt;/S&gt;
&lt;S C=’LCA’&gt;a&lt;/S&gt;&lt;S C=’UCA’&gt;O&lt;/S&gt;
&lt;S C=’CD’&gt;2&lt;/S&gt;&lt;S C=’WS’&gt; &lt;/S&gt;
&lt;S C=’LCA’&gt;as&lt;/S&gt;&lt;S C=’WS’&gt; &lt;/S&gt;
&lt;S C=’LCA’&gt;measured&lt;/S&gt;
</equation>
<figureCaption confidence="0.990866">
Figure 2: Character Sequence (S) Mark-up
</figureCaption>
<bodyText confidence="0.999990133333333">
stage process to identify word tokens within ab-
stracts. First, sequences of characters are bundled
into S (sequence) elements using fsgmatch. For each
class of character a sequence of one or more in-
stances is identified and the type is recorded as the
value of the attribute C (UCA=upper case alphabetic,
LCA=lower case alphabetic, WS=white space etc.).
Figure 2 shows the string Arterial PaO2 as mea-
sured marked up for S elements (line breaks added
for formatting purposes). Every single character in-
cluding white space and newline is contained in S
elements which become building blocks for the next
call to fsgmatch where words are identified. An al-
ternative approach would find words in a single step
but our two-step method provides a cleaner set of
word-level rules which are more easily modified and
tailored to different purposes: modifiability is criti-
cal since the definition of what is a word can differ
from one subsequent processing step to another.
A pipeline which first identifies words and then
performs sentence boundary identification and POS
tagging followed by lemmatisation is shown in Fig-
ure 3 (somewhat simplified and numbering added
for ease of exposition). The Perl program in step 1
wraps the input inside an XML header and footer
as a first step towards conversion to XML. Step 2
calls fsgmatch with the grammar file ohsumed.gr to
identify the fields of an OHSUMED entry and convert
them into XML mark-up: each abstract is put inside
a RECORD element which contains sub-structure re-
flecting e.g. author, title, MESH code and the ab-
stract itself. From this point on, all processing is di-
rected at the ABSTRACT elements through the query
“.*/ABSTRACT”1. Steps 3 and 4 make calls to fsg-
match to identify S and W (word) elements as de-
scribed above and after this point, in step 5, the S
mark-up is discarded (using the LT TTT program
sgdelmarkup) since it has now served its purpose.
Step 6 contains a call to the other main LT TTT
program, ltpos (Mikheev, 1997), which performs
both sentence identification and POS tagging. The
subquery (-qs) option picks out ABSTRACTs as the
elements within RECORDs (-q option) that are to
be processed; the -qw option indicates that the in-
put has already been segmented into words marked
</bodyText>
<figureCaption confidence="0.566302142857143">
1The query language that the LT TTT and LT XML tools use
is a specialised XML query language which pinpoints the part
of the XML tree-structure that is to be processed at that point.
This query language pre-dates XPath and in expressiveness it
constitutes a subset of XPath except that it also allows regular
expressions over text content. Future plans include modifying
out tools to allow for the use of XPath as a query language.
</figureCaption>
<bodyText confidence="0.999869222222222">
up as W elements; the -sent option indicates that
sentences should be wrapped as SENT elements; the
-tag option is an instruction to output POS tags and
the -pos attr option indicates that POS tags should
be encoded as the value of the attribute P on W ele-
ments. The final resource.xml names the resource
file that ltpos is to use. Note that the tagset used
by ltpos is the Penn Treebank tagset (Marcus et al.,
1994).
</bodyText>
<listItem confidence="0.993866555555555">
1. ohs2xml.perl \
2.  |fsgmatch -q &amp;quot;.*/TEXT&amp;quot; ohsumed.gr \
3.  |fsgmatch -q &amp;quot;.*/ABSTRACT&amp;quot; pretok.gr \
4.  |fsgmatch &amp;quot;.*/ABSTRACT&amp;quot; tok.gr \
5.  |sgdelmarkup -q &amp;quot;.*/S&amp;quot; \
6.  |ltpos -q &amp;quot;.*/RECORD&amp;quot; -qs &amp;quot;.*/ABSTRACT&amp;quot; \
-qw &amp;quot;.*/W&amp;quot; -sent SENT \
-tag -pos_attr P resource.xml \
7.  |xmlperl lemma.rule
</listItem>
<figureCaption confidence="0.996875">
Figure 3: Basic Tokenisation Pipeline
</figureCaption>
<bodyText confidence="0.99996384">
Up to this point, each module in the pipeline has
used one of the LT TTT or LT XML programs which
are sensitive to XML structure. There are, however,
a large number of tools available from the NLP com-
munity which could profitably be used but which are
not XML-aware. We have integrated some of these
tools into our pipelines using the LT XML program
xmlperl. This is a program which makes underly-
ing use of an XML parser so that rules defined in
a rule file can be directed at particular parts of the
XML tree-structure. The actions in the rules are de-
fined using the full capabilities of Perl. This gives
the potential for a much wider range of transforma-
tions of the input than fsgmatch allows and, in par-
ticular, we use Perl’s stream-handling capabilities
to pass the content of XML elements out to a non-
XML program, receive the result back and encode it
back in the XML mark-up. Step 7 of the pipeline in
Figure 3 shows a call to xmlperl with the rule file
lemma.rule. This rule file invokes Minnen et al.’s
(2000) morpha lemmatiser: the PCDATA content of
each verbal or nominal W element is passed to the
lemmatiser and the lemma that is returned is en-
coded as the value of the attribute LM. A sample
of the output from the pipeline is shown in Figure 1.
</bodyText>
<sectionHeader confidence="0.98152" genericHeader="method">
3 Deep Grammatical Analysis
</sectionHeader>
<bodyText confidence="0.9999189">
As part of our work with OHSUMED, we have
been attempting to improve the coverage of a hand-
crafted, linguistically motivated grammar which
provides full-syntactic analysis paired with logical
forms. The grammar and parsing system we use
is the wide-coverage grammar, morphological anal-
yser and lexicon provided by the Alvey Natural Lan-
guage Tools (ANLT) system (Carroll et al. 1991,
Grover et al. 1993). Our first aim was to increase
coverage up to a reasonable level so that parse rank-
ing techniques could then be applied.
The ANLT grammar is a feature-based unification
grammar based on the GPSG formalism (Gazdar et
al., 1985). In this framework, lexical entries carry
a significant amount of information including sub-
categorisation information. Thus the practical parse
success of the grammar is significantly dependent
on the quality of the lexicon. The ANLT grammar
is distributed with a large lexicon and, while this
provides a core of commonly-occurring lexical en-
tries, there remains a significant problem of inade-
quate lexical coverage. If we try to parse OHSUMED
sentences using the ANLT lexicon and no other re-
sources, we achieve very poor results (2% coverage)
because most of the medical domain words are sim-
ply not in the lexicon and there is no ‘robustness’
strategy built into ANLT. Rather than pursue the
labour-intensive course of augmenting the lexicon
with domain-specific lexical resources, we have de-
veloped a solution which does not require that new
lexicons be derived for each new domain type and
which has robustness built into the strategy. Fur-
thermore, this solution does not preclude the use of
specialist lexical resources if these can be used to
achieve further improvements in performance.
Our approach relies on the sophisticated XML-
based tokenisation and POS tagging described in the
previous section and it builds on this by combin-
ing POS tag information with the existing ANLT lex-
ical resources. We preserve POS tag information for
content words (nouns, verbs, adjectives, adverbs)
since this is usually reliable and informative and
we dispose of POS tags for function words (com-
plementizers, determiners, particles, conjunctions,
auxiliaries, pronouns, etc.) since the ANLT hand-
written entries for these are more reliable and are
tuned to the needs of the grammar. Furthermore,
unknown words are far more likely to be content
words, so knowledge of the POS tag will most often
be needed for content words.
Having retained content word tags, we use them
during lexical look-up in one of two ways. If the
word exists in the lexicon with the same basic cat-
egory as the POS tag then the POS tag plays a ‘dis-
ambiguating’ role, filtering out entries for the word
with different categories. If, on the other hand, the
word is not in the lexicon or it is not in the lexicon
with the relevant category, then a basic underspeci-
fied entry for the POS tag is used as the lexical entry
for the word, thereby allowing the parse to proceed.
For example, if the following partially tagged sen-
tence is input to the parser, it is successfully parsed.
We studied VBD the value NN of
transcutaneous JJ carbon NN dioxide NN
monitoring NN during transport NN
Without the tags the parse would fail since the word
transcutaneous is not in the ANLT lexicon. Further-
more, monitoring is present in the lexicon but as a
verb and not as a noun. For both these words, or-
dinary lexical look-up fails and the entries for the
tags have to be used instead. Note that the case
of monitoring would be problematic for a strategy
where tagging is used only in case lexical look-up
fails, since here it is incomplete rather than failed.
The implementation of our word tag pair look-up
method is specific to the ANLT system and uses its
morphological analysis component to treat tags as a
novel kind of affix. Space considerations preclude
discussion of this topic here but see Grover and Las-
carides (2001) for further details.
Another impediment to parse coverage is the
prevalence of technical expressions and formulae in
biomedical and other technical language. For ex-
ample, the following sentence has a straightforward
overall syntactic structure but the ANLT grammar
does not contain specialist rules for handling ex-
pressions such as 5.0+/-0.4 grams tension and thus
the parse would fail.
Control tissues displayed a reproducible response to
bethanechol stimulation at different calcium
concentrations with an ED50 of 0.4 mM calcium
and a peak response of 5.0+/-0.4 grams tension.
Our response to issues like these is to place a fur-
ther layer of processing in between the output of
the initial tokenisation pipeline in Figure 3 and the
input to the parser. Since the ANLT system is not
XML-based, we already use xmlperl to convert sen-
tences to the ANLT input format of one sentence per
line with tags appended to words using an under-
score. We can add a number of other processes at
this point to implement a strategy of using fsgmatch
grammars to package up technical expressions so as
to render them innocuous to the parser. Thus all
of the following ‘words’ have been identified using
fsgmatch rules and can be passed to the parser as
unanalysable units. The classification of these ex-
amples as nouns reflects a hypothesis that they can
slot into the correct parse as noun phrases but there
is room for experimentation since the conversion to
parser input format can rewrite the tag in any way.
</bodyText>
<equation confidence="0.97950075">
&lt;W P=‘NN’&gt;P less than 0.001&lt;/W&gt;
&lt;W P=‘NN’&gt;166 +/- 77 mg/dl&lt;/W&gt;
&lt;W P=‘NN’&gt;2 to 5 cc/day&lt;/W&gt;
&lt;W P=‘NN’&gt;2.5 mg i.v.&lt;/W&gt;
</equation>
<bodyText confidence="0.99279775">
In addition to these kinds of examples, we also
package up other less technical expressions such as
common multi-word words and spelled out num-
bers:
</bodyText>
<equation confidence="0.4571045">
&lt;W P=‘CD’&gt;thirty-five&lt;/W&gt; thirty-five CD
&lt;W P=‘CD’&gt;Twenty one&lt;/W&gt; Twenty—one CD
&lt;W P=‘IN’&gt;In order to&lt;/W&gt; In—order—to IN
&lt;W P=‘JJ’&gt;in vitro&lt;/W&gt; in—vitro JJ
</equation>
<bodyText confidence="0.986461961538461">
In order to measure the effectiveness of our at-
tempts to improve coverage, we conducted an ex-
periment where we parsed 200 sentences taken at
random from OHSUMED. We processed the sen-
tences in three different ways and gathered parse
success rates for each of the three methods. Ver-
sion 1 established a ‘no-intervention’ baseline by
using the initial pipeline in Figure 3 to identify
words and sentences but otherwise discarding all
other mark-up. Version 2 addressed the lexical ro-
bustness issue by retaining POS tags to be used by
the grammar in the way outlined above. Version 3
applied the full set of preprocessing techniques in-
cluding the packaging-up of formulaic and other
technical expressions. The parse results for these
runs are as follows:
Version 1 Version 2 Version 3
Parses 4 (2%) 32 (16%) 79 (39.5%)
Even in Version 3, coverage is still not very high but
the difference between the three versions demon-
strates that our approach has made significant in-
roads into the problem. Moreover, the increase in
coverage was achieved without any significant al-
terations to the general-purpose grammar and the
tokenisation of formulaic expressions was by no
means comprehensive.
</bodyText>
<sectionHeader confidence="0.988484" genericHeader="method">
4 Shallow Analysis
</sectionHeader>
<bodyText confidence="0.999989166666667">
In contrast to the full syntactic analysis experi-
ments described in the previous section, here we
describe two distinct methods of shallow analy-
sis from which we acquire frequency information
which is used to predict lexical semantic relations
in a particular kind of noun compound.
</bodyText>
<subsectionHeader confidence="0.99516">
4.1 The Task
</subsectionHeader>
<bodyText confidence="0.982761871794872">
The aim of the processing in this task is to pre-
dict the relationship between a deverbal nominalisa-
tion head and its modifier in noun-noun compounds
such as tube placement, antibody response, pain re-
sponse, helicopter transport. In these examples, the
meaning of the head noun is closely related to the
meaning of the verb from which it derives and the
relationship between this noun and its modifier can
typically be matched onto a relationship between
the verb and one of its arguments. For example,
there is a correspondence between the compound
tube placement and the verb plus direct object string
place the tube. When we interpret the compound
we describe the role that the modifier plays in terms
of the argument position it would fill in the corre-
sponding verbal construction:
tube placement object
antibody response subject
pain response to-object
helicopter transport by-object
We can infer that tube in tube placement fills the
object role in the place relation by gathering in-
stances from the corpus of the verb place and dis-
covering that tube occurs more frequently in object
position than in other positions and that the object
interpretation is therefore more probable.
To interpret such compounds in this way, we need
access to information about the verbs from which
the head nouns are derived. Specifically, for each
verb, we need counts of the frequency with which
it occurs with each noun in each of its argument
slots. Ultimately, in fact, in view of the sparse data
problem, we need to back off from specific noun in-
stances to noun classes (see Section 4.4). The cur-
rent state-of-the-art in NLP provides a number of
routes to acquiring grammatical relations informa-
tion about verbs, and for our experiment we chose
two methods in order to be able to compare the tech-
niques and assess their utility.
</bodyText>
<subsectionHeader confidence="0.999564">
4.2 Chunking with Cass
</subsectionHeader>
<bodyText confidence="0.993911">
Our first method of acquiring verb grammatical re-
lations is that used by Lapata (2000) for a similar
task on more general linguistic data. This method
uses Abney’s (1996) Cass chunker which uses the
finite-state cascade technique. A finite-state cas-
cade is a sequence of non-recursive levels: phrases
at one level are built on phrases at the previous
level without containing same level or higher-level
phrases. Two levels of particular importance are
chunks and simplex clauses. A chunk is the non-
recursive core of intra-clausal constituents extend-
ing from the beginning of the constituent to its head,
excluding post-head dependents (i.e., NP, VP, PP),
whereas a simplex clause is a sequence of non-
recursive clauses (Abney, 1996). Cass recognizes
chunks and simplex clauses using a regular expres-
sion grammar without attempting to resolve attach-
ment ambiguities. The parser comes with a large-
scale grammar for English and a built-in tool that
extracts predicate-argument tuples out of the parse
trees that Cass produces. Thus the tool identifies
subjects and objects as well as PPs without how-
ever distinguishing arguments from adjuncts. We
consider verbs followed by the preposition by and
a head noun as instances of verb-subject relations.
Our verb-object tuples also include prepositional
objects even though these are not explicitly iden-
tified by Cass. We assume that PPs adjacent to the
verb and headed by either of the prepositions in, to,
for, with, on, at, from, of, into, through, upon are
prepositional objects.
The input to the process is the entire OHSUMED
corpus after it has been converted to XML, to-
kenised, split into sentences and POS tagged us-
ing ltpos as described in Section 2. The output of
this tokenisation is converted to Cass’s input format
which is a non-XML file with one word per line and
tags separated by tab. We achieve this conversion
using xmlperl with a simple rule file. The output
of Cass and the grammatical relations processor is a
list of each verb-argument pair in the corpus:
manage :obj refibrillation
respond :subj psoriasis
access :to system
</bodyText>
<subsectionHeader confidence="0.9830675">
4.3 Shallow Parsing with the Tag Sequence
Grammar
</subsectionHeader>
<bodyText confidence="0.999882678571429">
Our second method of acquiring verb grammati-
cal relations uses the statistical parser developed by
Briscoe and Carroll (1993, 1997) which is an ex-
tension of the ANLT grammar development system
which we used for our deep grammatical analysis as
reported in Section 3 above. The statistical parser,
known as the Tag Sequence Grammar (TSG), uses a
hand-crafted grammar where the lexical entries are
for POS tags rather than words themselves. Thus it
is strings of tags that are parsed rather than strings
of words. The statistical part of the system is the
parse ranking component where probabilities are as-
sociated with transitions in an LR parse table. The
grammar does not achieve full-coverage but on the
OHSUMED corpus we were able to obtain parses for
99.05% of sentences. The number of parses found
per sentence ranges from zero into the thousands
but the system returns the highest ranked parse ac-
cording to the statistical ranking method. We do
not have an accurate measure of how many of the
highest ranked parses are actually correct but even a
partially incorrect parse may still yield useful gram-
matical relations data.
In recent developments (Carroll and Briscoe,
2001), the TSG authors have developed an algorithm
for mapping TSG parse trees to representations of
grammatical relations within the sentence in the fol-
lowing format:
</bodyText>
<equation confidence="0.926196777777778">
These centres are efficiently trapped in proteins at low
temperatures
(|ncsubj ||trap ||centre ||obj|)
(|iobj ||in ||trap ||protein|)
(|detmod ||centre ||These|)
(|mod ||trap ||efficiently|)
(|aux ||trap ||be|)
(|ncmod ||temperature ||low|)
(|ncmod ||at ||trap ||temperature|)
</equation>
<bodyText confidence="0.977488090909091">
This format can easily be mapped to the same for-
mat as described in Section 4.2 to give counts of the
number of times a particular verb occurs with a par-
ticular noun as its subject, object or prepositional
object.
As explained above, the TSG parses sequences
of tags, however it requires a different tagset from
that produced by ltpos, namely the CLAWS2 tagset
(Garside, 1987). To prepare the corpus for parsing
with the TSG we therefore tagged it with Elworthy’s
(1994) tagger and since this is a non-XML tool we
used xmlperl to invoke it and to incorporate its re-
sults back into the XML mark-up. Sentences were
then prepared as input to the TSG—this involved us-
ing xmlperl to replace words by their lemmas and to
convert to ANLT input format:
These DD2 centre NN2 be VBR efficiently RR
trap VVN in II protein NN2 at II low JJ
temperature NN2
The lemmas are needed in order that the TSG out-
puts them rather than inflected words in the gram-
matical relations output shown above.
</bodyText>
<subsectionHeader confidence="0.993249">
4.4 Compound Interpretation
</subsectionHeader>
<bodyText confidence="0.999985111111111">
Having collected two different sets of frequency
counts from the entire OHSUMED corpus for verbs
and their arguments, we performed an experiment to
discover (a) whether it is possible to reliably predict
semantic relations in nominalisation-headed com-
pounds and (b) whether the two methods of col-
lecting frequency counts make any significant dif-
ference to the process.
To collect data for the experiment we needed to
add to the mark-up already created by the basic
pipeline in Figure 3, (a) to mark up deverbal nomi-
nalisations with information about their verbal stem
to give nominalisation-verb equivalences and (b) to
mark up compounds in order to collect samples of
two-word compounds headed by deverbal nominal-
isations. For the first task we combined further use
of the lemmatiser with the use of lexical resources.
In a first pass we used the morpha lemmatiser to
find the verbal stem for -ing nominalisations such
as screening and then we looked up the remaining
nouns in a nominalisation lexicon which we created
by combining the nominalisation list which is pro-
vided by UMLS (2000) with the NOMLEX nominali-
sation lexicon (MacLeod et al., 1998) As a result of
these stages, most of the deverbal nominalisations
can be marked up with a VSTEM attribute whose
value is the verbal stem:
</bodyText>
<table confidence="0.6406045">
&lt;W P=’NN’ LM=’reaction’ VSTEM=’react’&gt;reaction&lt;/W&gt;
&lt;W P=’NN’ LM=’growth’ VSTEM=’grow’&gt;growth&lt;/W&gt;
&lt;W P=’NN’ LM=’control’ VSTEM=’control’&gt;control&lt;/W&gt;
&lt;W P=’NN’ LM=’coding’ VSTEM=’code’&gt;coding&lt;/W&gt;
</table>
<bodyText confidence="0.999705163265306">
To mark up compounds we developed an fsgmatch
grammar for compounds of all lengths and kinds
and we used this to process a subset of the first two
years of the corpus.
We interpret nominalisations in the biomedical
domain using a machine learning approach which
combines syntactic, semantic, and contextual fea-
tures. Using the LT XML program sggrep we
extracted all sentences containing two-word com-
pounds headed by deverbal nominalisations and
from this we took a random sample of 1,000 nom-
inalisations. These were manually disambiguated
using the following categories which denote the
argument relation between the deverbal head and
its modifier: SUBJ (age distribution), OBJ (weight
loss), WITH (graft replacement), FROM (blood elim-
ination), AGAINST (seizure protection), FOR (non-
stress test), IN (vessel obstruction), BY (aerosol ad-
ministration), OF (water deprivation), ON (knee op-
eration), and TO (treatment response). We also in-
cluded the categories NA (non applicable) for nom-
inalisations with relations other than the ones pre-
dicted by the underlying verb’s subcategorisation
frame (e.g., death stroke) and NV (non deverbal) for
compounds that were wrongly identified as nomi-
nalisations.
We treated the interpretation of nominalisations
as a classification task and experimented with dif-
ferent features using the C4.5 decision tree learner
(Quinlan, 1993). Some of the features we took into
account were the context surrounding the candidate
nominalisations (encoded as words or POS-tags), the
number of times a modifier was attested as an argu-
ment of the verb corresponding to the nominalised
head, and the nominalisation affix of the deverbal
head (e.g., -ation, -ment). In the face of sparse
data, linguistic resources such as WordNet (Miller
and Charles, 1991) and UMLS were used to recre-
ate distributional evidence absent from our corpus.
We obtained several different classification models
as a result of using different marked-up versions of
the corpus, different parsers, and different linguistic
resources. Full details of the results are described
in Grover et al. (2002); we only have space for a
brief summary here. Our best results achieved an
accuracy of 73.6% (over a baseline of 58.5%) when
using the type of affixation of the deverbal head, the
TSG, and WordNet for recreating missing frequen-
cies.
</bodyText>
<sectionHeader confidence="0.999441" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999987541666667">
We have performed a number of different NLP tasks
on the OHSUMED corpus of MEDLINE abstracts
ranging from low-level tokenisation through shal-
low parsing to deep syntactic and semantic analy-
sis. We have used XML as our processing paradigm
and we believe that without the core XML tools the
task would have become extremely hard. Further-
more, we have built fully-automatic pipelines and
have not resorted to hand-coding at any point so that
our output annotations are completely reproducable
and our resources are reusable on new data. Our
approach of building a firm foundation of low-level
tokenisation has proved invaluable for a variety of
higher-level tasks.
The XML-annotated OHSUMED corpus which has
resulted from our project will be useful for a num-
ber of different tasks in the biomedical domain. For
this reason we are developing a web-site from which
many of our resources (including the pipelines
described in this paper) are available: http://
www.ltg.ed.ac.uk/disp/. In addition, we pro-
vide various marked-up and tokenised versions of
OHSUMED, including the output of the parsers de-
scribed here.
</bodyText>
<sectionHeader confidence="0.999187" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999881924731183">
Steven Abney. 1996. Partial parsing via finite-state
cascades. In John Carroll, editor, Proceedings
of Workshop on Robust Parsing at Eighth Sum-
mer School in Logic, Language and Information,
pages 8–15. University of Sussex.
Ted Briscoe and John Carroll. 1993. Generalised
probabilistic LR parsing of natural language (cor-
pora) with unification grammars. Computational
Linguistics, 19(1):25–60.
Ted Briscoe and John Carroll. 1997. Automatic
extraction of subcategorization from corpora. In
Proceedings of the Fifth ACL Conference on Ap-
plied Natural Language Processing, 356–363.
John Carroll and Ted Briscoe. 2001. High preci-
sion extraction of grammatical relations. In Pro-
ceedings of the 7th ACL/SIGPARSE International
Workshop on Parsing Technologies, pages 78–89,
Beijing, China.
Mark Craven and Johan Kumlien. 1999. Construct-
ing biological knowledge bases by extracting in-
formation from text sources. In Proceedings of
the 7th Interntaional Conference on Intelligent
Systems for Molecular Biology (ISMB-99).
David Elworthy. 1994. Does Baum-Welch re-
estimation help taggers? In Proceedings of the
4th ACL conference on Applied Natural Lan-
guage Processing, pages 53–58, Stuttgart, Ger-
many.
Roger Garside. 1987. The CLAWS word-tagging
system. In Roger Garside, Geoffrey Leech, and
Geoffrey Sampson, editors, The Computational
Analysis ofEnglish. Longman, London.
Gerald Gazdar, Ewan Klein, Geoff Pullum, and Ivan
Sag. 1985. Generalized Phrase Structure Gram-
mar. Basil Blackwell, London.
Claire Grover, Colin Matheson, Andrei Mikheev,
and Marc Moens. 2000. LT TTT—a flexible
tokenisation tool. In LREC 2000—Proceedings
of the Second International Conference on Lan-
guage Resources and Evaluation, pages 1147–
1154.
Claire Grover and Alex Lascarides. 2001. XML-
based data preparation for robust deep parsing.
In Proceedings of the Joint EACL-ACL Meeting
(ACL-EACL 2001).
Claire Grover, Mirella Lapata and Alex Lascarides.
2002. A Comparison of Parsing Technologies for
the Biomedical Domain. Submitted to Journal of
Natural Language Engineering.
William Hersh, Chris Buckley, TJ Leone, and David
Hickam. 1994. OHSUMED: an interactive re-
trieval evaluation and new large test collection for
research. In W. Bruce Croft and C. J. van Rijsber-
gen, editors, Proceedings of the 17th Annual In-
ternational Conference on Research and Devel-
opment in Information Retrieval, pages 192–201.
Maria Lapata. 2000. The automatic interpretation
of nominalizations. In Proceedings of the 17th
National Conference on Artificial Intelligence,
pages 716–721, Austin, TX.
Catherine MacLeod, Ralph Grishman, Adam Mey-
ers, Leslie Barrett, and Ruth Reeves. 1998.
NOMLEX: a lexicon of nominalisations. In EU-
RALEX’98, pages 187–194.
Mitchell Marcus, Grace Kim, Mary Ann
Marcinkiewicz, Robert MacIntyre, Ann Bies,
Mark Ferguson, Karen Katz, and Britta Schas-
berger. 1994. The Penn treebank: annotating
predicate argument structure. In ARPA Human
Language Technologies Workshop.
David McKelvie. 2000. XMLPERL 1.7.2. A Rule
Based XML Transformation Language http://
www.cogsci.ed.ac.uk/˜dmck/xmlperl.
Andrei Mikheev. 1997. Automatic rule induction
for unknown word guessing. Computational Lin-
guistics, 23(3):405–423.
George A. Miller and William G. Charles. 1991.
Contextual correlates of semantic similarity.
Language and Cognitive Processes, 6(1):1–28.
Guido Minnen, John Carroll, and Darren Pearce.
2000. Robust, applied morphological generation.
In Proceedings of 1st International Natural Lan-
guage Conference (INLG ’2000).
Ross J. Quinlan. 1993. C4.5: Programs for Ma-
chine Learning. Morgan Kaufman, San Mateo,
CA.
Henry S. Thompson, Richard Tobin, David McK-
elvie, and Chris Brew. 1997. LT XML. Soft-
ware API and toolkit for XML processing. http:
//www.ltg.ed.ac.uk/software/.
UMLS. 2000. Unified Medical Language System
(UMLS) Knowledge Sources. National Library of
Medicine, Bethesda (MD), 11th edition edition.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.738084">
<title confidence="0.995763">XML-Based NLP Tools for Analysing and Annotating Medical Language</title>
<author confidence="0.996255">Claire Grover</author>
<author confidence="0.996255">Ewan Klein</author>
<author confidence="0.996255">Mirella Lapata</author>
<author confidence="0.996255">Alex</author>
<affiliation confidence="0.986851666666667">Division of The University of 2 Buccleuch</affiliation>
<address confidence="0.784144">Edinburgh EH8 9LW,</address>
<email confidence="0.985071">E.Klein,M.Lapata,</email>
<abstract confidence="0.997426411764706">We describe the use of a suite of highly flexible in a project for processing and interpreting text in the medical domain. The main aim of the paper is to demonstrate the central role and NLP have played in the analysis process and to describe the resultant corpus of In addition the we have succeeded in integrating variety of the shelf’ into our pipelines, so that their output is added into the mark-up. We demonstrate the utility of the annotations that result in two ways. First, we investigate how they can be used to improve parse coverage of a hand-crafted grammar that generates logical forms. And second, we investigate how they contribute to automatic lexical semantic acquisition processes.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
</authors>
<title>Partial parsing via finite-state cascades. In</title>
<date>1996</date>
<booktitle>Proceedings of Workshop on Robust Parsing at Eighth Summer School in Logic, Language and Information,</booktitle>
<pages>8--15</pages>
<editor>John Carroll, editor,</editor>
<publisher>University of Sussex.</publisher>
<contexts>
<context position="22094" citStr="Abney, 1996" startWordPosition="3592" endWordPosition="3593">al linguistic data. This method uses Abney’s (1996) Cass chunker which uses the finite-state cascade technique. A finite-state cascade is a sequence of non-recursive levels: phrases at one level are built on phrases at the previous level without containing same level or higher-level phrases. Two levels of particular importance are chunks and simplex clauses. A chunk is the nonrecursive core of intra-clausal constituents extending from the beginning of the constituent to its head, excluding post-head dependents (i.e., NP, VP, PP), whereas a simplex clause is a sequence of nonrecursive clauses (Abney, 1996). Cass recognizes chunks and simplex clauses using a regular expression grammar without attempting to resolve attachment ambiguities. The parser comes with a largescale grammar for English and a built-in tool that extracts predicate-argument tuples out of the parse trees that Cass produces. Thus the tool identifies subjects and objects as well as PPs without however distinguishing arguments from adjuncts. We consider verbs followed by the preposition by and a head noun as instances of verb-subject relations. Our verb-object tuples also include prepositional objects even though these are not ex</context>
</contexts>
<marker>Abney, 1996</marker>
<rawString>Steven Abney. 1996. Partial parsing via finite-state cascades. In John Carroll, editor, Proceedings of Workshop on Robust Parsing at Eighth Summer School in Logic, Language and Information, pages 8–15. University of Sussex.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
</authors>
<title>Generalised probabilistic LR parsing of natural language (corpora) with unification grammars.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="23626" citStr="Briscoe and Carroll (1993" startWordPosition="3841" endWordPosition="3844">entences and POS tagged using ltpos as described in Section 2. The output of this tokenisation is converted to Cass’s input format which is a non-XML file with one word per line and tags separated by tab. We achieve this conversion using xmlperl with a simple rule file. The output of Cass and the grammatical relations processor is a list of each verb-argument pair in the corpus: manage :obj refibrillation respond :subj psoriasis access :to system 4.3 Shallow Parsing with the Tag Sequence Grammar Our second method of acquiring verb grammatical relations uses the statistical parser developed by Briscoe and Carroll (1993, 1997) which is an extension of the ANLT grammar development system which we used for our deep grammatical analysis as reported in Section 3 above. The statistical parser, known as the Tag Sequence Grammar (TSG), uses a hand-crafted grammar where the lexical entries are for POS tags rather than words themselves. Thus it is strings of tags that are parsed rather than strings of words. The statistical part of the system is the parse ranking component where probabilities are associated with transitions in an LR parse table. The grammar does not achieve full-coverage but on the OHSUMED corpus we </context>
</contexts>
<marker>Briscoe, Carroll, 1993</marker>
<rawString>Ted Briscoe and John Carroll. 1993. Generalised probabilistic LR parsing of natural language (corpora) with unification grammars. Computational Linguistics, 19(1):25–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
</authors>
<title>Automatic extraction of subcategorization from corpora.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fifth ACL Conference on Applied Natural Language Processing,</booktitle>
<pages>356--363</pages>
<marker>Briscoe, Carroll, 1997</marker>
<rawString>Ted Briscoe and John Carroll. 1997. Automatic extraction of subcategorization from corpora. In Proceedings of the Fifth ACL Conference on Applied Natural Language Processing, 356–363.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Ted Briscoe</author>
</authors>
<title>High precision extraction of grammatical relations.</title>
<date>2001</date>
<booktitle>In Proceedings of the 7th ACL/SIGPARSE International Workshop on Parsing Technologies,</booktitle>
<pages>78--89</pages>
<location>Beijing, China.</location>
<contexts>
<context position="24682" citStr="Carroll and Briscoe, 2001" startWordPosition="4018" endWordPosition="4021">parse ranking component where probabilities are associated with transitions in an LR parse table. The grammar does not achieve full-coverage but on the OHSUMED corpus we were able to obtain parses for 99.05% of sentences. The number of parses found per sentence ranges from zero into the thousands but the system returns the highest ranked parse according to the statistical ranking method. We do not have an accurate measure of how many of the highest ranked parses are actually correct but even a partially incorrect parse may still yield useful grammatical relations data. In recent developments (Carroll and Briscoe, 2001), the TSG authors have developed an algorithm for mapping TSG parse trees to representations of grammatical relations within the sentence in the following format: These centres are efficiently trapped in proteins at low temperatures (|ncsubj ||trap ||centre ||obj|) (|iobj ||in ||trap ||protein|) (|detmod ||centre ||These|) (|mod ||trap ||efficiently|) (|aux ||trap ||be|) (|ncmod ||temperature ||low|) (|ncmod ||at ||trap ||temperature|) This format can easily be mapped to the same format as described in Section 4.2 to give counts of the number of times a particular verb occurs with a particular</context>
</contexts>
<marker>Carroll, Briscoe, 2001</marker>
<rawString>John Carroll and Ted Briscoe. 2001. High precision extraction of grammatical relations. In Proceedings of the 7th ACL/SIGPARSE International Workshop on Parsing Technologies, pages 78–89, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Craven</author>
<author>Johan Kumlien</author>
</authors>
<title>Constructing biological knowledge bases by extracting information from text sources.</title>
<date>1999</date>
<booktitle>In Proceedings of the 7th Interntaional Conference on Intelligent Systems for Molecular Biology (ISMB-99).</booktitle>
<contexts>
<context position="2328" citStr="Craven and Kumlien (1999)" startWordPosition="370" endWordPosition="373">e when confronted with character strings that represent specialised technical vocabulary. Once firm foundations are laid then one can achieve better performance from e.g. chunkers and parsers than might otherwise be the case. We show how well-founded tools, especially XMLbased ones, can enable a variety of NLP components to be bundled together in different ways to achieve different types of analysis. Note that in fields such as information extraction (IE) it is common to use statistical text classification methods for data analysis. Our more linguistic approach may be of assistence in IE: see Craven and Kumlien (1999) for discussion of methods for IE from MEDLINE. Our processing paradigm is XML-based. As a mark-up language for NLP tasks, XML is expressive and flexible yet constrainable. Furthermore, there exist a wide range of XML-based tools for NLP applications which lend themselves to a modular, pipelined approach to processing whereby linguistic knowledge is computed and added as XML annotations in an incremental fashion. In processing MEDLINE abstracts we have built a number of such pipelines using as key components the programs distributed with the LT TTT and LT XML toolsets (Grover et al., 2000; Tho</context>
</contexts>
<marker>Craven, Kumlien, 1999</marker>
<rawString>Mark Craven and Johan Kumlien. 1999. Constructing biological knowledge bases by extracting information from text sources. In Proceedings of the 7th Interntaional Conference on Intelligent Systems for Molecular Biology (ISMB-99).</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Elworthy</author>
</authors>
<title>Does Baum-Welch reestimation help taggers?</title>
<date>1994</date>
<booktitle>In Proceedings of the 4th ACL conference on Applied Natural Language Processing,</booktitle>
<pages>53--58</pages>
<location>Stuttgart, Germany.</location>
<marker>Elworthy, 1994</marker>
<rawString>David Elworthy. 1994. Does Baum-Welch reestimation help taggers? In Proceedings of the 4th ACL conference on Applied Natural Language Processing, pages 53–58, Stuttgart, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Garside</author>
</authors>
<title>The CLAWS word-tagging system.</title>
<date>1987</date>
<booktitle>The Computational Analysis ofEnglish. Longman,</booktitle>
<editor>In Roger Garside, Geoffrey Leech, and Geoffrey Sampson, editors,</editor>
<location>London.</location>
<contexts>
<context position="25498" citStr="Garside, 1987" startWordPosition="4145" endWordPosition="4146">n proteins at low temperatures (|ncsubj ||trap ||centre ||obj|) (|iobj ||in ||trap ||protein|) (|detmod ||centre ||These|) (|mod ||trap ||efficiently|) (|aux ||trap ||be|) (|ncmod ||temperature ||low|) (|ncmod ||at ||trap ||temperature|) This format can easily be mapped to the same format as described in Section 4.2 to give counts of the number of times a particular verb occurs with a particular noun as its subject, object or prepositional object. As explained above, the TSG parses sequences of tags, however it requires a different tagset from that produced by ltpos, namely the CLAWS2 tagset (Garside, 1987). To prepare the corpus for parsing with the TSG we therefore tagged it with Elworthy’s (1994) tagger and since this is a non-XML tool we used xmlperl to invoke it and to incorporate its results back into the XML mark-up. Sentences were then prepared as input to the TSG—this involved using xmlperl to replace words by their lemmas and to convert to ANLT input format: These DD2 centre NN2 be VBR efficiently RR trap VVN in II protein NN2 at II low JJ temperature NN2 The lemmas are needed in order that the TSG outputs them rather than inflected words in the grammatical relations output shown above</context>
</contexts>
<marker>Garside, 1987</marker>
<rawString>Roger Garside. 1987. The CLAWS word-tagging system. In Roger Garside, Geoffrey Leech, and Geoffrey Sampson, editors, The Computational Analysis ofEnglish. Longman, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Gazdar</author>
<author>Ewan Klein</author>
<author>Geoff Pullum</author>
<author>Ivan Sag</author>
</authors>
<date>1985</date>
<booktitle>Generalized Phrase Structure Grammar.</booktitle>
<publisher>Basil Blackwell,</publisher>
<location>London.</location>
<contexts>
<context position="12830" citStr="Gazdar et al., 1985" startWordPosition="2048" endWordPosition="2051">f our work with OHSUMED, we have been attempting to improve the coverage of a handcrafted, linguistically motivated grammar which provides full-syntactic analysis paired with logical forms. The grammar and parsing system we use is the wide-coverage grammar, morphological analyser and lexicon provided by the Alvey Natural Language Tools (ANLT) system (Carroll et al. 1991, Grover et al. 1993). Our first aim was to increase coverage up to a reasonable level so that parse ranking techniques could then be applied. The ANLT grammar is a feature-based unification grammar based on the GPSG formalism (Gazdar et al., 1985). In this framework, lexical entries carry a significant amount of information including subcategorisation information. Thus the practical parse success of the grammar is significantly dependent on the quality of the lexicon. The ANLT grammar is distributed with a large lexicon and, while this provides a core of commonly-occurring lexical entries, there remains a significant problem of inadequate lexical coverage. If we try to parse OHSUMED sentences using the ANLT lexicon and no other resources, we achieve very poor results (2% coverage) because most of the medical domain words are simply not</context>
</contexts>
<marker>Gazdar, Klein, Pullum, Sag, 1985</marker>
<rawString>Gerald Gazdar, Ewan Klein, Geoff Pullum, and Ivan Sag. 1985. Generalized Phrase Structure Grammar. Basil Blackwell, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Grover</author>
<author>Colin Matheson</author>
<author>Andrei Mikheev</author>
<author>Marc Moens</author>
</authors>
<title>LT TTT—a flexible tokenisation tool.</title>
<date>2000</date>
<booktitle>In LREC 2000—Proceedings of the Second International Conference on Language Resources and Evaluation,</booktitle>
<pages>1147--1154</pages>
<contexts>
<context position="2923" citStr="Grover et al., 2000" startWordPosition="467" endWordPosition="470">raven and Kumlien (1999) for discussion of methods for IE from MEDLINE. Our processing paradigm is XML-based. As a mark-up language for NLP tasks, XML is expressive and flexible yet constrainable. Furthermore, there exist a wide range of XML-based tools for NLP applications which lend themselves to a modular, pipelined approach to processing whereby linguistic knowledge is computed and added as XML annotations in an incremental fashion. In processing MEDLINE abstracts we have built a number of such pipelines using as key components the programs distributed with the LT TTT and LT XML toolsets (Grover et al., 2000; Thompson et al., 1997). We have also successfully integrated non-XML publicdomain tools into our pipelines and incorporated their output into the XML mark-up using the LT XML program xmlperl (McKelvie, 2000). In Section 2 we describe our use of XML-based tokenisation tools and techniques and in Sections 3 and 4 we describe two different approaches to analysing MEDLINE data which are built on top of the tokenisation. The first approach uses a handcoded grammar to give complete syntactic and semantic analyses of sentences. The second approach performs a shallower statistically-based analysis w</context>
</contexts>
<marker>Grover, Matheson, Mikheev, Moens, 2000</marker>
<rawString>Claire Grover, Colin Matheson, Andrei Mikheev, and Marc Moens. 2000. LT TTT—a flexible tokenisation tool. In LREC 2000—Proceedings of the Second International Conference on Language Resources and Evaluation, pages 1147– 1154.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Grover</author>
<author>Alex Lascarides</author>
</authors>
<title>XMLbased data preparation for robust deep parsing.</title>
<date>2001</date>
<booktitle>In Proceedings of the Joint EACL-ACL Meeting (ACL-EACL</booktitle>
<contexts>
<context position="16105" citStr="Grover and Lascarides (2001)" startWordPosition="2601" endWordPosition="2605">ermore, monitoring is present in the lexicon but as a verb and not as a noun. For both these words, ordinary lexical look-up fails and the entries for the tags have to be used instead. Note that the case of monitoring would be problematic for a strategy where tagging is used only in case lexical look-up fails, since here it is incomplete rather than failed. The implementation of our word tag pair look-up method is specific to the ANLT system and uses its morphological analysis component to treat tags as a novel kind of affix. Space considerations preclude discussion of this topic here but see Grover and Lascarides (2001) for further details. Another impediment to parse coverage is the prevalence of technical expressions and formulae in biomedical and other technical language. For example, the following sentence has a straightforward overall syntactic structure but the ANLT grammar does not contain specialist rules for handling expressions such as 5.0+/-0.4 grams tension and thus the parse would fail. Control tissues displayed a reproducible response to bethanechol stimulation at different calcium concentrations with an ED50 of 0.4 mM calcium and a peak response of 5.0+/-0.4 grams tension. Our response to issu</context>
</contexts>
<marker>Grover, Lascarides, 2001</marker>
<rawString>Claire Grover and Alex Lascarides. 2001. XMLbased data preparation for robust deep parsing. In Proceedings of the Joint EACL-ACL Meeting (ACL-EACL 2001).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Grover</author>
<author>Mirella Lapata</author>
<author>Alex Lascarides</author>
</authors>
<title>A Comparison of Parsing Technologies for the Biomedical Domain. Submitted to</title>
<date>2002</date>
<journal>Journal of Natural Language Engineering.</journal>
<contexts>
<context position="29702" citStr="Grover et al. (2002)" startWordPosition="4807" endWordPosition="4810">coded as words or POS-tags), the number of times a modifier was attested as an argument of the verb corresponding to the nominalised head, and the nominalisation affix of the deverbal head (e.g., -ation, -ment). In the face of sparse data, linguistic resources such as WordNet (Miller and Charles, 1991) and UMLS were used to recreate distributional evidence absent from our corpus. We obtained several different classification models as a result of using different marked-up versions of the corpus, different parsers, and different linguistic resources. Full details of the results are described in Grover et al. (2002); we only have space for a brief summary here. Our best results achieved an accuracy of 73.6% (over a baseline of 58.5%) when using the type of affixation of the deverbal head, the TSG, and WordNet for recreating missing frequencies. 5 Conclusions We have performed a number of different NLP tasks on the OHSUMED corpus of MEDLINE abstracts ranging from low-level tokenisation through shallow parsing to deep syntactic and semantic analysis. We have used XML as our processing paradigm and we believe that without the core XML tools the task would have become extremely hard. Furthermore, we have bui</context>
</contexts>
<marker>Grover, Lapata, Lascarides, 2002</marker>
<rawString>Claire Grover, Mirella Lapata and Alex Lascarides. 2002. A Comparison of Parsing Technologies for the Biomedical Domain. Submitted to Journal of Natural Language Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Hersh</author>
<author>Chris Buckley</author>
<author>TJ Leone</author>
<author>David Hickam</author>
</authors>
<title>OHSUMED: an interactive retrieval evaluation and new large test collection for research.</title>
<date>1994</date>
<booktitle>Proceedings of the 17th Annual International Conference on Research and Development in Information Retrieval,</booktitle>
<pages>192--201</pages>
<editor>In W. Bruce Croft and C. J. van Rijsbergen, editors,</editor>
<marker>Hersh, Buckley, Leone, Hickam, 1994</marker>
<rawString>William Hersh, Chris Buckley, TJ Leone, and David Hickam. 1994. OHSUMED: an interactive retrieval evaluation and new large test collection for research. In W. Bruce Croft and C. J. van Rijsbergen, editors, Proceedings of the 17th Annual International Conference on Research and Development in Information Retrieval, pages 192–201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Lapata</author>
</authors>
<title>The automatic interpretation of nominalizations.</title>
<date>2000</date>
<booktitle>In Proceedings of the 17th National Conference on Artificial Intelligence,</booktitle>
<pages>716--721</pages>
<location>Austin, TX.</location>
<contexts>
<context position="21449" citStr="Lapata (2000)" startWordPosition="3490" endWordPosition="3491">fically, for each verb, we need counts of the frequency with which it occurs with each noun in each of its argument slots. Ultimately, in fact, in view of the sparse data problem, we need to back off from specific noun instances to noun classes (see Section 4.4). The current state-of-the-art in NLP provides a number of routes to acquiring grammatical relations information about verbs, and for our experiment we chose two methods in order to be able to compare the techniques and assess their utility. 4.2 Chunking with Cass Our first method of acquiring verb grammatical relations is that used by Lapata (2000) for a similar task on more general linguistic data. This method uses Abney’s (1996) Cass chunker which uses the finite-state cascade technique. A finite-state cascade is a sequence of non-recursive levels: phrases at one level are built on phrases at the previous level without containing same level or higher-level phrases. Two levels of particular importance are chunks and simplex clauses. A chunk is the nonrecursive core of intra-clausal constituents extending from the beginning of the constituent to its head, excluding post-head dependents (i.e., NP, VP, PP), whereas a simplex clause is a s</context>
</contexts>
<marker>Lapata, 2000</marker>
<rawString>Maria Lapata. 2000. The automatic interpretation of nominalizations. In Proceedings of the 17th National Conference on Artificial Intelligence, pages 716–721, Austin, TX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catherine MacLeod</author>
<author>Ralph Grishman</author>
<author>Adam Meyers</author>
<author>Leslie Barrett</author>
<author>Ruth Reeves</author>
</authors>
<title>NOMLEX: a lexicon of nominalisations.</title>
<date>1998</date>
<booktitle>In EURALEX’98,</booktitle>
<pages>187--194</pages>
<contexts>
<context position="27279" citStr="MacLeod et al., 1998" startWordPosition="4446" endWordPosition="4449">h information about their verbal stem to give nominalisation-verb equivalences and (b) to mark up compounds in order to collect samples of two-word compounds headed by deverbal nominalisations. For the first task we combined further use of the lemmatiser with the use of lexical resources. In a first pass we used the morpha lemmatiser to find the verbal stem for -ing nominalisations such as screening and then we looked up the remaining nouns in a nominalisation lexicon which we created by combining the nominalisation list which is provided by UMLS (2000) with the NOMLEX nominalisation lexicon (MacLeod et al., 1998) As a result of these stages, most of the deverbal nominalisations can be marked up with a VSTEM attribute whose value is the verbal stem: &lt;W P=’NN’ LM=’reaction’ VSTEM=’react’&gt;reaction&lt;/W&gt; &lt;W P=’NN’ LM=’growth’ VSTEM=’grow’&gt;growth&lt;/W&gt; &lt;W P=’NN’ LM=’control’ VSTEM=’control’&gt;control&lt;/W&gt; &lt;W P=’NN’ LM=’coding’ VSTEM=’code’&gt;coding&lt;/W&gt; To mark up compounds we developed an fsgmatch grammar for compounds of all lengths and kinds and we used this to process a subset of the first two years of the corpus. We interpret nominalisations in the biomedical domain using a machine learning approach which combi</context>
</contexts>
<marker>MacLeod, Grishman, Meyers, Barrett, Reeves, 1998</marker>
<rawString>Catherine MacLeod, Ralph Grishman, Adam Meyers, Leslie Barrett, and Ruth Reeves. 1998. NOMLEX: a lexicon of nominalisations. In EURALEX’98, pages 187–194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell Marcus</author>
<author>Grace Kim</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Robert MacIntyre</author>
<author>Ann Bies</author>
<author>Mark Ferguson</author>
<author>Karen Katz</author>
<author>Britta Schasberger</author>
</authors>
<title>The Penn treebank: annotating predicate argument structure.</title>
<date>1994</date>
<booktitle>In ARPA Human Language Technologies Workshop.</booktitle>
<contexts>
<context position="10586" citStr="Marcus et al., 1994" startWordPosition="1656" endWordPosition="1659">pressiveness it constitutes a subset of XPath except that it also allows regular expressions over text content. Future plans include modifying out tools to allow for the use of XPath as a query language. up as W elements; the -sent option indicates that sentences should be wrapped as SENT elements; the -tag option is an instruction to output POS tags and the -pos attr option indicates that POS tags should be encoded as the value of the attribute P on W elements. The final resource.xml names the resource file that ltpos is to use. Note that the tagset used by ltpos is the Penn Treebank tagset (Marcus et al., 1994). 1. ohs2xml.perl \ 2. |fsgmatch -q &amp;quot;.*/TEXT&amp;quot; ohsumed.gr \ 3. |fsgmatch -q &amp;quot;.*/ABSTRACT&amp;quot; pretok.gr \ 4. |fsgmatch &amp;quot;.*/ABSTRACT&amp;quot; tok.gr \ 5. |sgdelmarkup -q &amp;quot;.*/S&amp;quot; \ 6. |ltpos -q &amp;quot;.*/RECORD&amp;quot; -qs &amp;quot;.*/ABSTRACT&amp;quot; \ -qw &amp;quot;.*/W&amp;quot; -sent SENT \ -tag -pos_attr P resource.xml \ 7. |xmlperl lemma.rule Figure 3: Basic Tokenisation Pipeline Up to this point, each module in the pipeline has used one of the LT TTT or LT XML programs which are sensitive to XML structure. There are, however, a large number of tools available from the NLP community which could profitably be used but which are not XML-aware. We hav</context>
</contexts>
<marker>Marcus, Kim, Marcinkiewicz, MacIntyre, Bies, Ferguson, Katz, Schasberger, 1994</marker>
<rawString>Mitchell Marcus, Grace Kim, Mary Ann Marcinkiewicz, Robert MacIntyre, Ann Bies, Mark Ferguson, Karen Katz, and Britta Schasberger. 1994. The Penn treebank: annotating predicate argument structure. In ARPA Human Language Technologies Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David McKelvie</author>
</authors>
<date>2000</date>
<booktitle>XMLPERL 1.7.2. A Rule Based XML Transformation Language http:// www.cogsci.ed.ac.uk/˜dmck/xmlperl.</booktitle>
<contexts>
<context position="3132" citStr="McKelvie, 2000" startWordPosition="501" endWordPosition="502">re exist a wide range of XML-based tools for NLP applications which lend themselves to a modular, pipelined approach to processing whereby linguistic knowledge is computed and added as XML annotations in an incremental fashion. In processing MEDLINE abstracts we have built a number of such pipelines using as key components the programs distributed with the LT TTT and LT XML toolsets (Grover et al., 2000; Thompson et al., 1997). We have also successfully integrated non-XML publicdomain tools into our pipelines and incorporated their output into the XML mark-up using the LT XML program xmlperl (McKelvie, 2000). In Section 2 we describe our use of XML-based tokenisation tools and techniques and in Sections 3 and 4 we describe two different approaches to analysing MEDLINE data which are built on top of the tokenisation. The first approach uses a handcoded grammar to give complete syntactic and semantic analyses of sentences. The second approach performs a shallower statistically-based analysis which yields ‘grammatical relations’ rather than full logical forms. This information about grammatical relations is used in a statistically-trained model which disambiguates the semantic relations in noun comp</context>
</contexts>
<marker>McKelvie, 2000</marker>
<rawString>David McKelvie. 2000. XMLPERL 1.7.2. A Rule Based XML Transformation Language http:// www.cogsci.ed.ac.uk/˜dmck/xmlperl.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrei Mikheev</author>
</authors>
<title>Automatic rule induction for unknown word guessing.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="9475" citStr="Mikheev, 1997" startWordPosition="1464" endWordPosition="1465">fields of an OHSUMED entry and convert them into XML mark-up: each abstract is put inside a RECORD element which contains sub-structure reflecting e.g. author, title, MESH code and the abstract itself. From this point on, all processing is directed at the ABSTRACT elements through the query “.*/ABSTRACT”1. Steps 3 and 4 make calls to fsgmatch to identify S and W (word) elements as described above and after this point, in step 5, the S mark-up is discarded (using the LT TTT program sgdelmarkup) since it has now served its purpose. Step 6 contains a call to the other main LT TTT program, ltpos (Mikheev, 1997), which performs both sentence identification and POS tagging. The subquery (-qs) option picks out ABSTRACTs as the elements within RECORDs (-q option) that are to be processed; the -qw option indicates that the input has already been segmented into words marked 1The query language that the LT TTT and LT XML tools use is a specialised XML query language which pinpoints the part of the XML tree-structure that is to be processed at that point. This query language pre-dates XPath and in expressiveness it constitutes a subset of XPath except that it also allows regular expressions over text conten</context>
</contexts>
<marker>Mikheev, 1997</marker>
<rawString>Andrei Mikheev. 1997. Automatic rule induction for unknown word guessing. Computational Linguistics, 23(3):405–423.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>William G Charles</author>
</authors>
<title>Contextual correlates of semantic similarity.</title>
<date>1991</date>
<booktitle>Language and Cognitive Processes,</booktitle>
<pages>6--1</pages>
<contexts>
<context position="29385" citStr="Miller and Charles, 1991" startWordPosition="4759" endWordPosition="4762">that were wrongly identified as nominalisations. We treated the interpretation of nominalisations as a classification task and experimented with different features using the C4.5 decision tree learner (Quinlan, 1993). Some of the features we took into account were the context surrounding the candidate nominalisations (encoded as words or POS-tags), the number of times a modifier was attested as an argument of the verb corresponding to the nominalised head, and the nominalisation affix of the deverbal head (e.g., -ation, -ment). In the face of sparse data, linguistic resources such as WordNet (Miller and Charles, 1991) and UMLS were used to recreate distributional evidence absent from our corpus. We obtained several different classification models as a result of using different marked-up versions of the corpus, different parsers, and different linguistic resources. Full details of the results are described in Grover et al. (2002); we only have space for a brief summary here. Our best results achieved an accuracy of 73.6% (over a baseline of 58.5%) when using the type of affixation of the deverbal head, the TSG, and WordNet for recreating missing frequencies. 5 Conclusions We have performed a number of diffe</context>
</contexts>
<marker>Miller, Charles, 1991</marker>
<rawString>George A. Miller and William G. Charles. 1991. Contextual correlates of semantic similarity. Language and Cognitive Processes, 6(1):1–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guido Minnen</author>
<author>John Carroll</author>
<author>Darren Pearce</author>
</authors>
<title>Robust, applied morphological generation.</title>
<date>2000</date>
<booktitle>In Proceedings of 1st International Natural Language Conference (INLG</booktitle>
<marker>Minnen, Carroll, Pearce, 2000</marker>
<rawString>Guido Minnen, John Carroll, and Darren Pearce. 2000. Robust, applied morphological generation. In Proceedings of 1st International Natural Language Conference (INLG ’2000).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ross J Quinlan</author>
</authors>
<title>C4.5: Programs for Machine Learning.</title>
<date>1993</date>
<publisher>Morgan</publisher>
<location>Kaufman, San Mateo, CA.</location>
<contexts>
<context position="28976" citStr="Quinlan, 1993" startWordPosition="4695" endWordPosition="4696">ST (seizure protection), FOR (nonstress test), IN (vessel obstruction), BY (aerosol administration), OF (water deprivation), ON (knee operation), and TO (treatment response). We also included the categories NA (non applicable) for nominalisations with relations other than the ones predicted by the underlying verb’s subcategorisation frame (e.g., death stroke) and NV (non deverbal) for compounds that were wrongly identified as nominalisations. We treated the interpretation of nominalisations as a classification task and experimented with different features using the C4.5 decision tree learner (Quinlan, 1993). Some of the features we took into account were the context surrounding the candidate nominalisations (encoded as words or POS-tags), the number of times a modifier was attested as an argument of the verb corresponding to the nominalised head, and the nominalisation affix of the deverbal head (e.g., -ation, -ment). In the face of sparse data, linguistic resources such as WordNet (Miller and Charles, 1991) and UMLS were used to recreate distributional evidence absent from our corpus. We obtained several different classification models as a result of using different marked-up versions of the co</context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>Ross J. Quinlan. 1993. C4.5: Programs for Machine Learning. Morgan Kaufman, San Mateo, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henry S Thompson</author>
<author>Richard Tobin</author>
<author>David McKelvie</author>
<author>Chris Brew</author>
</authors>
<date>1997</date>
<booktitle>LT XML. Software API and toolkit for XML processing. http:</booktitle>
<pages>//www.ltg.ed.ac.uk/software/.</pages>
<contexts>
<context position="2947" citStr="Thompson et al., 1997" startWordPosition="471" endWordPosition="474">99) for discussion of methods for IE from MEDLINE. Our processing paradigm is XML-based. As a mark-up language for NLP tasks, XML is expressive and flexible yet constrainable. Furthermore, there exist a wide range of XML-based tools for NLP applications which lend themselves to a modular, pipelined approach to processing whereby linguistic knowledge is computed and added as XML annotations in an incremental fashion. In processing MEDLINE abstracts we have built a number of such pipelines using as key components the programs distributed with the LT TTT and LT XML toolsets (Grover et al., 2000; Thompson et al., 1997). We have also successfully integrated non-XML publicdomain tools into our pipelines and incorporated their output into the XML mark-up using the LT XML program xmlperl (McKelvie, 2000). In Section 2 we describe our use of XML-based tokenisation tools and techniques and in Sections 3 and 4 we describe two different approaches to analysing MEDLINE data which are built on top of the tokenisation. The first approach uses a handcoded grammar to give complete syntactic and semantic analyses of sentences. The second approach performs a shallower statistically-based analysis which yields ‘grammatical</context>
</contexts>
<marker>Thompson, Tobin, McKelvie, Brew, 1997</marker>
<rawString>Henry S. Thompson, Richard Tobin, David McKelvie, and Chris Brew. 1997. LT XML. Software API and toolkit for XML processing. http: //www.ltg.ed.ac.uk/software/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>UMLS</author>
</authors>
<title>Unified Medical Language System (UMLS) Knowledge Sources. National Library of Medicine,</title>
<date>2000</date>
<location>Bethesda</location>
<note>(MD), 11th edition edition.</note>
<contexts>
<context position="27217" citStr="UMLS (2000)" startWordPosition="4438" endWordPosition="4439">igure 3, (a) to mark up deverbal nominalisations with information about their verbal stem to give nominalisation-verb equivalences and (b) to mark up compounds in order to collect samples of two-word compounds headed by deverbal nominalisations. For the first task we combined further use of the lemmatiser with the use of lexical resources. In a first pass we used the morpha lemmatiser to find the verbal stem for -ing nominalisations such as screening and then we looked up the remaining nouns in a nominalisation lexicon which we created by combining the nominalisation list which is provided by UMLS (2000) with the NOMLEX nominalisation lexicon (MacLeod et al., 1998) As a result of these stages, most of the deverbal nominalisations can be marked up with a VSTEM attribute whose value is the verbal stem: &lt;W P=’NN’ LM=’reaction’ VSTEM=’react’&gt;reaction&lt;/W&gt; &lt;W P=’NN’ LM=’growth’ VSTEM=’grow’&gt;growth&lt;/W&gt; &lt;W P=’NN’ LM=’control’ VSTEM=’control’&gt;control&lt;/W&gt; &lt;W P=’NN’ LM=’coding’ VSTEM=’code’&gt;coding&lt;/W&gt; To mark up compounds we developed an fsgmatch grammar for compounds of all lengths and kinds and we used this to process a subset of the first two years of the corpus. We interpret nominalisations in the b</context>
</contexts>
<marker>UMLS, 2000</marker>
<rawString>UMLS. 2000. Unified Medical Language System (UMLS) Knowledge Sources. National Library of Medicine, Bethesda (MD), 11th edition edition.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>