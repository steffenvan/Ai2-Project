<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.270882">
<title confidence="0.886899">
Visualization, Search, and Error Analysis for Coreference Annotations
</title>
<author confidence="0.987494">
Markus G¨artner Anders Bj¨orkelund Gregor Thiele Wolfgang Seeker Jonas Kuhn
</author>
<affiliation confidence="0.995116">
Institute for Natural Language Processing
University of Stuttgart
</affiliation>
<email confidence="0.99154">
{thielegr,seeker,gaertnms,anders,kuhn}@ims.uni-stuttgart.de
</email>
<sectionHeader confidence="0.997288" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999955466666667">
We present the ICARUS Coreference Ex-
plorer, an interactive tool to browse and
search coreference-annotated data. It can
display coreference annotations as a tree,
as an entity grid, or in a standard text-
based display mode, and lets the user
switch freely between the different modes.
The tool can compare two different an-
notations on the same document, allow-
ing system developers to evaluate errors in
automatic system predictions. It features
a flexible search engine, which enables
the user to graphically construct search
queries over sets of documents annotated
with coreference.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999923367346939">
Coreference resolution is the task of automatically
grouping references to the same real-world entity
in a document into a set. It is an active topic in cur-
rent NLP research and has received considerable
attention in recent years, including the 2011 and
2012 CoNLL shared tasks (Pradhan et al., 2011;
Pradhan et al., 2012).
Coreference relations are commonly repre-
sented by sets of mentions, where all mentions
in one set (or coreference cluster) are considered
coreferent. This type of representation does not
support any internal structure within the clusters.
However, many automatic coreference resolvers
establish links between pairs of mentions which
are subsequently transformed to a cluster by tak-
ing the transitive closure over all links, i.e., placing
all mentions that are directly or transitively classi-
fied as coreferent in one cluster. This is particu-
larly the case for several state-of-the-art resolvers
(Fernandes et al., 2012; Durrett and Klein, 2013;
Bj¨orkelund and Kuhn, 2014). These pairwise de-
cisions, which give rise to a clustering, can be ex-
ploited for detailed error analysis and more fine-
grained search queries on data automatically an-
notated for coreference.
We present the ICARUS Coreference Explorer
(ICE), an interactive tool to browse and search
coreference-annotated data. In addition to stan-
dard text-based display modes, ICE features two
other display modes: an entity-grid (Barzilay and
Lapata, 2008) and a tree view, which makes use
of the internal pairwise links within the clusters.
ICE builds on ICARUS (G¨artner et al., 2013), a
platform for search and exploration of dependency
treebanks.1
ICE is geared towards two (typically) distinct
users: The NLP developer who designs corefer-
ence resolution systems can inspect the predic-
tions of his system using the three different dis-
play modes. Moreover, ICE can compare the pre-
dictions of a system to a gold standard annotation,
enabling the developer to inspect system errors in-
teractively. The second potential user is the cor-
pus linguist, who might be interested in brows-
ing or searching a document, or a (large) set of
documents for certain coreference relations. The
built-in search engine of ICARUS now also allows
search queries over sets of documents in order to
meet the needs of this type of user.
</bodyText>
<sectionHeader confidence="0.955088" genericHeader="method">
2 Data Representation
</sectionHeader>
<bodyText confidence="0.999264857142857">
ICE reads the formats used in the 2011 and 2012
CoNLL shared tasks as well as the SemEval 2010
format (Recasens et al., 2010).2 Since these for-
mats cannot accommodate pairwise links, an aux-
iliary file with standoff annotation can be pro-
vided, which we call allocation. An allocation is a
list of pairwise links between mentions. Multiple
</bodyText>
<footnote confidence="0.999798">
1ICE is written in Java and is therefore platform indepen-
dent. It is open source (under GNU GPL) and we provide
both sources and binaries for download on http://www.
ims.uni-stuttgart.de/data/icarus.html
2These two formats are very similar tabular formats, but
differ slightly in the column representations.
</footnote>
<page confidence="0.995144">
7
</page>
<bodyText confidence="0.986293027777778">
Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 7–12,
Baltimore, Maryland USA, June 23-24, 2014. c�2014 Association for Computational Linguistics
allocations can be associated with a single docu-
ment and the user can select one of these for dis-
play or search queries. An allocation can also in-
clude properties on mentions and links. The set
of possible properties is not constrained, and the
user can freely specify properties as a list of key-
value pairs. Properties on mentions may include,
e.g., grammatical gender or number, or informa-
tion status labels. Additionally, a special property
that indicates the head word of a mention can be
provided in an allocation. The head property en-
ables the user to access head words of mentions
for display or search queries.
The motivation for keeping the allocation file
separate from the CoNLL or SemEval files is two-
fold: First, it allows ICE to work without hav-
ing to provide an allocation file, thereby making it
easy to use with the established formats for coref-
erence. The user is still able to introduce addi-
tional structure by the use of the allocation file.
Second, multiple allocation files allow the user to
switch between different allocations while explor-
ing a set of documents. Moreover, as we will see
in Section 3.3, ICE can also compare two different
allocations in order to highlight the differences.
In addition to user-specified allocations, ICE
will always by default provide an internal structure
for the clusters, in which the correct antecedent
of every mention is the closest coreferent mention
with respect to the linear order of the document
(this is equivalent to the training instance creation
heuristic proposed by Soon et al. (2001)). There-
fore, the user is not required to define an allocation
on their own.
</bodyText>
<sectionHeader confidence="0.997783" genericHeader="method">
3 Display Modes
</sectionHeader>
<bodyText confidence="0.999967538461538">
In this section we describe the entity grid and tree
display modes by means of screenshots. ICE addi-
tionally includes a standard text-based view, sim-
ilar to other coreference visualization tools. The
example document is taken from the CoNLL 2012
development set (Pradhan et al., 2012) and we
use two allocations: (1) the predictions output by
Bj¨orkelund and Kuhn (2014) system (predicted)
and (2) a gold allocation that was obtained by
running the same system in a restricted setting,
where only links between coreferent mentions are
allowed (gold). The complete document can be
seen in the lower half of Figure 1.
</bodyText>
<subsectionHeader confidence="0.999435">
3.1 Entity grid
</subsectionHeader>
<bodyText confidence="0.999922476190476">
Barzilay and Lapata (2008) introduce the entity
grid, a tabular view of entities in a document.
Specifically, rows of the grid correspond to sen-
tences, and columns to entities. The cells of the ta-
ble are used to indicate that an entity is mentioned
in the corresponding sentence. Entity grids pro-
vide a compact view on the distribution of men-
tions in a document and allow the user to see how
the description of an entity changes from mention
to mention.
Figure 1 shows ICE’s entity-grid view for the
example document using the predicted allocation.
When clicking on a cell in the entity grid the im-
mediate textual context of the cell is shown in the
lower pane. In Figure 1, the cell with the blue
background has been clicked, which corresponds
to the two mentions firms from Taiwan and they.
These mentions are thus highlighted in the lower
pane. The user can also right-click on a cell and
jump straight to the tree view, centered around the
same mentions.
</bodyText>
<subsectionHeader confidence="0.999814">
3.2 Label Patterns
</subsectionHeader>
<bodyText confidence="0.999960259259259">
The information that is displayed in the cells of
the entity grid (and also on the nodes in the tree
view, see Section 3.3) can be fully customized by
the user. The customization is achieved by defin-
ing label patterns. A label pattern is a string that
specifies the format according to which a mention
will be displayed. The pattern can extract infor-
mation on a mention according to three axes: (1)
at the token- level for the full mention, extracting,
e.g., the sequence of surface forms or the part-of-
speech tags of a mention; (2) at the mention- level,
extracting an arbitrary property of a mention as de-
fined in an allocation; (3) token-level information
from the head word of a mention.
Label patterns can be defined interactively
while displaying a document and the three axes are
referenced by dedicated operators. For instance,
the label pattern $form$ extracts the full surface
form of a mention, whereas #form# only extracts
the surface form of the head word of a mention.
All properties defined by the user in the allocation
(see Section 2) are accessible via label patterns.
For example, the allocations we use for Fig-
ure 1 include a number of properties on the
mentions, most of which are internally com-
puted by the coreference system: The TYPE of
a mention, which can take any of the values
</bodyText>
<page confidence="0.995615">
8
</page>
<figureCaption confidence="0.999642">
Figure 1: Entity grid over the predicted clustering in the example document.
</figureCaption>
<bodyText confidence="0.999736541666667">
{Name, Common, Pronoun} and is inferred from
the part- of-speech tags in the CoNLL file; The
grammatical NUMBER of a mention, which is as-
signed based on the number and gender data com-
piled by Bergsma and Lin (2006) and can take
the values {Sin, Plu, Unknown}. The label pat-
tern for displaying the number property associated
with a mention would be %Number%.
The label pattern used in Figure 1 is defined
as (&amp;quot;$form$&amp;quot; - %Type% - %Number%). This pat-
tern accesses the full surface form of the mentions
($form$), as well as the TYPE (%Type%) and gram-
matical NUMBER (%Number%) properties defined
in the allocation file.
Custom properties and label patterns can be
used for example to display the entity grid in the
form proposed by Barzilay and Lapata (2008): In
the allocation, we assign a coarse-grained gram-
matical function property (denoted GF) to every
mention, where each mention is tagged as either
subject, object, or other (denoted S, O, X, respec-
tively).3 The label pattern %GF% then displays the
grammatical function of each mention in the entity
grid, as shown in Figure 2.
</bodyText>
<subsectionHeader confidence="0.997146">
3.3 Tree view
</subsectionHeader>
<bodyText confidence="0.960919727272727">
Pairwise links output by an automatic coreference
system can be treated as arcs in a directed graph.
Linking the first mention of each cluster to an ar-
tificial root node creates a tree structure that en-
codes the entire clustering in a document. This
representation has been used in coreference re-
3The grammatical function was assigned by converting
the phrase-structure trees in the CoNLL file (which lack
grammatical function information) to Stanford dependencies
(de Marneffe and Manning, 2008), and then extracting the
grammatical function from the head word in each mention.
</bodyText>
<figureCaption confidence="0.95846">
Figure 2: Example entity grid, using the labels by
Barzilay and Lapata (2008).
</figureCaption>
<bodyText confidence="0.993885772727273">
solvers (Fernandes et al., 2012; Bj¨orkelund and
Kuhn, 2014), but ICE uses it to display links be-
tween mentions introduced by an automatic (pair-
wise) resolver.
Figure 3 shows three examples of the tree view
of the same document as before: The gold allo-
cation (3a), the predicted allocation (3b), as well
as the differential view, where the two allocations
are compared (3c). Each mention corresponds to
a node in the trees and all mentions are directly or
transitively dominated by the artificial root node.
Every subtree under the root constitutes its own
cluster and a solid arc between two mentions de-
notes that the two mentions are coreferent accord-
ing to a coreference allocation. The information
displayed in the nodes of the tree can be cus-
tomized using label patterns.
In the differential view (Figure 3c), solid arcs
correspond to the predicted allocation. Dashed
nodes and arcs are present in the gold allocation,
but not in the prediction. Discrepancies between
the predicted and the gold allocations are marked
</bodyText>
<page confidence="0.973617">
9
</page>
<figure confidence="0.992502">
(a) Tree representing the gold allocation. (b) Tree representing the predicted allocation.
(c) Differential view displaying the difference between the gold and predicted allocations.
</figure>
<figureCaption confidence="0.999959">
Figure 3: Tree view over the example document (gold, predicted, differential).
</figureCaption>
<bodyText confidence="0.992341">
with different colors denoting different types of er-
rors. The example in Figure 3c contains two errors
made by the system:
</bodyText>
<listItem confidence="0.865580333333333">
1. A false negative mention, denoted by the
dashed red node Shangtou. In the gold
standard (Figure 3a) this mention is clus-
tered with other mentions such as Shantou ’s,
Shantou City, etc. The dashed arc between
Shantou ’s and Shangtou is taken from the
gold allocation, and indicates what the sys-
tem prediction should have been like.4
2. A foreign antecedent, denoted by the solid
</listItem>
<bodyText confidence="0.926363166666667">
orange arc between Shantou ’s new high level
technology development zone and Shantou.
In this case, the coreference system erro-
neously clustered these two mentions. The
correct antecedent is indicated by the dashed
arc that originates from the document root.
</bodyText>
<footnote confidence="0.981660333333333">
4This error likely stems from the fact that Shantou is
spelled two different ways within the same document which
causes the resolver’s string-matching feature to fail.
</footnote>
<bodyText confidence="0.999893727272727">
This error is particularly interesting since the
system effectively merges the two clusters
corresponding to Shantou and Shantou’ s new
high level technology development zone. The
tree view, however, shows that the error stems
from a single link between these two men-
tions, and that the developer needs to address
this.
Since the tree-based view makes pairwise de-
cisions explicit, the differential view shown in
Figure 3c is more informative to NLP develop-
ers when inspecting errors by automatic system
than comparing a gold standard clustering to a pre-
dicted one. The problem with analyzing the error
on clusterings instead of trees is that the clusters
would be merged, i.e., it is not clear where the ac-
tual mistake was made.
Additional error types not illustrated by Fig-
ure 3c include false positive mentions, where
the system invents a mention that is not part
of the gold allocation. When a false positive
mention is assigned as an antecedent of another
</bodyText>
<page confidence="0.996805">
10
</page>
<bodyText confidence="0.9990625">
mention, the corresponding link is marked as an
invented antecedent. Links that erroneously start
a new cluster when it is coreferent with other men-
tions to the left is marked as false new.
</bodyText>
<sectionHeader confidence="0.991508" genericHeader="method">
4 Searching
</sectionHeader>
<bodyText confidence="0.998638933333333">
The search engine in ICE makes the annotations
in the documents searchable for, e. g., a corpus lin-
guist who is interested in specific coreference phe-
nomena. It allows the user to express queries over
mentions related through the tree. Queries can ac-
cess the different layers of annotation, both from
the allocation file and the underlying document,
using various constructs such as, e.g., transitivity,
regular expressions, and/or disjunctions. The user
can construct queries either textually (through a
query language) or graphically (by creating nodes
and configuring constraints in dialogues). For a
further discussion of the search engine we refer to
the original ICARUS paper (G¨artner et al., 2013).
Figure 4 shows a query that matches cataphoric
pronouns, i.e., pronouns that precede their an-
tecedents. The figure shows the query expressed
as a subgraph (on the left) and the corresponding
results (right) obtained on the development set of
the English CoNLL 2012 data using the manual
annotation represented in the gold allocation.
The query matches two mentions that are di-
rectly or transitively connected through the graph.
The first mention (red node) matches mentions of
the type Pronoun that have to be attached to the
document root node. In the tree formalism we
adopt, this implies that it must be the first men-
tion of its cluster. The second mention (green
node) matches any mention that is not of the type
Pronoun.
</bodyText>
<figure confidence="0.992644">
(a) (b)
</figure>
<figureCaption confidence="0.9843775">
Figure 4: Example search query and correspond-
ing results.
</figureCaption>
<bodyText confidence="0.999943125">
The search results are grouped along two axes:
the surface form of the head word of the first (red)
node, and the type property of the second mention
(green node), indicated by the special grouping
operator &lt;*&gt; inside the boxes. The correspond-
ing results are shown in the right half of Figure 4,
where the first group (surface form) runs verti-
cally, and the second group (mention type) runs
horizontally. The number of hits for each configu-
ration is shown in the corresponding cell. For ex-
ample, the case that the first mention of a chain is
the pronoun I and the closest following coreferent
mention that is not a pronoun is of type Common,
occurs 6 times. By clicking on a cell, the user can
jump straight to a list of the matches, and browse
them using any of the three display modes.
</bodyText>
<sectionHeader confidence="0.999946" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999952583333333">
Two popular annotation and visualization tools
for coreference are PAlinkA (Or˘asan, 2003) and
MMAX2 (M¨uller and Strube, 2006), which fo-
cus on a (customizable) textual visualization with
highlighting of clusters. The TrED (Pajas and
ˇStˇep´anek, 2009) project is a very flexible multi-
level annotation tool centered around tree-based
annotations that can be used to annotate and vi-
sualize coreference. It also features a powerful
search engine. Recent annotation tools include the
web-based BRAT (Stenetorp et al., 2012) and its
extension WebAnno (Yimam et al., 2013). A ded-
icated query and exploration tool for multi-level
annotations is ANNIS (Zeldes et al., 2009).
The aforementioned tools are primarily meant
as annotation tools. They have a tendency of lock-
ing the user into one type of visualization (tree- or
text-based), while often lacking advanced search
functionality. In contrast to them, ICE is not meant
to be yet another annotation tool, but was designed
as a dedicated coreference exploration tool, which
enables the user to swiftly switch between differ-
ent views. Moreover, none of the existing tools
provide an entity-grid view.
ICE is also the only tool that can graphically
compare predictions of a system to a gold standard
with a fine-grained distinction on the types of dif-
ferences. Kummerfeld and Klein (2013) present
an algorithm that transforms a predicted corefer-
ence clustering into a gold clustering and records
the necessary transformations, thereby quantify-
ing different types of errors. However, their algo-
rithm only works on clusterings (sets of mentions),
not pairwise links, and is therefore not able to pin-
point some of the mistakes that ICE can (such as
the foreign antecedent described in Section 3).
</bodyText>
<page confidence="0.998951">
11
</page>
<sectionHeader confidence="0.999368" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999974714285714">
We presented ICE, a flexible coreference visual-
ization and search tool. The tool complements
standard text-based display modes with entity-grid
and tree visualizations. It is also able to dis-
play discrepancies between two different corefer-
ence annotations on the same document, allow-
ing NLP developers to debug coreference sys-
tems in a graphical way. The built-in search en-
gine allows corpus linguists to construct complex
search queries and provide aggregate result views
over large sets of documents. Being based on the
ICARUS platform’s plugin-engine, ICE is extensi-
ble and can easily be extended to cover additional
data formats.
</bodyText>
<sectionHeader confidence="0.999166" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9848246">
This work was funded by the German Federal
Ministry of Education and Research (BMBF) via
CLARIN-D, No. 01UG1120F and the German
Research Foundation (DFG) via the SFB 732,
project D8.
</bodyText>
<sectionHeader confidence="0.99891" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999328795180723">
Regina Barzilay and Mirella Lapata. 2008. Model-
ing Local Coherence: An Entity-Based Approach.
Computational Linguistics, 34(1):1–34.
Shane Bergsma and Dekang Lin. 2006. Bootstrapping
path-based pronoun resolution. In COLING-ACL,
pages 33–40, Sydney, Australia, July.
Anders Bj¨orkelund and Jonas Kuhn. 2014. Learning
Structured Perceptrons for Coreference Resolution
with Latent Antecedents and Non-local Features. In
ACL, Baltimore, MD, USA, June.
Marie-Catherine de Marneffe and Christopher D. Man-
ning. 2008. The stanford typed dependencies
representation. In COLING Workshop on Cross-
framework and Cross-domain Parser Evaluation.
Greg Durrett and Dan Klein. 2013. Easy Victo-
ries and Uphill Battles in Coreference Resolution.
In EMNLP, pages 1971–1982, Seattle, Washington,
USA, October.
Eraldo Fernandes, C´ıcero dos Santos, and Ruy Milidi´u.
2012. Latent Structure Perceptron with Feature In-
duction for Unrestricted Coreference Resolution. In
EMNLP-CoNLL: Shared Task, pages 41–48, Jeju Is-
land, Korea, July.
Markus G¨artner, Gregor Thiele, Wolfgang Seeker, An-
ders Bj¨orkelund, and Jonas Kuhn. 2013. ICARUS
– An Extensible Graphical Search Tool for Depen-
dency Treebanks. In ACL: System Demonstrations,
pages 55–60, Sofia, Bulgaria, August.
Jonathan K. Kummerfeld and Dan Klein. 2013. Error-
Driven Analysis of Challenges in Coreference Res-
olution. In EMNLP, pages 265–277, Seattle, Wash-
ington, USA, October.
Christoph M¨uller and Michael Strube. 2006. Multi-
level annotation of linguistic data with MMAX2. In
Corpus Technology and Language Pedagogy: New
Resources, New Tools, New Methods, pages 197–
214. Peter Lang.
Constantin Or˘asan. 2003. PALinkA: A highly cus-
tomisable tool for discourse annotation. In Akira
Kurematsu, Alexander Rudnicky, and Syun Tutiya,
editors, Proceedings of the Fourth SIGdial Work-
shop on Discourse and Dialogue, pages 39–43.
Petr Pajas and Jan ˇStˇep´anek. 2009. System for
Querying Syntactically Annotated Corpora. InACL-
IJCNLP: Software Demonstrations, pages 33–36,
Suntec, Singapore.
Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,
Martha Palmer, Ralph Weischedel, and Nianwen
Xue. 2011. CoNLL-2011 Shared Task: Modeling
Unrestricted Coreference in OntoNotes. In CoNLL:
Shared Task, pages 1–27, Portland, Oregon, USA,
June.
Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,
Olga Uryupina, and Yuchen Zhang. 2012. CoNLL-
2012 Shared Task: Modeling Multilingual Unre-
stricted Coreference in OntoNotes. In EMNLP-
CoNLL: Shared Task, pages 1–40, Jeju Island, Ko-
rea, July.
Marta Recasens, Llu´ıs M`arquez, Emili Sapena,
M. Ant`onia Mart´ı, Mariona Taul´e, V´eronique Hoste,
Massimo Poesio, and Yannick Versley. 2010.
Semeval-2010 task 1: Coreference resolution in
multiple languages. In Proceedings of the 5th Inter-
national Workshop on Semantic Evaluation, pages
1–8, Uppsala, Sweden, July.
Wee Meng Soon, Hwee Tou Ng, and Daniel
Chung Yong Lim. 2001. A machine learning ap-
proach to coreference resolution of noun phrases.
Computational Linguistics, 27(4):521–544.
Pontus Stenetorp, Sampo Pyysalo, Goran Topi´c,
Tomoko Ohta, Sophia Ananiadou, and Jun’ichi Tsu-
jii. 2012. brat: a Web-based Tool for NLP-Assisted
Text Annotation. In EACL: Demonstrations, pages
102–107, April.
Seid Muhie Yimam, Iryna Gurevych, Richard
Eckart de Castilho, and Chris Biemann. 2013.
WebAnno: A Flexible, Web-based and Visually
Supported System for Distributed Annotations. In
ACL: System Demonstrations, pages 1–6, August.
Amir Zeldes, Julia Ritz, Anke L¨udeling, and Christian
Chiarcos. 2009. ANNIS: a search tool for multi-
layer annotated corpora. In Proceedings of Corpus
Linguistics.
</reference>
<page confidence="0.998455">
12
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.910588">
<title confidence="0.999457">Visualization, Search, and Error Analysis for Coreference Annotations</title>
<author confidence="0.999817">Markus G¨artner Anders Bj¨orkelund Gregor Thiele Wolfgang Seeker Jonas</author>
<affiliation confidence="0.998668">Institute for Natural Language University of</affiliation>
<abstract confidence="0.994448375">We present the ICARUS Coreference Explorer, an interactive tool to browse and search coreference-annotated data. It can display coreference annotations as a tree, as an entity grid, or in a standard textbased display mode, and lets the user switch freely between the different modes. The tool can compare two different annotations on the same document, allowing system developers to evaluate errors in automatic system predictions. It features a flexible search engine, which enables the user to graphically construct search queries over sets of documents annotated with coreference.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Mirella Lapata</author>
</authors>
<title>Modeling Local Coherence: An Entity-Based Approach.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="2316" citStr="Barzilay and Lapata, 2008" startWordPosition="338" endWordPosition="341">lassified as coreferent in one cluster. This is particularly the case for several state-of-the-art resolvers (Fernandes et al., 2012; Durrett and Klein, 2013; Bj¨orkelund and Kuhn, 2014). These pairwise decisions, which give rise to a clustering, can be exploited for detailed error analysis and more finegrained search queries on data automatically annotated for coreference. We present the ICARUS Coreference Explorer (ICE), an interactive tool to browse and search coreference-annotated data. In addition to standard text-based display modes, ICE features two other display modes: an entity-grid (Barzilay and Lapata, 2008) and a tree view, which makes use of the internal pairwise links within the clusters. ICE builds on ICARUS (G¨artner et al., 2013), a platform for search and exploration of dependency treebanks.1 ICE is geared towards two (typically) distinct users: The NLP developer who designs coreference resolution systems can inspect the predictions of his system using the three different display modes. Moreover, ICE can compare the predictions of a system to a gold standard annotation, enabling the developer to inspect system errors interactively. The second potential user is the corpus linguist, who migh</context>
<context position="6365" citStr="Barzilay and Lapata (2008)" startWordPosition="1002" endWordPosition="1005">entity grid and tree display modes by means of screenshots. ICE additionally includes a standard text-based view, similar to other coreference visualization tools. The example document is taken from the CoNLL 2012 development set (Pradhan et al., 2012) and we use two allocations: (1) the predictions output by Bj¨orkelund and Kuhn (2014) system (predicted) and (2) a gold allocation that was obtained by running the same system in a restricted setting, where only links between coreferent mentions are allowed (gold). The complete document can be seen in the lower half of Figure 1. 3.1 Entity grid Barzilay and Lapata (2008) introduce the entity grid, a tabular view of entities in a document. Specifically, rows of the grid correspond to sentences, and columns to entities. The cells of the table are used to indicate that an entity is mentioned in the corresponding sentence. Entity grids provide a compact view on the distribution of mentions in a document and allow the user to see how the description of an entity changes from mention to mention. Figure 1 shows ICE’s entity-grid view for the example document using the predicted allocation. When clicking on a cell in the entity grid the immediate textual context of t</context>
<context position="9454" citStr="Barzilay and Lapata (2008)" startWordPosition="1543" endWordPosition="1546">hich is assigned based on the number and gender data compiled by Bergsma and Lin (2006) and can take the values {Sin, Plu, Unknown}. The label pattern for displaying the number property associated with a mention would be %Number%. The label pattern used in Figure 1 is defined as (&amp;quot;$form$&amp;quot; - %Type% - %Number%). This pattern accesses the full surface form of the mentions ($form$), as well as the TYPE (%Type%) and grammatical NUMBER (%Number%) properties defined in the allocation file. Custom properties and label patterns can be used for example to display the entity grid in the form proposed by Barzilay and Lapata (2008): In the allocation, we assign a coarse-grained grammatical function property (denoted GF) to every mention, where each mention is tagged as either subject, object, or other (denoted S, O, X, respectively).3 The label pattern %GF% then displays the grammatical function of each mention in the entity grid, as shown in Figure 2. 3.3 Tree view Pairwise links output by an automatic coreference system can be treated as arcs in a directed graph. Linking the first mention of each cluster to an artificial root node creates a tree structure that encodes the entire clustering in a document. This represen</context>
</contexts>
<marker>Barzilay, Lapata, 2008</marker>
<rawString>Regina Barzilay and Mirella Lapata. 2008. Modeling Local Coherence: An Entity-Based Approach. Computational Linguistics, 34(1):1–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shane Bergsma</author>
<author>Dekang Lin</author>
</authors>
<title>Bootstrapping path-based pronoun resolution.</title>
<date>2006</date>
<booktitle>In COLING-ACL,</booktitle>
<pages>33--40</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="8915" citStr="Bergsma and Lin (2006)" startWordPosition="1451" endWordPosition="1454">ntion. All properties defined by the user in the allocation (see Section 2) are accessible via label patterns. For example, the allocations we use for Figure 1 include a number of properties on the mentions, most of which are internally computed by the coreference system: The TYPE of a mention, which can take any of the values 8 Figure 1: Entity grid over the predicted clustering in the example document. {Name, Common, Pronoun} and is inferred from the part- of-speech tags in the CoNLL file; The grammatical NUMBER of a mention, which is assigned based on the number and gender data compiled by Bergsma and Lin (2006) and can take the values {Sin, Plu, Unknown}. The label pattern for displaying the number property associated with a mention would be %Number%. The label pattern used in Figure 1 is defined as (&amp;quot;$form$&amp;quot; - %Type% - %Number%). This pattern accesses the full surface form of the mentions ($form$), as well as the TYPE (%Type%) and grammatical NUMBER (%Number%) properties defined in the allocation file. Custom properties and label patterns can be used for example to display the entity grid in the form proposed by Barzilay and Lapata (2008): In the allocation, we assign a coarse-grained grammatical f</context>
</contexts>
<marker>Bergsma, Lin, 2006</marker>
<rawString>Shane Bergsma and Dekang Lin. 2006. Bootstrapping path-based pronoun resolution. In COLING-ACL, pages 33–40, Sydney, Australia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Bj¨orkelund</author>
<author>Jonas Kuhn</author>
</authors>
<title>Learning Structured Perceptrons for Coreference Resolution with Latent Antecedents and Non-local Features.</title>
<date>2014</date>
<booktitle>In ACL,</booktitle>
<location>Baltimore, MD, USA,</location>
<marker>Bj¨orkelund, Kuhn, 2014</marker>
<rawString>Anders Bj¨orkelund and Jonas Kuhn. 2014. Learning Structured Perceptrons for Coreference Resolution with Latent Antecedents and Non-local Features. In ACL, Baltimore, MD, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Christopher D Manning</author>
</authors>
<title>The stanford typed dependencies representation.</title>
<date>2008</date>
<booktitle>In COLING Workshop on Crossframework and Cross-domain Parser Evaluation.</booktitle>
<marker>de Marneffe, Manning, 2008</marker>
<rawString>Marie-Catherine de Marneffe and Christopher D. Manning. 2008. The stanford typed dependencies representation. In COLING Workshop on Crossframework and Cross-domain Parser Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greg Durrett</author>
<author>Dan Klein</author>
</authors>
<title>Easy Victories and Uphill Battles in Coreference Resolution. In</title>
<date>2013</date>
<booktitle>EMNLP,</booktitle>
<pages>1971--1982</pages>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="1847" citStr="Durrett and Klein, 2013" startWordPosition="267" endWordPosition="270">s are commonly represented by sets of mentions, where all mentions in one set (or coreference cluster) are considered coreferent. This type of representation does not support any internal structure within the clusters. However, many automatic coreference resolvers establish links between pairs of mentions which are subsequently transformed to a cluster by taking the transitive closure over all links, i.e., placing all mentions that are directly or transitively classified as coreferent in one cluster. This is particularly the case for several state-of-the-art resolvers (Fernandes et al., 2012; Durrett and Klein, 2013; Bj¨orkelund and Kuhn, 2014). These pairwise decisions, which give rise to a clustering, can be exploited for detailed error analysis and more finegrained search queries on data automatically annotated for coreference. We present the ICARUS Coreference Explorer (ICE), an interactive tool to browse and search coreference-annotated data. In addition to standard text-based display modes, ICE features two other display modes: an entity-grid (Barzilay and Lapata, 2008) and a tree view, which makes use of the internal pairwise links within the clusters. ICE builds on ICARUS (G¨artner et al., 2013),</context>
</contexts>
<marker>Durrett, Klein, 2013</marker>
<rawString>Greg Durrett and Dan Klein. 2013. Easy Victories and Uphill Battles in Coreference Resolution. In EMNLP, pages 1971–1982, Seattle, Washington, USA, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eraldo Fernandes</author>
<author>C´ıcero dos Santos</author>
<author>Ruy Milidi´u</author>
</authors>
<title>Latent Structure Perceptron with Feature Induction for Unrestricted Coreference Resolution.</title>
<date>2012</date>
<booktitle>In EMNLP-CoNLL: Shared Task,</booktitle>
<pages>41--48</pages>
<location>Jeju Island, Korea,</location>
<marker>Fernandes, Santos, Milidi´u, 2012</marker>
<rawString>Eraldo Fernandes, C´ıcero dos Santos, and Ruy Milidi´u. 2012. Latent Structure Perceptron with Feature Induction for Unrestricted Coreference Resolution. In EMNLP-CoNLL: Shared Task, pages 41–48, Jeju Island, Korea, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus G¨artner</author>
<author>Gregor Thiele</author>
<author>Wolfgang Seeker</author>
<author>Anders Bj¨orkelund</author>
<author>Jonas Kuhn</author>
</authors>
<title>ICARUS – An Extensible Graphical Search Tool for Dependency Treebanks.</title>
<date>2013</date>
<booktitle>In ACL: System Demonstrations,</booktitle>
<pages>55--60</pages>
<location>Sofia, Bulgaria,</location>
<marker>G¨artner, Thiele, Seeker, Bj¨orkelund, Kuhn, 2013</marker>
<rawString>Markus G¨artner, Gregor Thiele, Wolfgang Seeker, Anders Bj¨orkelund, and Jonas Kuhn. 2013. ICARUS – An Extensible Graphical Search Tool for Dependency Treebanks. In ACL: System Demonstrations, pages 55–60, Sofia, Bulgaria, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan K Kummerfeld</author>
<author>Dan Klein</author>
</authors>
<title>ErrorDriven Analysis of Challenges in Coreference Resolution. In</title>
<date>2013</date>
<booktitle>EMNLP,</booktitle>
<pages>265--277</pages>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="17472" citStr="Kummerfeld and Klein (2013)" startWordPosition="2857" endWordPosition="2860"> meant as annotation tools. They have a tendency of locking the user into one type of visualization (tree- or text-based), while often lacking advanced search functionality. In contrast to them, ICE is not meant to be yet another annotation tool, but was designed as a dedicated coreference exploration tool, which enables the user to swiftly switch between different views. Moreover, none of the existing tools provide an entity-grid view. ICE is also the only tool that can graphically compare predictions of a system to a gold standard with a fine-grained distinction on the types of differences. Kummerfeld and Klein (2013) present an algorithm that transforms a predicted coreference clustering into a gold clustering and records the necessary transformations, thereby quantifying different types of errors. However, their algorithm only works on clusterings (sets of mentions), not pairwise links, and is therefore not able to pinpoint some of the mistakes that ICE can (such as the foreign antecedent described in Section 3). 11 6 Conclusion We presented ICE, a flexible coreference visualization and search tool. The tool complements standard text-based display modes with entity-grid and tree visualizations. It is als</context>
</contexts>
<marker>Kummerfeld, Klein, 2013</marker>
<rawString>Jonathan K. Kummerfeld and Dan Klein. 2013. ErrorDriven Analysis of Challenges in Coreference Resolution. In EMNLP, pages 265–277, Seattle, Washington, USA, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph M¨uller</author>
<author>Michael Strube</author>
</authors>
<title>Multilevel annotation of linguistic data with MMAX2.</title>
<date>2006</date>
<booktitle>In Corpus Technology and Language Pedagogy:</booktitle>
<pages>197--214</pages>
<publisher>Peter Lang.</publisher>
<location>New Resources, New Tools, New Methods,</location>
<marker>M¨uller, Strube, 2006</marker>
<rawString>Christoph M¨uller and Michael Strube. 2006. Multilevel annotation of linguistic data with MMAX2. In Corpus Technology and Language Pedagogy: New Resources, New Tools, New Methods, pages 197– 214. Peter Lang.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Constantin Or˘asan</author>
</authors>
<title>PALinkA: A highly customisable tool for discourse annotation.</title>
<date>2003</date>
<booktitle>In Akira Kurematsu, Alexander Rudnicky, and Syun Tutiya, editors, Proceedings of the Fourth SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>39--43</pages>
<marker>Or˘asan, 2003</marker>
<rawString>Constantin Or˘asan. 2003. PALinkA: A highly customisable tool for discourse annotation. In Akira Kurematsu, Alexander Rudnicky, and Syun Tutiya, editors, Proceedings of the Fourth SIGdial Workshop on Discourse and Dialogue, pages 39–43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Petr Pajas</author>
<author>Jan ˇStˇep´anek</author>
</authors>
<title>System for Querying Syntactically Annotated Corpora. InACLIJCNLP: Software Demonstrations,</title>
<date>2009</date>
<pages>33--36</pages>
<location>Suntec, Singapore.</location>
<marker>Pajas, ˇStˇep´anek, 2009</marker>
<rawString>Petr Pajas and Jan ˇStˇep´anek. 2009. System for Querying Syntactically Annotated Corpora. InACLIJCNLP: Software Demonstrations, pages 33–36, Suntec, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Lance Ramshaw</author>
<author>Mitchell Marcus</author>
<author>Martha Palmer</author>
<author>Ralph Weischedel</author>
<author>Nianwen Xue</author>
</authors>
<title>CoNLL-2011 Shared Task: Modeling Unrestricted Coreference in OntoNotes.</title>
<date>2011</date>
<booktitle>In CoNLL: Shared Task,</booktitle>
<pages>1--27</pages>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="1179" citStr="Pradhan et al., 2011" startWordPosition="167" endWordPosition="170">odes. The tool can compare two different annotations on the same document, allowing system developers to evaluate errors in automatic system predictions. It features a flexible search engine, which enables the user to graphically construct search queries over sets of documents annotated with coreference. 1 Introduction Coreference resolution is the task of automatically grouping references to the same real-world entity in a document into a set. It is an active topic in current NLP research and has received considerable attention in recent years, including the 2011 and 2012 CoNLL shared tasks (Pradhan et al., 2011; Pradhan et al., 2012). Coreference relations are commonly represented by sets of mentions, where all mentions in one set (or coreference cluster) are considered coreferent. This type of representation does not support any internal structure within the clusters. However, many automatic coreference resolvers establish links between pairs of mentions which are subsequently transformed to a cluster by taking the transitive closure over all links, i.e., placing all mentions that are directly or transitively classified as coreferent in one cluster. This is particularly the case for several state-o</context>
</contexts>
<marker>Pradhan, Ramshaw, Marcus, Palmer, Weischedel, Xue, 2011</marker>
<rawString>Sameer Pradhan, Lance Ramshaw, Mitchell Marcus, Martha Palmer, Ralph Weischedel, and Nianwen Xue. 2011. CoNLL-2011 Shared Task: Modeling Unrestricted Coreference in OntoNotes. In CoNLL: Shared Task, pages 1–27, Portland, Oregon, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Alessandro Moschitti</author>
<author>Nianwen Xue</author>
<author>Olga Uryupina</author>
<author>Yuchen Zhang</author>
</authors>
<title>CoNLL2012 Shared Task: Modeling Multilingual Unrestricted Coreference in OntoNotes.</title>
<date>2012</date>
<booktitle>In EMNLPCoNLL: Shared Task,</booktitle>
<pages>1--40</pages>
<location>Jeju Island, Korea,</location>
<contexts>
<context position="1202" citStr="Pradhan et al., 2012" startWordPosition="171" endWordPosition="174">pare two different annotations on the same document, allowing system developers to evaluate errors in automatic system predictions. It features a flexible search engine, which enables the user to graphically construct search queries over sets of documents annotated with coreference. 1 Introduction Coreference resolution is the task of automatically grouping references to the same real-world entity in a document into a set. It is an active topic in current NLP research and has received considerable attention in recent years, including the 2011 and 2012 CoNLL shared tasks (Pradhan et al., 2011; Pradhan et al., 2012). Coreference relations are commonly represented by sets of mentions, where all mentions in one set (or coreference cluster) are considered coreferent. This type of representation does not support any internal structure within the clusters. However, many automatic coreference resolvers establish links between pairs of mentions which are subsequently transformed to a cluster by taking the transitive closure over all links, i.e., placing all mentions that are directly or transitively classified as coreferent in one cluster. This is particularly the case for several state-of-the-art resolvers (Fe</context>
<context position="5991" citStr="Pradhan et al., 2012" startWordPosition="940" endWordPosition="943">for the clusters, in which the correct antecedent of every mention is the closest coreferent mention with respect to the linear order of the document (this is equivalent to the training instance creation heuristic proposed by Soon et al. (2001)). Therefore, the user is not required to define an allocation on their own. 3 Display Modes In this section we describe the entity grid and tree display modes by means of screenshots. ICE additionally includes a standard text-based view, similar to other coreference visualization tools. The example document is taken from the CoNLL 2012 development set (Pradhan et al., 2012) and we use two allocations: (1) the predictions output by Bj¨orkelund and Kuhn (2014) system (predicted) and (2) a gold allocation that was obtained by running the same system in a restricted setting, where only links between coreferent mentions are allowed (gold). The complete document can be seen in the lower half of Figure 1. 3.1 Entity grid Barzilay and Lapata (2008) introduce the entity grid, a tabular view of entities in a document. Specifically, rows of the grid correspond to sentences, and columns to entities. The cells of the table are used to indicate that an entity is mentioned in </context>
</contexts>
<marker>Pradhan, Moschitti, Xue, Uryupina, Zhang, 2012</marker>
<rawString>Sameer Pradhan, Alessandro Moschitti, Nianwen Xue, Olga Uryupina, and Yuchen Zhang. 2012. CoNLL2012 Shared Task: Modeling Multilingual Unrestricted Coreference in OntoNotes. In EMNLPCoNLL: Shared Task, pages 1–40, Jeju Island, Korea, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Recasens</author>
<author>Llu´ıs M`arquez</author>
<author>Emili Sapena</author>
<author>M Ant`onia Mart´ı</author>
<author>Mariona Taul´e</author>
<author>V´eronique Hoste</author>
<author>Massimo Poesio</author>
<author>Yannick Versley</author>
</authors>
<title>Semeval-2010 task 1: Coreference resolution in multiple languages.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<pages>1--8</pages>
<location>Uppsala, Sweden,</location>
<marker>Recasens, M`arquez, Sapena, Mart´ı, Taul´e, Hoste, Poesio, Versley, 2010</marker>
<rawString>Marta Recasens, Llu´ıs M`arquez, Emili Sapena, M. Ant`onia Mart´ı, Mariona Taul´e, V´eronique Hoste, Massimo Poesio, and Yannick Versley. 2010. Semeval-2010 task 1: Coreference resolution in multiple languages. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 1–8, Uppsala, Sweden, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wee Meng Soon</author>
<author>Hwee Tou Ng</author>
<author>Daniel Chung Yong Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>4</issue>
<contexts>
<context position="5614" citStr="Soon et al. (2001)" startWordPosition="877" endWordPosition="880"> the allocation file. Second, multiple allocation files allow the user to switch between different allocations while exploring a set of documents. Moreover, as we will see in Section 3.3, ICE can also compare two different allocations in order to highlight the differences. In addition to user-specified allocations, ICE will always by default provide an internal structure for the clusters, in which the correct antecedent of every mention is the closest coreferent mention with respect to the linear order of the document (this is equivalent to the training instance creation heuristic proposed by Soon et al. (2001)). Therefore, the user is not required to define an allocation on their own. 3 Display Modes In this section we describe the entity grid and tree display modes by means of screenshots. ICE additionally includes a standard text-based view, similar to other coreference visualization tools. The example document is taken from the CoNLL 2012 development set (Pradhan et al., 2012) and we use two allocations: (1) the predictions output by Bj¨orkelund and Kuhn (2014) system (predicted) and (2) a gold allocation that was obtained by running the same system in a restricted setting, where only links betw</context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational Linguistics, 27(4):521–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pontus Stenetorp</author>
</authors>
<title>Sampo Pyysalo, Goran Topi´c, Tomoko Ohta, Sophia Ananiadou, and Jun’ichi Tsujii.</title>
<date>2012</date>
<booktitle>In EACL: Demonstrations,</booktitle>
<pages>102--107</pages>
<marker>Stenetorp, 2012</marker>
<rawString>Pontus Stenetorp, Sampo Pyysalo, Goran Topi´c, Tomoko Ohta, Sophia Ananiadou, and Jun’ichi Tsujii. 2012. brat: a Web-based Tool for NLP-Assisted Text Annotation. In EACL: Demonstrations, pages 102–107, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seid Muhie Yimam</author>
<author>Iryna Gurevych</author>
<author>Richard Eckart de Castilho</author>
<author>Chris Biemann</author>
</authors>
<title>WebAnno: A Flexible, Web-based and Visually Supported System for Distributed Annotations.</title>
<date>2013</date>
<booktitle>In ACL: System Demonstrations,</booktitle>
<pages>1--6</pages>
<marker>Yimam, Gurevych, de Castilho, Biemann, 2013</marker>
<rawString>Seid Muhie Yimam, Iryna Gurevych, Richard Eckart de Castilho, and Chris Biemann. 2013. WebAnno: A Flexible, Web-based and Visually Supported System for Distributed Annotations. In ACL: System Demonstrations, pages 1–6, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amir Zeldes</author>
<author>Julia Ritz</author>
<author>Anke L¨udeling</author>
<author>Christian Chiarcos</author>
</authors>
<title>ANNIS: a search tool for multilayer annotated corpora.</title>
<date>2009</date>
<booktitle>In Proceedings of Corpus Linguistics.</booktitle>
<marker>Zeldes, Ritz, L¨udeling, Chiarcos, 2009</marker>
<rawString>Amir Zeldes, Julia Ritz, Anke L¨udeling, and Christian Chiarcos. 2009. ANNIS: a search tool for multilayer annotated corpora. In Proceedings of Corpus Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>