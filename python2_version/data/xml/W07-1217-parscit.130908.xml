<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.127758">
<title confidence="0.994893">
Partial Parse Selection for Robust Deep Processing
</title>
<author confidence="0.978456">
Yi Zhang† and Valia Kordoni† and Erin Fitzgerald‡
</author>
<affiliation confidence="0.972016666666667">
t Dept of Computational Linguistics, Saarland University and DFKI GmbH, Germany
t Center for Language &amp; Speech Processing,
Dept of Electrical &amp; Computer Engineering, Johns Hopkins University, USA
</affiliation>
<email confidence="0.9678795">
{yzhang,kordoni}@coli.uni-sb.de
erin@clsp.jhu.edu
</email>
<sectionHeader confidence="0.997368" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999984">
This paper presents an approach to partial
parse selection for robust deep processing.
The work is based on a bottom-up chart
parser for HPSG parsing. Following the def-
inition of partial parses in (Kasper et al.,
1999), different partial parse selection meth-
ods are presented and evaluated on the basis
of multiple metrics, from both the syntactic
and semantic viewpoints. The application
of the partial parsing in spontaneous speech
texts processing shows promising compe-
tence of the method.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999750303030304">
Linguistically deep processing is of high theoret-
ical and application interest because of its ability
to deliver fine-grained accurate analyses of natu-
ral language sentences. Unlike shallow methods
which usually return analyses for any input, deep
processing methods with precision grammars nor-
mally make a clear grammaticality judgment on in-
puts, therefore avoiding the generation of erroneous
analyses for less well-formed inputs. This is a desir-
able feature, for it allows for a more accurate mod-
eling of language itself.
However, this feature largely limits the robustness
of deep processing, for when a sentence is judged
to be ungrammatical, normally no analysis is gen-
erated. When faced with the noisy inputs in real
applications (e.g., input errors introduced by speech
recognizers or other pre-processors, mildly ungram-
matical sentences with fragmental utterances, self-
editing chunks or filler words in spoken texts, and
so forth), lack of robustness means poor coverage,
and makes deep processing less competitive as com-
pared to shallow methods.
Take the English Resource Grammar
(ERG; Flickinger (2000)), a large-scale accu-
rate HPSG for English, for example. (Baldwin et
al., 2004) reported coverage of 57% of the strings
with full lexical span from the British National
Corpus (BNC). Although recent extensions to the
grammar and lexicon have improved the coverage
significantly, full coverage over unseen texts by the
grammar is still not anywhere in sight.
Other domains are even more likely to not fit
into ERG’s universe, such as transcripts of sponta-
neously produced speech where speaker errors and
disfluencies are common. Using a recent version of
the ERG, we are not able to parse 22.6% of a ran-
dom sample of 500 utterances of conversational tele-
phone speech data. 76.1% of the unparsed data was
independently found to contain speaker errors and
disfluencies, and the remaining data either contained
filled pauses or other structures unaccounted for in
the grammar. Correctly recognizing and interpreting
the substrings in the utterance which have coherent
deep syntax is useful both for semantic analysis and
as building blocks for attempts to reconstruct the dis-
fluent spontaneously produced utterances into well-
formed sentences.
For these reasons, it is preferable to exploit the
intermediate syntactic and semantic analysis even if
the full analysis is not available. Various efforts have
been made on the partiality of language processing.
In bottom-up chart parsing, the passive parser edges
licensed by the grammar can be taken as partial anal-
yses. However, as pointed out in (Kasper et al.,
1999), not all passive edges are good candidates, as
not all of them provide useful syntactic/semantic in-
formation. Moreover, the huge amount of passive
edges suggests the need for a technique of select-
ing an optimal subset of them. During recent devel-
opment in statistical parse disambiguation, the use
of log-linear models has been pretty much standard-
ized. However, it remains to be explored whether the
techniques can be adapted for partial parse selection.
In this paper, we adopt the same definition for
partial parse as in (Kasper et al., 1999) and de-
fine the task of partial parse selection. Several dif-
</bodyText>
<page confidence="0.961102">
128
</page>
<note confidence="0.93102">
Proceedings of the ACL 2007 Workshop on Deep Linguistic Processing, pages 128–135,
Prague, Czech Republic, June, 2007. @2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.997442703703704">
ferent partial parse selection models are presented
and implemented for an efficient HPSG parser –
PET (Callmeier, 2001).
One of the main difficulties in the research of par-
tial analyses is the lack of good evaluation measure-
ments. Pure syntactic comparisons for parser eval-
uation are not good as they are very much specific
to the annotation guidelines. Also, the deep gram-
mars we are working with are not automatically ex-
tracted from annotated corpora. Therefore, unless
there are partial treebanks built specifically for the
deep grammars, there is simply no ‘gold’ standard
for non-golden partial analyses.
Instead, in this paper, we evaluate the partial anal-
yses results on the basis of multiple metrics, from
both the syntactic and semantic point of views. Em-
pirical evaluation has been done with the ERG on a
small set of texts from the Wall Street Journal Sec-
tion 22 of the Penn Treebank (Marcus et al., 1993).
A pilot study of applying partial parsing in sponta-
neous speech text processing is also carried out.
The remainder of the paper is organized as fol-
low. Section 2 provides background knowledge
about partial analysis. Section 3 presents various
partial parse selection models. Section 4 describes
the evaluation setup and results. Section 5 concludes
the paper.
</bodyText>
<sectionHeader confidence="0.970681" genericHeader="method">
2 Partial Parsing
</sectionHeader>
<subsectionHeader confidence="0.925488">
2.1 HPSG Parsing
</subsectionHeader>
<bodyText confidence="0.999767235294118">
Our work on partial parsing is done with the
DELPH-IN HPSG grammars. Many of these gram-
mars can be used for both parsing and generation.
In this paper, we only focus on the parsing task. For
efficient parsing, we use PET.1 The parsing module
in PET is essentially a bottom-up chart parser. The
parsing process is guided by the parsing tasks on an
agenda. A parsing task represents the combination
of a passive chart edge and an active chart edge or
a rule. When the combination succeeds, new tasks
are generated and put on to the agenda. The parser
terminates either when the task agenda is empty or
when a specific number of full analyses has been
found (only in the no-packing best-first mode).
HPSG grammars use typed feature structures (TF-
Ses) as their background formalism. The TFSes rep-
resent various linguistic objects with a set of fea-
</bodyText>
<footnote confidence="0.933925666666667">
1LKB (Copestake, 2002) has a similar chart-based parser,
being less efficient mainly due to its implementation in Lisp
rather than C/C++.
</footnote>
<bodyText confidence="0.999758666666667">
tures (attribute value pairs) and a type inheritance
system. Therefore, each passive edge on the parsing
chart corresponds to a TFS. A relatively small set of
highly generalized rules are used to check the com-
patibility among smaller TFSes and build up larger
ones.
</bodyText>
<subsectionHeader confidence="0.998313">
2.2 Partial Parses
</subsectionHeader>
<bodyText confidence="0.999167263157895">
Based on the bottom-up chart parsing, we use the
term Partial Parse to describe a set of intermediate
passive parsing edges whose spans (beginning and
end positions) are non-overlapping between each
other, and together they cover the entire input se-
quence (i.e., no skipped input tokens).
In a graph view, the intermediate results of a chart
parser can be described as a directed graph, where
all positions between input tokens/words are ver-
tices, and all the passive edges derived during pars-
ing are the directed graph arcs. Obviously such a
graph is acyclic and therefore topologically sorted.
A partial parse is then a path from the source vertex
(the beginning position of the input) to the terminal
vertex (the end position of the input).
Suppose in chart parsing, we derived the interme-
diate results as in Figure 1. There are in total 4 pos-
sible partial parses: {a, b, c, d}, {a, b, f}, {a, e, d}
and {a, g}.
</bodyText>
<figure confidence="0.993949833333333">
w1 w2 w3 w4
0 1 2 3 4
e
f
a b c d
g
</figure>
<figureCaption confidence="0.9690815">
Figure 1: Graph representation of intermediate chart
parsing results
</figureCaption>
<bodyText confidence="0.995863">
Note that each passive edge is a sub-structure li-
censed by the grammar. A derivation tree or TFS can
be reconstructed for it if required. This definition of
partial parse is effectively the same to the view of
partial analyses in (Kasper et al., 1999).
</bodyText>
<subsectionHeader confidence="0.989819">
2.3 Local Ambiguity Packing
</subsectionHeader>
<bodyText confidence="0.994621875">
There is one more complication concerning the par-
tial parses when the local ambiguity packing is used
in the parser.
Due to the inherent ambiguity of natural lan-
guage, the same sequence of input may be ana-
lyzed as the same linguistic object in different ways.
Such intermediate analyses must be recorded dur-
ing the processing and recovered in later stages.
</bodyText>
<page confidence="0.997883">
129
</page>
<bodyText confidence="0.99999">
Without any efficient processing technique, parsing
becomes computationally intractable with the com-
binatory explosion of such local ambiguities. In
PET, the subsumption-based ambiguity packing al-
gorithm proposed in (Oepen and Carroll, 2000) is
used. This separates the parsing into two phases:
forest creation phase and read-out/unpacking phase.
In relation to the work on partial parsing in this
paper, the local ambiguity packing poses an effi-
ciency and accuracy challenge, as not all the inter-
mediate parsing results are directly available as pas-
sive edges on the chart. Without unpacking the am-
biguity readings, interesting partial analyses might
be lost.2 But exhaustively unpacking all the readings
will pay back the efficiency gain by ambiguity pack-
ing, and eventually lead to computational intractable
results.
To efficiently recover the ambiguous readings
from packed representations, the selective unpack-
ing algorithm has been recently implemented as an
extension to the algorithm described in (Carroll and
Oepen, 2005). It is able to recover the top-n best
readings of a given passive parser edge based on the
score assigned by a maximum entropy parse rank-
ing model. This neat feature largely facilitates the
efficient searching for best partial parses described
in later sections.
</bodyText>
<sectionHeader confidence="0.988684" genericHeader="method">
3 Partial Parse Selection
</sectionHeader>
<bodyText confidence="0.979148173913044">
A partial parse is a set of partial analyses licensed
by the grammar which cover the entire input without
overlapping. As shown in the previous section, there
are usually more than one possible partial parses
for a given input. For deep linguistic processing, a
high level of local ambiguity means there are even
more partial parses due to the combinatory explo-
sion. However, not all the possible partial parses are
equally good. Some partial parses partition the in-
put into fragments that do not correspond to linguis-
tic constituents. Even if the bracketing is correct,
the different edges with the same span represent sig-
nificantly different linguistic objects, and their sub-
structures can be completely different, as well. All
these indicate the need for methods that can appro-
priately select the best partial parses from all the
possible ones.
In this section, we review some of the previous
2More informative analyses are subsumed by less informa-
tive ones. In subsumption-based packing, such analyses are
packed and are not directly accessible.
approaches to partial parse selection, as well as new
partial parse ranking models.
</bodyText>
<subsectionHeader confidence="0.999705">
3.1 Longest Edge
</subsectionHeader>
<bodyText confidence="0.99997">
One of the simplest and most commonly used cri-
terion in selecting the best partial parse is to prefer
the partial parses which contain an edge that covers
the largest fragment of the input. For example, un-
der such a criterion, the best partial parse in Figure 1
will be {a, g}, since edge g has the largest span. The
logic behind this criterion is that such largest frag-
ments should preserve the most interesting linguistic
analysis of the input. As an added incentive, finding
the longest edge does not involve much search.
The limitations of such an approach are obvious.
There is no guarantee that the longest edge will be
significantly better than shorter edges, or that it will
even correspond to a valid constituent. Moreover,
when there are multiple edges with the same length
(which is often the case in parsing), the criterion
does not suffice for the choice of the best partial
parse.
</bodyText>
<subsectionHeader confidence="0.999876">
3.2 Shortest Path
</subsectionHeader>
<bodyText confidence="0.998071259259259">
(Kasper et al., 1999) proposed an alternative solu-
tion to the problem. If the preference of each edge
as a part of the partial parse can be quantitatively de-
cided as a weight of the edge (with smaller weights
assigned to better candidates), then the problem of
finding the best partial parse is to find the shortest
path from the start vertex to the end vertex. Since
the graph is completely connected (by the lexical
edges spanning all the input tokens) and topolog-
ically sorted, such a path always exists. The dis-
covery of such a path can be done in linear time
(O(|V  |+ |E|)) with the DAG-shortest-path algo-
rithm (Cormen et al., 1990). Though not explic-
itly pointed out by (Kasper et al., 1999), such an
algorithm allows the weights of the edges to be of
any real value (no assumption of positive weights)
as long as the graph is a Directed Acyclic Graph
(DAG).
(Kasper et al., 1999) did point out that the weights
of the edges can be assigned by an estimation func-
tion. For example, the implementation of the al-
gorithm in PET preferred phrasal edges over lexi-
cal edges. Other types of edges are not allowed in
the partial parse. Suppose that we assign weight 1
to phrasal edges, 2 to lexical edges, and inf to all
other edges. Then for the graph in 2, the best par-
tial parses are {e, g} and {f, g}, both of which have
</bodyText>
<page confidence="0.982026">
130
</page>
<bodyText confidence="0.99368825">
the path length of 2. It should be noted that such an
approach does not always favor the paths with the
longest edges (i.e., path {h, d} is not preferred in
the given example).
</bodyText>
<figureCaption confidence="0.8641035">
Figure 2: Shortest path partial parses with heuristi-
cally assigned edge weights
</figureCaption>
<bodyText confidence="0.998204789473684">
However, (Kasper et al., 1999) did not pro-
vide any sophisticated estimation functions based
on the shortest path approach. Using the heuristic
weight described above, usually thousands of differ-
ent paths are found with the same weight. (Kasper
et al., 1999) rely on another scoring function in or-
der to re-rank the partial parses. Although different
requirements for the scoring function are discussed,
no further details have been defined.
It should be noted that different variations of the
shortest path approach are widely in use in many ro-
bust deep parsing systems. For instance, (Riezler et
al., 2002) uses the fewest chunk method to choose
the best fragment analyses for sentences without
full analysis. The well-formed chunks are preferred
over token chunks. With this partial parse selection
method, the grammar achieves 100% coverage on
unseen data. A similar approach is also used in (van
Noord et al., 1999).
</bodyText>
<subsectionHeader confidence="0.993887">
3.3 Alternative Estimation Functions
</subsectionHeader>
<bodyText confidence="0.9999597">
Generally speaking, the weights of the edges in the
shortest path approach represent the quality of the
local analyses and their likelihood of appearing in
the analysis of the entire input.
This is an interesting parallel to the parse selec-
tion models for the full analyses, where a goodness
score is usually assigned to the full analysis. For
example, the parse disambiguation model described
in (Toutanova et al., 2002) uses a maximum entropy
approach to model the conditional probability of a
parse for a given input sequence P(t|w). A similar
approach has also been reported in (Johnson et al.,
1999; Riezler et al., 2002; Malouf and van Noord,
2004).
For a given partial parse `b = {t1, ... , tk}, Q =
{w1, ... , wk} is a segmentation of the input se-
quence so that each local analysis ti ∈ `b corre-
sponds to a substring wi ∈ Q of the input sequence
w. Therefore, the probability of the partial parse `b
given an input sequence w is:
</bodyText>
<equation confidence="0.999682">
P(`b|w) = P(Q|w) · P(`b|Q) (1)
</equation>
<bodyText confidence="0.981049">
With the bold assumption that P(ti|wi) are mutually
independent for different i, we can derive:
</bodyText>
<equation confidence="0.996825857142857">
k
P(`b|w) ≈ P(Q|w) · P(ti|wi) (2)
i=1
Therefore, the log-probability will be
k
log P(`b|w) ≈ log P(Q|w) + log P(ti|wi) (3)
i=1
</equation>
<bodyText confidence="0.970070076923077">
Equation 3 indicates that the log-probability of a
partial parse for a given input is the sum of the log-
probability of local analyses for the sub-strings, with
an additional component −log P(Q|w) represent-
ing the conditional log-probability of the segmen-
tation. If we use − log P(ti|wi) as the weight for
each local analysis, then the DAG shortest path al-
gorithm will quickly find the partial parse that max-
imizes log P(`b|w) − log P(Q|w).
The probability P (ti|wi) can be modeled in a sim-
ilar way to the maximum entropy based full parse
selection models:
exp En j=1 ajfj(ti, wi)
</bodyText>
<equation confidence="0.961188">
P(ti|wi) = (4)
Et′ ∈T exp Enj =1 aj fj (t′, wi)
</equation>
<bodyText confidence="0.999875444444445">
where T is the set of all possible structures that
can be assigned to wi, f1 ... fn are the features and
a1 ... an are the parameters. The parameters can
be efficiently estimated from a treebank, as shown
by (Malouf, 2002). The only difference from the
full parse selection model is that here intermediate
results are used to generate events for training the
model (i.e. the intermediate nodes are used as posi-
tive events if it occurs on one of the active tree, or as
negative events if not). Since there is a huge number
of intermediate results availalbe, we only randomly
select a part of them as training data. This is es-
sentially similar to the approach in (Osborne, 2000),
where there is an infeasibly large number of training
events, only part of which is used in the estimation
step. The exact features used in the log-linear model
can significantly influence the disambiguation accu-
racy. In this experiment we used the same features
</bodyText>
<figure confidence="0.987049125">
e :1 g:1
w1 w2 w3 w4
0 1 2 3 4
a :2 b :2 c:2 d:2
f:1
h:1
i:
8
</figure>
<page confidence="0.984324">
131
</page>
<bodyText confidence="0.998608222222222">
as those used in the PCFG-S model in (Toutanova et
al., 2002) (i.e., depth-1 derivation trees).
The estimation of P(Ω|w) is more difficult. In
a sense it is similar to a segmentation or chunking
model, where the task is to segment the input into
fragments. However, it is difficult to collect train-
ing data to directly train such a model for the deep
grammar we have. Here we take a simple rough es-
timation:
</bodyText>
<equation confidence="0.989607">
Pˆ(Ω|w) = |Y (Ω) |(5)
|Z(w)|
</equation>
<bodyText confidence="0.999961076923077">
where Y (Ω) is the set of all partial parses that have
the segmentation Ω; Z(w) is the set of all partial
parses for the input w.
Unfortunately, the shortest path algorithm is not
able to directly find the maximized P(Φ|w). Fully
searching all the paths is not practical, since there
are usually tens of thousands of passive edges. In
order to achieve a balance between accuracy and ef-
ficiency, two different approximation approaches are
taken.
One way is to assume that the component
log P(Ω|w) in Equation 3 has less significant ef-
fect on the quality of the partial parse. If this is
valid, then we can simply use − log P(ti|wi) as edge
weights, and use the shortest path algorithm to ob-
tain the best Φ. This will be referred to as model
I.
An alternative way is to first retrieve several
“good” Ω with relatively high P(Ω|w), and then se-
lect the best edges ti that maximize P(ti|wi) for
each wi in Ω. We call this approach the model II.
How well these strategies work will be evaluated
in Section 4. Other strategies or more sophisticated
searching algorithms (e.g., genetic algorithm) can
also be used, but we will leave that to future re-
search.
</bodyText>
<subsectionHeader confidence="0.986611">
3.4 Partial Semantic Construction
</subsectionHeader>
<bodyText confidence="0.999975733333333">
For each local analysis on the partial parse derived in
the above steps, a semantic fragment can be derived.
The HPSG grammars we use take a compositional
approach to semantic construction. Minimal Re-
cursion Semantics (MRS; Copestake et al. (2006))
is used for semantic representation. MRS can be
easily converted to (Robust) MRS (RMRS; Copes-
take (2006)), which allows further underspecifica-
tion, and can be used for integration of deep and/or
shallow processing tools.
For robust deep processing, the ability to gener-
ate partial semantics is very important. Moreover, it
also provides us with a way to evaluate the partial
parses which is more or less independent from the
syntactic analysis.
</bodyText>
<sectionHeader confidence="0.998806" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999984305555556">
The evaluation of partial parses is not as easy as the
evaluation of full parses. For full parsers, there are
generally two ways of evaluation. For parsers that
are trained on a treebank using an automatically ex-
tracted grammar, an unseen set of manually anno-
tated data is used as the test set. The parser out-
put on the test set is compared to the gold standard
annotation, either with the widely used PARSEVAL
measurement, or with more annotation-neutral de-
pendency relations. For parsers based on manually
compiled grammars, more human judgment is in-
volved in the evaluation. With the evolution of the
grammar, the treebank as the output from the gram-
mar changes over time (Oepen et al., 2002). The
grammar writer inspects the parses generated by the
grammar and either “accepts” or “rejects” the anal-
ysis.
In partial parsing for manually compiled gram-
mars, the criterion for acceptable analyses is less
evident. Most current treebanking tools are not de-
signed for annotating partial analyses. Large-scale
manually annotated treebanks do have the annota-
tion for sentences that deep grammars are not able
to fully analyze. And the annotation difference in
other language resources makes the comparison less
straightforward. More complication is involved with
the platform and resources used in our experiment.
Since the DELPH-IN grammars (ERG, JaCY, GG)
use MRS for semantics representation, there is no
reliable way of evaluating the output with traditional
metrics, i.e., dependency relations.
In this paper, we use both manual and automatic
evaluation methods on the partial parsing results.
Different processing resources are used to help the
evaluation from the syntactic, as well as the seman-
tic point of view.
</bodyText>
<subsectionHeader confidence="0.991859">
4.1 Syntactic Evaluation
</subsectionHeader>
<bodyText confidence="0.9992564">
In order to evaluate the quality of the syntactic struc-
tures of the partial parses, we implemented the par-
tial parse models described in the previous section
in the PET parser. The Nov-06 version of the ERG
is used for the experiment. As test set, we used a
</bodyText>
<page confidence="0.995902">
132
</page>
<bodyText confidence="0.999961962962963">
subset of sentences from the Wall Street Journal Sec-
tion 22 from the Penn Treebank. The subset contains
143 sentences which do not receive any full analysis
licensed by the grammar, and do not contain lexi-
cal gaps (input tokens for which the grammar can-
not create any lexical edge). The average sentence
length is 24 words.
Due to the inconsistency of the tokenisation,
bracketing and branching between the Penn Tree-
bank annotation and the handling in ERG, we manu-
ally checked the partial parse derivation trees. Each
output is marked as one of the three cases: GBL if
both the bracketing and the labeling of the partial
parse derivation trees are good (with no more than
two brackets crossing or four false labelings); GB if
the bracketings of the derivation trees are good (with
no more than two brackets crossing), but the label-
ing is bad (with more than four false labelings); or E
if otherwise.
The manual evaluation results are listed in Ta-
ble 1. The test set is processed with two models
presented in Section 3.3 (M-I for model I, M-II
for model II). For comparison, we also evaluate for
the approach using the shortest path with heuristic
weights (denoted by SP). In case there are more than
one path found with the same weight, only the first
one is recorded and evaluated.
</bodyText>
<table confidence="0.9985362">
GBL GB E
# % # % # %
SP 55 38.5% 64 44.8% 24 16.8%
M-I 61 42.7% 46 32.2% 36 25.2%
M-II 74 51.7% 50 35.0% 19 13.3%
</table>
<tableCaption confidence="0.999405">
Table 1: Syntactic Evaluation Results
</tableCaption>
<bodyText confidence="0.999406285714286">
The results show that the naive shortest path ap-
proach based on the heuristic weights works pretty
well at predicting the bracketing (with 83.3% of the
partial parses having less than two brackets cross-
ing). But, when the labeling is also evaluated it is
worse than model I, and even more significantly out-
performed by model II.
</bodyText>
<subsectionHeader confidence="0.996948">
4.2 Semantic Evaluation
</subsectionHeader>
<bodyText confidence="0.997696833333333">
Evaluation of the syntactic structure only reflects the
partial parse quality from some aspects. In order
to get a more thorough comparison between differ-
ent selection models, we look at the semantic output
generated from the partial parses.
The same set of 143 sentences from the Wall
Street Journal Section 22 of the Penn Treebank is
used. The RMRS semantic representations are gen-
erated from the partial parses with different selection
models. To compare with, we used RASP 2 (Briscoe
et al., 2006), a domain-independent robust parsing
system for English. According to (Briscoe and Car-
roll, 2006), the parser achieves fairly good accuracy
around 80%. The reasons why we choose RASP
for the evaluation are: i) RASP has reasonable cov-
erage and accuracy; ii) its output can be converted
into RMRS representation with the LKB system.
Since there is no large scale (R)MRS treebank with
sentences not covered by the DELPH-IN precision
grammars, we hope to use the RASP’s RMRS out-
put as a standalone annotation to help the evaluation
of the different partial parse selection models.
To compare the RMRS from the RASP and the
partial parse selection models, we used the simi-
larity measurement proposed in (Dridan and Bond,
2006). The comparison outputs a distance value be-
tween two different RMRSes. We normalized the
distance value to be between 0 and 1. For each se-
lection model, the average RMRS distance from the
RASP output is listed in Table 2.
</bodyText>
<table confidence="0.9824595">
RMRS Dist.(0)
SP 0.674
M-I 0.330
M-II 0.296
</table>
<tableCaption confidence="0.999471">
Table 2: RMRS distance to RASP outputs
</tableCaption>
<bodyText confidence="0.999798642857143">
Again, we see that the outputs of model II
achieve the highest similarity when compared with
the RASP output. With some manual validation,
we do confirm that the different similarity does im-
ply a significant difference in the quality of the out-
put RMRS. The shortest path with heuristic weights
yielded very poor semantic similarity. The main rea-
son is that not every edge with the same span gen-
erates the same semantics. Therefore, although the
SP receives reasonable bracketing accuracy, it has
less idea of the goodness of different edges with the
same span. By incorporating P(tz|wz) in the scoring
model, the model I and II can produce RMRSes with
much higher quality.
</bodyText>
<subsectionHeader confidence="0.9770485">
4.3 Evaluating partial parses on spontaneous
speech text
</subsectionHeader>
<bodyText confidence="0.99963425">
The above evaluation shows in a comparative way
that model II outperforms other selection models
from both syntactic and semantic points of view. In
order to show its competence in real applications,
</bodyText>
<page confidence="0.998023">
133
</page>
<bodyText confidence="0.99992055319149">
we applied the best performing model II on sponta-
neous speech transcripts, which have a high level of
informality and irregularity not available in newspa-
per texts such as the Wall Street Journal.
To evaluate the accuracy and potential interpre-
tational value of partial parsing on spontaneous
speech transcripts, we considered a 100-sentence
random sample of the Fisher Conversational Tele-
phone Speech 2004 development subcorpus (Cieri
et al., 2004), used in the fall 2004 NIST Rich Tran-
scription task.
Of these 100 sentences, six utterances received
neither full nor partial parses due to lexical gaps cre-
ated by words not found in the grammar’s lexicon.3
75 utterances produced full HPSG parses. For the
remaining 19 utterances, the one best partial parse is
found for each using model II.
According to manual evaluation of the output, se-
mantically and syntactically cohesive partial analy-
ses were successfully assigned to 9 of the 19 par-
tially parsed utterances. 3 of the 19 received incom-
plete semantics. The remaining 7 were judged to
be poor due to false segmentation, the syntax and
semantics within those parsed fragments, or both.
In one instance, the interpretation was plausible but
viewed as far less likely by the evaluator than the
preferable interpretation (“... [i think you know it it ’s]
[court]”4). It is likely that n-best partial parsing could
help us in most cases. This would only require a
straightforward extension of the current partial pars-
ing models.
Current partial parsing models do not use any con-
fidence thresholds. Therefore, any input will receive
some full or partial analysis (ignoring the case of
unknown words), together with semantics. Seman-
tic completeness is not checked in partial parsing. In
future research, we may consider finding a sophisti-
cated solution of assigning confidence scores to the
output RMRS fragments.
Overall though, we believe that the current 50%
acceptability of segmentation is reasonable perfor-
mance considering the types of noise in the speech
transcript input.
As a further step to show the competence of par-
tial parsing, we briefly investigated its application
in capturing disfluent regions in speech texts. The
state of the art approach in identifying disfluent re-
</bodyText>
<footnote confidence="0.99827575">
3Lexical prediction was not used here to avoid obfuscating
the quality of partial parsing by introducing lexical type predic-
tion errors.
4The repetition error of “it” is interpreted as a topicalization.
</footnote>
<bodyText confidence="0.999951137931035">
gions and potentially capturing meaningful text is a
shallow parsing method described in (Johnson and
Charniak, 2004), which searches the text string for
approximately repeated constituents. We ran their
system on our random sample of the Fisher data, and
compared its results to the partial parse output of the
nine well-segmented partial parses analyses (every
utterance of which contained some speaker-induced
disfluency) to see how well partial parsing could po-
tentially fare as an approach for identifying disfluent
regions of speech text.
Often the (Johnson and Charniak, 2004) method
identified disfluent regions overlapped with identi-
fied fragments found in the partial parse, the removal
of which would yield a fluent sentence. As we hope
to learn confidence measures to determine which
fragments are contentless or repetitive in the fu-
ture, we identified those partial parses where whole
fragments could be deleted to obtain a fluent and
meaning-preserving sentence.
In three cases, simple repeated phrases caught by
(Johnson and Charniak, 2004) were also caught in
some form by the partial parse partitioning. In an-
other case, the speaker interrupts one thought to say
another, and both approaches identify in a single
fragment the final fluent statement. Finally, of the
nine well-segmented utterances, two partial parses
potentially catch deeper speaker errors that cannot
be caught by (Johnson and Charniak, 2004).
</bodyText>
<sectionHeader confidence="0.997485" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999970947368421">
In this paper, we have presented work on partial
parse selection. Different selection models have
been presented and evaluated from syntactic and
semantic viewpoints. In the application of spon-
taneous speech text processing, the method shows
promising competence, as well as a few problems
for further study.
One thing we did not do is a systematic compar-
ison on the efficiency of different partial parse se-
lection models. Although it is clear that less search-
ing is involved with the shortest path approach and
model I comparing to model II, a scientific bench-
marking of such difference will be helpful for the
choice between efficiency and accuracy. Also, a
more sophisticated estimation of P(Q|w) can poten-
tially help the accuracy of the selection models.
Another alternative way of evaluation would be
to generate an ungrammatical corpus by randomly
introducing grammar errors. The performance of the
</bodyText>
<page confidence="0.995912">
134
</page>
<bodyText confidence="0.9997183">
partial parse selection models can be measured by
evaluating how much of the parsing results can be
recovered from original sentences.
In the study with spontaneous speech text pro-
cessing, we see a need for confidence measurement
for partial analyses. We also see that the conditional
probability P (ti|wi) does not serve as a good mea-
surement, for it largely depends on the structures
that can be licensed to wi by the grammar. This
should be explored in future studies, as well.
</bodyText>
<sectionHeader confidence="0.998972" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999849742268041">
Timothy Baldwin, Emily M. Bender, Dan Flickinger, Ara Kim,
and Stephan Oepen. 2004. Road-testing the English Re-
source Grammar over the British National Corpus. In Pro-
ceedings of the Fourth International Conference on Lan-
guage Resources and Evaluation (LREC 2004), Lisbon.
Ted Briscoe and John Carroll. 2006. Evaluating the accuracy
of an unlexicalized statistical parser on the PARC DepBank.
In Proceedings of the COLING/ACL 2006 Main Conference
Poster Sessions, pages 41–48, Sydney, Australia.
Ted Briscoe, John Carroll, and Rebecca Watson. 2006. The
second release of the RASP system. In Proceedings of the
COLING/ACL 2006Interactive Presentation Sessions, pages
77–80, Sydney, Australia.
Ulrich Callmeier. 2001. Efficient parsing with large-scale uni-
fication grammars. Master’s thesis, Universit¨at des Saarlan-
des, Saarbr¨ucken, Germany.
John Carroll and Stephan Oepen. 2005. High efficiency realiza-
tion for a wide-coverage unification grammar. In Proceed-
ings of the Second International Joint Conference on Natu-
ral Language Processing (IJCNLP05), pages 165–176, Jeju
Island, Korea.
Christopher Cieri, Stephanie Strassel, Mohamed Maamouri,
Shudong Huang, James Fiumara, David Graff, Kevin
Walker, and Mark L iberman. 2004. Linguistic resource
creation and distribution for EARS. In Proceedings of the
Rich Transcription Fall Workshop (RT-04F).
Ann Copestake, Dan Flickinger, Carl Pollard, and Ivan A. Sag.
2006. Minimal Recursion Semantics: an Introduction. Re-
search on Language and Computation, 3(4):281–332.
Ann Copestake. 2002. Implementing Typed Feature Structure
Grammars. CSLI, Stanford, CA.
Ann Copestake. 2006. Robust Minimal Recursion Se-
mantics. Working Paper, Unpublished Draft 2004/2006,
http://www.cl.cam.ac.uk/ aac10/papers.html.
Thomas H. Cormen, Charles E. Leiserson, and Ronald L.
Rivest. 1990. Introduction to Algorithms. MIT Press, MA.
Rebecca Dridan and Francis Bond. 2006. Sentence compari-
son using Robust Minimal Recursion Semantics and an on-
tology. In Proceedings of the ACL Workshop on Linguistic
Distances, pages 35–42, Sydney, Australia.
Dan Flickinger. 2000. On building a more efficient grammar by
exploiting types. Natural Language Engineering, 6(1):15–
28.
Mark Johnson and Eugene Charniak. 2004. A tag-based noisy-
channel model of speech repairs. In Proceedings of the 42nd
Meeting of the Association for Computational Linguistics
(ACL’04), Main Volume, pages 33–39, Barcelona, Spain.
Mark Johnson, Stuart Geman, Stephen Canon, Zhiyi Chi, and
Stefan Riezler. 1999. Estimators for stochastic unifcation-
based grammars. In Proceedings of the 37th Annual Meeting
of the ACL, pages 535–541, Maryland.
Walter Kasper, Bernd Kiefer, Hans-Ulrich Krieger, C.J. Rupp,
and Karsten Worm. 1999. Charting the depths of robust
speech processing. In Proceedings of the 37th Meeting of the
Association for Computational Linguistics (ACL’99), Main
Volume, pages 405–412, Maryland, USA, June.
Robert Malouf and Gertjan van Noord. 2004. Wide cover-
age parsing with stochastic attribute value grammars. In
IJCNLP-04 Workshop: Beyond shallow analyses - For-
malisms and statistical modeling for deep analyses.
Robert Malouf. 2002. A comparison of algorithms for max-
imum entropy parameter estimation. In Proceedings of the
Sixth Conferencde on Natural Language Learning (CoNLL-
2002), pages 49–55.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated corpus
of English. The Penn Treebank. Computational Linguistics,
19:313–330.
Stephan Oepen and John Carroll. 2000. Ambiguity packing in
constraint-based parsing — practical results. In Proceedings
of the 1st Conference of the North American Chapter of the
ACL, pages 162–169, Seattle, WA.
Stephan Oepen, Kristina Toutanova, Stuart Shieber, Christopher
Manning, Dan Flickinger, and Thorsten Brants. 2002. The
LinGO Redwoods treebank: Motivation and preliminary ap-
plications. In Proceedings of COLING 2002: The 17th Inter-
national Conference on Computational Linguistics: Project
Notes, Taipei.
Miles Osborne. 2000. Estimation of Stochastic Attribute-Value
Grammars using an Informative Sample. In The 18th In-
ternational Conference on Computational Linguistics (COL-
ING 2000), volume 1, pages 586–592, Saarbr¨ucken.
Stefan Riezler, Tracy H. King, Ronald M. Kaplan, Richard
Crouch, John T. III Maxwell, and Mark Johnson. 2002.
Parsing the Wall Street Journal using a Lexical-Functional
Grammar and Discriminative Estimation Techniques. In
Proceedings of the 40th Annual Meeting of the Association
for Computational Linguistics, pages 271–278, Philadelphia.
Kristina Toutanova, Christoper D. Manning, Stuart M. Shieber,
Dan Flickinger, and Stephan Oepen. 2002. Parse rank-
ing for a rich HPSG grammar. In Proceedings of the First
Workshop on Treebanks and Linguistic Theories (TLT2002),
pages 253–263, Sozopol, Bulgaria.
Gertjan van Noord, Gosse Bouma, Rob Koeling, and Mark-Jan
Nederhof. 1999. Robust grammatical analysis for spoken
dialogue systems. Natural language engineering, 5(1):45–
93.
</reference>
<page confidence="0.998776">
135
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.624556">
<title confidence="0.997227">Partial Parse Selection for Robust Deep Processing</title>
<affiliation confidence="0.857497666666667">of Computational Linguistics, Saarland University and DFKI GmbH, for Language &amp; Speech Dept of Electrical &amp; Computer Engineering, Johns Hopkins University,</affiliation>
<email confidence="0.999877">erin@clsp.jhu.edu</email>
<abstract confidence="0.997531769230769">This paper presents an approach to partial parse selection for robust deep processing. The work is based on a bottom-up chart parser for HPSG parsing. Following the definition of partial parses in (Kasper et al., 1999), different partial parse selection methods are presented and evaluated on the basis of multiple metrics, from both the syntactic and semantic viewpoints. The application of the partial parsing in spontaneous speech texts processing shows promising competence of the method.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Emily M Bender</author>
<author>Dan Flickinger</author>
<author>Ara Kim</author>
<author>Stephan Oepen</author>
</authors>
<title>Road-testing the English Resource Grammar over the British National Corpus.</title>
<date>2004</date>
<booktitle>In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC 2004),</booktitle>
<location>Lisbon.</location>
<contexts>
<context position="2056" citStr="Baldwin et al., 2004" startWordPosition="304" endWordPosition="307">tness of deep processing, for when a sentence is judged to be ungrammatical, normally no analysis is generated. When faced with the noisy inputs in real applications (e.g., input errors introduced by speech recognizers or other pre-processors, mildly ungrammatical sentences with fragmental utterances, selfediting chunks or filler words in spoken texts, and so forth), lack of robustness means poor coverage, and makes deep processing less competitive as compared to shallow methods. Take the English Resource Grammar (ERG; Flickinger (2000)), a large-scale accurate HPSG for English, for example. (Baldwin et al., 2004) reported coverage of 57% of the strings with full lexical span from the British National Corpus (BNC). Although recent extensions to the grammar and lexicon have improved the coverage significantly, full coverage over unseen texts by the grammar is still not anywhere in sight. Other domains are even more likely to not fit into ERG’s universe, such as transcripts of spontaneously produced speech where speaker errors and disfluencies are common. Using a recent version of the ERG, we are not able to parse 22.6% of a random sample of 500 utterances of conversational telephone speech data. 76.1% o</context>
</contexts>
<marker>Baldwin, Bender, Flickinger, Kim, Oepen, 2004</marker>
<rawString>Timothy Baldwin, Emily M. Bender, Dan Flickinger, Ara Kim, and Stephan Oepen. 2004. Road-testing the English Resource Grammar over the British National Corpus. In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC 2004), Lisbon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
</authors>
<title>Evaluating the accuracy of an unlexicalized statistical parser on the PARC DepBank.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions,</booktitle>
<pages>41--48</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="23979" citStr="Briscoe and Carroll, 2006" startWordPosition="4039" endWordPosition="4043">I. 4.2 Semantic Evaluation Evaluation of the syntactic structure only reflects the partial parse quality from some aspects. In order to get a more thorough comparison between different selection models, we look at the semantic output generated from the partial parses. The same set of 143 sentences from the Wall Street Journal Section 22 of the Penn Treebank is used. The RMRS semantic representations are generated from the partial parses with different selection models. To compare with, we used RASP 2 (Briscoe et al., 2006), a domain-independent robust parsing system for English. According to (Briscoe and Carroll, 2006), the parser achieves fairly good accuracy around 80%. The reasons why we choose RASP for the evaluation are: i) RASP has reasonable coverage and accuracy; ii) its output can be converted into RMRS representation with the LKB system. Since there is no large scale (R)MRS treebank with sentences not covered by the DELPH-IN precision grammars, we hope to use the RASP’s RMRS output as a standalone annotation to help the evaluation of the different partial parse selection models. To compare the RMRS from the RASP and the partial parse selection models, we used the similarity measurement proposed in</context>
</contexts>
<marker>Briscoe, Carroll, 2006</marker>
<rawString>Ted Briscoe and John Carroll. 2006. Evaluating the accuracy of an unlexicalized statistical parser on the PARC DepBank. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 41–48, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
<author>Rebecca Watson</author>
</authors>
<title>The second release of the RASP system.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006Interactive Presentation Sessions,</booktitle>
<pages>77--80</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="23881" citStr="Briscoe et al., 2006" startWordPosition="4026" endWordPosition="4029"> also evaluated it is worse than model I, and even more significantly outperformed by model II. 4.2 Semantic Evaluation Evaluation of the syntactic structure only reflects the partial parse quality from some aspects. In order to get a more thorough comparison between different selection models, we look at the semantic output generated from the partial parses. The same set of 143 sentences from the Wall Street Journal Section 22 of the Penn Treebank is used. The RMRS semantic representations are generated from the partial parses with different selection models. To compare with, we used RASP 2 (Briscoe et al., 2006), a domain-independent robust parsing system for English. According to (Briscoe and Carroll, 2006), the parser achieves fairly good accuracy around 80%. The reasons why we choose RASP for the evaluation are: i) RASP has reasonable coverage and accuracy; ii) its output can be converted into RMRS representation with the LKB system. Since there is no large scale (R)MRS treebank with sentences not covered by the DELPH-IN precision grammars, we hope to use the RASP’s RMRS output as a standalone annotation to help the evaluation of the different partial parse selection models. To compare the RMRS fr</context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString>Ted Briscoe, John Carroll, and Rebecca Watson. 2006. The second release of the RASP system. In Proceedings of the COLING/ACL 2006Interactive Presentation Sessions, pages 77–80, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Callmeier</author>
</authors>
<title>Efficient parsing with large-scale unification grammars.</title>
<date>2001</date>
<booktitle>Master’s thesis, Universit¨at des Saarlandes,</booktitle>
<location>Saarbr¨ucken, Germany.</location>
<contexts>
<context position="4385" citStr="Callmeier, 2001" startWordPosition="676" endWordPosition="677">iguation, the use of log-linear models has been pretty much standardized. However, it remains to be explored whether the techniques can be adapted for partial parse selection. In this paper, we adopt the same definition for partial parse as in (Kasper et al., 1999) and define the task of partial parse selection. Several dif128 Proceedings of the ACL 2007 Workshop on Deep Linguistic Processing, pages 128–135, Prague, Czech Republic, June, 2007. @2007 Association for Computational Linguistics ferent partial parse selection models are presented and implemented for an efficient HPSG parser – PET (Callmeier, 2001). One of the main difficulties in the research of partial analyses is the lack of good evaluation measurements. Pure syntactic comparisons for parser evaluation are not good as they are very much specific to the annotation guidelines. Also, the deep grammars we are working with are not automatically extracted from annotated corpora. Therefore, unless there are partial treebanks built specifically for the deep grammars, there is simply no ‘gold’ standard for non-golden partial analyses. Instead, in this paper, we evaluate the partial analyses results on the basis of multiple metrics, from both </context>
</contexts>
<marker>Callmeier, 2001</marker>
<rawString>Ulrich Callmeier. 2001. Efficient parsing with large-scale unification grammars. Master’s thesis, Universit¨at des Saarlandes, Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Stephan Oepen</author>
</authors>
<title>High efficiency realization for a wide-coverage unification grammar.</title>
<date>2005</date>
<booktitle>In Proceedings of the Second International Joint Conference on Natural Language Processing (IJCNLP05),</booktitle>
<pages>165--176</pages>
<location>Jeju Island,</location>
<contexts>
<context position="9537" citStr="Carroll and Oepen, 2005" startWordPosition="1536" endWordPosition="1539">he local ambiguity packing poses an efficiency and accuracy challenge, as not all the intermediate parsing results are directly available as passive edges on the chart. Without unpacking the ambiguity readings, interesting partial analyses might be lost.2 But exhaustively unpacking all the readings will pay back the efficiency gain by ambiguity packing, and eventually lead to computational intractable results. To efficiently recover the ambiguous readings from packed representations, the selective unpacking algorithm has been recently implemented as an extension to the algorithm described in (Carroll and Oepen, 2005). It is able to recover the top-n best readings of a given passive parser edge based on the score assigned by a maximum entropy parse ranking model. This neat feature largely facilitates the efficient searching for best partial parses described in later sections. 3 Partial Parse Selection A partial parse is a set of partial analyses licensed by the grammar which cover the entire input without overlapping. As shown in the previous section, there are usually more than one possible partial parses for a given input. For deep linguistic processing, a high level of local ambiguity means there are ev</context>
</contexts>
<marker>Carroll, Oepen, 2005</marker>
<rawString>John Carroll and Stephan Oepen. 2005. High efficiency realization for a wide-coverage unification grammar. In Proceedings of the Second International Joint Conference on Natural Language Processing (IJCNLP05), pages 165–176, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Cieri</author>
<author>Stephanie Strassel</author>
<author>Mohamed Maamouri</author>
<author>Shudong Huang</author>
<author>James Fiumara</author>
<author>David Graff</author>
<author>Kevin Walker</author>
<author>Mark L iberman</author>
</authors>
<title>Linguistic resource creation and distribution for EARS.</title>
<date>2004</date>
<booktitle>In Proceedings of the Rich Transcription Fall Workshop (RT-04F).</booktitle>
<contexts>
<context position="26293" citStr="Cieri et al., 2004" startWordPosition="4424" endWordPosition="4427">mparative way that model II outperforms other selection models from both syntactic and semantic points of view. In order to show its competence in real applications, 133 we applied the best performing model II on spontaneous speech transcripts, which have a high level of informality and irregularity not available in newspaper texts such as the Wall Street Journal. To evaluate the accuracy and potential interpretational value of partial parsing on spontaneous speech transcripts, we considered a 100-sentence random sample of the Fisher Conversational Telephone Speech 2004 development subcorpus (Cieri et al., 2004), used in the fall 2004 NIST Rich Transcription task. Of these 100 sentences, six utterances received neither full nor partial parses due to lexical gaps created by words not found in the grammar’s lexicon.3 75 utterances produced full HPSG parses. For the remaining 19 utterances, the one best partial parse is found for each using model II. According to manual evaluation of the output, semantically and syntactically cohesive partial analyses were successfully assigned to 9 of the 19 partially parsed utterances. 3 of the 19 received incomplete semantics. The remaining 7 were judged to be poor d</context>
</contexts>
<marker>Cieri, Strassel, Maamouri, Huang, Fiumara, Graff, Walker, iberman, 2004</marker>
<rawString>Christopher Cieri, Stephanie Strassel, Mohamed Maamouri, Shudong Huang, James Fiumara, David Graff, Kevin Walker, and Mark L iberman. 2004. Linguistic resource creation and distribution for EARS. In Proceedings of the Rich Transcription Fall Workshop (RT-04F).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
<author>Carl Pollard</author>
<author>Ivan A Sag</author>
</authors>
<title>Minimal Recursion Semantics: an Introduction.</title>
<date>2006</date>
<journal>Research on Language and Computation,</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="19127" citStr="Copestake et al. (2006)" startWordPosition="3221" endWordPosition="3224">atively high P(Ω|w), and then select the best edges ti that maximize P(ti|wi) for each wi in Ω. We call this approach the model II. How well these strategies work will be evaluated in Section 4. Other strategies or more sophisticated searching algorithms (e.g., genetic algorithm) can also be used, but we will leave that to future research. 3.4 Partial Semantic Construction For each local analysis on the partial parse derived in the above steps, a semantic fragment can be derived. The HPSG grammars we use take a compositional approach to semantic construction. Minimal Recursion Semantics (MRS; Copestake et al. (2006)) is used for semantic representation. MRS can be easily converted to (Robust) MRS (RMRS; Copestake (2006)), which allows further underspecification, and can be used for integration of deep and/or shallow processing tools. For robust deep processing, the ability to generate partial semantics is very important. Moreover, it also provides us with a way to evaluate the partial parses which is more or less independent from the syntactic analysis. 4 Evaluation The evaluation of partial parses is not as easy as the evaluation of full parses. For full parsers, there are generally two ways of evaluati</context>
</contexts>
<marker>Copestake, Flickinger, Pollard, Sag, 2006</marker>
<rawString>Ann Copestake, Dan Flickinger, Carl Pollard, and Ivan A. Sag. 2006. Minimal Recursion Semantics: an Introduction. Research on Language and Computation, 3(4):281–332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
</authors>
<title>Implementing Typed Feature Structure Grammars.</title>
<date>2002</date>
<location>CSLI, Stanford, CA.</location>
<contexts>
<context position="6444" citStr="Copestake, 2002" startWordPosition="1025" endWordPosition="1026">is essentially a bottom-up chart parser. The parsing process is guided by the parsing tasks on an agenda. A parsing task represents the combination of a passive chart edge and an active chart edge or a rule. When the combination succeeds, new tasks are generated and put on to the agenda. The parser terminates either when the task agenda is empty or when a specific number of full analyses has been found (only in the no-packing best-first mode). HPSG grammars use typed feature structures (TFSes) as their background formalism. The TFSes represent various linguistic objects with a set of fea1LKB (Copestake, 2002) has a similar chart-based parser, being less efficient mainly due to its implementation in Lisp rather than C/C++. tures (attribute value pairs) and a type inheritance system. Therefore, each passive edge on the parsing chart corresponds to a TFS. A relatively small set of highly generalized rules are used to check the compatibility among smaller TFSes and build up larger ones. 2.2 Partial Parses Based on the bottom-up chart parsing, we use the term Partial Parse to describe a set of intermediate passive parsing edges whose spans (beginning and end positions) are non-overlapping between each </context>
</contexts>
<marker>Copestake, 2002</marker>
<rawString>Ann Copestake. 2002. Implementing Typed Feature Structure Grammars. CSLI, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
</authors>
<title>Robust Minimal Recursion Semantics. Working Paper, Unpublished Draft 2004/2006,</title>
<date>2006</date>
<note>http://www.cl.cam.ac.uk/ aac10/papers.html.</note>
<contexts>
<context position="19233" citStr="Copestake (2006)" startWordPosition="3239" endWordPosition="3241">oach the model II. How well these strategies work will be evaluated in Section 4. Other strategies or more sophisticated searching algorithms (e.g., genetic algorithm) can also be used, but we will leave that to future research. 3.4 Partial Semantic Construction For each local analysis on the partial parse derived in the above steps, a semantic fragment can be derived. The HPSG grammars we use take a compositional approach to semantic construction. Minimal Recursion Semantics (MRS; Copestake et al. (2006)) is used for semantic representation. MRS can be easily converted to (Robust) MRS (RMRS; Copestake (2006)), which allows further underspecification, and can be used for integration of deep and/or shallow processing tools. For robust deep processing, the ability to generate partial semantics is very important. Moreover, it also provides us with a way to evaluate the partial parses which is more or less independent from the syntactic analysis. 4 Evaluation The evaluation of partial parses is not as easy as the evaluation of full parses. For full parsers, there are generally two ways of evaluation. For parsers that are trained on a treebank using an automatically extracted grammar, an unseen set of </context>
</contexts>
<marker>Copestake, 2006</marker>
<rawString>Ann Copestake. 2006. Robust Minimal Recursion Semantics. Working Paper, Unpublished Draft 2004/2006, http://www.cl.cam.ac.uk/ aac10/papers.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas H Cormen</author>
<author>Charles E Leiserson</author>
<author>Ronald L Rivest</author>
</authors>
<title>Introduction to Algorithms.</title>
<date>1990</date>
<publisher>MIT Press,</publisher>
<location>MA.</location>
<contexts>
<context position="12528" citStr="Cormen et al., 1990" startWordPosition="2044" endWordPosition="2047">999) proposed an alternative solution to the problem. If the preference of each edge as a part of the partial parse can be quantitatively decided as a weight of the edge (with smaller weights assigned to better candidates), then the problem of finding the best partial parse is to find the shortest path from the start vertex to the end vertex. Since the graph is completely connected (by the lexical edges spanning all the input tokens) and topologically sorted, such a path always exists. The discovery of such a path can be done in linear time (O(|V |+ |E|)) with the DAG-shortest-path algorithm (Cormen et al., 1990). Though not explicitly pointed out by (Kasper et al., 1999), such an algorithm allows the weights of the edges to be of any real value (no assumption of positive weights) as long as the graph is a Directed Acyclic Graph (DAG). (Kasper et al., 1999) did point out that the weights of the edges can be assigned by an estimation function. For example, the implementation of the algorithm in PET preferred phrasal edges over lexical edges. Other types of edges are not allowed in the partial parse. Suppose that we assign weight 1 to phrasal edges, 2 to lexical edges, and inf to all other edges. Then f</context>
</contexts>
<marker>Cormen, Leiserson, Rivest, 1990</marker>
<rawString>Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest. 1990. Introduction to Algorithms. MIT Press, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Dridan</author>
<author>Francis Bond</author>
</authors>
<title>Sentence comparison using Robust Minimal Recursion Semantics and an ontology.</title>
<date>2006</date>
<booktitle>In Proceedings of the ACL Workshop on Linguistic Distances,</booktitle>
<pages>35--42</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="24603" citStr="Dridan and Bond, 2006" startWordPosition="4145" endWordPosition="4148">the parser achieves fairly good accuracy around 80%. The reasons why we choose RASP for the evaluation are: i) RASP has reasonable coverage and accuracy; ii) its output can be converted into RMRS representation with the LKB system. Since there is no large scale (R)MRS treebank with sentences not covered by the DELPH-IN precision grammars, we hope to use the RASP’s RMRS output as a standalone annotation to help the evaluation of the different partial parse selection models. To compare the RMRS from the RASP and the partial parse selection models, we used the similarity measurement proposed in (Dridan and Bond, 2006). The comparison outputs a distance value between two different RMRSes. We normalized the distance value to be between 0 and 1. For each selection model, the average RMRS distance from the RASP output is listed in Table 2. RMRS Dist.(0) SP 0.674 M-I 0.330 M-II 0.296 Table 2: RMRS distance to RASP outputs Again, we see that the outputs of model II achieve the highest similarity when compared with the RASP output. With some manual validation, we do confirm that the different similarity does imply a significant difference in the quality of the output RMRS. The shortest path with heuristic weights</context>
</contexts>
<marker>Dridan, Bond, 2006</marker>
<rawString>Rebecca Dridan and Francis Bond. 2006. Sentence comparison using Robust Minimal Recursion Semantics and an ontology. In Proceedings of the ACL Workshop on Linguistic Distances, pages 35–42, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Flickinger</author>
</authors>
<title>On building a more efficient grammar by exploiting types.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<volume>6</volume>
<issue>1</issue>
<pages>28</pages>
<contexts>
<context position="1977" citStr="Flickinger (2000)" startWordPosition="293" endWordPosition="294">modeling of language itself. However, this feature largely limits the robustness of deep processing, for when a sentence is judged to be ungrammatical, normally no analysis is generated. When faced with the noisy inputs in real applications (e.g., input errors introduced by speech recognizers or other pre-processors, mildly ungrammatical sentences with fragmental utterances, selfediting chunks or filler words in spoken texts, and so forth), lack of robustness means poor coverage, and makes deep processing less competitive as compared to shallow methods. Take the English Resource Grammar (ERG; Flickinger (2000)), a large-scale accurate HPSG for English, for example. (Baldwin et al., 2004) reported coverage of 57% of the strings with full lexical span from the British National Corpus (BNC). Although recent extensions to the grammar and lexicon have improved the coverage significantly, full coverage over unseen texts by the grammar is still not anywhere in sight. Other domains are even more likely to not fit into ERG’s universe, such as transcripts of spontaneously produced speech where speaker errors and disfluencies are common. Using a recent version of the ERG, we are not able to parse 22.6% of a r</context>
</contexts>
<marker>Flickinger, 2000</marker>
<rawString>Dan Flickinger. 2000. On building a more efficient grammar by exploiting types. Natural Language Engineering, 6(1):15– 28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
<author>Eugene Charniak</author>
</authors>
<title>A tag-based noisychannel model of speech repairs.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL’04), Main Volume,</booktitle>
<pages>33--39</pages>
<location>Barcelona,</location>
<contexts>
<context position="28399" citStr="Johnson and Charniak, 2004" startWordPosition="4762" endWordPosition="4765">egmentation is reasonable performance considering the types of noise in the speech transcript input. As a further step to show the competence of partial parsing, we briefly investigated its application in capturing disfluent regions in speech texts. The state of the art approach in identifying disfluent re3Lexical prediction was not used here to avoid obfuscating the quality of partial parsing by introducing lexical type prediction errors. 4The repetition error of “it” is interpreted as a topicalization. gions and potentially capturing meaningful text is a shallow parsing method described in (Johnson and Charniak, 2004), which searches the text string for approximately repeated constituents. We ran their system on our random sample of the Fisher data, and compared its results to the partial parse output of the nine well-segmented partial parses analyses (every utterance of which contained some speaker-induced disfluency) to see how well partial parsing could potentially fare as an approach for identifying disfluent regions of speech text. Often the (Johnson and Charniak, 2004) method identified disfluent regions overlapped with identified fragments found in the partial parse, the removal of which would yield</context>
<context position="29709" citStr="Johnson and Charniak, 2004" startWordPosition="4963" endWordPosition="4966">ments are contentless or repetitive in the future, we identified those partial parses where whole fragments could be deleted to obtain a fluent and meaning-preserving sentence. In three cases, simple repeated phrases caught by (Johnson and Charniak, 2004) were also caught in some form by the partial parse partitioning. In another case, the speaker interrupts one thought to say another, and both approaches identify in a single fragment the final fluent statement. Finally, of the nine well-segmented utterances, two partial parses potentially catch deeper speaker errors that cannot be caught by (Johnson and Charniak, 2004). 5 Conclusion and Future Work In this paper, we have presented work on partial parse selection. Different selection models have been presented and evaluated from syntactic and semantic viewpoints. In the application of spontaneous speech text processing, the method shows promising competence, as well as a few problems for further study. One thing we did not do is a systematic comparison on the efficiency of different partial parse selection models. Although it is clear that less searching is involved with the shortest path approach and model I comparing to model II, a scientific benchmarking </context>
</contexts>
<marker>Johnson, Charniak, 2004</marker>
<rawString>Mark Johnson and Eugene Charniak. 2004. A tag-based noisychannel model of speech repairs. In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL’04), Main Volume, pages 33–39, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
<author>Stuart Geman</author>
<author>Stephen Canon</author>
<author>Zhiyi Chi</author>
<author>Stefan Riezler</author>
</authors>
<title>Estimators for stochastic unifcationbased grammars.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the ACL,</booktitle>
<pages>535--541</pages>
<location>Maryland.</location>
<contexts>
<context position="15035" citStr="Johnson et al., 1999" startWordPosition="2474" endWordPosition="2477">mation Functions Generally speaking, the weights of the edges in the shortest path approach represent the quality of the local analyses and their likelihood of appearing in the analysis of the entire input. This is an interesting parallel to the parse selection models for the full analyses, where a goodness score is usually assigned to the full analysis. For example, the parse disambiguation model described in (Toutanova et al., 2002) uses a maximum entropy approach to model the conditional probability of a parse for a given input sequence P(t|w). A similar approach has also been reported in (Johnson et al., 1999; Riezler et al., 2002; Malouf and van Noord, 2004). For a given partial parse `b = {t1, ... , tk}, Q = {w1, ... , wk} is a segmentation of the input sequence so that each local analysis ti ∈ `b corresponds to a substring wi ∈ Q of the input sequence w. Therefore, the probability of the partial parse `b given an input sequence w is: P(`b|w) = P(Q|w) · P(`b|Q) (1) With the bold assumption that P(ti|wi) are mutually independent for different i, we can derive: k P(`b|w) ≈ P(Q|w) · P(ti|wi) (2) i=1 Therefore, the log-probability will be k log P(`b|w) ≈ log P(Q|w) + log P(ti|wi) (3) i=1 Equation 3 </context>
</contexts>
<marker>Johnson, Geman, Canon, Chi, Riezler, 1999</marker>
<rawString>Mark Johnson, Stuart Geman, Stephen Canon, Zhiyi Chi, and Stefan Riezler. 1999. Estimators for stochastic unifcationbased grammars. In Proceedings of the 37th Annual Meeting of the ACL, pages 535–541, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Kasper</author>
<author>Bernd Kiefer</author>
<author>Hans-Ulrich Krieger</author>
<author>C J Rupp</author>
<author>Karsten Worm</author>
</authors>
<title>Charting the depths of robust speech processing.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Meeting of the Association for Computational Linguistics (ACL’99), Main Volume,</booktitle>
<pages>405--412</pages>
<location>Maryland, USA,</location>
<contexts>
<context position="3488" citStr="Kasper et al., 1999" startWordPosition="532" endWordPosition="535">ing and interpreting the substrings in the utterance which have coherent deep syntax is useful both for semantic analysis and as building blocks for attempts to reconstruct the disfluent spontaneously produced utterances into wellformed sentences. For these reasons, it is preferable to exploit the intermediate syntactic and semantic analysis even if the full analysis is not available. Various efforts have been made on the partiality of language processing. In bottom-up chart parsing, the passive parser edges licensed by the grammar can be taken as partial analyses. However, as pointed out in (Kasper et al., 1999), not all passive edges are good candidates, as not all of them provide useful syntactic/semantic information. Moreover, the huge amount of passive edges suggests the need for a technique of selecting an optimal subset of them. During recent development in statistical parse disambiguation, the use of log-linear models has been pretty much standardized. However, it remains to be explored whether the techniques can be adapted for partial parse selection. In this paper, we adopt the same definition for partial parse as in (Kasper et al., 1999) and define the task of partial parse selection. Sever</context>
<context position="8116" citStr="Kasper et al., 1999" startWordPosition="1318" endWordPosition="1321">the beginning position of the input) to the terminal vertex (the end position of the input). Suppose in chart parsing, we derived the intermediate results as in Figure 1. There are in total 4 possible partial parses: {a, b, c, d}, {a, b, f}, {a, e, d} and {a, g}. w1 w2 w3 w4 0 1 2 3 4 e f a b c d g Figure 1: Graph representation of intermediate chart parsing results Note that each passive edge is a sub-structure licensed by the grammar. A derivation tree or TFS can be reconstructed for it if required. This definition of partial parse is effectively the same to the view of partial analyses in (Kasper et al., 1999). 2.3 Local Ambiguity Packing There is one more complication concerning the partial parses when the local ambiguity packing is used in the parser. Due to the inherent ambiguity of natural language, the same sequence of input may be analyzed as the same linguistic object in different ways. Such intermediate analyses must be recorded during the processing and recovered in later stages. 129 Without any efficient processing technique, parsing becomes computationally intractable with the combinatory explosion of such local ambiguities. In PET, the subsumption-based ambiguity packing algorithm propo</context>
<context position="11912" citStr="Kasper et al., 1999" startWordPosition="1933" endWordPosition="1936">he logic behind this criterion is that such largest fragments should preserve the most interesting linguistic analysis of the input. As an added incentive, finding the longest edge does not involve much search. The limitations of such an approach are obvious. There is no guarantee that the longest edge will be significantly better than shorter edges, or that it will even correspond to a valid constituent. Moreover, when there are multiple edges with the same length (which is often the case in parsing), the criterion does not suffice for the choice of the best partial parse. 3.2 Shortest Path (Kasper et al., 1999) proposed an alternative solution to the problem. If the preference of each edge as a part of the partial parse can be quantitatively decided as a weight of the edge (with smaller weights assigned to better candidates), then the problem of finding the best partial parse is to find the shortest path from the start vertex to the end vertex. Since the graph is completely connected (by the lexical edges spanning all the input tokens) and topologically sorted, such a path always exists. The discovery of such a path can be done in linear time (O(|V |+ |E|)) with the DAG-shortest-path algorithm (Corm</context>
<context position="13504" citStr="Kasper et al., 1999" startWordPosition="2227" endWordPosition="2230">plementation of the algorithm in PET preferred phrasal edges over lexical edges. Other types of edges are not allowed in the partial parse. Suppose that we assign weight 1 to phrasal edges, 2 to lexical edges, and inf to all other edges. Then for the graph in 2, the best partial parses are {e, g} and {f, g}, both of which have 130 the path length of 2. It should be noted that such an approach does not always favor the paths with the longest edges (i.e., path {h, d} is not preferred in the given example). Figure 2: Shortest path partial parses with heuristically assigned edge weights However, (Kasper et al., 1999) did not provide any sophisticated estimation functions based on the shortest path approach. Using the heuristic weight described above, usually thousands of different paths are found with the same weight. (Kasper et al., 1999) rely on another scoring function in order to re-rank the partial parses. Although different requirements for the scoring function are discussed, no further details have been defined. It should be noted that different variations of the shortest path approach are widely in use in many robust deep parsing systems. For instance, (Riezler et al., 2002) uses the fewest chunk </context>
</contexts>
<marker>Kasper, Kiefer, Krieger, Rupp, Worm, 1999</marker>
<rawString>Walter Kasper, Bernd Kiefer, Hans-Ulrich Krieger, C.J. Rupp, and Karsten Worm. 1999. Charting the depths of robust speech processing. In Proceedings of the 37th Meeting of the Association for Computational Linguistics (ACL’99), Main Volume, pages 405–412, Maryland, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Malouf</author>
<author>Gertjan van Noord</author>
</authors>
<title>Wide coverage parsing with stochastic attribute value grammars.</title>
<date>2004</date>
<booktitle>In IJCNLP-04 Workshop: Beyond</booktitle>
<marker>Malouf, van Noord, 2004</marker>
<rawString>Robert Malouf and Gertjan van Noord. 2004. Wide coverage parsing with stochastic attribute value grammars. In IJCNLP-04 Workshop: Beyond shallow analyses - Formalisms and statistical modeling for deep analyses.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Malouf</author>
</authors>
<title>A comparison of algorithms for maximum entropy parameter estimation.</title>
<date>2002</date>
<booktitle>In Proceedings of the Sixth Conferencde on Natural Language Learning (CoNLL2002),</booktitle>
<pages>49--55</pages>
<contexts>
<context position="16474" citStr="Malouf, 2002" startWordPosition="2746" endWordPosition="2747">ity of the segmentation. If we use − log P(ti|wi) as the weight for each local analysis, then the DAG shortest path algorithm will quickly find the partial parse that maximizes log P(`b|w) − log P(Q|w). The probability P (ti|wi) can be modeled in a similar way to the maximum entropy based full parse selection models: exp En j=1 ajfj(ti, wi) P(ti|wi) = (4) Et′ ∈T exp Enj =1 aj fj (t′, wi) where T is the set of all possible structures that can be assigned to wi, f1 ... fn are the features and a1 ... an are the parameters. The parameters can be efficiently estimated from a treebank, as shown by (Malouf, 2002). The only difference from the full parse selection model is that here intermediate results are used to generate events for training the model (i.e. the intermediate nodes are used as positive events if it occurs on one of the active tree, or as negative events if not). Since there is a huge number of intermediate results availalbe, we only randomly select a part of them as training data. This is essentially similar to the approach in (Osborne, 2000), where there is an infeasibly large number of training events, only part of which is used in the estimation step. The exact features used in the </context>
</contexts>
<marker>Malouf, 2002</marker>
<rawString>Robert Malouf. 2002. A comparison of algorithms for maximum entropy parameter estimation. In Proceedings of the Sixth Conferencde on Natural Language Learning (CoNLL2002), pages 49–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English. The Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="5182" citStr="Marcus et al., 1993" startWordPosition="810" endWordPosition="813">they are very much specific to the annotation guidelines. Also, the deep grammars we are working with are not automatically extracted from annotated corpora. Therefore, unless there are partial treebanks built specifically for the deep grammars, there is simply no ‘gold’ standard for non-golden partial analyses. Instead, in this paper, we evaluate the partial analyses results on the basis of multiple metrics, from both the syntactic and semantic point of views. Empirical evaluation has been done with the ERG on a small set of texts from the Wall Street Journal Section 22 of the Penn Treebank (Marcus et al., 1993). A pilot study of applying partial parsing in spontaneous speech text processing is also carried out. The remainder of the paper is organized as follow. Section 2 provides background knowledge about partial analysis. Section 3 presents various partial parse selection models. Section 4 describes the evaluation setup and results. Section 5 concludes the paper. 2 Partial Parsing 2.1 HPSG Parsing Our work on partial parsing is done with the DELPH-IN HPSG grammars. Many of these grammars can be used for both parsing and generation. In this paper, we only focus on the parsing task. For efficient pa</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English. The Penn Treebank. Computational Linguistics, 19:313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Oepen</author>
<author>John Carroll</author>
</authors>
<title>Ambiguity packing in constraint-based parsing — practical results.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st Conference of the North American Chapter of the ACL,</booktitle>
<pages>162--169</pages>
<location>Seattle, WA.</location>
<contexts>
<context position="8748" citStr="Oepen and Carroll, 2000" startWordPosition="1416" endWordPosition="1419">cal Ambiguity Packing There is one more complication concerning the partial parses when the local ambiguity packing is used in the parser. Due to the inherent ambiguity of natural language, the same sequence of input may be analyzed as the same linguistic object in different ways. Such intermediate analyses must be recorded during the processing and recovered in later stages. 129 Without any efficient processing technique, parsing becomes computationally intractable with the combinatory explosion of such local ambiguities. In PET, the subsumption-based ambiguity packing algorithm proposed in (Oepen and Carroll, 2000) is used. This separates the parsing into two phases: forest creation phase and read-out/unpacking phase. In relation to the work on partial parsing in this paper, the local ambiguity packing poses an efficiency and accuracy challenge, as not all the intermediate parsing results are directly available as passive edges on the chart. Without unpacking the ambiguity readings, interesting partial analyses might be lost.2 But exhaustively unpacking all the readings will pay back the efficiency gain by ambiguity packing, and eventually lead to computational intractable results. To efficiently recove</context>
</contexts>
<marker>Oepen, Carroll, 2000</marker>
<rawString>Stephan Oepen and John Carroll. 2000. Ambiguity packing in constraint-based parsing — practical results. In Proceedings of the 1st Conference of the North American Chapter of the ACL, pages 162–169, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Oepen</author>
<author>Kristina Toutanova</author>
<author>Stuart Shieber</author>
<author>Christopher Manning</author>
<author>Dan Flickinger</author>
<author>Thorsten Brants</author>
</authors>
<title>The LinGO Redwoods treebank: Motivation and preliminary applications.</title>
<date>2002</date>
<booktitle>In Proceedings of COLING 2002: The 17th International Conference on Computational Linguistics: Project Notes,</booktitle>
<location>Taipei.</location>
<contexts>
<context position="20282" citStr="Oepen et al., 2002" startWordPosition="3414" endWordPosition="3417">rses. For full parsers, there are generally two ways of evaluation. For parsers that are trained on a treebank using an automatically extracted grammar, an unseen set of manually annotated data is used as the test set. The parser output on the test set is compared to the gold standard annotation, either with the widely used PARSEVAL measurement, or with more annotation-neutral dependency relations. For parsers based on manually compiled grammars, more human judgment is involved in the evaluation. With the evolution of the grammar, the treebank as the output from the grammar changes over time (Oepen et al., 2002). The grammar writer inspects the parses generated by the grammar and either “accepts” or “rejects” the analysis. In partial parsing for manually compiled grammars, the criterion for acceptable analyses is less evident. Most current treebanking tools are not designed for annotating partial analyses. Large-scale manually annotated treebanks do have the annotation for sentences that deep grammars are not able to fully analyze. And the annotation difference in other language resources makes the comparison less straightforward. More complication is involved with the platform and resources used in </context>
</contexts>
<marker>Oepen, Toutanova, Shieber, Manning, Flickinger, Brants, 2002</marker>
<rawString>Stephan Oepen, Kristina Toutanova, Stuart Shieber, Christopher Manning, Dan Flickinger, and Thorsten Brants. 2002. The LinGO Redwoods treebank: Motivation and preliminary applications. In Proceedings of COLING 2002: The 17th International Conference on Computational Linguistics: Project Notes, Taipei.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miles Osborne</author>
</authors>
<title>Estimation of Stochastic Attribute-Value Grammars using an Informative Sample.</title>
<date>2000</date>
<booktitle>In The 18th International Conference on Computational Linguistics (COLING</booktitle>
<volume>1</volume>
<pages>586--592</pages>
<contexts>
<context position="16928" citStr="Osborne, 2000" startWordPosition="2826" endWordPosition="2827">gned to wi, f1 ... fn are the features and a1 ... an are the parameters. The parameters can be efficiently estimated from a treebank, as shown by (Malouf, 2002). The only difference from the full parse selection model is that here intermediate results are used to generate events for training the model (i.e. the intermediate nodes are used as positive events if it occurs on one of the active tree, or as negative events if not). Since there is a huge number of intermediate results availalbe, we only randomly select a part of them as training data. This is essentially similar to the approach in (Osborne, 2000), where there is an infeasibly large number of training events, only part of which is used in the estimation step. The exact features used in the log-linear model can significantly influence the disambiguation accuracy. In this experiment we used the same features e :1 g:1 w1 w2 w3 w4 0 1 2 3 4 a :2 b :2 c:2 d:2 f:1 h:1 i: 8 131 as those used in the PCFG-S model in (Toutanova et al., 2002) (i.e., depth-1 derivation trees). The estimation of P(Ω|w) is more difficult. In a sense it is similar to a segmentation or chunking model, where the task is to segment the input into fragments. However, it </context>
</contexts>
<marker>Osborne, 2000</marker>
<rawString>Miles Osborne. 2000. Estimation of Stochastic Attribute-Value Grammars using an Informative Sample. In The 18th International Conference on Computational Linguistics (COLING 2000), volume 1, pages 586–592, Saarbr¨ucken.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Riezler</author>
<author>Tracy H King</author>
<author>Ronald M Kaplan</author>
<author>Richard Crouch</author>
<author>John T Maxwell</author>
<author>Mark Johnson</author>
</authors>
<title>Parsing the Wall Street Journal using a Lexical-Functional Grammar and Discriminative Estimation Techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>271--278</pages>
<location>Philadelphia.</location>
<contexts>
<context position="14081" citStr="Riezler et al., 2002" startWordPosition="2320" endWordPosition="2323"> edge weights However, (Kasper et al., 1999) did not provide any sophisticated estimation functions based on the shortest path approach. Using the heuristic weight described above, usually thousands of different paths are found with the same weight. (Kasper et al., 1999) rely on another scoring function in order to re-rank the partial parses. Although different requirements for the scoring function are discussed, no further details have been defined. It should be noted that different variations of the shortest path approach are widely in use in many robust deep parsing systems. For instance, (Riezler et al., 2002) uses the fewest chunk method to choose the best fragment analyses for sentences without full analysis. The well-formed chunks are preferred over token chunks. With this partial parse selection method, the grammar achieves 100% coverage on unseen data. A similar approach is also used in (van Noord et al., 1999). 3.3 Alternative Estimation Functions Generally speaking, the weights of the edges in the shortest path approach represent the quality of the local analyses and their likelihood of appearing in the analysis of the entire input. This is an interesting parallel to the parse selection mode</context>
</contexts>
<marker>Riezler, King, Kaplan, Crouch, Maxwell, Johnson, 2002</marker>
<rawString>Stefan Riezler, Tracy H. King, Ronald M. Kaplan, Richard Crouch, John T. III Maxwell, and Mark Johnson. 2002. Parsing the Wall Street Journal using a Lexical-Functional Grammar and Discriminative Estimation Techniques. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 271–278, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Christoper D Manning</author>
<author>Stuart M Shieber</author>
<author>Dan Flickinger</author>
<author>Stephan Oepen</author>
</authors>
<title>Parse ranking for a rich HPSG grammar.</title>
<date>2002</date>
<booktitle>In Proceedings of the First Workshop on Treebanks and Linguistic Theories (TLT2002),</booktitle>
<pages>253--263</pages>
<location>Sozopol, Bulgaria.</location>
<contexts>
<context position="14853" citStr="Toutanova et al., 2002" startWordPosition="2443" endWordPosition="2446">en chunks. With this partial parse selection method, the grammar achieves 100% coverage on unseen data. A similar approach is also used in (van Noord et al., 1999). 3.3 Alternative Estimation Functions Generally speaking, the weights of the edges in the shortest path approach represent the quality of the local analyses and their likelihood of appearing in the analysis of the entire input. This is an interesting parallel to the parse selection models for the full analyses, where a goodness score is usually assigned to the full analysis. For example, the parse disambiguation model described in (Toutanova et al., 2002) uses a maximum entropy approach to model the conditional probability of a parse for a given input sequence P(t|w). A similar approach has also been reported in (Johnson et al., 1999; Riezler et al., 2002; Malouf and van Noord, 2004). For a given partial parse `b = {t1, ... , tk}, Q = {w1, ... , wk} is a segmentation of the input sequence so that each local analysis ti ∈ `b corresponds to a substring wi ∈ Q of the input sequence w. Therefore, the probability of the partial parse `b given an input sequence w is: P(`b|w) = P(Q|w) · P(`b|Q) (1) With the bold assumption that P(ti|wi) are mutually </context>
<context position="17320" citStr="Toutanova et al., 2002" startWordPosition="2902" endWordPosition="2905">the active tree, or as negative events if not). Since there is a huge number of intermediate results availalbe, we only randomly select a part of them as training data. This is essentially similar to the approach in (Osborne, 2000), where there is an infeasibly large number of training events, only part of which is used in the estimation step. The exact features used in the log-linear model can significantly influence the disambiguation accuracy. In this experiment we used the same features e :1 g:1 w1 w2 w3 w4 0 1 2 3 4 a :2 b :2 c:2 d:2 f:1 h:1 i: 8 131 as those used in the PCFG-S model in (Toutanova et al., 2002) (i.e., depth-1 derivation trees). The estimation of P(Ω|w) is more difficult. In a sense it is similar to a segmentation or chunking model, where the task is to segment the input into fragments. However, it is difficult to collect training data to directly train such a model for the deep grammar we have. Here we take a simple rough estimation: Pˆ(Ω|w) = |Y (Ω) |(5) |Z(w)| where Y (Ω) is the set of all partial parses that have the segmentation Ω; Z(w) is the set of all partial parses for the input w. Unfortunately, the shortest path algorithm is not able to directly find the maximized P(Φ|w). </context>
</contexts>
<marker>Toutanova, Manning, Shieber, Flickinger, Oepen, 2002</marker>
<rawString>Kristina Toutanova, Christoper D. Manning, Stuart M. Shieber, Dan Flickinger, and Stephan Oepen. 2002. Parse ranking for a rich HPSG grammar. In Proceedings of the First Workshop on Treebanks and Linguistic Theories (TLT2002), pages 253–263, Sozopol, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gertjan van Noord</author>
<author>Gosse Bouma</author>
<author>Rob Koeling</author>
<author>Mark-Jan Nederhof</author>
</authors>
<title>Robust grammatical analysis for spoken dialogue systems. Natural language engineering,</title>
<date>1999</date>
<pages>5--1</pages>
<marker>van Noord, Bouma, Koeling, Nederhof, 1999</marker>
<rawString>Gertjan van Noord, Gosse Bouma, Rob Koeling, and Mark-Jan Nederhof. 1999. Robust grammatical analysis for spoken dialogue systems. Natural language engineering, 5(1):45– 93.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>