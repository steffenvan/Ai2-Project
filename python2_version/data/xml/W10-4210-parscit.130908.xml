<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002484">
<title confidence="0.986279">
Natural Reference to Objects in a Visual Domain
</title>
<author confidence="0.986341">
Margaret Mitchell
</author>
<affiliation confidence="0.992391">
Computing Science Dept.
University of Aberdeen
</affiliation>
<address confidence="0.889175">
Scotland, U.K.
</address>
<email confidence="0.970869">
{m.mitchell,
</email>
<note confidence="0.44743125">
Kees van Deemter
Computing Science Dept.
University of Aberdeen
Scotland, U.K.
</note>
<author confidence="0.89413">
Ehud Reiter
</author>
<affiliation confidence="0.967834">
Computing Science Dept.
University of Aberdeen
</affiliation>
<address confidence="0.895432">
Scotland, U.K.
</address>
<email confidence="0.995273">
k.vdeemter, e.reiter}@abdn.ac.uk
</email>
<sectionHeader confidence="0.997345" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999983">
This paper discusses the basic structures
necessary for the generation of reference
to objects in a visual scene. We construct
a study designed to elicit naturalistic re-
ferring expressions to relatively complex
objects, and find aspects of reference that
have not been accounted for in work on
Referring Expression Generation (REG).
This includes reference to object parts,
size comparisons without crisp measure-
ments, and the use of analogies. By draw-
ing on research in cognitive science, neu-
rophysiology, and psycholinguistics, we
begin developing the input structure and
background knowledge necessary for an
algorithm capable of generating the kinds
of reference we observe.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999529711864407">
One of the dominating tasks in Natural Language
Generation (NLG) is the generation of expressions
to pick out a referent. In recent years there has
been increased interest in generating referential
expressions that are natural, e.g., like those pro-
duced by people. Although research on the gener-
ation of referring expressions has examined differ-
ent aspects of how people generate reference, there
has been surprisingly little research on how people
refer to objects in a real-world setting. This paper
addresses this issue, and we begin formulating the
requirements for an REG algorithm that refers to
visible three-dimensional objects in the real world.
Reference to objects in a visual domain pro-
vides a straightforward extension of the sorts of
reference REG research already tends to consider.
Toy examples outline reference to objects, peo-
ple, and animals that are perceptually available
before the speaker begins generating an utterance
(Dale and Reiter, 1995; Krahmer et al., 2003; van
Deemter et al., 2006; Areces et al., 2008). Exam-
ple referents may be referred to by their color, size,
type (“dog” or “cup”), whether or not they have a
beard, etc.
Typically, the reference process proceeds by
comparing the properties of the referent with the
properties of all the other items in the set. The
final expression roughly conforms to the Gricean
maxims (Grice, 1975).
However, when the goal is to generate natural
reference, this framework is too simple. The form
reference takes is profoundly affected by modality,
task, and audience (Chapanis et al., 1977; Cohen,
1984; Clark and Wilkes-Gibbs, 1986), and even
when these aspects are controlled, different people
will refer differently to the same object (Mitchell,
2008). In light of this, we isolate one kind of nat-
ural reference and begin building the algorithmic
framework necessary to generate the observed lan-
guage.
Psycholinguistic research has examined refer-
ence in a variety of settings, which may inform
research on natural REG, but it is not always clear
how to extend this work to a computational model.
This is true in part because these studies favor an
analysis of reference in the context of collabora-
tion; reference is embedded within language, and
language is often a joint activity. However, most
research on referring expression generation sup-
poses a solitary generating agent.1 This tacitly
assumes that reference will be taking place in a
monologue setting, rather than a dialogue or group
setting. Indeed, the goal of most REG algorithms
is to produce uniquely distinguishing, one-shot re-
ferring expressions.
Studies on natural reference usually use a
two person (speaker-listener) communication task
(e.g., Flavell et al., 1968; Krauss and Glucksberg,
1969; Ford and Olson, 1975). This research has
</bodyText>
<footnote confidence="0.31986">
1A notable exception is Heeman and Hirst (1995).
</footnote>
<bodyText confidence="0.999965098039216">
shown that reference is more accurate and efficient
when it incorporates things like gesture and gaze
(Clark and Krych, 2004). There is a trade-off in
effort between initiating a noun phrase and refash-
ioning it so that both speakers understand the ref-
erent (Clark and Wilkes-Gibbs, 1986), and speak-
ers communicate to form lexical pacts on how
to refer to an object (Sacks and Schegloff, 1979;
Brennan and Clark, 1996). Mutual understanding
of referents is achieved in part by referring within
a subset of potential referents (Clark et al., 1983;
Beun and Cremers, 1998). A few studies have
compared monologue to dialogue reference, and
have shown that monologue references tend to be
harder for a later listener to disambiguate (Clark
and Krych, 2004) and that subsequent references
tend to be longer than those in dialogues (Krauss
and Weinheimer, 1967).
Aiming to generate natural reference in a mono-
logue setting raises questions about what an algo-
rithm should use to produce utterances like those
produced by people. In a monologue setting, the
speaker (or algorithm) gets no feedback from the
listener; the speaker’s reference is not tied to in-
teractions with other participants. The speaker
is therefore in a difficult position, attempting to
clearly convey a referent without being able to
check if the reference is understood along the way.
Recent studies that have focused on monologue
reference do so rather explicitly, which may af-
fect participant responses. These studies utilize
2D graphical depictions of simple 3D objects (van
Deemter et al., 2006; Viethen and Dale, 2008),
where a small set of properties can be used to dis-
tinguish one item from another. The expressions
are elicited in isolation, typed and then submitted,
which may hide some of the underlying referen-
tial processes. None of these studies utilize actual
objects. It is therefore difficult to use these data
to draw conclusions about how reference works in
naturalistic settings. It is unclear if these experi-
mental settings are natural enough, i.e., if they get
at reference as it may occur every day.
The study in this paper attempts to bring out in-
formation about reference in a number of ways.
First, we conduct the study in-person, using real-
world objects. This design invites referential phe-
nomena that may not have been previously ob-
served in simpler domains. Second, the refer-
ring expressions are produced orally. This allows
us access to reference as it is generated, without
the participants revising and so potentially obscur-
ing information about their reference. Third, we
use a relatively complicated task, where partici-
pants must explain how to use pieces to put to-
gether a picture of a face. The fact that we are
looking at reference is not made explicit, which
lessens any experimental effects caused by sub-
jects guessing the purpose of the study. This ap-
proach also situates reference within a larger task,
which may draw out aspects of reference not usu-
ally seen in experiments that elicit reference in iso-
lation. Fourth, the objects used display a variety
of different features: texture, material, color, size
along several dimensions, etc. This brings the data
set closer to objects that people interact with every
day. A monologue setting offers a picture of the
phenomena at play during a single individual’s re-
ferring expression generation.
The referring expressions gathered in this study
exhibit several aspects of reference that have not
yet been addressed in REG. This includes (1) part-
whole modularity; (2) size comparisons across
three dimensions; and (3) analogies. Work in cog-
nitive sciences suggests that these phenomena are
interrelated, and may be possible to represent in a
computational framework. This research also of-
fers connections to further aspects of natural refer-
ence that were not directly observed in the study,
but will need to be accounted for in future work on
naturalistic referring expression generation. Us-
ing these ideas, we begin formulating the struc-
tures that an REG algorithm would need in order
to produce reference to real-world objects in a vi-
sual setting.
Approaching REG in this way allows us to tie
research in the generation of referring expressions
to computational models of visual perception and
cognitively-motivated computer vision. Moving in
this direction offers the prospect of eventually de-
veloping an application for the generation of nat-
ural reference to objects automatically recognized
by a computer vision system.
In the next section, we describe our study. In
Section 3, we analyze the results and discuss what
they tell us about natural reference. In Section 4,
we draw on our results and cognitive models of ob-
ject recognition to begin building the framework
for a referring expression algorithm that generates
naturalistic reference to objects in a visual scene.
In Section 5, we offer concluding remarks and out-
line areas for further study.
</bodyText>
<figureCaption confidence="0.99849">
Figure 1: Object Board.
</figureCaption>
<sectionHeader confidence="0.960418" genericHeader="introduction">
2 Method
</sectionHeader>
<subsectionHeader confidence="0.93563">
2.1 Subjects
</subsectionHeader>
<bodyText confidence="0.999994916666667">
The subjects were 20 residents of Aberdeen, Scot-
land, and included undergraduates, graduates, and
professionals. All were native speakers of English,
had normal or corrected vision, and had no other
known visual issues (such as color-blindness).
Subjects were paid for their participation. Two
recordings were left out of the analysis: one par-
ticipant’s session was not fully recorded due to a
software error, and one participant did not pick out
many objects in each face and so was not included.
The final set of participants included 18 people, 10
female and 8 male.
</bodyText>
<subsectionHeader confidence="0.993256">
2.2 Materials
</subsectionHeader>
<bodyText confidence="0.999907105263158">
A board was prepared with 51 craft objects. The
objects were chosen from various craft sets, and
included pom-poms, pipe-cleaners, beads, and
feathers (see Table 1). The motley group of objects
had different colors, textures, shapes, patterns, and
were made of different materials. Similar objects
were grouped together on the board, with a label
placed underneath. This was done to control the
head noun used in each reference. The objects
were used to make up 5 different craft “face” pic-
tures. Subjects sat at a desk facing the board and
the stack of pictures. A picture of the board is
shown in Figure 1.
Subjects were recorded on a head-mounted mi-
crophone, which fed directly into a laptop placed
on the left of the desk. The open-source audio-
recording program Audacity (Mazzoni, 2010) was
used to record the audio signal and export it to
wave format.
</bodyText>
<subsectionHeader confidence="0.996974">
2.3 Procedure
</subsectionHeader>
<bodyText confidence="0.999878375">
Subjects were told to give instructions on how to
construct each face using the craft supplies on the
board. They were instructed to be clear enough for
a listener to be able to reconstruct each face with-
out the pictures, with only the board items in front
of them. A pilot study revealed that such open-
ended instructions left some subjects spending an
inordinate amount of time on the exact placement
of each piece, and so in the current study sub-
jects were told that each face should take “a cou-
ple” minutes, and that the instructions should be
as clear as possible for a listener to use the same
objects in reconstructing the pictures without be-
ing “overly concerned” with the details of exactly
how each piece is angled in relation to the other.
Subjects were first given a practice face to de-
scribe. This face was the same face for all subjects.
They were then allowed to voice any concerns or
ask questions, but the experimenter only repeated
portions of the original instructions; no new infor-
mation was given. The subject could then proceed
to the next four faces, which were in a random or-
der for each subject. A transcript of a single face
from a session is provided in Figure 2.
</bodyText>
<subsectionHeader confidence="0.996646">
2.4 Analysis
</subsectionHeader>
<bodyText confidence="0.9998185">
The recordings of each monologue were tran-
scribed, including disfluencies, and each face sec-
tion (“eyes”, “chin”, etc.) was marked. First refer-
ence to items on the board were annotated with
their corresponding item numbers, yielding 722
references.2 Initial references to single objects
were extracted, creating a final data set with 505
references to single objects.
</bodyText>
<sectionHeader confidence="0.999949" genericHeader="method">
3 Results
</sectionHeader>
<bodyText confidence="0.99990175">
Each reference was annotated in terms of the prop-
erties used to pick out the referent. For exam-
ple, “the red feather” was annotated as contain-
ing the &lt;ATTRIBUTE:value&gt; pairs &lt;COLOR:red,
TYPE:feather&gt;. Discerning properties from the
modifiers used in reference is generally straight-
forward, and all of the references produced may
be partially deconstructed using such properties.
</bodyText>
<footnote confidence="0.9910275">
2This corpus is available at
http://www.csd.abdn.ac.uk/˜mitchema/craft corpus.
</footnote>
<table confidence="0.998446307692308">
14 foam shapes 2 large red hearts 2 small red hearts 2 small neon green hearts
2 small blue hearts 1 small green heart 1 green triangle 1 red circle
1 red square 1 red rectangle 1 white rectangle
11 beads 4 large round wooden beads 2 small white plastic beads 2 brown patterned beads
1 gold patterned bead 1 shiny gold patterned heart 1 red patterned heart
9 pom poms 2 big green pom-poms 2 small neon green pom-poms 2 small silver pom-poms
1 small metallic green pom-pom 1 large white pom-pom 1 medium white pom-pom
8 pipe cleaners 1 gold pipe-cleaner 1 gold pipe-cleaner in half 1 silver pipe-cleaner
1 circular neon yellow soft pipe-cleaner 1 neon orange puffy pipe-cleaner 1 grey puffy pipe-cleaner
1 purple/yellow striped pipe-cleaner 1 brown/grey striped pipe-cleaner
5 feathers 2 purple feathers 2 red feathers 1 yellow feather
3 ribbons 1 gold sequined wavy ribbon 1 silver wavy ribbon 1 small silver wavy ribbon
1 star 1 gold star
</table>
<tableCaption confidence="0.99991">
Table 1: Board items.
</tableCaption>
<bodyText confidence="0.980242178571429">
&lt;CHIN&gt; Okay so this face again um this face has um uh
for the chin, it uses (10 a gold pipe-cleaner in a V shape)
where the bottom of the V is the chin. &lt;/CHIN&gt;
&lt;MOUTH&gt; The mouth is made up of (9 a purplefeather).
And the mouth is slightly squint, um as if the the person
is smiling or even smirking. So this this smile is almost
off to one side. &lt;/MOUTH&gt;
&lt;NOSE&gt; The nose is uh (5 a wooden bead, a medium-
sized wooden bead with a hole in the center). &lt;/NOSE&gt;
&lt;EYES&gt; And the eyes are made of (2,3 whitepom-poms),
em just uh em evenly spaced in the center of the face.
&lt;/EYES&gt;
&lt;FOREHEAD&gt; Em it’s see the person’s em top of the per-
son’s head is made out of (1 another, thickerpipe-cleaner
that’s uh a grey color, it’s kind of uh a knotted blue-type
pipe-cleaner). So that that acts as the top of the person’s
head. &lt;/FOREHEAD&gt;
&lt;HAIR&gt; And down the side of the person’s face, there are
(7,8 two ribbons) on each side. (7,8 And those are silver
ribbons). Um and they just hang down the side of the face
and they join up the the grey pipe-cleaner and the top um
of the person’s head to the to the chin and then hang down
either side of the chin. &lt;/HAIR&gt;
&lt;EARS&gt; And the person’s ears are made up of (4,6 two
beads, which are um love-heart-shaped beads), where the
points of the love-hearts are facing outwards. And those
are just placed um around same em same em horizontal
line as the nose of the person’s face is. &lt;/EARS&gt;
</bodyText>
<figureCaption confidence="0.996908">
Figure 2: Excerpt Transcript.
</figureCaption>
<bodyText confidence="0.999968625">
Using sets of properties to distinguish referents
is nothing new in REG. Algorithms for the genera-
tion of referring expressions commonly use this as
a starting point, proposing that properties are orga-
nized in some linear order (Dale and Reiter, 1995)
or weighted order (Krahmer et al., 2003) as input.
However, we find evidence that more is at play. A
breakdown of our findings is listed in Table 2.
</bodyText>
<subsectionHeader confidence="0.994793">
3.1 Spatial Reference
</subsectionHeader>
<bodyText confidence="0.9996004">
In addition to properties that pick out referents,
throughout the data we see reference to objects
as they exist in space. Size is compared across
different dimensions of different objects, and ref-
erence is made to different parts of the objects,
picking out pieces within the whole. These two
phenomena – relative size comparisons and part-
whole modularity – point to an underlying spatial
object representation that may be utilized during
reference.
</bodyText>
<subsectionHeader confidence="0.473459">
3.1.1 Relative Size Comparisons
</subsectionHeader>
<bodyText confidence="0.9726505">
A total of 122 (24.2%) references mention size
with a vague modifier (e.g., “big”, “wide”). This
includes comparative (e.g, “larger”) and superla-
tive (e.g., “largest”) size modifiers, which occur 40
(7.9%) times in the data set. Examples are given
below.
</bodyText>
<listItem confidence="0.9995805">
(1) “the bigger pom-pom”
(2) “the green largest pom-pom”
(3) “the smallest long ribbon”
(4) “the large orange pipe-cleaner”
</listItem>
<bodyText confidence="0.9802034">
Of the references that mention size, 35 (6.9%)
use a vague modifier that applies to one or two di-
mensions. This includes modifiers for height (“the
short silver ribbon”), width (“quite a fat rectan-
gle”), and depth (“the thick grey pipe-cleaner”).
87 (17.2%) use a modifier that applies to the over-
all size of the object (e.g., “big” or “small”). Table
3 lists these values. Crisp measurements (such as
“1 centimeter”) occur only twice (0.4%), with both
produced by the same participant.
</bodyText>
<table confidence="0.98629325">
Comparative/Superlative: 40 (7.9%)
Base: 82 (16.2%)
Height/Width/Depth: 35 (6.9%)
Overall size: 87 (17.2%)
</table>
<tableCaption confidence="0.968215">
Table 3: Size Modifier Breakdown.
</tableCaption>
<table confidence="0.950120461538462">
Part-whole modularity Relative size Analogies
“a green pom-pom... “a red foam-piece... “a natural-looking piece
with the tinsel on the outside” which is more square of pipe-cleaner, it looks
“your gold twisty ribbon... in shape rather than a bit like a rope”
with sequins on it” the longer rectangle” “a pipe-cleaner that
“a wooden bead... “the grey pipe-cleaner... looks a bit like...
with a hole in the center” which is the thicker one... a fluffy caterpillar”
“one of the green pom-poms... “the slightly larger one” “the silver ribbon
with the sort of strands “the smaller silver ribbon” that’s almost like
coming out from it.” “the short silver ribbon” a big S shape.”
“the silver ribbon... with the chainmail “quite a fat rectangle” “a... pipe-cleaner
detail down through the middle of it.” “thick grey pipe-cleaner” that looks like tinsel.”
11 References 122 References 16 References
</table>
<tableCaption confidence="0.998998">
Table 2: Examples of Observed Reference.
</tableCaption>
<bodyText confidence="0.999814444444445">
Participants produce such modifiers without
sizes or measurements explicitly given; with an
input of a visual object presentation, the output
includes size modifiers. Such data suggests that
natural reference in a visual domain utilizes pro-
cesses comparing the length, width, and height of
a target object with other objects in the set. Indeed,
5 references (1.0%) in our data set include explicit
comparison with the size of other objects.
</bodyText>
<listItem confidence="0.997915">
(5) “a red foam-piece... which is more square in
shape rather than the longer rectangle”
(6) “the grey pipe-cleaner... which is the thicker
one... of the selection”
(7) “the shorter of the two silver ribbons”
(8) “the longer one of the ribbons”
(9) “the longer of the two silver ribbons”
</listItem>
<bodyText confidence="0.999934105263158">
In Example (5), height and width across two
different objects are compared, distinguishing a
square from a rectangle. In (6) “thicker” marks
the referent as having a larger circumference than
other items of the same type. (7) (8) and (9) com-
pare the height of the target referent to the height
of similar items.
The use of size modifiers in a domain without
specified measurements suggests that when peo-
ple refer to an object in a visual domain, they
are sensitive to its size and structure within a di-
mensional, real-world space. Without access to
crisp measurements, people compare relative size
across different objects, and this is reflected in the
expressions they generate. These comparisons are
not only limited to overall size, but include size
in each dimension. This suggests that objects’
structures within a real-world space are relevant
to REG in a visual domain.
</bodyText>
<subsubsectionHeader confidence="0.700596">
3.1.2 Part-Whole Modularity
</subsubsectionHeader>
<bodyText confidence="0.999945375">
The role that a spatial object understanding has
within reference is further detailed by utterances
that pick out the target object by mentioning an ob-
ject part. 11 utterances (2.2%) in our data include
mention of an object part within reference to the
whole object. This is spread across participants,
such that half of the participants make reference
to an object part at least once.
</bodyText>
<listItem confidence="0.997613">
(10) “a green pom-pom, which is with the tinsel
on the outside”
(11) “your gold twisty ribbon...with sequins on
it”
(12) “a wooden bead...with a hole in the center”
</listItem>
<bodyText confidence="0.999892769230769">
In (10), pieces of tinsel are isolated from the
whole object and specified as being on the outside.
In (11), smaller pieces that lay on top of the ribbon
are picked out. And in (12), a hole within the bead
is isolated.
The use of part-whole modularity suggests an
understanding that parts of the object take up their
own space within the object. An object is not only
viewed as a whole during reference, but parts in,
on, and around it may be considered as well. For
an REG algorithm to generate these kinds of ref-
erences, it must be provided with a representation
that details the structure of each object.
</bodyText>
<subsectionHeader confidence="0.944853">
3.2 ANALOGIES
</subsectionHeader>
<bodyText confidence="0.999845428571429">
The data from this study also provide information
on what can be expected from a knowledge base
in an algorithm that aims to generate naturalistic
reference. Reference is made 16 times (3.2%) to
objects not on the board, where the intended refer-
ent is compared against something it is like. Some
examples are given below.
</bodyText>
<listItem confidence="0.995580833333333">
(13) “a gold... pipe-cleaner... completely
straight, like a ruler”
(14) “a natural-looking piece ofpipe-cleaner, it
looks a bit like a rope”
(15) “a pipe-cleaner that looks a bit like... a
fluffy caterpillar... ”
</listItem>
<bodyText confidence="0.999275052631579">
In (13), a participant makes reference to a
SHAPE property of an object not on the board. In
(14) and (15), participants refer to objects that may
share a variety of properties with the referent, but
are also not on the board.
Reference to these other items do not pick out
single objects, but types of objects (e.g., an object
type, not token). They correspond to some pro-
totypical idea of an object with properties similar
to those of the referent. Work by Rosch (1975)
has examined this tendency, introducing the idea
ofprototype theory, which proposes that there may
be some central, ‘prototypical’ notions of items. A
knowledge base with stored prototypes could be
utilized by an REG algorithm to compare the tar-
get referent to item prototypes. Such representa-
tions would help guide the generation of reference
to items not in the scene, but similar to the target
referent.
</bodyText>
<sectionHeader confidence="0.999739" genericHeader="method">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999981081081081">
We have discussed several different aspects of ref-
erence in a study where referring expressions are
elicited for objects in a spatial, visual scene. Ref-
erence in this domain draws on object forms as
they exist in a three-dimensional space and uti-
lizes background knowledge to describe referents
by analogy to items outside of the scene. This
is undoubtedly not an exhaustive account of the
phenomena at play in such a domain, but offers
some initial conclusions that may be drawn from
exploratory work of this kind.
Before continuing with the discussion, it is
worthwhile to consider whether some of our data
might be seen as going beyond reference. Perhaps
the participants are doing something else, which
could be called describing. How to draw the line
between a distinguishing reference and a descrip-
tion, and whether such a line can be drawn at all, is
an interesting question. If the two are clearly dis-
tinct, then both are interesting to NLG research.
If the two are one in the same, then this sheds
some light on how REG algorithms should treat
reference. We leave a more detailed discussion of
this for future work, but note recent psycholinguis-
tic work suggesting that referring establishes (1)
an individual as the referent; (2) a conceptualiza-
tion or perspective on that individual (Clark and
Bangerter, 2004). Schematically, referring = indi-
cating + describing.
We now turn to a discussion of how the ob-
served phenomena may be best represented in an
REG algorithm. We propose that an algorithm ca-
pable of generating natural reference to objects in
a visual scene should utilize (1) a spatial object
representation; (2) a non-spatial feature-based rep-
resentation; and (3) a knowledge base of object
prototypes.
</bodyText>
<subsectionHeader confidence="0.981512">
4.1 Spatial and Visual Properties
</subsectionHeader>
<bodyText confidence="0.999985925">
It is perhaps unsurprising to find reference that ex-
hibits spatial knowledge in a study where objects
are presented in three-dimensional space. Hu-
man behavior is anchored in space, and spatial in-
formation is essential for our ability to navigate
the world we live in. However, referring expres-
sion generation algorithms geared towards spa-
tial representations have oversimplified this ten-
dency, keeping objects within the realm of two-
dimensions and only looking at the spatial rela-
tions between objects.
For example, Funakoshi et al. (2004) and Gatt
(2006) focus on how objects should be clustered
together to form groups. This utilizes some of
the spatial information between objects, but does
not address the spatial, three-dimensional nature
of objects themselves. Rather, objects exist as en-
tities that may be grouped with other entities in a
set or singled out as individual objects; they do not
have their own spatial characteristics. Similarly,
one of the strengths of the Graph-Based Algorithm
(Krahmer et al., 2003) is its ability to generate ex-
pressions that involve relations between objects,
and these include spatial ones (“next to”, “on top
of”, etc.). In all these approaches, however, ob-
jects are essentially one-dimensional, represented
as individual nodes.
Work that does look at the spatial information
of different objects is provided by Kelleher et al.
(2005). In this approach, the overall volume of
each object is calculated to assign salience rank-
ings, which then allow the Incremental Algorithm
(Dale and Reiter, 1995) to produce otherwise “un-
derspecified” reference. The spatial properties of
the objects are kept relatively simple. They are
not used in constructing the referring expression,
but one aspect of the object’s three-dimensional
shape (volume) affects the referring expression’s
final form. To the authors’ knowledge, the cur-
rent work is the first to suggest that objects them-
selves should have their spatial properties repre-
sented during reference.
Research in cognitive modelling supports the
idea that we attend to the spatial properties of ob-
jects when we view them (Blaser et al., 2000), and
that we have purely spatial attentional mechanisms
operating alongside non-spatial, feature-based at-
tentional mechanisms (Treue and Trujillo, 1999).
These feature-based attentional mechanisms pick
out properties commonly utilized in REG, such as
texture, orientation, and color. They also pick out
edges and corners, contrast, and brightness. Spa-
tial attentional mechanisms provide information
about where the non-spatial features are located in
relation to one another, size, and the spatial inter-
relations between component parts.
Applying these findings to our study, an REG
algorithm that generates natural reference should
utilize a visual, feature-based representation of ob-
jects alongside a structural, spatial representation
of objects. A feature-based representation is al-
ready common to REG, and could be represented
as a series of &lt;ATTRIBUTE:value&gt; pairs. A spa-
tial representation is necessary to define how the
object is situated within a dimensional space, pro-
viding information about the relative distances be-
tween object components, edges, and corners.
With such information provided by a spatial
representation, the generation of part-whole ex-
pressions, such as “the pom-pom with the tinsel on
the outside”, is possible. This also allows for the
generation of size modifiers (“big”, “small”) with-
out the need for crisp measurements, for example,
by comparing the difference in overall height of
the target object with other objects in the scene, or
against a stored prototype (discussed below). Rel-
ative size comparisons across different dimensions
would also be possible, used to generate size mod-
ifiers such as “wide” and “thick” that refer to one
dimensional axis.
</bodyText>
<subsectionHeader confidence="0.98204">
4.2 Analogies
</subsectionHeader>
<bodyText confidence="0.999989035714286">
A feature-based and a spatial representation may
also play a role in analogies. When we use analo-
gies, as in “the pipe-cleaner that looks like a cater-
pillar”, we use world knowledge about items that
are not themselves visible. Such an expression
draws on similarity that does not link the referent
with a particular object, but with a general type of
object: the pipe-cleaner is caterpillar-like.
To generate these kinds of expressions, an REG
algorithm would first need a knowledge base with
prototypes listing prototypical values of attributes.
For example, a banana prototype might have a pro-
totypical COLOR of yellow. With prototypes in the
knowledge base, the REG algorithm would need
to calculate similarity of a target referent to other
known items. This would allow a piece of yellow
cloth, for example, to be described as being the
color of a banana.
Implementing such similarity measures in an
REG algorithm will be challenging. One difficulty
is that prototype values may be different depend-
ing on what is known about an item; a prototypical
unripe banana may be green, or a prototypical rot-
ten banana brown. Another difficulty will be in
determining when a referent is similar enough to
a prototype to warrant an analogy. Additional re-
search is needed to explore how these properties
can be reasoned about.
</bodyText>
<subsectionHeader confidence="0.99661">
4.3 Further Implications
</subsectionHeader>
<bodyText confidence="0.954296623188406">
A knowledge base containing prototypes opens up
the possibility of generating many other kinds of
natural references. In particular, such knowledge
would allow the algorithm to compute which prop-
erties a given kind of referent may be expected
to have, and which properties may be unexpected.
Unexpected properties may therefore stand out as
particularly salient.
For example, a dog missing a leg may be de-
scribed as a “three-legged dog” because the pro-
totypical dog has four legs. We believe that this
perspective, which hinges on the unexpectedness
of a property, suggests a new approach to at-
tribute selection. Unlike the Incremental Algo-
rithm, the Preference Order that determines the or-
der in which attributes are examined would not be
fixed, but would depend on the nature of the refer-
ent and what is known about it.
Approaching REG in this way follows work in
cognitive science and neurophysiology that sug-
gests that expectations about objects’ visual and
spatial characteristics are derived from stored rep-
resentations of object ‘prototypes’ in the infe-
rior temporal lobe of the brain (Logothetis and
- A spatial representation (depicting size, inter-
relations between component parts)
- A non-spatial, propositional representation
(describing color, texture, orientation, etc.)
- A knowledge base with stored prototypical ob-
ject propositional and spatial representations
Table 4: Requirements for an REG algorithm that
generates natural reference to visual objects.
Sheinberg, 1996; Riesenhuber and Poggio, 2000;
Palmeri and Gauthier, 2004). Most formal theo-
ries of object perception posit some sort of cate-
gory activation system (Kosslyn, 1994), a system
that matches input properties of objects to those
of stored prototypes, which then helps guide ex-
pectations about objects in a top-down fashion.3
This appears to be a neurological correlate of the
knowledge base we propose to underlie analogies.
Such a system contains information about pro-
totypical objects’ component parts and where they
are placed relative to one another, as well as rele-
vant values for material, color, etc. This suggests
that the spatial and non-spatial feature-based rep-
resentations proposed for visible objects could be
used to represent prototype objects as well. In-
deed, how we view and refer to objects appears to
be influenced by the interaction of these structures:
Expectations about an object’s spatial properties
guide our attention towards expected object parts
and non-spatial, feature-based properties through-
out the scene (Kosslyn, 1994; Itti and Koch, 2001).
This affects the kinds of things we are most likely
to generate language about (Itti and Arbib, 2005).
We can now outline some general requirements
for an algorithm capable of generating naturalis-
tic reference to objects in a visual scene: Input to
such an algorithm should include a feature-based
representation, which we will call a propositional
representation, with values for color, texture, etc.,
and a spatial representation, with symbolic infor-
mation about objects’ size and the spatial relation-
ships between components. A system that gener-
ates naturalistic reference must also use a knowl-
edge base storing information about object proto-
types, which may be represented in terms of their
own propositional/spatial representations.
</bodyText>
<footnote confidence="0.596210666666667">
3Note that this is not the only proposed matching structure
in the brain – an exemplar activation system matches input to
stored exemplars.
</footnote>
<sectionHeader confidence="0.992686" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999988295454545">
We have explored the interaction between view-
ing objects in a three-dimensional, spatial domain
and referring expression generation. This has led
us to propose structures that may be used to con-
nect vision in a spatial modality to naturalistic ref-
erence. The proposed structures include a spatial
representation, a propositional representation, and
a knowledge base with representations for object
prototypes. Using structures that define the propo-
sitional and spatial content of objects fits well with
work in psycholinguistics, cognitive science and
neurophysiology, and may provide the basis to
generate a variety of natural-sounding references
from a system that recognizes objects.
It is important to note that any naturalistic ex-
perimental design limits the kinds of conclusions
that can be drawn about reference. A study that
elicits reference to objects in a visual scene pro-
vides insight into reference to objects in a visual
scene; these conclusions cannot easily be extended
to reference to other kinds of phenomena, such as
reference to people in a novel. We therefore make
no claims about reference as a whole in this paper;
generalizations from this research can provide hy-
potheses for further testing in different modalities
and with different sorts of referents.
Our data leave open many areas for further
study, and we hope to address these in future work.
Experiments designed specifically to elicit relative
size modifiers, reference to object components,
and reference to objects that are like other things
would help further detail the form our proposed
structures take.
What is clear from our data is that both a spa-
tial understanding and a non-spatial feature-based
understanding appear to play a role in reference
to objects in a visual scene, and further, refer-
ence in such a setting is bolstered by a knowl-
edge base with stored prototypical object repre-
sentations. Utilizing structures representative of
these phenomena, we may be able to extend ob-
ject recognition research into object reference re-
search, generating natural-sounding reference in
everyday settings.
</bodyText>
<sectionHeader confidence="0.998558" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.997909">
Thanks to Advaith Siddarthan for thought-
provoking discussions and to the anonymous re-
viewers for useful suggestions.
</bodyText>
<sectionHeader confidence="0.995644" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999737809523809">
Carlos Areces, Alexander Koller, and Kristina Strieg-
nitz. 2008. Referring expressions as formulas of
description logic. Proceedings of the Fifth Inter-
national Natural Language Generation Conference,
pages 42–29.
Robbert-Jan Beun and Anita H. M. Cremers. 1998.
Object reference in a shared domain of conversation.
Pragmatics and Cognition, 6:121–52.
Erik Blaser, Zenon W. Pylyshyn, and Alex O. Hol-
combe. 2000. Tracking an object through feature
space. Nature, 408:196–199.
Susan E. Brennan and Herbert H. Clark. 1996. Con-
ceptual pacts and lexical choice in conversation.
Journal of Experimental Psychology: Learning,
Memory, and Cognition, 22:1482–93.
Alphonse Chapanis, Robert N. Parrish, Robert B.
Ochsman, and Gerald D. Weeks. 1977. Studies
in interactive communication: II. the effects of four
communication modes on the linguistic performance
of teams during cooperative problem solving. Hu-
man Factors, 19:101–125.
Herbert H. Clark and Adrian Bangerter. 2004. Chang-
ing ideas about reference. In Ira A. Noveck and Dan
Sperber, editors, Experimental pragmatics, pages
25–49. Palgrave Macmillan, Basingstoke, England.
Herbert H. Clark and Meredyth A. Krych. 2004.
Speaking while monitoring addressees for under-
standing. Journal ofMemory and Language, 50:62–
81.
Herbert H. Clark and Deanna Wilkes-Gibbs. 1986. Re-
ferring as a collaborative process. Cognition, 22:1–
39.
Herbert H. Clark, Robert Schreuder, and Samuel But-
trick. 1983. Common ground and the understand-
ing of demonstrative reference. Journal of Verbal
Learning and Verbal Behavior, 22:1–39.
Philip R. Cohen. 1984. The pragmatics of referring
and the modality of communication. Computational
Linguistics, 10(2):97–146.
Robert Dale and Ehud Reiter. 1995. Computational
interpretations of the gricean maxims in the gener-
ation of referring expressions. Cognitive Science,
18:233–263.
J. H. Flavell, P. T. Botkin, D. L. Fry Jr., J. W. Wright,
and P. E. Jarvice. 1968. The Development of Role-
Taking and Communication Skills in Children. John
Wiley, New York.
William Ford and David Olson. 1975. The elaboration
of the noun phrase in children’s description of ob-
jects. The Journal of Experimental Child Psychol-
ogy, 19:371–382.
Kotaro Funakoshi, Satoru Watanabe, Naoko Kuriyama,
and Takenobu Tokunaga. 2004. Generating refer-
ring expressions using perceptual groups. In Pro-
ceedings ofthe 3rd International Conference on Nat-
ural Language Generation, pages 51–60.
Albert Gatt. 2006. Structuring knowledge for refer-
ence generation: A clustering algorithm. Proceed-
ings of the 11th Conference of the European Chap-
ter of the Association for Computational Linguistics
(EACL-06), pages 321–328.
Paul H. Grice. 1975. Logic and conversation. Syntax
and Semantics, 3:41–58.
Peter A. Heeman and Graeme Hirst. 1995. Collabo-
rating on referring expressions. Computational Lin-
guistics, 21.
Laurent Itti and Michael A. Arbib. 2005. Attention and
the minimal subscene. In Michael A. Arbib, editor,
Action to Language via the Mirror Neuron System.
Cambridge University Press.
Laurent Itti and Christof Koch. 2001. Computational
modelling of visual attention. Nature Reviews Neu-
roscience.
J. Kelleher, F. Costello, and J. van Genabith. 2005.
Dynamically structuring, updating and interrelating
representations of visual and linguistic discourse
context. Artificial Intelligence, 167:62–102.
Stephen M. Kosslyn. 1994. Image and Brain: The
Resolution of the Imagery Debate. MIT Press, Cam-
bridge, MA.
Emiel Krahmer, Sebastiaan van Erk, and Andr´e Verleg.
2003. Graph-based generation of referring expres-
sions. Computational Linguistics, 29(1):53–72.
Robert M. Krauss and Sam Glucksberg. 1969. The
development of communication: Competence as a
function of age. Child Development, 40:255–266.
Robert M. Krauss and Sidney Weinheimer. 1967. Ef-
fect of referent similarity and communication mode
on verbal encoding. Journal of Verbal Learning and
Verbal Behavior, 6:359–363.
Nikos K. Logothetis and David L. Sheinberg. 1996.
Visual object recognition. Annual Review Neuro-
science, 19:577–621.
Dominic Mazzoni. 2010. Audacity.
Margaret Mitchell. 2008. Towards the generation
of natural reference. Master’s thesis, University of
Washington.
Thomas J. Palmeri and Isabel Gauthier. 2004. Vi-
sual object understanding. Nature Reviews Neuro-
science, 5:291–303.
Maximilian Riesenhuber and Tomaso Poggio. 2000.
Models of object recognition. Nature Neuroscience
Supplement, 3:1199–1204.
Eleanor Rosch. 1975. Cognitive representation of
semantic categories. Journal of Experimental Psy-
chology, 104:192–233.
Harvey Sacks and Emanuel A. Schegloff. 1979. Two
preferences in the organization of reference to per-
sons in conversation and their interaction. In George
Psathas, editor, Everyday Language: Studies in Eth-
nomethodology, pages 15–21. Irvington Publishers,
New York.
Stegan Treue and Julio C. Martinez Trujillo. 1999.
Feature-based attention influences motion process-
ing gain in macaque visual cortex. Nature, 399:575–
579.
Kees van Deemter, Ielka van der Sluis, and Albert Gatt.
2006. Building a semantically transparent corpus
for the generation of referring expressions. In Pro-
ceedings ofthe 4th International Conference on Nat-
ural Language Generation, Sydney, Australia. ACL.
Jette Viethen and Robert Dale. 2008. The use of spatial
descriptions in referring expressions. In Proceed-
ings of the 5th International Conference on Natural
Language Generation, INLG-08, Salt Fork, Ohio.
ACL.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.281065">
<title confidence="0.997227">Natural Reference to Objects in a Visual Domain</title>
<author confidence="0.993815">Margaret</author>
<affiliation confidence="0.906490333333334">Computing Science University of Scotland, U.K.</affiliation>
<author confidence="0.820571">Kees van</author>
<affiliation confidence="0.919282571428572">Computing Science University of Scotland, U.K. Ehud Computing Science University of Scotland, U.K.</affiliation>
<abstract confidence="0.999435666666667">This paper discusses the basic structures necessary for the generation of reference to objects in a visual scene. We construct a study designed to elicit naturalistic referring expressions to relatively complex objects, and find aspects of reference that have not been accounted for in work on Referring Expression Generation (REG). This includes reference to object parts, size comparisons without crisp measurements, and the use of analogies. By drawing on research in cognitive science, neurophysiology, and psycholinguistics, we begin developing the input structure and background knowledge necessary for an algorithm capable of generating the kinds of reference we observe.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Carlos Areces</author>
<author>Alexander Koller</author>
<author>Kristina Striegnitz</author>
</authors>
<title>Referring expressions as formulas of description logic.</title>
<date>2008</date>
<booktitle>Proceedings of the Fifth International Natural Language Generation Conference,</booktitle>
<pages>42--29</pages>
<contexts>
<context position="2065" citStr="Areces et al., 2008" startWordPosition="306" endWordPosition="309">gly little research on how people refer to objects in a real-world setting. This paper addresses this issue, and we begin formulating the requirements for an REG algorithm that refers to visible three-dimensional objects in the real world. Reference to objects in a visual domain provides a straightforward extension of the sorts of reference REG research already tends to consider. Toy examples outline reference to objects, people, and animals that are perceptually available before the speaker begins generating an utterance (Dale and Reiter, 1995; Krahmer et al., 2003; van Deemter et al., 2006; Areces et al., 2008). Example referents may be referred to by their color, size, type (“dog” or “cup”), whether or not they have a beard, etc. Typically, the reference process proceeds by comparing the properties of the referent with the properties of all the other items in the set. The final expression roughly conforms to the Gricean maxims (Grice, 1975). However, when the goal is to generate natural reference, this framework is too simple. The form reference takes is profoundly affected by modality, task, and audience (Chapanis et al., 1977; Cohen, 1984; Clark and Wilkes-Gibbs, 1986), and even when these aspect</context>
</contexts>
<marker>Areces, Koller, Striegnitz, 2008</marker>
<rawString>Carlos Areces, Alexander Koller, and Kristina Striegnitz. 2008. Referring expressions as formulas of description logic. Proceedings of the Fifth International Natural Language Generation Conference, pages 42–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robbert-Jan Beun</author>
<author>Anita H M Cremers</author>
</authors>
<title>Object reference in a shared domain of conversation. Pragmatics and Cognition,</title>
<date>1998</date>
<pages>6--121</pages>
<contexts>
<context position="4428" citStr="Beun and Cremers, 1998" startWordPosition="685" endWordPosition="688"> has 1A notable exception is Heeman and Hirst (1995). shown that reference is more accurate and efficient when it incorporates things like gesture and gaze (Clark and Krych, 2004). There is a trade-off in effort between initiating a noun phrase and refashioning it so that both speakers understand the referent (Clark and Wilkes-Gibbs, 1986), and speakers communicate to form lexical pacts on how to refer to an object (Sacks and Schegloff, 1979; Brennan and Clark, 1996). Mutual understanding of referents is achieved in part by referring within a subset of potential referents (Clark et al., 1983; Beun and Cremers, 1998). A few studies have compared monologue to dialogue reference, and have shown that monologue references tend to be harder for a later listener to disambiguate (Clark and Krych, 2004) and that subsequent references tend to be longer than those in dialogues (Krauss and Weinheimer, 1967). Aiming to generate natural reference in a monologue setting raises questions about what an algorithm should use to produce utterances like those produced by people. In a monologue setting, the speaker (or algorithm) gets no feedback from the listener; the speaker’s reference is not tied to interactions with othe</context>
</contexts>
<marker>Beun, Cremers, 1998</marker>
<rawString>Robbert-Jan Beun and Anita H. M. Cremers. 1998. Object reference in a shared domain of conversation. Pragmatics and Cognition, 6:121–52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Blaser</author>
<author>Zenon W Pylyshyn</author>
<author>Alex O Holcombe</author>
</authors>
<title>Tracking an object through feature space.</title>
<date>2000</date>
<journal>Nature,</journal>
<pages>408--196</pages>
<contexts>
<context position="25677" citStr="Blaser et al., 2000" startWordPosition="4222" endWordPosition="4225">Algorithm (Dale and Reiter, 1995) to produce otherwise “underspecified” reference. The spatial properties of the objects are kept relatively simple. They are not used in constructing the referring expression, but one aspect of the object’s three-dimensional shape (volume) affects the referring expression’s final form. To the authors’ knowledge, the current work is the first to suggest that objects themselves should have their spatial properties represented during reference. Research in cognitive modelling supports the idea that we attend to the spatial properties of objects when we view them (Blaser et al., 2000), and that we have purely spatial attentional mechanisms operating alongside non-spatial, feature-based attentional mechanisms (Treue and Trujillo, 1999). These feature-based attentional mechanisms pick out properties commonly utilized in REG, such as texture, orientation, and color. They also pick out edges and corners, contrast, and brightness. Spatial attentional mechanisms provide information about where the non-spatial features are located in relation to one another, size, and the spatial interrelations between component parts. Applying these findings to our study, an REG algorithm that g</context>
</contexts>
<marker>Blaser, Pylyshyn, Holcombe, 2000</marker>
<rawString>Erik Blaser, Zenon W. Pylyshyn, and Alex O. Holcombe. 2000. Tracking an object through feature space. Nature, 408:196–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan E Brennan</author>
<author>Herbert H Clark</author>
</authors>
<title>Conceptual pacts and lexical choice in conversation.</title>
<date>1996</date>
<journal>Journal of Experimental Psychology: Learning, Memory, and Cognition,</journal>
<pages>22--1482</pages>
<contexts>
<context position="4276" citStr="Brennan and Clark, 1996" startWordPosition="661" endWordPosition="664">lly use a two person (speaker-listener) communication task (e.g., Flavell et al., 1968; Krauss and Glucksberg, 1969; Ford and Olson, 1975). This research has 1A notable exception is Heeman and Hirst (1995). shown that reference is more accurate and efficient when it incorporates things like gesture and gaze (Clark and Krych, 2004). There is a trade-off in effort between initiating a noun phrase and refashioning it so that both speakers understand the referent (Clark and Wilkes-Gibbs, 1986), and speakers communicate to form lexical pacts on how to refer to an object (Sacks and Schegloff, 1979; Brennan and Clark, 1996). Mutual understanding of referents is achieved in part by referring within a subset of potential referents (Clark et al., 1983; Beun and Cremers, 1998). A few studies have compared monologue to dialogue reference, and have shown that monologue references tend to be harder for a later listener to disambiguate (Clark and Krych, 2004) and that subsequent references tend to be longer than those in dialogues (Krauss and Weinheimer, 1967). Aiming to generate natural reference in a monologue setting raises questions about what an algorithm should use to produce utterances like those produced by peop</context>
</contexts>
<marker>Brennan, Clark, 1996</marker>
<rawString>Susan E. Brennan and Herbert H. Clark. 1996. Conceptual pacts and lexical choice in conversation. Journal of Experimental Psychology: Learning, Memory, and Cognition, 22:1482–93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alphonse Chapanis</author>
<author>Robert N Parrish</author>
<author>Robert B Ochsman</author>
<author>Gerald D Weeks</author>
</authors>
<title>Studies in interactive communication: II. the effects of four communication modes on the linguistic performance of teams during cooperative problem solving. Human Factors,</title>
<date>1977</date>
<contexts>
<context position="2593" citStr="Chapanis et al., 1977" startWordPosition="393" endWordPosition="396"> (Dale and Reiter, 1995; Krahmer et al., 2003; van Deemter et al., 2006; Areces et al., 2008). Example referents may be referred to by their color, size, type (“dog” or “cup”), whether or not they have a beard, etc. Typically, the reference process proceeds by comparing the properties of the referent with the properties of all the other items in the set. The final expression roughly conforms to the Gricean maxims (Grice, 1975). However, when the goal is to generate natural reference, this framework is too simple. The form reference takes is profoundly affected by modality, task, and audience (Chapanis et al., 1977; Cohen, 1984; Clark and Wilkes-Gibbs, 1986), and even when these aspects are controlled, different people will refer differently to the same object (Mitchell, 2008). In light of this, we isolate one kind of natural reference and begin building the algorithmic framework necessary to generate the observed language. Psycholinguistic research has examined reference in a variety of settings, which may inform research on natural REG, but it is not always clear how to extend this work to a computational model. This is true in part because these studies favor an analysis of reference in the context o</context>
</contexts>
<marker>Chapanis, Parrish, Ochsman, Weeks, 1977</marker>
<rawString>Alphonse Chapanis, Robert N. Parrish, Robert B. Ochsman, and Gerald D. Weeks. 1977. Studies in interactive communication: II. the effects of four communication modes on the linguistic performance of teams during cooperative problem solving. Human Factors, 19:101–125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
<author>Adrian Bangerter</author>
</authors>
<title>Changing ideas about reference.</title>
<date>2004</date>
<booktitle>Experimental pragmatics,</booktitle>
<pages>25--49</pages>
<editor>In Ira A. Noveck and Dan Sperber, editors,</editor>
<publisher>Palgrave Macmillan,</publisher>
<location>Basingstoke, England.</location>
<contexts>
<context position="23112" citStr="Clark and Bangerter, 2004" startWordPosition="3818" endWordPosition="3821">else, which could be called describing. How to draw the line between a distinguishing reference and a description, and whether such a line can be drawn at all, is an interesting question. If the two are clearly distinct, then both are interesting to NLG research. If the two are one in the same, then this sheds some light on how REG algorithms should treat reference. We leave a more detailed discussion of this for future work, but note recent psycholinguistic work suggesting that referring establishes (1) an individual as the referent; (2) a conceptualization or perspective on that individual (Clark and Bangerter, 2004). Schematically, referring = indicating + describing. We now turn to a discussion of how the observed phenomena may be best represented in an REG algorithm. We propose that an algorithm capable of generating natural reference to objects in a visual scene should utilize (1) a spatial object representation; (2) a non-spatial feature-based representation; and (3) a knowledge base of object prototypes. 4.1 Spatial and Visual Properties It is perhaps unsurprising to find reference that exhibits spatial knowledge in a study where objects are presented in three-dimensional space. Human behavior is an</context>
</contexts>
<marker>Clark, Bangerter, 2004</marker>
<rawString>Herbert H. Clark and Adrian Bangerter. 2004. Changing ideas about reference. In Ira A. Noveck and Dan Sperber, editors, Experimental pragmatics, pages 25–49. Palgrave Macmillan, Basingstoke, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
<author>Meredyth A Krych</author>
</authors>
<title>Speaking while monitoring addressees for understanding.</title>
<date>2004</date>
<journal>Journal ofMemory and Language,</journal>
<volume>50</volume>
<pages>81</pages>
<contexts>
<context position="3984" citStr="Clark and Krych, 2004" startWordPosition="611" endWordPosition="614">tary generating agent.1 This tacitly assumes that reference will be taking place in a monologue setting, rather than a dialogue or group setting. Indeed, the goal of most REG algorithms is to produce uniquely distinguishing, one-shot referring expressions. Studies on natural reference usually use a two person (speaker-listener) communication task (e.g., Flavell et al., 1968; Krauss and Glucksberg, 1969; Ford and Olson, 1975). This research has 1A notable exception is Heeman and Hirst (1995). shown that reference is more accurate and efficient when it incorporates things like gesture and gaze (Clark and Krych, 2004). There is a trade-off in effort between initiating a noun phrase and refashioning it so that both speakers understand the referent (Clark and Wilkes-Gibbs, 1986), and speakers communicate to form lexical pacts on how to refer to an object (Sacks and Schegloff, 1979; Brennan and Clark, 1996). Mutual understanding of referents is achieved in part by referring within a subset of potential referents (Clark et al., 1983; Beun and Cremers, 1998). A few studies have compared monologue to dialogue reference, and have shown that monologue references tend to be harder for a later listener to disambigua</context>
</contexts>
<marker>Clark, Krych, 2004</marker>
<rawString>Herbert H. Clark and Meredyth A. Krych. 2004. Speaking while monitoring addressees for understanding. Journal ofMemory and Language, 50:62– 81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
<author>Deanna Wilkes-Gibbs</author>
</authors>
<title>Referring as a collaborative process.</title>
<date>1986</date>
<journal>Cognition,</journal>
<volume>22</volume>
<pages>39</pages>
<contexts>
<context position="2637" citStr="Clark and Wilkes-Gibbs, 1986" startWordPosition="399" endWordPosition="402">al., 2003; van Deemter et al., 2006; Areces et al., 2008). Example referents may be referred to by their color, size, type (“dog” or “cup”), whether or not they have a beard, etc. Typically, the reference process proceeds by comparing the properties of the referent with the properties of all the other items in the set. The final expression roughly conforms to the Gricean maxims (Grice, 1975). However, when the goal is to generate natural reference, this framework is too simple. The form reference takes is profoundly affected by modality, task, and audience (Chapanis et al., 1977; Cohen, 1984; Clark and Wilkes-Gibbs, 1986), and even when these aspects are controlled, different people will refer differently to the same object (Mitchell, 2008). In light of this, we isolate one kind of natural reference and begin building the algorithmic framework necessary to generate the observed language. Psycholinguistic research has examined reference in a variety of settings, which may inform research on natural REG, but it is not always clear how to extend this work to a computational model. This is true in part because these studies favor an analysis of reference in the context of collaboration; reference is embedded withi</context>
<context position="4146" citStr="Clark and Wilkes-Gibbs, 1986" startWordPosition="638" endWordPosition="641">he goal of most REG algorithms is to produce uniquely distinguishing, one-shot referring expressions. Studies on natural reference usually use a two person (speaker-listener) communication task (e.g., Flavell et al., 1968; Krauss and Glucksberg, 1969; Ford and Olson, 1975). This research has 1A notable exception is Heeman and Hirst (1995). shown that reference is more accurate and efficient when it incorporates things like gesture and gaze (Clark and Krych, 2004). There is a trade-off in effort between initiating a noun phrase and refashioning it so that both speakers understand the referent (Clark and Wilkes-Gibbs, 1986), and speakers communicate to form lexical pacts on how to refer to an object (Sacks and Schegloff, 1979; Brennan and Clark, 1996). Mutual understanding of referents is achieved in part by referring within a subset of potential referents (Clark et al., 1983; Beun and Cremers, 1998). A few studies have compared monologue to dialogue reference, and have shown that monologue references tend to be harder for a later listener to disambiguate (Clark and Krych, 2004) and that subsequent references tend to be longer than those in dialogues (Krauss and Weinheimer, 1967). Aiming to generate natural refe</context>
</contexts>
<marker>Clark, Wilkes-Gibbs, 1986</marker>
<rawString>Herbert H. Clark and Deanna Wilkes-Gibbs. 1986. Referring as a collaborative process. Cognition, 22:1– 39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
<author>Robert Schreuder</author>
<author>Samuel Buttrick</author>
</authors>
<title>Common ground and the understanding of demonstrative reference.</title>
<date>1983</date>
<journal>Journal of Verbal Learning and Verbal Behavior,</journal>
<pages>22--1</pages>
<contexts>
<context position="4403" citStr="Clark et al., 1983" startWordPosition="681" endWordPosition="684">1975). This research has 1A notable exception is Heeman and Hirst (1995). shown that reference is more accurate and efficient when it incorporates things like gesture and gaze (Clark and Krych, 2004). There is a trade-off in effort between initiating a noun phrase and refashioning it so that both speakers understand the referent (Clark and Wilkes-Gibbs, 1986), and speakers communicate to form lexical pacts on how to refer to an object (Sacks and Schegloff, 1979; Brennan and Clark, 1996). Mutual understanding of referents is achieved in part by referring within a subset of potential referents (Clark et al., 1983; Beun and Cremers, 1998). A few studies have compared monologue to dialogue reference, and have shown that monologue references tend to be harder for a later listener to disambiguate (Clark and Krych, 2004) and that subsequent references tend to be longer than those in dialogues (Krauss and Weinheimer, 1967). Aiming to generate natural reference in a monologue setting raises questions about what an algorithm should use to produce utterances like those produced by people. In a monologue setting, the speaker (or algorithm) gets no feedback from the listener; the speaker’s reference is not tied </context>
</contexts>
<marker>Clark, Schreuder, Buttrick, 1983</marker>
<rawString>Herbert H. Clark, Robert Schreuder, and Samuel Buttrick. 1983. Common ground and the understanding of demonstrative reference. Journal of Verbal Learning and Verbal Behavior, 22:1–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip R Cohen</author>
</authors>
<title>The pragmatics of referring and the modality of communication.</title>
<date>1984</date>
<journal>Computational Linguistics,</journal>
<volume>10</volume>
<issue>2</issue>
<contexts>
<context position="2606" citStr="Cohen, 1984" startWordPosition="397" endWordPosition="398">; Krahmer et al., 2003; van Deemter et al., 2006; Areces et al., 2008). Example referents may be referred to by their color, size, type (“dog” or “cup”), whether or not they have a beard, etc. Typically, the reference process proceeds by comparing the properties of the referent with the properties of all the other items in the set. The final expression roughly conforms to the Gricean maxims (Grice, 1975). However, when the goal is to generate natural reference, this framework is too simple. The form reference takes is profoundly affected by modality, task, and audience (Chapanis et al., 1977; Cohen, 1984; Clark and Wilkes-Gibbs, 1986), and even when these aspects are controlled, different people will refer differently to the same object (Mitchell, 2008). In light of this, we isolate one kind of natural reference and begin building the algorithmic framework necessary to generate the observed language. Psycholinguistic research has examined reference in a variety of settings, which may inform research on natural REG, but it is not always clear how to extend this work to a computational model. This is true in part because these studies favor an analysis of reference in the context of collaborati</context>
</contexts>
<marker>Cohen, 1984</marker>
<rawString>Philip R. Cohen. 1984. The pragmatics of referring and the modality of communication. Computational Linguistics, 10(2):97–146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Dale</author>
<author>Ehud Reiter</author>
</authors>
<title>Computational interpretations of the gricean maxims in the generation of referring expressions.</title>
<date>1995</date>
<journal>Cognitive Science,</journal>
<pages>18--233</pages>
<contexts>
<context position="1995" citStr="Dale and Reiter, 1995" startWordPosition="293" endWordPosition="296">rent aspects of how people generate reference, there has been surprisingly little research on how people refer to objects in a real-world setting. This paper addresses this issue, and we begin formulating the requirements for an REG algorithm that refers to visible three-dimensional objects in the real world. Reference to objects in a visual domain provides a straightforward extension of the sorts of reference REG research already tends to consider. Toy examples outline reference to objects, people, and animals that are perceptually available before the speaker begins generating an utterance (Dale and Reiter, 1995; Krahmer et al., 2003; van Deemter et al., 2006; Areces et al., 2008). Example referents may be referred to by their color, size, type (“dog” or “cup”), whether or not they have a beard, etc. Typically, the reference process proceeds by comparing the properties of the referent with the properties of all the other items in the set. The final expression roughly conforms to the Gricean maxims (Grice, 1975). However, when the goal is to generate natural reference, this framework is too simple. The form reference takes is profoundly affected by modality, task, and audience (Chapanis et al., 1977; </context>
<context position="14964" citStr="Dale and Reiter, 1995" startWordPosition="2467" endWordPosition="2470"> to the to the chin and then hang down either side of the chin. &lt;/HAIR&gt; &lt;EARS&gt; And the person’s ears are made up of (4,6 two beads, which are um love-heart-shaped beads), where the points of the love-hearts are facing outwards. And those are just placed um around same em same em horizontal line as the nose of the person’s face is. &lt;/EARS&gt; Figure 2: Excerpt Transcript. Using sets of properties to distinguish referents is nothing new in REG. Algorithms for the generation of referring expressions commonly use this as a starting point, proposing that properties are organized in some linear order (Dale and Reiter, 1995) or weighted order (Krahmer et al., 2003) as input. However, we find evidence that more is at play. A breakdown of our findings is listed in Table 2. 3.1 Spatial Reference In addition to properties that pick out referents, throughout the data we see reference to objects as they exist in space. Size is compared across different dimensions of different objects, and reference is made to different parts of the objects, picking out pieces within the whole. These two phenomena – relative size comparisons and partwhole modularity – point to an underlying spatial object representation that may be util</context>
<context position="25090" citStr="Dale and Reiter, 1995" startWordPosition="4131" endWordPosition="4134">al characteristics. Similarly, one of the strengths of the Graph-Based Algorithm (Krahmer et al., 2003) is its ability to generate expressions that involve relations between objects, and these include spatial ones (“next to”, “on top of”, etc.). In all these approaches, however, objects are essentially one-dimensional, represented as individual nodes. Work that does look at the spatial information of different objects is provided by Kelleher et al. (2005). In this approach, the overall volume of each object is calculated to assign salience rankings, which then allow the Incremental Algorithm (Dale and Reiter, 1995) to produce otherwise “underspecified” reference. The spatial properties of the objects are kept relatively simple. They are not used in constructing the referring expression, but one aspect of the object’s three-dimensional shape (volume) affects the referring expression’s final form. To the authors’ knowledge, the current work is the first to suggest that objects themselves should have their spatial properties represented during reference. Research in cognitive modelling supports the idea that we attend to the spatial properties of objects when we view them (Blaser et al., 2000), and that we</context>
</contexts>
<marker>Dale, Reiter, 1995</marker>
<rawString>Robert Dale and Ehud Reiter. 1995. Computational interpretations of the gricean maxims in the generation of referring expressions. Cognitive Science, 18:233–263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H Flavell</author>
<author>P T Botkin</author>
<author>D L Fry Jr</author>
<author>J W Wright</author>
<author>P E Jarvice</author>
</authors>
<title>The Development of RoleTaking and Communication Skills in Children.</title>
<date>1968</date>
<publisher>John Wiley,</publisher>
<location>New York.</location>
<contexts>
<context position="3738" citStr="Flavell et al., 1968" startWordPosition="572" endWordPosition="575"> part because these studies favor an analysis of reference in the context of collaboration; reference is embedded within language, and language is often a joint activity. However, most research on referring expression generation supposes a solitary generating agent.1 This tacitly assumes that reference will be taking place in a monologue setting, rather than a dialogue or group setting. Indeed, the goal of most REG algorithms is to produce uniquely distinguishing, one-shot referring expressions. Studies on natural reference usually use a two person (speaker-listener) communication task (e.g., Flavell et al., 1968; Krauss and Glucksberg, 1969; Ford and Olson, 1975). This research has 1A notable exception is Heeman and Hirst (1995). shown that reference is more accurate and efficient when it incorporates things like gesture and gaze (Clark and Krych, 2004). There is a trade-off in effort between initiating a noun phrase and refashioning it so that both speakers understand the referent (Clark and Wilkes-Gibbs, 1986), and speakers communicate to form lexical pacts on how to refer to an object (Sacks and Schegloff, 1979; Brennan and Clark, 1996). Mutual understanding of referents is achieved in part by ref</context>
</contexts>
<marker>Flavell, Botkin, Jr, Wright, Jarvice, 1968</marker>
<rawString>J. H. Flavell, P. T. Botkin, D. L. Fry Jr., J. W. Wright, and P. E. Jarvice. 1968. The Development of RoleTaking and Communication Skills in Children. John Wiley, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Ford</author>
<author>David Olson</author>
</authors>
<title>The elaboration of the noun phrase in children’s description of objects.</title>
<date>1975</date>
<journal>The Journal of Experimental Child Psychology,</journal>
<pages>19--371</pages>
<contexts>
<context position="3790" citStr="Ford and Olson, 1975" startWordPosition="580" endWordPosition="583">ference in the context of collaboration; reference is embedded within language, and language is often a joint activity. However, most research on referring expression generation supposes a solitary generating agent.1 This tacitly assumes that reference will be taking place in a monologue setting, rather than a dialogue or group setting. Indeed, the goal of most REG algorithms is to produce uniquely distinguishing, one-shot referring expressions. Studies on natural reference usually use a two person (speaker-listener) communication task (e.g., Flavell et al., 1968; Krauss and Glucksberg, 1969; Ford and Olson, 1975). This research has 1A notable exception is Heeman and Hirst (1995). shown that reference is more accurate and efficient when it incorporates things like gesture and gaze (Clark and Krych, 2004). There is a trade-off in effort between initiating a noun phrase and refashioning it so that both speakers understand the referent (Clark and Wilkes-Gibbs, 1986), and speakers communicate to form lexical pacts on how to refer to an object (Sacks and Schegloff, 1979; Brennan and Clark, 1996). Mutual understanding of referents is achieved in part by referring within a subset of potential referents (Clark</context>
</contexts>
<marker>Ford, Olson, 1975</marker>
<rawString>William Ford and David Olson. 1975. The elaboration of the noun phrase in children’s description of objects. The Journal of Experimental Child Psychology, 19:371–382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kotaro Funakoshi</author>
<author>Satoru Watanabe</author>
<author>Naoko Kuriyama</author>
<author>Takenobu Tokunaga</author>
</authors>
<title>Generating referring expressions using perceptual groups.</title>
<date>2004</date>
<booktitle>In Proceedings ofthe 3rd International Conference on Natural Language Generation,</booktitle>
<pages>51--60</pages>
<contexts>
<context position="24087" citStr="Funakoshi et al. (2004)" startWordPosition="3973" endWordPosition="3976">n; and (3) a knowledge base of object prototypes. 4.1 Spatial and Visual Properties It is perhaps unsurprising to find reference that exhibits spatial knowledge in a study where objects are presented in three-dimensional space. Human behavior is anchored in space, and spatial information is essential for our ability to navigate the world we live in. However, referring expression generation algorithms geared towards spatial representations have oversimplified this tendency, keeping objects within the realm of twodimensions and only looking at the spatial relations between objects. For example, Funakoshi et al. (2004) and Gatt (2006) focus on how objects should be clustered together to form groups. This utilizes some of the spatial information between objects, but does not address the spatial, three-dimensional nature of objects themselves. Rather, objects exist as entities that may be grouped with other entities in a set or singled out as individual objects; they do not have their own spatial characteristics. Similarly, one of the strengths of the Graph-Based Algorithm (Krahmer et al., 2003) is its ability to generate expressions that involve relations between objects, and these include spatial ones (“nex</context>
</contexts>
<marker>Funakoshi, Watanabe, Kuriyama, Tokunaga, 2004</marker>
<rawString>Kotaro Funakoshi, Satoru Watanabe, Naoko Kuriyama, and Takenobu Tokunaga. 2004. Generating referring expressions using perceptual groups. In Proceedings ofthe 3rd International Conference on Natural Language Generation, pages 51–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Albert Gatt</author>
</authors>
<title>Structuring knowledge for reference generation: A clustering algorithm.</title>
<date>2006</date>
<booktitle>Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL-06),</booktitle>
<pages>321--328</pages>
<contexts>
<context position="24103" citStr="Gatt (2006)" startWordPosition="3978" endWordPosition="3979">of object prototypes. 4.1 Spatial and Visual Properties It is perhaps unsurprising to find reference that exhibits spatial knowledge in a study where objects are presented in three-dimensional space. Human behavior is anchored in space, and spatial information is essential for our ability to navigate the world we live in. However, referring expression generation algorithms geared towards spatial representations have oversimplified this tendency, keeping objects within the realm of twodimensions and only looking at the spatial relations between objects. For example, Funakoshi et al. (2004) and Gatt (2006) focus on how objects should be clustered together to form groups. This utilizes some of the spatial information between objects, but does not address the spatial, three-dimensional nature of objects themselves. Rather, objects exist as entities that may be grouped with other entities in a set or singled out as individual objects; they do not have their own spatial characteristics. Similarly, one of the strengths of the Graph-Based Algorithm (Krahmer et al., 2003) is its ability to generate expressions that involve relations between objects, and these include spatial ones (“next to”, “on top o</context>
</contexts>
<marker>Gatt, 2006</marker>
<rawString>Albert Gatt. 2006. Structuring knowledge for reference generation: A clustering algorithm. Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL-06), pages 321–328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul H Grice</author>
</authors>
<date>1975</date>
<booktitle>Logic and conversation. Syntax and Semantics,</booktitle>
<pages>3--41</pages>
<contexts>
<context position="2402" citStr="Grice, 1975" startWordPosition="365" endWordPosition="366">G research already tends to consider. Toy examples outline reference to objects, people, and animals that are perceptually available before the speaker begins generating an utterance (Dale and Reiter, 1995; Krahmer et al., 2003; van Deemter et al., 2006; Areces et al., 2008). Example referents may be referred to by their color, size, type (“dog” or “cup”), whether or not they have a beard, etc. Typically, the reference process proceeds by comparing the properties of the referent with the properties of all the other items in the set. The final expression roughly conforms to the Gricean maxims (Grice, 1975). However, when the goal is to generate natural reference, this framework is too simple. The form reference takes is profoundly affected by modality, task, and audience (Chapanis et al., 1977; Cohen, 1984; Clark and Wilkes-Gibbs, 1986), and even when these aspects are controlled, different people will refer differently to the same object (Mitchell, 2008). In light of this, we isolate one kind of natural reference and begin building the algorithmic framework necessary to generate the observed language. Psycholinguistic research has examined reference in a variety of settings, which may inform r</context>
</contexts>
<marker>Grice, 1975</marker>
<rawString>Paul H. Grice. 1975. Logic and conversation. Syntax and Semantics, 3:41–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter A Heeman</author>
<author>Graeme Hirst</author>
</authors>
<title>Collaborating on referring expressions.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<contexts>
<context position="3857" citStr="Heeman and Hirst (1995)" startWordPosition="591" endWordPosition="594">thin language, and language is often a joint activity. However, most research on referring expression generation supposes a solitary generating agent.1 This tacitly assumes that reference will be taking place in a monologue setting, rather than a dialogue or group setting. Indeed, the goal of most REG algorithms is to produce uniquely distinguishing, one-shot referring expressions. Studies on natural reference usually use a two person (speaker-listener) communication task (e.g., Flavell et al., 1968; Krauss and Glucksberg, 1969; Ford and Olson, 1975). This research has 1A notable exception is Heeman and Hirst (1995). shown that reference is more accurate and efficient when it incorporates things like gesture and gaze (Clark and Krych, 2004). There is a trade-off in effort between initiating a noun phrase and refashioning it so that both speakers understand the referent (Clark and Wilkes-Gibbs, 1986), and speakers communicate to form lexical pacts on how to refer to an object (Sacks and Schegloff, 1979; Brennan and Clark, 1996). Mutual understanding of referents is achieved in part by referring within a subset of potential referents (Clark et al., 1983; Beun and Cremers, 1998). A few studies have compared</context>
</contexts>
<marker>Heeman, Hirst, 1995</marker>
<rawString>Peter A. Heeman and Graeme Hirst. 1995. Collaborating on referring expressions. Computational Linguistics, 21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laurent Itti</author>
<author>Michael A Arbib</author>
</authors>
<title>Attention and the minimal subscene.</title>
<date>2005</date>
<editor>In Michael A. Arbib, editor,</editor>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="31385" citStr="Itti and Arbib, 2005" startWordPosition="5109" endWordPosition="5112">as well as relevant values for material, color, etc. This suggests that the spatial and non-spatial feature-based representations proposed for visible objects could be used to represent prototype objects as well. Indeed, how we view and refer to objects appears to be influenced by the interaction of these structures: Expectations about an object’s spatial properties guide our attention towards expected object parts and non-spatial, feature-based properties throughout the scene (Kosslyn, 1994; Itti and Koch, 2001). This affects the kinds of things we are most likely to generate language about (Itti and Arbib, 2005). We can now outline some general requirements for an algorithm capable of generating naturalistic reference to objects in a visual scene: Input to such an algorithm should include a feature-based representation, which we will call a propositional representation, with values for color, texture, etc., and a spatial representation, with symbolic information about objects’ size and the spatial relationships between components. A system that generates naturalistic reference must also use a knowledge base storing information about object prototypes, which may be represented in terms of their own pr</context>
</contexts>
<marker>Itti, Arbib, 2005</marker>
<rawString>Laurent Itti and Michael A. Arbib. 2005. Attention and the minimal subscene. In Michael A. Arbib, editor, Action to Language via the Mirror Neuron System. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laurent Itti</author>
<author>Christof Koch</author>
</authors>
<title>Computational modelling of visual attention.</title>
<date>2001</date>
<journal>Nature Reviews Neuroscience.</journal>
<contexts>
<context position="31282" citStr="Itti and Koch, 2001" startWordPosition="5091" endWordPosition="5094">mation about prototypical objects’ component parts and where they are placed relative to one another, as well as relevant values for material, color, etc. This suggests that the spatial and non-spatial feature-based representations proposed for visible objects could be used to represent prototype objects as well. Indeed, how we view and refer to objects appears to be influenced by the interaction of these structures: Expectations about an object’s spatial properties guide our attention towards expected object parts and non-spatial, feature-based properties throughout the scene (Kosslyn, 1994; Itti and Koch, 2001). This affects the kinds of things we are most likely to generate language about (Itti and Arbib, 2005). We can now outline some general requirements for an algorithm capable of generating naturalistic reference to objects in a visual scene: Input to such an algorithm should include a feature-based representation, which we will call a propositional representation, with values for color, texture, etc., and a spatial representation, with symbolic information about objects’ size and the spatial relationships between components. A system that generates naturalistic reference must also use a knowle</context>
</contexts>
<marker>Itti, Koch, 2001</marker>
<rawString>Laurent Itti and Christof Koch. 2001. Computational modelling of visual attention. Nature Reviews Neuroscience.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kelleher</author>
<author>F Costello</author>
<author>J van Genabith</author>
</authors>
<title>Dynamically structuring, updating and interrelating representations of visual and linguistic discourse context.</title>
<date>2005</date>
<journal>Artificial Intelligence,</journal>
<pages>167--62</pages>
<marker>Kelleher, Costello, van Genabith, 2005</marker>
<rawString>J. Kelleher, F. Costello, and J. van Genabith. 2005. Dynamically structuring, updating and interrelating representations of visual and linguistic discourse context. Artificial Intelligence, 167:62–102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen M Kosslyn</author>
</authors>
<title>Image and Brain: The Resolution of the Imagery Debate.</title>
<date>1994</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="30377" citStr="Kosslyn, 1994" startWordPosition="4953" endWordPosition="4954">rototypes’ in the inferior temporal lobe of the brain (Logothetis and - A spatial representation (depicting size, interrelations between component parts) - A non-spatial, propositional representation (describing color, texture, orientation, etc.) - A knowledge base with stored prototypical object propositional and spatial representations Table 4: Requirements for an REG algorithm that generates natural reference to visual objects. Sheinberg, 1996; Riesenhuber and Poggio, 2000; Palmeri and Gauthier, 2004). Most formal theories of object perception posit some sort of category activation system (Kosslyn, 1994), a system that matches input properties of objects to those of stored prototypes, which then helps guide expectations about objects in a top-down fashion.3 This appears to be a neurological correlate of the knowledge base we propose to underlie analogies. Such a system contains information about prototypical objects’ component parts and where they are placed relative to one another, as well as relevant values for material, color, etc. This suggests that the spatial and non-spatial feature-based representations proposed for visible objects could be used to represent prototype objects as well. </context>
</contexts>
<marker>Kosslyn, 1994</marker>
<rawString>Stephen M. Kosslyn. 1994. Image and Brain: The Resolution of the Imagery Debate. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emiel Krahmer</author>
<author>Sebastiaan van Erk</author>
<author>Andr´e Verleg</author>
</authors>
<title>Graph-based generation of referring expressions.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<marker>Krahmer, van Erk, Verleg, 2003</marker>
<rawString>Emiel Krahmer, Sebastiaan van Erk, and Andr´e Verleg. 2003. Graph-based generation of referring expressions. Computational Linguistics, 29(1):53–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert M Krauss</author>
<author>Sam Glucksberg</author>
</authors>
<title>The development of communication: Competence as a function of age. Child Development,</title>
<date>1969</date>
<pages>40--255</pages>
<contexts>
<context position="3767" citStr="Krauss and Glucksberg, 1969" startWordPosition="576" endWordPosition="579">udies favor an analysis of reference in the context of collaboration; reference is embedded within language, and language is often a joint activity. However, most research on referring expression generation supposes a solitary generating agent.1 This tacitly assumes that reference will be taking place in a monologue setting, rather than a dialogue or group setting. Indeed, the goal of most REG algorithms is to produce uniquely distinguishing, one-shot referring expressions. Studies on natural reference usually use a two person (speaker-listener) communication task (e.g., Flavell et al., 1968; Krauss and Glucksberg, 1969; Ford and Olson, 1975). This research has 1A notable exception is Heeman and Hirst (1995). shown that reference is more accurate and efficient when it incorporates things like gesture and gaze (Clark and Krych, 2004). There is a trade-off in effort between initiating a noun phrase and refashioning it so that both speakers understand the referent (Clark and Wilkes-Gibbs, 1986), and speakers communicate to form lexical pacts on how to refer to an object (Sacks and Schegloff, 1979; Brennan and Clark, 1996). Mutual understanding of referents is achieved in part by referring within a subset of pot</context>
</contexts>
<marker>Krauss, Glucksberg, 1969</marker>
<rawString>Robert M. Krauss and Sam Glucksberg. 1969. The development of communication: Competence as a function of age. Child Development, 40:255–266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert M Krauss</author>
<author>Sidney Weinheimer</author>
</authors>
<title>Effect of referent similarity and communication mode on verbal encoding.</title>
<date>1967</date>
<journal>Journal of Verbal Learning and Verbal Behavior,</journal>
<pages>6--359</pages>
<contexts>
<context position="4713" citStr="Krauss and Weinheimer, 1967" startWordPosition="730" endWordPosition="733">eakers understand the referent (Clark and Wilkes-Gibbs, 1986), and speakers communicate to form lexical pacts on how to refer to an object (Sacks and Schegloff, 1979; Brennan and Clark, 1996). Mutual understanding of referents is achieved in part by referring within a subset of potential referents (Clark et al., 1983; Beun and Cremers, 1998). A few studies have compared monologue to dialogue reference, and have shown that monologue references tend to be harder for a later listener to disambiguate (Clark and Krych, 2004) and that subsequent references tend to be longer than those in dialogues (Krauss and Weinheimer, 1967). Aiming to generate natural reference in a monologue setting raises questions about what an algorithm should use to produce utterances like those produced by people. In a monologue setting, the speaker (or algorithm) gets no feedback from the listener; the speaker’s reference is not tied to interactions with other participants. The speaker is therefore in a difficult position, attempting to clearly convey a referent without being able to check if the reference is understood along the way. Recent studies that have focused on monologue reference do so rather explicitly, which may affect partici</context>
</contexts>
<marker>Krauss, Weinheimer, 1967</marker>
<rawString>Robert M. Krauss and Sidney Weinheimer. 1967. Effect of referent similarity and communication mode on verbal encoding. Journal of Verbal Learning and Verbal Behavior, 6:359–363.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikos K Logothetis</author>
<author>David L Sheinberg</author>
</authors>
<title>Visual object recognition. Annual Review Neuroscience,</title>
<date>1996</date>
<marker>Logothetis, Sheinberg, 1996</marker>
<rawString>Nikos K. Logothetis and David L. Sheinberg. 1996. Visual object recognition. Annual Review Neuroscience, 19:577–621.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominic Mazzoni</author>
</authors>
<date>2010</date>
<publisher>Audacity.</publisher>
<contexts>
<context position="10186" citStr="Mazzoni, 2010" startWordPosition="1626" endWordPosition="1627"> group of objects had different colors, textures, shapes, patterns, and were made of different materials. Similar objects were grouped together on the board, with a label placed underneath. This was done to control the head noun used in each reference. The objects were used to make up 5 different craft “face” pictures. Subjects sat at a desk facing the board and the stack of pictures. A picture of the board is shown in Figure 1. Subjects were recorded on a head-mounted microphone, which fed directly into a laptop placed on the left of the desk. The open-source audiorecording program Audacity (Mazzoni, 2010) was used to record the audio signal and export it to wave format. 2.3 Procedure Subjects were told to give instructions on how to construct each face using the craft supplies on the board. They were instructed to be clear enough for a listener to be able to reconstruct each face without the pictures, with only the board items in front of them. A pilot study revealed that such openended instructions left some subjects spending an inordinate amount of time on the exact placement of each piece, and so in the current study subjects were told that each face should take “a couple” minutes, and that</context>
</contexts>
<marker>Mazzoni, 2010</marker>
<rawString>Dominic Mazzoni. 2010. Audacity.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Margaret Mitchell</author>
</authors>
<title>Towards the generation of natural reference. Master’s thesis,</title>
<date>2008</date>
<institution>University of Washington.</institution>
<contexts>
<context position="2758" citStr="Mitchell, 2008" startWordPosition="419" endWordPosition="420">up”), whether or not they have a beard, etc. Typically, the reference process proceeds by comparing the properties of the referent with the properties of all the other items in the set. The final expression roughly conforms to the Gricean maxims (Grice, 1975). However, when the goal is to generate natural reference, this framework is too simple. The form reference takes is profoundly affected by modality, task, and audience (Chapanis et al., 1977; Cohen, 1984; Clark and Wilkes-Gibbs, 1986), and even when these aspects are controlled, different people will refer differently to the same object (Mitchell, 2008). In light of this, we isolate one kind of natural reference and begin building the algorithmic framework necessary to generate the observed language. Psycholinguistic research has examined reference in a variety of settings, which may inform research on natural REG, but it is not always clear how to extend this work to a computational model. This is true in part because these studies favor an analysis of reference in the context of collaboration; reference is embedded within language, and language is often a joint activity. However, most research on referring expression generation supposes a </context>
</contexts>
<marker>Mitchell, 2008</marker>
<rawString>Margaret Mitchell. 2008. Towards the generation of natural reference. Master’s thesis, University of Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas J Palmeri</author>
<author>Isabel Gauthier</author>
</authors>
<title>Visual object understanding.</title>
<date>2004</date>
<journal>Nature Reviews Neuroscience,</journal>
<pages>5--291</pages>
<contexts>
<context position="30272" citStr="Palmeri and Gauthier, 2004" startWordPosition="4934" endWordPosition="4937">at expectations about objects’ visual and spatial characteristics are derived from stored representations of object ‘prototypes’ in the inferior temporal lobe of the brain (Logothetis and - A spatial representation (depicting size, interrelations between component parts) - A non-spatial, propositional representation (describing color, texture, orientation, etc.) - A knowledge base with stored prototypical object propositional and spatial representations Table 4: Requirements for an REG algorithm that generates natural reference to visual objects. Sheinberg, 1996; Riesenhuber and Poggio, 2000; Palmeri and Gauthier, 2004). Most formal theories of object perception posit some sort of category activation system (Kosslyn, 1994), a system that matches input properties of objects to those of stored prototypes, which then helps guide expectations about objects in a top-down fashion.3 This appears to be a neurological correlate of the knowledge base we propose to underlie analogies. Such a system contains information about prototypical objects’ component parts and where they are placed relative to one another, as well as relevant values for material, color, etc. This suggests that the spatial and non-spatial feature-</context>
</contexts>
<marker>Palmeri, Gauthier, 2004</marker>
<rawString>Thomas J. Palmeri and Isabel Gauthier. 2004. Visual object understanding. Nature Reviews Neuroscience, 5:291–303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maximilian Riesenhuber</author>
<author>Tomaso Poggio</author>
</authors>
<title>Models of object recognition.</title>
<date>2000</date>
<journal>Nature Neuroscience Supplement,</journal>
<pages>3--1199</pages>
<contexts>
<context position="30243" citStr="Riesenhuber and Poggio, 2000" startWordPosition="4930" endWordPosition="4933">urophysiology that suggests that expectations about objects’ visual and spatial characteristics are derived from stored representations of object ‘prototypes’ in the inferior temporal lobe of the brain (Logothetis and - A spatial representation (depicting size, interrelations between component parts) - A non-spatial, propositional representation (describing color, texture, orientation, etc.) - A knowledge base with stored prototypical object propositional and spatial representations Table 4: Requirements for an REG algorithm that generates natural reference to visual objects. Sheinberg, 1996; Riesenhuber and Poggio, 2000; Palmeri and Gauthier, 2004). Most formal theories of object perception posit some sort of category activation system (Kosslyn, 1994), a system that matches input properties of objects to those of stored prototypes, which then helps guide expectations about objects in a top-down fashion.3 This appears to be a neurological correlate of the knowledge base we propose to underlie analogies. Such a system contains information about prototypical objects’ component parts and where they are placed relative to one another, as well as relevant values for material, color, etc. This suggests that the spa</context>
</contexts>
<marker>Riesenhuber, Poggio, 2000</marker>
<rawString>Maximilian Riesenhuber and Tomaso Poggio. 2000. Models of object recognition. Nature Neuroscience Supplement, 3:1199–1204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eleanor Rosch</author>
</authors>
<title>Cognitive representation of semantic categories.</title>
<date>1975</date>
<journal>Journal of Experimental Psychology,</journal>
<pages>104--192</pages>
<contexts>
<context position="21370" citStr="Rosch (1975)" startWordPosition="3531" endWordPosition="3532">“a natural-looking piece ofpipe-cleaner, it looks a bit like a rope” (15) “a pipe-cleaner that looks a bit like... a fluffy caterpillar... ” In (13), a participant makes reference to a SHAPE property of an object not on the board. In (14) and (15), participants refer to objects that may share a variety of properties with the referent, but are also not on the board. Reference to these other items do not pick out single objects, but types of objects (e.g., an object type, not token). They correspond to some prototypical idea of an object with properties similar to those of the referent. Work by Rosch (1975) has examined this tendency, introducing the idea ofprototype theory, which proposes that there may be some central, ‘prototypical’ notions of items. A knowledge base with stored prototypes could be utilized by an REG algorithm to compare the target referent to item prototypes. Such representations would help guide the generation of reference to items not in the scene, but similar to the target referent. 4 Discussion We have discussed several different aspects of reference in a study where referring expressions are elicited for objects in a spatial, visual scene. Reference in this domain draws</context>
</contexts>
<marker>Rosch, 1975</marker>
<rawString>Eleanor Rosch. 1975. Cognitive representation of semantic categories. Journal of Experimental Psychology, 104:192–233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harvey Sacks</author>
<author>Emanuel A Schegloff</author>
</authors>
<title>Two preferences in the organization of reference to persons in conversation and their interaction.</title>
<date>1979</date>
<booktitle>Everyday Language: Studies in Ethnomethodology,</booktitle>
<pages>15--21</pages>
<editor>In George Psathas, editor,</editor>
<publisher>Irvington Publishers,</publisher>
<location>New York.</location>
<contexts>
<context position="4250" citStr="Sacks and Schegloff, 1979" startWordPosition="657" endWordPosition="660">s on natural reference usually use a two person (speaker-listener) communication task (e.g., Flavell et al., 1968; Krauss and Glucksberg, 1969; Ford and Olson, 1975). This research has 1A notable exception is Heeman and Hirst (1995). shown that reference is more accurate and efficient when it incorporates things like gesture and gaze (Clark and Krych, 2004). There is a trade-off in effort between initiating a noun phrase and refashioning it so that both speakers understand the referent (Clark and Wilkes-Gibbs, 1986), and speakers communicate to form lexical pacts on how to refer to an object (Sacks and Schegloff, 1979; Brennan and Clark, 1996). Mutual understanding of referents is achieved in part by referring within a subset of potential referents (Clark et al., 1983; Beun and Cremers, 1998). A few studies have compared monologue to dialogue reference, and have shown that monologue references tend to be harder for a later listener to disambiguate (Clark and Krych, 2004) and that subsequent references tend to be longer than those in dialogues (Krauss and Weinheimer, 1967). Aiming to generate natural reference in a monologue setting raises questions about what an algorithm should use to produce utterances l</context>
</contexts>
<marker>Sacks, Schegloff, 1979</marker>
<rawString>Harvey Sacks and Emanuel A. Schegloff. 1979. Two preferences in the organization of reference to persons in conversation and their interaction. In George Psathas, editor, Everyday Language: Studies in Ethnomethodology, pages 15–21. Irvington Publishers, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stegan Treue</author>
<author>Julio C Martinez Trujillo</author>
</authors>
<title>Feature-based attention influences motion processing gain in macaque visual cortex.</title>
<date>1999</date>
<journal>Nature,</journal>
<volume>399</volume>
<pages>579</pages>
<contexts>
<context position="25830" citStr="Treue and Trujillo, 1999" startWordPosition="4241" endWordPosition="4244"> They are not used in constructing the referring expression, but one aspect of the object’s three-dimensional shape (volume) affects the referring expression’s final form. To the authors’ knowledge, the current work is the first to suggest that objects themselves should have their spatial properties represented during reference. Research in cognitive modelling supports the idea that we attend to the spatial properties of objects when we view them (Blaser et al., 2000), and that we have purely spatial attentional mechanisms operating alongside non-spatial, feature-based attentional mechanisms (Treue and Trujillo, 1999). These feature-based attentional mechanisms pick out properties commonly utilized in REG, such as texture, orientation, and color. They also pick out edges and corners, contrast, and brightness. Spatial attentional mechanisms provide information about where the non-spatial features are located in relation to one another, size, and the spatial interrelations between component parts. Applying these findings to our study, an REG algorithm that generates natural reference should utilize a visual, feature-based representation of objects alongside a structural, spatial representation of objects. A </context>
</contexts>
<marker>Treue, Trujillo, 1999</marker>
<rawString>Stegan Treue and Julio C. Martinez Trujillo. 1999. Feature-based attention influences motion processing gain in macaque visual cortex. Nature, 399:575– 579.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kees van Deemter</author>
<author>Ielka van der Sluis</author>
<author>Albert Gatt</author>
</authors>
<title>Building a semantically transparent corpus for the generation of referring expressions.</title>
<date>2006</date>
<booktitle>In Proceedings ofthe 4th International Conference on Natural Language Generation,</booktitle>
<publisher>ACL.</publisher>
<location>Sydney, Australia.</location>
<marker>van Deemter, van der Sluis, Gatt, 2006</marker>
<rawString>Kees van Deemter, Ielka van der Sluis, and Albert Gatt. 2006. Building a semantically transparent corpus for the generation of referring expressions. In Proceedings ofthe 4th International Conference on Natural Language Generation, Sydney, Australia. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jette Viethen</author>
<author>Robert Dale</author>
</authors>
<title>The use of spatial descriptions in referring expressions.</title>
<date>2008</date>
<booktitle>In Proceedings of the 5th International Conference on Natural Language Generation, INLG-08,</booktitle>
<publisher>ACL.</publisher>
<location>Salt Fork, Ohio.</location>
<contexts>
<context position="5446" citStr="Viethen and Dale, 2008" startWordPosition="847" endWordPosition="850">use to produce utterances like those produced by people. In a monologue setting, the speaker (or algorithm) gets no feedback from the listener; the speaker’s reference is not tied to interactions with other participants. The speaker is therefore in a difficult position, attempting to clearly convey a referent without being able to check if the reference is understood along the way. Recent studies that have focused on monologue reference do so rather explicitly, which may affect participant responses. These studies utilize 2D graphical depictions of simple 3D objects (van Deemter et al., 2006; Viethen and Dale, 2008), where a small set of properties can be used to distinguish one item from another. The expressions are elicited in isolation, typed and then submitted, which may hide some of the underlying referential processes. None of these studies utilize actual objects. It is therefore difficult to use these data to draw conclusions about how reference works in naturalistic settings. It is unclear if these experimental settings are natural enough, i.e., if they get at reference as it may occur every day. The study in this paper attempts to bring out information about reference in a number of ways. First,</context>
</contexts>
<marker>Viethen, Dale, 2008</marker>
<rawString>Jette Viethen and Robert Dale. 2008. The use of spatial descriptions in referring expressions. In Proceedings of the 5th International Conference on Natural Language Generation, INLG-08, Salt Fork, Ohio. ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>