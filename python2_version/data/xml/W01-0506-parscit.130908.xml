<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000010">
<note confidence="0.771595">
In Proceedings of the 6th Conference on Empirical Methods in Natural Language Processing (EMNLP 2001), L.
Lee and D. Harman (Eds.), pp. 44–50, Carnegie Mellon University, Pittsburgh, PA, USA, 2001.
</note>
<title confidence="0.976938">
Stacking classifiers for anti-spam filtering of e-mail
</title>
<author confidence="0.9012225">
Georgios Sakkis&apos;, Ion Androutsopouloso, Georgios Paliouraso, Vangelis Karkaletsiso,
Constantine D. Spyropouloso, and Panagiotis Stamatopoulos&apos;
</author>
<affiliation confidence="0.9985965">
♦Department of Informatics ♣Software and Knowledge Engineering
University of Athens Laboratory
</affiliation>
<address confidence="0.4608632">
TYPA Buildings, Panepistimiopolis Institute of Informatics and Telecommunications
GR-157 71 Athens, Greece National Centre for Scientific Research
e-mail: {stud0926, “Demokritos”
T.Stamatopoulos}@di.uoa.gr GR-153 10 Ag. Paraskevi, Athens, Greece
e-mail: {ionandr, paliourg, vangelis,
</address>
<email confidence="0.928337">
costass}@iit.demokritos.gr
</email>
<sectionHeader confidence="0.996837" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999931083333333">
We evaluate empirically a scheme for
combining classifiers, known as stacked
generalization, in the context of anti-spam
filtering, a novel cost-sensitive application of
text categorization. Unsolicited commercial e-
mail, or “spam”, floods mailboxes, causing
frustration, wasting bandwidth, and exposing
minors to unsuitable content. Using a public
corpus, we show that stacking can improve the
efficiency of automatically induced anti-spam
filters, and that such filters can be used in real-
life applications.
</bodyText>
<sectionHeader confidence="0.972063" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.999977521739131">
This paper presents an empirical evaluation of
stacked generalization, a scheme for combining
automatically induced classifiers, in the context
of anti-spam filtering, a novel cost-sensitive
application of text categorization.
The increasing popularity and low cost of e-
mail have intrigued direct marketers to flood the
mailboxes of thousands of users with unsolicited
messages, advertising anything, from vacations
to get-rich schemes. These messages, known as
spam or more formally Unsolicited Commercial
E-mail, are extremely annoying, as they clutter
mailboxes, prolong dial-up connections, and
often expose minors to unsuitable content
(Cranor &amp; Lamacchia, 1998).
Legal and simplistic technical counter-
measures, like blacklists and keyword-based
filters, have had a very limited effect so far.1 The
success of machine learning techniques in text
categorization (Sebastiani, 2001) has recently
led to alternative, learning-based approaches
(Sahami, et al. 1998; Pantel &amp; Lin, 1998;
Drucker, et al. 1999). A classifier capable of
distinguishing between spam and non-spam,
hereafter legitimate, messages is induced from a
manually categorized learning collection of
messages, and is then used to identify incoming
spam e-mail. Initial results have been promising,
and experiments are becoming more systematic,
by exploiting recently introduced benchmark
corpora, and cost-sensitive evaluation measures
(Gomez Hidalgo, et al. 2000; Androutsopoulos,
et al. 2000a, b, c).
Stacked generalization (Wolpert, 1992), or
stacking, is an approach for constructing
classifier ensembles. A classifier ensemble, or
committee, is a set of classifiers whose
individual decisions are combined in some way
to classify new instances (Dietterich, 1997).
Stacking combines multiple classifiers to induce
a higher-level classifier with improved
performance. The latter can be thought of as the
president of a committee with the ground-level
classifiers as members. Each unseen incoming
message is first given to the members; the
president then decides on the category of the
</bodyText>
<footnote confidence="0.9514675">
1 Consult www.cauce.org, spam.abuse.net, and
www.junkemail.org.
</footnote>
<bodyText confidence="0.999807535714286">
message by considering the opinions of the
members and the message itself. Ground-level
classifiers often make different classification
errors. Hence, a president that has successfully
learned when to trust each of the members can
improve overall performance.
We have experimented with two ground-
level classifiers for which results on a public
benchmark corpus are available: a Naïve Bayes
classifier (Androutsopoulos, et al. 2000a, c) and
a memory-based classifier (Androutsopoulos, et
al. 2000b; Sakkis, et al. 2001). Using a third,
memory-based classifier as president, we
investigated two versions of stacking and two
different cost-sensitive scenarios. Overall, our
results indicate that stacking improves the
performance of the ground-level classifiers, and
that the performance of the resulting anti-spam
filter is acceptable for real-life applications.
Section 1 below presents the benchmark
corpus and the preprocessing of the messages;
section 2 introduces cost-sensitive evaluation
measures; section 3 provides details on the
stacking approaches that were explored; section
4 discusses the learning algorithms that were
employed and the motivation for selecting them;
section 5 presents our experimental results
followed by conclusions.
</bodyText>
<sectionHeader confidence="0.8513385" genericHeader="method">
1 Benchmark corpus and
preprocessing
</sectionHeader>
<bodyText confidence="0.966959418181818">
Text categorization has benefited from public
benchmark corpora. Producing such corpora for
anti-spam filtering is not straightforward, since
user mailboxes cannot be made public without
considering privacy issues. A useful public
approximation of a user’s mailbox, however, can
be constructed by mixing spam messages with
messages extracted from spam-free public
archives of mailing lists. The corpus that we
used, Ling-Spam, follows this approach
(Androutsopoulos, et al. 2000a, b; Sakkis, et al.
2001). It is a mixture of spam messages and
messages sent via the Linguist, a moderated list
about the science and profession of linguistics.
The corpus consists of 2412 Linguist messages
and 481 spam messages.
Spam messages constitute 16.6% of Ling-
Spam, close to the rates reported by Cranor and
LaMacchia (1998), and Sahami et al. (1998).
Although the Linguist messages are more topic-
specific than most users’ e-mail, they are less
standardized than one might expect. For
example, they contain job postings, software
availability announcements and even flame-like
responses. Moreover, recent experiments with an
encoded user mailbox and a Naïve Bayes (NB)
classifier (Androutsopoulos, et al. 2000c)
yielded results similar to those obtained with
Ling-Spam (Androutsopoulos, et al. 2000a).
Therefore, experimentation with Ling-Spam can
provide useful indicative results, at least in a
preliminary stage. Furthermore, experiments
with Ling-Spam can be seen as studies of anti-
spam filtering of open unmoderated lists.
Each message of Ling-Spam was converted
into a vector x x1 , x2 , x3, ... , x„
� = , where
x1,...,x„ are the values of attributes
X1,...,X„ . Each attribute shows if a particular
word (e.g. “adult”) occurs in the message. All
attributes are binary: Xi = 1 if the word is
present; otherwise Xi = 0. To avoid treating
forms of the same word as different attributes, a
lemmatizer was applied, converting each word
to its base form.
To reduce the dimensionality, attribute
selection was performed. First, words occurring
in less than 4 messages were discarded. Then,
the Information Gain (IG) of each candidate
attribute X was computed:
The attributes with the m highest IG-scores were
selected, with m corresponding to the best
configurations of the ground classifiers that have
been reported for Ling-Spam (Androutsopoulos,
et al. 2000a; Sakkis, et al. 2001); see Section 4.
</bodyText>
<sectionHeader confidence="0.99042" genericHeader="method">
2 Evaluation measures
</sectionHeader>
<bodyText confidence="0.999443142857143">
Blocking a legitimate message is generally more
severe an error than accepting a spam message.
Let L → S and S → L denote the two error
types, respectively, and let us assume that
L → S is λ times as costly as S → L .
Previous research has considered three cost
scenarios, where λ = 1, 9, or 999
</bodyText>
<equation confidence="0.990223714285714">
IG(X,C
) = ∑ P x c
( , )
⋅ log P
x ∈ {0 , 1} , c ∈ {spam, , legit} (x) ⋅ P(c)
P x c
( , )
</equation>
<bodyText confidence="0.993872142857143">
(Androutsopoulos, et al. 2000a, b, c; Sakkis, et
al. 2001). In the scenario where A = 999,
blocked messages are deleted immediately.
L → S is taken to be 999 times as costly as
S → L, since most users would consider losing
a legitimate message unacceptable. In the
scenario where A = 9, blocked messages are
returned to their senders with a request to resend
them to an unfiltered address. In this case,
L → S is penalized more than S → L , to
account for the fact that recovering from a
blocked legitimate message is more costly
(counting the sender’s extra work) than
recovering from a spam message that passed the
filter (deleting it manually). In the third scenario,
where A = 1, blocked messages are simply
flagged as possibly spam. Hence, L → S is no
more costly than S → L. Previous experiments
indicate that the Naïve Bayes ground-classifier
is unstable when A = 999 (Androutsopoulos, et
al. 2000a). Hence, we have considered only the
cases where A = 1 or 9.
Let WL (z) and WS (z) be the confidence of
a classifier (member or president) that message
x� is legitimate and spam, respectively. The
classifier classifies x� as spam iff:
never blocked, and spam messages always pass.
The weighted accuracy of the baseline is:
</bodyText>
<equation confidence="0.984538333333333">
WAcc
X NL
⋅ +
</equation>
<bodyText confidence="0.9974345">
The total cost ratio (TCR) compares the
performance of a filter to the baseline:
</bodyText>
<equation confidence="0.989396">
NS
→S + NS →L
</equation>
<bodyText confidence="0.997266">
Greater TCR values indicate better performance.
For TCR &lt; 1, not using the filter is better.
Our evaluation measures also include spam
recall (SR) and spam precision (SP):
</bodyText>
<figure confidence="0.943865416666667">
NS → S
N
+ N
S→S
S→L
NS → S
NS
→S
+ NL
→S
X
⋅ NL
b =
NS
WErr b
=
WErr
TCR
λ
⋅ NL
SR
SP
WS (z) &gt; λ
(z)
</figure>
<figureCaption confidence="0.308468">
If WL (z) and WS (z) are accurate estimates of
P(legit |x�) and P(spam  |x�), respectively, the
</figureCaption>
<bodyText confidence="0.999325285714286">
criterion above achieves optimal results (Duda
&amp; Hart, 1973).
To measure the performance of a filter,
weighted accuracy (WAcc) and its
complementary weighted error rate (WErr = 1 –
WAcc) are used (Androutsopoulos, et al. 2000a,
b, c; Sakkis, et al. 2001):
In all the experiments, stratified
cross-validation was used. That is, Ling-Spam
was partitioned into 10 equally populated parts,
maintaining the original spam-legitimate ratio.
Each experiment was repeated 10 times, each
time reserving a different part Sj (j = 1, ..., 10)
for testing, and using the remaining 9 parts as
</bodyText>
<figure confidence="0.5234252">
10-fold
Lj .
WL
WAcc λ ⋅ NL→L + NS→S
λ ⋅ NL + NS
</figure>
<bodyText confidence="0.9127835">
where NY→Z is the number of messages in
category Y that the filter classified as Z ,
</bodyText>
<equation confidence="0.810491">
NL = NL,L + NL,S , NS = NS,S + NS,L .
</equation>
<bodyText confidence="0.9954031875">
That is, when a legitimate message is blocked,
this counts as A errors; and when it passes the
filter, this counts as A successes.
We consider the case where no filter is
present as our baseline: legitimate messages are
SR measures the percentage of spam messages
that the filter blocks (intuitively, its
effectiveness), while SP measures how many
blocked messages are indeed spam (its safety).
Despite their intuitiveness, comparing different
filter configurations using SR and SP is difficult:
each configuration yields a pair of SR and SP
results; and without a single combining measure,
like TCR, that incorporates the notion of cost, it
is difficult to decide which pair is better.
the training set
</bodyText>
<sectionHeader confidence="0.996599" genericHeader="method">
3 Stacking
</sectionHeader>
<bodyText confidence="0.9993619">
In the first version of stacking that we explored
(Wolpert, 1992), which we call cross-validation
stacking, the training set of the president was
prepared using a second-level 3-fold cross-
validation. Each training set
was further
partitioned into three equally populated parts,
and the training set of the president was
prepared in three steps. At each step, a different
part
</bodyText>
<equation confidence="0.863727333333333">
(i = 1, 2, 3) of Lj
Lj
LSi
</equation>
<bodyText confidence="0.932656727272727">
was reserved, and
the members were trained on the union LLi of
the other two parts. Each x x 1,� , xm
� = of
LSi was enhanced with the members’
confidence WS1 (z) and WS2 (z) that z is spam,
yielding an enhanced LSi&apos; with vectors
1991). For the latter, we used TiMBL, an
implementation of the k-Nearest Neighbor
algorithm (Daelemans, et al. 2000).
With NB, the degree of confidence WS (x)
</bodyText>
<equation confidence="0.699230285714286">
�
that x� is spam is:
WsNB (z) = P(spam  |z) =
x&apos;= x1,...,xm, WS1 (4WS2 (x)
. At the end of
m
Pspam
( ) (
P x i
⋅∏
)
 |spam
the 3-fold cross-validation, the president was
trained on Lj&apos; = LS1&apos; U LS2&apos; U LS3&apos; . It was then
</equation>
<bodyText confidence="0.99891064516129">
tested on Sj , after retraining the members on
the entire Lj and enhancing the vectors of Sj
with the predictions of the members.
The second stacking version that we
explored, dubbed holdout stacking, is similar to
Kohavi’s (1995) holdout accuracy estimation. It
differs from the first version, in two ways: the
members are not retrained on the entire Lj ; and
each partitioning of Lj into LLi and LSi leads
to a different president, trained on LSi&apos;, which
is then tested on the enhanced Sj . Hence, there
are 3× 10 presidents in a 10-fold experiment,
while in the first version there are only 10. In
each case, WAcc is averaged over the presidents,
and TCR is reported as WErrb over the average
WErr.
Holdout stacking is likely to be less effective
than cross-validation stacking, since its
classifiers are trained on smaller sets.
Nonetheless, it requires fewer computations,
because the members are not retrained.
Furthermore, during classification the president
consults the same members that were used to
prepare its training set. In contrast, in cross-
validation stacking the president is tested using
members that have received more training than
those that prepared its training set. Hence, the
model that the president has acquired, which
shows when to trust each member, may not
apply to the members that the president consults
when classifying incoming messages.
</bodyText>
<sectionHeader confidence="0.996738" genericHeader="method">
4 Inducers employed
</sectionHeader>
<bodyText confidence="0.999872">
As already mentioned, we used a Naïve Bayes
(NB) and a memory-based learner as members
of the committee (Mitchell 1997; Aha, et al.
</bodyText>
<equation confidence="0.9982776">
1
m
∑ P(k) ⋅ ∏
k spam legit
∈ { , } i=1
</equation>
<bodyText confidence="0.999689">
NB assumes that X1,...,Xm are conditionally
independent given the category (Duda &amp; Hart,
1973).
With k-NN, a distance-weighted method is
used, with a voting function analogous to the
inverted cube of distance (Dudani 1976). The k
nearest neighbors x�i of x� are considered:
</bodyText>
<equation confidence="0.994105">
� � �
, C(xi )) d(x, xi )
Wk
S
1 d(z, zi )
i
=1
</equation>
<bodyText confidence="0.999570777777778">
where C(zi) is the category of neighbor x�i,
d (x�i , x�j) is the distance between x�i and x�j ,
and δ (c1, c2) =1, if c1 = c2, and 0 otherwise.
This formula weighs the contribution of each
neighbor by its distance from the message to be
classified, and the result is scaled to [0,1]. The
distance is computed by an attribute-weighted
function (Wettschereck, et al. 1995), employing
Information Gain (IG):
</bodyText>
<equation confidence="0.9922845">
n
d(zi,zj) ≡ ∑IGt ⋅ δ(xr,x&apos; ),
</equation>
<bodyText confidence="0.9931815">
IGt is the IG score of Xt (Section 1).
In Tables 1 and 2, we reproduce the best
performing configurations of the two learners on
Ling-Spam (Androutsopoulos, et al. 2000b;
Sakkis, et al. 2001). These configurations were
used as members of the committee.
The same memory-based learner was used as
the president. However, we experimented with
several configurations, varying the
neighborhood size (k) from 1 to 10, and
</bodyText>
<figure confidence="0.915574681818182">
t
1
where zi = )4,..., xm&apos;
zj = x1j,..., xmj
,
, and
i
=
P
(xi  |k)
−
NN
(z)
k ,
k
∑
δ(spam
i
=1
3
∑
3
</figure>
<bodyText confidence="0.999519833333333">
providing the president with the m best word-
attributes, as in Section 1, with m ranging from
50 to 700 by 50. The same attribute- and
distance-weighting schemes were used for the
president, as with the ground-level memory-
based learner.
</bodyText>
<table confidence="0.998166333333333">
λ m SR SP TCR
1 100 82.4% 99.0% 5.41
9 100 77.6% 99.5% 3.82
</table>
<tableCaption confidence="0.99824">
Table 1: Best configurations of NB per usage
scenario and the corresponding performance.
</tableCaption>
<table confidence="0.998710666666667">
Λ k m SR SP TCR
1 8 600 88.6% 97.4% 7.18
9 2 700 81.9% 98.8% 3.64
</table>
<tableCaption confidence="0.9936">
Table 2: Best configurations of k-NN per usage
scenario and the corresponding performance.
</tableCaption>
<table confidence="0.99917625">
λ true only one both fail
class fails
Legitimate 0.66% 0.08%
1 Spam 12.27% 8.52%
All 2.59% 1.49%
Legitimate 0.33% 0.08%
9 Spam 19.12% 10.19%
All 3.46% 1.76%
</table>
<tableCaption confidence="0.704344666666667">
Table 3: Analysis of the common errors of the
best configurations of NB and k-NN per
scenario (λ) and message class.
</tableCaption>
<bodyText confidence="0.999353416666667">
Our motivation for combining NB with k-NN
emerged from preliminary results indicating that
the two ground-level learners make rather
uncorrelated errors. Table 3 shows the average
percentages of messages where only one, or both
ground-level classifiers fail, per cost scenario (λ)
and message category. The figures are for the
configurations of Tables 1 and 2. It can be seen
that the common errors are always fewer than
the cases where both classifiers fail. Hence,
there is much space for improved accuracy, if a
president can learn to select the correct member.
</bodyText>
<sectionHeader confidence="0.980324" genericHeader="evaluation">
5 Experimental results
</sectionHeader>
<bodyText confidence="0.999871375">
Tables 4 and 5 summarize the performance of
the best configurations of the president in our
experiments, for each cost scenario. Comparing
the TCR scores in these tables with the
corresponding scores of Tables 1 and 2 shows
that stacking improves the performance of the
overall filter. From the two stacking versions,
cross-validation stacking is slightly better than
holdout stacking. It should also be noted that
stacking was beneficial for most of the
configurations of the president that we tested,
i.e. most sub-optimal presidents outperformed
the best configurations of the members. This is
encouraging, since the optimum configuration is
often hard to determine a priori, and may vary
from one user to the other.
</bodyText>
<table confidence="0.980709666666667">
λ k m SR SP TCR
1 5 100 91.7% 96.5% 8.44
9 3 200 84.2% 98.9% 3.98
</table>
<tableCaption confidence="0.991392">
Table 4: Best configurations of holdout
stacking per usage scenario and the
corresponding performance.
</tableCaption>
<table confidence="0.996484">
λ k m SR SP TCR
1 7 300 89.6% 98.7% 8.60
9 3 100 84.8% 98.8% 4.08
</table>
<tableCaption confidence="0.921923666666667">
Table 5: Best configurations of cross-validation
stacking per usage scenario and the
corresponding performance.
</tableCaption>
<bodyText confidence="0.999349464285714">
There was one interesting exception in the
positive impact of stacking. The 1-NN and 2-NN
(k = 1, 2) presidents were substantially worse
than the other k-NN presidents, often performing
worse than the ground-level classifiers. We
witnessed this behavior in both cost scenarios,
and with most values of m (number of
attributes). In a “postmortem” analysis, we
ascertained that most messages misclassified by
1-NN and 2-NN, but not the other presidents, are
legitimate, with their nearest neighbor being
spam. Therefore, the additional errors of 1-NN
and 2-NN, compared to the other presidents, are
of the L → S type. Interestingly, in most of
those cases, both members of the committee
classify the instance correctly, as legitimate.
This is an indication, that for small values of the
parameter k the additional two features, i.e., the
members’ confidence WS1 (z) and WS2 (z) , do
not enhance but distort the representation of
instances. As a result, the close neighborhood of
the unclassified instance is not a legitimate, but a
spam e-mail. This behavior of the memory-
based classifier is also noted in (Sakkis, et al.
2001). The suggested solution there was to use a
larger value for k, combined with a strong
distance weighting function, such as the one
presented in section 4.
</bodyText>
<sectionHeader confidence="0.972491" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.999803641025641">
In this paper we adopted a stacked
generalization approach to anti-spam filtering,
and evaluated its performance. The
configuration that we examined combined a
memory-based and a Naïve Bayes classifier in a
two-member committee, in which another
memory-based classifier presided. The
classifiers that we chose as members of the
committee have been evaluated individually on
the same data as in our evaluation, i.e. the Ling-
Spam corpus. The results of these earlier studies
were used as a basis for comparing the
performance of our method.
Our experiments, using two different
approaches to stacking and two different
misclassification cost scenarios, show that
stacking consistently improves the performance
of anti-spam filtering. This is explained by the
fact that the two members of the committee
disagree more often than agreeing in their
misclassification errors. Thus, the president is
able to improve the overall performance of the
filter, by choosing the right member’s decision
when they disagree.
The results presented here motivate further
work in the same direction. In particular, we are
interested in combining more classifiers, such as
decision trees (Quinlan, 1993) and support
vector machines (Drucker, et al. 1999), within
the stacking framework. A larger variety of
classifiers is expected to lead the president to
more informed decisions, resulting in further
improvement of the filter’s performance.
Furthermore, we would like to evaluate other
classifiers in the role of the president. Finally, it
would be interesting to compare the
performance of the stacked generalization
approach to other multi-classifier methods, such
as boosting (Schapire &amp; Singer, 2000).
</bodyText>
<sectionHeader confidence="0.998955" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999919263736263">
Aha, W. D., Kibler D., and Albert, M.K., (1991)
Instance-Based Learning Algorithms. “Machine
Learning”, Vol. 6, pp. 37–66.
Androutsopoulos, I., Koutsias, J., Chandrinos, K.V.,
Paliouras, G., and Spyropoulos, C.D. (2000a) “An
evaluation of naïve Bayesian anti-spam filtering”.
In Proceedings of the Workshop on Machine
Learning in the New Information Age, 11th
European Conference on Machine Learning
(ECML 2000), Barcelona, Spain, pp. 9–17.
Androutsopoulos, I., Paliouras, G., Karkaletsis, V.,
Sakkis, G., Spyropoulos, C.D., and Stamatopoulos,
P. (2000b). “Learning to filter spam e-mail: a
comparison of a naïve Bayesian and a memory-
based approach”. In Proceedings of the Workshop
on Machine Learning and Textual Information
Access, PKDD 2000, Lyon, France, pp. 1– 3.
Androutsopoulos, I, Koutsias, J, Chandrinos, K.V.,
and Spyropoulos, C.D. (2000c) “An experimental
comparison of naïve Bayesian and keyword-based
anti-spam filtering with encrypted personal e-mail
messages”. In Proceedings of SIGIR 2000, Athens,
Greece, pp. 160–167.
Cranor, L.F., and LaMacchia, B.A. (1998). “Spam!”,
Communications of ACM, 41(8):74–83.
Daelemans, W., Zavrel, J., van der Sloot, K., and van
den Bosch, A. (2000) TiMBL: Tilburg Memory
Based Learner, version 3.0, Reference Guide. ILK,
Computational Linguistics, Tilburg University.
http:/ilk.kub.nl/~ilk/papers.
Dietterich, G. T. (1997). “Machine Learning
Research: Four Current Directions”. AI Magazine
18(4):97-136.
Drucker, H. D. ,Wu, D., and Vapnik V. (1999).
“Support Vector Machines for Spam
Categorization”. IEEE Transactions On Neural
Networks, 10(5).
Duda, R.O, and Hart, P.E. (1973). “Bayes decision
theory”. Chapter 2 in Pattern Classification and
Scene Analysis, pp. 10–43, John Wiley.
Dudani, A. S. (1976). “The distance-weighted k-
nearest neighbor rule”. IEEE Transactions on
Systems, Man and Cybernetics, 6(4):325–327.
Gómez Hidalgo, J.M., Mafia Lσpéz, M., and Puertas
Sanz, E. (2000). “Combining text and heuristics for
cost-sensitive spam filtering”. In Proceedings of
the 4th Computational Natural Language Learning
Workshop, CoNLL-2000, Lisbon, Portugal, pp. 99–
102.
Kohavi, R. (1995). “A study of cross-validation and
bootstrap for accuracy estimation and model
selection”. In Proceedings of the 12th International
Joint Conference on Artificial Intelligence (IJCAI-
1995), Morgan Kaufmann, pp. 1137–1143.
Mitchell, T.M. (1997). Machine Learning. McGraw-
Hill.
Pantel, P., and Lin, D. (1998). “SpamCop: a spam
classification and organization program”. In
Learning for Text Categorization – Papers from
the AAAI Workshop, pp. 95–98, Madison
Wisconsin. AAAI Technical Report WS-98-05.
Quinlan, J.R. (1993). C4.5: Programs for Machine
Learning, Morgan Kaufmann, San Mateo,
California.
Sahami, M., Dumais, S., Heckerman D., and Horvitz,
E. (1998). “A Bayesian approach to filtering junk
e-mail”. In Learning for Text Categorization –
Papers from the AAAI Workshop, pp. 55–62,
Madison Wisconsin. AAAI Technical Report WS-
98-05.
Sakkis, G., Androutsopoulos, I., Paliouras, G.,
Karkaletsis, V., Spyropoulos, C.D., and
Stamatopoulos, P. (2001) “A memory-based
approach to anti-spam filtering”. NCSR
“Demokritos” Technical Report, Athens, Greece.
Schapire, R.E., and Singer, Y. (2000). “BoosTexter: a
boosting-based system for text categorization”.
Machine Learning, 39(2/3):135–168.
Sebastiani, F. (2001). Machine Learning in
Automated Text Categorization. Revised version of
Technical Report IEI-B4-31-1999, Istituto di
Elaborazione dell’Informazione, Consiglio
Nazionale delle Ricerche, Pisa, Italy.
Wettschereck, D., Aha, W. D., and Mohri, T. (1995).
A Review and Comparative Evaluation of Feature
Weighting Methods for Lazy Learning Algorithms.
Technical Report AIC-95-012, Naval Research
Laboratory, Navy Center for Applied Research in
Artificial Intelligence, Washington, D.C.
Wolpert, D. (1992). “Stacked Generalization”.
Neural Networks, 5(2):241–260.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.233936">
<note confidence="0.9987545">of the 6th Conference on Empirical Methods in Natural Language Processing 2001), L. Lee and D. Harman (Eds.), pp. 44–50, Carnegie Mellon University, Pittsburgh, PA, USA, 2001.</note>
<title confidence="0.708048666666667">Stacking classifiers for anti-spam filtering of e-mail Ion Georgios Vangelis D. and Panagiotis</title>
<affiliation confidence="0.837561">Department of Informatics University of Athens TYPA Buildings, Panepistimiopolis GR-157 71 Athens, Greece e-mail: {stud0926, T.Stamatopoulos}@di.uoa.gr and Knowledge Institute of Informatics and National Centre for Scientific</affiliation>
<address confidence="0.998787">GR-153 10 Ag. Paraskevi, Athens,</address>
<email confidence="0.9674535">e-mail:{ionandr,paliourg,costass}@iit.demokritos.gr</email>
<abstract confidence="0.997105230769231">We evaluate empirically a scheme for combining classifiers, known as stacked generalization, in the context of anti-spam filtering, a novel cost-sensitive application of text categorization. Unsolicited commercial email, or “spam”, floods mailboxes, causing frustration, wasting bandwidth, and exposing minors to unsuitable content. Using a public corpus, we show that stacking can improve the efficiency of automatically induced anti-spam filters, and that such filters can be used in reallife applications.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>W D Aha</author>
<author>D Kibler</author>
<author>M K Albert</author>
</authors>
<title>Instance-Based Learning Algorithms.</title>
<date>1991</date>
<journal>Machine Learning”,</journal>
<volume>6</volume>
<pages>37--66</pages>
<marker>Aha, Kibler, Albert, 1991</marker>
<rawString>Aha, W. D., Kibler D., and Albert, M.K., (1991) Instance-Based Learning Algorithms. “Machine Learning”, Vol. 6, pp. 37–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Androutsopoulos</author>
<author>J Koutsias</author>
<author>K V Chandrinos</author>
<author>G Paliouras</author>
<author>C D Spyropoulos</author>
</authors>
<title>(2000a) “An evaluation of naïve Bayesian anti-spam filtering”.</title>
<date></date>
<booktitle>In Proceedings of the Workshop on Machine Learning in the New Information Age, 11th European Conference on Machine Learning (ECML 2000),</booktitle>
<pages>9--17</pages>
<location>Barcelona,</location>
<marker>Androutsopoulos, Koutsias, Chandrinos, Paliouras, Spyropoulos, </marker>
<rawString>Androutsopoulos, I., Koutsias, J., Chandrinos, K.V., Paliouras, G., and Spyropoulos, C.D. (2000a) “An evaluation of naïve Bayesian anti-spam filtering”. In Proceedings of the Workshop on Machine Learning in the New Information Age, 11th European Conference on Machine Learning (ECML 2000), Barcelona, Spain, pp. 9–17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Androutsopoulos</author>
<author>G Paliouras</author>
<author>V Karkaletsis</author>
<author>G Sakkis</author>
<author>C D Spyropoulos</author>
<author>P Stamatopoulos</author>
</authors>
<title>Learning to filter spam e-mail: a comparison of a naïve Bayesian and a memorybased approach”.</title>
<date>2000</date>
<booktitle>In Proceedings of the Workshop on Machine Learning and Textual Information Access, PKDD 2000,</booktitle>
<pages>1--3</pages>
<location>Lyon, France,</location>
<contexts>
<context position="2794" citStr="Androutsopoulos, et al. 2000" startWordPosition="365" endWordPosition="368">echniques in text categorization (Sebastiani, 2001) has recently led to alternative, learning-based approaches (Sahami, et al. 1998; Pantel &amp; Lin, 1998; Drucker, et al. 1999). A classifier capable of distinguishing between spam and non-spam, hereafter legitimate, messages is induced from a manually categorized learning collection of messages, and is then used to identify incoming spam e-mail. Initial results have been promising, and experiments are becoming more systematic, by exploiting recently introduced benchmark corpora, and cost-sensitive evaluation measures (Gomez Hidalgo, et al. 2000; Androutsopoulos, et al. 2000a, b, c). Stacked generalization (Wolpert, 1992), or stacking, is an approach for constructing classifier ensembles. A classifier ensemble, or committee, is a set of classifiers whose individual decisions are combined in some way to classify new instances (Dietterich, 1997). Stacking combines multiple classifiers to induce a higher-level classifier with improved performance. The latter can be thought of as the president of a committee with the ground-level classifiers as members. Each unseen incoming message is first given to the members; the president then decides on the category of the 1 Con</context>
<context position="5216" citStr="Androutsopoulos, et al. 2000" startWordPosition="706" endWordPosition="709">oyed and the motivation for selecting them; section 5 presents our experimental results followed by conclusions. 1 Benchmark corpus and preprocessing Text categorization has benefited from public benchmark corpora. Producing such corpora for anti-spam filtering is not straightforward, since user mailboxes cannot be made public without considering privacy issues. A useful public approximation of a user’s mailbox, however, can be constructed by mixing spam messages with messages extracted from spam-free public archives of mailing lists. The corpus that we used, Ling-Spam, follows this approach (Androutsopoulos, et al. 2000a, b; Sakkis, et al. 2001). It is a mixture of spam messages and messages sent via the Linguist, a moderated list about the science and profession of linguistics. The corpus consists of 2412 Linguist messages and 481 spam messages. Spam messages constitute 16.6% of LingSpam, close to the rates reported by Cranor and LaMacchia (1998), and Sahami et al. (1998). Although the Linguist messages are more topicspecific than most users’ e-mail, they are less standardized than one might expect. For example, they contain job postings, software availability announcements and even flame-like responses. Mo</context>
<context position="7087" citStr="Androutsopoulos, et al. 2000" startWordPosition="1003" endWordPosition="1006"> in the message. All attributes are binary: Xi = 1 if the word is present; otherwise Xi = 0. To avoid treating forms of the same word as different attributes, a lemmatizer was applied, converting each word to its base form. To reduce the dimensionality, attribute selection was performed. First, words occurring in less than 4 messages were discarded. Then, the Information Gain (IG) of each candidate attribute X was computed: The attributes with the m highest IG-scores were selected, with m corresponding to the best configurations of the ground classifiers that have been reported for Ling-Spam (Androutsopoulos, et al. 2000a; Sakkis, et al. 2001); see Section 4. 2 Evaluation measures Blocking a legitimate message is generally more severe an error than accepting a spam message. Let L → S and S → L denote the two error types, respectively, and let us assume that L → S is λ times as costly as S → L . Previous research has considered three cost scenarios, where λ = 1, 9, or 999 IG(X,C ) = ∑ P x c ( , ) ⋅ log P x ∈ {0 , 1} , c ∈ {spam, , legit} (x) ⋅ P(c) P x c ( , ) (Androutsopoulos, et al. 2000a, b, c; Sakkis, et al. 2001). In the scenario where A = 999, blocked messages are deleted immediately. L → S is taken to b</context>
<context position="8439" citStr="Androutsopoulos, et al. 2000" startWordPosition="1271" endWordPosition="1274">ere A = 9, blocked messages are returned to their senders with a request to resend them to an unfiltered address. In this case, L → S is penalized more than S → L , to account for the fact that recovering from a blocked legitimate message is more costly (counting the sender’s extra work) than recovering from a spam message that passed the filter (deleting it manually). In the third scenario, where A = 1, blocked messages are simply flagged as possibly spam. Hence, L → S is no more costly than S → L. Previous experiments indicate that the Naïve Bayes ground-classifier is unstable when A = 999 (Androutsopoulos, et al. 2000a). Hence, we have considered only the cases where A = 1 or 9. Let WL (z) and WS (z) be the confidence of a classifier (member or president) that message x� is legitimate and spam, respectively. The classifier classifies x� as spam iff: never blocked, and spam messages always pass. The weighted accuracy of the baseline is: WAcc X NL ⋅ + The total cost ratio (TCR) compares the performance of a filter to the baseline: NS →S + NS →L Greater TCR values indicate better performance. For TCR &lt; 1, not using the filter is better. Our evaluation measures also include spam recall (SR) and spam precision </context>
<context position="14210" citStr="Androutsopoulos, et al. 2000" startWordPosition="2313" endWordPosition="2316"> Wk S 1 d(z, zi ) i =1 where C(zi) is the category of neighbor x�i, d (x�i , x�j) is the distance between x�i and x�j , and δ (c1, c2) =1, if c1 = c2, and 0 otherwise. This formula weighs the contribution of each neighbor by its distance from the message to be classified, and the result is scaled to [0,1]. The distance is computed by an attribute-weighted function (Wettschereck, et al. 1995), employing Information Gain (IG): n d(zi,zj) ≡ ∑IGt ⋅ δ(xr,x&apos; ), IGt is the IG score of Xt (Section 1). In Tables 1 and 2, we reproduce the best performing configurations of the two learners on Ling-Spam (Androutsopoulos, et al. 2000b; Sakkis, et al. 2001). These configurations were used as members of the committee. The same memory-based learner was used as the president. However, we experimented with several configurations, varying the neighborhood size (k) from 1 to 10, and t 1 where zi = )4,..., xm&apos; zj = x1j,..., xmj , , and i = P (xi |k) − NN (z) k , k ∑ δ(spam i =1 3 ∑ 3 providing the president with the m best wordattributes, as in Section 1, with m ranging from 50 to 700 by 50. The same attribute- and distance-weighting schemes were used for the president, as with the ground-level memorybased learner. λ m SR SP TCR </context>
</contexts>
<marker>Androutsopoulos, Paliouras, Karkaletsis, Sakkis, Spyropoulos, Stamatopoulos, 2000</marker>
<rawString>Androutsopoulos, I., Paliouras, G., Karkaletsis, V., Sakkis, G., Spyropoulos, C.D., and Stamatopoulos, P. (2000b). “Learning to filter spam e-mail: a comparison of a naïve Bayesian and a memorybased approach”. In Proceedings of the Workshop on Machine Learning and Textual Information Access, PKDD 2000, Lyon, France, pp. 1– 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Androutsopoulos</author>
<author>J Koutsias</author>
<author>K V Chandrinos</author>
<author>C D Spyropoulos</author>
</authors>
<title>An experimental comparison of naïve Bayesian and keyword-based anti-spam filtering with encrypted personal e-mail messages”.</title>
<date>2000</date>
<booktitle>In Proceedings of SIGIR 2000,</booktitle>
<pages>160--167</pages>
<location>Athens, Greece,</location>
<contexts>
<context position="2794" citStr="Androutsopoulos, et al. 2000" startWordPosition="365" endWordPosition="368">echniques in text categorization (Sebastiani, 2001) has recently led to alternative, learning-based approaches (Sahami, et al. 1998; Pantel &amp; Lin, 1998; Drucker, et al. 1999). A classifier capable of distinguishing between spam and non-spam, hereafter legitimate, messages is induced from a manually categorized learning collection of messages, and is then used to identify incoming spam e-mail. Initial results have been promising, and experiments are becoming more systematic, by exploiting recently introduced benchmark corpora, and cost-sensitive evaluation measures (Gomez Hidalgo, et al. 2000; Androutsopoulos, et al. 2000a, b, c). Stacked generalization (Wolpert, 1992), or stacking, is an approach for constructing classifier ensembles. A classifier ensemble, or committee, is a set of classifiers whose individual decisions are combined in some way to classify new instances (Dietterich, 1997). Stacking combines multiple classifiers to induce a higher-level classifier with improved performance. The latter can be thought of as the president of a committee with the ground-level classifiers as members. Each unseen incoming message is first given to the members; the president then decides on the category of the 1 Con</context>
<context position="5216" citStr="Androutsopoulos, et al. 2000" startWordPosition="706" endWordPosition="709">oyed and the motivation for selecting them; section 5 presents our experimental results followed by conclusions. 1 Benchmark corpus and preprocessing Text categorization has benefited from public benchmark corpora. Producing such corpora for anti-spam filtering is not straightforward, since user mailboxes cannot be made public without considering privacy issues. A useful public approximation of a user’s mailbox, however, can be constructed by mixing spam messages with messages extracted from spam-free public archives of mailing lists. The corpus that we used, Ling-Spam, follows this approach (Androutsopoulos, et al. 2000a, b; Sakkis, et al. 2001). It is a mixture of spam messages and messages sent via the Linguist, a moderated list about the science and profession of linguistics. The corpus consists of 2412 Linguist messages and 481 spam messages. Spam messages constitute 16.6% of LingSpam, close to the rates reported by Cranor and LaMacchia (1998), and Sahami et al. (1998). Although the Linguist messages are more topicspecific than most users’ e-mail, they are less standardized than one might expect. For example, they contain job postings, software availability announcements and even flame-like responses. Mo</context>
<context position="7087" citStr="Androutsopoulos, et al. 2000" startWordPosition="1003" endWordPosition="1006"> in the message. All attributes are binary: Xi = 1 if the word is present; otherwise Xi = 0. To avoid treating forms of the same word as different attributes, a lemmatizer was applied, converting each word to its base form. To reduce the dimensionality, attribute selection was performed. First, words occurring in less than 4 messages were discarded. Then, the Information Gain (IG) of each candidate attribute X was computed: The attributes with the m highest IG-scores were selected, with m corresponding to the best configurations of the ground classifiers that have been reported for Ling-Spam (Androutsopoulos, et al. 2000a; Sakkis, et al. 2001); see Section 4. 2 Evaluation measures Blocking a legitimate message is generally more severe an error than accepting a spam message. Let L → S and S → L denote the two error types, respectively, and let us assume that L → S is λ times as costly as S → L . Previous research has considered three cost scenarios, where λ = 1, 9, or 999 IG(X,C ) = ∑ P x c ( , ) ⋅ log P x ∈ {0 , 1} , c ∈ {spam, , legit} (x) ⋅ P(c) P x c ( , ) (Androutsopoulos, et al. 2000a, b, c; Sakkis, et al. 2001). In the scenario where A = 999, blocked messages are deleted immediately. L → S is taken to b</context>
<context position="8439" citStr="Androutsopoulos, et al. 2000" startWordPosition="1271" endWordPosition="1274">ere A = 9, blocked messages are returned to their senders with a request to resend them to an unfiltered address. In this case, L → S is penalized more than S → L , to account for the fact that recovering from a blocked legitimate message is more costly (counting the sender’s extra work) than recovering from a spam message that passed the filter (deleting it manually). In the third scenario, where A = 1, blocked messages are simply flagged as possibly spam. Hence, L → S is no more costly than S → L. Previous experiments indicate that the Naïve Bayes ground-classifier is unstable when A = 999 (Androutsopoulos, et al. 2000a). Hence, we have considered only the cases where A = 1 or 9. Let WL (z) and WS (z) be the confidence of a classifier (member or president) that message x� is legitimate and spam, respectively. The classifier classifies x� as spam iff: never blocked, and spam messages always pass. The weighted accuracy of the baseline is: WAcc X NL ⋅ + The total cost ratio (TCR) compares the performance of a filter to the baseline: NS →S + NS →L Greater TCR values indicate better performance. For TCR &lt; 1, not using the filter is better. Our evaluation measures also include spam recall (SR) and spam precision </context>
<context position="14210" citStr="Androutsopoulos, et al. 2000" startWordPosition="2313" endWordPosition="2316"> Wk S 1 d(z, zi ) i =1 where C(zi) is the category of neighbor x�i, d (x�i , x�j) is the distance between x�i and x�j , and δ (c1, c2) =1, if c1 = c2, and 0 otherwise. This formula weighs the contribution of each neighbor by its distance from the message to be classified, and the result is scaled to [0,1]. The distance is computed by an attribute-weighted function (Wettschereck, et al. 1995), employing Information Gain (IG): n d(zi,zj) ≡ ∑IGt ⋅ δ(xr,x&apos; ), IGt is the IG score of Xt (Section 1). In Tables 1 and 2, we reproduce the best performing configurations of the two learners on Ling-Spam (Androutsopoulos, et al. 2000b; Sakkis, et al. 2001). These configurations were used as members of the committee. The same memory-based learner was used as the president. However, we experimented with several configurations, varying the neighborhood size (k) from 1 to 10, and t 1 where zi = )4,..., xm&apos; zj = x1j,..., xmj , , and i = P (xi |k) − NN (z) k , k ∑ δ(spam i =1 3 ∑ 3 providing the president with the m best wordattributes, as in Section 1, with m ranging from 50 to 700 by 50. The same attribute- and distance-weighting schemes were used for the president, as with the ground-level memorybased learner. λ m SR SP TCR </context>
</contexts>
<marker>Androutsopoulos, Koutsias, Chandrinos, Spyropoulos, 2000</marker>
<rawString>Androutsopoulos, I, Koutsias, J, Chandrinos, K.V., and Spyropoulos, C.D. (2000c) “An experimental comparison of naïve Bayesian and keyword-based anti-spam filtering with encrypted personal e-mail messages”. In Proceedings of SIGIR 2000, Athens, Greece, pp. 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L F Cranor</author>
<author>B A LaMacchia</author>
</authors>
<date>1998</date>
<journal>Spam!”, Communications of ACM,</journal>
<volume>41</volume>
<issue>8</issue>
<contexts>
<context position="5550" citStr="Cranor and LaMacchia (1998)" startWordPosition="762" endWordPosition="765">t considering privacy issues. A useful public approximation of a user’s mailbox, however, can be constructed by mixing spam messages with messages extracted from spam-free public archives of mailing lists. The corpus that we used, Ling-Spam, follows this approach (Androutsopoulos, et al. 2000a, b; Sakkis, et al. 2001). It is a mixture of spam messages and messages sent via the Linguist, a moderated list about the science and profession of linguistics. The corpus consists of 2412 Linguist messages and 481 spam messages. Spam messages constitute 16.6% of LingSpam, close to the rates reported by Cranor and LaMacchia (1998), and Sahami et al. (1998). Although the Linguist messages are more topicspecific than most users’ e-mail, they are less standardized than one might expect. For example, they contain job postings, software availability announcements and even flame-like responses. Moreover, recent experiments with an encoded user mailbox and a Naïve Bayes (NB) classifier (Androutsopoulos, et al. 2000c) yielded results similar to those obtained with Ling-Spam (Androutsopoulos, et al. 2000a). Therefore, experimentation with Ling-Spam can provide useful indicative results, at least in a preliminary stage. Furtherm</context>
</contexts>
<marker>Cranor, LaMacchia, 1998</marker>
<rawString>Cranor, L.F., and LaMacchia, B.A. (1998). “Spam!”, Communications of ACM, 41(8):74–83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Daelemans</author>
<author>J Zavrel</author>
<author>K van der Sloot</author>
<author>A van den Bosch</author>
</authors>
<title>TiMBL: Tilburg Memory Based Learner, version 3.0, Reference Guide. ILK, Computational Linguistics,</title>
<date>2000</date>
<location>Tilburg University. http:/ilk.kub.nl/~ilk/papers.</location>
<marker>Daelemans, Zavrel, van der Sloot, van den Bosch, 2000</marker>
<rawString>Daelemans, W., Zavrel, J., van der Sloot, K., and van den Bosch, A. (2000) TiMBL: Tilburg Memory Based Learner, version 3.0, Reference Guide. ILK, Computational Linguistics, Tilburg University. http:/ilk.kub.nl/~ilk/papers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G T Dietterich</author>
</authors>
<title>Machine Learning Research: Four Current Directions”.</title>
<date>1997</date>
<journal>AI Magazine</journal>
<pages>18--4</pages>
<contexts>
<context position="3068" citStr="Dietterich, 1997" startWordPosition="406" endWordPosition="407">rom a manually categorized learning collection of messages, and is then used to identify incoming spam e-mail. Initial results have been promising, and experiments are becoming more systematic, by exploiting recently introduced benchmark corpora, and cost-sensitive evaluation measures (Gomez Hidalgo, et al. 2000; Androutsopoulos, et al. 2000a, b, c). Stacked generalization (Wolpert, 1992), or stacking, is an approach for constructing classifier ensembles. A classifier ensemble, or committee, is a set of classifiers whose individual decisions are combined in some way to classify new instances (Dietterich, 1997). Stacking combines multiple classifiers to induce a higher-level classifier with improved performance. The latter can be thought of as the president of a committee with the ground-level classifiers as members. Each unseen incoming message is first given to the members; the president then decides on the category of the 1 Consult www.cauce.org, spam.abuse.net, and www.junkemail.org. message by considering the opinions of the members and the message itself. Ground-level classifiers often make different classification errors. Hence, a president that has successfully learned when to trust each of </context>
</contexts>
<marker>Dietterich, 1997</marker>
<rawString>Dietterich, G. T. (1997). “Machine Learning Research: Four Current Directions”. AI Magazine 18(4):97-136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wu</author>
<author>V Vapnik</author>
</authors>
<title>Support Vector Machines for Spam Categorization”.</title>
<date>1999</date>
<journal>IEEE Transactions On Neural Networks,</journal>
<volume>10</volume>
<issue>5</issue>
<marker>Wu, Vapnik, 1999</marker>
<rawString>Drucker, H. D. ,Wu, D., and Vapnik V. (1999). “Support Vector Machines for Spam Categorization”. IEEE Transactions On Neural Networks, 10(5).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R O Duda</author>
<author>P E Hart</author>
</authors>
<title>Bayes decision theory”.</title>
<date>1973</date>
<journal>Chapter</journal>
<booktitle>in Pattern Classification and Scene Analysis,</booktitle>
<volume>2</volume>
<pages>10--43</pages>
<publisher>John Wiley.</publisher>
<contexts>
<context position="9302" citStr="Duda &amp; Hart, 1973" startWordPosition="1443" endWordPosition="1446">ocked, and spam messages always pass. The weighted accuracy of the baseline is: WAcc X NL ⋅ + The total cost ratio (TCR) compares the performance of a filter to the baseline: NS →S + NS →L Greater TCR values indicate better performance. For TCR &lt; 1, not using the filter is better. Our evaluation measures also include spam recall (SR) and spam precision (SP): NS → S N + N S→S S→L NS → S NS →S + NL →S X ⋅ NL b = NS WErr b = WErr TCR λ ⋅ NL SR SP WS (z) &gt; λ (z) If WL (z) and WS (z) are accurate estimates of P(legit |x�) and P(spam |x�), respectively, the criterion above achieves optimal results (Duda &amp; Hart, 1973). To measure the performance of a filter, weighted accuracy (WAcc) and its complementary weighted error rate (WErr = 1 – WAcc) are used (Androutsopoulos, et al. 2000a, b, c; Sakkis, et al. 2001): In all the experiments, stratified cross-validation was used. That is, Ling-Spam was partitioned into 10 equally populated parts, maintaining the original spam-legitimate ratio. Each experiment was repeated 10 times, each time reserving a different part Sj (j = 1, ..., 10) for testing, and using the remaining 9 parts as 10-fold Lj . WL WAcc λ ⋅ NL→L + NS→S λ ⋅ NL + NS where NY→Z is the number of messa</context>
<context position="13377" citStr="Duda &amp; Hart, 1973" startWordPosition="2158" endWordPosition="2161">ntrast, in crossvalidation stacking the president is tested using members that have received more training than those that prepared its training set. Hence, the model that the president has acquired, which shows when to trust each member, may not apply to the members that the president consults when classifying incoming messages. 4 Inducers employed As already mentioned, we used a Naïve Bayes (NB) and a memory-based learner as members of the committee (Mitchell 1997; Aha, et al. 1 m ∑ P(k) ⋅ ∏ k spam legit ∈ { , } i=1 NB assumes that X1,...,Xm are conditionally independent given the category (Duda &amp; Hart, 1973). With k-NN, a distance-weighted method is used, with a voting function analogous to the inverted cube of distance (Dudani 1976). The k nearest neighbors x�i of x� are considered: � � � , C(xi )) d(x, xi ) Wk S 1 d(z, zi ) i =1 where C(zi) is the category of neighbor x�i, d (x�i , x�j) is the distance between x�i and x�j , and δ (c1, c2) =1, if c1 = c2, and 0 otherwise. This formula weighs the contribution of each neighbor by its distance from the message to be classified, and the result is scaled to [0,1]. The distance is computed by an attribute-weighted function (Wettschereck, et al. 1995),</context>
</contexts>
<marker>Duda, Hart, 1973</marker>
<rawString>Duda, R.O, and Hart, P.E. (1973). “Bayes decision theory”. Chapter 2 in Pattern Classification and Scene Analysis, pp. 10–43, John Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A S Dudani</author>
</authors>
<title>The distance-weighted knearest neighbor rule”.</title>
<date>1976</date>
<journal>IEEE Transactions on Systems, Man and Cybernetics,</journal>
<volume>6</volume>
<issue>4</issue>
<contexts>
<context position="13505" citStr="Dudani 1976" startWordPosition="2180" endWordPosition="2181">s training set. Hence, the model that the president has acquired, which shows when to trust each member, may not apply to the members that the president consults when classifying incoming messages. 4 Inducers employed As already mentioned, we used a Naïve Bayes (NB) and a memory-based learner as members of the committee (Mitchell 1997; Aha, et al. 1 m ∑ P(k) ⋅ ∏ k spam legit ∈ { , } i=1 NB assumes that X1,...,Xm are conditionally independent given the category (Duda &amp; Hart, 1973). With k-NN, a distance-weighted method is used, with a voting function analogous to the inverted cube of distance (Dudani 1976). The k nearest neighbors x�i of x� are considered: � � � , C(xi )) d(x, xi ) Wk S 1 d(z, zi ) i =1 where C(zi) is the category of neighbor x�i, d (x�i , x�j) is the distance between x�i and x�j , and δ (c1, c2) =1, if c1 = c2, and 0 otherwise. This formula weighs the contribution of each neighbor by its distance from the message to be classified, and the result is scaled to [0,1]. The distance is computed by an attribute-weighted function (Wettschereck, et al. 1995), employing Information Gain (IG): n d(zi,zj) ≡ ∑IGt ⋅ δ(xr,x&apos; ), IGt is the IG score of Xt (Section 1). In Tables 1 and 2, we re</context>
</contexts>
<marker>Dudani, 1976</marker>
<rawString>Dudani, A. S. (1976). “The distance-weighted knearest neighbor rule”. IEEE Transactions on Systems, Man and Cybernetics, 6(4):325–327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gómez Hidalgo</author>
<author>Mafia Lσpéz J M</author>
<author>M</author>
<author>Puertas Sanz</author>
<author>E</author>
</authors>
<title>Combining text and heuristics for cost-sensitive spam filtering”.</title>
<date>2000</date>
<booktitle>In Proceedings of the 4th Computational Natural Language Learning Workshop, CoNLL-2000,</booktitle>
<pages>99--102</pages>
<location>Lisbon,</location>
<contexts>
<context position="2764" citStr="Hidalgo, et al. 2000" startWordPosition="361" endWordPosition="364"> of machine learning techniques in text categorization (Sebastiani, 2001) has recently led to alternative, learning-based approaches (Sahami, et al. 1998; Pantel &amp; Lin, 1998; Drucker, et al. 1999). A classifier capable of distinguishing between spam and non-spam, hereafter legitimate, messages is induced from a manually categorized learning collection of messages, and is then used to identify incoming spam e-mail. Initial results have been promising, and experiments are becoming more systematic, by exploiting recently introduced benchmark corpora, and cost-sensitive evaluation measures (Gomez Hidalgo, et al. 2000; Androutsopoulos, et al. 2000a, b, c). Stacked generalization (Wolpert, 1992), or stacking, is an approach for constructing classifier ensembles. A classifier ensemble, or committee, is a set of classifiers whose individual decisions are combined in some way to classify new instances (Dietterich, 1997). Stacking combines multiple classifiers to induce a higher-level classifier with improved performance. The latter can be thought of as the president of a committee with the ground-level classifiers as members. Each unseen incoming message is first given to the members; the president then decide</context>
</contexts>
<marker>Hidalgo, M, M, Sanz, E, 2000</marker>
<rawString>Gómez Hidalgo, J.M., Mafia Lσpéz, M., and Puertas Sanz, E. (2000). “Combining text and heuristics for cost-sensitive spam filtering”. In Proceedings of the 4th Computational Natural Language Learning Workshop, CoNLL-2000, Lisbon, Portugal, pp. 99– 102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Kohavi</author>
</authors>
<title>A study of cross-validation and bootstrap for accuracy estimation and model selection”.</title>
<date>1995</date>
<booktitle>In Proceedings of the 12th International Joint Conference on Artificial Intelligence (IJCAI1995),</booktitle>
<pages>1137--1143</pages>
<publisher>Morgan Kaufmann,</publisher>
<marker>Kohavi, 1995</marker>
<rawString>Kohavi, R. (1995). “A study of cross-validation and bootstrap for accuracy estimation and model selection”. In Proceedings of the 12th International Joint Conference on Artificial Intelligence (IJCAI1995), Morgan Kaufmann, pp. 1137–1143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T M Mitchell</author>
</authors>
<date>1997</date>
<journal>Machine Learning. McGrawHill.</journal>
<contexts>
<context position="13229" citStr="Mitchell 1997" startWordPosition="2129" endWordPosition="2130">are not retrained. Furthermore, during classification the president consults the same members that were used to prepare its training set. In contrast, in crossvalidation stacking the president is tested using members that have received more training than those that prepared its training set. Hence, the model that the president has acquired, which shows when to trust each member, may not apply to the members that the president consults when classifying incoming messages. 4 Inducers employed As already mentioned, we used a Naïve Bayes (NB) and a memory-based learner as members of the committee (Mitchell 1997; Aha, et al. 1 m ∑ P(k) ⋅ ∏ k spam legit ∈ { , } i=1 NB assumes that X1,...,Xm are conditionally independent given the category (Duda &amp; Hart, 1973). With k-NN, a distance-weighted method is used, with a voting function analogous to the inverted cube of distance (Dudani 1976). The k nearest neighbors x�i of x� are considered: � � � , C(xi )) d(x, xi ) Wk S 1 d(z, zi ) i =1 where C(zi) is the category of neighbor x�i, d (x�i , x�j) is the distance between x�i and x�j , and δ (c1, c2) =1, if c1 = c2, and 0 otherwise. This formula weighs the contribution of each neighbor by its distance from the </context>
</contexts>
<marker>Mitchell, 1997</marker>
<rawString>Mitchell, T.M. (1997). Machine Learning. McGrawHill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Pantel</author>
<author>D Lin</author>
</authors>
<title>SpamCop: a spam classification and organization program”.</title>
<date>1998</date>
<booktitle>In Learning for Text Categorization – Papers from the AAAI Workshop,</booktitle>
<tech>AAAI Technical Report WS-98-05.</tech>
<pages>95--98</pages>
<location>Madison Wisconsin.</location>
<contexts>
<context position="2317" citStr="Pantel &amp; Lin, 1998" startWordPosition="300" endWordPosition="303">ed messages, advertising anything, from vacations to get-rich schemes. These messages, known as spam or more formally Unsolicited Commercial E-mail, are extremely annoying, as they clutter mailboxes, prolong dial-up connections, and often expose minors to unsuitable content (Cranor &amp; Lamacchia, 1998). Legal and simplistic technical countermeasures, like blacklists and keyword-based filters, have had a very limited effect so far.1 The success of machine learning techniques in text categorization (Sebastiani, 2001) has recently led to alternative, learning-based approaches (Sahami, et al. 1998; Pantel &amp; Lin, 1998; Drucker, et al. 1999). A classifier capable of distinguishing between spam and non-spam, hereafter legitimate, messages is induced from a manually categorized learning collection of messages, and is then used to identify incoming spam e-mail. Initial results have been promising, and experiments are becoming more systematic, by exploiting recently introduced benchmark corpora, and cost-sensitive evaluation measures (Gomez Hidalgo, et al. 2000; Androutsopoulos, et al. 2000a, b, c). Stacked generalization (Wolpert, 1992), or stacking, is an approach for constructing classifier ensembles. A clas</context>
</contexts>
<marker>Pantel, Lin, 1998</marker>
<rawString>Pantel, P., and Lin, D. (1998). “SpamCop: a spam classification and organization program”. In Learning for Text Categorization – Papers from the AAAI Workshop, pp. 95–98, Madison Wisconsin. AAAI Technical Report WS-98-05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Quinlan</author>
</authors>
<date>1993</date>
<booktitle>C4.5: Programs for Machine Learning,</booktitle>
<publisher>Morgan Kaufmann,</publisher>
<location>San Mateo, California.</location>
<marker>Quinlan, 1993</marker>
<rawString>Quinlan, J.R. (1993). C4.5: Programs for Machine Learning, Morgan Kaufmann, San Mateo, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sahami</author>
<author>S Dumais</author>
<author>D Heckerman</author>
<author>E Horvitz</author>
</authors>
<title>A Bayesian approach to filtering junk e-mail”.</title>
<date>1998</date>
<booktitle>In Learning for Text Categorization – Papers from the AAAI Workshop,</booktitle>
<tech>AAAI Technical Report WS98-05.</tech>
<pages>55--62</pages>
<location>Madison Wisconsin.</location>
<contexts>
<context position="2297" citStr="Sahami, et al. 1998" startWordPosition="296" endWordPosition="299"> users with unsolicited messages, advertising anything, from vacations to get-rich schemes. These messages, known as spam or more formally Unsolicited Commercial E-mail, are extremely annoying, as they clutter mailboxes, prolong dial-up connections, and often expose minors to unsuitable content (Cranor &amp; Lamacchia, 1998). Legal and simplistic technical countermeasures, like blacklists and keyword-based filters, have had a very limited effect so far.1 The success of machine learning techniques in text categorization (Sebastiani, 2001) has recently led to alternative, learning-based approaches (Sahami, et al. 1998; Pantel &amp; Lin, 1998; Drucker, et al. 1999). A classifier capable of distinguishing between spam and non-spam, hereafter legitimate, messages is induced from a manually categorized learning collection of messages, and is then used to identify incoming spam e-mail. Initial results have been promising, and experiments are becoming more systematic, by exploiting recently introduced benchmark corpora, and cost-sensitive evaluation measures (Gomez Hidalgo, et al. 2000; Androutsopoulos, et al. 2000a, b, c). Stacked generalization (Wolpert, 1992), or stacking, is an approach for constructing classifi</context>
<context position="5576" citStr="Sahami et al. (1998)" startWordPosition="767" endWordPosition="770">seful public approximation of a user’s mailbox, however, can be constructed by mixing spam messages with messages extracted from spam-free public archives of mailing lists. The corpus that we used, Ling-Spam, follows this approach (Androutsopoulos, et al. 2000a, b; Sakkis, et al. 2001). It is a mixture of spam messages and messages sent via the Linguist, a moderated list about the science and profession of linguistics. The corpus consists of 2412 Linguist messages and 481 spam messages. Spam messages constitute 16.6% of LingSpam, close to the rates reported by Cranor and LaMacchia (1998), and Sahami et al. (1998). Although the Linguist messages are more topicspecific than most users’ e-mail, they are less standardized than one might expect. For example, they contain job postings, software availability announcements and even flame-like responses. Moreover, recent experiments with an encoded user mailbox and a Naïve Bayes (NB) classifier (Androutsopoulos, et al. 2000c) yielded results similar to those obtained with Ling-Spam (Androutsopoulos, et al. 2000a). Therefore, experimentation with Ling-Spam can provide useful indicative results, at least in a preliminary stage. Furthermore, experiments with Ling</context>
</contexts>
<marker>Sahami, Dumais, Heckerman, Horvitz, 1998</marker>
<rawString>Sahami, M., Dumais, S., Heckerman D., and Horvitz, E. (1998). “A Bayesian approach to filtering junk e-mail”. In Learning for Text Categorization – Papers from the AAAI Workshop, pp. 55–62, Madison Wisconsin. AAAI Technical Report WS98-05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Sakkis</author>
<author>I Androutsopoulos</author>
<author>G Paliouras</author>
<author>V Karkaletsis</author>
<author>C D Spyropoulos</author>
<author>P Stamatopoulos</author>
</authors>
<title>A memory-based approach to anti-spam filtering”.</title>
<date>2001</date>
<tech>NCSR “Demokritos” Technical Report,</tech>
<location>Athens, Greece.</location>
<contexts>
<context position="3971" citStr="Sakkis, et al. 2001" startWordPosition="535" endWordPosition="538">t then decides on the category of the 1 Consult www.cauce.org, spam.abuse.net, and www.junkemail.org. message by considering the opinions of the members and the message itself. Ground-level classifiers often make different classification errors. Hence, a president that has successfully learned when to trust each of the members can improve overall performance. We have experimented with two groundlevel classifiers for which results on a public benchmark corpus are available: a Naïve Bayes classifier (Androutsopoulos, et al. 2000a, c) and a memory-based classifier (Androutsopoulos, et al. 2000b; Sakkis, et al. 2001). Using a third, memory-based classifier as president, we investigated two versions of stacking and two different cost-sensitive scenarios. Overall, our results indicate that stacking improves the performance of the ground-level classifiers, and that the performance of the resulting anti-spam filter is acceptable for real-life applications. Section 1 below presents the benchmark corpus and the preprocessing of the messages; section 2 introduces cost-sensitive evaluation measures; section 3 provides details on the stacking approaches that were explored; section 4 discusses the learning algorith</context>
<context position="5242" citStr="Sakkis, et al. 2001" startWordPosition="711" endWordPosition="714">ing them; section 5 presents our experimental results followed by conclusions. 1 Benchmark corpus and preprocessing Text categorization has benefited from public benchmark corpora. Producing such corpora for anti-spam filtering is not straightforward, since user mailboxes cannot be made public without considering privacy issues. A useful public approximation of a user’s mailbox, however, can be constructed by mixing spam messages with messages extracted from spam-free public archives of mailing lists. The corpus that we used, Ling-Spam, follows this approach (Androutsopoulos, et al. 2000a, b; Sakkis, et al. 2001). It is a mixture of spam messages and messages sent via the Linguist, a moderated list about the science and profession of linguistics. The corpus consists of 2412 Linguist messages and 481 spam messages. Spam messages constitute 16.6% of LingSpam, close to the rates reported by Cranor and LaMacchia (1998), and Sahami et al. (1998). Although the Linguist messages are more topicspecific than most users’ e-mail, they are less standardized than one might expect. For example, they contain job postings, software availability announcements and even flame-like responses. Moreover, recent experiments</context>
<context position="7110" citStr="Sakkis, et al. 2001" startWordPosition="1007" endWordPosition="1010"> are binary: Xi = 1 if the word is present; otherwise Xi = 0. To avoid treating forms of the same word as different attributes, a lemmatizer was applied, converting each word to its base form. To reduce the dimensionality, attribute selection was performed. First, words occurring in less than 4 messages were discarded. Then, the Information Gain (IG) of each candidate attribute X was computed: The attributes with the m highest IG-scores were selected, with m corresponding to the best configurations of the ground classifiers that have been reported for Ling-Spam (Androutsopoulos, et al. 2000a; Sakkis, et al. 2001); see Section 4. 2 Evaluation measures Blocking a legitimate message is generally more severe an error than accepting a spam message. Let L → S and S → L denote the two error types, respectively, and let us assume that L → S is λ times as costly as S → L . Previous research has considered three cost scenarios, where λ = 1, 9, or 999 IG(X,C ) = ∑ P x c ( , ) ⋅ log P x ∈ {0 , 1} , c ∈ {spam, , legit} (x) ⋅ P(c) P x c ( , ) (Androutsopoulos, et al. 2000a, b, c; Sakkis, et al. 2001). In the scenario where A = 999, blocked messages are deleted immediately. L → S is taken to be 999 times as costly a</context>
<context position="9496" citStr="Sakkis, et al. 2001" startWordPosition="1476" endWordPosition="1479">ater TCR values indicate better performance. For TCR &lt; 1, not using the filter is better. Our evaluation measures also include spam recall (SR) and spam precision (SP): NS → S N + N S→S S→L NS → S NS →S + NL →S X ⋅ NL b = NS WErr b = WErr TCR λ ⋅ NL SR SP WS (z) &gt; λ (z) If WL (z) and WS (z) are accurate estimates of P(legit |x�) and P(spam |x�), respectively, the criterion above achieves optimal results (Duda &amp; Hart, 1973). To measure the performance of a filter, weighted accuracy (WAcc) and its complementary weighted error rate (WErr = 1 – WAcc) are used (Androutsopoulos, et al. 2000a, b, c; Sakkis, et al. 2001): In all the experiments, stratified cross-validation was used. That is, Ling-Spam was partitioned into 10 equally populated parts, maintaining the original spam-legitimate ratio. Each experiment was repeated 10 times, each time reserving a different part Sj (j = 1, ..., 10) for testing, and using the remaining 9 parts as 10-fold Lj . WL WAcc λ ⋅ NL→L + NS→S λ ⋅ NL + NS where NY→Z is the number of messages in category Y that the filter classified as Z , NL = NL,L + NL,S , NS = NS,S + NS,L . That is, when a legitimate message is blocked, this counts as A errors; and when it passes the filter, t</context>
<context position="14233" citStr="Sakkis, et al. 2001" startWordPosition="2317" endWordPosition="2320">zi) is the category of neighbor x�i, d (x�i , x�j) is the distance between x�i and x�j , and δ (c1, c2) =1, if c1 = c2, and 0 otherwise. This formula weighs the contribution of each neighbor by its distance from the message to be classified, and the result is scaled to [0,1]. The distance is computed by an attribute-weighted function (Wettschereck, et al. 1995), employing Information Gain (IG): n d(zi,zj) ≡ ∑IGt ⋅ δ(xr,x&apos; ), IGt is the IG score of Xt (Section 1). In Tables 1 and 2, we reproduce the best performing configurations of the two learners on Ling-Spam (Androutsopoulos, et al. 2000b; Sakkis, et al. 2001). These configurations were used as members of the committee. The same memory-based learner was used as the president. However, we experimented with several configurations, varying the neighborhood size (k) from 1 to 10, and t 1 where zi = )4,..., xm&apos; zj = x1j,..., xmj , , and i = P (xi |k) − NN (z) k , k ∑ δ(spam i =1 3 ∑ 3 providing the president with the m best wordattributes, as in Section 1, with m ranging from 50 to 700 by 50. The same attribute- and distance-weighting schemes were used for the president, as with the ground-level memorybased learner. λ m SR SP TCR 1 100 82.4% 99.0% 5.41 </context>
<context position="18156" citStr="Sakkis, et al. 2001" startWordPosition="2987" endWordPosition="2990">m. Therefore, the additional errors of 1-NN and 2-NN, compared to the other presidents, are of the L → S type. Interestingly, in most of those cases, both members of the committee classify the instance correctly, as legitimate. This is an indication, that for small values of the parameter k the additional two features, i.e., the members’ confidence WS1 (z) and WS2 (z) , do not enhance but distort the representation of instances. As a result, the close neighborhood of the unclassified instance is not a legitimate, but a spam e-mail. This behavior of the memorybased classifier is also noted in (Sakkis, et al. 2001). The suggested solution there was to use a larger value for k, combined with a strong distance weighting function, such as the one presented in section 4. Conclusion In this paper we adopted a stacked generalization approach to anti-spam filtering, and evaluated its performance. The configuration that we examined combined a memory-based and a Naïve Bayes classifier in a two-member committee, in which another memory-based classifier presided. The classifiers that we chose as members of the committee have been evaluated individually on the same data as in our evaluation, i.e. the LingSpam corpu</context>
</contexts>
<marker>Sakkis, Androutsopoulos, Paliouras, Karkaletsis, Spyropoulos, Stamatopoulos, 2001</marker>
<rawString>Sakkis, G., Androutsopoulos, I., Paliouras, G., Karkaletsis, V., Spyropoulos, C.D., and Stamatopoulos, P. (2001) “A memory-based approach to anti-spam filtering”. NCSR “Demokritos” Technical Report, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R E Schapire</author>
<author>Y Singer</author>
</authors>
<title>BoosTexter: a boosting-based system for text categorization”.</title>
<date>2000</date>
<booktitle>Machine Learning,</booktitle>
<pages>39--2</pages>
<marker>Schapire, Singer, 2000</marker>
<rawString>Schapire, R.E., and Singer, Y. (2000). “BoosTexter: a boosting-based system for text categorization”. Machine Learning, 39(2/3):135–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Sebastiani</author>
</authors>
<title>Machine Learning in Automated Text Categorization. Revised version of</title>
<date>2001</date>
<tech>Technical Report IEI-B4-31-1999,</tech>
<location>Pisa, Italy.</location>
<contexts>
<context position="2217" citStr="Sebastiani, 2001" startWordPosition="287" endWordPosition="288">f email have intrigued direct marketers to flood the mailboxes of thousands of users with unsolicited messages, advertising anything, from vacations to get-rich schemes. These messages, known as spam or more formally Unsolicited Commercial E-mail, are extremely annoying, as they clutter mailboxes, prolong dial-up connections, and often expose minors to unsuitable content (Cranor &amp; Lamacchia, 1998). Legal and simplistic technical countermeasures, like blacklists and keyword-based filters, have had a very limited effect so far.1 The success of machine learning techniques in text categorization (Sebastiani, 2001) has recently led to alternative, learning-based approaches (Sahami, et al. 1998; Pantel &amp; Lin, 1998; Drucker, et al. 1999). A classifier capable of distinguishing between spam and non-spam, hereafter legitimate, messages is induced from a manually categorized learning collection of messages, and is then used to identify incoming spam e-mail. Initial results have been promising, and experiments are becoming more systematic, by exploiting recently introduced benchmark corpora, and cost-sensitive evaluation measures (Gomez Hidalgo, et al. 2000; Androutsopoulos, et al. 2000a, b, c). Stacked gener</context>
</contexts>
<marker>Sebastiani, 2001</marker>
<rawString>Sebastiani, F. (2001). Machine Learning in Automated Text Categorization. Revised version of Technical Report IEI-B4-31-1999, Istituto di Elaborazione dell’Informazione, Consiglio Nazionale delle Ricerche, Pisa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wettschereck</author>
<author>W D Aha</author>
<author>T Mohri</author>
</authors>
<title>A Review and Comparative Evaluation of Feature Weighting Methods for Lazy Learning Algorithms.</title>
<date>1995</date>
<journal>Applied Research in Artificial Intelligence,</journal>
<tech>Technical Report AIC-95-012,</tech>
<institution>Naval Research Laboratory, Navy Center for</institution>
<location>Washington, D.C.</location>
<contexts>
<context position="13976" citStr="Wettschereck, et al. 1995" startWordPosition="2272" endWordPosition="2275">ategory (Duda &amp; Hart, 1973). With k-NN, a distance-weighted method is used, with a voting function analogous to the inverted cube of distance (Dudani 1976). The k nearest neighbors x�i of x� are considered: � � � , C(xi )) d(x, xi ) Wk S 1 d(z, zi ) i =1 where C(zi) is the category of neighbor x�i, d (x�i , x�j) is the distance between x�i and x�j , and δ (c1, c2) =1, if c1 = c2, and 0 otherwise. This formula weighs the contribution of each neighbor by its distance from the message to be classified, and the result is scaled to [0,1]. The distance is computed by an attribute-weighted function (Wettschereck, et al. 1995), employing Information Gain (IG): n d(zi,zj) ≡ ∑IGt ⋅ δ(xr,x&apos; ), IGt is the IG score of Xt (Section 1). In Tables 1 and 2, we reproduce the best performing configurations of the two learners on Ling-Spam (Androutsopoulos, et al. 2000b; Sakkis, et al. 2001). These configurations were used as members of the committee. The same memory-based learner was used as the president. However, we experimented with several configurations, varying the neighborhood size (k) from 1 to 10, and t 1 where zi = )4,..., xm&apos; zj = x1j,..., xmj , , and i = P (xi |k) − NN (z) k , k ∑ δ(spam i =1 3 ∑ 3 providing the pr</context>
</contexts>
<marker>Wettschereck, Aha, Mohri, 1995</marker>
<rawString>Wettschereck, D., Aha, W. D., and Mohri, T. (1995). A Review and Comparative Evaluation of Feature Weighting Methods for Lazy Learning Algorithms. Technical Report AIC-95-012, Naval Research Laboratory, Navy Center for Applied Research in Artificial Intelligence, Washington, D.C.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wolpert</author>
</authors>
<title>Stacked Generalization”.</title>
<date>1992</date>
<journal>Neural Networks,</journal>
<volume>5</volume>
<issue>2</issue>
<contexts>
<context position="2842" citStr="Wolpert, 1992" startWordPosition="373" endWordPosition="374">ly led to alternative, learning-based approaches (Sahami, et al. 1998; Pantel &amp; Lin, 1998; Drucker, et al. 1999). A classifier capable of distinguishing between spam and non-spam, hereafter legitimate, messages is induced from a manually categorized learning collection of messages, and is then used to identify incoming spam e-mail. Initial results have been promising, and experiments are becoming more systematic, by exploiting recently introduced benchmark corpora, and cost-sensitive evaluation measures (Gomez Hidalgo, et al. 2000; Androutsopoulos, et al. 2000a, b, c). Stacked generalization (Wolpert, 1992), or stacking, is an approach for constructing classifier ensembles. A classifier ensemble, or committee, is a set of classifiers whose individual decisions are combined in some way to classify new instances (Dietterich, 1997). Stacking combines multiple classifiers to induce a higher-level classifier with improved performance. The latter can be thought of as the president of a committee with the ground-level classifiers as members. Each unseen incoming message is first given to the members; the president then decides on the category of the 1 Consult www.cauce.org, spam.abuse.net, and www.junk</context>
<context position="10772" citStr="Wolpert, 1992" startWordPosition="1699" endWordPosition="1700">r is present as our baseline: legitimate messages are SR measures the percentage of spam messages that the filter blocks (intuitively, its effectiveness), while SP measures how many blocked messages are indeed spam (its safety). Despite their intuitiveness, comparing different filter configurations using SR and SP is difficult: each configuration yields a pair of SR and SP results; and without a single combining measure, like TCR, that incorporates the notion of cost, it is difficult to decide which pair is better. the training set 3 Stacking In the first version of stacking that we explored (Wolpert, 1992), which we call cross-validation stacking, the training set of the president was prepared using a second-level 3-fold crossvalidation. Each training set was further partitioned into three equally populated parts, and the training set of the president was prepared in three steps. At each step, a different part (i = 1, 2, 3) of Lj Lj LSi was reserved, and the members were trained on the union LLi of the other two parts. Each x x 1,� , xm � = of LSi was enhanced with the members’ confidence WS1 (z) and WS2 (z) that z is spam, yielding an enhanced LSi&apos; with vectors 1991). For the latter, we used T</context>
</contexts>
<marker>Wolpert, 1992</marker>
<rawString>Wolpert, D. (1992). “Stacked Generalization”. Neural Networks, 5(2):241–260.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>