<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.92892">
Approximation and Exactness in Finite State Optimality Theory
</title>
<author confidence="0.988718">
Dale Gerdemann Gertjan van Noord
</author>
<affiliation confidence="0.999672">
University of Tubingen University of Groningen
</affiliation>
<email confidence="0.945553">
dg@sfs.nphil.uni-tuebingen.de vannoord@let.rug.n1
</email>
<sectionHeader confidence="0.976462" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999163888888889">
Previous work (Frank and Satta, 1998; Kart-
tunen, 1998) has shown that Optimality Theory
with gradient constraints generally is not finite
state. A new finite-state treatment of gradient
constraints is presented which improves upon
the approximation of Karttunen (1998). The
method turns out to be exact, and very com-
pact, for the syllabification analysis of Prince
and Smolensky (1993).
</bodyText>
<sectionHeader confidence="0.995437" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999546088888889">
Finite state methods have proven quite success-
ful for encoding rule-based generative phonol-
ogy (Johnson, 1972; Kaplan and Kay, 1994).
Recently, however, Optimality Theory (Prince
and Smolensky, 1993) has emphasized phono-
logical accounts with default constraints on sur-
face forms. While Optimality Theory (OT)
has been successful in explaining certain phono-
logical phenomena such as conspiracies (Kisse-
berth, 1970), it has been less successful for com-
putation. The negative result of Frank and
Satta (1998) has shown that in the general case
the method of counting constraint violations
takes OT beyond the power of regular relations.
To handle such constraints, Karttunen (1998)
has proposed a finite-state approximation that
counts constraint violations up to a predeter-
mined bound. Unlike previous approaches (El-
lison, 1994; Walther, 1996), Karttunen&apos;s ap-
proach is encoded entirely in the finite state
calculus, with no extra-logical procedures for
counting constraint violations.
In this paper, we will present a new ap-
proach that seeks to minimize constraint viola-
tions without counting. Rather than counting,
our approach employs a filter based on matching
constraint violations against violations in alter-
natively derivable strings. As in Karttunen&apos;s
counting approach, our approach uses purely fi-
nite state methods without extra-logical proce-
dures. We show that our matching approach is
superior to the counting approach for both size
of resulting automata and closeness of approxi-
mation. The matching approach can in fact ex-
actly model many OT analyses where the count-
ing approach yields only an approximation; yet,
the size of the resulting automaton is typically
much smaller.
In this paper we will illustrate the matching
approach and compare it with the counting ap-
proach on the basis of the Prince &amp; Smolensky
syllable structure example (Prince and Smolen-
sky, 1993; Ellison, 1994; Tesar, 1995), for each
of the different constraint orderings identified in
Prince &amp; Smolensky.
</bodyText>
<sectionHeader confidence="0.854393" genericHeader="method">
2 Finite State Phonology
</sectionHeader>
<subsectionHeader confidence="0.798472">
2.1 Finite State Calculus
</subsectionHeader>
<bodyText confidence="0.973482421052631">
Finite state approaches have proven to be very
successful for efficient encoding of phonological
rules. In particular, the work of Kaplan and
Kay (1994) has provided a compiler from classi-
cal generative phonology rewriting rules to finite
state transducers. This work has clearly shown
how apparently procedural rules can be recast
in a declarative, reversible framework.
In the process of developing their rule com-
piler, Kaplan &amp; Kay also developed a high-level
finite state calculus. They argue convincingly
that this calculus provides an appropriate high-
level approach for expressing regular languages
and relations. The alternative conception in
term of states and transitions can become un-
wieldy for all but the simplest cases.&apos;
lAlthough in some cases such a direct implementation
can be much more efficient (Mohri and Sproat, 1996; van
Noord and Gerdemann, 1999).
</bodyText>
<page confidence="0.994789">
34
</page>
<figure confidence="0.977812894736842">
[1 empty string
[E1,E2,...,En] concatenation of El...En
{} empty language
fEl,E2,...,Enl union of El.. .En
(E) grouping for op. precedence
E* Kleene closure
E+ Kleene plus
E- optionality
El - E2 difference
-E complement
$ E containment
El &amp; E2 intersection
any symbol
El x E2 cross-product
A o B composition
domain (E) domain of a transduction
range(E) range of a transduction
identity(E) identity transduction2
inverse (E) inverse transduction
</figure>
<tableCaption confidence="0.984749">
Table 1: Regular expression operators.
</tableCaption>
<bodyText confidence="0.997943138888889">
Kaplan &amp; Kay&apos;s finite state calculus now ex-
ists in multiple implementations, the most well-
known of which is that of Karttunen et al.
(1996). In this paper, however, we will use
the alternative implementation provided by the
FSA Utilities (van Noord, 1997; van Noord,
1999; van Noord and Gerdemann, 1999). The
FSA Utilities allows the programmer to intro-
duce new regular expression operators of arbi-
trary complexity. This higher-level interface al-
lows us to express our algorithm more easily.
The syntax of the FSA Utilities calculus is sum-
marized in Table 1.
The finite state calculus has proven to be a
very useful tool for the development of higher-
level finite state operators (Karttunen, 1995;
Kempe and Karttunen, 1996; Karttunen, 1996;
Gerdemann and van Noord, 1999). An inter-
esting feature of most such operators is that
they are implemented using a generate-and-test
paradigm. Karttunen (1996), for example, in-
troduces an algorithm for a leftmost-longest re-
placement operator. Somewhat simplified, we
may view this algorithm as having two steps.
First, the generator freely marks up possible
replacement sites. Then the tester, which is
an identity transducer, filters out those cases
not conforming to the leftmost-longest strategy.
21f an expression for a recognizer occurs in a context
where a transducer is required, the identity operation
will be used implicitly for coercion.
Since the generator and tester are both imple-
mented as transducers, they can be composed
into a single transducer, which eliminates the
inefficiency normally associated with generate-
and-test algorithms.
</bodyText>
<subsectionHeader confidence="0.991234">
2.2 Finite State Optimality Theory
</subsectionHeader>
<bodyText confidence="0.989564571428571">
The generate-and-test paradigm initially ap-
pears to be appropriate for optimality theory.
If, as claimed in Ellison (1994), Gen is a regu-
lar relation and if each constraint can be imple-
mented as an identity transducer, then optimal-
ity theory analyses could be implemented as in
fig. 1.
</bodyText>
<figure confidence="0.918697">
Gen
Constraintl
ConstraintN
</figure>
<figureCaption confidence="0.903091">
Figure 1: Optimality Theory as Generate and
Test
</figureCaption>
<bodyText confidence="0.905203722222222">
The problem with this simple approach is
that in OT, a constraint is allowed to be vio-
lated if none of the candidates satisfy that con-
straint. Karttunen (1998) treats this problem
by providing a new operator for lenient compo-
sition, which is defined in terms of the auxiliary
operation of priority union. In the FSA Utilities
calculus, these operations can be defined as:3
macro(priority_union(Q,R),
fQ, -domain(Q) o RI).
macro(lenient_composition(S,C),
priority_union(S o C, S)).
The effect here is that the lenient composition
of S and C is the composition of S and C, except
for those elements in the domain of S that are
not mapped to anything by S o C. For these
elements not in the domain of S o C, the effect
is the same as the effect of S alone. We use the
</bodyText>
<footnote confidence="0.980039166666667">
3The notation macro (Expri. ,Expr2) is used to indi-
cate that the regular expression Exprl is an abbreviation
for the expression Expr2. Because Prolog variables are
allowed in both expressions this turns out to be an intu-
itive and powerful notation (van Noord and Gerdemann,
1999).
</footnote>
<page confidence="0.999546">
35
</page>
<bodyText confidence="0.99935375">
notation S lc C as a succinct notation for the
lenient composition of S and C. Using lenient
composition an OT analysis can be written as
in fig. 2.
</bodyText>
<figure confidence="0.908407">
Gen
lc
Constraintl
lc
...
lc
ConstraintN
</figure>
<figureCaption confidence="0.9956115">
Figure 2: Optimality Theory as Generate and
Test with Lenient Composition
</figureCaption>
<bodyText confidence="0.99995403125">
The use of lenient composition, however, is
not sufficient for implementing optimality the-
ory. In general, a candidate string can violate
a constraint multiple times and candidates that
violate the constraint the least number of times
need to be preferred. Lenient composition is
sufficient to prefer a candidate that violates the
constraint 0 times over a candidate that violates
the constraint at least once. However, lenient
composition cannot distinguish two candidates
if the first contains one violation, and the sec-
ond contains at least two violations.
The problem of implementing optimality the-
ory becomes considerably harder when con-
straint violations need to be counted. As Frank
and Satta (1998) have shown, an OT describes a
regular relation under the assumptions that Gen
is a regular relation, and each of the constraints
is a regular relation which maps a candidate
string to a natural number (indicating the num-
ber of constraint violations in that candidate),
where the range of each constraint is finite. If
constraints are defined in such a way that there
is no bound to the number of constraint viola-
tions that can occur in a given string, then the
resulting OT may describe a relation that is not
regular. A simple example of such an OT (at-
tributed to Markus Hiller) is the OT in which
the inputs of interest are of the form [a* ,b*],
Gen is defined as a transducer which maps all
a&apos;s to b&apos;s and all b&apos;s to a&apos;s, or alternatively, it
performs the identity map on each a and b:
</bodyText>
<equation confidence="0.806547">
{[(a x b)*,(b x a)*] ,
[(a x a)*,(b x b)*]}
</equation>
<bodyText confidence="0.980766705882353">
This OT contains only a single constraint, *A:
a string should not contain a. As can eas-
ily be verified, this OT defines the relation
{ (an bm, an, Tro i
o )in &lt; m} U {(anbrn, bnam)Im &lt;n},
which can easily be shown to be non-regular.
Although the OT described above is highly
unrealistic for natural language, one might nev-
ertheless expect that a constraint on syllable
structure in the analysis of Prince &amp; Smolensky
would require an unbounded amount of count-
ing (since words are of unbounded length), and
that therefore such analyses would not be de-
scribable as regular relations. An important
conclusion of this paper is that, contrary to this
potential expectation, such cases in fact can be
shown to be regular.
</bodyText>
<subsectionHeader confidence="0.977728">
2.3 Syllabification in Finite State OT
</subsectionHeader>
<bodyText confidence="0.989237181818182">
In order to illustrate our approach, we will start
with a finite state implementation of the syllab-
ification analysis as presented in chapter 6 of
Prince and Smolensky (1993). This section is
heavily based on Karttunen (1998), which the
reader should consult for more explanation and
examples.
The inputs to the syllabification OT are se-
quences of consonants and vowels. The input
will be marked up with onset, nucleus, coda and
unparsed brackets; where a syllable is a sequence
of an optional onset, followed by a nucleus, fol-
lowed by an optional coda. The input will be
marked up as a sequence of such syllables, where
at arbitrary places unparsed material can in-
tervene. The assumption is that an unparsed
vowel or consonant is not spelled out phoneti-
cally. Onsets, nuclei and codas are also allowed
to be empty; the phonetic interpretation of such
constituents is epenthesis.
First we give a number of simple abbrevia-
tions:
macro(cons,
{b,c,d,f,g,h,j,k,l,m,n,
p,q,r,s,t,v,w,x,y,z} ).
macro(vowel, {a,e,o,u,i}).
macro(o_br, onset
macro(n_br, % nucleus
macro(d_br, &apos;DP). % coda
macro(x_br, &apos;XP). % unparsed
macro(r_br, &apos;] &apos;) .
macro (bracket,
{o br,n br,d br,x br,r br1).
</bodyText>
<page confidence="0.987909">
36
</page>
<bodyText confidence="0.99131509375">
macro (onset , [o_br , cons- ,r_br] ) .
macro (nucleus , En_br , vowel&amp;quot; ,r_bri ) .
macro (coda, [d_br , cons- ,r_br] ) .
macro (unparsed, [x_br , letter ,r_br] ) .
Following Karttunen, Gen is formalized as in
fig. 3. Here, parse introduces onset, coda or
unparsed brackets around each consonant, and
nucleus or unparsed brackets around each vowel.
The replace (T ,Left ,Right) transducer ap-
plies transducer T obligatory within the con-
texts specified by Left and Right (Gerdemann
and van Noord, 1999). The replace (T) trans-
ducer is an abbreviation for replace (T, [1 , [1),
i.e. T is applied everywhere. The overparse
transducer introduces optional &apos;empty&apos; con-
stituents in the input, using the intro_each_pos
operator.4
In the definitions for the constraints, we will
deviate somewhat from Karttunen. In his for-
malization, a constraint simply describes the set
of strings which do not violate that constraint.
It turns out to be easier for our extension of
Karttunen&apos;s formalization below, as well as for
our alternative approach, if we return to the
concept of a constraint as introduced by Prince
and Smolensky where a constraint adds marks
in the candidate string at the position where
the string violates the constraint. Here we use
the symbol @ to indicate a constraint violation.
After checking each constraint the markers will
be removed, so that markers for one constraint
will not be confused with markers for the next.
</bodyText>
<equation confidence="0.495493833333333">
macro (mark_violat ion (parse ) ,
replace ( ( [] x
macro (mark_violat ion (no_coda) ,
replace ( ( [] x
macro (mark_violat ion (f ill_nuc) ,
replace ( ( [] x
</equation>
<bodyText confidence="0.9648879">
4An alternative would be to define overparse with
a Kleene star in place of the option operator. This
would introduce unbounded sequences of empty seg-
ments. Even though it can be shown that, with the con-
straints assumed here, no optimal candidate ever con-
tains two empty segments in a row (proposition 4 of
Prince and Smolensky (1993)) it is perhaps interesting
to note that defining Gen in this alternative way causes
cases of infinite ambiguity for the counting approach but
is unproblematic for the matching approach.
</bodyText>
<equation confidence="0.966335666666667">
macro(mark_violation(fill_ons),
replace ( ( C] x
macro(mark_violation(have_ons),
replace ( ( C] x @) , H ,n_br)
o
replace ( (@ x [] ) , onset , [] ) ) .
</equation>
<bodyText confidence="0.999990884615385">
The parse constraint simply states that a
candidate must not contain an unparsed con-
stituent. Thus, we add a mark after each un-
parsed bracket. The no_coda constraint is sim-
ilar: each coda bracket will be marked. The
fill_nuc constraint is only slightly more compli-
cated: each sequence of a nucleus bracket imme-
diately followed by a closing bracket is marked.
The fill_ons constraint treats empty onsets in
the same way. Finally, the have_ons constraint
is somewhat more complex. The constraint re-
quires that each nucleus is preceded by an onset.
This is achieved by marking all nuclei first, and
then removing those marks where in fact an on-
set is present.
This completes the building blocks we need
for an implementation of Prince and Smolen-
sky&apos;s analysis of syllabification. In the follow-
ing sections, we present two alternative imple-
mentations which employ these building blocks.
First, we discuss the approach of Karttunen
(1998), based on the lenient composition oper-
ator. This approach uses a counting approach
for multiple constraint violations. We will then
present an alternative approach in which con-
straints eliminate candidates using matching.
</bodyText>
<sectionHeader confidence="0.965349" genericHeader="method">
3 The Counting Approach
</sectionHeader>
<bodyText confidence="0.999453545454545">
In the approach of Karttunen (1998), a candi-
date set is leniently composed with the set of
strings which satisfy a given constraint. Since
we have defined a constraint as a transducer
which marks candidate strings, we need to al-
ter the definitions somewhat, but the result-
ing transducers are equivalent to the transduc-
ers produced by Karttunen (1998). We use the
(left-associative) optimality operator oo for ap-
plying an OT constraint to a given set of can-
didates:5
</bodyText>
<footnote confidence="0.89461">
5The operators o&apos; and &apos;lc&apos; are assumed to be left as-
sociative and have equal precedence.
</footnote>
<page confidence="0.996076">
37
</page>
<figure confidence="0.986872111111111">
macro (gen, {cons , vowel}*
overparse
parse
syllable_ structure
macro(parse, replace([[] x {o_br,d_br,x_br},cons, [1 x r_br])
replace([[] x {n_br,x_brI, vowel, ] x r_br] ) )
macro (overpar se , intro_each_pos ( Ho_br , d_br ,n_brI , r_br1 ) ) •
macro (intro_each_pos (E) , [] x E, ?]*, xEl).
macro(syllable_structure,ignore(Eonset^,nucleus,coda^],unparsed)*).
</figure>
<figureCaption confidence="0.999897">
Figure 3: The definition of Gen
</figureCaption>
<equation confidence="0.9435155">
macro(Cands oo Constraint,
Cands
mark_violation(Constraint)
lc
($ @)
{ @ x [] , ? - @}* ) .
</equation>
<bodyText confidence="0.999956636363637">
Here, the set of candidates is first composed
with the transducer which marks constraint vi-
olations. We then leniently compose the re-
sulting transducer with - ($ @)6, which encodes
the requirement that no such marks should be
contained in the string. Finally, the remaining
marks (if any) are removed from the set of sur-
viving candidates. Using the optimality opera-
tor, we can then combine Gen and the various
constraints as in the following example (equiv-
alent to figure 14 of Karttunen (1998)):
</bodyText>
<figure confidence="0.842469625">
macro(syllabify, gen
oo
have _ons
oo
no_coda
oo
fill_nuc
00
</figure>
<footnote confidence="0.9314495">
6As explained in footnote 2, this will be coerced into
an identity transducer.
</footnote>
<equation confidence="0.571793333333333">
parse
oo
fill_ons ).
</equation>
<bodyText confidence="0.999858666666667">
As mentioned above, a candidate string can
violate a constraint multiple times and candi-
dates that violate the constraint the least num-
ber of times need to be preferred. Lenient com-
position cannot distinguish two candidates if
the first contains one violation, and the sec-
ond contains at least two violations. For exam-
ple, the above syllabify transducer will assign
three outputs to the input bebop:
</bodyText>
<equation confidence="0.997055">
0 [b] N [e] X [b] X [o] X [p]
0 [b] N [e] 0 [b] N [o] X [p]
X [b] X [e] 0 [b] N [o] X [p]
</equation>
<bodyText confidence="0.9992102">
In this case, the second output should have been
preferred over the other two, because the sec-
ond output violates &apos;Parse&apos; only once, whereas
the other outputs violate &apos;Parse&apos; three times.
Karttunen recognizes this problem and pro-
poses to have a sequence of constraints Parse0,
Parsel, Parse2 ParseN, where each ParseX
constraint requires that candidates not contain
more than X unparsed constituents.7 In this
case, the resulting transducer only approximates
</bodyText>
<footnote confidence="0.958495666666667">
7This construction is similar to the construction in
Frank and Satta (1998), who used a suggestion in Ellison
(1994).
</footnote>
<page confidence="0.998258">
38
</page>
<bodyText confidence="0.999675285714286">
the OT analysis, because it turns out that for
any X there are candidate strings that this
transducer fails to handle correctly (assuming
that there is no bound on the length of candi-
date strings).
Our notation is somewhat different, but
equivalent to the notation used by Karttunen.
Instead of a sequence of constraints Cons°
... ConsX, we will write Cands oo Prec ::
Cons, which is read as: apply constraint Cons
to the candidate set Cands with precision Prec,
where &amp;quot;precision&amp;quot; means the predetermined
bound on counting. For example, a variant of
the syllabify constraint can be defined as:
</bodyText>
<equation confidence="0.938634454545455">
macro(syllabify, gen
oo
have_ons
oo
no_coda
oo
1 :: fill_nuc
oo
8 :: parse
oo
fill_ons ).
</equation>
<bodyText confidence="0.99947025">
Using techniques described in 0, this variant
can be shown to be exact for all strings of length
&lt; 10. Note that if no precision is specified, then
a precision of 0 is assumed.
This construct can be defined as follows (in
the actual implementation the regular expres-
sion is computed dynamically based on the
value of Prec):
</bodyText>
<equation confidence="0.957638142857143">
macro(Cands oo 3 :: Constraint,
Cands
o
mark_violation(Constraint)
lc
- MS @),($ @),($ @),($ @)])
lc
- ([($ @),($ @),($ 0)1)
lc
- ([($ @),($ MD
lc
- ($ 0)
o
{ 0 : [] , ? - 0}* ) .
</equation>
<sectionHeader confidence="0.913159" genericHeader="method">
4 The Matching Approach
</sectionHeader>
<subsectionHeader confidence="0.923234">
4.1 Introduction
</subsectionHeader>
<bodyText confidence="0.999818666666667">
In order to illustrate the alternative approach,
based on matching we return to the bebop ex-
ample given earlier, repeated here:
</bodyText>
<listItem confidence="0.560563">
cl: OE b ] NC e ] XE b ] XE o ] XE p ]
c2: OE b ] NC e ] OE b ] NC o ] XE p ]
c3: XE b ] XE e ] OE b ] NC o ] XE p ]
</listItem>
<bodyText confidence="0.961619258064516">
Here an instance of &apos;Xr is a constraint viola-
tion, so c2 is the best candidate. By counting,
one can see that c2 has one violation, while c1
and c3 each have 3. By matching, one can see
that all candidates have a violation in position
13, but cl and c3 also have violations in posi-
tions not corresponding to violations in c2. As
long the positions of violations line up in this
manner, it is possible to construct a finite state
filter to rule out candidates with a non-minimal
number of violations. The filter will take the
set of candidates, and subtract from that set all
strings that are similar, except that they con-
tain additional constraint violations.
Given the approach of marking up constraint
violations introduced earlier, it is possible to
construct such a matching filter. Consider
again the &apos;bebop&apos; example. If the violations are
marked, the candidates of interest are:
OE b 1 N C e 1 XE @ b 1 XE @ o 1 XE @ p 1
OE b ] NE e ] OE b ] NE o ] XE @ p 1
XE a b ] XE a e ] OE b 1 NE o 1 XE @ p 1
For the filter, we want to compare alterna-
tive mark-ups for the same input string. Any
other differences between the candidates can be
ignored. So the first step in constructing the fil-
ter is to eliminate everything except the markers
and the original input. For the syllable struc-
ture example, finding the original input is easy
since it never gets changed. For the &amp;quot;bebop&amp;quot;
example, the filter first constructs:
</bodyText>
<figure confidence="0.652684">
b e@b@o @ p
b e b o@p
@b@e b o @ p
</figure>
<bodyText confidence="0.9998264">
Since we want to rule out candidates with at
least one more constraint violation than nec-
essary, we apply a transducer to this set which
inserts at least one more marker. This will yield
an infinite set of bad candidates each of which
</bodyText>
<page confidence="0.998672">
39
</page>
<bodyText confidence="0.999979777777778">
has at least two markers and with one of the
markers coming directly before the final &apos;p&apos;.
In order to use this set of bad candidates as a
filter, brackets have to be reinserted. But since
the filter does not care about positions of brack-
ets, these can be inserted randomly. The result
is the set of all strings with at least two mark-
ers, one of the markers coming directly before
the final p&apos;, and arbitrary brackets anywhere.
This set includes the two candidates cl and c3
above. Therefore, after applying this filter only
the optimal candidate survives. The three steps
of deleting brackets, adding extra markers and
randomly reinserting brackets are encoded in
the add_violation macro given in fig. 4.
The application of an OT constraint can now
be defined as follows, using an alternative defi-
nition of the optimality operator:
</bodyText>
<equation confidence="0.818053571428571">
macro(Cands oo Constraint,
Cands
mark_violation(Constraint)
range (Cands
mark_violation(Constraint)
add_violation)
{(0 x U),(? - 0)1* ).
</equation>
<bodyText confidence="0.999929">
Note that this simple approach only works in
cases where constraint violations line up neatly.
It turns out that for the syllabification example
discussed earlier that this is the case. Using the
syllabify macro given above with this match-
ing implementation of the optimality operator
produces a transducer of only 22 states, and can
be shown to be exact for all inputs!
</bodyText>
<subsectionHeader confidence="0.956085">
4.2 Permutation
</subsectionHeader>
<bodyText confidence="0.988514571428571">
In the general case, however, constraint viola-
tions need not line up. For example, if the order
of constraints is somewhat rearranged as in:
parse oo fill_ons oo have_ons
oo fill_nuc oo no_coda
the matching approach is not exact: it will pro-
duce wrong results for an input such as &apos;arts&apos;:
</bodyText>
<equation confidence="0.963151">
N[a]D[r]0 [t]N[]D[s] %et : art@s
N [a] 0 [r] N [t] 0 [s]1\10 %cf : ar@ts@
</equation>
<bodyText confidence="0.9986705">
Here, the second output should not be produced
because it contains one more violation of the
f ill_nue constraint. In such cases, a limited
amount of permutation can be used in the fil-
ter to make the marker symbols line up. The
add_violation filter of fig. 4 can be extended
with the following transducer which permutes
marker symbols:
</bodyText>
<equation confidence="0.990470666666667">
macro (permute_marker,
*,(@ x [1) *, x
C? *,([] x @),? *,(@ x C1)11*,? *])
</equation>
<bodyText confidence="0.989813">
Greater degrees of permutation can be achieved
by composing permute_marker several times.
For example:8
</bodyText>
<equation confidence="0.980951625">
macro (add_violation (3) ,
{ (bracket x [1),(? - bracket ) }*
*, x *1
0
permute_marker
permute_marker
permute_marker
{( [1 x bracket) , (? - bracket ) ]-* ) .
</equation>
<bodyText confidence="0.999932666666667">
So we can incorporate a notion of &apos;precision&apos; in
the definition of the optimality operator for the
matching approach as well, by defining:
</bodyText>
<equation confidence="0.678951857142857">
macro(Cands oo Prec :: Constraint),
Cands
mark_violation(Constraint)
range (Cands
mark_violation(Constraint)
add_violation(Prec))
{ (0 x D),(? - 0)1* ).
</equation>
<footnote confidence="0.992261">
8An alternative approach would be to compose
the permute_marker transducers before inserting extra
markers. Our tests, however, show this alternative to be
somewhat less efficient.
</footnote>
<page confidence="0.993519">
40
</page>
<figure confidence="0.779220444444445">
macro(add_violation,
{(bracket x [1 ) , ? - bracket}*
0
C? *,(C] x 0)1 + , ? *]
-Up x bracket), ? - bracket}*
).
% delete brackets
% add at least one 0
% reinsert brackets
</figure>
<figureCaption confidence="0.998388">
Figure 4: Macro to introduce additional constraint violation marks.
</figureCaption>
<bodyText confidence="0.98525309375">
The use of permutation is most effective when
constraint violations in alternative candidates
tend to occur in corresponding positions. In
the worst case, none of the violations may line
up. Suppose that for some constraint, the input
&amp;quot;bebop&amp;quot; is marked up as:
cl: @ b @ e b o p
c2: b e ab ao Op
In this case, the precision needs to be two in
order for the markers in c1 to line up with
markers in c2. Similarly, the counting approach
also needs a precision of two in order to count
the two markers in cl and prefer this over
the greater than two markers in c2. The gen-
eral pattern is that any constraint that can be
treated exactly with counting precision N, can
also be handled by matching with precision less
than or equal to N. In the other direction, how-
ever, there are constraints, such as those in the
Prince and Smolensky syllabification problem,
that can only be exactly implemented by the
matching approach.
For each of the constraint orderings discussed
by Prince and Smolensky, it turns out that at
most a single step of permutation (i.e. a pre-
cision of 1) is required for an exact implemen-
tation. We conclude that this OT analysis of
syllabification is regular. This improves upon
the result of Karttunen (1998). Moreover, the
resulting transducers are typically much smaller
too. In 0 we present a number of experiments
which provide evidence for this observation.
</bodyText>
<subsectionHeader confidence="0.989138">
4.3 Discussion
</subsectionHeader>
<bodyText confidence="0.99975464">
Containment. It might be objected that the
Prince and Smolensky syllable structure exam-
ple is a particularly simple containment theory
analysis and that other varieties of OT such as
correspondence theory (McCarthy and Prince,
1995) are beyond the scope of matching.9 In-
deed we have relied on the fact that Gen only
adds brackets and does not add or delete any-
thing from the set of input symbols. The filter
that we construct needs to compare candidates
with alternative candidates generated from the
same input.
If Gen is allowed to change the input then a
way must be found to remember the original in-
put. Correspondence theory is beyond the scope
of this paper, however a simple example of an
OT where Gen modifies the input is provided by
the problem described in V.2 (from Frank and
Satta (1998)). Suppose we modify Gen here so
that its output includes a representation of the
original input. One way to do this would be
to adopt the convention that input symbols are
marked with a following 0 and output symbols
are marked with a following 1. With this con-
vention Gen becomes:
</bodyText>
<equation confidence="0.595198">
macro (gen,
x [a,0,b,1])*,(b x [D,O,a,1])*] ,
C(a x [a,0,a,1])*,(b x [b,0,b,1])*]})
</equation>
<bodyText confidence="0.9977864">
Then the constraint against the symbol a
needs to be recast as a constraint against
[a, 1] .1° And, whereas above add_violation
was previously written to ignore brackets, for
this case it will need to ignore output symbols
</bodyText>
<footnote confidence="0.996438333333333">
9Kager (1999) compares containment theory and cor-
respondence theory for the syllable structure example.
1°OT makes a fundamental distinction between
markedness constraints (referring only to the surface)
and faithfulness constraints (referring to both surface
and underlying form). With this mark-up convention,
faithfulness constraints might be allowed to refer to both
symbols marked with 0 and symbols marked with 1. But
note that the Fill and Parse constraints in syllabifica-
tion are also considered to be faithfulness constraints
since they correspond to epenthesis and deletion respec-
tively.
</footnote>
<page confidence="0.999135">
41
</page>
<figure confidence="0.9956025">
b
[]:a
5
b
4
c
[]:a
b
c
0
[]:a
b
1
2
3
c
</figure>
<bodyText confidence="0.960836943661972">
of whether a given transducer is ambiguous is
shown to be decidable in (Blattner and Head,
1977); and an efficient algorithm is proposed in
(Roche and Schabes, 1997).12 Therefore, in or-
der to check a given transducer T for exactness,
it must be the case that for each of the con-
straints C, is_exact (T , C) is nonambiguous.
If a transducer T is not exact, we characterize
the quality of the approximation by considering
the maximum length of input strings for which
T is exact. For example, even though T fails the
exactness check, it might be the case that
[? , ? &amp;quot; ?
-,? -,? -]
in fact is exact, indicating that T produces the
correct result for all inputs of length &lt; 5.
Suppose we are given the sequence of con-
straints:
have_ons &gt;&gt; fill_ons &gt;&gt; parse
&gt;&gt; fill_nuc &gt;&gt; no_coda
and suppose furthermore that we require that
the implementation, using the counting ap-
proach, must be exact for all strings of length
&lt; 10. How can we determine the level of pre-
cision for each of the constraints? A simple
algorithm (which does not necessarily produce
the smallest transducer) proceeds as follows.
Firstly, we determine the precision of the first,
most important, constraint by checking exact-
ness for the transducer
gen oo P have_ons
for increasing values for P. As soon as we find
the minimal P for which the exactness check suc-
ceeds (in this case for P=0), we continue by
determining the precision required for the next
constraint by finding the minimal value of P in:
gen oo 0 :: have_ons oo P fill_ons
We continue in this way until we have deter-
mined precision values for each of the con-
straints. In this case we obtain a transducer
with 8269 states implementing:
12We have adapted the algorithm proposed in (Roche
and Schabes, 1997) since it fails to treat certain types of
transducer correctly; we intend to provide details some-
where else.
gen oo 0 :: have_ons
oo 1 :: fill_ons
oo 8 :: parse
oo 5 :: fill_nuc
oo 4 :: no_coda
In contrast, using matching an exact implemen-
tation is obtained using a precision of 1 for the
fill_nuc constraint; all other constraints have
a precision of 0. This transducer contains only
28 states.
The assumption in OT is that each of the
constraints is universal, whereas the constraint
order differs from language to language. Prince
and Smolensky identify nine interestingly dif-
ferent constraint orderings. These nine &amp;quot;lan-
guages&amp;quot; are presented in table 2.
In table 3 we compare the size of the resulting
automata for the matching approach, as well
as for the counting approach, for three different
variants which are created in order to guarantee
exactness for strings of length &lt; 5, &lt; 10 and
&lt; 15 respectively.
Finally, the construction of the transducer us-
ing the matching approach is typically much
faster as well. In table 4 some comparisons are
summarized.
</bodyText>
<sectionHeader confidence="0.999344" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999959695652174">
We have presented a new approach for im-
plementing OT which is based on matching
rather than the counting approach of Karttunen
(1998). The matching approach shares the ad-
vantages of the counting approach in that it uses
the finite state calculus and avoids off-line sort-
ing and counting of constraint violations. We
have shown that the matching approach is su-
perior in that analyses that can only be approx-
imated by counting can be exactly implemented
by matching. Moreover, the size of the resulting
transducers is significantly smaller.
We have shown that the matching approach
along with global permutation provides a pow-
erful technique technique for minimizing con-
straint violations. Although we have only ap-
plied this approach to permutations of the
Prince &amp;z Smolensky syllabification analysis, we
speculate that the approach (even with local
permutation) will also yield exact implementa-
tions for most other OT phonological analyses.
Further investigation is needed here, particu-
larly with recent versions of OT such as cor-
</bodyText>
<page confidence="0.99958">
43
</page>
<figure confidence="0.9777186">
id constraint order
1 have_ons &gt;&gt; fill_ons &gt;&gt; no_coda &gt;&gt; fill_nuc &gt;&gt; parse
2 have_ons &gt;&gt; no_coda &gt;&gt; fill_nuc &gt;&gt; parse &gt;&gt; fill_ons
3 no_coda &gt;&gt; fill_nuc &gt;&gt; parse &gt;&gt; fill_ons &gt;&gt; have_ons
4 have_ons &gt;&gt; fill_ons &gt;&gt; no_coda &gt;&gt; parse &gt;&gt; fill_nuc
5 have_ons &gt;&gt; no_coda &gt;&gt; parse &gt;&gt; fill_nuc &gt;&gt; fill_ons
6 no_coda &gt;&gt; parse &gt;&gt; fill_nuc &gt;&gt; fill_ons &gt;&gt; have_ons
7 have_ons &gt;&gt; fill_ons &gt;&gt; parse &gt;&gt; fill_nuc &gt;&gt; no_coda
8 have_ons &gt;&gt; parse &gt;&gt; fill_ons &gt;&gt; fill_nuc &gt;&gt; no_coda
9 parse &gt;&gt; fill_ons &gt;&gt; have_ons &gt;&gt; fill_nuc &gt;&gt; no_coda
</figure>
<tableCaption confidence="0.732344">
Table 2: Nine different constraint orderings for syllabification, as given in Prince and Smolensky,
chapter 6.
</tableCaption>
<table confidence="0.9999255">
Method Exactness Constraint order
1 2 3 4 5 6 7 8 9
matching exact 29 22 20 17 10 8 28 23 20
counting &lt; 5 95 220 422 167 10 240 1169 2900 4567
counting &lt; 10 280 470 1667 342 10 420 8269 13247 16777
counting &lt; 15 465 720 3812 517 10 600 22634 43820 50502
</table>
<tableCaption confidence="0.784639">
Table 3: Comparison of the matching approach and the counting approach for various levels of
exactness. The numbers indicate the number of states of the resulting transducer.
</tableCaption>
<bodyText confidence="0.999575470588235">
respondence theory. Another line of further re-
search will be the proper integration of finite
state OT with non-OT phonological rules as dis-
cussed, for example, in papers collected in Her-
mans and van Oostendorp (1999) .
Finally, we intend also to investigate the ap-
plication of our approach to syntax. Karttunen
(1998) suggests that the Constraint Grammar
approach of Karlsson et al. (1995) could be
implemented using lenient composition. If this
is the case, it could most probably be imple-
mented more precisely using the matching ap-
proach. Recently, Oflazer (1999) has presented
an implementation of Dependency syntax which
also uses lenient composition with the counting
approach. The alternative of using a matching
approach here should be investigated.
</bodyText>
<sectionHeader confidence="0.999508" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99958190625">
Meera Blattner and Tom Head. 1977. Single-
valued a-transducers. Journal of Computer
and System Sciences, 15(3):328-353.
Mark T. Ellison. 1994. Phonological deriva-
tion in optimality theory. In Proceedings of
the 15th International Conference on Compu-
tational Linguistics (COLING), pages 1007-
1013, Kyoto.
Robert Frank and Giorgio Satta. 1998. Opti-
mality theory and the computational com-
plexity of constraint violability. Computa-
tional Linguistics, 24:307-315.
Dale Gerdemann and Gertjan van Noord. 1999.
Transducers from rewrite rules with backref-
erences. In Ninth Conference of the European
Chapter of the Association for Computational
Linguistics, Bergen Norway.
Ben Hermans and Marc van Oostendorp, ed-
itors. 1999. The Derivational Residue in
Phonological Optimality Theory, volume 28
of Linguistik Aktuell/Linguistics Today. John
Benjamins, Amsterdam/Philadelphia.
C. Douglas Johnson. 1972. Formal Aspects
of Phonological Descriptions. Mouton, The
Hague.
Rene Kager. 1999. Optimality Theory. Cam-
bridge UP, Cambridge, UK.
Ronald Kaplan and Martin Kay. 1994. Regular
models of phonological rule systems. Compu-
tational Linguistics, 20(3):331-379.
Fred Karlsson, Atro Voutilainen, Juha Heikkild,
and Arto Anttila. 1995. Constraint Gram-
</reference>
<page confidence="0.999068">
44
</page>
<table confidence="0.999375666666667">
Method Exactness Constraint order
1 2 3 4 5 6 7 8 9
matching exact 1.0 0.9 0.9 0.9 0.8 0.7 1.5 1.3 1.1
counting &lt; 5 0.9 1.7 4.8 1.6 0.5 1.9 10.6 18.0 30.8
counting &lt; 10 2.8 4.7 28.6 4.0 0.5 4.2 83.2 112.7 160.7
counting &lt; 15 6.8 10.1 99.9 8.6 0.5 8.2 336.1 569.1 757.2
</table>
<tableCaption confidence="0.96305">
Table 4: Comparison of the matching approac h and the counting approach for various levels of
exactness. The numbers indicate the CPU-time in seconds required to construct the transducer.
</tableCaption>
<reference confidence="0.99805504">
mar: A Language-Independent Framework
for Parsing Unrestricted Text. Mouton de
Gruyter, Berlin/New York.
Lauri Karttunen, Jean-Pierre Chanod, Gregory
Grefenstette, and Anne Schiller. 1996. Regu-
lar expressions for language engineering. Nat-
ural Language Engineering, 2(4):305-238.
Lauri Karttunen. 1995. The replace operator.
In 33th Annual Meeting of the Association
for Computational Linguistics, M.I.T. Cam-
bridge Mass.
Lauri Karttunen. 1996. Directed replacement.
In 34th Annual Meeting of the Association for
Computational Linguistics, Santa Cruz.
Lauri Karttunen. 1998. The proper treatment
of optimality theory in computational phonol-
ogy. In Finite-state Methods in Natural Lan-
guage Processing, pages 1-12, Ankara.
Andre Kempe and Lauri Karttunen. 1996. Par-
allel replacement in the finite-state calculus.
In Proceedings of the 16th International Con-
ference on Computational Linguistics (COL-
ING), Copenhagen, Denmark.
Charles Kisseberth. 1970. On the functional
unity of phonological rules. Linguistic In-
quiry, 1:291-306.
John McCarthy and Alan Prince. 1995. Faith-
fulness and reduplicative identity. In Jill
Beckman, Laura Walsh Dickey, and Suzanne
Urbanczyk, editors, Papers in Optimality
Theory, pages 249-384. Graduate Linguistic
Student Association, Amherst, Mass. Uni-
versity of Massachusetts Occasional Papers in
Linguistics 18.
Mehryar Mohri and Richard Sproat. 1996. An
efficient compiler for weighted rewrite rules.
In 34th Annual Meeting of the Association for
Computational Linguistics, Santa Cruz.
Kemal Oflazer. 1999. Dependency parsing with
an extended finite state approach. In 37th
Annual Meeting of the Association for Com-
putational Linguistics, pages 254-260.
Alan Prince and Paul Smolensky. 1993. Opti-
mality theory: Constraint interaction in gen-
erative grammar. Technical Report TR-2,
Rutgers University Cognitive Science Center,
New Brunswick, NJ. MIT Press, To Appear.
Emmanuel Roche and Yves Schabes. 1997. In-
troduction. In Emmanuel Roche and Yves
Schabes, editors, Finite-State Language Pro-
cessing. MIT Press, Cambridge, Mass.
Bruce Tesar. 1995. Computational Optimality
Theory. Ph.D. thesis, University of Colorado,
Boulder.
Gertjan van Noord and Dale Gerdemann. 1999.
An extendible regular expression compiler for
finite-state approaches in natural language
processing. In 0. Boldt, H. Juergensen, and
L. Robbins, editors, Workshop on Implement-
ing Automata; WIA99 Pre-Proceedings, Pots-
dam, Germany.
Gertjan van Noord. 1997. FSA Utilities: A
toolbox to manipulate finite-state automata.
In Darrell Raymond, Derick Wood, and
Sheng Yu, editors, Automata Implementa-
tion, pages 87-108. Springer Verlag. Lecture
Notes in Computer Science 1260.
Gertjan van Noord. 1999. FSA6 refer-
ence manual. The FSA Utilities tool-
box is available free of charge un-
der Gnu General Public License at
http://www.let.rug.n1/- vannoord/Fsa/.
Markus Walther. 1996. OT simple - a
construction-kit approach to optimality the-
ory implementation. ROA-152-1096.
</reference>
<page confidence="0.999387">
45
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.168667">
<title confidence="0.999765">Approximation and Exactness in Finite State Optimality Theory</title>
<author confidence="0.999891">Dale Gerdemann Gertjan van_Noord</author>
<affiliation confidence="0.959784">of University of Groningen</affiliation>
<address confidence="0.526368">dg@sfs.nphil.uni-tuebingen.de vannoord@let.rug.n1</address>
<abstract confidence="0.8942402">Previous work (Frank and Satta, 1998; Karttunen, 1998) has shown that Optimality Theory generally is not finite state. A new finite-state treatment of gradient constraints is presented which improves upon the approximation of Karttunen (1998). The method turns out to be exact, and very compact, for the syllabification analysis of Prince and Smolensky (1993).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Meera Blattner</author>
<author>Tom Head</author>
</authors>
<title>Singlevalued a-transducers.</title>
<date>1977</date>
<journal>Journal of Computer and System Sciences,</journal>
<pages>15--3</pages>
<contexts>
<context position="26781" citStr="Blattner and Head, 1977" startWordPosition="4527" endWordPosition="4530"> a fundamental distinction between markedness constraints (referring only to the surface) and faithfulness constraints (referring to both surface and underlying form). With this mark-up convention, faithfulness constraints might be allowed to refer to both symbols marked with 0 and symbols marked with 1. But note that the Fill and Parse constraints in syllabification are also considered to be faithfulness constraints since they correspond to epenthesis and deletion respectively. 41 b []:a 5 b 4 c []:a b c 0 []:a b 1 2 3 c of whether a given transducer is ambiguous is shown to be decidable in (Blattner and Head, 1977); and an efficient algorithm is proposed in (Roche and Schabes, 1997).12 Therefore, in order to check a given transducer T for exactness, it must be the case that for each of the constraints C, is_exact (T , C) is nonambiguous. If a transducer T is not exact, we characterize the quality of the approximation by considering the maximum length of input strings for which T is exact. For example, even though T fails the exactness check, it might be the case that [? , ? &amp;quot; ? -,? -,? -] in fact is exact, indicating that T produces the correct result for all inputs of length &lt; 5. Suppose we are given t</context>
</contexts>
<marker>Blattner, Head, 1977</marker>
<rawString>Meera Blattner and Tom Head. 1977. Singlevalued a-transducers. Journal of Computer and System Sciences, 15(3):328-353.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark T Ellison</author>
</authors>
<title>Phonological derivation in optimality theory.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics (COLING),</booktitle>
<pages>1007--1013</pages>
<location>Kyoto.</location>
<contexts>
<context position="1428" citStr="Ellison, 1994" startWordPosition="203" endWordPosition="205">ed phonological accounts with default constraints on surface forms. While Optimality Theory (OT) has been successful in explaining certain phonological phenomena such as conspiracies (Kisseberth, 1970), it has been less successful for computation. The negative result of Frank and Satta (1998) has shown that in the general case the method of counting constraint violations takes OT beyond the power of regular relations. To handle such constraints, Karttunen (1998) has proposed a finite-state approximation that counts constraint violations up to a predetermined bound. Unlike previous approaches (Ellison, 1994; Walther, 1996), Karttunen&apos;s approach is encoded entirely in the finite state calculus, with no extra-logical procedures for counting constraint violations. In this paper, we will present a new approach that seeks to minimize constraint violations without counting. Rather than counting, our approach employs a filter based on matching constraint violations against violations in alternatively derivable strings. As in Karttunen&apos;s counting approach, our approach uses purely finite state methods without extra-logical procedures. We show that our matching approach is superior to the counting approa</context>
<context position="5750" citStr="Ellison (1994)" startWordPosition="874" endWordPosition="875">which is an identity transducer, filters out those cases not conforming to the leftmost-longest strategy. 21f an expression for a recognizer occurs in a context where a transducer is required, the identity operation will be used implicitly for coercion. Since the generator and tester are both implemented as transducers, they can be composed into a single transducer, which eliminates the inefficiency normally associated with generateand-test algorithms. 2.2 Finite State Optimality Theory The generate-and-test paradigm initially appears to be appropriate for optimality theory. If, as claimed in Ellison (1994), Gen is a regular relation and if each constraint can be implemented as an identity transducer, then optimality theory analyses could be implemented as in fig. 1. Gen Constraintl ConstraintN Figure 1: Optimality Theory as Generate and Test The problem with this simple approach is that in OT, a constraint is allowed to be violated if none of the candidates satisfy that constraint. Karttunen (1998) treats this problem by providing a new operator for lenient composition, which is defined in terms of the auxiliary operation of priority union. In the FSA Utilities calculus, these operations can be</context>
<context position="16980" citStr="Ellison (1994)" startWordPosition="2778" endWordPosition="2779">o] X [p] X [b] X [e] 0 [b] N [o] X [p] In this case, the second output should have been preferred over the other two, because the second output violates &apos;Parse&apos; only once, whereas the other outputs violate &apos;Parse&apos; three times. Karttunen recognizes this problem and proposes to have a sequence of constraints Parse0, Parsel, Parse2 ParseN, where each ParseX constraint requires that candidates not contain more than X unparsed constituents.7 In this case, the resulting transducer only approximates 7This construction is similar to the construction in Frank and Satta (1998), who used a suggestion in Ellison (1994). 38 the OT analysis, because it turns out that for any X there are candidate strings that this transducer fails to handle correctly (assuming that there is no bound on the length of candidate strings). Our notation is somewhat different, but equivalent to the notation used by Karttunen. Instead of a sequence of constraints Cons° ... ConsX, we will write Cands oo Prec :: Cons, which is read as: apply constraint Cons to the candidate set Cands with precision Prec, where &amp;quot;precision&amp;quot; means the predetermined bound on counting. For example, a variant of the syllabify constraint can be defined as: m</context>
</contexts>
<marker>Ellison, 1994</marker>
<rawString>Mark T. Ellison. 1994. Phonological derivation in optimality theory. In Proceedings of the 15th International Conference on Computational Linguistics (COLING), pages 1007-1013, Kyoto.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Frank</author>
<author>Giorgio Satta</author>
</authors>
<title>Optimality theory and the computational complexity of constraint violability.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<pages>24--307</pages>
<contexts>
<context position="1108" citStr="Frank and Satta (1998)" startWordPosition="154" endWordPosition="157">s out to be exact, and very compact, for the syllabification analysis of Prince and Smolensky (1993). 1 Introduction Finite state methods have proven quite successful for encoding rule-based generative phonology (Johnson, 1972; Kaplan and Kay, 1994). Recently, however, Optimality Theory (Prince and Smolensky, 1993) has emphasized phonological accounts with default constraints on surface forms. While Optimality Theory (OT) has been successful in explaining certain phonological phenomena such as conspiracies (Kisseberth, 1970), it has been less successful for computation. The negative result of Frank and Satta (1998) has shown that in the general case the method of counting constraint violations takes OT beyond the power of regular relations. To handle such constraints, Karttunen (1998) has proposed a finite-state approximation that counts constraint violations up to a predetermined bound. Unlike previous approaches (Ellison, 1994; Walther, 1996), Karttunen&apos;s approach is encoded entirely in the finite state calculus, with no extra-logical procedures for counting constraint violations. In this paper, we will present a new approach that seeks to minimize constraint violations without counting. Rather than c</context>
<context position="8010" citStr="Frank and Satta (1998)" startWordPosition="1253" endWordPosition="1256">ty theory. In general, a candidate string can violate a constraint multiple times and candidates that violate the constraint the least number of times need to be preferred. Lenient composition is sufficient to prefer a candidate that violates the constraint 0 times over a candidate that violates the constraint at least once. However, lenient composition cannot distinguish two candidates if the first contains one violation, and the second contains at least two violations. The problem of implementing optimality theory becomes considerably harder when constraint violations need to be counted. As Frank and Satta (1998) have shown, an OT describes a regular relation under the assumptions that Gen is a regular relation, and each of the constraints is a regular relation which maps a candidate string to a natural number (indicating the number of constraint violations in that candidate), where the range of each constraint is finite. If constraints are defined in such a way that there is no bound to the number of constraint violations that can occur in a given string, then the resulting OT may describe a relation that is not regular. A simple example of such an OT (attributed to Markus Hiller) is the OT in which </context>
<context position="16939" citStr="Frank and Satta (1998)" startWordPosition="2769" endWordPosition="2772">[b] N [e] X [b] X [o] X [p] 0 [b] N [e] 0 [b] N [o] X [p] X [b] X [e] 0 [b] N [o] X [p] In this case, the second output should have been preferred over the other two, because the second output violates &apos;Parse&apos; only once, whereas the other outputs violate &apos;Parse&apos; three times. Karttunen recognizes this problem and proposes to have a sequence of constraints Parse0, Parsel, Parse2 ParseN, where each ParseX constraint requires that candidates not contain more than X unparsed constituents.7 In this case, the resulting transducer only approximates 7This construction is similar to the construction in Frank and Satta (1998), who used a suggestion in Ellison (1994). 38 the OT analysis, because it turns out that for any X there are candidate strings that this transducer fails to handle correctly (assuming that there is no bound on the length of candidate strings). Our notation is somewhat different, but equivalent to the notation used by Karttunen. Instead of a sequence of constraints Cons° ... ConsX, we will write Cands oo Prec :: Cons, which is read as: apply constraint Cons to the candidate set Cands with precision Prec, where &amp;quot;precision&amp;quot; means the predetermined bound on counting. For example, a variant of the </context>
<context position="25453" citStr="Frank and Satta (1998)" startWordPosition="4306" endWordPosition="4309">h as correspondence theory (McCarthy and Prince, 1995) are beyond the scope of matching.9 Indeed we have relied on the fact that Gen only adds brackets and does not add or delete anything from the set of input symbols. The filter that we construct needs to compare candidates with alternative candidates generated from the same input. If Gen is allowed to change the input then a way must be found to remember the original input. Correspondence theory is beyond the scope of this paper, however a simple example of an OT where Gen modifies the input is provided by the problem described in V.2 (from Frank and Satta (1998)). Suppose we modify Gen here so that its output includes a representation of the original input. One way to do this would be to adopt the convention that input symbols are marked with a following 0 and output symbols are marked with a following 1. With this convention Gen becomes: macro (gen, x [a,0,b,1])*,(b x [D,O,a,1])*] , C(a x [a,0,a,1])*,(b x [b,0,b,1])*]}) Then the constraint against the symbol a needs to be recast as a constraint against [a, 1] .1° And, whereas above add_violation was previously written to ignore brackets, for this case it will need to ignore output symbols 9Kager (19</context>
</contexts>
<marker>Frank, Satta, 1998</marker>
<rawString>Robert Frank and Giorgio Satta. 1998. Optimality theory and the computational complexity of constraint violability. Computational Linguistics, 24:307-315.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dale Gerdemann</author>
<author>Gertjan van Noord</author>
</authors>
<title>Transducers from rewrite rules with backreferences.</title>
<date>1999</date>
<booktitle>In Ninth Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<location>Bergen</location>
<marker>Gerdemann, van Noord, 1999</marker>
<rawString>Dale Gerdemann and Gertjan van Noord. 1999. Transducers from rewrite rules with backreferences. In Ninth Conference of the European Chapter of the Association for Computational Linguistics, Bergen Norway.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Hermans</author>
<author>Marc van Oostendorp</author>
<author>editors</author>
</authors>
<title>of Linguistik Aktuell/Linguistics Today.</title>
<date>1999</date>
<booktitle>The Derivational Residue in Phonological Optimality Theory,</booktitle>
<volume>28</volume>
<publisher>John Benjamins, Amsterdam/Philadelphia.</publisher>
<marker>Hermans, van Oostendorp, editors, 1999</marker>
<rawString>Ben Hermans and Marc van Oostendorp, editors. 1999. The Derivational Residue in Phonological Optimality Theory, volume 28 of Linguistik Aktuell/Linguistics Today. John Benjamins, Amsterdam/Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Douglas Johnson</author>
</authors>
<title>Formal Aspects of Phonological Descriptions.</title>
<date>1972</date>
<publisher>Mouton, The Hague.</publisher>
<contexts>
<context position="712" citStr="Johnson, 1972" startWordPosition="97" endWordPosition="98">ersity of Tubingen University of Groningen dg@sfs.nphil.uni-tuebingen.de vannoord@let.rug.n1 Abstract Previous work (Frank and Satta, 1998; Karttunen, 1998) has shown that Optimality Theory with gradient constraints generally is not finite state. A new finite-state treatment of gradient constraints is presented which improves upon the approximation of Karttunen (1998). The method turns out to be exact, and very compact, for the syllabification analysis of Prince and Smolensky (1993). 1 Introduction Finite state methods have proven quite successful for encoding rule-based generative phonology (Johnson, 1972; Kaplan and Kay, 1994). Recently, however, Optimality Theory (Prince and Smolensky, 1993) has emphasized phonological accounts with default constraints on surface forms. While Optimality Theory (OT) has been successful in explaining certain phonological phenomena such as conspiracies (Kisseberth, 1970), it has been less successful for computation. The negative result of Frank and Satta (1998) has shown that in the general case the method of counting constraint violations takes OT beyond the power of regular relations. To handle such constraints, Karttunen (1998) has proposed a finite-state ap</context>
</contexts>
<marker>Johnson, 1972</marker>
<rawString>C. Douglas Johnson. 1972. Formal Aspects of Phonological Descriptions. Mouton, The Hague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rene Kager</author>
</authors>
<title>Optimality Theory. Cambridge UP,</title>
<date>1999</date>
<location>Cambridge, UK.</location>
<contexts>
<context position="26056" citStr="Kager (1999)" startWordPosition="4411" endWordPosition="4412">ta (1998)). Suppose we modify Gen here so that its output includes a representation of the original input. One way to do this would be to adopt the convention that input symbols are marked with a following 0 and output symbols are marked with a following 1. With this convention Gen becomes: macro (gen, x [a,0,b,1])*,(b x [D,O,a,1])*] , C(a x [a,0,a,1])*,(b x [b,0,b,1])*]}) Then the constraint against the symbol a needs to be recast as a constraint against [a, 1] .1° And, whereas above add_violation was previously written to ignore brackets, for this case it will need to ignore output symbols 9Kager (1999) compares containment theory and correspondence theory for the syllable structure example. 1°OT makes a fundamental distinction between markedness constraints (referring only to the surface) and faithfulness constraints (referring to both surface and underlying form). With this mark-up convention, faithfulness constraints might be allowed to refer to both symbols marked with 0 and symbols marked with 1. But note that the Fill and Parse constraints in syllabification are also considered to be faithfulness constraints since they correspond to epenthesis and deletion respectively. 41 b []:a 5 b 4</context>
</contexts>
<marker>Kager, 1999</marker>
<rawString>Rene Kager. 1999. Optimality Theory. Cambridge UP, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald Kaplan</author>
<author>Martin Kay</author>
</authors>
<title>Regular models of phonological rule systems.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--3</pages>
<contexts>
<context position="735" citStr="Kaplan and Kay, 1994" startWordPosition="99" endWordPosition="102">gen University of Groningen dg@sfs.nphil.uni-tuebingen.de vannoord@let.rug.n1 Abstract Previous work (Frank and Satta, 1998; Karttunen, 1998) has shown that Optimality Theory with gradient constraints generally is not finite state. A new finite-state treatment of gradient constraints is presented which improves upon the approximation of Karttunen (1998). The method turns out to be exact, and very compact, for the syllabification analysis of Prince and Smolensky (1993). 1 Introduction Finite state methods have proven quite successful for encoding rule-based generative phonology (Johnson, 1972; Kaplan and Kay, 1994). Recently, however, Optimality Theory (Prince and Smolensky, 1993) has emphasized phonological accounts with default constraints on surface forms. While Optimality Theory (OT) has been successful in explaining certain phonological phenomena such as conspiracies (Kisseberth, 1970), it has been less successful for computation. The negative result of Frank and Satta (1998) has shown that in the general case the method of counting constraint violations takes OT beyond the power of regular relations. To handle such constraints, Karttunen (1998) has proposed a finite-state approximation that counts</context>
<context position="2795" citStr="Kaplan and Kay (1994)" startWordPosition="415" endWordPosition="418">counting approach yields only an approximation; yet, the size of the resulting automaton is typically much smaller. In this paper we will illustrate the matching approach and compare it with the counting approach on the basis of the Prince &amp; Smolensky syllable structure example (Prince and Smolensky, 1993; Ellison, 1994; Tesar, 1995), for each of the different constraint orderings identified in Prince &amp; Smolensky. 2 Finite State Phonology 2.1 Finite State Calculus Finite state approaches have proven to be very successful for efficient encoding of phonological rules. In particular, the work of Kaplan and Kay (1994) has provided a compiler from classical generative phonology rewriting rules to finite state transducers. This work has clearly shown how apparently procedural rules can be recast in a declarative, reversible framework. In the process of developing their rule compiler, Kaplan &amp; Kay also developed a high-level finite state calculus. They argue convincingly that this calculus provides an appropriate highlevel approach for expressing regular languages and relations. The alternative conception in term of states and transitions can become unwieldy for all but the simplest cases.&apos; lAlthough in some </context>
</contexts>
<marker>Kaplan, Kay, 1994</marker>
<rawString>Ronald Kaplan and Martin Kay. 1994. Regular models of phonological rule systems. Computational Linguistics, 20(3):331-379.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fred Karlsson</author>
</authors>
<title>Atro Voutilainen, Juha Heikkild, and Arto Anttila.</title>
<date>1995</date>
<location>Berlin/New York.</location>
<marker>Karlsson, 1995</marker>
<rawString>Fred Karlsson, Atro Voutilainen, Juha Heikkild, and Arto Anttila. 1995. Constraint Grammar: A Language-Independent Framework for Parsing Unrestricted Text. Mouton de Gruyter, Berlin/New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
<author>Jean-Pierre Chanod</author>
<author>Gregory Grefenstette</author>
<author>Anne Schiller</author>
</authors>
<title>Regular expressions for language engineering.</title>
<date>1996</date>
<journal>Natural Language Engineering,</journal>
<pages>2--4</pages>
<contexts>
<context position="4140" citStr="Karttunen et al. (1996)" startWordPosition="625" endWordPosition="628">[1 empty string [E1,E2,...,En] concatenation of El...En {} empty language fEl,E2,...,Enl union of El.. .En (E) grouping for op. precedence E* Kleene closure E+ Kleene plus E- optionality El - E2 difference -E complement $ E containment El &amp; E2 intersection any symbol El x E2 cross-product A o B composition domain (E) domain of a transduction range(E) range of a transduction identity(E) identity transduction2 inverse (E) inverse transduction Table 1: Regular expression operators. Kaplan &amp; Kay&apos;s finite state calculus now exists in multiple implementations, the most wellknown of which is that of Karttunen et al. (1996). In this paper, however, we will use the alternative implementation provided by the FSA Utilities (van Noord, 1997; van Noord, 1999; van Noord and Gerdemann, 1999). The FSA Utilities allows the programmer to introduce new regular expression operators of arbitrary complexity. This higher-level interface allows us to express our algorithm more easily. The syntax of the FSA Utilities calculus is summarized in Table 1. The finite state calculus has proven to be a very useful tool for the development of higherlevel finite state operators (Karttunen, 1995; Kempe and Karttunen, 1996; Karttunen, 1996</context>
</contexts>
<marker>Karttunen, Chanod, Grefenstette, Schiller, 1996</marker>
<rawString>Lauri Karttunen, Jean-Pierre Chanod, Gregory Grefenstette, and Anne Schiller. 1996. Regular expressions for language engineering. Natural Language Engineering, 2(4):305-238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
</authors>
<title>The replace operator.</title>
<date>1995</date>
<booktitle>In 33th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>M.I.T. Cambridge Mass.</location>
<contexts>
<context position="4696" citStr="Karttunen, 1995" startWordPosition="718" endWordPosition="719"> most wellknown of which is that of Karttunen et al. (1996). In this paper, however, we will use the alternative implementation provided by the FSA Utilities (van Noord, 1997; van Noord, 1999; van Noord and Gerdemann, 1999). The FSA Utilities allows the programmer to introduce new regular expression operators of arbitrary complexity. This higher-level interface allows us to express our algorithm more easily. The syntax of the FSA Utilities calculus is summarized in Table 1. The finite state calculus has proven to be a very useful tool for the development of higherlevel finite state operators (Karttunen, 1995; Kempe and Karttunen, 1996; Karttunen, 1996; Gerdemann and van Noord, 1999). An interesting feature of most such operators is that they are implemented using a generate-and-test paradigm. Karttunen (1996), for example, introduces an algorithm for a leftmost-longest replacement operator. Somewhat simplified, we may view this algorithm as having two steps. First, the generator freely marks up possible replacement sites. Then the tester, which is an identity transducer, filters out those cases not conforming to the leftmost-longest strategy. 21f an expression for a recognizer occurs in a context</context>
</contexts>
<marker>Karttunen, 1995</marker>
<rawString>Lauri Karttunen. 1995. The replace operator. In 33th Annual Meeting of the Association for Computational Linguistics, M.I.T. Cambridge Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
</authors>
<title>Directed replacement.</title>
<date>1996</date>
<booktitle>In 34th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Santa Cruz.</location>
<contexts>
<context position="4723" citStr="Karttunen, 1996" startWordPosition="722" endWordPosition="723"> that of Karttunen et al. (1996). In this paper, however, we will use the alternative implementation provided by the FSA Utilities (van Noord, 1997; van Noord, 1999; van Noord and Gerdemann, 1999). The FSA Utilities allows the programmer to introduce new regular expression operators of arbitrary complexity. This higher-level interface allows us to express our algorithm more easily. The syntax of the FSA Utilities calculus is summarized in Table 1. The finite state calculus has proven to be a very useful tool for the development of higherlevel finite state operators (Karttunen, 1995; Kempe and Karttunen, 1996; Karttunen, 1996; Gerdemann and van Noord, 1999). An interesting feature of most such operators is that they are implemented using a generate-and-test paradigm. Karttunen (1996), for example, introduces an algorithm for a leftmost-longest replacement operator. Somewhat simplified, we may view this algorithm as having two steps. First, the generator freely marks up possible replacement sites. Then the tester, which is an identity transducer, filters out those cases not conforming to the leftmost-longest strategy. 21f an expression for a recognizer occurs in a context where a transducer is requ</context>
</contexts>
<marker>Karttunen, 1996</marker>
<rawString>Lauri Karttunen. 1996. Directed replacement. In 34th Annual Meeting of the Association for Computational Linguistics, Santa Cruz.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
</authors>
<title>The proper treatment of optimality theory in computational phonology.</title>
<date>1998</date>
<booktitle>In Finite-state Methods in Natural Language Processing,</booktitle>
<pages>1--12</pages>
<location>Ankara.</location>
<contexts>
<context position="1281" citStr="Karttunen (1998)" startWordPosition="183" endWordPosition="184"> rule-based generative phonology (Johnson, 1972; Kaplan and Kay, 1994). Recently, however, Optimality Theory (Prince and Smolensky, 1993) has emphasized phonological accounts with default constraints on surface forms. While Optimality Theory (OT) has been successful in explaining certain phonological phenomena such as conspiracies (Kisseberth, 1970), it has been less successful for computation. The negative result of Frank and Satta (1998) has shown that in the general case the method of counting constraint violations takes OT beyond the power of regular relations. To handle such constraints, Karttunen (1998) has proposed a finite-state approximation that counts constraint violations up to a predetermined bound. Unlike previous approaches (Ellison, 1994; Walther, 1996), Karttunen&apos;s approach is encoded entirely in the finite state calculus, with no extra-logical procedures for counting constraint violations. In this paper, we will present a new approach that seeks to minimize constraint violations without counting. Rather than counting, our approach employs a filter based on matching constraint violations against violations in alternatively derivable strings. As in Karttunen&apos;s counting approach, ou</context>
<context position="6150" citStr="Karttunen (1998)" startWordPosition="944" endWordPosition="945">ency normally associated with generateand-test algorithms. 2.2 Finite State Optimality Theory The generate-and-test paradigm initially appears to be appropriate for optimality theory. If, as claimed in Ellison (1994), Gen is a regular relation and if each constraint can be implemented as an identity transducer, then optimality theory analyses could be implemented as in fig. 1. Gen Constraintl ConstraintN Figure 1: Optimality Theory as Generate and Test The problem with this simple approach is that in OT, a constraint is allowed to be violated if none of the candidates satisfy that constraint. Karttunen (1998) treats this problem by providing a new operator for lenient composition, which is defined in terms of the auxiliary operation of priority union. In the FSA Utilities calculus, these operations can be defined as:3 macro(priority_union(Q,R), fQ, -domain(Q) o RI). macro(lenient_composition(S,C), priority_union(S o C, S)). The effect here is that the lenient composition of S and C is the composition of S and C, except for those elements in the domain of S that are not mapped to anything by S o C. For these elements not in the domain of S o C, the effect is the same as the effect of S alone. We us</context>
<context position="9825" citStr="Karttunen (1998)" startWordPosition="1583" endWordPosition="1584">able structure in the analysis of Prince &amp; Smolensky would require an unbounded amount of counting (since words are of unbounded length), and that therefore such analyses would not be describable as regular relations. An important conclusion of this paper is that, contrary to this potential expectation, such cases in fact can be shown to be regular. 2.3 Syllabification in Finite State OT In order to illustrate our approach, we will start with a finite state implementation of the syllabification analysis as presented in chapter 6 of Prince and Smolensky (1993). This section is heavily based on Karttunen (1998), which the reader should consult for more explanation and examples. The inputs to the syllabification OT are sequences of consonants and vowels. The input will be marked up with onset, nucleus, coda and unparsed brackets; where a syllable is a sequence of an optional onset, followed by a nucleus, followed by an optional coda. The input will be marked up as a sequence of such syllables, where at arbitrary places unparsed material can intervene. The assumption is that an unparsed vowel or consonant is not spelled out phonetically. Onsets, nuclei and codas are also allowed to be empty; the phone</context>
<context position="13969" citStr="Karttunen (1998)" startWordPosition="2276" endWordPosition="2277"> followed by a closing bracket is marked. The fill_ons constraint treats empty onsets in the same way. Finally, the have_ons constraint is somewhat more complex. The constraint requires that each nucleus is preceded by an onset. This is achieved by marking all nuclei first, and then removing those marks where in fact an onset is present. This completes the building blocks we need for an implementation of Prince and Smolensky&apos;s analysis of syllabification. In the following sections, we present two alternative implementations which employ these building blocks. First, we discuss the approach of Karttunen (1998), based on the lenient composition operator. This approach uses a counting approach for multiple constraint violations. We will then present an alternative approach in which constraints eliminate candidates using matching. 3 The Counting Approach In the approach of Karttunen (1998), a candidate set is leniently composed with the set of strings which satisfy a given constraint. Since we have defined a constraint as a transducer which marks candidate strings, we need to alter the definitions somewhat, but the resulting transducers are equivalent to the transducers produced by Karttunen (1998). W</context>
<context position="15752" citStr="Karttunen (1998)" startWordPosition="2566" endWordPosition="2567">gure 3: The definition of Gen macro(Cands oo Constraint, Cands mark_violation(Constraint) lc ($ @) { @ x [] , ? - @}* ) . Here, the set of candidates is first composed with the transducer which marks constraint violations. We then leniently compose the resulting transducer with - ($ @)6, which encodes the requirement that no such marks should be contained in the string. Finally, the remaining marks (if any) are removed from the set of surviving candidates. Using the optimality operator, we can then combine Gen and the various constraints as in the following example (equivalent to figure 14 of Karttunen (1998)): macro(syllabify, gen oo have _ons oo no_coda oo fill_nuc 00 6As explained in footnote 2, this will be coerced into an identity transducer. parse oo fill_ons ). As mentioned above, a candidate string can violate a constraint multiple times and candidates that violate the constraint the least number of times need to be preferred. Lenient composition cannot distinguish two candidates if the first contains one violation, and the second contains at least two violations. For example, the above syllabify transducer will assign three outputs to the input bebop: 0 [b] N [e] X [b] X [o] X [p] 0 [b] N</context>
<context position="24483" citStr="Karttunen (1998)" startWordPosition="4144" endWordPosition="4145">t can be treated exactly with counting precision N, can also be handled by matching with precision less than or equal to N. In the other direction, however, there are constraints, such as those in the Prince and Smolensky syllabification problem, that can only be exactly implemented by the matching approach. For each of the constraint orderings discussed by Prince and Smolensky, it turns out that at most a single step of permutation (i.e. a precision of 1) is required for an exact implementation. We conclude that this OT analysis of syllabification is regular. This improves upon the result of Karttunen (1998). Moreover, the resulting transducers are typically much smaller too. In 0 we present a number of experiments which provide evidence for this observation. 4.3 Discussion Containment. It might be objected that the Prince and Smolensky syllable structure example is a particularly simple containment theory analysis and that other varieties of OT such as correspondence theory (McCarthy and Prince, 1995) are beyond the scope of matching.9 Indeed we have relied on the fact that Gen only adds brackets and does not add or delete anything from the set of input symbols. The filter that we construct need</context>
<context position="29624" citStr="Karttunen (1998)" startWordPosition="5030" endWordPosition="5031">int orderings. These nine &amp;quot;languages&amp;quot; are presented in table 2. In table 3 we compare the size of the resulting automata for the matching approach, as well as for the counting approach, for three different variants which are created in order to guarantee exactness for strings of length &lt; 5, &lt; 10 and &lt; 15 respectively. Finally, the construction of the transducer using the matching approach is typically much faster as well. In table 4 some comparisons are summarized. 6 Conclusion We have presented a new approach for implementing OT which is based on matching rather than the counting approach of Karttunen (1998). The matching approach shares the advantages of the counting approach in that it uses the finite state calculus and avoids off-line sorting and counting of constraint violations. We have shown that the matching approach is superior in that analyses that can only be approximated by counting can be exactly implemented by matching. Moreover, the size of the resulting transducers is significantly smaller. We have shown that the matching approach along with global permutation provides a powerful technique technique for minimizing constraint violations. Although we have only applied this approach t</context>
</contexts>
<marker>Karttunen, 1998</marker>
<rawString>Lauri Karttunen. 1998. The proper treatment of optimality theory in computational phonology. In Finite-state Methods in Natural Language Processing, pages 1-12, Ankara.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andre Kempe</author>
<author>Lauri Karttunen</author>
</authors>
<title>Parallel replacement in the finite-state calculus.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics (COLING),</booktitle>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="4723" citStr="Kempe and Karttunen, 1996" startWordPosition="720" endWordPosition="723">f which is that of Karttunen et al. (1996). In this paper, however, we will use the alternative implementation provided by the FSA Utilities (van Noord, 1997; van Noord, 1999; van Noord and Gerdemann, 1999). The FSA Utilities allows the programmer to introduce new regular expression operators of arbitrary complexity. This higher-level interface allows us to express our algorithm more easily. The syntax of the FSA Utilities calculus is summarized in Table 1. The finite state calculus has proven to be a very useful tool for the development of higherlevel finite state operators (Karttunen, 1995; Kempe and Karttunen, 1996; Karttunen, 1996; Gerdemann and van Noord, 1999). An interesting feature of most such operators is that they are implemented using a generate-and-test paradigm. Karttunen (1996), for example, introduces an algorithm for a leftmost-longest replacement operator. Somewhat simplified, we may view this algorithm as having two steps. First, the generator freely marks up possible replacement sites. Then the tester, which is an identity transducer, filters out those cases not conforming to the leftmost-longest strategy. 21f an expression for a recognizer occurs in a context where a transducer is requ</context>
</contexts>
<marker>Kempe, Karttunen, 1996</marker>
<rawString>Andre Kempe and Lauri Karttunen. 1996. Parallel replacement in the finite-state calculus. In Proceedings of the 16th International Conference on Computational Linguistics (COLING), Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Kisseberth</author>
</authors>
<title>On the functional unity of phonological rules.</title>
<date>1970</date>
<booktitle>Linguistic Inquiry,</booktitle>
<pages>1--291</pages>
<contexts>
<context position="1016" citStr="Kisseberth, 1970" startWordPosition="139" endWordPosition="141">is presented which improves upon the approximation of Karttunen (1998). The method turns out to be exact, and very compact, for the syllabification analysis of Prince and Smolensky (1993). 1 Introduction Finite state methods have proven quite successful for encoding rule-based generative phonology (Johnson, 1972; Kaplan and Kay, 1994). Recently, however, Optimality Theory (Prince and Smolensky, 1993) has emphasized phonological accounts with default constraints on surface forms. While Optimality Theory (OT) has been successful in explaining certain phonological phenomena such as conspiracies (Kisseberth, 1970), it has been less successful for computation. The negative result of Frank and Satta (1998) has shown that in the general case the method of counting constraint violations takes OT beyond the power of regular relations. To handle such constraints, Karttunen (1998) has proposed a finite-state approximation that counts constraint violations up to a predetermined bound. Unlike previous approaches (Ellison, 1994; Walther, 1996), Karttunen&apos;s approach is encoded entirely in the finite state calculus, with no extra-logical procedures for counting constraint violations. In this paper, we will present</context>
</contexts>
<marker>Kisseberth, 1970</marker>
<rawString>Charles Kisseberth. 1970. On the functional unity of phonological rules. Linguistic Inquiry, 1:291-306.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John McCarthy</author>
<author>Alan Prince</author>
</authors>
<title>Faithfulness and reduplicative identity.</title>
<date>1995</date>
<booktitle>Papers in Optimality Theory,</booktitle>
<pages>249--384</pages>
<editor>In Jill Beckman, Laura Walsh Dickey, and Suzanne Urbanczyk, editors,</editor>
<publisher>Graduate Linguistic Student Association,</publisher>
<location>Amherst, Mass.</location>
<contexts>
<context position="24885" citStr="McCarthy and Prince, 1995" startWordPosition="4202" endWordPosition="4205">ut that at most a single step of permutation (i.e. a precision of 1) is required for an exact implementation. We conclude that this OT analysis of syllabification is regular. This improves upon the result of Karttunen (1998). Moreover, the resulting transducers are typically much smaller too. In 0 we present a number of experiments which provide evidence for this observation. 4.3 Discussion Containment. It might be objected that the Prince and Smolensky syllable structure example is a particularly simple containment theory analysis and that other varieties of OT such as correspondence theory (McCarthy and Prince, 1995) are beyond the scope of matching.9 Indeed we have relied on the fact that Gen only adds brackets and does not add or delete anything from the set of input symbols. The filter that we construct needs to compare candidates with alternative candidates generated from the same input. If Gen is allowed to change the input then a way must be found to remember the original input. Correspondence theory is beyond the scope of this paper, however a simple example of an OT where Gen modifies the input is provided by the problem described in V.2 (from Frank and Satta (1998)). Suppose we modify Gen here so</context>
</contexts>
<marker>McCarthy, Prince, 1995</marker>
<rawString>John McCarthy and Alan Prince. 1995. Faithfulness and reduplicative identity. In Jill Beckman, Laura Walsh Dickey, and Suzanne Urbanczyk, editors, Papers in Optimality Theory, pages 249-384. Graduate Linguistic Student Association, Amherst, Mass. University of Massachusetts Occasional Papers in Linguistics 18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
<author>Richard Sproat</author>
</authors>
<title>An efficient compiler for weighted rewrite rules.</title>
<date>1996</date>
<booktitle>In 34th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Santa Cruz.</location>
<contexts>
<context position="3480" citStr="Mohri and Sproat, 1996" startWordPosition="520" endWordPosition="523">writing rules to finite state transducers. This work has clearly shown how apparently procedural rules can be recast in a declarative, reversible framework. In the process of developing their rule compiler, Kaplan &amp; Kay also developed a high-level finite state calculus. They argue convincingly that this calculus provides an appropriate highlevel approach for expressing regular languages and relations. The alternative conception in term of states and transitions can become unwieldy for all but the simplest cases.&apos; lAlthough in some cases such a direct implementation can be much more efficient (Mohri and Sproat, 1996; van Noord and Gerdemann, 1999). 34 [1 empty string [E1,E2,...,En] concatenation of El...En {} empty language fEl,E2,...,Enl union of El.. .En (E) grouping for op. precedence E* Kleene closure E+ Kleene plus E- optionality El - E2 difference -E complement $ E containment El &amp; E2 intersection any symbol El x E2 cross-product A o B composition domain (E) domain of a transduction range(E) range of a transduction identity(E) identity transduction2 inverse (E) inverse transduction Table 1: Regular expression operators. Kaplan &amp; Kay&apos;s finite state calculus now exists in multiple implementations, th</context>
</contexts>
<marker>Mohri, Sproat, 1996</marker>
<rawString>Mehryar Mohri and Richard Sproat. 1996. An efficient compiler for weighted rewrite rules. In 34th Annual Meeting of the Association for Computational Linguistics, Santa Cruz.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kemal Oflazer</author>
</authors>
<title>Dependency parsing with an extended finite state approach.</title>
<date>1999</date>
<booktitle>In 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>254--260</pages>
<marker>Oflazer, 1999</marker>
<rawString>Kemal Oflazer. 1999. Dependency parsing with an extended finite state approach. In 37th Annual Meeting of the Association for Computational Linguistics, pages 254-260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Prince</author>
<author>Paul Smolensky</author>
</authors>
<title>Optimality theory: Constraint interaction in generative grammar.</title>
<date>1993</date>
<tech>Technical Report TR-2,</tech>
<publisher>MIT Press,</publisher>
<institution>Rutgers University Cognitive Science Center,</institution>
<location>New Brunswick, NJ.</location>
<note>To Appear.</note>
<contexts>
<context position="802" citStr="Prince and Smolensky, 1993" startWordPosition="107" endWordPosition="110">noord@let.rug.n1 Abstract Previous work (Frank and Satta, 1998; Karttunen, 1998) has shown that Optimality Theory with gradient constraints generally is not finite state. A new finite-state treatment of gradient constraints is presented which improves upon the approximation of Karttunen (1998). The method turns out to be exact, and very compact, for the syllabification analysis of Prince and Smolensky (1993). 1 Introduction Finite state methods have proven quite successful for encoding rule-based generative phonology (Johnson, 1972; Kaplan and Kay, 1994). Recently, however, Optimality Theory (Prince and Smolensky, 1993) has emphasized phonological accounts with default constraints on surface forms. While Optimality Theory (OT) has been successful in explaining certain phonological phenomena such as conspiracies (Kisseberth, 1970), it has been less successful for computation. The negative result of Frank and Satta (1998) has shown that in the general case the method of counting constraint violations takes OT beyond the power of regular relations. To handle such constraints, Karttunen (1998) has proposed a finite-state approximation that counts constraint violations up to a predetermined bound. Unlike previous</context>
<context position="2480" citStr="Prince and Smolensky, 1993" startWordPosition="366" endWordPosition="370">nen&apos;s counting approach, our approach uses purely finite state methods without extra-logical procedures. We show that our matching approach is superior to the counting approach for both size of resulting automata and closeness of approximation. The matching approach can in fact exactly model many OT analyses where the counting approach yields only an approximation; yet, the size of the resulting automaton is typically much smaller. In this paper we will illustrate the matching approach and compare it with the counting approach on the basis of the Prince &amp; Smolensky syllable structure example (Prince and Smolensky, 1993; Ellison, 1994; Tesar, 1995), for each of the different constraint orderings identified in Prince &amp; Smolensky. 2 Finite State Phonology 2.1 Finite State Calculus Finite state approaches have proven to be very successful for efficient encoding of phonological rules. In particular, the work of Kaplan and Kay (1994) has provided a compiler from classical generative phonology rewriting rules to finite state transducers. This work has clearly shown how apparently procedural rules can be recast in a declarative, reversible framework. In the process of developing their rule compiler, Kaplan &amp; Kay al</context>
<context position="9774" citStr="Prince and Smolensky (1993)" startWordPosition="1573" endWordPosition="1576">guage, one might nevertheless expect that a constraint on syllable structure in the analysis of Prince &amp; Smolensky would require an unbounded amount of counting (since words are of unbounded length), and that therefore such analyses would not be describable as regular relations. An important conclusion of this paper is that, contrary to this potential expectation, such cases in fact can be shown to be regular. 2.3 Syllabification in Finite State OT In order to illustrate our approach, we will start with a finite state implementation of the syllabification analysis as presented in chapter 6 of Prince and Smolensky (1993). This section is heavily based on Karttunen (1998), which the reader should consult for more explanation and examples. The inputs to the syllabification OT are sequences of consonants and vowels. The input will be marked up with onset, nucleus, coda and unparsed brackets; where a syllable is a sequence of an optional onset, followed by a nucleus, followed by an optional coda. The input will be marked up as a sequence of such syllables, where at arbitrary places unparsed material can intervene. The assumption is that an unparsed vowel or consonant is not spelled out phonetically. Onsets, nucle</context>
<context position="12696" citStr="Prince and Smolensky (1993)" startWordPosition="2061" endWordPosition="2064">hecking each constraint the markers will be removed, so that markers for one constraint will not be confused with markers for the next. macro (mark_violat ion (parse ) , replace ( ( [] x macro (mark_violat ion (no_coda) , replace ( ( [] x macro (mark_violat ion (f ill_nuc) , replace ( ( [] x 4An alternative would be to define overparse with a Kleene star in place of the option operator. This would introduce unbounded sequences of empty segments. Even though it can be shown that, with the constraints assumed here, no optimal candidate ever contains two empty segments in a row (proposition 4 of Prince and Smolensky (1993)) it is perhaps interesting to note that defining Gen in this alternative way causes cases of infinite ambiguity for the counting approach but is unproblematic for the matching approach. macro(mark_violation(fill_ons), replace ( ( C] x macro(mark_violation(have_ons), replace ( ( C] x @) , H ,n_br) o replace ( (@ x [] ) , onset , [] ) ) . The parse constraint simply states that a candidate must not contain an unparsed constituent. Thus, we add a mark after each unparsed bracket. The no_coda constraint is similar: each coda bracket will be marked. The fill_nuc constraint is only slightly more co</context>
</contexts>
<marker>Prince, Smolensky, 1993</marker>
<rawString>Alan Prince and Paul Smolensky. 1993. Optimality theory: Constraint interaction in generative grammar. Technical Report TR-2, Rutgers University Cognitive Science Center, New Brunswick, NJ. MIT Press, To Appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emmanuel Roche</author>
<author>Yves Schabes</author>
</authors>
<date>1997</date>
<booktitle>Finite-State Language Processing.</booktitle>
<editor>Introduction. In Emmanuel Roche and Yves Schabes, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Mass.</location>
<contexts>
<context position="26850" citStr="Roche and Schabes, 1997" startWordPosition="4538" endWordPosition="4541">only to the surface) and faithfulness constraints (referring to both surface and underlying form). With this mark-up convention, faithfulness constraints might be allowed to refer to both symbols marked with 0 and symbols marked with 1. But note that the Fill and Parse constraints in syllabification are also considered to be faithfulness constraints since they correspond to epenthesis and deletion respectively. 41 b []:a 5 b 4 c []:a b c 0 []:a b 1 2 3 c of whether a given transducer is ambiguous is shown to be decidable in (Blattner and Head, 1977); and an efficient algorithm is proposed in (Roche and Schabes, 1997).12 Therefore, in order to check a given transducer T for exactness, it must be the case that for each of the constraints C, is_exact (T , C) is nonambiguous. If a transducer T is not exact, we characterize the quality of the approximation by considering the maximum length of input strings for which T is exact. For example, even though T fails the exactness check, it might be the case that [? , ? &amp;quot; ? -,? -,? -] in fact is exact, indicating that T produces the correct result for all inputs of length &lt; 5. Suppose we are given the sequence of constraints: have_ons &gt;&gt; fill_ons &gt;&gt; parse &gt;&gt; fill_nuc</context>
<context position="28415" citStr="Roche and Schabes, 1997" startWordPosition="4821" endWordPosition="4824">ermine the precision of the first, most important, constraint by checking exactness for the transducer gen oo P have_ons for increasing values for P. As soon as we find the minimal P for which the exactness check succeeds (in this case for P=0), we continue by determining the precision required for the next constraint by finding the minimal value of P in: gen oo 0 :: have_ons oo P fill_ons We continue in this way until we have determined precision values for each of the constraints. In this case we obtain a transducer with 8269 states implementing: 12We have adapted the algorithm proposed in (Roche and Schabes, 1997) since it fails to treat certain types of transducer correctly; we intend to provide details somewhere else. gen oo 0 :: have_ons oo 1 :: fill_ons oo 8 :: parse oo 5 :: fill_nuc oo 4 :: no_coda In contrast, using matching an exact implementation is obtained using a precision of 1 for the fill_nuc constraint; all other constraints have a precision of 0. This transducer contains only 28 states. The assumption in OT is that each of the constraints is universal, whereas the constraint order differs from language to language. Prince and Smolensky identify nine interestingly different constraint ord</context>
</contexts>
<marker>Roche, Schabes, 1997</marker>
<rawString>Emmanuel Roche and Yves Schabes. 1997. Introduction. In Emmanuel Roche and Yves Schabes, editors, Finite-State Language Processing. MIT Press, Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruce Tesar</author>
</authors>
<title>Computational Optimality Theory.</title>
<date>1995</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Colorado,</institution>
<location>Boulder.</location>
<contexts>
<context position="2509" citStr="Tesar, 1995" startWordPosition="373" endWordPosition="374">purely finite state methods without extra-logical procedures. We show that our matching approach is superior to the counting approach for both size of resulting automata and closeness of approximation. The matching approach can in fact exactly model many OT analyses where the counting approach yields only an approximation; yet, the size of the resulting automaton is typically much smaller. In this paper we will illustrate the matching approach and compare it with the counting approach on the basis of the Prince &amp; Smolensky syllable structure example (Prince and Smolensky, 1993; Ellison, 1994; Tesar, 1995), for each of the different constraint orderings identified in Prince &amp; Smolensky. 2 Finite State Phonology 2.1 Finite State Calculus Finite state approaches have proven to be very successful for efficient encoding of phonological rules. In particular, the work of Kaplan and Kay (1994) has provided a compiler from classical generative phonology rewriting rules to finite state transducers. This work has clearly shown how apparently procedural rules can be recast in a declarative, reversible framework. In the process of developing their rule compiler, Kaplan &amp; Kay also developed a high-level fin</context>
</contexts>
<marker>Tesar, 1995</marker>
<rawString>Bruce Tesar. 1995. Computational Optimality Theory. Ph.D. thesis, University of Colorado, Boulder.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gertjan van Noord</author>
<author>Dale Gerdemann</author>
</authors>
<title>An extendible regular expression compiler for finite-state approaches in natural language processing.</title>
<date>1999</date>
<journal>In</journal>
<booktitle>Workshop on Implementing Automata; WIA99 Pre-Proceedings,</booktitle>
<volume>0</volume>
<editor>Boldt, H. Juergensen, and L. Robbins, editors,</editor>
<location>Potsdam, Germany.</location>
<marker>van Noord, Gerdemann, 1999</marker>
<rawString>Gertjan van Noord and Dale Gerdemann. 1999. An extendible regular expression compiler for finite-state approaches in natural language processing. In 0. Boldt, H. Juergensen, and L. Robbins, editors, Workshop on Implementing Automata; WIA99 Pre-Proceedings, Potsdam, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gertjan van Noord</author>
</authors>
<title>FSA Utilities: A toolbox to manipulate finite-state automata.</title>
<date>1997</date>
<booktitle>Automata Implementation,</booktitle>
<pages>87--108</pages>
<editor>In Darrell Raymond, Derick Wood, and Sheng Yu, editors,</editor>
<publisher>Springer</publisher>
<marker>van Noord, 1997</marker>
<rawString>Gertjan van Noord. 1997. FSA Utilities: A toolbox to manipulate finite-state automata. In Darrell Raymond, Derick Wood, and Sheng Yu, editors, Automata Implementation, pages 87-108. Springer Verlag. Lecture Notes in Computer Science 1260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gertjan van Noord</author>
</authors>
<title>FSA6 reference manual. The FSA Utilities toolbox is available free of charge under Gnu General Public License at http://www.let.rug.n1/- vannoord/Fsa/.</title>
<date>1999</date>
<marker>van Noord, 1999</marker>
<rawString>Gertjan van Noord. 1999. FSA6 reference manual. The FSA Utilities toolbox is available free of charge under Gnu General Public License at http://www.let.rug.n1/- vannoord/Fsa/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Walther</author>
</authors>
<title>OT simple - a construction-kit approach to optimality theory implementation.</title>
<date>1996</date>
<pages>152--1096</pages>
<contexts>
<context position="1444" citStr="Walther, 1996" startWordPosition="206" endWordPosition="207"> accounts with default constraints on surface forms. While Optimality Theory (OT) has been successful in explaining certain phonological phenomena such as conspiracies (Kisseberth, 1970), it has been less successful for computation. The negative result of Frank and Satta (1998) has shown that in the general case the method of counting constraint violations takes OT beyond the power of regular relations. To handle such constraints, Karttunen (1998) has proposed a finite-state approximation that counts constraint violations up to a predetermined bound. Unlike previous approaches (Ellison, 1994; Walther, 1996), Karttunen&apos;s approach is encoded entirely in the finite state calculus, with no extra-logical procedures for counting constraint violations. In this paper, we will present a new approach that seeks to minimize constraint violations without counting. Rather than counting, our approach employs a filter based on matching constraint violations against violations in alternatively derivable strings. As in Karttunen&apos;s counting approach, our approach uses purely finite state methods without extra-logical procedures. We show that our matching approach is superior to the counting approach for both size</context>
</contexts>
<marker>Walther, 1996</marker>
<rawString>Markus Walther. 1996. OT simple - a construction-kit approach to optimality theory implementation. ROA-152-1096.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>