<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.059741">
<title confidence="0.989638">
CECL: a New Baseline and a Non-Compositional Approach for the Sick
Benchmark
</title>
<author confidence="0.975511">
Yves Bestgen
</author>
<affiliation confidence="0.956028">
Centre for English Corpus Linguistics
</affiliation>
<address confidence="0.566751">
Universit´e catholique de Louvain
</address>
<email confidence="0.992801">
yves.bestgen@uclouvain.be
</email>
<sectionHeader confidence="0.99369" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999845476190476">
This paper describes the two procedures
for determining the semantic similarities
between sentences submitted for the Se-
mEval 2014 Task 1. MeanMaxSim, an
unsupervised procedure, is proposed as a
new baseline to assess the efficiency gain
provided by compositional models. It out-
performs a number of other baselines by
a wide margin. Compared to the word-
overlap baseline, it has the advantage of
taking into account the distributional simi-
larity between words that are also involved
in compositional models. The second
procedure aims at building a predictive
model using as predictors MeanMaxSim
and (transformed) lexical features describ-
ing the differences between each sentence
of a pair. It finished sixth out of 17 teams
in the textual similarity sub-task and sixth
out of 19 in the textual entailment sub-
task.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999928461538461">
The SemEval-2014 Task 1 (Marelli et al., 2014a)
was designed to allow a rigorous evaluation
of compositional distributional semantic models
(CDSMs). CDSMs aim to represent the meaning
of phrases and sentences by composing the dis-
tributional representations of the words they con-
tain (Baroni et al., 2013; Bestgen and Cabiaux,
2002; Erk and Pado, 2008; Grefenstette, 2013;
Kintsch, 2001; Mitchell and Lapata, 2010); they
are thus an extension of Distributional Semantic
Models (DSMs), which approximate the meaning
of words with vectors summarizing their patterns
of co-occurrence in a corpus (Baroni and Lenci,
</bodyText>
<footnote confidence="0.9086375">
This work is licenced under a Creative Commons Attribution
4.0 International License. Page numbers and proceedings
footer are added by the organizers. License details: http:
//creativecommons.org/licenses/by/4.0/
</footnote>
<bodyText confidence="0.999511048780487">
2010; Bestgen et al., 2006; Kintsch, 1998; Lan-
dauer and Dumais, 1997). The dataset for this
task, called SICK (Sentences Involving Composi-
tional Knowledge), consists of almost 10,000 En-
glish sentence pairs annotated for relatedness in
meaning and entailment relation by ten annotators
(Marelli et al., 2014b).
The rationale behind this dataset is that ”un-
derstanding when two sentences have close mean-
ings or entail each other crucially requires a com-
positional semantics step” (Marelli et al., 2014b),
and thus that annotators judge the similarity be-
tween the two sentences of a pair by first build-
ing a mental representation of the meaning of each
sentence and then comparing these two represen-
tations. However, another option was available
to the annotators. They could have paid atten-
tion only to the differences between the sentences,
and assessed the significance of these differences.
Such an approach could have been favored by the
dataset built on the basis of a thousand sentences
modified by a limited number of (often) very
specific transformations, producing sentence pairs
that might seem quite repetitive. An analysis con-
ducted during the training phase of the challenge
brought some support for this hypothesis. The
analysis focused on pairs of sentences in which the
only difference between the two sentences was the
replacement of one content word by another, as in
A man is singing to a girl vs. A man is singing to
a woman, but also in A man is sitting in afield
vs. A man is running in a field. The material
was divided into two parts, 3500 sentence pairs
in the training set and the remaining 1500 in the
test set. First, the average similarity score for each
pair of interchanged words was calculated on the
training set (e.g., in this sample, there were 16 sen-
tence pairs in which woman and man were inter-
changed, and their mean similarity score was 3.6).
Then, these mean scores were used as the similar-
ity scores of the sentence pairs of the test sample
</bodyText>
<page confidence="0.960494">
160
</page>
<note confidence="0.7293285">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 160–165,
Dublin, Ireland, August 23-24, 2014.
</note>
<bodyText confidence="0.999984178571429">
in which the same words were interchanged. The
correlation between the actual scores and the pre-
dicted score was 0.83 (N=92), a value that can be
considered as very high, given the restrictions on
the range in which the predicted similarity scores
vary (min=3.5 and max=5.0; Howell, 2008, pp.
272-273). It is important to note that this observa-
tion does not prove that the participants have not
built a compositional representation, especially as
it only deals with a very specific type of trans-
formation. It nevertheless suggests that analyz-
ing only the differences between the sentences of
a pair could allow the similarity between them to
be effectively estimated.
Following these observations, I opted to try
to determine the degree of efficacy that can be
achieved by two non-compositional approaches.
The first approach, totally unsupervised, is pro-
posed as a new baseline to evaluate the efficacy
gains brought by compositional systems. The sec-
ond, a supervised approach, aims to capitalize on
the properties of the SICK benchmark. While
these approaches have been developed specifically
for the semantic relatedness sub-task, the second
has also been applied to the textual entailment sub-
task. This paper describes the two proposed ap-
proaches, their implementation in the context of
SemEval 2014 Task 1, and the results obtained.
</bodyText>
<sectionHeader confidence="0.993281" genericHeader="method">
2 Proposed Approaches
</sectionHeader>
<subsectionHeader confidence="0.998831">
2.1 A New Baseline for CDSM
</subsectionHeader>
<bodyText confidence="0.99997425">
An evident baseline in the field of CDSM is based
on the proportion of common words in two sen-
tences after the removal (or retaining) of stop
words (Cheung and Penn, 2012). Its main weak-
ness is that it does not take into account the seman-
tic similarities between the words that are com-
bined in the CDSM models. It follows that a com-
positional approach may seem significantly better
than this baseline, even if it is not compositionality
that matters but only the distributional part. At first
glance, this problem can be circumvented by using
as baseline a simple compositional model like the
additive model. The analyses below show that this
model is much less effective for the SILK dataset
than the distributional baseline proposed here.
MeanMaxSim, the proposed baseline, is an ex-
tension of the classic measure based on the pro-
portion of common words, taking advantage of the
distributional similarity but not of compositional-
ity. It corresponds to the mean, calculated using all
the words of the two sentences, of the maximum
semantic similarity between each word in a sen-
tence and all the words of the other sentence. More
formaly, given two sentences a = (a1, ..,an) and
</bodyText>
<equation confidence="0.96059675">
b = (b1, ..bm),
(�i maxj sim(ai,bj)+�j maxi sim(ai,bj))
MMS =
n+m
</equation>
<bodyText confidence="0.9999474">
In this study, the cosine between the word distri-
butional representations was used as the measure
of semantic similarity, but other measures may be
used. The common words of the two sentences
have an important impact on MeanMaxSim, since
their similarity with themselves is equal to the
maximum similarity possible. Their impact would
be much lower if the average similarity between
a word and all the words in the other sentence
were employed instead of the maximum similar-
ity. Several variants of this measure can be used,
for example not taking into account every instance
where a word is repeated in a sentence or not al-
lowing any single word to be the ”most similar” to
several other words.
</bodyText>
<subsectionHeader confidence="0.973088">
2.2 A Non-Compositional Approach Based
on the Differences Between the Sentences
</subsectionHeader>
<bodyText confidence="0.999994074074074">
The main limitation of the first approach in the
context of this challenge is that it is completely
unsupervised and therefore does not take advan-
tage of the training set provided by the task orga-
nizers. The second approach addresses this limi-
tation. It aims to build a predictive model, using
as predictors MeanMaxSim but also lexical fea-
tures describing the differences between each sen-
tence of a pair. For the extraction of these fea-
tures, each pair of sentences of the whole dataset
(training and testing sets) is analyzed to iden-
tify all the lemmas that are not present with the
same frequency in both sentences. Each of these
differences is encoded as a feature whose value
corresponds to the unsigned frequency difference.
This step leads to a two-way contingency table
with sentence pairs as rows and lexical features
as columns. Correspondence Analysis (Blasius
and Greenacre, 1994; Lebart et al., 2000), a sta-
tistical procedure available in many off-the-shelf
software like R (Nenadic and Greenacre, 2006), is
then used to decompose this table into orthogonal
dimensions ordered according to the correspond-
ing part of associations between rows and columns
they explain. Each row receives a coordinate on
these dimensions and these coordinates are used as
predictors of the relatedness scores of the sentence
</bodyText>
<page confidence="0.992695">
161
</page>
<bodyText confidence="0.9999655">
pairs. In this way, not only are the frequencies of
lexical features transformed into continuous pre-
dictors, but these predictors also take into account
the redundancy between the lexical features. Fi-
nally, a predictive model is built on the basis of
the training set by means of multiple linear regres-
sion with stepwise selection of the best predictors.
For the textual entailment sub-task, the same pro-
cedure was used except that the linear regression
was replaced by a linear discriminant analysis.
</bodyText>
<sectionHeader confidence="0.995299" genericHeader="method">
3 Implementation Details
</sectionHeader>
<bodyText confidence="0.999871">
This section describes the steps and additional
resources used to implement the proposed ap-
proaches for the SICK challenge.
</bodyText>
<subsectionHeader confidence="0.999549">
3.1 Preprocessing of the Dataset
</subsectionHeader>
<bodyText confidence="0.999022">
All sentences were tokenized and lemmatized by
the Stanford Parser (de Marneffe et al., 2006;
Toutanova et al., 2003).
</bodyText>
<subsectionHeader confidence="0.997553">
3.2 Distributional Semantics
</subsectionHeader>
<bodyText confidence="0.999912434782609">
Latent Semantic Analysis (LSA), a classical DSM
(Deerwester et al., 1991; Landauer et al., 1998),
was used to gather the semantic similarity between
words from corpora. The starting point of the anal-
ysis is a lexical table containing the frequencies of
every word in each of the text segments included
in the corpus. This table is submitted to a singu-
lar value decomposition, which extracts the most
significant orthogonal dimensions. In this seman-
tic space, the meaning of a word is represented by
a vector and the semantic similarity between two
words is estimated by the cosine between their cor-
responding vectors.
Three corpora were used to estimate these simi-
larities. The first one, the TASA corpus, is com-
posed of excerpts, with an approximate average
length of 250 words, obtained by a random sam-
pling of texts that American students read (Lan-
dauer et al., 1998). The version to which T.K.
Landauer (Institute of Cognitive Science, Univer-
sity of Colorado, Boulder) provided access con-
tains approximately 12 million words.
The second corpus, the BNC (British National
Corpus; Aston and Burnard, 1998) is composed
of approximately 100 million words and covers
many different genres. As the documents included
in this corpus can be of up to 45,000 words, they
were divided into segments of 250 words, the last
segment of a text being deleted if it contained
fewer than 250 words.
The third corpus (WIKI, approximately 600
million words after preprocessing) is derived from
the Wikipedia Foundation database, downloaded
in April 2011. It was built using WikiExtractor.py
by A. Fuschetto. As for the BNC, the texts were
cut into 250-word segments, and any segment of
fewer than 250 words was deleted.
All these corpora were lemmatized by means
of the TreeTagger (Schmid, 1994). In addition, a
series of functional words were removed as well
as all the words whose total frequency in the cor-
pus was lower than 10. The resulting (log-entropy
weighted) matrices of co-occurrences were sub-
mitted to a singular value decomposition (SVD-
PACKC, Berry et al., 1993) and the first 300 eigen-
vectors were retained.
</bodyText>
<subsectionHeader confidence="0.997183">
3.3 Unsupervised Approach Details
</subsectionHeader>
<bodyText confidence="0.999958571428571">
Before estimating the semantic similarity between
a pair of sentences using MeanMaxSim, words (in
their lemmatized forms) considered as stop words
were filtered out. This stop word list (n=82), was
built specifically for the occasion on the basis of
the list of the most frequent words in the training
dataset.
</bodyText>
<subsectionHeader confidence="0.985649">
3.4 Supervised Approach Details
</subsectionHeader>
<bodyText confidence="0.999751">
To identify words not present with the same fre-
quency in both sentences, all the lemmas (includ-
ing those belonging to the stop word list) were
taken into account. The optimization of the param-
eters of the predictive model was performed using
a three-fold cross-validation procedure, with two
thirds of the 5000 sentence pairs for training and
the remaining third for testing. The values tested
by means of an exhaustive search were:
</bodyText>
<listItem confidence="0.997459666666667">
• Minimum threshold frequency of the lexical
features in the complete dataset: from 10 to
70 by step of 10.
• Number of dimensions retained from the CA:
from 10 to the total number of dimensions
available by step of 10.
• P-value threshold to enter or remove predic-
tors from the model: 0.01 and from 0.05 to
0.45 by step of 0.05.
</listItem>
<bodyText confidence="0.9990235">
This cross-validation procedure was repeated
five times, each time changing the random distri-
bution of sentence pairs in the samples. The fi-
nal values of the three parameters were selected
</bodyText>
<page confidence="0.995843">
162
</page>
<bodyText confidence="0.999966142857143">
on the basis of the average correlation calculated
over all replications. For the relatedness sub-task,
the selected values were a minimum threshold fre-
quency of 40, 140 dimensions and a p-value of
0.20. For the entailment sub-task, they were a
minimum threshold frequency of 60, 100 dimen-
sions and a p-value of 0.25.
</bodyText>
<sectionHeader confidence="0.999984" genericHeader="evaluation">
4 Results
</sectionHeader>
<subsectionHeader confidence="0.999679">
4.1 Semantic Relatedness Sub-Task
</subsectionHeader>
<bodyText confidence="0.9983131">
The main measure of performance selected by the
task organizers was the Pearson correlation, calcu-
lated on the test set (4927 sentence pairs), between
the mean values of similarity according to the an-
notators and the values predicted by the automatic
procedures.
Unsupervised Approach: MeanMaxSim. Ta-
ble 1 shows the results obtained by MeanMaxSim,
based on the three corpora, and by three other
baselines:
</bodyText>
<listItem confidence="0.999308727272727">
• WO: The word-overlap baseline proposed by
the organizers of the task, computed as the
number of distinct tokens in both sentences
divided by the number of distinct tokens in
the longer sentence, optimizing the number
of the most frequent words stripped off the
sentences on the test set.
• SWL: The word-overlap baseline computed
as in WO but using lemmas instead of words
and the stop words list.
• ADD: The simple additive compositional
</listItem>
<bodyText confidence="0.694504666666667">
model, in which each sentence is represented
by the sum of the vectors of the lemmas that
compose it (stripping off stop words and us-
ing the best performing corpus) and the simi-
larity is the cosine between these two vectors
(Bestgen et al., 2010; Guevara, 2011) .
</bodyText>
<table confidence="0.9996575">
MeanMaxSim r Baseline r
TASA 0.696 WO 0.627
BNC 0.698 SWL 0.613
WIKI 0.696 ADD 0.500
</table>
<tableCaption confidence="0.841251">
Table 1: Pearson’s correlation for MeanMaxSim
and several other baselines on the test set.
</tableCaption>
<bodyText confidence="0.997209913043479">
MeanMaxSim produces almost identical results
regardless of the corpus used. The lack of differ-
ence between the three corpora was unexpected.
It could be related to the type of vocabulary used
in the SICK materials, seemingly mostly frequent
and concrete words whose use could be relatively
similar in the three corpora. MeanMaxSim per-
formance is clearly superior to all other baselines;
among these, the additive model is the worst. This
result is important because it shows that this com-
positional model is not, for the SICK benchmark,
the most interesting baseline to assess composi-
tional approaches. In the context of the best per-
formance of the other teams, MeanMaxSim is
(hopefully) well below the most effective proce-
dures, which reached correlations above 0.80.
Supervised Approach. The supervised ap-
proach resulted in a correlation of 0.78044, a value
well above all baselines reported above. This cor-
relation ranked the procedure sixth out of 17, tied
with another team (0.78019). The three best teams
scored significantly higher, with correlations be-
tween 0.826 and 0.828.
</bodyText>
<subsectionHeader confidence="0.997861">
4.2 Textual Entailment Sub-Task
</subsectionHeader>
<bodyText confidence="0.9999576">
Only the supervised approach was used for this
sub-task. The proposed procedure achieved an ac-
curacy of 79.998%, which ranks it sixth again, but
out of 19 teams, still at a respectable distance from
the best performance (84.575%).
</bodyText>
<sectionHeader confidence="0.994528" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999939333333333">
The main contribution of this research seems to be
the proposal of MeanMaxSim as baseline for eval-
uating CDSM. It outperforms a number of other
baselines by a wide margin and is very easy to
calculate. Compared to the word-overlap base-
line, it has the advantage of taking into account
the distributional similarity between words that are
also involved in compositional models. The su-
pervised approach proposed achieved an accept-
able result (sixth out of 17) and it could easily be
improved, for example by replacing standard lin-
ear regression by a procedure less sensitive to the
risk of overfit due to the large number of predictors
such as Partial Least Squares regression (Guevara,
2011). However, since this approach is not com-
positional and its efficacy (compared to others) is
limited, it is not obvious that trying to improve it
would be very useful.
</bodyText>
<sectionHeader confidence="0.999056" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<reference confidence="0.7176355">
Yves Bestgen is Research Associate of the Belgian
Fund for Scientific Research (F.R.S-FNRS).
</reference>
<page confidence="0.999387">
163
</page>
<sectionHeader confidence="0.985525" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998792546296296">
Aston Guy, and Burnard Lou (1998). The BNC Hand-
book: Exploring the British National Corpus with
SARA. Edinburgh: Edinburgh University Press.
Baroni, Marco, and Lenci Alessandro (2010) Distri-
butional memory: A general framework for corpus-
based semantics, Computational Linguistics, 36,
673-721.
Baroni, Marco, Bernardi, Raffaella, and Zamparelli,
Roberto (2013). Frege in space: a program for com-
positional distributional semantics. In Annie Zae-
nen, Bonnie Webber and Martha Palmer. Linguistic
Issues in Language Technologies (LiLT), CSLI Pub-
lications.
Berry, Michael, Do, Theresa, O’Brien, Gavin, Krishna,
Vijay, and Varadhan, Sowmini (1993). Svdpackc:
Version 1.0 user’s guide, Technical Report Num-
ber CS-93-194, University of Tennessee, Knoxville,
TN.
Bestgen, Yves, and Cabiaux, Anne-Franoise (2002).
L’analyse s´emantique latente et l’identification des
m´etaphores. InActes de la 9me Conf´erence annuelle
sur le traitement automatique des langues naturelles
(pp. 331-337). Nancy: INRIA.
Bestgen, Yves, Degand, Liesbeth, and Spooren,
Wilbert (2006). Towards automatic determination
of the semantics of connectives in large newspaper
corpora. Discourse Processes, 41, 175-193.
Bestgen, Yves, Lories, Guy, and Thewissen, Jennifer
(2010). Using latent semantic analysis to measure
coherence in essays by foreign language learners?
In Sergio Bolasco, Isabella Chiari and Luca Giu-
liano (Eds.), Proceedings of 10th International Con-
ference on Statistical Analysis of Textual Data, 385-
395. Roma: LED.
Blasius, Jorg, and Greenacre, Michael (1994). Com-
putation of Correspondence Analysis. In Michael
Greenacre and Jorg Blasius (eds.), Correspondence
Analysis in the Social Sciences, pp. 53-75. Academic
Press, London.
Cheung, Jackie, and Penn, Gerald (2012). Evaluating
distributional models of semantics for syntactically
invariant inference. In Conference of the European
Chapter of the Association for Computational Lin-
guistics, 33-43, Avignon, France.
de Marneffe, Marie-Catherine, MacCartney, Bill, and
Manning, Christopher (2006). Generating Typed
Dependency Parses from Phrase Structure Parses. In
Proceedings of the 5th Edition of the Language Re-
sources and Evaluation Conference. Genoa, Italy.
Deerwester, Scott, Dumais, Susan, Furnas, George,
Landauer, Thomas and Harshman, Richard (1990).
Indexing by latent semantic analysis. Journal of the
American Society for Information Science, 41, 391-
407.
Erk, Katrin, and Pado, Sebastian (2008). A structured
vector space model for word meaning in context. In
Proceedings of the 2008 Conference on Empirical
Methods in Natural Language Processing, 897-906,
Honolulu, Hawaii.
Grefenstette, Edward (2013). Category-theoretic
quantitative compositional distributional models of
natural language semantics. PhD Thesis, Univer-
sity of Oxford, UK.
Guevara, Emiliano (2011). Computing semantic com-
positionality in distributional semantics. In Pro-
ceedings of the Ninth International Conference on
Computational Semantics, 135-144, Oxford, UK.
Howell, David (2008). M´ethodes statistiques en sci-
ences humaines. Bruxelles, Belgique: De Boeck
Universit´e.
Kintsch, Walter (1998). Comprehension: A
Paradigme for Cognition. New York: Cambridge
University Press.
Kintsch, Walter (2001). Predication. Cognitive Sci-
ence, 25(2), 173-202.
Landauer, Thomas, and Dumais, Susan, (1997). A so-
lution to Plato’s problem: The latent semantic anal-
ysis theory of acquisition, induction and representa-
tion of knowledge. Psychological Review, 104(2),
211-240.
Landauer, Thomas, Foltz, Peter, and Laham, Darrell
(1998). An introduction to latent semantic analysis,
Discourse Processes, 25, 259-284.
Lebart, Ludovic, Piron Marie, et Morineau Alain
(2000). Statistique exploratoire multidimension-
nelle (3e ´edition), Paris: Dunod.
Marelli, Marco, Bentivogli, Luisa, Baroni, Marco,
Bernardi, Raffaella, Menini, Stefano, and Zampar-
elli, Roberto (2014a). Semeval-2014 task 1: Evalu-
ation of compositional distributional semantic mod-
els on full sentences through semantic relatedness
and textual entailment. In Proceedings of SemEval-
2014: Semantic Evaluation Exercises. Dublin, Ire-
land.
Marelli, Marco, Menini, Stefano, Baroni, Marco, Ben-
tivogli, Luisa, Bernardi, Raffaella, and Zamparelli,
Roberto (2014b). A SICK cure for the evaluation
of compositional distributional semantic models. In
Proceedings of the 9th Edition of the Language Re-
sources and Evaluation Conference, Reykjavik, Ice-
land.
Mitchell, Jeff, and Lapata, Mirella (2010). Composi-
tion in distributional models of semantics. Cognitive
Science, 34, 1388-1429.
Nenadic, Oleg, and Greenacre, Michael (2007). Cor-
respondence analysis in R, with two- and three-
dimensional graphics: the CA package, Journal of
Statistical Software, 20(3), 1-13.
</reference>
<page confidence="0.984978">
164
</page>
<reference confidence="0.998578090909091">
Schmid, Helmut (1994). Probabilistic part-of-speech
tagging using decision trees. In Proceedings of the
1994 International Conference on New Methods in
Language Processing, 44-49, Manchester, UK.
Toutanova, Kristina, Klein, Dan, Manning, Christo-
pher, and Singer, Yoram (2003). Feature-rich part-
of-speech tagging with a cyclic dependency net-
work. In Proceddings of the Human Language Tech-
nology Conference of the North American Chap-
ter of the Association for Computational Linguistic
2003, 252-259, Edmonton, Canada.
</reference>
<page confidence="0.998741">
165
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.468263">
<title confidence="0.9680365">CECL: a New Baseline and a Non-Compositional Approach for the Sick Benchmark</title>
<author confidence="0.884357">Yves</author>
<affiliation confidence="0.867204">Centre for English Corpus Universit´e catholique de</affiliation>
<email confidence="0.723289">yves.bestgen@uclouvain.be</email>
<abstract confidence="0.991219590909091">This paper describes the two procedures for determining the semantic similarities between sentences submitted for the SemEval 2014 Task 1. MeanMaxSim, an unsupervised procedure, is proposed as a new baseline to assess the efficiency gain provided by compositional models. It outperforms a number of other baselines by a wide margin. Compared to the wordoverlap baseline, it has the advantage of taking into account the distributional similarity between words that are also involved in compositional models. The second procedure aims at building a predictive model using as predictors MeanMaxSim and (transformed) lexical features describing the differences between each sentence of a pair. It finished sixth out of 17 teams in the textual similarity sub-task and sixth out of 19 in the textual entailment subtask.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Yves</author>
</authors>
<title>Bestgen is Research Associate of the Belgian Fund for Scientific Research (F.R.S-FNRS).</title>
<marker>Yves, </marker>
<rawString>Yves Bestgen is Research Associate of the Belgian Fund for Scientific Research (F.R.S-FNRS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aston Guy</author>
<author>Burnard Lou</author>
</authors>
<date>1998</date>
<booktitle>The BNC Handbook: Exploring the British National Corpus with SARA. Edinburgh:</booktitle>
<publisher>Edinburgh University Press.</publisher>
<marker>Guy, Lou, 1998</marker>
<rawString>Aston Guy, and Burnard Lou (1998). The BNC Handbook: Exploring the British National Corpus with SARA. Edinburgh: Edinburgh University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Lenci Alessandro</author>
</authors>
<title>Distributional memory: A general framework for corpusbased semantics,</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<pages>673--721</pages>
<marker>Baroni, Alessandro, 2010</marker>
<rawString>Baroni, Marco, and Lenci Alessandro (2010) Distributional memory: A general framework for corpusbased semantics, Computational Linguistics, 36, 673-721.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Raffaella Bernardi</author>
<author>Roberto Zamparelli</author>
</authors>
<title>Frege in space: a program for compositional distributional semantics.</title>
<date>2013</date>
<journal>In Annie Zaenen, Bonnie Webber</journal>
<publisher>CSLI Publications.</publisher>
<contexts>
<context position="1329" citStr="Baroni et al., 2013" startWordPosition="199" endWordPosition="202">cond procedure aims at building a predictive model using as predictors MeanMaxSim and (transformed) lexical features describing the differences between each sentence of a pair. It finished sixth out of 17 teams in the textual similarity sub-task and sixth out of 19 in the textual entailment subtask. 1 Introduction The SemEval-2014 Task 1 (Marelli et al., 2014a) was designed to allow a rigorous evaluation of compositional distributional semantic models (CDSMs). CDSMs aim to represent the meaning of phrases and sentences by composing the distributional representations of the words they contain (Baroni et al., 2013; Bestgen and Cabiaux, 2002; Erk and Pado, 2008; Grefenstette, 2013; Kintsch, 2001; Mitchell and Lapata, 2010); they are thus an extension of Distributional Semantic Models (DSMs), which approximate the meaning of words with vectors summarizing their patterns of co-occurrence in a corpus (Baroni and Lenci, This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http: //creativecommons.org/licenses/by/4.0/ 2010; Bestgen et al., 2006; Kintsch, 1998; Landauer and Dumais, 1997). The data</context>
</contexts>
<marker>Baroni, Bernardi, Zamparelli, 2013</marker>
<rawString>Baroni, Marco, Bernardi, Raffaella, and Zamparelli, Roberto (2013). Frege in space: a program for compositional distributional semantics. In Annie Zaenen, Bonnie Webber and Martha Palmer. Linguistic Issues in Language Technologies (LiLT), CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Berry</author>
<author>Theresa Do</author>
<author>Gavin O’Brien</author>
<author>Vijay Krishna</author>
<author>Sowmini Varadhan</author>
</authors>
<title>Svdpackc: Version 1.0 user’s guide,</title>
<date>1993</date>
<tech>Technical Report Number CS-93-194,</tech>
<institution>University of Tennessee,</institution>
<location>Knoxville, TN.</location>
<marker>Berry, Do, O’Brien, Krishna, Varadhan, 1993</marker>
<rawString>Berry, Michael, Do, Theresa, O’Brien, Gavin, Krishna, Vijay, and Varadhan, Sowmini (1993). Svdpackc: Version 1.0 user’s guide, Technical Report Number CS-93-194, University of Tennessee, Knoxville, TN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Bestgen</author>
<author>Anne-Franoise Cabiaux</author>
</authors>
<title>L’analyse s´emantique latente et l’identification des m´etaphores.</title>
<date>2002</date>
<booktitle>InActes de la 9me Conf´erence annuelle sur le traitement automatique des langues naturelles</booktitle>
<pages>331--337</pages>
<publisher>INRIA.</publisher>
<location>Nancy:</location>
<contexts>
<context position="1356" citStr="Bestgen and Cabiaux, 2002" startWordPosition="203" endWordPosition="206">t building a predictive model using as predictors MeanMaxSim and (transformed) lexical features describing the differences between each sentence of a pair. It finished sixth out of 17 teams in the textual similarity sub-task and sixth out of 19 in the textual entailment subtask. 1 Introduction The SemEval-2014 Task 1 (Marelli et al., 2014a) was designed to allow a rigorous evaluation of compositional distributional semantic models (CDSMs). CDSMs aim to represent the meaning of phrases and sentences by composing the distributional representations of the words they contain (Baroni et al., 2013; Bestgen and Cabiaux, 2002; Erk and Pado, 2008; Grefenstette, 2013; Kintsch, 2001; Mitchell and Lapata, 2010); they are thus an extension of Distributional Semantic Models (DSMs), which approximate the meaning of words with vectors summarizing their patterns of co-occurrence in a corpus (Baroni and Lenci, This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http: //creativecommons.org/licenses/by/4.0/ 2010; Bestgen et al., 2006; Kintsch, 1998; Landauer and Dumais, 1997). The dataset for this task, called S</context>
</contexts>
<marker>Bestgen, Cabiaux, 2002</marker>
<rawString>Bestgen, Yves, and Cabiaux, Anne-Franoise (2002). L’analyse s´emantique latente et l’identification des m´etaphores. InActes de la 9me Conf´erence annuelle sur le traitement automatique des langues naturelles (pp. 331-337). Nancy: INRIA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Bestgen</author>
<author>Liesbeth Degand</author>
<author>Wilbert Spooren</author>
</authors>
<title>Towards automatic determination of the semantics of connectives in large newspaper corpora.</title>
<date>2006</date>
<booktitle>Discourse Processes,</booktitle>
<volume>41</volume>
<pages>175--193</pages>
<contexts>
<context position="1876" citStr="Bestgen et al., 2006" startWordPosition="275" endWordPosition="278">ributional representations of the words they contain (Baroni et al., 2013; Bestgen and Cabiaux, 2002; Erk and Pado, 2008; Grefenstette, 2013; Kintsch, 2001; Mitchell and Lapata, 2010); they are thus an extension of Distributional Semantic Models (DSMs), which approximate the meaning of words with vectors summarizing their patterns of co-occurrence in a corpus (Baroni and Lenci, This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http: //creativecommons.org/licenses/by/4.0/ 2010; Bestgen et al., 2006; Kintsch, 1998; Landauer and Dumais, 1997). The dataset for this task, called SICK (Sentences Involving Compositional Knowledge), consists of almost 10,000 English sentence pairs annotated for relatedness in meaning and entailment relation by ten annotators (Marelli et al., 2014b). The rationale behind this dataset is that ”understanding when two sentences have close meanings or entail each other crucially requires a compositional semantics step” (Marelli et al., 2014b), and thus that annotators judge the similarity between the two sentences of a pair by first building a mental representation</context>
</contexts>
<marker>Bestgen, Degand, Spooren, 2006</marker>
<rawString>Bestgen, Yves, Degand, Liesbeth, and Spooren, Wilbert (2006). Towards automatic determination of the semantics of connectives in large newspaper corpora. Discourse Processes, 41, 175-193.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Bestgen</author>
<author>Guy Lories</author>
<author>Jennifer Thewissen</author>
</authors>
<title>Using latent semantic analysis to measure coherence in essays by foreign language learners?</title>
<date>2010</date>
<booktitle>In Sergio Bolasco, Isabella Chiari and Luca Giuliano (Eds.), Proceedings of 10th International Conference on Statistical Analysis of Textual Data,</booktitle>
<pages>385--395</pages>
<location>Roma: LED.</location>
<contexts>
<context position="14426" citStr="Bestgen et al., 2010" startWordPosition="2351" endWordPosition="2354">task, computed as the number of distinct tokens in both sentences divided by the number of distinct tokens in the longer sentence, optimizing the number of the most frequent words stripped off the sentences on the test set. • SWL: The word-overlap baseline computed as in WO but using lemmas instead of words and the stop words list. • ADD: The simple additive compositional model, in which each sentence is represented by the sum of the vectors of the lemmas that compose it (stripping off stop words and using the best performing corpus) and the similarity is the cosine between these two vectors (Bestgen et al., 2010; Guevara, 2011) . MeanMaxSim r Baseline r TASA 0.696 WO 0.627 BNC 0.698 SWL 0.613 WIKI 0.696 ADD 0.500 Table 1: Pearson’s correlation for MeanMaxSim and several other baselines on the test set. MeanMaxSim produces almost identical results regardless of the corpus used. The lack of difference between the three corpora was unexpected. It could be related to the type of vocabulary used in the SICK materials, seemingly mostly frequent and concrete words whose use could be relatively similar in the three corpora. MeanMaxSim performance is clearly superior to all other baselines; among these, the a</context>
</contexts>
<marker>Bestgen, Lories, Thewissen, 2010</marker>
<rawString>Bestgen, Yves, Lories, Guy, and Thewissen, Jennifer (2010). Using latent semantic analysis to measure coherence in essays by foreign language learners? In Sergio Bolasco, Isabella Chiari and Luca Giuliano (Eds.), Proceedings of 10th International Conference on Statistical Analysis of Textual Data, 385-395. Roma: LED.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorg Blasius</author>
<author>Michael Greenacre</author>
</authors>
<title>Computation of Correspondence Analysis.</title>
<date>1994</date>
<booktitle>In Michael Greenacre and Jorg Blasius (eds.), Correspondence Analysis in the Social Sciences,</booktitle>
<pages>53--75</pages>
<publisher>Academic Press,</publisher>
<location>London.</location>
<contexts>
<context position="8269" citStr="Blasius and Greenacre, 1994" startWordPosition="1339" endWordPosition="1342">uild a predictive model, using as predictors MeanMaxSim but also lexical features describing the differences between each sentence of a pair. For the extraction of these features, each pair of sentences of the whole dataset (training and testing sets) is analyzed to identify all the lemmas that are not present with the same frequency in both sentences. Each of these differences is encoded as a feature whose value corresponds to the unsigned frequency difference. This step leads to a two-way contingency table with sentence pairs as rows and lexical features as columns. Correspondence Analysis (Blasius and Greenacre, 1994; Lebart et al., 2000), a statistical procedure available in many off-the-shelf software like R (Nenadic and Greenacre, 2006), is then used to decompose this table into orthogonal dimensions ordered according to the corresponding part of associations between rows and columns they explain. Each row receives a coordinate on these dimensions and these coordinates are used as predictors of the relatedness scores of the sentence 161 pairs. In this way, not only are the frequencies of lexical features transformed into continuous predictors, but these predictors also take into account the redundancy </context>
</contexts>
<marker>Blasius, Greenacre, 1994</marker>
<rawString>Blasius, Jorg, and Greenacre, Michael (1994). Computation of Correspondence Analysis. In Michael Greenacre and Jorg Blasius (eds.), Correspondence Analysis in the Social Sciences, pp. 53-75. Academic Press, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jackie Cheung</author>
<author>Gerald Penn</author>
</authors>
<title>Evaluating distributional models of semantics for syntactically invariant inference.</title>
<date>2012</date>
<booktitle>In Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>33--43</pages>
<location>Avignon, France.</location>
<contexts>
<context position="5530" citStr="Cheung and Penn, 2012" startWordPosition="879" endWordPosition="882">stems. The second, a supervised approach, aims to capitalize on the properties of the SICK benchmark. While these approaches have been developed specifically for the semantic relatedness sub-task, the second has also been applied to the textual entailment subtask. This paper describes the two proposed approaches, their implementation in the context of SemEval 2014 Task 1, and the results obtained. 2 Proposed Approaches 2.1 A New Baseline for CDSM An evident baseline in the field of CDSM is based on the proportion of common words in two sentences after the removal (or retaining) of stop words (Cheung and Penn, 2012). Its main weakness is that it does not take into account the semantic similarities between the words that are combined in the CDSM models. It follows that a compositional approach may seem significantly better than this baseline, even if it is not compositionality that matters but only the distributional part. At first glance, this problem can be circumvented by using as baseline a simple compositional model like the additive model. The analyses below show that this model is much less effective for the SILK dataset than the distributional baseline proposed here. MeanMaxSim, the proposed basel</context>
</contexts>
<marker>Cheung, Penn, 2012</marker>
<rawString>Cheung, Jackie, and Penn, Gerald (2012). Evaluating distributional models of semantics for syntactically invariant inference. In Conference of the European Chapter of the Association for Computational Linguistics, 33-43, Avignon, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher Manning</author>
</authors>
<title>Generating Typed Dependency Parses from Phrase Structure Parses.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th Edition of the Language Resources and Evaluation Conference.</booktitle>
<location>Genoa, Italy.</location>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>de Marneffe, Marie-Catherine, MacCartney, Bill, and Manning, Christopher (2006). Generating Typed Dependency Parses from Phrase Structure Parses. In Proceedings of the 5th Edition of the Language Resources and Evaluation Conference. Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Deerwester</author>
<author>Susan Dumais</author>
<author>George Furnas</author>
<author>Thomas Landauer</author>
<author>Richard Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of the American Society for Information Science,</journal>
<volume>41</volume>
<pages>391--407</pages>
<marker>Deerwester, Dumais, Furnas, Landauer, Harshman, 1990</marker>
<rawString>Deerwester, Scott, Dumais, Susan, Furnas, George, Landauer, Thomas and Harshman, Richard (1990). Indexing by latent semantic analysis. Journal of the American Society for Information Science, 41, 391-407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
<author>Sebastian Pado</author>
</authors>
<title>A structured vector space model for word meaning in context.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>897--906</pages>
<location>Honolulu, Hawaii.</location>
<contexts>
<context position="1376" citStr="Erk and Pado, 2008" startWordPosition="207" endWordPosition="210">el using as predictors MeanMaxSim and (transformed) lexical features describing the differences between each sentence of a pair. It finished sixth out of 17 teams in the textual similarity sub-task and sixth out of 19 in the textual entailment subtask. 1 Introduction The SemEval-2014 Task 1 (Marelli et al., 2014a) was designed to allow a rigorous evaluation of compositional distributional semantic models (CDSMs). CDSMs aim to represent the meaning of phrases and sentences by composing the distributional representations of the words they contain (Baroni et al., 2013; Bestgen and Cabiaux, 2002; Erk and Pado, 2008; Grefenstette, 2013; Kintsch, 2001; Mitchell and Lapata, 2010); they are thus an extension of Distributional Semantic Models (DSMs), which approximate the meaning of words with vectors summarizing their patterns of co-occurrence in a corpus (Baroni and Lenci, This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http: //creativecommons.org/licenses/by/4.0/ 2010; Bestgen et al., 2006; Kintsch, 1998; Landauer and Dumais, 1997). The dataset for this task, called SICK (Sentences Invol</context>
</contexts>
<marker>Erk, Pado, 2008</marker>
<rawString>Erk, Katrin, and Pado, Sebastian (2008). A structured vector space model for word meaning in context. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, 897-906, Honolulu, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Grefenstette</author>
</authors>
<title>Category-theoretic quantitative compositional distributional models of natural language semantics.</title>
<date>2013</date>
<tech>PhD Thesis,</tech>
<institution>University of Oxford, UK.</institution>
<contexts>
<context position="1396" citStr="Grefenstette, 2013" startWordPosition="211" endWordPosition="212">rs MeanMaxSim and (transformed) lexical features describing the differences between each sentence of a pair. It finished sixth out of 17 teams in the textual similarity sub-task and sixth out of 19 in the textual entailment subtask. 1 Introduction The SemEval-2014 Task 1 (Marelli et al., 2014a) was designed to allow a rigorous evaluation of compositional distributional semantic models (CDSMs). CDSMs aim to represent the meaning of phrases and sentences by composing the distributional representations of the words they contain (Baroni et al., 2013; Bestgen and Cabiaux, 2002; Erk and Pado, 2008; Grefenstette, 2013; Kintsch, 2001; Mitchell and Lapata, 2010); they are thus an extension of Distributional Semantic Models (DSMs), which approximate the meaning of words with vectors summarizing their patterns of co-occurrence in a corpus (Baroni and Lenci, This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http: //creativecommons.org/licenses/by/4.0/ 2010; Bestgen et al., 2006; Kintsch, 1998; Landauer and Dumais, 1997). The dataset for this task, called SICK (Sentences Involving Compositional K</context>
</contexts>
<marker>Grefenstette, 2013</marker>
<rawString>Grefenstette, Edward (2013). Category-theoretic quantitative compositional distributional models of natural language semantics. PhD Thesis, University of Oxford, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emiliano Guevara</author>
</authors>
<title>Computing semantic compositionality in distributional semantics.</title>
<date>2011</date>
<booktitle>In Proceedings of the Ninth International Conference on Computational Semantics,</booktitle>
<pages>135--144</pages>
<location>Oxford, UK.</location>
<contexts>
<context position="14442" citStr="Guevara, 2011" startWordPosition="2355" endWordPosition="2356">number of distinct tokens in both sentences divided by the number of distinct tokens in the longer sentence, optimizing the number of the most frequent words stripped off the sentences on the test set. • SWL: The word-overlap baseline computed as in WO but using lemmas instead of words and the stop words list. • ADD: The simple additive compositional model, in which each sentence is represented by the sum of the vectors of the lemmas that compose it (stripping off stop words and using the best performing corpus) and the similarity is the cosine between these two vectors (Bestgen et al., 2010; Guevara, 2011) . MeanMaxSim r Baseline r TASA 0.696 WO 0.627 BNC 0.698 SWL 0.613 WIKI 0.696 ADD 0.500 Table 1: Pearson’s correlation for MeanMaxSim and several other baselines on the test set. MeanMaxSim produces almost identical results regardless of the corpus used. The lack of difference between the three corpora was unexpected. It could be related to the type of vocabulary used in the SICK materials, seemingly mostly frequent and concrete words whose use could be relatively similar in the three corpora. MeanMaxSim performance is clearly superior to all other baselines; among these, the additive model is</context>
</contexts>
<marker>Guevara, 2011</marker>
<rawString>Guevara, Emiliano (2011). Computing semantic compositionality in distributional semantics. In Proceedings of the Ninth International Conference on Computational Semantics, 135-144, Oxford, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Howell</author>
</authors>
<title>M´ethodes statistiques en sciences humaines.</title>
<date>2008</date>
<journal>Bruxelles, Belgique: De Boeck Universit´e.</journal>
<contexts>
<context position="4258" citStr="Howell, 2008" startWordPosition="675" endWordPosition="676">in which woman and man were interchanged, and their mean similarity score was 3.6). Then, these mean scores were used as the similarity scores of the sentence pairs of the test sample 160 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 160–165, Dublin, Ireland, August 23-24, 2014. in which the same words were interchanged. The correlation between the actual scores and the predicted score was 0.83 (N=92), a value that can be considered as very high, given the restrictions on the range in which the predicted similarity scores vary (min=3.5 and max=5.0; Howell, 2008, pp. 272-273). It is important to note that this observation does not prove that the participants have not built a compositional representation, especially as it only deals with a very specific type of transformation. It nevertheless suggests that analyzing only the differences between the sentences of a pair could allow the similarity between them to be effectively estimated. Following these observations, I opted to try to determine the degree of efficacy that can be achieved by two non-compositional approaches. The first approach, totally unsupervised, is proposed as a new baseline to evalu</context>
</contexts>
<marker>Howell, 2008</marker>
<rawString>Howell, David (2008). M´ethodes statistiques en sciences humaines. Bruxelles, Belgique: De Boeck Universit´e.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Kintsch</author>
</authors>
<title>Comprehension: A Paradigme for Cognition. New York:</title>
<date>1998</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1891" citStr="Kintsch, 1998" startWordPosition="279" endWordPosition="280">ions of the words they contain (Baroni et al., 2013; Bestgen and Cabiaux, 2002; Erk and Pado, 2008; Grefenstette, 2013; Kintsch, 2001; Mitchell and Lapata, 2010); they are thus an extension of Distributional Semantic Models (DSMs), which approximate the meaning of words with vectors summarizing their patterns of co-occurrence in a corpus (Baroni and Lenci, This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http: //creativecommons.org/licenses/by/4.0/ 2010; Bestgen et al., 2006; Kintsch, 1998; Landauer and Dumais, 1997). The dataset for this task, called SICK (Sentences Involving Compositional Knowledge), consists of almost 10,000 English sentence pairs annotated for relatedness in meaning and entailment relation by ten annotators (Marelli et al., 2014b). The rationale behind this dataset is that ”understanding when two sentences have close meanings or entail each other crucially requires a compositional semantics step” (Marelli et al., 2014b), and thus that annotators judge the similarity between the two sentences of a pair by first building a mental representation of the meaning</context>
</contexts>
<marker>Kintsch, 1998</marker>
<rawString>Kintsch, Walter (1998). Comprehension: A Paradigme for Cognition. New York: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Kintsch</author>
</authors>
<date>2001</date>
<journal>Predication. Cognitive Science,</journal>
<volume>25</volume>
<issue>2</issue>
<pages>173--202</pages>
<contexts>
<context position="1411" citStr="Kintsch, 2001" startWordPosition="213" endWordPosition="214">ransformed) lexical features describing the differences between each sentence of a pair. It finished sixth out of 17 teams in the textual similarity sub-task and sixth out of 19 in the textual entailment subtask. 1 Introduction The SemEval-2014 Task 1 (Marelli et al., 2014a) was designed to allow a rigorous evaluation of compositional distributional semantic models (CDSMs). CDSMs aim to represent the meaning of phrases and sentences by composing the distributional representations of the words they contain (Baroni et al., 2013; Bestgen and Cabiaux, 2002; Erk and Pado, 2008; Grefenstette, 2013; Kintsch, 2001; Mitchell and Lapata, 2010); they are thus an extension of Distributional Semantic Models (DSMs), which approximate the meaning of words with vectors summarizing their patterns of co-occurrence in a corpus (Baroni and Lenci, This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http: //creativecommons.org/licenses/by/4.0/ 2010; Bestgen et al., 2006; Kintsch, 1998; Landauer and Dumais, 1997). The dataset for this task, called SICK (Sentences Involving Compositional Knowledge), cons</context>
</contexts>
<marker>Kintsch, 2001</marker>
<rawString>Kintsch, Walter (2001). Predication. Cognitive Science, 25(2), 173-202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Landauer</author>
<author>Susan Dumais</author>
</authors>
<title>A solution to Plato’s problem: The latent semantic analysis theory of acquisition, induction and representation of knowledge.</title>
<date>1997</date>
<journal>Psychological Review,</journal>
<volume>104</volume>
<issue>2</issue>
<pages>211--240</pages>
<contexts>
<context position="1919" citStr="Landauer and Dumais, 1997" startWordPosition="281" endWordPosition="285">ds they contain (Baroni et al., 2013; Bestgen and Cabiaux, 2002; Erk and Pado, 2008; Grefenstette, 2013; Kintsch, 2001; Mitchell and Lapata, 2010); they are thus an extension of Distributional Semantic Models (DSMs), which approximate the meaning of words with vectors summarizing their patterns of co-occurrence in a corpus (Baroni and Lenci, This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http: //creativecommons.org/licenses/by/4.0/ 2010; Bestgen et al., 2006; Kintsch, 1998; Landauer and Dumais, 1997). The dataset for this task, called SICK (Sentences Involving Compositional Knowledge), consists of almost 10,000 English sentence pairs annotated for relatedness in meaning and entailment relation by ten annotators (Marelli et al., 2014b). The rationale behind this dataset is that ”understanding when two sentences have close meanings or entail each other crucially requires a compositional semantics step” (Marelli et al., 2014b), and thus that annotators judge the similarity between the two sentences of a pair by first building a mental representation of the meaning of each sentence and then c</context>
</contexts>
<marker>Landauer, Dumais, 1997</marker>
<rawString>Landauer, Thomas, and Dumais, Susan, (1997). A solution to Plato’s problem: The latent semantic analysis theory of acquisition, induction and representation of knowledge. Psychological Review, 104(2), 211-240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Landauer</author>
<author>Peter Foltz</author>
<author>Darrell Laham</author>
</authors>
<title>An introduction to latent semantic analysis,</title>
<date>1998</date>
<booktitle>Discourse Processes,</booktitle>
<volume>25</volume>
<pages>259--284</pages>
<contexts>
<context position="9629" citStr="Landauer et al., 1998" startWordPosition="1551" endWordPosition="1554"> with stepwise selection of the best predictors. For the textual entailment sub-task, the same procedure was used except that the linear regression was replaced by a linear discriminant analysis. 3 Implementation Details This section describes the steps and additional resources used to implement the proposed approaches for the SICK challenge. 3.1 Preprocessing of the Dataset All sentences were tokenized and lemmatized by the Stanford Parser (de Marneffe et al., 2006; Toutanova et al., 2003). 3.2 Distributional Semantics Latent Semantic Analysis (LSA), a classical DSM (Deerwester et al., 1991; Landauer et al., 1998), was used to gather the semantic similarity between words from corpora. The starting point of the analysis is a lexical table containing the frequencies of every word in each of the text segments included in the corpus. This table is submitted to a singular value decomposition, which extracts the most significant orthogonal dimensions. In this semantic space, the meaning of a word is represented by a vector and the semantic similarity between two words is estimated by the cosine between their corresponding vectors. Three corpora were used to estimate these similarities. The first one, the TAS</context>
</contexts>
<marker>Landauer, Foltz, Laham, 1998</marker>
<rawString>Landauer, Thomas, Foltz, Peter, and Laham, Darrell (1998). An introduction to latent semantic analysis, Discourse Processes, 25, 259-284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ludovic Lebart</author>
</authors>
<title>Piron Marie, et Morineau Alain</title>
<date>2000</date>
<publisher>Dunod.</publisher>
<location>Paris:</location>
<marker>Lebart, 2000</marker>
<rawString>Lebart, Ludovic, Piron Marie, et Morineau Alain (2000). Statistique exploratoire multidimensionnelle (3e ´edition), Paris: Dunod.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Marco Marelli</author>
<author>Luisa Bentivogli</author>
<author>Marco Baroni</author>
<author>Raffaella Bernardi</author>
<author>Stefano Menini</author>
<author>Roberto Zamparelli</author>
</authors>
<title>Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment.</title>
<booktitle>In Proceedings of SemEval2014: Semantic Evaluation Exercises.</booktitle>
<location>Dublin, Ireland.</location>
<marker>Marelli, Bentivogli, Baroni, Bernardi, Menini, Zamparelli, </marker>
<rawString>Marelli, Marco, Bentivogli, Luisa, Baroni, Marco, Bernardi, Raffaella, Menini, Stefano, and Zamparelli, Roberto (2014a). Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment. In Proceedings of SemEval2014: Semantic Evaluation Exercises. Dublin, Ireland.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Marco Marelli</author>
<author>Stefano Menini</author>
<author>Marco Baroni</author>
<author>Luisa Bentivogli</author>
<author>Raffaella Bernardi</author>
<author>Roberto Zamparelli</author>
</authors>
<title>A SICK cure for the evaluation of compositional distributional semantic models.</title>
<booktitle>In Proceedings of the 9th Edition of the Language Resources and Evaluation Conference,</booktitle>
<location>Reykjavik, Iceland.</location>
<marker>Marelli, Menini, Baroni, Bentivogli, Bernardi, Zamparelli, </marker>
<rawString>Marelli, Marco, Menini, Stefano, Baroni, Marco, Bentivogli, Luisa, Bernardi, Raffaella, and Zamparelli, Roberto (2014b). A SICK cure for the evaluation of compositional distributional semantic models. In Proceedings of the 9th Edition of the Language Resources and Evaluation Conference, Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Mitchell</author>
<author>Mirella Lapata</author>
</authors>
<title>Composition in distributional models of semantics.</title>
<date>2010</date>
<journal>Cognitive Science,</journal>
<volume>34</volume>
<pages>1388--1429</pages>
<contexts>
<context position="1439" citStr="Mitchell and Lapata, 2010" startWordPosition="215" endWordPosition="218">ical features describing the differences between each sentence of a pair. It finished sixth out of 17 teams in the textual similarity sub-task and sixth out of 19 in the textual entailment subtask. 1 Introduction The SemEval-2014 Task 1 (Marelli et al., 2014a) was designed to allow a rigorous evaluation of compositional distributional semantic models (CDSMs). CDSMs aim to represent the meaning of phrases and sentences by composing the distributional representations of the words they contain (Baroni et al., 2013; Bestgen and Cabiaux, 2002; Erk and Pado, 2008; Grefenstette, 2013; Kintsch, 2001; Mitchell and Lapata, 2010); they are thus an extension of Distributional Semantic Models (DSMs), which approximate the meaning of words with vectors summarizing their patterns of co-occurrence in a corpus (Baroni and Lenci, This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http: //creativecommons.org/licenses/by/4.0/ 2010; Bestgen et al., 2006; Kintsch, 1998; Landauer and Dumais, 1997). The dataset for this task, called SICK (Sentences Involving Compositional Knowledge), consists of almost 10,000 Englis</context>
</contexts>
<marker>Mitchell, Lapata, 2010</marker>
<rawString>Mitchell, Jeff, and Lapata, Mirella (2010). Composition in distributional models of semantics. Cognitive Science, 34, 1388-1429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oleg Nenadic</author>
<author>Michael Greenacre</author>
</authors>
<title>Correspondence analysis in R, with two- and threedimensional graphics: the CA package,</title>
<date>2007</date>
<journal>Journal of Statistical Software,</journal>
<volume>20</volume>
<issue>3</issue>
<pages>1--13</pages>
<marker>Nenadic, Greenacre, 2007</marker>
<rawString>Nenadic, Oleg, and Greenacre, Michael (2007). Correspondence analysis in R, with two- and threedimensional graphics: the CA package, Journal of Statistical Software, 20(3), 1-13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In Proceedings of the 1994 International Conference on New Methods in Language Processing,</booktitle>
<pages>44--49</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="11312" citStr="Schmid, 1994" startWordPosition="1831" endWordPosition="1832">many different genres. As the documents included in this corpus can be of up to 45,000 words, they were divided into segments of 250 words, the last segment of a text being deleted if it contained fewer than 250 words. The third corpus (WIKI, approximately 600 million words after preprocessing) is derived from the Wikipedia Foundation database, downloaded in April 2011. It was built using WikiExtractor.py by A. Fuschetto. As for the BNC, the texts were cut into 250-word segments, and any segment of fewer than 250 words was deleted. All these corpora were lemmatized by means of the TreeTagger (Schmid, 1994). In addition, a series of functional words were removed as well as all the words whose total frequency in the corpus was lower than 10. The resulting (log-entropy weighted) matrices of co-occurrences were submitted to a singular value decomposition (SVDPACKC, Berry et al., 1993) and the first 300 eigenvectors were retained. 3.3 Unsupervised Approach Details Before estimating the semantic similarity between a pair of sentences using MeanMaxSim, words (in their lemmatized forms) considered as stop words were filtered out. This stop word list (n=82), was built specifically for the occasion on th</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Schmid, Helmut (1994). Probabilistic part-of-speech tagging using decision trees. In Proceedings of the 1994 International Conference on New Methods in Language Processing, 44-49, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich partof-speech tagging with a cyclic dependency network.</title>
<date>2003</date>
<booktitle>In Proceddings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistic</booktitle>
<pages>252--259</pages>
<location>Edmonton, Canada.</location>
<contexts>
<context position="9502" citStr="Toutanova et al., 2003" startWordPosition="1533" endWordPosition="1536">e lexical features. Finally, a predictive model is built on the basis of the training set by means of multiple linear regression with stepwise selection of the best predictors. For the textual entailment sub-task, the same procedure was used except that the linear regression was replaced by a linear discriminant analysis. 3 Implementation Details This section describes the steps and additional resources used to implement the proposed approaches for the SICK challenge. 3.1 Preprocessing of the Dataset All sentences were tokenized and lemmatized by the Stanford Parser (de Marneffe et al., 2006; Toutanova et al., 2003). 3.2 Distributional Semantics Latent Semantic Analysis (LSA), a classical DSM (Deerwester et al., 1991; Landauer et al., 1998), was used to gather the semantic similarity between words from corpora. The starting point of the analysis is a lexical table containing the frequencies of every word in each of the text segments included in the corpus. This table is submitted to a singular value decomposition, which extracts the most significant orthogonal dimensions. In this semantic space, the meaning of a word is represented by a vector and the semantic similarity between two words is estimated by</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Toutanova, Kristina, Klein, Dan, Manning, Christopher, and Singer, Yoram (2003). Feature-rich partof-speech tagging with a cyclic dependency network. In Proceddings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistic 2003, 252-259, Edmonton, Canada.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>