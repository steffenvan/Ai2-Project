<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000429">
<title confidence="0.975687">
Entities&apos; Sentiment Relevance
</title>
<author confidence="0.970845">
Zvi Ben-Ami
</author>
<affiliation confidence="0.955427">
The Hebrew University
</affiliation>
<address confidence="0.556976">
Jerusalem, ISRAEL
</address>
<email confidence="0.878719">
zvi.benami@mail.huji.a
c.il
</email>
<author confidence="0.908003">
Ronen Feldman
</author>
<affiliation confidence="0.898029">
The Hebrew University
</affiliation>
<address confidence="0.531952">
Jerusalem, ISRAEL
</address>
<email confidence="0.7024165">
ronen.feldman@huji.ac
.il
</email>
<author confidence="0.594359">
Binyamin Rosenfeld
</author>
<affiliation confidence="0.52661">
Digital Trowel
</affiliation>
<address confidence="0.886294">
New York, USA
</address>
<email confidence="0.738657">
grurgrur@gmail.
com
</email>
<sectionHeader confidence="0.986266" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997549">
Sentiment relevance detection problems oc-
cur when there is a sentiment expression in a
text, and there is the question of whether or
not the expression is related to a given entity
or, more generally, to a given situation. The
paper discusses variants of the problem, and
shows that it is distinct from other somewhat
similar problems occurring in the field of sen-
timent analysis and opinion mining. We ex-
perimentally demonstrate that using the in-
formation about relevancy significantly af-
fects the final sentiment evaluation of the en-
tities. We then compare a set of different al-
gorithms for solving the relevance detection
problem. The most accurate results are
achieved by algorithms that use certain doc-
ument-level information about the target enti-
ties. We show that this information can be
accurately extracted using supervised classi-
fication methods.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999981844827586">
Sentiment extraction by modern sentiment analy-
sis (SA) systems is usually based on searching
the input text for sentiment-bearing words and
expressions, either general (language-wide) or
domain-specific. In most common SA approach-
es, each such expression carries a polarity value
(&amp;quot;positive&amp;quot; or &amp;quot;negative&amp;quot;) which is possibly
weighted. The sum of all polarity values from all
expressions found in a text becomes the senti-
ment score for the whole text.
People are, however, usually interested in sen-
timents regarding some entity or situation, and
not in sentiments of a particular document. A
natural way to make the SA more focused is to
explicitly bind each sentiment expression to a
specific entity, or to a small set of entities from
among all entities mentioned in the document.
The choice of which entity to bind a sentiment
expression to, can be made according to the
proximity (physical, syntactical, and/or semantic)
and/or salience of the entities.
In this paper, we argue that all of these meth-
ods can be useful in different contexts, and so the
best single algorithm should use all available
proximity information, of all kinds, together with
additional context information –position in the
document, section, or paragraph; proximity of
other entities; lexical contents; etc. One of the
most important context information is the type of
relation between the target entity and the docu-
ment – whether the entity is the main topic of the
document, or one of several main topics, or men-
tioned in passing, etc.
Another layer that we&apos;d like to add concerns
the interaction of different entity types during
SA. In a typical situation, there is only one entity
type which is the target for SA. In such cases,
clearly distinguishing between the relevancy of
target and non-target entities types is not essen-
tial. For example, when the general topic is a
COMPANY, and there is a sentiment expression
referring to a PERSON or a PRODUCT, this
sentiment expression is still relevant to the com-
pany and can be regarded as such. In other situa-
tions, SA users may be specifically interested in
an interaction between entities of different types.
For example, in a medical forum setting, it may
be interesting to know the users&apos; sentiments re-
garding a given DRUG in the context of a given
DISEASE. We will show that such situations are
modeled well enough using intersections of re-
gions of relevance of the participating entity
types, with the relevance region for each type
calculated separately.
We purposefully exclude possible interactions
between entities of the same type, because they
behave in a different way. The precise analysis
of such interactions is a different topic from rele-
</bodyText>
<page confidence="0.987649">
87
</page>
<bodyText confidence="0.63204325">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 87–92,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
vance detection, and so it is mostly ignored in
this paper.
</bodyText>
<sectionHeader confidence="0.999233" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.990416576923077">
The task of SA has drawn the attention of many
researchers worldwide (Connor et al., 2010; Liu,
2012; Loughran and Mcdonald, 2010; Pang and
Lee, 2004; Turney, 2002). While most SA re-
search is focused on discovering and classifying
the expressions, some are also concerned with
the targets of the expressions and explicitly iden-
tify the syntactic targets of sentiment expressions
(Pang and Lee, 2004).
Other related works belong to the Passage Re-
trieval field, since the relevance detection prob-
lem can be construed as a specific form of pas-
sage retrieval problem (Liu and Croft, 2002;
Tiedemann and Mur, 2008). Different approach-
es were suggested for passage retrieval (Buscaldi
et al., 2010; Comas et al., 2012; Hearst, 1997;
Lafferty et al., 2001; Lin et al., 2012; Liu and
Croft, 2002; Lloret et al., 2012; O’Connor et al.,
2013; Otterbacher et al., 2009; Salton et al.,
1993; Wachsmuth, 2013), some are more sophis-
ticated than others.
The closest approach to ours is the one of
Scheible and Schütze (2013), but in contrast to
them, we strive to discover sentiments&apos; relevance
for all entities (of a given type) mentioned in the
document, not necessarily topical.
</bodyText>
<sectionHeader confidence="0.992819" genericHeader="method">
3 Entity Relevance
</sectionHeader>
<bodyText confidence="0.997863625">
An instance of the sentiment relevance detection
problem for a single entity consists of a text doc-
ument, a sentiment expression within the docu-
ment, and a target entity. The task is a binary
decision: &apos;relevant&apos; vs. &apos;irrelevant&apos;. To solve this
task, we can use any information that can be
found by analyzing the document. Thus, we can
assume that we know the parse trees of all sen-
tences and the locations of all references of all
entities in the document, including co-references.
In addition, we make use of an extra piece of
information for each target entity – its &amp;quot;status
within the document&amp;quot;, or &amp;quot;document type with
respect to the entity&amp;quot;. We distinguish between
several types which are intuitively clearly differ-
ent:
</bodyText>
<listItem confidence="0.997676444444444">
• &apos;Target&apos; – the entity is the main topic of the
document;
• &apos;Accidental&apos; – the entity is not the main topic
of the document, and is mentioned in passing;
• &apos;RelationTarget&apos; – the main topic of the doc-
ument is a relation between the entity and
some other entities of the same type;
• &apos;ListTarget&apos; – the entity is one of a few equal-
ly important topics, dealt with sequentially.
</listItem>
<bodyText confidence="0.99992034">
In the datasets we use for experiments, each
entity is manually annotated with its status with-
in the document, which allows us to directly ob-
serve the influence of this data on the accuracy
of relevance discernment. We also show that this
data can be automatically extracted using super-
vised classification.
Since this paper is primarily a study of senti-
ment relevance, the actual sentiment expressions
are not always labeled in our datasets. Instead,
relevance ranges are annotated for each entity, in
the style of passage retrieval problems, with the
expectation that sentiment expressions relevant
to an entity only appear in the parts of the docu-
ment that are labeled as &amp;quot;relevant&amp;quot;, and converse-
ly, that all expressions appearing in parts labeled
&amp;quot;irrelevant&amp;quot; are irrelevant. This way of annotat-
ing allows the comparing of different relevance
detection strategies independently of the main
sentiment extraction tool.
All of the algorithms discussed in this paper
use the same document processing methods, thus
allowing us to compare the algorithms them-
selves independent of the quality and specifics of
the underlying NLP.
The multiple-entity relevance problem is dis-
tinguished from the single-entity relevance prob-
lem by the requirement for the sentiment expres-
sion to be relevant to several entities of different
types. The problem is close to Relation Extrac-
tion in this sense. The examples we are interested
in are in the medical domain and deal with three
main entity types: PERSON, DRUG, and
DISEASE, where PERSON is restricted to
known physicians. While each of the entity types
can be the target of a sentiment expression, the
more interesting questions in this domain involve
multiple entities, specifically, DRUG +
DISEASE (&amp;quot;how effective is this drug for this
disease?&amp;quot;), and PERSON + DRUG + DISEASE
(&amp;quot;what does this physician say about using this
drug to cure this disease?&amp;quot;).
We solve the multiple-entity relevance prob-
lem by intersecting the relevance ranges of dif-
ferent-type entities, thus reducing the problem to
the single-entity relevance detection. As such,
the experiments regarding the multiple-entity
relevance need only check the accuracy of this
reduction. In the medical domain, at least, this
accuracy appears to be adequate.
</bodyText>
<page confidence="0.997843">
88
</page>
<sectionHeader confidence="0.997583" genericHeader="method">
4 Relevance Algorithms
</sectionHeader>
<bodyText confidence="0.999989714285714">
Each algorithm receives, as input, the text of the
document, with labeled reference of the target
entity and other entities of the same type. The
labeled references also include all coreferential
references, extracted automatically by an NLP
system. The input text also includes labeled can-
didate sentiment expressions, either manually
labeled or automatically extracted by a rele-
vance-ignoring SA system1. The task of the algo-
rithms is to label each candidate expression as
relevant or irrelevant to the target entity. The
algorithms are evaluated according to the accura-
cy (recall, precision, and F1) of this labeling of
individual sentiment expressions.
This method produces a reasonably well-
understandable quality measure (the percentage
of expressions that the algorithms get right or
wrong), and also allows us to compare algo-
rithms focused on individual expressions and
algorithms working on text ranges. The algo-
rithms we evaluate are as follows:
</bodyText>
<listItem confidence="0.876468898550725">
• Baseline - Every expression is declared rele-
vant. This is the standard mode of operation of
document-level SA tools, although it is usually
only applied to the &apos;Target&apos; entities – the main
topic(s) of the document.
• Physical-proximity-based - A text-range fo-
cused algorithm, which labels pieces of text as
relevant or irrelevant according to their place-
ment relative to the references of the target en-
tity and other entities of the same type, as well
as some other contextual clues, such as para-
graph boundaries. Generally, the mentioning of
an entity starts its relevance range (and stops
the relevance range of the previously men-
tioned entity). For the first entity reference in a
paragraph, the range also extends backward to
the beginning of the sentence. There are three
flavors of the algorithm, specifically adapted
for different document-types-with-respect-to-
the-target-entity:
o &apos;Proximity-Accidental&apos; - stops relevance
ranges at paragraph boundaries,
o &apos;Proximity-Targeted&apos; - restarts relevance
ranges at paragraph boundaries (every para-
1In our experiments, we also use a standalone automatic
Financial SA system from Feldman et al. (2010), working
in the &apos;ignore relevance&apos; mode, which (1) finds and labels
all entities of the target type(s); (2) resolves all corefer-
ences for the target entity type(s); (3) finds and labels all
sentiment expressions, regardless of their relevance; and
(4) provides dependency parses for all sentences in the
corpus.
graph is assumed relevant at the start, unless
another entity is mentioned).
o &apos;Proximity-List&apos; - interpolates relevance
ranges over intermission paragraphs, unless
they are explicitly irrelevant (e.g., contain-
ing references of other entities of the same
type).
• Syntactic-proximity-based - An expression-
focused algorithm, which labels expressions as
relevant or irrelevant according to their dis-
tance to various entity references in the de-
pendency parse graph. There are two flavors of
the algorithm: direct and reverse. The former
considers an expression relevant only if it is
closest to the target entity from among all enti-
ties of the same type, and the distance is suffi-
ciently close. The latter considers an expres-
sion irrelevant only if it has the above-
described relation to some non-target entity of
the same type. The rationale for the two flavors
is the distinction between &apos;Targeted&apos; and &apos;Acci-
dental&apos; document types regarding the target en-
tity. For the &apos;Accidental&apos; entities, a sentiment
expression is assumed to be relevant only if it
is explicitly connected to the entity. For &apos;Tar-
geted&apos; entities, an expression is irrelevant only
if it is explicitly connected to some other entity
of the same type.
• Classification-based - This algorithm consid-
ers each candidate sentiment expression as an
instance of a binary classification problem, to
be solved using supervised classification. For
evaluating this algorithm, some part of the test
corpus is used for training, and the other for
testing, with N-fold cross-validation. The fea-
tures for classification may use any infor-
mation present in the input.
</listItem>
<bodyText confidence="0.999739857142857">
In the current experiments, we use refer-
ences of target and non-target entities, appear-
ances of paragraph and document boundaries,
length of syntactic connections to target and
non-target entities, when available, and explicit
entity status within documents, when available.
The (binary) classification features are built
from sequences of up to 5 occurrences of the
above-described pieces, with the pieces ap-
pearing before and after the sentiment expres-
sion tracked separately. For classification, we
use a linear classifier with Large Margin train-
ing (regularized perceptron, as discussed in
Scheible and Schütze, (2013)).
</bodyText>
<listItem confidence="0.985976">
• Sequence-classification-based - The algo-
rithm uses exactly the same features as the di-
rect classification-based above, but instead of
considering each expression separately, it con-
</listItem>
<page confidence="0.999521">
89
</page>
<bodyText confidence="0.999953">
siders them as a sequence, one per document.
So, instead of a Large Margin binary classifier,
a probabilistic sequence classifier is used
(CRF, as discussed in Lafferty et al. (2001)).
</bodyText>
<sectionHeader confidence="0.998729" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999824933333333">
For the experiments, we use two manually-
annotated corpora 2 , a financial corpus3 and a
medical4 corpus. In the Financial corpus, COM-
PANIEs are used as target entities and in the
medical corpus, DISEASEs, DRUGs and PER-
SONs are the entity types that are used as target
entities. For the purpose of the experiments, we
are interested only in single-entity sentiments
about DRUGs, and multiple-entity sentiments
about DRUGs + DISEASEs, and DRUGs +
DISEASEs + PERSONs.
The evaluation metrics in all of the experi-
ments are precision, recall, and F1. For the clas-
sification-based algorithms, unless stated other-
wise, we use 10-fold cross-validation.
</bodyText>
<subsectionHeader confidence="0.927215">
5.1 Experiment: Importance of relevance
</subsectionHeader>
<bodyText confidence="0.999775777777778">
In the first experiment, we demonstrate the im-
portance of using relevance when calculating the
consolidated sentiment score of an entity within
a set of documents. For each entity, we set the
&apos;correct&apos; consolidated sentiment score to the av-
erage of polarities of all sentiments in a corpus
which are labeled as relevant to the entity. Then,
we compare the correct value to the two scores
calculated without considering relevance:
</bodyText>
<listItem confidence="0.99629775">
• &apos;Baseline&apos; - the average of polarities of all sen-
timents in all documents where the entity is
mentioned, and
• &apos;TargetedOnly&apos; - the average of polarities of
all sentiments in the documents where the enti-
ty is labeled as target (main topic of the docu-
ment). This case models the typical state of a
relevance-agnostic SA system.
</listItem>
<bodyText confidence="0.974175333333333">
For this evaluation, we only compare the sign
of the final sentiment scores, without considering
their magnitudes (unless it is close to zero, in
</bodyText>
<footnote confidence="0.954947">
2 Fully annotating texts for semantic relevance is an arduous
task, thus the used annotated corpora are relatively small.
Sample can be found at http://goo.gl/6HONHP.
3 A corpus of 160 financial news documents on at least one
entity of interest, of average size —5Kb, downloaded from
various financial news websites. The dataset mentions 424
different companies.
4 A corpus of 160 documents, of average size —7Kb, down-
loaded following Google queries on a set of a few com-
mon drugs and diseases. The dataset mentions 722 differ-
ent people, 46 diseases, and 175 drugs.
</footnote>
<bodyText confidence="0.999292">
which it is considered &apos;neutral&apos;). The errors at this
level indicate definite SA errors – miscalculating
entity&apos;s sentiment into its opposite.
The results of the evaluation are as follows:
The &apos;Baseline&apos; scores show a large difference
from the correct scores, with 33% and 38% of
entities having wrong final polarity in the finan-
cial (COMPANY) and medical (DRUG) do-
mains, respectively. The &apos;TargetedOnly&apos; scores
are somewhat closer to correct, with 12% and
28% of entities with incorrect final polarities.
However, the &apos;TargetedOnly&apos; method naturally
suffers from a very low recall, with only 19%
and 38% of entities covered in the financial and
medical domains, respectively.
</bodyText>
<subsectionHeader confidence="0.96695">
5.2 Experiment: Influence of entity status
</subsectionHeader>
<bodyText confidence="0.999997375">
In this experiment, we compare the performance
of various algorithms while either providing or
withholding the information about the document-
type-with-respect-to-the-target-entity.
The performance of the physical proximity al-
gorithms on the financial corpus is shown at the
top left hand side of Table 1. The set of all in-
stances of relevance detection problems in the
corpus (an instance consists of a sentiment ex-
pression within a text, together with a target enti-
ty) is divided into three subsets, according to the
status of the target entity within the document.
As expected, the three flavors of the physical
proximity algorithm perform much better on the
corpus subsets they are adapted to. At the bottom
left hand side of Table 1, we similarly show the
performance of the two flavors of the syntax-
proximity-based algorithm on the medical do-
main (DRUG entities). Same as above, there is a
large difference in the performance of the two
flavors of the algorithm on different subsets of
the problem set. Finally, at the top of Table 2, we
compare the performance of the two classifica-
tion-based algorithms on the two (whole) prob-
lem sets, while either keeping or withholding the
entity status information from the classifier. The
difference in results is less pronounced here, but
is still noticeable. The reason for the smaller dif-
ference, we hypothesize, is the ability of the clas-
sifiers to partially infer the entity status from the
various context clues that are used as classifica-
tion features (see the experiment 5.3).
</bodyText>
<subsectionHeader confidence="0.8603395">
5.3 Experiment: Automatic identification of
entity status using classification.
</subsectionHeader>
<bodyText confidence="0.981756666666667">
In this experiment, we confirm that it is possible
to identify the entity status within documents
using supervised classification.
</bodyText>
<page confidence="0.994617">
90
</page>
<table confidence="0.999905625">
Proximity-Accidental Experiment 5.2 (Precision/Recall/F1) Experiment 5.3 ( F1, (diff. in F1 from exp. 5.2)
Accidental Targeted List Whole Accidental Targeted List Whole
84/43/57 93/76/84 92/74/82 92/72/81 60 (+2.6) 79 (-5.5) 83 (+1.1)
Proximity-Targeted 31/50/38 90/84/87 55/89/68 63/83/72 38 (-0.4) 82 (-5.2) 73 (+4.3)
Proximity-List 58/44/50 90/83/87 88/83/86 85/80/82 52 (+2.1) 81 (-5.9) 87 (+1.6)
Proximity-Combined 89/80/84 83 (-1.2)
Syntactic-Prox.-Direct 93/48/64 99/42/60 65 (+0.8) 59 (-0.2)
Syntactic-Prox.-Inverse 04/72/08 70/66/68 8 (-0.2) 76 (+6.4)
</table>
<tableCaption confidence="0.9154265">
Table 1. Performance of different algorithms on three subsets of the corpus with a different status of
the target entity within the document.
</tableCaption>
<table confidence="0.999978263157895">
Experiment Algorithm Financial Medical
Experiment 5.2 Classification (with entity 90/86/88 84/88/86
(Prec./ Rec,/F1). status info)
Classification (without 89/85/87 87/81/84
entity status info)
Sequence Classification 96/84/90 99/84/91
(with entity status info)
Sequence Classification 96/83/89 95/85/90
(without entity status info)
Experiment 5.3 Classification 86.7 (-0.9) 83.9 (-2.0)
(F1, (diff. in F1
from exp. 5.2))
Sequence Classification 89.7 (+0.1) 90.9 (-0.3)
Experiment 5.5 Baseline 37.2 28.6
(F1)
Physical Proximity 84.1 79.5
Syntactic-Proximity 43.8 54.6
Classification 87.6 85.9
Sequence-Classification 91.2 89.6
</table>
<tableCaption confidence="0.999792">
Table 2. Performance of different algorithms
</tableCaption>
<bodyText confidence="0.984059058823529">
on the different domains.
The results of direct evaluation show that the
accuracies of the Medical and Financial corpora
(using 10-fold X-validation) are 87.8% and
82.2% respectively, and the accuracy when using
the Medical corpus for training the Financial
corpus for testing and vice versa, are 78.2% and
86.1% , respectively.
The results of relevance detection using the
automatically extracted entity status values are
shown at the right hand side of Table 1 and in the
middle of Table 2, which utilize the same da-
tasets and algorithms as at the left hand side of
Table 1 and at the top of Table 2. As can be seen
from the tables, the drop in performance is small,
demonstrating the success of classification-based
extraction of entity status information.
</bodyText>
<subsectionHeader confidence="0.892176">
5.4 Experiment: Cross-domain applicability
</subsectionHeader>
<bodyText confidence="0.999501">
In this experiment, we test how well the classifi-
ers trained on data from one domain work on
input from a different domain.
The classification results using different types
of training data are shown in Table 3.
</bodyText>
<table confidence="0.997456">
Classification Sequence classification
Medical 2-fold/10-fold 84.6/85.9 85.7/89.6
Train on Fin, test on Med 83.5 86.8
Financial 2-fold/10-fold 86.1/87.6 90.3/91.2
Train on Med, test on Fin 85.4 91.0
</table>
<tableCaption confidence="0.94389">
Table 3. Performance of classification-based
algorithms using different training data (F1).
</tableCaption>
<bodyText confidence="0.9995925">
The table confirms general independence of
the classification performance on the domain.
Comparing the 2-fold and 10-fold cross-
validation results (the difference is equivalent to
doubling the amount of training data), shows that
the amount of training data is sufficient.
</bodyText>
<sectionHeader confidence="0.935045" genericHeader="method">
5.5 Experiment: Overall performance of
algorithms
</sectionHeader>
<bodyText confidence="0.999945692307692">
In this experiment, we simply compare the over-
all accuracy of various algorithms for relevance
discernment, operating at their best parameters.
The results are shown at the bottom of Table 2.
Overall, classification-based algorithms perform
better than the deterministic ones, with sequence-
classification performing significantly better than
direct classification. Syntactic proximity-based is
precise, but has relatively low recall, reducing its
overall performance. Physical proximity-based is
simplest, and produce reasonably high overall
results, although worse than the best-performing
classification-based methods.
</bodyText>
<sectionHeader confidence="0.999358" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9999872">
The results are mostly intuitively understood and
confirm the expectations. We confirmed that
relevance detection is essential for producing
correct consolidated SA results. We found that
the entity status within the document is one of
the important clues for solving the relevance
detection problem, and showed that this infor-
mation can be effectively automatically extracted
using supervised classification. We also com-
pared several algorithms for relevance detection,
with the results that classification-based algo-
rithms generally outperform simpler ones based
on the same clues, although a very simple prox-
imity-based algorithm performs reasonably well
if allowed to use the entity status information.
</bodyText>
<sectionHeader confidence="0.998322" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9902465">
This work is supported by the Israel Ministry of
Science and Technology Center of Knowledge in
Machine Learning and Artificial Intelligence and
the Israel Ministry of Defense.
</bodyText>
<page confidence="0.998143">
91
</page>
<sectionHeader confidence="0.990198" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999827063829787">
Buscaldi, D., Rosso, P., Gómez-Soriano, J., Sanchis,
E., 2010. Answering questions with an n-gram
based passage retrieval engine. J. Intell. Inf. Syst.
34, 113–134. doi:10.1007/s10844-009-0082-y
Comas, P.R., Turmo, J., Màrquez, L., 2012. Sibyl, a
factoid question-answering system for spoken
documents. ACM Trans. Inf. Syst. 30, 19:1–19:40.
doi:10.1145/2328967.2328972
Connor, B.O., Balasubramanyan, R., Routledge, B.R.,
Smith, N.A., 2010. From Tweets to Polls: Linking
Text Sentiment to Public Opinion Time Series, in:
Proceedings of the Fourth International AAAI
Conference on Weblogs and Social Media. pp.
122–129.
Feldman, R., Rosenfeld, B., Bar-haim, R., Fresko, M.,
2010. The Stock Sonar — Sentiment Analysis of
Stocks Based on a Hybrid Approach, in:
Proceedings of the Twenty-Third Innovative
Applications of Artificial Intelligence Conference.
pp. 1642–1647.
Hearst, M.A., 1997. TextTiling: segmenting text into
multi-paragraph subtopic passages. Comput.
Linguist. 23, 33–64.
Lafferty, J., McCallum, A., Pereira, F., 2001.
Conditional Random Fields: Probabilistic Models
for Segmenting and Labeling Sequence Data., in:
Proceedings of the Eighteenth International
Conference on Machine Learning (ICML-2001).
Lin, H.-T., Chi, N.-W., Hsieh, S.-H., 2012. A
concept-based information retrieval approach for
engineering domain-specific technical documents.
Adv. Eng. Informatics 26, 349–360.
doi:http://dx.doi.org/10.1016/j.aei.2011.12.003
Liu, B., 2012. Sentiment Analysis and Opinion
Mining Synthesis Lectures on Human Language
Technologies. Morgan &amp; Claypool Publishers.
Liu, X., Croft, W.B., 2002. Passage retrieval based on
language models, in: Proceedings of the Eleventh
International Conference on Information and
Knowledge Management, CIKM ’02. ACM, New
York, NY, USA, pp. 375–382.
doi:10.1145/584792.584854
Lloret, E., Balahur, A., Gómez, J., Montoyo, A.,
Palomar, M., 2012. Towards a unified framework
for opinion retrieval, mining and summarization. J.
Intell. Inf. Syst. 39, 711–747. doi:10.1007/s10844-
012-0209-4
Loughran, T.I.M., Mcdonald, B., 2010. When is a
Liability not a Liability? Textual Analysis ,
Dictionaries , and 10-Ks Journal of Finance ,
forthcoming. J. Finance 66, 35–65.
O’Connor, B., Stewart, B.M., Smith, N.A., 2013.
Learning to Extract International Relations from
Political Context, in: Proceedings of the 51st
Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long
Papers). Association for Computational
Linguistics, Sofia, Bulgaria, pp. 1094–1104.
Otterbacher, J., Erkan, G., Radev, D.R., 2009. Biased
LexRank: Passage retrieval using random walks
with question-based priors. Inf. Process. Manag.
45, 42–54.
doi:http://dx.doi.org/10.1016/j.ipm.2008.06.004
Pang, B., Lee, L., 2004. A Sentimental Education:
Sentiment Analysis Using Subjectivity
Summarization Based on Minimum Cuts.
Salton, G., Allan, J., Buckley, C., 1993. Approaches
to passage retrieval in full text information
systems, in: Proceedings of the 16th Annual
International ACM SIGIR Conference on Research
and Development in Information Retrieval, SIGIR
’93. ACM, New York, NY, USA, pp. 49–58.
doi:10.1145/160688.160693
Scheible, C., Schütze, H., 2013. Sentiment Relevance,
in: Proceedings of the 51st Annual Meeting of the
Association for Computational Linguistics
(Volume 1: Long Papers). Association for
Computational Linguistics, Sofia, Bulgaria, pp.
954–963.
Tiedemann, J., Mur, J., 2008. Simple is best:
experiments with different document segmentation
strategies for passage retrieval, in: Coling 2008:
Proceedings of the 2nd Workshop on Information
Retrieval for Question Answering, IRQA ’08.
Association for Computational Linguistics,
Stroudsburg, PA, USA, pp. 17–25.
Turney, P., 2002. Thumbs Up or Thumbs Down?
Semantic Orientation Applied to Unsupervised
Classification of Reviews, in: Proceedings of the
Association for Computational Linguistics (ACL).
pp. 417–424.
Wachsmuth, H., 2013. Information Extraction as a
Filtering Task Categories and Subject Descriptors,
in: To Appear in Proc. of the 22th ACM CIKM.
</reference>
<page confidence="0.996004">
92
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.030982">
<title confidence="0.996883">Entities&apos; Sentiment Relevance</title>
<author confidence="0.7375795">Zvi Ben-Ami The Hebrew</author>
<address confidence="0.992903">Jerusalem, ISRAEL</address>
<email confidence="0.9735055">zvi.benami@mail.huji.ac.il</email>
<author confidence="0.685281">Ronen</author>
<affiliation confidence="0.37458">The Hebrew</affiliation>
<address confidence="0.993862">Jerusalem, ISRAEL</address>
<email confidence="0.9186825">ronen.feldman@huji.ac.il</email>
<affiliation confidence="0.454097">Binyamin Digital</affiliation>
<address confidence="0.990297">New York, USA</address>
<email confidence="0.9820685">grurgrur@gmail.com</email>
<abstract confidence="0.997137904761905">Sentiment relevance detection problems occur when there is a sentiment expression in a text, and there is the question of whether or not the expression is related to a given entity or, more generally, to a given situation. The paper discusses variants of the problem, and shows that it is distinct from other somewhat similar problems occurring in the field of sentiment analysis and opinion mining. We experimentally demonstrate that using the information about relevancy significantly affects the final sentiment evaluation of the entities. We then compare a set of different algorithms for solving the relevance detection problem. The most accurate results are achieved by algorithms that use certain document-level information about the target entities. We show that this information can be accurately extracted using supervised classification methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Buscaldi</author>
<author>P Rosso</author>
<author>J Gómez-Soriano</author>
<author>E Sanchis</author>
</authors>
<title>Answering questions with an n-gram based passage retrieval engine.</title>
<date>2010</date>
<journal>J. Intell. Inf. Syst.</journal>
<volume>34</volume>
<pages>113--134</pages>
<contexts>
<context position="4801" citStr="Buscaldi et al., 2010" startWordPosition="763" endWordPosition="766">Connor et al., 2010; Liu, 2012; Loughran and Mcdonald, 2010; Pang and Lee, 2004; Turney, 2002). While most SA research is focused on discovering and classifying the expressions, some are also concerned with the targets of the expressions and explicitly identify the syntactic targets of sentiment expressions (Pang and Lee, 2004). Other related works belong to the Passage Retrieval field, since the relevance detection problem can be construed as a specific form of passage retrieval problem (Liu and Croft, 2002; Tiedemann and Mur, 2008). Different approaches were suggested for passage retrieval (Buscaldi et al., 2010; Comas et al., 2012; Hearst, 1997; Lafferty et al., 2001; Lin et al., 2012; Liu and Croft, 2002; Lloret et al., 2012; O’Connor et al., 2013; Otterbacher et al., 2009; Salton et al., 1993; Wachsmuth, 2013), some are more sophisticated than others. The closest approach to ours is the one of Scheible and Schütze (2013), but in contrast to them, we strive to discover sentiments&apos; relevance for all entities (of a given type) mentioned in the document, not necessarily topical. 3 Entity Relevance An instance of the sentiment relevance detection problem for a single entity consists of a text document,</context>
</contexts>
<marker>Buscaldi, Rosso, Gómez-Soriano, Sanchis, 2010</marker>
<rawString>Buscaldi, D., Rosso, P., Gómez-Soriano, J., Sanchis, E., 2010. Answering questions with an n-gram based passage retrieval engine. J. Intell. Inf. Syst. 34, 113–134. doi:10.1007/s10844-009-0082-y</rawString>
</citation>
<citation valid="true">
<authors>
<author>P R Comas</author>
<author>J Turmo</author>
<author>L Màrquez</author>
</authors>
<title>Sibyl, a factoid question-answering system for spoken documents.</title>
<date>2012</date>
<journal>ACM Trans. Inf. Syst.</journal>
<volume>30</volume>
<pages>19--1</pages>
<contexts>
<context position="4821" citStr="Comas et al., 2012" startWordPosition="767" endWordPosition="770">u, 2012; Loughran and Mcdonald, 2010; Pang and Lee, 2004; Turney, 2002). While most SA research is focused on discovering and classifying the expressions, some are also concerned with the targets of the expressions and explicitly identify the syntactic targets of sentiment expressions (Pang and Lee, 2004). Other related works belong to the Passage Retrieval field, since the relevance detection problem can be construed as a specific form of passage retrieval problem (Liu and Croft, 2002; Tiedemann and Mur, 2008). Different approaches were suggested for passage retrieval (Buscaldi et al., 2010; Comas et al., 2012; Hearst, 1997; Lafferty et al., 2001; Lin et al., 2012; Liu and Croft, 2002; Lloret et al., 2012; O’Connor et al., 2013; Otterbacher et al., 2009; Salton et al., 1993; Wachsmuth, 2013), some are more sophisticated than others. The closest approach to ours is the one of Scheible and Schütze (2013), but in contrast to them, we strive to discover sentiments&apos; relevance for all entities (of a given type) mentioned in the document, not necessarily topical. 3 Entity Relevance An instance of the sentiment relevance detection problem for a single entity consists of a text document, a sentiment express</context>
</contexts>
<marker>Comas, Turmo, Màrquez, 2012</marker>
<rawString>Comas, P.R., Turmo, J., Màrquez, L., 2012. Sibyl, a factoid question-answering system for spoken documents. ACM Trans. Inf. Syst. 30, 19:1–19:40. doi:10.1145/2328967.2328972</rawString>
</citation>
<citation valid="true">
<authors>
<author>B O Connor</author>
<author>R Balasubramanyan</author>
<author>B R Routledge</author>
<author>N A Smith</author>
</authors>
<title>From Tweets to Polls: Linking Text Sentiment to Public Opinion Time Series, in:</title>
<date>2010</date>
<booktitle>Proceedings of the Fourth International AAAI Conference on Weblogs and Social Media.</booktitle>
<pages>122--129</pages>
<contexts>
<context position="4199" citStr="Connor et al., 2010" startWordPosition="666" endWordPosition="669">vance region for each type calculated separately. We purposefully exclude possible interactions between entities of the same type, because they behave in a different way. The precise analysis of such interactions is a different topic from rele87 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 87–92, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics vance detection, and so it is mostly ignored in this paper. 2 Related Work The task of SA has drawn the attention of many researchers worldwide (Connor et al., 2010; Liu, 2012; Loughran and Mcdonald, 2010; Pang and Lee, 2004; Turney, 2002). While most SA research is focused on discovering and classifying the expressions, some are also concerned with the targets of the expressions and explicitly identify the syntactic targets of sentiment expressions (Pang and Lee, 2004). Other related works belong to the Passage Retrieval field, since the relevance detection problem can be construed as a specific form of passage retrieval problem (Liu and Croft, 2002; Tiedemann and Mur, 2008). Different approaches were suggested for passage retrieval (Buscaldi et al., 20</context>
</contexts>
<marker>Connor, Balasubramanyan, Routledge, Smith, 2010</marker>
<rawString>Connor, B.O., Balasubramanyan, R., Routledge, B.R., Smith, N.A., 2010. From Tweets to Polls: Linking Text Sentiment to Public Opinion Time Series, in: Proceedings of the Fourth International AAAI Conference on Weblogs and Social Media. pp. 122–129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Feldman</author>
<author>B Rosenfeld</author>
<author>R Bar-haim</author>
<author>M Fresko</author>
</authors>
<title>The Stock Sonar — Sentiment Analysis of Stocks Based on a Hybrid Approach, in:</title>
<date>2010</date>
<booktitle>Proceedings of the Twenty-Third Innovative Applications of Artificial Intelligence Conference.</booktitle>
<pages>1642--1647</pages>
<contexts>
<context position="10788" citStr="Feldman et al. (2010)" startWordPosition="1724" endWordPosition="1727">mentioning of an entity starts its relevance range (and stops the relevance range of the previously mentioned entity). For the first entity reference in a paragraph, the range also extends backward to the beginning of the sentence. There are three flavors of the algorithm, specifically adapted for different document-types-with-respect-tothe-target-entity: o &apos;Proximity-Accidental&apos; - stops relevance ranges at paragraph boundaries, o &apos;Proximity-Targeted&apos; - restarts relevance ranges at paragraph boundaries (every para1In our experiments, we also use a standalone automatic Financial SA system from Feldman et al. (2010), working in the &apos;ignore relevance&apos; mode, which (1) finds and labels all entities of the target type(s); (2) resolves all coreferences for the target entity type(s); (3) finds and labels all sentiment expressions, regardless of their relevance; and (4) provides dependency parses for all sentences in the corpus. graph is assumed relevant at the start, unless another entity is mentioned). o &apos;Proximity-List&apos; - interpolates relevance ranges over intermission paragraphs, unless they are explicitly irrelevant (e.g., containing references of other entities of the same type). • Syntactic-proximity-bas</context>
</contexts>
<marker>Feldman, Rosenfeld, Bar-haim, Fresko, 2010</marker>
<rawString>Feldman, R., Rosenfeld, B., Bar-haim, R., Fresko, M., 2010. The Stock Sonar — Sentiment Analysis of Stocks Based on a Hybrid Approach, in: Proceedings of the Twenty-Third Innovative Applications of Artificial Intelligence Conference. pp. 1642–1647.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Hearst</author>
</authors>
<title>TextTiling: segmenting text into multi-paragraph subtopic passages.</title>
<date>1997</date>
<journal>Comput. Linguist.</journal>
<volume>23</volume>
<pages>33--64</pages>
<contexts>
<context position="4835" citStr="Hearst, 1997" startWordPosition="771" endWordPosition="772">d Mcdonald, 2010; Pang and Lee, 2004; Turney, 2002). While most SA research is focused on discovering and classifying the expressions, some are also concerned with the targets of the expressions and explicitly identify the syntactic targets of sentiment expressions (Pang and Lee, 2004). Other related works belong to the Passage Retrieval field, since the relevance detection problem can be construed as a specific form of passage retrieval problem (Liu and Croft, 2002; Tiedemann and Mur, 2008). Different approaches were suggested for passage retrieval (Buscaldi et al., 2010; Comas et al., 2012; Hearst, 1997; Lafferty et al., 2001; Lin et al., 2012; Liu and Croft, 2002; Lloret et al., 2012; O’Connor et al., 2013; Otterbacher et al., 2009; Salton et al., 1993; Wachsmuth, 2013), some are more sophisticated than others. The closest approach to ours is the one of Scheible and Schütze (2013), but in contrast to them, we strive to discover sentiments&apos; relevance for all entities (of a given type) mentioned in the document, not necessarily topical. 3 Entity Relevance An instance of the sentiment relevance detection problem for a single entity consists of a text document, a sentiment expression within the</context>
</contexts>
<marker>Hearst, 1997</marker>
<rawString>Hearst, M.A., 1997. TextTiling: segmenting text into multi-paragraph subtopic passages. Comput. Linguist. 23, 33–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data., in:</title>
<date>2001</date>
<booktitle>Proceedings of the Eighteenth International Conference on Machine Learning (ICML-2001).</booktitle>
<contexts>
<context position="4858" citStr="Lafferty et al., 2001" startWordPosition="773" endWordPosition="776">10; Pang and Lee, 2004; Turney, 2002). While most SA research is focused on discovering and classifying the expressions, some are also concerned with the targets of the expressions and explicitly identify the syntactic targets of sentiment expressions (Pang and Lee, 2004). Other related works belong to the Passage Retrieval field, since the relevance detection problem can be construed as a specific form of passage retrieval problem (Liu and Croft, 2002; Tiedemann and Mur, 2008). Different approaches were suggested for passage retrieval (Buscaldi et al., 2010; Comas et al., 2012; Hearst, 1997; Lafferty et al., 2001; Lin et al., 2012; Liu and Croft, 2002; Lloret et al., 2012; O’Connor et al., 2013; Otterbacher et al., 2009; Salton et al., 1993; Wachsmuth, 2013), some are more sophisticated than others. The closest approach to ours is the one of Scheible and Schütze (2013), but in contrast to them, we strive to discover sentiments&apos; relevance for all entities (of a given type) mentioned in the document, not necessarily topical. 3 Entity Relevance An instance of the sentiment relevance detection problem for a single entity consists of a text document, a sentiment expression within the document, and a target</context>
<context position="13708" citStr="Lafferty et al. (2001)" startWordPosition="2176" endWordPosition="2179">ve-described pieces, with the pieces appearing before and after the sentiment expression tracked separately. For classification, we use a linear classifier with Large Margin training (regularized perceptron, as discussed in Scheible and Schütze, (2013)). • Sequence-classification-based - The algorithm uses exactly the same features as the direct classification-based above, but instead of considering each expression separately, it con89 siders them as a sequence, one per document. So, instead of a Large Margin binary classifier, a probabilistic sequence classifier is used (CRF, as discussed in Lafferty et al. (2001)). 5 Experiments For the experiments, we use two manuallyannotated corpora 2 , a financial corpus3 and a medical4 corpus. In the Financial corpus, COMPANIEs are used as target entities and in the medical corpus, DISEASEs, DRUGs and PERSONs are the entity types that are used as target entities. For the purpose of the experiments, we are interested only in single-entity sentiments about DRUGs, and multiple-entity sentiments about DRUGs + DISEASEs, and DRUGs + DISEASEs + PERSONs. The evaluation metrics in all of the experiments are precision, recall, and F1. For the classification-based algorithm</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>Lafferty, J., McCallum, A., Pereira, F., 2001. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data., in: Proceedings of the Eighteenth International Conference on Machine Learning (ICML-2001).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H-T Lin</author>
<author>N-W Chi</author>
<author>S-H Hsieh</author>
</authors>
<title>A concept-based information retrieval approach for engineering domain-specific technical documents.</title>
<date>2012</date>
<journal>Adv. Eng. Informatics</journal>
<volume>26</volume>
<pages>349--360</pages>
<contexts>
<context position="4876" citStr="Lin et al., 2012" startWordPosition="777" endWordPosition="780"> Turney, 2002). While most SA research is focused on discovering and classifying the expressions, some are also concerned with the targets of the expressions and explicitly identify the syntactic targets of sentiment expressions (Pang and Lee, 2004). Other related works belong to the Passage Retrieval field, since the relevance detection problem can be construed as a specific form of passage retrieval problem (Liu and Croft, 2002; Tiedemann and Mur, 2008). Different approaches were suggested for passage retrieval (Buscaldi et al., 2010; Comas et al., 2012; Hearst, 1997; Lafferty et al., 2001; Lin et al., 2012; Liu and Croft, 2002; Lloret et al., 2012; O’Connor et al., 2013; Otterbacher et al., 2009; Salton et al., 1993; Wachsmuth, 2013), some are more sophisticated than others. The closest approach to ours is the one of Scheible and Schütze (2013), but in contrast to them, we strive to discover sentiments&apos; relevance for all entities (of a given type) mentioned in the document, not necessarily topical. 3 Entity Relevance An instance of the sentiment relevance detection problem for a single entity consists of a text document, a sentiment expression within the document, and a target entity. The task </context>
</contexts>
<marker>Lin, Chi, Hsieh, 2012</marker>
<rawString>Lin, H.-T., Chi, N.-W., Hsieh, S.-H., 2012. A concept-based information retrieval approach for engineering domain-specific technical documents. Adv. Eng. Informatics 26, 349–360. doi:http://dx.doi.org/10.1016/j.aei.2011.12.003</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining Synthesis Lectures on Human Language Technologies.</title>
<date>2012</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="4210" citStr="Liu, 2012" startWordPosition="670" endWordPosition="671"> type calculated separately. We purposefully exclude possible interactions between entities of the same type, because they behave in a different way. The precise analysis of such interactions is a different topic from rele87 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 87–92, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics vance detection, and so it is mostly ignored in this paper. 2 Related Work The task of SA has drawn the attention of many researchers worldwide (Connor et al., 2010; Liu, 2012; Loughran and Mcdonald, 2010; Pang and Lee, 2004; Turney, 2002). While most SA research is focused on discovering and classifying the expressions, some are also concerned with the targets of the expressions and explicitly identify the syntactic targets of sentiment expressions (Pang and Lee, 2004). Other related works belong to the Passage Retrieval field, since the relevance detection problem can be construed as a specific form of passage retrieval problem (Liu and Croft, 2002; Tiedemann and Mur, 2008). Different approaches were suggested for passage retrieval (Buscaldi et al., 2010; Comas e</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Liu, B., 2012. Sentiment Analysis and Opinion Mining Synthesis Lectures on Human Language Technologies. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Liu</author>
<author>W B Croft</author>
</authors>
<title>Passage retrieval based on language models, in:</title>
<date>2002</date>
<booktitle>Proceedings of the Eleventh International Conference on Information and Knowledge Management, CIKM ’02.</booktitle>
<publisher>ACM,</publisher>
<location>New</location>
<contexts>
<context position="4693" citStr="Liu and Croft, 2002" startWordPosition="747" endWordPosition="750">nored in this paper. 2 Related Work The task of SA has drawn the attention of many researchers worldwide (Connor et al., 2010; Liu, 2012; Loughran and Mcdonald, 2010; Pang and Lee, 2004; Turney, 2002). While most SA research is focused on discovering and classifying the expressions, some are also concerned with the targets of the expressions and explicitly identify the syntactic targets of sentiment expressions (Pang and Lee, 2004). Other related works belong to the Passage Retrieval field, since the relevance detection problem can be construed as a specific form of passage retrieval problem (Liu and Croft, 2002; Tiedemann and Mur, 2008). Different approaches were suggested for passage retrieval (Buscaldi et al., 2010; Comas et al., 2012; Hearst, 1997; Lafferty et al., 2001; Lin et al., 2012; Liu and Croft, 2002; Lloret et al., 2012; O’Connor et al., 2013; Otterbacher et al., 2009; Salton et al., 1993; Wachsmuth, 2013), some are more sophisticated than others. The closest approach to ours is the one of Scheible and Schütze (2013), but in contrast to them, we strive to discover sentiments&apos; relevance for all entities (of a given type) mentioned in the document, not necessarily topical. 3 Entity Relevan</context>
</contexts>
<marker>Liu, Croft, 2002</marker>
<rawString>Liu, X., Croft, W.B., 2002. Passage retrieval based on language models, in: Proceedings of the Eleventh International Conference on Information and Knowledge Management, CIKM ’02. ACM, New</rawString>
</citation>
<citation valid="false">
<pages>375--382</pages>
<location>York, NY, USA,</location>
<marker></marker>
<rawString>York, NY, USA, pp. 375–382. doi:10.1145/584792.584854</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Lloret</author>
<author>A Balahur</author>
<author>J Gómez</author>
<author>A Montoyo</author>
<author>M Palomar</author>
</authors>
<title>Towards a unified framework for opinion retrieval, mining and summarization.</title>
<date>2012</date>
<journal>J. Intell. Inf. Syst.</journal>
<volume>39</volume>
<pages>711--747</pages>
<contexts>
<context position="4918" citStr="Lloret et al., 2012" startWordPosition="785" endWordPosition="788">is focused on discovering and classifying the expressions, some are also concerned with the targets of the expressions and explicitly identify the syntactic targets of sentiment expressions (Pang and Lee, 2004). Other related works belong to the Passage Retrieval field, since the relevance detection problem can be construed as a specific form of passage retrieval problem (Liu and Croft, 2002; Tiedemann and Mur, 2008). Different approaches were suggested for passage retrieval (Buscaldi et al., 2010; Comas et al., 2012; Hearst, 1997; Lafferty et al., 2001; Lin et al., 2012; Liu and Croft, 2002; Lloret et al., 2012; O’Connor et al., 2013; Otterbacher et al., 2009; Salton et al., 1993; Wachsmuth, 2013), some are more sophisticated than others. The closest approach to ours is the one of Scheible and Schütze (2013), but in contrast to them, we strive to discover sentiments&apos; relevance for all entities (of a given type) mentioned in the document, not necessarily topical. 3 Entity Relevance An instance of the sentiment relevance detection problem for a single entity consists of a text document, a sentiment expression within the document, and a target entity. The task is a binary decision: &apos;relevant&apos; vs. &apos;irre</context>
</contexts>
<marker>Lloret, Balahur, Gómez, Montoyo, Palomar, 2012</marker>
<rawString>Lloret, E., Balahur, A., Gómez, J., Montoyo, A., Palomar, M., 2012. Towards a unified framework for opinion retrieval, mining and summarization. J. Intell. Inf. Syst. 39, 711–747. doi:10.1007/s10844-012-0209-4</rawString>
</citation>
<citation valid="true">
<authors>
<author>T I M Loughran</author>
<author>B Mcdonald</author>
</authors>
<title>When is a Liability not a Liability? Textual Analysis , Dictionaries , and 10-Ks</title>
<date>2010</date>
<journal>Journal of Finance , forthcoming. J. Finance</journal>
<volume>66</volume>
<pages>35--65</pages>
<contexts>
<context position="4239" citStr="Loughran and Mcdonald, 2010" startWordPosition="672" endWordPosition="675">lated separately. We purposefully exclude possible interactions between entities of the same type, because they behave in a different way. The precise analysis of such interactions is a different topic from rele87 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 87–92, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics vance detection, and so it is mostly ignored in this paper. 2 Related Work The task of SA has drawn the attention of many researchers worldwide (Connor et al., 2010; Liu, 2012; Loughran and Mcdonald, 2010; Pang and Lee, 2004; Turney, 2002). While most SA research is focused on discovering and classifying the expressions, some are also concerned with the targets of the expressions and explicitly identify the syntactic targets of sentiment expressions (Pang and Lee, 2004). Other related works belong to the Passage Retrieval field, since the relevance detection problem can be construed as a specific form of passage retrieval problem (Liu and Croft, 2002; Tiedemann and Mur, 2008). Different approaches were suggested for passage retrieval (Buscaldi et al., 2010; Comas et al., 2012; Hearst, 1997; La</context>
</contexts>
<marker>Loughran, Mcdonald, 2010</marker>
<rawString>Loughran, T.I.M., Mcdonald, B., 2010. When is a Liability not a Liability? Textual Analysis , Dictionaries , and 10-Ks Journal of Finance , forthcoming. J. Finance 66, 35–65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B O’Connor</author>
<author>B M Stewart</author>
<author>N A Smith</author>
</authors>
<title>Learning to Extract International Relations from Political Context, in:</title>
<date>2013</date>
<booktitle>Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Association for Computational Linguistics,</booktitle>
<pages>1094--1104</pages>
<location>Sofia, Bulgaria,</location>
<marker>O’Connor, Stewart, Smith, 2013</marker>
<rawString>O’Connor, B., Stewart, B.M., Smith, N.A., 2013. Learning to Extract International Relations from Political Context, in: Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Association for Computational Linguistics, Sofia, Bulgaria, pp. 1094–1104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Otterbacher</author>
<author>G Erkan</author>
<author>D R Radev</author>
</authors>
<title>Biased LexRank: Passage retrieval using random walks with question-based priors.</title>
<date>2009</date>
<journal>Inf. Process. Manag.</journal>
<volume>45</volume>
<pages>42--54</pages>
<contexts>
<context position="4967" citStr="Otterbacher et al., 2009" startWordPosition="793" endWordPosition="796">e expressions, some are also concerned with the targets of the expressions and explicitly identify the syntactic targets of sentiment expressions (Pang and Lee, 2004). Other related works belong to the Passage Retrieval field, since the relevance detection problem can be construed as a specific form of passage retrieval problem (Liu and Croft, 2002; Tiedemann and Mur, 2008). Different approaches were suggested for passage retrieval (Buscaldi et al., 2010; Comas et al., 2012; Hearst, 1997; Lafferty et al., 2001; Lin et al., 2012; Liu and Croft, 2002; Lloret et al., 2012; O’Connor et al., 2013; Otterbacher et al., 2009; Salton et al., 1993; Wachsmuth, 2013), some are more sophisticated than others. The closest approach to ours is the one of Scheible and Schütze (2013), but in contrast to them, we strive to discover sentiments&apos; relevance for all entities (of a given type) mentioned in the document, not necessarily topical. 3 Entity Relevance An instance of the sentiment relevance detection problem for a single entity consists of a text document, a sentiment expression within the document, and a target entity. The task is a binary decision: &apos;relevant&apos; vs. &apos;irrelevant&apos;. To solve this task, we can use any infor</context>
</contexts>
<marker>Otterbacher, Erkan, Radev, 2009</marker>
<rawString>Otterbacher, J., Erkan, G., Radev, D.R., 2009. Biased LexRank: Passage retrieval using random walks with question-based priors. Inf. Process. Manag. 45, 42–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts.</title>
<date>2004</date>
<contexts>
<context position="4259" citStr="Pang and Lee, 2004" startWordPosition="676" endWordPosition="679">ully exclude possible interactions between entities of the same type, because they behave in a different way. The precise analysis of such interactions is a different topic from rele87 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 87–92, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics vance detection, and so it is mostly ignored in this paper. 2 Related Work The task of SA has drawn the attention of many researchers worldwide (Connor et al., 2010; Liu, 2012; Loughran and Mcdonald, 2010; Pang and Lee, 2004; Turney, 2002). While most SA research is focused on discovering and classifying the expressions, some are also concerned with the targets of the expressions and explicitly identify the syntactic targets of sentiment expressions (Pang and Lee, 2004). Other related works belong to the Passage Retrieval field, since the relevance detection problem can be construed as a specific form of passage retrieval problem (Liu and Croft, 2002; Tiedemann and Mur, 2008). Different approaches were suggested for passage retrieval (Buscaldi et al., 2010; Comas et al., 2012; Hearst, 1997; Lafferty et al., 2001;</context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>Pang, B., Lee, L., 2004. A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>J Allan</author>
<author>C Buckley</author>
</authors>
<title>Approaches to passage retrieval in full text information systems, in:</title>
<date>1993</date>
<booktitle>Proceedings of the 16th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’93.</booktitle>
<pages>49--58</pages>
<publisher>ACM,</publisher>
<location>New York, NY, USA,</location>
<contexts>
<context position="4988" citStr="Salton et al., 1993" startWordPosition="797" endWordPosition="800">so concerned with the targets of the expressions and explicitly identify the syntactic targets of sentiment expressions (Pang and Lee, 2004). Other related works belong to the Passage Retrieval field, since the relevance detection problem can be construed as a specific form of passage retrieval problem (Liu and Croft, 2002; Tiedemann and Mur, 2008). Different approaches were suggested for passage retrieval (Buscaldi et al., 2010; Comas et al., 2012; Hearst, 1997; Lafferty et al., 2001; Lin et al., 2012; Liu and Croft, 2002; Lloret et al., 2012; O’Connor et al., 2013; Otterbacher et al., 2009; Salton et al., 1993; Wachsmuth, 2013), some are more sophisticated than others. The closest approach to ours is the one of Scheible and Schütze (2013), but in contrast to them, we strive to discover sentiments&apos; relevance for all entities (of a given type) mentioned in the document, not necessarily topical. 3 Entity Relevance An instance of the sentiment relevance detection problem for a single entity consists of a text document, a sentiment expression within the document, and a target entity. The task is a binary decision: &apos;relevant&apos; vs. &apos;irrelevant&apos;. To solve this task, we can use any information that can be fo</context>
</contexts>
<marker>Salton, Allan, Buckley, 1993</marker>
<rawString>Salton, G., Allan, J., Buckley, C., 1993. Approaches to passage retrieval in full text information systems, in: Proceedings of the 16th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’93. ACM, New York, NY, USA, pp. 49–58. doi:10.1145/160688.160693</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Scheible</author>
<author>H Schütze</author>
</authors>
<title>Sentiment Relevance, in:</title>
<date>2013</date>
<booktitle>Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Association for Computational Linguistics,</booktitle>
<pages>954--963</pages>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="5119" citStr="Scheible and Schütze (2013)" startWordPosition="819" endWordPosition="822">ng and Lee, 2004). Other related works belong to the Passage Retrieval field, since the relevance detection problem can be construed as a specific form of passage retrieval problem (Liu and Croft, 2002; Tiedemann and Mur, 2008). Different approaches were suggested for passage retrieval (Buscaldi et al., 2010; Comas et al., 2012; Hearst, 1997; Lafferty et al., 2001; Lin et al., 2012; Liu and Croft, 2002; Lloret et al., 2012; O’Connor et al., 2013; Otterbacher et al., 2009; Salton et al., 1993; Wachsmuth, 2013), some are more sophisticated than others. The closest approach to ours is the one of Scheible and Schütze (2013), but in contrast to them, we strive to discover sentiments&apos; relevance for all entities (of a given type) mentioned in the document, not necessarily topical. 3 Entity Relevance An instance of the sentiment relevance detection problem for a single entity consists of a text document, a sentiment expression within the document, and a target entity. The task is a binary decision: &apos;relevant&apos; vs. &apos;irrelevant&apos;. To solve this task, we can use any information that can be found by analyzing the document. Thus, we can assume that we know the parse trees of all sentences and the locations of all reference</context>
<context position="13338" citStr="Scheible and Schütze, (2013)" startWordPosition="2119" endWordPosition="2122">nput. In the current experiments, we use references of target and non-target entities, appearances of paragraph and document boundaries, length of syntactic connections to target and non-target entities, when available, and explicit entity status within documents, when available. The (binary) classification features are built from sequences of up to 5 occurrences of the above-described pieces, with the pieces appearing before and after the sentiment expression tracked separately. For classification, we use a linear classifier with Large Margin training (regularized perceptron, as discussed in Scheible and Schütze, (2013)). • Sequence-classification-based - The algorithm uses exactly the same features as the direct classification-based above, but instead of considering each expression separately, it con89 siders them as a sequence, one per document. So, instead of a Large Margin binary classifier, a probabilistic sequence classifier is used (CRF, as discussed in Lafferty et al. (2001)). 5 Experiments For the experiments, we use two manuallyannotated corpora 2 , a financial corpus3 and a medical4 corpus. In the Financial corpus, COMPANIEs are used as target entities and in the medical corpus, DISEASEs, DRUGs an</context>
</contexts>
<marker>Scheible, Schütze, 2013</marker>
<rawString>Scheible, C., Schütze, H., 2013. Sentiment Relevance, in: Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Association for Computational Linguistics, Sofia, Bulgaria, pp. 954–963.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Tiedemann</author>
<author>J Mur</author>
</authors>
<title>Simple is best: experiments with different document segmentation strategies for passage retrieval, in: Coling</title>
<date>2008</date>
<booktitle>Proceedings of the 2nd Workshop on Information Retrieval for Question Answering, IRQA ’08. Association for Computational Linguistics,</booktitle>
<pages>17--25</pages>
<location>Stroudsburg, PA, USA,</location>
<contexts>
<context position="4719" citStr="Tiedemann and Mur, 2008" startWordPosition="751" endWordPosition="754">2 Related Work The task of SA has drawn the attention of many researchers worldwide (Connor et al., 2010; Liu, 2012; Loughran and Mcdonald, 2010; Pang and Lee, 2004; Turney, 2002). While most SA research is focused on discovering and classifying the expressions, some are also concerned with the targets of the expressions and explicitly identify the syntactic targets of sentiment expressions (Pang and Lee, 2004). Other related works belong to the Passage Retrieval field, since the relevance detection problem can be construed as a specific form of passage retrieval problem (Liu and Croft, 2002; Tiedemann and Mur, 2008). Different approaches were suggested for passage retrieval (Buscaldi et al., 2010; Comas et al., 2012; Hearst, 1997; Lafferty et al., 2001; Lin et al., 2012; Liu and Croft, 2002; Lloret et al., 2012; O’Connor et al., 2013; Otterbacher et al., 2009; Salton et al., 1993; Wachsmuth, 2013), some are more sophisticated than others. The closest approach to ours is the one of Scheible and Schütze (2013), but in contrast to them, we strive to discover sentiments&apos; relevance for all entities (of a given type) mentioned in the document, not necessarily topical. 3 Entity Relevance An instance of the sent</context>
</contexts>
<marker>Tiedemann, Mur, 2008</marker>
<rawString>Tiedemann, J., Mur, J., 2008. Simple is best: experiments with different document segmentation strategies for passage retrieval, in: Coling 2008: Proceedings of the 2nd Workshop on Information Retrieval for Question Answering, IRQA ’08. Association for Computational Linguistics, Stroudsburg, PA, USA, pp. 17–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Turney</author>
</authors>
<title>Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews, in:</title>
<date>2002</date>
<booktitle>Proceedings of the Association for Computational Linguistics (ACL).</booktitle>
<pages>417--424</pages>
<contexts>
<context position="4274" citStr="Turney, 2002" startWordPosition="680" endWordPosition="681">e interactions between entities of the same type, because they behave in a different way. The precise analysis of such interactions is a different topic from rele87 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 87–92, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics vance detection, and so it is mostly ignored in this paper. 2 Related Work The task of SA has drawn the attention of many researchers worldwide (Connor et al., 2010; Liu, 2012; Loughran and Mcdonald, 2010; Pang and Lee, 2004; Turney, 2002). While most SA research is focused on discovering and classifying the expressions, some are also concerned with the targets of the expressions and explicitly identify the syntactic targets of sentiment expressions (Pang and Lee, 2004). Other related works belong to the Passage Retrieval field, since the relevance detection problem can be construed as a specific form of passage retrieval problem (Liu and Croft, 2002; Tiedemann and Mur, 2008). Different approaches were suggested for passage retrieval (Buscaldi et al., 2010; Comas et al., 2012; Hearst, 1997; Lafferty et al., 2001; Lin et al., 20</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Turney, P., 2002. Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews, in: Proceedings of the Association for Computational Linguistics (ACL). pp. 417–424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Wachsmuth</author>
</authors>
<title>Information Extraction as a Filtering Task Categories and Subject Descriptors, in: To Appear in</title>
<date>2013</date>
<booktitle>Proc. of the 22th ACM CIKM.</booktitle>
<contexts>
<context position="5006" citStr="Wachsmuth, 2013" startWordPosition="801" endWordPosition="802"> targets of the expressions and explicitly identify the syntactic targets of sentiment expressions (Pang and Lee, 2004). Other related works belong to the Passage Retrieval field, since the relevance detection problem can be construed as a specific form of passage retrieval problem (Liu and Croft, 2002; Tiedemann and Mur, 2008). Different approaches were suggested for passage retrieval (Buscaldi et al., 2010; Comas et al., 2012; Hearst, 1997; Lafferty et al., 2001; Lin et al., 2012; Liu and Croft, 2002; Lloret et al., 2012; O’Connor et al., 2013; Otterbacher et al., 2009; Salton et al., 1993; Wachsmuth, 2013), some are more sophisticated than others. The closest approach to ours is the one of Scheible and Schütze (2013), but in contrast to them, we strive to discover sentiments&apos; relevance for all entities (of a given type) mentioned in the document, not necessarily topical. 3 Entity Relevance An instance of the sentiment relevance detection problem for a single entity consists of a text document, a sentiment expression within the document, and a target entity. The task is a binary decision: &apos;relevant&apos; vs. &apos;irrelevant&apos;. To solve this task, we can use any information that can be found by analyzing t</context>
</contexts>
<marker>Wachsmuth, 2013</marker>
<rawString>Wachsmuth, H., 2013. Information Extraction as a Filtering Task Categories and Subject Descriptors, in: To Appear in Proc. of the 22th ACM CIKM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>