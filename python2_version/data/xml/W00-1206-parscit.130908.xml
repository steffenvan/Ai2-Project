<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.984413">
Enhancement of a Chinese Discourse Marker Tagger with C4.5
</title>
<author confidence="0.995422">
Benjamin K. T&apos;sou&apos;, Torn B. Y. Lai&apos;, Samuel W. K. Chan&apos;, Weijun Gao4, Xuegang Zhans
</author>
<affiliation confidence="0.8667556">
123Language Information Sciences Research Centre
City University of Hong Kong
Tat Chee Avenue, Kowloon
Hong Kong SAR, China
Northeastern University, China
</affiliation>
<address confidence="0.481566">
{ &apos;rlbtsou, 2cttomlai}@uxmail.cityu.edu.h1c, 3swkchan@cs.cityu.edu.hk,
</address>
<email confidence="0.985021">
4wjgao@mail.neu.edu.cn, szxg@ics.cs.neu.edu.cn
</email>
<sectionHeader confidence="0.995458" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.989569">
Discourse markers are complex
discontinuous linguistic expressions which
are used to explicitly signal the discourse
structure of a text. This paper describes
efforts to improve an automatic tagging
system which identifies and classifies
discourse markers in Chinese texts by
applying machine learning (ML) to the
disambiguation of discourse markers, as an
integral part of automatic text summarization
via rhetorical structure. Encouraging results
are reported.
Keywords: discourse marker, Chinese
corpus, rhetorical relation, automatic tagging,
machine learning
</bodyText>
<sectionHeader confidence="0.999163" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999856171428572">
Discourse refers to any form of
language-based communication involving
multiple sentences or utterances. The most
important forms of discourse of interest to
Natural Language Processing (NLP) are text
and dialogue. The function of discourse
analysis is to divide a text into discourse
segments, and to recognize and re-construct
the discourse structure of the text as intended
by its author.
Automatic text abstraction has received
considerable attention (Paice 1990). Various
systems have been developed (Chan et al.
2000). Ono et al. (1994), T&apos;sou et al. (1992)
and Marcu (1997) focus on discourse
structure in summarization using the
Rhetorical Structure Theory (RST, Mann and
Thompson 1986). The theory has been
exploited in a number of computational
systems (e.g. Hovy 1993). The main idea is
to build a discourse tree where each node of
the tree represents an RST relation.
Summarization is achieved by trimming
unimportant sentences on the basis of the
relative saliency or rhetorical relations.
The SIFAS (Syntactic Marker based
Full-Text Abstraction System) system has
been implemented to use discourse markers
in the automatic summarization of Chinese
(T&apos;sou et al. 1999). In this paper, we report
our efforts to improve the SIFAS tagging
system by applying machine learning
techniques to disambiguation of discourse
markers. C4.5 (Quinlan, 1993) is used in our
system.
</bodyText>
<sectionHeader confidence="0.966497" genericHeader="method">
2 Manual Tagging Process
</sectionHeader>
<bodyText confidence="0.9053495">
To tag the discourse markers, the
following coding scheme is designed to
encode Real Discourse Markers (RDM)
appearing in the SIFAS corpus (T&apos;sou et al.
1998). We describe the jib discourse marker
with a 7-tuple RDM,:
RDM,=&lt; DM,, RR, , RP,, CT,, MN.,
RN,, 0T1&gt;, where
</bodyText>
<page confidence="0.995326">
38
</page>
<note confidence="0.623203666666667">
DM; : the lexical item of the
Discourse Marker, or the
value &apos;NULL&apos;.
</note>
<bodyText confidence="0.867201743589744">
RR; : the Rhetorical Relation in
which DM; is a constituent
marker.
RP; : the Relative Position of DMi.
CT; : the Connection Type of RR; .
MN; : the Discourse Marker
Sequence Number.
RN; : the Rhetorical Relation
Sequence Number.
OT; : the Order Type of RR;. The
value of OT; can be 1,-i or 0,
denoting respectively the
normal order, reverse order or
irrelevance of the premise-
consequence ordering of RR;.
For apparent discourse markers that do
not function as a real discourse marker in a
text, a different coding scheme is used to
encode them. We describe the th apparent
discourse marker using a 3-Tuple ADMi:
ADM;=&lt; LI;, *, SN; &gt;, where
LI; : the Lexical Item of the
apparent discourse marker.
SN; : the Sequence Number of the
apparent discourse marker.
In Chinese, discourse markers can be
either words or phrases. To tag the SIFAS
corpus, all discourse markers are organized
into a discourse marker pair-rhetorical
relation correspondence table. Part of the
table is shown Table 1.
To construct an automatic tagging
system, let us first examine the sequential
steps in the tagging process of a human
tagger.
Si. Written Chinese consists of running texts
without word delimiters; the first step is
is to segment the text into Chinese word
sequences.
</bodyText>
<listItem confidence="0.796012333333333">
S2. On the basis of a discourse marker list,
we identify those words in the text
which appear on the list as Candidate
Discourse Markers (CDMs).
S3. To winnow Real Discourse Markers
(RDMs) and Apparent Discourse
Markers (ADMs) from the CDMs, and
encode the ADMs with a 3-tuple.
S4. To encode the RDM with a 7-tuple
according to a Discourse Marker Pair-
Rhetorical Relation correspondence
table.
</listItem>
<table confidence="0.997118916666667">
Relat- Front Back Con- Order
ion nection Type
Type
Adver- 151A Inter 1
sativity
Adver- TU. A Infra 1
sativity
Causa- IN t ffi jj, Intra 1
lity
Causa- Z Efi Intra -1
lity W.
•
</table>
<tableCaption confidence="0.845854">
Table 1 Discourse Marker Pair-
Rhetorical Relation Table
</tableCaption>
<sectionHeader confidence="0.930729" genericHeader="method">
3 Automatic Tagging Process
</sectionHeader>
<bodyText confidence="0.999911142857143">
The identification of candidate discourse
markers is based on a discourse marker list,
which now contains 306 discourse markers
plus a NULL marker. The markers are
extracted from newspaper editorials of Hong
Kong, Mainland China, Taiwan and
Singapore. These markers constitute 480
distinct discontinuous pairs that correspond
to 25 rhetorical relations. In actual usage,
some discourse marker pairs designate
multiple rhetorical relations according to
context. Some pairs can represent both
INTER-sentence and INTRA-sentence
relations. Thus the correspondence between
the discourse marker pairs and the rhetorical
relations is not single-valued. Some
discourse marker pairs correspond to more
than one rhetorical relation or connection
type. We have 504 correspondences between
the discourse marker pairs and the rhetorical
relations.
</bodyText>
<page confidence="0.998884">
39
</page>
<bodyText confidence="0.9998162">
In practice, one discontinuous
constituent member of a marker pair is often
omitted. We use the NULL marker to
indicate the omission. In the 504
correspondences, 244 of them are double
constituent marker pairs, 260 are single
constituent markers (i.e. One of the markers
is NULL). And in the 244 double constituent
markers, only 3 are not single-valued
correspondences (one of which is an
INTER/INTRA relation, and can easily be
distinguished.). Thus the tagging of the 244
double constituent markers is basically a
table searching process. But for the 260
single constituent markers, the identity of the
NULL marker is often difficult to determine.
The SIFAS tagging system works in two
modes: automatic and interactive (semi-
automatic). The automatic tagging procedure
is as follows:
</bodyText>
<listItem confidence="0.984421166666667">
1. Data preparation: Input data files are
modified according to the required
format.
2. Word segmentation: Because there are
no delimiters between Chinese words in
a text, words have to be extracted
through a segmentation process.
3. CDM identification
4. Full-Marker RDM recognition
5. ADM identification (first pass,
deterministic)
6. CDM feature extraction
7. ADM identification (2nd pass, via ML)
8. Tagging NULL-marker CDM pairs (via
ML)
9. ADM and RDM sequencing, proof-
reading, training data generation, and
statistics
</listItem>
<bodyText confidence="0.98501125">
The following principles are adopted by
the tagging algorithm to resolve ambiguity in
the process of matching discontinuous
discourse markers:
</bodyText>
<listItem confidence="0.962863407407407">
1. the principle of greediness: When
matching a pair of discourse markers for
a rhetorical relation, priority is given to
the first matched relation from the left.
2. the principle of locality: When
matching a pair of discourse markers for
a rhetorical relation, priority is given to
the relation where the distance between
its constituent markers is shortest.
3. the principle of explicitness: When
matching a pair of discourse markers for
a rhetorical relation, priority is given to
the relation where both markers are
explicitly presented.
4. the principle of superiority: When
matching a pair of discourse markers for
a rhetorical relation, priority is given to
the inter-sentence relation whose back
discourse marker matched with the first
word of a sentence.
5. the principle of Back-marker
preference: This is applicable only to
rhetorical relations where either the
front or the back marker is absent, or to
a NULL marker. In such cases, priority
is given to the relation with the back
marker present.
</listItem>
<bodyText confidence="0.99987875">
Steps 1 to 6 and the five principles
underlie the original naïve tagger of the
SIFAS system (T&apos;sou et al. 1998), which also
contains the system framework.
</bodyText>
<sectionHeader confidence="0.999475" genericHeader="method">
4 Improvement
</sectionHeader>
<subsectionHeader confidence="0.999201">
4.1 Problems
</subsectionHeader>
<bodyText confidence="0.99998565">
Many Chinese discourse markers have
both discourse senses and alternate sentential
senses in different context. For a human
tagger, steps S3 and S4 in section 2 are not
difficult because he/she can identify an
ADM/RDM based on his/her text
comprehension. However, for an automatic
process, it is quite difficult to distinguish an
ADM from an RDM if no syntactic/semantic
information is available.
Another problem is the location of
NULL-Marker described above. Our earlier
statistics showed some characteristics in the
distance measured by punctuation marks.
Statistics from 80 tagged editorials show that
most of the relations are INTRA-Sentence
relations (about 93%), about 70% of the
INTRA RDM pairs have NULL markers.
Most of these RDM pairs are separated by
ONE comma (62%). These statistics show
</bodyText>
<page confidence="0.992212">
40
</page>
<bodyText confidence="0.998956347826087">
the importance of the problems of
positioning the NULL markers.
The naive tagger partially solved the
CDM discrimination and NULL marker
location problems. Our experiment shows
that about 45% of the ADMs can be
correctly identified, and about 60% of the
NULL markers can be correctly located one
comma/period away from the current RDM.
This leaves much room for improvement.
One solution is to add a few rules
according to previous statistics. The original
naive tagger did not assume any knowledge
of the statistics and behavioral patterns of
discourse markers. From the error analysis,
we extracted some additional rules to guide
the classification and matching of the
discourse markers. For example, one of the
rules we extracted is:
&amp;quot;A matching pair must be separated by
at least two words or by punctuation
marks&amp;quot;. Using this rule, the following
full marker matching error is avoided.
</bodyText>
<construct confidence="0.836442">
if ,conjunction,Front,Intra,5,5,1&gt;&lt; ** &gt;&lt; if,
conjunction, Back, Intra, 6,5,1&gt;&lt;V&gt;, &lt;Mfli&gt;&lt;71(
</construct>
<equation confidence="0.8053245">
±M*&gt;&lt;4&gt;&lt;115&gt;&lt;Iti&gt; , ,*,7&gt;&lt;A11, 3&gt;&lt;
&gt;&lt;1f
</equation>
<bodyText confidence="0.996182333333333">
Another solution is to use
syntactic/semantic information through
machine learning.
</bodyText>
<subsectionHeader confidence="0.990866">
4.2 C4.5
</subsectionHeader>
<bodyText confidence="0.998307166666666">
Most empirical learning systems are
given a set of pre-classified cases, each
described by a vector of attribute values, and
construct from them a mapping from
attribute values to classes. C4.5 is one such
system that learns decision-tree classifiers. It
uses a divide-and-conquer approach to
growing decision trees. The current version
of C4.5 is C5.0 for Unix and See5 for
Windows.
Let attributes be denoted A=fal, a2, ...,
a,, j, cases be denoted D=(d„ d2, dj, and
classes be denoted C&apos;=&amp;quot;c,, c,, ..., cii. For a
set of cases D, a test 7; is a split of D based
on attribute ai. It splits D into mutually
exclusive subsets Dp 1)2, Dr These
subsets of cases are single-class collections
of cases.
If a test T is chosen, the decision tree
for D consists of a node identifying the test
T, and one branch for each possible subset
Di. For each subset Di, a new test is then
chosen for further split. If Di satisfies a
stopping criterion, the tree for Di is a leaf
associated with the most frequent class in Di.
One reason for stopping is that cases in Di
belong to one class.
C4.5 uses arg max(gain(D,T)) or arg
max(gain ratio (D,T)) to choose tests for
split:
</bodyText>
<equation confidence="0.992519166666667">
Info(D) = p(ci, D)* log 2(p(o, D))
Split (D,T) = —±1 Rd *log2(1221)
D I D I
xe, I I
Gain(D,T) = Info(D)— Info(Di)
Gain ratio(D,T) = gain(D,T) I Split (D,T)
</equation>
<bodyText confidence="0.9999215">
where, p(c,D) denotes the proportion of
cases in D that belong to the ith class.
</bodyText>
<subsectionHeader confidence="0.999596">
4.3 Application of C4.5
</subsectionHeader>
<bodyText confidence="0.999131894736842">
Since using semantic information
requires a comprehensive thesaurus, which is
unavailable at present, we only use syntactic
information through machine learning.
The attributes used in the original
SIFAS system include the candidate
discourse marker itself, two words
immediately to the left of the CDM, and two
words immediately to the right of the CDM.
The attribute names are F2, F1, CDM, Bl,
B2, respectively (T&apos;sou et al, 1999). SIFAS
only uses the Part Of Speech attribute of the
neighboring words. This reflects to some
degree the syntactic characteristics of the
CDM.
To reflect the distance characteristics,
we add two other attributes: the number of
discourse delimiters (commas, semicolons
for INTRA-sentence relation, periods and
</bodyText>
<page confidence="0.99873">
41
</page>
<bodyText confidence="0.998044269230769">
exclamation marks for INTER-sentence
relation) before and after the current CDM,
denoted Fcom and Bcom, respectively. For
the location of the NULL marker, we still
add an actual number of delimiters Acorn.
The order of these attributes is: CDM,
Fl, F2, Bi, B2, Fcom, Bcom Acorn for Null
marker location, and CDM, Fl, F2, Bi, B2,
Fcom, Bcom, IsRDM for CDM classification,
where IsRDM is a Boolean value.
The following are two examples of
cases:
4 _EL ,?,q,a,a,7,1,1 for NULL marker
location
M,d,?,u,?,1,0,F for CDM classificati
on
where &amp;quot;?&amp;quot; denotes that no corresponding
word is at the position (beginning or end of
sentence); a, d, q, and u are part-of-speech
symbols in our segmentation dictionary,
representing adjective, adverb, classifier, and
auxiliary, respectively.
The following are two examples of the
rules generated by the C4.5. The first is a
CDM classification rule, and the other is a
NULL marker location rule.
</bodyText>
<equation confidence="0.9690814">
Rule 5: (11/1, lift 2.2)
CDM = 4
B1 =v
Fcom &gt; 0
4 class T [0.846]
</equation>
<bodyText confidence="0.9936895">
which can be explained as: if the word after
the CDM &amp;quot;#&amp;quot; is a verb, and there is one
comma in the sentence, before &amp;quot;#&amp;quot;, then
&amp;quot;4&amp;quot; is an RDM.
</bodyText>
<equation confidence="0.95337325">
Rule 22: (1, lift 3.4)
B2 = p
Fcom &gt; 1
—) class 2 [0.667]
</equation>
<bodyText confidence="0.9989838">
which can be explained as: if the second
word after the RDM is a preposition, and
there is more then one commas before the
current RDM, then the location of the NULL
marker is two commas away from the RDM.
</bodyText>
<subsectionHeader confidence="0.916947">
4.4 Objects in the SIFAS system
</subsectionHeader>
<bodyText confidence="0.9948185">
The objects in the new SIFAS tagging
system are listed below.
</bodyText>
<listItem confidence="0.987148909090909">
1. Dictionary Editor: for the update of
word segmentation dictionary and the
rhetorical relation table.
2. Data Manager: for the modification of
the input data (editorial texts) to
conform with the required format.
3. Word Segmenter: for the segmentation
of the original texts, and the recognition
of CDMs.
4. RDM Tagger: The initial identification
of RDMs is a table searching process.
</listItem>
<bodyText confidence="0.9907834">
All those full-marker pairs are identified
as rhetorical relations according to the
principles described above. For those
Null-marker pairs, the location of the
Null maker is left to the rule interpreter.
</bodyText>
<listItem confidence="0.846192">
5. ADM Tagger: The identification of
ADMs is also a table searching process,
</listItem>
<bodyText confidence="0.594860428571429">
because, without other
syntactic/semantic information, the only
way to identify ADMs from the CDMs
is to find out that the CDM cannot form
a valid pair with any other CDMs
(including the NULL marker) to
correspond to a rhetorical relation.
</bodyText>
<listItem confidence="0.9808175">
6. CDM Feature Extractor: For those
untagged CDMs, the classification is
</listItem>
<bodyText confidence="0.832602333333333">
carried out through C4.5. The Feature
Extractor extracts syntactic information
about the current CDM and send it to the
Rule Interpreter (see below).
7. Rule Interpreter: C4.5 takes feature data
file as the input to construct a classifier,
and the rules formed are stored in an
output file. The rule interpreter reads
this output file and applies the rules to
</bodyText>
<listItem confidence="0.9673938">
classify the CDMs. In our system, The
Rule Interpreter functions as a NULL
Marker Locator and a CDM classifier.
8. Sequencer: for the rearrangement of
RDM and ADM order number. In the
rearranging process, the Sequencer also
extracts statistical information for
analysis.
9. Interaction Recorder: for the recording
of user interaction information for
</listItem>
<page confidence="0.9967">
42
</page>
<bodyText confidence="0.649149">
statistics use.
10. Data Retriever: for data retrieval and
browsing.
</bodyText>
<sectionHeader confidence="0.976251" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999806529411765">
In order to evaluate the effectiveness of
the tagging system in terms of the percentage
of discourse markers that can be tagged
correctly, we have chosen 80 tagged
editorials from Ming Pao, a Chinese
newspaper of Hong Kong, in the duration
from December 1995 to January 1996 to
form a training data set. Then we randomly
selected 20 editorials from Mainland China
and Hong Kong newspapers for the system
to tag automatically, and then manually
checked the results.
The total CDMs in the training data set
is 4764, in which 2116 are RDMs and 2648
are ADMs. The distribution of INTER-
sentence relations, INTRA-sentence relations,
and NULL marker pairs is shown below.
</bodyText>
<table confidence="0.999862142857143">
Total Inter- Intra- Relations
Relations Sentence Sentence with
Relations Relations NULL
marker
pair
1589 98 1491 1062
100% 6.17% 93.83% 66.83%
</table>
<tableCaption confidence="0.708725">
Table 2 Distribution of INTER-/INTRA-
sentence relations,
and NULL marker pairs
</tableCaption>
<bodyText confidence="0.999117888888889">
Our evaluation is based on counting the
number of discourse markers that are
correctly and incorrectly tagged.
The total CDMs in the test data set is
1134, in which 563 are RDMs and 571 are
ADMs. The distribution of INTER-sentence
relations, INTRA-sentence relations, and
NULL marker pairs in the test data set is
shown in Table 3.
</bodyText>
<table confidence="0.999911571428571">
Total Inter- Intra- Relations
Relations Sentence Sentence with
Relations Relations NULL
marker
Pair •
424 23 401 285
100% 5.42% 94.58% 67.22%
</table>
<tableCaption confidence="0.992046666666667">
Table 3 Distribution of INTER-/INTRA-
sentence relations, and NULL marker
pairs in testing data set
</tableCaption>
<table confidence="0.99194025">
Tagged &gt;-, Full Other
Relations marker errors
a h° Z E ¢ A
451 399 11 1 65 3
</table>
<tableCaption confidence="0.998262">
Table 4 Test Results
</tableCaption>
<bodyText confidence="0.90066724137931">
From the test results shown in Table 4,
we can see that most of the errors are caused
by the misclassification of the CDMs. An
example of Other errors is shown below.
The following sentence is from an editorial
of People&apos;s Daily.
&lt; tiCIii &gt;&lt; 4 &gt;&lt; X &gt; P
&lt;NULL,sufficiency,Front,Intra,0,81,1&gt;&lt;— II
&gt;&lt;n&gt;&lt;Et1&gt;&lt;T:g&gt;&lt;Dif&gt;, &lt;T&gt;&lt;*-1.A&gt;&lt;-
1&amp;quot;4,111&gt;&lt;0&gt;&lt;IP:Ntl&gt;. &lt;T&gt;&lt;*-1,A&gt;&lt;Ot4&gt;&lt;
1,*,80&gt;&lt;4&apos; KI&gt;&lt;M&gt;&lt;-191i31&apos;&gt; , &lt;OM* &gt;.&lt;
Al,sufficiency,Back,Intra,81,81,1&lt;*&gt;&lt;A-&gt;&lt;14
x&gt;&lt;0&gt;4riT&gt;, .4;g*&gt;&lt;.*,&gt;&lt;,a,*,82&gt;&lt;VA
&gt;&lt;?ic*&gt;.
In the above sentence, the first &amp;quot;a&amp;quot; is
matched with the NULL marker, but the
second &amp;quot;a&amp;quot; is left as an ADM. This causes
an &amp;quot;Other error&amp;quot; and an &amp;quot;ADM/RDM
classification error&amp;quot;.
The Gross Accuracy (GA) as defined in
T&apos;sou et al. (1999) is:
GA = correctly tagged discourse
markers / total number of discourse markers
= 95.38%
This greatly improves the performance
compared with the original GA =68.89%.
The overgeneration problem (tagged 415,
actual 424) is caused by the mismatch of
CDMs as RDM pairs, or by the
</bodyText>
<page confidence="0.999252">
43
</page>
<bodyText confidence="0.9848925">
misclassification of CDMs as RDMs.
Following are two examples.
</bodyText>
<equation confidence="0.516330166666667">
&lt; A ,sufficiency,Front,Intra,54,54,1&gt;&lt; in &gt;.5
ft &gt;&lt;Vt,*,56&gt;&lt;A&gt;&lt;it A&gt; , &lt;ft A&gt;&lt;A&gt;&lt;fit
&gt;&lt; T&gt; , &lt; ,sufficiency,Bacic,Intra,57,54,1&gt;&lt;
tt,*,58&gt;&lt;ff %&gt;&lt;I3t&gt;&lt;*E&gt;&lt;:011,1-t&gt;4$ .$.&gt;.&lt;
&gt;&lt; 1.7 1V,&gt;&lt; Pit &gt;&lt;1-% &gt;&lt;.ffi ,*,59&gt;&lt;ft A &gt;&lt;
&gt;&lt;F —&gt;
</equation>
<bodyText confidence="0.999887125">
In this example, &amp;quot; A &amp;quot; could have
matched &lt;4,*,55&gt;, &lt;tt,*,56&gt;, or &lt;a*,58&gt;.
Only the &lt;44,*,55&gt; and the 4t,*,58&gt; can be
eliminated from the candidates according to
the &amp;quot;simple rules&amp;quot; mentioned in section 4.1.
The system has to choose from 4k,*,56&gt; and
&lt;J13,*,57&gt; to match with &amp;quot;n*&amp;quot; . Luckily,
the system has given a right choice here.
</bodyText>
<equation confidence="0.991734375">
&lt; 43 RI &gt;&lt; ,conjunction,Front,Intra,46,
46,1&gt;&lt; TIT • i&gt;&lt; 11(J &gt;&lt; &gt;, &lt;NULL,
conjunction,Front,Intra,0,49,1&gt;&lt;—t ig&gt;&lt;/#91i
&gt;&lt; I ,conjunction,Back,Intra,47,46,1&gt;&lt;
t-4,*,48&gt;&lt;fr P4&gt;&lt; ri9 118&gt;&lt;*E N&gt;&lt;0&gt;&lt;g8ic %Ec&gt;&lt;
43 III A &gt;&lt; 047 &gt;&lt; A RI &gt;&lt; &gt; &lt;
,conjunction,Back,Intra,49,49,1&gt;&lt; yq ).-&lt;.ft A
&gt;&lt;_L&gt;&lt;.t8
</equation>
<bodyText confidence="0.999889285714286">
The two &amp;quot;a&amp;quot; are misclassified as RDMs,
and causes a mismatch of RDM pair. Such
errors are difficult to avoid for an automatic
system. Without further syntactic/semantic
analysis, we can only hope for the ML
algorithm to give us a solution from more
training data.
</bodyText>
<sectionHeader confidence="0.999249" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999967611111111">
In order to study discourse markers for
use in the automatic summarization of
Chinese text, we have designed and
implemented the SIFAS system. In this
paper, we have focused on the problems of
NULL marker location and the classification
of RDMs and ADMs. A study on applying
machine learning techniques to discourse
marker disambiguation is conducted. C4.5 is
used to generate decision tree classifiers. Our
results indicate that machine learning is an
effective approach to improving the accuracy
of discourse marker tagging. For interactive
use of the system, if we set a threshold for
the rule precision and only display those low
precision rules for interactive selection, we
can greatly speed up the semi-automatic
tagging process.
</bodyText>
<sectionHeader confidence="0.999643" genericHeader="references">
7 References
</sectionHeader>
<reference confidence="0.999470692307692">
Chan S., Lai T., Gao W. J. and T&apos;sou B. K.
(2000) &amp;quot;Mining Discourse Markers for
Chinese Textual Summarization.&amp;quot; In
Proceedings of the Sixth Applied Natural
Language Processing Conference and the
North American Chapter of the
Association for Computational Linguistics.
Workshop on Automatic Summarization,
Seattle, Washington, 29 April to 3 May,
2000.
Grosz B.J. and Sidner C. (1986) &amp;quot;Attention,
Intention, and the Structure of Discourse,&amp;quot;
Computational Linguistics 12(3): 175-204.
Hirst G. (1981) &amp;quot;Discourse Oriented
Anaphoral Resolution in Natural Language
Understanding: A Review.&amp;quot; Computational
Linguistics 7(2): 85-98.
Hovy E. (1993) &amp;quot;Automated Discourse
Generation using Discourse Structure
Relations.&amp;quot; Artificial Intelligence 63: 341-
385.
Hwang C. H. and Schubert L. K. (1992)
&amp;quot;Tense Trees as the &apos;Fine Structure&apos; of
Discourse.&amp;quot; In Proc. 30th Annual Meeting,
Assoc. for Computational Linguistics, pp.
232-240.
Lin H. L., T&apos;sou B. K., H. C. Ho, Lai T., Lun
C., C. K. Choi and C.Y. Kit. (1991)
&amp;quot;Automatic Chinese Text Generation
Based on Inference Trees.&amp;quot; In Proc. of
ROCLING Computational Linguistic
Conference IV, Taipei, pp. 215-236.
Litman D. J. and Allen J. (1990) &amp;quot;Discourse
Processing and Commonsense Plans.&amp;quot; In
Cohen et al.(ed.) Intentions in
Communications, pp. 365-388.
Mann W. C. and Thompson S. A (1988)
&amp;quot;Rhetorical Structure Theory: Towards a
Functional Theory of Text Organization.&amp;quot;
</reference>
<page confidence="0.987001">
44
</page>
<reference confidence="0.990896265306122">
• Text 8(3): 243-281.
Marcu D. (1997) &amp;quot;From Discourse Structures
to Text Summaries.&amp;quot; In Proceedings of the
ACL/EACL&apos;97 Workshop on Intelligent
Scalable Text Summarization, Spain, pp.
82-88.
McKeown K. and Radev D. (1995)
&amp;quot;Summaries of Multiple News Articles.&amp;quot;
In Proceedings of the 18th Annual
International ACM SIGIR Conference on
Research and Development in Information
Retrieval, Seattle, pp. 74-82.
Ono K., Sumita K. and S. Miike. (1994)
&amp;quot;Abstract Generation based on Rhetorical
Structure Extraction.&amp;quot; In Proceedings of
International Conference on
Computational Linguistics, Japan, pp. 344-
348.
Paice C. D. (1990) &amp;quot;Constructing Literature
Abstracts by Computer: Techniques and
Prospects.&amp;quot; Information Processing and
Management 26(1): 171-186.
Quinlan J. Ross (1993) &amp;quot;C4.5 Programs for
Machine Learning.&amp;quot; San Mateo, CA:
Morgan Kaufmann.
T&apos;sou B. K., Ho H. C., Lai B. Y, Lun C. and
Lin H. L. (1992) &amp;quot;A Knowledge-based
Machine-aided System for Chinese Text
Abstraction.&amp;quot; In Proceedings of
International Conference on
Computational Linguistics, France, pp.
1039-1042.
T&apos;sou B. K., Gao W. J., Lin H. L., Lai T. B.
Y. and Ho H. C. (1999) &amp;quot;Tagging
Discourse Markers: Towards a Corpus
based Study of Discourse Marker Usage in
Chinese Text&amp;quot; In Proceedings of the 18th
International Conference on Computer
Processing of Oriental Languages, March
1999, Japan, pp. 391-396.
T&apos;sou B. K., Lin H. L., Ho H. C., Lai T. and
Chan T. (1996) &amp;quot;Automated Chinese Full-
text Abstraction Based on Rhetorical
Structure Analysis.&amp;quot; Computer Processing
of Oriental Languages 10(2): 225-238.
Tsou, B.K., et al., 1998: Sag, itArt, A
VnX, *ZIA, &amp;quot;413CX*47fSigifd
it 11 n&lt;7 &apos;b7 fth M &amp;quot;,
ICCIP&apos;98, Beijing, Nov. 18-20, 1998.
</reference>
<page confidence="0.999374">
45
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.226178">
<title confidence="0.890157">Enhancement of a Chinese Discourse Marker Tagger with C4.5</title>
<author confidence="0.946062">K T&apos;sou&apos;</author>
<author confidence="0.946062">Torn B Y Lai&apos;</author>
<author confidence="0.946062">Samuel W K Chan&apos;</author>
<author confidence="0.946062">Weijun Xuegang</author>
<affiliation confidence="0.940038333333333">Information Sciences Research City University of Hong Tat Chee Avenue,</affiliation>
<address confidence="0.611222">Hong Kong SAR, China</address>
<affiliation confidence="0.94006">Northeastern University, China</affiliation>
<email confidence="0.981048">'rlbtsou,</email>
<abstract confidence="0.9667714375">Discourse markers are complex discontinuous linguistic expressions which are used to explicitly signal the discourse structure of a text. This paper describes efforts to improve an automatic tagging system which identifies and classifies discourse markers in Chinese texts by applying machine learning (ML) to the disambiguation of discourse markers, as an integral part of automatic text summarization via rhetorical structure. Encouraging results are reported. marker, Chinese corpus, rhetorical relation, automatic tagging, machine learning</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Chan</author>
<author>T Lai</author>
<author>W J Gao</author>
<author>B K T&apos;sou</author>
</authors>
<title>Mining Discourse Markers for Chinese Textual Summarization.&amp;quot;</title>
<date>2000</date>
<booktitle>In Proceedings of the Sixth Applied Natural Language Processing Conference and the North American Chapter of the Association for Computational Linguistics. Workshop on Automatic Summarization,</booktitle>
<volume>3</volume>
<location>Seattle, Washington,</location>
<contexts>
<context position="1527" citStr="Chan et al. 2000" startWordPosition="202" endWordPosition="205">rker, Chinese corpus, rhetorical relation, automatic tagging, machine learning 1 Introduction Discourse refers to any form of language-based communication involving multiple sentences or utterances. The most important forms of discourse of interest to Natural Language Processing (NLP) are text and dialogue. The function of discourse analysis is to divide a text into discourse segments, and to recognize and re-construct the discourse structure of the text as intended by its author. Automatic text abstraction has received considerable attention (Paice 1990). Various systems have been developed (Chan et al. 2000). Ono et al. (1994), T&apos;sou et al. (1992) and Marcu (1997) focus on discourse structure in summarization using the Rhetorical Structure Theory (RST, Mann and Thompson 1986). The theory has been exploited in a number of computational systems (e.g. Hovy 1993). The main idea is to build a discourse tree where each node of the tree represents an RST relation. Summarization is achieved by trimming unimportant sentences on the basis of the relative saliency or rhetorical relations. The SIFAS (Syntactic Marker based Full-Text Abstraction System) system has been implemented to use discourse markers in </context>
</contexts>
<marker>Chan, Lai, Gao, T&apos;sou, 2000</marker>
<rawString>Chan S., Lai T., Gao W. J. and T&apos;sou B. K. (2000) &amp;quot;Mining Discourse Markers for Chinese Textual Summarization.&amp;quot; In Proceedings of the Sixth Applied Natural Language Processing Conference and the North American Chapter of the Association for Computational Linguistics. Workshop on Automatic Summarization, Seattle, Washington, 29 April to 3 May, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>C Sidner</author>
</authors>
<title>Attention, Intention, and the Structure of Discourse,&amp;quot;</title>
<date>1986</date>
<journal>Computational Linguistics</journal>
<volume>12</volume>
<issue>3</issue>
<pages>175--204</pages>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Grosz B.J. and Sidner C. (1986) &amp;quot;Attention, Intention, and the Structure of Discourse,&amp;quot; Computational Linguistics 12(3): 175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Hirst</author>
</authors>
<title>Discourse Oriented Anaphoral Resolution in Natural Language Understanding: A Review.&amp;quot;</title>
<date>1981</date>
<journal>Computational Linguistics</journal>
<volume>7</volume>
<issue>2</issue>
<pages>85--98</pages>
<marker>Hirst, 1981</marker>
<rawString>Hirst G. (1981) &amp;quot;Discourse Oriented Anaphoral Resolution in Natural Language Understanding: A Review.&amp;quot; Computational Linguistics 7(2): 85-98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hovy</author>
</authors>
<title>Automated Discourse Generation using Discourse Structure Relations.&amp;quot;</title>
<date>1993</date>
<journal>Artificial Intelligence</journal>
<volume>63</volume>
<pages>341--385</pages>
<contexts>
<context position="1783" citStr="Hovy 1993" startWordPosition="245" endWordPosition="246">guage Processing (NLP) are text and dialogue. The function of discourse analysis is to divide a text into discourse segments, and to recognize and re-construct the discourse structure of the text as intended by its author. Automatic text abstraction has received considerable attention (Paice 1990). Various systems have been developed (Chan et al. 2000). Ono et al. (1994), T&apos;sou et al. (1992) and Marcu (1997) focus on discourse structure in summarization using the Rhetorical Structure Theory (RST, Mann and Thompson 1986). The theory has been exploited in a number of computational systems (e.g. Hovy 1993). The main idea is to build a discourse tree where each node of the tree represents an RST relation. Summarization is achieved by trimming unimportant sentences on the basis of the relative saliency or rhetorical relations. The SIFAS (Syntactic Marker based Full-Text Abstraction System) system has been implemented to use discourse markers in the automatic summarization of Chinese (T&apos;sou et al. 1999). In this paper, we report our efforts to improve the SIFAS tagging system by applying machine learning techniques to disambiguation of discourse markers. C4.5 (Quinlan, 1993) is used in our system.</context>
</contexts>
<marker>Hovy, 1993</marker>
<rawString>Hovy E. (1993) &amp;quot;Automated Discourse Generation using Discourse Structure Relations.&amp;quot; Artificial Intelligence 63: 341-385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C H Hwang</author>
<author>L K Schubert</author>
</authors>
<title>Tense Trees as the &apos;Fine Structure&apos; of Discourse.&amp;quot;</title>
<date>1992</date>
<booktitle>In Proc. 30th Annual Meeting, Assoc. for Computational Linguistics,</booktitle>
<pages>232--240</pages>
<marker>Hwang, Schubert, 1992</marker>
<rawString>Hwang C. H. and Schubert L. K. (1992) &amp;quot;Tense Trees as the &apos;Fine Structure&apos; of Discourse.&amp;quot; In Proc. 30th Annual Meeting, Assoc. for Computational Linguistics, pp. 232-240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H L Lin</author>
<author>B K T&apos;sou</author>
<author>H C Ho</author>
<author>T Lai</author>
<author>C Lun</author>
<author>C K Choi</author>
<author>C Y Kit</author>
</authors>
<title>Automatic Chinese Text Generation Based on Inference Trees.&amp;quot;</title>
<date>1991</date>
<booktitle>In Proc. of ROCLING Computational Linguistic Conference IV, Taipei,</booktitle>
<pages>215--236</pages>
<marker>Lin, T&apos;sou, Ho, Lai, Lun, Choi, Kit, 1991</marker>
<rawString>Lin H. L., T&apos;sou B. K., H. C. Ho, Lai T., Lun C., C. K. Choi and C.Y. Kit. (1991) &amp;quot;Automatic Chinese Text Generation Based on Inference Trees.&amp;quot; In Proc. of ROCLING Computational Linguistic Conference IV, Taipei, pp. 215-236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D J Litman</author>
<author>J Allen</author>
</authors>
<title>Discourse Processing and Commonsense Plans.&amp;quot;</title>
<date>1990</date>
<booktitle>In Cohen et al.(ed.) Intentions in Communications,</booktitle>
<pages>365--388</pages>
<marker>Litman, Allen, 1990</marker>
<rawString>Litman D. J. and Allen J. (1990) &amp;quot;Discourse Processing and Commonsense Plans.&amp;quot; In Cohen et al.(ed.) Intentions in Communications, pp. 365-388.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Mann</author>
<author>S Thompson</author>
</authors>
<title>A</title>
<date>1988</date>
<journal>Text</journal>
<volume>8</volume>
<issue>3</issue>
<pages>243--281</pages>
<marker>Mann, Thompson, 1988</marker>
<rawString>Mann W. C. and Thompson S. A (1988) &amp;quot;Rhetorical Structure Theory: Towards a Functional Theory of Text Organization.&amp;quot; • Text 8(3): 243-281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Marcu</author>
</authors>
<title>From Discourse Structures to Text Summaries.&amp;quot;</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL/EACL&apos;97 Workshop on Intelligent Scalable Text Summarization,</booktitle>
<pages>82--88</pages>
<contexts>
<context position="1584" citStr="Marcu (1997)" startWordPosition="215" endWordPosition="216">machine learning 1 Introduction Discourse refers to any form of language-based communication involving multiple sentences or utterances. The most important forms of discourse of interest to Natural Language Processing (NLP) are text and dialogue. The function of discourse analysis is to divide a text into discourse segments, and to recognize and re-construct the discourse structure of the text as intended by its author. Automatic text abstraction has received considerable attention (Paice 1990). Various systems have been developed (Chan et al. 2000). Ono et al. (1994), T&apos;sou et al. (1992) and Marcu (1997) focus on discourse structure in summarization using the Rhetorical Structure Theory (RST, Mann and Thompson 1986). The theory has been exploited in a number of computational systems (e.g. Hovy 1993). The main idea is to build a discourse tree where each node of the tree represents an RST relation. Summarization is achieved by trimming unimportant sentences on the basis of the relative saliency or rhetorical relations. The SIFAS (Syntactic Marker based Full-Text Abstraction System) system has been implemented to use discourse markers in the automatic summarization of Chinese (T&apos;sou et al. 1999</context>
</contexts>
<marker>Marcu, 1997</marker>
<rawString>Marcu D. (1997) &amp;quot;From Discourse Structures to Text Summaries.&amp;quot; In Proceedings of the ACL/EACL&apos;97 Workshop on Intelligent Scalable Text Summarization, Spain, pp. 82-88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K McKeown</author>
<author>D Radev</author>
</authors>
<title>Summaries of Multiple News Articles.&amp;quot;</title>
<date>1995</date>
<booktitle>In Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>74--82</pages>
<location>Seattle,</location>
<marker>McKeown, Radev, 1995</marker>
<rawString>McKeown K. and Radev D. (1995) &amp;quot;Summaries of Multiple News Articles.&amp;quot; In Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, Seattle, pp. 74-82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Ono</author>
<author>K Sumita</author>
<author>S Miike</author>
</authors>
<title>Abstract Generation based on Rhetorical Structure Extraction.&amp;quot;</title>
<date>1994</date>
<booktitle>In Proceedings of International Conference on Computational Linguistics, Japan,</booktitle>
<pages>344--348</pages>
<contexts>
<context position="1546" citStr="Ono et al. (1994)" startWordPosition="206" endWordPosition="209">s, rhetorical relation, automatic tagging, machine learning 1 Introduction Discourse refers to any form of language-based communication involving multiple sentences or utterances. The most important forms of discourse of interest to Natural Language Processing (NLP) are text and dialogue. The function of discourse analysis is to divide a text into discourse segments, and to recognize and re-construct the discourse structure of the text as intended by its author. Automatic text abstraction has received considerable attention (Paice 1990). Various systems have been developed (Chan et al. 2000). Ono et al. (1994), T&apos;sou et al. (1992) and Marcu (1997) focus on discourse structure in summarization using the Rhetorical Structure Theory (RST, Mann and Thompson 1986). The theory has been exploited in a number of computational systems (e.g. Hovy 1993). The main idea is to build a discourse tree where each node of the tree represents an RST relation. Summarization is achieved by trimming unimportant sentences on the basis of the relative saliency or rhetorical relations. The SIFAS (Syntactic Marker based Full-Text Abstraction System) system has been implemented to use discourse markers in the automatic summa</context>
</contexts>
<marker>Ono, Sumita, Miike, 1994</marker>
<rawString>Ono K., Sumita K. and S. Miike. (1994) &amp;quot;Abstract Generation based on Rhetorical Structure Extraction.&amp;quot; In Proceedings of International Conference on Computational Linguistics, Japan, pp. 344-348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Paice</author>
</authors>
<title>Constructing Literature Abstracts by Computer: Techniques and Prospects.&amp;quot;</title>
<date>1990</date>
<journal>Information Processing and Management</journal>
<volume>26</volume>
<issue>1</issue>
<pages>171--186</pages>
<contexts>
<context position="1471" citStr="Paice 1990" startWordPosition="195" endWordPosition="196">aging results are reported. Keywords: discourse marker, Chinese corpus, rhetorical relation, automatic tagging, machine learning 1 Introduction Discourse refers to any form of language-based communication involving multiple sentences or utterances. The most important forms of discourse of interest to Natural Language Processing (NLP) are text and dialogue. The function of discourse analysis is to divide a text into discourse segments, and to recognize and re-construct the discourse structure of the text as intended by its author. Automatic text abstraction has received considerable attention (Paice 1990). Various systems have been developed (Chan et al. 2000). Ono et al. (1994), T&apos;sou et al. (1992) and Marcu (1997) focus on discourse structure in summarization using the Rhetorical Structure Theory (RST, Mann and Thompson 1986). The theory has been exploited in a number of computational systems (e.g. Hovy 1993). The main idea is to build a discourse tree where each node of the tree represents an RST relation. Summarization is achieved by trimming unimportant sentences on the basis of the relative saliency or rhetorical relations. The SIFAS (Syntactic Marker based Full-Text Abstraction System) </context>
</contexts>
<marker>Paice, 1990</marker>
<rawString>Paice C. D. (1990) &amp;quot;Constructing Literature Abstracts by Computer: Techniques and Prospects.&amp;quot; Information Processing and Management 26(1): 171-186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Quinlan J Ross</author>
</authors>
<title>C4.5 Programs for Machine Learning.&amp;quot;</title>
<date>1993</date>
<publisher>Morgan Kaufmann.</publisher>
<location>San Mateo, CA:</location>
<marker>Ross, 1993</marker>
<rawString>Quinlan J. Ross (1993) &amp;quot;C4.5 Programs for Machine Learning.&amp;quot; San Mateo, CA: Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B K T&apos;sou</author>
<author>H C Ho</author>
<author>B Y Lai</author>
<author>C Lun</author>
<author>H L Lin</author>
</authors>
<title>A Knowledge-based Machine-aided System for Chinese Text Abstraction.&amp;quot;</title>
<date>1992</date>
<booktitle>In Proceedings of International Conference on Computational Linguistics, France,</booktitle>
<pages>1039--1042</pages>
<contexts>
<context position="1567" citStr="T&apos;sou et al. (1992)" startWordPosition="210" endWordPosition="213">ion, automatic tagging, machine learning 1 Introduction Discourse refers to any form of language-based communication involving multiple sentences or utterances. The most important forms of discourse of interest to Natural Language Processing (NLP) are text and dialogue. The function of discourse analysis is to divide a text into discourse segments, and to recognize and re-construct the discourse structure of the text as intended by its author. Automatic text abstraction has received considerable attention (Paice 1990). Various systems have been developed (Chan et al. 2000). Ono et al. (1994), T&apos;sou et al. (1992) and Marcu (1997) focus on discourse structure in summarization using the Rhetorical Structure Theory (RST, Mann and Thompson 1986). The theory has been exploited in a number of computational systems (e.g. Hovy 1993). The main idea is to build a discourse tree where each node of the tree represents an RST relation. Summarization is achieved by trimming unimportant sentences on the basis of the relative saliency or rhetorical relations. The SIFAS (Syntactic Marker based Full-Text Abstraction System) system has been implemented to use discourse markers in the automatic summarization of Chinese (</context>
</contexts>
<marker>T&apos;sou, Ho, Lai, Lun, Lin, 1992</marker>
<rawString>T&apos;sou B. K., Ho H. C., Lai B. Y, Lun C. and Lin H. L. (1992) &amp;quot;A Knowledge-based Machine-aided System for Chinese Text Abstraction.&amp;quot; In Proceedings of International Conference on Computational Linguistics, France, pp. 1039-1042.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B K T&apos;sou</author>
<author>W J Gao</author>
<author>H L Lin</author>
<author>T B Y Lai</author>
<author>H C Ho</author>
</authors>
<title>Tagging Discourse Markers: Towards a Corpus based Study of Discourse Marker Usage in Chinese Text&amp;quot;</title>
<date>1999</date>
<booktitle>In Proceedings of the 18th International Conference on Computer Processing of Oriental Languages,</booktitle>
<pages>391--396</pages>
<contexts>
<context position="2185" citStr="T&apos;sou et al. 1999" startWordPosition="305" endWordPosition="308"> and Marcu (1997) focus on discourse structure in summarization using the Rhetorical Structure Theory (RST, Mann and Thompson 1986). The theory has been exploited in a number of computational systems (e.g. Hovy 1993). The main idea is to build a discourse tree where each node of the tree represents an RST relation. Summarization is achieved by trimming unimportant sentences on the basis of the relative saliency or rhetorical relations. The SIFAS (Syntactic Marker based Full-Text Abstraction System) system has been implemented to use discourse markers in the automatic summarization of Chinese (T&apos;sou et al. 1999). In this paper, we report our efforts to improve the SIFAS tagging system by applying machine learning techniques to disambiguation of discourse markers. C4.5 (Quinlan, 1993) is used in our system. 2 Manual Tagging Process To tag the discourse markers, the following coding scheme is designed to encode Real Discourse Markers (RDM) appearing in the SIFAS corpus (T&apos;sou et al. 1998). We describe the jib discourse marker with a 7-tuple RDM,: RDM,=&lt; DM,, RR, , RP,, CT,, MN., RN,, 0T1&gt;, where 38 DM; : the lexical item of the Discourse Marker, or the value &apos;NULL&apos;. RR; : the Rhetorical Relation in whi</context>
<context position="11910" citStr="T&apos;sou et al, 1999" startWordPosition="1886" endWordPosition="1889"> xe, I I Gain(D,T) = Info(D)— Info(Di) Gain ratio(D,T) = gain(D,T) I Split (D,T) where, p(c,D) denotes the proportion of cases in D that belong to the ith class. 4.3 Application of C4.5 Since using semantic information requires a comprehensive thesaurus, which is unavailable at present, we only use syntactic information through machine learning. The attributes used in the original SIFAS system include the candidate discourse marker itself, two words immediately to the left of the CDM, and two words immediately to the right of the CDM. The attribute names are F2, F1, CDM, Bl, B2, respectively (T&apos;sou et al, 1999). SIFAS only uses the Part Of Speech attribute of the neighboring words. This reflects to some degree the syntactic characteristics of the CDM. To reflect the distance characteristics, we add two other attributes: the number of discourse delimiters (commas, semicolons for INTRA-sentence relation, periods and 41 exclamation marks for INTER-sentence relation) before and after the current CDM, denoted Fcom and Bcom, respectively. For the location of the NULL marker, we still add an actual number of delimiters Acorn. The order of these attributes is: CDM, Fl, F2, Bi, B2, Fcom, Bcom Acorn for Null </context>
<context position="17775" citStr="T&apos;sou et al. (1999)" startWordPosition="2852" endWordPosition="2855"> of the CDMs. An example of Other errors is shown below. The following sentence is from an editorial of People&apos;s Daily. &lt; tiCIii &gt;&lt; 4 &gt;&lt; X &gt; P &lt;NULL,sufficiency,Front,Intra,0,81,1&gt;&lt;— II &gt;&lt;n&gt;&lt;Et1&gt;&lt;T:g&gt;&lt;Dif&gt;, &lt;T&gt;&lt;*-1.A&gt;&lt;- 1&amp;quot;4,111&gt;&lt;0&gt;&lt;IP:Ntl&gt;. &lt;T&gt;&lt;*-1,A&gt;&lt;Ot4&gt;&lt; 1,*,80&gt;&lt;4&apos; KI&gt;&lt;M&gt;&lt;-191i31&apos;&gt; , &lt;OM* &gt;.&lt; Al,sufficiency,Back,Intra,81,81,1&lt;*&gt;&lt;A-&gt;&lt;14 x&gt;&lt;0&gt;4riT&gt;, .4;g*&gt;&lt;.*,&gt;&lt;,a,*,82&gt;&lt;VA &gt;&lt;?ic*&gt;. In the above sentence, the first &amp;quot;a&amp;quot; is matched with the NULL marker, but the second &amp;quot;a&amp;quot; is left as an ADM. This causes an &amp;quot;Other error&amp;quot; and an &amp;quot;ADM/RDM classification error&amp;quot;. The Gross Accuracy (GA) as defined in T&apos;sou et al. (1999) is: GA = correctly tagged discourse markers / total number of discourse markers = 95.38% This greatly improves the performance compared with the original GA =68.89%. The overgeneration problem (tagged 415, actual 424) is caused by the mismatch of CDMs as RDM pairs, or by the 43 misclassification of CDMs as RDMs. Following are two examples. &lt; A ,sufficiency,Front,Intra,54,54,1&gt;&lt; in &gt;.5 ft &gt;&lt;Vt,*,56&gt;&lt;A&gt;&lt;it A&gt; , &lt;ft A&gt;&lt;A&gt;&lt;fit &gt;&lt; T&gt; , &lt; ,sufficiency,Bacic,Intra,57,54,1&gt;&lt; tt,*,58&gt;&lt;ff %&gt;&lt;I3t&gt;&lt;*E&gt;&lt;:011,1-t&gt;4$ .$.&gt;.&lt; &gt;&lt; 1.7 1V,&gt;&lt; Pit &gt;&lt;1-% &gt;&lt;.ffi ,*,59&gt;&lt;ft A &gt;&lt; &gt;&lt;F —&gt; In this example, &amp;quot; A &amp;quot; could hav</context>
</contexts>
<marker>T&apos;sou, Gao, Lin, Lai, Ho, 1999</marker>
<rawString>T&apos;sou B. K., Gao W. J., Lin H. L., Lai T. B. Y. and Ho H. C. (1999) &amp;quot;Tagging Discourse Markers: Towards a Corpus based Study of Discourse Marker Usage in Chinese Text&amp;quot; In Proceedings of the 18th International Conference on Computer Processing of Oriental Languages, March 1999, Japan, pp. 391-396.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B K T&apos;sou</author>
<author>H L Lin</author>
<author>H C Ho</author>
<author>T Lai</author>
<author>T Chan</author>
</authors>
<title>Automated Chinese Fulltext Abstraction Based on Rhetorical Structure Analysis.&amp;quot;</title>
<date>1996</date>
<journal>Computer Processing of Oriental Languages</journal>
<volume>10</volume>
<issue>2</issue>
<pages>225--238</pages>
<marker>T&apos;sou, Lin, Ho, Lai, Chan, 1996</marker>
<rawString>T&apos;sou B. K., Lin H. L., Ho H. C., Lai T. and Chan T. (1996) &amp;quot;Automated Chinese Fulltext Abstraction Based on Rhetorical Structure Analysis.&amp;quot; Computer Processing of Oriental Languages 10(2): 225-238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B K Tsou</author>
</authors>
<date>1998</date>
<booktitle>Sag, itArt, A VnX, *ZIA, &amp;quot;413CX*47fSigifd it 11 n&lt;7 &apos;b7 fth M &amp;quot;, ICCIP&apos;98,</booktitle>
<location>Beijing,</location>
<marker>Tsou, 1998</marker>
<rawString>Tsou, B.K., et al., 1998: Sag, itArt, A VnX, *ZIA, &amp;quot;413CX*47fSigifd it 11 n&lt;7 &apos;b7 fth M &amp;quot;, ICCIP&apos;98, Beijing, Nov. 18-20, 1998.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>