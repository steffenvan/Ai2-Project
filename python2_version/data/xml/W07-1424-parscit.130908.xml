<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000059">
<title confidence="0.989805">
Mutaphrase: Paraphrasing with FrameNet
</title>
<author confidence="0.784364">
Michael Ellsworth and Adam Janin
</author>
<email confidence="0.873333">
{infinity,janin}@icsi.berkeley.edu
</email>
<note confidence="0.365518">
International Computer Science Institute
</note>
<address confidence="0.6988805">
1947 Center Street, Suite 600
Berkeley, CA 94704-1105 USA
</address>
<sectionHeader confidence="0.97375" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999108">
We describe a preliminary version of Mu-
taphrase, a system that generates para-
phrases of semantically labeled input sen-
tences using the semantics and syntax en-
coded in FrameNet, a freely available lexico-
semantic database. The algorithm generates
a large number of paraphrases with a wide
range of syntactic and semantic distances
from the input. For example, given the in-
put “I like eating cheese”, the system out-
puts the syntactically distant “Eating cheese
is liked by me”, the semantically distant “I
fear sipping juice”, and thousands of other
sentences. The wide range of generated
paraphrases makes the algorithm ideal for a
range of statistical machine learning prob-
lems such as machine translation and lan-
guage modeling as well as other semantics-
dependent tasks such as query and language
generation.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.986277730769231">
A central tenet of statistical natural language pro-
cessing (NLP) is “there’s no data like more data”.
One method for generating more data is to restate
each phrase in a corpus, keeping similar seman-
tics while changing both the words and the word
sequence. The efficacy of this approach has been
well-established in many areas, including automated
evaluation of machine translation systems (Kauchak
and Barzilay, 2006), text summarization (Kittredge,
2002), question answering (Rinaldi et al., 2003),
document retrieval (Zukerman and Raskutti, 2002),
and many others.
Most of the reported work on paraphrase gener-
ation from arbitrary input sentences uses machine
learning techniques trained on sentences that are
known or can be inferred to be paraphrases of each
other (Bannard and Callison-Burch, 2005; Barzi-
lay and Lee, 2003; Barzilay and McKeown, 2001;
Callison-Burch et al., 2006; Dolan et al., 2004;
Ibrahim et al., 2003; Lin and Pantel, 2001; Pang et
al., 2003; Quirk et al., 2004; Shinyama et al., 2002).
Mutaphrase instead generates paraphrases algorith-
mically using an input sentence and FrameNet, a
freely available lexico-semantic resource (informa-
tion regarding FrameNet, including relevant termi-
nology, is presented in Section 2).
</bodyText>
<figureCaption confidence="0.915588">
Figure 1: Syntactic and semantic similarity to I like
eating cheese.
</figureCaption>
<bodyText confidence="0.95951">
Conceptually, the Mutaphrase algorithm takes a
semantic specification of a sentence, provided by an
automatic semantic parser such as Shalmaneser (Erk
</bodyText>
<figure confidence="0.982901285714286">
SemantICS
I fear SIPPIng JUICe.
TO SIP On JUICe dIStUrbS me.
I lIKe tO SnaCK On bread.
EatIng CheeSe IS lIKed bY me.
I lIKe eatIng CheeSe.
SYntaX
</figure>
<page confidence="0.986498">
143
</page>
<note confidence="0.7861315">
Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 143–150,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999580166666667">
and Pad´o, 2006), and recursively replaces each se-
mantically parsed phrase with a semantically similar
phrase. To generate each new phrase, each of the se-
mantic parts of the original phrase is mapped, using
FrameNet data, onto a new word or phrase whose
position and syntactic marking may be quite differ-
ent.
The Mutaphrase algorithm outputs a large set of
paraphrases with a variety of distances from the in-
put in terms of both syntax and semantics; see Fig-
ure 1. Depending on the needs of the application, fil-
tering can be applied to limit the distance to a desired
range. For example, language modeling may bene-
fit from a wider variety of semantic outputs, since
if I like eating cheese is in-domain, then I like sip-
ping juice is also likely in-domain. Other applica-
tions, e.g. Question Answering, require more strin-
gent limits on semantic distance. See Section 4.
</bodyText>
<subsectionHeader confidence="0.995807">
1.1 Current Limitations
</subsectionHeader>
<bodyText confidence="0.9999564">
The current implementation of Mutaphrase suffers
from several limitations. Perhaps the most signifi-
cant is that the input sentences must be semantically
labeled using FrameNet annotations. Since no au-
tomated systems for FrameNet-specific annotation
are currently incorporated into our algorithm, input
is limited to hand-annotated sentences. Also, cer-
tain types of semantic ill-formedness are permitted
(e.g. I like sipping meat), and some types of syntax
are not well supported (e.g. conjunctions, relative-
clauses). We believe all these factors can be ad-
dressed; they are covered briefly in Future Work
(Section 4). We confine ourselves in other sections
to describing the core Mutaphrase algorithm as cur-
rently implemented.
</bodyText>
<sectionHeader confidence="0.98994" genericHeader="introduction">
2 FrameNet
</sectionHeader>
<bodyText confidence="0.999520583333333">
The primary resource used in Mutaphrase is
FrameNet (Fontenelle, 2003; FrameNet, 2007b),
a lexico-semantic database that describes con-
cepts and their interrelations, wordform and word-
sequence information, syntactic categories, and
mappings between conceptual and lexical/syntactic
information. All of these are grounded in hand-
annotated examples of real-world sentences. At a
slightly more abstract level, FrameNet can be de-
scribed as providing a two-way mapping between
meaning (semantics) and form (syntax, wordforms,
sequences).
</bodyText>
<subsectionHeader confidence="0.988012">
2.1 Semantics
</subsectionHeader>
<bodyText confidence="0.999903909090909">
The conceptual information is represented using
frames, where a frame is a type of schema or sce-
nario (e.g. Motion, Commercial transaction), and
frame elements (FEs), which are the participants
and parameters of the frames (e.g. Motion.Path,
Commercial transaction.Buyer). Frames and their
frame elements are related and mapped with a lim-
ited type of conceptual ontology involving Inher-
itance (i.e. subtype), Subframe (i.e. temporal sub-
part), Using (i.e. presupposition) and a few other re-
lation types.
</bodyText>
<subsectionHeader confidence="0.993314">
2.2 Syntax
</subsectionHeader>
<bodyText confidence="0.999855">
On the form side, the representation is more min-
imal. Wordforms and word-sequences are repre-
sented so that words with multiple wordforms (e.g.
take/took) and word sequences with wordforms (e.g.
take/took off) can be referred to as unitary objects.
We have a category Support (and the more specific
label ‘Copula’) for pieces of multi-word expressions
that are optional for expressing the semantics of the
whole (e.g. take in take a bath). FrameNet also rep-
resents a small but sufficiently rich set of syntactic
categories of English (i.e. phrase types or PTs, such
as ‘Sfin’, i.e. finite sentence) and syntactic relations
(i.e. grammatical functions or GFs, e.g. ‘Object’).
</bodyText>
<subsectionHeader confidence="0.996161">
2.3 Syntax-Semantics Bindings
</subsectionHeader>
<bodyText confidence="0.998723076923077">
The most vital part of the FrameNet data for our Mu-
taphrase algorithm is the mappings between seman-
tics and syntax. There are several categories pertain-
ing to this in the data. Lexical units (LUs) are a pair-
ing of words/word sequences with the frame each
evokes. The valences for each LU are sequences
in which semantic and form information pertinent
to phrases are paired. They are not stored in the
database, so we have created a process that produces
them entirely automatically (see 3.2). For example,
for the LU hand in the Giving frame and possible in
the Likelihood frame, we have the following anno-
tated sentences:
</bodyText>
<footnote confidence="0.969150666666667">
1. [She]Donor/NP/Ext [handed]Target
[a bag]Theme/NP/Obj
[to Nob]Recipient/PP(to)/Dep
</footnote>
<page confidence="0.984455">
144
</page>
<listItem confidence="0.473999">
2. [It]Null [was]Copula [possible]Target [that he same frame (e.g. drink vs. eat) are not overtly mod-
</listItem>
<bodyText confidence="0.9849631">
had been hoping to frighten eled in FrameNet. Other resources, such as Word-
Steve]Hypothetical event/Sfin(that)/Dep Net, could provide added information in cases re-
quiring finer granularity (see Section 4).
Example 1 above shows a typical valence, in
which most of the positions are semantically labeled
with a frame element which is paired with syntac-
tic GF and PT information. The second annotation
(2) is more complex, exemplifying each of the major
categories that make up the positions of a valence.
The categories are:
</bodyText>
<listItem confidence="0.97260725">
1. a Null element, with syntax but no semantics
(usually there or it)
2. a Support or Copula with its wordforms
3. a Target (i.e. an LU or word that is part of an
LU) with its wordforms, conceptually repre-
senting a frame
4. a frame-element/phrase-type/grammatical-
function phrase description, which puts
together semantic (FE) information with
syntax (GF and PT); the PT also indicates
fixed words (e.g. the word that in the example
above)
</listItem>
<bodyText confidence="0.999651">
We can abstract away from the individual sen-
tences, preserving only the sequences of positions
with their features, as in the following representa-
tion of sentence 2 above:
</bodyText>
<equation confidence="0.521178">
Null(it), Copula, Target(possible), Hypotheti-
cal event/Dep/Sfin(that)
</equation>
<bodyText confidence="0.999949571428571">
These abstract valences are the basis for the al-
gorithm we present here. There are typically be-
tween two and ten basic patterns associated with
each annotated lexical unit, encompassing alterna-
tions in the realization of FEs such as Active/Passive
(I recommended her vs. She was recommended by
me), the Dative Alternation (He handed the paper to
Stephen vs. He handed Stephen the paper), optional
elements (I ate dinner vs. I ate) and many more.
Basing our algorithm on rearranging the fillers
of these FEs allows us to abstract away from syn-
tax, since the FEs of a frame express the same rela-
tions regardless of the LU or syntax they occur with.
Some meaning differences between LUs within the
</bodyText>
<sectionHeader confidence="0.982286" genericHeader="method">
3 Mutaphrase Algorithm
</sectionHeader>
<bodyText confidence="0.999788875">
At a very high level, the paraphrase algorithm that
we use is as follows: we begin with a sentence with
frame-semantic annotation, replace each lexical unit
and its associated frame Elements with an alternative
valence, then filter the output for its syntactic and
semantic fit with the original sentence. The valences
may be drawn from either the same LU, an LU of
the same frame, or an LU of a related frame.
</bodyText>
<listItem confidence="0.323069">
C: Output Tree
</listItem>
<figureCaption confidence="0.943192">
Figure 2: Algorithm Sketch: A syntactic/semantic
</figureCaption>
<bodyText confidence="0.847571">
tree of the original sentence (A) is rearranged to
match a different valence (B), producing a new tree
(C); thus I want your opinion yields the paraphrase
Your opinion is desired.
Figure 2 shows an example of one step of the al-
gorithm. An input tree for the sentence I want your
opinion is shown in Figure 2A. The particular va-
lence for the Desiring frame in Figure 2B describes
the relations between the word desire and its depen-
dents in sentences like A meeting was desired. Be-
cause the phrase types and grammatical functions of
the FEs between the input and the attested valence
are compatible, it is possible to replace the input
</bodyText>
<figure confidence="0.999439892857143">
Experiencer
Event
Event Target
A: Input Tree
+
B: Attested Valence
Frame: Desiring
Frame: Desiring
Target
Frame: Opinion
NP/Ext &amp;quot;I&amp;quot; &amp;quot;want&amp;quot;
NP/Obj
NP/Ext &amp;quot;is desired&amp;quot;
Cognizer
Target
Poss/Gen &amp;quot;your&amp;quot;
&amp;quot;opinion&amp;quot;
=
Frame: Desiring
Event
Target
Frame: Opinion
NP/Ext
&amp;quot;is desired&amp;quot;
Cognizer
Target
Poss/Gen &amp;quot;Your&amp;quot;
&amp;quot;opinion&amp;quot;
</figure>
<page confidence="0.992031">
145
</page>
<bodyText confidence="0.99971">
frame with the new valence. The output is shown
in Figure 2C.
The remainder of this section describes in more
detail how this algorithm is implemented.
</bodyText>
<subsectionHeader confidence="0.9995265">
3.1 Building a Syntax/Semantics Tree from
FrameNet Data
</subsectionHeader>
<bodyText confidence="0.999982916666667">
Because the FEs of the original sentence are often
filled by phrases with their own annotation, the ini-
tial syntactic/semantic annotation is (conceptually,
at least) in the form of a graph. Typically, the graph
is nearly a tree, with few or no non-tree edges1.
Hereafter, we will use the term ‘tree’ even for the
cases where there are non-tree edges.
Since the data are not organized in this format in
the FrameNet output, we have implemented a rou-
tine which can turn FrameNet data into a syntactico-
semantic tree; tree examples can be seen in Fig-
ure 2A and Figure 2C.
</bodyText>
<subsectionHeader confidence="0.997312">
3.2 Building Ordered Valences from FrameNet
Data
</subsectionHeader>
<bodyText confidence="0.9999495">
As mentioned in Section 2.3, we have constructed
a routine to parse FrameNet data to produce the va-
lences for each LU of a frame. The basic output is
an ordered list of syntactico-semantic elements, op-
tional apositional features (e.g. passive +/-), and the
frequency of the pattern.2
One innovation of our algorithm is its ability to
handle multiword LUs. It simply identifies each
word of the LU as a separate element in the list,
marking each with the label ‘Target’. Thus the or-
dered valences of take off.v in the Undressing frame
include, among others:
</bodyText>
<listItem confidence="0.99949825">
• Wearer/NP/Ext, take/Target, off/Target, Cloth-
ing/NP/Obj; Frequency: 57/68
(e.g. I TOOK OFF my watch)
• Wearer/NP/Ext, take/Target, Clothing/NP/Obj,
</listItem>
<footnote confidence="0.9720999">
1These non-tree edges are introduced when a phrase is an
FE of more than one frame. In keeping with normal syntactic
analysis, we treat the node as non-local to all but one parent.
2Although frequency of a particular pattern in the FrameNet
data is not strictly representative of the frequency of that pattern
in the corpus, a close examination reveals that the rank order of
patterns is largely identical, i.e. the most common pattern in
FrameNet represents the most common pattern in the corpus.
How useful this inexact statistical data will be is the subject of
future research.
</footnote>
<equation confidence="0.16551">
off/Target; Frequency: 7/68
(e.g. You TAKE your shoes OFF)
</equation>
<bodyText confidence="0.999649714285714">
One way of thinking about the valence set is that it
represents possible orderings of subparts of a phrase
that is semantically a frame instance and syntacti-
cally a phrase headed by the Target (see, for exam-
ple, Figure 2B). This semantic/syntactic information
is detailed enough to build the syntax of a phrase,
given FrameNet-style semantics.
</bodyText>
<subsectionHeader confidence="0.999228">
3.3 Core algorithm
</subsectionHeader>
<bodyText confidence="0.9999745">
Once the input has been turned into a tree and there
is a set of alternative ways of expressing each frame
that is in the input, the algorithm then recurses
downward and then, as it returns up, replaces each
phrase/frame node with a set of alternative phrases.
In the simplest case, these phrases are built from all
the valences that are attested for the frame that the
original phrase expressed 3. In other words, our al-
gorithm is a recursive tree-rewrite in which the cur-
rent valence of the current LU is replaced by many
alternate valences of many different LUs.
In the recursion, word and phrase nodes not
headed by an LU are kept the same (except for pro-
nouns, which are expanded to all their wordforms,
e.g. me to I/me/my/mine). The child phrases of such
an unparaphrased node, if they are headed by an
LU or pronoun, can be paraphrased as long as the
paraphrases match the phrase type and grammatical
function of the original child phrase.
In Figure 2, the original sentence (represented
in Figure 2A) has the phrase representing the De-
siring frame replaced with an alternative phrase
evoking the same frame (Figure 2B) to produce a
new, roughly semantically equivalent sentence (Fig-
ure 2C) by expressing the same set of frames in the
same FE relations to each other.
In practice, we have to throw away at the outset
many of the valences because they include FEs that
are not in the input sentence4 or because they have
syntactic requirements of their child phrases which
</bodyText>
<footnote confidence="0.935846875">
3Our algorithm will work just as well with related frames
as long as the relevant FEs are mapped in the FrameNet data.
Controlling the distance, direction, and relation-types of related
frames that are included for paraphrase (if any) is one way to
control the degree of semantic diversity of the paraphrase out-
put. See further Section 3.4.
4Thus attempting to use the valence Experiencer/NP/Ext,
Degree/AVP/Dep, want/Target, Event/NP/Obj (e.g. I really
</footnote>
<page confidence="0.99671">
146
</page>
<bodyText confidence="0.999795388888889">
cannot be filled by a paraphrase of the child phrases.
For example, for the input sentence I gave presents
to friends, the code can output 560 (unfiltered) para-
phrases. A random selection from the output in-
cludes Presents bequeathed to friends, I handed in
presents, and Presents donated by I. Of these, the
first and last are filtered out as not filling the original
sentential context and the last, in addition, is filtered
out because of the mismatch between the pronoun
wordform I and the non-subject grammatical func-
tion.
To further refine the paraphrases, we must elimi-
nate examples that are not compatible with the input
sentence. In our current implementation, our algo-
rithm filters out incorrect syntax during the recursion
over the tree. Ultimately, we will also filter out mal-
formed semantics. The rest of this section is devoted
to an explication of the details of this filtering.
</bodyText>
<subsectionHeader confidence="0.941311">
3.4 Syntactic/Semantic Compatibility
</subsectionHeader>
<bodyText confidence="0.999946857142857">
For both syntax and semantics, the degree of via-
bility of a paraphrase can be divided up into two
components: well-formedness and similarity. Syn-
tactic and semantic well-formedness is always desir-
able and the algorithm seeks to maximize it in ways
that are outlined below. Similarity between the orig-
inal sentence and its paraphrases (or among the para-
phrases), however, maybe more or less desirable de-
pending on the task. Figure 1 shows an example of
the various degrees of syntactic and semantic simi-
larity of the paraphrase output. To maintain flexibil-
ity, we will need several control parameters to allow
us to filter our output for syntactic/semantic similar-
ity.
</bodyText>
<subsectionHeader confidence="0.711005">
3.4.1 Syntactic Compatibility
</subsectionHeader>
<bodyText confidence="0.976390923076923">
Syntactic incompatibilities most commonly result
from gross mismatches between the Phrase Type
called for in a new valence and the Phrase Type pos-
sibilities available for the child phrase.
For example, if the initial sentence for paraphrase
is I want your opinion as in 1 below (repeated from
Figure 2), Valence 2 below represents a PT mis-
match, since I, an NP filler of the Experiencer role
want another chance) when paraphrasing the initial sentence
in Figure 2 will not work, since there is nothing in the original
to fill the Degree FE mentioned here.
in the original sentence, is not modifiable into an ad-
jective phrase (AJP).
</bodyText>
<listItem confidence="0.994549">
1. Experiencer/NP/Ext, want/Target,
Event/NP/Obj
2. There/Null, be/Copula, Experiencer/AJP/Dep,
desire/Target, Event/PP(for)/Dep
(e.g. There is a public desire for transparency)
3. There/Null, be/Copula, desire/Target,
Experiencer/PP(in)/Dep, Event/PP(for)/Dep
(e.g. There was a desire in America for home
rule)
</listItem>
<bodyText confidence="0.999972121212121">
This filtering is vital, as otherwise valence 2
would yield the awful There is me desire for your
opinion.
However, phrase types that are not exact matches
may nevertheless be compatible with each other. Va-
lence 3, for example, is compatible with the original
valence, since the original Experiencer and Event
FEs were filled by NPs, to which prepositions can
be added to match the PP realizations required by
Valence 3. This yields another paraphrase of the
sentence in Figure 2: There is a desire in me for
your opinion. Similarly, full sentential clauses can
be modified to match VPs by truncation of the Ex-
ternal (subject) argument, etc. A phrase from the
original sentence may also be omitted to match an
empty phrase in the paraphrase, as seen in the omis-
sion of the Experiencer in the paraphrase in Figure 2.
These alternations provide more variety in the po-
tential phrase types of the paraphrases. Which syn-
tactic modifications are allowed should be an ex-
ternally controllable parameter, but this has not yet
been implemented. In general, allowing fewer types
of modification should move the average output left-
ward in the syntax/semantic similarity graph in Fig-
ure 1 (toward more syntactic similarity).
Although every annotated valence represents a
grammatical structure, some of these structures will
more likely be judged as well-formed than others;
in particular, infrequent patterns are more likely ill-
formed than frequent ones. An additional control-
lable parameter, allowing a trade-off between re-
call and precision, is a frequency cut-off for accept-
ing a valence pattern based on the number of times
</bodyText>
<page confidence="0.996544">
147
</page>
<bodyText confidence="0.9999472">
the pattern is found in the FrameNet data. Our al-
gorithm currently produces a ranked list of para-
phrases based on exactly this frequency parameter,
and downstream processing can choose a cut-off fre-
quency or n-best to reduce the total output.
</bodyText>
<subsectionHeader confidence="0.779024">
3.4.2 Semantic Filtering
</subsectionHeader>
<bodyText confidence="0.999983">
Lexical units of the same frame are not necessar-
ily synonyms; they may be antonyms or coordinate
terms (i.e. co-hyponyms). For example, cheese and
juice are both in the Food frame, but I like eating
cheese and I like eating juice are certainly not a se-
mantic match! In fact, the second is a semantically
ill-formed modification of the first. Similarly, like
and hate are both in the Experiencer subject frame.
While I hate eating cheese is similar to I like eat-
ing cheese in describing an attitude toward eating
cheese, they are not an exact semantic match either;
in this case, however, the lack of semantic similarity
does not lead to semantic ill-formedness.
For some tasks such as expanding a language
model, exact semantic match is not necessary, but
for tasks that require strict semantic match, there are
several simple ways to increase robustness.
Tighter filtering, of whatever kind, will move the
average output of the algorithm downward in the
syntax/semantic similarity graph in Figure 1 (toward
more semantic similarity).
</bodyText>
<subsectionHeader confidence="0.988979">
3.5 Preliminary Results
</subsectionHeader>
<bodyText confidence="0.9988873125">
We have implemented the above algorithm to the
point that it is capable of producing paraphrases of
arbitrary input sentences that have received proper
FrameNet annotation. A large number of para-
phrases with a variety of phrase types are produced,
but the lack of semantic filtering occasionally leads
to semantically ill-formed results. The output is
ranked purely according to the frequency in the
FrameNet data of the valences used to build the para-
phrase.
For the sentence I like eating cheese, the para-
phraser produced 8403 paraphrases, of which the
following was top-ranked: I resented drinking
cheese, which suffers from the semantic mismatch
problems discussed in Section 3.4.2. Some other
output at random:
</bodyText>
<listItem confidence="0.99952">
• I am interested in cheese devouring.
• I was nervous that cheese’s ingested.
• I’m worried about gobbling down cheese.
• My regrets were that cheese was eaten by me.
</listItem>
<bodyText confidence="0.999810470588235">
Since most of the annotation in the Ingestion
frame (the frame for eat, etc.) concerns eating rather
than drinking, the majority of the output is semanti-
cally well-formed. The paraphrases generated from
the Experiencer subject frame (the frame for like, in-
terested, regret, etc.) are more uniformly felicitous,
even if semantically quite divergent from the mean-
ing of the original. Both the infelicity of drinking
cheese and the semantic divergence appear to be ad-
dressable by refining semantic tightness using Word-
Net. Averaging over senses, words like gobble and
ingest have lower WordNet-based semantic distance
from eat than drink.
For the sentence Nausea seems a commonplace
symptom, the paraphraser outputs 502 paraphrases,
of which the following was top-ranked: It seems a
commonplace sign. Other output at random:
</bodyText>
<listItem confidence="0.9998866">
• Tiredness looks indicative.
• Queasiness smelt of a commonplace sign.
• Sleepiness appears a commonplace sign.
• Queasiness smelt indicative queasiness.
• Somnolence appears to be indicative.
</listItem>
<bodyText confidence="0.992759375">
Longer sentences (e.g. Locally elected school
boards, especially in our larger cities, become the
prey of ambitious, generally corrupt, and invari-
ably demagogic local politicians or would-be politi-
cians) currently take excessive amounts of time and
memory to run, but typically produce 10,000+ para-
phrases. Pruning earlier during paraphrase genera-
tion should help address this issue.
</bodyText>
<sectionHeader confidence="0.999153" genericHeader="method">
4 Future Work
</sectionHeader>
<bodyText confidence="0.999904666666667">
Currently, Mutaphrase requires the input sentences
to have been marked with FrameNet annotations
prior to processing. Although automatic semantic
parsing is a large and growing field (Moldovan et
al., 2004; Litkowski, 2004; Baldewein et al., 2004),
two problems present themselves. First, output from
</bodyText>
<page confidence="0.996255">
148
</page>
<bodyText confidence="0.999980225">
an automated parser is not typically compatible with
FrameNet markup. Although this is mostly “a sim-
ple matter of programming”, some linguistic tools
must be developed to convert between formats (e.g.
to infer FrameNet phrase types from part-of-speech
tags).5 Second, it is not yet clear how the inevitable
errors introduced by the parser will affect the Mu-
taphrase algorithm6. We plan to use application-
dependent measures to judge the effects of parsing
errors.
Certain types of semantic ill-formedness cannot
be detected by the current version of Mutaphrase. A
typical example is I like sipping beef as a paraphrase
of I like eating cheese. We can guarantee semantic
well-formedness by limiting paraphrases to morpho-
logically related words (e.g. consume, consumption)
and/or by choosing only the FrameNet LUs which
are in the same WordNet (Fellbaum, 1998; Word-
Net, 2006) synset or higher in the WN hierarchy
than the original LU (e.g. eat to consume). Clearly
this will exclude many well-formed paraphrases, so
for tasks in which breadth is more important than
accuracy of paraphrase, we anticipate experiment-
ing with WordNet hierarchy distances between the
original and paraphrase LUs as a quantitative mea-
sure of semantic similarity as a proxy for semantic
well-formedness.
Currently, paraphrase scores are computed sim-
ply from the frequency of a particular valence in
FrameNet data. We plan to significantly extend
scoring to simultaneously rate each paraphrase on
its WordNet similarity, syntactic edit distance7, and
language model scores. We also plan to measure the
correlation between these estimated scores and both
human-judged paraphrase accuracy and application
dependent metrics, e.g. extension of in-domain lan-
guage models by paraphrase.
WordNet can also be used to provide additional
paraphrases beyond the particular valences attested
in FrameNet. For example, we plan to use WordNet
</bodyText>
<footnote confidence="0.981376777777778">
5It is worth noting that the current SemEval competition
(FrameNet, 2007a) should lead to more complete automatic
FrameNet-style annotation.
6An anecdotal example from a semantic parse of I was pre-
pared for a hound, but not for such a creature as this. (Doyle,
1902) assigns prepared to the Cooking creation frame, leading
to the interesting paraphrase I was tenderizedfor a hound....
7We plan to base the syntactic distance on the edit distance
between the original and paraphrase syntactic valences.
</footnote>
<bodyText confidence="0.9997255">
to generate synonyms of target words so that, for ex-
ample, adore could be used anywhere like is used
even if adore never appears in the FrameNet data.
Finally, the structure of the Mutaphrase algorithm
makes multi-lingual paraphrase possible. This re-
quires FrameNet-like data in other languages, and
several projects are underway to provide just such
a resource (FrameNet, 2007d; FrameNet, 2007c;
SALSA, 2007). We plan to exploit these as they be-
come available.
</bodyText>
<sectionHeader confidence="0.999407" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999995230769231">
We have presented the Mutaphrase algorithm, a sys-
tem for generating a large set of paraphrases of se-
mantically marked input sentences using FrameNet.
The generated sentences range widely in their sim-
ilarity to the input sentence both in terms of syntax
and semantics. Various methods of filtering the out-
put for well-formedness and semantic and syntactic
similarity were presented.
Although the current implementation suffers from
a number of limitations, we believe these can be
addressed, eventually providing a fully automated
paraphrase system suitable for use in a variety of sta-
tistical natural language processing systems.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9994658">
This work was partly supported by the European
Union 6th FWP IST Integrated Project AMI (Aug-
mented Multi-party Interaction, FP6-506811), and
by the Swiss National Science Foundation through
NCCR’s IM2 project.
</bodyText>
<sectionHeader confidence="0.99723" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.911451">
U. Baldewein, K. Erk, S. Pad´o, and D. Prescher. 2004.
Semantic role labelling with similarity-based general-
ization using EM-based clustering. In R. Mihalcea and
P. Edmonds, editors, Senseval-3: Third International
Workshop on the Evaluation ofSystemsfor the Seman-
tic Analysis of Text, pages 64–68, Barcelona, Spain,
July. Association for Computational Linguistics.
C. Bannard and C. Callison-Burch. 2005. Paraphrasing
with bilingual parallel corpora. In Proceedings of the
43rd annual meeting of the Association for Computa-
tional Linguistics (ACL), pages 597–604, Ann Arbor,
June.
R. Barzilay and L. Lee. 2003. Learning to paraphrase:
An unsupervised approach using multiple-sequence
</reference>
<page confidence="0.995695">
149
</page>
<reference confidence="0.99938069072165">
alignment. In Proceedings of the Human Language
Technology Conference (HLT), pages 16–23, Edmon-
ton, Canada, May.
R. Barzilay and K. McKeown. 2001. Extracting para-
phrases from a parallel corpus. In Proceedings of the
Annual Meeting of the Association for Computational
Linguistics (ACL), pages 50–57, Toulouse, July.
C. Callison-Burch, P. Koehn, and M. Osborne. 2006.
Improved statistical machine translation using para-
phrases. In Proceedings ofthe Human Language Tech-
nology Conference (HLT), pages 17–24, New York
City, June.
W. Dolan, C. Quirk, and C. Brockett. 2004. Unsuper-
vised construction of large paraphrase corpora: Ex-
ploiting massively parallel news sources. In Proceed-
ings of the 20th International Conference on Compu-
tational Linguistics (COLING), Geneva, Switzerland,
August.
A.C. Doyle. 1902. Hound of the Baskervilles. Project
Gutenburg web site.
http://www.gutenberg.org/dirs/etext02/bskrv11a.txt.
K. Erk and S. Pad´o. 2006. Shalmaneser — a flex-
ible toolbox for semantic role assignment. In Pro-
ceedings of the Fifth International Conference on Lan-
guage Resources and Evaluation (LREC), pages 527–
532, Genoa, Italy, May.
C. Fellbaum. 1998. WordNet: An Electronic Lexical
Database. The MIT Press, May.
T. Fontenelle, editor. 2003. International Journal ofLex-
icography Special Issue on FrameNet and Frame Se-
mantics. Oxford University Press, September. volume
16(3).
FrameNet. 2007a. The FrameNet task on SemEval web
site. http://nlp.cs.swarthmore.edu/semeval/
tasks/task19/summary.shtml.
FrameNet. 2007b. FrameNet web site.
http://framenet.icsi.berkeley.edu.
Japanese FrameNet. 2007c. Japanese FrameNet web
site. http://jfn.st.hc.keio.ac.jp/.
Spanish FrameNet. 2007d. Spanish FrameNet web site.
http://gemini.uab.es:9080/SFNsite.
A. Ibrahim, B. Katz, and J. Lin. 2003. Extracting struc-
tural paraphrases from aligned monolingual corpora.
In Proceedings of the Second International Workshop
on Paraphrasing, pages 57–64, Sapporo, Japan, July.
D. Kauchak and R. Barzilay. 2006. Paraphrasing for
automatic evaluation. In Proceedings of the Human
Language Technology Conference (HLT), pages 455–
462, New York City, June.
R. Kittredge. 2002. Paraphrasing for condensation in
journal abstracting. Journal of Biomedical Informat-
ics, 35(4):265–277.
D. Lin and P. Pantel. 2001. Discovery of inference rules
for question-answering. Natural Language Engineer-
ing, 7(4):343–360.
K. Litkowski. 2004. Senseval-3 task: Automatic labeling
of semantic roles. In R. Mihalcea and P. Edmonds,
editors, Senseval-3: Third International Workshop on
the Evaluation of Systems for the Semantic Analysis of
Text, pages 9–12, Barcelona, Spain, July. Association
for Computational Linguistics.
D. Moldovan, R. Girju, M. Olteanu, and O. Fortu. 2004.
SVM classification of FrameNet semantic roles. In
Rada Mihalcea and Phil Edmonds, editors, Senseval-
3: Third International Workshop on the Evaluation of
Systems for the Semantic Analysis of Text, pages 167–
170, Barcelona, Spain, July. Association for Computa-
tional Linguistics.
B. Pang, K. Knight, and D. Marcu. 2003. Syntax-based
alignment of multiple translations: Extracting para-
phrases and generating new sentences. In Proceed-
ings of the Human Language Technology Conference
(HLT), pages 102–109, Edmonton, Canada, May.
C. Quirk, C. Brockett, and W. Dolan. 2004. Monolingual
machine translation for paraphrase generation. In Pro-
ceedings of the 2004 Conference on Empirical Meth-
ods in Natural Language Processing, pages 142–149,
Barcelona Spain, July.
F. Rinaldi, J. Dowdall, K. Kaljurand, M. Hess, and
D. Moll´a. 2003. Exploiting paraphrases in a question
answering system. In Proceedings of the Second In-
ternational Workshop on Paraphrasing, pages 25–32,
July.
SALSA. 2007. SALSA Project web site.
http://www.coli.uni-saarland.de/projects/salsa/.
Y. Shinyama, S. Sekine, K. Sudo, and R. Grishman.
2002. Automatic paraphrase acquisition from news
articles. In Proceedings of Human Language Tech-
nology Conference (HLT), pages 40–46, San Diego,
March.
WordNet. 2006. WordNet web site.
http://wordnet.princeton.edu.
I. Zukerman and B. Raskutti. 2002. Lexical query para-
phrasing for document retrieval. In Proceedings of the
19th International Conference on Computational Lin-
guistics (COLING), pages 1–7, Taipei, Taiwan, Au-
gust.
</reference>
<page confidence="0.998296">
150
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.886350">
<title confidence="0.999578">Mutaphrase: Paraphrasing with FrameNet</title>
<author confidence="0.980688">Ellsworth</author>
<affiliation confidence="0.999186">International Computer Science</affiliation>
<address confidence="0.9966145">1947 Center Street, Suite Berkeley, CA 94704-1105 USA</address>
<abstract confidence="0.995636476190476">We describe a preliminary version of Mutaphrase, a system that generates paraphrases of semantically labeled input sentences using the semantics and syntax encoded in FrameNet, a freely available lexicosemantic database. The algorithm generates a large number of paraphrases with a wide range of syntactic and semantic distances from the input. For example, given the input “I like eating cheese”, the system outputs the syntactically distant “Eating cheese is liked by me”, the semantically distant “I fear sipping juice”, and thousands of other sentences. The wide range of generated paraphrases makes the algorithm ideal for a range of statistical machine learning problems such as machine translation and language modeling as well as other semanticsdependent tasks such as query and language generation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>U Baldewein</author>
<author>K Erk</author>
<author>S Pad´o</author>
<author>D Prescher</author>
</authors>
<title>Semantic role labelling with similarity-based generalization using EM-based clustering.</title>
<date>2004</date>
<booktitle>Senseval-3: Third International Workshop on the Evaluation ofSystemsfor the Semantic Analysis of Text,</booktitle>
<pages>64--68</pages>
<editor>In R. Mihalcea and P. Edmonds, editors,</editor>
<publisher>Association for Computational Linguistics.</publisher>
<location>Barcelona, Spain,</location>
<marker>Baldewein, Erk, Pad´o, Prescher, 2004</marker>
<rawString>U. Baldewein, K. Erk, S. Pad´o, and D. Prescher. 2004. Semantic role labelling with similarity-based generalization using EM-based clustering. In R. Mihalcea and P. Edmonds, editors, Senseval-3: Third International Workshop on the Evaluation ofSystemsfor the Semantic Analysis of Text, pages 64–68, Barcelona, Spain, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Bannard</author>
<author>C Callison-Burch</author>
</authors>
<title>Paraphrasing with bilingual parallel corpora.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd annual meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>597--604</pages>
<location>Ann Arbor,</location>
<contexts>
<context position="1840" citStr="Bannard and Callison-Burch, 2005" startWordPosition="274" endWordPosition="277">orpus, keeping similar semantics while changing both the words and the word sequence. The efficacy of this approach has been well-established in many areas, including automated evaluation of machine translation systems (Kauchak and Barzilay, 2006), text summarization (Kittredge, 2002), question answering (Rinaldi et al., 2003), document retrieval (Zukerman and Raskutti, 2002), and many others. Most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (Bannard and Callison-Burch, 2005; Barzilay and Lee, 2003; Barzilay and McKeown, 2001; Callison-Burch et al., 2006; Dolan et al., 2004; Ibrahim et al., 2003; Lin and Pantel, 2001; Pang et al., 2003; Quirk et al., 2004; Shinyama et al., 2002). Mutaphrase instead generates paraphrases algorithmically using an input sentence and FrameNet, a freely available lexico-semantic resource (information regarding FrameNet, including relevant terminology, is presented in Section 2). Figure 1: Syntactic and semantic similarity to I like eating cheese. Conceptually, the Mutaphrase algorithm takes a semantic specification of a sentence, prov</context>
</contexts>
<marker>Bannard, Callison-Burch, 2005</marker>
<rawString>C. Bannard and C. Callison-Burch. 2005. Paraphrasing with bilingual parallel corpora. In Proceedings of the 43rd annual meeting of the Association for Computational Linguistics (ACL), pages 597–604, Ann Arbor, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>L Lee</author>
</authors>
<title>Learning to paraphrase: An unsupervised approach using multiple-sequence alignment.</title>
<date>2003</date>
<booktitle>In Proceedings of the Human Language Technology Conference (HLT),</booktitle>
<pages>16--23</pages>
<location>Edmonton, Canada,</location>
<contexts>
<context position="1864" citStr="Barzilay and Lee, 2003" startWordPosition="278" endWordPosition="282">hile changing both the words and the word sequence. The efficacy of this approach has been well-established in many areas, including automated evaluation of machine translation systems (Kauchak and Barzilay, 2006), text summarization (Kittredge, 2002), question answering (Rinaldi et al., 2003), document retrieval (Zukerman and Raskutti, 2002), and many others. Most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (Bannard and Callison-Burch, 2005; Barzilay and Lee, 2003; Barzilay and McKeown, 2001; Callison-Burch et al., 2006; Dolan et al., 2004; Ibrahim et al., 2003; Lin and Pantel, 2001; Pang et al., 2003; Quirk et al., 2004; Shinyama et al., 2002). Mutaphrase instead generates paraphrases algorithmically using an input sentence and FrameNet, a freely available lexico-semantic resource (information regarding FrameNet, including relevant terminology, is presented in Section 2). Figure 1: Syntactic and semantic similarity to I like eating cheese. Conceptually, the Mutaphrase algorithm takes a semantic specification of a sentence, provided by an automatic sem</context>
</contexts>
<marker>Barzilay, Lee, 2003</marker>
<rawString>R. Barzilay and L. Lee. 2003. Learning to paraphrase: An unsupervised approach using multiple-sequence alignment. In Proceedings of the Human Language Technology Conference (HLT), pages 16–23, Edmonton, Canada, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>K McKeown</author>
</authors>
<title>Extracting paraphrases from a parallel corpus.</title>
<date>2001</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>50--57</pages>
<location>Toulouse,</location>
<contexts>
<context position="1892" citStr="Barzilay and McKeown, 2001" startWordPosition="283" endWordPosition="286">ords and the word sequence. The efficacy of this approach has been well-established in many areas, including automated evaluation of machine translation systems (Kauchak and Barzilay, 2006), text summarization (Kittredge, 2002), question answering (Rinaldi et al., 2003), document retrieval (Zukerman and Raskutti, 2002), and many others. Most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (Bannard and Callison-Burch, 2005; Barzilay and Lee, 2003; Barzilay and McKeown, 2001; Callison-Burch et al., 2006; Dolan et al., 2004; Ibrahim et al., 2003; Lin and Pantel, 2001; Pang et al., 2003; Quirk et al., 2004; Shinyama et al., 2002). Mutaphrase instead generates paraphrases algorithmically using an input sentence and FrameNet, a freely available lexico-semantic resource (information regarding FrameNet, including relevant terminology, is presented in Section 2). Figure 1: Syntactic and semantic similarity to I like eating cheese. Conceptually, the Mutaphrase algorithm takes a semantic specification of a sentence, provided by an automatic semantic parser such as Shalman</context>
</contexts>
<marker>Barzilay, McKeown, 2001</marker>
<rawString>R. Barzilay and K. McKeown. 2001. Extracting paraphrases from a parallel corpus. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), pages 50–57, Toulouse, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Callison-Burch</author>
<author>P Koehn</author>
<author>M Osborne</author>
</authors>
<title>Improved statistical machine translation using paraphrases.</title>
<date>2006</date>
<booktitle>In Proceedings ofthe Human Language Technology Conference (HLT),</booktitle>
<pages>17--24</pages>
<location>New York City,</location>
<contexts>
<context position="1921" citStr="Callison-Burch et al., 2006" startWordPosition="287" endWordPosition="290">The efficacy of this approach has been well-established in many areas, including automated evaluation of machine translation systems (Kauchak and Barzilay, 2006), text summarization (Kittredge, 2002), question answering (Rinaldi et al., 2003), document retrieval (Zukerman and Raskutti, 2002), and many others. Most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (Bannard and Callison-Burch, 2005; Barzilay and Lee, 2003; Barzilay and McKeown, 2001; Callison-Burch et al., 2006; Dolan et al., 2004; Ibrahim et al., 2003; Lin and Pantel, 2001; Pang et al., 2003; Quirk et al., 2004; Shinyama et al., 2002). Mutaphrase instead generates paraphrases algorithmically using an input sentence and FrameNet, a freely available lexico-semantic resource (information regarding FrameNet, including relevant terminology, is presented in Section 2). Figure 1: Syntactic and semantic similarity to I like eating cheese. Conceptually, the Mutaphrase algorithm takes a semantic specification of a sentence, provided by an automatic semantic parser such as Shalmaneser (Erk SemantICS I fear SI</context>
</contexts>
<marker>Callison-Burch, Koehn, Osborne, 2006</marker>
<rawString>C. Callison-Burch, P. Koehn, and M. Osborne. 2006. Improved statistical machine translation using paraphrases. In Proceedings ofthe Human Language Technology Conference (HLT), pages 17–24, New York City, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Dolan</author>
<author>C Quirk</author>
<author>C Brockett</author>
</authors>
<title>Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics (COLING),</booktitle>
<location>Geneva, Switzerland,</location>
<contexts>
<context position="1941" citStr="Dolan et al., 2004" startWordPosition="291" endWordPosition="294"> has been well-established in many areas, including automated evaluation of machine translation systems (Kauchak and Barzilay, 2006), text summarization (Kittredge, 2002), question answering (Rinaldi et al., 2003), document retrieval (Zukerman and Raskutti, 2002), and many others. Most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (Bannard and Callison-Burch, 2005; Barzilay and Lee, 2003; Barzilay and McKeown, 2001; Callison-Burch et al., 2006; Dolan et al., 2004; Ibrahim et al., 2003; Lin and Pantel, 2001; Pang et al., 2003; Quirk et al., 2004; Shinyama et al., 2002). Mutaphrase instead generates paraphrases algorithmically using an input sentence and FrameNet, a freely available lexico-semantic resource (information regarding FrameNet, including relevant terminology, is presented in Section 2). Figure 1: Syntactic and semantic similarity to I like eating cheese. Conceptually, the Mutaphrase algorithm takes a semantic specification of a sentence, provided by an automatic semantic parser such as Shalmaneser (Erk SemantICS I fear SIPPIng JUICe. TO SIP </context>
</contexts>
<marker>Dolan, Quirk, Brockett, 2004</marker>
<rawString>W. Dolan, C. Quirk, and C. Brockett. 2004. Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources. In Proceedings of the 20th International Conference on Computational Linguistics (COLING), Geneva, Switzerland, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A C Doyle</author>
</authors>
<title>Hound of the Baskervilles. Project Gutenburg web site.</title>
<date>1902</date>
<note>http://www.gutenberg.org/dirs/etext02/bskrv11a.txt.</note>
<contexts>
<context position="25123" citStr="Doyle, 1902" startWordPosition="4015" endWordPosition="4016">lan to measure the correlation between these estimated scores and both human-judged paraphrase accuracy and application dependent metrics, e.g. extension of in-domain language models by paraphrase. WordNet can also be used to provide additional paraphrases beyond the particular valences attested in FrameNet. For example, we plan to use WordNet 5It is worth noting that the current SemEval competition (FrameNet, 2007a) should lead to more complete automatic FrameNet-style annotation. 6An anecdotal example from a semantic parse of I was prepared for a hound, but not for such a creature as this. (Doyle, 1902) assigns prepared to the Cooking creation frame, leading to the interesting paraphrase I was tenderizedfor a hound.... 7We plan to base the syntactic distance on the edit distance between the original and paraphrase syntactic valences. to generate synonyms of target words so that, for example, adore could be used anywhere like is used even if adore never appears in the FrameNet data. Finally, the structure of the Mutaphrase algorithm makes multi-lingual paraphrase possible. This requires FrameNet-like data in other languages, and several projects are underway to provide just such a resource (F</context>
</contexts>
<marker>Doyle, 1902</marker>
<rawString>A.C. Doyle. 1902. Hound of the Baskervilles. Project Gutenburg web site. http://www.gutenberg.org/dirs/etext02/bskrv11a.txt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Erk</author>
<author>S Pad´o</author>
</authors>
<title>Shalmaneser — a flexible toolbox for semantic role assignment.</title>
<date>2006</date>
<booktitle>In Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>527--532</pages>
<location>Genoa, Italy,</location>
<marker>Erk, Pad´o, 2006</marker>
<rawString>K. Erk and S. Pad´o. 2006. Shalmaneser — a flexible toolbox for semantic role assignment. In Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC), pages 527– 532, Genoa, Italy, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>The MIT Press,</publisher>
<contexts>
<context position="23811" citStr="Fellbaum, 1998" startWordPosition="3814" endWordPosition="3815">of-speech tags).5 Second, it is not yet clear how the inevitable errors introduced by the parser will affect the Mutaphrase algorithm6. We plan to use applicationdependent measures to judge the effects of parsing errors. Certain types of semantic ill-formedness cannot be detected by the current version of Mutaphrase. A typical example is I like sipping beef as a paraphrase of I like eating cheese. We can guarantee semantic well-formedness by limiting paraphrases to morphologically related words (e.g. consume, consumption) and/or by choosing only the FrameNet LUs which are in the same WordNet (Fellbaum, 1998; WordNet, 2006) synset or higher in the WN hierarchy than the original LU (e.g. eat to consume). Clearly this will exclude many well-formed paraphrases, so for tasks in which breadth is more important than accuracy of paraphrase, we anticipate experimenting with WordNet hierarchy distances between the original and paraphrase LUs as a quantitative measure of semantic similarity as a proxy for semantic well-formedness. Currently, paraphrase scores are computed simply from the frequency of a particular valence in FrameNet data. We plan to significantly extend scoring to simultaneously rate each </context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>C. Fellbaum. 1998. WordNet: An Electronic Lexical Database. The MIT Press, May.</rawString>
</citation>
<citation valid="true">
<date></date>
<booktitle>2003. International Journal ofLexicography Special Issue on FrameNet and Frame Semantics.</booktitle>
<volume>16</volume>
<issue>3</issue>
<editor>T. Fontenelle, editor.</editor>
<publisher>Oxford University Press,</publisher>
<marker></marker>
<rawString>T. Fontenelle, editor. 2003. International Journal ofLexicography Special Issue on FrameNet and Frame Semantics. Oxford University Press, September. volume 16(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>FrameNet</author>
</authors>
<title>The FrameNet task on SemEval web site.</title>
<date>2007</date>
<note>http://nlp.cs.swarthmore.edu/semeval/ tasks/task19/summary.shtml.</note>
<contexts>
<context position="4517" citStr="FrameNet, 2007" startWordPosition="697" endWordPosition="698">systems for FrameNet-specific annotation are currently incorporated into our algorithm, input is limited to hand-annotated sentences. Also, certain types of semantic ill-formedness are permitted (e.g. I like sipping meat), and some types of syntax are not well supported (e.g. conjunctions, relativeclauses). We believe all these factors can be addressed; they are covered briefly in Future Work (Section 4). We confine ourselves in other sections to describing the core Mutaphrase algorithm as currently implemented. 2 FrameNet The primary resource used in Mutaphrase is FrameNet (Fontenelle, 2003; FrameNet, 2007b), a lexico-semantic database that describes concepts and their interrelations, wordform and wordsequence information, syntactic categories, and mappings between conceptual and lexical/syntactic information. All of these are grounded in handannotated examples of real-world sentences. At a slightly more abstract level, FrameNet can be described as providing a two-way mapping between meaning (semantics) and form (syntax, wordforms, sequences). 2.1 Semantics The conceptual information is represented using frames, where a frame is a type of schema or scenario (e.g. Motion, Commercial transaction)</context>
<context position="24929" citStr="FrameNet, 2007" startWordPosition="3982" endWordPosition="3983">r valence in FrameNet data. We plan to significantly extend scoring to simultaneously rate each paraphrase on its WordNet similarity, syntactic edit distance7, and language model scores. We also plan to measure the correlation between these estimated scores and both human-judged paraphrase accuracy and application dependent metrics, e.g. extension of in-domain language models by paraphrase. WordNet can also be used to provide additional paraphrases beyond the particular valences attested in FrameNet. For example, we plan to use WordNet 5It is worth noting that the current SemEval competition (FrameNet, 2007a) should lead to more complete automatic FrameNet-style annotation. 6An anecdotal example from a semantic parse of I was prepared for a hound, but not for such a creature as this. (Doyle, 1902) assigns prepared to the Cooking creation frame, leading to the interesting paraphrase I was tenderizedfor a hound.... 7We plan to base the syntactic distance on the edit distance between the original and paraphrase syntactic valences. to generate synonyms of target words so that, for example, adore could be used anywhere like is used even if adore never appears in the FrameNet data. Finally, the struct</context>
</contexts>
<marker>FrameNet, 2007</marker>
<rawString>FrameNet. 2007a. The FrameNet task on SemEval web site. http://nlp.cs.swarthmore.edu/semeval/ tasks/task19/summary.shtml.</rawString>
</citation>
<citation valid="true">
<authors>
<author>FrameNet</author>
</authors>
<date>2007</date>
<note>FrameNet web site. http://framenet.icsi.berkeley.edu.</note>
<contexts>
<context position="4517" citStr="FrameNet, 2007" startWordPosition="697" endWordPosition="698">systems for FrameNet-specific annotation are currently incorporated into our algorithm, input is limited to hand-annotated sentences. Also, certain types of semantic ill-formedness are permitted (e.g. I like sipping meat), and some types of syntax are not well supported (e.g. conjunctions, relativeclauses). We believe all these factors can be addressed; they are covered briefly in Future Work (Section 4). We confine ourselves in other sections to describing the core Mutaphrase algorithm as currently implemented. 2 FrameNet The primary resource used in Mutaphrase is FrameNet (Fontenelle, 2003; FrameNet, 2007b), a lexico-semantic database that describes concepts and their interrelations, wordform and wordsequence information, syntactic categories, and mappings between conceptual and lexical/syntactic information. All of these are grounded in handannotated examples of real-world sentences. At a slightly more abstract level, FrameNet can be described as providing a two-way mapping between meaning (semantics) and form (syntax, wordforms, sequences). 2.1 Semantics The conceptual information is represented using frames, where a frame is a type of schema or scenario (e.g. Motion, Commercial transaction)</context>
<context position="24929" citStr="FrameNet, 2007" startWordPosition="3982" endWordPosition="3983">r valence in FrameNet data. We plan to significantly extend scoring to simultaneously rate each paraphrase on its WordNet similarity, syntactic edit distance7, and language model scores. We also plan to measure the correlation between these estimated scores and both human-judged paraphrase accuracy and application dependent metrics, e.g. extension of in-domain language models by paraphrase. WordNet can also be used to provide additional paraphrases beyond the particular valences attested in FrameNet. For example, we plan to use WordNet 5It is worth noting that the current SemEval competition (FrameNet, 2007a) should lead to more complete automatic FrameNet-style annotation. 6An anecdotal example from a semantic parse of I was prepared for a hound, but not for such a creature as this. (Doyle, 1902) assigns prepared to the Cooking creation frame, leading to the interesting paraphrase I was tenderizedfor a hound.... 7We plan to base the syntactic distance on the edit distance between the original and paraphrase syntactic valences. to generate synonyms of target words so that, for example, adore could be used anywhere like is used even if adore never appears in the FrameNet data. Finally, the struct</context>
</contexts>
<marker>FrameNet, 2007</marker>
<rawString>FrameNet. 2007b. FrameNet web site. http://framenet.icsi.berkeley.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Japanese FrameNet</author>
</authors>
<date>2007</date>
<note>Japanese FrameNet web site. http://jfn.st.hc.keio.ac.jp/.</note>
<contexts>
<context position="4517" citStr="FrameNet, 2007" startWordPosition="697" endWordPosition="698">systems for FrameNet-specific annotation are currently incorporated into our algorithm, input is limited to hand-annotated sentences. Also, certain types of semantic ill-formedness are permitted (e.g. I like sipping meat), and some types of syntax are not well supported (e.g. conjunctions, relativeclauses). We believe all these factors can be addressed; they are covered briefly in Future Work (Section 4). We confine ourselves in other sections to describing the core Mutaphrase algorithm as currently implemented. 2 FrameNet The primary resource used in Mutaphrase is FrameNet (Fontenelle, 2003; FrameNet, 2007b), a lexico-semantic database that describes concepts and their interrelations, wordform and wordsequence information, syntactic categories, and mappings between conceptual and lexical/syntactic information. All of these are grounded in handannotated examples of real-world sentences. At a slightly more abstract level, FrameNet can be described as providing a two-way mapping between meaning (semantics) and form (syntax, wordforms, sequences). 2.1 Semantics The conceptual information is represented using frames, where a frame is a type of schema or scenario (e.g. Motion, Commercial transaction)</context>
<context position="24929" citStr="FrameNet, 2007" startWordPosition="3982" endWordPosition="3983">r valence in FrameNet data. We plan to significantly extend scoring to simultaneously rate each paraphrase on its WordNet similarity, syntactic edit distance7, and language model scores. We also plan to measure the correlation between these estimated scores and both human-judged paraphrase accuracy and application dependent metrics, e.g. extension of in-domain language models by paraphrase. WordNet can also be used to provide additional paraphrases beyond the particular valences attested in FrameNet. For example, we plan to use WordNet 5It is worth noting that the current SemEval competition (FrameNet, 2007a) should lead to more complete automatic FrameNet-style annotation. 6An anecdotal example from a semantic parse of I was prepared for a hound, but not for such a creature as this. (Doyle, 1902) assigns prepared to the Cooking creation frame, leading to the interesting paraphrase I was tenderizedfor a hound.... 7We plan to base the syntactic distance on the edit distance between the original and paraphrase syntactic valences. to generate synonyms of target words so that, for example, adore could be used anywhere like is used even if adore never appears in the FrameNet data. Finally, the struct</context>
</contexts>
<marker>FrameNet, 2007</marker>
<rawString>Japanese FrameNet. 2007c. Japanese FrameNet web site. http://jfn.st.hc.keio.ac.jp/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spanish FrameNet</author>
</authors>
<date>2007</date>
<note>Spanish FrameNet web site. http://gemini.uab.es:9080/SFNsite.</note>
<contexts>
<context position="4517" citStr="FrameNet, 2007" startWordPosition="697" endWordPosition="698">systems for FrameNet-specific annotation are currently incorporated into our algorithm, input is limited to hand-annotated sentences. Also, certain types of semantic ill-formedness are permitted (e.g. I like sipping meat), and some types of syntax are not well supported (e.g. conjunctions, relativeclauses). We believe all these factors can be addressed; they are covered briefly in Future Work (Section 4). We confine ourselves in other sections to describing the core Mutaphrase algorithm as currently implemented. 2 FrameNet The primary resource used in Mutaphrase is FrameNet (Fontenelle, 2003; FrameNet, 2007b), a lexico-semantic database that describes concepts and their interrelations, wordform and wordsequence information, syntactic categories, and mappings between conceptual and lexical/syntactic information. All of these are grounded in handannotated examples of real-world sentences. At a slightly more abstract level, FrameNet can be described as providing a two-way mapping between meaning (semantics) and form (syntax, wordforms, sequences). 2.1 Semantics The conceptual information is represented using frames, where a frame is a type of schema or scenario (e.g. Motion, Commercial transaction)</context>
<context position="24929" citStr="FrameNet, 2007" startWordPosition="3982" endWordPosition="3983">r valence in FrameNet data. We plan to significantly extend scoring to simultaneously rate each paraphrase on its WordNet similarity, syntactic edit distance7, and language model scores. We also plan to measure the correlation between these estimated scores and both human-judged paraphrase accuracy and application dependent metrics, e.g. extension of in-domain language models by paraphrase. WordNet can also be used to provide additional paraphrases beyond the particular valences attested in FrameNet. For example, we plan to use WordNet 5It is worth noting that the current SemEval competition (FrameNet, 2007a) should lead to more complete automatic FrameNet-style annotation. 6An anecdotal example from a semantic parse of I was prepared for a hound, but not for such a creature as this. (Doyle, 1902) assigns prepared to the Cooking creation frame, leading to the interesting paraphrase I was tenderizedfor a hound.... 7We plan to base the syntactic distance on the edit distance between the original and paraphrase syntactic valences. to generate synonyms of target words so that, for example, adore could be used anywhere like is used even if adore never appears in the FrameNet data. Finally, the struct</context>
</contexts>
<marker>FrameNet, 2007</marker>
<rawString>Spanish FrameNet. 2007d. Spanish FrameNet web site. http://gemini.uab.es:9080/SFNsite.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ibrahim</author>
<author>B Katz</author>
<author>J Lin</author>
</authors>
<title>Extracting structural paraphrases from aligned monolingual corpora.</title>
<date>2003</date>
<booktitle>In Proceedings of the Second International Workshop on Paraphrasing,</booktitle>
<pages>57--64</pages>
<location>Sapporo, Japan,</location>
<contexts>
<context position="1963" citStr="Ibrahim et al., 2003" startWordPosition="295" endWordPosition="298">lished in many areas, including automated evaluation of machine translation systems (Kauchak and Barzilay, 2006), text summarization (Kittredge, 2002), question answering (Rinaldi et al., 2003), document retrieval (Zukerman and Raskutti, 2002), and many others. Most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (Bannard and Callison-Burch, 2005; Barzilay and Lee, 2003; Barzilay and McKeown, 2001; Callison-Burch et al., 2006; Dolan et al., 2004; Ibrahim et al., 2003; Lin and Pantel, 2001; Pang et al., 2003; Quirk et al., 2004; Shinyama et al., 2002). Mutaphrase instead generates paraphrases algorithmically using an input sentence and FrameNet, a freely available lexico-semantic resource (information regarding FrameNet, including relevant terminology, is presented in Section 2). Figure 1: Syntactic and semantic similarity to I like eating cheese. Conceptually, the Mutaphrase algorithm takes a semantic specification of a sentence, provided by an automatic semantic parser such as Shalmaneser (Erk SemantICS I fear SIPPIng JUICe. TO SIP On JUICe dIStUrbS me. </context>
</contexts>
<marker>Ibrahim, Katz, Lin, 2003</marker>
<rawString>A. Ibrahim, B. Katz, and J. Lin. 2003. Extracting structural paraphrases from aligned monolingual corpora. In Proceedings of the Second International Workshop on Paraphrasing, pages 57–64, Sapporo, Japan, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Kauchak</author>
<author>R Barzilay</author>
</authors>
<title>Paraphrasing for automatic evaluation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference (HLT),</booktitle>
<pages>455--462</pages>
<location>New York City,</location>
<contexts>
<context position="1455" citStr="Kauchak and Barzilay, 2006" startWordPosition="218" endWordPosition="221">ithm ideal for a range of statistical machine learning problems such as machine translation and language modeling as well as other semanticsdependent tasks such as query and language generation. 1 Introduction A central tenet of statistical natural language processing (NLP) is “there’s no data like more data”. One method for generating more data is to restate each phrase in a corpus, keeping similar semantics while changing both the words and the word sequence. The efficacy of this approach has been well-established in many areas, including automated evaluation of machine translation systems (Kauchak and Barzilay, 2006), text summarization (Kittredge, 2002), question answering (Rinaldi et al., 2003), document retrieval (Zukerman and Raskutti, 2002), and many others. Most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (Bannard and Callison-Burch, 2005; Barzilay and Lee, 2003; Barzilay and McKeown, 2001; Callison-Burch et al., 2006; Dolan et al., 2004; Ibrahim et al., 2003; Lin and Pantel, 2001; Pang et al., 2003; Quirk et al., 2004; Shinyama et al., 2002). Mutap</context>
</contexts>
<marker>Kauchak, Barzilay, 2006</marker>
<rawString>D. Kauchak and R. Barzilay. 2006. Paraphrasing for automatic evaluation. In Proceedings of the Human Language Technology Conference (HLT), pages 455– 462, New York City, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Kittredge</author>
</authors>
<title>Paraphrasing for condensation in journal abstracting.</title>
<date>2002</date>
<journal>Journal of Biomedical Informatics,</journal>
<volume>35</volume>
<issue>4</issue>
<contexts>
<context position="1493" citStr="Kittredge, 2002" startWordPosition="224" endWordPosition="225">rning problems such as machine translation and language modeling as well as other semanticsdependent tasks such as query and language generation. 1 Introduction A central tenet of statistical natural language processing (NLP) is “there’s no data like more data”. One method for generating more data is to restate each phrase in a corpus, keeping similar semantics while changing both the words and the word sequence. The efficacy of this approach has been well-established in many areas, including automated evaluation of machine translation systems (Kauchak and Barzilay, 2006), text summarization (Kittredge, 2002), question answering (Rinaldi et al., 2003), document retrieval (Zukerman and Raskutti, 2002), and many others. Most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (Bannard and Callison-Burch, 2005; Barzilay and Lee, 2003; Barzilay and McKeown, 2001; Callison-Burch et al., 2006; Dolan et al., 2004; Ibrahim et al., 2003; Lin and Pantel, 2001; Pang et al., 2003; Quirk et al., 2004; Shinyama et al., 2002). Mutaphrase instead generates paraphrases al</context>
</contexts>
<marker>Kittredge, 2002</marker>
<rawString>R. Kittredge. 2002. Paraphrasing for condensation in journal abstracting. Journal of Biomedical Informatics, 35(4):265–277.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
<author>P Pantel</author>
</authors>
<title>Discovery of inference rules for question-answering.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context position="1985" citStr="Lin and Pantel, 2001" startWordPosition="299" endWordPosition="302">including automated evaluation of machine translation systems (Kauchak and Barzilay, 2006), text summarization (Kittredge, 2002), question answering (Rinaldi et al., 2003), document retrieval (Zukerman and Raskutti, 2002), and many others. Most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (Bannard and Callison-Burch, 2005; Barzilay and Lee, 2003; Barzilay and McKeown, 2001; Callison-Burch et al., 2006; Dolan et al., 2004; Ibrahim et al., 2003; Lin and Pantel, 2001; Pang et al., 2003; Quirk et al., 2004; Shinyama et al., 2002). Mutaphrase instead generates paraphrases algorithmically using an input sentence and FrameNet, a freely available lexico-semantic resource (information regarding FrameNet, including relevant terminology, is presented in Section 2). Figure 1: Syntactic and semantic similarity to I like eating cheese. Conceptually, the Mutaphrase algorithm takes a semantic specification of a sentence, provided by an automatic semantic parser such as Shalmaneser (Erk SemantICS I fear SIPPIng JUICe. TO SIP On JUICe dIStUrbS me. I lIKe tO SnaCK On bre</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>D. Lin and P. Pantel. 2001. Discovery of inference rules for question-answering. Natural Language Engineering, 7(4):343–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Litkowski</author>
</authors>
<title>Senseval-3 task: Automatic labeling of semantic roles.</title>
<date>2004</date>
<booktitle>Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text,</booktitle>
<pages>9--12</pages>
<editor>In R. Mihalcea and P. Edmonds, editors,</editor>
<publisher>Association for Computational Linguistics.</publisher>
<location>Barcelona, Spain,</location>
<contexts>
<context position="22872" citStr="Litkowski, 2004" startWordPosition="3668" endWordPosition="3669">r sentences (e.g. Locally elected school boards, especially in our larger cities, become the prey of ambitious, generally corrupt, and invariably demagogic local politicians or would-be politicians) currently take excessive amounts of time and memory to run, but typically produce 10,000+ paraphrases. Pruning earlier during paraphrase generation should help address this issue. 4 Future Work Currently, Mutaphrase requires the input sentences to have been marked with FrameNet annotations prior to processing. Although automatic semantic parsing is a large and growing field (Moldovan et al., 2004; Litkowski, 2004; Baldewein et al., 2004), two problems present themselves. First, output from 148 an automated parser is not typically compatible with FrameNet markup. Although this is mostly “a simple matter of programming”, some linguistic tools must be developed to convert between formats (e.g. to infer FrameNet phrase types from part-of-speech tags).5 Second, it is not yet clear how the inevitable errors introduced by the parser will affect the Mutaphrase algorithm6. We plan to use applicationdependent measures to judge the effects of parsing errors. Certain types of semantic ill-formedness cannot be det</context>
</contexts>
<marker>Litkowski, 2004</marker>
<rawString>K. Litkowski. 2004. Senseval-3 task: Automatic labeling of semantic roles. In R. Mihalcea and P. Edmonds, editors, Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, pages 9–12, Barcelona, Spain, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Moldovan</author>
<author>R Girju</author>
<author>M Olteanu</author>
<author>O Fortu</author>
</authors>
<title>SVM classification of FrameNet semantic roles.</title>
<date>2004</date>
<booktitle>Senseval3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text,</booktitle>
<pages>167--170</pages>
<editor>In Rada Mihalcea and Phil Edmonds, editors,</editor>
<publisher>Association for Computational Linguistics.</publisher>
<location>Barcelona, Spain,</location>
<contexts>
<context position="22855" citStr="Moldovan et al., 2004" startWordPosition="3664" endWordPosition="3667">to be indicative. Longer sentences (e.g. Locally elected school boards, especially in our larger cities, become the prey of ambitious, generally corrupt, and invariably demagogic local politicians or would-be politicians) currently take excessive amounts of time and memory to run, but typically produce 10,000+ paraphrases. Pruning earlier during paraphrase generation should help address this issue. 4 Future Work Currently, Mutaphrase requires the input sentences to have been marked with FrameNet annotations prior to processing. Although automatic semantic parsing is a large and growing field (Moldovan et al., 2004; Litkowski, 2004; Baldewein et al., 2004), two problems present themselves. First, output from 148 an automated parser is not typically compatible with FrameNet markup. Although this is mostly “a simple matter of programming”, some linguistic tools must be developed to convert between formats (e.g. to infer FrameNet phrase types from part-of-speech tags).5 Second, it is not yet clear how the inevitable errors introduced by the parser will affect the Mutaphrase algorithm6. We plan to use applicationdependent measures to judge the effects of parsing errors. Certain types of semantic ill-formedn</context>
</contexts>
<marker>Moldovan, Girju, Olteanu, Fortu, 2004</marker>
<rawString>D. Moldovan, R. Girju, M. Olteanu, and O. Fortu. 2004. SVM classification of FrameNet semantic roles. In Rada Mihalcea and Phil Edmonds, editors, Senseval3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, pages 167– 170, Barcelona, Spain, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>K Knight</author>
<author>D Marcu</author>
</authors>
<title>Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences.</title>
<date>2003</date>
<booktitle>In Proceedings of the Human Language Technology Conference (HLT),</booktitle>
<pages>102--109</pages>
<location>Edmonton, Canada,</location>
<contexts>
<context position="2004" citStr="Pang et al., 2003" startWordPosition="303" endWordPosition="306">aluation of machine translation systems (Kauchak and Barzilay, 2006), text summarization (Kittredge, 2002), question answering (Rinaldi et al., 2003), document retrieval (Zukerman and Raskutti, 2002), and many others. Most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (Bannard and Callison-Burch, 2005; Barzilay and Lee, 2003; Barzilay and McKeown, 2001; Callison-Burch et al., 2006; Dolan et al., 2004; Ibrahim et al., 2003; Lin and Pantel, 2001; Pang et al., 2003; Quirk et al., 2004; Shinyama et al., 2002). Mutaphrase instead generates paraphrases algorithmically using an input sentence and FrameNet, a freely available lexico-semantic resource (information regarding FrameNet, including relevant terminology, is presented in Section 2). Figure 1: Syntactic and semantic similarity to I like eating cheese. Conceptually, the Mutaphrase algorithm takes a semantic specification of a sentence, provided by an automatic semantic parser such as Shalmaneser (Erk SemantICS I fear SIPPIng JUICe. TO SIP On JUICe dIStUrbS me. I lIKe tO SnaCK On bread. EatIng CheeSe I</context>
</contexts>
<marker>Pang, Knight, Marcu, 2003</marker>
<rawString>B. Pang, K. Knight, and D. Marcu. 2003. Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences. In Proceedings of the Human Language Technology Conference (HLT), pages 102–109, Edmonton, Canada, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Quirk</author>
<author>C Brockett</author>
<author>W Dolan</author>
</authors>
<title>Monolingual machine translation for paraphrase generation.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>142--149</pages>
<location>Barcelona</location>
<contexts>
<context position="2024" citStr="Quirk et al., 2004" startWordPosition="307" endWordPosition="310"> translation systems (Kauchak and Barzilay, 2006), text summarization (Kittredge, 2002), question answering (Rinaldi et al., 2003), document retrieval (Zukerman and Raskutti, 2002), and many others. Most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (Bannard and Callison-Burch, 2005; Barzilay and Lee, 2003; Barzilay and McKeown, 2001; Callison-Burch et al., 2006; Dolan et al., 2004; Ibrahim et al., 2003; Lin and Pantel, 2001; Pang et al., 2003; Quirk et al., 2004; Shinyama et al., 2002). Mutaphrase instead generates paraphrases algorithmically using an input sentence and FrameNet, a freely available lexico-semantic resource (information regarding FrameNet, including relevant terminology, is presented in Section 2). Figure 1: Syntactic and semantic similarity to I like eating cheese. Conceptually, the Mutaphrase algorithm takes a semantic specification of a sentence, provided by an automatic semantic parser such as Shalmaneser (Erk SemantICS I fear SIPPIng JUICe. TO SIP On JUICe dIStUrbS me. I lIKe tO SnaCK On bread. EatIng CheeSe IS lIKed bY me. I lIK</context>
</contexts>
<marker>Quirk, Brockett, Dolan, 2004</marker>
<rawString>C. Quirk, C. Brockett, and W. Dolan. 2004. Monolingual machine translation for paraphrase generation. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, pages 142–149, Barcelona Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Rinaldi</author>
<author>J Dowdall</author>
<author>K Kaljurand</author>
<author>M Hess</author>
<author>D Moll´a</author>
</authors>
<title>Exploiting paraphrases in a question answering system.</title>
<date>2003</date>
<booktitle>In Proceedings of the Second International Workshop on Paraphrasing,</booktitle>
<pages>25--32</pages>
<marker>Rinaldi, Dowdall, Kaljurand, Hess, Moll´a, 2003</marker>
<rawString>F. Rinaldi, J. Dowdall, K. Kaljurand, M. Hess, and D. Moll´a. 2003. Exploiting paraphrases in a question answering system. In Proceedings of the Second International Workshop on Paraphrasing, pages 25–32, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>SALSA</author>
</authors>
<date>2007</date>
<note>SALSA Project web site. http://www.coli.uni-saarland.de/projects/salsa/.</note>
<contexts>
<context position="25768" citStr="SALSA, 2007" startWordPosition="4114" endWordPosition="4115">creation frame, leading to the interesting paraphrase I was tenderizedfor a hound.... 7We plan to base the syntactic distance on the edit distance between the original and paraphrase syntactic valences. to generate synonyms of target words so that, for example, adore could be used anywhere like is used even if adore never appears in the FrameNet data. Finally, the structure of the Mutaphrase algorithm makes multi-lingual paraphrase possible. This requires FrameNet-like data in other languages, and several projects are underway to provide just such a resource (FrameNet, 2007d; FrameNet, 2007c; SALSA, 2007). We plan to exploit these as they become available. 5 Conclusions We have presented the Mutaphrase algorithm, a system for generating a large set of paraphrases of semantically marked input sentences using FrameNet. The generated sentences range widely in their similarity to the input sentence both in terms of syntax and semantics. Various methods of filtering the output for well-formedness and semantic and syntactic similarity were presented. Although the current implementation suffers from a number of limitations, we believe these can be addressed, eventually providing a fully automated par</context>
</contexts>
<marker>SALSA, 2007</marker>
<rawString>SALSA. 2007. SALSA Project web site. http://www.coli.uni-saarland.de/projects/salsa/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Shinyama</author>
<author>S Sekine</author>
<author>K Sudo</author>
<author>R Grishman</author>
</authors>
<title>Automatic paraphrase acquisition from news articles.</title>
<date>2002</date>
<booktitle>In Proceedings of Human Language Technology Conference (HLT),</booktitle>
<pages>40--46</pages>
<location>San Diego,</location>
<contexts>
<context position="2048" citStr="Shinyama et al., 2002" startWordPosition="311" endWordPosition="314"> (Kauchak and Barzilay, 2006), text summarization (Kittredge, 2002), question answering (Rinaldi et al., 2003), document retrieval (Zukerman and Raskutti, 2002), and many others. Most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (Bannard and Callison-Burch, 2005; Barzilay and Lee, 2003; Barzilay and McKeown, 2001; Callison-Burch et al., 2006; Dolan et al., 2004; Ibrahim et al., 2003; Lin and Pantel, 2001; Pang et al., 2003; Quirk et al., 2004; Shinyama et al., 2002). Mutaphrase instead generates paraphrases algorithmically using an input sentence and FrameNet, a freely available lexico-semantic resource (information regarding FrameNet, including relevant terminology, is presented in Section 2). Figure 1: Syntactic and semantic similarity to I like eating cheese. Conceptually, the Mutaphrase algorithm takes a semantic specification of a sentence, provided by an automatic semantic parser such as Shalmaneser (Erk SemantICS I fear SIPPIng JUICe. TO SIP On JUICe dIStUrbS me. I lIKe tO SnaCK On bread. EatIng CheeSe IS lIKed bY me. I lIKe eatIng CheeSe. SYntaX </context>
</contexts>
<marker>Shinyama, Sekine, Sudo, Grishman, 2002</marker>
<rawString>Y. Shinyama, S. Sekine, K. Sudo, and R. Grishman. 2002. Automatic paraphrase acquisition from news articles. In Proceedings of Human Language Technology Conference (HLT), pages 40–46, San Diego, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>WordNet</author>
</authors>
<title>WordNet web site.</title>
<date>2006</date>
<note>http://wordnet.princeton.edu.</note>
<contexts>
<context position="23827" citStr="WordNet, 2006" startWordPosition="3816" endWordPosition="3818">5 Second, it is not yet clear how the inevitable errors introduced by the parser will affect the Mutaphrase algorithm6. We plan to use applicationdependent measures to judge the effects of parsing errors. Certain types of semantic ill-formedness cannot be detected by the current version of Mutaphrase. A typical example is I like sipping beef as a paraphrase of I like eating cheese. We can guarantee semantic well-formedness by limiting paraphrases to morphologically related words (e.g. consume, consumption) and/or by choosing only the FrameNet LUs which are in the same WordNet (Fellbaum, 1998; WordNet, 2006) synset or higher in the WN hierarchy than the original LU (e.g. eat to consume). Clearly this will exclude many well-formed paraphrases, so for tasks in which breadth is more important than accuracy of paraphrase, we anticipate experimenting with WordNet hierarchy distances between the original and paraphrase LUs as a quantitative measure of semantic similarity as a proxy for semantic well-formedness. Currently, paraphrase scores are computed simply from the frequency of a particular valence in FrameNet data. We plan to significantly extend scoring to simultaneously rate each paraphrase on it</context>
</contexts>
<marker>WordNet, 2006</marker>
<rawString>WordNet. 2006. WordNet web site. http://wordnet.princeton.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Zukerman</author>
<author>B Raskutti</author>
</authors>
<title>Lexical query paraphrasing for document retrieval.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics (COLING),</booktitle>
<pages>1--7</pages>
<location>Taipei, Taiwan,</location>
<contexts>
<context position="1586" citStr="Zukerman and Raskutti, 2002" startWordPosition="234" endWordPosition="237"> semanticsdependent tasks such as query and language generation. 1 Introduction A central tenet of statistical natural language processing (NLP) is “there’s no data like more data”. One method for generating more data is to restate each phrase in a corpus, keeping similar semantics while changing both the words and the word sequence. The efficacy of this approach has been well-established in many areas, including automated evaluation of machine translation systems (Kauchak and Barzilay, 2006), text summarization (Kittredge, 2002), question answering (Rinaldi et al., 2003), document retrieval (Zukerman and Raskutti, 2002), and many others. Most of the reported work on paraphrase generation from arbitrary input sentences uses machine learning techniques trained on sentences that are known or can be inferred to be paraphrases of each other (Bannard and Callison-Burch, 2005; Barzilay and Lee, 2003; Barzilay and McKeown, 2001; Callison-Burch et al., 2006; Dolan et al., 2004; Ibrahim et al., 2003; Lin and Pantel, 2001; Pang et al., 2003; Quirk et al., 2004; Shinyama et al., 2002). Mutaphrase instead generates paraphrases algorithmically using an input sentence and FrameNet, a freely available lexico-semantic resour</context>
</contexts>
<marker>Zukerman, Raskutti, 2002</marker>
<rawString>I. Zukerman and B. Raskutti. 2002. Lexical query paraphrasing for document retrieval. In Proceedings of the 19th International Conference on Computational Linguistics (COLING), pages 1–7, Taipei, Taiwan, August.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>