<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000681">
<title confidence="0.9950735">
A Computational Model of Emergent Simple Syntax: Supporting the Natural
Transition from the One-Word Stage to the Two-Word Stage.
</title>
<author confidence="0.99918">
Kris Jack, Chris Reed, and Annalu Waller
</author>
<affiliation confidence="0.9974125">
Division of Applied Computing,
University of Dundee,
</affiliation>
<address confidence="0.986127">
Dundee, Scotland, DD1 4HN
</address>
<email confidence="0.965869">
[kjack  |creed  |awaller]@computing.dundee.ac.uk
</email>
<sectionHeader confidence="0.993444" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999712866666667">
This paper introduces a system that simulates
the transition from the one-word stage to the
two-word stage in child language production.
Two-word descriptions are syntactically
generated and compete against one-word
descriptions from the outset. Two-word
descriptions become dominant as word
combinations are repeatedly recognised,
forming syntactic categories; resulting in an
emergent simple syntax. The system
demonstrates a similar maturation as children
as evidenced by phenomena such as
overextensions and mismatching, and the use
of one-word descriptions being replaced by
two-word descriptions over time.
</bodyText>
<sectionHeader confidence="0.998521" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999876952380952">
Studies of first language acquisition in children
have documented general stages in linguistic
development. Neither the trigger nor the
mechanism that takes a child from one stage to the
next are known. Stages arise gradually with no
precise start or end points, overlapping one
another (Ingram, 1989).
The aim of this research is to develop a system
that autonomously acquires conceptual
representations of individual words (the &amp;quot;one-word
stage&amp;quot;) and also, simultaneously, is capable of
developing representations of valid multi-word
structures i.e. simple syntax (the &amp;quot;two-word
stage&amp;quot;). Two-word descriptions are expected to
emerge as a result of the system state and not be
artificially triggered.
The system accepts sentences containing a
maximum of two words. It is designed to be
scalable, allowing larger, more natural sentence
sizes also. System input is therefore a mixture of
both one-word and two-word sentences. The
system is required to produce valid descriptions,
particularly in the two-word stage. Rules that
enforce syntactic order, and allow for the
production of semantically correct descriptions
from novel concepts, are desirable.
This paper is sectioned as follows; pre-one-
word stage linguistic abilities in children are
briefly discussed to explain why initial system
functionality assumptions are made; the defining
characteristics of both the one-word stage and two-
word stage in children are introduced as possible
benchmarks for the system; a detailed description
of system design and implementation with
examples of the learning process and games played
by the system are presented; a discussion of current
results along with their possible implications
follows; a brief review of related works that have
influenced this research, citing major influences;
the direction and aims of future research is
described briefly; and finally, conclusions are
drawn.
</bodyText>
<sectionHeader confidence="0.889555" genericHeader="introduction">
2 Pre-One-Word Stage Children
</sectionHeader>
<bodyText confidence="0.999762740740741">
Linguistic abilities can be found in children prior
to word production. In terms of comprehension,
children can distinguish between their mother&apos;s
voice and a stranger&apos;s voice, male and female
voices, and sentences spoken in their mother&apos;s
native language and sentences spoken in a different
language. They also show categorical perception
to voice, can use formant transition information to
mark articulation, and show intonation sensitivity
(Pinker, 1994, Jusczyk, 1999).
In terms of production, children produce noises,
such as discomfort noises (0-2 months), comfort
noises (2-4 months), and &amp;quot;play&amp;quot; vocally with pitch
and loudness variations (4-7 months) (Pinker,
1994). The babbling stage (6-8 months) is
characterised with the production of recognisable
syllables. The syllables are often repeated, such as
[mamama] and [papapa], with the easiest to
produce sounds often being associated with
members of the family (Jakobson, 1971).
From this evidence it is reasonable to draw
conclusions about linguistic abilities in the young
child that can be used to frame assumptions for use
in the system. It is assumed that the system can
receive and produce strings that can be broken
down into their component words. These words
can be compared and equalities can be detected.
</bodyText>
<page confidence="0.998881">
61
</page>
<sectionHeader confidence="0.855333" genericHeader="method">
3 One-Word Stage and Two-Word Stages
</sectionHeader>
<bodyText confidence="0.999675541666666">
The system is required to produce one-word
descriptions in early stages that develop into two-
word descriptions, where appropriate, in latter
stages.. The recognition of each stage is based on
the number of words that the system uses at a
particular point. In children, the one and two-word
stages have notable features.
The one-word, or holophrastic, stage (9-18
months), is characterised by one-word
vocalisations that are consistently associated with
concepts. These concepts can be either concrete or
abstract, such as &amp;quot;mama&amp;quot;, referring to the concrete
concept of the child&apos;s mother, and &amp;quot;more&amp;quot;, an
abstract concept which can be applied in a variety
of situations (Piaget, 1960).
Two phenomena that occur during this stage are
underextensions and overextensions. An
underextension is the formation of a word to
concept association that is too narrow, such as
&amp;quot;dog&amp;quot; referring to only the family dog.
Overextension, similarly, is an association that is
too broad, such as &amp;quot;dog&amp;quot; referring to all four
legged animals. Mismatches, or idiosyncratic
referencing also occur, resulting in a word being
associated with an unrelated concept, such as
&amp;quot;dog&amp;quot; referring to a table (Pinker, 1994). These
associations change over time.
The two-word stage (18-24 months) introduces
simple syntax into the child&apos;s language faculty.
Children appear to determine the most important
words in a sentence and, almost all of the time, use
them in the same order as an adult would
(Gleitman and Newport, 1995). Brown (1973)
defines a typology to express semantic relations in
the two-word stage. It contains ten sets of
relations, but only one will be considered in this
paper; attribute + entity (&amp;quot;red circle&amp;quot;). During this
stage, children already demonstrate a three word
comprehension level (Tomasello and Kruger,
1992). The concepts relating to their sentences
may therefore be more detailed than the phrases
themselves.
The system is expected to make the transition
from the one-word stage to the two-word stage
without changes to the functionality of the system.
Once the system begins to run, input is restricted to
that of sensory (concept based) and vocal (string
representation) data.
</bodyText>
<sectionHeader confidence="0.924895" genericHeader="method">
4 System Design and Implementation
</sectionHeader>
<subsectionHeader confidence="0.636478">
4.1 Introduction
</subsectionHeader>
<bodyText confidence="0.999906">
The system is designed to learn phrase-to-
concept associations and demonstrate it through
playing games: a guessing game and a naming
game. Games are often used to test, and encourage
system learning (Steels and Kaplan, 2001). The
learning process involves a user selecting an object
in a scene and naming it. The guessing game
involves a user saying a phrase, and the system
pointing to the object that the phrase refers to. The
naming game involves a user pointing to an object
and the system naming it The system is not
physically grounded, so all games are simulated.
The learning process allows the system to
acquire associations between phrases and concepts
while the games test system comprehension and
system production respectively. The learning
process takes a string and concept as input, and
produces no output. Comprehension takes a string
as input, and produces a concept as output,
whereas production takes a concept as input, and
produces a string as output.
</bodyText>
<subsectionHeader confidence="0.997254">
4.2 Strings and Concepts
</subsectionHeader>
<bodyText confidence="0.999764428571429">
A string is a list of characters with a fixed order.
A blank space is used to separate words within the
string, of which there can be either one or two.
The system can break strings down into their
component words.
A concept is a list of feature values. The
system recognises six feature values; red, blue,
green, white, circle, and square. There are no in-
built associations between any of the feature
values. This form of learning is supported by the
imageability theory (Paiviom 1971). No claims
concerning concept acquisition and formation are
made in this paper. All concepts are hard coded
from the outset.
The full list of objects used in the games are
derived from shape and colour combinations; red
square, red circle, blue square, blue circle, green
square, green circle, white square, and white
circle. Individual feature values can also act as
concepts, therefore the full list is concepts is the
list of object plus the list of feature values.
</bodyText>
<subsectionHeader confidence="0.996356">
4.3 Groups
</subsectionHeader>
<bodyText confidence="0.999058466666667">
To associate a string with a concept, the system
stores a list of groups. Each group contains an ID,
one or more description pairs, an observed
frequency, and zero or more occurrence
supporter links.
The ID acts as a unique identifier, allowing the
group to be found. A description pair is a string
and a concept. Groups must have at least one
description pair since their primary function is to
relate a string to a concept. The observed
frequency represents the number of times that the
description pair&apos;s components have been
associated through system input.
The occurrence supporter links are a set of group
IDs. Each ID in the set refers to a group that
</bodyText>
<page confidence="0.998453">
62
</page>
<bodyText confidence="0.9999113125">
contains a superset of either the description pair, or
the same value for one component of the
description pair and a superset of the other e.g. The
description pair [&amp;quot;red&amp;quot;; red] 1 would be supported
by the description pair [&amp;quot;red square&amp;quot;; red square].
A worked example is provided in the next section.
The links therefore record the number of
occurrences of the group&apos;s description pair. The
occurrence supporter link reinforces the
description pair&apos;s association and increases the
total frequency of the group. The total frequency
is the group&apos;s observed frequency plus the
observed frequency of all of its supporters, never
including a supporter more than once.
Finally, group equality is defined by groups
sharing the same description pair.
</bodyText>
<subsectionHeader confidence="0.998964">
4.4 The Learning Process
</subsectionHeader>
<bodyText confidence="0.999902545454546">
At each stage in the learning process, a
description pair is entered into the system. The
system does not attempt to parse the correctness of
the description. All data is considered to be
positive. The general learning process algorithm is
detailed in the rest of this section. Specific
examples are also provided in Table 1, showing the
groups&apos; values; ID, description pair, occurrence
frequency (OF), occurrence supporter links
(OSLs), and total frequency (TF). Five steps are
followed to incorporate the new data:
</bodyText>
<listItem confidence="0.9961346">
1. Identify the description pair.
2. Find equal and unequal parts.
3. Update system based on equal parts..
4. Update system based on unequal parts.
5. Re-enter new groups into the system.
</listItem>
<subsectionHeader confidence="0.580998">
4.4.1 Identify the description pair
</subsectionHeader>
<bodyText confidence="0.929108263157895">
If the description pair exists in a group that is
already in the system, then that group&apos;s observed
frequency is incremented. Otherwise, the system
creates a new group containing the new
description. It is given a unique ID and an
observed frequency of one. Assume that the
system already contains a group based on the
description pair [&amp;quot;red circle&amp;quot;; red circle]. This has
an ID of one. Assume also that the new
description pair entered is [&amp;quot;red square&amp;quot;; red
square]. Its group has an ID of two (group #2).
All description pairs entered into the system are
called concrete description pairs, this is, the
system has encountered them directly as input.
The new group is referred to as a concrete group,
since it contains a concrete description pair.
1 The convention of strings appearing in quotes
(“red”), and concepts appearing in italics (red) is
adopted throughout this paper.
</bodyText>
<table confidence="0.990743">
ID Description Pair OF OSLs TF
#1 [“red circle”; red circle] 1 [] 1
#2 [“red square”; red 1 [] 1
square]
#3 [“red”; red] 0 [#1,# 2] 2
#4 [“#3 circle”; #3 circle] 0 [#1] 1
#5 [“#3 square”; #3 0 [#2] 1
square]
#6 [“ circle”; circle], 0 [] 0
[“ square”; square]
#7 [“#3 #6”; #3 #6] 0 [#2] 1
</table>
<tableCaption confidence="0.999253">
Table 1: Sample data
</tableCaption>
<subsectionHeader confidence="0.864117">
4.4.2 Find equal and unequal parts
</subsectionHeader>
<bodyText confidence="0.999984217391304">
The new group is compared to all of the groups
in the system. Comparisons are based on the
groups&apos; description pairs alone. Strings are
compared separately from concepts. A string
match is found if one of the strings is a subset, or
exact match, of the other. Subsets of strings must
contain complete words. Words are regarded as
atomic units. Concepts are compared in the same
fashion as strings, where feature values are the
atomic units. Successful comparisons create a set
of equal parts and unequal parts. Comparison
results are only used when equal parts exist. This
approach is similar to alignment based learning,
but with the additional component of concepts (van
Zaanen, 2000).
In comparing the new group, group #2, to the
existing group, group #1, the equal part [&amp;quot;red&amp;quot;;
red] and the unequal part [&amp;quot;circle&amp;quot;; circle],
[&amp;quot;square&amp;quot;; square] are found. The comparison
algorithm is essential to the operation of the
system. It is used in the learning process and in the
games. Without it, no string or concept relations
could be drawn2.
</bodyText>
<subsectionHeader confidence="0.84931">
4.4.3 Update system based on equal parts
</subsectionHeader>
<bodyText confidence="0.972578375">
When an equal part is found, a new group is
created. In the example, an equal part is found
between group #1 and group #2. Group #3 is
created as a result. The new group is given an
observed frequency of zero. The IDs of the groups
that were compared (group #1 and group #2) are
added to the new group&apos;s (group #3) occurrence
supporter links. If the group already exists, then as
well as the existing group&apos;s observed frequency
being incremented, the IDs of the groups that were
compared are added to the occurrence supporter
links. IDs can only appear once in the set of
occurrence supporters links, so if an ID is already
in it, then it is not added.
2 The system assumes full compositionality. Idioms
and metaphors are not considered at this stage.
</bodyText>
<page confidence="0.997515">
63
</page>
<bodyText confidence="0.999970419354839">
Up until this point, all groups&apos; description pairs
have contained a string and concept. Description
pairs can also contain links to other groups&apos; strings
and groups&apos; concepts. These description pairs are
referred to as abstract description pairs. If all
elements of the abstract description pair are links
to other groups then it is fully abstract, else it is
partially abstract. A group that contains an
abstract description pair is called an abstract
group. The group is fully abstract if its abstract
description pair is fully abstract, else it is a
partially abstract group. Once a group has been
created (as group #3 was), based on a description
comparison, the system attempts to make two
abstract groups.
The new abstract groups (group #4 and group
#5) are based on substitutions of the new group&apos;s
ID (group #3) into each of the groups that were
originally compared. Group #4 is therefore created
by substituting group #3 into group #1. Similarly,
group #5 is created by substituting group #3 into
group #2.
The new abstract groups are given an observed
frequency of zero (ID&apos;s equal four and five). Note
that abstract groups always have an observed
frequency of zero as they can never been directly
observed. The ID of the appropriate group used in
comparison and later creation is added to the
occurrence supporters links. Each abstract group
therefore has a total frequency equal to that of the
group of which it is an abstract form.
</bodyText>
<subsectionHeader confidence="0.518499">
4.4.4 Update system based on unequal parts
</subsectionHeader>
<bodyText confidence="0.999970636363636">
Unequal parts are only considered if equal parts
are found in the comparison. Otherwise, the
unequal parts would be the complete set of data
from both groups, which does not provide useful
information for comparisson. For every set of
unequal parts that is found, a new group is created.
If there is more than one unequal part then the
group will contain more than one description pair.
Such a group is referred to as a multi-group. Two
unequal parts were found earlier in comparing
group #1 and group #2. They are [&amp;quot;circle&amp;quot;; circle]
and [&amp;quot;square&amp;quot;; square]. Group #6 is therefore
created using these two description pairs.
The creation of a multi-group allows for a fully
abstract group to be created. The system uses the
data from the new multi-group (group #6) and the
group created through equal parts (group #3).
Both groups are substituted back into the group
that was originally being compared (group #1).
The resulting group (group #7) is fully abstract as
both equal parts and unequal parts have been used
to reconstruct the original group (group #1).
</bodyText>
<subsubsectionHeader confidence="0.562336">
4.4.5 Re-enter new groups into the system
</subsubsectionHeader>
<bodyText confidence="0.997856">
All groups that have been created through steps
3 and 4 are compared to all other groups in the
system. Results of comparisons are dealt with by
repeating steps 3-5 with the new results. By use a
recursive step like this, all groups are compared to
one another in the system. All group equalities are
therefore created when the round is complete. The
amount of information available from every new
group entered into the system is therefore
maximised.
</bodyText>
<subsectionHeader confidence="0.99546">
4.5 The Significance of Groups Types
</subsectionHeader>
<bodyText confidence="0.999959">
Four different types of group have been
identified in the previous section. Although all
groups share the same properties, they can be seen
to represent difference aspects of language. It is
the combination and interaction of these groups
that gives rise to emergent simple syntax. This
syntax is bi-gram collocations, but since the system
is scalable, it is referred to as simple syntax.
</bodyText>
<subsubsectionHeader confidence="0.769616">
4.5.1 Concrete Groups
</subsubsectionHeader>
<bodyText confidence="0.9999475">
Concrete groups acquire the meaning of
individual lexemes (associate concepts with
strings). They are verifiable in the real world
through the use of scene based games.
</bodyText>
<subsectionHeader confidence="0.599864">
4.5.2 Multi-Groups
</subsectionHeader>
<bodyText confidence="0.999836857142857">
Multi-groups form syntactic categories based on
similarities between description pair usage. Under
the current system, groups can only have a
maximum of two description pairs. If this were to
be expanded, it is clear that large syntactic
categories such as noun and verb equivalents
would arise.
</bodyText>
<subsubsectionHeader confidence="0.623826">
4.5.3 Partially and Fully Abstract Groups
</subsubsectionHeader>
<bodyText confidence="0.991739421052632">
Partially and fully abstract groups act as phrasal
rules in the system. Abstract values contained
within the group&apos;s description pairs can relate to
both concrete groups and multi-groups. Abstract
groups that relate to multi-groups offer a choice of
substitutions.
For example, group #7 (Table 1) relates a single
group to a multi-group. By substitution of groups
#3 and #6 into group #7, the concrete pairings of
[&amp;quot;red circle&amp;quot;; red circle] and [&amp;quot;red square&amp;quot;; red
square] are produced. The string data are directly
equivalent to:
S -&gt; Adj. N,
where Adj. = {&amp;quot;red&amp;quot;}
and N = {&amp;quot;circle&amp;quot;, &amp;quot;square&amp;quot;}
When a description pair is entered into the
system, the process of semantic bootstrapping
takes place. Lexical items (strings) are associated
with their meanings (concepts). When group
</bodyText>
<page confidence="0.997218">
64
</page>
<bodyText confidence="0.9954378">
comparisons are made, syntactic bootstrapping
begins. Associations are made between all
combinations of lexical items throughout the
system, and all combinations of meanings
throughout the system.
The system stores lexical item-meaning
associations, lexical item-lexical item associations
and meaning-meaning associations. This basic
framework allows for the production of complex
phrasal rules.
</bodyText>
<subsectionHeader confidence="0.990846">
4.6 Comprehension and Production Through
Games
</subsectionHeader>
<bodyText confidence="0.999467674698796">
The guessing game tests comprehension while
the naming game test production. Comprehension
takes a string as input, and produces a concept as
output, whereas production takes a concept as
input, and produces a string as output. The
comprehension and the production algorithms are
the same, except the first is string based, and the
second is concept based.
The algorithm performs two tasks: finding
concrete groups with exact matches to the input,
and finding abstract groups with possible matches
to the input. Holophrastic matching uses only
concrete groups. Syntactic matching performs
holophrastic matching, followed by further
matches using abstract groups. Note that the
system only performs syntactic matching, which
includes holophrastic matching. Holophrastic
matching is never performed alone, unless in
testing stages.
For holophrastic matches, the system searches
through its list of groups. Their description pairs
are compared to the input being searched for.
There is therefore re-use of the comparison
algorithm introduced in the learning process.
When a match is found, the group is added to a list
of possible results.
If holophrastic matching is being performed
alone, then this list of possible results is sorted by
total frequency. The group with the highest total
frequency is output by the system.
Syntactic matching begins by performing
holophrastic matching, but does not output a result
until all abstract groups have been matched too. It
is therefore an extension of holophrastic matching.
Once a first fun of holophrastic matching is
performed, the input is converted into abstract
form. This is performed at the word/feature value
level. The most likely element is found by
searching through the groups, comparing it to the
description pair, and selecting the group with the
highest total frequency from those found.
The group IDs replace the appropriate element in
the input (just as substitutions were made during
the learning process). All multi-groups that
contain any of the abstract forms are found. Each
multi-group&apos;s description pair becomes a
replacement for the appropriate input&apos;s abstract
value.
The new input, which is still in abstract form, is
searched for, using holophrastic matching again.
Since the groups found are not exact matches of
the original input, their total frequency is
multiplied by an abstract factor. The abstract
factor is a value between zero and one inclusive.
The higher the factor, the greater the effect that
abstract groups have on the results. Syntactic
matches can therefore produce different results
based on the value of abstract factor. The abstract
factor is not changed from the initiation to
termination of the system.
Groups found during the search are added to a
new list of possible results. The appropriate
elements are substituted into the groups abstract
values to make them concrete. If an abstract value
is acting as a substitute (by being found originally
in a multi-group) then the original input value is
used, not the replacement element. This allows the
abstract group to act as a syntactic rule, but it is
penalised by the abstract factor so it does not have
as much influence as concrete groups, that have
been found to occur through direct input
associations.
The groups found throughout the entire syntactic
search are now contained in a second list of
possible results. This list is reduced by removing
duplicate groups. For each group that is removed,
its observed frequency and occurrence supporter
links are added to the duplicate that is kept in the
list.
The two lists from each matching routine are
merged and sorted by total frequency. The
string\concept of the group with the highest total
frequency is outputted by the system.
</bodyText>
<sectionHeader confidence="0.93034" genericHeader="method">
5 Testing and Results
</sectionHeader>
<bodyText confidence="0.973314">
The system is tested within the following areas:
</bodyText>
<listItem confidence="0.991824">
1. Comprehension and production of all
fourteen concepts. The rate at which full
comprehension and full production are
achieved is compared.
2. Correctness of production matches for
compound concepts. The correctness of
production matches are studied over a
number of rounds.
3. Type of production matches for compound
</listItem>
<bodyText confidence="0.981930666666667">
concepts. The type of production matches
favoured, holophrastic or syntactic, are
compared over a number of rounds
A match of concept to word or word to concept
is considered correct if the string describes the
concept fully. For example, [&amp;quot;red&amp;quot;; red] and [&amp;quot;red
</bodyText>
<page confidence="0.999142">
65
</page>
<bodyText confidence="0.998756">
square&amp;quot;; red square] are correct, but [&amp;quot;red&amp;quot;; red
square] and [&amp;quot;red square&amp;quot;; red] are incorrect. One
point is given for each correct match, zero for each
incorrect match.
Note that all test results are based on the average
of ten different system trials. Each result shows a
broad tendency that will likely be smoothed if
more trials are run. All input is randomly
generated. The abstract factor is set to 0.4 for all
tests.
</bodyText>
<subsectionHeader confidence="0.995596">
5.1 Comprehension Vs. Production
</subsectionHeader>
<bodyText confidence="0.990151">
Full comprehension occurs much sooner (see
Figure 1), on average, than full production. This
result is found in children also. Although
production and comprehension compete quite
steadily in early stages of the system,
comprehension reaches its maximum, on average,
in 20% of the time that production takes to reach
its maximum.
</bodyText>
<figureCaption confidence="0.854375">
Figure 1: Shows number of correct
comprehension and production matches
</figureCaption>
<bodyText confidence="0.9999567">
Full comprehension (fourteen points) is
achieved, on average, by round 50, while full
production comes at round 250. Both holophrastic
data and syntactic data contribute to the successes.
Underextensions are found during comprehension.
For example, in early rounds, &amp;quot;green&amp;quot; is used to
describe only green squares. This phenomena is
quickly eliminated in the trials but with a larger set
of concepts and vocabulary, it is likely to persist
for more than a few rounds.
</bodyText>
<subsectionHeader confidence="0.999631">
5.2 Correctness of Holophrastic Vs Syntactic
Matches
</subsectionHeader>
<bodyText confidence="0.999339962962963">
At the end of each round, production is tested
using the eight compound concepts alone. These
are based on the eight observable objects in the
simulated scene. Only compound concepts can
demonstrate simple syntax in this system, as
singular concepts have associations to single word
strings.
The system uses syntactic matching alone, but
syntactic matching includes holophrastic matching,
as discussed earlier. To determine whether
holophrastic data is being used, or syntactic data
when a syntactic match is run, the matching
algorithm has been split. The number of correct
strings produced using holophrastic data and the
number of correct strings produced using syntactic
data alone are compared (see Figure 2).
The data demonstrate that the system uses
mostly holophrastic matches in early rounds
(comparable to the one-word stage). This is
eliminated in further rounds, in favour or syntactic
matches alone (the two-word stage). Note that
although the holophrastic stage may appear to be
producing two-words, these words are considered
to be one-word. For example, &amp;quot;allgone&amp;quot; is
considered to be one-word in early stages of
linguistic development, as opposed to &amp;quot;all gone&amp;quot;
(Ingram, 1989).
</bodyText>
<figureCaption confidence="0.988412">
Figure 2: Shows number of correct holophrastic
</figureCaption>
<bodyText confidence="0.985218380952381">
and syntactic matches.
The syntactic data continues to rise, until it
achieves full production. The holophrastic stage
never achieves full production, but peaks, then
reduces to zero. This trend occurs as holophrastic
underextensions such as &amp;quot;red&amp;quot; representing red
square become more likely than &amp;quot;red square&amp;quot;
representing red square.
Early syntactic matches are based on novel
string productions for novel string concepts.
Holophrastic matching is incapable of producing
novel strings from novel concepts, as it deals with
concrete concepts. Abstract concepts however,
allow new string combinations to be produced,
such as &amp;quot;blue square&amp;quot;, from blue square even
though neither then string nor concept have been
encountered before. Such an abstraction may
come from a multi-group that associates &amp;quot;blue&amp;quot;
with &amp;quot;red&amp;quot;, while containing a group that contains
&amp;quot;red square&amp;quot; also. The novel string &amp;quot;blue square&amp;quot;
is therefore abstracted.
</bodyText>
<subsectionHeader confidence="0.999404">
5.3 Use of Holophrastic Vs Syntactic Matches
</subsectionHeader>
<bodyText confidence="0.977335428571429">
The system does not always produce the correct
strings when a concept is entered. The strings that
are produced are a result of either holophrastic or
syntactic matching. Regardless of correctness, the
amount of times that holophrastic matches are
made over syntactic matches can be compared (see
Figure 3).
</bodyText>
<figure confidence="0.984939347826087">
14
12
10
8
6
4
2
0
1 4 7 10 13 16 19 22 25 28 31 34 37
Production
Comprehension
40 43 46 49
6
5
4
3
2
0
1
1 5 9 13 17 21 25 29 33 37 41 45 49 53 57 61 65 69 73
Holophrastic
Syntactic
66
</figure>
<figureCaption confidence="0.9124655">
Figure 3: Shows distribution of holophrastic and
syntactic matches.
</figureCaption>
<bodyText confidence="0.9999576">
The system relies completely on one-word
descriptions at the outset, but soon syntactically
derived two-word descriptions become prevalent.
It is likely that the one-word stage will last longer
if larger concept and vocabulary sets are in use.
The system shows the same form of transition as
can be seen in children from the one-word stage to
the two-word stage, without the use of an artificial
trigger. The shift is gradual although the use of
larger concept and vocabulary sets, plus different
abstract factor values will affect the transition.
The greater the number of words in multi-groups
(the greater the size of syntactic categories), the
lower the abstract factor is required to encourage
the emergence of simple syntax.
</bodyText>
<sectionHeader confidence="0.999655" genericHeader="method">
6 Related Works
</sectionHeader>
<bodyText confidence="0.999914594594595">
Supporters of computational modelling in
language acquisition, often promote the practical
importance of running simulations, where
evolutionary effects can be recreated in short time
periods (Zuidema, 2001).
Although this paper is focussed on an individual
system, or agent, acquiring language, it is been
influenced by research into social learning
(Oliphant and Batali, 1997; Kirby, 1999; Steels
and Kaplan, 2002). Social learning demonstrates
the convergence upon a common language, or set
of languages, from an uncoordinated proto-
language, within a population of agents. Social
learning allows for the playing of games between
agents, similar to those in this paper, with the
results being used as further system input, to
support, or deny associations. This research can be
viewed as a form of social learning with one agent
(string and concept generator) performing the
teacher role, and the other agent (the system)
performing the learner role.
Simulations of both the babbling stage and the
one-word stage have been developed (Scheler,
1997; Abidi, 1999). ACCLAIM, a one-word stage
simulator, demonstrates that systems can react
appropriately to changes in situations. For
example, when a cessation event is triggered, it
produces &amp;quot;Stop&amp;quot;, and when an object is requested,
it produces &amp;quot;More&amp;quot;. Both examples are typical of
children during the one-word stage (Bloom, 1973).
Several systems exist that use perceptions to
encourage language acquisition (Howell, Becker,
and Jankowicz,, 2001; Roy, 2001). ELBA learns
both nouns and verbs from video scenes, starting
with a blank lexicon. Such systems have helped in
the selection of both appropriate input sources and
feature values to use in this research. This system
will also be physically grounded in future.
The research presented in this paper describes a
system that drives linguistic development. Other
systems have used similar techniques, based on
syntactic and semantic bootstrapping (Howell and
Becker, 2001), but have not explained how
multiple word acquisition is achieved from a single
word basis.
Steels (1998) introduces frames that group
lexical elements together by the roles that they
play, very similar to groups in this paper. Frames
are more dynamic than groups however,
structurally adapting when words reoccur. Groups
do not adapt in this way. New groups are created
to describe similarities rather than adapting
existing ones. Steels also introduces multiple word
sentences, but it is unclear as to why agents invent
a multiple word description over creating a new
single word description. The invention is triggered
and does not emerge. This research is based on
real multiple word inputs, so the reason for
invention is not necessary, unlike the reason for
adoption i.e. why the system adopts two-word
descriptions.
The comparison algorithm, as previously noted,
is similar to alignment based learning (van Zaanen,
2000). The system in this research performs
perfect alignment requiring exact word matches
when finding equal parts and unequal parts. This
system also uses concepts, reducing the number of
incorrect groupings, or constituents, when there is
ambiguity in text. Unsupervised grammar
induction can also be found in EMILE (van Zaanen
and Adriaans, 2001). EMILE identifies
substitution classes by means of clustering. These
classes are comparable to this system&apos;s groups
although no concepts are used.
</bodyText>
<sectionHeader confidence="0.991053" genericHeader="method">
7 Future Research
</sectionHeader>
<bodyText confidence="0.99991">
As the system stands, it uses a small input set.
Further developments are focussed on expanding
the system. All ten of Brown&apos;s relations should be
implemented. Larger concept and vocabulary sets
are therefore required. Extensions to these sets are
likely to affect underextensions, mismatches, the
length of pre-syntactic usage time, and the overall
growth pattern of simple syntax.
</bodyText>
<figure confidence="0.999203857142857">
100%
90%
80%
70%
60%
50%
40%
30%
20%
10%
0%
1 5 9 13 17 21 25 29 33 37 41 45 49 53 57 61 65 69 73
Syntactic
Holophrastic
</figure>
<page confidence="0.9943">
67
</page>
<sectionHeader confidence="0.994635" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.998784833333334">
This paper offers a potential explanation of the
mechanism by which the two-word stage emerges
from the one-word stage. It suggests that syntactic
data is sought out from the beginning of language
acquisition. This syntactic data is always
competing with the associations of holophrastic
data. Syntax is strengthened when patterns are
consistently found between strings and concepts,
and is used in favour of holophrastic data when it
is sufficiently frequent. The simple syntax
continues to grow in strength, ultimately being
used in favour of holophrastic data in all
production and comprehension tasks.
This system provides the foundation for more
complex, hierarchical, syntax to emerge. The type
and volume of input is the only constraint upon the
system. The entry into post two-word stages is
predicted from the system&apos;s robust architecture.
</bodyText>
<sectionHeader confidence="0.997514" genericHeader="acknowledgments">
9 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999898">
The first author is sponsored by a studentship
from the EPSRC.
Thanks to the workshop reviewers for their
helpful and much appreciated advice.
</bodyText>
<sectionHeader confidence="0.998742" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999859952380953">
S. Abidi, 1996. A Neural Network Simulation of Child
Language Development at the One-word Stage. In
proceedings of IASTED Int. Conf. on Modelling,
Simulation and Optimization, Gold Coast, Australia.
L. Bloom, 1973. One Word at a Time. The use of
single-word utterances before syntax The Hague,
Mouton.
R.W. Brown, 1986. Language and categories. In “A
Study of Thinking”, ed. J.S. Bruner, J.J. Goodnow,
and G.A. Austin, pages 247-312. New York: John
Wiley, 1956. Reprint, New Brunswick: Transaction.
L.R.. Gleitman and Elissa L. Newport, 1995. The
Invention of Language by Children: Environmental
and Biological Influences on the Acquisition
Language. In “An Invitation to Cognitive Science”,
L.R. Gleitman and M. Liberman, 2nd ed., Vol.1,
Cambridge, Mass., London, MIT Press.
S.R. Howell and S. Becker, 2001. Modelling language
acquisition: Grammar from the Lexicon? In
Proceedings of the Cognitive Science Society..
S.R. Howell, S. Becker, and D. Jankowicz, 2001.
Modelling Language Acquisition: Lexical Grounding
Through Perceptual Features. In Proceedings of the
2001 Workshop on Developmental Embodied
Cognition
J.R. Hurford, M. Studdert-Kennedey, and C. Knight,
1998. The Emergence of Syntax. In “Approaches to
the evolution of language: social and cognitive
bases”, Cambridge, Cambridge University Press.
D. Ingram, 1989. First Language Acquisition. Method,
Description and Explanation. Cambridge: Cambridge
University Press.
R. Jakobson, 1971. Why “mama” and “papa”? In
“ Child Language: A Book of Readings”, by A. Bar-
Adon and W. F. Leopold, ed., pages 213-217.
Englewood Cliffs, NJ:Prentice-Hall.
P.W. Jusczyk, 1999 How infants begin to extract words
from speech. Trends in Cognitive Science, 3 (9,
September):323-328.
S. Kirby, 1999. Syntax out of learning: The cultural
evolution of structured communication in a
population of induction algorithms. In Proceedings of
ECAL99 European Conference on Artificial Life, D.
Floreano et al. ed. pages 694-703, Berlin: Springer-
Verlag,
M. Oliphant and J. Batali 1997. Learning and the
emergence of coordinated communication. Centre for
Research in Language Newsletter, 11(1).
A. Paivio, 1971, Imagery and Verbal Processes. New
York: Holt, Rinehart &amp; Winston.
J. Piaget, 1960. The Language and Thought of the
Child. Routledge and K. Paul, 3rd ed.,. Routledge
Paperbacks.
S. Pinker, 1994. The Language Instinct. The New
Science of Language and Mind. Allen Lane, Penguin
Press.
D. Roy, 2001. Grounded spoken language acquisition:
Experiments in word learning. IEEE Transactions on
Multimedia.
G. Scheler, 1997d. The transition from babbling to the
one-word stage: A computational model. In
Proceedings of GALA &apos;97.
L. Steels and F. Kaplan, 2001. AIBO&apos;s first words: The
social learning of language and meaning. Evolution of
Communication, vol. 4(1):3-32. John Benjamin’s
Publishing Company, Amsterdam, Holland.
L. Steels, 1998. The Origins of Syntax in visually
grounded robotic agents. AI 103, 1-24.
M. Tomasello, and A.C. Kruger, 1992. Joint attention in
action: Acquiring verbs in ostensive and non-
ostensive contexts. Journal of Child Language
19:311-333.
M. van Zaanen, 2000. Learning structure using
alignment based learning. In Proceedings of the
Third Annual Doctoral Research Colloquium
(CLUK), pages 75-82.
M. van Zaanen and P. Adriaans, 2001. Alignment-
based learning versus EMILE: A comparison. In
Proceedings of the Belgian-Dutch Conference on AI
(BNAIC).
W.H. Zuidema, 2001. Emergent syntax: the unremitting
value of computational modelling for understanding
the origins of complex language. ECAL01, 641-644.
Springer, Prague, Sept. 10-14, 2001.
</reference>
<page confidence="0.999446">
68
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.9549715">A Computational Model of Emergent Simple Syntax: Supporting the Natural Transition from the One-Word Stage to the Two-Word Stage.</title>
<author confidence="0.940542">Kris Jack</author>
<author confidence="0.940542">Chris Reed</author>
<author confidence="0.940542">Annalu</author>
<affiliation confidence="0.9991915">Division of Applied University of</affiliation>
<address confidence="0.992682">Dundee, Scotland, DD1</address>
<email confidence="0.974643">[kjack|creed|awaller]@computing.dundee.ac.uk</email>
<abstract confidence="0.996866058528429">This paper introduces a system that simulates the transition from the one-word stage to the two-word stage in child language production. Two-word descriptions are syntactically generated and compete against one-word descriptions from the outset. descriptions become dominant as word combinations are repeatedly recognised, forming syntactic categories; resulting in an emergent simple syntax. The demonstrates a similar maturation as children as evidenced by phenomena such as overextensions and mismatching, and the use of one-word descriptions being replaced by two-word descriptions over time. Studies of first language acquisition in children have documented general stages in linguistic development. Neither the trigger nor mechanism that takes a child from one stage to the next are known. Stages arise gradually with no precise start or end points, overlapping one another (Ingram, 1989). The aim of this research is to develop a system that autonomously acquires conceptual representations of individual words (the &amp;quot;one-word stage&amp;quot;) and also, simultaneously, is capable of developing representations of valid multi-word structures i.e. simple syntax (the &amp;quot;two-word stage&amp;quot;). Two-word descriptions are expected to emerge as a result of the system state and not be artificially triggered. The system accepts sentences containing a maximum of two words. It is designed to be scalable, allowing larger, more natural sentence sizes also. System input is therefore a mixture of both one-word and two-word sentences. The system is required to produce valid descriptions, particularly in the two-word stage. Rules that enforce syntactic order, and allow for the production of semantically correct descriptions from novel concepts, are desirable. This paper is sectioned as follows; pre-oneword stage linguistic abilities in children are briefly discussed to explain why initial system functionality assumptions are made; the defining characteristics of both the one-word stage and twoword stage in children are introduced as possible benchmarks for the system; a detailed description of system design and implementation with examples of the learning process and games played by the system are presented; a discussion of current results along with their possible implications follows; a brief review of related works that have influenced this research, citing major influences; the direction and aims of future research is described briefly; and finally, conclusions are drawn. Stage Children Linguistic abilities can be found in children prior to word production. In terms of comprehension, children can distinguish between their mother&apos;s voice and a stranger&apos;s voice, male and female voices, and sentences spoken in their mother&apos;s native language and sentences spoken in a different language. They also show categorical perception to voice, can use formant transition information to mark articulation, and show intonation sensitivity (Pinker, 1994, Jusczyk, 1999). In terms of production, children produce noises, such as discomfort noises (0-2 months), comfort noises (2-4 months), and &amp;quot;play&amp;quot; vocally with pitch and loudness variations (4-7 months) (Pinker, 1994). The babbling stage (6-8 months) characterised with the production of recognisable syllables. The syllables are often repeated, such as [mamama] and [papapa], with the easiest to produce sounds often being associated with members of the family (Jakobson, 1971). From this evidence it is reasonable to draw conclusions about linguistic abilities in the young child that can be used to frame assumptions for use in the system. It is assumed that the system can receive and produce strings that can be broken down into their component words. These words can be compared and equalities can be detected. 61 Stage and Two-Word Stages The system is required to produce one-word descriptions in early stages that develop into twoword descriptions, where appropriate, in latter stages.. The recognition of each stage is based on the number of words that the system uses at a particular point. In children, the one and two-word stages have notable features. The one-word, or holophrastic, stage (9-18 months), is characterised by one-word vocalisations that are consistently associated with concepts. These concepts can be either concrete or abstract, such as &amp;quot;mama&amp;quot;, referring to the concrete concept of the child&apos;s mother, and &amp;quot;more&amp;quot;, an abstract concept which can be applied in a variety of situations (Piaget, 1960). Two phenomena that occur during this stage are underextensions and overextensions. underextension is the formation of a word to concept association that is too narrow, such as &amp;quot;dog&amp;quot; referring to only the family dog. Overextension, similarly, is an association that is too broad, such as &amp;quot;dog&amp;quot; referring to all four legged animals. Mismatches, or idiosyncratic referencing also occur, resulting in a word being associated with an unrelated concept, such as &amp;quot;dog&amp;quot; referring to a table (Pinker, 1994). These associations change over time. The two-word stage (18-24 months) introduces simple syntax into the child&apos;s language faculty. Children appear to determine the most important words in a sentence and, almost all of the time, use them in the same order as an adult would (Gleitman and Newport, 1995). Brown (1973) defines a typology to express semantic relations in the two-word stage. It contains ten sets of relations, but only one will be considered in this paper; attribute + entity (&amp;quot;red circle&amp;quot;). During this stage, children already demonstrate a three word comprehension level (Tomasello and Kruger, 1992). The concepts relating to their sentences may therefore be more detailed than the phrases themselves. The system is expected to make the transition from the one-word stage to the two-word stage without changes to the functionality of the system. Once the system begins to run, input is restricted to that of sensory (concept based) and vocal (string representation) data. Design and Implementation The system is designed to learn phrase-toconcept associations and demonstrate it through playing games: a guessing game and a naming game. Games are often used to test, and encourage system learning (Steels and Kaplan, 2001). The learning process involves a user selecting an object in a scene and naming it. The guessing game involves a user saying a phrase, and the system pointing to the object that the phrase refers to. The naming game involves a user pointing to an object and the system naming it The system is not physically grounded, so all games are simulated. The learning process allows the system to acquire associations between phrases and concepts while the games test system comprehension and system production respectively. The learning takes a input, and produces no output. Comprehension takes a string as input, and produces a concept as output, whereas production takes a concept as input, and produces a string as output. and Concepts A string is a list of characters with a fixed order. blank space is used to separate the string, of which there can be either one or two. The system can break strings down into their component words. concept is a list of The system recognises six feature values; red, blue, green, white, circle, and square. There are no inbuilt associations between any of the feature values. This form of learning is supported by the imageability theory (Paiviom 1971). No claims concerning concept acquisition and formation are made in this paper. All concepts are hard coded from the outset. The full list of objects used in the games are from shape and colour combinations; and Individual feature values can also act as concepts, therefore the full list is concepts is the list of object plus the list of feature values. To associate a string with a concept, the system a list of Each group contains an or more an and zero or more The ID acts as a unique identifier, allowing the group to be found. A description pair is a string and a concept. Groups must have at least one description pair since their primary function is to relate a string to a concept. The observed frequency represents the number of times that the description pair&apos;s components have been associated through system input. The occurrence supporter links are a set of group IDs. Each ID in the set refers to a group that 62 contains a superset of either the description pair, or the same value for one component of the description pair and a superset of the other e.g. The pair [&amp;quot;red&amp;quot;; 1would be supported the description pair [&amp;quot;red square&amp;quot;; A worked example is provided in the next section. The links therefore record the number of occurrences of the group&apos;s description pair. The occurrence supporter link reinforces the description pair&apos;s association and increases the frequency the group. The total frequency is the group&apos;s observed frequency plus the observed frequency of all of its supporters, never including a supporter more than once. Finally, group equality is defined by groups sharing the same description pair. Learning Process At each stage in the learning process, a description pair is entered into the system. The system does not attempt to parse the correctness of the description. All data is considered to be positive. The general learning process algorithm is detailed in the rest of this section. Specific examples are also provided in Table 1, showing the groups&apos; values; ID, description pair, occurrence frequency (OF), occurrence supporter links (OSLs), and total frequency (TF). Five steps are followed to incorporate the new data: 1. Identify the description pair. 2. Find equal and unequal parts. 3. Update system based on equal parts.. 4. Update system based on unequal parts. 5. Re-enter new groups into the system. the description pair If the description pair exists in a group that is already in the system, then that group&apos;s observed frequency is incremented. Otherwise, the system creates a new group containing the new description. It is given a unique ID and an observed frequency of one. Assume that the system already contains a group based on the pair [&amp;quot;red circle&amp;quot;; This has an ID of one. Assume also that the new pair entered is [&amp;quot;red square&amp;quot;; Its group has an ID of two (group #2). All description pairs entered into the system are description this is, the system has encountered them directly as input. new group is referred to as a since it contains a concrete description pair. convention of strings appearing in quotes and concepts appearing in italics is adopted throughout this paper. ID Description Pair OF OSLs TF square”; Table 1: Sample data equal and unequal parts The new group is compared to all of the groups in the system. Comparisons are based on the groups&apos; description pairs alone. Strings compared separately from concepts. A string match is found if one of the strings is a subset, or exact match, of the other. Subsets of strings must contain complete words. Words are regarded as atomic units. Concepts are compared in the same fashion as strings, where feature values are the atomic units. Successful comparisons create a set of equal parts and unequal parts. Comparison results are only used when equal parts exist. This approach is similar to alignment based learning, but with the additional component of concepts (van Zaanen, 2000). In comparing the new group, group #2, to the existing group, group #1, the equal part [&amp;quot;red&amp;quot;; and the unequal part [&amp;quot;circle&amp;quot;; are found. The comparison algorithm is essential to the operation of the system. It is used in the learning process and in the games. Without it, no string or concept relations be system based on equal parts When an equal part is found, a new group is created. In the example, an equal part is found between group #1 and group #2. Group #3 is created as a result. The new group is given an observed frequency of zero. The IDs of the groups that were compared (group #1 and group #2) are added to the new group&apos;s (group #3) occurrence supporter links. If the group already exists, then as well as the existing group&apos;s observed frequency being incremented, the IDs of the groups that were compared are added to the occurrence supporter links. IDs can only appear once in the set of occurrence supporters links, so if an ID is already in it, then it is not added. system assumes full compositionality. Idioms and metaphors are not considered at this stage. 63 Up until this point, all groups&apos; description pairs have contained a string and concept. Description pairs can also contain links to other groups&apos; strings and groups&apos; concepts. These description pairs are to as description If all elements of the abstract description pair are links other groups then it is else it is A group that contains an description pair is called an The group is fully abstract if its abstract description pair is fully abstract, else it is a abstract Once a group has been created (as group #3 was), based on a description comparison, the system attempts to make two abstract groups. The new abstract groups (group #4 and group ID (group #3) into each of the groups that were originally compared. Group #4 is therefore created by substituting group #3 into group #1. Similarly, group #5 is created by substituting group #3 into group #2. The new abstract groups are given an observed frequency of zero (ID&apos;s equal four and five). Note that abstract groups always have an observed frequency of zero as they can never been directly observed. The ID of the appropriate group used in comparison and later creation is added to the occurrence supporters links. Each abstract group therefore has a total frequency equal to that of the group of which it is an abstract form. system based on unequal parts Unequal parts are only considered if equal parts are found in the comparison. Otherwise, the unequal parts would be the complete set of data from both groups, which does not provide useful information for comparisson. For every set of unequal parts that is found, a new group is created. If there is more than one unequal part then the group will contain more than one description pair. a group is referred to as a Two unequal parts were found earlier in comparing [&amp;quot;square&amp;quot;; Group #6 is therefore created using these two description pairs. The creation of a multi-group allows for a fully abstract group to be created. The system uses the data from the new multi-group (group #6) and the group created through equal parts (group #3). Both groups are substituted back into the group that was originally being compared (group #1). The resulting group (group #7) is fully abstract as both equal parts and unequal parts have been used to reconstruct the original group (group #1). new groups into the system All groups that have been created through steps 3 and 4 are compared to all other groups in the system. Results of comparisons are dealt with by repeating steps 3-5 with the new results. By use a recursive step like this, all groups are compared to one another in the system. All group equalities are therefore created when the round is complete. The amount of information available from every new group entered into the system is therefore maximised. Significance of Groups Types Four different types of group have been identified in the previous section. Although all groups share the same properties, they can be seen to represent difference aspects of language. It is the combination and interaction of these groups that gives rise to emergent simple syntax. This syntax is bi-gram collocations, but since the system is scalable, it is referred to as simple syntax. Groups Concrete groups acquire the meaning of individual lexemes (associate concepts with strings). They are verifiable in the real world through the use of scene based games. Multi-groups form syntactic categories based on similarities between description pair usage. Under the current system, groups can only have a maximum of two description pairs. If this were to be expanded, it is clear that large syntactic categories such as noun and verb equivalents would arise. and Fully Abstract Groups Partially and fully abstract groups act as phrasal rules in the system. Abstract values contained within the group&apos;s description pairs can relate to both concrete groups and multi-groups. Abstract groups that relate to multi-groups offer a choice of substitutions. For example, group #7 (Table 1) relates a single group to a multi-group. By substitution of groups circle&amp;quot;; and [&amp;quot;red square&amp;quot;; are produced. The string data are directly equivalent to: S -&gt; Adj. N, where Adj. = and N = {&amp;quot;circle&amp;quot;, &amp;quot;square&amp;quot;} When a description pair is entered into the system, the process of semantic bootstrapping takes place. Lexical items (strings) are associated with their meanings (concepts). When group 64 comparisons are made, syntactic bootstrapping begins. Associations are made between combinations of lexical items throughout the system, and all combinations of meanings throughout the system. The system stores lexical item-meaning associations, lexical item-lexical item associations and meaning-meaning associations. This basic framework allows for the production of complex phrasal rules. and Production Through Games The guessing game tests comprehension while the naming game test production. Comprehension takes a string as input, and produces a concept as output, whereas production takes a concept as input, and produces a string as output. The comprehension and the production algorithms are the same, except the first is string based, and the second is concept based. The algorithm performs two tasks: finding concrete groups with exact matches to the input, and finding abstract groups with possible matches to the input. Holophrastic matching uses only concrete groups. Syntactic matching performs holophrastic matching, followed by further matches using abstract groups. Note that the system only performs syntactic matching, which includes holophrastic matching. matching is never performed alone, unless in testing stages. For holophrastic matches, the system searches through its list of groups. Their description pairs are compared to the input being searched for. There is therefore re-use of the comparison algorithm introduced in the learning process. When a match is found, the group is added to a list of possible results. If holophrastic matching is being performed alone, then this list of possible results is sorted by total frequency. The group with the highest total frequency is output by the system. Syntactic matching begins by performing holophrastic matching, but does not output a result until all abstract groups have been matched too. It is therefore an extension of holophrastic matching. Once a first fun of holophrastic matching is performed, the input is converted into abstract form. This is performed at the word/feature value level. The most likely element is found by searching through the groups, comparing it to the description pair, and selecting the group with the highest total frequency from those found. The group IDs replace the appropriate element in the input (just as substitutions were made during the learning process). All multi-groups that contain any of the abstract forms are found. Each multi-group&apos;s description pair becomes a replacement for the appropriate input&apos;s abstract value. The new input, which is still in abstract form, is searched for, using holophrastic matching again. Since the groups found are not exact matches of the original input, their total frequency is by an The abstract factor is a value between zero and one inclusive. The higher the factor, the greater the effect that abstract groups have on the results. Syntactic matches can therefore produce different results based on the value of abstract factor. The abstract factor is not changed from the initiation to termination of the system. Groups found during the search are added to a new list of possible results. The appropriate elements are substituted into the groups abstract values to make them concrete. If an abstract value is acting as a substitute (by being found originally in a multi-group) then the original input value is used, not the replacement element. This allows the abstract group to act as a syntactic rule, but it is penalised by the abstract factor so it does not have as much influence as concrete groups, that have been found to occur through direct input associations. The groups found throughout the entire syntactic search are now contained in a second list of possible results. This list is reduced by removing duplicate groups. For each group that is removed, its observed frequency and occurrence supporter links are added to the duplicate that is kept in the list. The two lists from each matching routine are merged and sorted by total frequency. The string\concept of the group with the highest total frequency is outputted by the system. and Results The system is tested within the following areas: 1. Comprehension and production of all fourteen concepts. The rate at which full comprehension and full production are achieved is compared. 2. Correctness of production matches for compound concepts. The correctness of production matches are studied over a number of rounds. 3. Type of production matches for compound concepts. The type of production matches favoured, holophrastic or syntactic, are compared over a number of rounds A match of concept to word or word to concept is considered correct if the string describes the fully. For example, [&amp;quot;red&amp;quot;; and [&amp;quot;red 65 are correct, but [&amp;quot;red&amp;quot;; and [&amp;quot;red square&amp;quot;; are incorrect. One point is given for each correct match, zero for each incorrect match. Note that all test results are based on the average of ten different system trials. Each result shows a broad tendency that will likely be smoothed if more trials are run. All input is randomly generated. The abstract factor is set to 0.4 for all tests. Vs. Production Full comprehension occurs much sooner (see Figure 1), on average, than full production. This result is found in children also. production and comprehension compete quite steadily in early stages of the system, comprehension reaches its maximum, on average, in 20% of the time that production takes to reach its maximum. Figure 1: Shows number of correct comprehension and production matches Full comprehension (fourteen points) is achieved, on average, by round 50, while full production comes at round 250. Both holophrastic data and syntactic data contribute to the successes. Underextensions are found during comprehension. For example, in early rounds, &amp;quot;green&amp;quot; is used to only This phenomena is quickly eliminated in the trials but with a larger set of concepts and vocabulary, it is likely to persist for more than a few rounds. of Holophrastic Vs Syntactic Matches At the end of each round, production is tested using the eight compound concepts alone. These are based on the eight observable objects in the simulated scene. Only compound concepts can demonstrate simple syntax in this system, as singular concepts have associations to single word strings. The system uses syntactic matching alone, but syntactic matching includes holophrastic matching, as discussed earlier. To determine holophrastic data is being used, or syntactic data when a syntactic match is run, the matching algorithm has been split. The number of correct strings produced using holophrastic data and the number of correct strings produced using syntactic data alone are compared (see Figure 2). The data demonstrate that the system uses mostly holophrastic matches in early rounds (comparable to the one-word stage). This is eliminated in further rounds, in favour or syntactic matches alone (the two-word stage). Note that although the holophrastic stage may appear to be producing two-words, these words are considered to be one-word. For example, &amp;quot;allgone&amp;quot; is considered to be one-word in early stages of linguistic development, as opposed to &amp;quot;all gone&amp;quot; (Ingram, 1989). Figure 2: Shows number of correct holophrastic and syntactic matches. The syntactic data continues to rise, until it achieves full production. The holophrastic stage never achieves full production, but peaks, then reduces to zero. This trend occurs as holophrastic such as &amp;quot;red&amp;quot; representing more likely than &amp;quot;red square&amp;quot; Early syntactic matches are based on novel string productions for novel string concepts. Holophrastic matching is incapable of producing novel strings from novel concepts, as it deals with concrete concepts. Abstract concepts however, allow new string combinations to be produced, as &amp;quot;blue square&amp;quot;, from square though neither then string nor concept have been encountered before. Such an abstraction may come from a multi-group that associates &amp;quot;blue&amp;quot; with &amp;quot;red&amp;quot;, while containing a group that contains &amp;quot;red square&amp;quot; also. The novel string &amp;quot;blue square&amp;quot; is therefore abstracted. of Holophrastic Vs Syntactic Matches The system does not always produce the correct strings when a concept is entered. The strings that are produced are a result of either holophrastic or syntactic matching. Regardless of correctness, the amount of times that holophrastic matches are made over syntactic matches can be compared (see Figure 3).</abstract>
<note confidence="0.862614842105263">14 12 10 8 6 4 2 0 1 4 7 10 13 16 19 22 25 28 31 34 37 Production Comprehension 40 43 46 49 6 5 4 3 2 0 1</note>
<phone confidence="0.504722">1 5 9 13 17 21 25 29 33 37 41 45 49 53 57 61 65 69 73</phone>
<abstract confidence="0.981567425531915">Holophrastic Syntactic 66 Figure 3: Shows distribution of holophrastic and syntactic matches. The system relies completely on one-word descriptions at the outset, but soon syntactically derived two-word descriptions become prevalent. It is likely that the one-word stage will last longer if larger concept and vocabulary sets are in use. The system shows the same form of transition as can be seen in children from the one-word stage to the two-word stage, without the use of an artificial trigger. The shift is gradual although the use of larger concept and vocabulary sets, plus different abstract factor values will affect the transition. The greater the number of words in multi-groups (the greater the size of syntactic categories), the lower the abstract factor is required to encourage the emergence of simple syntax. Works Supporters of computational modelling in language acquisition, often promote the practical importance of running simulations, where evolutionary effects can be recreated in short time periods (Zuidema, 2001). Although this paper is focussed on an individual system, or agent, acquiring language, it is been influenced by research into social learning (Oliphant and Batali, 1997; Kirby, 1999; Steels and Kaplan, 2002). Social learning demonstrates the convergence upon a common language, or set of languages, from an uncoordinated protolanguage, within a population of agents. Social learning allows for the playing of games between agents, similar to those in this paper, with the results being used as further system input, to support, or deny associations. This research can be viewed as a form of social learning with one agent (string and concept generator) performing the teacher role, and the other agent (the system) performing the learner role. Simulations of both the babbling stage and the one-word stage have been developed (Scheler, 1997; Abidi, 1999). ACCLAIM, a one-word stage simulator, demonstrates that systems can react appropriately to changes in situations. example, when a cessation event is triggered, it produces &amp;quot;Stop&amp;quot;, and when an object is requested, it produces &amp;quot;More&amp;quot;. Both examples are typical of children during the one-word stage (Bloom, 1973). Several systems exist that use perceptions to encourage language acquisition (Howell, Becker, and Jankowicz,, 2001; Roy, 2001). ELBA learns both nouns and verbs from video scenes, starting with a blank lexicon. Such systems have helped in the selection of both appropriate input sources and feature values to use in this research. This system will also be physically grounded in future. The research presented in this paper describes a system that drives linguistic development. Other systems have used similar techniques, based on syntactic and semantic bootstrapping (Howell and Becker, 2001), but have not explained how multiple word acquisition is achieved from a single word basis. Steels (1998) introduces frames that group lexical elements together by the roles that they play, very similar to groups in this paper. Frames are more dynamic than groups however, structurally adapting when words reoccur. Groups do not adapt in this way. New groups are created to describe similarities rather than adapting existing ones. Steels also introduces multiple word sentences, but it is unclear as to why agents invent a multiple word description over creating a new single word description. The invention is triggered and does not emerge. This research is based on real multiple word inputs, so the reason for invention is not necessary, unlike the reason for adoption i.e. why the system adopts two-word descriptions. The comparison algorithm, as previously noted, is similar to alignment based learning (van Zaanen, 2000). The system in this research performs perfect alignment requiring exact word matches when finding equal parts and unequal parts. This system also uses concepts, reducing the number of incorrect groupings, or constituents, when there is ambiguity in text. Unsupervised induction can also be found in EMILE (van Zaanen and Adriaans, 2001). EMILE substitution classes by means of clustering. These classes are comparable to this system&apos;s groups although no concepts are used. Research As the system stands, it uses a small input set. Further developments are focussed on expanding the system. All ten of Brown&apos;s relations should be implemented. Larger concept and vocabulary sets are therefore required. Extensions to these sets are likely to affect underextensions, mismatches, the length of pre-syntactic usage time, and the overall growth pattern of simple syntax. 100% 90% 80% 70% 60% 50% 40% 30% 20% 10% 0% 1 5 9 13 17 21 25 29 33 37 41 45 49 53 57 61 65 69 73 Syntactic Holophrastic 67 This paper offers a potential explanation of the mechanism by which the two-word stage emerges from the one-word stage. It suggests that syntactic data is sought out from the beginning of language acquisition. This syntactic data is always competing with the associations of holophrastic data. Syntax is strengthened when patterns are consistently found between strings and concepts, and is used in favour of holophrastic data when it is sufficiently frequent. The simple syntax continues to grow in strength, ultimately being used in favour of holophrastic data in all production and comprehension tasks. This system provides the foundation for more complex, hierarchical, syntax to emerge. The type and volume of input is the only constraint upon the system. The entry into post two-word stages is predicted from the system&apos;s robust architecture. The first author is sponsored by a studentship from the EPSRC. Thanks to the workshop reviewers for their helpful and much appreciated advice.</abstract>
<note confidence="0.963573230769231">References S. Abidi, 1996. A Neural Network Simulation of Child Development at the One-word Stage. of IASTED Int. Conf. on Simulation and Optimization, Gold Coast, Australia. L. Bloom, 1973. One Word at a Time. The use of single-word utterances before syntax The Hague, Mouton. Brown, 1986. Language and categories. In of ed. J.S. Bruner, J.J. Goodnow, and G.A. Austin, pages 247-312. New York: John Wiley, 1956. Reprint, New Brunswick: Transaction. Gleitman and Elissa L. Newport, 1995.</note>
<affiliation confidence="0.581686333333333">Invention of Language by Children: Environmental and Biological Influences on the Acquisition In “An Invitation to Cognitive Science”,</affiliation>
<address confidence="0.777143666666667">Gleitman and M. Liberman, ed., Vol.1, Cambridge, Mass., London, MIT Press. S.R. Howell and S. Becker, 2001. Modelling language</address>
<note confidence="0.971279">acquisition: Grammar from the Lexicon? Proceedings of the Cognitive Science Society.. S.R. Howell, S. Becker, and D. Jankowicz, 2001.</note>
<title confidence="0.90920075">Modelling Language Acquisition: Lexical Grounding Perceptual In Proceedings of the 2001 Workshop on Developmental Embodied Cognition</title>
<author confidence="0.982445">J R Hurford</author>
<author confidence="0.982445">M Studdert-Kennedey</author>
<author confidence="0.982445">C Knight</author>
<affiliation confidence="0.696398">The Emergence of Syntax. In to the evolution of language: social and cognitive Cambridge, Cambridge University Press.</affiliation>
<address confidence="0.740326">Ingram, 1989. Language Acquisition. Method,</address>
<affiliation confidence="0.9230245">and Cambridge: Cambridge University Press.</affiliation>
<address confidence="0.836802">Jakobson, 1971. “mama” and “papa”?</address>
<author confidence="0.502042">Child Language A Book of Readings”</author>
<author confidence="0.502042">by A Bar-</author>
<note confidence="0.860987448275862">Adon and W. F. Leopold, ed., pages 213-217. Englewood Cliffs, NJ:Prentice-Hall. P.W. Jusczyk, 1999 How infants begin to extract words speech. in Cognitive 3 (9, September):323-328. Kirby, 1999. out of learning: The cultural evolution of structured communication in a of induction In Proceedings of ECAL99 European Conference on Artificial Life, D. Floreano et al. ed. pages 694-703, Berlin: Springer- Verlag, M. Oliphant and J. Batali 1997. Learning and the of coordinated communication. for in Language 11(1). Paivio, 1971, and Verbal New York: Holt, Rinehart &amp; Winston. Piaget, 1960. Language and Thought of the and K. Paul, 3rd ed.,. Routledge Paperbacks. Pinker, 1994. Language Instinct. The New of Language and Allen Lane, Penguin Press. D. Roy, 2001. Grounded spoken language acquisition: in word learning. Transactions on Multimedia. G. Scheler, 1997d. The transition from babbling to the one-word stage: A computational model. In Proceedings of GALA &apos;97. L. Steels and F. Kaplan, 2001. AIBO&apos;s first words: The</note>
<abstract confidence="0.881506526315789">learning of language and meaning. of vol. 4(1):3-32. John Benjamin’s Publishing Company, Amsterdam, Holland. L. Steels, 1998. The Origins of Syntax in visually robotic agents. 1-24. M. Tomasello, and A.C. Kruger, 1992. Joint attention in action: Acquiring verbs in ostensive and noncontexts. of Child Language 19:311-333. M. van Zaanen, 2000. Learning structure using based learning. In of the Third Annual Doctoral Research Colloquium pages 75-82. M. van Zaanen and P. Adriaans, 2001. Alignmentbased learning versus EMILE: A comparison. In Proceedings of the Belgian-Dutch Conference on AI W.H. Zuidema, 2001. Emergent syntax: the unremitting value of computational modelling for understanding origins of complex language. 641-644.</abstract>
<note confidence="0.688553">Springer, Prague, Sept. 10-14, 2001. 68</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Abidi</author>
</authors>
<title>A Neural Network Simulation of Child Language Development at the One-word Stage.</title>
<date>1996</date>
<booktitle>In proceedings of IASTED Int. Conf. on Modelling, Simulation and Optimization,</booktitle>
<location>Gold Coast, Australia.</location>
<marker>Abidi, 1996</marker>
<rawString>S. Abidi, 1996. A Neural Network Simulation of Child Language Development at the One-word Stage. In proceedings of IASTED Int. Conf. on Modelling, Simulation and Optimization, Gold Coast, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Bloom</author>
</authors>
<title>One Word at a Time. The use of single-word utterances before syntax The Hague,</title>
<date>1973</date>
<location>Mouton.</location>
<contexts>
<context position="29489" citStr="Bloom, 1973" startWordPosition="4720" endWordPosition="4721">search can be viewed as a form of social learning with one agent (string and concept generator) performing the teacher role, and the other agent (the system) performing the learner role. Simulations of both the babbling stage and the one-word stage have been developed (Scheler, 1997; Abidi, 1999). ACCLAIM, a one-word stage simulator, demonstrates that systems can react appropriately to changes in situations. For example, when a cessation event is triggered, it produces &amp;quot;Stop&amp;quot;, and when an object is requested, it produces &amp;quot;More&amp;quot;. Both examples are typical of children during the one-word stage (Bloom, 1973). Several systems exist that use perceptions to encourage language acquisition (Howell, Becker, and Jankowicz,, 2001; Roy, 2001). ELBA learns both nouns and verbs from video scenes, starting with a blank lexicon. Such systems have helped in the selection of both appropriate input sources and feature values to use in this research. This system will also be physically grounded in future. The research presented in this paper describes a system that drives linguistic development. Other systems have used similar techniques, based on syntactic and semantic bootstrapping (Howell and Becker, 2001), bu</context>
</contexts>
<marker>Bloom, 1973</marker>
<rawString>L. Bloom, 1973. One Word at a Time. The use of single-word utterances before syntax The Hague, Mouton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R W Brown</author>
</authors>
<title>Language and categories. In</title>
<date>1986</date>
<pages>247--312</pages>
<editor>A Study of Thinking”, ed. J.S. Bruner, J.J. Goodnow, and G.A. Austin,</editor>
<publisher>John Wiley,</publisher>
<location>New York:</location>
<marker>Brown, 1986</marker>
<rawString>R.W. Brown, 1986. Language and categories. In “A Study of Thinking”, ed. J.S. Bruner, J.J. Goodnow, and G.A. Austin, pages 247-312. New York: John Wiley, 1956. Reprint, New Brunswick: Transaction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L R Gleitman</author>
<author>Elissa L Newport</author>
</authors>
<title>The Invention of Language by Children: Environmental and Biological Influences on the Acquisition Language.</title>
<date>1995</date>
<booktitle>In “An Invitation to Cognitive Science”, L.R. Gleitman and M. Liberman, 2nd ed., Vol.1,</booktitle>
<publisher>MIT Press.</publisher>
<location>Cambridge, Mass., London,</location>
<contexts>
<context position="5649" citStr="Gleitman and Newport, 1995" startWordPosition="840" endWordPosition="843">as &amp;quot;dog&amp;quot; referring to only the family dog. Overextension, similarly, is an association that is too broad, such as &amp;quot;dog&amp;quot; referring to all four legged animals. Mismatches, or idiosyncratic referencing also occur, resulting in a word being associated with an unrelated concept, such as &amp;quot;dog&amp;quot; referring to a table (Pinker, 1994). These associations change over time. The two-word stage (18-24 months) introduces simple syntax into the child&apos;s language faculty. Children appear to determine the most important words in a sentence and, almost all of the time, use them in the same order as an adult would (Gleitman and Newport, 1995). Brown (1973) defines a typology to express semantic relations in the two-word stage. It contains ten sets of relations, but only one will be considered in this paper; attribute + entity (&amp;quot;red circle&amp;quot;). During this stage, children already demonstrate a three word comprehension level (Tomasello and Kruger, 1992). The concepts relating to their sentences may therefore be more detailed than the phrases themselves. The system is expected to make the transition from the one-word stage to the two-word stage without changes to the functionality of the system. Once the system begins to run, input is </context>
</contexts>
<marker>Gleitman, Newport, 1995</marker>
<rawString>L.R.. Gleitman and Elissa L. Newport, 1995. The Invention of Language by Children: Environmental and Biological Influences on the Acquisition Language. In “An Invitation to Cognitive Science”, L.R. Gleitman and M. Liberman, 2nd ed., Vol.1, Cambridge, Mass., London, MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R Howell</author>
<author>S Becker</author>
</authors>
<title>Modelling language acquisition: Grammar from the Lexicon?</title>
<date>2001</date>
<booktitle>In Proceedings of the Cognitive Science Society..</booktitle>
<contexts>
<context position="30085" citStr="Howell and Becker, 2001" startWordPosition="4807" endWordPosition="4810">one-word stage (Bloom, 1973). Several systems exist that use perceptions to encourage language acquisition (Howell, Becker, and Jankowicz,, 2001; Roy, 2001). ELBA learns both nouns and verbs from video scenes, starting with a blank lexicon. Such systems have helped in the selection of both appropriate input sources and feature values to use in this research. This system will also be physically grounded in future. The research presented in this paper describes a system that drives linguistic development. Other systems have used similar techniques, based on syntactic and semantic bootstrapping (Howell and Becker, 2001), but have not explained how multiple word acquisition is achieved from a single word basis. Steels (1998) introduces frames that group lexical elements together by the roles that they play, very similar to groups in this paper. Frames are more dynamic than groups however, structurally adapting when words reoccur. Groups do not adapt in this way. New groups are created to describe similarities rather than adapting existing ones. Steels also introduces multiple word sentences, but it is unclear as to why agents invent a multiple word description over creating a new single word description. The </context>
</contexts>
<marker>Howell, Becker, 2001</marker>
<rawString>S.R. Howell and S. Becker, 2001. Modelling language acquisition: Grammar from the Lexicon? In Proceedings of the Cognitive Science Society..</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R Howell</author>
<author>S Becker</author>
<author>D Jankowicz</author>
</authors>
<title>Modelling Language Acquisition: Lexical Grounding Through Perceptual Features.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2001 Workshop on Developmental Embodied Cognition</booktitle>
<marker>Howell, Becker, Jankowicz, 2001</marker>
<rawString>S.R. Howell, S. Becker, and D. Jankowicz, 2001. Modelling Language Acquisition: Lexical Grounding Through Perceptual Features. In Proceedings of the 2001 Workshop on Developmental Embodied Cognition</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Hurford</author>
<author>M Studdert-Kennedey</author>
<author>C Knight</author>
</authors>
<title>The Emergence of Syntax. In “Approaches to the evolution of language: social and cognitive bases”, Cambridge,</title>
<date>1998</date>
<publisher>Cambridge University Press.</publisher>
<marker>Hurford, Studdert-Kennedey, Knight, 1998</marker>
<rawString>J.R. Hurford, M. Studdert-Kennedey, and C. Knight, 1998. The Emergence of Syntax. In “Approaches to the evolution of language: social and cognitive bases”, Cambridge, Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Ingram</author>
</authors>
<title>First Language Acquisition. Method, Description and Explanation. Cambridge:</title>
<date>1989</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1235" citStr="Ingram, 1989" startWordPosition="171" endWordPosition="172">dly recognised, forming syntactic categories; resulting in an emergent simple syntax. The system demonstrates a similar maturation as children as evidenced by phenomena such as overextensions and mismatching, and the use of one-word descriptions being replaced by two-word descriptions over time. 1 Introduction Studies of first language acquisition in children have documented general stages in linguistic development. Neither the trigger nor the mechanism that takes a child from one stage to the next are known. Stages arise gradually with no precise start or end points, overlapping one another (Ingram, 1989). The aim of this research is to develop a system that autonomously acquires conceptual representations of individual words (the &amp;quot;one-word stage&amp;quot;) and also, simultaneously, is capable of developing representations of valid multi-word structures i.e. simple syntax (the &amp;quot;two-word stage&amp;quot;). Two-word descriptions are expected to emerge as a result of the system state and not be artificially triggered. The system accepts sentences containing a maximum of two words. It is designed to be scalable, allowing larger, more natural sentence sizes also. System input is therefore a mixture of both one-word a</context>
<context position="25782" citStr="Ingram, 1989" startWordPosition="4128" endWordPosition="4129">ings produced using holophrastic data and the number of correct strings produced using syntactic data alone are compared (see Figure 2). The data demonstrate that the system uses mostly holophrastic matches in early rounds (comparable to the one-word stage). This is eliminated in further rounds, in favour or syntactic matches alone (the two-word stage). Note that although the holophrastic stage may appear to be producing two-words, these words are considered to be one-word. For example, &amp;quot;allgone&amp;quot; is considered to be one-word in early stages of linguistic development, as opposed to &amp;quot;all gone&amp;quot; (Ingram, 1989). Figure 2: Shows number of correct holophrastic and syntactic matches. The syntactic data continues to rise, until it achieves full production. The holophrastic stage never achieves full production, but peaks, then reduces to zero. This trend occurs as holophrastic underextensions such as &amp;quot;red&amp;quot; representing red square become more likely than &amp;quot;red square&amp;quot; representing red square. Early syntactic matches are based on novel string productions for novel string concepts. Holophrastic matching is incapable of producing novel strings from novel concepts, as it deals with concrete concepts. Abstract </context>
</contexts>
<marker>Ingram, 1989</marker>
<rawString>D. Ingram, 1989. First Language Acquisition. Method, Description and Explanation. Cambridge: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Jakobson</author>
</authors>
<title>Why “mama” and “papa”?</title>
<date>1971</date>
<booktitle>In “ Child Language: A Book of Readings”,</booktitle>
<pages>213--217</pages>
<editor>by A. BarAdon and W. F. Leopold, ed.,</editor>
<location>Englewood Cliffs, NJ:Prentice-Hall.</location>
<contexts>
<context position="3784" citStr="Jakobson, 1971" startWordPosition="544" endWordPosition="545">orical perception to voice, can use formant transition information to mark articulation, and show intonation sensitivity (Pinker, 1994, Jusczyk, 1999). In terms of production, children produce noises, such as discomfort noises (0-2 months), comfort noises (2-4 months), and &amp;quot;play&amp;quot; vocally with pitch and loudness variations (4-7 months) (Pinker, 1994). The babbling stage (6-8 months) is characterised with the production of recognisable syllables. The syllables are often repeated, such as [mamama] and [papapa], with the easiest to produce sounds often being associated with members of the family (Jakobson, 1971). From this evidence it is reasonable to draw conclusions about linguistic abilities in the young child that can be used to frame assumptions for use in the system. It is assumed that the system can receive and produce strings that can be broken down into their component words. These words can be compared and equalities can be detected. 61 3 One-Word Stage and Two-Word Stages The system is required to produce one-word descriptions in early stages that develop into twoword descriptions, where appropriate, in latter stages.. The recognition of each stage is based on the number of words that the </context>
</contexts>
<marker>Jakobson, 1971</marker>
<rawString>R. Jakobson, 1971. Why “mama” and “papa”? In “ Child Language: A Book of Readings”, by A. BarAdon and W. F. Leopold, ed., pages 213-217. Englewood Cliffs, NJ:Prentice-Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P W Jusczyk</author>
</authors>
<title>How infants begin to extract words from speech.</title>
<date>1999</date>
<journal>Trends in Cognitive Science,</journal>
<volume>3</volume>
<issue>9</issue>
<pages>323--328</pages>
<contexts>
<context position="3319" citStr="Jusczyk, 1999" startWordPosition="476" endWordPosition="477">influences; the direction and aims of future research is described briefly; and finally, conclusions are drawn. 2 Pre-One-Word Stage Children Linguistic abilities can be found in children prior to word production. In terms of comprehension, children can distinguish between their mother&apos;s voice and a stranger&apos;s voice, male and female voices, and sentences spoken in their mother&apos;s native language and sentences spoken in a different language. They also show categorical perception to voice, can use formant transition information to mark articulation, and show intonation sensitivity (Pinker, 1994, Jusczyk, 1999). In terms of production, children produce noises, such as discomfort noises (0-2 months), comfort noises (2-4 months), and &amp;quot;play&amp;quot; vocally with pitch and loudness variations (4-7 months) (Pinker, 1994). The babbling stage (6-8 months) is characterised with the production of recognisable syllables. The syllables are often repeated, such as [mamama] and [papapa], with the easiest to produce sounds often being associated with members of the family (Jakobson, 1971). From this evidence it is reasonable to draw conclusions about linguistic abilities in the young child that can be used to frame assum</context>
</contexts>
<marker>Jusczyk, 1999</marker>
<rawString>P.W. Jusczyk, 1999 How infants begin to extract words from speech. Trends in Cognitive Science, 3 (9, September):323-328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kirby</author>
</authors>
<title>Syntax out of learning: The cultural evolution of structured communication in a population of induction algorithms.</title>
<date>1999</date>
<booktitle>In Proceedings of ECAL99 European Conference on Artificial Life,</booktitle>
<pages>694--703</pages>
<editor>D. Floreano et al. ed.</editor>
<publisher>SpringerVerlag,</publisher>
<location>Berlin:</location>
<contexts>
<context position="28501" citStr="Kirby, 1999" startWordPosition="4567" endWordPosition="4568">ffect the transition. The greater the number of words in multi-groups (the greater the size of syntactic categories), the lower the abstract factor is required to encourage the emergence of simple syntax. 6 Related Works Supporters of computational modelling in language acquisition, often promote the practical importance of running simulations, where evolutionary effects can be recreated in short time periods (Zuidema, 2001). Although this paper is focussed on an individual system, or agent, acquiring language, it is been influenced by research into social learning (Oliphant and Batali, 1997; Kirby, 1999; Steels and Kaplan, 2002). Social learning demonstrates the convergence upon a common language, or set of languages, from an uncoordinated protolanguage, within a population of agents. Social learning allows for the playing of games between agents, similar to those in this paper, with the results being used as further system input, to support, or deny associations. This research can be viewed as a form of social learning with one agent (string and concept generator) performing the teacher role, and the other agent (the system) performing the learner role. Simulations of both the babbling stag</context>
</contexts>
<marker>Kirby, 1999</marker>
<rawString>S. Kirby, 1999. Syntax out of learning: The cultural evolution of structured communication in a population of induction algorithms. In Proceedings of ECAL99 European Conference on Artificial Life, D. Floreano et al. ed. pages 694-703, Berlin: SpringerVerlag,</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Oliphant</author>
<author>J Batali</author>
</authors>
<title>Learning and the emergence of coordinated communication.</title>
<date>1997</date>
<journal>Centre for Research in Language Newsletter,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="28488" citStr="Oliphant and Batali, 1997" startWordPosition="4563" endWordPosition="4566">stract factor values will affect the transition. The greater the number of words in multi-groups (the greater the size of syntactic categories), the lower the abstract factor is required to encourage the emergence of simple syntax. 6 Related Works Supporters of computational modelling in language acquisition, often promote the practical importance of running simulations, where evolutionary effects can be recreated in short time periods (Zuidema, 2001). Although this paper is focussed on an individual system, or agent, acquiring language, it is been influenced by research into social learning (Oliphant and Batali, 1997; Kirby, 1999; Steels and Kaplan, 2002). Social learning demonstrates the convergence upon a common language, or set of languages, from an uncoordinated protolanguage, within a population of agents. Social learning allows for the playing of games between agents, similar to those in this paper, with the results being used as further system input, to support, or deny associations. This research can be viewed as a form of social learning with one agent (string and concept generator) performing the teacher role, and the other agent (the system) performing the learner role. Simulations of both the </context>
</contexts>
<marker>Oliphant, Batali, 1997</marker>
<rawString>M. Oliphant and J. Batali 1997. Learning and the emergence of coordinated communication. Centre for Research in Language Newsletter, 11(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Paivio</author>
</authors>
<title>Imagery and Verbal Processes.</title>
<date>1971</date>
<publisher>Winston.</publisher>
<location>New York: Holt, Rinehart</location>
<marker>Paivio, 1971</marker>
<rawString>A. Paivio, 1971, Imagery and Verbal Processes. New York: Holt, Rinehart &amp; Winston.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Piaget</author>
</authors>
<title>The Language and Thought of the Child.</title>
<date>1960</date>
<editor>and K. Paul, 3rd ed.,.</editor>
<publisher>Routledge</publisher>
<contexts>
<context position="4844" citStr="Piaget, 1960" startWordPosition="715" endWordPosition="716">ges that develop into twoword descriptions, where appropriate, in latter stages.. The recognition of each stage is based on the number of words that the system uses at a particular point. In children, the one and two-word stages have notable features. The one-word, or holophrastic, stage (9-18 months), is characterised by one-word vocalisations that are consistently associated with concepts. These concepts can be either concrete or abstract, such as &amp;quot;mama&amp;quot;, referring to the concrete concept of the child&apos;s mother, and &amp;quot;more&amp;quot;, an abstract concept which can be applied in a variety of situations (Piaget, 1960). Two phenomena that occur during this stage are underextensions and overextensions. An underextension is the formation of a word to concept association that is too narrow, such as &amp;quot;dog&amp;quot; referring to only the family dog. Overextension, similarly, is an association that is too broad, such as &amp;quot;dog&amp;quot; referring to all four legged animals. Mismatches, or idiosyncratic referencing also occur, resulting in a word being associated with an unrelated concept, such as &amp;quot;dog&amp;quot; referring to a table (Pinker, 1994). These associations change over time. The two-word stage (18-24 months) introduces simple syntax </context>
</contexts>
<marker>Piaget, 1960</marker>
<rawString>J. Piaget, 1960. The Language and Thought of the Child. Routledge and K. Paul, 3rd ed.,. Routledge Paperbacks.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pinker</author>
</authors>
<title>The Language Instinct. The New Science of Language and Mind.</title>
<date>1994</date>
<publisher>Allen Lane, Penguin Press.</publisher>
<contexts>
<context position="3303" citStr="Pinker, 1994" startWordPosition="474" endWordPosition="475"> citing major influences; the direction and aims of future research is described briefly; and finally, conclusions are drawn. 2 Pre-One-Word Stage Children Linguistic abilities can be found in children prior to word production. In terms of comprehension, children can distinguish between their mother&apos;s voice and a stranger&apos;s voice, male and female voices, and sentences spoken in their mother&apos;s native language and sentences spoken in a different language. They also show categorical perception to voice, can use formant transition information to mark articulation, and show intonation sensitivity (Pinker, 1994, Jusczyk, 1999). In terms of production, children produce noises, such as discomfort noises (0-2 months), comfort noises (2-4 months), and &amp;quot;play&amp;quot; vocally with pitch and loudness variations (4-7 months) (Pinker, 1994). The babbling stage (6-8 months) is characterised with the production of recognisable syllables. The syllables are often repeated, such as [mamama] and [papapa], with the easiest to produce sounds often being associated with members of the family (Jakobson, 1971). From this evidence it is reasonable to draw conclusions about linguistic abilities in the young child that can be use</context>
<context position="5346" citStr="Pinker, 1994" startWordPosition="793" endWordPosition="794"> child&apos;s mother, and &amp;quot;more&amp;quot;, an abstract concept which can be applied in a variety of situations (Piaget, 1960). Two phenomena that occur during this stage are underextensions and overextensions. An underextension is the formation of a word to concept association that is too narrow, such as &amp;quot;dog&amp;quot; referring to only the family dog. Overextension, similarly, is an association that is too broad, such as &amp;quot;dog&amp;quot; referring to all four legged animals. Mismatches, or idiosyncratic referencing also occur, resulting in a word being associated with an unrelated concept, such as &amp;quot;dog&amp;quot; referring to a table (Pinker, 1994). These associations change over time. The two-word stage (18-24 months) introduces simple syntax into the child&apos;s language faculty. Children appear to determine the most important words in a sentence and, almost all of the time, use them in the same order as an adult would (Gleitman and Newport, 1995). Brown (1973) defines a typology to express semantic relations in the two-word stage. It contains ten sets of relations, but only one will be considered in this paper; attribute + entity (&amp;quot;red circle&amp;quot;). During this stage, children already demonstrate a three word comprehension level (Tomasello a</context>
</contexts>
<marker>Pinker, 1994</marker>
<rawString>S. Pinker, 1994. The Language Instinct. The New Science of Language and Mind. Allen Lane, Penguin Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roy</author>
</authors>
<title>Grounded spoken language acquisition: Experiments in word learning.</title>
<date>2001</date>
<journal>IEEE Transactions on Multimedia.</journal>
<contexts>
<context position="29617" citStr="Roy, 2001" startWordPosition="4737" endWordPosition="4738">he other agent (the system) performing the learner role. Simulations of both the babbling stage and the one-word stage have been developed (Scheler, 1997; Abidi, 1999). ACCLAIM, a one-word stage simulator, demonstrates that systems can react appropriately to changes in situations. For example, when a cessation event is triggered, it produces &amp;quot;Stop&amp;quot;, and when an object is requested, it produces &amp;quot;More&amp;quot;. Both examples are typical of children during the one-word stage (Bloom, 1973). Several systems exist that use perceptions to encourage language acquisition (Howell, Becker, and Jankowicz,, 2001; Roy, 2001). ELBA learns both nouns and verbs from video scenes, starting with a blank lexicon. Such systems have helped in the selection of both appropriate input sources and feature values to use in this research. This system will also be physically grounded in future. The research presented in this paper describes a system that drives linguistic development. Other systems have used similar techniques, based on syntactic and semantic bootstrapping (Howell and Becker, 2001), but have not explained how multiple word acquisition is achieved from a single word basis. Steels (1998) introduces frames that gr</context>
</contexts>
<marker>Roy, 2001</marker>
<rawString>D. Roy, 2001. Grounded spoken language acquisition: Experiments in word learning. IEEE Transactions on Multimedia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Scheler</author>
</authors>
<title>The transition from babbling to the one-word stage: A computational model.</title>
<date>1997</date>
<booktitle>In Proceedings of GALA &apos;97.</booktitle>
<contexts>
<context position="29160" citStr="Scheler, 1997" startWordPosition="4671" endWordPosition="4672">monstrates the convergence upon a common language, or set of languages, from an uncoordinated protolanguage, within a population of agents. Social learning allows for the playing of games between agents, similar to those in this paper, with the results being used as further system input, to support, or deny associations. This research can be viewed as a form of social learning with one agent (string and concept generator) performing the teacher role, and the other agent (the system) performing the learner role. Simulations of both the babbling stage and the one-word stage have been developed (Scheler, 1997; Abidi, 1999). ACCLAIM, a one-word stage simulator, demonstrates that systems can react appropriately to changes in situations. For example, when a cessation event is triggered, it produces &amp;quot;Stop&amp;quot;, and when an object is requested, it produces &amp;quot;More&amp;quot;. Both examples are typical of children during the one-word stage (Bloom, 1973). Several systems exist that use perceptions to encourage language acquisition (Howell, Becker, and Jankowicz,, 2001; Roy, 2001). ELBA learns both nouns and verbs from video scenes, starting with a blank lexicon. Such systems have helped in the selection of both appropri</context>
</contexts>
<marker>Scheler, 1997</marker>
<rawString>G. Scheler, 1997d. The transition from babbling to the one-word stage: A computational model. In Proceedings of GALA &apos;97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Steels</author>
<author>F Kaplan</author>
</authors>
<title>AIBO&apos;s first words: The social learning of language and meaning.</title>
<date>2001</date>
<journal>Evolution of Communication,</journal>
<volume>vol.</volume>
<pages>4--1</pages>
<publisher>John Benjamin’s Publishing Company,</publisher>
<location>Amsterdam, Holland.</location>
<contexts>
<context position="6611" citStr="Steels and Kaplan, 2001" startWordPosition="990" endWordPosition="993">o their sentences may therefore be more detailed than the phrases themselves. The system is expected to make the transition from the one-word stage to the two-word stage without changes to the functionality of the system. Once the system begins to run, input is restricted to that of sensory (concept based) and vocal (string representation) data. 4 System Design and Implementation 4.1 Introduction The system is designed to learn phrase-toconcept associations and demonstrate it through playing games: a guessing game and a naming game. Games are often used to test, and encourage system learning (Steels and Kaplan, 2001). The learning process involves a user selecting an object in a scene and naming it. The guessing game involves a user saying a phrase, and the system pointing to the object that the phrase refers to. The naming game involves a user pointing to an object and the system naming it The system is not physically grounded, so all games are simulated. The learning process allows the system to acquire associations between phrases and concepts while the games test system comprehension and system production respectively. The learning process takes a string and concept as input, and produces no output. C</context>
</contexts>
<marker>Steels, Kaplan, 2001</marker>
<rawString>L. Steels and F. Kaplan, 2001. AIBO&apos;s first words: The social learning of language and meaning. Evolution of Communication, vol. 4(1):3-32. John Benjamin’s Publishing Company, Amsterdam, Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Steels</author>
</authors>
<title>The Origins of Syntax in visually grounded robotic agents.</title>
<date>1998</date>
<journal>AI</journal>
<volume>103</volume>
<pages>1--24</pages>
<contexts>
<context position="30191" citStr="Steels (1998)" startWordPosition="4826" endWordPosition="4827">ecker, and Jankowicz,, 2001; Roy, 2001). ELBA learns both nouns and verbs from video scenes, starting with a blank lexicon. Such systems have helped in the selection of both appropriate input sources and feature values to use in this research. This system will also be physically grounded in future. The research presented in this paper describes a system that drives linguistic development. Other systems have used similar techniques, based on syntactic and semantic bootstrapping (Howell and Becker, 2001), but have not explained how multiple word acquisition is achieved from a single word basis. Steels (1998) introduces frames that group lexical elements together by the roles that they play, very similar to groups in this paper. Frames are more dynamic than groups however, structurally adapting when words reoccur. Groups do not adapt in this way. New groups are created to describe similarities rather than adapting existing ones. Steels also introduces multiple word sentences, but it is unclear as to why agents invent a multiple word description over creating a new single word description. The invention is triggered and does not emerge. This research is based on real multiple word inputs, so the re</context>
</contexts>
<marker>Steels, 1998</marker>
<rawString>L. Steels, 1998. The Origins of Syntax in visually grounded robotic agents. AI 103, 1-24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tomasello</author>
<author>A C Kruger</author>
</authors>
<title>Joint attention in action: Acquiring verbs in ostensive and nonostensive contexts.</title>
<date>1992</date>
<journal>Journal of Child Language</journal>
<pages>19--311</pages>
<contexts>
<context position="5962" citStr="Tomasello and Kruger, 1992" startWordPosition="888" endWordPosition="891">nker, 1994). These associations change over time. The two-word stage (18-24 months) introduces simple syntax into the child&apos;s language faculty. Children appear to determine the most important words in a sentence and, almost all of the time, use them in the same order as an adult would (Gleitman and Newport, 1995). Brown (1973) defines a typology to express semantic relations in the two-word stage. It contains ten sets of relations, but only one will be considered in this paper; attribute + entity (&amp;quot;red circle&amp;quot;). During this stage, children already demonstrate a three word comprehension level (Tomasello and Kruger, 1992). The concepts relating to their sentences may therefore be more detailed than the phrases themselves. The system is expected to make the transition from the one-word stage to the two-word stage without changes to the functionality of the system. Once the system begins to run, input is restricted to that of sensory (concept based) and vocal (string representation) data. 4 System Design and Implementation 4.1 Introduction The system is designed to learn phrase-toconcept associations and demonstrate it through playing games: a guessing game and a naming game. Games are often used to test, and en</context>
</contexts>
<marker>Tomasello, Kruger, 1992</marker>
<rawString>M. Tomasello, and A.C. Kruger, 1992. Joint attention in action: Acquiring verbs in ostensive and nonostensive contexts. Journal of Child Language 19:311-333.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M van Zaanen</author>
</authors>
<title>Learning structure using alignment based learning.</title>
<date>2000</date>
<booktitle>In Proceedings of the Third Annual Doctoral Research Colloquium (CLUK),</booktitle>
<pages>75--82</pages>
<marker>van Zaanen, 2000</marker>
<rawString>M. van Zaanen, 2000. Learning structure using alignment based learning. In Proceedings of the Third Annual Doctoral Research Colloquium (CLUK), pages 75-82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M van Zaanen</author>
<author>P Adriaans</author>
</authors>
<title>Alignmentbased learning versus EMILE: A comparison.</title>
<date>2001</date>
<booktitle>In Proceedings of the Belgian-Dutch Conference on AI (BNAIC).</booktitle>
<marker>van Zaanen, Adriaans, 2001</marker>
<rawString>M. van Zaanen and P. Adriaans, 2001. Alignmentbased learning versus EMILE: A comparison. In Proceedings of the Belgian-Dutch Conference on AI (BNAIC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W H Zuidema</author>
</authors>
<title>Emergent syntax: the unremitting value of computational modelling for understanding the origins of complex language.</title>
<date>2001</date>
<volume>01</volume>
<pages>641--644</pages>
<publisher>Springer,</publisher>
<location>Prague,</location>
<contexts>
<context position="28318" citStr="Zuidema, 2001" startWordPosition="4539" endWordPosition="4540">to the two-word stage, without the use of an artificial trigger. The shift is gradual although the use of larger concept and vocabulary sets, plus different abstract factor values will affect the transition. The greater the number of words in multi-groups (the greater the size of syntactic categories), the lower the abstract factor is required to encourage the emergence of simple syntax. 6 Related Works Supporters of computational modelling in language acquisition, often promote the practical importance of running simulations, where evolutionary effects can be recreated in short time periods (Zuidema, 2001). Although this paper is focussed on an individual system, or agent, acquiring language, it is been influenced by research into social learning (Oliphant and Batali, 1997; Kirby, 1999; Steels and Kaplan, 2002). Social learning demonstrates the convergence upon a common language, or set of languages, from an uncoordinated protolanguage, within a population of agents. Social learning allows for the playing of games between agents, similar to those in this paper, with the results being used as further system input, to support, or deny associations. This research can be viewed as a form of social </context>
</contexts>
<marker>Zuidema, 2001</marker>
<rawString>W.H. Zuidema, 2001. Emergent syntax: the unremitting value of computational modelling for understanding the origins of complex language. ECAL01, 641-644. Springer, Prague, Sept. 10-14, 2001.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>