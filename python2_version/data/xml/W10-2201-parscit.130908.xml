<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000027">
<title confidence="0.984081">
Instance-based acquisition of vowel harmony
</title>
<author confidence="0.999">
Fr´ed´eric Mailhot
</author>
<affiliation confidence="0.852821666666667">
Institute of Cognitive Science
Carleton University
Ottawa, ON, Canada
</affiliation>
<email confidence="0.995005">
fmailhot@connect.carleton.ca
</email>
<sectionHeader confidence="0.993823" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999039">
I present LIBPHON, a nonparametric
regression-based model of phonologi-
cal acquisition that induces a gener-
alised and productive pattern of vowel
harmony—including opaque and transpar-
ent neutrality—on the basis of simplified
formant data. The model quickly learns to
generate harmonically correct morpholog-
ically complex forms to which it has not
been exposed.
</bodyText>
<sectionHeader confidence="0.81443" genericHeader="method">
1 Explaining phonological patterns
</sectionHeader>
<bodyText confidence="0.999851346153846">
How do infants learn the phonetic categories
and phonotactic patterns of their native lan-
guages? How strong are the biases that learn-
ers bring to the task of phonological acquis-
tion? Phonologists from the rationalist tradition
that dominated the past half-century of linguis-
tic research typically posit strong biases in ac-
quisition, with language learners using innately-
given, domain-specific representations (Chomsky
and Halle, 1968), constraints (Prince and Smolen-
sky, 2004) and learning algorithms (Tesar and
Smolensky, 2000; Dresher, 1999) to learn abstract
rules or constraint rankings from which they can
classify or produce novel instances.
In the last decade, however, there has been a
shift toward empiricist approaches to phonologi-
cal acquisition, use and knowledge. In this liter-
ature, eager learning algorithms (Aha, 1997), in
which training data are used to update intensional
representations of functions or categories then dis-
carded, have been the norm.1 However, research
in related fields—particularly speech perception—
indicates that speakers’ knowledge and use of
language, both in production and comprehen-
sion, is at least partly episodic, or instance-based
(Goldinger, 1996; Johnson, 1997). Additionally,
</bodyText>
<footnote confidence="0.430463">
1Daelemans et al. (1994) is a notable exception.
</footnote>
<bodyText confidence="0.999842888888889">
motivation for instance-based models of categori-
sation has a lengthy history in cognitive psychol-
ogy (Medin and Schaffer, 1978), and these meth-
ods are well-known in the statistical and machine
learning literature, having been studied for over
half a century (Fix and Hodges, 1951; Cover and
Hart, 1967; Hastie et al., 2009). Consequently, it
seems a worthy endeavour applying an instance-
based method to a problem that is of interest to
traditional phonologists, the acquisition and use
of vowel harmony, while simultaneously effecting
a rapprochement with adjacent disicplines in the
cognitive sciences. In sections 2 and 3 I give some
brief background on vowel harmony and instance-
based models, respectively. Section 4 introduces
my model, LIBPHON, and section 5 the languages
it learns. I discuss some simulations and results in
section 6, and conclude in section 7.
</bodyText>
<sectionHeader confidence="0.964335" genericHeader="method">
2 Vowel harmony
</sectionHeader>
<bodyText confidence="0.999663666666667">
Vowel harmony is a phonological phenomenon in
which there are co-occurrence constraints on vow-
els within words.2 The vowels in a language with
vowel harmony can be classified into disjoint sets,
such that words contain vowels from only one of
the sets. The Finnish system of vowel harmony ex-
emplified by the forms in Table 1 provides a stan-
dard example from the literature (van der Hulst
and van de Weijer, 1995).
</bodyText>
<listItem confidence="0.665795666666667">
surface form gloss
a. tuhmasta ‘naughty’ (elative)
b. tihm¨ast¨a ‘stupid’ (elative)
</listItem>
<tableCaption confidence="0.993797">
Table 1: Finnish backness harmony
</tableCaption>
<bodyText confidence="0.9710805">
Crucially, the elative case marker alternates
systematically between front and back vowel
</bodyText>
<footnote confidence="0.919692">
2“Word” is used pre-theoretically here; harmony can oc-
cur over both supra- and sublexical domains.
</footnote>
<page confidence="0.525894">
1
</page>
<note confidence="0.968947">
Proceedings of the 11th Meeting of the ACL-SIGMORPHON, ACL 2010, pages 1–8,
Uppsala, Sweden, 15 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.969094">
variants—as -st¨a or -sta—depending on whether
the stem has front {¨u, ¨a} or back {u, a} vowels.
</bodyText>
<subsectionHeader confidence="0.901407">
2.1 Neutral vowels
</subsectionHeader>
<bodyText confidence="0.999833333333333">
In most languages with vowel harmony, there are
one or more vowels that systematically fail to
alternate. These are called neutral vowels, and
are typically further subclassified according to
whether or not they induce further harmonic al-
ternations in other vowels.
</bodyText>
<sectionHeader confidence="0.999761" genericHeader="method">
3 Instance-based models
</sectionHeader>
<bodyText confidence="0.999921896551724">
Instance-based approaches to cognitive process-
ing, also called memory-based, case-based, and
exemplar-based models, have their modern origins
in psychological theories and models of percep-
tual categorisation and episodic memory (Medin
and Schaffer, 1978; Nosofsky, 1986), although
the earliest explicit discussion seems to be (Se-
mon, 1921); a theory of memory that anticipates
many features of contemporary models. The core
features of these models are: (i) explicit stor-
age/memorisation (viz. extensional representa-
tion) of training data, (ii) classification/processing
of novel data via similarity-based computation,
and (iii) lazy evaluation (Aha, 1997), whereby
all computations are deferred until the model is
queried with data.3
Instance-based models were introduced to lin-
guistics via research in speech perception suggest-
ing that at least some aspects of linguistic perfor-
mance rely on remembered experiential episodes
(Johnson and Mullenix, 1997). The models imple-
mented to date in phonetics and phonology have
largely focused on perception (e.g. speaker nor-
malisation in Johnson (1997)), or on diachronic
processes (e.g. lenition in Pierrehumbert (2001),
chain shifts in Ettlinger (2007)), leaving the types
of phenomena that typically interest “traditional”
phonologists, viz. productive, generalised pat-
terns, comparatively neglected.4
</bodyText>
<sectionHeader confidence="0.997462" genericHeader="method">
4 LIBPHON
</sectionHeader>
<bodyText confidence="0.5564925">
LIBPHON, the Lazy Instance-based Phonologist,
is a lazy learning algorithm whose purpose (in the
</bodyText>
<footnote confidence="0.988962625">
3Compare eager learners, e.g. connectionist systems,
which build a global intensional representation of the func-
tion being learned on the basis of training data which are sub-
sequently discarded.
4Kirchner and Moore (2009) give a model of a syn-
chronic lenition process, and Daelemans and colleagues
give memory-based analyses of several linguistic phenomena
(Daelemans and van den Bosch, 2005).
</footnote>
<bodyText confidence="0.999552">
context of the simulations described here) is to
model an instance-based approach to the core as-
pects of the acquisition and subsequent productive
usage of vowel harmony.
</bodyText>
<subsectionHeader confidence="0.998014">
4.1 Decisions &amp; mechanisms
</subsectionHeader>
<bodyText confidence="0.999850948717949">
As discussed in (Johnson, 2007), there are some
decisions that need to be made in implementing an
instance-based model of phonological knowledge
involving the basic units of analysis (e.g. their
size), the relevant type of these units (e.g. discrete
or continuous), and the mechanisms for similarity-
matching and activation spread in the lexicon.
Units The arguments given by Johnson (2007)
and V¨alimaa-Blum (2009) for the “word-sized”
(rather than e.g. segmental) experience of lan-
guage, suggest that “words” are the correct basic
unit of analysis in instance-based langugage mod-
els (a fortiori in LIBPHON). Stronger evidence
comes from the wealth of psycholinguistic data
(reviewed in (Lodge, 2009)) showing that illiter-
ates and literates of non-alphabetic writing sys-
tems have poor phonemic (or at least segmental)
awareness, both in monitoring and manipulation.
On this basis, I take meaning-bearing unanalysed
acoustic chunks to be the relevant units of repre-
sentation for LIBPHON.5
Feature type Having determined the size of
LIBPHON’s basic unit, I move now to its em-
bedding space, where distinctive features present
themselves as obvious candidate dimensions.
Since the middle of the 20th century (ca. Chom-
sky and Halle (1968)), phonological theories have
nearly all supposed that lexical representations are
stored in terms of articulatory features (cf. (Halle,
1997) for explicit discussion of this viewpoint).
Coleman (1998), citing evidence from the neuro-
scientific and psycholinguistic literatures on lexi-
cal representation, claims that evidence for this po-
sition (e.g. from speech perception and phoneme
monitoring experiments) is weak at best, and that
lexical representations are more likely to be acous-
tic than articulatory. In addition, Phillips et al.
(2000) review neurolinguistic evidence for the role
of acoustic cortex in phonetics and phonology, and
</bodyText>
<footnote confidence="0.845351">
5The assumption that word-level segmentation of the
speech signal is available to the language learner prior to ac-
quisition of phonological phenomena is relatively uncontro-
versial, although there is evidence for the development of at
least some phonotactic knowledge prior to the emergence of
a productive lexicon (Jusczyk, 1999).
</footnote>
<page confidence="0.994757">
2
</page>
<bodyText confidence="0.999351941176471">
Mielke (2008) discusses several aspects of the in-
duction of distinctive phonological features from
acoustic representations. Recognising that the is-
sue is far from resolved, for the purposes of the
simulations run here, I take LIBPHON’s instance
space to be acoustically-based, and use formant
values as the embedding dimension. Vowels are
specified by their midpoint formant values,6 and
consonants are specified by so-called “locus” val-
ues, which can be identified by inspecting the tra-
jectories of consonant-vowel transitions in speech
(Sussman et al., 1998). Since I am modelling
palatal harmony in particular, and F2 magnitude is
the primary acoustic correlate of vowel palatality, I
omit F3 and F4, restricting LIBPHON’s acoustic
representations to sequences of (F 1, F2) values,
henceforth trajectories.
Similarity Given that LIBPHON’s instance-
space is continuous, and has a fairly intuitive
metric, I take simple Euclidean distance to be
LIBPHON’s similarity (or rather, dissimilarity)
function.7
Fixed-rate representations For the simulations
described here, I use fixed-rate trajectories, in
which consonants and vowels are represented
in a temporally coarse-grained manner with sin-
gle (F1, F2) tuples. Evidently, consonants and
vowels in actual human speech unfold in time,
but modelling segments at this level introduces
the problem of temporal variability; repeated to-
kens of a given word—both within and across
speakers—vary widely in duration. This variabil-
ity is one of the main obstacles in the develop-
ment of instance-based models of speech produc-
tion, due to the difficulty of aligning variable-
length forms. Although algorithms exist for align-
ing variable-length sequences, these require cog-
nitively implausible dynamic programming al-
gorithms, e.g. dynamic time warping (DTW)
6A reviewer asks about the psychological plausibility of
Hz-based formant represetations and the choice of point val-
ues for vowel and consonant representations, e.g. rather than
formant values at 20% and 80% of the vowel. These are
purely in the interests of simplicity for the work reported
here. As discussed below, future work with real speech ex-
emplars in psychophysically-motivated representational for-
mats, e.g. perceptual linear predictive coding (Hermansky,
1990), will render this issue moot.
7Often the measure of similarity in an instance-based
model is an exponential function of distance, d(xi, xj) of the
form exp(−cd(xi, xj)), so that increasing distance yields de-
creasing similarity (Nosofsky, 1986). The Euclidean measure
here is sufficient for the purpose at hand, although the shape
of the similarity measure is ultimately an empirical question.
and hidden Markov models (Rabiner and Juang,
1993). Even as proofs of concept, these may
be empirically inadequate; Kirchner and Moore
(2009) use DTW to good effect in an instance-
based production model of spirantisation using
real, temporally variable, speech signals. How-
ever, their inputs were all the same length in terms
of segmental content, and the model was only re-
quired to generalise within a word type. I am
currently investigating whether DTW can func-
tion as a proof of concept in a problem domain
like that addressed here, which involves learn-
ing about variably-sized “pieces” of morphology
across class labels.
</bodyText>
<subsectionHeader confidence="0.996585">
4.2 Perception/categorisation
</subsectionHeader>
<bodyText confidence="0.99199625">
LIBPHON’s method of perception/categorisation
of inputs is a relatively standard nearest-
neighbour-based classification algorithm. See Al-
gorithm 1 for a description in pseudocode.
</bodyText>
<construct confidence="0.9713938">
Algorithm 1 PERCEIVE(input, k)
Require: input as (LABEL ∈ [LEX](PL)[NOM |
ACC], instance ∈ Z2x{8,10,12}), k ∈ Z
if LABEL is not empty then
if LABEL ∈/ lexicon then
</construct>
<equation confidence="0.5963602">
Create LABEL in lexicon
end if
Associate(instance, LABEL)
else
neighbours ← k-nearest neighbours of
instance
LABEL ← majority class label of
neighbours
Associate(instance,LABEL)
end if
</equation>
<bodyText confidence="0.998465083333333">
If LABEL is not empty, LIBPHON checks its lex-
icon to see whether it knows the word being pre-
sented to it, i.e. whether it exists as a class label.
If so, it simply appends the input acoustic form to
the set of forms associated with the input mean-
ing/label. If it has no corresponding entry, a new
lexical entry is created for the input meaning, and
the input trajectory is added as its sole associated
acoustic form.
If LABEL is empty, LIBPHON assigns
instance to the majority class of its k
nearest neighbours in acoustic space.
</bodyText>
<page confidence="0.979543">
3
</page>
<subsectionHeader confidence="0.987622">
4.3 Production
</subsectionHeader>
<bodyText confidence="0.999970863636364">
In production, LIBPHON is provided with a LA-
BEL and has to generate a suitable instance for
it. LABELs are decomposable, signalling an ar-
bitrary “lexical” meaning, an optional plural mor-
pheme, PL, and an obligatory case marker from
{NOM, ACC}. Thus, there are several different
possibilities to consider in generating output for
some queried meaning.
In the two simplest cases, either the full queried
meaning (viz. lexical label with all inflections)
is already in the lexicon, or else there are no
class LABELs with the same lexical meaning (i.e.
LIBPHON is being asked to produce a word that it
doesn’t know). In the former case, a stored trajec-
tory is uniform8 randomly selected from the list of
acoustic forms associated with the queried label as
a seed token, the entire set of associated acoustic
forms is used as the analogical set, and an output
is generated by taking a distance-weighted mean
over the seed’s k nearest neighbours.9 In the case
where the lexical meaning of the queried LABEL
is unknown, the query is ignored.
In the more interesting cases, LIBPHON has a
LABEL in its lexicon with the same lexical mean-
ing, but with differing inflectional specification.
Consider the case in which LIBPHON knows only
the singular NOM form of a query label that is
specified as PL ACC. A seed instance is (uni-
form) randomly selected from the set of trajec-
tories associated to the NOM entry in the agent’s
lexicon, as this is the only entry with the corre-
sponding lexical meaning, and it is a variant of this
meaning that LIBPHON must produce. In this case
the analogical set, the set of instances from which
the final output is computed, is composed of the
seed’s nearest neighbours in the set of all trajec-
tories associated with LABELs of the form [LEX
PL ACC]. Once again, the output produced is a
distance-weighted mean of the analogical set.
This general procedure (viz. seed from a known
item with same lexical meaning, analogical set
from all items with desired inflection) is carried
out in parallel cases with all other possible LA-
BEL mismatches, e.g. a singular LABEL queried,
</bodyText>
<footnote confidence="0.596617625">
8Exemplar models often bias the selection of seed to-
kens with degrees of “activation” that take into account re-
cency and frequency. Although the results discussed below
show that this is not necessary for ultimate attainment, it is
likely that this kind of bias will need to be incorporated into
LIBPHON to accurately model more nuanced aspects of the
acquisition path.
9k = 5 for all results reported here.
</footnote>
<bodyText confidence="0.999092571428571">
but only a plural LABEL in the lexicon, a NOM
query with only an ACC form in the lexicon, etc.
In the cases where the lexicon contains multiple
entries with the same lexical meaning, but not the
query, the seed is selected from the LABEL with
the closest “semantic” match. Algorithm 2 gives
pseudocode for LIBPHON’s production algorithm.
</bodyText>
<figure confidence="0.960883">
Algorithm 2 PRODUCE(LABEL, k)
Require: LABELE [LEX](PL)[NOM I ACC], k EZ
if LABEL E lexicon then
seed +— uniform random selection from
instances associated to LABEL
cloud +— all instances associatedto LA-
BEL
else if I LABEL&apos; E lexicon s.t. lex(LABEL&apos;) =
lex(LABEL) then
seed +— uniform random selection from
instances associated to LABEL&apos;)
cloud +— all instances associated to
plural(LABEL) U case(LABEL)
else
pass
end if
neighbours +— k-nearest neighbours of seed in
cloud
</figure>
<figureCaption confidence="0.341357">
return distance-weighted mean of neighbours
</figureCaption>
<subsectionHeader confidence="0.990598">
4.4 Production as regression
</subsectionHeader>
<bodyText confidence="0.986064375">
The final steps in LIBPHON’s production algo-
rithm, finding the analogical set and computing the
output as a weighted average, together constitute
a technique known in the statistical learning lit-
erature as kernel-smoothed nearest-neighbour re-
gression, and in particular are closely related to the
well-known Nadaraya-Watson estimator (Hastie et
al., 2009):
</bodyText>
<equation confidence="0.984288">
�N i=1 Kλ(x, xi)yi
ˆf(x) = �N i=1
Kλ(x, xi)
</equation>
<bodyText confidence="0.99993475">
with inverse-distance as the kernel smoother, K,
and the bandwidth function, hλ(x) determined by
the number k of nearest neighbours. This link to
the statistical learning literature puts LIBPHON on
sound theoretical footing and opens the door to a
variety of future research paths, e.g. experiment-
ing with different kernel shapes, or formal analysis
of LIBPHON’s expected error bounds.
</bodyText>
<page confidence="0.998464">
4
</page>
<sectionHeader confidence="0.992755" genericHeader="method">
5 The languages
</sectionHeader>
<bodyText confidence="0.999940266666667">
On the view taken here, phonological knowledge
is taken to emerge from generalisation over lexical
items, and so the key to acquiring some phono-
logical pattern lies in learning a lexicon (Jusczyk,
2000). Consequently, the languages learned in
LIBPHON abstract away from sentence-level phe-
nomena, and the training data are simply labelled
formant trajectories, (LABEL, instance).
In order to get at the essence of the problem (viz.
the acquisition of vowel harmony as characterised
by morphophonological alternations), and in the
interests of computational tractability/efficiency,
the artificial languages learned by LIBPHON are
highly simplified, displaying only enough struc-
ture to capture the phenomena of interest.
</bodyText>
<figure confidence="0.99659345">
3000
2500
2000
1500
1000
500
00 2 4 6 8 10 12
GIDEGEBI NOM gidegebi
F1
F2
3000
2500
2000
1500
1000
500
00 2 4 6 8 10 12
GIDEGEBI ACC gidegebibe
F1
F2
</figure>
<figureCaption confidence="0.991823">
Figure 1: Graphical representation of singular
forms of GIDEGEBI, as produced by teacher agent
</figureCaption>
<subsectionHeader confidence="0.979202">
5.1 Phonological inventory
</subsectionHeader>
<bodyText confidence="0.999976428571429">
The phonological inventory consists of three con-
sonants, {b, d, 9}, and four vowels—two with high
F2 and two with low F2—which I label {i, e, u,
o}, for convenience.10 The formant values used
were generated from formant synthesis equations
in (de Boer, 2000), and from the locus equations
for CV-transitions in (Sussman et al., 1998).
</bodyText>
<subsectionHeader confidence="0.998509">
5.2 Lexical items
</subsectionHeader>
<bodyText confidence="0.946677303030303">
LIBPHON’s lexicon is populated with instance
trajectories consisting of four-syllable11 “roots”
with zero, one or two one-syllable “affixes”. These
trajectories have associated class labels, which
from a formal point of view are contentless in-
dices. Rather than employing e.g. natural num-
bers as labels, I use character strings which corre-
spond more or less to the English pronounciations
of their associated trajectories. LABELs func-
tion, metaphorically-speaking, as “meanings”.
These are compositional, comprising a “lexical
meaning” (arbitrary CVCVCVCV string from the
phoneme set listed above), one of two obligato-
rily present “case markers” (NOM|ACC), and an
optionally present “plural marker” (PL). Hence,
word categories in the artificial languages come in
four forms, NOM-SG, NOM-PL, ACC-SG, and ACC-
PL.
10Because LIBPHON’s representations lack F3, the pri-
mary acoustic correlate of rounding, the back vowels would
be more standardly represented as /s, m/, but these are com-
paratively uncommon IPA symbols, so we will use the sym-
bols for the rounded variants. Nothing in the results or dis-
cussion hinges on this.
11All syllables are CV-shaped.
Figure 1 gives examples of the singular NOM
and ACC forms of a high-F2 word. The NOM-
labelled trajectory has no suffixal morphology, and
corresponds to a bare form. The trajectory is eight
segments long,12 and the vowels in this case have
all high F2 (as in lexical front/back vowel har-
mony).13 Note also that ACC is realised with high
F2, in agreement with the root vowels.
</bodyText>
<subsectionHeader confidence="0.986998">
5.3 Neutral vowels
</subsectionHeader>
<bodyText confidence="0.999916823529412">
The harmony processes seen thus far are in some
sense “local”, being describable in terms of vowel
adjacency e.g. adjacency on a hypothesised au-
tosegmental tier (although the presence of inter-
vening consonants still renders the harmony pro-
cess “nonlocal” in some more concrete articula-
tory sense). One of the hallmarks of vowel har-
mony, as discussed in subsection 2.1, is the phe-
nomenon of neutral vowels. These vowels fail to
alternate, and may or may not induce harmonic al-
ternations in vowels that precede or follow them.
To introduce a neutral vowel, I added a category
label, PL, whose realisation corresponds roughly
to [9u], and which is treated as being either opaque
or transparent in the simulations described below.
Figures 2 and 3 show the “plural inflected”
forms of the same root as in 1. We see that the
</bodyText>
<footnote confidence="0.996061875">
12The even-numbered indices on the x-axis correspond to
consonants and the odd-numbered indices, the “pinches” in
the graphs, correspond to vowels.
13The languages LIBPHON learns have only harmonic
singular forms. This is unrealistic, as speakers of vowel
harmony languages typically have some exceptional dishar-
monic forms in their lexicons. The effect of these forms on
LIBPHON’s performance is currently being investigated.
</footnote>
<page confidence="0.995401">
5
</page>
<bodyText confidence="0.978451">
realisation of PL has fixed, low F2, and that the
realisation of ACC has alternating F2, which real-
isations corresponding roughly to [be] (high F2)
and [bo] (low F2).
Figure 2: Graphical representation of plural forms
of GIDEGEBI, as produced by teacher agent, with
opaque PL realisation.
gorisation of inputs is a poor indicator of the ex-
tent to which it has learned a productive “rule” of
vowel harmony. In lieu of this measure, I have
opted to pursue two difference courses of evalua-
tion.
For the harmony cases, LIBPHON is queried on
a held-out test set of 500 previously unseen LA-
BELs and its output is compared to the mean value
of the teacher’s stored trajectories for the same LA-
BELs. In particular, given some LABEL which was
not in the training data, we can query LIBPHON
at various stages of acquisition (viz. with lexicons
of increasing size) by having it produce an output
for that LABEL, and track the change in its perfor-
mance over time.
The actual measure of error taken is the root-
mean-squared deviation between the learner’s out-
put, y and the mean, t, of the teacher’s stored
forms for some label, l, over all of the consonants
and vowels within a word, averaged across the re-
maining unseen items of the test set:
</bodyText>
<figure confidence="0.996433541666666">
RMSE = ��
1 � i(ti − yi)2
l
N l∈lex len( t)
3000
F1
F2
GIDEGEBI NOM gidegebigu
2500
2000
1500
1000
500
00 2 4 6 8 10 12
3000
F1
F2
GIDEGEBI ACC gidegebigube
2500
2000
1500
1000
500
00 2 4 6 8 10 12
</figure>
<figureCaption confidence="0.934083">
Figure 3: Graphical representation of plural forms
of GIDEGEBI, as produced by teacher agent, with
transparent PL realisation.
</figureCaption>
<bodyText confidence="0.999887166666667">
These figures also illustrate the difference be-
tween languages with opaque versus transparent
PL, as reflected in the realisation of the word-final
ACC marker in the two lower graphs, which agrees
in F2 with the realised form of the PL or root, re-
spectively.
</bodyText>
<sectionHeader confidence="0.978989" genericHeader="method">
6 The experiments
</sectionHeader>
<bodyText confidence="0.999180857142857">
Assessing successful learning/generalisation in a
computational model requires some measurable
outcome that can be tracked over time. Because
LIBPHON is an output-oriented model, its cate-
Figures 4 and 5 show RMSE vs. lexicon size
for both opaque and transparent neutrality (cf. the
cases in Figures 2 and 3), for five simulation runs
each. We can see clearly that error drops as the
lexicon grows, hence that LIBPHON is learning to
make its outputs more like those of the teacher,
but the informativity of this measure stops there.
From a linguistic point of view, we are interested
in what LIBPHON’s outputs look like, viz. has it
learned vowel harmony?
</bodyText>
<figureCaption confidence="0.853901">
Figure 4: RMSE 1000-word lexicon. Opaque neu-
trality.
</figureCaption>
<page confidence="0.972323">
6
</page>
<figureCaption confidence="0.977102">
Figure 5: RMSE 1000-word lexicon. Transparent
neutrality.
</figureCaption>
<bodyText confidence="0.990213434782609">
Figures 6 and 7 show that vowel harmony is
learned, and moreover quite quickly, after going
through a brief initial phase of spurious outputs. In
these figures, LIBPHON is being asked to produce
outputs for all forms of the label GUBOGOBU. For
the particular run shown here, at the 10-word stage
(i.e. when LIBPHON had seen tokens from 10 la-
bels), the only tokens marked PL-ACC were from
high F2 (“front”) trajectories. Hence the nearest
neighbour calculation in the production algorithm
resulted in a fronted form being output. Although
acquisition research in vowel harmony languages
is relatively rare, or inaccessible to us due to lan-
guage barriers, what research there is seems to in-
dicate that harmony is mastered very quickly, with
virtually no errors by 2 years of age, hence it is un-
clear what status to assign to output patterns like
the one discussed here. Moreover, given the well-
known facts that (i) comprehension precedes pro-
duction, and (ii) infants avoid saying unfamiliar
words, it is unlikely that an infant could be coaxed
into producing an output form for such an early-
stage class.
</bodyText>
<sectionHeader confidence="0.989119" genericHeader="discussions">
7 Discussion and future work
</sectionHeader>
<bodyText confidence="0.994060363636364">
The experiments discussed here show that on the
basis of limited input data, LIBPHON, an instance-
based learner that produces output via kernel-
smoothed nearest-neighbour regression, learns to
produce harmonically correct novel outputs. In
particular, it is able to generalise and produce cor-
rect morphologically complex forms to which it
has not been exposed in its training data, i.e. a
previously unseen case-marked form will be out-
put with harmonically correct F2, including neu-
trality (opaque or transparent). In ongoing re-
</bodyText>
<figureCaption confidence="0.99274025">
Figure 6: Evolution of gubogobu in early acqui-
sition: 10 words
Figure 7: Evolution of gubogobu in early acqui-
sition: 30 words
</figureCaption>
<bodyText confidence="0.9812535">
search I am (i) evaluating LIBPHON’s perfor-
mance with respect to more traditional measures,
in particular F-score, on held-out data as the lexi-
con grows, and (ii) assessing the viability of DTW-
based alignment for preprocessing real speech to-
kens as inputs to LIBPHON.
</bodyText>
<sectionHeader confidence="0.997488" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999736714285714">
Many thanks to Ash Asudeh, Lev Blumenfeld,
Andrea Gormley, Jeff Mielke, Alan Hogue and
Andy Wedel for discussion and comments on this
line of research, and to three anonymous referees
for feedback that greatly improved this paper. This
work carried out with the support of NSERC Dis-
covery Grant 371969 to Dr. Ash Asudeh.
</bodyText>
<sectionHeader confidence="0.987611" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.5440135">
David Aha. 1997. Lazy learning. In Lazy Learning,
pages 7–10. Kluwer Academic Publishers.
</reference>
<figure confidence="0.996926923076923">
800
Learner 0
Learner 1
Learner 2
Learner 3
Learner 4
RMSE per word
500
400
3000 10 20 30 40 50 60 70 80 90 100 110 120
Lexicon size/10
1000
900
700
600
2500
2000
NOM
ACC
PL NOM
PL ACC
1500
1000
500
0 2 4 6 8 10 12
0
</figure>
<page confidence="0.996391">
7
</page>
<note confidence="0.838811">
Peter Jusczyk. 1999. How infants begin to extract
words from speech. Trends in Cognitive Sciences,
3(9):323–328.
Noam Chomsky and Morris Halle. 1968. The Sound
Pattern of English. Harper and Row.
</note>
<reference confidence="0.999900625">
John Coleman. 1998. Cognitive reality and the phono-
logical lexicon: A review. Journal of Neurolinguis-
tics, 11(3):295—-320.
Thomas Cover and Peter Hart. 1967. Nearest neighbor
pattern classification. IEEE Transactions on Infor-
mation Theory, 13:21–27.
Walter Daelemans and Antal van den Bosch. 2005.
Memory-Based Language Processing. Studies in
Natural Language Processing. Cambridge Univer-
sity Press.
Walter Daelemans, Steven Gillis, and Gert Durieux.
1994. The acquisition of stress: A data-oriented ap-
proach. Computational Linguistics, 20(3).
Bart de Boer. 2000. Self-organization in vowel sys-
tems. Journal of Phonetics, 28:441–465.
B. Elan Dresher. 1999. Charing the learning path:
Cues to parameter setting. Linguistic Inquiry,
30(1):27–67.
Marc Ettlinger. 2007. An exemplar-based model of
chain shifts. In Proceedings of the 16th Interna-
tional Congress of the Phonetic Science, pages 685–
688.
Evelyn Fix and J.L. Hodges. 1951. Discrimina-
tory analysis, nonparametric discrimination: Con-
sistency properties. Technical Report 4, USAF
School of Aviation Medicine.
Stephen Goldinger. 1996. Words and voices: Episodic
traces in spoken word identification and recogni-
tion memory. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 22:1166–1183.
Morris Halle. 1997. Some consequences of the repre-
sentation of words in memory. Lingua, 100:91–100.
Trevor Hastie, Robert Tibshirani, and Jerome Fried-
man. 2009. Elements of Statistical Learning.
Springer Series in Statistics. Springer-Verlag, 2 edi-
tion.
Hynek Hermansky. 1990. Perceptual linear predictive
(plp) analysis of speech. Journal of the Acoustical
Society ofAmerica, 87(4):1738–1752.
Keith Johnson and John W. Mullenix, editors. 1997.
Talker Variability in Speech Processing. Academic
Press.
Keith Johnson. 1997. Speech perception without
speaker normalization: an exemplar model. In
Talker Variability in Speech Processing, chapter 8,
pages 145–166. Academic Press.
Keith Johnson, 2007. Decision and Mechanisms in
Exemplar-based Phonology, chapter 3, pages 25–40.
Oxford University Press.
Peter Jusczyk. 2000. The Discovery of Spoken Lan-
guage. MIT Press.
Robert Kirchner and Roger Moore. 2009. Computing
phonological generalization over real speech exem-
plars. ms.
Ken Lodge. 2009. Fundamental Concepts in Phonol-
ogy: Sameness and difference. Edinburgh Univer-
sity Press.
Douglas Medin and Marguerite Schaffer. 1978. Con-
text theory of classification learning. Psychological
Review, 85(3):207–238.
Jeff Mielke. 2008. The Emergence of Distinctive Fea-
tures. Oxford Studies in Typology and Linguistic
Theory. Oxford University Press.
Robert Nosofsky. 1986. Attention, similarity, and the
identification-categorization relationship. Journal
of Experimental Psychology: General, 115(1):39–
57.
Colin Phillips, Thomas Pellathy, Alec Marantz, El-
ron Yellin, Kenneth Wexler, David Poeppel, Martha
McGinnis, and Timothy Roberts. 2000. Auditory
cortex accesses phonological categories: An meg
mismatch study. Journal of Cognitive Neuroscience,
12(6):1038–1055.
Janet Pierrehumbert. 2001. Exemplar dynamics: Word
frequency, lenition, and contrast. In Frequency ef-
fects and the emergence of linguistic structure, pages
137–157. John Benjamins.
Alan Prince and Paul Smolensky. 2004. Optimality
Theory: Constraint interaction in generative gram-
mar. Blackwell.
Lawrence Rabiner and Biing-Hwang Juang. 1993.
Fundamentals of Speech Recognition. Prentice Hall.
Richard Semon. 1921. The Mneme. George Allen and
Unwin.
Harvey Sussman, David Fruchter, Jon Hilbert, and
Joseph Sirosh. 1998. Linear correlates in the speech
signal: The orderly output constraint. Behavioral
and Brain Sciences, 21:241–299.
Bruce Tesar and Paul Smolensky. 2000. Learnability
in Optimality Theory. MIT Press.
Riitta V¨alimaa-Blum. 2009. The phoneme in cognitive
phonology: episodic memories of both meaningful
and meaningless units? Cognitextes, 2.
Harry van der Hulst and Jeroen van de Weijer. 1995.
Vowel harmony. In John Goldsmith, editor, Hand-
book of Phonological Theory. Blackwell.
</reference>
<page confidence="0.998496">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.979853">Instance-based acquisition of vowel harmony</title>
<author confidence="0.983358">Fr´ed´eric</author>
<affiliation confidence="0.955654">Institute of Cognitive Carleton</affiliation>
<address confidence="0.827244">Ottawa, ON,</address>
<email confidence="0.997954">fmailhot@connect.carleton.ca</email>
<abstract confidence="0.999665089005236">present a nonparametric regression-based model of phonological acquisition that induces a generalised and productive pattern of vowel harmony—including opaque and transparent neutrality—on the basis of simplified formant data. The model quickly learns to generate harmonically correct morphologically complex forms to which it has not been exposed. 1 Explaining phonological patterns How do infants learn the phonetic categories and phonotactic patterns of their native languages? How strong are the biases that learners bring to the task of phonological acquistion? Phonologists from the rationalist tradition that dominated the past half-century of linguistic research typically posit strong biases in acquisition, with language learners using innatelygiven, domain-specific representations (Chomsky and Halle, 1968), constraints (Prince and Smolensky, 2004) and learning algorithms (Tesar and Smolensky, 2000; Dresher, 1999) to learn abstract rules or constraint rankings from which they can classify or produce novel instances. In the last decade, however, there has been a shift toward empiricist approaches to phonological acquisition, use and knowledge. In this literalgorithms (Aha, 1997), in which training data are used to update intensional representations of functions or categories then dishave been the However, research in related fields—particularly speech perception— indicates that speakers’ knowledge and use of language, both in production and comprehension, is at least partly episodic, or instance-based (Goldinger, 1996; Johnson, 1997). Additionally, et al. (1994) is a notable exception. motivation for instance-based models of categorisation has a lengthy history in cognitive psychology (Medin and Schaffer, 1978), and these methods are well-known in the statistical and machine learning literature, having been studied for over half a century (Fix and Hodges, 1951; Cover and Hart, 1967; Hastie et al., 2009). Consequently, it seems a worthy endeavour applying an instancebased method to a problem that is of interest to traditional phonologists, the acquisition and use of vowel harmony, while simultaneously effecting adjacent disicplines in the cognitive sciences. In sections 2 and 3 I give some brief background on vowel harmony and instancebased models, respectively. Section 4 introduces model, and section 5 the languages it learns. I discuss some simulations and results in section 6, and conclude in section 7. 2 Vowel harmony Vowel harmony is a phonological phenomenon in which there are co-occurrence constraints on vowwithin The vowels in a language with vowel harmony can be classified into disjoint sets, such that words contain vowels from only one of the sets. The Finnish system of vowel harmony exemplified by the forms in Table 1 provides a standard example from the literature (van der Hulst and van de Weijer, 1995). surface form gloss a. tuhmasta ‘naughty’ (elative) b. tihm¨ast¨a ‘stupid’ (elative) Table 1: Finnish backness harmony Crucially, the elative case marker alternates systematically between front and back vowel is used pre-theoretically here; harmony can occur over both supraand sublexical domains. 1 of the 11th Meeting of the ACL-SIGMORPHON, ACL pages Sweden, 15 July 2010. Association for Computational Linguistics on whether stem has front back 2.1 Neutral vowels In most languages with vowel harmony, there are one or more vowels that systematically fail to These are called and are typically further subclassified according to whether or not they induce further harmonic alternations in other vowels. 3 Instance-based models Instance-based approaches to cognitive processing, also called memory-based, case-based, and exemplar-based models, have their modern origins in psychological theories and models of perceptual categorisation and episodic memory (Medin and Schaffer, 1978; Nosofsky, 1986), although the earliest explicit discussion seems to be (Semon, 1921); a theory of memory that anticipates many features of contemporary models. The core features of these models are: (i) explicit storrepresentation) of training data, (ii) classification/processing of novel data via similarity-based computation, (iii) evaluation 1997), whereby all computations are deferred until the model is with Instance-based models were introduced to linguistics via research in speech perception suggesting that at least some aspects of linguistic performance rely on remembered experiential episodes (Johnson and Mullenix, 1997). The models implemented to date in phonetics and phonology have focused on perception normalisation in Johnson (1997)), or on diachronic in Pierrehumbert (2001), chain shifts in Ettlinger (2007)), leaving the types of phenomena that typically interest “traditional” generalised patcomparatively the is a lazy learning algorithm whose purpose (in the systems, which build a global intensional representation of the function being learned on the basis of training data which are subsequently discarded. and Moore (2009) give a model of a synchronic lenition process, and Daelemans and colleagues give memory-based analyses of several linguistic phenomena (Daelemans and van den Bosch, 2005). context of the simulations described here) is to model an instance-based approach to the core aspects of the acquisition and subsequent productive usage of vowel harmony. 4.1 Decisions &amp; mechanisms As discussed in (Johnson, 2007), there are some decisions that need to be made in implementing an instance-based model of phonological knowledge the basic units of analysis the relevant type of these units or continuous), and the mechanisms for similaritymatching and activation spread in the lexicon. arguments given by Johnson (2007) and V¨alimaa-Blum (2009) for the “word-sized” than experience of language, suggest that “words” are the correct basic unit of analysis in instance-based langugage modfortiori Stronger evidence comes from the wealth of psycholinguistic data (reviewed in (Lodge, 2009)) showing that illiterates and literates of non-alphabetic writing systems have poor phonemic (or at least segmental) awareness, both in monitoring and manipulation. this basis, I take unanalysed chunks be the relevant units of reprefor type determined the size of basic unit, I move now to its embedding space, where distinctive features present themselves as obvious candidate dimensions. the middle of the century Chomsky and Halle (1968)), phonological theories have nearly all supposed that lexical representations are in terms of articulatory features 1997) for explicit discussion of this viewpoint). Coleman (1998), citing evidence from the neuroscientific and psycholinguistic literatures on lexical representation, claims that evidence for this pospeech perception and phoneme monitoring experiments) is weak at best, and that lexical representations are more likely to be acoustic than articulatory. In addition, Phillips et al. (2000) review neurolinguistic evidence for the role of acoustic cortex in phonetics and phonology, and assumption that word-level segmentation of the speech signal is available to the language learner prior to acquisition of phonological phenomena is relatively uncontroversial, although there is evidence for the development of at least some phonotactic knowledge prior to the emergence of a productive lexicon (Jusczyk, 1999). 2 Mielke (2008) discusses several aspects of the induction of distinctive phonological features from acoustic representations. Recognising that the issue is far from resolved, for the purposes of the run here, I take instance space to be acoustically-based, and use formant values as the embedding dimension. Vowels are by their midpoint formant and consonants are specified by so-called “locus” values, which can be identified by inspecting the trajectories of consonant-vowel transitions in speech (Sussman et al., 1998). Since I am modelling harmony in particular, and is the primary acoustic correlate of vowel palatality, I restricting acoustic to sequences of 1, F2) that instancespace is continuous, and has a fairly intuitive metric, I take simple Euclidean distance to be similarity (or rather, dissimilarity) representations the simulations described here, I use fixed-rate trajectories, in which consonants and vowels are represented in a temporally coarse-grained manner with sin- F2) Evidently, consonants and vowels in actual human speech unfold in time, but modelling segments at this level introduces the problem of temporal variability; repeated tokens of a given word—both within and across speakers—vary widely in duration. This variability is one of the main obstacles in the development of instance-based models of speech production, due to the difficulty of aligning variablelength forms. Although algorithms exist for aligning variable-length sequences, these require cognitively implausible dynamic programming altime warping (DTW) reviewer asks about the psychological plausibility of formant represetations and the choice of point valfor vowel and consonant representations, than values at the vowel. These are purely in the interests of simplicity for the work reported here. As discussed below, future work with real speech exemplars in psychophysically-motivated representational forlinear predictive coding (Hermansky, 1990), will render this issue moot. the measure of similarity in an instance-based is an exponential function of distance, the that increasing distance yields decreasing similarity (Nosofsky, 1986). The Euclidean measure here is sufficient for the purpose at hand, although the shape of the similarity measure is ultimately an empirical question. and hidden Markov models (Rabiner and Juang, 1993). Even as proofs of concept, these may be empirically inadequate; Kirchner and Moore (2009) use DTW to good effect in an instancebased production model of spirantisation using real, temporally variable, speech signals. However, their inputs were all the same length in terms of segmental content, and the model was only required to generalise within a word type. I am currently investigating whether DTW can function as a proof of concept in a problem domain like that addressed here, which involves learning about variably-sized “pieces” of morphology across class labels. 4.2 Perception/categorisation method of perception/categorisation of inputs is a relatively standard nearestneighbour-based classification algorithm. See Algorithm 1 for a description in pseudocode. 1 not empty lexicon end if else neighbours of instance class label of neighbours end if not empty, its lexicon to see whether it knows the word being preto it, it exists as a class label. If so, it simply appends the input acoustic form to the set of forms associated with the input meaning/label. If it has no corresponding entry, a new lexical entry is created for the input meaning, and the input trajectory is added as its sole associated acoustic form. empty, the majority class of its nearest neighbours in acoustic space. 3 4.3 Production production, provided with a has to generate a suitable are decomposable, signalling an arbitrary “lexical” meaning, an optional plural morand an obligatory case marker from Thus, there are several different possibilities to consider in generating output for some queried meaning. In the two simplest cases, either the full queried label with all inflections) is already in the lexicon, or else there are no with the same lexical meaning being asked to produce a word that it doesn’t know). In the former case, a stored trajecis selected from the list of acoustic forms associated with the queried label as a seed token, the entire set of associated acoustic forms is used as the analogical set, and an output is generated by taking a distance-weighted mean the seed’s the case the lexical meaning of the queried is unknown, the query is ignored. the more interesting cases, a its lexicon with the same lexical meaning, but with differing inflectional specification. the case in which only singular of a query label that is as A seed (uniform) randomly selected from the set of trajecassociated to the in the agent’s lexicon, as this is the only entry with the corresponding lexical meaning, and it is a variant of this that produce. In this case the analogical set, the set of instances from which the final output is computed, is composed of the seed’s nearest neighbours in the set of all trajecassociated with of the form Once again, the output produced is a distance-weighted mean of the analogical set. general procedure from a known item with same lexical meaning, analogical set from all items with desired inflection) is carried in parallel cases with all other possible singular models often bias the selection of seed tokens with degrees of “activation” that take into account recency and frequency. Although the results discussed below show that this is not necessary for ultimate attainment, it is likely that this kind of bias will need to be incorporated into accurately model more nuanced aspects of the acquisition path. = 5 all results reported here. only a plural the lexicon, a with only an in the lexicon, In the cases where the lexicon contains multiple entries with the same lexical meaning, but not the the seed is selected from the the closest “semantic” match. Algorithm 2 gives for production algorithm. 2 random selection from associated to associatedto BEL if s.t. = random selection from associated to associated to else pass end if neighbours of seed in cloud mean of neighbours 4.4 Production as regression final steps in production algorithm, finding the analogical set and computing the output as a weighted average, together constitute a technique known in the statistical learning litas nearest-neighbour reand in particular are closely related to the well-known Nadaraya-Watson estimator (Hastie et al., 2009): = inverse-distance as the kernel smoother, the bandwidth function, by number nearest neighbours. This link to statistical learning literature puts sound theoretical footing and opens the door to a of future research paths, experimenting with different kernel shapes, or formal analysis expected error bounds. 4 5 The languages On the view taken here, phonological knowledge is taken to emerge from generalisation over lexical items, and so the key to acquiring some phonological pattern lies in learning a lexicon (Jusczyk, 2000). Consequently, the languages learned in away from sentence-level phenomena, and the training data are simply labelled trajectories, order to get at the essence of the problem the acquisition of vowel harmony as characterised by morphophonological alternations), and in the interests of computational tractability/efficiency, artificial languages learned by highly simplified, displaying only enough structure to capture the phenomena of interest.</abstract>
<address confidence="0.924272833333333">3000 2500 2000 1500 1000 500</address>
<phone confidence="0.791896">00 2 4 6 8 10 12</phone>
<affiliation confidence="0.40166">NOM</affiliation>
<address confidence="0.843854875">F1 F2 3000 2500 2000 1500 1000 500</address>
<phone confidence="0.807199">00 2 4 6 8 10 12</phone>
<abstract confidence="0.967274632075471">ACC F1 F2 Figure 1: Graphical representation of singular of as produced by teacher agent 5.1 Phonological inventory The phonological inventory consists of three cond, and four vowels—two with high two with low I label e, u, for The formant values used were generated from formant synthesis equations in (de Boer, 2000), and from the locus equations for CV-transitions in (Sussman et al., 1998). 5.2 Lexical items lexicon is populated with consisting of “roots” with zero, one or two one-syllable “affixes”. These trajectories have associated class labels, which from a formal point of view are contentless in- Rather than employing numbers as labels, I use character strings which correspond more or less to the English pronounciations their associated trajectories. function, metaphorically-speaking, as “meanings”. These are compositional, comprising a “lexical (arbitrary from the phoneme set listed above), one of two obligatopresent “case markers” and an present “plural marker” Hence, word categories in the artificial languages come in forms, and representations lack the primary acoustic correlate of rounding, the back vowels would more standardly represented as m/, these are comparatively uncommon IPA symbols, so we will use the symbols for the rounded variants. Nothing in the results or discussion hinges on this. syllables are CV-shaped. 1 gives examples of the singular of a The labelled trajectory has no suffixal morphology, and corresponds to a bare form. The trajectory is eight and the vowels in this case have high in lexical front/back vowel har- Note also that realised with high in agreement with the root vowels. 5.3 Neutral vowels The harmony processes seen thus far are in some sense “local”, being describable in terms of vowel on a hypothesised autosegmental tier (although the presence of intervening consonants still renders the harmony process “nonlocal” in some more concrete articulatory sense). One of the hallmarks of vowel harmony, as discussed in subsection 2.1, is the pheof These vowels fail to alternate, and may or may not induce harmonic alternations in vowels that precede or follow them. To introduce a neutral vowel, I added a category whose realisation corresponds roughly to [9u], and which is treated as being either opaque or transparent in the simulations described below. Figures 2 and 3 show the “plural inflected” forms of the same root as in 1. We see that the even-numbered indices on the correspond to consonants and the odd-numbered indices, the “pinches” in the graphs, correspond to vowels. languages have only harmonic singular forms. This is unrealistic, as speakers of vowel harmony languages typically have some exceptional disharmonic forms in their lexicons. The effect of these forms on performance is currently being investigated. 5 of fixed, low and that the of alternating which realcorresponding roughly to Figure 2: Graphical representation of plural forms as produced by teacher agent, with gorisation of inputs is a poor indicator of the extent to which it has learned a productive “rule” of vowel harmony. In lieu of this measure, I have opted to pursue two difference courses of evaluation. the harmony cases, queried on held-out test set of 500 previously unseen and its output is compared to the mean value the teacher’s stored trajectories for the same In particular, given some was in the training data, we can query various stages of acquisition lexicons of increasing size) by having it produce an output that and track the change in its performance over time. The actual measure of error taken is the rootmean-squared deviation between the learner’s outthe mean, of the teacher’s stored for some label, over all of the consonants and vowels within a word, averaged across the remaining unseen items of the test set: �� 1� l 3000 F1 F2 NOM</abstract>
<address confidence="0.757830625">2500 2000 1500 1000 500 00 2 4 6 8 10 12 3000 F1</address>
<email confidence="0.227669">F2</email>
<affiliation confidence="0.649274">ACC</affiliation>
<address confidence="0.9107052">2500 2000 1500 1000 500</address>
<phone confidence="0.797481">00 2 4 6 8 10 12</phone>
<abstract confidence="0.997337178082192">Figure 3: Graphical representation of plural forms as produced by teacher agent, with These figures also illustrate the difference between languages with opaque versus transparent as reflected in the realisation of the word-final in the two lower graphs, which agrees the realised form of the root, respectively. 6 The experiments Assessing successful learning/generalisation in a computational model requires some measurable outcome that can be tracked over time. Because an output-oriented model, its cate- 4 and 5 show RMSE size both opaque and transparent neutrality cases in Figures 2 and 3), for five simulation runs each. We can see clearly that error drops as the grows, hence that learning to make its outputs more like those of the teacher, but the informativity of this measure stops there. From a linguistic point of view, we are interested what outputs look like, it learned vowel harmony? Figure 4: RMSE 1000-word lexicon. Opaque neutrality. 6 Figure 5: RMSE 1000-word lexicon. Transparent neutrality. 6 and 7 show that vowel harmony learned, and moreover quite quickly, after going through a brief initial phase of spurious outputs. In figures, being asked to produce for all forms of the label For the particular run shown here, at the 10-word stage seen tokens from 10 lathe only tokens marked from trajectories. Hence the nearest neighbour calculation in the production algorithm resulted in a fronted form being output. Although acquisition research in vowel harmony languages is relatively rare, or inaccessible to us due to language barriers, what research there is seems to indicate that harmony is mastered very quickly, with virtually no errors by 2 years of age, hence it is unclear what status to assign to output patterns like the one discussed here. Moreover, given the wellknown facts that (i) comprehension precedes production, and (ii) infants avoid saying unfamiliar words, it is unlikely that an infant could be coaxed into producing an output form for such an earlystage class. 7 Discussion and future work The experiments discussed here show that on the of limited input data, an instancebased learner that produces output via kernelsmoothed nearest-neighbour regression, learns to produce harmonically correct novel outputs. In particular, it is able to generalise and produce correct morphologically complex forms to which it not been exposed in its training data, previously unseen case-marked form will be outwith harmonically correct including neu- (opaque or transparent). In ongoing re- 6: Evolution of early acquisition: 10 words 7: Evolution of early acquisition: 30 words I am (i) evaluating performance with respect to more traditional measures, particular on held-out data as the lexicon grows, and (ii) assessing the viability of DTWbased alignment for preprocessing real speech toas inputs to</abstract>
<title confidence="0.374735">Acknowledgments</title>
<author confidence="0.783164">Many thanks to Ash Asudeh</author>
<author confidence="0.783164">Lev Blumenfeld</author>
<author confidence="0.783164">Andrea Gormley</author>
<author confidence="0.783164">Jeff Mielke</author>
<author confidence="0.783164">Alan Hogue</author>
<abstract confidence="0.8510196">Andy Wedel for discussion and comments on this line of research, and to three anonymous referees for feedback that greatly improved this paper. This work carried out with the support of NSERC Discovery Grant 371969 to Dr. Ash Asudeh.</abstract>
<note confidence="0.7451335">References Aha. 1997. Lazy learning. In pages 7–10. Kluwer Academic Publishers. 800 Learner 0 Learner 1 Learner 2 Learner 3 Learner 4 RMSE per word 500 400</note>
<phone confidence="0.528361">3000 10 20 30 40 50 60 70 80 90 100 110 120</phone>
<address confidence="0.890175428571429">Lexicon size/10 1000 900 700 600 2500 2000</address>
<email confidence="0.584703">NOM</email>
<affiliation confidence="0.494521666666667">ACC PL NOM PL ACC</affiliation>
<address confidence="0.821355">1500 1000 500</address>
<phone confidence="0.408148">0 2 4 6 8 10 12</phone>
<note confidence="0.885149254545454">0 7 Peter Jusczyk. 1999. How infants begin to extract from speech. in Cognitive 3(9):323–328. Chomsky and Morris Halle. 1968. Sound of Harper and Row. John Coleman. 1998. Cognitive reality and the phonolexicon: A review. of Neurolinguis- 11(3):295—-320. Thomas Cover and Peter Hart. 1967. Nearest neighbor classification. Transactions on Infor- 13:21–27. Walter Daelemans and Antal van den Bosch. 2005. Language Studies in Natural Language Processing. Cambridge University Press. Walter Daelemans, Steven Gillis, and Gert Durieux. 1994. The acquisition of stress: A data-oriented ap- 20(3). Bart de Boer. 2000. Self-organization in vowel sysof 28:441–465. B. Elan Dresher. 1999. Charing the learning path: to parameter setting. 30(1):27–67. Marc Ettlinger. 2007. An exemplar-based model of shifts. In of the 16th Interna- Congress of the Phonetic pages 685– 688. Evelyn Fix and J.L. Hodges. 1951. Discriminatory analysis, nonparametric discrimination: Consistency properties. Technical Report 4, USAF School of Aviation Medicine. Stephen Goldinger. 1996. Words and voices: Episodic traces in spoken word identification and recognimemory. of Experimental Psychology: Memory, and 22:1166–1183. Morris Halle. 1997. Some consequences of the repreof words in memory. 100:91–100. Trevor Hastie, Robert Tibshirani, and Jerome Fried- 2009. of Statistical Springer Series in Statistics. Springer-Verlag, 2 edition. Hynek Hermansky. 1990. Perceptual linear predictive analysis of speech. of the Acoustical 87(4):1738–1752. Keith Johnson and John W. Mullenix, editors. 1997. Variability in Speech Academic Press. Keith Johnson. 1997. Speech perception without speaker normalization: an exemplar model. In Variability in Speech chapter 8, pages 145–166. Academic Press. Johnson, 2007. and Mechanisms in chapter 3, pages 25–40.</note>
<affiliation confidence="0.72964">Oxford University Press.</affiliation>
<address confidence="0.504884">Jusczyk. 2000. Discovery of Spoken Lan-</address>
<affiliation confidence="0.811628">MIT Press.</affiliation>
<address confidence="0.536561">Robert Kirchner and Roger Moore. 2009. Computing</address>
<abstract confidence="0.9238345">phonological generalization over real speech exemplars. ms.</abstract>
<note confidence="0.82817155">Lodge. 2009. Concepts in Phonol- Sameness and Edinburgh University Press. Douglas Medin and Marguerite Schaffer. 1978. Contheory of classification learning. 85(3):207–238. Mielke. 2008. Emergence of Distinctive Fea- Oxford Studies in Typology and Linguistic Theory. Oxford University Press. Robert Nosofsky. 1986. Attention, similarity, and the relationship. Experimental Psychology: 115(1):39– 57. Colin Phillips, Thomas Pellathy, Alec Marantz, Elron Yellin, Kenneth Wexler, David Poeppel, Martha McGinnis, and Timothy Roberts. 2000. Auditory cortex accesses phonological categories: An meg study. of Cognitive 12(6):1038–1055. Janet Pierrehumbert. 2001. Exemplar dynamics: Word</note>
<abstract confidence="0.713397">lenition, and contrast. In efand the emergence of linguistic pages 137–157. John Benjamins.</abstract>
<note confidence="0.91299">Prince and Paul Smolensky. 2004. Theory: Constraint interaction in generative gram- Blackwell. Lawrence Rabiner and Biing-Hwang Juang. 1993. of Speech Prentice Hall. Semon. 1921. George Allen and Unwin. Harvey Sussman, David Fruchter, Jon Hilbert, and Joseph Sirosh. 1998. Linear correlates in the speech The orderly output constraint. Brain 21:241–299. Tesar and Paul Smolensky. 2000. Optimality MIT Press. Riitta V¨alimaa-Blum. 2009. The phoneme in cognitive</note>
<abstract confidence="0.4777134">phonology: episodic memories of both meaningful meaningless units? 2. Harry van der Hulst and Jeroen van de Weijer. 1995. harmony. In John Goldsmith, editor, Handof Phonological Blackwell.</abstract>
<intro confidence="0.589921">8</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Aha</author>
</authors>
<title>Lazy learning.</title>
<date>1997</date>
<booktitle>In Lazy Learning,</booktitle>
<pages>7--10</pages>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="1400" citStr="Aha, 1997" startWordPosition="196" endWordPosition="197">on that dominated the past half-century of linguistic research typically posit strong biases in acquisition, with language learners using innatelygiven, domain-specific representations (Chomsky and Halle, 1968), constraints (Prince and Smolensky, 2004) and learning algorithms (Tesar and Smolensky, 2000; Dresher, 1999) to learn abstract rules or constraint rankings from which they can classify or produce novel instances. In the last decade, however, there has been a shift toward empiricist approaches to phonological acquisition, use and knowledge. In this literature, eager learning algorithms (Aha, 1997), in which training data are used to update intensional representations of functions or categories then discarded, have been the norm.1 However, research in related fields—particularly speech perception— indicates that speakers’ knowledge and use of language, both in production and comprehension, is at least partly episodic, or instance-based (Goldinger, 1996; Johnson, 1997). Additionally, 1Daelemans et al. (1994) is a notable exception. motivation for instance-based models of categorisation has a lengthy history in cognitive psychology (Medin and Schaffer, 1978), and these methods are well-kn</context>
<context position="4669" citStr="Aha, 1997" startWordPosition="689" endWordPosition="690">ing, also called memory-based, case-based, and exemplar-based models, have their modern origins in psychological theories and models of perceptual categorisation and episodic memory (Medin and Schaffer, 1978; Nosofsky, 1986), although the earliest explicit discussion seems to be (Semon, 1921); a theory of memory that anticipates many features of contemporary models. The core features of these models are: (i) explicit storage/memorisation (viz. extensional representation) of training data, (ii) classification/processing of novel data via similarity-based computation, and (iii) lazy evaluation (Aha, 1997), whereby all computations are deferred until the model is queried with data.3 Instance-based models were introduced to linguistics via research in speech perception suggesting that at least some aspects of linguistic performance rely on remembered experiential episodes (Johnson and Mullenix, 1997). The models implemented to date in phonetics and phonology have largely focused on perception (e.g. speaker normalisation in Johnson (1997)), or on diachronic processes (e.g. lenition in Pierrehumbert (2001), chain shifts in Ettlinger (2007)), leaving the types of phenomena that typically interest “</context>
</contexts>
<marker>Aha, 1997</marker>
<rawString>David Aha. 1997. Lazy learning. In Lazy Learning, pages 7–10. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Coleman</author>
</authors>
<title>Cognitive reality and the phonological lexicon: A review.</title>
<date>1998</date>
<journal>Journal of Neurolinguistics,</journal>
<volume>11</volume>
<issue>3</issue>
<contexts>
<context position="7494" citStr="Coleman (1998)" startWordPosition="1108" endWordPosition="1109">areness, both in monitoring and manipulation. On this basis, I take meaning-bearing unanalysed acoustic chunks to be the relevant units of representation for LIBPHON.5 Feature type Having determined the size of LIBPHON’s basic unit, I move now to its embedding space, where distinctive features present themselves as obvious candidate dimensions. Since the middle of the 20th century (ca. Chomsky and Halle (1968)), phonological theories have nearly all supposed that lexical representations are stored in terms of articulatory features (cf. (Halle, 1997) for explicit discussion of this viewpoint). Coleman (1998), citing evidence from the neuroscientific and psycholinguistic literatures on lexical representation, claims that evidence for this position (e.g. from speech perception and phoneme monitoring experiments) is weak at best, and that lexical representations are more likely to be acoustic than articulatory. In addition, Phillips et al. (2000) review neurolinguistic evidence for the role of acoustic cortex in phonetics and phonology, and 5The assumption that word-level segmentation of the speech signal is available to the language learner prior to acquisition of phonological phenomena is relative</context>
</contexts>
<marker>Coleman, 1998</marker>
<rawString>John Coleman. 1998. Cognitive reality and the phonological lexicon: A review. Journal of Neurolinguistics, 11(3):295—-320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Cover</author>
<author>Peter Hart</author>
</authors>
<title>Nearest neighbor pattern classification.</title>
<date>1967</date>
<journal>IEEE Transactions on Information Theory,</journal>
<pages>13--21</pages>
<contexts>
<context position="2143" citStr="Cover and Hart, 1967" startWordPosition="304" endWordPosition="307">n the norm.1 However, research in related fields—particularly speech perception— indicates that speakers’ knowledge and use of language, both in production and comprehension, is at least partly episodic, or instance-based (Goldinger, 1996; Johnson, 1997). Additionally, 1Daelemans et al. (1994) is a notable exception. motivation for instance-based models of categorisation has a lengthy history in cognitive psychology (Medin and Schaffer, 1978), and these methods are well-known in the statistical and machine learning literature, having been studied for over half a century (Fix and Hodges, 1951; Cover and Hart, 1967; Hastie et al., 2009). Consequently, it seems a worthy endeavour applying an instancebased method to a problem that is of interest to traditional phonologists, the acquisition and use of vowel harmony, while simultaneously effecting a rapprochement with adjacent disicplines in the cognitive sciences. In sections 2 and 3 I give some brief background on vowel harmony and instancebased models, respectively. Section 4 introduces my model, LIBPHON, and section 5 the languages it learns. I discuss some simulations and results in section 6, and conclude in section 7. 2 Vowel harmony Vowel harmony is</context>
</contexts>
<marker>Cover, Hart, 1967</marker>
<rawString>Thomas Cover and Peter Hart. 1967. Nearest neighbor pattern classification. IEEE Transactions on Information Theory, 13:21–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Antal van den Bosch</author>
</authors>
<date>2005</date>
<booktitle>Memory-Based Language Processing. Studies in Natural Language Processing.</booktitle>
<publisher>Cambridge University Press.</publisher>
<marker>Daelemans, van den Bosch, 2005</marker>
<rawString>Walter Daelemans and Antal van den Bosch. 2005. Memory-Based Language Processing. Studies in Natural Language Processing. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Steven Gillis</author>
<author>Gert Durieux</author>
</authors>
<title>The acquisition of stress: A data-oriented approach.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>3</issue>
<contexts>
<context position="1817" citStr="Daelemans et al. (1994)" startWordPosition="252" endWordPosition="255">ce novel instances. In the last decade, however, there has been a shift toward empiricist approaches to phonological acquisition, use and knowledge. In this literature, eager learning algorithms (Aha, 1997), in which training data are used to update intensional representations of functions or categories then discarded, have been the norm.1 However, research in related fields—particularly speech perception— indicates that speakers’ knowledge and use of language, both in production and comprehension, is at least partly episodic, or instance-based (Goldinger, 1996; Johnson, 1997). Additionally, 1Daelemans et al. (1994) is a notable exception. motivation for instance-based models of categorisation has a lengthy history in cognitive psychology (Medin and Schaffer, 1978), and these methods are well-known in the statistical and machine learning literature, having been studied for over half a century (Fix and Hodges, 1951; Cover and Hart, 1967; Hastie et al., 2009). Consequently, it seems a worthy endeavour applying an instancebased method to a problem that is of interest to traditional phonologists, the acquisition and use of vowel harmony, while simultaneously effecting a rapprochement with adjacent disicpline</context>
</contexts>
<marker>Daelemans, Gillis, Durieux, 1994</marker>
<rawString>Walter Daelemans, Steven Gillis, and Gert Durieux. 1994. The acquisition of stress: A data-oriented approach. Computational Linguistics, 20(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bart de Boer</author>
</authors>
<title>Self-organization in vowel systems.</title>
<date>2000</date>
<journal>Journal of Phonetics,</journal>
<pages>28--441</pages>
<marker>de Boer, 2000</marker>
<rawString>Bart de Boer. 2000. Self-organization in vowel systems. Journal of Phonetics, 28:441–465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Elan Dresher</author>
</authors>
<title>Charing the learning path: Cues to parameter setting.</title>
<date>1999</date>
<journal>Linguistic Inquiry,</journal>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="1109" citStr="Dresher, 1999" startWordPosition="151" endWordPosition="152">s to which it has not been exposed. 1 Explaining phonological patterns How do infants learn the phonetic categories and phonotactic patterns of their native languages? How strong are the biases that learners bring to the task of phonological acquistion? Phonologists from the rationalist tradition that dominated the past half-century of linguistic research typically posit strong biases in acquisition, with language learners using innatelygiven, domain-specific representations (Chomsky and Halle, 1968), constraints (Prince and Smolensky, 2004) and learning algorithms (Tesar and Smolensky, 2000; Dresher, 1999) to learn abstract rules or constraint rankings from which they can classify or produce novel instances. In the last decade, however, there has been a shift toward empiricist approaches to phonological acquisition, use and knowledge. In this literature, eager learning algorithms (Aha, 1997), in which training data are used to update intensional representations of functions or categories then discarded, have been the norm.1 However, research in related fields—particularly speech perception— indicates that speakers’ knowledge and use of language, both in production and comprehension, is at least</context>
</contexts>
<marker>Dresher, 1999</marker>
<rawString>B. Elan Dresher. 1999. Charing the learning path: Cues to parameter setting. Linguistic Inquiry, 30(1):27–67.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Ettlinger</author>
</authors>
<title>An exemplar-based model of chain shifts.</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th International Congress of the Phonetic Science,</booktitle>
<pages>685--688</pages>
<contexts>
<context position="5210" citStr="Ettlinger (2007)" startWordPosition="769" endWordPosition="770">ata via similarity-based computation, and (iii) lazy evaluation (Aha, 1997), whereby all computations are deferred until the model is queried with data.3 Instance-based models were introduced to linguistics via research in speech perception suggesting that at least some aspects of linguistic performance rely on remembered experiential episodes (Johnson and Mullenix, 1997). The models implemented to date in phonetics and phonology have largely focused on perception (e.g. speaker normalisation in Johnson (1997)), or on diachronic processes (e.g. lenition in Pierrehumbert (2001), chain shifts in Ettlinger (2007)), leaving the types of phenomena that typically interest “traditional” phonologists, viz. productive, generalised patterns, comparatively neglected.4 4 LIBPHON LIBPHON, the Lazy Instance-based Phonologist, is a lazy learning algorithm whose purpose (in the 3Compare eager learners, e.g. connectionist systems, which build a global intensional representation of the function being learned on the basis of training data which are subsequently discarded. 4Kirchner and Moore (2009) give a model of a synchronic lenition process, and Daelemans and colleagues give memory-based analyses of several lingui</context>
</contexts>
<marker>Ettlinger, 2007</marker>
<rawString>Marc Ettlinger. 2007. An exemplar-based model of chain shifts. In Proceedings of the 16th International Congress of the Phonetic Science, pages 685– 688.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evelyn Fix</author>
<author>J L Hodges</author>
</authors>
<title>Discriminatory analysis, nonparametric discrimination: Consistency properties.</title>
<date>1951</date>
<tech>Technical Report 4,</tech>
<institution>USAF School of Aviation Medicine.</institution>
<contexts>
<context position="2121" citStr="Fix and Hodges, 1951" startWordPosition="300" endWordPosition="303">en discarded, have been the norm.1 However, research in related fields—particularly speech perception— indicates that speakers’ knowledge and use of language, both in production and comprehension, is at least partly episodic, or instance-based (Goldinger, 1996; Johnson, 1997). Additionally, 1Daelemans et al. (1994) is a notable exception. motivation for instance-based models of categorisation has a lengthy history in cognitive psychology (Medin and Schaffer, 1978), and these methods are well-known in the statistical and machine learning literature, having been studied for over half a century (Fix and Hodges, 1951; Cover and Hart, 1967; Hastie et al., 2009). Consequently, it seems a worthy endeavour applying an instancebased method to a problem that is of interest to traditional phonologists, the acquisition and use of vowel harmony, while simultaneously effecting a rapprochement with adjacent disicplines in the cognitive sciences. In sections 2 and 3 I give some brief background on vowel harmony and instancebased models, respectively. Section 4 introduces my model, LIBPHON, and section 5 the languages it learns. I discuss some simulations and results in section 6, and conclude in section 7. 2 Vowel ha</context>
</contexts>
<marker>Fix, Hodges, 1951</marker>
<rawString>Evelyn Fix and J.L. Hodges. 1951. Discriminatory analysis, nonparametric discrimination: Consistency properties. Technical Report 4, USAF School of Aviation Medicine.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Goldinger</author>
</authors>
<title>Words and voices: Episodic traces in spoken word identification and recognition memory.</title>
<date>1996</date>
<journal>Journal of Experimental Psychology: Learning, Memory, and Cognition,</journal>
<pages>22--1166</pages>
<contexts>
<context position="1761" citStr="Goldinger, 1996" startWordPosition="247" endWordPosition="248">t rankings from which they can classify or produce novel instances. In the last decade, however, there has been a shift toward empiricist approaches to phonological acquisition, use and knowledge. In this literature, eager learning algorithms (Aha, 1997), in which training data are used to update intensional representations of functions or categories then discarded, have been the norm.1 However, research in related fields—particularly speech perception— indicates that speakers’ knowledge and use of language, both in production and comprehension, is at least partly episodic, or instance-based (Goldinger, 1996; Johnson, 1997). Additionally, 1Daelemans et al. (1994) is a notable exception. motivation for instance-based models of categorisation has a lengthy history in cognitive psychology (Medin and Schaffer, 1978), and these methods are well-known in the statistical and machine learning literature, having been studied for over half a century (Fix and Hodges, 1951; Cover and Hart, 1967; Hastie et al., 2009). Consequently, it seems a worthy endeavour applying an instancebased method to a problem that is of interest to traditional phonologists, the acquisition and use of vowel harmony, while simultane</context>
</contexts>
<marker>Goldinger, 1996</marker>
<rawString>Stephen Goldinger. 1996. Words and voices: Episodic traces in spoken word identification and recognition memory. Journal of Experimental Psychology: Learning, Memory, and Cognition, 22:1166–1183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Morris Halle</author>
</authors>
<title>Some consequences of the representation of words in memory.</title>
<date>1997</date>
<booktitle>Lingua,</booktitle>
<pages>100--91</pages>
<contexts>
<context position="7435" citStr="Halle, 1997" startWordPosition="1100" endWordPosition="1101">ing systems have poor phonemic (or at least segmental) awareness, both in monitoring and manipulation. On this basis, I take meaning-bearing unanalysed acoustic chunks to be the relevant units of representation for LIBPHON.5 Feature type Having determined the size of LIBPHON’s basic unit, I move now to its embedding space, where distinctive features present themselves as obvious candidate dimensions. Since the middle of the 20th century (ca. Chomsky and Halle (1968)), phonological theories have nearly all supposed that lexical representations are stored in terms of articulatory features (cf. (Halle, 1997) for explicit discussion of this viewpoint). Coleman (1998), citing evidence from the neuroscientific and psycholinguistic literatures on lexical representation, claims that evidence for this position (e.g. from speech perception and phoneme monitoring experiments) is weak at best, and that lexical representations are more likely to be acoustic than articulatory. In addition, Phillips et al. (2000) review neurolinguistic evidence for the role of acoustic cortex in phonetics and phonology, and 5The assumption that word-level segmentation of the speech signal is available to the language learner</context>
</contexts>
<marker>Halle, 1997</marker>
<rawString>Morris Halle. 1997. Some consequences of the representation of words in memory. Lingua, 100:91–100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Hastie</author>
<author>Robert Tibshirani</author>
<author>Jerome Friedman</author>
</authors>
<date>2009</date>
<booktitle>Elements of Statistical Learning. Springer Series in Statistics.</booktitle>
<volume>2</volume>
<pages>edition.</pages>
<publisher>Springer-Verlag,</publisher>
<contexts>
<context position="2165" citStr="Hastie et al., 2009" startWordPosition="308" endWordPosition="311">research in related fields—particularly speech perception— indicates that speakers’ knowledge and use of language, both in production and comprehension, is at least partly episodic, or instance-based (Goldinger, 1996; Johnson, 1997). Additionally, 1Daelemans et al. (1994) is a notable exception. motivation for instance-based models of categorisation has a lengthy history in cognitive psychology (Medin and Schaffer, 1978), and these methods are well-known in the statistical and machine learning literature, having been studied for over half a century (Fix and Hodges, 1951; Cover and Hart, 1967; Hastie et al., 2009). Consequently, it seems a worthy endeavour applying an instancebased method to a problem that is of interest to traditional phonologists, the acquisition and use of vowel harmony, while simultaneously effecting a rapprochement with adjacent disicplines in the cognitive sciences. In sections 2 and 3 I give some brief background on vowel harmony and instancebased models, respectively. Section 4 introduces my model, LIBPHON, and section 5 the languages it learns. I discuss some simulations and results in section 6, and conclude in section 7. 2 Vowel harmony Vowel harmony is a phonological phenom</context>
<context position="16395" citStr="Hastie et al., 2009" startWordPosition="2518" endWordPosition="2521">orm random selection from instances associated to LABEL&apos;) cloud +— all instances associated to plural(LABEL) U case(LABEL) else pass end if neighbours +— k-nearest neighbours of seed in cloud return distance-weighted mean of neighbours 4.4 Production as regression The final steps in LIBPHON’s production algorithm, finding the analogical set and computing the output as a weighted average, together constitute a technique known in the statistical learning literature as kernel-smoothed nearest-neighbour regression, and in particular are closely related to the well-known Nadaraya-Watson estimator (Hastie et al., 2009): �N i=1 Kλ(x, xi)yi ˆf(x) = �N i=1 Kλ(x, xi) with inverse-distance as the kernel smoother, K, and the bandwidth function, hλ(x) determined by the number k of nearest neighbours. This link to the statistical learning literature puts LIBPHON on sound theoretical footing and opens the door to a variety of future research paths, e.g. experimenting with different kernel shapes, or formal analysis of LIBPHON’s expected error bounds. 4 5 The languages On the view taken here, phonological knowledge is taken to emerge from generalisation over lexical items, and so the key to acquiring some phonologica</context>
</contexts>
<marker>Hastie, Tibshirani, Friedman, 2009</marker>
<rawString>Trevor Hastie, Robert Tibshirani, and Jerome Friedman. 2009. Elements of Statistical Learning. Springer Series in Statistics. Springer-Verlag, 2 edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hynek Hermansky</author>
</authors>
<title>Perceptual linear predictive (plp) analysis of speech.</title>
<date>1990</date>
<journal>Journal of the Acoustical Society ofAmerica,</journal>
<volume>87</volume>
<issue>4</issue>
<contexts>
<context position="10532" citStr="Hermansky, 1990" startWordPosition="1558" endWordPosition="1559">st for aligning variable-length sequences, these require cognitively implausible dynamic programming algorithms, e.g. dynamic time warping (DTW) 6A reviewer asks about the psychological plausibility of Hz-based formant represetations and the choice of point values for vowel and consonant representations, e.g. rather than formant values at 20% and 80% of the vowel. These are purely in the interests of simplicity for the work reported here. As discussed below, future work with real speech exemplars in psychophysically-motivated representational formats, e.g. perceptual linear predictive coding (Hermansky, 1990), will render this issue moot. 7Often the measure of similarity in an instance-based model is an exponential function of distance, d(xi, xj) of the form exp(−cd(xi, xj)), so that increasing distance yields decreasing similarity (Nosofsky, 1986). The Euclidean measure here is sufficient for the purpose at hand, although the shape of the similarity measure is ultimately an empirical question. and hidden Markov models (Rabiner and Juang, 1993). Even as proofs of concept, these may be empirically inadequate; Kirchner and Moore (2009) use DTW to good effect in an instancebased production model of s</context>
</contexts>
<marker>Hermansky, 1990</marker>
<rawString>Hynek Hermansky. 1990. Perceptual linear predictive (plp) analysis of speech. Journal of the Acoustical Society ofAmerica, 87(4):1738–1752.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keith Johnson</author>
<author>John W Mullenix</author>
<author>editors</author>
</authors>
<date>1997</date>
<booktitle>Talker Variability in Speech Processing.</booktitle>
<publisher>Academic Press.</publisher>
<marker>Johnson, Mullenix, editors, 1997</marker>
<rawString>Keith Johnson and John W. Mullenix, editors. 1997. Talker Variability in Speech Processing. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keith Johnson</author>
</authors>
<title>Speech perception without speaker normalization: an exemplar model.</title>
<date>1997</date>
<booktitle>In Talker Variability in Speech Processing, chapter 8,</booktitle>
<pages>145--166</pages>
<publisher>Academic Press.</publisher>
<contexts>
<context position="1777" citStr="Johnson, 1997" startWordPosition="249" endWordPosition="250">hich they can classify or produce novel instances. In the last decade, however, there has been a shift toward empiricist approaches to phonological acquisition, use and knowledge. In this literature, eager learning algorithms (Aha, 1997), in which training data are used to update intensional representations of functions or categories then discarded, have been the norm.1 However, research in related fields—particularly speech perception— indicates that speakers’ knowledge and use of language, both in production and comprehension, is at least partly episodic, or instance-based (Goldinger, 1996; Johnson, 1997). Additionally, 1Daelemans et al. (1994) is a notable exception. motivation for instance-based models of categorisation has a lengthy history in cognitive psychology (Medin and Schaffer, 1978), and these methods are well-known in the statistical and machine learning literature, having been studied for over half a century (Fix and Hodges, 1951; Cover and Hart, 1967; Hastie et al., 2009). Consequently, it seems a worthy endeavour applying an instancebased method to a problem that is of interest to traditional phonologists, the acquisition and use of vowel harmony, while simultaneously effecting </context>
<context position="5108" citStr="Johnson (1997)" startWordPosition="755" endWordPosition="756">sation (viz. extensional representation) of training data, (ii) classification/processing of novel data via similarity-based computation, and (iii) lazy evaluation (Aha, 1997), whereby all computations are deferred until the model is queried with data.3 Instance-based models were introduced to linguistics via research in speech perception suggesting that at least some aspects of linguistic performance rely on remembered experiential episodes (Johnson and Mullenix, 1997). The models implemented to date in phonetics and phonology have largely focused on perception (e.g. speaker normalisation in Johnson (1997)), or on diachronic processes (e.g. lenition in Pierrehumbert (2001), chain shifts in Ettlinger (2007)), leaving the types of phenomena that typically interest “traditional” phonologists, viz. productive, generalised patterns, comparatively neglected.4 4 LIBPHON LIBPHON, the Lazy Instance-based Phonologist, is a lazy learning algorithm whose purpose (in the 3Compare eager learners, e.g. connectionist systems, which build a global intensional representation of the function being learned on the basis of training data which are subsequently discarded. 4Kirchner and Moore (2009) give a model of a </context>
</contexts>
<marker>Johnson, 1997</marker>
<rawString>Keith Johnson. 1997. Speech perception without speaker normalization: an exemplar model. In Talker Variability in Speech Processing, chapter 8, pages 145–166. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keith Johnson</author>
</authors>
<title>Decision and Mechanisms in Exemplar-based Phonology,</title>
<date>2007</date>
<volume>3</volume>
<pages>25--40</pages>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="6091" citStr="Johnson, 2007" startWordPosition="897" endWordPosition="898">eager learners, e.g. connectionist systems, which build a global intensional representation of the function being learned on the basis of training data which are subsequently discarded. 4Kirchner and Moore (2009) give a model of a synchronic lenition process, and Daelemans and colleagues give memory-based analyses of several linguistic phenomena (Daelemans and van den Bosch, 2005). context of the simulations described here) is to model an instance-based approach to the core aspects of the acquisition and subsequent productive usage of vowel harmony. 4.1 Decisions &amp; mechanisms As discussed in (Johnson, 2007), there are some decisions that need to be made in implementing an instance-based model of phonological knowledge involving the basic units of analysis (e.g. their size), the relevant type of these units (e.g. discrete or continuous), and the mechanisms for similaritymatching and activation spread in the lexicon. Units The arguments given by Johnson (2007) and V¨alimaa-Blum (2009) for the “word-sized” (rather than e.g. segmental) experience of language, suggest that “words” are the correct basic unit of analysis in instance-based langugage models (a fortiori in LIBPHON). Stronger evidence come</context>
</contexts>
<marker>Johnson, 2007</marker>
<rawString>Keith Johnson, 2007. Decision and Mechanisms in Exemplar-based Phonology, chapter 3, pages 25–40. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Jusczyk</author>
</authors>
<title>The Discovery of Spoken Language.</title>
<date>2000</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="17047" citStr="Jusczyk, 2000" startWordPosition="2626" endWordPosition="2627">(x, xi) with inverse-distance as the kernel smoother, K, and the bandwidth function, hλ(x) determined by the number k of nearest neighbours. This link to the statistical learning literature puts LIBPHON on sound theoretical footing and opens the door to a variety of future research paths, e.g. experimenting with different kernel shapes, or formal analysis of LIBPHON’s expected error bounds. 4 5 The languages On the view taken here, phonological knowledge is taken to emerge from generalisation over lexical items, and so the key to acquiring some phonological pattern lies in learning a lexicon (Jusczyk, 2000). Consequently, the languages learned in LIBPHON abstract away from sentence-level phenomena, and the training data are simply labelled formant trajectories, (LABEL, instance). In order to get at the essence of the problem (viz. the acquisition of vowel harmony as characterised by morphophonological alternations), and in the interests of computational tractability/efficiency, the artificial languages learned by LIBPHON are highly simplified, displaying only enough structure to capture the phenomena of interest. 3000 2500 2000 1500 1000 500 00 2 4 6 8 10 12 GIDEGEBI NOM gidegebi F1 F2 3000 2500</context>
</contexts>
<marker>Jusczyk, 2000</marker>
<rawString>Peter Jusczyk. 2000. The Discovery of Spoken Language. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Kirchner</author>
<author>Roger Moore</author>
</authors>
<title>Computing phonological generalization over real speech exemplars.</title>
<date>2009</date>
<note>ms.</note>
<contexts>
<context position="5689" citStr="Kirchner and Moore (2009)" startWordPosition="833" endWordPosition="836">e.g. speaker normalisation in Johnson (1997)), or on diachronic processes (e.g. lenition in Pierrehumbert (2001), chain shifts in Ettlinger (2007)), leaving the types of phenomena that typically interest “traditional” phonologists, viz. productive, generalised patterns, comparatively neglected.4 4 LIBPHON LIBPHON, the Lazy Instance-based Phonologist, is a lazy learning algorithm whose purpose (in the 3Compare eager learners, e.g. connectionist systems, which build a global intensional representation of the function being learned on the basis of training data which are subsequently discarded. 4Kirchner and Moore (2009) give a model of a synchronic lenition process, and Daelemans and colleagues give memory-based analyses of several linguistic phenomena (Daelemans and van den Bosch, 2005). context of the simulations described here) is to model an instance-based approach to the core aspects of the acquisition and subsequent productive usage of vowel harmony. 4.1 Decisions &amp; mechanisms As discussed in (Johnson, 2007), there are some decisions that need to be made in implementing an instance-based model of phonological knowledge involving the basic units of analysis (e.g. their size), the relevant type of these </context>
<context position="11067" citStr="Kirchner and Moore (2009)" startWordPosition="1638" endWordPosition="1641">vated representational formats, e.g. perceptual linear predictive coding (Hermansky, 1990), will render this issue moot. 7Often the measure of similarity in an instance-based model is an exponential function of distance, d(xi, xj) of the form exp(−cd(xi, xj)), so that increasing distance yields decreasing similarity (Nosofsky, 1986). The Euclidean measure here is sufficient for the purpose at hand, although the shape of the similarity measure is ultimately an empirical question. and hidden Markov models (Rabiner and Juang, 1993). Even as proofs of concept, these may be empirically inadequate; Kirchner and Moore (2009) use DTW to good effect in an instancebased production model of spirantisation using real, temporally variable, speech signals. However, their inputs were all the same length in terms of segmental content, and the model was only required to generalise within a word type. I am currently investigating whether DTW can function as a proof of concept in a problem domain like that addressed here, which involves learning about variably-sized “pieces” of morphology across class labels. 4.2 Perception/categorisation LIBPHON’s method of perception/categorisation of inputs is a relatively standard neares</context>
</contexts>
<marker>Kirchner, Moore, 2009</marker>
<rawString>Robert Kirchner and Roger Moore. 2009. Computing phonological generalization over real speech exemplars. ms.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken Lodge</author>
</authors>
<title>Fundamental Concepts in Phonology: Sameness and difference.</title>
<date>2009</date>
<publisher>Edinburgh University Press.</publisher>
<contexts>
<context position="6760" citStr="Lodge, 2009" startWordPosition="998" endWordPosition="999">enting an instance-based model of phonological knowledge involving the basic units of analysis (e.g. their size), the relevant type of these units (e.g. discrete or continuous), and the mechanisms for similaritymatching and activation spread in the lexicon. Units The arguments given by Johnson (2007) and V¨alimaa-Blum (2009) for the “word-sized” (rather than e.g. segmental) experience of language, suggest that “words” are the correct basic unit of analysis in instance-based langugage models (a fortiori in LIBPHON). Stronger evidence comes from the wealth of psycholinguistic data (reviewed in (Lodge, 2009)) showing that illiterates and literates of non-alphabetic writing systems have poor phonemic (or at least segmental) awareness, both in monitoring and manipulation. On this basis, I take meaning-bearing unanalysed acoustic chunks to be the relevant units of representation for LIBPHON.5 Feature type Having determined the size of LIBPHON’s basic unit, I move now to its embedding space, where distinctive features present themselves as obvious candidate dimensions. Since the middle of the 20th century (ca. Chomsky and Halle (1968)), phonological theories have nearly all supposed that lexical repr</context>
</contexts>
<marker>Lodge, 2009</marker>
<rawString>Ken Lodge. 2009. Fundamental Concepts in Phonology: Sameness and difference. Edinburgh University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas Medin</author>
<author>Marguerite Schaffer</author>
</authors>
<title>Context theory of classification learning.</title>
<date>1978</date>
<journal>Psychological Review,</journal>
<volume>85</volume>
<issue>3</issue>
<contexts>
<context position="1969" citStr="Medin and Schaffer, 1978" startWordPosition="275" endWordPosition="278">n this literature, eager learning algorithms (Aha, 1997), in which training data are used to update intensional representations of functions or categories then discarded, have been the norm.1 However, research in related fields—particularly speech perception— indicates that speakers’ knowledge and use of language, both in production and comprehension, is at least partly episodic, or instance-based (Goldinger, 1996; Johnson, 1997). Additionally, 1Daelemans et al. (1994) is a notable exception. motivation for instance-based models of categorisation has a lengthy history in cognitive psychology (Medin and Schaffer, 1978), and these methods are well-known in the statistical and machine learning literature, having been studied for over half a century (Fix and Hodges, 1951; Cover and Hart, 1967; Hastie et al., 2009). Consequently, it seems a worthy endeavour applying an instancebased method to a problem that is of interest to traditional phonologists, the acquisition and use of vowel harmony, while simultaneously effecting a rapprochement with adjacent disicplines in the cognitive sciences. In sections 2 and 3 I give some brief background on vowel harmony and instancebased models, respectively. Section 4 introdu</context>
<context position="4266" citStr="Medin and Schaffer, 1978" startWordPosition="631" endWordPosition="634">on whether the stem has front {¨u, ¨a} or back {u, a} vowels. 2.1 Neutral vowels In most languages with vowel harmony, there are one or more vowels that systematically fail to alternate. These are called neutral vowels, and are typically further subclassified according to whether or not they induce further harmonic alternations in other vowels. 3 Instance-based models Instance-based approaches to cognitive processing, also called memory-based, case-based, and exemplar-based models, have their modern origins in psychological theories and models of perceptual categorisation and episodic memory (Medin and Schaffer, 1978; Nosofsky, 1986), although the earliest explicit discussion seems to be (Semon, 1921); a theory of memory that anticipates many features of contemporary models. The core features of these models are: (i) explicit storage/memorisation (viz. extensional representation) of training data, (ii) classification/processing of novel data via similarity-based computation, and (iii) lazy evaluation (Aha, 1997), whereby all computations are deferred until the model is queried with data.3 Instance-based models were introduced to linguistics via research in speech perception suggesting that at least some a</context>
</contexts>
<marker>Medin, Schaffer, 1978</marker>
<rawString>Douglas Medin and Marguerite Schaffer. 1978. Context theory of classification learning. Psychological Review, 85(3):207–238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Mielke</author>
</authors>
<title>The Emergence of Distinctive Features.</title>
<date>2008</date>
<booktitle>Oxford Studies in Typology and Linguistic Theory.</booktitle>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="8279" citStr="Mielke (2008)" startWordPosition="1225" endWordPosition="1226">nd phoneme monitoring experiments) is weak at best, and that lexical representations are more likely to be acoustic than articulatory. In addition, Phillips et al. (2000) review neurolinguistic evidence for the role of acoustic cortex in phonetics and phonology, and 5The assumption that word-level segmentation of the speech signal is available to the language learner prior to acquisition of phonological phenomena is relatively uncontroversial, although there is evidence for the development of at least some phonotactic knowledge prior to the emergence of a productive lexicon (Jusczyk, 1999). 2 Mielke (2008) discusses several aspects of the induction of distinctive phonological features from acoustic representations. Recognising that the issue is far from resolved, for the purposes of the simulations run here, I take LIBPHON’s instance space to be acoustically-based, and use formant values as the embedding dimension. Vowels are specified by their midpoint formant values,6 and consonants are specified by so-called “locus” values, which can be identified by inspecting the trajectories of consonant-vowel transitions in speech (Sussman et al., 1998). Since I am modelling palatal harmony in particular</context>
</contexts>
<marker>Mielke, 2008</marker>
<rawString>Jeff Mielke. 2008. The Emergence of Distinctive Features. Oxford Studies in Typology and Linguistic Theory. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Nosofsky</author>
</authors>
<title>Attention, similarity, and the identification-categorization relationship.</title>
<date>1986</date>
<journal>Journal of Experimental Psychology: General,</journal>
<volume>115</volume>
<issue>1</issue>
<pages>57</pages>
<contexts>
<context position="4283" citStr="Nosofsky, 1986" startWordPosition="635" endWordPosition="636">ont {¨u, ¨a} or back {u, a} vowels. 2.1 Neutral vowels In most languages with vowel harmony, there are one or more vowels that systematically fail to alternate. These are called neutral vowels, and are typically further subclassified according to whether or not they induce further harmonic alternations in other vowels. 3 Instance-based models Instance-based approaches to cognitive processing, also called memory-based, case-based, and exemplar-based models, have their modern origins in psychological theories and models of perceptual categorisation and episodic memory (Medin and Schaffer, 1978; Nosofsky, 1986), although the earliest explicit discussion seems to be (Semon, 1921); a theory of memory that anticipates many features of contemporary models. The core features of these models are: (i) explicit storage/memorisation (viz. extensional representation) of training data, (ii) classification/processing of novel data via similarity-based computation, and (iii) lazy evaluation (Aha, 1997), whereby all computations are deferred until the model is queried with data.3 Instance-based models were introduced to linguistics via research in speech perception suggesting that at least some aspects of linguis</context>
<context position="10776" citStr="Nosofsky, 1986" startWordPosition="1595" endWordPosition="1596">ice of point values for vowel and consonant representations, e.g. rather than formant values at 20% and 80% of the vowel. These are purely in the interests of simplicity for the work reported here. As discussed below, future work with real speech exemplars in psychophysically-motivated representational formats, e.g. perceptual linear predictive coding (Hermansky, 1990), will render this issue moot. 7Often the measure of similarity in an instance-based model is an exponential function of distance, d(xi, xj) of the form exp(−cd(xi, xj)), so that increasing distance yields decreasing similarity (Nosofsky, 1986). The Euclidean measure here is sufficient for the purpose at hand, although the shape of the similarity measure is ultimately an empirical question. and hidden Markov models (Rabiner and Juang, 1993). Even as proofs of concept, these may be empirically inadequate; Kirchner and Moore (2009) use DTW to good effect in an instancebased production model of spirantisation using real, temporally variable, speech signals. However, their inputs were all the same length in terms of segmental content, and the model was only required to generalise within a word type. I am currently investigating whether </context>
</contexts>
<marker>Nosofsky, 1986</marker>
<rawString>Robert Nosofsky. 1986. Attention, similarity, and the identification-categorization relationship. Journal of Experimental Psychology: General, 115(1):39– 57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Phillips</author>
<author>Thomas Pellathy</author>
<author>Alec Marantz</author>
<author>Elron Yellin</author>
<author>Kenneth Wexler</author>
<author>David Poeppel</author>
<author>Martha McGinnis</author>
<author>Timothy Roberts</author>
</authors>
<title>Auditory cortex accesses phonological categories: An meg mismatch study.</title>
<date>2000</date>
<journal>Journal of Cognitive Neuroscience,</journal>
<volume>12</volume>
<issue>6</issue>
<contexts>
<context position="7836" citStr="Phillips et al. (2000)" startWordPosition="1157" endWordPosition="1160"> dimensions. Since the middle of the 20th century (ca. Chomsky and Halle (1968)), phonological theories have nearly all supposed that lexical representations are stored in terms of articulatory features (cf. (Halle, 1997) for explicit discussion of this viewpoint). Coleman (1998), citing evidence from the neuroscientific and psycholinguistic literatures on lexical representation, claims that evidence for this position (e.g. from speech perception and phoneme monitoring experiments) is weak at best, and that lexical representations are more likely to be acoustic than articulatory. In addition, Phillips et al. (2000) review neurolinguistic evidence for the role of acoustic cortex in phonetics and phonology, and 5The assumption that word-level segmentation of the speech signal is available to the language learner prior to acquisition of phonological phenomena is relatively uncontroversial, although there is evidence for the development of at least some phonotactic knowledge prior to the emergence of a productive lexicon (Jusczyk, 1999). 2 Mielke (2008) discusses several aspects of the induction of distinctive phonological features from acoustic representations. Recognising that the issue is far from resolv</context>
</contexts>
<marker>Phillips, Pellathy, Marantz, Yellin, Wexler, Poeppel, McGinnis, Roberts, 2000</marker>
<rawString>Colin Phillips, Thomas Pellathy, Alec Marantz, Elron Yellin, Kenneth Wexler, David Poeppel, Martha McGinnis, and Timothy Roberts. 2000. Auditory cortex accesses phonological categories: An meg mismatch study. Journal of Cognitive Neuroscience, 12(6):1038–1055.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janet Pierrehumbert</author>
</authors>
<title>Exemplar dynamics: Word frequency, lenition, and contrast. In Frequency effects and the emergence of linguistic structure,</title>
<date>2001</date>
<pages>137--157</pages>
<publisher>John Benjamins.</publisher>
<contexts>
<context position="5176" citStr="Pierrehumbert (2001)" startWordPosition="764" endWordPosition="765">) classification/processing of novel data via similarity-based computation, and (iii) lazy evaluation (Aha, 1997), whereby all computations are deferred until the model is queried with data.3 Instance-based models were introduced to linguistics via research in speech perception suggesting that at least some aspects of linguistic performance rely on remembered experiential episodes (Johnson and Mullenix, 1997). The models implemented to date in phonetics and phonology have largely focused on perception (e.g. speaker normalisation in Johnson (1997)), or on diachronic processes (e.g. lenition in Pierrehumbert (2001), chain shifts in Ettlinger (2007)), leaving the types of phenomena that typically interest “traditional” phonologists, viz. productive, generalised patterns, comparatively neglected.4 4 LIBPHON LIBPHON, the Lazy Instance-based Phonologist, is a lazy learning algorithm whose purpose (in the 3Compare eager learners, e.g. connectionist systems, which build a global intensional representation of the function being learned on the basis of training data which are subsequently discarded. 4Kirchner and Moore (2009) give a model of a synchronic lenition process, and Daelemans and colleagues give memor</context>
</contexts>
<marker>Pierrehumbert, 2001</marker>
<rawString>Janet Pierrehumbert. 2001. Exemplar dynamics: Word frequency, lenition, and contrast. In Frequency effects and the emergence of linguistic structure, pages 137–157. John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Prince</author>
<author>Paul Smolensky</author>
</authors>
<title>Optimality Theory: Constraint interaction in generative grammar.</title>
<date>2004</date>
<publisher>Blackwell.</publisher>
<contexts>
<context position="1042" citStr="Prince and Smolensky, 2004" startWordPosition="139" endWordPosition="143">del quickly learns to generate harmonically correct morphologically complex forms to which it has not been exposed. 1 Explaining phonological patterns How do infants learn the phonetic categories and phonotactic patterns of their native languages? How strong are the biases that learners bring to the task of phonological acquistion? Phonologists from the rationalist tradition that dominated the past half-century of linguistic research typically posit strong biases in acquisition, with language learners using innatelygiven, domain-specific representations (Chomsky and Halle, 1968), constraints (Prince and Smolensky, 2004) and learning algorithms (Tesar and Smolensky, 2000; Dresher, 1999) to learn abstract rules or constraint rankings from which they can classify or produce novel instances. In the last decade, however, there has been a shift toward empiricist approaches to phonological acquisition, use and knowledge. In this literature, eager learning algorithms (Aha, 1997), in which training data are used to update intensional representations of functions or categories then discarded, have been the norm.1 However, research in related fields—particularly speech perception— indicates that speakers’ knowledge and</context>
</contexts>
<marker>Prince, Smolensky, 2004</marker>
<rawString>Alan Prince and Paul Smolensky. 2004. Optimality Theory: Constraint interaction in generative grammar. Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Rabiner</author>
<author>Biing-Hwang Juang</author>
</authors>
<title>Fundamentals of Speech Recognition.</title>
<date>1993</date>
<publisher>Prentice Hall.</publisher>
<contexts>
<context position="10976" citStr="Rabiner and Juang, 1993" startWordPosition="1624" endWordPosition="1627"> here. As discussed below, future work with real speech exemplars in psychophysically-motivated representational formats, e.g. perceptual linear predictive coding (Hermansky, 1990), will render this issue moot. 7Often the measure of similarity in an instance-based model is an exponential function of distance, d(xi, xj) of the form exp(−cd(xi, xj)), so that increasing distance yields decreasing similarity (Nosofsky, 1986). The Euclidean measure here is sufficient for the purpose at hand, although the shape of the similarity measure is ultimately an empirical question. and hidden Markov models (Rabiner and Juang, 1993). Even as proofs of concept, these may be empirically inadequate; Kirchner and Moore (2009) use DTW to good effect in an instancebased production model of spirantisation using real, temporally variable, speech signals. However, their inputs were all the same length in terms of segmental content, and the model was only required to generalise within a word type. I am currently investigating whether DTW can function as a proof of concept in a problem domain like that addressed here, which involves learning about variably-sized “pieces” of morphology across class labels. 4.2 Perception/categorisat</context>
</contexts>
<marker>Rabiner, Juang, 1993</marker>
<rawString>Lawrence Rabiner and Biing-Hwang Juang. 1993. Fundamentals of Speech Recognition. Prentice Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Semon</author>
</authors>
<title>The Mneme. George Allen and Unwin.</title>
<date>1921</date>
<contexts>
<context position="4352" citStr="Semon, 1921" startWordPosition="645" endWordPosition="647"> with vowel harmony, there are one or more vowels that systematically fail to alternate. These are called neutral vowels, and are typically further subclassified according to whether or not they induce further harmonic alternations in other vowels. 3 Instance-based models Instance-based approaches to cognitive processing, also called memory-based, case-based, and exemplar-based models, have their modern origins in psychological theories and models of perceptual categorisation and episodic memory (Medin and Schaffer, 1978; Nosofsky, 1986), although the earliest explicit discussion seems to be (Semon, 1921); a theory of memory that anticipates many features of contemporary models. The core features of these models are: (i) explicit storage/memorisation (viz. extensional representation) of training data, (ii) classification/processing of novel data via similarity-based computation, and (iii) lazy evaluation (Aha, 1997), whereby all computations are deferred until the model is queried with data.3 Instance-based models were introduced to linguistics via research in speech perception suggesting that at least some aspects of linguistic performance rely on remembered experiential episodes (Johnson and</context>
</contexts>
<marker>Semon, 1921</marker>
<rawString>Richard Semon. 1921. The Mneme. George Allen and Unwin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harvey Sussman</author>
<author>David Fruchter</author>
<author>Jon Hilbert</author>
<author>Joseph Sirosh</author>
</authors>
<title>Linear correlates in the speech signal: The orderly output constraint. Behavioral and Brain Sciences,</title>
<date>1998</date>
<pages>21--241</pages>
<contexts>
<context position="8827" citStr="Sussman et al., 1998" startWordPosition="1305" endWordPosition="1308">to the emergence of a productive lexicon (Jusczyk, 1999). 2 Mielke (2008) discusses several aspects of the induction of distinctive phonological features from acoustic representations. Recognising that the issue is far from resolved, for the purposes of the simulations run here, I take LIBPHON’s instance space to be acoustically-based, and use formant values as the embedding dimension. Vowels are specified by their midpoint formant values,6 and consonants are specified by so-called “locus” values, which can be identified by inspecting the trajectories of consonant-vowel transitions in speech (Sussman et al., 1998). Since I am modelling palatal harmony in particular, and F2 magnitude is the primary acoustic correlate of vowel palatality, I omit F3 and F4, restricting LIBPHON’s acoustic representations to sequences of (F 1, F2) values, henceforth trajectories. Similarity Given that LIBPHON’s instancespace is continuous, and has a fairly intuitive metric, I take simple Euclidean distance to be LIBPHON’s similarity (or rather, dissimilarity) function.7 Fixed-rate representations For the simulations described here, I use fixed-rate trajectories, in which consonants and vowels are represented in a temporally</context>
<context position="18169" citStr="Sussman et al., 1998" startWordPosition="2804" endWordPosition="2807">na of interest. 3000 2500 2000 1500 1000 500 00 2 4 6 8 10 12 GIDEGEBI NOM gidegebi F1 F2 3000 2500 2000 1500 1000 500 00 2 4 6 8 10 12 GIDEGEBI ACC gidegebibe F1 F2 Figure 1: Graphical representation of singular forms of GIDEGEBI, as produced by teacher agent 5.1 Phonological inventory The phonological inventory consists of three consonants, {b, d, 9}, and four vowels—two with high F2 and two with low F2—which I label {i, e, u, o}, for convenience.10 The formant values used were generated from formant synthesis equations in (de Boer, 2000), and from the locus equations for CV-transitions in (Sussman et al., 1998). 5.2 Lexical items LIBPHON’s lexicon is populated with instance trajectories consisting of four-syllable11 “roots” with zero, one or two one-syllable “affixes”. These trajectories have associated class labels, which from a formal point of view are contentless indices. Rather than employing e.g. natural numbers as labels, I use character strings which correspond more or less to the English pronounciations of their associated trajectories. LABELs function, metaphorically-speaking, as “meanings”. These are compositional, comprising a “lexical meaning” (arbitrary CVCVCVCV string from the phoneme </context>
</contexts>
<marker>Sussman, Fruchter, Hilbert, Sirosh, 1998</marker>
<rawString>Harvey Sussman, David Fruchter, Jon Hilbert, and Joseph Sirosh. 1998. Linear correlates in the speech signal: The orderly output constraint. Behavioral and Brain Sciences, 21:241–299.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruce Tesar</author>
<author>Paul Smolensky</author>
</authors>
<title>Learnability in Optimality Theory.</title>
<date>2000</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="1093" citStr="Tesar and Smolensky, 2000" startWordPosition="147" endWordPosition="150">orphologically complex forms to which it has not been exposed. 1 Explaining phonological patterns How do infants learn the phonetic categories and phonotactic patterns of their native languages? How strong are the biases that learners bring to the task of phonological acquistion? Phonologists from the rationalist tradition that dominated the past half-century of linguistic research typically posit strong biases in acquisition, with language learners using innatelygiven, domain-specific representations (Chomsky and Halle, 1968), constraints (Prince and Smolensky, 2004) and learning algorithms (Tesar and Smolensky, 2000; Dresher, 1999) to learn abstract rules or constraint rankings from which they can classify or produce novel instances. In the last decade, however, there has been a shift toward empiricist approaches to phonological acquisition, use and knowledge. In this literature, eager learning algorithms (Aha, 1997), in which training data are used to update intensional representations of functions or categories then discarded, have been the norm.1 However, research in related fields—particularly speech perception— indicates that speakers’ knowledge and use of language, both in production and comprehens</context>
</contexts>
<marker>Tesar, Smolensky, 2000</marker>
<rawString>Bruce Tesar and Paul Smolensky. 2000. Learnability in Optimality Theory. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Riitta V¨alimaa-Blum</author>
</authors>
<title>The phoneme in cognitive phonology: episodic memories of both meaningful and meaningless units?</title>
<date>2009</date>
<journal>Cognitextes,</journal>
<volume>2</volume>
<marker>V¨alimaa-Blum, 2009</marker>
<rawString>Riitta V¨alimaa-Blum. 2009. The phoneme in cognitive phonology: episodic memories of both meaningful and meaningless units? Cognitextes, 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harry van der Hulst</author>
<author>Jeroen van de Weijer</author>
</authors>
<title>Vowel harmony. In</title>
<date>1995</date>
<booktitle>Handbook of Phonological Theory.</booktitle>
<editor>John Goldsmith, editor,</editor>
<publisher>Blackwell.</publisher>
<marker>van der Hulst, van de Weijer, 1995</marker>
<rawString>Harry van der Hulst and Jeroen van de Weijer. 1995. Vowel harmony. In John Goldsmith, editor, Handbook of Phonological Theory. Blackwell.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>