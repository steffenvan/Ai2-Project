<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000038">
<title confidence="0.999185">
Probabilistic Labeling for Efficient Referential Grounding based on
Collaborative Discourse
</title>
<author confidence="0.999768">
Changsong Liu, Lanbo She, Rui Fang, Joyce Y. Chai
</author>
<affiliation confidence="0.9961725">
Department of Computer Science and Engineering
Michigan State University
</affiliation>
<address confidence="0.976224">
East Lansing, MI 48824
</address>
<email confidence="0.997687">
{cliu, shelanbo, fangrui, jchai}@cse.msu.edu
</email>
<sectionHeader confidence="0.993856" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999855888888889">
When humans and artificial agents (e.g.
robots) have mismatched perceptions of
the shared environment, referential com-
munication between them becomes diffi-
cult. To mediate perceptual differences,
this paper presents a new approach us-
ing probabilistic labeling for referential
grounding. This approach aims to inte-
grate different types of evidence from the
collaborative referential discourse into a
unified scheme. Its probabilistic labeling
procedure can generate multiple ground-
ing hypotheses to facilitate follow-up dia-
logue. Our empirical results have shown
the probabilistic labeling approach sig-
nificantly outperforms a previous graph-
matching approach for referential ground-
ing.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999941448275862">
In situated human-robot dialogue, humans and
robots have mismatched capabilities of perceiving
the shared environment. Thus referential commu-
nication between them becomes extremely chal-
lenging. To address this problem, our previous
work has conducted a simulation-based study to
collect a set of human-human conversation data
that explain how partners with mismatched per-
ceptions strive to succeed in referential commu-
nication (Liu et al., 2012; Liu et al., 2013). Our
data have shown that, when conversation partners
have mismatched perceptions, they tend to make
extra collaborative effort in referential commu-
nication. For example, the speaker often refers
to the intended object iteratively: first issuing an
initial installment, and then refashioning till the
hearer identifies the referent correctly. The hearer,
on the other hand, often provides useful feedback
based on which further refashioning can be made.
This data has demonstrated the importance of in-
corporating collaborative discourse for referential
grounding.
Based on this data, as a first step we developed
a graph-matching approach for referential ground-
ing (Liu et al., 2012; Liu et al., 2013). This ap-
proach uses Attributed Relational Graph to cap-
ture collaborative discourse and employs a state-
space search algorithm to find proper ground-
ing results. Although it has made meaning-
ful progress in addressing collaborative referen-
tial grounding under mismatched perceptions, the
state-space search based approach has two ma-
jor limitations. First, it is neither flexible to ob-
tain multiple grounding hypotheses, nor flexible
to incorporate different hypotheses incrementally
for follow-up grounding. Second, the search al-
gorithm tends to have a high time complexity for
optimal solutions. Thus, the previous approach
is not ideal for collaborative and incremental di-
alogue systems that interact with human users in
real time.
To address these limitations, this paper de-
scribes a new approach to referential grounding
based on probabilistic labeling. This approach
aims to integrate different types of evidence from
the collaborative referential discourse into a uni-
fied probabilistic scheme. It is formulated un-
der the Bayesian reasoning framework to easily
support generation and incorporation of multi-
ple grounding hypotheses for follow-up processes.
Our empirical results have shown that the prob-
abilistic labeling approach significantly outper-
forms the state-space search approach in both
grounding accuracy and efficiency. This new ap-
proach provides a good basis for processing col-
laborative discourse and enabling collaborative di-
alogue system in situated referential communica-
tion.
</bodyText>
<page confidence="0.988927">
13
</page>
<bodyText confidence="0.2080035">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 13–18,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</bodyText>
<equation confidence="0.4021495">
2 Related Work M: I see there is a square, but fine, it is blue (4)
D: alright, I will just go with that, so and then right under
</equation>
<bodyText confidence="0.999767178571428">
Previous works on situated referential grounding
have mainly focused on computational models that
connect linguistic referring expressions to the per-
ceived environment (Gorniak and Roy, 2004; Gor-
niak and Roy, 2007; Siebert and Schlangen, 2008;
Matuszek et al., 2012; Jayant and Thomas, 2013).
These works have provided valuable insights on
how to manually and/or automatically build key
components (e.g., semantic parsing, grounding
functions between visual features and words, map-
ping procedures) for a situated referential ground-
ing system. However, most of these works only
dealt with the interpretation of single referring ex-
pressions, rather than interrelated expressions in
collaborative dialogue.
Some earlier work (Edmonds, 1994; Heeman
and Hirst, 1995) proposed a symbolic reasoning
(i.e. planning) based approach to incorporate col-
laborative dialogue. However, in situated settings
pure symbolic approaches will not be sufficient
and new approaches that are robust to uncertain-
ties need to be pursued. DeVault and Stone (2009)
proposed a hybrid approach which combined sym-
bolic reasoning and machine learning for inter-
preting referential grounding dialogue. But their
“environment” was a simplistic block world and
the issue of mismatched perceptions was not ad-
dressed.
</bodyText>
<sectionHeader confidence="0.997289" genericHeader="introduction">
3 Data
</sectionHeader>
<bodyText confidence="0.999581266666667">
Previously, we have collected a set of human-
human dialogues on an object-naming task (Liu
et al., 2012). To simulate mismatched perceptions
between a human and an artificial agent, two par-
ticipants were shown different versions of an im-
age: the director was shown the original image
containing some randomly placed objects (e.g.,
fruits), and the matcher was shown an impov-
erished version of the image generated by com-
puter vision. They were instructed to communi-
cate with each other to figure out the identities of
some “named” objects (only known to the direc-
tor), such that the matcher could also know which
object has what name.
Here is an example excerpt from this dataset:
</bodyText>
<footnote confidence="0.6249254">
D1: there is basically a cluster of four objects in the upper
left, do you see that
M: yes
D: ok, so the one in the corner is a blue cup
1D stands for the director; M stands for the matcher.
</footnote>
<table confidence="0.900872181818182">
that is a yellow pepper
M: ok, I see apple but orangish yellow
D: ok, so that yellow pepper is named Brittany
M: uh, the bottom left of those four? Because I do see a
yellow pepper in the upper right
D: the upper right of the four of them?
M: yes
D: ok, so that is basically the one to the right of the blue
cup
M: yeah
D: that is actually an apple
</table>
<bodyText confidence="0.999972461538461">
As we can see from this example, both the direc-
tor and the matcher make extra efforts to overcome
the mismatched perceptions through collaborative
dialogue. Our ultimate goal is to develop com-
putational approaches that can ground interrelated
referring expressions to the physical world, and
enable collaborative actions of the dialogue agent
(similar to the active role that the matcher played
in the human-human dialogue). For the time be-
ing, we use this data to evaluate our computa-
tional approach for referential grounding, namely,
replacing the matcher by our automatic system to
ground the director’s referring expressions.
</bodyText>
<sectionHeader confidence="0.9550775" genericHeader="method">
4 Probabilistic Labeling for Reference
Grounding
</sectionHeader>
<subsectionHeader confidence="0.99964">
4.1 System Overview
</subsectionHeader>
<bodyText confidence="0.977905263157895">
Our system first processes the data using auto-
matic semantic parsing and coreference resolu-
tion. For semantic parsing, we use a rule-based
CCG parser (Bozsahin et al., 2005) to parse each
utterance into a formal semantic representation.
For example, the utterance “a pear is to the right
of the apple” is parsed as
[a1, a2] , [Pear(a1), Apple(a2), RightOf(a1, a2)]
which consists of a list of discourse entities (e.g.,
a1 and a2) and a list of first-order-logic predicates
that specify the unary attributes of these entities
and the binary relations between them.
We then perform pairwise coreference resolu-
tion on the discourse entities to find out the dis-
course relations between entities from different ut-
terances. Formally, let ai be a discourse entity ex-
tracted from the current utterance, and aj a dis-
course entity from a previous utterance. We train a
maximum entropy classifier2 (Manning and Klein,
</bodyText>
<footnote confidence="0.55815125">
2The features we use for the classification include the dis-
tance between ai and aj, the determiners associated with
them, the associated pronouns, the syntactic roles, the ex-
tracted unary properties, etc.
</footnote>
<page confidence="0.997015">
14
</page>
<bodyText confidence="0.99976">
2003) to predict whether ai and aj should refer to
the same object (i.e. positive) or to different ob-
jects (i.e. negative).
Based on the semantic parsing and pairwise
coreference resolution results, our system fur-
ther builds a graph representation to capture the
collaborative discourse and formulate referential
grounding as a probabilistic labeling problem, as
described next.
</bodyText>
<subsectionHeader confidence="0.996301">
4.2 Graph Representation
</subsectionHeader>
<bodyText confidence="0.960219785714286">
We use an Attributed Relational Graph (Tsai and
Fu, 1979) to represent the referential grounding
discourse (which we call the “dialogue graph”). It
is constructed based on the semantic parsing and
coreference resolution results. The dialogue graph
contains a set A of N nodes:
A = {a1, a2, ... , aN}
in which each node ai represents a discourse en-
tity from the parsing results. And for each pair
of nodes ai and aj there can be an edge aiaj that
represents the physical or discourse relation (i.e.
coreference) between the two nodes.
Furthermore, each node ai can be assigned a set
of “attributes”:
</bodyText>
<equation confidence="0.9499475">
J (1) (2) (K) l
xi = xi , xi , ... , xi J
</equation>
<bodyText confidence="0.999925757575758">
which are used to specify information about the
unary properties of the corresponding discourse
entity. Similarly, each edge aiaj can also be as-
signed a set of attributes xij to specify informa-
tion about the binary relations between two dis-
course entities. The node attributes are from the
semantic parsing results, i.e., the unary proper-
ties associated to a discourse entity. The edge at-
tributes can be either from parsing results, such
as a spatial relation between two entities (e.g.,
RightOf(a1, a2)); Or from pairwise coreference
resolution results, i.e., two entities are coreferen-
tial (coref = +) or not (coref = −).
Besides the dialogue graph that represents the
linguistic discourse, we build another graph to rep-
resent the perceived environment. This graph is
called the “vision graph” (since this graph is built
based on computer vision’s outputs). It has a set Ω
of M nodes:
the vision graph also has edges (e.g., ωαωβ), node
attributes (e.g., ˘xα) and edge attributes (e.g., ˘xαβ).
Note that the attributes in the vision graph mostly
have numeric values extracted by computer vision
algorithms, whereas the attributes in the dialogue
graph have symbolic values extracted from the lin-
guistic discourse. A set of “symbol grounding
functions” are used to bridge between the hetero-
geneous attributes (described later).
Given these two graph representations, referen-
tial grounding then can be formulated as a “node
labeling” process, that is to assign a label θi to
each node ai. The value of θi can be any of the
M node labels from the set Ω.
</bodyText>
<subsectionHeader confidence="0.999393">
4.3 Probabilistic Labeling Algorithm
</subsectionHeader>
<bodyText confidence="0.999951666666667">
The probabilistic labeling algorithm (Christmas et
al., 1995) is formulated in the Bayesian frame-
work. It provides a unified evidence-combining
scheme to integrate unary attributes, binary rela-
tions and prior knowledge for updating the label-
ing probabilities (i.e. P (θi = ωα)). The algo-
rithm finds proper labelings in an iterative manner:
it first initiates the labeling probabilities by consid-
ering only the unary attributes of each node, and
then updates the labeling probability of each node
based on the labeling of its neighbors and the rela-
tions with them.
</bodyText>
<sectionHeader confidence="0.612761" genericHeader="method">
Initialization:
</sectionHeader>
<bodyText confidence="0.968359">
Compute the initial labeling probabilities:
</bodyText>
<equation confidence="0.9979475">
P(0)(θi = ωα) = P (ai  |θi = ωα)
P (ai  |θi = ωλ) Pˆ (θi = ωλ)
</equation>
<bodyText confidence="0.999853909090909">
in which Pˆ (θi = ωα) is the prior probability of
labeling ai with ωα. The prior probability can be
used to encode any prior knowledge about possi-
ble labelings. Especially in incremental process-
ing of the dialogue, the prior can encode previ-
ous grounding hypotheses, and other information
from the collaborative dialogue such as confirma-
tion, rejection, or replacement.
P (ai  |θi = ωα) is called the “compatibility co-
efficient” between ai and ωα, which is computed
based on the attributes of ai and ωα:
</bodyText>
<equation confidence="0.9857936">
Pˆ (θi = ωα)
E
ωλ∈Ω
P (ai  |θi = ωα) = P (xi  |θi = ωα)
Ω = {ω1,ω2, ... ,ωM} and we further define ≈ � P (x(k)  |θi = ω α)
</equation>
<bodyText confidence="0.82232">
in which each node ωα represents a physical ob- k
ject in the scene. Similar to the dialogue graph,
</bodyText>
<page confidence="0.967416">
15
</page>
<bodyText confidence="0.9619003125">
where L(k) is the “lexicon” for the k-th attribute of
a dialogue graph node, e.g., for the color attribute:
L(k) = {red, green, blue,...}
and p (˘, a  |xzk)) is what we call a “symbol
grounding function”, i.e., the probability of ob-
serving ˘x(k)
α given the word x(k)
i . It judges the
compatibilities between the symbolic attribute val-
ues from the dialogue graph and the numeric at-
tribute values from the vision graph. These sym-
bol grounding functions can be either manually
defined or automatically learned. In our current
work, we use a set of manually defined ground-
ing functions motivated by previous work (Gor-
niak and Roy, 2004).
</bodyText>
<sectionHeader confidence="0.879938" genericHeader="method">
Iteration:
</sectionHeader>
<bodyText confidence="0.9999355">
Once the initial probabilities are calculated, the
labeling procedure iterates till all the labeling
probabilities have converged or the number of it-
erations has reached a specified limit. At each it-
eration and for each possible labeling, it computes
a “support function” as:
</bodyText>
<equation confidence="0.975337">
Q(n) (ei = Wα) = 11 E P(n) (ej = Wβ)
jENiωβEΩ
P (aiaj  |ei = Wα, ej = Wβ)
</equation>
<bodyText confidence="0.995281">
and updates the probability of each possible label-
ing as:
</bodyText>
<equation confidence="0.999317">
P(n+1)(ei _ Wα) = P(n)(θi=ω w
a)Q(n)(Bi=a)
( — P P(n)(θi=ωλ)Q(n)(θi=ωλ)
ωλ∈Ω
</equation>
<bodyText confidence="0.996675285714286">
The support function Q(n) (ei = Wα) expresses
how the labeling ei = Wα at the n-th itera-
tion is supported by the labeling of ai’s neigh-
bors3, taking into consideration the binary rela-
tions that exist between ai and them. Similar to
the node compatibility coefficient, the edge com-
patibility coefficient between aiaj and WαWβ ,
</bodyText>
<footnote confidence="0.658352">
3The set of indices Ni is defined as:
</footnote>
<table confidence="0.95040025">
Ni = {1, 2,..., i − 1, i + 1,... ,N}
Top-1 Top-2 Top-3
Random 7.7% 15.4% 23.1%
Guess&apos;
S.S.S. 19.1% 19.7% 21.3%
P.L. 24.9% 36.1% 45.0%
Gainb 5.8% 16.4% 23.7%
(p &lt; 0.01) (p &lt; 0.001) (p &lt; 0.001)
P.L. using 66.4% 74.8% 81.9%
annotated
coreference
&apos;Each image contains an average of 13 objects.
</table>
<tableCaption confidence="0.696047142857143">
bp-value is based on the Wilcoxon signed-rank
test (Wilcoxon et al., 1970) on the 62 dialogues.
Table 1: Comparison of the reference grounding
performances of a random guess baseline, Prob-
abilistic Labeling (P.L.) and State-Space Search
(S.S.S.), and P.L. using manually annotated coref-
erence.
</tableCaption>
<bodyText confidence="0.9991505">
namely the P (aiaj  |ei = Wα, ej = Wβ) for com-
puting Q(n) (ei = Wα), is also based on the at-
tributes of the two edges and their corresponding
symbol grounding functions. So we also man-
ually defined a set of grounding functions for
edge attributes such as the spatial relation (e.g.,
RightOf, Above). If an edge is used to encode
the discourse relation between two entities (i.e.,
the pairwise coreference results), the compatibility
coefficient can be defined as (suppose edge aiaj
encodes a positive coreference relation between
entities ai and aj):
</bodyText>
<equation confidence="0.99702075">
P (aiaj = +  |ei = Wα, ej = Wβ)
P(θi=ωα,θj=ωβ|aiaj=+)P(aiaj=+)
=
P(θi=ωα,θj=ωβ)
</equation>
<bodyText confidence="0.989096">
which can be calculated based on the results from
the coreference classifier (Section 4.1).
</bodyText>
<sectionHeader confidence="0.966886" genericHeader="evaluation">
5 Evaluation and Discussion
</sectionHeader>
<bodyText confidence="0.999992928571429">
Our dataset has 62 dialogues, each of which con-
tains an average of 25 valid utterances from the
director. We first applied the semantic parser and
coreference classifier as described in Section 4.1
to process each dialogue, and then built a graph
representation based on the automatic processing
results at the end of the dialogue. On average, a di-
alogue graph consists of 33 discourse entities from
the director’s utterances that need to be grounded.
We then applied both the probabilistic label-
ing algorithm and the state-space search algorithm
to ground each of the director’s discourse entities
onto an object perceived from the image. The av-
eraged grounding accuracies of the two algorithms
</bodyText>
<equation confidence="0.9896045">
P (x(k)  |ei = Wα) = p (xi(k)  |˘x�k))
� � � �
˘x(k)
p α |x(k) x(k)
p
i i
=
P � � � �
</equation>
<figure confidence="0.5646615">
xj ∈L(k) p ˘x(k)
(k) α |x(k) x(k)
p
j j
</figure>
<page confidence="0.993677">
16
</page>
<bodyText confidence="0.998145826086957">
are shown in the middle part of Table 1. The first
column of Table 1 shows the grounding accura-
cies of the algorithm’s top-1 grounding hypothesis
(i.e., Bi = argmax P (Bi = wα) for each i). The
wα
second and third column then show the “accura-
cies” of the top-2 and top-3 hypotheses4, respec-
tively.
As shown in Table 1, probabilistic labeling
(i.e. P.L.) significantly outperforms state-space
search (S.S.S.), especially with regard to produc-
ing meaningful multiple grounding hypotheses.
The state-space search algorithm actually only re-
sults in multiple hypotheses for the overall match-
ing, and it fails to produce multiple hypotheses
for many individual discourse entities. Multiple
grounding hypotheses can be very useful to gen-
erate responses such as clarification questions or
nonverbal feedback (e.g. pointing, gazing). For
example, if there are two competing hypotheses,
the dialogue manager can utilize them to gener-
ate a response like “I see two objects there, are
you talking about this one (pointing to) or that one
(pointing to the other)?”. Such proactive feedback
is often an effective way in referential communi-
cation (Clark and Wilkes-Gibbs, 1986; Liu et al.,
2013).
The probabilistic labeling algorithm not only
produces better grounding results, it also runs
much faster (with a running-time complexity of
O (MN2),5 comparing to O (N4) of the state-
space search algorithm6). Figure 1 shows the av-
eraged running time of the state-space search al-
gorithm on a Intel Core i7 1.60GHz CPU with
16G RAM computer (the running time of the prob-
abilistic labeling algorithm is not shown in Fig-
ure 1 since it always takes less than 1 second to
run). As we can see, when the size of the dialogue
graph becomes greater than 15, state-space search
takes more than 1 minute to run. The efficiency of
the probabilistic labeling algorithm thus makes it
more appealing for real-time interaction applica-
tions.
Although probabilistic labeling significantly
outperforms the state-space search, the grounding
performance is still rather poor (less than 50%)
</bodyText>
<footnote confidence="0.994437428571429">
4The accuracy of the top-2/top-3 grounding hypotheses is
measured by whether the ground-truth reference is included
in the top-2/top-3 hypotheses.
5M is the number of nodes in the vision graph and N is
the number of nodes in the dialogue graph.
6Beam search algorithm is applied to reduce the exponen-
tial O (MN) to O (N4).
</footnote>
<figureCaption confidence="0.897021">
Figure 1: Average running time of the state-space
search algorithm with respect to the number of
nodes to be grounded in a dialogue graph.
</figureCaption>
<bodyText confidence="0.999898235294118">
even for the top-3 hypotheses. With no surprise,
the coreference resolution performance plays an
important role in the final grounding performance
(see the grounding performance of using manually
annotated coreference in the bottom part of Ta-
ble 1). Due to the simplicity of our current coref-
erence classifier and the flexibility of the human-
human dialogue in the data, the pairwise coref-
erence resolution only achieves 0.74 in precision
and 0.43 in recall. The low recall of coreference
resolution makes it difficult to link interrelated re-
ferring expressions and resolve them jointly. So it
is important to develop more sophisticated coref-
erence resolution and dialogue management com-
ponents to reliably track the discourse relations
and other dynamics in the dialogue to facilitate ref-
erential grounding.
</bodyText>
<sectionHeader confidence="0.999358" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999970125">
In this paper, we have presented a probabilistic la-
beling based approach for referential grounding in
situated dialogue. This approach provides a uni-
fied scheme for incorporating different sources of
information. Its probabilistic scheme allows each
information source to present multiple hypotheses
to better handle uncertainties. Based on the in-
tegrated information, the labeling procedure then
efficiently generates probabilistic grounding hy-
potheses, which can serve as important guidance
for the dialogue manager’s decision making. In
future work, we will utilize probabilistic labeling
to incorporate information from verbal and non-
verbal communication incrementally as the dia-
logue unfolds, and to enable collaborative dia-
logue agents in the physical world.
</bodyText>
<sectionHeader confidence="0.998274" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.955624333333333">
This work was supported by N00014-11-1-0410
from the Office of Naval Research and IIS-
1208390 from the National Science Foundation.
</bodyText>
<page confidence="0.998818">
17
</page>
<sectionHeader confidence="0.989751" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999680717948718">
Cem Bozsahin, Geert-Jan M Kruijff, and Michael
White. 2005. Specifying grammars for openccg: A
rough guide. Included in the OpenCCG distribution.
William J. Christmas, Josef Kittler, and Maria Petrou.
1995. Structural matching in computer vision
using probabilistic relaxation. Pattern Analysis
and Machine Intelligence, IEEE Transactions on,
17(8):749–764.
Herbert H Clark and Deanna Wilkes-Gibbs. 1986.
Referring as a collaborative process. Cognition,
22(1):1–39.
David DeVault and Matthew Stone. 2009. Learning to
interpret utterances using dialogue history. In Pro-
ceedings of the 12th Conference of the European
Chapter of the Association for Computational Lin-
guistics, pages 184–192. Association for Computa-
tional Linguistics.
Philip G Edmonds. 1994. Collaboration on reference
to objects that are not mutually known. In Pro-
ceedings of the 15th conference on Computational
linguistics-Volume 2, pages 1118–1122. Association
for Computational Linguistics.
Peter Gorniak and Deb Roy. 2004. Grounded seman-
tic composition for visual scenes. J. Artif. Intell.
Res.(JAIR), 21:429–470.
Peter Gorniak and Deb Roy. 2007. Situated lan-
guage understanding as filtering perceived affor-
dances. Cognitive Science, 31(2):197–231.
Peter A Heeman and Graeme Hirst. 1995. Collabo-
rating on referring expressions. Computational Lin-
guistics, 21(3):351–382.
Krishnamurthy Jayant and Kollar Thomas. 2013.
Jointly learning to parse and perceive: Connecting
natural language to the physical world. Transac-
tions of the Association of Computational Linguis-
tics, 1:193–206.
Changsong Liu, Rui Fang, and Joyce Chai. 2012. To-
wards mediating shared perceptual basis in situated
dialogue. In Proceedings of the 13th Annual Meet-
ing of the Special Interest Group on Discourse and
Dialogue, pages 140–149, Seoul, South Korea, July.
Association for Computational Linguistics.
Changsong Liu, Rui Fang, Lanbo She, and Joyce Chai.
2013. Modeling collaborative referring for situated
referential grounding. In Proceedings of the SIG-
DIAL 2013 Conference, pages 78–86, Metz, France,
August. Association for Computational Linguistics.
Christopher Manning and Dan Klein. 2003. Opti-
mization, maxent models, and conditional estima-
tion without magic. In Proceedings of the 2003
Conference of the North American Chapter of the
Association for Computational Linguistics on Hu-
man Language Technology: Tutorials - Volume 5,
NAACL-Tutorials ’03, pages 8–8, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Cynthia Matuszek, Nicholas FitzGerald, Luke Zettle-
moyer, Liefeng Bo, and Dieter Fox. 2012. A
joint model of language and perception for grounded
attribute learning. In John Langford and Joelle
Pineau, editors, Proceedings of the 29th Interna-
tional Conference on Machine Learning (ICML-12),
ICML ’12, pages 1671–1678, New York, NY, USA,
July. Omnipress.
Alexander Siebert and David Schlangen. 2008. A
simple method for resolution of definite reference
in a shared visual context. In Proceedings of the
9th SIGdial Workshop on Discourse and Dialogue,
pages 84–87. Association for Computational Lin-
guistics.
Wen-Hsiang Tsai and King-Sun Fu. 1979. Error-
correcting isomorphisms of attributed relational
graphs for pattern analysis. Systems, Man and Cy-
bernetics, IEEE Transactions on, 9(12):757–768.
Frank Wilcoxon, SK Katti, and Roberta A Wilcox.
1970. Critical values and probability levels for the
wilcoxon rank sum test and the wilcoxon signed
rank test. Selected tables in mathematical statistics,
1:171–259.
</reference>
<page confidence="0.99929">
18
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.672909">
<title confidence="0.9993605">Probabilistic Labeling for Efficient Referential Grounding based Collaborative Discourse</title>
<author confidence="0.99551">Changsong Liu</author>
<author confidence="0.99551">Lanbo She</author>
<author confidence="0.99551">Rui Fang</author>
<author confidence="0.99551">Y Joyce</author>
<affiliation confidence="0.950174">Department of Computer Science and Michigan State</affiliation>
<address confidence="0.821495">East Lansing, MI</address>
<email confidence="0.973298">shelanbo,fangrui,</email>
<abstract confidence="0.993609105263158">When humans and artificial agents (e.g. robots) have mismatched perceptions of the shared environment, referential communication between them becomes difficult. To mediate perceptual differences, this paper presents a new approach using probabilistic labeling for referential grounding. This approach aims to integrate different types of evidence from the collaborative referential discourse into a unified scheme. Its probabilistic labeling procedure can generate multiple grounding hypotheses to facilitate follow-up dialogue. Our empirical results have shown the probabilistic labeling approach significantly outperforms a previous graphmatching approach for referential grounding.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Cem Bozsahin</author>
<author>Geert-Jan M Kruijff</author>
<author>Michael White</author>
</authors>
<title>Specifying grammars for openccg: A rough guide. Included in the OpenCCG distribution.</title>
<date>2005</date>
<contexts>
<context position="7371" citStr="Bozsahin et al., 2005" startWordPosition="1130" endWordPosition="1133">ng expressions to the physical world, and enable collaborative actions of the dialogue agent (similar to the active role that the matcher played in the human-human dialogue). For the time being, we use this data to evaluate our computational approach for referential grounding, namely, replacing the matcher by our automatic system to ground the director’s referring expressions. 4 Probabilistic Labeling for Reference Grounding 4.1 System Overview Our system first processes the data using automatic semantic parsing and coreference resolution. For semantic parsing, we use a rule-based CCG parser (Bozsahin et al., 2005) to parse each utterance into a formal semantic representation. For example, the utterance “a pear is to the right of the apple” is parsed as [a1, a2] , [Pear(a1), Apple(a2), RightOf(a1, a2)] which consists of a list of discourse entities (e.g., a1 and a2) and a list of first-order-logic predicates that specify the unary attributes of these entities and the binary relations between them. We then perform pairwise coreference resolution on the discourse entities to find out the discourse relations between entities from different utterances. Formally, let ai be a discourse entity extracted from t</context>
</contexts>
<marker>Bozsahin, Kruijff, White, 2005</marker>
<rawString>Cem Bozsahin, Geert-Jan M Kruijff, and Michael White. 2005. Specifying grammars for openccg: A rough guide. Included in the OpenCCG distribution.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William J Christmas</author>
<author>Josef Kittler</author>
<author>Maria Petrou</author>
</authors>
<title>Structural matching in computer vision using probabilistic relaxation. Pattern Analysis and Machine Intelligence,</title>
<date>1995</date>
<journal>IEEE Transactions on,</journal>
<volume>17</volume>
<issue>8</issue>
<contexts>
<context position="11008" citStr="Christmas et al., 1995" startWordPosition="1731" endWordPosition="1734">vision graph mostly have numeric values extracted by computer vision algorithms, whereas the attributes in the dialogue graph have symbolic values extracted from the linguistic discourse. A set of “symbol grounding functions” are used to bridge between the heterogeneous attributes (described later). Given these two graph representations, referential grounding then can be formulated as a “node labeling” process, that is to assign a label θi to each node ai. The value of θi can be any of the M node labels from the set Ω. 4.3 Probabilistic Labeling Algorithm The probabilistic labeling algorithm (Christmas et al., 1995) is formulated in the Bayesian framework. It provides a unified evidence-combining scheme to integrate unary attributes, binary relations and prior knowledge for updating the labeling probabilities (i.e. P (θi = ωα)). The algorithm finds proper labelings in an iterative manner: it first initiates the labeling probabilities by considering only the unary attributes of each node, and then updates the labeling probability of each node based on the labeling of its neighbors and the relations with them. Initialization: Compute the initial labeling probabilities: P(0)(θi = ωα) = P (ai |θi = ωα) P (ai</context>
</contexts>
<marker>Christmas, Kittler, Petrou, 1995</marker>
<rawString>William J. Christmas, Josef Kittler, and Maria Petrou. 1995. Structural matching in computer vision using probabilistic relaxation. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 17(8):749–764.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
<author>Deanna Wilkes-Gibbs</author>
</authors>
<title>Referring as a collaborative process.</title>
<date>1986</date>
<journal>Cognition,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="17170" citStr="Clark and Wilkes-Gibbs, 1986" startWordPosition="2800" endWordPosition="2803"> results in multiple hypotheses for the overall matching, and it fails to produce multiple hypotheses for many individual discourse entities. Multiple grounding hypotheses can be very useful to generate responses such as clarification questions or nonverbal feedback (e.g. pointing, gazing). For example, if there are two competing hypotheses, the dialogue manager can utilize them to generate a response like “I see two objects there, are you talking about this one (pointing to) or that one (pointing to the other)?”. Such proactive feedback is often an effective way in referential communication (Clark and Wilkes-Gibbs, 1986; Liu et al., 2013). The probabilistic labeling algorithm not only produces better grounding results, it also runs much faster (with a running-time complexity of O (MN2),5 comparing to O (N4) of the statespace search algorithm6). Figure 1 shows the averaged running time of the state-space search algorithm on a Intel Core i7 1.60GHz CPU with 16G RAM computer (the running time of the probabilistic labeling algorithm is not shown in Figure 1 since it always takes less than 1 second to run). As we can see, when the size of the dialogue graph becomes greater than 15, state-space search takes more t</context>
</contexts>
<marker>Clark, Wilkes-Gibbs, 1986</marker>
<rawString>Herbert H Clark and Deanna Wilkes-Gibbs. 1986. Referring as a collaborative process. Cognition, 22(1):1–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David DeVault</author>
<author>Matthew Stone</author>
</authors>
<title>Learning to interpret utterances using dialogue history.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>184--192</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5029" citStr="DeVault and Stone (2009)" startWordPosition="727" endWordPosition="730">c parsing, grounding functions between visual features and words, mapping procedures) for a situated referential grounding system. However, most of these works only dealt with the interpretation of single referring expressions, rather than interrelated expressions in collaborative dialogue. Some earlier work (Edmonds, 1994; Heeman and Hirst, 1995) proposed a symbolic reasoning (i.e. planning) based approach to incorporate collaborative dialogue. However, in situated settings pure symbolic approaches will not be sufficient and new approaches that are robust to uncertainties need to be pursued. DeVault and Stone (2009) proposed a hybrid approach which combined symbolic reasoning and machine learning for interpreting referential grounding dialogue. But their “environment” was a simplistic block world and the issue of mismatched perceptions was not addressed. 3 Data Previously, we have collected a set of humanhuman dialogues on an object-naming task (Liu et al., 2012). To simulate mismatched perceptions between a human and an artificial agent, two participants were shown different versions of an image: the director was shown the original image containing some randomly placed objects (e.g., fruits), and the ma</context>
</contexts>
<marker>DeVault, Stone, 2009</marker>
<rawString>David DeVault and Matthew Stone. 2009. Learning to interpret utterances using dialogue history. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, pages 184–192. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip G Edmonds</author>
</authors>
<title>Collaboration on reference to objects that are not mutually known.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th conference on Computational linguistics-Volume 2,</booktitle>
<pages>1118--1122</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4729" citStr="Edmonds, 1994" startWordPosition="684" endWordPosition="685">ing expressions to the perceived environment (Gorniak and Roy, 2004; Gorniak and Roy, 2007; Siebert and Schlangen, 2008; Matuszek et al., 2012; Jayant and Thomas, 2013). These works have provided valuable insights on how to manually and/or automatically build key components (e.g., semantic parsing, grounding functions between visual features and words, mapping procedures) for a situated referential grounding system. However, most of these works only dealt with the interpretation of single referring expressions, rather than interrelated expressions in collaborative dialogue. Some earlier work (Edmonds, 1994; Heeman and Hirst, 1995) proposed a symbolic reasoning (i.e. planning) based approach to incorporate collaborative dialogue. However, in situated settings pure symbolic approaches will not be sufficient and new approaches that are robust to uncertainties need to be pursued. DeVault and Stone (2009) proposed a hybrid approach which combined symbolic reasoning and machine learning for interpreting referential grounding dialogue. But their “environment” was a simplistic block world and the issue of mismatched perceptions was not addressed. 3 Data Previously, we have collected a set of humanhuman</context>
</contexts>
<marker>Edmonds, 1994</marker>
<rawString>Philip G Edmonds. 1994. Collaboration on reference to objects that are not mutually known. In Proceedings of the 15th conference on Computational linguistics-Volume 2, pages 1118–1122. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Gorniak</author>
<author>Deb Roy</author>
</authors>
<title>Grounded semantic composition for visual scenes.</title>
<date>2004</date>
<journal>J. Artif. Intell. Res.(JAIR),</journal>
<pages>21--429</pages>
<contexts>
<context position="4183" citStr="Gorniak and Roy, 2004" startWordPosition="603" endWordPosition="606">course and enabling collaborative dialogue system in situated referential communication. 13 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 13–18, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Related Work M: I see there is a square, but fine, it is blue (4) D: alright, I will just go with that, so and then right under Previous works on situated referential grounding have mainly focused on computational models that connect linguistic referring expressions to the perceived environment (Gorniak and Roy, 2004; Gorniak and Roy, 2007; Siebert and Schlangen, 2008; Matuszek et al., 2012; Jayant and Thomas, 2013). These works have provided valuable insights on how to manually and/or automatically build key components (e.g., semantic parsing, grounding functions between visual features and words, mapping procedures) for a situated referential grounding system. However, most of these works only dealt with the interpretation of single referring expressions, rather than interrelated expressions in collaborative dialogue. Some earlier work (Edmonds, 1994; Heeman and Hirst, 1995) proposed a symbolic reasonin</context>
<context position="12991" citStr="Gorniak and Roy, 2004" startWordPosition="2087" endWordPosition="2091">is the “lexicon” for the k-th attribute of a dialogue graph node, e.g., for the color attribute: L(k) = {red, green, blue,...} and p (˘, a |xzk)) is what we call a “symbol grounding function”, i.e., the probability of observing ˘x(k) α given the word x(k) i . It judges the compatibilities between the symbolic attribute values from the dialogue graph and the numeric attribute values from the vision graph. These symbol grounding functions can be either manually defined or automatically learned. In our current work, we use a set of manually defined grounding functions motivated by previous work (Gorniak and Roy, 2004). Iteration: Once the initial probabilities are calculated, the labeling procedure iterates till all the labeling probabilities have converged or the number of iterations has reached a specified limit. At each iteration and for each possible labeling, it computes a “support function” as: Q(n) (ei = Wα) = 11 E P(n) (ej = Wβ) jENiωβEΩ P (aiaj |ei = Wα, ej = Wβ) and updates the probability of each possible labeling as: P(n+1)(ei _ Wα) = P(n)(θi=ω w a)Q(n)(Bi=a) ( — P P(n)(θi=ωλ)Q(n)(θi=ωλ) ωλ∈Ω The support function Q(n) (ei = Wα) expresses how the labeling ei = Wα at the n-th iteration is support</context>
</contexts>
<marker>Gorniak, Roy, 2004</marker>
<rawString>Peter Gorniak and Deb Roy. 2004. Grounded semantic composition for visual scenes. J. Artif. Intell. Res.(JAIR), 21:429–470.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Gorniak</author>
<author>Deb Roy</author>
</authors>
<title>Situated language understanding as filtering perceived affordances.</title>
<date>2007</date>
<journal>Cognitive Science,</journal>
<volume>31</volume>
<issue>2</issue>
<contexts>
<context position="4206" citStr="Gorniak and Roy, 2007" startWordPosition="607" endWordPosition="611">laborative dialogue system in situated referential communication. 13 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 13–18, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Related Work M: I see there is a square, but fine, it is blue (4) D: alright, I will just go with that, so and then right under Previous works on situated referential grounding have mainly focused on computational models that connect linguistic referring expressions to the perceived environment (Gorniak and Roy, 2004; Gorniak and Roy, 2007; Siebert and Schlangen, 2008; Matuszek et al., 2012; Jayant and Thomas, 2013). These works have provided valuable insights on how to manually and/or automatically build key components (e.g., semantic parsing, grounding functions between visual features and words, mapping procedures) for a situated referential grounding system. However, most of these works only dealt with the interpretation of single referring expressions, rather than interrelated expressions in collaborative dialogue. Some earlier work (Edmonds, 1994; Heeman and Hirst, 1995) proposed a symbolic reasoning (i.e. planning) based</context>
</contexts>
<marker>Gorniak, Roy, 2007</marker>
<rawString>Peter Gorniak and Deb Roy. 2007. Situated language understanding as filtering perceived affordances. Cognitive Science, 31(2):197–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter A Heeman</author>
<author>Graeme Hirst</author>
</authors>
<title>Collaborating on referring expressions.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>3</issue>
<contexts>
<context position="4754" citStr="Heeman and Hirst, 1995" startWordPosition="686" endWordPosition="689"> to the perceived environment (Gorniak and Roy, 2004; Gorniak and Roy, 2007; Siebert and Schlangen, 2008; Matuszek et al., 2012; Jayant and Thomas, 2013). These works have provided valuable insights on how to manually and/or automatically build key components (e.g., semantic parsing, grounding functions between visual features and words, mapping procedures) for a situated referential grounding system. However, most of these works only dealt with the interpretation of single referring expressions, rather than interrelated expressions in collaborative dialogue. Some earlier work (Edmonds, 1994; Heeman and Hirst, 1995) proposed a symbolic reasoning (i.e. planning) based approach to incorporate collaborative dialogue. However, in situated settings pure symbolic approaches will not be sufficient and new approaches that are robust to uncertainties need to be pursued. DeVault and Stone (2009) proposed a hybrid approach which combined symbolic reasoning and machine learning for interpreting referential grounding dialogue. But their “environment” was a simplistic block world and the issue of mismatched perceptions was not addressed. 3 Data Previously, we have collected a set of humanhuman dialogues on an object-n</context>
</contexts>
<marker>Heeman, Hirst, 1995</marker>
<rawString>Peter A Heeman and Graeme Hirst. 1995. Collaborating on referring expressions. Computational Linguistics, 21(3):351–382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Krishnamurthy Jayant</author>
<author>Kollar Thomas</author>
</authors>
<title>Jointly learning to parse and perceive: Connecting natural language to the physical world.</title>
<date>2013</date>
<journal>Transactions of the Association of Computational Linguistics,</journal>
<pages>1--193</pages>
<contexts>
<context position="4284" citStr="Jayant and Thomas, 2013" startWordPosition="620" endWordPosition="623">dings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 13–18, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Related Work M: I see there is a square, but fine, it is blue (4) D: alright, I will just go with that, so and then right under Previous works on situated referential grounding have mainly focused on computational models that connect linguistic referring expressions to the perceived environment (Gorniak and Roy, 2004; Gorniak and Roy, 2007; Siebert and Schlangen, 2008; Matuszek et al., 2012; Jayant and Thomas, 2013). These works have provided valuable insights on how to manually and/or automatically build key components (e.g., semantic parsing, grounding functions between visual features and words, mapping procedures) for a situated referential grounding system. However, most of these works only dealt with the interpretation of single referring expressions, rather than interrelated expressions in collaborative dialogue. Some earlier work (Edmonds, 1994; Heeman and Hirst, 1995) proposed a symbolic reasoning (i.e. planning) based approach to incorporate collaborative dialogue. However, in situated settings</context>
</contexts>
<marker>Jayant, Thomas, 2013</marker>
<rawString>Krishnamurthy Jayant and Kollar Thomas. 2013. Jointly learning to parse and perceive: Connecting natural language to the physical world. Transactions of the Association of Computational Linguistics, 1:193–206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Changsong Liu</author>
<author>Rui Fang</author>
<author>Joyce Chai</author>
</authors>
<title>Towards mediating shared perceptual basis in situated dialogue.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue,</booktitle>
<pages>140--149</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Seoul, South</location>
<contexts>
<context position="1436" citStr="Liu et al., 2012" startWordPosition="193" endWordPosition="196"> Our empirical results have shown the probabilistic labeling approach significantly outperforms a previous graphmatching approach for referential grounding. 1 Introduction In situated human-robot dialogue, humans and robots have mismatched capabilities of perceiving the shared environment. Thus referential communication between them becomes extremely challenging. To address this problem, our previous work has conducted a simulation-based study to collect a set of human-human conversation data that explain how partners with mismatched perceptions strive to succeed in referential communication (Liu et al., 2012; Liu et al., 2013). Our data have shown that, when conversation partners have mismatched perceptions, they tend to make extra collaborative effort in referential communication. For example, the speaker often refers to the intended object iteratively: first issuing an initial installment, and then refashioning till the hearer identifies the referent correctly. The hearer, on the other hand, often provides useful feedback based on which further refashioning can be made. This data has demonstrated the importance of incorporating collaborative discourse for referential grounding. Based on this da</context>
<context position="5383" citStr="Liu et al., 2012" startWordPosition="783" endWordPosition="786">symbolic reasoning (i.e. planning) based approach to incorporate collaborative dialogue. However, in situated settings pure symbolic approaches will not be sufficient and new approaches that are robust to uncertainties need to be pursued. DeVault and Stone (2009) proposed a hybrid approach which combined symbolic reasoning and machine learning for interpreting referential grounding dialogue. But their “environment” was a simplistic block world and the issue of mismatched perceptions was not addressed. 3 Data Previously, we have collected a set of humanhuman dialogues on an object-naming task (Liu et al., 2012). To simulate mismatched perceptions between a human and an artificial agent, two participants were shown different versions of an image: the director was shown the original image containing some randomly placed objects (e.g., fruits), and the matcher was shown an impoverished version of the image generated by computer vision. They were instructed to communicate with each other to figure out the identities of some “named” objects (only known to the director), such that the matcher could also know which object has what name. Here is an example excerpt from this dataset: D1: there is basically a</context>
</contexts>
<marker>Liu, Fang, Chai, 2012</marker>
<rawString>Changsong Liu, Rui Fang, and Joyce Chai. 2012. Towards mediating shared perceptual basis in situated dialogue. In Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 140–149, Seoul, South Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Changsong Liu</author>
<author>Rui Fang</author>
<author>Lanbo She</author>
<author>Joyce Chai</author>
</authors>
<title>Modeling collaborative referring for situated referential grounding.</title>
<date>2013</date>
<booktitle>In Proceedings of the SIGDIAL 2013 Conference,</booktitle>
<pages>78--86</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Metz, France,</location>
<contexts>
<context position="1455" citStr="Liu et al., 2013" startWordPosition="197" endWordPosition="200">ults have shown the probabilistic labeling approach significantly outperforms a previous graphmatching approach for referential grounding. 1 Introduction In situated human-robot dialogue, humans and robots have mismatched capabilities of perceiving the shared environment. Thus referential communication between them becomes extremely challenging. To address this problem, our previous work has conducted a simulation-based study to collect a set of human-human conversation data that explain how partners with mismatched perceptions strive to succeed in referential communication (Liu et al., 2012; Liu et al., 2013). Our data have shown that, when conversation partners have mismatched perceptions, they tend to make extra collaborative effort in referential communication. For example, the speaker often refers to the intended object iteratively: first issuing an initial installment, and then refashioning till the hearer identifies the referent correctly. The hearer, on the other hand, often provides useful feedback based on which further refashioning can be made. This data has demonstrated the importance of incorporating collaborative discourse for referential grounding. Based on this data, as a first step</context>
<context position="17189" citStr="Liu et al., 2013" startWordPosition="2804" endWordPosition="2807">s for the overall matching, and it fails to produce multiple hypotheses for many individual discourse entities. Multiple grounding hypotheses can be very useful to generate responses such as clarification questions or nonverbal feedback (e.g. pointing, gazing). For example, if there are two competing hypotheses, the dialogue manager can utilize them to generate a response like “I see two objects there, are you talking about this one (pointing to) or that one (pointing to the other)?”. Such proactive feedback is often an effective way in referential communication (Clark and Wilkes-Gibbs, 1986; Liu et al., 2013). The probabilistic labeling algorithm not only produces better grounding results, it also runs much faster (with a running-time complexity of O (MN2),5 comparing to O (N4) of the statespace search algorithm6). Figure 1 shows the averaged running time of the state-space search algorithm on a Intel Core i7 1.60GHz CPU with 16G RAM computer (the running time of the probabilistic labeling algorithm is not shown in Figure 1 since it always takes less than 1 second to run). As we can see, when the size of the dialogue graph becomes greater than 15, state-space search takes more than 1 minute to run</context>
</contexts>
<marker>Liu, Fang, She, Chai, 2013</marker>
<rawString>Changsong Liu, Rui Fang, Lanbo She, and Joyce Chai. 2013. Modeling collaborative referring for situated referential grounding. In Proceedings of the SIGDIAL 2013 Conference, pages 78–86, Metz, France, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Manning</author>
<author>Dan Klein</author>
</authors>
<title>Optimization, maxent models, and conditional estimation without magic.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology: Tutorials - Volume 5, NAACL-Tutorials ’03,</booktitle>
<pages>8--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Manning, Klein, 2003</marker>
<rawString>Christopher Manning and Dan Klein. 2003. Optimization, maxent models, and conditional estimation without magic. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology: Tutorials - Volume 5, NAACL-Tutorials ’03, pages 8–8, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cynthia Matuszek</author>
<author>Nicholas FitzGerald</author>
<author>Luke Zettlemoyer</author>
<author>Liefeng Bo</author>
<author>Dieter Fox</author>
</authors>
<title>A joint model of language and perception for grounded attribute learning.</title>
<date>2012</date>
<booktitle>In John Langford and Joelle Pineau, editors, Proceedings of the 29th International Conference on Machine Learning (ICML-12), ICML ’12,</booktitle>
<pages>1671--1678</pages>
<publisher>Omnipress.</publisher>
<location>New York, NY, USA,</location>
<contexts>
<context position="4258" citStr="Matuszek et al., 2012" startWordPosition="616" endWordPosition="619">ommunication. 13 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 13–18, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Related Work M: I see there is a square, but fine, it is blue (4) D: alright, I will just go with that, so and then right under Previous works on situated referential grounding have mainly focused on computational models that connect linguistic referring expressions to the perceived environment (Gorniak and Roy, 2004; Gorniak and Roy, 2007; Siebert and Schlangen, 2008; Matuszek et al., 2012; Jayant and Thomas, 2013). These works have provided valuable insights on how to manually and/or automatically build key components (e.g., semantic parsing, grounding functions between visual features and words, mapping procedures) for a situated referential grounding system. However, most of these works only dealt with the interpretation of single referring expressions, rather than interrelated expressions in collaborative dialogue. Some earlier work (Edmonds, 1994; Heeman and Hirst, 1995) proposed a symbolic reasoning (i.e. planning) based approach to incorporate collaborative dialogue. How</context>
</contexts>
<marker>Matuszek, FitzGerald, Zettlemoyer, Bo, Fox, 2012</marker>
<rawString>Cynthia Matuszek, Nicholas FitzGerald, Luke Zettlemoyer, Liefeng Bo, and Dieter Fox. 2012. A joint model of language and perception for grounded attribute learning. In John Langford and Joelle Pineau, editors, Proceedings of the 29th International Conference on Machine Learning (ICML-12), ICML ’12, pages 1671–1678, New York, NY, USA, July. Omnipress.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Siebert</author>
<author>David Schlangen</author>
</authors>
<title>A simple method for resolution of definite reference in a shared visual context.</title>
<date>2008</date>
<booktitle>In Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>84--87</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4235" citStr="Siebert and Schlangen, 2008" startWordPosition="612" endWordPosition="615">tem in situated referential communication. 13 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 13–18, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Related Work M: I see there is a square, but fine, it is blue (4) D: alright, I will just go with that, so and then right under Previous works on situated referential grounding have mainly focused on computational models that connect linguistic referring expressions to the perceived environment (Gorniak and Roy, 2004; Gorniak and Roy, 2007; Siebert and Schlangen, 2008; Matuszek et al., 2012; Jayant and Thomas, 2013). These works have provided valuable insights on how to manually and/or automatically build key components (e.g., semantic parsing, grounding functions between visual features and words, mapping procedures) for a situated referential grounding system. However, most of these works only dealt with the interpretation of single referring expressions, rather than interrelated expressions in collaborative dialogue. Some earlier work (Edmonds, 1994; Heeman and Hirst, 1995) proposed a symbolic reasoning (i.e. planning) based approach to incorporate coll</context>
</contexts>
<marker>Siebert, Schlangen, 2008</marker>
<rawString>Alexander Siebert and David Schlangen. 2008. A simple method for resolution of definite reference in a shared visual context. In Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 84–87. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wen-Hsiang Tsai</author>
<author>King-Sun Fu</author>
</authors>
<title>Errorcorrecting isomorphisms of attributed relational graphs for pattern analysis.</title>
<date>1979</date>
<journal>Systems, Man and Cybernetics, IEEE Transactions on,</journal>
<volume>9</volume>
<issue>12</issue>
<contexts>
<context position="8774" citStr="Tsai and Fu, 1979" startWordPosition="1353" endWordPosition="1356"> the distance between ai and aj, the determiners associated with them, the associated pronouns, the syntactic roles, the extracted unary properties, etc. 14 2003) to predict whether ai and aj should refer to the same object (i.e. positive) or to different objects (i.e. negative). Based on the semantic parsing and pairwise coreference resolution results, our system further builds a graph representation to capture the collaborative discourse and formulate referential grounding as a probabilistic labeling problem, as described next. 4.2 Graph Representation We use an Attributed Relational Graph (Tsai and Fu, 1979) to represent the referential grounding discourse (which we call the “dialogue graph”). It is constructed based on the semantic parsing and coreference resolution results. The dialogue graph contains a set A of N nodes: A = {a1, a2, ... , aN} in which each node ai represents a discourse entity from the parsing results. And for each pair of nodes ai and aj there can be an edge aiaj that represents the physical or discourse relation (i.e. coreference) between the two nodes. Furthermore, each node ai can be assigned a set of “attributes”: J (1) (2) (K) l xi = xi , xi , ... , xi J which are used t</context>
</contexts>
<marker>Tsai, Fu, 1979</marker>
<rawString>Wen-Hsiang Tsai and King-Sun Fu. 1979. Errorcorrecting isomorphisms of attributed relational graphs for pattern analysis. Systems, Man and Cybernetics, IEEE Transactions on, 9(12):757–768.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Wilcoxon</author>
<author>SK Katti</author>
<author>Roberta A Wilcox</author>
</authors>
<title>Critical values and probability levels for the wilcoxon rank sum test and the wilcoxon signed rank test. Selected tables in mathematical statistics,</title>
<date>1970</date>
<pages>1--171</pages>
<contexts>
<context position="14217" citStr="Wilcoxon et al., 1970" startWordPosition="2306" endWordPosition="2309">y the labeling of ai’s neighbors3, taking into consideration the binary relations that exist between ai and them. Similar to the node compatibility coefficient, the edge compatibility coefficient between aiaj and WαWβ , 3The set of indices Ni is defined as: Ni = {1, 2,..., i − 1, i + 1,... ,N} Top-1 Top-2 Top-3 Random 7.7% 15.4% 23.1% Guess&apos; S.S.S. 19.1% 19.7% 21.3% P.L. 24.9% 36.1% 45.0% Gainb 5.8% 16.4% 23.7% (p &lt; 0.01) (p &lt; 0.001) (p &lt; 0.001) P.L. using 66.4% 74.8% 81.9% annotated coreference &apos;Each image contains an average of 13 objects. bp-value is based on the Wilcoxon signed-rank test (Wilcoxon et al., 1970) on the 62 dialogues. Table 1: Comparison of the reference grounding performances of a random guess baseline, Probabilistic Labeling (P.L.) and State-Space Search (S.S.S.), and P.L. using manually annotated coreference. namely the P (aiaj |ei = Wα, ej = Wβ) for computing Q(n) (ei = Wα), is also based on the attributes of the two edges and their corresponding symbol grounding functions. So we also manually defined a set of grounding functions for edge attributes such as the spatial relation (e.g., RightOf, Above). If an edge is used to encode the discourse relation between two entities (i.e., t</context>
</contexts>
<marker>Wilcoxon, Katti, Wilcox, 1970</marker>
<rawString>Frank Wilcoxon, SK Katti, and Roberta A Wilcox. 1970. Critical values and probability levels for the wilcoxon rank sum test and the wilcoxon signed rank test. Selected tables in mathematical statistics, 1:171–259.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>