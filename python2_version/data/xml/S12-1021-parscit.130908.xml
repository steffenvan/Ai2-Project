<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000565">
<title confidence="0.995368">
An Unsupervised Ranking Model for Noun-Noun Compositionality
</title>
<author confidence="0.999342">
Karl Moritz Hermann, Phil Blunsom, and Stephen Pulman
</author>
<affiliation confidence="0.997819">
Department of Computer Science
University of Oxford
</affiliation>
<address confidence="0.9911705">
Wolfson Building, Parks Road
Oxford OX1 3QD, UK
</address>
<email confidence="0.999452">
{karl.moritz.hermann,phil.blunsom,stephen.pulman}@cs.ox.ac.uk
</email>
<sectionHeader confidence="0.995649" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999692363636364">
We propose an unsupervised system that
learns continuous degrees of lexicality for
noun-noun compounds, beating a strong base-
line on several tasks. We demonstrate that the
distributional representations of compounds
and their parts can be used to learn a fine-
grained representation of semantic contribu-
tion. Finally, we argue such a representation
captures compositionality better than the cur-
rent status-quo which treats compositionality
as a binary classification problem.
</bodyText>
<sectionHeader confidence="0.998929" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99489075">
A Multiword Expressions (MWE) can be defined as
a sequence of words whose meaning cannot nec-
essarily be derived from the meaning of the words
making up that sequence, for example:
</bodyText>
<subsectionHeader confidence="0.411798">
Rat Race — self-defeating or pointless pursuit1
</subsectionHeader>
<bodyText confidence="0.999769636363636">
MWEs are considered a “key problem for the de-
velopment of large-scale, linguistically sound nat-
ural language processing technology” (Sag et al.,
2002). The challenge posed by MWEs is three-
fold, consisting of MWE identification, classifica-
tion and interpretation. Following the identification
of a MWE, it needs to be established whether the
expression should be treated as lexical (idiomatic)
or as compositional. The final step, learning the se-
mantics of the MWE, strongly depends on this deci-
sion.
</bodyText>
<footnote confidence="0.6820915">
1Definition taken from Wikipedia, and clearly not recover-
able if one only knows the meaning of the words ‘rat’ and ‘race’.
</footnote>
<bodyText confidence="0.999909058823529">
The problem posed by MWEs is considered hard,
but at the same time it is highly relevant and inter-
esting. MWEs occur frequently in language and in-
terpreting them correctly would directly improve re-
sults in a number of tasks in NLP such as translation
and parsing (Korkontzelos and Manandhar, 2010).
By extension this makes deciding the lexicality of
MWEs an important challenge for various fields in-
cluding machine translation, question answering and
information retrieval. In this paper we discuss com-
positionality with respect to noun-noun compounds.
Most Computational Linguistics literature treats
compositionality as a binary problem, classifying
compounds as either lexical or compositional. We
show that this approach is too simplistic and argue
for the real-valued treatment of compositionality.
We propose two unsupervised models that learn
compositionality rankings for compounds, placing
them on a scale between lexical and compositional
extremes. We develop a fine-grained representa-
tion of compositionality using a novel generative ap-
proach that models context as generated by com-
pound constituents. This representation differenti-
ates between the semantic contribution of both com-
pound constituents as well as the compound itself.
Comparing it with existing work in the field, we
demonstrate the competitiveness of our approach.
We evaluate on an existing corpus of noun com-
pounds with ranked compositionality data, as well
as on a large corpus with a binary annotation for lex-
ical and compositional compounds. We analyse the
impact of data sparsity and propose an interpolation
approximation which significantly reduces the effect
of sparsity on model performance.
</bodyText>
<page confidence="0.960926">
132
</page>
<note confidence="0.978835">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 132–141,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.997411" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999903750000001">
Interpreting MWEs is a difficult task as “compound
nouns can be freely constructed” (Sp¨arck Jones,
1985), and are thus able to proliferate infinitely. At
the same time, semantic composition can take many
different forms, making uniform interpretation of
compounds impossible (Zanzotto et al., 2010).
Most current work on MWEs focuses on inter-
preting compounds and sidesteps the task of deter-
mining whether a compound is compositional in the
first place (Butnariu et al., 2010; Kim and Baldwin,
2008). Such methods, aimed at learning the seman-
tics of compounds, can roughly be divided into two
major strands of research.
One group relies on data intensive methods to ex-
tract semantics vectors from large corpora (Baroni
and Zamparelli, 2010; Zanzotto et al., 2010; Gies-
brecht, 2009). The focus of these approaches is to
develop methods for composing the vectors of un-
igrams into a semantic vector representing a com-
pound. Some of the work in this area touches on the
issue of lexicality, as models learning distributional
representations of MWEs ideally would first estab-
lish whether a given MWE is compositional or not
(Mitchell and Lapata, 2010).
The other group are knowledge intensive ap-
proaches collecting linguistic features (Kim and
Baldwin, 2005; Korkontzelos and Manandhar,
2009). Tratz and Hovy (2010), for instance, train
a classifier for noun compound interpretation on a
large set of WORDNET and Thesaurus features.
Combined approaches include Kim and Baldwin
(2008), who interpret noun compounds by extrapo-
lating their semantics from observations where the
two nouns forming a compound are in an intransi-
tive relationship. For example extracting the phrase
‘the family owns a car’ from the training data would
help learn that the compound ‘family car’ describes
a POSSESSOR-OWNED/POSSESSED relationship.
Some of these supervised classifiers include lexi-
cality as a classification option, considering it jointly
with the actual compound interpretation.
Next to the work on MWE interpretation there has
been some work focused on determining lexicality
in its own right (Reddy et al., 2011; Bu et al., 2010;
Kim and Baldwin, 2007).
One possibility is to exploit special properties of
lexical MWEs such as high statistical association
of their constituents (Pedersen, 2011) or syntactic
rigidity (Fazly et al., 2009; McCarthy et al., 2007).
However, these approaches are limited in their ap-
plicability to compound nouns (Reddy et al., 2011).
Another method is to compare the semantics of
a compound and its constituents to decide com-
positionality. The approaches used to determine
those semantics can again be divided into knowl-
edge intensive and data-driven methods. Depending
on the chosen representation of semantics these ap-
proaches can either be used for supervised classifiers
or together with a distance metric comparing vector
space representations of semantics. In a binary set-
ting, a threshold would then be applied to the result
of that distance function (Korkontzelos and Man-
andhar, 2009). In a real-valued setting the distance
metric itself can be used as a measure for compo-
sitionality (Reddy et al., 2011). Related to the vec-
tor space based models, some research focuses on
improving the distance metrics used to compare in-
duced semantics (Bu et al., 2010).
</bodyText>
<sectionHeader confidence="0.998153" genericHeader="method">
3 Methodology
</sectionHeader>
<bodyText confidence="0.999762777777778">
English noun-noun compounds are majority left-
branching (Lauer, 1995), with a head (the second
element), modified by an attributive noun (first el-
ement). For example:
Ground Floor — The floor of a building at or near-
est ground level.2
In this paper, we will use the terms attributive noun
(AN) and head noun (HN) to refer to the first and
second noun in a noun compound.
</bodyText>
<subsectionHeader confidence="0.992946">
3.1 Real-Valued Representation
</subsectionHeader>
<bodyText confidence="0.998553888888889">
Lexicality of MWEs is frequently treated as a bi-
nary property (Tratz and Hovy, 2010; O´ S´eaghdha,
2007). We argue that lexicality should instead be
treated as a graded property, as most compound se-
mantics exhibit a mixture of compositional and lexi-
cal influences. For example, ‘cocktail dress’ derives
a large part of its semantics from ‘dress’, but the
compound also contributes an idiosyncratic element
to its meaning.
</bodyText>
<footnote confidence="0.997193">
2Definition from http://www.thefreedictionary.com
</footnote>
<page confidence="0.99896">
133
</page>
<bodyText confidence="0.999903066666667">
We define lexicality as the degree to which id-
iosyncrasy contributes to a compound’s semantics.
Inversely phrased, the compositionality of a com-
pound can be defined as the degree to which its sense
is related to the senses of its constituents.3
This graded representation follows Sp¨arck Jones
(1985), who argued that “it is not possible to main-
tain a principled distinction between lexicalised and
non-lexicalised compounds”. Some recent work
also supports this view (Reddy et al., 2011; Bu et
al., 2010; Baldwin, 2006). From a practical per-
spective, a real-valued representation of composi-
tionality should help improve interpretation of com-
pounds. This is especially true when factoring in the
respective semantic contributions of its parts.
</bodyText>
<subsectionHeader confidence="0.999602">
3.2 Context Generation
</subsectionHeader>
<bodyText confidence="0.999927583333334">
According to the distributional hypothesis, the se-
mantics of a lexical item can be expressed by its
context. We apply this hypothesis to the problem of
noun compound compositionality by using a genera-
tive model on compound context. Our model allows
context to be generated by the compound itself or by
either one of its constituents. By learning which el-
ement of the compound generates which part of its
context we effectively determine the semantic con-
tribution of each element. This in turn gives us a
fine-grained, graded representation of a compound’s
lexicality.
</bodyText>
<sectionHeader confidence="0.999167" genericHeader="method">
4 Corpora for Evaluation
</sectionHeader>
<subsectionHeader confidence="0.894757">
4.1 Ranked Corpus — REDDY
</subsectionHeader>
<bodyText confidence="0.992462222222222">
As we want to evaluate our models’ ability to learn
lexicality as a real-valued property, we require an
annotated data set of noun compounds ranked by
lexicality. To the best of our knowledge the only
such data set was developed by Reddy et al. (2011).
This data set contains 90 distinct noun compounds
with real-valued gold standard scores ranking from
0 (lexical) to 5 (compositional). The compounds
are nearly linearly distributed across the [0;5] range,
with inter annotator agreement (Spearman’s p) of
3For example, the meaning of ‘gravy train’ has hardly any
relation to either ‘gravy’ or ‘train’. Its semantics are thus highly
dependent on the compound in its own right. On the other end
of the spectrum, ‘climate change’ is significantly related to both
‘climate’ and ‘change’, contributing little inherent semantics to
its overall meaning.
0.522. We refer to this data set and evaluation as
REDDY throughout this paper.
</bodyText>
<subsectionHeader confidence="0.988032">
4.2 Binary Corpora — TRATZ
</subsectionHeader>
<bodyText confidence="0.99999146875">
We also apply our models to a second, binary classi-
fication task. Tratz and Hovy (2010) compiled a data
set for noun compound interpretation, which classi-
fies noun compounds based on their internal struc-
ture. We use this corpus to extract lexical and com-
positional noun compounds.
After some pre-processing4 the data set contains
18,858 compositional and 118 lexical noun com-
pounds. We believe this to more accurately represent
the real world distribution of lexical and composi-
tional noun compounds: Tratz and Hovy (2010) ex-
tracted noun compounds from several large corpora
including the Wall Street Journal section of the Penn
Treebank, thus obtaining a reasonable approxima-
tion of real world occurrence. Other collections of
noun compounds ( O´ S´eaghdha, 2007) feature sim-
ilar proportions of lexical and compositional noun
compounds.
The large bias towards compositional noun com-
pounds does not support the status-quo of treating
compositionality as a binary property. As discussed
earlier, we assume that most compounds have a
compositional as well as a lexical element. While
the compositional aspect may be larger for most
compounds this alone does not suffice as a reason
to disregard the lexical element contained in these
compounds.
In order to evaluate our system on the TRATZ
data, we use receiving operator characteristic (ROC)
curves. ROC analysis enables us to evaluate a rank-
ing model without setting an artificial threshold for
the compositionality/lexicality decision.
</bodyText>
<sectionHeader confidence="0.97773" genericHeader="method">
5 Baseline Approach
</sectionHeader>
<bodyText confidence="0.99988025">
We develop a set of advanced baselines related to
the semi-supervised models presented by Reddy et
al. (2011). We define the context K of a noun com-
pound as all words in all sentences the compound
appears in. From this we calculate distributional
representations of a compound (c = (a, h)) and its
constituent elements a, h. We refer to these repre-
sentations as c� for the compound and ta, h for the
</bodyText>
<footnote confidence="0.907543">
4We removed trigrams from the data set.
</footnote>
<page confidence="0.991986">
134
</page>
<table confidence="0.824195833333333">
Name ® r p
ADD w.Sac + (1 − w).Shc .323 .567
MULT Sac.Shc .379 .551
MIN min(Sac, Shc) .343 .550
MAX max(Sac, Shc) .299 .505
COMB w1.Sac+w2.Shc+w3.Sac.Shc .366 .556
</table>
<tableCaption confidence="0.944293833333333">
Table 1: Results of COSLEX with different operators on
the REDDY data set, reporting Pearson’s r and Spear-
man’s p correlations. Weights for operators ADD (w =
0.3) and COMB (w = (0.3, 0.1, 0.6)) are manually opti-
mised. Values range from -1 (negative correlation) to +1
(perfect correlation) with 0 describing random data.
</tableCaption>
<bodyText confidence="0.9995226">
attributive and head noun, respectively. We can cal-
culate the cosine similarity based lexicality score
(COSLEX) by combining the cosine similarity of the
compound’s distribution with each of its two con-
stituents (Reddy et al., 2011).
</bodyText>
<equation confidence="0.990503">
Sac = sim(a,I
Shc = sim( K,cl
COSLEX(c) = Sac ® Shc
</equation>
<bodyText confidence="0.999986111111111">
We evaluate a number of alternative operators ® for
combining Sac and Shc. Results for this baseline
on the REDDY corpus are in Table 1,5 with weights
wi on the combination operators manually optimised
for Spearman’s p on that data set. In effect this
renders this baseline into a supervised approach, so
we would expect it to perform very well. We use
the best performing operators (ADD with w = 0.3,
MULT) as baselines for this paper.
</bodyText>
<sectionHeader confidence="0.99949" genericHeader="method">
6 Generative Models
</sectionHeader>
<bodyText confidence="0.992765666666667">
We exploit the distributional hypothesis to model
the semantic contribution of the different elements
of a noun compound. For this, we require a sys-
tem that treats a noun compound as a vector of three
semantics-bearing units: the compound itself, its
head and its attributive noun. This system should
then model the relationship between the context of
the compound and these three units, deciding which
of them is responsible for each context element.
5Reddy et al. (2011) report higher figures on our baseline
models. The differences are attributed to differences in training
data and parametrization.
</bodyText>
<subsectionHeader confidence="0.997966">
6.1 3-way Compound Mixture
</subsectionHeader>
<bodyText confidence="0.989366707317073">
We model a corpus D of tuples d = {c, k1, ..., kn}.
Each tuple d contains a noun compound c = (a, h)
and its context words K = (k1, ..., kn). We use vo-
cabularies Vc for noun compounds, Va for attributive
nouns, Vh for head nouns and Vk for context.
We condition our generative model on the noun
compounds. Given an observation d of a compound
c, we generate each context word in two steps. First,
we choose one of the compounds three elements6 to
generate the next context word. Second, we gener-
ate a new context word conditioned on that element.
Formally, the context is generated as follows.
We draw three multinomial parameters Tc, Ta
and Th from Dirichlet distributions with parameters
ac, aa and ah. Tc represents the distribution over
context words Vk given compound c. Ta and Th
are distributions over Vk given attributive noun a and
head noun h, respectively. These three distributions
form the mixture components of our model.
A fourth multinomial parameter Tz, drawn from
a Dirichlet distribution with parameter az, controls
the distribution over the mixture components. Tz is
specific to each compound c, so multiple observa-
tions of the same compound share this parameter.
For each context word we draw a mixture compo-
nent zc,i E {c, a, h} from the multinomial distribu-
tion with parameter Tz. zc,i determines which dis-
tribution the context word itself will be drawn from.
Finally, we draw the context word:
Ali: ki  |T{z-,i} �Multi(T{z`,i})
Thus, for each observation of a compound noun we
have a vector z, = (z1, ..., zn) detailing how its
context words were created either by the compound
itself or by one of its constituents. To determine lex-
icality, we are interested in learning the multinomial
parameter Tz, which describes to what extent the
compound and its constituents contribute to the gen-
eration of the context (i.e. semantics). We can ap-
proximate Tz from the vector z,
We define the lexicality score Lex(c) for a com-
pound as the percentage of context words created by
</bodyText>
<footnote confidence="0.983029">
6The compound itself, its attributive noun and its head noun
</footnote>
<page confidence="0.993392">
135
</page>
<figureCaption confidence="0.999237">
Figure 1: Plate diagram illustrating the MULT-CMPD
model with context words ki drawn from a mixture model
with three components controlled by zi.
</figureCaption>
<bodyText confidence="0.91077">
the compound and not one of its constituents:
</bodyText>
<equation confidence="0.997214">
Lex(c) = p(z=c|(a,h)), (1)
</equation>
<bodyText confidence="0.997278625">
where c = (a, h)
Figure 1 shows a plate diagram of this model, which
we will refer to as MULT-CMPD.
One hypothesis encoded in model MULT-CMPD
is that deciding which part of a compound (the com-
pound itself, the head or the attributive noun) gen-
erates context is a single decision. An alternative
representation could treat this as a two-step process,
which we encode in a second model BIN-CMPD.
The intuition behind the BIN-CMPD model is that
there are two distinct decisions. First, whether a
compound is compositional or not. Second, whether
(in the compositional case) its semantics stem from
its head or attributive noun
Where MULT-CMPD uses a three component mix-
ture to determine which multinomial distribution to
use, BIN-CMPD uses two cascaded binary mixtures
(see Figure 2). The BIN-CMPD model first chooses
whether to treat a compound as compositional or
lexical. If the compound is determined as composi-
tional, a second binary mixture determines whether
to generate a context word using the attributive (Ta)
or head multinomial (Th). For the lexical case, the
model remains unchanged.
</bodyText>
<figureCaption confidence="0.912914333333333">
Figure 2: Schematic description of compositional-
ity/lexicality decision for models MULT-CMPD and BIN-
CMPD.
</figureCaption>
<table confidence="0.9992556">
Model r p
COSLEX (ADD) .323 .567
COSLEX (MULT) .379 .551
MULT-CMPD .141 .435
BIN-CMPD .168 .410
</table>
<tableCaption confidence="0.983717666666667">
Table 2: Results on the REDDY data set, reporting Pear-
son’s r and Spearman’s p correlations. Values range from
-1 (negative correlation) to +1 (perfect correlation).
</tableCaption>
<sectionHeader confidence="0.428606" genericHeader="method">
6.1.1 Inference and Sampling
</sectionHeader>
<bodyText confidence="0.999965666666667">
We use Gibbs sampling to learn the vectors z for
each instance d, integrating out the parameters T&apos;.
We train our models on the British National Corpus
(BNC), extracting all noun-noun compounds from a
parsed version of the corpus.
In order to speed up convergence of the sampler,
we use simulated annealing over the first 20 iter-
ations (Kirkpatrick et al., 1983), helping the ran-
domly initialised model reach a mode faster. We re-
port results using marginal distributions after a fur-
ther 130 iterations, excluding the counts of the an-
nealing stage.
</bodyText>
<subsectionHeader confidence="0.545337">
6.1.2 Evaluation
</subsectionHeader>
<bodyText confidence="0.999947142857143">
We evaluate our two models on the REDDY data
set by comparing its scores for lexicality (Lex(c))
with the annotated gold standard. The aim of this
evaluation is to determine how accurately the mod-
els can capture gradual distinctions in lexicality. The
ROC analysis on the TRATZ data set furthermore in-
forms us how precise the models are at distinguish-
ing lexical from compositional compounds.
Results of the REDDY evaluation are in Table 2.
We use Spearman’s p to measure the monotonic cor-
relation of our data to the gold standard. Pearson’s r
additionally captures the linear relationship between
the data, taking into account the relative differences
in Lex(c) scores among noun compounds.
</bodyText>
<page confidence="0.998551">
136
</page>
<figureCaption confidence="0.997936">
Figure 3: ROC analysis of models MULT-CMPD and
BIN-CMPD versus the best COSLEX baseline (ADD) on
the TRATZ data set
</figureCaption>
<bodyText confidence="0.999909375">
While both models, BIN-CMPD and MULT-
CMPD, clearly learn a correlation with lexical-
ity rankings, they underperform the strong, semi-
supervised COSLEX baselines described earlier in
this paper. The second evaluation, on the binary
TRATZ data set shows a different picture (see Fig-
ure 3). The best COSLEX baseline (ADD with
w = 0.2) fails to outperform random choice on this
task. Both generative models clearly beat COSLEX
on this task, with MULT-CMPD in particular per-
forming very well for low sensitivity.
There is no clear distinction in performance be-
tween the two generative approaches. Further anal-
ysis might help us to separate the two more clearly,
and we will continue using both models throughout
this paper.
It is important to note the different performance of
the generative models vs. the cosine similarity ap-
proach on two tasks. The REDDY data set has a
nearly linear distribution of compositionality scores,
while the TRATZ data set is overwhelmingly com-
positional, which more closely represents the real
world distribution of compounds. The poor perfor-
mance of the cosine similarity approach (COSLEX)
on the TRATZ evaluation suggests the limitations
of this approach when applied to more realistic data
such as this data set. An additional explanation for
the semi-supervised baseline’s poorer result is that
the effect of parameter tuning decreases on larger
data.
Investigating the errors made by the models
MULT-CMPD and BIN-CMPD gives rise to a number
of possible explanations for their performance. The
most promising lead is related to data sparsity, with
many of the evaluated noun-noun compounds only
appearing once or twice in the corpus. This makes it
harder for our generative approach to learn sensible
context distributions for these instances.
We will next investigate how to reduce the effects
encountered by sparsity.
</bodyText>
<subsectionHeader confidence="0.987052">
6.2 Interpolation
</subsectionHeader>
<bodyText confidence="0.999960166666667">
Working on problems related to non-unigram data,
sparsity is a frequently encountered problem. As al-
ready explored in the previous section, this is also
the case for our generative models of lexicality.
It would be possible to use an even larger training
corpus, but there are limitations as to what extent
this is possible. The BNC, containing 100 million
words, is already one of the largest corpora regu-
larly used in Computational Linguistics. However,
adding more data in an unsupervised sense is un-
likely to significantly improve results (Brants et al.,
2007).
Alternatively, it would be possible to add spe-
cific training data that included the noun compounds
from the evaluation data sets. This would, how-
ever, compromise the unsupervised nature of our ap-
proach, and it thus not an option either.
In this paper, we will instead focus on extenuat-
ing the effects of data sparsity through other unsu-
pervised means. For this purpose we investigate in-
terpolating on a larger set of noun compounds.
Kim and Baldwin (2007) observed that seman-
tic similarity of verb-particle compounds correlates
with their lexicality. We extend this observation for
noun compounds, hypothesising that the lexicality
of similar words will be similar. We combine this
with the assumption that noun compounds sharing a
constituent are likely to be semantically similar (Ko-
rkontzelos and Manandhar, 2009).
Using this idea, we can approximate the lexical-
ity of a given compound with the lexicality scores of
all compounds sharing either of its constituents. So
far we have calculated the lexicality of a given com-
pound using the formula Lex(c) in Equation 1. The
formula Clex(c) in Equation 2 averages the lexical-
ity scores of a compound with those of its related
</bodyText>
<page confidence="0.996438">
137
</page>
<table confidence="0.993201222222222">
Function and Model r p
COSLEX (ADD) .323 .567
COSLEX (MULT) .379 .551
Lex(c) MULT-CMPD .141 .435
BIN-CMPD .168 .410
Clex(c) MULT-CMPD .357 .596
BIN-CMPD .400 .592
Ilex(c) MULT-CMPD .422 .621
BIN-CMPD .538 .623
</table>
<tableCaption confidence="0.874982666666667">
Table 3: Results on the REDDY data set, reporting
Pearson’s r and Spearman’s p correlations, comparing
Ilex(c) and Clec(c) interpolations with Lex(c).
</tableCaption>
<bodyText confidence="0.998750285714286">
compounds. As p(z=1|(a, h)) directly influences
both p(z=1|(a,·)) and p(z=1|(·,h)), we can also
consider dropping it from the approximation such as
in Equation 3. This approach trades some specificity
in favour of reducing sparsity, as we observe more
instances of such related compounds than of a par-
ticular noun compound itself only.
</bodyText>
<equation confidence="0.985465">
Lex(c) ≈ Clex(c) (2)
Clex(c) = p(z=1|ha, ·i) + p(z=1|h·, hi) + p(z=1|ha, hi)
,
3
</equation>
<bodyText confidence="0.569376">
where c = ha, hi
</bodyText>
<equation confidence="0.98062">
Lex(c) ≈ Ilex(c) (3)
Ilex(c) = p(z=1|ha, ·i) + p(z=1|h·, hi) ,
2
</equation>
<bodyText confidence="0.99933605">
where c = ha, hi
Both formulations enable us to better deal with
sparse data as decisions are made based on a wider
range of observations. At the same time, we avoid a
loss of specificity as the models and scores are still
highly dependent on the individual noun compound.
We avoid introducing additional degrees of free-
dom by using uniform weights only. However, it
would be simple to turn this approach into a semi-
supervised model by tuning the weights for the dif-
ferent probabilities involved in calculating Clex(c)
and Lex(c). That approach would be comparable to
the operators used on our COSLEX baselines.
Results on the REDDY data set using Clex(c)
and Ilex(c) are in Table 3. Figure 4 shows the im-
pact of these approximations on the Tratz data for
the BIN-CMPD model. These interpolations suggest
strong improvements in performance. It should es-
pecially be noted that Ilex(c) consistently outper-
forms Clex(c), which indicates the strength of the
</bodyText>
<figureCaption confidence="0.994843666666667">
Figure 4: ROC analysis of model BIN-CMPD on the
TRATZ data set, comparing Ilex(c) and Clec(c) inter-
polations with Lex(c).
</figureCaption>
<bodyText confidence="0.996744375">
related-compound probabilities over the individual
compound probabilities.
These results confirm our suspicion that sparsity
was a major factor affecting our models’ perfor-
mance. Furthermore, they strengthen our hypothe-
sis about the relatedness of semantic similarity and
lexicality and demonstrate a sensible approach for
exploiting this relationship.
</bodyText>
<sectionHeader confidence="0.966171" genericHeader="evaluation">
7 Analysis
</sectionHeader>
<bodyText confidence="0.99993635">
We use this section for qualitative evaluation, com-
plementing the quantitative evaluation in the previ-
ous sections. The purpose of the qualitative evalu-
ation is to better understand exactly what it is our
models are learning.
Table 5 lists the compounds that model BIN-
CMPD considers the most lexical and the most com-
positional. The list of compounds with the high lex-
icality scores is dominated by proper nouns such as
countries, companies and persons. This is in line
with expectation as compounds of proper nouns are
fully lexical. Removing proper nouns (also in Table
5), we get a slightly more ambiguous list. For exam-
ple, ‘study design’ is not considered a lexical com-
pound, but rather a highly institutionalized, com-
positional MWE (Sag et al., 2002). Using Lex(c)
‘study design’ is ranked as such, so this appears to
be a case where interpolation has a negative impact.
In this paper we argued for a finer grained analysis
of compositionality, taking into account the differ-
</bodyText>
<page confidence="0.99577">
138
</page>
<table confidence="0.987702416666667">
Context of ‘flea market’ generated by
flea market flea market
canal, wall, incline, stall, Paris, sale, barter, souvenir,
campsite Saturday, week, launderette,
Sunday, quarter, Lamine, Canet,
damage, change Kouyate, Plage
Context of ‘night owl’ generated by
night owl night owl
court, fee, guest, waive, player, adventurous
early, day, Baden, Halikarnas, bar,
membership, life, bird, unbooked,
game Vienna
Context of ‘memory lane’ generated by
memory lane memory lane
take, story, about, village, protection, war, justify, bill,
tell, real, glimpse, drive, catwalk, Campbell, rude-
Britain, reminis- plant boys
cence
Context of ‘melting pot’ generated by
melting pot melting pot
forest, racial, in, into, put, polit- ethnic, greatest,
caribbean, plan, ical, community, drawing, liaise,
programme, real- prepare pan-european,
ity, arrangement myth
</table>
<tableCaption confidence="0.9900825">
Table 4: Overview over context words generated by model BIN-CMPD. We list a selection of words predominately
generated by each of the mixture components of the given noun-noun compound.
</tableCaption>
<subsectionHeader confidence="0.846145">
Most Compositional
</subsectionHeader>
<bodyText confidence="0.998633">
labour union, tax authority, health council,
market counterparty, employment policy
</bodyText>
<subsectionHeader confidence="0.813697">
Most Lexical
</subsectionHeader>
<bodyText confidence="0.9953365">
study design, family motto, wood shaving,
avoidance behaviour, smash hit
</bodyText>
<subsectionHeader confidence="0.772797">
Most Lexical (including Proper Nouns)
</subsectionHeader>
<bodyText confidence="0.662962">
Vo Quy, Bonito Oliva, Mamur Zapt, Evander
Holyfield, Saudi Arabia
</bodyText>
<tableCaption confidence="0.9935845">
Table 5: Top lexical and compositional nouns for the
BIN-CMPD model using Ilex(c)
</tableCaption>
<bodyText confidence="0.999813066666667">
ent impact of both constituents. We tried to achieve
this by modelling a compound’s context as gener-
ated from its various semantic constituents. Table 4
highlights the impact of this method for a number
of noun compounds, showing which context words
were predominately generated by each constituent.
Due to the nature of the context used, some of
the links are semantically not obvious (e.g. the rela-
tionship between owls and Vienna). In some cases
the semantic contribution of the parts is more clearly
separated, such as the contributions of ‘memory’ and
‘lane’ to the semantics of ‘memory lane’. In sum-
mary, these examples clearly suggest that our mod-
els learn to associate context with compound ele-
ments and that this association is an informed one.
</bodyText>
<sectionHeader confidence="0.998306" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999973181818182">
We proposed a novel approach for learning lexicality
scores for noun compounds and empirically demon-
strated the feasiblity of this approach. Using a gen-
erative model we were able to beat a strong, semi-
supervised baseline with an unsupervised model.
We discussed the issue of data sparsity in depth
and proposed several approaches for overcoming
this problem. Focusing on unsupervised approaches,
we demonstrated how interpolation can be used to
tackle sparsity. The two interpolation methods that
we implemented helped us to strongly improve over-
all model performance. Our empirical evaluation of
interpolation metrics Clex(c) and Ilex(c) also gives
credence to the hypothesis that lexicality is related to
semantic similarity.
On the theoretical side, we offered further support
to the real-valued treatment of lexicality.
Further work will include using larger training
corpora. While the BNC is a popular corpus in Com-
putational Linguistics, it proved to be too small to
learn sensible representations for a number of com-
pounds encountered in the test data. Using larger
corpora will also allow us to further study and re-
duce the sparsity issues encountered.
To study the relationship between constituent and
compound compositionality in greater depth, we
will also investigate alternative approaches for in-
terpolation. Similarity measures that consider the
semantic relevance of individual context elements
should also be considered as a next step.
Another obvious source of future work is to ap-
ply our approach to general collocations beyond the
special case of noun compounds only.
</bodyText>
<sectionHeader confidence="0.998299" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.996950333333333">
The authors would like to acknowledge the use of
the Oxford Supercomputing Centre (OSC) in carry-
ing out this work.
</bodyText>
<page confidence="0.998485">
139
</page>
<sectionHeader confidence="0.990159" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999852714285714">
Timothy Baldwin. 2006. Compositionality and mul-
tiword expressions: Six of one, half a dozen of the
other? In Proceedings of the Workshop on Multiword
Expressions: Identifying and Exploiting Underlying
Properties, page 1, Sydney, Australia. Association for
Computational Linguistics.
Marco Baroni and Roberto Zamparelli. 2010. Nouns
are vectors, adjectives are matrices: representing
adjective-noun constructions in semantic space. In
Proceedings of the 2010 Conference on Empirical
Methods in Natural Language Processing, EMNLP
’10, pages 1183–1193, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
Thorsten Brants, Ashok C. Popat, Peng Xu, Franz J.
Och, and Jeffrey Dean. 2007. Large Language Mod-
els in Machine Translation. In Proceedings of the
2007 Joint Conference on Empirical Methods in Nat-
ural Language Processing and Computational Natu-
ral Language Learning (EMNLP-CoNLL), pages 858–
867.
Fan Bu, Xiaoyan Zhu, and Ming Li. 2010. Measuring
the non-compositionality of multiword expressions. In
Proceedings of the 23rd International Conference on
Computational Linguistics, COLING ’10, pages 116–
124, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Cristina Butnariu, Su Nam Kim, Preslav Nakov, Diar-
muid ´O. S´eaghdha, Stan Szpakowicz, and Tony Veale.
2010. Semeval-2010 task 9: The interpretation of
noun compounds using paraphrasing verbs and prepo-
sitions. In Proceedings of the 5th International Work-
shop on Semantic Evaluation, SemEval ’10, pages 39–
44, Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Afsaneh Fazly, Paul Cook, and Suzanne Stevenson.
2009. Unsupervised type and token identification
of idiomatic expressions. Computational Linguistics,
35(1):61–103.
Eugenie Giesbrecht. 2009. In search of semantic com-
positionality in vector spaces. In Proceedings of the
17th International Conference on Conceptual Struc-
tures: Conceptual Structures: Leveraging Semantic
Technologies, ICCS ’09, pages 173–184, Berlin, Hei-
delberg. Springer-Verlag.
Su Nam Kim and Timothy Baldwin. 2005. Automatic
interpretation of noun compounds using wordnet simi-
larity. In In Proceedings of the 2nd International Joint
Conference on Natural Language Processing, Jeju Is-
land, South Korea, 1113, pages 945–956.
Su Nam Kim and Timothy Baldwin. 2007. Detect-
ing compositionality of English verb-particle construc-
tions using semantic similarity. In Proceedings of the
7th Meeting of the Pacific Association for Computa-
tional Linguistics, PACLING ’07, pages 40–48.
Su Nam Kim and Timothy Baldwin. 2008. An unsu-
pervised approach to interpreting noun compounds. In
Natural Language Processing and Knowledge Engi-
neering, 2008. NLP-KE ’08. International Conference
on, pages 1–7.
S. Kirkpatrick, C. D. Gelatt, and M. P. Vecchi. 1983.
Optimization by simulated annealing. Science,
220(4598):671–680.
Ioannis Korkontzelos and Suresh Manandhar. 2009. De-
tecting compositionality in multi-word expressions.
In Proceedings of the ACL-IJCNLP 2009 Conference
Short Papers, ACLShort ’09, pages 65–68, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Ioannis Korkontzelos and Suresh Manandhar. 2010. Can
recognising multiword expressions improve shallow
parsing? In Human Language Technologies: The
2010 Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
HLT ’10, pages 636–644, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
Mark Lauer. 1995. Corpus statistics meet the noun com-
pound: some empirical results. In Proceedings of
the 33rd annual meeting on Association for Compu-
tational Linguistics, ACL ’95, pages 47–54, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Diana McCarthy, Sriram Venkatapathy, and Aravind
Joshi. 2007. Detecting compositionality of verb-
object combinations using selectional preferences. In
Proceedings of the 2007 Joint Conference on Empir-
ical Methods in Natural Language Processing and
Computational Natural Language Learning (EMNLP-
CoNLL), pages 369–379, Prague, Czech Republic. As-
sociation for Computational Linguistics.
Jeff Mitchell and Mirella Lapata. 2010. Composition in
distributional models of semantics. Cognitive Science,
34(8):1388–1429.
Diarmuid O´ S´eaghdha. 2007. Annotating and learning
compound noun semantics. In Proceedings of the 45th
Annual Meeting of the ACL: Student Research Work-
shop, ACL ’07, pages 73–78, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Ted Pedersen. 2011. Identifying collocations to mea-
sure compositionality: shared task system description.
In Proceedings of the Workshop on Distributional Se-
mantics and Compositionality, DiSCo ’11, pages 33–
37, Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Siva Reddy, Diana McCarthy, and Suresh Manandhar.
2011. An empirical study on compositionality in com-
</reference>
<page confidence="0.972074">
140
</page>
<reference confidence="0.998969962962963">
pound nouns. In Proceedings of The 5th Interna-
tional Joint Conference on Natural Language Process-
ing 2011 (IJCNLP 2011), Chiang Mai, Thailand.
Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann
Copestake, and Dan Flickinger. 2002. Multiword ex-
pressions: A pain in the neck for NLP. In In Proc.
of the 3rd International Conference on Intelligent Text
Processing and Computational Linguistics (CICLing-
2002, pages 1–15.
Karen Sp¨arck Jones. 1985. Compound noun interpre-
tation problems. In Frank Fallside and William A.
Woods, editors, Computer speech processing, pages
363–381. Prentice Hall International (UK) Ltd., Hert-
fordshire, UK, UK.
Stephen Tratz and Eduard Hovy. 2010. A taxonomy,
dataset, and classifier for automatic noun compound
interpretation. In Proceedings of the 48th Annual
Meeting of the Association for Computational Linguis-
tics, ACL ’10, pages 678–687, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Fabio Massimo Zanzotto, Ioannis Korkontzelos,
Francesca Fallucchi, and Suresh Manandhar. 2010.
Estimating linear models for compositional dis-
tributional semantics. In Proceedings of the 23rd
International Conference on Computational Linguis-
tics, COLING ’10, pages 1263–1271, Stroudsburg,
PA, USA. Association for Computational Linguistics.
</reference>
<page confidence="0.99825">
141
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.287465">
<title confidence="0.999767">An Unsupervised Ranking Model for Noun-Noun Compositionality</title>
<author confidence="0.999667">Karl Moritz Hermann</author>
<author confidence="0.999667">Phil Blunsom</author>
<author confidence="0.999667">Stephen</author>
<affiliation confidence="0.9973555">Department of Computer University of</affiliation>
<note confidence="0.4320905">Wolfson Building, Parks Oxford OX1 3QD,</note>
<abstract confidence="0.999519333333333">We propose an unsupervised system that learns continuous degrees of lexicality for noun-noun compounds, beating a strong baseline on several tasks. We demonstrate that the distributional representations of compounds and their parts can be used to learn a finegrained representation of semantic contribution. Finally, we argue such a representation captures compositionality better than the current status-quo which treats compositionality as a binary classification problem.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
</authors>
<title>Compositionality and multiword expressions: Six of one, half a dozen of the other?</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties,</booktitle>
<pages>page</pages>
<institution>1, Sydney, Australia. Association for Computational Linguistics.</institution>
<contexts>
<context position="8188" citStr="Baldwin, 2006" startWordPosition="1255" endWordPosition="1256">n idiosyncratic element to its meaning. 2Definition from http://www.thefreedictionary.com 133 We define lexicality as the degree to which idiosyncrasy contributes to a compound’s semantics. Inversely phrased, the compositionality of a compound can be defined as the degree to which its sense is related to the senses of its constituents.3 This graded representation follows Sp¨arck Jones (1985), who argued that “it is not possible to maintain a principled distinction between lexicalised and non-lexicalised compounds”. Some recent work also supports this view (Reddy et al., 2011; Bu et al., 2010; Baldwin, 2006). From a practical perspective, a real-valued representation of compositionality should help improve interpretation of compounds. This is especially true when factoring in the respective semantic contributions of its parts. 3.2 Context Generation According to the distributional hypothesis, the semantics of a lexical item can be expressed by its context. We apply this hypothesis to the problem of noun compound compositionality by using a generative model on compound context. Our model allows context to be generated by the compound itself or by either one of its constituents. By learning which e</context>
</contexts>
<marker>Baldwin, 2006</marker>
<rawString>Timothy Baldwin. 2006. Compositionality and multiword expressions: Six of one, half a dozen of the other? In Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties, page 1, Sydney, Australia. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Roberto Zamparelli</author>
</authors>
<title>Nouns are vectors, adjectives are matrices: representing adjective-noun constructions in semantic space.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10,</booktitle>
<pages>1183--1193</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4234" citStr="Baroni and Zamparelli, 2010" startWordPosition="628" endWordPosition="631">e thus able to proliferate infinitely. At the same time, semantic composition can take many different forms, making uniform interpretation of compounds impossible (Zanzotto et al., 2010). Most current work on MWEs focuses on interpreting compounds and sidesteps the task of determining whether a compound is compositional in the first place (Butnariu et al., 2010; Kim and Baldwin, 2008). Such methods, aimed at learning the semantics of compounds, can roughly be divided into two major strands of research. One group relies on data intensive methods to extract semantics vectors from large corpora (Baroni and Zamparelli, 2010; Zanzotto et al., 2010; Giesbrecht, 2009). The focus of these approaches is to develop methods for composing the vectors of unigrams into a semantic vector representing a compound. Some of the work in this area touches on the issue of lexicality, as models learning distributional representations of MWEs ideally would first establish whether a given MWE is compositional or not (Mitchell and Lapata, 2010). The other group are knowledge intensive approaches collecting linguistic features (Kim and Baldwin, 2005; Korkontzelos and Manandhar, 2009). Tratz and Hovy (2010), for instance, train a class</context>
</contexts>
<marker>Baroni, Zamparelli, 2010</marker>
<rawString>Marco Baroni and Roberto Zamparelli. 2010. Nouns are vectors, adjectives are matrices: representing adjective-noun constructions in semantic space. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10, pages 1183–1193, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Ashok C Popat</author>
<author>Peng Xu</author>
<author>Franz J Och</author>
<author>Jeffrey Dean</author>
</authors>
<title>Large Language Models in Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>858--867</pages>
<contexts>
<context position="21392" citStr="Brants et al., 2007" startWordPosition="3419" endWordPosition="3422"> the effects encountered by sparsity. 6.2 Interpolation Working on problems related to non-unigram data, sparsity is a frequently encountered problem. As already explored in the previous section, this is also the case for our generative models of lexicality. It would be possible to use an even larger training corpus, but there are limitations as to what extent this is possible. The BNC, containing 100 million words, is already one of the largest corpora regularly used in Computational Linguistics. However, adding more data in an unsupervised sense is unlikely to significantly improve results (Brants et al., 2007). Alternatively, it would be possible to add specific training data that included the noun compounds from the evaluation data sets. This would, however, compromise the unsupervised nature of our approach, and it thus not an option either. In this paper, we will instead focus on extenuating the effects of data sparsity through other unsupervised means. For this purpose we investigate interpolating on a larger set of noun compounds. Kim and Baldwin (2007) observed that semantic similarity of verb-particle compounds correlates with their lexicality. We extend this observation for noun compounds, </context>
</contexts>
<marker>Brants, Popat, Xu, Och, Dean, 2007</marker>
<rawString>Thorsten Brants, Ashok C. Popat, Peng Xu, Franz J. Och, and Jeffrey Dean. 2007. Large Language Models in Machine Translation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 858– 867.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fan Bu</author>
<author>Xiaoyan Zhu</author>
<author>Ming Li</author>
</authors>
<title>Measuring the non-compositionality of multiword expressions.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics, COLING ’10,</booktitle>
<pages>116--124</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="5611" citStr="Bu et al., 2010" startWordPosition="842" endWordPosition="845">mpounds by extrapolating their semantics from observations where the two nouns forming a compound are in an intransitive relationship. For example extracting the phrase ‘the family owns a car’ from the training data would help learn that the compound ‘family car’ describes a POSSESSOR-OWNED/POSSESSED relationship. Some of these supervised classifiers include lexicality as a classification option, considering it jointly with the actual compound interpretation. Next to the work on MWE interpretation there has been some work focused on determining lexicality in its own right (Reddy et al., 2011; Bu et al., 2010; Kim and Baldwin, 2007). One possibility is to exploit special properties of lexical MWEs such as high statistical association of their constituents (Pedersen, 2011) or syntactic rigidity (Fazly et al., 2009; McCarthy et al., 2007). However, these approaches are limited in their applicability to compound nouns (Reddy et al., 2011). Another method is to compare the semantics of a compound and its constituents to decide compositionality. The approaches used to determine those semantics can again be divided into knowledge intensive and data-driven methods. Depending on the chosen representation </context>
<context position="8172" citStr="Bu et al., 2010" startWordPosition="1251" endWordPosition="1254">lso contributes an idiosyncratic element to its meaning. 2Definition from http://www.thefreedictionary.com 133 We define lexicality as the degree to which idiosyncrasy contributes to a compound’s semantics. Inversely phrased, the compositionality of a compound can be defined as the degree to which its sense is related to the senses of its constituents.3 This graded representation follows Sp¨arck Jones (1985), who argued that “it is not possible to maintain a principled distinction between lexicalised and non-lexicalised compounds”. Some recent work also supports this view (Reddy et al., 2011; Bu et al., 2010; Baldwin, 2006). From a practical perspective, a real-valued representation of compositionality should help improve interpretation of compounds. This is especially true when factoring in the respective semantic contributions of its parts. 3.2 Context Generation According to the distributional hypothesis, the semantics of a lexical item can be expressed by its context. We apply this hypothesis to the problem of noun compound compositionality by using a generative model on compound context. Our model allows context to be generated by the compound itself or by either one of its constituents. By </context>
</contexts>
<marker>Bu, Zhu, Li, 2010</marker>
<rawString>Fan Bu, Xiaoyan Zhu, and Ming Li. 2010. Measuring the non-compositionality of multiword expressions. In Proceedings of the 23rd International Conference on Computational Linguistics, COLING ’10, pages 116– 124, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristina Butnariu</author>
<author>Su Nam Kim</author>
<author>Preslav Nakov</author>
<author>Diarmuid ´O S´eaghdha</author>
<author>Stan Szpakowicz</author>
<author>Tony Veale</author>
</authors>
<title>Semeval-2010 task 9: The interpretation of noun compounds using paraphrasing verbs and prepositions.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation, SemEval ’10,</booktitle>
<pages>39--44</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Butnariu, Kim, Nakov, S´eaghdha, Szpakowicz, Veale, 2010</marker>
<rawString>Cristina Butnariu, Su Nam Kim, Preslav Nakov, Diarmuid ´O. S´eaghdha, Stan Szpakowicz, and Tony Veale. 2010. Semeval-2010 task 9: The interpretation of noun compounds using paraphrasing verbs and prepositions. In Proceedings of the 5th International Workshop on Semantic Evaluation, SemEval ’10, pages 39– 44, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Afsaneh Fazly</author>
<author>Paul Cook</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Unsupervised type and token identification of idiomatic expressions.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>1</issue>
<contexts>
<context position="5819" citStr="Fazly et al., 2009" startWordPosition="873" endWordPosition="876">ining data would help learn that the compound ‘family car’ describes a POSSESSOR-OWNED/POSSESSED relationship. Some of these supervised classifiers include lexicality as a classification option, considering it jointly with the actual compound interpretation. Next to the work on MWE interpretation there has been some work focused on determining lexicality in its own right (Reddy et al., 2011; Bu et al., 2010; Kim and Baldwin, 2007). One possibility is to exploit special properties of lexical MWEs such as high statistical association of their constituents (Pedersen, 2011) or syntactic rigidity (Fazly et al., 2009; McCarthy et al., 2007). However, these approaches are limited in their applicability to compound nouns (Reddy et al., 2011). Another method is to compare the semantics of a compound and its constituents to decide compositionality. The approaches used to determine those semantics can again be divided into knowledge intensive and data-driven methods. Depending on the chosen representation of semantics these approaches can either be used for supervised classifiers or together with a distance metric comparing vector space representations of semantics. In a binary setting, a threshold would then </context>
</contexts>
<marker>Fazly, Cook, Stevenson, 2009</marker>
<rawString>Afsaneh Fazly, Paul Cook, and Suzanne Stevenson. 2009. Unsupervised type and token identification of idiomatic expressions. Computational Linguistics, 35(1):61–103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugenie Giesbrecht</author>
</authors>
<title>In search of semantic compositionality in vector spaces.</title>
<date>2009</date>
<booktitle>In Proceedings of the 17th International Conference on Conceptual Structures: Conceptual Structures: Leveraging Semantic Technologies, ICCS ’09,</booktitle>
<pages>173--184</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="4276" citStr="Giesbrecht, 2009" startWordPosition="636" endWordPosition="638">ime, semantic composition can take many different forms, making uniform interpretation of compounds impossible (Zanzotto et al., 2010). Most current work on MWEs focuses on interpreting compounds and sidesteps the task of determining whether a compound is compositional in the first place (Butnariu et al., 2010; Kim and Baldwin, 2008). Such methods, aimed at learning the semantics of compounds, can roughly be divided into two major strands of research. One group relies on data intensive methods to extract semantics vectors from large corpora (Baroni and Zamparelli, 2010; Zanzotto et al., 2010; Giesbrecht, 2009). The focus of these approaches is to develop methods for composing the vectors of unigrams into a semantic vector representing a compound. Some of the work in this area touches on the issue of lexicality, as models learning distributional representations of MWEs ideally would first establish whether a given MWE is compositional or not (Mitchell and Lapata, 2010). The other group are knowledge intensive approaches collecting linguistic features (Kim and Baldwin, 2005; Korkontzelos and Manandhar, 2009). Tratz and Hovy (2010), for instance, train a classifier for noun compound interpretation on </context>
</contexts>
<marker>Giesbrecht, 2009</marker>
<rawString>Eugenie Giesbrecht. 2009. In search of semantic compositionality in vector spaces. In Proceedings of the 17th International Conference on Conceptual Structures: Conceptual Structures: Leveraging Semantic Technologies, ICCS ’09, pages 173–184, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Su Nam Kim</author>
<author>Timothy Baldwin</author>
</authors>
<title>Automatic interpretation of noun compounds using wordnet similarity. In</title>
<date>2005</date>
<booktitle>In Proceedings of the 2nd International Joint Conference on Natural Language Processing,</booktitle>
<volume>1113</volume>
<pages>945--956</pages>
<location>Jeju Island, South</location>
<contexts>
<context position="4747" citStr="Kim and Baldwin, 2005" startWordPosition="711" endWordPosition="714">elies on data intensive methods to extract semantics vectors from large corpora (Baroni and Zamparelli, 2010; Zanzotto et al., 2010; Giesbrecht, 2009). The focus of these approaches is to develop methods for composing the vectors of unigrams into a semantic vector representing a compound. Some of the work in this area touches on the issue of lexicality, as models learning distributional representations of MWEs ideally would first establish whether a given MWE is compositional or not (Mitchell and Lapata, 2010). The other group are knowledge intensive approaches collecting linguistic features (Kim and Baldwin, 2005; Korkontzelos and Manandhar, 2009). Tratz and Hovy (2010), for instance, train a classifier for noun compound interpretation on a large set of WORDNET and Thesaurus features. Combined approaches include Kim and Baldwin (2008), who interpret noun compounds by extrapolating their semantics from observations where the two nouns forming a compound are in an intransitive relationship. For example extracting the phrase ‘the family owns a car’ from the training data would help learn that the compound ‘family car’ describes a POSSESSOR-OWNED/POSSESSED relationship. Some of these supervised classifier</context>
</contexts>
<marker>Kim, Baldwin, 2005</marker>
<rawString>Su Nam Kim and Timothy Baldwin. 2005. Automatic interpretation of noun compounds using wordnet similarity. In In Proceedings of the 2nd International Joint Conference on Natural Language Processing, Jeju Island, South Korea, 1113, pages 945–956.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Su Nam Kim</author>
<author>Timothy Baldwin</author>
</authors>
<title>Detecting compositionality of English verb-particle constructions using semantic similarity.</title>
<date>2007</date>
<booktitle>In Proceedings of the 7th Meeting of the Pacific Association for Computational Linguistics, PACLING ’07,</booktitle>
<pages>40--48</pages>
<contexts>
<context position="5635" citStr="Kim and Baldwin, 2007" startWordPosition="846" endWordPosition="849">olating their semantics from observations where the two nouns forming a compound are in an intransitive relationship. For example extracting the phrase ‘the family owns a car’ from the training data would help learn that the compound ‘family car’ describes a POSSESSOR-OWNED/POSSESSED relationship. Some of these supervised classifiers include lexicality as a classification option, considering it jointly with the actual compound interpretation. Next to the work on MWE interpretation there has been some work focused on determining lexicality in its own right (Reddy et al., 2011; Bu et al., 2010; Kim and Baldwin, 2007). One possibility is to exploit special properties of lexical MWEs such as high statistical association of their constituents (Pedersen, 2011) or syntactic rigidity (Fazly et al., 2009; McCarthy et al., 2007). However, these approaches are limited in their applicability to compound nouns (Reddy et al., 2011). Another method is to compare the semantics of a compound and its constituents to decide compositionality. The approaches used to determine those semantics can again be divided into knowledge intensive and data-driven methods. Depending on the chosen representation of semantics these appro</context>
<context position="21849" citStr="Kim and Baldwin (2007)" startWordPosition="3497" endWordPosition="3500">ra regularly used in Computational Linguistics. However, adding more data in an unsupervised sense is unlikely to significantly improve results (Brants et al., 2007). Alternatively, it would be possible to add specific training data that included the noun compounds from the evaluation data sets. This would, however, compromise the unsupervised nature of our approach, and it thus not an option either. In this paper, we will instead focus on extenuating the effects of data sparsity through other unsupervised means. For this purpose we investigate interpolating on a larger set of noun compounds. Kim and Baldwin (2007) observed that semantic similarity of verb-particle compounds correlates with their lexicality. We extend this observation for noun compounds, hypothesising that the lexicality of similar words will be similar. We combine this with the assumption that noun compounds sharing a constituent are likely to be semantically similar (Korkontzelos and Manandhar, 2009). Using this idea, we can approximate the lexicality of a given compound with the lexicality scores of all compounds sharing either of its constituents. So far we have calculated the lexicality of a given compound using the formula Lex(c) </context>
</contexts>
<marker>Kim, Baldwin, 2007</marker>
<rawString>Su Nam Kim and Timothy Baldwin. 2007. Detecting compositionality of English verb-particle constructions using semantic similarity. In Proceedings of the 7th Meeting of the Pacific Association for Computational Linguistics, PACLING ’07, pages 40–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Su Nam Kim</author>
<author>Timothy Baldwin</author>
</authors>
<title>An unsupervised approach to interpreting noun compounds.</title>
<date>2008</date>
<booktitle>In Natural Language Processing and Knowledge Engineering,</booktitle>
<pages>1--7</pages>
<contexts>
<context position="3994" citStr="Kim and Baldwin, 2008" startWordPosition="589" endWordPosition="592">(*SEM), pages 132–141, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics 2 Related Work Interpreting MWEs is a difficult task as “compound nouns can be freely constructed” (Sp¨arck Jones, 1985), and are thus able to proliferate infinitely. At the same time, semantic composition can take many different forms, making uniform interpretation of compounds impossible (Zanzotto et al., 2010). Most current work on MWEs focuses on interpreting compounds and sidesteps the task of determining whether a compound is compositional in the first place (Butnariu et al., 2010; Kim and Baldwin, 2008). Such methods, aimed at learning the semantics of compounds, can roughly be divided into two major strands of research. One group relies on data intensive methods to extract semantics vectors from large corpora (Baroni and Zamparelli, 2010; Zanzotto et al., 2010; Giesbrecht, 2009). The focus of these approaches is to develop methods for composing the vectors of unigrams into a semantic vector representing a compound. Some of the work in this area touches on the issue of lexicality, as models learning distributional representations of MWEs ideally would first establish whether a given MWE is c</context>
</contexts>
<marker>Kim, Baldwin, 2008</marker>
<rawString>Su Nam Kim and Timothy Baldwin. 2008. An unsupervised approach to interpreting noun compounds. In Natural Language Processing and Knowledge Engineering, 2008. NLP-KE ’08. International Conference on, pages 1–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kirkpatrick</author>
<author>C D Gelatt</author>
<author>M P Vecchi</author>
</authors>
<title>Optimization by simulated annealing.</title>
<date>1983</date>
<journal>Science,</journal>
<volume>220</volume>
<issue>4598</issue>
<contexts>
<context position="17948" citStr="Kirkpatrick et al., 1983" startWordPosition="2865" endWordPosition="2868">.567 COSLEX (MULT) .379 .551 MULT-CMPD .141 .435 BIN-CMPD .168 .410 Table 2: Results on the REDDY data set, reporting Pearson’s r and Spearman’s p correlations. Values range from -1 (negative correlation) to +1 (perfect correlation). 6.1.1 Inference and Sampling We use Gibbs sampling to learn the vectors z for each instance d, integrating out the parameters T&apos;. We train our models on the British National Corpus (BNC), extracting all noun-noun compounds from a parsed version of the corpus. In order to speed up convergence of the sampler, we use simulated annealing over the first 20 iterations (Kirkpatrick et al., 1983), helping the randomly initialised model reach a mode faster. We report results using marginal distributions after a further 130 iterations, excluding the counts of the annealing stage. 6.1.2 Evaluation We evaluate our two models on the REDDY data set by comparing its scores for lexicality (Lex(c)) with the annotated gold standard. The aim of this evaluation is to determine how accurately the models can capture gradual distinctions in lexicality. The ROC analysis on the TRATZ data set furthermore informs us how precise the models are at distinguishing lexical from compositional compounds. Resu</context>
</contexts>
<marker>Kirkpatrick, Gelatt, Vecchi, 1983</marker>
<rawString>S. Kirkpatrick, C. D. Gelatt, and M. P. Vecchi. 1983. Optimization by simulated annealing. Science, 220(4598):671–680.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ioannis Korkontzelos</author>
<author>Suresh Manandhar</author>
</authors>
<title>Detecting compositionality in multi-word expressions.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, ACLShort ’09,</booktitle>
<pages>65--68</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4782" citStr="Korkontzelos and Manandhar, 2009" startWordPosition="715" endWordPosition="718"> methods to extract semantics vectors from large corpora (Baroni and Zamparelli, 2010; Zanzotto et al., 2010; Giesbrecht, 2009). The focus of these approaches is to develop methods for composing the vectors of unigrams into a semantic vector representing a compound. Some of the work in this area touches on the issue of lexicality, as models learning distributional representations of MWEs ideally would first establish whether a given MWE is compositional or not (Mitchell and Lapata, 2010). The other group are knowledge intensive approaches collecting linguistic features (Kim and Baldwin, 2005; Korkontzelos and Manandhar, 2009). Tratz and Hovy (2010), for instance, train a classifier for noun compound interpretation on a large set of WORDNET and Thesaurus features. Combined approaches include Kim and Baldwin (2008), who interpret noun compounds by extrapolating their semantics from observations where the two nouns forming a compound are in an intransitive relationship. For example extracting the phrase ‘the family owns a car’ from the training data would help learn that the compound ‘family car’ describes a POSSESSOR-OWNED/POSSESSED relationship. Some of these supervised classifiers include lexicality as a classific</context>
<context position="6504" citStr="Korkontzelos and Manandhar, 2009" startWordPosition="979" endWordPosition="983">are limited in their applicability to compound nouns (Reddy et al., 2011). Another method is to compare the semantics of a compound and its constituents to decide compositionality. The approaches used to determine those semantics can again be divided into knowledge intensive and data-driven methods. Depending on the chosen representation of semantics these approaches can either be used for supervised classifiers or together with a distance metric comparing vector space representations of semantics. In a binary setting, a threshold would then be applied to the result of that distance function (Korkontzelos and Manandhar, 2009). In a real-valued setting the distance metric itself can be used as a measure for compositionality (Reddy et al., 2011). Related to the vector space based models, some research focuses on improving the distance metrics used to compare induced semantics (Bu et al., 2010). 3 Methodology English noun-noun compounds are majority leftbranching (Lauer, 1995), with a head (the second element), modified by an attributive noun (first element). For example: Ground Floor — The floor of a building at or nearest ground level.2 In this paper, we will use the terms attributive noun (AN) and head noun (HN) t</context>
<context position="22210" citStr="Korkontzelos and Manandhar, 2009" startWordPosition="3548" endWordPosition="3552">re of our approach, and it thus not an option either. In this paper, we will instead focus on extenuating the effects of data sparsity through other unsupervised means. For this purpose we investigate interpolating on a larger set of noun compounds. Kim and Baldwin (2007) observed that semantic similarity of verb-particle compounds correlates with their lexicality. We extend this observation for noun compounds, hypothesising that the lexicality of similar words will be similar. We combine this with the assumption that noun compounds sharing a constituent are likely to be semantically similar (Korkontzelos and Manandhar, 2009). Using this idea, we can approximate the lexicality of a given compound with the lexicality scores of all compounds sharing either of its constituents. So far we have calculated the lexicality of a given compound using the formula Lex(c) in Equation 1. The formula Clex(c) in Equation 2 averages the lexicality scores of a compound with those of its related 137 Function and Model r p COSLEX (ADD) .323 .567 COSLEX (MULT) .379 .551 Lex(c) MULT-CMPD .141 .435 BIN-CMPD .168 .410 Clex(c) MULT-CMPD .357 .596 BIN-CMPD .400 .592 Ilex(c) MULT-CMPD .422 .621 BIN-CMPD .538 .623 Table 3: Results on the RED</context>
</contexts>
<marker>Korkontzelos, Manandhar, 2009</marker>
<rawString>Ioannis Korkontzelos and Suresh Manandhar. 2009. Detecting compositionality in multi-word expressions. In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, ACLShort ’09, pages 65–68, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ioannis Korkontzelos</author>
<author>Suresh Manandhar</author>
</authors>
<title>Can recognising multiword expressions improve shallow parsing? In Human Language Technologies: The</title>
<date>2010</date>
<booktitle>Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10,</booktitle>
<pages>636--644</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1924" citStr="Korkontzelos and Manandhar, 2010" startWordPosition="286" endWordPosition="289">tion of a MWE, it needs to be established whether the expression should be treated as lexical (idiomatic) or as compositional. The final step, learning the semantics of the MWE, strongly depends on this decision. 1Definition taken from Wikipedia, and clearly not recoverable if one only knows the meaning of the words ‘rat’ and ‘race’. The problem posed by MWEs is considered hard, but at the same time it is highly relevant and interesting. MWEs occur frequently in language and interpreting them correctly would directly improve results in a number of tasks in NLP such as translation and parsing (Korkontzelos and Manandhar, 2010). By extension this makes deciding the lexicality of MWEs an important challenge for various fields including machine translation, question answering and information retrieval. In this paper we discuss compositionality with respect to noun-noun compounds. Most Computational Linguistics literature treats compositionality as a binary problem, classifying compounds as either lexical or compositional. We show that this approach is too simplistic and argue for the real-valued treatment of compositionality. We propose two unsupervised models that learn compositionality rankings for compounds, placin</context>
</contexts>
<marker>Korkontzelos, Manandhar, 2010</marker>
<rawString>Ioannis Korkontzelos and Suresh Manandhar. 2010. Can recognising multiword expressions improve shallow parsing? In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10, pages 636–644, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Lauer</author>
</authors>
<title>Corpus statistics meet the noun compound: some empirical results.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd annual meeting on Association for Computational Linguistics, ACL ’95,</booktitle>
<pages>47--54</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6859" citStr="Lauer, 1995" startWordPosition="1040" endWordPosition="1041">ther be used for supervised classifiers or together with a distance metric comparing vector space representations of semantics. In a binary setting, a threshold would then be applied to the result of that distance function (Korkontzelos and Manandhar, 2009). In a real-valued setting the distance metric itself can be used as a measure for compositionality (Reddy et al., 2011). Related to the vector space based models, some research focuses on improving the distance metrics used to compare induced semantics (Bu et al., 2010). 3 Methodology English noun-noun compounds are majority leftbranching (Lauer, 1995), with a head (the second element), modified by an attributive noun (first element). For example: Ground Floor — The floor of a building at or nearest ground level.2 In this paper, we will use the terms attributive noun (AN) and head noun (HN) to refer to the first and second noun in a noun compound. 3.1 Real-Valued Representation Lexicality of MWEs is frequently treated as a binary property (Tratz and Hovy, 2010; O´ S´eaghdha, 2007). We argue that lexicality should instead be treated as a graded property, as most compound semantics exhibit a mixture of compositional and lexical influences. Fo</context>
</contexts>
<marker>Lauer, 1995</marker>
<rawString>Mark Lauer. 1995. Corpus statistics meet the noun compound: some empirical results. In Proceedings of the 33rd annual meeting on Association for Computational Linguistics, ACL ’95, pages 47–54, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Sriram Venkatapathy</author>
<author>Aravind Joshi</author>
</authors>
<title>Detecting compositionality of verbobject combinations using selectional preferences.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL),</booktitle>
<pages>369--379</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="5843" citStr="McCarthy et al., 2007" startWordPosition="877" endWordPosition="880">p learn that the compound ‘family car’ describes a POSSESSOR-OWNED/POSSESSED relationship. Some of these supervised classifiers include lexicality as a classification option, considering it jointly with the actual compound interpretation. Next to the work on MWE interpretation there has been some work focused on determining lexicality in its own right (Reddy et al., 2011; Bu et al., 2010; Kim and Baldwin, 2007). One possibility is to exploit special properties of lexical MWEs such as high statistical association of their constituents (Pedersen, 2011) or syntactic rigidity (Fazly et al., 2009; McCarthy et al., 2007). However, these approaches are limited in their applicability to compound nouns (Reddy et al., 2011). Another method is to compare the semantics of a compound and its constituents to decide compositionality. The approaches used to determine those semantics can again be divided into knowledge intensive and data-driven methods. Depending on the chosen representation of semantics these approaches can either be used for supervised classifiers or together with a distance metric comparing vector space representations of semantics. In a binary setting, a threshold would then be applied to the result</context>
</contexts>
<marker>McCarthy, Venkatapathy, Joshi, 2007</marker>
<rawString>Diana McCarthy, Sriram Venkatapathy, and Aravind Joshi. 2007. Detecting compositionality of verbobject combinations using selectional preferences. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL), pages 369–379, Prague, Czech Republic. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Mitchell</author>
<author>Mirella Lapata</author>
</authors>
<title>Composition in distributional models of semantics.</title>
<date>2010</date>
<journal>Cognitive Science,</journal>
<volume>34</volume>
<issue>8</issue>
<contexts>
<context position="4641" citStr="Mitchell and Lapata, 2010" startWordPosition="696" endWordPosition="699"> at learning the semantics of compounds, can roughly be divided into two major strands of research. One group relies on data intensive methods to extract semantics vectors from large corpora (Baroni and Zamparelli, 2010; Zanzotto et al., 2010; Giesbrecht, 2009). The focus of these approaches is to develop methods for composing the vectors of unigrams into a semantic vector representing a compound. Some of the work in this area touches on the issue of lexicality, as models learning distributional representations of MWEs ideally would first establish whether a given MWE is compositional or not (Mitchell and Lapata, 2010). The other group are knowledge intensive approaches collecting linguistic features (Kim and Baldwin, 2005; Korkontzelos and Manandhar, 2009). Tratz and Hovy (2010), for instance, train a classifier for noun compound interpretation on a large set of WORDNET and Thesaurus features. Combined approaches include Kim and Baldwin (2008), who interpret noun compounds by extrapolating their semantics from observations where the two nouns forming a compound are in an intransitive relationship. For example extracting the phrase ‘the family owns a car’ from the training data would help learn that the com</context>
</contexts>
<marker>Mitchell, Lapata, 2010</marker>
<rawString>Jeff Mitchell and Mirella Lapata. 2010. Composition in distributional models of semantics. Cognitive Science, 34(8):1388–1429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diarmuid O´ S´eaghdha</author>
</authors>
<title>Annotating and learning compound noun semantics.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL: Student Research Workshop, ACL ’07,</booktitle>
<pages>73--78</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>S´eaghdha, 2007</marker>
<rawString>Diarmuid O´ S´eaghdha. 2007. Annotating and learning compound noun semantics. In Proceedings of the 45th Annual Meeting of the ACL: Student Research Workshop, ACL ’07, pages 73–78, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
</authors>
<title>Identifying collocations to measure compositionality: shared task system description.</title>
<date>2011</date>
<booktitle>In Proceedings of the Workshop on Distributional Semantics and Compositionality, DiSCo ’11,</booktitle>
<pages>33--37</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="5777" citStr="Pedersen, 2011" startWordPosition="868" endWordPosition="869">se ‘the family owns a car’ from the training data would help learn that the compound ‘family car’ describes a POSSESSOR-OWNED/POSSESSED relationship. Some of these supervised classifiers include lexicality as a classification option, considering it jointly with the actual compound interpretation. Next to the work on MWE interpretation there has been some work focused on determining lexicality in its own right (Reddy et al., 2011; Bu et al., 2010; Kim and Baldwin, 2007). One possibility is to exploit special properties of lexical MWEs such as high statistical association of their constituents (Pedersen, 2011) or syntactic rigidity (Fazly et al., 2009; McCarthy et al., 2007). However, these approaches are limited in their applicability to compound nouns (Reddy et al., 2011). Another method is to compare the semantics of a compound and its constituents to decide compositionality. The approaches used to determine those semantics can again be divided into knowledge intensive and data-driven methods. Depending on the chosen representation of semantics these approaches can either be used for supervised classifiers or together with a distance metric comparing vector space representations of semantics. In</context>
</contexts>
<marker>Pedersen, 2011</marker>
<rawString>Ted Pedersen. 2011. Identifying collocations to measure compositionality: shared task system description. In Proceedings of the Workshop on Distributional Semantics and Compositionality, DiSCo ’11, pages 33– 37, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siva Reddy</author>
<author>Diana McCarthy</author>
<author>Suresh Manandhar</author>
</authors>
<title>An empirical study on compositionality in compound nouns.</title>
<date>2011</date>
<booktitle>In Proceedings of The 5th International Joint Conference on Natural Language Processing</booktitle>
<location>Chiang Mai, Thailand.</location>
<contexts>
<context position="5594" citStr="Reddy et al., 2011" startWordPosition="838" endWordPosition="841">ho interpret noun compounds by extrapolating their semantics from observations where the two nouns forming a compound are in an intransitive relationship. For example extracting the phrase ‘the family owns a car’ from the training data would help learn that the compound ‘family car’ describes a POSSESSOR-OWNED/POSSESSED relationship. Some of these supervised classifiers include lexicality as a classification option, considering it jointly with the actual compound interpretation. Next to the work on MWE interpretation there has been some work focused on determining lexicality in its own right (Reddy et al., 2011; Bu et al., 2010; Kim and Baldwin, 2007). One possibility is to exploit special properties of lexical MWEs such as high statistical association of their constituents (Pedersen, 2011) or syntactic rigidity (Fazly et al., 2009; McCarthy et al., 2007). However, these approaches are limited in their applicability to compound nouns (Reddy et al., 2011). Another method is to compare the semantics of a compound and its constituents to decide compositionality. The approaches used to determine those semantics can again be divided into knowledge intensive and data-driven methods. Depending on the chose</context>
<context position="8155" citStr="Reddy et al., 2011" startWordPosition="1247" endWordPosition="1250">, but the compound also contributes an idiosyncratic element to its meaning. 2Definition from http://www.thefreedictionary.com 133 We define lexicality as the degree to which idiosyncrasy contributes to a compound’s semantics. Inversely phrased, the compositionality of a compound can be defined as the degree to which its sense is related to the senses of its constituents.3 This graded representation follows Sp¨arck Jones (1985), who argued that “it is not possible to maintain a principled distinction between lexicalised and non-lexicalised compounds”. Some recent work also supports this view (Reddy et al., 2011; Bu et al., 2010; Baldwin, 2006). From a practical perspective, a real-valued representation of compositionality should help improve interpretation of compounds. This is especially true when factoring in the respective semantic contributions of its parts. 3.2 Context Generation According to the distributional hypothesis, the semantics of a lexical item can be expressed by its context. We apply this hypothesis to the problem of noun compound compositionality by using a generative model on compound context. Our model allows context to be generated by the compound itself or by either one of its </context>
<context position="11626" citStr="Reddy et al. (2011)" startWordPosition="1797" endWordPosition="1800"> assume that most compounds have a compositional as well as a lexical element. While the compositional aspect may be larger for most compounds this alone does not suffice as a reason to disregard the lexical element contained in these compounds. In order to evaluate our system on the TRATZ data, we use receiving operator characteristic (ROC) curves. ROC analysis enables us to evaluate a ranking model without setting an artificial threshold for the compositionality/lexicality decision. 5 Baseline Approach We develop a set of advanced baselines related to the semi-supervised models presented by Reddy et al. (2011). We define the context K of a noun compound as all words in all sentences the compound appears in. From this we calculate distributional representations of a compound (c = (a, h)) and its constituent elements a, h. We refer to these representations as c� for the compound and ta, h for the 4We removed trigrams from the data set. 134 Name ® r p ADD w.Sac + (1 − w).Shc .323 .567 MULT Sac.Shc .379 .551 MIN min(Sac, Shc) .343 .550 MAX max(Sac, Shc) .299 .505 COMB w1.Sac+w2.Shc+w3.Sac.Shc .366 .556 Table 1: Results of COSLEX with different operators on the REDDY data set, reporting Pearson’s r and </context>
<context position="13662" citStr="Reddy et al. (2011)" startWordPosition="2149" endWordPosition="2152">uld expect it to perform very well. We use the best performing operators (ADD with w = 0.3, MULT) as baselines for this paper. 6 Generative Models We exploit the distributional hypothesis to model the semantic contribution of the different elements of a noun compound. For this, we require a system that treats a noun compound as a vector of three semantics-bearing units: the compound itself, its head and its attributive noun. This system should then model the relationship between the context of the compound and these three units, deciding which of them is responsible for each context element. 5Reddy et al. (2011) report higher figures on our baseline models. The differences are attributed to differences in training data and parametrization. 6.1 3-way Compound Mixture We model a corpus D of tuples d = {c, k1, ..., kn}. Each tuple d contains a noun compound c = (a, h) and its context words K = (k1, ..., kn). We use vocabularies Vc for noun compounds, Va for attributive nouns, Vh for head nouns and Vk for context. We condition our generative model on the noun compounds. Given an observation d of a compound c, we generate each context word in two steps. First, we choose one of the compounds three elements</context>
</contexts>
<marker>Reddy, McCarthy, Manandhar, 2011</marker>
<rawString>Siva Reddy, Diana McCarthy, and Suresh Manandhar. 2011. An empirical study on compositionality in compound nouns. In Proceedings of The 5th International Joint Conference on Natural Language Processing 2011 (IJCNLP 2011), Chiang Mai, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan A Sag</author>
<author>Timothy Baldwin</author>
<author>Francis Bond</author>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP. In</title>
<date>2002</date>
<booktitle>In Proc. of the 3rd International Conference on Intelligent Text Processing and Computational Linguistics (CICLing2002,</booktitle>
<pages>1--15</pages>
<contexts>
<context position="1154" citStr="Sag et al., 2002" startWordPosition="159" endWordPosition="162">n a finegrained representation of semantic contribution. Finally, we argue such a representation captures compositionality better than the current status-quo which treats compositionality as a binary classification problem. 1 Introduction A Multiword Expressions (MWE) can be defined as a sequence of words whose meaning cannot necessarily be derived from the meaning of the words making up that sequence, for example: Rat Race — self-defeating or pointless pursuit1 MWEs are considered a “key problem for the development of large-scale, linguistically sound natural language processing technology” (Sag et al., 2002). The challenge posed by MWEs is threefold, consisting of MWE identification, classification and interpretation. Following the identification of a MWE, it needs to be established whether the expression should be treated as lexical (idiomatic) or as compositional. The final step, learning the semantics of the MWE, strongly depends on this decision. 1Definition taken from Wikipedia, and clearly not recoverable if one only knows the meaning of the words ‘rat’ and ‘race’. The problem posed by MWEs is considered hard, but at the same time it is highly relevant and interesting. MWEs occur frequently</context>
<context position="25628" citStr="Sag et al., 2002" startWordPosition="4111" endWordPosition="4114">litative evaluation is to better understand exactly what it is our models are learning. Table 5 lists the compounds that model BINCMPD considers the most lexical and the most compositional. The list of compounds with the high lexicality scores is dominated by proper nouns such as countries, companies and persons. This is in line with expectation as compounds of proper nouns are fully lexical. Removing proper nouns (also in Table 5), we get a slightly more ambiguous list. For example, ‘study design’ is not considered a lexical compound, but rather a highly institutionalized, compositional MWE (Sag et al., 2002). Using Lex(c) ‘study design’ is ranked as such, so this appears to be a case where interpolation has a negative impact. In this paper we argued for a finer grained analysis of compositionality, taking into account the differ138 Context of ‘flea market’ generated by flea market flea market canal, wall, incline, stall, Paris, sale, barter, souvenir, campsite Saturday, week, launderette, Sunday, quarter, Lamine, Canet, damage, change Kouyate, Plage Context of ‘night owl’ generated by night owl night owl court, fee, guest, waive, player, adventurous early, day, Baden, Halikarnas, bar, membership,</context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann Copestake, and Dan Flickinger. 2002. Multiword expressions: A pain in the neck for NLP. In In Proc. of the 3rd International Conference on Intelligent Text Processing and Computational Linguistics (CICLing2002, pages 1–15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Sp¨arck Jones</author>
</authors>
<title>Compound noun interpretation problems.</title>
<date>1985</date>
<booktitle>Computer speech processing,</booktitle>
<pages>363--381</pages>
<editor>In Frank Fallside and William A. Woods, editors,</editor>
<publisher>Prentice Hall International (UK) Ltd., Hertfordshire, UK, UK.</publisher>
<contexts>
<context position="3599" citStr="Jones, 1985" startWordPosition="529" endWordPosition="530">existing corpus of noun compounds with ranked compositionality data, as well as on a large corpus with a binary annotation for lexical and compositional compounds. We analyse the impact of data sparsity and propose an interpolation approximation which significantly reduces the effect of sparsity on model performance. 132 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 132–141, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics 2 Related Work Interpreting MWEs is a difficult task as “compound nouns can be freely constructed” (Sp¨arck Jones, 1985), and are thus able to proliferate infinitely. At the same time, semantic composition can take many different forms, making uniform interpretation of compounds impossible (Zanzotto et al., 2010). Most current work on MWEs focuses on interpreting compounds and sidesteps the task of determining whether a compound is compositional in the first place (Butnariu et al., 2010; Kim and Baldwin, 2008). Such methods, aimed at learning the semantics of compounds, can roughly be divided into two major strands of research. One group relies on data intensive methods to extract semantics vectors from large c</context>
<context position="7968" citStr="Jones (1985)" startWordPosition="1220" endWordPosition="1221">aded property, as most compound semantics exhibit a mixture of compositional and lexical influences. For example, ‘cocktail dress’ derives a large part of its semantics from ‘dress’, but the compound also contributes an idiosyncratic element to its meaning. 2Definition from http://www.thefreedictionary.com 133 We define lexicality as the degree to which idiosyncrasy contributes to a compound’s semantics. Inversely phrased, the compositionality of a compound can be defined as the degree to which its sense is related to the senses of its constituents.3 This graded representation follows Sp¨arck Jones (1985), who argued that “it is not possible to maintain a principled distinction between lexicalised and non-lexicalised compounds”. Some recent work also supports this view (Reddy et al., 2011; Bu et al., 2010; Baldwin, 2006). From a practical perspective, a real-valued representation of compositionality should help improve interpretation of compounds. This is especially true when factoring in the respective semantic contributions of its parts. 3.2 Context Generation According to the distributional hypothesis, the semantics of a lexical item can be expressed by its context. We apply this hypothesis</context>
</contexts>
<marker>Jones, 1985</marker>
<rawString>Karen Sp¨arck Jones. 1985. Compound noun interpretation problems. In Frank Fallside and William A. Woods, editors, Computer speech processing, pages 363–381. Prentice Hall International (UK) Ltd., Hertfordshire, UK, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Tratz</author>
<author>Eduard Hovy</author>
</authors>
<title>A taxonomy, dataset, and classifier for automatic noun compound interpretation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>678--687</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4805" citStr="Tratz and Hovy (2010)" startWordPosition="719" endWordPosition="722">rs from large corpora (Baroni and Zamparelli, 2010; Zanzotto et al., 2010; Giesbrecht, 2009). The focus of these approaches is to develop methods for composing the vectors of unigrams into a semantic vector representing a compound. Some of the work in this area touches on the issue of lexicality, as models learning distributional representations of MWEs ideally would first establish whether a given MWE is compositional or not (Mitchell and Lapata, 2010). The other group are knowledge intensive approaches collecting linguistic features (Kim and Baldwin, 2005; Korkontzelos and Manandhar, 2009). Tratz and Hovy (2010), for instance, train a classifier for noun compound interpretation on a large set of WORDNET and Thesaurus features. Combined approaches include Kim and Baldwin (2008), who interpret noun compounds by extrapolating their semantics from observations where the two nouns forming a compound are in an intransitive relationship. For example extracting the phrase ‘the family owns a car’ from the training data would help learn that the compound ‘family car’ describes a POSSESSOR-OWNED/POSSESSED relationship. Some of these supervised classifiers include lexicality as a classification option, consideri</context>
<context position="7275" citStr="Tratz and Hovy, 2010" startWordPosition="1113" endWordPosition="1116">ased models, some research focuses on improving the distance metrics used to compare induced semantics (Bu et al., 2010). 3 Methodology English noun-noun compounds are majority leftbranching (Lauer, 1995), with a head (the second element), modified by an attributive noun (first element). For example: Ground Floor — The floor of a building at or nearest ground level.2 In this paper, we will use the terms attributive noun (AN) and head noun (HN) to refer to the first and second noun in a noun compound. 3.1 Real-Valued Representation Lexicality of MWEs is frequently treated as a binary property (Tratz and Hovy, 2010; O´ S´eaghdha, 2007). We argue that lexicality should instead be treated as a graded property, as most compound semantics exhibit a mixture of compositional and lexical influences. For example, ‘cocktail dress’ derives a large part of its semantics from ‘dress’, but the compound also contributes an idiosyncratic element to its meaning. 2Definition from http://www.thefreedictionary.com 133 We define lexicality as the degree to which idiosyncrasy contributes to a compound’s semantics. Inversely phrased, the compositionality of a compound can be defined as the degree to which its sense is relate</context>
<context position="10097" citStr="Tratz and Hovy (2010)" startWordPosition="1561" endWordPosition="1564">distributed across the [0;5] range, with inter annotator agreement (Spearman’s p) of 3For example, the meaning of ‘gravy train’ has hardly any relation to either ‘gravy’ or ‘train’. Its semantics are thus highly dependent on the compound in its own right. On the other end of the spectrum, ‘climate change’ is significantly related to both ‘climate’ and ‘change’, contributing little inherent semantics to its overall meaning. 0.522. We refer to this data set and evaluation as REDDY throughout this paper. 4.2 Binary Corpora — TRATZ We also apply our models to a second, binary classification task. Tratz and Hovy (2010) compiled a data set for noun compound interpretation, which classifies noun compounds based on their internal structure. We use this corpus to extract lexical and compositional noun compounds. After some pre-processing4 the data set contains 18,858 compositional and 118 lexical noun compounds. We believe this to more accurately represent the real world distribution of lexical and compositional noun compounds: Tratz and Hovy (2010) extracted noun compounds from several large corpora including the Wall Street Journal section of the Penn Treebank, thus obtaining a reasonable approximation of rea</context>
</contexts>
<marker>Tratz, Hovy, 2010</marker>
<rawString>Stephen Tratz and Eduard Hovy. 2010. A taxonomy, dataset, and classifier for automatic noun compound interpretation. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 678–687, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabio Massimo Zanzotto</author>
<author>Ioannis Korkontzelos</author>
<author>Francesca Fallucchi</author>
<author>Suresh Manandhar</author>
</authors>
<title>Estimating linear models for compositional distributional semantics.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics, COLING ’10,</booktitle>
<pages>1263--1271</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="3793" citStr="Zanzotto et al., 2010" startWordPosition="555" endWordPosition="558">t of data sparsity and propose an interpolation approximation which significantly reduces the effect of sparsity on model performance. 132 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 132–141, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics 2 Related Work Interpreting MWEs is a difficult task as “compound nouns can be freely constructed” (Sp¨arck Jones, 1985), and are thus able to proliferate infinitely. At the same time, semantic composition can take many different forms, making uniform interpretation of compounds impossible (Zanzotto et al., 2010). Most current work on MWEs focuses on interpreting compounds and sidesteps the task of determining whether a compound is compositional in the first place (Butnariu et al., 2010; Kim and Baldwin, 2008). Such methods, aimed at learning the semantics of compounds, can roughly be divided into two major strands of research. One group relies on data intensive methods to extract semantics vectors from large corpora (Baroni and Zamparelli, 2010; Zanzotto et al., 2010; Giesbrecht, 2009). The focus of these approaches is to develop methods for composing the vectors of unigrams into a semantic vector re</context>
</contexts>
<marker>Zanzotto, Korkontzelos, Fallucchi, Manandhar, 2010</marker>
<rawString>Fabio Massimo Zanzotto, Ioannis Korkontzelos, Francesca Fallucchi, and Suresh Manandhar. 2010. Estimating linear models for compositional distributional semantics. In Proceedings of the 23rd International Conference on Computational Linguistics, COLING ’10, pages 1263–1271, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>