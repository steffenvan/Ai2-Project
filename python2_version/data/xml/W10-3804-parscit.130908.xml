<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012386">
<title confidence="0.998059">
Syntactic Constraints on Phrase Extraction for Phrase-Based
Machine Translation
</title>
<author confidence="0.994698">
Hailong Cao, Andrew Finch and Eiichiro Sumita
</author>
<affiliation confidence="0.9850135">
Language Translation Group, MASTAR Project
National Institute of Information and Communications Technology
</affiliation>
<email confidence="0.996673">
{hlcao,andrew.finch,eiichiro.sumita }@nict.go.jp
</email>
<sectionHeader confidence="0.993851" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999817894736842">
A typical phrase-based machine transla-
tion (PBMT) system uses phrase pairs
extracted from word-aligned parallel
corpora. All phrase pairs that are consis-
tent with word alignments are collected.
The resulting phrase table is very large
and includes many non-syntactic phrases
which may not be necessary. We propose
to filter the phrase table based on source
language syntactic constraints. Rather
than filter out all non-syntactic phrases,
we only apply syntactic constraints when
there is phrase segmentation ambiguity
arising from unaligned words. Our
method is very simple and yields a
24.38% phrase pair reduction and a 0.52
BLEU point improvement when com-
pared to a baseline PBMT system with
full-size tables.
</bodyText>
<sectionHeader confidence="0.998987" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999934081632653">
Both PBMT models (Koehn et al., 2003; Chiang,
2005) and syntax-based machine translation
models (Yamada et al., 2000; Quirk et al., 2005;
Galley et al., 2006; Liu et al., 2006; Marcu et al.,
2006; and numerous others) are the state-of-the-
art statistical machine translation (SMT) meth-
ods. Over the last several years, an increasing
amount of work has been done to combine the
advantages of the two approaches. DeNeefe et al.
(2007) made a quantitative comparison of the
phrase pairs that each model has to work with
and found it is useful to improve the phrasal
coverage of their string-to-tree model. Liu et al.
(2007) proposed forest-to-string rules to capture
the non-syntactic phrases in their tree-to-string
model. Zhang et al. (2008) proposed a tree se-
quence based tree-to-tree model which can de-
scribe non-syntactic phrases with syntactic struc-
ture information.
The converse of the above methods is to in-
corporate syntactic information into the PBMT
model. Zollmann and Venugopal (2006) started
with a complete set of phrases as extracted by
traditional PBMT heuristics, and then annotated
the target side of each phrasal entry with the la-
bel of the constituent node in the target-side
parse tree that subsumes the span. Marton and
Resnik (2008) and Cherry (2008) imposed syn-
tactic constraints on the PBMT system by mak-
ing use of prior linguistic knowledge in the form
of syntax analysis. In their PBMT decoders, a
candidate translation gets an extra credit if it re-
spects the source side syntactic parse tree but
may incur a cost if it violates a constituent
boundary. Xiong et al. (2009) proposed a syn-
tax-driven bracketing model to predict whether a
phrase (a sequence of contiguous words) is
bracketable or not using rich syntactic con-
straints.
In this paper, we try to utilize syntactic
knowledge to constrain the phrase extraction
from word-based alignments for PBMT system.
Rather than filter out all non-syntactic phrases,
we only apply syntactic constraints when there is
phrase segmentation ambiguity arising from un-
aligned words. Our method is very simple and
yields a 24.38% phrase pair reduction and a 0.52
BLEU point improvement when compared to the
baseline PBMT system with full-size tables.
</bodyText>
<sectionHeader confidence="0.695948" genericHeader="method">
2 Extracting Phrase Pairs from Word-
based Alignments
</sectionHeader>
<bodyText confidence="0.990088666666667">
In this section, we briefly review a simple and
effective phrase pair extraction algorithm upon
which this work builds.
</bodyText>
<page confidence="0.989648">
28
</page>
<note confidence="0.8028405">
Proceedings of SSST-4, Fourth Workshop on Syntax and Structure in Statistical Translation, pages 28–33,
COLING 2010, Beijing, August 2010.
</note>
<bodyText confidence="0.999714111111111">
The basic translation unit of a PBMT model is
the phrase pair, which consists of a sequence of
source words, a sequence of target words and a
vector of feature values which represents this
pair’s contribution to the translation model. In
typical PBMT systems such as MOSES (Koehn,
2007), phrase pairs are extracted from word-
aligned parallel corpora. Figure 1 shows the
form of training example.
</bodyText>
<equation confidence="0.999166666666667">
f1 f2 f3 f4

e1 e2 e3
</equation>
<figureCaption confidence="0.8955175">
Figure 1: An example parallel sentence pair
and word alignment
</figureCaption>
<bodyText confidence="0.999931777777778">
Since there is no phrase segmentation infor-
mation in the word-aligned sentence pair, in
target word sequence” that are consistent with
word alignments are collected. The words in a
legal phrase pair are only aligned to each other,
and not to words outside (Och et al., 1999). For
example, given a sentence pair and its word
alignments shown in Figure1, the following nine
phrase pairs will be extracted:
</bodyText>
<tableCaption confidence="0.553183">
Table 1: Phrase pairs extracted from the example
in Figure 1
</tableCaption>
<bodyText confidence="0.999039304347826">
Note that neither the source phrase nor the
not a legal phrase pair.
Phrase pairs are extracted over the entire
training corpus. Given all the collected phrase
pairs, we can estimate the phrase translation
probability distribution by relative frequency.
The collected phrase pairs will also be used to
build the lexicalized reordering model. For more
details of the lexicalized reordering model,
please refer to Tillmann and Zhang (2005) and
section 2.7.2 of the MOSES’s manual1.
The main problem of such a phrase pair ex-
traction procedure is the resulting phrase transla-
tion table is very large, especially when a large
quantity of parallel data is available. This is not
desirable in real application where speed and
memory consumption are often critical concerns.
In addition, some phrase translation pairs are
generated from training data errors and word
alignment noise. Therefore, we need to filter the
phrase table in an appropriate way for both effi-
ciency and translation quality (Johnson et al.,
2007; Yang and Zheng, 2009).
</bodyText>
<sectionHeader confidence="0.9865115" genericHeader="method">
3 Syntactic Constraints on Phrase Pair
Extraction
</sectionHeader>
<bodyText confidence="0.999964333333333">
We can divide all the possible phrases into two
types: syntactic phrases and non-syntactic
phrases. A “syntactic phrase” is defined as a
word sequence that is covered by a single sub-
tree in a syntactic parse tree (Imamura, 2002).
Intuitively, we would think syntactic phrases are
much more reliable while the non-syntactic
phrases are useless. However, (Koehn et al.,
2003) showed that restricting phrasal translation
to only syntactic phrases yields poor translation
performance – the ability to translate non-
syntactic phrases (such as “there are”, “note
that”, and “according to”) turns out to be critical
and pervasive.
(Koehn et al., 2003) uses syntactic constraints
from both the source and target languages, and
over 80% of all phrase pairs are eliminated. In
this section, we try to use syntactic knowledge in
a less restrictive way.
Firstly, instead of using syntactic restriction
on both source phrases and target phrases, we
only apply syntactic restriction to the source
language side.
Secondly, we only apply syntactic restriction
to the source phrase whose first or last word is
unaligned.
For example, given a parse tree illustrated in
Figure 2, we will filter out the phrase pair “f2 f3
  e2” since the source phrase “f2 f3” is a non-
syntactic phrase and its last word “f3” is not
</bodyText>
<footnote confidence="0.962747">
1 http://www.statmt.org/moses/
</footnote>
<page confidence="0.998297">
29
</page>
<bodyText confidence="0.995815166666667">
aligned to any target word. The phrase pair “f1
same reason. But we do keep phrase pairs such
f2” is a non-syntactic phrase. Also, we keep “f3
ble 2 shows the completed set of phrase pairs
that are extracted with our constraint-based
method.
</bodyText>
<tableCaption confidence="0.663174">
Table 2: Phrase pairs extracted from the example
in Figure 2
</tableCaption>
<equation confidence="0.7404615">
f1 f2 f3 f4
e1 e2 e3
</equation>
<figureCaption confidence="0.9614285">
Figure 2: An example parse tree and word-
based alignments
</figureCaption>
<bodyText confidence="0.999966416666667">
The state-of-the-art alignment tool such as
GIZA++2 can not always find alignments for
every word in the sentence pair. The possible
reasons could be: its frequency is too low, noisy
data, auxiliary words or function words which
have no obvious correspondence in the opposite
language.
In the automatically aligned parallel corpus,
unaligned words are frequent enough to be no-
ticeable (see section 4.1 in this paper). How to
decide the translation of unaligned word is left to
the phrase extraction algorithm. An unaligned
</bodyText>
<footnote confidence="0.67967">
2 http://fjoch.com/GIZA++.html
</footnote>
<bodyText confidence="0.999894">
source word should be translated together with
the words on the right of it or the words on the
left of it. The existing algorithm considers both
unlikely that “f3” can be translated into both
“e2” and “e3”. So our algorithm uses prior syn-
</bodyText>
<sectionHeader confidence="0.999693" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999951045454546">
Our SMT system is based on a fairly typical
phrase-based model (Finch and Sumita, 2008).
For the training of our SMT model, we use a
modified training toolkit adapted from the
MOSES decoder. Our decoder can operate on
the same principles as the MOSES decoder.
Minimum error rate training (MERT) with re-
spect to BLEU score is used to tune the de-
coder’s parameters, and it is performed using the
standard technique of Och (2003). A lexicalized
reordering model was built by using the “msd-
bidirectional-fe” configuration in our experi-
ments.
The translation model was created from the
FBIS parallel corpus. We used a 5-gram lan-
guage model trained with modified Kneser-Ney
smoothing. The language model was trained on
the target side of the FBIS corpus and the Xin-
hua news in the GIGAWORD corpus. The de-
velopment and test sets are from the NIST MT08
evaluation campaign. Table 3 shows the statis-
tics of the corpora used in our experiments.
</bodyText>
<table confidence="0.999553333333333">
Data Sentences Chinese English
words words
Training set 221,994 6,251,554 8,065,629
Development set 1,664 38,779 46,387
Test set 1,357 32,377 42,444
GIGAWORD 19,049,757 - 306,221,306
</table>
<tableCaption confidence="0.999855">
Table 3: Corpora statistics
</tableCaption>
<bodyText confidence="0.9989988">
The Chinese sentences are segmented, POS
tagged and parsed by the tools described in Kru-
engkrai et al. (2009) and Cao et al. (2007), both
of which are trained on the Penn Chinese Tree-
bank 6.0.
</bodyText>
<equation confidence="0.858373333333333">
N2
N3
N1
</equation>
<page confidence="0.989894">
30
</page>
<subsectionHeader confidence="0.956493">
4.1 Experiments on Word Alignments
</subsectionHeader>
<bodyText confidence="0.99990775">
We use GIZA++ to align the sentences in both
the Chinese-English and English-Chinese direc-
tions. Then we combine the alignments using the
standard “grow-diag-final-and” procedure pro-
vided with MOSES.
In the combined word alignments, 614,369 or
9.82% of the Chinese words are unaligned. Ta-
ble 4 shows the top 10 most frequently un-
aligned words. Basically, these words are auxil-
iary words or function words whose usage is
very flexible. So it would be difficult to auto-
matically align them to the target words.
</bodyText>
<figure confidence="0.660153181818182">
Unaligned word Frequency
kj 77776
, 29051
在 9414
一 8768
中 8543
个 7471
是 7365
上 6155
T 5945
不 5450
</figure>
<tableCaption confidence="0.9887825">
Table 4: Frequently unaligned words from the
training corpus
</tableCaption>
<subsectionHeader confidence="0.966496">
4.2 Experiments on Chinese-English SMT
</subsectionHeader>
<bodyText confidence="0.999763666666667">
In order to confirm that it is advantageous to
apply appropriate syntactic constraints on phrase
extraction, we performed three translation ex-
periments by using different ways of phrase ex-
traction.
In the first experiment, we used the method
introduced in Section 2 to extract all possible
phrase translation pairs without using any con-
straints arising from knowledge of syntax.
The second experiment used source language
syntactic constraints to filter out all non-
syntactic phrases during phrase pair extraction.
The third experiment used source language
syntactic constraints to filter out only non-
syntactic phrases whose first or last source word
was unaligned.
With the exception of the above differences in
phrase translation pair extraction, all the other
settings were the identical in the three
experiments. Table 5 summarizes the SMT per-
formance. The evaluation metric is case-
sensitive BLEU-4 (Papineni et al., 2002) which
estimates the accuracy of translation output with
respect to a set of reference translations.
</bodyText>
<table confidence="0.993919">
Syntactic Con- Number of BLEU
straints distinct phrase pairs
None 14,195,686 17.26
Full constraint 4,855,108 16.51
Selectively 10,733,731 17.78
constraint
</table>
<tableCaption confidence="0.954235">
Table 5: Comparison of different constraints on
phrase pair extraction by translation quality
</tableCaption>
<bodyText confidence="0.999964142857143">
As shown in the table, it is harmful to fully
apply syntactic constraints on phrase extraction,
even just on the source language side. This is
consistent with the observation of (Koehn et al.,
2003) who applied both source and target con-
straints in German to English translation ex-
periments.
Clearly, we obtained the best performance if
we use source language syntactic constraints
only on phrases whose first or last source word
is unaligned. In addition, we reduced the number
of distinct phrase pairs by 24.38% over the base-
line full-size phrase table.
The results in table 5 show that while some
non-syntactic phrases are very important to
maintain the performance of a PBMT system,
not all of them are necessary. We can achieve
better performance and a smaller phrase table by
applying syntactic constraints when there is
phrase segmentation ambiguity arising from un-
aligned words.
</bodyText>
<sectionHeader confidence="0.999876" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999982444444444">
To some extent, our idea is similar to Ma et al.
(2008), who used an anchor word alignment
model to find a set of high-precision anchor
links and then aligned the remaining words rely-
ing on dependency information invoked by the
acquired anchor links. The similarity is that both
Ma et al. (2008) and this work utilize structure
information to find appropriate translations for
words which are difficult to align. The differ-
</bodyText>
<page confidence="0.99972">
31
</page>
<bodyText confidence="0.999968461538462">
ence is that they used dependency information in
the word alignment stage while our method uses
syntactic information during the phrase pair ex-
traction stage. There are also many works which
leverage syntax information to improve word
alignments (e.g., Cherry and Lin, 2006; DeNero
and Klein, 2007; Fossum et al., 2008; Hermja-
kob, 2009).
Johnson et al., (2007) presented a technique
for pruning the phrase table in a PBMT system
using Fisher’s exact test. They compute the sig-
nificance value of each phrase pair and prune the
table by deleting phrase pairs with significance
values smaller than a certain threshold. Yang
and Zheng (2008) extended the work in Johnson
et al., (2007) to a hierarchical PBMT model,
which is built on synchronous context free
grammars (SCFG). Tomeh et al., (2009) de-
scribed an approach for filtering phrase tables in
a statistical machine translation system, which
relies on a statistical independence measure
called Noise, first introduced in (Moore, 2004).
The difference between the above research and
this work is they took advantage of some statis-
tical measures while we use syntactic knowledge
to filter phrase tables.
</bodyText>
<sectionHeader confidence="0.996162" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999904866666666">
Phrase pair extraction plays a very important
role on the performance of PBMT systems. We
utilize syntactic knowledge to constrain the
phrase extraction from word-based alignments
for a PBMT system. Rather than filter out all
non-syntactic phrases, we only filter out non-
syntactic phrases whose first or last source word
is unaligned. Our method is very simple and
yields a 24.38% phrase pair reduction and a 0.52
BLEU point improvement when compared to the
baseline PBMT system with full-size tables.
In the future work, we will use other language
pairs to test our phrase extraction method so that
we can discover whether or not it is language
independent.
</bodyText>
<sectionHeader confidence="0.998981" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999593518518519">
Robert C. Moore. 2004. On log-likelihood-ratios and
the significance of rare events. In EMNLP.
Hailong Cao, Yujie Zhang and Hitoshi Isahara. Em-
pirical study on parsing Chinese based on Collins&apos;
model. 2007. In PACLING.
Colin Cherry and Dekang Lin. 2006. Soft syntactic
constraints for word alignment through discrimina-
tive training. In ACL.
Colin Cherry. 2008. Cohesive phrase-Based decoding
for statistical machine translation. In ACL-HLT.
David Chiang. 2005. A hierarchical phrase-based
model for statistical machine translation. In ACL.
Steve DeNeefe, Kevin Knight, Wei Wang, and
Daniel Marcu. 2007. What can syntax-based MT
learn from phrase-based MT? In EMNLP-CoNLL.
John DeNero and Dan Klein. 2007. Tailoring word
alignments to syntactic machine translation. In
ACL.
Andrew Finch and Eiichiro Sumita. 2008. Dynamic
model interpolation for statistical machine transla-
tion. In SMT Workshop.
Victoria Fossum, Kevin Knight and Steven Abney.
2008. Using syntax to improve word alignment
precision for syntax-based machine translation. In
SMT Workshop, ACL.
Michel Galley, Jonathan Graehl, Kevin Knight,
Daniel Marcu, Steve Deneefe, Wei Wang and
Ignacio Thayer. 2006. Scalable inference and
training of context-rich syntactic translation mod-
els. In ACL.
Ulf Hermjakob. 2009. Improved word alignment with
statistics and linguistic heuristics. In EMNLP.
Kenji Imamura. 2002. Application of translation
knowledge acquired by hierarchical phrase align-
ment for pattern-based MT. In TMI.
Howard Johnson, Joel Martin, George Foster and
Roland Kuhn. 2007. Improving translation quality
by discarding most of the phrase table. In EMNLP-
CoNLL.
Franz Josef Och, Christoph Tillmann and Hermann
Ney. 1999. Improved alignment models for statis-
tical machine translation. In EMNLP-VLC.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In ACL.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In HLT-
NAACL.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Ber-
toldi, Brooke Cowan, Wade Shen, Christine
Moran, Richard Zens, Chris Dyer, Ondrej Bojar,
Alexandra Constantin, Evan Herbst. 2007. Moses:
Open Source Toolkit for Statistical Machine
Translation. In ACL demo and poster sessions.
</reference>
<page confidence="0.984068">
32
</page>
<reference confidence="0.999841063829787">
Canasai Kruengkrai, Kiyotaka Uchimoto, Jun&apos;ichi
Kazama, Yiou Wang, Kentaro Torisawa and Hito-
shi Isahara. 2009. An error-driven word-character
hybrid model for joint Chinese word segmentation
and POS tagging. In ACL-IJCNLP.
Yang Liu, Qun Liu, Shouxun Lin. 2006. Tree-to-
string alignment template for statistical machine
translation. In ACL-COLING.
Yang Liu, Yun Huang, Qun Liu and Shouxun Lin.
2007. Forest-to-string statistical translation rules.
In ACL.
Yanjun Ma, Sylwia Ozdowska, Yanli Sun and Andy
Way. 2008. Improving word alignment using syn-
tactic dependencies. In SSST.
Daniel Marcu, Wei Wang, Abdessamad Echihabi,
and Kevin Knight. 2006. SPMT: Statistical ma-
chine translation with syntactified target language
phrases. In EMNLP.
Yuval Marton and Philip Resnik. 2008. Soft syntactic
constraints for hierarchical phrased-based transla-
tion. In ACL-HLT.
Kishore Papineni, Salim Roukos, Todd Ward and
WeiJing Zhu. 2002. BLEU: a method for auto-
matic evaluation of machine translation. In ACL.
Chris Quirk and Arul Menezes and Colin Cherry.
2005. Dependency treelet translation: Syntactically
informed phrasal SMT. In ACL.
Christoph Tillmann and Tong Zhang. 2005. A local-
ized prediction model for statistical machine trans-
lation. In ACL.
Nadi Tomeh, Nicola Cancedda and Marc Dymetman.
2009. Complexity-based phrase-table filtering for
statistical machine translation. In MT Summit.
Deyi Xiong, Min Zhang, Aiti Aw and Haizhou Li.
2009. A syntax-driven bracketing model for
phrase-based translation. In ACL-IJCNLP.
Kenji Yamada and Kevin Knight. 2000. A syntax-
based statistical translation model. In ACL.
Mei Yang and Jing Zheng. 2009. Toward smaller,
faster, and better hierarchical phrase-based SMT.
In ACL.
Min Zhang, Hongfei Jiang, Aiti Aw, Chew Lim Tan
and Sheng Li. 2008. A tree sequence alignment-
based tree-to-tree translation model. In ACL- HLT.
Andreas Zollmann and Ashish Venugopal. 2006.
Syntax augmented machine translation via chart
parsing. In SMT Workshop, HLT-NAACL.
</reference>
<page confidence="0.999379">
33
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.592760">
<title confidence="0.974268">Syntactic Constraints on Phrase Extraction for Phrase-Based Machine Translation Hailong Cao, Andrew Finch and Eiichiro Language Translation Group, MASTAR National Institute of Information and Communications</title>
<author confidence="0.605417">andrew finch hlcao</author>
<author confidence="0.605417">eiichiro sumita nict go jp</author>
<abstract confidence="0.9996984">A typical phrase-based machine translation (PBMT) system uses phrase pairs extracted from word-aligned parallel corpora. All phrase pairs that are consistent with word alignments are collected. The resulting phrase table is very large and includes many non-syntactic phrases which may not be necessary. We propose to filter the phrase table based on source language syntactic constraints. Rather than filter out all non-syntactic phrases, we only apply syntactic constraints when there is phrase segmentation ambiguity arising from unaligned words. Our method is very simple and yields a 24.38% phrase pair reduction and a 0.52 BLEU point improvement when compared to a baseline PBMT system with full-size tables.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Tomeh</author>
</authors>
<title>which is built on synchronous context free grammars</title>
<date>2009</date>
<marker>Tomeh, 2009</marker>
<rawString>which is built on synchronous context free grammars (SCFG). Tomeh et al., (2009) described an approach for filtering phrase tables in a statistical machine translation system, which relies on a statistical independence measure called Noise, first introduced in (Moore, 2004). The difference between the above research and this work is they took advantage of some statistical measures while we use syntactic knowledge to filter phrase tables. 6 Conclusion and Future Work Phrase pair extraction plays a very important role on the performance of PBMT systems. We utilize syntactic knowledge to constrain the phrase extraction from word-based alignments for a PBMT system. Rather than filter out all non-syntactic phrases, we only filter out nonsyntactic phrases whose first or last source word is unaligned. Our method is very simple and yields a 24.38% phrase pair reduction and a 0.52 BLEU point improvement when compared to the baseline PBMT system with full-size tables.</rawString>
</citation>
<citation valid="false">
<title>In the future work, we will use other language pairs to test our phrase extraction method so that we can discover whether or not it is language independent.</title>
<marker></marker>
<rawString>In the future work, we will use other language pairs to test our phrase extraction method so that we can discover whether or not it is language independent.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>On log-likelihood-ratios and the significance of rare events.</title>
<date>2004</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="13774" citStr="Moore, 2004" startWordPosition="2224" endWordPosition="2225">echnique for pruning the phrase table in a PBMT system using Fisher’s exact test. They compute the significance value of each phrase pair and prune the table by deleting phrase pairs with significance values smaller than a certain threshold. Yang and Zheng (2008) extended the work in Johnson et al., (2007) to a hierarchical PBMT model, which is built on synchronous context free grammars (SCFG). Tomeh et al., (2009) described an approach for filtering phrase tables in a statistical machine translation system, which relies on a statistical independence measure called Noise, first introduced in (Moore, 2004). The difference between the above research and this work is they took advantage of some statistical measures while we use syntactic knowledge to filter phrase tables. 6 Conclusion and Future Work Phrase pair extraction plays a very important role on the performance of PBMT systems. We utilize syntactic knowledge to constrain the phrase extraction from word-based alignments for a PBMT system. Rather than filter out all non-syntactic phrases, we only filter out nonsyntactic phrases whose first or last source word is unaligned. Our method is very simple and yields a 24.38% phrase pair reduction </context>
</contexts>
<marker>Moore, 2004</marker>
<rawString>Robert C. Moore. 2004. On log-likelihood-ratios and the significance of rare events. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hailong Cao</author>
</authors>
<title>Yujie Zhang and Hitoshi Isahara. Empirical study on parsing Chinese based on Collins&apos; model.</title>
<date>2007</date>
<booktitle>In PACLING.</booktitle>
<marker>Cao, 2007</marker>
<rawString>Hailong Cao, Yujie Zhang and Hitoshi Isahara. Empirical study on parsing Chinese based on Collins&apos; model. 2007. In PACLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
<author>Dekang Lin</author>
</authors>
<title>Soft syntactic constraints for word alignment through discriminative training.</title>
<date>2006</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="13061" citStr="Cherry and Lin, 2006" startWordPosition="2107" endWordPosition="2110">d alignment model to find a set of high-precision anchor links and then aligned the remaining words relying on dependency information invoked by the acquired anchor links. The similarity is that both Ma et al. (2008) and this work utilize structure information to find appropriate translations for words which are difficult to align. The differ31 ence is that they used dependency information in the word alignment stage while our method uses syntactic information during the phrase pair extraction stage. There are also many works which leverage syntax information to improve word alignments (e.g., Cherry and Lin, 2006; DeNero and Klein, 2007; Fossum et al., 2008; Hermjakob, 2009). Johnson et al., (2007) presented a technique for pruning the phrase table in a PBMT system using Fisher’s exact test. They compute the significance value of each phrase pair and prune the table by deleting phrase pairs with significance values smaller than a certain threshold. Yang and Zheng (2008) extended the work in Johnson et al., (2007) to a hierarchical PBMT model, which is built on synchronous context free grammars (SCFG). Tomeh et al., (2009) described an approach for filtering phrase tables in a statistical machine trans</context>
</contexts>
<marker>Cherry, Lin, 2006</marker>
<rawString>Colin Cherry and Dekang Lin. 2006. Soft syntactic constraints for word alignment through discriminative training. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
</authors>
<title>Cohesive phrase-Based decoding for statistical machine translation.</title>
<date>2008</date>
<booktitle>In ACL-HLT.</booktitle>
<contexts>
<context position="2290" citStr="Cherry (2008)" startWordPosition="347" endWordPosition="348">pture the non-syntactic phrases in their tree-to-string model. Zhang et al. (2008) proposed a tree sequence based tree-to-tree model which can describe non-syntactic phrases with syntactic structure information. The converse of the above methods is to incorporate syntactic information into the PBMT model. Zollmann and Venugopal (2006) started with a complete set of phrases as extracted by traditional PBMT heuristics, and then annotated the target side of each phrasal entry with the label of the constituent node in the target-side parse tree that subsumes the span. Marton and Resnik (2008) and Cherry (2008) imposed syntactic constraints on the PBMT system by making use of prior linguistic knowledge in the form of syntax analysis. In their PBMT decoders, a candidate translation gets an extra credit if it respects the source side syntactic parse tree but may incur a cost if it violates a constituent boundary. Xiong et al. (2009) proposed a syntax-driven bracketing model to predict whether a phrase (a sequence of contiguous words) is bracketable or not using rich syntactic constraints. In this paper, we try to utilize syntactic knowledge to constrain the phrase extraction from word-based alignments</context>
</contexts>
<marker>Cherry, 2008</marker>
<rawString>Colin Cherry. 2008. Cohesive phrase-Based decoding for statistical machine translation. In ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1071" citStr="Chiang, 2005" startWordPosition="149" endWordPosition="150"> alignments are collected. The resulting phrase table is very large and includes many non-syntactic phrases which may not be necessary. We propose to filter the phrase table based on source language syntactic constraints. Rather than filter out all non-syntactic phrases, we only apply syntactic constraints when there is phrase segmentation ambiguity arising from unaligned words. Our method is very simple and yields a 24.38% phrase pair reduction and a 0.52 BLEU point improvement when compared to a baseline PBMT system with full-size tables. 1 Introduction Both PBMT models (Koehn et al., 2003; Chiang, 2005) and syntax-based machine translation models (Yamada et al., 2000; Quirk et al., 2005; Galley et al., 2006; Liu et al., 2006; Marcu et al., 2006; and numerous others) are the state-of-theart statistical machine translation (SMT) methods. Over the last several years, an increasing amount of work has been done to combine the advantages of the two approaches. DeNeefe et al. (2007) made a quantitative comparison of the phrase pairs that each model has to work with and found it is useful to improve the phrasal coverage of their string-to-tree model. Liu et al. (2007) proposed forest-to-string rules</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A hierarchical phrase-based model for statistical machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve DeNeefe</author>
<author>Kevin Knight</author>
<author>Wei Wang</author>
<author>Daniel Marcu</author>
</authors>
<title>What can syntax-based MT learn from phrase-based MT?</title>
<date>2007</date>
<booktitle>In EMNLP-CoNLL.</booktitle>
<contexts>
<context position="1451" citStr="DeNeefe et al. (2007)" startWordPosition="210" endWordPosition="213">ed words. Our method is very simple and yields a 24.38% phrase pair reduction and a 0.52 BLEU point improvement when compared to a baseline PBMT system with full-size tables. 1 Introduction Both PBMT models (Koehn et al., 2003; Chiang, 2005) and syntax-based machine translation models (Yamada et al., 2000; Quirk et al., 2005; Galley et al., 2006; Liu et al., 2006; Marcu et al., 2006; and numerous others) are the state-of-theart statistical machine translation (SMT) methods. Over the last several years, an increasing amount of work has been done to combine the advantages of the two approaches. DeNeefe et al. (2007) made a quantitative comparison of the phrase pairs that each model has to work with and found it is useful to improve the phrasal coverage of their string-to-tree model. Liu et al. (2007) proposed forest-to-string rules to capture the non-syntactic phrases in their tree-to-string model. Zhang et al. (2008) proposed a tree sequence based tree-to-tree model which can describe non-syntactic phrases with syntactic structure information. The converse of the above methods is to incorporate syntactic information into the PBMT model. Zollmann and Venugopal (2006) started with a complete set of phrase</context>
</contexts>
<marker>DeNeefe, Knight, Wang, Marcu, 2007</marker>
<rawString>Steve DeNeefe, Kevin Knight, Wei Wang, and Daniel Marcu. 2007. What can syntax-based MT learn from phrase-based MT? In EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Tailoring word alignments to syntactic machine translation.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="13085" citStr="DeNero and Klein, 2007" startWordPosition="2111" endWordPosition="2114">ind a set of high-precision anchor links and then aligned the remaining words relying on dependency information invoked by the acquired anchor links. The similarity is that both Ma et al. (2008) and this work utilize structure information to find appropriate translations for words which are difficult to align. The differ31 ence is that they used dependency information in the word alignment stage while our method uses syntactic information during the phrase pair extraction stage. There are also many works which leverage syntax information to improve word alignments (e.g., Cherry and Lin, 2006; DeNero and Klein, 2007; Fossum et al., 2008; Hermjakob, 2009). Johnson et al., (2007) presented a technique for pruning the phrase table in a PBMT system using Fisher’s exact test. They compute the significance value of each phrase pair and prune the table by deleting phrase pairs with significance values smaller than a certain threshold. Yang and Zheng (2008) extended the work in Johnson et al., (2007) to a hierarchical PBMT model, which is built on synchronous context free grammars (SCFG). Tomeh et al., (2009) described an approach for filtering phrase tables in a statistical machine translation system, which rel</context>
</contexts>
<marker>DeNero, Klein, 2007</marker>
<rawString>John DeNero and Dan Klein. 2007. Tailoring word alignments to syntactic machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Finch</author>
<author>Eiichiro Sumita</author>
</authors>
<title>Dynamic model interpolation for statistical machine translation.</title>
<date>2008</date>
<booktitle>In SMT Workshop.</booktitle>
<contexts>
<context position="8179" citStr="Finch and Sumita, 2008" startWordPosition="1312" endWordPosition="1315">site language. In the automatically aligned parallel corpus, unaligned words are frequent enough to be noticeable (see section 4.1 in this paper). How to decide the translation of unaligned word is left to the phrase extraction algorithm. An unaligned 2 http://fjoch.com/GIZA++.html source word should be translated together with the words on the right of it or the words on the left of it. The existing algorithm considers both unlikely that “f3” can be translated into both “e2” and “e3”. So our algorithm uses prior syn4 Experiments Our SMT system is based on a fairly typical phrase-based model (Finch and Sumita, 2008). For the training of our SMT model, we use a modified training toolkit adapted from the MOSES decoder. Our decoder can operate on the same principles as the MOSES decoder. Minimum error rate training (MERT) with respect to BLEU score is used to tune the decoder’s parameters, and it is performed using the standard technique of Och (2003). A lexicalized reordering model was built by using the “msdbidirectional-fe” configuration in our experiments. The translation model was created from the FBIS parallel corpus. We used a 5-gram language model trained with modified Kneser-Ney smoothing. The lang</context>
</contexts>
<marker>Finch, Sumita, 2008</marker>
<rawString>Andrew Finch and Eiichiro Sumita. 2008. Dynamic model interpolation for statistical machine translation. In SMT Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victoria Fossum</author>
<author>Kevin Knight</author>
<author>Steven Abney</author>
</authors>
<title>Using syntax to improve word alignment precision for syntax-based machine translation.</title>
<date>2008</date>
<booktitle>In SMT Workshop, ACL.</booktitle>
<contexts>
<context position="13106" citStr="Fossum et al., 2008" startWordPosition="2115" endWordPosition="2118">ion anchor links and then aligned the remaining words relying on dependency information invoked by the acquired anchor links. The similarity is that both Ma et al. (2008) and this work utilize structure information to find appropriate translations for words which are difficult to align. The differ31 ence is that they used dependency information in the word alignment stage while our method uses syntactic information during the phrase pair extraction stage. There are also many works which leverage syntax information to improve word alignments (e.g., Cherry and Lin, 2006; DeNero and Klein, 2007; Fossum et al., 2008; Hermjakob, 2009). Johnson et al., (2007) presented a technique for pruning the phrase table in a PBMT system using Fisher’s exact test. They compute the significance value of each phrase pair and prune the table by deleting phrase pairs with significance values smaller than a certain threshold. Yang and Zheng (2008) extended the work in Johnson et al., (2007) to a hierarchical PBMT model, which is built on synchronous context free grammars (SCFG). Tomeh et al., (2009) described an approach for filtering phrase tables in a statistical machine translation system, which relies on a statistical </context>
</contexts>
<marker>Fossum, Knight, Abney, 2008</marker>
<rawString>Victoria Fossum, Kevin Knight and Steven Abney. 2008. Using syntax to improve word alignment precision for syntax-based machine translation. In SMT Workshop, ACL.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Michel Galley</author>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Steve Deneefe, Wei Wang and training of context-rich syntactic translation models.</title>
<booktitle>In ACL.</booktitle>
<marker>Galley, Graehl, Knight, Marcu, </marker>
<rawString>Michel Galley, Jonathan Graehl, Kevin Knight, Daniel Marcu, Steve Deneefe, Wei Wang and training of context-rich syntactic translation models. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulf Hermjakob</author>
</authors>
<title>Improved word alignment with statistics and linguistic heuristics.</title>
<date>2009</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="13124" citStr="Hermjakob, 2009" startWordPosition="2119" endWordPosition="2121">then aligned the remaining words relying on dependency information invoked by the acquired anchor links. The similarity is that both Ma et al. (2008) and this work utilize structure information to find appropriate translations for words which are difficult to align. The differ31 ence is that they used dependency information in the word alignment stage while our method uses syntactic information during the phrase pair extraction stage. There are also many works which leverage syntax information to improve word alignments (e.g., Cherry and Lin, 2006; DeNero and Klein, 2007; Fossum et al., 2008; Hermjakob, 2009). Johnson et al., (2007) presented a technique for pruning the phrase table in a PBMT system using Fisher’s exact test. They compute the significance value of each phrase pair and prune the table by deleting phrase pairs with significance values smaller than a certain threshold. Yang and Zheng (2008) extended the work in Johnson et al., (2007) to a hierarchical PBMT model, which is built on synchronous context free grammars (SCFG). Tomeh et al., (2009) described an approach for filtering phrase tables in a statistical machine translation system, which relies on a statistical independence measu</context>
</contexts>
<marker>Hermjakob, 2009</marker>
<rawString>Ulf Hermjakob. 2009. Improved word alignment with statistics and linguistic heuristics. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Imamura</author>
</authors>
<title>Application of translation knowledge acquired by hierarchical phrase alignment for pattern-based MT. In TMI.</title>
<date>2002</date>
<contexts>
<context position="5805" citStr="Imamura, 2002" startWordPosition="921" endWordPosition="922">tion where speed and memory consumption are often critical concerns. In addition, some phrase translation pairs are generated from training data errors and word alignment noise. Therefore, we need to filter the phrase table in an appropriate way for both efficiency and translation quality (Johnson et al., 2007; Yang and Zheng, 2009). 3 Syntactic Constraints on Phrase Pair Extraction We can divide all the possible phrases into two types: syntactic phrases and non-syntactic phrases. A “syntactic phrase” is defined as a word sequence that is covered by a single subtree in a syntactic parse tree (Imamura, 2002). Intuitively, we would think syntactic phrases are much more reliable while the non-syntactic phrases are useless. However, (Koehn et al., 2003) showed that restricting phrasal translation to only syntactic phrases yields poor translation performance – the ability to translate nonsyntactic phrases (such as “there are”, “note that”, and “according to”) turns out to be critical and pervasive. (Koehn et al., 2003) uses syntactic constraints from both the source and target languages, and over 80% of all phrase pairs are eliminated. In this section, we try to use syntactic knowledge in a less rest</context>
</contexts>
<marker>Imamura, 2002</marker>
<rawString>Kenji Imamura. 2002. Application of translation knowledge acquired by hierarchical phrase alignment for pattern-based MT. In TMI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Howard Johnson</author>
<author>Joel Martin</author>
<author>George Foster</author>
<author>Roland Kuhn</author>
</authors>
<title>Improving translation quality by discarding most of the phrase table.</title>
<date>2007</date>
<booktitle>In EMNLPCoNLL.</booktitle>
<contexts>
<context position="5502" citStr="Johnson et al., 2007" startWordPosition="869" endWordPosition="872">model, please refer to Tillmann and Zhang (2005) and section 2.7.2 of the MOSES’s manual1. The main problem of such a phrase pair extraction procedure is the resulting phrase translation table is very large, especially when a large quantity of parallel data is available. This is not desirable in real application where speed and memory consumption are often critical concerns. In addition, some phrase translation pairs are generated from training data errors and word alignment noise. Therefore, we need to filter the phrase table in an appropriate way for both efficiency and translation quality (Johnson et al., 2007; Yang and Zheng, 2009). 3 Syntactic Constraints on Phrase Pair Extraction We can divide all the possible phrases into two types: syntactic phrases and non-syntactic phrases. A “syntactic phrase” is defined as a word sequence that is covered by a single subtree in a syntactic parse tree (Imamura, 2002). Intuitively, we would think syntactic phrases are much more reliable while the non-syntactic phrases are useless. However, (Koehn et al., 2003) showed that restricting phrasal translation to only syntactic phrases yields poor translation performance – the ability to translate nonsyntactic phras</context>
<context position="13148" citStr="Johnson et al., (2007)" startWordPosition="2122" endWordPosition="2125">emaining words relying on dependency information invoked by the acquired anchor links. The similarity is that both Ma et al. (2008) and this work utilize structure information to find appropriate translations for words which are difficult to align. The differ31 ence is that they used dependency information in the word alignment stage while our method uses syntactic information during the phrase pair extraction stage. There are also many works which leverage syntax information to improve word alignments (e.g., Cherry and Lin, 2006; DeNero and Klein, 2007; Fossum et al., 2008; Hermjakob, 2009). Johnson et al., (2007) presented a technique for pruning the phrase table in a PBMT system using Fisher’s exact test. They compute the significance value of each phrase pair and prune the table by deleting phrase pairs with significance values smaller than a certain threshold. Yang and Zheng (2008) extended the work in Johnson et al., (2007) to a hierarchical PBMT model, which is built on synchronous context free grammars (SCFG). Tomeh et al., (2009) described an approach for filtering phrase tables in a statistical machine translation system, which relies on a statistical independence measure called Noise, first i</context>
</contexts>
<marker>Johnson, Martin, Foster, Kuhn, 2007</marker>
<rawString>Howard Johnson, Joel Martin, George Foster and Roland Kuhn. 2007. Improving translation quality by discarding most of the phrase table. In EMNLPCoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Christoph Tillmann</author>
<author>Hermann Ney</author>
</authors>
<title>Improved alignment models for statistical machine translation.</title>
<date>1999</date>
<booktitle>In EMNLP-VLC.</booktitle>
<contexts>
<context position="4302" citStr="Och et al., 1999" startWordPosition="676" endWordPosition="679">and a vector of feature values which represents this pair’s contribution to the translation model. In typical PBMT systems such as MOSES (Koehn, 2007), phrase pairs are extracted from wordaligned parallel corpora. Figure 1 shows the form of training example. f1 f2 f3 f4 e1 e2 e3 Figure 1: An example parallel sentence pair and word alignment Since there is no phrase segmentation information in the word-aligned sentence pair, in target word sequence” that are consistent with word alignments are collected. The words in a legal phrase pair are only aligned to each other, and not to words outside (Och et al., 1999). For example, given a sentence pair and its word alignments shown in Figure1, the following nine phrase pairs will be extracted: Table 1: Phrase pairs extracted from the example in Figure 1 Note that neither the source phrase nor the not a legal phrase pair. Phrase pairs are extracted over the entire training corpus. Given all the collected phrase pairs, we can estimate the phrase translation probability distribution by relative frequency. The collected phrase pairs will also be used to build the lexicalized reordering model. For more details of the lexicalized reordering model, please refer </context>
</contexts>
<marker>Och, Tillmann, Ney, 1999</marker>
<rawString>Franz Josef Och, Christoph Tillmann and Hermann Ney. 1999. Improved alignment models for statistical machine translation. In EMNLP-VLC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="8518" citStr="Och (2003)" startWordPosition="1374" endWordPosition="1375"> of it or the words on the left of it. The existing algorithm considers both unlikely that “f3” can be translated into both “e2” and “e3”. So our algorithm uses prior syn4 Experiments Our SMT system is based on a fairly typical phrase-based model (Finch and Sumita, 2008). For the training of our SMT model, we use a modified training toolkit adapted from the MOSES decoder. Our decoder can operate on the same principles as the MOSES decoder. Minimum error rate training (MERT) with respect to BLEU score is used to tune the decoder’s parameters, and it is performed using the standard technique of Och (2003). A lexicalized reordering model was built by using the “msdbidirectional-fe” configuration in our experiments. The translation model was created from the FBIS parallel corpus. We used a 5-gram language model trained with modified Kneser-Ney smoothing. The language model was trained on the target side of the FBIS corpus and the Xinhua news in the GIGAWORD corpus. The development and test sets are from the NIST MT08 evaluation campaign. Table 3 shows the statistics of the corpora used in our experiments. Data Sentences Chinese English words words Training set 221,994 6,251,554 8,065,629 Develop</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In HLTNAACL.</booktitle>
<contexts>
<context position="1056" citStr="Koehn et al., 2003" startWordPosition="145" endWordPosition="148">consistent with word alignments are collected. The resulting phrase table is very large and includes many non-syntactic phrases which may not be necessary. We propose to filter the phrase table based on source language syntactic constraints. Rather than filter out all non-syntactic phrases, we only apply syntactic constraints when there is phrase segmentation ambiguity arising from unaligned words. Our method is very simple and yields a 24.38% phrase pair reduction and a 0.52 BLEU point improvement when compared to a baseline PBMT system with full-size tables. 1 Introduction Both PBMT models (Koehn et al., 2003; Chiang, 2005) and syntax-based machine translation models (Yamada et al., 2000; Quirk et al., 2005; Galley et al., 2006; Liu et al., 2006; Marcu et al., 2006; and numerous others) are the state-of-theart statistical machine translation (SMT) methods. Over the last several years, an increasing amount of work has been done to combine the advantages of the two approaches. DeNeefe et al. (2007) made a quantitative comparison of the phrase pairs that each model has to work with and found it is useful to improve the phrasal coverage of their string-to-tree model. Liu et al. (2007) proposed forest-</context>
<context position="5950" citStr="Koehn et al., 2003" startWordPosition="940" endWordPosition="943">data errors and word alignment noise. Therefore, we need to filter the phrase table in an appropriate way for both efficiency and translation quality (Johnson et al., 2007; Yang and Zheng, 2009). 3 Syntactic Constraints on Phrase Pair Extraction We can divide all the possible phrases into two types: syntactic phrases and non-syntactic phrases. A “syntactic phrase” is defined as a word sequence that is covered by a single subtree in a syntactic parse tree (Imamura, 2002). Intuitively, we would think syntactic phrases are much more reliable while the non-syntactic phrases are useless. However, (Koehn et al., 2003) showed that restricting phrasal translation to only syntactic phrases yields poor translation performance – the ability to translate nonsyntactic phrases (such as “there are”, “note that”, and “according to”) turns out to be critical and pervasive. (Koehn et al., 2003) uses syntactic constraints from both the source and target languages, and over 80% of all phrase pairs are eliminated. In this section, we try to use syntactic knowledge in a less restrictive way. Firstly, instead of using syntactic restriction on both source phrases and target phrases, we only apply syntactic restriction to th</context>
<context position="11658" citStr="Koehn et al., 2003" startWordPosition="1877" endWordPosition="1880">. The evaluation metric is casesensitive BLEU-4 (Papineni et al., 2002) which estimates the accuracy of translation output with respect to a set of reference translations. Syntactic Con- Number of BLEU straints distinct phrase pairs None 14,195,686 17.26 Full constraint 4,855,108 16.51 Selectively 10,733,731 17.78 constraint Table 5: Comparison of different constraints on phrase pair extraction by translation quality As shown in the table, it is harmful to fully apply syntactic constraints on phrase extraction, even just on the source language side. This is consistent with the observation of (Koehn et al., 2003) who applied both source and target constraints in German to English translation experiments. Clearly, we obtained the best performance if we use source language syntactic constraints only on phrases whose first or last source word is unaligned. In addition, we reduced the number of distinct phrase pairs by 24.38% over the baseline full-size phrase table. The results in table 5 show that while some non-syntactic phrases are very important to maintain the performance of a PBMT system, not all of them are necessary. We can achieve better performance and a smaller phrase table by applying syntact</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In HLTNAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation. In ACL demo and poster sessions.</title>
<date>2007</date>
<pages>32</pages>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, Evan Herbst.</location>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, Evan Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In ACL demo and poster sessions. 32</rawString>
</citation>
<citation valid="true">
<authors>
<author>Canasai Kruengkrai</author>
</authors>
<title>Kiyotaka Uchimoto, Jun&apos;ichi Kazama, Yiou Wang, Kentaro Torisawa and Hitoshi Isahara.</title>
<date>2009</date>
<booktitle>In ACL-IJCNLP.</booktitle>
<marker>Kruengkrai, 2009</marker>
<rawString>Canasai Kruengkrai, Kiyotaka Uchimoto, Jun&apos;ichi Kazama, Yiou Wang, Kentaro Torisawa and Hitoshi Isahara. 2009. An error-driven word-character hybrid model for joint Chinese word segmentation and POS tagging. In ACL-IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Tree-tostring alignment template for statistical machine translation.</title>
<date>2006</date>
<booktitle>In ACL-COLING.</booktitle>
<contexts>
<context position="1195" citStr="Liu et al., 2006" startWordPosition="168" endWordPosition="171"> be necessary. We propose to filter the phrase table based on source language syntactic constraints. Rather than filter out all non-syntactic phrases, we only apply syntactic constraints when there is phrase segmentation ambiguity arising from unaligned words. Our method is very simple and yields a 24.38% phrase pair reduction and a 0.52 BLEU point improvement when compared to a baseline PBMT system with full-size tables. 1 Introduction Both PBMT models (Koehn et al., 2003; Chiang, 2005) and syntax-based machine translation models (Yamada et al., 2000; Quirk et al., 2005; Galley et al., 2006; Liu et al., 2006; Marcu et al., 2006; and numerous others) are the state-of-theart statistical machine translation (SMT) methods. Over the last several years, an increasing amount of work has been done to combine the advantages of the two approaches. DeNeefe et al. (2007) made a quantitative comparison of the phrase pairs that each model has to work with and found it is useful to improve the phrasal coverage of their string-to-tree model. Liu et al. (2007) proposed forest-to-string rules to capture the non-syntactic phrases in their tree-to-string model. Zhang et al. (2008) proposed a tree sequence based tree</context>
</contexts>
<marker>Liu, Liu, Lin, 2006</marker>
<rawString>Yang Liu, Qun Liu, Shouxun Lin. 2006. Tree-tostring alignment template for statistical machine translation. In ACL-COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Yun Huang</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Forest-to-string statistical translation rules.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1639" citStr="Liu et al. (2007)" startWordPosition="243" endWordPosition="246">th PBMT models (Koehn et al., 2003; Chiang, 2005) and syntax-based machine translation models (Yamada et al., 2000; Quirk et al., 2005; Galley et al., 2006; Liu et al., 2006; Marcu et al., 2006; and numerous others) are the state-of-theart statistical machine translation (SMT) methods. Over the last several years, an increasing amount of work has been done to combine the advantages of the two approaches. DeNeefe et al. (2007) made a quantitative comparison of the phrase pairs that each model has to work with and found it is useful to improve the phrasal coverage of their string-to-tree model. Liu et al. (2007) proposed forest-to-string rules to capture the non-syntactic phrases in their tree-to-string model. Zhang et al. (2008) proposed a tree sequence based tree-to-tree model which can describe non-syntactic phrases with syntactic structure information. The converse of the above methods is to incorporate syntactic information into the PBMT model. Zollmann and Venugopal (2006) started with a complete set of phrases as extracted by traditional PBMT heuristics, and then annotated the target side of each phrasal entry with the label of the constituent node in the target-side parse tree that subsumes t</context>
</contexts>
<marker>Liu, Huang, Liu, Lin, 2007</marker>
<rawString>Yang Liu, Yun Huang, Qun Liu and Shouxun Lin. 2007. Forest-to-string statistical translation rules. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yanjun Ma</author>
<author>Sylwia Ozdowska</author>
<author>Yanli Sun</author>
<author>Andy Way</author>
</authors>
<title>Improving word alignment using syntactic dependencies.</title>
<date>2008</date>
<booktitle>In SSST.</booktitle>
<contexts>
<context position="12417" citStr="Ma et al. (2008)" startWordPosition="2003" endWordPosition="2006">se source language syntactic constraints only on phrases whose first or last source word is unaligned. In addition, we reduced the number of distinct phrase pairs by 24.38% over the baseline full-size phrase table. The results in table 5 show that while some non-syntactic phrases are very important to maintain the performance of a PBMT system, not all of them are necessary. We can achieve better performance and a smaller phrase table by applying syntactic constraints when there is phrase segmentation ambiguity arising from unaligned words. 5 Related Work To some extent, our idea is similar to Ma et al. (2008), who used an anchor word alignment model to find a set of high-precision anchor links and then aligned the remaining words relying on dependency information invoked by the acquired anchor links. The similarity is that both Ma et al. (2008) and this work utilize structure information to find appropriate translations for words which are difficult to align. The differ31 ence is that they used dependency information in the word alignment stage while our method uses syntactic information during the phrase pair extraction stage. There are also many works which leverage syntax information to improve</context>
</contexts>
<marker>Ma, Ozdowska, Sun, Way, 2008</marker>
<rawString>Yanjun Ma, Sylwia Ozdowska, Yanli Sun and Andy Way. 2008. Improving word alignment using syntactic dependencies. In SSST.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>Wei Wang</author>
<author>Abdessamad Echihabi</author>
<author>Kevin Knight</author>
</authors>
<title>SPMT: Statistical machine translation with syntactified target language phrases.</title>
<date>2006</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="1215" citStr="Marcu et al., 2006" startWordPosition="172" endWordPosition="175">propose to filter the phrase table based on source language syntactic constraints. Rather than filter out all non-syntactic phrases, we only apply syntactic constraints when there is phrase segmentation ambiguity arising from unaligned words. Our method is very simple and yields a 24.38% phrase pair reduction and a 0.52 BLEU point improvement when compared to a baseline PBMT system with full-size tables. 1 Introduction Both PBMT models (Koehn et al., 2003; Chiang, 2005) and syntax-based machine translation models (Yamada et al., 2000; Quirk et al., 2005; Galley et al., 2006; Liu et al., 2006; Marcu et al., 2006; and numerous others) are the state-of-theart statistical machine translation (SMT) methods. Over the last several years, an increasing amount of work has been done to combine the advantages of the two approaches. DeNeefe et al. (2007) made a quantitative comparison of the phrase pairs that each model has to work with and found it is useful to improve the phrasal coverage of their string-to-tree model. Liu et al. (2007) proposed forest-to-string rules to capture the non-syntactic phrases in their tree-to-string model. Zhang et al. (2008) proposed a tree sequence based tree-to-tree model which</context>
</contexts>
<marker>Marcu, Wang, Echihabi, Knight, 2006</marker>
<rawString>Daniel Marcu, Wei Wang, Abdessamad Echihabi, and Kevin Knight. 2006. SPMT: Statistical machine translation with syntactified target language phrases. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuval Marton</author>
<author>Philip Resnik</author>
</authors>
<title>Soft syntactic constraints for hierarchical phrased-based transla-</title>
<date>2008</date>
<contexts>
<context position="2272" citStr="Marton and Resnik (2008)" startWordPosition="342" endWordPosition="345"> forest-to-string rules to capture the non-syntactic phrases in their tree-to-string model. Zhang et al. (2008) proposed a tree sequence based tree-to-tree model which can describe non-syntactic phrases with syntactic structure information. The converse of the above methods is to incorporate syntactic information into the PBMT model. Zollmann and Venugopal (2006) started with a complete set of phrases as extracted by traditional PBMT heuristics, and then annotated the target side of each phrasal entry with the label of the constituent node in the target-side parse tree that subsumes the span. Marton and Resnik (2008) and Cherry (2008) imposed syntactic constraints on the PBMT system by making use of prior linguistic knowledge in the form of syntax analysis. In their PBMT decoders, a candidate translation gets an extra credit if it respects the source side syntactic parse tree but may incur a cost if it violates a constituent boundary. Xiong et al. (2009) proposed a syntax-driven bracketing model to predict whether a phrase (a sequence of contiguous words) is bracketable or not using rich syntactic constraints. In this paper, we try to utilize syntactic knowledge to constrain the phrase extraction from wor</context>
</contexts>
<marker>Marton, Resnik, 2008</marker>
<rawString>Yuval Marton and Philip Resnik. 2008. Soft syntactic constraints for hierarchical phrased-based transla-</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>