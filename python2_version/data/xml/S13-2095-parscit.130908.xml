<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.076071">
<title confidence="0.859788">
NILC USP: A Hybrid System for Sentiment Analysis in Twitter Messages
</title>
<author confidence="0.962981">
Pedro P. Balage Filho and Thiago A. S. Pardo
</author>
<affiliation confidence="0.9592885">
Interinstitutional Center for Computational Linguistics (NILC)
Institute of Mathematical and Computer Science, University of S˜ao Paulo
</affiliation>
<address confidence="0.777521">
S˜ao Carlos - SP, Brazil
</address>
<email confidence="0.997297">
{balage, taspardo}@icmc.usp.br
</email>
<sectionHeader confidence="0.995613" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999352454545455">
This paper describes the NILC USP system
that participated in SemEval-2013 Task 2:
Sentiment Analysis in Twitter. Our system
adopts a hybrid classification process that
uses three classification approaches: rule-
based, lexicon-based and machine learning
approaches. We suggest a pipeline architec-
ture that extracts the best characteristics from
each classifier. Our system achieved an F-
score of 56.31% in the Twitter message-level
subtask.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999881815789474">
Twitter and Twitter messages (tweets) are a modern
way to express sentiment and feelings about aspects
of the world. In this scenario, understanding the sen-
timent contained in a message is of vital importance
in order to understand users behavior and for mar-
ket analysis (Java et al., 2007; Kwak et al., 2010).
The research area that deals with the computational
treatment of opinion, sentiment and subjectivity in
texts is called sentiment analysis (Pang et al., 2002).
Sentiment analysis is usually associated with a
text classification task. Sentiment classifiers are
commonly categorized in two basic approaches:
lexicon-based and machine learning (Taboada et al.,
2011). A lexicon-based classifier uses a lexicon to
provide the polarity, or semantic orientation, of each
word or phrase in the text. A machine learning clas-
sifier learns features (usually the vocabulary) from
annotated corpus or labeled examples.
In this paper, we present a hybrid system for senti-
ment classification in Twitter messages. Our system
combines three different approaches: rule-based,
lexicon-based and machine learning. The purpose of
our system is to better understand the use of a hybrid
system in Twitter text and to verify the performance
of this approach in an open evaluation contest.
Our system participated in SemEval-2013 Task
2: Sentiment Analysis in Twitter (Wilson et al.,
2013). The task objective was to determine the sen-
timent contained in Twitter messages. The task in-
cluded two sub-tasks: a expression-level classifi-
cation (Task A) and a message-level classification
(Task B). Our system participated in Task B. In this
task, for a given message, our system should classify
it as positive, negative, or neutral.
Our system was coded using Python and the
CLiPS Pattern library (De Smedt and Daelemans,
2012). This last library provides the part-of-speech
tagger and the SVM algorithm used in this work1.
</bodyText>
<sectionHeader confidence="0.999621" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.987511363636364">
Despite the significant number of works in senti-
ment analysis, few works have approached Twit-
ter messages. Agarwal et al. (2011) explored new
features for sentiment classification of twitter mes-
sages. Davidov et al. (2010) studied the use of
hashtags and emoticons in sentiment classification.
Diakopoulos and Shamma (2010) analyzed the peo-
ple’s sentiment on Twitter for first U.S. presidential
debate in 2008.
The majority of works in sentiment analysis uses
either machine learning techniques or lexicon-based
</bodyText>
<footnote confidence="0.998404">
1Our system code is freely available at
http://github.com/pedrobalage/SemevalTwitterHybridClassifier
</footnote>
<page confidence="0.884838">
568
</page>
<bodyText confidence="0.971808272727273">
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 568–572, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
techniques. However, some few works have pre-
sented hybrid approaches. K¨onig and Brill (2006)
propose a hybrid classifier that utilizes human rea-
soning over automatically discovered text patterns to
complement machine learning. Prabowo and Thel-
wall (2009) evaluates the effectiveness of different
classifiers. This study showed that the use of multi-
ple classifiers in a hybrid manner could improve the
effectiveness of sentiment analysis.
</bodyText>
<sectionHeader confidence="0.93956" genericHeader="method">
3 System architecture
</sectionHeader>
<bodyText confidence="0.9997125">
Our system is organized in four main components:
normalization, rule-based classifier, lexicon-based
classifier and machine learning classifier. These
components are connected in a pipeline architecture
that extracts the best characteristics from each com-
ponent. The Figure 1 shows the system architecture.
</bodyText>
<figureCaption confidence="0.998736">
Figure 1: System architecture
</figureCaption>
<bodyText confidence="0.999994194444444">
In this pipeline architecture, each classifier, in a
sequential order, evaluates the Twitter message. In
each step, the classifier may determine the polarity
class of the message if a certain degree of confidence
is achieved. If the classifier may not achieve this
confidence threshold, the classifier in the next step
is called. The machine learning classifier is the last
step in the process. It is responsible to determine the
polarity if the previous classifiers failed to achieve
the confidence level required to classification. The
normalization component is responsible to correct
and normalize the text before the classifiers use it.
This architecture improves the classification pro-
cess because it takes advantage of the multiple ap-
proaches. For example, the rule-based classifier is
the most reliable classifier. It achieves good results
when the text is matched by a high-confidence rule.
However, due the freedom of language, rules may
not match 100% of the unseen examples, conse-
quently it has a low recall rate.
Lexicon-based classifiers, for example, are very
confident in the process to determine if a text is polar
or neutral. Using sentiment lexicons, we can deter-
mine that sentences containing sentiment words are
polar and sentences that do not contain such words
are neutral. Moreover, the presence of a high num-
ber of positive or negative words in the text may be
a strong indicative of the polarity.
Finally, machine learning is known to be highly
domain adaptive and to be able to find deep corre-
lations (Taboada et al., 2011). This last classifier
might provide the final decision when the previous
methods failed. In the following sub-sections, we
describe in more details the components in which
our system is based on. In the next section, we ex-
plain how the confidence level was determined.
</bodyText>
<subsectionHeader confidence="0.996604">
3.1 Normalization and rule-based classifier
</subsectionHeader>
<bodyText confidence="0.999651333333333">
The normalization module is in charge of correcting
and normalizing the texts. This module performs the
following operations:
</bodyText>
<listItem confidence="0.999524333333333">
• Elements such as hashtags, urls and mentions
are transformed into a consistent set of codes;
• Emoticons are grouped into representative
categories (such as happy, sad, laugh) and con-
verted to particular codes;
• Signals of exaltation (such as repetitive excla-
mation marks) are recognized;
• A simple misspelling correction is performed;
• Part-of-speech tagging is performed.
</listItem>
<bodyText confidence="0.9998686">
The rule-based classifier is very simple. The only
rules applied here are concerned to the emoticons
found in the text. Empirically, we evidenced that
positive emoticons are an important indicative of
positiveness in texts. Likewise, negative emoticons
</bodyText>
<page confidence="0.992569">
569
</page>
<bodyText confidence="0.999276">
indicate negativeness tendency. This module re-
turns the number of positive and negative emoticons
matched in the text.
</bodyText>
<subsectionHeader confidence="0.998306">
3.2 Lexicon-based classifier
</subsectionHeader>
<bodyText confidence="0.999951631578947">
The lexicon-based classifier is based on the idea that
the polarity of a text can be summarized by the sum
of the individual polarity values of each word or
phrase present in the text. In this assumption, a
sentiment lexicon identifies polar words and assigns
polarity values to them (known as semantic orienta-
tions).
In our system, we used the sentiment lexicon pro-
vided by SentiStrength (Thelwall et al., 2010). This
lexicon provides an emotion vocabulary, an emoti-
cons list, a negation list and a booster word list.
In our algorithm, we sum the semantic orienta-
tions of each individual word in the text. If the word
is negated, the polarity is inverted. If the word is in-
tensified (boosted), we increase its polarity by a fac-
tor determined in the sentiment lexicon. A lexicon-
based classifier usually assumes the signal of the fi-
nal score as the sentiment class: positive, negative
or neutral (score zero).
</bodyText>
<subsectionHeader confidence="0.995795">
3.3 Machine learning classifier
</subsectionHeader>
<bodyText confidence="0.999927125">
The machine learning classifier uses labeled exam-
ples to learn how to classify new instances. The
algorithm learns by using features extracted from
these examples. In our classifier, we used the SVM
algorithm provided by CLiPS Pattern. The features
used by the classifier are bag-of-words, the part-of-
speech set, and the existence of negation in the sen-
tence.
</bodyText>
<sectionHeader confidence="0.813815" genericHeader="method">
4 Hybrid approach and tuning
</sectionHeader>
<bodyText confidence="0.999745111111111">
The organization from SemEval-2013 Task 2: Senti-
ment Analysis in Twitter provided three datasets for
the task (Wilson et al., 2013). A training dataset
(TrainSet), with 6,686 messages2, a development
dataset (DevSet), with 1,654 messages, and two test-
ing datasets (TestSets), with 3,813 (Twitter TestSet)
and 2,094 (SMS TestSet) messages each.
As we said in the previous section, our system is
a pipeline of classifiers where each classifier may
</bodyText>
<footnote confidence="0.776078">
2The number of messages may differ from other participants
because the data was collected by crawling
</footnote>
<bodyText confidence="0.998829">
assign a sentiment class if it achieves a particular
confidence threshold. This confidence threshold is a
fixed value we set for each system in order to have
a decision boundary. This decision was made by in-
specting the results table obtained with the develop-
ment set, as shown below.
Table 1 shows how the rule-based classifier per-
formed in the development dataset. The classifier
score consists in the difference between the num-
ber of positive emoticons and the number of nega-
tive emoticons found in the message. For example,
for score of -1 we had 22 negative, 4 neutral and 2
positive messages.
</bodyText>
<tableCaption confidence="0.999719">
Table 1: Correlation between the rule-based classifier
scores and the gold standard classes in the DevSet
</tableCaption>
<table confidence="0.992765">
Rule-based Gold Standard Class
classifier score
Negative Neutral Positive
-1 22 4 2
0 311 708 496
1 7 24 71
2 2 4
3 to 6 1 2
</table>
<bodyText confidence="0.999581541666667">
Inspecting the Table 1 we adjusted the rule-based
classifier boundary to decide when the score is dif-
ferent from zero. For values greater than zero, the
classifier will assign the positive class and, for val-
ues below zero, the classifier will assign the negative
class. For values equal zero, the classifier will call
the lexicon-based classifier.
Table 2 is similar to the Table 1, but it now shows
the scores obtained by the lexicon-based classifier
for the development set. This score is the message
semantic orientation computed by the sum of the se-
mantic orientation for each individual word.
Inspecting Table 2, we adjusted the lexicon-based
classifier to assign the positive class when the total
score is greater than 3 and negative class when the
total score is below -3. Moreover, we evidenced that,
compared to the other classifiers, the lexicon-based
classifier had better performance to determine the
neutral class. Therefore, we adjusted the lexicon-
based classifier to assign the neutral class when the
total score is zero. For any other values, the machine
learning classifier is called.
Finally, Table 3 shows the confusion matrix for
the machine learning classifier in the development
</bodyText>
<page confidence="0.99877">
570
</page>
<tableCaption confidence="0.998981666666667">
Table 2: Correlation between the lexicon-based classifier
score and the gold standard classes in the DevSet
Table 4: Average F-score (positive and negative) obtained
</tableCaption>
<table confidence="0.952885823529412">
by each classifier and the hybrid approach
Lexicon-based Gold Standard Class
classifier scores
Negative Neutral Positive
-11 to -6 26 8 4
-5 15 6 4
-4 31 20 9
-3 32 24 5
-2 57 86 22
-1 25 31 20
0 74 354 115
1 26 70 42
2 28 87 103
3 12 29 81
4 8 9 56
5 2 6 42
6 to 13 4 9 72
</table>
<bodyText confidence="0.998439">
dataset. The machine learning classifier does not
operate with a confidence threshold, so no decisions
were made for this classifier. We see that machine
learning classifier does not have a good accuracy
in general. Our hybrid approach proposed aims to
overcome this problem. Next section shows the re-
sults achieved for the Semeval test dataset.
</bodyText>
<tableCaption confidence="0.9816555">
Table 3: Confusion matrix for the machine learning clas-
sifier in the DevSet
</tableCaption>
<table confidence="0.999055666666667">
Machine learning Gold Standard Class
classifier class
Negative Neutral Positive
negative 35 6 11
neutral 232 595 262
positive 73 138 302
</table>
<sectionHeader confidence="0.999445" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999788714285714">
Table 4 shows the results obtained by each individ-
ual classifier and the hybrid classifier for the test
dataset. In the task, the systems were evaluated with
the average F-Score obtained for positive and nega-
tive classes3. We see that the Hybrid approach could
improve in relation to each classifier score, confirm-
ing our hypothesis.
</bodyText>
<footnote confidence="0.748327666666667">
3Semeval-2013 Task 2: Sentiment Analysis in Twitter com-
pares the systems by the average F-score for positive and nega-
tive classes. For more information see Wilson et al. (2013)
</footnote>
<table confidence="0.9324988">
Classifier Twitter TestSet SMS TestSet
Rule-based 0.1437 0.0665
Lexicon-Based 0.4487 0.4282
Machine Learning 0.4999 0.4029
Hybrid Approach 0.5631 0.5012
</table>
<bodyText confidence="0.99548825">
Table 5 shows the results in terms of precision,
recall and F-score for each class by the hybrid clas-
sifier in the Twitter dataset. Inspecting our algo-
rithm for the Twitter dataset, we had 277 examples
classified by the rule-based classifier, 2,312 by the
lexicon-based classifier and 1,224 the by machine
learning classifier. The results for the SMS dataset
had similar values.
</bodyText>
<tableCaption confidence="0.986423">
Table 5: Results for Twitter TestSet
</tableCaption>
<table confidence="0.96950825">
Class Precision Recall F-Score
positive 0.6935 0.6145 0.6516
negative 0.5614 0.4110 0.4745
neutral 0.6152 0.7427 0.6729
</table>
<sectionHeader confidence="0.998418" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999195857142857">
We described a hybrid classification system used for
Semeval-2013 Task 2: Sentiment Analysis in Twit-
ter. This paper showed how a hybrid classifier might
take advantage of multiple sentiment analysis ap-
proaches and how these approaches perform in a
Twitter dataset.
A future direction of this work would be im-
proving each individual classifier. In our system,
we used simple methods for each employed classi-
fier. Thus, we believe the hybrid classification tech-
nique applied might achieve even better results. This
strengthens our theory that hybrid techniques might
outperform the current state-of-art in sentiment anal-
ysis.
</bodyText>
<sectionHeader confidence="0.998295" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999843">
We would like to thank the organizers for their work
constructing the dataset and overseeing the task. We
also would like to thank FAPESP and CNPq for fi-
nancial support.
</bodyText>
<page confidence="0.996566">
571
</page>
<sectionHeader confidence="0.990131" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999778066666667">
Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Rambow,
and Rebecca Passonneau. 2011. Sentiment analysis
of twitter data. In Proceedings of the Workshop on
Languages in Social Media, LSM ’11, pages 30–38,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Dmitry Davidov, Oren Tsur, and Ari Rappoport. 2010.
Enhanced sentiment learning using twitter hashtags
and smileys. In Proceedings of the 23rd International
Conference on Computational Linguistics: Posters,
COLING ’10, pages 241–249, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Tom De Smedt and Walter Daelemans. 2012. Pattern for
python. The Journal of Machine Learning Research,
13:2063–2067.
Nicholas A. Diakopoulos and David A. Shamma. 2010.
Characterizing debate performance via aggregated
twitter sentiment. In Proceedings of the SIGCHI Con-
ference on Human Factors in Computing Systems, CHI
’10, pages 1195–1198, New York, NY, USA. ACM.
Akshay Java, Xiaodan Song, Tim Finin, and Belle Tseng.
2007. Why we twitter: understanding microblogging
usage and communities. In Proceedings of the 9th We-
bKDD and 1st SNA-KDD 2007 workshop on Web min-
ing and social network analysis, WebKDD/SNA-KDD
’07, pages 56–65, New York, NY, USA. ACM.
Arnd Christian K¨onig and Eric Brill. 2006. Reducing the
human overhead in text categorization. In Proceed-
ings of the 12th ACM SIGKDD international confer-
ence on Knowledge discovery and data mining, KDD
’06, pages 598–603, New York, NY, USA. ACM.
Haewoon Kwak, Changhyun Lee, Hosung Park, and Sue
Moon. 2010. What is twitter, a social network or
a news media? In Proceedings of the 19th inter-
national conference on World wide web, WWW ’10,
pages 591–600, New York, NY, USA. ACM.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up? Sentiment Classification using
Machine Learning Techniques. In Proceedings of the
ACL-02 conference on Empirical methods in natu-
ral language processing - EMNLP ’02, pages 79–86,
Morristown, NJ, USA, July. Association for Computa-
tional Linguistics.
Rudy Prabowo and Mike Thelwall. 2009. Sentiment
analysis: A combined approach. Journal of Informet-
rics, 3(2):143–157.
Maite Taboada, Julian Brooke, Milan Tofiloski, Kimberly
Voll, and Manfred Stede. 2011. Lexicon-Based Meth-
ods for Sentiment Analysis. Computational Linguis-
tics, 37(2):267–307, June.
Mike Thelwall, Kevan Buckley, Georgios Paltoglou,
Di Cai, and Arvid Kappas. 2010. Sentiment in short
strength detection informal text. Journal of the Amer-
ican Society for Information Science and Technology,
61(12):2544–2558, December.
Theresa Wilson, Zornitsa Kozareva, Preslav Nakov, Sara
Rosenthal, Veselin Stoyanov, and Alan Ritter. 2013.
SemEval-2013 task 2: Sentiment analysis in twitter.
In Proceedings of the International Workshop on Se-
mantic Evaluation, SemEval ’13, June.
</reference>
<page confidence="0.997386">
572
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.233963">
<title confidence="0.999488">NILC USP: A Hybrid System for Sentiment Analysis in Twitter Messages</title>
<author confidence="0.998959">Pedro P Balage Filho</author>
<author confidence="0.998959">A S Thiago</author>
<affiliation confidence="0.6841745">Interinstitutional Center for Computational Linguistics of Mathematical and Computer Science, University of</affiliation>
<author confidence="0.61583">Carlos</author>
<abstract confidence="0.99357175">This paper describes the NILC USP system participated in Task 2: Analysis in Our system adopts a hybrid classification process that uses three classification approaches: rulebased, lexicon-based and machine learning approaches. We suggest a pipeline architecture that extracts the best characteristics from each classifier. Our system achieved an Fscore of 56.31% in the Twitter message-level subtask.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Apoorv Agarwal</author>
<author>Boyi Xie</author>
<author>Ilia Vovsha</author>
<author>Owen Rambow</author>
<author>Rebecca Passonneau</author>
</authors>
<title>Sentiment analysis of twitter data.</title>
<date>2011</date>
<booktitle>In Proceedings of the Workshop on Languages in Social Media, LSM ’11,</booktitle>
<pages>30--38</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2818" citStr="Agarwal et al. (2011)" startWordPosition="427" endWordPosition="430">contained in Twitter messages. The task included two sub-tasks: a expression-level classification (Task A) and a message-level classification (Task B). Our system participated in Task B. In this task, for a given message, our system should classify it as positive, negative, or neutral. Our system was coded using Python and the CLiPS Pattern library (De Smedt and Daelemans, 2012). This last library provides the part-of-speech tagger and the SVM algorithm used in this work1. 2 Related work Despite the significant number of works in sentiment analysis, few works have approached Twitter messages. Agarwal et al. (2011) explored new features for sentiment classification of twitter messages. Davidov et al. (2010) studied the use of hashtags and emoticons in sentiment classification. Diakopoulos and Shamma (2010) analyzed the people’s sentiment on Twitter for first U.S. presidential debate in 2008. The majority of works in sentiment analysis uses either machine learning techniques or lexicon-based 1Our system code is freely available at http://github.com/pedrobalage/SemevalTwitterHybridClassifier 568 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop</context>
</contexts>
<marker>Agarwal, Xie, Vovsha, Rambow, Passonneau, 2011</marker>
<rawString>Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Rambow, and Rebecca Passonneau. 2011. Sentiment analysis of twitter data. In Proceedings of the Workshop on Languages in Social Media, LSM ’11, pages 30–38, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Davidov</author>
<author>Oren Tsur</author>
<author>Ari Rappoport</author>
</authors>
<title>Enhanced sentiment learning using twitter hashtags and smileys.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics: Posters, COLING ’10,</booktitle>
<pages>241--249</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2912" citStr="Davidov et al. (2010)" startWordPosition="441" endWordPosition="444">ion (Task A) and a message-level classification (Task B). Our system participated in Task B. In this task, for a given message, our system should classify it as positive, negative, or neutral. Our system was coded using Python and the CLiPS Pattern library (De Smedt and Daelemans, 2012). This last library provides the part-of-speech tagger and the SVM algorithm used in this work1. 2 Related work Despite the significant number of works in sentiment analysis, few works have approached Twitter messages. Agarwal et al. (2011) explored new features for sentiment classification of twitter messages. Davidov et al. (2010) studied the use of hashtags and emoticons in sentiment classification. Diakopoulos and Shamma (2010) analyzed the people’s sentiment on Twitter for first U.S. presidential debate in 2008. The majority of works in sentiment analysis uses either machine learning techniques or lexicon-based 1Our system code is freely available at http://github.com/pedrobalage/SemevalTwitterHybridClassifier 568 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 568–572, Atlanta, Georgia, June 14-15, 2013. c�2</context>
</contexts>
<marker>Davidov, Tsur, Rappoport, 2010</marker>
<rawString>Dmitry Davidov, Oren Tsur, and Ari Rappoport. 2010. Enhanced sentiment learning using twitter hashtags and smileys. In Proceedings of the 23rd International Conference on Computational Linguistics: Posters, COLING ’10, pages 241–249, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom De Smedt</author>
<author>Walter Daelemans</author>
</authors>
<title>Pattern for python.</title>
<date>2012</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>13--2063</pages>
<marker>De Smedt, Daelemans, 2012</marker>
<rawString>Tom De Smedt and Walter Daelemans. 2012. Pattern for python. The Journal of Machine Learning Research, 13:2063–2067.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicholas A Diakopoulos</author>
<author>David A Shamma</author>
</authors>
<title>Characterizing debate performance via aggregated twitter sentiment.</title>
<date>2010</date>
<booktitle>In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI ’10,</booktitle>
<pages>1195--1198</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="3013" citStr="Diakopoulos and Shamma (2010)" startWordPosition="455" endWordPosition="458">In this task, for a given message, our system should classify it as positive, negative, or neutral. Our system was coded using Python and the CLiPS Pattern library (De Smedt and Daelemans, 2012). This last library provides the part-of-speech tagger and the SVM algorithm used in this work1. 2 Related work Despite the significant number of works in sentiment analysis, few works have approached Twitter messages. Agarwal et al. (2011) explored new features for sentiment classification of twitter messages. Davidov et al. (2010) studied the use of hashtags and emoticons in sentiment classification. Diakopoulos and Shamma (2010) analyzed the people’s sentiment on Twitter for first U.S. presidential debate in 2008. The majority of works in sentiment analysis uses either machine learning techniques or lexicon-based 1Our system code is freely available at http://github.com/pedrobalage/SemevalTwitterHybridClassifier 568 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 568–572, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics techniques. However, some few works have presented hybr</context>
</contexts>
<marker>Diakopoulos, Shamma, 2010</marker>
<rawString>Nicholas A. Diakopoulos and David A. Shamma. 2010. Characterizing debate performance via aggregated twitter sentiment. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI ’10, pages 1195–1198, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akshay Java</author>
<author>Xiaodan Song</author>
<author>Tim Finin</author>
<author>Belle Tseng</author>
</authors>
<title>Why we twitter: understanding microblogging usage and communities.</title>
<date>2007</date>
<journal>WebKDD/SNA-KDD</journal>
<booktitle>In Proceedings of the 9th WebKDD and 1st SNA-KDD</booktitle>
<volume>07</volume>
<pages>56--65</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1058" citStr="Java et al., 2007" startWordPosition="154" endWordPosition="157">dopts a hybrid classification process that uses three classification approaches: rulebased, lexicon-based and machine learning approaches. We suggest a pipeline architecture that extracts the best characteristics from each classifier. Our system achieved an Fscore of 56.31% in the Twitter message-level subtask. 1 Introduction Twitter and Twitter messages (tweets) are a modern way to express sentiment and feelings about aspects of the world. In this scenario, understanding the sentiment contained in a message is of vital importance in order to understand users behavior and for market analysis (Java et al., 2007; Kwak et al., 2010). The research area that deals with the computational treatment of opinion, sentiment and subjectivity in texts is called sentiment analysis (Pang et al., 2002). Sentiment analysis is usually associated with a text classification task. Sentiment classifiers are commonly categorized in two basic approaches: lexicon-based and machine learning (Taboada et al., 2011). A lexicon-based classifier uses a lexicon to provide the polarity, or semantic orientation, of each word or phrase in the text. A machine learning classifier learns features (usually the vocabulary) from annotated</context>
</contexts>
<marker>Java, Song, Finin, Tseng, 2007</marker>
<rawString>Akshay Java, Xiaodan Song, Tim Finin, and Belle Tseng. 2007. Why we twitter: understanding microblogging usage and communities. In Proceedings of the 9th WebKDD and 1st SNA-KDD 2007 workshop on Web mining and social network analysis, WebKDD/SNA-KDD ’07, pages 56–65, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arnd Christian K¨onig</author>
<author>Eric Brill</author>
</authors>
<title>Reducing the human overhead in text categorization.</title>
<date>2006</date>
<booktitle>In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’06,</booktitle>
<pages>598--603</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>K¨onig, Brill, 2006</marker>
<rawString>Arnd Christian K¨onig and Eric Brill. 2006. Reducing the human overhead in text categorization. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’06, pages 598–603, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haewoon Kwak</author>
<author>Changhyun Lee</author>
<author>Hosung Park</author>
<author>Sue Moon</author>
</authors>
<title>What is twitter, a social network or a news media?</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th international conference on World wide web, WWW ’10,</booktitle>
<pages>591--600</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1078" citStr="Kwak et al., 2010" startWordPosition="158" endWordPosition="161">sification process that uses three classification approaches: rulebased, lexicon-based and machine learning approaches. We suggest a pipeline architecture that extracts the best characteristics from each classifier. Our system achieved an Fscore of 56.31% in the Twitter message-level subtask. 1 Introduction Twitter and Twitter messages (tweets) are a modern way to express sentiment and feelings about aspects of the world. In this scenario, understanding the sentiment contained in a message is of vital importance in order to understand users behavior and for market analysis (Java et al., 2007; Kwak et al., 2010). The research area that deals with the computational treatment of opinion, sentiment and subjectivity in texts is called sentiment analysis (Pang et al., 2002). Sentiment analysis is usually associated with a text classification task. Sentiment classifiers are commonly categorized in two basic approaches: lexicon-based and machine learning (Taboada et al., 2011). A lexicon-based classifier uses a lexicon to provide the polarity, or semantic orientation, of each word or phrase in the text. A machine learning classifier learns features (usually the vocabulary) from annotated corpus or labeled e</context>
</contexts>
<marker>Kwak, Lee, Park, Moon, 2010</marker>
<rawString>Haewoon Kwak, Changhyun Lee, Hosung Park, and Sue Moon. 2010. What is twitter, a social network or a news media? In Proceedings of the 19th international conference on World wide web, WWW ’10, pages 591–600, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment Classification using Machine Learning Techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 conference on Empirical methods in natural language processing - EMNLP ’02,</booktitle>
<pages>79--86</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA,</location>
<contexts>
<context position="1238" citStr="Pang et al., 2002" startWordPosition="182" endWordPosition="185">extracts the best characteristics from each classifier. Our system achieved an Fscore of 56.31% in the Twitter message-level subtask. 1 Introduction Twitter and Twitter messages (tweets) are a modern way to express sentiment and feelings about aspects of the world. In this scenario, understanding the sentiment contained in a message is of vital importance in order to understand users behavior and for market analysis (Java et al., 2007; Kwak et al., 2010). The research area that deals with the computational treatment of opinion, sentiment and subjectivity in texts is called sentiment analysis (Pang et al., 2002). Sentiment analysis is usually associated with a text classification task. Sentiment classifiers are commonly categorized in two basic approaches: lexicon-based and machine learning (Taboada et al., 2011). A lexicon-based classifier uses a lexicon to provide the polarity, or semantic orientation, of each word or phrase in the text. A machine learning classifier learns features (usually the vocabulary) from annotated corpus or labeled examples. In this paper, we present a hybrid system for sentiment classification in Twitter messages. Our system combines three different approaches: rule-based,</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment Classification using Machine Learning Techniques. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing - EMNLP ’02, pages 79–86, Morristown, NJ, USA, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rudy Prabowo</author>
<author>Mike Thelwall</author>
</authors>
<title>Sentiment analysis: A combined approach.</title>
<date>2009</date>
<journal>Journal of Informetrics,</journal>
<volume>3</volume>
<issue>2</issue>
<contexts>
<context position="3813" citStr="Prabowo and Thelwall (2009)" startWordPosition="559" endWordPosition="563">r lexicon-based 1Our system code is freely available at http://github.com/pedrobalage/SemevalTwitterHybridClassifier 568 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 568–572, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics techniques. However, some few works have presented hybrid approaches. K¨onig and Brill (2006) propose a hybrid classifier that utilizes human reasoning over automatically discovered text patterns to complement machine learning. Prabowo and Thelwall (2009) evaluates the effectiveness of different classifiers. This study showed that the use of multiple classifiers in a hybrid manner could improve the effectiveness of sentiment analysis. 3 System architecture Our system is organized in four main components: normalization, rule-based classifier, lexicon-based classifier and machine learning classifier. These components are connected in a pipeline architecture that extracts the best characteristics from each component. The Figure 1 shows the system architecture. Figure 1: System architecture In this pipeline architecture, each classifier, in a sequ</context>
</contexts>
<marker>Prabowo, Thelwall, 2009</marker>
<rawString>Rudy Prabowo and Mike Thelwall. 2009. Sentiment analysis: A combined approach. Journal of Informetrics, 3(2):143–157.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maite Taboada</author>
<author>Julian Brooke</author>
<author>Milan Tofiloski</author>
<author>Kimberly Voll</author>
<author>Manfred Stede</author>
</authors>
<title>Lexicon-Based Methods for Sentiment Analysis.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<volume>37</volume>
<issue>2</issue>
<contexts>
<context position="1443" citStr="Taboada et al., 2011" startWordPosition="209" endWordPosition="212">y to express sentiment and feelings about aspects of the world. In this scenario, understanding the sentiment contained in a message is of vital importance in order to understand users behavior and for market analysis (Java et al., 2007; Kwak et al., 2010). The research area that deals with the computational treatment of opinion, sentiment and subjectivity in texts is called sentiment analysis (Pang et al., 2002). Sentiment analysis is usually associated with a text classification task. Sentiment classifiers are commonly categorized in two basic approaches: lexicon-based and machine learning (Taboada et al., 2011). A lexicon-based classifier uses a lexicon to provide the polarity, or semantic orientation, of each word or phrase in the text. A machine learning classifier learns features (usually the vocabulary) from annotated corpus or labeled examples. In this paper, we present a hybrid system for sentiment classification in Twitter messages. Our system combines three different approaches: rule-based, lexicon-based and machine learning. The purpose of our system is to better understand the use of a hybrid system in Twitter text and to verify the performance of this approach in an open evaluation contes</context>
<context position="5906" citStr="Taboada et al., 2011" startWordPosition="886" endWordPosition="889">anguage, rules may not match 100% of the unseen examples, consequently it has a low recall rate. Lexicon-based classifiers, for example, are very confident in the process to determine if a text is polar or neutral. Using sentiment lexicons, we can determine that sentences containing sentiment words are polar and sentences that do not contain such words are neutral. Moreover, the presence of a high number of positive or negative words in the text may be a strong indicative of the polarity. Finally, machine learning is known to be highly domain adaptive and to be able to find deep correlations (Taboada et al., 2011). This last classifier might provide the final decision when the previous methods failed. In the following sub-sections, we describe in more details the components in which our system is based on. In the next section, we explain how the confidence level was determined. 3.1 Normalization and rule-based classifier The normalization module is in charge of correcting and normalizing the texts. This module performs the following operations: • Elements such as hashtags, urls and mentions are transformed into a consistent set of codes; • Emoticons are grouped into representative categories (such as h</context>
</contexts>
<marker>Taboada, Brooke, Tofiloski, Voll, Stede, 2011</marker>
<rawString>Maite Taboada, Julian Brooke, Milan Tofiloski, Kimberly Voll, and Manfred Stede. 2011. Lexicon-Based Methods for Sentiment Analysis. Computational Linguistics, 37(2):267–307, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Thelwall</author>
<author>Kevan Buckley</author>
<author>Georgios Paltoglou</author>
<author>Di Cai</author>
<author>Arvid Kappas</author>
</authors>
<title>Sentiment in short strength detection informal text.</title>
<date>2010</date>
<journal>Journal of the American Society for Information Science and Technology,</journal>
<volume>61</volume>
<issue>12</issue>
<marker>Thelwall, Buckley, Paltoglou, Di Cai, Kappas, 2010</marker>
<rawString>Mike Thelwall, Kevan Buckley, Georgios Paltoglou, Di Cai, and Arvid Kappas. 2010. Sentiment in short strength detection informal text. Journal of the American Society for Information Science and Technology, 61(12):2544–2558, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Zornitsa Kozareva</author>
<author>Preslav Nakov</author>
<author>Sara Rosenthal</author>
<author>Veselin Stoyanov</author>
<author>Alan Ritter</author>
</authors>
<title>SemEval-2013 task 2: Sentiment analysis in twitter.</title>
<date>2013</date>
<booktitle>In Proceedings of the International Workshop on Semantic Evaluation, SemEval ’13,</booktitle>
<contexts>
<context position="2145" citStr="Wilson et al., 2013" startWordPosition="318" endWordPosition="321">rientation, of each word or phrase in the text. A machine learning classifier learns features (usually the vocabulary) from annotated corpus or labeled examples. In this paper, we present a hybrid system for sentiment classification in Twitter messages. Our system combines three different approaches: rule-based, lexicon-based and machine learning. The purpose of our system is to better understand the use of a hybrid system in Twitter text and to verify the performance of this approach in an open evaluation contest. Our system participated in SemEval-2013 Task 2: Sentiment Analysis in Twitter (Wilson et al., 2013). The task objective was to determine the sentiment contained in Twitter messages. The task included two sub-tasks: a expression-level classification (Task A) and a message-level classification (Task B). Our system participated in Task B. In this task, for a given message, our system should classify it as positive, negative, or neutral. Our system was coded using Python and the CLiPS Pattern library (De Smedt and Daelemans, 2012). This last library provides the part-of-speech tagger and the SVM algorithm used in this work1. 2 Related work Despite the significant number of works in sentiment an</context>
<context position="8591" citStr="Wilson et al., 2013" startWordPosition="1314" endWordPosition="1317">as the sentiment class: positive, negative or neutral (score zero). 3.3 Machine learning classifier The machine learning classifier uses labeled examples to learn how to classify new instances. The algorithm learns by using features extracted from these examples. In our classifier, we used the SVM algorithm provided by CLiPS Pattern. The features used by the classifier are bag-of-words, the part-ofspeech set, and the existence of negation in the sentence. 4 Hybrid approach and tuning The organization from SemEval-2013 Task 2: Sentiment Analysis in Twitter provided three datasets for the task (Wilson et al., 2013). A training dataset (TrainSet), with 6,686 messages2, a development dataset (DevSet), with 1,654 messages, and two testing datasets (TestSets), with 3,813 (Twitter TestSet) and 2,094 (SMS TestSet) messages each. As we said in the previous section, our system is a pipeline of classifiers where each classifier may 2The number of messages may differ from other participants because the data was collected by crawling assign a sentiment class if it achieves a particular confidence threshold. This confidence threshold is a fixed value we set for each system in order to have a decision boundary. This</context>
<context position="12562" citStr="Wilson et al. (2013)" startWordPosition="1992" endWordPosition="1995">classifier class Negative Neutral Positive negative 35 6 11 neutral 232 595 262 positive 73 138 302 5 Results Table 4 shows the results obtained by each individual classifier and the hybrid classifier for the test dataset. In the task, the systems were evaluated with the average F-Score obtained for positive and negative classes3. We see that the Hybrid approach could improve in relation to each classifier score, confirming our hypothesis. 3Semeval-2013 Task 2: Sentiment Analysis in Twitter compares the systems by the average F-score for positive and negative classes. For more information see Wilson et al. (2013) Classifier Twitter TestSet SMS TestSet Rule-based 0.1437 0.0665 Lexicon-Based 0.4487 0.4282 Machine Learning 0.4999 0.4029 Hybrid Approach 0.5631 0.5012 Table 5 shows the results in terms of precision, recall and F-score for each class by the hybrid classifier in the Twitter dataset. Inspecting our algorithm for the Twitter dataset, we had 277 examples classified by the rule-based classifier, 2,312 by the lexicon-based classifier and 1,224 the by machine learning classifier. The results for the SMS dataset had similar values. Table 5: Results for Twitter TestSet Class Precision Recall F-Score</context>
</contexts>
<marker>Wilson, Kozareva, Nakov, Rosenthal, Stoyanov, Ritter, 2013</marker>
<rawString>Theresa Wilson, Zornitsa Kozareva, Preslav Nakov, Sara Rosenthal, Veselin Stoyanov, and Alan Ritter. 2013. SemEval-2013 task 2: Sentiment analysis in twitter. In Proceedings of the International Workshop on Semantic Evaluation, SemEval ’13, June.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>