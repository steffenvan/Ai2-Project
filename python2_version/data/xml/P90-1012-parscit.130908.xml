<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.702153">
NORMAL STATE IMPLICATURE
</title>
<author confidence="0.7795">
Nancy L. Green
</author>
<affiliation confidence="0.928599666666667">
Department of Computer and Information Sciences
University of Delaware
Newark, Delaware 19716, USA
</affiliation>
<sectionHeader confidence="0.972931" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999604">
In the right situation, a speaker can use an unqual-
ified indefinite description without being misun-
derstood. This use of language, normal sae
plicalure, is a kind of conversational irnplicature,
i.e. a non-truth-functional context-dependent in-
ference based upon language users&apos; awareness of
principles of cooperative conversation. I present
a convention for identifying normal state implica-
tures which is based upon mutual beliefs of the
speaker and hearer about certain properties of the
speaker&apos;s plan. A key property is the precondition
that an entity playing a role in the plan must be
in a normal state with respect to the plan.
</bodyText>
<sectionHeader confidence="0.99909" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.944450772727273">
In the right situation, a speaker can use
an unqualified indefinite description without being
misunderstood. For example, a typical customer
in a typical pet shop who said (la) in response to
the clerk&apos;s question in (1) would expect to be un-
derstood as meaning (lb). The goal of this paper
is to formally describe such uses of language. 1
&apos;A similar use of language is noted in [Mc087]. Mc-
Carthy (pp. 29-30) discusses the problem of bridging the
gap between a &amp;quot;rather direct [translation] into first order
logic&apos; of a statement of the Missionaries and Cannibals pus-
zle, and a representation suitable for devising a solution to
the puzzle. For example, if the puzzle statement mentions
that &amp;quot;a rowboat that seats two is available&amp;quot; and doesn&apos;t say
that anything is wrong with the boat, the problem-solver
may assume that the boat doesn&apos;t leak, has oars, etc. Mc-
Carthy proposes a general-purpose method for formalizing
common sense reasoning, &amp;quot;circumscription&amp;quot;, to solve the
problem.
Also, a similar use of language is described in [Gr175] (p.
51): &amp;quot;A is standing by an obviously immobilized car and is
approached by B; the following exchange takes place:
</bodyText>
<page confidence="0.55442">
A: I am out of petrol.
B: There is a garage round the comer.
</page>
<bodyText confidence="0.7374265">
[B] implicates that the garage is, or at least may be
open, [has petrol to sell], etc.&amp;quot; That this use of language
</bodyText>
<figure confidence="0.960751">
1. (Clerk A:) May I help you?
a. (Customer B:) I&apos;d like to see a parrot.
b. I [the speaker] would like to see a live parrot.
c. 9 p:PARROT R.EQUEST(B,A,SIIOGV(A,B,p))
d. 3 qqA p:PARROT LIVE(p)] REQUEST(B,A,
SIIOW(A,B,q)
</figure>
<bodyText confidence="0.982680666666667">
One problem is that (la) (i.e. its putative
representation in (1c)) does not entail (lb) (i.e. its
putative representation in (1d)). 2
Another problem
is the context-dependence, both spatio-temporal
and linguistic, of the relationship of (lb) to (la).
In a different spatio-temporal context, such as in
a china shop, a speaker might use (la) to convey
(2) rather than (lb).
</bodyText>
<sectionHeader confidence="0.690612" genericHeader="introduction">
2. I [the speaker] would like to see a porcelain
</sectionHeader>
<bodyText confidence="0.984135192307692">
parrot.
In a different linguistic context, such as if the cus-
tomer had said (3a) following (la), she would not
involves the use of language I have illustrated in (1) can
be seen by considering a situation identical to the above
except that the dialogue consists of just A&apos;s saying &amp;quot;I need
a garage.&amp;quot; In other words, Grice&apos;s example is of a situation
where B has anticipated a request from A which is the same
kind of request as (la).
2The customer&apos;s use of (la) is an indirect speech act,
namely, a request to be shown a parrot; other possible re-
alizations of this request include &amp;quot;Show me a parrot&amp;quot; and
&amp;quot;Can you show me a parrot?&amp;quot;. (The derivation of represen-
tations of indirect speech acts has been treated elsewhere
[PASO] and is not a concern of this paper.) (lc) is intended
to represent that request by means of a first order language
extended with higher-order operators such as REQUEST.
Also, indefinite descriptions are represented as in 1Web83].
The status of the existence of the parrot in the real world
or discourse context (and the related question as to the
proper scope of the existential quantifier), is not relevant
to the concerns of this paper. My point is that the usual
treatments employing a one-to-one translation from surface
structure to logical form without consideration of other in-
formation will not be able to explain the relationship of
(lb) to (la).
</bodyText>
<page confidence="0.996448">
59
</page>
<listItem confidence="0.561163">
normally expect the clerk to think she had meant
(lb). A related question is why it would be ap-
propriate (non-redundant) for the customer to say
(3b) following (la) if the customer believed that
the clerk might mistakenly believe that the cus-
tomer wanted to see a dead parrot.
3.a. a dead one
b. ... a live one
</listItem>
<bodyText confidence="0.999805263157895">
A third problem is that in order to derive
(lb) from (la) it is necessary to consider the beliefs
of speaker (5) and hearer (II): e.g. S&apos;s and H&apos;s
beliefs about why each said what they did, and
about the appropriate state of the parrot.
Grice IGri75) described conversational im-
plicature, a kind of non-truth-functional context-
dependent inference based upon a speaker&apos;s and
hearer&apos;s awareness of principles of cooperative con-
versation. In this paper, I claim that a speaker&apos;s
use of (la) may conversationally implicate (lb).
In order to formally describe this kind of conver-
sational implicature, which I have termed &apos;nor-
mal state implicature&apos;, I adopt the methodology
used by Hirschberg [Ilir851 for the identification of
another kind of conversational implicature, scalar
implicature.
In section 2, I present a brief description
of scalar implicatures and Hirschberg&apos;s methodol-
ogy for identifying them. In section 3, I present
a convention for identifying normal state implicar
tures. Informally speaking, the convention is that
if speaker S makes a request that hearer H per-
form an action A on an entity E, and if S and H
mutually believe that S has a plan whose success
depends on the E being in a certain state N (which
is the normal state for an E with respect to that
plan) and that S&apos;s request is a step of that plan,
then S is implicating a request for S to do A on an
E in state N.
In section 4, I clarify the notion of nor-
mal state with respect to a plan by distinguish-
ing it from the notions of stereotype and plan-
independent normal state. Next, in section 5, I
show how states can be represented in the lexicon,
In section 6, I compare scalar and normal state im-
plicature; in section 7, survey related work; and,
in section 8, present my conclusions.
</bodyText>
<sectionHeader confidence="0.963011" genericHeader="method">
2 Scalar Implicature
</sectionHeader>
<bodyText confidence="0.9990935">
Hirschberg proposes the following set of six
necessary and sufficient conditions for identifying
conversational implicatures (p. 38).3 A speaker
S conversationally implicates Q to a hearer H by
saying U (where U is a realization of a proposition
P) in a context C iff:
</bodyText>
<listItem confidence="0.996780615384615">
1. S intends to convey Q to H via U; and
2. S believes that S and H mutually believe that
S is being cooperative; and
3. S and H mutually believe that S&apos;s saying U in
C, given S&apos;s cooperativity, licenses Q; and
4. Q is cancelable; i.e., it is possible to deny Q
without denying P; and
5. @ is nondetachable; i.e., the choice of a real-
ization U of P does not affect S&apos;s implicating
Q (except in certain situations where Q is li-
censed via Grice&apos;s Maxim of Manner); and
6. Q is reinforceable; i.e., it is possible to affirm
Q without seeming redundant.
</listItem>
<bodyText confidence="0.9974466875">
Instead of using these conditions to identify
particular scalar implicatures, Hirschberg argues
that it is sufficient to provide a means of iden-
tifying instances of a class of conversational im-
plicature, such as scalar implicatures. Then, she
provides a convention for identifying instances of
scalar imp] icat u re .
Informally speaking, scalar implicature is
based on the convention that (pp. 1 - 2)&amp;quot;cooper-
ative speakers will say as much as they truthfully
can that is relevant to a conversational exchange&amp;quot;;
and distinguished from other conversational impli-
catures by &amp;quot;being dependent upon the identifica-
tion of some salient relation that orders a concept
referred to in an utterance with other concepts&amp;quot;;
e.g. by saying (4a), B has scalar implicated (4b).4
</bodyText>
<listItem confidence="0.945501666666667">
( 4) A: How was the party last night?
a. B: Some people left early.
b. Not all people left early.
</listItem>
<bodyText confidence="0.9587288125">
The convention for identifying scalar impli-
cature proposed by Hirschberg is of the form: if
314er conditions are a revision of Grice&apos;s. Also, I have
changed the names of her variables to be consistent with
usage in the rest of my paper.
90 4(4) is example (1) in Fir85].
there exists a partial order 0 such that S and H
mutually believe that 0 is salient in context C,
and utterance U realizes the proposition that S af-
firms/denies/is ignorant of some value in 0, then
by saying U to H in C, S licenses the scalar irn-
plicature that S has a particular belief regarding
some other value of 0.
In the next section, I will ap-
ply Hirschberg&apos;s methodology to the problem of
identifying normal state implicatures.
</bodyText>
<sectionHeader confidence="0.990708" genericHeader="method">
3 Normal State Implicature
</sectionHeader>
<bodyText confidence="0.982021605263158">
In this section, I will argue that (lb) is a
conversational implicature and propose a conven-
tion for identifying instances of that class of impli-
cature, which I will call &apos;normal state implicature&apos;.
First, I claim that a speaker S conversa-
tionally implicates (lb) to a hearer H by saying
(la) in the context described above; i.e. that (lb)
is a conversational implicature according to the
six conditions described in section 2. Condition 1
is met since S intends to cause H to believe (lb)
by saying (la); condition 2 since S believes that
it is a mutual belief of S and H that S is being
cooperative; condition 3 will be satisfied by pro-
viding a convention for normal state implicature
below. The previous discussion about (3a) and
(3b) provides evidence for cancelability (condition
4) and reinforceability (condition 6), respectively;
and, (lb) is nondetachable (condition 5) since al-
ternate ways of saying (la), in the same context,
would convey (lb).
Next, in order &apos;to motivate the general
convention ((fi) below) for identifying normal
state implicatures, I&apos;ll present the instance of
the convention that accounts for the implicature
in (I). Let S, H, U, and C be constants de-
noting speaker, hearer, utterance, and context,
respectively. Let bo, and g be first or-
der variables over parrots (PARROT), live par-
rots (the lambda expression), and plans (PLAN),
respectively.&apos; HAS-PLAN(Agent,Plan,Entity) is
5 The model of plans used he:re is that of STRIPS IFN711
with minor extensions. A plan includes preconditions
which must hold in order for the plan to succeed, and a
sequence of actions to be carried out to achieve some goal.
One extension to this model is to add a list of entities play-
ing a role in the plan either as instruments (e.g. a boat
which is to be used to cross a river) or as the goal itself
(e.g. a parrot to be acquired for a pet). The second exten-
</bodyText>
<construct confidence="0.804206315789474">
true if Agent has a plan in which Entity
plays a role; PRECOND(Plan,Proposition) is
true if Plan has Proposition as a precondition;
STEP(Plan,Action) is true if Action is a step
of Plan. Also, BMB(A,B,Proposition) is true
if A believes that A and B mutually believe
that Proposition; REALIZE(Utterance, Propo-
sition) is true if Utterance expresses Proposi-
tion; REQUEST(S,H,Action) is true if S re-
quests H to perform Action; and SAY(S,I1,U,C)
is true if S says U to H in C.&apos; SHOW(A,B,C) is
true if A shows C to B. IN-STATE(Entity,State)
is true if Entity is in the given State; and
NORMAL-STATE(State,Plan,Entity) is true if
State is the normal state of Entity with re-
spect to Plan.7 Finally, NORMAL-STATE-
IMP(Speaker,Hearer,Utterance,Proposition,Context)
is true if by use of Utterance in Context, Speaker
conveys Proposition to Hearer.
</construct>
<bodyText confidence="0.9038655">
Now, to paraphrase (5) below, if S and H
mutually believe that S has a plan in which a par-
rot plays a role and that a precondition of S&apos;s plan
is that the parrot should be alive, which is its nor-
mal state with respect to the plan, and that S&apos;s
saying U is a step of that plan; and, if U is a re-
quest to be shown a parrot, then S normal state
implicates a request to be shown a live parrot.
</bodyText>
<construct confidence="0.816707625">
5. Vbo:PARROT
: [Ab2: PARROT LIVE(b2)1
Vg:PLAN
BMB(S, H, HAS-PLAN(S, g, 50) A
PRECOND(g, IN-STATE(bo, LIVE)) A
NORMAL-STATE(LIVE, g, bo) A
STEP(g, SAY(S, H, U, C))) A
REALIZE(U, REQUEST(S, H, SHOW(H, S, be)))
</construct>
<bodyText confidence="0.8949048">
NORMAL-STATE-IMP(S, II, U, REQUEST(S, H,
SHOW(H, 5, bi)),C)
It is possible to generalize (5) as follows.
Let K, N, and A be higher order variables over
classifications (CLASSIF), states (STATE), and
actions that may be performed as a step in a plan
sion, suggested in Kar88), is to distinguish preconditions
which can be achieved as subgoals from those which are
unreasonable for the agent to try to bring about (&amp;quot;applica.
bility conditions&amp;quot;). In (5) and (6), preconditions are meant
in the sense of applicability conditions.
6BMR, REALIZE, REQUEST, and SAY are from
[Hir8.5].
71 will discuss what is meant by state and normal state
in section 4.
</bodyText>
<page confidence="0.519076">
9 J.
</page>
<table confidence="0.490467461538461">
(ACT), respectively. Then, (6) is the general con-
vention for identifying normal state implicature.
6. V K:CLASSIF V N:STATE V A:ACT
Ybo:K
: [Ab2:K N(b2)]
V g:PLAN
BMB(S, H, IAS-PLAN(S, g, bo) A
PRECOND(g, IN-STATE(bo, N)) A
NORMAL-STATE(N, g, bo) A
STEP(g, SAY(S, II, U, C))) A
REALIZE(U, REQUEST(S, H, A(b0))) &lt;=&gt;
NORMAL-STATE-IMP(S, H, U,
REQUEST(S, H, A(bi)),C)
</table>
<bodyText confidence="0.99804625">
Unfortunately, if (6) is to be of maximum
use, there are two problems to be solved. First,
there is the problem of representing alt precon-
ditions of a plan,&apos; and, second, is the problem of
plan inference, i.e., how does H come to know what
S&apos;s plan is (including the problem of recognizing
that the saying of U is a step in S&apos;s plan)?9 Both
problems are outside the scope of this paper.
</bodyText>
<sectionHeader confidence="0.972001" genericHeader="method">
4 States and Normal States
</sectionHeader>
<bodyText confidence="0.926388537037037">
First, what I mean by a side of an entity
E is, adopted from (La,n87], a history of related
events involving E. In Lansky&apos;s ontology, events
may be causally or temporally related. Tem-
poral precedence is transitive. Causality is not
transitive and does not necessitate occurrence but
does imply temporal precedence. A strong pre-
requisite constraint (--P) can be defined such that
&amp;quot;each event of type E2 can be caused by ex-
actly one event of type _El, and each event of
type E, can cause at most one event of type Ea&amp;quot;
([Lan87],p.142).
Many classifications expressed as nouns de-
note a class of entity whose state varies over the
period of existence during which it is aptly char-
acterized by the classification. For example, Fig-
ure 1 and Figure 2 depict causal event chains&apos; of
parrots and vases, respectively.
(Nodes represent events and directed arcs
represent causality.) The state of being dead or
see [McC871.
see IC ar88].
10I don&apos;t mean &apos;causal chain&apos; in the sense that philoso-
phers have recently used it jSch77], nor in the sense of
ISA 77), nor do I mean &apos;chain&apos; in the mathematical sense
of a total order.
broken can be defined in terms of the occurrence
of an event type of dying or breaking, respectively.
Live is the state of an entity who has been born
but has not yet died; ready-to-use is the state of
an artifact between its creation or repair and its
destruction.&amp;quot; Note that, paradoxically, language
users would agree that a dead parrot or a vase with
a crack in it is stilt aptly characterized as a parrot
Or vase, respectively.12
Next, what I mean by a normal state of E
is a state that E is expected to be in. For example,
in the absence of information to the contrary, live
or ready-to-use is expected by language users to
be a state of parrots or vases, respectively. Note,
however, that NORMAL-STATE in (6) represents
a normal state of an entity with respect to some
plan. That is, I am not claiming that, in the ab-
sence of information about S&apos;s plan, S&apos;s use of (la)
conversationally implicates (lb).
The reason for stipulating that NORMAL-
STATE be relative to S&apos;s plan is that use of (la) in
the context of a different plan could change what
S and H consider to be normal. For example, in a
taxidermist&apos;s plan, dead could be the normal state
of a parrot. Also, consider &apos;coffee&apos;: a speaker&apos;s use
of (7) in the context of a coffee farm could be used
to request coffee beans; in a grocery store, ajar of
instant; and in a restaurant, a hot beverage.
</bodyText>
<listItem confidence="0.822452">
7. I&apos;d like some coffee.
</listItem>
<bodyText confidence="0.998901733333333">
Note that more than one precondition of
S&apos;s plan may be relevant to interpreting S&apos;s use of
an expression. For example, a typical restaurant
customer uttering (7) expects to be understood as
not only requesting coffee in its hot-beverage state,
but also in its safe-to-drink state. Also, more than
one of S&apos;s plans may be relevant. Returning to the
pet shop example, suppose that S and H mutually
believe that S has plans to acquire a parrot as a pet
and also to study its vocalizations; then it would
be inappropriate for H to show S a parrot that H
believed to be incapable of making vocalizations.
Normal states differ from stereotypes. A
stereotype is a generalization about prototypes of
a category,13 e.g. (S).&apos;a
</bodyText>
<footnote confidence="0.966597">
11 Examples of how state predicates can be defined in
Lansky&apos;s formal language will be given later.
12The cracked vase example is from [fler87].
13 The prototype-stereotype distinction is described
in[II1I83].
14 Note that stereotypes may be relative to a state of the
</footnote>
<page confidence="0.993621">
92
</page>
<bodyText confidence="0.955534826086957">
8. Unripe bananas are green.
Qualifying an expression in a way which
contradicts a stereotype may have a different ef-
fect on H than doing so in a way which specifies a
non-normal state. For instance, if S says (9) after
saying (la) in the above pet shop scenario, H may
doubt S&apos;s sincerity or S&apos;s knowledge about parrots;
while S&apos;s use of (3a) after saying (1a) may cause
II to have doubts about S&apos;s sincerity or H&apos;s knowl-
edge of S&apos;s plan, but not S&apos;s knowledge about par-
rots.
9. a 100 pound one
Another difference between stereotypes and
normal states is that stereotypes are not affected
by S&apos;s and H&apos;s mutual beliefs about S&apos;s plan,
whereas I have just demonstrated that what is
considered normal may change in the context of
S&apos;s plan. Finally, another reason for making the
distinction is that I am not claiming that, in the
above pet shop scenario, S&apos;s use of (la) licenses
(10); i.e., S does not intend to convey (10.&apos;5
10. 1 [the speaker] would like to see a large,
green, talking bird.
</bodyText>
<sectionHeader confidence="0.978584" genericHeader="method">
5 The Role of Events in cer-
tain Lexical Representa-
tions
</sectionHeader>
<bodyText confidence="0.984366425">
Now I will show how the notion of state
presented in the previous section can be repre-
sented in the lexicon via state predicates based
on causal event chains. The purpose of this is to
clarify what counts as a state and hence, what is
prototype; e.g. contrast (8) with &amp;quot;Ripe bananas are yel-
low&amp;quot;. A statement of a stereotype in which the state of the
prototypes is unspecified may describe prototypes in the
plan-independent normal state for the category; e.g. con-
sider &amp;quot;Bananas are yellow&amp;quot;. Also, note that stereotypical
properties may be used to convey the state; e.g. consider
&amp;quot;I want a green banana&amp;quot; used to convey &amp;quot;I want an unripe
banana&amp;quot;.
15I recognize that it is possible for a speaker to exploit
mutual beliefs about stereotypes or plan-independent nor-
mal states to convey conversational implicatures. E.g., con-
sider the conversation: A says, &amp;quot;Is your neighbor rich?&amp;quot; B
replies, &amp;quot;He&apos;s a doctor.&amp;quot; However, this kind of implicature
does not occur under the same conditions as those given
for normal state implicature, and is outside of the scope of
this paper,
to be identified by the convention for normal state
implicature. This way of representing states has
benefits in other areas. First, entailment relation-
ships between states of an entity are thereby rep-
resented. Second, certain scalar implicatures may
be based on the event ordering of a causal event
chain.
For example, Figure 3 contains pictorial
and formal representations of a causal event chain
for the ripening of fruit. Definitions of states are
given as state predicates; e.g. the expression &apos;un-
ripe&apos; is used to denote a state such that no event
of ripening (R) has occurred (yet). Note that, as
(11) shows, &apos;ripe&apos; may be used to scalar implicate
but not to entail &apos;not overripe&apos;; the event order-
ing of the causal event chain serves as the salient
order for the scalar implicature. The expected en-
tailments follow from the constraints represented
in Figure 3.
</bodyText>
<listItem confidence="0.801423">
11.a. It&apos;s ripe. In fact, it&apos;s just right for eating.
b. It&apos;s ripe. In fact, it&apos;s overripe/too ripe.
</listItem>
<subsectionHeader confidence="0.696453">
6 Comparison of Scalar and
Normal State Implicature
</subsectionHeader>
<bodyText confidence="0.999709615384615">
These two classes of conversational impli-
cature have some interesting similarities and dif-
ferences.
First, licensing a scalar implicature requires
the mention of some specific value in an ordering,
while licensing a normal state implicature requires
the absence of the mention of any state. For ex-
ample, consider a situation where S is a restaurant
customer; H is a waiter; S and H have mutual be-
lief of the salience of an ordering such that warm
precedes boiling hot; and, S and H have mutual
belief of S&apos;s plan to make tea by steeping a tea
bag in boiling hot water.
</bodyText>
<listItem confidence="0.8680836">
14.a. I&apos;d like a pot of water.
b. I&apos;d like a pot of warm water.
c. I&apos;d like a pot of boiling hot water.
d. I&apos;d like a pot of warm but not boiling
hot water.
</listItem>
<bodyText confidence="0.9976758">
In this situation, use of (14a) would license
the normal state implicature (14c) but no scalar
implicature. However, use of (1413) would license
the scalar implicature (14d) but not the normal
state implicature (14c). (In fact, use of &apos;warm&apos; in
</bodyText>
<page confidence="0.977007">
93
</page>
<bodyText confidence="0.999672083333333">
(14b) would cancel (14c), as well as be confusing normal state implicature, while the presence of a
to H due to its inconsistency with H&apos;s belief about qualification (the marked case), blocks it (thereby
S&apos;s intention to make tea.) Thus, at least in this allowing the scalar implicature to be conveyed).
example, scalar and normal state implicature are Herskovits [11er87] addresses the
mutually exclusive. problem that the meaning of a locative expression
Second, saliency and order relations play a varies with the context of its use. Her approach
role in both. Scalar implicature is based on the is to specify &amp;quot;a set of characteristic constraints —
salience of a partially ordered set (from any do- constraints that must hold for the expression to be
main). Normal state implicature is based on the used truly and appropriately under normal condi-
salience of a plan; one of a plan&apos;s preconditions tions. &amp;quot; (p. 20) Her constraints appear to include
may involve a normal state, which can be defined stereotypes and plan-independent normal states;
in terms of a causal event chain. normal is distinguished from prototypical; and the
</bodyText>
<sectionHeader confidence="0.991608" genericHeader="related work">
&apos;7 Related Work constraints may include speaker purpose.
8 Conclusions
</sectionHeader>
<bodyText confidence="0.999982485714286">
This work is related to work in several dif-
ferent areas.
First, one of the goals of research on non-
monotonic reasoning16 has been the use of default
information. The classic example, that if some-
thing is a bird then it can fly, appears to in-
volve all three notions that I have distinguished
here; namely, stereotype, plan-independent nor-
mal state, and normal state with respect to a plan.
(It is a stereotype that birds are genetically suited
for flight; a plan-independent normal state that a
bird is alive or uninjured; and a normal state with
respect to a plan to send a message via carrier pi-
geon that the bird be able to fly.) Also, I have
shown that the calculation of normal state impli-
cature is based only on the third notion, i.e., that
certain &amp;quot;defaults&amp;quot; are context-dependent.
In another area, work has been done on
using knowledge of a speaker&apos;s plans to fill in
missing information to interpret incomplete utter-
ances, e.g. sentence fragments [AP80] and ellipsis
[C ar89].
As for related work on conversational im-
plicature, both [f1or84] and {AL81] describe prag-
matic inferences where what is conveyed by an
utterance is more precise than its literal mean-
ing. They claim that such inferences are based
OH a principle of speaker economy and exploit the
speaker&apos;s and hearer&apos;s shared beliefs about stereo-
types. Also, Horn points out that an unmarked ex-
pression tends to be associated with the stereotype
of an extension and its marked counterpart with
the non-stereotype. Roughly, this corresponds to
my observation regarding (14), that the absence
of a qualification (the unmarked case) licenses a
</bodyText>
<subsectionHeader confidence="0.920607">
&amp;quot;For a survey, see [Gin87]. 94
</subsectionHeader>
<bodyText confidence="0.977475866666667">
This paper has provided a convention for
identifying normal state implicatures. Normal
state implicature permits a speaker to omit certain
information from an indefinite description in cer-
tain situations without being misunderstood. The
convention is that if S makes a request that H per-
form an action A on an E, and if S and H mutually
believe that S has a plan whose success depends
upon the E being in the normal state N with re-
spect to that plan, and that S&apos;s request is a step
of that plan, then S is implicating a request for S
to do A on an E in state N.
In order to specify the convention for nor-
mal state implicature, I distinguished the notions
of stereotype, plan-independent normal state, and
normal state with respect to a plan. This distinc-
tion may prove useful in solving other problems in
the description of how language is used. Also, a
representation for states, in terms of causal event
chains, was proposed.
The convention I have provided is impor-
tant both in natural language generation and in-
terpretation. In generation, a system needs to
consider what normal state implicatures would be
licensed by its use of an indefinite description.
These implicatures determine what qualifications
may be omitted (namely, those which would be im-
plicated) and what ones are required (those which
are needed to block implicatures that the system
does not wish to convey).17 In interpretation, a
system may need to understand what a user has
17This latter behavior is an example of Joshi&apos;s revised
Maxim of Quality: &amp;quot;If you, the speaker, plan to say any-
thing which may imply for the hearer something you believe
to be false, then provide further information to block it.&amp;quot;
[Jos82j
implicated in order to provide a cooperative re-
sponse. For instance, if during a dialogue a sys-
tem has inferred that a user has a plan to make an
immediate delivery, and then the user says (15a),
then if the system knows that the only truck in
terminal A is out of service, it would be uncoop-
erative for the system to reply with (15b) alone;
(15c) should be added for a more cooperative re-
sponse.
</bodyText>
<listItem confidence="0.963140666666667">
15.a. User: Is there a truck in terminal A?
b. System: Yes, there is one
c. but it&apos;s out of service.
</listItem>
<bodyText confidence="0.999818142857143">
This work may be extended in at least two
ways. First, it would be interesting to investigate
what plan inference algorithms are necessary in or-
der to recognize normal state implicatures in ac-
tual dialogue. Another question is whether the
notion of normal state implicature can be gener-
alized to account for other uses of language.
</bodyText>
<sectionHeader confidence="0.996936" genericHeader="acknowledgments">
9 Acknowledgments
</sectionHeader>
<bodyText confidence="0.9991341">
An earlier version of this work was done
at the University of Pennsylvania, partially sup-
ported by DARPA grant N00014-85-K0018. My
thanks to the people there, particularly Bonnie
Webber and Ellen Prince. Thanks to my col-
leagues at SAS Institute Inc., Cary, N. C., for their
moral support while much of this paper was being
written. The final draft was prepared at the Uni-
versity of Delaware; thanks to the people there,
especially Sandra Carberry and K. Vijayashanker.
</bodyText>
<sectionHeader confidence="0.998977" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995275215189873">
[AL8I] Jay David Atlas and Stephen C. Levin-
son. It-clefts, informativeness, and log-
ical form: radical pragmatics (revised
standard version). In Peter Cole, editor,
Radical Pragmatics, pages 1-62, Aca-
demic Press, N. Y., 1981.
[AP80] James F. Allen and C. Raymond Per-
rault. Analyzing intention in utterances.
Artificial Intelligence, 15:143-178, 1980.
[Car88] Sandra Carberry. Modeling the user&apos;s
plans and goals. Computational Linguis-
tics, 14(3):23-37, 1988.
[Car89] Sandra Carberry. A pragmatics-based
approach to ellipsis resolution. Compu-
tational Linguistics, 15(2):75-96, 1989,
[FN71] R. E. Fikes and N. J. Nilsson. Strips: a
new approach to the application of the-
orem proving to problem solving. Artifi-
cial Intelligence, 2:189-208, 1971.
[Gin87] Matthew L. Ginsberg. Readings in Non-
monotonic Reasoning. Morgan Kauf-
mann, Los Altos, California, 1987.
[Gri75] II. Paul Grice. Logic and conversation.
In P. Cole and J. L. Morgan, editors,
Syntax and Semantics III: Speech Acts,
pages 41-58, Academic Press, N.Y.,
1975.
[Her87] Annette Ilerskovits. Language and Spa-
tial Cognition. Cambridge University
Press, Cambridge, England, 1987.
[111183] J. Hurford and B. Heasley. Semantics:
A Coursebook. Cambridge University
Press, Cambridge, England, 1983.
[Hir85j Julia Bell Hirschberg. A Theory
of Scalar Implicature. Technical Re-
port MS-CIS-85-56, Department of
Computer and Information Science, Uni-
versity of Pennsylvania, 1985.
[Hor84] Larry Horn. Toward a new taxonomy
for pragmatic inference: q-based and r-
based implicature. In D. Schiffrin, ed-
itor, CURT &apos;84. Meaning, Form and
Use in Context: Linguistic Applica-
tions, pages 11-42, Georgetown Univer-
sity Press, Washington, D. C., 1984.
[Jos82] Aravind K. Joshi. Mutual beliefs in
question-answer systems. In N. Smith,
editor, Mutual Beliefs, pages 181-197,
Academic Press, New York, 1982.
[Lan87] Amy Lansky. A representation of par-
allel activity based on events, struc-
ture, and causality. In M. P. George
and A. Lansky, editors, Reasoning about
Actions and Plans: Proceedings of the
1986 Workshop, pages 123-160, Morgan
Kaufmann, 1987.
[McC87] John McCarthy. Circumscription — a
form of non-monotonic reasoning. In
Matthew L. Ginsberg, editor, Readings
in Nonmonotonic Reasoning, pages 145-
95 152, Morgan Kaufmann, 1987.
[PASO] R. Perrault and J. Allen. A plan-based
analysis of indirect speech acts. Amer-
ican Journal of Computational Linguis-
tics, 6(3-4):167-182, 1980.
[SA77] Roger C. Schank and Robert P. Abel-
son. Scripts, Plans, Goals and Under-
standing. Lawrence Erlbaum Associates,
Hinsdale, New Jersey, 1977.
[Sch77] Stephen P. Schwartz. Introduction. In
Stephen P. Schwartz, editor, Naming,
Necessity, and Natural Kinds, pages 13-
41, Cornell University Press, 1977.
[Web83j Bonnie L. Webber. So what can we talk
about now? In Jones K. S. Grosz, B. and
13. L. Webber, editors, Readings in Nat-
ural Language Processing, Morgan Kauf-
mann, Los Altos, California, 1983.
live dead
</reference>
<figureCaption confidence="0.997981">
Figure 1: Causal event chain for parrot
</figureCaption>
<figure confidence="0.714821">
unfinished
</figure>
<figureCaption confidence="0.993667">
Figure 2: Causal event chain for vase
</figureCaption>
<bodyText confidence="0.748151333333333">
ripe
Fruit-for-eating = element type
events
</bodyText>
<figure confidence="0.6602674">
[Ripen]
0 [Become Overripe]
constraints
1. R-0
end element type
</figure>
<equation confidence="0.7993378">
unripe(x) (3 r:x.R) occurred(r)
just-ripe(x) a (3 rx.R) occurred(r) A
3o:x.0) occurred(o) A r o)
overripe(x) (A o:x.0) occurred(o)
ripe(x) E- (3 rx.R) occurred(r)
</equation>
<figureCaption confidence="0.999145">
Figure 3: Causal event chain for fruit ripening
</figureCaption>
<figure confidence="0.9974988">
unripe
just-ripe overripe
unborn
broken
repaired
</figure>
<page confidence="0.95149">
96
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.969439">
<title confidence="0.974518">NORMAL STATE IMPLICATURE</title>
<author confidence="0.999937">Nancy L Green</author>
<affiliation confidence="0.999906">Department of Computer and Information Sciences University of Delaware</affiliation>
<address confidence="0.999398">Newark, Delaware 19716, USA</address>
<abstract confidence="0.999676142857143">In the right situation, a speaker can use an unqualified indefinite description without being misun- This use of language, sae a kind of conversational irnplicature, i.e. a non-truth-functional context-dependent inference based upon language users&apos; awareness of principles of cooperative conversation. I present a convention for identifying normal state implicatures which is based upon mutual beliefs of the speaker and hearer about certain properties of the speaker&apos;s plan. A key property is the precondition that an entity playing a role in the plan must be in a normal state with respect to the plan.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jay David Atlas</author>
<author>Stephen C Levinson</author>
</authors>
<title>It-clefts, informativeness, and logical form: radical pragmatics (revised standard version).</title>
<date>1981</date>
<booktitle>Radical Pragmatics,</booktitle>
<pages>1--62</pages>
<editor>In Peter Cole, editor,</editor>
<publisher>Academic Press,</publisher>
<marker>[AL8I]</marker>
<rawString>Jay David Atlas and Stephen C. Levinson. It-clefts, informativeness, and logical form: radical pragmatics (revised standard version). In Peter Cole, editor, Radical Pragmatics, pages 1-62, Academic Press, N. Y., 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James F Allen</author>
<author>C Raymond Perrault</author>
</authors>
<title>Analyzing intention in utterances.</title>
<date>1980</date>
<journal>Artificial Intelligence,</journal>
<pages>15--143</pages>
<contexts>
<context position="23157" citStr="[AP80]" startWordPosition="4020" endWordPosition="4020">mal state with respect to a plan. (It is a stereotype that birds are genetically suited for flight; a plan-independent normal state that a bird is alive or uninjured; and a normal state with respect to a plan to send a message via carrier pigeon that the bird be able to fly.) Also, I have shown that the calculation of normal state implicature is based only on the third notion, i.e., that certain &amp;quot;defaults&amp;quot; are context-dependent. In another area, work has been done on using knowledge of a speaker&apos;s plans to fill in missing information to interpret incomplete utterances, e.g. sentence fragments [AP80] and ellipsis [C ar89]. As for related work on conversational implicature, both [f1or84] and {AL81] describe pragmatic inferences where what is conveyed by an utterance is more precise than its literal meaning. They claim that such inferences are based OH a principle of speaker economy and exploit the speaker&apos;s and hearer&apos;s shared beliefs about stereotypes. Also, Horn points out that an unmarked expression tends to be associated with the stereotype of an extension and its marked counterpart with the non-stereotype. Roughly, this corresponds to my observation regarding (14), that the absence of</context>
</contexts>
<marker>[AP80]</marker>
<rawString>James F. Allen and C. Raymond Perrault. Analyzing intention in utterances. Artificial Intelligence, 15:143-178, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra Carberry</author>
</authors>
<title>Modeling the user&apos;s plans and goals.</title>
<date>1988</date>
<journal>Computational Linguistics,</journal>
<pages>14--3</pages>
<marker>[Car88]</marker>
<rawString>Sandra Carberry. Modeling the user&apos;s plans and goals. Computational Linguistics, 14(3):23-37, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra Carberry</author>
</authors>
<title>A pragmatics-based approach to ellipsis resolution.</title>
<date>1989</date>
<journal>Computational Linguistics,</journal>
<pages>15--2</pages>
<marker>[Car89]</marker>
<rawString>Sandra Carberry. A pragmatics-based approach to ellipsis resolution. Computational Linguistics, 15(2):75-96, 1989,</rawString>
</citation>
<citation valid="true">
<authors>
<author>R E Fikes</author>
<author>N J Nilsson</author>
</authors>
<title>Strips: a new approach to the application of theorem proving to problem solving.</title>
<date>1971</date>
<journal>Artificial Intelligence,</journal>
<pages>2--189</pages>
<marker>[FN71]</marker>
<rawString>R. E. Fikes and N. J. Nilsson. Strips: a new approach to the application of theorem proving to problem solving. Artificial Intelligence, 2:189-208, 1971.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew L Ginsberg</author>
</authors>
<title>Readings in Nonmonotonic Reasoning.</title>
<date>1987</date>
<publisher>Morgan Kaufmann,</publisher>
<location>Los Altos, California,</location>
<contexts>
<context position="23831" citStr="[Gin87]" startWordPosition="4129" endWordPosition="4129">cature, both [f1or84] and {AL81] describe pragmatic inferences where what is conveyed by an utterance is more precise than its literal meaning. They claim that such inferences are based OH a principle of speaker economy and exploit the speaker&apos;s and hearer&apos;s shared beliefs about stereotypes. Also, Horn points out that an unmarked expression tends to be associated with the stereotype of an extension and its marked counterpart with the non-stereotype. Roughly, this corresponds to my observation regarding (14), that the absence of a qualification (the unmarked case) licenses a &amp;quot;For a survey, see [Gin87]. 94 This paper has provided a convention for identifying normal state implicatures. Normal state implicature permits a speaker to omit certain information from an indefinite description in certain situations without being misunderstood. The convention is that if S makes a request that H perform an action A on an E, and if S and H mutually believe that S has a plan whose success depends upon the E being in the normal state N with respect to that plan, and that S&apos;s request is a step of that plan, then S is implicating a request for S to do A on an E in state N. In order to specify the conventio</context>
</contexts>
<marker>[Gin87]</marker>
<rawString>Matthew L. Ginsberg. Readings in Nonmonotonic Reasoning. Morgan Kaufmann, Los Altos, California, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Grice</author>
</authors>
<title>Logic and conversation.</title>
<date>1975</date>
<booktitle>Syntax and Semantics III: Speech Acts,</booktitle>
<pages>41--58</pages>
<editor>In P. Cole and J. L. Morgan, editors,</editor>
<publisher>Academic Press,</publisher>
<location>N.Y.,</location>
<marker>[Gri75]</marker>
<rawString>II. Paul Grice. Logic and conversation. In P. Cole and J. L. Morgan, editors, Syntax and Semantics III: Speech Acts, pages 41-58, Academic Press, N.Y., 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annette Ilerskovits</author>
</authors>
<title>Language and Spatial Cognition.</title>
<date>1987</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, England,</location>
<marker>[Her87]</marker>
<rawString>Annette Ilerskovits. Language and Spatial Cognition. Cambridge University Press, Cambridge, England, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hurford</author>
<author>B Heasley</author>
</authors>
<title>Semantics: A Coursebook.</title>
<date>1983</date>
<tech>Technical Report MS-CIS-85-56,</tech>
<publisher>Cambridge University Press,</publisher>
<institution>Department of Computer and Information Science, University of Pennsylvania,</institution>
<location>Cambridge, England,</location>
<marker>[111183]</marker>
<rawString>J. Hurford and B. Heasley. Semantics: A Coursebook. Cambridge University Press, Cambridge, England, 1983. [Hir85j Julia Bell Hirschberg. A Theory of Scalar Implicature. Technical Report MS-CIS-85-56, Department of Computer and Information Science, University of Pennsylvania, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Larry Horn</author>
</authors>
<title>Toward a new taxonomy for pragmatic inference: q-based and rbased implicature.</title>
<date>1984</date>
<booktitle>CURT &apos;84. Meaning, Form and Use in Context: Linguistic Applications,</booktitle>
<pages>11--42</pages>
<editor>In D. Schiffrin, editor,</editor>
<publisher>University Press,</publisher>
<location>Georgetown</location>
<marker>[Hor84]</marker>
<rawString>Larry Horn. Toward a new taxonomy for pragmatic inference: q-based and rbased implicature. In D. Schiffrin, editor, CURT &apos;84. Meaning, Form and Use in Context: Linguistic Applications, pages 11-42, Georgetown University Press, Washington, D. C., 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
</authors>
<title>Mutual beliefs in question-answer systems.</title>
<date>1982</date>
<booktitle>Mutual Beliefs,</booktitle>
<pages>181--197</pages>
<editor>In N. Smith, editor,</editor>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<marker>[Jos82]</marker>
<rawString>Aravind K. Joshi. Mutual beliefs in question-answer systems. In N. Smith, editor, Mutual Beliefs, pages 181-197, Academic Press, New York, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amy Lansky</author>
</authors>
<title>A representation of parallel activity based on events, structure, and causality.</title>
<date>1987</date>
<booktitle>Reasoning about Actions and Plans: Proceedings of the 1986 Workshop,</booktitle>
<pages>123--160</pages>
<editor>In M. P. George and A. Lansky, editors,</editor>
<publisher>Morgan Kaufmann,</publisher>
<contexts>
<context position="13921" citStr="[Lan87]" startWordPosition="2409" endWordPosition="2409">n)?9 Both problems are outside the scope of this paper. 4 States and Normal States First, what I mean by a side of an entity E is, adopted from (La,n87], a history of related events involving E. In Lansky&apos;s ontology, events may be causally or temporally related. Temporal precedence is transitive. Causality is not transitive and does not necessitate occurrence but does imply temporal precedence. A strong prerequisite constraint (--P) can be defined such that &amp;quot;each event of type E2 can be caused by exactly one event of type _El, and each event of type E, can cause at most one event of type Ea&amp;quot; ([Lan87],p.142). Many classifications expressed as nouns denote a class of entity whose state varies over the period of existence during which it is aptly characterized by the classification. For example, Figure 1 and Figure 2 depict causal event chains&apos; of parrots and vases, respectively. (Nodes represent events and directed arcs represent causality.) The state of being dead or see [McC871. see IC ar88]. 10I don&apos;t mean &apos;causal chain&apos; in the sense that philosophers have recently used it jSch77], nor in the sense of ISA 77), nor do I mean &apos;chain&apos; in the mathematical sense of a total order. broken can b</context>
</contexts>
<marker>[Lan87]</marker>
<rawString>Amy Lansky. A representation of parallel activity based on events, structure, and causality. In M. P. George and A. Lansky, editors, Reasoning about Actions and Plans: Proceedings of the 1986 Workshop, pages 123-160, Morgan Kaufmann, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John McCarthy</author>
</authors>
<title>Circumscription — a form of non-monotonic reasoning.</title>
<date>1987</date>
<booktitle>Readings in Nonmonotonic Reasoning,</booktitle>
<pages>145--95</pages>
<editor>In Matthew L. Ginsberg, editor,</editor>
<publisher>Morgan Kaufmann,</publisher>
<marker>[McC87]</marker>
<rawString>John McCarthy. Circumscription — a form of non-monotonic reasoning. In Matthew L. Ginsberg, editor, Readings in Nonmonotonic Reasoning, pages 145-95 152, Morgan Kaufmann, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Perrault</author>
<author>J Allen</author>
</authors>
<title>A plan-based analysis of indirect speech acts.</title>
<date>1980</date>
<journal>American Journal of Computational Linguistics,</journal>
<pages>6--3</pages>
<contexts>
<context position="3493" citStr="[PASO]" startWordPosition="588" endWordPosition="588"> the use of language I have illustrated in (1) can be seen by considering a situation identical to the above except that the dialogue consists of just A&apos;s saying &amp;quot;I need a garage.&amp;quot; In other words, Grice&apos;s example is of a situation where B has anticipated a request from A which is the same kind of request as (la). 2The customer&apos;s use of (la) is an indirect speech act, namely, a request to be shown a parrot; other possible realizations of this request include &amp;quot;Show me a parrot&amp;quot; and &amp;quot;Can you show me a parrot?&amp;quot;. (The derivation of representations of indirect speech acts has been treated elsewhere [PASO] and is not a concern of this paper.) (lc) is intended to represent that request by means of a first order language extended with higher-order operators such as REQUEST. Also, indefinite descriptions are represented as in 1Web83]. The status of the existence of the parrot in the real world or discourse context (and the related question as to the proper scope of the existential quantifier), is not relevant to the concerns of this paper. My point is that the usual treatments employing a one-to-one translation from surface structure to logical form without consideration of other information will </context>
</contexts>
<marker>[PASO]</marker>
<rawString>R. Perrault and J. Allen. A plan-based analysis of indirect speech acts. American Journal of Computational Linguistics, 6(3-4):167-182, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger C Schank</author>
<author>Robert P Abelson</author>
</authors>
<title>Scripts, Plans, Goals and Understanding. Lawrence Erlbaum Associates,</title>
<date>1977</date>
<location>Hinsdale, New Jersey,</location>
<marker>[SA77]</marker>
<rawString>Roger C. Schank and Robert P. Abelson. Scripts, Plans, Goals and Understanding. Lawrence Erlbaum Associates, Hinsdale, New Jersey, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Introduction</author>
</authors>
<title>So what can we talk about now? In</title>
<date>1977</date>
<booktitle>Web83j</booktitle>
<pages>13--41</pages>
<editor>In Stephen P. Schwartz, editor, Naming, Necessity, and Natural Kinds,</editor>
<publisher>Cornell University Press,</publisher>
<location>Los Altos, California,</location>
<note>live dead</note>
<marker>[Sch77]</marker>
<rawString>Stephen P. Schwartz. Introduction. In Stephen P. Schwartz, editor, Naming, Necessity, and Natural Kinds, pages 13-41, Cornell University Press, 1977. [Web83j Bonnie L. Webber. So what can we talk about now? In Jones K. S. Grosz, B. and 13. L. Webber, editors, Readings in Natural Language Processing, Morgan Kaufmann, Los Altos, California, 1983. live dead</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>