<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001122">
<title confidence="0.9969655">
Comparing Lexicalized Treebank Grammars Extracted from
Chinese, Korean, and English Corpora
</title>
<author confidence="0.999186">
Fei Xia, Chung-hye Han, Martha Palmer, and Aravind Joshi
</author>
<affiliation confidence="0.885527">
University of Pennsylvania
Philadelphia PA 19104, USA
</affiliation>
<email confidence="0.999214">
{fxia,chunghye,mpalmer,joshi}@linc.cis.upenn.edu
</email>
<sectionHeader confidence="0.993893" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999846083333333">
In this paper, we present a method
for comparing Lexicalized Tree Ad-
joining Grammars extracted from
annotated corpora for three lan-
guages: English, Chinese and Ko-
rean. This method makes it possi-
ble to do a quantitative comparison
between the syntactic structures of
each language, thereby providing a
way of testing the Universal Gram-
mar Hypothesis, the foundation of
modern linguistic theories.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999906434782609">
The comparison of the grammars extracted
from annotated corpora (i.e., Treebanks) is
important on both theoretical and engineer-
ing grounds. Theoretically, it allows us to do
a quantitative testing of the Universal Gram-
mar Hypothesis. One of the major concerns
in modern linguistics is to establish an ex-
planatory basis for the similarities and varia-
tions among languages. The working assump-
tion is that languages of the world share a set
of universal linguistic principles and the ap-
parent structural differences attested among
languages can be explained as variation in
the way the universal principles are instan-
tiated. Comparison of the extracted syntac-
tic trees allows us to quantitatively evaluate
how similar the syntactic structures of differ-
ent languages are. From an engineering per-
spective the extracted grammars and the links
between the syntactic structures in the gram-
mars are valuable resources for NLP applica-
tions, such as parsing, computational lexicon
development, and machine translation (MT),
to name a few.
In this paper we first briefly discuss some
linguistic characteristics of English, Chinese,
and Korean, and introduce the Treebanks for
the three languages. We then describe a
tool that extracts Lexicalized Tree Adjoin-
ing Grammars (LTAGs) from Treebanks and
the results of its application to these three
Treebanks. Next, we describe our methodol-
ogy for automatic comparison of the extracted
Treebank grammars, This consists primar-
ily of matching syntactic structures (namely,
templates and sub-templates) in each pair
of Treebank grammars. The ability to per-
form this type of comparison for different lan-
guages has a definite positive impact on the
possibility of sorting out the universal ver-
sus language-dependent features of languages.
Therefore, our grammar extraction tool is not
only an engineering tool of great value in im-
proving the efficiency and accuracy of gram-
mar development, but it is also very useful for
investigating theoretical linguistics.
</bodyText>
<sectionHeader confidence="0.975508" genericHeader="method">
2 Three Languages and Three
Treebanks
</sectionHeader>
<bodyText confidence="0.9997395">
In this section, we briefly discuss some lin-
guistic characteristics of English, Chinese,
and Korean, and introduce the Treebanks for
these languages.
</bodyText>
<subsectionHeader confidence="0.970109">
2.1 Three Languages
</subsectionHeader>
<bodyText confidence="0.9972026">
These three languages belong to different lan-
guage families: English is Germanic, Chinese
is Sino-Tibetan, and Korean is Altaic (Corn-
re, 1987). There are several major differences
between these languages. First, both English
</bodyText>
<page confidence="0.996991">
52
</page>
<bodyText confidence="0.999769">
and Chinese have predominantly subject-
verb-object (SVO) word order, whereas Ko-
rean has underlying SOV order. Second, the
word order in Korean is freer than in English
and Chinese in the sense that argument NPs
are freely permutable (subject to certain dis-
course constraints). Third, Korean and Chi-
nese freely allow subject and object deletion,
but English does not. Fourth, Korean has
richer inflectional morphology than English,
whereas Chinese has little, if any, inflectional
morphology.
</bodyText>
<subsectionHeader confidence="0.999316">
2.2 Three Treebanks
</subsectionHeader>
<bodyText confidence="0.999925">
The Treebanks that we used in this paper are
the English Penn Treebank II (Marcus et al.,
1993), the Chinese Penn Treebank (Xia et
al., 2000b), and the Korean Penn Treebank
(Chung-hye Han, 2000). The main param-
eters of these Treebanks are summarized in
Table 1.1 The tags in each tagset can be
classified into one of four types: (1) syntac-
tic tags for phrase-level annotation, (2) Part-
Of-Speech (POS) tags for head-level annota-
tion, (3) function tags for grammatical func-
tion annotation, and (4) empty category tags
for dropped arguments, traces, and so on.
We chose these Treebanks because they all
use phrase structure annotation and their an-
notation schemata are similar, which facili-
tates the comparison between the extracted
Treebank grammars. Figure 1 shows an an-
notated sentence from the Penn English Tree-
bank.
</bodyText>
<sectionHeader confidence="0.9838675" genericHeader="method">
3 LTAGs and Extraction
Algorithm
</sectionHeader>
<bodyText confidence="0.99941">
In this section, we give a brief introduction to
the LTAG formalism and to a system named
LexTract, which we build to extract LTAGs
from Treebanks.
</bodyText>
<footnote confidence="0.9956305">
1The reason why the average sentence length for
Korean is much shorter than those for English and
Chinese is that a big portion of the corpus for Ko-
rean Treebank includes dialogues that contain many
one-word replies, whereas English and Chinese cor-
pora consist of newspaper articles.
</footnote>
<equation confidence="0.991696">
((S (PP-LOC (IN at)
(NP (NNP FNX))
(NP-SBJ-I (NNS underwriters))
(ADVP (RB still))
(VP (VBP draft)
(NP (NNS policies))
(S-MNR
(NP-SBJ (-NONE- *-I))
(VP (VBG using)
(NP
(NP (NN fountain) (NNS pens))
(CC and)
(NP (VBG blotting) (NN papers))))))))
</equation>
<figureCaption confidence="0.9080215">
Figure 1: An example from Penn English
Treebank
</figureCaption>
<subsectionHeader confidence="0.997346">
3.1 LTAG formalism
</subsectionHeader>
<bodyText confidence="0.999975">
LTAGs are based on the Tree Adjoining
Grammar formalism developed by Joshi,
Levy, and Takahashi (Josh i et al., 1975; Josh
and Schabes, 1997). The primitive elements
of an LTAG are elementary trees (etrees).
Each etree is associated with a lexical item
(called the anchor of the tree) on its fron-
tier. LTAGs possess many desirable proper-
ties, such as the Extended Domain of Local-
ity, which allows the encapsulation of all argu-
ments of the anchor associated with an etree.
There are two types of etrees: initial trees and
auxiliary trees. An auxiliary tree represents
a recursive structure and has a unique leaf
node, called the foot node, which has the same
syntactic category as the root node. Leaf
nodes other than anchor nodes and foot nodes
are substitution nodes. Etrees are combined
by two operations: substitution and adjunc-
tion. The resulting structure of the combined
etrees is called a derived tree. The combina-
tion process is expressed as a derivation tree.
Figure 2 shows the etrees, the derived tree,
and the derivation tree for the sentence un-
derwriters still draft policies. Foot and sub-
stitution nodes are marked by *, and 4., re-
spectively. The dashed and solid lines in the
derivation tree are for adjunction and substi-
tution operations, respectively.
</bodyText>
<subsectionHeader confidence="0.999423">
3.2 The Form of Target Grammars
</subsectionHeader>
<bodyText confidence="0.999916">
Without further constraints, the etrees in
the target grammar (i.e., the grammar to be
extracted by LexTract) could be of various
shapes. LexTract recognizes three types of
</bodyText>
<page confidence="0.998121">
53
</page>
<table confidence="0.9965266">
Language corpus size average sen- # of POS # of syntac- # of func- # of empty cat-
(words) tence length tags tic tags tion tags egory tags
English 1,174K 23.85 words 36 26 20 12
Chinese 100K 23.81 words 34 25 26 7 .
Korean 30K 10.52 words 17 18 17 4
</table>
<tableCaption confidence="0.999875">
Table 1: Size of the Treebanks and the tagsets used in each Treebank
</tableCaption>
<figure confidence="0.994333583333333">
#11:iv •i_;
\ s
-
I ADVP VP. .• Np I NT
NNS
RB
#4:
NP
NNS
polidt.x
VBP NPI
dr.d1
</figure>
<bodyText confidence="0.99665325">
Wq, and the other node X&amp;quot; is a modifier
of the foot node. X&apos; is further expanded
into a spine-etree whose head X° is the
anchor of the whole mod-etree.
</bodyText>
<figure confidence="0.9995434">
(a) el rr es
NP VP
I ADVP
VP
NNS
I RD POP NP
widimorilers I II
,dis draft NNS
policies
(b) derived tree
</figure>
<figureCaption confidence="0.8012075">
Figure 2: Etrees, derived tree, and derivation
tree for underwriters still draft policies
</figureCaption>
<bodyText confidence="0.993741625">
• The conj-etrees for coordination rela-
tions. In a conj-etree, the children of the
root are two conjoined constituents and
a node for a coordination conjunction.
One conjoined constituent is marked as
the foot node, and the other is expanded
into a spine-etree whose head is the an-
chor of the whole tree.
</bodyText>
<figure confidence="0.8980146">
draft(#3)
underwriters(#1) &apos;s policies(#4)
Nii11(#2)
(e) derivation tree
(a) spine-ctrec (h) mod-ctree (c) coin-cute
</figure>
<figureCaption confidence="0.9839065">
Figure 3: Three types of elementary trees in
the target grammar
</figureCaption>
<bodyText confidence="0.943761375">
relation (namely, predicate-argument, modi-
fication, and coordination relations) between
the anchor of an etree and other nodes in the
etree, and imposes the constraint that all the
etrees to be extracted should fall into exactly
one of the three patterns in Figure 3.
• The spine-etrees for predicate-argument
relations. X° is the head of X&amp;quot; and the
anchor of the etree. The etree is formed
by a spine X&apos; —&gt; X&amp;quot;-1 —&gt; X° and
the arguments of X°.
• The mod-etrees for modification rela-
tions. The root of the etree has two chil-
dren, one is a foot node with the label
Spine-etrees are initial trees, whereas mod-
etrees and conj-etrees are auxiliary trees.
</bodyText>
<subsectionHeader confidence="0.99977">
3.3 Extraction algorithm
</subsectionHeader>
<bodyText confidence="0.999931833333333">
The core of LexTract is an extraction algo-
rithm that takes a Treebank sentence such as
the one in Figure 1 and Treebank-specific in-
formation provided by the user of LexTract,
and produces a set of etrees as in Figure 4
and a derivation tree. We have described
LexTract&apos;s architecture, its extraction algo-
rithm, and its applications in (Xia, 1999; Xia
et al., 2000a). Therefore, we shall not re-
peat them in this paper other than point-
ing out that LexTract is completely language-
independent.
</bodyText>
<subsectionHeader confidence="0.915145">
3.4 Experiments
</subsectionHeader>
<bodyText confidence="0.997833222222222">
The results of running LexTract on English,
Chinese, and Korean Treebanks are shown in
Table 2. Templates are etrees with the lexical
items removed. For instance, #3, #6, and #9
in Figure 4 are three distinct etrees but they
share the same template.
Figure 5 shows the log frequency of tem-
plates in the English Treebank and percent-
age of template tokens covered by template
</bodyText>
<figure confidence="0.990770111111111">
wq
Y`i Xl `P X
•■•
xi
Z. Pi
limical hem
x.•
Yki
50
</figure>
<page confidence="0.971399">
54
</page>
<table confidence="0.9991566">
template etree word etree types etree types CFG rules
types types types per word type per word token (unlexicalized)
Eng Gi 6926 131,397 49,206 2.67 34.68 1524
Ch G2 1140 21,125 10,772 1.96 9.13 515
Kor G3 634 9,787 6,747 1.45 2.76 177
</table>
<tableCaption confidence="0.96867">
Table 2: Grammars extracted from three Treebanks
</tableCaption>
<table confidence="0.906239363636364">
#I: #2:
NP
PP S.
NNP
IN NPI FL
it
#11: #I2:
NP NP
VBG NP NPCC; NP1
NN
blotting
</table>
<figureCaption confidence="0.993772">
Figure 4: The extracted etrees from the fully
bracketed ttree
</figureCaption>
<bodyText confidence="0.999739133333334">
types.2 In both cases, template types are
sorted according to their frequencies and plot-
ted on the X-axis. The figure shows that
a small &amp;quot;subset of template types, which oc-
curs very frequently in the Treebank and can
be seen as the core of the Treebank gram-
mar, covers the majority of template tokens
in the Treebank. For instance, the most
frequent template type covers 9.37% of the
template tokens and the top 100 (500, 1000
and 1500, respectively) template types cover
87.1% (96.6%, 98.4% and 99.0%, respectively)
of the tokens, whereas about half (3440) of
the template types occur once, accounting for
only 0.32% of template tokens in total.
</bodyText>
<sectionHeader confidence="0.9855925" genericHeader="method">
4 Comparing Three Treebank
Grammars
</sectionHeader>
<bodyText confidence="0.999939333333333">
In this section, we describe our methodology
for comparing Treebank grammars and the
experimental results.
</bodyText>
<subsectionHeader confidence="0.92339">
4.1 Methodology
</subsectionHeader>
<bodyText confidence="0.929540666666667">
To compare Treebank grammars, we need to
ensure that the Treebank grammars are based
on the same tagset. To achieve that, we first
create a new tagset that includes all the tags
21f a template occurs n times in the corpus, it is
counted as one template type but n template tokens.
</bodyText>
<figure confidence="0.972565">
(a) Frequency
</figure>
<figureCaption confidence="0.995709333333333">
Figure 5: Etree template types and template
tokens in the Penn English Treebank
(X-axes: (a) and (b) template types
</figureCaption>
<bodyText confidence="0.994929548387097">
Y-axes: (a) log frequency of templates; (b)
percentage of template token covered by tem-
plate types)
from the three Treebanks. Then we merge
some tags in this new tagset into a single tag.
This step is necessary because certain distinc-
tions among some tags in one language do not
exist in another language. For example, the
English Treebank has distinct tags for verbs
in past tense, past participals, gerunds, and
so on; however, no such distinction is mor-
phologically marked in Chinese and, there-
fore, the Chinese Treebank uses the same tag
for verbs regardless of the tense and aspect.
To make the conversion straightforward for
verbs, we use a single tag for verbs in the new
tagset. Next, we replace the tags in the origi-
nal Treebanks with the tags in the new tagset,
and then re-run LexTract to build Treebank
grammars from those Treebanks.
Now that the Treebank grammars are based
on the same tagset, we can compare them ac-
cording to the templates and sub-templates
that appear in more than one Treebank —
that is, given a pair of Treebank grammars,
we first calculate how many templates oc-
cur in both granamars;3 Next, we decompose
3Ideally, to get more accurate comparison results,
we would like to compare etrees, rather than templates
(which are non-lexicalized); however, comparing etrees
requires bilingual parallel corpora, which we are cur-
</bodyText>
<figure confidence="0.988296676470588">
#2: #4:
NP VP
NNS ADVP VP&apos;
RB
undermilets I
alill
#3: #6:
NP
NPI VP NNS
VBP NPI polities
draft
#7:
VP )NIP
vp• S NN NP.
NP VP
I fountain
VBG 1,111
using
NP
NNS Cr
and
pens
(b) Coverage
55
templates: sub-templates:
spine: S -&gt; VP -&gt; V
12&gt; subcat: (NP, V@, NP)
V@ NPI with root S
(a) spine-etree template
(b) mod-etree template
NP spine: NP-&gt;N
NP CCI NI. (4&gt; subcat: (NO) with root NP
Ne conj-tuple: (NP*, CC, NP)
(c) conj-etree template
</figure>
<figureCaption confidence="0.76890875">
Figure 6: The decompositions of etree tem-
plates (In sub-templates, @ marks the anchor
in subcategorization frame, * marks the mod-
ifiee in a modifier-modifiee pair.)
</figureCaption>
<bodyText confidence="0.999662923076923">
each template into a list of sub-templates (e.g.,
spines and subcategorization frames) and cal-
culate how many of those sub-templates occur
in both grammars. A template is decomposed
as follows: A spine-etree template is decom-
posed into a spine and a subcategorization
frame; a mod-etree template is decomposed
into a spine, a subcategorization frame, and a
modifier-modifiee pair; a conj-etree template
is decomposed into a spine, a subcategoriza-
tion frame, and a coordination tuple. Figure
6 shows examples of this decomposition for
each type of template.
</bodyText>
<subsectionHeader confidence="0.838147">
4.2 Experiments
</subsectionHeader>
<bodyText confidence="0.991138463414634">
After tags in original Treebanks being re-
placed with the tags in the new tagset, the
numbers of templates in the new Treebank
grammars decrease by about 50%, as shown
in the second column of Table 3 (cf. the sec-
ond column in Table 2). Table 3 also lists the
numbers of sub-templates, such as spines and
subcategorization frames, for each grammar.
Table 4 lists the numbers of template types
shared by each pair of Treebank grammars
and the percentage of the template tokens
rently building.
in each Treebank which are covered by these
common template types. For example, there
are 237 template types that appear in both
English and Chinese Treebank grammars
These 237 template types account for 80.1%
of template tokens in the English Treebank,
and 81.5% of template tokens in the Chi-
nese Treebank. The table shows that, al-
though the number of matched templates are
not very high, they are among the most fre-
quent templates and they account for the ma-
jority of template tokens in the Treebanks.
For instance, in the (Eng, Ch) pair, the 237
template types that appear in both gram-
mars is only 7.5% of all the English template
types, but they cover 80.1% of template to-
kens in the English Treebank. If we define the
core grammar of a language as the set of the
templates that occur very often in the Tree-
bank, the data suggest that the majority of
the core grammars are easily inter-mappable
structures for these three languages.
If we compare sub-templates, rather than
templates, in the Treebank grammars, the
percentages of matched sub-template tokens
(as in Table 5) are higher than the percent-
ages of matched template tokens. This is be-
cause two distinct templates may share com-
mon sub-templates.
</bodyText>
<subsectionHeader confidence="0.99666">
4.3 Unmatched templates
</subsectionHeader>
<bodyText confidence="0.999947055555556">
Our previous experiments (see Table 4) show
that the percentages of unmatched template
tokens in three Treebanks range from 16.0%
to 43.8%, depending on the language pairs.
Given a language pair, there are many pos-
sible reasons why a template appears in one
Treebank grammar, but not in the other. We
divide those unmatched templates into two
categories: spuriously unmatched templates
and truly unmatched templates.
Spuriously unmatched templates Spu-
riously unmatched templates are templates
that either should have found a matched tem-
plate in the other grammar or should not have
been created by LexTract in the first place
if the &apos;Treebanks were complete, uniformly
annotated, and error-free. A spuriously un-
matched template exists because of one of the
</bodyText>
<figure confidence="0.87004125">
VP
vN
VP&apos;t PP
P@ NP;
spine: PP-&gt; P
subcat: (P@, NP)
with root PP
mod-pair: (VP*, PP)
</figure>
<page confidence="0.868187">
56
</page>
<table confidence="0.9980234">
templates subtenzplates
spines subcat frames mod-pairs conj-tuples total
Eng 3139 500 541 332 53 1426
Ch 547 108 180 152 18 458
Kor 271 55 58 53 6 172
</table>
<tableCaption confidence="0.986286">
Table 3: Treebank grammars with the new tagset
</tableCaption>
<table confidence="0.991340625">
matched templates templates with other unmatched
unique tags templates
(Eng,Ch) type (#) (237, 237) (536, 99) (2366, 211)
token (%) (80.1, 81.5) (2.8, 12.3) (17.1, 6.2)
(Eng, Kor) type (#) (83, 83) (2075, 6) (981, 182)
token (%) (57.7, 82.8) (28.1, 0.1) (14.2, 17.1)
(Ch, Kor) type (#) (59,59) (324,6) (164, 206)
token (%) (57.2, 84.0) (29.4, 0.1) (13.4, 16.0)
</table>
<tableCaption confidence="0.999856">
Table 4: Comparisons of templates in three Treebank grammars
</tableCaption>
<bodyText confidence="0.9744493125">
following reasons:
(Si) Treebank size: The template is lin-
guistically sound in both languages, and,
therefore, should belong to the grammars
for these languages. However, the tem-
plate appears in only one Treebank gram-
mar because the other Treebank is too
small to include such a template. Figure
7(S1) shows a template that is valid for
both English and Chinese, but it appears
only in the English Treebank, not in the
Chinese Treebank.
(S2) Annotation difference: Treebanks
may choose different annotations for
the same constructions; consequentially,
the templates for those constructions
look different. Figure 7(S2) shows the
templates used in English and Chinese
for a VP such as &amp;quot;surged 7 (dollars)&amp;quot;.
In the template for English, the QP
projects to an NP, but in the template
for Chinese, it does not.
(S3) Treebank annotation error: A tem-
plate in a Treebank may result from an-
notation errors in that Treebank. If no
corresponding mistakes are made in the
other Treebank, the template in the first
Treebank will not match any template in
the second Treebank. For instance, in the
English Treebank the word about in the
sentence About 5 people showed up is of-
ten mis-tagged as a preposition, resulting
in the template in Figure 7(S3). Not sur-
prisingly, that template does not match
any template in the Chinese Treebank.
Truly unmatched templates A truly un-
matched template is a template that does not
match any template in the other Treebank
even if we assume both Treebanks are per-
fectly annotated. Here, we list three reasons
why a truly unmatched template exist.
(Ti) Word order: The word order deter-
mines the positions of arguments w.r.t.
their heads, and the positions of modi-
fiers w.r.t. their modifiees. If two lan-
guages have different word orders, their
templates which include arguments of a
head or a modifier are likely to look dif-
ferent. For example, Figure 8(T1) show
the templates for transitive verbs in Chi-
nese and Korean grammars. The tem-
plates do not match because of the dif-
ferent positions of the object of the verb.
(T2) Unique tags: For each pair of lan-
guages, some Part-of-speech tags and
syntactic tags may appear in only one
language. Therefore, the templates with
those tags will not match any templates
in the other language. For instance, in
Korean the counterparts of preposition
phrases in English and Chinese are noun
phrases (with postpositions attaching to
them, not preposition phrases); there-
fore, the templates with PP in Chinese,
</bodyText>
<page confidence="0.994473">
57
</page>
<table confidence="0.999709">
spines subcat frames mod-pairs conj-tuples total
(Eng,Ch) type (60,60) (92, 92) (83,83) (11,11) (246,246)
token (94.7,87.2) (94.0, 86.3) (82.6, 80.0) (84.2, 99.1) (91.4, 85.2)
(Eng, Kor) type (39, 39) (40, 40) (46, 46) (1, 1) (126,126)
token (70.3, 96.9) (62.1, 96.6) (56.8, 99.5) (9.3, 52.3) (63.4,97.3)
(Ch, Kor) type (28, 28) (25,25) (29,29) (1, 1) (83, 83)
token (74.2, 99.2) (63.1, 98.1) (60.2, 93.4) (0.1, 0.4) (66.1, 96.9)
</table>
<tableCaption confidence="0.981981">
Table 5: Comparisons of sub-templates in three Treebank grammars
</tableCaption>
<table confidence="0.952427222222222">
VP* VP VP NPf
CC+ NF
V@
English
VP VP QP
VP. Np VP. QP P@ QP*
QP CD@ English
CD@ Chinese
English
</table>
<figure confidence="0.615172">
(SI) Treebank size (S2) annotation difference (S3) annotation error
</figure>
<figureCaption confidence="0.999885">
Figure 7: Examples of spuriously unmatched templates
</figureCaption>
<bodyText confidence="0.999596745098039">
such as the left one in Figure 8(T2), do
not match any template in Korean.
(T3) Unique syntactic relations: Some
syntactic relations may be present in
only one of the pair of languages being
compared. For instance, the template
in Figure 8(T3) is used for the sentence
such as &amp;quot;You should go,&amp;quot; said John,
where the subject of the verb said ap-
pears after the verb. No such template
exists in Chinese.
So far, we have listed six possible reasons
for unmatched templates. Without manually
examining all the unmatched templates, it is
difficult to tell how many unmatched tem-
plates are caused by a particular reason. Nev-
ertheless, these reasons help us to interpret
the results in Table 4. For instance, the ta-
ble shows that Korean grammars cover only
57.7% of template tokens in the English Tree-
bank, and 57.2% in the Chinese Treebank,
whereas the coverages for other language pairs
are all above 80%. We suspect that this
difference of coverage is mainly caused by
(Si), (Ti), and (T2). That is, first, Ko-
rean Treebank is much smaller than the En-
glish and the Chinese Treebanks, English and
Chinese Treebanks may have many tree tem-
plates that simply was not found in the Ko-
rean Treebank; Second, English and Chinese
are predominantly head-initial, whereas Ko-
rean is head-final, therefore, many templates
in English and Chinese can not find matched
templates in Korean because of the word or-
der difference; Third, Korean does not have
preposition phrases, causing all the templates
in English and Chinese with PPs become un-
matched. To measure the effect of the word
order factor to the matching rate, we re-did
the experiment in Section 4.2, but this time
we ignored the word order — that is, we treat
templates as unordered trees. The results are
given in Table 6. Comparing this table with
Table 4, we can clearly see that, the percent-
ages of matched templates increase substan-
tially for (Eng, Kor) and (Ch, Kor) when the
word order is ignored. Notice that the match-
ing percentage for (Eng, Ch) does not change
as much because the word orders in English
and Chinese are much similar than the orders
in English and Korean.
</bodyText>
<sectionHeader confidence="0.998954" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999899857142857">
We have presented a method of quantitatively
comparing LTAGs extracted from Treebanks.
Our experimental results show a high pro-
portion of easily inter-mappable structures,
giving a positive implications for Universal
Grammar hypothesis, We have also described
a number of reasons why a particular tern-
</bodyText>
<page confidence="0.993919">
58
</page>
<figure confidence="0.998499272727273">
se S
VP NEI
...••••■•
we
s
English
NO VP NO VP VP
/.N PP VP. NP VP.
NPt NP1 V@ NPI
Chinese Korean Chinese Korean
(Ti) word order (T2) unique tags (T3) unique relation
</figure>
<figureCaption confidence="0.999304">
Figure 8: Truly unmatched templates
</figureCaption>
<table confidence="0.860192857142857">
matched templates tag mismatches other mismatches
(Eng,Ch) type (334, 259) (536, 99) (2269, 189)
token (82.8, 82.2) (2.8, 12.3) (14.4, 5.5)
(Eng, Kor) type (222, 167) (2075, 6) (842, 98)
token (66.4, 92.4) (28.1, 0.1) (5.5, 7.5)
(Ch, Kor) type (126,125) (324,6) (97, 140)
token (68.3, 97.3) (29.4, 0.1) (2.3, 2.6)
</table>
<tableCaption confidence="0.993894">
Table 6: Comparisons of templates w/o orders
</tableCaption>
<bodyText confidence="0.993268222222222">
plate does not match any template in other
languages and tested the effect of word order
on matching percentages.
There are two natural extensions of this
work. First, running an alignment algorithm
on parallel bracketed corpora to produce
word-to-word mappings. Given such word-to-
word mappings and our template matching
algorithm, we can automatically create lexi-
calized etree-to-etree mappings, which can be
used for semi-automatic transfer lexicon con-
struction. Second, LexTract can build deriva-
tion trees for each sentence in the corpora. By
comparing derivation trees for parallel sen-
tences in two languages, instances of struc-
tural divergences (Dorr, 1993; Dorr, 1994;
Palmer et al., 1998) can be automatically de-
tected.
</bodyText>
<sectionHeader confidence="0.999456" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999899155555556">
Chung-hye Han. 2000. Bracketing Guide-
lines for the Penn Korean Treebank (draft).
www.cis.upenn.edu/ xtag/korean.tag.
Bernard Comrie. 1987. The World&apos;s Major Lan-
guages. Oxford University Press, New York.
B. J. Dorn 1993. Machine Translation: a View
from the Lexicon. MIT Press, Boston, Mass.
B. J. Dorr. 1994. Machine translation diver-
gences: a formal description and proposed so-
lution. Computational Linguistics, 20(4):597—
635.
Aravind Joshi and Yves Schabes. 1997. Tree
Adjoining Grammars. In A. Salomma and
G. Rosenberg, editors, Handbook of For-
mal Languages and Automata. Springer-Verlag,
Herdelberg.
Aravind K. Joshi, L. Levy, and M. Takahashi.
1975. Tree Adjunct Grammars. Journal of
Computer and System Sciences.
M. Marcus, B. Santorini, and M. A.
Marcinldewicz. 1993. Building a Large
Annotated Corpus of English: the Penn
Treebank. Computational Lingustics.
Martha Palmer, Owen Rambow, and Alexis Nasr.
1998. Rapid Prototyping of Domain-Specific
Machine Translation System. In Proc. of
AMTA-1998, Langhorne, PA.
Fei Xia, Martha Palmer, and Aravind Joshi.
2000a. A Uniform Method of Grammar Ex-
traction and its Applications. In Proc. of Joint
SIGDAT Conference on Empirical Methods in
Natural Language Processing and Very Large
Corpora (EMNLP/VLC).
Fei Xia, Martha Palmer, Nianwen Xue,
Mary Ellen Okurowski, John Kovarik, Shizhe
Huang, Tony Kroch, and Mitch Marcus.
2000b. Developing Guidelines and Ensuring
Consistency for Chinese Text Annotation.
In Proc. of the 2nd International Confer-
ence on Language Resources and Evaluation
(LREC-2000), Athens, Greece.
Fei Xia. 1999. Extracting Tree Adjoining Gram-
mars from Bracketed Corpora. In Proc. of 5th
Natural Language Processing Pacific Rim Sym-
posium (NLPRS-99), Beijing, China.
</reference>
<page confidence="0.999261">
59
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.517831">
<title confidence="0.922653">Comparing Lexicalized Treebank Grammars Extracted Chinese, Korean, and English Corpora</title>
<author confidence="0.963113">Fei Xia</author>
<author confidence="0.963113">Chung-hye Han</author>
<author confidence="0.963113">Martha Palmer</author>
<author confidence="0.963113">Aravind</author>
<affiliation confidence="0.997362">University of</affiliation>
<address confidence="0.620612">Philadelphia PA 19104,</address>
<email confidence="0.999493">fxia@linc.cis.upenn.edu</email>
<email confidence="0.999493">chunghye@linc.cis.upenn.edu</email>
<email confidence="0.999493">mpalmer@linc.cis.upenn.edu</email>
<email confidence="0.999493">joshi@linc.cis.upenn.edu</email>
<abstract confidence="0.999562615384615">In this paper, we present a method for comparing Lexicalized Tree Adjoining Grammars extracted from annotated corpora for three languages: English, Chinese and Korean. This method makes it possible to do a quantitative comparison between the syntactic structures of each language, thereby providing a way of testing the Universal Grammar Hypothesis, the foundation of modern linguistic theories.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Chung-hye Han</author>
</authors>
<title>Bracketing Guidelines for the Penn Korean Treebank (draft). www.cis.upenn.edu/ xtag/korean.tag.</title>
<date>2000</date>
<contexts>
<context position="3801" citStr="Han, 2000" startWordPosition="575" endWordPosition="576">ng SOV order. Second, the word order in Korean is freer than in English and Chinese in the sense that argument NPs are freely permutable (subject to certain discourse constraints). Third, Korean and Chinese freely allow subject and object deletion, but English does not. Fourth, Korean has richer inflectional morphology than English, whereas Chinese has little, if any, inflectional morphology. 2.2 Three Treebanks The Treebanks that we used in this paper are the English Penn Treebank II (Marcus et al., 1993), the Chinese Penn Treebank (Xia et al., 2000b), and the Korean Penn Treebank (Chung-hye Han, 2000). The main parameters of these Treebanks are summarized in Table 1.1 The tags in each tagset can be classified into one of four types: (1) syntactic tags for phrase-level annotation, (2) PartOf-Speech (POS) tags for head-level annotation, (3) function tags for grammatical function annotation, and (4) empty category tags for dropped arguments, traces, and so on. We chose these Treebanks because they all use phrase structure annotation and their annotation schemata are similar, which facilitates the comparison between the extracted Treebank grammars. Figure 1 shows an annotated sentence from the</context>
</contexts>
<marker>Han, 2000</marker>
<rawString>Chung-hye Han. 2000. Bracketing Guidelines for the Penn Korean Treebank (draft). www.cis.upenn.edu/ xtag/korean.tag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard Comrie</author>
</authors>
<title>The World&apos;s Major Languages.</title>
<date>1987</date>
<publisher>Oxford University Press,</publisher>
<location>New York.</location>
<marker>Comrie, 1987</marker>
<rawString>Bernard Comrie. 1987. The World&apos;s Major Languages. Oxford University Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Dorn</author>
</authors>
<title>Machine Translation: a View from the Lexicon.</title>
<date>1993</date>
<publisher>MIT Press,</publisher>
<location>Boston, Mass.</location>
<marker>Dorn, 1993</marker>
<rawString>B. J. Dorn 1993. Machine Translation: a View from the Lexicon. MIT Press, Boston, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Dorr</author>
</authors>
<title>Machine translation divergences: a formal description and proposed solution.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<pages>635</pages>
<marker>Dorr, 1994</marker>
<rawString>B. J. Dorr. 1994. Machine translation divergences: a formal description and proposed solution. Computational Linguistics, 20(4):597— 635.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind Joshi</author>
<author>Yves Schabes</author>
</authors>
<title>Tree Adjoining Grammars.</title>
<date>1997</date>
<booktitle>Handbook of Formal Languages and Automata.</booktitle>
<editor>In A. Salomma and G. Rosenberg, editors,</editor>
<publisher>Springer-Verlag, Herdelberg.</publisher>
<marker>Joshi, Schabes, 1997</marker>
<rawString>Aravind Joshi and Yves Schabes. 1997. Tree Adjoining Grammars. In A. Salomma and G. Rosenberg, editors, Handbook of Formal Languages and Automata. Springer-Verlag, Herdelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
<author>L Levy</author>
<author>M Takahashi</author>
</authors>
<title>Tree Adjunct Grammars.</title>
<date>1975</date>
<journal>Journal of Computer and System Sciences.</journal>
<marker>Joshi, Levy, Takahashi, 1975</marker>
<rawString>Aravind K. Joshi, L. Levy, and M. Takahashi. 1975. Tree Adjunct Grammars. Journal of Computer and System Sciences.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>B Santorini</author>
<author>M A Marcinldewicz</author>
</authors>
<title>Building a Large Annotated Corpus of English: the Penn Treebank. Computational Lingustics.</title>
<date>1993</date>
<contexts>
<context position="3702" citStr="Marcus et al., 1993" startWordPosition="557" endWordPosition="560">th English 52 and Chinese have predominantly subjectverb-object (SVO) word order, whereas Korean has underlying SOV order. Second, the word order in Korean is freer than in English and Chinese in the sense that argument NPs are freely permutable (subject to certain discourse constraints). Third, Korean and Chinese freely allow subject and object deletion, but English does not. Fourth, Korean has richer inflectional morphology than English, whereas Chinese has little, if any, inflectional morphology. 2.2 Three Treebanks The Treebanks that we used in this paper are the English Penn Treebank II (Marcus et al., 1993), the Chinese Penn Treebank (Xia et al., 2000b), and the Korean Penn Treebank (Chung-hye Han, 2000). The main parameters of these Treebanks are summarized in Table 1.1 The tags in each tagset can be classified into one of four types: (1) syntactic tags for phrase-level annotation, (2) PartOf-Speech (POS) tags for head-level annotation, (3) function tags for grammatical function annotation, and (4) empty category tags for dropped arguments, traces, and so on. We chose these Treebanks because they all use phrase structure annotation and their annotation schemata are similar, which facilitates th</context>
</contexts>
<marker>Marcus, Santorini, Marcinldewicz, 1993</marker>
<rawString>M. Marcus, B. Santorini, and M. A. Marcinldewicz. 1993. Building a Large Annotated Corpus of English: the Penn Treebank. Computational Lingustics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Owen Rambow</author>
<author>Alexis Nasr</author>
</authors>
<title>Rapid Prototyping of Domain-Specific Machine Translation System. In</title>
<date>1998</date>
<booktitle>Proc. of AMTA-1998,</booktitle>
<location>Langhorne, PA.</location>
<marker>Palmer, Rambow, Nasr, 1998</marker>
<rawString>Martha Palmer, Owen Rambow, and Alexis Nasr. 1998. Rapid Prototyping of Domain-Specific Machine Translation System. In Proc. of AMTA-1998, Langhorne, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
<author>Martha Palmer</author>
<author>Aravind Joshi</author>
</authors>
<title>A Uniform Method of Grammar Extraction and its Applications.</title>
<date>2000</date>
<booktitle>In Proc. of Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP/VLC).</booktitle>
<contexts>
<context position="3747" citStr="Xia et al., 2000" startWordPosition="565" endWordPosition="568">ectverb-object (SVO) word order, whereas Korean has underlying SOV order. Second, the word order in Korean is freer than in English and Chinese in the sense that argument NPs are freely permutable (subject to certain discourse constraints). Third, Korean and Chinese freely allow subject and object deletion, but English does not. Fourth, Korean has richer inflectional morphology than English, whereas Chinese has little, if any, inflectional morphology. 2.2 Three Treebanks The Treebanks that we used in this paper are the English Penn Treebank II (Marcus et al., 1993), the Chinese Penn Treebank (Xia et al., 2000b), and the Korean Penn Treebank (Chung-hye Han, 2000). The main parameters of these Treebanks are summarized in Table 1.1 The tags in each tagset can be classified into one of four types: (1) syntactic tags for phrase-level annotation, (2) PartOf-Speech (POS) tags for head-level annotation, (3) function tags for grammatical function annotation, and (4) empty category tags for dropped arguments, traces, and so on. We chose these Treebanks because they all use phrase structure annotation and their annotation schemata are similar, which facilitates the comparison between the extracted Treebank g</context>
<context position="8947" citStr="Xia et al., 2000" startWordPosition="1463" endWordPosition="1466"> the arguments of X°. • The mod-etrees for modification relations. The root of the etree has two children, one is a foot node with the label Spine-etrees are initial trees, whereas modetrees and conj-etrees are auxiliary trees. 3.3 Extraction algorithm The core of LexTract is an extraction algorithm that takes a Treebank sentence such as the one in Figure 1 and Treebank-specific information provided by the user of LexTract, and produces a set of etrees as in Figure 4 and a derivation tree. We have described LexTract&apos;s architecture, its extraction algorithm, and its applications in (Xia, 1999; Xia et al., 2000a). Therefore, we shall not repeat them in this paper other than pointing out that LexTract is completely languageindependent. 3.4 Experiments The results of running LexTract on English, Chinese, and Korean Treebanks are shown in Table 2. Templates are etrees with the lexical items removed. For instance, #3, #6, and #9 in Figure 4 are three distinct etrees but they share the same template. Figure 5 shows the log frequency of templates in the English Treebank and percentage of template tokens covered by template wq Y`i Xl `P X •■• xi Z. Pi limical hem x.• Yki 50 54 template etree word etree typ</context>
</contexts>
<marker>Xia, Palmer, Joshi, 2000</marker>
<rawString>Fei Xia, Martha Palmer, and Aravind Joshi. 2000a. A Uniform Method of Grammar Extraction and its Applications. In Proc. of Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP/VLC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
<author>Martha Palmer</author>
<author>Nianwen Xue</author>
<author>Mary Ellen Okurowski</author>
<author>John Kovarik</author>
<author>Shizhe Huang</author>
<author>Tony Kroch</author>
<author>Mitch Marcus</author>
</authors>
<title>Developing Guidelines and Ensuring Consistency for Chinese Text Annotation.</title>
<date>2000</date>
<booktitle>In Proc. of the 2nd International Conference on Language Resources and Evaluation (LREC-2000),</booktitle>
<location>Athens, Greece.</location>
<contexts>
<context position="3747" citStr="Xia et al., 2000" startWordPosition="565" endWordPosition="568">ectverb-object (SVO) word order, whereas Korean has underlying SOV order. Second, the word order in Korean is freer than in English and Chinese in the sense that argument NPs are freely permutable (subject to certain discourse constraints). Third, Korean and Chinese freely allow subject and object deletion, but English does not. Fourth, Korean has richer inflectional morphology than English, whereas Chinese has little, if any, inflectional morphology. 2.2 Three Treebanks The Treebanks that we used in this paper are the English Penn Treebank II (Marcus et al., 1993), the Chinese Penn Treebank (Xia et al., 2000b), and the Korean Penn Treebank (Chung-hye Han, 2000). The main parameters of these Treebanks are summarized in Table 1.1 The tags in each tagset can be classified into one of four types: (1) syntactic tags for phrase-level annotation, (2) PartOf-Speech (POS) tags for head-level annotation, (3) function tags for grammatical function annotation, and (4) empty category tags for dropped arguments, traces, and so on. We chose these Treebanks because they all use phrase structure annotation and their annotation schemata are similar, which facilitates the comparison between the extracted Treebank g</context>
<context position="8947" citStr="Xia et al., 2000" startWordPosition="1463" endWordPosition="1466"> the arguments of X°. • The mod-etrees for modification relations. The root of the etree has two children, one is a foot node with the label Spine-etrees are initial trees, whereas modetrees and conj-etrees are auxiliary trees. 3.3 Extraction algorithm The core of LexTract is an extraction algorithm that takes a Treebank sentence such as the one in Figure 1 and Treebank-specific information provided by the user of LexTract, and produces a set of etrees as in Figure 4 and a derivation tree. We have described LexTract&apos;s architecture, its extraction algorithm, and its applications in (Xia, 1999; Xia et al., 2000a). Therefore, we shall not repeat them in this paper other than pointing out that LexTract is completely languageindependent. 3.4 Experiments The results of running LexTract on English, Chinese, and Korean Treebanks are shown in Table 2. Templates are etrees with the lexical items removed. For instance, #3, #6, and #9 in Figure 4 are three distinct etrees but they share the same template. Figure 5 shows the log frequency of templates in the English Treebank and percentage of template tokens covered by template wq Y`i Xl `P X •■• xi Z. Pi limical hem x.• Yki 50 54 template etree word etree typ</context>
</contexts>
<marker>Xia, Palmer, Xue, Okurowski, Kovarik, Huang, Kroch, Marcus, 2000</marker>
<rawString>Fei Xia, Martha Palmer, Nianwen Xue, Mary Ellen Okurowski, John Kovarik, Shizhe Huang, Tony Kroch, and Mitch Marcus. 2000b. Developing Guidelines and Ensuring Consistency for Chinese Text Annotation. In Proc. of the 2nd International Conference on Language Resources and Evaluation (LREC-2000), Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
</authors>
<title>Extracting Tree Adjoining Grammars from Bracketed Corpora.</title>
<date>1999</date>
<booktitle>In Proc. of 5th Natural Language Processing Pacific Rim Symposium (NLPRS-99),</booktitle>
<location>Beijing, China.</location>
<contexts>
<context position="8929" citStr="Xia, 1999" startWordPosition="1461" endWordPosition="1462">1 —&gt; X° and the arguments of X°. • The mod-etrees for modification relations. The root of the etree has two children, one is a foot node with the label Spine-etrees are initial trees, whereas modetrees and conj-etrees are auxiliary trees. 3.3 Extraction algorithm The core of LexTract is an extraction algorithm that takes a Treebank sentence such as the one in Figure 1 and Treebank-specific information provided by the user of LexTract, and produces a set of etrees as in Figure 4 and a derivation tree. We have described LexTract&apos;s architecture, its extraction algorithm, and its applications in (Xia, 1999; Xia et al., 2000a). Therefore, we shall not repeat them in this paper other than pointing out that LexTract is completely languageindependent. 3.4 Experiments The results of running LexTract on English, Chinese, and Korean Treebanks are shown in Table 2. Templates are etrees with the lexical items removed. For instance, #3, #6, and #9 in Figure 4 are three distinct etrees but they share the same template. Figure 5 shows the log frequency of templates in the English Treebank and percentage of template tokens covered by template wq Y`i Xl `P X •■• xi Z. Pi limical hem x.• Yki 50 54 template et</context>
</contexts>
<marker>Xia, 1999</marker>
<rawString>Fei Xia. 1999. Extracting Tree Adjoining Grammars from Bracketed Corpora. In Proc. of 5th Natural Language Processing Pacific Rim Symposium (NLPRS-99), Beijing, China.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>