<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000860">
<title confidence="0.9944">
Aspect Extraction with Automated Prior Knowledge Learning
</title>
<author confidence="0.99422">
Zhiyuan Chen Arjun Mukherjee Bing Liu
</author>
<affiliation confidence="0.8875">
Department of Computer Science
University of Illinois at Chicago
Chicago, IL 60607, USA
</affiliation>
<email confidence="0.998567">
{czyuanacm,arjun4787}@gmail.com,liub@cs.uic.edu
</email>
<sectionHeader confidence="0.997383" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999392">
Aspect extraction is an important task in
sentiment analysis. Topic modeling is a
popular method for the task. However,
unsupervised topic models often generate
incoherent aspects. To address the is-
sue, several knowledge-based models have
been proposed to incorporate prior knowl-
edge provided by the user to guide mod-
eling. In this paper, we take a major
step forward and show that in the big data
era, without any user input, it is possi-
ble to learn prior knowledge automatically
from a large amount of review data avail-
able on the Web. Such knowledge can
then be used by a topic model to discover
more coherent aspects. There are two key
challenges: (1) learning quality knowl-
edge from reviews of diverse domains,
and (2) making the model fault-tolerant
to handle possibly wrong knowledge. A
novel approach is proposed to solve these
problems. Experimental results using re-
views from 36 domains show that the pro-
posed approach achieves significant im-
provements over state-of-the-art baselines.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999967462962963">
Aspect extraction aims to extract target entities
and their aspects (or attributes) that people have
expressed opinions upon (Hu and Liu, 2004, Liu,
2012). For example, in “The voice is not clear,”
the aspect term is “voice.” Aspect extraction has
two subtasks: aspect term extraction and aspect
term resolution. Aspect term resolution groups ex-
tracted synonymous aspect terms together. For ex-
ample, “voice” and “sound” should be grouped to-
gether as they refer to the same aspect of phones.
Recently, topic models have been extensively
applied to aspect extraction because they can per-
form both subtasks at the same time while other
existing methods all need two separate steps (see
Section 2). Traditional topic models such as
LDA (Blei et al., 2003) and pLSA (Hofmann,
1999) are unsupervised methods for extracting la-
tent topics in text documents. Topics are aspects
in our task. Each aspect (or topic) is a distribution
over (aspect) terms. However, researchers have
shown that fully unsupervised models often pro-
duce incoherent topics because the objective func-
tions of topic models do not always correlate well
with human judgments (Chang et al., 2009).
To tackle the problem, several semi-supervised
topic models, also called knowledge-based topic
models, have been proposed. DF-LDA (Andrze-
jewski et al., 2009) can incorporate two forms
of prior knowledge from the user: must-links
and cannot-links. A must-link implies that two
terms (or words) should belong to the same topic
whereas a cannot-link indicates that two terms
should not be in the same topic. In a similar but
more generic vein, must-sets and cannot-sets are
used in MC-LDA (Chen et al., 2013b). Other re-
lated works include (Andrzejewski et al., 2011,
Chen et al., 2013a, Chen et al., 2013c, Mukher-
jee and Liu, 2012, Hu et al., 2011, Jagarlamudi et
al., 2012, Lu et al., 2011, Petterson et al., 2010).
They all allow prior knowledge to be specified by
the user to guide the modeling process.
In this paper, we take a major step further. We
mine the prior knowledge directly from a large
amount of relevant data without any user inter-
vention, and thus make this approach fully au-
tomatic. We hypothesize that it is possible to
learn quality prior knowledge from the big data
(of reviews) available on the Web. The intuition
is that although every domain is different, there
is a decent amount of aspect overlapping across
domains. For example, every product domain
has the aspect/topic of “price,” most electronic
products share the aspect “battery” and some also
share “screen.” Thus, the shared aspect knowl-
</bodyText>
<page confidence="0.972748">
347
</page>
<note confidence="0.831062">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 347–358,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999254857142857">
edge mined from a set of domains can poten-
tially help improve aspect extraction in each of
these domains, as well as in new domains. Our
proposed method aims to achieve this objective.
There are two major challenges: (1) learning qual-
ity knowledge from a large number of domains,
and (2) making the extraction model fault-tolerant,
i.e., capable of handling possibly incorrect learned
knowledge. We briefly introduce the proposed
method below, which consists of two steps.
Learning quality knowledge: Clearly, learned
knowledge from only a single domain can be er-
roneous. However, if the learned knowledge is
shared by multiple domains, the knowledge is
more likely to be of high quality. We thus propose
to first use LDA to learn topics/aspects from each
individual domain and then discover the shared as-
pects (or topics) and aspect terms among a sub-
set of domains. These shared aspects and aspect
terms are more likely to be of good quality. They
can serve as the prior knowledge to guide a model
to extract aspects. A piece of knowledge is a set
of semantically coherent (aspect) terms which are
likely to belong to the same topic or aspect, i.e.,
similar to a must-link, but mined automatically.
Extraction guided by learned knowledge: For
reliable aspect extraction using the learned prior
knowledge, we must account for possible errors
in the knowledge. In particular, a piece of au-
tomatically learned knowledge may be wrong or
domain specific (i.e., the words in the knowledge
are semantically coherent in some domains but
not in others). To leverage such knowledge, the
system must detect those inappropriate pieces of
knowledge. We propose a method to solve this
problem, which also results in a new topic model,
called AKL (Automated Knowledge LDA), whose
inference can exploit the automatically learned
prior knowledge and handle the issues of incorrect
knowledge to produce superior aspects.
In summary, this paper makes the following
contributions:
</bodyText>
<listItem confidence="0.94586075">
1. It proposes to exploit the big data to learn prior
knowledge and leverage the knowledge in topic
models to extract more coherent aspects. The
process is fully automatic. To the best of our
knowledge, none of the existing models for as-
pect extraction is able to achieve this.
2. It proposes an effective method to learn qual-
ity knowledge from raw topics produced using
review corpora from many different domains.
3. It proposes a new inference mechanism for
topic modeling, which can handle incorrect
knowledge in aspect extraction.
</listItem>
<sectionHeader confidence="0.999089" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999846195652174">
Aspect extraction has been studied by many re-
searchers in sentiment analysis (Liu, 2012, Pang
and Lee, 2008), e.g., using supervised sequence
labeling or classification (Choi and Cardie, 2010,
Jakob and Gurevych, 2010, Kobayashi et al., 2007,
Li et al., 2010, Yang and Cardie, 2013) and us-
ing word frequency and syntactic patterns (Hu
and Liu, 2004, Ku et al., 2006, Liu et al., 2013,
Popescu and Etzioni, 2005, Qiu et al., 2011, So-
masundaran and Wiebe, 2009, Wu et al., 2009, Xu
et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou
et al., 2013, Zhuang et al., 2006). However,
these works only perform extraction but not as-
pect term grouping or resolution. Separate aspect
term grouping has been done in (Carenini et al.,
2005, Guo et al., 2009, Zhai et al., 2011). They
assume that aspect terms have been extracted be-
forehand.
To extract and group aspects simultaneously,
topic models have been applied by researchers
(Branavan et al., 2008, Brody and Elhadad, 2010,
Chen et al., 2013b, Fang and Huang, 2012, He
et al., 2011, Jo and Oh, 2011, Kim et al., 2013,
Lazaridou et al., 2013, Li et al., 2011, Lin and
He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and
Zhai, 2008, Mei et al., 2007, Moghaddam and Es-
ter, 2013, Mukherjee and Liu, 2012, Sauper and
Barzilay, 2013, Titov and McDonald, 2008, Wang
et al., 2010, Zhao et al., 2010). Our proposed AKL
model belongs to the class of knowledge-based
topic models. Besides the knowledge-based topic
models discussed in Section 1, document labels
are incorporated as implicit knowledge in (Blei
and McAuliffe, 2007, Ramage et al., 2009). Ge-
ographical region knowledge has also been con-
sidered in topic models (Eisenstein et al., 2010).
All of these models assume that the prior knowl-
edge is correct. GK-LDA (Chen et al., 2013a) is
the only knowledge-based topic model that deals
with wrong lexical knowledge to some extent. As
we will see in Section 6, AKL outperformed GK-
LDA significantly due to AKL’s more effective er-
ror handling mechanism. Furthermore, GK-LDA
does not learn any prior knowledge.
Our work is also related to transfer learning to
some extent. Topic models have been used to help
</bodyText>
<page confidence="0.997173">
348
</page>
<bodyText confidence="0.8072665">
Input: Corpora DL for knowledge learning
Test corpora DT
</bodyText>
<listItem confidence="0.9837352">
1: // STEP 1: Learning prior knowledge.
2: for r = 0 to R do // Iterate R + 1 times.
3: for each domain corpus Di E DL do
4: if r = 0 then
5: Ai +— LDA(Di);
6: else
7: Ai +— AKL(Di, K);
8: end if
9: end for
10: A +— UiAi;
11: TC +— Clustering(A);
12: for each cluster Tj E TC do
13: Kj +— FPM(Tj);
14: end for
15: K +— UjKj;
16: end for
17: // STEP 2: Using the learned knowledge.
18: for each test corpus Di E DT do
19: Ai +— AKL(Di, K);
20: end for
</listItem>
<figureCaption confidence="0.999569">
Figure 1: The proposed overall algorithm.
</figureCaption>
<bodyText confidence="0.999976333333333">
transfer learning (He et al., 2011, Pan and Yang,
2010, Xue et al., 2008). However, transfer learn-
ing in these papers is for traditional classification
rather than topic/aspect extraction. In (Kang et al.,
2012), labeled documents from source domains
are transferred to the target domain to produce
topic models with better fitting. However, we do
not use any labeled data. In (Yang et al., 2011), a
user provided parameter indicating the technical-
ity degree of a domain was used to model the lan-
guage gap between topics. In contrast, our method
is fully automatic without human intervention.
</bodyText>
<sectionHeader confidence="0.992317" genericHeader="method">
3 Overall Algorithm
</sectionHeader>
<bodyText confidence="0.999018145833333">
This section introduces the proposed overall algo-
rithm. It consists of two main steps: learning qual-
ity knowledge and using the learned knowledge.
Figure 1 gives the algorithm.
Step 1 (learning quality knowledge, Lines 1-
16): The input is the review corpora DL from
multiple domains, from which the knowledge is
automatically learned. Lines 3 and 5 run LDA on
each review domain corpus Di E DL to gener-
ate a set of aspects/topics Ai (lines 2, 4, and 6-
9 will be discussed below). Line 10 unions the
topics from all domains to give A. Lines 11-14
cluster the topics in A into some coherent groups
(or clusters) and then discover knowledge Kj from
each group of topics using frequent pattern mining
(FPM) (Han et al., 2007). We will detail these in
Section 4. Each piece of the learned knowledge
is a set of terms which are likely to belong to the
same aspect.
Iterative improvement: The above process can
actually run iteratively because the learned knowl-
edge K can help the topic model learn better top-
ics in each domain Di E DL, which results in
better knowledge K in the next iteration. This it-
erative process is reflected in lines 2, 4, 6-9 and 16.
We will examine the performance of the process at
different iterations in Section 6.2. From the sec-
ond iteration, we can use the knowledge learned
from the previous iteration (lines 6-8). The learned
knowledge is leveraged by the new model AKL,
which is discussed below in Step 2.
Step 2 (using the learned knowledge, Lines 17-
20): The proposed model AKL is employed to use
the learned knowledge K to help topic modeling
in test domains DT , which can be DL or other
unseen domains. The key challenge of this step is
how to use the learned prior knowledge K effec-
tively in AKL and deal with possible errors in K.
We will elaborate them in Section 5.
Scalability: the proposed algorithm is naturally
scalable as both LDA and AKL run on each do-
main independently. Thus, for all domains, the
algorithm can run in parallel. Only the resulting
topics need to be brought together for knowledge
learning (Step 1). These resulting topics used in
learning are much smaller than the domain corpus
as only a list of top terms from each topic are uti-
lized due to their high reliability.
</bodyText>
<sectionHeader confidence="0.914668" genericHeader="method">
4 Learning Quality Knowledge
</sectionHeader>
<bodyText confidence="0.999779875">
This section details Step 1 in the overall algorithm,
which has three sub-steps: running LDA (or AKL)
on each domain corpus, clustering the resulting
topics, and mining frequent patterns from the top-
ics in each cluster. Since running LDA is simple,
we will not discuss it further. The proposed AKL
model will be discussed in Section 5. Below we
focus on the other two sub-steps.
</bodyText>
<subsectionHeader confidence="0.994506">
4.1 Topic Clustering
</subsectionHeader>
<bodyText confidence="0.9999155">
After running LDA (or AKL) on each domain cor-
pus, a set of topics is obtained. Each topic is
a distribution over terms (or words), i.e., terms
with their associated probabilities. Here, we use
only the top terms with high probabilities. As dis-
cussed earlier, quality knowledge should be shared
</bodyText>
<page confidence="0.995685">
349
</page>
<bodyText confidence="0.99977825">
by topics across several domains. Thus, it is nat-
ural to exploit a frequency-based approach to dis-
cover frequent set of terms as quality knowledge.
However, we need to deal with two issues.
</bodyText>
<listItem confidence="0.6772016875">
1. Generic aspects, such as price with aspect
terms like cost and pricy, are shared by many
(even all) product domains. But specific as-
pects such as screen, occur only in domains
with products having them. It means that dif-
ferent aspects may have distinct frequencies.
Thus, using a single frequency threshold in the
frequency-based approach is not sufficient to
extract both generic and specific aspects be-
cause the generic aspects will result in numer-
ous spurious aspects (Han et al., 2007).
2. A term may have multiple senses in different
domains. For example, light can mean “of little
weight” or “something that makes things visi-
ble”. A good knowledge base should have the
capacity of handling this ambiguity.
</listItem>
<bodyText confidence="0.9999207">
To deal with these two issues, we propose to
discover knowledge in two stages: topic clustering
and frequent pattern mining (FPM).
The purpose of clustering is to group raw topics
from a topic model (LDA or AKL) into clusters.
Each cluster contains semantically related topics
likely to indicate the same real-world aspect. We
then mine knowledge from each cluster using an
FPM technique. Note that the multiple senses of a
term can be distinguished by the semantic mean-
ings represented by the topics in different clusters.
For clustering, we tried k-means and k-
medoids (Kaufman and Rousseeuw, 1990), and
found that k-medoids performs slightly better.
One possible reason is that k-means is more sen-
sitive to outliers. In our topic clustering, each data
point is a topic represented by its top terms (with
their probabilities normalized). The distance be-
tween two data points is measured by symmetrised
KL-Divergence.
</bodyText>
<subsectionHeader confidence="0.99524">
4.2 Frequent Pattern Mining
</subsectionHeader>
<bodyText confidence="0.999876541666667">
Given topics within each cluster, this step finds
sets of terms that appear together in multiple top-
ics, i.e., shared terms among similar topics across
multiple domains. Terms in such a set are likely
to belong to the same aspect. To find such sets of
terms within each cluster, we use frequent pattern
mining (FPM) (Han et al., 2007), which is suited
for the task. The probability of each term is ig-
nored in FPM.
FPM is stated as follows: Given a set of trans-
actions ❚, where each transaction tz E ❚ is a set
of items from a global item set ■, i.e., tz E ■. In
our context, tz is the topic vector comprising the
top terms of a topic (no probability attached). ❚
is the collection of all topics within a cluster and
■ is the set of all terms in ❚. The goal of FPM is
to find all patterns that satisfy some user-specified
frequency threshold (also called minimum support
count), which is the minimum number of times
that a pattern should appear in ❚. Such patterns
are called frequent patterns. In our context, a pat-
tern is a set of terms which have appeared multiple
times in the topics within a cluster. Such patterns
compose our knowledge base as shown below.
</bodyText>
<subsectionHeader confidence="0.998294">
4.3 Knowledge Representation
</subsectionHeader>
<bodyText confidence="0.954903642857143">
As the knowledge is extracted from each cluster
individually, we represent our knowledge base as
a set of clusters, where each cluster consists of a
set of frequent 2-patterns mined using FPM, e.g.,
Cluster 1: {battery, life}, {battery, hour},
{battery, long}, {charge, long}
Cluster 2: {service, support}, {support, cus-
tomer}, {service, customer}
Using two terms in a set is sufficient to cover the
semantic relationship of the terms belonging to the
same aspect. Longer patterns tend to contain more
errors since some terms in a set may not belong to
the same aspect as others. Such partial errors hurt
performance in the downstream model.
</bodyText>
<sectionHeader confidence="0.915021" genericHeader="method">
5 AKL: Using the Learned Knowledge
</sectionHeader>
<bodyText confidence="0.999983333333333">
We now present the proposed topic model AKL,
which is able to use the automatically learned
knowledge to improve aspect extraction.
</bodyText>
<subsectionHeader confidence="0.992564">
5.1 Plate Notation
</subsectionHeader>
<bodyText confidence="0.999984769230769">
Differing from most topic models based on topic-
term distribution, AKL incorporates a latent clus-
ter variable c to connect topics and terms. The
plate notation of AKL is shown in Figure 2. The
inputs of the model are M documents, T top-
ics and C clusters. Each document m has Nm
terms. We model distribution P(cluster|topic)
as ψ and distribution P(term|topic, cluster) as
cp with Dirichlet priors Q and γ respectively.
P (topic|document) is modeled by θ with a
Dirichlet prior α. The terms in each document are
assumed to be generated by first sampling a topic
z, and then a cluster c given topic z, and finally
</bodyText>
<page confidence="0.993312">
350
</page>
<figureCaption confidence="0.999293">
Figure 2: Plate notation for AKL.
</figureCaption>
<bodyText confidence="0.96903525">
a term w given topic z and cluster c. This plate
notation of AKL and its associated generative pro-
cess are similar to those of MC-LDA (Chen et al.,
2013b). However, there are three key differences.
</bodyText>
<listItem confidence="0.989733857142857">
1. Our knowledge is automatically mined which
may have errors (or noises), while the prior
knowledge for MC-LDA is manually provided
and assumed to be correct. As we will see in
Section 6, using our knowledge, MC-LDA does
not generate as coherent aspects as AKL.
2. Our knowledge is represented as clusters. Each
cluster contains a set of frequent 2-patterns
with semantically correlated terms. They are
different from must-sets used in MC-LDA.
3. Most importantly, due to the use of the new
form of knowledge, AKL’s inference mecha-
nism (Gibbs sampler) is entirely different from
that of MC-LDA (Section 5.2), which results in
</listItem>
<bodyText confidence="0.899872875">
superior performances (Section 6). Note that
the inference mechanism and the prior knowl-
edge cannot be reflected in the plate notation
for AKL in Figure 2.
In short, our modeling contributions are (1) the
capability of handling more expressive knowledge
in the form of clusters, (2) a novel Gibbs sampler
to deal with inappropriate knowledge.
</bodyText>
<subsectionHeader confidence="0.999118">
5.2 The Gibbs Sampler
</subsectionHeader>
<bodyText confidence="0.99886615">
As the automatically learned prior knowledge may
contain errors for a domain, AKL has to learn
the usefulness of each piece of knowledge dy-
namically during inference. Instead of assigning
weights to each piece of knowledge as a fixed prior
in (Chen et al., 2013a), we propose a new Gibbs
sampler, which can dynamically balance the use
of prior knowledge and the information in the cor-
pus during the Gibbs sampling iterations.
We adopt a Blocked Gibbs sampler (Rosen-Zvi
et al., 2010) as it improves convergence and re-
duces autocorrelation when the variables (topic z
and cluster c in AKL) are highly related. For each
term wi in each document, we jointly sample a
topic zi and cluster ci (containing wi) based on the
conditional distribution in Gibbs sampler (will be
detailed in Equation 4). To compute this distribu-
tion, instead of considering how well zi matches
with wi only (as in LDA), we also consider two
other factors:
</bodyText>
<listItem confidence="0.972583875">
1. The extent ci corroborates wi given the corpus.
By “corroborate”, we mean whether those fre-
quent 2-patterns in ci containing wi are also
supported by the actual information in the do-
main corpus to some extent (see the measure in
Equation 1 below). If ci corroborates wi well,
ci is likely to be useful, and thus should also
provide guidance in determining zi. Otherwise,
ci may not be a suitable piece of knowledge for
wi in the domain.
2. Agreement between ci and zi. By agreement
we mean the degree that the terms (union of all
frequent 2-patterns of ci) in cluster ci are re-
flected in topic zi. Unlike the first factor, this is
a global factor as it concerns all the terms in a
knowledge cluster.
</listItem>
<bodyText confidence="0.999841">
For the first factor, we measure how well ci
corroborates wi given the corpus based on co-
document frequency ratio. As shown in (Mimno
et al., 2011), co-document frequency is a good in-
dicator of term correlation in a domain. Follow-
ing (Mimno et al., 2011), we define a symmetric
co-document frequency ratio as follows:
</bodyText>
<equation confidence="0.9995865">
D(w, w&apos;) + 1
Co-Doc(w, w&apos;) = (D(w) + D(w&apos;)) × 2 + 1 (1)
</equation>
<bodyText confidence="0.999901611111111">
where (w, w&apos;) refers to each frequent 2-pattern in
the knowledge cluster ci. D(w, w&apos;) is the number
of documents that contain both terms w and w&apos; and
D(w) is the number of documents containing w.
A smoothing count of 1 is added to avoid the ratio
being 0.
For the second factor, if cluster ci and topic zi
agree, the intuition is that the terms in ci (union of
all frequent 2-patterns of ci) should appear as top
terms under zi (i.e., ranked top according to the
term probability under zi). We define the agree-
ment using symmetrised KL-Divergence between
the two distributions (DISTc and DISTz) cor-
responding to ci and zi respectively. As there is
no prior preference on the terms of ci, we use
the uniform distribution over all terms in ci for
DISTc. For DISTz, as only top 20 terms un-
der zi are usually reliable, we use these top terms
</bodyText>
<page confidence="0.994062">
351
</page>
<bodyText confidence="0.999842">
with their probabilities (re-normalized) to repre-
sent the topic. Note that a smoothing probability
(i.e., a very small value) is also given to every term
for calculating KL-Divergence. Given DISTc and
DISTz, the agreement is computed with:
</bodyText>
<equation confidence="0.9936">
1
Agreement(c, z) = KL(DISTc, DISTz) (2)
</equation>
<bodyText confidence="0.965931344827586">
The rationale of Equation 2 is that the lesser di-
vergence between DISTc and DISTz implies the
more agreement between ci and zi.
We further employ the Generalized Plya urn
(GPU) model (Mahmoud, 2008) which was shown
to be effective in leveraging semantically related
words (Chen et al., 2013a, Chen et al., 2013b,
Mimno et al., 2011). The GPU model here ba-
sically states that assigning topic zi and cluster ci
to term wi will not only increase the probability
of connecting zi and ci with wi, but also make
it more likely to associate zi and ci with term w0
where w0 shares a 2-pattern with wi in ci. The
amount of probability increase is determined by
matrix Ac,w0,w defined as:
⎧ 1, if w = w0 (3)
⎨⎪ v, if (w, w0) E c, w =� w0
❆c,w0,w = 0, otherwise
⎪⎩
where value 1 controls the probability increase of
w by seeing w itself, and σ controls the probability
increase of w0 by seeing w. Please refer to (Chen
et al., 2013b) for more details.
Putting together Equations 1, 2 and 3 into a
blocked Gibbs Sampler, we can define the follow-
ing sampling distribution in Gibbs sampler so that
it provides helpful guidance in determining the
usefulness of the prior knowledge and in selecting
the semantically coherent topic.
</bodyText>
<equation confidence="0.999793285714286">
P(zi = t, ci = c|z−i, c−i, w, α, Q, γ, ❆)
Xoc Co-Doc(w, w0) X Agreement(c, t)
(w,w0)∈c
n−im,t + α
X
PV v0=1(PV w0=1 ❆c,w0,v0 X n−i
t,c,w0 + γ)
</equation>
<bodyText confidence="0.999799363636363">
where n−i denotes the count excluding the current
assignment of zi and ci, i.e., z−i and c−i. nm,t de-
notes the number of times that topic t was assigned
to terms in document m. nt,c denotes the times
that cluster c occurs under topic t. nt,c,v refers to
the number of times that term v appears in cluster
c under topic t. α, Q and γ are predefined Dirichlet
hyperparameters.
Note that although the above Gibbs sampler is
able to distinguish useful knowledge from wrong
knowledge, it is possible that there is no cluster
corroborates for a particular term. For every term
w, apart from its knowledge clusters, we also add
a singleton cluster for w, i.e., a cluster with one
pattern {w, w} only. When no knowledge cluster
is applicable, this singleton cluster is used. As a
singleton cluster does not contain any knowledge
information but only the word itself, Equations 1
and 2 cannot be computed. For the values of sin-
gleton clusters for these two equations, we assign
them as the averages of those values of all non-
singleton knowledge clusters.
</bodyText>
<sectionHeader confidence="0.999856" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<bodyText confidence="0.999920545454545">
This section evaluates and compares the pro-
posed AKL model with three baseline models
LDA, MC-LDA, and GK-LDA. LDA (Blei et
al., 2003) is the most popular unsupervised topic
model. MC-LDA (Chen et al., 2013b) is a re-
cent knowledge-based model for aspect extrac-
tion. GK-LDA (Chen et al., 2013a) handles wrong
knowledge by setting prior weights using the ratio
of word probabilities. Our automatically extracted
knowledge is provided to these models. Note that
cannot-set of MC-LDA is not used in AKL.
</bodyText>
<subsectionHeader confidence="0.990392">
6.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.999982833333333">
Dataset. We created a large dataset containing
reviews from 36 product domains or types from
Amazon.com. The product domain names are
listed in Table 1. Each domain contains 1, 000 re-
views. This gives us 36 domain corpora. We have
made the dataset publically available at the web-
site of the first author.
Pre-processing. We followed (Chen et al., 2013b)
to employ standard pre-processing like lemmatiza-
tion and stopword removal. To have a fair compar-
ison, we also treat each sentence as a document as
in (Chen et al., 2013a, Chen et al., 2013b).
Parameter Settings. For all models, posterior es-
timates of latent variables were taken with a sam-
pling lag of 20 iterations in the post burn-in phase
(first 200 iterations for burn-in) with 2, 000 itera-
tions in total. The model parameters were tuned
on the development set in our pilot experiments
</bodyText>
<equation confidence="0.988684125">
X
X
PTt0=1(n−im,t0 + α) (4)
[� P/w0 1 PvV1=1 ❆c,v0 w0 X nt,c,v0 + Q
/�
Lac [=��1 (Pwv,=1 PVv0 =1 ❆c0 v0 w0 X nt c0 v0 + )3)
L�wI=1 ❆c,w0,wi X n−i
t,c,w0 + γ
</equation>
<page confidence="0.987335">
352
</page>
<table confidence="0.998416666666667">
Amplifier DVD Player Kindle MP3 Player Scanner Video Player
Blu-Ray Player GPS Laptop Network Adapter Speaker Video Recorder
Camera Hard Drive Media Player Printer Subwoofer Watch
CD Player Headphone Microphone Projector Tablet Webcam
Cell Phone Home Theater System Monitor Radar Detector Telephone Wireless Router
Computer Keyboard Mouse Remote Control TV Xbox
</table>
<tableCaption confidence="0.999579">
Table 1: List of 36 domain names.
</tableCaption>
<subsectionHeader confidence="0.486118">
Topic Coherence
</subsectionHeader>
<bodyText confidence="0.995929428571429">
and set to α = 1, Q = 0.1, T = 15, and σ = 0.2.
Furthermore, for each cluster, γ is set proportional
to the number of terms in it. The other param-
eters for MC-LDA and GK-LDA were set as in
their original papers. For parameters of AKL, we
used the top 15 terms for each topic in the clus-
tering phrase. The number of clusters is set to
the number of domains. We will test the sensitiv-
ity of these clustering parameters in Section 6.4.
The minimum support count for frequent pattern
mining was set empirically to min(5, 0.4 × #T),
where #T is the number of transactions (i.e., the
number of topics from all domains) in a cluster.
Test Settings: We use two test settings as below:
</bodyText>
<listItem confidence="0.992962">
1. (Sections 6.2, 6.3 and 6.4) Test on the same cor-
pora as those used in learning the prior knowl-
edge. This is meaningful as the learning phrase
is automatic and unsupervised (Figure 1). We
call this self-learning-and-improvement.
2. (Section 6.5) Test on new/unseen domain cor-
pora after knowledge learning.
</listItem>
<subsectionHeader confidence="0.997514">
6.2 Topic Coherence
</subsectionHeader>
<bodyText confidence="0.999659555555556">
This sub-section evaluates the topics/aspects gen-
erated by each model based on Topic Coher-
ence (Mimno et al., 2011) in test setting 1. Tra-
ditionally, topic models have been evaluated us-
ing perplexity. However, perplexity on the held-
out test set does not reflect the semantic coher-
ence of topics and may be contrary to human judg-
ments (Chang et al., 2009). Instead, the met-
ric Topic Coherence has been shown in (Mimno
</bodyText>
<figure confidence="0.781394125">
-1430
-1450
-1470
-1490
-1510
0 1 2 3 4 5 6
AKL GK-LDA
MC-LDA LDA
</figure>
<figureCaption confidence="0.931931333333333">
Figure 3: Average Topic Coherence of each model
at different learning iterations (Iteration 0 is equiv-
alent to LDA).
</figureCaption>
<bodyText confidence="0.999627153846154">
et al., 2011) to correlate well with human judg-
ments. Recently, it has become a standard prac-
tice to use Topic Coherence for evaluation of topic
models (Arora et al., 2013). A higher Topic Coher-
ence value indicates a better topic interpretability,
i.e., semantically more coherent topics.
Figure 3 shows the average Topic Coherence of
each model using knowledge learned at different
learning iterations (Figure 1). For MC-LDA or
GK-LDA, this is done by replacing AKL in lines
7 and 19 of Figure 1 with MC-LDA or GK-LDA.
Each value is the average over all 36 domains.
From Figure 3, we can observe the followings:
</bodyText>
<listItem confidence="0.961703857142857">
1. AKL performs the best with the highest Topic
Coherence values at all iterations. It is actu-
ally the best in all 36 domains. These show that
AKL finds more interpretable topics than the
baselines. Its values stabilize after iteration 3.
2. Both GK-LDA and MC-LDA perform slightly
better than LDA in iterations 1 and 2. MC-
</listItem>
<bodyText confidence="0.967176894736842">
LDA does not handle wrong knowledge. This
shows that the mined knowledge is of good
quality. Although GK-LDA uses large word
probability differences under a topic to detect
wrong lexical knowledge, it is not as effective
as AKL. The reason is that as the lexical knowl-
edge is from general dictionaries rather than
mined from relevant domain data, the words
in a wrong piece of knowledge usually have a
very large probability difference under a topic.
However, our knowledge is mined from top
words in related topics including topics from
the current domain. The words in a piece of in-
correct (or correct) knowledge often have sim-
ilar probabilities under a topic. The proposed
dynamic knowledge adjusting mechanism in
AKL is superior.
Paired t-test shows that AKL outperforms all
baselines significantly (p &lt; 0.0001).
</bodyText>
<subsectionHeader confidence="0.996639">
6.3 User Evaluation
</subsectionHeader>
<bodyText confidence="0.99998775">
As our objective is to discover more coherent as-
pects, we recruited two human judges. Here we
also use the test setting 1. Each topic is annotated
as coherent if the judge feels that most of its top
</bodyText>
<page confidence="0.995974">
353
</page>
<figure confidence="0.9950395625">
Precision @ 5
Precision @ 10
Camera Computer Headphone GPS
Camera Computer Headphone GPS
AKL GK-LDA MC-LDA LDA
AKL GK-LDA MC-LDA LDA
0.7
0.6
1.0
0.9
0.8
0.7
0.6
1.0
0.9
0.8
</figure>
<figureCaption confidence="0.902205">
Figure 4: Average Precision@5 (Left) and Precision@10 (Right) of coherent topics from four models
in each domain. (Headphone has a lot of overlapping topics in other domains while GPS has little.)
</figureCaption>
<bodyText confidence="0.999849820895523">
terms coherently represent a real-world product
aspect; otherwise incoherent. For a coherent topic,
each top term is annotated as correct if it reflects
the aspect represented by the topic; otherwise in-
correct. We labeled the topics of each model
at learning iteration 1 where the same pieces of
knowledge (extracted from LDA topics at learn-
ing iteration 0) are provided to each model. After
learning iteration 1, the gap between AKL and the
baseline models tends to widen. To be consistent,
the results later in Sections 6.4 and 6.5 also show
each model at learning iteration 1. We also notice
that after a few learning iterations, the topics from
AKL model tend to have some resemblance across
domains. We found that AKL with 2 learning it-
erations achieved the best topics. Note that LDA
cannot use any prior knowledge.
We manually labeled results from four domains,
i.e., Camera, Computer, Headphone, and GPS. We
chose Headphone as it has a lot of overlapping
of topics with other domains because many elec-
tronic products use headphone. GPS was cho-
sen because it does not have much topic overlap-
ping with other domains as its aspects are mostly
about Navigation and Maps. Domains Camera and
Computer lay in between. We want to see how
domain overlapping influences the performance of
AKL. Cohen’s Kappa scores for annotator agree-
ment are 0.918 (for topics) and 0.872 (for terms).
To measure the results, we compute
Precision@n (or p@n) based on the anno-
tations, which was also used in (Chen et al.,
2013b, Mukherjee and Liu, 2012).
Figure 4 shows the precision@n results for
n = 5 and 10. We can see that AKL makes im-
provements in all 4 domains. The improvement
varies in domains with the most increase in Head-
phone and the least in GPS as Headphone overlaps
more with other domains than GPS. Note that if a
domain shares aspects with many other domains,
its model should benefit more; otherwise, it is rea-
sonable to expect lesser improvements. For the
baselines, GK-LDA and MC-LDA perform simi-
larly to LDA with minor variations, all of which
are inferior to AKL. AKL’s improvements over
other models are statistically significant based on
paired t-test (p &lt; 0.002).
In terms of the number of coherent topics, AKL
discovers one more coherent topic than LDA in
Computer and one more coherent topic than GK-
LDA and MC-LDA in Headphone. For the other
domains, the numbers of coherent topics are the
same for all models.
Table 2 shows an example aspect (battery) and
its top 10 terms produced by AKL and LDA for
each domain to give a flavor of the kind of im-
provements made by AKL. The results for GK-
LDA and MC-LDA are about the same as LDA
(see also Figure 4). Table 2 focuses on the as-
pects generated by AKL and LDA. From Table 2,
we can see that AKL discovers more correct and
meaningful aspect terms at the top. Note that
those terms marked in red and italicized are er-
rors. Apart from Table 2, many aspects are dra-
matically improved by AKL, including some com-
monly shared aspects such as Price, Screen, and
Customer Service.
</bodyText>
<subsectionHeader confidence="0.999377">
6.4 Sensitivity to Clustering Parameters
</subsectionHeader>
<bodyText confidence="0.99564975">
This sub-section investigates the sensitivity of the
clustering parameters of AKL (again in test setting
1). The top sub-figure in Figure 5 shows the aver-
age Topic Coherence values versus the top k terms
per topic used in topic clustering (Section 4.1).
The number of clusters is set to the number of
domains (see below). We can observe that using
k = 15 top terms gives the highest value. This is
intuitive as too few (or too many) top terms may
generate insufficient (or noisy) knowledge.
The bottom sub-figure in Figure 5 shows the
average Topic Coherence given different number
</bodyText>
<page confidence="0.996316">
354
</page>
<table confidence="0.99867425">
Camera Computer Headphone GPS
AKL LDA AKL LDA AKL LDA AKL LDA
battery battery battery battery hour long battery trip
life card hour cable long battery hour battery
hour memory life speaker battery hour long hour
long life long dvi life comfortable model mile
charge usb speaker sound charge easy life long
extra hour sound hour amp uncomfortable charge life
minute minute charge connection uncomfortable headset trip destination
charger sd dvi life comfortable life purchase phone
short extra tv hdmus period money older charge
aa device hdmus tv output hard compass mode
</table>
<tableCaption confidence="0.999134">
Table 2: Example aspect Battery from AKL and LDA in each domain. Errors are italicized in red.
</tableCaption>
<figure confidence="0.995250428571429">
-1430
-1450
-1470
-1490
-1510
5 10 15 20 25 30
#Top Terms for Clustering
-1430
-1450
-1470
-1490
-1510
20 30 40 50 60 70
#Clusters
</figure>
<figureCaption confidence="0.9945385">
Figure 5: Average topic coherence of AKL versus
#top k terms (Top) and #clusters (Bottom).
</figureCaption>
<table confidence="0.697359571428572">
-1450
Topic Coherence
-1460
-1470
-1480
-1490
AKL GK-LDA MC-LDA LDA
</table>
<figureCaption confidence="0.98384">
Figure 6: Average topic coherence of each model
tested on new/unseen domain.
</figureCaption>
<bodyText confidence="0.998989222222222">
of clusters. We fix the number of top terms per
topic to 15 as it yields the best result (see the top
sub-figure in Figure 5). We can see that the per-
formance is not very sensitive to the number of
clusters. The model performs similarly for 30 to
50 clusters, with lower Topic Coherence for less
than 30 or more than 50 clusters. The significance
test indicates that using 30, 40, and 50 clusters,
AKL achieved significant improvements over all
baseline models (p &lt; 0.0001). With more do-
mains, we should expect a larger number of clus-
ters. However, it is difficult to obtain the optimal
number of clusters. Thus, we empirically set the
number of clusters to the number of domains in
our experiments. Note that the number of clus-
ters (C) is expected to be larger than the number
of topics in one domain (T) because C is for all
domains while T is for one particular domain.
</bodyText>
<subsectionHeader confidence="0.999711">
6.5 Test on New Domains
</subsectionHeader>
<bodyText confidence="0.999990928571429">
We now evaluate AKL in test setting 2, i.e., the au-
tomatically extracted knowledge K (Figure 1) is
applied in new/unseen domains other than those in
domains DL used in knowledge learning. The aim
is to see how K can help modeling in an unseen
domain. In this set of experiments, each domain
is tested by using the learned knowledge from the
rest 35 domains. Figure 6 shows the average Topic
Coherence of each model. The values are also av-
eraged over the 36 tested domains. We can see that
AKL achieves the highest Topic Coherence value
while LDA has the lowest. The improvements of
AKL over all baseline models are significant with
p &lt; 0.0001.
</bodyText>
<sectionHeader confidence="0.999459" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999920833333333">
This paper proposed an advanced aspect extraction
framework which can learn knowledge automati-
cally from a large number of review corpora and
exploit the learned knowledge in extracting more
coherent aspects. It first proposed a technique to
learn knowledge automatically by clustering and
FPM. Then a new topic model with an advanced
inference mechanism was proposed to exploit the
learned knowledge in a fault-tolerant manner. Ex-
perimental results using review corpora from 36
domains showed that the proposed method outper-
forms state-of-the-art methods significantly.
</bodyText>
<sectionHeader confidence="0.998893" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.89845">
This work was supported in part by a grant from
National Science Foundation (NSF) under grant
no. IIS-1111092.
</bodyText>
<figure confidence="0.979184">
Topic Coherence
Topic Coherence
</figure>
<page confidence="0.994039">
355
</page>
<sectionHeader confidence="0.996006" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999841557692308">
David Andrzejewski, Xiaojin Zhu, and Mark Craven.
2009. Incorporating domain knowledge into topic
modeling via Dirichlet Forest priors. In Proceedings
of ICML, pages 25–32.
David Andrzejewski, Xiaojin Zhu, Mark Craven, and
Benjamin Recht. 2011. A framework for incorpo-
rating general domain knowledge into latent Dirich-
let allocation using first-order logic. In Proceedings
of IJCAI, pages 1171–1177.
Sanjeev Arora, Rong Ge, Yonatan Halpern, David
Mimno, Ankur Moitra, David Sontag, Yichen Wu,
and Michael Zhu. 2013. A Practical Algorithm for
Topic Modeling with Provable Guarantees. In Pro-
ceedings of ICML, pages 280–288.
David M. Blei and Jon D McAuliffe. 2007. Supervised
Topic Models. In Proceedings of NIPS, pages 121–
128.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent Dirichlet Allocation. Journal of Ma-
chine Learning Research, 3:993–1022.
S R K Branavan, Harr Chen, Jacob Eisenstein, and
Regina Barzilay. 2008. Learning Document-Level
Semantic Properties from Free-Text Annotations. In
Proceedings of ACL, pages 263–271.
Samuel Brody and Noemie Elhadad. 2010. An unsu-
pervised aspect-sentiment model for online reviews.
In Proceedings of NAACL, pages 804–812.
Giuseppe Carenini, Raymond T Ng, and Ed Zwart.
2005. Extracting knowledge from evaluative text.
In Proceedings of K-CAP, pages 11–18.
Jonathan Chang, Jordan Boyd-Graber, Wang Chong,
Sean Gerrish, and David Blei, M. 2009. Reading
Tea Leaves: How Humans Interpret Topic Models.
In Proceedings of NIPS, pages 288–296.
Zhiyuan Chen, Arjun Mukherjee, Bing Liu, Meichun
Hsu, Malu Castellanos, and Riddhiman Ghosh.
2013a. Discovering Coherent Topics Using General
Knowledge. In Proceedings of CIKM, pages 209–
218.
Zhiyuan Chen, Arjun Mukherjee, Bing Liu, Meichun
Hsu, Malu Castellanos, and Riddhiman Ghosh.
2013b. Exploiting Domain Knowledge in Aspect
Extraction. In Proceedings of EMNLP, pages 1655–
1667.
Zhiyuan Chen, Arjun Mukherjee, Bing Liu, Meichun
Hsu, Malu Castellanos, and Riddhiman Ghosh.
2013c. Leveraging Multi-Domain Prior Knowledge
in Topic Models. In Proceedings of IJCAI, pages
2071–2077.
Yejin Choi and Claire Cardie. 2010. Hierarchical Se-
quential Learning for Extracting Opinions and their
Attributes. In Proceedings of ACL, pages 269–274.
Jacob Eisenstein, Brendan O’Connor, Noah A Smith,
and Eric P Xing. 2010. A Latent Variable Model
for Geographic Lexical Variation. In Proceedings of
EMNLP, pages 1277–1287.
Lei Fang and Minlie Huang. 2012. Fine Granular As-
pect Analysis using Latent Structural Models. In
Proceedings ofACL, pages 333–337.
Honglei Guo, Huijia Zhu, Zhili Guo, Xiaoxun Zhang,
and Zhong Su. 2009. Product feature categoriza-
tion with multilevel latent semantic association. In
Proceedings of CIKM, pages 1087–1096.
Jiawei Han, Hong Cheng, Dong Xin, and Xifeng Yan.
2007. Frequent pattern mining: current status and
future directions. Data Mining and Knowledge Dis-
covery, 15(1):55–86.
Yulan He, Chenghua Lin, and Harith Alani. 2011. Au-
tomatically Extracting Polarity-Bearing Topics for
Cross-Domain Sentiment Classification. In Pro-
ceedings of ACL, pages 123–131.
Thomas Hofmann. 1999. Probabilistic Latent Seman-
tic Analysis. In Proceedings of UAI, pages 289–296.
Minqing Hu and Bing Liu. 2004. Mining and Summa-
rizing Customer Reviews. In Proceedings of KDD,
pages 168–177.
Yuening Hu, Jordan Boyd-Graber, and Brianna Sati-
noff. 2011. Interactive Topic Modeling. In Pro-
ceedings of ACL, pages 248–257.
Jagadeesh Jagarlamudi, Hal Daum´e III, and Raghaven-
dra Udupa. 2012. Incorporating Lexical Priors into
Topic Models. In Proceedings of EACL, pages 204–
213.
Niklas Jakob and Iryna Gurevych. 2010. Extracting
Opinion Targets in a Single- and Cross-Domain Set-
ting with Conditional Random Fields. In Proceed-
ings of EMNLP, pages 1035–1045.
Yohan Jo and Alice H. Oh. 2011. Aspect and senti-
ment unification model for online review analysis.
In Proceedings of WSDM, pages 815–824.
Jeon-hyung Kang, Jun Ma, and Yan Liu. 2012. Trans-
fer Topic Modeling with Ease and Scalability. In
Proceedings of SDM, pages 564–575.
L Kaufman and P J Rousseeuw. 1990. Finding groups
in data: an introduction to cluster analysis. John
Wiley and Sons.
Suin Kim, Jianwen Zhang, Zheng Chen, Alice Oh, and
Shixia Liu. 2013. A Hierarchical Aspect-Sentiment
Model for Online Reviews. In Proceedings ofAAAI,
pages 526–533.
Nozomi Kobayashi, Kentaro Inui, and Yuji Matsumoto.
2007. Extracting Aspect-Evaluation and Aspect-of
Relations in Opinion Mining. In Proceedings of
EMNLP, pages 1065–1074.
</reference>
<page confidence="0.99411">
356
</page>
<reference confidence="0.999552214953271">
Lun-Wei Ku, Yu-Ting Liang, and Hsin-Hsi Chen.
2006. Opinion Extraction, Summarization and
Tracking in News and Blog Corpora. In Proceed-
ings of AAAI-CAAW, pages 100–107.
Angeliki Lazaridou, Ivan Titov, and Caroline
Sporleder. 2013. A Bayesian Model for Joint
Unsupervised Induction of Sentiment, Aspect and
Discourse Representations. In Proceedings of ACL,
pages 1630–1639.
Fangtao Li, Chao Han, Minlie Huang, Xiaoyan Zhu,
Yingju Xia, Shu Zhang, and Hao Yu. 2010.
Structure-Aware Review Mining and Summariza-
tion. In Proceedings of COLING, pages 653–661.
Peng Li, Yinglin Wang, Wei Gao, and Jing Jiang. 2011.
Generating Aspect-oriented Multi-Document Sum-
marization with Event-aspect model. In Proceed-
ings of EMNLP, pages 1137–1146.
Chenghua Lin and Yulan He. 2009. Joint senti-
ment/topic model for sentiment analysis. In Pro-
ceedings of CIKM, pages 375–384.
Kang Liu, Liheng Xu, and Jun Zhao. 2013. Syntactic
Patterns versus Word Alignment: Extracting Opin-
ion Targets from Online Reviews. In Proceedings of
ACL, pages 1754–1763.
Bing Liu. 2012. Sentiment Analysis and Opinion Min-
ing. Morgan &amp; Claypool Publishers.
Yue Lu and Chengxiang Zhai. 2008. Opinion inte-
gration through semi-supervised topic modeling. In
Proceedings of WWW, pages 121–130.
Yue Lu, ChengXiang Zhai, and Neel Sundaresan.
2009. Rated aspect summarization of short com-
ments. In Proceedings of WWW, pages 131–140.
Bin Lu, Myle Ott, Claire Cardie, and Benjamin K Tsou.
2011. Multi-aspect Sentiment Analysis with Topic
Models. In Proceedings of ICDM Workshops, pages
81–88.
Yue Lu, Hongning Wang, ChengXiang Zhai, and Dan
Roth. 2012. Unsupervised discovery of opposing
opinion networks from forum discussions. In Pro-
ceedings of CIKM, pages 1642–1646.
Hosam Mahmoud. 2008. Polya Urn Models. Chap-
man &amp; Hall/CRC Texts in Statistical Science.
Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su,
and ChengXiang Zhai. 2007. Topic sentiment mix-
ture: modeling facets and opinions in weblogs. In
Proceedings of WWW, pages 171–180.
David Mimno, Hanna M. Wallach, Edmund Talley,
Miriam Leenders, and Andrew McCallum. 2011.
Optimizing semantic coherence in topic models. In
Proceedings of EMNLP, pages 262–272.
Samaneh Moghaddam and Martin Ester. 2013. The
FLDA Model for Aspect-based Opinion Mining:
Addressing the Cold Start Problem. In Proceedings
of WWW, pages 909–918.
Arjun Mukherjee and Bing Liu. 2012. Aspect Extrac-
tion through Semi-Supervised Modeling. In Pro-
ceedings of ACL, pages 339–348.
Sinno Jialin Pan and Qiang Yang. 2010. A Survey on
Transfer Learning. IEEE Trans. Knowl. Data Eng.,
22(10):1345–1359.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and Trends in In-
formation Retrieval, 2(1-2):1–135.
James Petterson, Alex Smola, Tib´erio Caetano, Wray
Buntine, and Shravan Narayanamurthy. 2010. Word
Features for Latent Dirichlet Allocation. In Pro-
ceedings of NIPS, pages 1921–1929.
AM Popescu and Oren Etzioni. 2005. Extracting prod-
uct features and opinions from reviews. In Proceed-
ings of HLT, pages 339–346.
Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.
2011. Opinion Word Expansion and Target Extrac-
tion through Double Propagation. Computational
Linguistics, 37(1):9–27.
Daniel Ramage, David Hall, Ramesh Nallapati, and
Christopher D. Manning. 2009. Labeled LDA: a su-
pervised topic model for credit attribution in multi-
labeled corpora. In Proceedings of EMNLP, pages
248–256.
Michal Rosen-Zvi, Chaitanya Chemudugunta, Thomas
Griffiths, Padhraic Smyth, and Mark Steyvers.
2010. Learning author-topic models from text cor-
pora. ACM Transactions on Information Systems,
28(1):1–38.
Christina Sauper and Regina Barzilay. 2013. Auto-
matic Aggregation by Joint Modeling of Aspects and
Values. J. Artif. Intell. Res. (JAIR), 46:89–127.
Swapna Somasundaran and J Wiebe. 2009. Recog-
nizing stances in online debates. In Proceedings of
ACL, pages 226–234.
Ivan Titov and Ryan McDonald. 2008. A joint model
of text and aspect ratings for sentiment summariza-
tion. In Proceedings of ACL, pages 308–316.
Hongning Wang, Yue Lu, and Chengxiang Zhai. 2010.
Latent aspect rating analysis on review text data: a
rating regression approach. In Proceedings of KDD,
pages 783–792.
Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu.
2009. Phrase dependency parsing for opinion min-
ing. In Proceedings of EMNLP, pages 1533–1541.
Liheng Xu, Kang Liu, Siwei Lai, Yubo Chen, and Jun
Zhao. 2013. Mining Opinion Words and Opinion
Targets in a Two-Stage Framework. In Proceedings
ofACL, pages 1764–1773.
GR Xue, Wenyuan Dai, Q Yang, and Y Yu. 2008.
Topic-bridged PLSA for cross-domain text classifi-
cation. In Proceedings of SIGIR, pages 627–634.
</reference>
<page confidence="0.97716">
357
</page>
<reference confidence="0.999757866666667">
Bishan Yang and Claire Cardie. 2013. Joint Inference
for Fine-grained Opinion Extraction. In Proceed-
ings of ACL, pages 1640–1649.
Shuang Hong Yang, Steven P. Crain, and Hongyuan
Zha. 2011. Bridging the language gap: Topic adap-
tation for documents with different technicality. In
Proceedings of AISTATS, pages 823–831.
Jianxing Yu, Zheng-Jun Zha, Meng Wang, and Tat-
Seng Chua. 2011. Aspect Ranking: Identifying
Important Product Aspects from Online Consumer
Reviews. In Proceedings ofACL, pages 1496–1505.
Zhongwu Zhai, Bing Liu, Hua Xu, and Peifa Jia. 2011.
Constrained LDA for grouping product features in
opinion mining. In Proceedings of PAKDD, pages
448–459.
Wayne Xin Zhao, Jing Jiang, Hongfei Yan, and Xiaom-
ing Li. 2010. Jointly Modeling Aspects and Opin-
ions with a MaxEnt-LDA Hybrid. In Proceedings of
EMNLP, pages 56–65.
Yanyan Zhao, Bing Qin, and Ting Liu. 2012. Col-
location polarity disambiguation using web-based
pseudo contexts. In Proceedings of EMNLP-
CoNLL, pages 160–170.
Xinjie Zhou, Xiaojun Wan, and Jianguo Xiao. 2013.
Collective Opinion Target Extraction in Chinese Mi-
croblogs. In Proceedings of EMNLP, pages 1840–
1850.
Li Zhuang, Feng Jing, and Xiao-Yan Zhu. 2006.
Movie review mining and summarization. In Pro-
ceedings of CIKM, pages 43–50.
</reference>
<page confidence="0.997929">
358
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.826584">
<title confidence="0.999879">Aspect Extraction with Automated Prior Knowledge Learning</title>
<author confidence="0.998619">Zhiyuan Chen Arjun Mukherjee Bing</author>
<affiliation confidence="0.99351">Department of Computer University of Illinois at</affiliation>
<address confidence="0.886154">Chicago, IL 60607,</address>
<abstract confidence="0.996109307692308">Aspect extraction is an important task in sentiment analysis. Topic modeling is a popular method for the task. However, unsupervised topic models often generate incoherent aspects. To address the issue, several knowledge-based models have been proposed to incorporate prior knowledge provided by the user to guide modeling. In this paper, we take a major step forward and show that in the big data era, without any user input, it is possible to learn prior knowledge automatically from a large amount of review data available on the Web. Such knowledge can then be used by a topic model to discover more coherent aspects. There are two key challenges: (1) learning quality knowledge from reviews of diverse domains, and (2) making the model fault-tolerant to handle possibly wrong knowledge. A novel approach is proposed to solve these problems. Experimental results using reviews from 36 domains show that the proposed approach achieves significant improvements over state-of-the-art baselines.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Andrzejewski</author>
<author>Xiaojin Zhu</author>
<author>Mark Craven</author>
</authors>
<title>Incorporating domain knowledge into topic modeling via Dirichlet Forest priors.</title>
<date>2009</date>
<booktitle>In Proceedings of ICML,</booktitle>
<pages>25--32</pages>
<contexts>
<context position="2568" citStr="Andrzejewski et al., 2009" startWordPosition="396" endWordPosition="400"> 2). Traditional topic models such as LDA (Blei et al., 2003) and pLSA (Hofmann, 1999) are unsupervised methods for extracting latent topics in text documents. Topics are aspects in our task. Each aspect (or topic) is a distribution over (aspect) terms. However, researchers have shown that fully unsupervised models often produce incoherent topics because the objective functions of topic models do not always correlate well with human judgments (Chang et al., 2009). To tackle the problem, several semi-supervised topic models, also called knowledge-based topic models, have been proposed. DF-LDA (Andrzejewski et al., 2009) can incorporate two forms of prior knowledge from the user: must-links and cannot-links. A must-link implies that two terms (or words) should belong to the same topic whereas a cannot-link indicates that two terms should not be in the same topic. In a similar but more generic vein, must-sets and cannot-sets are used in MC-LDA (Chen et al., 2013b). Other related works include (Andrzejewski et al., 2011, Chen et al., 2013a, Chen et al., 2013c, Mukherjee and Liu, 2012, Hu et al., 2011, Jagarlamudi et al., 2012, Lu et al., 2011, Petterson et al., 2010). They all allow prior knowledge to be specif</context>
</contexts>
<marker>Andrzejewski, Zhu, Craven, 2009</marker>
<rawString>David Andrzejewski, Xiaojin Zhu, and Mark Craven. 2009. Incorporating domain knowledge into topic modeling via Dirichlet Forest priors. In Proceedings of ICML, pages 25–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Andrzejewski</author>
<author>Xiaojin Zhu</author>
<author>Mark Craven</author>
<author>Benjamin Recht</author>
</authors>
<title>A framework for incorporating general domain knowledge into latent Dirichlet allocation using first-order logic.</title>
<date>2011</date>
<booktitle>In Proceedings of IJCAI,</booktitle>
<pages>1171--1177</pages>
<contexts>
<context position="2973" citStr="Andrzejewski et al., 2011" startWordPosition="465" endWordPosition="468">ways correlate well with human judgments (Chang et al., 2009). To tackle the problem, several semi-supervised topic models, also called knowledge-based topic models, have been proposed. DF-LDA (Andrzejewski et al., 2009) can incorporate two forms of prior knowledge from the user: must-links and cannot-links. A must-link implies that two terms (or words) should belong to the same topic whereas a cannot-link indicates that two terms should not be in the same topic. In a similar but more generic vein, must-sets and cannot-sets are used in MC-LDA (Chen et al., 2013b). Other related works include (Andrzejewski et al., 2011, Chen et al., 2013a, Chen et al., 2013c, Mukherjee and Liu, 2012, Hu et al., 2011, Jagarlamudi et al., 2012, Lu et al., 2011, Petterson et al., 2010). They all allow prior knowledge to be specified by the user to guide the modeling process. In this paper, we take a major step further. We mine the prior knowledge directly from a large amount of relevant data without any user intervention, and thus make this approach fully automatic. We hypothesize that it is possible to learn quality prior knowledge from the big data (of reviews) available on the Web. The intuition is that although every domai</context>
</contexts>
<marker>Andrzejewski, Zhu, Craven, Recht, 2011</marker>
<rawString>David Andrzejewski, Xiaojin Zhu, Mark Craven, and Benjamin Recht. 2011. A framework for incorporating general domain knowledge into latent Dirichlet allocation using first-order logic. In Proceedings of IJCAI, pages 1171–1177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanjeev Arora</author>
<author>Rong Ge</author>
<author>Yonatan Halpern</author>
<author>David Mimno</author>
<author>Ankur Moitra</author>
<author>David Sontag</author>
<author>Yichen Wu</author>
<author>Michael Zhu</author>
</authors>
<title>A Practical Algorithm for Topic Modeling with Provable Guarantees.</title>
<date>2013</date>
<booktitle>In Proceedings of ICML,</booktitle>
<pages>280--288</pages>
<contexts>
<context position="27790" citStr="Arora et al., 2013" startWordPosition="4789" endWordPosition="4792">ic models have been evaluated using perplexity. However, perplexity on the heldout test set does not reflect the semantic coherence of topics and may be contrary to human judgments (Chang et al., 2009). Instead, the metric Topic Coherence has been shown in (Mimno -1430 -1450 -1470 -1490 -1510 0 1 2 3 4 5 6 AKL GK-LDA MC-LDA LDA Figure 3: Average Topic Coherence of each model at different learning iterations (Iteration 0 is equivalent to LDA). et al., 2011) to correlate well with human judgments. Recently, it has become a standard practice to use Topic Coherence for evaluation of topic models (Arora et al., 2013). A higher Topic Coherence value indicates a better topic interpretability, i.e., semantically more coherent topics. Figure 3 shows the average Topic Coherence of each model using knowledge learned at different learning iterations (Figure 1). For MC-LDA or GK-LDA, this is done by replacing AKL in lines 7 and 19 of Figure 1 with MC-LDA or GK-LDA. Each value is the average over all 36 domains. From Figure 3, we can observe the followings: 1. AKL performs the best with the highest Topic Coherence values at all iterations. It is actually the best in all 36 domains. These show that AKL finds more i</context>
</contexts>
<marker>Arora, Ge, Halpern, Mimno, Moitra, Sontag, Wu, Zhu, 2013</marker>
<rawString>Sanjeev Arora, Rong Ge, Yonatan Halpern, David Mimno, Ankur Moitra, David Sontag, Yichen Wu, and Michael Zhu. 2013. A Practical Algorithm for Topic Modeling with Provable Guarantees. In Proceedings of ICML, pages 280–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Jon D McAuliffe</author>
</authors>
<title>Supervised Topic Models.</title>
<date>2007</date>
<booktitle>In Proceedings of NIPS,</booktitle>
<pages>121--128</pages>
<contexts>
<context position="8106" citStr="Blei and McAuliffe, 2007" startWordPosition="1321" endWordPosition="1324">2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). Geographical region knowledge has also been considered in topic models (Eisenstein et al., 2010). All of these models assume that the prior knowledge is correct. GK-LDA (Chen et al., 2013a) is the only knowledge-based topic model that deals with wrong lexical knowledge to some extent. As we will see in Section 6, AKL outperformed GKLDA significantly due to AKL’s more effective error handling mechanism. Furthermore, GK-LDA does not learn any prior knowledge. Our work is also related to transfer learning to some extent. Topic models have been used to help 348 Input: Corpo</context>
</contexts>
<marker>Blei, McAuliffe, 2007</marker>
<rawString>David M. Blei and Jon D McAuliffe. 2007. Supervised Topic Models. In Proceedings of NIPS, pages 121– 128.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent Dirichlet Allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="2003" citStr="Blei et al., 2003" startWordPosition="311" endWordPosition="314">Liu, 2004, Liu, 2012). For example, in “The voice is not clear,” the aspect term is “voice.” Aspect extraction has two subtasks: aspect term extraction and aspect term resolution. Aspect term resolution groups extracted synonymous aspect terms together. For example, “voice” and “sound” should be grouped together as they refer to the same aspect of phones. Recently, topic models have been extensively applied to aspect extraction because they can perform both subtasks at the same time while other existing methods all need two separate steps (see Section 2). Traditional topic models such as LDA (Blei et al., 2003) and pLSA (Hofmann, 1999) are unsupervised methods for extracting latent topics in text documents. Topics are aspects in our task. Each aspect (or topic) is a distribution over (aspect) terms. However, researchers have shown that fully unsupervised models often produce incoherent topics because the objective functions of topic models do not always correlate well with human judgments (Chang et al., 2009). To tackle the problem, several semi-supervised topic models, also called knowledge-based topic models, have been proposed. DF-LDA (Andrzejewski et al., 2009) can incorporate two forms of prior</context>
<context position="24204" citStr="Blei et al., 2003" startWordPosition="4160" endWordPosition="4163">art from its knowledge clusters, we also add a singleton cluster for w, i.e., a cluster with one pattern {w, w} only. When no knowledge cluster is applicable, this singleton cluster is used. As a singleton cluster does not contain any knowledge information but only the word itself, Equations 1 and 2 cannot be computed. For the values of singleton clusters for these two equations, we assign them as the averages of those values of all nonsingleton knowledge clusters. 6 Experiments This section evaluates and compares the proposed AKL model with three baseline models LDA, MC-LDA, and GK-LDA. LDA (Blei et al., 2003) is the most popular unsupervised topic model. MC-LDA (Chen et al., 2013b) is a recent knowledge-based model for aspect extraction. GK-LDA (Chen et al., 2013a) handles wrong knowledge by setting prior weights using the ratio of word probabilities. Our automatically extracted knowledge is provided to these models. Note that cannot-set of MC-LDA is not used in AKL. 6.1 Experimental Settings Dataset. We created a large dataset containing reviews from 36 product domains or types from Amazon.com. The product domain names are listed in Table 1. Each domain contains 1, 000 reviews. This gives us 36 d</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent Dirichlet Allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R K Branavan</author>
<author>Harr Chen</author>
<author>Jacob Eisenstein</author>
<author>Regina Barzilay</author>
</authors>
<title>Learning Document-Level Semantic Properties from Free-Text Annotations.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>263--271</pages>
<contexts>
<context position="7486" citStr="Branavan et al., 2008" startWordPosition="1211" endWordPosition="1214">atterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei</context>
</contexts>
<marker>Branavan, Chen, Eisenstein, Barzilay, 2008</marker>
<rawString>S R K Branavan, Harr Chen, Jacob Eisenstein, and Regina Barzilay. 2008. Learning Document-Level Semantic Properties from Free-Text Annotations. In Proceedings of ACL, pages 263–271.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel Brody</author>
<author>Noemie Elhadad</author>
</authors>
<title>An unsupervised aspect-sentiment model for online reviews.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<pages>804--812</pages>
<contexts>
<context position="7511" citStr="Brody and Elhadad, 2010" startWordPosition="1215" endWordPosition="1218">04, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ram</context>
</contexts>
<marker>Brody, Elhadad, 2010</marker>
<rawString>Samuel Brody and Noemie Elhadad. 2010. An unsupervised aspect-sentiment model for online reviews. In Proceedings of NAACL, pages 804–812.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giuseppe Carenini</author>
<author>Raymond T Ng</author>
<author>Ed Zwart</author>
</authors>
<title>Extracting knowledge from evaluative text.</title>
<date>2005</date>
<booktitle>In Proceedings of K-CAP,</booktitle>
<pages>11--18</pages>
<contexts>
<context position="7271" citStr="Carenini et al., 2005" startWordPosition="1176" endWordPosition="1179">, e.g., using supervised sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al</context>
</contexts>
<marker>Carenini, Ng, Zwart, 2005</marker>
<rawString>Giuseppe Carenini, Raymond T Ng, and Ed Zwart. 2005. Extracting knowledge from evaluative text. In Proceedings of K-CAP, pages 11–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Chang</author>
<author>Jordan Boyd-Graber</author>
<author>Wang Chong</author>
<author>Sean Gerrish</author>
<author>David Blei</author>
<author>M</author>
</authors>
<title>Reading Tea Leaves: How Humans Interpret Topic Models.</title>
<date>2009</date>
<booktitle>In Proceedings of NIPS,</booktitle>
<pages>288--296</pages>
<contexts>
<context position="2409" citStr="Chang et al., 2009" startWordPosition="375" endWordPosition="378">plied to aspect extraction because they can perform both subtasks at the same time while other existing methods all need two separate steps (see Section 2). Traditional topic models such as LDA (Blei et al., 2003) and pLSA (Hofmann, 1999) are unsupervised methods for extracting latent topics in text documents. Topics are aspects in our task. Each aspect (or topic) is a distribution over (aspect) terms. However, researchers have shown that fully unsupervised models often produce incoherent topics because the objective functions of topic models do not always correlate well with human judgments (Chang et al., 2009). To tackle the problem, several semi-supervised topic models, also called knowledge-based topic models, have been proposed. DF-LDA (Andrzejewski et al., 2009) can incorporate two forms of prior knowledge from the user: must-links and cannot-links. A must-link implies that two terms (or words) should belong to the same topic whereas a cannot-link indicates that two terms should not be in the same topic. In a similar but more generic vein, must-sets and cannot-sets are used in MC-LDA (Chen et al., 2013b). Other related works include (Andrzejewski et al., 2011, Chen et al., 2013a, Chen et al., 2</context>
<context position="27372" citStr="Chang et al., 2009" startWordPosition="4712" endWordPosition="4715">e used in learning the prior knowledge. This is meaningful as the learning phrase is automatic and unsupervised (Figure 1). We call this self-learning-and-improvement. 2. (Section 6.5) Test on new/unseen domain corpora after knowledge learning. 6.2 Topic Coherence This sub-section evaluates the topics/aspects generated by each model based on Topic Coherence (Mimno et al., 2011) in test setting 1. Traditionally, topic models have been evaluated using perplexity. However, perplexity on the heldout test set does not reflect the semantic coherence of topics and may be contrary to human judgments (Chang et al., 2009). Instead, the metric Topic Coherence has been shown in (Mimno -1430 -1450 -1470 -1490 -1510 0 1 2 3 4 5 6 AKL GK-LDA MC-LDA LDA Figure 3: Average Topic Coherence of each model at different learning iterations (Iteration 0 is equivalent to LDA). et al., 2011) to correlate well with human judgments. Recently, it has become a standard practice to use Topic Coherence for evaluation of topic models (Arora et al., 2013). A higher Topic Coherence value indicates a better topic interpretability, i.e., semantically more coherent topics. Figure 3 shows the average Topic Coherence of each model using kn</context>
</contexts>
<marker>Chang, Boyd-Graber, Chong, Gerrish, Blei, M, 2009</marker>
<rawString>Jonathan Chang, Jordan Boyd-Graber, Wang Chong, Sean Gerrish, and David Blei, M. 2009. Reading Tea Leaves: How Humans Interpret Topic Models. In Proceedings of NIPS, pages 288–296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiyuan Chen</author>
<author>Arjun Mukherjee</author>
<author>Bing Liu</author>
<author>Meichun Hsu</author>
<author>Malu Castellanos</author>
<author>Riddhiman Ghosh</author>
</authors>
<title>Discovering Coherent Topics Using General Knowledge.</title>
<date>2013</date>
<booktitle>In Proceedings of CIKM,</booktitle>
<pages>209--218</pages>
<contexts>
<context position="2915" citStr="Chen et al., 2013" startWordPosition="456" endWordPosition="459"> the objective functions of topic models do not always correlate well with human judgments (Chang et al., 2009). To tackle the problem, several semi-supervised topic models, also called knowledge-based topic models, have been proposed. DF-LDA (Andrzejewski et al., 2009) can incorporate two forms of prior knowledge from the user: must-links and cannot-links. A must-link implies that two terms (or words) should belong to the same topic whereas a cannot-link indicates that two terms should not be in the same topic. In a similar but more generic vein, must-sets and cannot-sets are used in MC-LDA (Chen et al., 2013b). Other related works include (Andrzejewski et al., 2011, Chen et al., 2013a, Chen et al., 2013c, Mukherjee and Liu, 2012, Hu et al., 2011, Jagarlamudi et al., 2012, Lu et al., 2011, Petterson et al., 2010). They all allow prior knowledge to be specified by the user to guide the modeling process. In this paper, we take a major step further. We mine the prior knowledge directly from a large amount of relevant data without any user intervention, and thus make this approach fully automatic. We hypothesize that it is possible to learn quality prior knowledge from the big data (of reviews) availa</context>
<context position="7530" citStr="Chen et al., 2013" startWordPosition="1219" endWordPosition="1222">et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). </context>
<context position="17485" citStr="Chen et al., 2013" startWordPosition="2971" endWordPosition="2974"> 2. The inputs of the model are M documents, T topics and C clusters. Each document m has Nm terms. We model distribution P(cluster|topic) as ψ and distribution P(term|topic, cluster) as cp with Dirichlet priors Q and γ respectively. P (topic|document) is modeled by θ with a Dirichlet prior α. The terms in each document are assumed to be generated by first sampling a topic z, and then a cluster c given topic z, and finally 350 Figure 2: Plate notation for AKL. a term w given topic z and cluster c. This plate notation of AKL and its associated generative process are similar to those of MC-LDA (Chen et al., 2013b). However, there are three key differences. 1. Our knowledge is automatically mined which may have errors (or noises), while the prior knowledge for MC-LDA is manually provided and assumed to be correct. As we will see in Section 6, using our knowledge, MC-LDA does not generate as coherent aspects as AKL. 2. Our knowledge is represented as clusters. Each cluster contains a set of frequent 2-patterns with semantically correlated terms. They are different from must-sets used in MC-LDA. 3. Most importantly, due to the use of the new form of knowledge, AKL’s inference mechanism (Gibbs sampler) i</context>
<context position="18784" citStr="Chen et al., 2013" startWordPosition="3184" endWordPosition="3187">performances (Section 6). Note that the inference mechanism and the prior knowledge cannot be reflected in the plate notation for AKL in Figure 2. In short, our modeling contributions are (1) the capability of handling more expressive knowledge in the form of clusters, (2) a novel Gibbs sampler to deal with inappropriate knowledge. 5.2 The Gibbs Sampler As the automatically learned prior knowledge may contain errors for a domain, AKL has to learn the usefulness of each piece of knowledge dynamically during inference. Instead of assigning weights to each piece of knowledge as a fixed prior in (Chen et al., 2013a), we propose a new Gibbs sampler, which can dynamically balance the use of prior knowledge and the information in the corpus during the Gibbs sampling iterations. We adopt a Blocked Gibbs sampler (Rosen-Zvi et al., 2010) as it improves convergence and reduces autocorrelation when the variables (topic z and cluster c in AKL) are highly related. For each term wi in each document, we jointly sample a topic zi and cluster ci (containing wi) based on the conditional distribution in Gibbs sampler (will be detailed in Equation 4). To compute this distribution, instead of considering how well zi mat</context>
<context position="21941" citStr="Chen et al., 2013" startWordPosition="3746" endWordPosition="3749"> usually reliable, we use these top terms 351 with their probabilities (re-normalized) to represent the topic. Note that a smoothing probability (i.e., a very small value) is also given to every term for calculating KL-Divergence. Given DISTc and DISTz, the agreement is computed with: 1 Agreement(c, z) = KL(DISTc, DISTz) (2) The rationale of Equation 2 is that the lesser divergence between DISTc and DISTz implies the more agreement between ci and zi. We further employ the Generalized Plya urn (GPU) model (Mahmoud, 2008) which was shown to be effective in leveraging semantically related words (Chen et al., 2013a, Chen et al., 2013b, Mimno et al., 2011). The GPU model here basically states that assigning topic zi and cluster ci to term wi will not only increase the probability of connecting zi and ci with wi, but also make it more likely to associate zi and ci with term w0 where w0 shares a 2-pattern with wi in ci. The amount of probability increase is determined by matrix Ac,w0,w defined as: ⎧ 1, if w = w0 (3) ⎨⎪ v, if (w, w0) E c, w =� w0 ❆c,w0,w = 0, otherwise ⎪⎩ where value 1 controls the probability increase of w by seeing w itself, and σ controls the probability increase of w0 by seeing w. Plea</context>
<context position="24276" citStr="Chen et al., 2013" startWordPosition="4172" endWordPosition="4175">.e., a cluster with one pattern {w, w} only. When no knowledge cluster is applicable, this singleton cluster is used. As a singleton cluster does not contain any knowledge information but only the word itself, Equations 1 and 2 cannot be computed. For the values of singleton clusters for these two equations, we assign them as the averages of those values of all nonsingleton knowledge clusters. 6 Experiments This section evaluates and compares the proposed AKL model with three baseline models LDA, MC-LDA, and GK-LDA. LDA (Blei et al., 2003) is the most popular unsupervised topic model. MC-LDA (Chen et al., 2013b) is a recent knowledge-based model for aspect extraction. GK-LDA (Chen et al., 2013a) handles wrong knowledge by setting prior weights using the ratio of word probabilities. Our automatically extracted knowledge is provided to these models. Note that cannot-set of MC-LDA is not used in AKL. 6.1 Experimental Settings Dataset. We created a large dataset containing reviews from 36 product domains or types from Amazon.com. The product domain names are listed in Table 1. Each domain contains 1, 000 reviews. This gives us 36 domain corpora. We have made the dataset publically available at the webs</context>
<context position="31470" citStr="Chen et al., 2013" startWordPosition="5415" endWordPosition="5418">er, Headphone, and GPS. We chose Headphone as it has a lot of overlapping of topics with other domains because many electronic products use headphone. GPS was chosen because it does not have much topic overlapping with other domains as its aspects are mostly about Navigation and Maps. Domains Camera and Computer lay in between. We want to see how domain overlapping influences the performance of AKL. Cohen’s Kappa scores for annotator agreement are 0.918 (for topics) and 0.872 (for terms). To measure the results, we compute Precision@n (or p@n) based on the annotations, which was also used in (Chen et al., 2013b, Mukherjee and Liu, 2012). Figure 4 shows the precision@n results for n = 5 and 10. We can see that AKL makes improvements in all 4 domains. The improvement varies in domains with the most increase in Headphone and the least in GPS as Headphone overlaps more with other domains than GPS. Note that if a domain shares aspects with many other domains, its model should benefit more; otherwise, it is reasonable to expect lesser improvements. For the baselines, GK-LDA and MC-LDA perform similarly to LDA with minor variations, all of which are inferior to AKL. AKL’s improvements over other models ar</context>
</contexts>
<marker>Chen, Mukherjee, Liu, Hsu, Castellanos, Ghosh, 2013</marker>
<rawString>Zhiyuan Chen, Arjun Mukherjee, Bing Liu, Meichun Hsu, Malu Castellanos, and Riddhiman Ghosh. 2013a. Discovering Coherent Topics Using General Knowledge. In Proceedings of CIKM, pages 209– 218.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiyuan Chen</author>
<author>Arjun Mukherjee</author>
<author>Bing Liu</author>
<author>Meichun Hsu</author>
<author>Malu Castellanos</author>
<author>Riddhiman Ghosh</author>
</authors>
<title>Exploiting Domain Knowledge in Aspect Extraction.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1655--1667</pages>
<contexts>
<context position="2915" citStr="Chen et al., 2013" startWordPosition="456" endWordPosition="459"> the objective functions of topic models do not always correlate well with human judgments (Chang et al., 2009). To tackle the problem, several semi-supervised topic models, also called knowledge-based topic models, have been proposed. DF-LDA (Andrzejewski et al., 2009) can incorporate two forms of prior knowledge from the user: must-links and cannot-links. A must-link implies that two terms (or words) should belong to the same topic whereas a cannot-link indicates that two terms should not be in the same topic. In a similar but more generic vein, must-sets and cannot-sets are used in MC-LDA (Chen et al., 2013b). Other related works include (Andrzejewski et al., 2011, Chen et al., 2013a, Chen et al., 2013c, Mukherjee and Liu, 2012, Hu et al., 2011, Jagarlamudi et al., 2012, Lu et al., 2011, Petterson et al., 2010). They all allow prior knowledge to be specified by the user to guide the modeling process. In this paper, we take a major step further. We mine the prior knowledge directly from a large amount of relevant data without any user intervention, and thus make this approach fully automatic. We hypothesize that it is possible to learn quality prior knowledge from the big data (of reviews) availa</context>
<context position="7530" citStr="Chen et al., 2013" startWordPosition="1219" endWordPosition="1222">et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). </context>
<context position="17485" citStr="Chen et al., 2013" startWordPosition="2971" endWordPosition="2974"> 2. The inputs of the model are M documents, T topics and C clusters. Each document m has Nm terms. We model distribution P(cluster|topic) as ψ and distribution P(term|topic, cluster) as cp with Dirichlet priors Q and γ respectively. P (topic|document) is modeled by θ with a Dirichlet prior α. The terms in each document are assumed to be generated by first sampling a topic z, and then a cluster c given topic z, and finally 350 Figure 2: Plate notation for AKL. a term w given topic z and cluster c. This plate notation of AKL and its associated generative process are similar to those of MC-LDA (Chen et al., 2013b). However, there are three key differences. 1. Our knowledge is automatically mined which may have errors (or noises), while the prior knowledge for MC-LDA is manually provided and assumed to be correct. As we will see in Section 6, using our knowledge, MC-LDA does not generate as coherent aspects as AKL. 2. Our knowledge is represented as clusters. Each cluster contains a set of frequent 2-patterns with semantically correlated terms. They are different from must-sets used in MC-LDA. 3. Most importantly, due to the use of the new form of knowledge, AKL’s inference mechanism (Gibbs sampler) i</context>
<context position="18784" citStr="Chen et al., 2013" startWordPosition="3184" endWordPosition="3187">performances (Section 6). Note that the inference mechanism and the prior knowledge cannot be reflected in the plate notation for AKL in Figure 2. In short, our modeling contributions are (1) the capability of handling more expressive knowledge in the form of clusters, (2) a novel Gibbs sampler to deal with inappropriate knowledge. 5.2 The Gibbs Sampler As the automatically learned prior knowledge may contain errors for a domain, AKL has to learn the usefulness of each piece of knowledge dynamically during inference. Instead of assigning weights to each piece of knowledge as a fixed prior in (Chen et al., 2013a), we propose a new Gibbs sampler, which can dynamically balance the use of prior knowledge and the information in the corpus during the Gibbs sampling iterations. We adopt a Blocked Gibbs sampler (Rosen-Zvi et al., 2010) as it improves convergence and reduces autocorrelation when the variables (topic z and cluster c in AKL) are highly related. For each term wi in each document, we jointly sample a topic zi and cluster ci (containing wi) based on the conditional distribution in Gibbs sampler (will be detailed in Equation 4). To compute this distribution, instead of considering how well zi mat</context>
<context position="21941" citStr="Chen et al., 2013" startWordPosition="3746" endWordPosition="3749"> usually reliable, we use these top terms 351 with their probabilities (re-normalized) to represent the topic. Note that a smoothing probability (i.e., a very small value) is also given to every term for calculating KL-Divergence. Given DISTc and DISTz, the agreement is computed with: 1 Agreement(c, z) = KL(DISTc, DISTz) (2) The rationale of Equation 2 is that the lesser divergence between DISTc and DISTz implies the more agreement between ci and zi. We further employ the Generalized Plya urn (GPU) model (Mahmoud, 2008) which was shown to be effective in leveraging semantically related words (Chen et al., 2013a, Chen et al., 2013b, Mimno et al., 2011). The GPU model here basically states that assigning topic zi and cluster ci to term wi will not only increase the probability of connecting zi and ci with wi, but also make it more likely to associate zi and ci with term w0 where w0 shares a 2-pattern with wi in ci. The amount of probability increase is determined by matrix Ac,w0,w defined as: ⎧ 1, if w = w0 (3) ⎨⎪ v, if (w, w0) E c, w =� w0 ❆c,w0,w = 0, otherwise ⎪⎩ where value 1 controls the probability increase of w by seeing w itself, and σ controls the probability increase of w0 by seeing w. Plea</context>
<context position="24276" citStr="Chen et al., 2013" startWordPosition="4172" endWordPosition="4175">.e., a cluster with one pattern {w, w} only. When no knowledge cluster is applicable, this singleton cluster is used. As a singleton cluster does not contain any knowledge information but only the word itself, Equations 1 and 2 cannot be computed. For the values of singleton clusters for these two equations, we assign them as the averages of those values of all nonsingleton knowledge clusters. 6 Experiments This section evaluates and compares the proposed AKL model with three baseline models LDA, MC-LDA, and GK-LDA. LDA (Blei et al., 2003) is the most popular unsupervised topic model. MC-LDA (Chen et al., 2013b) is a recent knowledge-based model for aspect extraction. GK-LDA (Chen et al., 2013a) handles wrong knowledge by setting prior weights using the ratio of word probabilities. Our automatically extracted knowledge is provided to these models. Note that cannot-set of MC-LDA is not used in AKL. 6.1 Experimental Settings Dataset. We created a large dataset containing reviews from 36 product domains or types from Amazon.com. The product domain names are listed in Table 1. Each domain contains 1, 000 reviews. This gives us 36 domain corpora. We have made the dataset publically available at the webs</context>
<context position="31470" citStr="Chen et al., 2013" startWordPosition="5415" endWordPosition="5418">er, Headphone, and GPS. We chose Headphone as it has a lot of overlapping of topics with other domains because many electronic products use headphone. GPS was chosen because it does not have much topic overlapping with other domains as its aspects are mostly about Navigation and Maps. Domains Camera and Computer lay in between. We want to see how domain overlapping influences the performance of AKL. Cohen’s Kappa scores for annotator agreement are 0.918 (for topics) and 0.872 (for terms). To measure the results, we compute Precision@n (or p@n) based on the annotations, which was also used in (Chen et al., 2013b, Mukherjee and Liu, 2012). Figure 4 shows the precision@n results for n = 5 and 10. We can see that AKL makes improvements in all 4 domains. The improvement varies in domains with the most increase in Headphone and the least in GPS as Headphone overlaps more with other domains than GPS. Note that if a domain shares aspects with many other domains, its model should benefit more; otherwise, it is reasonable to expect lesser improvements. For the baselines, GK-LDA and MC-LDA perform similarly to LDA with minor variations, all of which are inferior to AKL. AKL’s improvements over other models ar</context>
</contexts>
<marker>Chen, Mukherjee, Liu, Hsu, Castellanos, Ghosh, 2013</marker>
<rawString>Zhiyuan Chen, Arjun Mukherjee, Bing Liu, Meichun Hsu, Malu Castellanos, and Riddhiman Ghosh. 2013b. Exploiting Domain Knowledge in Aspect Extraction. In Proceedings of EMNLP, pages 1655– 1667.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiyuan Chen</author>
<author>Arjun Mukherjee</author>
<author>Bing Liu</author>
<author>Meichun Hsu</author>
<author>Malu Castellanos</author>
<author>Riddhiman Ghosh</author>
</authors>
<title>Leveraging Multi-Domain Prior Knowledge in Topic Models.</title>
<date>2013</date>
<booktitle>In Proceedings of IJCAI,</booktitle>
<pages>2071--2077</pages>
<contexts>
<context position="2915" citStr="Chen et al., 2013" startWordPosition="456" endWordPosition="459"> the objective functions of topic models do not always correlate well with human judgments (Chang et al., 2009). To tackle the problem, several semi-supervised topic models, also called knowledge-based topic models, have been proposed. DF-LDA (Andrzejewski et al., 2009) can incorporate two forms of prior knowledge from the user: must-links and cannot-links. A must-link implies that two terms (or words) should belong to the same topic whereas a cannot-link indicates that two terms should not be in the same topic. In a similar but more generic vein, must-sets and cannot-sets are used in MC-LDA (Chen et al., 2013b). Other related works include (Andrzejewski et al., 2011, Chen et al., 2013a, Chen et al., 2013c, Mukherjee and Liu, 2012, Hu et al., 2011, Jagarlamudi et al., 2012, Lu et al., 2011, Petterson et al., 2010). They all allow prior knowledge to be specified by the user to guide the modeling process. In this paper, we take a major step further. We mine the prior knowledge directly from a large amount of relevant data without any user intervention, and thus make this approach fully automatic. We hypothesize that it is possible to learn quality prior knowledge from the big data (of reviews) availa</context>
<context position="7530" citStr="Chen et al., 2013" startWordPosition="1219" endWordPosition="1222">et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). </context>
<context position="17485" citStr="Chen et al., 2013" startWordPosition="2971" endWordPosition="2974"> 2. The inputs of the model are M documents, T topics and C clusters. Each document m has Nm terms. We model distribution P(cluster|topic) as ψ and distribution P(term|topic, cluster) as cp with Dirichlet priors Q and γ respectively. P (topic|document) is modeled by θ with a Dirichlet prior α. The terms in each document are assumed to be generated by first sampling a topic z, and then a cluster c given topic z, and finally 350 Figure 2: Plate notation for AKL. a term w given topic z and cluster c. This plate notation of AKL and its associated generative process are similar to those of MC-LDA (Chen et al., 2013b). However, there are three key differences. 1. Our knowledge is automatically mined which may have errors (or noises), while the prior knowledge for MC-LDA is manually provided and assumed to be correct. As we will see in Section 6, using our knowledge, MC-LDA does not generate as coherent aspects as AKL. 2. Our knowledge is represented as clusters. Each cluster contains a set of frequent 2-patterns with semantically correlated terms. They are different from must-sets used in MC-LDA. 3. Most importantly, due to the use of the new form of knowledge, AKL’s inference mechanism (Gibbs sampler) i</context>
<context position="18784" citStr="Chen et al., 2013" startWordPosition="3184" endWordPosition="3187">performances (Section 6). Note that the inference mechanism and the prior knowledge cannot be reflected in the plate notation for AKL in Figure 2. In short, our modeling contributions are (1) the capability of handling more expressive knowledge in the form of clusters, (2) a novel Gibbs sampler to deal with inappropriate knowledge. 5.2 The Gibbs Sampler As the automatically learned prior knowledge may contain errors for a domain, AKL has to learn the usefulness of each piece of knowledge dynamically during inference. Instead of assigning weights to each piece of knowledge as a fixed prior in (Chen et al., 2013a), we propose a new Gibbs sampler, which can dynamically balance the use of prior knowledge and the information in the corpus during the Gibbs sampling iterations. We adopt a Blocked Gibbs sampler (Rosen-Zvi et al., 2010) as it improves convergence and reduces autocorrelation when the variables (topic z and cluster c in AKL) are highly related. For each term wi in each document, we jointly sample a topic zi and cluster ci (containing wi) based on the conditional distribution in Gibbs sampler (will be detailed in Equation 4). To compute this distribution, instead of considering how well zi mat</context>
<context position="21941" citStr="Chen et al., 2013" startWordPosition="3746" endWordPosition="3749"> usually reliable, we use these top terms 351 with their probabilities (re-normalized) to represent the topic. Note that a smoothing probability (i.e., a very small value) is also given to every term for calculating KL-Divergence. Given DISTc and DISTz, the agreement is computed with: 1 Agreement(c, z) = KL(DISTc, DISTz) (2) The rationale of Equation 2 is that the lesser divergence between DISTc and DISTz implies the more agreement between ci and zi. We further employ the Generalized Plya urn (GPU) model (Mahmoud, 2008) which was shown to be effective in leveraging semantically related words (Chen et al., 2013a, Chen et al., 2013b, Mimno et al., 2011). The GPU model here basically states that assigning topic zi and cluster ci to term wi will not only increase the probability of connecting zi and ci with wi, but also make it more likely to associate zi and ci with term w0 where w0 shares a 2-pattern with wi in ci. The amount of probability increase is determined by matrix Ac,w0,w defined as: ⎧ 1, if w = w0 (3) ⎨⎪ v, if (w, w0) E c, w =� w0 ❆c,w0,w = 0, otherwise ⎪⎩ where value 1 controls the probability increase of w by seeing w itself, and σ controls the probability increase of w0 by seeing w. Plea</context>
<context position="24276" citStr="Chen et al., 2013" startWordPosition="4172" endWordPosition="4175">.e., a cluster with one pattern {w, w} only. When no knowledge cluster is applicable, this singleton cluster is used. As a singleton cluster does not contain any knowledge information but only the word itself, Equations 1 and 2 cannot be computed. For the values of singleton clusters for these two equations, we assign them as the averages of those values of all nonsingleton knowledge clusters. 6 Experiments This section evaluates and compares the proposed AKL model with three baseline models LDA, MC-LDA, and GK-LDA. LDA (Blei et al., 2003) is the most popular unsupervised topic model. MC-LDA (Chen et al., 2013b) is a recent knowledge-based model for aspect extraction. GK-LDA (Chen et al., 2013a) handles wrong knowledge by setting prior weights using the ratio of word probabilities. Our automatically extracted knowledge is provided to these models. Note that cannot-set of MC-LDA is not used in AKL. 6.1 Experimental Settings Dataset. We created a large dataset containing reviews from 36 product domains or types from Amazon.com. The product domain names are listed in Table 1. Each domain contains 1, 000 reviews. This gives us 36 domain corpora. We have made the dataset publically available at the webs</context>
<context position="31470" citStr="Chen et al., 2013" startWordPosition="5415" endWordPosition="5418">er, Headphone, and GPS. We chose Headphone as it has a lot of overlapping of topics with other domains because many electronic products use headphone. GPS was chosen because it does not have much topic overlapping with other domains as its aspects are mostly about Navigation and Maps. Domains Camera and Computer lay in between. We want to see how domain overlapping influences the performance of AKL. Cohen’s Kappa scores for annotator agreement are 0.918 (for topics) and 0.872 (for terms). To measure the results, we compute Precision@n (or p@n) based on the annotations, which was also used in (Chen et al., 2013b, Mukherjee and Liu, 2012). Figure 4 shows the precision@n results for n = 5 and 10. We can see that AKL makes improvements in all 4 domains. The improvement varies in domains with the most increase in Headphone and the least in GPS as Headphone overlaps more with other domains than GPS. Note that if a domain shares aspects with many other domains, its model should benefit more; otherwise, it is reasonable to expect lesser improvements. For the baselines, GK-LDA and MC-LDA perform similarly to LDA with minor variations, all of which are inferior to AKL. AKL’s improvements over other models ar</context>
</contexts>
<marker>Chen, Mukherjee, Liu, Hsu, Castellanos, Ghosh, 2013</marker>
<rawString>Zhiyuan Chen, Arjun Mukherjee, Bing Liu, Meichun Hsu, Malu Castellanos, and Riddhiman Ghosh. 2013c. Leveraging Multi-Domain Prior Knowledge in Topic Models. In Proceedings of IJCAI, pages 2071–2077.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
</authors>
<title>Hierarchical Sequential Learning for Extracting Opinions and their Attributes.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>269--274</pages>
<contexts>
<context position="6733" citStr="Choi and Cardie, 2010" startWordPosition="1077" endWordPosition="1080">re coherent aspects. The process is fully automatic. To the best of our knowledge, none of the existing models for aspect extraction is able to achieve this. 2. It proposes an effective method to learn quality knowledge from raw topics produced using review corpora from many different domains. 3. It proposes a new inference mechanism for topic modeling, which can handle incorrect knowledge in aspect extraction. 2 Related Work Aspect extraction has been studied by many researchers in sentiment analysis (Liu, 2012, Pang and Lee, 2008), e.g., using supervised sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspec</context>
</contexts>
<marker>Choi, Cardie, 2010</marker>
<rawString>Yejin Choi and Claire Cardie. 2010. Hierarchical Sequential Learning for Extracting Opinions and their Attributes. In Proceedings of ACL, pages 269–274.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
<author>Brendan O’Connor</author>
<author>Noah A Smith</author>
<author>Eric P Xing</author>
</authors>
<title>A Latent Variable Model for Geographic Lexical Variation.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1277--1287</pages>
<marker>Eisenstein, O’Connor, Smith, Xing, 2010</marker>
<rawString>Jacob Eisenstein, Brendan O’Connor, Noah A Smith, and Eric P Xing. 2010. A Latent Variable Model for Geographic Lexical Variation. In Proceedings of EMNLP, pages 1277–1287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Fang</author>
<author>Minlie Huang</author>
</authors>
<title>Fine Granular Aspect Analysis using Latent Structural Models.</title>
<date>2012</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>333--337</pages>
<contexts>
<context position="7553" citStr="Fang and Huang, 2012" startWordPosition="1223" endWordPosition="1226">u and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). Geographical region kno</context>
</contexts>
<marker>Fang, Huang, 2012</marker>
<rawString>Lei Fang and Minlie Huang. 2012. Fine Granular Aspect Analysis using Latent Structural Models. In Proceedings ofACL, pages 333–337.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Honglei Guo</author>
<author>Huijia Zhu</author>
<author>Zhili Guo</author>
<author>Xiaoxun Zhang</author>
<author>Zhong Su</author>
</authors>
<title>Product feature categorization with multilevel latent semantic association.</title>
<date>2009</date>
<booktitle>In Proceedings of CIKM,</booktitle>
<pages>1087--1096</pages>
<contexts>
<context position="7289" citStr="Guo et al., 2009" startWordPosition="1180" endWordPosition="1183">d sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our prop</context>
</contexts>
<marker>Guo, Zhu, Guo, Zhang, Su, 2009</marker>
<rawString>Honglei Guo, Huijia Zhu, Zhili Guo, Xiaoxun Zhang, and Zhong Su. 2009. Product feature categorization with multilevel latent semantic association. In Proceedings of CIKM, pages 1087–1096.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiawei Han</author>
<author>Hong Cheng</author>
<author>Dong Xin</author>
<author>Xifeng Yan</author>
</authors>
<title>Frequent pattern mining: current status and future directions. Data Mining and Knowledge Discovery,</title>
<date>2007</date>
<contexts>
<context position="10580" citStr="Han et al., 2007" startWordPosition="1772" endWordPosition="1775">owledge and using the learned knowledge. Figure 1 gives the algorithm. Step 1 (learning quality knowledge, Lines 1- 16): The input is the review corpora DL from multiple domains, from which the knowledge is automatically learned. Lines 3 and 5 run LDA on each review domain corpus Di E DL to generate a set of aspects/topics Ai (lines 2, 4, and 6- 9 will be discussed below). Line 10 unions the topics from all domains to give A. Lines 11-14 cluster the topics in A into some coherent groups (or clusters) and then discover knowledge Kj from each group of topics using frequent pattern mining (FPM) (Han et al., 2007). We will detail these in Section 4. Each piece of the learned knowledge is a set of terms which are likely to belong to the same aspect. Iterative improvement: The above process can actually run iteratively because the learned knowledge K can help the topic model learn better topics in each domain Di E DL, which results in better knowledge K in the next iteration. This iterative process is reflected in lines 2, 4, 6-9 and 16. We will examine the performance of the process at different iterations in Section 6.2. From the second iteration, we can use the knowledge learned from the previous iter</context>
<context position="13496" citStr="Han et al., 2007" startWordPosition="2282" endWordPosition="2285">a frequency-based approach to discover frequent set of terms as quality knowledge. However, we need to deal with two issues. 1. Generic aspects, such as price with aspect terms like cost and pricy, are shared by many (even all) product domains. But specific aspects such as screen, occur only in domains with products having them. It means that different aspects may have distinct frequencies. Thus, using a single frequency threshold in the frequency-based approach is not sufficient to extract both generic and specific aspects because the generic aspects will result in numerous spurious aspects (Han et al., 2007). 2. A term may have multiple senses in different domains. For example, light can mean “of little weight” or “something that makes things visible”. A good knowledge base should have the capacity of handling this ambiguity. To deal with these two issues, we propose to discover knowledge in two stages: topic clustering and frequent pattern mining (FPM). The purpose of clustering is to group raw topics from a topic model (LDA or AKL) into clusters. Each cluster contains semantically related topics likely to indicate the same real-world aspect. We then mine knowledge from each cluster using an FPM</context>
<context position="14999" citStr="Han et al., 2007" startWordPosition="2530" endWordPosition="2533">e reason is that k-means is more sensitive to outliers. In our topic clustering, each data point is a topic represented by its top terms (with their probabilities normalized). The distance between two data points is measured by symmetrised KL-Divergence. 4.2 Frequent Pattern Mining Given topics within each cluster, this step finds sets of terms that appear together in multiple topics, i.e., shared terms among similar topics across multiple domains. Terms in such a set are likely to belong to the same aspect. To find such sets of terms within each cluster, we use frequent pattern mining (FPM) (Han et al., 2007), which is suited for the task. The probability of each term is ignored in FPM. FPM is stated as follows: Given a set of transactions ❚, where each transaction tz E ❚ is a set of items from a global item set ■, i.e., tz E ■. In our context, tz is the topic vector comprising the top terms of a topic (no probability attached). ❚ is the collection of all topics within a cluster and ■ is the set of all terms in ❚. The goal of FPM is to find all patterns that satisfy some user-specified frequency threshold (also called minimum support count), which is the minimum number of times that a pattern shou</context>
</contexts>
<marker>Han, Cheng, Xin, Yan, 2007</marker>
<rawString>Jiawei Han, Hong Cheng, Dong Xin, and Xifeng Yan. 2007. Frequent pattern mining: current status and future directions. Data Mining and Knowledge Discovery, 15(1):55–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yulan He</author>
<author>Chenghua Lin</author>
<author>Harith Alani</author>
</authors>
<title>Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>123--131</pages>
<contexts>
<context position="7570" citStr="He et al., 2011" startWordPosition="1227" endWordPosition="1230">iu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). Geographical region knowledge has also b</context>
<context position="9278" citStr="He et al., 2011" startWordPosition="1550" endWordPosition="1553">els have been used to help 348 Input: Corpora DL for knowledge learning Test corpora DT 1: // STEP 1: Learning prior knowledge. 2: for r = 0 to R do // Iterate R + 1 times. 3: for each domain corpus Di E DL do 4: if r = 0 then 5: Ai +— LDA(Di); 6: else 7: Ai +— AKL(Di, K); 8: end if 9: end for 10: A +— UiAi; 11: TC +— Clustering(A); 12: for each cluster Tj E TC do 13: Kj +— FPM(Tj); 14: end for 15: K +— UjKj; 16: end for 17: // STEP 2: Using the learned knowledge. 18: for each test corpus Di E DT do 19: Ai +— AKL(Di, K); 20: end for Figure 1: The proposed overall algorithm. transfer learning (He et al., 2011, Pan and Yang, 2010, Xue et al., 2008). However, transfer learning in these papers is for traditional classification rather than topic/aspect extraction. In (Kang et al., 2012), labeled documents from source domains are transferred to the target domain to produce topic models with better fitting. However, we do not use any labeled data. In (Yang et al., 2011), a user provided parameter indicating the technicality degree of a domain was used to model the language gap between topics. In contrast, our method is fully automatic without human intervention. 3 Overall Algorithm This section introduc</context>
</contexts>
<marker>He, Lin, Alani, 2011</marker>
<rawString>Yulan He, Chenghua Lin, and Harith Alani. 2011. Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification. In Proceedings of ACL, pages 123–131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>Probabilistic Latent Semantic Analysis.</title>
<date>1999</date>
<booktitle>In Proceedings of UAI,</booktitle>
<pages>289--296</pages>
<contexts>
<context position="2028" citStr="Hofmann, 1999" startWordPosition="317" endWordPosition="318">ample, in “The voice is not clear,” the aspect term is “voice.” Aspect extraction has two subtasks: aspect term extraction and aspect term resolution. Aspect term resolution groups extracted synonymous aspect terms together. For example, “voice” and “sound” should be grouped together as they refer to the same aspect of phones. Recently, topic models have been extensively applied to aspect extraction because they can perform both subtasks at the same time while other existing methods all need two separate steps (see Section 2). Traditional topic models such as LDA (Blei et al., 2003) and pLSA (Hofmann, 1999) are unsupervised methods for extracting latent topics in text documents. Topics are aspects in our task. Each aspect (or topic) is a distribution over (aspect) terms. However, researchers have shown that fully unsupervised models often produce incoherent topics because the objective functions of topic models do not always correlate well with human judgments (Chang et al., 2009). To tackle the problem, several semi-supervised topic models, also called knowledge-based topic models, have been proposed. DF-LDA (Andrzejewski et al., 2009) can incorporate two forms of prior knowledge from the user:</context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>Thomas Hofmann. 1999. Probabilistic Latent Semantic Analysis. In Proceedings of UAI, pages 289–296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and Summarizing Customer Reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of KDD,</booktitle>
<pages>168--177</pages>
<contexts>
<context position="1394" citStr="Hu and Liu, 2004" startWordPosition="211" endWordPosition="214"> Such knowledge can then be used by a topic model to discover more coherent aspects. There are two key challenges: (1) learning quality knowledge from reviews of diverse domains, and (2) making the model fault-tolerant to handle possibly wrong knowledge. A novel approach is proposed to solve these problems. Experimental results using reviews from 36 domains show that the proposed approach achieves significant improvements over state-of-the-art baselines. 1 Introduction Aspect extraction aims to extract target entities and their aspects (or attributes) that people have expressed opinions upon (Hu and Liu, 2004, Liu, 2012). For example, in “The voice is not clear,” the aspect term is “voice.” Aspect extraction has two subtasks: aspect term extraction and aspect term resolution. Aspect term resolution groups extracted synonymous aspect terms together. For example, “voice” and “sound” should be grouped together as they refer to the same aspect of phones. Recently, topic models have been extensively applied to aspect extraction because they can perform both subtasks at the same time while other existing methods all need two separate steps (see Section 2). Traditional topic models such as LDA (Blei et a</context>
<context position="6890" citStr="Hu and Liu, 2004" startWordPosition="1105" endWordPosition="1108">t proposes an effective method to learn quality knowledge from raw topics produced using review corpora from many different domains. 3. It proposes a new inference mechanism for topic modeling, which can handle incorrect knowledge in aspect extraction. 2 Related Work Aspect extraction has been studied by many researchers in sentiment analysis (Liu, 2012, Pang and Lee, 2008), e.g., using supervised sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Br</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and Summarizing Customer Reviews. In Proceedings of KDD, pages 168–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuening Hu</author>
<author>Jordan Boyd-Graber</author>
<author>Brianna Satinoff</author>
</authors>
<title>Interactive Topic Modeling.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>248--257</pages>
<contexts>
<context position="3055" citStr="Hu et al., 2011" startWordPosition="482" endWordPosition="485">l semi-supervised topic models, also called knowledge-based topic models, have been proposed. DF-LDA (Andrzejewski et al., 2009) can incorporate two forms of prior knowledge from the user: must-links and cannot-links. A must-link implies that two terms (or words) should belong to the same topic whereas a cannot-link indicates that two terms should not be in the same topic. In a similar but more generic vein, must-sets and cannot-sets are used in MC-LDA (Chen et al., 2013b). Other related works include (Andrzejewski et al., 2011, Chen et al., 2013a, Chen et al., 2013c, Mukherjee and Liu, 2012, Hu et al., 2011, Jagarlamudi et al., 2012, Lu et al., 2011, Petterson et al., 2010). They all allow prior knowledge to be specified by the user to guide the modeling process. In this paper, we take a major step further. We mine the prior knowledge directly from a large amount of relevant data without any user intervention, and thus make this approach fully automatic. We hypothesize that it is possible to learn quality prior knowledge from the big data (of reviews) available on the Web. The intuition is that although every domain is different, there is a decent amount of aspect overlapping across domains. For</context>
</contexts>
<marker>Hu, Boyd-Graber, Satinoff, 2011</marker>
<rawString>Yuening Hu, Jordan Boyd-Graber, and Brianna Satinoff. 2011. Interactive Topic Modeling. In Proceedings of ACL, pages 248–257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jagadeesh Jagarlamudi</author>
<author>Hal Daum´e</author>
<author>Raghavendra Udupa</author>
</authors>
<title>Incorporating Lexical Priors into Topic Models.</title>
<date>2012</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>204--213</pages>
<marker>Jagarlamudi, Daum´e, Udupa, 2012</marker>
<rawString>Jagadeesh Jagarlamudi, Hal Daum´e III, and Raghavendra Udupa. 2012. Incorporating Lexical Priors into Topic Models. In Proceedings of EACL, pages 204– 213.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Niklas Jakob</author>
<author>Iryna Gurevych</author>
</authors>
<title>Extracting Opinion Targets in a Single- and Cross-Domain Setting with Conditional Random Fields.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1035--1045</pages>
<contexts>
<context position="6759" citStr="Jakob and Gurevych, 2010" startWordPosition="1081" endWordPosition="1084">e process is fully automatic. To the best of our knowledge, none of the existing models for aspect extraction is able to achieve this. 2. It proposes an effective method to learn quality knowledge from raw topics produced using review corpora from many different domains. 3. It proposes a new inference mechanism for topic modeling, which can handle incorrect knowledge in aspect extraction. 2 Related Work Aspect extraction has been studied by many researchers in sentiment analysis (Liu, 2012, Pang and Lee, 2008), e.g., using supervised sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracte</context>
</contexts>
<marker>Jakob, Gurevych, 2010</marker>
<rawString>Niklas Jakob and Iryna Gurevych. 2010. Extracting Opinion Targets in a Single- and Cross-Domain Setting with Conditional Random Fields. In Proceedings of EMNLP, pages 1035–1045.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yohan Jo</author>
<author>Alice H Oh</author>
</authors>
<title>Aspect and sentiment unification model for online review analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of WSDM,</booktitle>
<pages>815--824</pages>
<contexts>
<context position="7587" citStr="Jo and Oh, 2011" startWordPosition="1231" endWordPosition="1234">Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). Geographical region knowledge has also been considered in</context>
</contexts>
<marker>Jo, Oh, 2011</marker>
<rawString>Yohan Jo and Alice H. Oh. 2011. Aspect and sentiment unification model for online review analysis. In Proceedings of WSDM, pages 815–824.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeon-hyung Kang</author>
<author>Jun Ma</author>
<author>Yan Liu</author>
</authors>
<title>Transfer Topic Modeling with Ease and Scalability.</title>
<date>2012</date>
<booktitle>In Proceedings of SDM,</booktitle>
<pages>564--575</pages>
<contexts>
<context position="9455" citStr="Kang et al., 2012" startWordPosition="1578" endWordPosition="1581">: for each domain corpus Di E DL do 4: if r = 0 then 5: Ai +— LDA(Di); 6: else 7: Ai +— AKL(Di, K); 8: end if 9: end for 10: A +— UiAi; 11: TC +— Clustering(A); 12: for each cluster Tj E TC do 13: Kj +— FPM(Tj); 14: end for 15: K +— UjKj; 16: end for 17: // STEP 2: Using the learned knowledge. 18: for each test corpus Di E DT do 19: Ai +— AKL(Di, K); 20: end for Figure 1: The proposed overall algorithm. transfer learning (He et al., 2011, Pan and Yang, 2010, Xue et al., 2008). However, transfer learning in these papers is for traditional classification rather than topic/aspect extraction. In (Kang et al., 2012), labeled documents from source domains are transferred to the target domain to produce topic models with better fitting. However, we do not use any labeled data. In (Yang et al., 2011), a user provided parameter indicating the technicality degree of a domain was used to model the language gap between topics. In contrast, our method is fully automatic without human intervention. 3 Overall Algorithm This section introduces the proposed overall algorithm. It consists of two main steps: learning quality knowledge and using the learned knowledge. Figure 1 gives the algorithm. Step 1 (learning qual</context>
</contexts>
<marker>Kang, Ma, Liu, 2012</marker>
<rawString>Jeon-hyung Kang, Jun Ma, and Yan Liu. 2012. Transfer Topic Modeling with Ease and Scalability. In Proceedings of SDM, pages 564–575.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Kaufman</author>
<author>P J Rousseeuw</author>
</authors>
<title>Finding groups in data: an introduction to cluster analysis.</title>
<date>1990</date>
<publisher>John Wiley and Sons.</publisher>
<contexts>
<context position="14318" citStr="Kaufman and Rousseeuw, 1990" startWordPosition="2417" endWordPosition="2420"> of handling this ambiguity. To deal with these two issues, we propose to discover knowledge in two stages: topic clustering and frequent pattern mining (FPM). The purpose of clustering is to group raw topics from a topic model (LDA or AKL) into clusters. Each cluster contains semantically related topics likely to indicate the same real-world aspect. We then mine knowledge from each cluster using an FPM technique. Note that the multiple senses of a term can be distinguished by the semantic meanings represented by the topics in different clusters. For clustering, we tried k-means and kmedoids (Kaufman and Rousseeuw, 1990), and found that k-medoids performs slightly better. One possible reason is that k-means is more sensitive to outliers. In our topic clustering, each data point is a topic represented by its top terms (with their probabilities normalized). The distance between two data points is measured by symmetrised KL-Divergence. 4.2 Frequent Pattern Mining Given topics within each cluster, this step finds sets of terms that appear together in multiple topics, i.e., shared terms among similar topics across multiple domains. Terms in such a set are likely to belong to the same aspect. To find such sets of t</context>
</contexts>
<marker>Kaufman, Rousseeuw, 1990</marker>
<rawString>L Kaufman and P J Rousseeuw. 1990. Finding groups in data: an introduction to cluster analysis. John Wiley and Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Suin Kim</author>
<author>Jianwen Zhang</author>
<author>Zheng Chen</author>
<author>Alice Oh</author>
<author>Shixia Liu</author>
</authors>
<title>A Hierarchical Aspect-Sentiment Model for Online Reviews.</title>
<date>2013</date>
<booktitle>In Proceedings ofAAAI,</booktitle>
<pages>526--533</pages>
<contexts>
<context position="7605" citStr="Kim et al., 2013" startWordPosition="1235" endWordPosition="1238">Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). Geographical region knowledge has also been considered in topic models (Eis</context>
</contexts>
<marker>Kim, Zhang, Chen, Oh, Liu, 2013</marker>
<rawString>Suin Kim, Jianwen Zhang, Zheng Chen, Alice Oh, and Shixia Liu. 2013. A Hierarchical Aspect-Sentiment Model for Online Reviews. In Proceedings ofAAAI, pages 526–533.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nozomi Kobayashi</author>
<author>Kentaro Inui</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Extracting Aspect-Evaluation and Aspect-of Relations in Opinion Mining.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1065--1074</pages>
<contexts>
<context position="6783" citStr="Kobayashi et al., 2007" startWordPosition="1085" endWordPosition="1088">ic. To the best of our knowledge, none of the existing models for aspect extraction is able to achieve this. 2. It proposes an effective method to learn quality knowledge from raw topics produced using review corpora from many different domains. 3. It proposes a new inference mechanism for topic modeling, which can handle incorrect knowledge in aspect extraction. 2 Related Work Aspect extraction has been studied by many researchers in sentiment analysis (Liu, 2012, Pang and Lee, 2008), e.g., using supervised sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract</context>
</contexts>
<marker>Kobayashi, Inui, Matsumoto, 2007</marker>
<rawString>Nozomi Kobayashi, Kentaro Inui, and Yuji Matsumoto. 2007. Extracting Aspect-Evaluation and Aspect-of Relations in Opinion Mining. In Proceedings of EMNLP, pages 1065–1074.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lun-Wei Ku</author>
<author>Yu-Ting Liang</author>
<author>Hsin-Hsi Chen</author>
</authors>
<title>Opinion Extraction, Summarization and Tracking in News and Blog Corpora.</title>
<date>2006</date>
<booktitle>In Proceedings of AAAI-CAAW,</booktitle>
<pages>100--107</pages>
<contexts>
<context position="6907" citStr="Ku et al., 2006" startWordPosition="1109" endWordPosition="1112">ctive method to learn quality knowledge from raw topics produced using review corpora from many different domains. 3. It proposes a new inference mechanism for topic modeling, which can handle incorrect knowledge in aspect extraction. 2 Related Work Aspect extraction has been studied by many researchers in sentiment analysis (Liu, 2012, Pang and Lee, 2008), e.g., using supervised sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, </context>
</contexts>
<marker>Ku, Liang, Chen, 2006</marker>
<rawString>Lun-Wei Ku, Yu-Ting Liang, and Hsin-Hsi Chen. 2006. Opinion Extraction, Summarization and Tracking in News and Blog Corpora. In Proceedings of AAAI-CAAW, pages 100–107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angeliki Lazaridou</author>
<author>Ivan Titov</author>
<author>Caroline Sporleder</author>
</authors>
<title>A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>1630--1639</pages>
<contexts>
<context position="7629" citStr="Lazaridou et al., 2013" startWordPosition="1239" endWordPosition="1242"> al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). Geographical region knowledge has also been considered in topic models (Eisenstein et al., 2010). A</context>
</contexts>
<marker>Lazaridou, Titov, Sporleder, 2013</marker>
<rawString>Angeliki Lazaridou, Ivan Titov, and Caroline Sporleder. 2013. A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations. In Proceedings of ACL, pages 1630–1639.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangtao Li</author>
<author>Chao Han</author>
<author>Minlie Huang</author>
<author>Xiaoyan Zhu</author>
<author>Yingju Xia</author>
<author>Shu Zhang</author>
<author>Hao Yu</author>
</authors>
<title>Structure-Aware Review Mining and Summarization.</title>
<date>2010</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>653--661</pages>
<contexts>
<context position="6800" citStr="Li et al., 2010" startWordPosition="1089" endWordPosition="1092">nowledge, none of the existing models for aspect extraction is able to achieve this. 2. It proposes an effective method to learn quality knowledge from raw topics produced using review corpora from many different domains. 3. It proposes a new inference mechanism for topic modeling, which can handle incorrect knowledge in aspect extraction. 2 Related Work Aspect extraction has been studied by many researchers in sentiment analysis (Liu, 2012, Pang and Lee, 2008), e.g., using supervised sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspect</context>
</contexts>
<marker>Li, Han, Huang, Zhu, Xia, Zhang, Yu, 2010</marker>
<rawString>Fangtao Li, Chao Han, Minlie Huang, Xiaoyan Zhu, Yingju Xia, Shu Zhang, and Hao Yu. 2010. Structure-Aware Review Mining and Summarization. In Proceedings of COLING, pages 653–661.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peng Li</author>
<author>Yinglin Wang</author>
<author>Wei Gao</author>
<author>Jing Jiang</author>
</authors>
<title>Generating Aspect-oriented Multi-Document Summarization with Event-aspect model.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1137--1146</pages>
<contexts>
<context position="7646" citStr="Li et al., 2011" startWordPosition="1243" endWordPosition="1246">013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). Geographical region knowledge has also been considered in topic models (Eisenstein et al., 2010). All of these model</context>
</contexts>
<marker>Li, Wang, Gao, Jiang, 2011</marker>
<rawString>Peng Li, Yinglin Wang, Wei Gao, and Jing Jiang. 2011. Generating Aspect-oriented Multi-Document Summarization with Event-aspect model. In Proceedings of EMNLP, pages 1137–1146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chenghua Lin</author>
<author>Yulan He</author>
</authors>
<title>Joint sentiment/topic model for sentiment analysis.</title>
<date>2009</date>
<booktitle>In Proceedings of CIKM,</booktitle>
<pages>375--384</pages>
<contexts>
<context position="7664" citStr="Lin and He, 2009" startWordPosition="1247" endWordPosition="1250">011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). Geographical region knowledge has also been considered in topic models (Eisenstein et al., 2010). All of these models assume that the </context>
</contexts>
<marker>Lin, He, 2009</marker>
<rawString>Chenghua Lin and Yulan He. 2009. Joint sentiment/topic model for sentiment analysis. In Proceedings of CIKM, pages 375–384.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kang Liu</author>
<author>Liheng Xu</author>
<author>Jun Zhao</author>
</authors>
<title>Syntactic Patterns versus Word Alignment: Extracting Opinion Targets from Online Reviews.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>1754--1763</pages>
<contexts>
<context position="6925" citStr="Liu et al., 2013" startWordPosition="1113" endWordPosition="1116">earn quality knowledge from raw topics produced using review corpora from many different domains. 3. It proposes a new inference mechanism for topic modeling, which can handle incorrect knowledge in aspect extraction. 2 Related Work Aspect extraction has been studied by many researchers in sentiment analysis (Liu, 2012, Pang and Lee, 2008), e.g., using supervised sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al.,</context>
</contexts>
<marker>Liu, Xu, Zhao, 2013</marker>
<rawString>Kang Liu, Liheng Xu, and Jun Zhao. 2013. Syntactic Patterns versus Word Alignment: Extracting Opinion Targets from Online Reviews. In Proceedings of ACL, pages 1754–1763.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining.</title>
<date>2012</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="1406" citStr="Liu, 2012" startWordPosition="215" endWordPosition="216">n then be used by a topic model to discover more coherent aspects. There are two key challenges: (1) learning quality knowledge from reviews of diverse domains, and (2) making the model fault-tolerant to handle possibly wrong knowledge. A novel approach is proposed to solve these problems. Experimental results using reviews from 36 domains show that the proposed approach achieves significant improvements over state-of-the-art baselines. 1 Introduction Aspect extraction aims to extract target entities and their aspects (or attributes) that people have expressed opinions upon (Hu and Liu, 2004, Liu, 2012). For example, in “The voice is not clear,” the aspect term is “voice.” Aspect extraction has two subtasks: aspect term extraction and aspect term resolution. Aspect term resolution groups extracted synonymous aspect terms together. For example, “voice” and “sound” should be grouped together as they refer to the same aspect of phones. Recently, topic models have been extensively applied to aspect extraction because they can perform both subtasks at the same time while other existing methods all need two separate steps (see Section 2). Traditional topic models such as LDA (Blei et al., 2003) an</context>
<context position="3038" citStr="Liu, 2012" startWordPosition="480" endWordPosition="481">lem, several semi-supervised topic models, also called knowledge-based topic models, have been proposed. DF-LDA (Andrzejewski et al., 2009) can incorporate two forms of prior knowledge from the user: must-links and cannot-links. A must-link implies that two terms (or words) should belong to the same topic whereas a cannot-link indicates that two terms should not be in the same topic. In a similar but more generic vein, must-sets and cannot-sets are used in MC-LDA (Chen et al., 2013b). Other related works include (Andrzejewski et al., 2011, Chen et al., 2013a, Chen et al., 2013c, Mukherjee and Liu, 2012, Hu et al., 2011, Jagarlamudi et al., 2012, Lu et al., 2011, Petterson et al., 2010). They all allow prior knowledge to be specified by the user to guide the modeling process. In this paper, we take a major step further. We mine the prior knowledge directly from a large amount of relevant data without any user intervention, and thus make this approach fully automatic. We hypothesize that it is possible to learn quality prior knowledge from the big data (of reviews) available on the Web. The intuition is that although every domain is different, there is a decent amount of aspect overlapping ac</context>
<context position="6629" citStr="Liu, 2012" startWordPosition="1064" endWordPosition="1065">e big data to learn prior knowledge and leverage the knowledge in topic models to extract more coherent aspects. The process is fully automatic. To the best of our knowledge, none of the existing models for aspect extraction is able to achieve this. 2. It proposes an effective method to learn quality knowledge from raw topics produced using review corpora from many different domains. 3. It proposes a new inference mechanism for topic modeling, which can handle incorrect knowledge in aspect extraction. 2 Related Work Aspect extraction has been studied by many researchers in sentiment analysis (Liu, 2012, Pang and Lee, 2008), e.g., using supervised sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term groupi</context>
<context position="31497" citStr="Liu, 2012" startWordPosition="5421" endWordPosition="5422">eadphone as it has a lot of overlapping of topics with other domains because many electronic products use headphone. GPS was chosen because it does not have much topic overlapping with other domains as its aspects are mostly about Navigation and Maps. Domains Camera and Computer lay in between. We want to see how domain overlapping influences the performance of AKL. Cohen’s Kappa scores for annotator agreement are 0.918 (for topics) and 0.872 (for terms). To measure the results, we compute Precision@n (or p@n) based on the annotations, which was also used in (Chen et al., 2013b, Mukherjee and Liu, 2012). Figure 4 shows the precision@n results for n = 5 and 10. We can see that AKL makes improvements in all 4 domains. The improvement varies in domains with the most increase in Headphone and the least in GPS as Headphone overlaps more with other domains than GPS. Note that if a domain shares aspects with many other domains, its model should benefit more; otherwise, it is reasonable to expect lesser improvements. For the baselines, GK-LDA and MC-LDA perform similarly to LDA with minor variations, all of which are inferior to AKL. AKL’s improvements over other models are statistically significant</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment Analysis and Opinion Mining. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Lu</author>
<author>Chengxiang Zhai</author>
</authors>
<title>Opinion integration through semi-supervised topic modeling.</title>
<date>2008</date>
<booktitle>In Proceedings of WWW,</booktitle>
<pages>121--130</pages>
<contexts>
<context position="7717" citStr="Lu and Zhai, 2008" startWordPosition="1259" endWordPosition="1262"> al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). Geographical region knowledge has also been considered in topic models (Eisenstein et al., 2010). All of these models assume that the prior knowledge is correct. GK-LDA (Chen et al., 2013</context>
</contexts>
<marker>Lu, Zhai, 2008</marker>
<rawString>Yue Lu and Chengxiang Zhai. 2008. Opinion integration through semi-supervised topic modeling. In Proceedings of WWW, pages 121–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Lu</author>
<author>ChengXiang Zhai</author>
<author>Neel Sundaresan</author>
</authors>
<title>Rated aspect summarization of short comments.</title>
<date>2009</date>
<booktitle>In Proceedings of WWW,</booktitle>
<pages>131--140</pages>
<contexts>
<context position="7681" citStr="Lu et al., 2009" startWordPosition="1251" endWordPosition="1254">2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). Geographical region knowledge has also been considered in topic models (Eisenstein et al., 2010). All of these models assume that the prior knowledge i</context>
</contexts>
<marker>Lu, Zhai, Sundaresan, 2009</marker>
<rawString>Yue Lu, ChengXiang Zhai, and Neel Sundaresan. 2009. Rated aspect summarization of short comments. In Proceedings of WWW, pages 131–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bin Lu</author>
<author>Myle Ott</author>
<author>Claire Cardie</author>
<author>Benjamin K Tsou</author>
</authors>
<title>Multi-aspect Sentiment Analysis with Topic Models.</title>
<date>2011</date>
<booktitle>In Proceedings of ICDM Workshops,</booktitle>
<pages>81--88</pages>
<contexts>
<context position="3098" citStr="Lu et al., 2011" startWordPosition="490" endWordPosition="493"> knowledge-based topic models, have been proposed. DF-LDA (Andrzejewski et al., 2009) can incorporate two forms of prior knowledge from the user: must-links and cannot-links. A must-link implies that two terms (or words) should belong to the same topic whereas a cannot-link indicates that two terms should not be in the same topic. In a similar but more generic vein, must-sets and cannot-sets are used in MC-LDA (Chen et al., 2013b). Other related works include (Andrzejewski et al., 2011, Chen et al., 2013a, Chen et al., 2013c, Mukherjee and Liu, 2012, Hu et al., 2011, Jagarlamudi et al., 2012, Lu et al., 2011, Petterson et al., 2010). They all allow prior knowledge to be specified by the user to guide the modeling process. In this paper, we take a major step further. We mine the prior knowledge directly from a large amount of relevant data without any user intervention, and thus make this approach fully automatic. We hypothesize that it is possible to learn quality prior knowledge from the big data (of reviews) available on the Web. The intuition is that although every domain is different, there is a decent amount of aspect overlapping across domains. For example, every product domain has the aspe</context>
</contexts>
<marker>Lu, Ott, Cardie, Tsou, 2011</marker>
<rawString>Bin Lu, Myle Ott, Claire Cardie, and Benjamin K Tsou. 2011. Multi-aspect Sentiment Analysis with Topic Models. In Proceedings of ICDM Workshops, pages 81–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Lu</author>
<author>Hongning Wang</author>
<author>ChengXiang Zhai</author>
<author>Dan Roth</author>
</authors>
<title>Unsupervised discovery of opposing opinion networks from forum discussions.</title>
<date>2012</date>
<booktitle>In Proceedings of CIKM,</booktitle>
<pages>1642--1646</pages>
<contexts>
<context position="7698" citStr="Lu et al., 2012" startWordPosition="1255" endWordPosition="1258">, 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). Geographical region knowledge has also been considered in topic models (Eisenstein et al., 2010). All of these models assume that the prior knowledge is correct. GK-LDA</context>
</contexts>
<marker>Lu, Wang, Zhai, Roth, 2012</marker>
<rawString>Yue Lu, Hongning Wang, ChengXiang Zhai, and Dan Roth. 2012. Unsupervised discovery of opposing opinion networks from forum discussions. In Proceedings of CIKM, pages 1642–1646.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hosam Mahmoud</author>
</authors>
<title>Polya Urn Models.</title>
<date>2008</date>
<journal>Chapman &amp; Hall/CRC Texts in Statistical Science.</journal>
<contexts>
<context position="21849" citStr="Mahmoud, 2008" startWordPosition="3733" endWordPosition="3734">distribution over all terms in ci for DISTc. For DISTz, as only top 20 terms under zi are usually reliable, we use these top terms 351 with their probabilities (re-normalized) to represent the topic. Note that a smoothing probability (i.e., a very small value) is also given to every term for calculating KL-Divergence. Given DISTc and DISTz, the agreement is computed with: 1 Agreement(c, z) = KL(DISTc, DISTz) (2) The rationale of Equation 2 is that the lesser divergence between DISTc and DISTz implies the more agreement between ci and zi. We further employ the Generalized Plya urn (GPU) model (Mahmoud, 2008) which was shown to be effective in leveraging semantically related words (Chen et al., 2013a, Chen et al., 2013b, Mimno et al., 2011). The GPU model here basically states that assigning topic zi and cluster ci to term wi will not only increase the probability of connecting zi and ci with wi, but also make it more likely to associate zi and ci with term w0 where w0 shares a 2-pattern with wi in ci. The amount of probability increase is determined by matrix Ac,w0,w defined as: ⎧ 1, if w = w0 (3) ⎨⎪ v, if (w, w0) E c, w =� w0 ❆c,w0,w = 0, otherwise ⎪⎩ where value 1 controls the probability incre</context>
</contexts>
<marker>Mahmoud, 2008</marker>
<rawString>Hosam Mahmoud. 2008. Polya Urn Models. Chapman &amp; Hall/CRC Texts in Statistical Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiaozhu Mei</author>
<author>Xu Ling</author>
<author>Matthew Wondra</author>
<author>Hang Su</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Topic sentiment mixture: modeling facets and opinions in weblogs.</title>
<date>2007</date>
<booktitle>In Proceedings of WWW,</booktitle>
<pages>171--180</pages>
<contexts>
<context position="7735" citStr="Mei et al., 2007" startWordPosition="1263" endWordPosition="1266">r, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). Geographical region knowledge has also been considered in topic models (Eisenstein et al., 2010). All of these models assume that the prior knowledge is correct. GK-LDA (Chen et al., 2013a) is the only kno</context>
</contexts>
<marker>Mei, Ling, Wondra, Su, Zhai, 2007</marker>
<rawString>Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su, and ChengXiang Zhai. 2007. Topic sentiment mixture: modeling facets and opinions in weblogs. In Proceedings of WWW, pages 171–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Mimno</author>
<author>Hanna M Wallach</author>
<author>Edmund Talley</author>
<author>Miriam Leenders</author>
<author>Andrew McCallum</author>
</authors>
<title>Optimizing semantic coherence in topic models.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>262--272</pages>
<contexts>
<context position="20301" citStr="Mimno et al., 2011" startWordPosition="3454" endWordPosition="3457"> Equation 1 below). If ci corroborates wi well, ci is likely to be useful, and thus should also provide guidance in determining zi. Otherwise, ci may not be a suitable piece of knowledge for wi in the domain. 2. Agreement between ci and zi. By agreement we mean the degree that the terms (union of all frequent 2-patterns of ci) in cluster ci are reflected in topic zi. Unlike the first factor, this is a global factor as it concerns all the terms in a knowledge cluster. For the first factor, we measure how well ci corroborates wi given the corpus based on codocument frequency ratio. As shown in (Mimno et al., 2011), co-document frequency is a good indicator of term correlation in a domain. Following (Mimno et al., 2011), we define a symmetric co-document frequency ratio as follows: D(w, w&apos;) + 1 Co-Doc(w, w&apos;) = (D(w) + D(w&apos;)) × 2 + 1 (1) where (w, w&apos;) refers to each frequent 2-pattern in the knowledge cluster ci. D(w, w&apos;) is the number of documents that contain both terms w and w&apos; and D(w) is the number of documents containing w. A smoothing count of 1 is added to avoid the ratio being 0. For the second factor, if cluster ci and topic zi agree, the intuition is that the terms in ci (union of all frequent</context>
<context position="21983" citStr="Mimno et al., 2011" startWordPosition="3754" endWordPosition="3757">s 351 with their probabilities (re-normalized) to represent the topic. Note that a smoothing probability (i.e., a very small value) is also given to every term for calculating KL-Divergence. Given DISTc and DISTz, the agreement is computed with: 1 Agreement(c, z) = KL(DISTc, DISTz) (2) The rationale of Equation 2 is that the lesser divergence between DISTc and DISTz implies the more agreement between ci and zi. We further employ the Generalized Plya urn (GPU) model (Mahmoud, 2008) which was shown to be effective in leveraging semantically related words (Chen et al., 2013a, Chen et al., 2013b, Mimno et al., 2011). The GPU model here basically states that assigning topic zi and cluster ci to term wi will not only increase the probability of connecting zi and ci with wi, but also make it more likely to associate zi and ci with term w0 where w0 shares a 2-pattern with wi in ci. The amount of probability increase is determined by matrix Ac,w0,w defined as: ⎧ 1, if w = w0 (3) ⎨⎪ v, if (w, w0) E c, w =� w0 ❆c,w0,w = 0, otherwise ⎪⎩ where value 1 controls the probability increase of w by seeing w itself, and σ controls the probability increase of w0 by seeing w. Please refer to (Chen et al., 2013b) for more </context>
<context position="27133" citStr="Mimno et al., 2011" startWordPosition="4669" endWordPosition="4672">cally to min(5, 0.4 × #T), where #T is the number of transactions (i.e., the number of topics from all domains) in a cluster. Test Settings: We use two test settings as below: 1. (Sections 6.2, 6.3 and 6.4) Test on the same corpora as those used in learning the prior knowledge. This is meaningful as the learning phrase is automatic and unsupervised (Figure 1). We call this self-learning-and-improvement. 2. (Section 6.5) Test on new/unseen domain corpora after knowledge learning. 6.2 Topic Coherence This sub-section evaluates the topics/aspects generated by each model based on Topic Coherence (Mimno et al., 2011) in test setting 1. Traditionally, topic models have been evaluated using perplexity. However, perplexity on the heldout test set does not reflect the semantic coherence of topics and may be contrary to human judgments (Chang et al., 2009). Instead, the metric Topic Coherence has been shown in (Mimno -1430 -1450 -1470 -1490 -1510 0 1 2 3 4 5 6 AKL GK-LDA MC-LDA LDA Figure 3: Average Topic Coherence of each model at different learning iterations (Iteration 0 is equivalent to LDA). et al., 2011) to correlate well with human judgments. Recently, it has become a standard practice to use Topic Cohe</context>
</contexts>
<marker>Mimno, Wallach, Talley, Leenders, McCallum, 2011</marker>
<rawString>David Mimno, Hanna M. Wallach, Edmund Talley, Miriam Leenders, and Andrew McCallum. 2011. Optimizing semantic coherence in topic models. In Proceedings of EMNLP, pages 262–272.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samaneh Moghaddam</author>
<author>Martin Ester</author>
</authors>
<title>The FLDA Model for Aspect-based Opinion Mining: Addressing the Cold Start Problem.</title>
<date>2013</date>
<booktitle>In Proceedings of WWW,</booktitle>
<pages>909--918</pages>
<contexts>
<context position="7762" citStr="Moghaddam and Ester, 2013" startWordPosition="1267" endWordPosition="1271">y perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). Geographical region knowledge has also been considered in topic models (Eisenstein et al., 2010). All of these models assume that the prior knowledge is correct. GK-LDA (Chen et al., 2013a) is the only knowledge-based topic model th</context>
</contexts>
<marker>Moghaddam, Ester, 2013</marker>
<rawString>Samaneh Moghaddam and Martin Ester. 2013. The FLDA Model for Aspect-based Opinion Mining: Addressing the Cold Start Problem. In Proceedings of WWW, pages 909–918.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arjun Mukherjee</author>
<author>Bing Liu</author>
</authors>
<title>Aspect Extraction through Semi-Supervised Modeling.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>339--348</pages>
<contexts>
<context position="3038" citStr="Mukherjee and Liu, 2012" startWordPosition="477" endWordPosition="481">ackle the problem, several semi-supervised topic models, also called knowledge-based topic models, have been proposed. DF-LDA (Andrzejewski et al., 2009) can incorporate two forms of prior knowledge from the user: must-links and cannot-links. A must-link implies that two terms (or words) should belong to the same topic whereas a cannot-link indicates that two terms should not be in the same topic. In a similar but more generic vein, must-sets and cannot-sets are used in MC-LDA (Chen et al., 2013b). Other related works include (Andrzejewski et al., 2011, Chen et al., 2013a, Chen et al., 2013c, Mukherjee and Liu, 2012, Hu et al., 2011, Jagarlamudi et al., 2012, Lu et al., 2011, Petterson et al., 2010). They all allow prior knowledge to be specified by the user to guide the modeling process. In this paper, we take a major step further. We mine the prior knowledge directly from a large amount of relevant data without any user intervention, and thus make this approach fully automatic. We hypothesize that it is possible to learn quality prior knowledge from the big data (of reviews) available on the Web. The intuition is that although every domain is different, there is a decent amount of aspect overlapping ac</context>
<context position="7787" citStr="Mukherjee and Liu, 2012" startWordPosition="1272" endWordPosition="1275">t aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). Geographical region knowledge has also been considered in topic models (Eisenstein et al., 2010). All of these models assume that the prior knowledge is correct. GK-LDA (Chen et al., 2013a) is the only knowledge-based topic model that deals with wrong lexic</context>
<context position="31497" citStr="Mukherjee and Liu, 2012" startWordPosition="5419" endWordPosition="5422">PS. We chose Headphone as it has a lot of overlapping of topics with other domains because many electronic products use headphone. GPS was chosen because it does not have much topic overlapping with other domains as its aspects are mostly about Navigation and Maps. Domains Camera and Computer lay in between. We want to see how domain overlapping influences the performance of AKL. Cohen’s Kappa scores for annotator agreement are 0.918 (for topics) and 0.872 (for terms). To measure the results, we compute Precision@n (or p@n) based on the annotations, which was also used in (Chen et al., 2013b, Mukherjee and Liu, 2012). Figure 4 shows the precision@n results for n = 5 and 10. We can see that AKL makes improvements in all 4 domains. The improvement varies in domains with the most increase in Headphone and the least in GPS as Headphone overlaps more with other domains than GPS. Note that if a domain shares aspects with many other domains, its model should benefit more; otherwise, it is reasonable to expect lesser improvements. For the baselines, GK-LDA and MC-LDA perform similarly to LDA with minor variations, all of which are inferior to AKL. AKL’s improvements over other models are statistically significant</context>
</contexts>
<marker>Mukherjee, Liu, 2012</marker>
<rawString>Arjun Mukherjee and Bing Liu. 2012. Aspect Extraction through Semi-Supervised Modeling. In Proceedings of ACL, pages 339–348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sinno Jialin Pan</author>
<author>Qiang Yang</author>
</authors>
<title>A Survey on Transfer Learning.</title>
<date>2010</date>
<journal>IEEE Trans. Knowl. Data Eng.,</journal>
<volume>22</volume>
<issue>10</issue>
<contexts>
<context position="9298" citStr="Pan and Yang, 2010" startWordPosition="1554" endWordPosition="1557">d to help 348 Input: Corpora DL for knowledge learning Test corpora DT 1: // STEP 1: Learning prior knowledge. 2: for r = 0 to R do // Iterate R + 1 times. 3: for each domain corpus Di E DL do 4: if r = 0 then 5: Ai +— LDA(Di); 6: else 7: Ai +— AKL(Di, K); 8: end if 9: end for 10: A +— UiAi; 11: TC +— Clustering(A); 12: for each cluster Tj E TC do 13: Kj +— FPM(Tj); 14: end for 15: K +— UjKj; 16: end for 17: // STEP 2: Using the learned knowledge. 18: for each test corpus Di E DT do 19: Ai +— AKL(Di, K); 20: end for Figure 1: The proposed overall algorithm. transfer learning (He et al., 2011, Pan and Yang, 2010, Xue et al., 2008). However, transfer learning in these papers is for traditional classification rather than topic/aspect extraction. In (Kang et al., 2012), labeled documents from source domains are transferred to the target domain to produce topic models with better fitting. However, we do not use any labeled data. In (Yang et al., 2011), a user provided parameter indicating the technicality degree of a domain was used to model the language gap between topics. In contrast, our method is fully automatic without human intervention. 3 Overall Algorithm This section introduces the proposed over</context>
</contexts>
<marker>Pan, Yang, 2010</marker>
<rawString>Sinno Jialin Pan and Qiang Yang. 2010. A Survey on Transfer Learning. IEEE Trans. Knowl. Data Eng., 22(10):1345–1359.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<booktitle>Foundations and Trends in Information Retrieval,</booktitle>
<pages>2--1</pages>
<contexts>
<context position="6650" citStr="Pang and Lee, 2008" startWordPosition="1066" endWordPosition="1069">to learn prior knowledge and leverage the knowledge in topic models to extract more coherent aspects. The process is fully automatic. To the best of our knowledge, none of the existing models for aspect extraction is able to achieve this. 2. It proposes an effective method to learn quality knowledge from raw topics produced using review corpora from many different domains. 3. It proposes a new inference mechanism for topic modeling, which can handle incorrect knowledge in aspect extraction. 2 Related Work Aspect extraction has been studied by many researchers in sentiment analysis (Liu, 2012, Pang and Lee, 2008), e.g., using supervised sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, 2(1-2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Petterson</author>
<author>Alex Smola</author>
<author>Tib´erio Caetano</author>
<author>Wray Buntine</author>
<author>Shravan Narayanamurthy</author>
</authors>
<title>Word Features for Latent Dirichlet Allocation.</title>
<date>2010</date>
<booktitle>In Proceedings of NIPS,</booktitle>
<pages>1921--1929</pages>
<contexts>
<context position="3123" citStr="Petterson et al., 2010" startWordPosition="494" endWordPosition="497">topic models, have been proposed. DF-LDA (Andrzejewski et al., 2009) can incorporate two forms of prior knowledge from the user: must-links and cannot-links. A must-link implies that two terms (or words) should belong to the same topic whereas a cannot-link indicates that two terms should not be in the same topic. In a similar but more generic vein, must-sets and cannot-sets are used in MC-LDA (Chen et al., 2013b). Other related works include (Andrzejewski et al., 2011, Chen et al., 2013a, Chen et al., 2013c, Mukherjee and Liu, 2012, Hu et al., 2011, Jagarlamudi et al., 2012, Lu et al., 2011, Petterson et al., 2010). They all allow prior knowledge to be specified by the user to guide the modeling process. In this paper, we take a major step further. We mine the prior knowledge directly from a large amount of relevant data without any user intervention, and thus make this approach fully automatic. We hypothesize that it is possible to learn quality prior knowledge from the big data (of reviews) available on the Web. The intuition is that although every domain is different, there is a decent amount of aspect overlapping across domains. For example, every product domain has the aspect/topic of “price,” most</context>
</contexts>
<marker>Petterson, Smola, Caetano, Buntine, Narayanamurthy, 2010</marker>
<rawString>James Petterson, Alex Smola, Tib´erio Caetano, Wray Buntine, and Shravan Narayanamurthy. 2010. Word Features for Latent Dirichlet Allocation. In Proceedings of NIPS, pages 1921–1929.</rawString>
</citation>
<citation valid="true">
<authors>
<author>AM Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT,</booktitle>
<pages>339--346</pages>
<contexts>
<context position="6952" citStr="Popescu and Etzioni, 2005" startWordPosition="1117" endWordPosition="1120">edge from raw topics produced using review corpora from many different domains. 3. It proposes a new inference mechanism for topic modeling, which can handle incorrect knowledge in aspect extraction. 2 Related Work Aspect extraction has been studied by many researchers in sentiment analysis (Liu, 2012, Pang and Lee, 2008), e.g., using supervised sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 201</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>AM Popescu and Oren Etzioni. 2005. Extracting product features and opinions from reviews. In Proceedings of HLT, pages 339–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guang Qiu</author>
<author>Bing Liu</author>
<author>Jiajun Bu</author>
<author>Chun Chen</author>
</authors>
<title>Opinion Word Expansion and Target Extraction through Double Propagation.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<volume>37</volume>
<issue>1</issue>
<contexts>
<context position="6970" citStr="Qiu et al., 2011" startWordPosition="1121" endWordPosition="1124">ed using review corpora from many different domains. 3. It proposes a new inference mechanism for topic modeling, which can handle incorrect knowledge in aspect extraction. 2 Related Work Aspect extraction has been studied by many researchers in sentiment analysis (Liu, 2012, Pang and Lee, 2008), e.g., using supervised sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011</context>
</contexts>
<marker>Qiu, Liu, Bu, Chen, 2011</marker>
<rawString>Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2011. Opinion Word Expansion and Target Extraction through Double Propagation. Computational Linguistics, 37(1):9–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Ramage</author>
<author>David Hall</author>
<author>Ramesh Nallapati</author>
<author>Christopher D Manning</author>
</authors>
<title>Labeled LDA: a supervised topic model for credit attribution in multilabeled corpora.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>248--256</pages>
<contexts>
<context position="8128" citStr="Ramage et al., 2009" startWordPosition="1325" endWordPosition="1328">010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). Geographical region knowledge has also been considered in topic models (Eisenstein et al., 2010). All of these models assume that the prior knowledge is correct. GK-LDA (Chen et al., 2013a) is the only knowledge-based topic model that deals with wrong lexical knowledge to some extent. As we will see in Section 6, AKL outperformed GKLDA significantly due to AKL’s more effective error handling mechanism. Furthermore, GK-LDA does not learn any prior knowledge. Our work is also related to transfer learning to some extent. Topic models have been used to help 348 Input: Corpora DL for knowledge le</context>
</contexts>
<marker>Ramage, Hall, Nallapati, Manning, 2009</marker>
<rawString>Daniel Ramage, David Hall, Ramesh Nallapati, and Christopher D. Manning. 2009. Labeled LDA: a supervised topic model for credit attribution in multilabeled corpora. In Proceedings of EMNLP, pages 248–256.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michal Rosen-Zvi</author>
<author>Chaitanya Chemudugunta</author>
<author>Thomas Griffiths</author>
<author>Padhraic Smyth</author>
<author>Mark Steyvers</author>
</authors>
<title>Learning author-topic models from text corpora.</title>
<date>2010</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>28</volume>
<issue>1</issue>
<contexts>
<context position="19006" citStr="Rosen-Zvi et al., 2010" startWordPosition="3221" endWordPosition="3224">ng more expressive knowledge in the form of clusters, (2) a novel Gibbs sampler to deal with inappropriate knowledge. 5.2 The Gibbs Sampler As the automatically learned prior knowledge may contain errors for a domain, AKL has to learn the usefulness of each piece of knowledge dynamically during inference. Instead of assigning weights to each piece of knowledge as a fixed prior in (Chen et al., 2013a), we propose a new Gibbs sampler, which can dynamically balance the use of prior knowledge and the information in the corpus during the Gibbs sampling iterations. We adopt a Blocked Gibbs sampler (Rosen-Zvi et al., 2010) as it improves convergence and reduces autocorrelation when the variables (topic z and cluster c in AKL) are highly related. For each term wi in each document, we jointly sample a topic zi and cluster ci (containing wi) based on the conditional distribution in Gibbs sampler (will be detailed in Equation 4). To compute this distribution, instead of considering how well zi matches with wi only (as in LDA), we also consider two other factors: 1. The extent ci corroborates wi given the corpus. By “corroborate”, we mean whether those frequent 2-patterns in ci containing wi are also supported by th</context>
</contexts>
<marker>Rosen-Zvi, Chemudugunta, Griffiths, Smyth, Steyvers, 2010</marker>
<rawString>Michal Rosen-Zvi, Chaitanya Chemudugunta, Thomas Griffiths, Padhraic Smyth, and Mark Steyvers. 2010. Learning author-topic models from text corpora. ACM Transactions on Information Systems, 28(1):1–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christina Sauper</author>
<author>Regina Barzilay</author>
</authors>
<title>Automatic Aggregation by Joint Modeling of Aspects and Values.</title>
<date>2013</date>
<journal>J. Artif. Intell. Res. (JAIR),</journal>
<pages>46--89</pages>
<contexts>
<context position="7814" citStr="Sauper and Barzilay, 2013" startWordPosition="1276" endWordPosition="1279"> resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). Geographical region knowledge has also been considered in topic models (Eisenstein et al., 2010). All of these models assume that the prior knowledge is correct. GK-LDA (Chen et al., 2013a) is the only knowledge-based topic model that deals with wrong lexical knowledge to some extent</context>
</contexts>
<marker>Sauper, Barzilay, 2013</marker>
<rawString>Christina Sauper and Regina Barzilay. 2013. Automatic Aggregation by Joint Modeling of Aspects and Values. J. Artif. Intell. Res. (JAIR), 46:89–127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Swapna Somasundaran</author>
<author>J Wiebe</author>
</authors>
<title>Recognizing stances in online debates.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>226--234</pages>
<contexts>
<context position="7000" citStr="Somasundaran and Wiebe, 2009" startWordPosition="1125" endWordPosition="1129">rpora from many different domains. 3. It proposes a new inference mechanism for topic modeling, which can handle incorrect knowledge in aspect extraction. 2 Related Work Aspect extraction has been studied by many researchers in sentiment analysis (Liu, 2012, Pang and Lee, 2008), e.g., using supervised sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al.,</context>
</contexts>
<marker>Somasundaran, Wiebe, 2009</marker>
<rawString>Swapna Somasundaran and J Wiebe. 2009. Recognizing stances in online debates. In Proceedings of ACL, pages 226–234.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Ryan McDonald</author>
</authors>
<title>A joint model of text and aspect ratings for sentiment summarization.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>308--316</pages>
<contexts>
<context position="7840" citStr="Titov and McDonald, 2008" startWordPosition="1280" endWordPosition="1283">t term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). Geographical region knowledge has also been considered in topic models (Eisenstein et al., 2010). All of these models assume that the prior knowledge is correct. GK-LDA (Chen et al., 2013a) is the only knowledge-based topic model that deals with wrong lexical knowledge to some extent. As we will see in Sectio</context>
</contexts>
<marker>Titov, McDonald, 2008</marker>
<rawString>Ivan Titov and Ryan McDonald. 2008. A joint model of text and aspect ratings for sentiment summarization. In Proceedings of ACL, pages 308–316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongning Wang</author>
<author>Yue Lu</author>
<author>Chengxiang Zhai</author>
</authors>
<title>Latent aspect rating analysis on review text data: a rating regression approach.</title>
<date>2010</date>
<booktitle>In Proceedings of KDD,</booktitle>
<pages>783--792</pages>
<contexts>
<context position="7859" citStr="Wang et al., 2010" startWordPosition="1284" endWordPosition="1287">one in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). Geographical region knowledge has also been considered in topic models (Eisenstein et al., 2010). All of these models assume that the prior knowledge is correct. GK-LDA (Chen et al., 2013a) is the only knowledge-based topic model that deals with wrong lexical knowledge to some extent. As we will see in Section 6, AKL outperform</context>
</contexts>
<marker>Wang, Lu, Zhai, 2010</marker>
<rawString>Hongning Wang, Yue Lu, and Chengxiang Zhai. 2010. Latent aspect rating analysis on review text data: a rating regression approach. In Proceedings of KDD, pages 783–792.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuanbin Wu</author>
<author>Qi Zhang</author>
<author>Xuanjing Huang</author>
<author>Lide Wu</author>
</authors>
<title>Phrase dependency parsing for opinion mining.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1533--1541</pages>
<contexts>
<context position="7017" citStr="Wu et al., 2009" startWordPosition="1130" endWordPosition="1133">ins. 3. It proposes a new inference mechanism for topic modeling, which can handle incorrect knowledge in aspect extraction. 2 Related Work Aspect extraction has been studied by many researchers in sentiment analysis (Liu, 2012, Pang and Lee, 2008), e.g., using supervised sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou </context>
</contexts>
<marker>Wu, Zhang, Huang, Wu, 2009</marker>
<rawString>Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu. 2009. Phrase dependency parsing for opinion mining. In Proceedings of EMNLP, pages 1533–1541.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liheng Xu</author>
<author>Kang Liu</author>
<author>Siwei Lai</author>
<author>Yubo Chen</author>
<author>Jun Zhao</author>
</authors>
<title>Mining Opinion Words and Opinion Targets in a Two-Stage Framework.</title>
<date>2013</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>1764--1773</pages>
<contexts>
<context position="7034" citStr="Xu et al., 2013" startWordPosition="1134" endWordPosition="1137">es a new inference mechanism for topic modeling, which can handle incorrect knowledge in aspect extraction. 2 Related Work Aspect extraction has been studied by many researchers in sentiment analysis (Liu, 2012, Pang and Lee, 2008), e.g., using supervised sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li </context>
</contexts>
<marker>Xu, Liu, Lai, Chen, Zhao, 2013</marker>
<rawString>Liheng Xu, Kang Liu, Siwei Lai, Yubo Chen, and Jun Zhao. 2013. Mining Opinion Words and Opinion Targets in a Two-Stage Framework. In Proceedings ofACL, pages 1764–1773.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GR Xue</author>
<author>Wenyuan Dai</author>
<author>Q Yang</author>
<author>Y Yu</author>
</authors>
<title>Topic-bridged PLSA for cross-domain text classification.</title>
<date>2008</date>
<booktitle>In Proceedings of SIGIR,</booktitle>
<pages>627--634</pages>
<contexts>
<context position="9317" citStr="Xue et al., 2008" startWordPosition="1558" endWordPosition="1561"> Corpora DL for knowledge learning Test corpora DT 1: // STEP 1: Learning prior knowledge. 2: for r = 0 to R do // Iterate R + 1 times. 3: for each domain corpus Di E DL do 4: if r = 0 then 5: Ai +— LDA(Di); 6: else 7: Ai +— AKL(Di, K); 8: end if 9: end for 10: A +— UiAi; 11: TC +— Clustering(A); 12: for each cluster Tj E TC do 13: Kj +— FPM(Tj); 14: end for 15: K +— UjKj; 16: end for 17: // STEP 2: Using the learned knowledge. 18: for each test corpus Di E DT do 19: Ai +— AKL(Di, K); 20: end for Figure 1: The proposed overall algorithm. transfer learning (He et al., 2011, Pan and Yang, 2010, Xue et al., 2008). However, transfer learning in these papers is for traditional classification rather than topic/aspect extraction. In (Kang et al., 2012), labeled documents from source domains are transferred to the target domain to produce topic models with better fitting. However, we do not use any labeled data. In (Yang et al., 2011), a user provided parameter indicating the technicality degree of a domain was used to model the language gap between topics. In contrast, our method is fully automatic without human intervention. 3 Overall Algorithm This section introduces the proposed overall algorithm. It c</context>
</contexts>
<marker>Xue, Dai, Yang, Yu, 2008</marker>
<rawString>GR Xue, Wenyuan Dai, Q Yang, and Y Yu. 2008. Topic-bridged PLSA for cross-domain text classification. In Proceedings of SIGIR, pages 627–634.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bishan Yang</author>
<author>Claire Cardie</author>
</authors>
<title>Joint Inference for Fine-grained Opinion Extraction.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>1640--1649</pages>
<contexts>
<context position="6824" citStr="Yang and Cardie, 2013" startWordPosition="1093" endWordPosition="1096"> the existing models for aspect extraction is able to achieve this. 2. It proposes an effective method to learn quality knowledge from raw topics produced using review corpora from many different domains. 3. It proposes a new inference mechanism for topic modeling, which can handle incorrect knowledge in aspect extraction. 2 Related Work Aspect extraction has been studied by many researchers in sentiment analysis (Liu, 2012, Pang and Lee, 2008), e.g., using supervised sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic </context>
</contexts>
<marker>Yang, Cardie, 2013</marker>
<rawString>Bishan Yang and Claire Cardie. 2013. Joint Inference for Fine-grained Opinion Extraction. In Proceedings of ACL, pages 1640–1649.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shuang Hong Yang</author>
<author>Steven P Crain</author>
<author>Hongyuan Zha</author>
</authors>
<title>Bridging the language gap: Topic adaptation for documents with different technicality.</title>
<date>2011</date>
<booktitle>In Proceedings of AISTATS,</booktitle>
<pages>823--831</pages>
<contexts>
<context position="9640" citStr="Yang et al., 2011" startWordPosition="1609" endWordPosition="1612">E TC do 13: Kj +— FPM(Tj); 14: end for 15: K +— UjKj; 16: end for 17: // STEP 2: Using the learned knowledge. 18: for each test corpus Di E DT do 19: Ai +— AKL(Di, K); 20: end for Figure 1: The proposed overall algorithm. transfer learning (He et al., 2011, Pan and Yang, 2010, Xue et al., 2008). However, transfer learning in these papers is for traditional classification rather than topic/aspect extraction. In (Kang et al., 2012), labeled documents from source domains are transferred to the target domain to produce topic models with better fitting. However, we do not use any labeled data. In (Yang et al., 2011), a user provided parameter indicating the technicality degree of a domain was used to model the language gap between topics. In contrast, our method is fully automatic without human intervention. 3 Overall Algorithm This section introduces the proposed overall algorithm. It consists of two main steps: learning quality knowledge and using the learned knowledge. Figure 1 gives the algorithm. Step 1 (learning quality knowledge, Lines 1- 16): The input is the review corpora DL from multiple domains, from which the knowledge is automatically learned. Lines 3 and 5 run LDA on each review domain cor</context>
</contexts>
<marker>Yang, Crain, Zha, 2011</marker>
<rawString>Shuang Hong Yang, Steven P. Crain, and Hongyuan Zha. 2011. Bridging the language gap: Topic adaptation for documents with different technicality. In Proceedings of AISTATS, pages 823–831.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianxing Yu</author>
<author>Zheng-Jun Zha</author>
<author>Meng Wang</author>
<author>TatSeng Chua</author>
</authors>
<title>Aspect Ranking: Identifying Important Product Aspects from Online Consumer Reviews.</title>
<date>2011</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>1496--1505</pages>
<contexts>
<context position="7051" citStr="Yu et al., 2011" startWordPosition="1138" endWordPosition="1141">e mechanism for topic modeling, which can handle incorrect knowledge in aspect extraction. 2 Related Work Aspect extraction has been studied by many researchers in sentiment analysis (Liu, 2012, Pang and Lee, 2008), e.g., using supervised sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin</context>
</contexts>
<marker>Yu, Zha, Wang, Chua, 2011</marker>
<rawString>Jianxing Yu, Zheng-Jun Zha, Meng Wang, and TatSeng Chua. 2011. Aspect Ranking: Identifying Important Product Aspects from Online Consumer Reviews. In Proceedings ofACL, pages 1496–1505.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhongwu Zhai</author>
<author>Bing Liu</author>
<author>Hua Xu</author>
<author>Peifa Jia</author>
</authors>
<title>Constrained LDA for grouping product features in opinion mining.</title>
<date>2011</date>
<booktitle>In Proceedings of PAKDD,</booktitle>
<pages>448--459</pages>
<contexts>
<context position="7309" citStr="Zhai et al., 2011" startWordPosition="1184" endWordPosition="1187">g or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belon</context>
</contexts>
<marker>Zhai, Liu, Xu, Jia, 2011</marker>
<rawString>Zhongwu Zhai, Bing Liu, Hua Xu, and Peifa Jia. 2011. Constrained LDA for grouping product features in opinion mining. In Proceedings of PAKDD, pages 448–459.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wayne Xin Zhao</author>
<author>Jing Jiang</author>
<author>Hongfei Yan</author>
<author>Xiaoming Li</author>
</authors>
<title>Jointly Modeling Aspects and Opinions with a MaxEnt-LDA Hybrid.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>56--65</pages>
<contexts>
<context position="7879" citStr="Zhao et al., 2010" startWordPosition="1288" endWordPosition="1291"> al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai, 2008, Mei et al., 2007, Moghaddam and Ester, 2013, Mukherjee and Liu, 2012, Sauper and Barzilay, 2013, Titov and McDonald, 2008, Wang et al., 2010, Zhao et al., 2010). Our proposed AKL model belongs to the class of knowledge-based topic models. Besides the knowledge-based topic models discussed in Section 1, document labels are incorporated as implicit knowledge in (Blei and McAuliffe, 2007, Ramage et al., 2009). Geographical region knowledge has also been considered in topic models (Eisenstein et al., 2010). All of these models assume that the prior knowledge is correct. GK-LDA (Chen et al., 2013a) is the only knowledge-based topic model that deals with wrong lexical knowledge to some extent. As we will see in Section 6, AKL outperformed GKLDA significant</context>
</contexts>
<marker>Zhao, Jiang, Yan, Li, 2010</marker>
<rawString>Wayne Xin Zhao, Jing Jiang, Hongfei Yan, and Xiaoming Li. 2010. Jointly Modeling Aspects and Opinions with a MaxEnt-LDA Hybrid. In Proceedings of EMNLP, pages 56–65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yanyan Zhao</author>
<author>Bing Qin</author>
<author>Ting Liu</author>
</authors>
<title>Collocation polarity disambiguation using web-based pseudo contexts.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLPCoNLL,</booktitle>
<pages>160--170</pages>
<contexts>
<context position="7070" citStr="Zhao et al., 2012" startWordPosition="1142" endWordPosition="1145">opic modeling, which can handle incorrect knowledge in aspect extraction. 2 Related Work Aspect extraction has been studied by many researchers in sentiment analysis (Liu, 2012, Pang and Lee, 2008), e.g., using supervised sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu e</context>
</contexts>
<marker>Zhao, Qin, Liu, 2012</marker>
<rawString>Yanyan Zhao, Bing Qin, and Ting Liu. 2012. Collocation polarity disambiguation using web-based pseudo contexts. In Proceedings of EMNLPCoNLL, pages 160–170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xinjie Zhou</author>
<author>Xiaojun Wan</author>
<author>Jianguo Xiao</author>
</authors>
<title>Collective Opinion Target Extraction in Chinese Microblogs.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1840--1850</pages>
<contexts>
<context position="7089" citStr="Zhou et al., 2013" startWordPosition="1146" endWordPosition="1149">h can handle incorrect knowledge in aspect extraction. 2 Related Work Aspect extraction has been studied by many researchers in sentiment analysis (Liu, 2012, Pang and Lee, 2008), e.g., using supervised sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et </context>
</contexts>
<marker>Zhou, Wan, Xiao, 2013</marker>
<rawString>Xinjie Zhou, Xiaojun Wan, and Jianguo Xiao. 2013. Collective Opinion Target Extraction in Chinese Microblogs. In Proceedings of EMNLP, pages 1840– 1850.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Zhuang</author>
<author>Feng Jing</author>
<author>Xiao-Yan Zhu</author>
</authors>
<title>Movie review mining and summarization.</title>
<date>2006</date>
<booktitle>In Proceedings of CIKM,</booktitle>
<pages>43--50</pages>
<contexts>
<context position="7111" citStr="Zhuang et al., 2006" startWordPosition="1150" endWordPosition="1153">ect knowledge in aspect extraction. 2 Related Work Aspect extraction has been studied by many researchers in sentiment analysis (Liu, 2012, Pang and Lee, 2008), e.g., using supervised sequence labeling or classification (Choi and Cardie, 2010, Jakob and Gurevych, 2010, Kobayashi et al., 2007, Li et al., 2010, Yang and Cardie, 2013) and using word frequency and syntactic patterns (Hu and Liu, 2004, Ku et al., 2006, Liu et al., 2013, Popescu and Etzioni, 2005, Qiu et al., 2011, Somasundaran and Wiebe, 2009, Wu et al., 2009, Xu et al., 2013, Yu et al., 2011, Zhao et al., 2012, Zhou et al., 2013, Zhuang et al., 2006). However, these works only perform extraction but not aspect term grouping or resolution. Separate aspect term grouping has been done in (Carenini et al., 2005, Guo et al., 2009, Zhai et al., 2011). They assume that aspect terms have been extracted beforehand. To extract and group aspects simultaneously, topic models have been applied by researchers (Branavan et al., 2008, Brody and Elhadad, 2010, Chen et al., 2013b, Fang and Huang, 2012, He et al., 2011, Jo and Oh, 2011, Kim et al., 2013, Lazaridou et al., 2013, Li et al., 2011, Lin and He, 2009, Lu et al., 2009, Lu et al., 2012, Lu and Zhai</context>
</contexts>
<marker>Zhuang, Jing, Zhu, 2006</marker>
<rawString>Li Zhuang, Feng Jing, and Xiao-Yan Zhu. 2006. Movie review mining and summarization. In Proceedings of CIKM, pages 43–50.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>