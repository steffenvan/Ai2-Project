<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.144605">
<title confidence="0.837349">
SLINERC: The Sydney Language-Independent Named Entity
Recogniser and Classifier
</title>
<author confidence="0.994568">
Jon Patrick, Casey Whitelaw, and Robert Munro
</author>
<affiliation confidence="0.995378333333333">
Language Technology Research Group
Capital Markets Co-operative Research Centre
University of Sydney
</affiliation>
<email confidence="0.431732">
{jonpat, Casey, rmunro} it. usy d. edu. an
</email>
<sectionHeader confidence="0.989064" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998897333333333">
The Sydney Language Independent Named En-
tity Recogniser and Classifier (SLINERC) is a
multi-stage system for the recognition and clas-
sification of named entities. Each stage uses
a decision graph learner to combine statistical
features with results from prior stages. Earlier
stages are focused upon entity recognition, the
division of non-entity terms from entities. Later
stages concentrate on the classification of these
entities into the desired classes. The best over-
all f-values are 73.92 and 71.36 for the Spanish
and Dutch datasets, respectively.
</bodyText>
<sectionHeader confidence="0.997905" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999870142857143">
Identification of named entities is an increas-
ingly important task with applications in many
areas of human language technology, includ-
ing information extraction and machine trans-
lation. There has been a move away from hand-
coded systems toward machine learning systems
that can be trained to recognise named enti-
ties in any target language. The linguistic fea-
tures available to these language-independent
systems are obviously more restricted than for
language-specific systems. It becomes necessary
to work at a meta-linguistic level, and develop
techniques to automatically learn the peculiar-
ities of a target language. Techniques includ-
ing hidden Markov models (Bikel et al., 1997)
and maximum entropy theory (Borthwick et al.,
1998) have been successful in supervised clas-
sification; there have been various approaches
based on learning from seed lists and unanno-
tated data (Buchholz and van den Bosch, 2000)
(Cucerzan and Yarowsky, 1999).
</bodyText>
<sectionHeader confidence="0.97985" genericHeader="method">
2 SLINERC Developments
</sectionHeader>
<bodyText confidence="0.99935272">
SLINERC focuses on deeper statistical prop-
erties of languages, rather than traditional
surface-level linguistic features.
Surface-level features include the token itself,
capitalisation, sentence position and punctua-
tion. The extraction and use of these features
as attributes in a machine learner is straightfor-
ward, and requires minimal processing. There
are a large number of possible surface-level fea-
tures, but it is unrealistic to provide more than
a handful to machine learners. However, feature
selection is most often language-dependent.
Statistically derived attributes can overcome
the limitations of surface-level features. Al-
though the extraction of the attributes is more
involved, a smaller set of statistical features can
capture a wide range of implicit linguistic phe-
nomena. No surface feature selection is nec-
essary, allowing the attributes to stay largely
language-independent, whilst giving the ma-
chine learner a rich source of data.
As an example, SLINERC contains no cap-
italisation attributes, yet the capitalisation of
a word could contribute to many or all of the
statistical attributes for a given stage.
</bodyText>
<subsectionHeader confidence="0.991288">
2.1 Recognition and Classification
</subsectionHeader>
<bodyText confidence="0.999932666666667">
It is important to understand that what has
been referred to as &amp;quot;named entity recognition&amp;quot;
is in fact two separate tasks. The first, which
we call named entity recognition, is the division
of text into entities and non-entities. An entity
is divided into a headword (B-ENT) and zero
or more continuation words (1-ENT). The sec-
ond, named entity classification, is the task of
determining what the type of an entity is - per-
son, location, organisation, or other categories
as required. Obviously, a system&apos;s recognition
performance provides an upper bound to the
performance of its classification, but recogni-
tion is important in its own right, and should
be considered in the performance evaluation of
</bodyText>
<figure confidence="0.996841647058824">
1
0.9
0.8
0.7
0.6
0.5
0.4
0 1 2 3 4 5 6 7
Stage
O
ENT
B-ENT
I-ENT
B-PER
B-ORG
B-LOC
B-MISC
O
ENT
B-ENT
I-ENT
B-PER
B-ORG
B-LOC
B-MISC
0 1 2 3 4 5 6 7
Stage
1
0.9
0.8
0.7
0.6
0.5
0.4
</figure>
<bodyText confidence="0.998931333333333">
word-by-word basis, and no phrase grouping is
performed. The discrepancy between these and
the CoNLL results is due to errors in matching
entire phrases.
SLINERC performs particularly well at
named entity recognition, with f-values of 93.1
and 93.8 for Dutch and Spanish, respectively.
The result at Stage 3 provides a solid founda-
tion for classifications in later stages.
Table 1 shows performance on seen and un-
seen tokens. The performance on unseen to-
kens shows the benefits of statistical and contex-
tual features; gazetteer-based approaches per-
form very badly on unseen data. SLINERC out-
performs a simple learned-list based classifier,
even for seen data; this shows the importance
of contextual information in correct classifica-
tion. The relative difficulty of identifying MISC
entities is apparent in the low performance on
unseen data in Spanish; in Dutch, MISC entities
performed similarly to other categories.
</bodyText>
<sectionHeader confidence="0.995808" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999901444444444">
SLINERC is based entirely on statistical prop-
erties of the training data. It uses no external
data sources (gazetteers), nor does it make any
assumptions about the target language. It has
proven to be robustly language-independent,
with consistently competitive performance. The
techniques used could easily form the basis of
a more informed named entity recognition sys-
tem, through the use of either domain-specific
gazetteers, or language-specific linguistic fea-
tures.
After making our initial submission to the
CoNNL shared task, we reorganised our pro-
cessing system significantly. This caused a re-
duction in the f-value for Spanish development
data from 74.9 to 70.3. It is clear the interac-
tion effects of our multiple stages has significant
effects on the final results.
</bodyText>
<sectionHeader confidence="0.998412" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.990913714285714">
Daniel M. Bikel, Scott Miller, Richard
Schwartz, and Ralph Weischedel. 1997.
Nymble: a high-performance learning name-
finder. In Proceedings of ANLP-97, pages
194-201.
A. Borthwick, J. Sterling, E. Agichtein, and
R. Grishman. 1998. Exploiting diverse
</reference>
<table confidence="0.999758833333333">
Spanish dev precision recall F0-1
LOC 67.05% 76.32% 71.39
MISC 54.19% 43.60% 48.32
ORG 71.13% 68.71% 69.90
PER 82.91% 72.67% 77.45
overall 71.61% 68.97% 70.26
Spanish test precision recall F0-1
LOC 78.51% 72.79% 75.54
MISC 50.97% 38.64% 43.96
ORG 72.56% 79.14% 75.71
PER 80.44% 80.00% 80.22
overall 74.32% 73.52% 73.92
Dutch dev precision recall F0-1
LOC 66.47% 70.38% 68.37
MISC 68.97% 62.87% 65.78
ORG 72.80% 51.25% 60.16
PER 67.86% 69.49% 68.67
overall 68.87% 63.01% 65.81
Dutch test precision recall F0-1
LOC 76.12% 77.30% 76.71
MISC 71.04% 60.15% 65.15
ORG 70.42% 61.35% 65.57
PER 77.67% 78.44% 78.05
overall 74.01% 68.90% 71.36
</table>
<tableCaption confidence="0.927733">
Table 2: CoNNL results for Spanish and Dutch,
</tableCaption>
<reference confidence="0.821904529411765">
both test sets.
knowledge sources via maximum entropy in
named entity recognition.
S. Buchholz and A. van den Bosch. 2000. Inte-
grating seed names and n-grams for a named
entity list and classifier.
S. Cucerzan and D. Yarowsky. 1999. Lan-
guage independent named entity recognition
combining morphological and contextual evi-
dence.
A. Mikheev, M. Moens, and C. Grover. 1999.
Named entity recognition without gazetteers.
Jon D. Patrick and Ishaan Goyal. 2001.
Boosted decision graphs for nlp learning
tasks. In Walter Daelemans and Remi Zajac,
editors, Proceedings of CoNLL-2001, pages
58-60. Toulouse, France.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.473018">
<title confidence="0.99885">SLINERC: The Sydney Language-Independent Named Recogniser and Classifier</title>
<author confidence="0.993757">Jon Patrick</author>
<author confidence="0.993757">Casey Whitelaw</author>
<author confidence="0.993757">Robert</author>
<affiliation confidence="0.997913333333333">Language Technology Research Capital Markets Co-operative Research University of</affiliation>
<address confidence="0.508057">{jonpat, Casey, rmunro} it. usy d. edu. an</address>
<abstract confidence="0.995374923076923">The Sydney Language Independent Named Entity Recogniser and Classifier (SLINERC) is a multi-stage system for the recognition and classification of named entities. Each stage uses a decision graph learner to combine statistical features with results from prior stages. Earlier stages are focused upon entity recognition, the division of non-entity terms from entities. Later stages concentrate on the classification of these entities into the desired classes. The best overall f-values are 73.92 and 71.36 for the Spanish and Dutch datasets, respectively.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Daniel M Bikel</author>
<author>Scott Miller</author>
<author>Richard Schwartz</author>
<author>Ralph Weischedel</author>
</authors>
<title>Nymble: a high-performance learning namefinder.</title>
<date>1997</date>
<booktitle>In Proceedings of ANLP-97,</booktitle>
<pages>194--201</pages>
<contexts>
<context position="1533" citStr="Bikel et al., 1997" startWordPosition="221" endWordPosition="224">k with applications in many areas of human language technology, including information extraction and machine translation. There has been a move away from handcoded systems toward machine learning systems that can be trained to recognise named entities in any target language. The linguistic features available to these language-independent systems are obviously more restricted than for language-specific systems. It becomes necessary to work at a meta-linguistic level, and develop techniques to automatically learn the peculiarities of a target language. Techniques including hidden Markov models (Bikel et al., 1997) and maximum entropy theory (Borthwick et al., 1998) have been successful in supervised classification; there have been various approaches based on learning from seed lists and unannotated data (Buchholz and van den Bosch, 2000) (Cucerzan and Yarowsky, 1999). 2 SLINERC Developments SLINERC focuses on deeper statistical properties of languages, rather than traditional surface-level linguistic features. Surface-level features include the token itself, capitalisation, sentence position and punctuation. The extraction and use of these features as attributes in a machine learner is straightforward,</context>
</contexts>
<marker>Bikel, Miller, Schwartz, Weischedel, 1997</marker>
<rawString>Daniel M. Bikel, Scott Miller, Richard Schwartz, and Ralph Weischedel. 1997. Nymble: a high-performance learning namefinder. In Proceedings of ANLP-97, pages 194-201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Borthwick</author>
<author>J Sterling</author>
<author>E Agichtein</author>
<author>R Grishman</author>
</authors>
<title>Exploiting diverse both test sets. knowledge sources via maximum entropy in named entity recognition.</title>
<date>1998</date>
<contexts>
<context position="1585" citStr="Borthwick et al., 1998" startWordPosition="229" endWordPosition="232">age technology, including information extraction and machine translation. There has been a move away from handcoded systems toward machine learning systems that can be trained to recognise named entities in any target language. The linguistic features available to these language-independent systems are obviously more restricted than for language-specific systems. It becomes necessary to work at a meta-linguistic level, and develop techniques to automatically learn the peculiarities of a target language. Techniques including hidden Markov models (Bikel et al., 1997) and maximum entropy theory (Borthwick et al., 1998) have been successful in supervised classification; there have been various approaches based on learning from seed lists and unannotated data (Buchholz and van den Bosch, 2000) (Cucerzan and Yarowsky, 1999). 2 SLINERC Developments SLINERC focuses on deeper statistical properties of languages, rather than traditional surface-level linguistic features. Surface-level features include the token itself, capitalisation, sentence position and punctuation. The extraction and use of these features as attributes in a machine learner is straightforward, and requires minimal processing. There are a large </context>
</contexts>
<marker>Borthwick, Sterling, Agichtein, Grishman, 1998</marker>
<rawString>A. Borthwick, J. Sterling, E. Agichtein, and R. Grishman. 1998. Exploiting diverse both test sets. knowledge sources via maximum entropy in named entity recognition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Buchholz</author>
<author>A van den Bosch</author>
</authors>
<title>Integrating seed names and n-grams for a named entity list and classifier.</title>
<date>2000</date>
<marker>Buchholz, van den Bosch, 2000</marker>
<rawString>S. Buchholz and A. van den Bosch. 2000. Integrating seed names and n-grams for a named entity list and classifier.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Cucerzan</author>
<author>D Yarowsky</author>
</authors>
<title>Language independent named entity recognition combining morphological and contextual evidence.</title>
<date>1999</date>
<contexts>
<context position="1791" citStr="Cucerzan and Yarowsky, 1999" startWordPosition="261" endWordPosition="264">es in any target language. The linguistic features available to these language-independent systems are obviously more restricted than for language-specific systems. It becomes necessary to work at a meta-linguistic level, and develop techniques to automatically learn the peculiarities of a target language. Techniques including hidden Markov models (Bikel et al., 1997) and maximum entropy theory (Borthwick et al., 1998) have been successful in supervised classification; there have been various approaches based on learning from seed lists and unannotated data (Buchholz and van den Bosch, 2000) (Cucerzan and Yarowsky, 1999). 2 SLINERC Developments SLINERC focuses on deeper statistical properties of languages, rather than traditional surface-level linguistic features. Surface-level features include the token itself, capitalisation, sentence position and punctuation. The extraction and use of these features as attributes in a machine learner is straightforward, and requires minimal processing. There are a large number of possible surface-level features, but it is unrealistic to provide more than a handful to machine learners. However, feature selection is most often language-dependent. Statistically derived attrib</context>
</contexts>
<marker>Cucerzan, Yarowsky, 1999</marker>
<rawString>S. Cucerzan and D. Yarowsky. 1999. Language independent named entity recognition combining morphological and contextual evidence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Mikheev</author>
<author>M Moens</author>
<author>C Grover</author>
</authors>
<title>Named entity recognition without gazetteers.</title>
<date>1999</date>
<marker>Mikheev, Moens, Grover, 1999</marker>
<rawString>A. Mikheev, M. Moens, and C. Grover. 1999. Named entity recognition without gazetteers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon D Patrick</author>
<author>Ishaan Goyal</author>
</authors>
<title>Boosted decision graphs for nlp learning tasks.</title>
<date>2001</date>
<booktitle>In Walter Daelemans and Remi Zajac, editors, Proceedings of CoNLL-2001,</booktitle>
<pages>58--60</pages>
<location>Toulouse, France.</location>
<marker>Patrick, Goyal, 2001</marker>
<rawString>Jon D. Patrick and Ishaan Goyal. 2001. Boosted decision graphs for nlp learning tasks. In Walter Daelemans and Remi Zajac, editors, Proceedings of CoNLL-2001, pages 58-60. Toulouse, France.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>