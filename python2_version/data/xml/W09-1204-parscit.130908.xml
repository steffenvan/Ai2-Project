<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.057312">
<title confidence="0.996253">
Hybrid Multilingual Parsing with HPSG for SRL
</title>
<author confidence="0.990151">
Yi Zhang Rui Wang Stephan Oepen
</author>
<affiliation confidence="0.861753">
Language Technology Computational Linguistics Informatics
DFKI GmbH, Germany Saarland University, Germany University of Oslo, Norway
</affiliation>
<email confidence="0.931899">
yzhang@coli.uni-sb.de rwang@coli.uni-sb.de oe@ifi.uio.no
</email>
<sectionHeader confidence="0.982332" genericHeader="abstract">
Abstract
</sectionHeader>
<subsectionHeader confidence="0.613813">
In this paper we present our syntactic and se-
</subsectionHeader>
<figureCaption confidence="0.9237731">
mantic dependency parsing system submitted
to both the closed and open challenges of the
CoNLL 2009 Shared Task. The system ex-
tends the system of Zhang, Wang, &amp; Uszko-
reit (2008) in the multilingual direction, and
achieves 76.49 average macro F1 Score on the
closed joint task. Substantial improvements
to the open SRL task have been observed that
are attributed to the HPSG parses with hand-
crafted grammars. †
</figureCaption>
<sectionHeader confidence="0.996338" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.982332333333333">
The CoNLL 2009 shared task (Hajiˇc et al., 2009)
continues the exploration on learning syntactic and
semantic structures based on dependency notations
in previous year’s shared task. The new addition
to this year’s shared task is the extension to mul-
tiple languages. Being one of the leading compe-
titions in the field, the shared task received sub-
missions from systems built on top of the state-
of-the-art data-driven dependency parsing and se-
mantic role labeling systems. Although it was
originally designed as a task for machine learning
approaches, CoNLL shared tasks also feature an
‘open’ track since 2008, which encourages the use
of extra linguistic resources to further improve the
†We are indebted to our DELPH-IN colleagues, specifi-
cally Peter Adolphs, Francis Bond, Berthold Crysmann, and
Montserrat Marimon for numerous hours of support in adapt-
ing their grammars and the PET software to parsing the CoNLL
data sets. The first author thanks the German Excellence Clus-
ter of Multimodal Computing and Interaction for the support
of the work. The second author is funded by the PIRE PhD
scholarship program. Participation of the third author in this
work was supported by the University of Oslo, as part of its re-
search partnership with the Center for the Study of Language
and Information at Stanford University. Our deep parsing ex-
perimentation was executed on the TITAN HPC facilities at the
University of Oslo.
</bodyText>
<page confidence="0.998843">
31
</page>
<bodyText confidence="0.999468047619048">
performance. This makes the task a nice testbed for
the cross-fertilization of various language process-
ing techniques.
As an example of such work, Zhang et al. (2008)
have shown in the past that deep linguistic parsing
outputs can be integrated to help improve the per-
formance of the English semantic role labeling task.
But several questions remain unanswered. First, the
integration only experimented with the semantic role
labeling part of the task. It is not clear whether
syntactic dependency parsing can also benefit from
grammar-based parsing results. Second, the English
grammar used to achieve the improvement is one of
the largest and most mature hand-crafted linguistic
grammars. It is not clear whether similar improve-
ments can be achieved with less developed gram-
mars. More specifically, the lack of coverage of
hand-crafted linguistic grammars is a major concern.
On the other hand, the CoNLL task is also a good
opportunity for the deep processing community to
(re-)evaluate their resources and software.
</bodyText>
<sectionHeader confidence="0.97702" genericHeader="method">
2 System Architecture
</sectionHeader>
<bodyText confidence="0.99989375">
The overall system architecture is shown in Figure 1.
It is similar to the architecture used by Zhang et al.
(2008). Three major components were involved.
The HPSG parsing component utilizes several hand-
crafted grammars for deep linguistic parsing. The
outputs of deep parsings are passed to the syntactic
dependency parser and semantic role labeler. The
syntactic parsing component is composed of a mod-
ified MST parser which accepts HPSG parsing re-
sults as extra features. The semantic role labeler is
comprised of a pipeline of 4 sub-components (pred-
icate identification is not necessary in this year’s
task). Comparing to Zhang et al. (2008), this archi-
tecture simplified the syntactic component, and puts
more focus on the integration of deep parsing out-
puts. While Zhang et al. (2008) only used seman-
</bodyText>
<note confidence="0.894235">
Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task, pages 31–36,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999752">
Figure 1: Joint system architecture.
</figureCaption>
<bodyText confidence="0.998991333333333">
tic features from HPSG parsing in the SRL task, we
added extra syntactic features from deep parsing to
help both tasks.
</bodyText>
<sectionHeader confidence="0.987184" genericHeader="method">
3 HPSG Parsing for the CoNLL Data
</sectionHeader>
<bodyText confidence="0.990908347826087">
DELPH-IN (Deep Linguistic Processing with
HPSG) is a repository of open-source software and
linguistic resources for so-called ‘deep’ grammat-
ical analysis.1 The grammars are rooted in rela-
tively detailed, hand-coded linguistic knowledge—
including lexical argument structure and the linking
of syntactic functions to thematic arguments—and
are intended as general-purpose resources, applica-
ble to both parsing and generation. Semantics in
DELPH-IN is cast in the Minimal Recursion Seman-
tics framework (MRS; Copestake, Flickinger, Pol-
lard, &amp; Sag, 2005), essentially predicate–argument
structures with provision for underspecified scopal
relations. For the 2009 ‘open’ task, we used the
DELPH-IN grammars for English (ERG; Flickinger,
2000), German (GG; Crysmann, 2005), Japanese
(JaCY; Siegel &amp; Bender, 2002), and Spanish (SRG;
Marimon, Bel, &amp; Seghezzi, 2007). The grammars
vary in their stage of development: the ERG com-
prises some 15 years of continuous development,
whereas work on the SRG only started about five
years ago, with GG and JaCY ranging somewhere
inbetween.
</bodyText>
<subsectionHeader confidence="0.99842">
3.1 Overall Setup
</subsectionHeader>
<bodyText confidence="0.9939435">
We applied the DELPH-IN grammars to the CoNLL
data using the PET parser (Callmeier, 2002) running
</bodyText>
<footnote confidence="0.996645">
1See http://www.delph-in.net for background.
</footnote>
<bodyText confidence="0.999806333333333">
it through the [incr tsdbo ] environment (Oepen &amp;
Carroll, 2000), for parallelization and distribution.
Also, [incr tsdbo ] provides facilities for (re-)training
the MaxEnt parse selection models that PET uses for
disambiguation.
The two main challenges in applying DELPH-
IN resources to parsing CoNLL data were (a) mis-
matches in basic assumptions, specifically tokeniza-
tion and the inventory of PoS tags provided as part of
the input, and (b) the need to adapt the resources for
new domains and genres—in particular in terms of
parse disambiguation—as the English and Spanish
grammars at least had not been previously applied
to the corpora used in the CoNLL shared task.
The importance of the first of these two aspects
is often underestimated. A detailed computational
grammar, inevitably, comes with its own assump-
tions about tokenization—the ERG, for example, re-
jects the conventional assumptions underlying the
PTB (and derived tools). It opts for an analysis of
punctuation akin to affixation (rather than as stand-
alone tokens), does not break up contracted negated
auxiliaries, and splits hyphenated words like ill-
advised into two tokens (the hyphen being part of
the first component). Thus, a string like Don’t you!
in the CoNLL data is tokenized as the four-element
sequence (do, n’t, you, !),2 whereas the ERG analy-
sis has only two leaf nodes: (don’t, you!).
Fortunately, the DELPH-IN toolchain recently
incorporated a mechanism called chart mapping
(Adolphs et al., 2008), which allows one to map
flexibly from ‘external’ input to grammar-internal
assumptions, while keeping track of external token
identities and their contributions to the final analysis.
The February 2009 release of the ERG already had
this machinery in place (with the goal of supporting
extant, PTB-trained PoS taggers in pre-processing
input to the deep parser), and we found that only a
tiny number of additional chart mapping rules was
required to ‘fix up’ CoNLL-specific deviations from
the PTB tradition. With the help of the original de-
velopers, we created new chart mapping configura-
tions for the German and Japanese grammars (with
17 and 16 such accomodation rules, respectively) in
a similar spirit. All four DELPH-IN grammars in-
</bodyText>
<footnote confidence="0.8198685">
2Note that the implied analogy to a non-contracted variant is
linguistically mis-leading, as ∗Do not you! is ungrammatical.
</footnote>
<figure confidence="0.9990435">
Syntactic
Dependency
Parsing
Semantic
Role
Labeling
Argument Classification
Argument Identification
Predicate Classification
Syn.Dep.
MST Parser
HPSG Syn.
MRS
HPSG Parsing
[incr tsdb()]
PET
JaCY
ERG
SRG
GG
</figure>
<page confidence="0.993011">
32
</page>
<bodyText confidence="0.999968722222223">
clude an account of unknown words, based on un-
derspecified ‘generic’ lexical entries that are acti-
vated from PoS information.
The Japenese case was interesting, in that
the grammar assumes a different pre-processor
(ChaSen, rather than Juman), such that not only to-
ken boundaries but also PoS tags and morphological
features had to be mapped. From our limited ex-
perience to date, we found the chart mapping ap-
proach adequate in accomodating such discrepan-
cies, and the addition of this extra layer of input
processing gave substantial gains in parser cover-
age (see below). For the Spanish data, on the other
hand, we found it impossible to make effective use
of the PoS and morphological information in the
CoNLL data, due to more fundamental discrepan-
cies (e.g. the treatment of enclitics and multi-word
expressions).
</bodyText>
<subsectionHeader confidence="0.998821">
3.2 Retraining Disambiguation Models
</subsectionHeader>
<bodyText confidence="0.999890107142857">
The ERG includes a domain-specific parse selection
model (for tourism instructions); GG only a stub
model trained on a handful of test sentences. For
use on the CoNLL data, thus, we had to train new
parse selections models, better adapted to the shared
task corpora. Disambiguation in PET is realized by
conditional MaxEnt models (Toutanova, Manning,
Flickinger, &amp; Oepen, 2005), usually trained on full
HPSG treebanks. Lacking this kind of training ma-
terial, we utilized the CoNLL dependency informa-
tion instead, by defining an unlabeled dependency
accuracy (DA) metric for HPSG analyses, essen-
tially quantifying the degree of overlap in head–
dependent relations against the CoNLL annotations.
Calculating DA for HPSG trees is similar to the
procedure commonly used for extracting bi-lexical
dependencies from phrase structure trees, in a sense
even simpler as HPSG analyses fully determine
headeness. Taking into account the technical com-
plication of token-level mismatches, our DA met-
ric loosely corresponds to the unlabeled attachment
score. To train CoNLL-specific parse selection mod-
els, we parsed the development sections in 500-best
mode (using the existing models) and then mechani-
cally ‘annotated’ the HPSG analyses with maximum
DA as preferred, all others as dis-preferred. In other
words, this procedure constructs a ‘binarized’ em-
pirical distribution where estimation of log-linear
</bodyText>
<tableCaption confidence="0.99863">
Table 1: Performance of the DELPH-IN grammars.
</tableCaption>
<bodyText confidence="0.9991406875">
model parameters amounts to adjusting conditional
probabilities towards higher DA values.3
Using the [incr tsdbo)] MaxEnt experimentation
facilities, we trained new parse selection models
for English and German, using the first 16,000 sen-
tences of the English training data and the full Ger-
man training corpus; seeing that only inputs that (a)
parse successfully and (b) have multiple readings,
with distinct DA values are relevant to this step, the
final models reflect close to 13,000 sentences for En-
glish, and a little more than 4,000 items for German.
Much like in the SRL component, these experiments
are carried out with the TADM software, using ten-
fold cross-validation and exact match ranking accu-
racy (against the binarized training distribution) to
optimize estimation hyper-parameters
</bodyText>
<subsectionHeader confidence="0.995587">
3.3 Deep Parsing Features
</subsectionHeader>
<bodyText confidence="0.999939125">
HPSG parsing coverage and average cpu time per
input for the four languages with DELPH-IN gram-
mars are summarized in Table 1. The PoS-based
unknown word mechanism was active for all gram-
mars but no other robustness measures (which tend
to lower the quality of results) were used, i.e. only
complete spanning HPSG analyses were accepted.
Parse times are for 1-best parsing, using selective
unpacking (Zhang, Oepen, &amp; Carroll, 2007).
HPSG parsing outputs are available in several dif-
ferent forms. We investigated two types of struc-
tures: syntactic derivations and MRS meaningrep-
resentations. Representative features were extracted
from both structures and selectively used in the sta-
tistical syntactic dependency parsing and semantic
role labeling modules for the ‘open’ challenge.
</bodyText>
<footnote confidence="0.7572932">
3We also experimented with using DA scores directly as em-
pirical probabilities in the training distribution (or some func-
tion of DA, to make it fall off more sharply), but none of
these methods seemed to further improve parse selection per-
formance.
</footnote>
<table confidence="0.997576">
Grammar Coverage Time
ERG 80.4% 10.06 s
GG 28.6% 3.41 s
JaCY 42.7% 2.13 s
SRG 7.5% 0.80 s
</table>
<page confidence="0.924152">
33
</page>
<bodyText confidence="0.994101793103448">
Deep Semantic Features Similar to Zhang et al.
(2008), we extract a set of features from the seman-
tic outputs (MRS) of the HPSG parses. These fea-
tures represent the basic predicate-argument struc-
ture, and provides a simplified semantic view on the
target sentence.
Deep Syntactic Dependency Features A HPSG
derivation is a tree structure. The internal nodes are
labeled with identifiers of grammar rules, and leaves
with lexical entries. The derivation tree provides
complete information about the actual HPSG anal-
ysis, and can be used together with the grammar to
reproduce complete feature structure and/or MRS.
Given that the shared task adopts dependency rep-
resentation, we further map the derivation trees into
token-token dependencies, labeled by corresponding
HPSG rules, by defining a set of head-finding rules
for each grammar. This dependency structure is dif-
ferent from the dependencies in CoNLL dataset, and
provides an alternative HPSG view on the sentences.
We refer to this structure as the dependency back-
bone (DB) of the HPSG anaylsis. A set of features
were extracted from the deep syntactic dependency
structures. This includes: i) the POS of the DB par-
ent from the predicate and/or argument; ii) DB la-
bel of the argument to its parent (only for AI/AC);
iii) labeled path from predicate to argument in DB
(only for AI/AC); iv) POSes of the predicate’s DB
dependents
</bodyText>
<sectionHeader confidence="0.989865" genericHeader="method">
4 Syntactic Dependency Parsing
</sectionHeader>
<bodyText confidence="0.999983212765958">
For the syntactic dependency parsing, we use the
MST Parser (McDonald et al., 2005), which is a
graph-based approach. The best parse tree is ac-
quired by searching for a spanning tree which max-
imizes the score on either a partially or a fully con-
nected graph with all words in the sentence as nodes
(Eisner, 1996; McDonald et al., 2005). Based on our
experience last year, we use the second order setting
of the parser, which includes features over pairs of
adjacent edges as well as features over single edges
in the graph. For the projective or non-projective
setting, we compare the results on the development
datasets of different languages. According to the
parser performance, we decide to use non-projective
parsing for German, Japanese, and Czech, and use
projective parsing for the rest.
For the Closed Challenge, we first consider
whether to use the morphological features. We find
that except for Czech, parser performs better with-
out morphological features on other languages (En-
glish and Chinese have no morphological features).
As for the other features (i.e. lemma and pos) given
by the data sets, we also compare the gold standard
features and P-columns. For all languages, the per-
formance decreases in the following order: training
with gold standard features and evaluating with the
gold standard features, training with P-columns and
evaluating with P-columns, training with gold stan-
dard features and testing with P-columns. Conse-
quently, in the final submission, we take the second
combination.
The goal of the Open Challenge is to see whether
using external resources can be helpful for the pars-
ing performance. As we mentioned before, our
deep parser gives us both the syntactic analysis of
the input sentences using the HPSG formalism and
also the semantic analysis using MRS as the repre-
sentation. However, for the syntactic dependency
parsing, we only extract features from the syntac-
tic HPSG analyses and feed them into the MST
Parser. Although, when parsing with gold standard
lemma and POS features, our open system outper-
forms the closed system on out-domain tests (for En-
glish), when parsing with P-columns there is no sub-
stantial improvement observed after using the HPSG
features. Therefore, we did not include it in the final
submission.
</bodyText>
<sectionHeader confidence="0.9822" genericHeader="method">
5 Semantic Role Labeling
</sectionHeader>
<bodyText confidence="0.9999495">
The semantic role labeling component used in the
submitted system is similar to the one described
by Zhang et al. (2008). Since predicates are indi-
cated in the data, the predicate identification mod-
ule is removed from this year’s system. Argument
identification, argument classification and predicate
classification are the three sub-components in the
pipeline. All of them are MaxEnt-based classifiers.
For parameter estimation, we use the open source
TADM system (Malouf, 2002).
The active features used in various steps of SRL
are fine tuned separately for different languages us-
ing development datasets. The significance of fea-
ture types varies across languages and datasets.
</bodyText>
<page confidence="0.996314">
34
</page>
<table confidence="0.999039714285714">
ca zh cs en de ja es
SYN Closed 82.67 73.63 75.58 87.90 84.57 91.47 82.69
ood - - 71.29 81.50 75.06 - -
SRL Closed 67.34 73.20 78.28 77.85 62.95 64.71 67.81
ood - - 77.78 67.07 54.87 - -
Open - - - 78.13 (T0.28) 64.31 (T1.36) 65.95 (T1.24) 68.24 (T0.43)
ood - - - 68.11 (T1.04) 58.42 (T3.55) - -
</table>
<tableCaption confidence="0.99963">
Table 2: Summary of System Performance on Multiple Languages
</tableCaption>
<bodyText confidence="0.9995012">
In the open challenge, two groups of extra fea-
tures from HPSG parsing outputs, as described in
Section 3.3, were used on languages for which we
have HPSG grammars, that is English, German,
Japanese, and Spanish.
</bodyText>
<sectionHeader confidence="0.993643" genericHeader="method">
6 Result Analysis
</sectionHeader>
<bodyText confidence="0.99996665">
The evaluation results of the submitted system are
summarized in Table 2. The overall ranking of
the system is #7 in the closed challenge, and #2
in the open challenge. While the system achieves
mediocre performance, the clear performance dif-
ference between the closed and open challenges of
the semantic role labeler indicates a substantial gain
from the integration of HPSG parsing outputs. The
most interesting observation is that even with gram-
mars which only achieve very limited coverage, no-
ticeable SRL improvements are obtained. Con-
firming the observation of Zhang et al. (2008), the
gain with HPSG features is more significant on out-
domain tests, this time on German as well.
The training of the syntactic parsing models for
all seven languages with MST parser takes about
100 CPU hours with 10 iterations. The dependency
parsing takes 6 – 7 CPU hours. The training and test-
ing of the semantic role labeler is much more effi-
cient, thanks to the use of MaxEnt models and the
efficient parameter estimation software. The train-
ing of all SRL models for 7 languages takes about 3
CPU hours in total. The total time for semantic role
labeling on test datasets is less than 1 hour.
Figure 2 shows the learning curve of the syntactic
parser and semantic role labeler on the Czech and
English datasets. While most of the systems con-
tinue to improve when trained on larger datasets, an
exception was observed with the Czech dataset on
the out-domain test for syntactic accuracy. In most
of the cases, with the increase of training data, the
out-domain test performance of the syntactic parser
and semantic role labeler improves slowly relative
to the in-domain test. For the English dataset, the
SRL learning curve climbs more quickly than those
of syntactic parsers. This is largely due to the fact
that the semantic role annotation is sparser than the
syntactic dependencies. On the Czech dataset which
has dense semantic annotation, this effect is not ob-
served.
</bodyText>
<sectionHeader confidence="0.995021" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999952823529412">
In this paper, we described our syntactic parsing and
semantic role labeling system participated in both
closed and open challenge of the (Joint) CoNLL
2009 Shared Task. Four hand-written HPSG gram-
mars of a variety of scale have been applied to parse
the datasets, and the outcomes were integrated as
features into the semantic role labeler of the sys-
tem. The results clearly show that the integration of
HPSG parsing results in the semantic role labeling
task brings substantial performance improvement.
The conclusion of Zhang et al. (2008) has been re-
confirmed on multiple languages for which we hand-
built HPSG grammars exist, even where grammati-
cal coverage is low. Also, the gain is more signifi-
cant on out-of-domain tests, indicating that the hy-
brid system is more robust to cross-domain varia-
tion.
</bodyText>
<sectionHeader confidence="0.997048" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9649861">
Adolphs, P., Oepen, S., Callmeier, U., Crysmann, B.,
Flickinger, D., &amp; Kiefer, B. (2008). Some fine points
of hybrid natural language parsing. In Proceedings
of the 6th International Conference on Language Re-
sources and Evaluation. Marrakech, Morocco.
Burchardt, A., Erk, K., Frank, A., Kowalski, A., Pad´o, S.,
&amp; Pinkal, M. (2006). The SALSA corpus: a German
corpus resource for lexical semantics. In Proceedings
of the 4th International Conference on Language Re-
sources and Evaluation. Genoa, Italy.
</reference>
<page confidence="0.992727">
35
</page>
<figure confidence="0.9985412">
Syn
SRL
Syn-ood
SRL-ood
Accuracy (%)
90
85
80
75
70
65
60
Accuracy (%)
79
78
77
76
75
74
73
72
71
70
69
Syn
SRL
Syn-ood
SRL-ood
0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Training Corpus Size (English) Training Corpus Size (Czech)
</figure>
<figureCaption confidence="0.996992">
Figure 2: Learning curves of syntactic dependency parser and semantic role labeler on Czech and English datasets
</figureCaption>
<reference confidence="0.998937963414634">
Callmeier, U. (2002). Preprocessing and encoding tech-
niques in PET. In S. Oepen, D. Flickinger, J. Tsujii, &amp;
H. Uszkoreit (Eds.), Collaborative language engineer-
ing. A case study in efficient grammar-based process-
ing. Stanford, CA: CSLI Publications.
Copestake, A., Flickinger, D., Pollard, C., &amp; Sag, I. A.
(2005). Minimal Recursion Semantics. An introduc-
tion. Journal of Research on Language and Computa-
tion, 3(4), 281– 332.
Crysmann, B. (2005). Relative clause extraposition
in German. An efficient and portable implementation.
Research on Language and Computation, 3(1), 61–
82.
Flickinger, D. (2000). On building a more efficient gram-
mar by exploiting types. Natural Language Engineer-
ing, 6 (1), 15 – 28.
Hajiˇc, J., Ciaramita, M., Johansson, R., Kawahara, D.,
Martf, M. A., M`arquez, L., Meyers, A., Nivre, J., Pad´o,
S., ˇStˇep´anek, J., Straˇn´ak, P., Surdeanu, M., Xue, N.,
&amp; Zhang, Y. (2009). The CoNLL-2009 shared task:
Syntactic and semantic dependencies in multiple lan-
guages. In Proceedings of the 13th Conference on
Computational Natural Language Learning. Boulder,
CO, USA.
Hajiˇc, J., Panevov´a, J., Hajiˇcov´a, E., Sgall, P., Pa-
jas, P., ˇStˇep´anek, J., Havelka, J., Mikulov´a, M., &amp;
ˇZabokrtsk´y, Z. (2006). Prague Dependency Treebank
2.0 (Nos. Cat. No. LDC2006T01, ISBN 1-58563-370-
4). Philadelphia, PA, USA: Linguistic Data Consor-
tium.
Kawahara, D., Kurohashi, S., &amp; Hasida, K. (2002). Con-
struction of a Japanese relevance-tagged corpus. In
Proceedings of the 3rd International Conference on
Language Resources and Evaluation (pp. 2008–2013).
Las Palmas, Canary Islands.
Malouf, R. (2002). A comparison of algorithms for max-
imum entropy parameter estimation. In Proceedings
of the 6th conferencde on natural language learning
(CoNLL 2002) (pp. 49–55). Taipei, Taiwan.
Marimon, M., Bel, N., &amp; Seghezzi, N. (2007). Test suite
construction for a Spanish grammar. In T. H. King &amp;
E. M. Bender (Eds.), Proceedings of the Grammar En-
gineering Across Frameworks workshop (p. 250-264).
Stanford, CA: CSLI Publications.
Oepen, S., &amp; Carroll, J. (2000). Performance profiling for
parser engineering. Natural Language Engineering, 6
(1), 81–97.
Palmer, M., Kingsbury, P., &amp; Gildea, D. (2005). The
Proposition Bank: An Annotated Corpus of Semantic
Roles. Computational Linguistics, 31(1), 71–106.
Palmer, M., &amp; Xue, N. (2009). Adding semantic roles
to the Chinese Treebank. Natural Language Engineer-
ing,15(1), 143–172.
Siegel, M., &amp; Bender, E. M. (2002). Efficient deep pro-
cessing of Japanese. In Proceedings of the 3rd work-
shop on asian language resources and international
standardization at the 19th international conference
on computational linguistics. Taipei, Taiwan.
Surdeanu, M., Johansson, R., Meyers, A., M`arquez, L.,
&amp; Nivre, J. (2008). The CoNLL-2008 shared task on
joint parsing of syntactic and semantic dependencies.
In Proceedings of the 12th Conference on Computa-
tional Natural Language Learning. Manchester, UK.
Taul´e, M., Martf, M. A., &amp; Recasens, M. (2008). An-
Cora: Multilevel Annotated Corpora for Catalan and
Spanish. In Proceedings of the 6th International Con-
ference on Language Resources and Evaluation. Mar-
rakesh, Morroco.
Toutanova, K., Manning, C. D., Flickinger, D., &amp; Oepen,
S. (2005). Stochastic HPSG parse selection using the
Redwoods corpus. Journal of Research on Language
and Computation, 3(1), 83 –105.
Zhang, Y., Oepen, S., &amp; Carroll, J. (2007). Efficiency in
unification-based n-best parsing. In Proceedings of the
10th International Conference on Parsing Technolo-
gies (pp. 48 – 59). Prague, Czech Republic.
Zhang, Y., Wang, R., &amp; Uszkoreit, H. (2008). Hy-
brid Learning of Dependency Structures from Hetero-
geneous Linguistic Resources. In Proceedings of the
Twelfth Conference on Computational Natural Lan-
guage Learning (CoNLL 2008) (pp. 198–202). Manch-
ester, UK.
</reference>
<page confidence="0.998938">
36
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.254256">
<title confidence="0.999835">Hybrid Multilingual Parsing with HPSG for SRL</title>
<author confidence="0.999338">Yi Zhang Rui Wang Stephan Oepen</author>
<affiliation confidence="0.913818">Language Technology Computational Linguistics Informatics</affiliation>
<address confidence="0.466983">DFKI GmbH, Germany Saarland University, Germany University of Oslo, Norway</address>
<email confidence="0.835738">yzhang@coli.uni-sb.derwang@coli.uni-sb.deoe@ifi.uio.no</email>
<abstract confidence="0.967542583333333">In this paper we present our syntactic and semantic dependency parsing system submitted to both the closed and open challenges of the CoNLL 2009 Shared Task. The system extends the system of Zhang, Wang, &amp; Uszkoreit (2008) in the multilingual direction, and achieves 76.49 average macro F1 Score on the closed joint task. Substantial improvements to the open SRL task have been observed that are attributed to the HPSG parses with handgrammars.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P Adolphs</author>
<author>S Oepen</author>
<author>U Callmeier</author>
<author>B Crysmann</author>
<author>D Flickinger</author>
<author>B Kiefer</author>
</authors>
<title>Some fine points of hybrid natural language parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th International Conference on Language Resources and Evaluation.</booktitle>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="7125" citStr="Adolphs et al., 2008" startWordPosition="1104" endWordPosition="1107">e, rejects the conventional assumptions underlying the PTB (and derived tools). It opts for an analysis of punctuation akin to affixation (rather than as standalone tokens), does not break up contracted negated auxiliaries, and splits hyphenated words like illadvised into two tokens (the hyphen being part of the first component). Thus, a string like Don’t you! in the CoNLL data is tokenized as the four-element sequence (do, n’t, you, !),2 whereas the ERG analysis has only two leaf nodes: (don’t, you!). Fortunately, the DELPH-IN toolchain recently incorporated a mechanism called chart mapping (Adolphs et al., 2008), which allows one to map flexibly from ‘external’ input to grammar-internal assumptions, while keeping track of external token identities and their contributions to the final analysis. The February 2009 release of the ERG already had this machinery in place (with the goal of supporting extant, PTB-trained PoS taggers in pre-processing input to the deep parser), and we found that only a tiny number of additional chart mapping rules was required to ‘fix up’ CoNLL-specific deviations from the PTB tradition. With the help of the original developers, we created new chart mapping configurations for</context>
</contexts>
<marker>Adolphs, Oepen, Callmeier, Crysmann, Flickinger, Kiefer, 2008</marker>
<rawString>Adolphs, P., Oepen, S., Callmeier, U., Crysmann, B., Flickinger, D., &amp; Kiefer, B. (2008). Some fine points of hybrid natural language parsing. In Proceedings of the 6th International Conference on Language Resources and Evaluation. Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Burchardt</author>
<author>K Erk</author>
<author>A Frank</author>
<author>A Kowalski</author>
<author>S Pad´o</author>
<author>M Pinkal</author>
</authors>
<title>The SALSA corpus: a German corpus resource for lexical semantics.</title>
<date>2006</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation.</booktitle>
<location>Genoa, Italy.</location>
<marker>Burchardt, Erk, Frank, Kowalski, Pad´o, Pinkal, 2006</marker>
<rawString>Burchardt, A., Erk, K., Frank, A., Kowalski, A., Pad´o, S., &amp; Pinkal, M. (2006). The SALSA corpus: a German corpus resource for lexical semantics. In Proceedings of the 4th International Conference on Language Resources and Evaluation. Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Callmeier</author>
</authors>
<title>Preprocessing and encoding techniques in</title>
<date>2002</date>
<publisher>CSLI Publications.</publisher>
<location>Stanford, CA:</location>
<contexts>
<context position="5589" citStr="Callmeier, 2002" startWordPosition="866" endWordPosition="867"> predicate–argument structures with provision for underspecified scopal relations. For the 2009 ‘open’ task, we used the DELPH-IN grammars for English (ERG; Flickinger, 2000), German (GG; Crysmann, 2005), Japanese (JaCY; Siegel &amp; Bender, 2002), and Spanish (SRG; Marimon, Bel, &amp; Seghezzi, 2007). The grammars vary in their stage of development: the ERG comprises some 15 years of continuous development, whereas work on the SRG only started about five years ago, with GG and JaCY ranging somewhere inbetween. 3.1 Overall Setup We applied the DELPH-IN grammars to the CoNLL data using the PET parser (Callmeier, 2002) running 1See http://www.delph-in.net for background. it through the [incr tsdbo ] environment (Oepen &amp; Carroll, 2000), for parallelization and distribution. Also, [incr tsdbo ] provides facilities for (re-)training the MaxEnt parse selection models that PET uses for disambiguation. The two main challenges in applying DELPHIN resources to parsing CoNLL data were (a) mismatches in basic assumptions, specifically tokenization and the inventory of PoS tags provided as part of the input, and (b) the need to adapt the resources for new domains and genres—in particular in terms of parse disambiguati</context>
</contexts>
<marker>Callmeier, 2002</marker>
<rawString>Callmeier, U. (2002). Preprocessing and encoding techniques in PET. In S. Oepen, D. Flickinger, J. Tsujii, &amp; H. Uszkoreit (Eds.), Collaborative language engineering. A case study in efficient grammar-based processing. Stanford, CA: CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
<author>D Flickinger</author>
<author>C Pollard</author>
<author>I A Sag</author>
</authors>
<title>Minimal Recursion Semantics. An introduction.</title>
<date>2005</date>
<journal>Journal of Research on Language and Computation,</journal>
<volume>3</volume>
<issue>4</issue>
<pages>281--332</pages>
<contexts>
<context position="4959" citStr="Copestake, Flickinger, Pollard, &amp; Sag, 2005" startWordPosition="765" endWordPosition="771">a syntactic features from deep parsing to help both tasks. 3 HPSG Parsing for the CoNLL Data DELPH-IN (Deep Linguistic Processing with HPSG) is a repository of open-source software and linguistic resources for so-called ‘deep’ grammatical analysis.1 The grammars are rooted in relatively detailed, hand-coded linguistic knowledge— including lexical argument structure and the linking of syntactic functions to thematic arguments—and are intended as general-purpose resources, applicable to both parsing and generation. Semantics in DELPH-IN is cast in the Minimal Recursion Semantics framework (MRS; Copestake, Flickinger, Pollard, &amp; Sag, 2005), essentially predicate–argument structures with provision for underspecified scopal relations. For the 2009 ‘open’ task, we used the DELPH-IN grammars for English (ERG; Flickinger, 2000), German (GG; Crysmann, 2005), Japanese (JaCY; Siegel &amp; Bender, 2002), and Spanish (SRG; Marimon, Bel, &amp; Seghezzi, 2007). The grammars vary in their stage of development: the ERG comprises some 15 years of continuous development, whereas work on the SRG only started about five years ago, with GG and JaCY ranging somewhere inbetween. 3.1 Overall Setup We applied the DELPH-IN grammars to the CoNLL data using th</context>
</contexts>
<marker>Copestake, Flickinger, Pollard, Sag, 2005</marker>
<rawString>Copestake, A., Flickinger, D., Pollard, C., &amp; Sag, I. A. (2005). Minimal Recursion Semantics. An introduction. Journal of Research on Language and Computation, 3(4), 281– 332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Crysmann</author>
</authors>
<title>Relative clause extraposition in German. An efficient and portable implementation.</title>
<date>2005</date>
<journal>Research on Language and Computation,</journal>
<volume>3</volume>
<issue>1</issue>
<pages>61--82</pages>
<contexts>
<context position="5176" citStr="Crysmann, 2005" startWordPosition="798" endWordPosition="799">is.1 The grammars are rooted in relatively detailed, hand-coded linguistic knowledge— including lexical argument structure and the linking of syntactic functions to thematic arguments—and are intended as general-purpose resources, applicable to both parsing and generation. Semantics in DELPH-IN is cast in the Minimal Recursion Semantics framework (MRS; Copestake, Flickinger, Pollard, &amp; Sag, 2005), essentially predicate–argument structures with provision for underspecified scopal relations. For the 2009 ‘open’ task, we used the DELPH-IN grammars for English (ERG; Flickinger, 2000), German (GG; Crysmann, 2005), Japanese (JaCY; Siegel &amp; Bender, 2002), and Spanish (SRG; Marimon, Bel, &amp; Seghezzi, 2007). The grammars vary in their stage of development: the ERG comprises some 15 years of continuous development, whereas work on the SRG only started about five years ago, with GG and JaCY ranging somewhere inbetween. 3.1 Overall Setup We applied the DELPH-IN grammars to the CoNLL data using the PET parser (Callmeier, 2002) running 1See http://www.delph-in.net for background. it through the [incr tsdbo ] environment (Oepen &amp; Carroll, 2000), for parallelization and distribution. Also, [incr tsdbo ] provides </context>
</contexts>
<marker>Crysmann, 2005</marker>
<rawString>Crysmann, B. (2005). Relative clause extraposition in German. An efficient and portable implementation. Research on Language and Computation, 3(1), 61– 82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Flickinger</author>
</authors>
<title>On building a more efficient grammar by exploiting types.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<volume>6</volume>
<issue>1</issue>
<pages>15--28</pages>
<contexts>
<context position="5147" citStr="Flickinger, 2000" startWordPosition="794" endWordPosition="795">alled ‘deep’ grammatical analysis.1 The grammars are rooted in relatively detailed, hand-coded linguistic knowledge— including lexical argument structure and the linking of syntactic functions to thematic arguments—and are intended as general-purpose resources, applicable to both parsing and generation. Semantics in DELPH-IN is cast in the Minimal Recursion Semantics framework (MRS; Copestake, Flickinger, Pollard, &amp; Sag, 2005), essentially predicate–argument structures with provision for underspecified scopal relations. For the 2009 ‘open’ task, we used the DELPH-IN grammars for English (ERG; Flickinger, 2000), German (GG; Crysmann, 2005), Japanese (JaCY; Siegel &amp; Bender, 2002), and Spanish (SRG; Marimon, Bel, &amp; Seghezzi, 2007). The grammars vary in their stage of development: the ERG comprises some 15 years of continuous development, whereas work on the SRG only started about five years ago, with GG and JaCY ranging somewhere inbetween. 3.1 Overall Setup We applied the DELPH-IN grammars to the CoNLL data using the PET parser (Callmeier, 2002) running 1See http://www.delph-in.net for background. it through the [incr tsdbo ] environment (Oepen &amp; Carroll, 2000), for parallelization and distribution. </context>
</contexts>
<marker>Flickinger, 2000</marker>
<rawString>Flickinger, D. (2000). On building a more efficient grammar by exploiting types. Natural Language Engineering, 6 (1), 15 – 28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hajiˇc</author>
<author>M Ciaramita</author>
<author>R Johansson</author>
<author>D Kawahara</author>
<author>M A Martf</author>
<author>L M`arquez</author>
<author>A Meyers</author>
<author>J Nivre</author>
<author>S Pad´o</author>
<author>J ˇStˇep´anek</author>
<author>P Straˇn´ak</author>
<author>M Surdeanu</author>
<author>N Xue</author>
<author>Y Zhang</author>
</authors>
<title>The CoNLL-2009 shared task: Syntactic and semantic dependencies in multiple languages.</title>
<date>2009</date>
<booktitle>In Proceedings of the 13th Conference on Computational Natural Language Learning.</booktitle>
<location>Boulder, CO, USA.</location>
<marker>Hajiˇc, Ciaramita, Johansson, Kawahara, Martf, M`arquez, Meyers, Nivre, Pad´o, ˇStˇep´anek, Straˇn´ak, Surdeanu, Xue, Zhang, 2009</marker>
<rawString>Hajiˇc, J., Ciaramita, M., Johansson, R., Kawahara, D., Martf, M. A., M`arquez, L., Meyers, A., Nivre, J., Pad´o, S., ˇStˇep´anek, J., Straˇn´ak, P., Surdeanu, M., Xue, N., &amp; Zhang, Y. (2009). The CoNLL-2009 shared task: Syntactic and semantic dependencies in multiple languages. In Proceedings of the 13th Conference on Computational Natural Language Learning. Boulder, CO, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hajiˇc</author>
<author>J Panevov´a</author>
<author>E Hajiˇcov´a</author>
<author>P Sgall</author>
<author>P Pajas</author>
<author>J ˇStˇep´anek</author>
<author>J Havelka</author>
<author>M Mikulov´a</author>
<author>Z ˇZabokrtsk´y</author>
</authors>
<date>2006</date>
<booktitle>Prague Dependency Treebank 2.0 (Nos. Cat. No. LDC2006T01, ISBN</booktitle>
<pages>1--58563</pages>
<institution>Linguistic Data Consortium.</institution>
<location>Philadelphia, PA, USA:</location>
<marker>Hajiˇc, Panevov´a, Hajiˇcov´a, Sgall, Pajas, ˇStˇep´anek, Havelka, Mikulov´a, ˇZabokrtsk´y, 2006</marker>
<rawString>Hajiˇc, J., Panevov´a, J., Hajiˇcov´a, E., Sgall, P., Pajas, P., ˇStˇep´anek, J., Havelka, J., Mikulov´a, M., &amp; ˇZabokrtsk´y, Z. (2006). Prague Dependency Treebank 2.0 (Nos. Cat. No. LDC2006T01, ISBN 1-58563-370-4). Philadelphia, PA, USA: Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Kawahara</author>
<author>S Kurohashi</author>
<author>K Hasida</author>
</authors>
<title>Construction of a Japanese relevance-tagged corpus.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd International Conference on Language Resources and Evaluation (pp. 2008–2013). Las</booktitle>
<location>Palmas, Canary Islands.</location>
<marker>Kawahara, Kurohashi, Hasida, 2002</marker>
<rawString>Kawahara, D., Kurohashi, S., &amp; Hasida, K. (2002). Construction of a Japanese relevance-tagged corpus. In Proceedings of the 3rd International Conference on Language Resources and Evaluation (pp. 2008–2013). Las Palmas, Canary Islands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Malouf</author>
</authors>
<title>A comparison of algorithms for maximum entropy parameter estimation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 6th conferencde on natural language learning (CoNLL</booktitle>
<pages>49--55</pages>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="16631" citStr="Malouf, 2002" startWordPosition="2607" endWordPosition="2608">mprovement observed after using the HPSG features. Therefore, we did not include it in the final submission. 5 Semantic Role Labeling The semantic role labeling component used in the submitted system is similar to the one described by Zhang et al. (2008). Since predicates are indicated in the data, the predicate identification module is removed from this year’s system. Argument identification, argument classification and predicate classification are the three sub-components in the pipeline. All of them are MaxEnt-based classifiers. For parameter estimation, we use the open source TADM system (Malouf, 2002). The active features used in various steps of SRL are fine tuned separately for different languages using development datasets. The significance of feature types varies across languages and datasets. 34 ca zh cs en de ja es SYN Closed 82.67 73.63 75.58 87.90 84.57 91.47 82.69 ood - - 71.29 81.50 75.06 - - SRL Closed 67.34 73.20 78.28 77.85 62.95 64.71 67.81 ood - - 77.78 67.07 54.87 - - Open - - - 78.13 (T0.28) 64.31 (T1.36) 65.95 (T1.24) 68.24 (T0.43) ood - - - 68.11 (T1.04) 58.42 (T3.55) - - Table 2: Summary of System Performance on Multiple Languages In the open challenge, two groups of ex</context>
</contexts>
<marker>Malouf, 2002</marker>
<rawString>Malouf, R. (2002). A comparison of algorithms for maximum entropy parameter estimation. In Proceedings of the 6th conferencde on natural language learning (CoNLL 2002) (pp. 49–55). Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marimon</author>
<author>N Bel</author>
<author>N Seghezzi</author>
</authors>
<title>Test suite construction for a Spanish grammar. In</title>
<date>2007</date>
<booktitle>Proceedings of the Grammar Engineering Across Frameworks workshop</booktitle>
<pages>250--264</pages>
<publisher>CSLI Publications.</publisher>
<location>Stanford, CA:</location>
<contexts>
<context position="5266" citStr="Marimon, Bel, &amp; Seghezzi, 2007" startWordPosition="809" endWordPosition="813">knowledge— including lexical argument structure and the linking of syntactic functions to thematic arguments—and are intended as general-purpose resources, applicable to both parsing and generation. Semantics in DELPH-IN is cast in the Minimal Recursion Semantics framework (MRS; Copestake, Flickinger, Pollard, &amp; Sag, 2005), essentially predicate–argument structures with provision for underspecified scopal relations. For the 2009 ‘open’ task, we used the DELPH-IN grammars for English (ERG; Flickinger, 2000), German (GG; Crysmann, 2005), Japanese (JaCY; Siegel &amp; Bender, 2002), and Spanish (SRG; Marimon, Bel, &amp; Seghezzi, 2007). The grammars vary in their stage of development: the ERG comprises some 15 years of continuous development, whereas work on the SRG only started about five years ago, with GG and JaCY ranging somewhere inbetween. 3.1 Overall Setup We applied the DELPH-IN grammars to the CoNLL data using the PET parser (Callmeier, 2002) running 1See http://www.delph-in.net for background. it through the [incr tsdbo ] environment (Oepen &amp; Carroll, 2000), for parallelization and distribution. Also, [incr tsdbo ] provides facilities for (re-)training the MaxEnt parse selection models that PET uses for disambigu</context>
</contexts>
<marker>Marimon, Bel, Seghezzi, 2007</marker>
<rawString>Marimon, M., Bel, N., &amp; Seghezzi, N. (2007). Test suite construction for a Spanish grammar. In T. H. King &amp; E. M. Bender (Eds.), Proceedings of the Grammar Engineering Across Frameworks workshop (p. 250-264). Stanford, CA: CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Oepen</author>
<author>J Carroll</author>
</authors>
<title>Performance profiling for parser engineering.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<volume>6</volume>
<issue>1</issue>
<pages>81--97</pages>
<contexts>
<context position="5707" citStr="Oepen &amp; Carroll, 2000" startWordPosition="880" endWordPosition="883">used the DELPH-IN grammars for English (ERG; Flickinger, 2000), German (GG; Crysmann, 2005), Japanese (JaCY; Siegel &amp; Bender, 2002), and Spanish (SRG; Marimon, Bel, &amp; Seghezzi, 2007). The grammars vary in their stage of development: the ERG comprises some 15 years of continuous development, whereas work on the SRG only started about five years ago, with GG and JaCY ranging somewhere inbetween. 3.1 Overall Setup We applied the DELPH-IN grammars to the CoNLL data using the PET parser (Callmeier, 2002) running 1See http://www.delph-in.net for background. it through the [incr tsdbo ] environment (Oepen &amp; Carroll, 2000), for parallelization and distribution. Also, [incr tsdbo ] provides facilities for (re-)training the MaxEnt parse selection models that PET uses for disambiguation. The two main challenges in applying DELPHIN resources to parsing CoNLL data were (a) mismatches in basic assumptions, specifically tokenization and the inventory of PoS tags provided as part of the input, and (b) the need to adapt the resources for new domains and genres—in particular in terms of parse disambiguation—as the English and Spanish grammars at least had not been previously applied to the corpora used in the CoNLL share</context>
</contexts>
<marker>Oepen, Carroll, 2000</marker>
<rawString>Oepen, S., &amp; Carroll, J. (2000). Performance profiling for parser engineering. Natural Language Engineering, 6 (1), 81–97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>P Kingsbury</author>
<author>D Gildea</author>
</authors>
<title>The Proposition Bank: An Annotated Corpus of Semantic Roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<pages>71--106</pages>
<marker>Palmer, Kingsbury, Gildea, 2005</marker>
<rawString>Palmer, M., Kingsbury, P., &amp; Gildea, D. (2005). The Proposition Bank: An Annotated Corpus of Semantic Roles. Computational Linguistics, 31(1), 71–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>N Xue</author>
</authors>
<title>Adding semantic roles to the Chinese Treebank.</title>
<date>2009</date>
<journal>Natural Language</journal>
<volume>15</volume>
<issue>1</issue>
<pages>143--172</pages>
<marker>Palmer, Xue, 2009</marker>
<rawString>Palmer, M., &amp; Xue, N. (2009). Adding semantic roles to the Chinese Treebank. Natural Language Engineering,15(1), 143–172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Siegel</author>
<author>E M Bender</author>
</authors>
<title>Efficient deep processing of Japanese.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd workshop on asian language resources and international standardization at the 19th international conference on computational linguistics.</booktitle>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="5216" citStr="Siegel &amp; Bender, 2002" startWordPosition="802" endWordPosition="805">elatively detailed, hand-coded linguistic knowledge— including lexical argument structure and the linking of syntactic functions to thematic arguments—and are intended as general-purpose resources, applicable to both parsing and generation. Semantics in DELPH-IN is cast in the Minimal Recursion Semantics framework (MRS; Copestake, Flickinger, Pollard, &amp; Sag, 2005), essentially predicate–argument structures with provision for underspecified scopal relations. For the 2009 ‘open’ task, we used the DELPH-IN grammars for English (ERG; Flickinger, 2000), German (GG; Crysmann, 2005), Japanese (JaCY; Siegel &amp; Bender, 2002), and Spanish (SRG; Marimon, Bel, &amp; Seghezzi, 2007). The grammars vary in their stage of development: the ERG comprises some 15 years of continuous development, whereas work on the SRG only started about five years ago, with GG and JaCY ranging somewhere inbetween. 3.1 Overall Setup We applied the DELPH-IN grammars to the CoNLL data using the PET parser (Callmeier, 2002) running 1See http://www.delph-in.net for background. it through the [incr tsdbo ] environment (Oepen &amp; Carroll, 2000), for parallelization and distribution. Also, [incr tsdbo ] provides facilities for (re-)training the MaxEnt </context>
</contexts>
<marker>Siegel, Bender, 2002</marker>
<rawString>Siegel, M., &amp; Bender, E. M. (2002). Efficient deep processing of Japanese. In Proceedings of the 3rd workshop on asian language resources and international standardization at the 19th international conference on computational linguistics. Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Surdeanu</author>
<author>R Johansson</author>
<author>A Meyers</author>
<author>L M`arquez</author>
<author>J Nivre</author>
</authors>
<title>The CoNLL-2008 shared task on joint parsing of syntactic and semantic dependencies.</title>
<date>2008</date>
<booktitle>In Proceedings of the 12th Conference on Computational Natural Language Learning.</booktitle>
<location>Manchester, UK.</location>
<marker>Surdeanu, Johansson, Meyers, M`arquez, Nivre, 2008</marker>
<rawString>Surdeanu, M., Johansson, R., Meyers, A., M`arquez, L., &amp; Nivre, J. (2008). The CoNLL-2008 shared task on joint parsing of syntactic and semantic dependencies. In Proceedings of the 12th Conference on Computational Natural Language Learning. Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Taul´e</author>
<author>M A Martf</author>
<author>M Recasens</author>
</authors>
<title>AnCora: Multilevel Annotated Corpora for Catalan and Spanish.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th International Conference on Language Resources and Evaluation. Marrakesh,</booktitle>
<location>Morroco.</location>
<marker>Taul´e, Martf, Recasens, 2008</marker>
<rawString>Taul´e, M., Martf, M. A., &amp; Recasens, M. (2008). AnCora: Multilevel Annotated Corpora for Catalan and Spanish. In Proceedings of the 6th International Conference on Language Resources and Evaluation. Marrakesh, Morroco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanova</author>
<author>C D Manning</author>
<author>D Flickinger</author>
<author>S Oepen</author>
</authors>
<title>Stochastic HPSG parse selection using the Redwoods corpus.</title>
<date>2005</date>
<journal>Journal of Research on Language and Computation,</journal>
<volume>3</volume>
<issue>1</issue>
<pages>83--105</pages>
<contexts>
<context position="9429" citStr="Toutanova, Manning, Flickinger, &amp; Oepen, 2005" startWordPosition="1463" endWordPosition="1468">h data, on the other hand, we found it impossible to make effective use of the PoS and morphological information in the CoNLL data, due to more fundamental discrepancies (e.g. the treatment of enclitics and multi-word expressions). 3.2 Retraining Disambiguation Models The ERG includes a domain-specific parse selection model (for tourism instructions); GG only a stub model trained on a handful of test sentences. For use on the CoNLL data, thus, we had to train new parse selections models, better adapted to the shared task corpora. Disambiguation in PET is realized by conditional MaxEnt models (Toutanova, Manning, Flickinger, &amp; Oepen, 2005), usually trained on full HPSG treebanks. Lacking this kind of training material, we utilized the CoNLL dependency information instead, by defining an unlabeled dependency accuracy (DA) metric for HPSG analyses, essentially quantifying the degree of overlap in head– dependent relations against the CoNLL annotations. Calculating DA for HPSG trees is similar to the procedure commonly used for extracting bi-lexical dependencies from phrase structure trees, in a sense even simpler as HPSG analyses fully determine headeness. Taking into account the technical complication of token-level mismatches,</context>
</contexts>
<marker>Toutanova, Manning, Flickinger, Oepen, 2005</marker>
<rawString>Toutanova, K., Manning, C. D., Flickinger, D., &amp; Oepen, S. (2005). Stochastic HPSG parse selection using the Redwoods corpus. Journal of Research on Language and Computation, 3(1), 83 –105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
<author>S Oepen</author>
<author>J Carroll</author>
</authors>
<title>Efficiency in unification-based n-best parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of the 10th International Conference on Parsing Technologies (pp. 48 – 59).</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="11747" citStr="Zhang, Oepen, &amp; Carroll, 2007" startWordPosition="1817" endWordPosition="1821">with the TADM software, using tenfold cross-validation and exact match ranking accuracy (against the binarized training distribution) to optimize estimation hyper-parameters 3.3 Deep Parsing Features HPSG parsing coverage and average cpu time per input for the four languages with DELPH-IN grammars are summarized in Table 1. The PoS-based unknown word mechanism was active for all grammars but no other robustness measures (which tend to lower the quality of results) were used, i.e. only complete spanning HPSG analyses were accepted. Parse times are for 1-best parsing, using selective unpacking (Zhang, Oepen, &amp; Carroll, 2007). HPSG parsing outputs are available in several different forms. We investigated two types of structures: syntactic derivations and MRS meaningrepresentations. Representative features were extracted from both structures and selectively used in the statistical syntactic dependency parsing and semantic role labeling modules for the ‘open’ challenge. 3We also experimented with using DA scores directly as empirical probabilities in the training distribution (or some function of DA, to make it fall off more sharply), but none of these methods seemed to further improve parse selection performance. </context>
</contexts>
<marker>Zhang, Oepen, Carroll, 2007</marker>
<rawString>Zhang, Y., Oepen, S., &amp; Carroll, J. (2007). Efficiency in unification-based n-best parsing. In Proceedings of the 10th International Conference on Parsing Technologies (pp. 48 – 59). Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
<author>R Wang</author>
<author>H Uszkoreit</author>
</authors>
<title>Hybrid Learning of Dependency Structures from Heterogeneous Linguistic Resources.</title>
<date>2008</date>
<booktitle>In Proceedings of the Twelfth Conference on Computational Natural Language Learning (CoNLL</booktitle>
<pages>198--202</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="2339" citStr="Zhang et al. (2008)" startWordPosition="367" endWordPosition="370"> Cluster of Multimodal Computing and Interaction for the support of the work. The second author is funded by the PIRE PhD scholarship program. Participation of the third author in this work was supported by the University of Oslo, as part of its research partnership with the Center for the Study of Language and Information at Stanford University. Our deep parsing experimentation was executed on the TITAN HPC facilities at the University of Oslo. 31 performance. This makes the task a nice testbed for the cross-fertilization of various language processing techniques. As an example of such work, Zhang et al. (2008) have shown in the past that deep linguistic parsing outputs can be integrated to help improve the performance of the English semantic role labeling task. But several questions remain unanswered. First, the integration only experimented with the semantic role labeling part of the task. It is not clear whether syntactic dependency parsing can also benefit from grammar-based parsing results. Second, the English grammar used to achieve the improvement is one of the largest and most mature hand-crafted linguistic grammars. It is not clear whether similar improvements can be achieved with less deve</context>
<context position="3859" citStr="Zhang et al. (2008)" startWordPosition="607" endWordPosition="610">ecture is shown in Figure 1. It is similar to the architecture used by Zhang et al. (2008). Three major components were involved. The HPSG parsing component utilizes several handcrafted grammars for deep linguistic parsing. The outputs of deep parsings are passed to the syntactic dependency parser and semantic role labeler. The syntactic parsing component is composed of a modified MST parser which accepts HPSG parsing results as extra features. The semantic role labeler is comprised of a pipeline of 4 sub-components (predicate identification is not necessary in this year’s task). Comparing to Zhang et al. (2008), this architecture simplified the syntactic component, and puts more focus on the integration of deep parsing outputs. While Zhang et al. (2008) only used semanProceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task, pages 31–36, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Figure 1: Joint system architecture. tic features from HPSG parsing in the SRL task, we added extra syntactic features from deep parsing to help both tasks. 3 HPSG Parsing for the CoNLL Data DELPH-IN (Deep Linguistic Processing with HPSG) is</context>
<context position="12493" citStr="Zhang et al. (2008)" startWordPosition="1938" endWordPosition="1941">s and MRS meaningrepresentations. Representative features were extracted from both structures and selectively used in the statistical syntactic dependency parsing and semantic role labeling modules for the ‘open’ challenge. 3We also experimented with using DA scores directly as empirical probabilities in the training distribution (or some function of DA, to make it fall off more sharply), but none of these methods seemed to further improve parse selection performance. Grammar Coverage Time ERG 80.4% 10.06 s GG 28.6% 3.41 s JaCY 42.7% 2.13 s SRG 7.5% 0.80 s 33 Deep Semantic Features Similar to Zhang et al. (2008), we extract a set of features from the semantic outputs (MRS) of the HPSG parses. These features represent the basic predicate-argument structure, and provides a simplified semantic view on the target sentence. Deep Syntactic Dependency Features A HPSG derivation is a tree structure. The internal nodes are labeled with identifiers of grammar rules, and leaves with lexical entries. The derivation tree provides complete information about the actual HPSG analysis, and can be used together with the grammar to reproduce complete feature structure and/or MRS. Given that the shared task adopts depen</context>
<context position="16272" citStr="Zhang et al. (2008)" startWordPosition="2554" endWordPosition="2557">S as the representation. However, for the syntactic dependency parsing, we only extract features from the syntactic HPSG analyses and feed them into the MST Parser. Although, when parsing with gold standard lemma and POS features, our open system outperforms the closed system on out-domain tests (for English), when parsing with P-columns there is no substantial improvement observed after using the HPSG features. Therefore, we did not include it in the final submission. 5 Semantic Role Labeling The semantic role labeling component used in the submitted system is similar to the one described by Zhang et al. (2008). Since predicates are indicated in the data, the predicate identification module is removed from this year’s system. Argument identification, argument classification and predicate classification are the three sub-components in the pipeline. All of them are MaxEnt-based classifiers. For parameter estimation, we use the open source TADM system (Malouf, 2002). The active features used in various steps of SRL are fine tuned separately for different languages using development datasets. The significance of feature types varies across languages and datasets. 34 ca zh cs en de ja es SYN Closed 82.67</context>
<context position="18008" citStr="Zhang et al. (2008)" startWordPosition="2842" endWordPosition="2845">, and Spanish. 6 Result Analysis The evaluation results of the submitted system are summarized in Table 2. The overall ranking of the system is #7 in the closed challenge, and #2 in the open challenge. While the system achieves mediocre performance, the clear performance difference between the closed and open challenges of the semantic role labeler indicates a substantial gain from the integration of HPSG parsing outputs. The most interesting observation is that even with grammars which only achieve very limited coverage, noticeable SRL improvements are obtained. Confirming the observation of Zhang et al. (2008), the gain with HPSG features is more significant on outdomain tests, this time on German as well. The training of the syntactic parsing models for all seven languages with MST parser takes about 100 CPU hours with 10 iterations. The dependency parsing takes 6 – 7 CPU hours. The training and testing of the semantic role labeler is much more efficient, thanks to the use of MaxEnt models and the efficient parameter estimation software. The training of all SRL models for 7 languages takes about 3 CPU hours in total. The total time for semantic role labeling on test datasets is less than 1 hour. F</context>
</contexts>
<marker>Zhang, Wang, Uszkoreit, 2008</marker>
<rawString>Zhang, Y., Wang, R., &amp; Uszkoreit, H. (2008). Hybrid Learning of Dependency Structures from Heterogeneous Linguistic Resources. In Proceedings of the Twelfth Conference on Computational Natural Language Learning (CoNLL 2008) (pp. 198–202). Manchester, UK.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>