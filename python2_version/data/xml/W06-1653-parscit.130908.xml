<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003789">
<title confidence="0.994208">
Relevance Feedback Models for Recommendation
</title>
<author confidence="0.99014">
Masao Utiyama
</author>
<affiliation confidence="0.993905">
National Institute of Information and Communications Technology
</affiliation>
<address confidence="0.961152">
3-5 Hikari-dai, Soraku-gun, Kyoto 619-0289 Japan
</address>
<email confidence="0.99671">
mutiyama@nict.go.jp
</email>
<author confidence="0.996063">
Mikio Yamamoto
</author>
<affiliation confidence="0.999204">
University of Tsukuba, 1-1-1 Tennodai, Tsukuba, 305-8573 Japan
</affiliation>
<email confidence="0.998291">
myama@cs.tsukuba.ac.jp
</email>
<sectionHeader confidence="0.99564" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999947857142857">
We extended language modeling ap-
proaches in information retrieval (IR) to
combine collaborative filtering (CF) and
content-based filtering (CBF). Our ap-
proach is based on the analogy between
IR and CF, especially between CF and rel-
evance feedback (RF). Both CF and RF
exploit users’ preference/relevance judg-
ments to recommend items. We first in-
troduce a multinomial model that com-
bines CF and CBF in a language modeling
framework. We then generalize the model
to another multinomial model that approx-
imates the Polya distribution. This gener-
alized model outperforms the multinomial
model by 3.4% for CBF and 17.4% for
CF in recommending English Wikipedia
articles. The performance of the gener-
alized model for three different datasets
was comparable to that of a state-of-the-
art item-based CF method.
</bodyText>
<sectionHeader confidence="0.999131" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999832173076923">
Recommender systems (Resnick and Varian,
1997) help users select particular items (e.g,
movies, books, music, and TV programs) that
match their taste from a large number of choices
by providing recommendations. The systems ei-
ther recommend a set of N items that will be of
interest to users (top-N recommendation problem)
or predict the degree of users’ preference for items
(prediction problem).
For those systems to work, they first have to
aggregate users’ evaluations of items explicitly or
implicitly. Users may explicitly evaluate certain
movies as rating five stars to express their prefer-
ence. These evaluations are used by the systems
as explicit ratings (votes) of items or the systems
infer the evaluations of items from the behavior of
users and use these inferred evaluations as implicit
ratings. For example, systems can infer that users
may like certain items if the systems learn which
books they buy, which articles they read, or which
TV programs they watch.
Collaborative filtering (CF) (Resnick et al.,
1994; Breese et al., 1998) and content-based (or
adaptive) filtering (CBF) (Allan, 1996; Schapire
et al., 1998) are two of the most popular types
of algorithms used in recommender systems. A
CF system makes recommendations to current
(active) users by exploiting their ratings in the
database. User-based CF (Resnick et al., 1994;
Herlocker et al., 1999) and item-based CF (Sarwar
et al., 2001; Karypis, 2001), among other CF algo-
rithms, have been studied extensively. User-based
CF first identifies a set of users (neighbors) that
are similar to the active user in terms of their rat-
ing patterns in the database. It then uses the neigh-
bors’ rating patterns to produce recommendations
for the active user. On the other hand, item-based
CF calculates the similarity between items before-
hand and then recommends items that are similar
to those preferred by the active user. The perfor-
mance of item-based CF has been shown to be
comparable to or better than that of user-based CF
(Sarwar et al., 2001; Karypis, 2001). In contrast
to CF, CBF uses the contents (e.g., texts, genres,
authors, images, and audio) of items to make rec-
ommendations for the active user. Because CF
and CBF are complementary, much work has been
done to combine them (Basu et al., 1998; Yu et
al., 2003; Si and Jin, 2004; Basilico and Hofmann,
2004).
The approach we took in this study is designed
to solve top-N recommendation problems with im-
</bodyText>
<page confidence="0.989369">
449
</page>
<note confidence="0.8538855">
Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 449–456,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999916735294118">
plicit ratings by using an item-based combination
of CF and CBF. The methods described in this
paper will be applied to recommending English
Wikipedia1 articles based on those articles edited
by active users. (This is discussed in Section 3.)
We use their editing histories and the contents of
their articles to make top-N recommendations. We
regard users’ editing histories as implicit ratings.
That is, if users have edited articles, we consider
that they have positive attitudes toward the arti-
cles. Those implicit ratings are regarded as pos-
itive examples. We do not have negative examples
for learning their negative attitudes toward arti-
cles. Consequently, handling our application with
standard machine learning algorithms that require
both positive and negative examples for classifica-
tion (e.g., support vector machines) is awkward.
Our approach is based on the advancement in
language modeling approaches to information re-
trieval (IR) (Croft and Lafferty, 2003) and extends
these to incorporate CF. The motivation behind our
approach is the analogy between CF and IR, espe-
cially between CF and relevance feedback (RF).
Both CF and RF recommend items based on user
preference/relevance judgments. Indeed, RF tech-
niques have been applied to CBF, or adaptive fil-
tering, successfully (Allan, 1996; Schapire et al.,
1998). Thus, it is likely that RF can also be applied
to CF.
To apply RF, we first extend the representation
of items to combine CF and CBF under the models
developed in Section 2. In Section 3, we report
our experiments with the models. Future work and
conclusion are in Sections 4 and 5.
</bodyText>
<sectionHeader confidence="0.973944" genericHeader="method">
2 Relevance feedback models
</sectionHeader>
<bodyText confidence="0.999940222222222">
The analogy between IR and CF that will be ex-
ploited in this paper is as follows.2 First, a docu-
ment in IR corresponds to an item in CF. Both are
represented as vectors. A document is represented
as a vector of words (bag-of-words) and an item
is represented as a vector of user ratings (bag-of-
user ratings). In RF, a user specifies documents
that are relevant to his information need. These
documents are used by the system to retrieve new
</bodyText>
<footnote confidence="0.914127">
1http://en.wikipedia.org/wiki/Main Page
2The analogy between IR and CF has been recognized.
For example, Breese et al. (1998) used the vector space
model to measure the similarity between users in a user-based
CF framework. Wang et al. (2005) used a language modeling
approach different from ours. These works, however, treated
only CF. In contrast with these, our model extends language
modeling approaches to incorporate both CF and CBF.
</footnote>
<bodyText confidence="0.999456173913044">
relevant documents. In CF, an active user (implic-
itly) specifies items that he likes. These items are
used to search new items that will be preferred by
the active user.
We use relevance models (Lavrenko and Croft,
2001; Lavrenko, 2004) as the basic framework
of our relevance feedback models because (1)
they perform relevance feedback well (Lavrenko,
2004) and (2) they can simultaneously handle dif-
ferent kinds of features (e.g., different language
texts (Lavrenko et al., 2002), such as texts and im-
ages (Leon et al., 2003). These two points are es-
sential in our application.
We first introduce a multinomial model follow-
ing the work of Lavrenko (2004). This model is
a novel one that extends relevance feedback ap-
proaches to incorporate CF. It is like a combina-
tion of relevance feedback (Lavrenko, 2004) and
cross-language information retrieval (Lavrenko et
al., 2002). We then generalize that model to an ap-
proximated Polya distribution model that is better
suited to CF and CBF. This generalized model is
the main technical contribution of this work.
</bodyText>
<subsectionHeader confidence="0.98858">
2.1 Preparation
</subsectionHeader>
<bodyText confidence="0.999609875">
Lavrenko (2004) adopts the method of kernels to
estimate probabilities: Let d be an item in the
database or training data, the probability of item x
is estimated as p(x) = M Ed p(x|θd), where M
is the number of items in the training data, θd is the
parameter vector estimated from d, and p(x|θd) is
the conditional probability of x given θd.3 This
means that once we have defined a probability dis-
tribution p(x|θ) and the method of estimating θd
from d, then we can assign probability p(x) to x
and apply language modeling approaches to CF
and CBF.
To begin with, we define the representation
of item x as the concatenation of two vectors
{wx, ux}, where wx = wx1wx2 ... is the se-
quence of words (contents) contained in x and
ux = ux1ux2 ... is the sequence of users who
have rated x implicitly. We use V„ and Vu to de-
note the set of words and users in the database.
The parameter vector θ is also the concatenation
of two vectors {ω, µ}, where ω and µ are the pa-
rameter vectors for V„ and Vu, respectively. The
probability of x given θ is defined as p(x|θ) =
pw(wx|ω)pA(ux|µ).
</bodyText>
<footnote confidence="0.997346666666667">
3Item d in summation Ed and word w in E. and 11.
go over every distinct item d and word w in the training data,
unless otherwise stated.
</footnote>
<page confidence="0.993691">
450
</page>
<subsectionHeader confidence="0.981288">
2.2 Multinomial model
</subsectionHeader>
<bodyText confidence="0.999871">
Our first model regards that both pω and pµ follow
multinomial distributions. In this case, ω(w) and
µ(u) are the probabilities of word w and user u.
Then, pω(wx|ω) is defined as
of d given q. Sq(d) is derived as follows. (We
ignore terms that are irrelevant to ranking items.)
</bodyText>
<equation confidence="0.979770235294118">
−D(θq||θd) = −D(ωq||ωd) − D(µq||µd)
Xk
−D(ωq||ωd) rank =1
k
i=1
S(ωqi||ωd) (5)
pω(wx|ω) =
|wx|
Y
i=1
where
X
S(ωqi||ωd) =
w
Yω(wxi) = ω(w)n(w,wx)
wEVw
(1)
</equation>
<bodyText confidence="0.999940666666667">
where n(w, wx) is the number of occurrences of w
in wx. In this model, we use a linear interpolation
method to estimate probability ωd(w).
</bodyText>
<equation confidence="0.894465666666667">
ωd(w) = λωPl(w|wd) + (1 − λω)Pg(w) (2)
where Pl(w|wd) = Pn(w,wd)
w0 n(w0,wd), Pg(w) =
PP d n(w,wd)
P w0 n(w0,wd) and λω (0 ≤ λω ≤ 1) is
d
</equation>
<bodyText confidence="0.996281">
a smoothing parameter. The estimation of user
probabilities goes similarly: Let n(u, ux) be the
number of times user u implicitly rated item x,
we define or estimate pµ, λµ and µd in the same
way. In summary, we have defined a probability
distribution p(x|θ) and the method of estimating
θd = {ωd, µd} from d.
To recommend top-N items, we have to rank
items in the database in response to the implicit
ratings of active users. We call those implicit rat-
ings query q. It is a set of items and is represented
as q = {q1 ... qk}, where qi is an item implic-
itly rated by an active user and k is the size of q.
We next estimate θq = {ωq, µq}. Then, we com-
pare θq and θd to rank items by using Kullback-
Leibler divergence D(θq||θd) (Lafferty and Zhai,
2001; Lavrenko, 2004).
</bodyText>
<equation confidence="0.9765395">
ωq(w) can be approximated as
Xk ωqi(w) (3)
1
ωq(w) = k i=1
</equation>
<bodyText confidence="0.99999225">
where ωqi(w) is obtained by Eq. 2 (Lavrenko,
2004). However, we found in preliminary experi-
ments that smoothing query probabilities hurt per-
formance in our application. Thus, we use
</bodyText>
<equation confidence="0.7929285">
ωqi(w) = Pl(w|wqi) Pw( w&apos;wqi)qi) (4)
nlw ,w
</equation>
<bodyText confidence="0.98099725">
instead of Eq. 2 when qi is in a query.
Because KL-divergence is a distance measure,
we use a score function derived from −D(θq||θd)
to rank items. We use Sq(d) to denote the score
</bodyText>
<equation confidence="0.9980765">
Pl(w|wqi)×log λωPl(w|wd) + 1
µ(1 − λω)Pg(w) ¶ .
</equation>
<bodyText confidence="0.9966285">
The summation goes over every word w that
is shared by both wqi and wd. We define
S(µqi||µd) similarly.4 Then, the score of d given
qi, Sqi(d) is defined as Sqi(d) = λsS(µqi||µd) + (1 − λs)S(ωqi||ωd)
where λs (0 ≤ λs ≤ 1) is a free parameter. Fi-
nally, the score of d given q is
</bodyText>
<equation confidence="0.982896666666667">
Xk
1
Sq(d) = k
</equation>
<bodyText confidence="0.999806461538462">
The calculation of Sq(d) can be very efficient
because once we cache Sqi(d) for each item pair
of qi and d in the database, we can reuse it to cal-
culate Sq(d) for any query q. We further optimize
the calculation of top-N recommendations by stor-
ing only the top 100 items (neighbors) in decreas-
ing order of Sqi(·) for each item qi and setting
the scores of lower ranked items as 0. (Note that
Sqi(d) &gt;= 0 holds.) Consequently, we only have
to search small part of the search space without
affecting the performance very much. These two
types of optimization are common in item-based
CF (Sarwar et al., 2001; Karypis, 2001).
</bodyText>
<subsectionHeader confidence="0.995533">
2.3 Polya model
</subsectionHeader>
<bodyText confidence="0.9969675">
Our second model is based on the Polya distribu-
tion. We first introduce (hyper) parameter Θ =
{αω, αµ} and denote the probability of x given
Θ as p(x|Θ) = pω(wx|αω)pµ(ux|αµ). αω and
αµ are the parameter vectors for words and users.
pω(wx|αω) is defined as follows.
</bodyText>
<equation confidence="0.987155133333333">
Γ(P w αω w) Y Γ(nx w + αω w)
pω(wx|αω) = Γ(P w nx w + αω w) Γ(αω w) (9)
w
P
u Pl(u|uqi) ×
3 λµPl(u|ud) ´
log (1−λµ)Pg(u) + 1 , where Pl(u|uqi) =
Pu0 n(u0,µqi), Pl(u|ud) = Pn(u,ud)
n(u,µqi) u0 n(u0,ud), and
PPg(u) = P d n(u,ud)
Pu0 n(u0,ud).
d
Sqi(d). (8)
i=1
4S(µqi||µd)
</equation>
<page confidence="0.95715">
451
</page>
<figure confidence="0.9491455">
0 2 4 6 8 10
n
</figure>
<figureCaption confidence="0.981649">
Figure 1: Relationship between original count n
and dumped count v(n, α)
</figureCaption>
<bodyText confidence="0.999944666666667">
where F is known as thegamma function, αωw is a
parameter for word w and nxw = n(w, wx). This
can be approximated as follows (Minka, 2003).
</bodyText>
<equation confidence="0.9972415">
11 pω(wx|αω) � W(w)�n(w,w.) (10)
w
</equation>
<bodyText confidence="0.745264">
where
</bodyText>
<equation confidence="0.89872">
n(w, wx) = αω w(IF(nx w + αωw) — IF(αωw))
� v(nxw, αωw) (11)
</equation>
<bodyText confidence="0.793889421052631">
IF is known as the digamma function and is sim-
ilar to the natural logarithm. We call Eq. 10 the
approximated Polya model or simply the Polya
model in this paper.
Eq. 10 indicates that the Polya distribution
can be interpreted as a multinomial distribution
over a modified set of counts n(·) (Minka, 2003).
These modified counts are dumped as shown in
Fig. 1. When αωw -* oc, v(nxw, αωw) approaches
nxw. When αωw -* 0, v(nxw, αωw) = 0 if nxw = 0
otherwise it is 1. For intermediate values of αωw,
the mapping v dumps the original counts.
Under the approximation of Eq. 10, the es-
timation of parameters can be understood as the
maximum-likelihood estimate of a multinomial
distribution from dumped counts n(·) (Minka,
2003). Indeed, all we have to do to estimate the
parameters for ranking items is replace Pl and Pg
from Section 2.2 with Pl(w|wd) = Ew0 �n(w0,wd),
</bodyText>
<equation confidence="0.8591614">
n(w,wd)
__ Ed�n(w,wd)
Pg (w) Ed Ew0 n(w0,wd), and Pl(w|wqi) =
n(w,wqi) Then, as in the multinomial model,
Ew0 n(w0,wqi) .
</equation>
<bodyText confidence="0.999525081081081">
we can define S(Wqi||Wd) with these probabilities.
This argument also applies to S(µqi||µd).
The approximated Polya model is a generaliza-
tion of the multinomial model described in Sec-
tion 2.2. If we set αωw and αµu very large then the
Polya model is identical to the multinomial model.
By comparing Eqs. 1 and 10, we can see why the
Polya model is superior to the multinomial model
for modeling the occurrences of words (and users).
In the multinomial model, if a word with probabil-
ity p occurs twice, its probability becomes p2. In
the Polya model, the word’s probability becomes
p1.5, for example, if we set αωw = 1. Clearly,
p2 &lt; p1.5; therefore, the Polya model assigns
higher probability. In this example, the Polya
model assigns probability p to the first occurrence
and p0.5(&gt; p) to the second. Since words that oc-
cur once are likely to occur again (Church, 2000),
the Polya model is better suited to model the oc-
currences of words and users. See Yamamoto and
Sadamitsu (2005) for further discussion on apply-
ing the Polya distribution to text modeling.
Zaragoza et al.(2003) applied the Polya distri-
bution to ad hoc IR. They introduced the exact
Polya distribution (see Eq. 9) as an extension
to the Dirichlet prior method (Zhai and Lafferty,
2001). However, we have introduced a multino-
mial approximation of the Polya distribution. This
approximation allows us to use the linear interpo-
lation method to mix the approximated Polya dis-
tributions. Thus, our model is similar to two-stage
language models (Zhai and Lafferty, 2002) that
combine the Dirichlet prior method and the lin-
ear interpolation method. In contrast to our model,
Zaragoza et al.(2003) had difficulty in mixing the
Polya distributions and did not treat that in their
paper.
</bodyText>
<sectionHeader confidence="0.999739" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.9999032">
We first examined the behavior of the Polya model
by varying the parameters. We tied αωw for every
w and αµu for every u; for any w and u, αωw = αω
and αµu = αµ. We then compared the Polya model
to an item-based CF method.
</bodyText>
<subsectionHeader confidence="0.9917635">
3.1 Behavior of Polya model
3.1.1 Dataset
</subsectionHeader>
<bodyText confidence="0.999135666666667">
We made a dataset of articles from English
Wikipedia5 to evaluate the Polya model. English
Wikipedia is an online encyclopedia that anyone
</bodyText>
<footnote confidence="0.921311">
5We downloaded 20050713 pages full.xml.gz
and 20050713 pages current.xml.gz from
http://download.wikimedia.org/wikipedia/en/.
</footnote>
<figure confidence="0.99737721875">
10
9
8
6
5
4
2
0
7
3
1
alpha=1e+5
alpha=38.8
alpha=16.4
alpha=9.0
alpha=5.4
alpha=3.3
alpha=2.0
alpha=1.1
alpha=0.4
alpha=1e-5
10
9
8
7
6
5
4
3
2
1
0
</figure>
<page confidence="0.997242">
452
</page>
<bodyText confidence="0.99998112195122">
can edit, and it has many registered users. Our
aim is to recommend a set of articles to each user
that is likely to be of interest to that user. If we
can successfully recommend interesting articles,
this could be very useful to a wide audience be-
cause Wikipedia is very popular. In addition, be-
cause wikis are popular media for sharing knowl-
edge, developing effective recommender systems
for wikis is important.
In our Wikipedia dataset, each item (article) x
consisted of wx and ux. ux was the sequence of
users who had edited x. If users had edited x mul-
tiple times, then those users occurred in ux multi-
ple times. wx was the sequence of words that were
typical in x. To make wx, we removed stop words
and stemmed the remaining words with a Porter
stemmer. Next, we identified 100 typical words
in each article and extracted only those words
(|wx |&gt; 100 because some of them occurred
multiple times). Typicality was measured using
the log-likelihood ratio test (Dunning, 1993). We
needed to reduce the number of words to speed up
our recommender system.
To make our dataset, we first extracted 302,606
articles, which had more than 100 tokens after the
stop words were removed. We then selected typi-
cal words in each article. The implicit rating data
were obtained from the histories of users editing
these articles. Each rating consisted of {user, ar-
ticle, number of edits}. The size of this original
rating data was 3,325,746. From this data, we ex-
tracted a dense subset that consisted of users and
articles included in at least 25 units of the original
data. We discarded the users who had edited more
than 999 articles because they were often software
robots or system operators, not casual users. The
resulting 430,096 ratings consisted of 4,193 users
and 9,726 articles. Each user rated (edited) 103
articles on average (the median was 57). The av-
erage number of ratings per item was 44 and the
median was 36.
</bodyText>
<subsectionHeader confidence="0.981198">
3.1.2 Evaluation of Polya model
</subsectionHeader>
<bodyText confidence="0.996062816666667">
We conducted a four-fold cross validation of
this rating dataset to evaluate the Polya model. We
used three-fourth of the dataset to train the model
and one-fourth to test it.6 All users who existed in
6We needed to estimate probabilities of users and words.
We used only training data to estimate the probabilities of
users. However, we used all 9,726 articles to estimate the
probabilities of words because the articles are usually avail-
able even when editing histories of users are not.
both training and test data were used for evalua-
tion. For each user, we regarded the articles in the
training data that had been edited by the user as a
query and ranked articles in response to it. These
ranked top-N articles were then compared to the
articles in the test data that were edited by the
same user to measure the precisions for the user.
We used P@N (precision at rank N = the ratio of
the articles edited by the user in the top-N articles),
S@N (success at rank N = 1 if some top-N articles
were edited by the user, else 0), and R-precision (=
P@N, where N is the number of articles edited by
the user in the test data). These measures for each
user were averaged over all users to get the mean
precision of each measure. Then, these mean pre-
cisions were averaged over the cross validation re-
peats.
Here, we report the averaged mean pre-
cisions with standard deviations. We first
report how R-precision varied depend-
ing on α (αu, or αµ). α was varied over
10−5,0.4,1.1,2,3.3,5.4,9,16.4,38.8, and 105.
The values of v(10, α) were approximately 1, 2,
3, 4, 5, 6, 7, 8, 9, and 10, respectively, as shown
in Fig. 1. When α = 105, the Polya model
represents the multinomial model as discussed in
Section 2.3. For each value of α, we varied A (au,
or aµ) over 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6,
0.7, 0.8, 0.9, 0.95, and 0.99 to obtain the optimum
R-precision. These optimum R-precisions are
shown in Fig. 2. In this figure, CBF and CF
represent the R-precisions for the content-based
and collaborative filtering part of the Polya model.
The values of CBF and CF were obtained by
setting as = 0 and as = 1 in Eq. 7 (which
is applied to the Polya model instead of the
multinomial model), respectively. The error bars
represent standard deviations.
At once, we noticed that CBF outperformed
CF. This is reasonable because the contents of
Wikipedia articles should strongly reflect the users
(authors) interest. In addition, each article had
about 100 typical words, and this was richer than
the average number of users per article (44). This
observation contrasts with other work where CBF
performed poorly compared with CF, e.g., (Ali and
van Stam, 2004).
Another important observation is that both
curves in Fig. 2 are concave. The best R-
precisions were obtained at intermediate values of
α for both CF and CBF as shown in Table 1.
</bodyText>
<page confidence="0.998105">
453
</page>
<figure confidence="0.9651665">
1 2 3 4 5 6 7 8 9 10
nu(10,alpha)
</figure>
<figureCaption confidence="0.929362">
Figure 2: R-precision for Polya model
</figureCaption>
<figure confidence="0.9792375">
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
lambda
</figure>
<figureCaption confidence="0.999187">
Figure 3: Combination of CBF and CF.
</figureCaption>
<figure confidence="0.997620454545455">
CBF
CF
CBF+CF
CBF
CF
0.095
0.09
0.085
0.08
0.075
0.07
0.065
0.1
0.095
0.09
0.085
0.08
0.075
0.07
0.065
0.06
0.055
</figure>
<tableCaption confidence="0.999097">
Table 1: Improvement in R-precision (RP)
</tableCaption>
<table confidence="0.989407">
best RP (v(·)/α) RP (v(·)/α) %change
CBF 0.091 (7/9.0) 0.088 (10/105) +3.4%
CF 0.081 (2/0.4) 0.069 (10/105) +17.4%
</table>
<bodyText confidence="0.991866333333333">
When a = 105 or v(10, a) - 10, the Polya
model represents the multinomial model as dis-
cussed in Section 2.3. Thus, Fig. 2 and Table 1
show that the best R-precisions achieved by the
Polya model were better than those obtained by
the multinomial model. The improvement was
3.4% for CBF and 17.4% for CF as shown in Ta-
ble 1. The improvement of CF was larger than
that of CBF. This implies that the occurrences of
users are more clustered than those of words. In
other words, the degree of repetition in the editing
histories of users is greater than that in word se-
quences. A user who edits an article are likely to
edit the article again.
From Fig. 2 and Table 1, we concluded that the
generalization of a multinomial model achieved by
the Polya model is effective in improving recom-
mendation performance.
</bodyText>
<subsectionHeader confidence="0.990824">
3.1.3 Combination of CBF and CF
</subsectionHeader>
<bodyText confidence="0.999707857142857">
Next, we show how the combination of CBF
and CF improves recommendation performance.
We set a (aω and aµ) to the optimum values in
Table 1 and varied a (as, aω and aµ) to obtain the
R-precisions for CBF+CF, CBF and CF in Fig. 3.
The values of CBF were obtained as follows. We
first set as = 0 in Eq. 7 to use only CBF scores
and then varied aω, which is the smoothing pa-
rameter for word probabilities, in Eq. 2. To get
the values of CF, we set as = 1 in Eq. 7 and then
varied aµ, which is the smoothing parameter for
user probabilities. The values of CBF+CF were
obtained by varying as in Eq. 7 while setting aω
and aµ to the optimum values obtained from CBF
</bodyText>
<tableCaption confidence="0.997011">
Table 2: Precision and Success at top-N
</tableCaption>
<table confidence="0.995183375">
N CBF+CF CBF CF
P@N S@N P@N S@N P@N S@N
5 0.166 0.470 0.149 0.444 0.137 0.408
10 0.135 0.585 0.123 0.562 0.112 0.516
15 0.117 0.650 0.107 0.628 0.098 0.582
20 0.105 0.694 0.096 0.671 0.089 0.627
R-precision 0.099 0.091 0.081
optimum A As = 0.2 A� = 0.01 A, = 0.2
</table>
<bodyText confidence="0.996385052631579">
and CF (see Table 2). These parameters (as, aω
and aµ) were defined in the context of the multi-
nomial model in Section 2.2 and used similarly in
the Polya model in this experiment.
We can see that the combination was quite ef-
fective as CBF+CF outperformed both CBF and
CF. Table 2 shows R-precision, P@N and S@N
for N = 5,10,15, 20. These values were obtained
by using the optimum values of a in Fig. 3.
Table 2 shows the same tendency as Fig. 3. For
all values of N, CBF+CF outperformed both CBF
and CF. We attribute this effectiveness of the com-
bination to the feature independence of CBF and
CF. CBF used words as features and CF used user
ratings as features. They are very different kinds
of features and thus can provide complementary
information. Consequently, CBF+CF can exploit
the benefits of both methods. We need to do fur-
ther work to confirm this conjecture.
</bodyText>
<subsectionHeader confidence="0.999957">
3.2 Comparison with a baseline method
</subsectionHeader>
<bodyText confidence="0.999892555555555">
We compared the Polya model to an implementa-
tion of a state-of-the-art item-based CF method,
CProb (Karypis, 2001). CProb has been tested
with various datasets and found to be effective in
top-N recommendation problems. CProb has also
been used in recent work as a baseline method
(Ziegler et al., 2005; Wang et al., 2005).
In addition to the Wikipedia dataset, we used
two other datasets for comparison. The first was
</bodyText>
<page confidence="0.997013">
454
</page>
<table confidence="0.9996782">
WP R-precision BX WP P@10 BX
ML ML
Polya-CF 0.081 0.272 0.066 0.112 0.384 0.054
CProb 0.082 0.258 0.071 0.113 0.373 0.057
%change -1.2% +5.4% -7.0% -0.9% +2.9% -5.3%
</table>
<tableCaption confidence="0.999965">
Table 3: Comparison of Polya-CF and CProb
</tableCaption>
<bodyText confidence="0.999951">
the 1 million MovieLens dataset.7 This data con-
sists of 1,000,209 ratings of 3,706 movies by 6,040
users. Each user rated an average of 166 movies
(the median was 96). The average number of rat-
ings per movie was 270 and the median was 124.
The second was the BookCrossing dataset (Ziegler
et al., 2005). This data consists of 1,149,780 rat-
ings of 340,532 books by 105,283 users. From
this data, we removed books rated by less than 20
users. We also removed users who rated less than
5 books. The resulting 296,471 ratings consisted
of 10,345 users and 5,943 books. Each user rated
29 books on average (the median was 10). The av-
erage number of ratings per book was 50 and the
median was 33. Note that in our experiments, we
regarded the ratings of these two datasets as im-
plicit ratings. We regarded the number of occur-
rence of each rating as one.
We conducted a four-fold cross validation for
each dataset to compare CProb and Polya-CF,
which is the collaborative filtering part of the
Polya model as described in the previous section.
For each cross validation repeat, we tuned the pa-
rameters of CProb and Polya-CF on the test data to
get the optimum R-precisions, in order to compare
best results for these models.8 P@N and S@N
were calculated with the same parameters. These
measures were averaged as described above. R-
precision and P@10 are in Table 3. The max-
imum standard deviation of these measures was
0.001. We omitted reporting other measures be-
cause they had similar tendencies. In Table 3, WP,
ML and BX represent the Wikipedia, MovieLens,
and BookCrossing datasets.
In Table 3, we can see that the variation of per-
formance among datasets was greater than that be-
tween Polya-CF and CProb. Both methods per-
</bodyText>
<footnote confidence="0.663584454545455">
7http://www.grouplens.org/
8CProb has two free parameters. Polya-CF also has two
free parameters (αµ and Aµ). However, for MovieLens and
BookCrossing datasets, Polya-CF has only one free parame-
ter Aµ, because we regarded the number of occurrence of each
rating as one, which means v(1, αµ) = 1 for all αµ &gt; 0 (See
Fig. 1). Consequently, we don’t have to tune αµ. Since the
number of free parameters is small, the comparison of perfor-
mance shown in Table 3 is likely to be reproduced when we
tune the parameters on separate development data instead of
test data.
</footnote>
<bodyText confidence="0.999671166666667">
formed best against ML. We think that this is be-
cause ML had the densest ratings. The average
number of ratings per item was 270 for ML while
that for WP was 44 and that for BX was 50.
Table 3 also shows that Polya-CF outperformed
CProb when the dataset was ML and CProb was
better than Polya-CF in the other cases. However,
the differences in precision were small. Overall,
we can say that the performance of Polya-CF is
comparable to that of CProb.
An important advantage of the Polya model
over CProb is that the Polya model can unify CBF
and CF in a single language modeling framework
while CProb handles only CF. Another advantage
of the Polya model is that we can expect to im-
prove its performance by incorporating techniques
developed in IR because the Polya model is based
on language modeling approaches in IR.
</bodyText>
<sectionHeader confidence="0.999847" genericHeader="method">
4 Future work
</sectionHeader>
<bodyText confidence="0.9999622">
We want to investigate two areas in our future
work. One is the parameter estimation and the
other is the refinement of the query model.
We tuned the parameters of the Polya model by
exhaustively searching the parameter space guided
by R-precision. We actually tried to learn αu,
and αµ from the training data by using an EM
method (Minka, 2003; Yamamoto and Sadamitsu,
2005). However, the estimated parameters were
about 0.05, too small for better recommendations.
We need further study to understand the relation
between the probabilistic quality (perplexity) of
the Polya model and its recommendation quality.
We approximate the query model as Eq. 3. This
allows us to optimize score calculation consider-
ably. However, this does not consider the interac-
tion among items, which may deteriorate the qual-
ity of probability estimation. We want to inves-
tigate more efficient query models in our future
work.
</bodyText>
<sectionHeader confidence="0.998953" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999762">
Recommender systems help users select particular
items from a large number of choices by provid-
ing recommendations. Much work has been done
to combine content-based filtering (CBF) and col-
laborative filtering (CF) to provide better recom-
mendations. The contributions reported in this pa-
per are twofold: (1) we extended relevance feed-
back approaches to incorporate CF and (2) we in-
troduced the approximated Polya model as a gen-
</bodyText>
<page confidence="0.996879">
455
</page>
<bodyText confidence="0.999964111111111">
eralization of the multinomial model and showed
that it is better suited to CF and CBF. The perfor-
mance of the Polya model is comparable to that of
a state-of-the-art item-based CF method.
Our work shows that language modeling ap-
proaches in information retrieval can be extended
to CF. This implies that a large amount of work
in the field of IR could be imported into CF. This
would be interesting to investigate in future work.
</bodyText>
<sectionHeader confidence="0.999187" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999927011235955">
Kamal Ali and Wijnand van Stam. 2004. TiVo: Mak-
ing show recommendations using a distributed col-
laborative filtering architecture. In KDD’04.
James Allan. 1996. Incremental relevance feedback
for information filtering. In SIGIR’96.
Justin Basilico and Thomas Hofmann. 2004. Uni-
fying collaborative and content-based filtering. In
ICML’04.
Chumki Basu, Haym Hirsh, and William Cohen. 1998.
Recommendation as classification: Using social and
content-based information in recommendation. In
AAAI-98.
John S. Breese, David Heckerman, and Carl Kadie.
1998. Empirical analysis of predictive algorithms
for collaborative filtering. Technical report, MSR-
TR-98-12.
Kenneth W. Church. 2000. Empirical estimates of
adaptation: The chance of two Noriegas is closer to
p/2 than p2. In COLING-2000, pages 180–186.
W. Bruce Croft and John Lafferty, editors. 2003. Lan-
guage Modeling for Information Retrieval. Kluwer
Academic Publishers.
Ted Dunning. 1993. Accurate methods for the statis-
tics of surprise and coincidence. Computational
Linguistics, 19(1):61–74.
Jonathan L. Herlocker, Joseph A. Konstan,
Al Borchers, and John Riedl. 1999. An algo-
rithmic framework for performing collaborative
filtering. In SIGIR’99, pages 230–237.
George Karypis. 2001. Evaluation of item-based top-
N recommendation algorithms. In CIKM’01.
John Lafferty and ChengXiang Zhai. 2001. Document
language models, query models and risk minimiza-
tion for information retrieval. In SIGIR’01.
Victor Lavrenko and W. Bruce Croft. 2001.
Relevance-based language models. In SIGIR’01.
Victor Lavrenko, Martin Choquette, and W. Bruce
Croft. 2002. Cross-lingual relevance models. In
SIGIR’02, pages 175–182.
Victor Lavrenko. 2004. A Generative Theory of Rele-
vance. Ph.D. thesis, University of Massachusetts.
J. Leon, V. Lavrenko, and R. Manmatha. 2003. Au-
tomatic image annotation and retrieval using cross-
media relevance models. In SIGIR’03.
Thomas P. Minka. 2003. Es-
timating a Dirichlet distribution.
http://research.microsoft.com/˜minka/papers/dirichlet/.
Paul Resnick and Hal R. Varian. 1997. Recommender
systems. Communications of the ACM, 40(3):56–
58.
Paul Resnick, Neophytos Iacovou, Mitesh Suchak, Pe-
ter Bergstrom, and John Riedl. 1994. GroupLens:
An open architecture for collaborative filtering of
netnews. In CSCW’94, pages 175–186.
Badrul Sarwar, George Karypis, Joseph Konstan, and
John Riedl. 2001. Item-based collaborative filtering
recommendation algorithms. In WWW10.
Robert E. Schapire, Yoram Singer, and Amit Singhal.
1998. Boosting and Rocchio applied to text filtering.
In SIGIR’98, pages 215–223.
Luo Si and Rong Jin. 2004. Unified filtering by com-
bining collaborative filtering and content-based fil-
tering via mixture model and exponential model. In
CIKM-04, pages 156–157.
Jun Wang, Marcel J.T. Reinders, Reginald L. La-
gendijk, and Johan Pouwelse. 2005. Self-
organizing distributed collaborative filtering. In SI-
GIR’05, pages 659–660.
Mikio Yamamoto and Kugatsu Sadamitsu. 2005.
Dirichlet mixtures in text modeling. Technical re-
port, University of Tsukuba, CS-TR-05-1.
Kai Yu, Anton Schwaighofer, Volker Tresp, Wei-Ying
Ma, and HongJiang Zhang. 2003. Collaborative
ensemble learning: Combining collaborative and
content-based information filtering via hierarchical
Bayes. In UAI-2003.
Hugo Zaragoza, Djoerd Hiemstra, and Michael Tip-
ping. 2003. Bayesian extension to the language
model for ad hoc information retrieval. In SIGIR’03.
ChengXiang Zhai and John Lafferty. 2001. A study of
smoothing methods for language models applied to
ad hoc information retrieval. In SIGIR’01.
ChengXiang Zhai and John Lafferty. 2002. Two-stage
language models for information retrieval. In SI-
GIR’02, pages 49–56.
Cai-Nicolas Ziegler, Sean M. McNee, Joseph A. Kon-
stan, and Georg Lausen. 2005. Improving rec-
ommendation lists through topic diversification. In
WWW’05, pages 22–32.
</reference>
<page confidence="0.999082">
456
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.308213">
<title confidence="0.999936">Relevance Feedback Models for Recommendation</title>
<author confidence="0.821199">Masao</author>
<affiliation confidence="0.910863">National Institute of Information and Communications</affiliation>
<address confidence="0.780053">3-5 Hikari-dai, Soraku-gun, Kyoto 619-0289</address>
<email confidence="0.967051">mutiyama@nict.go.jp</email>
<author confidence="0.990057">Mikio Yamamoto</author>
<affiliation confidence="0.552387">University of Tsukuba, 1-1-1 Tennodai, Tsukuba, 305-8573</affiliation>
<email confidence="0.955131">myama@cs.tsukuba.ac.jp</email>
<abstract confidence="0.994413681818182">We extended language modeling approaches in information retrieval (IR) to combine collaborative filtering (CF) and content-based filtering (CBF). Our approach is based on the analogy between IR and CF, especially between CF and relevance feedback (RF). Both CF and RF exploit users’ preference/relevance judgments to recommend items. We first introduce a multinomial model that combines CF and CBF in a language modeling framework. We then generalize the model to another multinomial model that approximates the Polya distribution. This generalized model outperforms the multinomial model by 3.4% for CBF and 17.4% for CF in recommending English Wikipedia articles. The performance of the generalized model for three different datasets was comparable to that of a state-of-theart item-based CF method.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kamal Ali</author>
<author>Wijnand van Stam</author>
</authors>
<title>TiVo: Making show recommendations using a distributed collaborative filtering architecture.</title>
<date>2004</date>
<booktitle>In KDD’04.</booktitle>
<marker>Ali, van Stam, 2004</marker>
<rawString>Kamal Ali and Wijnand van Stam. 2004. TiVo: Making show recommendations using a distributed collaborative filtering architecture. In KDD’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Allan</author>
</authors>
<title>Incremental relevance feedback for information filtering.</title>
<date>1996</date>
<booktitle>In SIGIR’96.</booktitle>
<contexts>
<context position="2229" citStr="Allan, 1996" startWordPosition="336" endWordPosition="337">icitly. Users may explicitly evaluate certain movies as rating five stars to express their preference. These evaluations are used by the systems as explicit ratings (votes) of items or the systems infer the evaluations of items from the behavior of users and use these inferred evaluations as implicit ratings. For example, systems can infer that users may like certain items if the systems learn which books they buy, which articles they read, or which TV programs they watch. Collaborative filtering (CF) (Resnick et al., 1994; Breese et al., 1998) and content-based (or adaptive) filtering (CBF) (Allan, 1996; Schapire et al., 1998) are two of the most popular types of algorithms used in recommender systems. A CF system makes recommendations to current (active) users by exploiting their ratings in the database. User-based CF (Resnick et al., 1994; Herlocker et al., 1999) and item-based CF (Sarwar et al., 2001; Karypis, 2001), among other CF algorithms, have been studied extensively. User-based CF first identifies a set of users (neighbors) that are similar to the active user in terms of their rating patterns in the database. It then uses the neighbors’ rating patterns to produce recommendations fo</context>
<context position="5047" citStr="Allan, 1996" startWordPosition="788" endWordPosition="789">h standard machine learning algorithms that require both positive and negative examples for classification (e.g., support vector machines) is awkward. Our approach is based on the advancement in language modeling approaches to information retrieval (IR) (Croft and Lafferty, 2003) and extends these to incorporate CF. The motivation behind our approach is the analogy between CF and IR, especially between CF and relevance feedback (RF). Both CF and RF recommend items based on user preference/relevance judgments. Indeed, RF techniques have been applied to CBF, or adaptive filtering, successfully (Allan, 1996; Schapire et al., 1998). Thus, it is likely that RF can also be applied to CF. To apply RF, we first extend the representation of items to combine CF and CBF under the models developed in Section 2. In Section 3, we report our experiments with the models. Future work and conclusion are in Sections 4 and 5. 2 Relevance feedback models The analogy between IR and CF that will be exploited in this paper is as follows.2 First, a document in IR corresponds to an item in CF. Both are represented as vectors. A document is represented as a vector of words (bag-of-words) and an item is represented as a</context>
</contexts>
<marker>Allan, 1996</marker>
<rawString>James Allan. 1996. Incremental relevance feedback for information filtering. In SIGIR’96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Justin Basilico</author>
<author>Thomas Hofmann</author>
</authors>
<title>Unifying collaborative and content-based filtering.</title>
<date>2004</date>
<booktitle>In ICML’04.</booktitle>
<contexts>
<context position="3462" citStr="Basilico and Hofmann, 2004" startWordPosition="544" endWordPosition="547">active user. On the other hand, item-based CF calculates the similarity between items beforehand and then recommends items that are similar to those preferred by the active user. The performance of item-based CF has been shown to be comparable to or better than that of user-based CF (Sarwar et al., 2001; Karypis, 2001). In contrast to CF, CBF uses the contents (e.g., texts, genres, authors, images, and audio) of items to make recommendations for the active user. Because CF and CBF are complementary, much work has been done to combine them (Basu et al., 1998; Yu et al., 2003; Si and Jin, 2004; Basilico and Hofmann, 2004). The approach we took in this study is designed to solve top-N recommendation problems with im449 Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 449–456, Sydney, July 2006. c�2006 Association for Computational Linguistics plicit ratings by using an item-based combination of CF and CBF. The methods described in this paper will be applied to recommending English Wikipedia1 articles based on those articles edited by active users. (This is discussed in Section 3.) We use their editing histories and the contents of their articles to make </context>
</contexts>
<marker>Basilico, Hofmann, 2004</marker>
<rawString>Justin Basilico and Thomas Hofmann. 2004. Unifying collaborative and content-based filtering. In ICML’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chumki Basu</author>
<author>Haym Hirsh</author>
<author>William Cohen</author>
</authors>
<title>Recommendation as classification: Using social and content-based information in recommendation.</title>
<date>1998</date>
<booktitle>In AAAI-98.</booktitle>
<contexts>
<context position="3398" citStr="Basu et al., 1998" startWordPosition="532" endWordPosition="535">s’ rating patterns to produce recommendations for the active user. On the other hand, item-based CF calculates the similarity between items beforehand and then recommends items that are similar to those preferred by the active user. The performance of item-based CF has been shown to be comparable to or better than that of user-based CF (Sarwar et al., 2001; Karypis, 2001). In contrast to CF, CBF uses the contents (e.g., texts, genres, authors, images, and audio) of items to make recommendations for the active user. Because CF and CBF are complementary, much work has been done to combine them (Basu et al., 1998; Yu et al., 2003; Si and Jin, 2004; Basilico and Hofmann, 2004). The approach we took in this study is designed to solve top-N recommendation problems with im449 Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 449–456, Sydney, July 2006. c�2006 Association for Computational Linguistics plicit ratings by using an item-based combination of CF and CBF. The methods described in this paper will be applied to recommending English Wikipedia1 articles based on those articles edited by active users. (This is discussed in Section 3.) We use the</context>
</contexts>
<marker>Basu, Hirsh, Cohen, 1998</marker>
<rawString>Chumki Basu, Haym Hirsh, and William Cohen. 1998. Recommendation as classification: Using social and content-based information in recommendation. In AAAI-98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John S Breese</author>
<author>David Heckerman</author>
<author>Carl Kadie</author>
</authors>
<title>Empirical analysis of predictive algorithms for collaborative filtering.</title>
<date>1998</date>
<tech>Technical report,</tech>
<pages>98--12</pages>
<contexts>
<context position="2168" citStr="Breese et al., 1998" startWordPosition="326" endWordPosition="329">first have to aggregate users’ evaluations of items explicitly or implicitly. Users may explicitly evaluate certain movies as rating five stars to express their preference. These evaluations are used by the systems as explicit ratings (votes) of items or the systems infer the evaluations of items from the behavior of users and use these inferred evaluations as implicit ratings. For example, systems can infer that users may like certain items if the systems learn which books they buy, which articles they read, or which TV programs they watch. Collaborative filtering (CF) (Resnick et al., 1994; Breese et al., 1998) and content-based (or adaptive) filtering (CBF) (Allan, 1996; Schapire et al., 1998) are two of the most popular types of algorithms used in recommender systems. A CF system makes recommendations to current (active) users by exploiting their ratings in the database. User-based CF (Resnick et al., 1994; Herlocker et al., 1999) and item-based CF (Sarwar et al., 2001; Karypis, 2001), among other CF algorithms, have been studied extensively. User-based CF first identifies a set of users (neighbors) that are similar to the active user in terms of their rating patterns in the database. It then uses</context>
<context position="5950" citStr="Breese et al. (1998)" startWordPosition="946" endWordPosition="949"> are in Sections 4 and 5. 2 Relevance feedback models The analogy between IR and CF that will be exploited in this paper is as follows.2 First, a document in IR corresponds to an item in CF. Both are represented as vectors. A document is represented as a vector of words (bag-of-words) and an item is represented as a vector of user ratings (bag-ofuser ratings). In RF, a user specifies documents that are relevant to his information need. These documents are used by the system to retrieve new 1http://en.wikipedia.org/wiki/Main Page 2The analogy between IR and CF has been recognized. For example, Breese et al. (1998) used the vector space model to measure the similarity between users in a user-based CF framework. Wang et al. (2005) used a language modeling approach different from ours. These works, however, treated only CF. In contrast with these, our model extends language modeling approaches to incorporate both CF and CBF. relevant documents. In CF, an active user (implicitly) specifies items that he likes. These items are used to search new items that will be preferred by the active user. We use relevance models (Lavrenko and Croft, 2001; Lavrenko, 2004) as the basic framework of our relevance feedback</context>
</contexts>
<marker>Breese, Heckerman, Kadie, 1998</marker>
<rawString>John S. Breese, David Heckerman, and Carl Kadie. 1998. Empirical analysis of predictive algorithms for collaborative filtering. Technical report, MSRTR-98-12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
</authors>
<title>Empirical estimates of adaptation: The chance of two Noriegas is closer to p/2 than p2. In</title>
<date>2000</date>
<booktitle>COLING-2000,</booktitle>
<pages>180--186</pages>
<contexts>
<context position="14230" citStr="Church, 2000" startWordPosition="2464" endWordPosition="2465">al to the multinomial model. By comparing Eqs. 1 and 10, we can see why the Polya model is superior to the multinomial model for modeling the occurrences of words (and users). In the multinomial model, if a word with probability p occurs twice, its probability becomes p2. In the Polya model, the word’s probability becomes p1.5, for example, if we set αωw = 1. Clearly, p2 &lt; p1.5; therefore, the Polya model assigns higher probability. In this example, the Polya model assigns probability p to the first occurrence and p0.5(&gt; p) to the second. Since words that occur once are likely to occur again (Church, 2000), the Polya model is better suited to model the occurrences of words and users. See Yamamoto and Sadamitsu (2005) for further discussion on applying the Polya distribution to text modeling. Zaragoza et al.(2003) applied the Polya distribution to ad hoc IR. They introduced the exact Polya distribution (see Eq. 9) as an extension to the Dirichlet prior method (Zhai and Lafferty, 2001). However, we have introduced a multinomial approximation of the Polya distribution. This approximation allows us to use the linear interpolation method to mix the approximated Polya distributions. Thus, our model i</context>
</contexts>
<marker>Church, 2000</marker>
<rawString>Kenneth W. Church. 2000. Empirical estimates of adaptation: The chance of two Noriegas is closer to p/2 than p2. In COLING-2000, pages 180–186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Bruce Croft</author>
<author>John Lafferty</author>
<author>editors</author>
</authors>
<title>Language Modeling for Information Retrieval.</title>
<date>2003</date>
<publisher>Kluwer Academic Publishers.</publisher>
<marker>Croft, Lafferty, editors, 2003</marker>
<rawString>W. Bruce Croft and John Lafferty, editors. 2003. Language Modeling for Information Retrieval. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="16786" citStr="Dunning, 1993" startWordPosition="2902" endWordPosition="2903">ive recommender systems for wikis is important. In our Wikipedia dataset, each item (article) x consisted of wx and ux. ux was the sequence of users who had edited x. If users had edited x multiple times, then those users occurred in ux multiple times. wx was the sequence of words that were typical in x. To make wx, we removed stop words and stemmed the remaining words with a Porter stemmer. Next, we identified 100 typical words in each article and extracted only those words (|wx |&gt; 100 because some of them occurred multiple times). Typicality was measured using the log-likelihood ratio test (Dunning, 1993). We needed to reduce the number of words to speed up our recommender system. To make our dataset, we first extracted 302,606 articles, which had more than 100 tokens after the stop words were removed. We then selected typical words in each article. The implicit rating data were obtained from the histories of users editing these articles. Each rating consisted of {user, article, number of edits}. The size of this original rating data was 3,325,746. From this data, we extracted a dense subset that consisted of users and articles included in at least 25 units of the original data. We discarded t</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Ted Dunning. 1993. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics, 19(1):61–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan L Herlocker</author>
<author>Joseph A Konstan</author>
<author>Al Borchers</author>
<author>John Riedl</author>
</authors>
<title>An algorithmic framework for performing collaborative filtering.</title>
<date>1999</date>
<booktitle>In SIGIR’99,</booktitle>
<pages>230--237</pages>
<contexts>
<context position="2496" citStr="Herlocker et al., 1999" startWordPosition="377" endWordPosition="380">and use these inferred evaluations as implicit ratings. For example, systems can infer that users may like certain items if the systems learn which books they buy, which articles they read, or which TV programs they watch. Collaborative filtering (CF) (Resnick et al., 1994; Breese et al., 1998) and content-based (or adaptive) filtering (CBF) (Allan, 1996; Schapire et al., 1998) are two of the most popular types of algorithms used in recommender systems. A CF system makes recommendations to current (active) users by exploiting their ratings in the database. User-based CF (Resnick et al., 1994; Herlocker et al., 1999) and item-based CF (Sarwar et al., 2001; Karypis, 2001), among other CF algorithms, have been studied extensively. User-based CF first identifies a set of users (neighbors) that are similar to the active user in terms of their rating patterns in the database. It then uses the neighbors’ rating patterns to produce recommendations for the active user. On the other hand, item-based CF calculates the similarity between items beforehand and then recommends items that are similar to those preferred by the active user. The performance of item-based CF has been shown to be comparable to or better than</context>
</contexts>
<marker>Herlocker, Konstan, Borchers, Riedl, 1999</marker>
<rawString>Jonathan L. Herlocker, Joseph A. Konstan, Al Borchers, and John Riedl. 1999. An algorithmic framework for performing collaborative filtering. In SIGIR’99, pages 230–237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Karypis</author>
</authors>
<title>Evaluation of item-based topN recommendation algorithms.</title>
<date>2001</date>
<booktitle>In CIKM’01.</booktitle>
<contexts>
<context position="2551" citStr="Karypis, 2001" startWordPosition="388" endWordPosition="389">ple, systems can infer that users may like certain items if the systems learn which books they buy, which articles they read, or which TV programs they watch. Collaborative filtering (CF) (Resnick et al., 1994; Breese et al., 1998) and content-based (or adaptive) filtering (CBF) (Allan, 1996; Schapire et al., 1998) are two of the most popular types of algorithms used in recommender systems. A CF system makes recommendations to current (active) users by exploiting their ratings in the database. User-based CF (Resnick et al., 1994; Herlocker et al., 1999) and item-based CF (Sarwar et al., 2001; Karypis, 2001), among other CF algorithms, have been studied extensively. User-based CF first identifies a set of users (neighbors) that are similar to the active user in terms of their rating patterns in the database. It then uses the neighbors’ rating patterns to produce recommendations for the active user. On the other hand, item-based CF calculates the similarity between items beforehand and then recommends items that are similar to those preferred by the active user. The performance of item-based CF has been shown to be comparable to or better than that of user-based CF (Sarwar et al., 2001; Karypis, 2</context>
<context position="11487" citStr="Karypis, 2001" startWordPosition="1960" endWordPosition="1961">culation of Sq(d) can be very efficient because once we cache Sqi(d) for each item pair of qi and d in the database, we can reuse it to calculate Sq(d) for any query q. We further optimize the calculation of top-N recommendations by storing only the top 100 items (neighbors) in decreasing order of Sqi(·) for each item qi and setting the scores of lower ranked items as 0. (Note that Sqi(d) &gt;= 0 holds.) Consequently, we only have to search small part of the search space without affecting the performance very much. These two types of optimization are common in item-based CF (Sarwar et al., 2001; Karypis, 2001). 2.3 Polya model Our second model is based on the Polya distribution. We first introduce (hyper) parameter Θ = {αω, αµ} and denote the probability of x given Θ as p(x|Θ) = pω(wx|αω)pµ(ux|αµ). αω and αµ are the parameter vectors for words and users. pω(wx|αω) is defined as follows. Γ(P w αω w) Y Γ(nx w + αω w) pω(wx|αω) = Γ(P w nx w + αω w) Γ(αω w) (9) w P u Pl(u|uqi) × 3 λµPl(u|ud) ´ log (1−λµ)Pg(u) + 1 , where Pl(u|uqi) = Pu0 n(u0,µqi), Pl(u|ud) = Pn(u,ud) n(u,µqi) u0 n(u0,ud), and PPg(u) = P d n(u,ud) Pu0 n(u0,ud). d Sqi(d). (8) i=1 4S(µqi||µd) 451 0 2 4 6 8 10 n Figure 1: Relationship betw</context>
<context position="23847" citStr="Karypis, 2001" startWordPosition="4186" endWordPosition="4187">2 shows the same tendency as Fig. 3. For all values of N, CBF+CF outperformed both CBF and CF. We attribute this effectiveness of the combination to the feature independence of CBF and CF. CBF used words as features and CF used user ratings as features. They are very different kinds of features and thus can provide complementary information. Consequently, CBF+CF can exploit the benefits of both methods. We need to do further work to confirm this conjecture. 3.2 Comparison with a baseline method We compared the Polya model to an implementation of a state-of-the-art item-based CF method, CProb (Karypis, 2001). CProb has been tested with various datasets and found to be effective in top-N recommendation problems. CProb has also been used in recent work as a baseline method (Ziegler et al., 2005; Wang et al., 2005). In addition to the Wikipedia dataset, we used two other datasets for comparison. The first was 454 WP R-precision BX WP P@10 BX ML ML Polya-CF 0.081 0.272 0.066 0.112 0.384 0.054 CProb 0.082 0.258 0.071 0.113 0.373 0.057 %change -1.2% +5.4% -7.0% -0.9% +2.9% -5.3% Table 3: Comparison of Polya-CF and CProb the 1 million MovieLens dataset.7 This data consists of 1,000,209 ratings of 3,706 </context>
</contexts>
<marker>Karypis, 2001</marker>
<rawString>George Karypis. 2001. Evaluation of item-based topN recommendation algorithms. In CIKM’01.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Document language models, query models and risk minimization for information retrieval.</title>
<date>2001</date>
<booktitle>In SIGIR’01.</booktitle>
<contexts>
<context position="10040" citStr="Lafferty and Zhai, 2001" startWordPosition="1688" endWordPosition="1691">tly rated item x, we define or estimate pµ, λµ and µd in the same way. In summary, we have defined a probability distribution p(x|θ) and the method of estimating θd = {ωd, µd} from d. To recommend top-N items, we have to rank items in the database in response to the implicit ratings of active users. We call those implicit ratings query q. It is a set of items and is represented as q = {q1 ... qk}, where qi is an item implicitly rated by an active user and k is the size of q. We next estimate θq = {ωq, µq}. Then, we compare θq and θd to rank items by using KullbackLeibler divergence D(θq||θd) (Lafferty and Zhai, 2001; Lavrenko, 2004). ωq(w) can be approximated as Xk ωqi(w) (3) 1 ωq(w) = k i=1 where ωqi(w) is obtained by Eq. 2 (Lavrenko, 2004). However, we found in preliminary experiments that smoothing query probabilities hurt performance in our application. Thus, we use ωqi(w) = Pl(w|wqi) Pw( w&apos;wqi)qi) (4) nlw ,w instead of Eq. 2 when qi is in a query. Because KL-divergence is a distance measure, we use a score function derived from −D(θq||θd) to rank items. We use Sq(d) to denote the score Pl(w|wqi)×log λωPl(w|wd) + 1 µ(1 − λω)Pg(w) ¶ . The summation goes over every word w that is shared by both wqi and</context>
</contexts>
<marker>Lafferty, Zhai, 2001</marker>
<rawString>John Lafferty and ChengXiang Zhai. 2001. Document language models, query models and risk minimization for information retrieval. In SIGIR’01.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor Lavrenko</author>
<author>W Bruce Croft</author>
</authors>
<title>Relevance-based language models.</title>
<date>2001</date>
<booktitle>In SIGIR’01.</booktitle>
<contexts>
<context position="6484" citStr="Lavrenko and Croft, 2001" startWordPosition="1034" endWordPosition="1037">Page 2The analogy between IR and CF has been recognized. For example, Breese et al. (1998) used the vector space model to measure the similarity between users in a user-based CF framework. Wang et al. (2005) used a language modeling approach different from ours. These works, however, treated only CF. In contrast with these, our model extends language modeling approaches to incorporate both CF and CBF. relevant documents. In CF, an active user (implicitly) specifies items that he likes. These items are used to search new items that will be preferred by the active user. We use relevance models (Lavrenko and Croft, 2001; Lavrenko, 2004) as the basic framework of our relevance feedback models because (1) they perform relevance feedback well (Lavrenko, 2004) and (2) they can simultaneously handle different kinds of features (e.g., different language texts (Lavrenko et al., 2002), such as texts and images (Leon et al., 2003). These two points are essential in our application. We first introduce a multinomial model following the work of Lavrenko (2004). This model is a novel one that extends relevance feedback approaches to incorporate CF. It is like a combination of relevance feedback (Lavrenko, 2004) and cross</context>
</contexts>
<marker>Lavrenko, Croft, 2001</marker>
<rawString>Victor Lavrenko and W. Bruce Croft. 2001. Relevance-based language models. In SIGIR’01.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor Lavrenko</author>
<author>Martin Choquette</author>
<author>W Bruce Croft</author>
</authors>
<title>Cross-lingual relevance models.</title>
<date>2002</date>
<booktitle>In SIGIR’02,</booktitle>
<pages>175--182</pages>
<contexts>
<context position="6746" citStr="Lavrenko et al., 2002" startWordPosition="1073" endWordPosition="1076">hese works, however, treated only CF. In contrast with these, our model extends language modeling approaches to incorporate both CF and CBF. relevant documents. In CF, an active user (implicitly) specifies items that he likes. These items are used to search new items that will be preferred by the active user. We use relevance models (Lavrenko and Croft, 2001; Lavrenko, 2004) as the basic framework of our relevance feedback models because (1) they perform relevance feedback well (Lavrenko, 2004) and (2) they can simultaneously handle different kinds of features (e.g., different language texts (Lavrenko et al., 2002), such as texts and images (Leon et al., 2003). These two points are essential in our application. We first introduce a multinomial model following the work of Lavrenko (2004). This model is a novel one that extends relevance feedback approaches to incorporate CF. It is like a combination of relevance feedback (Lavrenko, 2004) and cross-language information retrieval (Lavrenko et al., 2002). We then generalize that model to an approximated Polya distribution model that is better suited to CF and CBF. This generalized model is the main technical contribution of this work. 2.1 Preparation Lavren</context>
</contexts>
<marker>Lavrenko, Choquette, Croft, 2002</marker>
<rawString>Victor Lavrenko, Martin Choquette, and W. Bruce Croft. 2002. Cross-lingual relevance models. In SIGIR’02, pages 175–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor Lavrenko</author>
</authors>
<title>A Generative Theory of Relevance.</title>
<date>2004</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Massachusetts.</institution>
<contexts>
<context position="6501" citStr="Lavrenko, 2004" startWordPosition="1038" endWordPosition="1039">IR and CF has been recognized. For example, Breese et al. (1998) used the vector space model to measure the similarity between users in a user-based CF framework. Wang et al. (2005) used a language modeling approach different from ours. These works, however, treated only CF. In contrast with these, our model extends language modeling approaches to incorporate both CF and CBF. relevant documents. In CF, an active user (implicitly) specifies items that he likes. These items are used to search new items that will be preferred by the active user. We use relevance models (Lavrenko and Croft, 2001; Lavrenko, 2004) as the basic framework of our relevance feedback models because (1) they perform relevance feedback well (Lavrenko, 2004) and (2) they can simultaneously handle different kinds of features (e.g., different language texts (Lavrenko et al., 2002), such as texts and images (Leon et al., 2003). These two points are essential in our application. We first introduce a multinomial model following the work of Lavrenko (2004). This model is a novel one that extends relevance feedback approaches to incorporate CF. It is like a combination of relevance feedback (Lavrenko, 2004) and cross-language informa</context>
<context position="10057" citStr="Lavrenko, 2004" startWordPosition="1692" endWordPosition="1693">ne or estimate pµ, λµ and µd in the same way. In summary, we have defined a probability distribution p(x|θ) and the method of estimating θd = {ωd, µd} from d. To recommend top-N items, we have to rank items in the database in response to the implicit ratings of active users. We call those implicit ratings query q. It is a set of items and is represented as q = {q1 ... qk}, where qi is an item implicitly rated by an active user and k is the size of q. We next estimate θq = {ωq, µq}. Then, we compare θq and θd to rank items by using KullbackLeibler divergence D(θq||θd) (Lafferty and Zhai, 2001; Lavrenko, 2004). ωq(w) can be approximated as Xk ωqi(w) (3) 1 ωq(w) = k i=1 where ωqi(w) is obtained by Eq. 2 (Lavrenko, 2004). However, we found in preliminary experiments that smoothing query probabilities hurt performance in our application. Thus, we use ωqi(w) = Pl(w|wqi) Pw( w&apos;wqi)qi) (4) nlw ,w instead of Eq. 2 when qi is in a query. Because KL-divergence is a distance measure, we use a score function derived from −D(θq||θd) to rank items. We use Sq(d) to denote the score Pl(w|wqi)×log λωPl(w|wd) + 1 µ(1 − λω)Pg(w) ¶ . The summation goes over every word w that is shared by both wqi and wd. We define S(</context>
</contexts>
<marker>Lavrenko, 2004</marker>
<rawString>Victor Lavrenko. 2004. A Generative Theory of Relevance. Ph.D. thesis, University of Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Leon</author>
<author>V Lavrenko</author>
<author>R Manmatha</author>
</authors>
<title>Automatic image annotation and retrieval using crossmedia relevance models.</title>
<date>2003</date>
<booktitle>In SIGIR’03.</booktitle>
<contexts>
<context position="6792" citStr="Leon et al., 2003" startWordPosition="1083" endWordPosition="1086">with these, our model extends language modeling approaches to incorporate both CF and CBF. relevant documents. In CF, an active user (implicitly) specifies items that he likes. These items are used to search new items that will be preferred by the active user. We use relevance models (Lavrenko and Croft, 2001; Lavrenko, 2004) as the basic framework of our relevance feedback models because (1) they perform relevance feedback well (Lavrenko, 2004) and (2) they can simultaneously handle different kinds of features (e.g., different language texts (Lavrenko et al., 2002), such as texts and images (Leon et al., 2003). These two points are essential in our application. We first introduce a multinomial model following the work of Lavrenko (2004). This model is a novel one that extends relevance feedback approaches to incorporate CF. It is like a combination of relevance feedback (Lavrenko, 2004) and cross-language information retrieval (Lavrenko et al., 2002). We then generalize that model to an approximated Polya distribution model that is better suited to CF and CBF. This generalized model is the main technical contribution of this work. 2.1 Preparation Lavrenko (2004) adopts the method of kernels to esti</context>
</contexts>
<marker>Leon, Lavrenko, Manmatha, 2003</marker>
<rawString>J. Leon, V. Lavrenko, and R. Manmatha. 2003. Automatic image annotation and retrieval using crossmedia relevance models. In SIGIR’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas P Minka</author>
</authors>
<title>Estimating a Dirichlet distribution.</title>
<date>2003</date>
<note>http://research.microsoft.com/˜minka/papers/dirichlet/.</note>
<contexts>
<context position="12271" citStr="Minka, 2003" startWordPosition="2116" endWordPosition="2117"> pω(wx|αω)pµ(ux|αµ). αω and αµ are the parameter vectors for words and users. pω(wx|αω) is defined as follows. Γ(P w αω w) Y Γ(nx w + αω w) pω(wx|αω) = Γ(P w nx w + αω w) Γ(αω w) (9) w P u Pl(u|uqi) × 3 λµPl(u|ud) ´ log (1−λµ)Pg(u) + 1 , where Pl(u|uqi) = Pu0 n(u0,µqi), Pl(u|ud) = Pn(u,ud) n(u,µqi) u0 n(u0,ud), and PPg(u) = P d n(u,ud) Pu0 n(u0,ud). d Sqi(d). (8) i=1 4S(µqi||µd) 451 0 2 4 6 8 10 n Figure 1: Relationship between original count n and dumped count v(n, α) where F is known as thegamma function, αωw is a parameter for word w and nxw = n(w, wx). This can be approximated as follows (Minka, 2003). 11 pω(wx|αω) � W(w)�n(w,w.) (10) w where n(w, wx) = αω w(IF(nx w + αωw) — IF(αωw)) � v(nxw, αωw) (11) IF is known as the digamma function and is similar to the natural logarithm. We call Eq. 10 the approximated Polya model or simply the Polya model in this paper. Eq. 10 indicates that the Polya distribution can be interpreted as a multinomial distribution over a modified set of counts n(·) (Minka, 2003). These modified counts are dumped as shown in Fig. 1. When αωw -* oc, v(nxw, αωw) approaches nxw. When αωw -* 0, v(nxw, αωw) = 0 if nxw = 0 otherwise it is 1. For intermediate values of αωw, </context>
<context position="27822" citStr="Minka, 2003" startWordPosition="4887" endWordPosition="4888">ge modeling framework while CProb handles only CF. Another advantage of the Polya model is that we can expect to improve its performance by incorporating techniques developed in IR because the Polya model is based on language modeling approaches in IR. 4 Future work We want to investigate two areas in our future work. One is the parameter estimation and the other is the refinement of the query model. We tuned the parameters of the Polya model by exhaustively searching the parameter space guided by R-precision. We actually tried to learn αu, and αµ from the training data by using an EM method (Minka, 2003; Yamamoto and Sadamitsu, 2005). However, the estimated parameters were about 0.05, too small for better recommendations. We need further study to understand the relation between the probabilistic quality (perplexity) of the Polya model and its recommendation quality. We approximate the query model as Eq. 3. This allows us to optimize score calculation considerably. However, this does not consider the interaction among items, which may deteriorate the quality of probability estimation. We want to investigate more efficient query models in our future work. 5 Conclusion Recommender systems help </context>
</contexts>
<marker>Minka, 2003</marker>
<rawString>Thomas P. Minka. 2003. Estimating a Dirichlet distribution. http://research.microsoft.com/˜minka/papers/dirichlet/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Resnick</author>
<author>Hal R Varian</author>
</authors>
<title>Recommender systems.</title>
<date>1997</date>
<journal>Communications of the ACM,</journal>
<volume>40</volume>
<issue>3</issue>
<pages>58</pages>
<contexts>
<context position="1165" citStr="Resnick and Varian, 1997" startWordPosition="164" endWordPosition="167">feedback (RF). Both CF and RF exploit users’ preference/relevance judgments to recommend items. We first introduce a multinomial model that combines CF and CBF in a language modeling framework. We then generalize the model to another multinomial model that approximates the Polya distribution. This generalized model outperforms the multinomial model by 3.4% for CBF and 17.4% for CF in recommending English Wikipedia articles. The performance of the generalized model for three different datasets was comparable to that of a state-of-theart item-based CF method. 1 Introduction Recommender systems (Resnick and Varian, 1997) help users select particular items (e.g, movies, books, music, and TV programs) that match their taste from a large number of choices by providing recommendations. The systems either recommend a set of N items that will be of interest to users (top-N recommendation problem) or predict the degree of users’ preference for items (prediction problem). For those systems to work, they first have to aggregate users’ evaluations of items explicitly or implicitly. Users may explicitly evaluate certain movies as rating five stars to express their preference. These evaluations are used by the systems as</context>
</contexts>
<marker>Resnick, Varian, 1997</marker>
<rawString>Paul Resnick and Hal R. Varian. 1997. Recommender systems. Communications of the ACM, 40(3):56– 58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Resnick</author>
<author>Neophytos Iacovou</author>
<author>Mitesh Suchak</author>
<author>Peter Bergstrom</author>
<author>John Riedl</author>
</authors>
<title>GroupLens: An open architecture for collaborative filtering of netnews.</title>
<date>1994</date>
<booktitle>In CSCW’94,</booktitle>
<pages>175--186</pages>
<contexts>
<context position="2146" citStr="Resnick et al., 1994" startWordPosition="322" endWordPosition="325">systems to work, they first have to aggregate users’ evaluations of items explicitly or implicitly. Users may explicitly evaluate certain movies as rating five stars to express their preference. These evaluations are used by the systems as explicit ratings (votes) of items or the systems infer the evaluations of items from the behavior of users and use these inferred evaluations as implicit ratings. For example, systems can infer that users may like certain items if the systems learn which books they buy, which articles they read, or which TV programs they watch. Collaborative filtering (CF) (Resnick et al., 1994; Breese et al., 1998) and content-based (or adaptive) filtering (CBF) (Allan, 1996; Schapire et al., 1998) are two of the most popular types of algorithms used in recommender systems. A CF system makes recommendations to current (active) users by exploiting their ratings in the database. User-based CF (Resnick et al., 1994; Herlocker et al., 1999) and item-based CF (Sarwar et al., 2001; Karypis, 2001), among other CF algorithms, have been studied extensively. User-based CF first identifies a set of users (neighbors) that are similar to the active user in terms of their rating patterns in the </context>
</contexts>
<marker>Resnick, Iacovou, Suchak, Bergstrom, Riedl, 1994</marker>
<rawString>Paul Resnick, Neophytos Iacovou, Mitesh Suchak, Peter Bergstrom, and John Riedl. 1994. GroupLens: An open architecture for collaborative filtering of netnews. In CSCW’94, pages 175–186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Badrul Sarwar</author>
<author>George Karypis</author>
<author>Joseph Konstan</author>
<author>John Riedl</author>
</authors>
<title>Item-based collaborative filtering recommendation algorithms.</title>
<date>2001</date>
<booktitle>In WWW10.</booktitle>
<contexts>
<context position="2535" citStr="Sarwar et al., 2001" startWordPosition="384" endWordPosition="387">cit ratings. For example, systems can infer that users may like certain items if the systems learn which books they buy, which articles they read, or which TV programs they watch. Collaborative filtering (CF) (Resnick et al., 1994; Breese et al., 1998) and content-based (or adaptive) filtering (CBF) (Allan, 1996; Schapire et al., 1998) are two of the most popular types of algorithms used in recommender systems. A CF system makes recommendations to current (active) users by exploiting their ratings in the database. User-based CF (Resnick et al., 1994; Herlocker et al., 1999) and item-based CF (Sarwar et al., 2001; Karypis, 2001), among other CF algorithms, have been studied extensively. User-based CF first identifies a set of users (neighbors) that are similar to the active user in terms of their rating patterns in the database. It then uses the neighbors’ rating patterns to produce recommendations for the active user. On the other hand, item-based CF calculates the similarity between items beforehand and then recommends items that are similar to those preferred by the active user. The performance of item-based CF has been shown to be comparable to or better than that of user-based CF (Sarwar et al., </context>
<context position="11471" citStr="Sarwar et al., 2001" startWordPosition="1956" endWordPosition="1959">k 1 Sq(d) = k The calculation of Sq(d) can be very efficient because once we cache Sqi(d) for each item pair of qi and d in the database, we can reuse it to calculate Sq(d) for any query q. We further optimize the calculation of top-N recommendations by storing only the top 100 items (neighbors) in decreasing order of Sqi(·) for each item qi and setting the scores of lower ranked items as 0. (Note that Sqi(d) &gt;= 0 holds.) Consequently, we only have to search small part of the search space without affecting the performance very much. These two types of optimization are common in item-based CF (Sarwar et al., 2001; Karypis, 2001). 2.3 Polya model Our second model is based on the Polya distribution. We first introduce (hyper) parameter Θ = {αω, αµ} and denote the probability of x given Θ as p(x|Θ) = pω(wx|αω)pµ(ux|αµ). αω and αµ are the parameter vectors for words and users. pω(wx|αω) is defined as follows. Γ(P w αω w) Y Γ(nx w + αω w) pω(wx|αω) = Γ(P w nx w + αω w) Γ(αω w) (9) w P u Pl(u|uqi) × 3 λµPl(u|ud) ´ log (1−λµ)Pg(u) + 1 , where Pl(u|uqi) = Pu0 n(u0,µqi), Pl(u|ud) = Pn(u,ud) n(u,µqi) u0 n(u0,ud), and PPg(u) = P d n(u,ud) Pu0 n(u0,ud). d Sqi(d). (8) i=1 4S(µqi||µd) 451 0 2 4 6 8 10 n Figure 1: R</context>
</contexts>
<marker>Sarwar, Karypis, Konstan, Riedl, 2001</marker>
<rawString>Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. 2001. Item-based collaborative filtering recommendation algorithms. In WWW10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert E Schapire</author>
<author>Yoram Singer</author>
<author>Amit Singhal</author>
</authors>
<title>Boosting and Rocchio applied to text filtering.</title>
<date>1998</date>
<booktitle>In SIGIR’98,</booktitle>
<pages>215--223</pages>
<contexts>
<context position="2253" citStr="Schapire et al., 1998" startWordPosition="338" endWordPosition="341"> may explicitly evaluate certain movies as rating five stars to express their preference. These evaluations are used by the systems as explicit ratings (votes) of items or the systems infer the evaluations of items from the behavior of users and use these inferred evaluations as implicit ratings. For example, systems can infer that users may like certain items if the systems learn which books they buy, which articles they read, or which TV programs they watch. Collaborative filtering (CF) (Resnick et al., 1994; Breese et al., 1998) and content-based (or adaptive) filtering (CBF) (Allan, 1996; Schapire et al., 1998) are two of the most popular types of algorithms used in recommender systems. A CF system makes recommendations to current (active) users by exploiting their ratings in the database. User-based CF (Resnick et al., 1994; Herlocker et al., 1999) and item-based CF (Sarwar et al., 2001; Karypis, 2001), among other CF algorithms, have been studied extensively. User-based CF first identifies a set of users (neighbors) that are similar to the active user in terms of their rating patterns in the database. It then uses the neighbors’ rating patterns to produce recommendations for the active user. On th</context>
<context position="5071" citStr="Schapire et al., 1998" startWordPosition="790" endWordPosition="793">chine learning algorithms that require both positive and negative examples for classification (e.g., support vector machines) is awkward. Our approach is based on the advancement in language modeling approaches to information retrieval (IR) (Croft and Lafferty, 2003) and extends these to incorporate CF. The motivation behind our approach is the analogy between CF and IR, especially between CF and relevance feedback (RF). Both CF and RF recommend items based on user preference/relevance judgments. Indeed, RF techniques have been applied to CBF, or adaptive filtering, successfully (Allan, 1996; Schapire et al., 1998). Thus, it is likely that RF can also be applied to CF. To apply RF, we first extend the representation of items to combine CF and CBF under the models developed in Section 2. In Section 3, we report our experiments with the models. Future work and conclusion are in Sections 4 and 5. 2 Relevance feedback models The analogy between IR and CF that will be exploited in this paper is as follows.2 First, a document in IR corresponds to an item in CF. Both are represented as vectors. A document is represented as a vector of words (bag-of-words) and an item is represented as a vector of user ratings </context>
</contexts>
<marker>Schapire, Singer, Singhal, 1998</marker>
<rawString>Robert E. Schapire, Yoram Singer, and Amit Singhal. 1998. Boosting and Rocchio applied to text filtering. In SIGIR’98, pages 215–223.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luo Si</author>
<author>Rong Jin</author>
</authors>
<title>Unified filtering by combining collaborative filtering and content-based filtering via mixture model and exponential model.</title>
<date>2004</date>
<booktitle>In CIKM-04,</booktitle>
<pages>156--157</pages>
<contexts>
<context position="3433" citStr="Si and Jin, 2004" startWordPosition="540" endWordPosition="543">endations for the active user. On the other hand, item-based CF calculates the similarity between items beforehand and then recommends items that are similar to those preferred by the active user. The performance of item-based CF has been shown to be comparable to or better than that of user-based CF (Sarwar et al., 2001; Karypis, 2001). In contrast to CF, CBF uses the contents (e.g., texts, genres, authors, images, and audio) of items to make recommendations for the active user. Because CF and CBF are complementary, much work has been done to combine them (Basu et al., 1998; Yu et al., 2003; Si and Jin, 2004; Basilico and Hofmann, 2004). The approach we took in this study is designed to solve top-N recommendation problems with im449 Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 449–456, Sydney, July 2006. c�2006 Association for Computational Linguistics plicit ratings by using an item-based combination of CF and CBF. The methods described in this paper will be applied to recommending English Wikipedia1 articles based on those articles edited by active users. (This is discussed in Section 3.) We use their editing histories and the conten</context>
</contexts>
<marker>Si, Jin, 2004</marker>
<rawString>Luo Si and Rong Jin. 2004. Unified filtering by combining collaborative filtering and content-based filtering via mixture model and exponential model. In CIKM-04, pages 156–157.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Wang</author>
<author>Marcel J T Reinders</author>
<author>Reginald L Lagendijk</author>
<author>Johan Pouwelse</author>
</authors>
<title>Selforganizing distributed collaborative filtering.</title>
<date>2005</date>
<booktitle>In SIGIR’05,</booktitle>
<pages>659--660</pages>
<contexts>
<context position="6067" citStr="Wang et al. (2005)" startWordPosition="966" endWordPosition="969">r is as follows.2 First, a document in IR corresponds to an item in CF. Both are represented as vectors. A document is represented as a vector of words (bag-of-words) and an item is represented as a vector of user ratings (bag-ofuser ratings). In RF, a user specifies documents that are relevant to his information need. These documents are used by the system to retrieve new 1http://en.wikipedia.org/wiki/Main Page 2The analogy between IR and CF has been recognized. For example, Breese et al. (1998) used the vector space model to measure the similarity between users in a user-based CF framework. Wang et al. (2005) used a language modeling approach different from ours. These works, however, treated only CF. In contrast with these, our model extends language modeling approaches to incorporate both CF and CBF. relevant documents. In CF, an active user (implicitly) specifies items that he likes. These items are used to search new items that will be preferred by the active user. We use relevance models (Lavrenko and Croft, 2001; Lavrenko, 2004) as the basic framework of our relevance feedback models because (1) they perform relevance feedback well (Lavrenko, 2004) and (2) they can simultaneously handle diff</context>
<context position="24055" citStr="Wang et al., 2005" startWordPosition="4220" endWordPosition="4223">as features and CF used user ratings as features. They are very different kinds of features and thus can provide complementary information. Consequently, CBF+CF can exploit the benefits of both methods. We need to do further work to confirm this conjecture. 3.2 Comparison with a baseline method We compared the Polya model to an implementation of a state-of-the-art item-based CF method, CProb (Karypis, 2001). CProb has been tested with various datasets and found to be effective in top-N recommendation problems. CProb has also been used in recent work as a baseline method (Ziegler et al., 2005; Wang et al., 2005). In addition to the Wikipedia dataset, we used two other datasets for comparison. The first was 454 WP R-precision BX WP P@10 BX ML ML Polya-CF 0.081 0.272 0.066 0.112 0.384 0.054 CProb 0.082 0.258 0.071 0.113 0.373 0.057 %change -1.2% +5.4% -7.0% -0.9% +2.9% -5.3% Table 3: Comparison of Polya-CF and CProb the 1 million MovieLens dataset.7 This data consists of 1,000,209 ratings of 3,706 movies by 6,040 users. Each user rated an average of 166 movies (the median was 96). The average number of ratings per movie was 270 and the median was 124. The second was the BookCrossing dataset (Ziegler et</context>
</contexts>
<marker>Wang, Reinders, Lagendijk, Pouwelse, 2005</marker>
<rawString>Jun Wang, Marcel J.T. Reinders, Reginald L. Lagendijk, and Johan Pouwelse. 2005. Selforganizing distributed collaborative filtering. In SIGIR’05, pages 659–660.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikio Yamamoto</author>
<author>Kugatsu Sadamitsu</author>
</authors>
<title>Dirichlet mixtures in text modeling.</title>
<date>2005</date>
<tech>Technical report,</tech>
<pages>05--1</pages>
<institution>University of Tsukuba,</institution>
<contexts>
<context position="14343" citStr="Yamamoto and Sadamitsu (2005)" startWordPosition="2482" endWordPosition="2485">or to the multinomial model for modeling the occurrences of words (and users). In the multinomial model, if a word with probability p occurs twice, its probability becomes p2. In the Polya model, the word’s probability becomes p1.5, for example, if we set αωw = 1. Clearly, p2 &lt; p1.5; therefore, the Polya model assigns higher probability. In this example, the Polya model assigns probability p to the first occurrence and p0.5(&gt; p) to the second. Since words that occur once are likely to occur again (Church, 2000), the Polya model is better suited to model the occurrences of words and users. See Yamamoto and Sadamitsu (2005) for further discussion on applying the Polya distribution to text modeling. Zaragoza et al.(2003) applied the Polya distribution to ad hoc IR. They introduced the exact Polya distribution (see Eq. 9) as an extension to the Dirichlet prior method (Zhai and Lafferty, 2001). However, we have introduced a multinomial approximation of the Polya distribution. This approximation allows us to use the linear interpolation method to mix the approximated Polya distributions. Thus, our model is similar to two-stage language models (Zhai and Lafferty, 2002) that combine the Dirichlet prior method and the </context>
<context position="27853" citStr="Yamamoto and Sadamitsu, 2005" startWordPosition="4889" endWordPosition="4892">ramework while CProb handles only CF. Another advantage of the Polya model is that we can expect to improve its performance by incorporating techniques developed in IR because the Polya model is based on language modeling approaches in IR. 4 Future work We want to investigate two areas in our future work. One is the parameter estimation and the other is the refinement of the query model. We tuned the parameters of the Polya model by exhaustively searching the parameter space guided by R-precision. We actually tried to learn αu, and αµ from the training data by using an EM method (Minka, 2003; Yamamoto and Sadamitsu, 2005). However, the estimated parameters were about 0.05, too small for better recommendations. We need further study to understand the relation between the probabilistic quality (perplexity) of the Polya model and its recommendation quality. We approximate the query model as Eq. 3. This allows us to optimize score calculation considerably. However, this does not consider the interaction among items, which may deteriorate the quality of probability estimation. We want to investigate more efficient query models in our future work. 5 Conclusion Recommender systems help users select particular items f</context>
</contexts>
<marker>Yamamoto, Sadamitsu, 2005</marker>
<rawString>Mikio Yamamoto and Kugatsu Sadamitsu. 2005. Dirichlet mixtures in text modeling. Technical report, University of Tsukuba, CS-TR-05-1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kai Yu</author>
<author>Anton Schwaighofer</author>
<author>Volker Tresp</author>
<author>Wei-Ying Ma</author>
<author>HongJiang Zhang</author>
</authors>
<title>Collaborative ensemble learning: Combining collaborative and content-based information filtering via hierarchical Bayes.</title>
<date>2003</date>
<booktitle>In UAI-2003.</booktitle>
<contexts>
<context position="3415" citStr="Yu et al., 2003" startWordPosition="536" endWordPosition="539">to produce recommendations for the active user. On the other hand, item-based CF calculates the similarity between items beforehand and then recommends items that are similar to those preferred by the active user. The performance of item-based CF has been shown to be comparable to or better than that of user-based CF (Sarwar et al., 2001; Karypis, 2001). In contrast to CF, CBF uses the contents (e.g., texts, genres, authors, images, and audio) of items to make recommendations for the active user. Because CF and CBF are complementary, much work has been done to combine them (Basu et al., 1998; Yu et al., 2003; Si and Jin, 2004; Basilico and Hofmann, 2004). The approach we took in this study is designed to solve top-N recommendation problems with im449 Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 449–456, Sydney, July 2006. c�2006 Association for Computational Linguistics plicit ratings by using an item-based combination of CF and CBF. The methods described in this paper will be applied to recommending English Wikipedia1 articles based on those articles edited by active users. (This is discussed in Section 3.) We use their editing histor</context>
</contexts>
<marker>Yu, Schwaighofer, Tresp, Ma, Zhang, 2003</marker>
<rawString>Kai Yu, Anton Schwaighofer, Volker Tresp, Wei-Ying Ma, and HongJiang Zhang. 2003. Collaborative ensemble learning: Combining collaborative and content-based information filtering via hierarchical Bayes. In UAI-2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hugo Zaragoza</author>
<author>Djoerd Hiemstra</author>
<author>Michael Tipping</author>
</authors>
<title>Bayesian extension to the language model for ad hoc information retrieval.</title>
<date>2003</date>
<booktitle>In SIGIR’03.</booktitle>
<marker>Zaragoza, Hiemstra, Tipping, 2003</marker>
<rawString>Hugo Zaragoza, Djoerd Hiemstra, and Michael Tipping. 2003. Bayesian extension to the language model for ad hoc information retrieval. In SIGIR’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ChengXiang Zhai</author>
<author>John Lafferty</author>
</authors>
<title>A study of smoothing methods for language models applied to ad hoc information retrieval.</title>
<date>2001</date>
<booktitle>In SIGIR’01.</booktitle>
<contexts>
<context position="14615" citStr="Zhai and Lafferty, 2001" startWordPosition="2527" endWordPosition="2530">&lt; p1.5; therefore, the Polya model assigns higher probability. In this example, the Polya model assigns probability p to the first occurrence and p0.5(&gt; p) to the second. Since words that occur once are likely to occur again (Church, 2000), the Polya model is better suited to model the occurrences of words and users. See Yamamoto and Sadamitsu (2005) for further discussion on applying the Polya distribution to text modeling. Zaragoza et al.(2003) applied the Polya distribution to ad hoc IR. They introduced the exact Polya distribution (see Eq. 9) as an extension to the Dirichlet prior method (Zhai and Lafferty, 2001). However, we have introduced a multinomial approximation of the Polya distribution. This approximation allows us to use the linear interpolation method to mix the approximated Polya distributions. Thus, our model is similar to two-stage language models (Zhai and Lafferty, 2002) that combine the Dirichlet prior method and the linear interpolation method. In contrast to our model, Zaragoza et al.(2003) had difficulty in mixing the Polya distributions and did not treat that in their paper. 3 Experiments We first examined the behavior of the Polya model by varying the parameters. We tied αωw for </context>
</contexts>
<marker>Zhai, Lafferty, 2001</marker>
<rawString>ChengXiang Zhai and John Lafferty. 2001. A study of smoothing methods for language models applied to ad hoc information retrieval. In SIGIR’01.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ChengXiang Zhai</author>
<author>John Lafferty</author>
</authors>
<title>Two-stage language models for information retrieval.</title>
<date>2002</date>
<booktitle>In SIGIR’02,</booktitle>
<pages>49--56</pages>
<contexts>
<context position="14894" citStr="Zhai and Lafferty, 2002" startWordPosition="2570" endWordPosition="2573">del the occurrences of words and users. See Yamamoto and Sadamitsu (2005) for further discussion on applying the Polya distribution to text modeling. Zaragoza et al.(2003) applied the Polya distribution to ad hoc IR. They introduced the exact Polya distribution (see Eq. 9) as an extension to the Dirichlet prior method (Zhai and Lafferty, 2001). However, we have introduced a multinomial approximation of the Polya distribution. This approximation allows us to use the linear interpolation method to mix the approximated Polya distributions. Thus, our model is similar to two-stage language models (Zhai and Lafferty, 2002) that combine the Dirichlet prior method and the linear interpolation method. In contrast to our model, Zaragoza et al.(2003) had difficulty in mixing the Polya distributions and did not treat that in their paper. 3 Experiments We first examined the behavior of the Polya model by varying the parameters. We tied αωw for every w and αµu for every u; for any w and u, αωw = αω and αµu = αµ. We then compared the Polya model to an item-based CF method. 3.1 Behavior of Polya model 3.1.1 Dataset We made a dataset of articles from English Wikipedia5 to evaluate the Polya model. English Wikipedia is an </context>
</contexts>
<marker>Zhai, Lafferty, 2002</marker>
<rawString>ChengXiang Zhai and John Lafferty. 2002. Two-stage language models for information retrieval. In SIGIR’02, pages 49–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cai-Nicolas Ziegler</author>
<author>Sean M McNee</author>
<author>Joseph A Konstan</author>
<author>Georg Lausen</author>
</authors>
<title>Improving recommendation lists through topic diversification.</title>
<date>2005</date>
<booktitle>In WWW’05,</booktitle>
<pages>22--32</pages>
<contexts>
<context position="24035" citStr="Ziegler et al., 2005" startWordPosition="4216" endWordPosition="4219">nd CF. CBF used words as features and CF used user ratings as features. They are very different kinds of features and thus can provide complementary information. Consequently, CBF+CF can exploit the benefits of both methods. We need to do further work to confirm this conjecture. 3.2 Comparison with a baseline method We compared the Polya model to an implementation of a state-of-the-art item-based CF method, CProb (Karypis, 2001). CProb has been tested with various datasets and found to be effective in top-N recommendation problems. CProb has also been used in recent work as a baseline method (Ziegler et al., 2005; Wang et al., 2005). In addition to the Wikipedia dataset, we used two other datasets for comparison. The first was 454 WP R-precision BX WP P@10 BX ML ML Polya-CF 0.081 0.272 0.066 0.112 0.384 0.054 CProb 0.082 0.258 0.071 0.113 0.373 0.057 %change -1.2% +5.4% -7.0% -0.9% +2.9% -5.3% Table 3: Comparison of Polya-CF and CProb the 1 million MovieLens dataset.7 This data consists of 1,000,209 ratings of 3,706 movies by 6,040 users. Each user rated an average of 166 movies (the median was 96). The average number of ratings per movie was 270 and the median was 124. The second was the BookCrossing</context>
</contexts>
<marker>Ziegler, McNee, Konstan, Lausen, 2005</marker>
<rawString>Cai-Nicolas Ziegler, Sean M. McNee, Joseph A. Konstan, and Georg Lausen. 2005. Improving recommendation lists through topic diversification. In WWW’05, pages 22–32.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>