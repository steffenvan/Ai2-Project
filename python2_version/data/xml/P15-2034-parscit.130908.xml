<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003435">
<title confidence="0.99183">
Word Order Typology through Multilingual Word Alignment
</title>
<author confidence="0.998209">
Robert ¨Ostling
</author>
<affiliation confidence="0.9821725">
Department of Linguistics
Stockholm University
</affiliation>
<address confidence="0.893494">
SE-106 91 Stockholm, Sweden
</address>
<email confidence="0.997201">
robert@ling.su.se
</email>
<sectionHeader confidence="0.994749" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99994676">
With massively parallel corpora of hun-
dreds or thousands of translations of the
same text, it is possible to automatically
perform typological studies of language
structure using very large language sam-
ples. We investigate the domain of word
order using multilingual word alignment
and high-precision annotation transfer in a
corpus with 1144 translations in 986 lan-
guages of the New Testament. Results are
encouraging, with 86% to 96% agreement
between our method and the manually cre-
ated WALS database for a range of differ-
ent word order features. Beyond reproduc-
ing the categorical data in WALS and ex-
tending it to hundreds of other languages,
we also provide quantitative data for the
relative frequencies of different word or-
ders, and show the usefulness of this for
language comparison. Our method has
applications for basic research in linguis-
tic typology, as well as for NLP tasks
like transfer learning for dependency pars-
ing, which has been shown to benefit from
word order information.
</bodyText>
<sectionHeader confidence="0.998883" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999947575757576">
Since the work of Greenberg (1963), word order
features have played a central role in linguistic ty-
pology research. There is a great deal of varia-
tion across languages, and interesting interactions
between different features which may hint at cog-
nitive constraints in the processing of human lan-
guage. A full theoretical discussion on word order
typology is beyond the scope of this paper, but the
interested reader is referred to e.g. Dryer (2007)
for an overview of the field.
This study uses multilingual word alignment
( ¨Ostling, 2014) and high-precision annotation pro-
jection of part-of-speech (PoS) tags and depen-
dency parse trees to investigate five different
word order properties in 986 different languages,
through a corpus of New Testament translations.
The results are validated through comparison to
relevant chapters in the World Atlas on Language
Structures, WALS (Dryer and Haspelmath, 2013),
and we find a very high level of agreement be-
tween this database and our method.
We identify two primary applications of this
method. First, it provides a new tool for basic re-
search in linguistic typology. Second, it has been
shown that using these word order features leads
to increased accuracy during dependency parsing
model transfer (T¨ackstr¨om et al., 2013). These
benefits can now be extended to hundreds of more
languages. The quantified word order characteris-
tics computed for each of the 986 languages in the
New Testament corpus, including about 600 not in
the WALS samples for these features, are available
for download.1
</bodyText>
<sectionHeader confidence="0.999675" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999548461538462">
Using parallel texts for linguistic typology has be-
come increasingly popular recently, as massively
parallel texts with hundreds or thousands of lan-
guages have become easily accessible through the
web (Cysouw and W¨alchli, 2007; Dahl, 2007;
W¨alchli, 2014). Specific applications include
data-driven language classification (Mayer and
Cysouw, 2012) and lexical typology (W¨alchli and
Cysouw, 2012). However, unlike our work, none
of these authors developed automatic methods for
studying syntactic properties like word order, nor
did they utilize recent advances in the field of word
alignment algorithms.
</bodyText>
<footnote confidence="0.998963">
1http://www.ling.su.se/
acl2015-wordorder.zip
</footnote>
<page confidence="0.722234">
205
</page>
<bodyText confidence="0.229477">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 205–211,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</bodyText>
<sectionHeader confidence="0.976611" genericHeader="method">
3 Method
</sectionHeader>
<bodyText confidence="0.999051444444444">
The first step consists of using supervised systems
for annotating the source texts with Universal PoS
Tags (Petrov et al., 2012) and dependency struc-
ture in the Universal Dependency Treebank format
(McDonald et al., 2013). For PoS tagging, we use
the Stanford Tagger (Toutanova et al., 2003) fol-
lowed by a conversion step from the Penn Tree-
bank tagset to the “universal” PoS tags using the
tables published by Petrov et al. Next, we use the
MaltParser dependency parser (Nivre et al., 2007)
trained on the Universal Dependency Treebank us-
ing MaltOptimizer (Ballesteros and Nivre, 2012).
The corpus is then aligned using the multilin-
gual alignment tool of ¨Ostling (2014). This model
learns an “interlingua” representation of the text,
in this case the New Testament, to which all trans-
lations are then aligned independently. An inter-
lingua sentence e is assumed to generate the cor-
responding sentences f(l) for each of the L lan-
guages through a set of alignment variables a(l)
for each language. This can be seen as a multilin-
gual extension of the IBM model 1 (Brown et al.,
1993) with Dirichlet priors (Mermer and Sarac¸lar,
2011), where not only the alignment variables are
hidden but also the source e. The probability of a
sentence and its alignments (in L languages) under
this model is
</bodyText>
<equation confidence="0.998377">
P(a(1...L),f(1...L)|e) =
L J pt(f(l) j|ea(l) ) I (1)
l=1 H 7 · i=1 pc(ei)
j=1
</equation>
<bodyText confidence="0.999603695652174">
where the translation distributions pt are assumed
to have symmetric Dirichlet priors and the source
token distribution pc a Chinese Restaurant Process
prior. Given the parallel sentences f(1...L), then
a(1...L) and e are sampled using Gibbs sampling.
The advantage of this method is that the multi-
source transfer can be done once, to the interlin-
gua representation, then transferred in a second
step to all of the 986 languages investigated. It
would be possible to instead perform 986 separate
multi-source projection steps, but at the expense of
having to perform a large number of bitext align-
ments.
From the annotated source texts, PoS and de-
pendency annotations are transferred to the inter-
lingua representation. Since alignments are noisy
and low recall is acceptable in this task, we use
an aggressive filtering scheme: dependency links
must be transferred from at least 80% of source
texts in order to be included. For PoS tags,
which are only used to double-check grammati-
cal relations and should not impact precision neg-
atively, the majority tag among aligned words is
used. Apart from compensating for noisy align-
ments and parsing errors, this method also helps
to catch violations against the direct correspon-
dence assumption (Hwa et al., 2002) by filter-
ing out instances where different source texts use
different constructions, favoring the most proto-
typical cases. Each word order feature is coded
in terms of dependency relations, with additional
constraints on the parts of speech that can be in-
volved. For instance, when investigating the order
between nouns and their modifying adjectives we
look for an AMOD dependency relation between
an ADJ-tagged and a NOUN-tagged word, and note
the order between the adjective and the noun. This
method rests on the assumption that translation
equivalents have the same grammatical functions
across translations, which is not always the case.
For instance, if one language uses a passive con-
struction where the source texts all use the active
voice, we would obtain the wrong order between
subject and object.
To summarize, our algorithm consists of the fol-
lowing steps:
</bodyText>
<listItem confidence="0.989837625">
1. Compute an interlingua representation of the
parallel text, as well as word alignments link-
ing it to each of the translations.
2. Annotate a subset of translations with PoS
tags and dependency structure.
3. Use multi-source annotation projection from
this subset to the interlingua representation,
including only dependency links where the
same link is projected from at least 80% of
the source translations.
4. Use single-source annotation projection from
the interlingua representation to each of the
986 translations.
5. For each construction of interest, and for each
language, count the frequency of each order-
ing of its constituents.
</listItem>
<sectionHeader confidence="0.991626" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999816">
We evaluate our method through comparison
to the WALS database (Dryer and Haspelmath,
</bodyText>
<page confidence="0.996016">
206
</page>
<table confidence="0.9961668">
SOV SVO OSV OVS VSO VOS
Polynesian (Hawaiian, Maori)
3 31 2 2 70 3
6 26 5 4 76 18
Sinitic (Mandarin, Hakka)
54 235 6 0 3 5
18 84 1 2 5 3
Turkic (Kara-Kalpak, Kumyk)
114 2 8 7 0 0
89 1 12 11 4 1
</table>
<tableCaption confidence="0.998408">
Table 1: Number of transitive clauses with a given
</tableCaption>
<bodyText confidence="0.8342024">
order of subject/object/verb, according to our al-
gorithm, for six languages (from three families).
2013), by manual analysis of selected cases, and
by cluster analysis of the word order properties
computed for each language by our method.
</bodyText>
<subsectionHeader confidence="0.935951">
4.1 Data and methodology
</subsectionHeader>
<bodyText confidence="0.999988076923077">
A corpus of web-crawled translations of the New
Testament was used, comprising 1144 translations
in 986 different languages. Of these, we used five
English translations as source texts for annotation
projection. Ideally more languages should be used
as sources, but since we only had access to com-
plete annotation pipelines for English and German
we only considered these two languages, and pre-
liminary experiments using some German transla-
tions in addition to the English ones did not lead
to significantly different results. A typologically
more diverse set of source languages would help
to identify those instances in the text which are
most consistently translated across languages, in
order to reduce the probability that peculiarities of
the source language(s) will bias the results.
In order to evaluate our method automatically,
we used data from the WALS database (Dryer and
Haspelmath, 2013) which classifies languages ac-
cording to a large number of features. Several fea-
tures concern word order, and we focused on five
of these (listed in Table 2). Only languages which
are represented both in the New Testament cor-
pus and the WALS data were used for the evalua-
tion. In addition, we exclude languages for which
WALS does not indicate a particular word order.
This might be due to e.g. lacking adpositions alto-
gether (which makes the adposition/noun order of
that language undefined), or because no specific
order is considered dominant.
The frequencies of all possible word orders for
a feature are then counted, and for the purpose of
evaluation the most common order is chosen as the
algorithm’s output. Although the relative frequen-
cies of the different possible word orders are dis-
carded for the sake of comparability with WALS,
these frequencies are themselves an important re-
sult of our work and tell a much richer story of the
word order properties (see Table 1 and Figure 1).
Counting the number of instances (token fre-
quency) of each word order is the most straight-
forward way to estimate the relative proportions of
each ordering, but the results are biased towards
the behavior of the most frequent words, which
often have idiosyncratic, non-productive features.
Therefore, we also compute the corresponding
statistics where each type is counted only once for
each word order it participates in, disregarding its
frequency. The type-based counts should better
capture the behavior of productive patterns in the
language. For the purpose of this study, we define
the type of our relations as follows:
</bodyText>
<listItem confidence="0.999861">
• adjective-noun: the form of the adjective
• adposition-noun: the forms of both adposi-
tion and noun
• verb-(subject)-(object): the form of the verb
</listItem>
<bodyText confidence="0.999966">
For instance, given the following three sentences:
“we see him,” “I see her” and “them I see”, we
would increase the count by one for SVO order
and for OVS order, because these are the orders in
which the verb see has been observed to partici-
pate.
In cases where there are multiple translations
into a particular language, information is aggre-
gated from all these translations into a single pro-
file for the language. This is problematic in some
cases, such as when a very long time separates two
translations and word order characteristics have
evolved, or simply due to different translators or
source texts. However, since the typical case is a
single translation per language, and WALS only
contains one data point per language, we leave
inter-language comparison to future research.
</bodyText>
<subsectionHeader confidence="0.530374">
4.2 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.9966798">
Table 1 shows how the output of our token-based
algorithm looks for three pairs of languages se-
lected from different families. The absolute counts
vary due to our filtering procedure and differing
numbers of translations, but as we might expect
</bodyText>
<page confidence="0.968727">
207
</page>
<figure confidence="0.995379235294118">
Southern Altai (T)
Tuvinian (T)
Tatar (T)
Kara-Kalpak (T)
Kazakh (T)
Karachay-Balkar (T)
Khakas (T)
Uighur (T)
Kirghiz (T)
Kumyk (T)
Gagauz (T)
Afrikaans (G)
Plautdietsch (G)
Dutch (G)
German (G)
Swabian (G)
Samoan (P)
Maori (P)
Hawaiian (P)
Kapingamarangi (P)
Romanian (R)
French (R)
Italian (R)
Catalan (R)
Spanish (R)
Portuguese (R)
Mandarin Chinese (S)
Hakka Chinese (S)
English (G)
Icelandic (G)
Swedish (G)
Faroese (G)
Danish (G)
Norwegian (G)
</figure>
<figureCaption confidence="0.9878725">
Figure 1: Hierarchical clustering based on word order statistics from our algorithm. Language families
represented are (G)ermanic, (R)omance, (T)urkic, (P)olynesian and (S)initic.
</figureCaption>
<bodyText confidence="0.994475925925926">
the relative numbers are quite similar within each
pair.
As a way of visualizing our data, we also
tried performing hierarchical clustering of lan-
guages, by normalizing the word order count vec-
tors and treating them (together) as a single 14-
dimensional vector. The result confirmed that lan-
guages can be grouped remarkably well on basis
of these five automatically extracted word order
features. A subset of the clustering containing
all languages from five language families repre-
sented in the New Testament corpus can be found
in Figure 1. While the clustering mostly follows
traditional genealogical boundaries, it is perhaps
more interesting to look at the cases where it does
not. The most glaring case is the wide split be-
tween the West Germanic and the North Germanic
languages, which in spite of their shared ances-
try have widely different word order characteris-
tics. Interestingly, English is not grouped with
the West Germanic languages, but rather with the
North Germanic languages which it has been in
close contact with.2 One can also note that the
Sinitic languages, with respect to word order, are
quite close to the North Germanic languages.
Table 2 shows the agreement between the algo-
rithm’s output and the corresponding WALS chap-
</bodyText>
<footnote confidence="0.844002">
2One reviewer pointed us to the controversial claim of
Emonds (2011), that modern English in fact is a North Ger-
manic language, albeit with strong influence from the extinct
West Germanic language of Old English.
</footnote>
<bodyText confidence="0.999891258064516">
ter for each feature. The level of agreement is
high, even though the sample consists mainly of
languages unrelated to English, from which the
dependency structure and PoS annotations were
transferred. The most common column gives the
ratio of the most common ordering for each fea-
ture (according to WALS), which can serve as a
naive baseline.
As expected, the lowest level of agreement is
observed for WALS chapter 81A, which has a
lower baseline since it allows six permutations of
the verb, subject and object, whereas all the other
features are binary. In addition, this feature re-
quires that two dependency relations (subject-verb
and object-verb) have been correctly transferred,
which substantially reduces the number of rela-
tions available for comparison.
The fact that sources sometimes differ as to
the basic word order of a given language makes
it evident that the disagreement reported in Ta-
ble 2 is not necessarily due to errors made by
our algorithm. Another example of this can be
found when looking at the order of adjective and
noun in some Romance languages (Spanish, Cata-
lan, Portuguese, French and Italian), which are all
classified as having noun-adjective order (Dryer,
2013a). It turns out that adjective-noun order in
fact dominates in all of these languages, narrowly
when using type counts and by a fairly large mar-
gin when using token counts. This result was
confirmed by manual inspection, which leads us
</bodyText>
<page confidence="0.998997">
208
</page>
<tableCaption confidence="0.943459">
Table 2: Agreement between WALS and our results, on languages present in both datasets. The relative
</tableCaption>
<bodyText confidence="0.644189333333333">
frequency of the most common ordering is given for comparison. Types is the agreement using type-
based counts (see text for details), whereas Tokens uses token-based counts.
Feature
</bodyText>
<footnote confidence="0.9950846">
81A: Subject, Object, Verb (Dryer, 2013e)
82A: Subject, Verb (Dryer, 2013d)
83A: Object, Verb (Dryer, 2013c)
85A: Adposition, Noun Phrase (Dryer, 2013b)
87A: Adjective, Noun (Dryer, 2013a)
</footnote>
<note confidence="0.997315166666667">
Languages Types Tokens Most common
342 85.4% 85.7% SOV: 43.3%
376 89.4% 90.4% SV: 79.8%
387 96.4% 96.4% VO: 54.8%
329 94.8% 95.1% Prep: 50.4%
334 85.9% 88.0% AdjN: 68.9%
</note>
<bodyText confidence="0.994250375">
to search further for an explanation for the dis-
crepancy.3 The Universal Dependency Treebank
(McDonald et al., 2013) version 2 contains sub-
corpora in French, Italian, Spanish and Brazilian
Portuguese. In all of these, noun-adjective or-
der is dominant, which casts further doubts on
our result. The key difference turns out to be the
genre: whereas the modern texts used for the Uni-
versal Dependency Treebank have mainly noun-
adjective order, we used our supervised annota-
tion pipeline to confirm that the French transla-
tions of the New Testament indeed are dominated
by adjective-noun order. This should serve as a
warning about extrapolating too far from results
obtained in one very specific genre, let alone in a
single text.
</bodyText>
<sectionHeader confidence="0.96675" genericHeader="conclusions">
5 Conclusions and future directions
</sectionHeader>
<bodyText confidence="0.9999555">
The promising results from this study show that
high-precision annotation transfer is a realistic
way of exploring word order features in very large
language samples, when a suitable parallel text is
available. Although the WALS features on word
order already use very large samples (over a thou-
sand languages), using our method with the New
Testament corpus contributes about 600 additional
data points per feature, and adds quantitative data
for all of the 986 languages contained in the cor-
pus.
There are many other structural properties of
languages that could be investigated with high-
precision annotation transfer in massively paral-
lel corpora, not just regarding word order but also
within in domains such as negation, comparison
and tense/aspect systems. While there are lim-
its to the quality and types of answers obtainable,
our work demonstrates that for some problems it is
possible to obtain quick, quantitative answers that
</bodyText>
<subsectionHeader confidence="0.360355">
3Thanks to Francesca Di Garbo for helping with this.
</subsectionHeader>
<bodyText confidence="0.9981783125">
can be used to guide more traditional and thorough
typological research.
On the technical side, the alignment model used
is based on a non-symmetrized IBM model 1, and
more elaborate methods for alignment and annota-
tion projection could potentially lead to more ac-
curate results. Preliminary results however indi-
cate that adding a HMM-based word order model
akin to Vogel et al. (1996) actually leads to some-
what reduced agreement with the WALS classifi-
cation, because the projections become biased to-
wards the word order characteristics of the source
language(s), in our case English. This indicates
that using the less accurate but also less biased
IBM model 1 is in fact an advantage, when ag-
gressive high-precision filtering is used.
</bodyText>
<sectionHeader confidence="0.985066" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9987996">
Thanks to Calle B¨orstell, ¨Osten Dahl, Francesca
Di Garbo, Joakim Nivre, Janet B. Pierrehumbert,
J¨org Tiedemann, Bernhard W¨alchli, Mats Wir´en
and the anonymous reviewers for helpful com-
ments and discussions.
</bodyText>
<page confidence="0.998169">
209
</page>
<sectionHeader confidence="0.983446" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999839387387387">
Miguel Ballesteros and Joakim Nivre. 2012. Mal-
tOptimizer: An optimization tool for MaltParser.
In Proceedings of the Demonstrations at the 13th
Conference of the European Chapter of the Asso-
ciation for Computational Linguistics, EACL ’12,
pages 58–62, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Peter F. Brown, Vincent J. Della Pietra, Stephen
A. Della Pietra, and Robert L. Mercer. 1993.
The mathematics of statistical machine translation:
Parameter estimation. Computational Linguistics,
19(2):263–311, June.
Michael Cysouw and Bernhard W¨alchli. 2007. Paral-
lel texts: Using translational equivalents in linguistic
typology. STUF - Language Typology and Univer-
sals, 60(2):95–99.
¨Osten Dahl. 2007. From questionnaires to parallel cor-
pora in typology. STUF - Language Typology and
Universals, 60(2):172–181.
Matthew S. Dryer and Martin Haspelmath. 2013. The
World Atlas of Language Structures Online. http:
//wals.info.
Matthew S. Dryer. 2007. Word order. In Timo-
thy Shopen, editor, Language Typology and Syntac-
tic Description, volume I, chapter 2, pages 61–131.
Cambridge University Press.
Matthew S. Dryer. 2013a. Order of adjective and noun.
In Matthew S. Dryer and Martin Haspelmath, edi-
tors, The World Atlas of Language Structures On-
line. Max Planck Institute for Evolutionary Anthro-
pology, Leipzig.
Matthew S. Dryer. 2013b. Order of adposition and
noun phrase. In Matthew S. Dryer and Martin
Haspelmath, editors, The World Atlas of Language
Structures Online. Max Planck Institute for Evolu-
tionary Anthropology, Leipzig.
Matthew S. Dryer. 2013c. Order of object and verb.
In Matthew S. Dryer and Martin Haspelmath, edi-
tors, The World Atlas of Language Structures On-
line. Max Planck Institute for Evolutionary Anthro-
pology, Leipzig.
Matthew S. Dryer. 2013d. Order of subject and verb.
In Matthew S. Dryer and Martin Haspelmath, edi-
tors, The World Atlas of Language Structures On-
line. Max Planck Institute for Evolutionary Anthro-
pology, Leipzig.
Matthew S. Dryer. 2013e. Order of subject, object and
verb. In Matthew S. Dryer and Martin Haspelmath,
editors, The World Atlas of Language Structures On-
line. Max Planck Institute for Evolutionary Anthro-
pology, Leipzig.
Joseph Emonds. 2011. English as a North Germanic
language: From the Norman conquest to the present.
In Roman Truˇsnfk, Katarfna Nemˇcokov´a, and Gre-
gory Jason Bell, editors, Proceedings of the Sec-
ond International Conference on English and Amer-
ican Studies, pages 13–26, Zl´ın, Czech Republic,
September.
Joseph H. Greenberg. 1963. Some universals of gram-
mar with particular reference to the order of mean-
ingful elements. In Joseph H. Greenberg, editor,
Universals of Human Language, pages 73–113. MIT
Press, Cambridge, Massachusetts.
Rebecca Hwa, Philip Resnik, Amy Weinberg, and
Okan Kolak. 2002. Evaluating translational cor-
respondence using annotation projection. In Pro-
ceedings of the 40th Annual Meeting on Association
for Computational Linguistics, ACL ’02, pages 392–
399, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Thomas Mayer and Michael Cysouw. 2012. Lan-
guage comparison through sparse multilingual word
alignment. In Proceedings of the EACL 2012 Joint
Workshop of LINGVIS &amp; UNCLH, EACL 2012,
pages 54–62, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-
Brundage, Yoav Goldberg, Dipanjan Das, Kuz-
man Ganchev, Keith Hall, Slav Petrov, Hao
Zhang, Oscar T¨ackstr¨om, Claudia Bedini, N´uria
Bertomeu Castell´o, and Jungmee Lee. 2013. Uni-
versal dependency annotation for multilingual pars-
ing. In Proceedings of the 51st Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 2: Short Papers), pages 92–97, Sofia, Bulgaria,
August. Association for Computational Linguistics.
Cos¸kun Mermer and Murat Sarac¸lar. 2011. Bayesian
word alignment for statistical machine translation.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies: short papers - Volume 2,
HLT ’11, pages 182–187, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Joakim Nivre, Johan Hall, Jens Nilsson, Atanas
Chanev, G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav
Marinov, and Erwin Marsi. 2007. MaltParser:
A language-independent system for data-driven de-
pendency parsing. Natural Language Engineering,
13:95–135, 6.
Robert ¨Ostling. 2014. Bayesian word alignment for
massively parallel texts. In Proceedings of the 14th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics, volume 2: Short
Papers, pages 123–127, Gothenburg, Sweden, April.
Association for Computational Linguistics.
Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012.
A universal part-of-speech tagset. In Proceed-
ings of the Eight International Conference on Lan-
guage Resources and Evaluation (LREC’12), Istan-
bul, Turkey, may. European Language Resources
Association (ELRA).
</reference>
<page confidence="0.981619">
210
</page>
<reference confidence="0.994743666666667">
Oscar T¨ackstr¨om, Dipanjan Das, Slav Petrov, Ryan
McDonald, and Joakim Nivre. 2013. Token and
type constraints for cross-lingual part-of-speech tag-
ging. Transactions of the Association for Computa-
tional Linguistics, 1:1–12.
Kristina Toutanova, Dan Klein, Christopher D. Man-
ning, and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network.
In Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology
- Volume 1, NAACL ’03, pages 173–180, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. HMM-based word alignment in statistical
translation. In Proceedings of the 16th Conference
on Computational Linguistics - Volume 2, COLING
’96, pages 836–841, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.
Bernhard W¨alchli and Michael Cysouw. 2012. Lex-
ical typology through similarity semantics: To-
ward a semantic map of motion verbs. Linguistics,
50(3):671–710.
Bernhard W¨alchli. 2014. Algorithmic typology and
going from known to similar unknown categories
within and across languages. In Benedikt Szm-
recsanyi and Bernhard W¨alchli, editors, Linguistic
Variation in Text and Speech, number 28 in Linguae
&amp; Litterae, pages 355–393. De Gruyter.
</reference>
<page confidence="0.998766">
211
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.353249">
<title confidence="0.767393">Word Order Typology through Multilingual Word Alignment</title>
<affiliation confidence="0.949938">Department of</affiliation>
<address confidence="0.737118">Stockholm SE-106 91 Stockholm,</address>
<email confidence="0.997079">robert@ling.su.se</email>
<abstract confidence="0.998640730769231">With massively parallel corpora of hundreds or thousands of translations of the same text, it is possible to automatically perform typological studies of language structure using very large language samples. We investigate the domain of word order using multilingual word alignment and high-precision annotation transfer in a corpus with 1144 translations in 986 languages of the New Testament. Results are encouraging, with 86% to 96% agreement between our method and the manually created WALS database for a range of different word order features. Beyond reproducing the categorical data in WALS and extending it to hundreds of other languages, we also provide quantitative data for the relative frequencies of different word orders, and show the usefulness of this for language comparison. Our method has applications for basic research in linguistic typology, as well as for NLP tasks like transfer learning for dependency parsing, which has been shown to benefit from word order information.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Miguel Ballesteros</author>
<author>Joakim Nivre</author>
</authors>
<title>MaltOptimizer: An optimization tool for MaltParser.</title>
<date>2012</date>
<booktitle>In Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics, EACL ’12,</booktitle>
<pages>58--62</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4274" citStr="Ballesteros and Nivre, 2012" startWordPosition="653" endWordPosition="656">on for Computational Linguistics 3 Method The first step consists of using supervised systems for annotating the source texts with Universal PoS Tags (Petrov et al., 2012) and dependency structure in the Universal Dependency Treebank format (McDonald et al., 2013). For PoS tagging, we use the Stanford Tagger (Toutanova et al., 2003) followed by a conversion step from the Penn Treebank tagset to the “universal” PoS tags using the tables published by Petrov et al. Next, we use the MaltParser dependency parser (Nivre et al., 2007) trained on the Universal Dependency Treebank using MaltOptimizer (Ballesteros and Nivre, 2012). The corpus is then aligned using the multilingual alignment tool of ¨Ostling (2014). This model learns an “interlingua” representation of the text, in this case the New Testament, to which all translations are then aligned independently. An interlingua sentence e is assumed to generate the corresponding sentences f(l) for each of the L languages through a set of alignment variables a(l) for each language. This can be seen as a multilingual extension of the IBM model 1 (Brown et al., 1993) with Dirichlet priors (Mermer and Sarac¸lar, 2011), where not only the alignment variables are hidden bu</context>
</contexts>
<marker>Ballesteros, Nivre, 2012</marker>
<rawString>Miguel Ballesteros and Joakim Nivre. 2012. MaltOptimizer: An optimization tool for MaltParser. In Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics, EACL ’12, pages 58–62, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Stephen A Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="4769" citStr="Brown et al., 1993" startWordPosition="740" endWordPosition="743">y parser (Nivre et al., 2007) trained on the Universal Dependency Treebank using MaltOptimizer (Ballesteros and Nivre, 2012). The corpus is then aligned using the multilingual alignment tool of ¨Ostling (2014). This model learns an “interlingua” representation of the text, in this case the New Testament, to which all translations are then aligned independently. An interlingua sentence e is assumed to generate the corresponding sentences f(l) for each of the L languages through a set of alignment variables a(l) for each language. This can be seen as a multilingual extension of the IBM model 1 (Brown et al., 1993) with Dirichlet priors (Mermer and Sarac¸lar, 2011), where not only the alignment variables are hidden but also the source e. The probability of a sentence and its alignments (in L languages) under this model is P(a(1...L),f(1...L)|e) = L J pt(f(l) j|ea(l) ) I (1) l=1 H 7 · i=1 pc(ei) j=1 where the translation distributions pt are assumed to have symmetric Dirichlet priors and the source token distribution pc a Chinese Restaurant Process prior. Given the parallel sentences f(1...L), then a(1...L) and e are sampled using Gibbs sampling. The advantage of this method is that the multisource trans</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Cysouw</author>
<author>Bernhard W¨alchli</author>
</authors>
<title>Parallel texts: Using translational equivalents in linguistic typology.</title>
<date>2007</date>
<journal>STUF - Language Typology and Universals,</journal>
<volume>60</volume>
<issue>2</issue>
<marker>Cysouw, W¨alchli, 2007</marker>
<rawString>Michael Cysouw and Bernhard W¨alchli. 2007. Parallel texts: Using translational equivalents in linguistic typology. STUF - Language Typology and Universals, 60(2):95–99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>¨Osten Dahl</author>
</authors>
<title>From questionnaires to parallel corpora in typology.</title>
<date>2007</date>
<journal>STUF - Language Typology and Universals,</journal>
<volume>60</volume>
<issue>2</issue>
<contexts>
<context position="2986" citStr="Dahl, 2007" startWordPosition="468" endWordPosition="469">ncreased accuracy during dependency parsing model transfer (T¨ackstr¨om et al., 2013). These benefits can now be extended to hundreds of more languages. The quantified word order characteristics computed for each of the 986 languages in the New Testament corpus, including about 600 not in the WALS samples for these features, are available for download.1 2 Related work Using parallel texts for linguistic typology has become increasingly popular recently, as massively parallel texts with hundreds or thousands of languages have become easily accessible through the web (Cysouw and W¨alchli, 2007; Dahl, 2007; W¨alchli, 2014). Specific applications include data-driven language classification (Mayer and Cysouw, 2012) and lexical typology (W¨alchli and Cysouw, 2012). However, unlike our work, none of these authors developed automatic methods for studying syntactic properties like word order, nor did they utilize recent advances in the field of word alignment algorithms. 1http://www.ling.su.se/ acl2015-wordorder.zip 205 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages</context>
</contexts>
<marker>Dahl, 2007</marker>
<rawString>¨Osten Dahl. 2007. From questionnaires to parallel corpora in typology. STUF - Language Typology and Universals, 60(2):172–181.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew S Dryer</author>
<author>Martin Haspelmath</author>
</authors>
<title>The World Atlas of Language Structures Online.</title>
<date>2013</date>
<note>http: //wals.info.</note>
<contexts>
<context position="2094" citStr="Dryer and Haspelmath, 2013" startWordPosition="322" endWordPosition="325">g of human language. A full theoretical discussion on word order typology is beyond the scope of this paper, but the interested reader is referred to e.g. Dryer (2007) for an overview of the field. This study uses multilingual word alignment ( ¨Ostling, 2014) and high-precision annotation projection of part-of-speech (PoS) tags and dependency parse trees to investigate five different word order properties in 986 different languages, through a corpus of New Testament translations. The results are validated through comparison to relevant chapters in the World Atlas on Language Structures, WALS (Dryer and Haspelmath, 2013), and we find a very high level of agreement between this database and our method. We identify two primary applications of this method. First, it provides a new tool for basic research in linguistic typology. Second, it has been shown that using these word order features leads to increased accuracy during dependency parsing model transfer (T¨ackstr¨om et al., 2013). These benefits can now be extended to hundreds of more languages. The quantified word order characteristics computed for each of the 986 languages in the New Testament corpus, including about 600 not in the WALS samples for these f</context>
<context position="9346" citStr="Dryer and Haspelmath, 2013" startWordPosition="1489" endWordPosition="1492">only had access to complete annotation pipelines for English and German we only considered these two languages, and preliminary experiments using some German translations in addition to the English ones did not lead to significantly different results. A typologically more diverse set of source languages would help to identify those instances in the text which are most consistently translated across languages, in order to reduce the probability that peculiarities of the source language(s) will bias the results. In order to evaluate our method automatically, we used data from the WALS database (Dryer and Haspelmath, 2013) which classifies languages according to a large number of features. Several features concern word order, and we focused on five of these (listed in Table 2). Only languages which are represented both in the New Testament corpus and the WALS data were used for the evaluation. In addition, we exclude languages for which WALS does not indicate a particular word order. This might be due to e.g. lacking adpositions altogether (which makes the adposition/noun order of that language undefined), or because no specific order is considered dominant. The frequencies of all possible word orders for a fea</context>
</contexts>
<marker>Dryer, Haspelmath, 2013</marker>
<rawString>Matthew S. Dryer and Martin Haspelmath. 2013. The World Atlas of Language Structures Online. http: //wals.info.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew S Dryer</author>
</authors>
<title>Word order.</title>
<date>2007</date>
<booktitle>Language Typology and Syntactic Description, volume I, chapter 2,</booktitle>
<pages>61--131</pages>
<editor>In Timothy Shopen, editor,</editor>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1634" citStr="Dryer (2007)" startWordPosition="256" endWordPosition="257">istic typology, as well as for NLP tasks like transfer learning for dependency parsing, which has been shown to benefit from word order information. 1 Introduction Since the work of Greenberg (1963), word order features have played a central role in linguistic typology research. There is a great deal of variation across languages, and interesting interactions between different features which may hint at cognitive constraints in the processing of human language. A full theoretical discussion on word order typology is beyond the scope of this paper, but the interested reader is referred to e.g. Dryer (2007) for an overview of the field. This study uses multilingual word alignment ( ¨Ostling, 2014) and high-precision annotation projection of part-of-speech (PoS) tags and dependency parse trees to investigate five different word order properties in 986 different languages, through a corpus of New Testament translations. The results are validated through comparison to relevant chapters in the World Atlas on Language Structures, WALS (Dryer and Haspelmath, 2013), and we find a very high level of agreement between this database and our method. We identify two primary applications of this method. Firs</context>
</contexts>
<marker>Dryer, 2007</marker>
<rawString>Matthew S. Dryer. 2007. Word order. In Timothy Shopen, editor, Language Typology and Syntactic Description, volume I, chapter 2, pages 61–131. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew S Dryer</author>
</authors>
<title>Order of adjective and noun.</title>
<date>2013</date>
<booktitle>The World Atlas of Language Structures Online. Max Planck Institute for Evolutionary Anthropology,</booktitle>
<editor>In Matthew S. Dryer and Martin Haspelmath, editors,</editor>
<location>Leipzig.</location>
<contexts>
<context position="15468" citStr="Dryer, 2013" startWordPosition="2488" endWordPosition="2489">quires that two dependency relations (subject-verb and object-verb) have been correctly transferred, which substantially reduces the number of relations available for comparison. The fact that sources sometimes differ as to the basic word order of a given language makes it evident that the disagreement reported in Table 2 is not necessarily due to errors made by our algorithm. Another example of this can be found when looking at the order of adjective and noun in some Romance languages (Spanish, Catalan, Portuguese, French and Italian), which are all classified as having noun-adjective order (Dryer, 2013a). It turns out that adjective-noun order in fact dominates in all of these languages, narrowly when using type counts and by a fairly large margin when using token counts. This result was confirmed by manual inspection, which leads us 208 Table 2: Agreement between WALS and our results, on languages present in both datasets. The relative frequency of the most common ordering is given for comparison. Types is the agreement using typebased counts (see text for details), whereas Tokens uses token-based counts. Feature 81A: Subject, Object, Verb (Dryer, 2013e) 82A: Subject, Verb (Dryer, 2013d) 8</context>
</contexts>
<marker>Dryer, 2013</marker>
<rawString>Matthew S. Dryer. 2013a. Order of adjective and noun. In Matthew S. Dryer and Martin Haspelmath, editors, The World Atlas of Language Structures Online. Max Planck Institute for Evolutionary Anthropology, Leipzig.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew S Dryer</author>
</authors>
<title>Order of adposition and noun phrase.</title>
<date>2013</date>
<booktitle>The World Atlas of Language Structures Online. Max Planck Institute for Evolutionary Anthropology,</booktitle>
<editor>In Matthew S. Dryer and Martin Haspelmath, editors,</editor>
<location>Leipzig.</location>
<contexts>
<context position="15468" citStr="Dryer, 2013" startWordPosition="2488" endWordPosition="2489">quires that two dependency relations (subject-verb and object-verb) have been correctly transferred, which substantially reduces the number of relations available for comparison. The fact that sources sometimes differ as to the basic word order of a given language makes it evident that the disagreement reported in Table 2 is not necessarily due to errors made by our algorithm. Another example of this can be found when looking at the order of adjective and noun in some Romance languages (Spanish, Catalan, Portuguese, French and Italian), which are all classified as having noun-adjective order (Dryer, 2013a). It turns out that adjective-noun order in fact dominates in all of these languages, narrowly when using type counts and by a fairly large margin when using token counts. This result was confirmed by manual inspection, which leads us 208 Table 2: Agreement between WALS and our results, on languages present in both datasets. The relative frequency of the most common ordering is given for comparison. Types is the agreement using typebased counts (see text for details), whereas Tokens uses token-based counts. Feature 81A: Subject, Object, Verb (Dryer, 2013e) 82A: Subject, Verb (Dryer, 2013d) 8</context>
</contexts>
<marker>Dryer, 2013</marker>
<rawString>Matthew S. Dryer. 2013b. Order of adposition and noun phrase. In Matthew S. Dryer and Martin Haspelmath, editors, The World Atlas of Language Structures Online. Max Planck Institute for Evolutionary Anthropology, Leipzig.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew S Dryer</author>
</authors>
<title>Order of object and verb.</title>
<date>2013</date>
<booktitle>The World Atlas of Language Structures Online. Max Planck Institute for Evolutionary Anthropology,</booktitle>
<editor>In Matthew S. Dryer and Martin Haspelmath, editors,</editor>
<location>Leipzig.</location>
<contexts>
<context position="15468" citStr="Dryer, 2013" startWordPosition="2488" endWordPosition="2489">quires that two dependency relations (subject-verb and object-verb) have been correctly transferred, which substantially reduces the number of relations available for comparison. The fact that sources sometimes differ as to the basic word order of a given language makes it evident that the disagreement reported in Table 2 is not necessarily due to errors made by our algorithm. Another example of this can be found when looking at the order of adjective and noun in some Romance languages (Spanish, Catalan, Portuguese, French and Italian), which are all classified as having noun-adjective order (Dryer, 2013a). It turns out that adjective-noun order in fact dominates in all of these languages, narrowly when using type counts and by a fairly large margin when using token counts. This result was confirmed by manual inspection, which leads us 208 Table 2: Agreement between WALS and our results, on languages present in both datasets. The relative frequency of the most common ordering is given for comparison. Types is the agreement using typebased counts (see text for details), whereas Tokens uses token-based counts. Feature 81A: Subject, Object, Verb (Dryer, 2013e) 82A: Subject, Verb (Dryer, 2013d) 8</context>
</contexts>
<marker>Dryer, 2013</marker>
<rawString>Matthew S. Dryer. 2013c. Order of object and verb. In Matthew S. Dryer and Martin Haspelmath, editors, The World Atlas of Language Structures Online. Max Planck Institute for Evolutionary Anthropology, Leipzig.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew S Dryer</author>
</authors>
<title>Order of subject and verb.</title>
<date>2013</date>
<booktitle>The World Atlas of Language Structures Online. Max Planck Institute for Evolutionary Anthropology,</booktitle>
<editor>In Matthew S. Dryer and Martin Haspelmath, editors,</editor>
<location>Leipzig.</location>
<contexts>
<context position="15468" citStr="Dryer, 2013" startWordPosition="2488" endWordPosition="2489">quires that two dependency relations (subject-verb and object-verb) have been correctly transferred, which substantially reduces the number of relations available for comparison. The fact that sources sometimes differ as to the basic word order of a given language makes it evident that the disagreement reported in Table 2 is not necessarily due to errors made by our algorithm. Another example of this can be found when looking at the order of adjective and noun in some Romance languages (Spanish, Catalan, Portuguese, French and Italian), which are all classified as having noun-adjective order (Dryer, 2013a). It turns out that adjective-noun order in fact dominates in all of these languages, narrowly when using type counts and by a fairly large margin when using token counts. This result was confirmed by manual inspection, which leads us 208 Table 2: Agreement between WALS and our results, on languages present in both datasets. The relative frequency of the most common ordering is given for comparison. Types is the agreement using typebased counts (see text for details), whereas Tokens uses token-based counts. Feature 81A: Subject, Object, Verb (Dryer, 2013e) 82A: Subject, Verb (Dryer, 2013d) 8</context>
</contexts>
<marker>Dryer, 2013</marker>
<rawString>Matthew S. Dryer. 2013d. Order of subject and verb. In Matthew S. Dryer and Martin Haspelmath, editors, The World Atlas of Language Structures Online. Max Planck Institute for Evolutionary Anthropology, Leipzig.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew S Dryer</author>
</authors>
<title>Order of subject, object and verb.</title>
<date>2013</date>
<booktitle>The World Atlas of Language Structures Online. Max Planck Institute for Evolutionary Anthropology,</booktitle>
<editor>In Matthew S. Dryer and Martin Haspelmath, editors,</editor>
<location>Leipzig.</location>
<contexts>
<context position="15468" citStr="Dryer, 2013" startWordPosition="2488" endWordPosition="2489">quires that two dependency relations (subject-verb and object-verb) have been correctly transferred, which substantially reduces the number of relations available for comparison. The fact that sources sometimes differ as to the basic word order of a given language makes it evident that the disagreement reported in Table 2 is not necessarily due to errors made by our algorithm. Another example of this can be found when looking at the order of adjective and noun in some Romance languages (Spanish, Catalan, Portuguese, French and Italian), which are all classified as having noun-adjective order (Dryer, 2013a). It turns out that adjective-noun order in fact dominates in all of these languages, narrowly when using type counts and by a fairly large margin when using token counts. This result was confirmed by manual inspection, which leads us 208 Table 2: Agreement between WALS and our results, on languages present in both datasets. The relative frequency of the most common ordering is given for comparison. Types is the agreement using typebased counts (see text for details), whereas Tokens uses token-based counts. Feature 81A: Subject, Object, Verb (Dryer, 2013e) 82A: Subject, Verb (Dryer, 2013d) 8</context>
</contexts>
<marker>Dryer, 2013</marker>
<rawString>Matthew S. Dryer. 2013e. Order of subject, object and verb. In Matthew S. Dryer and Martin Haspelmath, editors, The World Atlas of Language Structures Online. Max Planck Institute for Evolutionary Anthropology, Leipzig.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Emonds</author>
</authors>
<title>English as a North Germanic language: From the Norman conquest to the present.</title>
<date>2011</date>
<contexts>
<context position="14127" citStr="Emonds (2011)" startWordPosition="2269" endWordPosition="2270">case is the wide split between the West Germanic and the North Germanic languages, which in spite of their shared ancestry have widely different word order characteristics. Interestingly, English is not grouped with the West Germanic languages, but rather with the North Germanic languages which it has been in close contact with.2 One can also note that the Sinitic languages, with respect to word order, are quite close to the North Germanic languages. Table 2 shows the agreement between the algorithm’s output and the corresponding WALS chap2One reviewer pointed us to the controversial claim of Emonds (2011), that modern English in fact is a North Germanic language, albeit with strong influence from the extinct West Germanic language of Old English. ter for each feature. The level of agreement is high, even though the sample consists mainly of languages unrelated to English, from which the dependency structure and PoS annotations were transferred. The most common column gives the ratio of the most common ordering for each feature (according to WALS), which can serve as a naive baseline. As expected, the lowest level of agreement is observed for WALS chapter 81A, which has a lower baseline since i</context>
</contexts>
<marker>Emonds, 2011</marker>
<rawString>Joseph Emonds. 2011. English as a North Germanic language: From the Norman conquest to the present.</rawString>
</citation>
<citation valid="true">
<date></date>
<booktitle>Proceedings of the Second International Conference on English and American Studies,</booktitle>
<pages>13--26</pages>
<editor>In Roman Truˇsnfk, Katarfna Nemˇcokov´a, and Gregory Jason Bell, editors,</editor>
<location>Zl´ın, Czech Republic,</location>
<marker></marker>
<rawString>In Roman Truˇsnfk, Katarfna Nemˇcokov´a, and Gregory Jason Bell, editors, Proceedings of the Second International Conference on English and American Studies, pages 13–26, Zl´ın, Czech Republic, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph H Greenberg</author>
</authors>
<title>Some universals of grammar with particular reference to the order of meaningful elements.</title>
<date>1963</date>
<booktitle>Universals of Human Language,</booktitle>
<pages>73--113</pages>
<editor>In Joseph H. Greenberg, editor,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="1220" citStr="Greenberg (1963)" startWordPosition="188" endWordPosition="189">o 96% agreement between our method and the manually created WALS database for a range of different word order features. Beyond reproducing the categorical data in WALS and extending it to hundreds of other languages, we also provide quantitative data for the relative frequencies of different word orders, and show the usefulness of this for language comparison. Our method has applications for basic research in linguistic typology, as well as for NLP tasks like transfer learning for dependency parsing, which has been shown to benefit from word order information. 1 Introduction Since the work of Greenberg (1963), word order features have played a central role in linguistic typology research. There is a great deal of variation across languages, and interesting interactions between different features which may hint at cognitive constraints in the processing of human language. A full theoretical discussion on word order typology is beyond the scope of this paper, but the interested reader is referred to e.g. Dryer (2007) for an overview of the field. This study uses multilingual word alignment ( ¨Ostling, 2014) and high-precision annotation projection of part-of-speech (PoS) tags and dependency parse tr</context>
</contexts>
<marker>Greenberg, 1963</marker>
<rawString>Joseph H. Greenberg. 1963. Some universals of grammar with particular reference to the order of meaningful elements. In Joseph H. Greenberg, editor, Universals of Human Language, pages 73–113. MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Hwa</author>
<author>Philip Resnik</author>
<author>Amy Weinberg</author>
<author>Okan Kolak</author>
</authors>
<title>Evaluating translational correspondence using annotation projection.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02,</booktitle>
<pages>392--399</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6316" citStr="Hwa et al., 2002" startWordPosition="994" endWordPosition="997"> and dependency annotations are transferred to the interlingua representation. Since alignments are noisy and low recall is acceptable in this task, we use an aggressive filtering scheme: dependency links must be transferred from at least 80% of source texts in order to be included. For PoS tags, which are only used to double-check grammatical relations and should not impact precision negatively, the majority tag among aligned words is used. Apart from compensating for noisy alignments and parsing errors, this method also helps to catch violations against the direct correspondence assumption (Hwa et al., 2002) by filtering out instances where different source texts use different constructions, favoring the most prototypical cases. Each word order feature is coded in terms of dependency relations, with additional constraints on the parts of speech that can be involved. For instance, when investigating the order between nouns and their modifying adjectives we look for an AMOD dependency relation between an ADJ-tagged and a NOUN-tagged word, and note the order between the adjective and the noun. This method rests on the assumption that translation equivalents have the same grammatical functions across</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Kolak, 2002</marker>
<rawString>Rebecca Hwa, Philip Resnik, Amy Weinberg, and Okan Kolak. 2002. Evaluating translational correspondence using annotation projection. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02, pages 392– 399, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Mayer</author>
<author>Michael Cysouw</author>
</authors>
<title>Language comparison through sparse multilingual word alignment.</title>
<date>2012</date>
<booktitle>In Proceedings of the EACL 2012 Joint Workshop of LINGVIS &amp; UNCLH, EACL 2012,</booktitle>
<pages>54--62</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="3095" citStr="Mayer and Cysouw, 2012" startWordPosition="478" endWordPosition="481">efits can now be extended to hundreds of more languages. The quantified word order characteristics computed for each of the 986 languages in the New Testament corpus, including about 600 not in the WALS samples for these features, are available for download.1 2 Related work Using parallel texts for linguistic typology has become increasingly popular recently, as massively parallel texts with hundreds or thousands of languages have become easily accessible through the web (Cysouw and W¨alchli, 2007; Dahl, 2007; W¨alchli, 2014). Specific applications include data-driven language classification (Mayer and Cysouw, 2012) and lexical typology (W¨alchli and Cysouw, 2012). However, unlike our work, none of these authors developed automatic methods for studying syntactic properties like word order, nor did they utilize recent advances in the field of word alignment algorithms. 1http://www.ling.su.se/ acl2015-wordorder.zip 205 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 205–211, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics 3 Method The fir</context>
</contexts>
<marker>Mayer, Cysouw, 2012</marker>
<rawString>Thomas Mayer and Michael Cysouw. 2012. Language comparison through sparse multilingual word alignment. In Proceedings of the EACL 2012 Joint Workshop of LINGVIS &amp; UNCLH, EACL 2012, pages 54–62, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
<author>Yvonne QuirmbachBrundage</author>
<author>Yoav Goldberg</author>
<author>Dipanjan Das</author>
<author>Kuzman Ganchev</author>
<author>Keith Hall</author>
<author>Slav Petrov</author>
<author>Hao Zhang</author>
<author>Oscar T¨ackstr¨om</author>
<author>Claudia Bedini</author>
<author>N´uria Bertomeu Castell´o</author>
<author>Jungmee Lee</author>
</authors>
<title>Universal dependency annotation for multilingual parsing.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>92--97</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<marker>McDonald, Nivre, QuirmbachBrundage, Goldberg, Das, Ganchev, Hall, Petrov, Zhang, T¨ackstr¨om, Bedini, Castell´o, Lee, 2013</marker>
<rawString>Ryan McDonald, Joakim Nivre, Yvonne QuirmbachBrundage, Yoav Goldberg, Dipanjan Das, Kuzman Ganchev, Keith Hall, Slav Petrov, Hao Zhang, Oscar T¨ackstr¨om, Claudia Bedini, N´uria Bertomeu Castell´o, and Jungmee Lee. 2013. Universal dependency annotation for multilingual parsing. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 92–97, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cos¸kun Mermer</author>
<author>Murat Sarac¸lar</author>
</authors>
<title>Bayesian word alignment for statistical machine translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11,</booktitle>
<pages>182--187</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Mermer, Sarac¸lar, 2011</marker>
<rawString>Cos¸kun Mermer and Murat Sarac¸lar. 2011. Bayesian word alignment for statistical machine translation. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11, pages 182–187, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
</authors>
<title>Atanas Chanev, G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav Marinov, and Erwin Marsi.</title>
<date>2007</date>
<journal>Natural Language Engineering,</journal>
<volume>13</volume>
<pages>6</pages>
<contexts>
<context position="4179" citStr="Nivre et al., 2007" startWordPosition="640" endWordPosition="643">sing (Short Papers), pages 205–211, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics 3 Method The first step consists of using supervised systems for annotating the source texts with Universal PoS Tags (Petrov et al., 2012) and dependency structure in the Universal Dependency Treebank format (McDonald et al., 2013). For PoS tagging, we use the Stanford Tagger (Toutanova et al., 2003) followed by a conversion step from the Penn Treebank tagset to the “universal” PoS tags using the tables published by Petrov et al. Next, we use the MaltParser dependency parser (Nivre et al., 2007) trained on the Universal Dependency Treebank using MaltOptimizer (Ballesteros and Nivre, 2012). The corpus is then aligned using the multilingual alignment tool of ¨Ostling (2014). This model learns an “interlingua” representation of the text, in this case the New Testament, to which all translations are then aligned independently. An interlingua sentence e is assumed to generate the corresponding sentences f(l) for each of the L languages through a set of alignment variables a(l) for each language. This can be seen as a multilingual extension of the IBM model 1 (Brown et al., 1993) with Diri</context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev, G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav Marinov, and Erwin Marsi. 2007. MaltParser: A language-independent system for data-driven dependency parsing. Natural Language Engineering, 13:95–135, 6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert ¨Ostling</author>
</authors>
<title>Bayesian word alignment for massively parallel texts.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<volume>volume</volume>
<pages>123--127</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Gothenburg, Sweden,</location>
<marker>¨Ostling, 2014</marker>
<rawString>Robert ¨Ostling. 2014. Bayesian word alignment for massively parallel texts. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, volume 2: Short Papers, pages 123–127, Gothenburg, Sweden, April. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dipanjan Das</author>
<author>Ryan McDonald</author>
</authors>
<title>A universal part-of-speech tagset.</title>
<date>2012</date>
<journal>European Language Resources Association (ELRA).</journal>
<booktitle>In Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12),</booktitle>
<location>Istanbul, Turkey,</location>
<contexts>
<context position="3817" citStr="Petrov et al., 2012" startWordPosition="578" endWordPosition="581">eloped automatic methods for studying syntactic properties like word order, nor did they utilize recent advances in the field of word alignment algorithms. 1http://www.ling.su.se/ acl2015-wordorder.zip 205 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 205–211, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics 3 Method The first step consists of using supervised systems for annotating the source texts with Universal PoS Tags (Petrov et al., 2012) and dependency structure in the Universal Dependency Treebank format (McDonald et al., 2013). For PoS tagging, we use the Stanford Tagger (Toutanova et al., 2003) followed by a conversion step from the Penn Treebank tagset to the “universal” PoS tags using the tables published by Petrov et al. Next, we use the MaltParser dependency parser (Nivre et al., 2007) trained on the Universal Dependency Treebank using MaltOptimizer (Ballesteros and Nivre, 2012). The corpus is then aligned using the multilingual alignment tool of ¨Ostling (2014). This model learns an “interlingua” representation of the</context>
</contexts>
<marker>Petrov, Das, McDonald, 2012</marker>
<rawString>Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012. A universal part-of-speech tagset. In Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12), Istanbul, Turkey, may. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Token and type constraints for cross-lingual part-of-speech tagging.</title>
<date>2013</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<pages>1--1</pages>
<marker>T¨ackstr¨om, Das, Petrov, McDonald, Nivre, 2013</marker>
<rawString>Oscar T¨ackstr¨om, Dipanjan Das, Slav Petrov, Ryan McDonald, and Joakim Nivre. 2013. Token and type constraints for cross-lingual part-of-speech tagging. Transactions of the Association for Computational Linguistics, 1:1–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-ofspeech tagging with a cyclic dependency network.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Volume 1, NAACL ’03,</booktitle>
<pages>173--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="3980" citStr="Toutanova et al., 2003" startWordPosition="604" endWordPosition="607">p://www.ling.su.se/ acl2015-wordorder.zip 205 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 205–211, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics 3 Method The first step consists of using supervised systems for annotating the source texts with Universal PoS Tags (Petrov et al., 2012) and dependency structure in the Universal Dependency Treebank format (McDonald et al., 2013). For PoS tagging, we use the Stanford Tagger (Toutanova et al., 2003) followed by a conversion step from the Penn Treebank tagset to the “universal” PoS tags using the tables published by Petrov et al. Next, we use the MaltParser dependency parser (Nivre et al., 2007) trained on the Universal Dependency Treebank using MaltOptimizer (Ballesteros and Nivre, 2012). The corpus is then aligned using the multilingual alignment tool of ¨Ostling (2014). This model learns an “interlingua” representation of the text, in this case the New Testament, to which all translations are then aligned independently. An interlingua sentence e is assumed to generate the corresponding</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher D. Manning, and Yoram Singer. 2003. Feature-rich part-ofspeech tagging with a cyclic dependency network. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Volume 1, NAACL ’03, pages 173–180, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Hermann Ney</author>
<author>Christoph Tillmann</author>
</authors>
<title>HMM-based word alignment in statistical translation.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th Conference on Computational Linguistics - Volume 2, COLING ’96,</booktitle>
<pages>836--841</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>Stephan Vogel, Hermann Ney, and Christoph Tillmann. 1996. HMM-based word alignment in statistical translation. In Proceedings of the 16th Conference on Computational Linguistics - Volume 2, COLING ’96, pages 836–841, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernhard W¨alchli</author>
<author>Michael Cysouw</author>
</authors>
<title>Lexical typology through similarity semantics: Toward a semantic map of motion verbs.</title>
<date>2012</date>
<journal>Linguistics,</journal>
<volume>50</volume>
<issue>3</issue>
<marker>W¨alchli, Cysouw, 2012</marker>
<rawString>Bernhard W¨alchli and Michael Cysouw. 2012. Lexical typology through similarity semantics: Toward a semantic map of motion verbs. Linguistics, 50(3):671–710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernhard W¨alchli</author>
</authors>
<title>Algorithmic typology and going from known to similar unknown categories within and across languages.</title>
<date>2014</date>
<booktitle>Linguistic Variation in Text and Speech, number 28 in Linguae &amp; Litterae,</booktitle>
<pages>355--393</pages>
<editor>In Benedikt Szmrecsanyi and Bernhard W¨alchli, editors,</editor>
<note>De Gruyter.</note>
<marker>W¨alchli, 2014</marker>
<rawString>Bernhard W¨alchli. 2014. Algorithmic typology and going from known to similar unknown categories within and across languages. In Benedikt Szmrecsanyi and Bernhard W¨alchli, editors, Linguistic Variation in Text and Speech, number 28 in Linguae &amp; Litterae, pages 355–393. De Gruyter.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>