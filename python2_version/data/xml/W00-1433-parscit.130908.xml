<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000005">
<title confidence="0.97733">
Rhetorical structure in dialog*
</title>
<author confidence="0.973797">
Amanda Stent
</author>
<affiliation confidence="0.9935205">
Computer Science Department
University of Rochester
</affiliation>
<address confidence="0.918265">
RocheSter,NY 14627
</address>
<email confidence="0.999252">
stent@cs.rochester.edu
</email>
<sectionHeader confidence="0.995667" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998360166666667">
In this paper we report on several issues arising
out of a first attempt to annotate task-oriented spo-
ken dialog for rhetorical structure using Rhetorical
Structure Theory. We discuss an annotation scheme
we are developing to resolve the difficulties we have
encountered.
</bodyText>
<sectionHeader confidence="0.997872" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.861045">
In this paper we report on several issues arising out
of a first attempt to annotate complex task-oriented
spoken dialog for rhetorical structure using Rhetor-
ical Structure Theory (RST):
a Relations needed (section 3.1)
a Identification of minimal units for annotation
(section 3.2.2)
a Dialog coverage (section 3.2.3)
a Overlap due to the subject-matter/presenta-
tional relation distinction (section 3.3)
We discuss how we are dealing with these issues in an
annotation scheme for argumentation acts in dialog
that we are developing.
</bodyText>
<sectionHeader confidence="0.983529" genericHeader="method">
2 Previous work
</sectionHeader>
<bodyText confidence="0.999970888888889">
We are engaged in the construction and implemen-
tation of a theory of content-planning for complex,
mixed-initiative task-oriented dialogs based on cor-
pus analysis, for use in dialog systems such as the
TRIPS system (Allen et al., 2000)1. Our basic
premise is that a conversational agent should be able
to produce whatever a human can produce in simi-
lar discourse situations, and that if we can explain
why a human produced a particular contribution,
</bodyText>
<listItem confidence="0.7753455">
• This work was supported by ONR research grant NO0014-
95-1-1088, U.S. Air Force/Rome Labs research contract no.
</listItem>
<footnote confidence="0.833110125">
F30602-95-1-0025, NSF research grant no. MI-9623565 and
Columbia liniversity/NSF research grant no. OPC: 1307. We
would like to t hank the anonymous reviewers, and Dr. .1a.qon
Eisner For their helpful comments on earlier drans of this
paper.
3 VIC are using the Monroe corpus (Stent, 2000), with ref-
erence to the TRAINS corpus (fleeman and Allen, 1995) and
the FICRC Maptask corpus (Anderson et al., 11101).
</footnote>
<bodyText confidence="0.898835418604651">
we can program a conversational agent to produce
something similar. Therefore, in examining our di-
alogs the question we must answer is &amp;quot;Why did this
speaker produce this?&amp;quot;.
RST is a descriptive theory of hierarchical struc-
ture in discourse that identifies functional relation-
ships between discourse parts based on the inten-
tions behind their production (Mann and Thomp-
son, 1987). It has been used in content plan-
ning systems for text (effectively text monolog) (e.g.
(Cawsey, 1993), (Hovy, 1993), (Moore and Paris,
1993)). It has not yet been used much in content
planning for spoken dialog.
Because the dialogs we are examining are task-
oriented, they are hierarchically structured and so
provide a natural place to use RST. In fact, in or-
der to uncover the full structure behind discourse
contributions, it is necessary for us to use a model
of rhetorical structure. Certain dialog contribu-
tions are explained by the speaker&apos;s rhetorical goals.
rather than by task goals. In example 1, utterance 3
is justification for utterance 1 but does not directly
contribute to completing the task.
Example 1
A 1 They can&apos;t fix that power line at five
ninety and East
B 2 Well it
A 3 Because you got to fix the tree First
The details of how to apply RST to spoken dialog
are unclear. If we mark rhetorical structure only
within individual turns (as has generally been the
case in annotations of text dialog, e.g. (Moser et
1996),(Cawsey, 1993)), we miss the structure in
contributions like example 1 or example 2. There
is also the question of how to handle dialog-specific
behaviors: grounding utterances and back-channels
(utterances that maintain the communication), and
abandoned or interrupted utterances.
Example 2 (simplified)
A 1 Bus C at.lrondequoit broke down.
B 2 Before it even got started?
A 3 Yeah, hut we convinced some people to
loan us some vans.
</bodyText>
<page confidence="0.989286">
247
</page>
<table confidence="0.9457865">
Initial annotation
Dialog-specific Subtypes of Elaboration. Other
Comment Particularize, Generalize Comparison
Correction Instantiate Counter-expectation
Cue Exemplify Agent, Role
ew manual
Argumentation acts Subtypes of Elaboration Schemas
Question-vesponse, -Set-member Joke, List
Proposal-accept Process-step Make-plan
Greeting-ack. Object-attribute Describe-situation
</table>
<figureCaption confidence="0.999368">
Figure 1: Examples of other relations
</figureCaption>
<bodyText confidence="0.9999894">
In our first attempt to annotate, we removed
abandoned utterances, back-channels, and simple
acknowledgments such as &amp;quot;Okay&amp;quot;. We used utter-
ances as minimal units; utterances were segmented
using prosodic and syntactic cues and speaker
changes (see 3.2.2). We did occasionally split an ut-
terance into two units if it consisted of two phrases or
clauses separated by a cue word such as &amp;quot;because&amp;quot;.
Two annotators, working separately, marked one
complete dialog using Michael O&apos;Donnell&apos;s RST an-
notation tool (1997). They used the set of relations
in (Mann and Thompson, 1987), and some addi-
tional relations specific to dialog or to our domain.
Examples of the additional relations are given in fig-
ure 1. When we compared the results, the tree struc-
tures obtained were similar, but the relation labels
were very different, and in neither case was the entire
dialog covered. Also, the annotators found structure
not covered by the relations given. As a result, we
stopped the annotation project and started develop-
ing an annotation scheme that would retain rhetor-
ical relations while dealing with the difficulties we
had encountered. The rest of this paper describes
this new annotation scheme. An example of the type
of analysis we are looking for appears in figure 3.
</bodyText>
<sectionHeader confidence="0.987626" genericHeader="method">
3 Issues and proposals
</sectionHeader>
<bodyText confidence="0.9998464">
The issues we encountered fall into three areas,
which we will examine in turn: issues related to in-
dividual relations, dialog-specific issues, and issues
related to the well-known presentational/subject-
matter distinction in RST.
</bodyText>
<subsectionHeader confidence="0.975619">
3.1 Relations
</subsectionHeader>
<bodyText confidence="0.999845296296296">
The key in any annotation project, is to have a set
of tags that are mutually exclusive, descriptive, and
give a useful distinction between different behaviors.
The set of relations we used failed this test with
respect to our corpus.
As in earlier. work (Moore anti Paris, 1992). our
annotators found some of the relations ambiguous.
In particular, the differences between the motivate
and ju,stify relations and between the elaboration and
motivation relations were unclear (partly because
we did not distinguish between presentational and
subject-matter relations).
Some of the relations we used overlapped. The
elaboration relation is too broad; in some sections
of our dialogs almost every utterance is an elabora-
tion of the first one, but the utterances cover a wide
variety of different types of elaborations. Anticipat-
ing this, we had given the annotators several more
specific relations (see figure 1), but we also allowed
them to use the elaboration tag in case a type of elab-
oration arose for which there was no subtype. As a
result of the overlap, use of the elaboration tag was
inconsistent. The joint relation is also too broad.
Other relations were never used, although one an-
notator went on to look at several more dialogs. In
short, the set of relation-tags we used did not effec-
tively partition the set of relations we saw.
In our annotation scheme, we are taking several
steps to define relations more clearly, reduce over-
lap, and eliminate too-broad relations. Instead of
giving annotators an semi-ordered set of relations
with their definitions, we are giving them decision
trees, with questions they can use to clarify the dis-
tinctions between relations at each point (figure 2).
The annotators did not find the relation definitions
in (Mann and Thompson, 1987) particularly help-
ful, but we are including simplified definitions, arid
annotators are instructed to test against the defini-
tions before labeling any. relation. We are including
several examples with each definition, so that anno-
tators can obtain an intuitive understanding of how
the relations appear. Finally, we are providing arty
useful discourse cues that signal the existence of a
relation.
We are eliminating relations that overlap with
others. Where a relation appears to cover a variety
of different phenomena, as in the case of elaborntion,
we are using more specific relations instead. We are
eliminating the joint relation, as it gives no help-
ful information from a content-planning perspective
and annotators are tempted to over-use it.
One of the criticisms of RST is that there is an
infinite set of relations (Grosz and Sidner, 1986).
The goal is to arrive at a mutually-exclusive, clearly-
</bodyText>
<page confidence="0.868622">
248
</page>
<bodyText confidence="0.84186687755102">
defined set of relations with discriminatory power in 1. In this set of spans, is the speaker attempting to
each domain, so we expect that for each new do- affect the hearer&apos;s:
main, it may be necessary to start with an initial * belief - go to question 2
set of high-level relations selected from different cat- 6 attitude - go to question 3
egories, examine a small set of texts or dialogs in that * ability to perform an action - enablement
domain, and then revise the set of relations by mak- Ls.the-speaker trying.to.increase the hearers belief
ing relevant high-level relations more specific. We- in some fact, or enable the hearer to better under-
used this process to develop our annotation scheme. stand some fact?
In the manual we include instructions for moving to • Belief — evidence
new domains. Our examples come from a variety of ci Understanding — background
domains and types of discourse, to add generality. 3.
3.2 Dialog-specific issues Figure 2: Partial decision tree for presentational re-
3.2.1 Dialog-specific relations, schemas and lations, expressed as a list of questions
conversational games tentatively categorized adjacency pairs with subject-
Task-oriented dialog is a complex behavior, involv- matter relations, although they may eventually be-
ing two participants, each with their own beliefs come a third category of relation.
and intentions, in a collaborative effort to inter- Some of these relations are hi-nuclear. For in-
act to solve some problem. There is a whole set stance, although usually the answer is the only part
of behaviors related to maintaining the collabora- required for discourse coherence, at times both ques-
tion and synchronizing beliefs that does not arise tion and answer may be needed, as in example 4.
in monolog [(Clark, 1996), (Traum and Hinkelman, Example 4
1992)1. These include answering questions, agree- A I And the last one was at the where
ing to proposals, and simply acknowledging that the on the loop?
other participant has spoken. B 2 Four ninety.
In example 3, utterance 3 provides motivation for It would seem that these relations can only apply
utterance 1. However, A would not have produced at the lowest levels of an RST analysis, with a dif-
utterance 3 without B&apos;s question. If we simply mark ferent speaker for each span. However, example 5,
a motivation relation between utterances 1 and 3 we in which turns 2-7 are the answer to the question in
will be losing dialog coverage, the spans involved utterance 1, shows that this is not the case.
in the relation will not be adjacent, and we will be Example 5 (slightly simplified)
ignoring the important relationship between utter- A l What&apos;s &amp;quot;close&amp;quot;?
ances 2 and 3. A better analysis would be to mark B 2 &amp;quot;Close&amp;quot;. Urn I don&apos;t know. I I&apos;m pretty
a question-answer relation between utterances 2 and sure that
3, and a motivation relation between utterance 1 and A 3 So Mount Hope and Highland would be.
the unit consisting of utterances 2 and 3. B 4 Yeah.
Example 3 A 5 Well what about like 252 and 383?
A I Then they&apos;re going to have to B 6 It says &amp;quot;next&amp;quot;.
basically wait A 7 Okay. So I guess it has to be adjacent.
B 2 Why?
A 3 Because the roads have to be fixed before
electrical lines can be fixed
The question-answer relation is not in Mann and It might seem that the simplest approach would
Thompson&apos;s original list of relations. It is an be to annotate adjacency pairs between turns, and
jacency pair&apos;&apos;3, and is a type of conversational game mark other rhetorical relations only within turns.
(Clark, 1996). Adjacency pairs, like other relations, However, we have found many instances of rhetori-
are functional relationships between parts of dis- cal relations, or even units (section 3.2.2), spanning
course, but they are specific to multi-party discourse. turns. The two examples below illustrate a cross-
In our annotation scheme, we include relations for speaker elaboration and a cross-speaker sequence re-
different kinds of adjacency pairs (figure 1). We have lation.
</bodyText>
<figure confidence="0.9013541">
Example 6
A I So that.takes care of the ill guy
and the handicapped guy.
B 2 - Okay
B 3 And that takes two hours.
2They do however. inciude requests for information 1110
solutionhood rotation
3Art adjacency pair is a pair of utterances, the first of which
imposes a cognitive preference for the second, e.g. question.
answer, proposal-accept.
249
(11 (2) 4/ \
(41 (51
A 1 We have to send buses to the Lake.
A 2 There are people there to evacuate.
B 3 How many are we sending?
A 4 Two.
B 5 Okay.
B 6 So 1 ambulance to Pittsford and 2
buses to the Lake.
</figure>
<figureCaption confidence="0.993355666666667">
Figure 3: Sample analysis of part of a constructed
dialog. Nuclei are marked with *; non-RST relations
are in italics.
</figureCaption>
<figure confidence="0.836303333333333">
Example 7
A 1 So they can ta- ta- take out the power.
B 2 And then we have to wait ...
</figure>
<bodyText confidence="0.9833375">
With a model of adjacency pairs, we can.now han-
dle grounding acts such as acknowledgments. If an
utterance is clearly a back-channel or abandoned,
annotators are instructed to so mark it and leave it
out of further annotation.
RST in its original formulation does not cover en-
veloping or parallel structures or conventional forms.
However, even in task-oriented dialogs speakers oc-
casionally tell jokes. Furthermore, there are fixed,
structural patterns in dialog, such as form-filling
behaviors. These are frequently domain-specific,
and resemble schema_s [(McKeown, 1985), (Cawsey,
1993)]. While it. may he possible to give an RST
analysis for some of these, it is more accurate to
identify what is actually going on. Our annotation
scheme includes four of these, make.-plan, describe-
situation, list and joke. It also includes an adjacency
pair for greetings, a conventional form.
An annotated dialog extract illustrating most. of
these issues is shown in figure 3.
</bodyText>
<subsubsectionHeader confidence="0.904811">
3.2.2 Identifying and ordering units
</subsubsectionHeader>
<bodyText confidence="0.999668">
In spoken dialog, both participants often speak at
once, or one speaker may complete what another
speaker says, as in examples 8 and 9.
</bodyText>
<footnote confidence="0.65731575">
Example 8 (+&apos;s mark overlapping speech)
A 1 And + hc&apos;s dour + with that at oar thirty
13 2 + Okay +
Example 9
</footnote>
<bodyText confidence="0.907607923076923">
A 1 So it&apos;ll take then,
13 2 Two more hours
Our original use of utterances as minimal units
splits a cross-turn completion from the utterance it
completes (example 9) , and says nothing about how
to order units when one overlaps with another. We
have altered our segmentation rules to take care of
these difficulties. Our definition is that a minimal
_unit.intist be oneof the folhawing,“with-earlier pos-
sibilities taking precedence over later ones:
I. A syntactic phrase separated from the immedi-
ately prior phrase by a cue word such as &amp;quot;be-
cause&amp;quot; or &amp;quot;since&amp;quot;
</bodyText>
<listItem confidence="0.96698925">
2. A syntactically complete clause
3. A stretch of continuous speech ended by a
pause, a prosodic boundary or a change of
speaker
</listItem>
<bodyText confidence="0.998559555555556">
One unit will be considered to succeed another if
it starts after the other.
This means that the standard segmentation of a
dialog into utterances may have to be modified for
the purposes of an RST analysis, although a segmen-
tation into utterances and one into minimal units
will be very similar. Annotators will start with a
dialog segmented into turns and utterances, and are
encouraged to re-segment as needed.
</bodyText>
<subsectionHeader confidence="0.488732">
3.2.3 Dialog coverage
</subsectionHeader>
<bodyText confidence="0.9996845">
When one gets higher in the tree resulting from an
RST annotation, the spans typically begin to fol-
low the task structure or the experimental structure.
In the Monroe corpus, usually one partner tells the
other about the task, then the two collaborate to
solve it, and finally one partner summarizes the so-
lution (following the experimental structure). In the
TRAINS corpus usually one subtask in the plan is
discussed at a time (following the task structure).
Given the length and complexity of a typical dia-
log, it may not, be possible to achieve complete cov-
erage, even with our expanded relation set and the
use of schemas. If we can identify useful sub-dialogs
or can associate parts of a dialog with parts of the
task, finding annotations for each part may suffice.
For our domain, we have established heuristics about
when an annotator can stop trying to achieve cover-
age. An annotator can stop when:
</bodyText>
<listItem confidence="0.741119">
• The top level of the annotation tree has one
relation label covering the whole dialog.
O The structure between the spans at the top level
is identical to the task structure_
</listItem>
<bodyText confidence="0.9223938">
6, The structure between the spans at the top
level is identical to a domain-dependent or
experiment-dependent schema.
O There is consensus between annotators that. no
more relations can he marked.
</bodyText>
<figure confidence="0.994818">
Summary
/\
Make-plan (6)
* /*I
-- Object-attribute, Enablemem
Solutionhood, Quesrion-ansver (number),
Motivaiion
*/
(3) Assert-ark.
</figure>
<page confidence="0.926223">
250
</page>
<bodyText confidence="0.886219333333333">
3.3 The subject-matter/presentational
relation distinction
The relations in RST fall into two classes. Subject-
matter relations such as summary are intended to
be recognized by the hearer. Presentational rela-
tions such as motivation are supposed to &amp;quot;increase
</bodyText>
<listItem confidence="0.593952">
• some inclination&amp;quot;. in he -hearer; such as. the . inclina- .
</listItem>
<bodyText confidence="0.964624909090909">
tion to act (Mann and Thompson, 1987). As Moore
and associates have explained in (1992) and (1993),
while the intentions of the speaker are adequately
represented in the case of presentational relations
by the relations themselves, in the case of subject-
matter relations the intentions of the speaker may
vary. Furthermore, these two types of relations ac-
tually come from different levels of relationship be-
tween discourse elements: the informational level
(subject-matter relations), and the intentional level
(presentational relations). RST conflates these two
levels.
Mann and Thompson said that, in the case where
a presentational relation and a subject-matter re-
lation were both applicable, the subject-matter re-
lation should take precedence. However, we would
like to have information about both levels when pos-
sible. In our annotation scheme the presentational
relations are split from the subject-matter relations
and annotators are instructed to consider for each
set of spans whether there is a subject-matter rela-
tion, and also whether there is a presentational rela-
tion. If there are two relations, both are marked. If
one covers a slightly different span than the other,
at the next level of annotation the span that seems
more appropriate is used.
In the following example, utterance 3 is justifica-
tion (presentational) for utterance 1, but it is also
in a non-volitional cause sitbject.-matter) relation-
ship with utterance 1. The annotator would be in-
structed to label both relations.
Example 10 (slightly simplified)
A 1 1 can&apos;t find the Rochester airport
</bodyText>
<equation confidence="0.977483">
B &apos;2 + I- it&apos;s +
A 3 + I think I have + adisabihty with maps
</equation>
<bodyText confidence="0.999983285714286">
We would also like more information, at times,
about the subject matter in the spans of a relation.
The relation between a &amp;quot;When&amp;quot; question and an-
swer is question-answer, as is that between a
question and answer; but the first question-answer
forms part of an elaboration arid the second forms
part of a justification or motivation. In our annota-
tion scheme, we supply a list of content types, such
as time, location and number. The annotator adds
the content. type in parentheses after the relation tag
when required. This means that the annotator may
have to mark three items for a given set of spans: the
presentational relation (if any), the subject-matter
relation, and the content type (if required). We find
</bodyText>
<page confidence="0.975387">
2.5
</page>
<bodyText confidence="0.999931">
this approach preferable to expanding the set of re-
lations to include, for instance, temporal-question-
answer and spatial-question-answer. Cawsey used a
similar method in (1993).
</bodyText>
<sectionHeader confidence="0.734033" genericHeader="method">
4 Current and future work
</sectionHeader>
<bodyText confidence="0.994994222222222">
-We-have .an -annotation nranual-that we are refining
using TRAINS-93 dialogs4. Shortly, we will begin
annotating the Monroe corpus with the new manual
and different annotators. We will also annotate a
few dialogs from a different corpus (e.g. Maptask)
to ensure generality. We plan to use the results of
our annotation in the construction (ongoing) of new
generation components for the TRIPS system at the
University of Rochester (Allen et al., 2000).
</bodyText>
<sectionHeader confidence="0.997649" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999277641509434">
In recent years there has been much research on
annotation schemes for dialog. Traum and Hinkel-
man outline four levels of &amp;quot;conversational acts&amp;quot; in
(1992). &amp;quot;Argumentation acts&amp;quot;, including rhetorical
relations, form the top level, but this level is not de-
scribed in detail. DAMSL (Core and Allen, 1997) in-
cludes speech acts and some grounding acts, but not
rhetorical relations. The HCRC Maptask project an-
notation scheme includes adjacency pairs, but not
rhetorical relations (Carletta et al., 1996).
The COCONUT project annotation manual al-
lows the annotator to mark individual utter-
ances as elaboration, and segments as summary,
act:condition, act:consequence or otherinfo
genio et al., 1998). This annotation scheme does
not treat rhetorical structure separately from other
types of dialog behavior. We have observed enough_
structure in the corpora we have looked at to jus-
tify treating rhetorical structure as a separate, im-
portant phenomenon. For instance, in a DANISL-
tagged set of 8 dialogs in our corpus, 40% of the
utterances were statements, and many of these ap-
peared in sequences of statements. The relationships
between many of these statements are unclear with-
out a model of rhetorical structure.
In (1999), Nakatani and Traum describe a hierar-
chical annotation of dialog for I-units, based on the
..damthation and satisfaction-precedence relations of
(Grosz and Sidner, 1986). Other researchers have
shown that Grosz and Sidner&apos;s model of discourse
structure (GST) and RST are similar in many re-
spects [(Moser and Moore, 1996), (Marcu, 1999)].
However, RST provides more specific relations than
GST, and this is useful for content planning. As
well as helping., to specify generation goals, content
arid ordering constraints, the rhetorical information
is needed in case the system has to explain what it
has said.
&amp;quot;IA rough draft is a.vailahte from the author.
RDA is an annotation scheme for identifying
rhetorical structure in explanatory texts in the
SHERLOCK domain (Moser et al., 1996). We follow
RDA in requiring annotators to consider both in-
tentional and informational relations. However, be-
cause of the dialog issues previously described, RDA
is not sufficient for dialog.
Marcu uses discourse ..cues -to-automatically un-
cover rhetorical relations in text (1997). Much of
this work is applicable to the problem of uncovering
rhetorical relations in dialog; however, many cues
in dialog are prosodic and it is not yet possible to
obtain accurate information about prosodic cues au-
tomatically.
</bodyText>
<sectionHeader confidence="0.999486" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999965625">
We have examined several issues arising from a first
attempt to annotate spoken dialog for rhetorical
structure. We have proposed ways of dealing with
each of these issues in an annotation scheme we are
developing. Much future work is certainly needed
in this area; we hope that the results of our annota-
tion may form a quantitative baseline for comparison
with future work.
</bodyText>
<sectionHeader confidence="0.996395" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998630058823529">
J. Allen, D. Byron, M. Dzikovska, G. Ferguson,
L. GaIescu, and A. Stent. 2000. An architecture
for a generic dialogue shell. upcoming in the Nat-
ural Language Engineering Journal special issue
on Best Practices in Spoken Language Dialogue
Systems Engineering.
A. Anderson, M. Bader, E. Bard, E. Boyle, G. Do-
herty, S. Garrod, S. hard, J. Kowtko, J. McAl-
lister, J. Miller, C. Sotillo, H. Thompson, and
R. Weinert. 1991. The [&apos;CRC 11/Iaptask corpus.
Language and Speech. 34:351-366_
J. Carletta, A. Isard, S. Isard, J. Kowtko,
and G. Doherty-Sneddon. 1996. HCRC dia-
log structure coding manual. Technical Report
HCRC/TR-82, HCRC, Edinburgh University.
A. Cai.vsey. 1993. Planning interactive explanations.
International Journal of Man-Machine Studies,
38:169-199.
H. Clark. 1996. Using Language.. Cambridge Uni-
versity Press.
M. Core and J. Allen. 1997. Coding dialogs with the
DAMSI, annotation scheme. In AAAI Fall Sym-
posium on Communicative Action in Humans and
Machines, pages 28-35. November.
ft DiEugertio. P. ,Jordan. and L. Pylkkiinen. 1998.
The COCONUT project: Dialogue annotation
manual. Technical Report 98-1, ISE), University
of Pittsburgh.
ft Gros. and C. Sidner. 1986. Attention, inten-
tions, and the structure of discourse. Coniputa-
tzonal Linguistics, 12(3).
P. Heeman and J. Allen. 1995. The TRAINS-93
dialogs. Technical Report Trains TN 94-2, Com-
puter Science Dept., U. Rochester, March.
E. Hovy. 1993. Automated discourse generation us-
ing discourse structure relations. Artificial Intel-
ligence, 63(1-2):341-385.
W. Mann and S. Thompson. 1987. Rhetorical.struc-
ture theory: a theory of text organisation. In
L. Polanyi, editor, The Structure of Discourse.
Ablex, Norwood, NJ.
D. Marcu. 1997. The rhetorical parsing, sum-
marization, and generation of natural language
texts. Technical Report CSRG-371, Department
of Computer Science, University of Toronto.
D. Marcu. 1999. A formal and computational
synthesis of Grosz and Sidner&apos;s and Mann and
Thompson&apos;s theories. In The Workshop on Levels
of Representation in Discourse, Edinburgh, Scot-
land.
K. McKeown. 1985. Text Generation: Using Dis-
course Strategies and Focus Constraints to Gener-
ate Natural Language Text. Cambridge University
Press, Cambridge.
J. Moore and C. Paris. 1992. Exploiting user feed-
back to compensate for the unreliability of user
models. UMUAI, 2(4):331-365.
J. D. Moore and C. L. Paris. 1993. Planning text
for advisory dialogues: Capturing intentional and
rhetorical information. Computational Linguis-
tics, 19(4):651-695.
J. Moore and M. Pollack. 1992. A problem for RST:
The need for multi-level discourse analysis. Com-
putational Linguistics, 18(4):537-544.
M. G. Moser and J. D. Moore. 1996. Toward a
synthesis of two accounts of discourse structure.
Computational Linguistics, 22(3):409-420.
M. Moser, J. Moore, and E. Glendening,. 19913
Instructions for coding explanations: Identifying
segments. relations and minimal units. Technical
Report 96-17. University of Pittsburgh. Depart-
ment of Computer Science.
C. Nakatani and D. Traum. 1999. Coding discourse
structure in dialogue (version 1.0). Technical Re-
port UMIACS-TR-99-03, University of Maryland.
Michael O&apos;Donnell. 1997_ RST -Tool: An RST
analysis tool. In Proceedings of the 6th Eu-
ropean Workshop on Natural Language Gene.r-
ation, Gerhard-Mercator University, Duisburg,
Germany.
A. Stent. 2000. The Monroe corpus. Technical Re-
port TR728/TN99-2, University of Rochester.
D. Traurn and E. Hinkelman. 1992. Coriversatirm
acts in task-oriented spoken dialogue. Computa-
tional Intelligence, 8(3):575-599.
</reference>
<page confidence="0.997436">
252
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.586528">
<title confidence="0.9865">Rhetorical structure in dialog*</title>
<author confidence="0.97899">Amanda</author>
<affiliation confidence="0.896604666666667">Computer Science University of RocheSter,NY</affiliation>
<email confidence="0.999224">stent@cs.rochester.edu</email>
<abstract confidence="0.982113571428571">In this paper we report on several issues arising out of a first attempt to annotate task-oriented spoken dialog for rhetorical structure using Rhetorical Structure Theory. We discuss an annotation scheme we are developing to resolve the difficulties we have encountered.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Allen</author>
<author>D Byron</author>
<author>M Dzikovska</author>
<author>G Ferguson</author>
<author>L GaIescu</author>
<author>A Stent</author>
</authors>
<title>An architecture for a generic dialogue shell. upcoming in the Natural Language Engineering Journal special issue on Best Practices in Spoken Language Dialogue Systems Engineering.</title>
<date>2000</date>
<contexts>
<context position="1220" citStr="Allen et al., 2000" startWordPosition="178" endWordPosition="181">ucture Theory (RST): a Relations needed (section 3.1) a Identification of minimal units for annotation (section 3.2.2) a Dialog coverage (section 3.2.3) a Overlap due to the subject-matter/presentational relation distinction (section 3.3) We discuss how we are dealing with these issues in an annotation scheme for argumentation acts in dialog that we are developing. 2 Previous work We are engaged in the construction and implementation of a theory of content-planning for complex, mixed-initiative task-oriented dialogs based on corpus analysis, for use in dialog systems such as the TRIPS system (Allen et al., 2000)1. Our basic premise is that a conversational agent should be able to produce whatever a human can produce in similar discourse situations, and that if we can explain why a human produced a particular contribution, • This work was supported by ONR research grant NO0014- 95-1-1088, U.S. Air Force/Rome Labs research contract no. F30602-95-1-0025, NSF research grant no. MI-9623565 and Columbia liniversity/NSF research grant no. OPC: 1307. We would like to t hank the anonymous reviewers, and Dr. .1a.qon Eisner For their helpful comments on earlier drans of this paper. 3 VIC are using the Monroe co</context>
<context position="20322" citStr="Allen et al., 2000" startWordPosition="3331" endWordPosition="3334">g the set of relations to include, for instance, temporal-questionanswer and spatial-question-answer. Cawsey used a similar method in (1993). 4 Current and future work -We-have .an -annotation nranual-that we are refining using TRAINS-93 dialogs4. Shortly, we will begin annotating the Monroe corpus with the new manual and different annotators. We will also annotate a few dialogs from a different corpus (e.g. Maptask) to ensure generality. We plan to use the results of our annotation in the construction (ongoing) of new generation components for the TRIPS system at the University of Rochester (Allen et al., 2000). 5 Related Work In recent years there has been much research on annotation schemes for dialog. Traum and Hinkelman outline four levels of &amp;quot;conversational acts&amp;quot; in (1992). &amp;quot;Argumentation acts&amp;quot;, including rhetorical relations, form the top level, but this level is not described in detail. DAMSL (Core and Allen, 1997) includes speech acts and some grounding acts, but not rhetorical relations. The HCRC Maptask project annotation scheme includes adjacency pairs, but not rhetorical relations (Carletta et al., 1996). The COCONUT project annotation manual allows the annotator to mark individual utter</context>
</contexts>
<marker>Allen, Byron, Dzikovska, Ferguson, GaIescu, Stent, 2000</marker>
<rawString>J. Allen, D. Byron, M. Dzikovska, G. Ferguson, L. GaIescu, and A. Stent. 2000. An architecture for a generic dialogue shell. upcoming in the Natural Language Engineering Journal special issue on Best Practices in Spoken Language Dialogue Systems Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Anderson</author>
<author>M Bader</author>
<author>E Bard</author>
<author>E Boyle</author>
<author>G Doherty</author>
<author>S Garrod</author>
<author>S hard</author>
<author>J Kowtko</author>
<author>J McAllister</author>
<author>J Miller</author>
<author>C Sotillo</author>
<author>H Thompson</author>
<author>R Weinert</author>
</authors>
<title>The [&apos;CRC 11/Iaptask corpus. Language and Speech.</title>
<date>1991</date>
<pages>34--351</pages>
<marker>Anderson, Bader, Bard, Boyle, Doherty, Garrod, hard, Kowtko, McAllister, Miller, Sotillo, Thompson, Weinert, 1991</marker>
<rawString>A. Anderson, M. Bader, E. Bard, E. Boyle, G. Doherty, S. Garrod, S. hard, J. Kowtko, J. McAllister, J. Miller, C. Sotillo, H. Thompson, and R. Weinert. 1991. The [&apos;CRC 11/Iaptask corpus. Language and Speech. 34:351-366_</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carletta</author>
<author>A Isard</author>
<author>S Isard</author>
<author>J Kowtko</author>
<author>G Doherty-Sneddon</author>
</authors>
<title>HCRC dialog structure coding manual.</title>
<date>1996</date>
<tech>Technical Report HCRC/TR-82,</tech>
<institution>HCRC, Edinburgh University.</institution>
<contexts>
<context position="20837" citStr="Carletta et al., 1996" startWordPosition="3412" endWordPosition="3415">oing) of new generation components for the TRIPS system at the University of Rochester (Allen et al., 2000). 5 Related Work In recent years there has been much research on annotation schemes for dialog. Traum and Hinkelman outline four levels of &amp;quot;conversational acts&amp;quot; in (1992). &amp;quot;Argumentation acts&amp;quot;, including rhetorical relations, form the top level, but this level is not described in detail. DAMSL (Core and Allen, 1997) includes speech acts and some grounding acts, but not rhetorical relations. The HCRC Maptask project annotation scheme includes adjacency pairs, but not rhetorical relations (Carletta et al., 1996). The COCONUT project annotation manual allows the annotator to mark individual utterances as elaboration, and segments as summary, act:condition, act:consequence or otherinfo genio et al., 1998). This annotation scheme does not treat rhetorical structure separately from other types of dialog behavior. We have observed enough_ structure in the corpora we have looked at to justify treating rhetorical structure as a separate, important phenomenon. For instance, in a DANISLtagged set of 8 dialogs in our corpus, 40% of the utterances were statements, and many of these appeared in sequences of stat</context>
</contexts>
<marker>Carletta, Isard, Isard, Kowtko, Doherty-Sneddon, 1996</marker>
<rawString>J. Carletta, A. Isard, S. Isard, J. Kowtko, and G. Doherty-Sneddon. 1996. HCRC dialog structure coding manual. Technical Report HCRC/TR-82, HCRC, Edinburgh University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Cai vsey</author>
</authors>
<title>Planning interactive explanations.</title>
<date>1993</date>
<journal>International Journal of Man-Machine Studies,</journal>
<pages>38--169</pages>
<marker>vsey, 1993</marker>
<rawString>A. Cai.vsey. 1993. Planning interactive explanations. International Journal of Man-Machine Studies, 38:169-199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Clark</author>
</authors>
<title>Using Language..</title>
<date>1996</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="10227" citStr="Clark, 1996" startWordPosition="1628" endWordPosition="1629">Task-oriented dialog is a complex behavior, involv- matter relations, although they may eventually being two participants, each with their own beliefs come a third category of relation. and intentions, in a collaborative effort to inter- Some of these relations are hi-nuclear. For inact to solve some problem. There is a whole set stance, although usually the answer is the only part of behaviors related to maintaining the collabora- required for discourse coherence, at times both question and synchronizing beliefs that does not arise tion and answer may be needed, as in example 4. in monolog [(Clark, 1996), (Traum and Hinkelman, Example 4 1992)1. These include answering questions, agree- A I And the last one was at the where ing to proposals, and simply acknowledging that the on the loop? other participant has spoken. B 2 Four ninety. In example 3, utterance 3 provides motivation for It would seem that these relations can only apply utterance 1. However, A would not have produced at the lowest levels of an RST analysis, with a difutterance 3 without B&apos;s question. If we simply mark ferent speaker for each span. However, example 5, a motivation relation between utterances 1 and 3 we in which turn</context>
<context position="11980" citStr="Clark, 1996" startWordPosition="1947" endWordPosition="1948">. the unit consisting of utterances 2 and 3. B 4 Yeah. Example 3 A 5 Well what about like 252 and 383? A I Then they&apos;re going to have to B 6 It says &amp;quot;next&amp;quot;. basically wait A 7 Okay. So I guess it has to be adjacent. B 2 Why? A 3 Because the roads have to be fixed before electrical lines can be fixed The question-answer relation is not in Mann and It might seem that the simplest approach would Thompson&apos;s original list of relations. It is an be to annotate adjacency pairs between turns, and jacency pair&apos;&apos;3, and is a type of conversational game mark other rhetorical relations only within turns. (Clark, 1996). Adjacency pairs, like other relations, However, we have found many instances of rhetoriare functional relationships between parts of dis- cal relations, or even units (section 3.2.2), spanning course, but they are specific to multi-party discourse. turns. The two examples below illustrate a crossIn our annotation scheme, we include relations for speaker elaboration and a cross-speaker sequence redifferent kinds of adjacency pairs (figure 1). We have lation. Example 6 A I So that.takes care of the ill guy and the handicapped guy. B 2 - Okay B 3 And that takes two hours. 2They do however. inci</context>
</contexts>
<marker>Clark, 1996</marker>
<rawString>H. Clark. 1996. Using Language.. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Core</author>
<author>J Allen</author>
</authors>
<title>Coding dialogs with the DAMSI, annotation scheme.</title>
<date>1997</date>
<booktitle>In AAAI Fall Symposium on Communicative Action in Humans and Machines,</booktitle>
<pages>28--35</pages>
<contexts>
<context position="20639" citStr="Core and Allen, 1997" startWordPosition="3382" endWordPosition="3385">nual and different annotators. We will also annotate a few dialogs from a different corpus (e.g. Maptask) to ensure generality. We plan to use the results of our annotation in the construction (ongoing) of new generation components for the TRIPS system at the University of Rochester (Allen et al., 2000). 5 Related Work In recent years there has been much research on annotation schemes for dialog. Traum and Hinkelman outline four levels of &amp;quot;conversational acts&amp;quot; in (1992). &amp;quot;Argumentation acts&amp;quot;, including rhetorical relations, form the top level, but this level is not described in detail. DAMSL (Core and Allen, 1997) includes speech acts and some grounding acts, but not rhetorical relations. The HCRC Maptask project annotation scheme includes adjacency pairs, but not rhetorical relations (Carletta et al., 1996). The COCONUT project annotation manual allows the annotator to mark individual utterances as elaboration, and segments as summary, act:condition, act:consequence or otherinfo genio et al., 1998). This annotation scheme does not treat rhetorical structure separately from other types of dialog behavior. We have observed enough_ structure in the corpora we have looked at to justify treating rhetorical</context>
</contexts>
<marker>Core, Allen, 1997</marker>
<rawString>M. Core and J. Allen. 1997. Coding dialogs with the DAMSI, annotation scheme. In AAAI Fall Symposium on Communicative Action in Humans and Machines, pages 28-35. November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jordan</author>
<author>L Pylkkiinen</author>
</authors>
<title>The COCONUT project: Dialogue annotation manual.</title>
<date>1998</date>
<tech>Technical Report 98-1,</tech>
<institution>ISE), University of Pittsburgh.</institution>
<marker>Jordan, Pylkkiinen, 1998</marker>
<rawString>ft DiEugertio. P. ,Jordan. and L. Pylkkiinen. 1998. The COCONUT project: Dialogue annotation manual. Technical Report 98-1, ISE), University of Pittsburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Sidner</author>
</authors>
<title>Attention, intentions, and the structure of discourse.</title>
<date>1986</date>
<journal>Coniputatzonal Linguistics,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="8388" citStr="Sidner, 1986" startWordPosition="1326" endWordPosition="1327">can obtain an intuitive understanding of how the relations appear. Finally, we are providing arty useful discourse cues that signal the existence of a relation. We are eliminating relations that overlap with others. Where a relation appears to cover a variety of different phenomena, as in the case of elaborntion, we are using more specific relations instead. We are eliminating the joint relation, as it gives no helpful information from a content-planning perspective and annotators are tempted to over-use it. One of the criticisms of RST is that there is an infinite set of relations (Grosz and Sidner, 1986). The goal is to arrive at a mutually-exclusive, clearly248 defined set of relations with discriminatory power in 1. In this set of spans, is the speaker attempting to each domain, so we expect that for each new do- affect the hearer&apos;s: main, it may be necessary to start with an initial * belief - go to question 2 set of high-level relations selected from different cat- 6 attitude - go to question 3 egories, examine a small set of texts or dialogs in that * ability to perform an action - enablement domain, and then revise the set of relations by mak- Ls.the-speaker trying.to.increase the heare</context>
<context position="21728" citStr="Sidner, 1986" startWordPosition="3552" endWordPosition="3553">types of dialog behavior. We have observed enough_ structure in the corpora we have looked at to justify treating rhetorical structure as a separate, important phenomenon. For instance, in a DANISLtagged set of 8 dialogs in our corpus, 40% of the utterances were statements, and many of these appeared in sequences of statements. The relationships between many of these statements are unclear without a model of rhetorical structure. In (1999), Nakatani and Traum describe a hierarchical annotation of dialog for I-units, based on the ..damthation and satisfaction-precedence relations of (Grosz and Sidner, 1986). Other researchers have shown that Grosz and Sidner&apos;s model of discourse structure (GST) and RST are similar in many respects [(Moser and Moore, 1996), (Marcu, 1999)]. However, RST provides more specific relations than GST, and this is useful for content planning. As well as helping., to specify generation goals, content arid ordering constraints, the rhetorical information is needed in case the system has to explain what it has said. &amp;quot;IA rough draft is a.vailahte from the author. RDA is an annotation scheme for identifying rhetorical structure in explanatory texts in the SHERLOCK domain (Mos</context>
</contexts>
<marker>Sidner, 1986</marker>
<rawString>ft Gros. and C. Sidner. 1986. Attention, intentions, and the structure of discourse. Coniputatzonal Linguistics, 12(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Heeman</author>
<author>J Allen</author>
</authors>
<title>The TRAINS-93 dialogs.</title>
<date>1995</date>
<tech>Technical Report Trains TN 94-2,</tech>
<institution>Computer Science</institution>
<marker>Heeman, Allen, 1995</marker>
<rawString>P. Heeman and J. Allen. 1995. The TRAINS-93 dialogs. Technical Report Trains TN 94-2, Computer Science Dept., U. Rochester, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hovy</author>
</authors>
<title>Automated discourse generation using discourse structure relations.</title>
<date>1993</date>
<journal>Artificial Intelligence,</journal>
<pages>63--1</pages>
<contexts>
<context position="2452" citStr="Hovy, 1993" startWordPosition="379" endWordPosition="380">ith reference to the TRAINS corpus (fleeman and Allen, 1995) and the FICRC Maptask corpus (Anderson et al., 11101). we can program a conversational agent to produce something similar. Therefore, in examining our dialogs the question we must answer is &amp;quot;Why did this speaker produce this?&amp;quot;. RST is a descriptive theory of hierarchical structure in discourse that identifies functional relationships between discourse parts based on the intentions behind their production (Mann and Thompson, 1987). It has been used in content planning systems for text (effectively text monolog) (e.g. (Cawsey, 1993), (Hovy, 1993), (Moore and Paris, 1993)). It has not yet been used much in content planning for spoken dialog. Because the dialogs we are examining are taskoriented, they are hierarchically structured and so provide a natural place to use RST. In fact, in order to uncover the full structure behind discourse contributions, it is necessary for us to use a model of rhetorical structure. Certain dialog contributions are explained by the speaker&apos;s rhetorical goals. rather than by task goals. In example 1, utterance 3 is justification for utterance 1 but does not directly contribute to completing the task. Exampl</context>
</contexts>
<marker>Hovy, 1993</marker>
<rawString>E. Hovy. 1993. Automated discourse generation using discourse structure relations. Artificial Intelligence, 63(1-2):341-385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Mann</author>
<author>S Thompson</author>
</authors>
<title>Rhetorical.structure theory: a theory of text organisation.</title>
<date>1987</date>
<booktitle>The Structure of Discourse. Ablex,</booktitle>
<editor>In L. Polanyi, editor,</editor>
<location>Norwood, NJ.</location>
<contexts>
<context position="2335" citStr="Mann and Thompson, 1987" startWordPosition="357" endWordPosition="361">d Dr. .1a.qon Eisner For their helpful comments on earlier drans of this paper. 3 VIC are using the Monroe corpus (Stent, 2000), with reference to the TRAINS corpus (fleeman and Allen, 1995) and the FICRC Maptask corpus (Anderson et al., 11101). we can program a conversational agent to produce something similar. Therefore, in examining our dialogs the question we must answer is &amp;quot;Why did this speaker produce this?&amp;quot;. RST is a descriptive theory of hierarchical structure in discourse that identifies functional relationships between discourse parts based on the intentions behind their production (Mann and Thompson, 1987). It has been used in content planning systems for text (effectively text monolog) (e.g. (Cawsey, 1993), (Hovy, 1993), (Moore and Paris, 1993)). It has not yet been used much in content planning for spoken dialog. Because the dialogs we are examining are taskoriented, they are hierarchically structured and so provide a natural place to use RST. In fact, in order to uncover the full structure behind discourse contributions, it is necessary for us to use a model of rhetorical structure. Certain dialog contributions are explained by the speaker&apos;s rhetorical goals. rather than by task goals. In ex</context>
<context position="4795" citStr="Mann and Thompson, 1987" startWordPosition="742" endWordPosition="745">cribe-situation Figure 1: Examples of other relations In our first attempt to annotate, we removed abandoned utterances, back-channels, and simple acknowledgments such as &amp;quot;Okay&amp;quot;. We used utterances as minimal units; utterances were segmented using prosodic and syntactic cues and speaker changes (see 3.2.2). We did occasionally split an utterance into two units if it consisted of two phrases or clauses separated by a cue word such as &amp;quot;because&amp;quot;. Two annotators, working separately, marked one complete dialog using Michael O&apos;Donnell&apos;s RST annotation tool (1997). They used the set of relations in (Mann and Thompson, 1987), and some additional relations specific to dialog or to our domain. Examples of the additional relations are given in figure 1. When we compared the results, the tree structures obtained were similar, but the relation labels were very different, and in neither case was the entire dialog covered. Also, the annotators found structure not covered by the relations given. As a result, we stopped the annotation project and started developing an annotation scheme that would retain rhetorical relations while dealing with the difficulties we had encountered. The rest of this paper describes this new a</context>
<context position="7538" citStr="Mann and Thompson, 1987" startWordPosition="1189" endWordPosition="1192">were never used, although one annotator went on to look at several more dialogs. In short, the set of relation-tags we used did not effectively partition the set of relations we saw. In our annotation scheme, we are taking several steps to define relations more clearly, reduce overlap, and eliminate too-broad relations. Instead of giving annotators an semi-ordered set of relations with their definitions, we are giving them decision trees, with questions they can use to clarify the distinctions between relations at each point (figure 2). The annotators did not find the relation definitions in (Mann and Thompson, 1987) particularly helpful, but we are including simplified definitions, arid annotators are instructed to test against the definitions before labeling any. relation. We are including several examples with each definition, so that annotators can obtain an intuitive understanding of how the relations appear. Finally, we are providing arty useful discourse cues that signal the existence of a relation. We are eliminating relations that overlap with others. Where a relation appears to cover a variety of different phenomena, as in the case of elaborntion, we are using more specific relations instead. We</context>
<context position="17353" citStr="Mann and Thompson, 1987" startWordPosition="2853" endWordPosition="2856"> a domain-dependent or experiment-dependent schema. O There is consensus between annotators that. no more relations can he marked. Summary /\ Make-plan (6) * /*I -- Object-attribute, Enablemem Solutionhood, Quesrion-ansver (number), Motivaiion */ (3) Assert-ark. 250 3.3 The subject-matter/presentational relation distinction The relations in RST fall into two classes. Subjectmatter relations such as summary are intended to be recognized by the hearer. Presentational relations such as motivation are supposed to &amp;quot;increase • some inclination&amp;quot;. in he -hearer; such as. the . inclina- . tion to act (Mann and Thompson, 1987). As Moore and associates have explained in (1992) and (1993), while the intentions of the speaker are adequately represented in the case of presentational relations by the relations themselves, in the case of subjectmatter relations the intentions of the speaker may vary. Furthermore, these two types of relations actually come from different levels of relationship between discourse elements: the informational level (subject-matter relations), and the intentional level (presentational relations). RST conflates these two levels. Mann and Thompson said that, in the case where a presentational re</context>
</contexts>
<marker>Mann, Thompson, 1987</marker>
<rawString>W. Mann and S. Thompson. 1987. Rhetorical.structure theory: a theory of text organisation. In L. Polanyi, editor, The Structure of Discourse. Ablex, Norwood, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Marcu</author>
</authors>
<title>The rhetorical parsing, summarization, and generation of natural language texts.</title>
<date>1997</date>
<tech>Technical Report CSRG-371,</tech>
<institution>Department of Computer Science, University of Toronto.</institution>
<marker>Marcu, 1997</marker>
<rawString>D. Marcu. 1997. The rhetorical parsing, summarization, and generation of natural language texts. Technical Report CSRG-371, Department of Computer Science, University of Toronto.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Marcu</author>
</authors>
<title>A formal and computational synthesis of Grosz and Sidner&apos;s and Mann and Thompson&apos;s theories.</title>
<date>1999</date>
<booktitle>In The Workshop on Levels of Representation in Discourse,</booktitle>
<location>Edinburgh, Scotland.</location>
<contexts>
<context position="21894" citStr="Marcu, 1999" startWordPosition="3579" endWordPosition="3580">non. For instance, in a DANISLtagged set of 8 dialogs in our corpus, 40% of the utterances were statements, and many of these appeared in sequences of statements. The relationships between many of these statements are unclear without a model of rhetorical structure. In (1999), Nakatani and Traum describe a hierarchical annotation of dialog for I-units, based on the ..damthation and satisfaction-precedence relations of (Grosz and Sidner, 1986). Other researchers have shown that Grosz and Sidner&apos;s model of discourse structure (GST) and RST are similar in many respects [(Moser and Moore, 1996), (Marcu, 1999)]. However, RST provides more specific relations than GST, and this is useful for content planning. As well as helping., to specify generation goals, content arid ordering constraints, the rhetorical information is needed in case the system has to explain what it has said. &amp;quot;IA rough draft is a.vailahte from the author. RDA is an annotation scheme for identifying rhetorical structure in explanatory texts in the SHERLOCK domain (Moser et al., 1996). We follow RDA in requiring annotators to consider both intentional and informational relations. However, because of the dialog issues previously des</context>
</contexts>
<marker>Marcu, 1999</marker>
<rawString>D. Marcu. 1999. A formal and computational synthesis of Grosz and Sidner&apos;s and Mann and Thompson&apos;s theories. In The Workshop on Levels of Representation in Discourse, Edinburgh, Scotland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K McKeown</author>
</authors>
<title>Text Generation: Using Discourse Strategies and Focus Constraints to Generate Natural Language Text.</title>
<date>1985</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="13775" citStr="McKeown, 1985" startWordPosition="2253" endWordPosition="2254"> power. B 2 And then we have to wait ... With a model of adjacency pairs, we can.now handle grounding acts such as acknowledgments. If an utterance is clearly a back-channel or abandoned, annotators are instructed to so mark it and leave it out of further annotation. RST in its original formulation does not cover enveloping or parallel structures or conventional forms. However, even in task-oriented dialogs speakers occasionally tell jokes. Furthermore, there are fixed, structural patterns in dialog, such as form-filling behaviors. These are frequently domain-specific, and resemble schema_s [(McKeown, 1985), (Cawsey, 1993)]. While it. may he possible to give an RST analysis for some of these, it is more accurate to identify what is actually going on. Our annotation scheme includes four of these, make.-plan, describesituation, list and joke. It also includes an adjacency pair for greetings, a conventional form. An annotated dialog extract illustrating most. of these issues is shown in figure 3. 3.2.2 Identifying and ordering units In spoken dialog, both participants often speak at once, or one speaker may complete what another speaker says, as in examples 8 and 9. Example 8 (+&apos;s mark overlapping </context>
</contexts>
<marker>McKeown, 1985</marker>
<rawString>K. McKeown. 1985. Text Generation: Using Discourse Strategies and Focus Constraints to Generate Natural Language Text. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Moore</author>
<author>C Paris</author>
</authors>
<title>Exploiting user feedback to compensate for the unreliability of user models.</title>
<date>1992</date>
<pages>2--4</pages>
<publisher>UMUAI,</publisher>
<marker>Moore, Paris, 1992</marker>
<rawString>J. Moore and C. Paris. 1992. Exploiting user feedback to compensate for the unreliability of user models. UMUAI, 2(4):331-365.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Moore</author>
<author>C L Paris</author>
</authors>
<title>Planning text for advisory dialogues: Capturing intentional and rhetorical information.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--4</pages>
<contexts>
<context position="2477" citStr="Moore and Paris, 1993" startWordPosition="381" endWordPosition="384">to the TRAINS corpus (fleeman and Allen, 1995) and the FICRC Maptask corpus (Anderson et al., 11101). we can program a conversational agent to produce something similar. Therefore, in examining our dialogs the question we must answer is &amp;quot;Why did this speaker produce this?&amp;quot;. RST is a descriptive theory of hierarchical structure in discourse that identifies functional relationships between discourse parts based on the intentions behind their production (Mann and Thompson, 1987). It has been used in content planning systems for text (effectively text monolog) (e.g. (Cawsey, 1993), (Hovy, 1993), (Moore and Paris, 1993)). It has not yet been used much in content planning for spoken dialog. Because the dialogs we are examining are taskoriented, they are hierarchically structured and so provide a natural place to use RST. In fact, in order to uncover the full structure behind discourse contributions, it is necessary for us to use a model of rhetorical structure. Certain dialog contributions are explained by the speaker&apos;s rhetorical goals. rather than by task goals. In example 1, utterance 3 is justification for utterance 1 but does not directly contribute to completing the task. Example 1 A 1 They can&apos;t fix th</context>
</contexts>
<marker>Moore, Paris, 1993</marker>
<rawString>J. D. Moore and C. L. Paris. 1993. Planning text for advisory dialogues: Capturing intentional and rhetorical information. Computational Linguistics, 19(4):651-695.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Moore</author>
<author>M Pollack</author>
</authors>
<title>A problem for RST: The need for multi-level discourse analysis.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<pages>18--4</pages>
<marker>Moore, Pollack, 1992</marker>
<rawString>J. Moore and M. Pollack. 1992. A problem for RST: The need for multi-level discourse analysis. Computational Linguistics, 18(4):537-544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M G Moser</author>
<author>J D Moore</author>
</authors>
<title>Toward a synthesis of two accounts of discourse structure.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--3</pages>
<contexts>
<context position="21879" citStr="Moser and Moore, 1996" startWordPosition="3575" endWordPosition="3578">parate, important phenomenon. For instance, in a DANISLtagged set of 8 dialogs in our corpus, 40% of the utterances were statements, and many of these appeared in sequences of statements. The relationships between many of these statements are unclear without a model of rhetorical structure. In (1999), Nakatani and Traum describe a hierarchical annotation of dialog for I-units, based on the ..damthation and satisfaction-precedence relations of (Grosz and Sidner, 1986). Other researchers have shown that Grosz and Sidner&apos;s model of discourse structure (GST) and RST are similar in many respects [(Moser and Moore, 1996), (Marcu, 1999)]. However, RST provides more specific relations than GST, and this is useful for content planning. As well as helping., to specify generation goals, content arid ordering constraints, the rhetorical information is needed in case the system has to explain what it has said. &amp;quot;IA rough draft is a.vailahte from the author. RDA is an annotation scheme for identifying rhetorical structure in explanatory texts in the SHERLOCK domain (Moser et al., 1996). We follow RDA in requiring annotators to consider both intentional and informational relations. However, because of the dialog issues</context>
</contexts>
<marker>Moser, Moore, 1996</marker>
<rawString>M. G. Moser and J. D. Moore. 1996. Toward a synthesis of two accounts of discourse structure. Computational Linguistics, 22(3):409-420.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Moser</author>
<author>J Moore</author>
<author>E Glendening</author>
</authors>
<title>19913 Instructions for coding explanations: Identifying segments. relations and minimal units.</title>
<tech>Technical Report 96-17.</tech>
<institution>University of Pittsburgh. Department of Computer Science.</institution>
<marker>Moser, Moore, Glendening, </marker>
<rawString>M. Moser, J. Moore, and E. Glendening,. 19913 Instructions for coding explanations: Identifying segments. relations and minimal units. Technical Report 96-17. University of Pittsburgh. Department of Computer Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Nakatani</author>
<author>D Traum</author>
</authors>
<title>Coding discourse structure in dialogue (version 1.0).</title>
<date>1999</date>
<tech>Technical Report UMIACS-TR-99-03,</tech>
<institution>University of Maryland.</institution>
<marker>Nakatani, Traum, 1999</marker>
<rawString>C. Nakatani and D. Traum. 1999. Coding discourse structure in dialogue (version 1.0). Technical Report UMIACS-TR-99-03, University of Maryland.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Michael O&apos;Donnell</author>
</authors>
<title>1997_ RST -Tool: An RST analysis tool.</title>
<booktitle>In Proceedings of the 6th European Workshop on Natural Language Gene.ration,</booktitle>
<institution>Gerhard-Mercator University,</institution>
<location>Duisburg, Germany.</location>
<marker>O&apos;Donnell, </marker>
<rawString>Michael O&apos;Donnell. 1997_ RST -Tool: An RST analysis tool. In Proceedings of the 6th European Workshop on Natural Language Gene.ration, Gerhard-Mercator University, Duisburg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stent</author>
</authors>
<title>The Monroe corpus.</title>
<date>2000</date>
<tech>Technical Report TR728/TN99-2,</tech>
<institution>University of Rochester.</institution>
<contexts>
<context position="1838" citStr="Stent, 2000" startWordPosition="280" endWordPosition="281"> basic premise is that a conversational agent should be able to produce whatever a human can produce in similar discourse situations, and that if we can explain why a human produced a particular contribution, • This work was supported by ONR research grant NO0014- 95-1-1088, U.S. Air Force/Rome Labs research contract no. F30602-95-1-0025, NSF research grant no. MI-9623565 and Columbia liniversity/NSF research grant no. OPC: 1307. We would like to t hank the anonymous reviewers, and Dr. .1a.qon Eisner For their helpful comments on earlier drans of this paper. 3 VIC are using the Monroe corpus (Stent, 2000), with reference to the TRAINS corpus (fleeman and Allen, 1995) and the FICRC Maptask corpus (Anderson et al., 11101). we can program a conversational agent to produce something similar. Therefore, in examining our dialogs the question we must answer is &amp;quot;Why did this speaker produce this?&amp;quot;. RST is a descriptive theory of hierarchical structure in discourse that identifies functional relationships between discourse parts based on the intentions behind their production (Mann and Thompson, 1987). It has been used in content planning systems for text (effectively text monolog) (e.g. (Cawsey, 1993)</context>
</contexts>
<marker>Stent, 2000</marker>
<rawString>A. Stent. 2000. The Monroe corpus. Technical Report TR728/TN99-2, University of Rochester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Traurn</author>
<author>E Hinkelman</author>
</authors>
<title>Coriversatirm acts in task-oriented spoken dialogue.</title>
<date>1992</date>
<journal>Computational Intelligence,</journal>
<pages>8--3</pages>
<marker>Traurn, Hinkelman, 1992</marker>
<rawString>D. Traurn and E. Hinkelman. 1992. Coriversatirm acts in task-oriented spoken dialogue. Computational Intelligence, 8(3):575-599.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>