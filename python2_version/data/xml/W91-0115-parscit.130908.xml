<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.7019972">
Handling Pragmatic Information
With A Reversible Architecture
Masato Ishizaki
NTT Communications and Information Processing
Laboratories
</title>
<address confidence="0.716042">
1-2356, Take, Yokosuka, Kanagawa, 238-03 Japan
</address>
<email confidence="0.943929">
E-mail: ish izaki%nttn ly.ntt.jp@ relay.cs. net
</email>
<sectionHeader confidence="0.991706" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999867272727273">
This paper proposes a reversible architecture
to handle not only syntactic and semantic
information but also pragmatic information.
Existing architectures cannot represent prag-
matic information explicitly, and lack rea-
soning capability given insufficient informa-
tion. I argue that the techniques of plan rep-
resentation and approximate reasoning are,
in the enhanced argumentation system pro-
posed here, effective for solving these prob-
lems.
</bodyText>
<sectionHeader confidence="0.997806" genericHeader="keywords">
1. Introduction
</sectionHeader>
<bodyText confidence="0.965353508196722">
Reversibility or bi-directionality of grammars
seems to play a quite important role in natural
language processing. It reduces the cost of
constructing a grammar, we need to use only
one grammar instead of two for parsing and
generation. Cost here includes not only the
making of grammar rules but also verifying
the rules and the algorithms for parsing and
generation. Reversibility differs from bi-
directionality: the former requires the same
mechanism and &apos;grammar for parsing and
generation; the latter requires just the same
grammar as shown Figure l(Noord,1990).
Pragmatic information is not rigidly
defined; rather it is thought of as information
other than syntactic and semantic informa-
tion. It is indispensable for explaining many
linguistic phenomena from cleft sentences
to discourse structures. As pragmatics cannot
restrain language in a strict manner like syn-
tax, it must be processed differently; that is,
a distinction must be made between con-
straints that need to be fully satisfied and
those that do not. Plan representation seems
to be appropriate for collecting different
level information. A plan consists of precon
ditions, constraints, plan expansion (usually
termed the body), and effects. The relation-
ship between preconditions and constraints
parallels that between pragmatic and syntactic
information. Thus, the difference between
preconditions and constraints can be easily
modeled.
Handling pragmatic information clearly
depends on assumption of belief: Generating
referring expressions requires inferencing
the hearer&apos;s belief (Appelt,1985); Producing
text requires the usage of a one-sided mutual
belieV(Moore et al.,1989); the listener&apos;s
inference about the speaker&apos;s belief greatly
helps to resolve anaphora or to analyze the
speaker&apos;s intention. In any case, belief be-
comes a condition for further inference; how-
ever, it is difficult if not impossible to confirm
the assumed belief. Thus, a new mechanism
based on a new architecture is needed. Ap-
proximate reasoning (Elkan,1990) is suit-
able for this purpose. Processing can con-
tinue, even if some preconditions are not
fully satisfied; they are held as assump-
tions&apos;. This approach seems to be very
natural . For example, in conversations, the
speaker should conceptualize the listener&apos;s
&apos;One-sided mutual belief is one half of
mutual knowledge, so to speak, namely the set of
those pieces of mutual knowledge that constitute
the knowledge of one speaker (Bunt,1989: 60).
2S ince approximate reasoning can fail,
assumptions must be held explicitly for further in-
ference. Plan representation is adequate for that
reason.
</bodyText>
<page confidence="0.994035">
119
</page>
<note confidence="0.586058">
Para eters Strings Stri gs
</note>
<figureCaption confidence="0.997345">
Figure 1. Reversible And Bi-directional Architectures.
</figureCaption>
<bodyText confidence="0.984723615384615">
understanding. In most conversations, how-
ever, the speaker does not keep confirming
the other&apos;s belief because this would disrupt
the conversation flow.
This paper describes a reversible archi-
tecture to handle not only syntactic and se-
mantic information, but also pragmatic in-
formation. Existing architectures cannot rep-
resent pragmatic information explicitly, and
lack reasoning capability given insufficient
information. I argue that the techniques of
plan representation and approximate reason-
ing in the argumentation system introduced
here are effective for solving these problems.
First, the difficulties of existing architec-
tures have in handling pragmatic information
are described. Next, plan representation of
linguistic information and approximate rea-
soning are mentioned in the context of the
argumentation system. Third, parsing and
generation examples are shown. Finally, the
problem of proposed data structure, the de-
composition of semantic representation, the
role of syntactic information and the differ-
ence between active and passive vocabulary
are discussed.
</bodyText>
<sectionHeader confidence="0.855287" genericHeader="introduction">
2. Existing Architectures For Re-
</sectionHeader>
<subsectionHeader confidence="0.9696235">
versible And Bi-directional Gram-
mar
</subsectionHeader>
<bodyText confidence="0.961155333333333">
Shieber proposed a uniform architecture for
sentence parsing and generation based on
the Early type deduction mechanism
(Shieber,1988). He parametrized the archi-
tecture with the initial condition, a priority
function on lemmas, and a predicate ex-
pressing the concept of successful proof.
Shieber remedied the inefficiency of the gen
eration algorithm in his uniform architecture
to introduce the concept of semantic head
(Shieber et al.,1989). Although Definite
Clause Grammar (DCG) is reversible, its
synthesis mode is inefficient. Dymetman
and Strzallcowski approached the problem
by compiling DCG into efficient analysis
and synthesis programs (Dymetman et
al.,1988) (Strzalkowski,1990). The compi-
lation is realized by changing goal ordering
statically. Since Shieber&apos;s, Dymetman&apos;s and
Strzalkowski&apos;s architectures are based on
syntax deduction, they have difficulties in
handling pragmatic information.
Dependency propagation was suggested
for parsing and generation in (Hasida et
al.,1987). His idea was developed using
horn clauses similar to PROLOG. The word
dependency indicates the states where vari-
ables are shared by constraints&apos;. Problem
solving or parsing and generation can be
modeled by resolving the dependencies. De-
pendency resolution is executed by fold/un-
fold transformations. Dependency propaga-
tion is a very elegant mechanism for problem
</bodyText>
<tableCaption confidence="0.517239857142857">
solving, but it seems to be difficult to repre-
sent syntactic, semantic and pragmatic infor-
mation with indiscrete constraints. In addi-
tion, to that, since dependency propagation
is a kind of co-routine process, programs
are very hard to debug and so constraints
are tough to stipulate.
Ait-Kaci&apos;s typed unification was applied
to a reversible architecture (Emele and Zajac
,1990). All features in sign are sorted and
placed in hierarchical structures. Parsing and
generation can be executed by rewriting the
3Constraints are represented by the usual
PROLOG predicates.
</tableCaption>
<page confidence="0.995928">
120
</page>
<bodyText confidence="0.9998352">
features into their most specific forms. Their
mechanism greatly depends on the hierarchy
of information, but with information other
than syntactic, especially pragmatic, it is hard
to construct the hierarchy.
</bodyText>
<sectionHeader confidence="0.552331" genericHeader="method">
3. Introduction To the New Re-
</sectionHeader>
<subsectionHeader confidence="0.8471615">
versible ArChitecture
3.1. The Linguistic Objects
</subsectionHeader>
<bodyText confidence="0.96759825">
We introduce the linguistic object sign which
incorporates syntactic, semantic and prag-
matic information. Sign is represented by
feature structures and consists of features
phn, syn, sem and prag. Phn represents
surface string information for words, phras-
es and sentences. Syn stands for syntactic
information like the part of speech and sub-
categorization information using HPSG.
HPSG inherits the fundamental properties
of Generalized Phrase Structure Gram-
mar(GPSG). That is, HPSG makes use of
a set of feature-value pairs, feature con-
straints and unification to stipulate grammar
instead of rewriting rules for terminal and
nonterrninal symbols. The major difference
between HPSG, and GPSG is that subcat-
egorization information is stored in lexical
entries, instead of being stored in grammar
rules (Pollard et al.,1987,1990). Sem de-
notes semantic information or logical forms.
Logical forms are expressed by the semantic
representation language proposed by Gazdar
(Gazdar et a1,1989). Since the language is a
feature representation of Woods&apos; representa-
tion (Woods,1978), it has the advantages
that it can represent quantifier scope ambigu-
ities. It consists. of the features qnt, var,
rest, and body :cint is for quantifier expres-
sions; var is for variables bound by the
qnt; rest is for restrictions of the var; while
body represents the predication of the logical
form. Prag delineates pragmatic informa-
tion. Pragmatic conditions are not necessarily
true but are held as assumptions. Uniqueness
and novelty conditions in cleft sentences are
instances of the conditions.
phn: &amp;quot;It was the girl that a boy loved&amp;quot;
syn: pos: verb
subcat:subc(H)
</bodyText>
<listItem confidence="0.972951846153846">
sem: qnt: indefinite
var: X
rest: argO: X
pred: BOY
body: qnt: definite
var: Y
rest: argO: Y
pred: GIRL
body: argO: X
argl: Y
pred: LOVED
prag: [novel(Y), unique(Y)]
— Sign
</listItem>
<figureCaption confidence="0.916883857142857">
Figure 2. Linguistic Object Example.
Figure 2 shows an example of the
linguistic object sign. The feature phn indi-
cates that surface string is &amp;quot;It was a girl
that the boy loved&amp;quot;. Syn represents that: 1)
the part of speech is verb; 2) subcategoriza-
tion information is satisfied. Sem shows
that: 1) the quantifier at the top level is in-
definite; 2) the property of the variable X is
a boy; 3) the property of the variable Y
bounded by the quantifier definite is a girl;
4) the boy loved the girl. Prag mentions
that the variable Y is constrained with
uniquness and novelty conditions.
</figureCaption>
<subsectionHeader confidence="0.9998295">
3.2. The Plan Representation of
Linguistic Objects
</subsectionHeader>
<bodyText confidence="0.999997785714286">
To handle syntactic , semantic, and pragmatic
information, our generator represents them
as plans. Plans are composed of precondi-
tions, constraints, plan expansion, and ef-
fects. Preconditions include pragmatic infor-
mation which are the criteria needed to select
a plan. Constraints include syntactic condi-
tions such as the head feature principle and
conditions on surface strings. Plan expan-
sion contains sub-semantic expressions for
effects, which are complete semantic ex-
pressions. Constraints and preconditions are
similar, but differ in that the former must be
satisfied, but the latter are retained as as-
</bodyText>
<page confidence="0.988911">
121
</page>
<bodyText confidence="0.9766695">
sumptions if not satisfied.
Figure 3 describes a plan relating to the
semantic information LOVED. No precondi-
tions exists because the expression &amp;quot;loved&amp;quot;
has no pragmatic information. Constraints
indicate that: 1) the part of speech equals
verb; 2) the subcategorization information
is subc([Sbj,Obj]); 3) The sem features of
</bodyText>
<equation confidence="0.909582833333333">
precond: [1
const: (Sign:syn:pos = verb),
(Sign:syn:subcat = subc([Sbj,Obj])),
(Arg0 = S bj : sem), (Argl = Obj : sem),
(Sign:phn = &amp;quot;loved&amp;quot;)
eplan: []
</equation>
<listItem confidence="0.590046333333333">
effect: argO: Arg0
arg 1 : Argl
pred: LOVED
</listItem>
<figureCaption confidence="0.998149">
Figure 3. Plan Example.
</figureCaption>
<bodyText confidence="0.999768833333333">
Sbj and Obj are semantic arguments of pred-
icate LOVED; 4) the surface string is &amp;quot;loved&amp;quot;.
There is no plan expansion because lexical
information does not need to be expanded.
Effects mention semantic expression of
LOVED.
</bodyText>
<subsectionHeader confidence="0.9998795">
3.3. An Argumentation System
For Planning
</subsectionHeader>
<bodyText confidence="0.999953384615385">
A plan recognition scheme, named the argu-
mentation system, was proposed by Kono-
lige and Pollack (Konolige and Pollack
,1989). It can defeasibly reason about belief
and intention ascription&apos;, and can process
preferences over candidate ascriptions. The
framework is so general and powerful that
it can perform other processes other than
belief and intention ascription. For example,
Shimazu has shown that it can model parsing
mechanism
The argumentation system consists of
arguments. An argument is a relation between
</bodyText>
<page confidence="0.958507">
4
</page>
<bodyText confidence="0.985982619047619">
Defeasible reasoning and approximate
reasoning are very similar, but differ in that: the
former addresses the result after rule application; the
latter considers just rule application.
a set of propositions (the premises of the
argument), and another set of propositions
(the conclusion of the argument) (Konolige
and Pollack,1989: 926). The system has a
language containing the following operators:
t(P) which indicates the truth of the proposi-
tion P; bel(A,PF) which mentions that agent
A believes plan fragment PF; int(A,PF)
which shows that agent A intends plan frag-
ment PF; exp(A,P) which means that agent
A expects proposition P to be true; and
by(Actexp 1 ,Actexp2,Pexp) which signifies
the complex plan fragment which consists
of the action expression Actexp2, by doing
action expression Actexpl while proposi-
tional expression Pexp is true5. The argu-
ments to the operators, action expressions
inform(S,H,Sem) and utter(S,H,Str), are in-
troduced to mimic informing and uttering
activities: the former is designated such that
speaker S informs hearer H about semantic
content Sem; the latter indicates speaker S
utters string Str to hearer H.
Plan expansion, effects and constraints
mentioned in subsection 3.2 correspond to
Actexpl, Actexp2 and Pexp, respectively.
To represent the difference between precon-
ditions and constraints, the operator by is
revised to include preconditions as the fourth
argument. Thus, the new operator
by(Actexpl,Actexp2,Pexpl,Pexp2) is de-
fined as the complex plan fragment, consist-
ing of doing Actexp2 (effect(s)), by doing
Actexpl (plan expansion) while Pexpl (con-
straints) is true, and Pexp2 (precondition(s))
is true or held as assumptions. The plan in
figure 2 was redefined by using axiom (1)6.
Axiom (2) shows another example cor-
</bodyText>
<tableCaption confidence="0.512762857142857">
5Action expressions are formed from an
action name and parameters; Propositional expres-
sions are formed from a property name and parameters.
6Because of space limitations, abbrevia-
tions are used as necessary. For example, Pos is
taken to mean the value of the features of part
_of speech of syntactic information of sign.
</tableCaption>
<page confidence="0.991684">
122
</page>
<bodyText confidence="0.96406">
responding to the context free grammar for
a cleft sentence.
</bodyText>
<sectionHeader confidence="0.541171" genericHeader="method">
Axiom (1):
</sectionHeader>
<bodyText confidence="0.911334142857143">
t(by(utter(S,H,&amp;quot;loved&amp;quot;),
inform(S,H,LOVED),
((Pos=verb),
(Subcat=sUbc([Sbj,Obj1)),
(Sbj:sem=Arg0),
(Obj:sem=Arg1)),
0)
</bodyText>
<sectionHeader confidence="0.670198" genericHeader="method">
Axiom (2):
</sectionHeader>
<bodyText confidence="0.914033666666667">
t(by((inform(S,H,LF17),
inform(S,H,LF28)),
inform(S,H,LF9),
((Pos=Pos2),(Sign1=Sbj),
(Subcat=subc([])),
(Slash=s1([])),
(Slash2=sIgObjp),
(Phn=&amp;quot;It was&amp;quot;+Phn1+&amp;quot;that&amp;quot;+Phn2)),
(Prag))).
</bodyText>
<table confidence="0.96451156">
71,F1 is designated as:
Signl: Sem: qnt: Q2
var: Y
rest: argO: Y
pred: YRest.
8LF2 is designated as:
Sign2: sem: qnt: Q1
var: X
rest: argO: X
pred: XRest
body: argO: Arg0
arg 1: Arg 1
pred: Pred.
9LF designated as:
Sign: sem: qnt: Q1
var: X
rest: argO: X
pred: XRest
body: qnt: Q2
var: Y
rest: argO: Y
pred: YRest
body: argO: Arg0
argl: Argl
pred: Pred.
</table>
<bodyText confidence="0.999152866666667">
Plan expansion and effects indicate that if
speaker S wants to inform hearer H about
LF, the speaker should inform the hearer
about LF1 and LF2, while observing con-
straints 1) -4). Constraints state that: 1) the
part of speech of Sign equals one of Sign2;
2) Subcategorized and slash information of
Sign is nil; 3) Subcategorized information
of Sign2 equals nil; 4) Slash information of
Sign2 is equivalent to Obj; 4) a surface string
consists of the string &amp;quot;It was&amp;quot;, the string
relating to Signl, the string &amp;quot;that&amp;quot; and the
string relating to Sign2. Other axioms which
are necessary for explaining parsing and gen-
eration examples are listed in the appendix.
</bodyText>
<sectionHeader confidence="0.904048" genericHeader="method">
4. Reversibility In Proposed Ar-
</sectionHeader>
<bodyText confidence="0.612666">
chitecture
</bodyText>
<subsectionHeader confidence="0.992623">
4.1. Sentence Parsing
</subsectionHeader>
<bodyText confidence="0.99988075">
Parsing techniques were simulated using an
argumentation system in (Shimazu,1990).
Since he faithfully tried to model existing
techniques, many parsing oriented terms
such as complete and addition were intro-
duced. This seems to be the cause of the
difficulty he experienced in integrating pars-
ing with other processes.
</bodyText>
<subsectionHeader confidence="0.432898">
Argument (a):
</subsectionHeader>
<bodyText confidence="0.7130649">
belascl°
t(P) &gt; bel(S,P) .
Argument (b):
bel(S,by(PE,E,C,PR)),int(S,PE),
exp(S,C),expl(S,PR)
by2&apos;
&gt; int(S,by(PE,E,C,PR)),
int(S,E).
10The expression above the arrow
indicates the class of an argument.
</bodyText>
<page confidence="0.997978">
123
</page>
<bodyText confidence="0.999005083333334">
Since syntactic, semantic and pragmatic in-
formation can be represented with the new
by relation, arguments (a) and (b) enable
us to simulate parsing: (a) says that true
propositions can be ascribed to a speaker&apos;s
belief; (b) states that, if a speaker is assumed
to believe that E is an effect of performing
plan expansion PE, while constraint C is
true and precondition PR is assumed to be
true&amp;quot;, then it is plausible that his reason
for doing PE is his intention to do E.
Parsing is executed as follows: first,
axioms whose constraints match an input
word are collected; second, the axiom which
satisfies the constraint is selected (precondi-
tions are asserted); third, an effect, or se-
mantic information is derived using an in-
stance of argument (b); fourth, another in-
stance of the argument is applied to the effect
and the effect which was already derived to
obtain a new effect. If the application cannot
proceed further, a new word is analyzed;
Lastly, if all words in a sentence are analyzed
successfully, the execution is complete.
Parsing is exactly the same as plan
recognition in the sense of (Konolige and
Pollack,1989:925):
Plan recognition is essentially a &amp;quot;bottom-up&amp;quot;
recognition process, with global coherence
used mostly as an evaluative measure, to
eliminate ambiguous plan fragments that
emerge from local cues.
Maximizing head elements can realize
right association and minimal attachment,
but handling semantic ambiguities, that is to
clarify global coherence, is a further issue.
</bodyText>
<subsectionHeader confidence="0.999176">
4.2. Sentence Generation
</subsectionHeader>
<bodyText confidence="0.999449">
Generation can be simulated using arguments
(a) and (c). (c) says that, if a speaker believes
that E is an effect of performing plan expan-
sion PE, while constraint C is true and pre-
condition PR is assumed to be true, and he
intends to do E, then it is plausible that his
intention PE is to achieve E.
&apos;Action expression expl(A,P)
means that agent A expects proposition P
to be assumed to be true if not fully satisfied.
</bodyText>
<equation confidence="0.624126">
Argument (c):
bel(S,by(PE,E,C,PR)),int(S,E),
exp(S,C),expl(S,PR)
by3&apos;
&gt; int(by(PE,E,C,PR)),
int(S,PE)
</equation>
<bodyText confidence="0.995904678571429">
Generation is executed in a similar way
to parsing except that axioms are collected
using semantic information and the result is
a string&apos;. Figure 4 describes the generation
process. The input linguistic object is equiv-
alent to the object in Figure 2 whose surface
string information is parameterized. The gen-
eration result is the input object with the
instatiated surface string, that is Figure 1.
In Figure 4, axiom (2) creates subgoals
related to the variable Y and others (cor-
responding to (2) and (3)) because the se-
mantic and pragmatic information of the input
equals the effect and preconditions of the
axiom. As the head features propagate to
the linguistic object (2), execution addressing
object (2) is preferred. The axiom (6) con-
structs subgoals by referring to the objects
whose semantic information is related to the
features qnt, var, rest and the logical form
concerned with the bound variable X. The
head feature preference makes the generator
execute axioms about object (4). This results
in the axiom (1) of lexical information. Sim-
ilar to the above process, the remaining sub-
goals (5) and (2) are executed. Finally, the
surface string &amp;quot;It was a girl that the boy
loved&amp;quot; is obtained.
</bodyText>
<sectionHeader confidence="0.928684" genericHeader="method">
5. Discussions
</sectionHeader>
<bodyText confidence="0.980634571428571">
As mentioned in (Emele and Zajac,1990),
the proposed approach inevitably leads to
the consequence that the data structure be-
comes slightly complicated. However, due
12Because of space limitation, action
expressions inform and utter are omitted
in the figure.
</bodyText>
<page confidence="0.98868">
124
</page>
<figure confidence="0.76821912">
(2)
(12) (11)
(14) (13)
Sign:phn:Expll Sign:phn:Expl2
syn:Syn 1 1 syn:Syn 1
sem:qnt:definite sem:rest: argO:Y
var:Y pred:GIRL
prag:[] prag:[]
1
S ign:phn:&amp;quot; the&amp;quot; Sign:phn:&amp;quot;girl&amp;quot;
syn:pos:deI syn: pos: noun
sem:qnt:definite sem:rest:argO:Y
var:Y pred:GIRL
prag:[] prag:[]
(1) Sign:phn:&amp;quot; It was&amp;quot;+Expl+&amp;quot;that&amp;quot;+Exp2
syn:pos:verb
subcatsubc(0)
slash:WO)
sem:qnt:indefinite
var:X
rest:arg0:X
pred:BOY
body:gm:definite
var:Y
rest:argO:Y
pred:GIRL
body:arg0:X
argl:Y
pred:LOVED
prag:[novel(Y),unique(Y)]
Sign:phn:Exp 1 (3)
syn:Syn 1
sem:gni:definite
var:Y
reit:argO:Y
pred:GIRL
prag:[] ,
Sign:phn:Exp2
syn:pos:verb
subcat:subc(])
slash:s1([0bj])
sem:qnt: indefinite
var:X
rest:arg0:X
pred: BOY
body:arg0:X
arg 1 :Y
pred:LOVED
prag:[]
(5) Sign:phn:Exp21 (4) Sign:phn:Exp22
</figure>
<table confidence="0.964709444444444">
syn:Syn21 syn:pos:verb
sem:qnt: indefinite subcat:subc([Sbj,Obj])
var:X sem:arg0:X
rest:arg0:X argl:Y
pred:BOY pred:LOVED
prag:[] prag:[]
Sign: phn:Exp211 (7) Sign:phn:Exp212 (6) S ign:phn:&amp;quot; loved&amp;quot;
syn:Syn211 syn:S yn21 syn:pos:verb
sem:qnt: indefinite sem:rest:arg0:X subcat:subc([Sbj,Obj])
var:X pred:BOY scm:argO: X
prag [1 prag:[] argl:Y
pred:LOVED
prag:[]
Sign:phn:&amp;quot; a&amp;quot; (9) S ign:phn:&amp;quot; boy&amp;quot;
syn:pos:det syn:pos: noun
sem :qn t: indefi n ite sem :rescarg0:X
var:X pred:BOY
prag:[] prag:[]
</table>
<figureCaption confidence="0.988274">
Figure 4. Generation Example.
</figureCaption>
<page confidence="0.935793">
125
</page>
<figure confidence="0.593432">
(8)
(10)
</figure>
<bodyText confidence="0.999898098039216">
to the segregation of the structure such as
the distinction between preconditions and
constraints, the task of developing rules can
be done independently. Thus, if you want,
you can concentrate on developing grammar
rules irrespective of the pragmatic informa-
tion. If desired, however, pragmatics can
be used to precisely stipulate some linguistic
phenomena (Delin,1990).
The semantic representation utilized here
depends on the strong assumption that it
can be systematically decomposed. It is ad-
vantageous that the assumption supports
symmetry as discussed in (Noord,1990)
and naturally realizes semantic indexing
which leads to efficient processing
(Calder,1989). However, it limits the repre-
sentation capability for semantic processing
(Shieber et al.,1989). The problems of se-
mantic representation are still difficult, so
their study is an ongoing task.
Syntactic information, or grammar
rules in the paper is neutral in the sense
that only one kind of rules, or axioms are
sufficient for both parsing and generation;
but their difference lies in their usage of
information. In the case of parsing, syntactic
information is used as a local cue to derive
the semantic and pragmatic information. In
the case of generation, it is used to prevent
the production of ungrammatical strings.
This difference appears to mirror asymmetry
between writing and reading (or speaking
and hearing). The reading process lets un-
known words be hypothesized by referring
to neighboring words that are understood.
Writing, on the other hand, is a process in
which unknown words cannot be developed
by examining adjacent words. Hypothesiz-
ing is used both for parsing and generation,
but its role in these processes is different. It
is used to derive a coherent interpretation
from all words in the parsing, while it is
used to smooth the conversational (or text)
flow in generation. The difference of the
hypothesis use seems to be one of the factors
in explaining this asymmetry. The proposed
architecture is certain to provide a basis to
examine this claim in the sense that it inte-
grates linguistic processes with a reasoning
mechanism.
</bodyText>
<sectionHeader confidence="0.98443" genericHeader="method">
6. Conclusion
</sectionHeader>
<bodyText confidence="0.9921931">
This paper has proposed a reversible archi-
tecture to handle not only syntactic and se-
mantic information but also pragmatic infor-
mation. Existing architectures cannot repre-
sent pragmatic information explicitly, and
lack reasoning capability given insufficient
information. I argue that the techniques of
plan representation and approximate reason-
ing in the enhanced argumentation system
are effective for solving these problems.
</bodyText>
<sectionHeader confidence="0.988843" genericHeader="method">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999883">
The author wishes to extend his sincere grat-
itude to Tsuneald Kato and Yoshihiko Ha-
yashi for discussing this architecture. He
also thank Masanobu Higashida and Yoichi
Sakai for encouraging him to study this sub-
ject.
</bodyText>
<sectionHeader confidence="0.668185" genericHeader="method">
Appendix
Axiom (3):
</sectionHeader>
<bodyText confidence="0.99803675">
t(by(utter(S,H,&amp;quot;the&amp;quot;),
inform(S,H,definite),
((Pos=det),(Adjacent=noun)),
0)).
</bodyText>
<sectionHeader confidence="0.787149" genericHeader="method">
Axiom (4):
</sectionHeader>
<bodyText confidence="0.99799925">
t(by(utter(S,H,&amp;quot;boy&amp;quot;),
inform(S,H,BOY),
(Pos=noun),
0)).
</bodyText>
<sectionHeader confidence="0.800204" genericHeader="method">
Axiom (5):
</sectionHeader>
<bodyText confidence="0.99184875">
t(by(utter(S,H,&amp;quot;a&amp;quot;),
inform(S,H,indefinite),
((Pos=det),(Adjacent=noun)),
0)).
</bodyText>
<page confidence="0.995602">
126
</page>
<bodyText confidence="0.985642954545455">
Axiom (6):
t(by(utter(S,H,&amp;quot;girl&amp;quot;),
inform(S,H,GIRL),
(Pos=noun),
0)).
Axiom (7):
t(by((inform(S,H,LF11),
inform(S,H,LF12)),
inform(S,H,LF1),
((Pos1=Pog12),
(Phn1=Phri11+Phn12)),
0)).
Axiom (8):
t(by((inform(S,H,LF21),
inform(S,H,LF22)),
inform(S,H,LF2),
((Pos2=P6s21),
(Subcat2=Isubc(0)),
(Slash2=s1([0bj])),
(Subcat22=---subc([Sbj,Obj])),
(Phn2=P1M21+Phn22)),
0)).
</bodyText>
<sectionHeader confidence="0.795055" genericHeader="conclusions">
Bibliography
</sectionHeader>
<reference confidence="0.99989845">
(Appelt,1985&apos;) Douglas E. Appelt. 1985.
&amp;quot;Planning English Sentences&amp;quot;. Cambridge
University Press.
(Calder et al.,1989) Jonathan Calder,
Mike Reape, and Henk Zeevat. 1989. &amp;quot;An
Algorithm for Generation in Unification Cat-
egorial Grammar&amp;quot;. Proceedings of the 4th
Conference of the European Chapter of the
Association for Computational Linguistics.
Manchester, U.K.. 10-12, April. 233-240.
(Delin,1990) J.L.Delin. 1990. &amp;quot;A Multi-
Level Account of Cleft Constructions in Dis-
course&amp;quot;. Proceedings of the 13th Interna-
tional Conference on Computational Linguis-
tics. Aug. 20-25. Helsinki, Finland. 83-88.
(Dymetman et al.,1989) Marc Dymet-
man and Pierre Isabelle. 1989. &amp;quot;Reversible
Logic Grammars For Machine Translation&amp;quot;.
Proceedings of the 2nd International Confer-
ence on Theoretical and Methodological Is-
sues In Machine Translation of Natural Lan-
guages. Jun. 12-14. Pittsburgh, Pennsylva-
nia, U.S.A..
(Elkan,1990) Charles Ellcan. 1990. &amp;quot;In-
cremental, Approximate Planning&amp;quot;. Pro-
ceedings of the 8th National Conference on
Artificial Intelligence. Jul.29-Aug.3. Bos-
ton, MA, U.S.A.. 145-150.
(Emele and Zajac,1990) Martin Emele
and Remi Zajac. 1990. &amp;quot;Typed Unification
Grammars&amp;quot;. Proceedings of the 13th Inter-
national Conference on Computational Lin-
guistics. Aug. 20-25. Helsinki, Finland.
293-298.
(Gazdar et al.,1989) Gerald Gazdar and
Chris Mellish. 1989. &amp;quot;Natural Language
Processing in PROLOG&amp;quot;. Addison-Welsley
Publishing Company.
(Hasida,1987) Hasida Koiti. 1987. &amp;quot;De-
pendency Propagation: A Unified Theory
of Sentence Comprehension and Genera-
tion&amp;quot;. Proceedings of the 10th International
Joint Conference on Artificial Intelligence.
Aug. 23-28. Milan, Italy. 664-670.
(Konolige and Pollack,1989) Kurt
Konolige and Martha E. Pollack. 1989. &amp;quot;As-
cribing Plans To Agents - Preliminary Report
- &amp;quot;. Proceedings of the 11th International
Joint Conference on Artificial Intelligence.
Aug. 20-25. Detroit, Michigan, U.S.A..
924-930.
(Moore et a1,1989) Johanna D. Moore
and Cecile Paris. 1989. &amp;quot;Planning Text For
Advisory Dialogue&amp;quot;. Proceedings of the 27th
Annual Meeting of the Association for Com-
putational Linguistics. Jun. 26-29. Van cou-
ver, British Columbia, Canada. 203-211.
(Pollard et al.,1987) Carl Pollard and
Ivan A. Sag. 1987. &amp;quot;An Information-Based
Syntax and Semantics (Volume 1)&amp;quot;. CSLI
</reference>
<page confidence="0.976524">
127
</page>
<reference confidence="0.992729083333333">
Lecture Notes. Number 13.
(Pollard et al.,1990) Carl Pollard and
Ivan A. Sag. 1990. &amp;quot;An Information-Based
Syntax and Semantics (Volume 2)&amp;quot;. ms.
(Shieber,1988) Stuart M. Shieber. 1988.
&amp;quot;A Uniform Architecture For Parsing and
Generation&amp;quot;. Proceedings of the 12th Inter-
national Conference on Computational Lin-
guistics. Aug. 22-27. Bonn, Germany. 614-
619.
(Shieber et al.,1989) Stuart M. Shieber,
Gertjan van Noord, Robert C. Moore, and
Fernando C.N. Perreira. 1989. &amp;quot;A Semantic-
Head-Driven Generation Algorithms for
Unification-Based Formalisms&amp;quot;. Proceed-
ings of the 27th Annual Meeting of the As-
sociation for Computational Linguistics.
Jun. 26-29. Van couver, British Columbia,
Canada. 7-17.
(Shimazu,1990) Akira Shimazu. 1990.
&amp;quot;Japanese Sentence Analysis as Argumenta-
tion&amp;quot;. Proceedings of the 13th International
Conference on Computational Linguistics.
Aug. 20-25. Helsinki, Finland. 259-264.
(Strzalkowski,1990) Tomek Strza-
lkowski. 1990. &amp;quot;How To Invert A Natural
Language Parser Into An Efficient Generator
An Algorithm For Logic Grammars&amp;quot;. Pro-
ceedings of the 13th International Conference
on Computational Linguistics. Aug. 20-25.
Helsinki, Finland. 347-352.
(Woods,1978) W.A.Woods. 1978. &amp;quot;Se-
mantics and Quantification in Natural Lan-
guage Question Answering&amp;quot;. Advances in
Computers. Vol. 17. M.Yovits (ed.). Aca-
demic Press.
</reference>
<page confidence="0.996744">
128
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.800834">
<title confidence="0.9977505">Handling Pragmatic Information With A Reversible Architecture</title>
<author confidence="0.996316">Masato Ishizaki</author>
<affiliation confidence="0.996735">NTT Communications and Information</affiliation>
<address confidence="0.995436">1-2356, Take, Yokosuka, Kanagawa, 238-03</address>
<email confidence="0.973183">E-mail:ishizaki%nttnly.ntt.jp@relay.cs.net</email>
<abstract confidence="0.98588525">This paper proposes a reversible architecture to handle not only syntactic and semantic information but also pragmatic information. Existing architectures cannot represent pragmatic information explicitly, and lack reasoning capability given insufficient information. I argue that the techniques of plan representation and approximate reasoning are, in the enhanced argumentation system proposed here, effective for solving these problems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Douglas E Appelt</author>
</authors>
<title>Planning English Sentences&amp;quot;.</title>
<date>1985</date>
<publisher>Cambridge University Press.</publisher>
<marker>(Appelt,1985&apos;)</marker>
<rawString>Douglas E. Appelt. 1985. &amp;quot;Planning English Sentences&amp;quot;. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Calder</author>
<author>Mike Reape</author>
<author>Henk Zeevat</author>
</authors>
<title>An Algorithm for Generation in Unification Categorial Grammar&amp;quot;.</title>
<date>1989</date>
<booktitle>Proceedings of the 4th Conference of the European Chapter of the Association for Computational Linguistics.</booktitle>
<pages>10--12</pages>
<location>Manchester, U.K..</location>
<marker>(Calder et al.,1989)</marker>
<rawString>Jonathan Calder, Mike Reape, and Henk Zeevat. 1989. &amp;quot;An Algorithm for Generation in Unification Categorial Grammar&amp;quot;. Proceedings of the 4th Conference of the European Chapter of the Association for Computational Linguistics. Manchester, U.K.. 10-12, April. 233-240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Delin</author>
</authors>
<title>A MultiLevel Account of Cleft Constructions in Discourse&amp;quot;.</title>
<date>1990</date>
<booktitle>Proceedings of the 13th International Conference on Computational Linguistics.</booktitle>
<pages>83--88</pages>
<location>Helsinki,</location>
<marker>(Delin,1990)</marker>
<rawString>J.L.Delin. 1990. &amp;quot;A MultiLevel Account of Cleft Constructions in Discourse&amp;quot;. Proceedings of the 13th International Conference on Computational Linguistics. Aug. 20-25. Helsinki, Finland. 83-88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Dymetman</author>
<author>Pierre Isabelle</author>
</authors>
<title>Reversible Logic Grammars For Machine Translation&amp;quot;.</title>
<date>1989</date>
<booktitle>Proceedings of the 2nd International Conference on Theoretical and Methodological Issues In Machine Translation of Natural Languages.</booktitle>
<pages>12--14</pages>
<location>Pittsburgh, Pennsylvania, U.S.A..</location>
<marker>(Dymetman et al.,1989)</marker>
<rawString>Marc Dymetman and Pierre Isabelle. 1989. &amp;quot;Reversible Logic Grammars For Machine Translation&amp;quot;. Proceedings of the 2nd International Conference on Theoretical and Methodological Issues In Machine Translation of Natural Languages. Jun. 12-14. Pittsburgh, Pennsylvania, U.S.A..</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Ellcan</author>
</authors>
<title>Incremental, Approximate Planning&amp;quot;.</title>
<date>1990</date>
<booktitle>Proceedings of the 8th National Conference on Artificial Intelligence. Jul.29-Aug.3.</booktitle>
<pages>145--150</pages>
<location>Boston, MA, U.S.A..</location>
<marker>(Elkan,1990)</marker>
<rawString>Charles Ellcan. 1990. &amp;quot;Incremental, Approximate Planning&amp;quot;. Proceedings of the 8th National Conference on Artificial Intelligence. Jul.29-Aug.3. Boston, MA, U.S.A.. 145-150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Emele</author>
<author>Remi Zajac</author>
</authors>
<title>Typed Unification Grammars&amp;quot;.</title>
<date>1990</date>
<booktitle>Proceedings of the 13th International Conference on Computational Linguistics.</booktitle>
<pages>293--298</pages>
<location>Helsinki,</location>
<marker>(Emele and Zajac,1990)</marker>
<rawString>Martin Emele and Remi Zajac. 1990. &amp;quot;Typed Unification Grammars&amp;quot;. Proceedings of the 13th International Conference on Computational Linguistics. Aug. 20-25. Helsinki, Finland. 293-298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Gazdar</author>
<author>Chris Mellish</author>
</authors>
<title>Natural Language Processing in PROLOG&amp;quot;.</title>
<date>1989</date>
<publisher>Addison-Welsley Publishing Company.</publisher>
<marker>(Gazdar et al.,1989)</marker>
<rawString>Gerald Gazdar and Chris Mellish. 1989. &amp;quot;Natural Language Processing in PROLOG&amp;quot;. Addison-Welsley Publishing Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hasida Koiti</author>
</authors>
<title>Dependency Propagation: A Unified Theory of Sentence Comprehension and Generation&amp;quot;.</title>
<date>1987</date>
<booktitle>Proceedings of the 10th International Joint Conference on Artificial Intelligence. Aug.</booktitle>
<pages>23--28</pages>
<location>Milan,</location>
<marker>(Hasida,1987)</marker>
<rawString>Hasida Koiti. 1987. &amp;quot;Dependency Propagation: A Unified Theory of Sentence Comprehension and Generation&amp;quot;. Proceedings of the 10th International Joint Conference on Artificial Intelligence. Aug. 23-28. Milan, Italy. 664-670.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kurt Konolige</author>
<author>Martha E Pollack</author>
</authors>
<title>Ascribing Plans To Agents - Preliminary Report - &amp;quot;.</title>
<date>1989</date>
<booktitle>Proceedings of the 11th International Joint Conference on Artificial Intelligence.</booktitle>
<pages>924--930</pages>
<location>Detroit, Michigan, U.S.A..</location>
<marker>(Konolige and Pollack,1989)</marker>
<rawString>Kurt Konolige and Martha E. Pollack. 1989. &amp;quot;Ascribing Plans To Agents - Preliminary Report - &amp;quot;. Proceedings of the 11th International Joint Conference on Artificial Intelligence. Aug. 20-25. Detroit, Michigan, U.S.A.. 924-930.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johanna D Moore</author>
<author>Cecile Paris</author>
</authors>
<title>Planning Text For Advisory Dialogue&amp;quot;.</title>
<date>1989</date>
<booktitle>Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<location>British Columbia,</location>
<marker>(Moore et a1,1989)</marker>
<rawString>Johanna D. Moore and Cecile Paris. 1989. &amp;quot;Planning Text For Advisory Dialogue&amp;quot;. Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics. Jun. 26-29. Van couver, British Columbia, Canada. 203-211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan A Sag</author>
</authors>
<title>An Information-Based Syntax and Semantics (Volume 1)&amp;quot;. CSLI Lecture Notes.</title>
<date>1987</date>
<journal>Number</journal>
<volume>13</volume>
<marker>(Pollard et al.,1987)</marker>
<rawString>Carl Pollard and Ivan A. Sag. 1987. &amp;quot;An Information-Based Syntax and Semantics (Volume 1)&amp;quot;. CSLI Lecture Notes. Number 13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan A Sag</author>
</authors>
<title>An Information-Based Syntax and Semantics (Volume 2)&amp;quot;. ms.</title>
<date>1990</date>
<marker>(Pollard et al.,1990)</marker>
<rawString>Carl Pollard and Ivan A. Sag. 1990. &amp;quot;An Information-Based Syntax and Semantics (Volume 2)&amp;quot;. ms.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>A Uniform Architecture For Parsing and Generation&amp;quot;.</title>
<date>1988</date>
<booktitle>Proceedings of the 12th International Conference on Computational Linguistics. Aug. 22-27.</booktitle>
<pages>614--619</pages>
<location>Bonn,</location>
<marker>(Shieber,1988)</marker>
<rawString>Stuart M. Shieber. 1988. &amp;quot;A Uniform Architecture For Parsing and Generation&amp;quot;. Proceedings of the 12th International Conference on Computational Linguistics. Aug. 22-27. Bonn, Germany. 614-619.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
<author>Gertjan van Noord</author>
<author>Robert C Moore</author>
<author>Fernando C N Perreira</author>
</authors>
<title>A SemanticHead-Driven Generation Algorithms for Unification-Based Formalisms&amp;quot;.</title>
<date>1989</date>
<booktitle>Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<pages>7--17</pages>
<location>British Columbia,</location>
<marker>(Shieber et al.,1989)</marker>
<rawString>Stuart M. Shieber, Gertjan van Noord, Robert C. Moore, and Fernando C.N. Perreira. 1989. &amp;quot;A SemanticHead-Driven Generation Algorithms for Unification-Based Formalisms&amp;quot;. Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics. Jun. 26-29. Van couver, British Columbia, Canada. 7-17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akira Shimazu</author>
</authors>
<title>Japanese Sentence Analysis as Argumentation&amp;quot;.</title>
<date>1990</date>
<booktitle>Proceedings of the 13th International Conference on Computational Linguistics.</booktitle>
<pages>259--264</pages>
<location>Helsinki,</location>
<marker>(Shimazu,1990)</marker>
<rawString>Akira Shimazu. 1990. &amp;quot;Japanese Sentence Analysis as Argumentation&amp;quot;. Proceedings of the 13th International Conference on Computational Linguistics. Aug. 20-25. Helsinki, Finland. 259-264.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomek Strzalkowski</author>
</authors>
<title>How To Invert A Natural Language Parser Into An Efficient Generator An Algorithm For Logic Grammars&amp;quot;.</title>
<date>1990</date>
<booktitle>Proceedings of the 13th International Conference on Computational Linguistics.</booktitle>
<pages>347--352</pages>
<location>Helsinki,</location>
<marker>(Strzalkowski,1990)</marker>
<rawString>Tomek Strzalkowski. 1990. &amp;quot;How To Invert A Natural Language Parser Into An Efficient Generator An Algorithm For Logic Grammars&amp;quot;. Proceedings of the 13th International Conference on Computational Linguistics. Aug. 20-25. Helsinki, Finland. 347-352.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
</authors>
<title>Semantics and Quantification in Natural Language Question Answering&amp;quot;.</title>
<date>1978</date>
<journal>Advances in Computers.</journal>
<volume>17</volume>
<editor>M.Yovits (ed.).</editor>
<publisher>Academic Press.</publisher>
<marker>(Woods,1978)</marker>
<rawString>W.A.Woods. 1978. &amp;quot;Semantics and Quantification in Natural Language Question Answering&amp;quot;. Advances in Computers. Vol. 17. M.Yovits (ed.). Academic Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>