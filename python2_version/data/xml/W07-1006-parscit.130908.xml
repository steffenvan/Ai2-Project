<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001518">
<title confidence="0.99138">
Combining Multiple Evidence for Gene Symbol Disambiguation
</title>
<author confidence="0.998685">
Hua Xu
</author>
<affiliation confidence="0.9953255">
Dept. of Biomedical Informatics,
Columbia University
</affiliation>
<address confidence="0.490429">
622 W 168th St. NY, USA
</address>
<email confidence="0.985354">
hux7002@dbmi.columbia.edu
</email>
<author confidence="0.988076">
Jung-Wei Fan
</author>
<affiliation confidence="0.9762">
Dept. of Biomedical Infor-
matics, Columbia University
</affiliation>
<address confidence="0.50639">
622 W 168th St. NY, USA
</address>
<email confidence="0.992855">
fan@dbmi.columbia.edu
</email>
<author confidence="0.993463">
Carol Friedman
</author>
<affiliation confidence="0.9951065">
Dept. of Biomedical Informatics,
Columbia University
</affiliation>
<address confidence="0.49221">
622 W 168th St. NY, USA
</address>
<email confidence="0.990698">
friedman@dbmi.columbia.edu
</email>
<sectionHeader confidence="0.995457" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999905666666667">
Gene names and symbols are important
biomedical entities, but are highly
ambiguous. This ambiguity affects the
performance of both information extraction
and information retrieval systems in the
biomedical domain. Existing knowledge
sources contain different types of
information about genes and could be used
to disambiguate gene symbols. In this
paper, we applied an information retrieval
(IR) based method for human gene symbol
disambiguation and studied different
methods to combine various types of
information from available knowledge
sources. Results showed that a combination
of evidence usually improved performance.
The combination method using coefficients
obtained from a logistic regression model
reached the highest precision of 92.2% on a
testing set of ambiguous human gene
symbols.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999912104166667">
In the past decade, biomedical discoveries and
publications have increased exponentially due to
high-throughput technologies such as automated
genomic sequencing, and therefore, it is impossible
for researchers to keep up-to-date with the most
recent knowledge by manually reading the litera-
ture. Therefore, automated text mining tools, such
as information retrieval and information extraction
systems, have received great amounts of interest
(Erhardt et al., 2006; Krallinger and Valencia,
2005). Biomedical entity recognition is a first cru-
cial step for text mining tools in this domain, but is
a very challenging task, partially due to the ambi-
guity (one name referring to different entities) of
names in the biomedical field.
Genes are among the most important biological
entities for understanding biological functions and
processes, but gene names and symbols are highly
ambiguous. Chen et al. (2005) obtained gene in-
formation from 21 organisms and found that ambi-
guities within species, across species, with English
words and with medical terms were 5.02%,
13.43%, 1.10%, 2.99%, respectively, when both
official gene symbols and aliases were considered.
When mining MEDLINE abstracts, they found that
85.1% of mouse genes in the articles were am-
biguous with other gene names. Recently, Fundel
and Zimmer (2006) studied gene/protein nomen-
clature in 5 public databases. Their results showed
that the ambiguity problem was not trivial. The
degree of ambiguity also varied among different
organisms. Unlike other abbreviations in the litera-
ture, which usually are accompanied by their cor-
responding long forms, many gene symbols occur
alone without any mention of their long forms. Ac-
cording to Schuemie et al. (2004), only 30% of
gene symbols in abstracts and 18% in full text
were accompanied by their corresponding full
names, which makes the task of gene symbol nor-
malization much harder.
Gene symbol disambiguation (GSD) is a par-
ticular case of word sense disambiguation (WSD),
which has been extensively studied in the domain
of general English. One type of method for WSD
uses established knowledge bases, such as a ma-
chine readable dictionary (Lesk, 1986; Harley and
Glennon, 1997). Another type of WSD method
uses supervised machine learning (ML) technolo-
</bodyText>
<page confidence="0.993833">
41
</page>
<note confidence="0.81532925">
BioNLP 2007: Biological, translational, and clinical language processing, pages 41–48,
Prague, June 2007. c�2007 Association for Computational Linguistics
gies (Bruce and Wiebe, 1994; Lee and Ng, 2002;
Liu et al., 2002).
</note>
<bodyText confidence="0.9999202">
In the biomedical domain, there are many gene
related knowledge sources, such as Entrez Gene
(Maglott et al., 2005), developed at NCBI (Na-
tional Center for Biotechnology Information),
which have been used for gene symbol disam-
biguation. Podowski et al. (2004) used MEDLINE
references in the LocusLink and SwissProt data-
bases to build Bayesian classifiers for GSD. A
validation on MEDLINE documents for a set of 66
human genes showed most accuracies were greater
than 90% if there was enough training data (more
than 20 abstracts for each gene sense).
More recently, information retrieval (IR) based
approaches have been applied to resolve gene am-
biguity using existing knowledge sources. Typi-
cally, a profile vector for each gene sense is built
from available knowledge source(s) and a context
vector is derived from the context where the am-
biguous gene occurs. Then similarities between the
context vector and candidate gene profile vectors
are calculated, and the gene corresponding to the
gene profile vector that has the highest similarity
score to the context vector is selected as the correct
sense. Schijvenaars et al. (2005) reported on an IR-
based method for human GSD. It utilized informa-
tion from either Online Mendelian Inheritance in
Man (OMIM) annotation or MEDLINE abstracts.
The system achieved an accuracy rate of 92.7% on
an automatically generated testing set when five
abstracts were used for the gene profile. Xu et al.
(2007) studied the performance of an IR-based ap-
proach for GSD for mouse, fly and yeast organ-
isms when different types of information from dif-
ferent knowledge sources were used. They also
used a simple method to combine different types of
information and reported that a highest precision of
93.9% was reached for a testing set of mouse genes
using multiple types of information.
In the field of IR, it has been shown that com-
bining heterogeneous evidence improves retrieval
effectiveness. Studies on combining multiple rep-
resentations of document content (Katzer et al.,
1982), combining results from different queries
(Xu and Croft, 1996), different ranking algorithms
(Lee, 1995), and different search systems (Lee,
1997) have shown improved performance of re-
trieval systems. Different methods have also been
developed to combine different evidence for IR
tasks. The inference-network-based framework,
developed by Turtle and Croft (1991), was able to
combine different document representations and
retrieval algorithms into an overall estimate of the
probability of relevance. Fox et al. (1988) extended
the vector space model to use sub-vectors to de-
scribe different representations derived from
documents. An overall similarity between a docu-
ment and a query is defined as a weighted linear
combination of similarities of sub-vectors. A linear
regression analysis was used to determine the
value of the coefficients.
Though previous related efforts (Schijvenaars et
al., 2005, Xu et al., 2007) have explored the use of
multiple types of information from different
knowledge sources, none have focused on devel-
opment of formal methods for combining multiple
evidence for the GSD problem to optimize per-
formance of an IR-based method. In this study, we
adapted various IR-based combination models spe-
cifically for the GSD problem. Our motivation for
this work is that there are diverse knowledge
sources containing different types of information
about genes, and the amount of such information is
continuously increasing. A primary source contain-
ing gene information is MEDLINE articles, which
could be linked to specific genes through annota-
tion databases. For example, Entrez Gene contains
an annotated file called “gene2pubmed”, which
lists the PMIDs (PubMed ID) of articles associated
with a particular gene. From related MEDLINE
articles, words and different ontological concepts
can be obtained and then be used as information
associated with a gene. However they could be
noisy, because one article could mention multiple
genes. Another type of source contains summa-
rized annotation of genes, which are more specific
to certain aspects of genes. For example, Entrez
Gene contains a file called “gene2go”. This file
lists genes and their associated Gene Ontology
(GO) (Ashburner et al., 2000) codes, which include
concepts related to biological processes, molecular
functions, and cellular components of genes.
Therefore, methods that are able to efficiently
combine the different types of information from
the different sources are important to explore for
the purpose of improving performance of GSD
systems. In this paper, we describe various models
for combining different types of information from
MEDLINE abstracts for IR-based GSD systems.
We also evaluated the combination models using
two data sets containing ambiguous human genes.
</bodyText>
<page confidence="0.999228">
42
</page>
<figureCaption confidence="0.806094">
Figure 1 Overview of an IR combination-based gene symbol disambiguation approach using different
types of information.
</figureCaption>
<sectionHeader confidence="0.982606" genericHeader="introduction">
2 Methods
</sectionHeader>
<bodyText confidence="0.999985785714286">
In this paper, we extend the IR vector space model
to be capable of combining different types of gene
related information in a flexible manner, thus im-
proving the performance of an IR-based GSD sys-
tem. Figure 1 shows an overview of the IR combi-
nation-based approach. We generated three differ-
ent sub-vectors for the context and three for the
profile, so that each sub-vector corresponded to a
different type of information. The similarity scores
between context and profile were measured for
each type of sub-vector and then combined to gen-
erate the overall similarity scores to determine the
correct sense. We explored five different combina-
tion methods using two testing sets.
</bodyText>
<subsectionHeader confidence="0.8513115">
2.1 Knowledge Sources and Available Infor-
mation
</subsectionHeader>
<bodyText confidence="0.99994">
The “gene2pubmed” file in Entrez Gene was
downloaded in January 2006. A profile was then
built for each gene using information derived from
the related articles. We used the following three
types of information: 1) Words in the related
MEDLINE articles (title and abstract). This is the
simplest type of information about a gene. General
English stop words were removed and all other
words were stemmed using the Porter stemming
algorithm (Porter, 1980). 2) UMLS (Unified
Medical Language System) (Bodenreider 2004)
CUIs (Concept Unique Identifier), which were
obtained from titles and abstracts of MEDLINE
articles using an NLP system called MetaMap
(Aronson 2001). 3) MeSH (Medical Subject
Headings) terms, which are manually annotated by
curators based on full-text articles at the National
Library of Medicine (NLM) of the United States.
</bodyText>
<subsectionHeader confidence="0.999798">
2.2 Document Set and Testing Sets
</subsectionHeader>
<bodyText confidence="0.998940742857143">
Using the “gene2pubmed” file, we downloaded the
MEDLINE abstracts that were known to be related
to human genes. Articles associated with more than
25 genes (as determined by our observation) were
excluded, since they mostly discussed high-
throughput technologies and provided less valuable
information for GSD. This excluded 168 articles
and yielded a collection of 116,929 abstracts,
which were used to generate gene profiles and one
of the test sets. Two test sets were obtained for
evaluating the combination methods: testing set 1
was based on the “gene2pubmed” file, and testing
set 2 was based on the BioCreAtIvE II evaluation.
Testing set 1 was automatically generated from
the 116,929 abstracts, using the following 3 steps:
1) Identifying ambiguous gene symbols in the
abstracts. This involved processing the entire col-
lection of abstracts using an NLP system called
BioMedLEE (Biomedical Language Extracting and
Encoding System) (Lussier et al. 2006), which was
shown to identify gene names/symbols with high
precision when used in conjunction with GO anno-
tations. When an ambiguous gene was identified in
an article, the candidate gene identifiers (GeneID
from Entrez Gene) were listed by the NLP system,
but not disambiguated. For each ambiguous gene
that was detected, a pair was created consisting of
the PMID of the article and the gene symbol, so
that each pair would be considered a possible test-
ing sample. Repeated gene symbols in the same
article were ignored, because we assumed only one
sense per gene symbol in the same article. Using
this method, 69,111 PMID and ambiguous human
gene symbol pairs were identified from the above
collection of abstracts.
</bodyText>
<page confidence="0.997754">
43
</page>
<listItem confidence="0.572260666666667">
2) Tagging the correct sense of the ambiguous
gene symbols. The list of candidate PMID/gene
symbol pairs generated from the articles was then
compared with the list of gene identifiers known to
be associated with the articles based on
“gene2pubmed”. If one of the candidate gene
senses matched, that gene sense was assumed to be
the correct sense. Then the PMID/gene-symbol
pair was tagged with that sense and set aside as a
testing sample. We identified a pool of 12,289 test-
ing samples, along with the corresponding tagged
senses.
3) Selecting testing set 1. We randomly selected
2,000 testing samples from the above pool to form
testing set 1.
</listItem>
<bodyText confidence="0.9999436875">
Testing set 2 was derived using the training and
evaluation sets of the BioCreAtIvE II Gene Nor-
malization (GN) task (Morgan 2007). The Bio-
CreAtIvE II GN task involved mapping human
gene mentions in MEDLINE abstracts to gene
identifiers (Entrez Gene ID), which is a broader
task than the GSD task. However, these abstracts
were useful for creating a testing set for GSD, be-
cause whenever a gene mention mapped to more
than one identifier, disambiguation was required.
Therefore, it was possible to derive a list of am-
biguous gene symbols based on data that was pro-
vided by BioCreAtIvE. We combined both manu-
ally annotated training (281 abstracts) and evalua-
tion (262 abstracts) sets provided by BioCreAtIvE.
Using the same process as described in step 1 of
testing set 1, we processed the abstracts and identi-
fied 217 occurrences of ambiguous gene symbols
from the combined set. Following a similar proce-
dure as was used for step 2 in the testing set 1 (ex-
cept that the reference standard in this case was the
manually annotated results obtained from Bio-
CreAtIvE instead of “gene2pubmed”), we obtained
124 PMID/gene-symbol pairs with the correspond-
ing tagged senses, which formed testing set 2.
Because one article may contain multiple am-
biguous gene symbols, a total of 2,048 PMIDs
were obtained from both testing sets 1 and 2. Arti-
cles with those PMIDs were excluded from the
collection of 116,929 abstracts. We used the re-
maining document set to generate gene profiles,
which were used for both testing sets.
</bodyText>
<subsectionHeader confidence="0.994962">
2.3 Profile and Context Vectors
</subsectionHeader>
<bodyText confidence="0.998834277777778">
For each gene in “gene2pubmed” file, we created a
profile. It consisted of three sub-vectors containing
word, CUI, or McSH, respectively, using the in-
formation derived from the related MEDLINE ab-
stracts. Similarly, a context vector was also formed
for each testing sample, using three sub-vectors
containing word, CUI, or McSH, which were de-
rived from the abstract whose PMID was stated in
the testing sample. The tf-idf weighting schema
(Salton and Buckley, 1988) was used to assign
weights to index terms in the profile and context
sub-vectors. Given a document d, the Term Fre-
quency (tf) of term t is defined as the frequency of
t occurring in d. The Inverse Document Frequency
(idf) of term t is defined as the logarithm of the
number of all documents in the collection divided
by the number of documents containing the term t.
Then term t in document d is weighted as tf*idf.
</bodyText>
<subsectionHeader confidence="0.973504">
2.4 Similarity Measurement
</subsectionHeader>
<bodyText confidence="0.9999">
The similarity score between the same type of con-
text and profile sub-vectors were measured as co-
sine similarity of two vectors. The cosine similarity
between two vectors a and b is defined as the inner
product of a and b, normalized by the length of
two vectors. See the formula below:
</bodyText>
<equation confidence="0.955892">
a⋅b
Sim(a,b) = cosine ө =
2a= a1 +az +...+a,2, b = b12+bz + ... +bn
</equation>
<bodyText confidence="0.999951428571429">
We built three basic classifiers that used only
one type of sub-vector: word, CUI, or McSH, re-
spectively, recorded three individual similarity
scores of each sub-vector for each candidate gene
of all testing samples. We implemented five meth-
ods to combine similarity scores from each basic
classifier, which are described as follows:
</bodyText>
<listItem confidence="0.984270466666667">
1) CombMax - Each individual similarity score
from a basic classifier was normalized by di-
viding the sum of similarity scores of all
candidate genes for that basic classifier.
Then the decision made by the classifier with
the highest normalized score was selected as
the final decision of the combined method.
2) CombSum - Each individual similarity score
from a basic classifier was normalized by di-
viding the maximum similarity score of all
candidate genes for that basic classifier. The
overall similarity score of a candidate gene
was considered to be the sum of the normal-
ized similarity scores from all three basic
classifiers for that gene. The candidate gene
</listItem>
<bodyText confidence="0.724288">
ab
where
</bodyText>
<page confidence="0.97181">
44
</page>
<bodyText confidence="0.9981535">
with the highest overall similarity was se-
lected as the correct sense.
</bodyText>
<listItem confidence="0.9498015">
3) CombSumVote - The overall similarity score
was considered as the similarity score from
CombSum, multiplied by the number of basic
classifiers that voted for that gene as the cor-
rect sense.
4) CombLR - The overall similarity score was
defined as a predicted probability (P) of be-
ing the correct sense, given the coefficients
obtained from a logistic regression model
and similarity scores from all three basic
classifiers for that gene. The relation be-
tween dependent variable (probability of be-
ing the correct sense) and independent vari-
ables (similarity scores from individual basic
classifiers) of the logistic regression model is
shown below, where Cs (Cword, Ccui, Cmesh and
</listItem>
<bodyText confidence="0.955819451612903">
C) are the coefficients, and SIMs (SIMword,
SIMcui, SIMmesh) are the individual similarity
scores from the basic classifiers. To obtain
the model, we divided 2,000 testing samples
into a training set and a testing set, as de-
scribed in section 2.5. For samples in the
training set, the correct gene senses were la-
beled as “1” and incorrect gene senses were
labeled as “0”. Then logistic regression was
applied, taking the binary labels as the value
of the dependent variable and the similarities
from the basic classifiers as the independent
variables. In testing, coefficients obtained
from training were used to predict each can-
didate gene’s probability of being the correct
sense for a given ambiguous symbol.
5) CombRank – Instead of using the similarity
scores, we ranked the similarity scores and
used the rank to determine the combined
output. Following a procedure called Borda
count (Black, 1958), the top predicted gene
sense was given a ranking score of N-1, the
second top was given N-2, and so on, where
N is the total number of candidate senses.
After each sense was ranked for each basic
classifier, the combined ranking score of a
candidate gene was determined by the sum
of ranking scores from all three basic classi-
fiers. The sense with the highest combined
ranking score was selected as the correct
sense.
</bodyText>
<subsectionHeader confidence="0.941876">
2.5 Experiments and Evaluation
</subsectionHeader>
<bodyText confidence="0.999993652173913">
In this study, we measured both precision and cov-
erage of IR-based GSD approaches. Precision was
defined as the ratio between the number of cor-
rectly disambiguated samples and the number of
total testing samples for which the disambiguation
method yielded a decision. When a candidate gene
had an empty profile or different candidate gene
profiles had the same similarity scores (e.g. zero
score) with a particular context vector, the disam-
biguation method was not able to make a decision.
Therefore, we also reported on coverage, which
was defined as the number of testing samples that
could be disambiguated using the profile-based
method over the total number of testing samples.
We evaluated precision and coverage of different
combined methods for gene symbol disambigua-
tion on both testing sets.
Results of three basic classifiers that used a sin-
gle type of information were reported as well. We
also defined a baseline method. It used the major-
ity sense of an ambiguous gene symbol as the cor-
rect sense. The majority sense is defined as the
gene sense which was associated with the most
MEDLINE articles based on the “gene2pubmed”
file.
To evaluate the CombLR, we used 10-fold cross
validation. We divided the sense-tagged testing set
into 10 equal partitions, which resulted in 200 test-
ing samples for each partition. When one partition
was used for testing, the remaining nine partitions
were combined and used for training, which also
involved deriving coefficients for each round. To
make other combination methods comparable with
CombLR, we tested the performance of other com-
bination methods on the same partitions as well.
Therefore, we had 10 measurements for each com-
bination method. Mean precision and mean cover-
age were reported for those 10 measurements. For
testing set 2, we did not test the CombLR method
because the set was too small to train a regression
model.
We used Friedman’s Test (Friedman, 1937) fol-
lowed by Dunn’s Test (Dunn, 1964), which are
non-parametric tests, to assess whether there were
significant differences in terms of median precision
among the different single or combined methods.
</bodyText>
<figure confidence="0.722785363636364">
e
Cword SIMword Ccui
&amp;quot; +
+Cmesh&amp;quot;SIMmesh+C
&amp;quot; SIMcui
P
Cword&amp;quot;SIMword+Ccui
+Cmesh SIMmesh C
&amp;quot; +
&amp;quot; SIMcui
1+e
</figure>
<page confidence="0.997657">
45
</page>
<sectionHeader confidence="0.999881" genericHeader="method">
3 Results
</sectionHeader>
<bodyText confidence="0.9996259375">
Results of different combination methods for test-
ing set 1 are shown in Table 1, which contains the
mean precision and coverage for 10-fold cross
validation, as well as the standard errors in paren-
theses. All IR-based gene symbol disambiguation
approaches showed large improvements when
compared to the baseline method. All of the com-
bination methods showed improved performance
when compared to results from any run that used a
single type of information. Among the five differ-
ent combination methods, CombLR achieved the
highest mean precision of 0.922 for testing set 1.
CombSum, which is a simple combination method,
also had a good mean precision of 0.920 on testing
set 1. The third Column of Table 1 shows that cov-
erage was in a range of 0.936-0.938.
</bodyText>
<table confidence="0.9997813">
Run Precision Coverage
Baseline 0.707 (0.032) 0.992 (0.005)
Word 0.882 (0.023) 0.937 (0.017)
CUI 0.887 (0.022) 0.938 (0.017)
MeSH 0.900 (0.021) 0.936 (0.017)
CombMax 0.909 (0.020) 0.938 (0.017)
CombSum 0.920 (0.019) 0.937 (0.017)
CombSumVote 0.917(0.019) 0.938 (0.017)
CombLR 0.922 (0.019) 0.938 (0.017)
CombRank 0.918 (0.020) 0.938 (0.017)
</table>
<tableCaption confidence="0.999805">
Table 1. Results on testing set 1.
</tableCaption>
<table confidence="0.999957777777778">
Run Precision Coverage
Baseline 0.593 0.991
Word 0.872 0.944
CUI 0.897 0.944
MeSH 0.863 0.944
CombMax 0.906 0.944
CombSum 0.906 0.944
CombSumVote 0.897 0.944
CombRank 0.889 0.944
</table>
<tableCaption confidence="0.999933">
Table 2. Results on testing set 2.
</tableCaption>
<bodyText confidence="0.9998746">
We performed Friedman’s test followed by
Dunn’s test on each single run: word, CUI or
MeSH, with all combination runs respectively.
Friedman tests showed that differences of median
precisions among the different methods were sta-
tistically significant at α=0.05. Dunn tests showed
that combination runs CombSum, CombSumVote,
CombLR, and CombRank were statistically signifi-
cantly better than single runs using word or CUI.
For single run using MeSH, combination runs
CombLR and CombSum were statistically signifi-
cantly better.
The results of different runs on testing set 2 are
shown in Table 2. Most combined methods, except
CombRank, showed improved precision. The high-
est precision of 0.906 was reached when using
CombSum and CombMax methods. Note that the
logistic regression method was not applicable. The
coverage for testing set 2 was 0.944 for all of the
methods.
</bodyText>
<sectionHeader confidence="0.999828" genericHeader="method">
4 Discussion
</sectionHeader>
<subsectionHeader confidence="0.999565">
4.1 Why Combine?
</subsectionHeader>
<bodyText confidence="0.999954757575757">
As stated in Croft (2002), a Bayesian probabilistic
framework could provide the theoretical justifica-
tion for evidence combination. Additional evidence
with smaller errors can reduce the effect of large
errors from one piece of evidence and lower the
average error.
The idea behind CombMax was to use the single
classifier that had the most confidence, but it did
not seem to improve performance very much be-
cause it ignored evidence from the other two basic
classifiers. The CombSum was a simple combina-
tion method, but with reasonable performance,
which was also observed by other studies for the
IR task (Fox and Shaw, 1994). CombSumVote was
a variant of CombSum. It favors the candidate
genes selected by more basic classifiers. In Lee
(1997), a similar implementation of CombSumVote
(named “CombMNZ”) also achieved better per-
formance in the IR task. CombLR, the combination
method trained on a logistic regression model,
achieved the best performance in this study. It used
a set of coefficients derived from the training data
when combining the similarities from individual
basic classifiers. Therefore, it could be considered
as a more complicated linear combination model
than CombSum. In situations where training data is
not available, CombSum or CombSumVote would
be a good choice. CombRank did not perform as
well as methods that used similarity scores, proba-
bly due to the loss of subtle probability information
in the similarity scores. We explored ranking be-
cause it was independent of the weighting schema
and could be valuable if it performed well.
</bodyText>
<page confidence="0.998455">
46
</page>
<bodyText confidence="0.999991676470588">
The typical scenario where combination should
help is when a classifier based on one type of in-
formation made a wrong prediction, but the
other(s), based on different types of information,
made the correct predictions. In those cases, the
overall prediction may be correct when an appro-
priate combination method applies. For example,
an ambiguous gene symbol PDK1 (in the article
with PMID 10856237), which has two possible
gene senses (‘GeneID:5163 pyruvate dehydro-
genase kinase, isoenzyme 1’ and ‘GeneID:5170 3-
phosphoinositide dependent protein kinase-1’),
was incorrectly predicted as ‘GeneID: 5163’ when
only “word” was used. But the classifiers using
“CUI” and “MeSH” predicted it correctly. When
the CombSum method was used to combine the
similarity scores from all three classifiers, the cor-
rect sense ‘GeneID: 5170’ was selected. When all
three classifiers were incorrect in predicting a test-
ing sample, generally none of the combination
methods would help in making the final decision
correct. Therefore, there is an upper bound on the
performance of the combined system. In our case,
we detected that all three classifiers made incorrect
predictions for 65 testing samples of the 2,000
samples. Therefore, the upper bound would be
1,935/2,000=96.7%.
The methods for combining different types of
information from biomedical knowledge sources
described in this study, though targeted to the GSD
problem, could be also applicable to other text
mining tasks that are based on similarity measure-
ment, such as text categorization, clustering, and
the IR task in the biomedical domain.
</bodyText>
<subsectionHeader confidence="0.998579">
4.2 Coverage of the Methods
</subsectionHeader>
<bodyText confidence="0.999990608695652">
The IR-based gene symbol disambiguation method
described in this paper aims to resolve intra-
species gene ambiguity. We focused on ambiguous
gene symbols within the human species and used
articles known to be associated with human genes.
Fundel and Zimmer (2006) reported that the degree
of ambiguity of the human gene symbols from En-
trez Gene was 3.16%–3.32%, which is substantial.
However, this is only part of the gene ambiguity
problem.
Based on the “gene_info” file downloaded in
January 2006 from Entrez Gene, there were a total
of 32,852 human genes. Based on the
“gene2pubmed” file, 24,170 (73.4%) out of 32,852
human genes have at least one associated MED-
LINE article, which indicates that profiles could be
generated for at least 73.4% of human genes. On
average, there are 9.02 MEDLINE articles associ-
ated with a particular human gene. Coverage re-
ported in this study was relatively high because the
testing samples were selected from annotated arti-
cles as listed in “gene2pubmed”, and not randomly
from the collection of all MEDLINE abstracts.
</bodyText>
<subsectionHeader confidence="0.99405">
4.3 Evaluation Issues
</subsectionHeader>
<bodyText confidence="0.9999951">
It would be interesting to compare our work with
other related work, but that would require use of
the same testing set. For example, it is not straight-
forward to compare our precision result (92.2%)
with that (92.7%) reported by Schijvenaars et al.
(2005), because they used a testing set that was
generated by removing ambiguous genes with less
than 6 associated articles for each of their senses,
and they did not report on coverage. The data set
from the BioCreAtIvE II GN task therefore is a
valuable testing set that enables evaluation and
comparison of other gene symbol disambiguation
methods. From the BioCreAtIvE abstracts, we
identified 217 occurrences of ambiguous gene
symbols, but only 124 were annotated in the Bio-
CreAtIvE data set. There are a few possible expla-
nations for this. First, the version of the Entrez
Gene database used by the NLP system was not the
most recent one, so some new genes were not
listed as possible candidate senses. The second is-
sue is related to gene families or genes/proteins
with multiple sub-units. According to the
‘gene_info’ file, the gene symbol “IL-1” is a syno-
nym for both “GeneID: 3552 interleukin 1, alpha”
and “GeneID: 3553 interleukin 1, beta”. Therefore,
the NLP system identified it as an ambiguous gene
symbol. When annotators in the BioCreAtIvE II
task saw a gene family name that was not clearly
mapped to a specific gene identifier in Entrez
Gene, they may not have added it to the mapped
list. In Morgan et al. (2007), it was suggested that
mapping gene family mentions might be appropri-
ate for those entities. Testing set 2 was a small set
and results from that set might not be statistically
meaningful, but it is useful for comparing with
others working on the same data set.
In this paper, we focused on the study of im-
provements in precision of the gene symbol dis-
ambiguation system. When combining information
from different knowledge sources, coverage may
</bodyText>
<page confidence="0.997702">
47
</page>
<bodyText confidence="0.9967585">
also be increased by benefiting from the cross-
coverage of different knowledge sources.
</bodyText>
<sectionHeader confidence="0.976809" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999985260869565">
We applied an IR-based approach for human gene
symbol disambiguation, focusing on a study of
different methods for combining various types of
information from available knowledge sources.
Results showed that combination of multiple
evidence usually improved the performance of
gene symbol disambiguation. The combination
method using coefficients obtained from a logistic
regression model reached the highest precision of
92.2% on an automatically generated testing set of
ambiguous human gene symbols. On a testing set
derived from BioCreAtIvE II GN task, the combi-
nation method that performed summation of indi-
vidual similarities reached the highest precision of
90.6%. However, the regression-based method
could not be used, because the testing sample was
small.
In the future, we will add information that is
specifically related to genes, such as GO codes,
into the combination model. Meanwhile, we will
also study the performance gain in terms of
coverage by integrating different knowledge
sources.
</bodyText>
<sectionHeader confidence="0.996004" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999971">
This work was supported in part by Grants R01
LM7659 and R01 LM8635 from the National Li-
brary of Medicine, and Grant NSF-IIS-0430743
from the National Science Foundation. We would
like to thank Alexander Morgan for providing the
evaluation set from the BioCreAtIvE II GN task.
</bodyText>
<sectionHeader confidence="0.99915" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999555104477612">
Aronson, A. R. 2001. Proc. AMIA. Symp., 17-21.
Ashburner, M. et al. 2000. Nat Genet, 25, 25-29.
Black, D. 1958. Cambridge University Press.
Bodenreider, O. 2004. Nucleic Acids Research, 2004,
32, D267-D270.
Bruce, R. and Wiebe, J. 1994. Proceedings of ACL
1994, 139-146.
Chen, L., Liu, H. and Friedman, C. 2005. Bioinformat-
ics, 21, 248-256.
Croft, W. 2002. Advances in Information Retrieval.
Springer Netherlands, Chapter 1, 1-36
Dunn, O. J. 1964. Technometrics, 6, 241-252.
Erhardt, R.A., Schneider, R. and Blaschke, C. 2006.
Drug Discov. Today, 11, 315-325.
Fox, E., Nunn, G., and Lee, W. 1988. Proceedings of
the 11th ACM SIGIR Conference on Research and
Development in Information Retrieval, 291–308.
Fox, E. and Shaw, J. 1994. Proceedings TREC-2, 243–
252.
Friedman, M. 1937. Journal of the American Statistical
Association, 32, 675-701.
Fundel, K. and Zimmer, R. 2006. BMC. Bioinformatics.,
7: 372.
Harley, A. and Glennon, D. 1997. Proc. SIGLEX Work-
shop &amp;quot;Tagging Text With Lexical Semantics&amp;quot;, 74-78.
Katzer, J., McGill, M., Tessier, J., Frakes,W., and
DasGupta, P. 1998. Information Technology: Re-
search and Development, 1(4):261–274.
Krallinger, M. and Valencia, A. 2005. Genome Biol., 6,
224.
Lee, J. 1995. Proceedings of the 18th ACMSIGIR Con-
ference on Research and Development in Information
Retrieval, 180–188.
Lee, J. 1997. Proceedings of the 20th ACM SIGIR Con-
ference on Research and Development in Information
Retrieval, 267–276.
Lee, Y. K. and Ng, H. T. 2002. Proc EMNLP 2002, 41-
48.
Lesk, M. 1986. 1986 SIGDOC Conference, 24-26.
Liu, H., Johnson, S. B. and Friedman, C. 2002. J. Am.
Med. Inform. Assoc., 9, 621-636.
Lussier, Y., Borlawsky, T., Rappaport, D., Liu, Y.,
Friedman, C. 2006. Pac. Symp. Biocomput., 11, 64-
75.
Maglott D, Ostell J, Pruitt KD, Tatusova T. 2005. Nu-
cleic Acids Res., 3, D54-D58.
Morgan, A., Wellner, B., Colombe, J. B., Arens, R.,
Colosimo, M. E., Hirschman L. 2007. Pacific Sym-
posium on Biocomputing 12:281-291.
Podowski, R.M., Cleary, J.G., Goncharoff, N.T.,
Amoutzias, G., Hayes W.S. 2004. Proc IEEE Com-
put Syst Bioinform Conf, 2004, 415-24.
Porter,M.F. 1980. Program, 14, 130-137.
Salton, G. and Buckley, C. 1988. Information
Processing &amp; Management, 24, 513-523.
Schijvenaars, B.JA. et al. 2005. BMC. Bioinformatics.,
6:149.
Schuemie, M.J. et al. 2004. Bioinformatics, 20, 2597-
2604.
Turtle, H. and Croft, W. 1991. ACM Transactions on
Information Systems, 9(3):187–222.
Xu, H., Fan, J. W., Hripcsak, G., Mendonça A. E., Mar-
katou, M., Friedman, C. 2007. Bioinformatics, doi:
10.1093/bioinformatics/btm056
Xu, J. and Croft,W. 1996. Proceedings of the 19th ACM
SIGIR Conference on Research and Development in
Information Retrieval, pages 4–11.
</reference>
<page confidence="0.999353">
48
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.137653">
<title confidence="0.999753">Combining Multiple Evidence for Gene Symbol Disambiguation</title>
<author confidence="0.979341">Hua</author>
<affiliation confidence="0.862938333333333">Dept. of Biomedical Columbia W St. NY,</affiliation>
<email confidence="0.996694">hux7002@dbmi.columbia.edu</email>
<author confidence="0.891354">Jung-Wei</author>
<affiliation confidence="0.97441">of Biomedical</affiliation>
<address confidence="0.758467">matics, Columbia</address>
<affiliation confidence="0.67798">W St. NY,</affiliation>
<email confidence="0.998851">fan@dbmi.columbia.edu</email>
<author confidence="0.8218">Carol</author>
<affiliation confidence="0.822874666666667">Dept. of Biomedical Columbia W St. NY,</affiliation>
<email confidence="0.99987">friedman@dbmi.columbia.edu</email>
<abstract confidence="0.996831954545455">Gene names and symbols are important biomedical entities, but are highly ambiguous. This ambiguity affects the performance of both information extraction and information retrieval systems in the biomedical domain. Existing knowledge sources contain different types of information about genes and could be used to disambiguate gene symbols. In this paper, we applied an information retrieval (IR) based method for human gene symbol disambiguation and studied different methods to combine various types of information from available knowledge sources. Results showed that a combination of evidence usually improved performance. The combination method using coefficients obtained from a logistic regression model reached the highest precision of 92.2% on a testing set of ambiguous human gene symbols.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A R Aronson</author>
</authors>
<date>2001</date>
<journal>Nat Genet,</journal>
<booktitle>Proc. AMIA. Symp.,</booktitle>
<volume>25</volume>
<pages>17--21</pages>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="10030" citStr="Aronson 2001" startWordPosition="1531" endWordPosition="1532"> in January 2006. A profile was then built for each gene using information derived from the related articles. We used the following three types of information: 1) Words in the related MEDLINE articles (title and abstract). This is the simplest type of information about a gene. General English stop words were removed and all other words were stemmed using the Porter stemming algorithm (Porter, 1980). 2) UMLS (Unified Medical Language System) (Bodenreider 2004) CUIs (Concept Unique Identifier), which were obtained from titles and abstracts of MEDLINE articles using an NLP system called MetaMap (Aronson 2001). 3) MeSH (Medical Subject Headings) terms, which are manually annotated by curators based on full-text articles at the National Library of Medicine (NLM) of the United States. 2.2 Document Set and Testing Sets Using the “gene2pubmed” file, we downloaded the MEDLINE abstracts that were known to be related to human genes. Articles associated with more than 25 genes (as determined by our observation) were excluded, since they mostly discussed highthroughput technologies and provided less valuable information for GSD. This excluded 168 articles and yielded a collection of 116,929 abstracts, which</context>
</contexts>
<marker>Aronson, 2001</marker>
<rawString>Aronson, A. R. 2001. Proc. AMIA. Symp., 17-21. Ashburner, M. et al. 2000. Nat Genet, 25, 25-29. Black, D. 1958. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Bodenreider</author>
</authors>
<date>2004</date>
<journal>Nucleic Acids Research,</journal>
<pages>32--267</pages>
<contexts>
<context position="9880" citStr="Bodenreider 2004" startWordPosition="1509" endWordPosition="1510">different combination methods using two testing sets. 2.1 Knowledge Sources and Available Information The “gene2pubmed” file in Entrez Gene was downloaded in January 2006. A profile was then built for each gene using information derived from the related articles. We used the following three types of information: 1) Words in the related MEDLINE articles (title and abstract). This is the simplest type of information about a gene. General English stop words were removed and all other words were stemmed using the Porter stemming algorithm (Porter, 1980). 2) UMLS (Unified Medical Language System) (Bodenreider 2004) CUIs (Concept Unique Identifier), which were obtained from titles and abstracts of MEDLINE articles using an NLP system called MetaMap (Aronson 2001). 3) MeSH (Medical Subject Headings) terms, which are manually annotated by curators based on full-text articles at the National Library of Medicine (NLM) of the United States. 2.2 Document Set and Testing Sets Using the “gene2pubmed” file, we downloaded the MEDLINE abstracts that were known to be related to human genes. Articles associated with more than 25 genes (as determined by our observation) were excluded, since they mostly discussed hight</context>
</contexts>
<marker>Bodenreider, 2004</marker>
<rawString>Bodenreider, O. 2004. Nucleic Acids Research, 2004, 32, D267-D270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bruce</author>
<author>J Wiebe</author>
</authors>
<date>1994</date>
<booktitle>Proceedings of ACL</booktitle>
<pages>139--146</pages>
<contexts>
<context position="3675" citStr="Bruce and Wiebe, 1994" startWordPosition="539" endWordPosition="542">, which makes the task of gene symbol normalization much harder. Gene symbol disambiguation (GSD) is a particular case of word sense disambiguation (WSD), which has been extensively studied in the domain of general English. One type of method for WSD uses established knowledge bases, such as a machine readable dictionary (Lesk, 1986; Harley and Glennon, 1997). Another type of WSD method uses supervised machine learning (ML) technolo41 BioNLP 2007: Biological, translational, and clinical language processing, pages 41–48, Prague, June 2007. c�2007 Association for Computational Linguistics gies (Bruce and Wiebe, 1994; Lee and Ng, 2002; Liu et al., 2002). In the biomedical domain, there are many gene related knowledge sources, such as Entrez Gene (Maglott et al., 2005), developed at NCBI (National Center for Biotechnology Information), which have been used for gene symbol disambiguation. Podowski et al. (2004) used MEDLINE references in the LocusLink and SwissProt databases to build Bayesian classifiers for GSD. A validation on MEDLINE documents for a set of 66 human genes showed most accuracies were greater than 90% if there was enough training data (more than 20 abstracts for each gene sense). More recen</context>
</contexts>
<marker>Bruce, Wiebe, 1994</marker>
<rawString>Bruce, R. and Wiebe, J. 1994. Proceedings of ACL 1994, 139-146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Chen</author>
<author>H Liu</author>
<author>C Friedman</author>
</authors>
<date>2005</date>
<journal>Bioinformatics,</journal>
<volume>21</volume>
<pages>248--256</pages>
<contexts>
<context position="2129" citStr="Chen et al. (2005)" startWordPosition="299" endWordPosition="302">erature. Therefore, automated text mining tools, such as information retrieval and information extraction systems, have received great amounts of interest (Erhardt et al., 2006; Krallinger and Valencia, 2005). Biomedical entity recognition is a first crucial step for text mining tools in this domain, but is a very challenging task, partially due to the ambiguity (one name referring to different entities) of names in the biomedical field. Genes are among the most important biological entities for understanding biological functions and processes, but gene names and symbols are highly ambiguous. Chen et al. (2005) obtained gene information from 21 organisms and found that ambiguities within species, across species, with English words and with medical terms were 5.02%, 13.43%, 1.10%, 2.99%, respectively, when both official gene symbols and aliases were considered. When mining MEDLINE abstracts, they found that 85.1% of mouse genes in the articles were ambiguous with other gene names. Recently, Fundel and Zimmer (2006) studied gene/protein nomenclature in 5 public databases. Their results showed that the ambiguity problem was not trivial. The degree of ambiguity also varied among different organisms. Unl</context>
</contexts>
<marker>Chen, Liu, Friedman, 2005</marker>
<rawString>Chen, L., Liu, H. and Friedman, C. 2005. Bioinformatics, 21, 248-256.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Croft</author>
</authors>
<title>Advances in Information Retrieval.</title>
<date>2002</date>
<journal>Netherlands, Chapter</journal>
<volume>1</volume>
<pages>1--36</pages>
<publisher>Springer</publisher>
<contexts>
<context position="23013" citStr="Croft (2002)" startWordPosition="3665" endWordPosition="3666">mbSumVote, CombLR, and CombRank were statistically significantly better than single runs using word or CUI. For single run using MeSH, combination runs CombLR and CombSum were statistically significantly better. The results of different runs on testing set 2 are shown in Table 2. Most combined methods, except CombRank, showed improved precision. The highest precision of 0.906 was reached when using CombSum and CombMax methods. Note that the logistic regression method was not applicable. The coverage for testing set 2 was 0.944 for all of the methods. 4 Discussion 4.1 Why Combine? As stated in Croft (2002), a Bayesian probabilistic framework could provide the theoretical justification for evidence combination. Additional evidence with smaller errors can reduce the effect of large errors from one piece of evidence and lower the average error. The idea behind CombMax was to use the single classifier that had the most confidence, but it did not seem to improve performance very much because it ignored evidence from the other two basic classifiers. The CombSum was a simple combination method, but with reasonable performance, which was also observed by other studies for the IR task (Fox and Shaw, 199</context>
</contexts>
<marker>Croft, 2002</marker>
<rawString>Croft, W. 2002. Advances in Information Retrieval. Springer Netherlands, Chapter 1, 1-36 Dunn, O. J. 1964. Technometrics, 6, 241-252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R A Erhardt</author>
<author>R Schneider</author>
<author>C Blaschke</author>
</authors>
<date>2006</date>
<journal>Drug Discov. Today,</journal>
<volume>11</volume>
<pages>315--325</pages>
<contexts>
<context position="1687" citStr="Erhardt et al., 2006" startWordPosition="229" endWordPosition="232">fficients obtained from a logistic regression model reached the highest precision of 92.2% on a testing set of ambiguous human gene symbols. 1 Introduction In the past decade, biomedical discoveries and publications have increased exponentially due to high-throughput technologies such as automated genomic sequencing, and therefore, it is impossible for researchers to keep up-to-date with the most recent knowledge by manually reading the literature. Therefore, automated text mining tools, such as information retrieval and information extraction systems, have received great amounts of interest (Erhardt et al., 2006; Krallinger and Valencia, 2005). Biomedical entity recognition is a first crucial step for text mining tools in this domain, but is a very challenging task, partially due to the ambiguity (one name referring to different entities) of names in the biomedical field. Genes are among the most important biological entities for understanding biological functions and processes, but gene names and symbols are highly ambiguous. Chen et al. (2005) obtained gene information from 21 organisms and found that ambiguities within species, across species, with English words and with medical terms were 5.02%, </context>
</contexts>
<marker>Erhardt, Schneider, Blaschke, 2006</marker>
<rawString>Erhardt, R.A., Schneider, R. and Blaschke, C. 2006. Drug Discov. Today, 11, 315-325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Fox</author>
<author>G Nunn</author>
<author>W Lee</author>
</authors>
<date>1988</date>
<booktitle>Proceedings of the 11th ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>291--308</pages>
<contexts>
<context position="6252" citStr="Fox et al. (1988)" startWordPosition="946" endWordPosition="949">iveness. Studies on combining multiple representations of document content (Katzer et al., 1982), combining results from different queries (Xu and Croft, 1996), different ranking algorithms (Lee, 1995), and different search systems (Lee, 1997) have shown improved performance of retrieval systems. Different methods have also been developed to combine different evidence for IR tasks. The inference-network-based framework, developed by Turtle and Croft (1991), was able to combine different document representations and retrieval algorithms into an overall estimate of the probability of relevance. Fox et al. (1988) extended the vector space model to use sub-vectors to describe different representations derived from documents. An overall similarity between a document and a query is defined as a weighted linear combination of similarities of sub-vectors. A linear regression analysis was used to determine the value of the coefficients. Though previous related efforts (Schijvenaars et al., 2005, Xu et al., 2007) have explored the use of multiple types of information from different knowledge sources, none have focused on development of formal methods for combining multiple evidence for the GSD problem to opt</context>
</contexts>
<marker>Fox, Nunn, Lee, 1988</marker>
<rawString>Fox, E., Nunn, G., and Lee, W. 1988. Proceedings of the 11th ACM SIGIR Conference on Research and Development in Information Retrieval, 291–308.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Fox</author>
<author>J Shaw</author>
</authors>
<date>1994</date>
<booktitle>Proceedings TREC-2,</booktitle>
<pages>243--252</pages>
<contexts>
<context position="23615" citStr="Fox and Shaw, 1994" startWordPosition="3761" endWordPosition="3764">d in Croft (2002), a Bayesian probabilistic framework could provide the theoretical justification for evidence combination. Additional evidence with smaller errors can reduce the effect of large errors from one piece of evidence and lower the average error. The idea behind CombMax was to use the single classifier that had the most confidence, but it did not seem to improve performance very much because it ignored evidence from the other two basic classifiers. The CombSum was a simple combination method, but with reasonable performance, which was also observed by other studies for the IR task (Fox and Shaw, 1994). CombSumVote was a variant of CombSum. It favors the candidate genes selected by more basic classifiers. In Lee (1997), a similar implementation of CombSumVote (named “CombMNZ”) also achieved better performance in the IR task. CombLR, the combination method trained on a logistic regression model, achieved the best performance in this study. It used a set of coefficients derived from the training data when combining the similarities from individual basic classifiers. Therefore, it could be considered as a more complicated linear combination model than CombSum. In situations where training data</context>
</contexts>
<marker>Fox, Shaw, 1994</marker>
<rawString>Fox, E. and Shaw, J. 1994. Proceedings TREC-2, 243– 252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Friedman</author>
</authors>
<date>1937</date>
<journal>Journal of the American Statistical Association,</journal>
<volume>32</volume>
<pages>675--701</pages>
<contexts>
<context position="20420" citStr="Friedman, 1937" startWordPosition="3253" endWordPosition="3254">ach partition. When one partition was used for testing, the remaining nine partitions were combined and used for training, which also involved deriving coefficients for each round. To make other combination methods comparable with CombLR, we tested the performance of other combination methods on the same partitions as well. Therefore, we had 10 measurements for each combination method. Mean precision and mean coverage were reported for those 10 measurements. For testing set 2, we did not test the CombLR method because the set was too small to train a regression model. We used Friedman’s Test (Friedman, 1937) followed by Dunn’s Test (Dunn, 1964), which are non-parametric tests, to assess whether there were significant differences in terms of median precision among the different single or combined methods. e Cword SIMword Ccui &amp;quot; + +Cmesh&amp;quot;SIMmesh+C &amp;quot; SIMcui P Cword&amp;quot;SIMword+Ccui +Cmesh SIMmesh C &amp;quot; + &amp;quot; SIMcui 1+e 45 3 Results Results of different combination methods for testing set 1 are shown in Table 1, which contains the mean precision and coverage for 10-fold cross validation, as well as the standard errors in parentheses. All IR-based gene symbol disambiguation approaches showed large improvement</context>
</contexts>
<marker>Friedman, 1937</marker>
<rawString>Friedman, M. 1937. Journal of the American Statistical Association, 32, 675-701.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Fundel</author>
<author>R Zimmer</author>
</authors>
<date>2006</date>
<journal>BMC. Bioinformatics.,</journal>
<volume>7</volume>
<pages>372</pages>
<contexts>
<context position="2540" citStr="Fundel and Zimmer (2006)" startWordPosition="363" endWordPosition="366">s) of names in the biomedical field. Genes are among the most important biological entities for understanding biological functions and processes, but gene names and symbols are highly ambiguous. Chen et al. (2005) obtained gene information from 21 organisms and found that ambiguities within species, across species, with English words and with medical terms were 5.02%, 13.43%, 1.10%, 2.99%, respectively, when both official gene symbols and aliases were considered. When mining MEDLINE abstracts, they found that 85.1% of mouse genes in the articles were ambiguous with other gene names. Recently, Fundel and Zimmer (2006) studied gene/protein nomenclature in 5 public databases. Their results showed that the ambiguity problem was not trivial. The degree of ambiguity also varied among different organisms. Unlike other abbreviations in the literature, which usually are accompanied by their corresponding long forms, many gene symbols occur alone without any mention of their long forms. According to Schuemie et al. (2004), only 30% of gene symbols in abstracts and 18% in full text were accompanied by their corresponding full names, which makes the task of gene symbol normalization much harder. Gene symbol disambigu</context>
<context position="26437" citStr="Fundel and Zimmer (2006)" startWordPosition="4200" endWordPosition="4203">6.7%. The methods for combining different types of information from biomedical knowledge sources described in this study, though targeted to the GSD problem, could be also applicable to other text mining tasks that are based on similarity measurement, such as text categorization, clustering, and the IR task in the biomedical domain. 4.2 Coverage of the Methods The IR-based gene symbol disambiguation method described in this paper aims to resolve intraspecies gene ambiguity. We focused on ambiguous gene symbols within the human species and used articles known to be associated with human genes. Fundel and Zimmer (2006) reported that the degree of ambiguity of the human gene symbols from Entrez Gene was 3.16%–3.32%, which is substantial. However, this is only part of the gene ambiguity problem. Based on the “gene_info” file downloaded in January 2006 from Entrez Gene, there were a total of 32,852 human genes. Based on the “gene2pubmed” file, 24,170 (73.4%) out of 32,852 human genes have at least one associated MEDLINE article, which indicates that profiles could be generated for at least 73.4% of human genes. On average, there are 9.02 MEDLINE articles associated with a particular human gene. Coverage report</context>
</contexts>
<marker>Fundel, Zimmer, 2006</marker>
<rawString>Fundel, K. and Zimmer, R. 2006. BMC. Bioinformatics., 7: 372.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Harley</author>
<author>D Glennon</author>
</authors>
<date>1997</date>
<booktitle>Proc. SIGLEX Workshop &amp;quot;Tagging Text With Lexical Semantics&amp;quot;,</booktitle>
<pages>74--78</pages>
<contexts>
<context position="3415" citStr="Harley and Glennon, 1997" startWordPosition="504" endWordPosition="507">accompanied by their corresponding long forms, many gene symbols occur alone without any mention of their long forms. According to Schuemie et al. (2004), only 30% of gene symbols in abstracts and 18% in full text were accompanied by their corresponding full names, which makes the task of gene symbol normalization much harder. Gene symbol disambiguation (GSD) is a particular case of word sense disambiguation (WSD), which has been extensively studied in the domain of general English. One type of method for WSD uses established knowledge bases, such as a machine readable dictionary (Lesk, 1986; Harley and Glennon, 1997). Another type of WSD method uses supervised machine learning (ML) technolo41 BioNLP 2007: Biological, translational, and clinical language processing, pages 41–48, Prague, June 2007. c�2007 Association for Computational Linguistics gies (Bruce and Wiebe, 1994; Lee and Ng, 2002; Liu et al., 2002). In the biomedical domain, there are many gene related knowledge sources, such as Entrez Gene (Maglott et al., 2005), developed at NCBI (National Center for Biotechnology Information), which have been used for gene symbol disambiguation. Podowski et al. (2004) used MEDLINE references in the LocusLink </context>
</contexts>
<marker>Harley, Glennon, 1997</marker>
<rawString>Harley, A. and Glennon, D. 1997. Proc. SIGLEX Workshop &amp;quot;Tagging Text With Lexical Semantics&amp;quot;, 74-78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Katzer</author>
<author>M McGill</author>
<author>J Tessier</author>
<author>W Frakes</author>
<author>P DasGupta</author>
</authors>
<date>1998</date>
<booktitle>Information Technology: Research and Development,</booktitle>
<volume>1</volume>
<issue>4</issue>
<marker>Katzer, McGill, Tessier, Frakes, DasGupta, 1998</marker>
<rawString>Katzer, J., McGill, M., Tessier, J., Frakes,W., and DasGupta, P. 1998. Information Technology: Research and Development, 1(4):261–274.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Krallinger</author>
<author>A Valencia</author>
</authors>
<date>2005</date>
<journal>Genome Biol.,</journal>
<volume>6</volume>
<pages>224</pages>
<contexts>
<context position="1719" citStr="Krallinger and Valencia, 2005" startWordPosition="233" endWordPosition="236">m a logistic regression model reached the highest precision of 92.2% on a testing set of ambiguous human gene symbols. 1 Introduction In the past decade, biomedical discoveries and publications have increased exponentially due to high-throughput technologies such as automated genomic sequencing, and therefore, it is impossible for researchers to keep up-to-date with the most recent knowledge by manually reading the literature. Therefore, automated text mining tools, such as information retrieval and information extraction systems, have received great amounts of interest (Erhardt et al., 2006; Krallinger and Valencia, 2005). Biomedical entity recognition is a first crucial step for text mining tools in this domain, but is a very challenging task, partially due to the ambiguity (one name referring to different entities) of names in the biomedical field. Genes are among the most important biological entities for understanding biological functions and processes, but gene names and symbols are highly ambiguous. Chen et al. (2005) obtained gene information from 21 organisms and found that ambiguities within species, across species, with English words and with medical terms were 5.02%, 13.43%, 1.10%, 2.99%, respective</context>
</contexts>
<marker>Krallinger, Valencia, 2005</marker>
<rawString>Krallinger, M. and Valencia, A. 2005. Genome Biol., 6, 224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lee</author>
</authors>
<date>1995</date>
<booktitle>Proceedings of the 18th ACMSIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>180--188</pages>
<contexts>
<context position="5836" citStr="Lee, 1995" startWordPosition="889" endWordPosition="890">, fly and yeast organisms when different types of information from different knowledge sources were used. They also used a simple method to combine different types of information and reported that a highest precision of 93.9% was reached for a testing set of mouse genes using multiple types of information. In the field of IR, it has been shown that combining heterogeneous evidence improves retrieval effectiveness. Studies on combining multiple representations of document content (Katzer et al., 1982), combining results from different queries (Xu and Croft, 1996), different ranking algorithms (Lee, 1995), and different search systems (Lee, 1997) have shown improved performance of retrieval systems. Different methods have also been developed to combine different evidence for IR tasks. The inference-network-based framework, developed by Turtle and Croft (1991), was able to combine different document representations and retrieval algorithms into an overall estimate of the probability of relevance. Fox et al. (1988) extended the vector space model to use sub-vectors to describe different representations derived from documents. An overall similarity between a document and a query is defined as a w</context>
</contexts>
<marker>Lee, 1995</marker>
<rawString>Lee, J. 1995. Proceedings of the 18th ACMSIGIR Conference on Research and Development in Information Retrieval, 180–188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lee</author>
</authors>
<date>1997</date>
<booktitle>Proceedings of the 20th ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>267--276</pages>
<contexts>
<context position="5878" citStr="Lee, 1997" startWordPosition="895" endWordPosition="896">ypes of information from different knowledge sources were used. They also used a simple method to combine different types of information and reported that a highest precision of 93.9% was reached for a testing set of mouse genes using multiple types of information. In the field of IR, it has been shown that combining heterogeneous evidence improves retrieval effectiveness. Studies on combining multiple representations of document content (Katzer et al., 1982), combining results from different queries (Xu and Croft, 1996), different ranking algorithms (Lee, 1995), and different search systems (Lee, 1997) have shown improved performance of retrieval systems. Different methods have also been developed to combine different evidence for IR tasks. The inference-network-based framework, developed by Turtle and Croft (1991), was able to combine different document representations and retrieval algorithms into an overall estimate of the probability of relevance. Fox et al. (1988) extended the vector space model to use sub-vectors to describe different representations derived from documents. An overall similarity between a document and a query is defined as a weighted linear combination of similarities</context>
<context position="23734" citStr="Lee (1997)" startWordPosition="3782" endWordPosition="3783">tional evidence with smaller errors can reduce the effect of large errors from one piece of evidence and lower the average error. The idea behind CombMax was to use the single classifier that had the most confidence, but it did not seem to improve performance very much because it ignored evidence from the other two basic classifiers. The CombSum was a simple combination method, but with reasonable performance, which was also observed by other studies for the IR task (Fox and Shaw, 1994). CombSumVote was a variant of CombSum. It favors the candidate genes selected by more basic classifiers. In Lee (1997), a similar implementation of CombSumVote (named “CombMNZ”) also achieved better performance in the IR task. CombLR, the combination method trained on a logistic regression model, achieved the best performance in this study. It used a set of coefficients derived from the training data when combining the similarities from individual basic classifiers. Therefore, it could be considered as a more complicated linear combination model than CombSum. In situations where training data is not available, CombSum or CombSumVote would be a good choice. CombRank did not perform as well as methods that used</context>
</contexts>
<marker>Lee, 1997</marker>
<rawString>Lee, J. 1997. Proceedings of the 20th ACM SIGIR Conference on Research and Development in Information Retrieval, 267–276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y K Lee</author>
<author>H T Ng</author>
</authors>
<date>2002</date>
<booktitle>Proc EMNLP</booktitle>
<pages>41--48</pages>
<contexts>
<context position="3693" citStr="Lee and Ng, 2002" startWordPosition="543" endWordPosition="546">of gene symbol normalization much harder. Gene symbol disambiguation (GSD) is a particular case of word sense disambiguation (WSD), which has been extensively studied in the domain of general English. One type of method for WSD uses established knowledge bases, such as a machine readable dictionary (Lesk, 1986; Harley and Glennon, 1997). Another type of WSD method uses supervised machine learning (ML) technolo41 BioNLP 2007: Biological, translational, and clinical language processing, pages 41–48, Prague, June 2007. c�2007 Association for Computational Linguistics gies (Bruce and Wiebe, 1994; Lee and Ng, 2002; Liu et al., 2002). In the biomedical domain, there are many gene related knowledge sources, such as Entrez Gene (Maglott et al., 2005), developed at NCBI (National Center for Biotechnology Information), which have been used for gene symbol disambiguation. Podowski et al. (2004) used MEDLINE references in the LocusLink and SwissProt databases to build Bayesian classifiers for GSD. A validation on MEDLINE documents for a set of 66 human genes showed most accuracies were greater than 90% if there was enough training data (more than 20 abstracts for each gene sense). More recently, information r</context>
</contexts>
<marker>Lee, Ng, 2002</marker>
<rawString>Lee, Y. K. and Ng, H. T. 2002. Proc EMNLP 2002, 41-48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lesk</author>
</authors>
<date>1986</date>
<booktitle>SIGDOC Conference,</booktitle>
<pages>24--26</pages>
<contexts>
<context position="3388" citStr="Lesk, 1986" startWordPosition="502" endWordPosition="503">usually are accompanied by their corresponding long forms, many gene symbols occur alone without any mention of their long forms. According to Schuemie et al. (2004), only 30% of gene symbols in abstracts and 18% in full text were accompanied by their corresponding full names, which makes the task of gene symbol normalization much harder. Gene symbol disambiguation (GSD) is a particular case of word sense disambiguation (WSD), which has been extensively studied in the domain of general English. One type of method for WSD uses established knowledge bases, such as a machine readable dictionary (Lesk, 1986; Harley and Glennon, 1997). Another type of WSD method uses supervised machine learning (ML) technolo41 BioNLP 2007: Biological, translational, and clinical language processing, pages 41–48, Prague, June 2007. c�2007 Association for Computational Linguistics gies (Bruce and Wiebe, 1994; Lee and Ng, 2002; Liu et al., 2002). In the biomedical domain, there are many gene related knowledge sources, such as Entrez Gene (Maglott et al., 2005), developed at NCBI (National Center for Biotechnology Information), which have been used for gene symbol disambiguation. Podowski et al. (2004) used MEDLINE r</context>
</contexts>
<marker>Lesk, 1986</marker>
<rawString>Lesk, M. 1986. 1986 SIGDOC Conference, 24-26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Liu</author>
<author>S B Johnson</author>
<author>C Friedman</author>
</authors>
<date>2002</date>
<journal>J. Am. Med. Inform. Assoc.,</journal>
<volume>9</volume>
<pages>621--636</pages>
<contexts>
<context position="3712" citStr="Liu et al., 2002" startWordPosition="547" endWordPosition="550">malization much harder. Gene symbol disambiguation (GSD) is a particular case of word sense disambiguation (WSD), which has been extensively studied in the domain of general English. One type of method for WSD uses established knowledge bases, such as a machine readable dictionary (Lesk, 1986; Harley and Glennon, 1997). Another type of WSD method uses supervised machine learning (ML) technolo41 BioNLP 2007: Biological, translational, and clinical language processing, pages 41–48, Prague, June 2007. c�2007 Association for Computational Linguistics gies (Bruce and Wiebe, 1994; Lee and Ng, 2002; Liu et al., 2002). In the biomedical domain, there are many gene related knowledge sources, such as Entrez Gene (Maglott et al., 2005), developed at NCBI (National Center for Biotechnology Information), which have been used for gene symbol disambiguation. Podowski et al. (2004) used MEDLINE references in the LocusLink and SwissProt databases to build Bayesian classifiers for GSD. A validation on MEDLINE documents for a set of 66 human genes showed most accuracies were greater than 90% if there was enough training data (more than 20 abstracts for each gene sense). More recently, information retrieval (IR) based</context>
</contexts>
<marker>Liu, Johnson, Friedman, 2002</marker>
<rawString>Liu, H., Johnson, S. B. and Friedman, C. 2002. J. Am. Med. Inform. Assoc., 9, 621-636.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Lussier</author>
<author>T Borlawsky</author>
<author>D Rappaport</author>
<author>Y Liu</author>
<author>C Friedman</author>
</authors>
<date>2006</date>
<journal>Pac. Symp. Biocomput.,</journal>
<volume>11</volume>
<pages>64--75</pages>
<contexts>
<context position="11200" citStr="Lussier et al. 2006" startWordPosition="1710" endWordPosition="1713">d yielded a collection of 116,929 abstracts, which were used to generate gene profiles and one of the test sets. Two test sets were obtained for evaluating the combination methods: testing set 1 was based on the “gene2pubmed” file, and testing set 2 was based on the BioCreAtIvE II evaluation. Testing set 1 was automatically generated from the 116,929 abstracts, using the following 3 steps: 1) Identifying ambiguous gene symbols in the abstracts. This involved processing the entire collection of abstracts using an NLP system called BioMedLEE (Biomedical Language Extracting and Encoding System) (Lussier et al. 2006), which was shown to identify gene names/symbols with high precision when used in conjunction with GO annotations. When an ambiguous gene was identified in an article, the candidate gene identifiers (GeneID from Entrez Gene) were listed by the NLP system, but not disambiguated. For each ambiguous gene that was detected, a pair was created consisting of the PMID of the article and the gene symbol, so that each pair would be considered a possible testing sample. Repeated gene symbols in the same article were ignored, because we assumed only one sense per gene symbol in the same article. Using th</context>
</contexts>
<marker>Lussier, Borlawsky, Rappaport, Liu, Friedman, 2006</marker>
<rawString>Lussier, Y., Borlawsky, T., Rappaport, D., Liu, Y., Friedman, C. 2006. Pac. Symp. Biocomput., 11, 64-75.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Maglott</author>
<author>J Ostell</author>
<author>Pruitt KD</author>
<author>T Tatusova</author>
</authors>
<date>2005</date>
<journal>Nucleic Acids Res.,</journal>
<volume>3</volume>
<pages>54--58</pages>
<contexts>
<context position="3829" citStr="Maglott et al., 2005" startWordPosition="566" endWordPosition="569"> which has been extensively studied in the domain of general English. One type of method for WSD uses established knowledge bases, such as a machine readable dictionary (Lesk, 1986; Harley and Glennon, 1997). Another type of WSD method uses supervised machine learning (ML) technolo41 BioNLP 2007: Biological, translational, and clinical language processing, pages 41–48, Prague, June 2007. c�2007 Association for Computational Linguistics gies (Bruce and Wiebe, 1994; Lee and Ng, 2002; Liu et al., 2002). In the biomedical domain, there are many gene related knowledge sources, such as Entrez Gene (Maglott et al., 2005), developed at NCBI (National Center for Biotechnology Information), which have been used for gene symbol disambiguation. Podowski et al. (2004) used MEDLINE references in the LocusLink and SwissProt databases to build Bayesian classifiers for GSD. A validation on MEDLINE documents for a set of 66 human genes showed most accuracies were greater than 90% if there was enough training data (more than 20 abstracts for each gene sense). More recently, information retrieval (IR) based approaches have been applied to resolve gene ambiguity using existing knowledge sources. Typically, a profile vector</context>
</contexts>
<marker>Maglott, Ostell, KD, Tatusova, 2005</marker>
<rawString>Maglott D, Ostell J, Pruitt KD, Tatusova T. 2005. Nucleic Acids Res., 3, D54-D58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Morgan</author>
<author>B Wellner</author>
<author>J B Colombe</author>
<author>R Arens</author>
<author>M E Colosimo</author>
<author>L Hirschman</author>
</authors>
<date>2007</date>
<booktitle>Pacific Symposium on Biocomputing</booktitle>
<pages>12--281</pages>
<contexts>
<context position="28735" citStr="Morgan et al. (2007)" startWordPosition="4588" endWordPosition="4591">tem was not the most recent one, so some new genes were not listed as possible candidate senses. The second issue is related to gene families or genes/proteins with multiple sub-units. According to the ‘gene_info’ file, the gene symbol “IL-1” is a synonym for both “GeneID: 3552 interleukin 1, alpha” and “GeneID: 3553 interleukin 1, beta”. Therefore, the NLP system identified it as an ambiguous gene symbol. When annotators in the BioCreAtIvE II task saw a gene family name that was not clearly mapped to a specific gene identifier in Entrez Gene, they may not have added it to the mapped list. In Morgan et al. (2007), it was suggested that mapping gene family mentions might be appropriate for those entities. Testing set 2 was a small set and results from that set might not be statistically meaningful, but it is useful for comparing with others working on the same data set. In this paper, we focused on the study of improvements in precision of the gene symbol disambiguation system. When combining information from different knowledge sources, coverage may 47 also be increased by benefiting from the crosscoverage of different knowledge sources. 5 Conclusion and Future Work We applied an IR-based approach for</context>
</contexts>
<marker>Morgan, Wellner, Colombe, Arens, Colosimo, Hirschman, 2007</marker>
<rawString>Morgan, A., Wellner, B., Colombe, J. B., Arens, R., Colosimo, M. E., Hirschman L. 2007. Pacific Symposium on Biocomputing 12:281-291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Podowski</author>
<author>J G Cleary</author>
<author>N T Goncharoff</author>
<author>G Amoutzias</author>
<author>W S Hayes</author>
</authors>
<date>2004</date>
<journal>Program,</journal>
<booktitle>Proc IEEE Comput Syst Bioinform Conf,</booktitle>
<volume>14</volume>
<pages>415--24</pages>
<contexts>
<context position="3973" citStr="Podowski et al. (2004)" startWordPosition="588" endWordPosition="591">chine readable dictionary (Lesk, 1986; Harley and Glennon, 1997). Another type of WSD method uses supervised machine learning (ML) technolo41 BioNLP 2007: Biological, translational, and clinical language processing, pages 41–48, Prague, June 2007. c�2007 Association for Computational Linguistics gies (Bruce and Wiebe, 1994; Lee and Ng, 2002; Liu et al., 2002). In the biomedical domain, there are many gene related knowledge sources, such as Entrez Gene (Maglott et al., 2005), developed at NCBI (National Center for Biotechnology Information), which have been used for gene symbol disambiguation. Podowski et al. (2004) used MEDLINE references in the LocusLink and SwissProt databases to build Bayesian classifiers for GSD. A validation on MEDLINE documents for a set of 66 human genes showed most accuracies were greater than 90% if there was enough training data (more than 20 abstracts for each gene sense). More recently, information retrieval (IR) based approaches have been applied to resolve gene ambiguity using existing knowledge sources. Typically, a profile vector for each gene sense is built from available knowledge source(s) and a context vector is derived from the context where the ambiguous gene occur</context>
</contexts>
<marker>Podowski, Cleary, Goncharoff, Amoutzias, Hayes, 2004</marker>
<rawString>Podowski, R.M., Cleary, J.G., Goncharoff, N.T., Amoutzias, G., Hayes W.S. 2004. Proc IEEE Comput Syst Bioinform Conf, 2004, 415-24. Porter,M.F. 1980. Program, 14, 130-137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>C Buckley</author>
</authors>
<date>1988</date>
<journal>Information Processing &amp; Management,</journal>
<volume>24</volume>
<pages>513--523</pages>
<contexts>
<context position="14574" citStr="Salton and Buckley, 1988" startWordPosition="2274" endWordPosition="2277">ction of 116,929 abstracts. We used the remaining document set to generate gene profiles, which were used for both testing sets. 2.3 Profile and Context Vectors For each gene in “gene2pubmed” file, we created a profile. It consisted of three sub-vectors containing word, CUI, or McSH, respectively, using the information derived from the related MEDLINE abstracts. Similarly, a context vector was also formed for each testing sample, using three sub-vectors containing word, CUI, or McSH, which were derived from the abstract whose PMID was stated in the testing sample. The tf-idf weighting schema (Salton and Buckley, 1988) was used to assign weights to index terms in the profile and context sub-vectors. Given a document d, the Term Frequency (tf) of term t is defined as the frequency of t occurring in d. The Inverse Document Frequency (idf) of term t is defined as the logarithm of the number of all documents in the collection divided by the number of documents containing the term t. Then term t in document d is weighted as tf*idf. 2.4 Similarity Measurement The similarity score between the same type of context and profile sub-vectors were measured as cosine similarity of two vectors. The cosine similarity betwe</context>
</contexts>
<marker>Salton, Buckley, 1988</marker>
<rawString>Salton, G. and Buckley, C. 1988. Information Processing &amp; Management, 24, 513-523.</rawString>
</citation>
<citation valid="true">
<date>2005</date>
<journal>BMC. Bioinformatics.,</journal>
<pages>6--149</pages>
<contexts>
<context position="2129" citStr="(2005)" startWordPosition="302" endWordPosition="302">refore, automated text mining tools, such as information retrieval and information extraction systems, have received great amounts of interest (Erhardt et al., 2006; Krallinger and Valencia, 2005). Biomedical entity recognition is a first crucial step for text mining tools in this domain, but is a very challenging task, partially due to the ambiguity (one name referring to different entities) of names in the biomedical field. Genes are among the most important biological entities for understanding biological functions and processes, but gene names and symbols are highly ambiguous. Chen et al. (2005) obtained gene information from 21 organisms and found that ambiguities within species, across species, with English words and with medical terms were 5.02%, 13.43%, 1.10%, 2.99%, respectively, when both official gene symbols and aliases were considered. When mining MEDLINE abstracts, they found that 85.1% of mouse genes in the articles were ambiguous with other gene names. Recently, Fundel and Zimmer (2006) studied gene/protein nomenclature in 5 public databases. Their results showed that the ambiguity problem was not trivial. The degree of ambiguity also varied among different organisms. Unl</context>
<context position="4846" citStr="(2005)" startWordPosition="731" endWordPosition="731">ts for each gene sense). More recently, information retrieval (IR) based approaches have been applied to resolve gene ambiguity using existing knowledge sources. Typically, a profile vector for each gene sense is built from available knowledge source(s) and a context vector is derived from the context where the ambiguous gene occurs. Then similarities between the context vector and candidate gene profile vectors are calculated, and the gene corresponding to the gene profile vector that has the highest similarity score to the context vector is selected as the correct sense. Schijvenaars et al. (2005) reported on an IRbased method for human GSD. It utilized information from either Online Mendelian Inheritance in Man (OMIM) annotation or MEDLINE abstracts. The system achieved an accuracy rate of 92.7% on an automatically generated testing set when five abstracts were used for the gene profile. Xu et al. (2007) studied the performance of an IR-based approach for GSD for mouse, fly and yeast organisms when different types of information from different knowledge sources were used. They also used a simple method to combine different types of information and reported that a highest precision of </context>
<context position="27509" citStr="(2005)" startWordPosition="4381" endWordPosition="4381">or at least 73.4% of human genes. On average, there are 9.02 MEDLINE articles associated with a particular human gene. Coverage reported in this study was relatively high because the testing samples were selected from annotated articles as listed in “gene2pubmed”, and not randomly from the collection of all MEDLINE abstracts. 4.3 Evaluation Issues It would be interesting to compare our work with other related work, but that would require use of the same testing set. For example, it is not straightforward to compare our precision result (92.2%) with that (92.7%) reported by Schijvenaars et al. (2005), because they used a testing set that was generated by removing ambiguous genes with less than 6 associated articles for each of their senses, and they did not report on coverage. The data set from the BioCreAtIvE II GN task therefore is a valuable testing set that enables evaluation and comparison of other gene symbol disambiguation methods. From the BioCreAtIvE abstracts, we identified 217 occurrences of ambiguous gene symbols, but only 124 were annotated in the BioCreAtIvE data set. There are a few possible explanations for this. First, the version of the Entrez Gene database used by the N</context>
</contexts>
<marker>2005</marker>
<rawString>Schijvenaars, B.JA. et al. 2005. BMC. Bioinformatics., 6:149.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Schuemie</author>
</authors>
<date>2004</date>
<journal>Bioinformatics,</journal>
<volume>20</volume>
<pages>2597--2604</pages>
<marker>Schuemie, 2004</marker>
<rawString>Schuemie, M.J. et al. 2004. Bioinformatics, 20, 2597-2604.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Turtle</author>
<author>W Croft</author>
</authors>
<date>1991</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>9</volume>
<issue>3</issue>
<contexts>
<context position="6095" citStr="Turtle and Croft (1991)" startWordPosition="923" endWordPosition="926">sting set of mouse genes using multiple types of information. In the field of IR, it has been shown that combining heterogeneous evidence improves retrieval effectiveness. Studies on combining multiple representations of document content (Katzer et al., 1982), combining results from different queries (Xu and Croft, 1996), different ranking algorithms (Lee, 1995), and different search systems (Lee, 1997) have shown improved performance of retrieval systems. Different methods have also been developed to combine different evidence for IR tasks. The inference-network-based framework, developed by Turtle and Croft (1991), was able to combine different document representations and retrieval algorithms into an overall estimate of the probability of relevance. Fox et al. (1988) extended the vector space model to use sub-vectors to describe different representations derived from documents. An overall similarity between a document and a query is defined as a weighted linear combination of similarities of sub-vectors. A linear regression analysis was used to determine the value of the coefficients. Though previous related efforts (Schijvenaars et al., 2005, Xu et al., 2007) have explored the use of multiple types o</context>
</contexts>
<marker>Turtle, Croft, 1991</marker>
<rawString>Turtle, H. and Croft, W. 1991. ACM Transactions on Information Systems, 9(3):187–222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Xu</author>
<author>J W Fan</author>
<author>G Hripcsak</author>
<author>A E Mendonça</author>
<author>M Markatou</author>
<author>C Friedman</author>
</authors>
<date>2007</date>
<pages>10--1093</pages>
<location>Bioinformatics, doi:</location>
<contexts>
<context position="5160" citStr="Xu et al. (2007)" startWordPosition="780" endWordPosition="783">here the ambiguous gene occurs. Then similarities between the context vector and candidate gene profile vectors are calculated, and the gene corresponding to the gene profile vector that has the highest similarity score to the context vector is selected as the correct sense. Schijvenaars et al. (2005) reported on an IRbased method for human GSD. It utilized information from either Online Mendelian Inheritance in Man (OMIM) annotation or MEDLINE abstracts. The system achieved an accuracy rate of 92.7% on an automatically generated testing set when five abstracts were used for the gene profile. Xu et al. (2007) studied the performance of an IR-based approach for GSD for mouse, fly and yeast organisms when different types of information from different knowledge sources were used. They also used a simple method to combine different types of information and reported that a highest precision of 93.9% was reached for a testing set of mouse genes using multiple types of information. In the field of IR, it has been shown that combining heterogeneous evidence improves retrieval effectiveness. Studies on combining multiple representations of document content (Katzer et al., 1982), combining results from diff</context>
<context position="6653" citStr="Xu et al., 2007" startWordPosition="1008" endWordPosition="1011">work-based framework, developed by Turtle and Croft (1991), was able to combine different document representations and retrieval algorithms into an overall estimate of the probability of relevance. Fox et al. (1988) extended the vector space model to use sub-vectors to describe different representations derived from documents. An overall similarity between a document and a query is defined as a weighted linear combination of similarities of sub-vectors. A linear regression analysis was used to determine the value of the coefficients. Though previous related efforts (Schijvenaars et al., 2005, Xu et al., 2007) have explored the use of multiple types of information from different knowledge sources, none have focused on development of formal methods for combining multiple evidence for the GSD problem to optimize performance of an IR-based method. In this study, we adapted various IR-based combination models specifically for the GSD problem. Our motivation for this work is that there are diverse knowledge sources containing different types of information about genes, and the amount of such information is continuously increasing. A primary source containing gene information is MEDLINE articles, which c</context>
</contexts>
<marker>Xu, Fan, Hripcsak, Mendonça, Markatou, Friedman, 2007</marker>
<rawString>Xu, H., Fan, J. W., Hripcsak, G., Mendonça A. E., Markatou, M., Friedman, C. 2007. Bioinformatics, doi: 10.1093/bioinformatics/btm056</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Xu</author>
<author>W Croft</author>
</authors>
<date>1996</date>
<booktitle>Proceedings of the 19th ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>4--11</pages>
<contexts>
<context position="5794" citStr="Xu and Croft, 1996" startWordPosition="882" endWordPosition="885">rformance of an IR-based approach for GSD for mouse, fly and yeast organisms when different types of information from different knowledge sources were used. They also used a simple method to combine different types of information and reported that a highest precision of 93.9% was reached for a testing set of mouse genes using multiple types of information. In the field of IR, it has been shown that combining heterogeneous evidence improves retrieval effectiveness. Studies on combining multiple representations of document content (Katzer et al., 1982), combining results from different queries (Xu and Croft, 1996), different ranking algorithms (Lee, 1995), and different search systems (Lee, 1997) have shown improved performance of retrieval systems. Different methods have also been developed to combine different evidence for IR tasks. The inference-network-based framework, developed by Turtle and Croft (1991), was able to combine different document representations and retrieval algorithms into an overall estimate of the probability of relevance. Fox et al. (1988) extended the vector space model to use sub-vectors to describe different representations derived from documents. An overall similarity betwee</context>
</contexts>
<marker>Xu, Croft, 1996</marker>
<rawString>Xu, J. and Croft,W. 1996. Proceedings of the 19th ACM SIGIR Conference on Research and Development in Information Retrieval, pages 4–11.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>