<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012592">
<title confidence="0.970895">
KX: A flexible system for Keyphrase eXtraction
</title>
<author confidence="0.948578">
Emanuele Pianta Sara Tonelli
</author>
<affiliation confidence="0.7944015">
Fondazione Bruno Kessler Fondazione Bruno Kessler
Trento, Italy. Trento, Italy.
</affiliation>
<email confidence="0.992552">
pianta@fbk.eu satonelli@fbk.eu
</email>
<sectionHeader confidence="0.99438" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.991928105263158">
In this paper we present KX, a system for key-
phrase extraction developed at FBK-IRST,
which exploits basic linguistic annotation
combined with simple statistical measures to
select a list of weighted keywords from a
document. The system is flexible in that it of-
fers to the user the possibility of setting pa-
rameters such as frequency thresholds for col-
location extraction and indicators for key-
phrase relevance, as well as it allows for do-
main adaptation exploiting a corpus of docu-
ments in an unsupervised way. KX is also eas-
ily adaptable to new languages in that it re-
quires only a PoS-Tagger to derive lexical pat-
terns. In the SemEval task 5 “Automatic Key-
phrase Extraction from Scientific Articles”,
KX performance achieved satisfactory results
both in finding reader-assigned keywords and
in the combined keywords subtask.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99984605882353">
Keyphrases are expressions, either single words
or phrases, describing the most important con-
cepts of a document. As such, a list of key-
phrases provides an approximate but useful char-
acterization of the content of a text and can be
used in a number of interesting ways both for
human and automatic processing. For example,
keyphrases provide a sort of quick summary of a
document. This can be exploited not only in
automatic summarization tasks, but also to en-
able quick topic search over a number of docu-
ments indexed according to their keywords,
which is more precise and efficient than full-text
search. Once the keywords of a document collec-
tion are known, they can also be used to calculate
semantic similarity between documents and to
cluster the texts according to such similarity
(Ricca et al, 2004). Also, keyword extraction can
be used as an intermediate step for automatic
sense extraction (Jones et al, 2002).
For these reasons, the keyphrase extraction
task proposed at SemEval 2010 raised much at-
tention among NLP researchers, with 20 groups
participating to the competition. In this frame-
work, we presented the KX system, specifically
tuned to identify keyphrases in scientific articles.
In particular, the challenge comprised two sub-
tasks: the extraction of reader-assigned and of
author-assigned keyphrases in scientific articles
from the ACM digital library. The former are
assigned to the articles by annotators, who can
choose only keyphrases that occur in the docu-
ment, while author-assigned keyphrases are not
necessarily included in the text.
</bodyText>
<sectionHeader confidence="0.944716" genericHeader="method">
2 KX architecture
</sectionHeader>
<bodyText confidence="0.999980692307692">
A previous version of the KX system, named
KXPat (Pianta, 2009), was developed to extract
keyphrases from patent documents in the PatEx-
pert project (www.patexpert.org). The sys-
tem employed in the SemEval task has additional
parameters and has been tailored to identify key-
phrases in scientific articles.
With KX, the identification of keyphrases can
be accomplished with or without the help of a
reference corpus, from which some statistical
measures are computed in an unsupervised way.
We present here the general KX architecture,
including the corpus-based pre-processing, even
if in the SemEval task the information extracted
from the corpus did not contribute as expected
(see Section 3).
KX keyphrase extraction combines linguistic
and statistical information, similar to (Frantzi et
al., 2000) and is based on 4 steps. The first three
steps are carried out at corpus level, whereas the
fourth one extracts information specific to each
single document to be processed. This means that
the first three steps require a corpus C, preferably
sharing the same domain of the document d from
which the keyphrases should be extracted. The
fourth step, instead, is focused only on the
</bodyText>
<page confidence="0.948515">
170
</page>
<bodyText confidence="0.983451174311927">
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 170–173,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
document d. The steps can be summarized as
follows:
Step 1: Extract from C the list NG-c of corpus
n-grams, where an n-gram is any sequence
of tokens in the text, for instance “the sys-
tem”, “of the”, “specifically built”.
Step 2: Select from the list NG-c a sub-list of
multiword terms MW-c, that is combina-
tions of words expressing a unitary con-
cept, for instance “light beam” or “access
control”
Step 3: For each document in C, recognize
and mark the multiword terms. Calculate
the inverse document frequency (IDF) for
all words and multiword terms in the cor-
pus.
Step 4: Given a document d from which a set
of relevant keyphrases should be ex-
tracted, count all words and multiword
terms and rank them.
Step 1 is aimed at building a list of all possible n-
grams in C. The maximum length of the selected
n-grams can be set by the user. For SemEval,
beside one-token n-grams, we select 2-, 3- and 4-
grams. Since n-grams occurring only a few times
are very unlikely to be useful for keyphrase
recognition, they are cut off from the extracted
list and excluded for further processing. The fre-
quency threshold can be set according to the ref-
erence corpus dimensions. For SemEval, we
fixed the frequency threshold to 4. In this step, a
black-list was also used in order to exclude n-
grams containing any of the stopwords in the list.
Such stopwords include for example “every-
thing”, “exemplary”, “preceding”, etc.
In Step 2, we select as multiword terms those
n-grams that match certain lexical patterns. To
this purpose, we first analyze all n-grams with
the MorphoPro morphological analyzer of the
TextPro toolsuite (Pianta et al., 2006). Then, we
filter out the n-grams whose analysis does not
correspond to a predefined set of lexical patterns.
For example, one of the patterns admitted for 4-
grams is the following: [N]—[O]—[ASPGLU]—[NU].
This means that a 4-gram is a candidate
multiword term if it is composed by a Noun, fol-
lowed by “of” or “for” (defined as O), followed
by either an Adjective, Singular noun, Past parti-
ciple, Gerund, punctuation (L) or Unknown
word, followed by either a Noun or Unknown
word. This is matched for example by the 4-gram
“subset [S] of [O] parent [S] peers [N]”.
Both the lexical categories (e.g. S for singular
noun) and the admissible lexical patterns can be
defined by the user.
In Step 3, multiword terms are recognized by
combining local (document) and global (corpus)
evidence. To this purpose, we do not exploit as-
sociation measures such as Log-Likelihood, or
Mutual Information, but a simple frequency
based criterion. Two thresholds are defined:
MinCorpus, which corresponds to the minimum
number of occurrences of an n-gram in a refer-
ence corpus, and MinDoc, i.e. the minimum
number of occurrences in the current document.
KX marks an n-gram in a document as a
multiword term if it occurs at least MinCorpus
times in the corpus or at least MinDoc times in
the document. The two parameters depend on the
size of the corpus and the document respectively.
In SemEval, we found that the best thresholds
are MinDoc=4 and MinCorpus=8. A similar, fre-
quency-based, strategy is used to solve ambigui-
ties in how sequences of contiguous multiwords
should be segmented. For instance, given the
sequence “combined storage capability of sen-
sors” we need to decide whether we recognize
“combined storage capability” or “storage capa-
bility of sensors”. To this purpose, we calculate
the strength of each alternative collocation as
docFrequency * corpusFrequency, and then
choose the stronger one. To calculate IDF for
each word and multiword term, we use the usual
formula: log( TotDocs / DocsContaningTerm ).
In step 4, we take into account a new docu-
ment d, possibly not included in C, from which
the keyphrases should be extracted. First we rec-
ognize and mark multiword terms, through the
same algorithm used in Step 3. Note that KX can
recognize multiwords also in isolated documents,
independently of any reference corpus, by acti-
vating only the MinDoc parameter (see above).
Then, we count the frequency of words and
multiword terms in d, obtaining a first list of
keyphrases, ranked according to frequency.
Thus, frequency is the baseline ranking parame-
ter, based on the assumption that important con-
cepts are mentioned more frequently than less
important ones.
After the creation of a frequency-based list of
keyphrases, various techniques are used to re-
rank it according to relevance. In order to find
the best ranking mechanism for the type of key-
phrases we want to extract, different parameters
can be set:
• Inverse document frequency (IDF): this
parameter takes into account the fact that a
</bodyText>
<page confidence="0.993047">
171
</page>
<bodyText confidence="0.994535666666667">
concept that is mentioned in all documents
is less relevant to our task than a concept
occurring in few documents
</bodyText>
<listItem confidence="0.980406675">
• Keyphrase length: number of tokens in a
keyphrase. Concepts expressed by longer
phrases are expected to be more specific,
and thus more relevant. When this pa-
rameter is activated, frequency is multi-
plied by the keyphrase length.
• Position of first occurrence: important
concepts are expected to be mentioned be-
fore less relevant ones. If the parameter is
activated, the frequency score will be mul-
tiplied by the PosFact factor computed as
(DistFromEnd / MaxIndex)pwr2, where
MaxIndex is the length of the current
document and DistFromEnd is MaxIndex
minus the position of the first keyphrase
occurrence in the text.
• Shorter concept subsumption: In the key-
phrase list, two concepts can occur, such
that one is a specification of the other.
Concept subsumption and boosting are
used to merge or re-rank such couples of
concepts. If a keyphrase is (stringwise) in-
cluded in a longer keyphrase with a higher
frequency, the frequency of the shorter
keyphrase is transferred to the count of the
longer one. E.g. “grid service discov-
ery”=6 and “grid service”=4 are re-ranked
as “grid service discovery”=10 and “grid
service”=0
• Longer concept boosting: If a keyphrase
is included in a longer one with a lower
frequency, the average score between the
two keyphrase frequency is computed.
Such score is assigned to the less frequent
keyphrase and subtracted from the fre-
quency score of the higher ranked one. For
example, if “grid service discovery”=4
and “grid service”=6, the average fre-
quency is 5, so that “grid service discov-
ery”=5 and “grid service” = 6–5=1. This
</listItem>
<bodyText confidence="0.977815675675676">
parameter can be activated alone or to-
gether with another one that modifies the
criterion for computing the boosting. With
this second option, the longer keyphrase is
assigned the frequency of the shorter one.
For example, if “grid service discovery”=4
and “grid service”=6, the boosting gives
“grid service discovery”=6 and “grid serv-
ice”=6.
After the list of ranked keyphrases is extracted
for each document, it is finally post-processed in
two steps. The post-processing phase has been
added specifically for SemEval, because key-
phrases do not usually need to be stemmed and
acronym expansion is relevant only for the spe-
cific genre of scientific articles. For this reason,
the two processes are not part of the official sys-
tem architecture.
First, acronyms are replaced by the extended
form, which is automatically extracted from the
current document. The algorithm for acronym
detection scans for parenthetical expressions in
the text and checks if a preceding text span can
be considered a suitable correspondence
(Nguyen and Kan, 2007). The algorithm should
detect cases in which the acronym appears after
or before the extended form, like in “Immediate
Predecessors Tracking (IPT)” and “IPT (Imme-
diate Predecessors Tracking)”. If the acronym
and the extended form appear both in the key-
phrase list, only the extended form is kept and
the acronym frequency is added.
The second step is stemming with the (Porter
Stemmer). Then, we check if the list of stemmed
keyphrases contains duplicate entries. If yes, we
sum the frequencies of the double keyphrases
and remove one of the two from the list.
</bodyText>
<sectionHeader confidence="0.995518" genericHeader="method">
3 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999632523809524">
In the SemEval task, 144 training files were
made available before the test data release. We
split them into a training/development set of 100
documents and a test set of 44 documents, in or-
der to find the best parameter combination. Key-
phrase assignment is a subjective task and crite-
ria for keyphrase identification depend on the
domain and on the goal for which the keyphrases
are needed. For example in scientific articles
longer keyphrases are often more informative
than shorter ones, so the parameters for boosting
longer concepts are particularly relevant.
We first tested all parameters in isolation to
compute the improvement over the frequency-
based baseline. Results are reported in Table 1.
F1 is computed as the harmonic mean of preci-
sion and recall over the 15 top-ranked key-
phrases after stemming. We report the combined
F1, as computed by the task scorer in order to
combine reader-assigned and author-assigned
keyword sets.
</bodyText>
<table confidence="0.5843998125">
Parameter F1 (combined)
Baseline(MinDoc = 2) 13.63
Baseline(MinDoc = 4) 14.84
+CorpusColloc(small) 13.48
+CorpusColloc(big) 13.33
+IDF 17.98
172
+KeyphraseLength 16.78 participants, while the combined measure
+FirstPosition 16.18 achieved the 7th best result out of 20.
+ShortConcSubsumption 16.03
+LongConcBoost(version1) 14.38 5 Conclusions
+LongConcBoost(version2) 13.93
MinDoc = 4, +FirstPosition,
+IDF, +KeyphraseLength, 25.62
+ShortConcSubsumption,
+LongConcBoost(version1)
</table>
<tableCaption confidence="0.999365">
Table 1: Parameter performance over development set
</tableCaption>
<bodyText confidence="0.999986034482759">
The parameter scoring the highest improvement
over the baseline is IDF. Also the parameters
boosting longer keyphrases and those that occur
at the beginning of the text are effective. Note
that the LongConcBoost parameter achieves bet-
ter results in the first version, which has a higher
impact on the re-ranking. Surprisingly, using a
domain corpus to extract information about
multiword terms, as described in Section 2, steps
1 - 3, does not achieve any improvement. This
means that KX can better recognize keyphrases
in single documents without any corpus refer-
ence. Besides, the best setting for MinDoc, the
minimum number of multiword occurrences in
the current document (see Section 2) is 4. We
tested the CorpusColloc parameter using two
different reference corpora: one contained the
100 articles of the training set (CorpusColloc
small), while the other (CorpusColloc big) in-
cluded both the 100 training articles and the 200
scientific publications of the NUS Keyphrase
Corpus (Nguyen and Kan, 2007). The perform-
ance is worse using the larger corpus than the
smaller one, and in both cases it is below the
baseline obtained without any reference corpus.
In the bottom row of Table 1, the best pa-
rameter combination is reported with the score
obtained over the development set. The im-
provement over the baseline reaches 11.99 F1.
</bodyText>
<sectionHeader confidence="0.999462" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.9997482">
In the SemEval task, the system was run on the
test set (100 articles) with the best performing
parameter combination described in the previous
section. The results obtained over the 15 top-
ranked keyphrases are reported in Table 2.
</bodyText>
<table confidence="0.973470666666667">
Keyphrase type P R F1
Reader-assigned 20.33 25.33 22.56
Combined 23.60 24.15 23.87
</table>
<tableCaption confidence="0.999393">
Table 2: System performance over test set
</tableCaption>
<bodyText confidence="0.999863208333334">
In the competition, the F1 score over reader-
assigned keyphrases was ranked 3rd out of 20
In this work we have described KX, a flexible
system for keyphrase extraction, which achieved
promising results in the SemEval task 5. The
good KX performance is due to its adaptable ar-
chitecture, based on a set of parameters that can
be tailored to the document type, the preferred
keyphrase length, etc. The system can also ex-
ploit multiword lists (with frequency) extracted
from a reference corpus, even if this feature did
not improve KX performance in this specific
task. However, this proved to be relevant when
applied to keyphrase extraction in the patent do-
main, using a large domain-specific corpus of
10.000 very long documents (Pianta, 2009).
A limitation of KX in the task was that it ex-
tracts only keyphrases already present in a given
document, while the author-assigned subtask in
the SemEval competition included also key-
phrases that do not occur in the text. Another
improvement, which is now being implemented,
is the extraction of the best parameter combina-
tion using machine-learning techniques.
</bodyText>
<sectionHeader confidence="0.999117" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997007260869565">
Jones, S., Lundy, S. and Paynter, G. W. 2002. Interac-
tive Document Summarization Using Automati-
cally Extracted Keyphrases. In Proc. of the 35th
Hawaii International Conference on System Sci-
ences.
Frantzi, K., Ananiadou, S. and Mima, H. 2000.
Automatic recognition of multi-word terms: the C-
value/NC-value method. Journal on Digital Li-
braries. 3 (2), pp.115-130.
Thuy Dung Nguyen and Min-Yen Kan. 2007. Key-
phrase Extraction in Scientific Documents. In
D.H.-L. Goh et al. (eds.): ICADL 2007, LNCS
4822, pp. 317-326.
Pianta, E., Girardi, C and Zanoli, R. 2006. The
TextPro tool suite. In Proc. of LREC.
Pianta, E. 2009. Content Distillation from Patent Ma-
terial, FBK Technical Report.
Ricca, F., Tonella, P., Girardi, C and Pianta, E. 2004.
An empirical study on Keyword-based Web Site
Clustering. In Proceedings of the 12th IWPC.
PorterStemmer:
http://tartarus.org/~martin/PorterStem
mer/perl.txt.
</reference>
<page confidence="0.999045">
173
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.311036">
<title confidence="0.999767">KX: A flexible system for Keyphrase eXtraction</title>
<author confidence="0.9452915">Emanuele Pianta Sara Tonelli Fondazione Bruno Kessler Fondazione Bruno Kessler</author>
<address confidence="0.728193">Trento, Italy. Trento, Italy.</address>
<email confidence="0.986683">pianta@fbk.eusatonelli@fbk.eu</email>
<abstract confidence="0.97461955">In this paper we present KX, a system for keyphrase extraction developed at FBK-IRST, which exploits basic linguistic annotation combined with simple statistical measures to select a list of weighted keywords from a document. The system is flexible in that it offers to the user the possibility of setting parameters such as frequency thresholds for collocation extraction and indicators for keyphrase relevance, as well as it allows for domain adaptation exploiting a corpus of documents in an unsupervised way. KX is also easily adaptable to new languages in that it requires only a PoS-Tagger to derive lexical patterns. In the SemEval task 5 “Automatic Keyphrase Extraction from Scientific Articles”, KX performance achieved satisfactory results in finding keywords the keywords</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Jones</author>
<author>S Lundy</author>
<author>G W Paynter</author>
</authors>
<title>Interactive Document Summarization Using Automatically Extracted Keyphrases.</title>
<date>2002</date>
<booktitle>In Proc. of the 35th Hawaii International Conference on System Sciences.</booktitle>
<contexts>
<context position="1960" citStr="Jones et al, 2002" startWordPosition="313" endWordPosition="316">essing. For example, keyphrases provide a sort of quick summary of a document. This can be exploited not only in automatic summarization tasks, but also to enable quick topic search over a number of documents indexed according to their keywords, which is more precise and efficient than full-text search. Once the keywords of a document collection are known, they can also be used to calculate semantic similarity between documents and to cluster the texts according to such similarity (Ricca et al, 2004). Also, keyword extraction can be used as an intermediate step for automatic sense extraction (Jones et al, 2002). For these reasons, the keyphrase extraction task proposed at SemEval 2010 raised much attention among NLP researchers, with 20 groups participating to the competition. In this framework, we presented the KX system, specifically tuned to identify keyphrases in scientific articles. In particular, the challenge comprised two subtasks: the extraction of reader-assigned and of author-assigned keyphrases in scientific articles from the ACM digital library. The former are assigned to the articles by annotators, who can choose only keyphrases that occur in the document, while author-assigned keyphra</context>
</contexts>
<marker>Jones, Lundy, Paynter, 2002</marker>
<rawString>Jones, S., Lundy, S. and Paynter, G. W. 2002. Interactive Document Summarization Using Automatically Extracted Keyphrases. In Proc. of the 35th Hawaii International Conference on System Sciences.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Frantzi</author>
<author>S Ananiadou</author>
<author>H Mima</author>
</authors>
<title>Automatic recognition of multi-word terms: the Cvalue/NC-value method.</title>
<date>2000</date>
<journal>Journal on Digital Libraries.</journal>
<volume>3</volume>
<issue>2</issue>
<pages>115--130</pages>
<contexts>
<context position="3424" citStr="Frantzi et al., 2000" startWordPosition="533" endWordPosition="536"> employed in the SemEval task has additional parameters and has been tailored to identify keyphrases in scientific articles. With KX, the identification of keyphrases can be accomplished with or without the help of a reference corpus, from which some statistical measures are computed in an unsupervised way. We present here the general KX architecture, including the corpus-based pre-processing, even if in the SemEval task the information extracted from the corpus did not contribute as expected (see Section 3). KX keyphrase extraction combines linguistic and statistical information, similar to (Frantzi et al., 2000) and is based on 4 steps. The first three steps are carried out at corpus level, whereas the fourth one extracts information specific to each single document to be processed. This means that the first three steps require a corpus C, preferably sharing the same domain of the document d from which the keyphrases should be extracted. The fourth step, instead, is focused only on the 170 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 170–173, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics document d. The steps can be summari</context>
</contexts>
<marker>Frantzi, Ananiadou, Mima, 2000</marker>
<rawString>Frantzi, K., Ananiadou, S. and Mima, H. 2000. Automatic recognition of multi-word terms: the Cvalue/NC-value method. Journal on Digital Libraries. 3 (2), pp.115-130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thuy Dung Nguyen</author>
<author>Min-Yen Kan</author>
</authors>
<title>Keyphrase Extraction in Scientific Documents.</title>
<date>2007</date>
<booktitle>ICADL 2007, LNCS 4822,</booktitle>
<pages>317--326</pages>
<editor>In D.H.-L. Goh et al. (eds.):</editor>
<contexts>
<context position="11348" citStr="Nguyen and Kan, 2007" startWordPosition="1849" endWordPosition="1852">lly post-processed in two steps. The post-processing phase has been added specifically for SemEval, because keyphrases do not usually need to be stemmed and acronym expansion is relevant only for the specific genre of scientific articles. For this reason, the two processes are not part of the official system architecture. First, acronyms are replaced by the extended form, which is automatically extracted from the current document. The algorithm for acronym detection scans for parenthetical expressions in the text and checks if a preceding text span can be considered a suitable correspondence (Nguyen and Kan, 2007). The algorithm should detect cases in which the acronym appears after or before the extended form, like in “Immediate Predecessors Tracking (IPT)” and “IPT (Immediate Predecessors Tracking)”. If the acronym and the extended form appear both in the keyphrase list, only the extended form is kept and the acronym frequency is added. The second step is stemming with the (Porter Stemmer). Then, we check if the list of stemmed keyphrases contains duplicate entries. If yes, we sum the frequencies of the double keyphrases and remove one of the two from the list. 3 Experimental Setup In the SemEval tas</context>
<context position="14411" citStr="Nguyen and Kan, 2007" startWordPosition="2318" endWordPosition="2321"> terms, as described in Section 2, steps 1 - 3, does not achieve any improvement. This means that KX can better recognize keyphrases in single documents without any corpus reference. Besides, the best setting for MinDoc, the minimum number of multiword occurrences in the current document (see Section 2) is 4. We tested the CorpusColloc parameter using two different reference corpora: one contained the 100 articles of the training set (CorpusColloc small), while the other (CorpusColloc big) included both the 100 training articles and the 200 scientific publications of the NUS Keyphrase Corpus (Nguyen and Kan, 2007). The performance is worse using the larger corpus than the smaller one, and in both cases it is below the baseline obtained without any reference corpus. In the bottom row of Table 1, the best parameter combination is reported with the score obtained over the development set. The improvement over the baseline reaches 11.99 F1. 4 Evaluation In the SemEval task, the system was run on the test set (100 articles) with the best performing parameter combination described in the previous section. The results obtained over the 15 topranked keyphrases are reported in Table 2. Keyphrase type P R F1 Rea</context>
</contexts>
<marker>Nguyen, Kan, 2007</marker>
<rawString>Thuy Dung Nguyen and Min-Yen Kan. 2007. Keyphrase Extraction in Scientific Documents. In D.H.-L. Goh et al. (eds.): ICADL 2007, LNCS 4822, pp. 317-326.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Pianta</author>
<author>C Girardi</author>
<author>R Zanoli</author>
</authors>
<title>The TextPro tool suite.</title>
<date>2006</date>
<booktitle>In Proc. of LREC.</booktitle>
<contexts>
<context position="5622" citStr="Pianta et al., 2006" startWordPosition="909" endWordPosition="912">cut off from the extracted list and excluded for further processing. The frequency threshold can be set according to the reference corpus dimensions. For SemEval, we fixed the frequency threshold to 4. In this step, a black-list was also used in order to exclude ngrams containing any of the stopwords in the list. Such stopwords include for example “everything”, “exemplary”, “preceding”, etc. In Step 2, we select as multiword terms those n-grams that match certain lexical patterns. To this purpose, we first analyze all n-grams with the MorphoPro morphological analyzer of the TextPro toolsuite (Pianta et al., 2006). Then, we filter out the n-grams whose analysis does not correspond to a predefined set of lexical patterns. For example, one of the patterns admitted for 4- grams is the following: [N]—[O]—[ASPGLU]—[NU]. This means that a 4-gram is a candidate multiword term if it is composed by a Noun, followed by “of” or “for” (defined as O), followed by either an Adjective, Singular noun, Past participle, Gerund, punctuation (L) or Unknown word, followed by either a Noun or Unknown word. This is matched for example by the 4-gram “subset [S] of [O] parent [S] peers [N]”. Both the lexical categories (e.g. S</context>
</contexts>
<marker>Pianta, Girardi, Zanoli, 2006</marker>
<rawString>Pianta, E., Girardi, C and Zanoli, R. 2006. The TextPro tool suite. In Proc. of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Pianta</author>
</authors>
<title>Content Distillation from Patent Material, FBK</title>
<date>2009</date>
<tech>Technical Report.</tech>
<contexts>
<context position="2687" citStr="Pianta, 2009" startWordPosition="425" endWordPosition="426">chers, with 20 groups participating to the competition. In this framework, we presented the KX system, specifically tuned to identify keyphrases in scientific articles. In particular, the challenge comprised two subtasks: the extraction of reader-assigned and of author-assigned keyphrases in scientific articles from the ACM digital library. The former are assigned to the articles by annotators, who can choose only keyphrases that occur in the document, while author-assigned keyphrases are not necessarily included in the text. 2 KX architecture A previous version of the KX system, named KXPat (Pianta, 2009), was developed to extract keyphrases from patent documents in the PatExpert project (www.patexpert.org). The system employed in the SemEval task has additional parameters and has been tailored to identify keyphrases in scientific articles. With KX, the identification of keyphrases can be accomplished with or without the help of a reference corpus, from which some statistical measures are computed in an unsupervised way. We present here the general KX architecture, including the corpus-based pre-processing, even if in the SemEval task the information extracted from the corpus did not contribut</context>
</contexts>
<marker>Pianta, 2009</marker>
<rawString>Pianta, E. 2009. Content Distillation from Patent Material, FBK Technical Report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Ricca</author>
<author>P Tonella</author>
<author>C Girardi</author>
<author>E Pianta</author>
</authors>
<title>An empirical study on Keyword-based Web Site Clustering.</title>
<date>2004</date>
<booktitle>In Proceedings of the 12th IWPC.</booktitle>
<contexts>
<context position="1847" citStr="Ricca et al, 2004" startWordPosition="295" endWordPosition="298">zation of the content of a text and can be used in a number of interesting ways both for human and automatic processing. For example, keyphrases provide a sort of quick summary of a document. This can be exploited not only in automatic summarization tasks, but also to enable quick topic search over a number of documents indexed according to their keywords, which is more precise and efficient than full-text search. Once the keywords of a document collection are known, they can also be used to calculate semantic similarity between documents and to cluster the texts according to such similarity (Ricca et al, 2004). Also, keyword extraction can be used as an intermediate step for automatic sense extraction (Jones et al, 2002). For these reasons, the keyphrase extraction task proposed at SemEval 2010 raised much attention among NLP researchers, with 20 groups participating to the competition. In this framework, we presented the KX system, specifically tuned to identify keyphrases in scientific articles. In particular, the challenge comprised two subtasks: the extraction of reader-assigned and of author-assigned keyphrases in scientific articles from the ACM digital library. The former are assigned to the</context>
</contexts>
<marker>Ricca, Tonella, Girardi, Pianta, 2004</marker>
<rawString>Ricca, F., Tonella, P., Girardi, C and Pianta, E. 2004. An empirical study on Keyword-based Web Site Clustering. In Proceedings of the 12th IWPC.</rawString>
</citation>
<citation valid="false">
<note>PorterStemmer: http://tartarus.org/~martin/PorterStem mer/perl.txt.</note>
<marker></marker>
<rawString>PorterStemmer: http://tartarus.org/~martin/PorterStem mer/perl.txt.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>