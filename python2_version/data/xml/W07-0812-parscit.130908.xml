<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.974872">
Improved Arabic Base Phrase Chunking with a new enriched POS tag set
</title>
<author confidence="0.994632">
Mona T. Diab
</author>
<affiliation confidence="0.997072">
Center for Computational Learning Systems
Columbia University
</affiliation>
<email confidence="0.998683">
mdiab@cs.columbia.edu
</email>
<sectionHeader confidence="0.993878" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999874714285714">
Base Phrase Chunking (BPC) or shallow
syntactic parsing is proving to be a task of
interest to many natural language processing
applications. In this paper, A BPC system
is introduced that improves over state of the
art performance in BPC using a new part of
speech tag (POS) set. The new POS tag set,
ERTS, reflects some of the morphological
features specific to Modern Standard Ara-
bic. ERTS explicitly encodes definiteness,
number and gender information increasing
the number of tags from 25 in the standard
LDC reduced tag set to 75 tags. For the BPC
task, we introduce a more language specific
set of definitions for the base phrase anno-
tations. We employ a support vector ma-
chine approach for both the POS tagging and
the BPC processes. The POS tagging per-
formance using this enriched tag set, ERTS,
is at 96.13% accuracy. In the BPC exper-
iments, we vary the feature set along two
factors: the POS tag set and a set of explic-
itly encoded morphological features. Us-
ing the ERTS POS tagset, BPC achieves the
highest overall FO=1 of 96.33% on 10 dif-
ferent chunk types outperforming the use of
the standard POS tag set even when explicit
morphological features are present.
</bodyText>
<sectionHeader confidence="0.999333" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999907025">
Base Phrase Chunking (BPC), also known as shal-
low syntactic parsing, is the process by which ad-
jacent words are grouped together to form non-
recursive chunks in a sentence. The base chunks
form phrases such as verb phrases, noun phrases
and adjective phrases, etc. An English example of
base phrases is [I]NP [would eat]V P [red luscious
apples]NP [on Sundays]PP . The BPC task is prov-
ing to be an enabling step that is useful to many nat-
ural language processing (NLP) applications such
as information extraction and semantic role label-
ing (Hacioglu &amp; Ward, 2003). In English, these ap-
plications have shown robust relative performance
when exploiting BPC when compared to using full
syntactic parses. In general, BPC is appealing as
an enabling technology since state of the art perfor-
mance for BPC is higher (FO=1 95.48%) than that
for full syntactic parsing (FO=1 90.02% ) in English
(Collins, 2000; Kudo &amp; Matsumato, 2000). More-
over, since BPC had been cast as a classification
problem by Ramshaw and Marcus (1995), the task
is performed with greater efficiency and is easily
portable to new languages in a supervised manner
(Diab et al., 2004; Diab et al., 2007). For Arabic,
BPC is especially interesting as it constitutes a vi-
able alternative to full syntactic parsing due to the
low performance in Arabic full syntactic parsing (la-
beled FO=1 = —80% compared to FO=1=91.44% for
BPC) (Bikel, 2004; Diab et al., 2007; Kulick et al.,
2006).
In this paper, we present a support vector machine
(SVM) based supervised method for Arabic BPC.
The new BPC system achieves an FO=1 of 96.33%
across 10 base phrase chunk types. We vary the
feature sets along two different factors: the usage
of explicit morphological features, and the use of
different part of speech (POS) tag sets. We intro-
duce a new enriched POS set for Arabic which com-
prises 75 POS tags. The new POS tag set enriches
the standard reduced POS tag set (RTS), distributed
</bodyText>
<page confidence="0.99725">
89
</page>
<note confidence="0.9202165">
Proceedings of the 5th Workshop on Important Unresolved Matters, pages 89–96,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999913761904762">
with the LDC Arabic Treebank (ATB) (Maamouri
et al., 2004), by adding definiteness, gender and
number information to the basic RTS. We devise
an automatic POS tagger based on the enriched tag
set, ERTS. We use the same unified discriminative
model approach to both POS tagging and BPC. The
POS tagging results using ERTS are comparable to
state of the art POS tagging using RTS with an ac-
curacy of 96.13% for ERTS and 96.15% for RTS.
However, using the ERTS as a feature in the BPC
task, we note an overall significant increase of 1%
absolute F0_1 improvement over the usage of RTS
alone. Moreover, we experiment with different ex-
plicit morphological features together with the dif-
ferent POS tag sets with no significant improvement.
The paper is laid out as follows: Section 2 dis-
cusses state of the art related work in the field of
BPC in both English and Arabic; Section 3 illus-
trates our approach for both POS and BPC in de-
tail; Section 4 presents the experimental setup, re-
sults and discussions.
</bodyText>
<sectionHeader confidence="0.999691" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.965697458333333">
English BPC has made a lot of head way in recent
years. It was first cast as a classification problem
by Ramshaw and Marcus (1995), as a problem of
NP chunking. Then it was extended to include other
types of base phrases by Sang and Buchholz (2000)
in the CoNLL 2000 shared task. Most successful ap-
proaches are based on machine learning techniques
and sequence modeling of the different labels as-
sociated with the chunks. Both generative algo-
rithms such as HMMs and multilevel Markov mod-
els, as well as, discriminative methods such as Sup-
port Vector Machines (SVM) and conditional ran-
dom fields have been used for the BPC task. The
closest relevant approach to the current investigation
is the work of Kudo and Matsumato (2000) (KM00)
on using SVMs and a sequence model for chunking.
A la Ramshaw and Marcus (1995), they represent
the words as a sequence of labeled words with IOB
annotations, where the B marks a word at the begin-
ning of a chunk, I marks a word inside a chunk, and
O marks those words (and punctuation) that are out-
side chunks. The IOB annotation scheme for the En-
glish example described earlier is illustrated in Table
1.
</bodyText>
<table confidence="0.9991268">
word IOB label
I B-NP
would B-VP
eat I-VP
red B-NP
luscious I-NP
apples I-NP
on B-PP
Sundays I-PP
. O
</table>
<tableCaption confidence="0.99977">
Table 1: IOB annotation example
</tableCaption>
<bodyText confidence="0.999135066666667">
KM00 develop a sequence model, YAMCHA, over
the labeled sequences of words.1 YAMCHA is based
on the TinySVM algorithm (Joachims, 1998). They
use a degree 2 polynomial kernel. In their work on
the task of English BPC, YAMCHA achieves an over-
all F&apos;3_1 of 93.48% on five chunk types. They report
improved results of 93.91% using a combined voting
scheme (Kudo &amp; Matsumato, 2000).
As far as Arabic BPC, Diab et al. (2004 &amp; 2007)
adopt the KM00 model for Arabic using YAMCHA.
They cast the Arabic data from the ATB in the IOB
annotation scheme. They use the reduced standard
LDC tag set, RTS, as their only feature. Their sys-
tem achieves an overall F&apos;3_1 of 91.44% on 9 chunk
types.
</bodyText>
<sectionHeader confidence="0.948452" genericHeader="method">
3 Current Approach
</sectionHeader>
<bodyText confidence="0.999899266666667">
This paper is a significant extension to the Diab et
al. (2007) work. Similar to other researchers in the
area of BPC, we adopt a discriminative approach.
A la Ramshaw and Marcus (1995), and Kudo and
Matsumato (2000), we use the IOB tagging style for
modeling and classification.
Various machine learning approaches have been
applied to POS and BPC tagging, by casting them as
classification tasks. Given a set of features extracted
from the linguistic context, a classifier predicts the
POS or BPC class of a token. SVMs (Vapnik, 1995)
are one such supervised machine learning algorithm,
with the advantages of: discriminative training, ro-
bustness and a capability to handle a large number of
(overlapping) features with good generalization per-
</bodyText>
<footnote confidence="0.703768">
lhttp://www.chasen.org/ taku/software/yamcha/
</footnote>
<page confidence="0.990992">
90
</page>
<bodyText confidence="0.990979875">
formance. Consequently, SVMs have been applied
in many NLP tasks with great success (Joachims,
1998; Hacioglu &amp; Ward, 2003).
We adopt a unified tagging perspective for both
the POS tagging and the BPC tasks. We address
them using the same SVM experimental setup which
comprises a standard SVM as a multi-class classifier
(Allwein et al., 2000).
A la KM00, we use the YAMCHA sequence model
on the SVMs to take advantage of the context of the
items being compared in a vertical manner in addi-
tion to the encoded features in the horizontal input
of the vectors. Accordingly, in our different tasks,
we define the notion of context to be a window of
fixed size around the segment in focus for learning
and tagging.
</bodyText>
<subsectionHeader confidence="0.997145">
3.1 POS Tagging
</subsectionHeader>
<bodyText confidence="0.999961714285714">
Modern Standard Arabic is a rich morphological
language, where words are explicitly marked for
case, gender, number, definiteness, mood, person,
voice, tense and other features. These morpholog-
ical features are explicitly encoded in the full tag
set provided in the ATB. These full morphological
tags amount to over 2000 tag types (FULL). As ex-
pected, such morphological tags are not very use-
ful for automatic statistical syntactic parsing since
they are extremely sparse.2 Hence, the LDC intro-
duced the reduced tag set (RTS) of 25 tags. RTS
masks case, mood, gender, person, definiteness for
all categories. It maintains voice and tense for verbs,
and some number information for nouns, namely,
marking plural vs. singular for nouns and proper
nouns. Therefore, in the process it masks duality for
nouns and number for all adjectives. It should be
noted, however, that it is extremely useful to have
these morphological tags in order to induce features.
There exists a system that produces the full morpho-
logical POS tag set, MADA, with very high accu-
racy, 96% (Habash &amp; Rambow, 2005).
In this work, we introduce a new tag set that ex-
plicitly marks gender, number, and definiteness for
nominals (namely, nouns, proper nouns, adjectives
and pronouns). Verbs, particles, as well as, the per-
son feature on pronouns, are not affected by this en-
richment process, since neither person nor mood are
</bodyText>
<footnote confidence="0.404567">
2Dan Bikel, personal communication.
</footnote>
<bodyText confidence="0.99996259375">
explicitly encoded. Morphological case is also not
explicitly encoded in ERTS. The new tag set, ERTS,
is derived from the FULL tag set where there is an
explicit specification in the tag itself for the different
features to be encoded. We restricted ERTS to this
set of features as they tend to be explicitly marked
in the surface form of unvowelized Arabic text. In
ERTS, definiteness is encoded with a present (D)
or an absent one. Gender is encoded with an F or
an M, corresponding to Fem and Masc, respectively.
Number is encoded with (Du) for dual or an (S) for
plurals or the absence of any marking for singular.
For example, Table 2 illustrates some words with
the FULL morphological tag and their correspond-
ing RTS and ERTS definitions.3
Our approach: ERTS comprises 75 tags. For the
current system, only 57 tags are instantiated. We
develop a POS tagger based on this new set. We
adopt the YAMCHA sequence model based on the
TinySVM classifier. The tagger trained for ERTS
tag set uses lexical features of +/-4 character n-
grams from the beginning and end of a word in
focus. The context for YAMCHA is defined as +/-
2 words around the focus word. The words be-
fore the focus word are considered with their ERTS
tags. The kernel is a polynomial degree 2 kernel.
We adopt the one-vs-all approach for classification,
where the tagged examples for one class are con-
sidered positive training examples and instances for
other classes are considered negative examples. We
present results and a brief discussion of the POS tag-
ging performance in Section 4.
</bodyText>
<subsectionHeader confidence="0.999934">
3.2 Base Phrase Chunking
</subsectionHeader>
<bodyText confidence="0.999870909090909">
In this task, we use a setup similar to that of Kudo
&amp; Matsumato (2000) and Diab et al. (2004 &amp; 2007),
with the IOB annotation representation: Inside I a
phrase, Outside O a phrase, and Beginning B of a
phrase. However, we designate 10 types of chunked
phrases. The chunk phrases identified for Arabic
are ADJP, ADVP, CONJP, INTJP, NP, PP, PREDP,
PRTP, SBARP, VP. Thus the task is a one of 21 clas-
sification task (since there are I and B tags for each
chunk phrase type, and a single O tag). The 21
IOB tags are listed: {O, I-ADJP, B-ADJP, I-ADVP,
</bodyText>
<footnote confidence="0.982484">
3All the romanized Arabic is presented in the Buckwalter
transliteration scheme (Buckwalter, 2002).
</footnote>
<page confidence="0.991456">
91
</page>
<table confidence="0.999834">
Gloss FULL RTS ERTS
HSylp ‘outcome’ NOUN+NSUFF FEM SG+CASE IND NOM NN NNF
nhA}yp ‘final’ ADJ+NSUFF FEM SG+CASE IND NOM JJ JJF
HAdv ‘accident’ NOUN+CASE DEF ACC NN NNM
AlnAr ‘the-fire’ DET+NOUN+CASE DEF GEN NN DNNM
AljmAEy ‘group’ DET+ADJ+CASE DEF GEN JJ DJJM
$xSyn ‘two persons’ NOUN+NSUFF MASC DU GEN NN NNMDu
</table>
<tableCaption confidence="0.991368">
Table 2: Examples of POS tag sets RTS, ERTS and FULL
</tableCaption>
<construct confidence="0.610065333333333">
B-ADVP, I-CONJP, B-CONJP, I-INTJP, B-INTJP, I-
NP, B-NP, I-PP, B-PP, I-PREDP, B-PREDP, I-PRTP,
B-PRTP, I-SBARP, B-SBARP, I-VP, B-VP}.
</construct>
<bodyText confidence="0.999433142857143">
The training data is derived from the ATB using
the ChunkLink software.4 ChunkLink flattens
the tree to a sequence of base (non-recursive) phrase
chunks with their IOB labels. For example, a to-
ken occurring at the beginning of a noun phrase is
labeled as B-NP. The following Table 3 Arabic ex-
ample illustrates the IOB annotation scheme:
</bodyText>
<table confidence="0.9993005">
Tags B-VP B-NP I-NP O
Arabic .
Translit wqE msA’ AljmEp .
Gloss happened night the-Friday .
</table>
<tableCaption confidence="0.999834">
Table 3: An Arabic IOB annotation example
</tableCaption>
<bodyText confidence="0.998962285714286">
Chunklink, however, is tailored for English
syntactic structures. Hence, in order to train on rea-
sonable Arabic chunks, we modify Chunklink’s
output using linguistic knowledge of Arabic syntac-
tic structures. Some of the rules used are described
below (we illustrate using ERTS for ease of exposi-
tion).
</bodyText>
<listItem confidence="0.9944305">
• IDAFA: This syntactic structure marks posses-
sion in Arabic. It is syntactically the case where
an indefinite noun is followed by a definite one.
The Chunklink output is modified to ensure that
they form a single NP. Example: msA’
AljmEp ‘night of Friday’ is IOB annotated as [msA‘
DNN B-NP, AljmEp DNNM I-NP].
• NOUN-ADJ: Nouns followed by adjectives and
they agree in their morphological features of gender,
number and definiteness form a single NP chunk.
</listItem>
<footnote confidence="0.953016">
4http://ilk.uvt.nl/ sabine/chunklink
</footnote>
<bodyText confidence="0.443927333333333">
Example: HSylp nhA}yp rsmyp
‘final official outcome’ is IOB annotated as [HSylp
NNF B-NP, nhA}yp JJF I-NP, rsmyp JJF I-NP]
</bodyText>
<listItem confidence="0.996746928571429">
• Pronouns: This is an artifact of the ATB style
of clitic tokenization. All pronouns, except in nom-
inative position in the sentence such as hw and hy,
are chunk internal.
• Interjections: If an interjection is followed by
a noun, the noun is marked as internal to the inter-
jective phrase.
• Prepositional Phrases: Nouns following
prepositions are considered internal to the preposi-
tional phrase and are IOB annotated, I-PP.
Phrase Types: The different phrase types are de-
scribed as follows.
• ADJP: This is an adjectival phrase. The ad-
jectival phrase could comprise a single adjective if
</listItem>
<bodyText confidence="0.9200945">
mentioned in isolation such as jydA ‘well’, or
multiple words such as qrybA jdA ‘very
soon’. The latter is IOB annotated [qrybA B-ADJP]
and [jdA I-ADJP], respectively.
</bodyText>
<listItem confidence="0.762570833333334">
• ADVP: This is an adverbial phrase. It may com-
prise a single adverb following a verb, such as
sryEA ‘quickly’, or multiple words such as
lkn hA ‘but she’.5 The latter is IOB annotated [lkn
B-ADVP] and [hA I-ADVP], respectively.
• CONJP: This chunk marks conjunctive
</listItem>
<bodyText confidence="0.522087333333333">
phrases. We see single word CONJP when the con-
junction appears before a verb phrase or a preposi-
tional phrase such the conjunction w ‘and’. But
we also have multiword conjunctive phrases when
the conjunction is followed by a noun. For instance,
w AlflsTynywn ‘and the Palestinians’
</bodyText>
<footnote confidence="0.992461">
5This is a result of the ATB clitic tokenization style.
</footnote>
<page confidence="0.987061">
92
</page>
<bodyText confidence="0.706078">
is IOB annotated [w B-CONJP] and [AlflsTynywn I-
CONJP].
</bodyText>
<listItem confidence="0.9679005">
• INTJP: This is an interjective phrase. The in-
terjective phrase could comprise a single interjection
</listItem>
<bodyText confidence="0.94826275">
if mentioned in isolation such as nEm ‘yes’. Or
with multiple words such as yA Axt ‘Oh sis-
ter’, where it is IOB annotated [yA B-INTJP] and
[Axt I-INTJP].
</bodyText>
<listItem confidence="0.80145375">
• NP: This is a noun phrase. It may comprise a
single noun or multiple nouns or a noun and one or
more adjectives. In this phrase type, we see typi-
cal noun adjective constructions as in
</listItem>
<bodyText confidence="0.99552275">
AlzfAfAljmAEy ‘the group wedding’, where the ini-
tial noun is marked as [AlzfAf B-NP], and the folow-
ing adjective is IOB annotated [AljmAEy I-NP]. We
also encounter idafa constructions. For example,
mlk AlArdn ‘king of Jordan’, where mlk
‘king’ is an indefinite noun, and AlArdn ‘Jordan’ is
a definite one. This phrase is IOB annotated [mlk
B-NP] and [AlArdn I-NP].
</bodyText>
<listItem confidence="0.892561">
• PP: This is a prepositional phrase. The phrase
</listItem>
<bodyText confidence="0.9833454">
starts with a preposition followed by a pronoun,
noun or proper noun. If the noun or proper noun is it-
self the beginning of an NP, the whole NP is internal
to the PP. For example,
xlAl Hfl AlzfAfAljmAEy ‘during the group wedding
party’, xlAl is the preposition and is IOB annotated
[xlAl B-PP], [Hfl I-PP] (if Hfl were not preceded by
a preposition it would have been annotated [Hfl B-
NP]), then for the noun [AlzfAf I-PP], and finally the
adjective [AljmAEy I-PP].
</bodyText>
<listItem confidence="0.998917">
• PREDP: This is a predicative phrase. It
</listItem>
<bodyText confidence="0.886970444444445">
typically begins with a particle An ‘[is]’,
followed by a noun phrase. For example,
An AlASlAH Al-
dyny mhmp Almjddyn ‘religious improvement is the
reformers’ task’. In our data, since we do not mark
recursive structures in this BPC level, only the pred-
icative particle is IOB annotated with B-PREDP. If it
were followed by a possessive pronoun, the pronoun
is annotated I-PREDP.
</bodyText>
<listItem confidence="0.949622555555556">
• PRTP: This phrase type marks particles such as
negative particles that precede both nouns and verbs.
A particle could be single word or a complex particle
phrase. An example of a simple word particle is lm
‘not’, and a complex one is lA sy—mA ‘not
as long’. In the latter case, it is IOB annotated [lA
B-PRTP] and [sy—mA I-PRTP].
• SBARP: This phrase structure marks the sub-
junctive constructions. SBARP phrases typically be-
</listItem>
<bodyText confidence="0.858764">
gin with a particle meaning ‘that’ such as An or
mmA or Al*y followed by a verb phrase.
</bodyText>
<listItem confidence="0.6335136">
• VP: This is a verb phrase. VP phrases are typ-
ically headed by a verb. All object pronouns pro-
ceeding a verb are IOB annotated I-VP. Moreover,
we observe cases where a VP is headed by nominals
(nouns and adjectives, in particular). The majority
of these nominals are the active participle. The ac-
tive participle in the ATB is tagged as an adjective.
Active participles in Arabic are equivalent to pred-
icative nominals in English (gerunds). Hence, some
VPs are headed by JJs. An example active partici-
</listItem>
<bodyText confidence="0.971294">
ple heading a verb phrase in our data is mthmA
‘accusing’.
Our Approach: We vary two factors in our fea-
ture sets: the POS tag set, and the presence or ab-
sence of explicit morphological features. We have
three possible tag sets: RTS, ERTS and the full mor-
phological tag set (FULL). We define a set of 6
morphological features (and their possible values):
CASE (ACC, GEN, NOM, NULL), MOOD (Indica-
tive, Jussive, Subjunctive, NULL), DEF (DEF, IN-
DEF, NULL), NUM (Sing, Dual, Plural, NULL),
GEN (Fem, Masc, NULL), PER (1, 2, 3, NULL).
From the intersection of the two factors, we devise
10 different experimental conditions. The condi-
tions always have one of the POS tag sets and either
no explicit features (noFeat), all explicit features
(allFeat), or some selective features of: case mood
and person (CASE MOOD PER), or definiteness
gender and number (DEF GEN NUM). Therefore,
the experimental conditions are as follows: RTS-
noFeat, RTS-allFeat, RTS-CASE MOOD PER,
RTS-DEF GEN NUM, ERTS-noFeat, ERTS-
allFeat, ERTS-CASE MOOD PER, ERTS-
DEF GEN NUM, FULL-noFeat, FULL-allFeat.
The BPC context is defined as a window of +/−2
tokens centered around the focus word where all the
features for the specific condition are used and the
tags for the previous two tokens before the focus to-
ken are also considered.
</bodyText>
<page confidence="0.996363">
93
</page>
<sectionHeader confidence="0.315577" genericHeader="method">
4 Experiments and Results training data, the token is assigned the NN tag as a
</sectionHeader>
<subsectionHeader confidence="0.462078">
4.1 Data default tag.
</subsectionHeader>
<bodyText confidence="0.999362454545455">
The dev, test and training data are obtained from
ATB1v3, ATB2v2 and ATB3v2 (Maamouri et
al., 2004). We adopt the same data splits intro-
duced by Chiang et. al (2006). The corpora are all
news genre. The total development data comprises
2304 sentences and 70188 tokens, the total training
data comprises 18970 sentences and 594683 tokens,
and the total test data comprises 2337 sentences and
69665 tokens.
We use the unvocalized Buckwalter transliterated
version of the ATB. For both POS tagging and BPC,
we use the gold annotations of the training and test
data for preprocessing. Hence, for POS tagging, the
training and test data are both gold tokenized in the
ATB clitic tokenization style. And for BPC, the POS
tags, the morphological features, and, the tokeniza-
tion is all gold. We derive the gold ERTS determin-
istically from the FULL set for the BPC results re-
ported here.
The IOB annotations on the training and gold
evaluation data are derived using Chunklink fol-
lowed by our linguistic fixes described in Section 3.
</bodyText>
<subsectionHeader confidence="0.992544">
4.2 SVM Setup
</subsectionHeader>
<bodyText confidence="0.9998865">
We use the default values for YAMCHA with the C
parameter set to 0.5. It has a degree 2 polynomial
kernel. YAMCHA adopts a one-vs-all binarization
method.
</bodyText>
<subsectionHeader confidence="0.998646">
4.3 Evaluation Metric
</subsectionHeader>
<bodyText confidence="0.99945875">
Standard metrics of Accuracy (Acc.), Precision, Re-
call, and F-measure F,3=1, on the test data are uti-
lized. For both POS tagging and BPC, we use the
CoNLL shared task evaluation tools.6
</bodyText>
<sectionHeader confidence="0.807362" genericHeader="method">
4.4 Results
4.4.1 ERTS POS Tagging Results
</sectionHeader>
<bodyText confidence="0.994181142857143">
Table 4 shows the results obtained with the YAM-
CHA based POS tagger, POS-TAG, and the results
obtained with a simple baseline, BASELINE. BASE-
LINE is a supervised baseline, where the most fre-
quent POS tag associated with a token from the
training data is assigned to it in the test set, regard-
less of context. If the token does not occur in the
</bodyText>
<footnote confidence="0.962985">
6http://cnts.uia.ac.be/conll2003/ner/bin/conlleval
</footnote>
<table confidence="0.65896275">
POS tagset Acc.%
RTS 96.15
ERTS 96.13
BASELINE 86.5
</table>
<tableCaption confidence="0.943733">
Table 4: Results of POS-TAG on two different tag
sets RTS and ERTS
</tableCaption>
<bodyText confidence="0.999765823529412">
POS-TAG clearly outperforms the most frequent
baseline. Looking closely at the data, the worst ob-
tained results are for the NO FUNC category, as it
is randomly confusable with almost all POS tags.
Then, the imperative verbs are mostly confused with
passive verbs 50% of the time, however the test data
only comprises 8 imperative verbs. VBN, passive
verbs, yields an accuracy of 68% only. It is worth
noting that the most frequent baseline for VBN is
21%. VBN is a most difficult category to discern
in the absence of the passivization diacritic which is
naturally absent in unvowelized text (our experimen-
tal setup). The overall performance on the nouns and
adjectives is relatively high. However, confusing
these two categories is almost always present due
to the inherent ambiguity. In fact, almost all Arabic
adjectives could be used as nouns in Arabic.7
</bodyText>
<subsectionHeader confidence="0.936152">
4.4.2 Base Phrase Chunking (BPC)
</subsectionHeader>
<bodyText confidence="0.99944275">
Table 5 illustrates the overall obtained results by
our BPC system over the different experimental con-
ditions.
The overall results for all the conditions signif-
icantly outperform state of the art published results
on Arabic BPC of F,3=1=91.44% in Diab et al. (2004
&amp; 2007). This is mainly attributed to the better
quality annotations associated with tailoring of the
Chunklink IOB annotations to the Arabic lan-
guage characteristics.
All the F&apos;3=1 results yielded by ERTS POS tag
set outperform their counterparts using the RTS POS
tagset. In fact, ERTS-noFeat condition outperforms
all other conditions in our experiments.
We note that adding morphological features to
the RTS POS tag set helps the performance slightly
</bodyText>
<footnote confidence="0.995496">
7This inherent ambiguity leads to inconsistency in the ATB
gold annotations.
</footnote>
<page confidence="0.99554">
94
</page>
<table confidence="0.9999245">
Condition Fβ=1 Condition Fβ=1
RTS-noFeat 95.41 ERTS-noFeat 96.33
RTS-CASE MOOD PER 95.73 ERTS-CASE MOOD PER 96.32
RTS-DEF GEN NUM 95.8 ERTS-DEF GEN NUM 96.33
RTS-allFeat 95.97 ERTS-allFeat 96.25
FULL-noFeat 96.29 FULL-allFeat 96.22
</table>
<tableCaption confidence="0.999274">
Table 5: Overall Fβ=1 % results yielded for the different BPC experimental conditions
</tableCaption>
<bodyText confidence="0.999397754098361">
as we see a sequence of small jumps in perfor-
mance from RTS-noFeat (95.41%) to RTS-allFeat
(95.97%). However adding these features to the
ERTS and FULL conditions does not help. In fact, in
both the allFeat conditionsfor both ERTS and FULL,
we note a slight decrease. The ERTS condition per-
formance goes down from 96.33% (ERTS-noFeat)
to 96.25% (ERTS-allFeat), and the FULL condi-
tion performance goes down from 96.29% (FULL-
noFeat) to 96.22% (FULL-allFeat). This suggests
that the features are not adding much information
over and above what is already encoded in the POS
tag set, and, in fact adding the explicit morphologi-
cal features might be adding noise.
There is no significant difference between using
ERTS and FULL in the overall results. However, we
note that ERTS conditions slightly outperform the
FULL conditions. This may be attributed the consis-
tency introduced by ERTS over FULL, i.e., if FULL
is not consistent in assigning CASE or MOOD or
PER, for instance, ERTS, being insensitive to these
features masks these inconsistencies present in the
FULL tag set.
RTS-DEF GEN NUM may be viewed as an ex-
plicit encoding of the features in ERTS-noFeat, how-
ever, ERTS-noFeat outperforms it. Explicitly encod-
ing the CASE MOOD and PER features does not
help ERTS, in fact we see a slight drop in overall
performance. However, upon closer inspection of
the results per phrase type, we note slight relative
improvement on PRTP and VP chunk types perfor-
mance when the CASE, MOOD and PER are ex-
plicitly encoded. In ERTS-CASE MOOD PER, VP
yields an Fβ=1 of 99.3% and PRTP yields 97.2%,
corresponding to ERTS-noFeat where VP yields an
Fβ=1 of 99.2% and PRTP an Fβ=1 of 96.8%.
To better assess the quality of the performance
and impact of the new POS tag set, we examine
closely in Table 6 the phrase types directly affected
by the added information whether encoded in the
POS tag set or explicitly used as independent fea-
tures. These phrase types are the ADJP, INTJP, NP
and PP. The PP scored highly across the board with
Fβ=1 over 99% for all conditions, hence, it is not
included in Table 6.
Table 6: Fβ=1 Results for ADJP, INTJP, and NP,
across the different experimental conditions
As illustrated in Table 6, ERTS outperforms RTS
and FULL in all corresponding conditions where
they have similar corresponding morphological fea-
ture settings. ERTS-noFeat yields better results than
RTS-noFeat and FULL-noFeat for the three differ-
ent phrase types. The INTJP phrase is the worst
performing of the three phrase types, however it
marks the most significant change in performance
depending on the experimental condition. We note
that adding explicit morphological features to the
base condition RTS yields consistently better re-
sults for the three phrase types. The highest per-
formance for NP is yielded by ERTS-noFeat and
ERTS-DEF GEN NUM with an Fβ=1 of 94.92%.
</bodyText>
<table confidence="0.967961090909091">
Condition ADJP INTJP NP
RTS-noFeat 68.42 55.17 92.98
RTS-CASE MOOD PER 69.47 59.26 93.72
RTS-DEF GEN NUM 71.57 64.29 93.71
RTS-allFeat 72.22 57.14 94.15
ERTS-noFeat 72.35 57.14 94.92
ERTS-CASE MOOD PER 73.16 61.54 94.86
ERTS-DEF GEN NUM 72.6 64.29 94.92
ERTS-allFeat 72.91 59.26 94.78
FULL-noFeat 71.84 51.85 94.81
FULL-allFeat 72.52 57.14 94.67
</table>
<page confidence="0.997293">
95
</page>
<bodyText confidence="0.999961142857143">
The highest scores yielded for ADJP (73.16) and IN-
TJP (64.29) are in an ERTS experimental condition.
We also observe a slight drop in performance in NP
for the ERTS conditions when the CASE MOOD
and PER features are added. This might be due to
the inconsistent or confusable assignment of these
different features in the ATB.
</bodyText>
<sectionHeader confidence="0.998104" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999973521739131">
In this paper, we address the problem of Arabic base
phrase chunking, BPC. In the process, we introduce
a new enriched POS tag set, ERTS, that adds def-
initeness, gender and number information to nomi-
nals. We present an SVM approach to both the POS
tagging with ERTS and the BPC tasks. The POS
tagger yields 96.13% accuracy which is comparable
to the results obtained on the standard reduced tag
set RTS. On the BPC front, the results obtained for
all conditions are significantly better than state of
the art published results. This indicates that better
linguistic tailoring of the IOB chunks creates more
consistent data. Overall, we show that using the en-
riched POS tag set, ERTS, yields the best BPC per-
formance. Even using ERTS with no explicit mor-
phological features yields better results than using
RTS in all conditions with or without explicit mor-
phological features. These results are confirmed by
closely observing specific phrases that are directly
affected by the change in POS tag set namely, ADJP,
INTJP and NP. Our results strongly suggests that
choosing the POS tag set carefully has a significant
impact on higher level syntactic processing.
</bodyText>
<sectionHeader confidence="0.999457" genericHeader="acknowledgments">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.9985485">
This work was funded by DARPA Contract No. HR0011-06-C-
0023. Any opinions, findings and conclusions or recommenda-
tions expressed in this material are those of the author and do
not necessarily reflect the views of DARPA.
</bodyText>
<sectionHeader confidence="0.999435" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999798508196721">
Erin L. Allwein, Robert E. Schapire, and Yoram Singer.
2000. Reducing multiclass to binary: A unifying ap-
proach for margin classifiers. Journal of Machine
Learning Research, 1:113-141.
Daniel Bikel. 2004. Intricacies of Collins Parser. Com-
putational Linguistics.
Tim Buckwalter. 2002. Buckwalter Arabic Morphologi-
cal Analyzer Version 1.0. Linguistic Data Consortium,
University of Pennsylvania, 2002. LDC Catalog No.:
LDC2002L49
David Chiang, Mona Diab, Nizar Habash, Owen Ram-
bow, and Safiullah Shareef. 2006. Parsing Arabic Di-
alects. Proceedings of the European Chapter of ACL
(EACL).
Michael Collins. 2000. Discriminative Reranking for
Natural Language Parsing. Proceedings of the 17th
International Conference on Machine Learning.
Mona Diab, Kadri Hacioglu and Daniel Jurafsky. 2004.
Automatic Tagging of Arabic Text: From Raw Text to
Base Phrase Chunks. Proceedings of North American
Association for Computational Linguistics.
Mona Diab, Kadri Hacioglu and Daniel Jurafsky. 2007.
Automated Methods for Processing Arabic Text: From
Tokenization to Base Phrase Chunking. Book Chapter.
In Arabic Computational Morphology: Knowledge-
based and Empirical Methods. Editors Antal van den
Bosch and Abdelhadi Soudi. Kluwer/Springer Publi-
cations.
Nizar Habash and Owen Rambow. 2005. Arabic
Tokenization, Morphological Analysis, and Part-of-
Speech Tagging in One Fell Swoop. Proceedings of
the Conference of American Association for Compu-
tational Linguistics (ACL).
Kadri Hacioglu and Wayne Ward. 2003. Target word
Detection and semantic role chunking using support
vector machines. HLT-NAACL.
Thorsten Joachims. 1998. Text Categorization with Sup-
port Vector Machines: Learning with Many Relevant
Features. Proc. of ECML-98, 10th European Conf. on
Machine Learning.
Seth Kulick, Ryan Gabbard, and Mitch Marcus. 2006.
Parsing the Arabic Treebank: Analysis and Improve-
ments. in Treebanks and Linguistic Theories.
Taku Kudo and Yuji Matsumato. 2000. Use of support
vector learning for chunk identification. Proc. of the
4th Conf. on Very Large Corpora, pages 142-144.
Mohamed Maamouri, Ann Bies, Tim Buckwalter, and
Wigdan Mekki. 2004. The Penn Arabic Treebank
: Building a Large-Scale Annota ted Arabic Corpus.
NEMLAR Conference on Arabic Language Resources
and Tools. pp. 102-109.
Lance A. Ramshaw and Mitchell P. Marcus. 1995.
Text Chunking using transformational based learning.
Proc. of the 3rd ACL workshop on Very Large Corpora
Erik Tjong, Kim Sang, and Sabine Buchholz. 2000. In-
troduction to the CoNLL-2000 shared task: Chunking.
Proc. of the 4th Conf. on Computational Natural Lan-
guage Learning (CoNLL), Lisbon, Portugal, 2000, pp.
127-132.
Vladamir Vapnik. 1995. The Nature of Statistical Learn-
ing Theory. Springer Verlag, New York, USA.
</reference>
<page confidence="0.998447">
96
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.851330">
<title confidence="0.989759">Improved Arabic Base Phrase Chunking with a new enriched POS tag set</title>
<author confidence="0.999562">T Mona</author>
<affiliation confidence="0.935662">Center for Computational Learning Columbia</affiliation>
<email confidence="0.99984">mdiab@cs.columbia.edu</email>
<abstract confidence="0.999556620689655">Base Phrase Chunking (BPC) or shallow syntactic parsing is proving to be a task of interest to many natural language processing applications. In this paper, A BPC system is introduced that improves over state of the art performance in BPC using a new part of speech tag (POS) set. The new POS tag set, ERTS, reflects some of the morphological features specific to Modern Standard Arabic. ERTS explicitly encodes definiteness, number and gender information increasing the number of tags from 25 in the standard LDC reduced tag set to 75 tags. For the BPC task, we introduce a more language specific set of definitions for the base phrase annotations. We employ a support vector machine approach for both the POS tagging and the BPC processes. The POS tagging performance using this enriched tag set, ERTS, is at 96.13% accuracy. In the BPC experiments, we vary the feature set along two factors: the POS tag set and a set of explicitly encoded morphological features. Using the ERTS POS tagset, BPC achieves the overall of 96.33% on 10 different chunk types outperforming the use of the standard POS tag set even when explicit morphological features are present.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Erin L Allwein</author>
<author>Robert E Schapire</author>
<author>Yoram Singer</author>
</authors>
<title>Reducing multiclass to binary: A unifying approach for margin classifiers.</title>
<date>2000</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>1--113</pages>
<contexts>
<context position="7589" citStr="Allwein et al., 2000" startWordPosition="1295" endWordPosition="1298"> SVMs (Vapnik, 1995) are one such supervised machine learning algorithm, with the advantages of: discriminative training, robustness and a capability to handle a large number of (overlapping) features with good generalization perlhttp://www.chasen.org/ taku/software/yamcha/ 90 formance. Consequently, SVMs have been applied in many NLP tasks with great success (Joachims, 1998; Hacioglu &amp; Ward, 2003). We adopt a unified tagging perspective for both the POS tagging and the BPC tasks. We address them using the same SVM experimental setup which comprises a standard SVM as a multi-class classifier (Allwein et al., 2000). A la KM00, we use the YAMCHA sequence model on the SVMs to take advantage of the context of the items being compared in a vertical manner in addition to the encoded features in the horizontal input of the vectors. Accordingly, in our different tasks, we define the notion of context to be a window of fixed size around the segment in focus for learning and tagging. 3.1 POS Tagging Modern Standard Arabic is a rich morphological language, where words are explicitly marked for case, gender, number, definiteness, mood, person, voice, tense and other features. These morphological features are expli</context>
</contexts>
<marker>Allwein, Schapire, Singer, 2000</marker>
<rawString>Erin L. Allwein, Robert E. Schapire, and Yoram Singer. 2000. Reducing multiclass to binary: A unifying approach for margin classifiers. Journal of Machine Learning Research, 1:113-141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Bikel</author>
</authors>
<date>2004</date>
<journal>Intricacies of Collins Parser. Computational Linguistics.</journal>
<contexts>
<context position="2765" citStr="Bikel, 2004" startWordPosition="466" endWordPosition="467"> for BPC is higher (FO=1 95.48%) than that for full syntactic parsing (FO=1 90.02% ) in English (Collins, 2000; Kudo &amp; Matsumato, 2000). Moreover, since BPC had been cast as a classification problem by Ramshaw and Marcus (1995), the task is performed with greater efficiency and is easily portable to new languages in a supervised manner (Diab et al., 2004; Diab et al., 2007). For Arabic, BPC is especially interesting as it constitutes a viable alternative to full syntactic parsing due to the low performance in Arabic full syntactic parsing (labeled FO=1 = —80% compared to FO=1=91.44% for BPC) (Bikel, 2004; Diab et al., 2007; Kulick et al., 2006). In this paper, we present a support vector machine (SVM) based supervised method for Arabic BPC. The new BPC system achieves an FO=1 of 96.33% across 10 base phrase chunk types. We vary the feature sets along two different factors: the usage of explicit morphological features, and the use of different part of speech (POS) tag sets. We introduce a new enriched POS set for Arabic which comprises 75 POS tags. The new POS tag set enriches the standard reduced POS tag set (RTS), distributed 89 Proceedings of the 5th Workshop on Important Unresolved Matters</context>
</contexts>
<marker>Bikel, 2004</marker>
<rawString>Daniel Bikel. 2004. Intricacies of Collins Parser. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Buckwalter</author>
</authors>
<title>Buckwalter Arabic Morphological Analyzer Version 1.0. Linguistic Data Consortium,</title>
<date>2002</date>
<institution>University of Pennsylvania,</institution>
<note>LDC Catalog No.: LDC2002L49</note>
<contexts>
<context position="11630" citStr="Buckwalter, 2002" startWordPosition="1993" endWordPosition="1994">similar to that of Kudo &amp; Matsumato (2000) and Diab et al. (2004 &amp; 2007), with the IOB annotation representation: Inside I a phrase, Outside O a phrase, and Beginning B of a phrase. However, we designate 10 types of chunked phrases. The chunk phrases identified for Arabic are ADJP, ADVP, CONJP, INTJP, NP, PP, PREDP, PRTP, SBARP, VP. Thus the task is a one of 21 classification task (since there are I and B tags for each chunk phrase type, and a single O tag). The 21 IOB tags are listed: {O, I-ADJP, B-ADJP, I-ADVP, 3All the romanized Arabic is presented in the Buckwalter transliteration scheme (Buckwalter, 2002). 91 Gloss FULL RTS ERTS HSylp ‘outcome’ NOUN+NSUFF FEM SG+CASE IND NOM NN NNF nhA}yp ‘final’ ADJ+NSUFF FEM SG+CASE IND NOM JJ JJF HAdv ‘accident’ NOUN+CASE DEF ACC NN NNM AlnAr ‘the-fire’ DET+NOUN+CASE DEF GEN NN DNNM AljmAEy ‘group’ DET+ADJ+CASE DEF GEN JJ DJJM $xSyn ‘two persons’ NOUN+NSUFF MASC DU GEN NN NNMDu Table 2: Examples of POS tag sets RTS, ERTS and FULL B-ADVP, I-CONJP, B-CONJP, I-INTJP, B-INTJP, INP, B-NP, I-PP, B-PP, I-PREDP, B-PREDP, I-PRTP, B-PRTP, I-SBARP, B-SBARP, I-VP, B-VP}. The training data is derived from the ATB using the ChunkLink software.4 ChunkLink flattens the tre</context>
</contexts>
<marker>Buckwalter, 2002</marker>
<rawString>Tim Buckwalter. 2002. Buckwalter Arabic Morphological Analyzer Version 1.0. Linguistic Data Consortium, University of Pennsylvania, 2002. LDC Catalog No.: LDC2002L49</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Mona Diab</author>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
<author>Safiullah Shareef</author>
</authors>
<title>Parsing Arabic Dialects.</title>
<date>2006</date>
<booktitle>Proceedings of the European Chapter of ACL (EACL).</booktitle>
<marker>Chiang, Diab, Habash, Rambow, Shareef, 2006</marker>
<rawString>David Chiang, Mona Diab, Nizar Habash, Owen Rambow, and Safiullah Shareef. 2006. Parsing Arabic Dialects. Proceedings of the European Chapter of ACL (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative Reranking for Natural Language Parsing.</title>
<date>2000</date>
<booktitle>Proceedings of the 17th International Conference on Machine Learning.</booktitle>
<contexts>
<context position="2264" citStr="Collins, 2000" startWordPosition="381" endWordPosition="382">base phrases is [I]NP [would eat]V P [red luscious apples]NP [on Sundays]PP . The BPC task is proving to be an enabling step that is useful to many natural language processing (NLP) applications such as information extraction and semantic role labeling (Hacioglu &amp; Ward, 2003). In English, these applications have shown robust relative performance when exploiting BPC when compared to using full syntactic parses. In general, BPC is appealing as an enabling technology since state of the art performance for BPC is higher (FO=1 95.48%) than that for full syntactic parsing (FO=1 90.02% ) in English (Collins, 2000; Kudo &amp; Matsumato, 2000). Moreover, since BPC had been cast as a classification problem by Ramshaw and Marcus (1995), the task is performed with greater efficiency and is easily portable to new languages in a supervised manner (Diab et al., 2004; Diab et al., 2007). For Arabic, BPC is especially interesting as it constitutes a viable alternative to full syntactic parsing due to the low performance in Arabic full syntactic parsing (labeled FO=1 = —80% compared to FO=1=91.44% for BPC) (Bikel, 2004; Diab et al., 2007; Kulick et al., 2006). In this paper, we present a support vector machine (SVM)</context>
</contexts>
<marker>Collins, 2000</marker>
<rawString>Michael Collins. 2000. Discriminative Reranking for Natural Language Parsing. Proceedings of the 17th International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Kadri Hacioglu</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic Tagging of Arabic Text: From Raw Text to Base Phrase Chunks.</title>
<date>2004</date>
<booktitle>Proceedings of North American Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2510" citStr="Diab et al., 2004" startWordPosition="421" endWordPosition="424">e labeling (Hacioglu &amp; Ward, 2003). In English, these applications have shown robust relative performance when exploiting BPC when compared to using full syntactic parses. In general, BPC is appealing as an enabling technology since state of the art performance for BPC is higher (FO=1 95.48%) than that for full syntactic parsing (FO=1 90.02% ) in English (Collins, 2000; Kudo &amp; Matsumato, 2000). Moreover, since BPC had been cast as a classification problem by Ramshaw and Marcus (1995), the task is performed with greater efficiency and is easily portable to new languages in a supervised manner (Diab et al., 2004; Diab et al., 2007). For Arabic, BPC is especially interesting as it constitutes a viable alternative to full syntactic parsing due to the low performance in Arabic full syntactic parsing (labeled FO=1 = —80% compared to FO=1=91.44% for BPC) (Bikel, 2004; Diab et al., 2007; Kulick et al., 2006). In this paper, we present a support vector machine (SVM) based supervised method for Arabic BPC. The new BPC system achieves an FO=1 of 96.33% across 10 base phrase chunk types. We vary the feature sets along two different factors: the usage of explicit morphological features, and the use of different</context>
<context position="6171" citStr="Diab et al. (2004" startWordPosition="1064" endWordPosition="1067">r the English example described earlier is illustrated in Table 1. word IOB label I B-NP would B-VP eat I-VP red B-NP luscious I-NP apples I-NP on B-PP Sundays I-PP . O Table 1: IOB annotation example KM00 develop a sequence model, YAMCHA, over the labeled sequences of words.1 YAMCHA is based on the TinySVM algorithm (Joachims, 1998). They use a degree 2 polynomial kernel. In their work on the task of English BPC, YAMCHA achieves an overall F&apos;3_1 of 93.48% on five chunk types. They report improved results of 93.91% using a combined voting scheme (Kudo &amp; Matsumato, 2000). As far as Arabic BPC, Diab et al. (2004 &amp; 2007) adopt the KM00 model for Arabic using YAMCHA. They cast the Arabic data from the ATB in the IOB annotation scheme. They use the reduced standard LDC tag set, RTS, as their only feature. Their system achieves an overall F&apos;3_1 of 91.44% on 9 chunk types. 3 Current Approach This paper is a significant extension to the Diab et al. (2007) work. Similar to other researchers in the area of BPC, we adopt a discriminative approach. A la Ramshaw and Marcus (1995), and Kudo and Matsumato (2000), we use the IOB tagging style for modeling and classification. Various machine learning approaches hav</context>
<context position="11077" citStr="Diab et al. (2004" startWordPosition="1894" endWordPosition="1897">d end of a word in focus. The context for YAMCHA is defined as +/- 2 words around the focus word. The words before the focus word are considered with their ERTS tags. The kernel is a polynomial degree 2 kernel. We adopt the one-vs-all approach for classification, where the tagged examples for one class are considered positive training examples and instances for other classes are considered negative examples. We present results and a brief discussion of the POS tagging performance in Section 4. 3.2 Base Phrase Chunking In this task, we use a setup similar to that of Kudo &amp; Matsumato (2000) and Diab et al. (2004 &amp; 2007), with the IOB annotation representation: Inside I a phrase, Outside O a phrase, and Beginning B of a phrase. However, we designate 10 types of chunked phrases. The chunk phrases identified for Arabic are ADJP, ADVP, CONJP, INTJP, NP, PP, PREDP, PRTP, SBARP, VP. Thus the task is a one of 21 classification task (since there are I and B tags for each chunk phrase type, and a single O tag). The 21 IOB tags are listed: {O, I-ADJP, B-ADJP, I-ADVP, 3All the romanized Arabic is presented in the Buckwalter transliteration scheme (Buckwalter, 2002). 91 Gloss FULL RTS ERTS HSylp ‘outcome’ NOUN+N</context>
<context position="22215" citStr="Diab et al. (2004" startWordPosition="3787" endWordPosition="3790">critic which is naturally absent in unvowelized text (our experimental setup). The overall performance on the nouns and adjectives is relatively high. However, confusing these two categories is almost always present due to the inherent ambiguity. In fact, almost all Arabic adjectives could be used as nouns in Arabic.7 4.4.2 Base Phrase Chunking (BPC) Table 5 illustrates the overall obtained results by our BPC system over the different experimental conditions. The overall results for all the conditions significantly outperform state of the art published results on Arabic BPC of F,3=1=91.44% in Diab et al. (2004 &amp; 2007). This is mainly attributed to the better quality annotations associated with tailoring of the Chunklink IOB annotations to the Arabic language characteristics. All the F&apos;3=1 results yielded by ERTS POS tag set outperform their counterparts using the RTS POS tagset. In fact, ERTS-noFeat condition outperforms all other conditions in our experiments. We note that adding morphological features to the RTS POS tag set helps the performance slightly 7This inherent ambiguity leads to inconsistency in the ATB gold annotations. 94 Condition Fβ=1 Condition Fβ=1 RTS-noFeat 95.41 ERTS-noFeat 96.33</context>
</contexts>
<marker>Diab, Hacioglu, Jurafsky, 2004</marker>
<rawString>Mona Diab, Kadri Hacioglu and Daniel Jurafsky. 2004. Automatic Tagging of Arabic Text: From Raw Text to Base Phrase Chunks. Proceedings of North American Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Kadri Hacioglu</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automated Methods for Processing Arabic Text: From Tokenization to Base Phrase Chunking. Book Chapter.</title>
<date>2007</date>
<booktitle>In Arabic Computational Morphology: Knowledgebased and Empirical Methods. Editors Antal</booktitle>
<publisher>Kluwer/Springer Publications.</publisher>
<contexts>
<context position="2530" citStr="Diab et al., 2007" startWordPosition="425" endWordPosition="428">u &amp; Ward, 2003). In English, these applications have shown robust relative performance when exploiting BPC when compared to using full syntactic parses. In general, BPC is appealing as an enabling technology since state of the art performance for BPC is higher (FO=1 95.48%) than that for full syntactic parsing (FO=1 90.02% ) in English (Collins, 2000; Kudo &amp; Matsumato, 2000). Moreover, since BPC had been cast as a classification problem by Ramshaw and Marcus (1995), the task is performed with greater efficiency and is easily portable to new languages in a supervised manner (Diab et al., 2004; Diab et al., 2007). For Arabic, BPC is especially interesting as it constitutes a viable alternative to full syntactic parsing due to the low performance in Arabic full syntactic parsing (labeled FO=1 = —80% compared to FO=1=91.44% for BPC) (Bikel, 2004; Diab et al., 2007; Kulick et al., 2006). In this paper, we present a support vector machine (SVM) based supervised method for Arabic BPC. The new BPC system achieves an FO=1 of 96.33% across 10 base phrase chunk types. We vary the feature sets along two different factors: the usage of explicit morphological features, and the use of different part of speech (POS</context>
<context position="6515" citStr="Diab et al. (2007)" startWordPosition="1128" endWordPosition="1131">se a degree 2 polynomial kernel. In their work on the task of English BPC, YAMCHA achieves an overall F&apos;3_1 of 93.48% on five chunk types. They report improved results of 93.91% using a combined voting scheme (Kudo &amp; Matsumato, 2000). As far as Arabic BPC, Diab et al. (2004 &amp; 2007) adopt the KM00 model for Arabic using YAMCHA. They cast the Arabic data from the ATB in the IOB annotation scheme. They use the reduced standard LDC tag set, RTS, as their only feature. Their system achieves an overall F&apos;3_1 of 91.44% on 9 chunk types. 3 Current Approach This paper is a significant extension to the Diab et al. (2007) work. Similar to other researchers in the area of BPC, we adopt a discriminative approach. A la Ramshaw and Marcus (1995), and Kudo and Matsumato (2000), we use the IOB tagging style for modeling and classification. Various machine learning approaches have been applied to POS and BPC tagging, by casting them as classification tasks. Given a set of features extracted from the linguistic context, a classifier predicts the POS or BPC class of a token. SVMs (Vapnik, 1995) are one such supervised machine learning algorithm, with the advantages of: discriminative training, robustness and a capabili</context>
</contexts>
<marker>Diab, Hacioglu, Jurafsky, 2007</marker>
<rawString>Mona Diab, Kadri Hacioglu and Daniel Jurafsky. 2007. Automated Methods for Processing Arabic Text: From Tokenization to Base Phrase Chunking. Book Chapter. In Arabic Computational Morphology: Knowledgebased and Empirical Methods. Editors Antal van den Bosch and Abdelhadi Soudi. Kluwer/Springer Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Arabic Tokenization, Morphological Analysis, and Part-ofSpeech Tagging in One Fell Swoop.</title>
<date>2005</date>
<booktitle>Proceedings of the Conference of American Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="9058" citStr="Habash &amp; Rambow, 2005" startWordPosition="1543" endWordPosition="1546">y sparse.2 Hence, the LDC introduced the reduced tag set (RTS) of 25 tags. RTS masks case, mood, gender, person, definiteness for all categories. It maintains voice and tense for verbs, and some number information for nouns, namely, marking plural vs. singular for nouns and proper nouns. Therefore, in the process it masks duality for nouns and number for all adjectives. It should be noted, however, that it is extremely useful to have these morphological tags in order to induce features. There exists a system that produces the full morphological POS tag set, MADA, with very high accuracy, 96% (Habash &amp; Rambow, 2005). In this work, we introduce a new tag set that explicitly marks gender, number, and definiteness for nominals (namely, nouns, proper nouns, adjectives and pronouns). Verbs, particles, as well as, the person feature on pronouns, are not affected by this enrichment process, since neither person nor mood are 2Dan Bikel, personal communication. explicitly encoded. Morphological case is also not explicitly encoded in ERTS. The new tag set, ERTS, is derived from the FULL tag set where there is an explicit specification in the tag itself for the different features to be encoded. We restricted ERTS t</context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>Nizar Habash and Owen Rambow. 2005. Arabic Tokenization, Morphological Analysis, and Part-ofSpeech Tagging in One Fell Swoop. Proceedings of the Conference of American Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kadri Hacioglu</author>
<author>Wayne Ward</author>
</authors>
<title>Target word Detection and semantic role chunking using support vector machines.</title>
<date>2003</date>
<publisher>HLT-NAACL.</publisher>
<contexts>
<context position="1927" citStr="Hacioglu &amp; Ward, 2003" startWordPosition="324" endWordPosition="327">explicit morphological features are present. 1 Introduction Base Phrase Chunking (BPC), also known as shallow syntactic parsing, is the process by which adjacent words are grouped together to form nonrecursive chunks in a sentence. The base chunks form phrases such as verb phrases, noun phrases and adjective phrases, etc. An English example of base phrases is [I]NP [would eat]V P [red luscious apples]NP [on Sundays]PP . The BPC task is proving to be an enabling step that is useful to many natural language processing (NLP) applications such as information extraction and semantic role labeling (Hacioglu &amp; Ward, 2003). In English, these applications have shown robust relative performance when exploiting BPC when compared to using full syntactic parses. In general, BPC is appealing as an enabling technology since state of the art performance for BPC is higher (FO=1 95.48%) than that for full syntactic parsing (FO=1 90.02% ) in English (Collins, 2000; Kudo &amp; Matsumato, 2000). Moreover, since BPC had been cast as a classification problem by Ramshaw and Marcus (1995), the task is performed with greater efficiency and is easily portable to new languages in a supervised manner (Diab et al., 2004; Diab et al., 20</context>
<context position="7369" citStr="Hacioglu &amp; Ward, 2003" startWordPosition="1258" endWordPosition="1261"> learning approaches have been applied to POS and BPC tagging, by casting them as classification tasks. Given a set of features extracted from the linguistic context, a classifier predicts the POS or BPC class of a token. SVMs (Vapnik, 1995) are one such supervised machine learning algorithm, with the advantages of: discriminative training, robustness and a capability to handle a large number of (overlapping) features with good generalization perlhttp://www.chasen.org/ taku/software/yamcha/ 90 formance. Consequently, SVMs have been applied in many NLP tasks with great success (Joachims, 1998; Hacioglu &amp; Ward, 2003). We adopt a unified tagging perspective for both the POS tagging and the BPC tasks. We address them using the same SVM experimental setup which comprises a standard SVM as a multi-class classifier (Allwein et al., 2000). A la KM00, we use the YAMCHA sequence model on the SVMs to take advantage of the context of the items being compared in a vertical manner in addition to the encoded features in the horizontal input of the vectors. Accordingly, in our different tasks, we define the notion of context to be a window of fixed size around the segment in focus for learning and tagging. 3.1 POS Tagg</context>
</contexts>
<marker>Hacioglu, Ward, 2003</marker>
<rawString>Kadri Hacioglu and Wayne Ward. 2003. Target word Detection and semantic role chunking using support vector machines. HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Text Categorization with Support Vector Machines: Learning with Many Relevant Features.</title>
<date>1998</date>
<booktitle>Proc. of ECML-98, 10th European Conf. on Machine Learning.</booktitle>
<contexts>
<context position="5889" citStr="Joachims, 1998" startWordPosition="1014" endWordPosition="1015">aw and Marcus (1995), they represent the words as a sequence of labeled words with IOB annotations, where the B marks a word at the beginning of a chunk, I marks a word inside a chunk, and O marks those words (and punctuation) that are outside chunks. The IOB annotation scheme for the English example described earlier is illustrated in Table 1. word IOB label I B-NP would B-VP eat I-VP red B-NP luscious I-NP apples I-NP on B-PP Sundays I-PP . O Table 1: IOB annotation example KM00 develop a sequence model, YAMCHA, over the labeled sequences of words.1 YAMCHA is based on the TinySVM algorithm (Joachims, 1998). They use a degree 2 polynomial kernel. In their work on the task of English BPC, YAMCHA achieves an overall F&apos;3_1 of 93.48% on five chunk types. They report improved results of 93.91% using a combined voting scheme (Kudo &amp; Matsumato, 2000). As far as Arabic BPC, Diab et al. (2004 &amp; 2007) adopt the KM00 model for Arabic using YAMCHA. They cast the Arabic data from the ATB in the IOB annotation scheme. They use the reduced standard LDC tag set, RTS, as their only feature. Their system achieves an overall F&apos;3_1 of 91.44% on 9 chunk types. 3 Current Approach This paper is a significant extension</context>
<context position="7345" citStr="Joachims, 1998" startWordPosition="1256" endWordPosition="1257"> Various machine learning approaches have been applied to POS and BPC tagging, by casting them as classification tasks. Given a set of features extracted from the linguistic context, a classifier predicts the POS or BPC class of a token. SVMs (Vapnik, 1995) are one such supervised machine learning algorithm, with the advantages of: discriminative training, robustness and a capability to handle a large number of (overlapping) features with good generalization perlhttp://www.chasen.org/ taku/software/yamcha/ 90 formance. Consequently, SVMs have been applied in many NLP tasks with great success (Joachims, 1998; Hacioglu &amp; Ward, 2003). We adopt a unified tagging perspective for both the POS tagging and the BPC tasks. We address them using the same SVM experimental setup which comprises a standard SVM as a multi-class classifier (Allwein et al., 2000). A la KM00, we use the YAMCHA sequence model on the SVMs to take advantage of the context of the items being compared in a vertical manner in addition to the encoded features in the horizontal input of the vectors. Accordingly, in our different tasks, we define the notion of context to be a window of fixed size around the segment in focus for learning a</context>
</contexts>
<marker>Joachims, 1998</marker>
<rawString>Thorsten Joachims. 1998. Text Categorization with Support Vector Machines: Learning with Many Relevant Features. Proc. of ECML-98, 10th European Conf. on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seth Kulick</author>
<author>Ryan Gabbard</author>
<author>Mitch Marcus</author>
</authors>
<title>Parsing the Arabic Treebank: Analysis and Improvements. in Treebanks and Linguistic Theories.</title>
<date>2006</date>
<contexts>
<context position="2806" citStr="Kulick et al., 2006" startWordPosition="472" endWordPosition="475"> than that for full syntactic parsing (FO=1 90.02% ) in English (Collins, 2000; Kudo &amp; Matsumato, 2000). Moreover, since BPC had been cast as a classification problem by Ramshaw and Marcus (1995), the task is performed with greater efficiency and is easily portable to new languages in a supervised manner (Diab et al., 2004; Diab et al., 2007). For Arabic, BPC is especially interesting as it constitutes a viable alternative to full syntactic parsing due to the low performance in Arabic full syntactic parsing (labeled FO=1 = —80% compared to FO=1=91.44% for BPC) (Bikel, 2004; Diab et al., 2007; Kulick et al., 2006). In this paper, we present a support vector machine (SVM) based supervised method for Arabic BPC. The new BPC system achieves an FO=1 of 96.33% across 10 base phrase chunk types. We vary the feature sets along two different factors: the usage of explicit morphological features, and the use of different part of speech (POS) tag sets. We introduce a new enriched POS set for Arabic which comprises 75 POS tags. The new POS tag set enriches the standard reduced POS tag set (RTS), distributed 89 Proceedings of the 5th Workshop on Important Unresolved Matters, pages 89–96, Prague, Czech Republic, Ju</context>
</contexts>
<marker>Kulick, Gabbard, Marcus, 2006</marker>
<rawString>Seth Kulick, Ryan Gabbard, and Mitch Marcus. 2006. Parsing the Arabic Treebank: Analysis and Improvements. in Treebanks and Linguistic Theories.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumato</author>
</authors>
<title>Use of support vector learning for chunk identification.</title>
<date>2000</date>
<booktitle>Proc. of the 4th Conf. on Very Large Corpora,</booktitle>
<pages>142--144</pages>
<contexts>
<context position="5207" citStr="Kudo and Matsumato (2000)" startWordPosition="888" endWordPosition="891">by Ramshaw and Marcus (1995), as a problem of NP chunking. Then it was extended to include other types of base phrases by Sang and Buchholz (2000) in the CoNLL 2000 shared task. Most successful approaches are based on machine learning techniques and sequence modeling of the different labels associated with the chunks. Both generative algorithms such as HMMs and multilevel Markov models, as well as, discriminative methods such as Support Vector Machines (SVM) and conditional random fields have been used for the BPC task. The closest relevant approach to the current investigation is the work of Kudo and Matsumato (2000) (KM00) on using SVMs and a sequence model for chunking. A la Ramshaw and Marcus (1995), they represent the words as a sequence of labeled words with IOB annotations, where the B marks a word at the beginning of a chunk, I marks a word inside a chunk, and O marks those words (and punctuation) that are outside chunks. The IOB annotation scheme for the English example described earlier is illustrated in Table 1. word IOB label I B-NP would B-VP eat I-VP red B-NP luscious I-NP apples I-NP on B-PP Sundays I-PP . O Table 1: IOB annotation example KM00 develop a sequence model, YAMCHA, over the labe</context>
<context position="6668" citStr="Kudo and Matsumato (2000)" startWordPosition="1154" endWordPosition="1157">port improved results of 93.91% using a combined voting scheme (Kudo &amp; Matsumato, 2000). As far as Arabic BPC, Diab et al. (2004 &amp; 2007) adopt the KM00 model for Arabic using YAMCHA. They cast the Arabic data from the ATB in the IOB annotation scheme. They use the reduced standard LDC tag set, RTS, as their only feature. Their system achieves an overall F&apos;3_1 of 91.44% on 9 chunk types. 3 Current Approach This paper is a significant extension to the Diab et al. (2007) work. Similar to other researchers in the area of BPC, we adopt a discriminative approach. A la Ramshaw and Marcus (1995), and Kudo and Matsumato (2000), we use the IOB tagging style for modeling and classification. Various machine learning approaches have been applied to POS and BPC tagging, by casting them as classification tasks. Given a set of features extracted from the linguistic context, a classifier predicts the POS or BPC class of a token. SVMs (Vapnik, 1995) are one such supervised machine learning algorithm, with the advantages of: discriminative training, robustness and a capability to handle a large number of (overlapping) features with good generalization perlhttp://www.chasen.org/ taku/software/yamcha/ 90 formance. Consequently</context>
<context position="2289" citStr="Kudo &amp; Matsumato, 2000" startWordPosition="383" endWordPosition="386"> [I]NP [would eat]V P [red luscious apples]NP [on Sundays]PP . The BPC task is proving to be an enabling step that is useful to many natural language processing (NLP) applications such as information extraction and semantic role labeling (Hacioglu &amp; Ward, 2003). In English, these applications have shown robust relative performance when exploiting BPC when compared to using full syntactic parses. In general, BPC is appealing as an enabling technology since state of the art performance for BPC is higher (FO=1 95.48%) than that for full syntactic parsing (FO=1 90.02% ) in English (Collins, 2000; Kudo &amp; Matsumato, 2000). Moreover, since BPC had been cast as a classification problem by Ramshaw and Marcus (1995), the task is performed with greater efficiency and is easily portable to new languages in a supervised manner (Diab et al., 2004; Diab et al., 2007). For Arabic, BPC is especially interesting as it constitutes a viable alternative to full syntactic parsing due to the low performance in Arabic full syntactic parsing (labeled FO=1 = —80% compared to FO=1=91.44% for BPC) (Bikel, 2004; Diab et al., 2007; Kulick et al., 2006). In this paper, we present a support vector machine (SVM) based supervised method </context>
<context position="6130" citStr="Kudo &amp; Matsumato, 2000" startWordPosition="1055" endWordPosition="1058">re outside chunks. The IOB annotation scheme for the English example described earlier is illustrated in Table 1. word IOB label I B-NP would B-VP eat I-VP red B-NP luscious I-NP apples I-NP on B-PP Sundays I-PP . O Table 1: IOB annotation example KM00 develop a sequence model, YAMCHA, over the labeled sequences of words.1 YAMCHA is based on the TinySVM algorithm (Joachims, 1998). They use a degree 2 polynomial kernel. In their work on the task of English BPC, YAMCHA achieves an overall F&apos;3_1 of 93.48% on five chunk types. They report improved results of 93.91% using a combined voting scheme (Kudo &amp; Matsumato, 2000). As far as Arabic BPC, Diab et al. (2004 &amp; 2007) adopt the KM00 model for Arabic using YAMCHA. They cast the Arabic data from the ATB in the IOB annotation scheme. They use the reduced standard LDC tag set, RTS, as their only feature. Their system achieves an overall F&apos;3_1 of 91.44% on 9 chunk types. 3 Current Approach This paper is a significant extension to the Diab et al. (2007) work. Similar to other researchers in the area of BPC, we adopt a discriminative approach. A la Ramshaw and Marcus (1995), and Kudo and Matsumato (2000), we use the IOB tagging style for modeling and classification</context>
<context position="11055" citStr="Kudo &amp; Matsumato (2000)" startWordPosition="1889" endWordPosition="1892">ngrams from the beginning and end of a word in focus. The context for YAMCHA is defined as +/- 2 words around the focus word. The words before the focus word are considered with their ERTS tags. The kernel is a polynomial degree 2 kernel. We adopt the one-vs-all approach for classification, where the tagged examples for one class are considered positive training examples and instances for other classes are considered negative examples. We present results and a brief discussion of the POS tagging performance in Section 4. 3.2 Base Phrase Chunking In this task, we use a setup similar to that of Kudo &amp; Matsumato (2000) and Diab et al. (2004 &amp; 2007), with the IOB annotation representation: Inside I a phrase, Outside O a phrase, and Beginning B of a phrase. However, we designate 10 types of chunked phrases. The chunk phrases identified for Arabic are ADJP, ADVP, CONJP, INTJP, NP, PP, PREDP, PRTP, SBARP, VP. Thus the task is a one of 21 classification task (since there are I and B tags for each chunk phrase type, and a single O tag). The 21 IOB tags are listed: {O, I-ADJP, B-ADJP, I-ADVP, 3All the romanized Arabic is presented in the Buckwalter transliteration scheme (Buckwalter, 2002). 91 Gloss FULL RTS ERTS </context>
</contexts>
<marker>Kudo, Matsumato, 2000</marker>
<rawString>Taku Kudo and Yuji Matsumato. 2000. Use of support vector learning for chunk identification. Proc. of the 4th Conf. on Very Large Corpora, pages 142-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Tim Buckwalter</author>
<author>Wigdan Mekki</author>
</authors>
<title>The Penn Arabic Treebank : Building a Large-Scale Annota ted Arabic Corpus.</title>
<date>2004</date>
<booktitle>NEMLAR Conference on Arabic Language Resources and Tools.</booktitle>
<pages>102--109</pages>
<contexts>
<context position="3522" citStr="Maamouri et al., 2004" startWordPosition="591" endWordPosition="594">BPC. The new BPC system achieves an FO=1 of 96.33% across 10 base phrase chunk types. We vary the feature sets along two different factors: the usage of explicit morphological features, and the use of different part of speech (POS) tag sets. We introduce a new enriched POS set for Arabic which comprises 75 POS tags. The new POS tag set enriches the standard reduced POS tag set (RTS), distributed 89 Proceedings of the 5th Workshop on Important Unresolved Matters, pages 89–96, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics with the LDC Arabic Treebank (ATB) (Maamouri et al., 2004), by adding definiteness, gender and number information to the basic RTS. We devise an automatic POS tagger based on the enriched tag set, ERTS. We use the same unified discriminative model approach to both POS tagging and BPC. The POS tagging results using ERTS are comparable to state of the art POS tagging using RTS with an accuracy of 96.13% for ERTS and 96.15% for RTS. However, using the ERTS as a feature in the BPC task, we note an overall significant increase of 1% absolute F0_1 improvement over the usage of RTS alone. Moreover, we experiment with different explicit morphological feature</context>
<context position="19199" citStr="Maamouri et al., 2004" startWordPosition="3282" endWordPosition="3285">experimental conditions are as follows: RTSnoFeat, RTS-allFeat, RTS-CASE MOOD PER, RTS-DEF GEN NUM, ERTS-noFeat, ERTSallFeat, ERTS-CASE MOOD PER, ERTSDEF GEN NUM, FULL-noFeat, FULL-allFeat. The BPC context is defined as a window of +/−2 tokens centered around the focus word where all the features for the specific condition are used and the tags for the previous two tokens before the focus token are also considered. 93 4 Experiments and Results training data, the token is assigned the NN tag as a 4.1 Data default tag. The dev, test and training data are obtained from ATB1v3, ATB2v2 and ATB3v2 (Maamouri et al., 2004). We adopt the same data splits introduced by Chiang et. al (2006). The corpora are all news genre. The total development data comprises 2304 sentences and 70188 tokens, the total training data comprises 18970 sentences and 594683 tokens, and the total test data comprises 2337 sentences and 69665 tokens. We use the unvocalized Buckwalter transliterated version of the ATB. For both POS tagging and BPC, we use the gold annotations of the training and test data for preprocessing. Hence, for POS tagging, the training and test data are both gold tokenized in the ATB clitic tokenization style. And f</context>
</contexts>
<marker>Maamouri, Bies, Buckwalter, Mekki, 2004</marker>
<rawString>Mohamed Maamouri, Ann Bies, Tim Buckwalter, and Wigdan Mekki. 2004. The Penn Arabic Treebank : Building a Large-Scale Annota ted Arabic Corpus. NEMLAR Conference on Arabic Language Resources and Tools. pp. 102-109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lance A Ramshaw</author>
<author>Mitchell P Marcus</author>
</authors>
<title>Text Chunking using transformational based learning.</title>
<date>1995</date>
<booktitle>Proc. of the 3rd ACL workshop on Very Large Corpora</booktitle>
<contexts>
<context position="2381" citStr="Ramshaw and Marcus (1995)" startWordPosition="399" endWordPosition="402">be an enabling step that is useful to many natural language processing (NLP) applications such as information extraction and semantic role labeling (Hacioglu &amp; Ward, 2003). In English, these applications have shown robust relative performance when exploiting BPC when compared to using full syntactic parses. In general, BPC is appealing as an enabling technology since state of the art performance for BPC is higher (FO=1 95.48%) than that for full syntactic parsing (FO=1 90.02% ) in English (Collins, 2000; Kudo &amp; Matsumato, 2000). Moreover, since BPC had been cast as a classification problem by Ramshaw and Marcus (1995), the task is performed with greater efficiency and is easily portable to new languages in a supervised manner (Diab et al., 2004; Diab et al., 2007). For Arabic, BPC is especially interesting as it constitutes a viable alternative to full syntactic parsing due to the low performance in Arabic full syntactic parsing (labeled FO=1 = —80% compared to FO=1=91.44% for BPC) (Bikel, 2004; Diab et al., 2007; Kulick et al., 2006). In this paper, we present a support vector machine (SVM) based supervised method for Arabic BPC. The new BPC system achieves an FO=1 of 96.33% across 10 base phrase chunk ty</context>
<context position="4610" citStr="Ramshaw and Marcus (1995)" startWordPosition="786" endWordPosition="789">crease of 1% absolute F0_1 improvement over the usage of RTS alone. Moreover, we experiment with different explicit morphological features together with the different POS tag sets with no significant improvement. The paper is laid out as follows: Section 2 discusses state of the art related work in the field of BPC in both English and Arabic; Section 3 illustrates our approach for both POS and BPC in detail; Section 4 presents the experimental setup, results and discussions. 2 Related Work English BPC has made a lot of head way in recent years. It was first cast as a classification problem by Ramshaw and Marcus (1995), as a problem of NP chunking. Then it was extended to include other types of base phrases by Sang and Buchholz (2000) in the CoNLL 2000 shared task. Most successful approaches are based on machine learning techniques and sequence modeling of the different labels associated with the chunks. Both generative algorithms such as HMMs and multilevel Markov models, as well as, discriminative methods such as Support Vector Machines (SVM) and conditional random fields have been used for the BPC task. The closest relevant approach to the current investigation is the work of Kudo and Matsumato (2000) (K</context>
<context position="6637" citStr="Ramshaw and Marcus (1995)" startWordPosition="1149" endWordPosition="1152">8% on five chunk types. They report improved results of 93.91% using a combined voting scheme (Kudo &amp; Matsumato, 2000). As far as Arabic BPC, Diab et al. (2004 &amp; 2007) adopt the KM00 model for Arabic using YAMCHA. They cast the Arabic data from the ATB in the IOB annotation scheme. They use the reduced standard LDC tag set, RTS, as their only feature. Their system achieves an overall F&apos;3_1 of 91.44% on 9 chunk types. 3 Current Approach This paper is a significant extension to the Diab et al. (2007) work. Similar to other researchers in the area of BPC, we adopt a discriminative approach. A la Ramshaw and Marcus (1995), and Kudo and Matsumato (2000), we use the IOB tagging style for modeling and classification. Various machine learning approaches have been applied to POS and BPC tagging, by casting them as classification tasks. Given a set of features extracted from the linguistic context, a classifier predicts the POS or BPC class of a token. SVMs (Vapnik, 1995) are one such supervised machine learning algorithm, with the advantages of: discriminative training, robustness and a capability to handle a large number of (overlapping) features with good generalization perlhttp://www.chasen.org/ taku/software/ya</context>
</contexts>
<marker>Ramshaw, Marcus, 1995</marker>
<rawString>Lance A. Ramshaw and Mitchell P. Marcus. 1995. Text Chunking using transformational based learning. Proc. of the 3rd ACL workshop on Very Large Corpora</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Tjong</author>
<author>Kim Sang</author>
<author>Sabine Buchholz</author>
</authors>
<title>Introduction to the CoNLL-2000 shared task:</title>
<date>2000</date>
<booktitle>Chunking. Proc. of the 4th Conf. on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>127--132</pages>
<location>Lisbon, Portugal,</location>
<marker>Tjong, Sang, Buchholz, 2000</marker>
<rawString>Erik Tjong, Kim Sang, and Sabine Buchholz. 2000. Introduction to the CoNLL-2000 shared task: Chunking. Proc. of the 4th Conf. on Computational Natural Language Learning (CoNLL), Lisbon, Portugal, 2000, pp. 127-132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladamir Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory.</title>
<date>1995</date>
<publisher>Springer Verlag,</publisher>
<location>New York, USA.</location>
<contexts>
<context position="6988" citStr="Vapnik, 1995" startWordPosition="1208" endWordPosition="1209">tem achieves an overall F&apos;3_1 of 91.44% on 9 chunk types. 3 Current Approach This paper is a significant extension to the Diab et al. (2007) work. Similar to other researchers in the area of BPC, we adopt a discriminative approach. A la Ramshaw and Marcus (1995), and Kudo and Matsumato (2000), we use the IOB tagging style for modeling and classification. Various machine learning approaches have been applied to POS and BPC tagging, by casting them as classification tasks. Given a set of features extracted from the linguistic context, a classifier predicts the POS or BPC class of a token. SVMs (Vapnik, 1995) are one such supervised machine learning algorithm, with the advantages of: discriminative training, robustness and a capability to handle a large number of (overlapping) features with good generalization perlhttp://www.chasen.org/ taku/software/yamcha/ 90 formance. Consequently, SVMs have been applied in many NLP tasks with great success (Joachims, 1998; Hacioglu &amp; Ward, 2003). We adopt a unified tagging perspective for both the POS tagging and the BPC tasks. We address them using the same SVM experimental setup which comprises a standard SVM as a multi-class classifier (Allwein et al., 2000</context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>Vladamir Vapnik. 1995. The Nature of Statistical Learning Theory. Springer Verlag, New York, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>