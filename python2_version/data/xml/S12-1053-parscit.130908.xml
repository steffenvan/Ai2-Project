<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000382">
<title confidence="0.99089">
Semeval-2012 Task 8:
Cross-lingual Textual Entailment for Content Synchronization
</title>
<author confidence="0.97675">
Matteo Negri Alessandro Marchetti Yashar Mehdad
</author>
<affiliation confidence="0.790889">
FBK-irst CELCT FBK-irst
Trento, Italy Trento, Italy Trento, Italy
</affiliation>
<email confidence="0.941605">
negri@fbk.eu amarchetti@celct.it mehdad@fbk.eu
</email>
<author confidence="0.963076">
Luisa Bentivogli
</author>
<affiliation confidence="0.899882">
FBK-irst
</affiliation>
<address confidence="0.852562">
Trento, Italy
</address>
<email confidence="0.997311">
bentivo@fbk.eu
</email>
<sectionHeader confidence="0.995611" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999798125">
This paper presents the first round of the
task on Cross-lingual Textual Entailment for
Content Synchronization, organized within
SemEval-2012. The task was designed to pro-
mote research on semantic inference over texts
written in different languages, targeting at the
same time a real application scenario. Par-
ticipants were presented with datasets for dif-
ferent language pairs, where multi-directional
entailment relations (“forward”, “backward”,
“bidirectional”, “no entailment”) had to be
identified. We report on the training and test
data used for evaluation, the process of their
creation, the participating systems (10 teams,
92 runs), the approaches adopted and the re-
sults achieved.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999818066666667">
The cross-lingual textual entailment task (Mehdad et
al., 2010) addresses textual entailment (TE) recog-
nition (Dagan and Glickman, 2004) under the new
dimension of cross-linguality, and within the new
challenging application scenario of content synchro-
nization.
Cross-linguality represents a dimension of the TE
recognition problem that has been so far only par-
tially investigated. The great potential for integrat-
ing monolingual TE recognition components into
NLP architectures has been reported in several ar-
eas, including question answering, information re-
trieval, information extraction, and document sum-
marization. However, mainly due to the absence of
cross-lingual textual entailment (CLTE) recognition
</bodyText>
<sectionHeader confidence="0.5449715" genericHeader="introduction">
Danilo Giampiccolo
CELCT
</sectionHeader>
<address confidence="0.507229">
Trento, Italy
</address>
<email confidence="0.851293">
giampiccolo@celct.it
</email>
<bodyText confidence="0.999834382352941">
components, similar improvements have not been
achieved yet in any cross-lingual application. The
CLTE task aims at prompting research to fill this
gap. Along such direction, research can now ben-
efit from recent advances in other fields, especially
machine translation (MT), and the availability of: i)
large amounts of parallel and comparable corpora in
many languages, ii) open source software to com-
pute word-alignments from parallel corpora, and iii)
open source software to set up MT systems. We
believe that all these resources can positively con-
tribute to develop inference mechanisms for multi-
lingual data.
Content synchronization represents a challenging
application scenario to test the capabilities of ad-
vanced NLP systems. Given two documents about
the same topic written in different languages (e.g.
Wiki pages), the task consists of automatically de-
tecting and resolving differences in the information
they provide, in order to produce aligned, mutually
enriched versions of the two documents. Towards
this objective, a crucial requirement is to identify the
information in one page that is either equivalent or
novel (more informative) with respect to the content
of the other. The task can be naturally cast as an
entailment recognition problem, where bidirectional
and unidirectional entailment judgments for two text
fragments are respectively mapped into judgments
about semantic equivalence and novelty. Alterna-
tively, the task can be seen as a machine translation
evaluation problem, where judgments about seman-
tic equivalence and novelty depend on the possibility
to fully or partially translate a text fragment into the
other.
</bodyText>
<page confidence="0.985802">
399
</page>
<note confidence="0.9889385">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 399–407,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<figureCaption confidence="0.995332">
Figure 1: “bidirectional”, “forward”, “backward” and
“no entailment” judgments for SP/EN CLTE pairs.
</figureCaption>
<bodyText confidence="0.99948968">
The recent advances on monolingual TE on the
one hand, and the methodologies used in Statisti-
cal Machine Translation (SMT) on the other, offer
promising solutions to approach the CLTE task. In
line with a number of systems that model the RTE
task as a similarity problem (i.e. handling similar-
ity scores between T and H as useful evidence to
draw entailment decisions), the standard sentence
and word alignment programs used in SMT offer a
strong baseline for CLTE. However, although repre-
senting a solid starting point to approach the prob-
lem, similarity-based techniques are just approx-
imations, open to significant improvements com-
ing from semantic inference at the multilingual
level (e.g. cross-lingual entailment rules such as
“perro”→“animal”). Taken in isolation, similarity-
based techniques clearly fall short of providing an
effective solution to the problem of assigning direc-
tions to the entailment relations (especially in the
complex CLTE scenario, where entailment relations
are multi-directional). Thanks to the contiguity be-
tween CLTE, TE and SMT, the proposed task pro-
vides an interesting scenario to approach the issues
outlined above from different perspectives, and large
room for mutual improvement.
</bodyText>
<sectionHeader confidence="0.938441" genericHeader="method">
2 The task
</sectionHeader>
<bodyText confidence="0.9995134">
Given a pair of topically related text fragments (T1
and T2) in different languages, the CLTE task con-
sists of automatically annotating it with one of the
following entailment judgments (see Figure 1 for
Spanish/English examples of each judgment):
</bodyText>
<listItem confidence="0.9909835">
• bidirectional (T1→T2 &amp; T1←T2): the two
fragments entail each other (semantic equiva-
lence);
• forward (T1→T2 &amp; T16←T2): unidirectional
entailment from T1 to T2;
• backward (T16→T2 &amp; T1←T2): unidirectional
entailment from T2 to T1;
• no entailment (T16→T2 &amp; T16←T2): there is
no entailment between T1 and T2 in both direc-
tions;
</listItem>
<bodyText confidence="0.9967928">
In this task, both T1 and T2 are assumed to be
true statements. Although contradiction is relevant
from an application-oriented perspective, contradic-
tory pairs are not present in the dataset created for
the first round of the task.
</bodyText>
<sectionHeader confidence="0.994449" genericHeader="method">
3 Dataset description
</sectionHeader>
<bodyText confidence="0.9980302">
Four CLTE corpora have been created for the fol-
lowing language combinations: Spanish/English
(SP-EN), Italian/English (IT-EN), French/English
(FR-EN), German/English (DE-EN). The datasets
are released in the XML format shown in Figure 1.
</bodyText>
<subsectionHeader confidence="0.999899">
3.1 Data collection and annotation
</subsectionHeader>
<bodyText confidence="0.998658333333333">
The dataset was created following the crowdsourc-
ing methodology proposed in (Negri et al., 2011),
which consists of the following steps:
</bodyText>
<listItem confidence="0.8861906875">
1. First, English sentences were manually ex-
tracted from copyright-free sources (Wikipedia
and Wikinews). The selected sentences repre-
sent one of the elements (T1) of each entail-
ment pair;
2. Next, each T1 was modified through crowd-
sourcing in various ways in order to ob-
tain a corresponding T2 (e.g. introduc-
ing meaning-preserving lexical and syntactic
changes, adding and removing portions of
text);
3. Each T2 was then paired to the original T1,
and the resulting pairs were annotated with one
of the four entailment judgments. In order to
reduce the correlation between the difference
in sentences’ length and entailment judgments,
</listItem>
<page confidence="0.994516">
400
</page>
<bodyText confidence="0.97443525">
only the pairs where the difference between the
number of words in T1 and T2 (length diff) was
below a fixed threshold (10 words) were re-
tained.1 The final result is a monolingual En-
glish dataset annotated with multi-directional
entailment judgments, which are well dis-
tributed over length diff values ranging from 0
to 9;
</bodyText>
<listItem confidence="0.564996857142857">
4. In order to create the cross-lingual datasets,
each English T1 was manually translated into
four different languages (i.e. Spanish, German,
Italian and French) by expert translators;
5. By pairing the translated T1 with the cor-
responding T2 in English, four cross-lingual
datasets were obtained.
</listItem>
<bodyText confidence="0.999977090909091">
To ensure the good quality of the datasets, all the
collected pairs were manually checked and corrected
when necessary. Only pairs with agreement between
two expert annotators were retained. The final result
is a multilingual parallel entailment corpus, where
T1s are in 5 different languages (i.e. English, Span-
ish, German, Italian, and French), and T2s are in En-
glish. It’s worth mentioning that the monolingual
English corpus, a by-product of our data collection
methodology, will be publicly released as a further
contribution to the research community.2
</bodyText>
<subsectionHeader confidence="0.999546">
3.2 Dataset statistics
</subsectionHeader>
<bodyText confidence="0.999959454545455">
Each dataset consists of 1,000 pairs (500 for training
and 500 for test), balanced across the four entail-
ment judgments (bidirectional, forward, backward,
and no entailment).
For each language combination, the distribu-
tion of the four entailment judgments according to
length diff is shown in Figure 2. Vertical bars rep-
resent, for each length diff value, the proportion
of pairs belonging to the four entailment classes.
As can be seen, the length diff constraint applied
to the length difference in the monolingual English
</bodyText>
<footnote confidence="0.9628055">
1Such constraint has been applied in order to focus as much
as possible on semantic aspects of the problem, by reduc-
ing the applicability of simple association rules such as IF
length(T1)&gt;length(T2) THEN T1--+T2.
2The cross-lingual datasets are already available for research
purposes at http://www.celct.it/resourcesList.
php. The monolingual English dataset will be publicly released
to non participants in July 2012.
</footnote>
<bodyText confidence="0.999717363636364">
pairs (step 3 of the creation process) is substantially
reflected in the cross-lingual datasets for all lan-
guage combinations. In fact, as shown in Table 1,
the majority of the pairs is always included in the
same length diff range (approximately [-5,+5]) and,
within this range, the distribution of the four classes
is substantially uniform. Our assumption is that such
data distribution makes entailment judgments based
on mere surface features such as sentence length in-
effective, thus encouraging the development of alter-
native, deeper processing strategies.
</bodyText>
<table confidence="0.9937025">
SP-EN IT-EN FR-EN DE-EN
Forward 104 132 121 179
Backward 202 182 191 123
No entailment 163 173 169 174
Bidirectional 175 199 193 209
ALL 644 686 674 685
</table>
<tableCaption confidence="0.8134085">
Table 1: CLTE pairs distribution within the -5/+5
length diff range.
</tableCaption>
<sectionHeader confidence="0.954611" genericHeader="method">
4 Evaluation metrics and baselines
</sectionHeader>
<bodyText confidence="0.999839222222222">
Evaluation results have been automatically com-
puted by comparing the entailment judgments re-
turned by each system with those manually assigned
by human annotators. The metric used for systems’
ranking is accuracy over the whole test set, i.e. the
number of correct judgments out of the total number
of judgments in the test set. Additionally, we calcu-
lated precision, recall, and F1 measures for each of
the four entailment judgment categories taken sep-
arately. These scores aim at giving participants the
possibility to gain clearer insights into their system’s
behavior on the entailment phenomena relevant to
the task.
For each language combination, two baselines
considering the length difference between T1 and T2
have been calculated (besides the trivial 0.25 accu-
racy score obtained by assigning each test pair in the
balanced dataset to one of the four classes):
</bodyText>
<listItem confidence="0.99802925">
• Composition of binary judgments (Bi-
nary). To calculate this baseline an SVM
classifier is trained to take binary entailment
decisions (“YES”, “NO”). The classifier uses
length(T1)/length(T2) as a single feature to
check for entailment from T1 to T2, and
length(T2)/length(T1) for the opposite direc-
tion. For each test pair, the unidirectional
</listItem>
<page confidence="0.990905">
401
</page>
<figure confidence="0.999589241935484">
-14 -10 -7 -4 -1 2 5 8 11 14 17
(d) DE-EN
-21 -18 -15 -12 -9 -6 -3 0 3 6 9
(a) SP-EN
no_entailment
forward
bidirectional
backward
-21 -18 -15 -12 -9 -6 -3 0 3 6 9 12
(c) FR-EN
90
80
70
60
50
40
30
20
10
0
80
70
60
50
40
30
20
10
0
no_entailment
forward
bidirectional
backward
80
-17 -14 -11 -8 -5 -2 1 4 7 10
(b) IT-EN
90
no_entailment
forward
bidirectional
backward
80
70
60
50
40
30
20
10
0
70
60
50
40
30
20
10
0
no_entailment
forward
bidirectional
backward
</figure>
<figureCaption confidence="0.999915">
Figure 2: CLTE pairs distribution for different length diff values across all datasets.
</figureCaption>
<bodyText confidence="0.766568">
judgments returned by the two classifiers are
composed into a single multi-directional judg-
ment (“YES-YES”=“bidirectional”, “YES-
NO”=“forward”, “NO-YES”=“backward”,
“NO-NO”=“no entailment”);
</bodyText>
<listItem confidence="0.812192">
• Multi-class classification (Multi-class). A
single SVM classifier is trained with the same
features to directly assign to each pair one of
the four entailment judgments.
</listItem>
<bodyText confidence="0.99628">
Both the baselines have been calculated with the
LIBSVM package (Chang and Lin, 2011), using a
linear kernel with default parameters. Baseline re-
sults are reported in Table 2.
Although the four CLTE datasets are derived from
the same monolingual EN-EN corpus, baseline re-
sults present slight differences due to the effect of
translation into different languages.
</bodyText>
<table confidence="0.9949885">
SP-EN IT-EN FR-EN DE-EN
1-class 0.25 0.25 0.25 0.25
Binary 0.34 0.39 0.39 0.40
Multi-class 0.43 0.44 0.42 0.42
</table>
<tableCaption confidence="0.98895">
Table 2: Baseline accuracy results.
</tableCaption>
<sectionHeader confidence="0.884996" genericHeader="method">
5 Submitted runs and results
</sectionHeader>
<bodyText confidence="0.999935">
Participants were allowed to submit up to five runs
for each language combination. A total of 17 teams
registered to participate in the task and downloaded
the training set. Out of them, 12 downloaded the
test set and 10 (including one of the task organizers)
submitted valid runs. Eight teams produced submis-
sions for all the language combinations, while two
teams participated only in the SP-EN task. In total,
92 runs have been submitted and evaluated (29 for
SP-EN, and 21 for each of the other language pairs).
</bodyText>
<page confidence="0.994435">
402
</page>
<bodyText confidence="0.999792333333333">
Despite the novelty and the difficulty of the problem,
these numbers demonstrate the interest raised by the
task, and the overall success of the initiative.
</bodyText>
<table confidence="0.999976323529412">
System name SP-EN IT-EN FR-EN DE-EN
BUAP run1 0.350 0.336 0.334 0.330
BUAP run2 0.366 0.344 0.342 0.268
celi run1 0.276 0.278 0.278 0.280
celi run2 0.336 0.338 0.300 0.352
celi run3 0.322 0.334 0.298 0.350
celi run4 0.268 0.280 0.280 0.274
DirRelCond3 run1 0.300 0.280 0.362 0.336
DirRelCond3 run2 0.300 0.284 0.360 0.336
DirRelCond3 run3 0.300 0.338 0.384 0.364
DirRelCond3 run4 0.344 0.316 0.384 0.374
FBK run1* 0.502 - - -
FBK run2* 0.490 - - -
FBK run3* 0.504 - - -
FBK run4* 0.500 - - -
HDU run1 0.630 0.554 0.564 0.558
HDU run2 0.632 0.562 0.570 0.552
ICT run1 0.448 0.454 0.456 0.460
JU-CSE-NLP run1 0.274 0.316 0.288 0.262
JU-CSE-NLP run2 0.266 0.326 0.294 0.296
JU-CSE-NLP run3 0.272 0.314 0.296 0.264
Sagan run1 0.342 0.352 0.346 0.342
Sagan run2 0.328 0.352 0.336 0.310
Sagan run3 0.346 0.356 0.330 0.332
Sagan run4 0.340 0.330 0.310 0.310
SoftCard run1 0.552 0.566 0.570 0.550
UAlacant run1 LATE 0.598 - - -
UAlacant run2 0.582 - - -
UAlacant run3 LATE 0.510 - - -
UAlacant run4 0.514 - - -
Highest 0.632 0.566 0.570 0.558
Average 0.440 0.411 0.408 0.408
Median 0.407 0.350 0.365 0.363
Lowest 0.274 0.326 0.296 0.296
</table>
<tableCaption confidence="0.975559">
Table 3: Accuracy results (92 runs) over the 4 lan-
guage combinations. Highest, average, median and low-
est scores are calculated considering the best run for each
team (*task organizers’ system).
</tableCaption>
<bodyText confidence="0.999767051724138">
Accuracy results are reported in Table 3. As can
be seen from the table, overall accuracy scores are
quite different across language pairs, with the high-
est result on SP-EN (0.632), which is considerably
higher than the highest score on DE-EN (0.558).
This might be due to the fact that most of the partic-
ipating systems rely on a “pivoting” approach that
addresses CLTE by automatically translating T1 in
the same language of T2 (see Section 6). Regard-
ing the DE-EN dataset, pivoting methods might be
penalized by the lower quality of MT output when
German T1s are translated into English.
The comparison with baselines results leads to in-
teresting observations. First of all, while all systems
significantly outperform the lowest 1-class baseline
(0.25), both other baselines are surprisingly hard to
beat. This shows that, despite the effort in keep-
ing the distribution of the entailment classes uni-
form across different length diff values, eliminating
the correlation between sentences’ length and cor-
rect entailment decisions is difficult. As a conse-
quence, although disregarding semantic aspects of
the problem, features considering such information
are quite effective.
In general, systems performed better on the SP-
EN dataset, with most results above the binary base-
line (8 out of 10), and half of the systems above the
multi-class baseline. For the other language pairs
the results are lower, with only 3 out of 8 partici-
pants above the two baselines in all datasets. Aver-
age results reflect this situation: the average scores
are always above the binary baseline, whereas only
the SP-EN average result is higher than the multi-
class baseline(0.44 vs. 0.43).
To better understand the behaviour of each sys-
tem (also in relation to the different language com-
binations), Table 4 provides separate precision, re-
call, and F1 scores for each entailment judgment,
calculated over the best runs of each participating
team. Overall, the results suggest that the “bidi-
rectional” and “no entailment” categories are more
problematic than “forward” and “backward” judg-
ments. For most datasets, in fact, systems’ perfor-
mance on “bidirectional” and “no entailment” is sig-
nificantly lower, typically on recall. Except for the
DE-EN dataset (more problematic on “forward”),
also average F1 results on these judgments are lower.
This might be due to the fact that, for all datasets, the
vast majority of “bidirectional” and “no entailment”
judgments falls in a length diff range where the dis-
tribution of the four classes is more uniform (see
Figure 2).
Similar reasons can justify the fact that “back-
ward” entailment results are consistently higher on
all datasets. Compared with “forward” entailment,
these judgments are in fact less scattered across the
entire length diff range (i.e. less intermingled with
the other classes).
</bodyText>
<page confidence="0.999453">
403
</page>
<sectionHeader confidence="0.997721" genericHeader="evaluation">
6 Approaches
</sectionHeader>
<bodyText confidence="0.996855">
A rough classification of the approaches adopted by
participants can be made along two orthogonal di-
mensions, namely:
</bodyText>
<listItem confidence="0.9772870625">
• Pivoting vs. Cross-lingual. Pivoting meth-
ods rely on the automatic translation of one of
the two texts (either single words or the en-
tire sentence) into the language of the other
(typically English) in order perform monolin-
gual TE recognition. Cross-lingual methods as-
sign entailment judgments without preliminary
translation.
• Composition of binary judgments vs. Multi-
class classification. Compositional approaches
map unidirectional entailment decisions taken
separately into single judgments (similar to the
Binary baseline in Section 4). Methods based
on multi-class classification directly assign one
of the four entailment judgments to each test
pair (similar to our Multi-class baseline).
</listItem>
<bodyText confidence="0.999837909090909">
Concerning the former dimension, most of the
systems (6 out of 10) adopted a pivoting approach,
relying on Google Translate (4 systems), Microsoft
Bing Translator (1), or a combination of Google,
Bing, and other MT systems (1) to produce English
T2s. Regarding the latter dimension, the composi-
tional approach was preferred to multi-class classi-
fication (6 out of 10). The best performing system
relies on a “hybrid” approach (combining monolin-
gual and cross-lingual alignments) and a compo-
sitional strategy. Besides the frequent recourse to
MT tools, other resources used by participants in-
clude: on-line dictionaries for the translation of sin-
gle words, word alignment tools, part-of-speech tag-
gers, NP chunkers, named entity recognizers, stem-
mers, stopwords lists, and Wikipedia as an external
multilingual corpus. More in detail:
BUAP [pivoting, compositional] (Vilari˜no et al.,
2012) adopts a pivoting method based on translating
T1 into the language of T2 and vice versa (Google
Translate3 and the OpenOffice Thesaurus4). Simi-
larity measures (e.g. Jaccard index) and rules are
</bodyText>
<footnote confidence="0.992204333333333">
3http://translate.google.com/
4http://extensions.services.openoffice.
org/en/taxonomy/term/233
</footnote>
<bodyText confidence="0.997770755555556">
respectively used to annotate the two resulting sen-
tence pairs with entailment judgments and combine
them in a single decision.
CELI [cross lingual, compositional &amp; multi-
class] (Kouylekov, 2012) uses dictionaries for word
matching, and a multilingual corpus extracted from
Wikipedia for term weighting. Word overlap and
similarity measures are then used in different ap-
proaches to the task. In one run (Run 1), they are
used to train a classifier that assigns separate en-
tailment judgments for each direction. Such judg-
ments are finally composed into a single one for each
pair. In the other runs, the same features are used for
multi-class classification.
DirRelCond3 [cross lingual, compositional]
(Perini, 2012) uses bilingual dictionaries (Freedict5
and WordReference6) to translate content words into
English. Then, entailment decisions are taken com-
bining directional relatedness scores between words
in both directions (Perini, 2011).
FBK [cross lingual, compositional &amp; multi-
class] (Mehdad et al., 2012a) uses cross-lingual
matching features extracted from lexical phrase ta-
bles, semantic phrase tables, and dependency rela-
tions (Mehdad et al., 2011; Mehdad et al., 2012b;
Mehdad et al., 2012c). The features are used for
multi-class and binary classification using SVMs.
HDU [hybrid, compositional] (W¨aschle and
Fendrich, 2012) uses a combination of binary clas-
sifiers for each entailment direction. The classifiers
use both monolingual alignment features based on
METEOR (Banerjee and Lavie, 2005) alignments
(translations obtained from Google Translate), and
cross-lingual alignment features based on GIZA++
(Och and Ney, 2000) (word alignments learned on
Europarl).
ICT [pivoting, compositional] (Meng et al.,
2012) adopts a pivoting method (using Google
Translate and an in-house hierarchical MT system),
and the open source EDITS system (Kouylekov and
Negri, 2010) to calculate similarity scores between
monolingual English pairs. Separate unidirectional
entailment judgments obtained from binary classi-
fier are combined to return one of the four valid
CLTE judgments.
</bodyText>
<footnote confidence="0.9999655">
5http://www.freedict.com/
6http://www.wordreference.com/
</footnote>
<page confidence="0.993283">
404
</page>
<table confidence="0.99994138">
SP-EN
Forward Backward No entailment Bidirectional
System name P R F1 P R F1 P R F1 P R F1
BUAP spa-eng run2 0,337 0,664 0,447 0,406 0,568 0,473 0,333 0,088 0,139 0,391 0,144 0,211
celi spa-eng run2 0,324 0,368 0,345 0,411 0,368 0,388 0,306 0,296 0,301 0,312 0,312 0,312
DirRelCond3 spa-eng run4 0,358 0,608 0,451 0,444 0,448 0,446 0,286 0,032 0,058 0,243 0,288 0,264
FBK spa-eng run3 0,515 0,704 0,595 0,546 0,568 0,557 0,447 0,304 0,362 0,482 0,440 0,460
HDU spa-eng run2 0,607 0,656 0,631 0,677 0,704 0,690 0,602 0,592 0,597 0,643 0,576 0,608
ICT spa-eng run1 0,750 0,240 0,364 0,440 0,472 0,456 0,395 0,560 0,464 0,436 0,520 0,474
JU-CSE-NLP spa-eng run1 0,211 0,288 0,243 0,272 0,296 0,284 0,354 0,232 0,280 0,315 0,280 0,297
Sagan spa-eng run3 0,225 0,200 0,212 0,269 0,224 0,245 0,418 0,448 0,432 0,424 0,512 0,464
SoftCard spa-eng run1 0,602 0,616 0,609 0,650 0,624 0,637 0,471 0,448 0,459 0,489 0,520 0,504
UAlacant spa-eng run1 LATE 0,689 0,568 0,623 0,645 0,728 0,684 0,507 0,544 0,525 0,566 0,552 0,559
AVG. 0,462 0,491 0,452 0,476 0,5 0,486 0,412 0,354 0,362 0,43 0,414 0,415
IT-EN
Forward Backward No entailment Bidirectional
System name P R F1 P R F1 P R F1 P R F1
BUAP ita-eng run2 0,324 0,456 0,379 0,327 0,672 0,440 0,538 0,056 0,101 0,444 0,192 0,268
celi ita-eng run2 0,349 0,360 0,354 0,455 0,36 0,402 0,294 0,320 0,307 0,287 0,312 0,299
DirRelCond3 ita-eng run3 0,323 0,488 0,389 0,480 0,288 0,360 0,331 0,368 0,348 0,268 0,208 0,234
HDU ita-eng run2 0,564 0,600 0,581 0,628 0,648 0,638 0,551 0,520 0,535 0,500 0,480 0,490
ICT ita-eng run1 0,661 0,296 0,409 0,554 0,368 0,442 0,427 0,448 0,438 0,383 0,704 0,496
JU-CSE-NLP ita-eng run2 0,240 0,280 0,258 0,339 0,480 0,397 0,412 0,280 0,333 0,359 0,264 0,304
Sagan ita-eng run3 0,306 0,296 0,301 0,252 0,216 0,233 0,395 0,512 0,446 0,455 0,400 0,426
SoftCard ita-eng run1 0,602 0,616 0,609 0,617 0,696 0,654 0,560 0,448 0,498 0,481 0,504 0,492
AVG. 0,421 0,424 0,410 0,457 0,466 0,446 0,439 0,369 0,376 0,397 0,383 0,376
FR-EN
Forward Backward No entailment Bidirectional
System name P R F1 P R F1 P R F1 P R F1
BUAP fra-eng run2 0,447 0,272 0,338 0,291 0,760 0,420 0,250 0,016 0,030 0,449 0,320 0,374
celi fra-eng run2 0,316 0,296 0,306 0,378 0,360 0,369 0,270 0,296 0,282 0,244 0,248 0,246
DirRelCond3 fra-eng run3 0,393 0,576 0,468 0,441 0,512 0,474 0,387 0,232 0,290 0,278 0,216 0,243
HDU fra-eng run2 0,564 0,672 0,613 0,582 0,736 0,650 0,676 0,384 0,490 0,500 0,488 0,494
ICT fra-eng run1 0,750 0,192 0,306 0,517 0,496 0,506 0,385 0,656 0,485 0,444 0,480 0,462
JU-CSE-NLP fra-eng run3 0,215 0,208 0,211 0,289 0,296 0,292 0,341 0,496 0,404 0,333 0,184 0,237
Sagan fra-eng run1 0,244 0,168 0,199 0,297 0,344 0,319 0,394 0,568 0,466 0,427 0,304 0,355
SoftCard fra-eng run1 0,551 0,608 0,578 0,649 0,696 0,672 0,560 0,488 0,521 0,513 0,488 0,500
AVG. 0,435 0,374 0,377 0,431 0,525 0,463 0,408 0,392 0,371 0,399 0,341 0,364
DE-EN
Forward Backward No entailment Bidirectional
System name P R F1 P R F1 P R F1 P R F1
BUAP deu-eng run1 0,395 0,120 0,184 0,248 0,224 0,235 0,344 0,688 0,459 0,364 0,288 0,321
celi deu-eng run2 0,347 0,416 0,378 0,402 0,392 0,397 0,339 0,312 0,325 0,319 0,288 0,303
DirRelCond3 deu-eng run4 0,429 0,312 0,361 0,408 0,552 0,469 0,367 0,320 0,342 0,298 0,312 0,305
HDU deu-eng run1 0,559 0,528 0,543 0,600 0,696 0,644 0,540 0,488 0,513 0,524 0,520 0,522
ICT deu-eng run1 0,718 0,224 0,341 0,493 0,552 0,521 0,390 0,512 0,443 0,439 0,552 0,489
JU-CSE-NLP deu-eng run2 0,182 0,048 0,076 0,307 0,496 0,379 0,315 0,560 0,403 0,233 0,080 0,119
Sagan deu-eng run1 0,250 0,168 0,201 0,239 0,256 0,247 0,405 0,600 0,484 0,443 0,344 0,387
SoftCard deu-eng run1 0,568 0,568 0,568 0,611 0,640 0,625 0,521 0,488 0,504 0,496 0,504 0,500
AVG. 0,431 0,298 0,332 0,414 0,476 0,440 0,403 0,496 0,434 0,390 0,361 0,368
</table>
<tableCaption confidence="0.999307">
Table 4: precision, recall and F1 scores, calculated for each team’s best run for all the language combinations.
</tableCaption>
<bodyText confidence="0.960660166666667">
JU-CSE-NLP [pivoting, compositional] (Neogi
et al., 2012) uses Microsoft Bing translator7 to pro-
duce monolingual English pairs. Separate lexical
mapping scores are calculated (from T1 to T2 and
vice-versa) considering different types of informa-
tion and similarity metrics. Binary entailment de-
</bodyText>
<footnote confidence="0.841234">
7http://www.microsofttranslator.com/
</footnote>
<bodyText confidence="0.995977625">
cisions are then heuristically combined into single
decisions.
Sagan [pivoting, multi-class] (Castillo and Car-
denas, 2012) adopts a pivoting method using Google
Translate, and trains a monolingual system based on
a SVM multi-class classifier. A CLTE corpus de-
rived from the RTE-3 dataset is also used as a source
of additional training material.
</bodyText>
<page confidence="0.997222">
405
</page>
<bodyText confidence="0.9911">
SoftCard [pivoting, multi-class] (Jimenez et al.,
2012) after automatic translation with Google Trans-
late, uses SVMs to learn entailment decisions based
on information about the cardinality of: T1, T2, their
intersection and their union. Cardinalities are com-
puted in different ways, considering tokens in T1 and
T2, their IDF, and their similarity (computed with
edit-distance)
UAlacant [pivoting, multi-class] (Espl`a-Gomis
et al., 2012) exploits translations obtained from
Google Translate, Microsoft Bing translator, and the
Apertium open-source MT platform (Forcada et al.,
2011).8 Then, a multi-class SVM classifier is used
to take entailment decisions using information about
overlapping sub-segments as features.
</bodyText>
<sectionHeader confidence="0.999046" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999574413793103">
Despite the novelty of the problem and the diffi-
culty to capture multi-directional entailment rela-
tions across languages, the first round of the Cross-
lingual Textual Entailment for Content Synchroniza-
tion task organized within SemEval-2012 was a suc-
cessful experience. This year a new interesting chal-
lenge has been proposed, a benchmark for four lan-
guage combinations has been released, baseline re-
sults have been proposed for comparison, and a
monolingual English dataset has been produced as
a by-product which can be useful for monolingual
TE research. The interest shown by participants
was encouraging: 10 teams submitted a total of 92
runs for all the language pairs proposed. Overall,
the results achieved on all datasets are encourag-
ing, with best systems significantly outperforming
the proposed baselines. It is worth observing that the
nature of the task, which lies between semantics and
machine translation, led to the participation of teams
coming from both these communities, showing in-
teresting opportunities for integration and mutual
improvement. The proposed approaches reflect this
situation, with teams traditionally working on MT
now dealing with entailment, and teams tradition-
ally participating in the RTE challenges now dealing
with cross-lingual alignment techniques. Our ambi-
tion, for the future editions of the CLTE task, is to
further consolidate the bridge between the semantics
and MT communities.
</bodyText>
<footnote confidence="0.89058">
8http://www.apertium.org/
</footnote>
<sectionHeader confidence="0.993293" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.991971">
This work has been partially supported by the EC-
funded project CoSyne (FP7-ICT-4-24853). The
authors would also like to acknowledge Giovanni
Moretti from CELCT for evaluation scripts and
technical assistance, and the volunteer translators
that contributed to the creation of the dataset:
</bodyText>
<reference confidence="0.9922355">
Marfa Sol Accossato, Laura Barth´el´emy, Clau-
dia Biacchi, Jane Brendler, Amandine Chantrel,
Hanna Cheda Patete, Ellen Clancy, Rodrigo Damian
Tejeda, Daniela Dold, Valentina Frattini, Debora
Hedy Amato, Geniz Hernandez, B´en´edicte Jean-
nequin, Beate Jones, Anne Kauffman, Marcia Laura
Zanoli, Jasmin Lewis, Alicia L´opez, Domenico Los-
eto, Sabrina Luj´an S´anchez, Julie Mailfait, Gabriele
Mark, Nunzio Pruiti, Lourdes Rey Cascallar, Sylvie
Martlew, Aleane Salas Velez, Monica Scalici, An-
dreas Schwab, Marianna Sicuranza, Chiara Sisler,
Stefano Tordazzi, Yvonne.
</reference>
<sectionHeader confidence="0.954504" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996633178571429">
Satanjeev Banerjee and Alon Lavie. 2005. METEOR:
An Automatic Metric for MT Evaluation with Im-
proved Correlation with Human Judgments. In Pro-
ceedings of the ACL Workshop on Intrinsic and Ex-
trinsic Evaluation Measures for Machine Translation
and/or Summarization, pages 65–72.
Julio Castillo and Marina Cardenas. 2012. Sagan: A
Cross Lingual Textual Entailment system based on
Machine Traslation. In Proceedings of the 6th Inter-
national Workshop on Semantic Evaluation (SemEval
2012).
Chih-Chung Chang and Chih-Jen Lin. 2011. Libsvm:
a library for support vector machines. ACM Trans-
actions on Intelligent Systems and Technology (TIST),
2(3):27.
Ido Dagan and Oren Glickman. 2004. Probabilistic Tex-
tual Entailment: Generic Applied Modeling of Lan-
guage Variability. In Proceedings of the PASCAL
Workshop of Learning Methods for Text Understand-
ing and Mining.
Miquel Espl`a-Gomis, Felipe S´anchez-Martfnez, and
Mikel L. Forcada. 2012. UAlacant: Using Online
Machine Translation for Cross-Lingual Textual Entail-
ment. In Proceedings of the 6th International Work-
shop on Semantic Evaluation (SemEval 2012).
Mikel L. Forcada, Ginestf-Rosell Mireia, Nordfalk Jacob,
O’Regan Jim, Ortiz-Rojas Sergio, P´erez-Ortiz Juan A.,
S´anchez-Martfnez Felipe, Ramfrez-S´anchez Gema,
</reference>
<page confidence="0.987993">
406
</page>
<reference confidence="0.999665151898734">
and Tyers Francis M. 2011. Apertium: a Free/Open-
Source Platform for Rule-Based Machine Translation.
Machine Translation, 25(2):127–144. Special Issue:
Free/Open-Source Machine Translation.
Sergio Jimenez, Claudia Becerra, and Alexander Gel-
bukh. 2012. Soft Cardinality + ML: Learning Adap-
tive Similarity Functions for Cross-lingual Textual En-
tailment. In Proceedings of the 6th International
Workshop on Semantic Evaluation (SemEval 2012).
Milen Kouylekov and Matteo Negri. 2010. An open-
source package for recognizing textual entailment. In
Proceedings of the ACL 2010 System Demonstrations.
Milen Kouylekov. 2012. CELI: An Experiment with
Cross Language Textual Entailment. In Proceedings
of the 6th International Workshop on Semantic Evalu-
ation (SemEval 2012).
Yashar Mehdad, Matteo Negri, and Marcello Federico.
2010. Towards Cross-Lingual Textual Entailment. In
Proceedings of the 11th Annual Conference of the
North American Chapter of the Association for Com-
putational Linguistics (NAACL HLT 2010).
Yashar Mehdad, Matteo Negri, and Marcello Federico.
2011. Using Bilingual Parallel Corpora for Cross-
Lingual Textual Entailment. In Proceedings of the
49th Annual Meeting of the Association for Compu-
tational Linguistics: Human Language Technologies
(ACL HLT 2011).
Yashar Mehdad, Matteo Negri, and Jos´e G. C. de Souza.
2012a. FBK: Cross-Lingual Textual Entailment With-
out Translation. In Proceedings of the 6th Interna-
tional Workshop on Semantic Evaluation (SemEval
2012).
Yashar Mehdad, Matteo Negri, and Marcello Federico.
2012b. Detecting Semantic Equivalence and Informa-
tion Disparity in Cross-lingual Documents. In Pro-
ceedings of the 50th Annual Meeting of the Association
for Computational Linguistics (ACL 2012).
Yashar Mehdad, Matteo Negri, and Marcello Federico.
2012c. Match without a Referee: Evaluating MT Ade-
quacy without Reference Translations. In Proceedings
of the 7th Workshop on Statistical Machine Translation
(WMT 2012).
Fandong Meng, Hao Xiong, and Qun Liu. 2012. ICT:
A Translation based Cross-lingual Textual Entailment.
In Proceedings of the 6th International Workshop on
Semantic Evaluation (SemEval 2012).
Matto Negri, Luisa Bentivogli, Yashar Mehdad, Danilo
Giampiccolo, and Alessandro Marchetti. 2011. Di-
vide and Conquer: Crowdsourcing the Creation of
Cross-Lingual Textual Entailment Corpora. Proceed-
ings of the 2011 Conference on Empirical Methods in
Natural Language Processing (EMNLP 2011).
Snehasis Neogi, Partha Pakray, Sivaji Bandyopadhyay,
and Alexander Gelbukh. 2012. JU-CSE-NLP: Lan-
guage Independent Cross-lingual Textual Entailment
System. In Proceedings of the 6th International Work-
shop on Semantic Evaluation (SemEval 2012).
Franz J. Och and Hermann Ney. 2000. Improved Sta-
tistical Alignment Models. In Proceedings of the 38th
Annual Meeting of the Association for Computational
Linguistics (ACL 2000).
Alp´ar Perini. 2011. Detecting textual entailment
with conditions on directional text relatedness scores.
Studia Universitatis Babes-Bolyai Series Informatica,
LVI(2):13–18.
Alp´ar Perini. 2012. DirRelCond3: Detecting Textual
Entailment Across Languages With Conditions On Di-
rectional Text Relatedness Scores. In Proceedings of
the 6th International Workshop on Semantic Evalua-
tion (SemEval 2012).
Darnes Vilari˜no, David Pinto, Mireya Tovar, Saul Le´on,
and Esteban Castillo. 2012. BUAP: Lexical and
Semantic Similarity for Cross-lingual Textual Entail-
ment. In Proceedings of the 6th International Work-
shop on Semantic Evaluation (SemEval 2012).
Katharina W¨aschle and Sascha Fendrich. 2012. HDU:
Cross-lingual Textual Entailment with SMT Features.
In Proceedings of the 6th International Workshop on
Semantic Evaluation (SemEval 2012).
</reference>
<page confidence="0.998312">
407
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.293410">
<title confidence="0.9508585">Semeval-2012 Task 8: Cross-lingual Textual Entailment for Content Synchronization</title>
<author confidence="0.998458">Matteo Negri Alessandro Marchetti Yashar Mehdad</author>
<affiliation confidence="0.826498">FBK-irst CELCT FBK-irst</affiliation>
<address confidence="0.832764">Trento, Italy Trento, Italy Trento, Italy</address>
<email confidence="0.861045">negri@fbk.euamarchetti@celct.itmehdad@fbk.eu</email>
<affiliation confidence="0.704884">Luisa</affiliation>
<address confidence="0.65389">Trento,</address>
<email confidence="0.998768">bentivo@fbk.eu</email>
<abstract confidence="0.995908529411765">This paper presents the first round of the on Textual Entailment for organized within SemEval-2012. The task was designed to promote research on semantic inference over texts written in different languages, targeting at the same time a real application scenario. Participants were presented with datasets for different language pairs, where multi-directional entailment relations (“forward”, “backward”, “bidirectional”, “no entailment”) had to be identified. We report on the training and test data used for evaluation, the process of their creation, the participating systems (10 teams, 92 runs), the approaches adopted and the results achieved.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Marfa Sol Accossato</author>
<author>Laura Barth´el´emy</author>
<author>Claudia Biacchi</author>
<author>Jane Brendler</author>
<author>Amandine Chantrel</author>
<author>Hanna Cheda Patete</author>
<author>Ellen Clancy</author>
<author>Rodrigo Damian Tejeda</author>
<author>Daniela Dold</author>
<author>Valentina Frattini</author>
</authors>
<title>Nunzio Pruiti, Lourdes Rey Cascallar, Sylvie Martlew, Aleane Salas Velez, Monica Scalici, Andreas Schwab,</title>
<institution>Debora Hedy Amato, Geniz Hernandez, B´en´edicte Jeannequin, Beate Jones, Anne Kauffman, Marcia Laura Zanoli, Jasmin Lewis,</institution>
<location>Alicia L´opez, Domenico Loseto, Sabrina Luj´an</location>
<marker>Accossato, Barth´el´emy, Biacchi, Brendler, Chantrel, Patete, Clancy, Tejeda, Dold, Frattini, </marker>
<rawString>Marfa Sol Accossato, Laura Barth´el´emy, Claudia Biacchi, Jane Brendler, Amandine Chantrel, Hanna Cheda Patete, Ellen Clancy, Rodrigo Damian Tejeda, Daniela Dold, Valentina Frattini, Debora Hedy Amato, Geniz Hernandez, B´en´edicte Jeannequin, Beate Jones, Anne Kauffman, Marcia Laura Zanoli, Jasmin Lewis, Alicia L´opez, Domenico Loseto, Sabrina Luj´an S´anchez, Julie Mailfait, Gabriele Mark, Nunzio Pruiti, Lourdes Rey Cascallar, Sylvie Martlew, Aleane Salas Velez, Monica Scalici, Andreas Schwab, Marianna Sicuranza, Chiara Sisler, Stefano Tordazzi, Yvonne.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satanjeev Banerjee</author>
<author>Alon Lavie</author>
</authors>
<title>METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization,</booktitle>
<pages>65--72</pages>
<contexts>
<context position="20803" citStr="Banerjee and Lavie, 2005" startWordPosition="3220" endWordPosition="3223">ss scores between words in both directions (Perini, 2011). FBK [cross lingual, compositional &amp; multiclass] (Mehdad et al., 2012a) uses cross-lingual matching features extracted from lexical phrase tables, semantic phrase tables, and dependency relations (Mehdad et al., 2011; Mehdad et al., 2012b; Mehdad et al., 2012c). The features are used for multi-class and binary classification using SVMs. HDU [hybrid, compositional] (W¨aschle and Fendrich, 2012) uses a combination of binary classifiers for each entailment direction. The classifiers use both monolingual alignment features based on METEOR (Banerjee and Lavie, 2005) alignments (translations obtained from Google Translate), and cross-lingual alignment features based on GIZA++ (Och and Ney, 2000) (word alignments learned on Europarl). ICT [pivoting, compositional] (Meng et al., 2012) adopts a pivoting method (using Google Translate and an in-house hierarchical MT system), and the open source EDITS system (Kouylekov and Negri, 2010) to calculate similarity scores between monolingual English pairs. Separate unidirectional entailment judgments obtained from binary classifier are combined to return one of the four valid CLTE judgments. 5http://www.freedict.com</context>
</contexts>
<marker>Banerjee, Lavie, 2005</marker>
<rawString>Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments. In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, pages 65–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julio Castillo</author>
<author>Marina Cardenas</author>
</authors>
<title>Sagan: A Cross Lingual Textual Entailment system based on Machine Traslation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="25805" citStr="Castillo and Cardenas, 2012" startWordPosition="4021" endWordPosition="4025">98 0,332 0,414 0,476 0,440 0,403 0,496 0,434 0,390 0,361 0,368 Table 4: precision, recall and F1 scores, calculated for each team’s best run for all the language combinations. JU-CSE-NLP [pivoting, compositional] (Neogi et al., 2012) uses Microsoft Bing translator7 to produce monolingual English pairs. Separate lexical mapping scores are calculated (from T1 to T2 and vice-versa) considering different types of information and similarity metrics. Binary entailment de7http://www.microsofttranslator.com/ cisions are then heuristically combined into single decisions. Sagan [pivoting, multi-class] (Castillo and Cardenas, 2012) adopts a pivoting method using Google Translate, and trains a monolingual system based on a SVM multi-class classifier. A CLTE corpus derived from the RTE-3 dataset is also used as a source of additional training material. 405 SoftCard [pivoting, multi-class] (Jimenez et al., 2012) after automatic translation with Google Translate, uses SVMs to learn entailment decisions based on information about the cardinality of: T1, T2, their intersection and their union. Cardinalities are computed in different ways, considering tokens in T1 and T2, their IDF, and their similarity (computed with edit-dis</context>
</contexts>
<marker>Castillo, Cardenas, 2012</marker>
<rawString>Julio Castillo and Marina Cardenas. 2012. Sagan: A Cross Lingual Textual Entailment system based on Machine Traslation. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>Libsvm: a library for support vector machines.</title>
<date>2011</date>
<booktitle>ACM Transactions on Intelligent Systems and Technology (TIST),</booktitle>
<pages>2--3</pages>
<contexts>
<context position="12006" citStr="Chang and Lin, 2011" startWordPosition="1838" endWordPosition="1841">50 40 30 20 10 0 70 60 50 40 30 20 10 0 no_entailment forward bidirectional backward Figure 2: CLTE pairs distribution for different length diff values across all datasets. judgments returned by the two classifiers are composed into a single multi-directional judgment (“YES-YES”=“bidirectional”, “YESNO”=“forward”, “NO-YES”=“backward”, “NO-NO”=“no entailment”); • Multi-class classification (Multi-class). A single SVM classifier is trained with the same features to directly assign to each pair one of the four entailment judgments. Both the baselines have been calculated with the LIBSVM package (Chang and Lin, 2011), using a linear kernel with default parameters. Baseline results are reported in Table 2. Although the four CLTE datasets are derived from the same monolingual EN-EN corpus, baseline results present slight differences due to the effect of translation into different languages. SP-EN IT-EN FR-EN DE-EN 1-class 0.25 0.25 0.25 0.25 Binary 0.34 0.39 0.39 0.40 Multi-class 0.43 0.44 0.42 0.42 Table 2: Baseline accuracy results. 5 Submitted runs and results Participants were allowed to submit up to five runs for each language combination. A total of 17 teams registered to participate in the task and d</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2011. Libsvm: a library for support vector machines. ACM Transactions on Intelligent Systems and Technology (TIST), 2(3):27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
</authors>
<title>Probabilistic Textual Entailment: Generic Applied Modeling of Language Variability.</title>
<date>2004</date>
<booktitle>In Proceedings of the PASCAL Workshop of Learning Methods for Text Understanding and Mining.</booktitle>
<contexts>
<context position="1150" citStr="Dagan and Glickman, 2004" startWordPosition="151" endWordPosition="154"> written in different languages, targeting at the same time a real application scenario. Participants were presented with datasets for different language pairs, where multi-directional entailment relations (“forward”, “backward”, “bidirectional”, “no entailment”) had to be identified. We report on the training and test data used for evaluation, the process of their creation, the participating systems (10 teams, 92 runs), the approaches adopted and the results achieved. 1 Introduction The cross-lingual textual entailment task (Mehdad et al., 2010) addresses textual entailment (TE) recognition (Dagan and Glickman, 2004) under the new dimension of cross-linguality, and within the new challenging application scenario of content synchronization. Cross-linguality represents a dimension of the TE recognition problem that has been so far only partially investigated. The great potential for integrating monolingual TE recognition components into NLP architectures has been reported in several areas, including question answering, information retrieval, information extraction, and document summarization. However, mainly due to the absence of cross-lingual textual entailment (CLTE) recognition Danilo Giampiccolo CELCT T</context>
</contexts>
<marker>Dagan, Glickman, 2004</marker>
<rawString>Ido Dagan and Oren Glickman. 2004. Probabilistic Textual Entailment: Generic Applied Modeling of Language Variability. In Proceedings of the PASCAL Workshop of Learning Methods for Text Understanding and Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miquel Espl`a-Gomis</author>
<author>Felipe S´anchez-Martfnez</author>
<author>Mikel L Forcada</author>
</authors>
<title>UAlacant: Using Online Machine Translation for Cross-Lingual Textual Entailment.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<marker>Espl`a-Gomis, S´anchez-Martfnez, Forcada, 2012</marker>
<rawString>Miquel Espl`a-Gomis, Felipe S´anchez-Martfnez, and Mikel L. Forcada. 2012. UAlacant: Using Online Machine Translation for Cross-Lingual Textual Entailment. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikel L Forcada</author>
<author>Ginestf-Rosell Mireia</author>
<author>Nordfalk Jacob</author>
<author>O’Regan Jim</author>
<author>Ortiz-Rojas Sergio</author>
<author>P´erez-Ortiz Juan A</author>
<author>S´anchez-Martfnez Felipe</author>
<author>Ramfrez-S´anchez Gema</author>
<author>Tyers Francis M</author>
</authors>
<title>Apertium: a Free/OpenSource Platform for Rule-Based Machine Translation. Machine Translation, 25(2):127–144. Special Issue: Free/Open-Source Machine Translation.</title>
<date>2011</date>
<contexts>
<context position="26617" citStr="Forcada et al., 2011" startWordPosition="4141" endWordPosition="4144">of additional training material. 405 SoftCard [pivoting, multi-class] (Jimenez et al., 2012) after automatic translation with Google Translate, uses SVMs to learn entailment decisions based on information about the cardinality of: T1, T2, their intersection and their union. Cardinalities are computed in different ways, considering tokens in T1 and T2, their IDF, and their similarity (computed with edit-distance) UAlacant [pivoting, multi-class] (Espl`a-Gomis et al., 2012) exploits translations obtained from Google Translate, Microsoft Bing translator, and the Apertium open-source MT platform (Forcada et al., 2011).8 Then, a multi-class SVM classifier is used to take entailment decisions using information about overlapping sub-segments as features. 7 Conclusion Despite the novelty of the problem and the difficulty to capture multi-directional entailment relations across languages, the first round of the Crosslingual Textual Entailment for Content Synchronization task organized within SemEval-2012 was a successful experience. This year a new interesting challenge has been proposed, a benchmark for four language combinations has been released, baseline results have been proposed for comparison, and a mono</context>
</contexts>
<marker>Forcada, Mireia, Jacob, Jim, Sergio, A, Felipe, Gema, M, 2011</marker>
<rawString>Mikel L. Forcada, Ginestf-Rosell Mireia, Nordfalk Jacob, O’Regan Jim, Ortiz-Rojas Sergio, P´erez-Ortiz Juan A., S´anchez-Martfnez Felipe, Ramfrez-S´anchez Gema, and Tyers Francis M. 2011. Apertium: a Free/OpenSource Platform for Rule-Based Machine Translation. Machine Translation, 25(2):127–144. Special Issue: Free/Open-Source Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergio Jimenez</author>
<author>Claudia Becerra</author>
<author>Alexander Gelbukh</author>
</authors>
<title>Soft Cardinality + ML: Learning Adaptive Similarity Functions for Cross-lingual Textual Entailment.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="26088" citStr="Jimenez et al., 2012" startWordPosition="4067" endWordPosition="4070">nglish pairs. Separate lexical mapping scores are calculated (from T1 to T2 and vice-versa) considering different types of information and similarity metrics. Binary entailment de7http://www.microsofttranslator.com/ cisions are then heuristically combined into single decisions. Sagan [pivoting, multi-class] (Castillo and Cardenas, 2012) adopts a pivoting method using Google Translate, and trains a monolingual system based on a SVM multi-class classifier. A CLTE corpus derived from the RTE-3 dataset is also used as a source of additional training material. 405 SoftCard [pivoting, multi-class] (Jimenez et al., 2012) after automatic translation with Google Translate, uses SVMs to learn entailment decisions based on information about the cardinality of: T1, T2, their intersection and their union. Cardinalities are computed in different ways, considering tokens in T1 and T2, their IDF, and their similarity (computed with edit-distance) UAlacant [pivoting, multi-class] (Espl`a-Gomis et al., 2012) exploits translations obtained from Google Translate, Microsoft Bing translator, and the Apertium open-source MT platform (Forcada et al., 2011).8 Then, a multi-class SVM classifier is used to take entailment decisi</context>
</contexts>
<marker>Jimenez, Becerra, Gelbukh, 2012</marker>
<rawString>Sergio Jimenez, Claudia Becerra, and Alexander Gelbukh. 2012. Soft Cardinality + ML: Learning Adaptive Similarity Functions for Cross-lingual Textual Entailment. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Milen Kouylekov</author>
<author>Matteo Negri</author>
</authors>
<title>An opensource package for recognizing textual entailment.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 System Demonstrations.</booktitle>
<contexts>
<context position="21174" citStr="Kouylekov and Negri, 2010" startWordPosition="3272" endWordPosition="3275">classification using SVMs. HDU [hybrid, compositional] (W¨aschle and Fendrich, 2012) uses a combination of binary classifiers for each entailment direction. The classifiers use both monolingual alignment features based on METEOR (Banerjee and Lavie, 2005) alignments (translations obtained from Google Translate), and cross-lingual alignment features based on GIZA++ (Och and Ney, 2000) (word alignments learned on Europarl). ICT [pivoting, compositional] (Meng et al., 2012) adopts a pivoting method (using Google Translate and an in-house hierarchical MT system), and the open source EDITS system (Kouylekov and Negri, 2010) to calculate similarity scores between monolingual English pairs. Separate unidirectional entailment judgments obtained from binary classifier are combined to return one of the four valid CLTE judgments. 5http://www.freedict.com/ 6http://www.wordreference.com/ 404 SP-EN Forward Backward No entailment Bidirectional System name P R F1 P R F1 P R F1 P R F1 BUAP spa-eng run2 0,337 0,664 0,447 0,406 0,568 0,473 0,333 0,088 0,139 0,391 0,144 0,211 celi spa-eng run2 0,324 0,368 0,345 0,411 0,368 0,388 0,306 0,296 0,301 0,312 0,312 0,312 DirRelCond3 spa-eng run4 0,358 0,608 0,451 0,444 0,448 0,446 0,</context>
</contexts>
<marker>Kouylekov, Negri, 2010</marker>
<rawString>Milen Kouylekov and Matteo Negri. 2010. An opensource package for recognizing textual entailment. In Proceedings of the ACL 2010 System Demonstrations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Milen Kouylekov</author>
</authors>
<title>CELI: An Experiment with Cross Language Textual Entailment.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="19489" citStr="Kouylekov, 2012" startWordPosition="3028" endWordPosition="3029">rds lists, and Wikipedia as an external multilingual corpus. More in detail: BUAP [pivoting, compositional] (Vilari˜no et al., 2012) adopts a pivoting method based on translating T1 into the language of T2 and vice versa (Google Translate3 and the OpenOffice Thesaurus4). Similarity measures (e.g. Jaccard index) and rules are 3http://translate.google.com/ 4http://extensions.services.openoffice. org/en/taxonomy/term/233 respectively used to annotate the two resulting sentence pairs with entailment judgments and combine them in a single decision. CELI [cross lingual, compositional &amp; multiclass] (Kouylekov, 2012) uses dictionaries for word matching, and a multilingual corpus extracted from Wikipedia for term weighting. Word overlap and similarity measures are then used in different approaches to the task. In one run (Run 1), they are used to train a classifier that assigns separate entailment judgments for each direction. Such judgments are finally composed into a single one for each pair. In the other runs, the same features are used for multi-class classification. DirRelCond3 [cross lingual, compositional] (Perini, 2012) uses bilingual dictionaries (Freedict5 and WordReference6) to translate content</context>
</contexts>
<marker>Kouylekov, 2012</marker>
<rawString>Milen Kouylekov. 2012. CELI: An Experiment with Cross Language Textual Entailment. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Marcello Federico</author>
</authors>
<title>Towards Cross-Lingual Textual Entailment.</title>
<date>2010</date>
<booktitle>In Proceedings of the 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT</booktitle>
<contexts>
<context position="1077" citStr="Mehdad et al., 2010" startWordPosition="141" endWordPosition="144">sk was designed to promote research on semantic inference over texts written in different languages, targeting at the same time a real application scenario. Participants were presented with datasets for different language pairs, where multi-directional entailment relations (“forward”, “backward”, “bidirectional”, “no entailment”) had to be identified. We report on the training and test data used for evaluation, the process of their creation, the participating systems (10 teams, 92 runs), the approaches adopted and the results achieved. 1 Introduction The cross-lingual textual entailment task (Mehdad et al., 2010) addresses textual entailment (TE) recognition (Dagan and Glickman, 2004) under the new dimension of cross-linguality, and within the new challenging application scenario of content synchronization. Cross-linguality represents a dimension of the TE recognition problem that has been so far only partially investigated. The great potential for integrating monolingual TE recognition components into NLP architectures has been reported in several areas, including question answering, information retrieval, information extraction, and document summarization. However, mainly due to the absence of cross</context>
</contexts>
<marker>Mehdad, Negri, Federico, 2010</marker>
<rawString>Yashar Mehdad, Matteo Negri, and Marcello Federico. 2010. Towards Cross-Lingual Textual Entailment. In Proceedings of the 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Marcello Federico</author>
</authors>
<title>Using Bilingual Parallel Corpora for CrossLingual Textual Entailment.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL HLT</booktitle>
<contexts>
<context position="20452" citStr="Mehdad et al., 2011" startWordPosition="3169" endWordPosition="3172">omposed into a single one for each pair. In the other runs, the same features are used for multi-class classification. DirRelCond3 [cross lingual, compositional] (Perini, 2012) uses bilingual dictionaries (Freedict5 and WordReference6) to translate content words into English. Then, entailment decisions are taken combining directional relatedness scores between words in both directions (Perini, 2011). FBK [cross lingual, compositional &amp; multiclass] (Mehdad et al., 2012a) uses cross-lingual matching features extracted from lexical phrase tables, semantic phrase tables, and dependency relations (Mehdad et al., 2011; Mehdad et al., 2012b; Mehdad et al., 2012c). The features are used for multi-class and binary classification using SVMs. HDU [hybrid, compositional] (W¨aschle and Fendrich, 2012) uses a combination of binary classifiers for each entailment direction. The classifiers use both monolingual alignment features based on METEOR (Banerjee and Lavie, 2005) alignments (translations obtained from Google Translate), and cross-lingual alignment features based on GIZA++ (Och and Ney, 2000) (word alignments learned on Europarl). ICT [pivoting, compositional] (Meng et al., 2012) adopts a pivoting method (us</context>
</contexts>
<marker>Mehdad, Negri, Federico, 2011</marker>
<rawString>Yashar Mehdad, Matteo Negri, and Marcello Federico. 2011. Using Bilingual Parallel Corpora for CrossLingual Textual Entailment. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL HLT 2011).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Jos´e G C de Souza</author>
</authors>
<title>FBK: Cross-Lingual Textual Entailment Without Translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<marker>Mehdad, Negri, de Souza, 2012</marker>
<rawString>Yashar Mehdad, Matteo Negri, and Jos´e G. C. de Souza. 2012a. FBK: Cross-Lingual Textual Entailment Without Translation. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Marcello Federico</author>
</authors>
<title>Detecting Semantic Equivalence and Information Disparity in Cross-lingual Documents.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<contexts>
<context position="20305" citStr="Mehdad et al., 2012" startWordPosition="3148" endWordPosition="3151">In one run (Run 1), they are used to train a classifier that assigns separate entailment judgments for each direction. Such judgments are finally composed into a single one for each pair. In the other runs, the same features are used for multi-class classification. DirRelCond3 [cross lingual, compositional] (Perini, 2012) uses bilingual dictionaries (Freedict5 and WordReference6) to translate content words into English. Then, entailment decisions are taken combining directional relatedness scores between words in both directions (Perini, 2011). FBK [cross lingual, compositional &amp; multiclass] (Mehdad et al., 2012a) uses cross-lingual matching features extracted from lexical phrase tables, semantic phrase tables, and dependency relations (Mehdad et al., 2011; Mehdad et al., 2012b; Mehdad et al., 2012c). The features are used for multi-class and binary classification using SVMs. HDU [hybrid, compositional] (W¨aschle and Fendrich, 2012) uses a combination of binary classifiers for each entailment direction. The classifiers use both monolingual alignment features based on METEOR (Banerjee and Lavie, 2005) alignments (translations obtained from Google Translate), and cross-lingual alignment features based </context>
</contexts>
<marker>Mehdad, Negri, Federico, 2012</marker>
<rawString>Yashar Mehdad, Matteo Negri, and Marcello Federico. 2012b. Detecting Semantic Equivalence and Information Disparity in Cross-lingual Documents. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Marcello Federico</author>
</authors>
<title>Match without a Referee: Evaluating MT Adequacy without Reference Translations.</title>
<date>2012</date>
<booktitle>In Proceedings of the 7th Workshop on Statistical Machine Translation (WMT</booktitle>
<contexts>
<context position="20305" citStr="Mehdad et al., 2012" startWordPosition="3148" endWordPosition="3151">In one run (Run 1), they are used to train a classifier that assigns separate entailment judgments for each direction. Such judgments are finally composed into a single one for each pair. In the other runs, the same features are used for multi-class classification. DirRelCond3 [cross lingual, compositional] (Perini, 2012) uses bilingual dictionaries (Freedict5 and WordReference6) to translate content words into English. Then, entailment decisions are taken combining directional relatedness scores between words in both directions (Perini, 2011). FBK [cross lingual, compositional &amp; multiclass] (Mehdad et al., 2012a) uses cross-lingual matching features extracted from lexical phrase tables, semantic phrase tables, and dependency relations (Mehdad et al., 2011; Mehdad et al., 2012b; Mehdad et al., 2012c). The features are used for multi-class and binary classification using SVMs. HDU [hybrid, compositional] (W¨aschle and Fendrich, 2012) uses a combination of binary classifiers for each entailment direction. The classifiers use both monolingual alignment features based on METEOR (Banerjee and Lavie, 2005) alignments (translations obtained from Google Translate), and cross-lingual alignment features based </context>
</contexts>
<marker>Mehdad, Negri, Federico, 2012</marker>
<rawString>Yashar Mehdad, Matteo Negri, and Marcello Federico. 2012c. Match without a Referee: Evaluating MT Adequacy without Reference Translations. In Proceedings of the 7th Workshop on Statistical Machine Translation (WMT 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fandong Meng</author>
<author>Hao Xiong</author>
<author>Qun Liu</author>
</authors>
<title>ICT: A Translation based Cross-lingual Textual Entailment.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="21023" citStr="Meng et al., 2012" startWordPosition="3249" endWordPosition="3252">, and dependency relations (Mehdad et al., 2011; Mehdad et al., 2012b; Mehdad et al., 2012c). The features are used for multi-class and binary classification using SVMs. HDU [hybrid, compositional] (W¨aschle and Fendrich, 2012) uses a combination of binary classifiers for each entailment direction. The classifiers use both monolingual alignment features based on METEOR (Banerjee and Lavie, 2005) alignments (translations obtained from Google Translate), and cross-lingual alignment features based on GIZA++ (Och and Ney, 2000) (word alignments learned on Europarl). ICT [pivoting, compositional] (Meng et al., 2012) adopts a pivoting method (using Google Translate and an in-house hierarchical MT system), and the open source EDITS system (Kouylekov and Negri, 2010) to calculate similarity scores between monolingual English pairs. Separate unidirectional entailment judgments obtained from binary classifier are combined to return one of the four valid CLTE judgments. 5http://www.freedict.com/ 6http://www.wordreference.com/ 404 SP-EN Forward Backward No entailment Bidirectional System name P R F1 P R F1 P R F1 P R F1 BUAP spa-eng run2 0,337 0,664 0,447 0,406 0,568 0,473 0,333 0,088 0,139 0,391 0,144 0,211 ce</context>
</contexts>
<marker>Meng, Xiong, Liu, 2012</marker>
<rawString>Fandong Meng, Hao Xiong, and Qun Liu. 2012. ICT: A Translation based Cross-lingual Textual Entailment. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matto Negri</author>
<author>Luisa Bentivogli</author>
<author>Yashar Mehdad</author>
<author>Danilo Giampiccolo</author>
<author>Alessandro Marchetti</author>
</authors>
<title>Divide and Conquer: Crowdsourcing the Creation of Cross-Lingual Textual Entailment Corpora.</title>
<date>2011</date>
<booktitle>Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<contexts>
<context position="6140" citStr="Negri et al., 2011" startWordPosition="896" endWordPosition="899">is task, both T1 and T2 are assumed to be true statements. Although contradiction is relevant from an application-oriented perspective, contradictory pairs are not present in the dataset created for the first round of the task. 3 Dataset description Four CLTE corpora have been created for the following language combinations: Spanish/English (SP-EN), Italian/English (IT-EN), French/English (FR-EN), German/English (DE-EN). The datasets are released in the XML format shown in Figure 1. 3.1 Data collection and annotation The dataset was created following the crowdsourcing methodology proposed in (Negri et al., 2011), which consists of the following steps: 1. First, English sentences were manually extracted from copyright-free sources (Wikipedia and Wikinews). The selected sentences represent one of the elements (T1) of each entailment pair; 2. Next, each T1 was modified through crowdsourcing in various ways in order to obtain a corresponding T2 (e.g. introducing meaning-preserving lexical and syntactic changes, adding and removing portions of text); 3. Each T2 was then paired to the original T1, and the resulting pairs were annotated with one of the four entailment judgments. In order to reduce the corre</context>
</contexts>
<marker>Negri, Bentivogli, Mehdad, Giampiccolo, Marchetti, 2011</marker>
<rawString>Matto Negri, Luisa Bentivogli, Yashar Mehdad, Danilo Giampiccolo, and Alessandro Marchetti. 2011. Divide and Conquer: Crowdsourcing the Creation of Cross-Lingual Textual Entailment Corpora. Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP 2011).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Snehasis Neogi</author>
<author>Partha Pakray</author>
<author>Sivaji Bandyopadhyay</author>
<author>Alexander Gelbukh</author>
</authors>
<title>JU-CSE-NLP: Language Independent Cross-lingual Textual Entailment System.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="25410" citStr="Neogi et al., 2012" startWordPosition="3971" endWordPosition="3974">2 ICT deu-eng run1 0,718 0,224 0,341 0,493 0,552 0,521 0,390 0,512 0,443 0,439 0,552 0,489 JU-CSE-NLP deu-eng run2 0,182 0,048 0,076 0,307 0,496 0,379 0,315 0,560 0,403 0,233 0,080 0,119 Sagan deu-eng run1 0,250 0,168 0,201 0,239 0,256 0,247 0,405 0,600 0,484 0,443 0,344 0,387 SoftCard deu-eng run1 0,568 0,568 0,568 0,611 0,640 0,625 0,521 0,488 0,504 0,496 0,504 0,500 AVG. 0,431 0,298 0,332 0,414 0,476 0,440 0,403 0,496 0,434 0,390 0,361 0,368 Table 4: precision, recall and F1 scores, calculated for each team’s best run for all the language combinations. JU-CSE-NLP [pivoting, compositional] (Neogi et al., 2012) uses Microsoft Bing translator7 to produce monolingual English pairs. Separate lexical mapping scores are calculated (from T1 to T2 and vice-versa) considering different types of information and similarity metrics. Binary entailment de7http://www.microsofttranslator.com/ cisions are then heuristically combined into single decisions. Sagan [pivoting, multi-class] (Castillo and Cardenas, 2012) adopts a pivoting method using Google Translate, and trains a monolingual system based on a SVM multi-class classifier. A CLTE corpus derived from the RTE-3 dataset is also used as a source of additional </context>
</contexts>
<marker>Neogi, Pakray, Bandyopadhyay, Gelbukh, 2012</marker>
<rawString>Snehasis Neogi, Partha Pakray, Sivaji Bandyopadhyay, and Alexander Gelbukh. 2012. JU-CSE-NLP: Language Independent Cross-lingual Textual Entailment System. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>Improved Statistical Alignment Models.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<contexts>
<context position="20934" citStr="Och and Ney, 2000" startWordPosition="3237" endWordPosition="3240">ss-lingual matching features extracted from lexical phrase tables, semantic phrase tables, and dependency relations (Mehdad et al., 2011; Mehdad et al., 2012b; Mehdad et al., 2012c). The features are used for multi-class and binary classification using SVMs. HDU [hybrid, compositional] (W¨aschle and Fendrich, 2012) uses a combination of binary classifiers for each entailment direction. The classifiers use both monolingual alignment features based on METEOR (Banerjee and Lavie, 2005) alignments (translations obtained from Google Translate), and cross-lingual alignment features based on GIZA++ (Och and Ney, 2000) (word alignments learned on Europarl). ICT [pivoting, compositional] (Meng et al., 2012) adopts a pivoting method (using Google Translate and an in-house hierarchical MT system), and the open source EDITS system (Kouylekov and Negri, 2010) to calculate similarity scores between monolingual English pairs. Separate unidirectional entailment judgments obtained from binary classifier are combined to return one of the four valid CLTE judgments. 5http://www.freedict.com/ 6http://www.wordreference.com/ 404 SP-EN Forward Backward No entailment Bidirectional System name P R F1 P R F1 P R F1 P R F1 BUA</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>Franz J. Och and Hermann Ney. 2000. Improved Statistical Alignment Models. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics (ACL 2000).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alp´ar Perini</author>
</authors>
<title>Detecting textual entailment with conditions on directional text relatedness scores.</title>
<date>2011</date>
<booktitle>Studia Universitatis Babes-Bolyai Series Informatica, LVI(2):13–18.</booktitle>
<contexts>
<context position="20235" citStr="Perini, 2011" startWordPosition="3139" endWordPosition="3140">ity measures are then used in different approaches to the task. In one run (Run 1), they are used to train a classifier that assigns separate entailment judgments for each direction. Such judgments are finally composed into a single one for each pair. In the other runs, the same features are used for multi-class classification. DirRelCond3 [cross lingual, compositional] (Perini, 2012) uses bilingual dictionaries (Freedict5 and WordReference6) to translate content words into English. Then, entailment decisions are taken combining directional relatedness scores between words in both directions (Perini, 2011). FBK [cross lingual, compositional &amp; multiclass] (Mehdad et al., 2012a) uses cross-lingual matching features extracted from lexical phrase tables, semantic phrase tables, and dependency relations (Mehdad et al., 2011; Mehdad et al., 2012b; Mehdad et al., 2012c). The features are used for multi-class and binary classification using SVMs. HDU [hybrid, compositional] (W¨aschle and Fendrich, 2012) uses a combination of binary classifiers for each entailment direction. The classifiers use both monolingual alignment features based on METEOR (Banerjee and Lavie, 2005) alignments (translations obtain</context>
</contexts>
<marker>Perini, 2011</marker>
<rawString>Alp´ar Perini. 2011. Detecting textual entailment with conditions on directional text relatedness scores. Studia Universitatis Babes-Bolyai Series Informatica, LVI(2):13–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alp´ar Perini</author>
</authors>
<title>DirRelCond3: Detecting Textual Entailment Across Languages With Conditions On Directional Text Relatedness Scores.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="20009" citStr="Perini, 2012" startWordPosition="3110" endWordPosition="3111">them in a single decision. CELI [cross lingual, compositional &amp; multiclass] (Kouylekov, 2012) uses dictionaries for word matching, and a multilingual corpus extracted from Wikipedia for term weighting. Word overlap and similarity measures are then used in different approaches to the task. In one run (Run 1), they are used to train a classifier that assigns separate entailment judgments for each direction. Such judgments are finally composed into a single one for each pair. In the other runs, the same features are used for multi-class classification. DirRelCond3 [cross lingual, compositional] (Perini, 2012) uses bilingual dictionaries (Freedict5 and WordReference6) to translate content words into English. Then, entailment decisions are taken combining directional relatedness scores between words in both directions (Perini, 2011). FBK [cross lingual, compositional &amp; multiclass] (Mehdad et al., 2012a) uses cross-lingual matching features extracted from lexical phrase tables, semantic phrase tables, and dependency relations (Mehdad et al., 2011; Mehdad et al., 2012b; Mehdad et al., 2012c). The features are used for multi-class and binary classification using SVMs. HDU [hybrid, compositional] (W¨asc</context>
</contexts>
<marker>Perini, 2012</marker>
<rawString>Alp´ar Perini. 2012. DirRelCond3: Detecting Textual Entailment Across Languages With Conditions On Directional Text Relatedness Scores. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Darnes Vilari˜no</author>
<author>David Pinto</author>
<author>Mireya Tovar</author>
<author>Saul Le´on</author>
<author>Esteban Castillo</author>
</authors>
<title>BUAP: Lexical and Semantic Similarity for Cross-lingual Textual Entailment.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<marker>Vilari˜no, Pinto, Tovar, Le´on, Castillo, 2012</marker>
<rawString>Darnes Vilari˜no, David Pinto, Mireya Tovar, Saul Le´on, and Esteban Castillo. 2012. BUAP: Lexical and Semantic Similarity for Cross-lingual Textual Entailment. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katharina W¨aschle</author>
<author>Sascha Fendrich</author>
</authors>
<title>HDU: Cross-lingual Textual Entailment with SMT Features.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<marker>W¨aschle, Fendrich, 2012</marker>
<rawString>Katharina W¨aschle and Sascha Fendrich. 2012. HDU: Cross-lingual Textual Entailment with SMT Features. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>