<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000721">
<title confidence="0.9890325">
Robustness Issues in a Data-Driven Spoken Language Understanding
System
</title>
<author confidence="0.997471">
Yulan He and Steve Young
</author>
<affiliation confidence="0.994101">
Cambridge University Engineering Department
</affiliation>
<address confidence="0.705269">
Trumpington Street, Cambridge CB2 1PZ, England
</address>
<email confidence="0.9973">
{yh213, sjy}@eng.cam.ac.uk
</email>
<sectionHeader confidence="0.942014" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999401393939394">
Robustness is a key requirement in spoken lan-
guage understanding (SLU) systems. Human
speech is often ungrammatical and ill-formed,
and there will frequently be a mismatch be-
tween training and test data. This paper dis-
cusses robustness and adaptation issues in a
statistically-based SLU system which is en-
tirely data-driven. To test robustness, the sys-
tem has been tested on data from the Air Travel
Information Service (ATIS) domain which has
been artificially corrupted with varying levels
of additive noise. Although the speech recog-
nition performance degraded steadily, the sys-
tem did not fail catastrophically. Indeed, the
rate at which the end-to-end performance of
the complete system degraded was significantly
slower than that of the actual recognition com-
ponent. In a second set of experiments, the
ability to rapidly adapt the core understanding
component of the system to a different appli-
cation within the same broad domain has been
tested. Using only a small amount of training
data, experiments have shown that a semantic
parser based on the Hidden Vector State (HVS)
model originally trained on the ATIS corpus
can be straightforwardly adapted to the some-
what different DARPA Communicator task us-
ing standard adaptation algorithms. The paper
concludes by suggesting that the results pre-
sented provide initial support to the claim that
an SLU system which is statistically-based and
trained entirely from data is intrinsically robust
and can be readily adapted to new applications.
</bodyText>
<sectionHeader confidence="0.999259" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999691710526316">
Spoken language is highly variable as different people
use different words and sentence structures to convey the
same meaning. Also, many utterances are grammatically-
incorrect or ill-formed. It thus remains an open issue as to
how to provide robustness for large populations of non-
expert users in spoken dialogue systems. The key compo-
nent of a spoken language understanding (SLU) system is
the semantic parser, which translates the users’ utterances
into semantic representations. Traditionally, most seman-
tic parser systems have been built using hand-crafted se-
mantic grammar rules and so-called robust parsing (Ward
and Issar, 1996; Seneff, 1992; Dowding et al., 1994) is
used to handle the ill-formed user input in which word
patterns corresponding to semantic tokens are used to fill
slots in different semantic frames in parallel. The frame
with the highest score then yields the selected semantic
representation.
Formally speaking, the robustness of language (recog-
nition, parsing, etc.) is a measure of the ability of hu-
man speakers to communicate despite incomplete infor-
mation, ambiguity, and the constant element of surprise
(Briscoe, 1996). In this paper, two aspects of SLU sys-
tem performance are investigated: noise robustness and
adaptability to different applications. For the former, we
expect that an SLU system should maintain acceptable
performance when given noisy input speech data. This
requires, the understanding components of the SLU sys-
tem to be able to correctly interpret the meaning of an
utterance even when faced with recognition errors. For
the latter, the SLU system should be readily adaptable to
a different application using a relatively small set (e.g.
less than 100) of adaptation utterances.
The rest of the paper is organized as follows. An
overview of our data-driven SLU system is outlined in
section 2. Experimental results on performance under a
range of SNRs are then presented in section 3. Section 4
discusses adaptation of the HVS model to new applica-
tions. Finally, section 5 concludes the paper.
</bodyText>
<sectionHeader confidence="0.947188" genericHeader="method">
2 System Overview
</sectionHeader>
<bodyText confidence="0.999952444444445">
Spoken language understanding (SLU) aims to interpret
the meanings of users’ utterances and respond reason-
ably to what users have said. A typical architecture of
an SLU system is given in Fig. 1, which consists of a
speech recognizer, a semantic parser, and a dialog act de-
coder. Within a statistical framework, the SLU problem
can be factored into three stages. First the speech recog-
nizer recognizes the underlying word string W from each
input acoustic signal A, i.e.
</bodyText>
<equation confidence="0.9996175">
P(W|A) = argmax P(A|W)P(W) (1)
W
</equation>
<bodyText confidence="0.651954">
then the semantic parser maps the recognized word string
Wˆ into a set of semantic concepts C
</bodyText>
<equation confidence="0.99618">
P(C |Wˆ) (2)
</equation>
<bodyText confidence="0.997314">
and finally the dialogue act decoder infers the user’s dia-
log acts or goals by solving
</bodyText>
<equation confidence="0.732457">
ˆGu = argmax P(Gu |ˆC) (3)
</equation>
<figure confidence="0.840736">
Gu
Acoustic Signal Words Concepts User’s Dialog Acts
A Speech W Semantic C Dialog Act
Recognizer Parser Decoder
</figure>
<figureCaption confidence="0.989358">
Figure 1: Typical structure of a spoken language under-
standing system.
</figureCaption>
<bodyText confidence="0.999902">
The sequential decoding described above is suboptimal
since the solution at each stage depends on an exact so-
lution to the previous stage. To reduce the effect of this
approximation, a word lattice or N-best word hypotheses
can be retained instead of the single best string Wˆ as the
output of the speech recognizer. The semantic parse re-
sults may then be incorporated with the output from the
speech recognizer to rescore the N-best list as below.
model for semantic parsing (He and Young, 2003b), and
Tree-Augmented Naive Bayes networks (TAN) (Fried-
man et al., 1997) for dialog act decoding.
The speech recognizer comprises 14 mixture Gaus-
sian HMM state-clustered cross-word triphones aug-
mented by using heteroscedastic linear discriminant anal-
ysis (HLDA) (Kumar, 1997). Incremental speaker adap-
tation based on the maximum likelihood linear regression
(MLLR) method (Gales and Woodland, 1996) was per-
formed during the test with updating being performed in
batches of five utterances per speaker.
The Hidden Vector State (HVS) model (He and Young,
2003b) is a hierarchical semantic parser which associates
each state of a push-down automata with the state of a
HMM. State transitions are factored into separate stack
pop and push operations and then constrained to give
a tractable search space. The result is a model which
is complex enough to capture hierarchical structure but
which can be trained automatically from unannotated
data.
</bodyText>
<table confidence="0.7623816">
sent_start I want to return to Dallas on Thursday sent_end
SS DUMMY RETURN TOLOC CITY ON DATE SE
SS SS RETURN TOLOC RETURN ON SS
SS RETURN SS RETURN
SS SS
</table>
<figureCaption confidence="0.991375">
Figure 2: Example of a parse tree and its vector state
equivalent.
</figureCaption>
<bodyText confidence="0.997254857142857">
Let each state at time t be denoted by a vector of Dt
semantic concept labels (tags) ct = [ct[1], ct[2], ..ct[Dt]]
where ct[1] is the preterminal concept and ct[Dt] is the
root concept (SS in Figure 2). Given a word sequence
W, concept vector sequence C and a sequence of stack
pop operations N, the joint probability of P(W, C, N)
can be decomposed as
</bodyText>
<figure confidence="0.895368411764706">
DUMMY
SS
TOLOC ON
RETURN
CITY
DATE
SE
Wˆ = argmax
W
Cˆ = argmax
C
Gu
ˆC, Wˆ  argmax P(A|W)P(W)P(C|W) T P(nt|ct_1) ·
C,WELN H
 argmax t=1
C,WELN
P(A|W)P(W)ryP(C|W)a (4) P(W, C, N) =
</figure>
<bodyText confidence="0.998698">
where P(A|W) is the acoustic probability from the
first pass, P(W) is the language modelling likelihood,
P(C|W) is the semantic parse score, LN denotes the N-
best list, a is a semantic parse scale factor, and y is a
grammar scale factor.
In the system described in this paper, each of these
stages is modelled separately. We use a standard HTK-
based (HTK, 2004) Hidden Markov Model (HMM) rec-
ognizer for recognition, the Hidden Vector State (HVS)
</bodyText>
<equation confidence="0.971243">
P(ct[1]|ct[2··· Dt]) · P(wt|ct) (5)
</equation>
<bodyText confidence="0.993504625">
where ct at word position t is a vector of Dt semantic
concept labels (tags), nt is the vector stack shift operation
and takes values in the range 0, · · · , Dt_1 where Dt_1 is
the stack size at word position t − 1, and ct[1] = cwt is
the new preterminal semantic tag assigned to word wt at
word position t.
Thus, the HVS model consists of three types of proba-
bilistic move:
</bodyText>
<listItem confidence="0.99903">
1. popping semantic tags off the stack;
2. pushing a pre-terminal semantic tag onto the stack;
3. generating the next word.
</listItem>
<bodyText confidence="0.999792833333333">
The dialog act decoder was implemented using the
Tree-Augmented Naive Bayes (TAN) algorithm (Fried-
man et al., 1997), which is an extension of Naive Bayes
Networks. One TAN was used for each dialogue act or
goal G,,,, the semantic concepts Ci which serve as input
to its corresponding TAN were selected based on the mu-
tual information (MI) between the goal and the concept.
Naive Bayes networks assume all the concepts are con-
ditionally independent given the value of the goal. TAN
networks relax this independence assumption by adding
dependencies between concepts based on the conditional
mutual information (CMI) between concepts given the
goal. The goal prior probability P(G,,,) and the condi-
tional probability of each semantic concept Ci given the
goal G,,,, P(Ci|G,,,) are learned from the training data.
Dialogue act detection is done by picking the goal with
the highest posterior probability of G,,, given the particu-
lar instance of concepts Cl · · · Com,, P(G,,,|C, · · · Com,).
</bodyText>
<sectionHeader confidence="0.995225" genericHeader="method">
3 Noise Robustness
</sectionHeader>
<bodyText confidence="0.999977909090909">
The ATIS corpus which contains air travel information
data (Dahl et al., 1994) has been chosen for the SLU sys-
tem development and evaluation. ATIS was developed
in the DARPA sponsored spoken language understanding
programme conducted from 1990 to 1995 and it provides
a convenient and well-documented standard for measur-
ing the end-to-end performance of an SLU system. How-
ever, since the ATIS corpus contains only clean speech,
corrupted test data has been generated by adding samples
ofbackground noise to the clean test data at the waveform
level.
</bodyText>
<subsectionHeader confidence="0.996947">
3.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999991235294117">
The experimental setup used to evaluate the SLU system
was similar to that described in (He and Young, 2003a).
As mentioned in section 2, the SLU system consists of
three main components, a standard HTK-based HMM
recognizer, the HVS semantic parser, and the TAN dia-
logue act (DA) decoder. Each of the three major compo-
nents are trained separately. The acoustic speech signal
in the ATIS training data is modelled by extracting 39
features every 10ms: 12 cepstra, energy, and their first
and second derivatives. This data is then used to train the
speaker-independent, continuous speech recognizer. The
HVS semantic parser is trained on the unannotated utter-
ances using EM constrained by the domain-specific lex-
ical class information and the dominance relations built
into the abstract annotations (He and Young, 2003b). In
the case of ATIS, the lexical classes can be extracted au-
tomatically from the relational database, whilst abstract
semantic annotations for each utterance are automatically
derived from the accompanying SQL queries of the train-
ing utterances. The dialogue act decoder is trained using
the main topics or goals and the key semantic concepts
extracted automatically from the reference SQL queries
Performance is measured at both the component and
the system level. For the former, the recognizer is eval-
uated by word error rate, the parser by concept slot re-
trieval rate using an F-measure metric (Goel and Byrne,
1999), and the dialog act decoder by detection rate. The
overall system performance is measured using the stan-
dard NIST “query answer” rate.
In the expriments reported here, car noise from the
NOISEX-92 (Varga et al., 1992) database was added to
the ATIS-3 NOV93 and DEC94 test sets. In order to ob-
tain different SNRs, the noise was scaled accordingly be-
fore adding to the speech signal.
</bodyText>
<subsectionHeader confidence="0.998182">
3.2 Experimental Results
</subsectionHeader>
<bodyText confidence="0.999986807017544">
Robust spoken language understanding components
should be able to compensate for the weakness of the
speech recognizer. That is, ideally they should be capable
of generating the correct meaning of an utterance even
if it is recognized wrongly by a speech recognizer. At
minimum, the performance of the understanding compo-
nents should degrade gracefully as recognition accuracy
degrades.
Figure 3 gives the system performance on the cor-
rupted test data with additive noise ranging from 25dB to
10dB SNR. The label “clean” in the X-axis denotes the
original clean speech data without additive noise. Note
that the recognition results on the corrupted test data
were obtained directly using the original clean speech
HMM models without retraining for the noisy condi-
tions. The upper portion of Figure 3 shows the end-to-
end performance in terms of query answer error rate for
the NOV93 and DEC94 test sets. For easy reference,
WER is also shown. The individual component perfor-
mance, F-measure for the HVS semantic parser and di-
alogue act (DA) detection accuracy for the DA decoder,
are illustrated in the lower portion of Figure 3. For each
test set, the performance on the rescored word hypothe-
ses is given as well. This incorporates the semantic parse
scores into the acoustic and language modelling likeli-
hoods to rescore the 25-best word lists from the speech
recognizer.
It can be observed that the system gives fairly stable
performance at high SNRs and then the recognition accu-
racy degrades rapidly in the presence of increasing noise.
At 20dB SNR, the WER for the NOV93 test set increases
by 1.6 times relative to clean whilst the query answer
error rate increases by only 1.3 times. On decreasing
the SNR to 15dB, the system performance degrades sig-
nificantly. The WER increases by 3.1 times relative to
clean but the query answer error rate increases by only
1.7 times. Similar figures were obtained for the DEC94
test set.
The above suggests that the end-to-end performance
measured in terms of answer error rate degrades more
slowly compared to the recognizer WER as the noise
level increases. This demonstrates that the statistically-
based understanding components of the SLU system, the
semantic parser and the dialogue act decoder, are rela-
tively robust to degrading recognition performance.
Regarding the individual component performance, the
dialogue act detection accuracy appears to be less sensi-
tive to decreasing SNR. This is probably a consequence
of the fact that the Bayesian networks are set up to re-
spond to only the presence or absence of semantic con-
cepts or slots, regardless of the actual values assigned to
them. In another words, the performance of the dialogue
act decoder is not affected by the mis-recognition of indi-
vidual words, but only by a failure to detect the presence
of a semantic concept. It can also be observed from Fig-
ure 3 that the F-measure needs to be better than 85% in
order to achieve acceptable end-to-end performance.
</bodyText>
<sectionHeader confidence="0.957931" genericHeader="method">
4 Adaptation to New Applications
</sectionHeader>
<bodyText confidence="0.999096814814815">
Statistical model adaptation techniques are widely used
to reduce the mismatch between training and test or to
adapt a well-trained model to a novel domain. Com-
monly used techniques can be classified into two cat-
egories, Bayesian adaptation which uses a maximum a
posteriori (MAP) probability criteria (Gauvain and Lee,
1994) and transformation-based approaches such as max-
imum likelihood linear regression (MLLR) (Gales and
Woodland, 1996), which uses a maximum likelihood
(ML) criteria. In recent years, MAP adaptation has been
successfully applied to n-gram language models (Bac-
chiani and Roark, 2003) and lexicalized PCFG models
(Roark and Bacchiani, 2003). Luo et al. have proposed
transformation-based approaches based on the Markov
transform (Luo et al., 1999) and the Householder trans-
form (Luo, 2000), to adapt statistical parsers. However,
the optimisation processes for the latter are complex and
it is not clear how general they are.
Since MAP adaptation is straightforward and has been
applied successfully to PCFG parsers, it has been selected
for investigation in this paper. Since one of the special
forms of MAP adaptation is interpolation between the in-
domain and out-of-domain models, it is natural to also
consider the use of non-linear interpolation and hence this
has been studied as well 1.
&apos;Experiments using linear interpolation have also been con-
ducted but it was found that the results are worse than those
</bodyText>
<subsectionHeader confidence="0.980378">
4.1 MAP Adaptation
</subsectionHeader>
<bodyText confidence="0.9999752">
Bayesian adaptation reestimates model parameters di-
rectly using adaptation data. It can be implemented via
maximum a posteriori (MAP) estimation. Assuming that
model parameters are denoted by O, then given observa-
tion samples Y , the MAP estimate is obtained as
</bodyText>
<equation confidence="0.997992333333333">
OMAP = argmaxP(OIY) = argmaxP(Y |O)P(O)
 
(6)
</equation>
<bodyText confidence="0.999634466666667">
where P(YIO) is the likelihood of the adaptation data Y
and model parameters O are random vectors described by
their probabilistic mass function (pmf) P(O), also called
the prior distribution.
In the case of HVS model adaptation, the objective is to
estimate probabilities of discrete distributions over vector
state stack shift operations and output word generation.
Assuming that they can be modelled under the multino-
mial distribution, for mathematical tractability, the con-
jugate prior, the Dirichlet density, is normally used. As-
sume a parser model P(W, C) for a word sequence W
and semantic concept sequence C exists with J compo-
nent distributions Pj each of dimension K, then given
some adaptation data Wl, the MAP estimate of the kth
component of Pj, ˆPj(k), is
</bodyText>
<equation confidence="0.9983645">
ˆPj(k) = j
j + 
</equation>
<bodyText confidence="0.999902454545454">
where j = EKk=1 j(k) in which j(k) is defined as the
total count of the events associated with the kth compo-
nent of Pj summed across the decoding of all adaptation
utterances Wl,  is the prior weighting parameter, Pj(k)
is the probability of the original unadapted model, and
˜Pj(k) is the empirical distribution of the adaptation data,
which is defined as
As discussed in section 2, the HVS model consists of
three types of probabilistic move. The MAP adaptation
technique can be applied to the HVS model by adapting
each of these three component distributions individually.
</bodyText>
<subsectionHeader confidence="0.746518">
4.2 Log-Linear Interpolation
</subsectionHeader>
<bodyText confidence="0.977573375">
Log-linear interpolation has been applied to language
model adaptation and has been shown to be equivalent
to a constrained minimum Kullback-Leibler distance op-
timisation problem(Klakow, 1998).
Following the notation introduced in section 4.1, where
Pj(k) is the probability of the original unadapted model,
and ˜Pj(k) is the empirical distribution of the adaptation
obtained using MAP adaptation or log-linear interpolation.
</bodyText>
<equation confidence="0.8259726">
˜Pj(k) +  Pj(k) (7)
j + 
˜Pj(k) = j(k)
8
Ei= 1 j(i)
</equation>
<figure confidence="0.992841916666667">
Speech to Noise Ratio − SNR (NOV93 Test Set)
(a) NOV93 End-to-End Performance
Speech to Noise Ratio − SNR (NOV93 Test Set)
(b) NOV93 Component Performance
Speech to Noise Ratio − SNR (DEC94 Test Set)
(c) DEC94 End-to-End Performance
Speech to Noise Ratio − SNR (DEC94 Test Set)
(d) DEC94 Component Performance
WER
WER with Rescoring
Answer Error
Answer Error with Rescoring
38.5
33.5
28.5
23.5
18.5
13.5
8.5
3.5
clean 25dB 20dB 15dB 10dB
Spoken Language Understanding Error Rate (%)
43.5
0.95
0.9
0.75
F−measure
F−measure with Rescoring
DA Detection Accuracy
DA Detection Accuracy with Rescoring
0.7
clean 25dB 20dB 15dB 10dB
F−measure and DA Detection Accuracy
0.85
0.8
WER
WER with Rescoring
Answer Error
Answer Error with Rescoring
27.5
22.5
17.5
12.5
7.5
2.5
clean 25dB 20dB 15dB 10dB
Spoken Language Understanding Error Rate (%)
32.5
F−measure and DA Detection Accuracy
0.92
0.88
0.86
0.84
0.82
clean 25dB 20dB 15dB 10dB
0.9
F−measure
F−measure with Rescoring
DA Detection Accuracy
DA Detection Accuracy with Rescoring
</figure>
<figureCaption confidence="0.999932">
Figure 3: SLU system performance vs SNR.
</figureCaption>
<bodyText confidence="0.9978065">
data, denote the final adapted model probability as ˆPj(k).
It is assumed that the Kullback-Leibler distance of the
adapted model to the unadapted and empirically deter-
mined model is
</bodyText>
<equation confidence="0.999994">
D(ˆPj(k) 11 Pj(k)) = d1 (9)
D(ˆPj(k) 11 ˜Pj(k)) = d2 (10)
</equation>
<bodyText confidence="0.997643529411764">
Given an additional model probability ¯Pj(k) whose
distance to ˆPj(k) should be kept small, and introducing
Lagrange multipliers A�1 and A2 to ensure that constraints
9 and 10 are satistifed, yields
Minimizing D with respect to ˆPj(k) yields the required
distribution.
With some manipulation and redefinition of the La-
grange Multipliers, it can be shown that
where Pj(k) has been assumed to be a uniform distribu-
tion which is then absorbed into the normalization term
Z.
The computation of Z is very expensive and can usu-
ally be dropped without significant loss in performance
(Martin et al., 2000). For the other parameters, A1 and
A2, the generalized iterative scaling algorithm or the sim-
plex method can be employed to estimate their optimal
settings.
</bodyText>
<subsectionHeader confidence="0.989905">
4.3 Experiments
</subsectionHeader>
<bodyText confidence="0.99980917948718">
To test the portability of the statistical parser, the initial
experiments reported here are focussed on assessing the
adaptability of the HVS model when it is tested in a do-
main which covers broadly similar concepts, but com-
prises rather different speaking styles. To this end, the
flight information subset of the DARPA Communicator
Travel task has been used as the target domain (CUD-
ata, 2004). By limiting the test in this way, we ensure
that the dimensionalities of the HVS model parameters
remain the same and no new semantic concepts are intro-
duced by the adaptation training data.
The baseline HVS parser was trained on the ATIS
corpus using 4978 utterances selected from the context-
independent (Class A) training data in the ATIS-2 and
ATIS-3 corpora. The vocabulary size of the ATIS training
corpus is 611 and there are altogether 110 semantic con-
cepts defined. The parser model was then adapted using
utterances relating to flight reservation from the DARPA
Communicator data. Although the latter bears similari-
ties to the ATIS data, it contains utterances of a different
style and is often more complex. For example, Commu-
nicator contains utterances on multiple flight legs, infor-
mation which is not available in ATIS.
To compare the adapted ATIS parser with an in-domain
Communicator parser, a HVS model was trained from
scratch using 10682 Communicator training utterances.
The vocabulary size of the in-domain Communicator
training data is 505 and a total of 99 semantic concepts
have been defined. For all tests, a set of 1017 Communi-
cator test utterances was used.
Table 1 lists the recall, precision, and F-measure re-
sults obtained when tested on the 1017 utterance DARPA
Communicator test set. The baseline is the unadapted
HVS parser trained on the ATIS corpus only. The in-
domain results are obtained using the HVS parser trained
solely on the 10682 DARPA training data. The other rows
of the table give the parser performance using MAP and
log-linear interpolation based adaptation of the baseline
model using 50 randomly selected adaptation utterances.
</bodyText>
<table confidence="0.9990746">
System Recall Precision F-measure
Baseline 79.81% 87.14% 83.31%
In-domain 87.18% 91.89% 89.47%
MAP 86.74% 91.07% 88.85%
Log-Linear 86.25% 92.35% 89.20%
</table>
<tableCaption confidence="0.88802">
Table 1: Performance comparison of adaptation using
MAP or log-linear interpolation.
</tableCaption>
<bodyText confidence="0.99991176">
Since we do not yet have a reference database for the
DARPA Communicator task, it is not possible to conduct
the end-to-end performance evaluation as in section 3.
However, the experimental results in section 3.2 indi-
cate that the F-measure needs to exceed 85% to give ac-
ceptable end-to-end performance (see Figure 3). There-
fore, it can be inferred from Table 1 that the unadapted
ATIS parser model would perform very badly in the new
Communicator application whereas the adapted models
would give performance close to that of a fully trained
in-domain model.
Figure 4 shows the parser performance versus the num-
ber of adaptation utterances used. It can be observed that
when there are only a few adaptation utterances, MAP
adaptation performs significantly better than log-linear
interpolation. However above 25 adaptation utterances,
the converse is true. The parser performance saturates
when the number of adaptation utterances reaches 50 for
both techniques and the best performance overall is given
by the parser adapted using log-linear interpolation. The
performance of both models however degrades when the
number of adaptation utterances exceeds 100, possibly
due to model overtraining. For this particular application,
we conclude that just 50 adaptation utterances would be
sufficient to adapt the baseline model to give comparable
</bodyText>
<equation confidence="0.991555">
D = D(
ˆPj(k) 11
¯Pj(k))+A�1(D(ˆPj(k) 11 Pj(k))−d1)
+ A 2(D( ˆPj(k) 11 ˜Pj(k)) − d2) (11)
ˆPj(k) = 1 () ()
ZPj k 1 P&apos; k 2 (12)
</equation>
<bodyText confidence="0.930285">
results to the in-domain Communicator model.
</bodyText>
<sectionHeader confidence="0.186824" genericHeader="method">
Adaptation Training Utterance Number
</sectionHeader>
<figureCaption confidence="0.9542805">
Figure 4: F-measure vs amount of adaptation training
data.
</figureCaption>
<sectionHeader confidence="0.998848" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.99999262">
The spoken language understanding (SLU) system dis-
cussed in this paper is entirely statistically based. The
recogniser uses a HMM-based acoustic model and an n-
gram language model, the semantic parser uses a hid-
den vector state model and the dialogue act decoder uses
Bayesian networks. The system is trained entirely from
data and there are no heuristic rules. One of the major
claims motivating the design of this type of system is
that its fully-statistical framework makes it intrinsically
robust and readily adaptable to new applications. The
aim of this paper has been to investigate this claim ex-
perimentally via two sets of experiments using a system
trained on the ATIS corpus.
In the first set of experiments, the acoustic test data
was corrupted with varying levels of additive car noise.
The end-to-end system performance was then measured
along with the individual component performances. It
was found that although the addition of noise had a sub-
stantial effect on the word error rate, its relative influ-
ence on both the semantic parser slot/value retrieval rate
and the dialogue act detection accuracy was somewhat
less. Overall, the end-to-end error rate degraded rela-
tively more slowly than word error rate and perhaps most
importantly of all, there was no catastrophic failure point
at which the system effectively stops working, a situation
not uncommon in current rule-based systems.
In the second set of experiments, the ability of the se-
mantic decoder component to be adapted to another ap-
plication was investigated. In order, to limit the issues to
parameter mismatch problems, the new application cho-
sen (Communicator) covered essentially the same set of
concepts but was a rather different corpus with different
user speaking styles and different syntactic forms. Over-
all, we found that moving a system trained on ATIS to
this new application resulted in a 6% absolute drop in F-
measure on concept accuracy (i.e. a 62% relative increase
in parser error) and by extrapolation with the results in
the ATIS domain, we infer that this would make the non-
adapted system essentially unusable in the new applica-
tion. However, when adaptation was applied using only
50 adaptation sentences, the loss of concept accuracy was
mostly restored. Specifically, using log-linear adapta-
tion, the out-of-domain F-measure of 83.3% was restored
to 89.2% which is close to the in-domain F-measure of
89.5%.
Although these tests are preliminary and are based on
off-line corpora, the results do give positive support to
the initial claim made for statistically-based spoken lan-
guage systems, i.e. that they are robust and they are read-
ily adaptable to new or changing applications.
</bodyText>
<sectionHeader confidence="0.996933" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999801333333333">
The authors would like to thank Mark Gales for providing
the software to generate the corrupted speech data with
additive noise.
</bodyText>
<sectionHeader confidence="0.998189" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9931165">
M. Bacchiani and B. Roark. 2003. Unsupervised lan-
guage model adaptation. In Proc. of the IEEE Intl.
Conf. on Acoustics, Speech and Signal Processing,
Hong Kong, Apr.
T. Briscoe. 1996. Robust parsing. In R. Cole, J. Mariani,
H. Uszkoreit, A. Zaenen, and V. Zue, editors, Survey
of the State of the Art ofHuman Language Technology,
chapter 3.7. Cambridge University Press, Cambridge,
England.
CUData, 2004. DARPA Communicator Travel
Data. University of Colorado at Boulder.
http://communicator.colorado.edu/phoenix.
D.A. Dahl, M. Bates, M. Brown, K. Hunicke-Smith,
D. Pallett, C. Pao, A. Rudnicky, and L. Shriberg. 1994.
Expanding the scope of the ATIS task: the ATIS-3
corpus. In ARPA Human Language Technology Work-
shop, Princeton, NJ, Mar.
J. Dowding, R. Moore, F. Andry, and D. Moran.
1994. Interleaving syntax and semantics in an efficient
bottom-up parser. In Proc. of the 32nd Annual Meet-
ing of the Association for Computational Linguistics,
pages 110–116, Las Cruces, New Maxico, June.
N. Friedman, D. Geiger, and M. Goldszmidt. 1997.
Bayesian network classifiers. Machine Learning,
29(2):131–163.
M.J. Gales and P.C. Woodland. 1996. Mean and variance
adaptation within the MLLR framework. Computer
Speech and Language, 10:249–264, Oct.
</reference>
<figure confidence="0.9807486">
150
0 25 50 75 100 125
0.9
0.88
MAP
Log−Linear
0.84
0.82
F−measure
0.86
</figure>
<reference confidence="0.999641981818182">
J.L. Gauvain and C.-H. Lee. 1994. Maximum a poste-
riori estimation for multivariate Gaussian mixture ob-
servations of Markov chains. IEEE Trans. on Speech
and Audio Processing, 2(2):291–298.
V. Goel and W. Byrne. 1999. Task dependent loss
functions in speech recognition: Application to named
entity extraction. In ESCA ETRW Workshop on Ac-
cessing Information from Spoken Audio, pages 49–53,
Cambridge, UK.
Yulan He and Steve Young. 2003a. A data-driven spoken
language understanding system. In IEEE Automatic
Speech Recognition and Understanding Workshop, St.
Thomas, U.S. Virgin Islands, Dec.
Yulan He and Steve Young. 2003b. Hidden vector state
model for hierarchical semantic parsing. In Proc. of
the IEEE Intl. Conf. on Acoustics, Speech and Signal
Processing, Hong Kong, Apr.
HTK, 2004. Hidden Markov Model Toolkit (HTK)
3.2. Cambridge University Engineering Department.
http://htk.eng.cam.ac.uk/.
D. Klakow. 1998. Log-linear interpolation of language
models. In Proc. of Intl. Conf. on Spoken Language
Processing, Sydney, Australia, Nov.
N. Kumar. 1997. Investigation of Silicon Auditory Mod-
els and Generalization ofLinear Discriminant analysis
for Improved Speech Recognition. Ph.D. thesis, Johns
Hopkins University, Baltimore MD.
X. Luo, S. Roukos, and T. Ward. 1999. Unsupervised
adaptation of statistical parsers based on Markov trans-
form. In IEEE Automatic Speech Recognition and Un-
derstanding Workshop, Keystone, Colorado, Dec.
X. Luo. 2000. Parser adaptation via householder trans-
form. In Proc. of the IEEE Intl. Conf. on Acoustics,
Speech and Signal Processing, Istanbul, Turkey, June.
S. Martin, A. Kellner, and T. Portele. 2000. Interpolation
of stochastic grammar and word bigram models in nat-
ural language understanding. In Proc. ofIntl. Conf. on
Spoken Language Processing, Beijing, China, Oct.
B. Roark and M. Bacchiani. 2003. Supervised and unsu-
pervised PCFG adaptation to novel domains. In Pro-
ceedings of the joint meeting of the North American
Chapter of the Association for Computational Linguis-
tics and the Human Language Technology Conference
(HLT-NAACL 2003), Edmonton, Canada, May.
S. Seneff. 1992. Robust parsing for spoken language
systems. In Proc. of the IEEE Intl. Conf. on Acoustics,
Speech and Signal Processing, San Francisco.
A.P. Varga, H.J.M. Steeneken, M. Tomlinson, and
D. Jones. 1992. The NOISEX-92 study on the ef-
fect of additive noise on automatic speech recognition.
Technical report, DRA Speech Research Unit.
W. Ward and S. Issar. 1996. Recent improvements in the
CMU spoken language understanding system. In Proc.
of the ARPA Human Language Technology Workshop,
pages 213–216. Morgan Kaufman Publishers, Inc.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.595894">
<title confidence="0.9979315">Robustness Issues in a Data-Driven Spoken Language Understanding System</title>
<author confidence="0.96772">He</author>
<affiliation confidence="0.99787">Cambridge University Engineering</affiliation>
<address confidence="0.620747">Trumpington Street, Cambridge CB2 1PZ,</address>
<abstract confidence="0.999827205882353">Robustness is a key requirement in spoken language understanding (SLU) systems. Human speech is often ungrammatical and ill-formed, and there will frequently be a mismatch between training and test data. This paper discusses robustness and adaptation issues in a statistically-based SLU system which is entirely data-driven. To test robustness, the system has been tested on data from the Air Travel Information Service (ATIS) domain which has been artificially corrupted with varying levels of additive noise. Although the speech recognition performance degraded steadily, the system did not fail catastrophically. Indeed, the rate at which the end-to-end performance of the complete system degraded was significantly slower than that of the actual recognition component. In a second set of experiments, the ability to rapidly adapt the core understanding component of the system to a different application within the same broad domain has been tested. Using only a small amount of training data, experiments have shown that a semantic parser based on the Hidden Vector State (HVS) model originally trained on the ATIS corpus can be straightforwardly adapted to the somewhat different DARPA Communicator task using standard adaptation algorithms. The paper concludes by suggesting that the results presented provide initial support to the claim that an SLU system which is statistically-based and trained entirely from data is intrinsically robust and can be readily adapted to new applications.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Bacchiani</author>
<author>B Roark</author>
</authors>
<title>Unsupervised language model adaptation.</title>
<date>2003</date>
<booktitle>In Proc. of the IEEE Intl. Conf. on Acoustics, Speech and Signal Processing,</booktitle>
<location>Hong Kong,</location>
<contexts>
<context position="14922" citStr="Bacchiani and Roark, 2003" startWordPosition="2437" endWordPosition="2441">n to New Applications Statistical model adaptation techniques are widely used to reduce the mismatch between training and test or to adapt a well-trained model to a novel domain. Commonly used techniques can be classified into two categories, Bayesian adaptation which uses a maximum a posteriori (MAP) probability criteria (Gauvain and Lee, 1994) and transformation-based approaches such as maximum likelihood linear regression (MLLR) (Gales and Woodland, 1996), which uses a maximum likelihood (ML) criteria. In recent years, MAP adaptation has been successfully applied to n-gram language models (Bacchiani and Roark, 2003) and lexicalized PCFG models (Roark and Bacchiani, 2003). Luo et al. have proposed transformation-based approaches based on the Markov transform (Luo et al., 1999) and the Householder transform (Luo, 2000), to adapt statistical parsers. However, the optimisation processes for the latter are complex and it is not clear how general they are. Since MAP adaptation is straightforward and has been applied successfully to PCFG parsers, it has been selected for investigation in this paper. Since one of the special forms of MAP adaptation is interpolation between the indomain and out-of-domain models, </context>
</contexts>
<marker>Bacchiani, Roark, 2003</marker>
<rawString>M. Bacchiani and B. Roark. 2003. Unsupervised language model adaptation. In Proc. of the IEEE Intl. Conf. on Acoustics, Speech and Signal Processing, Hong Kong, Apr.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Briscoe</author>
</authors>
<title>Robust parsing. In</title>
<date>1996</date>
<booktitle>Survey of the State of the Art ofHuman Language Technology, chapter 3.7.</booktitle>
<editor>R. Cole, J. Mariani, H. Uszkoreit, A. Zaenen, and V. Zue, editors,</editor>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, England.</location>
<contexts>
<context position="2887" citStr="Briscoe, 1996" startWordPosition="438" endWordPosition="439">uilt using hand-crafted semantic grammar rules and so-called robust parsing (Ward and Issar, 1996; Seneff, 1992; Dowding et al., 1994) is used to handle the ill-formed user input in which word patterns corresponding to semantic tokens are used to fill slots in different semantic frames in parallel. The frame with the highest score then yields the selected semantic representation. Formally speaking, the robustness of language (recognition, parsing, etc.) is a measure of the ability of human speakers to communicate despite incomplete information, ambiguity, and the constant element of surprise (Briscoe, 1996). In this paper, two aspects of SLU system performance are investigated: noise robustness and adaptability to different applications. For the former, we expect that an SLU system should maintain acceptable performance when given noisy input speech data. This requires, the understanding components of the SLU system to be able to correctly interpret the meaning of an utterance even when faced with recognition errors. For the latter, the SLU system should be readily adaptable to a different application using a relatively small set (e.g. less than 100) of adaptation utterances. The rest of the pap</context>
</contexts>
<marker>Briscoe, 1996</marker>
<rawString>T. Briscoe. 1996. Robust parsing. In R. Cole, J. Mariani, H. Uszkoreit, A. Zaenen, and V. Zue, editors, Survey of the State of the Art ofHuman Language Technology, chapter 3.7. Cambridge University Press, Cambridge, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>CUData</author>
</authors>
<title>DARPA Communicator Travel Data.</title>
<date>2004</date>
<institution>University of Colorado at Boulder.</institution>
<note>http://communicator.colorado.edu/phoenix.</note>
<contexts>
<context position="20437" citStr="CUData, 2004" startWordPosition="3336" endWordPosition="3338">nt loss in performance (Martin et al., 2000). For the other parameters, A1 and A2, the generalized iterative scaling algorithm or the simplex method can be employed to estimate their optimal settings. 4.3 Experiments To test the portability of the statistical parser, the initial experiments reported here are focussed on assessing the adaptability of the HVS model when it is tested in a domain which covers broadly similar concepts, but comprises rather different speaking styles. To this end, the flight information subset of the DARPA Communicator Travel task has been used as the target domain (CUData, 2004). By limiting the test in this way, we ensure that the dimensionalities of the HVS model parameters remain the same and no new semantic concepts are introduced by the adaptation training data. The baseline HVS parser was trained on the ATIS corpus using 4978 utterances selected from the contextindependent (Class A) training data in the ATIS-2 and ATIS-3 corpora. The vocabulary size of the ATIS training corpus is 611 and there are altogether 110 semantic concepts defined. The parser model was then adapted using utterances relating to flight reservation from the DARPA Communicator data. Although</context>
</contexts>
<marker>CUData, 2004</marker>
<rawString>CUData, 2004. DARPA Communicator Travel Data. University of Colorado at Boulder. http://communicator.colorado.edu/phoenix.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Dahl</author>
<author>M Bates</author>
<author>M Brown</author>
<author>K Hunicke-Smith</author>
<author>D Pallett</author>
<author>C Pao</author>
<author>A Rudnicky</author>
<author>L Shriberg</author>
</authors>
<title>Expanding the scope of the ATIS task: the ATIS-3 corpus.</title>
<date>1994</date>
<booktitle>In ARPA Human Language Technology Workshop,</booktitle>
<location>Princeton, NJ,</location>
<contexts>
<context position="8971" citStr="Dahl et al., 1994" startWordPosition="1473" endWordPosition="1476">he goal. TAN networks relax this independence assumption by adding dependencies between concepts based on the conditional mutual information (CMI) between concepts given the goal. The goal prior probability P(G,,,) and the conditional probability of each semantic concept Ci given the goal G,,,, P(Ci|G,,,) are learned from the training data. Dialogue act detection is done by picking the goal with the highest posterior probability of G,,, given the particular instance of concepts Cl · · · Com,, P(G,,,|C, · · · Com,). 3 Noise Robustness The ATIS corpus which contains air travel information data (Dahl et al., 1994) has been chosen for the SLU system development and evaluation. ATIS was developed in the DARPA sponsored spoken language understanding programme conducted from 1990 to 1995 and it provides a convenient and well-documented standard for measuring the end-to-end performance of an SLU system. However, since the ATIS corpus contains only clean speech, corrupted test data has been generated by adding samples ofbackground noise to the clean test data at the waveform level. 3.1 Experimental Setup The experimental setup used to evaluate the SLU system was similar to that described in (He and Young, 20</context>
</contexts>
<marker>Dahl, Bates, Brown, Hunicke-Smith, Pallett, Pao, Rudnicky, Shriberg, 1994</marker>
<rawString>D.A. Dahl, M. Bates, M. Brown, K. Hunicke-Smith, D. Pallett, C. Pao, A. Rudnicky, and L. Shriberg. 1994. Expanding the scope of the ATIS task: the ATIS-3 corpus. In ARPA Human Language Technology Workshop, Princeton, NJ, Mar.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Dowding</author>
<author>R Moore</author>
<author>F Andry</author>
<author>D Moran</author>
</authors>
<title>Interleaving syntax and semantics in an efficient bottom-up parser.</title>
<date>1994</date>
<booktitle>In Proc. of the 32nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>110--116</pages>
<location>Las Cruces, New Maxico,</location>
<contexts>
<context position="2407" citStr="Dowding et al., 1994" startWordPosition="362" endWordPosition="365">ople use different words and sentence structures to convey the same meaning. Also, many utterances are grammaticallyincorrect or ill-formed. It thus remains an open issue as to how to provide robustness for large populations of nonexpert users in spoken dialogue systems. The key component of a spoken language understanding (SLU) system is the semantic parser, which translates the users’ utterances into semantic representations. Traditionally, most semantic parser systems have been built using hand-crafted semantic grammar rules and so-called robust parsing (Ward and Issar, 1996; Seneff, 1992; Dowding et al., 1994) is used to handle the ill-formed user input in which word patterns corresponding to semantic tokens are used to fill slots in different semantic frames in parallel. The frame with the highest score then yields the selected semantic representation. Formally speaking, the robustness of language (recognition, parsing, etc.) is a measure of the ability of human speakers to communicate despite incomplete information, ambiguity, and the constant element of surprise (Briscoe, 1996). In this paper, two aspects of SLU system performance are investigated: noise robustness and adaptability to different </context>
</contexts>
<marker>Dowding, Moore, Andry, Moran, 1994</marker>
<rawString>J. Dowding, R. Moore, F. Andry, and D. Moran. 1994. Interleaving syntax and semantics in an efficient bottom-up parser. In Proc. of the 32nd Annual Meeting of the Association for Computational Linguistics, pages 110–116, Las Cruces, New Maxico, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Friedman</author>
<author>D Geiger</author>
<author>M Goldszmidt</author>
</authors>
<title>Bayesian network classifiers.</title>
<date>1997</date>
<booktitle>Machine Learning,</booktitle>
<pages>29--2</pages>
<contexts>
<context position="5277" citStr="Friedman et al., 1997" startWordPosition="835" endWordPosition="839"> structure of a spoken language understanding system. The sequential decoding described above is suboptimal since the solution at each stage depends on an exact solution to the previous stage. To reduce the effect of this approximation, a word lattice or N-best word hypotheses can be retained instead of the single best string Wˆ as the output of the speech recognizer. The semantic parse results may then be incorporated with the output from the speech recognizer to rescore the N-best list as below. model for semantic parsing (He and Young, 2003b), and Tree-Augmented Naive Bayes networks (TAN) (Friedman et al., 1997) for dialog act decoding. The speech recognizer comprises 14 mixture Gaussian HMM state-clustered cross-word triphones augmented by using heteroscedastic linear discriminant analysis (HLDA) (Kumar, 1997). Incremental speaker adaptation based on the maximum likelihood linear regression (MLLR) method (Gales and Woodland, 1996) was performed during the test with updating being performed in batches of five utterances per speaker. The Hidden Vector State (HVS) model (He and Young, 2003b) is a hierarchical semantic parser which associates each state of a push-down automata with the state of a HMM. S</context>
<context position="8000" citStr="Friedman et al., 1997" startWordPosition="1311" endWordPosition="1315">ct) (5) where ct at word position t is a vector of Dt semantic concept labels (tags), nt is the vector stack shift operation and takes values in the range 0, · · · , Dt_1 where Dt_1 is the stack size at word position t − 1, and ct[1] = cwt is the new preterminal semantic tag assigned to word wt at word position t. Thus, the HVS model consists of three types of probabilistic move: 1. popping semantic tags off the stack; 2. pushing a pre-terminal semantic tag onto the stack; 3. generating the next word. The dialog act decoder was implemented using the Tree-Augmented Naive Bayes (TAN) algorithm (Friedman et al., 1997), which is an extension of Naive Bayes Networks. One TAN was used for each dialogue act or goal G,,,, the semantic concepts Ci which serve as input to its corresponding TAN were selected based on the mutual information (MI) between the goal and the concept. Naive Bayes networks assume all the concepts are conditionally independent given the value of the goal. TAN networks relax this independence assumption by adding dependencies between concepts based on the conditional mutual information (CMI) between concepts given the goal. The goal prior probability P(G,,,) and the conditional probability </context>
</contexts>
<marker>Friedman, Geiger, Goldszmidt, 1997</marker>
<rawString>N. Friedman, D. Geiger, and M. Goldszmidt. 1997. Bayesian network classifiers. Machine Learning, 29(2):131–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Gales</author>
<author>P C Woodland</author>
</authors>
<title>Mean and variance adaptation within the MLLR framework.</title>
<date>1996</date>
<journal>Computer Speech and Language,</journal>
<pages>10--249</pages>
<contexts>
<context position="5603" citStr="Gales and Woodland, 1996" startWordPosition="881" endWordPosition="884">ring Wˆ as the output of the speech recognizer. The semantic parse results may then be incorporated with the output from the speech recognizer to rescore the N-best list as below. model for semantic parsing (He and Young, 2003b), and Tree-Augmented Naive Bayes networks (TAN) (Friedman et al., 1997) for dialog act decoding. The speech recognizer comprises 14 mixture Gaussian HMM state-clustered cross-word triphones augmented by using heteroscedastic linear discriminant analysis (HLDA) (Kumar, 1997). Incremental speaker adaptation based on the maximum likelihood linear regression (MLLR) method (Gales and Woodland, 1996) was performed during the test with updating being performed in batches of five utterances per speaker. The Hidden Vector State (HVS) model (He and Young, 2003b) is a hierarchical semantic parser which associates each state of a push-down automata with the state of a HMM. State transitions are factored into separate stack pop and push operations and then constrained to give a tractable search space. The result is a model which is complex enough to capture hierarchical structure but which can be trained automatically from unannotated data. sent_start I want to return to Dallas on Thursday sent_</context>
<context position="14758" citStr="Gales and Woodland, 1996" startWordPosition="2413" endWordPosition="2416">ic concept. It can also be observed from Figure 3 that the F-measure needs to be better than 85% in order to achieve acceptable end-to-end performance. 4 Adaptation to New Applications Statistical model adaptation techniques are widely used to reduce the mismatch between training and test or to adapt a well-trained model to a novel domain. Commonly used techniques can be classified into two categories, Bayesian adaptation which uses a maximum a posteriori (MAP) probability criteria (Gauvain and Lee, 1994) and transformation-based approaches such as maximum likelihood linear regression (MLLR) (Gales and Woodland, 1996), which uses a maximum likelihood (ML) criteria. In recent years, MAP adaptation has been successfully applied to n-gram language models (Bacchiani and Roark, 2003) and lexicalized PCFG models (Roark and Bacchiani, 2003). Luo et al. have proposed transformation-based approaches based on the Markov transform (Luo et al., 1999) and the Householder transform (Luo, 2000), to adapt statistical parsers. However, the optimisation processes for the latter are complex and it is not clear how general they are. Since MAP adaptation is straightforward and has been applied successfully to PCFG parsers, it </context>
</contexts>
<marker>Gales, Woodland, 1996</marker>
<rawString>M.J. Gales and P.C. Woodland. 1996. Mean and variance adaptation within the MLLR framework. Computer Speech and Language, 10:249–264, Oct.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Gauvain</author>
<author>C-H Lee</author>
</authors>
<title>Maximum a posteriori estimation for multivariate Gaussian mixture observations of Markov chains.</title>
<date>1994</date>
<journal>IEEE Trans. on Speech and Audio Processing,</journal>
<volume>2</volume>
<issue>2</issue>
<contexts>
<context position="14643" citStr="Gauvain and Lee, 1994" startWordPosition="2398" endWordPosition="2401">ot affected by the mis-recognition of individual words, but only by a failure to detect the presence of a semantic concept. It can also be observed from Figure 3 that the F-measure needs to be better than 85% in order to achieve acceptable end-to-end performance. 4 Adaptation to New Applications Statistical model adaptation techniques are widely used to reduce the mismatch between training and test or to adapt a well-trained model to a novel domain. Commonly used techniques can be classified into two categories, Bayesian adaptation which uses a maximum a posteriori (MAP) probability criteria (Gauvain and Lee, 1994) and transformation-based approaches such as maximum likelihood linear regression (MLLR) (Gales and Woodland, 1996), which uses a maximum likelihood (ML) criteria. In recent years, MAP adaptation has been successfully applied to n-gram language models (Bacchiani and Roark, 2003) and lexicalized PCFG models (Roark and Bacchiani, 2003). Luo et al. have proposed transformation-based approaches based on the Markov transform (Luo et al., 1999) and the Householder transform (Luo, 2000), to adapt statistical parsers. However, the optimisation processes for the latter are complex and it is not clear h</context>
</contexts>
<marker>Gauvain, Lee, 1994</marker>
<rawString>J.L. Gauvain and C.-H. Lee. 1994. Maximum a posteriori estimation for multivariate Gaussian mixture observations of Markov chains. IEEE Trans. on Speech and Audio Processing, 2(2):291–298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Goel</author>
<author>W Byrne</author>
</authors>
<title>Task dependent loss functions in speech recognition: Application to named entity extraction.</title>
<date>1999</date>
<booktitle>In ESCA ETRW Workshop on Accessing Information from Spoken Audio,</booktitle>
<pages>49--53</pages>
<location>Cambridge, UK.</location>
<contexts>
<context position="10906" citStr="Goel and Byrne, 1999" startWordPosition="1782" endWordPosition="1785"> In the case of ATIS, the lexical classes can be extracted automatically from the relational database, whilst abstract semantic annotations for each utterance are automatically derived from the accompanying SQL queries of the training utterances. The dialogue act decoder is trained using the main topics or goals and the key semantic concepts extracted automatically from the reference SQL queries Performance is measured at both the component and the system level. For the former, the recognizer is evaluated by word error rate, the parser by concept slot retrieval rate using an F-measure metric (Goel and Byrne, 1999), and the dialog act decoder by detection rate. The overall system performance is measured using the standard NIST “query answer” rate. In the expriments reported here, car noise from the NOISEX-92 (Varga et al., 1992) database was added to the ATIS-3 NOV93 and DEC94 test sets. In order to obtain different SNRs, the noise was scaled accordingly before adding to the speech signal. 3.2 Experimental Results Robust spoken language understanding components should be able to compensate for the weakness of the speech recognizer. That is, ideally they should be capable of generating the correct meanin</context>
</contexts>
<marker>Goel, Byrne, 1999</marker>
<rawString>V. Goel and W. Byrne. 1999. Task dependent loss functions in speech recognition: Application to named entity extraction. In ESCA ETRW Workshop on Accessing Information from Spoken Audio, pages 49–53, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yulan He</author>
<author>Steve Young</author>
</authors>
<title>A data-driven spoken language understanding system.</title>
<date>2003</date>
<booktitle>In IEEE Automatic Speech Recognition and Understanding Workshop,</booktitle>
<location>St. Thomas, U.S. Virgin Islands,</location>
<contexts>
<context position="5204" citStr="He and Young, 2003" startWordPosition="825" endWordPosition="828">h W Semantic C Dialog Act Recognizer Parser Decoder Figure 1: Typical structure of a spoken language understanding system. The sequential decoding described above is suboptimal since the solution at each stage depends on an exact solution to the previous stage. To reduce the effect of this approximation, a word lattice or N-best word hypotheses can be retained instead of the single best string Wˆ as the output of the speech recognizer. The semantic parse results may then be incorporated with the output from the speech recognizer to rescore the N-best list as below. model for semantic parsing (He and Young, 2003b), and Tree-Augmented Naive Bayes networks (TAN) (Friedman et al., 1997) for dialog act decoding. The speech recognizer comprises 14 mixture Gaussian HMM state-clustered cross-word triphones augmented by using heteroscedastic linear discriminant analysis (HLDA) (Kumar, 1997). Incremental speaker adaptation based on the maximum likelihood linear regression (MLLR) method (Gales and Woodland, 1996) was performed during the test with updating being performed in batches of five utterances per speaker. The Hidden Vector State (HVS) model (He and Young, 2003b) is a hierarchical semantic parser which</context>
<context position="9573" citStr="He and Young, 2003" startWordPosition="1570" endWordPosition="1573">hl et al., 1994) has been chosen for the SLU system development and evaluation. ATIS was developed in the DARPA sponsored spoken language understanding programme conducted from 1990 to 1995 and it provides a convenient and well-documented standard for measuring the end-to-end performance of an SLU system. However, since the ATIS corpus contains only clean speech, corrupted test data has been generated by adding samples ofbackground noise to the clean test data at the waveform level. 3.1 Experimental Setup The experimental setup used to evaluate the SLU system was similar to that described in (He and Young, 2003a). As mentioned in section 2, the SLU system consists of three main components, a standard HTK-based HMM recognizer, the HVS semantic parser, and the TAN dialogue act (DA) decoder. Each of the three major components are trained separately. The acoustic speech signal in the ATIS training data is modelled by extracting 39 features every 10ms: 12 cepstra, energy, and their first and second derivatives. This data is then used to train the speaker-independent, continuous speech recognizer. The HVS semantic parser is trained on the unannotated utterances using EM constrained by the domain-specific </context>
</contexts>
<marker>He, Young, 2003</marker>
<rawString>Yulan He and Steve Young. 2003a. A data-driven spoken language understanding system. In IEEE Automatic Speech Recognition and Understanding Workshop, St. Thomas, U.S. Virgin Islands, Dec.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yulan He</author>
<author>Steve Young</author>
</authors>
<title>Hidden vector state model for hierarchical semantic parsing.</title>
<date>2003</date>
<booktitle>In Proc. of the IEEE Intl. Conf. on Acoustics, Speech and Signal Processing,</booktitle>
<location>Hong Kong,</location>
<contexts>
<context position="5204" citStr="He and Young, 2003" startWordPosition="825" endWordPosition="828">h W Semantic C Dialog Act Recognizer Parser Decoder Figure 1: Typical structure of a spoken language understanding system. The sequential decoding described above is suboptimal since the solution at each stage depends on an exact solution to the previous stage. To reduce the effect of this approximation, a word lattice or N-best word hypotheses can be retained instead of the single best string Wˆ as the output of the speech recognizer. The semantic parse results may then be incorporated with the output from the speech recognizer to rescore the N-best list as below. model for semantic parsing (He and Young, 2003b), and Tree-Augmented Naive Bayes networks (TAN) (Friedman et al., 1997) for dialog act decoding. The speech recognizer comprises 14 mixture Gaussian HMM state-clustered cross-word triphones augmented by using heteroscedastic linear discriminant analysis (HLDA) (Kumar, 1997). Incremental speaker adaptation based on the maximum likelihood linear regression (MLLR) method (Gales and Woodland, 1996) was performed during the test with updating being performed in batches of five utterances per speaker. The Hidden Vector State (HVS) model (He and Young, 2003b) is a hierarchical semantic parser which</context>
<context position="9573" citStr="He and Young, 2003" startWordPosition="1570" endWordPosition="1573">hl et al., 1994) has been chosen for the SLU system development and evaluation. ATIS was developed in the DARPA sponsored spoken language understanding programme conducted from 1990 to 1995 and it provides a convenient and well-documented standard for measuring the end-to-end performance of an SLU system. However, since the ATIS corpus contains only clean speech, corrupted test data has been generated by adding samples ofbackground noise to the clean test data at the waveform level. 3.1 Experimental Setup The experimental setup used to evaluate the SLU system was similar to that described in (He and Young, 2003a). As mentioned in section 2, the SLU system consists of three main components, a standard HTK-based HMM recognizer, the HVS semantic parser, and the TAN dialogue act (DA) decoder. Each of the three major components are trained separately. The acoustic speech signal in the ATIS training data is modelled by extracting 39 features every 10ms: 12 cepstra, energy, and their first and second derivatives. This data is then used to train the speaker-independent, continuous speech recognizer. The HVS semantic parser is trained on the unannotated utterances using EM constrained by the domain-specific </context>
</contexts>
<marker>He, Young, 2003</marker>
<rawString>Yulan He and Steve Young. 2003b. Hidden vector state model for hierarchical semantic parsing. In Proc. of the IEEE Intl. Conf. on Acoustics, Speech and Signal Processing, Hong Kong, Apr.</rawString>
</citation>
<citation valid="true">
<authors>
<author>HTK</author>
</authors>
<title>Hidden Markov Model Toolkit (HTK) 3.2.</title>
<date>2004</date>
<institution>Cambridge University Engineering Department.</institution>
<note>http://htk.eng.cam.ac.uk/.</note>
<contexts>
<context position="7265" citStr="HTK, 2004" startWordPosition="1181" endWordPosition="1182">rations N, the joint probability of P(W, C, N) can be decomposed as DUMMY SS TOLOC ON RETURN CITY DATE SE Wˆ = argmax W Cˆ = argmax C Gu ˆC, Wˆ  argmax P(A|W)P(W)P(C|W) T P(nt|ct_1) · C,WELN H  argmax t=1 C,WELN P(A|W)P(W)ryP(C|W)a (4) P(W, C, N) = where P(A|W) is the acoustic probability from the first pass, P(W) is the language modelling likelihood, P(C|W) is the semantic parse score, LN denotes the Nbest list, a is a semantic parse scale factor, and y is a grammar scale factor. In the system described in this paper, each of these stages is modelled separately. We use a standard HTKbased (HTK, 2004) Hidden Markov Model (HMM) recognizer for recognition, the Hidden Vector State (HVS) P(ct[1]|ct[2··· Dt]) · P(wt|ct) (5) where ct at word position t is a vector of Dt semantic concept labels (tags), nt is the vector stack shift operation and takes values in the range 0, · · · , Dt_1 where Dt_1 is the stack size at word position t − 1, and ct[1] = cwt is the new preterminal semantic tag assigned to word wt at word position t. Thus, the HVS model consists of three types of probabilistic move: 1. popping semantic tags off the stack; 2. pushing a pre-terminal semantic tag onto the stack; 3. genera</context>
</contexts>
<marker>HTK, 2004</marker>
<rawString>HTK, 2004. Hidden Markov Model Toolkit (HTK) 3.2. Cambridge University Engineering Department. http://htk.eng.cam.ac.uk/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klakow</author>
</authors>
<title>Log-linear interpolation of language models.</title>
<date>1998</date>
<booktitle>In Proc. of Intl. Conf. on Spoken Language Processing,</booktitle>
<location>Sydney, Australia,</location>
<contexts>
<context position="17671" citStr="Klakow, 1998" startWordPosition="2884" endWordPosition="2885">he prior weighting parameter, Pj(k) is the probability of the original unadapted model, and ˜Pj(k) is the empirical distribution of the adaptation data, which is defined as As discussed in section 2, the HVS model consists of three types of probabilistic move. The MAP adaptation technique can be applied to the HVS model by adapting each of these three component distributions individually. 4.2 Log-Linear Interpolation Log-linear interpolation has been applied to language model adaptation and has been shown to be equivalent to a constrained minimum Kullback-Leibler distance optimisation problem(Klakow, 1998). Following the notation introduced in section 4.1, where Pj(k) is the probability of the original unadapted model, and ˜Pj(k) is the empirical distribution of the adaptation obtained using MAP adaptation or log-linear interpolation. ˜Pj(k) +  Pj(k) (7) j +  ˜Pj(k) = j(k) 8 Ei= 1 j(i) Speech to Noise Ratio − SNR (NOV93 Test Set) (a) NOV93 End-to-End Performance Speech to Noise Ratio − SNR (NOV93 Test Set) (b) NOV93 Component Performance Speech to Noise Ratio − SNR (DEC94 Test Set) (c) DEC94 End-to-End Performance Speech to Noise Ratio − SNR (DEC94 Test Set) (d) DEC94 Component Performance</context>
</contexts>
<marker>Klakow, 1998</marker>
<rawString>D. Klakow. 1998. Log-linear interpolation of language models. In Proc. of Intl. Conf. on Spoken Language Processing, Sydney, Australia, Nov.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Kumar</author>
</authors>
<title>Investigation of Silicon Auditory Models and Generalization ofLinear Discriminant analysis for Improved Speech Recognition.</title>
<date>1997</date>
<tech>Ph.D. thesis,</tech>
<institution>Johns Hopkins University,</institution>
<location>Baltimore MD.</location>
<contexts>
<context position="5480" citStr="Kumar, 1997" startWordPosition="866" endWordPosition="867"> of this approximation, a word lattice or N-best word hypotheses can be retained instead of the single best string Wˆ as the output of the speech recognizer. The semantic parse results may then be incorporated with the output from the speech recognizer to rescore the N-best list as below. model for semantic parsing (He and Young, 2003b), and Tree-Augmented Naive Bayes networks (TAN) (Friedman et al., 1997) for dialog act decoding. The speech recognizer comprises 14 mixture Gaussian HMM state-clustered cross-word triphones augmented by using heteroscedastic linear discriminant analysis (HLDA) (Kumar, 1997). Incremental speaker adaptation based on the maximum likelihood linear regression (MLLR) method (Gales and Woodland, 1996) was performed during the test with updating being performed in batches of five utterances per speaker. The Hidden Vector State (HVS) model (He and Young, 2003b) is a hierarchical semantic parser which associates each state of a push-down automata with the state of a HMM. State transitions are factored into separate stack pop and push operations and then constrained to give a tractable search space. The result is a model which is complex enough to capture hierarchical stru</context>
</contexts>
<marker>Kumar, 1997</marker>
<rawString>N. Kumar. 1997. Investigation of Silicon Auditory Models and Generalization ofLinear Discriminant analysis for Improved Speech Recognition. Ph.D. thesis, Johns Hopkins University, Baltimore MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Luo</author>
<author>S Roukos</author>
<author>T Ward</author>
</authors>
<title>Unsupervised adaptation of statistical parsers based on Markov transform.</title>
<date>1999</date>
<booktitle>In IEEE Automatic Speech Recognition and Understanding Workshop,</booktitle>
<location>Keystone, Colorado,</location>
<contexts>
<context position="15085" citStr="Luo et al., 1999" startWordPosition="2462" endWordPosition="2465">omain. Commonly used techniques can be classified into two categories, Bayesian adaptation which uses a maximum a posteriori (MAP) probability criteria (Gauvain and Lee, 1994) and transformation-based approaches such as maximum likelihood linear regression (MLLR) (Gales and Woodland, 1996), which uses a maximum likelihood (ML) criteria. In recent years, MAP adaptation has been successfully applied to n-gram language models (Bacchiani and Roark, 2003) and lexicalized PCFG models (Roark and Bacchiani, 2003). Luo et al. have proposed transformation-based approaches based on the Markov transform (Luo et al., 1999) and the Householder transform (Luo, 2000), to adapt statistical parsers. However, the optimisation processes for the latter are complex and it is not clear how general they are. Since MAP adaptation is straightforward and has been applied successfully to PCFG parsers, it has been selected for investigation in this paper. Since one of the special forms of MAP adaptation is interpolation between the indomain and out-of-domain models, it is natural to also consider the use of non-linear interpolation and hence this has been studied as well 1. &apos;Experiments using linear interpolation have also bee</context>
</contexts>
<marker>Luo, Roukos, Ward, 1999</marker>
<rawString>X. Luo, S. Roukos, and T. Ward. 1999. Unsupervised adaptation of statistical parsers based on Markov transform. In IEEE Automatic Speech Recognition and Understanding Workshop, Keystone, Colorado, Dec.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Luo</author>
</authors>
<title>Parser adaptation via householder transform.</title>
<date>2000</date>
<booktitle>In Proc. of the IEEE Intl. Conf. on Acoustics, Speech and Signal Processing,</booktitle>
<location>Istanbul, Turkey,</location>
<contexts>
<context position="15127" citStr="Luo, 2000" startWordPosition="2471" endWordPosition="2472"> into two categories, Bayesian adaptation which uses a maximum a posteriori (MAP) probability criteria (Gauvain and Lee, 1994) and transformation-based approaches such as maximum likelihood linear regression (MLLR) (Gales and Woodland, 1996), which uses a maximum likelihood (ML) criteria. In recent years, MAP adaptation has been successfully applied to n-gram language models (Bacchiani and Roark, 2003) and lexicalized PCFG models (Roark and Bacchiani, 2003). Luo et al. have proposed transformation-based approaches based on the Markov transform (Luo et al., 1999) and the Householder transform (Luo, 2000), to adapt statistical parsers. However, the optimisation processes for the latter are complex and it is not clear how general they are. Since MAP adaptation is straightforward and has been applied successfully to PCFG parsers, it has been selected for investigation in this paper. Since one of the special forms of MAP adaptation is interpolation between the indomain and out-of-domain models, it is natural to also consider the use of non-linear interpolation and hence this has been studied as well 1. &apos;Experiments using linear interpolation have also been conducted but it was found that the resu</context>
</contexts>
<marker>Luo, 2000</marker>
<rawString>X. Luo. 2000. Parser adaptation via householder transform. In Proc. of the IEEE Intl. Conf. on Acoustics, Speech and Signal Processing, Istanbul, Turkey, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Martin</author>
<author>A Kellner</author>
<author>T Portele</author>
</authors>
<title>Interpolation of stochastic grammar and word bigram models in natural language understanding.</title>
<date>2000</date>
<booktitle>In Proc. ofIntl. Conf. on Spoken Language Processing,</booktitle>
<location>Beijing, China,</location>
<contexts>
<context position="19868" citStr="Martin et al., 2000" startWordPosition="3242" endWordPosition="3245">1 ˜Pj(k)) = d2 (10) Given an additional model probability ¯Pj(k) whose distance to ˆPj(k) should be kept small, and introducing Lagrange multipliers A�1 and A2 to ensure that constraints 9 and 10 are satistifed, yields Minimizing D with respect to ˆPj(k) yields the required distribution. With some manipulation and redefinition of the Lagrange Multipliers, it can be shown that where Pj(k) has been assumed to be a uniform distribution which is then absorbed into the normalization term Z. The computation of Z is very expensive and can usually be dropped without significant loss in performance (Martin et al., 2000). For the other parameters, A1 and A2, the generalized iterative scaling algorithm or the simplex method can be employed to estimate their optimal settings. 4.3 Experiments To test the portability of the statistical parser, the initial experiments reported here are focussed on assessing the adaptability of the HVS model when it is tested in a domain which covers broadly similar concepts, but comprises rather different speaking styles. To this end, the flight information subset of the DARPA Communicator Travel task has been used as the target domain (CUData, 2004). By limiting the test in this </context>
</contexts>
<marker>Martin, Kellner, Portele, 2000</marker>
<rawString>S. Martin, A. Kellner, and T. Portele. 2000. Interpolation of stochastic grammar and word bigram models in natural language understanding. In Proc. ofIntl. Conf. on Spoken Language Processing, Beijing, China, Oct.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Roark</author>
<author>M Bacchiani</author>
</authors>
<title>Supervised and unsupervised PCFG adaptation to novel domains.</title>
<date>2003</date>
<booktitle>In Proceedings of the joint meeting of the North American Chapter of the Association for Computational Linguistics and the Human Language Technology Conference (HLT-NAACL 2003),</booktitle>
<location>Edmonton, Canada,</location>
<contexts>
<context position="14978" citStr="Roark and Bacchiani, 2003" startWordPosition="2446" endWordPosition="2449">iques are widely used to reduce the mismatch between training and test or to adapt a well-trained model to a novel domain. Commonly used techniques can be classified into two categories, Bayesian adaptation which uses a maximum a posteriori (MAP) probability criteria (Gauvain and Lee, 1994) and transformation-based approaches such as maximum likelihood linear regression (MLLR) (Gales and Woodland, 1996), which uses a maximum likelihood (ML) criteria. In recent years, MAP adaptation has been successfully applied to n-gram language models (Bacchiani and Roark, 2003) and lexicalized PCFG models (Roark and Bacchiani, 2003). Luo et al. have proposed transformation-based approaches based on the Markov transform (Luo et al., 1999) and the Householder transform (Luo, 2000), to adapt statistical parsers. However, the optimisation processes for the latter are complex and it is not clear how general they are. Since MAP adaptation is straightforward and has been applied successfully to PCFG parsers, it has been selected for investigation in this paper. Since one of the special forms of MAP adaptation is interpolation between the indomain and out-of-domain models, it is natural to also consider the use of non-linear int</context>
</contexts>
<marker>Roark, Bacchiani, 2003</marker>
<rawString>B. Roark and M. Bacchiani. 2003. Supervised and unsupervised PCFG adaptation to novel domains. In Proceedings of the joint meeting of the North American Chapter of the Association for Computational Linguistics and the Human Language Technology Conference (HLT-NAACL 2003), Edmonton, Canada, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Seneff</author>
</authors>
<title>Robust parsing for spoken language systems.</title>
<date>1992</date>
<booktitle>In Proc. of the IEEE Intl. Conf. on Acoustics, Speech and Signal Processing,</booktitle>
<location>San Francisco.</location>
<contexts>
<context position="2384" citStr="Seneff, 1992" startWordPosition="360" endWordPosition="361">s different people use different words and sentence structures to convey the same meaning. Also, many utterances are grammaticallyincorrect or ill-formed. It thus remains an open issue as to how to provide robustness for large populations of nonexpert users in spoken dialogue systems. The key component of a spoken language understanding (SLU) system is the semantic parser, which translates the users’ utterances into semantic representations. Traditionally, most semantic parser systems have been built using hand-crafted semantic grammar rules and so-called robust parsing (Ward and Issar, 1996; Seneff, 1992; Dowding et al., 1994) is used to handle the ill-formed user input in which word patterns corresponding to semantic tokens are used to fill slots in different semantic frames in parallel. The frame with the highest score then yields the selected semantic representation. Formally speaking, the robustness of language (recognition, parsing, etc.) is a measure of the ability of human speakers to communicate despite incomplete information, ambiguity, and the constant element of surprise (Briscoe, 1996). In this paper, two aspects of SLU system performance are investigated: noise robustness and ada</context>
</contexts>
<marker>Seneff, 1992</marker>
<rawString>S. Seneff. 1992. Robust parsing for spoken language systems. In Proc. of the IEEE Intl. Conf. on Acoustics, Speech and Signal Processing, San Francisco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A P Varga</author>
<author>H J M Steeneken</author>
<author>M Tomlinson</author>
<author>D Jones</author>
</authors>
<title>The NOISEX-92 study on the effect of additive noise on automatic speech recognition.</title>
<date>1992</date>
<tech>Technical report,</tech>
<institution>DRA Speech Research Unit.</institution>
<contexts>
<context position="11124" citStr="Varga et al., 1992" startWordPosition="1818" endWordPosition="1821">f the training utterances. The dialogue act decoder is trained using the main topics or goals and the key semantic concepts extracted automatically from the reference SQL queries Performance is measured at both the component and the system level. For the former, the recognizer is evaluated by word error rate, the parser by concept slot retrieval rate using an F-measure metric (Goel and Byrne, 1999), and the dialog act decoder by detection rate. The overall system performance is measured using the standard NIST “query answer” rate. In the expriments reported here, car noise from the NOISEX-92 (Varga et al., 1992) database was added to the ATIS-3 NOV93 and DEC94 test sets. In order to obtain different SNRs, the noise was scaled accordingly before adding to the speech signal. 3.2 Experimental Results Robust spoken language understanding components should be able to compensate for the weakness of the speech recognizer. That is, ideally they should be capable of generating the correct meaning of an utterance even if it is recognized wrongly by a speech recognizer. At minimum, the performance of the understanding components should degrade gracefully as recognition accuracy degrades. Figure 3 gives the syst</context>
</contexts>
<marker>Varga, Steeneken, Tomlinson, Jones, 1992</marker>
<rawString>A.P. Varga, H.J.M. Steeneken, M. Tomlinson, and D. Jones. 1992. The NOISEX-92 study on the effect of additive noise on automatic speech recognition. Technical report, DRA Speech Research Unit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Ward</author>
<author>S Issar</author>
</authors>
<title>Recent improvements in the CMU spoken language understanding system.</title>
<date>1996</date>
<booktitle>In Proc. of the ARPA Human Language Technology Workshop,</booktitle>
<pages>213--216</pages>
<publisher>Morgan Kaufman Publishers, Inc.</publisher>
<contexts>
<context position="2370" citStr="Ward and Issar, 1996" startWordPosition="356" endWordPosition="359">e is highly variable as different people use different words and sentence structures to convey the same meaning. Also, many utterances are grammaticallyincorrect or ill-formed. It thus remains an open issue as to how to provide robustness for large populations of nonexpert users in spoken dialogue systems. The key component of a spoken language understanding (SLU) system is the semantic parser, which translates the users’ utterances into semantic representations. Traditionally, most semantic parser systems have been built using hand-crafted semantic grammar rules and so-called robust parsing (Ward and Issar, 1996; Seneff, 1992; Dowding et al., 1994) is used to handle the ill-formed user input in which word patterns corresponding to semantic tokens are used to fill slots in different semantic frames in parallel. The frame with the highest score then yields the selected semantic representation. Formally speaking, the robustness of language (recognition, parsing, etc.) is a measure of the ability of human speakers to communicate despite incomplete information, ambiguity, and the constant element of surprise (Briscoe, 1996). In this paper, two aspects of SLU system performance are investigated: noise robu</context>
</contexts>
<marker>Ward, Issar, 1996</marker>
<rawString>W. Ward and S. Issar. 1996. Recent improvements in the CMU spoken language understanding system. In Proc. of the ARPA Human Language Technology Workshop, pages 213–216. Morgan Kaufman Publishers, Inc.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>