<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000012">
<title confidence="0.966244">
The PARC 700 Dependency Bank
</title>
<author confidence="0.994061">
Tracy Holloway King, Richard Crouch, Stefan Riezler,
Mary Dalrymple and Ronald M. Kaplan
</author>
<affiliation confidence="0.997999">
Palo Alto Research Center
</affiliation>
<address confidence="0.496736">
3333 Coyote Hill Road, 94304 Palo Alto, CA
</address>
<email confidence="0.99683">
fthkingIcrouchlriezlerldalrymplelkaplanl@parc.com
</email>
<sectionHeader confidence="0.998594" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999422727272727">
In this paper we discuss the construc-
tion, features, and current uses of the
PARC 700 DEPBANK. The PARC 700
DEPBANK is a dependency bank con-
taining predicate-argument relations and
a wide variety of other grammatical fea-
tures. It was semi-automatically pro-
duced and boot-strapped from the out-
put of a deep parser: this allowed for
greater consistency of analysis and for
more rapid construction.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999984571428571">
The PARC 700 Dependency Bank (DEPBANK)
consists of 700 sentences which were randomly
extracted from section 23 of the UPenn Wall Street
Journal (WSJ) treebank (Marcus et al., 1994).
These were parsed by a deep Lexical-Functional
Grammar (LFG), converted to the DEPBANK for-
mat, and then manually corrected and extended by
human validators. Average sentence length is 19.8
words, and the average number of dependencies
per sentence is 65.4. The corpus is freely avail-
able for research and evaluation; documentation
and tools for displaying and pruning structures are
also freely available.
The DEPBANK was created because existing
treebanks were found inadequate for evaluating
predicate-argument structure. In treebanks, this
information is usually encoded implicitly in the
phrase structure. However, LFG, HPSG, and re-
lated grammars encode grammatical functions di-
rectly and hence evaluating against tree structures
can be difficult. As such, grammar engineers have
begun to move away from treebanks to depen-
dency banks (Carroll et al., 2002). In this paper we
present PARC&apos;s techniques for semi-automatically
producing a dependency bank that would be of use
for a wide variety of applications, including parser
evaluation for a variety of formalisms.
The paper is organized as follows. We first dis-
cuss in detail how the DEPBANK was created us-
ing both automated and manual techniques (sec-
tion 2). We then examine several features of the
DEPBANK, including tools to specialize it for par-
ticular applications (section 3). Finally, we pro-
vide some discussion, including current applica-
tions for the dependency bank (sections 4 and 6).
</bodyText>
<sectionHeader confidence="0.983339" genericHeader="method">
2 Constructing the Dependency Bank
</sectionHeader>
<bodyText confidence="0.9999542">
This section presents our technique for producing
the DEPBANK. We used a combination of auto-
matic and manual techniques in order to get the
most accurate results in a reasonable amount of
time. The basic process is as follows:
</bodyText>
<listItem confidence="0.989402428571429">
1. Parse the sentence using a broad cover-
age LFG grammar and bank the functional-
structure of the best parse.
2. Convert this automatically to the DEPBANK
format, making systematic adjustments.
3. Manually check/correct each structure using
pretty-printing and validation tools.
</listItem>
<bodyText confidence="0.994659">
The last step was performed by three linguist val-
idators (two validators per structure).
</bodyText>
<page confidence="0.975636">
1
</page>
<bodyText confidence="0.999976206896552">
However, even when the saved parse diverged
from the desired one, it was still found to be ef-
fective to use it as the basis for the DEPBANK
structure rather than create the DEPBANK structure
from scratch. This was because subconstituents
of the parse were often correct and could be re-
connected into the proper structure. For example,
in the structure for a sentence like (1), the month
phrases and the % phrases might be correct and
hence only need to be combined into a coordinate
structure with the appropriate modifiers.
The second step was to convert the saved gram-
mar f-structure outputl into the DEPBANK format.
This was done automatically and included basic
reformatting and some systematic adjustments to
the structures. In addition, header information was
added to indicate the sentence id number, the val-
idators, etc. The f-structures contain detailed in-
formation about grammatical relations. In addi-
tion to grammatical functions (e.g., subject, ob-
ject, adjunct), the f-structures also have informa-
tion about other syntactically relevant information
(e.g., tense, number, adjunct-type). For exam-
ple, a sentence like Mary left. might have the f-
structure shown in (2). Note that the f-structures
are attribute-value matrices; values of attributes
can be either atomic (e.g., vtype&apos;s value is main)
or another f-structure (e.g., subj&apos;s value is the f-
structure for Mary).
</bodyText>
<footnote confidence="0.781544666666667">
&apos;The output of the grammar comprises the f-structures
and the c(onstituent)-structures. The c-structures are trees.
C-structures are not included in the DEPBANK.
</footnote>
<figure confidence="0.559296733333333">
&apos;leave&lt;subj&gt;&apos;
pred &apos;Mary&apos;
ntype proper
annn
case nom
gend-sem female
num sg
pers 3
mood indicative
perf
prog
tense past
passive
stmt-type decl
vtype main
</figure>
<bodyText confidence="0.706457076923077">
The conversion process involved a certain
amount of &amp;quot;flattening&amp;quot;. That is, the highly artic-
ulated structure of the grammar output was made
less articulate when no loss of information would
result. Certain attributes with AVM values were
removed, leaving the original AVM value as an at-
tribute of the AVM which contained the eliminated
attribute. In particular, attributes which contained
no PRED values were flattened. For example, the
grammar output in (3a) would be flattened to that
in (3b) in which there is no tns-asp feature. Note
that f-structure pred values are assigned an index,
e.g., ::0; this is explained in section 3.1.
</bodyText>
<listItem confidence="0.966079">
(3) a. pred go&lt;subj &gt;f
</listItem>
<bodyText confidence="0.789779">
subj pred &apos;Mary]
tense past
tns-asp mood indicative
</bodyText>
<equation confidence="0.9784056">
prog +
b. subj(go::0, Mary::1),
tense(go::0, past),
mood(go::0, indicative),
prog(go::0, +)
</equation>
<bodyText confidence="0.9995191">
In addition to the flattening, several across-the-
board changes were made automatically to the
structures to make them more legible and to mod-
ify grammatical analyses which were felt to be un-
desirable. For example, the grammar had subjs
for all attributive adjectives (e.g., the flimsy chair).
However, for the purposes of the DEPBANK, it was
decided to eliminate these subjs. For example, the
structure in (4a) for the red chair was automati-
cally converted to that in (4b).
</bodyText>
<listItem confidence="0.9925084">
(4) a. adjunct(chair:: , red::2),
subj(red::2, chair::1),
adegree(red::2, positive),
atype(red::2, attributive),
adjunct_type(red::2, nominal)
</listItem>
<equation confidence="0.735456">
pred
subj
tns-asp
2.1 Initial Construction (2)
</equation>
<bodyText confidence="0.8903145">
The first step in building the DEPBANK was to
parse the 700 sentences with a broad-coverage
deep LFG grammar of English using the XLE sys-
tem (Maxwell III and Kaplan, 1993). For many
of the sentences there was more than one possible
parse. The best parse was chosen by manual in-
spection and saved. Note that in a few cases, the
best parse was far from the desired parse, as was
the case with the sentence in (1) (parc_23.580).
(1) 8 13/16% to 8 11/16% one month; 8 13/16%
to 8 11/16% two months; 8 13/16% to 8
11/16% three months; 8 3/4% to 8 5/8% four
months; 8 11/16% to 8 9/16% five months; 8
5/8% to 8 1/2% six months.
</bodyText>
<page confidence="0.927016">
2
</page>
<bodyText confidence="0.8715206">
b. adjunct(chair:: 1, red::2),
adegree(red::2, positive),
atype(red::2, attributive),
adjunct_type(red::2, nominal)
Other examples of this type included the elimina-
tion of negative (—) values for pelf and prog, leav-
ing only the positive (+) values. For example, the
structure in (5a) for he left was automatically con-
verted to that in (5b), while the structure in (6) for
he was leaving was not changed.
</bodyText>
<listItem confidence="0.8398122">
(5) a. tense(leave::0, past),
prog(leave:: 0, —)
b. tense(leave::0, past)
(6) tense(leave::0, past),
prog(leave::0, +)
</listItem>
<bodyText confidence="0.99698975">
On a more minor level, several features were re-
named to increase legibility, e.g, attr became at-
tributive; this rewriting was double-checked by the
validation tools discussed in the next section.
</bodyText>
<subsectionHeader confidence="0.994909">
2.2 Validation
</subsectionHeader>
<bodyText confidence="0.999969294117647">
Each DEPBANK structure was manually evaluated
by two people. If the structure was not correct,
changes were made. In some instances where the
grammar effectively did not cover a particular lin-
guistic construction, these changes were substan-
tial, as in (1). In most cases they were minor.
Manual evaluation was made possible by two
tools. The first is a pretty printer which dis-
plays the DEPBANK structures in a simplified f-
structure AVM like structure. This makes the
structures more human readable without altering
the application-friendly DEPBANK structure. Con-
sider the DEPBANK structure for Don&apos;t jump yet.
(parc_23.313); this is shown in (7a) and its pretty-
printed equivalent is in (7b). There is a second
pretty-print format (not shown) which displays the
index numbers as part of the AVM format.
</bodyText>
<listItem confidence="0.611594">
(7) a. structure(
</listItem>
<footnote confidence="0.670890909090909">
mood(jump::0, imperative),
adjunct(jump::0, not::5),
adjunct(jump::0, yet::4),
stmt_type(jump::0, imperative),
subj(jump::0, pro::1),
vtype(jump::0, main),
pers(pro::1, 2),
pron_type(pro::1, null),
adegree(yet::4, positive),
adv_type(yet::4, sadv),
adjunct_type(not::5, negative))
</footnote>
<figure confidence="0.7927405">
b. pred &apos;jump&apos;
mood imperative
stmt_type imperative
vtype main
subj pred &apos;pro&apos;
pers 2
pron_type null
adjunct pred &apos;yet&apos;
adegree positive
ad v _type sadv
adjunct pred &apos;not&apos;
adjunct_type negative
</figure>
<bodyText confidence="0.999977105263158">
The second tool checked for valid structures.
This validation tool performs two types of tasks.
The first is to determine whether a structure is
notationally well-formed. For example, it checks
whether header information is formatted correctly,
whether commas, parentheses, and colons are cor-
rectly placed, and whether the structure is fully
connected. These checks eliminate common typos
that occur when making changes to the structures.
The second task of the validation tool is to
check for user-defined substative well-formedness
requirements. For example, all the possible fea-
ture names are declared (e.g., subj, num, tense),
as are their possible values (e.g., adegree can have
the values comparative, positive, superlative). If
a feature is found that was not predeclared or was
associated with an incorrect value, then the tool
reports it to the validator. This helps locate typos
and is useful for finding naming inconsistencies.
In addition to listing possible feature names,
the validators could list co-occurrence and other
well-formedness conditions. For example, xcomps
(e.g. infinitives, small clauses) must have subjs;
mods (i.e. nouns in noun-noun compounds) must
have pers and num but not atype; conjs (i.e. co-
ordinate structures) must have coord_level and co-
ord_form but not subjs; pronouns with a pron_type
of expletive must not have a pro value.
These checks were invaluable in two circum-
stances. The first was when the original banked
structure was incorrect and had to be modified by
the validator. This, for example, occurred rela-
tively frequently where the wrong choice had been
made between a noun and an adjective modifier;
this distinction is important because it has seman-
tic reprecussions, as witnessed by the frequent lex-
icalization of noun-noun compounds (e.g., tractor
trailer). The word red in a phrase like the red box
</bodyText>
<page confidence="0.99488">
3
</page>
<bodyText confidence="0.9977935">
has the structure in (8a) when it is an adjective and
the structure in (8b) when it is a noun.
</bodyText>
<equation confidence="0.735038428571429">
(8) a. adjunct(box::1, red::2),
adegree(red::2, positive),
atype(red::2, attributive)
adjunct_type(red::2, nominal)
b. mod(box::1, red::2),
num(red::2, sg),
pers(red::2, 3)
</equation>
<bodyText confidence="0.999877777777778">
Since the change from adjective to noun and vice
versa required several concurrent changes, the val-
idating tool can check that all the relevant changes
have been made.
The second circumstance where this validation
tool was used was where the grammar had been in-
complete. For example, it was discovered that not
all conjunctions provided a coord_form (in partic-
ular, lexical conjunctions such as and and or had
a coord_form, but punctuation conjunctions such
as; and : did not). To provide consistency in the
DEPBANK, these missing forms were added, and
the validation tool was used to bring the absence
of the feature to the validator&apos;s attention. Note that
many across-the-board changes were made by the
automatic converter from the output of the gram-
mar to the DEPBANK structures, e.g., the elimina-
tion of subjs in attributive adjectives (section 2.1).
This decreased the changes the validators had to
make and hence the chance for human error.
In conclusion, although the process of creating
the DEPBANK was labor intensive, the extremely
detailed results were made possible by (1) using
a deep grammar to bootstrap the initial structures
and (2) having validation tools to double check for
wellformedness at the level of typos and of gram-
matical structure.
</bodyText>
<sectionHeader confidence="0.84859" genericHeader="method">
3 Features of the Dependency Bank
</sectionHeader>
<bodyText confidence="0.999505727272727">
In this section, we discuss the contents of the DEP-
BANK structures themselves. Much of this infor-
mation can be found in greater detail in the on-line
documentation. The choice of format and of the
dependencies is extremely important since it dic-
tates what applications the DEPBANK can be used
for. First we discuss indices, reentrancies, and
stemming (section 3.1). We then discuss the de-
pendencies chosen (section 3.2) and finally men-
tion problems with redundant information in the
DEPBANK (section 3.3).
</bodyText>
<subsectionHeader confidence="0.973811">
3.1 Indices, Reentrancies, and Stemming
</subsectionHeader>
<bodyText confidence="0.998357">
All predicates in a given DEPBANK structure are
assigned a unique index, with the matrix predicate
always being assigned the index ::0. One reason
for the indices is to distinguish two instances of
the same word. For example, in Most estimates
for Monsanto run between $1.7 and $2 a share.
(parc_23.328), there are two distinct instances of
the predicate $: one of them is designated $::10
and one $:://. These in turn have their own mod-
ifiers (i.e., 1.7 for $::10 and 2 for $:://).
The second use of the indices is for reentrant
structures, i.e., structures in which a single item
is related to more than one predicate. This oc-
curs with controlled infinitives, with small clauses,
and with the second argument of copular construc-
tions. Consider Of course, the health of the econ-
omy will be threatened if the market continues to
dive this week. (parc_23.315). The noun phrase
the market is the subject of continues and of dive.
This is shown in (9).
</bodyText>
<listItem confidence="0.980936666666667">
(9) subj(continue::8, market::11),
xcomp(continue::8, dive: :6),
subj (dive: : 6, market: :11)
</listItem>
<bodyText confidence="0.984290052631579">
There are two important points about the analysis
in (9). The first is that the subj of the infinitive
is indicated even though it does not appear in the
string in canonical subject position, i e, immedi-
ately before to dive. The second is that the fact
that the two subjects are the same is indicated by
their identical index ::11.
The example in (9) also demonstrates the stem-
ming used in the DEPBANK. The surface form
continues is stemmed to continue. Note that the
features for market, shown in (10), indicate that it
is third person singular, and hence is compatible
with the third singular surface form of the verb.
(10) num(market::11, sg),
pers(market::11, 3)
Stemming and indices provide a uniform, easy
to manage format for indicating predicates. More
difficult is deciding which dependencies to have in
the DEPBANK; this is dicussed next.
</bodyText>
<subsectionHeader confidence="0.98856">
3.2 Dependencies Chosen
</subsectionHeader>
<bodyText confidence="0.99950975">
The most difficult decisions in creating the DEP-
BANK involved deciding which dependencies and
features to keep. There were two main types of
dependencies at issue: dependencies representing
</bodyText>
<page confidence="0.987951">
4
</page>
<bodyText confidence="0.96655735106383">
surface information and redundant dependencies.
As will be discussed in more detail below, the gen-
eral approach was to keep redundant information
because it is easier to delete it using the DEPBANK
structure-pruning tool than to go back and add it.
All argument and adjunct relations are indicated
in the DEPBANK structures — without this the
structures would not be properly connected. The
possible grammatical functions include (see (Butt
et al., 1999)):
(11) a. Subcategorized functions: subj, obj,
obj_theta (secondary objects), comp
(`thar- and &apos;whether&apos; -clauses), xcomp
(infinitives, small clauses, and postcop-
ular arguments), obi and obj_ag and
obl_compar (subcategorized obliques)
b. Nonsubcategorized functions: adjunct,
name_mod (used in person names), mod,
topic_rel and pron_rel (used in relative
clauses), focusint and pron_int (used in
interrogatives), poss, conj, number, quant
and aquant (quantifiers)
Information of this type is included in all depen-
dency banks, although it is only indirectly present
in most tree banks. In general, determining these
grammatical relations was not difficult, other than
the obl-adjunct distinction, and the output of the
grammar was quite reliable.
However, the DEPBANK includes a large num-
ber of syntactic features in addition to those indi-
cating the role of the phrase in the clause. These
include information about: statement type; tense,
mood, aspect, and passivization; person, number,
gender, and case; determiners; comparatives and
superlatives; adjunct and adverb types. These fea-
tures can be extremely useful for certain applica-
tions and as such they are included in the DEP-
BAN K. An example full structure was shown in
(7). For applications which need only predicate-
argument structure, a structure pruning tool is pro-
vided which allows the user to specify which fea-
tures to keep. The tool will not prune the core
grammatical function features. That is, if the value
of a feature is something with an index, it cannot
be pruned. For example, num can be pruned be-
cause its values are sg and pl, but subj cannot be
pruned because its value is indexed and the result-
ing structure would be disconnected. In addition,
it is possible to keep features only when they have
certain values. For example, someone might wish
to keep adegree only when it has the values com-
parative or superlative but not positive.
There are two classes of features that are present
in the grammar output, but are eliminated in the
DEPBANK structures. The first class are features
that exist solely for grammar internal reasons, e.g.,
to test certain well-formedness constraints. For-
tunately, these are all contained within the feature
check and so deleting a single feature check as part
of the automatic conversion program eliminates all
these features (section 2.1). The second class in-
volves features that are inconsistently present in
the grammar output and were not hand-corrected
by the validators because they were not felt to be
important for the DEPBANK. For example, peo-
ple&apos;s names, e.g., Mary, provide an anim + fea-
ture in the grammar. However, not all animates
have this feature in the grammar output, e.g., girl
does not. Because of this, the anim feature is felt
to be misleading since its absence does not indi-
cate an inanimate. So, anim is eliminated from the
DEPBANK structures.
As a final note, there are certain other types
of information that are not included in the DEP-
BANK. One of these is word sense disambigua-
tion: only the stemmed form of the word is indi-
cated, without any information as to its sense in
the clause. In addition, word order is not indicated
other than in the recording of the original string in
the sentence_form field of each DEPBANK struc-
ture. For example, in I don&apos;t feel either hard or
soft. (parc_23.384), there is no indication in the
DEPBANK structure as to which of the adjectives
is first in the coordination. Instead, they are both
conjs of coord::6,2 as seen in (12).
(12) conj(coord::6, soft::18),
conj (coord: :6, hard: :17),
coord_form(coord::6, or),
coordievel(coord::6, AP),
precoord_form(coord::6, either)
As we have seen, the DEPBANK includes ex-
tremely detailed grammatical information, well
beyond the level of predicate argument structure.
As discussed in the next section, this level of de-
</bodyText>
<footnote confidence="0.996349">
2coord is a special predicate introduced where the gram-
mar output has the set structure used for coordination in LFG.
It represents the elements of the f-structure set by having one
conj attribute for each set member, i.e. for each conjunct.
</footnote>
<page confidence="0.996302">
5
</page>
<bodyText confidence="0.999866">
tail, while useful for many applications, can pro-
vide difficulties for others.
</bodyText>
<subsectionHeader confidence="0.999074">
3.3 Double Counting Information
</subsectionHeader>
<bodyText confidence="0.999877066666667">
Some of the information in the DEPBANK is redun-
dant for certain applications. That is, if the output
of an application is matched against a DEPBANK
structure, it may be the case that if it matches fea-
turel then it will always also match feature2, and
that if it misses featurel then it will always also
miss feature2. This is undesirable for some eval-
uation measures and training scenarios since the
result is a double credit or a double penalty.
For example, imperative constructions are indi-
cated in two ways. They are assigned stmt_type
imperative and mood imperative. In addition, the
vast majority of imperatives have a null pronomi-
nal subj. This was seen above in Don&apos;t jump yet.
(parc_23.313); the relevant dependencies are re-
</bodyText>
<equation confidence="0.813895333333333">
peated in (13).
( 1 3 ) stmt_type(jump::0, imperative),
mood(jump::0, imperative),
subj(jump::0, pro::1),
pers(pro::1, 2),
pron_type(pro::1, null)
</equation>
<bodyText confidence="0.999526461538461">
So, whenever the stmt_type imperative is found,
the mood and sub] information follow automati-
cally. However, for non-imperative constructions,
the sub] value is not predictable, and the mood
information cannot be derived from the stmt_type
and vice versa, e.g., stmt_type declarative can cor-
respond to mood indicative or subjunctive.
Another example comes from pronouns, which
in the DEPBANK are assigned the indexed value
pro except for expletive it and there. The form
of the pronoun provides a wealth of information
about the pronoun. For example, in parc_23.374
the pronoun she has the features in (14).
</bodyText>
<equation confidence="0.81878725">
(14) case(pro::1, nom),
gend_sem(pro::1, female),
num(pro::1, sg),
pers(pro::1, 3),
</equation>
<bodyText confidence="0.903724285714286">
pron _form (pro : : 1 , she),
pron_type(pro::1, pers)
The case, gender, number, person, and pronoun
type information can all be derived by know-
ing that the pron_form was she. For applica-
tions where this is a problem, everything but the
pron_form could be eliminated.3 However, there
</bodyText>
<footnote confidence="0.867569">
3The pronouns are stemmed, but their case can be recov-
ered from their grammatical function
</footnote>
<bodyText confidence="0.999866066666667">
are situations where being able to search for all
instances of, for example, personal pronouns is
necessary and so having this information overtly
recorded via the pron_type feature is useful.
At this time, a complete list of &amp;quot;doubled&amp;quot; de-
pendencies is not available. However, as they
are found, the structure pruning tool can eliminate
them if they interfere with a given application. By
having this pruning tool available, the possible ap-
plications of the DEPBANK are increased.
Thus, as the detailed syntactic information
found in the DEPBANK is not necessary or even
desirable for all applications, a structure pruning
tool is provided to eliminate unwanted dependen-
cies from the DEPBANK.
</bodyText>
<sectionHeader confidence="0.996569" genericHeader="method">
4 Applications
</sectionHeader>
<bodyText confidence="0.999978153846154">
We used the DEPBANK to evaluate a stochastic
parsing system consisting of an LFG grammar and
a stochastic disambiguation model trained on sec-
tions 02-21 of the UPenn WSJ treebank (Riezler
et al., 2002; Crouch et al., 2002).
In an evaluation of a combined system of parser
and stochastic disambiguator, three types of parse
selection are compared against the gold standard
of the DEPBANK: (i) lower bound: random choice
of a parse from the set of analyses (averaged over
10 runs), (ii) upper bound: selection of the parse
with the best F-score, and (iii) stochastic: the
parse selected by the stochastic disambiguator.
</bodyText>
<tableCaption confidence="0.929298">
Table 1: F-score results for parser evaluation
against DEPBANK.
</tableCaption>
<bodyText confidence="0.956159285714286">
lower bd. stochastic upper bd. error red.
76.6 79.5 85.2 34
Table 1 shows F-scores for these parse selections,
where F-score is defined as 2 x precision x recall
I (precision + recall). The disambiguation accu-
racy of the stochastic selection system is assessed
in a window defined by a random choice and the
best possible choice from the parses delivered by
the symbolic parsing system. The reduction in er-
ror rate relative to these upper and lower bounds
achieved by the stochastic disambiguation system
is noted in the error red. column of Table 1.
In addition to an overall figure, precision, re-
call, and F-score results can be broken down ac-
</bodyText>
<page confidence="0.998561">
6
</page>
<bodyText confidence="0.999947961538462">
cording to separate dependencies. Fig. 1 shows a
breakout of evaluation scores according to the de-
pendencies in the parses selected by the stochastic
disambiguation system.
We have also used the DEPBANK in grammar
development. In order to have an accurate as-
sessment of grammar coverage, it is not suffi-
cient to know simply whether a sentence parses
or not. By comparing the grammar output against
the dependency structure, it is possible to deter-
mine whether the grammar produced the correct
structure, e.g., is the correct noun phrase the sub-
ject? Independent of a stochastic disambiguation
system, it is possible for the grammar writer to de-
termine how close the match is by inspecting eval-
uation scores computed for the upper bound selec-
tion. The result is not all-or-nothing, but rather a
gradient score for each dependency or for the over-
all matching result.
DEPBANK tools have also been used for re-
banking other parse banks, where the best (though
not necessarily correct) analysis has been hand-
chosen. Grammar changes require updates to the
parse bank. This is achieved semi-automatically
by chosing the new parse with the closest match-
ing dependency structure to the original analysis.
</bodyText>
<sectionHeader confidence="0.989617" genericHeader="method">
5 Comparisons to Other Banks
</sectionHeader>
<bodyText confidence="0.99571605">
The DEPBANK is closest in form and intent to the
gold-standard dependency annotations proposed
by (Carroll et al., 1999) for 500 sentences se-
lected from the Brown corpus. As discussed in
more detail in (Crouch et al., 2002), the DEPBANK
(a) eliminates residual aspects of surface structure
that intruded into the Carroll et al annotations, and
(b) provides a more detailed range of grammatical
features. In addition, it provides a genuinely ran-
dom selection of sentences (i.e. not preselected to
be parsable by a particular parser/grammar), taken
from the de facto standard corpus for parser eval-
uation. An evaluation of a WSJ-trained stochastic
parsing system for LFG achieved 76% F-score on
Carroll et al.&apos;s test set (see Riezler et al. (2002)).
The Tiger treebank (Brants et al., 2002) for Ger-
man newspaper texts is on a much larger scale
(some 30,000 sentences) than the PARC 700 DEP-
BANK, and also makes use of the XLE as an anno-
tation tool, but is quite different in form and intent.
</bodyText>
<table confidence="0.999738204081633">
DEPENDENCY PREC. REC. F-SCORE
number-type 96 95 96
coord-form 92 93 93
ptype 92 91 91
psem 89 92 90
pron-form 88 89 89
number 91 88 89
ytype 91 88 89
inf-form 97 80 88
det-type 88 86 87
perf 90 85 87
pers 87 87 87
num 86 87 86
tense 86 86 86
deixis 80 89 84
quant 85 80 83
case 83 80 82
passive 80 83 82
stmt-type 80 79 80
prog 94 69 79
proper 79 79 79
pron-type 74 82 78
atype 80 75 77
adegree 81 72 76
obj 75 75 75
poss 74 76 75
adjunct-type 74 74 74
xcomp 74 73 74
subj 73 73 73
obi 64 83 72
comp 78 64 70
obi-ag 74 65 69
pit-form 72 65 68
precoord-form 100 50 67
adjunct 67 63 65
conj 68 62 65
gerund 53 80 64
adv-type 71 57 63
mod 59 62 60
pease 60 56 58
topic-rel 48 72 57
coord-level 56 56 56
focus-int 49 63 55
partitive 40 83 54
comp-form 32 54 40
obj7theta 42 36 39
topic 20 67 31
obl-compar 29 29 29
OVERALL 80.0 78.8 79.5
</table>
<figureCaption confidence="0.982291">
Figure 1: Evaluation scores broken down accord-
ing to (selected) dependency relations.
</figureCaption>
<bodyText confidence="0.9999395">
It is a treebank supplemented with some gram-
matical relations annotations, rather than a depen-
dency bank. By abstracting away from details of
surface structure, the DEPBANK provides a more
transparent and articulated account of predicate-
argument/adjunct and other semantically relevant
structures. The intent of Tiger is to provide a re-
source for both the training and evaluation of lan-
guage processing; the DEPBANK is targeted at the
evaluation of systems performing deeper language
analysis. The Prague Dependency Bank (Haji,
1998) for Czech is constructed in a similar fash-
ion as the Tiger treebank, using POS tagging and
a basic grammar to bootstrap the manual treebank
</bodyText>
<page confidence="0.997699">
7
</page>
<bodyText confidence="0.999988631578947">
annotation. Unlike the Tiger treebank, the Prague
Dependency Bank does not encode linear order,
although it does use tree structures to encode de-
pendencies. Unlike the DEPBANK, it primarily
encodes relations between words, i.e., predicate-
argument structure, and not other syntactic depen-
dencies, although some of these, such as number
and tense, can be derived from the POS tags.
The LinGO-Redwoods treebank (Oepen et al.,
2002) supplements its trees with explicit semantic
representations, and is thus also aimed at provid-
ing resources for deeper language analysis. How-
ever, the LinGO-Redwoods treebank does not pro-
vide a gold-standard annotation in that it only
records the best analysis produced by a particular
grammar and parser, which need not necessarily
be the correct analysis. It is also very heavily tied
to the HPSG formalism, whereas the DEPBANK at-
tempts to generalize away from its LFG heritage.
</bodyText>
<sectionHeader confidence="0.999668" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999989730769231">
The PARC 700 DEPBANK is a dependency bank
containing both predicate-argument relations and
a wide variety of other grammatical features.
It was semi-automatically produced and boot-
strapped from the output of a deep parser. Without
this automation and boot-strapping, consistency of
analysis would have been extremely difficult to
achieve, and the time involved would have been
exorbitant. Although the process is not entirely
automated, it is hoped that the system can be used
to efficiently create further dependency banks.
The DEPBANK has so far been applied to eval-
uate the combined system of parser and stochastic
disambiguator presented in Riezler et al. (2002).
Since most state-of-the-art statistical parsing sys-
tems are based on the UPenn WSJ treebank,
the DEPBANK can directly be applied for a
dependency-based evaluation of such parsing sys-
tems. Furthermore, due to the possibility of prun-
ing unwanted dependencies, the PARC 700 DEP-
BANK may be useful to evaluate also parsing sys-
tems that were not trained or created from the
UPenn treebank. Moreover, the grammar develop-
ment possibilities opened up by the DEPBANK can
be exploited for parsers that were developed for
corpora other than newspaper text like the WSJ.
</bodyText>
<sectionHeader confidence="0.998471" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999652921568628">
Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolf-
gang Lezius, and George Smith. 2002. The TIGER
treebank. In Proceedings of the Workshop on Tree-
banks and Linguistic Theories, Sozopol.
Miriam Butt, Tracy Holloway King, Maria-Eugenia
Nifio, and Frederique Segond. 1999. A Grammar
Writer&apos;s Cookbook. CSLI Publications.
John Carroll, Guido Minnen, and Ted Briscoe. 1999.
Corpus annotation for parser evaluation. In Pro-
ceedings of the EACL workshop on Linguistically
Interpreted Corpora (LINC). Bergen, Norway.
John Carroll, Anette Frank, Dekang Lin, Detlef
Prescher, and Hans Uszkoreit, editors. 2002. Pro-
ceedings of the Workshop on Parseval and Beyond
and the 3rd International Conference on Language
Resources and Evaluation (LREC&apos;02). ELRA.
Richard Crouch, Ronald M. Kaplan, Tracy Holloway
King, and Stefan Riezler. 2002. A comparison of
evaluation metrics for a broad coverage stochastic
parser. In Proceedings of the Workshop on Parseval
and Beyond and the 3rd International Conference
on Language Resources and Evaluation (LREC&apos;02).
Las Palmas, Spain.
Jan Haji. 1998. Building a syntactically anno-
tated corpus: The prague dependency treebank. In
Issues of Valency and Meaning, pages 106-132.
Karolinum, Prague.
Mitchell Marcus, Grace Kim, Mary Ann
Marcinkiewicz, Robert MacIntyre, Ann Bies,
Mark Ferguson, Karen Katz, and Britta Schas-
berger. 1994. The Penn treebank: Annotating
predicate argument structure. In ARPA Human
Language Technology Workshop.
John T. Maxwell III and Ronald M. Kaplan. 1993. The
interface between phrasal and functional constraints.
Computational Linguistics, 19:571-589.
Stephan Oepen, Ezra Callahan, Dan Flickinger,
Christopher Manning, and Kristina Toutanova.
2002. LinG0 redwoods: a rich and dynamic tree-
bank for HPSG. In Proceedings of the Workshop
on Parseval and Beyond and the 3rd International
Conference on Language Resources and Evaluation
(LREC&apos;02). Las Palmas, Spain.
Stefan Riezler, Tracy Holloway King, Ronald M. Ka-
plan, Richard Crouch, John T. Maxwell III, and
Mark Johnson. 2002. Parsing the Wall Street Jour-
nal using a Lexical-Functional Grammar and dis-
criminative estimation techniques. In Proceedings
of hte 40th Annual Meeting of the Association for
Computational Linguistics (ACL &apos;02). Philadelphia,
PA.
</reference>
<page confidence="0.998461">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.629102">
<title confidence="0.986384">The PARC 700 Dependency Bank</title>
<author confidence="0.8943405">Tracy Holloway King</author>
<author confidence="0.8943405">Richard Crouch</author>
<author confidence="0.8943405">Stefan Dalrymple M</author>
<affiliation confidence="0.838188">Palo Alto Research</affiliation>
<address confidence="0.993002">3333 Coyote Hill Road, 94304 Palo Alto, CA</address>
<email confidence="0.999445">fthkingIcrouchlriezlerldalrymplelkaplanl@parc.com</email>
<abstract confidence="0.997643666666666">In this paper we discuss the construction, features, and current uses of the 700 PARC 700 a dependency bank containing predicate-argument relations and a wide variety of other grammatical features. It was semi-automatically produced and boot-strapped from the output of a deep parser: this allowed for greater consistency of analysis and for more rapid construction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sabine Brants</author>
<author>Stefanie Dipper</author>
<author>Silvia Hansen</author>
<author>Wolfgang Lezius</author>
<author>George Smith</author>
</authors>
<title>The TIGER treebank.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Treebanks and Linguistic Theories,</booktitle>
<location>Sozopol.</location>
<contexts>
<context position="25443" citStr="Brants et al., 2002" startWordPosition="4062" endWordPosition="4065">s. As discussed in more detail in (Crouch et al., 2002), the DEPBANK (a) eliminates residual aspects of surface structure that intruded into the Carroll et al annotations, and (b) provides a more detailed range of grammatical features. In addition, it provides a genuinely random selection of sentences (i.e. not preselected to be parsable by a particular parser/grammar), taken from the de facto standard corpus for parser evaluation. An evaluation of a WSJ-trained stochastic parsing system for LFG achieved 76% F-score on Carroll et al.&apos;s test set (see Riezler et al. (2002)). The Tiger treebank (Brants et al., 2002) for German newspaper texts is on a much larger scale (some 30,000 sentences) than the PARC 700 DEPBANK, and also makes use of the XLE as an annotation tool, but is quite different in form and intent. DEPENDENCY PREC. REC. F-SCORE number-type 96 95 96 coord-form 92 93 93 ptype 92 91 91 psem 89 92 90 pron-form 88 89 89 number 91 88 89 ytype 91 88 89 inf-form 97 80 88 det-type 88 86 87 perf 90 85 87 pers 87 87 87 num 86 87 86 tense 86 86 86 deixis 80 89 84 quant 85 80 83 case 83 80 82 passive 80 83 82 stmt-type 80 79 80 prog 94 69 79 proper 79 79 79 pron-type 74 82 78 atype 80 75 77 adegree 81 7</context>
</contexts>
<marker>Brants, Dipper, Hansen, Lezius, Smith, 2002</marker>
<rawString>Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolfgang Lezius, and George Smith. 2002. The TIGER treebank. In Proceedings of the Workshop on Treebanks and Linguistic Theories, Sozopol.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam Butt</author>
<author>Tracy Holloway King</author>
<author>Maria-Eugenia Nifio</author>
<author>Frederique Segond</author>
</authors>
<title>A Grammar Writer&apos;s Cookbook.</title>
<date>1999</date>
<publisher>CSLI Publications.</publisher>
<contexts>
<context position="15264" citStr="Butt et al., 1999" startWordPosition="2412" endWordPosition="2415"> in creating the DEPBANK involved deciding which dependencies and features to keep. There were two main types of dependencies at issue: dependencies representing 4 surface information and redundant dependencies. As will be discussed in more detail below, the general approach was to keep redundant information because it is easier to delete it using the DEPBANK structure-pruning tool than to go back and add it. All argument and adjunct relations are indicated in the DEPBANK structures — without this the structures would not be properly connected. The possible grammatical functions include (see (Butt et al., 1999)): (11) a. Subcategorized functions: subj, obj, obj_theta (secondary objects), comp (`thar- and &apos;whether&apos; -clauses), xcomp (infinitives, small clauses, and postcopular arguments), obi and obj_ag and obl_compar (subcategorized obliques) b. Nonsubcategorized functions: adjunct, name_mod (used in person names), mod, topic_rel and pron_rel (used in relative clauses), focusint and pron_int (used in interrogatives), poss, conj, number, quant and aquant (quantifiers) Information of this type is included in all dependency banks, although it is only indirectly present in most tree banks. In general, de</context>
</contexts>
<marker>Butt, King, Nifio, Segond, 1999</marker>
<rawString>Miriam Butt, Tracy Holloway King, Maria-Eugenia Nifio, and Frederique Segond. 1999. A Grammar Writer&apos;s Cookbook. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Guido Minnen</author>
<author>Ted Briscoe</author>
</authors>
<title>Corpus annotation for parser evaluation.</title>
<date>1999</date>
<booktitle>In Proceedings of the EACL workshop on Linguistically Interpreted Corpora (LINC).</booktitle>
<location>Bergen, Norway.</location>
<contexts>
<context position="24775" citStr="Carroll et al., 1999" startWordPosition="3953" endWordPosition="3956"> upper bound selection. The result is not all-or-nothing, but rather a gradient score for each dependency or for the overall matching result. DEPBANK tools have also been used for rebanking other parse banks, where the best (though not necessarily correct) analysis has been handchosen. Grammar changes require updates to the parse bank. This is achieved semi-automatically by chosing the new parse with the closest matching dependency structure to the original analysis. 5 Comparisons to Other Banks The DEPBANK is closest in form and intent to the gold-standard dependency annotations proposed by (Carroll et al., 1999) for 500 sentences selected from the Brown corpus. As discussed in more detail in (Crouch et al., 2002), the DEPBANK (a) eliminates residual aspects of surface structure that intruded into the Carroll et al annotations, and (b) provides a more detailed range of grammatical features. In addition, it provides a genuinely random selection of sentences (i.e. not preselected to be parsable by a particular parser/grammar), taken from the de facto standard corpus for parser evaluation. An evaluation of a WSJ-trained stochastic parsing system for LFG achieved 76% F-score on Carroll et al.&apos;s test set (</context>
</contexts>
<marker>Carroll, Minnen, Briscoe, 1999</marker>
<rawString>John Carroll, Guido Minnen, and Ted Briscoe. 1999. Corpus annotation for parser evaluation. In Proceedings of the EACL workshop on Linguistically Interpreted Corpora (LINC). Bergen, Norway.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
</authors>
<title>Anette Frank, Dekang Lin, Detlef Prescher,</title>
<date>2002</date>
<booktitle>Proceedings of the Workshop on Parseval and Beyond and the 3rd International Conference on Language Resources and Evaluation (LREC&apos;02). ELRA.</booktitle>
<editor>and Hans Uszkoreit, editors.</editor>
<marker>Carroll, 2002</marker>
<rawString>John Carroll, Anette Frank, Dekang Lin, Detlef Prescher, and Hans Uszkoreit, editors. 2002. Proceedings of the Workshop on Parseval and Beyond and the 3rd International Conference on Language Resources and Evaluation (LREC&apos;02). ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Crouch</author>
<author>Ronald M Kaplan</author>
<author>Tracy Holloway King</author>
<author>Stefan Riezler</author>
</authors>
<title>A comparison of evaluation metrics for a broad coverage stochastic parser.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Parseval and Beyond and the 3rd International Conference on Language Resources and Evaluation (LREC&apos;02). Las</booktitle>
<location>Palmas,</location>
<contexts>
<context position="22324" citStr="Crouch et al., 2002" startWordPosition="3547" endWordPosition="3550">pruning tool can eliminate them if they interfere with a given application. By having this pruning tool available, the possible applications of the DEPBANK are increased. Thus, as the detailed syntactic information found in the DEPBANK is not necessary or even desirable for all applications, a structure pruning tool is provided to eliminate unwanted dependencies from the DEPBANK. 4 Applications We used the DEPBANK to evaluate a stochastic parsing system consisting of an LFG grammar and a stochastic disambiguation model trained on sections 02-21 of the UPenn WSJ treebank (Riezler et al., 2002; Crouch et al., 2002). In an evaluation of a combined system of parser and stochastic disambiguator, three types of parse selection are compared against the gold standard of the DEPBANK: (i) lower bound: random choice of a parse from the set of analyses (averaged over 10 runs), (ii) upper bound: selection of the parse with the best F-score, and (iii) stochastic: the parse selected by the stochastic disambiguator. Table 1: F-score results for parser evaluation against DEPBANK. lower bd. stochastic upper bd. error red. 76.6 79.5 85.2 34 Table 1 shows F-scores for these parse selections, where F-score is defined as 2</context>
<context position="24878" citStr="Crouch et al., 2002" startWordPosition="3972" endWordPosition="3975">y or for the overall matching result. DEPBANK tools have also been used for rebanking other parse banks, where the best (though not necessarily correct) analysis has been handchosen. Grammar changes require updates to the parse bank. This is achieved semi-automatically by chosing the new parse with the closest matching dependency structure to the original analysis. 5 Comparisons to Other Banks The DEPBANK is closest in form and intent to the gold-standard dependency annotations proposed by (Carroll et al., 1999) for 500 sentences selected from the Brown corpus. As discussed in more detail in (Crouch et al., 2002), the DEPBANK (a) eliminates residual aspects of surface structure that intruded into the Carroll et al annotations, and (b) provides a more detailed range of grammatical features. In addition, it provides a genuinely random selection of sentences (i.e. not preselected to be parsable by a particular parser/grammar), taken from the de facto standard corpus for parser evaluation. An evaluation of a WSJ-trained stochastic parsing system for LFG achieved 76% F-score on Carroll et al.&apos;s test set (see Riezler et al. (2002)). The Tiger treebank (Brants et al., 2002) for German newspaper texts is on a</context>
</contexts>
<marker>Crouch, Kaplan, King, Riezler, 2002</marker>
<rawString>Richard Crouch, Ronald M. Kaplan, Tracy Holloway King, and Stefan Riezler. 2002. A comparison of evaluation metrics for a broad coverage stochastic parser. In Proceedings of the Workshop on Parseval and Beyond and the 3rd International Conference on Language Resources and Evaluation (LREC&apos;02). Las Palmas, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Haji</author>
</authors>
<title>Building a syntactically annotated corpus: The prague dependency treebank.</title>
<date>1998</date>
<booktitle>In Issues of Valency and Meaning,</booktitle>
<pages>106--132</pages>
<publisher>Karolinum,</publisher>
<location>Prague.</location>
<contexts>
<context position="27097" citStr="Haji, 1998" startWordPosition="4393" endWordPosition="4394">: Evaluation scores broken down according to (selected) dependency relations. It is a treebank supplemented with some grammatical relations annotations, rather than a dependency bank. By abstracting away from details of surface structure, the DEPBANK provides a more transparent and articulated account of predicateargument/adjunct and other semantically relevant structures. The intent of Tiger is to provide a resource for both the training and evaluation of language processing; the DEPBANK is targeted at the evaluation of systems performing deeper language analysis. The Prague Dependency Bank (Haji, 1998) for Czech is constructed in a similar fashion as the Tiger treebank, using POS tagging and a basic grammar to bootstrap the manual treebank 7 annotation. Unlike the Tiger treebank, the Prague Dependency Bank does not encode linear order, although it does use tree structures to encode dependencies. Unlike the DEPBANK, it primarily encodes relations between words, i.e., predicateargument structure, and not other syntactic dependencies, although some of these, such as number and tense, can be derived from the POS tags. The LinGO-Redwoods treebank (Oepen et al., 2002) supplements its trees with e</context>
</contexts>
<marker>Haji, 1998</marker>
<rawString>Jan Haji. 1998. Building a syntactically annotated corpus: The prague dependency treebank. In Issues of Valency and Meaning, pages 106-132. Karolinum, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell Marcus</author>
<author>Grace Kim</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Robert MacIntyre</author>
<author>Ann Bies</author>
<author>Mark Ferguson</author>
<author>Karen Katz</author>
<author>Britta Schasberger</author>
</authors>
<title>The Penn treebank: Annotating predicate argument structure.</title>
<date>1994</date>
<booktitle>In ARPA Human Language Technology Workshop.</booktitle>
<contexts>
<context position="837" citStr="Marcus et al., 1994" startWordPosition="124" endWordPosition="127">lelkaplanl@parc.com Abstract In this paper we discuss the construction, features, and current uses of the PARC 700 DEPBANK. The PARC 700 DEPBANK is a dependency bank containing predicate-argument relations and a wide variety of other grammatical features. It was semi-automatically produced and boot-strapped from the output of a deep parser: this allowed for greater consistency of analysis and for more rapid construction. 1 Introduction The PARC 700 Dependency Bank (DEPBANK) consists of 700 sentences which were randomly extracted from section 23 of the UPenn Wall Street Journal (WSJ) treebank (Marcus et al., 1994). These were parsed by a deep Lexical-Functional Grammar (LFG), converted to the DEPBANK format, and then manually corrected and extended by human validators. Average sentence length is 19.8 words, and the average number of dependencies per sentence is 65.4. The corpus is freely available for research and evaluation; documentation and tools for displaying and pruning structures are also freely available. The DEPBANK was created because existing treebanks were found inadequate for evaluating predicate-argument structure. In treebanks, this information is usually encoded implicitly in the phrase</context>
</contexts>
<marker>Marcus, Kim, Marcinkiewicz, MacIntyre, Bies, Ferguson, Katz, Schasberger, 1994</marker>
<rawString>Mitchell Marcus, Grace Kim, Mary Ann Marcinkiewicz, Robert MacIntyre, Ann Bies, Mark Ferguson, Karen Katz, and Britta Schasberger. 1994. The Penn treebank: Annotating predicate argument structure. In ARPA Human Language Technology Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John T Maxwell</author>
<author>Ronald M Kaplan</author>
</authors>
<title>The interface between phrasal and functional constraints.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--571</pages>
<marker>Maxwell, Kaplan, 1993</marker>
<rawString>John T. Maxwell III and Ronald M. Kaplan. 1993. The interface between phrasal and functional constraints. Computational Linguistics, 19:571-589.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Oepen</author>
<author>Ezra Callahan</author>
<author>Dan Flickinger</author>
<author>Christopher Manning</author>
<author>Kristina Toutanova</author>
</authors>
<title>LinG0 redwoods: a rich and dynamic treebank for HPSG.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Parseval and Beyond and the 3rd International Conference on Language Resources and Evaluation (LREC&apos;02). Las</booktitle>
<location>Palmas,</location>
<contexts>
<context position="27668" citStr="Oepen et al., 2002" startWordPosition="4483" endWordPosition="4486">nalysis. The Prague Dependency Bank (Haji, 1998) for Czech is constructed in a similar fashion as the Tiger treebank, using POS tagging and a basic grammar to bootstrap the manual treebank 7 annotation. Unlike the Tiger treebank, the Prague Dependency Bank does not encode linear order, although it does use tree structures to encode dependencies. Unlike the DEPBANK, it primarily encodes relations between words, i.e., predicateargument structure, and not other syntactic dependencies, although some of these, such as number and tense, can be derived from the POS tags. The LinGO-Redwoods treebank (Oepen et al., 2002) supplements its trees with explicit semantic representations, and is thus also aimed at providing resources for deeper language analysis. However, the LinGO-Redwoods treebank does not provide a gold-standard annotation in that it only records the best analysis produced by a particular grammar and parser, which need not necessarily be the correct analysis. It is also very heavily tied to the HPSG formalism, whereas the DEPBANK attempts to generalize away from its LFG heritage. 6 Conclusion The PARC 700 DEPBANK is a dependency bank containing both predicate-argument relations and a wide variety</context>
</contexts>
<marker>Oepen, Callahan, Flickinger, Manning, Toutanova, 2002</marker>
<rawString>Stephan Oepen, Ezra Callahan, Dan Flickinger, Christopher Manning, and Kristina Toutanova. 2002. LinG0 redwoods: a rich and dynamic treebank for HPSG. In Proceedings of the Workshop on Parseval and Beyond and the 3rd International Conference on Language Resources and Evaluation (LREC&apos;02). Las Palmas, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Riezler</author>
<author>Tracy Holloway King</author>
<author>Ronald M Kaplan</author>
<author>Richard Crouch</author>
<author>John T Maxwell</author>
<author>Mark Johnson</author>
</authors>
<title>Parsing the Wall Street Journal using a Lexical-Functional Grammar and discriminative estimation techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of hte 40th Annual Meeting of the Association for Computational Linguistics (ACL &apos;02).</booktitle>
<location>Philadelphia, PA.</location>
<contexts>
<context position="22302" citStr="Riezler et al., 2002" startWordPosition="3543" endWordPosition="3546"> found, the structure pruning tool can eliminate them if they interfere with a given application. By having this pruning tool available, the possible applications of the DEPBANK are increased. Thus, as the detailed syntactic information found in the DEPBANK is not necessary or even desirable for all applications, a structure pruning tool is provided to eliminate unwanted dependencies from the DEPBANK. 4 Applications We used the DEPBANK to evaluate a stochastic parsing system consisting of an LFG grammar and a stochastic disambiguation model trained on sections 02-21 of the UPenn WSJ treebank (Riezler et al., 2002; Crouch et al., 2002). In an evaluation of a combined system of parser and stochastic disambiguator, three types of parse selection are compared against the gold standard of the DEPBANK: (i) lower bound: random choice of a parse from the set of analyses (averaged over 10 runs), (ii) upper bound: selection of the parse with the best F-score, and (iii) stochastic: the parse selected by the stochastic disambiguator. Table 1: F-score results for parser evaluation against DEPBANK. lower bd. stochastic upper bd. error red. 76.6 79.5 85.2 34 Table 1 shows F-scores for these parse selections, where F</context>
<context position="25400" citStr="Riezler et al. (2002)" startWordPosition="4055" endWordPosition="4058"> 500 sentences selected from the Brown corpus. As discussed in more detail in (Crouch et al., 2002), the DEPBANK (a) eliminates residual aspects of surface structure that intruded into the Carroll et al annotations, and (b) provides a more detailed range of grammatical features. In addition, it provides a genuinely random selection of sentences (i.e. not preselected to be parsable by a particular parser/grammar), taken from the de facto standard corpus for parser evaluation. An evaluation of a WSJ-trained stochastic parsing system for LFG achieved 76% F-score on Carroll et al.&apos;s test set (see Riezler et al. (2002)). The Tiger treebank (Brants et al., 2002) for German newspaper texts is on a much larger scale (some 30,000 sentences) than the PARC 700 DEPBANK, and also makes use of the XLE as an annotation tool, but is quite different in form and intent. DEPENDENCY PREC. REC. F-SCORE number-type 96 95 96 coord-form 92 93 93 ptype 92 91 91 psem 89 92 90 pron-form 88 89 89 number 91 88 89 ytype 91 88 89 inf-form 97 80 88 det-type 88 86 87 perf 90 85 87 pers 87 87 87 num 86 87 86 tense 86 86 86 deixis 80 89 84 quant 85 80 83 case 83 80 82 passive 80 83 82 stmt-type 80 79 80 prog 94 69 79 proper 79 79 79 pro</context>
</contexts>
<marker>Riezler, King, Kaplan, Crouch, Maxwell, Johnson, 2002</marker>
<rawString>Stefan Riezler, Tracy Holloway King, Ronald M. Kaplan, Richard Crouch, John T. Maxwell III, and Mark Johnson. 2002. Parsing the Wall Street Journal using a Lexical-Functional Grammar and discriminative estimation techniques. In Proceedings of hte 40th Annual Meeting of the Association for Computational Linguistics (ACL &apos;02). Philadelphia, PA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>