<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000158">
<title confidence="0.987194">
Semantic Role Labeling Using Support Vector Machines
</title>
<author confidence="0.974267">
Tomohiro Mitsumori , Masaki Murata , Yasushi Fukuda
Kouichi Doi , and Hirohumi Doi
</author>
<affiliation confidence="0.87868075">
Graduate School of Information Science, Nara Institute of Science and Technology
8916-5, Takayama-cho, Ikoma-shi, Nara, 630-0101, Japan
mitsumor,doy @is.naist.jp,doi@cl-sciences.co.jp
National Institute of Information and Communications Technology
</affiliation>
<address confidence="0.878723">
3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto 619-0289, Japan
</address>
<email confidence="0.907937">
murata@nict.go.jp
</email>
<affiliation confidence="0.617315">
Sony-Kihara Research Center Inc.
</affiliation>
<address confidence="0.911465">
1-14-10 Higashigotanda, Shinagawa-ku, Tokyo, 141-0022, Japan
</address>
<email confidence="0.997927">
yasu@krc.sony.co.jp
</email>
<sectionHeader confidence="0.99563" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999900111111111">
In this paper, we describe our systems for
the CoNLL-2005 shared task. The aim of
the task is semantic role labeling using a
machine-learning algorithm. We apply the
Support Vector Machines to the task. We
added new features based on full parses
and manually categorized words. We also
report on system performance and what
effect the newly added features had.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99991944">
The CoNLL-2005 shared task (Carreras and
M`arquez, 2005) concerns the recognition of au-
tomatic semantic roles for the English language.
Given a sentence, the task consists of analyzing the
propositions expressed by various target verbs of the
sentence. The semantic roles of constituents of the
sentence are extracted for each target verb. There
are semantic arguments such as Agent, Patient, and
Instrument and also adjuncts such as Locative and
Temporal. We performed the semantic role labeling
using Support Vector Machines (SVMs). Systems
that used SVMs achieved good performance in the
CoNLL-2004 shared task, and we added data on full
parses to it. We prepared a feature used by the full
parses, and we also categorized words that appeared
in the training set and added them as features. Here,
we report on systems for automatically labeling se-
mantic roles in a closed challenge in the CoNLL-
2005 shared task.
This paper is arranged as follows. Section 2 de-
scribes the SVMs. Our system is described Sec-
tion 3, where we also describe methods of data rep-
resentation, feature coding, and the parameters of
SVMs. The experimental results and conclusion are
presented in Sections 4 and 5.
</bodyText>
<sectionHeader confidence="0.862621" genericHeader="method">
2 Support Vector Machines
</sectionHeader>
<bodyText confidence="0.721677166666667">
SVMs are one of the binary classifiers based on
the maximum margin strategy introduced by Vap-
nik (Vapnik, 1995). This algorithm has achieved
good performance in many classification tasks, e.g.
named entity recognition and document classifica-
tion. There are some advantages to SVMs in that
</bodyText>
<listItem confidence="0.980812">
(i) they have high generalization performance inde-
pendent of the dimensions of the feature vectors and
(ii) learning with a combination of multiple features
is possible by using the polynomial kernel func-
tion (Yamada and Matsumoto, 2003). SVMs were
used in the CoNLL-2004 shred task and achieved
good performance (Hacioglu et al., 2004) (Kyung-
Mi Park and Rim, 2004). We used YamCha (Yet
Another Multipurpose Chunk Annotator)1 (Kudo
and Matsumoto, 2001), which is a general purpose
SVM-based chunker. We also used TinySVM2 as a
package for SVMs.
</listItem>
<sectionHeader confidence="0.975964" genericHeader="method">
3 System Description
</sectionHeader>
<subsectionHeader confidence="0.998168">
3.1 Data Representation
</subsectionHeader>
<bodyText confidence="0.995039666666667">
We changed the representation of original data ac-
cording to Hacioglu et al. (Hacioglu et al., 2004) in
our system.
</bodyText>
<footnote confidence="0.999988">
1http://chasen.org/˜ taku/software/yamcha/
2http://chasen.org/˜ taku/software/TinySVM/
</footnote>
<page confidence="0.91513">
197
</page>
<note confidence="0.381177">
Proceedings of the 9th Conference on Computational Natural Language Learning (CoNLL),
pages 197–200, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics
</note>
<bodyText confidence="0.998882666666667">
Bracketed representation of roles was con-
verted into IOB2 representation (Ramhsaw and
Marcus, 1995) (Sang and Veenstra, 1999).
Word-by-word was changed to the phrase-by-
phrase method (Hacioglu et al., 2004).
Word tokens were collapsed into base phrase (BP)
tokens. The BP headwords were rightmost words.
Verb phrases were not collapsed because some in-
cluded more the one predicate.
</bodyText>
<subsectionHeader confidence="0.99953">
3.2 Feature Coding
</subsectionHeader>
<bodyText confidence="0.886361444444444">
We prepared the training and development set by us-
ing files corresponding to: words, predicated partial
parsing (part-of-speech, base chunks), predicate full
parsing trees (Charniak models), and named entities.
We will describe feature extraction according to Fig.
1. Figure 1 shows an example of an annotated sen-
tence.
1st Words (Bag of Words): All words appearing in
the training data.
</bodyText>
<subsectionHeader confidence="0.362096">
2nd Part of Speech (POS) Tags
</subsectionHeader>
<bodyText confidence="0.634928">
3rd Base Phrase Tags: Partial parses (chunks +
clauses) predicted with UPC processors.
</bodyText>
<subsectionHeader confidence="0.409834">
4th Named Entities
</subsectionHeader>
<bodyText confidence="0.911951625">
5th Token Depth: This means the degree of depth
from a predicate (see Fig. 2). We used full
parses predicted by the Charniak parser. In this
figure, the depth of paid , which is a predicate,
is zero and the depth of April is -2.
6th Words of Predicate
7th Position of Tokens: The position of the current
word from the predicate. This has three value
of “before”, “after”, and “-” (for the predicate).
8th Phrase Distance on Flat Path: This means the
distance from the current token to the predi-
cate as a number of the phrase on flat path.
For example, the phrase distance of “April” is
4, because two “NP” and one “PP” exist from
“paid”(predicate) to “April” (see 3rd column in
Fig.1).
</bodyText>
<tableCaption confidence="0.9284175">
Table 1: Five most frequently categorized BP head-
words appearing in training set.
</tableCaption>
<table confidence="0.886130125">
Class Examples
Person he, I, people, investors, we
Organization company, Corp., Inc., companies, group
Time year, years, time, yesterday, months
Location Francisco, York, California, city, America
Number %, million, billion, number, quarter
Money price, prices, cents, money, dollars
9th Flat Path: This means the path from the current
</table>
<bodyText confidence="0.998047705882353">
word to the predicate as a chain of the phrases.
The chain begins from the BP of the current
word to the BP of the predicate.
10th Semantic Class : We collected the most fre-
quently occurring 1,000 BP headwords appear-
ing in the training set and tried to manually
classified. The five classes (person, organiza-
tion, time, location, number and money) were
relatively easy to classify. In the 1,000 words,
the 343 words could be classified into the five
classes. Remainder could not be classified. The
details are listed in Table 1.
Preceding class: The class (e.g. B-A0 or I-A1) of
the token(s) preceding the current token. The
number of preceding tokens is dependent on the
window size. In this paper, the left context con-
sidered is two.
</bodyText>
<figure confidence="0.480168">
Depth
</figure>
<figureCaption confidence="0.966061">
Figure 2: Parsing results obtained with Charniak
parser and token depth.
</figureCaption>
<subsectionHeader confidence="0.967179">
3.3 Machine learning with YamCha
</subsectionHeader>
<bodyText confidence="0.994758">
YamCha (Kudo and Matsumoto, 2001) is a general
purpose SVM-based chunker. After inputting the
training and test data, YamCha converts them for
</bodyText>
<figure confidence="0.99349593939394">
4 S
DT
NP
NN
VBD
NP
VP
PP
�
�
The
company
paid
NP NP
IN
NP
-1
-2
3
1
0
CD
NNS
DT
NN in
NNP
five
cents
a
share
April
198
Data representation
</figure>
<figureCaption confidence="0.741861">
Figure 1: Example annotated sentence. Input features are words (1st), POS tags (2nd), base phrase chunks
(3rd), named entities (4th), token depth (5th), predicate (6th), position of tokens (7th), phrase distance (8th),
flat paths (9th), semantic classes (10th), argument classes (11th).
</figureCaption>
<bodyText confidence="0.988320909090909">
the SVM. The YamCha format for an example sen-
tence is shown in Fig. 1. Input features are writ-
ten in each column as words (1st), POS tags (2nd),
base phrase chunks (3rd), named entities (4th), token
depth (5th), predicate (6th), the position of tokens
(7th), the phrase distance (8th), flat paths (9th), se-
mantic classes (10th), and argument classes (11th).
The boxed area in Fig. 1 shows the elements of
feature vectors for the current word, in this case
“share”. The information from the two preceding
and two following tokens is used for each vector.
</bodyText>
<subsectionHeader confidence="0.998996">
3.4 Parameters of SVM
</subsectionHeader>
<bodyText confidence="0.999806823529412">
Degree of polynomial kernel (natural number):
We can only use a polynomial kernel in Yam-
Cha. In this paper, we adopted the degree of
two.
Range of window (integer): The SVM can use
the information on tokens surrounding the to-
ken of interest as illustrated in Fig. 1. In this
paper, we adopted the range from the left two
tokens to the right two tokens.
Method of solving a multi-class problem: We
adopted the one-vs.-rest method. The BIO
class is learned as (B vs. other), (I vs. other),
and (O vs. other).
Cost of constraint violation (floating number):
There is a trade-off between the training error
and the soft margin for the hyper plane. We
adopted a default value (1.0).
</bodyText>
<sectionHeader confidence="0.99984" genericHeader="evaluation">
4 Results
</sectionHeader>
<subsectionHeader confidence="0.979806">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.999989375">
The data provided for the shared task consisted of
sections from the Wall Street Journal (WSJ) part of
Penn TreeBank II. The training set was WSJ Sec-
tions 02-21, the development set was Section 24, and
the test set was Section 23 with the addition of fresh
sentences. Our experiments were carried out using
Sections 15-18 for the training set, because the en-
tire file was too large to learn.
</bodyText>
<subsectionHeader confidence="0.918774">
4.2 Experiments
</subsectionHeader>
<bodyText confidence="0.999734285714286">
Our final results for the CoNLL-2005 shared task are
listed in Table 2. Our system achieved 74.15% pre-
cision, 68.25% recall and 71.08 F on the overall
results of Test WSJ. Table 3 lists the effects of the
token-depth and semantic-class features. The token-
depth feature had a larger effect than that for the se-
mantic class.
</bodyText>
<page confidence="0.995568">
199
</page>
<table confidence="0.999996736842105">
Precision Recall F
Development 71.68% 64.93% 68.14
Test WSJ 74.15% 68.25% 71.08
Test Brown 63.24% 54.20% 58.37
Test WSJ+Brown 72.77% 66.37% 69.43
Test WSJ Precision Recall F
Overall 74.15% 68.25% 71.08
A0 81.38% 76.93% 79.09
A1 73.16% 70.87% 72.00
A2 64.53% 59.01% 61.65
A3 61.16% 42.77% 50.34
A4 68.18% 58.82% 63.16
A5 100.00% 80.00% 88.89
AM-ADV 55.09% 43.87% 48.84
AM-CAU 60.00% 28.77% 38.89
AM-DIR 45.10% 27.06% 33.82
AM-DIS 72.70% 69.06% 70.83
AM-EXT 70.59% 37.50% 48.98
AM-LOC 55.62% 50.41% 52.89
AM-MNR 51.40% 42.73% 46.67
AM-MOD 97.04% 95.28% 96.15
AM-NEG 96.92% 95.65% 96.28
AM-PNC 56.00% 36.52% 44.21
AM-PRD 0.00% 0.00% 0.00
AM-REC 0.00% 0.00% 0.00
AM-TMP 73.39% 62.93% 67.76
R-A0 81.31% 71.88% 76.30
R-A1 59.69% 49.36% 54.04
R-A2 60.00% 18.75% 28.57
R-A3 0.00% 0.00% 0.00
R-A4 0.00% 0.00% 0.00
R-AM-ADV 0.00% 0.00% 0.00
R-AM-CAU 0.00% 0.00% 0.00
R-AM-EXT 0.00% 0.00% 0.00
R-AM-LOC 85.71% 28.57% 42.86
R-AM-MNR 100.00% 16.67% 28.57
R-AM-TMP 72.34% 65.38% 68.69
V 97.55% 96.05% 96.80
</table>
<tableCaption confidence="0.959843">
Table 2: Overall results (top) and detailed results on
the WSJ test (bottom).
</tableCaption>
<sectionHeader confidence="0.997861" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999034923076923">
This paper reported on semantic role labeling using
SVMs. Systems that used SVMs achieved good per-
formance in the CoNLL-2004 shared task, and we
added data on full parses to it. We applied a token-
depth feature to SVM learning and it had a large ef-
fect. We also added a semantic-class feature and it
had a small effect. Some classes were similar to the
named entities, e.g., the PERSON or LOCATION
of the named entities. Our semantic class feature
also included not only proper names but also com-
mon words. For example, “he” and “she” also in-
cluded the PERSON semantic class. Furthermore,
we added a time, number, and money class. The
</bodyText>
<tableCaption confidence="0.959205">
Table 3: Effects Token Depth (TD) and Semantic
Class (SC) had on feature development set.
</tableCaption>
<table confidence="0.9768635">
Precision Recall F
Without DF and SC 68.07% 59.71% 63.62
With DF 71.36% 64.13% 67.55
With DF and SC 71.68% 64.93% 68.14
</table>
<bodyText confidence="0.99492625">
semantic class feature was manually categorized on
the most frequently occurring 1,000 words in the
training set. More effort of the categorization may
improve the performance of our system.
</bodyText>
<sectionHeader confidence="0.999432" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9993620625">
Xavier Carreras and Lluis M`arquez. 2005. Introduction
to the CoNLL-2005 Shared Task: Semantic Role La-
beling . In Proceedings of CoNLL-2005.
Kadri Hacioglu, Sameer Pradhan, Wayne Ward, James H.
Martin, and Daniel Jurafskey. 2004. Semantic Role
Labeling by Tagging Syntactic Chunks. In Proceed-
ings of Conference on Computational Natural Lan-
guage Learning (CoNLL-2004) Shared Task on Se-
mantic Role Labeling.
Taku Kudo and Yuji Matsumoto. 2001. Chunking with
Support Vector Machines. In Proceedings of Second
Meeting ofNorth American Chapter of the Association
for Computational Linguistics (NAACL), pages 192–
199.
Young-Sook Hwang Kyung-Mi Park and Hae-Chang
Rim. 2004. Semantic Role Labeling by Tagging Syn-
tactic Chunks. In Proceedings of the Conference on
Computational Natural Language Learning (CoNLL-
2004) Shared Task on Semantic Role Labeling.
Lance E. Ramhsaw and Mitchell P. Marcus. 1995. Text
Chunking Using Transformation Based Learning . In
Proceedings of the 3rd ACL Workshop on Very Large
Corpora, pages 82–94.
Erik F. T. J. Sang and John Veenstra. 1999. Representing
Text Chunks. In Proceedings ofEACL!G99, pages 173–
179.
Vladimir N. Vapnik. 1995. The Nature of Statistical
Learning Theory. Springer.
Hiroyasu Yamada and Yuji Matsumoto. 2003. Statistical
dependency analysis with Support Vector Machines .
In Proceedings of the 8th International Workshop on
Parsing Technologies (IWPT), pages 195–206.
</reference>
<page confidence="0.996539">
200
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.704333">
<title confidence="0.999856">Semantic Role Labeling Using Support Vector Machines</title>
<author confidence="0.966643">Yasushi Kouichi Doi</author>
<affiliation confidence="0.99967">Graduate School of Information Science, Nara Institute of Science and</affiliation>
<address confidence="0.913972">8916-5, Takayama-cho, Ikoma-shi, Nara, 630-0101,</address>
<affiliation confidence="0.971463">National Institute of Information and Communications</affiliation>
<address confidence="0.854655">3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto 619-0289,</address>
<affiliation confidence="0.991994">Sony-Kihara Research Center</affiliation>
<address confidence="0.997458">1-14-10 Higashigotanda, Shinagawa-ku, Tokyo, 141-0022,</address>
<email confidence="0.983647">yasu@krc.sony.co.jp</email>
<abstract confidence="0.9990716">In this paper, we describe our systems for the CoNLL-2005 shared task. The aim of the task is semantic role labeling using a machine-learning algorithm. We apply the Support Vector Machines to the task. We added new features based on full parses and manually categorized words. We also report on system performance and what effect the newly added features had.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Lluis M`arquez</author>
</authors>
<title>Introduction to the CoNLL-2005 Shared Task: Semantic Role Labeling .</title>
<date>2005</date>
<booktitle>In Proceedings of CoNLL-2005.</booktitle>
<marker>Carreras, M`arquez, 2005</marker>
<rawString>Xavier Carreras and Lluis M`arquez. 2005. Introduction to the CoNLL-2005 Shared Task: Semantic Role Labeling . In Proceedings of CoNLL-2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kadri Hacioglu</author>
<author>Sameer Pradhan</author>
<author>Wayne Ward</author>
<author>James H Martin</author>
<author>Daniel Jurafskey</author>
</authors>
<title>Semantic Role Labeling by Tagging Syntactic Chunks.</title>
<date>2004</date>
<booktitle>In Proceedings of Conference on Computational Natural Language Learning (CoNLL-2004) Shared Task on Semantic Role Labeling.</booktitle>
<contexts>
<context position="2801" citStr="Hacioglu et al., 2004" startWordPosition="422" endWordPosition="425">s are one of the binary classifiers based on the maximum margin strategy introduced by Vapnik (Vapnik, 1995). This algorithm has achieved good performance in many classification tasks, e.g. named entity recognition and document classification. There are some advantages to SVMs in that (i) they have high generalization performance independent of the dimensions of the feature vectors and (ii) learning with a combination of multiple features is possible by using the polynomial kernel function (Yamada and Matsumoto, 2003). SVMs were used in the CoNLL-2004 shred task and achieved good performance (Hacioglu et al., 2004) (KyungMi Park and Rim, 2004). We used YamCha (Yet Another Multipurpose Chunk Annotator)1 (Kudo and Matsumoto, 2001), which is a general purpose SVM-based chunker. We also used TinySVM2 as a package for SVMs. 3 System Description 3.1 Data Representation We changed the representation of original data according to Hacioglu et al. (Hacioglu et al., 2004) in our system. 1http://chasen.org/˜ taku/software/yamcha/ 2http://chasen.org/˜ taku/software/TinySVM/ 197 Proceedings of the 9th Conference on Computational Natural Language Learning (CoNLL), pages 197–200, Ann Arbor, June 2005. c�2005 Associatio</context>
</contexts>
<marker>Hacioglu, Pradhan, Ward, Martin, Jurafskey, 2004</marker>
<rawString>Kadri Hacioglu, Sameer Pradhan, Wayne Ward, James H. Martin, and Daniel Jurafskey. 2004. Semantic Role Labeling by Tagging Syntactic Chunks. In Proceedings of Conference on Computational Natural Language Learning (CoNLL-2004) Shared Task on Semantic Role Labeling.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Chunking with Support Vector Machines.</title>
<date>2001</date>
<booktitle>In Proceedings of Second Meeting ofNorth American Chapter of the Association for Computational Linguistics (NAACL),</booktitle>
<pages>192--199</pages>
<contexts>
<context position="2917" citStr="Kudo and Matsumoto, 2001" startWordPosition="440" endWordPosition="443">s algorithm has achieved good performance in many classification tasks, e.g. named entity recognition and document classification. There are some advantages to SVMs in that (i) they have high generalization performance independent of the dimensions of the feature vectors and (ii) learning with a combination of multiple features is possible by using the polynomial kernel function (Yamada and Matsumoto, 2003). SVMs were used in the CoNLL-2004 shred task and achieved good performance (Hacioglu et al., 2004) (KyungMi Park and Rim, 2004). We used YamCha (Yet Another Multipurpose Chunk Annotator)1 (Kudo and Matsumoto, 2001), which is a general purpose SVM-based chunker. We also used TinySVM2 as a package for SVMs. 3 System Description 3.1 Data Representation We changed the representation of original data according to Hacioglu et al. (Hacioglu et al., 2004) in our system. 1http://chasen.org/˜ taku/software/yamcha/ 2http://chasen.org/˜ taku/software/TinySVM/ 197 Proceedings of the 9th Conference on Computational Natural Language Learning (CoNLL), pages 197–200, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics Bracketed representation of roles was converted into IOB2 representation (Ramhsaw an</context>
<context position="6342" citStr="Kudo and Matsumoto, 2001" startWordPosition="990" endWordPosition="993">ually classified. The five classes (person, organization, time, location, number and money) were relatively easy to classify. In the 1,000 words, the 343 words could be classified into the five classes. Remainder could not be classified. The details are listed in Table 1. Preceding class: The class (e.g. B-A0 or I-A1) of the token(s) preceding the current token. The number of preceding tokens is dependent on the window size. In this paper, the left context considered is two. Depth Figure 2: Parsing results obtained with Charniak parser and token depth. 3.3 Machine learning with YamCha YamCha (Kudo and Matsumoto, 2001) is a general purpose SVM-based chunker. After inputting the training and test data, YamCha converts them for 4 S DT NP NN VBD NP VP PP � � The company paid NP NP IN NP -1 -2 3 1 0 CD NNS DT NN in NNP five cents a share April 198 Data representation Figure 1: Example annotated sentence. Input features are words (1st), POS tags (2nd), base phrase chunks (3rd), named entities (4th), token depth (5th), predicate (6th), position of tokens (7th), phrase distance (8th), flat paths (9th), semantic classes (10th), argument classes (11th). the SVM. The YamCha format for an example sentence is shown in </context>
</contexts>
<marker>Kudo, Matsumoto, 2001</marker>
<rawString>Taku Kudo and Yuji Matsumoto. 2001. Chunking with Support Vector Machines. In Proceedings of Second Meeting ofNorth American Chapter of the Association for Computational Linguistics (NAACL), pages 192– 199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Young-Sook Hwang Kyung-Mi Park</author>
<author>Hae-Chang Rim</author>
</authors>
<title>Semantic Role Labeling by Tagging Syntactic Chunks.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Computational Natural Language Learning (CoNLL2004) Shared Task on Semantic Role Labeling.</booktitle>
<contexts>
<context position="2830" citStr="Park and Rim, 2004" startWordPosition="428" endWordPosition="431">ers based on the maximum margin strategy introduced by Vapnik (Vapnik, 1995). This algorithm has achieved good performance in many classification tasks, e.g. named entity recognition and document classification. There are some advantages to SVMs in that (i) they have high generalization performance independent of the dimensions of the feature vectors and (ii) learning with a combination of multiple features is possible by using the polynomial kernel function (Yamada and Matsumoto, 2003). SVMs were used in the CoNLL-2004 shred task and achieved good performance (Hacioglu et al., 2004) (KyungMi Park and Rim, 2004). We used YamCha (Yet Another Multipurpose Chunk Annotator)1 (Kudo and Matsumoto, 2001), which is a general purpose SVM-based chunker. We also used TinySVM2 as a package for SVMs. 3 System Description 3.1 Data Representation We changed the representation of original data according to Hacioglu et al. (Hacioglu et al., 2004) in our system. 1http://chasen.org/˜ taku/software/yamcha/ 2http://chasen.org/˜ taku/software/TinySVM/ 197 Proceedings of the 9th Conference on Computational Natural Language Learning (CoNLL), pages 197–200, Ann Arbor, June 2005. c�2005 Association for Computational Linguisti</context>
</contexts>
<marker>Park, Rim, 2004</marker>
<rawString>Young-Sook Hwang Kyung-Mi Park and Hae-Chang Rim. 2004. Semantic Role Labeling by Tagging Syntactic Chunks. In Proceedings of the Conference on Computational Natural Language Learning (CoNLL2004) Shared Task on Semantic Role Labeling.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lance E Ramhsaw</author>
<author>Mitchell P Marcus</author>
</authors>
<title>Text Chunking Using Transformation Based Learning .</title>
<date>1995</date>
<booktitle>In Proceedings of the 3rd ACL Workshop on Very Large Corpora,</booktitle>
<pages>82--94</pages>
<contexts>
<context position="3532" citStr="Ramhsaw and Marcus, 1995" startWordPosition="523" endWordPosition="526">oto, 2001), which is a general purpose SVM-based chunker. We also used TinySVM2 as a package for SVMs. 3 System Description 3.1 Data Representation We changed the representation of original data according to Hacioglu et al. (Hacioglu et al., 2004) in our system. 1http://chasen.org/˜ taku/software/yamcha/ 2http://chasen.org/˜ taku/software/TinySVM/ 197 Proceedings of the 9th Conference on Computational Natural Language Learning (CoNLL), pages 197–200, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics Bracketed representation of roles was converted into IOB2 representation (Ramhsaw and Marcus, 1995) (Sang and Veenstra, 1999). Word-by-word was changed to the phrase-byphrase method (Hacioglu et al., 2004). Word tokens were collapsed into base phrase (BP) tokens. The BP headwords were rightmost words. Verb phrases were not collapsed because some included more the one predicate. 3.2 Feature Coding We prepared the training and development set by using files corresponding to: words, predicated partial parsing (part-of-speech, base chunks), predicate full parsing trees (Charniak models), and named entities. We will describe feature extraction according to Fig. 1. Figure 1 shows an example of an</context>
</contexts>
<marker>Ramhsaw, Marcus, 1995</marker>
<rawString>Lance E. Ramhsaw and Mitchell P. Marcus. 1995. Text Chunking Using Transformation Based Learning . In Proceedings of the 3rd ACL Workshop on Very Large Corpora, pages 82–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik F T J Sang</author>
<author>John Veenstra</author>
</authors>
<title>Representing Text Chunks.</title>
<date>1999</date>
<booktitle>In Proceedings ofEACL!G99,</booktitle>
<pages>173--179</pages>
<contexts>
<context position="3558" citStr="Sang and Veenstra, 1999" startWordPosition="527" endWordPosition="530">ral purpose SVM-based chunker. We also used TinySVM2 as a package for SVMs. 3 System Description 3.1 Data Representation We changed the representation of original data according to Hacioglu et al. (Hacioglu et al., 2004) in our system. 1http://chasen.org/˜ taku/software/yamcha/ 2http://chasen.org/˜ taku/software/TinySVM/ 197 Proceedings of the 9th Conference on Computational Natural Language Learning (CoNLL), pages 197–200, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics Bracketed representation of roles was converted into IOB2 representation (Ramhsaw and Marcus, 1995) (Sang and Veenstra, 1999). Word-by-word was changed to the phrase-byphrase method (Hacioglu et al., 2004). Word tokens were collapsed into base phrase (BP) tokens. The BP headwords were rightmost words. Verb phrases were not collapsed because some included more the one predicate. 3.2 Feature Coding We prepared the training and development set by using files corresponding to: words, predicated partial parsing (part-of-speech, base chunks), predicate full parsing trees (Charniak models), and named entities. We will describe feature extraction according to Fig. 1. Figure 1 shows an example of an annotated sentence. 1st W</context>
</contexts>
<marker>Sang, Veenstra, 1999</marker>
<rawString>Erik F. T. J. Sang and John Veenstra. 1999. Representing Text Chunks. In Proceedings ofEACL!G99, pages 173– 179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir N Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory.</title>
<date>1995</date>
<publisher>Springer.</publisher>
<contexts>
<context position="2287" citStr="Vapnik, 1995" startWordPosition="345" endWordPosition="346"> categorized words that appeared in the training set and added them as features. Here, we report on systems for automatically labeling semantic roles in a closed challenge in the CoNLL2005 shared task. This paper is arranged as follows. Section 2 describes the SVMs. Our system is described Section 3, where we also describe methods of data representation, feature coding, and the parameters of SVMs. The experimental results and conclusion are presented in Sections 4 and 5. 2 Support Vector Machines SVMs are one of the binary classifiers based on the maximum margin strategy introduced by Vapnik (Vapnik, 1995). This algorithm has achieved good performance in many classification tasks, e.g. named entity recognition and document classification. There are some advantages to SVMs in that (i) they have high generalization performance independent of the dimensions of the feature vectors and (ii) learning with a combination of multiple features is possible by using the polynomial kernel function (Yamada and Matsumoto, 2003). SVMs were used in the CoNLL-2004 shred task and achieved good performance (Hacioglu et al., 2004) (KyungMi Park and Rim, 2004). We used YamCha (Yet Another Multipurpose Chunk Annotato</context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>Vladimir N. Vapnik. 1995. The Nature of Statistical Learning Theory. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyasu Yamada</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Statistical dependency analysis with Support Vector Machines .</title>
<date>2003</date>
<booktitle>In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT),</booktitle>
<pages>195--206</pages>
<contexts>
<context position="2702" citStr="Yamada and Matsumoto, 2003" startWordPosition="406" endWordPosition="409">The experimental results and conclusion are presented in Sections 4 and 5. 2 Support Vector Machines SVMs are one of the binary classifiers based on the maximum margin strategy introduced by Vapnik (Vapnik, 1995). This algorithm has achieved good performance in many classification tasks, e.g. named entity recognition and document classification. There are some advantages to SVMs in that (i) they have high generalization performance independent of the dimensions of the feature vectors and (ii) learning with a combination of multiple features is possible by using the polynomial kernel function (Yamada and Matsumoto, 2003). SVMs were used in the CoNLL-2004 shred task and achieved good performance (Hacioglu et al., 2004) (KyungMi Park and Rim, 2004). We used YamCha (Yet Another Multipurpose Chunk Annotator)1 (Kudo and Matsumoto, 2001), which is a general purpose SVM-based chunker. We also used TinySVM2 as a package for SVMs. 3 System Description 3.1 Data Representation We changed the representation of original data according to Hacioglu et al. (Hacioglu et al., 2004) in our system. 1http://chasen.org/˜ taku/software/yamcha/ 2http://chasen.org/˜ taku/software/TinySVM/ 197 Proceedings of the 9th Conference on Comp</context>
</contexts>
<marker>Yamada, Matsumoto, 2003</marker>
<rawString>Hiroyasu Yamada and Yuji Matsumoto. 2003. Statistical dependency analysis with Support Vector Machines . In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT), pages 195–206.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>