<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000972">
<title confidence="0.966713">
IIITH: Domain Specific Word Sense Disambiguation
</title>
<author confidence="0.963294">
Siva Reddy
</author>
<affiliation confidence="0.8823975">
IIIT Hyderabad
India
</affiliation>
<email confidence="0.956868">
gvsreddy@students.iiit.ac.in
</email>
<author confidence="0.980704">
Diana McCarthy
</author>
<affiliation confidence="0.89882">
Lexical Computing Ltd.
</affiliation>
<address confidence="0.737754">
United Kingdom
</address>
<email confidence="0.990221">
diana@dianamccarthy.co.uk
</email>
<author confidence="0.801037">
Abhilash Inumella
</author>
<affiliation confidence="0.7628395">
IIIT Hyderabad
India
</affiliation>
<email confidence="0.932677">
abhilashi@students.iiit.ac.in
</email>
<author confidence="0.99816">
Mark Stevenson
</author>
<affiliation confidence="0.998748">
University of Sheffield
</affiliation>
<address confidence="0.79818">
United Kingdom
</address>
<email confidence="0.997806">
m.stevenson@dcs.shef.ac.uk
</email>
<sectionHeader confidence="0.995632" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999759944444445">
We describe two systems that participated
in SemEval-2010 task 17 (All-words Word
Sense Disambiguation on a Specific Do-
main) and were ranked in the third and
fourth positions in the formal evaluation.
Domain adaptation techniques using the
background documents released in the
task were used to assign ranking scores to
the words and their senses. The test data
was disambiguated using the Personalized
PageRank algorithm which was applied
to a graph constructed from the whole of
WordNet in which nodes are initialized
with ranking scores of words and their
senses. In the competition, our systems
achieved comparable accuracy of 53.4 and
52.2, which outperforms the most frequent
sense baseline (50.5).
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999567509433963">
The senses in WordNet are ordered according to
their frequency in a manually tagged corpus, Sem-
Cor (Miller et al., 1993). Senses that do not oc-
cur in SemCor are ordered arbitrarily after those
senses of the word that have occurred. It is known
from the results of SENSEVAL2 (Cotton et al.,
2001) and SENSEVAL3 (Mihalcea and Edmonds,
2004) that first sense heuristic outperforms many
WSD systems (see McCarthy et al. (2007)). The
first sense baseline’s strong performance is due to
the skewed frequency distribution of word senses.
WordNet sense distributions based on SemCor are
clearly useful, however in a given domain these
distributions may not hold true. For example, the
first sense for “bank” in WordNet refers to “slop-
ing land beside a body of river” and the second
to “financial institution”, but in the domain of “fi-
nance” the “financial institution” sense would be
expected to be more likely than the “sloping land
beside a body of river” sense. Unfortunately, it
is not feasible to produce large manually sense-
annotated corpora for every domain of interest.
McCarthy et al. (2004) propose a method to pre-
dict sense distributions from raw corpora and use
this as a first sense heuristic for tagging text with
the predominant sense. Rather than assigning pre-
dominant sense in every case, our approach aims
to use these sense distributions collected from do-
main specific corpora as a knowledge source and
combine this with information from the context.
Our approach focuses on the strong influence of
domain for WSD (Buitelaar et al., 2006) and the
benefits of focusing on words salient to the do-
main (Koeling et al., 2005). Words are assigned
a ranking score based on its keyness (salience) in
the given domain. We use these word scores as
another knowledge source.
Graph based methods have been shown to
produce state-of-the-art performance for unsu-
pervised word sense disambiguation (Agirre and
Soroa, 2009; Sinha and Mihalcea, 2007). These
approaches use well-known graph-based tech-
niques to find and exploit the structural properties
of the graph underlying a particular lexical knowl-
edge base (LKB), such as WordNet. These graph-
based algorithms are appealing because they take
into account information drawn from the entire
graph as well as from the given context, making
them superior to other approaches that rely only
on local information individually derived for each
word.
Our approach uses the Personalized PageRank
algorithm (Agirre and Soroa, 2009) over a graph
</bodyText>
<page confidence="0.976344">
387
</page>
<bodyText confidence="0.850396071428572">
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 387–391,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
representing WordNet to disambiguate ambigu-
ous words by taking their context into consider-
ation. We also combine domain-specific informa-
tion from the knowledge sources, like sense distri-
bution scores and keyword ranking scores, into the
graph thus personalizing the graph for the given
domain.
In section 2, we describe domain sense ranking.
Domain keyword ranking is described in Section
3. Graph construction and personalized page rank
are described in Section 4. Evaluation results over
the SemEval data are provided in Section 5.
</bodyText>
<sectionHeader confidence="0.931771" genericHeader="method">
2 Domain Sense Ranking
</sectionHeader>
<bodyText confidence="0.986280096774194">
McCarthy et al. (2004) propose a method for
finding predominant senses from raw text. The
method uses a thesaurus acquired from automat-
ically parsed text based on the method described
by Lin (1998). This provides the top k nearest
neighbours for each target word w, along with the
distributional similarity score between the target
word and each neighbour. The senses of a word
w are each assigned a score by summing over the
distributional similarity scores of its neighbours.
These are weighted by a semantic similarity score
(using WordNet Similarity score (Pedersen et al.,
2004) between the sense of w and the sense of the
neighbour that maximizes the semantic similarity
score.
More formally, let N,,, = {n1, n2,... nk}
be the ordered set of the top k scoring
neighbours of w from the thesaurus with
associated distributional similarity scores
{dss(w, n1), dss(w, n2),... dss(w, nk)}. Let
senses(w) be the set of senses of w. For each
sense of w (wsi E senses(w)) a ranking score is
obtained by summing over the dss(w, nj) of each
neighbour (nj E N,,,) multiplied by a weight.
This weight is the WordNet similarity score
(wnss) between the target sense (wsi) and the
sense of nj (nsx E senses(nj)) that maximizes
this score, divided by the sum of all such WordNet
similarity scores for senses(w) and nj. Each
sense wsi E senses(w) is given a sense ranking
score srs(wsi) using
</bodyText>
<equation confidence="0.9979102">
srs(wsi) =
wnss(wsi, nj)
dss(w, nj) ×
E wnss(wsi, nj)
wsiesenses(w)
</equation>
<bodyText confidence="0.952408318181818">
where wnss(wsi, nj) (_
maxnsx ∈senses(nj) (wnss (wsi, nsx))
Since this approach requires only raw text,
sense rankings for a particular domain can be gen-
erated by simply training the algorithm using a
corpus representing that domain. We used the
background documents provided to the partici-
pants in this task as a domain specific corpus. In
general, a domain specific corpus can be obtained
using domain-specific keywords (Kilgarriff et al.,
2010). A thesaurus is acquired from automatically
parsed background documents using the Stanford
Parser (Klein and Manning, 2003). We used k = 5
to built the thesaurus. As we increased k we found
the number of non-domain specific words occur-
ring in the thesaurus increased and negatively af-
fected the sense distributions. To counter this, one
of our systems IIITH2 used a slightly modified
ranking score by multiplying the effect of each
neighbour with its domain keyword ranking score.
The modified sense ranking msrs(wsj) score of
sense wsi is
</bodyText>
<equation confidence="0.998965">
msrs(wsi) =
wnss(wsi, nj)
dss(w, nj)×
E wnss(wsi, nj)
wsiesenses(w)
</equation>
<bodyText confidence="0.9977992">
where krs(nj) is the keyword ranking score of
the neighbour nj in the domain specific corpus. In
the next section we describe the way in which we
compute krs(nj).
WordNet::Similarity::lesk (Pedersen et al.,
2004) was used to compute word similarity wnss.
IIITH1 and IIITH2 systems differ in the way
senses are ranked. IIITH1 uses srs(wsj) whereas
IIITH2 system uses msrs(wsj) for computing
sense ranking scores in the given domain.
</bodyText>
<sectionHeader confidence="0.997033" genericHeader="method">
3 Domain Keyword Ranking
</sectionHeader>
<bodyText confidence="0.9969907">
We extracted keywords in the domain by compar-
ing the frequency lists of domain corpora (back-
ground documents) and a very large general cor-
pus, ukWaC (Ferraresi et al., 2008), using the
method described by Rayson and Garside (2000).
For each word in the frequency list of the domain
corpora, words(domain), we calculated the log-
likelihood (LL) statistic as described in Rayson
and Garside (2000). We then normalized LL to
compute keyword ranking score krs(w) of word
</bodyText>
<equation confidence="0.797554111111111">
w words(domain) using
E
nj eNw
E
nj eNw
×krs(nj)
388
krs(w) = E LL(w) LL(wi)
wi∈words(domain)
</equation>
<bodyText confidence="0.992215">
The above score represents the keyness of the
word in the given domain. Top ten keywords (in
descending order of krs) in the corpora provided
for this task are species, biodiversity, life, habitat,
natura1, EU, forest, conservation, years, amp2.
</bodyText>
<sectionHeader confidence="0.995849" genericHeader="method">
4 Personalized PageRank
</sectionHeader>
<bodyText confidence="0.9999875">
Our approach uses the Personalized PageRank al-
gorithm (Agirre and Soroa, 2009) with WordNet
as the lexical knowledge base (LKB) to perform
WSD. WordNet is converted to a graph by repre-
senting each synset as a node (synset node) and the
relationships in WordNet (hypernymy, hyponymy
etc.) as edges between synset nodes. The graph is
initialized by adding a node (word node) for each
context word of the target word (including itself)
thus creating a context dependent graph (person-
alized graph). The popular PageRank (Page et al.,
1999) algorithm is employed to analyze this per-
sonalized graph (thus the algorithm is referred as
personalized PageRank algorithm) and the sense
for each disambiguous word is chosen by choos-
ing the synset node which gets the highest weight
after a certain number of iterations of PageRank
algorithm.
We capture domain information in the personal-
ized graph by using sense ranking scores and key-
word ranking scores of the domain to assign initial
weights to the word nodes and their edges (word-
synset edge). This way we personalize the graph
for the given domain.
</bodyText>
<subsectionHeader confidence="0.972621">
4.1 Graph Initialization Methods
</subsectionHeader>
<bodyText confidence="0.999791555555556">
We experimented with different ways of initial-
izing the graph, described below, which are de-
signed to capture domain specific information.
Personalized Page rank (PPR): In this method,
the graph is initialized by allocating equal prob-
ability mass to all the word nodes in the context
including the target word itself, thus making the
graph context sensitive. This does not include do-
main specific information.
</bodyText>
<footnote confidence="0.995562333333333">
1In background documents this word occurs in reports de-
scribing Natura 2000 networking programme.
2This new word ”amp” is created by our programs while
extracting body text from background documents. The
HTML code ”&amp;” which represents the symbol”&amp;” is
converted into this word.
</footnote>
<bodyText confidence="0.989324473684211">
Keyword Ranking scores with PPR (KRS +
PPR): This is same as PPR except that context
words are initialized with krs.
Sense Ranking scores with PPR (SRS + PPR):
Edges connecting words and their synsets are as-
signed weights equal to srs. The initialization of
word nodes is same as in PPR.
KRS + SRS + PPR: Word nodes are initialized
with krs and edges are assigned weights equal to
srs.
In addition to the above methods of unsuper-
vised graph initialization, we also initialized the
graph in a semi-supervised manner. WordNet (ver-
sion 1.7 and above) have a field tag cnt for each
synset (in the file index.sense) which represents
the number of times the synset is tagged in vari-
ous semantic concordance texts. We used this in-
formation, concordance score (cs) of each synset,
with the above methods of graph initialization as
described below.
Concordance scores with PPR (CS + PPR): The
graph initialization is similar to PPR initialization
additionally with concordance score of synsets on
the edges joining words and their synsets.
CS + KRS + PPR: The initialization graph of
KRS + PPR is further initialized by assigning con-
cordance scores to the edges connecting words and
their synsets.
CS + SRS + PPR: Edges connecting words and
their synsets are assigned weights equal to sum of
the concordance scores and sense ranking scores
i.e. cs + srs. The initialization of word nodes is
same as in PPR.
CS + KRS + SRS + PPR: Word nodes are ini-
tialized with krs and edges are assigned weights
equal to cs + srs.
PageRank was applied to all the above graphs to
disambiguate a target word.
</bodyText>
<subsectionHeader confidence="0.973492">
4.2 Experimental details of PageRank
</subsectionHeader>
<bodyText confidence="0.9993616">
Tool: We used UKB tool3 (Agirre and Soroa,
2009) which provides an implementation of per-
sonalized PageRank. We modified it to incorpo-
rate our methods of graph initialization. The LKB
used in our experiments is WordNet3.0 + Gloss
which is provided in the tool. More details of the
tools used can be found in the Appendix.
Normalizations: Sense ranking scores (srs) and
keyword ranking scores (krs) have diverse ranges.
We found srs generally in the range between 0 to
</bodyText>
<footnote confidence="0.952792">
3http://ixa2.si.ehu.es/ukb/
</footnote>
<page confidence="0.995109">
389
</page>
<table confidence="0.999134285714286">
Precision Recall
Unsupervised Graph Initialization
PPR 37.3 36.8
KRS + PPR 38.1 37.6
SRS + PPR 48.4 47.8
KRS + SRS + PPR 48.0 47.4
Semi-supervised Graph Initialization
CS + PPR 50.2 49.6
CS + KRS + PPR 50.1 49.5
* CS + SRS + PPR 53.4 52.8
CS + KRS + SRS + PPR 53.6 52.9
Others
1stsense 50.5 50.5
PSH 49.8 43.2
</table>
<tableCaption confidence="0.979937">
Table 1: Evaluation results on English test data of SemEval-2010 Task-17. * represents the system which
we submitted to SemEval and is ranked 3rd in public evaluation.
</tableCaption>
<bodyText confidence="0.891350571428571">
1 and krs in the range 0 to 0.02. Since these scores
are used to assign initial weights in the graph,
these ranges are scaled to fall in a common range
of [0, 100]. Using any other scaling method should
not effect the performance much since PageRank
(and UKB tool) has its own internal mechanisms
to normalize the weights.
</bodyText>
<sectionHeader confidence="0.974424" genericHeader="evaluation">
5 Evaluation Results
</sectionHeader>
<bodyText confidence="0.999545409090909">
Test data released for this task is disambiguated
using IIITH1 and IIITH2 systems. As described
in Section 2, IIITH1 and IIITH2 systems differ in
the way the sense ranking scores are computed.
Here we project only the results of IIITH1 since
IIITH1 performed slightly better than IIITH2 in all
the above settings. Results of 1stsense system pro-
vided by the organizers which assigns first sense
computed from the annotations in hand-labeled
corpora is also presented. Additionally, we also
present the results of Predominant Sense Heuristic
(PSH) which assigns every word w with the sense
wsj (wsj ∈ senses(w)) which has the highest
value of srs(wsj) computed in Section 2 similar
to (McCarthy et al., 2004).
Table 1 presents the evaluation results. We used
TreeTagger 4 to Part of Speech tag the test data.
POS information was used to discard irrelevant
senses. Due to POS tagging errors, our precision
values were not equal to recall values. In the com-
petition, we submitted IIITH1 and IIITH2 systems
with CS + SRS + PPR graph initialization. IIITH1
</bodyText>
<footnote confidence="0.9507365">
4http://www.ims.uni-stuttgart.de/
projekte/corplex/TreeTagger/
</footnote>
<bodyText confidence="0.99972915">
and IIIH2 gave performances of 53.4 % and 52.2
% precision respectively. In our later experiments,
we found CS + KRS + SRS + PPR has given the
best performance of 53.6 % precision.
From the results, it can be seen when srs in-
formation is incorporated in the graph, precision
improved by 11.1% compared to PPR in unsuper-
vised graph initialization and by 3.19% compared
to CS + PPR in semi-supervised graph initializa-
tion. Also little improvements are seen when krs
information is added. This shows that domain
specific information like sense ranking scores and
keyword ranking scores play a major role in do-
main specific WSD.
The difference between the results in unsu-
pervised and semi-supervised graph initializations
may be attributed to the additional information the
semi-supervised graph is having i.e. the sense dis-
tribution knowledge of non-domain specific words
(common words).
</bodyText>
<sectionHeader confidence="0.999249" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999404">
This paper proposes a method for domain specific
WSD. Our method is based on a graph-based al-
gorithm (Personalized Page Rank) which is mod-
ified to include information representing the do-
main (sense ranking and key word ranking scores).
Experiments show that exploiting this domain spe-
cific information within the graph based methods
produces better results than when this information
is used individually.
</bodyText>
<page confidence="0.996505">
390
</page>
<sectionHeader confidence="0.996527" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99989575">
The authors are grateful to Ted Pedersen for his
helpful advice on the WordNet Similarity Pack-
age. We also thank Rajeev Sangal for supporting
the authors Siva Reddy and Abhilash Inumella.
</bodyText>
<sectionHeader confidence="0.998033" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.977722103448276">
Eneko Agirre and Aitor Soroa. 2009. Personaliz-
ing pagerank for word sense disambiguation. In
EACL ’09: Proceedings of the 12th Conference of
the European Chapter of the Association for Compu-
tational Linguistics, pages 33–41, Morristown, NJ,
USA. Association for Computational Linguistics.
Paul Buitelaar, Bernardo Magnini, Carlo Strapparava,
and Piek Vossen. 2006. Domain-specific wsd. In
Word Sense Disambiguation. Algorithms and Appli-
cations, Editors: Eneko Agirre and Philip Edmonds.
Springer.
Scott Cotton, Phil Edmonds, Adam Kilgarriff, and
Martha Palmer. 2001. Senseval-2. http://www.
sle.sharp.co.uk/senseval2.
A. Ferraresi, E. Zanchetta, M. Baroni, and S. Bernar-
dini. 2008. Introducing and evaluating ukwac,
a very large web-derived corpus of english. In
Proceed-ings of the WAC4 Workshop at LREC 2008,
Marrakesh, Morocco.
Adam Kilgarriff, Siva Reddy, Jan Pomik´alek, and Avi-
nesh PVS. 2010. A corpus factory for many lan-
guages. In LREC 2010, Malta.
Dan Klein and Christopher D. Manning. 2003. Accu-
rate unlexicalized parsing. In ACL ’03: Proceedings
of the 41st Annual Meeting on Association for Com-
putational Linguistics, pages 423–430, Morristown,
NJ, USA. Association for Computational Linguis-
tics.
Rob Koeling, Diana McCarthy, and John Carroll.
2005. Domain-specific sense distributions and pre-
dominant sense acquisition. In HLT ’05: Proceed-
ings of the conference on Human Language Tech-
nology and Empirical Methods in Natural Language
Processing, pages 419–426, Morristown, NJ, USA.
Association for Computational Linguistics.
Dekang Lin. 1998. Automatic retrieval and cluster-
ing of similar words. In Proceedings of the 17th
international conference on Computational linguis-
tics, pages 768–774, Morristown, NJ, USA. Associ-
ation for Computational Linguistics.
Diana McCarthy, Rob Koeling, Julie Weeds, and John
Carroll. 2004. Finding predominant word senses in
untagged text. In ACL ’04: Proceedings of the 42nd
Annual Meeting on Association for Computational
Linguistics, page 279, Morristown, NJ, USA. Asso-
ciation for Computational Linguistics.
Diana McCarthy, Rob Koeling, Julie Weeds, and John
Carroll. 2007. Unsupervised acquisition of pre-
dominant word senses. Computational Linguistics,
33(4):553–590.
Rada Mihalcea and Phil Edmonds, editors. 2004.
Proceedings Senseval-3 3rd International Workshop
on Evaluating Word Sense Disambiguation Systems.
ACL, Barcelona, Spain.
George A. Miller, Claudia Leacock, Randee Tengi, and
Ross T. Bunker. 1993. A semantic concordance. In
Proceedings of the ARPA Workshop on Human Lan-
guage Technology, pages 303–308. Morgan Kauf-
man.
Lawrence Page, Sergey Brin, Rajeev Motwani, and
Terry Winograd. 1999. The pagerank citation rank-
ing: Bringing order to the web. Technical Report
1999-66, Stanford InfoLab, November.
Ted Pedersen, Siddharth Patwardhan, and Jason Miche-
lizzi. 2004. Wordnet::similarity: measuring the re-
latedness of concepts. In HLT-NAACL ’04: Demon-
stration Papers at HLT-NAACL 2004 on XX, pages
38–41, Morristown, NJ, USA. Association for Com-
putational Linguistics.
Paul Rayson and Roger Garside. 2000. Comparing
corpora using frequency profiling. In Proceedings
of the workshop on Comparing corpora, pages 1–
6, Morristown, NJ, USA. Association for Computa-
tional Linguistics.
Ravi Sinha and Rada Mihalcea. 2007. Unsupervised
graph-basedword sense disambiguation using mea-
sures of word semantic similarity. In ICSC ’07: Pro-
ceedings of the International Conference on Seman-
tic Computing, pages 363–369, Washington, DC,
USA. IEEE Computer Society.
Appendix
Domain Specific Thesaurus, Sense Ranking
Scores and Keyword Ranking Scores are accessi-
ble at
http://web.iiit.ac.in/˜gvsreddy/
SemEval2010/
Tools Used:
</reference>
<listItem confidence="0.961059">
• UKB is used with options –ppr –dict weight. Dictio-
nary files which UKB uses are automatically generated
using sense ranking scores srs.
• Background document words are canonicalized using
KSTEM, a morphological analyzer
• The Stanford Parser is used to parse background docu-
ments to build thesaurus
• Test data is part of speech tagged using TreeTagger.
</listItem>
<page confidence="0.997505">
391
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.114403">
<title confidence="0.998965">IIITH: Domain Specific Word Sense Disambiguation</title>
<author confidence="0.997451">Siva Reddy</author>
<affiliation confidence="0.967569">IIIT Hyderabad</affiliation>
<address confidence="0.682957">India</address>
<email confidence="0.888109">gvsreddy@students.iiit.ac.in</email>
<author confidence="0.999614">Diana McCarthy</author>
<affiliation confidence="0.999908">Lexical Computing Ltd.</affiliation>
<address confidence="0.939681">United Kingdom</address>
<email confidence="0.994525">diana@dianamccarthy.co.uk</email>
<author confidence="0.751615">Abhilash Inumella</author>
<affiliation confidence="0.869329">IIIT Hyderabad</affiliation>
<address confidence="0.712443">India</address>
<email confidence="0.893947">abhilashi@students.iiit.ac.in</email>
<author confidence="0.99998">Mark Stevenson</author>
<affiliation confidence="0.751794">University of Sheffield United Kingdom</affiliation>
<email confidence="0.9977">m.stevenson@dcs.shef.ac.uk</email>
<abstract confidence="0.992452052631579">We describe two systems that participated in SemEval-2010 task 17 (All-words Word Sense Disambiguation on a Specific Domain) and were ranked in the third and fourth positions in the formal evaluation. Domain adaptation techniques using the background documents released in the task were used to assign ranking scores to the words and their senses. The test data was disambiguated using the Personalized PageRank algorithm which was applied to a graph constructed from the whole of WordNet in which nodes are initialized with ranking scores of words and their senses. In the competition, our systems achieved comparable accuracy of 53.4 and 52.2, which outperforms the most frequent sense baseline (50.5).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Aitor Soroa</author>
</authors>
<title>Personalizing pagerank for word sense disambiguation.</title>
<date>2009</date>
<booktitle>In EACL ’09: Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>33--41</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2986" citStr="Agirre and Soroa, 2009" startWordPosition="461" endWordPosition="464">, our approach aims to use these sense distributions collected from domain specific corpora as a knowledge source and combine this with information from the context. Our approach focuses on the strong influence of domain for WSD (Buitelaar et al., 2006) and the benefits of focusing on words salient to the domain (Koeling et al., 2005). Words are assigned a ranking score based on its keyness (salience) in the given domain. We use these word scores as another knowledge source. Graph based methods have been shown to produce state-of-the-art performance for unsupervised word sense disambiguation (Agirre and Soroa, 2009; Sinha and Mihalcea, 2007). These approaches use well-known graph-based techniques to find and exploit the structural properties of the graph underlying a particular lexical knowledge base (LKB), such as WordNet. These graphbased algorithms are appealing because they take into account information drawn from the entire graph as well as from the given context, making them superior to other approaches that rely only on local information individually derived for each word. Our approach uses the Personalized PageRank algorithm (Agirre and Soroa, 2009) over a graph 387 Proceedings of the 5th Intern</context>
<context position="8164" citStr="Agirre and Soroa, 2009" startWordPosition="1295" endWordPosition="1298">pora, words(domain), we calculated the loglikelihood (LL) statistic as described in Rayson and Garside (2000). We then normalized LL to compute keyword ranking score krs(w) of word w words(domain) using E nj eNw E nj eNw ×krs(nj) 388 krs(w) = E LL(w) LL(wi) wi∈words(domain) The above score represents the keyness of the word in the given domain. Top ten keywords (in descending order of krs) in the corpora provided for this task are species, biodiversity, life, habitat, natura1, EU, forest, conservation, years, amp2. 4 Personalized PageRank Our approach uses the Personalized PageRank algorithm (Agirre and Soroa, 2009) with WordNet as the lexical knowledge base (LKB) to perform WSD. WordNet is converted to a graph by representing each synset as a node (synset node) and the relationships in WordNet (hypernymy, hyponymy etc.) as edges between synset nodes. The graph is initialized by adding a node (word node) for each context word of the target word (including itself) thus creating a context dependent graph (personalized graph). The popular PageRank (Page et al., 1999) algorithm is employed to analyze this personalized graph (thus the algorithm is referred as personalized PageRank algorithm) and the sense for</context>
<context position="11566" citStr="Agirre and Soroa, 2009" startWordPosition="1869" endWordPosition="1872">R: The initialization graph of KRS + PPR is further initialized by assigning concordance scores to the edges connecting words and their synsets. CS + SRS + PPR: Edges connecting words and their synsets are assigned weights equal to sum of the concordance scores and sense ranking scores i.e. cs + srs. The initialization of word nodes is same as in PPR. CS + KRS + SRS + PPR: Word nodes are initialized with krs and edges are assigned weights equal to cs + srs. PageRank was applied to all the above graphs to disambiguate a target word. 4.2 Experimental details of PageRank Tool: We used UKB tool3 (Agirre and Soroa, 2009) which provides an implementation of personalized PageRank. We modified it to incorporate our methods of graph initialization. The LKB used in our experiments is WordNet3.0 + Gloss which is provided in the tool. More details of the tools used can be found in the Appendix. Normalizations: Sense ranking scores (srs) and keyword ranking scores (krs) have diverse ranges. We found srs generally in the range between 0 to 3http://ixa2.si.ehu.es/ukb/ 389 Precision Recall Unsupervised Graph Initialization PPR 37.3 36.8 KRS + PPR 38.1 37.6 SRS + PPR 48.4 47.8 KRS + SRS + PPR 48.0 47.4 Semi-supervised Gr</context>
</contexts>
<marker>Agirre, Soroa, 2009</marker>
<rawString>Eneko Agirre and Aitor Soroa. 2009. Personalizing pagerank for word sense disambiguation. In EACL ’09: Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, pages 33–41, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Buitelaar</author>
<author>Bernardo Magnini</author>
<author>Carlo Strapparava</author>
<author>Piek Vossen</author>
</authors>
<title>Domain-specific wsd. In Word Sense Disambiguation. Algorithms and Applications, Editors: Eneko Agirre and Philip Edmonds.</title>
<date>2006</date>
<publisher>Springer.</publisher>
<contexts>
<context position="2617" citStr="Buitelaar et al., 2006" startWordPosition="401" endWordPosition="404">beside a body of river” sense. Unfortunately, it is not feasible to produce large manually senseannotated corpora for every domain of interest. McCarthy et al. (2004) propose a method to predict sense distributions from raw corpora and use this as a first sense heuristic for tagging text with the predominant sense. Rather than assigning predominant sense in every case, our approach aims to use these sense distributions collected from domain specific corpora as a knowledge source and combine this with information from the context. Our approach focuses on the strong influence of domain for WSD (Buitelaar et al., 2006) and the benefits of focusing on words salient to the domain (Koeling et al., 2005). Words are assigned a ranking score based on its keyness (salience) in the given domain. We use these word scores as another knowledge source. Graph based methods have been shown to produce state-of-the-art performance for unsupervised word sense disambiguation (Agirre and Soroa, 2009; Sinha and Mihalcea, 2007). These approaches use well-known graph-based techniques to find and exploit the structural properties of the graph underlying a particular lexical knowledge base (LKB), such as WordNet. These graphbased </context>
</contexts>
<marker>Buitelaar, Magnini, Strapparava, Vossen, 2006</marker>
<rawString>Paul Buitelaar, Bernardo Magnini, Carlo Strapparava, and Piek Vossen. 2006. Domain-specific wsd. In Word Sense Disambiguation. Algorithms and Applications, Editors: Eneko Agirre and Philip Edmonds. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Cotton</author>
<author>Phil Edmonds</author>
<author>Adam Kilgarriff</author>
<author>Martha Palmer</author>
</authors>
<date>2001</date>
<note>Senseval-2. http://www. sle.sharp.co.uk/senseval2.</note>
<contexts>
<context position="1363" citStr="Cotton et al., 2001" startWordPosition="196" endWordPosition="199">nalized PageRank algorithm which was applied to a graph constructed from the whole of WordNet in which nodes are initialized with ranking scores of words and their senses. In the competition, our systems achieved comparable accuracy of 53.4 and 52.2, which outperforms the most frequent sense baseline (50.5). 1 Introduction The senses in WordNet are ordered according to their frequency in a manually tagged corpus, SemCor (Miller et al., 1993). Senses that do not occur in SemCor are ordered arbitrarily after those senses of the word that have occurred. It is known from the results of SENSEVAL2 (Cotton et al., 2001) and SENSEVAL3 (Mihalcea and Edmonds, 2004) that first sense heuristic outperforms many WSD systems (see McCarthy et al. (2007)). The first sense baseline’s strong performance is due to the skewed frequency distribution of word senses. WordNet sense distributions based on SemCor are clearly useful, however in a given domain these distributions may not hold true. For example, the first sense for “bank” in WordNet refers to “sloping land beside a body of river” and the second to “financial institution”, but in the domain of “finance” the “financial institution” sense would be expected to be more</context>
</contexts>
<marker>Cotton, Edmonds, Kilgarriff, Palmer, 2001</marker>
<rawString>Scott Cotton, Phil Edmonds, Adam Kilgarriff, and Martha Palmer. 2001. Senseval-2. http://www. sle.sharp.co.uk/senseval2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ferraresi</author>
<author>E Zanchetta</author>
<author>M Baroni</author>
<author>S Bernardini</author>
</authors>
<title>Introducing and evaluating ukwac, a very large web-derived corpus of english.</title>
<date>2008</date>
<booktitle>In Proceed-ings of the WAC4 Workshop at LREC</booktitle>
<location>Marrakesh, Morocco.</location>
<contexts>
<context position="7429" citStr="Ferraresi et al., 2008" startWordPosition="1177" endWordPosition="1180">rs(nj) is the keyword ranking score of the neighbour nj in the domain specific corpus. In the next section we describe the way in which we compute krs(nj). WordNet::Similarity::lesk (Pedersen et al., 2004) was used to compute word similarity wnss. IIITH1 and IIITH2 systems differ in the way senses are ranked. IIITH1 uses srs(wsj) whereas IIITH2 system uses msrs(wsj) for computing sense ranking scores in the given domain. 3 Domain Keyword Ranking We extracted keywords in the domain by comparing the frequency lists of domain corpora (background documents) and a very large general corpus, ukWaC (Ferraresi et al., 2008), using the method described by Rayson and Garside (2000). For each word in the frequency list of the domain corpora, words(domain), we calculated the loglikelihood (LL) statistic as described in Rayson and Garside (2000). We then normalized LL to compute keyword ranking score krs(w) of word w words(domain) using E nj eNw E nj eNw ×krs(nj) 388 krs(w) = E LL(w) LL(wi) wi∈words(domain) The above score represents the keyness of the word in the given domain. Top ten keywords (in descending order of krs) in the corpora provided for this task are species, biodiversity, life, habitat, natura1, EU, fo</context>
</contexts>
<marker>Ferraresi, Zanchetta, Baroni, Bernardini, 2008</marker>
<rawString>A. Ferraresi, E. Zanchetta, M. Baroni, and S. Bernardini. 2008. Introducing and evaluating ukwac, a very large web-derived corpus of english. In Proceed-ings of the WAC4 Workshop at LREC 2008, Marrakesh, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
<author>Siva Reddy</author>
<author>Jan Pomik´alek</author>
<author>Avinesh PVS</author>
</authors>
<title>A corpus factory for many languages. In LREC</title>
<date>2010</date>
<marker>Kilgarriff, Reddy, Pomik´alek, PVS, 2010</marker>
<rawString>Adam Kilgarriff, Siva Reddy, Jan Pomik´alek, and Avinesh PVS. 2010. A corpus factory for many languages. In LREC 2010, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In ACL ’03: Proceedings of the 41st Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>423--430</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="6314" citStr="Klein and Manning, 2003" startWordPosition="993" endWordPosition="996">(wsi, nj) dss(w, nj) × E wnss(wsi, nj) wsiesenses(w) where wnss(wsi, nj) (_ maxnsx ∈senses(nj) (wnss (wsi, nsx)) Since this approach requires only raw text, sense rankings for a particular domain can be generated by simply training the algorithm using a corpus representing that domain. We used the background documents provided to the participants in this task as a domain specific corpus. In general, a domain specific corpus can be obtained using domain-specific keywords (Kilgarriff et al., 2010). A thesaurus is acquired from automatically parsed background documents using the Stanford Parser (Klein and Manning, 2003). We used k = 5 to built the thesaurus. As we increased k we found the number of non-domain specific words occurring in the thesaurus increased and negatively affected the sense distributions. To counter this, one of our systems IIITH2 used a slightly modified ranking score by multiplying the effect of each neighbour with its domain keyword ranking score. The modified sense ranking msrs(wsj) score of sense wsi is msrs(wsi) = wnss(wsi, nj) dss(w, nj)× E wnss(wsi, nj) wsiesenses(w) where krs(nj) is the keyword ranking score of the neighbour nj in the domain specific corpus. In the next section w</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In ACL ’03: Proceedings of the 41st Annual Meeting on Association for Computational Linguistics, pages 423–430, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rob Koeling</author>
<author>Diana McCarthy</author>
<author>John Carroll</author>
</authors>
<title>Domain-specific sense distributions and predominant sense acquisition.</title>
<date>2005</date>
<booktitle>In HLT ’05: Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>419--426</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2700" citStr="Koeling et al., 2005" startWordPosition="417" endWordPosition="420">ually senseannotated corpora for every domain of interest. McCarthy et al. (2004) propose a method to predict sense distributions from raw corpora and use this as a first sense heuristic for tagging text with the predominant sense. Rather than assigning predominant sense in every case, our approach aims to use these sense distributions collected from domain specific corpora as a knowledge source and combine this with information from the context. Our approach focuses on the strong influence of domain for WSD (Buitelaar et al., 2006) and the benefits of focusing on words salient to the domain (Koeling et al., 2005). Words are assigned a ranking score based on its keyness (salience) in the given domain. We use these word scores as another knowledge source. Graph based methods have been shown to produce state-of-the-art performance for unsupervised word sense disambiguation (Agirre and Soroa, 2009; Sinha and Mihalcea, 2007). These approaches use well-known graph-based techniques to find and exploit the structural properties of the graph underlying a particular lexical knowledge base (LKB), such as WordNet. These graphbased algorithms are appealing because they take into account information drawn from the </context>
</contexts>
<marker>Koeling, McCarthy, Carroll, 2005</marker>
<rawString>Rob Koeling, Diana McCarthy, and John Carroll. 2005. Domain-specific sense distributions and predominant sense acquisition. In HLT ’05: Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 419–426, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th international conference on Computational linguistics,</booktitle>
<pages>768--774</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="4489" citStr="Lin (1998)" startWordPosition="693" endWordPosition="694">m the knowledge sources, like sense distribution scores and keyword ranking scores, into the graph thus personalizing the graph for the given domain. In section 2, we describe domain sense ranking. Domain keyword ranking is described in Section 3. Graph construction and personalized page rank are described in Section 4. Evaluation results over the SemEval data are provided in Section 5. 2 Domain Sense Ranking McCarthy et al. (2004) propose a method for finding predominant senses from raw text. The method uses a thesaurus acquired from automatically parsed text based on the method described by Lin (1998). This provides the top k nearest neighbours for each target word w, along with the distributional similarity score between the target word and each neighbour. The senses of a word w are each assigned a score by summing over the distributional similarity scores of its neighbours. These are weighted by a semantic similarity score (using WordNet Similarity score (Pedersen et al., 2004) between the sense of w and the sense of the neighbour that maximizes the semantic similarity score. More formally, let N,,, = {n1, n2,... nk} be the ordered set of the top k scoring neighbours of w from the thesau</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retrieval and clustering of similar words. In Proceedings of the 17th international conference on Computational linguistics, pages 768–774, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Rob Koeling</author>
<author>Julie Weeds</author>
<author>John Carroll</author>
</authors>
<title>Finding predominant word senses in untagged text.</title>
<date>2004</date>
<booktitle>In ACL ’04: Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>279</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2160" citStr="McCarthy et al. (2004)" startWordPosition="325" endWordPosition="328"> is due to the skewed frequency distribution of word senses. WordNet sense distributions based on SemCor are clearly useful, however in a given domain these distributions may not hold true. For example, the first sense for “bank” in WordNet refers to “sloping land beside a body of river” and the second to “financial institution”, but in the domain of “finance” the “financial institution” sense would be expected to be more likely than the “sloping land beside a body of river” sense. Unfortunately, it is not feasible to produce large manually senseannotated corpora for every domain of interest. McCarthy et al. (2004) propose a method to predict sense distributions from raw corpora and use this as a first sense heuristic for tagging text with the predominant sense. Rather than assigning predominant sense in every case, our approach aims to use these sense distributions collected from domain specific corpora as a knowledge source and combine this with information from the context. Our approach focuses on the strong influence of domain for WSD (Buitelaar et al., 2006) and the benefits of focusing on words salient to the domain (Koeling et al., 2005). Words are assigned a ranking score based on its keyness (s</context>
<context position="4314" citStr="McCarthy et al. (2004)" startWordPosition="662" endWordPosition="665"> Association for Computational Linguistics representing WordNet to disambiguate ambiguous words by taking their context into consideration. We also combine domain-specific information from the knowledge sources, like sense distribution scores and keyword ranking scores, into the graph thus personalizing the graph for the given domain. In section 2, we describe domain sense ranking. Domain keyword ranking is described in Section 3. Graph construction and personalized page rank are described in Section 4. Evaluation results over the SemEval data are provided in Section 5. 2 Domain Sense Ranking McCarthy et al. (2004) propose a method for finding predominant senses from raw text. The method uses a thesaurus acquired from automatically parsed text based on the method described by Lin (1998). This provides the top k nearest neighbours for each target word w, along with the distributional similarity score between the target word and each neighbour. The senses of a word w are each assigned a score by summing over the distributional similarity scores of its neighbours. These are weighted by a semantic similarity score (using WordNet Similarity score (Pedersen et al., 2004) between the sense of w and the sense o</context>
<context position="13545" citStr="McCarthy et al., 2004" startWordPosition="2209" endWordPosition="2212">s described in Section 2, IIITH1 and IIITH2 systems differ in the way the sense ranking scores are computed. Here we project only the results of IIITH1 since IIITH1 performed slightly better than IIITH2 in all the above settings. Results of 1stsense system provided by the organizers which assigns first sense computed from the annotations in hand-labeled corpora is also presented. Additionally, we also present the results of Predominant Sense Heuristic (PSH) which assigns every word w with the sense wsj (wsj ∈ senses(w)) which has the highest value of srs(wsj) computed in Section 2 similar to (McCarthy et al., 2004). Table 1 presents the evaluation results. We used TreeTagger 4 to Part of Speech tag the test data. POS information was used to discard irrelevant senses. Due to POS tagging errors, our precision values were not equal to recall values. In the competition, we submitted IIITH1 and IIITH2 systems with CS + SRS + PPR graph initialization. IIITH1 4http://www.ims.uni-stuttgart.de/ projekte/corplex/TreeTagger/ and IIIH2 gave performances of 53.4 % and 52.2 % precision respectively. In our later experiments, we found CS + KRS + SRS + PPR has given the best performance of 53.6 % precision. From the re</context>
</contexts>
<marker>McCarthy, Koeling, Weeds, Carroll, 2004</marker>
<rawString>Diana McCarthy, Rob Koeling, Julie Weeds, and John Carroll. 2004. Finding predominant word senses in untagged text. In ACL ’04: Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, page 279, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Rob Koeling</author>
<author>Julie Weeds</author>
<author>John Carroll</author>
</authors>
<title>Unsupervised acquisition of predominant word senses.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>4</issue>
<contexts>
<context position="1490" citStr="McCarthy et al. (2007)" startWordPosition="215" endWordPosition="218">with ranking scores of words and their senses. In the competition, our systems achieved comparable accuracy of 53.4 and 52.2, which outperforms the most frequent sense baseline (50.5). 1 Introduction The senses in WordNet are ordered according to their frequency in a manually tagged corpus, SemCor (Miller et al., 1993). Senses that do not occur in SemCor are ordered arbitrarily after those senses of the word that have occurred. It is known from the results of SENSEVAL2 (Cotton et al., 2001) and SENSEVAL3 (Mihalcea and Edmonds, 2004) that first sense heuristic outperforms many WSD systems (see McCarthy et al. (2007)). The first sense baseline’s strong performance is due to the skewed frequency distribution of word senses. WordNet sense distributions based on SemCor are clearly useful, however in a given domain these distributions may not hold true. For example, the first sense for “bank” in WordNet refers to “sloping land beside a body of river” and the second to “financial institution”, but in the domain of “finance” the “financial institution” sense would be expected to be more likely than the “sloping land beside a body of river” sense. Unfortunately, it is not feasible to produce large manually sense</context>
</contexts>
<marker>McCarthy, Koeling, Weeds, Carroll, 2007</marker>
<rawString>Diana McCarthy, Rob Koeling, Julie Weeds, and John Carroll. 2007. Unsupervised acquisition of predominant word senses. Computational Linguistics, 33(4):553–590.</rawString>
</citation>
<citation valid="true">
<date>2004</date>
<booktitle>Proceedings Senseval-3 3rd International Workshop on Evaluating Word Sense Disambiguation Systems. ACL,</booktitle>
<editor>Rada Mihalcea and Phil Edmonds, editors.</editor>
<location>Barcelona, Spain.</location>
<contexts>
<context position="2160" citStr="(2004)" startWordPosition="328" endWordPosition="328">kewed frequency distribution of word senses. WordNet sense distributions based on SemCor are clearly useful, however in a given domain these distributions may not hold true. For example, the first sense for “bank” in WordNet refers to “sloping land beside a body of river” and the second to “financial institution”, but in the domain of “finance” the “financial institution” sense would be expected to be more likely than the “sloping land beside a body of river” sense. Unfortunately, it is not feasible to produce large manually senseannotated corpora for every domain of interest. McCarthy et al. (2004) propose a method to predict sense distributions from raw corpora and use this as a first sense heuristic for tagging text with the predominant sense. Rather than assigning predominant sense in every case, our approach aims to use these sense distributions collected from domain specific corpora as a knowledge source and combine this with information from the context. Our approach focuses on the strong influence of domain for WSD (Buitelaar et al., 2006) and the benefits of focusing on words salient to the domain (Koeling et al., 2005). Words are assigned a ranking score based on its keyness (s</context>
<context position="4314" citStr="(2004)" startWordPosition="665" endWordPosition="665"> Computational Linguistics representing WordNet to disambiguate ambiguous words by taking their context into consideration. We also combine domain-specific information from the knowledge sources, like sense distribution scores and keyword ranking scores, into the graph thus personalizing the graph for the given domain. In section 2, we describe domain sense ranking. Domain keyword ranking is described in Section 3. Graph construction and personalized page rank are described in Section 4. Evaluation results over the SemEval data are provided in Section 5. 2 Domain Sense Ranking McCarthy et al. (2004) propose a method for finding predominant senses from raw text. The method uses a thesaurus acquired from automatically parsed text based on the method described by Lin (1998). This provides the top k nearest neighbours for each target word w, along with the distributional similarity score between the target word and each neighbour. The senses of a word w are each assigned a score by summing over the distributional similarity scores of its neighbours. These are weighted by a semantic similarity score (using WordNet Similarity score (Pedersen et al., 2004) between the sense of w and the sense o</context>
</contexts>
<marker>2004</marker>
<rawString>Rada Mihalcea and Phil Edmonds, editors. 2004. Proceedings Senseval-3 3rd International Workshop on Evaluating Word Sense Disambiguation Systems. ACL, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Claudia Leacock</author>
<author>Randee Tengi</author>
<author>Ross T Bunker</author>
</authors>
<title>A semantic concordance.</title>
<date>1993</date>
<booktitle>In Proceedings of the ARPA Workshop on Human Language Technology,</booktitle>
<pages>303--308</pages>
<publisher>Morgan Kaufman.</publisher>
<contexts>
<context position="1188" citStr="Miller et al., 1993" startWordPosition="164" endWordPosition="167">echniques using the background documents released in the task were used to assign ranking scores to the words and their senses. The test data was disambiguated using the Personalized PageRank algorithm which was applied to a graph constructed from the whole of WordNet in which nodes are initialized with ranking scores of words and their senses. In the competition, our systems achieved comparable accuracy of 53.4 and 52.2, which outperforms the most frequent sense baseline (50.5). 1 Introduction The senses in WordNet are ordered according to their frequency in a manually tagged corpus, SemCor (Miller et al., 1993). Senses that do not occur in SemCor are ordered arbitrarily after those senses of the word that have occurred. It is known from the results of SENSEVAL2 (Cotton et al., 2001) and SENSEVAL3 (Mihalcea and Edmonds, 2004) that first sense heuristic outperforms many WSD systems (see McCarthy et al. (2007)). The first sense baseline’s strong performance is due to the skewed frequency distribution of word senses. WordNet sense distributions based on SemCor are clearly useful, however in a given domain these distributions may not hold true. For example, the first sense for “bank” in WordNet refers to</context>
</contexts>
<marker>Miller, Leacock, Tengi, Bunker, 1993</marker>
<rawString>George A. Miller, Claudia Leacock, Randee Tengi, and Ross T. Bunker. 1993. A semantic concordance. In Proceedings of the ARPA Workshop on Human Language Technology, pages 303–308. Morgan Kaufman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Page</author>
<author>Sergey Brin</author>
<author>Rajeev Motwani</author>
<author>Terry Winograd</author>
</authors>
<title>The pagerank citation ranking: Bringing order to the web.</title>
<date>1999</date>
<tech>Technical Report 1999-66,</tech>
<institution>Stanford InfoLab,</institution>
<contexts>
<context position="8621" citStr="Page et al., 1999" startWordPosition="1371" endWordPosition="1374">, habitat, natura1, EU, forest, conservation, years, amp2. 4 Personalized PageRank Our approach uses the Personalized PageRank algorithm (Agirre and Soroa, 2009) with WordNet as the lexical knowledge base (LKB) to perform WSD. WordNet is converted to a graph by representing each synset as a node (synset node) and the relationships in WordNet (hypernymy, hyponymy etc.) as edges between synset nodes. The graph is initialized by adding a node (word node) for each context word of the target word (including itself) thus creating a context dependent graph (personalized graph). The popular PageRank (Page et al., 1999) algorithm is employed to analyze this personalized graph (thus the algorithm is referred as personalized PageRank algorithm) and the sense for each disambiguous word is chosen by choosing the synset node which gets the highest weight after a certain number of iterations of PageRank algorithm. We capture domain information in the personalized graph by using sense ranking scores and keyword ranking scores of the domain to assign initial weights to the word nodes and their edges (wordsynset edge). This way we personalize the graph for the given domain. 4.1 Graph Initialization Methods We experim</context>
</contexts>
<marker>Page, Brin, Motwani, Winograd, 1999</marker>
<rawString>Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1999. The pagerank citation ranking: Bringing order to the web. Technical Report 1999-66, Stanford InfoLab, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Siddharth Patwardhan</author>
<author>Jason Michelizzi</author>
</authors>
<title>Wordnet::similarity: measuring the relatedness of concepts.</title>
<date>2004</date>
<booktitle>In HLT-NAACL ’04: Demonstration Papers at HLT-NAACL 2004 on XX,</booktitle>
<pages>38--41</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="4875" citStr="Pedersen et al., 2004" startWordPosition="753" endWordPosition="756">d in Section 5. 2 Domain Sense Ranking McCarthy et al. (2004) propose a method for finding predominant senses from raw text. The method uses a thesaurus acquired from automatically parsed text based on the method described by Lin (1998). This provides the top k nearest neighbours for each target word w, along with the distributional similarity score between the target word and each neighbour. The senses of a word w are each assigned a score by summing over the distributional similarity scores of its neighbours. These are weighted by a semantic similarity score (using WordNet Similarity score (Pedersen et al., 2004) between the sense of w and the sense of the neighbour that maximizes the semantic similarity score. More formally, let N,,, = {n1, n2,... nk} be the ordered set of the top k scoring neighbours of w from the thesaurus with associated distributional similarity scores {dss(w, n1), dss(w, n2),... dss(w, nk)}. Let senses(w) be the set of senses of w. For each sense of w (wsi E senses(w)) a ranking score is obtained by summing over the dss(w, nj) of each neighbour (nj E N,,,) multiplied by a weight. This weight is the WordNet similarity score (wnss) between the target sense (wsi) and the sense of n</context>
<context position="7011" citStr="Pedersen et al., 2004" startWordPosition="1108" endWordPosition="1111">er of non-domain specific words occurring in the thesaurus increased and negatively affected the sense distributions. To counter this, one of our systems IIITH2 used a slightly modified ranking score by multiplying the effect of each neighbour with its domain keyword ranking score. The modified sense ranking msrs(wsj) score of sense wsi is msrs(wsi) = wnss(wsi, nj) dss(w, nj)× E wnss(wsi, nj) wsiesenses(w) where krs(nj) is the keyword ranking score of the neighbour nj in the domain specific corpus. In the next section we describe the way in which we compute krs(nj). WordNet::Similarity::lesk (Pedersen et al., 2004) was used to compute word similarity wnss. IIITH1 and IIITH2 systems differ in the way senses are ranked. IIITH1 uses srs(wsj) whereas IIITH2 system uses msrs(wsj) for computing sense ranking scores in the given domain. 3 Domain Keyword Ranking We extracted keywords in the domain by comparing the frequency lists of domain corpora (background documents) and a very large general corpus, ukWaC (Ferraresi et al., 2008), using the method described by Rayson and Garside (2000). For each word in the frequency list of the domain corpora, words(domain), we calculated the loglikelihood (LL) statistic as</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Ted Pedersen, Siddharth Patwardhan, and Jason Michelizzi. 2004. Wordnet::similarity: measuring the relatedness of concepts. In HLT-NAACL ’04: Demonstration Papers at HLT-NAACL 2004 on XX, pages 38–41, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Rayson</author>
<author>Roger Garside</author>
</authors>
<title>Comparing corpora using frequency profiling.</title>
<date>2000</date>
<booktitle>In Proceedings of the workshop on Comparing corpora,</booktitle>
<volume>1</volume>
<pages>pages</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="7486" citStr="Rayson and Garside (2000)" startWordPosition="1186" endWordPosition="1189"> in the domain specific corpus. In the next section we describe the way in which we compute krs(nj). WordNet::Similarity::lesk (Pedersen et al., 2004) was used to compute word similarity wnss. IIITH1 and IIITH2 systems differ in the way senses are ranked. IIITH1 uses srs(wsj) whereas IIITH2 system uses msrs(wsj) for computing sense ranking scores in the given domain. 3 Domain Keyword Ranking We extracted keywords in the domain by comparing the frequency lists of domain corpora (background documents) and a very large general corpus, ukWaC (Ferraresi et al., 2008), using the method described by Rayson and Garside (2000). For each word in the frequency list of the domain corpora, words(domain), we calculated the loglikelihood (LL) statistic as described in Rayson and Garside (2000). We then normalized LL to compute keyword ranking score krs(w) of word w words(domain) using E nj eNw E nj eNw ×krs(nj) 388 krs(w) = E LL(w) LL(wi) wi∈words(domain) The above score represents the keyness of the word in the given domain. Top ten keywords (in descending order of krs) in the corpora provided for this task are species, biodiversity, life, habitat, natura1, EU, forest, conservation, years, amp2. 4 Personalized PageRank </context>
</contexts>
<marker>Rayson, Garside, 2000</marker>
<rawString>Paul Rayson and Roger Garside. 2000. Comparing corpora using frequency profiling. In Proceedings of the workshop on Comparing corpora, pages 1– 6, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ravi Sinha</author>
<author>Rada Mihalcea</author>
</authors>
<title>Unsupervised graph-basedword sense disambiguation using measures of word semantic similarity.</title>
<date>2007</date>
<booktitle>In ICSC ’07: Proceedings of the International Conference on Semantic Computing,</booktitle>
<pages>363--369</pages>
<publisher>IEEE Computer Society.</publisher>
<location>Washington, DC, USA.</location>
<contexts>
<context position="3013" citStr="Sinha and Mihalcea, 2007" startWordPosition="465" endWordPosition="468">se these sense distributions collected from domain specific corpora as a knowledge source and combine this with information from the context. Our approach focuses on the strong influence of domain for WSD (Buitelaar et al., 2006) and the benefits of focusing on words salient to the domain (Koeling et al., 2005). Words are assigned a ranking score based on its keyness (salience) in the given domain. We use these word scores as another knowledge source. Graph based methods have been shown to produce state-of-the-art performance for unsupervised word sense disambiguation (Agirre and Soroa, 2009; Sinha and Mihalcea, 2007). These approaches use well-known graph-based techniques to find and exploit the structural properties of the graph underlying a particular lexical knowledge base (LKB), such as WordNet. These graphbased algorithms are appealing because they take into account information drawn from the entire graph as well as from the given context, making them superior to other approaches that rely only on local information individually derived for each word. Our approach uses the Personalized PageRank algorithm (Agirre and Soroa, 2009) over a graph 387 Proceedings of the 5th International Workshop on Semanti</context>
</contexts>
<marker>Sinha, Mihalcea, 2007</marker>
<rawString>Ravi Sinha and Rada Mihalcea. 2007. Unsupervised graph-basedword sense disambiguation using measures of word semantic similarity. In ICSC ’07: Proceedings of the International Conference on Semantic Computing, pages 363–369, Washington, DC, USA. IEEE Computer Society.</rawString>
</citation>
<citation valid="false">
<title>Appendix Domain Specific Thesaurus, Sense Ranking Scores and Keyword Ranking Scores are accessible at http://web.iiit.ac.in/˜gvsreddy/ SemEval2010/</title>
<marker></marker>
<rawString>Appendix Domain Specific Thesaurus, Sense Ranking Scores and Keyword Ranking Scores are accessible at http://web.iiit.ac.in/˜gvsreddy/ SemEval2010/</rawString>
</citation>
<citation valid="false">
<institution>Tools Used:</institution>
<marker></marker>
<rawString>Tools Used:</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>