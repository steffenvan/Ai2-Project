<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000073">
<title confidence="0.991064">
Construction of bilingual multimodal corpora of referring expressions in
collaborative problem solving
</title>
<author confidence="0.770058">
TOKUNAGA Takenobu IIDA Ryu YASUHARA Masaaki TERAI Asuka
</author>
<email confidence="0.843818">
{take,ryu-i,yasuhara}@cl.cs.titech.ac.jp asuka@nm.hum.titech.ac.jp
</email>
<affiliation confidence="0.751309">
Tokyo Institute of Technology
</affiliation>
<author confidence="0.650648">
David MORRIS Anja BELZ
</author>
<email confidence="0.792791">
D.Morris@brighton.ac.uk a.s.belz@itri.brighton.ac.uk
</email>
<affiliation confidence="0.946018">
University of Brighton
</affiliation>
<sectionHeader confidence="0.977308" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999965185185185">
This paper presents on-going work on
constructing bilingual multimodal corpora
of referring expressions in collaborative
problem solving for English and Japanese.
The corpora were collected from dia-
logues in which two participants collab-
oratively solved Tangram puzzles with
a puzzle simulator. Extra-linguistic in-
formation such as operations on puzzle
pieces, mouse cursor position and piece
positions were recorded in synchronisa-
tion with utterances. The speech data
was transcribed and time-aligned with the
extra-linguistic information. Referring
expressions in utterances that refer to puz-
zle pieces were annotated in terms of their
spans, their referents and their other at-
tributes. The Japanese corpus has already
been completed, but the English counter-
part is still undergoing annotation. We
have conducted a preliminary comparative
analysis of both corpora, mainly with re-
spect to task completion time, task suc-
cess rates and attributes of referring ex-
pressions. These corpora showed signif-
icant differences in task completion time
and success rate.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999891725">
A referring expression (RE) is a linguistic de-
vice that refers to a certain object of interest (e.g.
used in describing where the object is located in
space). REs have attracted a great deal of atten-
tion in both language analysis and language gen-
eration research. In language analysis research,
reference resolution, particularly anaphora resolu-
tion (Mitkov, 2002), has a long research history as
far back as the mid-1970s (Hobbs, 1978). Much
research has been conducted from both theoretical
and empirical perspectives, mainly concerning the
identification of antecedents or entities mentioned
within the same text. This trend, targeting refer-
ence resolution in written text, is still dominant in
the language analysis, perhaps because such tech-
niques are intended for use in applications such as
information extraction.
In contrast, in language generation research in-
terest has recently shifted from the generation of
one-off references to entities to generation of REs
in discourse context (Belz et al., 2010) and inves-
tigating human referential behaviour in real world
situations, with the aim of using such techniques
in applications like human-robot interaction (Pi-
wek, 2007; Foster et al., 2008; Bard et al., 2009).
In both analysis and generation, machine-
learning approaches have come to replace rule-
based approaches as the predominant research
trend since the 1990s. This trend has made anno-
tated corpora an indispensable component of re-
search for training and evaluating proposed meth-
ods. In fact, research on reference resolution has
developed significantly as a result of large scale
corpora, e.g. those provided by the Message Un-
derstanding Conference (MUC)1 and the Auto-
matic Content Extraction (ACE)2 project. These
corpora were constructed primarily for informa-
tion extraction research, thus were annotated with
co-reference relations within texts. Also in the
language generation community, several corpora
</bodyText>
<footnote confidence="0.8821705">
lhttp://www.nlpir.nist.gov/related projects/muc/
zhttp://www.itl.nist.gov/iad/tests/ace/
</footnote>
<page confidence="0.978618">
38
</page>
<note confidence="0.975021833333333">
Proceedings of the 8th Workshop on Asian Language Resources, pages 38–46,
Beijing, China, 21-22 August 2010. c�2010 Asian Federation for Natural Language Processing
have been developed (Di Eugenio et al., 2000; By-
ron, 2005; van Deemter et al., 2006; Foster and
Oberlander, 2007; Foster et al., 2008; Stoia et al.,
2008; Spanger et al., 2009a; Belz et al., 2010).
</note>
<bodyText confidence="0.996645065217392">
Unlike the corpora of MUC and ACE, many are
collected from situated dialogues, and therefore
include multimodal information (e.g. gestures and
eye-gaze) other than just transcribed text (Martin
et al., 2007). Foster and Oberlander (2007) em-
phasised that any corpus for language generation
should include all possible contextual information
at the appropriate granularity. Since constructing
a dialogue corpus generally requires experiments
for data collection, this kind of corpus tends to be
small-scale compared with corpora for reference
resolution.
Against this background, we have been de-
veloping multimodal corpora of referring expres-
sions in collaborative problem-solving settings.
This paper presents on-going work of construct-
ing bilingual (English and Japanese) comparable
corpora in this domain. We achieve our goal by
replicating, for the English corpus, the same pro-
cess of data collection and annotation as we used
for our existing Japanese corpus (Spanger et al.,
2009a). Our aim is to create bilingual multimodal
corpora collected from dialogues in dynamic situ-
ations. From the point of view of reference anal-
ysis, our corpora contribute to augmenting the re-
sources of multimodal dialogue corpora annotated
with reference relations which have been minor
in number compared to other types of text cor-
pora. From the point of view of reference gen-
eration, our corpora contribute to increasing the
resources available that can be used to further re-
search of this kind. In addition, our corpora con-
tribute to comparative studies of human referential
behaviour in different languages
The structure of the paper is as follows. Sec-
tion 2 describes the experimental set-up for data
collection which was introduced in our previous
work (Spanger et al., 2009a). The setting is basi-
cally the same for the construction of the English
corpus. Section 3 explains the annotation scheme
adopted in our corpora, followed by a description
of a preliminary analysis of the corpora in sec-
tion 4. Section 5 briefly mentions related work
to highlight the characteristics of our corpora. Fi-
nally, Section 6 concludes the paper and looks at
possible future directions.
</bodyText>
<figureCaption confidence="0.999011">
Figure 1: Screenshot of the Tangram simulator
</figureCaption>
<sectionHeader confidence="0.972258" genericHeader="method">
2 Data collection
</sectionHeader>
<subsectionHeader confidence="0.98094">
2.1 Experimental set-up
</subsectionHeader>
<bodyText confidence="0.999965966666667">
We recruited subjects in pairs of friends and col-
leagues. Each pair was instructed to solve Tan-
gram puzzles collaboratively. Tangram puzzles
are geometrical puzzles that originated in ancient
China. The goal of a Tangram puzzle is to con-
struct a given goal shape by arranging seven sim-
ple shapes, as shown in Figure 1. The pieces in-
clude two large triangles, a medium-sized trian-
gle, two small triangles, a parallelogram and a
square.
With the aim of recording the precise position
of every piece and every action the participants
made during the solving process, we implemented
a Tangram simulator in which the pieces can be
moved, rotated and flipped with simple mouse op-
erations on a computer display. The simulator dis-
plays two areas: a goal shape area and a work-
ing area where the pieces can be manupulated and
their movements are shown in real time.
We assigned a different role to each participant
of a pair: one acted as the solver and the other as
the operator. The operator has a mouse for manip-
ulating Tangram pieces, but does not have a goal
shape on the screen. The solver has a goal shape
on the screen but does not have a mouse. This set-
ting naturally leads to a situation where given a
certain goal shape, the solver thinks of the neces-
sary arrangement of the pieces and gives instruc-
tions to the operator how to move them, while the
operator manipulates the pieces with the mouse
</bodyText>
<figure confidence="0.5084345">
goal shape
working area
</figure>
<page confidence="0.945963">
39
</page>
<note confidence="0.301662">
according to the solver’s instructions.
</note>
<figureCaption confidence="0.999323">
Figure 2: Picture of the experiment setting
</figureCaption>
<bodyText confidence="0.999809368421052">
As we mentioned in our previous
study (Spanger et al., 2009a), this interaction
produces frequent use of referring expressions
intended to distinguish specific pieces of the
puzzle. In our Tangram simulator, all pieces
are of the same color, thus color is not useful
in identifying a specific piece, i.e. only size
and shape are discriminative object-intrinsic
attributes. Instead, we can expect other attributes
such as spatial relations and deictic reference to
be used more often.
Each pair of participants sat side by side as
shown in Figure 2. Each participant had his/her
own computer display showing the shared work-
ing area. A room-divider screen was set between
the solver (right side) and operator (left side) to
prevent the operator from seeing the goal shape on
the solver’s screen, and to restrict their interaction
to speech only.
</bodyText>
<figureCaption confidence="0.997931">
Figure 3: The goal shapes given to the subjects
</figureCaption>
<bodyText confidence="0.999971377777778">
Each participant pair was assigned 4 trials con-
sisting of two symmetric and two asymmetric
goal shapes as shown in Figure 3. In Cogni-
tive Science, a wide variety of different kinds of
puzzles have been employed extensively in the
field of Insight Problem solving. This has been
termed the “puzzle-problem approach” (Sternberg
and Davidson, 1996; Suzuki et al., 2001) and
in the case of physical puzzles has relatively of-
ten involved puzzle tasks of symmetric shapes
like the so-called T-puzzle, e.g. (Kiyokawa and
Nakazawa, 2006). In more recent work Tangram
puzzles have been used as a means to study var-
ious new aspects of human problem solving ap-
proaches, including collection of of eye-gaze in-
formation (Baran et al., 2007). In order to col-
lect data as broadly as possible in this context, we
set up puzzle-problems including both symmetri-
cal as well as asymmetrical ones as shown in Fig-
ure 3.
The participants exchanged their roles after two
trials, i.e. a participant first solves a symmetric and
then an asymmetric puzzle as the solver and then
does the same as the operator, and vice versa. The
order of the puzzle trials is the same for all pairs.
Before starting the first trial as the operator,
each participant had a short training exercise in
order to learn how to manipulate pieces with the
mouse. The initial arrangement of the pieces was
randomised every time. We set a time limit of 15
minutes for the completion of each trial (i.e. con-
struction of the goal shape). In order to prevent the
solver from getting into deep thought and keeping
silent, the simulator is designed to give a hint ev-
ery five minutes by showing a correct piece posi-
tion in the goal shape area. After 10 minutes have
passed, a second hint is provided, while the pre-
vious hint disappears. A trial ends when the goal
shape is complete or the time is up. Utterances by
the participants are recorded separately in stereo
through headset microphones in synchronisation
with the position of the pieces and the mouse op-
erations. Piece positions and mouse actions were
automatically recorded by the simulator at inter-
vals of 10 msec.
</bodyText>
<figure confidence="0.9998345">
(a) Mountain
(c) Chair
(d) Tea bowl
(b) Swan
</figure>
<page confidence="0.986435">
40
</page>
<tableCaption confidence="0.99953">
Table 1: The ELAN Tiers of the corpus
</tableCaption>
<bodyText confidence="0.614865615384615">
Tier meaning
OP-UT utterances by the operator
SV-UT utterances by the solver
OP-REX referring expressions by the operator
OP-Ref referents of OP-REX
OP-Attr attributes of OP-REX
SV-REX referring expressions by the solver
SV-Ref referents of SV-REX
SV-Attr attributes of SV-REX
Action action on a piece
Target the target piece of Action
Mouse the piece on which the mouse is hovering
* Indentation of Tier denotes parent-child relations.
</bodyText>
<subsectionHeader confidence="0.998912">
2.2 Subjects and collected data
</subsectionHeader>
<bodyText confidence="0.99995047826087">
For our Japanese corpus, we recruited 12 Japanese
graduate students of the Cognitive Science depart-
ment, 4 females and 8 males, and split them into 6
pairs. All pairs knew each other previously and
were of the same sex and approximately same
age3. We collected 24 dialogues (4 trials by 6
pairs) of about 4 hours and 16 minutes. The av-
erage length of a dialogue was 10 minutes 40 sec-
onds (SD = 3 minutes 18 seconds).
For the comparable English corpus, we re-
cruited 12 native English speakers of various oc-
cupations, 6 males and 6 females. Their aver-
age age was 30. There were 6 pairs all of whom
knew each other beforehand except for one pair.
Whereas during the creation of the Japanese cor-
pus we had to give extra attention to ensuring that
social relationships did not have an impact on how
the subjects communicated with one another, for
the English corpus there was no such concern. We
collected 24 dialogues (4 trials by 6 pairs) of 5
hours and 7 minutes total length. The average
length of a dialogue was 12 minutes 47 seconds
(SD = 3 minutes 34 seconds).
</bodyText>
<sectionHeader confidence="0.991359" genericHeader="method">
3 Annotation
</sectionHeader>
<bodyText confidence="0.999638666666667">
The recorded speech data was transcribed and
the referring expressions were annotated with
the Web-based multi-purpose annotation tool
</bodyText>
<footnote confidence="0.9207972">
3In Japan, the relationship of senior to junior or socially
higher to lower placed might affect the language use. We
carefully recruited pairs to avoid the effects of this social re-
lationship such as the possible use of overly polite and indi-
rect language, reluctance to correct mistakes etc.
</footnote>
<tableCaption confidence="0.979595">
Table 2: Attributes of referring expressions
</tableCaption>
<bodyText confidence="0.866864789473684">
dpr : demonstrative pronoun, e.g. “the same one”,
“this”, “that”, “it”
dad : demonstrative adjective, e.g. “that triangle”
siz : size, e.g. “the large triangle”
typ : type, e.g. “the square”
dir : direction of a piece, e.g. “the triangle facing the
left”.
prj : projective spatial relation (including directional
prepositions or nouns such as “right”, “left”,
“above”...) e.g. “the triangle to the left of the
square”
tpl : topological spatial relation (including non-
directional prepositions or nouns such as “near”,
“middle”...), e.g. “the triangle near the square”
ovl : overlap, e.g. “the small triangle under the large
one”
act : action on pieces, e.g “the triangle that you are
holding now”, “the triangle that you just rotated”
cmp : complement, e.g. “the other one”
</bodyText>
<equation confidence="0.829828666666667">
sim : similarity, e.g. “the same one”
num : number, e.g. “the two triangle”
rpr : repair, e.g. “the big, no, small triangle”
</equation>
<bodyText confidence="0.987523222222222">
err : obvious erroneous expression, e.g. “the square”
referring to a triangle
nest : nested expression; when a referring expression
includes another referring expression, only the
outermost expression is annotated with this at-
tribute, e.g. “(the triangle to the left of (the small
triangle))”
meta: metaphorical expression, e.g. “the leg”, “the
head”
SLAT (Noguchi et al., 2008)4. Our target expres-
sions in this corpus are referring expressions re-
ferring to a puzzle piece or a set of puzzle pieces.
We do not deal with expressions referring to a lo-
cation, a part of a piece or a constructed shape.
These expressions are put aside for future work.
The annotation of referring expressions is three-
fold: (1) identification of the span of expressions,
(2) identification of their referents, and (3) assign-
ment of a set of attributes to each referring expres-
sion.
Using the multimodal annotation tool ELAN,5
the annotations of referring expressions were then
merged with extra-linguistic data recorded by the
Tangram simulator. The available extra-linguistic
information from the simulator consists of (1) the
action on a piece, (2) the coordinates of the mouse
cursor and (3) the position of each piece in the
</bodyText>
<footnote confidence="0.991379">
4We did not use SLAT for English corpus annotation. In-
stead, ELAN was directly used for annotating referring ex-
pressions.
5http://www.lat-mpi.eu/tools/elan/
</footnote>
<page confidence="0.999251">
41
</page>
<tableCaption confidence="0.998462">
Table 3: Summary of trials
</tableCaption>
<table confidence="0.999900678571429">
ID time success OP-REX SV-REX ID time success OP-REX SV-REX
E01 15:00 J01 8:40 o 10 48
E02 15:00 J02 11:49 o 7 55
E03 15:00 J03 11:36 o 5 26
E04 15:00 J04 7:31 o 2 21
E05 15:00 J05 15:00 23 78
E06 15:00 J06 11:12 o 5 60
E07 15:00 J07 12:11 o 3 59
E08 15:00 J08 11:20 o 4 61
E09 10:39 o J09 14:59 o 36 84
E10 15:00 J10 6:20 o 3 47
E11 15:00 J11 5:21 o 2 14
E12 8:30 o J12 13:40 o 37 77
E13 14:33 o 8 95 J13 15:00 8 56
E14 7:27 o 1 62 J14 4:48 o 1 29
E15 14:02 o 16 127 J15 9:30 o 20 39
E16 3:57 o 1 31 J16 5:07 o 3 17
E17 13:00 o J17 13:37 o 10 46
E18 6:40 o J18 8:57 o 4 51
E19 15:00 J19 8:02 o 0 37
E20 12:32 o J20 11:23 o 1 59
E21 15:00 J21 10:12 o 7 71
E22 15:00 J22 10:24 o 9 64
E23 15:00 J23 15:00 0 69
E24 5:36 o J24 14:22 o 0 76
Ave. 12:47 6.5 78.8 Ave. 10:40 8.3 51.8
SD 3:34 7.14 41.4 SD 3:18 10.4 20.1
Total 5:06:56 10 26 315 Total 4:16:01 21 200 1,244
</table>
<bodyText confidence="0.998526352941177">
working area. Actions and mouse cursor positions
are recorded at intervals of 10 msec, and are ab-
stracted into (1) a time span labeled with an action
symbol (“move”, “rotate” or “flip”) and its target
piece number (1–7), and (2) a time span labeled
with a piece number which is under the mouse
cursor during that span. The position of pieces is
updated and recorded with a timestamp when the
position of any piece changes. Information about
piece positions is not merged into the ELAN files
and is kept in separate files. As a result, we have
11 time-aligned ELAN Tiers as shown in Table 1.
Two annotators (two of the authors) first an-
notated four Japanese dialogues separately and
based on a discussion of discrepancies, decided
on the following criteria to identify a referring ex-
pression.
</bodyText>
<listItem confidence="0.997042944444444">
• The minimum span of a noun phrase in-
cluding necessary information to identify a
referent is annotated. The span might in-
clude repairs with their reparandum and dis-
fluency (Nakatani and Hirschberg, 1993) if
needed.
• Demonstrative adjectives are included in ex-
pressions.
• Erroneous expressions are annotated with a
special attribute.
• An expression without a definite referent (i.e.
a group of possible referents or none) is as-
signed a referent number sequence consist-
ing of a prefix, followed by the sequence of
possible referents as its referent, if any are
present.
• All expressions appearing in muttering to
oneself are excluded.
</listItem>
<bodyText confidence="0.990791142857143">
Table 2 shows a list of attributes of referring
expressions used in annotating the corpus.
The rest of the 20 Japanese dialogues were an-
notated by two of the authors and discrepancies
were resolved by discussion. Four English dia-
logues have been annotated so far by one of the
authors.
</bodyText>
<sectionHeader confidence="0.986491" genericHeader="method">
4 Preliminary corpus analysis
</sectionHeader>
<bodyText confidence="0.9999694">
We have already completed the Japanese corpus,
which is named REX-J (2008-08), but only 4 out
of 24 dialogues have been annotated for the En-
glish counterpart (REX-E (2010-03)). Table 3
shows a summary of the trials. The horizontal
</bodyText>
<page confidence="0.998015">
42
</page>
<bodyText confidence="0.99986425">
lines divide the trials by pairs, “o” in the “suc-
cess” column denotes that the trial was success-
fully completed in the time limit (15 minutes), and
the “OP-REX” and “SV-REX” columns show the
number of referring expressions used by the op-
erator and the solver respectively. The following
subsections describe a preliminary comparison of
the English and Japanese corpora.
</bodyText>
<tableCaption confidence="0.996015">
Table 4: Task completion time
</tableCaption>
<table confidence="0.984944166666667">
Lang.\Shape (a) (b) (c) (d)
English 832.0 741.2 890.3 605.8
(105.4) (246.5) (23.7) (287.2)
Japanese 774.7 535.0 571.7 633.8
(167.3) (168.5) (242.2) (215.2)
* Average (SD)
</table>
<subsectionHeader confidence="0.981888">
4.1 Task performance
</subsectionHeader>
<bodyText confidence="0.999803130434783">
We conducted a two-way ANOVA with the task
completion time as the dependent variable, and
the goal shape and the language as the indepen-
dent variables. Only the main effect of the lan-
guage was significant (F (1, 40) = 5.82, p &lt;
0.05). Table 4 shows the average and the standard
deviation of the completion time. Note that we set
a time limit (15 minutes) for solving the puzzle.
We considered the completion time as 15 minutes
even when a puzzle was not actually solved in the
time limit. We also conducted a two-way ANOVA
using only the successful cases. Both main effects
and their interaction were not significant.
We then conducted an ANOVA with the num-
ber of successfully solved puzzles by each pair as
the dependent variable and the language as the in-
dependent variable. The main effect was signifi-
cant (F(1,10) = 6.79, p &lt; 0.05). Table 5 shows
the average number of success goals per pair and
the success rate with their standard deviations in
parentheses.
Finally, we conducted an ANOVA with the
number of pairs who succeeded in solving a goal
</bodyText>
<tableCaption confidence="0.8597245">
Table 5: The number of solved trials and success
rates
</tableCaption>
<figure confidence="0.3942445">
Lang. solved trials success rate [%]
Japanese 3.50 (0.55) 87.5 (13.7)
English 1.67 (1.63) 41.7 (40.8)
* Average (SD)
</figure>
<bodyText confidence="0.999947">
shape as the dependent variable and the goal shape
as the independent variable. The main effect was
not significant.
In summary, we found a difference in the task
performance between the languages in terms of
the task completion time and the success rate, but
no difference among the goal shapes. This dif-
ference could be explained by the diversity of the
subjects rather than the difference of languages.
The Japanese subject group consisted of univer-
sity graduate students from the same department
(Cognitive Science) and roughly of the same age
(Average = 23.3, SD = 1.5). In contrast, the En-
glish subjects have diverse backgrounds (e.g. high
school students, university faculty, writer, pro-
grammer, etc.) and age (Average = 30.8, SD =
11.7). In addition, a familiarity with this kind of
geometric puzzle might have some effect. How-
ever, we collected a familiarity with the puzzle
only from the English subjects, we could not con-
duct further analysis on this viewpoint. Anyhow,
in this respect, the independent variable should
have been named “subject group” instead of “lan-
guage”.
</bodyText>
<subsectionHeader confidence="0.995298">
4.2 Referring expressions
</subsectionHeader>
<bodyText confidence="0.999595727272727">
It is important to note that since we have only
completed the annotation of four dialogs, all by
one pair of subjects, our analyses of referring ex-
pressions are tentative and pending further analy-
sis.
We have 200 and 1,243 referring expressions by
the operator and the solver respectively, 1,444 in
total in the 24 Japanese dialogues. On the other
hand we have 26 (operator) and 315 (solver) re-
ferring expressions in 4 English dialogues. The
average number of referring expressions per di-
alogue in Table 3 suggests that English subjects
use more referring expressions than Japanese sub-
jects. Since we have only the data from a single
pair, we cannot say whether this tendency applies
to the other pairs. We cannot draw a decisive con-
clusion until we complete the annotation of the
English corpus.
Table 6 shows the total frequencies of the at-
tributes and their frequencies per dialogue. The
table gives us an impression of significantly fre-
quent use of demonstrative pronouns (dpr) by the
</bodyText>
<page confidence="0.999899">
43
</page>
<tableCaption confidence="0.999631">
Table 6: Comparison of attribute distribution
</tableCaption>
<table confidence="0.979803571428571">
attribute English Japanese
(4 dialogues) (24 dialogues)
frq frq/dlg frq frq/dlg
dpr 226 56.5 678 28.3
dad 29 7.3 178 7.4
siz 68 17.0 288 12.0
typ 103 25.8 655 27.3
</table>
<bodyText confidence="0.952208411764706">
dir 0 0 7 0.3
prj 10 2.5 141 5.9
tpl 4 1 9 0.4
ovl 0 0 2 0.1
act 5 1.3 103 4.3
cmp 17 4.3 33 1.4
sim 0 0 7 0.3
num 22 5.5 35 1.5
rpr 0 0 1 0
err 0 0 1 0
nest 1 0.3 31 1.3
meta 1 0.3 6 0.3
English subjects. The Japanese subjects use more
attributes of projective spatial relations (prj) and
actions on the referent (act).6 The English subjects
use more complement attributes (cmp) as well as
more number attributes (num).
</bodyText>
<sectionHeader confidence="0.999803" genericHeader="method">
5 Related work
</sectionHeader>
<bodyText confidence="0.991025617647059">
Over the last decade, with a growing recogni-
tion that referring expressions frequently appear
in collaborative task dialogues (Clark and Wilkes-
Gibbs, 1986; Heeman and Hirst, 1995), a num-
ber of corpora have been constructed to study the
nature of their use. This tendency also reflects
the recognition that this area yields both challeng-
ing research topics as well as promising applica-
tions such as human-robot interaction (Foster et
al., 2008; Kruijff et al., 2010).
The COCONUT corpus (Di Eugenio et al.,
2000) was collected from keyboard-dialogs be-
tween two participants, who worked together on
a simple 2-D design task, buying and arranging
furniture for two rooms. The COCONUT cor-
pus is limited in annotations which describe sym-
bolic object information such as object intrinsic
attributes and location in discrete co-ordinates. As
an initial work of constructing a corpus for collab-
orative tasks, the COCONUT corpus can be char-
acterised as having a rather simple domain as well
6We called such expressions as action-mentioning expres-
sions (AME) in our previous work.
as limited annotation.
The QUAKE corpus (Byron, 2005) and its suc-
cessor, the SCARE corpus (Stoia et al., 2008) deal
with a more complex domain, where two partici-
pants collaboratively play a treasure hunting game
in a 3-D virtual world. Despite the complexity
of the domain, the participants were only allowed
limited actions, e.g. moving step forward, pushing
a button etc.
As a part of the JAST project, the Joint Con-
struction Task (JCT) corpus was created based on
dialogues in which two participants constructed a
puzzle (Foster et al., 2008). The setting of the
experiment is quite similar to ours except that
both participants have even roles. Since our main
concern is referring expressions, we believe our
asymmetric setting elicits more referring expres-
sions than the symmetric setting of the JCT cor-
pus.
In contrast to these previous corpora, our cor-
pora record a wide range of information useful
for analysis of human reference behaviour in situ-
ated dialogue. While the domain of our corpora is
simple compared to the QUAKE and SCARE cor-
pora, we allowed a comparatively large flexibil-
ity in the actions necessary for achieving the goal
shape (i.e. flipping, turning and moving of puzzle
pieces at different degrees), relative to the com-
plexity of the domain. Providing this relatively
larger freedom of actions to the participants to-
gether with the recording of detailed information
allows for research into new aspects of referring
expressions.
As for a multilingual aspect, all the above cor-
pora are English. There have been several recent
attempts at collecting multilingual corpora in situ-
ated domains. For instance, (Gargett et al., 2010)
collected German and English corpora in the same
setting. Their domain is similar to the QUAKE
corpus. Van der Sluis et al. (2009) aim at a com-
parative study of referring expressions between
English and Japanese. Their domain is still static
at the moment. Our corpora aim at dealing with
the dynamic nature of situated dialogues between
very different languages, English and Japanese.
</bodyText>
<page confidence="0.999532">
44
</page>
<tableCaption confidence="0.999179">
Table 7: The REX-J corpus family
</tableCaption>
<table confidence="0.999259571428571">
name puzzle #pairs #dialg. #valid status
T2008-08 Tangram 6 24 24 completed
T2009-03 Tangram 10 40 16 completed
T2009-11 Tangram 10 36 27 validating
N2009-11 Tangram 5 20 8 validating
P2009-11 Polyomino 7 28 24 annotating
D2009-112-Tangram 7 42 24 annotating
</table>
<sectionHeader confidence="0.982027" genericHeader="conclusions">
6 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.994493162790697">
This paper presented an overview of our English-
Japanese bilingual multimodal corpora of refer-
ring expressions in a collaborative problem solv-
ing setting. The Japanese corpus was completed
and has already been used for research (Spanger et
al., 2009b; Spanger et al., 2010; Iida et al., 2010),
but the English counterpart is still undergoing an-
notation. We have also presented a preliminary
comparative analysis of these corpora in terms of
the task performance and usage of referring ex-
pressions. We found a significant difference of the
task performance, which could be attributed to the
difference in diversity of subjects. We have tenta-
tive results on the usage of referring expressions,
since only four English dialogues are available at
the moment.
The data collection experiments were con-
ducted in August 2008 for Japanese and in March
2010 for English. Between these periods, we
conducted various data collections to build differ-
ent types of Japanese corpora (March, 2009 and
November 2009). These experiments involve cap-
turing eye-gaze information of participants during
problem solving, and introducing variants of puz-
zles (Polyomino, Double Tangram and Tangram
without any hints7). They are also under prepa-
ration for publication. Table 7 gives an overview
of the REX-J corpus family, where “#valid” de-
notes the number of dialogues with valid eye-
gaze data. Eye-gaze data is difficult to capture
cleanly throughout a dialogue. We discarded di-
alogues in which eye-gaze was captured success-
fully less than 70% of the total time of the dia-
logue. Namely, we annotated or will annotate di-
alogues with validated eye-gaze data only.
These corpora enable research on utilising eye-
gaze information in reference resolution and gen-
7N2009-11 in Table 7
eration, and evaluation in different tasks (puzzles)
as well. We are planning to distribute the REX-J
corpus family through GSK (Language Resources
Association in Japan)8, and the REX-E corpus
from both University of Brighton and GSK.
</bodyText>
<sectionHeader confidence="0.998525" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994519585365854">
Baran, Bahar, Berrin Dogusoy, and Kursat Cagiltay.
2007. How do adults solve digital tangram prob-
lems? Analyzing cognitive strategies through eye
tracking approach. In HCI International 2007 - 12th
International Conference - Part III, pages 555–563.
Bard, Ellen Gurman, Robin Hill, Manabu Arai, and
Mary Ellen Foster. 2009. Accessibility and atten-
tion in situated dialogue: Roles and regulations. In
Proceedings of the Workshop on Production of Re-
ferring Expressions Pre-CogSci 2009.
Belz, Anja, Eric Kow, Jette Viethen, and Albert Gatt.
2010. Referring expression generation in context:
The GREC shared task evaluation challenges. In
Krahmer, Emiel and Mari¨et Theune, editors, Empir-
ical Methods in Natural Language Generation, vol-
ume 5980 of Lecture Notes in Computer Science.
Springer-Verlag, Berlin/Heidelberg.
Byron, Donna K. 2005. The OSU Quake 2004 cor-
pus of two-party situated problem-solving dialogs.
Technical report, Department of Computer Science
and Enginerring, The Ohio State University.
Clark, H. Herbert. and Deanna Wilkes-Gibbs. 1986.
Referring as a collaborative process. Cognition,
22:1–39.
Di Eugenio, Barbara, Pamela W. Jordan, Richmond H.
Thomason, and Johanna. D. Moore. 2000. The
agreement process: An empirical investigation of
human-human computer-mediated collaborative di-
alogues. International Journal ofHuman-Computer
Studies, 53(6):1017–1076.
Foster, Mary Ellen and Jon Oberlander. 2007. Corpus-
based generation of head and eyebrow motion for
an embodied conversational agent. Language Re-
sources and Evaluation, 41(3–4):305–323, Decem-
ber.
Foster, Mary Ellen, Ellen Gurman Bard, Markus Guhe,
Robin L. Hill, Jon Oberlander, and Alois Knoll.
2008. The roles of haptic-ostensive referring ex-
pressions in cooperative, task-based human-robot
dialogue. In Proceedings of 3rd Human-Robot In-
teraction, pages 295–302.
</reference>
<footnote confidence="0.923706">
8http://www.gsk.or.jp/index e.html
</footnote>
<page confidence="0.997757">
45
</page>
<reference confidence="0.991221032258064">
Gargett, Andrew, Konstantina Garoufi, Alexander
Koller, and Kristina Striegnitz. 2010. The give-
2 corpus of giving instructions in virtual environ-
ments. In Proceedings of the Seventh conference on
International Language Resources and Evaluation
(LREC 2010), pages 2401–2406.
Heeman, Peter A. and Graeme Hirst. 1995. Collabo-
rating on referring expressions. Computational Lin-
guistics, 21:351–382.
Hobbs, Jerry R. 1978. Resolving pronoun references.
Lingua, 44:311–338.
Iida, Ryu, Shumpei Kobayashi, and Takenobu Toku-
naga. 2010. Incorporating extra-linguistic informa-
tion into reference resolution in collaborative task
dialogue. In Proceedings of 48th Annual Meeting
of the Association for Computational Linguistics,
pages 1259–1267.
Kiyokawa, Sachiko and Midori Nakazawa. 2006. Ef-
fects of reflective verbalization on insight problem
solving. In Proceedings of 5th International Con-
ference of the Cognitive Science, pages 137–139.
Kruijff, Geert-Jan M., Pierre Lison, Trevor Ben-
jamin, Henrik Jacobsson, Hendrik Zender, and
Ivana Kruijff-Korbayova. 2010. Situated dialogue
processing for human-robot interaction. In Cogni-
tive Systems: Final report of the CoSy project, pages
311–364. Springer-Verlag.
Martin, Jean-Claude, Patrizia Paggio, Peter Kuehnlein,
Rainer Stiefelhagen, and Fabio Pianesi. 2007. Spe-
cial issue on Mulitmodal corpora for modeling hu-
man multimodal behaviour. Language Resources
and Evaluation, 41(3-4).
Mitkov, Ruslan. 2002. Anaphora Resolution. Long-
man.
Nakatani, Christine and Julia Hirschberg. 1993. A
speech-first model for repair identification and cor-
rection. In Proceedings of 31th Annual Meeting of
ACL, pages 200–207.
Noguchi, Masaki, Kenta Miyoshi, Takenobu Toku-
naga, Ryu Iida, Mamoru Komachi, and Kentaro
Inui. 2008. Multiple purpose annotation using
SLAT – Segment and link-based annotation tool.
In Proceedings of 2nd Linguistic Annotation Work-
shop, pages 61–64.
Piwek, Paul L. A. 2007. Modality choise for gen-
eration of referring acts. In Proceedings of the
Workshop on Multimodal Output Generation (MOG
2007), pages 129–139.
Spanger, Philipp, Masaaki Yasuhara, Ryu Iida, and
Takenobu Tokunaga. 2009a. A Japanese corpus
of referring expressions used in a situated collab-
oration task. In Proceedings of the 12th European
Workshop on Natural Language Generation (ENLG
2009), pages 110 – 113.
Spanger, Philipp, Masaaki Yasuhara, Ryu Iida, and
Takenobu Tokunaga. 2009b. Using extra linguistic
information for generating demonstrative pronouns
in a situated collaboration task. In Proceedings of
PreCogSci 2009: Production of Referring Expres-
sions: Bridging the gap between computational and
empirical approaches to reference.
Spanger, Philipp, Ryu Iida, Takenobu Tokunaga,
Asuka Teri, and Naoko Kuriyama. 2010. Towards
an extrinsic evaluation of referring expressions in
situated dialogs. In Kelleher, John, Brian Mac
Namee, and Ielka van der Sluis, editors, Proceed-
ings of the Sixth International Natural Language
Generation Conference (INGL 2010), pages 135–
144.
Sternberg, Robert J. and Janet E. Davidson, editors.
1996. The Nature of Insight. The MIT Press.
Stoia, Laura, Darla Magdalene Shockley, Donna K.
Byron, and Eric Fosler-Lussier. 2008. SCARE:
A situated corpus with annotated referring expres-
sions. In Proceedings of the Sixth International
Conference on Language Resources and Evaluation
(LREC 2008), pages 28–30.
Suzuki, Hiroaki, Keiga Abe, Kazuo Hiraki, and
Michiko Miyazaki. 2001. Cue-readiness in in-
sight problem-solving. In Proceedings of the 23rd
Annual Meeting of the Cognitive Science Society,
pages 1012 – 1017.
van Deemter, Kees, Ielka van der Sluis, and Albert
Gatt. 2006. Building a semantically transparent
corpus for the generation of referring expressions.
In Proceedings of the Fourth International Natural
Language Generation Conference, pages 130–132.
van der Sluis, Ielka, Junko Nagai, and Saturnino Luz.
2009. Producing referring expressions in dialogue:
Insights from a translation exercise. In Proceedings
of PreCogSci 2009: Production of Referring Ex-
pressions: Bridging the gap between computational
and empirical approaches to reference.
</reference>
<page confidence="0.999525">
46
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.077602">
<title confidence="0.7525865">Construction of bilingual multimodal corpora of referring expressions in collaborative problem solving</title>
<author confidence="0.482529">TOKUNAGA Takenobu IIDA Ryu YASUHARA Masaaki TERAI Asuka</author>
<email confidence="0.546529">asuka@nm.hum.titech.ac.jp</email>
<affiliation confidence="0.982028">Tokyo Institute of Technology</affiliation>
<author confidence="0.3853225">David MORRIS Anja BELZ D Morrisbrighton ac uk a s belzitri brighton ac uk</author>
<affiliation confidence="0.995978">University of Brighton</affiliation>
<abstract confidence="0.999701964285714">This paper presents on-going work on constructing bilingual multimodal corpora of referring expressions in collaborative problem solving for English and Japanese. The corpora were collected from dialogues in which two participants collaboratively solved Tangram puzzles with a puzzle simulator. Extra-linguistic information such as operations on puzzle pieces, mouse cursor position and piece positions were recorded in synchronisation with utterances. The speech data was transcribed and time-aligned with the extra-linguistic information. Referring expressions in utterances that refer to puzzle pieces were annotated in terms of their spans, their referents and their other attributes. The Japanese corpus has already been completed, but the English counterpart is still undergoing annotation. We have conducted a preliminary comparative analysis of both corpora, mainly with respect to task completion time, task success rates and attributes of referring expressions. These corpora showed significant differences in task completion time and success rate.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Bahar Baran</author>
<author>Berrin Dogusoy</author>
<author>Kursat Cagiltay</author>
</authors>
<title>How do adults solve digital tangram problems? Analyzing cognitive strategies through eye tracking approach.</title>
<date>2007</date>
<booktitle>In HCI International</booktitle>
<pages>555--563</pages>
<contexts>
<context position="9192" citStr="Baran et al., 2007" startWordPosition="1426" endWordPosition="1429">own in Figure 3. In Cognitive Science, a wide variety of different kinds of puzzles have been employed extensively in the field of Insight Problem solving. This has been termed the “puzzle-problem approach” (Sternberg and Davidson, 1996; Suzuki et al., 2001) and in the case of physical puzzles has relatively often involved puzzle tasks of symmetric shapes like the so-called T-puzzle, e.g. (Kiyokawa and Nakazawa, 2006). In more recent work Tangram puzzles have been used as a means to study various new aspects of human problem solving approaches, including collection of of eye-gaze information (Baran et al., 2007). In order to collect data as broadly as possible in this context, we set up puzzle-problems including both symmetrical as well as asymmetrical ones as shown in Figure 3. The participants exchanged their roles after two trials, i.e. a participant first solves a symmetric and then an asymmetric puzzle as the solver and then does the same as the operator, and vice versa. The order of the puzzle trials is the same for all pairs. Before starting the first trial as the operator, each participant had a short training exercise in order to learn how to manipulate pieces with the mouse. The initial arr</context>
</contexts>
<marker>Baran, Dogusoy, Cagiltay, 2007</marker>
<rawString>Baran, Bahar, Berrin Dogusoy, and Kursat Cagiltay. 2007. How do adults solve digital tangram problems? Analyzing cognitive strategies through eye tracking approach. In HCI International 2007 - 12th International Conference - Part III, pages 555–563.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Gurman Bard</author>
<author>Robin Hill</author>
<author>Manabu Arai</author>
<author>Mary Ellen Foster</author>
</authors>
<title>Accessibility and attention in situated dialogue: Roles and regulations.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Production of Referring Expressions Pre-CogSci</booktitle>
<contexts>
<context position="2659" citStr="Bard et al., 2009" startWordPosition="378" endWordPosition="381">he same text. This trend, targeting reference resolution in written text, is still dominant in the language analysis, perhaps because such techniques are intended for use in applications such as information extraction. In contrast, in language generation research interest has recently shifted from the generation of one-off references to entities to generation of REs in discourse context (Belz et al., 2010) and investigating human referential behaviour in real world situations, with the aim of using such techniques in applications like human-robot interaction (Piwek, 2007; Foster et al., 2008; Bard et al., 2009). In both analysis and generation, machinelearning approaches have come to replace rulebased approaches as the predominant research trend since the 1990s. This trend has made annotated corpora an indispensable component of research for training and evaluating proposed methods. In fact, research on reference resolution has developed significantly as a result of large scale corpora, e.g. those provided by the Message Understanding Conference (MUC)1 and the Automatic Content Extraction (ACE)2 project. These corpora were constructed primarily for information extraction research, thus were annotate</context>
</contexts>
<marker>Bard, Hill, Arai, Foster, 2009</marker>
<rawString>Bard, Ellen Gurman, Robin Hill, Manabu Arai, and Mary Ellen Foster. 2009. Accessibility and attention in situated dialogue: Roles and regulations. In Proceedings of the Workshop on Production of Referring Expressions Pre-CogSci 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anja Belz</author>
</authors>
<title>Eric Kow, Jette Viethen, and Albert Gatt.</title>
<date>2010</date>
<booktitle>In Krahmer, Emiel and Mari¨et Theune, editors, Empirical Methods in Natural Language Generation,</booktitle>
<volume>5980</volume>
<publisher>Springer-Verlag, Berlin/Heidelberg.</publisher>
<marker>Belz, 2010</marker>
<rawString>Belz, Anja, Eric Kow, Jette Viethen, and Albert Gatt. 2010. Referring expression generation in context: The GREC shared task evaluation challenges. In Krahmer, Emiel and Mari¨et Theune, editors, Empirical Methods in Natural Language Generation, volume 5980 of Lecture Notes in Computer Science. Springer-Verlag, Berlin/Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donna K Byron</author>
</authors>
<title>The OSU Quake</title>
<date>2005</date>
<tech>Technical report,</tech>
<institution>Department of Computer Science and Enginerring, The Ohio State University.</institution>
<contexts>
<context position="3676" citStr="Byron, 2005" startWordPosition="520" endWordPosition="522"> the Message Understanding Conference (MUC)1 and the Automatic Content Extraction (ACE)2 project. These corpora were constructed primarily for information extraction research, thus were annotated with co-reference relations within texts. Also in the language generation community, several corpora lhttp://www.nlpir.nist.gov/related projects/muc/ zhttp://www.itl.nist.gov/iad/tests/ace/ 38 Proceedings of the 8th Workshop on Asian Language Resources, pages 38–46, Beijing, China, 21-22 August 2010. c�2010 Asian Federation for Natural Language Processing have been developed (Di Eugenio et al., 2000; Byron, 2005; van Deemter et al., 2006; Foster and Oberlander, 2007; Foster et al., 2008; Stoia et al., 2008; Spanger et al., 2009a; Belz et al., 2010). Unlike the corpora of MUC and ACE, many are collected from situated dialogues, and therefore include multimodal information (e.g. gestures and eye-gaze) other than just transcribed text (Martin et al., 2007). Foster and Oberlander (2007) emphasised that any corpus for language generation should include all possible contextual information at the appropriate granularity. Since constructing a dialogue corpus generally requires experiments for data collection</context>
<context position="23509" citStr="Byron, 2005" startWordPosition="3930" endWordPosition="3931">was collected from keyboard-dialogs between two participants, who worked together on a simple 2-D design task, buying and arranging furniture for two rooms. The COCONUT corpus is limited in annotations which describe symbolic object information such as object intrinsic attributes and location in discrete co-ordinates. As an initial work of constructing a corpus for collaborative tasks, the COCONUT corpus can be characterised as having a rather simple domain as well 6We called such expressions as action-mentioning expressions (AME) in our previous work. as limited annotation. The QUAKE corpus (Byron, 2005) and its successor, the SCARE corpus (Stoia et al., 2008) deal with a more complex domain, where two participants collaboratively play a treasure hunting game in a 3-D virtual world. Despite the complexity of the domain, the participants were only allowed limited actions, e.g. moving step forward, pushing a button etc. As a part of the JAST project, the Joint Construction Task (JCT) corpus was created based on dialogues in which two participants constructed a puzzle (Foster et al., 2008). The setting of the experiment is quite similar to ours except that both participants have even roles. Sinc</context>
</contexts>
<marker>Byron, 2005</marker>
<rawString>Byron, Donna K. 2005. The OSU Quake 2004 corpus of two-party situated problem-solving dialogs. Technical report, Department of Computer Science and Enginerring, The Ohio State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deanna Wilkes-Gibbs</author>
</authors>
<title>Referring as a collaborative process.</title>
<date>1986</date>
<journal>Cognition,</journal>
<pages>22--1</pages>
<marker>Wilkes-Gibbs, 1986</marker>
<rawString>Clark, H. Herbert. and Deanna Wilkes-Gibbs. 1986. Referring as a collaborative process. Cognition, 22:1–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Moore</author>
</authors>
<title>The agreement process: An empirical investigation of human-human computer-mediated collaborative dialogues.</title>
<date>2000</date>
<journal>International Journal ofHuman-Computer Studies,</journal>
<volume>53</volume>
<issue>6</issue>
<marker>Moore, 2000</marker>
<rawString>Di Eugenio, Barbara, Pamela W. Jordan, Richmond H. Thomason, and Johanna. D. Moore. 2000. The agreement process: An empirical investigation of human-human computer-mediated collaborative dialogues. International Journal ofHuman-Computer Studies, 53(6):1017–1076.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Ellen Foster</author>
<author>Jon Oberlander</author>
</authors>
<title>Corpusbased generation of head and eyebrow motion for an embodied conversational agent. Language Resources and Evaluation,</title>
<date>2007</date>
<pages>41--3</pages>
<contexts>
<context position="3731" citStr="Foster and Oberlander, 2007" startWordPosition="528" endWordPosition="531">MUC)1 and the Automatic Content Extraction (ACE)2 project. These corpora were constructed primarily for information extraction research, thus were annotated with co-reference relations within texts. Also in the language generation community, several corpora lhttp://www.nlpir.nist.gov/related projects/muc/ zhttp://www.itl.nist.gov/iad/tests/ace/ 38 Proceedings of the 8th Workshop on Asian Language Resources, pages 38–46, Beijing, China, 21-22 August 2010. c�2010 Asian Federation for Natural Language Processing have been developed (Di Eugenio et al., 2000; Byron, 2005; van Deemter et al., 2006; Foster and Oberlander, 2007; Foster et al., 2008; Stoia et al., 2008; Spanger et al., 2009a; Belz et al., 2010). Unlike the corpora of MUC and ACE, many are collected from situated dialogues, and therefore include multimodal information (e.g. gestures and eye-gaze) other than just transcribed text (Martin et al., 2007). Foster and Oberlander (2007) emphasised that any corpus for language generation should include all possible contextual information at the appropriate granularity. Since constructing a dialogue corpus generally requires experiments for data collection, this kind of corpus tends to be small-scale compared </context>
</contexts>
<marker>Foster, Oberlander, 2007</marker>
<rawString>Foster, Mary Ellen and Jon Oberlander. 2007. Corpusbased generation of head and eyebrow motion for an embodied conversational agent. Language Resources and Evaluation, 41(3–4):305–323, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Ellen Foster</author>
<author>Ellen Gurman Bard</author>
<author>Markus Guhe</author>
<author>Robin L Hill</author>
<author>Jon Oberlander</author>
<author>Alois Knoll</author>
</authors>
<title>The roles of haptic-ostensive referring expressions in cooperative, task-based human-robot dialogue.</title>
<date>2008</date>
<booktitle>In Proceedings of 3rd Human-Robot Interaction,</booktitle>
<pages>295--302</pages>
<contexts>
<context position="2639" citStr="Foster et al., 2008" startWordPosition="374" endWordPosition="377">es mentioned within the same text. This trend, targeting reference resolution in written text, is still dominant in the language analysis, perhaps because such techniques are intended for use in applications such as information extraction. In contrast, in language generation research interest has recently shifted from the generation of one-off references to entities to generation of REs in discourse context (Belz et al., 2010) and investigating human referential behaviour in real world situations, with the aim of using such techniques in applications like human-robot interaction (Piwek, 2007; Foster et al., 2008; Bard et al., 2009). In both analysis and generation, machinelearning approaches have come to replace rulebased approaches as the predominant research trend since the 1990s. This trend has made annotated corpora an indispensable component of research for training and evaluating proposed methods. In fact, research on reference resolution has developed significantly as a result of large scale corpora, e.g. those provided by the Message Understanding Conference (MUC)1 and the Automatic Content Extraction (ACE)2 project. These corpora were constructed primarily for information extraction research</context>
<context position="22827" citStr="Foster et al., 2008" startWordPosition="3820" endWordPosition="3823">ve spatial relations (prj) and actions on the referent (act).6 The English subjects use more complement attributes (cmp) as well as more number attributes (num). 5 Related work Over the last decade, with a growing recognition that referring expressions frequently appear in collaborative task dialogues (Clark and WilkesGibbs, 1986; Heeman and Hirst, 1995), a number of corpora have been constructed to study the nature of their use. This tendency also reflects the recognition that this area yields both challenging research topics as well as promising applications such as human-robot interaction (Foster et al., 2008; Kruijff et al., 2010). The COCONUT corpus (Di Eugenio et al., 2000) was collected from keyboard-dialogs between two participants, who worked together on a simple 2-D design task, buying and arranging furniture for two rooms. The COCONUT corpus is limited in annotations which describe symbolic object information such as object intrinsic attributes and location in discrete co-ordinates. As an initial work of constructing a corpus for collaborative tasks, the COCONUT corpus can be characterised as having a rather simple domain as well 6We called such expressions as action-mentioning expressions</context>
</contexts>
<marker>Foster, Bard, Guhe, Hill, Oberlander, Knoll, 2008</marker>
<rawString>Foster, Mary Ellen, Ellen Gurman Bard, Markus Guhe, Robin L. Hill, Jon Oberlander, and Alois Knoll. 2008. The roles of haptic-ostensive referring expressions in cooperative, task-based human-robot dialogue. In Proceedings of 3rd Human-Robot Interaction, pages 295–302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Gargett</author>
<author>Konstantina Garoufi</author>
<author>Alexander Koller</author>
<author>Kristina Striegnitz</author>
</authors>
<title>The give2 corpus of giving instructions in virtual environments.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC</booktitle>
<pages>2401--2406</pages>
<contexts>
<context position="25109" citStr="Gargett et al., 2010" startWordPosition="4190" endWordPosition="4193">E and SCARE corpora, we allowed a comparatively large flexibility in the actions necessary for achieving the goal shape (i.e. flipping, turning and moving of puzzle pieces at different degrees), relative to the complexity of the domain. Providing this relatively larger freedom of actions to the participants together with the recording of detailed information allows for research into new aspects of referring expressions. As for a multilingual aspect, all the above corpora are English. There have been several recent attempts at collecting multilingual corpora in situated domains. For instance, (Gargett et al., 2010) collected German and English corpora in the same setting. Their domain is similar to the QUAKE corpus. Van der Sluis et al. (2009) aim at a comparative study of referring expressions between English and Japanese. Their domain is still static at the moment. Our corpora aim at dealing with the dynamic nature of situated dialogues between very different languages, English and Japanese. 44 Table 7: The REX-J corpus family name puzzle #pairs #dialg. #valid status T2008-08 Tangram 6 24 24 completed T2009-03 Tangram 10 40 16 completed T2009-11 Tangram 10 36 27 validating N2009-11 Tangram 5 20 8 vali</context>
</contexts>
<marker>Gargett, Garoufi, Koller, Striegnitz, 2010</marker>
<rawString>Gargett, Andrew, Konstantina Garoufi, Alexander Koller, and Kristina Striegnitz. 2010. The give2 corpus of giving instructions in virtual environments. In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC 2010), pages 2401–2406.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter A Heeman</author>
<author>Graeme Hirst</author>
</authors>
<title>Collaborating on referring expressions.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<pages>21--351</pages>
<contexts>
<context position="22564" citStr="Heeman and Hirst, 1995" startWordPosition="3776" endWordPosition="3779">55 27.3 dir 0 0 7 0.3 prj 10 2.5 141 5.9 tpl 4 1 9 0.4 ovl 0 0 2 0.1 act 5 1.3 103 4.3 cmp 17 4.3 33 1.4 sim 0 0 7 0.3 num 22 5.5 35 1.5 rpr 0 0 1 0 err 0 0 1 0 nest 1 0.3 31 1.3 meta 1 0.3 6 0.3 English subjects. The Japanese subjects use more attributes of projective spatial relations (prj) and actions on the referent (act).6 The English subjects use more complement attributes (cmp) as well as more number attributes (num). 5 Related work Over the last decade, with a growing recognition that referring expressions frequently appear in collaborative task dialogues (Clark and WilkesGibbs, 1986; Heeman and Hirst, 1995), a number of corpora have been constructed to study the nature of their use. This tendency also reflects the recognition that this area yields both challenging research topics as well as promising applications such as human-robot interaction (Foster et al., 2008; Kruijff et al., 2010). The COCONUT corpus (Di Eugenio et al., 2000) was collected from keyboard-dialogs between two participants, who worked together on a simple 2-D design task, buying and arranging furniture for two rooms. The COCONUT corpus is limited in annotations which describe symbolic object information such as object intrins</context>
</contexts>
<marker>Heeman, Hirst, 1995</marker>
<rawString>Heeman, Peter A. and Graeme Hirst. 1995. Collaborating on referring expressions. Computational Linguistics, 21:351–382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Resolving pronoun references.</title>
<date>1978</date>
<journal>Lingua,</journal>
<pages>44--311</pages>
<contexts>
<context position="1874" citStr="Hobbs, 1978" startWordPosition="262" endWordPosition="263">pletion time, task success rates and attributes of referring expressions. These corpora showed significant differences in task completion time and success rate. 1 Introduction A referring expression (RE) is a linguistic device that refers to a certain object of interest (e.g. used in describing where the object is located in space). REs have attracted a great deal of attention in both language analysis and language generation research. In language analysis research, reference resolution, particularly anaphora resolution (Mitkov, 2002), has a long research history as far back as the mid-1970s (Hobbs, 1978). Much research has been conducted from both theoretical and empirical perspectives, mainly concerning the identification of antecedents or entities mentioned within the same text. This trend, targeting reference resolution in written text, is still dominant in the language analysis, perhaps because such techniques are intended for use in applications such as information extraction. In contrast, in language generation research interest has recently shifted from the generation of one-off references to entities to generation of REs in discourse context (Belz et al., 2010) and investigating human</context>
</contexts>
<marker>Hobbs, 1978</marker>
<rawString>Hobbs, Jerry R. 1978. Resolving pronoun references. Lingua, 44:311–338.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryu Iida</author>
<author>Shumpei Kobayashi</author>
<author>Takenobu Tokunaga</author>
</authors>
<title>Incorporating extra-linguistic information into reference resolution in collaborative task dialogue.</title>
<date>2010</date>
<booktitle>In Proceedings of 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1259--1267</pages>
<contexts>
<context position="26111" citStr="Iida et al., 2010" startWordPosition="4353" endWordPosition="4356">e. 44 Table 7: The REX-J corpus family name puzzle #pairs #dialg. #valid status T2008-08 Tangram 6 24 24 completed T2009-03 Tangram 10 40 16 completed T2009-11 Tangram 10 36 27 validating N2009-11 Tangram 5 20 8 validating P2009-11 Polyomino 7 28 24 annotating D2009-112-Tangram 7 42 24 annotating 6 Conclusion and future work This paper presented an overview of our EnglishJapanese bilingual multimodal corpora of referring expressions in a collaborative problem solving setting. The Japanese corpus was completed and has already been used for research (Spanger et al., 2009b; Spanger et al., 2010; Iida et al., 2010), but the English counterpart is still undergoing annotation. We have also presented a preliminary comparative analysis of these corpora in terms of the task performance and usage of referring expressions. We found a significant difference of the task performance, which could be attributed to the difference in diversity of subjects. We have tentative results on the usage of referring expressions, since only four English dialogues are available at the moment. The data collection experiments were conducted in August 2008 for Japanese and in March 2010 for English. Between these periods, we condu</context>
</contexts>
<marker>Iida, Kobayashi, Tokunaga, 2010</marker>
<rawString>Iida, Ryu, Shumpei Kobayashi, and Takenobu Tokunaga. 2010. Incorporating extra-linguistic information into reference resolution in collaborative task dialogue. In Proceedings of 48th Annual Meeting of the Association for Computational Linguistics, pages 1259–1267.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sachiko Kiyokawa</author>
<author>Midori Nakazawa</author>
</authors>
<title>Effects of reflective verbalization on insight problem solving.</title>
<date>2006</date>
<booktitle>In Proceedings of 5th International Conference of the Cognitive Science,</booktitle>
<pages>137--139</pages>
<contexts>
<context position="8994" citStr="Kiyokawa and Nakazawa, 2006" startWordPosition="1391" endWordPosition="1394"> and to restrict their interaction to speech only. Figure 3: The goal shapes given to the subjects Each participant pair was assigned 4 trials consisting of two symmetric and two asymmetric goal shapes as shown in Figure 3. In Cognitive Science, a wide variety of different kinds of puzzles have been employed extensively in the field of Insight Problem solving. This has been termed the “puzzle-problem approach” (Sternberg and Davidson, 1996; Suzuki et al., 2001) and in the case of physical puzzles has relatively often involved puzzle tasks of symmetric shapes like the so-called T-puzzle, e.g. (Kiyokawa and Nakazawa, 2006). In more recent work Tangram puzzles have been used as a means to study various new aspects of human problem solving approaches, including collection of of eye-gaze information (Baran et al., 2007). In order to collect data as broadly as possible in this context, we set up puzzle-problems including both symmetrical as well as asymmetrical ones as shown in Figure 3. The participants exchanged their roles after two trials, i.e. a participant first solves a symmetric and then an asymmetric puzzle as the solver and then does the same as the operator, and vice versa. The order of the puzzle trials</context>
</contexts>
<marker>Kiyokawa, Nakazawa, 2006</marker>
<rawString>Kiyokawa, Sachiko and Midori Nakazawa. 2006. Effects of reflective verbalization on insight problem solving. In Proceedings of 5th International Conference of the Cognitive Science, pages 137–139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geert-Jan M Kruijff</author>
<author>Pierre Lison</author>
<author>Trevor Benjamin</author>
<author>Henrik Jacobsson</author>
<author>Hendrik Zender</author>
<author>Ivana Kruijff-Korbayova</author>
</authors>
<title>Situated dialogue processing for human-robot interaction. In Cognitive Systems: Final report of the CoSy project,</title>
<date>2010</date>
<pages>311--364</pages>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="22850" citStr="Kruijff et al., 2010" startWordPosition="3824" endWordPosition="3827">(prj) and actions on the referent (act).6 The English subjects use more complement attributes (cmp) as well as more number attributes (num). 5 Related work Over the last decade, with a growing recognition that referring expressions frequently appear in collaborative task dialogues (Clark and WilkesGibbs, 1986; Heeman and Hirst, 1995), a number of corpora have been constructed to study the nature of their use. This tendency also reflects the recognition that this area yields both challenging research topics as well as promising applications such as human-robot interaction (Foster et al., 2008; Kruijff et al., 2010). The COCONUT corpus (Di Eugenio et al., 2000) was collected from keyboard-dialogs between two participants, who worked together on a simple 2-D design task, buying and arranging furniture for two rooms. The COCONUT corpus is limited in annotations which describe symbolic object information such as object intrinsic attributes and location in discrete co-ordinates. As an initial work of constructing a corpus for collaborative tasks, the COCONUT corpus can be characterised as having a rather simple domain as well 6We called such expressions as action-mentioning expressions (AME) in our previous </context>
</contexts>
<marker>Kruijff, Lison, Benjamin, Jacobsson, Zender, Kruijff-Korbayova, 2010</marker>
<rawString>Kruijff, Geert-Jan M., Pierre Lison, Trevor Benjamin, Henrik Jacobsson, Hendrik Zender, and Ivana Kruijff-Korbayova. 2010. Situated dialogue processing for human-robot interaction. In Cognitive Systems: Final report of the CoSy project, pages 311–364. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean-Claude Martin</author>
<author>Patrizia Paggio</author>
<author>Peter Kuehnlein</author>
<author>Rainer Stiefelhagen</author>
<author>Fabio Pianesi</author>
</authors>
<title>Special issue on Mulitmodal corpora for modeling human multimodal behaviour. Language Resources and Evaluation,</title>
<date>2007</date>
<pages>41--3</pages>
<contexts>
<context position="4024" citStr="Martin et al., 2007" startWordPosition="575" endWordPosition="578">s/muc/ zhttp://www.itl.nist.gov/iad/tests/ace/ 38 Proceedings of the 8th Workshop on Asian Language Resources, pages 38–46, Beijing, China, 21-22 August 2010. c�2010 Asian Federation for Natural Language Processing have been developed (Di Eugenio et al., 2000; Byron, 2005; van Deemter et al., 2006; Foster and Oberlander, 2007; Foster et al., 2008; Stoia et al., 2008; Spanger et al., 2009a; Belz et al., 2010). Unlike the corpora of MUC and ACE, many are collected from situated dialogues, and therefore include multimodal information (e.g. gestures and eye-gaze) other than just transcribed text (Martin et al., 2007). Foster and Oberlander (2007) emphasised that any corpus for language generation should include all possible contextual information at the appropriate granularity. Since constructing a dialogue corpus generally requires experiments for data collection, this kind of corpus tends to be small-scale compared with corpora for reference resolution. Against this background, we have been developing multimodal corpora of referring expressions in collaborative problem-solving settings. This paper presents on-going work of constructing bilingual (English and Japanese) comparable corpora in this domain. </context>
</contexts>
<marker>Martin, Paggio, Kuehnlein, Stiefelhagen, Pianesi, 2007</marker>
<rawString>Martin, Jean-Claude, Patrizia Paggio, Peter Kuehnlein, Rainer Stiefelhagen, and Fabio Pianesi. 2007. Special issue on Mulitmodal corpora for modeling human multimodal behaviour. Language Resources and Evaluation, 41(3-4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
</authors>
<title>Anaphora Resolution.</title>
<date>2002</date>
<publisher>Longman.</publisher>
<contexts>
<context position="1802" citStr="Mitkov, 2002" startWordPosition="249" endWordPosition="250">ary comparative analysis of both corpora, mainly with respect to task completion time, task success rates and attributes of referring expressions. These corpora showed significant differences in task completion time and success rate. 1 Introduction A referring expression (RE) is a linguistic device that refers to a certain object of interest (e.g. used in describing where the object is located in space). REs have attracted a great deal of attention in both language analysis and language generation research. In language analysis research, reference resolution, particularly anaphora resolution (Mitkov, 2002), has a long research history as far back as the mid-1970s (Hobbs, 1978). Much research has been conducted from both theoretical and empirical perspectives, mainly concerning the identification of antecedents or entities mentioned within the same text. This trend, targeting reference resolution in written text, is still dominant in the language analysis, perhaps because such techniques are intended for use in applications such as information extraction. In contrast, in language generation research interest has recently shifted from the generation of one-off references to entities to generation</context>
</contexts>
<marker>Mitkov, 2002</marker>
<rawString>Mitkov, Ruslan. 2002. Anaphora Resolution. Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christine Nakatani</author>
<author>Julia Hirschberg</author>
</authors>
<title>A speech-first model for repair identification and correction.</title>
<date>1993</date>
<booktitle>In Proceedings of 31th Annual Meeting of ACL,</booktitle>
<pages>200--207</pages>
<contexts>
<context position="16836" citStr="Nakatani and Hirschberg, 1993" startWordPosition="2791" endWordPosition="2794">with a timestamp when the position of any piece changes. Information about piece positions is not merged into the ELAN files and is kept in separate files. As a result, we have 11 time-aligned ELAN Tiers as shown in Table 1. Two annotators (two of the authors) first annotated four Japanese dialogues separately and based on a discussion of discrepancies, decided on the following criteria to identify a referring expression. • The minimum span of a noun phrase including necessary information to identify a referent is annotated. The span might include repairs with their reparandum and disfluency (Nakatani and Hirschberg, 1993) if needed. • Demonstrative adjectives are included in expressions. • Erroneous expressions are annotated with a special attribute. • An expression without a definite referent (i.e. a group of possible referents or none) is assigned a referent number sequence consisting of a prefix, followed by the sequence of possible referents as its referent, if any are present. • All expressions appearing in muttering to oneself are excluded. Table 2 shows a list of attributes of referring expressions used in annotating the corpus. The rest of the 20 Japanese dialogues were annotated by two of the authors </context>
</contexts>
<marker>Nakatani, Hirschberg, 1993</marker>
<rawString>Nakatani, Christine and Julia Hirschberg. 1993. A speech-first model for repair identification and correction. In Proceedings of 31th Annual Meeting of ACL, pages 200–207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masaki Noguchi</author>
<author>Kenta Miyoshi</author>
<author>Takenobu Tokunaga</author>
<author>Ryu Iida</author>
<author>Mamoru Komachi</author>
<author>Kentaro Inui</author>
</authors>
<title>Multiple purpose annotation using SLAT – Segment and link-based annotation tool.</title>
<date>2008</date>
<booktitle>In Proceedings of 2nd Linguistic Annotation Workshop,</booktitle>
<pages>61--64</pages>
<contexts>
<context position="13961" citStr="Noguchi et al., 2008" startWordPosition="2237" endWordPosition="2240"> “the triangle that you are holding now”, “the triangle that you just rotated” cmp : complement, e.g. “the other one” sim : similarity, e.g. “the same one” num : number, e.g. “the two triangle” rpr : repair, e.g. “the big, no, small triangle” err : obvious erroneous expression, e.g. “the square” referring to a triangle nest : nested expression; when a referring expression includes another referring expression, only the outermost expression is annotated with this attribute, e.g. “(the triangle to the left of (the small triangle))” meta: metaphorical expression, e.g. “the leg”, “the head” SLAT (Noguchi et al., 2008)4. Our target expressions in this corpus are referring expressions referring to a puzzle piece or a set of puzzle pieces. We do not deal with expressions referring to a location, a part of a piece or a constructed shape. These expressions are put aside for future work. The annotation of referring expressions is threefold: (1) identification of the span of expressions, (2) identification of their referents, and (3) assignment of a set of attributes to each referring expression. Using the multimodal annotation tool ELAN,5 the annotations of referring expressions were then merged with extra-lingu</context>
</contexts>
<marker>Noguchi, Miyoshi, Tokunaga, Iida, Komachi, Inui, 2008</marker>
<rawString>Noguchi, Masaki, Kenta Miyoshi, Takenobu Tokunaga, Ryu Iida, Mamoru Komachi, and Kentaro Inui. 2008. Multiple purpose annotation using SLAT – Segment and link-based annotation tool. In Proceedings of 2nd Linguistic Annotation Workshop, pages 61–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul L A Piwek</author>
</authors>
<title>Modality choise for generation of referring acts.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on Multimodal Output Generation (MOG</booktitle>
<pages>129--139</pages>
<contexts>
<context position="2618" citStr="Piwek, 2007" startWordPosition="371" endWordPosition="373">nts or entities mentioned within the same text. This trend, targeting reference resolution in written text, is still dominant in the language analysis, perhaps because such techniques are intended for use in applications such as information extraction. In contrast, in language generation research interest has recently shifted from the generation of one-off references to entities to generation of REs in discourse context (Belz et al., 2010) and investigating human referential behaviour in real world situations, with the aim of using such techniques in applications like human-robot interaction (Piwek, 2007; Foster et al., 2008; Bard et al., 2009). In both analysis and generation, machinelearning approaches have come to replace rulebased approaches as the predominant research trend since the 1990s. This trend has made annotated corpora an indispensable component of research for training and evaluating proposed methods. In fact, research on reference resolution has developed significantly as a result of large scale corpora, e.g. those provided by the Message Understanding Conference (MUC)1 and the Automatic Content Extraction (ACE)2 project. These corpora were constructed primarily for informatio</context>
</contexts>
<marker>Piwek, 2007</marker>
<rawString>Piwek, Paul L. A. 2007. Modality choise for generation of referring acts. In Proceedings of the Workshop on Multimodal Output Generation (MOG 2007), pages 129–139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Spanger</author>
<author>Masaaki Yasuhara</author>
<author>Ryu Iida</author>
<author>Takenobu Tokunaga</author>
</authors>
<title>A Japanese corpus of referring expressions used in a situated collaboration task.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th European Workshop on Natural Language Generation (ENLG</booktitle>
<pages>110--113</pages>
<contexts>
<context position="3794" citStr="Spanger et al., 2009" startWordPosition="540" endWordPosition="543">ra were constructed primarily for information extraction research, thus were annotated with co-reference relations within texts. Also in the language generation community, several corpora lhttp://www.nlpir.nist.gov/related projects/muc/ zhttp://www.itl.nist.gov/iad/tests/ace/ 38 Proceedings of the 8th Workshop on Asian Language Resources, pages 38–46, Beijing, China, 21-22 August 2010. c�2010 Asian Federation for Natural Language Processing have been developed (Di Eugenio et al., 2000; Byron, 2005; van Deemter et al., 2006; Foster and Oberlander, 2007; Foster et al., 2008; Stoia et al., 2008; Spanger et al., 2009a; Belz et al., 2010). Unlike the corpora of MUC and ACE, many are collected from situated dialogues, and therefore include multimodal information (e.g. gestures and eye-gaze) other than just transcribed text (Martin et al., 2007). Foster and Oberlander (2007) emphasised that any corpus for language generation should include all possible contextual information at the appropriate granularity. Since constructing a dialogue corpus generally requires experiments for data collection, this kind of corpus tends to be small-scale compared with corpora for reference resolution. Against this background,</context>
<context position="5580" citStr="Spanger et al., 2009" startWordPosition="815" endWordPosition="818">contribute to augmenting the resources of multimodal dialogue corpora annotated with reference relations which have been minor in number compared to other types of text corpora. From the point of view of reference generation, our corpora contribute to increasing the resources available that can be used to further research of this kind. In addition, our corpora contribute to comparative studies of human referential behaviour in different languages The structure of the paper is as follows. Section 2 describes the experimental set-up for data collection which was introduced in our previous work (Spanger et al., 2009a). The setting is basically the same for the construction of the English corpus. Section 3 explains the annotation scheme adopted in our corpora, followed by a description of a preliminary analysis of the corpora in section 4. Section 5 briefly mentions related work to highlight the characteristics of our corpora. Finally, Section 6 concludes the paper and looks at possible future directions. Figure 1: Screenshot of the Tangram simulator 2 Data collection 2.1 Experimental set-up We recruited subjects in pairs of friends and colleagues. Each pair was instructed to solve Tangram puzzles collabo</context>
<context position="7632" citStr="Spanger et al., 2009" startWordPosition="1171" endWordPosition="1174"> other as the operator. The operator has a mouse for manipulating Tangram pieces, but does not have a goal shape on the screen. The solver has a goal shape on the screen but does not have a mouse. This setting naturally leads to a situation where given a certain goal shape, the solver thinks of the necessary arrangement of the pieces and gives instructions to the operator how to move them, while the operator manipulates the pieces with the mouse goal shape working area 39 according to the solver’s instructions. Figure 2: Picture of the experiment setting As we mentioned in our previous study (Spanger et al., 2009a), this interaction produces frequent use of referring expressions intended to distinguish specific pieces of the puzzle. In our Tangram simulator, all pieces are of the same color, thus color is not useful in identifying a specific piece, i.e. only size and shape are discriminative object-intrinsic attributes. Instead, we can expect other attributes such as spatial relations and deictic reference to be used more often. Each pair of participants sat side by side as shown in Figure 2. Each participant had his/her own computer display showing the shared working area. A room-divider screen was s</context>
<context position="26068" citStr="Spanger et al., 2009" startWordPosition="4345" endWordPosition="4348">very different languages, English and Japanese. 44 Table 7: The REX-J corpus family name puzzle #pairs #dialg. #valid status T2008-08 Tangram 6 24 24 completed T2009-03 Tangram 10 40 16 completed T2009-11 Tangram 10 36 27 validating N2009-11 Tangram 5 20 8 validating P2009-11 Polyomino 7 28 24 annotating D2009-112-Tangram 7 42 24 annotating 6 Conclusion and future work This paper presented an overview of our EnglishJapanese bilingual multimodal corpora of referring expressions in a collaborative problem solving setting. The Japanese corpus was completed and has already been used for research (Spanger et al., 2009b; Spanger et al., 2010; Iida et al., 2010), but the English counterpart is still undergoing annotation. We have also presented a preliminary comparative analysis of these corpora in terms of the task performance and usage of referring expressions. We found a significant difference of the task performance, which could be attributed to the difference in diversity of subjects. We have tentative results on the usage of referring expressions, since only four English dialogues are available at the moment. The data collection experiments were conducted in August 2008 for Japanese and in March 2010 f</context>
</contexts>
<marker>Spanger, Yasuhara, Iida, Tokunaga, 2009</marker>
<rawString>Spanger, Philipp, Masaaki Yasuhara, Ryu Iida, and Takenobu Tokunaga. 2009a. A Japanese corpus of referring expressions used in a situated collaboration task. In Proceedings of the 12th European Workshop on Natural Language Generation (ENLG 2009), pages 110 – 113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Spanger</author>
<author>Masaaki Yasuhara</author>
<author>Ryu Iida</author>
<author>Takenobu Tokunaga</author>
</authors>
<title>Using extra linguistic information for generating demonstrative pronouns in a situated collaboration task.</title>
<date>2009</date>
<booktitle>In Proceedings of PreCogSci</booktitle>
<contexts>
<context position="3794" citStr="Spanger et al., 2009" startWordPosition="540" endWordPosition="543">ra were constructed primarily for information extraction research, thus were annotated with co-reference relations within texts. Also in the language generation community, several corpora lhttp://www.nlpir.nist.gov/related projects/muc/ zhttp://www.itl.nist.gov/iad/tests/ace/ 38 Proceedings of the 8th Workshop on Asian Language Resources, pages 38–46, Beijing, China, 21-22 August 2010. c�2010 Asian Federation for Natural Language Processing have been developed (Di Eugenio et al., 2000; Byron, 2005; van Deemter et al., 2006; Foster and Oberlander, 2007; Foster et al., 2008; Stoia et al., 2008; Spanger et al., 2009a; Belz et al., 2010). Unlike the corpora of MUC and ACE, many are collected from situated dialogues, and therefore include multimodal information (e.g. gestures and eye-gaze) other than just transcribed text (Martin et al., 2007). Foster and Oberlander (2007) emphasised that any corpus for language generation should include all possible contextual information at the appropriate granularity. Since constructing a dialogue corpus generally requires experiments for data collection, this kind of corpus tends to be small-scale compared with corpora for reference resolution. Against this background,</context>
<context position="5580" citStr="Spanger et al., 2009" startWordPosition="815" endWordPosition="818">contribute to augmenting the resources of multimodal dialogue corpora annotated with reference relations which have been minor in number compared to other types of text corpora. From the point of view of reference generation, our corpora contribute to increasing the resources available that can be used to further research of this kind. In addition, our corpora contribute to comparative studies of human referential behaviour in different languages The structure of the paper is as follows. Section 2 describes the experimental set-up for data collection which was introduced in our previous work (Spanger et al., 2009a). The setting is basically the same for the construction of the English corpus. Section 3 explains the annotation scheme adopted in our corpora, followed by a description of a preliminary analysis of the corpora in section 4. Section 5 briefly mentions related work to highlight the characteristics of our corpora. Finally, Section 6 concludes the paper and looks at possible future directions. Figure 1: Screenshot of the Tangram simulator 2 Data collection 2.1 Experimental set-up We recruited subjects in pairs of friends and colleagues. Each pair was instructed to solve Tangram puzzles collabo</context>
<context position="7632" citStr="Spanger et al., 2009" startWordPosition="1171" endWordPosition="1174"> other as the operator. The operator has a mouse for manipulating Tangram pieces, but does not have a goal shape on the screen. The solver has a goal shape on the screen but does not have a mouse. This setting naturally leads to a situation where given a certain goal shape, the solver thinks of the necessary arrangement of the pieces and gives instructions to the operator how to move them, while the operator manipulates the pieces with the mouse goal shape working area 39 according to the solver’s instructions. Figure 2: Picture of the experiment setting As we mentioned in our previous study (Spanger et al., 2009a), this interaction produces frequent use of referring expressions intended to distinguish specific pieces of the puzzle. In our Tangram simulator, all pieces are of the same color, thus color is not useful in identifying a specific piece, i.e. only size and shape are discriminative object-intrinsic attributes. Instead, we can expect other attributes such as spatial relations and deictic reference to be used more often. Each pair of participants sat side by side as shown in Figure 2. Each participant had his/her own computer display showing the shared working area. A room-divider screen was s</context>
<context position="26068" citStr="Spanger et al., 2009" startWordPosition="4345" endWordPosition="4348">very different languages, English and Japanese. 44 Table 7: The REX-J corpus family name puzzle #pairs #dialg. #valid status T2008-08 Tangram 6 24 24 completed T2009-03 Tangram 10 40 16 completed T2009-11 Tangram 10 36 27 validating N2009-11 Tangram 5 20 8 validating P2009-11 Polyomino 7 28 24 annotating D2009-112-Tangram 7 42 24 annotating 6 Conclusion and future work This paper presented an overview of our EnglishJapanese bilingual multimodal corpora of referring expressions in a collaborative problem solving setting. The Japanese corpus was completed and has already been used for research (Spanger et al., 2009b; Spanger et al., 2010; Iida et al., 2010), but the English counterpart is still undergoing annotation. We have also presented a preliminary comparative analysis of these corpora in terms of the task performance and usage of referring expressions. We found a significant difference of the task performance, which could be attributed to the difference in diversity of subjects. We have tentative results on the usage of referring expressions, since only four English dialogues are available at the moment. The data collection experiments were conducted in August 2008 for Japanese and in March 2010 f</context>
</contexts>
<marker>Spanger, Yasuhara, Iida, Tokunaga, 2009</marker>
<rawString>Spanger, Philipp, Masaaki Yasuhara, Ryu Iida, and Takenobu Tokunaga. 2009b. Using extra linguistic information for generating demonstrative pronouns in a situated collaboration task. In Proceedings of PreCogSci 2009: Production of Referring Expressions: Bridging the gap between computational and empirical approaches to reference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Spanger</author>
<author>Ryu Iida</author>
<author>Takenobu Tokunaga</author>
<author>Asuka Teri</author>
<author>Naoko Kuriyama</author>
</authors>
<title>Towards an extrinsic evaluation of referring expressions in situated dialogs.</title>
<date>2010</date>
<booktitle>Proceedings of the Sixth International Natural Language Generation Conference (INGL 2010),</booktitle>
<pages>135--144</pages>
<editor>In Kelleher, John, Brian Mac Namee, and Ielka van der Sluis, editors,</editor>
<contexts>
<context position="26091" citStr="Spanger et al., 2010" startWordPosition="4349" endWordPosition="4352">s, English and Japanese. 44 Table 7: The REX-J corpus family name puzzle #pairs #dialg. #valid status T2008-08 Tangram 6 24 24 completed T2009-03 Tangram 10 40 16 completed T2009-11 Tangram 10 36 27 validating N2009-11 Tangram 5 20 8 validating P2009-11 Polyomino 7 28 24 annotating D2009-112-Tangram 7 42 24 annotating 6 Conclusion and future work This paper presented an overview of our EnglishJapanese bilingual multimodal corpora of referring expressions in a collaborative problem solving setting. The Japanese corpus was completed and has already been used for research (Spanger et al., 2009b; Spanger et al., 2010; Iida et al., 2010), but the English counterpart is still undergoing annotation. We have also presented a preliminary comparative analysis of these corpora in terms of the task performance and usage of referring expressions. We found a significant difference of the task performance, which could be attributed to the difference in diversity of subjects. We have tentative results on the usage of referring expressions, since only four English dialogues are available at the moment. The data collection experiments were conducted in August 2008 for Japanese and in March 2010 for English. Between the</context>
</contexts>
<marker>Spanger, Iida, Tokunaga, Teri, Kuriyama, 2010</marker>
<rawString>Spanger, Philipp, Ryu Iida, Takenobu Tokunaga, Asuka Teri, and Naoko Kuriyama. 2010. Towards an extrinsic evaluation of referring expressions in situated dialogs. In Kelleher, John, Brian Mac Namee, and Ielka van der Sluis, editors, Proceedings of the Sixth International Natural Language Generation Conference (INGL 2010), pages 135– 144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert J Sternberg</author>
<author>Janet E Davidson</author>
<author>editors</author>
</authors>
<title>The Nature of Insight.</title>
<date>1996</date>
<publisher>The MIT Press.</publisher>
<marker>Sternberg, Davidson, editors, 1996</marker>
<rawString>Sternberg, Robert J. and Janet E. Davidson, editors. 1996. The Nature of Insight. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Stoia</author>
<author>Darla Magdalene Shockley</author>
<author>Donna K Byron</author>
<author>Eric Fosler-Lussier</author>
</authors>
<title>SCARE: A situated corpus with annotated referring expressions.</title>
<date>2008</date>
<booktitle>In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>28--30</pages>
<contexts>
<context position="3772" citStr="Stoia et al., 2008" startWordPosition="536" endWordPosition="539">project. These corpora were constructed primarily for information extraction research, thus were annotated with co-reference relations within texts. Also in the language generation community, several corpora lhttp://www.nlpir.nist.gov/related projects/muc/ zhttp://www.itl.nist.gov/iad/tests/ace/ 38 Proceedings of the 8th Workshop on Asian Language Resources, pages 38–46, Beijing, China, 21-22 August 2010. c�2010 Asian Federation for Natural Language Processing have been developed (Di Eugenio et al., 2000; Byron, 2005; van Deemter et al., 2006; Foster and Oberlander, 2007; Foster et al., 2008; Stoia et al., 2008; Spanger et al., 2009a; Belz et al., 2010). Unlike the corpora of MUC and ACE, many are collected from situated dialogues, and therefore include multimodal information (e.g. gestures and eye-gaze) other than just transcribed text (Martin et al., 2007). Foster and Oberlander (2007) emphasised that any corpus for language generation should include all possible contextual information at the appropriate granularity. Since constructing a dialogue corpus generally requires experiments for data collection, this kind of corpus tends to be small-scale compared with corpora for reference resolution. Ag</context>
<context position="23566" citStr="Stoia et al., 2008" startWordPosition="3939" endWordPosition="3942">rticipants, who worked together on a simple 2-D design task, buying and arranging furniture for two rooms. The COCONUT corpus is limited in annotations which describe symbolic object information such as object intrinsic attributes and location in discrete co-ordinates. As an initial work of constructing a corpus for collaborative tasks, the COCONUT corpus can be characterised as having a rather simple domain as well 6We called such expressions as action-mentioning expressions (AME) in our previous work. as limited annotation. The QUAKE corpus (Byron, 2005) and its successor, the SCARE corpus (Stoia et al., 2008) deal with a more complex domain, where two participants collaboratively play a treasure hunting game in a 3-D virtual world. Despite the complexity of the domain, the participants were only allowed limited actions, e.g. moving step forward, pushing a button etc. As a part of the JAST project, the Joint Construction Task (JCT) corpus was created based on dialogues in which two participants constructed a puzzle (Foster et al., 2008). The setting of the experiment is quite similar to ours except that both participants have even roles. Since our main concern is referring expressions, we believe o</context>
</contexts>
<marker>Stoia, Shockley, Byron, Fosler-Lussier, 2008</marker>
<rawString>Stoia, Laura, Darla Magdalene Shockley, Donna K. Byron, and Eric Fosler-Lussier. 2008. SCARE: A situated corpus with annotated referring expressions. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC 2008), pages 28–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroaki Suzuki</author>
<author>Keiga Abe</author>
<author>Kazuo Hiraki</author>
<author>Michiko Miyazaki</author>
</authors>
<title>Cue-readiness in insight problem-solving.</title>
<date>2001</date>
<booktitle>In Proceedings of the 23rd Annual Meeting of the Cognitive Science Society,</booktitle>
<pages>1012--1017</pages>
<contexts>
<context position="8831" citStr="Suzuki et al., 2001" startWordPosition="1365" endWordPosition="1368">-divider screen was set between the solver (right side) and operator (left side) to prevent the operator from seeing the goal shape on the solver’s screen, and to restrict their interaction to speech only. Figure 3: The goal shapes given to the subjects Each participant pair was assigned 4 trials consisting of two symmetric and two asymmetric goal shapes as shown in Figure 3. In Cognitive Science, a wide variety of different kinds of puzzles have been employed extensively in the field of Insight Problem solving. This has been termed the “puzzle-problem approach” (Sternberg and Davidson, 1996; Suzuki et al., 2001) and in the case of physical puzzles has relatively often involved puzzle tasks of symmetric shapes like the so-called T-puzzle, e.g. (Kiyokawa and Nakazawa, 2006). In more recent work Tangram puzzles have been used as a means to study various new aspects of human problem solving approaches, including collection of of eye-gaze information (Baran et al., 2007). In order to collect data as broadly as possible in this context, we set up puzzle-problems including both symmetrical as well as asymmetrical ones as shown in Figure 3. The participants exchanged their roles after two trials, i.e. a part</context>
</contexts>
<marker>Suzuki, Abe, Hiraki, Miyazaki, 2001</marker>
<rawString>Suzuki, Hiroaki, Keiga Abe, Kazuo Hiraki, and Michiko Miyazaki. 2001. Cue-readiness in insight problem-solving. In Proceedings of the 23rd Annual Meeting of the Cognitive Science Society, pages 1012 – 1017.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kees van Deemter</author>
<author>Ielka van der Sluis</author>
<author>Albert Gatt</author>
</authors>
<title>Building a semantically transparent corpus for the generation of referring expressions.</title>
<date>2006</date>
<booktitle>In Proceedings of the Fourth International Natural Language Generation Conference,</booktitle>
<pages>130--132</pages>
<marker>van Deemter, van der Sluis, Gatt, 2006</marker>
<rawString>van Deemter, Kees, Ielka van der Sluis, and Albert Gatt. 2006. Building a semantically transparent corpus for the generation of referring expressions. In Proceedings of the Fourth International Natural Language Generation Conference, pages 130–132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ielka van der Sluis</author>
<author>Junko Nagai</author>
<author>Saturnino Luz</author>
</authors>
<title>Producing referring expressions in dialogue: Insights from a translation exercise.</title>
<date>2009</date>
<booktitle>In Proceedings of PreCogSci</booktitle>
<marker>van der Sluis, Nagai, Luz, 2009</marker>
<rawString>van der Sluis, Ielka, Junko Nagai, and Saturnino Luz. 2009. Producing referring expressions in dialogue: Insights from a translation exercise. In Proceedings of PreCogSci 2009: Production of Referring Expressions: Bridging the gap between computational and empirical approaches to reference.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>