<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006091">
<title confidence="0.995716">
Extracting Formulaic and Free Text Clinical Research Articles Metadata
using Conditional Random Fields
</title>
<author confidence="0.9978155">
Sein Lin&apos; Jun-Ping Ng&apos; Shreyasee Pradhan&apos;
Jatin Shah&apos; Ricardo Pietrobon&apos; Min-Yen Kan&apos;
</author>
<affiliation confidence="0.999771">
&apos;Department of Computer Science, National University of Singapore
</affiliation>
<email confidence="0.825526">
justin@seinlin.com, {junping,kanmy}@comp.nus.edu.sg
</email>
<affiliation confidence="0.448251">
&apos;Duke-NUS Graduate Medical School Singapore
</affiliation>
<email confidence="0.996623">
{shreyasee.pradhan,jashstar}@gmail.com, rpietro@duke.edu
</email>
<sectionHeader confidence="0.993823" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999939625">
We explore the use of conditional random
fields (CRFs) to automatically extract impor-
tant metadata from clinical research articles.
These metadata fields include formulaic meta-
data about the authors, extracted from the title
page, as well as free text fields concerning the
study’s critical parameters, such as longitudi-
nal variables and medical intervention meth-
ods, extracted from the body text of the arti-
cle. Extracting such information can help both
readers conduct deep semantic search of arti-
cles and policy makers and sociologists track
macro level trends in research. Preliminary re-
sults show an acceptable level of performance
for formulaic metadata and a high precision
for those found in the free text.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998933125">
The increasing number of clinical research articles
published each year is a double-edged sword. As
of 2009, PubMed indexed over 19 million citations,
over which 700,000 were added over the previous
year1. While the research results further our knowl-
edge and competency in the field, the volume of in-
formation poses a challenge to researchers who need
to stay up to speed. Even within a single clinical
research area, there can be hundreds of new clini-
cal research results per year. Policy makers, who
need to decide which clinical research proposals to
fund and fast-track, and which proposals could tag
onto existing research and cost share, have equally
daunting information synthesis issues that have both
monetary and public health implications (Johnston
et al., 2006).
</bodyText>
<footnote confidence="0.881165">
1http://www.nlm.nih.gov/bsd/bsd_key.html
</footnote>
<bodyText confidence="0.999179277777777">
Systematic reviews – secondary publications that
compile evidence and best practices from primary
research results – partially address these concerns,
but can take years before their final publication, due
to liability and administrative overheads. In many
fast-paced fields of clinical practice, such guidelines
can be outdated by the time of publication. Re-
searchers and policy makers alike still need effective
tools to help them search, digest and organize their
knowledge of the primary literature.
One avenue that researchers have turned to is the
use of automated information extraction (IE). We
distinguish between two distinct uses of Information
Extraction: 1) extracting regular, formulaic fields
(e.g., author names, their institutional affiliation and
email addresses), and 2) extracting free text descrip-
tions of key study parameters (e.g., longitudinal vari-
ables, observation time periods, databases utilized).
Extracting such formulaic fields helps policy
makers determine returns on health-care investments
(Kwan et al., 2007), as well as researchers in large
scale sociological studies understand macroscopic
trends in clinical research authorship and topic shifts
over time (Cappell and Davis, 2008; Lin et al.,
2008). But due to the wide variety of publication
venues for clinical research, even performing the
seemingly simple task of author name extraction
turns out to be difficult, and published studies thus
far have relied on manual analysis and extraction.
Proposals to extract values of key study parame-
ters may have more profound effects. Deeper char-
acterization of research artifacts will enable more
semantically-oriented searches of the clinical lit-
erature. Further programmatic access allows and
encourages data sharing of raw clinical trial re-
sults, databases and cohorts (Piwowar and Chap-
</bodyText>
<page confidence="0.985096">
90
</page>
<note confidence="0.7557305">
Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents, pages 90–95,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999905290322581">
man, 2008) that may result in cost sharing across
on-going studies, saving funds for other deserving
clinical trials.
On one hand, the medical community has been
proactive in using natural language processing
(NLP) and information extraction technology in an-
alyzing their own literature. Many approaches to
metadata extraction have used regular expressions
or baseline supervised machine learning classifiers.
However, these techniques are not considered state-
of-the-art.
On the other hand, much of the work from the
NLP community applied to biomedical research has
been on in-depth relationship extraction, such as
the identification of gene pathways and protein-
protein interaction (PPI). While certainly difficult
and worthwhile problems to solve, there is room for
contribution even at the basic IE level, to retrieve
both regular and free form metadata fields.
We address this need in this paper. We apply a
linear-chain Conditional Random Field (CRF) (Laf-
ferty et al., 2001) as our methodology for extracting
metadata fields. CRFs are a sequence labeling model
that has shown good performance over a large num-
ber of information extraction tasks. We conduct ex-
periments using basic token features to assess their
efficacy for metadata extraction. While preliminary,
our results indicate that CRFs are suitable for iden-
tifying formulaic metadata, but may need additional
deeper, natural language processing features to iden-
tify free text fields.
</bodyText>
<sectionHeader confidence="0.999766" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999964557692308">
Many researchers have recognized the utility of the
application of IE on biomedical text. These works
have focused mainly on the application of well-
known machine learning algorithms to tag impor-
tant biomedical entities such as genes and proteins
within biomedical articles. (Tanabe and Wilbur,
2002) uses a Naive Bayes classifier, while (Zhou et
al., 2004) uses use a Hidden Markov Model (HMM).
The Conditional Random Field (CRF) learning
model combines the strengths of two well known
methods: the Hidden Markov Model (HMM), a se-
quence labeling methodology, and the Maximum
Entropy Model, a classification methodology. It
models the probability of a class label y for a given
token, directly from the observable stream of tokens
x in direct (discriminative) manner, rather than as
a by-product as in generative methods such as in
HMMs. A CRF can model arbitrary dependencies
between observation and class variables, but most
commonly, a simple linear chain sequence is used
(which connects adjacent class variables to each
other and to their corresponding observation vari-
able), making them topologically similar to HMMs.
Since their inception in 2001, (linear chain) CRFs
have been applied extensively to many areas, includ-
ing the biomedical field. CRFs have been used for
the processing and extraction of important medical
entities and their relationships among each other.
(He and Kayaalp, 2008) reports on the suitability of
CRFs to find biological entities, combining basic or-
thographic token features with features derived from
semantic lexicons such as UMLS, ABGene, Sem-
Rep and MetaMap. In a related vein, CRFs have
been applied to gene map and relationship identifi-
cation as well (Bundschus et al., 2008; Talreja et al.,
2004).
In a different domain, digital library practition-
ers have also studied how to extract formulaic meta-
data to enable more comprehensive article index-
ing. To extract author and title information, systems
have used both the Support Vector Machine (SVM)
(Han et al., 2003) and CRFs (Peng and McCallum,
2004; Councill et al., 2008). These works have been
applied largely to the computer science community
and have not yet been extensively tested on biomed-
ical and clinical research articles.
Our work differs from the above by making use
of CRFs to extract fields in clinical text. Similar
lexical-based features are employed, however in ad-
dition to regular author metadata, we also attempt to
extract domain-specific fields from the body text of
the article.
</bodyText>
<sectionHeader confidence="0.986434" genericHeader="method">
3 Method
</sectionHeader>
<bodyText confidence="0.998378428571429">
External to the scope of the research presented here,
our wider project goal focuses on constructing a
knowledge base of clinical researchers, databases,
instruments and expertise in the Asia-Pacific region.
Dataset. In this pilot study, we created a gold
standard dataset consisting of freely-available ar-
ticles available from PubMedCentral. These arti-
</bodyText>
<page confidence="0.993766">
91
</page>
<bodyText confidence="0.994985928571429">
cles focused on health services research in the Asia-
Pacific region. In particular, we selected open-
access full-text literature documenting oncological
and cardio-vascular studies in the region, over a
three year period from 2005 to 2008.
By constructing an appropriate staged query with
PubMed, we obtained an initial listing of 260 arti-
cles. From an initial analysis, we determined that
a significant portion (-1/3) of the retrieved full-
text were not primary research, but reviews, case
studies, editorials or descriptions. After eliminating
these, the remaining 185 articles were earmarked to
be manually tagged by clinicians affiliated with the
project. Since the resulting corpus compiles arti-
cles across different journals and other publication
venues, their presentation of even the formulaic au-
thor metadata varied.
The clinicians were given rich text (RTF) versions
of the original HTML documents retrieved from
PubMed. They identified and extracted only the sec-
tions of the articles that had pertinent data classes to
tag. This process excluded most introductory, dis-
cussion and result sections, preserving the sections
that described the study and results at a high level
(e.g., Demographics and Methods).
After an initial training session, each clinician
used a word processor to manually insert opening
and closing XML tags for the tagset for a particular
subsection of the 185-article corpus. Due to the high
cost of clinician time, we chose to emphasize cover-
age, rather than have the clinicians multiply annotate
the same articles. As a result, we could not calculate
annotation agreement, but feel that the repeatability
of the annotation was addressed by the initial train-
ing. At the time of writing, 93 articles have been
completely tagged and sectioned, with the remainder
in progress. The average length of the documents is
about 1300 words. Once the dataset has been com-
pleted, we plan to release the annotated data offsets
to the public, to encourage comparative evaluation.
The clinicians annotated the following Formulaic
Author Metadata (3 classes):
</bodyText>
<listItem confidence="0.997104">
• Author (Au): The names of the authors of the
study;
• E-mail (Em): The email addresses of the corre-
sponding authors of the study;
• Institution (In): The names of the institutions
that the authors are from.
</listItem>
<bodyText confidence="0.996971875">
Such metadata can be used to build an author ci-
tation network for macro trend analysis. Note that
this data is obtained from the article’s title page it-
self, and not from any references to source articles,
which have been the target of previous studies on
CRF-based information extraction (Peng and Mc-
Callum, 2004; Councill et al., 2008). The clinicians
also annotated the following Key Study Parameters
</bodyText>
<listItem confidence="0.971439233333333">
(10 classes):
• Age Group (Ag): The age range of the subjects
of the study (e.g., 45 and 80 years, 21-79
years);
• Data Analysis Name (Da): The name of the
method or software used in the analysis of data
collected for the study (e.g., proportional haz-
ards survival models, SAS package);
• Data Collection Method (Dc): The data collec-
tion methods for the study (e.g., medical
records, review of medical records and linkage
to computerized discharge abstracts);
• Database Name (Dn): The name of any biomed-
ical databases used or mentioned in the study
(e.g., Queensland Cancer Registry, National
Death Index, population-based registry);
• Data Type (Dt): The type of data involved in the
study (e.g., Cohort study, retrospectively);
• Geographical Area (Ga): The names of the ge-
ographical area in which an experiment takes
place or the subjects are from (e.g., Pune,
Switzerland);
• Intervention (Iv): The name of medical interven-
tion used in the study (e.g., surgery, radiother-
apy, chemotherapy, radio-frequency ablation);
• Longitudinal Variables (Lv): Data collected
over the observation period (e.g., subjects);
• Number of Observations (No): The number of
cases or subjects observed in the study (e.g.,
158 Indigenous, 84 patients);
</listItem>
<page confidence="0.687649">
92
</page>
<listItem confidence="0.912114">
• Time Period (Tp): The duration of an experi-
ment or observation in the study (e.g., 1997–
2002, between January 1988 and June 2006).
</listItem>
<bodyText confidence="0.999572925925926">
As can be seen from the examples, the tagging
guidelines loosely define the criteria for tagging. For
some classes, clinicians tagged entire noun phrases
or clauses, and for others, only numeric values and
modifiers were tagged. This variability arises from
the difficulty in tagging these free text fields.
Features. The CRF model requires a set of bi-
nary features to serve as a representation of the text.
A simple baseline is to use the presence/absence of
particular tokens as features. The CRF software im-
plementation we utilized is CRF++2, which com-
piles the binary features automatically from a con-
text window centered the current labeling problem
instance.
We first preprocess an input article from its RTF
representation and convert it into plain text. This
is a lossy transformation that discards font informa-
tion and corrupts mathematical symbols that could
be helpful in the detection task. We take hyphenated
token forms (e.g., 2006-2007) and convert them into
individual tokens. The plain text is processed to note
the specific locations of the XML tags for the learn-
ing process. The bulk of the words in each article
were not tagged by clinicians, and for these words,
we assigned a Not Applicable (NA) tag. We list
the simple inventory of feature types that we use for
classification.
</bodyText>
<listItem confidence="0.966792777777778">
• Vocabulary: Individual word tokens are stemmed
with Porter’s stemming algorithm (Porter,
1980) and down-cased to collapse orthographic
variants. Each word token is then used as an
individual feature. This feature alone was used
to compile baseline performance as discussed
later in evaluation.
• Lexical: Lists of keywords were compiled to lend
additional weight for specific classes. In par-
</listItem>
<bodyText confidence="0.9875406">
ticular, we compiled lists of months, common
names, cue words that signaled observations,
institution names and data analyses methods.
For example, a list of common given and sur-
name names is useful for the Au field; while a
</bodyText>
<footnote confidence="0.629287">
2http://crfpp.sourceforge.net
</footnote>
<bodyText confidence="0.999272571428572">
list of months and their abbreviated forms help
to identify Tp. Each list constitutes a different
feature. As an example, in the case of human
names, the names Alice and Auburn are on the
list. If a word token corresponds to any of the
words in the list, the corresponding feature is
turned on (e.g., isApersonName).
</bodyText>
<listItem confidence="0.98772055">
• Position: If a word token is within the first 15
lines of an article, this feature is turned on. This
specifically caters to limit the scope of the for-
mulaic author metadata fields, to match them
only at the beginning of the article.
• Email: We create a specific feature for email ad-
dresses that is turned on when a particular word
token is matched by a handwritten regular ex-
pression.
• Numeric: For some free text classes, such as Ag,
No and Tp, the tagged text often contains nu-
meric data. This can be present in both numeric
and word form (e.g., 23 versus. twenty-three).
We turn this feature on for a token solely con-
taining digits or numeric word forms.
• Orthographic: Orthographic features, such as
the capitalization of a word token are useful to
help identify proper nouns and names. If there
are capital letters within a word token, this fea-
ture is turned on.
</listItem>
<sectionHeader confidence="0.995948" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.9997530625">
To ascertain the efficacy of our proposed solution,
three-fold cross validation (CV) was first performed
on a dataset comprising the 93 articles which have
been completely annotated.
Baseline. For the purpose of comparison, we cre-
ated a baseline system that utilizes the same CRF++
toolkit but uses only the vocabulary feature type
with a five-word window (two previous tokens, the
target token to be classified, and two subsequent to-
kens). The performance of this baseline system is
shown in Table 1, where the standard classification
performance measures of precision, recall and Fl are
given. Count measures the number of word tokens
that are predicted as belonging to the stated field.
Discussion. We see that the overwhelming major-
ity of tokens are not tagged (belonging to class NA).
</bodyText>
<page confidence="0.997221">
93
</page>
<bodyText confidence="0.999766176470588">
The skewness of the dataset is not uncommon for IE
tasks.
The baseline results show weak performance
across the board. Clearly, significant feature engi-
neering could help boost performance. Of particular
surprise was the relatively weak performance on the
formulaic metadata. From our manual analysis, it
was clear that the wide range and variety of tokens
present in names and institutions barred the system
from achieving good performance on these classes.
Comparative studies in citation and reference pars-
ing usually peg classification performance of these
classes at the 95% and above level.
Without suitable customization, detection of the
key study parameters was also not possible. Only
relatively common fields could be captured by the
CRF, and when captured were more precise but
lacked enough data to build a model with any ac-
ceptable level of recall.
Table 2 illustrates the improved results obtained
by running CRF++ with all of the described features
on the same dataset. The same five-word window
size is used for the vocabulary feature. As seen, sig-
nificant improvements over the baseline are obtained
for all except four fields — Da, Dc, Iv, and Lv.
These four fields were the classes with the most vari-
ability in annotation. For example, the data collec-
tion methodologies (Dc) and interventions (Iv) are
often captured as long sentence fragments and hard
to model with individual word cues.
The largest improvements occurred for the classes
of age groups Ag and time periods Tp, both of which
benefited from the addition of the numeric feature
which boosted recognition performance.
</bodyText>
<sectionHeader confidence="0.998294" genericHeader="method">
5 Future Work
</sectionHeader>
<bodyText confidence="0.998549727272727">
The work presented here is ongoing, and based on
our current results, we are planning to re-examine
the quality of the annotations and refine our anno-
tation guideline and scheme. We discovered cases
where the CRF tagger correctly annotated key study
parameters which the annotators had missed or mis-
keyed. Drawing on lessons from the initial anno-
tation exercise, a more comprehensive guideline is
planned which will provide concise instructions with
accompanying annotation examples.
We also plan to enrich the feature set. The current
</bodyText>
<table confidence="0.999711210526316">
Field Prec. Recall Fl Count
Formulaic Author Metadata
Au 84.6 74.3 79.1 1818
Em 93.4 92.2 92.8 151
In 80.5 69.5 74.6 3906
Macro Avg. 86.2 78.7 82.3
Key Study Parameters
Ag 29.0 40.4 33.8 334
Da 61.0 39.0 47.6 708
Dc 8.3 3.2 4.6 48
Dn 35.9 15.1 21.2 92
Dt 52.8 26.8 35.5 36
Ga 7.3 4.5 5.6 41
Iv 4.6 1.4 2.1 22
Lv 15.4 20.0 17.4 13
No 14.4 5.8 8.3 125
Tp 73.6 55.8 63.5 261
Macro Avg. 30.2 21.2 24.0
NA 97.1 98.5 97.8 119998
</table>
<tableCaption confidence="0.965408">
Table 1: Baseline aggregated results over 93 tagged arti-
cles under 3 fold cross validation.
</tableCaption>
<table confidence="0.999905789473684">
Field P. Recall Fl Count
Formulaic Author Metadata
Au 89.0 85.3 87.1 7312
Em 100.0 97.3 98.6 154
In 91.3 78.0 84.1 4515
Macro Avg. 93.4 86.6 89.9
Key Study Parameters
Ag 64.3 35.4 45.7 240
Da 79.3 37.2 50.6 2296
Dc 20.0 1.6 2.9 125
Dn 42.5 10.5 16.8 219
Dt 70.0 19.7 30.7 71
Ga 43.7 10.4 16.8 62
Iv 40.0 2.7 5.1 73
Lv 0.0 0.0 0.0 10
No 43.4 10.7 17.1 308
Tp 82.7 69.4 75.5 344
Macro Avg. 48.5 19.7 26.1
NA 97.5 99.3 98.4 120430
</table>
<tableCaption confidence="0.976754">
Table 2: Aggregated results using the full feature set un-
der 3 fold cross validation.
</tableCaption>
<page confidence="0.998869">
94
</page>
<bodyText confidence="0.999971466666667">
set employed is still simplistic and serves as a de-
velopmental platform for furthering our feature en-
gineering process. For example, the vocabulary, po-
sition and word lists features can be further modified
to capture more fined-grained information.
Once we exhaust the development of basic fea-
tures, our future work will attempt to harness deeper,
semantic features, making use of part-of-speech
tags, grammar parses, and named entity recognition
for example. The incorporation of these features will
likely be useful in improving the performance of the
CRF learner. We also plan to use both clinical re-
search and general medical ontologies (e.g., UMLS)
to gain additional insight on individual terms that
have special domain-specific meanings.
</bodyText>
<sectionHeader confidence="0.999561" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999912583333333">
We have developed a CRF-based information ex-
traction system that targets two different types of
metadata present in clinical articles. Our work in
progress demonstrates that formulaic author meta-
data can be effectively extracted using the CRF
methodology. By further performing feature engi-
neering, we were able to extract key study parame-
ters with a moderate level of success. Our post eval-
uation analysis indicates that more careful attention
to annotation and feature engineering will be neces-
sary to garner acceptable performance of such im-
portant clinical study parameters.
</bodyText>
<sectionHeader confidence="0.99764" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998415">
We like to express our gratitude to the reviewers
whose insightful comments and pointers to addi-
tional relevant studies have helped improve the pa-
per.
</bodyText>
<sectionHeader confidence="0.999282" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999865546875">
M. Bundschus, M. Dejori, M. Stetter, V. Tresp, and H.P.
Kriegel. 2008. Extraction of semantic biomedical
relations from text using conditional random fields.
BMC bioinformatics, 9(1):207.
Mitchell S. Cappell and Michael Davis. 2008. A signif-
icant decline in the american domination of research
in gastroenterology with increasing globalization from
1980 to 2005: An analysis of american authorship
among 8,251 articles. The American Journal of Gas-
troenterology, 103:1065–1074.
Isaac G. Councill, C. Lee Giles, and Min-Yen Kan. 2008.
ParsCit: An open-source CRF reference string parsing
package. In Proceedings of the Language Resources
and Evaluation Conference (LREC 08), Marrakesh,
Morrocco.
Hui Han, C. Giles, E. Manavoglu, H. Zha, Z. Zhang, and
Ed Fox. 2003. Automatic document meta-data extrac-
tion using support vector machines. In Proceedings of
Joint Conference on Digital Libraries.
Ying He and Mehmet Kayaalp. 2008. Biological entity
recognition with conditional random fields. In Pro-
ceedings of the Annual Symposium of the American
Medical Informatics Association (AMIA), pages 293–
297.
S.C. Johnston, J.D. Rootenberg, S Katrak, Wade S.
Smith, and Jacob S Elkins. 2006. Effect of a us na-
tional institutes of health programme of clinical trials
on public health and costs. Lancet, 367:13191327.
Patrick Kwan, Janice Johnston, Anne Fung, Doris SY
Chong, Richard Collins, and Su Lo. 2007. A system-
atic evaluation of payback of publicly funded health
and health services research in hong kong. BMC
Health Services Research, 7(1):121.
John Lafferty, Andrew McCallum, and Fernando Pereira.
2001. Conditional Random Fields: Probabilistic Mod-
els for Segmenting and Labeling Sequence Data. In
Proceedings of the International Conference on Ma-
chine Learning, pages 282–289.
JM Lin, JW Bohland, P Andrews, Burns GA, CB Allen,
and PP Mitra. 2008. An analysis of the abstracts pre-
sented at the annual meetings of the society for neuro-
science from 2001 to 2006. PLoS ONE, 3(e2052).
F. Peng and A. McCallum. 2004. Accurate information
extraction from research papers using conditional ran-
dom fields. In Proceedings of Human Language Tech-
nology Conference and North American Chapter of
the Association for Computational Linguistics (HLT-
NAACL), pages 329–336.
Heather A. Piwowar and Wendy W. Chapman. 2008.
Identifying data sharing in biomedical literature. In
Proceedings of the Annual Symposium of the Ameri-
can Medical Informatics Association (AMIA).
M.F. Porter. 1980. An Algorithm For Suffix Stripping.
14(3):130–137.
R. Talreja, A. Schein, S. Winters, and L. Ungar. 2004.
GeneTaggerCRF: An entity tagger for recognizing
gene names in text. Technical report, Univ. of Penn-
sylvania.
L. Tanabe and W.J. Wilbur. 2002. Tagging gene and
protein names in biomedical text. Bioinformatics,
18(8):1124.
G. Zhou, J. Zhang, J. Su, D. Shen, and C. Tan. 2004.
Recognizing names in biomedical texts: a machine
learning approach. Bioinformatics, 20(7):1178–1190.
</reference>
<page confidence="0.99908">
95
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.777910">
<title confidence="0.998237">Extracting Formulaic and Free Text Clinical Research Articles</title>
<author confidence="0.877067">using Conditional Random Fields</author>
<affiliation confidence="0.9409415">of Computer Science, National University of Graduate Medical School</affiliation>
<email confidence="0.99954">rpietro@duke.edu</email>
<abstract confidence="0.99390805882353">We explore the use of conditional random fields (CRFs) to automatically extract important metadata from clinical research articles. These metadata fields include formulaic metadata about the authors, extracted from the title page, as well as free text fields concerning the study’s critical parameters, such as longitudinal variables and medical intervention methods, extracted from the body text of the article. Extracting such information can help both readers conduct deep semantic search of articles and policy makers and sociologists track macro level trends in research. Preliminary results show an acceptable level of performance for formulaic metadata and a high precision for those found in the free text.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Bundschus</author>
<author>M Dejori</author>
<author>M Stetter</author>
<author>V Tresp</author>
<author>H P Kriegel</author>
</authors>
<title>Extraction of semantic biomedical relations from text using conditional random fields.</title>
<date>2008</date>
<journal>BMC bioinformatics,</journal>
<pages>9--1</pages>
<contexts>
<context position="7164" citStr="Bundschus et al., 2008" startWordPosition="1066" endWordPosition="1069">m topologically similar to HMMs. Since their inception in 2001, (linear chain) CRFs have been applied extensively to many areas, including the biomedical field. CRFs have been used for the processing and extraction of important medical entities and their relationships among each other. (He and Kayaalp, 2008) reports on the suitability of CRFs to find biological entities, combining basic orthographic token features with features derived from semantic lexicons such as UMLS, ABGene, SemRep and MetaMap. In a related vein, CRFs have been applied to gene map and relationship identification as well (Bundschus et al., 2008; Talreja et al., 2004). In a different domain, digital library practitioners have also studied how to extract formulaic metadata to enable more comprehensive article indexing. To extract author and title information, systems have used both the Support Vector Machine (SVM) (Han et al., 2003) and CRFs (Peng and McCallum, 2004; Councill et al., 2008). These works have been applied largely to the computer science community and have not yet been extensively tested on biomedical and clinical research articles. Our work differs from the above by making use of CRFs to extract fields in clinical text.</context>
</contexts>
<marker>Bundschus, Dejori, Stetter, Tresp, Kriegel, 2008</marker>
<rawString>M. Bundschus, M. Dejori, M. Stetter, V. Tresp, and H.P. Kriegel. 2008. Extraction of semantic biomedical relations from text using conditional random fields. BMC bioinformatics, 9(1):207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell S Cappell</author>
<author>Michael Davis</author>
</authors>
<title>A significant decline in the american domination of research in gastroenterology with increasing globalization from</title>
<date>2008</date>
<journal>The American Journal of Gastroenterology,</journal>
<pages>103--1065</pages>
<contexts>
<context position="3180" citStr="Cappell and Davis, 2008" startWordPosition="451" endWordPosition="454">(IE). We distinguish between two distinct uses of Information Extraction: 1) extracting regular, formulaic fields (e.g., author names, their institutional affiliation and email addresses), and 2) extracting free text descriptions of key study parameters (e.g., longitudinal variables, observation time periods, databases utilized). Extracting such formulaic fields helps policy makers determine returns on health-care investments (Kwan et al., 2007), as well as researchers in large scale sociological studies understand macroscopic trends in clinical research authorship and topic shifts over time (Cappell and Davis, 2008; Lin et al., 2008). But due to the wide variety of publication venues for clinical research, even performing the seemingly simple task of author name extraction turns out to be difficult, and published studies thus far have relied on manual analysis and extraction. Proposals to extract values of key study parameters may have more profound effects. Deeper characterization of research artifacts will enable more semantically-oriented searches of the clinical literature. Further programmatic access allows and encourages data sharing of raw clinical trial results, databases and cohorts (Piwowar an</context>
</contexts>
<marker>Cappell, Davis, 2008</marker>
<rawString>Mitchell S. Cappell and Michael Davis. 2008. A significant decline in the american domination of research in gastroenterology with increasing globalization from 1980 to 2005: An analysis of american authorship among 8,251 articles. The American Journal of Gastroenterology, 103:1065–1074.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isaac G Councill</author>
<author>C Lee Giles</author>
<author>Min-Yen Kan</author>
</authors>
<title>ParsCit: An open-source CRF reference string parsing package.</title>
<date>2008</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC 08),</booktitle>
<location>Marrakesh, Morrocco.</location>
<contexts>
<context position="7514" citStr="Councill et al., 2008" startWordPosition="1123" endWordPosition="1126">nd biological entities, combining basic orthographic token features with features derived from semantic lexicons such as UMLS, ABGene, SemRep and MetaMap. In a related vein, CRFs have been applied to gene map and relationship identification as well (Bundschus et al., 2008; Talreja et al., 2004). In a different domain, digital library practitioners have also studied how to extract formulaic metadata to enable more comprehensive article indexing. To extract author and title information, systems have used both the Support Vector Machine (SVM) (Han et al., 2003) and CRFs (Peng and McCallum, 2004; Councill et al., 2008). These works have been applied largely to the computer science community and have not yet been extensively tested on biomedical and clinical research articles. Our work differs from the above by making use of CRFs to extract fields in clinical text. Similar lexical-based features are employed, however in addition to regular author metadata, we also attempt to extract domain-specific fields from the body text of the article. 3 Method External to the scope of the research presented here, our wider project goal focuses on constructing a knowledge base of clinical researchers, databases, instrume</context>
<context position="10929" citStr="Councill et al., 2008" startWordPosition="1664" endWordPosition="1667">e clinicians annotated the following Formulaic Author Metadata (3 classes): • Author (Au): The names of the authors of the study; • E-mail (Em): The email addresses of the corresponding authors of the study; • Institution (In): The names of the institutions that the authors are from. Such metadata can be used to build an author citation network for macro trend analysis. Note that this data is obtained from the article’s title page itself, and not from any references to source articles, which have been the target of previous studies on CRF-based information extraction (Peng and McCallum, 2004; Councill et al., 2008). The clinicians also annotated the following Key Study Parameters (10 classes): • Age Group (Ag): The age range of the subjects of the study (e.g., 45 and 80 years, 21-79 years); • Data Analysis Name (Da): The name of the method or software used in the analysis of data collected for the study (e.g., proportional hazards survival models, SAS package); • Data Collection Method (Dc): The data collection methods for the study (e.g., medical records, review of medical records and linkage to computerized discharge abstracts); • Database Name (Dn): The name of any biomedical databases used or mentio</context>
</contexts>
<marker>Councill, Giles, Kan, 2008</marker>
<rawString>Isaac G. Councill, C. Lee Giles, and Min-Yen Kan. 2008. ParsCit: An open-source CRF reference string parsing package. In Proceedings of the Language Resources and Evaluation Conference (LREC 08), Marrakesh, Morrocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hui Han</author>
<author>C Giles</author>
<author>E Manavoglu</author>
<author>H Zha</author>
<author>Z Zhang</author>
<author>Ed Fox</author>
</authors>
<title>Automatic document meta-data extraction using support vector machines.</title>
<date>2003</date>
<booktitle>In Proceedings of Joint Conference on Digital Libraries.</booktitle>
<contexts>
<context position="7456" citStr="Han et al., 2003" startWordPosition="1113" endWordPosition="1116">yaalp, 2008) reports on the suitability of CRFs to find biological entities, combining basic orthographic token features with features derived from semantic lexicons such as UMLS, ABGene, SemRep and MetaMap. In a related vein, CRFs have been applied to gene map and relationship identification as well (Bundschus et al., 2008; Talreja et al., 2004). In a different domain, digital library practitioners have also studied how to extract formulaic metadata to enable more comprehensive article indexing. To extract author and title information, systems have used both the Support Vector Machine (SVM) (Han et al., 2003) and CRFs (Peng and McCallum, 2004; Councill et al., 2008). These works have been applied largely to the computer science community and have not yet been extensively tested on biomedical and clinical research articles. Our work differs from the above by making use of CRFs to extract fields in clinical text. Similar lexical-based features are employed, however in addition to regular author metadata, we also attempt to extract domain-specific fields from the body text of the article. 3 Method External to the scope of the research presented here, our wider project goal focuses on constructing a k</context>
</contexts>
<marker>Han, Giles, Manavoglu, Zha, Zhang, Fox, 2003</marker>
<rawString>Hui Han, C. Giles, E. Manavoglu, H. Zha, Z. Zhang, and Ed Fox. 2003. Automatic document meta-data extraction using support vector machines. In Proceedings of Joint Conference on Digital Libraries.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying He</author>
<author>Mehmet Kayaalp</author>
</authors>
<title>Biological entity recognition with conditional random fields.</title>
<date>2008</date>
<booktitle>In Proceedings of the Annual Symposium of the American Medical Informatics Association (AMIA),</booktitle>
<pages>293--297</pages>
<contexts>
<context position="6851" citStr="He and Kayaalp, 2008" startWordPosition="1015" endWordPosition="1018"> as a by-product as in generative methods such as in HMMs. A CRF can model arbitrary dependencies between observation and class variables, but most commonly, a simple linear chain sequence is used (which connects adjacent class variables to each other and to their corresponding observation variable), making them topologically similar to HMMs. Since their inception in 2001, (linear chain) CRFs have been applied extensively to many areas, including the biomedical field. CRFs have been used for the processing and extraction of important medical entities and their relationships among each other. (He and Kayaalp, 2008) reports on the suitability of CRFs to find biological entities, combining basic orthographic token features with features derived from semantic lexicons such as UMLS, ABGene, SemRep and MetaMap. In a related vein, CRFs have been applied to gene map and relationship identification as well (Bundschus et al., 2008; Talreja et al., 2004). In a different domain, digital library practitioners have also studied how to extract formulaic metadata to enable more comprehensive article indexing. To extract author and title information, systems have used both the Support Vector Machine (SVM) (Han et al., </context>
</contexts>
<marker>He, Kayaalp, 2008</marker>
<rawString>Ying He and Mehmet Kayaalp. 2008. Biological entity recognition with conditional random fields. In Proceedings of the Annual Symposium of the American Medical Informatics Association (AMIA), pages 293– 297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S C Johnston</author>
<author>J D Rootenberg</author>
<author>S Katrak</author>
<author>Wade S Smith</author>
<author>Jacob S Elkins</author>
</authors>
<title>Effect of a us national institutes of health programme of clinical trials on public health and costs.</title>
<date>2006</date>
<tech>Lancet,</tech>
<pages>367--13191327</pages>
<contexts>
<context position="1920" citStr="Johnston et al., 2006" startWordPosition="277" endWordPosition="280">over which 700,000 were added over the previous year1. While the research results further our knowledge and competency in the field, the volume of information poses a challenge to researchers who need to stay up to speed. Even within a single clinical research area, there can be hundreds of new clinical research results per year. Policy makers, who need to decide which clinical research proposals to fund and fast-track, and which proposals could tag onto existing research and cost share, have equally daunting information synthesis issues that have both monetary and public health implications (Johnston et al., 2006). 1http://www.nlm.nih.gov/bsd/bsd_key.html Systematic reviews – secondary publications that compile evidence and best practices from primary research results – partially address these concerns, but can take years before their final publication, due to liability and administrative overheads. In many fast-paced fields of clinical practice, such guidelines can be outdated by the time of publication. Researchers and policy makers alike still need effective tools to help them search, digest and organize their knowledge of the primary literature. One avenue that researchers have turned to is the use</context>
</contexts>
<marker>Johnston, Rootenberg, Katrak, Smith, Elkins, 2006</marker>
<rawString>S.C. Johnston, J.D. Rootenberg, S Katrak, Wade S. Smith, and Jacob S Elkins. 2006. Effect of a us national institutes of health programme of clinical trials on public health and costs. Lancet, 367:13191327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Kwan</author>
<author>Janice Johnston</author>
<author>Anne Fung</author>
<author>Doris SY Chong</author>
<author>Richard Collins</author>
<author>Su Lo</author>
</authors>
<title>A systematic evaluation of payback of publicly funded health and health services research in hong kong.</title>
<date>2007</date>
<journal>BMC Health Services Research,</journal>
<volume>7</volume>
<issue>1</issue>
<contexts>
<context position="3006" citStr="Kwan et al., 2007" startWordPosition="426" endWordPosition="429">lp them search, digest and organize their knowledge of the primary literature. One avenue that researchers have turned to is the use of automated information extraction (IE). We distinguish between two distinct uses of Information Extraction: 1) extracting regular, formulaic fields (e.g., author names, their institutional affiliation and email addresses), and 2) extracting free text descriptions of key study parameters (e.g., longitudinal variables, observation time periods, databases utilized). Extracting such formulaic fields helps policy makers determine returns on health-care investments (Kwan et al., 2007), as well as researchers in large scale sociological studies understand macroscopic trends in clinical research authorship and topic shifts over time (Cappell and Davis, 2008; Lin et al., 2008). But due to the wide variety of publication venues for clinical research, even performing the seemingly simple task of author name extraction turns out to be difficult, and published studies thus far have relied on manual analysis and extraction. Proposals to extract values of key study parameters may have more profound effects. Deeper characterization of research artifacts will enable more semantically</context>
</contexts>
<marker>Kwan, Johnston, Fung, Chong, Collins, Lo, 2007</marker>
<rawString>Patrick Kwan, Janice Johnston, Anne Fung, Doris SY Chong, Richard Collins, and Su Lo. 2007. A systematic evaluation of payback of publicly funded health and health services research in hong kong. BMC Health Services Research, 7(1):121.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data.</title>
<date>2001</date>
<booktitle>In Proceedings of the International Conference on Machine Learning,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="4967" citStr="Lafferty et al., 2001" startWordPosition="721" endWordPosition="725">or baseline supervised machine learning classifiers. However, these techniques are not considered stateof-the-art. On the other hand, much of the work from the NLP community applied to biomedical research has been on in-depth relationship extraction, such as the identification of gene pathways and proteinprotein interaction (PPI). While certainly difficult and worthwhile problems to solve, there is room for contribution even at the basic IE level, to retrieve both regular and free form metadata fields. We address this need in this paper. We apply a linear-chain Conditional Random Field (CRF) (Lafferty et al., 2001) as our methodology for extracting metadata fields. CRFs are a sequence labeling model that has shown good performance over a large number of information extraction tasks. We conduct experiments using basic token features to assess their efficacy for metadata extraction. While preliminary, our results indicate that CRFs are suitable for identifying formulaic metadata, but may need additional deeper, natural language processing features to identify free text fields. 2 Related Work Many researchers have recognized the utility of the application of IE on biomedical text. These works have focused </context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. In Proceedings of the International Conference on Machine Learning, pages 282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>JM Lin</author>
<author>JW Bohland</author>
<author>P Andrews</author>
<author>Burns GA</author>
<author>CB Allen</author>
<author>PP Mitra</author>
</authors>
<title>An analysis of the abstracts presented at the annual meetings of the society for neuroscience from</title>
<date>2008</date>
<note>to</note>
<contexts>
<context position="3199" citStr="Lin et al., 2008" startWordPosition="455" endWordPosition="458">een two distinct uses of Information Extraction: 1) extracting regular, formulaic fields (e.g., author names, their institutional affiliation and email addresses), and 2) extracting free text descriptions of key study parameters (e.g., longitudinal variables, observation time periods, databases utilized). Extracting such formulaic fields helps policy makers determine returns on health-care investments (Kwan et al., 2007), as well as researchers in large scale sociological studies understand macroscopic trends in clinical research authorship and topic shifts over time (Cappell and Davis, 2008; Lin et al., 2008). But due to the wide variety of publication venues for clinical research, even performing the seemingly simple task of author name extraction turns out to be difficult, and published studies thus far have relied on manual analysis and extraction. Proposals to extract values of key study parameters may have more profound effects. Deeper characterization of research artifacts will enable more semantically-oriented searches of the clinical literature. Further programmatic access allows and encourages data sharing of raw clinical trial results, databases and cohorts (Piwowar and Chap90 Proceeding</context>
</contexts>
<marker>Lin, Bohland, Andrews, GA, Allen, Mitra, 2008</marker>
<rawString>JM Lin, JW Bohland, P Andrews, Burns GA, CB Allen, and PP Mitra. 2008. An analysis of the abstracts presented at the annual meetings of the society for neuroscience from 2001 to 2006. PLoS ONE, 3(e2052).</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Peng</author>
<author>A McCallum</author>
</authors>
<title>Accurate information extraction from research papers using conditional random fields.</title>
<date>2004</date>
<booktitle>In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics (HLTNAACL),</booktitle>
<pages>329--336</pages>
<contexts>
<context position="7490" citStr="Peng and McCallum, 2004" startWordPosition="1119" endWordPosition="1122">suitability of CRFs to find biological entities, combining basic orthographic token features with features derived from semantic lexicons such as UMLS, ABGene, SemRep and MetaMap. In a related vein, CRFs have been applied to gene map and relationship identification as well (Bundschus et al., 2008; Talreja et al., 2004). In a different domain, digital library practitioners have also studied how to extract formulaic metadata to enable more comprehensive article indexing. To extract author and title information, systems have used both the Support Vector Machine (SVM) (Han et al., 2003) and CRFs (Peng and McCallum, 2004; Councill et al., 2008). These works have been applied largely to the computer science community and have not yet been extensively tested on biomedical and clinical research articles. Our work differs from the above by making use of CRFs to extract fields in clinical text. Similar lexical-based features are employed, however in addition to regular author metadata, we also attempt to extract domain-specific fields from the body text of the article. 3 Method External to the scope of the research presented here, our wider project goal focuses on constructing a knowledge base of clinical research</context>
<context position="10905" citStr="Peng and McCallum, 2004" startWordPosition="1659" endWordPosition="1663">omparative evaluation. The clinicians annotated the following Formulaic Author Metadata (3 classes): • Author (Au): The names of the authors of the study; • E-mail (Em): The email addresses of the corresponding authors of the study; • Institution (In): The names of the institutions that the authors are from. Such metadata can be used to build an author citation network for macro trend analysis. Note that this data is obtained from the article’s title page itself, and not from any references to source articles, which have been the target of previous studies on CRF-based information extraction (Peng and McCallum, 2004; Councill et al., 2008). The clinicians also annotated the following Key Study Parameters (10 classes): • Age Group (Ag): The age range of the subjects of the study (e.g., 45 and 80 years, 21-79 years); • Data Analysis Name (Da): The name of the method or software used in the analysis of data collected for the study (e.g., proportional hazards survival models, SAS package); • Data Collection Method (Dc): The data collection methods for the study (e.g., medical records, review of medical records and linkage to computerized discharge abstracts); • Database Name (Dn): The name of any biomedical </context>
</contexts>
<marker>Peng, McCallum, 2004</marker>
<rawString>F. Peng and A. McCallum. 2004. Accurate information extraction from research papers using conditional random fields. In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics (HLTNAACL), pages 329–336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heather A Piwowar</author>
<author>Wendy W Chapman</author>
</authors>
<title>Identifying data sharing in biomedical literature.</title>
<date>2008</date>
<booktitle>In Proceedings of the Annual Symposium of the American Medical Informatics Association (AMIA).</booktitle>
<marker>Piwowar, Chapman, 2008</marker>
<rawString>Heather A. Piwowar and Wendy W. Chapman. 2008. Identifying data sharing in biomedical literature. In Proceedings of the Annual Symposium of the American Medical Informatics Association (AMIA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Porter</author>
</authors>
<title>An Algorithm For Suffix Stripping.</title>
<date>1980</date>
<contexts>
<context position="13766" citStr="Porter, 1980" startWordPosition="2124" endWordPosition="2125">ormation that discards font information and corrupts mathematical symbols that could be helpful in the detection task. We take hyphenated token forms (e.g., 2006-2007) and convert them into individual tokens. The plain text is processed to note the specific locations of the XML tags for the learning process. The bulk of the words in each article were not tagged by clinicians, and for these words, we assigned a Not Applicable (NA) tag. We list the simple inventory of feature types that we use for classification. • Vocabulary: Individual word tokens are stemmed with Porter’s stemming algorithm (Porter, 1980) and down-cased to collapse orthographic variants. Each word token is then used as an individual feature. This feature alone was used to compile baseline performance as discussed later in evaluation. • Lexical: Lists of keywords were compiled to lend additional weight for specific classes. In particular, we compiled lists of months, common names, cue words that signaled observations, institution names and data analyses methods. For example, a list of common given and surname names is useful for the Au field; while a 2http://crfpp.sourceforge.net list of months and their abbreviated forms help </context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>M.F. Porter. 1980. An Algorithm For Suffix Stripping. 14(3):130–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Talreja</author>
<author>A Schein</author>
<author>S Winters</author>
<author>L Ungar</author>
</authors>
<title>GeneTaggerCRF: An entity tagger for recognizing gene names in text.</title>
<date>2004</date>
<tech>Technical report,</tech>
<institution>Univ. of Pennsylvania.</institution>
<contexts>
<context position="7187" citStr="Talreja et al., 2004" startWordPosition="1070" endWordPosition="1073">to HMMs. Since their inception in 2001, (linear chain) CRFs have been applied extensively to many areas, including the biomedical field. CRFs have been used for the processing and extraction of important medical entities and their relationships among each other. (He and Kayaalp, 2008) reports on the suitability of CRFs to find biological entities, combining basic orthographic token features with features derived from semantic lexicons such as UMLS, ABGene, SemRep and MetaMap. In a related vein, CRFs have been applied to gene map and relationship identification as well (Bundschus et al., 2008; Talreja et al., 2004). In a different domain, digital library practitioners have also studied how to extract formulaic metadata to enable more comprehensive article indexing. To extract author and title information, systems have used both the Support Vector Machine (SVM) (Han et al., 2003) and CRFs (Peng and McCallum, 2004; Councill et al., 2008). These works have been applied largely to the computer science community and have not yet been extensively tested on biomedical and clinical research articles. Our work differs from the above by making use of CRFs to extract fields in clinical text. Similar lexical-based </context>
</contexts>
<marker>Talreja, Schein, Winters, Ungar, 2004</marker>
<rawString>R. Talreja, A. Schein, S. Winters, and L. Ungar. 2004. GeneTaggerCRF: An entity tagger for recognizing gene names in text. Technical report, Univ. of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Tanabe</author>
<author>W J Wilbur</author>
</authors>
<title>Tagging gene and protein names in biomedical text.</title>
<date>2002</date>
<journal>Bioinformatics,</journal>
<volume>18</volume>
<issue>8</issue>
<contexts>
<context position="5751" citStr="Tanabe and Wilbur, 2002" startWordPosition="842" endWordPosition="845">tion tasks. We conduct experiments using basic token features to assess their efficacy for metadata extraction. While preliminary, our results indicate that CRFs are suitable for identifying formulaic metadata, but may need additional deeper, natural language processing features to identify free text fields. 2 Related Work Many researchers have recognized the utility of the application of IE on biomedical text. These works have focused mainly on the application of wellknown machine learning algorithms to tag important biomedical entities such as genes and proteins within biomedical articles. (Tanabe and Wilbur, 2002) uses a Naive Bayes classifier, while (Zhou et al., 2004) uses use a Hidden Markov Model (HMM). The Conditional Random Field (CRF) learning model combines the strengths of two well known methods: the Hidden Markov Model (HMM), a sequence labeling methodology, and the Maximum Entropy Model, a classification methodology. It models the probability of a class label y for a given token, directly from the observable stream of tokens x in direct (discriminative) manner, rather than as a by-product as in generative methods such as in HMMs. A CRF can model arbitrary dependencies between observation and</context>
</contexts>
<marker>Tanabe, Wilbur, 2002</marker>
<rawString>L. Tanabe and W.J. Wilbur. 2002. Tagging gene and protein names in biomedical text. Bioinformatics, 18(8):1124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Zhou</author>
<author>J Zhang</author>
<author>J Su</author>
<author>D Shen</author>
<author>C Tan</author>
</authors>
<title>Recognizing names in biomedical texts: a machine learning approach.</title>
<date>2004</date>
<journal>Bioinformatics,</journal>
<volume>20</volume>
<issue>7</issue>
<contexts>
<context position="5808" citStr="Zhou et al., 2004" startWordPosition="852" endWordPosition="855">o assess their efficacy for metadata extraction. While preliminary, our results indicate that CRFs are suitable for identifying formulaic metadata, but may need additional deeper, natural language processing features to identify free text fields. 2 Related Work Many researchers have recognized the utility of the application of IE on biomedical text. These works have focused mainly on the application of wellknown machine learning algorithms to tag important biomedical entities such as genes and proteins within biomedical articles. (Tanabe and Wilbur, 2002) uses a Naive Bayes classifier, while (Zhou et al., 2004) uses use a Hidden Markov Model (HMM). The Conditional Random Field (CRF) learning model combines the strengths of two well known methods: the Hidden Markov Model (HMM), a sequence labeling methodology, and the Maximum Entropy Model, a classification methodology. It models the probability of a class label y for a given token, directly from the observable stream of tokens x in direct (discriminative) manner, rather than as a by-product as in generative methods such as in HMMs. A CRF can model arbitrary dependencies between observation and class variables, but most commonly, a simple linear chai</context>
</contexts>
<marker>Zhou, Zhang, Su, Shen, Tan, 2004</marker>
<rawString>G. Zhou, J. Zhang, J. Su, D. Shen, and C. Tan. 2004. Recognizing names in biomedical texts: a machine learning approach. Bioinformatics, 20(7):1178–1190.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>