<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002159">
<title confidence="0.928126">
GTI: An Unsupervised Approach for Sentiment Analysis in Twitter
</title>
<author confidence="0.933225">
Milagros Fern´andez-Gavilanes, Tamara ´Alvarez-L´opez, Jonathan Juncal-Martinez,
Enrique Costa-Montenegro, Francisco Javier Gonz´alez-Casta˜no
</author>
<affiliation confidence="0.790678">
GTI Research Group
AtlantTIC Centre, School of Telecommunication Engineering, University of Vigo
</affiliation>
<address confidence="0.93497">
36310 Vigo, Spain
</address>
<email confidence="0.9933945">
{milagros.fernandez,talvarez,jonijm,kike}@gti.uvigo.es,
javier@det.uvigo.es
</email>
<sectionHeader confidence="0.995485" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998734">
This paper presents the approach of the GTI
Research Group to SemEval-2015 task 10 on
Sentiment Analysis in Twitter, or more specif-
ically, subtasks A (Contextual Polarity Disam-
biguation) and B (Message Polarity Classifi-
cation). We followed an unsupervised depen-
dency parsing-based approach using a senti-
ment lexicon, created by means of an auto-
matic polarity expansion algorithm and Nat-
ural Language Processing techniques. These
techniques involve the use of linguistic pe-
culiarities, such as the detection of polar-
ity conflicts or adversative/concessive subor-
dinate clauses. The results obtained confirm
the competitive and robust performance of the
system.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999952673469388">
The domain of sentiment analysis has received in-
creasing attention in recent years (Liu, 2012), partic-
ularly due to the growth of the Internet and content
generated by users of social networks and other plat-
forms. Some of these, such as Twitter, allow people
to express their opinions using colloquial, compact
language. The result is a new form of expression
that may in the long term become a source of ex-
tremely valuable information. An increasing num-
ber of companies are now focusing their market-
ing campaigns on online comments, sentiments, and
opinions of brands from clients or potential clients,
and some are even trying to predict the acceptance
and rejection of certain products using this informa-
tion (Jansen et al., 2009).
Even though the approaches used for this pur-
pose are numerous and varied, they can be
broadly divided into two categories: supervised
machine-learning and unsupervised semantic-based
approaches. The former are often classifiers built
from features of a “bag of words” representation (Hu
and Liu, 2004; Pak et al., 2010). In other words,
they consist of automatically analyzing n-grams in
search of recurrent combinations of opinion words.
The latter aim at capturing and modeling linguistic
knowledge through the use of dictionaries (Taboada
et al., 2011) containing words that are tagged with
their semantic orientation. These methods detect the
words present in a text using different strategies in-
volving lexics, syntax or semantics (Quinn et al.,
2010) and then aggregate their values. Such meth-
ods usually combine two or more levels of analysis.
In recent years, work on sentiment classification
using different types of texts has shown that special-
ized methods are required. For example, emotions
are not conveyed in the same manner in newspaper
articles as in blogs, reviews, forums or other types
of user-generated content (Balahur, 2013). Dealing
with sentiment in Twitter, thus, requires an analy-
sis of the characteristics of tweets and the design of
adapted methods.
This paper presents a method for sentiment analy-
sis in English that uses dependency parsing to deter-
mine the polarity of tweets, using a previously cre-
ated sentiment lexicon and considering the special
structure and linguistic content of these postings.
The remainder of this article is structured as fol-
lows: Section 2 provides a brief description of the
task and some of its subtasks. Section 3 presents in
</bodyText>
<page confidence="0.981479">
533
</page>
<bodyText confidence="0.804127666666667">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 533–538,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
detail the system proposed for the performance of
these tasks, and Section 4 shows the results obtained
and discusses them. Finally, Section 5 summarizes
the main findings and conclusions.
</bodyText>
<sectionHeader confidence="0.960084" genericHeader="method">
2 Task Description
</sectionHeader>
<bodyText confidence="0.9843385">
This paper describes our contribution to the
SemEval-2015 Task 10: Sentiment Analysis in Twit-
ter. Of the five subtasks established, we participated
in two:
</bodyText>
<listItem confidence="0.935660333333333">
• Contextual Polarity Disambiguation (A), on
determining the polarity of a marked instance
of a word or phrase in the context of a given
message.
• Message Polarity Classification (B), on clas-
sifying the content of a whole message.
</listItem>
<bodyText confidence="0.995093">
This year there were two datasets for testing can-
didate systems for substasks A and B: The Official
2015 Test and a Progress Test. The first test con-
sisted of a set of Twitter messages (Rosenthal et al.,
2015) whilst the second test was a rerun of SemEval-
2014 Task 9 (Rosenthal et al., 2014), which includes
Twitter messages and other kinds of texts from dif-
ferent domains. Datasets formed by the datasets
given in SemEval-2013 Task 2 (Nakov et al., 2013)
were also provided for training and development. In
our case, the approach does not involve any training,
and all the datasets were used to test the behavior of
our system.
</bodyText>
<sectionHeader confidence="0.976536" genericHeader="method">
3 System Overview
</sectionHeader>
<bodyText confidence="0.9999815">
The main objective of the tasks was to detect
whether a marked instance of word/phrase in a given
context (A) or message (B) expresses positive, nega-
tive or neutral sentiment. Most learning- or lexicon-
based systems do not usually take into account re-
lations between words, although they try to simu-
late comprehension of some linguistic constructions,
such as negation, but this does not always work cor-
rectly due to the complexity of human language. For
this reason, in this paper, we propose an alternative
system to exploit the information present in depen-
dencies obtained from a parsing analysis, without
the need for any kind of training. The research we
describe in this section has several linguistic pecu-
liarities that were used to improve sentiment detec-
tion performance. Our method, which was fully un-
supervised, consisted of four stages, which are each
explained in detail below.
</bodyText>
<subsectionHeader confidence="0.99916">
3.1 Preprocessing
</subsectionHeader>
<bodyText confidence="0.999640625">
Working with tweets presents several challenges for
natural language processing. The language used on
social media sites is quite different from that used
in other forums because it often contains words that
are not found in a dictionary. One reason is that
tweets have particular orthographic and typograph-
ical characteristics, such as letter or word duplica-
tion. Hence, before applying our approach, it was
necessary to start with a data preprocessing stage to
normalize the language used, remove noisy elements
and generalize the vocabulary used to express senti-
ment. The aim of the preprocessing module is to
bring tweets as close as possible to natural language
by eliminating expressions that are not considered
part of current usage, in order to minimize the noise
in later stages. There are four main steps involved:
</bodyText>
<listItem confidence="0.9913154">
• URL links (such as “http://url”), hashtags links
(such as “#hashtag”) and username links (such
as “@username”) are replaced with “URL”,
“HASHTAG” and “USERNAME” placehold-
ers respectively.
• Replicated characters are removed to return the
word to its normal form, such as sweeeeet →
sweet.
• Emoticons1 are replaced by one of nine
labels: e laugh, e happy, e surprise,
</listItem>
<bodyText confidence="0.704337166666667">
e positive state, e neutral state,
e inexpressive, e negative state,
e sad and e sick. For instance, :-( is replaced
with e sad.
• Abbreviations2 are replaced with their respec-
tive full written forms, such as h8 → hate.
</bodyText>
<footnote confidence="0.99740175">
1taken from the list available at
http://www.datagenetics.com/blog/october52012/index.html
2taken from the lists available at
http://chatslang.com/terms/abbreviations.
</footnote>
<page confidence="0.992882">
534
</page>
<subsectionHeader confidence="0.999276">
3.2 Lexical and syntactic analysis
</subsectionHeader>
<bodyText confidence="0.999779142857143">
In order to derive the syntactic context, each pre-
processed social media message must first be bro-
ken into tokens and then into sentences. To then en-
sure that all inflected forms of a word are covered,
lemmatization and part-of-speech (POS) tagging are
performed using the Freeling Tagger (Atserias et
al., 2006; Padr´o et al., 2012), or more specifically,
its tagger implementation based on HMM (Brants,
2000). Freeling is a library that provides multiple
language analysis services, including probabilistic
prediction of categories of unknown words. POS
tagging allows the identification of lexical items that
can contribute to the correct recognition of senti-
ment in message. These items are namely adjectives,
adverbs, verbs and nouns.
The resulting lemmatized and POS-annotated
messages are fed to a parser that transforms the out-
put of the tagger into a full parse tree. Finally, the
tree is converted to dependencies, and the functions
are annotated. The entire process is performed with
Freeling Parser (Padr´o et al., 2012).
</bodyText>
<subsectionHeader confidence="0.999818">
3.3 Sentiment lexicons
</subsectionHeader>
<bodyText confidence="0.999953515151515">
Sentiment lexicons, such as SOCAL (Taboada et al.,
2011), AFINN (Nielsen et al., 2011) and NRC Emo-
tion and Hashtag Sentiment Lexicon (Mohammad et
al., 2013; Mohammad et al., 2013b), have been used
in many systems for determining the semantic orien-
tation of a phrase within a tweet or sentence. These
lexicons contain English word lists sorted by lexical
category, i.e. adjectives, verbs, nouns and adverbs.
Each word is assigned a score of between -5 and 5.
However, these lexical resources are intrinsically
non-contextual, so it is necessary to improve their
coverage. To do this, we need to acquire new
polarities of subjective words that are not present
in generic dictionaries and adapt the scores of the
other words using the data available. Consequently,
we apply an automatic polarity expansion algorithm
based on graphs (Cruz et al., 2011). The graph is
generated from the syntactic dependencies provided
by the Freeling Parser, considering only those in-
volving verbs, nouns and adjectives. The starting
point of the algorithm is a subset of negative and
positive words, that are fed into the system as seed
words. In this regard, we chose the most negative
and positive words in the SOCAL and AFINN lex-
icons, as they resulted to work quite well for the
datasets provided, after carrying out different experi-
ments through the training datasets. Then, we apply
the iterative polarity expansion through the created
graph, and the result is merged with the unique word
list of SOCAL/AFINN lexicons, incorporating 5982
of new words. The next step is to include emoticon
labels, together with their polarities, in the resulting
sentiment lexicon.
</bodyText>
<subsectionHeader confidence="0.992582">
3.4 Sentiment Detection
</subsectionHeader>
<bodyText confidence="0.999994933333333">
Once the lexical and syntactic analyses are com-
plete, it is possible to estimate the polarity result-
ing from a message. In other words, its sentiment
can be expressed by a real number, which can be
later interpreted as positive, negative or neutral. This
value is computed by using the lexical polarities of
the words included in the text (provided by the senti-
ment lexicon we have generated), and subjecting the
special parsing structure and its content to linguis-
tic processing which is described below. Once these
have been applied, the resulting sentiment is a prop-
agation of the values of linguistic elements within
the dependencies, from the leaves to the upper lev-
els until the root is achieved (Caro, 2013). Then, it
is classified according to defined interval.
</bodyText>
<subsectionHeader confidence="0.53654">
3.4.1 Intensification treatment
</subsectionHeader>
<bodyText confidence="0.999987466666667">
Intensifiers and diminishers, such as “very” or “a
little”, are usually adverbs that emphasize or attenu-
ate the semantic orientation of the words or expres-
sions they precede. Intensification is achieved by
associating a positive or negative percentage, which
implies a graduation depending on its type (Zhang
et al., 2012). For instance, in “very good”, “very”
enhances the positivity of “good”. Our system de-
tects these structures and uses the parsing to identify
the exact scope of the intensification whose seman-
tic orientation will be altered. Superlative adjectives
are also taken into account by asuming that they be-
have like a word accompanied by an intensifier. An
example is “greatest”, where the superlative implies
an intensification of the word “great”.
</bodyText>
<subsectionHeader confidence="0.71597">
3.4.2 Negation treatment
</subsectionHeader>
<bodyText confidence="0.9700905">
Negation can be used to deny or reject statements.
It is expressed grammatically through a variety of
</bodyText>
<page confidence="0.992339">
535
</page>
<bodyText confidence="0.999923">
negator words, such as “no”, “not”, “never” or “nei-
ther” (Zhang et al., 2012). In our case, it is first
necessary to identify the dependencies in which any
of the above negator forms are present to estimate
the negation scope. Later, the semantic polarities of
the words involved in the affected dependencies are
modified using a negative factor.
</bodyText>
<subsectionHeader confidence="0.771089">
3.4.3 Polarity conflict treatment
</subsectionHeader>
<bodyText confidence="0.999974611111111">
The mere application of polar lexicons, intensi-
fiers, diminishers and negators on a syntactic struc-
ture is insufficient. That is, words cannot be con-
sidered individually (Moilanen et al., 2007). The
meaning and polarity of “unpleasant dream” differs
for example from those of “wonderful dream”. The
first statement has a negative connotation while the
second has a positive one. In both cases, the word
“dream” is involved, and we could expect that, re-
gardless of its accompanying terms, it should behave
in a specific way, with certain polarity effects or ex-
pectations. However, the meaning changes signifi-
cantly with the addition of “unpleasant” or “wonder-
ful”. In these cases, our system is able to detect po-
larity conflicts, i.e., it recognizes when a positive ad-
jective modifies a negative noun, or vice-versa, and
subsequently reduces the polarity of the elements
that cause the conflict.
</bodyText>
<subsectionHeader confidence="0.790228">
3.4.4 Adversative/concessive clause treatment
</subsectionHeader>
<bodyText confidence="0.999928307692308">
There is a point in common between adversative
and concessive subordinate clauses. While the for-
mer express an objection in compliance with what is
said in the main clause, the latter express a difficulty
in fulfilling the main clause, although it is not im-
possible. In both cases, one part of the sentence is in
contrast with the other part. For this reason, in a con-
text of sentiment analysis, we can assume that both
constructions will restrict, exclude, amplify or di-
minish the sentiment reflected in the clauses. In this
regard, it is necessary to clearly distinguish them. In
an adversative structure, the argument introduced by
items such as “but” or “however” is usually more im-
portant (Winterstein, 2012; Poria et al., 2014), while
in a concessive structure, that introduced by items
such as “despite” or “in spite of” is the least impor-
tant (Rudolph, 1996).
Our approach is able to coherently estimate the
sentiment of sentences that involve not only adver-
sative clauses, such as “Bill Maher may be a little
out there, but he does make some points” (where the
speaker is backing the view of Bill in general), but
also concessive clauses such as “Despite going off
on Saturday, it looks like Ian Bennett could be fine
for Wembley” (where what appears to be really im-
portant is that Ian could go to Wembley).
</bodyText>
<sectionHeader confidence="0.997142" genericHeader="method">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.995509">
In this section we describe the experiments we
conducted for both subtasks. These experiments
were carried out using the datasets provided by the
SemEval-2015 task organizers. These datasets are
composed of texts extracted from Twitter (including
sarcastic tweets), LiveJournal and phone text mes-
sages. The performance of each system is measured
by means of the F-score, calculated as shown in
Equation 1,
</bodyText>
<equation confidence="0.994174">
F-score = (FP + FN)/2 (1)
</equation>
<bodyText confidence="0.999699">
where FP stands for the F-score estimated only for
positive results. In this case, this value is computed
as shown in Equation 2, where PP represents the
precision and RP the recall, both for positive results.
The same is calculated for negative results, denomi-
nated FN.
</bodyText>
<equation confidence="0.99621">
FP = (2 * PP * RP)/(PP + RP) (2)
</equation>
<bodyText confidence="0.997994">
Table 1 presents the overall score for subtasks A
and B, in Twitter2015 Test, as well as precision, re-
call and F-measure values for positive (P), negative
(N) and neutral (NEU) results.
</bodyText>
<table confidence="0.940129">
Twitter 2015
Precision Recall F-score
Task A P 87.33% 71.26% 78.48%
N 80.02% 72.47% 76.06%
NEU 10.25% 34.21% 15.78%
Overall score: 77.27%
Task B P 72.13% 66.09% 68.98%
N 41.57% 59.45% 48.93%
NEU 61.72% 57.35% 59.45%
Overall score: 58.95%
</table>
<tableCaption confidence="0.999936">
Table 1: Results of our approach for subtasks A and B.
</tableCaption>
<bodyText confidence="0.9860925">
The approach previously described was applied
on both datasets (A and B) in the same way using the
</bodyText>
<page confidence="0.994863">
536
</page>
<table confidence="0.981904772727273">
TASK A TASK B
Q’14 SMS’13 T’13 T’14 TS’14 Q’14 SMS’13 T’13 T’14 TS’14
84.65 % 82.16 % 91.41% 93.23% 88.75 % 73.53% 56.57 % 68.54 % 76.27 % 52.17 %
85.04 % 92.64 % 87.53% 78.86% 95.83 % 74.52% 58.47 % 54.56 % 51.94 % 87.50 %
31.62 % 16.55 % 7.76% 9.79% 10.00 % 62.00% 81.64 % 67.69 % 60.03 % 37.50 %
76.06 % 83.85 % 81.38% 76.26% 86.59 % 70.26% 71.75 % 73.73 % 70.06 % 72.73 %
81.21 % 79.80 % 79.23% 71.63% 62.16 % 64.47% 70.05 % 59.73 % 63.34 % 35.00 %
51.39 % 30.19 % 29.38% 52.27% 40.00 % 71.05% 67.44 % 60.43 % 62.18 % 69.23 %
80.13 % 82.99 % 86.11% 83.90% 87.65 % 71.86% 63.26 % 71.04 % 73.04 % 60.76 %
83.08 % 85.74 % 83.17% 75.07% 75.41 % 69.14% 63.74 % 57.03 % 58.26 % 50.00 %
39.15 % 21.38 % 12.27% 16.49% 16.00 % 66.21% 73.87 % 63.85 % 61.09 % 48.65 %
81.61 % 84.37 % 84.64% 79.48% 81.53 % 70.50% 63.50 % 64.03 % 65.65 % 55.38 %
P
Precision N
NEU
P
Recall N
NEU
P
F-score N
NEU
Overall
</table>
<tableCaption confidence="0.999268">
Table 2: Performance of our approach on the progress test A and B.
</tableCaption>
<bodyText confidence="0.999672571428572">
generated sentiment lexicon and applying the propa-
gation of the sentiment values within the dependen-
cies. After performing several tests on the training
datasets provided by organizers, we set the neutral
sentiment intervals to [−0.05,0.05] for subtask A
and [−1.0,1.0] for subtask B.
As can be seen, all our results are adjusted, so we
can state that our system has no bias for one particu-
lar result, but performs quite well for all three types
of answers. However, as can be seen in subtask A,
the performance measures for neutral tweets are no-
tably lower than those obtained for positive and neg-
ative tweets. This can be explained by the content
of the dataset provided, which contained 1006 neg-
ative and 1896 positive tweets, but just 190 neutral
tweets, which is an insufficient sample for producing
reliable estimates on precision. The same problem
happened for progress test A, where the proportions
of tweets are similarly unbalanced.
Detailed scores for progress tests of subtasks A
and B are shown in Table 2. In general, we can say
that our system is quite stable, as it generates similar
results for the different kinds of texts under evalua-
tion. Also of note are the high percentages obtained
for sarcastic tweets, which ranked in the first posi-
tion in subtask A and in the tenth (test dataset) and
sixth positions (progress dataset) in subtask B (as
shown in Table 3).
</bodyText>
<sectionHeader confidence="0.997497" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9997692">
This paper describes the participation of the GTI Re-
search Group, AtlantTIC Centre, University of Vigo,
in SemEval-2015 task 10: Sentiment Analysis in
Twitter. We achieved our results using a fully un-
supervised approach for message-level and phrase-
</bodyText>
<table confidence="0.998424">
Test sets Task A Task B
Twitter2015 9/11 22/40
Twitter2015Sarcasm - 10/40
LiveJournal2014 8/11 18/40
SMS2013 6/11 16/40
Twitter2013 5/11 25/40
Twitter2014 9/11 22/40
Twitter2014Sarcasm 1/11 6/40
</table>
<tableCaption confidence="0.9851965">
Table 3: Position of our approach for each test and task,
according to results provided on January 1, 2015.
</tableCaption>
<bodyText confidence="0.999936769230769">
level sentiment analysis of tweets. Table 3 shows
our position in the ranking published for both sub-
tasks A and B for all the different datasets evaluated.
Our approach comprises different processing
stages, including the generation of sentiment lexi-
cons, test preprocessing and the application of dif-
ferent methods for determining contextual polarity
based on syntactical structure. This makes our ap-
proach robust in diverse contexts without the need
for previous manual tagging of datasets. To the best
of our knowledge, it is the only system presented in
this competition whose sentiment analysis method
does not require any supervision.
</bodyText>
<sectionHeader confidence="0.997488" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9972635">
This work was supported by the Spanish Govern-
ment, co-financed by the European Regional Devel-
opment Fund (ERDF) under project TACTICA, and
REdTEIC (R2014/037).
</bodyText>
<sectionHeader confidence="0.995443" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.7902095">
Atserias Jordi, Casas Bernardino, Comelles Elisabeth,
Gonz´alez Meritxell, Padr´o Luis and Padr´o Muntsa.
</reference>
<page confidence="0.988897">
537
</page>
<reference confidence="0.99849529245283">
2006. FreeLing 1.3: Syntactic and semantic services
in an open-source NLP library. In Proc. of the 5th
International Conference on Language Resources and
Evaluation, p. 48–55. Genoa, Italy.
Balahur Alexandra. 2013. Sentiment Analysis in Social
Media Texts. In Proc. of the 4th Workshop on Compu-
tational Approaches to Subjectivity, Sentiment and So-
cial Media Analysis, p. 120–128, ACL. Atlanta, Geor-
gia.
Brants Thorsten. 2000. TnT: A Statistical Part-of-speech
Tagger. In Proc. of the 6th Conference on Applied Nat-
ural Language Processing, p. 224–231. Seattle, Wash-
ington.
Caro Luigi and Grella Matteo. 2013. Sentiment analysis
via dependency parsing. In Computer Standards &amp;
Interfaces Journal, p. 442–453, volume 35 (5), New
York.
Cruz Ferm´ın L., Troyano Jos´e A., Ortega F. Javier and
Enr´ıquez Fernando. 2011. Automatic Expansion of
Feature-level Opinion Lexicons. In Proc. of the 2nd
Workshop on Computational Approaches to Subjectiv-
ity and Sentiment Analysis, p. 125–131. ACL. Port-
land.
Jansen Bernard J., Zhang Mimi, Sobel Kate and Chow-
dury Abdur. 2009. Twitter power: Tweets as elec-
tronic word of mouth. Journal of the American Soci-
ety for Information Science and Technology, p.2169–
2188, volume 60 (1), New York.
Hu Minqing and Liu Bing. 2004. Mining and sum-
marizing customer reviews. In Proc. of the 10th
ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining, p. 168–177. ACM
Press.
Liu Bing. 2012. Sentiment Analysis and Opinion Min-
ing. In Synthesis Digital Library of Engineering and
Computer Science, Morgan &amp; Claypool Publisher.
Mohammad Saif M. and Turney Peter D. 2013. Crowd-
sourcing a Word-Emotion Association Lexicon. Jour-
nal of Computational Intelligence, p. 436–465, volume
29 (3).
Mohammad Saif M., Kiritchenko Svetlana and Zhu Xi-
aodan 2013. NRC-Canada: Building the State-of-the-
Art in SentimentAnalysis of Tweets. In Proc. of the 7th
International workshop on Semantic Evaluation Exer-
cises (SemEval-2013), p. 282–290. Vienna, Austria.
Moilanen Karo and Pulman Stephen. 2007. Sentiment
Composition. In Proc. of Recent Advances in Natural
Language Processing (RANLP), p.378–382, Borovets,
Bulgaria.
Nakov Preslav, Rosenthal Sara, Kozareva Zornitsa, Stoy-
anov Veselin, Ritter Alan and Wilson Theresa. 2013.
SemEval-2013 Task 2: Sentiment Analysis in Twitter.
In Proc. of the 7th International Workshop on Seman-
tic Evaluation, p. 312–320. ACL. Atlanta, Georgia,
USA.
Nielsen Finn ˚Arup. 2011. A new ANEW: Evaluation of
a word list for sentiment analysis in microblogs. In
Proc. of the ESWC2011 Workshop on Making Sense of
Microposts, p. 93–98.
Padr´o Llu´ıs and Stanilovsky Evgeny. 2012. FreeLing
3.0: Towards Wider Multilinguality. In Proc. of the
8th International Conference on Language Resources
and Evaluation, p.23–25, Istanbul, Turkey.
Pak Alexander and Paroubek Patrick. 2010. Twitter as
a Corpus for Sentiment Analysis and Opinion Mining.
In Proc. of the 7th International Conference on Lan-
guage Resources and Evaluation (LREC’10), p.19–21,
Valleta, Malta.
Poria Soujanya, Cambria Erik, Winterstein Gr´egoire
and Huang Guang-Bin. 2014. Sentic patterns:
Dependency-based rules for concept-level sentiment
analysis. Journal of Knowledge-Based Systems, p.45–
63, volume 69 (1).
Quinn Kevin M., Monroe Burt L., Colaresi Michael,
Crespin Michael H. and Radev Dragomir R. 2010.
How to Analyze Political Attention with Minimal As-
sumptions and Costs. American Journal of Political
Science, p.209–228, volume 54 (1).
Rosenthal Sara, Nakov Preslav, Kiritchenko Svetlana,
Mohammad Saif M., Ritter Alan and Stoyanov
Veselin. 2015. SemEval-2015 Task 10: Sentiment
Analysis in Twitter. In Proc. of the 9th International
Workshop on Semantic Evaluation, ACL. Denver, Col-
orado.
Rosenthal Sara, Ritter Alan, Nakov Preslav and Stoyanov
Veselin. 2014. SemEval-2014 Task 9: SentimentAnal-
ysis in Twitter. In Proc. of the 8th International Work-
shop on Semantic Evaluation, p.73–80. ACL. Dublin,
Ireland.
Rudolph Elisabeth. 1996. Contrast: Adversative and
Concessive Relations and Their Expressions in En-
glish, German, Spanish, Portuguese on Sentence and
Text Level. Research in text theory, Walter de Gruyter.
Berlin.
Taboada Maite, Brooke Julian, Tofiloski Milan, Voll
Kimberly and Stede Manfred. 2011. Lexicon-based
Methods for Sentiment Analysis. Journal of the Com-
putational Linguistics, p.267–307, volume 35 (2), MIT
Press. Cambridge, MA, USA.
Winterstein Gr´egoire. 2012. What but-sentences argue
for: a modern argumentative analysis of but. Lingua
122 (15), p. 1864–1885.
Zhang Lei, Ferrari Silvia and Enjalbert Patrice. 2012.
Opinion Analysis: the Effect of Negation on Polarity
and Intensity. In Proc. of KONVENS 2012 (PATHOS
2012 Workshop), p. 282–290. Vienna, Austria.
</reference>
<page confidence="0.996776">
538
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.510991">
<title confidence="0.999386">GTI: An Unsupervised Approach for Sentiment Analysis in Twitter</title>
<author confidence="0.978879">Milagros Fern´andez-Gavilanes</author>
<author confidence="0.978879">Tamara ´Alvarez-L´opez</author>
<author confidence="0.978879">Jonathan Costa-Montenegro</author>
<author confidence="0.978879">Francisco Javier</author>
<affiliation confidence="0.994962">GTI Research</affiliation>
<address confidence="0.7740645">AtlantTIC Centre, School of Telecommunication Engineering, University of 36310 Vigo,</address>
<email confidence="0.996233">javier@det.uvigo.es</email>
<abstract confidence="0.998289705882353">This paper presents the approach of the GTI Research Group to SemEval-2015 task 10 on Sentiment Analysis in Twitter, or more specifically, subtasks A (Contextual Polarity Disambiguation) and B (Message Polarity Classification). We followed an unsupervised dependency parsing-based approach using a sentiment lexicon, created by means of an autopolarity expansion algorithm and Nat- Language Processing These techniques involve the use of linguistic peculiarities, such as the detection of polarity conflicts or adversative/concessive subordinate clauses. The results obtained confirm the competitive and robust performance of the system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Atserias Jordi</author>
<author>Casas Bernardino</author>
</authors>
<institution>Comelles Elisabeth, Gonz´alez Meritxell, Padr´o Luis and Padr´o Muntsa.</institution>
<marker>Jordi, Bernardino, </marker>
<rawString>Atserias Jordi, Casas Bernardino, Comelles Elisabeth, Gonz´alez Meritxell, Padr´o Luis and Padr´o Muntsa.</rawString>
</citation>
<citation valid="true">
<title>FreeLing 1.3: Syntactic and semantic services in an open-source NLP library.</title>
<date>2006</date>
<booktitle>In Proc. of the 5th International Conference on Language Resources and Evaluation,</booktitle>
<pages>48--55</pages>
<location>Genoa, Italy.</location>
<marker>2006</marker>
<rawString>2006. FreeLing 1.3: Syntactic and semantic services in an open-source NLP library. In Proc. of the 5th International Conference on Language Resources and Evaluation, p. 48–55. Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Balahur Alexandra</author>
</authors>
<title>Sentiment Analysis in Social Media Texts.</title>
<date>2013</date>
<booktitle>In Proc. of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, p. 120–128, ACL.</booktitle>
<location>Atlanta,</location>
<marker>Alexandra, 2013</marker>
<rawString>Balahur Alexandra. 2013. Sentiment Analysis in Social Media Texts. In Proc. of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, p. 120–128, ACL. Atlanta, Georgia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brants Thorsten</author>
</authors>
<title>TnT: A Statistical Part-of-speech Tagger.</title>
<date>2000</date>
<booktitle>In Proc. of the 6th Conference on Applied Natural Language Processing,</booktitle>
<pages>224--231</pages>
<location>Seattle, Washington.</location>
<marker>Thorsten, 2000</marker>
<rawString>Brants Thorsten. 2000. TnT: A Statistical Part-of-speech Tagger. In Proc. of the 6th Conference on Applied Natural Language Processing, p. 224–231. Seattle, Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Caro Luigi</author>
<author>Grella Matteo</author>
</authors>
<title>Sentiment analysis via dependency parsing.</title>
<date>2013</date>
<journal>In Computer Standards &amp; Interfaces Journal,</journal>
<volume>35</volume>
<issue>5</issue>
<location>New York.</location>
<marker>Luigi, Matteo, 2013</marker>
<rawString>Caro Luigi and Grella Matteo. 2013. Sentiment analysis via dependency parsing. In Computer Standards &amp; Interfaces Journal, p. 442–453, volume 35 (5), New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cruz Ferm´ın L</author>
<author>Troyano Jos´e A</author>
<author>Ortega F Javier</author>
<author>Enr´ıquez Fernando</author>
</authors>
<title>Automatic Expansion of Feature-level Opinion Lexicons.</title>
<date>2011</date>
<booktitle>In Proc. of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis,</booktitle>
<pages>125--131</pages>
<publisher>ACL. Portland.</publisher>
<marker>L, A, Javier, Fernando, 2011</marker>
<rawString>Cruz Ferm´ın L., Troyano Jos´e A., Ortega F. Javier and Enr´ıquez Fernando. 2011. Automatic Expansion of Feature-level Opinion Lexicons. In Proc. of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, p. 125–131. ACL. Portland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jansen Bernard J</author>
<author>Zhang Mimi</author>
<author>Sobel Kate</author>
<author>Chowdury Abdur</author>
</authors>
<title>Twitter power: Tweets as electronic word of mouth.</title>
<date>2009</date>
<journal>Journal of the American Society for Information Science and Technology,</journal>
<volume>60</volume>
<issue>1</issue>
<location>New York.</location>
<marker>J, Mimi, Kate, Abdur, 2009</marker>
<rawString>Jansen Bernard J., Zhang Mimi, Sobel Kate and Chowdury Abdur. 2009. Twitter power: Tweets as electronic word of mouth. Journal of the American Society for Information Science and Technology, p.2169– 2188, volume 60 (1), New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hu Minqing</author>
<author>Liu Bing</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proc. of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>168--177</pages>
<publisher>ACM Press.</publisher>
<marker>Minqing, Bing, 2004</marker>
<rawString>Hu Minqing and Liu Bing. 2004. Mining and summarizing customer reviews. In Proc. of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, p. 168–177. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liu Bing</author>
</authors>
<title>Sentiment Analysis and Opinion Mining.</title>
<date>2012</date>
<booktitle>In Synthesis Digital Library of Engineering and Computer Science,</booktitle>
<publisher>Morgan &amp; Claypool Publisher.</publisher>
<marker>Bing, 2012</marker>
<rawString>Liu Bing. 2012. Sentiment Analysis and Opinion Mining. In Synthesis Digital Library of Engineering and Computer Science, Morgan &amp; Claypool Publisher.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohammad Saif M</author>
<author>Turney Peter D</author>
</authors>
<title>Crowdsourcing a Word-Emotion Association Lexicon.</title>
<date>2013</date>
<journal>Journal of Computational Intelligence,</journal>
<volume>29</volume>
<issue>3</issue>
<marker>M, D, 2013</marker>
<rawString>Mohammad Saif M. and Turney Peter D. 2013. Crowdsourcing a Word-Emotion Association Lexicon. Journal of Computational Intelligence, p. 436–465, volume 29 (3).</rawString>
</citation>
<citation valid="false">
<authors>
<author>Mohammad Saif M</author>
</authors>
<title>Kiritchenko Svetlana and Zhu Xiaodan 2013. NRC-Canada: Building the State-of-theArt in SentimentAnalysis of Tweets.</title>
<booktitle>In Proc. of the 7th International workshop on Semantic Evaluation Exercises (SemEval-2013),</booktitle>
<pages>282--290</pages>
<location>Vienna, Austria.</location>
<marker>M, </marker>
<rawString>Mohammad Saif M., Kiritchenko Svetlana and Zhu Xiaodan 2013. NRC-Canada: Building the State-of-theArt in SentimentAnalysis of Tweets. In Proc. of the 7th International workshop on Semantic Evaluation Exercises (SemEval-2013), p. 282–290. Vienna, Austria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Moilanen Karo</author>
<author>Pulman Stephen</author>
</authors>
<title>Sentiment Composition.</title>
<date>2007</date>
<booktitle>In Proc. of Recent Advances in Natural Language Processing (RANLP), p.378–382, Borovets,</booktitle>
<marker>Karo, Stephen, 2007</marker>
<rawString>Moilanen Karo and Pulman Stephen. 2007. Sentiment Composition. In Proc. of Recent Advances in Natural Language Processing (RANLP), p.378–382, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nakov Preslav</author>
<author>Rosenthal Sara</author>
<author>Kozareva Zornitsa</author>
<author>Stoyanov Veselin</author>
<author>Ritter Alan</author>
<author>Wilson Theresa</author>
</authors>
<date>2013</date>
<booktitle>SemEval-2013 Task 2: Sentiment Analysis in Twitter.</booktitle>
<marker>Preslav, Sara, Zornitsa, Veselin, Alan, Theresa, 2013</marker>
<rawString>Nakov Preslav, Rosenthal Sara, Kozareva Zornitsa, Stoyanov Veselin, Ritter Alan and Wilson Theresa. 2013. SemEval-2013 Task 2: Sentiment Analysis in Twitter.</rawString>
</citation>
<citation valid="false">
<booktitle>In Proc. of the 7th International Workshop on Semantic Evaluation, p. 312–320. ACL.</booktitle>
<location>Atlanta, Georgia, USA.</location>
<marker></marker>
<rawString>In Proc. of the 7th International Workshop on Semantic Evaluation, p. 312–320. ACL. Atlanta, Georgia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nielsen Finn ˚Arup</author>
</authors>
<title>A new ANEW: Evaluation of a word list for sentiment analysis in microblogs.</title>
<date>2011</date>
<booktitle>In Proc. of the ESWC2011 Workshop on Making Sense of Microposts,</booktitle>
<pages>93--98</pages>
<marker>˚Arup, 2011</marker>
<rawString>Nielsen Finn ˚Arup. 2011. A new ANEW: Evaluation of a word list for sentiment analysis in microblogs. In Proc. of the ESWC2011 Workshop on Making Sense of Microposts, p. 93–98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Padr´o Llu´ıs</author>
<author>Stanilovsky Evgeny</author>
</authors>
<title>FreeLing 3.0: Towards Wider Multilinguality.</title>
<date>2012</date>
<booktitle>In Proc. of the 8th International Conference on Language Resources and Evaluation, p.23–25,</booktitle>
<location>Istanbul, Turkey.</location>
<marker>Llu´ıs, Evgeny, 2012</marker>
<rawString>Padr´o Llu´ıs and Stanilovsky Evgeny. 2012. FreeLing 3.0: Towards Wider Multilinguality. In Proc. of the 8th International Conference on Language Resources and Evaluation, p.23–25, Istanbul, Turkey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pak Alexander</author>
<author>Paroubek Patrick</author>
</authors>
<title>Twitter as a Corpus for Sentiment Analysis and Opinion Mining.</title>
<date>2010</date>
<booktitle>In Proc. of the 7th International Conference on Language Resources and Evaluation (LREC’10), p.19–21,</booktitle>
<location>Valleta,</location>
<marker>Alexander, Patrick, 2010</marker>
<rawString>Pak Alexander and Paroubek Patrick. 2010. Twitter as a Corpus for Sentiment Analysis and Opinion Mining. In Proc. of the 7th International Conference on Language Resources and Evaluation (LREC’10), p.19–21, Valleta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Poria Soujanya</author>
<author>Cambria Erik</author>
<author>Winterstein Gr´egoire</author>
<author>Huang Guang-Bin</author>
</authors>
<title>Sentic patterns: Dependency-based rules for concept-level sentiment analysis.</title>
<date>2014</date>
<journal>Journal of Knowledge-Based Systems,</journal>
<volume>69</volume>
<issue>1</issue>
<marker>Soujanya, Erik, Gr´egoire, Guang-Bin, 2014</marker>
<rawString>Poria Soujanya, Cambria Erik, Winterstein Gr´egoire and Huang Guang-Bin. 2014. Sentic patterns: Dependency-based rules for concept-level sentiment analysis. Journal of Knowledge-Based Systems, p.45– 63, volume 69 (1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Quinn Kevin M</author>
<author>Monroe Burt L</author>
<author>Colaresi Michael</author>
<author>Crespin Michael H</author>
<author>Radev Dragomir R</author>
</authors>
<title>How to Analyze Political Attention with Minimal Assumptions and Costs.</title>
<date>2010</date>
<journal>American Journal of Political Science,</journal>
<volume>54</volume>
<issue>1</issue>
<marker>M, L, Michael, H, R, 2010</marker>
<rawString>Quinn Kevin M., Monroe Burt L., Colaresi Michael, Crespin Michael H. and Radev Dragomir R. 2010. How to Analyze Political Attention with Minimal Assumptions and Costs. American Journal of Political Science, p.209–228, volume 54 (1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rosenthal Sara</author>
<author>Nakov Preslav</author>
<author>Kiritchenko Svetlana</author>
<author>Mohammad Saif M</author>
<author>Ritter Alan</author>
<author>Stoyanov Veselin</author>
</authors>
<title>SemEval-2015 Task 10: Sentiment Analysis in Twitter.</title>
<date>2015</date>
<booktitle>In Proc. of the 9th International Workshop on Semantic Evaluation, ACL.</booktitle>
<location>Denver, Colorado.</location>
<marker>Sara, Preslav, Svetlana, M, Alan, Veselin, 2015</marker>
<rawString>Rosenthal Sara, Nakov Preslav, Kiritchenko Svetlana, Mohammad Saif M., Ritter Alan and Stoyanov Veselin. 2015. SemEval-2015 Task 10: Sentiment Analysis in Twitter. In Proc. of the 9th International Workshop on Semantic Evaluation, ACL. Denver, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rosenthal Sara</author>
<author>Ritter Alan</author>
<author>Nakov Preslav</author>
<author>Stoyanov Veselin</author>
</authors>
<title>SemEval-2014 Task 9: SentimentAnalysis in Twitter.</title>
<date>2014</date>
<booktitle>In Proc. of the 8th International Workshop on Semantic Evaluation, p.73–80. ACL.</booktitle>
<location>Dublin, Ireland.</location>
<marker>Sara, Alan, Preslav, Veselin, 2014</marker>
<rawString>Rosenthal Sara, Ritter Alan, Nakov Preslav and Stoyanov Veselin. 2014. SemEval-2014 Task 9: SentimentAnalysis in Twitter. In Proc. of the 8th International Workshop on Semantic Evaluation, p.73–80. ACL. Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rudolph Elisabeth</author>
</authors>
<title>Contrast: Adversative and Concessive Relations and Their Expressions</title>
<date>1996</date>
<booktitle>in English, German, Spanish, Portuguese on Sentence and Text Level. Research in text theory, Walter de Gruyter.</booktitle>
<location>Berlin.</location>
<marker>Elisabeth, 1996</marker>
<rawString>Rudolph Elisabeth. 1996. Contrast: Adversative and Concessive Relations and Their Expressions in English, German, Spanish, Portuguese on Sentence and Text Level. Research in text theory, Walter de Gruyter. Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taboada Maite</author>
<author>Brooke Julian</author>
<author>Tofiloski Milan</author>
<author>Voll Kimberly</author>
<author>Stede Manfred</author>
</authors>
<title>Lexicon-based Methods for Sentiment Analysis.</title>
<date>2011</date>
<journal>Journal of the Computational Linguistics,</journal>
<volume>35</volume>
<issue>2</issue>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA, USA.</location>
<marker>Maite, Julian, Milan, Kimberly, Manfred, 2011</marker>
<rawString>Taboada Maite, Brooke Julian, Tofiloski Milan, Voll Kimberly and Stede Manfred. 2011. Lexicon-based Methods for Sentiment Analysis. Journal of the Computational Linguistics, p.267–307, volume 35 (2), MIT Press. Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Winterstein Gr´egoire</author>
</authors>
<title>What but-sentences argue for: a modern argumentative analysis of but.</title>
<date>2012</date>
<journal>Lingua</journal>
<volume>122</volume>
<issue>15</issue>
<pages>1864--1885</pages>
<marker>Gr´egoire, 2012</marker>
<rawString>Winterstein Gr´egoire. 2012. What but-sentences argue for: a modern argumentative analysis of but. Lingua 122 (15), p. 1864–1885.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhang Lei</author>
<author>Ferrari Silvia</author>
<author>Enjalbert Patrice</author>
</authors>
<title>Opinion Analysis: the Effect of Negation on Polarity and Intensity.</title>
<date>2012</date>
<booktitle>In Proc. of KONVENS 2012 (PATHOS 2012 Workshop),</booktitle>
<pages>282--290</pages>
<location>Vienna, Austria.</location>
<marker>Lei, Silvia, Patrice, 2012</marker>
<rawString>Zhang Lei, Ferrari Silvia and Enjalbert Patrice. 2012. Opinion Analysis: the Effect of Negation on Polarity and Intensity. In Proc. of KONVENS 2012 (PATHOS 2012 Workshop), p. 282–290. Vienna, Austria.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>