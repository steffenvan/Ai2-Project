<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000224">
<title confidence="0.9451302">
Prosodic Aids to Syntactic and Semantic Analysis of Spoken English
Chris Rowles and Xiuming Huang
Al Systems Section
Australia and Overseas Telecommunications Corporation
Telecommunications Research Laboratories
</title>
<author confidence="0.367819">
PO Box 249, Clayton, Victoria, 3168, Australia
</author>
<email confidence="0.793593">
Internet: c.rowles@trloz.au
</email>
<sectionHeader confidence="0.960976" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.953196">
Prosody can be useful in resolving certain lex-
ical and structural ambiguities in spoken English.
In this paper we present some results of employ-
ing two types of prosodic information, namely
pitch and pause, to assist syntactic and semantic
analysis during parsing.
</bodyText>
<sectionHeader confidence="0.988086" genericHeader="introduction">
1. INTRODUCTION
</sectionHeader>
<bodyText confidence="0.998904112676056">
In attempting to merge speech recognition
and natural language understanding to produce a
system capable of understanding spoken dia-
logues, we are confronted with a range of prob-
lems not found in text processing.
Spoken language conversations are typically
more terse, less grammatically correct, less well-
structured and more ambiguous than text (Brown
&amp; Yule 1983). Additionally, speech recognition
systems that attempt to extract words from
speech typically produce word insertion, deletion
or substitution errors due to incorrect recognition
and segmentation.
The motivation for our work is to combine
speech recognition and natural language under-
standing (NLU) techniques to produce a system
which can, in some sense, understand the intent
of a speaker in telephone-based, information
seeking dialogues. As a result, we are interested
in NLU to improve the semantic recognition accu-
racy of such a system, but since we do not have
explicit utterance segmentation and structural in-
formation, such as punctuation in text, we have
explored the use of prosody.
Intonation can be useful in understanding dia-
logue structure (c.f. Hirschberg &amp; Pierrehumbert
1986), but parsing can also be assisted. (Briscoe
&amp; Boguraev 1984) suggests that if prosodic struc-
ture could be derived for the noun compound Bo-
ron epoxy rocket motor chambers, then their
parser LEXICAT could reduce the fourteen licit
morphosyntactic interpretations to one correct
analysis without error (p. 262). (Steedman 1990)
explores taking advantage of intonational struc-
ture in spoken sentence understanding in the
combinatory categorial grammar formalism.
(Bear &amp; Price 1990) discusses integrating proso-
dy and syntax in parsing spoken English, relative
duration of phonetic segments being the one as-
pect of prosody examined.
Compared with the efforts expended on syn-
tactic/semantic disambiguation mechanisms,
prosody is still an under-exploited area. No work
has yet been carried out which treats prosody at
the same level as syntax, semantics, and prag-
matics, even though evidence shows that proso-
dy is as important as the other means in human
understanding of utterances (see, for example,
experiments reported in (Price et al 1989)). (Scott
&amp; Cutler 1984) noticed that listeners can suc-
cessfully identify the intended meaning of ambig-
uous sentences even in the absence of a
disambiguating context, and suggested that
speakers can exploit acoustic features to high-
light the distinction that is to be conveyed to the
listener (p. 450).
Our current work incorporates certain prosod-
ic information into the process of parsing, com-
bining syntax, semantics, pragmatics and
prosody for disambiguationl. The context of the
work is an electronic directory assistance system
(Rowles et al 1990). In the following sections, an
overview of the system is first given (Section 2).
Then the parser is described in Section 3. Sec-
tion 4 discusses how prosody can be employed
in helping resolve ambiguity involved in process-
1. Another possible acoustic source to help
disambiguation is &amp;quot;segmental phonology&amp;quot;, the ap-
plication of certain phonological assimilation and
elision rules (Scott &amp; Cutler 1984). The current
work makes no attempt at this aspect.
</bodyText>
<page confidence="0.996415">
112
</page>
<bodyText confidence="0.9999075">
ing fixed expressions, prepositional phrase at-
tachment (PP attachment), and coordinate
constructions. Section 5 shows the implementa-
tion of the parser.
</bodyText>
<sectionHeader confidence="0.993333" genericHeader="method">
2. SYSTEM OVERVIEW
</sectionHeader>
<bodyText confidence="0.999958769230769">
Our work is aimed at the construction of a
prototype system for the understanding of spo-
ken requests to an electronic directory assis-
tance service, such as finding the phone number
and address of a local business that offers partic-
ular services.
Our immediate work does not concentrate on
speech recognition (SR) or lexical access. In-
stead, we assume that a future speech recogni-
tion system performs phoneme recognition and
uses linguistic information during word recogni-
tion. Recognition is supplemented by a prosodic
feature extractor, which produces features syn-
chronized to the word string output by the SR.
The output of the recognizer is passed to a
sentence-level parser. Here &amp;quot;sentence&amp;quot; really
means a conversational move, that is, a contigu-
ous utterance of words constructed so as to con-
vey a proposition.
Parses of conversational moves are passed
to a dialogue analyzer that segments the dia-
logue into contextually-consistent sub-dialogues
(i.e. exchanges) and interpret speaker requests
in terms of available system functions. A dia-
logue manager manages interaction with the
speaker and retrieves database information.
</bodyText>
<sectionHeader confidence="0.985786" genericHeader="method">
3. PROSODY EXTRACTION
</sectionHeader>
<bodyText confidence="0.99998090909091">
As the input to the parser is spoken language,
it lacks the segmentation apparent in text. Within
a move, there is no punctuation to hint at internal
grammatical structure. In addition, as complete
sentences are frequently reduced to phrases, el-
lipsis etc. during a dialogue, the Parser cannot
use syntax alone for segmentation.
Although intonation reflects deeper issues,
such as a speakers&apos; intended interpretation, it
provides the surface structure for spoken lan-
guage. Intonation is inherently supra-segmental,
but it is also useful for segmentation purposes
where other information is unavailable. Thus, in-
tonation can be used to provide initial segmenta-
tion via a pre-processor for the parser.
Although there are many prosodic features
that are potentially useful in the understanding of
spoken English, pitch and pause information
have received the most attention due to ease of
measurement and their relative importance
(Cruttenden 1986, pp 3 &amp; 36). Our efforts to date
use only these two feature types.
We extract pitch and pause information from
speech using specifically designed hardware
with some software post-processing. The hard-
ware performs frequency to amplitude transfor-
mation and filtering to produce an approximate
pitch contour with pauses.
The post-processing samples the pitch con-
tour, determines the pitch range and classifies
the instantaneous pitch into high, medium and
low categories within that range. This is similar to
that used in (Hirschberg &amp; Pierrehumbert 1986).
Pauses are classed as short (less than 250ms),
long (between 250ms and 800ms) or extended
(greater than 800ms). These times were empiri-
cally derived from spoken information seeking di-
alogues conducted over a telephone to human
operators. Short pauses signify strong turn-hold-
ing behaviour, long pauses signify weaker turn-
holding behaviour and extended pauses signify
turn passing or exchange completion (Vonwiller
1991). These interpretations can vary with cer-
tain pitch movements, however. Unvoiced
sounds are distinguished from pauses by subse-
quent synchronisation of prosodic features with
the word stream by post-processing.
A parser pre-processor then takes the SR
word string, pitch markers and pauses, annotat-
ing the word string with pitch markers (low
marked as&amp;quot; &amp;quot;, medium &amp;quot; - &amp;quot; and high &amp;quot;&apos;i &amp;quot; ) and
pauses (short&amp;quot; &amp;quot; and long &amp;quot; ** &amp;quot;). The markers
are synchronised with words or syllables. The
pre-processor uses the pitch and pause markers
to segment the word string into intonationally-
consistent groups, such as tone groups (bound-
aries marked as&amp;quot; &lt; &amp;quot;and &amp;quot;&gt; &amp;quot;) and moves (//). A
tone group is a group of words whose intonation-
al structure indicates that they form a major
structural component of the speech, which is
commonly also a major syntactic grouping (Crut-
tenden 1986, pp. 75 - 80). Short conversational
moves often correspond to tone groups, while
longer moves may consist of several tone
groups. With cue words for example, the cue
forms its own tone group.
</bodyText>
<page confidence="0.995648">
113
</page>
<bodyText confidence="0.999742166666666">
Pauses usually occur at points of low transi-
tional probability and often mark phrase bound-
aries (Cruttenden 1986). In general, although
pitch plays an important part, long pauses, indi-
cate tone group and move boundaries, and short
pauses indicate tone group boundaries. Ex-
change boundary markers are dealt with in the
dialogue manager (not covered here). Pitch
movements indicate turn-holding behaviour, top-
ic changes, move completion and information
contrastiveness (Cooper &amp; Sorensen 1977; Von-
wilier 1991).
The pre-processor also locates fixed expres-
sions, so that during the parsing nondeterminism
can be reduced. A problem here is that a cluster
of words may be ambiguous in terms of whether
they form a fixed expression or not. &amp;quot;Look after&amp;quot;,
for example, means lake care of&amp;quot; in &amp;quot;Mary
helped John to look after his kids&amp;quot;, whereas
look&amp;quot; and &amp;quot;after&apos; have separate meaning in &amp;quot;I&apos;ll
look after you do so&amp;quot;. The pre-processor makes
use of tone group information to help resolve the
fixed expression ambiguity. A more detailed dis-
cussion is given in section 5.2.
</bodyText>
<sectionHeader confidence="0.830585" genericHeader="method">
4. THE PARSER
</sectionHeader>
<bodyText confidence="0.999958067567568">
Once the input is segmented, moves annotat-
ed with prosody are input to the parser. The pars-
er deals with one move at a time.
In general, the intonational structure of a sen-
tence and its syntactic structure coincide (Crut-
tenden 1986). Thus, prosodic segmentation
avoids having the Parser try to extract moves
from unsegmented word strings based solely on
syntax. It also reduces the computational com-
plexity in comparing syntactic and prosodic word
groupings. There is a complication, however, in
that tone group boundaries and move bound-
aries may not align exactly. This is not frequent,
and is not present in the material used here. Into-
nation is used to limit the range of syntactic pos-
sibilities and the parser will align tone group and
move syntactic boundaries at a later stage.
By integrating syntax and semantics, the
Parser is capable of resolving most of the ambig-
uous structures it encounters in parsing written
English sentences, such as coordinate conjunc-
tions, PP attachments, and lexical ambiguity
(Huang 1988). Migrating the Parser from written
to spoken English is our current focus.
Moves input to the Parser are unlikely to be
well-formed sentences, as people do not always
speak grammatically, or due to the SR&apos;s inability
to accurately recognise the actual words spoken.
The parser first assumes that the input move is
lexically correct and tries to obtain a parse for it,
employing syntactic and semantic relaxation
techniques for handling ill-formed sentences
(Huang 1988). If no acceptable analysis is pro-
duced, the parser asks the SR to provide the
next alternative word string.
Exchanges between the parser and the SR
are needed for handling situations where an ill-
formed utterance gets further distorted by the
SR. In these cases other knowledge sources
such as pragmatics, dialogue analysis, and dia-
logue management must be used to find the
most likely interpretation for the input string. We
use pragmatics and knowledge of dialogue struc-
ture to find the semantic links between separate
conversational moves by either participant and
resolve indirectness such as pronouns, deictic
expressions and brief responses to the other
speaker [for more details, see (Rowles, 1989)].
By determining the dialogue purpose of utteranc-
es and their domain context, it is then possible to
correct some of the insertion and mis-recognised
word errors from the SR and determine the com-
municative intent of the speaker. The dialogue
manager queries the speaker if sentences can-
not be analysed at the pragmatic stage.
The output of the parser is a parse tree that
contains syntactic, semantic and prosodic fea-
tures. Most ambiguity is removed in the parse
tree, though some is left for later resolution, such
as definite and anaphoric references, whose res-
olution normally requires inter-move inferences.
The parser also detects cue words in its input
using prosody. Cue words, such as &amp;quot;now&amp;quot; in
&amp;quot;Now, I want to ...&amp;quot;, are words whose meta-func-
tion in determining the structure of dialogues
overrides their semantic roles (Reichman
1985).Cue words and phrases are prosodically
distinct due to their high pitch and pause separa-
tion from tone groups that convey most of the
propositional content (Hirschberg &amp; Litman
1987). While relatively unimportant semantically,
cue words are very important in dialogue analy-
sis due to their ability to indicate segmentation
and the linkage of the dialogue components.
</bodyText>
<page confidence="0.997641">
114
</page>
<sectionHeader confidence="0.996444" genericHeader="method">
5. PROSODY AND DISAMBIGUATION
</sectionHeader>
<bodyText confidence="0.999982454545455">
During parsing prosodic information is used
to help disambiguate certain structures which
cannot be disambiguated syntactically/semanti-
cally, or whose processing demands extra ef-
forts, if no such prosodic information is available.
In general, prosody includes pitch, loudness, du-
ration (of words, morphemes and pauses) and
rhythm. While all of these are important cues, we
are currently focussing on pitch and pauses as
these are easily extracted from the waveform
and offer useful disambiguation during parsing
and segmentation in dialogue analysis. Subse-
quent work will include the other features, and
further refinement of the use of pitch and pause.
At present, for example, we do not consider the
length of pauses internal to tone groups, al-
though this may be significant.
The prosodic markers are used by the parser
as additional pre-conditions for grammatical
rules, discriminating between possible grammati-
cal constructions via consistent intonational
structures.
</bodyText>
<subsectionHeader confidence="0.66362">
5.1 HOMOGRAPHS
</subsectionHeader>
<bodyText confidence="0.999964153846154">
Even when using prosody, homographs are a
problem for parsers, although a system recognis-
ing words from phonemes can make the problem
a simpler. The word sense of &amp;quot;bank&amp;quot; in &amp;quot;John
went to the bank&apos; must be determined from se-
mantics as the sense is not dependent upon vo-
calisation, but the difference between the
homograph &amp;quot;content&amp;quot; in &amp;quot;contents of a book&apos; and
&amp;quot;happy and content&apos; can be determined through
differing syllabic stress and resultant different
phonemes. Thus, different homographs can be
detected during lexical access in the SR inde-
pendently of the Parser.
</bodyText>
<subsectionHeader confidence="0.968243">
5.2 FIXED EXPRESSIONS
</subsectionHeader>
<bodyText confidence="0.995646285714286">
As is mentioned in subsection 4.1, when the
pre-processor tries to locate fixed expressions, it
may face multiple choices. Some fixed expres-
sions are obligatory, i.e., they form single seman-
tic units, for instance &amp;quot;look forward to&amp;quot; often
means &amp;quot;expect to feel pleasure in (something
about to happen)&amp;quot;2. Some other strings may or
</bodyText>
<listItem confidence="0.8012755">
2. Longman Dictionary of Contemporary En-
glish, 1978.
</listItem>
<bodyText confidence="0.862181318181818">
may not form single sematic units, depending on
the context. &amp;quot;Look after&amp;quot; and &amp;quot;win over&amp;quot; are two
examples. Without prosodic information, the pre-
processor has to make a choice blindly, e.g.
treating all potential fixed expressions as such
and on backtracking dissolve them into separate
words. This adds to the nondeterminism of the
parsing. As prosodic information becomes avail-
able, the nondeterminism is avoided.
In the system&apos;s fixed expression lexicon, we
have entries such as lix_e([gave, up], gave_-
up)&amp;quot;. The pre-processor contains a rule to the fol-
lowing effect, which conjoins two (or more) words
into one fixed expression only when there is no
pause following the first word:
match_fix_e([FirstW, SecondWIRestW], [Fixe-
dElMoreVVD:-
no_pause jn_between(FirstW, SecondW),
fix_e([FirstW, SecondVV], FixedE),
Match_fix_e(RestW, MoreVV).
This rule produces the following segmen 1-
tions:
</bodyText>
<listItem confidence="0.89693275">
(5.1a) &lt;-He -gave&gt; *&lt;^up to ^two hundred
dollars&gt; *&lt;-to the Acharity&gt;&amp;quot;//
(5.1b) &lt;-He ^gave ^up&gt; *&lt;^two hundred dol-
lars&gt; *&lt;-for damage compensation&gt;&amp;quot;//.
</listItem>
<bodyText confidence="0.999842">
In (5.1a), gave and up to are treated as be-
longing to two separate tone groups, whereas in
(5.1b) gave up is marked as one tone group. The
pre-processor checking its fixed expression dic-
tionary will therefore convert up to in (5.1a) to
up to, and gave up in (5.1b) to gave_up.
</bodyText>
<subsectionHeader confidence="0.970461">
5.3 PP ATTACHMENT
</subsectionHeader>
<bodyText confidence="0.966405916666667">
(Steedman 1990 &amp; Crittenden 1986) ob-
served that intonational structure is strongly con-
strained by meaning. For example, an intonation
imposing bracketings like the following is not al-
lowed:
(5.2) &lt;Three cats&gt; &lt;in ten prefer corduroy&gt;//
Conversely, the actual contour detected for
the input can be significant in helping decide the
segmentation and resolving PP attachment. In
the following sentence, f.g.,
(5.3) &lt;I would like&gt; &lt; information on her ar-
rival&gt; [&amp;quot;on her arrival&amp;quot; attached to &amp;quot;information
</bodyText>
<page confidence="0.997985">
115
</page>
<bodyText confidence="0.997015526315789">
(5.4) &lt;I would like&gt; &lt;information&gt; ** &lt;on her
arrival&gt; [&amp;quot;on her arrival&amp;quot; attached to &amp;quot;like]
the pause after &amp;quot;information&amp;quot; in (5.4), but not in
(5.3), breaks the bracketed phrase in (5.3) into
two separate tone groups with different attach-
ments.
In a clash between prosodic constraints and
syntactic/semantic constraints, the latter takes
precedence over the former. For instance, in:
(5.5) &lt;I would like&gt; &lt;information&gt; ** &lt;on
some panel beaters in my area&gt;.
although the intonation does not suggest attach-
ment of the PP to &amp;quot; information&amp;quot;, since the se-
mantics constraints exclude attachment to &amp;quot;like&amp;quot;
meaning &amp;quot;choose to have&amp;quot; (&amp;quot;On panel beaters [as
a location or time] I like information&amp;quot; does not
rate as a good interpretation), it is attached to &amp;quot;in-
formation&amp;quot; anyway (which satisfies the syntactic/
semantic constraints).
</bodyText>
<subsectionHeader confidence="0.828748">
5.4 COORDINATE CONSTRUCTIONS
</subsectionHeader>
<bodyText confidence="0.996612090909091">
Coordinate constructions can be highly am-
biguous, and are handled by rules such as:
Np --&gt; det(Det), adj(Adj),
/* check if a pause follows the adjective */
{check_pause (Flag)}, noun (Noun),
{construct_np(Det, Adj, Noun, NP),
conjunction(NP, Flag, FinaINP).
In the conjunction rule, if two noun phrases
are joined, we check for any pauses to see if the
adjective modifying the first noun should be cop-
ied to allow it to modify the second noun. Similar-
ly, we check for a pause preceding the
conjunction to decide if we should copy the post
modifier of the second noun to the first noun
phrase. For instance, the text-form phrase:
(5.6) old men and women in glasses
can produce three possible interpretations:
[old men (in glasses)] and [(old) women in
glasses] (5.6a)
[old men] and [women in glasses] (5.6b)
[old men (in glasses)] and [women in glasses]
(5.6c).
</bodyText>
<figure confidence="0.999232909090909">
(Liz)
(2) attachment of
2 phrases
(3) isolated
(Eft)
-1i:ne (f.)
(and women in glass - es&gt;
)00
(4) attachment of
1 phrase only
7.
1I-ne )
&lt; Old men) &lt;and W0111C11&gt; &lt;in glass - es&gt;
A
&lt;men and women in glass. es&gt;
lo
(%)
Old men and women
(I) neutral
intonation
Pact,
in glass - es
</figure>
<figureCaption confidence="0.99964">
Figure 1.
</figureCaption>
<bodyText confidence="0.8112625">
Figure1 shows some measured pitch con-
tours for utterances of phrase (5.6) with an at-
tempt by the speaker to provide the
interpretations (a) through (c). Note that the con-
tour is smoothed by the hardware pitch extrac-
tion. Pauses and unvoiced sounds are
distinguished in the software post-processor.
In all waveforms &amp;quot;old&amp;quot; and &amp;quot;glasses&amp;quot; have
high pitch. In (5.6a), a short pause follows &amp;quot;old&amp;quot;,
indicating that &amp;quot;old&amp;quot; modifies &amp;quot;men and women in
glasses&amp;quot; as a sub-phrase. This is in contrast to
(5.6b) where the short pause appears after
&amp;quot;men&amp;quot; indicating &amp;quot;old men&amp;quot; as one conjunct and
&amp;quot;women in glasses&amp;quot; as the other. Notice also that
duration of &amp;quot;men&amp;quot; in (5.6b) is longer than in
(5.6a). In (5.6c) we have two major pauses, a
shorter one after &amp;quot;men&amp;quot; and a longer one after
&amp;quot;women&amp;quot;. Using this variation in pause locations,
</bodyText>
<page confidence="0.982348">
116
</page>
<bodyText confidence="0.996755333333333">
the parser produces the correct interpretation
(i.e. the speaker&apos;s intended interpretation) for
sentences (5.6a-c).
</bodyText>
<sectionHeader confidence="0.997424" genericHeader="method">
6. IMPLEMENTATION
</sectionHeader>
<bodyText confidence="0.997865243243243">
Prosodic information, currently the pitch con-
tour and pauses, are extracted by hardware and
software. The hardware detects pitch and paus-
es from the speech waveform, while the software
determines the duration of pauses, categorises
pitch movements and synchronises these to the
sequence of lexical tokens output from a hypo-
thetical word recogniser. The parser is written in
the Definite Clause Grammars formalism (Perei-
ra et al. 1980) and runs under BIM Prolog on a
SPARCstation 1. The pitch and pause extractor
as described here is also complete.
To illustrate the function of the prosodic fea-
ture extractor and the Parser pre-processor, the
following sentence was uttered and its pitch con-
tour analysed:
&amp;quot;yes i&apos;d like information on some panel beaters&amp;quot;
Prosodic feature extraction produced:
**Ayes** ^i&apos;d &amp;quot;like * -information on some &amp;quot;panel
beaters **//
The Parser pre-processor then segments the
input (in terms of moves and tone groups) for the
Parser, resulting in:
**&lt; ^yes&gt; **// &lt; &amp;quot;I&apos;d ^like&gt; * &lt;-information on some
&amp;quot;panel beaters&gt; **//
The actual output of the pre-processor is in
two parts, one an indexed string of lexical items
plus prosodic information, the other a string of
tone groups indicating their start and end points:
[** &amp;quot;yes, 1] [**// Al, 2] [would, 3] [Alike, 4] [* -infor-
mation, 5] [on, 6] [some, 7] [&amp;quot;panel_ beaters, 8]
[**ll, 9]
&lt;1,1&gt; &lt;2,4&gt; &lt; 5, 8&gt; &lt;9,9&gt;
We use a set of sentences3, all beginning
with &amp;quot;Before the King/feature races&amp;quot;, but with dif-
ferent intonation to provide different interpreta-
tions, to illustrate how syntax, semantics and
</bodyText>
<listItem confidence="0.80555225">
3. Adapted from (Briscoe &amp; Boguraev 1984).
prosody are used for disambiguation:
(6.1) &lt;- Before the -King Araces&gt;*&lt;-his
^horse&gt; &lt;is -usually ^groomed&gt;**//.
(6.2) &lt;-Before the -King&gt; *&lt;-races his
^horse&gt; &amp;quot;&lt;it&apos;s -usually ^groomed&gt;**//.
(6.3) &lt;-Before the &amp;quot;feature -races&gt; *&lt;-his
&amp;quot;horse is -usually ^groomed&gt;**//.
</listItem>
<bodyText confidence="0.998818025">
The syntactic ambiguity of &amp;quot;before&amp;quot; (preposi-
tion in 6.3 and subordinate conjunction in 6.1 and
6.2) is solved by semantic checking: &amp;quot;race&amp;quot; as a
verb requires an animate subject, which &amp;quot;the
King&amp;quot; satisfies, but not &amp;quot;the feature&amp;quot;; &amp;quot;race&amp;quot; as a
noun can normally be modified by other nouns
such as &amp;quot;feature&amp;quot;, but not &amp;quot;King&amp;quot;4. However,
when prosody information is not used the time
needed for parsing the three sentences varies
tremendously, due to the top-down, depth-first
nature of the parser. (6.3) took 2.05 seconds to
parse, whereas (6.1) took 9.34 seconds, and
(6.2), 41.78 seconds. The explanation lies in that
on seeing the word &amp;quot;before&amp;quot; the parser made an
assumption that it was a preposition (correct for
6.3), and took the &amp;quot;wrong&amp;quot; path before backtrack-
ing to find that it really was a conjunction (for 6.1
and 6.2). Changing the order of rules would not
help here: if the first assumption treats &amp;quot;before&amp;quot;
as a conjunction, then parsing of (6.3) would
have been slowed down.
We made one change to the grammar so that
it takes into account the pitch information accom-
panying the word &amp;quot;races&amp;quot;, to see if improvement
can be made. The parser states that a noun-
noun string can form a compound noun group
only when the last noun has a low pitch. That is,
the feature -races forms a legitimate noun
phrase, while the King -races and the King &amp;quot;rac-
es do not. This is in accordance with one of the
best known English stress rules, the &amp;quot;Compound
Stress Rule&amp;quot; (Chomsky and Halle 1968), which
asserts that the first lexically stressed syllable in
a constituent has the primary stress if the constit-
uent is a compound construction forming an ad-
jective, verb, or noun.
4. It is very difficult, though, to give a clear cut
as to what kind of nouns can function as noun
modifiers. King races may be a perfect noun
group in certain context.
</bodyText>
<page confidence="0.992789">
117
</page>
<bodyText confidence="0.966803472222222">
We then added the pause information in the
parser along similar lines. The following is a sim-
plified version of the VP grammar to illustrate the
parsing mechanism:
P Noun phrase rule.
&amp;quot;Mods&amp;quot; can be a string of adjectives or nouns:
major (races), feature (races), etc.*/
Np --&gt; Det, Mods,HeadNoun.
P Head noun is preferred to be low-pitched.*/
HeadNoun --&gt; [Noun], {low_pitched(Noun)}.
P Verb phrase rule 1.*/
Vp --&gt; V intr.
P Verb phrase rule 2. Some semantic check-
ing is carried out after a transitive verb and a
noun phrase is found.*/
Vp --&gt; V_tr, Np, {match(V_tr,Np)}.
P If a verb is found which might be used as in-
transitive, check if there is a pause following it.*/
Vintr --&gt; [Verb], (is_intransitive(Verb)),
Pause.
P Otherwise see if the verb can be used as
transitive.*/
P tr --&gt; [Verb], {is transitive(Verb)).
P This succeeds if a pause is detected. */
Pause --&gt; [pause].
The pause information following &amp;quot;races&amp;quot; in
sentences(6.1) and (6.2) thus helps the parser to
decide if &amp;quot;races&amp;quot; is transitive or intransitive, again
reducing nondeterminism. The above rules spec-
ify only the preferred patterns, not absolute con-
straints. If they cannot be satisfied, e.g. when
there is no pause detected after a verb which is
intransitive, the string is accepted anyway.
The parse times for sentences (6.1) to (6.3)
with and without prosodic rules in the parser are
given in the Table 6.1.
</bodyText>
<table confidence="0.95456">
Without Prosody With Prosody
(6.1) 9.34 1.23
(6.2) 41.78 8.69
(6.3) 2.05 1.27
</table>
<tableCaption confidence="0.96534225">
Table 6.1 Parsing Times for the &amp;quot;races&amp;quot; sentence
(in seconds).
Table 6.2 shows how the parser performed on
the following sentences:
</tableCaption>
<table confidence="0.717899777777778">
(6.4) look* &amp;quot;after the -boy -comes**//
(6.5) &amp;quot;He ^gave* &amp;quot;up to &amp;quot;two &amp;quot;hundred dollars
to the -chality**//
(6.6) &amp;quot;Now* -I want -some -information on
&amp;quot;panel &amp;quot;beaters -in -Clayton**//
Without Prosody With Prosody
(6.4) 6.59 1.19
(6.5) 41.38 2.49
(6.6) 2.15 2.55
</table>
<tableCaption confidence="0.6958806">
Table 6.2 Parsing Times for sentences (6.4) to
(6.6) (in seconds).
While (6.6) is slower with prosodic annotation,
the parser correctly recognises &amp;quot;now&amp;quot; as a cue
word rather than as an adverb.
</tableCaption>
<sectionHeader confidence="0.708305" genericHeader="discussions">
7. DISCUSSION
</sectionHeader>
<bodyText confidence="0.999955366666667">
We have shown that by integrating prosody
with syntax and semantics in a natural language
parser we can improve parser performance. In
spoken language, prosody is used to isolate sen-
tences at the parser&apos;s input and again to deter-
mine the syntactic structure of sentences by
seeking structures that are intonationally and
syntactically consistent.
The work described here is in progress. The
prosodic features with which sentences have
been annotated are the output of our feature ex-
tractor, but synchronisation is by hand as we do
not have a speech recognition system. As shown
by the &amp;quot;old men ...&amp;quot; example, the system is capa-
ble of accurately producing correct interpreta-
tions, but as yet, no formal experiments using
data extracted from ordinary telephone conver-
sations and human comparisons have been per-
formed. The aim has been to investigate the
potential for the use of prosody in parsers intend-
ed for use in speech understanding systems.
(Bear &amp; Price 1990) modified the grammar
they use to change all the rules of the form A -&gt;
B C to the form A -&gt; B Link C, and add con-
straints to the rules application in terms of the
value of the &amp;quot;breaking indices&amp;quot; based on relative
duration of phonetic segments. For instance the
rule VP -&gt; V Link PP applies only when the value
of the link is either 0 or 1, indicating a close cou-
pling of neighbouring words. Duration is thus tak-
</bodyText>
<page confidence="0.995452">
118
</page>
<bodyText confidence="0.9991444375">
en into consideration in deciding the structure of
the input. In our work, pitch contour and pause
are used instead, achieving a similar result.
The principle of preference semantics allows
the straightforward integration of prosody into
parsing rules and a consistent representation of
prosody and syntax. Such integration may have
been more of a problem if the basic parsing ap-
proach had been different. Also relevant is the
choice of English, as the integration may not car-
ry across to other languages.
Future research aims at a more thorough
treatment of prosody. Research currently under-
way, is also focussing on the use of prosody and
dialogue knowledge for dialogue analysis and
turn management.
</bodyText>
<sectionHeader confidence="0.722114" genericHeader="acknowledgments">
ACKNOWLEDGEMENTS
</sectionHeader>
<bodyText confidence="0.9998532">
The permission of the Director, Research,
AOTC to publish the above paper is hereby ac-
knowledged. The authors have benefited from
discussions with Robin King, Peter Sefton, Julie
Vonwiller and Christian Matthiessen, Sydney
University, and Muriel de Beier, Telecommunica-
tion Research Laboratories, who are involved in
further work on this project. The authors would
also like to thanks the anonymous reviewers for
positive comments on paper improvements.
</bodyText>
<sectionHeader confidence="0.992817" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999780935483871">
Bear, J. &amp; Price, P. J. (1990), Prosody, Syntax
and Parsing. 28th Annual Meeting of the Assoc.
for Computational Linguistics (pp. 17-22).
Briscoe, E.J. &amp; Boguraev, B.K. (1984), Con-
trol Structures and Theories of Interaction in
Speech Understanding Systems. 22th Annual
Meeting of the Assoc. for Computational Linguis-
tics (pp. 259-266)
Brown, G., &amp; Yule, G., (1983), Discourse
Analysis, Cambridge University Press.
Chomsky, N.&amp; Halle, M. (1968), The Sound
Pattern of English, (New York: Harper and Row).
Cooper, W.E. &amp; Sorensen, J.M., (1977), Fun-
damental Frequency Contours at Syntactic
Boundaries, Journal of the Acoustical Society of
America, Vol. 62, No. 3, September.
Cruttenden, A., (1986), Intonation, Cam-
bridge University Press.
Hirschberg, J. &amp; Litman, D., (1987), Now Let&apos;s
Talk About Now: Identifying Cue Phrases Intona-
tionally, 25th Annual Meeting of the Assoc. for
Computational Linguistics.
Hirschberg, J. &amp; Pierrehumbert, J., The Into-
national Structure of Discourse, 24th Annual
Meeting of the Assoc. for Computational Linguis-
tics, 1986.
Huang, X-M. (1988), Semantic Analysis in
XTRA, An English - Chinese Machine Translation
System, Computers and Translation 3, No.2. (pp.
101-120)
Pereira, F. &amp; Warren, D. (1980), Definite
Clause Grammars for Language Analysis - A
Survey of the Formalism and A Comparison with
Augmented Transition Networks. Artificial Intelli-
gence, 13:231-278.
Price, P. J., Ostendorf, M. &amp; VVightmen, C.W.
(1989), Prosody and Parsing. DARPA Workshop
on Speech and Natural Language, Cape Cod,
October 1989 (pp.5-11).
Reichman, R. (1985), Getting Computers to
Talk Like You and Me, (Cambridge: MIT Press).
Rowles, C.D. (1989), Recognizing User Inten-
tions from Natural language Expressions, First
Australia-Japan Joint Symposium on Natural
Language Processing, (pp.157-166).
Rowles, C.D., Huang, X., and Aumann, G.,
(1990), Natural Language Understanding and
Speech Recognition: Exploring the Connections,
Third Australian International Conference on
Speech Science and Technology, (pp. 374 - 382).
Steedman, M. (1990),Structure and Intonation
in Spoken Language Understanding. 28th Annual
Meeting of the Assoc. for Computational Linguis-
tics (pp. 9-16).
Scott, D.R &amp; Cutler, A. (1984), Segmental
Phonology and the Perception of Syntactic Struc-
ture, Journal of Verbal Learning and Verbal Be-
havior 23, (pp. 450-466).
Vonwiller, J. (1991),An Empirical Study of
Some Features of Intonation, Second Australia-
Japan Natural Language Processing Sympo-
sium, Japan, November, (pp 66-71).
</reference>
<page confidence="0.999091">
119
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.777641">
<title confidence="0.992101">Prosodic Aids to Syntactic and Semantic Analysis of Spoken English</title>
<author confidence="0.968763">Rowles Huang</author>
<affiliation confidence="0.944485">Al Systems Section Australia and Overseas Telecommunications Corporation Telecommunications Research Laboratories</affiliation>
<address confidence="0.983441">PO Box 249, Clayton, Victoria, 3168, Australia</address>
<email confidence="0.946376">Internet:c.rowles@trloz.au</email>
<abstract confidence="0.998822142857143">Prosody can be useful in resolving certain lexical and structural ambiguities in spoken English. In this paper we present some results of employing two types of prosodic information, namely pitch and pause, to assist syntactic and semantic analysis during parsing.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Bear</author>
<author>P J Price</author>
</authors>
<date>1990</date>
<booktitle>Prosody, Syntax and Parsing. 28th Annual Meeting of the Assoc. for Computational Linguistics</booktitle>
<pages>17--22</pages>
<contexts>
<context position="2215" citStr="Bear &amp; Price 1990" startWordPosition="323" endWordPosition="326">t, we have explored the use of prosody. Intonation can be useful in understanding dialogue structure (c.f. Hirschberg &amp; Pierrehumbert 1986), but parsing can also be assisted. (Briscoe &amp; Boguraev 1984) suggests that if prosodic structure could be derived for the noun compound Boron epoxy rocket motor chambers, then their parser LEXICAT could reduce the fourteen licit morphosyntactic interpretations to one correct analysis without error (p. 262). (Steedman 1990) explores taking advantage of intonational structure in spoken sentence understanding in the combinatory categorial grammar formalism. (Bear &amp; Price 1990) discusses integrating prosody and syntax in parsing spoken English, relative duration of phonetic segments being the one aspect of prosody examined. Compared with the efforts expended on syntactic/semantic disambiguation mechanisms, prosody is still an under-exploited area. No work has yet been carried out which treats prosody at the same level as syntax, semantics, and pragmatics, even though evidence shows that prosody is as important as the other means in human understanding of utterances (see, for example, experiments reported in (Price et al 1989)). (Scott &amp; Cutler 1984) noticed that lis</context>
<context position="26102" citStr="Bear &amp; Price 1990" startWordPosition="4177" endWordPosition="4180"> The work described here is in progress. The prosodic features with which sentences have been annotated are the output of our feature extractor, but synchronisation is by hand as we do not have a speech recognition system. As shown by the &amp;quot;old men ...&amp;quot; example, the system is capable of accurately producing correct interpretations, but as yet, no formal experiments using data extracted from ordinary telephone conversations and human comparisons have been performed. The aim has been to investigate the potential for the use of prosody in parsers intended for use in speech understanding systems. (Bear &amp; Price 1990) modified the grammar they use to change all the rules of the form A -&gt; B C to the form A -&gt; B Link C, and add constraints to the rules application in terms of the value of the &amp;quot;breaking indices&amp;quot; based on relative duration of phonetic segments. For instance the rule VP -&gt; V Link PP applies only when the value of the link is either 0 or 1, indicating a close coupling of neighbouring words. Duration is thus tak118 en into consideration in deciding the structure of the input. In our work, pitch contour and pause are used instead, achieving a similar result. The principle of preference semantics a</context>
</contexts>
<marker>Bear, Price, 1990</marker>
<rawString>Bear, J. &amp; Price, P. J. (1990), Prosody, Syntax and Parsing. 28th Annual Meeting of the Assoc. for Computational Linguistics (pp. 17-22).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E J Briscoe</author>
<author>B K Boguraev</author>
</authors>
<title>Control Structures and Theories of Interaction in Speech Understanding Systems.</title>
<date>1984</date>
<booktitle>22th Annual Meeting of the Assoc. for Computational Linguistics</booktitle>
<pages>259--266</pages>
<contexts>
<context position="1797" citStr="Briscoe &amp; Boguraev 1984" startWordPosition="262" endWordPosition="265"> combine speech recognition and natural language understanding (NLU) techniques to produce a system which can, in some sense, understand the intent of a speaker in telephone-based, information seeking dialogues. As a result, we are interested in NLU to improve the semantic recognition accuracy of such a system, but since we do not have explicit utterance segmentation and structural information, such as punctuation in text, we have explored the use of prosody. Intonation can be useful in understanding dialogue structure (c.f. Hirschberg &amp; Pierrehumbert 1986), but parsing can also be assisted. (Briscoe &amp; Boguraev 1984) suggests that if prosodic structure could be derived for the noun compound Boron epoxy rocket motor chambers, then their parser LEXICAT could reduce the fourteen licit morphosyntactic interpretations to one correct analysis without error (p. 262). (Steedman 1990) explores taking advantage of intonational structure in spoken sentence understanding in the combinatory categorial grammar formalism. (Bear &amp; Price 1990) discusses integrating prosody and syntax in parsing spoken English, relative duration of phonetic segments being the one aspect of prosody examined. Compared with the efforts expend</context>
<context position="20974" citStr="Briscoe &amp; Boguraev 1984" startWordPosition="3317" endWordPosition="3320">&amp;quot;I&apos;d ^like&gt; * &lt;-information on some &amp;quot;panel beaters&gt; **// The actual output of the pre-processor is in two parts, one an indexed string of lexical items plus prosodic information, the other a string of tone groups indicating their start and end points: [** &amp;quot;yes, 1] [**// Al, 2] [would, 3] [Alike, 4] [* -information, 5] [on, 6] [some, 7] [&amp;quot;panel_ beaters, 8] [**ll, 9] &lt;1,1&gt; &lt;2,4&gt; &lt; 5, 8&gt; &lt;9,9&gt; We use a set of sentences3, all beginning with &amp;quot;Before the King/feature races&amp;quot;, but with different intonation to provide different interpretations, to illustrate how syntax, semantics and 3. Adapted from (Briscoe &amp; Boguraev 1984). prosody are used for disambiguation: (6.1) &lt;- Before the -King Araces&gt;*&lt;-his ^horse&gt; &lt;is -usually ^groomed&gt;**//. (6.2) &lt;-Before the -King&gt; *&lt;-races his ^horse&gt; &amp;quot;&lt;it&apos;s -usually ^groomed&gt;**//. (6.3) &lt;-Before the &amp;quot;feature -races&gt; *&lt;-his &amp;quot;horse is -usually ^groomed&gt;**//. The syntactic ambiguity of &amp;quot;before&amp;quot; (preposition in 6.3 and subordinate conjunction in 6.1 and 6.2) is solved by semantic checking: &amp;quot;race&amp;quot; as a verb requires an animate subject, which &amp;quot;the King&amp;quot; satisfies, but not &amp;quot;the feature&amp;quot;; &amp;quot;race&amp;quot; as a noun can normally be modified by other nouns such as &amp;quot;feature&amp;quot;, but not &amp;quot;King&amp;quot;4. However,</context>
</contexts>
<marker>Briscoe, Boguraev, 1984</marker>
<rawString>Briscoe, E.J. &amp; Boguraev, B.K. (1984), Control Structures and Theories of Interaction in Speech Understanding Systems. 22th Annual Meeting of the Assoc. for Computational Linguistics (pp. 259-266)</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Brown</author>
<author>G Yule</author>
</authors>
<title>Discourse Analysis,</title>
<date>1983</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="942" citStr="Brown &amp; Yule 1983" startWordPosition="132" endWordPosition="135">olving certain lexical and structural ambiguities in spoken English. In this paper we present some results of employing two types of prosodic information, namely pitch and pause, to assist syntactic and semantic analysis during parsing. 1. INTRODUCTION In attempting to merge speech recognition and natural language understanding to produce a system capable of understanding spoken dialogues, we are confronted with a range of problems not found in text processing. Spoken language conversations are typically more terse, less grammatically correct, less wellstructured and more ambiguous than text (Brown &amp; Yule 1983). Additionally, speech recognition systems that attempt to extract words from speech typically produce word insertion, deletion or substitution errors due to incorrect recognition and segmentation. The motivation for our work is to combine speech recognition and natural language understanding (NLU) techniques to produce a system which can, in some sense, understand the intent of a speaker in telephone-based, information seeking dialogues. As a result, we are interested in NLU to improve the semantic recognition accuracy of such a system, but since we do not have explicit utterance segmentation</context>
</contexts>
<marker>Brown, Yule, 1983</marker>
<rawString>Brown, G., &amp; Yule, G., (1983), Discourse Analysis, Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N &amp; Halle Chomsky</author>
<author>M</author>
</authors>
<title>The Sound Pattern of English,</title>
<date>1968</date>
<location>(New York: Harper and Row).</location>
<marker>Chomsky, M, 1968</marker>
<rawString>Chomsky, N.&amp; Halle, M. (1968), The Sound Pattern of English, (New York: Harper and Row).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W E Cooper</author>
<author>J M Sorensen</author>
</authors>
<title>Fundamental Frequency Contours at Syntactic Boundaries,</title>
<date>1977</date>
<journal>Journal of the Acoustical Society of America,</journal>
<volume>62</volume>
<contexts>
<context position="8572" citStr="Cooper &amp; Sorensen 1977" startWordPosition="1315" endWordPosition="1318">ne groups, while longer moves may consist of several tone groups. With cue words for example, the cue forms its own tone group. 113 Pauses usually occur at points of low transitional probability and often mark phrase boundaries (Cruttenden 1986). In general, although pitch plays an important part, long pauses, indicate tone group and move boundaries, and short pauses indicate tone group boundaries. Exchange boundary markers are dealt with in the dialogue manager (not covered here). Pitch movements indicate turn-holding behaviour, topic changes, move completion and information contrastiveness (Cooper &amp; Sorensen 1977; Vonwilier 1991). The pre-processor also locates fixed expressions, so that during the parsing nondeterminism can be reduced. A problem here is that a cluster of words may be ambiguous in terms of whether they form a fixed expression or not. &amp;quot;Look after&amp;quot;, for example, means lake care of&amp;quot; in &amp;quot;Mary helped John to look after his kids&amp;quot;, whereas look&amp;quot; and &amp;quot;after&apos; have separate meaning in &amp;quot;I&apos;ll look after you do so&amp;quot;. The pre-processor makes use of tone group information to help resolve the fixed expression ambiguity. A more detailed discussion is given in section 5.2. 4. THE PARSER Once the input i</context>
</contexts>
<marker>Cooper, Sorensen, 1977</marker>
<rawString>Cooper, W.E. &amp; Sorensen, J.M., (1977), Fundamental Frequency Contours at Syntactic Boundaries, Journal of the Acoustical Society of America, Vol. 62, No. 3, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Cruttenden</author>
</authors>
<title>Intonation,</title>
<date>1986</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="6048" citStr="Cruttenden 1986" startWordPosition="917" endWordPosition="918">Although intonation reflects deeper issues, such as a speakers&apos; intended interpretation, it provides the surface structure for spoken language. Intonation is inherently supra-segmental, but it is also useful for segmentation purposes where other information is unavailable. Thus, intonation can be used to provide initial segmentation via a pre-processor for the parser. Although there are many prosodic features that are potentially useful in the understanding of spoken English, pitch and pause information have received the most attention due to ease of measurement and their relative importance (Cruttenden 1986, pp 3 &amp; 36). Our efforts to date use only these two feature types. We extract pitch and pause information from speech using specifically designed hardware with some software post-processing. The hardware performs frequency to amplitude transformation and filtering to produce an approximate pitch contour with pauses. The post-processing samples the pitch contour, determines the pitch range and classifies the instantaneous pitch into high, medium and low categories within that range. This is similar to that used in (Hirschberg &amp; Pierrehumbert 1986). Pauses are classed as short (less than 250ms)</context>
<context position="7885" citStr="Cruttenden 1986" startWordPosition="1209" endWordPosition="1211">SR word string, pitch markers and pauses, annotating the word string with pitch markers (low marked as&amp;quot; &amp;quot;, medium &amp;quot; - &amp;quot; and high &amp;quot;&apos;i &amp;quot; ) and pauses (short&amp;quot; &amp;quot; and long &amp;quot; ** &amp;quot;). The markers are synchronised with words or syllables. The pre-processor uses the pitch and pause markers to segment the word string into intonationallyconsistent groups, such as tone groups (boundaries marked as&amp;quot; &lt; &amp;quot;and &amp;quot;&gt; &amp;quot;) and moves (//). A tone group is a group of words whose intonational structure indicates that they form a major structural component of the speech, which is commonly also a major syntactic grouping (Cruttenden 1986, pp. 75 - 80). Short conversational moves often correspond to tone groups, while longer moves may consist of several tone groups. With cue words for example, the cue forms its own tone group. 113 Pauses usually occur at points of low transitional probability and often mark phrase boundaries (Cruttenden 1986). In general, although pitch plays an important part, long pauses, indicate tone group and move boundaries, and short pauses indicate tone group boundaries. Exchange boundary markers are dealt with in the dialogue manager (not covered here). Pitch movements indicate turn-holding behaviour,</context>
<context position="9388" citStr="Cruttenden 1986" startWordPosition="1459" endWordPosition="1461">ether they form a fixed expression or not. &amp;quot;Look after&amp;quot;, for example, means lake care of&amp;quot; in &amp;quot;Mary helped John to look after his kids&amp;quot;, whereas look&amp;quot; and &amp;quot;after&apos; have separate meaning in &amp;quot;I&apos;ll look after you do so&amp;quot;. The pre-processor makes use of tone group information to help resolve the fixed expression ambiguity. A more detailed discussion is given in section 5.2. 4. THE PARSER Once the input is segmented, moves annotated with prosody are input to the parser. The parser deals with one move at a time. In general, the intonational structure of a sentence and its syntactic structure coincide (Cruttenden 1986). Thus, prosodic segmentation avoids having the Parser try to extract moves from unsegmented word strings based solely on syntax. It also reduces the computational complexity in comparing syntactic and prosodic word groupings. There is a complication, however, in that tone group boundaries and move boundaries may not align exactly. This is not frequent, and is not present in the material used here. Intonation is used to limit the range of syntactic possibilities and the parser will align tone group and move syntactic boundaries at a later stage. By integrating syntax and semantics, the Parser </context>
</contexts>
<marker>Cruttenden, 1986</marker>
<rawString>Cruttenden, A., (1986), Intonation, Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hirschberg</author>
<author>D Litman</author>
</authors>
<title>Now Let&apos;s Talk About Now: Identifying Cue Phrases Intonationally, 25th Annual Meeting of the Assoc. for Computational Linguistics.</title>
<date>1987</date>
<contexts>
<context position="12381" citStr="Hirschberg &amp; Litman 1987" startWordPosition="1938" endWordPosition="1941"> and prosodic features. Most ambiguity is removed in the parse tree, though some is left for later resolution, such as definite and anaphoric references, whose resolution normally requires inter-move inferences. The parser also detects cue words in its input using prosody. Cue words, such as &amp;quot;now&amp;quot; in &amp;quot;Now, I want to ...&amp;quot;, are words whose meta-function in determining the structure of dialogues overrides their semantic roles (Reichman 1985).Cue words and phrases are prosodically distinct due to their high pitch and pause separation from tone groups that convey most of the propositional content (Hirschberg &amp; Litman 1987). While relatively unimportant semantically, cue words are very important in dialogue analysis due to their ability to indicate segmentation and the linkage of the dialogue components. 114 5. PROSODY AND DISAMBIGUATION During parsing prosodic information is used to help disambiguate certain structures which cannot be disambiguated syntactically/semantically, or whose processing demands extra efforts, if no such prosodic information is available. In general, prosody includes pitch, loudness, duration (of words, morphemes and pauses) and rhythm. While all of these are important cues, we are curr</context>
</contexts>
<marker>Hirschberg, Litman, 1987</marker>
<rawString>Hirschberg, J. &amp; Litman, D., (1987), Now Let&apos;s Talk About Now: Identifying Cue Phrases Intonationally, 25th Annual Meeting of the Assoc. for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hirschberg</author>
<author>J Pierrehumbert</author>
</authors>
<date>1986</date>
<booktitle>The Intonational Structure of Discourse, 24th Annual Meeting of the Assoc. for Computational Linguistics,</booktitle>
<contexts>
<context position="1736" citStr="Hirschberg &amp; Pierrehumbert 1986" startWordPosition="252" endWordPosition="255">rrect recognition and segmentation. The motivation for our work is to combine speech recognition and natural language understanding (NLU) techniques to produce a system which can, in some sense, understand the intent of a speaker in telephone-based, information seeking dialogues. As a result, we are interested in NLU to improve the semantic recognition accuracy of such a system, but since we do not have explicit utterance segmentation and structural information, such as punctuation in text, we have explored the use of prosody. Intonation can be useful in understanding dialogue structure (c.f. Hirschberg &amp; Pierrehumbert 1986), but parsing can also be assisted. (Briscoe &amp; Boguraev 1984) suggests that if prosodic structure could be derived for the noun compound Boron epoxy rocket motor chambers, then their parser LEXICAT could reduce the fourteen licit morphosyntactic interpretations to one correct analysis without error (p. 262). (Steedman 1990) explores taking advantage of intonational structure in spoken sentence understanding in the combinatory categorial grammar formalism. (Bear &amp; Price 1990) discusses integrating prosody and syntax in parsing spoken English, relative duration of phonetic segments being the one</context>
<context position="6601" citStr="Hirschberg &amp; Pierrehumbert 1986" startWordPosition="1000" endWordPosition="1003">ntion due to ease of measurement and their relative importance (Cruttenden 1986, pp 3 &amp; 36). Our efforts to date use only these two feature types. We extract pitch and pause information from speech using specifically designed hardware with some software post-processing. The hardware performs frequency to amplitude transformation and filtering to produce an approximate pitch contour with pauses. The post-processing samples the pitch contour, determines the pitch range and classifies the instantaneous pitch into high, medium and low categories within that range. This is similar to that used in (Hirschberg &amp; Pierrehumbert 1986). Pauses are classed as short (less than 250ms), long (between 250ms and 800ms) or extended (greater than 800ms). These times were empirically derived from spoken information seeking dialogues conducted over a telephone to human operators. Short pauses signify strong turn-holding behaviour, long pauses signify weaker turnholding behaviour and extended pauses signify turn passing or exchange completion (Vonwiller 1991). These interpretations can vary with certain pitch movements, however. Unvoiced sounds are distinguished from pauses by subsequent synchronisation of prosodic features with the w</context>
</contexts>
<marker>Hirschberg, Pierrehumbert, 1986</marker>
<rawString>Hirschberg, J. &amp; Pierrehumbert, J., The Intonational Structure of Discourse, 24th Annual Meeting of the Assoc. for Computational Linguistics, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X-M Huang</author>
</authors>
<title>Semantic Analysis in XTRA, An English -</title>
<date>1988</date>
<booktitle>Chinese Machine Translation System, Computers and Translation 3, No.2.</booktitle>
<pages>101--120</pages>
<contexts>
<context position="10180" citStr="Huang 1988" startWordPosition="1587" endWordPosition="1588">paring syntactic and prosodic word groupings. There is a complication, however, in that tone group boundaries and move boundaries may not align exactly. This is not frequent, and is not present in the material used here. Intonation is used to limit the range of syntactic possibilities and the parser will align tone group and move syntactic boundaries at a later stage. By integrating syntax and semantics, the Parser is capable of resolving most of the ambiguous structures it encounters in parsing written English sentences, such as coordinate conjunctions, PP attachments, and lexical ambiguity (Huang 1988). Migrating the Parser from written to spoken English is our current focus. Moves input to the Parser are unlikely to be well-formed sentences, as people do not always speak grammatically, or due to the SR&apos;s inability to accurately recognise the actual words spoken. The parser first assumes that the input move is lexically correct and tries to obtain a parse for it, employing syntactic and semantic relaxation techniques for handling ill-formed sentences (Huang 1988). If no acceptable analysis is produced, the parser asks the SR to provide the next alternative word string. Exchanges between the</context>
</contexts>
<marker>Huang, 1988</marker>
<rawString>Huang, X-M. (1988), Semantic Analysis in XTRA, An English - Chinese Machine Translation System, Computers and Translation 3, No.2. (pp. 101-120)</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pereira</author>
<author>D Warren</author>
</authors>
<title>Definite Clause Grammars for Language Analysis - A Survey of the Formalism and A Comparison with Augmented Transition Networks.</title>
<date>1980</date>
<journal>Artificial Intelligence,</journal>
<pages>13--231</pages>
<marker>Pereira, Warren, 1980</marker>
<rawString>Pereira, F. &amp; Warren, D. (1980), Definite Clause Grammars for Language Analysis - A Survey of the Formalism and A Comparison with Augmented Transition Networks. Artificial Intelligence, 13:231-278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P J Price</author>
<author>M Ostendorf</author>
<author>C W VVightmen</author>
</authors>
<date>1989</date>
<booktitle>Prosody and Parsing. DARPA Workshop on Speech and Natural Language, Cape Cod,</booktitle>
<pages>5--11</pages>
<contexts>
<context position="2774" citStr="Price et al 1989" startWordPosition="411" endWordPosition="414">binatory categorial grammar formalism. (Bear &amp; Price 1990) discusses integrating prosody and syntax in parsing spoken English, relative duration of phonetic segments being the one aspect of prosody examined. Compared with the efforts expended on syntactic/semantic disambiguation mechanisms, prosody is still an under-exploited area. No work has yet been carried out which treats prosody at the same level as syntax, semantics, and pragmatics, even though evidence shows that prosody is as important as the other means in human understanding of utterances (see, for example, experiments reported in (Price et al 1989)). (Scott &amp; Cutler 1984) noticed that listeners can successfully identify the intended meaning of ambiguous sentences even in the absence of a disambiguating context, and suggested that speakers can exploit acoustic features to highlight the distinction that is to be conveyed to the listener (p. 450). Our current work incorporates certain prosodic information into the process of parsing, combining syntax, semantics, pragmatics and prosody for disambiguationl. The context of the work is an electronic directory assistance system (Rowles et al 1990). In the following sections, an overview of the </context>
</contexts>
<marker>Price, Ostendorf, VVightmen, 1989</marker>
<rawString>Price, P. J., Ostendorf, M. &amp; VVightmen, C.W. (1989), Prosody and Parsing. DARPA Workshop on Speech and Natural Language, Cape Cod, October 1989 (pp.5-11).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Reichman</author>
</authors>
<title>Getting Computers to Talk Like You and Me,</title>
<date>1985</date>
<publisher>MIT Press).</publisher>
<location>Cambridge:</location>
<contexts>
<context position="12198" citStr="Reichman 1985" startWordPosition="1911" endWordPosition="1912"> The dialogue manager queries the speaker if sentences cannot be analysed at the pragmatic stage. The output of the parser is a parse tree that contains syntactic, semantic and prosodic features. Most ambiguity is removed in the parse tree, though some is left for later resolution, such as definite and anaphoric references, whose resolution normally requires inter-move inferences. The parser also detects cue words in its input using prosody. Cue words, such as &amp;quot;now&amp;quot; in &amp;quot;Now, I want to ...&amp;quot;, are words whose meta-function in determining the structure of dialogues overrides their semantic roles (Reichman 1985).Cue words and phrases are prosodically distinct due to their high pitch and pause separation from tone groups that convey most of the propositional content (Hirschberg &amp; Litman 1987). While relatively unimportant semantically, cue words are very important in dialogue analysis due to their ability to indicate segmentation and the linkage of the dialogue components. 114 5. PROSODY AND DISAMBIGUATION During parsing prosodic information is used to help disambiguate certain structures which cannot be disambiguated syntactically/semantically, or whose processing demands extra efforts, if no such pr</context>
</contexts>
<marker>Reichman, 1985</marker>
<rawString>Reichman, R. (1985), Getting Computers to Talk Like You and Me, (Cambridge: MIT Press).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Rowles</author>
</authors>
<title>Recognizing User Intentions from Natural language Expressions,</title>
<date>1989</date>
<booktitle>First Australia-Japan Joint Symposium on Natural Language Processing,</booktitle>
<pages>157--166</pages>
<contexts>
<context position="11355" citStr="Rowles, 1989" startWordPosition="1773" endWordPosition="1774">ive word string. Exchanges between the parser and the SR are needed for handling situations where an illformed utterance gets further distorted by the SR. In these cases other knowledge sources such as pragmatics, dialogue analysis, and dialogue management must be used to find the most likely interpretation for the input string. We use pragmatics and knowledge of dialogue structure to find the semantic links between separate conversational moves by either participant and resolve indirectness such as pronouns, deictic expressions and brief responses to the other speaker [for more details, see (Rowles, 1989)]. By determining the dialogue purpose of utterances and their domain context, it is then possible to correct some of the insertion and mis-recognised word errors from the SR and determine the communicative intent of the speaker. The dialogue manager queries the speaker if sentences cannot be analysed at the pragmatic stage. The output of the parser is a parse tree that contains syntactic, semantic and prosodic features. Most ambiguity is removed in the parse tree, though some is left for later resolution, such as definite and anaphoric references, whose resolution normally requires inter-move</context>
</contexts>
<marker>Rowles, 1989</marker>
<rawString>Rowles, C.D. (1989), Recognizing User Intentions from Natural language Expressions, First Australia-Japan Joint Symposium on Natural Language Processing, (pp.157-166).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Rowles</author>
<author>X Huang</author>
<author>G Aumann</author>
</authors>
<title>Natural Language Understanding and Speech Recognition: Exploring the Connections,</title>
<date>1990</date>
<booktitle>Third Australian International Conference on Speech Science and Technology,</booktitle>
<pages>374--382</pages>
<contexts>
<context position="3326" citStr="Rowles et al 1990" startWordPosition="497" endWordPosition="500">nces (see, for example, experiments reported in (Price et al 1989)). (Scott &amp; Cutler 1984) noticed that listeners can successfully identify the intended meaning of ambiguous sentences even in the absence of a disambiguating context, and suggested that speakers can exploit acoustic features to highlight the distinction that is to be conveyed to the listener (p. 450). Our current work incorporates certain prosodic information into the process of parsing, combining syntax, semantics, pragmatics and prosody for disambiguationl. The context of the work is an electronic directory assistance system (Rowles et al 1990). In the following sections, an overview of the system is first given (Section 2). Then the parser is described in Section 3. Section 4 discusses how prosody can be employed in helping resolve ambiguity involved in process1. Another possible acoustic source to help disambiguation is &amp;quot;segmental phonology&amp;quot;, the application of certain phonological assimilation and elision rules (Scott &amp; Cutler 1984). The current work makes no attempt at this aspect. 112 ing fixed expressions, prepositional phrase attachment (PP attachment), and coordinate constructions. Section 5 shows the implementation of the p</context>
</contexts>
<marker>Rowles, Huang, Aumann, 1990</marker>
<rawString>Rowles, C.D., Huang, X., and Aumann, G., (1990), Natural Language Understanding and Speech Recognition: Exploring the Connections, Third Australian International Conference on Speech Science and Technology, (pp. 374 - 382).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
</authors>
<title>and Intonation in Spoken Language Understanding.</title>
<date>1990</date>
<booktitle>28th Annual Meeting of the Assoc. for Computational Linguistics</booktitle>
<pages>9--16</pages>
<contexts>
<context position="2061" citStr="Steedman 1990" startWordPosition="304" endWordPosition="305">recognition accuracy of such a system, but since we do not have explicit utterance segmentation and structural information, such as punctuation in text, we have explored the use of prosody. Intonation can be useful in understanding dialogue structure (c.f. Hirschberg &amp; Pierrehumbert 1986), but parsing can also be assisted. (Briscoe &amp; Boguraev 1984) suggests that if prosodic structure could be derived for the noun compound Boron epoxy rocket motor chambers, then their parser LEXICAT could reduce the fourteen licit morphosyntactic interpretations to one correct analysis without error (p. 262). (Steedman 1990) explores taking advantage of intonational structure in spoken sentence understanding in the combinatory categorial grammar formalism. (Bear &amp; Price 1990) discusses integrating prosody and syntax in parsing spoken English, relative duration of phonetic segments being the one aspect of prosody examined. Compared with the efforts expended on syntactic/semantic disambiguation mechanisms, prosody is still an under-exploited area. No work has yet been carried out which treats prosody at the same level as syntax, semantics, and pragmatics, even though evidence shows that prosody is as important as t</context>
<context position="15913" citStr="Steedman 1990" startWordPosition="2484" endWordPosition="2485"> no_pause jn_between(FirstW, SecondW), fix_e([FirstW, SecondVV], FixedE), Match_fix_e(RestW, MoreVV). This rule produces the following segmen 1- tions: (5.1a) &lt;-He -gave&gt; *&lt;^up to ^two hundred dollars&gt; *&lt;-to the Acharity&gt;&amp;quot;// (5.1b) &lt;-He ^gave ^up&gt; *&lt;^two hundred dollars&gt; *&lt;-for damage compensation&gt;&amp;quot;//. In (5.1a), gave and up to are treated as belonging to two separate tone groups, whereas in (5.1b) gave up is marked as one tone group. The pre-processor checking its fixed expression dictionary will therefore convert up to in (5.1a) to up to, and gave up in (5.1b) to gave_up. 5.3 PP ATTACHMENT (Steedman 1990 &amp; Crittenden 1986) observed that intonational structure is strongly constrained by meaning. For example, an intonation imposing bracketings like the following is not allowed: (5.2) &lt;Three cats&gt; &lt;in ten prefer corduroy&gt;// Conversely, the actual contour detected for the input can be significant in helping decide the segmentation and resolving PP attachment. In the following sentence, f.g., (5.3) &lt;I would like&gt; &lt; information on her arrival&gt; [&amp;quot;on her arrival&amp;quot; attached to &amp;quot;information 115 (5.4) &lt;I would like&gt; &lt;information&gt; ** &lt;on her arrival&gt; [&amp;quot;on her arrival&amp;quot; attached to &amp;quot;like] the pause after &amp;quot;i</context>
</contexts>
<marker>Steedman, 1990</marker>
<rawString>Steedman, M. (1990),Structure and Intonation in Spoken Language Understanding. 28th Annual Meeting of the Assoc. for Computational Linguistics (pp. 9-16).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Scott</author>
<author>A Cutler</author>
</authors>
<title>Segmental Phonology and the Perception of Syntactic Structure,</title>
<date>1984</date>
<journal>Journal of Verbal Learning and Verbal Behavior</journal>
<volume>23</volume>
<pages>450--466</pages>
<contexts>
<context position="2798" citStr="Scott &amp; Cutler 1984" startWordPosition="415" endWordPosition="418">rammar formalism. (Bear &amp; Price 1990) discusses integrating prosody and syntax in parsing spoken English, relative duration of phonetic segments being the one aspect of prosody examined. Compared with the efforts expended on syntactic/semantic disambiguation mechanisms, prosody is still an under-exploited area. No work has yet been carried out which treats prosody at the same level as syntax, semantics, and pragmatics, even though evidence shows that prosody is as important as the other means in human understanding of utterances (see, for example, experiments reported in (Price et al 1989)). (Scott &amp; Cutler 1984) noticed that listeners can successfully identify the intended meaning of ambiguous sentences even in the absence of a disambiguating context, and suggested that speakers can exploit acoustic features to highlight the distinction that is to be conveyed to the listener (p. 450). Our current work incorporates certain prosodic information into the process of parsing, combining syntax, semantics, pragmatics and prosody for disambiguationl. The context of the work is an electronic directory assistance system (Rowles et al 1990). In the following sections, an overview of the system is first given (S</context>
</contexts>
<marker>Scott, Cutler, 1984</marker>
<rawString>Scott, D.R &amp; Cutler, A. (1984), Segmental Phonology and the Perception of Syntactic Structure, Journal of Verbal Learning and Verbal Behavior 23, (pp. 450-466).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Vonwiller</author>
</authors>
<title>Empirical Study of Some Features of Intonation,</title>
<date>1991</date>
<booktitle>Second AustraliaJapan Natural Language Processing Symposium,</booktitle>
<pages>66--71</pages>
<location>Japan,</location>
<contexts>
<context position="7022" citStr="Vonwiller 1991" startWordPosition="1064" endWordPosition="1065">ntour, determines the pitch range and classifies the instantaneous pitch into high, medium and low categories within that range. This is similar to that used in (Hirschberg &amp; Pierrehumbert 1986). Pauses are classed as short (less than 250ms), long (between 250ms and 800ms) or extended (greater than 800ms). These times were empirically derived from spoken information seeking dialogues conducted over a telephone to human operators. Short pauses signify strong turn-holding behaviour, long pauses signify weaker turnholding behaviour and extended pauses signify turn passing or exchange completion (Vonwiller 1991). These interpretations can vary with certain pitch movements, however. Unvoiced sounds are distinguished from pauses by subsequent synchronisation of prosodic features with the word stream by post-processing. A parser pre-processor then takes the SR word string, pitch markers and pauses, annotating the word string with pitch markers (low marked as&amp;quot; &amp;quot;, medium &amp;quot; - &amp;quot; and high &amp;quot;&apos;i &amp;quot; ) and pauses (short&amp;quot; &amp;quot; and long &amp;quot; ** &amp;quot;). The markers are synchronised with words or syllables. The pre-processor uses the pitch and pause markers to segment the word string into intonationallyconsistent groups, such a</context>
</contexts>
<marker>Vonwiller, 1991</marker>
<rawString>Vonwiller, J. (1991),An Empirical Study of Some Features of Intonation, Second AustraliaJapan Natural Language Processing Symposium, Japan, November, (pp 66-71).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>