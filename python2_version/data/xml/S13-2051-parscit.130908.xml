<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.066445">
<title confidence="0.942045">
unimelb: Topic Modelling-based Word Sense Induction
</title>
<author confidence="0.996998">
Jey Han Lau, Paul Cook and Timothy Baldwin
</author>
<affiliation confidence="0.9964595">
Department of Computing and Information Systems
The University of Melbourne
</affiliation>
<email confidence="0.975647">
jhlau@csse.unimelb.edu.au, paulcook@unimelb.edu.au,
tb@ldwin.net
</email>
<sectionHeader confidence="0.998499" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998788">
This paper describes our system for shared
task 13 “Word Sense Induction for Graded and
Non-Graded Senses” of SemEval-2013. The
task is on word sense induction (WSI), and
builds on earlier SemEval WSI tasks in ex-
ploring the possibility of multiple senses be-
ing compatible to varying degrees with a sin-
gle contextual instance: participants are asked
to grade senses rather than selecting a sin-
gle sense like most word sense disambigua-
tion (WSD) settings. The evaluation measures
are designed to assess how well a system per-
ceives the different senses in a contextual in-
stance. We adopt a previously-proposed WSI
methodology for the task, which is based on a
Hierarchical Dirichlet Process (HDP), a non-
parametric topic model. Our system requires
no parameter tuning, uses the English ukWaC
as an external resource, and achieves encour-
aging results over the shared task.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999760117647059">
In our previous work (Lau et al., 2012) we devel-
oped a word-sense induction (WSI) system based on
topic modelling, specifically a Hierarchical Dirich-
let Process (Teh et al., 2006). In evaluations over
the SemEval-2007 and SemEval-2010 WSI tasks we
achieved performance on par with the current state-
of-the art. The SemEval-2007 and SemEval-2010
WSI tasks assumed that each usage of a word has
a single gold-standard sense. In this paper we apply
this WSI method “off-the-shelf”, with no adaptation,
to the novel SemEval-2013 task of “Word Sense In-
duction for Graded and Non-Graded Senses”. Given
that the topic model allocates a multinomial distri-
bution over topics to each word usage (“document”,
in topic modelling terms), the SemEval-2013 WSI
task is an ideal means for evaluating this aspect of
the topic model.
</bodyText>
<sectionHeader confidence="0.98875" genericHeader="method">
2 System Description
</sectionHeader>
<bodyText confidence="0.980253466666667">
Our system is based on the WSI methodology pro-
posed by Lau et al. (2012), and also applied to
SemEval-2013 Task 11 on WSI for web snippet
clustering (Lau et al., to appear). The core machin-
ery of our system is driven by a Latent Dirichlet Al-
location (LDA) topic model (Blei et al., 2003). In
LDA, the model learns latent topics for a collection
of documents, and associates these latent topics with
every document in the collection. A topic is repre-
sented by a multinomial distribution of words, and
the association of topics with documents is repre-
sented by a multinomial distribution of topics, a dis-
tribution for each document. The generative process
of LDA for drawing word w in document d is as fol-
lows:
</bodyText>
<listItem confidence="0.9655035">
1. draw latent topic z from document d;
2. draw word w from the chosen latent topic z.
</listItem>
<bodyText confidence="0.7567835">
The probability of selecting word w given a doc-
ument d is thus given by:
</bodyText>
<equation confidence="0.991122666666667">
T
P(wld) = E P(wlt = z)P(t = z1d).
z=1
</equation>
<bodyText confidence="0.9426845">
where t is the topic variable, and T is the number of
topics.
</bodyText>
<page confidence="0.980596">
307
</page>
<bodyText confidence="0.977814739130435">
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 307–311, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
The number of topics, T, is a parameter in LDA.
We relax this assumption by extending the model
to be non-parametric, using a Hierarchical Dirichlet
Process (HDP: (Teh et al., 2006)). HDP learns the
number of topics based on data, with the concentra-
tion parameters -y and α0 controlling the variability
of topics in the documents (for details of HDP please
refer to the original paper).
To apply HDP to WSI, the latent topics are in-
terpreted as the word senses, and the documents are
usages that contain the target word of interest. That
is, given a target word (e.g. paper), a “document”
in our application is a sentence context surround-
ing the target word. In addition to the bag of words
surrounding the target word, we also include posi-
tional context word information, which was used in
our earlier work (Lau et al., 2012). That is, we in-
troduce an additional word feature for each of the
three words to the left and right of the target word.
An example of the topic model features is given in
Table 1.
</bodyText>
<subsectionHeader confidence="0.999369">
2.1 Background Corpus and Preprocessing
</subsectionHeader>
<bodyText confidence="0.99906117948718">
The test dataset provides us with contextual in-
stances for each target word, and these instances
constitute the documents for the topic model. The
text of the test data is tokenised and lemmatised us-
ing OpenNLP and Morpha (Minnen et al., 2001).
Note, however, that there are only 100 instances
for most target words in the test dataset, and as such
the dataset may be too small for the topic model
to induce meaningful senses. To this end, we turn
to the English ukWaC — a web corpus of approxi-
mately 1.9 billion tokens — to expand the data, by
extracting context sentences that contain the target
word. Each extracted usage is a three-sentence con-
text containing the target word: the original sentence
that contains the actual usage and its preceding and
succeeding sentences. The extraction of usages from
the ukWaC significantly increases the amount of in-
formation for the topic model to learn the senses for
the target words from. However, HDP is compu-
tationally intensive, so we limit the number of ex-
tracted usages from the ukWaC using two sampling
approaches:
UNIMELB (5P) Take a 5% random sample of us-
ages;
UNIMELB (50K) Limit the maximum number of
randomly-sampled usages to 50,000 instances.
The usages from the ukWaC are tokenised and
lemmatised using TreeTagger (Schmid, 1994), as
provided by the corpus.
To summarise, for each target word we apply
the HDP model to the combined collection of the
test instances (provided by the shared task) and
the extracted usages from the English ukWaC (not-
ing that each instance/usage corresponds to a topic
model “document”). The topic model learns the
senses/topics for all documents in the collection, but
we only use the sense/topic distribution for the test
instances as they are the ones evaluated in the shared
task.
</bodyText>
<sectionHeader confidence="0.999391" genericHeader="evaluation">
3 Experiments and Results
</sectionHeader>
<bodyText confidence="0.995379612903226">
Following Lau et al. (2012), we use the default pa-
rameters (-y = 0.1 and α0 = 1.0) for HDP.1 For each
target word, we apply HDP to induce the senses, and
a distribution of senses is produced for each “docu-
ment” in the model. To grade the senses for the in-
stances in the test dataset, we apply the sense proba-
bilities learnt by the topic model as the sense weights
without any modification.
To illustrate the senses induced by our model, we
present the top-10 words of the induced senses for
the verb strike in Table 2. Although 13 senses in
total are induced and some of them do not seem very
coherent, only the first 8 senses — the more coherent
ones — are observed (i.e., have non-zero probability
for any usage) in the test dataset.
Two forms of evaluation are used in the task:
WSD evaluation and clustering comparison. For
WSD evaluation, three measures are used: (1)
Jaccard Index (JI), which measures the degree of
overlap between the induced senses and the gold
senses; (2) positionally-weighted Kendall’s tau (KT:
(Kumar and Vassilvitskii, 2010)), which measures
the correlation between the ranking of the induced
senses and that of the gold senses; and (3) nor-
malised discounted cumulative gain (NDCG), which
1These settings were considered “vague” priors in Teh et
al. (2006). They were tested in Lau et al. (2012) and the
model was shown to be robust under different parameter set-
tings. As such we decided to keep the settings. The imple-
mentation of our WSI system can be accessed via GitHub:
https://github.com/jhlau/hdp-wsi.
</bodyText>
<page confidence="0.997815">
308
</page>
<table confidence="0.530117">
Target word dogs
Context sentence Most breeds of dogs are at most a few hundred years old
Bag-of-word features most, breeds, of, are, at, most, a, few, hundred, years, old
Positional word features most #-3, breeds #-2, of #-1, are #1, at #2, most #3
</table>
<tableCaption confidence="0.997858">
Table 1: An example of the topic model features.
</tableCaption>
<figure confidence="0.932444428571429">
Sense Num Top-10 Terms
1 strike @card@ worker union war iraq week pay government action
2 strike hand god head n’t look face fall leave blow
3 strike @card@ balance court company case need balance #1 order claim
4 strike ball @card@ minute game goal play player shot half
5 strike @card@ people fire disaster area road car ship lightning
6 @card@ strike new news post deal april home business week
7 strike n’t people thing think way life book find new
8 @card@ strike coin die john church police age house william
9 div ukl syn color hunter text-decoration australian verb condom font-size
10 invent rocamadour cost mp3 terminal total wav honor omen node
11 training run rush kata performance marathon exercise technique workout interval
12 wrong qha september/2000 sayd — hawksmoor thyna pan salt common
13 zidane offering stone blow zidane #-1 type type #2 zidane #1 blow #3 materials
</figure>
<tableCaption confidence="0.966665">
Table 2: The top-10 terms for each of the senses induced for the verb strike by the HDP model.
</tableCaption>
<bodyText confidence="0.999524880952381">
measures the correlation between the weights of
the induced senses and that of the gold senses.
For clustering comparison, fuzzy normalised mu-
tual information (FNMI) and fuzzy b-cubed (FBC)
are used. Note that the WSD systems participat-
ing in this shared task are not evaluated with clus-
tering comparison metrics, as they do not induce
senses/clusters in the same manner as WSI systems.
WSI systems produce senses that are different to
the gold standard sense inventory (WordNet 3.1),
and the induced senses are mapped to the gold stan-
dard senses using the 80/20 validation setting. De-
tails of this mapping procedure are described in Jur-
gens (2012).
Results for all test instances are presented in Ta-
ble 3. Note that many baselines are used, only some
of which we present in this paper, namely: (1) RAN-
DOM — label instances with one of three random in-
duced senses; (2) SEMCOR MFS — label instances
with the most frequently occurring sense in Semcor;
(3) TEST MFS — label instances with the most fre-
quently occurring sense in the test dataset. To bench-
mark our method, we present one or two of the best
systems from each team.
Looking at Table 3, our system performs encour-
agingly well. Although not the best system, we
achieve results close to the best system for each eval-
uation measure.
Most of the instances in the data were annotated
with only one sense; only 11% were annotated with
two senses, and 0.5% with three. As a result, the
task organisers categorised the instances into single-
sense instances and multi-sense instances to bet-
ter analyse the performance of participating sys-
tems. Results for single-sense and multi-sense in-
stances are presented in Table 4 and Table 5, re-
spectively. Note that for single-sense instances, only
precision is used for WSD evaluation as the Jaccard
Index, positionally-weighted Kendall’s tau and nor-
malised discounted cumulative gain are not applica-
ble. Our system performs relatively well, and trails
marginally behind the best system in most cases.
</bodyText>
<sectionHeader confidence="0.999667" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.9996765">
We adopt a WSI methodology from Lau et al. (2012)
for the task of grading senses in a WSD setting.
</bodyText>
<page confidence="0.996253">
309
</page>
<table confidence="0.9992243">
System JI KT NDCG FNMI FBC
RANDOM 0.244 0.633 0.287 0.018 0.382
SEMCOR MFS 0.455 0.465 0.339 — —
TEST MFS 0.552 0.560 0.412 — —
AI-KU 0.197 0.620 0.387 0.065 0.390
AI-KU (REMOVE5-AD1000) 0.244 0.642 0.332 0.039 0.451
LA SAPIENZA (2) 0.149 0.510 0.383 — —
UOS (TOP-3) 0.232 0.625 0.374 0.045 0.448
UNIMELB (5P) 0.218 0.614 0.365 0.056 0.459
UNIMELB (50K) 0.213 0.620 0.371 0.060 0.483
</table>
<tableCaption confidence="0.952612">
Table 3: Results for all instances. The best-performing system is indicated in boldface.
</tableCaption>
<table confidence="0.999973">
System Precision FNMI FBC
RANDOM 0.555 0.010 0.359
SEMCOR MFS 0.477 — —
TEST MFS 0.578 — —
AI-KU 0.641 0.045 0.351
AI-KU (REMOVE5-AD1000) 0.628 0.026 0.421
UOS (TOP-3) 0.600 0.028 0.414
UNIMELB (5P) 0.596 0.035 0.421
UNIMELB (50K) 0.605 0.039 0.441
</table>
<tableCaption confidence="0.951008">
Table 4: Results for single-sense instances. The best-performing system is indicated in boldface.
</tableCaption>
<table confidence="0.9999182">
System JI KT NDCG FNMI FBC
RANDOM 0.429 0.548 0.236 0.006 0.113
SEMCOR MFS 0.283 0.373 0.197 — —
TEST MFS 0.354 0.426 0.248 — —
AI-KU 0.394 0.617 0.317 0.029 0.078
AI-KU (REMOVE5-AD1000) 0.434 0.586 0.291 0.004 0.116
LA SAPIENZA (2) 0.263 0.531 0.365 — —
UOS (#WN SENSES) 0.387 0.628 0.314 0.036 0.037
UNIMELB (5P) 0.426 0.586 0.287 0.019 0.130
UNIMELB (50K) 0.414 0.602 0.299 0.021 0.134
</table>
<tableCaption confidence="0.996095">
Table 5: Results for multi-sense instances. The best-performing system is indicated in boldface.
</tableCaption>
<page confidence="0.996937">
310
</page>
<bodyText confidence="0.999969333333333">
With no parameter tuning and using only the English
ukWaC as an external resource, our system performs
relatively well at the task.
</bodyText>
<sectionHeader confidence="0.998475" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99965303030303">
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent Dirichlet allocation. Journal of Machine
Learning Research, 3:993–1022.
David Jurgens. 2012. An evaluation of graded sense
disambiguation using word sense induction. In Proc.
of the First Joint Conference on Lexical and Com-
putational Semantics (*SEM 2012), pages 189–198,
Montr´eal, Canada.
Ravi Kumar and Sergei Vassilvitskii. 2010. Generalized
distances between rankings. In Proc. of the 19th Inter-
national Conference on the World Wide Web (WWW
2010), pages 571–580, Raleigh, USA.
Jey Han Lau, Paul Cook, Diana McCarthy, David New-
man, and Timothy Baldwin. 2012. Word sense induc-
tion for novel sense detection. In Proc. of the 13th
Conference of the EACL (EACL 2012), pages 591–
601, Avignon, France.
Jey Han Lau, Paul Cook, and Timothy Baldwin. to ap-
pear. unimelb: Topic modelling-based word sense in-
duction for web snippet clustering. In Proc. of the 7th
International Workshop on Semantic Evaluation (Se-
mEval 2013).
Guido Minnen, John Carroll, and Darren Pearce. 2001.
Applied morphological processing of English. Natu-
ral Language Engineering, 7(3):207–223.
Helmut Schmid. 1994. Probabilistic part-of-speech tag-
ging using decision trees. In Proc. of the Confer-
ence on New Methods in Natural Language Process-
ing, Manchester, 1994.
Yee Whye Teh, Michael I. Jordan, Matthew J. Beal, and
David M. Blei. 2006. Hierarchical Dirichlet pro-
cesses. Journal of the American Statistical Associa-
tion, 101:1566–1581.
</reference>
<page confidence="0.999007">
311
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.965523">
<title confidence="0.99986">unimelb: Topic Modelling-based Word Sense Induction</title>
<author confidence="0.999558">Han Lau</author>
<author confidence="0.999558">Paul Cook</author>
<affiliation confidence="0.9990065">Department of Computing and Information The University of Melbourne</affiliation>
<email confidence="0.988626">tb@ldwin.net</email>
<abstract confidence="0.998779428571429">This paper describes our system for shared task 13 “Word Sense Induction for Graded and Non-Graded Senses” of SemEval-2013. The task is on word sense induction (WSI), and builds on earlier SemEval WSI tasks in exploring the possibility of multiple senses being compatible to varying degrees with a single contextual instance: participants are asked rather than selecting a single sense like most word sense disambiguation (WSD) settings. The evaluation measures are designed to assess how well a system perceives the different senses in a contextual instance. We adopt a previously-proposed WSI methodology for the task, which is based on a Hierarchical Dirichlet Process (HDP), a nonparametric topic model. Our system requires no parameter tuning, uses the English ukWaC as an external resource, and achieves encouraging results over the shared task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent Dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="2251" citStr="Blei et al., 2003" startWordPosition="358" endWordPosition="361">novel SemEval-2013 task of “Word Sense Induction for Graded and Non-Graded Senses”. Given that the topic model allocates a multinomial distribution over topics to each word usage (“document”, in topic modelling terms), the SemEval-2013 WSI task is an ideal means for evaluating this aspect of the topic model. 2 System Description Our system is based on the WSI methodology proposed by Lau et al. (2012), and also applied to SemEval-2013 Task 11 on WSI for web snippet clustering (Lau et al., to appear). The core machinery of our system is driven by a Latent Dirichlet Allocation (LDA) topic model (Blei et al., 2003). In LDA, the model learns latent topics for a collection of documents, and associates these latent topics with every document in the collection. A topic is represented by a multinomial distribution of words, and the association of topics with documents is represented by a multinomial distribution of topics, a distribution for each document. The generative process of LDA for drawing word w in document d is as follows: 1. draw latent topic z from document d; 2. draw word w from the chosen latent topic z. The probability of selecting word w given a document d is thus given by: T P(wld) = E P(wlt</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent Dirichlet allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Jurgens</author>
</authors>
<title>An evaluation of graded sense disambiguation using word sense induction.</title>
<date>2012</date>
<booktitle>In Proc. of the First Joint Conference on Lexical and Computational Semantics (*SEM 2012),</booktitle>
<pages>189--198</pages>
<location>Montr´eal, Canada.</location>
<contexts>
<context position="9509" citStr="Jurgens (2012)" startWordPosition="1607" endWordPosition="1609">he weights of the induced senses and that of the gold senses. For clustering comparison, fuzzy normalised mutual information (FNMI) and fuzzy b-cubed (FBC) are used. Note that the WSD systems participating in this shared task are not evaluated with clustering comparison metrics, as they do not induce senses/clusters in the same manner as WSI systems. WSI systems produce senses that are different to the gold standard sense inventory (WordNet 3.1), and the induced senses are mapped to the gold standard senses using the 80/20 validation setting. Details of this mapping procedure are described in Jurgens (2012). Results for all test instances are presented in Table 3. Note that many baselines are used, only some of which we present in this paper, namely: (1) RANDOM — label instances with one of three random induced senses; (2) SEMCOR MFS — label instances with the most frequently occurring sense in Semcor; (3) TEST MFS — label instances with the most frequently occurring sense in the test dataset. To benchmark our method, we present one or two of the best systems from each team. Looking at Table 3, our system performs encouragingly well. Although not the best system, we achieve results close to the </context>
</contexts>
<marker>Jurgens, 2012</marker>
<rawString>David Jurgens. 2012. An evaluation of graded sense disambiguation using word sense induction. In Proc. of the First Joint Conference on Lexical and Computational Semantics (*SEM 2012), pages 189–198, Montr´eal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ravi Kumar</author>
<author>Sergei Vassilvitskii</author>
</authors>
<title>Generalized distances between rankings.</title>
<date>2010</date>
<booktitle>In Proc. of the 19th International Conference on the World Wide Web (WWW 2010),</booktitle>
<pages>571--580</pages>
<location>Raleigh, USA.</location>
<contexts>
<context position="7090" citStr="Kumar and Vassilvitskii, 2010" startWordPosition="1194" endWordPosition="1197">y our model, we present the top-10 words of the induced senses for the verb strike in Table 2. Although 13 senses in total are induced and some of them do not seem very coherent, only the first 8 senses — the more coherent ones — are observed (i.e., have non-zero probability for any usage) in the test dataset. Two forms of evaluation are used in the task: WSD evaluation and clustering comparison. For WSD evaluation, three measures are used: (1) Jaccard Index (JI), which measures the degree of overlap between the induced senses and the gold senses; (2) positionally-weighted Kendall’s tau (KT: (Kumar and Vassilvitskii, 2010)), which measures the correlation between the ranking of the induced senses and that of the gold senses; and (3) normalised discounted cumulative gain (NDCG), which 1These settings were considered “vague” priors in Teh et al. (2006). They were tested in Lau et al. (2012) and the model was shown to be robust under different parameter settings. As such we decided to keep the settings. The implementation of our WSI system can be accessed via GitHub: https://github.com/jhlau/hdp-wsi. 308 Target word dogs Context sentence Most breeds of dogs are at most a few hundred years old Bag-of-word features </context>
</contexts>
<marker>Kumar, Vassilvitskii, 2010</marker>
<rawString>Ravi Kumar and Sergei Vassilvitskii. 2010. Generalized distances between rankings. In Proc. of the 19th International Conference on the World Wide Web (WWW 2010), pages 571–580, Raleigh, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jey Han Lau</author>
<author>Paul Cook</author>
<author>Diana McCarthy</author>
<author>David Newman</author>
<author>Timothy Baldwin</author>
</authors>
<title>Word sense induction for novel sense detection.</title>
<date>2012</date>
<booktitle>In Proc. of the 13th Conference of the EACL (EACL 2012),</booktitle>
<pages>591--601</pages>
<location>Avignon, France.</location>
<contexts>
<context position="1167" citStr="Lau et al., 2012" startWordPosition="176" endWordPosition="179">contextual instance: participants are asked to grade senses rather than selecting a single sense like most word sense disambiguation (WSD) settings. The evaluation measures are designed to assess how well a system perceives the different senses in a contextual instance. We adopt a previously-proposed WSI methodology for the task, which is based on a Hierarchical Dirichlet Process (HDP), a nonparametric topic model. Our system requires no parameter tuning, uses the English ukWaC as an external resource, and achieves encouraging results over the shared task. 1 Introduction In our previous work (Lau et al., 2012) we developed a word-sense induction (WSI) system based on topic modelling, specifically a Hierarchical Dirichlet Process (Teh et al., 2006). In evaluations over the SemEval-2007 and SemEval-2010 WSI tasks we achieved performance on par with the current stateof-the art. The SemEval-2007 and SemEval-2010 WSI tasks assumed that each usage of a word has a single gold-standard sense. In this paper we apply this WSI method “off-the-shelf”, with no adaptation, to the novel SemEval-2013 task of “Word Sense Induction for Graded and Non-Graded Senses”. Given that the topic model allocates a multinomial</context>
<context position="4015" citStr="Lau et al., 2012" startWordPosition="663" endWordPosition="666">topics based on data, with the concentration parameters -y and α0 controlling the variability of topics in the documents (for details of HDP please refer to the original paper). To apply HDP to WSI, the latent topics are interpreted as the word senses, and the documents are usages that contain the target word of interest. That is, given a target word (e.g. paper), a “document” in our application is a sentence context surrounding the target word. In addition to the bag of words surrounding the target word, we also include positional context word information, which was used in our earlier work (Lau et al., 2012). That is, we introduce an additional word feature for each of the three words to the left and right of the target word. An example of the topic model features is given in Table 1. 2.1 Background Corpus and Preprocessing The test dataset provides us with contextual instances for each target word, and these instances constitute the documents for the topic model. The text of the test data is tokenised and lemmatised using OpenNLP and Morpha (Minnen et al., 2001). Note, however, that there are only 100 instances for most target words in the test dataset, and as such the dataset may be too small f</context>
<context position="6063" citStr="Lau et al. (2012)" startWordPosition="1012" endWordPosition="1015">es from the ukWaC are tokenised and lemmatised using TreeTagger (Schmid, 1994), as provided by the corpus. To summarise, for each target word we apply the HDP model to the combined collection of the test instances (provided by the shared task) and the extracted usages from the English ukWaC (noting that each instance/usage corresponds to a topic model “document”). The topic model learns the senses/topics for all documents in the collection, but we only use the sense/topic distribution for the test instances as they are the ones evaluated in the shared task. 3 Experiments and Results Following Lau et al. (2012), we use the default parameters (-y = 0.1 and α0 = 1.0) for HDP.1 For each target word, we apply HDP to induce the senses, and a distribution of senses is produced for each “document” in the model. To grade the senses for the instances in the test dataset, we apply the sense probabilities learnt by the topic model as the sense weights without any modification. To illustrate the senses induced by our model, we present the top-10 words of the induced senses for the verb strike in Table 2. Although 13 senses in total are induced and some of them do not seem very coherent, only the first 8 senses </context>
<context position="7361" citStr="Lau et al. (2012)" startWordPosition="1239" endWordPosition="1242">usage) in the test dataset. Two forms of evaluation are used in the task: WSD evaluation and clustering comparison. For WSD evaluation, three measures are used: (1) Jaccard Index (JI), which measures the degree of overlap between the induced senses and the gold senses; (2) positionally-weighted Kendall’s tau (KT: (Kumar and Vassilvitskii, 2010)), which measures the correlation between the ranking of the induced senses and that of the gold senses; and (3) normalised discounted cumulative gain (NDCG), which 1These settings were considered “vague” priors in Teh et al. (2006). They were tested in Lau et al. (2012) and the model was shown to be robust under different parameter settings. As such we decided to keep the settings. The implementation of our WSI system can be accessed via GitHub: https://github.com/jhlau/hdp-wsi. 308 Target word dogs Context sentence Most breeds of dogs are at most a few hundred years old Bag-of-word features most, breeds, of, are, at, most, a, few, hundred, years, old Positional word features most #-3, breeds #-2, of #-1, are #1, at #2, most #3 Table 1: An example of the topic model features. Sense Num Top-10 Terms 1 strike @card@ worker union war iraq week pay government ac</context>
<context position="10916" citStr="Lau et al. (2012)" startWordPosition="1846" endWordPosition="1849">task organisers categorised the instances into singlesense instances and multi-sense instances to better analyse the performance of participating systems. Results for single-sense and multi-sense instances are presented in Table 4 and Table 5, respectively. Note that for single-sense instances, only precision is used for WSD evaluation as the Jaccard Index, positionally-weighted Kendall’s tau and normalised discounted cumulative gain are not applicable. Our system performs relatively well, and trails marginally behind the best system in most cases. 4 Conclusion We adopt a WSI methodology from Lau et al. (2012) for the task of grading senses in a WSD setting. 309 System JI KT NDCG FNMI FBC RANDOM 0.244 0.633 0.287 0.018 0.382 SEMCOR MFS 0.455 0.465 0.339 — — TEST MFS 0.552 0.560 0.412 — — AI-KU 0.197 0.620 0.387 0.065 0.390 AI-KU (REMOVE5-AD1000) 0.244 0.642 0.332 0.039 0.451 LA SAPIENZA (2) 0.149 0.510 0.383 — — UOS (TOP-3) 0.232 0.625 0.374 0.045 0.448 UNIMELB (5P) 0.218 0.614 0.365 0.056 0.459 UNIMELB (50K) 0.213 0.620 0.371 0.060 0.483 Table 3: Results for all instances. The best-performing system is indicated in boldface. System Precision FNMI FBC RANDOM 0.555 0.010 0.359 SEMCOR MFS 0.477 — — T</context>
</contexts>
<marker>Lau, Cook, McCarthy, Newman, Baldwin, 2012</marker>
<rawString>Jey Han Lau, Paul Cook, Diana McCarthy, David Newman, and Timothy Baldwin. 2012. Word sense induction for novel sense detection. In Proc. of the 13th Conference of the EACL (EACL 2012), pages 591– 601, Avignon, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jey Han Lau</author>
<author>Paul Cook</author>
<author>Timothy Baldwin</author>
</authors>
<title>to appear. unimelb: Topic modelling-based word sense induction for web snippet clustering.</title>
<date>2013</date>
<booktitle>In Proc. of the 7th International Workshop on Semantic Evaluation (SemEval</booktitle>
<marker>Lau, Cook, Baldwin, 2013</marker>
<rawString>Jey Han Lau, Paul Cook, and Timothy Baldwin. to appear. unimelb: Topic modelling-based word sense induction for web snippet clustering. In Proc. of the 7th International Workshop on Semantic Evaluation (SemEval 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guido Minnen</author>
<author>John Carroll</author>
<author>Darren Pearce</author>
</authors>
<title>Applied morphological processing of English.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>3</issue>
<contexts>
<context position="4479" citStr="Minnen et al., 2001" startWordPosition="746" endWordPosition="749"> to the bag of words surrounding the target word, we also include positional context word information, which was used in our earlier work (Lau et al., 2012). That is, we introduce an additional word feature for each of the three words to the left and right of the target word. An example of the topic model features is given in Table 1. 2.1 Background Corpus and Preprocessing The test dataset provides us with contextual instances for each target word, and these instances constitute the documents for the topic model. The text of the test data is tokenised and lemmatised using OpenNLP and Morpha (Minnen et al., 2001). Note, however, that there are only 100 instances for most target words in the test dataset, and as such the dataset may be too small for the topic model to induce meaningful senses. To this end, we turn to the English ukWaC — a web corpus of approximately 1.9 billion tokens — to expand the data, by extracting context sentences that contain the target word. Each extracted usage is a three-sentence context containing the target word: the original sentence that contains the actual usage and its preceding and succeeding sentences. The extraction of usages from the ukWaC significantly increases t</context>
</contexts>
<marker>Minnen, Carroll, Pearce, 2001</marker>
<rawString>Guido Minnen, John Carroll, and Darren Pearce. 2001. Applied morphological processing of English. Natural Language Engineering, 7(3):207–223.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In Proc. of the Conference on New Methods in Natural Language Processing,</booktitle>
<location>Manchester,</location>
<contexts>
<context position="5524" citStr="Schmid, 1994" startWordPosition="924" endWordPosition="925">word: the original sentence that contains the actual usage and its preceding and succeeding sentences. The extraction of usages from the ukWaC significantly increases the amount of information for the topic model to learn the senses for the target words from. However, HDP is computationally intensive, so we limit the number of extracted usages from the ukWaC using two sampling approaches: UNIMELB (5P) Take a 5% random sample of usages; UNIMELB (50K) Limit the maximum number of randomly-sampled usages to 50,000 instances. The usages from the ukWaC are tokenised and lemmatised using TreeTagger (Schmid, 1994), as provided by the corpus. To summarise, for each target word we apply the HDP model to the combined collection of the test instances (provided by the shared task) and the extracted usages from the English ukWaC (noting that each instance/usage corresponds to a topic model “document”). The topic model learns the senses/topics for all documents in the collection, but we only use the sense/topic distribution for the test instances as they are the ones evaluated in the shared task. 3 Experiments and Results Following Lau et al. (2012), we use the default parameters (-y = 0.1 and α0 = 1.0) for H</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In Proc. of the Conference on New Methods in Natural Language Processing, Manchester, 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Whye Teh</author>
<author>Michael I Jordan</author>
<author>Matthew J Beal</author>
<author>David M Blei</author>
</authors>
<title>Hierarchical Dirichlet processes.</title>
<date>2006</date>
<journal>Journal of the American Statistical Association,</journal>
<pages>101--1566</pages>
<contexts>
<context position="1307" citStr="Teh et al., 2006" startWordPosition="198" endWordPosition="201">ettings. The evaluation measures are designed to assess how well a system perceives the different senses in a contextual instance. We adopt a previously-proposed WSI methodology for the task, which is based on a Hierarchical Dirichlet Process (HDP), a nonparametric topic model. Our system requires no parameter tuning, uses the English ukWaC as an external resource, and achieves encouraging results over the shared task. 1 Introduction In our previous work (Lau et al., 2012) we developed a word-sense induction (WSI) system based on topic modelling, specifically a Hierarchical Dirichlet Process (Teh et al., 2006). In evaluations over the SemEval-2007 and SemEval-2010 WSI tasks we achieved performance on par with the current stateof-the art. The SemEval-2007 and SemEval-2010 WSI tasks assumed that each usage of a word has a single gold-standard sense. In this paper we apply this WSI method “off-the-shelf”, with no adaptation, to the novel SemEval-2013 task of “Word Sense Induction for Graded and Non-Graded Senses”. Given that the topic model allocates a multinomial distribution over topics to each word usage (“document”, in topic modelling terms), the SemEval-2013 WSI task is an ideal means for evaluat</context>
<context position="3370" citStr="Teh et al., 2006" startWordPosition="549" endWordPosition="552">pic z. The probability of selecting word w given a document d is thus given by: T P(wld) = E P(wlt = z)P(t = z1d). z=1 where t is the topic variable, and T is the number of topics. 307 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 307–311, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics The number of topics, T, is a parameter in LDA. We relax this assumption by extending the model to be non-parametric, using a Hierarchical Dirichlet Process (HDP: (Teh et al., 2006)). HDP learns the number of topics based on data, with the concentration parameters -y and α0 controlling the variability of topics in the documents (for details of HDP please refer to the original paper). To apply HDP to WSI, the latent topics are interpreted as the word senses, and the documents are usages that contain the target word of interest. That is, given a target word (e.g. paper), a “document” in our application is a sentence context surrounding the target word. In addition to the bag of words surrounding the target word, we also include positional context word information, which wa</context>
<context position="7322" citStr="Teh et al. (2006)" startWordPosition="1231" endWordPosition="1234">.e., have non-zero probability for any usage) in the test dataset. Two forms of evaluation are used in the task: WSD evaluation and clustering comparison. For WSD evaluation, three measures are used: (1) Jaccard Index (JI), which measures the degree of overlap between the induced senses and the gold senses; (2) positionally-weighted Kendall’s tau (KT: (Kumar and Vassilvitskii, 2010)), which measures the correlation between the ranking of the induced senses and that of the gold senses; and (3) normalised discounted cumulative gain (NDCG), which 1These settings were considered “vague” priors in Teh et al. (2006). They were tested in Lau et al. (2012) and the model was shown to be robust under different parameter settings. As such we decided to keep the settings. The implementation of our WSI system can be accessed via GitHub: https://github.com/jhlau/hdp-wsi. 308 Target word dogs Context sentence Most breeds of dogs are at most a few hundred years old Bag-of-word features most, breeds, of, are, at, most, a, few, hundred, years, old Positional word features most #-3, breeds #-2, of #-1, are #1, at #2, most #3 Table 1: An example of the topic model features. Sense Num Top-10 Terms 1 strike @card@ worke</context>
</contexts>
<marker>Teh, Jordan, Beal, Blei, 2006</marker>
<rawString>Yee Whye Teh, Michael I. Jordan, Matthew J. Beal, and David M. Blei. 2006. Hierarchical Dirichlet processes. Journal of the American Statistical Association, 101:1566–1581.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>