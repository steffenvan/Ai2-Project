<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000207">
<title confidence="0.9950775">
An Intelligent Terminology Database as a Pre-processor for
Statistical Machine Translation
</title>
<author confidence="0.6850895">
Michael Carl and Philippe Langlais
RALI / DIRO / Universite de Montreal
</author>
<affiliation confidence="0.733151">
Montreal (Quebec), Canada
</affiliation>
<email confidence="0.995583">
email:{carl;felipe}@iro.umontreal.ca
</email>
<sectionHeader confidence="0.995581" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997569375">
In a recent study Langlais (Langlais, 2002) has
shown that the output of a Statistical Machine
Translation (SMT) system deteriorates signifi-
cantly the more the new text differs from the
text the system has been trained on. Langlais
shows that bilingual terminological databases
are resources that can be taken into account to
boost the performance of the statistical engine.
This paper extends the notion of &apos;terminologi-
cal databases&apos; to an Intelligent Terminological
Database (ITDB) capable to detect and reduce
terms and their variants and to re-generate the
authorized target language terms. The paper
discusses the aims and the architecture of the
ITDB and evaluates its integration with a SMT
system.
</bodyText>
<sectionHeader confidence="0.998523" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998016517857143">
SMT mainly became known to the linguistic
community as a result of the seminal work of
Brown et al. (1993). Since then, many re-
searchers have invested effort into designing bet-
ter models than the ones proposed in the afore-
mentioned article and several new exciting ways
have been proposed to attack the problem&apos;.
In a recent paper Langlais (2002) investigated
how a statistical engine behaves when trans-
lating a very domain-specific text far different
from the corpus used to train both the transla-
tion and language models used by the engine.
Langlais measured a significant drop in per-
formances mainly due to out-of-vocabulary
words and specific terminology that the models
handle poorly. He then proposed to overcome
the problem by opening the engine to available
(non statistical) terminological resources. This
1-See for instance (Och and Ney, 2000) for a compar-
ison of several translation models.
contrasts to a previous approach of (Brown et
al., 1993) who develop a statistical model of
a bilingual dictionary which is then integrated
with training text. Both authors find, however,
that terminological databases are resources that
boost the performance of a statistical transla-
tion engine.
With the possibility to introduce prior knowl-
edge resources into SMT it becomes also inter-
esting to explore their linguistic modeling and
to investigate the adaptability of SMT systems
to different domains. In this paper, we investi-
gate a possibility to integrate an Intelligent Ter-
minological Database (ITDB) as a pre-processor
for an SMT system. This ITDB has the main
advantage over simple lists of terms which were
used in (Langlais, 2002) as to recognized termi-
nological variants.
Terminological variants are cumbersome in
every MT System as they introduce ambiguities
which have to be resolved during translation.
On the one hand side it is unrealistic and unde-
sirable to list every possible variant in a termi-
nological lexicon. On the other hand, the appro-
priate target language term has to be generated
by the MT engine. In order to overcome this
gap, the ITDB follows an abductive approach:
a number of possible variants are abduced in
a pre-processing step from a list of authorized
term translations. The variants and the autho-
rized terms are stored in a database which is
consulted at run-time of the too12. The idea be-
ing that variants in the source text can thus be
traced back to their authorized form and trans-
lated properly.
The ITDB is an enhanced version of a ter-
</bodyText>
<footnote confidence="0.95444275">
2Variants and Terms are stored in an under-specified
format such that the size of the database increases much
more slowly than the number of abduced variants. For
a more detailed discussion see (Carl et al., 2002).
</footnote>
<bodyText confidence="0.973403041666667">
minology tool described in (Carl et al., 2002)
which was adapted and modified here for the
bilingual application.
The first part of this paper outlines the aims
and architecture of the ITDB. The second part
discusses a number of experiments. In section
2, we give an idea of the variants we want to
tackle in the ITDB and discuss a number of ter-
minological variants found in an aligned text.
Section 3 presents the architecture of the ITDB
and section 4 underpins its basic assumptions.
In section 5 we show how variants are abduced
from a bilingual terminology and sections 6 and
7 report on two experiments.
2 Aim of the ITDB
We have examined an English-French sentence
aligned bilingual text form a military domain.
The text which we refer to as SNIPER2 is
a manuals on sniper training and deployment
that was used in a previous study (Macklovitch,
1995, cf. section 6).
The text consists of 391 English-French
aligned sentences. We have focused on the fol-
lowing phenomena of term variation:
</bodyText>
<subsectionHeader confidence="0.995625">
2.1 Variation by Omission
</subsectionHeader>
<bodyText confidence="0.999937285714286">
A number of omission variants can be distin-
guished. The examples (1b,2b) show omission
variations for French. In (lb) the expansion
pour arnnes is not specified while in (2h) the
type of the lunette is under-specified. Following
(Jacquemin, 1996, p. 425), these variants can
be said to be in a generic/specific relation.
</bodyText>
<figure confidence="0.74386175">
general purpose weapons oil
huile polyvalente pour arnnes
general purpose weapons oil
huile polyvalente
Unertl telescopic sight
lunette de tir Unertl
Unertl telescopic sight
lunette Unertl
</figure>
<subsectionHeader confidence="0.991181">
2.2 Variation by Insertion
</subsectionHeader>
<bodyText confidence="0.972763166666667">
Variants by insertion are complementary to
omission variants. While in the French term
(3h) a new head word tireur is introduced the
English term is modified by the additional
participle supported. In (4b), the English term
is permuted and function words are inserted.
</bodyText>
<listItem confidence="0.9114226">
(3a) prone position position couche
(3b) prone supported position
position du tireur couche
(4a) rifle butt crosse du fusil
(4b) butt of a rifle crosse du fusil
</listItem>
<subsectionHeader confidence="0.987328">
2.3 Synonyms
</subsectionHeader>
<bodyText confidence="0.99975175">
In addition to insertion and omission, terms
also appear as synonyms. As Hamond and
Nazarenko (Hamon and Nazarenko, 2001)
notice, synonyms may appear in the head
and/or in the expansion of a compound. As
these different variation processes overlap it
becomes particularly difficult to identify the
intended meaning. Consider, for instance, the
two term-cluster (5a-e) and (6a-e). The terms
on the left-hand side in (5a) and (5b) show
English variants in their head nouns telescope
and scope while the French variants on the
right-hand side in (6a) and (6b) have different
expansions tir and visee. There is an English
omission variant in (6c) which is translated into
a full-form French term and a number of French
omission variants (5c,d,e 6d,e). Here it becomes
particularly ambiguous and confusing to know
whether the full-form authorized translation of
French lunette is spotting telescope or telescopic
sight.
spotting telescope lunette d&apos;observation
spotting scope lunette d&apos;observation
spotting telescope lunette
telescope lunette
scope lunette
telescopic sight lunette de visee
telescopic sight lunette de tir
sight lunette de tir
telescopic sight lunette
sight lunette
Synonyms and omission variants may thus
appear simultaneously, multiplying the &apos;noise&apos;
in translations and aligned texts. It is, how-
ever, clear, that one would not like to store all
these variants in a bilingual terminology.
</bodyText>
<page confidence="0.381387">
3 Architecture of the ITDB
</page>
<bodyText confidence="0.999789">
In order to recognize variants of terms and their
translations, we have adopted and modified a
monolingual terminology tool described in (Carl
et al., 2002). The monolingual terminology tool
</bodyText>
<table confidence="0.935597125">
Reduced LHS Alignments Reduced RHS Alignments
Marking Terms Marking Terms
and Variants and Variants
LHS Aligned Text RHS Aligned Text
LHS Synonyms and LHS Terms and RHS Terms and RHS Synonyms and
Variation Pattern abduced variants abduced variants Variation Pattern
LHS of Terminology
RHS of Terminology
</table>
<figureCaption confidence="0.999745">
Figure 1: Components of the ITDB
</figureCaption>
<bodyText confidence="0.99654124">
and the ITDB integrate a rule-based formalism
KURD and the example-based translation sys-
tem EDGAR. The modified architecture of the
bilingual terminology tool is shown in figure 1.
It consists of two symmetrical language sides, a
left-hand side (LHS, i.e. English) and a right-
hand side (RHS, i.e. French). The architecture
in figure 1 is designed to evaluate the perfor-
mance of the ITDB. A runtime version of the
ITDB is shown in figure 3 and discussed in sec-
tion 7. In this section we describe the different
parts of the evaluation architecture.
The ITDB assumes a bilingual terminology
(cf. bottom in figure 1). This terminology is
either provided by a terminologist or may be
automatically acquired. In a study reported in
section 6 we use a small bilingual terminology
which was manually extracted from the SNIPER2
text. The bilingual terminology contains un-
ambiguous term translations, indicated by the
symbol
A limited number of variants are generated
through the process of &amp;quot;abduction&amp;quot; (discussed
below) independently from each language side
of a term. Abduction is performed by the rule-
based formalism KURD which takes as its input
a set of terms, a set of synonyms and a set of
variation pattern (see figure 1). The abduced
variants are stored in a database together with
the original terms and each variant is linked to
their authorized forms3. Abduction produces
m— to— n translations equivalences as indicated
by the symbol x.
A bilingual aligned text can now be matched
against the database to mark terms and vari-
ants in the text as shown in the upper part
3cf. (Carl et al., 2002) for a more detailed description
of this process.
in figure 1. We use the example-based transla-
tion system EDGAR which marks matched se-
quences of words in the text as variant or term
according to the status of the matched database
entry. To evaluate coverage and precision of the
ITDB (cf. section 6), the marked sequences are
reduced to a generic label which are counted
and compared in LHS and RHS. In the run-
time architecture (cf. figure 3), authorized tar-
get language forms of source language terms and
their variants are re-generated as discussed in
section 7.
</bodyText>
<sectionHeader confidence="0.963904" genericHeader="method">
4 An Abductive Approach
</sectionHeader>
<bodyText confidence="0.983822111111111">
ITDB recognizes variants of terms by abduc-
tion. According to Streiter (Streiter, 2001), ab-
ductive reasoning creates hypothesis which are
not logically implied by the premises. Unlike de-
ductive reasoning, abduction is not always cor-
rect in all reasoning steps. However, abductive
reasoning should be &amp;quot;plausible&amp;quot; in a context and
yield correct results in the vast majority. Where
deductive inference stops in front of gaps, ab-
duction creates new hypothesis which allow to
bridge the gap and continue the inference. As
an illustration for abductive reasoning, Streiter
gives the following example
&amp;quot;Imagine, you ordered a product and
a week later you received a par-
cel. Using abduction you might as-
sume that this is what you ordered.
In order to come to this conclu-
sion you induce from single experi-
ences ](x,y) order(x,y)Areeeive(x,y)
a hypothesis V (x ,y) order(x,y)
reeeive(x,y) and instantiate x and y
with &amp;quot;I&amp;quot; and &amp;quot;product&amp;quot;, so that you
(safely) assume that you receive your
focusing ring bague de mise au point
eyepiece locking ring bague de verrouillage de l&apos;oculaire
rearward movement nnouvennent arriere
</bodyText>
<figure confidence="0.98096525">
(7LHSo)
(7RHSo)
(7RHS1)
(9LHSo)
(9RHSo)
(9RHS2)
focusing (ring;buckle;collar;light;pneumatic;ripening; ...)
(bague;anneau;aggraver;bouche;boucle; ...) de mise au point
bague;anneau;aggraver;bouche;boucle
(rearward;recompense;remunerate;pay;compensate) (movement;transport;traffic;trade;...)
(nnouvennentennouvoir;transporttrafic;...) (arriere;fond;derriere;severe;queue; ...)
(nnouvennentennouvoir;transporttrafic;...) x y (arriere;fond;derriere;severe;queue; ...)
</figure>
<figureCaption confidence="0.999688">
Figure 2: Abduction of Term Variants
</figureCaption>
<bodyText confidence="0.990742405405406">
product. &amp;quot;
Essentially, in Streiter&apos;s example, from the co-
occurrence of two single experiences is inferred
an implication containing a universal quantifier
in the hypothesis. Abduction consists in re-
instantiating the generated hypothesis by ap-
propriate events to draw the desired conclusion.
Mooney (Mooney, 2000) examines the rela-
tion between abduction and induction. Al-
though precise definitions of abduction and in-
duction are still somewhat controversial, he
finds:
&amp;quot;In abduction, the hypothesis is a spe-
cific set of assumptions that explain
the observations of a particular case;
while in induction, the hypothesis is
a general theory that explains the ob-
servations across a number of cases.&amp;quot;
(Mooney, 2000, p.183)
Mooney applies abductive learning for the-
ory refinement. Theory refinement is the task
to make an existing imperfect domain theory
consistent with a set of data. For him, abduc-
tion is primary useful in generalizing a theory
to cover more positive examples. For each in-
dividual positive example that is not derivable
from the current theory, abduction is applied to
determine a set of assumptions that would allow
it to be proven.
In a similar way the ITDB detects and re-
duces terminological inconsistencies. The un-
derlaying assumption in ITDB is that each term
in the LHS of an alignment (or in a the source
text) has also a translation in the RHS (or in the
target text) of that alignment and vice versa. In
case a term-translation cannot be detected, the
ITDB tries to prove the presence of a variant.
</bodyText>
<sectionHeader confidence="0.858441" genericHeader="method">
5 Abduction of Term Variants
</sectionHeader>
<bodyText confidence="0.999942678571429">
As outlined in section 3, abduction of term vari-
ants in the ITDB presupposes a bilingual ter-
minology. In an evaluation scenario which we
shall describe in this section, a bilingual ter-
minology was manually extracted from a text
SNIPER2 (cf. section 6). The bilingual termi-
nology contains 168 non-ambiguous term trans-
lations where each LHS and each RHS occurs
exactly once in the terminology.
Synonyms of the term&apos;s content words were
generated automatically from a bilingual dic-
tionary by back-and-forth translating4. For in-
stance, the terms (7), (8) and (9) in figure 2
were manually extracted from SNIPER2. The
terms (7) and (8) contain as their head words
the translation ring bague. Back-and-forth
translation of French bague yields 29 synonyms
while through back-and-forth translation of En-
glish ring 45 synonyms were generated. In this
way, variants (7mis0) are recognized as variants
of the English term in (7) and variants (7
\ • Rliso)
are recognized as variants of the French term in
(7). In all, 549 and 650 synonyms were gener-
ated from the 168 English and French terms.
In addition to this, a number of variation pat-
tern were used to abduce further variants. Cur-
rently, we have the following two simple varia-
</bodyText>
<footnote confidence="0.973864857142857">
4We used a general-purpose English-French dictio-
nary with 77016 entries. Lists of English synonyms
were obtained by looking up their French translations
and then back-translating each of the French transla-
tions into English using the same dictionary. In future
we consider to use WordNet to obtain synonyms of the
term&apos;s content words.
</footnote>
<bodyText confidence="0.966102">
tion pattern for French omission (1) and inser-
tion (2) variation :
</bodyText>
<listItem confidence="0.980137">
(1) Nip...
(2) NiAdj2 NixyAdj2
</listItem>
<bodyText confidence="0.982771">
These variation pattern produced 131 addi-
tional variants for the French terms. For in-
stance, the omission variant (7
</bodyText>
<listItem confidence="0.810392">
• Riisi) was ab-
duced using variation pattern (1) while inser-
tion variant (9
</listItem>
<bodyText confidence="0.990753565217391">
\--RHS2) was abduced using varia-
tion pattern (2). The tag xy matches any se-
quence of two words such that, for instance,
nnouvennent vers l&apos;arriere is abduced as a vari-
ant of (9). For the English side, only synonyms,
but no variation pattern were generated.
While the original terminology contains only
1 — to — 1 term translations, abduction gener-
ates m — to — n translation relations. Thus due
to variation pattern (1), French bague is rec-
ognized as an omission variant either of term
(7) or of term (8). Accordingly, the translations
may be English focusing ring or eyepiece locking
ring. Unless another translation is known, the
same translation is also abduced for the syn-
onyms: anneau;aggraver;bouche;boucle;.... Ab-
duction thus enables m different French expres-
sions to be translated into n different English
terms. However, adding further terms to the
terminology will narrow the number of gener-
ated translations, as a terminology entry will
be preferred over an abduced variant if they de-
scribe the same surface string.
</bodyText>
<sectionHeader confidence="0.780736" genericHeader="method">
6 Coverage and Precision of ITDB
</sectionHeader>
<bodyText confidence="0.99959271875">
The ITDB was tested on two texts, SNIPER2 and
SNIPER3. The texts are an excerpt of an army
manual on sniper training and deployment that
was used in an other study (Macklovitch, 1995).
This corpus is highly specific to the military do-
main and would certainly prove difficult to any
translation engine not specifically tuned to such
material.
SNIPER2 and SNIPER3 have 391 and 916
French-English aligned sentences, respectively
with an average length of 19 and 22 words in the
English LHS and the French RHS. Note that the
terminology was also extracted from SNIPER2.
Both language sides of the two texts were
passed through the ITDB in two different ways:
once only the authorized terms (T) and another
time the authorized terms and their abduced
variants (T+A) were were marked in both lan-
guage sides of the aligned texts and retrieved
from the output of the evaluation architecture
(cf. figure 1). To measure the gain in coverage
and precision, we have counted the noise pro-
duced in the English and French sides as well
as the valid recovered translations equivalences.
The table 1 summarizes the results. The row
E indicates the noise on the English side of the
alignments, i.e the number of matched English
expressions which have no correspondences in
the French side of the alignment. The row F
indicates the noise on the French side. The row
E F gives the number of valid translations
in the alignment.
</bodyText>
<table confidence="0.997627714285714">
SNIPER2 SNIPER3
T T-FA T-FA
131 78 396 343
74 220 166 666
EF 528 638 783 948
PE 0.80 0.90 0.66 0.73
PF 0.87 0.74 0.83 0.59
</table>
<tableCaption confidence="0.999646">
Table 1: Coverage and Precision of the ITDB
</tableCaption>
<bodyText confidence="0.981058">
In SNIPER2, 659 English terms (i.e. E F+
E) and 602 French terms (i.e. E F F) were
found using the terminology only, while 716 En-
glish and 858 French expressions were matched
with abduced variants. Of these matched terms
and expressions 528 and 638 were valid trans-
lations. This equals a gain of 120% in coverage
when using abduced variants.
A similar situation appears for SNIPER3,
where 948 valid translations were found using
abduced variants compared to 783 translation
equivalences for the terminology only. This
amounts to an increase of 121% coverage com-
pared to the terminology.
</bodyText>
<table confidence="0.994285333333333">
SNIPER T-T 1-S S-S 1-T S-T 2-T
2 528 17 6 80 6 1
3 782 28 10 102 26 0
</table>
<tableCaption confidence="0.9485615">
Table 2: Types and Number of Abduced Trans-
lation Equivalences
Analysing the abduced translation equiva-
lences for SNIPER2 and SNIPER3 (cf. table 2), we
</tableCaption>
<note confidence="0.9569766">
LHS Aligned Text RHS Aligned Text WER and SER
Marking of Generating authorized Statistical
Terms and Variants target language terms Machine Translation
LHS Terms and RHS of
abduced variants Terminology
</note>
<figureCaption confidence="0.999361">
Figure 3: Runtime architecture of the ITDB.
</figureCaption>
<bodyText confidence="0.992995181818182">
find the 528 and 7835 French-English term
term translations (T-T) amongst the the 638
and 948 valid translations. In addition there
are 17 and 28 omission-variant synonym (1-S)
translations and 6 and 10 synonym synonym
(S-S) translations and 87 and 127 variant
term (1-T, S-T and 2-T) translations.
By far most of the abduced translation equiv-
alences are due to variation pattern (1) i.e.
the French/English translations 1-S and 1-T
which generates 97 and 130 additional transla-
tion equivalences for SNIPER2 and SNIPER3.
However, variation pattern (1) also generates
most of the noise in the French alignments. The
rows PE and PF in table 1 indicate precision
for the English side of alignments calculated as
PE EF+E and for the French side of align-
ments calculated as PF =
While the precision of the matched English
terms increases when matching abduced vari-
ants, the precision of the French terms de-
creases.
</bodyText>
<table confidence="0.992645">
SNIPER2 SNIPER3
T 1 1 S 2
78 0 316 0 27 0
68 152 157 492 12 5
</table>
<tableCaption confidence="0.999855">
Table 3: Origin of Noise in Alignments
</tableCaption>
<bodyText confidence="0.992700157894737">
Examining the origin of noise in alignments
(cf. table 3), more than 2/3 of the matched
French sequences which have no correspondence
on the English side of the alignment are due to
variation pattern 1. As discussed previously (cf.
figure 2), each occurrence of the word bouche in
the French side of an alignment produces noise
if no variant of focusing ring or eyepiece locking
5 The table 2 shows the number 782: I could not figure
out where the missing translation equivalent disappeared
ring was found in the English side of that align-
ment. This clearly indicates that the variation
pattern (1) is too simple specially if com-
bined with a noisy list of synonyms which
calls for further refinement.
In order to reduce this noise and to extend the
coverage of the ITDB, future work will be in line
with the methodology of iterative refinement as
outlined by Meyer (Meyer, 2001).
</bodyText>
<sectionHeader confidence="0.981063" genericHeader="method">
7 Integrating ITDB and STM
</sectionHeader>
<bodyText confidence="0.99985824">
In a second experiment we have linked the ITDB
with an SMT system. The way the ITDB in-
teracts with the SMT engine is depicted in the
block diagram of Figure 3. The ITDB identi-
fies and marks terms and their possible variants
in the source text (LHS Aligned Text) and re-
generates their authorized target language form.
The marked and with target language segments
enriched text is then passed through the SMT
system as described in (Langlais, 2002). While
the position of the target term in the French
target sentence is determined by the SMT sys-
tem, its form is generated by the ITDB6. in the
French alignments . The output of the SMT
is then compared with an oracle translation i.e.
the RHS Aligned Text.
As in the previous experiment, the architec-
ture was tested on SNIPER2 and SNIPER3, this
time in three different settings: without any ter-
minological lexicon, with the terminology (T)
and with both the terminology and its abduced
variants (T+A). The results of the translation
sessions are resumed in Table 4. For practical
reasons, we only translated the sentences that
contained at most 30 words.
</bodyText>
<footnote confidence="0.552938333333333">
6Texts were translated from English to French so that
the noisy French terms, as reported in the previous sec-
tion, would not be generated.
</footnote>
<table confidence="0.70971475">
corpus WITHOUT T T+A
SER WER SER WER SER WER
SNIPER2 86.8 82.9 82.6 77.1 82.5 76.6
SNIPER3 91.8 82 91.8 79.4 91.8 79.4
</table>
<tableCaption confidence="0.71562">
Table 4: SMT Results with the ITDB as a Pre-
processor
</tableCaption>
<bodyText confidence="0.999846413793103">
The performance of our engine was evalu-
ated in terms of word error rate (WER) and
sentence error rate (SER) according to a
single oracle translation. The former rate is
computed by a classical Levenstein distance; the
latter one is given by the ratio of translation
that were strictly identical to the oracle trans-
lation.
First, the WER measured without terminol-
ogy is fairly high (more than 82% for both cor-
pora), but in the same range as the ones ob-
served by (Langlais, 2002) in cases where the
decoder is faced to texts very different from the
ones used at training time. The introduction of
the terminology into the engine improves signif-
icantly the WER (77% on SNIPER2 and 79.4%
on smPER3).
Finally, the further introduction of the ter-
minological variants does have a slight positive
impact on SNIPER2, but none on SNIPER-3. We
have currently no convincing explanation for
these findings. We must stress that WER com-
puted over a single oracle translation is prob-
ably severe: it may happen that an authorized
term translation proposed by the ITDB was not
the one present in the oracle translation. This
degrades WER even though a correct (i.e. more
consistent) translation was produced than was
contained in the oracle translation.
</bodyText>
<sectionHeader confidence="0.998595" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999994047619048">
The paper presents an Intelligent Terminolog-
ical Database (ITDB), a tool to detect terms
and their variants in texts and to retrieve their
authorized translations from a bilingual termi-
nology. The paper outlines the architecture of
the ITDB and reports on two experiments. The
first experiment quantifies the coverage and pre-
cision for detecting terminological variants and
their translations in aligned texts. In the second
experiment, the ITDB is used to translate terms
and their variants as a pre-processor for a sta-
tistical machine translation system. While the
first experiment shows encouraging results, the
success of the ITDB as a pre-processor for a sta-
tistical machine translation seems more doubt-
ful. A thorough revision and modification of the
interaction of both systems is probably in order
to fully complement the strength of the two sys-
tems. Further experimentation and refinement
is also required to reduce the noise produced by
the ITDB and to augment its coverage.
</bodyText>
<sectionHeader confidence="0.999206" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999745813953488">
Didier Bourigault, Christian Jacquemin, and Maine-
Claude L&apos;Homme 2001. Recent Advances in
Computational Terminology. John Benj amins
Publishing Company, Amsterdam/Philadelphia.
Peter F. Brown, Stephen A. Della Pietra, Vincent
J. Della Pietra, Meredith J. Goldsmith, Jan Ha-
jic, Robert L. Mercer, and Surya Mohanty. 1993.
But dictionaries are data too. In Human Lan-
guage Technology (HLT), pages 202 205, Prince-
ton, NJ, march.
Michael Carl, Johann Haller, Christoph
Horschmann, Dieter Maas, and Jorg Schutz.
2002. The TETRIS Terminology Tool. TAL,
Structuration de terminologie(1).
Thierry Hamon and Adeline Nazarenko. 2001. De-
tection of synonymy links between terms: Exper-
iment and results. In in (Bourigault et al.„ 2001),
pages 185 208.
Christian Jacquemin. 1996. A symbolic and surgical
acquisition of terms through variation. In Con-
nectionist, Statistical and Symbolic Approaches to
Learning for Natural Language Processing, pages
425 438.
Philipe Langlais. 2002. Ressources terminologiques
et traduction probabiliste: premiers pas positifs
vers un systeme adaptatif. In TAL1V.
Elliott Macklovitch. 1995. Can terminological con-
sistency be validated automatically ? Technical
report, CITI/RALI, Montreal, Canada.
Ingrid Meyer. 2001. Extracting knowledge-rich con-
texts for terminography. In in (Bourigault et al.,
2001), pages 279 302.
Raymond J. Mooney. 2000. Integrating abduction
and induction in machine learning. In P. Flach
and A. Kakas, editors, Abduction and Induction,
pages 181 191, Kluwer Academic Publishers.
F.J. Och and H. Ney. 2000. A comparison of aligne-
ment models for statistical machine translation.
In COLINGOO, pages 1086 1090.
Oliver Streiter. 2001. Treebank Development
with Deductive and Abductive Explanation-based
Learning: Exploratory Experiments, unpublished
draft.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.625795">
<title confidence="0.999184">An Intelligent Terminology Database as a Pre-processor Statistical Machine Translation</title>
<author confidence="0.993412">Michael Carl</author>
<author confidence="0.993412">Philippe</author>
<affiliation confidence="0.819904">RALI / DIRO / Universite de Montreal (Quebec),</affiliation>
<email confidence="0.994879">carl;felipe}@iro.umontreal.ca</email>
<abstract confidence="0.995566705882353">a study Langlais (Langlais, 2002) has shown that the output of a Statistical Machine Translation (SMT) system deteriorates significantly the more the new text differs from the text the system has been trained on. Langlais shows that bilingual terminological databases are resources that can be taken into account to boost the performance of the statistical engine. This paper extends the notion of &apos;terminological databases&apos; to an Intelligent Terminological Database (ITDB) capable to detect and reduce terms and their variants and to re-generate the authorized target language terms. The paper discusses the aims and the architecture of the ITDB and evaluates its integration with a SMT system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Didier Bourigault</author>
<author>Christian Jacquemin</author>
<author>MaineClaude L&apos;Homme</author>
</authors>
<date>2001</date>
<booktitle>Recent Advances in Computational Terminology. John Benj amins Publishing Company,</booktitle>
<location>Amsterdam/Philadelphia.</location>
<marker>Bourigault, Jacquemin, L&apos;Homme, 2001</marker>
<rawString>Didier Bourigault, Christian Jacquemin, and MaineClaude L&apos;Homme 2001. Recent Advances in Computational Terminology. John Benj amins Publishing Company, Amsterdam/Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Meredith J Goldsmith</author>
<author>Jan Hajic</author>
<author>Robert L Mercer</author>
<author>Surya Mohanty</author>
</authors>
<title>But dictionaries are data too.</title>
<date>1993</date>
<booktitle>In Human Language Technology (HLT),</booktitle>
<pages>202--205</pages>
<location>Princeton, NJ,</location>
<contexts>
<context position="1062" citStr="Brown et al. (1993)" startWordPosition="156" endWordPosition="159">en trained on. Langlais shows that bilingual terminological databases are resources that can be taken into account to boost the performance of the statistical engine. This paper extends the notion of &apos;terminological databases&apos; to an Intelligent Terminological Database (ITDB) capable to detect and reduce terms and their variants and to re-generate the authorized target language terms. The paper discusses the aims and the architecture of the ITDB and evaluates its integration with a SMT system. 1 Introduction SMT mainly became known to the linguistic community as a result of the seminal work of Brown et al. (1993). Since then, many researchers have invested effort into designing better models than the ones proposed in the aforementioned article and several new exciting ways have been proposed to attack the problem&apos;. In a recent paper Langlais (2002) investigated how a statistical engine behaves when translating a very domain-specific text far different from the corpus used to train both the translation and language models used by the engine. Langlais measured a significant drop in performances mainly due to out-of-vocabulary words and specific terminology that the models handle poorly. He then proposed</context>
</contexts>
<marker>Brown, Pietra, Pietra, Goldsmith, Hajic, Mercer, Mohanty, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, Meredith J. Goldsmith, Jan Hajic, Robert L. Mercer, and Surya Mohanty. 1993. But dictionaries are data too. In Human Language Technology (HLT), pages 202 205, Princeton, NJ, march.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Carl</author>
<author>Johann Haller</author>
<author>Christoph Horschmann</author>
<author>Dieter Maas</author>
<author>Jorg Schutz</author>
</authors>
<date>2002</date>
<booktitle>The TETRIS Terminology Tool. TAL, Structuration de terminologie(1).</booktitle>
<contexts>
<context position="3649" citStr="Carl et al., 2002" startWordPosition="581" endWordPosition="584">an abductive approach: a number of possible variants are abduced in a pre-processing step from a list of authorized term translations. The variants and the authorized terms are stored in a database which is consulted at run-time of the too12. The idea being that variants in the source text can thus be traced back to their authorized form and translated properly. The ITDB is an enhanced version of a ter2Variants and Terms are stored in an under-specified format such that the size of the database increases much more slowly than the number of abduced variants. For a more detailed discussion see (Carl et al., 2002). minology tool described in (Carl et al., 2002) which was adapted and modified here for the bilingual application. The first part of this paper outlines the aims and architecture of the ITDB. The second part discusses a number of experiments. In section 2, we give an idea of the variants we want to tackle in the ITDB and discuss a number of terminological variants found in an aligned text. Section 3 presents the architecture of the ITDB and section 4 underpins its basic assumptions. In section 5 we show how variants are abduced from a bilingual terminology and sections 6 and 7 report on two e</context>
<context position="7238" citStr="Carl et al., 2002" startWordPosition="1153" endWordPosition="1156">pe lunette d&apos;observation spotting telescope lunette telescope lunette scope lunette telescopic sight lunette de visee telescopic sight lunette de tir sight lunette de tir telescopic sight lunette sight lunette Synonyms and omission variants may thus appear simultaneously, multiplying the &apos;noise&apos; in translations and aligned texts. It is, however, clear, that one would not like to store all these variants in a bilingual terminology. 3 Architecture of the ITDB In order to recognize variants of terms and their translations, we have adopted and modified a monolingual terminology tool described in (Carl et al., 2002). The monolingual terminology tool Reduced LHS Alignments Reduced RHS Alignments Marking Terms Marking Terms and Variants and Variants LHS Aligned Text RHS Aligned Text LHS Synonyms and LHS Terms and RHS Terms and RHS Synonyms and Variation Pattern abduced variants abduced variants Variation Pattern LHS of Terminology RHS of Terminology Figure 1: Components of the ITDB and the ITDB integrate a rule-based formalism KURD and the example-based translation system EDGAR. The modified architecture of the bilingual terminology tool is shown in figure 1. It consists of two symmetrical language sides, </context>
<context position="9204" citStr="Carl et al., 2002" startWordPosition="1478" endWordPosition="1481">s of &amp;quot;abduction&amp;quot; (discussed below) independently from each language side of a term. Abduction is performed by the rulebased formalism KURD which takes as its input a set of terms, a set of synonyms and a set of variation pattern (see figure 1). The abduced variants are stored in a database together with the original terms and each variant is linked to their authorized forms3. Abduction produces m— to— n translations equivalences as indicated by the symbol x. A bilingual aligned text can now be matched against the database to mark terms and variants in the text as shown in the upper part 3cf. (Carl et al., 2002) for a more detailed description of this process. in figure 1. We use the example-based translation system EDGAR which marks matched sequences of words in the text as variant or term according to the status of the matched database entry. To evaluate coverage and precision of the ITDB (cf. section 6), the marked sequences are reduced to a generic label which are counted and compared in LHS and RHS. In the runtime architecture (cf. figure 3), authorized target language forms of source language terms and their variants are re-generated as discussed in section 7. 4 An Abductive Approach ITDB recog</context>
</contexts>
<marker>Carl, Haller, Horschmann, Maas, Schutz, 2002</marker>
<rawString>Michael Carl, Johann Haller, Christoph Horschmann, Dieter Maas, and Jorg Schutz. 2002. The TETRIS Terminology Tool. TAL, Structuration de terminologie(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thierry Hamon</author>
<author>Adeline Nazarenko</author>
</authors>
<title>Detection of synonymy links between terms: Experiment and results.</title>
<date>2001</date>
<booktitle>In in (Bourigault et al.„</booktitle>
<pages>185--208</pages>
<contexts>
<context position="5773" citStr="Hamon and Nazarenko, 2001" startWordPosition="930" endWordPosition="933">tl telescopic sight lunette Unertl 2.2 Variation by Insertion Variants by insertion are complementary to omission variants. While in the French term (3h) a new head word tireur is introduced the English term is modified by the additional participle supported. In (4b), the English term is permuted and function words are inserted. (3a) prone position position couche (3b) prone supported position position du tireur couche (4a) rifle butt crosse du fusil (4b) butt of a rifle crosse du fusil 2.3 Synonyms In addition to insertion and omission, terms also appear as synonyms. As Hamond and Nazarenko (Hamon and Nazarenko, 2001) notice, synonyms may appear in the head and/or in the expansion of a compound. As these different variation processes overlap it becomes particularly difficult to identify the intended meaning. Consider, for instance, the two term-cluster (5a-e) and (6a-e). The terms on the left-hand side in (5a) and (5b) show English variants in their head nouns telescope and scope while the French variants on the right-hand side in (6a) and (6b) have different expansions tir and visee. There is an English omission variant in (6c) which is translated into a full-form French term and a number of French omissi</context>
</contexts>
<marker>Hamon, Nazarenko, 2001</marker>
<rawString>Thierry Hamon and Adeline Nazarenko. 2001. Detection of synonymy links between terms: Experiment and results. In in (Bourigault et al.„ 2001), pages 185 208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Jacquemin</author>
</authors>
<title>A symbolic and surgical acquisition of terms through variation.</title>
<date>1996</date>
<booktitle>In Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing,</booktitle>
<pages>425--438</pages>
<contexts>
<context position="4917" citStr="Jacquemin, 1996" startWordPosition="798" endWordPosition="799">lish-French sentence aligned bilingual text form a military domain. The text which we refer to as SNIPER2 is a manuals on sniper training and deployment that was used in a previous study (Macklovitch, 1995, cf. section 6). The text consists of 391 English-French aligned sentences. We have focused on the following phenomena of term variation: 2.1 Variation by Omission A number of omission variants can be distinguished. The examples (1b,2b) show omission variations for French. In (lb) the expansion pour arnnes is not specified while in (2h) the type of the lunette is under-specified. Following (Jacquemin, 1996, p. 425), these variants can be said to be in a generic/specific relation. general purpose weapons oil huile polyvalente pour arnnes general purpose weapons oil huile polyvalente Unertl telescopic sight lunette de tir Unertl Unertl telescopic sight lunette Unertl 2.2 Variation by Insertion Variants by insertion are complementary to omission variants. While in the French term (3h) a new head word tireur is introduced the English term is modified by the additional participle supported. In (4b), the English term is permuted and function words are inserted. (3a) prone position position couche (3b</context>
</contexts>
<marker>Jacquemin, 1996</marker>
<rawString>Christian Jacquemin. 1996. A symbolic and surgical acquisition of terms through variation. In Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing, pages 425 438.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipe Langlais</author>
</authors>
<title>Ressources terminologiques et traduction probabiliste: premiers pas positifs vers un systeme adaptatif.</title>
<date>2002</date>
<booktitle>In TAL1V.</booktitle>
<contexts>
<context position="1302" citStr="Langlais (2002)" startWordPosition="198" endWordPosition="199"> Terminological Database (ITDB) capable to detect and reduce terms and their variants and to re-generate the authorized target language terms. The paper discusses the aims and the architecture of the ITDB and evaluates its integration with a SMT system. 1 Introduction SMT mainly became known to the linguistic community as a result of the seminal work of Brown et al. (1993). Since then, many researchers have invested effort into designing better models than the ones proposed in the aforementioned article and several new exciting ways have been proposed to attack the problem&apos;. In a recent paper Langlais (2002) investigated how a statistical engine behaves when translating a very domain-specific text far different from the corpus used to train both the translation and language models used by the engine. Langlais measured a significant drop in performances mainly due to out-of-vocabulary words and specific terminology that the models handle poorly. He then proposed to overcome the problem by opening the engine to available (non statistical) terminological resources. This 1-See for instance (Och and Ney, 2000) for a comparison of several translation models. contrasts to a previous approach of (Brown e</context>
<context position="2597" citStr="Langlais, 2002" startWordPosition="401" endWordPosition="402">then integrated with training text. Both authors find, however, that terminological databases are resources that boost the performance of a statistical translation engine. With the possibility to introduce prior knowledge resources into SMT it becomes also interesting to explore their linguistic modeling and to investigate the adaptability of SMT systems to different domains. In this paper, we investigate a possibility to integrate an Intelligent Terminological Database (ITDB) as a pre-processor for an SMT system. This ITDB has the main advantage over simple lists of terms which were used in (Langlais, 2002) as to recognized terminological variants. Terminological variants are cumbersome in every MT System as they introduce ambiguities which have to be resolved during translation. On the one hand side it is unrealistic and undesirable to list every possible variant in a terminological lexicon. On the other hand, the appropriate target language term has to be generated by the MT engine. In order to overcome this gap, the ITDB follows an abductive approach: a number of possible variants are abduced in a pre-processing step from a list of authorized term translations. The variants and the authorized</context>
<context position="20857" citStr="Langlais, 2002" startWordPosition="3400" endWordPosition="3401">extend the coverage of the ITDB, future work will be in line with the methodology of iterative refinement as outlined by Meyer (Meyer, 2001). 7 Integrating ITDB and STM In a second experiment we have linked the ITDB with an SMT system. The way the ITDB interacts with the SMT engine is depicted in the block diagram of Figure 3. The ITDB identifies and marks terms and their possible variants in the source text (LHS Aligned Text) and regenerates their authorized target language form. The marked and with target language segments enriched text is then passed through the SMT system as described in (Langlais, 2002). While the position of the target term in the French target sentence is determined by the SMT system, its form is generated by the ITDB6. in the French alignments . The output of the SMT is then compared with an oracle translation i.e. the RHS Aligned Text. As in the previous experiment, the architecture was tested on SNIPER2 and SNIPER3, this time in three different settings: without any terminological lexicon, with the terminology (T) and with both the terminology and its abduced variants (T+A). The results of the translation sessions are resumed in Table 4. For practical reasons, we only t</context>
<context position="22302" citStr="Langlais, 2002" startWordPosition="3656" endWordPosition="3657">ER SER WER SNIPER2 86.8 82.9 82.6 77.1 82.5 76.6 SNIPER3 91.8 82 91.8 79.4 91.8 79.4 Table 4: SMT Results with the ITDB as a Preprocessor The performance of our engine was evaluated in terms of word error rate (WER) and sentence error rate (SER) according to a single oracle translation. The former rate is computed by a classical Levenstein distance; the latter one is given by the ratio of translation that were strictly identical to the oracle translation. First, the WER measured without terminology is fairly high (more than 82% for both corpora), but in the same range as the ones observed by (Langlais, 2002) in cases where the decoder is faced to texts very different from the ones used at training time. The introduction of the terminology into the engine improves significantly the WER (77% on SNIPER2 and 79.4% on smPER3). Finally, the further introduction of the terminological variants does have a slight positive impact on SNIPER2, but none on SNIPER-3. We have currently no convincing explanation for these findings. We must stress that WER computed over a single oracle translation is probably severe: it may happen that an authorized term translation proposed by the ITDB was not the one present in</context>
</contexts>
<marker>Langlais, 2002</marker>
<rawString>Philipe Langlais. 2002. Ressources terminologiques et traduction probabiliste: premiers pas positifs vers un systeme adaptatif. In TAL1V.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elliott Macklovitch</author>
</authors>
<title>Can terminological consistency be validated automatically ?</title>
<date>1995</date>
<tech>Technical report, CITI/RALI,</tech>
<location>Montreal, Canada.</location>
<contexts>
<context position="4507" citStr="Macklovitch, 1995" startWordPosition="733" endWordPosition="734">s. In section 2, we give an idea of the variants we want to tackle in the ITDB and discuss a number of terminological variants found in an aligned text. Section 3 presents the architecture of the ITDB and section 4 underpins its basic assumptions. In section 5 we show how variants are abduced from a bilingual terminology and sections 6 and 7 report on two experiments. 2 Aim of the ITDB We have examined an English-French sentence aligned bilingual text form a military domain. The text which we refer to as SNIPER2 is a manuals on sniper training and deployment that was used in a previous study (Macklovitch, 1995, cf. section 6). The text consists of 391 English-French aligned sentences. We have focused on the following phenomena of term variation: 2.1 Variation by Omission A number of omission variants can be distinguished. The examples (1b,2b) show omission variations for French. In (lb) the expansion pour arnnes is not specified while in (2h) the type of the lunette is under-specified. Following (Jacquemin, 1996, p. 425), these variants can be said to be in a generic/specific relation. general purpose weapons oil huile polyvalente pour arnnes general purpose weapons oil huile polyvalente Unertl tel</context>
<context position="16047" citStr="Macklovitch, 1995" startWordPosition="2562" endWordPosition="2563">n, the same translation is also abduced for the synonyms: anneau;aggraver;bouche;boucle;.... Abduction thus enables m different French expressions to be translated into n different English terms. However, adding further terms to the terminology will narrow the number of generated translations, as a terminology entry will be preferred over an abduced variant if they describe the same surface string. 6 Coverage and Precision of ITDB The ITDB was tested on two texts, SNIPER2 and SNIPER3. The texts are an excerpt of an army manual on sniper training and deployment that was used in an other study (Macklovitch, 1995). This corpus is highly specific to the military domain and would certainly prove difficult to any translation engine not specifically tuned to such material. SNIPER2 and SNIPER3 have 391 and 916 French-English aligned sentences, respectively with an average length of 19 and 22 words in the English LHS and the French RHS. Note that the terminology was also extracted from SNIPER2. Both language sides of the two texts were passed through the ITDB in two different ways: once only the authorized terms (T) and another time the authorized terms and their abduced variants (T+A) were were marked in bo</context>
</contexts>
<marker>Macklovitch, 1995</marker>
<rawString>Elliott Macklovitch. 1995. Can terminological consistency be validated automatically ? Technical report, CITI/RALI, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ingrid Meyer</author>
</authors>
<title>Extracting knowledge-rich contexts for terminography.</title>
<date>2001</date>
<booktitle>In in (Bourigault et al.,</booktitle>
<pages>279--302</pages>
<contexts>
<context position="20382" citStr="Meyer, 2001" startWordPosition="3316" endWordPosition="3317">word bouche in the French side of an alignment produces noise if no variant of focusing ring or eyepiece locking 5 The table 2 shows the number 782: I could not figure out where the missing translation equivalent disappeared ring was found in the English side of that alignment. This clearly indicates that the variation pattern (1) is too simple specially if combined with a noisy list of synonyms which calls for further refinement. In order to reduce this noise and to extend the coverage of the ITDB, future work will be in line with the methodology of iterative refinement as outlined by Meyer (Meyer, 2001). 7 Integrating ITDB and STM In a second experiment we have linked the ITDB with an SMT system. The way the ITDB interacts with the SMT engine is depicted in the block diagram of Figure 3. The ITDB identifies and marks terms and their possible variants in the source text (LHS Aligned Text) and regenerates their authorized target language form. The marked and with target language segments enriched text is then passed through the SMT system as described in (Langlais, 2002). While the position of the target term in the French target sentence is determined by the SMT system, its form is generated </context>
</contexts>
<marker>Meyer, 2001</marker>
<rawString>Ingrid Meyer. 2001. Extracting knowledge-rich contexts for terminography. In in (Bourigault et al., 2001), pages 279 302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raymond J Mooney</author>
</authors>
<title>Integrating abduction and induction in machine learning.</title>
<date>2000</date>
<booktitle>Abduction and Induction,</booktitle>
<pages>181--191</pages>
<editor>In P. Flach and A. Kakas, editors,</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="11718" citStr="Mooney, 2000" startWordPosition="1836" endWordPosition="1837">e (rearward;recompense;remunerate;pay;compensate) (movement;transport;traffic;trade;...) (nnouvennentennouvoir;transporttrafic;...) (arriere;fond;derriere;severe;queue; ...) (nnouvennentennouvoir;transporttrafic;...) x y (arriere;fond;derriere;severe;queue; ...) Figure 2: Abduction of Term Variants product. &amp;quot; Essentially, in Streiter&apos;s example, from the cooccurrence of two single experiences is inferred an implication containing a universal quantifier in the hypothesis. Abduction consists in reinstantiating the generated hypothesis by appropriate events to draw the desired conclusion. Mooney (Mooney, 2000) examines the relation between abduction and induction. Although precise definitions of abduction and induction are still somewhat controversial, he finds: &amp;quot;In abduction, the hypothesis is a specific set of assumptions that explain the observations of a particular case; while in induction, the hypothesis is a general theory that explains the observations across a number of cases.&amp;quot; (Mooney, 2000, p.183) Mooney applies abductive learning for theory refinement. Theory refinement is the task to make an existing imperfect domain theory consistent with a set of data. For him, abduction is primary us</context>
</contexts>
<marker>Mooney, 2000</marker>
<rawString>Raymond J. Mooney. 2000. Integrating abduction and induction in machine learning. In P. Flach and A. Kakas, editors, Abduction and Induction, pages 181 191, Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A comparison of alignement models for statistical machine translation.</title>
<date>2000</date>
<booktitle>In COLINGOO,</booktitle>
<pages>1086--1090</pages>
<contexts>
<context position="1809" citStr="Och and Ney, 2000" startWordPosition="274" endWordPosition="277">icle and several new exciting ways have been proposed to attack the problem&apos;. In a recent paper Langlais (2002) investigated how a statistical engine behaves when translating a very domain-specific text far different from the corpus used to train both the translation and language models used by the engine. Langlais measured a significant drop in performances mainly due to out-of-vocabulary words and specific terminology that the models handle poorly. He then proposed to overcome the problem by opening the engine to available (non statistical) terminological resources. This 1-See for instance (Och and Ney, 2000) for a comparison of several translation models. contrasts to a previous approach of (Brown et al., 1993) who develop a statistical model of a bilingual dictionary which is then integrated with training text. Both authors find, however, that terminological databases are resources that boost the performance of a statistical translation engine. With the possibility to introduce prior knowledge resources into SMT it becomes also interesting to explore their linguistic modeling and to investigate the adaptability of SMT systems to different domains. In this paper, we investigate a possibility to i</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>F.J. Och and H. Ney. 2000. A comparison of alignement models for statistical machine translation. In COLINGOO, pages 1086 1090.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oliver Streiter</author>
</authors>
<title>Treebank Development with Deductive and Abductive Explanation-based Learning: Exploratory Experiments,</title>
<date>2001</date>
<note>unpublished draft.</note>
<contexts>
<context position="9880" citStr="Streiter, 2001" startWordPosition="1595" endWordPosition="1596">. We use the example-based translation system EDGAR which marks matched sequences of words in the text as variant or term according to the status of the matched database entry. To evaluate coverage and precision of the ITDB (cf. section 6), the marked sequences are reduced to a generic label which are counted and compared in LHS and RHS. In the runtime architecture (cf. figure 3), authorized target language forms of source language terms and their variants are re-generated as discussed in section 7. 4 An Abductive Approach ITDB recognizes variants of terms by abduction. According to Streiter (Streiter, 2001), abductive reasoning creates hypothesis which are not logically implied by the premises. Unlike deductive reasoning, abduction is not always correct in all reasoning steps. However, abductive reasoning should be &amp;quot;plausible&amp;quot; in a context and yield correct results in the vast majority. Where deductive inference stops in front of gaps, abduction creates new hypothesis which allow to bridge the gap and continue the inference. As an illustration for abductive reasoning, Streiter gives the following example &amp;quot;Imagine, you ordered a product and a week later you received a parcel. Using abduction you </context>
</contexts>
<marker>Streiter, 2001</marker>
<rawString>Oliver Streiter. 2001. Treebank Development with Deductive and Abductive Explanation-based Learning: Exploratory Experiments, unpublished draft.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>