<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000119">
<title confidence="0.985856">
Constituent-based Accent Prediction
</title>
<author confidence="0.813197">
Christine H. Nakatani
</author>
<affiliation confidence="0.692381">
AT&amp;T Labs — Research
</affiliation>
<address confidence="0.888166">
180 Park Avenue, Florham Park NJ 07932-0971, USA
</address>
<email confidence="0.999534">
email: chn@research.attcom
</email>
<sectionHeader confidence="0.993904" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999367444444445">
Near-perfect automatic accent assignment is at-
tainable for citation-style speech, but better com-
putational models are needed to predict accent
in extended, spontaneous discourses. This paper
presents an empirically motivated theory of the dis-
course focusing nature of accent in spontaneous
speech. Hypotheses based on this theory lead to a
new approach to accent prediction, in which pat-
terns of deviation from citation form accentuation,
defined at the constituent or noun phrase level,
are automatically learned from an annotated cor-
pus. Machine learning experiments on 1031 noun
phrases from eighteen spontaneous direction-giving
monologues show that accent assignment can be
significantly improved by up to 4%-6% relative to
a hypothetical baseline system that would produce
only citation-form accentuation, giving error rate
reductions of 11%-25%.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999978534883721">
In speech synthesis systems, near-perfect (98%) ac-
cent assignment is automatically attainable for read-
aloud, citation-style speech (Hirschberg, 1993). But
for unrestricted, extended spontaneous discourses,
highly natural accentuation is often achieved only
by costly human post-editing. A better understand-
ing of the effects of discourse context on accentual
variation is needed not only to fully model this fun-
damental prosodic feature for text-to-speech (TTS)
synthesis systems, but also to further the integration
of prosody into speech understanding and concept-
to-speech (CTS) synthesis systems at the appropri-
ate level of linguistic representation.
This paper presents an empirically motivated the-
ory of the discourse focusing function of accent.
The theory describes for the first time the interacting
contributions to accent prediction made by factors
related to the local and global attentional status of
discourse referents in a discourse model (Grosz and
Sidner, 1986). The ability of the focusing features
to predict accent for a blind test corpus is examined
using machine learning. Because attentional status
is a property of referring expressions, a novel ap-
proach to accent prediction is proposed to allow for
the integration of word-based and constituent-based
linguistic features in the models to be learned.
The task of accent assignment is redefined as
the prediction of patterns of deviation from citation
form accentuation. Crucially, these deviations are
captured at the constituent level. This task redefi-
nition has two novel properties: (1) it bootstraps di-
rectly on knowledge about citation form or so-called
&amp;quot;context-independent&amp;quot; prosody embodied in current
TTS technology; and (2) the abstraction from word
to constituent allows for the natural integration of
focusing features into the prediction methods.
Results of the constituent-based accent prediction
experiments show that for two speakers from a cor-
pus of spontaneous direction-giving monologues,
accent assignment can be improved by up to 4%-6%
relative to a hypothetical baseline system that would
produce only citation-form accentuation, giving er-
ror rate reductions of 11%-25%.
</bodyText>
<sectionHeader confidence="0.842268" genericHeader="introduction">
2 Accent and attention
</sectionHeader>
<bodyText confidence="0.999863117647059">
Much theoretical work on intonational meaning has
focused on the association of accent with NEW in-
formation, and lack of accent with GIVEN informa-
tion, where given and new are defined with respect
to whether or not the information is already repre-
sented in a discourse model. While this association
reflects a general tendency (Brown, 1983), empir-
ical studies on longer discourses have shown this
simple dichotomy cannot explain important sub-
classes of expressions, such as accented pronouns,
cf. (Terken, 1984; Hirschberg, 1993).
We propose a new theory of the relationship be-
tween accent and attention, based on an enriched
taxonomy of given/new information status provided
by both the LOCAL (centering) and GLOBAL (fo-
cus stack model) attentional state models in Grosz
and Sidner&apos; s discourse modeling theory (1986).
</bodyText>
<page confidence="0.997104">
939
</page>
<bodyText confidence="0.988035">
Analysis of a 20-minute spontaneous story-telling
monologue&apos; identified separate but interacting con-
tributions of grammatical function, form of refer-
ring expression and accentuation2 in conveying the
attentional status of a discourse referent. These in-
teractions can be formally expressed in the frame-
work of attentional modeling by the following prin-
ciples of interpretation:
</bodyText>
<listItem confidence="0.967309894736842">
• The LEXICAL FORM OF A REFERRING EXPRES-
SION indicates the level of attentional processing,
i.e., pronouns involve local focusing while full lex-
ical forms involve global focusing (Grosz et al.,
1995).
• The GRAMMATICAL FUNCTION of a referring ex-
pression reflects the local attentional status of the
referent, i.e., subject position generally holds the
highest ranking member of the forward-looking
centers list (Cf list), while direct object holds the
next highest ranking member of the Cf list (Grosz
et al., 1995; Kameyama, 1985).
• The ACCENTING of a referring expression serves
as an inference cue to shift attention to a new
backward-looking center (Cb), or to mark the
global (re)introduction of a referent; LACK OF AC-
CENT serves as an inference cue to maintain atten-
tional focus on the Cb, Cf list members or global
referents (Nakatani, 1997).
</listItem>
<bodyText confidence="0.999980583333333">
The third principle concerning accent interpreta-
tion defines for the first time how accent serves uni-
formly to shift attention and lack of accent serves to
maintain attention, at either the local or global level
of discourse structure. This principle describing the
discourse focusing functions of accent directly ex-
plains 86.5% (173/200) of the referring expressions
in the spontaneous narrative, as shown in Table 1. If
performance factors (e.g. repairs, interruptions) and
special discourse situations (e.g. direct quotations)
are also considered accounted for, then coverage in-
creases to 96.5% (193/200).
</bodyText>
<sectionHeader confidence="0.996496" genericHeader="method">
3 Constituent-based experiments
</sectionHeader>
<bodyText confidence="0.999607333333334">
To test the generality of the proposed account of ac-
cent and attention, the ability of local and global fo-
cusing features to predict accent for a blind corpus
is examined using machine learning. To rigorously
assess the potential gains to be had from these at-
tentional features, we consider them in combination
with lexical and syntactic features identified in the
literature as strong predictors of accentuation (Al-
tenberg, 1987; Hirschberg, 1993; Ross et al., 1992).
</bodyText>
<footnote confidence="0.883615333333333">
&apos;The narrative was collected by Virginia Merlini.
2Accented expressions are identified by the presence of
PITCH ACCENT (Pierrehumbert, 1980).
</footnote>
<table confidence="0.958105028571428">
SUBJECT PRONOUNS (N=111)
25 prominent 23%
16 shift in Cb
6 contrast
3 emphasis
86 nonprominent 77%
75 continue or resume Cb
3 repair
2 dialogue tag
1 interruption from interviewer
5 unaccounted for
DIRECT OBJECT PRONOUNS (N=15)
1 prominent 7%
1 contrast
14 nonprominent 93%
10 maintain non-Cb in Cf list
3 inter-sentential anaphora
1 repair
SUBJECT EXPLICIT FORMS (N=54)
49 prominent 91%
44 introduce new global ref as Cp
2 quoted context
1 repair
2 unaccounted for
5 nonprominent 9%
2 top-level global focus
1 quoted context
1 repair
1 interruption from interviewer
DIRECT OBJECT EXPLICIT FORMS (N=20)
11 prominent 55%
11 introduce new global referent
9 nonprominent 45%
7 maintain ref in global focus
2 quoted context
</table>
<tableCaption confidence="0.9637705">
Table 1: Coverage of narrative data. The discourse
focusing functions of accent appear in italics.
</tableCaption>
<bodyText confidence="0.9987162">
Previous studies, nonetheless, were aimed at pre-
dicting word accentuation, and so the features we
borrow are being tested for the first time in learning
the abstract accentuation patterns of syntactic con-
stituents, specifically noun phrases (NPs).
</bodyText>
<subsectionHeader confidence="0.983313">
3.1 Methods
</subsectionHeader>
<bodyText confidence="0.999853">
Accent prediction models are learned from a cor-
pus of unrestricted, spontaneous direction-giving
monologues from the Boston Directions Corpus
(Nakatani et al., 1995). Eighteen spontaneous
direction-giving monologues are analyzed from two
American English speakers, H1 (male) and H3 (fe-
male). The monologues range from 43 to 631 words
in length, and comprise 1031 referring expressions
made up of 2020 words. Minimal, non-recursive
</bodyText>
<page confidence="0.984072">
940
</page>
<table confidence="0.95911275">
Accent class TTS-assigned accenting Actual accenting
citation a LITTLE SHOPPING AREA a LITTLE SHOPPING AREA
we we
supra one ONE
a PRETTY nice AMBIANCE a PRETTY NICE AMBIANCE
reduced the GREEN LINE SUBWAY the GREEN Line SUBWAY
YET ANOTHER RIGHT TURN yet ANOTHER RIGHT TURN
shift a VERY FAST FIVE MINUTE lunch a VERY FAST FIVE minute LUNCH
</table>
<tableCaption confidence="0.999481">
Table 3: Examples of citation-based accent classes. Accented words appear in boldface.
</tableCaption>
<bodyText confidence="0.999037111111111">
NP constituents, referred to as BAsENPs, are au-
tomatically identified using Collins&apos; (1996) lexical
dependency parser. In the following complex NP,
baseNPs appear in square brackets: [the brownstone
apartment building] on [the corner] of [Beacon and
Mass Aye]. BaseNPs are semi-automatically la-
beled for lexical, syntactic, local focus and global
focus features. Table 2 provides summary corpus
statistics. A rule-based machine learning program,
</bodyText>
<table confidence="0.902194">
Corpus measure H1 H3 Total
total no. of words 2359 1616 3975
baseNPs 621 410 1031
words in baseNPs 1203 817 2020
% words in baseNPs 51.0% 50.6% 50.8%
</table>
<tableCaption confidence="0.989409">
Table 2: Word and baseNP corpus measures.
</tableCaption>
<bodyText confidence="0.99973625">
Ripper (Cohen, 1995), is used to acquire accent
classification systems from a training corpus of cor-
rectly classified examples, each defined by a vector
of feature values, or predictors.3
</bodyText>
<subsectionHeader confidence="0.999381">
3.2 Citation-based Accent Classification
</subsectionHeader>
<bodyText confidence="0.999969833333333">
The accentuation of baseNPs is coded according to
the relationship of the actual accenting (i.e. ac-
cented versus unaccented) on the words in the
baseNP to the accenting predicted by a TI&apos;S system
that received each sentence in the corpus in isola-
tion. The actual accenting is determined by prosodic
labeling using the ToBI standard (Pitrelli et al.,
1994). Word accent predictions are produced by the
Bell Laboratories NewTTS system (Sproat, 1997).
NewTTS incorporates complex nominal accenting
rules (Sproat, 1994) as well as general, word-based
accenting rules (Hirschberg, 1993). It is assumed
</bodyText>
<footnote confidence="0.922159">
3Ripper is similar to CART (Breiman et al., 1984), but it
directly produces IF-THEN logic rules instead of decision trees
and also utilizes incremental error reduction techniques in com-
bination with novel rule optimization strategies.
</footnote>
<bodyText confidence="0.9936116">
for the purposes of this study that NewTTS gener-
ally assigns citation-style accentuation when passed
sentences in isolation.
For each baseNP, one of the following four ac-
centing patterns is assigned:
</bodyText>
<listItem confidence="0.994045272727273">
• CITATION FORM: exact match between actual and
TTS-assigned word accenting.
• SUPRA: one or more accented words are predicted
unaccented by TTS; otherwise, TTS predictions
match actual accenting.
• REDUCED: one or more unaccented words are pre-
dicted accented by TTS; otherwise, TTS predic-
tions match actual accenting.
• SHIFT: at least one accented word is predicted un-
accented by TTS, and at least one unaccented word
is predicted accented by TTS.
</listItem>
<bodyText confidence="0.96959325">
Examples from the Boston Directions Corpus for
each accent class appear in Table 3.
Table 4 gives the breakdown of coded baseNPs by
accent class. In contrast to read-aloud citation-style
</bodyText>
<table confidence="0.997994857142857">
Accent Hi baseNPs H3 baseNPs
class
citation 471 75.8% 247 60.2%
supra 73 11.8% 68 16.6%
reduced 68 11.9% 83 20.2%
shift 9 1.4% 12 2.9%
total 621 100% 410 100%
</table>
<tableCaption confidence="0.99985">
Table 4: Accent class distribution for all baseNPs.
</tableCaption>
<bodyText confidence="0.99989">
speech, in these unrestricted, spontaneous mono-
logues, 30% of referring expressions do not bear
citation form accentuation. The citation form ac-
cent percentages serve as the baseline for the accent
prediction experiments; correct classification rates
above 75.8% and 60.2% for H1 and H3 respectively
would represent performance above and beyond the
</bodyText>
<page confidence="0.992399">
941
</page>
<bodyText confidence="0.989233333333333">
state-of-the-art citation form accentuation models,
gained by direct modeling of cases of supra, reduced
or shifted constituent-based accentuation.
</bodyText>
<subsectionHeader confidence="0.9553905">
3.3 Predictors
3.3.1 Lexical features
</subsectionHeader>
<bodyText confidence="0.999924476190476">
The use of set features, which are handled by Rip-
per, extends lexical word features to the constituent
level. Two set-valued features, BROAD CLASS SE-
QUENCE and LEMMA SEQUENCE, represent lexical
information. These features consist of an ordered
list of the broad class part-of-speech (POS) tags or
word lemmas for the words making up the baseNP.
For example, the lemma sequence for the NP, the
Harvard Square T stop, is {the, Harvard, Square, T,
stop}. The corresponding broad class sequence is
{determiner, noun, noun, noun, noun}. Broad class
tags are derived using Brill&apos; s (1995) part-of-speech
tagger, and word lemma information is produced by
NewTTS (Sproat, 1997).
POS information is used to assign accenting in
nearly all speech synthesis systems. Initial word-
based experiments on our corpus showed that broad
class categories performed slightly better than both
the function-content distinction and the POS tags
themselves, giving 69%-81% correct word predic-
tions (Nakatani, 1997).
</bodyText>
<subsectionHeader confidence="0.913842">
3.3.2 Syntactic constituency features
</subsectionHeader>
<bodyText confidence="0.998423565217391">
The CLAUSE TYPE feature represents global syn-
tactic constituency information, while the BASENP
TYPE feature represents local or NP-internal syntac-
tic constituency information. Four clause types are
coded: matrix, subordinate, predicate complement
and relative. Each baseNP is semi-automatically as-
signed the clause type of the lowest level clause or
nearest dominating clausal node in the parse tree,
which contains the baseNP. As for baseNP types,
the baseNP type of baseNPs not dominated by any
NP node is SIMPLE-BASENP. BaseNPs that occur
in complex NPs (and are thus dominated by at least
one NP node) are labeled according to whether the
baseNP contains the head word for the dominating
NP. Those that are dominated by only one NP node
and contain the head word for the dominating NP
are HEAD-BASENPS; all other NPs in a complex NP
are CHILD-BASENPS. Conjoined noun phrases in-
volve additional categories of baseNPs that are col-
lapsed into the CONJUNCT-BASENP category. Ta-
ble 5 gives the distributions of baseNP types.
Focus projection theories of accent, e.g. (Gussen-
hoven, 1984; Selkirk, 1984), would predict a large
</bodyText>
<table confidence="0.998548285714286">
baseNP type N Hi N H3
% %
simple 447 72.0% 280 68.3%
head 61 9.8% 46 11.2%
child 74 11.9% 65 15.9%
conjunct 39 6.3% 19 4.5%
total 621 100% 410 100%
</table>
<tableCaption confidence="0.847851">
Table 5: Distribution of baseNP types for all
baseNPs.
</tableCaption>
<bodyText confidence="0.988045">
role for syntactic constituency information in de-
termining accent, especially for noun phrase con-
stituents. Empirical evidence for such a role, how-
ever, has been weak (Altenberg, 1987).
</bodyText>
<subsectionHeader confidence="0.677059">
3.3.3 Local focusing features
</subsectionHeader>
<bodyText confidence="0.998685363636364">
The local attentional status of baseNPs is repre-
sented by two features commonly used in centering
theory to compute the Cb and the Cf list, GRAM-
MATICAL FUNCTION and FORM OF EXPRESSION
(Grosz et al., 1995). Hand-labeled grammatical
functions include subject, direct object, indirect ob-
ject, predicate complement, adjunct. Form of ex-
pression feature values are ,adverbial noun, cardi-
nal, definite NP demonstrative NP, indefinite NP,
pronoun, proper name, quantifier NP verbal noun,
etc.
</bodyText>
<subsectionHeader confidence="0.644352">
3.3.4 Global focus feature
</subsectionHeader>
<bodyText confidence="0.999392739130435">
The global focusing status of baseNPs is computed
using two sets of analyses: discourse segmenta-
tions and coreference coding. Expert discourse
structure analyses are used to derive CONSENSUS
SEGMENTATIONS, consisting of discourse bound-
aries whose coding all three labelers agreed upon
(Hirschberg and Nakatani, 1996). The consensus
labels for segment-initial boundaries provide a lin-
ear segmentation of a discourse into discourse seg-
ments. Coreferential relations are coded by two la-
belers using DTT (Discourse Tagging Tool) (Aone
and Bennett, 1995). To compute coreference chains,
only the relation of strict coference is used. Two
NPs, np 1 and np2, are in a strict coreference rela-
tionship, when np2 occurs after npl in the discourse
and realizes the same discourse entity that is real-
ized by np 1 . Reference chains are then automat-
ically computed by linking noun phrases in strict
coference relations into the longest possible chains.
Given a consensus linear segmentation and refer-
ence chains, global focusing status is determined.
For each baseNP, if it does not occur in a refer-
ence chain, and thus is realized only once in the dis-
</bodyText>
<page confidence="0.995438">
942
</page>
<bodyText confidence="0.999821083333333">
course, it is assigned the SINGLE-MENTION focus-
ing status. The remaining statuses apply to baseNPs
that do occur in reference chains. If a baseNP in a
chain is not previously mentioned in the discourse,
it is assigned the FIRST-MENTION status. If its most
recent coreferring expression occurs in the current
segment, the baseNP is in IMMEDIATE focus; if it
occurs in the immediately previous segment, the
baseNP is in NEIGHBORING focus; if it occurs in
the discourse but not in either the current or imme-
diately previous segments, then the baseNP is as-
signed STACK focus.
</bodyText>
<sectionHeader confidence="0.999969" genericHeader="evaluation">
4 Results
</sectionHeader>
<subsectionHeader confidence="0.892644">
4.1 Individual features
</subsectionHeader>
<bodyText confidence="0.999573">
Experimental results on individual features are re-
ported in Table 4.1 in terms of the average per-
cent correct classification and standard deviation.4
A trend emerges that lexical features (i.e. word
</bodyText>
<table confidence="0.997027615384615">
Experiment H1 H3
Lexical
Broad cl seq 78.58 ± 1.30 59.51 ± 2.72
Lemma seq 80.05 ± 1.85 62.93 ± 2.68
Syntactic
baseNP type 75.86 ± 2.52 60.24 ± 2.97
Clause type 75.85 ± 1.14 60.24 ± 3.49
Local focus
Gram fn 75.83 ± 1.93 62.68 ± 2.74
Form of expr 78.10± 1.54 61.95± 1.89
Global focus
Global focus 75.85 ± 2.07 -
Baseline 75.8 60.2
</table>
<tableCaption confidence="0.961526">
Table 6: Average percentages correct classification
</tableCaption>
<bodyText confidence="0.9994855">
and standard deviations for individual feature exper-
iments.
lemma and broad class sequences, and form of ex-
pression) enable the largest improvements in clas-
sification, e.g. 2.7% and 2.3% for HI using broad
class sequence and form of expression information
respectively. These results suggest that the abstract
level of lexical description supplied by form of ex-
pression does the equivalent work of the lower-level
lexical features. Thus, for CTS, accentuation class
might be predicted when the more abstract form of
expression information is known, and need not be
</bodyText>
<footnote confidence="0.563763333333333">
4Ripper experiments are conducted with 10-fold cross-
validation. Statistically significant differences in the perfor-
mance of two systems are determined by using the Student&apos;s
curve approximation to compute confidence intervals, follow-
ing Litman (1996). Significant results at p &lt;.05 or stronger
appear in italics.
</footnote>
<bodyText confidence="0.9996725">
delayed until the tactical generation of the expres-
sion is completed. Conversely, for TTS, simple cor-
pus analysis of lemma and POS sequences may per-
form as well as higher-level lexical analysis.
</bodyText>
<subsectionHeader confidence="0.979604">
4.2 Combinations of classes of features
</subsectionHeader>
<bodyText confidence="0.516285">
Experiments on combinations of feature classes are
</bodyText>
<table confidence="0.999340625">
reported in Table 7. The average classification rate
Experiment H1 H3
Local/syntax 77.61 ± 1.39 60.98 ± 2.60
Local/lex 78.74 ± 1.48 63.17± 1.90
Local/lex/syntax 79.06± 1.53 61.95 ± 2.27
Local/global 78.11 ± 1.28
Loc/glob/lex/syn 79.22± 1.96
Baseline 75.8 60.2
</table>
<tableCaption confidence="0.995792">
Table 7: Average percentages correct classifica-
</tableCaption>
<bodyText confidence="0.9159823">
tion and standard deviations for combination exper-
iments.
of 63.17% for H3 on the local focus and lexical fea-
ture class model, is the best obtained for all H3 ex-
periments, increasing prediction accuracy by nearly
3%. The highest classification rate for H1 is 79.22%
for the model including local and global focus, and
lexical and syntactic feature classes, showing an im-
provement of 3.4%. These results, however, do not
attain significance.
</bodyText>
<subsectionHeader confidence="0.999673">
4.3 Experiments on simple-baseNPs
</subsectionHeader>
<bodyText confidence="0.996278285714286">
Three sets of experiments that showed strong per-
formance gains are reported for the non-recursive
simple-baseNPs. These are: (1) word lemma se-
quence alone, (2) lemma and broad class sequences
together, and (3) local focus and lexical features
combined. Table 8 shows the accent class distribu-
tion for simple-baseNPs.
</bodyText>
<table confidence="0.995706571428571">
Accent H1 simple-baseNPs H3 simple-baseNPs
class
citation 334 74.7 167 59.6
supra 62 13.9 47 16.8
reduced 46 10.3 56 0.20
shift 5 1.1 10 3.6
total 447 100 280 100
</table>
<tableCaption confidence="0.7745315">
Table 8: Accent class distribution for simple-
baseNPs.
</tableCaption>
<bodyText confidence="0.993599714285714">
Results appear in Table 9. For H3, the lemma
sequence model delivers the best performance,
65.71%, for a 4.3% improvement over the baseline.
The best classification rate of 80.93% for H1 on the
local focus and lexical feature model represents a
6.23% gain over the baseline. These figures repre-
sent an 11% reduction in error rate for H3, and a
</bodyText>
<page confidence="0.997675">
943
</page>
<table confidence="0.942886571428571">
25% reduction in error rate for F11, and are statis-
tically significant improvements over the baseline.
Experiment H1 H3
Lemma seq 80.74 ± 1.87 65.71 ± 2.70
Lemma, broad cl 80.80± 1.41 62.14 ± 2.58
Local/lexical 80.93 ± 1.35 63.21 ± 1.78
Baseline 74.7 59.6
</table>
<tableCaption confidence="0.991361">
Table 9: Average percentages correct classification
</tableCaption>
<bodyText confidence="0.9699165">
and standard deviations for simple-baseNP experi-
ments.
In the rule sets learned by Ripper for the HI lo-
cal focus/lexical model, interactions of the different
features in specific rules can be observed. Two rule
sets that performed with error rates of 13.6% and
13.7% on different, cross-validation runs are pre-
sented in Figure 1. Inspection of the rule sets
</bodyText>
<table confidence="0.833413444444445">
H1 local focus/lexical model rule set 1
reduced :- form of expr=proper name, broad class
seq det, lemma seq Harvard.
supra :- broad class seq -- adverbial.
supra :- gram fn=adjunct, lemma seq this.
supra :- gram fn=adjunct, lemma seq Cowper-
waithe.
supra :- lemma seq I.
default citation.
H1 local focus/lexical model rule set 2
reduced:- broad class seq n, lemma seq -- the,
lemma seq Square.
supra :- form of expr=adverbial.
supra :- gram fn=adjunct, lemma seq Cowper-
waithe.
supra :- lemma seq this.
supra :- lemma seq I.
default citation.
</table>
<figureCaption confidence="0.8891095">
Figure 1: Highest performing learned rule sets for
H1, local focus/lexical model.
</figureCaption>
<bodyText confidence="0.97381045">
reveals that there are few non-lexical rules learned.
The exception seems to be the rule that adverbial
noun phrases belong to the supra accent class. How-
ever, new interactions of local focusing features
(grammatical function and form of expression) with
lexical information are discovered by Ripper. It also
appears that as suggested by earlier experiments,
51n the rules themselves, written in Prolog-style notation,
the tilde character is a two-place operator, X Y, signifying
that Y is a member of the set-value for feature X.
lexical features trade-off for one other as well as
with form of expression information. In comparing
the first rules in each set, for example, the clauses
broad class seq det and lemma seq ,-- the sub-
stitute for one another. However, in the first rule
set the less specific broad class constraint must be
combined with another abstract constraint, form of
expr=proper name, to achieve a similar descrip-
tion of a rule for reduced accentuation on common
place names, such as the Harvard Square T stop.
</bodyText>
<sectionHeader confidence="0.998864" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999940926829268">
Accent prediction experiments on noun phrase con-
stituents demonstrated that deviations from citation
form accentuation (supra, reduced and shift classes)
can be directly modeled. Machine learning experi-
ments using not only lexical and syntactic features,
but also discourse focusing features identified by
a new theory of accent interpretation in discourse,
showed that accent assignment can be improved by
up to 4%-6% relative to a hypothetical baseline sys-
tem that would produce only citation-form accen-
tuation, giving error rate reductions of 11 %-25%.
In general, constituent-based accentuation is most
accurately learned from lexical information readily
available in TTS systems. For CTS systems, com-
parable performance may be achieved using only
higher level attentional features. There are several
other lessons to be learned, concerning individual
speaker, domain dependent and domain indepen-
dent effects on accent modeling.
First, it is perhaps counterintuitively harder to
predict deviations from citation form accentuation
for speakers who exhibit a great deal of non-
citation-style accenting behavior, such as speaker
H3. Accent prediction results for HI exceeded those
for H3, although about 15% more of I-13&apos;s tokens
exhibited non-citation form accentuation. Finding
the appropriate parameters by which to describe the
prosody of individual speakers is an important goal
that can be advanced by using machine learning
techniques to explore large spaces of hypotheses.
Second, it is evident from the strong performance
of the word lemma sequence models that deviations
from citation-form accentuation may often be ex-
pressed by lexicalized rules of some sort. Lexical-
ized rules in fact have proven useful in other areas of
natural language statistical modeling, such as POS
tagging (Brill, 1995) and parsing (Collins, 1996).
The specific lexicalized rules learned for many of
the models would not have followed from any the-
oretical or empirical proposals in the literature. It
may be that domain dependent training using au-
</bodyText>
<page confidence="0.99521">
944
</page>
<bodyText confidence="0.999906842105263">
tomatic learning is the appropriate way to develop
practical models of accenting patterns on different
corpora. And especially for different speakers in the
same domain, automatic learning methods seem to
be the only efficient way to capture perhaps idiolec-
tical variation in accenting.
Finally, it should be noted that notwithstanding
individual speaker and domain dependent effects,
domain independent factors identified by the new
theory of accent and attention do contribute to ex-
perimental performance. The two local focusing
features, grammatical function and form of refer-
ring expression, enable improvements above the
citation-form baseline, especially in combination
with lexical information. Global focusing informa-
tion is of limited use by itself, but as may have
been hypothesized, contributes to accent prediction
in combination with local focus, lexical and syntac-
tic features.
</bodyText>
<sectionHeader confidence="0.998561" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99986775">
This research was supported by a NSF Graduate Re-
search Fellowship and NSF Grants Nos. IRI-90-
09018, IRI-93-08173 and CDA-94-01024 at Har-
vard University. The author is grateful to Barbara
Grosz, Julia Hirschberg and Stuart Shieber for valu-
able discussion on this research; to Chinatsu Aone,
Scott Bennett, Eric Brill, William Cohen, Michael
Collins, Giovanni Flammia, Diane Litman, Becky
Passonneau, Richard Sproat and Gregory Ward for
sharing and discussing methods and tools; and to
Diane Litman, Marilyn Walker and Steve Whittaker
for suggestions for improving this paper.
</bodyText>
<sectionHeader confidence="0.998589" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999331287356322">
B. Altenberg. 1987. Prosodic Patterns in Spoken En-
glish: Studies in the Correlation Between Prosody and
Grammar for Text-to-Speech Conversion. Lund Uni-
versity Press, Lund, Sweden.
C. Aone and S. W. Bennett. 1995. Evaluating auto-
mated and manual acquisition of anaphora resolution
strategies. In Proceedings of the 33rd Annual Meet-
ing, Boston. Association for Computational Linguis-
tics.
Leo Breiman, Jerome H. Friedman, Richard A. Olshen,
and Charles J. Stone. 1984. Classification and Re-
gression Trees. Wadsworth and Brooks, Pacific Grove
CA.
Eric Brill. 1995. Transformation-based error-driven
learning and natural language processing: a case study
in part of speech tagging. Computational Lingusitics.
G. Brown. 1983. Prosodic structure and the Given/New
distinction. In A. Cutler and D. R. Ladd, editors,
Prosody: Models and Measurements, pages 67-78.
Springer-Verlag, Berlin.
William A. Cohen. 1995. Fast effective rule induction.
In Proceedings of the Twelfth International Confer-
ence on Machine Learning.
Michael John Collins. 1996. A new statistical parser
based on bigram lexical dependencies. In Proceed-
ings of the 34th Annual Meeting of the Association for
Computational Linguistics.
Barbara Grosz and Candace Sidner. 1986. Attention,
intentions, and the structure of discourse. Computa-
tional Linguistics, 12(3):175-204.
Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein.
1995. Centering: a framework for modelling the lo-
cal coherence of discourse. Computational Linguis-
tics, 21(2), June.
Carlos Gussenhoven. 1984. On the Grammar and Se-
mantics of Sentence Accents. Foris Publications, Dor-
drecht.
Julia Hirschberg and Christine Nakatani. 1996. A
prosodic analysis of discourse segments in direction-
giving monologues. In Proceedings of the 34th An-
nual Meeting of the ACL, Santa Cruz. Association for
Computational Linguistics.
Julia Hirschberg. 1993. Pitch accent in context: predict-
ing intonational prominence from text. Artificial In-
telligence, 63(1-2):305-340.
M. Kameyama. 1985. Zero anaphora: the case in
Japanese. Ph.D. thesis, Stanford University.
Diane J. Litman. 1996. Cue phrase classification using
machine learning. Journal of Artificial Intelligence,
pages 53-94.
Christine H. Nakatani, Barbara Grosz, and Julia
Hirschberg. 1995. Discourse structure in spoken lan-
guage: studies on speech corpora. In Proceedings of
the AAAI Spring Symposium on Empirical Methods in
Discourse Interpretation and Generation, Palo Alto,
CA, March. American Association for Artificial Intel-
ligence.
Christine H. Nakatani. 1997. The Computational Pro-
cessing of Intonational Prominence: a Functional
Prosody Perspective. Ph.D. thesis, Harvard Univer-
sity, Cambridge, MA, May.
Janet Pierrehumbert. 1980. The Phonology and Phonet-
ics of English Intonation. Ph.D. thesis, Massachusetts
Institute of Technology, September. Distributed by
the Indiana University Linguistics Club.
John Pitrelli, Mary Beckman, and Julia Hirschberg.
1994. Evaluation of prosodic transcription labeling
reliability in the ToBI framework. In Proceedings of
the 3rd International Conference on Spoken Language
Processing, volume 2, pages 123-126, Yokohama,
Japan.
K. Ross, M. Ostendorf, and S. Shattuck-Hufnagel. 1992.
Factors affecting pitch accent placement. In Proceed-
ings of the 2nd International Conference on Spoken
Language Processing, pages 365-368, Banff, Canada,
October.
E. Selkirk. 1984. Phonology and Syntax. MIT Press,
Cambridge MA.
Richard Sproat. 1994. English noun-phrase accent pre-
diction for text-to-speech. Computer Speech and Lan-
guage, 8:79-94.
Richard Sproat, editor. 1997. Multilingual Text-to-
Speech Synthesis: The Bell Labs Approach. Kluwer
Academic, Boston.
J. Terken. 1984. The distribution of pitch accents in in-
structions as a function of discourse structure. Lan-
guage and Speech, 27:269-289.
</reference>
<page confidence="0.99885">
945
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.988889">
<title confidence="0.998281">Constituent-based Accent Prediction</title>
<author confidence="0.99999">Christine H Nakatani</author>
<affiliation confidence="0.999572">AT&amp;T Labs — Research</affiliation>
<address confidence="0.999231">180 Park Avenue, Florham Park NJ 07932-0971, USA</address>
<abstract confidence="0.999563631578948">Near-perfect automatic accent assignment is attainable for citation-style speech, but better computational models are needed to predict accent in extended, spontaneous discourses. This paper presents an empirically motivated theory of the discourse focusing nature of accent in spontaneous speech. Hypotheses based on this theory lead to a new approach to accent prediction, in which patterns of deviation from citation form accentuation, defined at the constituent or noun phrase level, are automatically learned from an annotated corpus. Machine learning experiments on 1031 noun phrases from eighteen spontaneous direction-giving monologues show that accent assignment can be significantly improved by up to 4%-6% relative to a hypothetical baseline system that would produce only citation-form accentuation, giving error rate reductions of 11%-25%.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Altenberg</author>
</authors>
<title>Prosodic Patterns in Spoken English: Studies in the Correlation Between Prosody and Grammar for Text-to-Speech Conversion.</title>
<date>1987</date>
<publisher>Lund University Press,</publisher>
<location>Lund, Sweden.</location>
<contexts>
<context position="6343" citStr="Altenberg, 1987" startWordPosition="949" endWordPosition="951">, interruptions) and special discourse situations (e.g. direct quotations) are also considered accounted for, then coverage increases to 96.5% (193/200). 3 Constituent-based experiments To test the generality of the proposed account of accent and attention, the ability of local and global focusing features to predict accent for a blind corpus is examined using machine learning. To rigorously assess the potential gains to be had from these attentional features, we consider them in combination with lexical and syntactic features identified in the literature as strong predictors of accentuation (Altenberg, 1987; Hirschberg, 1993; Ross et al., 1992). &apos;The narrative was collected by Virginia Merlini. 2Accented expressions are identified by the presence of PITCH ACCENT (Pierrehumbert, 1980). SUBJECT PRONOUNS (N=111) 25 prominent 23% 16 shift in Cb 6 contrast 3 emphasis 86 nonprominent 77% 75 continue or resume Cb 3 repair 2 dialogue tag 1 interruption from interviewer 5 unaccounted for DIRECT OBJECT PRONOUNS (N=15) 1 prominent 7% 1 contrast 14 nonprominent 93% 10 maintain non-Cb in Cf list 3 inter-sentential anaphora 1 repair SUBJECT EXPLICIT FORMS (N=54) 49 prominent 91% 44 introduce new global ref as</context>
<context position="14288" citStr="Altenberg, 1987" startWordPosition="2195" endWordPosition="2196">nal categories of baseNPs that are collapsed into the CONJUNCT-BASENP category. Table 5 gives the distributions of baseNP types. Focus projection theories of accent, e.g. (Gussenhoven, 1984; Selkirk, 1984), would predict a large baseNP type N Hi N H3 % % simple 447 72.0% 280 68.3% head 61 9.8% 46 11.2% child 74 11.9% 65 15.9% conjunct 39 6.3% 19 4.5% total 621 100% 410 100% Table 5: Distribution of baseNP types for all baseNPs. role for syntactic constituency information in determining accent, especially for noun phrase constituents. Empirical evidence for such a role, however, has been weak (Altenberg, 1987). 3.3.3 Local focusing features The local attentional status of baseNPs is represented by two features commonly used in centering theory to compute the Cb and the Cf list, GRAMMATICAL FUNCTION and FORM OF EXPRESSION (Grosz et al., 1995). Hand-labeled grammatical functions include subject, direct object, indirect object, predicate complement, adjunct. Form of expression feature values are ,adverbial noun, cardinal, definite NP demonstrative NP, indefinite NP, pronoun, proper name, quantifier NP verbal noun, etc. 3.3.4 Global focus feature The global focusing status of baseNPs is computed using </context>
</contexts>
<marker>Altenberg, 1987</marker>
<rawString>B. Altenberg. 1987. Prosodic Patterns in Spoken English: Studies in the Correlation Between Prosody and Grammar for Text-to-Speech Conversion. Lund University Press, Lund, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Aone</author>
<author>S W Bennett</author>
</authors>
<title>Evaluating automated and manual acquisition of anaphora resolution strategies.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boston.</location>
<contexts>
<context position="15381" citStr="Aone and Bennett, 1995" startWordPosition="2355" endWordPosition="2358">, proper name, quantifier NP verbal noun, etc. 3.3.4 Global focus feature The global focusing status of baseNPs is computed using two sets of analyses: discourse segmentations and coreference coding. Expert discourse structure analyses are used to derive CONSENSUS SEGMENTATIONS, consisting of discourse boundaries whose coding all three labelers agreed upon (Hirschberg and Nakatani, 1996). The consensus labels for segment-initial boundaries provide a linear segmentation of a discourse into discourse segments. Coreferential relations are coded by two labelers using DTT (Discourse Tagging Tool) (Aone and Bennett, 1995). To compute coreference chains, only the relation of strict coference is used. Two NPs, np 1 and np2, are in a strict coreference relationship, when np2 occurs after npl in the discourse and realizes the same discourse entity that is realized by np 1 . Reference chains are then automatically computed by linking noun phrases in strict coference relations into the longest possible chains. Given a consensus linear segmentation and reference chains, global focusing status is determined. For each baseNP, if it does not occur in a reference chain, and thus is realized only once in the dis942 course</context>
</contexts>
<marker>Aone, Bennett, 1995</marker>
<rawString>C. Aone and S. W. Bennett. 1995. Evaluating automated and manual acquisition of anaphora resolution strategies. In Proceedings of the 33rd Annual Meeting, Boston. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leo Breiman</author>
<author>Jerome H Friedman</author>
<author>Richard A Olshen</author>
<author>Charles J Stone</author>
</authors>
<title>Classification and Regression Trees. Wadsworth and Brooks,</title>
<date>1984</date>
<location>Pacific Grove CA.</location>
<contexts>
<context position="9977" citStr="Breiman et al., 1984" startWordPosition="1513" endWordPosition="1516">Ps is coded according to the relationship of the actual accenting (i.e. accented versus unaccented) on the words in the baseNP to the accenting predicted by a TI&apos;S system that received each sentence in the corpus in isolation. The actual accenting is determined by prosodic labeling using the ToBI standard (Pitrelli et al., 1994). Word accent predictions are produced by the Bell Laboratories NewTTS system (Sproat, 1997). NewTTS incorporates complex nominal accenting rules (Sproat, 1994) as well as general, word-based accenting rules (Hirschberg, 1993). It is assumed 3Ripper is similar to CART (Breiman et al., 1984), but it directly produces IF-THEN logic rules instead of decision trees and also utilizes incremental error reduction techniques in combination with novel rule optimization strategies. for the purposes of this study that NewTTS generally assigns citation-style accentuation when passed sentences in isolation. For each baseNP, one of the following four accenting patterns is assigned: • CITATION FORM: exact match between actual and TTS-assigned word accenting. • SUPRA: one or more accented words are predicted unaccented by TTS; otherwise, TTS predictions match actual accenting. • REDUCED: one or</context>
</contexts>
<marker>Breiman, Friedman, Olshen, Stone, 1984</marker>
<rawString>Leo Breiman, Jerome H. Friedman, Richard A. Olshen, and Charles J. Stone. 1984. Classification and Regression Trees. Wadsworth and Brooks, Pacific Grove CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Transformation-based error-driven learning and natural language processing: a case study in part of speech tagging.</title>
<date>1995</date>
<journal>Computational Lingusitics.</journal>
<contexts>
<context position="24129" citStr="Brill, 1995" startWordPosition="3767" endWordPosition="3768">ugh about 15% more of I-13&apos;s tokens exhibited non-citation form accentuation. Finding the appropriate parameters by which to describe the prosody of individual speakers is an important goal that can be advanced by using machine learning techniques to explore large spaces of hypotheses. Second, it is evident from the strong performance of the word lemma sequence models that deviations from citation-form accentuation may often be expressed by lexicalized rules of some sort. Lexicalized rules in fact have proven useful in other areas of natural language statistical modeling, such as POS tagging (Brill, 1995) and parsing (Collins, 1996). The specific lexicalized rules learned for many of the models would not have followed from any theoretical or empirical proposals in the literature. It may be that domain dependent training using au944 tomatic learning is the appropriate way to develop practical models of accenting patterns on different corpora. And especially for different speakers in the same domain, automatic learning methods seem to be the only efficient way to capture perhaps idiolectical variation in accenting. Finally, it should be noted that notwithstanding individual speaker and domain de</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>Eric Brill. 1995. Transformation-based error-driven learning and natural language processing: a case study in part of speech tagging. Computational Lingusitics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Brown</author>
</authors>
<title>Prosodic structure and the Given/New distinction.</title>
<date>1983</date>
<booktitle>Prosody: Models and Measurements,</booktitle>
<pages>67--78</pages>
<editor>In A. Cutler and D. R. Ladd, editors,</editor>
<contexts>
<context position="3562" citStr="Brown, 1983" startWordPosition="521" endWordPosition="522">akers from a corpus of spontaneous direction-giving monologues, accent assignment can be improved by up to 4%-6% relative to a hypothetical baseline system that would produce only citation-form accentuation, giving error rate reductions of 11%-25%. 2 Accent and attention Much theoretical work on intonational meaning has focused on the association of accent with NEW information, and lack of accent with GIVEN information, where given and new are defined with respect to whether or not the information is already represented in a discourse model. While this association reflects a general tendency (Brown, 1983), empirical studies on longer discourses have shown this simple dichotomy cannot explain important subclasses of expressions, such as accented pronouns, cf. (Terken, 1984; Hirschberg, 1993). We propose a new theory of the relationship between accent and attention, based on an enriched taxonomy of given/new information status provided by both the LOCAL (centering) and GLOBAL (focus stack model) attentional state models in Grosz and Sidner&apos; s discourse modeling theory (1986). 939 Analysis of a 20-minute spontaneous story-telling monologue&apos; identified separate but interacting contributions of gra</context>
</contexts>
<marker>Brown, 1983</marker>
<rawString>G. Brown. 1983. Prosodic structure and the Given/New distinction. In A. Cutler and D. R. Ladd, editors, Prosody: Models and Measurements, pages 67-78.</rawString>
</citation>
<citation valid="false">
<publisher>Springer-Verlag,</publisher>
<location>Berlin.</location>
<marker></marker>
<rawString>Springer-Verlag, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Cohen</author>
</authors>
<title>Fast effective rule induction.</title>
<date>1995</date>
<booktitle>In Proceedings of the Twelfth International Conference on Machine Learning.</booktitle>
<contexts>
<context position="9122" citStr="Cohen, 1995" startWordPosition="1384" endWordPosition="1385">utomatically identified using Collins&apos; (1996) lexical dependency parser. In the following complex NP, baseNPs appear in square brackets: [the brownstone apartment building] on [the corner] of [Beacon and Mass Aye]. BaseNPs are semi-automatically labeled for lexical, syntactic, local focus and global focus features. Table 2 provides summary corpus statistics. A rule-based machine learning program, Corpus measure H1 H3 Total total no. of words 2359 1616 3975 baseNPs 621 410 1031 words in baseNPs 1203 817 2020 % words in baseNPs 51.0% 50.6% 50.8% Table 2: Word and baseNP corpus measures. Ripper (Cohen, 1995), is used to acquire accent classification systems from a training corpus of correctly classified examples, each defined by a vector of feature values, or predictors.3 3.2 Citation-based Accent Classification The accentuation of baseNPs is coded according to the relationship of the actual accenting (i.e. accented versus unaccented) on the words in the baseNP to the accenting predicted by a TI&apos;S system that received each sentence in the corpus in isolation. The actual accenting is determined by prosodic labeling using the ToBI standard (Pitrelli et al., 1994). Word accent predictions are produc</context>
</contexts>
<marker>Cohen, 1995</marker>
<rawString>William A. Cohen. 1995. Fast effective rule induction. In Proceedings of the Twelfth International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael John Collins</author>
</authors>
<title>A new statistical parser based on bigram lexical dependencies.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="24157" citStr="Collins, 1996" startWordPosition="3771" endWordPosition="3772">&apos;s tokens exhibited non-citation form accentuation. Finding the appropriate parameters by which to describe the prosody of individual speakers is an important goal that can be advanced by using machine learning techniques to explore large spaces of hypotheses. Second, it is evident from the strong performance of the word lemma sequence models that deviations from citation-form accentuation may often be expressed by lexicalized rules of some sort. Lexicalized rules in fact have proven useful in other areas of natural language statistical modeling, such as POS tagging (Brill, 1995) and parsing (Collins, 1996). The specific lexicalized rules learned for many of the models would not have followed from any theoretical or empirical proposals in the literature. It may be that domain dependent training using au944 tomatic learning is the appropriate way to develop practical models of accenting patterns on different corpora. And especially for different speakers in the same domain, automatic learning methods seem to be the only efficient way to capture perhaps idiolectical variation in accenting. Finally, it should be noted that notwithstanding individual speaker and domain dependent effects, domain inde</context>
</contexts>
<marker>Collins, 1996</marker>
<rawString>Michael John Collins. 1996. A new statistical parser based on bigram lexical dependencies. In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Grosz</author>
<author>Candace Sidner</author>
</authors>
<title>Attention, intentions, and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<pages>12--3</pages>
<contexts>
<context position="2010" citStr="Grosz and Sidner, 1986" startWordPosition="283" endWordPosition="286">ual variation is needed not only to fully model this fundamental prosodic feature for text-to-speech (TTS) synthesis systems, but also to further the integration of prosody into speech understanding and conceptto-speech (CTS) synthesis systems at the appropriate level of linguistic representation. This paper presents an empirically motivated theory of the discourse focusing function of accent. The theory describes for the first time the interacting contributions to accent prediction made by factors related to the local and global attentional status of discourse referents in a discourse model (Grosz and Sidner, 1986). The ability of the focusing features to predict accent for a blind test corpus is examined using machine learning. Because attentional status is a property of referring expressions, a novel approach to accent prediction is proposed to allow for the integration of word-based and constituent-based linguistic features in the models to be learned. The task of accent assignment is redefined as the prediction of patterns of deviation from citation form accentuation. Crucially, these deviations are captured at the constituent level. This task redefinition has two novel properties: (1) it bootstraps</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Barbara Grosz and Candace Sidner. 1986. Attention, intentions, and the structure of discourse. Computational Linguistics, 12(3):175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Aravind K Joshi</author>
<author>Scott Weinstein</author>
</authors>
<title>Centering: a framework for modelling the local coherence of discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="4621" citStr="Grosz et al., 1995" startWordPosition="678" endWordPosition="681">r&apos; s discourse modeling theory (1986). 939 Analysis of a 20-minute spontaneous story-telling monologue&apos; identified separate but interacting contributions of grammatical function, form of referring expression and accentuation2 in conveying the attentional status of a discourse referent. These interactions can be formally expressed in the framework of attentional modeling by the following principles of interpretation: • The LEXICAL FORM OF A REFERRING EXPRESSION indicates the level of attentional processing, i.e., pronouns involve local focusing while full lexical forms involve global focusing (Grosz et al., 1995). • The GRAMMATICAL FUNCTION of a referring expression reflects the local attentional status of the referent, i.e., subject position generally holds the highest ranking member of the forward-looking centers list (Cf list), while direct object holds the next highest ranking member of the Cf list (Grosz et al., 1995; Kameyama, 1985). • The ACCENTING of a referring expression serves as an inference cue to shift attention to a new backward-looking center (Cb), or to mark the global (re)introduction of a referent; LACK OF ACCENT serves as an inference cue to maintain attentional focus on the Cb, Cf</context>
<context position="14524" citStr="Grosz et al., 1995" startWordPosition="2233" endWordPosition="2236">NP type N Hi N H3 % % simple 447 72.0% 280 68.3% head 61 9.8% 46 11.2% child 74 11.9% 65 15.9% conjunct 39 6.3% 19 4.5% total 621 100% 410 100% Table 5: Distribution of baseNP types for all baseNPs. role for syntactic constituency information in determining accent, especially for noun phrase constituents. Empirical evidence for such a role, however, has been weak (Altenberg, 1987). 3.3.3 Local focusing features The local attentional status of baseNPs is represented by two features commonly used in centering theory to compute the Cb and the Cf list, GRAMMATICAL FUNCTION and FORM OF EXPRESSION (Grosz et al., 1995). Hand-labeled grammatical functions include subject, direct object, indirect object, predicate complement, adjunct. Form of expression feature values are ,adverbial noun, cardinal, definite NP demonstrative NP, indefinite NP, pronoun, proper name, quantifier NP verbal noun, etc. 3.3.4 Global focus feature The global focusing status of baseNPs is computed using two sets of analyses: discourse segmentations and coreference coding. Expert discourse structure analyses are used to derive CONSENSUS SEGMENTATIONS, consisting of discourse boundaries whose coding all three labelers agreed upon (Hirsch</context>
</contexts>
<marker>Grosz, Joshi, Weinstein, 1995</marker>
<rawString>Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein. 1995. Centering: a framework for modelling the local coherence of discourse. Computational Linguistics, 21(2), June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos Gussenhoven</author>
</authors>
<title>On the Grammar and Semantics of Sentence Accents.</title>
<date>1984</date>
<publisher>Foris Publications,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="13861" citStr="Gussenhoven, 1984" startWordPosition="2118" endWordPosition="2120">f baseNPs not dominated by any NP node is SIMPLE-BASENP. BaseNPs that occur in complex NPs (and are thus dominated by at least one NP node) are labeled according to whether the baseNP contains the head word for the dominating NP. Those that are dominated by only one NP node and contain the head word for the dominating NP are HEAD-BASENPS; all other NPs in a complex NP are CHILD-BASENPS. Conjoined noun phrases involve additional categories of baseNPs that are collapsed into the CONJUNCT-BASENP category. Table 5 gives the distributions of baseNP types. Focus projection theories of accent, e.g. (Gussenhoven, 1984; Selkirk, 1984), would predict a large baseNP type N Hi N H3 % % simple 447 72.0% 280 68.3% head 61 9.8% 46 11.2% child 74 11.9% 65 15.9% conjunct 39 6.3% 19 4.5% total 621 100% 410 100% Table 5: Distribution of baseNP types for all baseNPs. role for syntactic constituency information in determining accent, especially for noun phrase constituents. Empirical evidence for such a role, however, has been weak (Altenberg, 1987). 3.3.3 Local focusing features The local attentional status of baseNPs is represented by two features commonly used in centering theory to compute the Cb and the Cf list, G</context>
</contexts>
<marker>Gussenhoven, 1984</marker>
<rawString>Carlos Gussenhoven. 1984. On the Grammar and Semantics of Sentence Accents. Foris Publications, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hirschberg</author>
<author>Christine Nakatani</author>
</authors>
<title>A prosodic analysis of discourse segments in directiongiving monologues.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Annual Meeting of the ACL,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Santa Cruz.</location>
<contexts>
<context position="15148" citStr="Hirschberg and Nakatani, 1996" startWordPosition="2320" endWordPosition="2323"> 1995). Hand-labeled grammatical functions include subject, direct object, indirect object, predicate complement, adjunct. Form of expression feature values are ,adverbial noun, cardinal, definite NP demonstrative NP, indefinite NP, pronoun, proper name, quantifier NP verbal noun, etc. 3.3.4 Global focus feature The global focusing status of baseNPs is computed using two sets of analyses: discourse segmentations and coreference coding. Expert discourse structure analyses are used to derive CONSENSUS SEGMENTATIONS, consisting of discourse boundaries whose coding all three labelers agreed upon (Hirschberg and Nakatani, 1996). The consensus labels for segment-initial boundaries provide a linear segmentation of a discourse into discourse segments. Coreferential relations are coded by two labelers using DTT (Discourse Tagging Tool) (Aone and Bennett, 1995). To compute coreference chains, only the relation of strict coference is used. Two NPs, np 1 and np2, are in a strict coreference relationship, when np2 occurs after npl in the discourse and realizes the same discourse entity that is realized by np 1 . Reference chains are then automatically computed by linking noun phrases in strict coference relations into the l</context>
</contexts>
<marker>Hirschberg, Nakatani, 1996</marker>
<rawString>Julia Hirschberg and Christine Nakatani. 1996. A prosodic analysis of discourse segments in directiongiving monologues. In Proceedings of the 34th Annual Meeting of the ACL, Santa Cruz. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hirschberg</author>
</authors>
<title>Pitch accent in context: predicting intonational prominence from text.</title>
<date>1993</date>
<journal>Artificial Intelligence,</journal>
<pages>63--1</pages>
<contexts>
<context position="1181" citStr="Hirschberg, 1993" startWordPosition="163" endWordPosition="164">ation from citation form accentuation, defined at the constituent or noun phrase level, are automatically learned from an annotated corpus. Machine learning experiments on 1031 noun phrases from eighteen spontaneous direction-giving monologues show that accent assignment can be significantly improved by up to 4%-6% relative to a hypothetical baseline system that would produce only citation-form accentuation, giving error rate reductions of 11%-25%. 1 Introduction In speech synthesis systems, near-perfect (98%) accent assignment is automatically attainable for readaloud, citation-style speech (Hirschberg, 1993). But for unrestricted, extended spontaneous discourses, highly natural accentuation is often achieved only by costly human post-editing. A better understanding of the effects of discourse context on accentual variation is needed not only to fully model this fundamental prosodic feature for text-to-speech (TTS) synthesis systems, but also to further the integration of prosody into speech understanding and conceptto-speech (CTS) synthesis systems at the appropriate level of linguistic representation. This paper presents an empirically motivated theory of the discourse focusing function of accen</context>
<context position="3751" citStr="Hirschberg, 1993" startWordPosition="548" endWordPosition="549">tion-form accentuation, giving error rate reductions of 11%-25%. 2 Accent and attention Much theoretical work on intonational meaning has focused on the association of accent with NEW information, and lack of accent with GIVEN information, where given and new are defined with respect to whether or not the information is already represented in a discourse model. While this association reflects a general tendency (Brown, 1983), empirical studies on longer discourses have shown this simple dichotomy cannot explain important subclasses of expressions, such as accented pronouns, cf. (Terken, 1984; Hirschberg, 1993). We propose a new theory of the relationship between accent and attention, based on an enriched taxonomy of given/new information status provided by both the LOCAL (centering) and GLOBAL (focus stack model) attentional state models in Grosz and Sidner&apos; s discourse modeling theory (1986). 939 Analysis of a 20-minute spontaneous story-telling monologue&apos; identified separate but interacting contributions of grammatical function, form of referring expression and accentuation2 in conveying the attentional status of a discourse referent. These interactions can be formally expressed in the framework </context>
<context position="6361" citStr="Hirschberg, 1993" startWordPosition="952" endWordPosition="953">and special discourse situations (e.g. direct quotations) are also considered accounted for, then coverage increases to 96.5% (193/200). 3 Constituent-based experiments To test the generality of the proposed account of accent and attention, the ability of local and global focusing features to predict accent for a blind corpus is examined using machine learning. To rigorously assess the potential gains to be had from these attentional features, we consider them in combination with lexical and syntactic features identified in the literature as strong predictors of accentuation (Altenberg, 1987; Hirschberg, 1993; Ross et al., 1992). &apos;The narrative was collected by Virginia Merlini. 2Accented expressions are identified by the presence of PITCH ACCENT (Pierrehumbert, 1980). SUBJECT PRONOUNS (N=111) 25 prominent 23% 16 shift in Cb 6 contrast 3 emphasis 86 nonprominent 77% 75 continue or resume Cb 3 repair 2 dialogue tag 1 interruption from interviewer 5 unaccounted for DIRECT OBJECT PRONOUNS (N=15) 1 prominent 7% 1 contrast 14 nonprominent 93% 10 maintain non-Cb in Cf list 3 inter-sentential anaphora 1 repair SUBJECT EXPLICIT FORMS (N=54) 49 prominent 91% 44 introduce new global ref as Cp 2 quoted conte</context>
<context position="9912" citStr="Hirschberg, 1993" startWordPosition="1503" endWordPosition="1504">itation-based Accent Classification The accentuation of baseNPs is coded according to the relationship of the actual accenting (i.e. accented versus unaccented) on the words in the baseNP to the accenting predicted by a TI&apos;S system that received each sentence in the corpus in isolation. The actual accenting is determined by prosodic labeling using the ToBI standard (Pitrelli et al., 1994). Word accent predictions are produced by the Bell Laboratories NewTTS system (Sproat, 1997). NewTTS incorporates complex nominal accenting rules (Sproat, 1994) as well as general, word-based accenting rules (Hirschberg, 1993). It is assumed 3Ripper is similar to CART (Breiman et al., 1984), but it directly produces IF-THEN logic rules instead of decision trees and also utilizes incremental error reduction techniques in combination with novel rule optimization strategies. for the purposes of this study that NewTTS generally assigns citation-style accentuation when passed sentences in isolation. For each baseNP, one of the following four accenting patterns is assigned: • CITATION FORM: exact match between actual and TTS-assigned word accenting. • SUPRA: one or more accented words are predicted unaccented by TTS; oth</context>
</contexts>
<marker>Hirschberg, 1993</marker>
<rawString>Julia Hirschberg. 1993. Pitch accent in context: predicting intonational prominence from text. Artificial Intelligence, 63(1-2):305-340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kameyama</author>
</authors>
<title>Zero anaphora: the case in Japanese.</title>
<date>1985</date>
<tech>Ph.D. thesis,</tech>
<institution>Stanford University.</institution>
<contexts>
<context position="4953" citStr="Kameyama, 1985" startWordPosition="732" endWordPosition="733">he framework of attentional modeling by the following principles of interpretation: • The LEXICAL FORM OF A REFERRING EXPRESSION indicates the level of attentional processing, i.e., pronouns involve local focusing while full lexical forms involve global focusing (Grosz et al., 1995). • The GRAMMATICAL FUNCTION of a referring expression reflects the local attentional status of the referent, i.e., subject position generally holds the highest ranking member of the forward-looking centers list (Cf list), while direct object holds the next highest ranking member of the Cf list (Grosz et al., 1995; Kameyama, 1985). • The ACCENTING of a referring expression serves as an inference cue to shift attention to a new backward-looking center (Cb), or to mark the global (re)introduction of a referent; LACK OF ACCENT serves as an inference cue to maintain attentional focus on the Cb, Cf list members or global referents (Nakatani, 1997). The third principle concerning accent interpretation defines for the first time how accent serves uniformly to shift attention and lack of accent serves to maintain attention, at either the local or global level of discourse structure. This principle describing the discourse focu</context>
</contexts>
<marker>Kameyama, 1985</marker>
<rawString>M. Kameyama. 1985. Zero anaphora: the case in Japanese. Ph.D. thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diane J Litman</author>
</authors>
<title>Cue phrase classification using machine learning.</title>
<date>1996</date>
<journal>Journal of Artificial Intelligence,</journal>
<pages>53--94</pages>
<contexts>
<context position="17976" citStr="Litman (1996)" startWordPosition="2787" endWordPosition="2788">oad class sequence and form of expression information respectively. These results suggest that the abstract level of lexical description supplied by form of expression does the equivalent work of the lower-level lexical features. Thus, for CTS, accentuation class might be predicted when the more abstract form of expression information is known, and need not be 4Ripper experiments are conducted with 10-fold crossvalidation. Statistically significant differences in the performance of two systems are determined by using the Student&apos;s curve approximation to compute confidence intervals, following Litman (1996). Significant results at p &lt;.05 or stronger appear in italics. delayed until the tactical generation of the expression is completed. Conversely, for TTS, simple corpus analysis of lemma and POS sequences may perform as well as higher-level lexical analysis. 4.2 Combinations of classes of features Experiments on combinations of feature classes are reported in Table 7. The average classification rate Experiment H1 H3 Local/syntax 77.61 ± 1.39 60.98 ± 2.60 Local/lex 78.74 ± 1.48 63.17± 1.90 Local/lex/syntax 79.06± 1.53 61.95 ± 2.27 Local/global 78.11 ± 1.28 Loc/glob/lex/syn 79.22± 1.96 Baseline 7</context>
</contexts>
<marker>Litman, 1996</marker>
<rawString>Diane J. Litman. 1996. Cue phrase classification using machine learning. Journal of Artificial Intelligence, pages 53-94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christine H Nakatani</author>
<author>Barbara Grosz</author>
<author>Julia Hirschberg</author>
</authors>
<title>Discourse structure in spoken language: studies on speech corpora.</title>
<date>1995</date>
<journal>Artificial Intelligence.</journal>
<booktitle>In Proceedings of the AAAI Spring Symposium on Empirical Methods in Discourse Interpretation and Generation,</booktitle>
<publisher>American Association for</publisher>
<location>Palo Alto, CA,</location>
<contexts>
<context position="7769" citStr="Nakatani et al., 1995" startWordPosition="1170" endWordPosition="1173"> introduce new global referent 9 nonprominent 45% 7 maintain ref in global focus 2 quoted context Table 1: Coverage of narrative data. The discourse focusing functions of accent appear in italics. Previous studies, nonetheless, were aimed at predicting word accentuation, and so the features we borrow are being tested for the first time in learning the abstract accentuation patterns of syntactic constituents, specifically noun phrases (NPs). 3.1 Methods Accent prediction models are learned from a corpus of unrestricted, spontaneous direction-giving monologues from the Boston Directions Corpus (Nakatani et al., 1995). Eighteen spontaneous direction-giving monologues are analyzed from two American English speakers, H1 (male) and H3 (female). The monologues range from 43 to 631 words in length, and comprise 1031 referring expressions made up of 2020 words. Minimal, non-recursive 940 Accent class TTS-assigned accenting Actual accenting citation a LITTLE SHOPPING AREA a LITTLE SHOPPING AREA we we supra one ONE a PRETTY nice AMBIANCE a PRETTY NICE AMBIANCE reduced the GREEN LINE SUBWAY the GREEN Line SUBWAY YET ANOTHER RIGHT TURN yet ANOTHER RIGHT TURN shift a VERY FAST FIVE MINUTE lunch a VERY FAST FIVE minut</context>
</contexts>
<marker>Nakatani, Grosz, Hirschberg, 1995</marker>
<rawString>Christine H. Nakatani, Barbara Grosz, and Julia Hirschberg. 1995. Discourse structure in spoken language: studies on speech corpora. In Proceedings of the AAAI Spring Symposium on Empirical Methods in Discourse Interpretation and Generation, Palo Alto, CA, March. American Association for Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christine H Nakatani</author>
</authors>
<title>The Computational Processing of Intonational Prominence: a Functional Prosody Perspective.</title>
<date>1997</date>
<tech>Ph.D. thesis,</tech>
<institution>Harvard University,</institution>
<location>Cambridge, MA,</location>
<contexts>
<context position="5271" citStr="Nakatani, 1997" startWordPosition="787" endWordPosition="788">eferring expression reflects the local attentional status of the referent, i.e., subject position generally holds the highest ranking member of the forward-looking centers list (Cf list), while direct object holds the next highest ranking member of the Cf list (Grosz et al., 1995; Kameyama, 1985). • The ACCENTING of a referring expression serves as an inference cue to shift attention to a new backward-looking center (Cb), or to mark the global (re)introduction of a referent; LACK OF ACCENT serves as an inference cue to maintain attentional focus on the Cb, Cf list members or global referents (Nakatani, 1997). The third principle concerning accent interpretation defines for the first time how accent serves uniformly to shift attention and lack of accent serves to maintain attention, at either the local or global level of discourse structure. This principle describing the discourse focusing functions of accent directly explains 86.5% (173/200) of the referring expressions in the spontaneous narrative, as shown in Table 1. If performance factors (e.g. repairs, interruptions) and special discourse situations (e.g. direct quotations) are also considered accounted for, then coverage increases to 96.5% </context>
<context position="12738" citStr="Nakatani, 1997" startWordPosition="1942" endWordPosition="1943">nce for the NP, the Harvard Square T stop, is {the, Harvard, Square, T, stop}. The corresponding broad class sequence is {determiner, noun, noun, noun, noun}. Broad class tags are derived using Brill&apos; s (1995) part-of-speech tagger, and word lemma information is produced by NewTTS (Sproat, 1997). POS information is used to assign accenting in nearly all speech synthesis systems. Initial wordbased experiments on our corpus showed that broad class categories performed slightly better than both the function-content distinction and the POS tags themselves, giving 69%-81% correct word predictions (Nakatani, 1997). 3.3.2 Syntactic constituency features The CLAUSE TYPE feature represents global syntactic constituency information, while the BASENP TYPE feature represents local or NP-internal syntactic constituency information. Four clause types are coded: matrix, subordinate, predicate complement and relative. Each baseNP is semi-automatically assigned the clause type of the lowest level clause or nearest dominating clausal node in the parse tree, which contains the baseNP. As for baseNP types, the baseNP type of baseNPs not dominated by any NP node is SIMPLE-BASENP. BaseNPs that occur in complex NPs (an</context>
</contexts>
<marker>Nakatani, 1997</marker>
<rawString>Christine H. Nakatani. 1997. The Computational Processing of Intonational Prominence: a Functional Prosody Perspective. Ph.D. thesis, Harvard University, Cambridge, MA, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janet Pierrehumbert</author>
</authors>
<title>The Phonology and Phonetics of English Intonation.</title>
<date>1980</date>
<tech>Ph.D. thesis,</tech>
<institution>Massachusetts Institute of Technology, September. Distributed by the Indiana University Linguistics Club.</institution>
<contexts>
<context position="6523" citStr="Pierrehumbert, 1980" startWordPosition="975" endWordPosition="976">xperiments To test the generality of the proposed account of accent and attention, the ability of local and global focusing features to predict accent for a blind corpus is examined using machine learning. To rigorously assess the potential gains to be had from these attentional features, we consider them in combination with lexical and syntactic features identified in the literature as strong predictors of accentuation (Altenberg, 1987; Hirschberg, 1993; Ross et al., 1992). &apos;The narrative was collected by Virginia Merlini. 2Accented expressions are identified by the presence of PITCH ACCENT (Pierrehumbert, 1980). SUBJECT PRONOUNS (N=111) 25 prominent 23% 16 shift in Cb 6 contrast 3 emphasis 86 nonprominent 77% 75 continue or resume Cb 3 repair 2 dialogue tag 1 interruption from interviewer 5 unaccounted for DIRECT OBJECT PRONOUNS (N=15) 1 prominent 7% 1 contrast 14 nonprominent 93% 10 maintain non-Cb in Cf list 3 inter-sentential anaphora 1 repair SUBJECT EXPLICIT FORMS (N=54) 49 prominent 91% 44 introduce new global ref as Cp 2 quoted context 1 repair 2 unaccounted for 5 nonprominent 9% 2 top-level global focus 1 quoted context 1 repair 1 interruption from interviewer DIRECT OBJECT EXPLICIT FORMS (N</context>
</contexts>
<marker>Pierrehumbert, 1980</marker>
<rawString>Janet Pierrehumbert. 1980. The Phonology and Phonetics of English Intonation. Ph.D. thesis, Massachusetts Institute of Technology, September. Distributed by the Indiana University Linguistics Club.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Pitrelli</author>
<author>Mary Beckman</author>
<author>Julia Hirschberg</author>
</authors>
<title>Evaluation of prosodic transcription labeling reliability in the ToBI framework.</title>
<date>1994</date>
<booktitle>In Proceedings of the 3rd International Conference on Spoken Language Processing,</booktitle>
<volume>2</volume>
<pages>123--126</pages>
<location>Yokohama, Japan.</location>
<contexts>
<context position="9686" citStr="Pitrelli et al., 1994" startWordPosition="1471" endWordPosition="1474">e 2: Word and baseNP corpus measures. Ripper (Cohen, 1995), is used to acquire accent classification systems from a training corpus of correctly classified examples, each defined by a vector of feature values, or predictors.3 3.2 Citation-based Accent Classification The accentuation of baseNPs is coded according to the relationship of the actual accenting (i.e. accented versus unaccented) on the words in the baseNP to the accenting predicted by a TI&apos;S system that received each sentence in the corpus in isolation. The actual accenting is determined by prosodic labeling using the ToBI standard (Pitrelli et al., 1994). Word accent predictions are produced by the Bell Laboratories NewTTS system (Sproat, 1997). NewTTS incorporates complex nominal accenting rules (Sproat, 1994) as well as general, word-based accenting rules (Hirschberg, 1993). It is assumed 3Ripper is similar to CART (Breiman et al., 1984), but it directly produces IF-THEN logic rules instead of decision trees and also utilizes incremental error reduction techniques in combination with novel rule optimization strategies. for the purposes of this study that NewTTS generally assigns citation-style accentuation when passed sentences in isolation</context>
</contexts>
<marker>Pitrelli, Beckman, Hirschberg, 1994</marker>
<rawString>John Pitrelli, Mary Beckman, and Julia Hirschberg. 1994. Evaluation of prosodic transcription labeling reliability in the ToBI framework. In Proceedings of the 3rd International Conference on Spoken Language Processing, volume 2, pages 123-126, Yokohama, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Ross</author>
<author>M Ostendorf</author>
<author>S Shattuck-Hufnagel</author>
</authors>
<title>Factors affecting pitch accent placement.</title>
<date>1992</date>
<booktitle>In Proceedings of the 2nd International Conference on Spoken Language Processing,</booktitle>
<pages>365--368</pages>
<location>Banff, Canada,</location>
<contexts>
<context position="6381" citStr="Ross et al., 1992" startWordPosition="954" endWordPosition="957">rse situations (e.g. direct quotations) are also considered accounted for, then coverage increases to 96.5% (193/200). 3 Constituent-based experiments To test the generality of the proposed account of accent and attention, the ability of local and global focusing features to predict accent for a blind corpus is examined using machine learning. To rigorously assess the potential gains to be had from these attentional features, we consider them in combination with lexical and syntactic features identified in the literature as strong predictors of accentuation (Altenberg, 1987; Hirschberg, 1993; Ross et al., 1992). &apos;The narrative was collected by Virginia Merlini. 2Accented expressions are identified by the presence of PITCH ACCENT (Pierrehumbert, 1980). SUBJECT PRONOUNS (N=111) 25 prominent 23% 16 shift in Cb 6 contrast 3 emphasis 86 nonprominent 77% 75 continue or resume Cb 3 repair 2 dialogue tag 1 interruption from interviewer 5 unaccounted for DIRECT OBJECT PRONOUNS (N=15) 1 prominent 7% 1 contrast 14 nonprominent 93% 10 maintain non-Cb in Cf list 3 inter-sentential anaphora 1 repair SUBJECT EXPLICIT FORMS (N=54) 49 prominent 91% 44 introduce new global ref as Cp 2 quoted context 1 repair 2 unacco</context>
</contexts>
<marker>Ross, Ostendorf, Shattuck-Hufnagel, 1992</marker>
<rawString>K. Ross, M. Ostendorf, and S. Shattuck-Hufnagel. 1992. Factors affecting pitch accent placement. In Proceedings of the 2nd International Conference on Spoken Language Processing, pages 365-368, Banff, Canada, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Selkirk</author>
</authors>
<title>Phonology and Syntax.</title>
<date>1984</date>
<publisher>MIT Press,</publisher>
<location>Cambridge MA.</location>
<contexts>
<context position="13877" citStr="Selkirk, 1984" startWordPosition="2121" endWordPosition="2122">ated by any NP node is SIMPLE-BASENP. BaseNPs that occur in complex NPs (and are thus dominated by at least one NP node) are labeled according to whether the baseNP contains the head word for the dominating NP. Those that are dominated by only one NP node and contain the head word for the dominating NP are HEAD-BASENPS; all other NPs in a complex NP are CHILD-BASENPS. Conjoined noun phrases involve additional categories of baseNPs that are collapsed into the CONJUNCT-BASENP category. Table 5 gives the distributions of baseNP types. Focus projection theories of accent, e.g. (Gussenhoven, 1984; Selkirk, 1984), would predict a large baseNP type N Hi N H3 % % simple 447 72.0% 280 68.3% head 61 9.8% 46 11.2% child 74 11.9% 65 15.9% conjunct 39 6.3% 19 4.5% total 621 100% 410 100% Table 5: Distribution of baseNP types for all baseNPs. role for syntactic constituency information in determining accent, especially for noun phrase constituents. Empirical evidence for such a role, however, has been weak (Altenberg, 1987). 3.3.3 Local focusing features The local attentional status of baseNPs is represented by two features commonly used in centering theory to compute the Cb and the Cf list, GRAMMATICAL FUNCT</context>
</contexts>
<marker>Selkirk, 1984</marker>
<rawString>E. Selkirk. 1984. Phonology and Syntax. MIT Press, Cambridge MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Sproat</author>
</authors>
<title>English noun-phrase accent prediction for text-to-speech.</title>
<date>1994</date>
<journal>Computer Speech and Language,</journal>
<pages>8--79</pages>
<contexts>
<context position="9846" citStr="Sproat, 1994" startWordPosition="1494" endWordPosition="1495">h defined by a vector of feature values, or predictors.3 3.2 Citation-based Accent Classification The accentuation of baseNPs is coded according to the relationship of the actual accenting (i.e. accented versus unaccented) on the words in the baseNP to the accenting predicted by a TI&apos;S system that received each sentence in the corpus in isolation. The actual accenting is determined by prosodic labeling using the ToBI standard (Pitrelli et al., 1994). Word accent predictions are produced by the Bell Laboratories NewTTS system (Sproat, 1997). NewTTS incorporates complex nominal accenting rules (Sproat, 1994) as well as general, word-based accenting rules (Hirschberg, 1993). It is assumed 3Ripper is similar to CART (Breiman et al., 1984), but it directly produces IF-THEN logic rules instead of decision trees and also utilizes incremental error reduction techniques in combination with novel rule optimization strategies. for the purposes of this study that NewTTS generally assigns citation-style accentuation when passed sentences in isolation. For each baseNP, one of the following four accenting patterns is assigned: • CITATION FORM: exact match between actual and TTS-assigned word accenting. • SUPR</context>
</contexts>
<marker>Sproat, 1994</marker>
<rawString>Richard Sproat. 1994. English noun-phrase accent prediction for text-to-speech. Computer Speech and Language, 8:79-94.</rawString>
</citation>
<citation valid="true">
<title>Multilingual Text-toSpeech Synthesis: The Bell Labs Approach.</title>
<date>1997</date>
<editor>Richard Sproat, editor.</editor>
<publisher>Kluwer Academic,</publisher>
<location>Boston.</location>
<marker>1997</marker>
<rawString>Richard Sproat, editor. 1997. Multilingual Text-toSpeech Synthesis: The Bell Labs Approach. Kluwer Academic, Boston.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Terken</author>
</authors>
<title>The distribution of pitch accents in instructions as a function of discourse structure. Language and Speech,</title>
<date>1984</date>
<pages>27--269</pages>
<contexts>
<context position="3732" citStr="Terken, 1984" startWordPosition="546" endWordPosition="547">duce only citation-form accentuation, giving error rate reductions of 11%-25%. 2 Accent and attention Much theoretical work on intonational meaning has focused on the association of accent with NEW information, and lack of accent with GIVEN information, where given and new are defined with respect to whether or not the information is already represented in a discourse model. While this association reflects a general tendency (Brown, 1983), empirical studies on longer discourses have shown this simple dichotomy cannot explain important subclasses of expressions, such as accented pronouns, cf. (Terken, 1984; Hirschberg, 1993). We propose a new theory of the relationship between accent and attention, based on an enriched taxonomy of given/new information status provided by both the LOCAL (centering) and GLOBAL (focus stack model) attentional state models in Grosz and Sidner&apos; s discourse modeling theory (1986). 939 Analysis of a 20-minute spontaneous story-telling monologue&apos; identified separate but interacting contributions of grammatical function, form of referring expression and accentuation2 in conveying the attentional status of a discourse referent. These interactions can be formally expresse</context>
</contexts>
<marker>Terken, 1984</marker>
<rawString>J. Terken. 1984. The distribution of pitch accents in instructions as a function of discourse structure. Language and Speech, 27:269-289.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>