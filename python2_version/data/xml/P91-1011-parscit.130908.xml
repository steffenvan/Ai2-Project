<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<sectionHeader confidence="0.819566" genericHeader="abstract">
EFFICIENT INCREMENTAL PROCESSING WITH CATEGORIAL GRAMMAR
</sectionHeader>
<author confidence="0.977657">
Mark Hepple
</author>
<affiliation confidence="0.997423">
University of Cambridge Computer Laboratory,
</affiliation>
<address confidence="0.718053">
New Museums Site, Pembroke St, Cambridge, UK.
</address>
<email confidence="0.935087">
e-mail: mrhuk.ac.cam.c1
</email>
<sectionHeader confidence="0.992387" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.9977475">
Some problems are discussed that arise for incremental pro-
cessing using certain flexible categorial grammars, which in-
volve either undesirable parsing properties or failure to allow
combinations useful to incrementality. We suggest a new cal-
culus which, though &apos;designed&apos; in relation to categorial inter-
pretations of some notions of dependency grammar, seems to
provide a degree of flexibility that is highly appropriate for in-
cremental interpretation. We demonstrate how this grammar
may be used for efficient incremental parsing, by employing
normalisation techniques.
</bodyText>
<sectionHeader confidence="0.976319" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.999942466666667">
A range of categorial grammars (CGs) have been
proposed which allow considerable flexibility in the
assignment of syntactic structure, a characteristic
which provides for categorial treatments of extrac-
tion (Ades 8.6 Steedman, 1982) and non-constituent
coordination (Steedman, 1985; Dowty, 1988), and
that is claimed to allow for incremental processing
of natural language (Steedman, 1989). It is this lat-
ter possibility that is the focus of this paper.
Such &apos;flexible&apos; CGs (FCGs) typically allow that
grammatical sentences may be given (amongst oth-
ers) analyses which are either fully or primarily left-
branching. These analyses have the property of des-
ignating many of the initial substrings of sentences
as interpretable constituents, providing for a style of
processing in which the interpretation of a sentence
is generated &apos;on-line&apos; as the sentence is presented.
It has been argued that incremental interpretation
may provide for efficient language processing — by
both humans and machines — in allowing early fil-
tering of thematically or referentially implausible
readings. The view that human sentence processing
is &apos;incremental&apos; is supported by both introspective
and experimental evidence.
In this paper, we discuss FCG approaches and
some problems that arise for using them as a ba-
sis for incremental processing. Then, we propose a
grammar that avoids these problems, and demon-
strate how it may be used for efficient incremental
processing.
</bodyText>
<subsectionHeader confidence="0.777202">
Flexible Categorial Grammars
</subsectionHeader>
<bodyText confidence="0.999910222222222">
CGs consist of two components: (i) a categorial lex-
icon, which assigns to each word at least one syn-
tactic type (plus associated meaning), (ii) a calculus
which determines the set of admitted type combina-
tions and transitions. The set of types (T) is defined
recursively in terms of a set of basic types (To) and
a set of operators ( \ and /, for standard bidirectional
CG), as the smallest set such that (i) To C T, (ii)
if x,y E T, then x\y, x/y E T.1 Intuitively, lexi-
cal types specify subcategorisation requirements of
words, and requirements on constituent order. The
most basic (non-flexible) CGs provide only rules of
application for combining types, shown in (1). We
adopt a scheme for specifying the semantics of com-
bination rules where the rule name identifies a func-
tion that applies to the meanings of the input types
in their left-to-right order to give the meaning of
the result expression.
</bodyText>
<equation confidence="0.636143">
(1) f: X/Y + Y X (where f= )aAb.(ab))
b: Y+ X\Y = X (where b = AaAb.(ba))
</equation>
<subsectionHeader confidence="0.726327">
The Lambek calculus
</subsectionHeader>
<bodyText confidence="0.982055826086956">
We begin by briefly considering the (product-free)
Lambek calculus (LC - Lambek, 1958). Various for-
mulations of the LC are possible (although we shall
not present one here due to space limitations).2
The LC is complete with respect to an intuitively
sensible interpretation of the slash connectives whereby
the type x/y (resp. x \y) may be assigned to any
string z which when left-concatenated (resp. right-
concatenated) with any string y of type y yields
a string x.y (resp. y.x) of type x. The LC can
be seen to provide the limit for what are possible
1We use a categorial notation in which x/y and x \y are
both functions from y into x, and adopt a convention of
left association, so that, e.g. ((s \np)/pp)/np may be writ-
ten s \npippinp.
2See Lambek (1958) and Moortgat (1989) for a sequent
formulation of the LC. See Morrill, Leslie, Hepple &amp; Barry
(1990), and Barry, Hepple, Leslie &amp; Morrill (1991) for a natu-
ral deduction formulation. Zielonlca (1981) provides a LC for-
mulation in terms of (recursively defined) reduction schema.
Various extensions of the LC are currently under investiga-
tion, although we shall not have space to discuss them here.
See Hepple (1990), Morrill (1990) and Moortgat (1990b).
</bodyText>
<page confidence="0.997207">
79
</page>
<bodyText confidence="0.998944">
type combinations — the other calculi which we
consider admit only a subset of the Lambek type
combinations.&apos;
The flexibility of the LC is such that, for any com-
bination xi ,..,xn xo, a fully left-branching deriva-
tion is always possible (i.e. combining xi and x2,
then combining the result with x3, and so on). How-
ever, the properties of the LC make it useless for
practical incremental processing. Under the LC,
there is always an infinite number of result types
for any combination, and we can only in practice ad-
dress the possibility of combining some types to give
a known result type. Even if we were to allow only
S as the overall result of a parse, this would not tell
us the intermediate target types for binary combi-
nations made in incrementally accepting a sentence,
so that such an analysis cannot in practice be made.
</bodyText>
<subsectionHeader confidence="0.728899">
Combinatory Categorial Grammar
</subsectionHeader>
<bodyText confidence="0.970109875">
Combinatory Categorial Grammars (CCGs – Steed-
man, 1987; Szabolcsi, 1987) are formulated by adding
a number of type combination and transition schemes
to the basic rules of application. We can formulate a
simple version of CCG with the rules of type raising
and composition shown in (2). This CCG allows
the combinations (3a,b), as shown by the proofs
(4a,b).
</bodyText>
<listItem confidence="0.828989">
(2) T: x y/(y \ x) (where T = )txAf.(fx))
B: x/y y/z x/z
(where B = AfAgAx.f(gx))
(3) a. np:x, s\ np/np:f s/np:Ay.fyx
b. vp/s:f, np:x vp/(s\np):Ag.f(gx)
(4) (a) np T s\np/np (b) vp/s np
</listItem>
<equation confidence="0.9790305">
s/(s\np) s/(s\np)
s/np vp/(rAnp)
</equation>
<bodyText confidence="0.9999654">
The derived rule (3a) allows a subject NP to com-
bine with a transitive verb before the verb has com-
bined with its object. In (3b), a sentence em-
bedding verb is composed with a raised subject NP.
Note that it is not clear for this latter case that the
combination would usefully contribute to incremen-
tal processing, i.e. in the resulting semantic expres-
sion, the meanings of the types combined are not di-
rectly related to each other, but rather a hypothet-
ical function mediates between the two. Hence, any
</bodyText>
<footnote confidence="0.9108125">
3In some frameworks, the use of non-Lambek-valid rules
such as disharmonic composition (e.g. x/y y\z x\z)
has been suggested. We shall not consider such rules in this
paper.
</footnote>
<bodyText confidence="0.99061074">
requirements that the verb may have on the seman-
tic properties of its argument (i.e. the clause) could
not be exploited at this stage to rule out the re-
sulting expression as semantically implausible. We
define as contentful only those combinations which
directly relate the meanings of the expressions com-
bined, without depending on the mediation of hy-
pothetical functions.
Note that this calculus (like other versions of CCG)
fails to admit some combinations, which are allowed
by the LC, that are contentful in this sense — for
example, (5). Note that although the seman-
tics for the result expression in (5) is complex,
the meanings of the two types combined are still di-
rectly related — the lambda abstractions effectively
just fulfil the role of swapping the argument order
of the subordinate functor.
(5) x/(y\z):f, ylw\z:g x/w:Av.f(Aw.gwv)
Other problems arise for using CCG as a basis
for incremental processing. Firstly, the free use of
type-raising rules presents problems, i.e. since the
rule can always apply to its own output. In practice,
however, CCG grammars typically use type specific
raising rules (e.g. np s/(s\np)), thereby avoiding
this problem. Note that this restriction on type-
raising also excludes various possibilities for flexible
combination (e.g. so that not all combinations of the
form y, x \y/z x/z are allowed, as would be the
case with unrestricted type-raising).
Some problems for efficient processing of CCGs
arise from what has been termed &apos;spurious ambigu-
ity&apos; or &apos;derivational equivalence&apos;, i.e. the existence
of multiple distinct proofs which assign the same
reading for some combination of types. For exam-
ple, the proofs (6a,b) assign the same reading for
the combination. Since search for proofs must be
exhaustive to ensure that all distinct readings for a
combination are found, effort will be wasted con-
structing proofs which eiigit the same meaning,
considerably reducing the efficiency of processing.
Hepple Az Morrill (1989) suggest a solution to this
problem that involves specifying a notion of nor-
mal form (NF) for CCG proofs, and ensuring that
the parser returns only NF proofs.4 However, their
method has a number of limitations. (i) They con-
sidered a &apos;toy grammar&apos; involving only the CCG
rules stated above. For a grammar involving fur-
ther combination rules, normalisation would need
to be completely reworked, and it remains to be
shown that this task can be successfully done. (ii)
</bodyText>
<footnote confidence="0.996566333333333">
4Norrnalisation has also been suggested to deal with the
problem of spurious ambiguity as it arises for the LC. See
Honig (1989), Hepple (1990) and Moortgat (1990).
</footnote>
<page confidence="0.998677">
80
</page>
<bodyText confidence="0.997678">
The NF proofs of this system are right-branching
— again, it remains to be shown that a NF can be
defined which favours left-branching (or even pri-
marily left-branching) proofs.
</bodyText>
<equation confidence="0.700895">
z/Y YizB z
x/z
--f
</equation>
<subsectionHeader confidence="0.791004">
Meta-Categorial Grammar
</subsectionHeader>
<bodyText confidence="0.999213857142857">
In Meta-Categorial Grammar (MCG – Morrill, 1988)
combination rules are recursively defined from the
application rules (f and b) using the metarules (7)
and (8). The metarules state that given a rule
of the form shown to the left of with name 0,
a further rule is allowed of the form shown to the
right, with name given by applying R or L to 0 as
indicated. For example, applying ft to backward
application gives the rule (9), which allows com-
bination of subject and transitive verb, as T and
B do for CCG. Note, however, that this calculus
does not allow any `non-contentfur combinations
— all rules are recursively defined on the applica-
tion rules which require a proper functional relation
between the types combined. However, this calcu-
lus also fails to allow some contentful combinations,
such as the case x/(y \z), y/w x/w mentioned
above in (5). Like CCG, MCG suffers from spurious
ambiguity, although this problem can be dealt with
via normalisation (Morrill, 1988; Hepple &amp; Morrill,
1989).
</bodyText>
<listItem confidence="0.9988508">
(7) RO: x + y/w z/w
(where R = AgAaAbAc.ga(bc))
(8) x y z = LO: x\w y z\w
(where L = AgAaAbAc.g(ac)b)
(9) Rb: y + x\y/z = x/z
</listItem>
<subsectionHeader confidence="0.95049">
The Dependency Calculus
</subsectionHeader>
<bodyText confidence="0.994071208955224">
In this section, we will suggest a new calculus which,
we will argue, is well suited to the task of incremen-
tal processing. We begin, however, with some dis-
cussion of the notions of head and dependent, and
their relevance to CG.
The dependency grammar (DG) tradition takes
as fundamental the notions of head, dependent and
the head-dependent relationship; where a head is,
loosely, an element on which other elements depend.
An analogy is often drawn between CG and DG
based on equating categorial functors with heads,
whereby a functor x/yi../yn (ignoring directional-
ity, for the moment) is taken to correspond to a head
requiring dependents yi..yn, although there are sev-
eral obvious differences between the two approaches.
Firstly, a categorial functor specifies an ordering
over its &apos;dependents&apos; (function-argument order, that
is, rather than constituent order) where no such or-
dering is identified by a DG head. Secondly, the
arguments of a categorial functor are necessarily
phrasal, whereas by the standard view in DG, the
dependents of a head are taken to be words (which
may themselves be heads of other head/dependent
complexes). Thirdly, categorial functors may spec-
ify arguments which have complex types, which, by
the analogy, might be described as a head being able
to make stipulations about the dependency require-
ments of its dependent and also to &apos;absorb&apos; those
dependency requirements.5 For example, a type
x/(y \z) seeks an argument which is a &amp;quot;y needing a
dependent z&amp;quot; under the head/functor analogy. On
combining with such a type, the requirement &amp;quot;need
a dependent z&amp;quot; is gone. Contrast this with the use
of, say, composition (i.e. x/y, y/z x/z), where a
type x/y simply needs a dependent y, and where
composition allows the functor to combine with its
dependent y while the latter still requires a depen-
dent z, and where that requirement is inherited onto
the result of the combination and can be satisfied
later on.
Barry &amp; Pickering (B&amp;P, 1990) explore the view
of dependency that arises in CG when the functor-
argument relationship is taken as analogous to the
traditional head-dependent relationship. A problem
arises in employing this analogy with FCGs, since
FCGs permit certain type transformations that un-
dermine the head-dependent relations that are im-
plicit in lexical type assignments. An obvious exam-
ple is the type-raising transformation x y/(y \x),
which directly reverses the direction of the head-
dependent relationship between a functor and its
argument. B&amp;P identify a subset of LC combina-
tions as dependency preserving (DP), i.e. those com-
binations which preserve the head-dependent rela-
tions implicit in the types combined, and call con-
stituents which have DP analyses dependency con-
stituents. B&amp;P argue for the significance of this
notion of constituency in relation to the treatment
of coordination and the comparative difficulty ob-
served for (human) processing of nested and non-
5 Clearly, a CO where argument types were required to be
basic would be a closer analogue of DG in not allowing a
&apos;head&apos; to make such stipulations about its dependents. Such
a system could be enforced by adopting a more restricted
definition of the set of types (T) as the smallest set such that
(i) To C T, (ii) if x E Tandy E To, then x\y, x/y E T (c.f.
the definition given earlier).
</bodyText>
<figure confidence="0.45044">
(6) to x/y y/z z (b)
X
</figure>
<page confidence="0.985942">
81
</page>
<bodyText confidence="0.9987835">
nested constructions.&apos; B&amp;P suggest a means for
identifying the DP subset of LC transformations
and combinations in terms of the lambda expres-
sions that assign their semantics. Specifically, a
combination is DP if the lambda expression speci-
fying its semantics does not involve abstraction over
a variable that fulfils the role of functor within the
expression (c.f. the semantics of type raising in (2)).7
We will adopt a different approach to B&amp;P for
addressing dependency constituency, which involves
specifying a calculus that allows all and only the DP
combinations (as opposed to a criterion identifying
a subset of LC combinations as DP). Consider again
the combination x/(y \z), y/w \z x/w, not admit-
ted by either the CCG or MCG stated above. This
combination would be admitted by the MCG (and
also the CCG) if we added the following (Lambek-
valid) associativity axioms, as illustrated in (11).
</bodyText>
<listItem confidence="0.647531">
(10) a: x\y/z = x/z\y
</listItem>
<figure confidence="0.892899428571429">
a: x/y\z x\z/y
(where a = )tfAaAb.fba)
(11) x/(y\z) y/w\z
a
y\z/w
RI
x/w
</figure>
<bodyText confidence="0.989474724137931">
We take it as self-evident that the unary trans-
formations specified by these two axioms are DP,
since function-argument order is a notion extrane-
ous to dependency; the functors x\y/z and x/z\y
have the same dependency requirements, i.e. depen-
dents y and z.8 For the same reason, such reordering
of arguments should also be possible for functions
that occur as subtypes within larger types, as in
(12a,b). The operation of the associativity rules
can be &apos;generalised&apos; in this fashion by including the
unary metarules (13),8 which recursively define
6See Barry (forthcoming) for extensive discussion of de-
pendency and CG, and Pickering (1991) for the relevance of
dependency to human sentence processing.
7B&amp;P suggest a second criterion in terms of the form of
proofs which, for the natural deduction formulation of the
LC that B&amp;P use, is equivalent to the criterion in terms
of lambda expressions (given that a variant of the Curry-
Howard correspondence between implicational deductions
and lambda expressions obtains).
8 Clearly, the reversal of two co-directional arguments (i.e.
x/y/z x/z/y) would also be DP for this reason, but is not
LC-valid (since it would not preserve linear order require-
ments). For a unidirectional CG system (i.e. a system with a
single connective /, that did not specify linear order require-
ments), free reversal of arguments would be appropriate. We
suggest that a unidirectional variant of the calculus to be
proposed might be the best system for pure reasoning about
&apos;categorial dependency&apos;, aside from linearity considerations.
</bodyText>
<listItem confidence="0.938738666666667">
9 These unary metarules have been used elsewhere as part
of the LC formulation of Zielonka (1981).
new unary rules from the associatt■ Lk axioms.
(12) a. a\b/c/d a/c\b/d
b. x/(a\b/c) x/(a/c\b)
(13) a. 41: x = y VO: x/z = y/z
</listItem>
<equation confidence="0.985552166666667">
x = y VO: x\z = y\z
(where V = )tfAciAb.f(ab))
b. irk: x y ZO: z/y z/x
41: x y = ZO: z\y z\x
(where Z = AfAci)tb.a(fb))
(14) x/(a\b/c):f x/(a/c\b):Av.f()taA b. vba)
</equation>
<bodyText confidence="0.99994285">
Clearly, the rules {V,Z,a} allow only DP unary
transformations. However, we make the stronger
claim that these rules specify the limit of DP unary
transformations. The rules allow that the given
functional structure of a type be &apos;shuffled&apos; upto the
limit of preserving linear order requirements. But
the only alternative to such &apos;shuffling&apos; would seem
to be that some of the given type structure be re-
moved or further type structure be added, which, by
the assumption that functional structure expresses
dependency relations, cannot be DP.
We propose the system {L,R,V,Z,a,f,b} as a cal-
culus allowing all and only the DP combinations and
transformations of types, with a &apos;division of labour&apos;
as follows: (i) the rules f and b, allowing the estab-
lishment of direct head-dependent relations, (ii) the
subsystem {V,Z,a}, allowing DP transformation of
types upto the limit of preserving linear order, and
(iii) the rules R and L, which provide for the inher-
itance of &apos;dependency requirements&apos; onto the result
of a combination. We call this calculus the depen-
dency calculus (DC) (of which we identify two sub-
systems: (i) the binary calculus B = {L,R,f,b}, (ii)
the unary calculus U = {V,Z,a}). Note that B&amp;P&apos;s
criterion and the DC do not agree on what are DP
combinations in all cases. For example, the seman-
tics for the type transformation in (14) involves ab-
straction over a variable that occurs as a functor.
Hence this transformation is not DP under B&amp;P&apos;s
criterion, although it is admitted by the DC. We
believe that the DC is correct in admitting this and
the other additional combinations that it allows.
There is clearly a close relation between DP type
combination and the notion of contentful combi-
nation discussed earlier. The &apos;dependency require-
ments&apos; stated by any lexical type will constitute the
sum of the &apos;thematically contentful&apos; relationships
into which it may enter. In allowing all DP com-
binations (subject to the limit of preserving linear
order requirements), the DC ensures that lexically
</bodyText>
<page confidence="0.997061">
82
</page>
<bodyText confidence="0.98367966">
originating dependency structure is both preserved
and also exploited in full. Consequently, the DC is
well suited to incremental processing. Note, how-
ever, that there is some extent of divergence be-
tween the DC and the (admittedly vague) criterion
of `contentful&apos; combination defined earlier. Con-
sider the LC-valid combination in (15), which is
not admitted by the DC. This combination would
appear to be `contentful&apos; since no hypothetical se-
mantic functor intervenes between land g (although
g has undergone a change in its relationship to its
own argument which depends on such a hypothet-
ical functor). However, we do not expect that the
exclusion of such combinations will substract signif-
icantly from genuinely useful incrementality in pars-
ing actual grammars.
(15) xl(y1z):f, yl(w\(wlz)):g = x:f(Av.g(Ah.hv))
Parsing and the Dependency Calculus
Binary combinations allowed by the DC are all of
the form (16) (where the vertical dots abbrevi-
ate unary transformations, and (f) is some binary
rule). The obvious naive approach to finding possi-
ble combinations of two types x and y under the DC
involves searching through the possible unary trans-
forms of x and y, then trying each possible pairing
of them with the binary rules of B, and then deriv-
ing the set of unary transforms for the result of any
successful combination.
At first sight, the efficiency of processing using
this calculus seems to be in doubt. Firstly, the
search space to be addressed in checking for possible
combinations of two types is considerably greater
than for CCG or MCG. Also, the DC will suffer spu-
rious ambiguity in a fashion directly comparable to
CCG and MCG (obviously, for the latter case, since
the above MCG is a subsystem of the DC). For ex-
ample, the combination x/y, y/z, z = x has both
left and right branching derivations.
However, a further equivalence problem arises due
to the interderivability of types under the unary
subsystem U. For any unary transformation x = y,
the converse y x is always possible, and the se-
mantics of these transformations are always inverses.
(This obviously holds for a, and can be shown to
hold for more complex transformations by a simple
induction.) Consequently, if parsing assigns distinct
types x and y to some substring that are merely
variants under the unary calculus, this will engen-
der redundancy, since anything that can be proven
with x can equivalently be proven with y.
</bodyText>
<equation confidence="0.979523">
(16) x y
x&apos; y&apos;
</equation>
<bodyText confidence="0.987668565217391">
Normalisation and the Dependency Calculus
These efficiency problems for parsing with the DC
can be seen to result from equivalence amongst terms
occurring at a number of levels within the system.
Our solution to this problem involves specifying nor-
mal forms (NFs) for terms — to act as privileged
members of their equivalence class — at three differ-
ent levels of the system: (i) types, (ii) binary com-
binations, (iii) proofs. The resulting system allows
for efficient categorial parsing which is incremental
up to the limit allowed by the DC.
A standard way of specifying NFs is based on
the method of reduction, and involves defining a
contraction relation (N1) between terms, which is
stated as a number of contraction rules of the form
X Di Y (where X is termed a redez and Y its con-
tractum). Each contraction rule allows that a term
containing a redex may be transformed into a term
where that occurrence is replaced by its contractum.
A term is said to be in NF if and only if it contains
no redexes. The contraction relation generates a re-
duction relation (N) such that X reduces to Y (X 1&gt;
Y) if Y is obtained from X by a finite series (pos-
sibly zero) of contractions. A term Y is a NF of X
if Y is a NF and X D Y. The contraction relation
also generates an equivalence relation which is such
that X = Y if Y can be obtained from X by a se-
quence of zero or more steps, each of which is either
a contraction or reverse contraction.
Interderivability of types under U can be seen as
giving a notion of equivalence for types. The con-
traction rule (17) defines a NF for types. Since
contraction rules apply to any redex subformula oc-
curring within some overall term, this rule&apos;s do-
main of application is as broad as that of the as-
sociativity axioms in the unary calculus given the
generalising effects of the unary metarules. Hence,
the notion of equivalence generated by rule (16) is
the same as that defined by interderivability un-
der U. It is straightforward to show that the reduc-
tion relation defined by (16) exhibits two impor-
tant properties: (i) strong normalisationl° , with the
&amp;quot;To prove strong normalisation it is sufficient to give a
metric which assigns each term a finite non-negative integer
score, and under which every contraction reduces the score
for a term by a positive integer amount. The following metric
</bodyText>
<listItem confidence="0.7676535">
suffices: (a) X&apos; = 1 if X is atomic, (b) (X/Y)&apos; = X&apos; -I- Y&apos;,
(c) (X \ Y)&apos; = 2(X&amp;quot;
</listItem>
<page confidence="0.997954">
83
</page>
<bodyText confidence="0.999551">
consequence that every type has a NF, and (ii) the
Church-Rosser property, from which it follows that
NFs are unique. In (18), a constructive notion
of NF is specified. It is easily shown that this con-
structive definition identifies the same types to be
NFs as the reductive definition.&amp;quot;
</bodyText>
<equation confidence="0.819601">
(17) x/y\z x\z/y
(18) x\yi...Yi/Yi+1..Yn
where n &gt; 0, x is a basic type and each yi
(1 &lt; j &lt; n) is in turn of this general form.
(19) 0: x/ui..un + y = z
L(n)0: x\w/ui..un + y z\w
(where L(n) = )tgAaAbAc.g(Avi..vn.avi..vnc)b)
</equation>
<bodyText confidence="0.9996983">
We next consider normalisation for binary com-
binations. For this purpose, we require a modified
version of the binary calculus, called B&apos;, having the
rules {L(n),R,f,13}), where L(n) is a &apos;generalised&apos;
variant of the metarule L, shown in (19) (where the
notation x/ui..un is schematic for a function seek-
ing n forward directional arguments, e.g. so that for
n = 3 we have x/ui..un = x/ui/u2/u3). Note that
the case L(0) is equivalent to L.
We will show that for every binary combination
</bodyText>
<equation confidence="0.7231505">
X + Y Z under the DC, there is a correspond-
ing combination X&apos; + Y&apos; Z&apos; under B&apos;, where X&apos;,
</equation>
<bodyText confidence="0.99852325">
Y&apos; and Z&apos; are the NFs of X, Y and Z. To demon-
strate this, it is sufficient to show that for every
combination under B, there is a corresponding B&apos;
combination of the NFs of the types (i.e. since for
binary combinations under the DC, of the form in
(16), the types occurring at the top and bottom of
any sequence of unary transformations will have the
same NF).
The following contraction rules define a NF for
combinations under B&apos; (which includes the combi-
nations of B as a subset — provided that each use
of L is relabelled as
</bodyText>
<listItem confidence="0.9653225">
(20) IF w r, w&apos; THEN
a. f: w/y + y w f: w&apos; ly y w&apos;
b. f: y/w + w y f: y/w&apos; + w&apos; y
c. b: y + w\y w b: y + w1\y w&apos;
d. b: w + y\w y b: w&apos; + y\w&apos; y
e. L(i)0: x\w/ui..ui + y = z\w t&gt;i
</listItem>
<equation confidence="0.960056">
L(i)0: + y = z\w&apos;
f. RO: x + y/w z/w
RO: x + y/w&apos; = z/w&apos;
</equation>
<footnote confidence="0.6005658">
11This NF is based on an arbitrary bias in the restruc-
turing of types, i.e. ordering backward directional arguments
after forward directional arguments. The opposite bias (i.e.
forward arguments after backward arguments) could as well
have been chosen.
</footnote>
<listItem confidence="0.990018">
(21) L(i)R0: x\w/ui..u, + y/v = z/v\w Di
RL(i)0: x\w/ui..ui y/v z \w/v
(22) L(o)f: x/w\v + w = x\v
f: x\v/w + w = x\v
(23) L(i)f: x\w/ui..ui + u = x/ui..ui_i\w
</listItem>
<equation confidence="0.839311076923077">
f: x\w/ui..ui + ui x\w/ui..ui-i
for i&gt; 0.
(24) b: z + x/y\z x/y
Rb: z x\z/y x/y
(25) L(i)0: x/v\w/ui..ui + y z\w
L(i+1)0: x\w/v/ui..ui + Y z\w
(26) IF ¢): x + y z x&apos; + y&apos; = z&apos;
THEN RO: x y lw zlw
x&apos; + y&apos;/w z&apos;/w
(27) IF 0: xlui..ui y = z t&gt;1
4/: + y&apos; = z&apos;
THEN L(i)4): y = z ti
L(i)01: x&apos;\wlui&apos; ..uii + z&apos;
</equation>
<bodyText confidence="0.999819235294118">
These rules also transform the types involved into
their NFs. In the cases in (20), a contraction is
made without affecting the identity of the particular
rule used to combine the types. In (21-25), the
transformations made on types requires that some
change be made to the rule used to combine them.
The rules (26) and (27) recursively define new
contractions in terms of the basic ones.
This reduction system can be shown to exhibit
strong normalisation, and it is straightforward to ar-
gue that each combination must have a unique NF.
This definition of NF accords with the constructive
definition (28). (Note that the notation Rn rep-
resents a sequence of n Rs, which are to be brack-
eted right-associatively with the following rule, e.g.
so that R2f = (R(Rf)), and that i takes the same
value for each L(i) in the sequence L(i)m.)
</bodyText>
<listItem confidence="0.686555">
(28) 0: x y z
</listItem>
<bodyText confidence="0.988617571428571">
where x, y, z are NF types, and 0 is (Rnf)
or (Rn(i)mb), for n,m &gt; 0.
Each proof of some combination xi xn xo
under the DC can be seen to consist of a number of
binary `subtrees&apos;, each of the form (16). If we sub-
stitute each binary subtree with its NF combination
in B&apos;, this gives a proof of xo&apos; (where
each xi&apos; is the NF of xi). Hence, for every DC proof,
there is a corresponding proof of the combination of
the NFs of the same types under B&apos;.
Even if we consider only proofs involving NF com-
binations in B&apos;, we observe spurious ambiguity of
the kind familiar from CCG and MCG. Again, we
can deal with this problem by defining NFs for such
</bodyText>
<page confidence="0.993913">
84
</page>
<bodyText confidence="0.924063166666667">
proofs. Since we are interested in incremental pro-
cessing, our method for identifying NF proofs is
based on favouring left-branching structures.
Let us consider the patterns of functional depen-
dency that are possible amongst sequences of three
types. These are shown in (29).12 Of these cases,
some (i.e. (a) and (f)) can only be derived with
a left-branching proof under B&apos; (or the DC), and
others (i.e. (b) and (e)) can only be derived with
a right-branching proof. Combinations of the pat-
terns (c),(d) and (g) commonly allow both right and
left-branching derivations (though not in all cases).
</bodyText>
<figure confidence="0.8728217">
(b)
y z
(d)
(1)
(g)
--&gt;
(30) (RN): x/y + y/ui ..un
(31) (R&amp;quot;L(ti)mb):
+ y\(x/ui..ui)/vi..v.
y
</figure>
<bodyText confidence="0.9959909">
NF binary combinations of the pattern in (28) take
the two more specific forms in (30) and (31).
Knowing this, we can easily sketch out the schematic
form of the three element combinations correspond-
ing to (29c,d,g) which have equivalent left and
right branching proofs, as shown in Figure 1.
We can define a NF for proofs under B&apos; (that use
only NF combinations) by stating three contraction
rules, one for each of the three cases in Figure 1,
where each rule rewrites the right branching three-
leaf subproof as the equivalent left branching sub-
proof. This will identify the optimally left branch-
ing member of each equivalence class of proofs as its
NF exemplar. Again, it is easily shown that reduc-
tion under these rules exhibits strong normalisation
and the Church-Rosser property, so that every proof
must have a unique normal form. However, it is not
so easy to prove the stronger claim that there is only
a single NF proof that assigns each distinct read-
ing for any combination.13 We shall not attempt
</bodyText>
<footnote confidence="0.96419975">
12Note that various other conceivable patterns of depen-
dency do not need to be considered here since they do not
correspond to any Lambek-valid combination.
13 This holds if the contraction relation generates an equiv-
</footnote>
<figureCaption confidence="0.637727538461539">
to demonstrate this property, although we believe
that it holds. We can identify the redexes of these
three contraction rules purely in terms of the rules
used to combine types, i.e. without needing to ex-
amine the schematic form of the types, since the
rules themselves identify the relevant structure of
the types. In fact, the right-branching subproofs for
cases (29c,g) collapse to the single schematic redex
(32), and that for (29d) simplifies to the schematic
redex (33). (Note that the notation Of is used to
represent any (NF) rule which is recursively defined
on a second rule 7r, e.g. so that 7rb is any NF rule
defined on b.)
</figureCaption>
<figure confidence="0.726955">
(32) x y z
Rmf
where n&gt; m
Rnd,
(33) x y z
where n &gt; 1
irb
</figure>
<bodyText confidence="0.995536966666667">
Let us consider the use of this system for pars-
ing. In seeking combinations of some sequence of
types, we first begin by transforming the types into
their NFs.14 Then, we can search for proofs using
only the NF binary combinations. Any proof that
is found to contain a proof redexes is discontinued,
so that only NF proofs are returned, avoiding the
problems of spurious ambiguity. Any result types
assigned by such proofs stand as NF exemplars for
the set of non-NF types that could be derived from
the original input types under the DC. We may want
to know if some input types can combine to give a
specific result type x. This will be the case if the
parser returns the NF of x.
Regarding incremental processing, we have seen
that the DC is well-suited to this task in terms of al-
lowing combinations that may usefully contribute to
a knowledge of the semantic relations amongst the
phrases combined, and that the NF proofs we have
defined (and which the parser will construct) are
optimally left-branching to the limit set by the cal-
culus. Hence, in left-to-right analysis of sentences,
the parser will be able to combine the presented
material to the maximal extent that doing so use-
fully contributes to incremental interpretation and
the filtering of semantically implausible analyses.
alence relation that equates any two proofs if these assign
extensionally equivalent readings.
14 The complexity of this transformation is constant in the
complexity of the type.
</bodyText>
<figure confidence="0.982120107142857">
x y
x y
4—
x y
41(L(i)b)
85
(280:
X/Y Y/W1-Wn RN. Wn/Vi-V,
x/wl -wn
x/wi -Wn_i /v1 -v,
(b) x/y Y/W1 -Wn Wn /VI -V, Rmf
31w1 -Wn-1 -Vinitm+n-1 f
x/wl-wn-1 /v1 -vm
Case
(a)
R.mf
(28d):
wn xVy/v1..vi)/ti..trniunorb
x\ivi..wn-z\(wn/uz-ui)/ti-tmwnL(j)kb
x\vii..wn-1\c1-clk/ti..tm
wnVb j)kb x\(y/vi..vi)/ti..tm
RIL(
Case
Ern L(i)k+n-1 b
Case (28g):
(a) x\(y/ui..ui)/vi..vm
(b) y ..wi/ui..ui x \ (y/ui..ui)/vi..vm vmhz -clnRnf
x \(y/ui..ui)/vi.•vm-1/41-clnityni.n-1L(i)jb
</figure>
<figureCaption confidence="0.999253">
Figure 1: Equivalent left and right-branching three-leaf subproofs
</figureCaption>
<bodyText confidence="0.49227">
RmL(i)jb vm/cu..cin
</bodyText>
<sectionHeader confidence="0.980719" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999712333333333">
Ades, A.E. and Steedman, M.J. 1982. &apos;On the order of
words.&apos; Linguistics and Philosophy, 4.
Barry, G. forthcoming:1991. Ph.D. dissertation, Centre for
Cognitive Science, University of Edinburgh.
Barry, G., Hepple, M., Leslie, N. and Morrill, G. 1991. &apos;Proof
figures and structural operators for categorial grammar&apos;. In
EACL-5, Berlin.
Barry, G. and Morrill, G. 1990. (Eds). Studies in Categorial
Grammar. Edinburgh Working Papers in Cognitive Sci-
ence, Volume 5. Centre for Cognitive Science, University
of Edinburgh.
Barry, G. and Pickering, M. 1990. &apos;Dependency and Con-
stituency in Categorial Grammar.&apos; In Barry, G. and Mor-
rill, G. 1990.
Dowty, D. 1988. &apos;Type raising, function composition, and
non-constituent conjunction.&apos; In Oehrle, R., Bach, E. and
Wheeler, D. (Eds), Categorial Grammars and Natural Lan-
guage Structures, D. Reidel, Dordrecht.
Hepple, M. 1990. &apos;Normal form theorem proving for the Lam-
bek calculus.&apos; In Karlgren, H. (Ed), Proc. of COLING
1990.
Hepple, M. 1990. The Grammar and Processing of Order
and Dependency: A Categorial Approach. Ph.D. disser-
tation, Centre for Cognitive Science, University of Edin-
burgh.
Hepple, M. and Morrill, G. 1989. &apos;Parsing and derivational
equivalence.&apos; In EA CL-4, UMIST, Manchester.
Konig, E. 1989, &apos;Parsing as natural deduction.&apos; In Proc. of
ACL-25, Vancouver.
Lambek, J. 1958. &apos;The mathematics of sentence structure.&apos;
American Mathematical Monthly 65.
Moortgat, M. 1989. Categorial Investigations: Logical and
Linguistic Aspects of the Lambek Calculus, Foris, Dordrecht.
Moortgat, M. 1990. &apos;Unambiguous proof representations for
the Laznbek calculus.&apos; In Proc. of 7th Amsterdam Collo-
quium, University of Amsterdam.
Moortgat, M. 1990. &apos;The logic of discontinuous type con-
structors.&apos; In Proc. of the Symposium on Discontinuous
Constituency, Institute for Language Technology and In-
formation, University of Tilburg.
Morrill, G. 1988, Extraction and Coordination in Phrase
Structure Grammar and Categorial Grammar. Ph.D. dis-
sertation, Centre for Cognitive Science, University of Ed-
inburgh.
Morrill, G. 1990. &apos;Grammar and Logical Types.&apos; In Proc.
7th Amsterdam Colloquium, University of Amsterdam. An
extended version appears in Barry, G. and Morrill, G. 1990.
Morrill, G., Leslie, N., Hepple, M. and Barry, G. 1990. &apos;Cat-
egorial deductions and structural operations.&apos; In Barry, G.
and Morrill, G. 1990.
Pickering, M. 1991. Processing Dependencies. Ph.D. disser-
tation, Centre for Cognitive Science, University of Edin-
burgh.
Steedman, Mark. 1985. &apos;Dependency and Coordination in
the Grammar of Dutch and English.&apos; Language, 61:3.
Steedman, Mark. 1987. &apos;Combinatory Grammars and Para-
sitic Gaps.&apos; NLLT, 5:3.
Steedman, M.J. 1989. &apos;Grammar, interpretation and process-
ing from the lexicon.&apos; hi Marslen-Wilson, W. (Ed), Lexical
Representation and Process, MIT Press, Cambridge, MA.
Szabolcsi, A. 1987 &apos;On Combinatory Categorial grammar.&apos;
In Proc. of the Symposium on Logic and Language, Debre-
cen, Akademiai KiadO, Budapest.
Zielonka, W. 1981. &apos;Axiomatizability of Ajdukiewicz-Lambek
Calculus by Means of Cancellation Schemes.&apos; Zeitschr. f.
math. Logik und Grundlagen d. Math. 27.
</reference>
<page confidence="0.998556">
86
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.904560">
<title confidence="0.996798">EFFICIENT INCREMENTAL PROCESSING WITH CATEGORIAL GRAMMAR</title>
<author confidence="0.999984">Mark Hepple</author>
<affiliation confidence="0.999987">University of Cambridge Computer Laboratory,</affiliation>
<address confidence="0.984056">New Museums Site, Pembroke St, Cambridge, UK.</address>
<email confidence="0.929252">e-mail:mrhuk.ac.cam.c1</email>
<abstract confidence="0.999160636363637">Some problems are discussed that arise for incremental prousing certain grammars, which involve either undesirable parsing properties or failure to allow combinations useful to incrementality. We suggest a new calculus which, though &apos;designed&apos; in relation to categorial interpretations of some notions of dependency grammar, seems to provide a degree of flexibility that is highly appropriate for incremental interpretation. We demonstrate how this grammar may be used for efficient incremental parsing, by employing normalisation techniques.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A E Ades</author>
<author>M J Steedman</author>
</authors>
<title>On the order of words.&apos;</title>
<date>1982</date>
<journal>Linguistics and Philosophy,</journal>
<volume>4</volume>
<marker>Ades, Steedman, 1982</marker>
<rawString>Ades, A.E. and Steedman, M.J. 1982. &apos;On the order of words.&apos; Linguistics and Philosophy, 4.</rawString>
</citation>
<citation valid="false">
<authors>
<author>G Barry</author>
</authors>
<tech>forthcoming:1991. Ph.D. dissertation,</tech>
<institution>Centre for Cognitive Science, University of Edinburgh.</institution>
<marker>Barry, </marker>
<rawString>Barry, G. forthcoming:1991. Ph.D. dissertation, Centre for Cognitive Science, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Barry</author>
<author>M Hepple</author>
<author>N Leslie</author>
<author>G Morrill</author>
</authors>
<title>Proof figures and structural operators for categorial grammar&apos;.</title>
<date>1991</date>
<booktitle>In EACL-5,</booktitle>
<location>Berlin.</location>
<marker>Barry, Hepple, Leslie, Morrill, 1991</marker>
<rawString>Barry, G., Hepple, M., Leslie, N. and Morrill, G. 1991. &apos;Proof figures and structural operators for categorial grammar&apos;. In EACL-5, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Barry</author>
<author>G Morrill</author>
</authors>
<title>(Eds). Studies in Categorial Grammar. Edinburgh Working Papers in Cognitive Science,</title>
<date>1990</date>
<volume>5</volume>
<institution>Centre for Cognitive Science, University of Edinburgh.</institution>
<marker>Barry, Morrill, 1990</marker>
<rawString>Barry, G. and Morrill, G. 1990. (Eds). Studies in Categorial Grammar. Edinburgh Working Papers in Cognitive Science, Volume 5. Centre for Cognitive Science, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Barry</author>
<author>M Pickering</author>
</authors>
<title>Dependency and Constituency in Categorial Grammar.&apos; In</title>
<date>1990</date>
<marker>Barry, Pickering, 1990</marker>
<rawString>Barry, G. and Pickering, M. 1990. &apos;Dependency and Constituency in Categorial Grammar.&apos; In Barry, G. and Morrill, G. 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Dowty</author>
</authors>
<title>Type raising, function composition, and non-constituent conjunction.&apos; In</title>
<date>1988</date>
<location>D. Reidel, Dordrecht.</location>
<contexts>
<context position="1072" citStr="Dowty, 1988" startWordPosition="144" endWordPosition="145">ned&apos; in relation to categorial interpretations of some notions of dependency grammar, seems to provide a degree of flexibility that is highly appropriate for incremental interpretation. We demonstrate how this grammar may be used for efficient incremental parsing, by employing normalisation techniques. Introduction A range of categorial grammars (CGs) have been proposed which allow considerable flexibility in the assignment of syntactic structure, a characteristic which provides for categorial treatments of extraction (Ades 8.6 Steedman, 1982) and non-constituent coordination (Steedman, 1985; Dowty, 1988), and that is claimed to allow for incremental processing of natural language (Steedman, 1989). It is this latter possibility that is the focus of this paper. Such &apos;flexible&apos; CGs (FCGs) typically allow that grammatical sentences may be given (amongst others) analyses which are either fully or primarily leftbranching. These analyses have the property of designating many of the initial substrings of sentences as interpretable constituents, providing for a style of processing in which the interpretation of a sentence is generated &apos;on-line&apos; as the sentence is presented. It has been argued that inc</context>
</contexts>
<marker>Dowty, 1988</marker>
<rawString>Dowty, D. 1988. &apos;Type raising, function composition, and non-constituent conjunction.&apos; In Oehrle, R., Bach, E. and Wheeler, D. (Eds), Categorial Grammars and Natural Language Structures, D. Reidel, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hepple</author>
</authors>
<title>Normal form theorem proving for the Lambek calculus.&apos;</title>
<date>1990</date>
<booktitle>In Karlgren, H. (Ed), Proc. of COLING</booktitle>
<contexts>
<context position="4428" citStr="Hepple (1990)" startWordPosition="709" endWordPosition="710">e a categorial notation in which x/y and x \y are both functions from y into x, and adopt a convention of left association, so that, e.g. ((s \np)/pp)/np may be written s \npippinp. 2See Lambek (1958) and Moortgat (1989) for a sequent formulation of the LC. See Morrill, Leslie, Hepple &amp; Barry (1990), and Barry, Hepple, Leslie &amp; Morrill (1991) for a natural deduction formulation. Zielonlca (1981) provides a LC formulation in terms of (recursively defined) reduction schema. Various extensions of the LC are currently under investigation, although we shall not have space to discuss them here. See Hepple (1990), Morrill (1990) and Moortgat (1990b). 79 type combinations — the other calculi which we consider admit only a subset of the Lambek type combinations.&apos; The flexibility of the LC is such that, for any combination xi ,..,xn xo, a fully left-branching derivation is always possible (i.e. combining xi and x2, then combining the result with x3, and so on). However, the properties of the LC make it useless for practical incremental processing. Under the LC, there is always an infinite number of result types for any combination, and we can only in practice address the possibility of combining some typ</context>
<context position="9169" citStr="Hepple (1990)" startWordPosition="1501" endWordPosition="1502">989) suggest a solution to this problem that involves specifying a notion of normal form (NF) for CCG proofs, and ensuring that the parser returns only NF proofs.4 However, their method has a number of limitations. (i) They considered a &apos;toy grammar&apos; involving only the CCG rules stated above. For a grammar involving further combination rules, normalisation would need to be completely reworked, and it remains to be shown that this task can be successfully done. (ii) 4Norrnalisation has also been suggested to deal with the problem of spurious ambiguity as it arises for the LC. See Honig (1989), Hepple (1990) and Moortgat (1990). 80 The NF proofs of this system are right-branching — again, it remains to be shown that a NF can be defined which favours left-branching (or even primarily left-branching) proofs. z/Y YizB z x/z --f Meta-Categorial Grammar In Meta-Categorial Grammar (MCG – Morrill, 1988) combination rules are recursively defined from the application rules (f and b) using the metarules (7) and (8). The metarules state that given a rule of the form shown to the left of with name 0, a further rule is allowed of the form shown to the right, with name given by applying R or L to 0 as indicate</context>
</contexts>
<marker>Hepple, 1990</marker>
<rawString>Hepple, M. 1990. &apos;Normal form theorem proving for the Lambek calculus.&apos; In Karlgren, H. (Ed), Proc. of COLING 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hepple</author>
</authors>
<title>The Grammar and Processing of Order and Dependency: A Categorial Approach.</title>
<date>1990</date>
<institution>Centre for Cognitive Science, University of Edinburgh.</institution>
<note>Ph.D. dissertation,</note>
<contexts>
<context position="4428" citStr="Hepple (1990)" startWordPosition="709" endWordPosition="710">e a categorial notation in which x/y and x \y are both functions from y into x, and adopt a convention of left association, so that, e.g. ((s \np)/pp)/np may be written s \npippinp. 2See Lambek (1958) and Moortgat (1989) for a sequent formulation of the LC. See Morrill, Leslie, Hepple &amp; Barry (1990), and Barry, Hepple, Leslie &amp; Morrill (1991) for a natural deduction formulation. Zielonlca (1981) provides a LC formulation in terms of (recursively defined) reduction schema. Various extensions of the LC are currently under investigation, although we shall not have space to discuss them here. See Hepple (1990), Morrill (1990) and Moortgat (1990b). 79 type combinations — the other calculi which we consider admit only a subset of the Lambek type combinations.&apos; The flexibility of the LC is such that, for any combination xi ,..,xn xo, a fully left-branching derivation is always possible (i.e. combining xi and x2, then combining the result with x3, and so on). However, the properties of the LC make it useless for practical incremental processing. Under the LC, there is always an infinite number of result types for any combination, and we can only in practice address the possibility of combining some typ</context>
<context position="9169" citStr="Hepple (1990)" startWordPosition="1501" endWordPosition="1502">989) suggest a solution to this problem that involves specifying a notion of normal form (NF) for CCG proofs, and ensuring that the parser returns only NF proofs.4 However, their method has a number of limitations. (i) They considered a &apos;toy grammar&apos; involving only the CCG rules stated above. For a grammar involving further combination rules, normalisation would need to be completely reworked, and it remains to be shown that this task can be successfully done. (ii) 4Norrnalisation has also been suggested to deal with the problem of spurious ambiguity as it arises for the LC. See Honig (1989), Hepple (1990) and Moortgat (1990). 80 The NF proofs of this system are right-branching — again, it remains to be shown that a NF can be defined which favours left-branching (or even primarily left-branching) proofs. z/Y YizB z x/z --f Meta-Categorial Grammar In Meta-Categorial Grammar (MCG – Morrill, 1988) combination rules are recursively defined from the application rules (f and b) using the metarules (7) and (8). The metarules state that given a rule of the form shown to the left of with name 0, a further rule is allowed of the form shown to the right, with name given by applying R or L to 0 as indicate</context>
</contexts>
<marker>Hepple, 1990</marker>
<rawString>Hepple, M. 1990. The Grammar and Processing of Order and Dependency: A Categorial Approach. Ph.D. dissertation, Centre for Cognitive Science, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hepple</author>
<author>G Morrill</author>
</authors>
<title>Parsing and derivational equivalence.&apos;</title>
<date>1989</date>
<booktitle>In EA CL-4, UMIST,</booktitle>
<location>Manchester.</location>
<contexts>
<context position="10411" citStr="Hepple &amp; Morrill, 1989" startWordPosition="1711" endWordPosition="1714">lying ft to backward application gives the rule (9), which allows combination of subject and transitive verb, as T and B do for CCG. Note, however, that this calculus does not allow any `non-contentfur combinations — all rules are recursively defined on the application rules which require a proper functional relation between the types combined. However, this calculus also fails to allow some contentful combinations, such as the case x/(y \z), y/w x/w mentioned above in (5). Like CCG, MCG suffers from spurious ambiguity, although this problem can be dealt with via normalisation (Morrill, 1988; Hepple &amp; Morrill, 1989). (7) RO: x + y/w z/w (where R = AgAaAbAc.ga(bc)) (8) x y z = LO: x\w y z\w (where L = AgAaAbAc.g(ac)b) (9) Rb: y + x\y/z = x/z The Dependency Calculus In this section, we will suggest a new calculus which, we will argue, is well suited to the task of incremental processing. We begin, however, with some discussion of the notions of head and dependent, and their relevance to CG. The dependency grammar (DG) tradition takes as fundamental the notions of head, dependent and the head-dependent relationship; where a head is, loosely, an element on which other elements depend. An analogy is often dra</context>
</contexts>
<marker>Hepple, Morrill, 1989</marker>
<rawString>Hepple, M. and Morrill, G. 1989. &apos;Parsing and derivational equivalence.&apos; In EA CL-4, UMIST, Manchester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Konig</author>
</authors>
<title>Parsing as natural deduction.&apos;</title>
<date>1989</date>
<booktitle>In Proc. of ACL-25,</booktitle>
<location>Vancouver.</location>
<marker>Konig, 1989</marker>
<rawString>Konig, E. 1989, &apos;Parsing as natural deduction.&apos; In Proc. of ACL-25, Vancouver.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lambek</author>
</authors>
<title>The mathematics of sentence structure.&apos;</title>
<date>1958</date>
<journal>American Mathematical Monthly</journal>
<volume>65</volume>
<contexts>
<context position="3342" citStr="Lambek, 1958" startWordPosition="520" endWordPosition="521">al types specify subcategorisation requirements of words, and requirements on constituent order. The most basic (non-flexible) CGs provide only rules of application for combining types, shown in (1). We adopt a scheme for specifying the semantics of combination rules where the rule name identifies a function that applies to the meanings of the input types in their left-to-right order to give the meaning of the result expression. (1) f: X/Y + Y X (where f= )aAb.(ab)) b: Y+ X\Y = X (where b = AaAb.(ba)) The Lambek calculus We begin by briefly considering the (product-free) Lambek calculus (LC - Lambek, 1958). Various formulations of the LC are possible (although we shall not present one here due to space limitations).2 The LC is complete with respect to an intuitively sensible interpretation of the slash connectives whereby the type x/y (resp. x \y) may be assigned to any string z which when left-concatenated (resp. rightconcatenated) with any string y of type y yields a string x.y (resp. y.x) of type x. The LC can be seen to provide the limit for what are possible 1We use a categorial notation in which x/y and x \y are both functions from y into x, and adopt a convention of left association, so </context>
</contexts>
<marker>Lambek, 1958</marker>
<rawString>Lambek, J. 1958. &apos;The mathematics of sentence structure.&apos; American Mathematical Monthly 65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Moortgat</author>
</authors>
<title>Categorial Investigations: Logical and Linguistic Aspects of the Lambek Calculus,</title>
<date>1989</date>
<location>Foris, Dordrecht.</location>
<contexts>
<context position="4035" citStr="Moortgat (1989)" startWordPosition="645" endWordPosition="646">ne here due to space limitations).2 The LC is complete with respect to an intuitively sensible interpretation of the slash connectives whereby the type x/y (resp. x \y) may be assigned to any string z which when left-concatenated (resp. rightconcatenated) with any string y of type y yields a string x.y (resp. y.x) of type x. The LC can be seen to provide the limit for what are possible 1We use a categorial notation in which x/y and x \y are both functions from y into x, and adopt a convention of left association, so that, e.g. ((s \np)/pp)/np may be written s \npippinp. 2See Lambek (1958) and Moortgat (1989) for a sequent formulation of the LC. See Morrill, Leslie, Hepple &amp; Barry (1990), and Barry, Hepple, Leslie &amp; Morrill (1991) for a natural deduction formulation. Zielonlca (1981) provides a LC formulation in terms of (recursively defined) reduction schema. Various extensions of the LC are currently under investigation, although we shall not have space to discuss them here. See Hepple (1990), Morrill (1990) and Moortgat (1990b). 79 type combinations — the other calculi which we consider admit only a subset of the Lambek type combinations.&apos; The flexibility of the LC is such that, for any combina</context>
</contexts>
<marker>Moortgat, 1989</marker>
<rawString>Moortgat, M. 1989. Categorial Investigations: Logical and Linguistic Aspects of the Lambek Calculus, Foris, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Moortgat</author>
</authors>
<title>Unambiguous proof representations for the Laznbek calculus.&apos;</title>
<date>1990</date>
<booktitle>In Proc. of 7th</booktitle>
<institution>Amsterdam Colloquium, University of Amsterdam.</institution>
<contexts>
<context position="4463" citStr="Moortgat (1990" startWordPosition="714" endWordPosition="715">/y and x \y are both functions from y into x, and adopt a convention of left association, so that, e.g. ((s \np)/pp)/np may be written s \npippinp. 2See Lambek (1958) and Moortgat (1989) for a sequent formulation of the LC. See Morrill, Leslie, Hepple &amp; Barry (1990), and Barry, Hepple, Leslie &amp; Morrill (1991) for a natural deduction formulation. Zielonlca (1981) provides a LC formulation in terms of (recursively defined) reduction schema. Various extensions of the LC are currently under investigation, although we shall not have space to discuss them here. See Hepple (1990), Morrill (1990) and Moortgat (1990b). 79 type combinations — the other calculi which we consider admit only a subset of the Lambek type combinations.&apos; The flexibility of the LC is such that, for any combination xi ,..,xn xo, a fully left-branching derivation is always possible (i.e. combining xi and x2, then combining the result with x3, and so on). However, the properties of the LC make it useless for practical incremental processing. Under the LC, there is always an infinite number of result types for any combination, and we can only in practice address the possibility of combining some types to give a known result type. Eve</context>
<context position="9189" citStr="Moortgat (1990)" startWordPosition="1504" endWordPosition="1505">ution to this problem that involves specifying a notion of normal form (NF) for CCG proofs, and ensuring that the parser returns only NF proofs.4 However, their method has a number of limitations. (i) They considered a &apos;toy grammar&apos; involving only the CCG rules stated above. For a grammar involving further combination rules, normalisation would need to be completely reworked, and it remains to be shown that this task can be successfully done. (ii) 4Norrnalisation has also been suggested to deal with the problem of spurious ambiguity as it arises for the LC. See Honig (1989), Hepple (1990) and Moortgat (1990). 80 The NF proofs of this system are right-branching — again, it remains to be shown that a NF can be defined which favours left-branching (or even primarily left-branching) proofs. z/Y YizB z x/z --f Meta-Categorial Grammar In Meta-Categorial Grammar (MCG – Morrill, 1988) combination rules are recursively defined from the application rules (f and b) using the metarules (7) and (8). The metarules state that given a rule of the form shown to the left of with name 0, a further rule is allowed of the form shown to the right, with name given by applying R or L to 0 as indicated. For example, appl</context>
</contexts>
<marker>Moortgat, 1990</marker>
<rawString>Moortgat, M. 1990. &apos;Unambiguous proof representations for the Laznbek calculus.&apos; In Proc. of 7th Amsterdam Colloquium, University of Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Moortgat</author>
</authors>
<title>The logic of discontinuous type constructors.&apos;</title>
<date>1990</date>
<booktitle>In Proc. of the Symposium on Discontinuous Constituency, Institute for Language Technology</booktitle>
<institution>and Information, University of Tilburg.</institution>
<contexts>
<context position="4463" citStr="Moortgat (1990" startWordPosition="714" endWordPosition="715">/y and x \y are both functions from y into x, and adopt a convention of left association, so that, e.g. ((s \np)/pp)/np may be written s \npippinp. 2See Lambek (1958) and Moortgat (1989) for a sequent formulation of the LC. See Morrill, Leslie, Hepple &amp; Barry (1990), and Barry, Hepple, Leslie &amp; Morrill (1991) for a natural deduction formulation. Zielonlca (1981) provides a LC formulation in terms of (recursively defined) reduction schema. Various extensions of the LC are currently under investigation, although we shall not have space to discuss them here. See Hepple (1990), Morrill (1990) and Moortgat (1990b). 79 type combinations — the other calculi which we consider admit only a subset of the Lambek type combinations.&apos; The flexibility of the LC is such that, for any combination xi ,..,xn xo, a fully left-branching derivation is always possible (i.e. combining xi and x2, then combining the result with x3, and so on). However, the properties of the LC make it useless for practical incremental processing. Under the LC, there is always an infinite number of result types for any combination, and we can only in practice address the possibility of combining some types to give a known result type. Eve</context>
<context position="9189" citStr="Moortgat (1990)" startWordPosition="1504" endWordPosition="1505">ution to this problem that involves specifying a notion of normal form (NF) for CCG proofs, and ensuring that the parser returns only NF proofs.4 However, their method has a number of limitations. (i) They considered a &apos;toy grammar&apos; involving only the CCG rules stated above. For a grammar involving further combination rules, normalisation would need to be completely reworked, and it remains to be shown that this task can be successfully done. (ii) 4Norrnalisation has also been suggested to deal with the problem of spurious ambiguity as it arises for the LC. See Honig (1989), Hepple (1990) and Moortgat (1990). 80 The NF proofs of this system are right-branching — again, it remains to be shown that a NF can be defined which favours left-branching (or even primarily left-branching) proofs. z/Y YizB z x/z --f Meta-Categorial Grammar In Meta-Categorial Grammar (MCG – Morrill, 1988) combination rules are recursively defined from the application rules (f and b) using the metarules (7) and (8). The metarules state that given a rule of the form shown to the left of with name 0, a further rule is allowed of the form shown to the right, with name given by applying R or L to 0 as indicated. For example, appl</context>
</contexts>
<marker>Moortgat, 1990</marker>
<rawString>Moortgat, M. 1990. &apos;The logic of discontinuous type constructors.&apos; In Proc. of the Symposium on Discontinuous Constituency, Institute for Language Technology and Information, University of Tilburg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Morrill</author>
</authors>
<title>Extraction and Coordination in Phrase Structure Grammar and Categorial Grammar.</title>
<date>1988</date>
<institution>Centre for Cognitive Science, University of Edinburgh.</institution>
<note>Ph.D. dissertation,</note>
<contexts>
<context position="9463" citStr="Morrill, 1988" startWordPosition="1549" endWordPosition="1550"> For a grammar involving further combination rules, normalisation would need to be completely reworked, and it remains to be shown that this task can be successfully done. (ii) 4Norrnalisation has also been suggested to deal with the problem of spurious ambiguity as it arises for the LC. See Honig (1989), Hepple (1990) and Moortgat (1990). 80 The NF proofs of this system are right-branching — again, it remains to be shown that a NF can be defined which favours left-branching (or even primarily left-branching) proofs. z/Y YizB z x/z --f Meta-Categorial Grammar In Meta-Categorial Grammar (MCG – Morrill, 1988) combination rules are recursively defined from the application rules (f and b) using the metarules (7) and (8). The metarules state that given a rule of the form shown to the left of with name 0, a further rule is allowed of the form shown to the right, with name given by applying R or L to 0 as indicated. For example, applying ft to backward application gives the rule (9), which allows combination of subject and transitive verb, as T and B do for CCG. Note, however, that this calculus does not allow any `non-contentfur combinations — all rules are recursively defined on the application rules</context>
</contexts>
<marker>Morrill, 1988</marker>
<rawString>Morrill, G. 1988, Extraction and Coordination in Phrase Structure Grammar and Categorial Grammar. Ph.D. dissertation, Centre for Cognitive Science, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Morrill</author>
</authors>
<title>Grammar and Logical Types.&apos;</title>
<date>1990</date>
<booktitle>In Proc. 7th</booktitle>
<institution>Amsterdam Colloquium, University of Amsterdam.</institution>
<note>An extended version appears in</note>
<contexts>
<context position="4444" citStr="Morrill (1990)" startWordPosition="711" endWordPosition="712">notation in which x/y and x \y are both functions from y into x, and adopt a convention of left association, so that, e.g. ((s \np)/pp)/np may be written s \npippinp. 2See Lambek (1958) and Moortgat (1989) for a sequent formulation of the LC. See Morrill, Leslie, Hepple &amp; Barry (1990), and Barry, Hepple, Leslie &amp; Morrill (1991) for a natural deduction formulation. Zielonlca (1981) provides a LC formulation in terms of (recursively defined) reduction schema. Various extensions of the LC are currently under investigation, although we shall not have space to discuss them here. See Hepple (1990), Morrill (1990) and Moortgat (1990b). 79 type combinations — the other calculi which we consider admit only a subset of the Lambek type combinations.&apos; The flexibility of the LC is such that, for any combination xi ,..,xn xo, a fully left-branching derivation is always possible (i.e. combining xi and x2, then combining the result with x3, and so on). However, the properties of the LC make it useless for practical incremental processing. Under the LC, there is always an infinite number of result types for any combination, and we can only in practice address the possibility of combining some types to give a kno</context>
</contexts>
<marker>Morrill, 1990</marker>
<rawString>Morrill, G. 1990. &apos;Grammar and Logical Types.&apos; In Proc. 7th Amsterdam Colloquium, University of Amsterdam. An extended version appears in Barry, G. and Morrill, G. 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Morrill</author>
<author>N Leslie</author>
<author>M Hepple</author>
<author>G Barry</author>
</authors>
<title>Categorial deductions and structural operations.&apos; In</title>
<date>1990</date>
<marker>Morrill, Leslie, Hepple, Barry, 1990</marker>
<rawString>Morrill, G., Leslie, N., Hepple, M. and Barry, G. 1990. &apos;Categorial deductions and structural operations.&apos; In Barry, G. and Morrill, G. 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pickering</author>
</authors>
<title>Processing Dependencies.</title>
<date>1991</date>
<tech>Ph.D. dissertation,</tech>
<institution>Centre for Cognitive Science, University of Edinburgh.</institution>
<contexts>
<context position="15532" citStr="Pickering (1991)" startWordPosition="2569" endWordPosition="2570">nt that the unary transformations specified by these two axioms are DP, since function-argument order is a notion extraneous to dependency; the functors x\y/z and x/z\y have the same dependency requirements, i.e. dependents y and z.8 For the same reason, such reordering of arguments should also be possible for functions that occur as subtypes within larger types, as in (12a,b). The operation of the associativity rules can be &apos;generalised&apos; in this fashion by including the unary metarules (13),8 which recursively define 6See Barry (forthcoming) for extensive discussion of dependency and CG, and Pickering (1991) for the relevance of dependency to human sentence processing. 7B&amp;P suggest a second criterion in terms of the form of proofs which, for the natural deduction formulation of the LC that B&amp;P use, is equivalent to the criterion in terms of lambda expressions (given that a variant of the CurryHoward correspondence between implicational deductions and lambda expressions obtains). 8 Clearly, the reversal of two co-directional arguments (i.e. x/y/z x/z/y) would also be DP for this reason, but is not LC-valid (since it would not preserve linear order requirements). For a unidirectional CG system (i.e</context>
</contexts>
<marker>Pickering, 1991</marker>
<rawString>Pickering, M. 1991. Processing Dependencies. Ph.D. dissertation, Centre for Cognitive Science, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Dependency and Coordination in the Grammar of Dutch and English.&apos; Language,</title>
<date>1985</date>
<pages>61--3</pages>
<contexts>
<context position="1058" citStr="Steedman, 1985" startWordPosition="142" endWordPosition="143">h, though &apos;designed&apos; in relation to categorial interpretations of some notions of dependency grammar, seems to provide a degree of flexibility that is highly appropriate for incremental interpretation. We demonstrate how this grammar may be used for efficient incremental parsing, by employing normalisation techniques. Introduction A range of categorial grammars (CGs) have been proposed which allow considerable flexibility in the assignment of syntactic structure, a characteristic which provides for categorial treatments of extraction (Ades 8.6 Steedman, 1982) and non-constituent coordination (Steedman, 1985; Dowty, 1988), and that is claimed to allow for incremental processing of natural language (Steedman, 1989). It is this latter possibility that is the focus of this paper. Such &apos;flexible&apos; CGs (FCGs) typically allow that grammatical sentences may be given (amongst others) analyses which are either fully or primarily leftbranching. These analyses have the property of designating many of the initial substrings of sentences as interpretable constituents, providing for a style of processing in which the interpretation of a sentence is generated &apos;on-line&apos; as the sentence is presented. It has been a</context>
</contexts>
<marker>Steedman, 1985</marker>
<rawString>Steedman, Mark. 1985. &apos;Dependency and Coordination in the Grammar of Dutch and English.&apos; Language, 61:3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Combinatory Grammars and Parasitic Gaps.&apos;</title>
<date>1987</date>
<journal>NLLT,</journal>
<volume>5</volume>
<contexts>
<context position="5385" citStr="Steedman, 1987" startWordPosition="873" endWordPosition="875">d so on). However, the properties of the LC make it useless for practical incremental processing. Under the LC, there is always an infinite number of result types for any combination, and we can only in practice address the possibility of combining some types to give a known result type. Even if we were to allow only S as the overall result of a parse, this would not tell us the intermediate target types for binary combinations made in incrementally accepting a sentence, so that such an analysis cannot in practice be made. Combinatory Categorial Grammar Combinatory Categorial Grammars (CCGs – Steedman, 1987; Szabolcsi, 1987) are formulated by adding a number of type combination and transition schemes to the basic rules of application. We can formulate a simple version of CCG with the rules of type raising and composition shown in (2). This CCG allows the combinations (3a,b), as shown by the proofs (4a,b). (2) T: x y/(y \ x) (where T = )txAf.(fx)) B: x/y y/z x/z (where B = AfAgAx.f(gx)) (3) a. np:x, s\ np/np:f s/np:Ay.fyx b. vp/s:f, np:x vp/(s\np):Ag.f(gx) (4) (a) np T s\np/np (b) vp/s np s/(s\np) s/(s\np) s/np vp/(rAnp) The derived rule (3a) allows a subject NP to combine with a transitive verb </context>
</contexts>
<marker>Steedman, 1987</marker>
<rawString>Steedman, Mark. 1987. &apos;Combinatory Grammars and Parasitic Gaps.&apos; NLLT, 5:3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Steedman</author>
</authors>
<title>Grammar, interpretation and processing from the lexicon.&apos; hi</title>
<date>1989</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1166" citStr="Steedman, 1989" startWordPosition="158" endWordPosition="159"> to provide a degree of flexibility that is highly appropriate for incremental interpretation. We demonstrate how this grammar may be used for efficient incremental parsing, by employing normalisation techniques. Introduction A range of categorial grammars (CGs) have been proposed which allow considerable flexibility in the assignment of syntactic structure, a characteristic which provides for categorial treatments of extraction (Ades 8.6 Steedman, 1982) and non-constituent coordination (Steedman, 1985; Dowty, 1988), and that is claimed to allow for incremental processing of natural language (Steedman, 1989). It is this latter possibility that is the focus of this paper. Such &apos;flexible&apos; CGs (FCGs) typically allow that grammatical sentences may be given (amongst others) analyses which are either fully or primarily leftbranching. These analyses have the property of designating many of the initial substrings of sentences as interpretable constituents, providing for a style of processing in which the interpretation of a sentence is generated &apos;on-line&apos; as the sentence is presented. It has been argued that incremental interpretation may provide for efficient language processing — by both humans and mac</context>
</contexts>
<marker>Steedman, 1989</marker>
<rawString>Steedman, M.J. 1989. &apos;Grammar, interpretation and processing from the lexicon.&apos; hi Marslen-Wilson, W. (Ed), Lexical Representation and Process, MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Szabolcsi</author>
</authors>
<title>On Combinatory Categorial grammar.&apos;</title>
<date>1987</date>
<booktitle>In Proc. of the Symposium on Logic and Language,</booktitle>
<location>Debrecen, Akademiai KiadO, Budapest.</location>
<contexts>
<context position="5403" citStr="Szabolcsi, 1987" startWordPosition="876" endWordPosition="877">r, the properties of the LC make it useless for practical incremental processing. Under the LC, there is always an infinite number of result types for any combination, and we can only in practice address the possibility of combining some types to give a known result type. Even if we were to allow only S as the overall result of a parse, this would not tell us the intermediate target types for binary combinations made in incrementally accepting a sentence, so that such an analysis cannot in practice be made. Combinatory Categorial Grammar Combinatory Categorial Grammars (CCGs – Steedman, 1987; Szabolcsi, 1987) are formulated by adding a number of type combination and transition schemes to the basic rules of application. We can formulate a simple version of CCG with the rules of type raising and composition shown in (2). This CCG allows the combinations (3a,b), as shown by the proofs (4a,b). (2) T: x y/(y \ x) (where T = )txAf.(fx)) B: x/y y/z x/z (where B = AfAgAx.f(gx)) (3) a. np:x, s\ np/np:f s/np:Ay.fyx b. vp/s:f, np:x vp/(s\np):Ag.f(gx) (4) (a) np T s\np/np (b) vp/s np s/(s\np) s/(s\np) s/np vp/(rAnp) The derived rule (3a) allows a subject NP to combine with a transitive verb before the verb ha</context>
</contexts>
<marker>Szabolcsi, 1987</marker>
<rawString>Szabolcsi, A. 1987 &apos;On Combinatory Categorial grammar.&apos; In Proc. of the Symposium on Logic and Language, Debrecen, Akademiai KiadO, Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Zielonka</author>
</authors>
<title>Axiomatizability of Ajdukiewicz-Lambek Calculus by Means of Cancellation Schemes.&apos;</title>
<date>1981</date>
<journal>Zeitschr. f. math. Logik und Grundlagen d. Math.</journal>
<volume>27</volume>
<contexts>
<context position="16550" citStr="Zielonka (1981)" startWordPosition="2731" endWordPosition="2732">of two co-directional arguments (i.e. x/y/z x/z/y) would also be DP for this reason, but is not LC-valid (since it would not preserve linear order requirements). For a unidirectional CG system (i.e. a system with a single connective /, that did not specify linear order requirements), free reversal of arguments would be appropriate. We suggest that a unidirectional variant of the calculus to be proposed might be the best system for pure reasoning about &apos;categorial dependency&apos;, aside from linearity considerations. 9 These unary metarules have been used elsewhere as part of the LC formulation of Zielonka (1981). new unary rules from the associatt■ Lk axioms. (12) a. a\b/c/d a/c\b/d b. x/(a\b/c) x/(a/c\b) (13) a. 41: x = y VO: x/z = y/z x = y VO: x\z = y\z (where V = )tfAciAb.f(ab)) b. irk: x y ZO: z/y z/x 41: x y = ZO: z\y z\x (where Z = AfAci)tb.a(fb)) (14) x/(a\b/c):f x/(a/c\b):Av.f()taA b. vba) Clearly, the rules {V,Z,a} allow only DP unary transformations. However, we make the stronger claim that these rules specify the limit of DP unary transformations. The rules allow that the given functional structure of a type be &apos;shuffled&apos; upto the limit of preserving linear order requirements. But the onl</context>
</contexts>
<marker>Zielonka, 1981</marker>
<rawString>Zielonka, W. 1981. &apos;Axiomatizability of Ajdukiewicz-Lambek Calculus by Means of Cancellation Schemes.&apos; Zeitschr. f. math. Logik und Grundlagen d. Math. 27.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>