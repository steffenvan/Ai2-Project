<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000014">
<note confidence="0.808309666666667">
Proceedings of the Workshop on Speech-to-Speech Translation:
Algorithms and Systems, Philadelphia, July 2002, pp. 39-44.
Association for Computational Linguistics.
</note>
<title confidence="0.9973735">
Architectures for speech-to-speech translation
using finite-state models
</title>
<author confidence="0.891572">
Juan Miguel Vilar
</author>
<affiliation confidence="0.5390725">
Dpt. de Llenguatges i Sistemes Inform`atics
Universitat Jaume I
</affiliation>
<address confidence="0.829242">
Castell´o, SPAIN.
</address>
<email confidence="0.963619">
jvilar@lsi.uji.es
</email>
<author confidence="0.998174">
Francisco Casacuberta Enrique Vidal
</author>
<affiliation confidence="0.746410666666667">
Dpt. de Sistemes Inform`atics i Computaci´o &amp;
Institut Tecnol`ogic d’Inform`atica
Universitat Polit`ecnica de Val`encia
</affiliation>
<address confidence="0.948493">
46071 Val`encia, SPAIN.
</address>
<email confidence="0.994317">
fcn@iti.upv.es, evidal@iti.upv.es
</email>
<sectionHeader confidence="0.998582" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999966678571429">
Speech-to-speech translation can be ap-
proached using finite state models and
several ideas borrowed from automatic
speech recognition. The models can be
Hidden Markov Models for the accous-
tic part, language models for the source
language and finite state transducers for
the transfer between the source and target
language. A “serial architecture” would
use the Hidden Markov and the language
models for recognizing input utterance
and the transducer for finding the transla-
tion. An “integrated architecture”, on the
other hand, would integrate all the mod-
els in a single network where the search
process takes place. The output of this
search process is the target word sequence
associated to the optimal path. In both
architectures, HMMs can be trained from
a source-language speech corpus, and the
translation model can be learned automat-
ically from a parallel text training cor-
pus. The experiments presented here cor-
respond to speech-input translations from
Spanish to English and from Italian to En-
glish, in applications involving the inter-
action (by telephone) of a customer with
the front-desk of a hotel.
</bodyText>
<sectionHeader confidence="0.999499" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999648833333333">
Present finite-state technology allows us to build
speech-to-speech translation (ST) systems using
ideas very similar to those of automatic speech
recognition (ASR). In ASR the acoustic hidden
Markov models (HMMs) can be integrated into the
language model, which is typically a finite-state
grammar (e.g. a N-gram). In ST the same HMMs
can be integrated in a translation model which con-
sists in a stochastic finite-state transducer (SFST).
Thanks to this integration, the translation process
can be efficiently performed by searching for an
optimal path of states through the integrated net-
work by using well-known optimization procedures
such as (beam-search accelerated) Viterbi search.
This “integrated architecture” can be compared with
the more conventional “serial architecture”, where
the HMMs, along with a suitable source language
model, are used as a front-end to recognize a se-
quence of source-language words which is then pro-
cessed by the translation model. A related approach
has been proposed in (Bangalore and Ricardi, 2000;
Bangalore and Ricardi, 2001).
In any case, a pure pattern-recognition approach
can be followed to build the required systems.
Acoustic models can be trained from a suffi-
ciently large source-language speech training set,
in the very same way as in speech recognition.
On the other hand, using adequate learning algo-
rithms (Casacuberta, 2000; Vilar, 2000), the trans-
lation model can also be learned from a sufficiently
large training set consisting of source-target parallel
text.
In this paper, we comment the results obtained us-
ing this approach in EUTRANS, a five-year joint ef-
fort of four European institutions, partially funded
by the European Union.
</bodyText>
<page confidence="0.437222">
t1
</page>
<sectionHeader confidence="0.9580825" genericHeader="method">
2 Finite-state transducers and speech
translation
</sectionHeader>
<bodyText confidence="0.999324571428571">
The statistical framework allow us to formulate the
speech translation problem as follows: Let x be an
acoustic representation of a given utterance; typi-
cally a sequence of acoustic vectors or “frames”.
The translation of x into a target-language sentence
can be formulated as the search for a word se-
quence, ˆt, from the target language such that:
</bodyText>
<equation confidence="0.9997425">
tˆ = argmax
t Pr(t|x). (1)
</equation>
<bodyText confidence="0.9429835">
Conceptually, the translation can be viewed as a
two-step process (Ney, 1999; Ney et al., 2000):
</bodyText>
<equation confidence="0.967785">
x — *s — *t,
</equation>
<bodyText confidence="0.99856925">
where s is a sequence of source-language words
which would match the observed acoustic sequence
x and t is a target-language word sequence associ-
ated with s. Consequently,
</bodyText>
<equation confidence="0.9853565">
Pr(t|x) = X Pr(t, s|x), (2)
s
</equation>
<bodyText confidence="0.9936995">
and, with the natural assumption that Pr(x|s, t) does
not depend on the target sentence t,
</bodyText>
<equation confidence="0.9963105">
Xtˆ = argmax !Pr(s, t) · Pr(x|s) . (3)
t s
</equation>
<bodyText confidence="0.667725666666667">
Using a SFST as a model for Pr(s, t) and HMMs
to model Pr(x|s), Eq. 3 is transformed in the opti-
mization problem:
</bodyText>
<equation confidence="0.977843791666667">
for
q,q0 E Q, a E Σ, ω E Δ* and1P : R —* IR+
IR+(final-
state probabilities) are functions such that bq E Q:
F(q) + X P (q, a, ω, q0) = 1.
(transition probabilities) and F : Q —*
φ :(q0,s1,˜t1,q1),(q1,s2,˜t2,q2),
. . . , (qI−1, sI, ˜tI , qI),
is also possible), such that
... tI = t an
t2
d I is the length of the source sen-
PrT (φ) = F(qI) ·
φ is
P(qi−1,si, ti,qi). (5)
!PrT (s, t) · PrM(x|s) , (4)
Xtˆ = argmax
t
s
X PrT (φ) (6)
=φ∈d(s,t)
max (7
� PrT (φ),
φ∈d(s,t) )
</equation>
<bodyText confidence="0.996972547945206">
obtained by removing the target (source) words fr
om
each transition of the model.
where PrT(s, t) is the probability supplied by the
SFST and
PrM(x|s) is the density value supplied
by the corresponding HMMs associated to s for the
acoustic sequence x.
2.1 Finite-state transducers
A SFST, T, is a tuple (Q,
R,
F, P), where
Q is a finite set of states;
is the initial state;
and
are finite sets of input symbols (source words) and
outputsymbols (target words), respectively
=
0
Σ,Δ,
q0,
q0
Σ
Δ
(Σf1Δ
); R is a set of transitions of the form (q, a, ω, q0)
∀(a, w, q&apos;) E E x Δ* x Q :
(q, a, w, q&apos;) E R
Fig. 1 shows a small fragment of a SFST for Spanish
to English translation.
A particular case of finite-state transducers are
known as subsequential transducers (SSTs). These
are finite-state transducers with the restriction of be-
ing deterministic (if (q, a,
q), (q, a,
E R,
then
=
and q =
SSTs also have output
strings associated to the (final) states. This can fit
well under the above formulation by simply adding
an end-off-sentence marker to each input sentence.
For a pair (s, t) E
x
a translation form,
is a sequence of tran
ω,
ω0,q0)
ω
ω0
q0).
Σ*
Δ*,
φ,
sitions in a SFST T :
where tj denotes a substring of target words (the
empty string for tj
tence s. The probability of
YI
i=0
Finally, the probability of the pair (s, t) is
PrT(s, t)
where d(s, t) is the set of all translation forms for
the pair (s, t).
These models have implicit source and target lan-
guage models embedded in their definitions, which
are simply the marginal distributions of PrT. In
practice, the source (target) language model can be
D* and E* we denote the sets of finite-length strings on
D and E, re
1By
spectively
</bodyText>
<figureCaption confidence="0.904293333333333">
Figure 1: Example of SFST. A denotes the empty string. The source sentence “una habitaci´on doble” can
be translated to either “a double room” or “a room with two beds”. The most probable translation is the
first one with probability of 0.09.
</figureCaption>
<figure confidence="0.897178083333333">
habitación / room (0.1)
2
doble / with two beds (1)
una / a (0.5)
0 1
habitación / room (0.3)
la / the (0.5)
habitación / λ (0.6)
doble / double room (0.3)
4
3
individual / single room (0.7)
</figure>
<bodyText confidence="0.999913944444445">
The structural (states and transitions) and the
probabilistic components of a SFST can be learned
automatically from training pairs in a single process
using the MGTI technique (Casacuberta, 2000). Al-
ternatively, the structural component can be learned
using the OMEGA technique (Vilar, 2000), while
the probabilistic component is estimated in a second
step using maximum likelihood or other possible cri-
teria (Pic´o and Casacuberta, 2001). One of the main
problems that appear during the learning process is
the modelling of events that have not been seen in
the training set. This problem can be confronted,
in a similar way as in language modelling, by using
smoothing techniques in the estimation process of
the probabilistic components of the SFST (Llorens,
2000). Alternatively, smoothing can be applied in
the process of learning both components (Casacu-
berta, 2000).
</bodyText>
<subsectionHeader confidence="0.850389">
2.2 Architectures for speech translation
</subsectionHeader>
<bodyText confidence="0.858069">
Using Eq. 7 as a model for Pr(s, t) in Eq. 4,
</bodyText>
<equation confidence="0.9572025">
!PrT (φ) · PrM(x|s) ,
(8)
</equation>
<bodyText confidence="0.9952012">
For the computation of PrM(x|s) in Eq. 8, let
b be an arbitrary segmentation of x into I acous-
tic subsequences, each of which associated with a
source word (therefore, I is the number of words in
s). Then:
</bodyText>
<equation confidence="0.990833333333333">
I
PrM(x|s) = X Y PrM(¯xi|si), (9)
b i=1
</equation>
<bodyText confidence="0.9998578">
where ¯xi is the i-th. acoustic segment of b, and each
source word si has an associated HMM that supplies
the density value PrM(¯xi|si).
Finally, by substituting Eq. 5 and Eq. 9 into Eq. 8
and approximating sums by maximisations:
</bodyText>
<equation confidence="0.8609405">
P(qi−1,si, ¯ti,qi) · PrM(¯xi|si).
(10)
</equation>
<bodyText confidence="0.9714595625">
Solving this maximisation yields (an approximation
to) the most likely target-language sentence tˆ for the
observed source-language acoustic sequence x.
This computation can be accomplished using the
well known Viterbi algorithm. It searches for an op-
timal sequence of states in an integrated network (in-
tegrated architecture) which is built by substituting
each edge of the SFST by the corresponding HMM
of the source word associated to the edge.
This integration process is illustrated in Fig. 2. A
small SFST is presented in the first panel (a) of this
figure. In panel (b), the source words in each edge
are substituted by the corresponding phonetic tran-
scription. In panel (c) each phoneme is substituted
by the corresponding HMM of the phone. Clearly,
this direct integration approach often results in huge
finite-state networks. Correspondingly, a straight-
forward (dynamic-programming) search for an op-
timal target sentence may require a prohibitively
high computational effort. Fortunately, this compu-
tational cost can be dramatically reduced by means
of standard heuristic acceleration techniques such as
beam search.
An alternative, which sacrifices optimality more
drastically, is to break the search down into two
steps, leading to a so-called “serial architecture”. In
the first step a conventional source-language speech
decoding system (using just a source-language lan-
guage model) is used to obtain a single (may be mul-
tiple) hypothesis for the sequence of uttered words.
In the second step, this text sequence is translated
into a target-language sentence.
</bodyText>
<equation confidence="0.951752166666667">
Xtˆ = argmax max
t s OEd(s,t)
tˆ = argmax
OEd(s,t),b
YI
i=1
</equation>
<listItem confidence="0.57013">
a) Original FST.
b) Lexical expansion.
c) Phonetic expansion.
</listItem>
<figureCaption confidence="0.97433975">
Figure 2: Example of the integration process of the lexical knowledge (figure b) and the phonetic knowledge
(figure c) in a FST (figure a). A denotes the empty string in panels a and b. In panel c, source symbols are
typeset in small fonts, target strings are typeset in large fonts and edges with no symbols denote empty
transitions.
</figureCaption>
<figure confidence="0.993996888888889">
maleta / λ
azul / blue suitcase
2
la / the
0 1
bolsa / λ
3
azul / blue bag
4
0 l / λ a / the 1
b / λ o / λ l / λ s / λ
m / λ a / λ l / λ e / λ
s / λ 3
a / λ
t / λ
t / λ
a / λ
a / λ
2
z / λ
a / λ
s / λ
z / λ
s / λ
u / λ l / blue bag
u / λ
l / blue suitcase
4
t
a
z
the m
l a
0 1
u l
blue suitcase
e
a l
t
a
2
s
b
o l s
s
a
3
a
z
s
u
blue bag
l
4
</figure>
<bodyText confidence="0.997556857142857">
Using Pr(s, t) = Pr(t  |s) · Pr(s) in Eq. 3 and
approximating the sum by the maximum, the opti-
mization problem can be presented as
A better alternative for this crude “two-step” ap-
proach is to use Pr(s, t) = Pr(s  |t)·Pr(t) in Eq. 3.
Now, approximating the sum by the maximum, the
optimization problem can be presented as
</bodyText>
<equation confidence="0.99246475">
(ˆt, ˆs) = argmax
t,s
(Pr(t|s) · Pr(s) · Pr(x|s)) ,
(11)
</equation>
<bodyText confidence="0.787919">
and the two-step approximation reduces to
</bodyText>
<equation confidence="0.977805">
(ˆt, ˆs) = argmax
t,s
(Pr(s  |t) · Pr(t) · Pr(x  |s)) ,
(15)
</equation>
<bodyText confidence="0.945661">
and now the two-step approximation reduces to
</bodyText>
<equation confidence="0.993838833333333">
sˆ ≈ argmax {Pr(s) · Pr(x|s)}, (12) sˆ ≈ argmax {Pr(s  |t) · Pr(x  |s)}, (16)
s Pr(t|ˆs) (13) s Pr(ˆs  |t) · Pr(t) (17)
tˆ ≈ argmax Pr(ˆs, t). (14) tˆ ≈ argmax Pr(ˆs, t). (18)
t t
= argmax = argmax
t t
</equation>
<bodyText confidence="0.9967505">
In other words, the search for an optimal target-
language sentence is now approximated as follows:
</bodyText>
<listItem confidence="0.819941777777778">
1. Word decoding of x. A source-language sen-
tence sˆ is searched for using a source language
model, PrN(s), for Pr(s) and the correspond-
ing HMMs, PrM(x|s), to model Pr(x|s):
sˆ ≈ argmax (PrN(s) · PrM(x|s)) .
s
2. Translation of ˆs. A target-language sentence tˆ
is searched for using a SFST, PrT (ˆs, t), as a
model of Pr(ˆs, t)
</listItem>
<equation confidence="0.955893">
tˆ ≈ argmax
t
</equation>
<bodyText confidence="0.922889625">
The main problem of this approach is the term
t that appears in the first maximisation (Eq. 16).
A possible solution is to follow an iterative proce-
dure where t, that is used for computing ˆs, is the
one obtained from argmaxt Pr(ˆs, t) in the previous
iteration (Garcia-Varea et al., 2000). In this case,
Pr(s  |t) can be modelled by a source language
model that depends on a previously computed ˜t:
PrN,˜t(s). In the first iteration no tˆ is known, but
PrN,˜t(s) can be approximated by PrN(s). Follow-
ing this idea, the search can be formulated as:
Initialization:
Let PrN ,t(s) be approximated by a source lan-
guage model PrN(s).
PrT (ˆs, t).
while not convergence
</bodyText>
<listItem confidence="0.855264083333333">
1. Word decoding of x. A source-language sen-
tence sˆ is searched for using a source lan-
guage model that depends on the target sen-
tence, PrN ,˘t(s), for Pr(s  |t) (˘t is the tˆ com-
puted in the previous iteration) and the corre-
sponding HMMs, PrM(x  |s), to model Pr(x |
s):
( )
PrN ,˘t(s) · PrM(x  |s) .
2. Translation of ˆs. A target-language sentence tˆ
is searched for using a SFST, PrT (ˆs, t), as a
model of Pr(ˆs, t)
</listItem>
<equation confidence="0.9707535">
tˆ Pz� argmax
t
</equation>
<bodyText confidence="0.938219428571428">
end of while
The first iteration corresponds to the sequential ar-
chitecture proposed above.
While this seems a promising idea, only very
preliminary experiments were carried out (Garcia-
Varea et al., 2000) and it has not been considered in
the experiments presented in the present paper.
</bodyText>
<sectionHeader confidence="0.993269" genericHeader="evaluation">
3 Experiments and results
</sectionHeader>
<bodyText confidence="0.999979202898551">
Three sets of speech-to-speech translation proto-
types have been implemented for Spanish to English
and for Italian to English. In all of them, the appli-
cation was the translation of queries, requests and
complaints made by telephone to the front desk of
a hotel. Three tasks of different degree of difficulty
have been considered.
In the first one (EUTRANS-0), Spanish-to-English
translation systems were learned from a big and
well controlled training corpus: about 170k differ-
ent pairs (Pz� 2M running words), with a lexicon of
about 700 words. In the second one (EUTRANS-
I), also from Spanish to English, the systems were
learned from a random subset of 10k pairs (Pz� 100k
running words) from the previous corpus; this was
established as a more realistic training corpus for the
kind of application considered. In the third and most
difficult one, from Italian to English (EUTRANS-II),
the systems were learned from a small training cor-
pus that was obtained from a transcription of a spon-
taneous speech corpus: about 3k pairs (Pz� 60k run-
ning words), with a lexicon of about 2,500 words.
For the serial architecture, the speech decoding
was performed in a conventional way, using the
same acoustic models as with the integrated archi-
tecture and trigrams of the source language models.
For the integrated architecture, the speech decoding
of an utterance is a sub-product of the translation
process (the sequence of source words associated to
the optimal sequence of transitions that produces the
sequence of target words).
The acoustic models of phone units were trained
with the HTK Toolkit (Woodland, 1997). For the
EUTRANS-0 and EUTRANS-I prototypes, a training
speech corpus of 57,000 Spanish running words was
used, while the EUTRANS-II Italian acoustic models
were trained from another corpus of 52,000 running
words
Performance was assessed on the base of 336
Spanish sentences in the case of EUTRANS-0
and EUTRANS-I and 278 Italian sentences in
EUTRANS-II. In all the cases, the test sentences (as
well as the corresponding speakers) were different
from those appearing in the training data.
For the easiest task, EUTRANS-0, (well controlled
and a large training set), the best result was achieved
with an integrated architecture and a SFST obtained
with the OMEGA learning technique. A Transla-
tion Word Error Rate of 7.6% was achieved, while
the corresponding source-language speech decoding
Word Error Rate was 8.4%. Although these figures
may seem strange (and they would certainly be in
the case of a serial architecture), they are in fact con-
sistent with the fact that, in this task (corpus), the tar-
get language exhibits a significantly lower perplex-
ity than the source language.
For the second, less easy task EUTRANS-I, (well
controlled task but a small training set), the best
result was achieved with an integrated architecture
and a SFST obtained with the MGTI learning tech-
nique (10.5% of word error rate corresponding to the
speech decoding and 12.6% of translation word er-
ror rate).
For the most difficult task, EUTRANS-II (spon-
taneous task and a small training set), the best result
was achieved with a serial architecture and a SFST
obtained with the MGTI learning technique (22.1%
of word error rate corresponding to the speech de-
coding and 37.9% of translation word error rate).
</bodyText>
<figure confidence="0.9710682">
sˆ Pz� argmax
s
PrT (ˆs, t).
4 Conclusions of the North American Chapter of the Association for
Computational Linguistics.
</figure>
<bodyText confidence="0.999670481481481">
Several systems have been implemented for speech-
to-speech translation based on SFSTs. Some of them
were implemented for translation from Italian to En-
glish and the others for translation from Spanish to
English. All of them support all kinds of finite-state
translation models and run on low-cost hardware.
They are currently accessible through standard tele-
phone lines with response times close to or better
than real time.
From the results presented, it appears that the in-
tegrated architecture allows for the achievement of
better results than the results achieved with a serial
architecture when enough training data is available
to train the SFST. However, when the training data
is insufficient, the results obtained by the serial ar-
chitecture were better than the results obtained by
the integrated architecture. This effect is possible
because the source language models for the exper-
iments with the serial architecture were smoothed
trigrams. In the case of sufficient training data, the
source language model associated to a SFST learnt
by the MGTI or OMEGA is better than trigrams
(Section 2.1). However, in the other case (not suf-
ficient training data) these source languages were
worse than trigrams. Consequently an important
degradation is produced in the implicit decoding of
the input utterance.
</bodyText>
<sectionHeader confidence="0.998965" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9996605">
The authors would like to thank the researchers that
participated in the EUTRANS project and have de-
veloped the methodologies that are presented in this
paper.
This work has been partially supported by the Eu-
ropean Union under grant IT-LTR-OS-30268, by the
project TT2 in the “IST, V Framework Programme”,
and Spanish project TIC 2000-1599-C02-01.
</bodyText>
<sectionHeader confidence="0.99962" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999493666666667">
S. Bangalore and G. Ricardi. 2000. Stochastic finite-
state models for spoken language machine translation.
In Workshop on Embeded Machine Translation Sys-
tems.
S. Bangalore and G. Ricardi. 2001. A finite-state ap-
proach to machine translation. In The Second Meeting
F. Casacuberta. 2000. Inference of finite-state trans-
ducers by using regular grammars and morphisms.
In Grammatical Inference: Algorithms and Applica-
tions, volume 1891 of Lecture Notes in Artificial Intel-
ligence, pages 1–14. Springer-Verlag.
I. Garcia-Varea, A. Sanchis, and F. Casacuberta. 2000.
A new approach to speech-input statistical translation.
In Proceedings of the International Conference on Pat-
tern Recognition (ICPR2000), volume 2, pages 907–
910, Barcelona, Sept. IAPR, IEEE Press.
D. Llorens. 2000. Suavizado de aut´omatas y traduc-
tores finitos estoc´asticos. Ph.D. thesis, Universitat
Polit`ecnica de Val`encia.
H. Ney, S. Nießen, F. Och, H. Sawaf, C. Tillmann, and
S. Vogel. 2000. Algorithms for statistical translation
of spoken language. IEEE Transactions on Speech and
Audio Processing, 8(1):24–36.
H. Ney. 1999. Speech translation: Coupling of recogni-
tion and translation. In Proceedins of the IEEE Inter-
national Conference on Acoustic, Speech and Signal
Processing, pages 517–520, Phoenix, AR, March.
D. Pic´o and F. Casacuberta. 2001. Some statistical-
estimation methods for stochastic finite-state transduc-
ers. Machine Learning, 44:121–141.
J.M. Vilar. 2000. Improve the learning of subsequen-
tial transducers by using alignments and dictionaries.
In Grammatical Inference: Algorithms and Applica-
tions, volume 1891 of Lenture Notes in Artificial Intel-
ligence, pages 298–312. Springer-Verlag.
S. Young; J. Odell; D. Ollason; V. Valtchev; P. Wood-
land. 1997. The HTK Book (Version 2.1). Cambridge
University Department and Entropic Research Labora-
tories Inc.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.271459">
<note confidence="0.944808">Proceedings of the Workshop on Speech-to-Speech Translation: Algorithms and Systems, Philadelphia, July 2002, pp. 39-44. Association for Computational Linguistics.</note>
<title confidence="0.8093065">Architectures for speech-to-speech translation using finite-state models</title>
<author confidence="0.999913">Juan Miguel Vilar</author>
<affiliation confidence="0.9761745">Dpt. de Llenguatges i Sistemes Universitat Jaume</affiliation>
<address confidence="0.702535">Castell´o,</address>
<email confidence="0.906904">jvilar@lsi.uji.es</email>
<author confidence="0.998289">Francisco Casacuberta Enrique Vidal</author>
<affiliation confidence="0.970342">Dpt. de Sistemes Inform`atics i Computaci´o Institut Tecnol`ogic Universitat Polit`ecnica de</affiliation>
<address confidence="0.990994">46071 Val`encia,</address>
<email confidence="0.989559">fcn@iti.upv.es,evidal@iti.upv.es</email>
<abstract confidence="0.998990103448276">Speech-to-speech translation can be approached using finite state models and several ideas borrowed from automatic speech recognition. The models can be Hidden Markov Models for the accoustic part, language models for the source language and finite state transducers for the transfer between the source and target language. A “serial architecture” would use the Hidden Markov and the language models for recognizing input utterance and the transducer for finding the translation. An “integrated architecture”, on the other hand, would integrate all the models in a single network where the search process takes place. The output of this search process is the target word sequence associated to the optimal path. In both architectures, HMMs can be trained from a source-language speech corpus, and the translation model can be learned automatically from a parallel text training corpus. The experiments presented here correspond to speech-input translations from Spanish to English and from Italian to English, in applications involving the interaction (by telephone) of a customer with the front-desk of a hotel.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Bangalore</author>
<author>G Ricardi</author>
</authors>
<title>Stochastic finitestate models for spoken language machine translation.</title>
<date>2000</date>
<booktitle>In Workshop on Embeded Machine Translation Systems.</booktitle>
<contexts>
<context position="2744" citStr="Bangalore and Ricardi, 2000" startWordPosition="396" endWordPosition="399">ite-state transducer (SFST). Thanks to this integration, the translation process can be efficiently performed by searching for an optimal path of states through the integrated network by using well-known optimization procedures such as (beam-search accelerated) Viterbi search. This “integrated architecture” can be compared with the more conventional “serial architecture”, where the HMMs, along with a suitable source language model, are used as a front-end to recognize a sequence of source-language words which is then processed by the translation model. A related approach has been proposed in (Bangalore and Ricardi, 2000; Bangalore and Ricardi, 2001). In any case, a pure pattern-recognition approach can be followed to build the required systems. Acoustic models can be trained from a sufficiently large source-language speech training set, in the very same way as in speech recognition. On the other hand, using adequate learning algorithms (Casacuberta, 2000; Vilar, 2000), the translation model can also be learned from a sufficiently large training set consisting of source-target parallel text. In this paper, we comment the results obtained using this approach in EUTRANS, a five-year joint effort of four Europea</context>
</contexts>
<marker>Bangalore, Ricardi, 2000</marker>
<rawString>S. Bangalore and G. Ricardi. 2000. Stochastic finitestate models for spoken language machine translation. In Workshop on Embeded Machine Translation Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bangalore</author>
<author>G Ricardi</author>
</authors>
<title>A finite-state approach to machine translation.</title>
<date>2001</date>
<booktitle>In The Second Meeting</booktitle>
<contexts>
<context position="2774" citStr="Bangalore and Ricardi, 2001" startWordPosition="400" endWordPosition="403">Thanks to this integration, the translation process can be efficiently performed by searching for an optimal path of states through the integrated network by using well-known optimization procedures such as (beam-search accelerated) Viterbi search. This “integrated architecture” can be compared with the more conventional “serial architecture”, where the HMMs, along with a suitable source language model, are used as a front-end to recognize a sequence of source-language words which is then processed by the translation model. A related approach has been proposed in (Bangalore and Ricardi, 2000; Bangalore and Ricardi, 2001). In any case, a pure pattern-recognition approach can be followed to build the required systems. Acoustic models can be trained from a sufficiently large source-language speech training set, in the very same way as in speech recognition. On the other hand, using adequate learning algorithms (Casacuberta, 2000; Vilar, 2000), the translation model can also be learned from a sufficiently large training set consisting of source-target parallel text. In this paper, we comment the results obtained using this approach in EUTRANS, a five-year joint effort of four European institutions, partially fund</context>
</contexts>
<marker>Bangalore, Ricardi, 2001</marker>
<rawString>S. Bangalore and G. Ricardi. 2001. A finite-state approach to machine translation. In The Second Meeting</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Casacuberta</author>
</authors>
<title>Inference of finite-state transducers by using regular grammars and morphisms.</title>
<date>2000</date>
<booktitle>In Grammatical Inference: Algorithms and Applications,</booktitle>
<volume>1891</volume>
<pages>1--14</pages>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="3085" citStr="Casacuberta, 2000" startWordPosition="451" endWordPosition="452"> “serial architecture”, where the HMMs, along with a suitable source language model, are used as a front-end to recognize a sequence of source-language words which is then processed by the translation model. A related approach has been proposed in (Bangalore and Ricardi, 2000; Bangalore and Ricardi, 2001). In any case, a pure pattern-recognition approach can be followed to build the required systems. Acoustic models can be trained from a sufficiently large source-language speech training set, in the very same way as in speech recognition. On the other hand, using adequate learning algorithms (Casacuberta, 2000; Vilar, 2000), the translation model can also be learned from a sufficiently large training set consisting of source-target parallel text. In this paper, we comment the results obtained using this approach in EUTRANS, a five-year joint effort of four European institutions, partially funded by the European Union. t1 2 Finite-state transducers and speech translation The statistical framework allow us to formulate the speech translation problem as follows: Let x be an acoustic representation of a given utterance; typically a sequence of acoustic vectors or “frames”. The translation of x into a t</context>
<context position="7186" citStr="Casacuberta, 2000" startWordPosition="1218" endWordPosition="1219">ample of SFST. A denotes the empty string. The source sentence “una habitaci´on doble” can be translated to either “a double room” or “a room with two beds”. The most probable translation is the first one with probability of 0.09. habitación / room (0.1) 2 doble / with two beds (1) una / a (0.5) 0 1 habitación / room (0.3) la / the (0.5) habitación / λ (0.6) doble / double room (0.3) 4 3 individual / single room (0.7) The structural (states and transitions) and the probabilistic components of a SFST can be learned automatically from training pairs in a single process using the MGTI technique (Casacuberta, 2000). Alternatively, the structural component can be learned using the OMEGA technique (Vilar, 2000), while the probabilistic component is estimated in a second step using maximum likelihood or other possible criteria (Pic´o and Casacuberta, 2001). One of the main problems that appear during the learning process is the modelling of events that have not been seen in the training set. This problem can be confronted, in a similar way as in language modelling, by using smoothing techniques in the estimation process of the probabilistic components of the SFST (Llorens, 2000). Alternatively, smoothing c</context>
</contexts>
<marker>Casacuberta, 2000</marker>
<rawString>F. Casacuberta. 2000. Inference of finite-state transducers by using regular grammars and morphisms. In Grammatical Inference: Algorithms and Applications, volume 1891 of Lecture Notes in Artificial Intelligence, pages 1–14. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Garcia-Varea</author>
<author>A Sanchis</author>
<author>F Casacuberta</author>
</authors>
<title>A new approach to speech-input statistical translation.</title>
<date>2000</date>
<booktitle>In Proceedings of the International Conference on Pattern Recognition (ICPR2000),</booktitle>
<volume>2</volume>
<pages>907--910</pages>
<publisher>IAPR, IEEE Press.</publisher>
<location>Barcelona,</location>
<contexts>
<context position="12321" citStr="Garcia-Varea et al., 2000" startWordPosition="2175" endWordPosition="2178">d decoding of x. A source-language sentence sˆ is searched for using a source language model, PrN(s), for Pr(s) and the corresponding HMMs, PrM(x|s), to model Pr(x|s): sˆ ≈ argmax (PrN(s) · PrM(x|s)) . s 2. Translation of ˆs. A target-language sentence tˆ is searched for using a SFST, PrT (ˆs, t), as a model of Pr(ˆs, t) tˆ ≈ argmax t The main problem of this approach is the term t that appears in the first maximisation (Eq. 16). A possible solution is to follow an iterative procedure where t, that is used for computing ˆs, is the one obtained from argmaxt Pr(ˆs, t) in the previous iteration (Garcia-Varea et al., 2000). In this case, Pr(s |t) can be modelled by a source language model that depends on a previously computed ˜t: PrN,˜t(s). In the first iteration no tˆ is known, but PrN,˜t(s) can be approximated by PrN(s). Following this idea, the search can be formulated as: Initialization: Let PrN ,t(s) be approximated by a source language model PrN(s). PrT (ˆs, t). while not convergence 1. Word decoding of x. A source-language sentence sˆ is searched for using a source language model that depends on the target sentence, PrN ,˘t(s), for Pr(s |t) (˘t is the tˆ computed in the previous iteration) and the corres</context>
</contexts>
<marker>Garcia-Varea, Sanchis, Casacuberta, 2000</marker>
<rawString>I. Garcia-Varea, A. Sanchis, and F. Casacuberta. 2000. A new approach to speech-input statistical translation. In Proceedings of the International Conference on Pattern Recognition (ICPR2000), volume 2, pages 907– 910, Barcelona, Sept. IAPR, IEEE Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Llorens</author>
</authors>
<title>Suavizado de aut´omatas y traductores finitos estoc´asticos.</title>
<date>2000</date>
<tech>Ph.D. thesis,</tech>
<institution>Universitat Polit`ecnica de Val`encia.</institution>
<contexts>
<context position="7758" citStr="Llorens, 2000" startWordPosition="1309" endWordPosition="1310">ing the MGTI technique (Casacuberta, 2000). Alternatively, the structural component can be learned using the OMEGA technique (Vilar, 2000), while the probabilistic component is estimated in a second step using maximum likelihood or other possible criteria (Pic´o and Casacuberta, 2001). One of the main problems that appear during the learning process is the modelling of events that have not been seen in the training set. This problem can be confronted, in a similar way as in language modelling, by using smoothing techniques in the estimation process of the probabilistic components of the SFST (Llorens, 2000). Alternatively, smoothing can be applied in the process of learning both components (Casacuberta, 2000). 2.2 Architectures for speech translation Using Eq. 7 as a model for Pr(s, t) in Eq. 4, !PrT (φ) · PrM(x|s) , (8) For the computation of PrM(x|s) in Eq. 8, let b be an arbitrary segmentation of x into I acoustic subsequences, each of which associated with a source word (therefore, I is the number of words in s). Then: I PrM(x|s) = X Y PrM(¯xi|si), (9) b i=1 where ¯xi is the i-th. acoustic segment of b, and each source word si has an associated HMM that supplies the density value PrM(¯xi|si)</context>
</contexts>
<marker>Llorens, 2000</marker>
<rawString>D. Llorens. 2000. Suavizado de aut´omatas y traductores finitos estoc´asticos. Ph.D. thesis, Universitat Polit`ecnica de Val`encia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Ney</author>
<author>S Nießen</author>
<author>F Och</author>
<author>H Sawaf</author>
<author>C Tillmann</author>
<author>S Vogel</author>
</authors>
<title>Algorithms for statistical translation of spoken language.</title>
<date>2000</date>
<journal>IEEE Transactions on Speech and Audio Processing,</journal>
<volume>8</volume>
<issue>1</issue>
<contexts>
<context position="3924" citStr="Ney et al., 2000" startWordPosition="586" endWordPosition="589">ive-year joint effort of four European institutions, partially funded by the European Union. t1 2 Finite-state transducers and speech translation The statistical framework allow us to formulate the speech translation problem as follows: Let x be an acoustic representation of a given utterance; typically a sequence of acoustic vectors or “frames”. The translation of x into a target-language sentence can be formulated as the search for a word sequence, ˆt, from the target language such that: tˆ = argmax t Pr(t|x). (1) Conceptually, the translation can be viewed as a two-step process (Ney, 1999; Ney et al., 2000): x — *s — *t, where s is a sequence of source-language words which would match the observed acoustic sequence x and t is a target-language word sequence associated with s. Consequently, Pr(t|x) = X Pr(t, s|x), (2) s and, with the natural assumption that Pr(x|s, t) does not depend on the target sentence t, Xtˆ = argmax !Pr(s, t) · Pr(x|s) . (3) t s Using a SFST as a model for Pr(s, t) and HMMs to model Pr(x|s), Eq. 3 is transformed in the optimization problem: for q,q0 E Q, a E Σ, ω E Δ* and1P : R —* IR+ IR+(finalstate probabilities) are functions such that bq E Q: F(q) + X P (q, a, ω, q0) = 1</context>
</contexts>
<marker>Ney, Nießen, Och, Sawaf, Tillmann, Vogel, 2000</marker>
<rawString>H. Ney, S. Nießen, F. Och, H. Sawaf, C. Tillmann, and S. Vogel. 2000. Algorithms for statistical translation of spoken language. IEEE Transactions on Speech and Audio Processing, 8(1):24–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Ney</author>
</authors>
<title>Speech translation: Coupling of recognition and translation.</title>
<date>1999</date>
<booktitle>In Proceedins of the IEEE International Conference on Acoustic, Speech and Signal Processing,</booktitle>
<pages>517--520</pages>
<location>Phoenix, AR,</location>
<contexts>
<context position="3905" citStr="Ney, 1999" startWordPosition="584" endWordPosition="585">UTRANS, a five-year joint effort of four European institutions, partially funded by the European Union. t1 2 Finite-state transducers and speech translation The statistical framework allow us to formulate the speech translation problem as follows: Let x be an acoustic representation of a given utterance; typically a sequence of acoustic vectors or “frames”. The translation of x into a target-language sentence can be formulated as the search for a word sequence, ˆt, from the target language such that: tˆ = argmax t Pr(t|x). (1) Conceptually, the translation can be viewed as a two-step process (Ney, 1999; Ney et al., 2000): x — *s — *t, where s is a sequence of source-language words which would match the observed acoustic sequence x and t is a target-language word sequence associated with s. Consequently, Pr(t|x) = X Pr(t, s|x), (2) s and, with the natural assumption that Pr(x|s, t) does not depend on the target sentence t, Xtˆ = argmax !Pr(s, t) · Pr(x|s) . (3) t s Using a SFST as a model for Pr(s, t) and HMMs to model Pr(x|s), Eq. 3 is transformed in the optimization problem: for q,q0 E Q, a E Σ, ω E Δ* and1P : R —* IR+ IR+(finalstate probabilities) are functions such that bq E Q: F(q) + X </context>
</contexts>
<marker>Ney, 1999</marker>
<rawString>H. Ney. 1999. Speech translation: Coupling of recognition and translation. In Proceedins of the IEEE International Conference on Acoustic, Speech and Signal Processing, pages 517–520, Phoenix, AR, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Pic´o</author>
<author>F Casacuberta</author>
</authors>
<title>Some statisticalestimation methods for stochastic finite-state transducers.</title>
<date>2001</date>
<booktitle>Machine Learning,</booktitle>
<pages>44--121</pages>
<marker>Pic´o, Casacuberta, 2001</marker>
<rawString>D. Pic´o and F. Casacuberta. 2001. Some statisticalestimation methods for stochastic finite-state transducers. Machine Learning, 44:121–141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Vilar</author>
</authors>
<title>Improve the learning of subsequential transducers by using alignments and dictionaries.</title>
<date>2000</date>
<booktitle>In Grammatical Inference: Algorithms and Applications,</booktitle>
<volume>1891</volume>
<pages>298--312</pages>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="3099" citStr="Vilar, 2000" startWordPosition="453" endWordPosition="454">re”, where the HMMs, along with a suitable source language model, are used as a front-end to recognize a sequence of source-language words which is then processed by the translation model. A related approach has been proposed in (Bangalore and Ricardi, 2000; Bangalore and Ricardi, 2001). In any case, a pure pattern-recognition approach can be followed to build the required systems. Acoustic models can be trained from a sufficiently large source-language speech training set, in the very same way as in speech recognition. On the other hand, using adequate learning algorithms (Casacuberta, 2000; Vilar, 2000), the translation model can also be learned from a sufficiently large training set consisting of source-target parallel text. In this paper, we comment the results obtained using this approach in EUTRANS, a five-year joint effort of four European institutions, partially funded by the European Union. t1 2 Finite-state transducers and speech translation The statistical framework allow us to formulate the speech translation problem as follows: Let x be an acoustic representation of a given utterance; typically a sequence of acoustic vectors or “frames”. The translation of x into a target-language</context>
<context position="7282" citStr="Vilar, 2000" startWordPosition="1232" endWordPosition="1233">ed to either “a double room” or “a room with two beds”. The most probable translation is the first one with probability of 0.09. habitación / room (0.1) 2 doble / with two beds (1) una / a (0.5) 0 1 habitación / room (0.3) la / the (0.5) habitación / λ (0.6) doble / double room (0.3) 4 3 individual / single room (0.7) The structural (states and transitions) and the probabilistic components of a SFST can be learned automatically from training pairs in a single process using the MGTI technique (Casacuberta, 2000). Alternatively, the structural component can be learned using the OMEGA technique (Vilar, 2000), while the probabilistic component is estimated in a second step using maximum likelihood or other possible criteria (Pic´o and Casacuberta, 2001). One of the main problems that appear during the learning process is the modelling of events that have not been seen in the training set. This problem can be confronted, in a similar way as in language modelling, by using smoothing techniques in the estimation process of the probabilistic components of the SFST (Llorens, 2000). Alternatively, smoothing can be applied in the process of learning both components (Casacuberta, 2000). 2.2 Architectures </context>
</contexts>
<marker>Vilar, 2000</marker>
<rawString>J.M. Vilar. 2000. Improve the learning of subsequential transducers by using alignments and dictionaries. In Grammatical Inference: Algorithms and Applications, volume 1891 of Lenture Notes in Artificial Intelligence, pages 298–312. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Young</author>
<author>J Odell</author>
<author>D Ollason</author>
<author>V Valtchev</author>
<author>P Woodland</author>
</authors>
<date>1997</date>
<journal>The HTK Book (Version</journal>
<volume>2</volume>
<institution>Cambridge University Department and Entropic Research Laboratories Inc.</institution>
<marker>Young, Odell, Ollason, Valtchev, Woodland, 1997</marker>
<rawString>S. Young; J. Odell; D. Ollason; V. Valtchev; P. Woodland. 1997. The HTK Book (Version 2.1). Cambridge University Department and Entropic Research Laboratories Inc.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>