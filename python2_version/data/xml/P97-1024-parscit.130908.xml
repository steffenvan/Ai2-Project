<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000033">
<title confidence="0.981355">
Independence Assumptions Considered Harmful
</title>
<author confidence="0.912327">
Alexander Franz
</author>
<affiliation confidence="0.783909">
Sony Computer Science Laboratory &amp; D21 Laboratory
Sony Corporation
</affiliation>
<address confidence="0.9563345">
6-7-35 Kitashinagawa
Shinagawa-ku, Tokyo 141, Japan
</address>
<email confidence="0.998255">
amf@csl.sony.co.jp
</email>
<sectionHeader confidence="0.989449" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998296142857143">
Many current approaches to statistical lan-
guage modeling rely on independence as-
sumptions between the different, explana-
tory variables. This results in models
which are computationally simple, but
which only model the main effects of the
explanatory variables on the response vari-
able. This paper presents an argument in
favor of a statistical approach that also
models the interactions between the ex-
planatory variables. The argument rests
on empirical evidence from two series of ex-
periments concerning automatic ambiguity
resolution.
</bodyText>
<sectionHeader confidence="0.995587" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999372315789474">
In this paper. we present an empirical argument in
favor of a certain approach to statistical natural lan-
guage modeling: we advocate statistical natural lan-
guage models that account for the interactions be-
tween the explanatory statistical variables, rather
than relying on independence assumptions. Such
models are able to perform prediction on the basis of
estimated probability distributions that are properly
conditioned on the combinations of the individual
values of the explanatory variables.
After describing one type of statistical model that
is particularly well-suited to modeling natural lan-
guage data, called a loglinear model, we present em-
pirical evidence from a series of experiments on dif-
ferent ambiguity resolution tasks that show that the
performance of the loglinear models outranks the
performance of other models described in the lit-
erature that. assume independence between the ex-
planatory variables.
</bodyText>
<sectionHeader confidence="0.971707" genericHeader="method">
2 Statistical Language Modeling
</sectionHeader>
<bodyText confidence="0.999433714285714">
By -statistical language model&amp;quot;, we refer to a mathe-
matical object that &amp;quot;imitates the properties&amp;quot; of some
aspects of natural language, and in turn makes pre-
dictions that. are useful from a scientific or engineer-
ing point of view. Much recent work in this frame-
work has used written and spoken natural language
data to estimate parameters for statistical models
that were characterized by serious limitations: mod-
els were either limited to a single explanatory vari-
able or. if more than one explanatory variable was
considered, the variables were assumed to be inde-
pendent,. In this section, we describe a method for
statistical language modeling that transcends these
limitations.
</bodyText>
<subsectionHeader confidence="0.948983">
2.1 Categorical Data Analysis
</subsectionHeader>
<bodyText confidence="0.997420076923077">
Categorical data analysis is the area of statistics that
addresses categorical statistical variable: variables
whose values are one of a set of categories. An exam-
ple of such a linguistic variable is PART-OF-SPEECH,
whose possible values might include noun, verb, de-
terminer. preposition. etc.
We distinguish between a set of explanatory vari-
ables. and one response variable. A statistical model
can be used to perform prediction in the following
manner: Given the values of the explanatory vari-
ables. what. is the probability distribution for the
response variable. i.e.. what are the probabilities for
the different. possible values of the response variable?
</bodyText>
<subsectionHeader confidence="0.980939">
2.2 The Contingency Table
</subsectionHeader>
<bodyText confidence="0.992488571428571">
The basic tool used in categorical data analysis is
the contingency table (sometimes called the &amp;quot;cross-
classified table of counts&amp;quot;). A contingency table is a
matrix with one dimension for each variable, includ-
ing the response variable. Each cell in the contin-
gency table records the frequency of data with the
appropriate characteristics.
Since each cell concerns a specific combination of
features, this provides a way to estimate probabil-
ities of specific feature combinations from the ob-
served frequencies, as the cell counts can easily be
converted to probabilities. Prediction is achieved by
determining the value of the response variable given
the values of the explanatory variables.
</bodyText>
<page confidence="0.992571">
182
</page>
<subsectionHeader confidence="0.907956">
2.3 The Loglinear Model
</subsectionHeader>
<bodyText confidence="0.996408823529412">
A loglinear model is a statistical model of the effect
of a set of categorical variables and their combina-
tions on the cell counts in a contingency table. It can
be used to address the problem of sparse data, since
it can act as a &amp;quot;smoothing device, used to obtain
cell estimates for every cell in a sparse array, even if
the observed count is zero- (Bishop. Fienberg, and
Holland. 1975).
Marginal totals (sums for all values of some vari-
ables) of the observed counts are used to estimate
the parameters of the loglinear model: the model in
turn delivers estimated expected cell counts, which
are smoother than the original cell counts.
The mathematical form of a loglinear model is as
follows. Let ?nip,: be the expected cell count for cell
(i. j. k.... ) in the contingency table. The general
form of a loglinear model is as follows:
</bodyText>
<equation confidence="0.988936">
logrnjj.= u+ui( -i-u2(i) -Eu3( +u12( + (1)
</equation>
<bodyText confidence="0.99996008">
In this formula, u denotes the mean of the logarithms
of all the expected counts. u+ul(i) denotes the mean
of the logarithms of the expected counts with value
i of the first variable, u + u2(i) denotes the mean of
the logarithms of the expected counts with value j of
the second variable, u + u12(j.1) denotes the mean of
the logarithms of the expected counts with value i of
the first veriable and value j of the second variable,
and so on.
Thus, the term U1(j) denotes the deviation of the
mean of the expected cell counts with value i of the
first variable from the grand mean u. Similarly, the
term 1/12(ji) denotes the deviation of the mean of the
expected cell counts with value i of the first variable
and value j of the second variable from the grand
mean u. In other words, u12(ii) represents the com-
bined effect of the values i and j for the first and
second variables on the logarithms of the expected
cell counts.
In this way, a loglinear model provides a way to
estimate expected cell counts that depend not only
on the main effects of the variables, but also on
the interactions between variables. This is achieved
by adding &amp;quot;interaction terms- such as U12(j) to the
model. For further details, see (Fienberg, 1980).
</bodyText>
<subsectionHeader confidence="0.99817">
2.4 The Iterative Estimation Procedure
</subsectionHeader>
<bodyText confidence="0.996985">
For some loglinear models, it is possible to obtain
closed forms for the expected cell counts. For more
complicated models. the iterative proportional fitting
algorithm for hierarchical loglinear models (Deming
and Stephan, 1940) can be used. Briefly, this proce-
dure works as follows.
Let the values for the expected cell counts that are
estimated by the model be represented by the sym-
bol The interaction terms in the loglinear
models represent constraints on the estimated ex-
pected marginal totals. Each of these marginal con-
straints translates into an adjustment scaling factor
for the cell entries. The iterative procedure has the
following steps:
</bodyText>
<listItem confidence="0.99101475">
1. Start with initial estimates for the estimated ex-
pected cell counts. For example, set all 7hijki =
1.0.
2. Adjust each cell entry by multiplying it by the
scaling factors. This moves the cell entries to-
wards satisfaction of the marginal constraints
specified by the model.
3. Iterate through the adjustment steps until the
maximum difference f. between the marginal
totals observed in the sample and the esti-
mated marginal totals reaches a certain mini-
mum threshold. e.g. e = 0.1.
</listItem>
<bodyText confidence="0.998622285714286">
After each cycle, the estimates satisfy the con-
straints specified in the model, and the estimated
expected marginal totals come closer to matching
the observed totals. Thus, the process converges.
This results in Maximum Likelihood estimates for
both multinomial and independent Poisson sampling
schemes (Agresti, 1990).
</bodyText>
<subsectionHeader confidence="0.999092">
2.5 Modeling Interactions
</subsectionHeader>
<bodyText confidence="0.999976714285714">
For natural language classification and prediction
tasks, the aim is to estimate a conditional proba-
bility distribution P(HIE) over the possible values
of the hypothesis H, where the evidence E consists
of a number of linguistic features el, e2, .... Much of
the previous work in this area assumes independence
between the linguistic features:
</bodyText>
<equation confidence="0.997285">
P(Hlei.ei,• • .) P(He) x P(Hlei) x ... (2)
</equation>
<bodyText confidence="0.9998635">
For example. a model to predict Part-of-Speech of
a word on the basis of its morphological affix and its
capitalization might assume independence between
the two explanatory variables as follows:
</bodyText>
<equation confidence="0.9996125">
P(POSIAFFIX, CAPITALIZATION) (3)
P(POSIAFFIX) x P(POSICAPITALIZATION)
</equation>
<bodyText confidence="0.9968684">
This results in a considerable computational sim-
plification of the model but, as we shall see below.
leads to a considerable loss of information and con-
comitant decrease in prediction accuracy. With a
loglinear model, on the other hand, such indepen-
dence assumptions are not necessary. The loglinear
model provides a posterior distribution that is prop-
erly conditioned on the evidence, and maximizing
the conditional probability P(HIE) leads to mini-
mum error rate classification (Duda and Hart. 1973).
</bodyText>
<page confidence="0.993529">
183
</page>
<figure confidence="0.571884">
Overall Accuracy
F=0.4 Set Accuracy
3 Predicting Part-of-Speech 4 919opentlent Feeturos • Independent Feetufee I
</figure>
<bodyText confidence="0.998654555555556">
We will now turn to the empirical evidence support- • Looneer Fes99•• II al Lochnear Features I
ing the argument against independence assumptions. 1 11. 9 Lapknow Features
In this section, we will compare two models for pre- 9 Lopfinear Features
dicting the Part-of-Speech of an unknown word: A
simple model that treats the various explanatory
variables as independent, and a model using log-
linear smoothing of a contingency table that takes
into account the interactions between the explana-
tory variables.
</bodyText>
<subsectionHeader confidence="0.99986">
3.1 Constructing the Model
</subsectionHeader>
<bodyText confidence="0.9990448">
The model was constructed in the following way.
First, features that could be used to guess the POS
of a word were determined by examining the training
portion of a text corpus. The initial set of features
consisted of the following:
</bodyText>
<listItem confidence="0.997626727272727">
• INCLUDES-NUMBER. Does the word include a
number?
• CAPITALIZED. Is the word in sentence-initial po-
sition and capitalized, in any other position and
capitalized, or in lower case&apos;?
• INCLUDES-PERIOD. Does the word include a pe-
riod&apos;?
• INCLUDES-COMMA. Does the word include a
comma.
• FINAL-PERIOD. Is the last character of the word
a period?
• INCLUDES-HYPHEN. Does the word include a
hyphen?
• ALL-UPPER-CASE. Is the word in all upper case?
• SHORT. Is the length of the word three charac-
ters or less?
• INFLECTION. Does the word carry one of the
English inflectional suffixes?
• PREFIX. Does the word carry one of a list of
frequently occurring prefixes?
• SUFFIX. Does the word carry one of a list of
frequently occurring suffixes&apos;?
</listItem>
<bodyText confidence="0.999778428571429">
Next, exploratory data analysis was performed in
order to determine relevant features and their values,
and to approximate which features interact. Each
word of the training data was then turned into a
feature vector, and the feature vectors were cross-
classified in a contingency table. The contingency
table was smoothed using a loglinear models.
</bodyText>
<subsectionHeader confidence="0.999314">
3.2 Data
</subsectionHeader>
<bodyText confidence="0.998701166666667">
Training and evaluation data was obtained from the
Penn Treebank Brown corpus (Marcus. Santorini.
and Marcinkiewicz. 1993). The characteristics of
*rare&amp;quot; words that might show up as unknown words
differ from the characteristics of words in general.
so a two-step procedure was employed a first time
</bodyText>
<figureCaption confidence="0.999625">
Figure 1: Performance of Different Models
</figureCaption>
<bodyText confidence="0.9969127">
to obtain a set of -rare&amp;quot; words as training data, and
again a second time to obtain a separate set of -rare&amp;quot;
words as evaluation data. There were 17,000 words
in the training data, and 21.000 words in the evalua-
tion data. Ambiguity resolution accuracy was evalu-
ated for the -overall accuracy&amp;quot; (Percentage that the
most likely POS tag is correct), and -cutoff factor
accuracy&amp;quot; (accuracy of the answer set consisting of
all POS tags whose probability lies within a factor
F of the most likely POS (de Marcken, 1990)).
</bodyText>
<subsectionHeader confidence="0.999916">
3.3 Accuracy Results
</subsectionHeader>
<bodyText confidence="0.992660103448276">
(Weischedel et al.. 1993) describe a model for un-
known words that uses four features, but treats the
features as independent. We reimplemented this
model by using four features: POS. INFLECTION.
CAPITALIZED, and HYPHENATED. In Figures 1 2,
the results for this model are labeled 4 Indepen-
dent Features. For comparison, we created a log-
linear model with the same four features: the results
for this model are labeled 4 Loglinear Features.
The highest accuracy was obtained by the log-
linear model that includes all two-way interac-
tions and consists of two contingency tables with
the following features: POS, ALL-UPPER-CASE,
HYPHENATED. INCLUDES-NUMBER. CAPITALIZED,
INFLECTION, SHORT. PREFIX, and SUFFIX. The re-
sults for this model are labeled 9 Loglinear Fea-
tures. The parameters for all three unknown word
models were estimated from the training data, and
the models were evaluated on the evaluation data.
The accuracy of the different models in assigning
the most likely POSs to words is summarized in Fig-
ure 1. In the left diagram, the two barcharts show
two different accuracy measures: Percent correct
(Overall Accuracy). and percent correct within
the F=0.4 cutoff factor answer set (F=0.4 Set
Accuracy). In both cases, the loglinear model
with four features obtains higher accuracy than
the method that assumes independence between the
same four features. The loglinear model with nine
</bodyText>
<page confidence="0.973986">
184
</page>
<figure confidence="0.968026">
Unigram Probabilities
</figure>
<figureCaption confidence="0.999645">
Figure 2: Effect of Number of Features on Accuracy Figure 3: Error Rate on Unknown Words
</figureCaption>
<bodyText confidence="0.900445">
features further improves this score.
</bodyText>
<subsectionHeader confidence="0.7578915">
3.4 Effect of Number of Features on
Accuracy
</subsectionHeader>
<bodyText confidence="0.999974">
The performance of the loglinear model can be im-
proved by adding more features, but this is not pos-
sible with the simpler model that assumes indepen-
dence between the features. Figure 2 shows the
performance of the two types of models with fea-
ture sets that ranged from a single feature to nine
features.
As the diagram shows, the accuracies for both
methods rise with the first few features, but then
the two methods show a clear divergence. The ac-
curacy of the simpler method levels off around at
around 50-55%, while the loglinear model reaches
an accuracy of 70-75%. This shows that the loglin-
ear model is able to tolerate redundant features and
use information from more features than the simpler
method, and therefore achieves better results at am-
biguity resolution.
</bodyText>
<subsectionHeader confidence="0.962198">
3.5 Adding Context to the Model
</subsectionHeader>
<bodyText confidence="0.99968075">
Next, we added of a stochastic POS tagger (Char-
niak et al., 1993) to provide a model of context. A
stochastic POS tagger assigns POS labels to words
in a sentence by using two parameters:
</bodyText>
<listItem confidence="0.877386">
• Lexical Probabilities: P(0) the proba-
bility of observing word w given that the tag t
occurred.
• Contextual Probabilities: P(414_1, 4_2) —
the probability of observing tag 4 given that the
two previous tags 4_1, 4_2 occurred.
</listItem>
<bodyText confidence="0.952765">
The tagger maximizes the probability of the tag se-
</bodyText>
<equation confidence="0.7069118">
quence T t„ given the word sequence
W = w1, w2, , w„, which is approximated as fol-
lows:
TS
P(TIW) Hp(wiiti)p(tiiti_1,ti_2) (4)
</equation>
<bodyText confidence="0.9983078">
The accuracy of the combination of the loglinear
model for local features and the stochastic POS tag-
ger for contextual features was evaluated empirically
by comparing three methods of handling unknown
words:
</bodyText>
<listItem confidence="0.982739857142857">
• Unigram: Using the prior probability distri-
bution P(t) of the POS tags for rare words.
• Probabilistic UWM: Using the probabilistic
model that assumes independence between the
features.
• Classifier UWM: Using the loglinear model
for unknown words.
</listItem>
<bodyText confidence="0.998848833333333">
Separate sets of training and evaluation data for the
tagger were obtained from from the Penn Treebank
Wall Street corpus. Evaluation of the combined sys-
tem was performed on different configurations of the
POS tagger on 30-40 different samples containing
4,000 words each.
Since the tagger displays considerable variance in
its accuracy in assigning POS to unknown words in
context, we use boxplots to display the results. Fig-
ure 3 compares the tagging error rate on unknown
words for the unigram method (left) and the log-
linear method with nine features (labeled statisti-
cal classifier) at right. This shows that the loglin-
ear model significantly improves the Part-of-Speech
tagging accuracy of a stochastic tagger on unknown
words. The median error rate is lowered consider-
ably, and samples with error rates over 32% are elim-
inated entirely.
</bodyText>
<page confidence="0.976892">
185
</page>
<figure confidence="0.9534925">
10 15 20 25 30 35 40 45 50 55 SO
Persontag• 44 Unknown Wags
</figure>
<figureCaption confidence="0.989748">
Figure 4: Effect of Proportion of Unknown Words
on Overall Tagging Error Rate
</figureCaption>
<subsectionHeader confidence="0.474081">
3.6 Effect of Proportion of Unknown
Words
</subsectionHeader>
<bodyText confidence="0.9999674">
Since most of the lexical ambiguity resolution power
of stochastic POS tagging comes from the lexical
probabilities, unknown words represent a significant
source of error. Therefore, we investigated the effect
of different types of models for unknown words on
the error rate for tagging text with different propor-
tions of unknown words.
Samples of text that contained different propor-
tions of unknown words were tagged using the three
different methods for handling unknown words de-
scribed above. The overall tagging error rate in-
creases significantly as the proportion of new words
increases. Figure 4 shows a graph of overall tagging
accuracy versus percentage of unknown words in the
text. The graph compares the three different meth-
ods of handling unknown words. The diagram shows
that the loglinear model leads to better overall tag-
ging performance than the simpler methods, with a
clear separation of all samples whose proportion of
new words is above approximately 10%.
</bodyText>
<sectionHeader confidence="0.991571" genericHeader="method">
4 Predicting PP Attachment
</sectionHeader>
<bodyText confidence="0.99822825">
In the second series of experiments, we compare the
performance of different statistical models on the
task of predicting Prepositional Phrase (PP) attach-
ment.
</bodyText>
<sectionHeader confidence="0.70654" genericHeader="method">
4.1 Features for PP Attachment
</sectionHeader>
<bodyText confidence="0.9819475">
First, an initial set of linguistic features that could
be useful for predicting PP attachment was deter-
mined. The initial set included the following fea-
tures:
</bodyText>
<listItem confidence="0.8938185">
• PREPOSITION. Possible values of this feature in-
clude one of the more frequent prepositions in
the training set, or the value other-prep.
• VERB-LEVEL. Lexical association strength be-
tween the verb and the preposition.
• NOUN-LEVEL. Lexical association strength be-
tween the noun and the preposition.
• NOUN-TAG. Part-of-Speech of the nominal at-
tachment site. This is included to account for
correlations between attachment and syntactic
category of the nominal attachment site, such
as &amp;quot;PPs disfavor attachment to proper nouns.&amp;quot;
• NOUN-DEFINITENESS. Does the nominal attach-
ment site include a definite determiner? This
feature is included to account for a possible cor-
relation between PP attachment to the nom-
inal site and definiteness, which was derived
by (Hirst, 1986) from the principle of presup-
position minimization of (Crain and Steedman,
1985).
• PP-OBJECT-TAG. Part-of-speech of the object of
the PP. Certain types of PP objects favor at-
</listItem>
<bodyText confidence="0.961444928571429">
tachment to the verbal or nominal site. For ex-
ample, temporal PPs, such as &amp;quot;in 1959&amp;quot;, where
the prepositional object is tagged CD (cardi-
nal), favor attachment to the VP, because the
VP is more likely to have a temporal dimension.
The association strengths for VERB-LEVEL and
NOUN-LEVEL were measured using the Mutual In-
formation between the noun or verb, and the prepo-
sition.1 The probabilities were derived as Maximum
Likelihood estimates from all PP cases in the train-
ing data. The Mutual Information values were or-
dered by rank. Then, the association strengths were
categorized into eight levels (A-H), depending on
percentile in the ranked Mutual Information values.
</bodyText>
<subsectionHeader confidence="0.99287">
4.2 Experimental Data and Evaluation
</subsectionHeader>
<bodyText confidence="0.9998648">
Training and evaluation data was prepared from the
Penn treebank. All 1.1 million words of parsed text
in the Brown Corpus, and 2.6 million words of parsed
WSJ articles, were used. All instances of PPs that.
are attached to VPs and NPs were extracted. This
resulted in 82,000 PP cases from the Brown Corpus,
and 89,000 PP cases from the WSJ articles. Verbs
and nouns were lemmatized to their root forms if the
root forms were attested in the corpus. If the root
form did not occur in the corpus, then the inflected
form was used.
All the PP cases from the Brown Corpus, and
50,000 of the WSJ cases, were reserved as training
data. The remaining 39,00 WSJ PP cases formed the
evaluation pool. In each experiment, performance
&apos;Mutual Information provides an estimate of the
magnitude of the ratio between the joint. probability
P(verb/noun,preposition), and the joint probability as-
suming independence P(verb/noun)P(preposition) - see
(Church and Hanks, 1990).
</bodyText>
<page confidence="0.993881">
186
</page>
<figure confidence="0.541542">
R140 Ammon. WW4 &amp; Rooth Log MN/ MpOel Rogrw Assoc.. Ba rx Lox., Assocusoon
</figure>
<figureCaption confidence="0.998852">
Figure 5: Results for Two Attachment Sites Figure 6: Three Attachment. Sites: Right Associa-
</figureCaption>
<bodyText confidence="0.8195625">
tion and Lexical Association
was evaluated on a series of 25 random samples of
100 PP cases from the evaluation pool. in order to
provide a characterization of the error variance.
</bodyText>
<subsectionHeader confidence="0.995508">
4.3 Experimental Results: Two
Attachments Sites
</subsectionHeader>
<bodyText confidence="0.999967142857143">
Previous work on automatic PP attachment disam-
biguation has only considered the pattern of a verb
phrase containing an object, and a final PP. This
leads to two possible attachment sites, the verb and
the object of the verb. The pattern is usually further
simplified by considering only the heads of the possi-
ble attachment sites, corresponding to the sequence
&amp;quot;Verb Nouni Preposition Noun2&amp;quot;.
The first set of experiments concerns this pattern.
There are 53,000 such cases in the training data. and
16,000 such cases in the evaluation pool. A number
of methods were evaluated on this pattern accord-
ing to the 25-sample scheme described above. The
results are shown in Figure 5.
</bodyText>
<subsubsectionHeader confidence="0.480162">
4.3.1 Baseline: Right Association
</subsubsectionHeader>
<bodyText confidence="0.999953142857143">
Prepositional phrases exhibit a tendency to attach
to the most recent possible attachment site; this is
referred to as the principle of &amp;quot;Right Association-.
For the &amp;quot;V NP PP&apos; pattern, this means preferring
attachment to the noun phrase. On the evaluation
samples. a median of 65% of the PP cases were at-
tached to the noun.
</bodyText>
<subsectionHeader confidence="0.76208">
4.3.2 Results of Lexical Association
</subsectionHeader>
<bodyText confidence="0.999412769230769">
(Hindle and Rooth. 1993) described a method for
obtaining estimates of lexical association strengths
between nouns or verbs and prepositions, and then
using lexical association strength to predict PP at-
tachment. In our reimplementation of this method.
the probabilities were estimated from all the PP
cases in the training set. Since our training data
are bracketed, it was possible to estimate the lexi-
cal associations with much less noise than Hindle SE
R.00th, who were working with unparsed text. The
median accuracy for our reimplementation of Hindle
Rooth&apos;s method was 81%. This is labeled &amp;quot;Hindle
Sz Rooth&apos; in Figure 5.
</bodyText>
<subsubsectionHeader confidence="0.756044">
4.3.3 Results of the Loglinear Model
</subsubsectionHeader>
<bodyText confidence="0.9995274">
The loglinear model for this task used the features
PREPOSITION. VERB-LEVEL, NOUN-LEVEL, and
NOUN-DEFINITENESS, and it. included all second-
order interaction terms. This model achieved a me-
dian accuracy of 82%.
Hindle Sz Booth&apos;s lexical association strategy only
uses one feature (lexical association) to predict PP
attachment. but, as the boxplot shows, the results
from the loglinear model for the &amp;quot;V NP PP- pattern
do not. show any significant improvement.
</bodyText>
<subsectionHeader confidence="0.9989825">
4.4 Experimental Results: Three
Attachment Sites
</subsectionHeader>
<bodyText confidence="0.999981125">
As suggested by (Gibson and Pearlinutter. 1994).
PP attachment for the -Verb NP PP&amp;quot; pattern is
relatively easy to predict because the two possible
attachment sites differ in syntactic category, and
therefore have very different kinds of lexical pref-
erences. For example, most PPs with of attach to
nouns, and most PPs with to and by attach to verbs.
In actual texts. there are often more than two possi-
ble attachment sites for a PP. Thus, a second, more
realistic series of experiments was performed that.
investigated different. PP attachment strategies for
the pattern -Verb Nonni Noun2 Preposition Noun3&amp;quot;
that includes more than two possible attachment.
sites that are not syntactically heterogeneous. There
were 28,000 such cases in the training data. and 8000
cases in the evaluation pool.
</bodyText>
<page confidence="0.975717">
187
</page>
<figure confidence="0.842726">
Rigid AssocudiOn SOW MirCX* R Roo., logivuor Maw
</figure>
<figureCaption confidence="0.9764035">
Figure 7: Summary of Results for Three Attachment
Sites
</figureCaption>
<subsectionHeader confidence="0.700142">
4.4.1 Baseline: Right Association
</subsectionHeader>
<bodyText confidence="0.9999905">
As in the first set. of experiments, a number of
methods were evaluated on the three attachment site
pattern with 25 samples of 100 random PP cases.
The results are shown in Figures 6-7. The baseline
is again provided by attachment according to the
principle of &amp;quot;Right Attachment&amp;quot; to the most recent
possible site, i.e. attachment to Noun2. A median
of 69% of the PP cases were attached to Noun2.
</bodyText>
<subsectionHeader confidence="0.931307">
4.4.2 Results of Lexical Association
</subsectionHeader>
<bodyText confidence="0.999987533333333">
Next, the lexical association method was evalu-
ated on this pattern. First, the method described
by Hindle &amp; Rooth was reimplemented by using the
lexical association strengths estimated from all PP
cases. The results for this strategy are labeled &amp;quot;Basic
Lexical Association&amp;quot; in Figure 6. This method only
achieved a median accuracy of 59%, which is worse
than always choosing the rightmost attachment site.
These results suggest that. Hindle &amp; Rooth&apos;s scoring
function worked well in the -Verb Nouni Preposi-
tion Noun.,&amp;quot; case not only because it. was an accurate
estimator of lexical associations between individual
verbs/nouns and prepositions which determine PP
attachment. but also because it accurately predicted
the general verb-noun skew of prepositions.
</bodyText>
<sectionHeader confidence="0.7843995" genericHeader="method">
4.4.3 Results of Enhanced Lexical
Association
</sectionHeader>
<bodyText confidence="0.999952727272727">
It seems natural that this pattern calls for a com-
bination of a structural feature with lexical associa-
tion strength. To implement. this, we modified Hin-
dle &amp; R.00th&apos;s method to estimate attachments to
the verb, first noun, and second noun separately.
This resulted in estimates that combine the struc-
tural feature directly with the lexical association
strength. The modified method performed better
than the original lexical association scoring function,
but it still only obtained a median accuracy of 72%.
This is labeled &amp;quot;Split Hindle &amp; Rooth&amp;quot; in Figure 7.
</bodyText>
<subsectionHeader confidence="0.815822">
4.4.4 Results of Loglinear Model
</subsectionHeader>
<bodyText confidence="0.935441882352941">
To create a model that combines various
structural and lexical features without indepen-
dence assumptions, we implemented a loglinear
model that includes the variables VERB-LEVEL.
FIRST-NOUN-LEVEL, and SECOND-NOUN-LEVEL.2
The loglinear model also includes the variables
PREPOSITION and PP-OBJECT-TAG. It was
smoothed with a loglinear model that includes all
second-order interactions.
This method obtained a median accuracy of 79%;
this is labeled &amp;quot;Loglinear Model&amp;quot; in Figure 7. As the
boxplot shows, it performs significantly better than
the methods that only use estimates of lexical asso-
ciation. Compared with the &amp;quot;Split Hindle &amp; Rooth&amp;quot;
method, the samples are a little less spread out, and
there is no overlap at all between the central 50% of
the samples from the two methods.
</bodyText>
<subsectionHeader confidence="0.73068">
4.5 Discussion
</subsectionHeader>
<bodyText confidence="0.999990733333333">
The simpler &amp;quot;V NP PP&amp;quot; pattern with two syntacti-
cally different attachment sites yielded a null result:
The loglinear method did not perform significantly
better than the lexical association method. This
could mean that the results of the lexical associa-
tion method can not be improved by adding other
features, but it is also possible that the features that
could result in improved accuracy were not identi-
fied.
The lexical association strategy does not perform
well on the more difficult pattern with three possible
attachment sites. The loglinear model, on the other
hand, predicts attachment with significantly higher
accuracy, achieving a clear separation of the central
50% of the evaluation samples.
</bodyText>
<sectionHeader confidence="0.99966" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999000411764706">
We have contrasted two types of statistical language
models: A model that derives a probability distribu-
tion over the response variable that. is properly con-
ditioned on the combination of the explanatory vari-
able, and a simpler model that treats the explana-
tory variables as independent, and therefore models
the response variable simply as the addition of the
individual main effects of the explanatory variables.
2 These features use the same Mutual Information-
based measure of lexical association as the previous log-
linear model for two possible atta.chment sites. which
were estimated from all nominal and verbal PP attach-
ments in the corpus. The features FIRST-NOUN-LEVEL
and SECOND-NOUN-LEVEL use the same estimates: in
other words, in contrast. to the &amp;quot;split. Lexical Associa-
tion&apos; method, they were not estimated separately for
the two different. nominal attachment. sites.
</bodyText>
<page confidence="0.995634">
188
</page>
<bodyText confidence="0.999975928571428">
The experimental results show that, with the same
feature set, modeling feature interactions yields bet-
ter performance: such models achieves higher accu-
racy, and its accuracy can be raised with additional
features. It is interesting to note that. modeling vari-
able interactions yields a higher performance gain
than including additional explanatory variables.
While these results do not prove that modeling
feature interactions is necessary, we believe that they
provide a strong indication. This suggests a number
of avenues for further research.
First, we could attempt to improve the specific
models that were presented by incorporating addi-
tional features, and perhaps by taking into account
higher-order features. This might help to address
the performance gap between our models and hu-
man subjects that has been documented in the lit-
erature.3 A more ambitious idea would be to use a
statistical model to rank overall parse quality for en-
tire sentences. This would be an improvement over
schemes that assume independence between a num-
ber of individual scoring functions, such as (Alshawi
and Carter, 1994). If such a model were to include
only a few general variables to account for such fea-
tures as lexical association and recency preference
for syntactic attachment, it might even be worth-
while to investigate it as an approximation to the
human parsing mechanism.
</bodyText>
<sectionHeader confidence="0.999091" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.991460424657534">
Agresti, Alan. 1990. Categorical Data Analysis.
John Wiley &amp; Sons, New York.
Alshawi, Hiyan and David Carter. 1994. Training
and scaling preference functions for disambigua-
tion. Computational Linguistics, 20(4):635-648.
Bishop, Y. M., S. E. Fienberg, and P. W. Holland.
1975. Discrete Multivariate Analysis: Theory and
Practice. MIT Press, Cambridge, MA.
Charniak, Eugene, Curtis Hendrickson, Neil Jacob-
son, and Mike Perkowitz. 1993. Equations for
part-of-speech tagging. In AAAI-93, pages 784-
789.
Church, Kenneth W. and Patrick Hanks. 1990.
Word association norms, mutual information,
and lexicography. Computational Linguistics,
16(1):22-29.
Crain, Stephen and Mark J. Steedman. 1985. On
not being led up the garden path: The use of
3 For example, If random sentences with &amp;quot;Verb NP
PP- cases from the Penn trecbank axe taken as the gold
standard. then (Hindle and Rooth, 1993) and (R.atna-
parklii. Rynar, and R.oukos. 1994) report that human
experts using only head words obtain 85%-88% accu-
racy. If the human experts are allowed to consult the
whole sentence, their accuracy judged against random
Treebank sentences rises to approximately 93%.
context by the psychological syntax processor.
In David R. Dowty, Lauri Karttunen, and An-
mold M. Zwicky, editors, Natural Language Pars-
ing, pages 320-358, Cambridge, UK. Cambridge
University Press.
de Marcken, Carl G. 1990. Parsing the LOB corpus.
In Proceedings of A CL-90, pages 243-251.
Deming, W. E. and F. F. Stephan. 1940. On a least
squares adjustment of a sampled frequency ta-
ble when the expected marginal totals are known.
Ann. Math. Statis, (11):427--444.
Duda, Richard 0. and Peter E. Hart. 1973. Pattern
Classification and Scene Analysis. John Wiley &amp;
Sons, New York.
Fienberg, Stephen E. 1980. The Analysis of Cross-
Classified Categorical Data. The MIT Press,
Cambridge, MA, second edition edition.
Franz. Alexander. 1996. Automatic Ambiguity Res-
olution in Natural Language Processing. volume
1171 of Lecture Notes in Artificial Intelligence.
Springer Verlag, Berlin.
Gibson, Ted and Neal Pearlmutter. 1994. A corpus-
based analysis of psycholinguistic constraints on
PP attachment. In Charles Clifton Jr., Lyn
Frazier, and Keith Rayner, editors, Perspectives
on Sentence Processing. Lawrence Erlbaum Asso-
ciates.
Hindle, Donald and Mats Rooth. 1993. Structural
ambiguity and lexical relations. Computational
Linguistics, 19(0:103-120.
Hirst, Graeme. 1986. Semantic Interpretation and
the Resolution of Ambiguity. Cambridge Univer-
sity Press, Cambridge.
Marcus, Mitchell P., Beatrice Santorini, and
Mary Ann Marcinkiewicz. 1993. Building a large
annotated corpus of English: The Penn Treebank.
Computational Linguistics, 19(2 ):313-330.
R.atnaparkhi, Adwait, Jeff R.ynar, and Salim
R.oukos. 1994. A maximum entropy model
for Prepositional Phrase attachment.. In ARPA
Workshop on Human Language Technology.
Plainsboro, NJ, March 8-11.
Weischedel, Ralph, Marie Meteer, Richard Schwartz,
Lance Ramshaw, and Jeff Pahnucci. 1993. Cop-
ing with ambiguity and unknown words through
probabilistic models. Computational Linguistics,
19(2):359-382.
</reference>
<page confidence="0.998922">
189
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.854547">
<title confidence="0.999643">Independence Assumptions Considered Harmful</title>
<author confidence="0.999837">Alexander Franz</author>
<affiliation confidence="0.9994555">Sony Computer Science Laboratory &amp; D21 Laboratory Sony Corporation</affiliation>
<address confidence="0.980797">6-7-35 Kitashinagawa Shinagawa-ku, Tokyo 141, Japan</address>
<email confidence="0.980579">amf@csl.sony.co.jp</email>
<abstract confidence="0.993028666666666">Many current approaches to statistical language modeling rely on independence assumptions between the different, explanatory variables. This results in models which are computationally simple, but which only model the main effects of the explanatory variables on the response variable. This paper presents an argument in favor of a statistical approach that also models the interactions between the explanatory variables. The argument rests on empirical evidence from two series of experiments concerning automatic ambiguity resolution.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alan Agresti</author>
</authors>
<title>Categorical Data Analysis.</title>
<date>1990</date>
<publisher>John Wiley &amp; Sons,</publisher>
<location>New York.</location>
<contexts>
<context position="7435" citStr="Agresti, 1990" startWordPosition="1190" endWordPosition="1191"> cell entries towards satisfaction of the marginal constraints specified by the model. 3. Iterate through the adjustment steps until the maximum difference f. between the marginal totals observed in the sample and the estimated marginal totals reaches a certain minimum threshold. e.g. e = 0.1. After each cycle, the estimates satisfy the constraints specified in the model, and the estimated expected marginal totals come closer to matching the observed totals. Thus, the process converges. This results in Maximum Likelihood estimates for both multinomial and independent Poisson sampling schemes (Agresti, 1990). 2.5 Modeling Interactions For natural language classification and prediction tasks, the aim is to estimate a conditional probability distribution P(HIE) over the possible values of the hypothesis H, where the evidence E consists of a number of linguistic features el, e2, .... Much of the previous work in this area assumes independence between the linguistic features: P(Hlei.ei,• • .) P(He) x P(Hlei) x ... (2) For example. a model to predict Part-of-Speech of a word on the basis of its morphological affix and its capitalization might assume independence between the two explanatory variables a</context>
</contexts>
<marker>Agresti, 1990</marker>
<rawString>Agresti, Alan. 1990. Categorical Data Analysis. John Wiley &amp; Sons, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiyan Alshawi</author>
<author>David Carter</author>
</authors>
<title>Training and scaling preference functions for disambiguation.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--4</pages>
<marker>Alshawi, Carter, 1994</marker>
<rawString>Alshawi, Hiyan and David Carter. 1994. Training and scaling preference functions for disambiguation. Computational Linguistics, 20(4):635-648.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y M Bishop</author>
<author>S E Fienberg</author>
<author>P W Holland</author>
</authors>
<title>Discrete Multivariate Analysis: Theory and Practice.</title>
<date>1975</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Bishop, Fienberg, Holland, 1975</marker>
<rawString>Bishop, Y. M., S. E. Fienberg, and P. W. Holland. 1975. Discrete Multivariate Analysis: Theory and Practice. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Curtis Hendrickson</author>
<author>Neil Jacobson</author>
<author>Mike Perkowitz</author>
</authors>
<title>Equations for part-of-speech tagging.</title>
<date>1993</date>
<booktitle>In AAAI-93,</booktitle>
<pages>784--789</pages>
<contexts>
<context position="13935" citStr="Charniak et al., 1993" startWordPosition="2241" endWordPosition="2245">sets that ranged from a single feature to nine features. As the diagram shows, the accuracies for both methods rise with the first few features, but then the two methods show a clear divergence. The accuracy of the simpler method levels off around at around 50-55%, while the loglinear model reaches an accuracy of 70-75%. This shows that the loglinear model is able to tolerate redundant features and use information from more features than the simpler method, and therefore achieves better results at ambiguity resolution. 3.5 Adding Context to the Model Next, we added of a stochastic POS tagger (Charniak et al., 1993) to provide a model of context. A stochastic POS tagger assigns POS labels to words in a sentence by using two parameters: • Lexical Probabilities: P(0) the probability of observing word w given that the tag t occurred. • Contextual Probabilities: P(414_1, 4_2) — the probability of observing tag 4 given that the two previous tags 4_1, 4_2 occurred. The tagger maximizes the probability of the tag sequence T t„ given the word sequence W = w1, w2, , w„, which is approximated as follows: TS P(TIW) Hp(wiiti)p(tiiti_1,ti_2) (4) The accuracy of the combination of the loglinear model for local feature</context>
</contexts>
<marker>Charniak, Hendrickson, Jacobson, Perkowitz, 1993</marker>
<rawString>Charniak, Eugene, Curtis Hendrickson, Neil Jacobson, and Mike Perkowitz. 1993. Equations for part-of-speech tagging. In AAAI-93, pages 784-789.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
<author>Patrick Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<pages>16--1</pages>
<contexts>
<context position="19917" citStr="Church and Hanks, 1990" startWordPosition="3212" endWordPosition="3215">he WSJ articles. Verbs and nouns were lemmatized to their root forms if the root forms were attested in the corpus. If the root form did not occur in the corpus, then the inflected form was used. All the PP cases from the Brown Corpus, and 50,000 of the WSJ cases, were reserved as training data. The remaining 39,00 WSJ PP cases formed the evaluation pool. In each experiment, performance &apos;Mutual Information provides an estimate of the magnitude of the ratio between the joint. probability P(verb/noun,preposition), and the joint probability assuming independence P(verb/noun)P(preposition) - see (Church and Hanks, 1990). 186 R140 Ammon. WW4 &amp; Rooth Log MN/ MpOel Rogrw Assoc.. Ba rx Lox., Assocusoon Figure 5: Results for Two Attachment Sites Figure 6: Three Attachment. Sites: Right Association and Lexical Association was evaluated on a series of 25 random samples of 100 PP cases from the evaluation pool. in order to provide a characterization of the error variance. 4.3 Experimental Results: Two Attachments Sites Previous work on automatic PP attachment disambiguation has only considered the pattern of a verb phrase containing an object, and a final PP. This leads to two possible attachment sites, the verb and</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Church, Kenneth W. and Patrick Hanks. 1990. Word association norms, mutual information, and lexicography. Computational Linguistics, 16(1):22-29.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Stephen Crain</author>
<author>Mark J Steedman</author>
</authors>
<title>On not being led up the garden path: The use of 3 For example, If random sentences with &amp;quot;Verb NP PP- cases from the Penn trecbank axe taken as the gold standard. then (Hindle and Rooth,</title>
<date>1985</date>
<contexts>
<context position="18157" citStr="Crain and Steedman, 1985" startWordPosition="2923" endWordPosition="2926">LEVEL. Lexical association strength between the noun and the preposition. • NOUN-TAG. Part-of-Speech of the nominal attachment site. This is included to account for correlations between attachment and syntactic category of the nominal attachment site, such as &amp;quot;PPs disfavor attachment to proper nouns.&amp;quot; • NOUN-DEFINITENESS. Does the nominal attachment site include a definite determiner? This feature is included to account for a possible correlation between PP attachment to the nominal site and definiteness, which was derived by (Hirst, 1986) from the principle of presupposition minimization of (Crain and Steedman, 1985). • PP-OBJECT-TAG. Part-of-speech of the object of the PP. Certain types of PP objects favor attachment to the verbal or nominal site. For example, temporal PPs, such as &amp;quot;in 1959&amp;quot;, where the prepositional object is tagged CD (cardinal), favor attachment to the VP, because the VP is more likely to have a temporal dimension. The association strengths for VERB-LEVEL and NOUN-LEVEL were measured using the Mutual Information between the noun or verb, and the preposition.1 The probabilities were derived as Maximum Likelihood estimates from all PP cases in the training data. The Mutual Information va</context>
</contexts>
<marker>Crain, Steedman, 1985</marker>
<rawString>Crain, Stephen and Mark J. Steedman. 1985. On not being led up the garden path: The use of 3 For example, If random sentences with &amp;quot;Verb NP PP- cases from the Penn trecbank axe taken as the gold standard. then (Hindle and Rooth, 1993) and (R.atnaparklii. Rynar, and R.oukos. 1994) report that human experts using only head words obtain 85%-88% accuracy. If the human experts are allowed to consult the whole sentence, their accuracy judged against random Treebank sentences rises to approximately 93%.</rawString>
</citation>
<citation valid="false">
<title>context by the psychological syntax processor. In</title>
<booktitle>Natural Language Parsing,</booktitle>
<pages>320--358</pages>
<editor>David R. Dowty, Lauri Karttunen, and Anmold M. Zwicky, editors,</editor>
<publisher>Cambridge University Press.</publisher>
<location>Cambridge, UK.</location>
<marker></marker>
<rawString>context by the psychological syntax processor. In David R. Dowty, Lauri Karttunen, and Anmold M. Zwicky, editors, Natural Language Parsing, pages 320-358, Cambridge, UK. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl G de Marcken</author>
</authors>
<title>Parsing the LOB corpus.</title>
<date>1990</date>
<booktitle>In Proceedings of A CL-90,</booktitle>
<pages>243--251</pages>
<marker>de Marcken, 1990</marker>
<rawString>de Marcken, Carl G. 1990. Parsing the LOB corpus. In Proceedings of A CL-90, pages 243-251.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W E Deming</author>
<author>F F Stephan</author>
</authors>
<title>On a least squares adjustment of a sampled frequency table when the expected marginal totals are known.</title>
<date>1940</date>
<journal>Ann. Math. Statis,</journal>
<pages>11--427</pages>
<contexts>
<context position="6209" citStr="Deming and Stephan, 1940" startWordPosition="991" endWordPosition="994">bles on the logarithms of the expected cell counts. In this way, a loglinear model provides a way to estimate expected cell counts that depend not only on the main effects of the variables, but also on the interactions between variables. This is achieved by adding &amp;quot;interaction terms- such as U12(j) to the model. For further details, see (Fienberg, 1980). 2.4 The Iterative Estimation Procedure For some loglinear models, it is possible to obtain closed forms for the expected cell counts. For more complicated models. the iterative proportional fitting algorithm for hierarchical loglinear models (Deming and Stephan, 1940) can be used. Briefly, this procedure works as follows. Let the values for the expected cell counts that are estimated by the model be represented by the symbol The interaction terms in the loglinear models represent constraints on the estimated expected marginal totals. Each of these marginal constraints translates into an adjustment scaling factor for the cell entries. The iterative procedure has the following steps: 1. Start with initial estimates for the estimated expected cell counts. For example, set all 7hijki = 1.0. 2. Adjust each cell entry by multiplying it by the scaling factors. Th</context>
</contexts>
<marker>Deming, Stephan, 1940</marker>
<rawString>Deming, W. E. and F. F. Stephan. 1940. On a least squares adjustment of a sampled frequency table when the expected marginal totals are known. Ann. Math. Statis, (11):427--444.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter E Hart</author>
</authors>
<title>Pattern Classification and Scene Analysis.</title>
<date>1973</date>
<publisher>John Wiley &amp; Sons,</publisher>
<location>New York.</location>
<marker>Hart, 1973</marker>
<rawString>Duda, Richard 0. and Peter E. Hart. 1973. Pattern Classification and Scene Analysis. John Wiley &amp; Sons, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen E Fienberg</author>
</authors>
<title>The Analysis of CrossClassified Categorical Data.</title>
<date>1980</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA,</location>
<note>second edition edition.</note>
<contexts>
<context position="5939" citStr="Fienberg, 1980" startWordPosition="955" endWordPosition="956">notes the deviation of the mean of the expected cell counts with value i of the first variable and value j of the second variable from the grand mean u. In other words, u12(ii) represents the combined effect of the values i and j for the first and second variables on the logarithms of the expected cell counts. In this way, a loglinear model provides a way to estimate expected cell counts that depend not only on the main effects of the variables, but also on the interactions between variables. This is achieved by adding &amp;quot;interaction terms- such as U12(j) to the model. For further details, see (Fienberg, 1980). 2.4 The Iterative Estimation Procedure For some loglinear models, it is possible to obtain closed forms for the expected cell counts. For more complicated models. the iterative proportional fitting algorithm for hierarchical loglinear models (Deming and Stephan, 1940) can be used. Briefly, this procedure works as follows. Let the values for the expected cell counts that are estimated by the model be represented by the symbol The interaction terms in the loglinear models represent constraints on the estimated expected marginal totals. Each of these marginal constraints translates into an adju</context>
</contexts>
<marker>Fienberg, 1980</marker>
<rawString>Fienberg, Stephen E. 1980. The Analysis of CrossClassified Categorical Data. The MIT Press, Cambridge, MA, second edition edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander</author>
</authors>
<title>Automatic Ambiguity Resolution in Natural Language Processing.</title>
<date>1996</date>
<booktitle>of Lecture Notes in Artificial Intelligence.</booktitle>
<volume>1171</volume>
<publisher>Springer Verlag,</publisher>
<location>Berlin.</location>
<marker>Alexander, 1996</marker>
<rawString>Franz. Alexander. 1996. Automatic Ambiguity Resolution in Natural Language Processing. volume 1171 of Lecture Notes in Artificial Intelligence. Springer Verlag, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Gibson</author>
<author>Neal Pearlmutter</author>
</authors>
<title>A corpusbased analysis of psycholinguistic constraints on PP attachment.</title>
<date>1994</date>
<booktitle>Perspectives on Sentence Processing. Lawrence Erlbaum Associates.</booktitle>
<editor>In Charles Clifton Jr., Lyn Frazier, and Keith Rayner, editors,</editor>
<marker>Gibson, Pearlmutter, 1994</marker>
<rawString>Gibson, Ted and Neal Pearlmutter. 1994. A corpusbased analysis of psycholinguistic constraints on PP attachment. In Charles Clifton Jr., Lyn Frazier, and Keith Rayner, editors, Perspectives on Sentence Processing. Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Hindle</author>
<author>Mats Rooth</author>
</authors>
<title>Structural ambiguity and lexical relations.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--0</pages>
<marker>Hindle, Rooth, 1993</marker>
<rawString>Hindle, Donald and Mats Rooth. 1993. Structural ambiguity and lexical relations. Computational Linguistics, 19(0:103-120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Hirst</author>
</authors>
<title>Semantic Interpretation and the Resolution of Ambiguity.</title>
<date>1986</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="18077" citStr="Hirst, 1986" startWordPosition="2913" endWordPosition="2914"> association strength between the verb and the preposition. • NOUN-LEVEL. Lexical association strength between the noun and the preposition. • NOUN-TAG. Part-of-Speech of the nominal attachment site. This is included to account for correlations between attachment and syntactic category of the nominal attachment site, such as &amp;quot;PPs disfavor attachment to proper nouns.&amp;quot; • NOUN-DEFINITENESS. Does the nominal attachment site include a definite determiner? This feature is included to account for a possible correlation between PP attachment to the nominal site and definiteness, which was derived by (Hirst, 1986) from the principle of presupposition minimization of (Crain and Steedman, 1985). • PP-OBJECT-TAG. Part-of-speech of the object of the PP. Certain types of PP objects favor attachment to the verbal or nominal site. For example, temporal PPs, such as &amp;quot;in 1959&amp;quot;, where the prepositional object is tagged CD (cardinal), favor attachment to the VP, because the VP is more likely to have a temporal dimension. The association strengths for VERB-LEVEL and NOUN-LEVEL were measured using the Mutual Information between the noun or verb, and the preposition.1 The probabilities were derived as Maximum Likeli</context>
</contexts>
<marker>Hirst, 1986</marker>
<rawString>Hirst, Graeme. 1986. Semantic Interpretation and the Resolution of Ambiguity. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<pages>313--330</pages>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Marcus, Mitchell P., Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19(2 ):313-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait R atnaparkhi</author>
<author>Jeff R ynar</author>
<author>Salim R oukos</author>
</authors>
<title>A maximum entropy model for Prepositional Phrase attachment..</title>
<date>1994</date>
<booktitle>In ARPA Workshop on Human Language Technology.</booktitle>
<location>Plainsboro, NJ,</location>
<marker>atnaparkhi, ynar, oukos, 1994</marker>
<rawString>R.atnaparkhi, Adwait, Jeff R.ynar, and Salim R.oukos. 1994. A maximum entropy model for Prepositional Phrase attachment.. In ARPA Workshop on Human Language Technology. Plainsboro, NJ, March 8-11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Weischedel</author>
<author>Marie Meteer</author>
<author>Richard Schwartz</author>
<author>Lance Ramshaw</author>
<author>Jeff Pahnucci</author>
</authors>
<title>Coping with ambiguity and unknown words through probabilistic models.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--2</pages>
<marker>Weischedel, Meteer, Schwartz, Ramshaw, Pahnucci, 1993</marker>
<rawString>Weischedel, Ralph, Marie Meteer, Richard Schwartz, Lance Ramshaw, and Jeff Pahnucci. 1993. Coping with ambiguity and unknown words through probabilistic models. Computational Linguistics, 19(2):359-382.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>