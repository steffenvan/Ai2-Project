<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000393">
<title confidence="0.989814">
Associative Anaphora Resolution: A Web-Based Approach
</title>
<author confidence="0.992622">
Razvan Bunescu
</author>
<affiliation confidence="0.9986305">
Department of Computer Sciences
University of Texas at Austin
</affiliation>
<address confidence="0.887144">
Austin, TX 78712-1188
</address>
<email confidence="0.997703">
razvan@cs.utexas.edu
</email>
<sectionHeader confidence="0.998594" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999989416666667">
We present a novel approach to solving
definite descriptions in unrestricted text
based on searching the web for a par-
ticular type of lexico-syntactic patterns.
Using statistics on these patterns, we in-
tend to recover the antecedents for a pre-
defined subset of definite descriptions
occurring in two types of anaphoric re-
lations: identity anaphora and associa-
tive anaphora. Preliminary results ob-
tained with this method are promising
and compare well with other methods.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999146222222222">
Definite descriptions (noun phrases beginning
with a definite article) have been extensively stud-
ied in linguistics, philosophy and computational
linguistics and different authors have proposed
different schemes for classifying possible uses of
definite descriptions. The terminology that we use
here is based on that introduced by Hawkins in
(Hawkins, 1978) and is simplified by the fact that
we are concerned with two types only:
</bodyText>
<listItem confidence="0.9798773">
• Identity Anaphora This is the same as
Hawkins&apos; anaphoric use, and subsumes defi-
nite descriptions that refer to the same entity
as a previous phrase (antecedent) in the dis-
course. Examples:
1. Fred was discussing an interesting book
in his class. I went to discuss the book
with him afterwards.
2. Fred was wearing trousers. The pants
had a big patch on them.
• Associative Anaphora This corresponds to
Hawkins&apos; associative anaphoric use, and
refers to definite descriptions whose refer-
ent is uniquely identifiable based on general
knowledge about associations with entities
evoked by antecedents. Examples:
1. Bill found himself in the middle of afor-
est. The trees were tall and sturdy.
2. Tacos and burritos are the meat of the
menu in this Mexican restaurant. The
</listItem>
<bodyText confidence="0.975633">
atmosphere is extremely laid back and
the service is too.
In his analysis of the associative anaphoric use,
Hawkins introduces the terms trigger and asso-
ciate to refer to the antecedent and its associated
definite description. We will extend the denota-
tion of these two terms to cover also the case of
identity anaphora. Consequently, in the above ex-
amples we have five trigger:associate pairs: an in-
teresting book: the book, trousers: the pants, for-
est: the trees, restaurant: the atmosphere, restau-
rant: the service. The types of relations involved
in associative anaphora can be very diverse, from
meronymy as in forest: the trees, to attributes as
in car: the price, to complex relationships as in
Auschwitz: the victims. Therefore, we will con-
cern ourselves with identifying trigger:associate
pairs, without establishing the exact type of their
association.
Extracting the triggers of anaphoric definite de-
scriptions is not an easy task. In one experiment
</bodyText>
<page confidence="0.998748">
47
</page>
<bodyText confidence="0.999921952380952">
(Poesio et al., 1997), the authors exploited the
WordNet lexical database (Miller, 1991) in or-
der to account for the commonsense knowledge
that humans seem to employ when solving defi-
nite descriptions. Another approach (Poesio et
al., 1998) tried to address the incompletness of
the information hand-coded in WordNet by hy-
pothesizing a semantic priming effect between a
trigger and its associate which could be detected
automatically using a lexical clustering algorithm
similar to that described in (Lund et al., 1995).
In (Meyer and Dale, 2002) lexico-syntactic pat-
terns have been used to mine lexical associative
axioms from a corpus of 2000 encyclopaedia ar-
ticles. These associations were further general-
ized based on WordNet and their performance was
evaluated on a set of five anaphoric heads.
Our method, as described in the following sec-
tions, combines the power of a different type of
lexico-syntactic patterns with the huge coverage
offered by the world wide web.
</bodyText>
<sectionHeader confidence="0.970721" genericHeader="method">
2 The Method
</sectionHeader>
<bodyText confidence="0.999693071428571">
Given a pair of nouns nt:na occurring in the same
document, we want to detect how likely it is that
the two nouns are in a trigger:associate relation-
ship. To accomplish this, we plug the two nouns
in the pattern from Figure 1, as if sit were end-
ing a sentence and na were at the beginning of the
next sentence in a definite description followed by
one of the verbs is/are, was/were, has/have, had,
may, might, can, could, should, would. For each of
the three instantiated patterns, a search engine will
return the number of matching documents, and,
based on these numbers, we shall derive a mea-
sure of the degree of association between the two
nouns.
</bodyText>
<equation confidence="0.993689666666667">
Vnt,na) = &amp;quot;[nt]. The [na] [verb]&amp;quot;
Q(nt) = &amp;quot;[nt].&amp;quot;
Vna) = &amp;quot;The [Thai [verb]&amp;quot;
</equation>
<figureCaption confidence="0.997474">
Figure 1: Phrase Patterns
</figureCaption>
<bodyText confidence="0.990078142857143">
Our intuition is that ordered pairs of nouns oc-
curring in identity or associative anaphora will get
a high degree of association in this kind of pattern,
whereas unrelated nouns should get a low value
for the same association measure. The rationale
behind this pattern is based on the following ob-
servations:
</bodyText>
<listItem confidence="0.663058266666667">
• Relatively many trigger:associate pairs ap-
pear in this kind of configuration (we ignore
the verb for the time being). Three of our
five examples follow this pattern; the litera-
ture on the anaphora phenomena is rife with
this type of examples, and, most important,
there is a slight tendency in natural language
towards employing associated nouns (in the
two anaphoric senses discussed in the intro-
duction) when using this pattern.
• Definite descriptions, when used in identity
or associative anaphora, do not need an estab-
lishing modifier, relative clause or preposi-
tional phrase, as the hearer can already iden-
tify their referent. We enforce this in our
</listItem>
<bodyText confidence="0.903426944444444">
pattern as follows: there is no modifier be-
tween the definite article and the potential as-
sociate, and the presence of a subordinate rel-
ative clause or attached prepositional phrase
after the associate is prohibited by the imme-
diate presence of a generic verb. This is the
reason for placing a verb after the associate
in the pattern.
• The particular set of verbs used in the pattern
was determined by the need to exclude any
possible association between the verb and the
two nouns. Therefore, we have selected verbs
which we thought were general enough to
preclude such associations: the verb &amp;quot;to be&amp;quot;
and modal verbs at different tenses. The gen-
erality of these verbs was also instrumental in
increasing the number of hits returned by the
search engine.
</bodyText>
<listItem confidence="0.9423357">
• The final form of this pattern was highly
constrained by the fact that we needed it
to conform to one of the query formats ac-
cepted by the current search engines. The
only available query formats emphasizing
word co-occurrences in short spans of text
are the &amp;quot;Phrase&amp;quot; and &amp;quot;NEAR&amp;quot; queries. With
a &amp;quot;Phrase&amp;quot; type of query, a search engine
looks for documents containing the exact
specified phrase. With a &amp;quot;NEAR&amp;quot; type of
</listItem>
<page confidence="0.996251">
48
</page>
<bodyText confidence="0.999980777777778">
query, the search engine will return doc-
uments containing both specified words or
phrases within a constant number of words
of each other. However, because the trig-
ger:associate relation is generally asymmet-
ric while the &amp;quot;NEAR&amp;quot; type of query (shown
in Figure 2) is symmetric, we hypothesized
that the phrase pattern should give a better
performance (the experiments will validate
this as will be seen later in Section 3).
There is also the issue of time complexity. We
could, for instance, drop the verb from the phrase
pattern, download each matching document and
filter out those documents in which the second
noun from the pattern had a subordinate relative
clause or an attached prepositional phrase. This
however would be very time consuming and would
require too much network traffic.
</bodyText>
<equation confidence="0.998278">
Q(nt,na) = &amp;quot;fnt/ &amp;quot; NEAR &amp;quot;the [nal&amp;quot;
Vnt) = &amp;quot;Intl&amp;quot;
Q(na) = &amp;quot;the [nal&amp;quot;
</equation>
<figureCaption confidence="0.940374">
Figure 2: NEAR Patterns
</figureCaption>
<bodyText confidence="0.999791307692308">
The exact method for computing the degree of
anaphoric association between a potential trigger
noun nt and a potential associate noun na is based
on the information-theoretic measure of pointwise
mutual information (Church and Hanks, 1990;
Manning and Schiitze, 1999). If we denote with
N the total number of web documents indexed by
a search engine, and with D(query) the number of
web documents returned by the same search en-
gine with the given query, then the degree of as-
sociation (when we use either the Phrase pattern
or the NEAR pattern) will be given by /(nt, Tha)
computed as in Figure 3.
</bodyText>
<equation confidence="0.997819833333333">
I(n),na) = log2 P(c2(nt,n.))P(Q(nt))P(C2(%))
D(Q(nt,na))
log2 N
D(Q(nt)),,D(Q(na))
, N*D(Q(nt,na))
— log2 D(Q(Tht))*D(Q(Tha))
</equation>
<figureCaption confidence="0.996822">
Figure 3: Pointwise Mutual Information
</figureCaption>
<bodyText confidence="0.995942833333333">
the number of hits that the Altavistal search en-
gine returns for the three phrase queries illustrated
in Figure 1 and compute I(nt, na) accordingly. If
there is no association (in the anaphoric sense) be-
tween nt and na, then the numerator and denom-
inator tend to have the same value, and the point-
wise mutual information will be close to 0. On the
other hand, if nt and na can be related in associa-
tive anaphora, then there will be a dependence be-
tween the events involved in the probabilities from
Figure 3, which will result in a higher value for
/(nt, na).
</bodyText>
<sectionHeader confidence="0.999365" genericHeader="method">
3 Experimental Evaluation
</sectionHeader>
<bodyText confidence="0.99993595">
We tested our method on the first 32 documents
from the Brown section of the Treebank corpus
(Marcus et al., 1994) (cf01 to cf32). For each
document, we created a list of potential associates
consisting of definite descriptions with only one
noun, with the additional constraint that no prepo-
sitional phrase or relative phrase was attached to
them (in this way we focused our method on those
definite descriptions that were most susceptible to
be anaphoric). We have also excluded from the
set of possible associates all definite descriptions
whose head noun had occurred before in the docu-
ment (as is the case with the first example of iden-
tity anaphora in Section 1). The resulting list of
potential associates contains 686 definite descrip-
tions, and the task becomes that of identifying the
trigger (if such a trigger exists) for each of them.
All 686 potential associates were annotated by
hand as belonging to one or more of the follow-
ing 6 classes:
</bodyText>
<listItem confidence="0.8613218">
1. If a definite noun phrase is anaphoric and it
has one or more trigger nouns (it is possible
to have more than one trigger noun for the
same associate), then the definite noun phrase
is annotated as an associate with the corre-
sponding list of triggers.
2. This class contains anaphoric definite noun
phrases for which the trigger is not a noun
(for instance, the trigger may be a verb, or
even an entire phrase).
</listItem>
<bodyText confidence="0.799754">
For a particular pair of nouns nt:na, we collect URL: http: //www altavista com
</bodyText>
<page confidence="0.992897">
49
</page>
<listItem confidence="0.532105">
3. Some definite noun phrases like &amp;quot;the world&amp;quot;,
</listItem>
<bodyText confidence="0.847613444444445">
&amp;quot;the moon&amp;quot;, &amp;quot;the earth&amp;quot;, &amp;quot;the balkans&amp;quot;,
&amp;quot;the past&amp;quot;, &amp;quot;the future&amp;quot; or &amp;quot;the pope&amp;quot; (the
larger situation uses in Hawkins&apos; classifica-
tion) have a well known referent based on the
common knowledge shared by speaker and
hearer. These were included in a separate
class. By reification, many definite descrip-
tions can enter this class, and in our test set
we have examples such as &amp;quot;the brain&amp;quot;, &amp;quot;the
eyes&amp;quot;, &amp;quot;the eye&amp;quot;, &amp;quot;the street&amp;quot;, etc.
4. Another category is that of definite noun
phrases triggered by the discourse but for
which we cannot find a trigger in the form
of a word or a phrase. Typical examples are
most occurrences of noun phrases like &amp;quot;the
problem&amp;quot;, &amp;quot;the situation&amp;quot;, &amp;quot;the issue&amp;quot;, &amp;quot;the
question&amp;quot;, etc.
5. There are cases of definite description use
where the hearer/reader cannot infer the ref-
erent. This may happen especially at the
beginning of documents or in direct speech.
One document from our test set begins with
the following sentence: &amp;quot;The food is won-
derful and it is a lot of fun to be here!&amp;quot;.
These definite descriptions were then tagged
accordingly as belonging to a separate cate-
gory.
</bodyText>
<listItem confidence="0.8143248">
6. Yet another class of definite descriptions is
that of definite noun phrases occurring in-
side an idiomatic phrase, such as: &amp;quot;out of the
blue&amp;quot;, &amp;quot;on the contrary&amp;quot;, &amp;quot;in the making&amp;quot;,
or &amp;quot;let the cat out of the bag&amp;quot;.
</listItem>
<bodyText confidence="0.999264333333333">
Some of these classes may overlap, especially
the first and the third class. One example is the
phrase &amp;quot;the historian&amp;quot; used with a reified mean-
ing in one document. It was included in the
third class of definite descriptions, nevertheless
the same phrase could be viewed as triggered
by the preceding noun &amp;quot;history&amp;quot; (document cf19
from the test corpus).
The distribution of the 686 potential associates
over these 6 categories is shown in Table 1.
Given a definite noun phrase (from the list of
potential associates) containing a noun n a, we
</bodyText>
<table confidence="0.9897995">
Class 1 2 3 4 5 6
Total 324 29 175 126 42 30
</table>
<tableCaption confidence="0.998984">
Table 1: Class Statistics
</tableCaption>
<bodyText confidence="0.999903">
consider each of the preceding 50 nouns as a pos-
sible trigger. Consequently we create 50 nt:na
pairs and compute for each of them the degree of
association as described in Figure 3. We then se-
lect the trigger for which we get the highest de-
gree of association. Except in the case when it
contains the first noun from the document, a def-
inite description will be associated with its high-
est ranking trigger noun. By imposing a thresh-
old on the minimum acceptable value for the asso-
ciation measure and by varying this threshold we
get the precision-recall graphs from Figure 4. The
graph labeled &amp;quot;Phrase&amp;quot; corresponds to our method
when using the Phrase pattern from Figure 1. The
precision-recall graph labeled &amp;quot;NEAR&amp;quot; stands for
the same method when the pattern was changed to
the NEAR pattern from Figure 2.
The definite descriptions for which there exists
a word or phrase trigger are those from classes 1
and 2, therefore our method was evaluated on the
task of extracting exactly this maximal set of asso-
ciations, starting from the entire set of 686 poten-
tial associates. Note that the method was designed
to extract associations from the first class only,
consequently its performance on extracting only
the first type of associations is actually higher.
</bodyText>
<equation confidence="0.605404">
Recall (%)
</equation>
<figureCaption confidence="0.825714666666667">
Figure 4: Precision-recall graphs
We&apos;ve also evaluated the performance of 2 base-
line approaches:
</figureCaption>
<figure confidence="0.980938588235294">
100
90
80
70
60
10
20
50
40
11
30 7
20 7
10
0 o
Phrase
NEAR
40
</figure>
<page confidence="0.983664">
50
</page>
<listItem confidence="0.812399625">
1. In the first baseline, for each potential asso-
ciate we assigned as trigger a random noun
from the preceding 50 nouns. The precision
was 1.1% at a recall of 2.1%.
2. In the second baseline, each potential asso-
ciate was considered triggered by the closest
preceding noun. The precision was 3.4% at a
recall of 6.2%.
</listItem>
<sectionHeader confidence="0.677303" genericHeader="method">
4 Discussion of results
</sectionHeader>
<bodyText confidence="0.999924411764706">
The precision-recall graphs show a significant bet-
ter performance for the Phrase pattern when com-
pared with the NEAR pattern, confirming our
intuition about the importance of enforcing two
anaphoric features in the statistical pattern: the
asymmetry of the trigger:association relationship
and the fact that associates do not need establish-
ing modifiers or relative clauses.
The method compares well with the approach
from (Poesio et al., 1998) where precision and re-
call on the class of inferential descriptions were
22.7%. At the same recall our method has a preci-
sion of 53%. However the comparison is compli-
cated by the fact that the test sets are from differ-
ent sections of Treebank, plus the fact that our set
of potential associates was created using a differ-
ent method which, as described at the beginning of
Section 3, did not take into account the manual an-
notation of the document. The approach presented
here also validates the prediction made in the same
paper (Poesio et al., 1998), namely that statistical
pattern matching may provide a way to trade off
between precision and recall by varying a suitable
threshold.
The Phrase pattern seems more general than
other patterns used for the same task: a pattern
based on genitive constructions, for instance, can-
not cover trigger:associate cases like that of &amp;quot;cou-
ple&amp;quot; and &amp;quot;the man&amp;quot; (a web search for the phrase
&amp;quot;the couple&apos;s man&amp;quot; returns no hits).
In the following paragraphs we&apos;ll investigate
some of the errors and limitations of our method.
Sometimes the second best trigger was a cor-
rect trigger, while the first one was incorrect. It
was also closer to the associate noun than the
first ranked trigger, which suggests that distance
should play a role in the ranking decision.
There were cases when a spurious trigger was
ranked very high because of an &amp;quot;unjustified&amp;quot; high
number of hits from the search engine. One ex-
ample is the pair car:butter for which the phrase
pattern, instantiated to &amp;quot;car The butter is&amp;quot;, re-
turned 7 documents. But all 7 documents con-
tain the same text section called &amp;quot;Ideas for Care-
givers&amp;quot; with the text &amp;quot;We need ONE egg. That&apos;s
a RED car The butter is in this SQUARE box.&amp;quot;
Normally, these 7 documents should be counted
as one, however this kind of checking requires sig-
nificant processing and network traffic (there may
be thousands of documents returned by the search
engine).
Anaphora resolution may require more com-
plicated reasoning than a simple decision based
on a lexical association measure. In one doc-
ument, &amp;quot;the Greek&amp;quot; corefers with &amp;quot;a member
of a greek syndicate&amp;quot;. The degree of associa-
tion between &amp;quot;member&amp;quot; and &amp;quot;Greek&amp;quot;, as com-
puted by our method, is very low, nevertheless the
two are coreferent. Another interesting example
that couldn&apos;t be solved with the current method
was the following sequence of phrases (document
cf02): &amp;quot;She was just another freighter from the
States&amp;quot;, &amp;quot;She was the John Harvey&amp;quot;, &amp;quot;John Har-
vey&amp;quot;, &amp;quot;the ship&amp;quot;. Between the two nouns &amp;quot;ship&amp;quot;
and &amp;quot;freighter&amp;quot; there is a distance of more than
50 nouns, therefore our method could not detect
an association between them. One may think of
extending this window size and making a more
informed decision based on the (presumably al-
ready detected) coreference between &amp;quot;freighter&amp;quot;
and &amp;quot;John Harvey&amp;quot;, and the fact that &amp;quot;John Har-
vey&amp;quot; is very close to &amp;quot;the ship&amp;quot;, which has a
high degree of association with &amp;quot;freighter&amp;quot;. In
other words, the association should propagate to
all coreferent items.
There are special cases of coreference for which
the association measure cannot help, cases which,
nevertheless, can be solved by a simple approach.
An example is with the &amp;quot;the latter&amp;quot; constructions,
as in &amp;quot;the decisions of the highest ecclesiastical
authority and the natural law. The latter plays a
prominent role...&amp;quot; (document cf15).
Changes in discourse topic may invalidate
strong associations between nouns from fragments
with different topic. An algorithm for detecting
</bodyText>
<page confidence="0.994808">
51
</page>
<bodyText confidence="0.99980795">
topic changes may prove very useful in restricting
the set of potential triggers for a given associate.
Another limitation of our method is the fact that
it can be applied for finding trigger:associate pairs
consisting of single nouns only. To make it ap-
plicable to more general noun phrases we need a
mechanism for detecting collocations. The impor-
tance of detecting collocations is evident if we try
to find &amp;quot;sonata&amp;quot; as the trigger for &amp;quot;the first move-
ment&amp;quot;. If we create a phrase pattern as in Fig-
ure 1 based only on the head nouns &amp;quot;sonata&amp;quot; and
&amp;quot;movement&amp;quot;, we get no hits from the search en-
gine. This happens because &apos;first movement&amp;quot; is
a terminological collocation and it should be used
as it is in the phrase pattern. The dependence on
a good collocation extraction algorithm shall be-
come more critical if we intend to use our ap-
proach on a corpus in which terminological col-
locations are very common, as is the case with the
Wall Street Journal section of the Treebank.
</bodyText>
<sectionHeader confidence="0.998856" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.997651333333333">
Web search engines have been used before to help
in tasks from natural language processing. In
(Turney, 2001), the Altavista search engine was
used for recognizing synonyms. A similar ap-
proach was followed in (Turney, 2002) in order to
detect the semantic orientation of reviews. To our
knowledge, our method represents the first attempt
to use a web search engine for solving identity and
associative anaphora in unrestricted text. Prelimi-
nary results are promising and compare well with
other methods. There is still room for improve-
ment - a direction to follow is that of enhancing
the current method with the ability to detect collo-
cations and use them accordingly in the statistical
patterns. In particular, we may follow a web based
approach for finding collocations too. Another im-
provement may come from considering the dis-
tance between a definite description and a poten-
tial trigger as a factor in the trigger selection pro-
cess. We also intend to evaluate how much can be
gained by using the knowledge encoded in Word-
Net to boost potential triggers whose relation with
the associate is one of synonymy, hyponymy, or
meronymy. For this kind of relations there is also
the option of using other types of statistical pat-
terns with a potentially higher accuracy, as shown
in (Poesio et al., 2002).
</bodyText>
<sectionHeader confidence="0.99742" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999832659574468">
Kenneth W. Church and Patrick W. Hanks. 1990. Word
association norms, mutual information and lexicog-
raphy. Computational Linguistics, 16(1):22-29.
John A. Hawkins. 1978. Definiteness and Indefinite-
ness. Humanities Press, Atlantic Highlands, NJ.
K. Lund, C. Burgess, and R. A. Atchley. 1995. Se-
mantic and associative priming in highdimensional
semantic space. In Proceedings of the Seventeenth
Annual Conference of the Cognitive Science Society,
pages 660-665, Mahwah, NJ.
C. D. Manning and H. Schiitze. 1999. Foundations
of Statistical Natural Language Processing. MIT
Press, Cambridge, MA.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1994. Building a large annotated
corpus of english: The Penn Treebank. Computa-
tional Linguistics, 19(2):313-330.
Josef Meyer and Robert Dale. 2002 Mining a corpus
to support associative anaphora resolution. In 4th
Discourse Anaphora and Anaphor Resolution Col-
loquium, Lisbon, Portugal, september.
George Miller. 1991. WordNet: An on-line lexical
database. International Journal of Lexicography,
3(4).
Massimo Poesio, Renata Vieira, and Simone Teufel.
1997. Resolving bridging references in unrestricted
text. In Proc. of the ACL Workshop on Operational
Factors in Robust Anaphora Resolution, pages 1-6.
Massimo Poesio, Sabine Schulte im Walde, and Chris
Brew. 1998. Lexical clustering and definite descrip-
tion interpretation. In AAAI Spring Symposium on
Leaming for Discourse, pages 82-89, Stanford, CA,
march.
Massimo Poesio, Tomonori Ishikawa, Sabine Schulte
im Walde, and Renata Vieira. 2002. Acquiring lexi-
cal knowledge for anaphora resolution. In Proceed-
ings of LREC, Las Palmas, Spain.
Peter D. Turney. 2001. Mining the web for synonyms:
PMI-IR versus LSA on TOEFL. In Proc. of the
12th European Conference on Machine Learning,
Freiburg, Germany, september.
Peter D. Turney. 2002. Thumbs up or thumbs down?
Semantic orientation applied to unsupervised classi-
fication of reviews. In Proceedings of the 40th An-
nual Meeting of the Association for Computational
Linguistics, pages 417-424, Philadelphia, Pennsyl-
vania.
</reference>
<page confidence="0.998856">
52
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.376171">
<title confidence="0.99973">Associative Anaphora Resolution: A Web-Based Approach</title>
<author confidence="0.983657">Razvan</author>
<affiliation confidence="0.791924333333333">Department of Computer University of Texas at Austin, TX</affiliation>
<email confidence="0.999302">razvan@cs.utexas.edu</email>
<abstract confidence="0.999488">We present a novel approach to solving definite descriptions in unrestricted text based on searching the web for a particular type of lexico-syntactic patterns. Using statistics on these patterns, we intend to recover the antecedents for a predefined subset of definite descriptions occurring in two types of anaphoric relations: identity anaphora and associative anaphora. Preliminary results obtained with this method are promising and compare well with other methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
<author>Patrick W Hanks</author>
</authors>
<title>Word association norms, mutual information and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<pages>16--1</pages>
<contexts>
<context position="7838" citStr="Church and Hanks, 1990" startWordPosition="1281" endWordPosition="1284">verb from the phrase pattern, download each matching document and filter out those documents in which the second noun from the pattern had a subordinate relative clause or an attached prepositional phrase. This however would be very time consuming and would require too much network traffic. Q(nt,na) = &amp;quot;fnt/ &amp;quot; NEAR &amp;quot;the [nal&amp;quot; Vnt) = &amp;quot;Intl&amp;quot; Q(na) = &amp;quot;the [nal&amp;quot; Figure 2: NEAR Patterns The exact method for computing the degree of anaphoric association between a potential trigger noun nt and a potential associate noun na is based on the information-theoretic measure of pointwise mutual information (Church and Hanks, 1990; Manning and Schiitze, 1999). If we denote with N the total number of web documents indexed by a search engine, and with D(query) the number of web documents returned by the same search engine with the given query, then the degree of association (when we use either the Phrase pattern or the NEAR pattern) will be given by /(nt, Tha) computed as in Figure 3. I(n),na) = log2 P(c2(nt,n.))P(Q(nt))P(C2(%)) D(Q(nt,na)) log2 N D(Q(nt)),,D(Q(na)) , N*D(Q(nt,na)) — log2 D(Q(Tht))*D(Q(Tha)) Figure 3: Pointwise Mutual Information the number of hits that the Altavistal search engine returns for the three </context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth W. Church and Patrick W. Hanks. 1990. Word association norms, mutual information and lexicography. Computational Linguistics, 16(1):22-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Hawkins</author>
</authors>
<title>Definiteness and Indefiniteness.</title>
<date>1978</date>
<publisher>Humanities Press,</publisher>
<location>Atlantic Highlands, NJ.</location>
<contexts>
<context position="1027" citStr="Hawkins, 1978" startWordPosition="146" endWordPosition="147">nts for a predefined subset of definite descriptions occurring in two types of anaphoric relations: identity anaphora and associative anaphora. Preliminary results obtained with this method are promising and compare well with other methods. 1 Introduction Definite descriptions (noun phrases beginning with a definite article) have been extensively studied in linguistics, philosophy and computational linguistics and different authors have proposed different schemes for classifying possible uses of definite descriptions. The terminology that we use here is based on that introduced by Hawkins in (Hawkins, 1978) and is simplified by the fact that we are concerned with two types only: • Identity Anaphora This is the same as Hawkins&apos; anaphoric use, and subsumes definite descriptions that refer to the same entity as a previous phrase (antecedent) in the discourse. Examples: 1. Fred was discussing an interesting book in his class. I went to discuss the book with him afterwards. 2. Fred was wearing trousers. The pants had a big patch on them. • Associative Anaphora This corresponds to Hawkins&apos; associative anaphoric use, and refers to definite descriptions whose referent is uniquely identifiable based on g</context>
</contexts>
<marker>Hawkins, 1978</marker>
<rawString>John A. Hawkins. 1978. Definiteness and Indefiniteness. Humanities Press, Atlantic Highlands, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Lund</author>
<author>C Burgess</author>
<author>R A Atchley</author>
</authors>
<title>Semantic and associative priming in highdimensional semantic space.</title>
<date>1995</date>
<booktitle>In Proceedings of the Seventeenth Annual Conference of the Cognitive Science Society,</booktitle>
<pages>660--665</pages>
<location>Mahwah, NJ.</location>
<contexts>
<context position="3352" citStr="Lund et al., 1995" startWordPosition="521" endWordPosition="524">tracting the triggers of anaphoric definite descriptions is not an easy task. In one experiment 47 (Poesio et al., 1997), the authors exploited the WordNet lexical database (Miller, 1991) in order to account for the commonsense knowledge that humans seem to employ when solving definite descriptions. Another approach (Poesio et al., 1998) tried to address the incompletness of the information hand-coded in WordNet by hypothesizing a semantic priming effect between a trigger and its associate which could be detected automatically using a lexical clustering algorithm similar to that described in (Lund et al., 1995). In (Meyer and Dale, 2002) lexico-syntactic patterns have been used to mine lexical associative axioms from a corpus of 2000 encyclopaedia articles. These associations were further generalized based on WordNet and their performance was evaluated on a set of five anaphoric heads. Our method, as described in the following sections, combines the power of a different type of lexico-syntactic patterns with the huge coverage offered by the world wide web. 2 The Method Given a pair of nouns nt:na occurring in the same document, we want to detect how likely it is that the two nouns are in a trigger:a</context>
</contexts>
<marker>Lund, Burgess, Atchley, 1995</marker>
<rawString>K. Lund, C. Burgess, and R. A. Atchley. 1995. Semantic and associative priming in highdimensional semantic space. In Proceedings of the Seventeenth Annual Conference of the Cognitive Science Society, pages 660-665, Mahwah, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Manning</author>
<author>H Schiitze</author>
</authors>
<date>1999</date>
<booktitle>Foundations of Statistical Natural Language Processing.</booktitle>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="7867" citStr="Manning and Schiitze, 1999" startWordPosition="1285" endWordPosition="1288">tern, download each matching document and filter out those documents in which the second noun from the pattern had a subordinate relative clause or an attached prepositional phrase. This however would be very time consuming and would require too much network traffic. Q(nt,na) = &amp;quot;fnt/ &amp;quot; NEAR &amp;quot;the [nal&amp;quot; Vnt) = &amp;quot;Intl&amp;quot; Q(na) = &amp;quot;the [nal&amp;quot; Figure 2: NEAR Patterns The exact method for computing the degree of anaphoric association between a potential trigger noun nt and a potential associate noun na is based on the information-theoretic measure of pointwise mutual information (Church and Hanks, 1990; Manning and Schiitze, 1999). If we denote with N the total number of web documents indexed by a search engine, and with D(query) the number of web documents returned by the same search engine with the given query, then the degree of association (when we use either the Phrase pattern or the NEAR pattern) will be given by /(nt, Tha) computed as in Figure 3. I(n),na) = log2 P(c2(nt,n.))P(Q(nt))P(C2(%)) D(Q(nt,na)) log2 N D(Q(nt)),,D(Q(na)) , N*D(Q(nt,na)) — log2 D(Q(Tht))*D(Q(Tha)) Figure 3: Pointwise Mutual Information the number of hits that the Altavistal search engine returns for the three phrase queries illustrated in</context>
</contexts>
<marker>Manning, Schiitze, 1999</marker>
<rawString>C. D. Manning and H. Schiitze. 1999. Foundations of Statistical Natural Language Processing. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of english: The Penn Treebank. Computational Linguistics,</title>
<date>1994</date>
<pages>19--2</pages>
<contexts>
<context position="9063" citStr="Marcus et al., 1994" startWordPosition="1494" endWordPosition="1497">e queries illustrated in Figure 1 and compute I(nt, na) accordingly. If there is no association (in the anaphoric sense) between nt and na, then the numerator and denominator tend to have the same value, and the pointwise mutual information will be close to 0. On the other hand, if nt and na can be related in associative anaphora, then there will be a dependence between the events involved in the probabilities from Figure 3, which will result in a higher value for /(nt, na). 3 Experimental Evaluation We tested our method on the first 32 documents from the Brown section of the Treebank corpus (Marcus et al., 1994) (cf01 to cf32). For each document, we created a list of potential associates consisting of definite descriptions with only one noun, with the additional constraint that no prepositional phrase or relative phrase was attached to them (in this way we focused our method on those definite descriptions that were most susceptible to be anaphoric). We have also excluded from the set of possible associates all definite descriptions whose head noun had occurred before in the document (as is the case with the first example of identity anaphora in Section 1). The resulting list of potential associates c</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1994</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1994. Building a large annotated corpus of english: The Penn Treebank. Computational Linguistics, 19(2):313-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josef Meyer</author>
<author>Robert Dale</author>
</authors>
<title>Mining a corpus to support associative anaphora resolution.</title>
<date>2002</date>
<booktitle>In 4th Discourse Anaphora and Anaphor Resolution Colloquium,</booktitle>
<location>Lisbon, Portugal,</location>
<contexts>
<context position="3379" citStr="Meyer and Dale, 2002" startWordPosition="526" endWordPosition="529"> anaphoric definite descriptions is not an easy task. In one experiment 47 (Poesio et al., 1997), the authors exploited the WordNet lexical database (Miller, 1991) in order to account for the commonsense knowledge that humans seem to employ when solving definite descriptions. Another approach (Poesio et al., 1998) tried to address the incompletness of the information hand-coded in WordNet by hypothesizing a semantic priming effect between a trigger and its associate which could be detected automatically using a lexical clustering algorithm similar to that described in (Lund et al., 1995). In (Meyer and Dale, 2002) lexico-syntactic patterns have been used to mine lexical associative axioms from a corpus of 2000 encyclopaedia articles. These associations were further generalized based on WordNet and their performance was evaluated on a set of five anaphoric heads. Our method, as described in the following sections, combines the power of a different type of lexico-syntactic patterns with the huge coverage offered by the world wide web. 2 The Method Given a pair of nouns nt:na occurring in the same document, we want to detect how likely it is that the two nouns are in a trigger:associate relationship. To a</context>
</contexts>
<marker>Meyer, Dale, 2002</marker>
<rawString>Josef Meyer and Robert Dale. 2002 Mining a corpus to support associative anaphora resolution. In 4th Discourse Anaphora and Anaphor Resolution Colloquium, Lisbon, Portugal, september.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Miller</author>
</authors>
<title>WordNet: An on-line lexical database.</title>
<date>1991</date>
<journal>International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="2921" citStr="Miller, 1991" startWordPosition="455" endWordPosition="456"> pants, forest: the trees, restaurant: the atmosphere, restaurant: the service. The types of relations involved in associative anaphora can be very diverse, from meronymy as in forest: the trees, to attributes as in car: the price, to complex relationships as in Auschwitz: the victims. Therefore, we will concern ourselves with identifying trigger:associate pairs, without establishing the exact type of their association. Extracting the triggers of anaphoric definite descriptions is not an easy task. In one experiment 47 (Poesio et al., 1997), the authors exploited the WordNet lexical database (Miller, 1991) in order to account for the commonsense knowledge that humans seem to employ when solving definite descriptions. Another approach (Poesio et al., 1998) tried to address the incompletness of the information hand-coded in WordNet by hypothesizing a semantic priming effect between a trigger and its associate which could be detected automatically using a lexical clustering algorithm similar to that described in (Lund et al., 1995). In (Meyer and Dale, 2002) lexico-syntactic patterns have been used to mine lexical associative axioms from a corpus of 2000 encyclopaedia articles. These associations </context>
</contexts>
<marker>Miller, 1991</marker>
<rawString>George Miller. 1991. WordNet: An on-line lexical database. International Journal of Lexicography, 3(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
<author>Renata Vieira</author>
<author>Simone Teufel</author>
</authors>
<title>Resolving bridging references in unrestricted text.</title>
<date>1997</date>
<booktitle>In Proc. of the ACL Workshop on Operational Factors in Robust Anaphora Resolution,</booktitle>
<pages>1--6</pages>
<contexts>
<context position="2854" citStr="Poesio et al., 1997" startWordPosition="444" endWordPosition="447">five trigger:associate pairs: an interesting book: the book, trousers: the pants, forest: the trees, restaurant: the atmosphere, restaurant: the service. The types of relations involved in associative anaphora can be very diverse, from meronymy as in forest: the trees, to attributes as in car: the price, to complex relationships as in Auschwitz: the victims. Therefore, we will concern ourselves with identifying trigger:associate pairs, without establishing the exact type of their association. Extracting the triggers of anaphoric definite descriptions is not an easy task. In one experiment 47 (Poesio et al., 1997), the authors exploited the WordNet lexical database (Miller, 1991) in order to account for the commonsense knowledge that humans seem to employ when solving definite descriptions. Another approach (Poesio et al., 1998) tried to address the incompletness of the information hand-coded in WordNet by hypothesizing a semantic priming effect between a trigger and its associate which could be detected automatically using a lexical clustering algorithm similar to that described in (Lund et al., 1995). In (Meyer and Dale, 2002) lexico-syntactic patterns have been used to mine lexical associative axiom</context>
</contexts>
<marker>Poesio, Vieira, Teufel, 1997</marker>
<rawString>Massimo Poesio, Renata Vieira, and Simone Teufel. 1997. Resolving bridging references in unrestricted text. In Proc. of the ACL Workshop on Operational Factors in Robust Anaphora Resolution, pages 1-6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
<author>Sabine Schulte im Walde</author>
<author>Chris Brew</author>
</authors>
<title>Lexical clustering and definite description interpretation.</title>
<date>1998</date>
<booktitle>In AAAI Spring Symposium on Leaming for Discourse,</booktitle>
<pages>82--89</pages>
<location>Stanford, CA,</location>
<contexts>
<context position="3073" citStr="Poesio et al., 1998" startWordPosition="478" endWordPosition="481">ry diverse, from meronymy as in forest: the trees, to attributes as in car: the price, to complex relationships as in Auschwitz: the victims. Therefore, we will concern ourselves with identifying trigger:associate pairs, without establishing the exact type of their association. Extracting the triggers of anaphoric definite descriptions is not an easy task. In one experiment 47 (Poesio et al., 1997), the authors exploited the WordNet lexical database (Miller, 1991) in order to account for the commonsense knowledge that humans seem to employ when solving definite descriptions. Another approach (Poesio et al., 1998) tried to address the incompletness of the information hand-coded in WordNet by hypothesizing a semantic priming effect between a trigger and its associate which could be detected automatically using a lexical clustering algorithm similar to that described in (Lund et al., 1995). In (Meyer and Dale, 2002) lexico-syntactic patterns have been used to mine lexical associative axioms from a corpus of 2000 encyclopaedia articles. These associations were further generalized based on WordNet and their performance was evaluated on a set of five anaphoric heads. Our method, as described in the followin</context>
<context position="14597" citStr="Poesio et al., 1998" startWordPosition="2454" endWordPosition="2457">2. In the second baseline, each potential associate was considered triggered by the closest preceding noun. The precision was 3.4% at a recall of 6.2%. 4 Discussion of results The precision-recall graphs show a significant better performance for the Phrase pattern when compared with the NEAR pattern, confirming our intuition about the importance of enforcing two anaphoric features in the statistical pattern: the asymmetry of the trigger:association relationship and the fact that associates do not need establishing modifiers or relative clauses. The method compares well with the approach from (Poesio et al., 1998) where precision and recall on the class of inferential descriptions were 22.7%. At the same recall our method has a precision of 53%. However the comparison is complicated by the fact that the test sets are from different sections of Treebank, plus the fact that our set of potential associates was created using a different method which, as described at the beginning of Section 3, did not take into account the manual annotation of the document. The approach presented here also validates the prediction made in the same paper (Poesio et al., 1998), namely that statistical pattern matching may pr</context>
</contexts>
<marker>Poesio, Walde, Brew, 1998</marker>
<rawString>Massimo Poesio, Sabine Schulte im Walde, and Chris Brew. 1998. Lexical clustering and definite description interpretation. In AAAI Spring Symposium on Leaming for Discourse, pages 82-89, Stanford, CA, march.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
<author>Tomonori Ishikawa</author>
<author>Sabine Schulte im Walde</author>
<author>Renata Vieira</author>
</authors>
<title>Acquiring lexical knowledge for anaphora resolution.</title>
<date>2002</date>
<booktitle>In Proceedings of LREC, Las</booktitle>
<location>Palmas,</location>
<marker>Poesio, Ishikawa, Walde, Vieira, 2002</marker>
<rawString>Massimo Poesio, Tomonori Ishikawa, Sabine Schulte im Walde, and Renata Vieira. 2002. Acquiring lexical knowledge for anaphora resolution. In Proceedings of LREC, Las Palmas, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Mining the web for synonyms: PMI-IR versus LSA on TOEFL.</title>
<date>2001</date>
<booktitle>In Proc. of the 12th European Conference on Machine Learning,</booktitle>
<location>Freiburg, Germany,</location>
<contexts>
<context position="19203" citStr="Turney, 2001" startWordPosition="3235" endWordPosition="3236">e 1 based only on the head nouns &amp;quot;sonata&amp;quot; and &amp;quot;movement&amp;quot;, we get no hits from the search engine. This happens because &apos;first movement&amp;quot; is a terminological collocation and it should be used as it is in the phrase pattern. The dependence on a good collocation extraction algorithm shall become more critical if we intend to use our approach on a corpus in which terminological collocations are very common, as is the case with the Wall Street Journal section of the Treebank. 5 Conclusions and Future Work Web search engines have been used before to help in tasks from natural language processing. In (Turney, 2001), the Altavista search engine was used for recognizing synonyms. A similar approach was followed in (Turney, 2002) in order to detect the semantic orientation of reviews. To our knowledge, our method represents the first attempt to use a web search engine for solving identity and associative anaphora in unrestricted text. Preliminary results are promising and compare well with other methods. There is still room for improvement - a direction to follow is that of enhancing the current method with the ability to detect collocations and use them accordingly in the statistical patterns. In particul</context>
</contexts>
<marker>Turney, 2001</marker>
<rawString>Peter D. Turney. 2001. Mining the web for synonyms: PMI-IR versus LSA on TOEFL. In Proc. of the 12th European Conference on Machine Learning, Freiburg, Germany, september.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>417--424</pages>
<location>Philadelphia, Pennsylvania.</location>
<contexts>
<context position="19317" citStr="Turney, 2002" startWordPosition="3253" endWordPosition="3254">use &apos;first movement&amp;quot; is a terminological collocation and it should be used as it is in the phrase pattern. The dependence on a good collocation extraction algorithm shall become more critical if we intend to use our approach on a corpus in which terminological collocations are very common, as is the case with the Wall Street Journal section of the Treebank. 5 Conclusions and Future Work Web search engines have been used before to help in tasks from natural language processing. In (Turney, 2001), the Altavista search engine was used for recognizing synonyms. A similar approach was followed in (Turney, 2002) in order to detect the semantic orientation of reviews. To our knowledge, our method represents the first attempt to use a web search engine for solving identity and associative anaphora in unrestricted text. Preliminary results are promising and compare well with other methods. There is still room for improvement - a direction to follow is that of enhancing the current method with the ability to detect collocations and use them accordingly in the statistical patterns. In particular, we may follow a web based approach for finding collocations too. Another improvement may come from considering</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter D. Turney. 2002. Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 417-424, Philadelphia, Pennsylvania.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>