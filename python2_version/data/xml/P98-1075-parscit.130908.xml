<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.819618">
Growing Semantic Grammars
</title>
<author confidence="0.831969">
Marsal Gayalda and Alex Waibel
</author>
<affiliation confidence="0.819639666666667">
Interactive Systems Laboratories
Carnegie Mellon University
Pittsburgh, PA 15213, U.S.A.
</affiliation>
<email confidence="0.998862">
marsal@cs.cmu.edu
</email>
<sectionHeader confidence="0.994795" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9985092">
A critical path in the development of natural language
understanding (NLU) modules lies in the difficulty of
defining a mapping from words to semantics: Usually it
takes in the order of years of highly-skilled labor to de-
velop a semantic mapping, e.g., in the form of a semantic
grammar, that is comprehensive enough for a given do-
main. Yet, due to the very nature of human language,
such mappings invariably fail to achieve full coverage on
unseen data. Acknowledging the impossibility of stat-
ing a priori all the surface forms by which a concept can
be expressed, we present GSG: an empathic computer
system for the rapid deployment of NLU front-ends and
their dynamic customization by non-expert end-users.
Given a new domain for which an NLU front-end is to
be developed, two stages are involved. In the author-
ing stage, GSG aids the developer in the construction
of a simple domain model and a kernel analysis gram-
mar. Then, in the run-time stage, GSG provides the end-
user with an interactive environment in which the kernel
grammar is dynamically extended. Three learning meth-
ods are employed in the acquisition of semantic mappings
from unseen data: (i) parser predictions, (ii) hidden un-
derstanding model, and (iii) end-user paraphrases. A
baseline version of GSG has been implemented and pre-
liminary experiments show promising results.
</bodyText>
<sectionHeader confidence="0.998878" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.993155592592593">
The mapping between words and semantics, be it in
the form of a semantic grammar,1 or of a set of rules
that transform syntax trees onto, say, a frame-slot
structure, is one of the major bottlenecks in the de-
velopment of natural language understanding (NLU)
systems. A parser will work for any domain but
the semantic mapping is domain-dependent. Even
after the domain model has been established, the
daunting task of trying to come up with all the
possible surface forms by which each concept can
&apos;Semantic grammars are grammars whose non-terminals
correspond to semantic concepts (e.g., [greeting] or
[suggest_time]) rather than to syntactic constituents (such
as Verb or NounPhrase). They have the advantage that the
semantics of a sentence can be directly read off its parse tree,
and the disadvantage that a new grammar must be developed
for each domain.
be expressed, still lies ahead. Writing such map-
pings takes in the order of years, can only be per-
formed by qualified humans (usually computational
linguists) and yet the final result is often fragile and
non-adaptive.
Following a radically different philosophy, we pro-
pose rapid (in the order of days) deployment of NLU
modules for new domains with on-need basis learn-
ing: let the semantic grammar grow automatically
when and where it is needed.
</bodyText>
<sectionHeader confidence="0.955185" genericHeader="method">
2 Grammar development
</sectionHeader>
<bodyText confidence="0.999656">
If we analyze the traditional method of developing
a semantic grammar for a new domain, we find that
the following stages are involved.
</bodyText>
<listItem confidence="0.996696142857143">
1. Data collection. Naturally-occurring data from
the domain at hand are collected.
2. Design of the domain model. A hierarchical
structuring of the relevant concepts in the do-
main is built in the form of an ontology or do-
main model.
3. Development of a kerne/ grammar. A grammar
that covers a small subset of the collected data
is constructed.
4. Expansion of grammar coverage. Lengthy, ar-
duous task of developing the grammar to extend
its coverage over the collected data and beyond.
5. Deployment. Release of the final grammar for
the application at hand.
</listItem>
<bodyText confidence="0.999937666666667">
The GSG system described in this paper aids all but
the first of these stages: For the second stage, we
have built a simple editor to design and analize the
Domain Model; for the third, a semi-automated way
of constructing the Kernel Grammar; for the fourth,
an interactive environment in which new semantic
mappings are dynamically acquired. As for the fifth
(deployment), it advances one place: after the short
initial authoring phase (stages 2 and 3 above) the
final application can already be launched, since the
semantic grammar will be extended, at run-time, by
the non-expert end-user.
</bodyText>
<sectionHeader confidence="0.96079" genericHeader="method">
3 System architecture
</sectionHeader>
<bodyText confidence="0.993285">
As depicted in Fig. 1, GSG is composed of the fol-
lowing modules: the Domain Model Editor and the
</bodyText>
<page confidence="0.999102">
451
</page>
<figureCaption confidence="0.999864">
Figure 1: System architecture of GSG.
</figureCaption>
<bodyText confidence="0.998727">
Kernel Grammar Editor, for the authoring stage,
and the SOUP parser and the IDIGA environment,
for the run-time stage.
</bodyText>
<subsectionHeader confidence="0.999951">
3.1 Authoring stage
</subsectionHeader>
<bodyText confidence="0.999869684210526">
In the authoring stage, a developer2 creates the Do-
main Model (DM) with the aid of the DM Editor.
In our present formalism, the DM is simply a di-
rected acyclic graph in which the vertices correspond
to concept-labels and the edges indicate concept-
subconcept relations (see Fig. 2 for an example).
Once the DM is defined, the Kernel Grammar Ed-
itor drives the development of the Kernel Grammar
by querying the developer to instantiate into gram-
mar rules the rule templates derived from the DM.
For instance, in the DM in Fig. 2, given that con-
cept [suggest _t ime] requires subconcept [t ime] ,
the rule template [suggest_time] [time] is
generated, which the developer can instantiate into,
say, rule (2) in Fig. 3.
The Kernel Grammar Editor follows a concrete-
to-abstract ordering of the concepts obtained via a
topological sort of the DM to query the developer,
after which the Kernel Grammar is complete3 and
</bodyText>
<footnote confidence="0.5911928">
2Understood here as a qualified person (e.g., knowledge
engineer or software developer) who is familiar with the do-
main at hand and has access to some sample sentences that
the NLU front-end is supposed to understand.
3We say that grammar G is complete with respect to do-
main model DM if and only if for each arc from concept i to
concept j in DM there is at least one grammar rule headed
by concept i that contains concept j. This ensures that any
idea expressible in DM has a surface form, or, seen it from
another angle, that any in-domain utterance has a paraphrase
</footnote>
<figure confidence="0.996802">
(greeting) (farewell) (suggestion) [rejection] [acceptance]
..s.
*1/4•0
[name(
[time)
- C-1
[interval]
•
(start_point] lend_pointl
[point]
(day_of_week) [time_of_day]
</figure>
<figureCaption confidence="0.771978">
Figure 2: Fragment of a domain model for a schedul-
ing task. A dashed edge indicates optional subconcept
(default is required), a dashed angle indicates inclusive
subconcepts (default is exclusive).
</figureCaption>
<listItem confidence="0.983261333333333">
(1) [suggestion] E— [suggest _t ime]
(2) [suggest_time] 4-- how about [time]
(3) [time] 4— [point]
(4) [point] 4— eon [day_of _week] * [t ime_of _day]
(5) [day_of _week] Tuesday
(6) ime_of _day] 4— afternoon
</listItem>
<figureCaption confidence="0.988913">
Figure 3: Fragment of a grammar for a scheduling task.
A &apos;*&apos; indicates optionality.
</figureCaption>
<bodyText confidence="0.9925885">
the NLU front-end is ready to be deployed.
It is assumed that: (i) after the authoring stage
the DM is fixed, and (ii) the communicative goal of
the end-user is expressible in the domain.
</bodyText>
<subsectionHeader confidence="0.999091">
3.2 Run-time stage
</subsectionHeader>
<bodyText confidence="0.903390125">
Instead of attempting &amp;quot;universal coverage&amp;quot; we rather
accept the fact that one can never know all the sur-
face forms by which the concepts in the domain can
be expressed. What GSG provides in the run-time
stage are mechanisms that allow a non-expert end-
user to &amp;quot;teach&amp;quot; the meaning of new expressions.
The tight coupling between the SOUP parser4 and
the IDIGA5 environment allows for a rapid and multi-
faceted analysis of the input string. If the parse, or
rather, the paraphrase automatically generated by
GsG6, is deemed incorrect by the end-user, a learn-
ing episode ensues.
that is covered by G.
4Very fast, stochastic top-down chart parser developed by
the first author incorporating heuristics to, in this order, max-
imize coverage, minimize tree complexity and maximize tree
probability.
6Acronym for interactive, distributed, incremental gram-
mar acquisition.
61n order for all the interactions with the end-user to be
performed in natural language only, a generation grammar
is needed to transform semantic representations into surface
forms. To that effect GSG is able to cleverly use the analysis
grammar in &amp;quot;reverse.&amp;quot;
</bodyText>
<equation confidence="0.422604">
(suggest_time)(reject_time) (accept_timel
</equation>
<page confidence="0.984462">
452
</page>
<bodyText confidence="0.999926285714286">
By bringing to bear contextual constraints, GSG
can make predictions as to what a sequence of un-
parsed words might mean, thereby exhibiting an
&amp;quot;empathic&amp;quot; behavior toward the end-user. To this
aim, three different learning methods are employed:
parser predictions, hidden understanding model,
and end-user paraphrases.
</bodyText>
<subsectionHeader confidence="0.978618">
3.2.1 Learning
</subsectionHeader>
<bodyText confidence="0.999769428571429">
Similar to Lehman (1989), learning in GSG takes
place by the dynamic creation of grammar rules that
capture the meaning of unseen expressions, and by
the subsequent update of the stochastic models. Ac-
quiring a new mapping from an unparsed sequence
of words onto its desired semantic representation in-
volves the following steps.
</bodyText>
<listItem confidence="0.996963818181818">
1. Hypothesis formation and filtering. Given the
context of the sentence at hand, GSG constructs
hypotheses in the form of parse trees that cover
the unparsed sequence, discards those hypothe-
ses that are not approved by the DM7 and ranks
the remaining by likelihood.
2. Interaction with the end-user. The ranked hy-
potheses are presented to the end-user in the
form of questions about, or rephrases of, the
original utterance.
3. Dynamic rule creation. If the end-user is sat-
</listItem>
<bodyText confidence="0.984375875">
isfied with one of the options, a new grammar
rule is dynamically created and becomes part
of the end-user&apos;s grammar until further notice.
Each new rule is annotated with the learning
episode that gave rise to it, including end-user
ID, time stamp, and a counter that will keep
track of how many times the new rule fires in
successful parses.8
</bodyText>
<subsectionHeader confidence="0.63065">
3.2.2 Parser predictions
</subsectionHeader>
<bodyText confidence="0.856543227272727">
As suggested by Kiyono and Tsujii (1993), one can
make use of parse failures to acquire new knowledge,
both about the nature of the unparsed words and
about the inadequacy of the existing grammar rules.
GSG uses incomplete parses to predict what can
come next (i.e. after the partially-parsed sequence
7I.e., parse trees containing concept-subconcept relations
that are inconsistent with the stipulations of the DM.
8 The degree of generalization or level of abstraction that
a new rule should exhibit is an open question but currently a
Principle of Maximal Abstraction is followed:
(a) Parse the lexical items of the new rule&apos;s right-hand-side
with all concepts granted top-level status, i.e., able to
stand at the root of a parse tree.
(b) If a word is not covered by any tree, take it as is into
the final right-hand side. Else, take the root of the parse
tree with largest span; if tie, prefer the root that ranks
higher in the DM.
For example, with the DM in Fig. 2 and the grammar in Fig. 3,
What about Tuesday? is abstracted to the maximally general
what about [time] (as opposed to what about [day_of_week]
or what about [point]&apos;).
</bodyText>
<figureCaption confidence="0.992782666666667">
Figure 4: Example of a learning episode using parser
predictions. Initially only the temporal expression is un-
derstood...
</figureCaption>
<bodyText confidence="0.996504666666667">
in left-to-right parsing, or before the partially-parsed
sequence in right-to-left parsing). This allows two
kinds of grammar acquisition:
</bodyText>
<listItem confidence="0.995892866666667">
1. Discovery of expression equivalence. E.g., with
the grammar in Fig. 3 and input sentence What
about Tuesday afternoon? GSG is able to ask
the end-user whether the utterance means the
same as How about Tuesday afternoon? (See
Figs. 4, 5 and 6). That is because in the pro-
cess of parsing What about Tuesday afternoon?
right-to-left, the parser has been able to match
rule (2) in Fig. 2 up to about, and thus it
hypothesizes the equivalence of what and how
since that would allow the parse to complete.9
2. Discovery of an ISA relation. Similarly, from
input sentence How about noon? GSG is able
to predict, in left-to-right parsing, that noon is
a [time].
</listItem>
<subsectionHeader confidence="0.779708">
3.2.3 Hidden understanding model
</subsectionHeader>
<bodyText confidence="0.797362285714286">
As another way of bringing contextual information
to bear in the process of predicting the meaning
gFor real-world grammars, of, say, over 1000 rules, it is
necessary to bound the number of partial parses by enforcing
a maximum beam size at the left-hand side level, i.e., placing
a limit on the number of subparses under each nonterminal
to curb the exponential explosion.
</bodyText>
<figure confidence="0.999607409090909">
Learning
Bed
ilkinccessad
Ensorwook „ET]
1
Clear n
Gwent Sentence
Neeeent Thenree-ease
Autequatle Rephrase
tuesday afternoon
rnSnitech Arg3
Previous Sentences
.4
1■YhataboutTuesdayaftemocc?
kiterpretation
tine)
.-ipoint1
+-iday_pf_waek)
1
I .-tumaday
+-Itime_of_daY]
I.-afternoon
</figure>
<page confidence="0.936714">
453
</page>
<figureCaption confidence="0.985319">
Figure 5: ...but a correct prediction is made...
</figureCaption>
<figure confidence="0.819989193548387">
Amalmortioa. I I 4
Previous Sentences
What about Tuesday afternoon? i
\PI
Cumint Sentence I Clear I
What about Tuesday afternoon? I
Interpretation 100 S Coverage 1 :Simeon Acts
auggootioni
I
+-Ergo. Lair]
.-ubat
.-about
.-Etlem)
1
.-ipoint]
I
•-(day_of_wook 3
I I
1 .-cummlay
I
4,-(timm_of_day]
1
r,
Automatic Rephrase
lotat about tbesday afternoon
IN fi,1
(-------a--- --II
teeming _Er? jAireedY Ok ET Stiteessful ......EnUnaucceSSU
INEAV rule: (suggest _time) &lt;-- what about [time] (From Nwhat about tuesday afternoe
_
• ,
</figure>
<figureCaption confidence="0.999645">
Figure 6: ...and a new rule is acquired.
</figureCaption>
<bodyText confidence="0.99681">
of unparsed words, the following stochastic models,
inspired in Miller et al. (1994) and Seneff (1992),
and collectively referred to as hidden understanding
model (HUM), are employed.
</bodyText>
<listItem confidence="0.995840777777778">
• Speech-act n-gram. Top-level concepts can be
seen as speech acts of the domain. For instance,
in the DM in Fig. 2 top-level concepts such
as [greeting], [farewell] or [suggest ion] ,
correspond to discourse speech acts, and in
normally-occurring conversation, they follow a
distribution that is clearly non-uniform.1°
• Concept-subconcept HMM. Discrete hidden
Markov model in which the states correspond
</listItem>
<tableCaption confidence="0.77760025">
10Needless to say, speech-act transition distributions
are empirically estimated, but, intuitively, the sequence
&lt; [greeting], [suggestion] &gt; is more likely than the se-
quence &lt; [greeting], [farewell]&gt;.
</tableCaption>
<bodyText confidence="0.999801625">
to the concepts in the DM (i.e., equivalent to
grammar non-terminals) and the observations
to the embedded concepts appearing as imme-
diate daughters of the state in a parse tree.
For example, the parse tree in Fig. 4 contains
the following set of &lt;state, observation&gt; pairs:
{ &lt; [t ime] , [point] &gt; , &lt; [po int] , [day_of _veek] &gt;,
&lt; [po int] , Et ime_of _day] &gt;} .
</bodyText>
<listItem confidence="0.783889">
• Concept-word HMM. Discrete hidden Markov
</listItem>
<bodyText confidence="0.989074173913044">
model in which the states correspond to the con-
cepts in the DM and the observations to the em-
bedded lexical items (i.e., grammar terminals)
appearing as immediate daughters of the state
in a parse tree. For example, the parse tree
in Fig. 4 contains the pairs: {&lt;[day_of_week],
tuesday&gt;, &lt; [t ime_of _day] , afternoon&gt;}.
The HUM thus attempts to capture the recurring
patterns of the language used in the domain in an
asynchronous mode, i.e., independent of word order
(as opposed to parser predictions that heavily de-
pend on word order). Its aim is, again, to provide
predictive power at run-time: upon encountering an
unparsable expression, the HUM hypothesizes possi-
ble intended meanings in the form of a ranked list of
the most likely parse trees, given the current state in
the discourse, the subparses for the expression and
the lexical items present in the expression.
Its parameters can be best estimated through
training over a given corpus of correct parses, but
in order not to compromise our established goal of
rapid deployment, we employ the following tech-
niques.
</bodyText>
<listItem confidence="0.997105">
1. In the absence of a training corpus, the HUM
parameters are seeded from the Kernel Gram-
mar itself.
2. Training is maintained at run-time through dy-
namic updates of all model parameters after
each utterance and learning episode.
</listItem>
<subsubsectionHeader confidence="0.752329">
3.2.4 End-user paraphrases
</subsubsectionHeader>
<bodyText confidence="0.999692625">
If the end-user is not satisfied with the hypotheses
presented by the parser predictions or the HUM, a
third learning method is triggered: learning from
a paraphrase of the original utterance, given also
by the end-user. Assuming the paraphrase is
understood,&amp;quot; GSG updates the grammar in such a
fashion so that the semantics of the first sentence
are equivalent to those of the paraphrase.12
</bodyText>
<footnote confidence="0.9781995">
11 Precisely, the requirement that the grammar be complete
(see note 3) ensures the existence of a suitable paraphrase for
any utterance expressible in the domain. In practice, however,
it may take too many attempts to find an appropriate para-
phrase. Currently, if the first paraphrase is not understood,
no further requests are made.
12Presently, the root of the paraphrase&apos;s parse tree directly
becomes the left-hand-side of the new rule.
</footnote>
<page confidence="0.994408">
454
</page>
<table confidence="0.99941">
Perfect Ok Bad
Expert before 55.41 17.58 27.01
Expert after 75.68 10.81 13.51
A +20.27 -6.77 -13.50
End-user&apos; before 58.11 18.92 22.97
End-user&apos; after 64.86 22.97 12.17
A +6.75 +4.05 -10.80
End-user2 before 41.89 16.22 41.89
End-user2 after 48.64 28.38 22.98
A +6.75 +12.16 -18.91
</table>
<tableCaption confidence="0.9981255">
Table 1: Comparison of parse grades (in %). Expert
using traditional method vs. non-experts using GSG.
</tableCaption>
<sectionHeader confidence="0.955384" genericHeader="method">
4 Preliminary results
</sectionHeader>
<bodyText confidence="0.985398725">
We have conducted a series of preliminary exper-
iments in different languages (English, German and
Chinese) and domains (scheduling, travel reserva-
tions). We present here the results for an experiment
involving the comparison of expert vs. non-expert
grammar development on a spontaneous travel reser-
vation task in English. The grammar had been de-
veloped over the course of three months by a full-
time expert grammar writer and the experiment con-
sisted in having this expert develop on an unseen
set of 72 sentences using the traditional environment
and asking two non-expert users13 to &amp;quot;teach&amp;quot; GSG
the meaning of the same 72 sentences through in-
teractions with the system. Table 1 compares the
correct parses before and after development.
It took the expert 15 minutes to add 8 rules and
reduce bad coverage from 27.01% to 13.51%. As
for the non-experts, end-useri , starting with a sim-
ilar grammar, reduced bad parses from 22.97% to
12.17% through a 30-minute session14 with GSG that
gave rise to 8 new rules; end-user2, starting with the
smallest possible complete grammar, reduced bad
parses from 41.89% to 22.98% through a 35-minute
session14 that triggered the creation of 17 new rules.
60% of the learning episodes were successful, with
an average number of questions of 2.91. The unsuc-
cessful learning episodes had an average number of
questions of 6.19 and their failure is mostly due to
unsuccessful paraphrases.
As for the nature of the acquired rules, they dif-
fer in that the expert makes use of optional and re-
peatable tokens, an expressive power not currently
available to GSG. On the other hand this lack of
generality can be compensated by the Principle of
Maximal Abstraction (see note 8). As an example,
to cover the new construction And your last name?,
the expert chose to create the rule:
[request_name] 4- *and your last name
&apos;3Undergraduate students not majoring in computer sci-
ence or linguistics.
</bodyText>
<subsectionHeader confidence="0.632463">
14 Including a 5-minute introduction.
</subsectionHeader>
<bodyText confidence="0.9935145">
whereas both end-useri and end-user2 induced the
automatic acquisition of the rule:
</bodyText>
<sectionHeader confidence="0.7395905" genericHeader="method">
[request.name] CONJ POSS [last] name.&amp;quot;
5 Discussion
</sectionHeader>
<bodyText confidence="0.9999336">
Although preliminary and limited in scope, these
results are encouraging and suggest that grammar
development by non-experts through GSG is indeed
possible and cost-effective. It can take the non-
expert twice as long as the expert to go through a set
of sentences, but the main point is that it is possible
at all for a user with no background in computer sci-
ence or linguistics to teach GSG the meaning of new
expressions without being aware of the underlying
machinery.
Potential applications of GSG are many, most no-
tably a very fast development of NLU components
for a variety of tasks including speech recognition
and NL interfaces. Also, the IDIGA environment
enhances the usability of any system or application
that incorporates it, for the end-users are able to eas-
ily &amp;quot;teach the computer&amp;quot; their individual language
patterns and preferences.
Current and future work includes further develop-
ment of the learning methods and their integration,
design of a rule-merging mechanism, comparison
of individual vs. collective grammars, distributed
grammar development over the World Wide Web,
and integration of GsG&apos;s run-time stage into the
JANUS speech recognition system (Lavie et al. 1997).
</bodyText>
<sectionHeader confidence="0.99573" genericHeader="method">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.651165666666667">
The work reported in this paper was funded in part by
a grant from ATR Interpreting Telecommunications Re-
search Laboratories of Japan.
</bodyText>
<sectionHeader confidence="0.976218" genericHeader="conclusions">
References
</sectionHeader>
<bodyText confidence="0.5659305">
Kiyono, Masaki and Jun-ichi Tsujii. 1993. &amp;quot;Linguistic
knowledge acquisition from parsing failures.&amp;quot; In Pro-
ceedings of the 6th Conference of the European Chap-
ter of the ACL.
</bodyText>
<reference confidence="0.964978176470588">
Lavie, Alon, Alex Waibel, Lori Levin, Michael Finke,
Donna Gates, Marsal Gavalda, Torsten Zeppenfeld,
and Puming Zhan. 1997. &amp;quot;JANus III: speech-to-
speech translation in multiple languages.&amp;quot; In Proceed-
ings of ICASSP-97.
Lehman, Jill Fain. 1989. Adaptive parsing: Self-
extending natural language interfaces. Ph.D. disserta-
tion, School of Computer Science, Carnegie Mellon
University.
Miller, Scott, Robert Bobrow, Robert Ingria, and
Richard Schwartz. 1994. &amp;quot;Hidden understanding mod-
els of natural language.&amp;quot; In Proceedings of ACL-94.
Seneff, Stephanie. 1992. &amp;quot;TINA: a natural language sys-
tem for spoken language applications.&amp;quot; In Computa-
tional Linguistics, vol. 18, no. 1, pp. 61-83.
15Uppercased nonterminals (such as CONJ and POSS) are
more syntactical in nature and do not depend on the DM.
</reference>
<page confidence="0.999187">
455
</page>
<sectionHeader confidence="0.893828" genericHeader="references">
Resum
</sectionHeader>
<bodyText confidence="0.99982734920635">
Un dels camins critics en el desenvolupament
de moduls de comprensiO del llenguatge natural
passa per la dificultat de definir la funcio que
assigna, a una seqiiencia de mots, la representaciO
semantica desitjada. Els metodes tradicionals per
definir aquesta correspondencia requereixen l&apos;esforg
de lingiiistes computacionals, que dediquen mesos o
adhuc anys construint, per exemple, una gramatica
semantica (formalisme en el qual els simbols no ter-
minals de la gramatica corresponen directament als
conceptes del domini de l&apos;aplicaciO determinada),
tanmateix, degut precisament a la propia natura del
llenguatge hurna, la gramatica resultant mai no es
capag de cobrir tots els mots i expressions que ocor-
ren naturalment al domini en qiiestiO.
Reconeixent per tant la impossibilitat d&apos;establir a
priori totes les formes superficials amb que un con-
cepte pot ser expressat, presentem en aquest tre-
ball GSG: un sistema computacional empatic per
al rapid desplegament de moduls de comprensiO del
llenguatge natural i Ilur adaptacio dinamica a les
particularitats i preferencies d&apos;usuaris finals inex-
perts.
El proces de construcciO d&apos;un modul de corn-
prensiO del llenguatge natural per a un nou domini
pot ser dividit en dues parts. Primerament, durant
la fase de cornposicio, GSG ajuda el desenvolupador
expert en l&apos;estructuraciO dels conceptes del domini
(ontologia) i en l&apos;establiment d&apos;una gramatica mi-
nimal. Tot seguit, durant la fase d&apos;erecucio, GSG
forneix l&apos;usuari final inexpert d&apos;un medi interactiu
en que la gramatica es augmentada dinamicament.
Tres metodes d&apos;aprenentatge automatic sOn uti-
litzats en l&apos;adquisiciO de regles gramaticals a partir
de noves frases i construccions: (i) prediccions de
l&apos;analitzador (GSG empra analisis incompletes per
conjecturar quins mots poden apareixer tant despres
de l&apos;arbre incomplet, en analisi d&apos;esquerra
a dreta, corn abans de l&apos;arbre incomplet, en
analisi de dreta a esquerra), (ii) cadenes de Markov
(metodes estocastics que modelen, independentment
de l&apos;ordre dels mots, la distribuciO dels conceptes i
llurs transicions, emprats per calcular el concepte
global mes probable donats un context i uns arbres
d&apos;analisi parcials determinats), i (iii) parafrasis (em-
prades per assignar llur representaciO semantica a la
frase original).
Hem implementat una primera versio de GSG i els
resultats obtinguts, per be que preliminars, son ben
encoratjadors car demostren que un usuari inexpert
pot &amp;quot;ensenyar&amp;quot; a GSG el significat de noves expres-
sions i causar una extensiO de la gramatica compa-
rable a la d&apos;un expert.
Actualment estem treballant en la millora dels
metodes automatics d&apos;aprenentatge i llur inte-
gracio, en el disseny d&apos;un mecanisme de corn-
binaciO automatica de regles gramaticals, en
la comparaciO de gramatiques individuals amb
gramatiques collectives, en el desenvolupament
distribuit de gramatiques a tray&amp; de la World
Wide Web, i en la integraciO de la fase
d&apos;execuciO de GSG en el sistema de reconeixe-
ment de la parla i traducci6 automatica JANUS.
</bodyText>
<figure confidence="0.949819409090909">
4A-A-
Ait4A-44-31.044A0A-k*A,tE
tAliCAkisIAL00341:=EV4—+44
X0Aitii--+A-4k11/0*51-AA-(—
*401c44A4A-A34-5C*7
t*—++AAAJL4001-M0lViAttit
4A*1-1,-k4-01A+1,1Mit#00341-
t,* SAM 4- iT fig it
Aitti4ttit4,AMAGsG:
1-1%taAlAtIA*1-Plit4A,*43tiA
VA*45*itA04-1zAP04-g-J-310
IttAVA,.
*34—+*X0411A,AA*PIAIF
Wtif3As3?i§,. GSG
Wh3t3ti.Al_A—+M400AAS140
---+4;41.1*R,GsGgp-AP
44J4—+I-44474t0640
GsGA-A=#11-4tt*Agagt
1-&apos;144$01A*:ita-WARI,MIlit*
411,4vAP**.
AMW—÷0G4t1,44,*
4-T UO
</figure>
<page confidence="0.993803">
456
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.959601">
<title confidence="0.999971">Growing Semantic Grammars</title>
<author confidence="0.992189">Gayalda Waibel</author>
<affiliation confidence="0.998714">Interactive Systems Laboratories Carnegie Mellon University</affiliation>
<address confidence="0.977129">Pittsburgh, PA 15213, U.S.A.</address>
<email confidence="0.999499">marsal@cs.cmu.edu</email>
<abstract confidence="0.999625461538461">A critical path in the development of natural language understanding (NLU) modules lies in the difficulty of defining a mapping from words to semantics: Usually it takes in the order of years of highly-skilled labor to develop a semantic mapping, e.g., in the form of a semantic grammar, that is comprehensive enough for a given domain. Yet, due to the very nature of human language, such mappings invariably fail to achieve full coverage on unseen data. Acknowledging the impossibility of stating a priori all the surface forms by which a concept can expressed, we present empathic computer system for the rapid deployment of NLU front-ends and their dynamic customization by non-expert end-users. Given a new domain for which an NLU front-end is to be developed, two stages are involved. In the authorstage, the the construction of a simple domain model and a kernel analysis gram- Then, in the run-time stage, the enduser with an interactive environment in which the kernel grammar is dynamically extended. Three learning methods are employed in the acquisition of semantic mappings from unseen data: (i) parser predictions, (ii) hidden understanding model, and (iii) end-user paraphrases. A version of been implemented and preliminary experiments show promising results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alon Lavie</author>
<author>Alex Waibel</author>
<author>Lori Levin</author>
<author>Michael Finke</author>
<author>Donna Gates</author>
</authors>
<title>Marsal Gavalda, Torsten Zeppenfeld, and Puming Zhan.</title>
<date>1997</date>
<booktitle>In Proceedings of ICASSP-97.</booktitle>
<marker>Lavie, Waibel, Levin, Finke, Gates, 1997</marker>
<rawString>Lavie, Alon, Alex Waibel, Lori Levin, Michael Finke, Donna Gates, Marsal Gavalda, Torsten Zeppenfeld, and Puming Zhan. 1997. &amp;quot;JANus III: speech-tospeech translation in multiple languages.&amp;quot; In Proceedings of ICASSP-97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jill Fain Lehman</author>
</authors>
<title>Adaptive parsing: Selfextending natural language interfaces.</title>
<date>1989</date>
<institution>School of Computer Science, Carnegie Mellon University.</institution>
<note>Ph.D. dissertation,</note>
<contexts>
<context position="8319" citStr="Lehman (1989)" startWordPosition="1356" endWordPosition="1357"> to be performed in natural language only, a generation grammar is needed to transform semantic representations into surface forms. To that effect GSG is able to cleverly use the analysis grammar in &amp;quot;reverse.&amp;quot; (suggest_time)(reject_time) (accept_timel 452 By bringing to bear contextual constraints, GSG can make predictions as to what a sequence of unparsed words might mean, thereby exhibiting an &amp;quot;empathic&amp;quot; behavior toward the end-user. To this aim, three different learning methods are employed: parser predictions, hidden understanding model, and end-user paraphrases. 3.2.1 Learning Similar to Lehman (1989), learning in GSG takes place by the dynamic creation of grammar rules that capture the meaning of unseen expressions, and by the subsequent update of the stochastic models. Acquiring a new mapping from an unparsed sequence of words onto its desired semantic representation involves the following steps. 1. Hypothesis formation and filtering. Given the context of the sentence at hand, GSG constructs hypotheses in the form of parse trees that cover the unparsed sequence, discards those hypotheses that are not approved by the DM7 and ranks the remaining by likelihood. 2. Interaction with the end-u</context>
</contexts>
<marker>Lehman, 1989</marker>
<rawString>Lehman, Jill Fain. 1989. Adaptive parsing: Selfextending natural language interfaces. Ph.D. dissertation, School of Computer Science, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Miller</author>
<author>Robert Bobrow</author>
<author>Robert Ingria</author>
<author>Richard Schwartz</author>
</authors>
<title>Hidden understanding models of natural language.&amp;quot;</title>
<date>1994</date>
<booktitle>In Proceedings of ACL-94.</booktitle>
<contexts>
<context position="12915" citStr="Miller et al. (1994)" startWordPosition="2103" endWordPosition="2106">ntences What about Tuesday afternoon? i \PI Cumint Sentence I Clear I What about Tuesday afternoon? I Interpretation 100 S Coverage 1 :Simeon Acts auggootioni I +-Ergo. Lair] .-ubat .-about .-Etlem) 1 .-ipoint] I •-(day_of_wook 3 I I 1 .-cummlay I 4,-(timm_of_day] 1 r, Automatic Rephrase lotat about tbesday afternoon IN fi,1 (-------a--- --II teeming _Er? jAireedY Ok ET Stiteessful ......EnUnaucceSSU INEAV rule: (suggest _time) &lt;-- what about [time] (From Nwhat about tuesday afternoe _ • , Figure 6: ...and a new rule is acquired. of unparsed words, the following stochastic models, inspired in Miller et al. (1994) and Seneff (1992), and collectively referred to as hidden understanding model (HUM), are employed. • Speech-act n-gram. Top-level concepts can be seen as speech acts of the domain. For instance, in the DM in Fig. 2 top-level concepts such as [greeting], [farewell] or [suggest ion] , correspond to discourse speech acts, and in normally-occurring conversation, they follow a distribution that is clearly non-uniform.1° • Concept-subconcept HMM. Discrete hidden Markov model in which the states correspond 10Needless to say, speech-act transition distributions are empirically estimated, but, intuiti</context>
</contexts>
<marker>Miller, Bobrow, Ingria, Schwartz, 1994</marker>
<rawString>Miller, Scott, Robert Bobrow, Robert Ingria, and Richard Schwartz. 1994. &amp;quot;Hidden understanding models of natural language.&amp;quot; In Proceedings of ACL-94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephanie Seneff</author>
</authors>
<title>TINA: a natural language system for spoken language applications.&amp;quot;</title>
<date>1992</date>
<journal>In Computational Linguistics,</journal>
<volume>18</volume>
<pages>61--83</pages>
<contexts>
<context position="12933" citStr="Seneff (1992)" startWordPosition="2108" endWordPosition="2109">y afternoon? i \PI Cumint Sentence I Clear I What about Tuesday afternoon? I Interpretation 100 S Coverage 1 :Simeon Acts auggootioni I +-Ergo. Lair] .-ubat .-about .-Etlem) 1 .-ipoint] I •-(day_of_wook 3 I I 1 .-cummlay I 4,-(timm_of_day] 1 r, Automatic Rephrase lotat about tbesday afternoon IN fi,1 (-------a--- --II teeming _Er? jAireedY Ok ET Stiteessful ......EnUnaucceSSU INEAV rule: (suggest _time) &lt;-- what about [time] (From Nwhat about tuesday afternoe _ • , Figure 6: ...and a new rule is acquired. of unparsed words, the following stochastic models, inspired in Miller et al. (1994) and Seneff (1992), and collectively referred to as hidden understanding model (HUM), are employed. • Speech-act n-gram. Top-level concepts can be seen as speech acts of the domain. For instance, in the DM in Fig. 2 top-level concepts such as [greeting], [farewell] or [suggest ion] , correspond to discourse speech acts, and in normally-occurring conversation, they follow a distribution that is clearly non-uniform.1° • Concept-subconcept HMM. Discrete hidden Markov model in which the states correspond 10Needless to say, speech-act transition distributions are empirically estimated, but, intuitively, the sequence</context>
</contexts>
<marker>Seneff, 1992</marker>
<rawString>Seneff, Stephanie. 1992. &amp;quot;TINA: a natural language system for spoken language applications.&amp;quot; In Computational Linguistics, vol. 18, no. 1, pp. 61-83.</rawString>
</citation>
<citation valid="false">
<title>15Uppercased nonterminals (such as CONJ and POSS) are more syntactical in nature and do not depend on the DM.</title>
<marker></marker>
<rawString>15Uppercased nonterminals (such as CONJ and POSS) are more syntactical in nature and do not depend on the DM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>