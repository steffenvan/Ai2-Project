<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.061677">
<title confidence="0.939404">
ALTN: Word Alignment Features for Cross-lingual Textual Entailment
</title>
<author confidence="0.92216">
Marco Turchi and Matteo Negri
</author>
<affiliation confidence="0.841918">
Fondazione Bruno Kessler
</affiliation>
<address confidence="0.570149">
Trento, Italy
</address>
<email confidence="0.998943">
{turchi,negri}@fbk.eu
</email>
<sectionHeader confidence="0.9986" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999914315789474">
We present a supervised learning approach to
cross-lingual textual entailment that explores
statistical word alignment models to predict
entailment relations between sentences writ-
ten in different languages. Our approach
is language independent, and was used to
participate in the CLTE task (Task#8) or-
ganized within Semeval 2013 (Negri et al.,
2013). The four runs submitted, one for
each language combination covered by the test
data (i.e. Spanish/English, German/English,
French/English and Italian/English), achieved
encouraging results. In terms of accuracy,
performance ranges from 38.8% (for Ger-
man/English) to 43.2% (for Italian/English).
On the Italian/English and Spanish/English
test sets our systems ranked second among
five participants, close to the top results (re-
spectively 43.4% and 45.4%).
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999927904761905">
Cross-lingual textual entailment (CLTE) is an ex-
tension of the Textual Entailment task (Dagan and
Glickman, 2004) that consists in deciding, given
two texts T and H written in different languages
(respectively called text and hypothesis), if H can
be inferred from T (Mehdad et al., 2010). In the
case of SemEval 2013, the task is formulated as
a multi-class classification problem in which there
are four possible relations between T and H: for-
ward (T —* H), backward (T +— H), bidirectional
(T H H) and “no entailment”.
Targeting the identification of semantic equiva-
lence and information disparity between topically
related sentences, CLTE recognition can be seen as a
core task for a number of cross-lingual applications.
Among others, multilingual content synchronization
has been recently proposed as an ideal framework
for the exploitation of CLTE components and the in-
tegration of semantics and machine translation (MT)
technology (Mehdad et al., 2011; Mehdad et al.,
2012b; Bronner et al., 2012; Monz et al., 2011).
In the last few years, several methods have been
proposed for CLTE. These can be roughly divided
in two main groups (Negri et al., 2012): i) those us-
ing a pivoting strategy by translating H into the lan-
guage of T and then using monolingual TE compo-
nents1, and those directly using cross-lingual strate-
gies. Among this second group, several sources of
cross-lingual knowledge have been used, such as
dictionaries (Kouylekov et al., 2012; Perini, 2012),
phrase and paraphrase tables (Mehdad et al., 2012a),
GIZA++ (Och and Ney, 2003) word alignment mod-
els (W¨aschle and Fendrich, 2012), MT of sub-
segments (Espl`a-Gomis et al., 2012), or semantic
Wordnets (Castillo, 2011).
In this work we propose a CLTE detection method
based on a new set of features using word align-
ment as a source of cross-lingual knowledge. This
set, which is richer than the one by (W¨aschle and
Fendrich, 2012), is aimed not only at grasping infor-
mation about the proportion of aligned words, but
also about the distribution of the alignments in both
</bodyText>
<footnote confidence="0.9878442">
1In the first CLTE evaluation round at Semeval 2012, for
instance, the system described in (Meng et al., 2012) used the
open source EDITS system (Kouylekov and Negri, 2010; Negri
et al., 2009) to calculate similarity scores between monolingual
English pairs.
</footnote>
<page confidence="0.886835">
128
</page>
<bodyText confidence="0.975992692307692">
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 128–132, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
H and T. This set of features is later used by two
support vector machine (SVM) classifiers for detect-
ing CLTE separately in both directions (T —* H and
T +— H). We use the combined output of both clas-
sifiers for performing the CLTE detection.
The paper is organized as follows: Section 2
describes the features used and the classification
method; Section 3 explains the experimental frame-
work and the results obtained for the different
language-pair sets; finally, the conclusions obtained
from the results are summarised in Section 4.
</bodyText>
<sectionHeader confidence="0.986602" genericHeader="method">
2 ALTN System
</sectionHeader>
<figureCaption confidence="0.8037515">
In our approach we have implemented a system
based on supervised learning. It takes an unlabeled
sentence pair as input (T and H) and labels it au-
tomatically with one of the possible four valid en-
tailment relations. The architecture is depicted in
Figure 1.
</figureCaption>
<bodyText confidence="0.9999283">
A key component to our approach is the word
alignment model. In a preprocessing step it is
trained on a set of parallel texts for the target lan-
guage pair. Next, different features based on the
word alignment are extracted. Taking the features
and the target language pair labels as input, a su-
pervised learning algorithm is run to fit a model to
the data. The last step is to use the model to au-
tomatically label unseen instances with entailment
relations.
</bodyText>
<subsectionHeader confidence="0.871165">
2.1 Features
</subsectionHeader>
<bodyText confidence="0.9999684">
What characterizes our submission is the use of
word alignment features to capture entailment rela-
tions. We extract the following features from a word
alignment model for a given sentence pair (all fea-
tures are calculated for both T and H):
</bodyText>
<listItem confidence="0.98993375">
• proportion of aligned words in the sentence
(baseline);
• number of unaligned sequences of words nor-
malized by the length of the sentence;
• length of the longest sequence of aligned words
normalized by the length of the sentence;
• length of the longest sequence of unaligned
words normalized by the length of the sentence;
</listItem>
<figureCaption confidence="0.904103">
Figure 1: System architecture
</figureCaption>
<listItem confidence="0.994325666666667">
• average length of the aligned word sequences;
• average length of the unaligned word se-
quences;
• position of the first unaligned word normalized
by the length of the sentence;
• position of the last unaligned word normalized
by the lenght of the sentence;
• proportion of aligned n-grams in the sentence
(n varying from 1 to 5).
</listItem>
<bodyText confidence="0.999582571428571">
These features are language independent as they
are obtained from statistical models that take as in-
put a parallel corpus. Provided that there exist paral-
lel data for a given language pair, the only constraint
in terms of resources, the adoption of these features
makes our approach virtually portable across lan-
guages with limited effort.
</bodyText>
<subsectionHeader confidence="0.970458">
2.2 CLTE Model
</subsectionHeader>
<bodyText confidence="0.999982333333333">
Our CLTE model is composed by two supervised bi-
nary classifiers that predict whether there is entail-
ment between the T and H. One classifier checks
</bodyText>
<page confidence="0.993225">
129
</page>
<bodyText confidence="0.9987">
for forward entailment (T —* H) and the other
checks for backward entailment (T +— H). The out-
put of both classifiers is combined to form the four
valid entailment decisions:
</bodyText>
<listItem confidence="0.997311625">
• forward and backward classifier output true:
“bidirectional” entailment;
• forward is true and backward is false:
“forward” entailment;
• forward is false and backward is true:
“backward” entailment;
• both forward and backward output false: “no
entailment” relation.
</listItem>
<bodyText confidence="0.974436333333333">
Both binary classifiers were implemented using
the SVM implementation of Weka (Hall et al.,
2009).
</bodyText>
<sectionHeader confidence="0.999873" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.99976726923077">
In our submission we experimented with three stan-
dard word alignment algorithms: the hidden Markov
model (HMM) (Vogel et al., 1996) and IBM models
3 and 4 (Brown et al., 1993). They are implemented
in the MGIZA++ package (Gao and Vogel, 2008).
Building on a probabilistic lexical model to establish
mappings between words in two languages, these
models compute alignments between the word po-
sitions in two input sentences S1 and S2. The mod-
els are trained incrementally: HMM is the base for
IBM model 3, which is the base for IBM model 4.
To train our models, we used 5 iterations of HMM,
and 3 iterations of IBM models 3 and 4.
Word alignments produced by these models are
asymmetric (S1 —* S2 =� S2 —* S1). To cope
with this, different heuristics (Koehn et al., 2005)
have been proposed to obtain symmetric alignments
from two asymmetric sets (S1 H S2). We ex-
perimented with three symmetrization heuristics,
namely: union, intersection, and grow-diag-final-
and, a more complex symmetrization method which
combines intersection with some alignments from
the union.
To train the word alignment models we used
the Europarl parallel corpus (Koehn, 2005) con-
catenated with the News Commentary corpus2 for
</bodyText>
<footnote confidence="0.9186355">
2http://www.statmt.org/wmt11/
translation-task.html#download
</footnote>
<bodyText confidence="0.999767128205128">
three language pairs: English-German (2,079,049
sentences), English-Spanish (2,123,036 sentences),
English-French (2,144,820 sentences). For English-
Italian we only used the parallel data available in Eu-
roparl (1,909,115 sentences) since this language pair
is not covered by the News Commentary corpus.
For our submitted run the SVM classifiers were
trained using the whole training set. Such dataset
consists of 1,000 pairs for each of the four language
combinations, resulting from a concatenation of the
training and test sets used for the first round of eval-
uation at SemEval 2012 (Negri et al., 2012; Negri et
al., 2011). We have set a polynomial kernel with pa-
rameters empirically estimated on the training set:
C = 2.0, and d = 1. After some preliminary ex-
periments we have concluded that the HMM model
in conjunction with the intersection symmetrization
provides the best results.
Our results, calculated over the 500 test pairs pro-
vided for each language combination, are presented
in Table 3. As can be seen from the table, our system
consistently outperforms the best average run of all
participants and is the second best system for Span-
ish/English and Italian/English. For the other two
languages, French/English and German/English, it
is the 3rd best system with a larger distance from top
results. The motivations for such lower results, cur-
rently under investigation, might be related to lower
performance in terms of word alignment, the core
of our approach. The first step of our analysis will
hence address, and in case try to cope with, signifi-
cant differences in word alignment performance af-
fecting results.
Overall, considering the small distance from top
results, and the fact that our approach does not re-
quire deep linguistic processing to be reasonably ef-
fective for any language pair for which parallel cor-
pora are available, our results are encouraging and
motivate further research along such direction.
</bodyText>
<sectionHeader confidence="0.999292" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.997180833333333">
In this paper we presented the participation of the
Fondazione Bruno Kessler in the Semeval 2013
Task#8 on Cross-lingual Textual Entailment for
Content Synchronization. To identify entailment re-
lations between texts in different languages, our sys-
tem explores the use of word alignment features
</bodyText>
<page confidence="0.99262">
130
</page>
<table confidence="0.9994495">
Features / Language pair German/English Spanish/English French/English Italian/English
Avg best runs 0.378 0.404 0.407 0.405
ALTN 0.388 0.428 0.420 0.432
Best system 0.452 0.434 0.458 0.454
</table>
<tableCaption confidence="0.941711">
Table 1: Accuracy results for the language pairs evaluated for the average of the best runs of the participating systems,
our submission and the best systems.
</tableCaption>
<bodyText confidence="0.9996236">
within a supervised learning setting. In our ap-
proach, word alignment models obtained by statis-
tical methods from parallel corpora leverage infor-
mation about the number, the proportion, and the
distribution of aligned terms in the input sentences.
In terms of accuracy results over the SemEval 2013
CLTE test data, performance ranges from 38.8%
(for German/English) to 43.2% (for Italian/English).
On the Italian/English and Spanish/English test sets
our systems ranked second among five participants,
close to the top results (respectively 43.4% and
45.4%). Such results suggest that the use of word
alignment models to capture sentence-level seman-
tic relations in different language settings represents
a promising research direction.
</bodyText>
<sectionHeader confidence="0.988911" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999425">
This work has been partially supported by the EC-
funded project CoSyne (FP7-ICT-4-248531).
</bodyText>
<sectionHeader confidence="0.994886" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997000587301587">
Amit Bronner, Matteo Negri, Yashar Mehdad, Angela
Fahrni, and Christof Monz. 2012. CoSyne: Synchro-
nizing Multilingual Wiki Content. In Proceedings of
the Eighth Annual International Symposium on Wikis
and Open Collaboration, WikiSym ’12, pages 33:1–
33:4, New York, NY, USA. ACM.
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1993. The Mathematics
of Statistical Machine Translation: Parameter Estima-
tion. Computational Linguistics, 19(2):263–311.
Julio J. Castillo. 2011. A WordNet-based Semantic Ap-
proach to Textual Entailment and Cross-lingual Tex-
tual Entailment. International Journal of Machine
Learning and Cybernetics, 2(3):177–189.
Ido Dagan and Oren Glickman. 2004. Probabilistic Tex-
tual Entailment: Generic Applied Modeling of Lan-
guage Variability. In Proceedings of the PASCAL
Workshop of Learning Methods for Text Understand-
ing and Mining, Grenoble, France.
Miquel Espl`a-Gomis, Felipe S´anchez-Martinez, and
Mikel L. Forcada. 2012. UAlacant: Using Online
Machine Translation for Cross-Lingual Textual Entail-
ment. In Proceedings of the 6th International Work-
shop on Semantic Evaluation (SemEval 2012), pages
472–476, Montr´eal, Canada.
Qin Gao and Stephan Vogel. 2008. Parallel Implemen-
tations of Word Alignment Tool. In Software Engi-
neering, Testing, and Quality Assurance for Natural
Language Processing, pages 49–57, Columbus, Ohio,
USA.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The WEKA Data Mining Software: an Update.
SIGKDD Explorations, 11(1):10–18.
Philipp Koehn, Amittai Axelrod, Alexandra Birch
Mayne, Chris Callison-Burch, Miles Osborne, and
David Talbot. 2005. Edinburgh System Description
for the 2005 IWSLT Speech Translation Evaluation.
In Proceedings of the International Workshop on Spo-
ken Language Translation, Pittsburgh, Pennsylvania,
USA.
Philip Koehn. 2005. Europarl: a Parallel Corpus for
Statistical Machine Translation. In Proceedings of
Machine Translation Summit X, pages 79–86, Phuket,
Thailand.
Milen Kouylekov and Matteo Negri. 2010. An Open-
source Package for Recognizing Textual Entailment.
In Proceedings of the ACL 2010 System Demonstra-
tions.
Milen Kouylekov, Luca Dini, Alessio Bosca, and Marco
Trevisan. 2012. CELI: an Experiment with Cross
Language Textual Entailment. In Proceedings of the
6th International Workshop on Semantic Evaluation
(SemEval 2012), pages 696–700, Montr´eal, Canada.
Yashar Mehdad, Matteo Negri, and Marcello Federico.
2010. Towards Cross-Lingual Textual Entailment. In
Proceedings of the 11th Annual Conference of the
North American Chapter of the Association for Com-
putational Linguistics (NAACL HLT 2010).
Yashar Mehdad, Matteo Negri, and Marcello Federico.
2011. Using Bilingual Parallel Corpora for Cross-
Lingual Textual Entailment. In Proceedings of the
49th Annual Meeting of the Association for Compu-
</reference>
<page confidence="0.992049">
131
</page>
<reference confidence="0.990781363636363">
tational Linguistics: Human Language Technologies
(ACL HLT 2011).
Yashar Mehdad, Matteo Negri, and Jos´e Guilherme C.
de Souza. 2012a. FBK: cross-lingual textual entail-
ment without translation. In Proceedings of the 6th
International Workshop on Semantic Evaluation (Se-
mEval 2012), pages 701–705, Montr´eal, Canada.
Yashar Mehdad, Matteo Negri, and Marcello Federico.
2012b. Detecting Semantic Equivalence and Informa-
tion Disparity in Cross-lingual Documents. In Pro-
ceedings of the 50th Annual Meeting of the Association
for Computational Linguistics (ACL 2012).
Fandong Meng, Hao Xiong, and Qun Liu. 2012. ICT:
A Translation based Cross-lingual Textual Entailment.
In Proceedings of the 6th International Workshop on
Semantic Evaluation (SemEval 2012).
Christoph Monz, Vivi Nastase, Matteo Negri, Angela
Fahrni, Yashar Mehdad, and Michael Strube. 2011.
CoSyne: a Framework for Multilingual Content Syn-
chronization of Wikis. In Proceedings of Wikisym
2011, the International Symposium on Wikis and Open
Collaboration, pages 217–218, Mountain View, Cali-
fornia, USA.
Matteo Negri, Milen Ognianov Kouylekov, Bernardo
Magnini, Yashar Mehdad, and Elena Cabrio. 2009.
Towards Extensible Textual Entailment Engines: the
EDITS Package. In AI*IA 2009: XIth International
Conference of the Italian Association for Artificial In-
telligence.
Matteo Negri, Luisa Bentivogli, Yashar Mehdad, Danilo
Giampiccolo, and Alessandro Marchetti. 2011. Di-
vide and Conquer: Crowdsourcing the Creation of
Cross-Lingual Textual Entailment Corpora. Proceed-
ings of the 2011 Conference on Empirical Methods in
Natural Language Processing (EMNLP 2011).
Matteo Negri, Alessandro Marchetti, Yashar Mehdad,
Luisa Bentivogli, and Danilo Giampiccolo. 2012.
Semeval-2012 Task 8: Cross-Lingual Textual Entail-
ment for Content Synchronization. In Proceedings
of the 6th International Workshop on Semantic Eval-
uation (SemEval 2012), pages 399–407, Montr´eal,
Canada.
Matteo Negri, Alessandro Marchetti, Yashar Mehdad,
Luisa Bentivogli, and Danilo Giampiccolo. 2013.
Semeval-2013 Task 8: Cross-lingual Textual Entail-
ment for Content Synchronization. In Proceedings of
the 7th International Workshop on Semantic Evalua-
tion (SemEval 2013).
Franz J. Och and Hermann Ney. 2003. A Systematic
Comparison of Various Statistical Alignment Models.
Computational Linguistics, 29(1):19–51.
Alp´ar Perini. 2012. DirRelCond3: detecting textual en-
tailment across languages with conditions on direc-
tional text relatedness scores. In Proceedings of the
6th International Workshop on Semantic Evaluation
(SemEval 2012), pages 710–714, Montr´eal, Canada.
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. HMM-based word alignment in statistical trans-
lation. In Proceedings of the 16th International Con-
ference on Computational Linguistics (ACL’96), pages
836–841, Copenhagen, Denmark.
Katharina W¨aschle and Sascha Fendrich. 2012. HDU:
Cross-lingual Textual Entailment with SMT Features.
In Proceedings of the 6th International Workshop on
Semantic Evaluation (SemEval 2012), pages 467–471,
Montr´eal, Canada.
</reference>
<page confidence="0.997718">
132
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.346013">
<title confidence="0.999126">ALTN: Word Alignment Features for Cross-lingual Textual Entailment</title>
<author confidence="0.785543">Marco Turchi</author>
<author confidence="0.785543">Matteo Fondazione Bruno</author>
<affiliation confidence="0.563952">Trento,</affiliation>
<abstract confidence="0.99170395">We present a supervised learning approach to cross-lingual textual entailment that explores statistical word alignment models to predict entailment relations between sentences written in different languages. Our approach is language independent, and was used to participate in the CLTE task (Task#8) organized within Semeval 2013 (Negri et al., 2013). The four runs submitted, one for each language combination covered by the test German/English, French/English and Italian/English), achieved encouraging results. In terms of accuracy, performance ranges from 38.8% (for German/English) to 43.2% (for Italian/English). On the Italian/English and Spanish/English test sets our systems ranked second among five participants, close to the top results (respectively 43.4% and 45.4%).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Amit Bronner</author>
<author>Matteo Negri</author>
<author>Yashar Mehdad</author>
<author>Angela Fahrni</author>
<author>Christof Monz</author>
</authors>
<title>CoSyne: Synchronizing Multilingual Wiki Content.</title>
<date>2012</date>
<booktitle>In Proceedings of the Eighth Annual International Symposium on Wikis and Open Collaboration, WikiSym ’12,</booktitle>
<pages>33--1</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1993" citStr="Bronner et al., 2012" startWordPosition="291" endWordPosition="294">n which there are four possible relations between T and H: forward (T —* H), backward (T +— H), bidirectional (T H H) and “no entailment”. Targeting the identification of semantic equivalence and information disparity between topically related sentences, CLTE recognition can be seen as a core task for a number of cross-lingual applications. Among others, multilingual content synchronization has been recently proposed as an ideal framework for the exploitation of CLTE components and the integration of semantics and machine translation (MT) technology (Mehdad et al., 2011; Mehdad et al., 2012b; Bronner et al., 2012; Monz et al., 2011). In the last few years, several methods have been proposed for CLTE. These can be roughly divided in two main groups (Negri et al., 2012): i) those using a pivoting strategy by translating H into the language of T and then using monolingual TE components1, and those directly using cross-lingual strategies. Among this second group, several sources of cross-lingual knowledge have been used, such as dictionaries (Kouylekov et al., 2012; Perini, 2012), phrase and paraphrase tables (Mehdad et al., 2012a), GIZA++ (Och and Ney, 2003) word alignment models (W¨aschle and Fendrich, </context>
</contexts>
<marker>Bronner, Negri, Mehdad, Fahrni, Monz, 2012</marker>
<rawString>Amit Bronner, Matteo Negri, Yashar Mehdad, Angela Fahrni, and Christof Monz. 2012. CoSyne: Synchronizing Multilingual Wiki Content. In Proceedings of the Eighth Annual International Symposium on Wikis and Open Collaboration, WikiSym ’12, pages 33:1– 33:4, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The Mathematics of Statistical Machine Translation: Parameter Estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="7002" citStr="Brown et al., 1993" startWordPosition="1126" endWordPosition="1129">ers is combined to form the four valid entailment decisions: • forward and backward classifier output true: “bidirectional” entailment; • forward is true and backward is false: “forward” entailment; • forward is false and backward is true: “backward” entailment; • both forward and backward output false: “no entailment” relation. Both binary classifiers were implemented using the SVM implementation of Weka (Hall et al., 2009). 3 Experiments In our submission we experimented with three standard word alignment algorithms: the hidden Markov model (HMM) (Vogel et al., 1996) and IBM models 3 and 4 (Brown et al., 1993). They are implemented in the MGIZA++ package (Gao and Vogel, 2008). Building on a probabilistic lexical model to establish mappings between words in two languages, these models compute alignments between the word positions in two input sentences S1 and S2. The models are trained incrementally: HMM is the base for IBM model 3, which is the base for IBM model 4. To train our models, we used 5 iterations of HMM, and 3 iterations of IBM models 3 and 4. Word alignments produced by these models are asymmetric (S1 —* S2 =� S2 —* S1). To cope with this, different heuristics (Koehn et al., 2005) have </context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julio J Castillo</author>
</authors>
<title>A WordNet-based Semantic Approach to Textual Entailment and Cross-lingual Textual Entailment.</title>
<date>2011</date>
<journal>International Journal of Machine Learning and Cybernetics,</journal>
<volume>2</volume>
<issue>3</issue>
<contexts>
<context position="2684" citStr="Castillo, 2011" startWordPosition="407" endWordPosition="408">sed for CLTE. These can be roughly divided in two main groups (Negri et al., 2012): i) those using a pivoting strategy by translating H into the language of T and then using monolingual TE components1, and those directly using cross-lingual strategies. Among this second group, several sources of cross-lingual knowledge have been used, such as dictionaries (Kouylekov et al., 2012; Perini, 2012), phrase and paraphrase tables (Mehdad et al., 2012a), GIZA++ (Och and Ney, 2003) word alignment models (W¨aschle and Fendrich, 2012), MT of subsegments (Espl`a-Gomis et al., 2012), or semantic Wordnets (Castillo, 2011). In this work we propose a CLTE detection method based on a new set of features using word alignment as a source of cross-lingual knowledge. This set, which is richer than the one by (W¨aschle and Fendrich, 2012), is aimed not only at grasping information about the proportion of aligned words, but also about the distribution of the alignments in both 1In the first CLTE evaluation round at Semeval 2012, for instance, the system described in (Meng et al., 2012) used the open source EDITS system (Kouylekov and Negri, 2010; Negri et al., 2009) to calculate similarity scores between monolingual En</context>
</contexts>
<marker>Castillo, 2011</marker>
<rawString>Julio J. Castillo. 2011. A WordNet-based Semantic Approach to Textual Entailment and Cross-lingual Textual Entailment. International Journal of Machine Learning and Cybernetics, 2(3):177–189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
</authors>
<title>Probabilistic Textual Entailment: Generic Applied Modeling of Language Variability.</title>
<date>2004</date>
<booktitle>In Proceedings of the PASCAL Workshop of Learning Methods for Text Understanding and Mining,</booktitle>
<location>Grenoble, France.</location>
<contexts>
<context position="1103" citStr="Dagan and Glickman, 2004" startWordPosition="148" endWordPosition="151">ithin Semeval 2013 (Negri et al., 2013). The four runs submitted, one for each language combination covered by the test data (i.e. Spanish/English, German/English, French/English and Italian/English), achieved encouraging results. In terms of accuracy, performance ranges from 38.8% (for German/English) to 43.2% (for Italian/English). On the Italian/English and Spanish/English test sets our systems ranked second among five participants, close to the top results (respectively 43.4% and 45.4%). 1 Introduction Cross-lingual textual entailment (CLTE) is an extension of the Textual Entailment task (Dagan and Glickman, 2004) that consists in deciding, given two texts T and H written in different languages (respectively called text and hypothesis), if H can be inferred from T (Mehdad et al., 2010). In the case of SemEval 2013, the task is formulated as a multi-class classification problem in which there are four possible relations between T and H: forward (T —* H), backward (T +— H), bidirectional (T H H) and “no entailment”. Targeting the identification of semantic equivalence and information disparity between topically related sentences, CLTE recognition can be seen as a core task for a number of cross-lingual a</context>
</contexts>
<marker>Dagan, Glickman, 2004</marker>
<rawString>Ido Dagan and Oren Glickman. 2004. Probabilistic Textual Entailment: Generic Applied Modeling of Language Variability. In Proceedings of the PASCAL Workshop of Learning Methods for Text Understanding and Mining, Grenoble, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miquel Espl`a-Gomis</author>
<author>Felipe S´anchez-Martinez</author>
<author>Mikel L Forcada</author>
</authors>
<title>UAlacant: Using Online Machine Translation for Cross-Lingual Textual Entailment.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>472--476</pages>
<location>Montr´eal, Canada.</location>
<marker>Espl`a-Gomis, S´anchez-Martinez, Forcada, 2012</marker>
<rawString>Miquel Espl`a-Gomis, Felipe S´anchez-Martinez, and Mikel L. Forcada. 2012. UAlacant: Using Online Machine Translation for Cross-Lingual Textual Entailment. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012), pages 472–476, Montr´eal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qin Gao</author>
<author>Stephan Vogel</author>
</authors>
<title>Parallel Implementations of Word Alignment Tool.</title>
<date>2008</date>
<booktitle>In Software Engineering, Testing, and Quality Assurance for Natural Language Processing,</booktitle>
<pages>49--57</pages>
<location>Columbus, Ohio, USA.</location>
<contexts>
<context position="7069" citStr="Gao and Vogel, 2008" startWordPosition="1137" endWordPosition="1140">ward and backward classifier output true: “bidirectional” entailment; • forward is true and backward is false: “forward” entailment; • forward is false and backward is true: “backward” entailment; • both forward and backward output false: “no entailment” relation. Both binary classifiers were implemented using the SVM implementation of Weka (Hall et al., 2009). 3 Experiments In our submission we experimented with three standard word alignment algorithms: the hidden Markov model (HMM) (Vogel et al., 1996) and IBM models 3 and 4 (Brown et al., 1993). They are implemented in the MGIZA++ package (Gao and Vogel, 2008). Building on a probabilistic lexical model to establish mappings between words in two languages, these models compute alignments between the word positions in two input sentences S1 and S2. The models are trained incrementally: HMM is the base for IBM model 3, which is the base for IBM model 4. To train our models, we used 5 iterations of HMM, and 3 iterations of IBM models 3 and 4. Word alignments produced by these models are asymmetric (S1 —* S2 =� S2 —* S1). To cope with this, different heuristics (Koehn et al., 2005) have been proposed to obtain symmetric alignments from two asymmetric se</context>
</contexts>
<marker>Gao, Vogel, 2008</marker>
<rawString>Qin Gao and Stephan Vogel. 2008. Parallel Implementations of Word Alignment Tool. In Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 49–57, Columbus, Ohio, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The WEKA Data Mining Software: an Update.</title>
<date>2009</date>
<journal>SIGKDD Explorations,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="6811" citStr="Hall et al., 2009" startWordPosition="1093" endWordPosition="1096"> whether there is entailment between the T and H. One classifier checks 129 for forward entailment (T —* H) and the other checks for backward entailment (T +— H). The output of both classifiers is combined to form the four valid entailment decisions: • forward and backward classifier output true: “bidirectional” entailment; • forward is true and backward is false: “forward” entailment; • forward is false and backward is true: “backward” entailment; • both forward and backward output false: “no entailment” relation. Both binary classifiers were implemented using the SVM implementation of Weka (Hall et al., 2009). 3 Experiments In our submission we experimented with three standard word alignment algorithms: the hidden Markov model (HMM) (Vogel et al., 1996) and IBM models 3 and 4 (Brown et al., 1993). They are implemented in the MGIZA++ package (Gao and Vogel, 2008). Building on a probabilistic lexical model to establish mappings between words in two languages, these models compute alignments between the word positions in two input sentences S1 and S2. The models are trained incrementally: HMM is the base for IBM model 3, which is the base for IBM model 4. To train our models, we used 5 iterations of </context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The WEKA Data Mining Software: an Update. SIGKDD Explorations, 11(1):10–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Amittai Axelrod</author>
<author>Alexandra Birch Mayne</author>
<author>Chris Callison-Burch</author>
<author>Miles Osborne</author>
<author>David Talbot</author>
</authors>
<title>Edinburgh System Description for the 2005 IWSLT Speech Translation Evaluation.</title>
<date>2005</date>
<booktitle>In Proceedings of the International Workshop on Spoken Language Translation,</booktitle>
<location>Pittsburgh, Pennsylvania, USA.</location>
<contexts>
<context position="7596" citStr="Koehn et al., 2005" startWordPosition="1233" endWordPosition="1236">nd 4 (Brown et al., 1993). They are implemented in the MGIZA++ package (Gao and Vogel, 2008). Building on a probabilistic lexical model to establish mappings between words in two languages, these models compute alignments between the word positions in two input sentences S1 and S2. The models are trained incrementally: HMM is the base for IBM model 3, which is the base for IBM model 4. To train our models, we used 5 iterations of HMM, and 3 iterations of IBM models 3 and 4. Word alignments produced by these models are asymmetric (S1 —* S2 =� S2 —* S1). To cope with this, different heuristics (Koehn et al., 2005) have been proposed to obtain symmetric alignments from two asymmetric sets (S1 H S2). We experimented with three symmetrization heuristics, namely: union, intersection, and grow-diag-finaland, a more complex symmetrization method which combines intersection with some alignments from the union. To train the word alignment models we used the Europarl parallel corpus (Koehn, 2005) concatenated with the News Commentary corpus2 for 2http://www.statmt.org/wmt11/ translation-task.html#download three language pairs: English-German (2,079,049 sentences), English-Spanish (2,123,036 sentences), English-</context>
</contexts>
<marker>Koehn, Axelrod, Mayne, Callison-Burch, Osborne, Talbot, 2005</marker>
<rawString>Philipp Koehn, Amittai Axelrod, Alexandra Birch Mayne, Chris Callison-Burch, Miles Osborne, and David Talbot. 2005. Edinburgh System Description for the 2005 IWSLT Speech Translation Evaluation. In Proceedings of the International Workshop on Spoken Language Translation, Pittsburgh, Pennsylvania, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Koehn</author>
</authors>
<title>Europarl: a Parallel Corpus for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Proceedings of Machine Translation Summit X,</booktitle>
<pages>79--86</pages>
<location>Phuket, Thailand.</location>
<contexts>
<context position="7977" citStr="Koehn, 2005" startWordPosition="1290" endWordPosition="1291"> To train our models, we used 5 iterations of HMM, and 3 iterations of IBM models 3 and 4. Word alignments produced by these models are asymmetric (S1 —* S2 =� S2 —* S1). To cope with this, different heuristics (Koehn et al., 2005) have been proposed to obtain symmetric alignments from two asymmetric sets (S1 H S2). We experimented with three symmetrization heuristics, namely: union, intersection, and grow-diag-finaland, a more complex symmetrization method which combines intersection with some alignments from the union. To train the word alignment models we used the Europarl parallel corpus (Koehn, 2005) concatenated with the News Commentary corpus2 for 2http://www.statmt.org/wmt11/ translation-task.html#download three language pairs: English-German (2,079,049 sentences), English-Spanish (2,123,036 sentences), English-French (2,144,820 sentences). For EnglishItalian we only used the parallel data available in Europarl (1,909,115 sentences) since this language pair is not covered by the News Commentary corpus. For our submitted run the SVM classifiers were trained using the whole training set. Such dataset consists of 1,000 pairs for each of the four language combinations, resulting from a con</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philip Koehn. 2005. Europarl: a Parallel Corpus for Statistical Machine Translation. In Proceedings of Machine Translation Summit X, pages 79–86, Phuket, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Milen Kouylekov</author>
<author>Matteo Negri</author>
</authors>
<title>An Opensource Package for Recognizing Textual Entailment.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 System Demonstrations.</booktitle>
<contexts>
<context position="3209" citStr="Kouylekov and Negri, 2010" startWordPosition="497" endWordPosition="500">endrich, 2012), MT of subsegments (Espl`a-Gomis et al., 2012), or semantic Wordnets (Castillo, 2011). In this work we propose a CLTE detection method based on a new set of features using word alignment as a source of cross-lingual knowledge. This set, which is richer than the one by (W¨aschle and Fendrich, 2012), is aimed not only at grasping information about the proportion of aligned words, but also about the distribution of the alignments in both 1In the first CLTE evaluation round at Semeval 2012, for instance, the system described in (Meng et al., 2012) used the open source EDITS system (Kouylekov and Negri, 2010; Negri et al., 2009) to calculate similarity scores between monolingual English pairs. 128 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 128–132, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics H and T. This set of features is later used by two support vector machine (SVM) classifiers for detecting CLTE separately in both directions (T —* H and T +— H). We use the combined output of both classifiers for performing the CLTE detection. The paper is </context>
</contexts>
<marker>Kouylekov, Negri, 2010</marker>
<rawString>Milen Kouylekov and Matteo Negri. 2010. An Opensource Package for Recognizing Textual Entailment. In Proceedings of the ACL 2010 System Demonstrations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Milen Kouylekov</author>
<author>Luca Dini</author>
<author>Alessio Bosca</author>
<author>Marco Trevisan</author>
</authors>
<title>CELI: an Experiment with Cross Language Textual Entailment.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>696--700</pages>
<location>Montr´eal, Canada.</location>
<contexts>
<context position="2450" citStr="Kouylekov et al., 2012" startWordPosition="369" endWordPosition="372">oitation of CLTE components and the integration of semantics and machine translation (MT) technology (Mehdad et al., 2011; Mehdad et al., 2012b; Bronner et al., 2012; Monz et al., 2011). In the last few years, several methods have been proposed for CLTE. These can be roughly divided in two main groups (Negri et al., 2012): i) those using a pivoting strategy by translating H into the language of T and then using monolingual TE components1, and those directly using cross-lingual strategies. Among this second group, several sources of cross-lingual knowledge have been used, such as dictionaries (Kouylekov et al., 2012; Perini, 2012), phrase and paraphrase tables (Mehdad et al., 2012a), GIZA++ (Och and Ney, 2003) word alignment models (W¨aschle and Fendrich, 2012), MT of subsegments (Espl`a-Gomis et al., 2012), or semantic Wordnets (Castillo, 2011). In this work we propose a CLTE detection method based on a new set of features using word alignment as a source of cross-lingual knowledge. This set, which is richer than the one by (W¨aschle and Fendrich, 2012), is aimed not only at grasping information about the proportion of aligned words, but also about the distribution of the alignments in both 1In the firs</context>
</contexts>
<marker>Kouylekov, Dini, Bosca, Trevisan, 2012</marker>
<rawString>Milen Kouylekov, Luca Dini, Alessio Bosca, and Marco Trevisan. 2012. CELI: an Experiment with Cross Language Textual Entailment. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012), pages 696–700, Montr´eal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Marcello Federico</author>
</authors>
<title>Towards Cross-Lingual Textual Entailment.</title>
<date>2010</date>
<booktitle>In Proceedings of the 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT</booktitle>
<contexts>
<context position="1278" citStr="Mehdad et al., 2010" startWordPosition="178" endWordPosition="181">nd Italian/English), achieved encouraging results. In terms of accuracy, performance ranges from 38.8% (for German/English) to 43.2% (for Italian/English). On the Italian/English and Spanish/English test sets our systems ranked second among five participants, close to the top results (respectively 43.4% and 45.4%). 1 Introduction Cross-lingual textual entailment (CLTE) is an extension of the Textual Entailment task (Dagan and Glickman, 2004) that consists in deciding, given two texts T and H written in different languages (respectively called text and hypothesis), if H can be inferred from T (Mehdad et al., 2010). In the case of SemEval 2013, the task is formulated as a multi-class classification problem in which there are four possible relations between T and H: forward (T —* H), backward (T +— H), bidirectional (T H H) and “no entailment”. Targeting the identification of semantic equivalence and information disparity between topically related sentences, CLTE recognition can be seen as a core task for a number of cross-lingual applications. Among others, multilingual content synchronization has been recently proposed as an ideal framework for the exploitation of CLTE components and the integration of</context>
</contexts>
<marker>Mehdad, Negri, Federico, 2010</marker>
<rawString>Yashar Mehdad, Matteo Negri, and Marcello Federico. 2010. Towards Cross-Lingual Textual Entailment. In Proceedings of the 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Marcello Federico</author>
</authors>
<title>Using Bilingual Parallel Corpora for CrossLingual Textual Entailment.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL HLT</booktitle>
<contexts>
<context position="1949" citStr="Mehdad et al., 2011" startWordPosition="283" endWordPosition="286">d as a multi-class classification problem in which there are four possible relations between T and H: forward (T —* H), backward (T +— H), bidirectional (T H H) and “no entailment”. Targeting the identification of semantic equivalence and information disparity between topically related sentences, CLTE recognition can be seen as a core task for a number of cross-lingual applications. Among others, multilingual content synchronization has been recently proposed as an ideal framework for the exploitation of CLTE components and the integration of semantics and machine translation (MT) technology (Mehdad et al., 2011; Mehdad et al., 2012b; Bronner et al., 2012; Monz et al., 2011). In the last few years, several methods have been proposed for CLTE. These can be roughly divided in two main groups (Negri et al., 2012): i) those using a pivoting strategy by translating H into the language of T and then using monolingual TE components1, and those directly using cross-lingual strategies. Among this second group, several sources of cross-lingual knowledge have been used, such as dictionaries (Kouylekov et al., 2012; Perini, 2012), phrase and paraphrase tables (Mehdad et al., 2012a), GIZA++ (Och and Ney, 2003) wo</context>
</contexts>
<marker>Mehdad, Negri, Federico, 2011</marker>
<rawString>Yashar Mehdad, Matteo Negri, and Marcello Federico. 2011. Using Bilingual Parallel Corpora for CrossLingual Textual Entailment. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL HLT 2011).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Jos´e Guilherme C de Souza</author>
</authors>
<title>FBK: cross-lingual textual entailment without translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>701--705</pages>
<location>Montr´eal, Canada.</location>
<marker>Mehdad, Negri, de Souza, 2012</marker>
<rawString>Yashar Mehdad, Matteo Negri, and Jos´e Guilherme C. de Souza. 2012a. FBK: cross-lingual textual entailment without translation. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012), pages 701–705, Montr´eal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Marcello Federico</author>
</authors>
<title>Detecting Semantic Equivalence and Information Disparity in Cross-lingual Documents.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<contexts>
<context position="1970" citStr="Mehdad et al., 2012" startWordPosition="287" endWordPosition="290">assification problem in which there are four possible relations between T and H: forward (T —* H), backward (T +— H), bidirectional (T H H) and “no entailment”. Targeting the identification of semantic equivalence and information disparity between topically related sentences, CLTE recognition can be seen as a core task for a number of cross-lingual applications. Among others, multilingual content synchronization has been recently proposed as an ideal framework for the exploitation of CLTE components and the integration of semantics and machine translation (MT) technology (Mehdad et al., 2011; Mehdad et al., 2012b; Bronner et al., 2012; Monz et al., 2011). In the last few years, several methods have been proposed for CLTE. These can be roughly divided in two main groups (Negri et al., 2012): i) those using a pivoting strategy by translating H into the language of T and then using monolingual TE components1, and those directly using cross-lingual strategies. Among this second group, several sources of cross-lingual knowledge have been used, such as dictionaries (Kouylekov et al., 2012; Perini, 2012), phrase and paraphrase tables (Mehdad et al., 2012a), GIZA++ (Och and Ney, 2003) word alignment models (</context>
</contexts>
<marker>Mehdad, Negri, Federico, 2012</marker>
<rawString>Yashar Mehdad, Matteo Negri, and Marcello Federico. 2012b. Detecting Semantic Equivalence and Information Disparity in Cross-lingual Documents. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fandong Meng</author>
<author>Hao Xiong</author>
<author>Qun Liu</author>
</authors>
<title>ICT: A Translation based Cross-lingual Textual Entailment.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="3148" citStr="Meng et al., 2012" startWordPosition="487" endWordPosition="490">h and Ney, 2003) word alignment models (W¨aschle and Fendrich, 2012), MT of subsegments (Espl`a-Gomis et al., 2012), or semantic Wordnets (Castillo, 2011). In this work we propose a CLTE detection method based on a new set of features using word alignment as a source of cross-lingual knowledge. This set, which is richer than the one by (W¨aschle and Fendrich, 2012), is aimed not only at grasping information about the proportion of aligned words, but also about the distribution of the alignments in both 1In the first CLTE evaluation round at Semeval 2012, for instance, the system described in (Meng et al., 2012) used the open source EDITS system (Kouylekov and Negri, 2010; Negri et al., 2009) to calculate similarity scores between monolingual English pairs. 128 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 128–132, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics H and T. This set of features is later used by two support vector machine (SVM) classifiers for detecting CLTE separately in both directions (T —* H and T +— H). We use the combined output of both</context>
</contexts>
<marker>Meng, Xiong, Liu, 2012</marker>
<rawString>Fandong Meng, Hao Xiong, and Qun Liu. 2012. ICT: A Translation based Cross-lingual Textual Entailment. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph Monz</author>
<author>Vivi Nastase</author>
<author>Matteo Negri</author>
<author>Angela Fahrni</author>
<author>Yashar Mehdad</author>
<author>Michael Strube</author>
</authors>
<title>CoSyne: a Framework for Multilingual Content Synchronization of Wikis.</title>
<date>2011</date>
<booktitle>In Proceedings of Wikisym 2011, the International Symposium on Wikis and Open Collaboration,</booktitle>
<pages>217--218</pages>
<location>Mountain View, California, USA.</location>
<contexts>
<context position="2013" citStr="Monz et al., 2011" startWordPosition="295" endWordPosition="298"> possible relations between T and H: forward (T —* H), backward (T +— H), bidirectional (T H H) and “no entailment”. Targeting the identification of semantic equivalence and information disparity between topically related sentences, CLTE recognition can be seen as a core task for a number of cross-lingual applications. Among others, multilingual content synchronization has been recently proposed as an ideal framework for the exploitation of CLTE components and the integration of semantics and machine translation (MT) technology (Mehdad et al., 2011; Mehdad et al., 2012b; Bronner et al., 2012; Monz et al., 2011). In the last few years, several methods have been proposed for CLTE. These can be roughly divided in two main groups (Negri et al., 2012): i) those using a pivoting strategy by translating H into the language of T and then using monolingual TE components1, and those directly using cross-lingual strategies. Among this second group, several sources of cross-lingual knowledge have been used, such as dictionaries (Kouylekov et al., 2012; Perini, 2012), phrase and paraphrase tables (Mehdad et al., 2012a), GIZA++ (Och and Ney, 2003) word alignment models (W¨aschle and Fendrich, 2012), MT of subsegm</context>
</contexts>
<marker>Monz, Nastase, Negri, Fahrni, Mehdad, Strube, 2011</marker>
<rawString>Christoph Monz, Vivi Nastase, Matteo Negri, Angela Fahrni, Yashar Mehdad, and Michael Strube. 2011. CoSyne: a Framework for Multilingual Content Synchronization of Wikis. In Proceedings of Wikisym 2011, the International Symposium on Wikis and Open Collaboration, pages 217–218, Mountain View, California, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matteo Negri</author>
<author>Milen Ognianov Kouylekov</author>
<author>Bernardo Magnini</author>
<author>Yashar Mehdad</author>
<author>Elena Cabrio</author>
</authors>
<title>Towards Extensible Textual Entailment Engines: the EDITS Package.</title>
<date>2009</date>
<booktitle>In AI*IA 2009: XIth International Conference of the Italian Association for Artificial Intelligence.</booktitle>
<contexts>
<context position="3230" citStr="Negri et al., 2009" startWordPosition="501" endWordPosition="504">gments (Espl`a-Gomis et al., 2012), or semantic Wordnets (Castillo, 2011). In this work we propose a CLTE detection method based on a new set of features using word alignment as a source of cross-lingual knowledge. This set, which is richer than the one by (W¨aschle and Fendrich, 2012), is aimed not only at grasping information about the proportion of aligned words, but also about the distribution of the alignments in both 1In the first CLTE evaluation round at Semeval 2012, for instance, the system described in (Meng et al., 2012) used the open source EDITS system (Kouylekov and Negri, 2010; Negri et al., 2009) to calculate similarity scores between monolingual English pairs. 128 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 128–132, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics H and T. This set of features is later used by two support vector machine (SVM) classifiers for detecting CLTE separately in both directions (T —* H and T +— H). We use the combined output of both classifiers for performing the CLTE detection. The paper is organized as follows:</context>
</contexts>
<marker>Negri, Kouylekov, Magnini, Mehdad, Cabrio, 2009</marker>
<rawString>Matteo Negri, Milen Ognianov Kouylekov, Bernardo Magnini, Yashar Mehdad, and Elena Cabrio. 2009. Towards Extensible Textual Entailment Engines: the EDITS Package. In AI*IA 2009: XIth International Conference of the Italian Association for Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matteo Negri</author>
<author>Luisa Bentivogli</author>
<author>Yashar Mehdad</author>
<author>Danilo Giampiccolo</author>
<author>Alessandro Marchetti</author>
</authors>
<title>Divide and Conquer: Crowdsourcing the Creation of Cross-Lingual Textual Entailment Corpora.</title>
<date>2011</date>
<booktitle>Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<contexts>
<context position="8713" citStr="Negri et al., 2011" startWordPosition="1393" endWordPosition="1396"> language pairs: English-German (2,079,049 sentences), English-Spanish (2,123,036 sentences), English-French (2,144,820 sentences). For EnglishItalian we only used the parallel data available in Europarl (1,909,115 sentences) since this language pair is not covered by the News Commentary corpus. For our submitted run the SVM classifiers were trained using the whole training set. Such dataset consists of 1,000 pairs for each of the four language combinations, resulting from a concatenation of the training and test sets used for the first round of evaluation at SemEval 2012 (Negri et al., 2012; Negri et al., 2011). We have set a polynomial kernel with parameters empirically estimated on the training set: C = 2.0, and d = 1. After some preliminary experiments we have concluded that the HMM model in conjunction with the intersection symmetrization provides the best results. Our results, calculated over the 500 test pairs provided for each language combination, are presented in Table 3. As can be seen from the table, our system consistently outperforms the best average run of all participants and is the second best system for Spanish/English and Italian/English. For the other two languages, French/English</context>
</contexts>
<marker>Negri, Bentivogli, Mehdad, Giampiccolo, Marchetti, 2011</marker>
<rawString>Matteo Negri, Luisa Bentivogli, Yashar Mehdad, Danilo Giampiccolo, and Alessandro Marchetti. 2011. Divide and Conquer: Crowdsourcing the Creation of Cross-Lingual Textual Entailment Corpora. Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP 2011).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matteo Negri</author>
<author>Alessandro Marchetti</author>
<author>Yashar Mehdad</author>
<author>Luisa Bentivogli</author>
<author>Danilo Giampiccolo</author>
</authors>
<title>Semeval-2012 Task 8: Cross-Lingual Textual Entailment for Content Synchronization.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>399--407</pages>
<location>Montr´eal, Canada.</location>
<contexts>
<context position="2151" citStr="Negri et al., 2012" startWordPosition="320" endWordPosition="323">fication of semantic equivalence and information disparity between topically related sentences, CLTE recognition can be seen as a core task for a number of cross-lingual applications. Among others, multilingual content synchronization has been recently proposed as an ideal framework for the exploitation of CLTE components and the integration of semantics and machine translation (MT) technology (Mehdad et al., 2011; Mehdad et al., 2012b; Bronner et al., 2012; Monz et al., 2011). In the last few years, several methods have been proposed for CLTE. These can be roughly divided in two main groups (Negri et al., 2012): i) those using a pivoting strategy by translating H into the language of T and then using monolingual TE components1, and those directly using cross-lingual strategies. Among this second group, several sources of cross-lingual knowledge have been used, such as dictionaries (Kouylekov et al., 2012; Perini, 2012), phrase and paraphrase tables (Mehdad et al., 2012a), GIZA++ (Och and Ney, 2003) word alignment models (W¨aschle and Fendrich, 2012), MT of subsegments (Espl`a-Gomis et al., 2012), or semantic Wordnets (Castillo, 2011). In this work we propose a CLTE detection method based on a new se</context>
<context position="8692" citStr="Negri et al., 2012" startWordPosition="1389" endWordPosition="1392">.html#download three language pairs: English-German (2,079,049 sentences), English-Spanish (2,123,036 sentences), English-French (2,144,820 sentences). For EnglishItalian we only used the parallel data available in Europarl (1,909,115 sentences) since this language pair is not covered by the News Commentary corpus. For our submitted run the SVM classifiers were trained using the whole training set. Such dataset consists of 1,000 pairs for each of the four language combinations, resulting from a concatenation of the training and test sets used for the first round of evaluation at SemEval 2012 (Negri et al., 2012; Negri et al., 2011). We have set a polynomial kernel with parameters empirically estimated on the training set: C = 2.0, and d = 1. After some preliminary experiments we have concluded that the HMM model in conjunction with the intersection symmetrization provides the best results. Our results, calculated over the 500 test pairs provided for each language combination, are presented in Table 3. As can be seen from the table, our system consistently outperforms the best average run of all participants and is the second best system for Spanish/English and Italian/English. For the other two lang</context>
</contexts>
<marker>Negri, Marchetti, Mehdad, Bentivogli, Giampiccolo, 2012</marker>
<rawString>Matteo Negri, Alessandro Marchetti, Yashar Mehdad, Luisa Bentivogli, and Danilo Giampiccolo. 2012. Semeval-2012 Task 8: Cross-Lingual Textual Entailment for Content Synchronization. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012), pages 399–407, Montr´eal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matteo Negri</author>
<author>Alessandro Marchetti</author>
<author>Yashar Mehdad</author>
<author>Luisa Bentivogli</author>
<author>Danilo Giampiccolo</author>
</authors>
<title>Semeval-2013 Task 8: Cross-lingual Textual Entailment for Content Synchronization.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval</booktitle>
<marker>Negri, Marchetti, Mehdad, Bentivogli, Giampiccolo, 2013</marker>
<rawString>Matteo Negri, Alessandro Marchetti, Yashar Mehdad, Luisa Bentivogli, and Danilo Giampiccolo. 2013. Semeval-2013 Task 8: Cross-lingual Textual Entailment for Content Synchronization. In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="2546" citStr="Och and Ney, 2003" startWordPosition="384" endWordPosition="387"> (Mehdad et al., 2011; Mehdad et al., 2012b; Bronner et al., 2012; Monz et al., 2011). In the last few years, several methods have been proposed for CLTE. These can be roughly divided in two main groups (Negri et al., 2012): i) those using a pivoting strategy by translating H into the language of T and then using monolingual TE components1, and those directly using cross-lingual strategies. Among this second group, several sources of cross-lingual knowledge have been used, such as dictionaries (Kouylekov et al., 2012; Perini, 2012), phrase and paraphrase tables (Mehdad et al., 2012a), GIZA++ (Och and Ney, 2003) word alignment models (W¨aschle and Fendrich, 2012), MT of subsegments (Espl`a-Gomis et al., 2012), or semantic Wordnets (Castillo, 2011). In this work we propose a CLTE detection method based on a new set of features using word alignment as a source of cross-lingual knowledge. This set, which is richer than the one by (W¨aschle and Fendrich, 2012), is aimed not only at grasping information about the proportion of aligned words, but also about the distribution of the alignments in both 1In the first CLTE evaluation round at Semeval 2012, for instance, the system described in (Meng et al., 201</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz J. Och and Hermann Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alp´ar Perini</author>
</authors>
<title>DirRelCond3: detecting textual entailment across languages with conditions on directional text relatedness scores.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>710--714</pages>
<location>Montr´eal, Canada.</location>
<contexts>
<context position="2465" citStr="Perini, 2012" startWordPosition="373" endWordPosition="374">nts and the integration of semantics and machine translation (MT) technology (Mehdad et al., 2011; Mehdad et al., 2012b; Bronner et al., 2012; Monz et al., 2011). In the last few years, several methods have been proposed for CLTE. These can be roughly divided in two main groups (Negri et al., 2012): i) those using a pivoting strategy by translating H into the language of T and then using monolingual TE components1, and those directly using cross-lingual strategies. Among this second group, several sources of cross-lingual knowledge have been used, such as dictionaries (Kouylekov et al., 2012; Perini, 2012), phrase and paraphrase tables (Mehdad et al., 2012a), GIZA++ (Och and Ney, 2003) word alignment models (W¨aschle and Fendrich, 2012), MT of subsegments (Espl`a-Gomis et al., 2012), or semantic Wordnets (Castillo, 2011). In this work we propose a CLTE detection method based on a new set of features using word alignment as a source of cross-lingual knowledge. This set, which is richer than the one by (W¨aschle and Fendrich, 2012), is aimed not only at grasping information about the proportion of aligned words, but also about the distribution of the alignments in both 1In the first CLTE evaluati</context>
</contexts>
<marker>Perini, 2012</marker>
<rawString>Alp´ar Perini. 2012. DirRelCond3: detecting textual entailment across languages with conditions on directional text relatedness scores. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012), pages 710–714, Montr´eal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Hermann Ney</author>
<author>Christoph Tillmann</author>
</authors>
<title>HMM-based word alignment in statistical translation.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics (ACL’96),</booktitle>
<pages>836--841</pages>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="6958" citStr="Vogel et al., 1996" startWordPosition="1116" endWordPosition="1119">ilment (T +— H). The output of both classifiers is combined to form the four valid entailment decisions: • forward and backward classifier output true: “bidirectional” entailment; • forward is true and backward is false: “forward” entailment; • forward is false and backward is true: “backward” entailment; • both forward and backward output false: “no entailment” relation. Both binary classifiers were implemented using the SVM implementation of Weka (Hall et al., 2009). 3 Experiments In our submission we experimented with three standard word alignment algorithms: the hidden Markov model (HMM) (Vogel et al., 1996) and IBM models 3 and 4 (Brown et al., 1993). They are implemented in the MGIZA++ package (Gao and Vogel, 2008). Building on a probabilistic lexical model to establish mappings between words in two languages, these models compute alignments between the word positions in two input sentences S1 and S2. The models are trained incrementally: HMM is the base for IBM model 3, which is the base for IBM model 4. To train our models, we used 5 iterations of HMM, and 3 iterations of IBM models 3 and 4. Word alignments produced by these models are asymmetric (S1 —* S2 =� S2 —* S1). To cope with this, dif</context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>Stephan Vogel, Hermann Ney, and Christoph Tillmann. 1996. HMM-based word alignment in statistical translation. In Proceedings of the 16th International Conference on Computational Linguistics (ACL’96), pages 836–841, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katharina W¨aschle</author>
<author>Sascha Fendrich</author>
</authors>
<title>HDU: Cross-lingual Textual Entailment with SMT Features.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>467--471</pages>
<location>Montr´eal, Canada.</location>
<marker>W¨aschle, Fendrich, 2012</marker>
<rawString>Katharina W¨aschle and Sascha Fendrich. 2012. HDU: Cross-lingual Textual Entailment with SMT Features. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012), pages 467–471, Montr´eal, Canada.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>