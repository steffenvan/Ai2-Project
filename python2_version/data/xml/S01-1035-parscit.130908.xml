<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005020">
<title confidence="0.79183">
Anaphora Resolution with Word Sense Disambiguation
</title>
<author confidence="0.744538">
Judita Preiss*
</author>
<affiliation confidence="0.449798">
Computer Laboratory
JJ Thomson Avenue
</affiliation>
<address confidence="0.499919">
Cambridge CB3 OFD
United Kingdom
</address>
<email confidence="0.992146">
Judita.Preiss@el.cam.ac.uk
</email>
<sectionHeader confidence="0.98729" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9996838">
We describe a simple word sense disambiguation
system equipped with the Kennedy and Bogu-
raev (1996) anaphora resolution algorithm,
evaluated on the SENSEVAL-2 English all-words
task. The system relies on the structure of
the WordNet hierarchy to pick optimal senses
for nouns in the text. Since anaphoric refer-
ences are known to indicate the topic of the text
(Boguraev et al., 1998), they may aid disam-
biguation.
</bodyText>
<sectionHeader confidence="0.993786" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999705526315789">
We investigate the effect of repeating pronom-
inalized nouns in the input to our Word Sense
Disambiguation (WSD) algorithm (Preiss,
2001). The WSD algorithm is based on the
WordNet 1.7 hierarchy (Miller et al., 1990), and
assigns (WordNet) senses to all nouns. The en-
riched version we evaluate in this paper makes
use of our re-implementation of an anaphora
resolution algorithm of Kennedy and Boguraev
(1996).
If, as claimed by Boguraev et al. (1998), the
topic of the discourse is thus repeated, then the
main topic words will be more likely to be dis-
ambiguated correctly. The subsequent WSD al-
gorithm makes use of this extra topic informa-
tion, and this will in turn affect the disambigua-
tion of all other nouns in the discourse.
The system is evaluated on the English all-
words task in SENSEVAL-2.
</bodyText>
<sectionHeader confidence="0.992118" genericHeader="introduction">
2 Algorithms
</sectionHeader>
<subsectionHeader confidence="0.974025">
2.1 Overview of the Algorithm
</subsectionHeader>
<bodyText confidence="0.972963477272727">
Our WSD algorithm has three components, as
depicted in Figure 1. Taking as input the
* This work was supported by the EPSRC while the
author was at the University of Sheffield.
test data parsed using the Briscoe and Car-
roll (1993) parser (which uses the grammar de-
scribed in Carroll and Briscoe (1996)), the first
step is to identify and discard the pleonastic
pronouns. Our pleonastic component is de-
scribed in section 2.2.
In the next phase (section 2.3), third person
pronouns are resolved to a noun antecedent and
replaced in the text by the noun antecedent.
The purpose of this is to increase the number
of topic words in the text, to aid the disam-
biguation of other nouns. This approach as-
sumes firstly that pronouns refer mainly to topic
words, and secondly that repeating topic words
in the text helps overall disambiguation.
The final phase of the algorithm is the WSD
component, described in section 2.4. Using sim-
ulated annealing, it attempts to find a sense
assignment for every noun that minimizes an
overall &apos;distance&apos; function using the WordNet
hierarchy. In addition, for the repeated nouns
added in the previous phase, the senses are tied
together. This means that if the sense of one
word in a tie is changed during simulated an-
nealing, the sense of all words in the tie are si-
multaneously changed.
The advantage of this approach can be shown
on the following discourse: The parrot, like the
chicken, is kept by people as a domesticated
bird. It can speak. Suppose firstly that there is
no anaphora resolution phase. The words par-
rot, chicken, person, bird are given to the word
sense disambiguation algorithm, and the system
chooses senses which are related to people (par-
rot in the sense of mimicking people, chicken
a wimp and so on). This is clearly incorrect.
Now suppose we resolve the pronoun it to par-
rot, and repeat the word parrot in the text. Now
the words parrot, chicken, person, bird, parrot
are passed to the WSD system (where the two
</bodyText>
<page confidence="0.998517">
143
</page>
<bodyText confidence="0.9992765">
parrots are sense-tied together), and the system
now chooses the correct bird-related senses.
</bodyText>
<subsectionHeader confidence="0.985013">
2.2 Pleonastic Pronouns Component
</subsectionHeader>
<bodyText confidence="0.997828125">
It can be a pleonastic pronoun (pronoun with
no antecedent), for example in the sentence: It
is raining. We label the pronoun it as pleonastic
if it is a subject of a raising verb (these were ex-
tracted from the ANLT lexicon (Boguraev and
Briscoe, 1987)) or if it was used in conjunctions
with the verb to be and one of a particular set
of adjectives (for example It is possible to go to
town.).
The component was evaluated on a manually
anaphorically resolved portion of the BNC (the
initial 2000 sentences of w01). It has a preci-
sion (proportion of pronouns deemed pleonastic
which really are pleonastic) of 94% and recall
(proportion of pleonastic pronouns recognized
as pleonastic) of 61%.
</bodyText>
<subsectionHeader confidence="0.996674">
2.3 Anaphora Resolution Component
</subsectionHeader>
<bodyText confidence="0.999985217391304">
The pronominal anaphora resolution is carried
out by our re-implementation of the Kennedy
and Boguraev (Kennedy and Boguraev, 1996)
anaphora resolution algorithm. This algorithm
is based on that of Lappin and Leass (Lappin
and Leass, 1994), but does not require a full
parse. It treats the cases of third person pro-
nouns and lexical anaphors.1 Its cited accuracy
is 75% on general corpora (Kennedy and Bogu-
raev, 1996), but note that their published algo-
rithm uses the LINGSOFT morphosyntactic tag-
ger.
The algorithm creates coreference classes
which join together words which are believed
by the algorithm to be referring to the same ob-
ject. These classes are assigned a salience value
based on the presence of the features in Table
1. The salience value of a class is the sum of
the feature weights of its members, scaled down
by the number of sentences ago that the feature
last occurred. The correct antecedent is chosen
to be the closest word from the coreference class
with the highest salience.
</bodyText>
<subsectionHeader confidence="0.951866">
2.4 WSD Component
</subsectionHeader>
<bodyText confidence="0.798573">
We define a notion of distance between any two
WordNet noun senses which is based on the
&apos;Lexical anaphors are reflexives and reciprocals.
</bodyText>
<table confidence="0.999941727272727">
Condition Weight
Current sentence 100
Current context 50
Subject 80
Existential construct 70
Possessive 65
Direct object 50
Indirect object 40
Oblique 30
Non embedded 80
Non adjunct 50
</table>
<tableCaption confidence="0.999496">
Table 1: Salience values
</tableCaption>
<bodyText confidence="0.9981185">
WordNet hierarchy.2 As pointed out by Resnik
(1999), it is naive to assume that the distance
between any two nodes in the hierarchy is equal.
We therefore assign a weight w to every noun
</bodyText>
<equation confidence="0.8825205">
sense x:
weight(x) =
</equation>
<bodyText confidence="0.95060675">
number of children below x in hierarchy
total nodes in hierarchy
This is used to define the distance between two
distinct noun senses x and y:
</bodyText>
<equation confidence="0.980659333333333">
dist(x, y) =
min weight (z) — weight (x) — weight (y )
zEh(x)nh(y)
</equation>
<bodyText confidence="0.946949142857143">
where h(s) denotes the hypernym chain of noun
sense s.3 If the hypernym chains of x and y do
not intersect, the distance is set to the max-
imum value of 1. In Preiss (2001), we investi-
gated scaling the distance function such that for
noun senses x and y at positions in the corpus
n and m respectively:
dist(x, y)
In — rnla
Note that we do not explicitly use a window
of surrounding nouns, but the In — mI denom-
inator means that contributions from far away
nouns are usually negligible. We showed that it
was not possible to guess the optimal value of a
</bodyText>
<footnote confidence="0.9757405">
2In the SENSEVAL-2 task we identify nouns by using
an enhanced version of the GATE tagger and lemmatizer
(Cunningham et al., 1995).
_3The hypernym chain of s consists of the word s, the
parent word of s, the grandparent of s, etc, all the way
to a root word.
</footnote>
<equation confidence="0.977905">
dist* (x, y) =
</equation>
<page confidence="0.997316">
144
</page>
<figure confidence="0.9988925">
Pleonastic
component
Anaphora
resolution
Text
WSD
</figure>
<figureCaption confidence="0.999996">
Figure 1: Integration of components
</figureCaption>
<bodyText confidence="0.998718487179487">
in advance for any set of texts covered in SEM-
COR. However, averaged over all words there is
a slight peak around a = 1, so this is the value
we take.
The distance between two adjacent nodes in
the hierarchy may now not be equal. To il-
lustrate this, consider the following example
adapted from a paper of Resnik (1999). In
WordNet 1.7 (prerelease), VALVE is the parent
node of SAFETY VALVE, and MACHINE is the
parent of INFORMATION PROCESSING SYSTEM.
However, the intuitive distance between the first
pair of nodes seems to be less than the distance
between the second pair. Using our distance
function outlined above, the distance between
SAFETY VALVE and VALVE is 0.000121, while
the distance between INFORMATION PROCESS-
ING SYSTEM and MACHINE is 0.00229. This is
depicted in Figure 2.
We want to assign precisely one sense to each
noun in the text; we call this a path. We find the
&apos;optimal&apos; path by simulated annealing (Bertsi-
mas and Tsitsiklis, 1992). Simulated annealing
is a probabilistic method for finding the global
optimum of a function which may have a num-
ber of local optima. We define the function to
be minimized, the energy function, to be the
sum of all the pairwise scaled distances.
Our version of simulated annealing starts
with a randomly chosen path which it attempts
to improve. It performs a number of iterations
in which it randomly chooses a word and then
chooses a new sense for this word.4 If this
change is an improvement in terms of the en-
ergy function, it is kept. Otherwise, it may or
may not be accepted depending on the current
value of the temperature. Over time the tem-
perature decreases, making it less likely to keep
changes that increase the energy. The algorithm
</bodyText>
<footnote confidence="0.735572">
4We slightly skewed the probability distribution of
the senses towards the more frequent sense. The proba-
bility of the nth sense is proportional to
</footnote>
<bodyText confidence="0.998983416666667">
terminates when no changes were made in the
last 1000 iterations.
When simulated annealing terminates, it out-
puts what it deems the optimal sense assign-
ment for all the nouns in the text. For a
more detailed description of the WSD algo-
rithm, please refer to Preiss (2001).
This algorithm was implemented in C and ex-
ecuted on a Pentium III 500MHz. Each text
took 1 hour to initialize, and 2 hours to perform
20 runs of simulated annealing. A majority vote
then decided the sense assignment.
</bodyText>
<table confidence="0.9992225">
Article Words Senses Ties
1 363 1698 38
2 575 2098 46
3 340 1495 60
</table>
<tableCaption confidence="0.997997">
Table 2: Test data for the English all words task
</tableCaption>
<sectionHeader confidence="0.999226" genericHeader="background">
3 Results
</sectionHeader>
<bodyText confidence="0.999984266666667">
The WSD component enhanced with the
anaphora resolution algorithm was submitted
for the English all-words task in SENSEVAL-2.
The test data for this task consisted of three ar-
ticles, and information gathered from each ar-
ticle is displayed in Table 2. The words col-
umn shows the number of words marked as
nouns by the part of speech tagger in the parser.
The senses column contains the total number of
senses for all of these words. The ties column
shows the number of ties in the text, where each
tie contains a noun and some pronouns that re-
fer to it. The system achieved 44% precision
and 20% recall fine-grained, and 45.2% preci-
sion and 20.5% recall coarse-grained.5
</bodyText>
<footnote confidence="0.983439">
5The system assigns senses to all nouns but to no
other part of speech. It also has no mechanism for mark-
ing a word undecidable.
</footnote>
<page confidence="0.996191">
145
</page>
<figure confidence="0.996186428571428">
valve 3 machine 1
weight = 0.000132 weight = 0.002598
ZY\
safety_valve 9 other children
weight = 0.000011
information_processing_system 39 other children
weight = 0.000308
</figure>
<figureCaption confidence="0.988886">
Figure 2: Distance between adjacent nodes
</figureCaption>
<sectionHeader confidence="0.997118" genericHeader="discussions">
4 Future Work
</sectionHeader>
<bodyText confidence="0.9999905">
We would like to investigate the performance
of the WSD system with and without anaphora
resolution, with a view to also extending links
in text to other entities.
Although the precision of the pleonastic com-
ponent is currently quite high, we intend to
boost recall possibly by including some of the
rules devised by Lappin and Leass (1994).
</bodyText>
<sectionHeader confidence="0.991474" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.983901">
I would like to thank John Carroll for parsing
the SENSEVAL-2 corpus for me.
</bodyText>
<sectionHeader confidence="0.990033" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.941638705882353">
D. Bertsimas and J. Tsitsiklis. 1992. Simulated
annealing. In Probability and Algorithms,
pages 17-29. National Academy Press, Wash-
ington, D. C..
B.K. Boguraev and E.J. Briscoe. 1987. Large
lexicons for natural language processing: util-
ising the grammar coding system of the
longman dictionary of contemporary english.
Computational Linguistics, 13(4):219-240.
B. Boguraev, C. Kennedy, R. Bellamy,
S. Brawer, Y. Y. Wong, and J. Swartz. 1998.
Dynamic presentation of document content
for rapid on-line skimming. In Proceedings of
AAAI Spring Symposium on Intelligent Text
Summarisation, pages 118-128.
E. Briscoe and J. Carroll. 1993. Generalised
probabilistic LR parsing of natural language
(corpora) with unification-based grammars.
Computational Linguistics, 19(1):25-60.
J. Carroll and T. Briscoe. 1996. Apportion-
ing development effort in a probabilistic LR
parsing system through evaluation. In Pro-
ceedings of the ACL SIGDAT Conference on
Empirical Methodsin Natural Language Pro-
cessing, pages 92-100.
. Cunningham, R. Gaizauskas, and Y. Wilks.
1995. A general architecture for text engi-
neering (GATE) — a new approach to lan-
guage R&amp;D. Technical Report CS-95-21,
University of Sheffield.
C. Kennedy and B. Boguraev. 1996. Anaphora
for everyone: Pronominal anaphora resolu-
tion without a parser. In Proceedings of the
16th International Conference on Computa-
tional Linguistics (COLING&apos;96), pages 113-
118.
S. Lappin and H. Leass. 1994. An algorithm
for pronominal anaphora resolution. Compu-
tational Linguistics, 20(4):535-561.
. Miller, R. Beckwith, C. Felbaum, D. Gross,
and K. Miller. 1990. Introduction to Word-
Net: An on-line lexical database. Journal of
Lexicography, 3 (4) :235-244.
J. Preiss. 2001. Local versus global context for
WSD of nouns. In Proceedings of CL UK 4,
pages 1-8.
P. Resnik. 1999. Semantic similarity in a tax-
onomy: An information-based measure and
its application to problems of ambiguity in
natural language. Journal of Artificial Intel-
ligence Research, 11:95-130.
</reference>
<page confidence="0.998786">
146
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.202441">
<title confidence="0.998794">Anaphora Resolution with Word Sense Disambiguation</title>
<author confidence="0.841512">Judita</author>
<affiliation confidence="0.89608">Computer JJ Thomson</affiliation>
<address confidence="0.896761">Cambridge CB3</address>
<note confidence="0.6082125">United Judita.Preiss@el.cam.ac.uk</note>
<abstract confidence="0.968818272727273">We describe a simple word sense disambiguation system equipped with the Kennedy and Boguraev (1996) anaphora resolution algorithm, on the all-words task. The system relies on the structure of the WordNet hierarchy to pick optimal senses for nouns in the text. Since anaphoric references are known to indicate the topic of the text (Boguraev et al., 1998), they may aid disambiguation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Bertsimas</author>
<author>J Tsitsiklis</author>
</authors>
<title>Simulated annealing.</title>
<date>1992</date>
<booktitle>In Probability and Algorithms,</booktitle>
<pages>17--29</pages>
<publisher>National Academy Press,</publisher>
<location>Washington, D. C..</location>
<contexts>
<context position="7927" citStr="Bertsimas and Tsitsiklis, 1992" startWordPosition="1359" endWordPosition="1363">WordNet 1.7 (prerelease), VALVE is the parent node of SAFETY VALVE, and MACHINE is the parent of INFORMATION PROCESSING SYSTEM. However, the intuitive distance between the first pair of nodes seems to be less than the distance between the second pair. Using our distance function outlined above, the distance between SAFETY VALVE and VALVE is 0.000121, while the distance between INFORMATION PROCESSING SYSTEM and MACHINE is 0.00229. This is depicted in Figure 2. We want to assign precisely one sense to each noun in the text; we call this a path. We find the &apos;optimal&apos; path by simulated annealing (Bertsimas and Tsitsiklis, 1992). Simulated annealing is a probabilistic method for finding the global optimum of a function which may have a number of local optima. We define the function to be minimized, the energy function, to be the sum of all the pairwise scaled distances. Our version of simulated annealing starts with a randomly chosen path which it attempts to improve. It performs a number of iterations in which it randomly chooses a word and then chooses a new sense for this word.4 If this change is an improvement in terms of the energy function, it is kept. Otherwise, it may or may not be accepted depending on the c</context>
</contexts>
<marker>Bertsimas, Tsitsiklis, 1992</marker>
<rawString>D. Bertsimas and J. Tsitsiklis. 1992. Simulated annealing. In Probability and Algorithms, pages 17-29. National Academy Press, Washington, D. C..</rawString>
</citation>
<citation valid="true">
<authors>
<author>B K Boguraev</author>
<author>E J Briscoe</author>
</authors>
<title>Large lexicons for natural language processing: utilising the grammar coding system of the longman dictionary of contemporary english.</title>
<date>1987</date>
<journal>Computational Linguistics,</journal>
<pages>13--4</pages>
<contexts>
<context position="3796" citStr="Boguraev and Briscoe, 1987" startWordPosition="637" endWordPosition="640">le, chicken a wimp and so on). This is clearly incorrect. Now suppose we resolve the pronoun it to parrot, and repeat the word parrot in the text. Now the words parrot, chicken, person, bird, parrot are passed to the WSD system (where the two 143 parrots are sense-tied together), and the system now chooses the correct bird-related senses. 2.2 Pleonastic Pronouns Component It can be a pleonastic pronoun (pronoun with no antecedent), for example in the sentence: It is raining. We label the pronoun it as pleonastic if it is a subject of a raising verb (these were extracted from the ANLT lexicon (Boguraev and Briscoe, 1987)) or if it was used in conjunctions with the verb to be and one of a particular set of adjectives (for example It is possible to go to town.). The component was evaluated on a manually anaphorically resolved portion of the BNC (the initial 2000 sentences of w01). It has a precision (proportion of pronouns deemed pleonastic which really are pleonastic) of 94% and recall (proportion of pleonastic pronouns recognized as pleonastic) of 61%. 2.3 Anaphora Resolution Component The pronominal anaphora resolution is carried out by our re-implementation of the Kennedy and Boguraev (Kennedy and Boguraev,</context>
</contexts>
<marker>Boguraev, Briscoe, 1987</marker>
<rawString>B.K. Boguraev and E.J. Briscoe. 1987. Large lexicons for natural language processing: utilising the grammar coding system of the longman dictionary of contemporary english. Computational Linguistics, 13(4):219-240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Boguraev</author>
<author>C Kennedy</author>
<author>R Bellamy</author>
<author>S Brawer</author>
<author>Y Y Wong</author>
<author>J Swartz</author>
</authors>
<title>Dynamic presentation of document content for rapid on-line skimming.</title>
<date>1998</date>
<booktitle>In Proceedings of AAAI Spring Symposium on Intelligent Text Summarisation,</booktitle>
<pages>118--128</pages>
<contexts>
<context position="1052" citStr="Boguraev et al. (1998)" startWordPosition="159" endWordPosition="162">l senses for nouns in the text. Since anaphoric references are known to indicate the topic of the text (Boguraev et al., 1998), they may aid disambiguation. 1 Introduction We investigate the effect of repeating pronominalized nouns in the input to our Word Sense Disambiguation (WSD) algorithm (Preiss, 2001). The WSD algorithm is based on the WordNet 1.7 hierarchy (Miller et al., 1990), and assigns (WordNet) senses to all nouns. The enriched version we evaluate in this paper makes use of our re-implementation of an anaphora resolution algorithm of Kennedy and Boguraev (1996). If, as claimed by Boguraev et al. (1998), the topic of the discourse is thus repeated, then the main topic words will be more likely to be disambiguated correctly. The subsequent WSD algorithm makes use of this extra topic information, and this will in turn affect the disambiguation of all other nouns in the discourse. The system is evaluated on the English allwords task in SENSEVAL-2. 2 Algorithms 2.1 Overview of the Algorithm Our WSD algorithm has three components, as depicted in Figure 1. Taking as input the * This work was supported by the EPSRC while the author was at the University of Sheffield. test data parsed using the Bris</context>
</contexts>
<marker>Boguraev, Kennedy, Bellamy, Brawer, Wong, Swartz, 1998</marker>
<rawString>B. Boguraev, C. Kennedy, R. Bellamy, S. Brawer, Y. Y. Wong, and J. Swartz. 1998. Dynamic presentation of document content for rapid on-line skimming. In Proceedings of AAAI Spring Symposium on Intelligent Text Summarisation, pages 118-128.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Briscoe</author>
<author>J Carroll</author>
</authors>
<title>Generalised probabilistic LR parsing of natural language (corpora) with unification-based grammars.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--1</pages>
<contexts>
<context position="1674" citStr="Briscoe and Carroll (1993)" startWordPosition="270" endWordPosition="274">998), the topic of the discourse is thus repeated, then the main topic words will be more likely to be disambiguated correctly. The subsequent WSD algorithm makes use of this extra topic information, and this will in turn affect the disambiguation of all other nouns in the discourse. The system is evaluated on the English allwords task in SENSEVAL-2. 2 Algorithms 2.1 Overview of the Algorithm Our WSD algorithm has three components, as depicted in Figure 1. Taking as input the * This work was supported by the EPSRC while the author was at the University of Sheffield. test data parsed using the Briscoe and Carroll (1993) parser (which uses the grammar described in Carroll and Briscoe (1996)), the first step is to identify and discard the pleonastic pronouns. Our pleonastic component is described in section 2.2. In the next phase (section 2.3), third person pronouns are resolved to a noun antecedent and replaced in the text by the noun antecedent. The purpose of this is to increase the number of topic words in the text, to aid the disambiguation of other nouns. This approach assumes firstly that pronouns refer mainly to topic words, and secondly that repeating topic words in the text helps overall disambiguati</context>
</contexts>
<marker>Briscoe, Carroll, 1993</marker>
<rawString>E. Briscoe and J. Carroll. 1993. Generalised probabilistic LR parsing of natural language (corpora) with unification-based grammars. Computational Linguistics, 19(1):25-60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carroll</author>
<author>T Briscoe</author>
</authors>
<title>Apportioning development effort in a probabilistic LR parsing system through evaluation.</title>
<date>1996</date>
<booktitle>In Proceedings of the ACL SIGDAT Conference on Empirical Methodsin Natural Language Processing,</booktitle>
<pages>92--100</pages>
<contexts>
<context position="1745" citStr="Carroll and Briscoe (1996)" startWordPosition="283" endWordPosition="286">words will be more likely to be disambiguated correctly. The subsequent WSD algorithm makes use of this extra topic information, and this will in turn affect the disambiguation of all other nouns in the discourse. The system is evaluated on the English allwords task in SENSEVAL-2. 2 Algorithms 2.1 Overview of the Algorithm Our WSD algorithm has three components, as depicted in Figure 1. Taking as input the * This work was supported by the EPSRC while the author was at the University of Sheffield. test data parsed using the Briscoe and Carroll (1993) parser (which uses the grammar described in Carroll and Briscoe (1996)), the first step is to identify and discard the pleonastic pronouns. Our pleonastic component is described in section 2.2. In the next phase (section 2.3), third person pronouns are resolved to a noun antecedent and replaced in the text by the noun antecedent. The purpose of this is to increase the number of topic words in the text, to aid the disambiguation of other nouns. This approach assumes firstly that pronouns refer mainly to topic words, and secondly that repeating topic words in the text helps overall disambiguation. The final phase of the algorithm is the WSD component, described in</context>
</contexts>
<marker>Carroll, Briscoe, 1996</marker>
<rawString>J. Carroll and T. Briscoe. 1996. Apportioning development effort in a probabilistic LR parsing system through evaluation. In Proceedings of the ACL SIGDAT Conference on Empirical Methodsin Natural Language Processing, pages 92-100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Gaizauskas Cunningham</author>
<author>Y Wilks</author>
</authors>
<title>A general architecture for text engineering (GATE) — a new approach to language R&amp;D.</title>
<date>1995</date>
<tech>Technical Report CS-95-21,</tech>
<institution>University of Sheffield.</institution>
<marker>Cunningham, Wilks, 1995</marker>
<rawString>. Cunningham, R. Gaizauskas, and Y. Wilks. 1995. A general architecture for text engineering (GATE) — a new approach to language R&amp;D. Technical Report CS-95-21, University of Sheffield.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Kennedy</author>
<author>B Boguraev</author>
</authors>
<title>Anaphora for everyone: Pronominal anaphora resolution without a parser.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics (COLING&apos;96),</booktitle>
<pages>113--118</pages>
<contexts>
<context position="1010" citStr="Kennedy and Boguraev (1996)" startWordPosition="151" endWordPosition="154">ructure of the WordNet hierarchy to pick optimal senses for nouns in the text. Since anaphoric references are known to indicate the topic of the text (Boguraev et al., 1998), they may aid disambiguation. 1 Introduction We investigate the effect of repeating pronominalized nouns in the input to our Word Sense Disambiguation (WSD) algorithm (Preiss, 2001). The WSD algorithm is based on the WordNet 1.7 hierarchy (Miller et al., 1990), and assigns (WordNet) senses to all nouns. The enriched version we evaluate in this paper makes use of our re-implementation of an anaphora resolution algorithm of Kennedy and Boguraev (1996). If, as claimed by Boguraev et al. (1998), the topic of the discourse is thus repeated, then the main topic words will be more likely to be disambiguated correctly. The subsequent WSD algorithm makes use of this extra topic information, and this will in turn affect the disambiguation of all other nouns in the discourse. The system is evaluated on the English allwords task in SENSEVAL-2. 2 Algorithms 2.1 Overview of the Algorithm Our WSD algorithm has three components, as depicted in Figure 1. Taking as input the * This work was supported by the EPSRC while the author was at the University of </context>
<context position="4402" citStr="Kennedy and Boguraev, 1996" startWordPosition="735" endWordPosition="738">ev and Briscoe, 1987)) or if it was used in conjunctions with the verb to be and one of a particular set of adjectives (for example It is possible to go to town.). The component was evaluated on a manually anaphorically resolved portion of the BNC (the initial 2000 sentences of w01). It has a precision (proportion of pronouns deemed pleonastic which really are pleonastic) of 94% and recall (proportion of pleonastic pronouns recognized as pleonastic) of 61%. 2.3 Anaphora Resolution Component The pronominal anaphora resolution is carried out by our re-implementation of the Kennedy and Boguraev (Kennedy and Boguraev, 1996) anaphora resolution algorithm. This algorithm is based on that of Lappin and Leass (Lappin and Leass, 1994), but does not require a full parse. It treats the cases of third person pronouns and lexical anaphors.1 Its cited accuracy is 75% on general corpora (Kennedy and Boguraev, 1996), but note that their published algorithm uses the LINGSOFT morphosyntactic tagger. The algorithm creates coreference classes which join together words which are believed by the algorithm to be referring to the same object. These classes are assigned a salience value based on the presence of the features in Table</context>
</contexts>
<marker>Kennedy, Boguraev, 1996</marker>
<rawString>C. Kennedy and B. Boguraev. 1996. Anaphora for everyone: Pronominal anaphora resolution without a parser. In Proceedings of the 16th International Conference on Computational Linguistics (COLING&apos;96), pages 113-118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Lappin</author>
<author>H Leass</author>
</authors>
<title>An algorithm for pronominal anaphora resolution.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--4</pages>
<contexts>
<context position="4510" citStr="Lappin and Leass, 1994" startWordPosition="752" endWordPosition="755">ctives (for example It is possible to go to town.). The component was evaluated on a manually anaphorically resolved portion of the BNC (the initial 2000 sentences of w01). It has a precision (proportion of pronouns deemed pleonastic which really are pleonastic) of 94% and recall (proportion of pleonastic pronouns recognized as pleonastic) of 61%. 2.3 Anaphora Resolution Component The pronominal anaphora resolution is carried out by our re-implementation of the Kennedy and Boguraev (Kennedy and Boguraev, 1996) anaphora resolution algorithm. This algorithm is based on that of Lappin and Leass (Lappin and Leass, 1994), but does not require a full parse. It treats the cases of third person pronouns and lexical anaphors.1 Its cited accuracy is 75% on general corpora (Kennedy and Boguraev, 1996), but note that their published algorithm uses the LINGSOFT morphosyntactic tagger. The algorithm creates coreference classes which join together words which are believed by the algorithm to be referring to the same object. These classes are assigned a salience value based on the presence of the features in Table 1. The salience value of a class is the sum of the feature weights of its members, scaled down by the numbe</context>
</contexts>
<marker>Lappin, Leass, 1994</marker>
<rawString>S. Lappin and H. Leass. 1994. An algorithm for pronominal anaphora resolution. Computational Linguistics, 20(4):535-561.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Beckwith Miller</author>
<author>C Felbaum</author>
<author>D Gross</author>
<author>K Miller</author>
</authors>
<title>Introduction to WordNet: An on-line lexical database.</title>
<date>1990</date>
<journal>Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<pages>235--244</pages>
<contexts>
<context position="817" citStr="Miller et al., 1990" startWordPosition="120" endWordPosition="123">d sense disambiguation system equipped with the Kennedy and Boguraev (1996) anaphora resolution algorithm, evaluated on the SENSEVAL-2 English all-words task. The system relies on the structure of the WordNet hierarchy to pick optimal senses for nouns in the text. Since anaphoric references are known to indicate the topic of the text (Boguraev et al., 1998), they may aid disambiguation. 1 Introduction We investigate the effect of repeating pronominalized nouns in the input to our Word Sense Disambiguation (WSD) algorithm (Preiss, 2001). The WSD algorithm is based on the WordNet 1.7 hierarchy (Miller et al., 1990), and assigns (WordNet) senses to all nouns. The enriched version we evaluate in this paper makes use of our re-implementation of an anaphora resolution algorithm of Kennedy and Boguraev (1996). If, as claimed by Boguraev et al. (1998), the topic of the discourse is thus repeated, then the main topic words will be more likely to be disambiguated correctly. The subsequent WSD algorithm makes use of this extra topic information, and this will in turn affect the disambiguation of all other nouns in the discourse. The system is evaluated on the English allwords task in SENSEVAL-2. 2 Algorithms 2.1</context>
</contexts>
<marker>Miller, Felbaum, Gross, Miller, 1990</marker>
<rawString>. Miller, R. Beckwith, C. Felbaum, D. Gross, and K. Miller. 1990. Introduction to WordNet: An on-line lexical database. Journal of Lexicography, 3 (4) :235-244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Preiss</author>
</authors>
<title>Local versus global context for WSD of nouns.</title>
<date>2001</date>
<booktitle>In Proceedings of CL UK 4,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="738" citStr="Preiss, 2001" startWordPosition="108" endWordPosition="109">ted Kingdom Judita.Preiss@el.cam.ac.uk Abstract We describe a simple word sense disambiguation system equipped with the Kennedy and Boguraev (1996) anaphora resolution algorithm, evaluated on the SENSEVAL-2 English all-words task. The system relies on the structure of the WordNet hierarchy to pick optimal senses for nouns in the text. Since anaphoric references are known to indicate the topic of the text (Boguraev et al., 1998), they may aid disambiguation. 1 Introduction We investigate the effect of repeating pronominalized nouns in the input to our Word Sense Disambiguation (WSD) algorithm (Preiss, 2001). The WSD algorithm is based on the WordNet 1.7 hierarchy (Miller et al., 1990), and assigns (WordNet) senses to all nouns. The enriched version we evaluate in this paper makes use of our re-implementation of an anaphora resolution algorithm of Kennedy and Boguraev (1996). If, as claimed by Boguraev et al. (1998), the topic of the discourse is thus repeated, then the main topic words will be more likely to be disambiguated correctly. The subsequent WSD algorithm makes use of this extra topic information, and this will in turn affect the disambiguation of all other nouns in the discourse. The s</context>
<context position="6227" citStr="Preiss (2001)" startWordPosition="1058" endWordPosition="1059">able 1: Salience values WordNet hierarchy.2 As pointed out by Resnik (1999), it is naive to assume that the distance between any two nodes in the hierarchy is equal. We therefore assign a weight w to every noun sense x: weight(x) = number of children below x in hierarchy total nodes in hierarchy This is used to define the distance between two distinct noun senses x and y: dist(x, y) = min weight (z) — weight (x) — weight (y ) zEh(x)nh(y) where h(s) denotes the hypernym chain of noun sense s.3 If the hypernym chains of x and y do not intersect, the distance is set to the maximum value of 1. In Preiss (2001), we investigated scaling the distance function such that for noun senses x and y at positions in the corpus n and m respectively: dist(x, y) In — rnla Note that we do not explicitly use a window of surrounding nouns, but the In — mI denominator means that contributions from far away nouns are usually negligible. We showed that it was not possible to guess the optimal value of a 2In the SENSEVAL-2 task we identify nouns by using an enhanced version of the GATE tagger and lemmatizer (Cunningham et al., 1995). _3The hypernym chain of s consists of the word s, the parent word of s, the grandparen</context>
<context position="9094" citStr="Preiss (2001)" startWordPosition="1566" endWordPosition="1567"> may or may not be accepted depending on the current value of the temperature. Over time the temperature decreases, making it less likely to keep changes that increase the energy. The algorithm 4We slightly skewed the probability distribution of the senses towards the more frequent sense. The probability of the nth sense is proportional to terminates when no changes were made in the last 1000 iterations. When simulated annealing terminates, it outputs what it deems the optimal sense assignment for all the nouns in the text. For a more detailed description of the WSD algorithm, please refer to Preiss (2001). This algorithm was implemented in C and executed on a Pentium III 500MHz. Each text took 1 hour to initialize, and 2 hours to perform 20 runs of simulated annealing. A majority vote then decided the sense assignment. Article Words Senses Ties 1 363 1698 38 2 575 2098 46 3 340 1495 60 Table 2: Test data for the English all words task 3 Results The WSD component enhanced with the anaphora resolution algorithm was submitted for the English all-words task in SENSEVAL-2. The test data for this task consisted of three articles, and information gathered from each article is displayed in Table 2. Th</context>
</contexts>
<marker>Preiss, 2001</marker>
<rawString>J. Preiss. 2001. Local versus global context for WSD of nouns. In Proceedings of CL UK 4, pages 1-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
</authors>
<title>Semantic similarity in a taxonomy: An information-based measure and its application to problems of ambiguity in natural language.</title>
<date>1999</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>11--95</pages>
<contexts>
<context position="5689" citStr="Resnik (1999)" startWordPosition="953" endWordPosition="954"> members, scaled down by the number of sentences ago that the feature last occurred. The correct antecedent is chosen to be the closest word from the coreference class with the highest salience. 2.4 WSD Component We define a notion of distance between any two WordNet noun senses which is based on the &apos;Lexical anaphors are reflexives and reciprocals. Condition Weight Current sentence 100 Current context 50 Subject 80 Existential construct 70 Possessive 65 Direct object 50 Indirect object 40 Oblique 30 Non embedded 80 Non adjunct 50 Table 1: Salience values WordNet hierarchy.2 As pointed out by Resnik (1999), it is naive to assume that the distance between any two nodes in the hierarchy is equal. We therefore assign a weight w to every noun sense x: weight(x) = number of children below x in hierarchy total nodes in hierarchy This is used to define the distance between two distinct noun senses x and y: dist(x, y) = min weight (z) — weight (x) — weight (y ) zEh(x)nh(y) where h(s) denotes the hypernym chain of noun sense s.3 If the hypernym chains of x and y do not intersect, the distance is set to the maximum value of 1. In Preiss (2001), we investigated scaling the distance function such that for </context>
<context position="7291" citStr="Resnik (1999)" startWordPosition="1256" endWordPosition="1257">n of the GATE tagger and lemmatizer (Cunningham et al., 1995). _3The hypernym chain of s consists of the word s, the parent word of s, the grandparent of s, etc, all the way to a root word. dist* (x, y) = 144 Pleonastic component Anaphora resolution Text WSD Figure 1: Integration of components in advance for any set of texts covered in SEMCOR. However, averaged over all words there is a slight peak around a = 1, so this is the value we take. The distance between two adjacent nodes in the hierarchy may now not be equal. To illustrate this, consider the following example adapted from a paper of Resnik (1999). In WordNet 1.7 (prerelease), VALVE is the parent node of SAFETY VALVE, and MACHINE is the parent of INFORMATION PROCESSING SYSTEM. However, the intuitive distance between the first pair of nodes seems to be less than the distance between the second pair. Using our distance function outlined above, the distance between SAFETY VALVE and VALVE is 0.000121, while the distance between INFORMATION PROCESSING SYSTEM and MACHINE is 0.00229. This is depicted in Figure 2. We want to assign precisely one sense to each noun in the text; we call this a path. We find the &apos;optimal&apos; path by simulated anneal</context>
</contexts>
<marker>Resnik, 1999</marker>
<rawString>P. Resnik. 1999. Semantic similarity in a taxonomy: An information-based measure and its application to problems of ambiguity in natural language. Journal of Artificial Intelligence Research, 11:95-130.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>