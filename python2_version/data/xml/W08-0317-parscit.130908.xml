<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.015232">
<title confidence="0.9937145">
Effects of Morphological Analysis in Translation between German and
English
</title>
<author confidence="0.998051">
Sara Stymne, Maria Holmqvist and Lars Ahrenberg
</author>
<affiliation confidence="0.942534">
Department of Computer and Information Science
Link¨oping University, Sweden
</affiliation>
<email confidence="0.997829">
{sarst,marho,lah}@ida.liu.se
</email>
<sectionHeader confidence="0.998591" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999952">
We describe the LIU systems for German-
English and English-German translation sub-
mitted to the Shared Task of the Third Work-
shop of Statistical Machine Translation. The
main features of the systems, as compared
with the baseline, is the use of morphologi-
cal pre- and post-processing, and a sequence
model for German using morphologically rich
parts-of-speech. It is shown that these addi-
tions lead to improved translations.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999966333333333">
Research in statistical machine translation (SMT)
increasingly makes use of linguistic analysis in order
to improve performance. By including abstract cat-
egories, such as lemmas and parts-of-speech (POS),
in the models, it is argued that systems can become
better at handling sentences for which training data
at the word level is sparse. Such categories can be
integrated in the statistical framework using factored
models (Koehn et al., 2007). Furthermore, by pars-
ing input sentences and restructuring based on the
result to narrow the structural difference between
source and target language, the current phrase-based
models can be used more effectively (Collins et al.,
2005).
German differs structurally from English in sev-
eral respects (see e.g. Collins et al., 2005). In this
work we wanted to look at one particular aspect
of restructuring, namely splitting of German com-
pounds, and evaluate its effect in both translation di-
rections, thus extending the initial experiments re-
ported in Holmqvist et al. (2007). In addition, since
German is much richer in morphology than English,
we wanted to test the effects of using a sequence
model for German based on morphologically sub-
categorized parts-of-speech. All systems have been
specified as extensions of the Moses system pro-
vided for the Shared Task.
</bodyText>
<sectionHeader confidence="0.820225" genericHeader="introduction">
2 Part-of-speech and Morphology
</sectionHeader>
<bodyText confidence="0.998894615384616">
For both English and German we used the part-of-
speech tagger TreeTagger (Schmid, 1994) to obtain
POS-tags.
The German POS-tags from TreeTagger were re-
fined by adding morphological information from
a commercial dependency parser, including case,
number, gender, definiteness, and person for nouns,
pronouns, verbs, adjectives and determiners in the
cases where both tools agreed on the POS-tag. If
they did not agree, the POS-tag from TreeTagger
was chosen. This tag set seemed more suitable for
SMT, with tags for proper names and foreign words
which the commercial parser does not have.
</bodyText>
<sectionHeader confidence="0.972918" genericHeader="method">
3 Compound Analysis
</sectionHeader>
<bodyText confidence="0.9971179">
Compounding is common in many languages, in-
cluding German. Since compounding is highly pro-
ductive it increases vocabulary size and leads to
sparse data problems.
Compounds in German are formed by joining
words, and in addition filler letters can be inserted
or letters can be removed from the end of all but the
last word of the compound (Langer, 1998). We have
chosen to allow simple additions of letter(s) (-s, -n,
-en, -nen, -es, -er, -ien) and simple truncations (-e,
</bodyText>
<page confidence="0.982566">
135
</page>
<affiliation confidence="0.2695585">
Proceedings of the Third Workshop on Statistical Machine Translation, pages 135–138,
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</affiliation>
<listItem confidence="0.8565835">
-en, -n). Example of compounds with additions and
truncations can be seen in (1).
(1) a. Staatsfeind (Staat + Feind)
public enemy
b. Kirchhof (Kirche + Hof)
graveyard
</listItem>
<subsectionHeader confidence="0.999778">
3.1 Splitting compounds
</subsectionHeader>
<bodyText confidence="0.999971515151515">
Noun and adjective compounds are split by a mod-
ified version of the corpus-based method presented
by Koehn and Knight (2003). First the German lan-
guage model data is POS-tagged and used to calcu-
late frequencies of all nouns, verbs, adjectives, ad-
verbs and the negative particle. Then, for each noun
and adjective all splits into these known words from
the corpus, allowing filler additions and truncations,
are considered, choosing the splitting option with
the highest arithmetic mean1 of the frequencies of
its parts.
A length limit of each part was set to 4 charac-
ters. For adjectives we restrict the number of parts
to maximum two, since they do not tend to have
multiple parts as often as nouns. In addition we
added a stop list with 14 parts, often mistagged, that
gave rise to wrong adjective splits, such as arische
(’Aryan’) in konsularische (’consular’).
As Koehn and Knight (2003) points out, parts of
compounds do not always have the same meaning
as when they stand alone, e.g. Grundrechte (’basic
rights’), where the first part, Grund, usually trans-
lates as foundation, which is wrong in this com-
pound. To overcome this we marked all compound
parts but the last, with the symbol ’#’. Thus they are
handled as separate words. Parts of split words also
receive a special POS-tag, based on the POS of the
last word of the compound, and the last part receives
the same POS as the full word.
We also split words containing hyphens based on
the same algorithm. Their parts receive a different
POS-tag, and the hyphens are left at the end of all
but the last part.
</bodyText>
<footnote confidence="0.63452">
1We choose the arithmetic mean over the geometric mean
used by Koehn and Knight (2003) in order to increase the num-
ber of splits.
</footnote>
<subsectionHeader confidence="0.999753">
3.2 Merging compounds
</subsectionHeader>
<bodyText confidence="0.999906636363636">
For translation into German, the translation output
contains split compounds, which need to be merged.
An algorithm for merging has been proposed by
Popovi´c et al. (2006) using lists of compounds and
their parts. This method cannot merge unseen com-
pounds, however, so instead we base merging on
POS. If a word has a compound-POS, and the fol-
lowing word has a matching POS, they are merged.
If the next POS does not match, a hyphen is added
to the word, allowing for coordinated compounds as
in (2).
</bodyText>
<listItem confidence="0.957876">
(2) Wasser- und Bodenqualit¨at
water and soil quality
</listItem>
<sectionHeader confidence="0.995363" genericHeader="method">
4 System Descriptions
</sectionHeader>
<bodyText confidence="0.999896666666667">
The main difference of our system in relation to the
baseline system of the Shared Task2 is the pre- and
post-processing described above, the use of a POS
factor, and an additional sequence model on POS.
We also modified the tuning to include compound
merging, and used a smaller corpus, 600 sentences
picked evenly from the dev2006 corpus, for tuning.
We use the Moses decoder (Koehn et al., 2007) and
SRILM language models (Stolcke, 2002).
</bodyText>
<subsectionHeader confidence="0.986368">
4.1 German ==&gt;. English
</subsectionHeader>
<bodyText confidence="0.998661071428571">
We used POS as an output factor, as can be seen in
Figure 1. Using additional factors only on the tar-
get side means that only the training data need to be
POS-tagged, not the tuning data or translation input.
However, POS-tagging is still performed for Ger-
man as input to the pre-processing step. As Figure 1
shows we have two sequence models. A 5-gram lan-
guage model based on surface form using Kneser-
Ney smoothing and in addition a 7-gram sequence
model based on POS using Witten-Bell3 smoothing.
The training corpus was filtered to sentences with
2–40 words, resulting in a total of 1054688 sen-
tences. Training was done purely on Europarl data,
but results were submitted both on Europarl and
</bodyText>
<footnote confidence="0.992884333333333">
2http://www.statmt.org/wmt08/baseline.
html
3Kneser-Ney smoothing can not be used for the POS se-
quence model, since there were counts-of-counts of zero. How-
ever, Witten-Bell smoothing gives good results when the vocab-
ulary is small.
</footnote>
<page confidence="0.992637">
136
</page>
<figure confidence="0.854303166666667">
Factors Sequence
Source Target models
word
5−gram
POS
7−gram
</figure>
<figureCaption confidence="0.999888">
Figure 1: Architecture of the factored system
</figureCaption>
<bodyText confidence="0.99204175">
News data. The news data were submitted to see
how well a pure out-of-domain system could per-
form.
In the pre-processing step compounds were split.
This was done for training, tuning and translation.
In addition German contracted prepositions and de-
terminers, such as zum from zu dem (’to the’), when
identified as such by the tagger, were split.
</bodyText>
<subsectionHeader confidence="0.989805">
4.2 English ==&gt;. German
</subsectionHeader>
<bodyText confidence="0.999991133333333">
All features of the German to English system were
used, and in addition more fine-grained German
POS-tags that were sub-categorized for morpholog-
ical features. This was done for training, tuning
and sequence models. At translation time no pre-
processing was needed for the English input, but a
post-processing step for the German output is re-
quired, including the merging of compounds and
contracted prepositions and determiners. The latter
was done in connection with uppercasing, by train-
ing an instance of Moses on a lower cased corpus
with split contractions and an upper-cased corpus
with untouched contractions. The tuning step was
modified so that merging of compounds were done
as part of the tuning.
</bodyText>
<subsectionHeader confidence="0.990678">
4.3 Baseline
</subsectionHeader>
<bodyText confidence="0.9995187">
For comparison, we constructed a baseline accord-
ing to the shared-task description, but with smaller
tuning corpus, and the same sentence filtering for the
translation model as in the submitted system, using
only sentences of length 2-40.
In addition we constructed a factored baseline
system, with POS as an output factor and a se-
quence model for POS. Here we only used the orig-
inal POS-tags from TreeTagger, no additional mor-
phology was added for German.
</bodyText>
<table confidence="0.994602">
De-En En-De
Baseline 26.95 20.16
Factored baseline 27.43 20.27
Submitted system 27.63 20.46
</table>
<tableCaption confidence="0.99037">
Table 1: Bleu scores for Europarl (test2007)
</tableCaption>
<table confidence="0.9996695">
De-En En-De
Baseline 19.54 14.31
Factored baseline 20.16 14.37
Submitted system 20.61 14.77
</table>
<tableCaption confidence="0.997626">
Table 2: Bleu scores for News Commentary (nc-test2007)
</tableCaption>
<sectionHeader confidence="0.999871" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999551545454545">
Case-sensitive Bleu scores4 (Papineni et al., 2002)
for the Europarl devtest set (test2007) are shown in
table 1. We can see that the submitted system per-
forms best, and that the factored baseline is better
than the pure baseline, especially for translation into
English.
Bleu scores for News Commentary5 (nc-test2007)
are shown in Table 2. Here we can also see that the
submitted system is the best. As expected, Bleu is
much lower on out-of-domain news text than on the
Europarl development test set.
</bodyText>
<subsectionHeader confidence="0.98535">
5.1 Compounds
</subsectionHeader>
<bodyText confidence="0.999716357142857">
The quality of compound translations were analysed
manually. The first 100 compounds that could be
found by the splitting algorithm were extracted from
the Europarl reference text, test2007, together with
their English translations6.
System translations were compared to the an-
notated compounds and classified into seven cate-
gories: correct, alternative good translation, correct
but different form, part of the compound translated,
no direct equivalent, wrong and untranslated. Out
of these the first three categories can be considered
good translations.
We performed the error analysis for the submitted
and the baseline system. The result can be seen in
</bodyText>
<footnote confidence="0.997468333333333">
4The %Bleu notation is used in this report
5No development test set for News test were provided, so we
present result for the News commentary, which can be expected
to give similar results.
6The English translations need not be compounds. Com-
pounds without a clear English translation were skipped.
</footnote>
<table confidence="0.907220230769231">
word
word
POS
137
De=:�En En=:�De
Subm Base Subm Base
Correct 50 46 40 39
Alternative 36 26 32 29
Form 5 7 6 8
Part 2 5 10 15
No equivalent 6 2 8 5
Wrong 1 7 1 1
Untranslated – 7 3 3
</table>
<tableCaption confidence="0.980743666666667">
Table 3: Results of the error analysis of compound trans-
lations
Table 3. For translation into English the submitted
</tableCaption>
<bodyText confidence="0.97325625">
system handles compound translations considerably
better than the baseline with 91% good translations
compared to 79%. In the submitted system all com-
pounds have a translation, compared to the baseline
system which has 7% of the compounds untrans-
lated. In the other translation direction the difference
is smaller, the biggest difference is that the submit-
ted system has fewer cases of partial translation.
</bodyText>
<subsectionHeader confidence="0.998743">
5.2 Agreement in German NPs
</subsectionHeader>
<bodyText confidence="0.999967933333334">
To study the effects of using fine-grained POS-tags
in the German sequence model, a similar close study
of German NPs was performed. 100 English NPs
having at least two dependents of the head noun
were selected from a randomly chosen subsection
of the development test set. Their translations in
the baseline and submitted system were then identi-
fied. Translations that were not NPs were discarded.
In about two thirds (62 out of 99) of the cases, the
translations were identical. For the remainder, 12
translations were of equal quality, the submitted sys-
tem had a better translation in 17 cases (46%), and a
worse one in 8 cases (22%). In the majority of cases
where the baseline was better, this was due to word
selection, not agreement.
</bodyText>
<sectionHeader confidence="0.999709" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999771333333333">
Adding morphological processing improved trans-
lation results in both directions for both text types.
Splitting compounds gave a bigger effect for trans-
lation from German. Marking of compound parts
worked well, with no untranslated parts left in the
sample used for evaluation. The mini-evaluation
of German NPs in English-German translation in-
dicates that the morphologically rich POS-based se-
quence model for German also had a positive effect.
</bodyText>
<sectionHeader confidence="0.954451" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.9998">
We would like to thank Joe Steinhauer for help with
the evaluation of German output.
</bodyText>
<sectionHeader confidence="0.998949" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999885880952381">
M. Collins, P. Koehn, and I. Kuˇcerov´a. 2005. Clause re-
structuring for statistical machine translation. In Pro-
ceedings of the 43rd Annual Meeting of the ACL, pages
531–540, Ann Arbor, Michigan.
M. Holmqvist, S. Stymne, and L. Ahrenberg. 2007. Get-
ting to know Moses: Initial experiments on German-
English factored translation. In Proceedings of the
Second Workshop on Statistical Machine Translation,
pages 181–184, Prague, Czech Republic. Association
for Computational Linguistics.
P. Koehn and K. Knight. 2003. Empirical methods for
compound splitting. In Proceedings of the tenth con-
ference of EACL, pages 187–193, Budapest, Hungary.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open source toolkit for
statistical machine translation. In Proceedings of the
45th Annual Meeting of the ACL, demonstration ses-
sion, Prague, Czech Republic.
S. Langer. 1998. Zur Morphologie und Semantik von
Nominalkomposita. In Tagungsband der 4. Konferenz
zur Verarbeitung nat¨urlicher Sprache (KONVENS),
pages 83–97.
K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. 2002.
BLEU: a method for automatic evaluation of machine
translation. In Proceedings of the 40th Annual Meet-
ing of the ACL, pages 311–318, Philadelphia, Pennsyl-
vania.
M. Popovi´c, D. Stein, and H. Ney. 2006. Statistical ma-
chine translation of German compound words. In Pro-
ceedings ofFinTAL - 5th International Conference on
Natural Language Processing, pages 616–624, Turku,
Finland.
H. Schmid. 1994. Probabilistic part-of-speech tagging
using decision trees. In Preoceedings of the Interna-
tional Conference on New Methods in Language Pro-
cessing, Manchester, UK.
A. Stolcke. 2002. SRILM - an extensible language
modeling toolkit. In Proceedings of the International
Conference on Spoken Language Processing (ICSLP),
pages 901–904, Denver, Colorado.
</reference>
<page confidence="0.997338">
138
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.771105">
<title confidence="0.8826755">Effects of Morphological Analysis in Translation between German and English</title>
<author confidence="0.901834">Sara Stymne</author>
<author confidence="0.901834">Maria Holmqvist</author>
<author confidence="0.901834">Lars</author>
<affiliation confidence="0.9998195">Department of Computer and Information Link¨oping University,</affiliation>
<abstract confidence="0.998288454545455">We describe the LIU systems for German- English and English-German translation submitted to the Shared Task of the Third Workshop of Statistical Machine Translation. The main features of the systems, as compared with the baseline, is the use of morphological preand post-processing, and a sequence model for German using morphologically rich parts-of-speech. It is shown that these additions lead to improved translations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>P Koehn</author>
<author>I Kuˇcerov´a</author>
</authors>
<title>Clause restructuring for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the ACL,</booktitle>
<pages>531--540</pages>
<location>Ann Arbor, Michigan.</location>
<marker>Collins, Koehn, Kuˇcerov´a, 2005</marker>
<rawString>M. Collins, P. Koehn, and I. Kuˇcerov´a. 2005. Clause restructuring for statistical machine translation. In Proceedings of the 43rd Annual Meeting of the ACL, pages 531–540, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Holmqvist</author>
<author>S Stymne</author>
<author>L Ahrenberg</author>
</authors>
<title>Getting to know Moses: Initial experiments on GermanEnglish factored translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>181--184</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="1694" citStr="Holmqvist et al. (2007)" startWordPosition="251" endWordPosition="254">amework using factored models (Koehn et al., 2007). Furthermore, by parsing input sentences and restructuring based on the result to narrow the structural difference between source and target language, the current phrase-based models can be used more effectively (Collins et al., 2005). German differs structurally from English in several respects (see e.g. Collins et al., 2005). In this work we wanted to look at one particular aspect of restructuring, namely splitting of German compounds, and evaluate its effect in both translation directions, thus extending the initial experiments reported in Holmqvist et al. (2007). In addition, since German is much richer in morphology than English, we wanted to test the effects of using a sequence model for German based on morphologically subcategorized parts-of-speech. All systems have been specified as extensions of the Moses system provided for the Shared Task. 2 Part-of-speech and Morphology For both English and German we used the part-ofspeech tagger TreeTagger (Schmid, 1994) to obtain POS-tags. The German POS-tags from TreeTagger were refined by adding morphological information from a commercial dependency parser, including case, number, gender, definiteness, an</context>
</contexts>
<marker>Holmqvist, Stymne, Ahrenberg, 2007</marker>
<rawString>M. Holmqvist, S. Stymne, and L. Ahrenberg. 2007. Getting to know Moses: Initial experiments on GermanEnglish factored translation. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 181–184, Prague, Czech Republic. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>K Knight</author>
</authors>
<title>Empirical methods for compound splitting.</title>
<date>2003</date>
<booktitle>In Proceedings of the tenth conference of EACL,</booktitle>
<pages>187--193</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="3582" citStr="Koehn and Knight (2003)" startWordPosition="551" endWordPosition="554">und (Langer, 1998). We have chosen to allow simple additions of letter(s) (-s, -n, -en, -nen, -es, -er, -ien) and simple truncations (-e, 135 Proceedings of the Third Workshop on Statistical Machine Translation, pages 135–138, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics -en, -n). Example of compounds with additions and truncations can be seen in (1). (1) a. Staatsfeind (Staat + Feind) public enemy b. Kirchhof (Kirche + Hof) graveyard 3.1 Splitting compounds Noun and adjective compounds are split by a modified version of the corpus-based method presented by Koehn and Knight (2003). First the German language model data is POS-tagged and used to calculate frequencies of all nouns, verbs, adjectives, adverbs and the negative particle. Then, for each noun and adjective all splits into these known words from the corpus, allowing filler additions and truncations, are considered, choosing the splitting option with the highest arithmetic mean1 of the frequencies of its parts. A length limit of each part was set to 4 characters. For adjectives we restrict the number of parts to maximum two, since they do not tend to have multiple parts as often as nouns. In addition we added a </context>
<context position="5115" citStr="Koehn and Knight (2003)" startWordPosition="819" endWordPosition="822">t part, Grund, usually translates as foundation, which is wrong in this compound. To overcome this we marked all compound parts but the last, with the symbol ’#’. Thus they are handled as separate words. Parts of split words also receive a special POS-tag, based on the POS of the last word of the compound, and the last part receives the same POS as the full word. We also split words containing hyphens based on the same algorithm. Their parts receive a different POS-tag, and the hyphens are left at the end of all but the last part. 1We choose the arithmetic mean over the geometric mean used by Koehn and Knight (2003) in order to increase the number of splits. 3.2 Merging compounds For translation into German, the translation output contains split compounds, which need to be merged. An algorithm for merging has been proposed by Popovi´c et al. (2006) using lists of compounds and their parts. This method cannot merge unseen compounds, however, so instead we base merging on POS. If a word has a compound-POS, and the following word has a matching POS, they are merged. If the next POS does not match, a hyphen is added to the word, allowing for coordinated compounds as in (2). (2) Wasser- und Bodenqualit¨at wat</context>
</contexts>
<marker>Koehn, Knight, 2003</marker>
<rawString>P. Koehn and K. Knight. 2003. Empirical methods for compound splitting. In Proceedings of the tenth conference of EACL, pages 187–193, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
<author>C Dyer</author>
<author>O Bojar</author>
<author>A Constantin</author>
<author>E Herbst</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL, demonstration session,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="1121" citStr="Koehn et al., 2007" startWordPosition="161" endWordPosition="164">nd post-processing, and a sequence model for German using morphologically rich parts-of-speech. It is shown that these additions lead to improved translations. 1 Introduction Research in statistical machine translation (SMT) increasingly makes use of linguistic analysis in order to improve performance. By including abstract categories, such as lemmas and parts-of-speech (POS), in the models, it is argued that systems can become better at handling sentences for which training data at the word level is sparse. Such categories can be integrated in the statistical framework using factored models (Koehn et al., 2007). Furthermore, by parsing input sentences and restructuring based on the result to narrow the structural difference between source and target language, the current phrase-based models can be used more effectively (Collins et al., 2005). German differs structurally from English in several respects (see e.g. Collins et al., 2005). In this work we wanted to look at one particular aspect of restructuring, namely splitting of German compounds, and evaluate its effect in both translation directions, thus extending the initial experiments reported in Holmqvist et al. (2007). In addition, since German</context>
<context position="6155" citStr="Koehn et al., 2007" startWordPosition="999" endWordPosition="1002">as a matching POS, they are merged. If the next POS does not match, a hyphen is added to the word, allowing for coordinated compounds as in (2). (2) Wasser- und Bodenqualit¨at water and soil quality 4 System Descriptions The main difference of our system in relation to the baseline system of the Shared Task2 is the pre- and post-processing described above, the use of a POS factor, and an additional sequence model on POS. We also modified the tuning to include compound merging, and used a smaller corpus, 600 sentences picked evenly from the dev2006 corpus, for tuning. We use the Moses decoder (Koehn et al., 2007) and SRILM language models (Stolcke, 2002). 4.1 German ==&gt;. English We used POS as an output factor, as can be seen in Figure 1. Using additional factors only on the target side means that only the training data need to be POS-tagged, not the tuning data or translation input. However, POS-tagging is still performed for German as input to the pre-processing step. As Figure 1 shows we have two sequence models. A 5-gram language model based on surface form using KneserNey smoothing and in addition a 7-gram sequence model based on POS using Witten-Bell3 smoothing. The training corpus was filtered </context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin, and E. Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the ACL, demonstration session, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Langer</author>
</authors>
<title>Zur Morphologie und Semantik von Nominalkomposita.</title>
<date>1998</date>
<booktitle>In Tagungsband der 4. Konferenz zur Verarbeitung nat¨urlicher Sprache (KONVENS),</booktitle>
<pages>83--97</pages>
<contexts>
<context position="2977" citStr="Langer, 1998" startWordPosition="459" endWordPosition="460"> cases where both tools agreed on the POS-tag. If they did not agree, the POS-tag from TreeTagger was chosen. This tag set seemed more suitable for SMT, with tags for proper names and foreign words which the commercial parser does not have. 3 Compound Analysis Compounding is common in many languages, including German. Since compounding is highly productive it increases vocabulary size and leads to sparse data problems. Compounds in German are formed by joining words, and in addition filler letters can be inserted or letters can be removed from the end of all but the last word of the compound (Langer, 1998). We have chosen to allow simple additions of letter(s) (-s, -n, -en, -nen, -es, -er, -ien) and simple truncations (-e, 135 Proceedings of the Third Workshop on Statistical Machine Translation, pages 135–138, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics -en, -n). Example of compounds with additions and truncations can be seen in (1). (1) a. Staatsfeind (Staat + Feind) public enemy b. Kirchhof (Kirche + Hof) graveyard 3.1 Splitting compounds Noun and adjective compounds are split by a modified version of the corpus-based method presented by Koehn and Knight (</context>
</contexts>
<marker>Langer, 1998</marker>
<rawString>S. Langer. 1998. Zur Morphologie und Semantik von Nominalkomposita. In Tagungsband der 4. Konferenz zur Verarbeitung nat¨urlicher Sprache (KONVENS), pages 83–97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W-J Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the ACL,</booktitle>
<pages>311--318</pages>
<location>Philadelphia, Pennsylvania.</location>
<contexts>
<context position="9157" citStr="Papineni et al., 2002" startWordPosition="1484" endWordPosition="1487">the submitted system, using only sentences of length 2-40. In addition we constructed a factored baseline system, with POS as an output factor and a sequence model for POS. Here we only used the original POS-tags from TreeTagger, no additional morphology was added for German. De-En En-De Baseline 26.95 20.16 Factored baseline 27.43 20.27 Submitted system 27.63 20.46 Table 1: Bleu scores for Europarl (test2007) De-En En-De Baseline 19.54 14.31 Factored baseline 20.16 14.37 Submitted system 20.61 14.77 Table 2: Bleu scores for News Commentary (nc-test2007) 5 Results Case-sensitive Bleu scores4 (Papineni et al., 2002) for the Europarl devtest set (test2007) are shown in table 1. We can see that the submitted system performs best, and that the factored baseline is better than the pure baseline, especially for translation into English. Bleu scores for News Commentary5 (nc-test2007) are shown in Table 2. Here we can also see that the submitted system is the best. As expected, Bleu is much lower on out-of-domain news text than on the Europarl development test set. 5.1 Compounds The quality of compound translations were analysed manually. The first 100 compounds that could be found by the splitting algorithm we</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the ACL, pages 311–318, Philadelphia, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Popovi´c</author>
<author>D Stein</author>
<author>H Ney</author>
</authors>
<title>Statistical machine translation of German compound words.</title>
<date>2006</date>
<booktitle>In Proceedings ofFinTAL - 5th International Conference on Natural Language Processing,</booktitle>
<pages>616--624</pages>
<location>Turku, Finland.</location>
<marker>Popovi´c, Stein, Ney, 2006</marker>
<rawString>M. Popovi´c, D. Stein, and H. Ney. 2006. Statistical machine translation of German compound words. In Proceedings ofFinTAL - 5th International Conference on Natural Language Processing, pages 616–624, Turku, Finland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In Preoceedings of the International Conference on New Methods in Language Processing,</booktitle>
<location>Manchester, UK.</location>
<contexts>
<context position="2103" citStr="Schmid, 1994" startWordPosition="318" endWordPosition="319">particular aspect of restructuring, namely splitting of German compounds, and evaluate its effect in both translation directions, thus extending the initial experiments reported in Holmqvist et al. (2007). In addition, since German is much richer in morphology than English, we wanted to test the effects of using a sequence model for German based on morphologically subcategorized parts-of-speech. All systems have been specified as extensions of the Moses system provided for the Shared Task. 2 Part-of-speech and Morphology For both English and German we used the part-ofspeech tagger TreeTagger (Schmid, 1994) to obtain POS-tags. The German POS-tags from TreeTagger were refined by adding morphological information from a commercial dependency parser, including case, number, gender, definiteness, and person for nouns, pronouns, verbs, adjectives and determiners in the cases where both tools agreed on the POS-tag. If they did not agree, the POS-tag from TreeTagger was chosen. This tag set seemed more suitable for SMT, with tags for proper names and foreign words which the commercial parser does not have. 3 Compound Analysis Compounding is common in many languages, including German. Since compounding i</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>H. Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In Preoceedings of the International Conference on New Methods in Language Processing, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>SRILM - an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference on Spoken Language Processing (ICSLP),</booktitle>
<pages>901--904</pages>
<location>Denver, Colorado.</location>
<contexts>
<context position="6197" citStr="Stolcke, 2002" startWordPosition="1007" endWordPosition="1008"> POS does not match, a hyphen is added to the word, allowing for coordinated compounds as in (2). (2) Wasser- und Bodenqualit¨at water and soil quality 4 System Descriptions The main difference of our system in relation to the baseline system of the Shared Task2 is the pre- and post-processing described above, the use of a POS factor, and an additional sequence model on POS. We also modified the tuning to include compound merging, and used a smaller corpus, 600 sentences picked evenly from the dev2006 corpus, for tuning. We use the Moses decoder (Koehn et al., 2007) and SRILM language models (Stolcke, 2002). 4.1 German ==&gt;. English We used POS as an output factor, as can be seen in Figure 1. Using additional factors only on the target side means that only the training data need to be POS-tagged, not the tuning data or translation input. However, POS-tagging is still performed for German as input to the pre-processing step. As Figure 1 shows we have two sequence models. A 5-gram language model based on surface form using KneserNey smoothing and in addition a 7-gram sequence model based on POS using Witten-Bell3 smoothing. The training corpus was filtered to sentences with 2–40 words, resulting in</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>A. Stolcke. 2002. SRILM - an extensible language modeling toolkit. In Proceedings of the International Conference on Spoken Language Processing (ICSLP), pages 901–904, Denver, Colorado.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>