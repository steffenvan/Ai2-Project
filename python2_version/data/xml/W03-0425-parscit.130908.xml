<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000122">
<title confidence="0.932893">
Named Entity Recognition through Classifier Combination
</title>
<note confidence="0.470844666666667">
Radu Florian and Abe Ittycheriah and Hongyan Jing and Tong Zhang
IBM T.J. Watson Research Center
1101 Kitchawan Rd, Yorktown Heights, NY 10598, USA
</note>
<email confidence="0.998468">
{raduf,abei,hjing,tzhang}@us.ibm.com
</email>
<sectionHeader confidence="0.995639" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999987642857143">
This paper presents a classifier-combination
experimental framework for named entity
recognition in which four diverse classi-
fiers (robust linear classifier, maximum en-
tropy, transformation-based learning, and hid-
den Markov model) are combined under differ-
ent conditions. When no gazetteer or other ad-
ditional training resources are used, the com-
bined system attains a performance of 91.6F
on the English development data; integrat-
ing name, location and person gazetteers, and
named entity systems trained on additional,
more general, data reduces the F-measure error
by a factor of 15 to 21% on the English data.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999908714285714">
This paper investigates the combination of a set of di-
verse statistical named entity classifiers, including a
rule-based classifier – the transformation-based learning
classifier (Brill, 1995; Florian and Ngai, 2001, hence-
forth fnTBL) with the forward-backward extension de-
scribed in Florian (2002a), a hidden Markov model clas-
sifier (henceforth HMM), similar to the one described
in Bikel et al. (1999), a robust risk minimization classi-
fier, based on a regularized winnow method (Zhang et al.,
2002) (henceforth RRM) and a maximum entropy clas-
sifier (Darroch and Ratcliff, 1972; Berger et al., 1996;
Borthwick, 1999) (henceforth MaxEnt). This particular
set of classifiers is diverse across multiple dimensions,
making it suitable for combination:
</bodyText>
<listItem confidence="0.78561">
• fnTBL is a discriminant classifier – it bases its clas-
sification decision only on the few most discriminant
features active on an example – while HMM, RRM
and MaxEnt are agglomerative classifiers – their de-
cision is based on the combination of all features ac-
tive for the particular example.
• In dealing with the data sparseness problem, fnTBL,
MaxEnt and RRM investigate and integrate in their
</listItem>
<bodyText confidence="0.7882335">
decision arbitrary feature types, while HMM is de-
pendent on a prespecified back-off path.
</bodyText>
<listItem confidence="0.928452692307692">
• The search methods employed by each classifier are
different: the HMM, MaxEnt and RRM classifiers
construct a model for each example and then rely
on a sequence search such as the Viterbi algorithm
(Viterbi, 1967) to identify the best overall sequence,
while fnTBL starts with most frequent classification
(usually per token), and then dynamically models
the interaction between classifications, effectively
performing the search at training time.
• The classifiers also differ in their output: fnTBL
and RRM return a single classification per exam-
ple1, while the MaxEnt and HMM classifiers return
a probability distribution.
</listItem>
<bodyText confidence="0.9998254">
The remainder of the paper is organized as follows: Sec-
tion 2 describes the features used by the classifiers, Sec-
tion 3 briefly describes the algorithms used by each clas-
sifier, and Section 4 analyzes in detail the results obtained
by each classifier and their combination.
</bodyText>
<sectionHeader confidence="0.913887" genericHeader="method">
2 The Classification Method and Features
Used
</sectionHeader>
<bodyText confidence="0.999126466666667">
All algorithms described in this paper identify the named
entities in the text by labeling each word with a tag
corresponding to its position relative to a named entity:
whether it starts/continues/ends a specific named entity,
or does not belong to any entity. RRM, MaxEnt, and
fnTBL treat the problem entirely as a tagging task, while
the HMM algorithm used here is constraining the transi-
tions between the various phases, similar to the method
described in (Bikel et al., 1999).
Feature design and integration is of utmost importance
in the overall classifier design – a rich feature space is the
key to good performance. Often, high performing classi-
fiers operating in an impoverished space are surpassed by
a lower performing classifier when the latter has access
to enhanced feature spaces (Zhang et al., 2002; Florian,
</bodyText>
<footnote confidence="0.7060185">
1 However, both classifiers’ algorithms can be modified such
that a class probability distribution is returned instead.
</footnote>
<bodyText confidence="0.824834666666667">
2002a). In accordance with this observation, the clas-
sifiers used in this research can access a diverse set of
features when examining a word in context, including:
</bodyText>
<listItem confidence="0.992695875">
• words and their lemmas in a 5-word-window sur-
rounding the current word
• the part-of-speech tags of the current and surround-
ing words
• the text chunks in a -1..1 window
• the prefixes and suffixes of length up to 4 of the cur-
rent and the surrounding words
• a word feature flag for each word, similar to the flag
described in (Bikel et al., 1999); examples of such
assigned flags are firstCap, 2digit and allCaps.
• gazetteer information, in the form of a list of 50,000
cities, 80,000 proper names and 3500 organizations
• the output of other two named entity classifiers,
trained on a richer tagset data (32 named categories),
used in the IBM question answering system (Itty-
cheriah et al., 2001)
</listItem>
<bodyText confidence="0.999615">
In addition, a ngram-based capitalization restoration al-
gorithm has been applied on the sentences that appear in
all caps2, for the English task.
</bodyText>
<sectionHeader confidence="0.99101" genericHeader="method">
3 The Algorithms
</sectionHeader>
<bodyText confidence="0.99996125">
This section describes only briefly the classifiers used in
combination in Section 4; a full description of the algo-
rithms and their properties is beyond the scope of this pa-
per – the reader is instead referred to the original articles.
</bodyText>
<subsectionHeader confidence="0.999062">
3.1 The Robust Risk Minimization Classifier
</subsectionHeader>
<bodyText confidence="0.999974">
This classifier is described in detail in (Zhang and John-
son, 2003, this volume), along with a comprehensive
evaluation of its performance, and therefore is not pre-
sented here.
</bodyText>
<subsectionHeader confidence="0.999335">
3.2 The Maximum Entropy Classifier
</subsectionHeader>
<bodyText confidence="0.999920777777778">
The MaxEnt classifier computes the posterior class prob-
ability of an example by evaluating the normalized prod-
uct of the weights active for the particular example. The
model weights are trained using the improved iterative
scaling algorithm (Berger et al., 1996). To avoid running
in severe over-training problems, a feature cutoff of 4 is
applied before the model weights are learned. At decod-
ing time, the best sequence of classifications is identified
with the Viterbi algorithm.
</bodyText>
<subsectionHeader confidence="0.999527">
3.3 The Transformation-Based Learning Classifier
</subsectionHeader>
<bodyText confidence="0.999907">
Transformation-based learning is an error-driven algo-
rithm which has two major steps: it starts by assigning
some classification to each example, and then automat-
ically proposing, evaluating and selecting the classifica-
tion changes that maximally decrease the number of er-
rors.
</bodyText>
<page confidence="0.799203">
2 Usually, document titles, but also table headers, etc.
</page>
<figure confidence="0.655147">
English German
(a) (b) (a) (b)
</figure>
<table confidence="0.830347">
HMM 82.0 74.6 - -
TBL 88.1 81.2 69.5 68.6
MaxEnt 90.8 85.6 68.0 67.3
RRM 92.1 85.5 70.7 71.3
</table>
<tableCaption confidence="0.748258">
Tab. 1: Individual classifier results on the two test sets.
</tableCaption>
<bodyText confidence="0.999920636363636">
TBL has some attractive qualities that make it suitable
for the language-related tasks: it can automatically in-
tegrate heterogeneous types of knowledge, without the
need for explicit modeling, it is error–driven, and has an
inherently dynamic behavior.
The particular setup in which fnTBL is used in this
work is described in Florian (2002a): in a first phase,
TBL is used to identify the entity boundaries, followed by
a sequence classification stage, where the entities identi-
fied at the first step are classified using internal and exter-
nal clues3.
</bodyText>
<subsectionHeader confidence="0.974236">
3.4 The Hidden Markov Model Classifier
</subsectionHeader>
<bodyText confidence="0.9999196">
The HMM classifier used in the experiments in Section
4 follows the system description in (Bikel et al., 1999),
and it performs sequence classification by assigning each
word either one of the named entity types or the label
NOT-A-NAME to represent &amp;quot;not a named entity&amp;quot;. The
states in the HMM are organized into regions, one re-
gion for each type of named entity plus one for NOT-
A-NAME. Within each of the regions, a statistical bi-
gram language model is used to compute the likelihood of
words occurring within that region (named entity type).
The transition probabilities are computed by deleted in-
terpolation (Jelinek, 1997), and the decoding is done
through the Viterbi algorithm. The particular implemen-
tation we used underperformed consistently all the other
classifiers on German, and is not included.
</bodyText>
<sectionHeader confidence="0.9616945" genericHeader="method">
4 Combination Methodology and
Experimental Results
</sectionHeader>
<bodyText confidence="0.987587444444444">
The results obtained by each individual classifier, bro-
ken down by entity type, are presented in Table 1. Out
of the four classifiers, the MaxEnt and RRM classifiers
are the best performers, followed by the modified fnTBL
classifier and the HMM classifier. The error-based clas-
sifiers (RRM and fnTBL) tend to obtain balanced preci-
sion/recall numbers, while the other two tend to be more
precise at the expense of recall. To facilitate comparison
with other classifiers for this task, most reported results
3 The method of retaining only the boundaries and reclas-
sifying the entities was shown to improve the performance of
11 of the 12 systems participating in the CoNLL-2002 shared
tasks, in both languages (Florian, 2002b).
are obtained by using features exclusively extracted from
the training data.
In general, given n classifiers, one can interpret the
classifier combination framework as combining probabil-
ity distributions:
</bodyText>
<equation confidence="0.987475">
P (C|w, Cn1 ) = f ((Pi (C|w, Cn1 ))i=1...n) (1)
</equation>
<bodyText confidence="0.98953825">
where Ci is the classifier i’s classification output, f is
a combination function. A widely used combination
scheme is through linear interpolation of the classifiers’
class probability distribution
</bodyText>
<table confidence="0.999839714285714">
Method Precision Recall Fmeasure
Best Classifier 91.37% 88.56% 89.94
Equal voting 91.5±0.13 91.0±0.06 91.23±0.08
Weighted voting 92.13% 91.00% 91.56
Model 1 90.99% 90.81% 90.9
Model 2 92.43% 90.86% 91.64
RRM (Combo) 92.01% 91.25% 91.63
</table>
<figureCaption confidence="0.466702">
Tab. 2: Classifier combination results on English devset
data (no gazetteers of any kind)
</figureCaption>
<equation confidence="0.956395833333333">
P (C|w, i, Ci) · P (i|w)
P (C|w,Cn1 ) =
n
i=1
Pi (C|w, Ci) · Ai (w) (2)
=
</equation>
<table confidence="0.97528625">
Development Test
Language Unique Corpus Unique Corpus
English 33.4% 8.0% 40.3% 11.7%
German 52% 16.2% 48.6% 14.2%
</table>
<equation confidence="0.442776">
i=1
</equation>
<bodyText confidence="0.994796891891892">
The weights Ai (w) encode the importance given to clas-
sifier i in combination, for the context of word w, and
Pi (C|w, Ci) is an estimation of the probability that the
correct classification is C, given that the output of the
classifier i on word w is Ci.
To estimate the parameters in Equation (2), the pro-
vided training data was split into 5 equal parts, and each
classifier was trained, in a round-robin fashion, on 4 fifths
of the data and applied on the remaining fifth. This
way, the entire training data can be used to estimate the
weight parameters Ai (w) and Pi (C|w, Ci) but, at de-
coding time, the individual classifier outputs Ci are com-
puted by using the entire training data.
Table 2 presents the combination results, for differ-
ent ways of estimating the interpolation parameters. A
simple combination method is the equal voting method
(van Halteren et al., 2001; Tjong Kim Sang et al., 2000),
where the parameters are computed as Ai (w) = 1n and
Pi (C|w, Ci) = S (C, Ci), where S is the Kronecker op-
erator (S (x, y) := (x = y?1 : 0)) – each of the classi-
fiers votes with equal weight for the class that is most
likely under its model, and the class receiving the largest
number of votes wins. However, this procedure may lead
to ties, where some classes receive the same number of
votes – one usually resorts to randomly selecting one of
the tied candidates in this case – Table 2 presents the av-
erage results obtained by this method, together with the
variance obtained over 30 trials. To make the decision de-
terministically, the weights associated with the classifiers
can be chosen as Ai (w) = Pi (error). In this method,
presented in Table 2 as weighted voting, better perform-
ing classifiers will have a higher impact in the final clas-
sification.
In the voting methods, each classifier gave its entire
vote to one class – its own output. However, Equation
(2) allows for classifiers to give partial credit to alterna-
tive classifications, through the probability Pi (C|w, Ci).
</bodyText>
<tableCaption confidence="0.399178">
Tab. 3: Word statistics (percent unknown words)
</tableCaption>
<bodyText confidence="0.994983454545455">
In our experiments, this value is computed through 5-
fold cross-validation on the training data. The space
of possible choices for C, w and Ci is large enough
to make the estimation unreliable, so we use two ap-
proximations, named Model 1 and Model 2 in Table 2:
Pi (C|w, Ci) = Pi (C|w)and Pi (C|w, Ci) = Pi (C|Ci),
respectively. On the development data, the former esti-
mation type obtains a lower performance than the latter.
In a last experiment using only features extracted from
the training data, we use the RRM method to compute
the function f in Equation (1), allowing the system to
select a good performing combination of features. At
training time, the system was fed the output of each clas-
sifier on the cross-classified data, the part-of-speech and
chunk boundary tags. At test time, the system was fed the
classifications of each system trained on the entire train-
ing data, and the corresponding POS and chunk bound-
ary tags. The result obtained rivals the one obtained by
model 2, both displaying a 17% reduction in F-measure
error4, indicating that maybe all sources of information
have been explored and incorporated.
The RRM method is showing its combining power
when additional information sources are used. Specifi-
cally, the system was fed additional feature streams from
a list of gazetteers and the output of two other named en-
tity systems trained on 1.7M words annotated with 32
name categories. The RRM system alone obtains an F-
measure of 92.1, and can effectively integrate these in-
formation streams with the output of the four classifiers,
gazetteers and the two additional classifiers into obtaining
93.9 F-measure, as detailed in Table 4, a 21% reduction
in F-measure error. In contrast, combination model 2 ob-
tains only a performance of 92.4, showing its limitations
</bodyText>
<footnote confidence="0.406899">
4 Measured as 100 − F.
</footnote>
<bodyText confidence="0.9996588">
in combining diverse sources of information.
German poses a completely different problem for
named entity recognition: the data is considerably
sparser. Table 3 shows the relative distribution of un-
known words in the development and test corpora. We
note that the numbers are roughly twice as large for the
development data in German as they are for English.
Since the unknown words are classed by most classifiers,
this results in few data points to estimate classifier com-
binations. Also, specifically for the German data, tradi-
tional approaches which utilize capitalization do not work
as well as in English, because all nouns are capitalized in
German.
For German, in addition to the entity lists provided, we
also used a small gazetteer of names (4500 first and last
names, 4800 locations in Germany and 190 countries),
which was collected by browsing web pages in about two
person-hours. The average classifier performance gain by
using these features is about 1.5F for the testa data and
about .6F for the testb data.
</bodyText>
<sectionHeader confidence="0.998835" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999952333333333">
In conclusion, we have shown results on a set of both
well-established and novel classifier techniques which
improve the overall performance, when compared with
the best performing classifier, by 17-21% on the English
task. For the German task, the improvement yielded by
classifier combination is smaller. As a machine learning
method, the RRM algorithm seems especially suited to
handle additional feature streams, and therefore is a good
candidate for classifier combination.
</bodyText>
<sectionHeader confidence="0.997295" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.988823958333333">
A. Berger, S. Della Pietra, and V. Della Pietra. 1996. A maxi-
mum entropy approach to natural language processing. Com-
putational Linguistics, 22(1):39–71.
Daniel M. Bikel, Richard L. Schwartz, and Ralph M.
Weischedel. 1999. An algorithm that learns what’s in a
name. Machine Learning, 34(1-3):211–231.
A. Borthwick. 1999. A Maximum Entropy Approach to Named
Entity Recognition. Ph.D. thesis, New York University.
E. Brill. 1995. Transformation-based error-driven learning and
natural language processing: A case study in part of speech
tagging. Computational Linguistics, 21(4):543–565.
J. N. Darroch and D. Ratcliff. 1972. Generalized iterative
scaling for log-linear models. The Annals of Mathematical
Statistics, 43(5):1470–1480.
R. Florian and G. Ngai, 2001. Fast Transformation-
Based Learning Toolkit. Johns Hopkins University,
http://nlp.cs.jhu.edu/˜rflorian/fntbl/documentation.html.
R. Florian. 2002a. Named entity recognition as a house of
cards: Classifier stacking. In Proceedings of CoNLL-2002,
pages 175–178.
R. Florian. 2002b. Transformation Based Learning and Data-
Driven Lexical Disambiguation: Syntactic and Semantic
Ambiguity Resolution. Ph.D. thesis, Johns Hopkins Univer-
sity. Chapter 5.3, pages 135–142.
</reference>
<table confidence="0.994949708333333">
English devel. Precision Recall Fβ=1
LOC 96.59% 95.65% 96.12
MISC 90.77% 87.42% 89.06
ORG 90.85% 89.63% 90.24
PER 96.08% 97.12% 96.60
overall 94.26% 93.47% 93.87
English test Precision Recall Fβ=1
LOC 90.59% 91.73% 91.15
MISC 83.46% 77.64% 80.44
ORG 85.93% 83.44% 84.67
PER 92.49% 95.24% 93.85
overall 88.99% 88.54% 88.76
German devel. Precision Recall Fβ=1
LOC 83.19% 72.90% 77.71
MISC 83.20% 42.18% 55.98
ORG 83.64% 61.80% 71.08
PER 87.43% 67.02% 75.88
overall 84.60% 61.93% 71.51
German test Precision Recall Fβ=1
LOC 80.19% 71.59% 75.65
MISC 77.87% 41.49% 54.14
ORG 79.43% 54.46% 64.62
PER 91.93% 75.31% 82.80
overall 83.87% 63.71% 72.41
</table>
<reference confidence="0.992855875">
Tab. 4: Results on the development and test sets in En-
glish and German
Abraham Ittycheriah, Martin Franz, and Salim Roukos. 2001.
IBM’s statistical question answering system – trec-10.
TREC-10 Proceedings, pages 258–264.
F. Jelinek. 1997. Statistical Methods for Speech Recognition.
MIT Press.
E. F. Tjong Kim Sang, W. Daelemans, H. Dejean, R. Koeling,
Y. Krymolowsky, V. Punyakanok, and D. Roth. 2000. Ap-
plying system combination to base noun phrase identifica-
tion. In Proceedings of COLING 2000, pages 857–863.
H. van Halteren, J. Zavrel, and W. Daelemans. 2001. Improv-
ing accuracy in word class tagging through the combination
fo machine learning systems. Computational Linguistics,
27(2):199–230.
A. J. Viterbi. 1967. Error bounds for convolutional codes and an
asymptotically optimum decoding algorithm. IEEE Transac-
tions on Information Theory, IT-13:260–267.
T. Zhang and D. Johnson. 2003. A robust risk minimization
based named entity recognition system. In Proceedings of
CoNLL-2003.
T. Zhang, F. Damerau, and D. Johnson. 2002. Text chunking
based on a generalization of winnow. Journal of Machine
Learning Research, 2:615–637, March.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.940181">
<title confidence="0.999967">Named Entity Recognition through Classifier Combination</title>
<author confidence="0.997689">Florian Ittycheriah Jing</author>
<affiliation confidence="0.998789">IBM T.J. Watson Research</affiliation>
<address confidence="0.974026">1101 Kitchawan Rd, Yorktown Heights, NY 10598,</address>
<email confidence="0.999677">raduf@us.ibm.com</email>
<email confidence="0.999677">abei@us.ibm.com</email>
<email confidence="0.999677">hjing@us.ibm.com</email>
<email confidence="0.999677">tzhang@us.ibm.com</email>
<abstract confidence="0.997444533333333">This paper presents a classifier-combination experimental framework for named entity recognition in which four diverse classifiers (robust linear classifier, maximum entropy, transformation-based learning, and hidden Markov model) are combined under different conditions. When no gazetteer or other additional training resources are used, the combined system attains a performance of 91.6F on the English development data; integrating name, location and person gazetteers, and named entity systems trained on additional, more general, data reduces the F-measure error by a factor of 15 to 21% on the English data.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Berger</author>
<author>S Della Pietra</author>
<author>V Della Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="1479" citStr="Berger et al., 1996" startWordPosition="215" endWordPosition="218">ta. 1 Introduction This paper investigates the combination of a set of diverse statistical named entity classifiers, including a rule-based classifier – the transformation-based learning classifier (Brill, 1995; Florian and Ngai, 2001, henceforth fnTBL) with the forward-backward extension described in Florian (2002a), a hidden Markov model classifier (henceforth HMM), similar to the one described in Bikel et al. (1999), a robust risk minimization classifier, based on a regularized winnow method (Zhang et al., 2002) (henceforth RRM) and a maximum entropy classifier (Darroch and Ratcliff, 1972; Berger et al., 1996; Borthwick, 1999) (henceforth MaxEnt). This particular set of classifiers is diverse across multiple dimensions, making it suitable for combination: • fnTBL is a discriminant classifier – it bases its classification decision only on the few most discriminant features active on an example – while HMM, RRM and MaxEnt are agglomerative classifiers – their decision is based on the combination of all features active for the particular example. • In dealing with the data sparseness problem, fnTBL, MaxEnt and RRM investigate and integrate in their decision arbitrary feature types, while HMM is depen</context>
<context position="5795" citStr="Berger et al., 1996" startWordPosition="917" endWordPosition="920">operties is beyond the scope of this paper – the reader is instead referred to the original articles. 3.1 The Robust Risk Minimization Classifier This classifier is described in detail in (Zhang and Johnson, 2003, this volume), along with a comprehensive evaluation of its performance, and therefore is not presented here. 3.2 The Maximum Entropy Classifier The MaxEnt classifier computes the posterior class probability of an example by evaluating the normalized product of the weights active for the particular example. The model weights are trained using the improved iterative scaling algorithm (Berger et al., 1996). To avoid running in severe over-training problems, a feature cutoff of 4 is applied before the model weights are learned. At decoding time, the best sequence of classifications is identified with the Viterbi algorithm. 3.3 The Transformation-Based Learning Classifier Transformation-based learning is an error-driven algorithm which has two major steps: it starts by assigning some classification to each example, and then automatically proposing, evaluating and selecting the classification changes that maximally decrease the number of errors. 2 Usually, document titles, but also table headers, </context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>A. Berger, S. Della Pietra, and V. Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):39–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel M Bikel</author>
<author>Richard L Schwartz</author>
<author>Ralph M Weischedel</author>
</authors>
<title>An algorithm that learns what’s in a name.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<pages>34--1</pages>
<contexts>
<context position="1282" citStr="Bikel et al. (1999)" startWordPosition="183" endWordPosition="186">ent data; integrating name, location and person gazetteers, and named entity systems trained on additional, more general, data reduces the F-measure error by a factor of 15 to 21% on the English data. 1 Introduction This paper investigates the combination of a set of diverse statistical named entity classifiers, including a rule-based classifier – the transformation-based learning classifier (Brill, 1995; Florian and Ngai, 2001, henceforth fnTBL) with the forward-backward extension described in Florian (2002a), a hidden Markov model classifier (henceforth HMM), similar to the one described in Bikel et al. (1999), a robust risk minimization classifier, based on a regularized winnow method (Zhang et al., 2002) (henceforth RRM) and a maximum entropy classifier (Darroch and Ratcliff, 1972; Berger et al., 1996; Borthwick, 1999) (henceforth MaxEnt). This particular set of classifiers is diverse across multiple dimensions, making it suitable for combination: • fnTBL is a discriminant classifier – it bases its classification decision only on the few most discriminant features active on an example – while HMM, RRM and MaxEnt are agglomerative classifiers – their decision is based on the combination of all fea</context>
<context position="3545" citStr="Bikel et al., 1999" startWordPosition="544" endWordPosition="547"> Section 4 analyzes in detail the results obtained by each classifier and their combination. 2 The Classification Method and Features Used All algorithms described in this paper identify the named entities in the text by labeling each word with a tag corresponding to its position relative to a named entity: whether it starts/continues/ends a specific named entity, or does not belong to any entity. RRM, MaxEnt, and fnTBL treat the problem entirely as a tagging task, while the HMM algorithm used here is constraining the transitions between the various phases, similar to the method described in (Bikel et al., 1999). Feature design and integration is of utmost importance in the overall classifier design – a rich feature space is the key to good performance. Often, high performing classifiers operating in an impoverished space are surpassed by a lower performing classifier when the latter has access to enhanced feature spaces (Zhang et al., 2002; Florian, 1 However, both classifiers’ algorithms can be modified such that a class probability distribution is returned instead. 2002a). In accordance with this observation, the classifiers used in this research can access a diverse set of features when examining</context>
<context position="7285" citStr="Bikel et al., 1999" startWordPosition="1156" endWordPosition="1159">asks: it can automatically integrate heterogeneous types of knowledge, without the need for explicit modeling, it is error–driven, and has an inherently dynamic behavior. The particular setup in which fnTBL is used in this work is described in Florian (2002a): in a first phase, TBL is used to identify the entity boundaries, followed by a sequence classification stage, where the entities identified at the first step are classified using internal and external clues3. 3.4 The Hidden Markov Model Classifier The HMM classifier used in the experiments in Section 4 follows the system description in (Bikel et al., 1999), and it performs sequence classification by assigning each word either one of the named entity types or the label NOT-A-NAME to represent &amp;quot;not a named entity&amp;quot;. The states in the HMM are organized into regions, one region for each type of named entity plus one for NOTA-NAME. Within each of the regions, a statistical bigram language model is used to compute the likelihood of words occurring within that region (named entity type). The transition probabilities are computed by deleted interpolation (Jelinek, 1997), and the decoding is done through the Viterbi algorithm. The particular implementati</context>
</contexts>
<marker>Bikel, Schwartz, Weischedel, 1999</marker>
<rawString>Daniel M. Bikel, Richard L. Schwartz, and Ralph M. Weischedel. 1999. An algorithm that learns what’s in a name. Machine Learning, 34(1-3):211–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Borthwick</author>
</authors>
<title>A Maximum Entropy Approach to Named Entity Recognition.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>New York University.</institution>
<contexts>
<context position="1497" citStr="Borthwick, 1999" startWordPosition="219" endWordPosition="220">is paper investigates the combination of a set of diverse statistical named entity classifiers, including a rule-based classifier – the transformation-based learning classifier (Brill, 1995; Florian and Ngai, 2001, henceforth fnTBL) with the forward-backward extension described in Florian (2002a), a hidden Markov model classifier (henceforth HMM), similar to the one described in Bikel et al. (1999), a robust risk minimization classifier, based on a regularized winnow method (Zhang et al., 2002) (henceforth RRM) and a maximum entropy classifier (Darroch and Ratcliff, 1972; Berger et al., 1996; Borthwick, 1999) (henceforth MaxEnt). This particular set of classifiers is diverse across multiple dimensions, making it suitable for combination: • fnTBL is a discriminant classifier – it bases its classification decision only on the few most discriminant features active on an example – while HMM, RRM and MaxEnt are agglomerative classifiers – their decision is based on the combination of all features active for the particular example. • In dealing with the data sparseness problem, fnTBL, MaxEnt and RRM investigate and integrate in their decision arbitrary feature types, while HMM is dependent on a prespeci</context>
</contexts>
<marker>Borthwick, 1999</marker>
<rawString>A. Borthwick. 1999. A Maximum Entropy Approach to Named Entity Recognition. Ph.D. thesis, New York University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>Transformation-based error-driven learning and natural language processing: A case study in part of speech tagging.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="1070" citStr="Brill, 1995" startWordPosition="151" endWordPosition="152"> hidden Markov model) are combined under different conditions. When no gazetteer or other additional training resources are used, the combined system attains a performance of 91.6F on the English development data; integrating name, location and person gazetteers, and named entity systems trained on additional, more general, data reduces the F-measure error by a factor of 15 to 21% on the English data. 1 Introduction This paper investigates the combination of a set of diverse statistical named entity classifiers, including a rule-based classifier – the transformation-based learning classifier (Brill, 1995; Florian and Ngai, 2001, henceforth fnTBL) with the forward-backward extension described in Florian (2002a), a hidden Markov model classifier (henceforth HMM), similar to the one described in Bikel et al. (1999), a robust risk minimization classifier, based on a regularized winnow method (Zhang et al., 2002) (henceforth RRM) and a maximum entropy classifier (Darroch and Ratcliff, 1972; Berger et al., 1996; Borthwick, 1999) (henceforth MaxEnt). This particular set of classifiers is diverse across multiple dimensions, making it suitable for combination: • fnTBL is a discriminant classifier – it</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>E. Brill. 1995. Transformation-based error-driven learning and natural language processing: A case study in part of speech tagging. Computational Linguistics, 21(4):543–565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J N Darroch</author>
<author>D Ratcliff</author>
</authors>
<title>Generalized iterative scaling for log-linear models.</title>
<date>1972</date>
<journal>The Annals of Mathematical Statistics,</journal>
<volume>43</volume>
<issue>5</issue>
<contexts>
<context position="1458" citStr="Darroch and Ratcliff, 1972" startWordPosition="211" endWordPosition="214"> 15 to 21% on the English data. 1 Introduction This paper investigates the combination of a set of diverse statistical named entity classifiers, including a rule-based classifier – the transformation-based learning classifier (Brill, 1995; Florian and Ngai, 2001, henceforth fnTBL) with the forward-backward extension described in Florian (2002a), a hidden Markov model classifier (henceforth HMM), similar to the one described in Bikel et al. (1999), a robust risk minimization classifier, based on a regularized winnow method (Zhang et al., 2002) (henceforth RRM) and a maximum entropy classifier (Darroch and Ratcliff, 1972; Berger et al., 1996; Borthwick, 1999) (henceforth MaxEnt). This particular set of classifiers is diverse across multiple dimensions, making it suitable for combination: • fnTBL is a discriminant classifier – it bases its classification decision only on the few most discriminant features active on an example – while HMM, RRM and MaxEnt are agglomerative classifiers – their decision is based on the combination of all features active for the particular example. • In dealing with the data sparseness problem, fnTBL, MaxEnt and RRM investigate and integrate in their decision arbitrary feature type</context>
</contexts>
<marker>Darroch, Ratcliff, 1972</marker>
<rawString>J. N. Darroch and D. Ratcliff. 1972. Generalized iterative scaling for log-linear models. The Annals of Mathematical Statistics, 43(5):1470–1480.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Florian</author>
<author>G Ngai</author>
</authors>
<date>2001</date>
<institution>Fast TransformationBased Learning Toolkit. Johns Hopkins University,</institution>
<note>http://nlp.cs.jhu.edu/˜rflorian/fntbl/documentation.html.</note>
<contexts>
<context position="1094" citStr="Florian and Ngai, 2001" startWordPosition="153" endWordPosition="156">v model) are combined under different conditions. When no gazetteer or other additional training resources are used, the combined system attains a performance of 91.6F on the English development data; integrating name, location and person gazetteers, and named entity systems trained on additional, more general, data reduces the F-measure error by a factor of 15 to 21% on the English data. 1 Introduction This paper investigates the combination of a set of diverse statistical named entity classifiers, including a rule-based classifier – the transformation-based learning classifier (Brill, 1995; Florian and Ngai, 2001, henceforth fnTBL) with the forward-backward extension described in Florian (2002a), a hidden Markov model classifier (henceforth HMM), similar to the one described in Bikel et al. (1999), a robust risk minimization classifier, based on a regularized winnow method (Zhang et al., 2002) (henceforth RRM) and a maximum entropy classifier (Darroch and Ratcliff, 1972; Berger et al., 1996; Borthwick, 1999) (henceforth MaxEnt). This particular set of classifiers is diverse across multiple dimensions, making it suitable for combination: • fnTBL is a discriminant classifier – it bases its classificatio</context>
</contexts>
<marker>Florian, Ngai, 2001</marker>
<rawString>R. Florian and G. Ngai, 2001. Fast TransformationBased Learning Toolkit. Johns Hopkins University, http://nlp.cs.jhu.edu/˜rflorian/fntbl/documentation.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Florian</author>
</authors>
<title>Named entity recognition as a house of cards: Classifier stacking.</title>
<date>2002</date>
<booktitle>In Proceedings of CoNLL-2002,</booktitle>
<pages>175--178</pages>
<contexts>
<context position="1176" citStr="Florian (2002" startWordPosition="167" endWordPosition="168">ining resources are used, the combined system attains a performance of 91.6F on the English development data; integrating name, location and person gazetteers, and named entity systems trained on additional, more general, data reduces the F-measure error by a factor of 15 to 21% on the English data. 1 Introduction This paper investigates the combination of a set of diverse statistical named entity classifiers, including a rule-based classifier – the transformation-based learning classifier (Brill, 1995; Florian and Ngai, 2001, henceforth fnTBL) with the forward-backward extension described in Florian (2002a), a hidden Markov model classifier (henceforth HMM), similar to the one described in Bikel et al. (1999), a robust risk minimization classifier, based on a regularized winnow method (Zhang et al., 2002) (henceforth RRM) and a maximum entropy classifier (Darroch and Ratcliff, 1972; Berger et al., 1996; Borthwick, 1999) (henceforth MaxEnt). This particular set of classifiers is diverse across multiple dimensions, making it suitable for combination: • fnTBL is a discriminant classifier – it bases its classification decision only on the few most discriminant features active on an example – while</context>
<context position="6923" citStr="Florian (2002" startWordPosition="1098" endWordPosition="1099">y decrease the number of errors. 2 Usually, document titles, but also table headers, etc. English German (a) (b) (a) (b) HMM 82.0 74.6 - - TBL 88.1 81.2 69.5 68.6 MaxEnt 90.8 85.6 68.0 67.3 RRM 92.1 85.5 70.7 71.3 Tab. 1: Individual classifier results on the two test sets. TBL has some attractive qualities that make it suitable for the language-related tasks: it can automatically integrate heterogeneous types of knowledge, without the need for explicit modeling, it is error–driven, and has an inherently dynamic behavior. The particular setup in which fnTBL is used in this work is described in Florian (2002a): in a first phase, TBL is used to identify the entity boundaries, followed by a sequence classification stage, where the entities identified at the first step are classified using internal and external clues3. 3.4 The Hidden Markov Model Classifier The HMM classifier used in the experiments in Section 4 follows the system description in (Bikel et al., 1999), and it performs sequence classification by assigning each word either one of the named entity types or the label NOT-A-NAME to represent &amp;quot;not a named entity&amp;quot;. The states in the HMM are organized into regions, one region for each type of</context>
<context position="8755" citStr="Florian, 2002" startWordPosition="1395" endWordPosition="1396"> of the four classifiers, the MaxEnt and RRM classifiers are the best performers, followed by the modified fnTBL classifier and the HMM classifier. The error-based classifiers (RRM and fnTBL) tend to obtain balanced precision/recall numbers, while the other two tend to be more precise at the expense of recall. To facilitate comparison with other classifiers for this task, most reported results 3 The method of retaining only the boundaries and reclassifying the entities was shown to improve the performance of 11 of the 12 systems participating in the CoNLL-2002 shared tasks, in both languages (Florian, 2002b). are obtained by using features exclusively extracted from the training data. In general, given n classifiers, one can interpret the classifier combination framework as combining probability distributions: P (C|w, Cn1 ) = f ((Pi (C|w, Cn1 ))i=1...n) (1) where Ci is the classifier i’s classification output, f is a combination function. A widely used combination scheme is through linear interpolation of the classifiers’ class probability distribution Method Precision Recall Fmeasure Best Classifier 91.37% 88.56% 89.94 Equal voting 91.5±0.13 91.0±0.06 91.23±0.08 Weighted voting 92.13% 91.00% 9</context>
</contexts>
<marker>Florian, 2002</marker>
<rawString>R. Florian. 2002a. Named entity recognition as a house of cards: Classifier stacking. In Proceedings of CoNLL-2002, pages 175–178.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Florian</author>
</authors>
<title>Transformation Based Learning and DataDriven Lexical Disambiguation: Syntactic and Semantic Ambiguity Resolution.</title>
<date>2002</date>
<journal>Chapter</journal>
<tech>Ph.D. thesis,</tech>
<volume>5</volume>
<pages>135--142</pages>
<institution>Johns Hopkins University.</institution>
<contexts>
<context position="1176" citStr="Florian (2002" startWordPosition="167" endWordPosition="168">ining resources are used, the combined system attains a performance of 91.6F on the English development data; integrating name, location and person gazetteers, and named entity systems trained on additional, more general, data reduces the F-measure error by a factor of 15 to 21% on the English data. 1 Introduction This paper investigates the combination of a set of diverse statistical named entity classifiers, including a rule-based classifier – the transformation-based learning classifier (Brill, 1995; Florian and Ngai, 2001, henceforth fnTBL) with the forward-backward extension described in Florian (2002a), a hidden Markov model classifier (henceforth HMM), similar to the one described in Bikel et al. (1999), a robust risk minimization classifier, based on a regularized winnow method (Zhang et al., 2002) (henceforth RRM) and a maximum entropy classifier (Darroch and Ratcliff, 1972; Berger et al., 1996; Borthwick, 1999) (henceforth MaxEnt). This particular set of classifiers is diverse across multiple dimensions, making it suitable for combination: • fnTBL is a discriminant classifier – it bases its classification decision only on the few most discriminant features active on an example – while</context>
<context position="6923" citStr="Florian (2002" startWordPosition="1098" endWordPosition="1099">y decrease the number of errors. 2 Usually, document titles, but also table headers, etc. English German (a) (b) (a) (b) HMM 82.0 74.6 - - TBL 88.1 81.2 69.5 68.6 MaxEnt 90.8 85.6 68.0 67.3 RRM 92.1 85.5 70.7 71.3 Tab. 1: Individual classifier results on the two test sets. TBL has some attractive qualities that make it suitable for the language-related tasks: it can automatically integrate heterogeneous types of knowledge, without the need for explicit modeling, it is error–driven, and has an inherently dynamic behavior. The particular setup in which fnTBL is used in this work is described in Florian (2002a): in a first phase, TBL is used to identify the entity boundaries, followed by a sequence classification stage, where the entities identified at the first step are classified using internal and external clues3. 3.4 The Hidden Markov Model Classifier The HMM classifier used in the experiments in Section 4 follows the system description in (Bikel et al., 1999), and it performs sequence classification by assigning each word either one of the named entity types or the label NOT-A-NAME to represent &amp;quot;not a named entity&amp;quot;. The states in the HMM are organized into regions, one region for each type of</context>
<context position="8755" citStr="Florian, 2002" startWordPosition="1395" endWordPosition="1396"> of the four classifiers, the MaxEnt and RRM classifiers are the best performers, followed by the modified fnTBL classifier and the HMM classifier. The error-based classifiers (RRM and fnTBL) tend to obtain balanced precision/recall numbers, while the other two tend to be more precise at the expense of recall. To facilitate comparison with other classifiers for this task, most reported results 3 The method of retaining only the boundaries and reclassifying the entities was shown to improve the performance of 11 of the 12 systems participating in the CoNLL-2002 shared tasks, in both languages (Florian, 2002b). are obtained by using features exclusively extracted from the training data. In general, given n classifiers, one can interpret the classifier combination framework as combining probability distributions: P (C|w, Cn1 ) = f ((Pi (C|w, Cn1 ))i=1...n) (1) where Ci is the classifier i’s classification output, f is a combination function. A widely used combination scheme is through linear interpolation of the classifiers’ class probability distribution Method Precision Recall Fmeasure Best Classifier 91.37% 88.56% 89.94 Equal voting 91.5±0.13 91.0±0.06 91.23±0.08 Weighted voting 92.13% 91.00% 9</context>
</contexts>
<marker>Florian, 2002</marker>
<rawString>R. Florian. 2002b. Transformation Based Learning and DataDriven Lexical Disambiguation: Syntactic and Semantic Ambiguity Resolution. Ph.D. thesis, Johns Hopkins University. Chapter 5.3, pages 135–142.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Tab</author>
</authors>
<title>4: Results on the development and test sets in English and German</title>
<marker>Tab, </marker>
<rawString>Tab. 4: Results on the development and test sets in English and German</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abraham Ittycheriah</author>
<author>Martin Franz</author>
<author>Salim Roukos</author>
</authors>
<title>IBM’s statistical question answering system –</title>
<date>2001</date>
<booktitle>trec-10. TREC-10 Proceedings,</booktitle>
<pages>258--264</pages>
<contexts>
<context position="4876" citStr="Ittycheriah et al., 2001" startWordPosition="768" endWordPosition="772">the part-of-speech tags of the current and surrounding words • the text chunks in a -1..1 window • the prefixes and suffixes of length up to 4 of the current and the surrounding words • a word feature flag for each word, similar to the flag described in (Bikel et al., 1999); examples of such assigned flags are firstCap, 2digit and allCaps. • gazetteer information, in the form of a list of 50,000 cities, 80,000 proper names and 3500 organizations • the output of other two named entity classifiers, trained on a richer tagset data (32 named categories), used in the IBM question answering system (Ittycheriah et al., 2001) In addition, a ngram-based capitalization restoration algorithm has been applied on the sentences that appear in all caps2, for the English task. 3 The Algorithms This section describes only briefly the classifiers used in combination in Section 4; a full description of the algorithms and their properties is beyond the scope of this paper – the reader is instead referred to the original articles. 3.1 The Robust Risk Minimization Classifier This classifier is described in detail in (Zhang and Johnson, 2003, this volume), along with a comprehensive evaluation of its performance, and therefore i</context>
</contexts>
<marker>Ittycheriah, Franz, Roukos, 2001</marker>
<rawString>Abraham Ittycheriah, Martin Franz, and Salim Roukos. 2001. IBM’s statistical question answering system – trec-10. TREC-10 Proceedings, pages 258–264.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Jelinek</author>
</authors>
<title>Statistical Methods for Speech Recognition.</title>
<date>1997</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="7800" citStr="Jelinek, 1997" startWordPosition="1244" endWordPosition="1245">ssifier used in the experiments in Section 4 follows the system description in (Bikel et al., 1999), and it performs sequence classification by assigning each word either one of the named entity types or the label NOT-A-NAME to represent &amp;quot;not a named entity&amp;quot;. The states in the HMM are organized into regions, one region for each type of named entity plus one for NOTA-NAME. Within each of the regions, a statistical bigram language model is used to compute the likelihood of words occurring within that region (named entity type). The transition probabilities are computed by deleted interpolation (Jelinek, 1997), and the decoding is done through the Viterbi algorithm. The particular implementation we used underperformed consistently all the other classifiers on German, and is not included. 4 Combination Methodology and Experimental Results The results obtained by each individual classifier, broken down by entity type, are presented in Table 1. Out of the four classifiers, the MaxEnt and RRM classifiers are the best performers, followed by the modified fnTBL classifier and the HMM classifier. The error-based classifiers (RRM and fnTBL) tend to obtain balanced precision/recall numbers, while the other </context>
</contexts>
<marker>Jelinek, 1997</marker>
<rawString>F. Jelinek. 1997. Statistical Methods for Speech Recognition. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E F Tjong Kim Sang</author>
<author>W Daelemans</author>
<author>H Dejean</author>
<author>R Koeling</author>
<author>Y Krymolowsky</author>
<author>V Punyakanok</author>
<author>D Roth</author>
</authors>
<title>Applying system combination to base noun phrase identification.</title>
<date>2000</date>
<booktitle>In Proceedings of COLING</booktitle>
<pages>857--863</pages>
<contexts>
<context position="10634" citStr="Sang et al., 2000" startWordPosition="1709" endWordPosition="1712">quation (2), the provided training data was split into 5 equal parts, and each classifier was trained, in a round-robin fashion, on 4 fifths of the data and applied on the remaining fifth. This way, the entire training data can be used to estimate the weight parameters Ai (w) and Pi (C|w, Ci) but, at decoding time, the individual classifier outputs Ci are computed by using the entire training data. Table 2 presents the combination results, for different ways of estimating the interpolation parameters. A simple combination method is the equal voting method (van Halteren et al., 2001; Tjong Kim Sang et al., 2000), where the parameters are computed as Ai (w) = 1n and Pi (C|w, Ci) = S (C, Ci), where S is the Kronecker operator (S (x, y) := (x = y?1 : 0)) – each of the classifiers votes with equal weight for the class that is most likely under its model, and the class receiving the largest number of votes wins. However, this procedure may lead to ties, where some classes receive the same number of votes – one usually resorts to randomly selecting one of the tied candidates in this case – Table 2 presents the average results obtained by this method, together with the variance obtained over 30 trials. To m</context>
</contexts>
<marker>Sang, Daelemans, Dejean, Koeling, Krymolowsky, Punyakanok, Roth, 2000</marker>
<rawString>E. F. Tjong Kim Sang, W. Daelemans, H. Dejean, R. Koeling, Y. Krymolowsky, V. Punyakanok, and D. Roth. 2000. Applying system combination to base noun phrase identification. In Proceedings of COLING 2000, pages 857–863.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H van Halteren</author>
<author>J Zavrel</author>
<author>W Daelemans</author>
</authors>
<title>Improving accuracy in word class tagging through the combination fo machine learning systems.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>2</issue>
<marker>van Halteren, Zavrel, Daelemans, 2001</marker>
<rawString>H. van Halteren, J. Zavrel, and W. Daelemans. 2001. Improving accuracy in word class tagging through the combination fo machine learning systems. Computational Linguistics, 27(2):199–230.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A J Viterbi</author>
</authors>
<title>Error bounds for convolutional codes and an asymptotically optimum decoding algorithm.</title>
<date>1967</date>
<journal>IEEE Transactions on Information Theory,</journal>
<pages>13--260</pages>
<contexts>
<context position="2332" citStr="Viterbi, 1967" startWordPosition="354" endWordPosition="355">ew most discriminant features active on an example – while HMM, RRM and MaxEnt are agglomerative classifiers – their decision is based on the combination of all features active for the particular example. • In dealing with the data sparseness problem, fnTBL, MaxEnt and RRM investigate and integrate in their decision arbitrary feature types, while HMM is dependent on a prespecified back-off path. • The search methods employed by each classifier are different: the HMM, MaxEnt and RRM classifiers construct a model for each example and then rely on a sequence search such as the Viterbi algorithm (Viterbi, 1967) to identify the best overall sequence, while fnTBL starts with most frequent classification (usually per token), and then dynamically models the interaction between classifications, effectively performing the search at training time. • The classifiers also differ in their output: fnTBL and RRM return a single classification per example1, while the MaxEnt and HMM classifiers return a probability distribution. The remainder of the paper is organized as follows: Section 2 describes the features used by the classifiers, Section 3 briefly describes the algorithms used by each classifier, and Secti</context>
</contexts>
<marker>Viterbi, 1967</marker>
<rawString>A. J. Viterbi. 1967. Error bounds for convolutional codes and an asymptotically optimum decoding algorithm. IEEE Transactions on Information Theory, IT-13:260–267.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Zhang</author>
<author>D Johnson</author>
</authors>
<title>A robust risk minimization based named entity recognition system.</title>
<date>2003</date>
<booktitle>In Proceedings of CoNLL-2003.</booktitle>
<contexts>
<context position="5387" citStr="Zhang and Johnson, 2003" startWordPosition="853" endWordPosition="857">a richer tagset data (32 named categories), used in the IBM question answering system (Ittycheriah et al., 2001) In addition, a ngram-based capitalization restoration algorithm has been applied on the sentences that appear in all caps2, for the English task. 3 The Algorithms This section describes only briefly the classifiers used in combination in Section 4; a full description of the algorithms and their properties is beyond the scope of this paper – the reader is instead referred to the original articles. 3.1 The Robust Risk Minimization Classifier This classifier is described in detail in (Zhang and Johnson, 2003, this volume), along with a comprehensive evaluation of its performance, and therefore is not presented here. 3.2 The Maximum Entropy Classifier The MaxEnt classifier computes the posterior class probability of an example by evaluating the normalized product of the weights active for the particular example. The model weights are trained using the improved iterative scaling algorithm (Berger et al., 1996). To avoid running in severe over-training problems, a feature cutoff of 4 is applied before the model weights are learned. At decoding time, the best sequence of classifications is identified</context>
</contexts>
<marker>Zhang, Johnson, 2003</marker>
<rawString>T. Zhang and D. Johnson. 2003. A robust risk minimization based named entity recognition system. In Proceedings of CoNLL-2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Zhang</author>
<author>F Damerau</author>
<author>D Johnson</author>
</authors>
<title>Text chunking based on a generalization of winnow.</title>
<date>2002</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>2--615</pages>
<contexts>
<context position="1380" citStr="Zhang et al., 2002" startWordPosition="199" endWordPosition="202">ditional, more general, data reduces the F-measure error by a factor of 15 to 21% on the English data. 1 Introduction This paper investigates the combination of a set of diverse statistical named entity classifiers, including a rule-based classifier – the transformation-based learning classifier (Brill, 1995; Florian and Ngai, 2001, henceforth fnTBL) with the forward-backward extension described in Florian (2002a), a hidden Markov model classifier (henceforth HMM), similar to the one described in Bikel et al. (1999), a robust risk minimization classifier, based on a regularized winnow method (Zhang et al., 2002) (henceforth RRM) and a maximum entropy classifier (Darroch and Ratcliff, 1972; Berger et al., 1996; Borthwick, 1999) (henceforth MaxEnt). This particular set of classifiers is diverse across multiple dimensions, making it suitable for combination: • fnTBL is a discriminant classifier – it bases its classification decision only on the few most discriminant features active on an example – while HMM, RRM and MaxEnt are agglomerative classifiers – their decision is based on the combination of all features active for the particular example. • In dealing with the data sparseness problem, fnTBL, Max</context>
<context position="3880" citStr="Zhang et al., 2002" startWordPosition="598" endWordPosition="601">/ends a specific named entity, or does not belong to any entity. RRM, MaxEnt, and fnTBL treat the problem entirely as a tagging task, while the HMM algorithm used here is constraining the transitions between the various phases, similar to the method described in (Bikel et al., 1999). Feature design and integration is of utmost importance in the overall classifier design – a rich feature space is the key to good performance. Often, high performing classifiers operating in an impoverished space are surpassed by a lower performing classifier when the latter has access to enhanced feature spaces (Zhang et al., 2002; Florian, 1 However, both classifiers’ algorithms can be modified such that a class probability distribution is returned instead. 2002a). In accordance with this observation, the classifiers used in this research can access a diverse set of features when examining a word in context, including: • words and their lemmas in a 5-word-window surrounding the current word • the part-of-speech tags of the current and surrounding words • the text chunks in a -1..1 window • the prefixes and suffixes of length up to 4 of the current and the surrounding words • a word feature flag for each word, similar </context>
</contexts>
<marker>Zhang, Damerau, Johnson, 2002</marker>
<rawString>T. Zhang, F. Damerau, and D. Johnson. 2002. Text chunking based on a generalization of winnow. Journal of Machine Learning Research, 2:615–637, March.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>