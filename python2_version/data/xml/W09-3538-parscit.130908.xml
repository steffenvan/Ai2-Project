<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000525">
<title confidence="0.973289">
Czech Named Entity Corpus and SVM-based Recognizer
</title>
<author confidence="0.993657">
Jana Kravalov´a
</author>
<affiliation confidence="0.978087">
Charles University in Prague
Institute of Formal and Applied Linguistics
</affiliation>
<email confidence="0.964178">
kravalova@ufal.mff.cuni.cz
</email>
<author confidence="0.587666">
Zdenˇek ˇZabokrtsk´y
</author>
<affiliation confidence="0.5755385">
Charles University in Prague
Institute of Formal and Applied Linguistics
</affiliation>
<email confidence="0.965581">
zabokrtsky@ufal.mff.cuni.cz
</email>
<sectionHeader confidence="0.993107" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999895214285714">
This paper deals with recognition of
named entities in Czech texts. We present
a recently released corpus of Czech sen-
tences with manually annotated named en-
tities, in which a rich two-level classifica-
tion scheme was used. There are around
6000 sentences in the corpus with roughly
33000 marked named entity instances. We
use the data for training and evaluating a
named entity recognizer based on Support
Vector Machine classification technique.
The presented recognizer outperforms the
results previously reported for NE recog-
nition in Czech.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99991728125">
After the series of Message Understanding
Conferences (MUC; (Grishman and Sundheim,
1996)), processing of named entities (NEs) be-
came a well established discipline within the NLP
domain, usually motivated by the needs of Infor-
mation Extraction, Question Answering, or Ma-
chine Translation. For English, one can find liter-
ature about attempts at rule-based solutions for the
NE task as well as machine-learning approaches,
be they dependent on the existence of labeled data
(such as CoNLL-2003 shared task data), unsuper-
vised (using redundancy in NE expressions and
their contexts, see e.g. (Collins and Singer, 1999))
or a combination of both (such as (Talukdar et al.,
2006), in which labeled data are used as a source
of seed for an unsupervised procedure exploiting
huge unlabeled data). A survey of research on
named entity recognition is available in (Ekbal and
Bandyopadhyay, 2008).
There has been considerably less research
done in the NE field in Czech, as discussed in
(ˇSevˇcikov´a et al., 2007b). Therefore we focus on
it in this paper, which is structured as follows. In
Section 2 we present a recently released corpus
of Czech sentences with manually annotated in-
stances of named entities, in which a rich classi-
fication scheme is used. In Section 3 we describe
a new NE recognizer developed for Czech, based
on the Support Vector Machine (SVM) classifi-
cation technique. Evaluation of such approach is
presented in Section 4. The summary is given in
Section 5.
</bodyText>
<sectionHeader confidence="0.982839" genericHeader="method">
2 Manually Annotated Corpus
</sectionHeader>
<subsectionHeader confidence="0.941661">
2.1 Data Selection
</subsectionHeader>
<bodyText confidence="0.999935">
We have randomly selected 6000 sentences
from the Czech National Corpus1 from the re-
sult of the query ([word=&amp;quot;.*[a-z0-9]&amp;quot;]
[word=&amp;quot;[A-Z].*&amp;quot;]). This query makes the
relative frequency of NEs in the selection higher
than the corpus average, which makes the sub-
sequent manual annotation much more effective,
even if it may slightly bias the distribution of NE
types and their observed density.2
</bodyText>
<subsectionHeader confidence="0.899187">
2.2 Annotation NE Instances with Two-level
NE Classification
</subsectionHeader>
<bodyText confidence="0.999616272727273">
There is no generally accepted typology of Named
Entities. One can see two trends: from the view-
point of unsupervised learning, it is advantageous
to have just a few coarse-grained categories (cf.
the NE classification developed for MUC confer-
ences or the classification proposed in (Collins
and Singer, 1999), where only persons, locations,
and organizations were distinguished), whereas
those interested in semantically oriented applica-
tions prefer more informative (finer-grained) cat-
egories (e.g. (Fleischman and Hovy, 2002) with
</bodyText>
<footnote confidence="0.999147">
1http://ucnk.ff.cuni.cz
2The query is trivially motivated by the fact that NEs in
Czech (as well as in many other languages) are often marked
by capitalization of the first letter. Annotation of NEs in a cor-
pus without such selection would lower the bias, but would
be more expensive due to the lower density of NE instances
in the annotated material.
</footnote>
<page confidence="0.923329">
194
</page>
<note confidence="0.9891255">
Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 194–201,
Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP
</note>
<figure confidence="0.60524337037037">
Types of NE
q - Quantitative expressions
n - Specific number usages
a - Numbers in addresses
g - Geographical names
c - Bibliographic items
t - Time expressions
p - Personal names
m - Media names
o - Artifact names
i - Institutions
oa - cultural artifacts (books, movies)
if - companies, concerns...
np - part of personal name
gl - nature areas / objects
ia - conferences/contests
qc - cardinal numbers
cb - volume numbers
pd - (academic) titles
gs - streets, squares
pm - second names
ah - street numbers
o_ - underspecified
n_ - underspecified
oe - measure units
pb - animal names
cp - page numbers
</figure>
<equation confidence="0.848223934782609">
i_ - underspecified
mr - radio stations
mi - internet links
gu - cities/towns
gq - urban parts
cs - article titles
ps - surnames
az - zip codes
op - products
tc - centuries
tm - months
ni - itemizer
gc - states
gh - hydronyms
tf - feasts
na - age
nr - ratio
io - government/political inst.
cn - chapt./sect./fig. numbers
gp - planets, cosmic objects
ic - cult./educ./scient. inst.
pp - relig./myth persons
at - phone/fax numbers
cr - legisl. act numbers
pc - inhabitant names
or - directives, norms
qo - ordinal numbers
gr - territorial names
g_ - underspecified
om - currency units
p_ - underspecified
nq - town quarter
mt - TV stations
nm - in formula
nc - sport score
mn - periodical
pf - first names
gt - continents
oc - chemical
nw - flat size
tn - minutes
th - hours
td - days
tp - epochs
ts - seconds
ty - years
</equation>
<figureCaption confidence="0.984704">
Figure 1: Two-level hierarchical classification of NEs used in the corpus. Note that the (detailed) NE
types are divided into two columns just because of the space reasons here.
</figureCaption>
<page confidence="0.993265">
195
</page>
<bodyText confidence="0.99794472">
eight types of person labels, or Sekine’s Extended
NE Hierarchy, cf. (Sekine, 2003)).
In our corpus, we use a two-level NE classifi-
cation depicted in Figure 1. The first level corre-
sponds to rough categories (called NE supertypes)
such as person names, geographical names etc.
The second level provides a more detailed classi-
fication: e.g. within the supertype of geographi-
cal names, the NE types of names of cities/towns,
names of states, names of rivers/seas/lakes etc.
are distinguished.3 If more robust processing is
necessary, only the first level (NE supertypes)
can be used, while the second level (NE types)
comes into play when more subtle information is
needed. Each NE type is encoded by a unique two-
character tag (e.g., gu for names of cities/towns,
gc for names of states; a special tag, such as g ,
makes it possible to leave the NE type underspec-
ified).
Besides the terms of NE type and supertype, we
use also the term NE instance, which stands for a
continuous subsequence of tokens expressing the
entity in a given text. In the simple plain-text for-
mat, which we use for manual annotations, the NE
instances are marked as follows: the word or the
span of words belonging to the NE is delimited by
symbols &lt; and &gt;, with the former one immediately
followed by the NE type tag (e.g. &lt;pf John&gt; loves
&lt;pf Mary&gt;).
The annotation scheme allows for the embed-
ding of NE instances. There are two types of em-
bedding. In the first case, the NE of a certain
type can be embedded in another NE (e.g., the
river name can be part of a name of a city as in
&lt;gu ´Ust´ı nad &lt;gh Labem&gt;&gt;). In the second case,
two or more NEs are parts of a (so-called) con-
tainer NE (e.g., two NEs, a first name and a sur-
name, form together a person name container NE
such as in &lt;P&lt;pf Paul&gt; &lt;ps Newman&gt;&gt;). The
container NEs are marked with a capital one-letter
tag: P for (complex) person names, T for tempo-
ral expressions, A for addresses, and C for biblio-
graphic items. A more detailed description of the
NE classification can be found in (ˇSevˇc´ıkov´a et al.,
2007b).
3Given the size of the annotated data, further subdivi-
sion into even finer classes (such as persons divided into cat-
egories such as lawyer, politician, scientist used in (Fleis-
chman and Hovy, 2002)) would result in too sparse annota-
tions.
</bodyText>
<subsectionHeader confidence="0.998255">
2.3 Annotated Data Cleaning
</subsectionHeader>
<bodyText confidence="0.99998475">
After collecting all the sentences annotated by the
annotators, it was necessary to clean the data in or-
der to improve the data quality. For this purpose,
a set of tests was implemented. The tests revealed
wrong or “suspicious” spots in the data (based e.g.
on the assumption that the same lemma should
manifest an entity of the same type in most its oc-
currences), which were manually checked and cor-
rected if necessary. Some noisy sentences caused
e.g. by wrong sentence segmentation in the origi-
nal resource were deleted; the final size of the cor-
pus is 5870 sentences.
</bodyText>
<subsectionHeader confidence="0.99327">
2.4 Morphological Analysis of Annotated
Data
</subsectionHeader>
<bodyText confidence="0.999981833333333">
The sentences have been enriched with morpho-
logical tags and lemmas using Jan Hajiˇc’s tagger
shipped with Prague Dependency Treebank 2.0
(Hajiˇc et al., 2006) integrated into the TectoMT
environment (ˇZabokrtsk´y et al., 2008). Motivation
for this step was twofold
</bodyText>
<listItem confidence="0.973504071428571">
• Czech is a morphologically rich language,
and named entities might be subject to
paradigms with rich inflection too. For
example, male first name Tom´aˇs (Thomas)
migh appear also in one of the following
forms: Tom´aˇse, Tom´aˇsovi, Tom´aˇsi, Tom´aˇsem,
Tom´aˇsov´e, Tom´aˇs˚um ... (according to gram-
matical case and number), which would make
the training data without lemmatization much
sparser.
• Additional features (useful for SVM as well
as for any other Machine Learning approach)
can be mined from the lemma and tag se-
quences, as shown in Section 3.2.
</listItem>
<subsectionHeader confidence="0.969299">
2.5 Public Data Release
</subsectionHeader>
<bodyText confidence="0.999892">
Manually annotated and cleaned 6000 sentences
with roughly 33000 named entities were released
as Czech Named Entity Corpus 1.0. The corpus
consists of manually annotated sentences and mor-
phological analysis in several formats: a simple
plain text format, a simple xml format, a more
complex xml format based on the Prague Markup
Language (Pajas and ˇStˇep´anek, 2006) and contain-
ing also the above mentioned morphological anal-
ysis, and the html format with visually highlighted
NE instances.
For the purposes of supervised machine learn-
ing, division of data into training, development
</bodyText>
<page confidence="0.995748">
196
</page>
<bodyText confidence="0.999325454545455">
and evaluation subset is provided in the corpus.
The division into training, development and evalu-
ation subsets was made by random division of sen-
tences into three sets, in proportion 80% (training),
10% (development) and 10% (evaluation), see Ta-
ble 1. Other basic quantitative properties are sum-
marized in Table 2 and Table 3.
The resulting data collection, called
Czech Named Entity Corpus 1.0, is
now publicly available on the Internet at
http://ufal.mff.cuni.cz/tectomt.
</bodyText>
<table confidence="0.9981634">
Set #Sentences #Words #NE instances
train 4696 119921 26491
dtest 587 14982 3476
etest 587 15119 3615
total 5870 150022 33582
</table>
<tableCaption confidence="0.984462">
Table 1: Division of the annotated corpus into
training, development test, and evaluation test sets.
</tableCaption>
<table confidence="0.999983411764706">
NE type #Occurrences Proportion
ps 4040 12.03%
pf 3072 9.15%
P 2722 8.11%
gu 2685 8.00%
qc 2040 6.07%
oa 1695 5.05%
ic 1410 4.20%
ty 1325 3.95%
th 1325 3.95%
s 1285 3.83%
gc 1107 3.30%
if 834 2.48%
io 830 2.47%
tm 559 1.66%
n 512 1.52%
f 506 1.51%
</table>
<tableCaption confidence="0.9976395">
Table 3: Distribution of several most frequent NE
types in the annotated corpus.
</tableCaption>
<table confidence="0.999760333333333">
Lenght #Occurrences Proportion
one-word 23057 68.66%
two-word 6885 20.50%
three-word 1961 5.84%
longer 1679 5.00%
total 33582 100.00%
</table>
<tableCaption confidence="0.95145">
Table 2: Occurrences of NE instances of different
length in the annotated corpus.
</tableCaption>
<sectionHeader confidence="0.987091" genericHeader="method">
3 SVM-based Recognizer
</sectionHeader>
<subsectionHeader confidence="0.984272">
3.1 NER as a classification task
</subsectionHeader>
<bodyText confidence="0.99972">
In this section, we formulate named entity recog-
nition as a classification problem. The task of
named entity recognition as a whole includes sev-
eral problems to be solved:
</bodyText>
<listItem confidence="0.935388714285714">
• detecting “basic” one-word, two-word and
multiword named entities,
• detecting complex entities containing other
entities (e.g. an institution name containing
a personal name).
Furthermore, one can have different require-
ments on what a correctly recognized named entity
is (and train a separate recognizer for each case):
• an entity whose span and type are correctly
recognized,
• an entity whose span and supertype are cor-
rectly recognized,
• an entity whose span is correctly recognized
(without regard to its type).
</listItem>
<bodyText confidence="0.999955857142857">
Therefore, we subdivide the classification prob-
lem into a few subproblems. Firstly, we indepen-
dently evaluate the recognition system for one-
word named entities, for two-word named enti-
ties and for multiword named entities. For each
of these three problems, we define three tasks, or-
dered from the easiest to the most difficult:
</bodyText>
<listItem confidence="0.9439919375">
• Named entity span recognition – all words of
named entity must be found but the type is
not relevant. For one-word entities, this re-
duces to 0/1 classification problem, that is,
each word is either marked as named entity
(1) or as regular word (0). For two-word en-
tities, this 0/1 decision is made for each cou-
ple of subsequent words (bigram) in the sen-
tence.
• Named entity supertype recognition – all
words of named entity must be found and the
supertype must be correct. This is a multi-
class classification problem, where classes
are named entity classes of the first level in
hierarchy (p, g, i, ...) plus one class
for regular words.
</listItem>
<page confidence="0.993658">
197
</page>
<bodyText confidence="0.985597384615385">
• Named entity type recognition – all words
of named entity must be found and the type
must be correct.
In our solution, a separate SVM classifier
is built for one-word named entities, two-word
named entities and three-word named entities.
Then, as we proceed through the text, we apply the
classifier on each “window” or “n-gram” of words
– one-word, two-word and three-word, classifying
the n-gram with the corresponding SVM classi-
fier. We deliberately omit named entities contain-
ing four and more words, as they represent only a
small portion of the instances (5%).
</bodyText>
<subsectionHeader confidence="0.954548">
3.2 Features
</subsectionHeader>
<bodyText confidence="0.987423">
Classification features which were used by the
SVM classifier(s), are as follows:
</bodyText>
<listItem confidence="0.998879">
• morphological features – part of speech, gen-
der, case and number,
• orthographic features – boolean features
such as capital letter at the beginning of the
word or regular expression for time and year
,
• lists of known named entities – boolean fea-
tures describing whether the word is listed
in lists of Czech most used names and sur-
names, Czech cities, countries or famous in-
stitutions,
• lemma – some lemmas contain shortcuts de-
scribing the property of lemma, for example
“Prahou” (Prague, 7th case) would lemma-
tize to “Praha ;G” with mark “ ;G” hinting
that “Praha” is a geographical name,
• context features – similar features for pre-
</listItem>
<bodyText confidence="0.774454777777778">
ceding and following words, that is, part of
speech, gender, case and number for the pre-
ceding and following word, orthographic fea-
tures, membership in a list of known entities
and lemma hints for the preceding and fol-
lowing word.
All classification features were transformed into
binary (boolean) features, resulting in roughly
200-dimensional binary feature space.
</bodyText>
<subsectionHeader confidence="0.987836">
3.3 Classifier implementation
</subsectionHeader>
<bodyText confidence="0.999699529411765">
For the classification task, we decided to use Sup-
port Vector Machine classification method. First,
this solution has been repeatedly shown to give
better scores in NE recognition in comparison to
other Machine Learning methods, see e.g. (Isozaki
and Kazawa, 2002) and (Ekbal and Bandyopad-
hyay, 2008). Second, in our preliminary experi-
ments on our data it outperformed all other solu-
tions too (based on naive Bayes, k nearest neigh-
bors, and decision trees).
As an SVM classifier, we used its CPAN Perl
implementation Algorithm-SVM.4
Technically, the NE recognizer is implemented
as a Perl module included into TectoMT, which is
a modular open source software framework for im-
plementing NLP applications, (ˇZabokrtsk´y et al.,
2008).5
</bodyText>
<sectionHeader confidence="0.999617" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.998822">
4.1 Evaluation metrics
</subsectionHeader>
<bodyText confidence="0.9993445">
We use the following standard quantities for eval-
uating performance of the presented classifier:
</bodyText>
<listItem confidence="0.983308">
• precision – the number of correctly predicted
NEs divided by the number of all predicted
NEs,
• recall – the number of correctly predicted
NEs divided by the number of all NEs in the
data,
•
</listItem>
<bodyText confidence="0.996774571428571">
f-score – harmonic mean of precision and re-
call.
In our opinion, simpler quantities such as accu-
racy (the percentage of correctly marked words)
are not suitable for this task, since the number
of NE instances to be found is not known in ad-
vance.6
</bodyText>
<subsectionHeader confidence="0.759492">
4.2 Results
</subsectionHeader>
<bodyText confidence="0.99995125">
The results for SVM classifier when applied on
the evaluation test set of the corpus are summa-
rized in Table 4. The table evaluates all subtasks
as defined in Section 3.1, that is, for combination
</bodyText>
<footnote confidence="0.9944297">
4http://www.cpan.org/authors/id/L/LA/LAIRDM/
5One of the reasons for integrating the classifier into Tec-
toMT is the fact that it requires the input texts to be sentence-
segmented, tokenized, tagged and lemmatized; all the nec-
essary tools for such preprocessing are already available in
TectoMT.
6Counting also all non-NE words predicted as non-entities
as a success would lead to very high accuracy value without
much information content (obviously most words are not NE
instances).
</footnote>
<page confidence="0.985031">
198
</page>
<table confidence="0.9998908">
All NEs One-word NEs Two-word NEs
P R F P R F P R F
span+type 0.75 0.62 0.68 0.80 0.71 0.75 0.68 0.62 0.65
span+supertype 0.75 0.67 0.71 0.87 0.78 0.82 0.71 0.64 0.67
span 0.84 0.70 0.76 0.89 0.80 0.84 0.76 0.69 0.72
</table>
<tableCaption confidence="0.911523">
Table 4: Summary of the SVM classifier performance (P=precision, R=recall, F=f-measure). Recogni-
tion of NEs of different length is evaluated separately. The other dimension corresponds to the gradually
released correctness requirements.
</tableCaption>
<table confidence="0.992567875">
true type predicted type true type description predicted type description errors
oa x cultural artifacts (books, movies) no entity 184
ic x cult./educ./scient. inst. no entity 74
x gu no entity cities/towns 71
x P no entity personal name container 66
if x companies, concerns ... no entity 60
x ic no entity cult./educ./scient. inst. 59
io x government/political inst. no entity 57
x ps no entity surnames 47
P x personal name container no entity 43
ps x surnames no entity 41
gu x cities/towns no entity 37
x td no entity days 35
op x products no entity 33
x pf no entity first names 31
T x time container no entity 30
</table>
<tableCaption confidence="0.999597">
Table 5: The most frequent types of errors in NE recognition made by the SVM classifier.
</tableCaption>
<bodyText confidence="0.999616428571429">
of subtask defined for all entities, one-word enti-
ties and two-word entities and with gradually re-
leased requirements for correctness: correct span
and correct (detailed) type, correct span and cor-
rect supertype, correct span only.
The most common SVM classification errors
are shown in Table 5.
</bodyText>
<subsectionHeader confidence="0.974952">
4.3 Discussion
</subsectionHeader>
<bodyText confidence="0.999967742857143">
As we can see in Table 4, the classifier recognizes
span and type of all named entities in text with
f-measure = 0.68. This improves the results re-
ported on this data in (ˇSevˇcikov´a et al., 2007a),
which was 0.62. For one-word named entities, the
improvement is also noticeable, from 0.70 to 0.75.
In our opinion, the improvement is caused by
better feature selection on one hand. We do not
use as many classification features as the authors
of (ˇSevˇc´ıkov´a et al., 2007a), instead we made a
preliminary manual selection of features we con-
sidered to be helpful. For example, we do not use
the whole variety of 15 Czech morphological cat-
egories for every word in context, but we use only
part of speech, gender, case and number. Also,
we avoided using features based on storing words
which occurred in training data, such as boolean
feature, which is true for words, which appeared
in training data as named entity. We tried employ-
ing such features, but in our opinion, they result in
sparsity in space searched by SVM.
It would be highly difficult to correctly compare
the achieved results with results reported on other
languages (such as f-score 88.76% achieved for
English in (Zhang and Johnson, 2003)), especially
because of different task granularity (and obvi-
ously highly different baselines). Furthermore, in
Czech the task is more complicated due to inflec-
tion: many named entities can appear in several
many different forms. For example, the Czech
capital city “Praha” appeared in these forms in
training data: Praha, Prahy, Prahou, Prahu.
Table 5 describes the most common errors made
by classifier. Clearly, the most problematic classes
are objects (oa) and institutions (ic, if, io),
</bodyText>
<page confidence="0.996527">
199
</page>
<bodyText confidence="0.99997245">
which mostly remain unrecognized. The problem
is that, cultural artifacts like books or movies, or
institutions, tend to have quite new and unusual
names, as opposed to personal names, for which
fairly limited amount of choice exists, and cities,
which do not change and can be listed easily.
Institutions also tend to have long and com-
plicated names, for which it is especially diffi-
cult to find the ending frontier. We believe that
dependency syntax analysis (such as dependency
trees resulting from the maximum spanning tree
parser, (McDonald et al., 2005)) might provide
some clues here. By determining the head of the
clause, e.g. theatre, university, gallery and it’s de-
pendants, we might get some hints about which
words are part of the name and which are not.
Yet another improvement in overall perfor-
mance could be achieved by incorporating hyper-
nym discovery (making use e.g. of Wikipedia) as
proposed in (Kliegr et al., 2008).
</bodyText>
<sectionHeader confidence="0.999484" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9999469375">
We have presented a new recently published cor-
pus of Czech sentences with manually annotated
named entities with fine-grained two-level annota-
tion. We used the data for training and evaluating a
named entity recognizer based on Support Vector
Machines classification technique. Our classifier
reached f-measure 0.68 in recognizing and classi-
fying Czech named entities into 62 categories and
thus outperformed the results previously reported
for NE recognition in Czech in (&amp;quot;Sev&amp;quot;c´ıkov´a et al.,
2007a).
We intend to further improve our classifier,
especially recognition of institution and object
names, by employing dependency syntax features.
Another improvement is hoped to be achieved us-
ing WWW-based ontologies.
</bodyText>
<sectionHeader confidence="0.997496" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.987226333333333">
This research was supported by MSM
0021620838, GAAV &amp;quot;CR 1ET101120503, and
M&amp;quot;SMT &amp;quot;CR LC536.
</bodyText>
<sectionHeader confidence="0.99884" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999738847457627">
Michael Collins and Yoram Singer. 1999. Unsuper-
vised Models for Named Entity Classification. In
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing and Very Large
Corpora (EMNLP/VLC), pages 189–196.
Asif Ekbal and Sivaji Bandyopadhyay. 2008. Named
Entity Recognition using Support Vector Machine:
A Language Independent Approach. International
Journal of Computer Systems Science and Engineer-
ing, 4(2):155–170.
Michael Fleischman and Eduard Hovy. 2002. Fine
Grained Classification of Named Entities . In Pro-
ceedings of the 19th International Conference on
Computational Linguistics (COLING), volume I,
pages 267–273.
Ralph Grishman and Beth Sundheim. 1996. Mes-
sage Understanding Conference - 6: A Brief History.
In Proceedings of the 16th International Conference
on Computational Linguistics (COLING), volume I,
pages 466–471.
Jan Haji&amp;quot;c, Jarmila Panevov´a, Eva Haji&amp;quot;cov´a, Petr
Sgall, Petr Pajas, Jan &amp;quot;St&amp;quot;ep´anek, Ji&amp;quot;r´ı Havelka,
Marie Mikulov´a, Zden&amp;quot;ek &amp;quot;Zabokrtsk´y, and Magda
&amp;quot;Sev&amp;quot;c´ıkov´a. 2006. Prague Dependency Treebank
2.0.
Hideki Isozaki and Hideto Kazawa. 2002. Effi-
cient Support Vector Classifiers For Named Entity
Recognition. In Proceedings of the 19th Inter-
national Conference on Computational Linguistics
(COLING’02).
Tomas Kliegr, Krishna Chandramouli, Jan Nemrava,
Vojtech Svatek, and Ebroul Izquierdo. 2008.
Wikipedia as the premiere source for targeted hy-
pernym discovery. WBBT ECML08.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Haji&amp;quot;c. 2005. Non-Projective Dependency Pars-
ing using Spanning Tree Algorithms. In Proceed-
ings of Human Langauge Technology Conference
and Conference on Empirical Methods in Natural
Language Processing (HTL/EMNLP), pages 523–
530, Vancouver, BC, Canada.
Petr Pajas and Jan &amp;quot;St&amp;quot;ep´anek. 2006. XML-based rep-
resentation of multi-layered annotation in the PDT
2.0. In Richard Erhard Hinrichs, Nancy Ide, Martha
Palmer, and James Pustejovsky, editors, Proceed-
ings of the LREC Workshop on Merging and Layer-
ing Linguistic Information (LREC 2006), pages 40–
47, Paris, France.
Satoshi Sekine. 2003. Sekine’s Extended Named En-
tity Hierarchy. http://nlp.cs.nyu.edu/ene/.
Magda &amp;quot;Sev&amp;quot;c´ıkov´a, Zden&amp;quot;ek &amp;quot;Zabokrtsk´y, and Old&amp;quot;rich
Kr˚uza. 2007. Named Entities in Czech: Annotat-
ing Data and Developing NE Tagger. In V´aclav Ma-
tou&amp;quot;sek and Pavel Mautner, editors, Lecture Notes in
Artificial Intelligence, Proceedings of the 10th Inter-
national Conference on Text, Speech and Dialogue,
volume 4629 of Lecture Notes in Computer Science,
pages 188–195, Pilsen, Czech Republic. Springer
Science+Business Media Deutschland GmbH.
</reference>
<page confidence="0.939683">
200
</page>
<reference confidence="0.99962755">
Partha Pratim Talukdar, Thorsten Brants, Mark Liber-
man, and Fernando Pereira. 2006. A Context Pat-
tern Induction Method for Named Entity Extraction.
In Proceedings of the 10th Conference on Com-
putational Natural Language Learning (CoNLL-X),
pages 141–148.
Magda ˇSevˇc´ıkov´a, Zdenˇek ˇZabokrtsk´y, and Oldˇrich
Kr˚uza. 2007. Zpracov´an´ı pojmenovan´ych entit
v ˇcesk´ych textech. Technical report, ´UFAL MFF
UK, Praha.
Zdenˇek ˇZabokrtsk´y, Jan Pt´aˇcek, and Petr Pajas. 2008.
TectoMT: Highly Modular MT System with Tec-
togrammatics Used as Transfer Layer. In Proceed-
ings of the 3rd Workshop on Statistical Machine
Translation, ACL.
Tong Zhang and David Johnson. 2003. A robust risk
minimization based named entity recognition sys-
tem. In Walter Daelemans and Miles Osborne, ed-
itors, Proceedings of CoNLL-2003, pages 204–207.
Edmonton, Canada.
</reference>
<page confidence="0.998404">
201
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.576960">
<title confidence="0.990504">Czech Named Entity Corpus and SVM-based Recognizer</title>
<author confidence="0.999796">Jana Kravalov´a</author>
<affiliation confidence="0.994396">Charles University in Prague Institute of Formal and Applied Linguistics</affiliation>
<email confidence="0.83698">kravalova@ufal.mff.cuni.cz</email>
<affiliation confidence="0.9761775">Charles University in Prague Institute of Formal and Applied Linguistics</affiliation>
<email confidence="0.910601">zabokrtsky@ufal.mff.cuni.cz</email>
<abstract confidence="0.986124466666667">This paper deals with recognition of named entities in Czech texts. We present a recently released corpus of Czech sentences with manually annotated named entities, in which a rich two-level classification scheme was used. There are around 6000 sentences in the corpus with roughly 33000 marked named entity instances. We use the data for training and evaluating a named entity recognizer based on Support Vector Machine classification technique. The presented recognizer outperforms the results previously reported for NE recognition in Czech.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Yoram Singer</author>
</authors>
<title>Unsupervised Models for Named Entity Classification.</title>
<date>1999</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP/VLC),</booktitle>
<pages>189--196</pages>
<contexts>
<context position="1473" citStr="Collins and Singer, 1999" startWordPosition="211" endWordPosition="214">roduction After the series of Message Understanding Conferences (MUC; (Grishman and Sundheim, 1996)), processing of named entities (NEs) became a well established discipline within the NLP domain, usually motivated by the needs of Information Extraction, Question Answering, or Machine Translation. For English, one can find literature about attempts at rule-based solutions for the NE task as well as machine-learning approaches, be they dependent on the existence of labeled data (such as CoNLL-2003 shared task data), unsupervised (using redundancy in NE expressions and their contexts, see e.g. (Collins and Singer, 1999)) or a combination of both (such as (Talukdar et al., 2006), in which labeled data are used as a source of seed for an unsupervised procedure exploiting huge unlabeled data). A survey of research on named entity recognition is available in (Ekbal and Bandyopadhyay, 2008). There has been considerably less research done in the NE field in Czech, as discussed in (ˇSevˇcikov´a et al., 2007b). Therefore we focus on it in this paper, which is structured as follows. In Section 2 we present a recently released corpus of Czech sentences with manually annotated instances of named entities, in which a ri</context>
<context position="3139" citStr="Collins and Singer, 1999" startWordPosition="481" endWordPosition="484">*&amp;quot;]). This query makes the relative frequency of NEs in the selection higher than the corpus average, which makes the subsequent manual annotation much more effective, even if it may slightly bias the distribution of NE types and their observed density.2 2.2 Annotation NE Instances with Two-level NE Classification There is no generally accepted typology of Named Entities. One can see two trends: from the viewpoint of unsupervised learning, it is advantageous to have just a few coarse-grained categories (cf. the NE classification developed for MUC conferences or the classification proposed in (Collins and Singer, 1999), where only persons, locations, and organizations were distinguished), whereas those interested in semantically oriented applications prefer more informative (finer-grained) categories (e.g. (Fleischman and Hovy, 2002) with 1http://ucnk.ff.cuni.cz 2The query is trivially motivated by the fact that NEs in Czech (as well as in many other languages) are often marked by capitalization of the first letter. Annotation of NEs in a corpus without such selection would lower the bias, but would be more expensive due to the lower density of NE instances in the annotated material. 194 Proceedings of the </context>
</contexts>
<marker>Collins, Singer, 1999</marker>
<rawString>Michael Collins and Yoram Singer. 1999. Unsupervised Models for Named Entity Classification. In Proceedings of the Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP/VLC), pages 189–196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asif Ekbal</author>
<author>Sivaji Bandyopadhyay</author>
</authors>
<title>Named Entity Recognition using Support Vector Machine: A Language Independent Approach.</title>
<date>2008</date>
<journal>International Journal of Computer Systems Science and Engineering,</journal>
<volume>4</volume>
<issue>2</issue>
<contexts>
<context position="1744" citStr="Ekbal and Bandyopadhyay, 2008" startWordPosition="256" endWordPosition="259">swering, or Machine Translation. For English, one can find literature about attempts at rule-based solutions for the NE task as well as machine-learning approaches, be they dependent on the existence of labeled data (such as CoNLL-2003 shared task data), unsupervised (using redundancy in NE expressions and their contexts, see e.g. (Collins and Singer, 1999)) or a combination of both (such as (Talukdar et al., 2006), in which labeled data are used as a source of seed for an unsupervised procedure exploiting huge unlabeled data). A survey of research on named entity recognition is available in (Ekbal and Bandyopadhyay, 2008). There has been considerably less research done in the NE field in Czech, as discussed in (ˇSevˇcikov´a et al., 2007b). Therefore we focus on it in this paper, which is structured as follows. In Section 2 we present a recently released corpus of Czech sentences with manually annotated instances of named entities, in which a rich classification scheme is used. In Section 3 we describe a new NE recognizer developed for Czech, based on the Support Vector Machine (SVM) classification technique. Evaluation of such approach is presented in Section 4. The summary is given in Section 5. 2 Manually An</context>
<context position="14804" citStr="Ekbal and Bandyopadhyay, 2008" startWordPosition="2458" endWordPosition="2462">nd number for the preceding and following word, orthographic features, membership in a list of known entities and lemma hints for the preceding and following word. All classification features were transformed into binary (boolean) features, resulting in roughly 200-dimensional binary feature space. 3.3 Classifier implementation For the classification task, we decided to use Support Vector Machine classification method. First, this solution has been repeatedly shown to give better scores in NE recognition in comparison to other Machine Learning methods, see e.g. (Isozaki and Kazawa, 2002) and (Ekbal and Bandyopadhyay, 2008). Second, in our preliminary experiments on our data it outperformed all other solutions too (based on naive Bayes, k nearest neighbors, and decision trees). As an SVM classifier, we used its CPAN Perl implementation Algorithm-SVM.4 Technically, the NE recognizer is implemented as a Perl module included into TectoMT, which is a modular open source software framework for implementing NLP applications, (ˇZabokrtsk´y et al., 2008).5 4 Evaluation 4.1 Evaluation metrics We use the following standard quantities for evaluating performance of the presented classifier: • precision – the number of corre</context>
</contexts>
<marker>Ekbal, Bandyopadhyay, 2008</marker>
<rawString>Asif Ekbal and Sivaji Bandyopadhyay. 2008. Named Entity Recognition using Support Vector Machine: A Language Independent Approach. International Journal of Computer Systems Science and Engineering, 4(2):155–170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Fleischman</author>
<author>Eduard Hovy</author>
</authors>
<title>Fine Grained Classification of Named Entities .</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics (COLING), volume I,</booktitle>
<pages>267--273</pages>
<contexts>
<context position="3358" citStr="Fleischman and Hovy, 2002" startWordPosition="508" endWordPosition="511">E types and their observed density.2 2.2 Annotation NE Instances with Two-level NE Classification There is no generally accepted typology of Named Entities. One can see two trends: from the viewpoint of unsupervised learning, it is advantageous to have just a few coarse-grained categories (cf. the NE classification developed for MUC conferences or the classification proposed in (Collins and Singer, 1999), where only persons, locations, and organizations were distinguished), whereas those interested in semantically oriented applications prefer more informative (finer-grained) categories (e.g. (Fleischman and Hovy, 2002) with 1http://ucnk.ff.cuni.cz 2The query is trivially motivated by the fact that NEs in Czech (as well as in many other languages) are often marked by capitalization of the first letter. Annotation of NEs in a corpus without such selection would lower the bias, but would be more expensive due to the lower density of NE instances in the annotated material. 194 Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 194–201, Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP Types of NE q - Quantitative expressions n - Specific number usages a - Numbers in addresses g - Geogr</context>
<context position="7706" citStr="Fleischman and Hovy, 2002" startWordPosition="1296" endWordPosition="1300">are parts of a (so-called) container NE (e.g., two NEs, a first name and a surname, form together a person name container NE such as in &lt;P&lt;pf Paul&gt; &lt;ps Newman&gt;&gt;). The container NEs are marked with a capital one-letter tag: P for (complex) person names, T for temporal expressions, A for addresses, and C for bibliographic items. A more detailed description of the NE classification can be found in (ˇSevˇc´ıkov´a et al., 2007b). 3Given the size of the annotated data, further subdivision into even finer classes (such as persons divided into categories such as lawyer, politician, scientist used in (Fleischman and Hovy, 2002)) would result in too sparse annotations. 2.3 Annotated Data Cleaning After collecting all the sentences annotated by the annotators, it was necessary to clean the data in order to improve the data quality. For this purpose, a set of tests was implemented. The tests revealed wrong or “suspicious” spots in the data (based e.g. on the assumption that the same lemma should manifest an entity of the same type in most its occurrences), which were manually checked and corrected if necessary. Some noisy sentences caused e.g. by wrong sentence segmentation in the original resource were deleted; the fi</context>
</contexts>
<marker>Fleischman, Hovy, 2002</marker>
<rawString>Michael Fleischman and Eduard Hovy. 2002. Fine Grained Classification of Named Entities . In Proceedings of the 19th International Conference on Computational Linguistics (COLING), volume I, pages 267–273.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Grishman</author>
<author>Beth Sundheim</author>
</authors>
<title>Message Understanding Conference - 6: A Brief History.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics (COLING), volume I,</booktitle>
<pages>466--471</pages>
<contexts>
<context position="947" citStr="Grishman and Sundheim, 1996" startWordPosition="129" endWordPosition="132"> recognition of named entities in Czech texts. We present a recently released corpus of Czech sentences with manually annotated named entities, in which a rich two-level classification scheme was used. There are around 6000 sentences in the corpus with roughly 33000 marked named entity instances. We use the data for training and evaluating a named entity recognizer based on Support Vector Machine classification technique. The presented recognizer outperforms the results previously reported for NE recognition in Czech. 1 Introduction After the series of Message Understanding Conferences (MUC; (Grishman and Sundheim, 1996)), processing of named entities (NEs) became a well established discipline within the NLP domain, usually motivated by the needs of Information Extraction, Question Answering, or Machine Translation. For English, one can find literature about attempts at rule-based solutions for the NE task as well as machine-learning approaches, be they dependent on the existence of labeled data (such as CoNLL-2003 shared task data), unsupervised (using redundancy in NE expressions and their contexts, see e.g. (Collins and Singer, 1999)) or a combination of both (such as (Talukdar et al., 2006), in which labe</context>
</contexts>
<marker>Grishman, Sundheim, 1996</marker>
<rawString>Ralph Grishman and Beth Sundheim. 1996. Message Understanding Conference - 6: A Brief History. In Proceedings of the 16th International Conference on Computational Linguistics (COLING), volume I, pages 466–471.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajic</author>
<author>Jarmila Panevov´a</author>
<author>Eva Hajicov´a</author>
<author>Petr Sgall</author>
<author>Petr Pajas</author>
</authors>
<title>St&amp;quot;ep´anek, Ji&amp;quot;r´ı Havelka, Marie Mikulov´a, Zden&amp;quot;ek &amp;quot;Zabokrtsk´y, and Magda &amp;quot;Sev&amp;quot;c´ıkov´a.</title>
<date></date>
<journal>Prague Dependency Treebank</journal>
<volume>2</volume>
<marker>Hajic, Panevov´a, Hajicov´a, Sgall, Pajas, </marker>
<rawString>Jan Haji&amp;quot;c, Jarmila Panevov´a, Eva Haji&amp;quot;cov´a, Petr Sgall, Petr Pajas, Jan &amp;quot;St&amp;quot;ep´anek, Ji&amp;quot;r´ı Havelka, Marie Mikulov´a, Zden&amp;quot;ek &amp;quot;Zabokrtsk´y, and Magda &amp;quot;Sev&amp;quot;c´ıkov´a. 2006. Prague Dependency Treebank 2.0.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hideki Isozaki</author>
<author>Hideto Kazawa</author>
</authors>
<title>Efficient Support Vector Classifiers For Named Entity Recognition.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics (COLING’02).</booktitle>
<contexts>
<context position="14768" citStr="Isozaki and Kazawa, 2002" startWordPosition="2453" endWordPosition="2456"> part of speech, gender, case and number for the preceding and following word, orthographic features, membership in a list of known entities and lemma hints for the preceding and following word. All classification features were transformed into binary (boolean) features, resulting in roughly 200-dimensional binary feature space. 3.3 Classifier implementation For the classification task, we decided to use Support Vector Machine classification method. First, this solution has been repeatedly shown to give better scores in NE recognition in comparison to other Machine Learning methods, see e.g. (Isozaki and Kazawa, 2002) and (Ekbal and Bandyopadhyay, 2008). Second, in our preliminary experiments on our data it outperformed all other solutions too (based on naive Bayes, k nearest neighbors, and decision trees). As an SVM classifier, we used its CPAN Perl implementation Algorithm-SVM.4 Technically, the NE recognizer is implemented as a Perl module included into TectoMT, which is a modular open source software framework for implementing NLP applications, (ˇZabokrtsk´y et al., 2008).5 4 Evaluation 4.1 Evaluation metrics We use the following standard quantities for evaluating performance of the presented classifie</context>
</contexts>
<marker>Isozaki, Kazawa, 2002</marker>
<rawString>Hideki Isozaki and Hideto Kazawa. 2002. Efficient Support Vector Classifiers For Named Entity Recognition. In Proceedings of the 19th International Conference on Computational Linguistics (COLING’02).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Kliegr</author>
<author>Krishna Chandramouli</author>
</authors>
<date></date>
<note>Nemrava,</note>
<marker>Kliegr, Chandramouli, </marker>
<rawString>Tomas Kliegr, Krishna Chandramouli, Jan Nemrava,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vojtech Svatek</author>
<author>Ebroul Izquierdo</author>
</authors>
<title>Wikipedia as the premiere source for targeted hypernym discovery. WBBT ECML08.</title>
<date>2008</date>
<marker>Svatek, Izquierdo, 2008</marker>
<rawString>Vojtech Svatek, and Ebroul Izquierdo. 2008. Wikipedia as the premiere source for targeted hypernym discovery. WBBT ECML08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajic</author>
</authors>
<title>Non-Projective Dependency Parsing using Spanning Tree Algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Langauge Technology Conference and Conference on Empirical Methods in Natural Language Processing (HTL/EMNLP),</booktitle>
<pages>523--530</pages>
<location>Vancouver, BC,</location>
<contexts>
<context position="20243" citStr="McDonald et al., 2005" startWordPosition="3367" endWordPosition="3370">ic classes are objects (oa) and institutions (ic, if, io), 199 which mostly remain unrecognized. The problem is that, cultural artifacts like books or movies, or institutions, tend to have quite new and unusual names, as opposed to personal names, for which fairly limited amount of choice exists, and cities, which do not change and can be listed easily. Institutions also tend to have long and complicated names, for which it is especially difficult to find the ending frontier. We believe that dependency syntax analysis (such as dependency trees resulting from the maximum spanning tree parser, (McDonald et al., 2005)) might provide some clues here. By determining the head of the clause, e.g. theatre, university, gallery and it’s dependants, we might get some hints about which words are part of the name and which are not. Yet another improvement in overall performance could be achieved by incorporating hypernym discovery (making use e.g. of Wikipedia) as proposed in (Kliegr et al., 2008). 5 Conclusions We have presented a new recently published corpus of Czech sentences with manually annotated named entities with fine-grained two-level annotation. We used the data for training and evaluating a named entity</context>
</contexts>
<marker>McDonald, Pereira, Ribarov, Hajic, 2005</marker>
<rawString>Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Haji&amp;quot;c. 2005. Non-Projective Dependency Parsing using Spanning Tree Algorithms. In Proceedings of Human Langauge Technology Conference and Conference on Empirical Methods in Natural Language Processing (HTL/EMNLP), pages 523– 530, Vancouver, BC, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Petr Pajas</author>
<author>Jan Step´anek</author>
</authors>
<title>XML-based representation of multi-layered annotation in the PDT 2.0.</title>
<date>2006</date>
<booktitle>Proceedings of the LREC Workshop on Merging and Layering Linguistic Information (LREC</booktitle>
<pages>40--47</pages>
<editor>In Richard Erhard Hinrichs, Nancy Ide, Martha Palmer, and James Pustejovsky, editors,</editor>
<location>Paris, France.</location>
<marker>Pajas, Step´anek, 2006</marker>
<rawString>Petr Pajas and Jan &amp;quot;St&amp;quot;ep´anek. 2006. XML-based representation of multi-layered annotation in the PDT 2.0. In Richard Erhard Hinrichs, Nancy Ide, Martha Palmer, and James Pustejovsky, editors, Proceedings of the LREC Workshop on Merging and Layering Linguistic Information (LREC 2006), pages 40– 47, Paris, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoshi Sekine</author>
</authors>
<title>Sekine’s Extended Named Entity Hierarchy.</title>
<date>2003</date>
<note>http://nlp.cs.nyu.edu/ene/.</note>
<contexts>
<context position="5541" citStr="Sekine, 2003" startWordPosition="909" endWordPosition="910">ames or - directives, norms qo - ordinal numbers gr - territorial names g_ - underspecified om - currency units p_ - underspecified nq - town quarter mt - TV stations nm - in formula nc - sport score mn - periodical pf - first names gt - continents oc - chemical nw - flat size tn - minutes th - hours td - days tp - epochs ts - seconds ty - years Figure 1: Two-level hierarchical classification of NEs used in the corpus. Note that the (detailed) NE types are divided into two columns just because of the space reasons here. 195 eight types of person labels, or Sekine’s Extended NE Hierarchy, cf. (Sekine, 2003)). In our corpus, we use a two-level NE classification depicted in Figure 1. The first level corresponds to rough categories (called NE supertypes) such as person names, geographical names etc. The second level provides a more detailed classification: e.g. within the supertype of geographical names, the NE types of names of cities/towns, names of states, names of rivers/seas/lakes etc. are distinguished.3 If more robust processing is necessary, only the first level (NE supertypes) can be used, while the second level (NE types) comes into play when more subtle information is needed. Each NE typ</context>
</contexts>
<marker>Sekine, 2003</marker>
<rawString>Satoshi Sekine. 2003. Sekine’s Extended Named Entity Hierarchy. http://nlp.cs.nyu.edu/ene/.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Magda Sevc´ıkov´a</author>
</authors>
<title>Zden&amp;quot;ek &amp;quot;Zabokrtsk´y, and Old&amp;quot;rich Kr˚uza.</title>
<date>2007</date>
<booktitle>Lecture Notes in Artificial Intelligence, Proceedings of the 10th International Conference on Text, Speech and Dialogue,</booktitle>
<volume>4629</volume>
<pages>188--195</pages>
<editor>In V´aclav Matou&amp;quot;sek and Pavel Mautner, editors,</editor>
<publisher>Springer Science+Business Media Deutschland GmbH.</publisher>
<location>Pilsen, Czech Republic.</location>
<marker>Sevc´ıkov´a, 2007</marker>
<rawString>Magda &amp;quot;Sev&amp;quot;c´ıkov´a, Zden&amp;quot;ek &amp;quot;Zabokrtsk´y, and Old&amp;quot;rich Kr˚uza. 2007. Named Entities in Czech: Annotating Data and Developing NE Tagger. In V´aclav Matou&amp;quot;sek and Pavel Mautner, editors, Lecture Notes in Artificial Intelligence, Proceedings of the 10th International Conference on Text, Speech and Dialogue, volume 4629 of Lecture Notes in Computer Science, pages 188–195, Pilsen, Czech Republic. Springer Science+Business Media Deutschland GmbH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Partha Pratim Talukdar</author>
<author>Thorsten Brants</author>
<author>Mark Liberman</author>
<author>Fernando Pereira</author>
</authors>
<title>A Context Pattern Induction Method for Named Entity Extraction.</title>
<date>2006</date>
<booktitle>In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X),</booktitle>
<pages>141--148</pages>
<contexts>
<context position="1532" citStr="Talukdar et al., 2006" startWordPosition="222" endWordPosition="225">s (MUC; (Grishman and Sundheim, 1996)), processing of named entities (NEs) became a well established discipline within the NLP domain, usually motivated by the needs of Information Extraction, Question Answering, or Machine Translation. For English, one can find literature about attempts at rule-based solutions for the NE task as well as machine-learning approaches, be they dependent on the existence of labeled data (such as CoNLL-2003 shared task data), unsupervised (using redundancy in NE expressions and their contexts, see e.g. (Collins and Singer, 1999)) or a combination of both (such as (Talukdar et al., 2006), in which labeled data are used as a source of seed for an unsupervised procedure exploiting huge unlabeled data). A survey of research on named entity recognition is available in (Ekbal and Bandyopadhyay, 2008). There has been considerably less research done in the NE field in Czech, as discussed in (ˇSevˇcikov´a et al., 2007b). Therefore we focus on it in this paper, which is structured as follows. In Section 2 we present a recently released corpus of Czech sentences with manually annotated instances of named entities, in which a rich classification scheme is used. In Section 3 we describe </context>
</contexts>
<marker>Talukdar, Brants, Liberman, Pereira, 2006</marker>
<rawString>Partha Pratim Talukdar, Thorsten Brants, Mark Liberman, and Fernando Pereira. 2006. A Context Pattern Induction Method for Named Entity Extraction. In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X), pages 141–148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magda ˇSevˇc´ıkov´a</author>
<author>Zdenˇek ˇZabokrtsk´y</author>
<author>Oldˇrich Kr˚uza</author>
</authors>
<title>Zpracov´an´ı pojmenovan´ych entit v ˇcesk´ych textech.</title>
<date>2007</date>
<tech>Technical report, ´UFAL</tech>
<publisher>MFF UK, Praha.</publisher>
<marker>ˇSevˇc´ıkov´a, ˇZabokrtsk´y, Kr˚uza, 2007</marker>
<rawString>Magda ˇSevˇc´ıkov´a, Zdenˇek ˇZabokrtsk´y, and Oldˇrich Kr˚uza. 2007. Zpracov´an´ı pojmenovan´ych entit v ˇcesk´ych textech. Technical report, ´UFAL MFF UK, Praha.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zdenˇek ˇZabokrtsk´y</author>
<author>Jan Pt´aˇcek</author>
<author>Petr Pajas</author>
</authors>
<title>TectoMT: Highly Modular MT System with Tectogrammatics Used as Transfer Layer.</title>
<date>2008</date>
<booktitle>In Proceedings of the 3rd Workshop on Statistical Machine Translation, ACL.</booktitle>
<marker>ˇZabokrtsk´y, Pt´aˇcek, Pajas, 2008</marker>
<rawString>Zdenˇek ˇZabokrtsk´y, Jan Pt´aˇcek, and Petr Pajas. 2008. TectoMT: Highly Modular MT System with Tectogrammatics Used as Transfer Layer. In Proceedings of the 3rd Workshop on Statistical Machine Translation, ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tong Zhang</author>
<author>David Johnson</author>
</authors>
<title>A robust risk minimization based named entity recognition system.</title>
<date>2003</date>
<booktitle>In Walter Daelemans</booktitle>
<pages>204--207</pages>
<editor>and Miles Osborne, editors,</editor>
<location>Edmonton, Canada.</location>
<contexts>
<context position="19188" citStr="Zhang and Johnson, 2003" startWordPosition="3200" endWordPosition="3203"> not use the whole variety of 15 Czech morphological categories for every word in context, but we use only part of speech, gender, case and number. Also, we avoided using features based on storing words which occurred in training data, such as boolean feature, which is true for words, which appeared in training data as named entity. We tried employing such features, but in our opinion, they result in sparsity in space searched by SVM. It would be highly difficult to correctly compare the achieved results with results reported on other languages (such as f-score 88.76% achieved for English in (Zhang and Johnson, 2003)), especially because of different task granularity (and obviously highly different baselines). Furthermore, in Czech the task is more complicated due to inflection: many named entities can appear in several many different forms. For example, the Czech capital city “Praha” appeared in these forms in training data: Praha, Prahy, Prahou, Prahu. Table 5 describes the most common errors made by classifier. Clearly, the most problematic classes are objects (oa) and institutions (ic, if, io), 199 which mostly remain unrecognized. The problem is that, cultural artifacts like books or movies, or insti</context>
</contexts>
<marker>Zhang, Johnson, 2003</marker>
<rawString>Tong Zhang and David Johnson. 2003. A robust risk minimization based named entity recognition system. In Walter Daelemans and Miles Osborne, editors, Proceedings of CoNLL-2003, pages 204–207. Edmonton, Canada.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>