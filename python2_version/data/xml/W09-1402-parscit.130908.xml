<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009716">
<title confidence="0.987919">
Extracting Complex Biological Events with Rich Graph-Based Feature Sets
</title>
<author confidence="0.977773">
Jari Bj¨orne,&apos; Juho Heimonen,&apos;,2 Filip Ginter,&apos; Antti Airola,&apos;,2
Tapio Pahikkala&apos; and Tapio Salakoski&apos;,2
</author>
<affiliation confidence="0.9970225">
&apos;Department of Information Technology, University of Turku
2Turku Centre for Computer Science (TUCS)
</affiliation>
<address confidence="0.936159">
Joukahaisenkatu 3-5, 20520 Turku, Finland
</address>
<email confidence="0.998404">
firstname.lastname@utu.fi
</email>
<sectionHeader confidence="0.995629" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997023">
We describe a system for extracting com-
plex events among genes and proteins from
biomedical literature, developed in context of
the BioNLP’09 Shared Task on Event Extrac-
tion. For each event, its text trigger, class, and
arguments are extracted. In contrast to the pre-
vailing approaches in the domain, events can
be arguments of other events, resulting in a
nested structure that better captures the under-
lying biological statements. We divide the task
into independent steps which we approach as
machine learning problems. We define a wide
array of features and in particular make ex-
tensive use of dependency parse graphs. A
rule-based post-processing step is used to re-
fine the output in accordance with the restric-
tions of the extraction task. In the shared task
evaluation, the system achieved an F-score of
51.95% on the primary task, the best perfor-
mance among the participants.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999644111111111">
In this paper, we present the best-performing system
in the primary task of the BioNLP’09 Shared Task
on Event Extraction (Kim et al., 2009).1 The pur-
pose of this shared task was to competitively eval-
uate information extraction systems targeting com-
plex events in the biomedical domain. Such an eval-
uation helps to establish the relative merits of com-
peting approaches, allowing direct comparability of
results in a controlled setting. The shared task was
</bodyText>
<footnote confidence="0.9818125">
1http://www-tsujii.is.s.u-tokyo.ac.jp/
GENIA/SharedTask
</footnote>
<page confidence="0.99124">
10
</page>
<bodyText confidence="0.999957235294118">
the first competitive evaluation of its kind in the
BioNLP field as the extraction of complex events
became possible only recently with the introduction
of corpora containing the necessary annotation: the
GENIA event corpus (Kim et al., 2008a) and the
BioInfer corpus (Pyysalo et al., 2007).
The objective of the primary task (Task 1) was
to detect biologically relevant events such as pro-
tein binding and phosphorylation, given only anno-
tation of named entities. For each event, its class,
trigger expression in the text, and arguments need to
be extracted. The task follows the recent movement
in BioNLP towards the extraction of semantically
typed, complex events the arguments of which can
also be other events. This results in a nested struc-
ture that captures the underlying biological state-
ments more accurately compared to the prevailing
approach of merely detecting binary interactions of
pairs of biological entities.
Our system is characterized by heavy reliance
on efficient, state-of-the-art machine learning tech-
niques and a wide array of features derived from
a full dependency analysis of each sentence. The
system is a pipeline of three major processing steps:
trigger recognition, argument detection and seman-
tic post-processing. By separating trigger recog-
nition from argument detection, we can use meth-
ods familiar from named entity recognition to tag
words as event triggers. Event argument detection
then becomes the task of predicting for each trigger–
trigger or trigger–named entity pair whether it cor-
responds to an actual instantiation of an event argu-
ment. Both steps can thus be approached as classi-
fication tasks. In contrast, semantic post-processing
</bodyText>
<note confidence="0.989615">
Proceedings of the Workshop on BioNLP: Shared Task, pages 10–18,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<figure confidence="0.824860833333333">
Conversion to graph
representation
Trigger detection
(multi-class SVM)
Edge detection
(multi-class SVM)
</figure>
<figureCaption confidence="0.99999">
Figure 1: The main components of the system.
</figureCaption>
<bodyText confidence="0.9998382">
is rule-based, directly implementing argument type
constraints following from the definition of the task.
In the following sections, we present the imple-
mentation of the three stages of our information ex-
traction system in detail, and provide insights into
why we chose the approach we did. We also discuss
alternate directions we followed but that did not im-
prove performance. Finally, we analyze the overall
performance of our system in the shared task as well
as evaluate its components individually.
</bodyText>
<sectionHeader confidence="0.749206" genericHeader="method">
2 The system description
</sectionHeader>
<bodyText confidence="0.999863285714286">
The overall architecture of the system is shown
in Figure 1. All steps in the system process one
sentence at a time. Since 95% of all annotated
events are fully contained within a single sentence,
this does not incur a large performance penalty but
greatly reduces the size and complexity of the ma-
chine learning problems.
</bodyText>
<subsectionHeader confidence="0.974028">
2.1 Graph representation
</subsectionHeader>
<bodyText confidence="0.998696066666667">
We represent the extraction target in terms of seman-
tic networks, graphs where the nodes correspond
to named entities and events, and the edges corre-
spond to event arguments. The shared task can then
be viewed as the problem of finding the nodes and
edges of this graph. For instance, nested events are
naturally represented through edges connecting two
event nodes. The graph representation of an exam-
ple sentence is illustrated in Figure 2D.
We have previously used this graph representa-
tion for information extraction (Heimonen et al.,
2008; Bj¨orne et al., 2009) as well as for establishing
the connection between events and syntactic depen-
dency parses in the Stanford scheme of de Marneffe
and Manning (2008) (Bj¨orne et al., 2008).
</bodyText>
<subsectionHeader confidence="0.998551">
2.2 Trigger detection
</subsectionHeader>
<bodyText confidence="0.999964282051282">
We cast trigger detection as a token labeling prob-
lem, that is, each token is assigned to an event class,
or a negative class if it does not belong to a trig-
ger. Triggers are then formed based on the predicted
classes of the individual tokens. Since 92% of all
triggers in the data consist of a single token, adjacent
tokens with the same class prediction form a single
trigger only in case that the resulting string occurs
as a trigger in the training data. An event node is
created for each detected trigger (Figure 2B).
In rare cases, the triggers of events of different
class share a token, thus the token belongs to sev-
eral separate classes. To be able to approach trigger
detection as a multi-class classification task where
each token is given a single prediction, we intro-
duce combined classes as needed. For instance the
class gene expression/positive regulation denotes to-
kens that act as a trigger to two events of the two
respective classes. Note that this implies that the
trigger detection step produces at most one event
node per class for any detected trigger. In the shared
task, however, multiple events of the same class can
share the same trigger. For instance, the trigger in-
volves in Figure 2 corresponds to two separate regu-
lation events. A separate post-processing step is in-
troduced after event argument detection to duplicate
event nodes as necessary (see Section 2.4).
Due to the nature of the GENIA event annota-
tion principles, trigger detection cannot be easily re-
duced to a simple dictionary lookup of trigger ex-
pressions for two main reasons. First, a number of
common textual expressions act as event triggers in
some cases, but not in other cases. For example,
only 28% of the instances of the expression activates
are triggers for a positive regulation event while the
remaining 72% are not triggers for any event. Sec-
ond, a single expression may be associated with var-
ious event classes. For example, the instances of the
token overexpression are evenly distributed among
</bodyText>
<figure confidence="0.994567307692308">
Sentence splitting
Tokenization
Parsing
Input data
Semantic post-processing
(rule-based)
System output
11
Training Data Preparation
Protein
Protein
Protein
Protein
IL-4 gene
IL-4 gene
IL-4 gene
IL-4 gene regulation involves
NN NN NN VBZ NN CC NN .
T7 Protein IL-4
T8 Protein NFAT1
T9 Protein NFAT2
&lt;nn
&lt;Theme
&lt;Theme &lt;Theme Cause&gt;
&lt;nn
Regulation
Regulation
Regulation
regulation
regulation
regulation
&lt;Theme
&lt;nsubj
&lt;Theme Cause&gt;
trigger recognition
node duplication
T29 Regulation regulation
T30 Regulation involves
E10 Regulation:T29 Theme:T7
E11 Regulation:T30 Theme:E10 Cause:T9
E12 Regulation:T30 Theme:E10 Cause:T8
edge detection
equivalent
Regulation
Regulation
Regulation
Regulation
involves
involves
involves
dobj&gt;
Protein
Protein
Protein
Protein
NFAT1 and
NFAT1 and
NFAT1 and
NFAT1 and
Cause&gt;
dobj&gt;
Cause&gt;
conj_and&gt;
Protein
Protein
Protein
Protein
NFAT2 .
NFAT2 .
NFAT2 .
NFAT2 .
parse
A
D
C
E
B
Event Extraction
</figure>
<figureCaption confidence="0.995028">
Figure 2: An example sentence from Shared Task document 10069428 (simplified). A) Named entities are given.
</figureCaption>
<bodyText confidence="0.958562358974359">
B) Triggers are detected and corresponding event nodes are created. C) Event argument edges are predicted between
nodes. The result is a sentence-level semantic network. D) One node may denote multiple events of the same class,
therefore nodes are duplicated in the semantic post-processing step. E) The resulting graph can be losslessly trans-
formed into the Shared Task event annotation. Training data for the trigger recognizer includes named entity annotation
(A) and for the edge detector the semantic network with no node duplication (C).
gene expression, positive regulation, and the nega-
tive class. In light of these properties, we address
trigger detection with a multi-class support vector
machine (SVM) classifier that assigns event classes
to individual tokens, one at a time. This is in con-
trast to sequence labeling problems such as named
entity recognition, where a sequential model is typ-
ically employed. The classifier is trained on gold-
standard triggers from the training data and incorpo-
rates a wide array of features capturing the proper-
ties of the token to be classified, both its linear and
dependency context, and the named entities within
the sentence.
Token features include binary tests for capital-
ization, presence of punctuation or numeric charac-
ters, stem using the Porter stemmer (Porter, 1980),
character bigrams and trigrams, and presence of the
token in a gazetteer of known trigger expressions
and their classes, extracted from the training data.
Token features are generated not only for the token
to be classified, but also for tokens in the immediate
linear context and dependency context (tokens that
govern or depend on the token to be classified).
Frequency features include the number of
named entities in the sentence and in a linear win-
dow around the token in question as well as bag-of-
word counts of token texts in the sentence.
Dependency chains up to depth of three are
constructed, starting from the token to be classified.
At each depth, both token features and dependency
type are included, as well as the sequence of depen-
dency types in the chain.
The trigger detector used in the shared task is
in fact a weighted combination of two indepen-
</bodyText>
<page confidence="0.993061">
12
</page>
<bodyText confidence="0.999981315789474">
dent SVM trigger detectors, both based on the same
multi-class classification principle and somewhat
different feature sets.2 The predictions of the two
trigger detectors are combined as follows. For each
trigger detector and each token, the classifier confi-
dence scores of the top five classes are re-normalized
into the [0, 1] interval. The renormalized confidence
scores of the two detectors are then linearly inter-
polated using a parameter A, 0 &lt; A &lt; 1, whose
value is set experimentally on the development set,
as discussed below.
Setting the correct precision–recall trade-off in
trigger detection is very important. On one hand,
any trigger left undetected directly implies a false
negative event. On the other hand, the edge detec-
tor is trained on gold standard data where there are
no event nodes without arguments, which creates a
bias toward predicting edges for any event node the
edge detector is presented with. On the develop-
ment set, essentially all predicted event nodes are
given at least one argument edge. We optimize the
precision–recall trade-off explicitly by introducing a
parameter Q, 0 &lt; Q, that multiplies the classifier
confidence score given to the negative class, that is,
the “no trigger” class. When Q &lt; 1, the confidence
of the negative class is decreased, thus increasing
the possibility of a given token forming a trigger,
and consequently increasing the recall of the trigger
detector (naturally, at the expense of its precision).
Both trigger detection parameters, the interpola-
tion weight A and the precision–recall trade-off pa-
rameter Q, are set experimentally using a grid search
to find the globally optimal performance of the en-
tire system on the development set, using the shared
task performance metric. The parameters are thus
not set to optimize the performance of trigger detec-
tion in isolation; they are rather set to optimize the
performance of the whole system.
</bodyText>
<subsectionHeader confidence="0.996771">
2.3 Edge detection
</subsectionHeader>
<bodyText confidence="0.94480325">
After trigger detection, edge detection is used to pre-
dict the edges of the semantic graph, thus extracting
event arguments. Like the trigger detector, the edge
detector is based on a multi-class SVM classifier.
We generate examples for all potential edges, which
2This design should be considered an artifact of the time-
constrained, experiment-driven development of the system
rather than a principled design choice.
</bodyText>
<figure confidence="0.957343">
0 1 2 3 4 5 6 7 8 9 10 &gt;10
Edge length
</figure>
<figureCaption confidence="0.9977642">
Figure 3: The distribution of event argument edge lengths
measured as the number of dependencies on the shortest
dependency path between the edge terminal nodes, con-
trasted with edge lengths measured as the linear token
distance.
</figureCaption>
<bodyText confidence="0.999949466666667">
are always directed from an event node to another
event node (event nesting) or from an event node to
a named entity node. Each example is then classified
as theme, cause, or a negative denoting the absence
of an edge between the two nodes in the given di-
rection. It should be noted that even though event
nodes often require multiple outgoing edges corre-
sponding to multiple event arguments, all edges are
predicted independently and are not affected by pos-
itive or negative classifications of other edges.
The feature set makes extensive use of syntac-
tic dependencies, in line with many recent stud-
ies in biomedical information extraction (see, e.g.
(Kim et al., 2008b; Miwa et al., 2008; Airola et al.,
2008; Van Landeghem et al., 2008; Katrenko and
Adriaans, 2008)). The central concept in generat-
ing features of potential event argument edges is the
shortest undirected path of syntactic dependencies
in the Stanford scheme parse of the sentence which
we assume to accurately capture the relationship ex-
pressed by the edge. In Figure 3, we show that the
distances among event and named entity nodes in
terms of shortest dependency path length are con-
siderably shorter than in terms of their linear order in
the sentence. The end points of the path are the syn-
tactic head tokens of the two named entities or event
triggers. The head tokens are identified using a sim-
ple heuristic. Where multiple shortest paths exist,
all are considered. Most features are built by com-
bining the attributes of multiple tokens (token text,
</bodyText>
<figure confidence="0.993662642857143">
dependency distance
linear distance
50
45
Proportion of edges [%]
40
35
30
25
20
15
10
5
0
</figure>
<page confidence="0.994821">
13
</page>
<bodyText confidence="0.999891236842105">
POS tag and entity or event class, such as protein or
binding) or dependencies (type such as subject and
direction relative to surrounding tokens).
N-grams are generated by merging the at-
tributes of 2–4 consecutive tokens. N-grams are also
built for consecutive dependencies. Additional tri-
grams are built for each token and its two flank-
ing dependencies, as well as for each dependency
and its two flanking tokens. These N-grams are de-
fined in the direction of the potential event argument
edge. To take into account the varying directions
of the dependencies, each pair of consecutive tokens
forms an additional bigram defining their governor-
dependent relationship.
Individual component features are defined for
each token and edge in a path based on their
attributes which are also combined with the to-
ken/edge position at either the interior or the end of
the path. Edge attributes are combined with their di-
rection relative to the path.
Semantic node features are built by directly
combining the attributes of the two terminal
event/entity nodes of the potential event argument
edge. These features concatenate both the specific
types of the nodes (e.g. protein or binding) as well
as their categories (event or named entity). Finally,
if the events/entities have the same head token, this
self-loop is explicitly defined as a feature.
Frequency features include the length of the
shortest path as an integer-valued feature as well as
an explicit binary feature for each length. The num-
ber of named entities and event nodes, per type, in
the sentence are defined for each example.
We have used this type of edge detector with a
largely similar feature set previously (Bj¨orne et al.,
2009). Also, many of these features are standard
in relation extraction studies (see, e.g., Buyko et al.
(2008)).
</bodyText>
<subsectionHeader confidence="0.990126">
2.4 Semantic post-processing
</subsectionHeader>
<bodyText confidence="0.999530375">
The semantic graph produced by the trigger and
edge detection steps is not final. In particular, it
may contain event nodes with an improper combi-
nation of arguments, or no arguments whatsoever.
Additionally, as discussed in Section 2.2, if there are
events of the same class with the same trigger, they
are represented by a single node. Therefore, we in-
troduce a rule-based post-processing step to refine
</bodyText>
<figureCaption confidence="0.9952465">
Figure 4: Example of event duplication. A) All theme–
cause combinations are generated for regulation events.
B) A heuristic is applied to decide how theme arguments
of binding events should be grouped.
</figureCaption>
<bodyText confidence="0.99897746875">
the graph, using the restrictions on event argument
types and combinations defined in the shared task.
In Task 1, the allowed argument edges in the
graph are 1) theme from an event to a named en-
tity, 2) theme or cause from a regulation event (or its
subclasses) to an event or a named entity. Edges cor-
responding to invalid arguments are removed. Also,
directed cycles are broken by removing the edge
with the weakest classification confidence score.
After pruning invalid edges, event nodes are du-
plicated so that all events have a valid combination
of arguments. For example, the regulation event in-
volves in Figure 2C has two cause arguments and
therefore represents two distinct events. We thus
duplicate the event node, obtaining one regulation
event for each of the cause arguments (Figure 2D).
Events of type gene expression, transcription,
translation, protein catabolism, localization, and
phosphorylation must have exactly one theme argu-
ment, which makes the duplication process trivial:
duplicate events are created, one for each of the ar-
guments. Regulation events must have one theme
and can additionally have one cause argument. For
these classes we use a heuristic, generating a new
event for each theme–cause combination of outgo-
ing edges (Figure 4A). Binding is the only event
class that can have multiple theme arguments. There
is thus no simple way of determining how multi-
ple outgoing theme edges should be grouped (Fig-
ure 4B). We apply a heuristic that first groups the ar-
guments by their syntactic role, defined here as xthe
first dependency in the shortest path from the event
</bodyText>
<page confidence="0.997882">
14
</page>
<bodyText confidence="0.9996398">
to the argument. It then generates an event for each
pair of arguments that are in different groups. In the
case of only one group, all single-argument events
are generated.
Finally, all events with no arguments as well as
regulation events without a theme argument are iter-
atively removed until no such event remains. The
resulting graph is the output of our event extrac-
tion system and can be losslessly converted into the
shared task format (Figure 2D&amp;E).
</bodyText>
<subsectionHeader confidence="0.991805">
2.5 Alternative directions
</subsectionHeader>
<bodyText confidence="0.999992854545455">
We now briefly describe some of the alternative di-
rections explored during the system development,
which however did not result in increased perfor-
mance, and were thus not included in the final sys-
tem. Whether the reason was due to the considered
approaches being inadequate for the extraction task,
or simply a result of the tight time constraints en-
forced by the shared task is a question only further
research can shed light on.
For the purpose of dividing the extraction prob-
lem into manageable subproblems, we make strong
independence assumptions. This is particularly the
case in the edge detection phase where each edge
is considered in isolation from other edges, some
of which may actually be associated with the same
event. Similar assumptions are made in the trigger
detection phase, where the classifications of individ-
ual tokens are independent.
A common way to relax independence assump-
tions is to use N-best re-ranking where N most-
likely candidates are re-ranked using global features
that model data dependencies that could not be mod-
elled in the candidate generation step. The best can-
didate with respect to this re-ranked order is then
the final prediction of the system. N-best re-ranking
has been successfully applied for example in statisti-
cal parsing (Charniak and Johnson, 2005). We gen-
erated the ten most likely candidate graphs, as de-
termined by the confidence scores of the individual
edges given by the multi-class SVM. A perfect re-
ranking of these ten candidates would lead to 11.5
percentage point improvement in the overall system
F-score on the development set. While we were un-
able to produce a re-ranker sufficiently accurate to
improve the system performance in the time given,
the large potential gain warrants further research.
In trigger word detection, we experimented with
a structural SVM incorporating Hidden Markov
Model type of sequential dependencies (Altun et al.,
2003; Tsochantaridis et al., 2004), which allow con-
ditioning classification decisions on decisions made
for previous tokens as well as with a conditional ran-
dom field (CRF) sequence classifier (Lafferty et al.,
2001). Neither of these experiments led to a perfor-
mance gain over the multiclass SVM classifier.
As discussed previously, 4.8% of all annotated
events cross sentence boundaries. This problem
could be approached using coreference resolution
techniques, however, the necessary explicit corefer-
ence annotation to train a coreference resolution sys-
tem is not present in the data. Instead, we attempted
to build a machine-learning based system to detect
cross-sentence event arguments directly, rather than
via their referring expression, but were unable to im-
prove the system performance.
</bodyText>
<sectionHeader confidence="0.839275" genericHeader="method">
3 Tools and resources
</sectionHeader>
<subsectionHeader confidence="0.995676">
3.1 Multi-class SVM
</subsectionHeader>
<bodyText confidence="0.999921">
We use a support vector machine (SVM) multi-class
classifier which has been shown to have state-of-
the-art classification performance (see e.g. (Cram-
mer and Singer, 2002; Tsochantaridis et al., 2004)).
Namely, we use the SVMmulticlass implementa-
tion3 which is one of the fastest multi-class SVM
implementations currently available. Analogously
to the binary SVMs, multi-class SVMs have a reg-
ularization parameter that determines the trade-off
between the training error and the complexity of the
learned concept. We select the value of the parame-
ter on the development set. Multi-class SVMs scale
linearly with respect to both the amount of training
data and the average number of nonzero features per
training example, making them an especially suit-
able learning method for our purposes. They also
provide a real-valued prediction for each example
to be classified which is used as a confidence score
in trigger detection precision–recall trade-off adjust-
ment and event argument edge cycle breaking in se-
mantic post-processing. We use the linear kernel,
the only practical choice to train the classifier with
the large training sets available. For example, the
</bodyText>
<footnote confidence="0.961279">
3http://svmlight.joachims.org/svm_
multiclass.html
</footnote>
<page confidence="0.979365">
15
</page>
<figure confidence="0.996564818181818">
80
70
60
50
40
30
20
10
0
0 10 20 30 40 50 60 70 80
Precision [%]
</figure>
<figureCaption confidence="0.995977666666667">
Figure 5: Performance of the 24 systems that participated
in Task 1, together with an F-score contour plot for refer-
ence. Our system is marked with a full circle.
</figureCaption>
<bodyText confidence="0.999876307692308">
final training data of the edge detector (8932 sen-
tences) consists of 31792 training examples with
295034 unique features. Training with even this
amount of data is computationally feasible, typically
taking less than an hour.
All classifiers used in the system are trained as
follows. First we optimize the regularization param-
eter C by training on the shared task training set and
testing on the shared task development set. We then
re-train the final classifier on the union of the train-
ing and development sets, using the best value of C
in the previous step. The same protocol is followed
for the A and Q parameters in trigger detection.
</bodyText>
<subsectionHeader confidence="0.999654">
3.2 Dependency parses
</subsectionHeader>
<bodyText confidence="0.999975363636364">
Both trigger detection and edge prediction rely on
a wide array of features derived from full depen-
dency parses of the sentence. We use the McClosky-
Charniak domain-adapted parser (McClosky and
Charniak, 2008) which is among the best perform-
ing parsers trained on the GENIA Treebank corpus.
The native constituency output of the parser is trans-
formed to the “collapsed” form of the Stanford de-
pendency scheme (de Marneffe and Manning, 2008)
using the Stanford parser tools.4 The parses were
provided by the shared task organizers.
</bodyText>
<sectionHeader confidence="0.998404" genericHeader="evaluation">
4 Results and discussion
</sectionHeader>
<bodyText confidence="0.961912">
The final evaluation of the system was performed by
the shared task organizers using a test set whose an-
</bodyText>
<footnote confidence="0.871599">
4http://nlp.stanford.edu/software/
</footnote>
<bodyText confidence="0.9999738125">
notation was at no point available to the task partici-
pants. By the main criterion of Task 1, approximate
span matching with approximate recursive match-
ing, our system achieved an F-score of 51.95%. Fig-
ure 5 shows the performance of all systems partic-
ipating in Task 1. The per-class results in Table 1
show that regulation events (including positive and
negative regulation) as well as binding events are the
hardest to extract. These classes have F-scores in
the 31–44% range, while the other classes fall into
the 50–78% range. This is not particularly surpris-
ing since binding and regulation are the only classes
in which events can have multiple arguments, which
means that for an event to be detected correctly, the
edge detector often must make several correct pre-
dictions. Additionally, these classes have the lowest
trigger recognition performance on the development
set. It is interesting to note that the per-class perfor-
mance in Table 1 shows no clear correlation between
the number of events of a class and its F-score.
Table 2 shows the performance of the system us-
ing various other evaluation criteria defined in the
shared task. The most interesting of these is the
strict matching criterion, which, in order to consider
an event correctly extracted, requires exact trigger
span as well as all its nested events to be recursively
correct. The performance of the system with respect
to the strict criterion is 47.41% F-score, only 4.5 per-
centage points lower than the relaxed primary mea-
sure. As seen in Table 2, this difference is almost
exclusively due to triggers with incorrect span.
To evaluate the performance impact of each sys-
tem component individually, we report in Table 3
overall system performance on the development set,
obtained by progressively replacing the processing
steps with gold-standard data. The results show that
the errors of the system are almost evenly distributed
between the trigger and edge detectors. For instance,
a perfect trigger detector would decrease the overall
system error of 46.5% by 18.58 percentage points,
a relative decrease of 40%. A perfect edge detec-
tor would, in combination with a perfect trigger de-
tector, lead to system performance of 94.69%. The
improvement that could be gained by further devel-
opment of the semantic post-processing step is thus
limited, indicating that the strict argument combina-
tion restrictions of Task 1 are sufficient to resolve the
majority of post-processing cases.
</bodyText>
<equation confidence="0.668502">
Recall [%]
</equation>
<page confidence="0.895725">
16
</page>
<table confidence="0.999382090909091">
Event Class # R P F
Protein catabolism 14 42.86 66.67 52.17
Phosphorylation 135 80.74 74.66 77.58
Transcription 137 39.42 69.23 50.23
Localization 174 49.43 81.90 61.65
Regulation 291 25.43 38.14 30.52
Binding 347 40.06 49.82 44.41
Negative regulation 379 35.36 43.46 38.99
Gene expression 722 69.81 78.50 73.90
Positive regulation 983 38.76 48.72 43.17
Total 3182 46.73 58.48 51.95
</table>
<tableCaption confidence="0.985252">
Table 1: Per-class performance in terms of Recall, Preci-
sion, and F-score on the test set (3182 events) using ap-
proximate span and recursive matching, the primary eval-
uation criterion of Task 1.
</tableCaption>
<table confidence="0.9997875">
Matching R P F
Strict 42.65 53.38 47.41
Approx. Span 46.51 58.24 51.72
Approx. Span&amp;Recursive 46.73 58.48 51.95
</table>
<tableCaption confidence="0.967549">
Table 2: Performance of our system on the test set (3182
events) with respect to other evaluation measures in the
shared task.
</tableCaption>
<sectionHeader confidence="0.99868" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999235272727273">
We have described a system for extracting complex,
typed events from biomedical literature, only assum-
ing named entities as given knowledge. The high
rank achieved in the BioNLP’09 Shared Task com-
petitive evaluation validates the approach taken in
building the system. While the performance is cur-
rently the highest achieved on this data, the F-score
of 51.95% indicates that there remains considerable
room for further development and improvement.
We use a unified graph representation of the data
in which the individual processing steps can be for-
mulated as simple graph transformations: adding or
removing nodes and edges. It is our experience that
such a representation makes handling the data fast,
easy and consistent. The choice of graph representa-
tion is further motivated by the close correlation of
these graphs with dependency parses. As we are go-
ing to explore the interpretation and applications of
these graphs in the future, the graph representation
will likely provide a flexible base to build on.
Dividing the task of event extraction into multi-
ple subtasks that can be approached by well-studied
</bodyText>
<table confidence="0.994587">
Trig Edge PP R P F ΔF
pred pred pred 51.54 55.62 53.50
GS pred pred 71.66 72.51 72.08 18.58
GS GS pred 97.21 92.30 94.69 22.61
GS GS GS 100.0 100.0 100.0 5.31
</table>
<tableCaption confidence="0.998558">
Table 3: Effect of the trigger detector (Trig), edge detec-
</tableCaption>
<bodyText confidence="0.936825484848485">
tor (Edge), and post-processing (PP) on performance on
the development set (1789 events). The ΔF column in-
dicates the effect of replacing the predictions (pred) of
a component with the corresponding gold standard data
(GS), i.e. the maximal possible performance gain obtain-
able from further development of that component.
methods proved to be an effective approach in de-
veloping our system. We relied on state-of-the-art
machine learning techniques that scale up to the task
and allow the use of a considerable number of fea-
tures. We also carefully optimized the various pa-
rameters, a vital step when using machine learning
methods, to fine-tune the performance of the system.
In Section 2.5, we discussed alternative directions
pursued during the development of the current sys-
tem, indicating possible future research directions.
To support this future work as well as complement
the description of the system in this paper we intend
to publish our system under an open-source license.
This shared task represents the first competi-
tive evaluation of complex event extraction in the
biomedical domain. The prior research has largely
focused on binary interaction extraction, achieving
after a substantial research effort F-scores of slightly
over 60% (see, e.g., Miwa et al. (2008)) on AIMed,
the de facto standard corpus for this task. Even if
a direct comparison of these results is difficult, they
suggest that 52% F-score in complex event extrac-
tion is a non-trivial achievement, especially consid-
ering the more detailed semantics of the extracted
events. Further, complex event extraction is still a
new problem — relevant corpora having been avail-
able for only a few years.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998338">
This research was funded by the Academy of Fin-
land. Computational resources were provided by
CSC — IT Center for Science Ltd. We thank the
shared task organizers for their efforts in data prepa-
ration and system evaluation.
</bodyText>
<page confidence="0.998691">
17
</page>
<sectionHeader confidence="0.995887" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99972012244898">
Antti Airola, Sampo Pyysalo, Jari Bj¨orne, Tapio
Pahikkala, Filip Ginter, and Tapio Salakoski. 2008.
All-paths graph kernel for protein-protein interaction
extraction with evaluation of cross-corpus learning.
BMC Bioinformatics, 9(Suppl 11):S2.
Yasemin Altun, Ioannis Tsochantaridis, and Thomas
Hofmann. 2003. Hidden Markov support vector ma-
chines. In Proceedings of the Twentieth International
Conference on Machine Learning (ICML’03), pages
3–10. AAAI Press.
Jari Bj¨orne, Sampo Pyysalo, Filip Ginter, and Tapio
Salakoski. 2008. How complex are complex
protein-protein interactions? In Proceedings of the
Third International Symposium on Semantic Mining in
Biomedicine (SMBM’08), pages 125–128. TUCS.
Jari Bj¨orne, Filip Ginter, Juho Heimonen, Sampo
Pyysalo, and Tapio Salakoski. 2009. Learning to ex-
tract biological event and relation graphs. In Proceed-
ings of the 17th Nordic Conference on Computational
Linguistics (NODALIDA’09).
Ekaterina Buyko, Elena Beisswanger, and Udo Hahn.
2008. Testing different ACE-style feature sets for
the extraction of gene regulation relations from MED-
LINE abstracts. In Proceedings of the Third Interna-
tional Symposium on Semantic Mining in Biomedicine
(SMBM’08), pages 21–28. TUCS.
Eugene Charniak and Mark Johnson. 2005. Coarse-to-
fine n-best parsing and maxent discriminative rerank-
ing. In Proceedings of the 43rd Annual Meeting of the
Association for Computational Linguistics (ACL’05),
pages 173–180. ACL.
Koby Crammer and Yoram Singer. 2002. On the al-
gorithmic implementation of multiclass kernel-based
vector machines. Journal of Machine Learning Re-
search, 2:265–292.
Marie-Catherine de Marneffe and Christopher Manning.
2008. Stanford typed hierarchies representation. In
Proceedings of the COLING’08 Workshop on Cross-
Framework and Cross-Domain Parser Evaluation,
pages 1–8.
Juho Heimonen, Sampo Pyysalo, Filip Ginter, and Tapio
Salakoski. 2008. Complex-to-pairwise mapping of
biological relationships using a semantic network rep-
resentation. In Proceedings of the Third Interna-
tional Symposium on Semantic Mining in Biomedicine
(SMBM’08), pages 45–52. TUCS.
Sophia Katrenko and Pieter Adriaans. 2008. A local
alignment kernel in the context of NLP. In Proceed-
ings of the 22nd International Conference on Compu-
tational Linguistics (Coling’08).
Jin-Dong Kim, Tomoko Ohta, and Tsujii Jun’ichi. 2008a.
Corpus annotation for mining biomedical events from
literature. BMC Bioinformatics, 9(1):10.
Seonho Kim, Juntae Yoon, and Jihoon Yang. 2008b.
Kernel approaches for genic interaction extraction.
Bioinformatics, 24(1):118–126.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun’ichi Tsujii. 2009. Overview
of BioNLP’09 shared task on event extraction. In
Proceedings of the NAACL-HLT 2009 Workshop
on Natural Language Processing in Biomedicine
(BioNLP’09). ACL.
John Lafferty, Andrew McCallum, and Fernando Pereira.
2001. Conditional random fields: Probabilistic mod-
els for segmenting and labeling sequence data. In Pro-
ceedings of the 18th International Conference on Ma-
chine Learning (ICML’01), pages 282–289.
David McClosky and Eugene Charniak. 2008. Self-
training for biomedical parsing. In Proceedings of
ACL-08: HLT, Short Papers, pages 101–104. Associa-
tion for Computational Linguistics.
Makoto Miwa, Rune Sætre, Yusuke Miyao, Tomoko
Ohta, and Jun’ichi Tsujii. 2008. Combining
multiple layers of syntactic information for protein-
protein interaction extraction. In Proceedings of the
Third International Symposium on Semantic Mining in
Biomedicine (SMBM’08), pages 101–108. TUCS.
Martin F. Porter. 1980. An algorithm for suffix stripping.
Program, 14(3):130–137.
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Bj¨orne, Jorma Boberg, Jouni J¨arvinen, and Tapio
Salakoski. 2007. BioInfer: A corpus for information
extraction in the biomedical domain. BMC Bioinfor-
matics, 8(1):50.
Ioannis Tsochantaridis, Thomas Hofmann, Thorsten
Joachims, and Yasemin Altun. 2004. Support vec-
tor machine learning for interdependent and structured
output spaces. In Proceedings of the Twenty-first Inter-
national
wentyfirstInter-
national Conference on Machine Learning (ICML’04),
pages 104–111. ACM.
Sofie Van Landeghem, Yvan Saeys, Bernard De Baets,
and Yves Van de Peer. 2008. Extracting protein-
protein interactions from text using rich feature vec-
tors and feature selection. In Proceedings of the
Third International Symposium on Semantic Mining in
Biomedicine (SMBM’08), pages 77–84. TUCS.
</reference>
<page confidence="0.999283">
18
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.778605">
<title confidence="0.999939">Extracting Complex Biological Events with Rich Graph-Based Feature Sets</title>
<author confidence="0.993272">Filip</author>
<affiliation confidence="0.990763">of Information Technology, University of Centre for Computer Science</affiliation>
<address confidence="0.803486">Joukahaisenkatu 3-5, 20520 Turku,</address>
<email confidence="0.998432">firstname.lastname@utu.fi</email>
<abstract confidence="0.999482904761905">We describe a system for extracting complex events among genes and proteins from biomedical literature, developed in context of the BioNLP’09 Shared Task on Event Extraction. For each event, its text trigger, class, and arguments are extracted. In contrast to the prevailing approaches in the domain, events can be arguments of other events, resulting in a nested structure that better captures the underlying biological statements. We divide the task into independent steps which we approach as machine learning problems. We define a wide array of features and in particular make extensive use of dependency parse graphs. A rule-based post-processing step is used to refine the output in accordance with the restrictions of the extraction task. In the shared task evaluation, the system achieved an F-score of 51.95% on the primary task, the best performance among the participants.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Antti Airola</author>
<author>Sampo Pyysalo</author>
<author>Jari Bj¨orne</author>
<author>Tapio Pahikkala</author>
<author>Filip Ginter</author>
<author>Tapio Salakoski</author>
</authors>
<title>All-paths graph kernel for protein-protein interaction extraction with evaluation of cross-corpus learning.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<pages>11--2</pages>
<marker>Airola, Pyysalo, Bj¨orne, Pahikkala, Ginter, Salakoski, 2008</marker>
<rawString>Antti Airola, Sampo Pyysalo, Jari Bj¨orne, Tapio Pahikkala, Filip Ginter, and Tapio Salakoski. 2008. All-paths graph kernel for protein-protein interaction extraction with evaluation of cross-corpus learning. BMC Bioinformatics, 9(Suppl 11):S2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yasemin Altun</author>
<author>Ioannis Tsochantaridis</author>
<author>Thomas Hofmann</author>
</authors>
<title>Hidden Markov support vector machines.</title>
<date>2003</date>
<booktitle>In Proceedings of the Twentieth International Conference on Machine Learning (ICML’03),</booktitle>
<pages>3--10</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="21291" citStr="Altun et al., 2003" startWordPosition="3433" endWordPosition="3436">2005). We generated the ten most likely candidate graphs, as determined by the confidence scores of the individual edges given by the multi-class SVM. A perfect reranking of these ten candidates would lead to 11.5 percentage point improvement in the overall system F-score on the development set. While we were unable to produce a re-ranker sufficiently accurate to improve the system performance in the time given, the large potential gain warrants further research. In trigger word detection, we experimented with a structural SVM incorporating Hidden Markov Model type of sequential dependencies (Altun et al., 2003; Tsochantaridis et al., 2004), which allow conditioning classification decisions on decisions made for previous tokens as well as with a conditional random field (CRF) sequence classifier (Lafferty et al., 2001). Neither of these experiments led to a performance gain over the multiclass SVM classifier. As discussed previously, 4.8% of all annotated events cross sentence boundaries. This problem could be approached using coreference resolution techniques, however, the necessary explicit coreference annotation to train a coreference resolution system is not present in the data. Instead, we atte</context>
</contexts>
<marker>Altun, Tsochantaridis, Hofmann, 2003</marker>
<rawString>Yasemin Altun, Ioannis Tsochantaridis, and Thomas Hofmann. 2003. Hidden Markov support vector machines. In Proceedings of the Twentieth International Conference on Machine Learning (ICML’03), pages 3–10. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jari Bj¨orne</author>
<author>Sampo Pyysalo</author>
<author>Filip Ginter</author>
<author>Tapio Salakoski</author>
</authors>
<title>How complex are complex protein-protein interactions?</title>
<date>2008</date>
<booktitle>In Proceedings of the Third International Symposium on Semantic Mining in Biomedicine (SMBM’08),</booktitle>
<pages>125--128</pages>
<publisher>TUCS.</publisher>
<marker>Bj¨orne, Pyysalo, Ginter, Salakoski, 2008</marker>
<rawString>Jari Bj¨orne, Sampo Pyysalo, Filip Ginter, and Tapio Salakoski. 2008. How complex are complex protein-protein interactions? In Proceedings of the Third International Symposium on Semantic Mining in Biomedicine (SMBM’08), pages 125–128. TUCS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jari Bj¨orne</author>
<author>Filip Ginter</author>
<author>Juho Heimonen</author>
<author>Sampo Pyysalo</author>
<author>Tapio Salakoski</author>
</authors>
<title>Learning to extract biological event and relation graphs.</title>
<date>2009</date>
<booktitle>In Proceedings of the 17th Nordic Conference on Computational Linguistics (NODALIDA’09).</booktitle>
<marker>Bj¨orne, Ginter, Heimonen, Pyysalo, Salakoski, 2009</marker>
<rawString>Jari Bj¨orne, Filip Ginter, Juho Heimonen, Sampo Pyysalo, and Tapio Salakoski. 2009. Learning to extract biological event and relation graphs. In Proceedings of the 17th Nordic Conference on Computational Linguistics (NODALIDA’09).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Buyko</author>
<author>Elena Beisswanger</author>
<author>Udo Hahn</author>
</authors>
<title>Testing different ACE-style feature sets for the extraction of gene regulation relations from MEDLINE abstracts.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third International Symposium on Semantic Mining in Biomedicine (SMBM’08),</booktitle>
<pages>21--28</pages>
<publisher>TUCS.</publisher>
<contexts>
<context position="16647" citStr="Buyko et al. (2008)" startWordPosition="2675" endWordPosition="2678"> well as their categories (event or named entity). Finally, if the events/entities have the same head token, this self-loop is explicitly defined as a feature. Frequency features include the length of the shortest path as an integer-valued feature as well as an explicit binary feature for each length. The number of named entities and event nodes, per type, in the sentence are defined for each example. We have used this type of edge detector with a largely similar feature set previously (Bj¨orne et al., 2009). Also, many of these features are standard in relation extraction studies (see, e.g., Buyko et al. (2008)). 2.4 Semantic post-processing The semantic graph produced by the trigger and edge detection steps is not final. In particular, it may contain event nodes with an improper combination of arguments, or no arguments whatsoever. Additionally, as discussed in Section 2.2, if there are events of the same class with the same trigger, they are represented by a single node. Therefore, we introduce a rule-based post-processing step to refine Figure 4: Example of event duplication. A) All theme– cause combinations are generated for regulation events. B) A heuristic is applied to decide how theme argume</context>
</contexts>
<marker>Buyko, Beisswanger, Hahn, 2008</marker>
<rawString>Ekaterina Buyko, Elena Beisswanger, and Udo Hahn. 2008. Testing different ACE-style feature sets for the extraction of gene regulation relations from MEDLINE abstracts. In Proceedings of the Third International Symposium on Semantic Mining in Biomedicine (SMBM’08), pages 21–28. TUCS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarse-tofine n-best parsing and maxent discriminative reranking.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>173--180</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="20678" citStr="Charniak and Johnson, 2005" startWordPosition="3335" endWordPosition="3338">me of which may actually be associated with the same event. Similar assumptions are made in the trigger detection phase, where the classifications of individual tokens are independent. A common way to relax independence assumptions is to use N-best re-ranking where N mostlikely candidates are re-ranked using global features that model data dependencies that could not be modelled in the candidate generation step. The best candidate with respect to this re-ranked order is then the final prediction of the system. N-best re-ranking has been successfully applied for example in statistical parsing (Charniak and Johnson, 2005). We generated the ten most likely candidate graphs, as determined by the confidence scores of the individual edges given by the multi-class SVM. A perfect reranking of these ten candidates would lead to 11.5 percentage point improvement in the overall system F-score on the development set. While we were unable to produce a re-ranker sufficiently accurate to improve the system performance in the time given, the large potential gain warrants further research. In trigger word detection, we experimented with a structural SVM incorporating Hidden Markov Model type of sequential dependencies (Altun</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Eugene Charniak and Mark Johnson. 2005. Coarse-tofine n-best parsing and maxent discriminative reranking. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 173–180. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>On the algorithmic implementation of multiclass kernel-based vector machines.</title>
<date>2002</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>2--265</pages>
<contexts>
<context position="22294" citStr="Crammer and Singer, 2002" startWordPosition="3582" endWordPosition="3586">aries. This problem could be approached using coreference resolution techniques, however, the necessary explicit coreference annotation to train a coreference resolution system is not present in the data. Instead, we attempted to build a machine-learning based system to detect cross-sentence event arguments directly, rather than via their referring expression, but were unable to improve the system performance. 3 Tools and resources 3.1 Multi-class SVM We use a support vector machine (SVM) multi-class classifier which has been shown to have state-ofthe-art classification performance (see e.g. (Crammer and Singer, 2002; Tsochantaridis et al., 2004)). Namely, we use the SVMmulticlass implementation3 which is one of the fastest multi-class SVM implementations currently available. Analogously to the binary SVMs, multi-class SVMs have a regularization parameter that determines the trade-off between the training error and the complexity of the learned concept. We select the value of the parameter on the development set. Multi-class SVMs scale linearly with respect to both the amount of training data and the average number of nonzero features per training example, making them an especially suitable learning metho</context>
</contexts>
<marker>Crammer, Singer, 2002</marker>
<rawString>Koby Crammer and Yoram Singer. 2002. On the algorithmic implementation of multiclass kernel-based vector machines. Journal of Machine Learning Research, 2:265–292.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Christopher Manning</author>
</authors>
<title>Stanford typed hierarchies representation.</title>
<date>2008</date>
<booktitle>In Proceedings of the COLING’08 Workshop on CrossFramework and Cross-Domain Parser Evaluation,</booktitle>
<pages>1--8</pages>
<marker>de Marneffe, Manning, 2008</marker>
<rawString>Marie-Catherine de Marneffe and Christopher Manning. 2008. Stanford typed hierarchies representation. In Proceedings of the COLING’08 Workshop on CrossFramework and Cross-Domain Parser Evaluation, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juho Heimonen</author>
<author>Sampo Pyysalo</author>
<author>Filip Ginter</author>
<author>Tapio Salakoski</author>
</authors>
<title>Complex-to-pairwise mapping of biological relationships using a semantic network representation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third International Symposium on Semantic Mining in Biomedicine (SMBM’08),</booktitle>
<pages>45--52</pages>
<publisher>TUCS.</publisher>
<contexts>
<context position="5163" citStr="Heimonen et al., 2008" startWordPosition="794" endWordPosition="797">ize and complexity of the machine learning problems. 2.1 Graph representation We represent the extraction target in terms of semantic networks, graphs where the nodes correspond to named entities and events, and the edges correspond to event arguments. The shared task can then be viewed as the problem of finding the nodes and edges of this graph. For instance, nested events are naturally represented through edges connecting two event nodes. The graph representation of an example sentence is illustrated in Figure 2D. We have previously used this graph representation for information extraction (Heimonen et al., 2008; Bj¨orne et al., 2009) as well as for establishing the connection between events and syntactic dependency parses in the Stanford scheme of de Marneffe and Manning (2008) (Bj¨orne et al., 2008). 2.2 Trigger detection We cast trigger detection as a token labeling problem, that is, each token is assigned to an event class, or a negative class if it does not belong to a trigger. Triggers are then formed based on the predicted classes of the individual tokens. Since 92% of all triggers in the data consist of a single token, adjacent tokens with the same class prediction form a single trigger only </context>
</contexts>
<marker>Heimonen, Pyysalo, Ginter, Salakoski, 2008</marker>
<rawString>Juho Heimonen, Sampo Pyysalo, Filip Ginter, and Tapio Salakoski. 2008. Complex-to-pairwise mapping of biological relationships using a semantic network representation. In Proceedings of the Third International Symposium on Semantic Mining in Biomedicine (SMBM’08), pages 45–52. TUCS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sophia Katrenko</author>
<author>Pieter Adriaans</author>
</authors>
<title>A local alignment kernel in the context of NLP.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (Coling’08).</booktitle>
<contexts>
<context position="13995" citStr="Katrenko and Adriaans, 2008" startWordPosition="2233" endWordPosition="2236">hen classified as theme, cause, or a negative denoting the absence of an edge between the two nodes in the given direction. It should be noted that even though event nodes often require multiple outgoing edges corresponding to multiple event arguments, all edges are predicted independently and are not affected by positive or negative classifications of other edges. The feature set makes extensive use of syntactic dependencies, in line with many recent studies in biomedical information extraction (see, e.g. (Kim et al., 2008b; Miwa et al., 2008; Airola et al., 2008; Van Landeghem et al., 2008; Katrenko and Adriaans, 2008)). The central concept in generating features of potential event argument edges is the shortest undirected path of syntactic dependencies in the Stanford scheme parse of the sentence which we assume to accurately capture the relationship expressed by the edge. In Figure 3, we show that the distances among event and named entity nodes in terms of shortest dependency path length are considerably shorter than in terms of their linear order in the sentence. The end points of the path are the syntactic head tokens of the two named entities or event triggers. The head tokens are identified using a s</context>
</contexts>
<marker>Katrenko, Adriaans, 2008</marker>
<rawString>Sophia Katrenko and Pieter Adriaans. 2008. A local alignment kernel in the context of NLP. In Proceedings of the 22nd International Conference on Computational Linguistics (Coling’08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Dong Kim</author>
<author>Tomoko Ohta</author>
<author>Tsujii Jun’ichi</author>
</authors>
<title>Corpus annotation for mining biomedical events from literature.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<issue>1</issue>
<marker>Kim, Ohta, Jun’ichi, 2008</marker>
<rawString>Jin-Dong Kim, Tomoko Ohta, and Tsujii Jun’ichi. 2008a. Corpus annotation for mining biomedical events from literature. BMC Bioinformatics, 9(1):10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seonho Kim</author>
<author>Juntae Yoon</author>
<author>Jihoon Yang</author>
</authors>
<title>Kernel approaches for genic interaction extraction.</title>
<date>2008</date>
<journal>Bioinformatics,</journal>
<volume>24</volume>
<issue>1</issue>
<contexts>
<context position="2010" citStr="Kim et al., 2008" startWordPosition="300" endWordPosition="303">.1 The purpose of this shared task was to competitively evaluate information extraction systems targeting complex events in the biomedical domain. Such an evaluation helps to establish the relative merits of competing approaches, allowing direct comparability of results in a controlled setting. The shared task was 1http://www-tsujii.is.s.u-tokyo.ac.jp/ GENIA/SharedTask 10 the first competitive evaluation of its kind in the BioNLP field as the extraction of complex events became possible only recently with the introduction of corpora containing the necessary annotation: the GENIA event corpus (Kim et al., 2008a) and the BioInfer corpus (Pyysalo et al., 2007). The objective of the primary task (Task 1) was to detect biologically relevant events such as protein binding and phosphorylation, given only annotation of named entities. For each event, its class, trigger expression in the text, and arguments need to be extracted. The task follows the recent movement in BioNLP towards the extraction of semantically typed, complex events the arguments of which can also be other events. This results in a nested structure that captures the underlying biological statements more accurately compared to the prevail</context>
<context position="13896" citStr="Kim et al., 2008" startWordPosition="2216" endWordPosition="2219">nt node (event nesting) or from an event node to a named entity node. Each example is then classified as theme, cause, or a negative denoting the absence of an edge between the two nodes in the given direction. It should be noted that even though event nodes often require multiple outgoing edges corresponding to multiple event arguments, all edges are predicted independently and are not affected by positive or negative classifications of other edges. The feature set makes extensive use of syntactic dependencies, in line with many recent studies in biomedical information extraction (see, e.g. (Kim et al., 2008b; Miwa et al., 2008; Airola et al., 2008; Van Landeghem et al., 2008; Katrenko and Adriaans, 2008)). The central concept in generating features of potential event argument edges is the shortest undirected path of syntactic dependencies in the Stanford scheme parse of the sentence which we assume to accurately capture the relationship expressed by the edge. In Figure 3, we show that the distances among event and named entity nodes in terms of shortest dependency path length are considerably shorter than in terms of their linear order in the sentence. The end points of the path are the syntacti</context>
</contexts>
<marker>Kim, Yoon, Yang, 2008</marker>
<rawString>Seonho Kim, Juntae Yoon, and Jihoon Yang. 2008b. Kernel approaches for genic interaction extraction. Bioinformatics, 24(1):118–126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Dong Kim</author>
<author>Tomoko Ohta</author>
<author>Sampo Pyysalo</author>
<author>Yoshinobu Kano</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Overview of BioNLP’09 shared task on event extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the NAACL-HLT 2009 Workshop on Natural Language Processing in Biomedicine (BioNLP’09).</booktitle>
<publisher>ACL.</publisher>
<contexts>
<context position="1394" citStr="Kim et al., 2009" startWordPosition="209" endWordPosition="212">tatements. We divide the task into independent steps which we approach as machine learning problems. We define a wide array of features and in particular make extensive use of dependency parse graphs. A rule-based post-processing step is used to refine the output in accordance with the restrictions of the extraction task. In the shared task evaluation, the system achieved an F-score of 51.95% on the primary task, the best performance among the participants. 1 Introduction In this paper, we present the best-performing system in the primary task of the BioNLP’09 Shared Task on Event Extraction (Kim et al., 2009).1 The purpose of this shared task was to competitively evaluate information extraction systems targeting complex events in the biomedical domain. Such an evaluation helps to establish the relative merits of competing approaches, allowing direct comparability of results in a controlled setting. The shared task was 1http://www-tsujii.is.s.u-tokyo.ac.jp/ GENIA/SharedTask 10 the first competitive evaluation of its kind in the BioNLP field as the extraction of complex events became possible only recently with the introduction of corpora containing the necessary annotation: the GENIA event corpus (</context>
</contexts>
<marker>Kim, Ohta, Pyysalo, Kano, Tsujii, 2009</marker>
<rawString>Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshinobu Kano, and Jun’ichi Tsujii. 2009. Overview of BioNLP’09 shared task on event extraction. In Proceedings of the NAACL-HLT 2009 Workshop on Natural Language Processing in Biomedicine (BioNLP’09). ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the 18th International Conference on Machine Learning (ICML’01),</booktitle>
<pages>282--289</pages>
<contexts>
<context position="21503" citStr="Lafferty et al., 2001" startWordPosition="3465" endWordPosition="3468"> 11.5 percentage point improvement in the overall system F-score on the development set. While we were unable to produce a re-ranker sufficiently accurate to improve the system performance in the time given, the large potential gain warrants further research. In trigger word detection, we experimented with a structural SVM incorporating Hidden Markov Model type of sequential dependencies (Altun et al., 2003; Tsochantaridis et al., 2004), which allow conditioning classification decisions on decisions made for previous tokens as well as with a conditional random field (CRF) sequence classifier (Lafferty et al., 2001). Neither of these experiments led to a performance gain over the multiclass SVM classifier. As discussed previously, 4.8% of all annotated events cross sentence boundaries. This problem could be approached using coreference resolution techniques, however, the necessary explicit coreference annotation to train a coreference resolution system is not present in the data. Instead, we attempted to build a machine-learning based system to detect cross-sentence event arguments directly, rather than via their referring expression, but were unable to improve the system performance. 3 Tools and resourc</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the 18th International Conference on Machine Learning (ICML’01), pages 282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David McClosky</author>
<author>Eugene Charniak</author>
</authors>
<title>Selftraining for biomedical parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT, Short Papers,</booktitle>
<pages>101--104</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="24443" citStr="McClosky and Charniak, 2008" startWordPosition="3933" endWordPosition="3936">ed in the system are trained as follows. First we optimize the regularization parameter C by training on the shared task training set and testing on the shared task development set. We then re-train the final classifier on the union of the training and development sets, using the best value of C in the previous step. The same protocol is followed for the A and Q parameters in trigger detection. 3.2 Dependency parses Both trigger detection and edge prediction rely on a wide array of features derived from full dependency parses of the sentence. We use the McCloskyCharniak domain-adapted parser (McClosky and Charniak, 2008) which is among the best performing parsers trained on the GENIA Treebank corpus. The native constituency output of the parser is transformed to the “collapsed” form of the Stanford dependency scheme (de Marneffe and Manning, 2008) using the Stanford parser tools.4 The parses were provided by the shared task organizers. 4 Results and discussion The final evaluation of the system was performed by the shared task organizers using a test set whose an4http://nlp.stanford.edu/software/ notation was at no point available to the task participants. By the main criterion of Task 1, approximate span mat</context>
</contexts>
<marker>McClosky, Charniak, 2008</marker>
<rawString>David McClosky and Eugene Charniak. 2008. Selftraining for biomedical parsing. In Proceedings of ACL-08: HLT, Short Papers, pages 101–104. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Makoto Miwa</author>
<author>Rune Sætre</author>
<author>Yusuke Miyao</author>
<author>Tomoko Ohta</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Combining multiple layers of syntactic information for proteinprotein interaction extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third International Symposium on Semantic Mining in Biomedicine (SMBM’08),</booktitle>
<pages>101--108</pages>
<publisher>TUCS.</publisher>
<contexts>
<context position="13916" citStr="Miwa et al., 2008" startWordPosition="2220" endWordPosition="2223">ing) or from an event node to a named entity node. Each example is then classified as theme, cause, or a negative denoting the absence of an edge between the two nodes in the given direction. It should be noted that even though event nodes often require multiple outgoing edges corresponding to multiple event arguments, all edges are predicted independently and are not affected by positive or negative classifications of other edges. The feature set makes extensive use of syntactic dependencies, in line with many recent studies in biomedical information extraction (see, e.g. (Kim et al., 2008b; Miwa et al., 2008; Airola et al., 2008; Van Landeghem et al., 2008; Katrenko and Adriaans, 2008)). The central concept in generating features of potential event argument edges is the shortest undirected path of syntactic dependencies in the Stanford scheme parse of the sentence which we assume to accurately capture the relationship expressed by the edge. In Figure 3, we show that the distances among event and named entity nodes in terms of shortest dependency path length are considerably shorter than in terms of their linear order in the sentence. The end points of the path are the syntactic head tokens of the</context>
<context position="30848" citStr="Miwa et al. (2008)" startWordPosition="4968" endWordPosition="4971">f the system. In Section 2.5, we discussed alternative directions pursued during the development of the current system, indicating possible future research directions. To support this future work as well as complement the description of the system in this paper we intend to publish our system under an open-source license. This shared task represents the first competitive evaluation of complex event extraction in the biomedical domain. The prior research has largely focused on binary interaction extraction, achieving after a substantial research effort F-scores of slightly over 60% (see, e.g., Miwa et al. (2008)) on AIMed, the de facto standard corpus for this task. Even if a direct comparison of these results is difficult, they suggest that 52% F-score in complex event extraction is a non-trivial achievement, especially considering the more detailed semantics of the extracted events. Further, complex event extraction is still a new problem — relevant corpora having been available for only a few years. Acknowledgments This research was funded by the Academy of Finland. Computational resources were provided by CSC — IT Center for Science Ltd. We thank the shared task organizers for their efforts in da</context>
</contexts>
<marker>Miwa, Sætre, Miyao, Ohta, Tsujii, 2008</marker>
<rawString>Makoto Miwa, Rune Sætre, Yusuke Miyao, Tomoko Ohta, and Jun’ichi Tsujii. 2008. Combining multiple layers of syntactic information for proteinprotein interaction extraction. In Proceedings of the Third International Symposium on Semantic Mining in Biomedicine (SMBM’08), pages 101–108. TUCS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin F Porter</author>
</authors>
<title>An algorithm for suffix stripping.</title>
<date>1980</date>
<journal>Program,</journal>
<volume>14</volume>
<issue>3</issue>
<contexts>
<context position="9739" citStr="Porter, 1980" startWordPosition="1529" endWordPosition="1530">M) classifier that assigns event classes to individual tokens, one at a time. This is in contrast to sequence labeling problems such as named entity recognition, where a sequential model is typically employed. The classifier is trained on goldstandard triggers from the training data and incorporates a wide array of features capturing the properties of the token to be classified, both its linear and dependency context, and the named entities within the sentence. Token features include binary tests for capitalization, presence of punctuation or numeric characters, stem using the Porter stemmer (Porter, 1980), character bigrams and trigrams, and presence of the token in a gazetteer of known trigger expressions and their classes, extracted from the training data. Token features are generated not only for the token to be classified, but also for tokens in the immediate linear context and dependency context (tokens that govern or depend on the token to be classified). Frequency features include the number of named entities in the sentence and in a linear window around the token in question as well as bag-ofword counts of token texts in the sentence. Dependency chains up to depth of three are construc</context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>Martin F. Porter. 1980. An algorithm for suffix stripping. Program, 14(3):130–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sampo Pyysalo</author>
<author>Filip Ginter</author>
<author>Juho Heimonen</author>
<author>Jari Bj¨orne</author>
<author>Jorma Boberg</author>
<author>Jouni J¨arvinen</author>
<author>Tapio Salakoski</author>
</authors>
<title>BioInfer: A corpus for information extraction in the biomedical domain.</title>
<date>2007</date>
<journal>BMC Bioinformatics,</journal>
<volume>8</volume>
<issue>1</issue>
<marker>Pyysalo, Ginter, Heimonen, Bj¨orne, Boberg, J¨arvinen, Salakoski, 2007</marker>
<rawString>Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari Bj¨orne, Jorma Boberg, Jouni J¨arvinen, and Tapio Salakoski. 2007. BioInfer: A corpus for information extraction in the biomedical domain. BMC Bioinformatics, 8(1):50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ioannis Tsochantaridis</author>
<author>Thomas Hofmann</author>
<author>Thorsten Joachims</author>
<author>Yasemin Altun</author>
</authors>
<title>Support vector machine learning for interdependent and structured output spaces.</title>
<date>2004</date>
<booktitle>In Proceedings of the Twenty-first International</booktitle>
<contexts>
<context position="21321" citStr="Tsochantaridis et al., 2004" startWordPosition="3437" endWordPosition="3440">the ten most likely candidate graphs, as determined by the confidence scores of the individual edges given by the multi-class SVM. A perfect reranking of these ten candidates would lead to 11.5 percentage point improvement in the overall system F-score on the development set. While we were unable to produce a re-ranker sufficiently accurate to improve the system performance in the time given, the large potential gain warrants further research. In trigger word detection, we experimented with a structural SVM incorporating Hidden Markov Model type of sequential dependencies (Altun et al., 2003; Tsochantaridis et al., 2004), which allow conditioning classification decisions on decisions made for previous tokens as well as with a conditional random field (CRF) sequence classifier (Lafferty et al., 2001). Neither of these experiments led to a performance gain over the multiclass SVM classifier. As discussed previously, 4.8% of all annotated events cross sentence boundaries. This problem could be approached using coreference resolution techniques, however, the necessary explicit coreference annotation to train a coreference resolution system is not present in the data. Instead, we attempted to build a machine-learn</context>
</contexts>
<marker>Tsochantaridis, Hofmann, Joachims, Altun, 2004</marker>
<rawString>Ioannis Tsochantaridis, Thomas Hofmann, Thorsten Joachims, and Yasemin Altun. 2004. Support vector machine learning for interdependent and structured output spaces. In Proceedings of the Twenty-first International</rawString>
</citation>
<citation valid="false">
<booktitle>wentyfirstInternational Conference on Machine Learning (ICML’04),</booktitle>
<pages>104--111</pages>
<publisher>ACM.</publisher>
<marker></marker>
<rawString>wentyfirstInternational Conference on Machine Learning (ICML’04), pages 104–111. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sofie Van Landeghem</author>
<author>Yvan Saeys</author>
<author>Bernard De Baets</author>
<author>Yves Van de Peer</author>
</authors>
<title>Extracting proteinprotein interactions from text using rich feature vectors and feature selection.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third International Symposium on Semantic Mining in Biomedicine (SMBM’08),</booktitle>
<pages>77--84</pages>
<publisher>TUCS.</publisher>
<marker>Van Landeghem, Saeys, De Baets, Van de Peer, 2008</marker>
<rawString>Sofie Van Landeghem, Yvan Saeys, Bernard De Baets, and Yves Van de Peer. 2008. Extracting proteinprotein interactions from text using rich feature vectors and feature selection. In Proceedings of the Third International Symposium on Semantic Mining in Biomedicine (SMBM’08), pages 77–84. TUCS.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>