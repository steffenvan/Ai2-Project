<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000745">
<title confidence="0.9990715">
Is Knowledge-Free Induction of Multiword Unit
Dictionary Headwords a Solved Problem?
</title>
<author confidence="0.994408">
Patrick Schone and Daniel Jurafsky
</author>
<affiliation confidence="0.999847">
University of Colorado, Boulder CO 80309
</affiliation>
<email confidence="0.997011">
{schone, jurafsky}@cs.colorado.edu
</email>
<sectionHeader confidence="0.997334" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999841777777778">
We seek a knowledge-free method for inducing
multiword units from text corpora for use as
machine-readable dictionary headwords. We
provide two major evaluations of nine existing
collocation-finders and illustrate the continuing
need for improvement. We use Latent Semantic
Analysis to make modest gains in performance, but
we show the significant challenges encountered in
trying this approach.
</bodyText>
<sectionHeader confidence="0.998797" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999903000000001">
A multiword unit (MWU) is a connected
collocation: a sequence of neighboring words
“whose exact and unambiguous meaning or
connotation cannot be derived from the meaning or
connotation of its components” (Choueka, 1988). In
other words, MWUs are typically non-compositional
at some linguistic level. For example, phonological
non-compositionality has been observed (Finke &amp;
Weibel, 1997; Gregory, et al, 1999) where words
like “got” [gat] and “to” [tu] change phonetically to
“gotta” [gave] when combined. We have interest in
inducing headwords for machine-readable
dictionaries (MRDs), so our interest is in semantic
rather than phonological non-compositionality. As
an example of semantic non-compositionality,
consider “compact disk”: one could not deduce that
it was a music medium by only considering the
semantics of “compact” and “disk.”
MWUs may also be non-substitutable and/or
non-modifiable (Manning and Schütze, 1999). Non-
substitutability implies that substituting a word of
the MWU with its synonym should no longer
convey the same original content: “compact disk”
does not readily imply “densely-packed disk.” Non-
modifiability, on the other hand, suggests one
cannot modify the MWU’s structure and still convey
the same content: “compact disk” does not signify
“disk that is compact.”
MWU dictionary headwords generally satisfy at
least one of these constraints. For example, a
compositional phrase would typically be excluded
from a hard-copy dictionary since its constituent
words would already be listed. These strategies
allow hard-copy dictionaries to remain compact.
As mentioned, we wish to find MWU headwords
for machine-readable dictionaries (MRDs).
Although space is not an issue in MRDs, we desire
to follow the lexicographic practice of reducing
redundancy. As Sproat indicated, &amp;quot;simply
expanding the dictionary to encompass every word
one is ever likely to encounter is wrong: it fails to
take advantage of regularities&amp;quot; (1992, p. xiii). Our
goal is to identify an automatic, knowledge-free
algorithm that finds all and only those collocations
where it is necessary to supply a definition.
“Knowledge-free” means that the process should
proceed without human input (other than, perhaps,
indicating whitespace and punctuation).
This seems like a solved problem. Many
collocation-finders exist, so one might suspect that
most could suffice for finding MWU dictionary
headwords. To verify this, we evaluate nine
existing collocation-finders to see which best
identifies valid headwords. We evaluate using two
completely separate gold standards: (1) WordNet
and (2) a compendium of Internet dictionaries.
Although web-based resources are dynamic and
have better coverage than WordNet (especially for
acronyms and names), we show that WordNet-based
scores are comparable to those using Internet
MRDs. Yet the evaluations indicate that significant
improvement is still needed in MWU-induction.
As an attempt to improve MWU headword
induction, we introduce several algorithms using
Latent Semantic Analysis (LSA). LSA is a
technique which automatically induces semantic
relationships between words. We use LSA to try to
eliminate proposed MWUs which are semantically
compositional. Unfortunately, this does not help.
Yet when we use LSA to identify substitutable delimiters. This suggests that in a language with
MWUs, we do show modest performance gains. whitespace, one might prefer to begin at the word
</bodyText>
<sectionHeader confidence="0.961717" genericHeader="method">
2 Previous Approaches
</sectionHeader>
<bodyText confidence="0.999960833333334">
For decades, researchers have explored various
techniques for identifying interesting collocations.
There have essentially been three separate kinds of
approaches for accomplishing this task. These
approaches could be broadly classified into (1)
segmentation-based, (2) word-based and knowledge-
driven, or (3) word-based and probabilistic. We will
illustrate strategies that have been attempted in each
of the approaches. Since we assume knowledge of
whitespace, and since many of the first and all of the
second categories rely upon human input, we will be
most interested in the third category.
</bodyText>
<subsectionHeader confidence="0.979581">
2.1 Segmentation-driven Strategies
</subsectionHeader>
<bodyText confidence="0.999965909090909">
Some researchers view MWU-finding as a natural
by-product of segmentation. One can regard text as
a stream of symbols and segmentation as a means of
placing delimiters in that stream so as to separate
logical groupings of symbols from one another. A
segmentation process may find that a symbol stream
should not be delimited even though subcomponents
of the stream have been seen elsewhere. In such
cases, these larger units may be MWUs.
The principal work on segmentation has focused
either on identifying words in phonetic streams
(Saffran, et. al, 1996; Brent, 1996; de Marcken,
1996) or on tokenizing Asian and Indian languages
that do not normally include word delimiters in their
orthography (Sproat, et al, 1996; Ponte and Croft
1996; Shimohata, 1997; Teahan, et al., 2000; and
many others). Such efforts have employed various
strategies for segmentation, including the use of
hidden Markov models, minimum description
length, dictionary-based approaches, probabilistic
automata, transformation-based learning, and text
compression. Some of these approaches require
significant sources of human knowledge, though
others, especially those that follow data
compression or HMM schemes, do not.
These approaches could be applied to languages
where word delimiters exist (such as in European
languages delimited by the space character).
However, in such languages, it seems more prudent
to simply take advantage of delimiters rather than
introducing potential errors by trying to find word
boundaries while ignoring knowledge of the
level and identify appropriate word combinations.
</bodyText>
<subsectionHeader confidence="0.977223">
2.2 Word-based, knowledge-driven Strategies
</subsectionHeader>
<bodyText confidence="0.999991684210527">
Some researchers start with words and propose
MWU induction methods that make use of parts of
speech, lexicons, syntax or other linguistic structure
(Justeson and Katz, 1995; Jacquemin, et al., 1997;
Daille, 1996). For example, Justeson and Katz
indicated that the patterns NOUN NOUN and ADJ
NOUN are very typical of MWUs. Daille also
suggests that in French, technical MWUs follow
patterns such as “NOUN de NOUN&amp;quot; (1996, p. 50).
To find word combinations that satisfy such patterns
in both of these situations necessitates the use of a
lexicon equipped with part of speech tags. Since we
are interested in knowledge-free induction of
MWUs, these approaches are less directly related to
our work. Furthermore, we are not really interested
in identifying constructs such as general noun
phrases as the above rules might generate, but
rather, in finding only those collocations that one
would typically need to define.
</bodyText>
<subsectionHeader confidence="0.999322">
2.3 Word-based, Probabilistic Approaches
</subsectionHeader>
<bodyText confidence="0.999825833333333">
The third category assumes at most whitespace
and punctuation knowledge and attempts to infer
MWUs using word combination probabilities.
Table 1 (see next page) shows nine commonly-used
probabilistic MWU-induction approaches. In the
table, fX and PX signify frequency and probability
of a word X. A variable XY indicates a word bigram
and 4XY indicates its expected frequency at random.
An overbar signifies a variable’s complement. For
more details, one can consult the original sources as
well as Ferreira and Pereira (1999) and Manning
and Schütze (1999).
</bodyText>
<sectionHeader confidence="0.99225" genericHeader="method">
3 Lexical Access
</sectionHeader>
<bodyText confidence="0.9965078">
Prior to applying the algorithms, we lemmatize
using a weakly-informed tokenizer that knows only
that whitespace and punctuation separate words.
Punctuation can either be discarded or treated as
words. Since we are equally interested in finding
units like “Dr.” and “U. S.,” we opt to treat
punctuation as words.
Once we tokenize, we use Church’s (1995) suffix
array approach to identify word n-grams that occur
at least T times (for T=10). We then rank-order the
</bodyText>
<tableCaption confidence="0.996244">
Table 1: Probabilistic Approaches
</tableCaption>
<table confidence="0.994508756756757">
METHOD FORMULA
Frequency fXY
(Guiliano, 1964)
Pointwise Mutual log2 (PXY / PXPY)
Information (MI)
(Fano, 1961;
Church and Hanks,
1990)
Selectional PX|YMIXY
Association
(Resnik, 1996)
1:Z PrZ|YMIZY
Symmetric PXY2 / PXPY
Conditional
Probability
(Ferreira and
Pereira, 1999)
Dice Formula 2 fXY / (fX+fY)
(Dice, 1945)
Log-likelihood [PXPYPXPY]fY
(Dunning, 1993; �2log
Daille, 1996)
[PXYPXY]fXY[PXYPXY]fXY
2 (fij � ij)2
Chi-squared (� ) EiE{X,X}
(Church and Gale,
1991)
j�{Y,Y} ij
Z-Score fXY � XY
(Smadja, 1993;
Fontenelle, et al.,
1994)
XY (1-(XY/N))
Student’s t-Score fXY - XY
(Church and
Hanks, 1990)
fXY (1�(fXY/N))
</table>
<bodyText confidence="0.998112086956521">
n-gram list in accordance to each probabilistic
algorithm. This task is non-trivial since most
algorithms were originally suited for finding two-
word collocations. We must therefore decide how
to expand the algorithms to identify general n-grams
(say, C=w1w2 ...wn). We can either generalize or
approximate. Since generalizing requires
exponential compute time and memory for several
of the algorithms, approximation is an attractive
alternative.
One approximation redefines X and Y to be,
respectively, the word sequences w1w2 ...wi and
wi+1wi+2...wn, where i is chosen to maximize PXPY.
This has a natural interpretation of being the
expected probability of concatenating the two most
probable substrings in order to form the larger unit.
Since it can be computed rapidly with low memory
costs, we use this approximation.
Two additional issues need addressing before
evaluation. The first regards document sourcing. If
an n-gram appears in multiple sources (eg.,
Congressional Record versus Associated Press), its
likelihood of accuracy should increase. This is
particularly true if we are looking for MWU
headwords for a general versus specialized
dictionary. Phrases that appear in one source may
in fact be general MWUs, but frequently, they are
text-specific units. Hence, precision gained by
excluding single-source n-grams may be worth
losses in recall. We will measure this trade-off.
Second, evaluating with punctuation as words and
applying no filtering mechanism may unfairly bias
against some algorithms. Pre- or post-processing of
n-grams with a linguistic filter has shown to
improve some induction algorithms’ performance
(Daille, 1996). Since we need knowledge-poor
induction, we cannot use human-suggested filtering
rules as in Section 2.2. Yet we can filter by pruning
n-grams whose beginning or ending word is among
the top N most frequent words. This unfortunately
eliminates acronyms like “U. S.” and phrasal verbs
like “throw up.” However, discarding some words
may be worthwhile if the final list of n-grams is
richer in terms of MRD headwords. We therefore
evaluate with such an automatic filter, arbitrarily
(and without optimization) choosing N=75.
</bodyText>
<sectionHeader confidence="0.958534" genericHeader="method">
4 Evaluating Performance
</sectionHeader>
<bodyText confidence="0.999857307692308">
A natural scoring standard is to select a language
and evaluate against headwords from existing
dictionaries in that language. Others have used
similar standards (Daille, 1996), but to our
knowledge, none to the extent described here. We
evaluate thousands of hypothesized units from an
unconstrained corpus. Furthermore, we use two
separate evaluation gold standards: (1) WordNet
(Miller, et al, 1990) and (2) a collection of Internet
MRDs. Using two gold standards helps valid
MWUs. It also provides evaluation using both static
and dynamic resources. We choose to evaluate in
English due to the wealth of linguistic resources.
</bodyText>
<tableCaption confidence="0.995395">
Table 2: Outputs from each algorithm at different sorted ranks
</tableCaption>
<table confidence="0.999787757575758">
Rank ZScore �2 SCP Mutual Dice Log TScore Freq
Info. Select Like.
Assoc.
1 Iwo Buenos Buenos Buenos Iwo United United United United
Jima Aires Aires Aires Jima States States States States
2 bona Iwo Iwo Iwo bona House Los Los Los
fide Jima Jima Jima fide of Angeles Angeles Angeles
Repre-
sentatives
4 Burkina Suu Kyi Suu Kyi Suu Kyi Wounded Los New New New
Faso Knee Angeles York York York
8 Satanic Sault Ste Sault Ste Sault Ste Hubble my Soviet my my
Verses Space colleagues Union colleagues colleagues
Telescope
16 Ku Ku Ku Ku alma mater Social High High
Klux Klux Klux Klux H . R Security School School
32 Pledge of Pledge of Pledge of Pledge of Coca - War II House of
Allegiance Allegiance Allegiance Allegiance Cola Repre-
sentatives
Wednesday
64 Telephone Telephone Telephone Internal Planned Prime * * * real New
&amp; amp ; &amp; amp ; &amp; amp ; Revenue Parent- Minister estate Jersey
Telegraph Telegraph Telegraph hood
128 Prime Prime Prime Salman Sault Ste both At the Wall term
Minister Minister Minister Rushdie . Marie sides same time Street care
256 Lehman Lehman Lehman in tongue - o ’ clock At the del Mar all grand
Hutton Hutton Hutton - same over jury
cheek
512 La Habra La Habra La Habra compens- 20th - Monday days 80 Great
atory and Century night later percent Northern
punitive
1024 telephone telephone telephone Food and Sheriff ’s South County where 300
interview interview interview Agriculture deputies Dakota Jail you million
</table>
<subsectionHeader confidence="0.389791">
The “* *” and “* * *” are actual units.
</subsectionHeader>
<bodyText confidence="0.963516333333333">
In particular, we use a randomly-selected corpus the first five columns as “information-like.”
consisting of a 6.7 million word subset of the TREC Similarly, since the last four columns share
databases (DARPA, 1993-1997). properties of the frequency approach, we will refer
Table 2 illustrates a sample of rank-ordered output to them as “frequency-like.”
from each of the different algorithms (following the One’s application may dictate which set of
cross-source, filtered paradigm described in section algorithms to use. Our gold standard selection
3). Note that algorithms in the first four columns reflects our interest in general word dictionaries, so
produce results that are similar to each other as do results we obtain may differ from results we might
those in the last four columns. Although the mutual have obtained using terminology lexicons.
information results seem to be almost in a class of If our gold standard contains K MWUs with
their own, they actually are similar overall to the corpus frequencies satisfying threshold (T=10), our
first four sets of results; therefore, we will refer to figure of merit (FOM) is given by
</bodyText>
<equation confidence="0.995750666666667">
1EK P
i=1
K
</equation>
<bodyText confidence="0.99998025">
where Pi (precision at i) equals i/Hi , and Hi is the
number of hypothesized MWUs required to find the
ith correct MWU. This FOM corresponds to area
under a precision-recall curve.
</bodyText>
<subsectionHeader confidence="0.968979">
4.1 WordNet-based Evaluation
</subsectionHeader>
<bodyText confidence="0.999700956521739">
WordNet has definite advantages as an evaluation
resource. It has in excess of 50,000 MWUs, is freely
accessible, widely used, and is in electronic form.
Yet, it obviously cannot contain every MWU. For
instance, our corpus contains 177,331 n-grams (for
2&lt;n&lt;10) satisfying T&gt;_10, but WordNet contains
only 2610 of these. It is unclear, therefore, if
algorithms are wrong when they propose MWUs
that are not in WordNet. We will assume they are
wrong but with a special caveat for proper nouns.
WordNet includes few proper noun MWUs. Yet
several algorithms produce large numbers of proper
nouns. This biases against them. One could contend
that all proper nouns MWUs are valid, but we
disagree. Although such may be MWUs, they are
not necessarily MRD headwords; one would not
include every proper noun in a dictionary, but
rather, those needing definitions. To overcome this,
we will have two scoring modes. The first, “S”
mode (standing for some) discards any proposed
capitalized n-gram whose uncapitalized version is
not in WordNet. The second mode “N” (for none)
disregards all capitalized n-grams.
Table 3 illustrates algorithmic performance as
compared to the 2610 MWUs from WordNet. The
first double column illustrates “out-of-the-box”
performance on all 177,331 possible n-grams. The
second double column shows cross-sourcing: only
hypothesizing MWUs that appear in at least two
separate datasets (124,952 in all), but being
evaluated against all of the 2610 valid units. Double
columns 3 and 4 show effects from high-frequency
filtering the n-grams of the first and second columns
(reporting only 29,716 and 17,720 n-grams)
respectively.
As Table 3 suggests, for every condition, the
information-like algorithms seem to perform best at
identifying valid, general MWU headwords.
Moreover, they are enhanced when cross-sourcing
is considered; but since much of their strength
comes from identifying proper nouns, filtering has
little or even negative impact. On the other hand,
data source. They also improve significantly with
filtering. Overall, though, after the algorithms are
judged, even the best score of 0.265 is far short of
the maximum possible, namely 1.0.
</bodyText>
<tableCaption confidence="0.994129">
Table 3: WordNet-based scores
</tableCaption>
<table confidence="0.999834533333333">
Prob (1) (2) (3) (4)
algo- WordNet WordNet WordNet WordNet
rithm cross- +Filter cross-
source source
+Filter
S N S N S N S N
Zscore .222 .146 .263 .193 .220 .129 .265 .173
SCP .221 .145 .262 .192 .220 .129 .265 .173
Chi-sqr .222 .146 .263 .193 .220 .129 .265 .173
Dice .242 .167 .265 .199 .230 .142 .256 .172
MI .191 .122 .245 .169 .185 .111 .233 .151
SA .057 .051 .058 .053 .182 .125 .202 .143
Loglike .049 .050 .068 .064 .118 .095 .177 .129
T-score .050 .051 .050 .052 .150 .109 .160 .118
Freq .035 .037 .034 .037 .144 .105 .152 .112
</table>
<subsectionHeader confidence="0.880957">
4.2 Web-based Evaluation
</subsectionHeader>
<bodyText confidence="0.99197">
Since WordNet is static and cannot report on all of
a corpus’ n-grams, one may expect different
performance by using a more all-encompassing,
dynamic resource. The Internet houses dynamic
resources which can judge practically every induced
n-gram. With permission and sufficient time, one
can repeatedly query websites that host large
collections of MRDs and evaluate each n-gram.
Having approval, we queried: (1) onelook.com,
(2) acronymfinder.com, and (3) infoplease.com. The
first website interfaces with over 600 electronic
dictionaries. The second is devoted to identifying
proper acronyms. The third focuses on world facts
such as historical figures and organization names.
To minimize disruption to websites by reducing
the total number of queries needed for evaluation,
we use an evaluation approach from the information
retrieval community (Sparck-Jones and van
Rijsbergen, 1975). Each algorithm reports its top
5000 MWU choices and the union of these choices
(45192 possible n-grams) is looked up on the
Internet. Valid MWUs identified at any website are
assumed to be the only valid units in the data.
i, the frequency-like approaches are independent of
Algorithms are then evaluated based on this showed how one could compute latent semantic
collection. Although this strategy for evaluation is vectors for any word in a corpus (Schone and
not flawless, it is reasonable and makes dynamic Jurafsky, 2000). Using the same approach, we
evaluation tractable. Table 4 shows the algorithms’ compute semantic vectors for every proposed word
performance (including proper nouns). n-gram C=X X ...X Since LSA involves word
</bodyText>
<equation confidence="0.621278">
1 2 n.
</equation>
<bodyText confidence="0.9927138">
Though Internet dictionaries and WordNet are counts, we can also compute semantic vectors
completely separate “gold standards,” results are
surprisingly consistent. One can conclude that
WordNet may safely be used as a gold standard in
future MWU headword evaluations. Also,
</bodyText>
<tableCaption confidence="0.993954">
Table 4 Performance on Internet data
</tableCaption>
<table confidence="0.999359928571429">
Prob (1) (2) (3) (4)
algorithm Internet Internet Internet Internet
cross- +Filter cross-
source source
+Filter
Z-Score .165 .260 .169 .269
SCP .166 .259 .170 .270
Chi-sqr .166 .260 .170 .270
Dice .183 .258 .187 .267
MI .139 .234 .140 .234
SA .027 .033 .107 .194
Log Like .023 .043 .087 .162
T-score .025 .027 .110 .142
Freq .016 .017 .104 .134
</table>
<tableCaption confidence="0.484552">
one can see that Z-scores, $ , and
</tableCaption>
<page confidence="0.450249">
2
</page>
<bodyText confidence="0.99985975">
SCP have virtually identical results and seem to best
identify MWU headwords (particularly if proper
nouns are desired). Yet there is still significant
room for improvement.
</bodyText>
<sectionHeader confidence="0.978004" genericHeader="method">
5 Improvement strategies
</sectionHeader>
<bodyText confidence="0.999940666666667">
Can performance be improved? Numerous
strategies could be explored. An idea we discuss
here tries using induced semantics to rescore the
output of the best algorithm (filtered, cross-sourced
Zscore) and eliminate semantically compositional or
modifiable MWU hypotheses.
Deerwester, et al (1990) introduced Latent
Semantic Analysis (LSA) as a computational
technique for inducing semantic relationships
between words and documents. It forms high-
dimensional vectors using word counts and uses
singular value decomposition to project those
vectors into an optimal k-dimensional, “semantic”
subspace (see Landauer, et al, 1998).
Following an approach from Schütze (1993), we
(denoted by SL) for C’s subcomponents. These can
either include ({X } n) or exclude QX* } n ) C’s
counts. We seek to see if induced sema4ics can
help eliminate incorrectly-chosen MWUs. As will
be shown, the effort using semantics in this nature
has a very small payoff for the expended cost.
</bodyText>
<subsectionHeader confidence="0.990391">
5.1 Non-compositionality
</subsectionHeader>
<bodyText confidence="0.998336333333333">
Non-compositionality is a key component of valid
MWUs, so we may desire to emphasize n-grams that
are semantically non-compositional. Suppose we
wanted to determine if C (defined above) were non-
compositional. Then given some meaning function,
`I&apos;, C should satisfy an equation like:
</bodyText>
<equation confidence="0.950712">
g( T(C) , h( T(X1),...,T(Xn) ) )?0, (1)
</equation>
<bodyText confidence="0.999992714285714">
where h combines the semantics of C’s
subcomponents and g measures semantic
differences. If C were a bigram, then if g(a,b) is
defined to be |a-b|, if h(c,d) is the sum of c and d,
and if T(e) is set to -log Pe, then equation (1) would
become the pointwise mutual information of the
bigram. If g(a,b) were defined to be (a-b)/b , and if
</bodyText>
<page confidence="0.399832">
1/2
</page>
<bodyText confidence="0.9998512">
h(a,b)=ab/N and `I&apos;(X)=fX , we essentially get Z-
scores. These formulations suggest that several of
the probabilistic algorithms we have seen include
non-compositionality measures already. However,
since the probabilistic algorithms rely only on
distributional information obtained by considering
juxtaposed words, they tend to incorporate a
significant amount of non-semantic information
such as syntax. Can semantic-only rescoring help?
To find out, we must select g, h, and T. Since we
want to eliminate MWUs that are compositional, we
want h’s output to correlate well with C when there
is compositionality and correlate poorly otherwise.
Frequently, LSA vectors are correlated using the
cosine between them:
</bodyText>
<equation confidence="0.808156">
X�Y
cos(X,Y) _
</equation>
<bodyText confidence="0.999794666666667">
A large cosine indicates strong correlation, so large
values for g(a,b)=1-|cos(a,b) |should signal weak
correlation or non-compositionality. h could
</bodyText>
<equation confidence="0.8694005">
.
||X  |Y||
</equation>
<bodyText confidence="0.98837">
represent a weighted vector sum of the components’ required for this task. This seems to be a significant
semantic vectors with weights (wi) set to either 1.0 component. Yet there is still another: maybe
or the reciprocal of the words’ frequencies. semantic compositionality is not always bad.
Table 5 indicates several results using these Interestingly, this is often the case. Consider
settings. As the first four rows indicate and as vice_president, organized crime, and
desired, non-compositionality is more apparent for Marine_Corps. Although these are MWUs, one
52X* (i.e., the vectors derived from excluding C’s
counts) than for 52X. Yet, performance overall is
horrible, particularly considering we are rescoring
Z-score output whose score was 0.269. Rescoring
caused five-fold degradation!
</bodyText>
<tableCaption confidence="0.997969">
Table 5: Equation 1 settings
</tableCaption>
<table confidence="0.9973331">
g(a,b) h(a) T(X) wi Score on
Internet
SLX 1 0.0517
1/fi 0.0473
1-|cos(a,b) |52X* 1 0.0598
y:ni�1 wi ai 1/fi* 0.0523
SLX 1 0.174
|cos(a,b) |1/fi 0.169
52X* 1 0.131
1/fi* 0.128
</table>
<bodyText confidence="0.99753575">
What happens if we instead emphasize
compositionality? Rows 5-8 illustrate the effect:
there is a significant recovery in performance. The
most reasonable explanation for this is that if
MWUs and their components are strongly
correlated, the components may rarely occur except
in context with the MWU. It takes about 20 hours
to compute the 52X* for each possible n-gram
combination. Since the probabilistic algorithms
already identify n-grams that share strong
distributional properties with their components, it
seems imprudent to exhaust resources on this LSA-
based strategy for non-compositionality.
These findings warrant some discussion. Why did
non-compositionality fail? Certainly there is the
possibility that better choices for g, h, and T could
yield improvements. We actually spent months
trying to find an optimal combination as well as a
strategy for coupling LSA-based scores with the Z-
scores, but without avail. Another possibility:
although LSA can find semantic relationships, it
may not make semantic decisions at the level
would still expect that the first is related to
president, the second relates to crime, and the last
relates to Marine. Similarly, tokens such as
Johns_Hopkins and Elvis are anaphors for
Johns_Hopkins_University and Elvis_Presley, so
they should have similar meanings.
This begs the question: can induced semantics
help at all? The answer is “yes.” The key is using
LSA where it does best: finding things that are
similar — or substitutable.
</bodyText>
<subsectionHeader confidence="0.999359">
5.2 Non-substitutivity
</subsectionHeader>
<bodyText confidence="0.999949285714286">
For every collocation C=X1X2..Xi-1XiXi+1..Xn, we
attempt to find other similar patterns in the data,
X1X2..Xi-1YXi+1..Xn. If Xi and Y are semantically
related, chances are that C is substitutable.
Since LSA excels at finding semantic correlations,
we can compare 52Xi and SLY to see if C is
substitutable. We use our earlier approach (Schone
and Jurafsky, 2000) for performing the comparison;
namely, for every word W, we compute cos(52w, SLR)
for 200 randomly chosen words, R. This allows for
computation of a correlaton mean (µW) and standard
deviation (6W) between W and other words. As
before, we then compute a normalized cosine score
( ) between words of interest, defined by
</bodyText>
<equation confidence="0.887049666666667">
cos
min cos(52m , flY)-µk
cos(Xi,Y) = ke{Xi,Y}
</equation>
<bodyText confidence="0.997853142857143">
With this set-up, we now look for substitutivity.
Note that phrases may be substitutable and still be
headword if their substitute phrases are themselves
MWUs. For example, dioxide in carbon_dioxide is
semantically similar to monoxide in
carbon_monoxide. Moreover, there are other
important instances of valid substitutivity:
</bodyText>
<figure confidence="0.442668777777778">
&amp; Abbreviations
Al--Albert &lt; Al_Gore--Albert_Gore
&amp; Morphological similarities
Rico--Rican &lt; Puerto_Rico°Puerto_Rican
&amp; Taxonomic relationships
bachelor�master&lt;
bachelor_’_s_degree master_’_s_degree.
.
6k
</figure>
<bodyText confidence="0.999094571428571">
However, guilty and innocent are semantically
related, but pleaded_guilty and pleaded_innocent
are not MWUs. We would like to emphasize only n-
grams whose substitutes are valid MWUs.
To show how we do this using LSA, suppose we
want to rescore a list L whose entries are potential
MWUs. For every entry X in L, we seek out all
other entries whose sorted order is less than some
maximum value (such as 5000) that have all but one
word in common. For example, suppose X is
“bachelor_’_s_degree.” The only other entry that
matches in all but one word is “master_’_s_degree.”
If the semantic vectors for “bachelor” and “master”
have a normalized cosine score greater than a
threshold of 2.0, we then say that the two MWUs
are in each others substitution set. To rescore, we
assign a new score to each entry in substitution set.
Each element in the substitution set gets the same
score. The score is derived using a combination of
the previous Z-scores for each element in the
substitution set. The combining function may be an
averaging, or a computation of the median, the
maximum, or something else. The maximum
outperforms the average and the median on our data.
By applying in to our data, we observe a small but
visible improvement of 1.3% absolute to .282 (see
Fig. 1). It is also possible that other improvements
could be gained using other combining strategies.
</bodyText>
<sectionHeader confidence="0.99962" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999858210526316">
This paper identifies several new results in the area
of MWU-finding. We saw that MWU headword
evaluations using WordNet provide similar results
to those obtained from far more extensive web-
based resources. Thus, one could safely use
WordNet as a gold standard for future evaluations.
We also noted that information-like algorithms,
particularly Z-scores, SCP, and x2, seem to perform
best at finding MRD headwords regardless of
filtering mechanism, but that improvements are still
needed. We proposed two new LSA-based
approaches which attempted to address issues of
non-compositionality and non-substitutivity.
Apparently, either current algorithms already
capture much non-compositionality or LSA-based
models of non-compositionality are of little help.
LSA does help somewhat as a model of
substitutivity. However, LSA-based gains are small
compared to the effort required to obtain them.
</bodyText>
<figureCaption confidence="0.996451">
Figure 1: Precision-recall curve for rescoring
</figureCaption>
<sectionHeader confidence="0.997469" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9951205">
The authors would like to thank the anonymous
reviewers for their comments and insights.
</bodyText>
<sectionHeader confidence="0.998024" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998798642335767">
AcronymFinder.com(2000-1).http://www.acronymfinder.
com. Searches between March 2000 and April 2001.
Brent, M.R. and Cartwright, T.A. (1996). Distributional
regularity and phonotactic constraints are useful for
segmentation. Cognition, 61, 93-125.
Choueka, Y. (1988). Looking for needles in a haystack
or locating interesting collocation expressions in large
textual databases. Proceedings of the RIAO, pp. 38-43.
Church, K.W. (1995). N-grams. Tutorial at ACL, ‘95.
MIT, Cambridge, MA.
Church, K.W., &amp; Gale, W.A. (1991). Concordances for
parallel text. Proc. of the 7 Annual Conference of the
th
UW Center for ITE New OED &amp; Text Research, pp.
40-62, Oxford.
Church, K.W., &amp; Hanks, P. (1990). Word association
norms, mutual information and lexicography.
Computational Linguistics, Vol. 16, No. 1, pp. 22-29.
Daille, B. (1996). “Study and Implementation of
Combined Techniques from Automatic Extraction of
Terminology” Chap. 3 of &amp;quot;The Balancing Act&amp;quot;:
Combining Symbolic and Statistical Approaches to
Language (Klavans, J., Resnik, P. (eds.)), pp. 49-66
DARPA (1993-1997). DARPA text collections: A.P.
Material, 1988-1990, Ziff Communications Corpus,
1989, Congressional Record of the 103 Congress,
rd
and Los Angeles Times.
Deerwester, S., S.T. Dumais, G.W. Furnas, T.K.
Landauer, and R. Harshman. (1990) Indexing by
Latent Semantic Analysis. Journal of the American
Society of Information Science, Vol. 41
de Marcken, C. (1996) Unsupervised Language
Acquisition, Ph.D., MIT Manning, C.D., Schütze, H. (1999) Foundations of
Dias, G., S. Guilloré, J.G. Pereira Lopes (1999). Statistical Natural Language Processing, MIT Press,
Language independent automatic acquisition of rigid Cambridge, MA, 1999.
multiword units from unrestricted text corpora. TALN, Mikheev, A., Finch, S. (1997). Collocation lattices and
Cargèse. maximum entropy models. WVLC, Hong Kong.
Dice, L.R. (1945). Measures of the amount of ecologic
associations between species. Journal of Ecology, 26,
1945.
Dunning, T (1993). Accurate methods for the statistics of
surprise and coincidence. Computational Linguistics.
Vol. 19, No. 1.
Fano, R. (1961). Transmission of Information. MIT
Press, Cambridge, MA.
Finke, M. and Weibel, A. (1997) Speaking mode
dependent pronunciation modeling in large vocabulary
conversational speech recognition. Eurospeech-97.
Ferreira da Silva, J., Pereira Lopes, G. (1999). A local
maxima method and a fair dispersion normalization for
extracting multi-word units from corpora. Sixth
Meeting on Mathematics of Language, pp. 369-381.
Fontenelle, T., Brüls, W., Thomas, L., Vanallemeersch,
T., Jansen, J. (1994). DECIDE, MLAP-Project 93-19,
deliverable D-1a: Survey of collocation extraction
tools. Tech. Report, Univ. of Liege, Liege, Belgium.
Giuliano, V. E. (1964) &amp;quot;The interpretation of word
associations.&amp;quot; In M.E. Stevens et al. (Eds.) Statistical
association methods for mechanized documentation,
pp. 25-32. National Bureau of Standards
Miscellaneous Publication 269, Dec. 15, 1965.
Gregory, M. L., Raymond, W.D., Bell, A., Fosler-
Lussier, E., Jurafsky, D. (1999). The effects of
collocational strength and contextual predictability in
lexical production. CLS99, University of Chicago.
Heid, U. (1994). On ways words work together. Euralex-
99.
Hindle, D. (1990). Noun classification from predicate-
argument structures. Proceedings of the Annual
Meeting of the ACL, pp. 268-275.
InfoPlease.com (2000-1). http://www.infoplease.com.
Searches between March 2000 and April 2001.
Jacquemin, C., Klavans, J.L., &amp; Tzoukermann, E. (1997).
Expansion of multi-word terms for indexing and
retrieval using morphology and syntax. Proc. of ACL
1997, Madrid, pp. 24-31.
Justeson, J.S. and S.M.Katz (1995). Technical
terminology: some linguistic properties and an
algorithm for identification in text. Natural Language
Engineering 1:9-27.
Kilgariff, A., &amp; Rose, T. (1998). Metrics for corpus
similarity &amp; homogeneity. Manuscript, ITRI,
University of Brighton.
Landauer, T.K., P.W. Foltz, and D. Laham. (1998)
Introduction to Latent Semantic Analysis. Discourse
Processes. Vol. 25, pp. 259-284.
Miller, G. (1990).“WordNet: An on-line lexical
database,” International Journal of Lexicography, 3(4).
OneLook.com (2000-1). http://www.onelook.com.
Searches between March 2000 and April 2001.
Ponte, J.M., Croft, B.W. (1996). Useg: A Retargetable
word segmentation procedure for information retrieval.
Symposium on Document Analysis and Information
Retrieval ‘96. Technical Report TR96-2, University of
Massachusetts.
Resnik, P. (1996). Selectional constraints: an
information-theoretic model and its computational
realization. Cognition. Vol. 61, pp. 127-159.
Saffran, J.R., Newport, E.L., and Aslin, R.N. (1996).
Word segmentation: the role of distributional cues.
Journal of Memory and Language, Vol. 25, pp. 606-
621.
Schone, P. and D. Jurafsky. (2000) Knowledge-free
induction of morphology using latent semantic
analysis. Proc. of the Computational Natural
Language Learning Conference, Lisbon, pp. 67-72.
Schütze, H. (1993) Distributed syntactic representations
with an application to part-of-speech tagging.
Proceedings of the IEEE International Conference on
Neural Networks, pp. 1504-1509.
Shimohata, S., Sugio, T., Nagata, J. (1997). Retrieving
collocations by co-occurrences and word order
constraints. Proceedings of the 35 Annual Mtg. of the
th
Assoc. for Computational Linguistics. Madrid.
Morgan-Kauffman Publishers, San Francisco. Pp.
476-481.
Smadja, F. (1993). Retrieving collocations from text:
Xtract. Computational Linguistics, 19:143-177.
Sparck-Jones, K., C. van Rijsbergen (1975) Report on the
need for and provision of an “ideal” information
retrieval text collection, British Library Research and
Development Report, 5266, Computer Laboratory,
University of Cambridge.
Sproat R, Shih, C. (1990) A statistical method for finding
word boundaries in Chinese text. Computer
Processing of Chinese &amp; Oriental Languages, Vol. 4,
No. 4.
Sproat, R. (1992) Morphology and Computation. MIT
Press, Cambridge, MA.
Sproat, R.W., Shih, C., Gale, W., Chang, N. (1996) A
stochastic finite-state word segmentation algorithm for
Chinese. Computational Linguistics, Vol. 22, #3.
Teahan, W.J., Yingyin, W. McNab, R, Witten, I.H.
(2000). A Compression-based algorithm for Chinese
word segmentation. ACL Vol. 26, No. 3, pp. 375-394.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.958524">
<title confidence="0.9905225">Is Knowledge-Free Induction of Multiword Dictionary Headwords a Solved Problem?</title>
<author confidence="0.992633">Patrick Schone</author>
<author confidence="0.992633">Daniel</author>
<affiliation confidence="0.999818">University of Colorado, Boulder CO</affiliation>
<email confidence="0.998301">schone@cs.colorado.edu</email>
<email confidence="0.998301">jurafsky@cs.colorado.edu</email>
<abstract confidence="0.997106">We seek a knowledge-free method for inducing multiword units from text corpora for use as machine-readable dictionary headwords. We provide two major evaluations of nine existing collocation-finders and illustrate the continuing need for improvement. We use Latent Semantic Analysis to make modest gains in performance, but we show the significant challenges encountered in trying this approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>com</author>
</authors>
<title>Searches between</title>
<date>2000</date>
<location>and</location>
<marker>com, 2000</marker>
<rawString>AcronymFinder.com(2000-1).http://www.acronymfinder. com. Searches between March 2000 and April 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Brent</author>
<author>T A Cartwright</author>
</authors>
<title>Distributional regularity and phonotactic constraints are useful for segmentation.</title>
<date>1996</date>
<journal>Cognition,</journal>
<volume>61</volume>
<pages>93--125</pages>
<marker>Brent, Cartwright, 1996</marker>
<rawString>Brent, M.R. and Cartwright, T.A. (1996). Distributional regularity and phonotactic constraints are useful for segmentation. Cognition, 61, 93-125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Choueka</author>
</authors>
<title>Looking for needles in a haystack or locating interesting collocation expressions in large textual databases.</title>
<date>1988</date>
<booktitle>Proceedings of the RIAO,</booktitle>
<pages>38--43</pages>
<contexts>
<context position="835" citStr="Choueka, 1988" startWordPosition="114" endWordPosition="115">dge-free method for inducing multiword units from text corpora for use as machine-readable dictionary headwords. We provide two major evaluations of nine existing collocation-finders and illustrate the continuing need for improvement. We use Latent Semantic Analysis to make modest gains in performance, but we show the significant challenges encountered in trying this approach. 1 Introduction A multiword unit (MWU) is a connected collocation: a sequence of neighboring words “whose exact and unambiguous meaning or connotation cannot be derived from the meaning or connotation of its components” (Choueka, 1988). In other words, MWUs are typically non-compositional at some linguistic level. For example, phonological non-compositionality has been observed (Finke &amp; Weibel, 1997; Gregory, et al, 1999) where words like “got” [gat] and “to” [tu] change phonetically to “gotta” [gave] when combined. We have interest in inducing headwords for machine-readable dictionaries (MRDs), so our interest is in semantic rather than phonological non-compositionality. As an example of semantic non-compositionality, consider “compact disk”: one could not deduce that it was a music medium by only considering the semantics</context>
</contexts>
<marker>Choueka, 1988</marker>
<rawString>Choueka, Y. (1988). Looking for needles in a haystack or locating interesting collocation expressions in large textual databases. Proceedings of the RIAO, pp. 38-43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
</authors>
<date>1995</date>
<journal>N-grams. Tutorial at ACL,</journal>
<volume>95</volume>
<publisher>MIT,</publisher>
<location>Cambridge, MA.</location>
<marker>Church, 1995</marker>
<rawString>Church, K.W. (1995). N-grams. Tutorial at ACL, ‘95. MIT, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
<author>W A Gale</author>
</authors>
<title>Concordances for parallel text.</title>
<date>1991</date>
<booktitle>Proc. of the 7 Annual Conference of the th UW Center for ITE New OED &amp; Text Research,</booktitle>
<pages>40--62</pages>
<location>Oxford.</location>
<contexts>
<context position="8822" citStr="Church and Gale, 1991" startWordPosition="1299" endWordPosition="1302">h’s (1995) suffix array approach to identify word n-grams that occur at least T times (for T=10). We then rank-order the Table 1: Probabilistic Approaches METHOD FORMULA Frequency fXY (Guiliano, 1964) Pointwise Mutual log2 (PXY / PXPY) Information (MI) (Fano, 1961; Church and Hanks, 1990) Selectional PX|YMIXY Association (Resnik, 1996) 1:Z PrZ|YMIZY Symmetric PXY2 / PXPY Conditional Probability (Ferreira and Pereira, 1999) Dice Formula 2 fXY / (fX+fY) (Dice, 1945) Log-likelihood [PXPYPXPY]fY (Dunning, 1993; �2log Daille, 1996) [PXYPXY]fXY[PXYPXY]fXY 2 (fij � ij)2 Chi-squared (� ) EiE{X,X} (Church and Gale, 1991) j�{Y,Y} ij Z-Score fXY � XY (Smadja, 1993; Fontenelle, et al., 1994) XY (1-(XY/N)) Student’s t-Score fXY - XY (Church and Hanks, 1990) fXY (1�(fXY/N)) n-gram list in accordance to each probabilistic algorithm. This task is non-trivial since most algorithms were originally suited for finding twoword collocations. We must therefore decide how to expand the algorithms to identify general n-grams (say, C=w1w2 ...wn). We can either generalize or approximate. Since generalizing requires exponential compute time and memory for several of the algorithms, approximation is an attractive alternativ</context>
</contexts>
<marker>Church, Gale, 1991</marker>
<rawString>Church, K.W., &amp; Gale, W.A. (1991). Concordances for parallel text. Proc. of the 7 Annual Conference of the th UW Center for ITE New OED &amp; Text Research, pp. 40-62, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
<author>P Hanks</author>
</authors>
<title>Word association norms, mutual information and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<pages>22--29</pages>
<contexts>
<context position="8489" citStr="Church and Hanks, 1990" startWordPosition="1254" endWordPosition="1257">applying the algorithms, we lemmatize using a weakly-informed tokenizer that knows only that whitespace and punctuation separate words. Punctuation can either be discarded or treated as words. Since we are equally interested in finding units like “Dr.” and “U. S.,” we opt to treat punctuation as words. Once we tokenize, we use Church’s (1995) suffix array approach to identify word n-grams that occur at least T times (for T=10). We then rank-order the Table 1: Probabilistic Approaches METHOD FORMULA Frequency fXY (Guiliano, 1964) Pointwise Mutual log2 (PXY / PXPY) Information (MI) (Fano, 1961; Church and Hanks, 1990) Selectional PX|YMIXY Association (Resnik, 1996) 1:Z PrZ|YMIZY Symmetric PXY2 / PXPY Conditional Probability (Ferreira and Pereira, 1999) Dice Formula 2 fXY / (fX+fY) (Dice, 1945) Log-likelihood [PXPYPXPY]fY (Dunning, 1993; �2log Daille, 1996) [PXYPXY]fXY[PXYPXY]fXY 2 (fij � ij)2 Chi-squared (� ) EiE{X,X} (Church and Gale, 1991) j�{Y,Y} ij Z-Score fXY � XY (Smadja, 1993; Fontenelle, et al., 1994) XY (1-(XY/N)) Student’s t-Score fXY - XY (Church and Hanks, 1990) fXY (1�(fXY/N)) n-gram list in accordance to each probabilistic algorithm. This task is non-trivial since most algorithms were</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Church, K.W., &amp; Hanks, P. (1990). Word association norms, mutual information and lexicography. Computational Linguistics, Vol. 16, No. 1, pp. 22-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Daille</author>
</authors>
<title>of &amp;quot;The Balancing Act&amp;quot;: Combining Symbolic and Statistical Approaches to Language (Klavans,</title>
<date>1996</date>
<booktitle>Study and Implementation of Combined Techniques from Automatic Extraction of Terminology” Chap.</booktitle>
<volume>3</volume>
<pages>49--66</pages>
<editor>J., Resnik, P. (eds.)),</editor>
<contexts>
<context position="6537" citStr="Daille, 1996" startWordPosition="950" endWordPosition="951">ed to languages where word delimiters exist (such as in European languages delimited by the space character). However, in such languages, it seems more prudent to simply take advantage of delimiters rather than introducing potential errors by trying to find word boundaries while ignoring knowledge of the level and identify appropriate word combinations. 2.2 Word-based, knowledge-driven Strategies Some researchers start with words and propose MWU induction methods that make use of parts of speech, lexicons, syntax or other linguistic structure (Justeson and Katz, 1995; Jacquemin, et al., 1997; Daille, 1996). For example, Justeson and Katz indicated that the patterns NOUN NOUN and ADJ NOUN are very typical of MWUs. Daille also suggests that in French, technical MWUs follow patterns such as “NOUN de NOUN&amp;quot; (1996, p. 50). To find word combinations that satisfy such patterns in both of these situations necessitates the use of a lexicon equipped with part of speech tags. Since we are interested in knowledge-free induction of MWUs, these approaches are less directly related to our work. Furthermore, we are not really interested in identifying constructs such as general noun phrases as the above rules m</context>
<context position="8734" citStr="Daille, 1996" startWordPosition="1288" endWordPosition="1289">d “U. S.,” we opt to treat punctuation as words. Once we tokenize, we use Church’s (1995) suffix array approach to identify word n-grams that occur at least T times (for T=10). We then rank-order the Table 1: Probabilistic Approaches METHOD FORMULA Frequency fXY (Guiliano, 1964) Pointwise Mutual log2 (PXY / PXPY) Information (MI) (Fano, 1961; Church and Hanks, 1990) Selectional PX|YMIXY Association (Resnik, 1996) 1:Z PrZ|YMIZY Symmetric PXY2 / PXPY Conditional Probability (Ferreira and Pereira, 1999) Dice Formula 2 fXY / (fX+fY) (Dice, 1945) Log-likelihood [PXPYPXPY]fY (Dunning, 1993; �2log Daille, 1996) [PXYPXY]fXY[PXYPXY]fXY 2 (fij � ij)2 Chi-squared (� ) EiE{X,X} (Church and Gale, 1991) j�{Y,Y} ij Z-Score fXY � XY (Smadja, 1993; Fontenelle, et al., 1994) XY (1-(XY/N)) Student’s t-Score fXY - XY (Church and Hanks, 1990) fXY (1�(fXY/N)) n-gram list in accordance to each probabilistic algorithm. This task is non-trivial since most algorithms were originally suited for finding twoword collocations. We must therefore decide how to expand the algorithms to identify general n-grams (say, C=w1w2 ...wn). We can either generalize or approximate. Since generalizing requires exponential compute </context>
<context position="10630" citStr="Daille, 1996" startWordPosition="1570" endWordPosition="1571">should increase. This is particularly true if we are looking for MWU headwords for a general versus specialized dictionary. Phrases that appear in one source may in fact be general MWUs, but frequently, they are text-specific units. Hence, precision gained by excluding single-source n-grams may be worth losses in recall. We will measure this trade-off. Second, evaluating with punctuation as words and applying no filtering mechanism may unfairly bias against some algorithms. Pre- or post-processing of n-grams with a linguistic filter has shown to improve some induction algorithms’ performance (Daille, 1996). Since we need knowledge-poor induction, we cannot use human-suggested filtering rules as in Section 2.2. Yet we can filter by pruning n-grams whose beginning or ending word is among the top N most frequent words. This unfortunately eliminates acronyms like “U. S.” and phrasal verbs like “throw up.” However, discarding some words may be worthwhile if the final list of n-grams is richer in terms of MRD headwords. We therefore evaluate with such an automatic filter, arbitrarily (and without optimization) choosing N=75. 4 Evaluating Performance A natural scoring standard is to select a language </context>
</contexts>
<marker>Daille, 1996</marker>
<rawString>Daille, B. (1996). “Study and Implementation of Combined Techniques from Automatic Extraction of Terminology” Chap. 3 of &amp;quot;The Balancing Act&amp;quot;: Combining Symbolic and Statistical Approaches to Language (Klavans, J., Resnik, P. (eds.)), pp. 49-66</rawString>
</citation>
<citation valid="true">
<authors>
<author>DARPA</author>
</authors>
<title>DARPA text collections:</title>
<date>1989</date>
<journal>A.P. Material, 1988-1990, Ziff Communications Corpus,</journal>
<booktitle>Congressional Record of the 103 Congress, rd and</booktitle>
<location>Los Angeles Times.</location>
<marker>DARPA, 1989</marker>
<rawString>DARPA (1993-1997). DARPA text collections: A.P. Material, 1988-1990, Ziff Communications Corpus, 1989, Congressional Record of the 103 Congress, rd and Los Angeles Times.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Deerwester</author>
<author>S T Dumais</author>
<author>G W Furnas</author>
<author>T K Landauer</author>
<author>R Harshman</author>
</authors>
<title>Indexing by Latent Semantic Analysis.</title>
<date>1990</date>
<journal>Journal of the American Society of Information Science,</journal>
<volume>41</volume>
<location>Ph.D., MIT</location>
<note>Foundations of</note>
<contexts>
<context position="20297" citStr="Deerwester, et al (1990)" startWordPosition="3131" endWordPosition="3134">3 .107 .194 Log Like .023 .043 .087 .162 T-score .025 .027 .110 .142 Freq .016 .017 .104 .134 one can see that Z-scores, $ , and 2 SCP have virtually identical results and seem to best identify MWU headwords (particularly if proper nouns are desired). Yet there is still significant room for improvement. 5 Improvement strategies Can performance be improved? Numerous strategies could be explored. An idea we discuss here tries using induced semantics to rescore the output of the best algorithm (filtered, cross-sourced Zscore) and eliminate semantically compositional or modifiable MWU hypotheses. Deerwester, et al (1990) introduced Latent Semantic Analysis (LSA) as a computational technique for inducing semantic relationships between words and documents. It forms highdimensional vectors using word counts and uses singular value decomposition to project those vectors into an optimal k-dimensional, “semantic” subspace (see Landauer, et al, 1998). Following an approach from Schütze (1993), we (denoted by SL) for C’s subcomponents. These can either include ({X } n) or exclude QX* } n ) C’s counts. We seek to see if induced sema4ics can help eliminate incorrectly-chosen MWUs. As will be shown, the effort using sem</context>
</contexts>
<marker>Deerwester, Dumais, Furnas, Landauer, Harshman, 1990</marker>
<rawString>Deerwester, S., S.T. Dumais, G.W. Furnas, T.K. Landauer, and R. Harshman. (1990) Indexing by Latent Semantic Analysis. Journal of the American Society of Information Science, Vol. 41 de Marcken, C. (1996) Unsupervised Language Acquisition, Ph.D., MIT Manning, C.D., Schütze, H. (1999) Foundations of</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Dias</author>
<author>S Guilloré</author>
<author>J G Pereira Lopes</author>
</authors>
<title>Statistical Natural Language Processing,</title>
<date>1999</date>
<publisher>MIT Press,</publisher>
<location>MA,</location>
<marker>Dias, Guilloré, Lopes, 1999</marker>
<rawString>Dias, G., S. Guilloré, J.G. Pereira Lopes (1999). Statistical Natural Language Processing, MIT Press, Language independent automatic acquisition of rigid Cambridge, MA, 1999. multiword units from unrestricted text corpora. TALN, Mikheev, A., Finch, S. (1997). Collocation lattices and Cargèse. maximum entropy models. WVLC, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L R Dice</author>
</authors>
<title>Measures of the amount of ecologic associations between species.</title>
<date>1945</date>
<journal>Journal of Ecology,</journal>
<volume>26</volume>
<contexts>
<context position="8670" citStr="Dice, 1945" startWordPosition="1281" endWordPosition="1282">Since we are equally interested in finding units like “Dr.” and “U. S.,” we opt to treat punctuation as words. Once we tokenize, we use Church’s (1995) suffix array approach to identify word n-grams that occur at least T times (for T=10). We then rank-order the Table 1: Probabilistic Approaches METHOD FORMULA Frequency fXY (Guiliano, 1964) Pointwise Mutual log2 (PXY / PXPY) Information (MI) (Fano, 1961; Church and Hanks, 1990) Selectional PX|YMIXY Association (Resnik, 1996) 1:Z PrZ|YMIZY Symmetric PXY2 / PXPY Conditional Probability (Ferreira and Pereira, 1999) Dice Formula 2 fXY / (fX+fY) (Dice, 1945) Log-likelihood [PXPYPXPY]fY (Dunning, 1993; �2log Daille, 1996) [PXYPXY]fXY[PXYPXY]fXY 2 (fij � ij)2 Chi-squared (� ) EiE{X,X} (Church and Gale, 1991) j�{Y,Y} ij Z-Score fXY � XY (Smadja, 1993; Fontenelle, et al., 1994) XY (1-(XY/N)) Student’s t-Score fXY - XY (Church and Hanks, 1990) fXY (1�(fXY/N)) n-gram list in accordance to each probabilistic algorithm. This task is non-trivial since most algorithms were originally suited for finding twoword collocations. We must therefore decide how to expand the algorithms to identify general n-grams (say, C=w1w2 ...wn). We can either generalize </context>
</contexts>
<marker>Dice, 1945</marker>
<rawString>Dice, L.R. (1945). Measures of the amount of ecologic associations between species. Journal of Ecology, 26, 1945.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics.</journal>
<volume>19</volume>
<contexts>
<context position="8713" citStr="Dunning, 1993" startWordPosition="1285" endWordPosition="1286">g units like “Dr.” and “U. S.,” we opt to treat punctuation as words. Once we tokenize, we use Church’s (1995) suffix array approach to identify word n-grams that occur at least T times (for T=10). We then rank-order the Table 1: Probabilistic Approaches METHOD FORMULA Frequency fXY (Guiliano, 1964) Pointwise Mutual log2 (PXY / PXPY) Information (MI) (Fano, 1961; Church and Hanks, 1990) Selectional PX|YMIXY Association (Resnik, 1996) 1:Z PrZ|YMIZY Symmetric PXY2 / PXPY Conditional Probability (Ferreira and Pereira, 1999) Dice Formula 2 fXY / (fX+fY) (Dice, 1945) Log-likelihood [PXPYPXPY]fY (Dunning, 1993; �2log Daille, 1996) [PXYPXY]fXY[PXYPXY]fXY 2 (fij � ij)2 Chi-squared (� ) EiE{X,X} (Church and Gale, 1991) j�{Y,Y} ij Z-Score fXY � XY (Smadja, 1993; Fontenelle, et al., 1994) XY (1-(XY/N)) Student’s t-Score fXY - XY (Church and Hanks, 1990) fXY (1�(fXY/N)) n-gram list in accordance to each probabilistic algorithm. This task is non-trivial since most algorithms were originally suited for finding twoword collocations. We must therefore decide how to expand the algorithms to identify general n-grams (say, C=w1w2 ...wn). We can either generalize or approximate. Since generalizing requires</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Dunning, T (1993). Accurate methods for the statistics of surprise and coincidence. Computational Linguistics. Vol. 19, No. 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Fano</author>
</authors>
<title>Transmission of Information.</title>
<date>1961</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="8464" citStr="Fano, 1961" startWordPosition="1252" endWordPosition="1253">ss Prior to applying the algorithms, we lemmatize using a weakly-informed tokenizer that knows only that whitespace and punctuation separate words. Punctuation can either be discarded or treated as words. Since we are equally interested in finding units like “Dr.” and “U. S.,” we opt to treat punctuation as words. Once we tokenize, we use Church’s (1995) suffix array approach to identify word n-grams that occur at least T times (for T=10). We then rank-order the Table 1: Probabilistic Approaches METHOD FORMULA Frequency fXY (Guiliano, 1964) Pointwise Mutual log2 (PXY / PXPY) Information (MI) (Fano, 1961; Church and Hanks, 1990) Selectional PX|YMIXY Association (Resnik, 1996) 1:Z PrZ|YMIZY Symmetric PXY2 / PXPY Conditional Probability (Ferreira and Pereira, 1999) Dice Formula 2 fXY / (fX+fY) (Dice, 1945) Log-likelihood [PXPYPXPY]fY (Dunning, 1993; �2log Daille, 1996) [PXYPXY]fXY[PXYPXY]fXY 2 (fij � ij)2 Chi-squared (� ) EiE{X,X} (Church and Gale, 1991) j�{Y,Y} ij Z-Score fXY � XY (Smadja, 1993; Fontenelle, et al., 1994) XY (1-(XY/N)) Student’s t-Score fXY - XY (Church and Hanks, 1990) fXY (1�(fXY/N)) n-gram list in accordance to each probabilistic algorithm. This task is non-trivial s</context>
</contexts>
<marker>Fano, 1961</marker>
<rawString>Fano, R. (1961). Transmission of Information. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Finke</author>
<author>A Weibel</author>
</authors>
<title>Speaking mode dependent pronunciation modeling in large vocabulary conversational speech recognition.</title>
<date>1997</date>
<booktitle>Eurospeech-97.</booktitle>
<contexts>
<context position="1002" citStr="Finke &amp; Weibel, 1997" startWordPosition="134" endWordPosition="137">g collocation-finders and illustrate the continuing need for improvement. We use Latent Semantic Analysis to make modest gains in performance, but we show the significant challenges encountered in trying this approach. 1 Introduction A multiword unit (MWU) is a connected collocation: a sequence of neighboring words “whose exact and unambiguous meaning or connotation cannot be derived from the meaning or connotation of its components” (Choueka, 1988). In other words, MWUs are typically non-compositional at some linguistic level. For example, phonological non-compositionality has been observed (Finke &amp; Weibel, 1997; Gregory, et al, 1999) where words like “got” [gat] and “to” [tu] change phonetically to “gotta” [gave] when combined. We have interest in inducing headwords for machine-readable dictionaries (MRDs), so our interest is in semantic rather than phonological non-compositionality. As an example of semantic non-compositionality, consider “compact disk”: one could not deduce that it was a music medium by only considering the semantics of “compact” and “disk.” MWUs may also be non-substitutable and/or non-modifiable (Manning and Schütze, 1999). Nonsubstitutability implies that substituting a word of</context>
</contexts>
<marker>Finke, Weibel, 1997</marker>
<rawString>Finke, M. and Weibel, A. (1997) Speaking mode dependent pronunciation modeling in large vocabulary conversational speech recognition. Eurospeech-97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ferreira da Silva</author>
<author>Pereira Lopes J</author>
<author>G</author>
</authors>
<title>A local maxima method and a fair dispersion normalization for extracting multi-word units from corpora.</title>
<date>1999</date>
<booktitle>Sixth Meeting on Mathematics of Language,</booktitle>
<pages>369--381</pages>
<marker>Silva, J, G, 1999</marker>
<rawString>Ferreira da Silva, J., Pereira Lopes, G. (1999). A local maxima method and a fair dispersion normalization for extracting multi-word units from corpora. Sixth Meeting on Mathematics of Language, pp. 369-381.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Fontenelle</author>
<author>W Brüls</author>
<author>L Thomas</author>
<author>T Vanallemeersch</author>
<author>J Jansen</author>
</authors>
<title>DECIDE, MLAP-Project 93-19, deliverable D-1a: Survey of collocation extraction tools.</title>
<date>1994</date>
<tech>Tech. Report,</tech>
<institution>Univ. of Liege, Liege, Belgium.</institution>
<contexts>
<context position="8893" citStr="Fontenelle, et al., 1994" startWordPosition="1311" endWordPosition="1314"> at least T times (for T=10). We then rank-order the Table 1: Probabilistic Approaches METHOD FORMULA Frequency fXY (Guiliano, 1964) Pointwise Mutual log2 (PXY / PXPY) Information (MI) (Fano, 1961; Church and Hanks, 1990) Selectional PX|YMIXY Association (Resnik, 1996) 1:Z PrZ|YMIZY Symmetric PXY2 / PXPY Conditional Probability (Ferreira and Pereira, 1999) Dice Formula 2 fXY / (fX+fY) (Dice, 1945) Log-likelihood [PXPYPXPY]fY (Dunning, 1993; �2log Daille, 1996) [PXYPXY]fXY[PXYPXY]fXY 2 (fij � ij)2 Chi-squared (� ) EiE{X,X} (Church and Gale, 1991) j�{Y,Y} ij Z-Score fXY � XY (Smadja, 1993; Fontenelle, et al., 1994) XY (1-(XY/N)) Student’s t-Score fXY - XY (Church and Hanks, 1990) fXY (1�(fXY/N)) n-gram list in accordance to each probabilistic algorithm. This task is non-trivial since most algorithms were originally suited for finding twoword collocations. We must therefore decide how to expand the algorithms to identify general n-grams (say, C=w1w2 ...wn). We can either generalize or approximate. Since generalizing requires exponential compute time and memory for several of the algorithms, approximation is an attractive alternative. One approximation redefines X and Y to be, respectively, the word se</context>
</contexts>
<marker>Fontenelle, Brüls, Thomas, Vanallemeersch, Jansen, 1994</marker>
<rawString>Fontenelle, T., Brüls, W., Thomas, L., Vanallemeersch, T., Jansen, J. (1994). DECIDE, MLAP-Project 93-19, deliverable D-1a: Survey of collocation extraction tools. Tech. Report, Univ. of Liege, Liege, Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V E Giuliano</author>
</authors>
<title>The interpretation of word associations.&amp;quot; In</title>
<date>1964</date>
<journal>National Bureau of Standards Miscellaneous Publication</journal>
<volume>269</volume>
<pages>25--32</pages>
<marker>Giuliano, 1964</marker>
<rawString>Giuliano, V. E. (1964) &amp;quot;The interpretation of word associations.&amp;quot; In M.E. Stevens et al. (Eds.) Statistical association methods for mechanized documentation, pp. 25-32. National Bureau of Standards Miscellaneous Publication 269, Dec. 15, 1965.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M L Gregory</author>
<author>W D Raymond</author>
<author>A Bell</author>
<author>E FoslerLussier</author>
<author>D Jurafsky</author>
</authors>
<title>The effects of collocational strength and contextual predictability in lexical production. CLS99,</title>
<date>1999</date>
<institution>University of Chicago.</institution>
<contexts>
<context position="1025" citStr="Gregory, et al, 1999" startWordPosition="138" endWordPosition="141">and illustrate the continuing need for improvement. We use Latent Semantic Analysis to make modest gains in performance, but we show the significant challenges encountered in trying this approach. 1 Introduction A multiword unit (MWU) is a connected collocation: a sequence of neighboring words “whose exact and unambiguous meaning or connotation cannot be derived from the meaning or connotation of its components” (Choueka, 1988). In other words, MWUs are typically non-compositional at some linguistic level. For example, phonological non-compositionality has been observed (Finke &amp; Weibel, 1997; Gregory, et al, 1999) where words like “got” [gat] and “to” [tu] change phonetically to “gotta” [gave] when combined. We have interest in inducing headwords for machine-readable dictionaries (MRDs), so our interest is in semantic rather than phonological non-compositionality. As an example of semantic non-compositionality, consider “compact disk”: one could not deduce that it was a music medium by only considering the semantics of “compact” and “disk.” MWUs may also be non-substitutable and/or non-modifiable (Manning and Schütze, 1999). Nonsubstitutability implies that substituting a word of the MWU with its synon</context>
</contexts>
<marker>Gregory, Raymond, Bell, FoslerLussier, Jurafsky, 1999</marker>
<rawString>Gregory, M. L., Raymond, W.D., Bell, A., FoslerLussier, E., Jurafsky, D. (1999). The effects of collocational strength and contextual predictability in lexical production. CLS99, University of Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Heid</author>
</authors>
<title>On ways words work together.</title>
<date>1994</date>
<tech>Euralex99.</tech>
<marker>Heid, 1994</marker>
<rawString>Heid, U. (1994). On ways words work together. Euralex99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hindle</author>
</authors>
<title>Noun classification from predicateargument structures.</title>
<date>1990</date>
<booktitle>Proceedings of the Annual Meeting of the ACL,</booktitle>
<pages>268--275</pages>
<marker>Hindle, 1990</marker>
<rawString>Hindle, D. (1990). Noun classification from predicateargument structures. Proceedings of the Annual Meeting of the ACL, pp. 268-275.</rawString>
</citation>
<citation valid="true">
<authors>
<author>http www infoplease com</author>
</authors>
<title>Searches between</title>
<date>2000</date>
<location>and</location>
<marker>com, 2000</marker>
<rawString>InfoPlease.com (2000-1). http://www.infoplease.com. Searches between March 2000 and April 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Jacquemin</author>
<author>J L Klavans</author>
<author>E Tzoukermann</author>
</authors>
<title>Expansion of multi-word terms for indexing and retrieval using morphology and syntax.</title>
<date>1997</date>
<booktitle>Proc. of ACL</booktitle>
<pages>24--31</pages>
<location>Madrid,</location>
<contexts>
<context position="6522" citStr="Jacquemin, et al., 1997" startWordPosition="946" endWordPosition="949">approaches could be applied to languages where word delimiters exist (such as in European languages delimited by the space character). However, in such languages, it seems more prudent to simply take advantage of delimiters rather than introducing potential errors by trying to find word boundaries while ignoring knowledge of the level and identify appropriate word combinations. 2.2 Word-based, knowledge-driven Strategies Some researchers start with words and propose MWU induction methods that make use of parts of speech, lexicons, syntax or other linguistic structure (Justeson and Katz, 1995; Jacquemin, et al., 1997; Daille, 1996). For example, Justeson and Katz indicated that the patterns NOUN NOUN and ADJ NOUN are very typical of MWUs. Daille also suggests that in French, technical MWUs follow patterns such as “NOUN de NOUN&amp;quot; (1996, p. 50). To find word combinations that satisfy such patterns in both of these situations necessitates the use of a lexicon equipped with part of speech tags. Since we are interested in knowledge-free induction of MWUs, these approaches are less directly related to our work. Furthermore, we are not really interested in identifying constructs such as general noun phrases as th</context>
</contexts>
<marker>Jacquemin, Klavans, Tzoukermann, 1997</marker>
<rawString>Jacquemin, C., Klavans, J.L., &amp; Tzoukermann, E. (1997). Expansion of multi-word terms for indexing and retrieval using morphology and syntax. Proc. of ACL 1997, Madrid, pp. 24-31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Justeson</author>
</authors>
<title>and S.M.Katz</title>
<date>1995</date>
<journal>Natural Language Engineering</journal>
<marker>Justeson, 1995</marker>
<rawString>Justeson, J.S. and S.M.Katz (1995). Technical terminology: some linguistic properties and an algorithm for identification in text. Natural Language Engineering 1:9-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilgariff</author>
<author>T Rose</author>
</authors>
<title>Metrics for corpus similarity &amp; homogeneity.</title>
<date>1998</date>
<tech>Manuscript,</tech>
<institution>ITRI, University of Brighton.</institution>
<marker>Kilgariff, Rose, 1998</marker>
<rawString>Kilgariff, A., &amp; Rose, T. (1998). Metrics for corpus similarity &amp; homogeneity. Manuscript, ITRI, University of Brighton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T K Landauer</author>
<author>P W Foltz</author>
<author>D Laham</author>
</authors>
<title>Introduction to Latent Semantic Analysis.</title>
<date>1998</date>
<booktitle>Discourse Processes.</booktitle>
<volume>25</volume>
<pages>259--284</pages>
<contexts>
<context position="20626" citStr="Landauer, et al, 1998" startWordPosition="3176" endWordPosition="3179">an performance be improved? Numerous strategies could be explored. An idea we discuss here tries using induced semantics to rescore the output of the best algorithm (filtered, cross-sourced Zscore) and eliminate semantically compositional or modifiable MWU hypotheses. Deerwester, et al (1990) introduced Latent Semantic Analysis (LSA) as a computational technique for inducing semantic relationships between words and documents. It forms highdimensional vectors using word counts and uses singular value decomposition to project those vectors into an optimal k-dimensional, “semantic” subspace (see Landauer, et al, 1998). Following an approach from Schütze (1993), we (denoted by SL) for C’s subcomponents. These can either include ({X } n) or exclude QX* } n ) C’s counts. We seek to see if induced sema4ics can help eliminate incorrectly-chosen MWUs. As will be shown, the effort using semantics in this nature has a very small payoff for the expended cost. 5.1 Non-compositionality Non-compositionality is a key component of valid MWUs, so we may desire to emphasize n-grams that are semantically non-compositional. Suppose we wanted to determine if C (defined above) were noncompositional. Then given some meaning fu</context>
</contexts>
<marker>Landauer, Foltz, Laham, 1998</marker>
<rawString>Landauer, T.K., P.W. Foltz, and D. Laham. (1998) Introduction to Latent Semantic Analysis. Discourse Processes. Vol. 25, pp. 259-284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
</authors>
<title>An on-line lexical database,”</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<marker>Miller, 1990</marker>
<rawString>Miller, G. (1990).“WordNet: An on-line lexical database,” International Journal of Lexicography, 3(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>http www onelook com</author>
</authors>
<title>Searches between</title>
<date>2000</date>
<location>and</location>
<marker>com, 2000</marker>
<rawString>OneLook.com (2000-1). http://www.onelook.com. Searches between March 2000 and April 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Ponte</author>
<author>B W Croft</author>
</authors>
<title>Useg: A Retargetable word segmentation procedure for information retrieval.</title>
<date>1996</date>
<booktitle>Symposium on Document Analysis and Information Retrieval ‘96.</booktitle>
<tech>Technical Report TR96-2,</tech>
<institution>University of Massachusetts.</institution>
<contexts>
<context position="5435" citStr="Ponte and Croft 1996" startWordPosition="795" endWordPosition="798">d segmentation as a means of placing delimiters in that stream so as to separate logical groupings of symbols from one another. A segmentation process may find that a symbol stream should not be delimited even though subcomponents of the stream have been seen elsewhere. In such cases, these larger units may be MWUs. The principal work on segmentation has focused either on identifying words in phonetic streams (Saffran, et. al, 1996; Brent, 1996; de Marcken, 1996) or on tokenizing Asian and Indian languages that do not normally include word delimiters in their orthography (Sproat, et al, 1996; Ponte and Croft 1996; Shimohata, 1997; Teahan, et al., 2000; and many others). Such efforts have employed various strategies for segmentation, including the use of hidden Markov models, minimum description length, dictionary-based approaches, probabilistic automata, transformation-based learning, and text compression. Some of these approaches require significant sources of human knowledge, though others, especially those that follow data compression or HMM schemes, do not. These approaches could be applied to languages where word delimiters exist (such as in European languages delimited by the space character). H</context>
</contexts>
<marker>Ponte, Croft, 1996</marker>
<rawString>Ponte, J.M., Croft, B.W. (1996). Useg: A Retargetable word segmentation procedure for information retrieval. Symposium on Document Analysis and Information Retrieval ‘96. Technical Report TR96-2, University of Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
</authors>
<title>Selectional constraints: an information-theoretic model and its computational realization.</title>
<date>1996</date>
<journal>Cognition.</journal>
<volume>61</volume>
<pages>127--159</pages>
<contexts>
<context position="8538" citStr="Resnik, 1996" startWordPosition="1261" endWordPosition="1262">ed tokenizer that knows only that whitespace and punctuation separate words. Punctuation can either be discarded or treated as words. Since we are equally interested in finding units like “Dr.” and “U. S.,” we opt to treat punctuation as words. Once we tokenize, we use Church’s (1995) suffix array approach to identify word n-grams that occur at least T times (for T=10). We then rank-order the Table 1: Probabilistic Approaches METHOD FORMULA Frequency fXY (Guiliano, 1964) Pointwise Mutual log2 (PXY / PXPY) Information (MI) (Fano, 1961; Church and Hanks, 1990) Selectional PX|YMIXY Association (Resnik, 1996) 1:Z PrZ|YMIZY Symmetric PXY2 / PXPY Conditional Probability (Ferreira and Pereira, 1999) Dice Formula 2 fXY / (fX+fY) (Dice, 1945) Log-likelihood [PXPYPXPY]fY (Dunning, 1993; �2log Daille, 1996) [PXYPXY]fXY[PXYPXY]fXY 2 (fij � ij)2 Chi-squared (� ) EiE{X,X} (Church and Gale, 1991) j�{Y,Y} ij Z-Score fXY � XY (Smadja, 1993; Fontenelle, et al., 1994) XY (1-(XY/N)) Student’s t-Score fXY - XY (Church and Hanks, 1990) fXY (1�(fXY/N)) n-gram list in accordance to each probabilistic algorithm. This task is non-trivial since most algorithms were originally suited for finding twoword collocatio</context>
</contexts>
<marker>Resnik, 1996</marker>
<rawString>Resnik, P. (1996). Selectional constraints: an information-theoretic model and its computational realization. Cognition. Vol. 61, pp. 127-159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Saffran</author>
<author>E L Newport</author>
<author>R N Aslin</author>
</authors>
<title>Word segmentation: the role of distributional cues.</title>
<date>1996</date>
<journal>Journal of Memory and Language,</journal>
<volume>25</volume>
<pages>606--621</pages>
<marker>Saffran, Newport, Aslin, 1996</marker>
<rawString>Saffran, J.R., Newport, E.L., and Aslin, R.N. (1996). Word segmentation: the role of distributional cues. Journal of Memory and Language, Vol. 25, pp. 606-621.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Schone</author>
<author>D Jurafsky</author>
</authors>
<title>Knowledge-free induction of morphology using latent semantic analysis.</title>
<date>2000</date>
<booktitle>Proc. of the Computational Natural Language Learning Conference, Lisbon,</booktitle>
<pages>67--72</pages>
<contexts>
<context position="25413" citStr="Schone and Jurafsky, 2000" startWordPosition="3923" endWordPosition="3926">_University and Elvis_Presley, so they should have similar meanings. This begs the question: can induced semantics help at all? The answer is “yes.” The key is using LSA where it does best: finding things that are similar — or substitutable. 5.2 Non-substitutivity For every collocation C=X1X2..Xi-1XiXi+1..Xn, we attempt to find other similar patterns in the data, X1X2..Xi-1YXi+1..Xn. If Xi and Y are semantically related, chances are that C is substitutable. Since LSA excels at finding semantic correlations, we can compare 52Xi and SLY to see if C is substitutable. We use our earlier approach (Schone and Jurafsky, 2000) for performing the comparison; namely, for every word W, we compute cos(52w, SLR) for 200 randomly chosen words, R. This allows for computation of a correlaton mean (µW) and standard deviation (6W) between W and other words. As before, we then compute a normalized cosine score ( ) between words of interest, defined by cos min cos(52m , flY)-µk cos(Xi,Y) = ke{Xi,Y} With this set-up, we now look for substitutivity. Note that phrases may be substitutable and still be headword if their substitute phrases are themselves MWUs. For example, dioxide in carbon_dioxide is semantically similar to monoxi</context>
</contexts>
<marker>Schone, Jurafsky, 2000</marker>
<rawString>Schone, P. and D. Jurafsky. (2000) Knowledge-free induction of morphology using latent semantic analysis. Proc. of the Computational Natural Language Learning Conference, Lisbon, pp. 67-72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schütze</author>
</authors>
<title>Distributed syntactic representations with an application to part-of-speech tagging.</title>
<date>1993</date>
<booktitle>Proceedings of the IEEE International Conference on Neural Networks,</booktitle>
<pages>1504--1509</pages>
<contexts>
<context position="20669" citStr="Schütze (1993)" startWordPosition="3184" endWordPosition="3185">ld be explored. An idea we discuss here tries using induced semantics to rescore the output of the best algorithm (filtered, cross-sourced Zscore) and eliminate semantically compositional or modifiable MWU hypotheses. Deerwester, et al (1990) introduced Latent Semantic Analysis (LSA) as a computational technique for inducing semantic relationships between words and documents. It forms highdimensional vectors using word counts and uses singular value decomposition to project those vectors into an optimal k-dimensional, “semantic” subspace (see Landauer, et al, 1998). Following an approach from Schütze (1993), we (denoted by SL) for C’s subcomponents. These can either include ({X } n) or exclude QX* } n ) C’s counts. We seek to see if induced sema4ics can help eliminate incorrectly-chosen MWUs. As will be shown, the effort using semantics in this nature has a very small payoff for the expended cost. 5.1 Non-compositionality Non-compositionality is a key component of valid MWUs, so we may desire to emphasize n-grams that are semantically non-compositional. Suppose we wanted to determine if C (defined above) were noncompositional. Then given some meaning function, `I&apos;, C should satisfy an equation l</context>
</contexts>
<marker>Schütze, 1993</marker>
<rawString>Schütze, H. (1993) Distributed syntactic representations with an application to part-of-speech tagging. Proceedings of the IEEE International Conference on Neural Networks, pp. 1504-1509.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Shimohata</author>
<author>T Sugio</author>
<author>J Nagata</author>
</authors>
<title>Retrieving collocations by co-occurrences and word order constraints.</title>
<date>1997</date>
<booktitle>Proceedings of the 35 Annual Mtg. of the th Assoc. for Computational Linguistics.</booktitle>
<pages>476--481</pages>
<publisher>Morgan-Kauffman Publishers,</publisher>
<location>Madrid.</location>
<marker>Shimohata, Sugio, Nagata, 1997</marker>
<rawString>Shimohata, S., Sugio, T., Nagata, J. (1997). Retrieving collocations by co-occurrences and word order constraints. Proceedings of the 35 Annual Mtg. of the th Assoc. for Computational Linguistics. Madrid. Morgan-Kauffman Publishers, San Francisco. Pp. 476-481.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Smadja</author>
</authors>
<title>Retrieving collocations from text:</title>
<date>1993</date>
<booktitle>Xtract. Computational Linguistics,</booktitle>
<pages>19--143</pages>
<contexts>
<context position="8866" citStr="Smadja, 1993" startWordPosition="1309" endWordPosition="1310">ams that occur at least T times (for T=10). We then rank-order the Table 1: Probabilistic Approaches METHOD FORMULA Frequency fXY (Guiliano, 1964) Pointwise Mutual log2 (PXY / PXPY) Information (MI) (Fano, 1961; Church and Hanks, 1990) Selectional PX|YMIXY Association (Resnik, 1996) 1:Z PrZ|YMIZY Symmetric PXY2 / PXPY Conditional Probability (Ferreira and Pereira, 1999) Dice Formula 2 fXY / (fX+fY) (Dice, 1945) Log-likelihood [PXPYPXPY]fY (Dunning, 1993; �2log Daille, 1996) [PXYPXY]fXY[PXYPXY]fXY 2 (fij � ij)2 Chi-squared (� ) EiE{X,X} (Church and Gale, 1991) j�{Y,Y} ij Z-Score fXY � XY (Smadja, 1993; Fontenelle, et al., 1994) XY (1-(XY/N)) Student’s t-Score fXY - XY (Church and Hanks, 1990) fXY (1�(fXY/N)) n-gram list in accordance to each probabilistic algorithm. This task is non-trivial since most algorithms were originally suited for finding twoword collocations. We must therefore decide how to expand the algorithms to identify general n-grams (say, C=w1w2 ...wn). We can either generalize or approximate. Since generalizing requires exponential compute time and memory for several of the algorithms, approximation is an attractive alternative. One approximation redefines X and Y to be</context>
</contexts>
<marker>Smadja, 1993</marker>
<rawString>Smadja, F. (1993). Retrieving collocations from text: Xtract. Computational Linguistics, 19:143-177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sparck-Jones</author>
<author>C van Rijsbergen</author>
</authors>
<title>Report on the need for and provision of an “ideal” information retrieval text collection,</title>
<date>1975</date>
<booktitle>British Library Research and Development Report,</booktitle>
<pages>5266</pages>
<institution>Computer Laboratory, University of Cambridge.</institution>
<marker>Sparck-Jones, van Rijsbergen, 1975</marker>
<rawString>Sparck-Jones, K., C. van Rijsbergen (1975) Report on the need for and provision of an “ideal” information retrieval text collection, British Library Research and Development Report, 5266, Computer Laboratory, University of Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sproat</author>
<author>C Shih</author>
</authors>
<title>A statistical method for finding word boundaries in Chinese text.</title>
<date>1990</date>
<journal>Computer Processing of Chinese &amp; Oriental Languages,</journal>
<volume>4</volume>
<marker>Sproat, Shih, 1990</marker>
<rawString>Sproat R, Shih, C. (1990) A statistical method for finding word boundaries in Chinese text. Computer Processing of Chinese &amp; Oriental Languages, Vol. 4, No. 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sproat</author>
</authors>
<title>Morphology and Computation.</title>
<date>1992</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Sproat, 1992</marker>
<rawString>Sproat, R. (1992) Morphology and Computation. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R W Sproat</author>
<author>C Shih</author>
<author>W Gale</author>
<author>N Chang</author>
</authors>
<title>A stochastic finite-state word segmentation algorithm for Chinese.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<pages>3</pages>
<contexts>
<context position="5413" citStr="Sproat, et al, 1996" startWordPosition="791" endWordPosition="794"> stream of symbols and segmentation as a means of placing delimiters in that stream so as to separate logical groupings of symbols from one another. A segmentation process may find that a symbol stream should not be delimited even though subcomponents of the stream have been seen elsewhere. In such cases, these larger units may be MWUs. The principal work on segmentation has focused either on identifying words in phonetic streams (Saffran, et. al, 1996; Brent, 1996; de Marcken, 1996) or on tokenizing Asian and Indian languages that do not normally include word delimiters in their orthography (Sproat, et al, 1996; Ponte and Croft 1996; Shimohata, 1997; Teahan, et al., 2000; and many others). Such efforts have employed various strategies for segmentation, including the use of hidden Markov models, minimum description length, dictionary-based approaches, probabilistic automata, transformation-based learning, and text compression. Some of these approaches require significant sources of human knowledge, though others, especially those that follow data compression or HMM schemes, do not. These approaches could be applied to languages where word delimiters exist (such as in European languages delimited by t</context>
</contexts>
<marker>Sproat, Shih, Gale, Chang, 1996</marker>
<rawString>Sproat, R.W., Shih, C., Gale, W., Chang, N. (1996) A stochastic finite-state word segmentation algorithm for Chinese. Computational Linguistics, Vol. 22, #3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W J Teahan</author>
<author>W McNab Yingyin</author>
<author>R Witten</author>
<author>I H</author>
</authors>
<title>A Compression-based algorithm for Chinese word segmentation.</title>
<date>2000</date>
<journal>ACL</journal>
<volume>26</volume>
<pages>375--394</pages>
<contexts>
<context position="5474" citStr="Teahan, et al., 2000" startWordPosition="801" endWordPosition="804">limiters in that stream so as to separate logical groupings of symbols from one another. A segmentation process may find that a symbol stream should not be delimited even though subcomponents of the stream have been seen elsewhere. In such cases, these larger units may be MWUs. The principal work on segmentation has focused either on identifying words in phonetic streams (Saffran, et. al, 1996; Brent, 1996; de Marcken, 1996) or on tokenizing Asian and Indian languages that do not normally include word delimiters in their orthography (Sproat, et al, 1996; Ponte and Croft 1996; Shimohata, 1997; Teahan, et al., 2000; and many others). Such efforts have employed various strategies for segmentation, including the use of hidden Markov models, minimum description length, dictionary-based approaches, probabilistic automata, transformation-based learning, and text compression. Some of these approaches require significant sources of human knowledge, though others, especially those that follow data compression or HMM schemes, do not. These approaches could be applied to languages where word delimiters exist (such as in European languages delimited by the space character). However, in such languages, it seems mor</context>
</contexts>
<marker>Teahan, Yingyin, Witten, H, 2000</marker>
<rawString>Teahan, W.J., Yingyin, W. McNab, R, Witten, I.H. (2000). A Compression-based algorithm for Chinese word segmentation. ACL Vol. 26, No. 3, pp. 375-394.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>