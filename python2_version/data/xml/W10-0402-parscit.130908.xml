<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.015764">
<title confidence="0.954521">
Scientific Authoring Support: A Tool to Navigate in Typed Citation Graphs
</title>
<author confidence="0.96407">
Ulrich Sch¨afer
</author>
<affiliation confidence="0.701278666666667">
Language Technology Lab
German Research Center for
Artificial Intelligence (DFKI)
</affiliation>
<address confidence="0.900073">
D-66123 Saarbr¨ucken, Germany
</address>
<email confidence="0.996627">
ulrich.schaefer@dfki.de
</email>
<author confidence="0.992206">
Uwe Kasterka
</author>
<affiliation confidence="0.9959805">
Computer Science Department
Saarland University
</affiliation>
<address confidence="0.820039">
Campus
D-66123 Saarbr¨ucken, Germany
</address>
<email confidence="0.998447">
uwe.kasterka@dfki.de
</email>
<sectionHeader confidence="0.995625" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999608791666667">
Scientific authors urgently need help in man-
aging the fast increasing number of publica-
tions. We describe and demonstrate a tool
that supports authors in browsing graphically
through electronically available publications,
thus allowing them to quickly adapt to new
domains and publish faster. Navigation is as-
sisted by means of typed citation graphs, i.e.
we use methods and resources from compu-
tational linguistics to compute the kind of ci-
tation that is made from one paper to another
(refutation, use, confirmation etc.). To verify
the computed citation type, the user can in-
spect the highlighted citation sentence in the
original PDF document. While our classi-
fication methods used to generate a realistic
test data set are relatively simple and could
be combined with other proposed approaches,
we put a strong focus on usability and quick
navigation in the potentially huge graphs. In
the outlook, we argue that our tool could be
made part of a community approach to over-
come the sparseness and correctness dilemma
in citation classification.
</bodyText>
<sectionHeader confidence="0.990819" genericHeader="categories and subject descriptors">
1 Introduction and Motivation
</sectionHeader>
<bodyText confidence="0.999906555555556">
According to different studies, the number of scien-
tific works is doubled every 5-10 years. Important
issues to be addressed by the scientific community
are finding relevant information and avoiding redun-
dancy and duplication of work. The organization
and preservation of scientific knowledge in scientific
publications, vulgo text documents, thwarts these ef-
forts. From a viewpoint of a computer scientist, sci-
entific papers are just ‘unstructured information’.
</bodyText>
<page confidence="0.986464">
7
</page>
<bodyText confidence="0.999969558823529">
One specific, but very important aspect of the con-
tent of scientific papers is their relation to previous
work and, once published, their impact to subse-
quent or derived research. While it is still hard if
not impossible to capture and formalize the semantic
content of a scientific publication automatically, at
least citation properties and derived scientific impact
can be and usually are measured automatically on
the basis of simple citation graphs. In other words,
these graphs can be used to describe I/O behavior of
publications in a very simple way.
However, just counting citations is a very coarse
approach and does not tell much about the reasons
for citing one’s work in a specific situation. More-
over, once such measure is formalized and standard-
ized e.g. for science evaluation, it can be exploited
to tune up statistics. Since the first proposal of the
Science Citation Index (Garfield, 1955), it has also
provoked criticism.
In the bibliometrics and computational linguistics
literature, many proposals are available on how ci-
tations could be further classified by careful analy-
sis of citation sentences and context (Garfield, 1965;
Garzone, 1996; Mercer and Di Marco, 2004; Teufel
et al., 2006; Bornmann and Daniel, 2008).
The number of different classes proposed varies
from 3 to 35. Different authors try to identify di-
mensions and mutually exclusive classes, but the
more classes a schema contains, the more difficult
becomes the automatic classification.
The focus of our paper is to combine automatic
classification approaches with a tool that supports
scientists in graphically navigating through typed ci-
tation graphs (TCG). Such TCGs can be generated
</bodyText>
<subsectionHeader confidence="0.498242">
Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics and Writing, pages 7–14,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</subsectionHeader>
<bodyText confidence="0.99995762962963">
by augmenting a simple citation graph with informa-
tion synonymously called citation function (Teufel
et al., 2006), citation relation (Mercer and Di Marco,
2004) or citation sentiment, forming the labels of the
graph’s edges. In the following, we use the more
neutral and general term citation type.
The idea is to help scientists, especially those not
so familiar with an area, understanding the relations
between publications and quickly get an overview of
the field. Moreover, the goal is to embed this tool in
a larger framework for scientists that also supports
semantic search assisted by domain ontologies and
further tools for authoring support (Sch¨afer et al.,
2008).
Our paper is structured as follows. In Section 2,
we describe how we automatically compute the
typed citation graph from the raw text content of a
scientific paper corpus to generate realistic data for
testing the visualization and navigation tool. Sec-
tion 3 contains an evaluation of the quality of the
extracted unlabeled graphs and of the citation classi-
fication step. We then describe in Section 4 the ideas
of efficient and at the same time well-arranged visu-
alization and navigation in the typed citation graph.
We compare with related work in Section 5. Finally,
we conclude and give an outlook to future work in
Section 6.
</bodyText>
<sectionHeader confidence="0.9438905" genericHeader="method">
2 Data Preparation and Automatic
Citation Type Classification
</sectionHeader>
<bodyText confidence="0.999181411764706">
Our corpus is based on 6300 electronically-available
papers, a subset (published 2002-2008) of the ACL
Anthology (Bird et al., 2008), a comprehensive col-
lection of scientific conference and workshop papers
in the area of computational linguistics and language
technology.
The overall workflow of the employed tools and
data is shown in Fig. 1.
We ran the open source tool ParsCit (Councill et
al., 2008) to extract references lists and correspond-
ing citation sentences from raw paper texts. To build
the citation graph, we used the Levenshtein distance
(Levenshtein, 1966) to find and match titles and au-
thors of identical papers yet tolerating spelling and
PDF extraction errors.
To increase robustness, publication years were
not considered as they would hinder matches for
</bodyText>
<figureCaption confidence="0.995723">
Figure 1: Workflow from ACL Anthology data (top)
to citation graph navigation applet and citation sentence
viewer (bottom)
</figureCaption>
<bodyText confidence="0.99994175862069">
delayed journal publications. Generation of the
graph edges, i.e. matching of papers and reference
strings, is performed by means of the ACL ID, a
unique identifier for each paper, available for the
PDF (source nodes of references) and BibTeX files
(targets of references).
We evaluated the generated graph against the one
that was corrected manually by the ACL Anthol-
ogy Network (AAN) group (Radev et al., 2009) and
found that 10821 citation links were shared between
both and can be considered correct1.
3883 additional ones were in the AAN but not rec-
ognized by us, the other way round, 1021 discovered
by us were not in the AAN. In addition, the publica-
tion bases were not identical. The anthology net-
work data ends in February 2007 but covers years
before 2002, while our data covers 2002-2008 in-
clusively. Given the fact that our graph is computed
fully automatically, the result can be considered very
good.
In the next step, we augmented the citation graph
by types for each edge. In contrast to other ap-
proaches, we currently only consider the citation
sentence itself to determine the citation type, neither
a wider context, its position nor the abstract, title or
content of the cited paper. A reference (from the
references section at the end of a paper) may be as-
sociated with several citation sentences mentioning
the paper referenced at the end.
</bodyText>
<footnote confidence="0.9042445">
1We only consider intra-network links here, not those point-
ing to books or other publications outside the corpus.
</footnote>
<page confidence="0.996715">
8
</page>
<bodyText confidence="0.999361083333333">
In only considering the citation sentence itself, we
may lose some citation type information, as it may
be (also) contained in follow-up sentences referring
to the citation using a pronoun (“they”, “their ap-
proach” etc.). Considering follow-up or even pre-
ceding sentences is planned to be addressed in future
work.
After consulting the rich literature on citation
classification (Bornmann and Daniel, 2008; Gar-
zone, 1996; Teufel et al., 2006), we derived a simpli-
fied classification schema consisting of the follow-
ing five classes.
</bodyText>
<listItem confidence="0.9977545">
• Agree: The citing paper agrees with the cited
paper
• PRecycle: The citing paper uses an algorithm,
data, method or tool from the cited paper
• Negative: The paper is cited nega-
tively/contrastively
</listItem>
<sectionHeader confidence="0.625787" genericHeader="method">
3 Results: Distribution and Evaluation
</sectionHeader>
<bodyText confidence="0.999964142857143">
These pattern where then used for the classification
algorithm and applied to the extracted citation sen-
tences. In case of multiple citations with different
classes, a voting mechanism was applied were the
‘stronger’ classes (Agree, Negative, PRecycle) won
in standoff cases. For the total of 91419 citations we
obtained the results shown in Table 1.
</bodyText>
<table confidence="0.9954486">
Classes Citations Percent
Agree 3513 3.8%
Agree, Neutral 2020 2.2%
Negative 1147 1.2%
PRecycle 10609 11.6%
PRecycle, Agree 1419 1.6%
PRecycle, Agree, Neutral 922 1.0%
PRecycle, Neutral 3882 4.2%
Neutral 13430 14.7%
Undef 54837 60.0%
</table>
<tableCaption confidence="0.998196">
Table 1: Citation classification result
</tableCaption>
<listItem confidence="0.978452333333333">
• Neutral: The paper is cited neutrally
• Undef: impossible determine the sentiment of
the citation (fallback)
</listItem>
<bodyText confidence="0.9990295">
Then, we used a blend of methods to collect ver-
bal and non-verbal patterns (cue words) and asso-
ciated each with a class from the aforementioned
schema.
</bodyText>
<listItem confidence="0.999134533333333">
• A list from (Garzone, 1996) devised for
biomedical texts; it is largely applicable to the
computational linguistics domain as well.
• Simple negation of positive cue words to obtain
negative patterns.
• A list of automatically extracted synonyms and
antonyms (the latter for increasing number of
patterns for negative citations) from WordNet
(Miller et al., 1993).
• Automatically computed most frequent cooc-
currences from all extracted citation sentences
of the corpus using an open source cooccur-
rence tool (Banerjee and Pedersen, 2003).
• Inspection: browse and filter cue words manu-
ally, remove redundancies.
</listItem>
<bodyText confidence="0.999928846153846">
The numbers reflect a careful classification ap-
proach where uncertain citations are classified as
Undef. In case of multiple matches, the first (left-
most) was taken to achieve a unique result.
The results also confirm obervations made in
other works: (1) citation classification is a hard task,
(2) there are only a few strongly negative citations
which coincides with observations made by (Teufel
et al., 2006), (Pendlebury, 2009) and others, (3) the
majority of citations is neutral or of unknown type.
An evaluation on a test set of 100 citations spread
across all the types of papers with a manual check
of the accuracy of the computed labels showed an
overall accuracy of 30% mainly caused by the fact
that 90% of undefined hits were in fact neutral
(i.e., labeling all undefs neutral would increase ac-
curacy). Negative citations are sparse and unreliable
(33%), neutral ones are about 60% accurate, PRecy-
cle: 33%, Agree: 25%.
To sum up, our automatic classification approach
based on only local citation information could surely
be improved by applying methods described in the
literature, but it helped us to quickly (without an-
notation effort) generate a plausible data set for the
main task, visualization and navigation in the typed
citation graphs.
</bodyText>
<page confidence="0.990489">
9
</page>
<figureCaption confidence="0.999097">
Figure 2: Typed citation graph navigator applet
</figureCaption>
<sectionHeader confidence="0.9563395" genericHeader="method">
4 Visualization Algorithm and Navigation
User Interface
</sectionHeader>
<bodyText confidence="0.9992725">
The overall idea of the citation visualization and
navigation tool is simple and intuitive. Each paper is
represented by a node, all citations between papers
are drawn as edges between nodes where the color
of the edge indicates the computed (overall) citation
type, e.g. green for agree, red for negative, blue for
recycle and black for neutral or undefined.
To cope with flexible layouts and scalability of
the graph, we decided to use the open source tool
Java Universal Network/Graph Framework (JUNG,
http://jung.sourceforge.net). Its main advantages
over similar tools are that it supports user interaction
(clicking on nodes and edges, tool tips) and user-
implemented graph layout algorithms. A screenshot
of the final user interface is presented in Figure 2.
The decision for and development of the visual-
ization and navigation tool was mainly driven by the
fact that citation graphs quickly grow and become
unmanagable by humans when extended to the tran-
sitive closures of citing or cited papers of a given
publication. The sheer number of crossing edges
would make the display unreadable.
</bodyText>
<figureCaption confidence="0.998342">
Figure 3: Focused paper in the center
</figureCaption>
<bodyText confidence="0.999626666666667">
The main design goal therefore was reducing the
number of nodes and edges where possible and (by
default) have only one paper in focus (Fig. 3), with
</bodyText>
<page confidence="0.996798">
10
</page>
<bodyText confidence="0.998877083333333">
all cited papers on the left side (Fig. 4), and all citing
papers on the right (Fig. 5).
This also reflects a time line order where the ori-
gin (oldest papers) is on the left. In the graphical
user interface, the citation depth (default 1) is ad-
justable by a slider to higher numbers. The graph
display is updated upon change of the configured
depth.
each other), we devised a fan-out layout generation
(Fig. 6). It increases the width of the displayed
graph, but leads to better readability. Fan-out lay-
out can also be switched off in the user interface.
</bodyText>
<figureCaption confidence="0.992428">
Figure 4: Papers cited by the focused paper
</figureCaption>
<bodyText confidence="0.815463142857143">
At level 1, papers citing the citing papers (anal-
ogously for cited papers), are not fully drawn as
nodes, but only adumbrated by short ingoing or out-
going edges (arrows). However, the color of these
short edges still signifies the citation type and may
attract interest which can easily be satisfied by click-
ing on the edge’s remaining node (cf. screenshot in
</bodyText>
<figureCaption confidence="0.9977505">
Figure 2). When the mouse is moved over a node,
a tooltip text display pops up displaying full author
list and paper title.
Figure 5: Papers citing the focused paper
</figureCaption>
<bodyText confidence="0.9825245">
To avoid crossing edges caused by citations at
the same level (citing or cited papers also cite
</bodyText>
<figureCaption confidence="0.993018">
Figure 6: Fan-out layout: avoid crossing edges caused by
citations on the same level
</figureCaption>
<bodyText confidence="0.999825">
In addition, the graph layout algorithm orders pa-
pers chronologically in the vertical direction. Here,
we have implemented another technique that helps
to avoid crossing edges. As shown in Fig. 7, we
sort papers vertically by also taking into account the
position of its predecessor, the cited paper. It often
leads to less crossing edges.
</bodyText>
<figureCaption confidence="0.9816245">
Figure 7: Order: avoid crossing edges by ordering
chronologically (strict, simple variant on the left for com-
parison), taking into account the position of the cited pa-
per on the previous level (right)
</figureCaption>
<page confidence="0.997736">
11
</page>
<bodyText confidence="0.999845047619048">
By double-clicking on any node representing a
paper (cited or citing), this node can be made the
new center and the graph is re-arranged accordingly.
Zooming in and out is possible via mouse wheel
or shortcut buttons (‘overview’, ‘center’).
Using the right mouse button context menu on a
node, it is possible to open a details page for the
selected paper with bibliographic metadata and all
citations and types. All references in the document
with their citation sentences identified are displayed
in a structured list.
The citation context around a citation sentence
is shown as well, while the citation sentence itself
is colored according to the citation type color and
clickable. If clicked, the original PDF document
opens with the citation sentence highlighted (Fig. 8;
currently only possible in Acrobat Reader).
By clicking on an edge instead of a node, only the
citations between the two papers at both ends are
displayed, in the same way as described above for
all citations of a document.
</bodyText>
<sectionHeader confidence="0.99985" genericHeader="method">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999947904761905">
Our paper touches and combines results of three
disciplines, (1) bibliometrics, (2) computational lin-
guistics, and (3) information visualization. We
briefly discuss related and mostly recent literature,
being aware of the fact that this list is necessarily
incomplete.
(Garfield, 1965) is probably the first to discuss
an automatic computation of citation types. He is
also the founder of citation indexing and the Insti-
tute of Scientific Information (ISI). His first publica-
tion on science citation indexing appeared in 1955
(Garfield, 1955) and he remained the probably most
influential scientist in this field for decades. (Born-
mann and Daniel, 2008) is a comprehensive recent
metastudy on citing behavior.
Investigating citation classification has a long tra-
dition in bibliometrics and information science and
in the last 20 years also attracted computational
linguistics researchers trying to automate the task
based on rhetorics of science, statistical methods and
sentence parsing.
There is much more work than we can cite here
on citation function computation worth combination
with our approach (Bornmann and Daniel, 2008;
Garzone, 1996; Teufel et al., 2006) – using our tool
one can easily browse to further publications!
There is little work on innovative layout tech-
niques for displaying and navigating citation graphs.
We found three independent approaches to citation
graph visualization: CiteViz (Elmqvist and Tsigas,
2004), CircleView (Bergstr¨om and Jr., 2006), and
(Nguyen et al., 2007). They share a disadvantageous
property in that they try to visualize too much infor-
mation at the same time. In our opinion, this con-
tradicts the need to navigate and keep control over
displayable parts of large paper collections.
Moreover, these approaches do not provide infor-
mation on citation types derived from text as our
system does. Further ideas on visualizing science-
related information such as author co-citation net-
works are also discussed and summarized in (Chen,
2006).
</bodyText>
<sectionHeader confidence="0.951477" genericHeader="conclusions">
6 Summary and Outlook
</sectionHeader>
<bodyText confidence="0.999967814814815">
We have presented an innovative tool to support sci-
entific authors in browsing graphically through large
collections of publications by means of typed cita-
tion graphs. To quickly generate a realistic data set,
we devised a classification approach avoiding man-
ual annotation and intervention.
Our classification results cannot compete with ap-
proaches such as (Teufel et al., 2006) based on con-
siderable manual annotation for machine learning.
However, we think that our application could be
combined with this or other approaches described
for classifying citations between scientific papers.
We envisage to integrate the navigation tool in
a larger framework supporting scientific authoring
(Sch¨afer et al., 2008). When publishing a service of
this kind on the Web, one would be faced with ethi-
cal issues such as the problem that authors could feel
offended by wrongly classified citations.
The reason is that citation type classification is
potentially even more subjective than a bare citation
index—which itself is already highly controversal,
as discussed in the introduction. Moreover, there is
not always a single, unique citation type, but often
vagueness and room for interpretation.
Therefore, we suggest to augment such a service
by a Web 2.0 application that would allow regis-
tered users to confirm, alter and annotate precom-
</bodyText>
<page confidence="0.995752">
12
</page>
<figureCaption confidence="0.999371">
Figure 8: Citation sentence viewer; citation sentence in context on the left, highlighted in PDF on the right when
selected on the left
</figureCaption>
<bodyText confidence="0.998955727272727">
puted citation classifications. In this community ap-
plication, all citation links in the automatically gen-
erated graph could be represented by dashed arrows
initially, and users could turn them solid by confirm-
ing or correcting the citation type and also adding a
comment text.
Line thickness could be increased (up to an appro-
priate maximum) each time another user confirms a
classified citation type. The results could then also
be employed for active learning and help to improve
the automatic classification procedure.
</bodyText>
<sectionHeader confidence="0.997488" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999332692307692">
First of all, we are indebted to the anonymous re-
viewers for their useful, encouraging and detailed
comments. Many thanks also to Donia Scott for her
feedback on an earlier version of the tool and helpful
comments on terminology. We would like to thank
Madeline Maher and Boris Fersing for generating
and evaluating the citation type data on a subcorpus
of the ACL Anthology.
The work described in this paper has been carried
out in the context of the project TAKE (Technolo-
gies for Advanced Knowledge Extraction), funded
under contract 01IW08003 by the German Federal
Ministry of Education and Research.
</bodyText>
<sectionHeader confidence="0.998423" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996018631578947">
Satanjeev Banerjee and Ted Pedersen. 2003. The de-
sign, implementation, and use of the ngram statistics
package. In Proceedings of the Fourth International
Conference on Intelligent Text Processing and Com-
putational Linguistics, pages 370–381, Mexico City.
Peter Bergstr¨om and E. James Whitehead Jr. 2006. Cir-
cleView: Scalable visualization and navigation of cita-
tion networks. In Proceedings of the 2006 Symposium
on Interactive Visual Information Collections and Ac-
tivity IVICA, College Station, Texas.
Steven Bird, Robert Dale, Bonnie Dorr, Bryan Gibson,
Mark Joseph, Min-Yen Kan, Dongwon Lee, Brett
Powley, Dragomir Radev, and Yee Fan Tan. 2008. The
ACL anthology reference corpus: A reference dataset
for bibliographic research. In Proceedings of the Lan-
guage Resources and Evaluation Conference (LREC-
2008), Marrakesh, Morocco.
Lutz Bornmann and Hans-Dieter Daniel. 2008. What
do citation counts measure? A review of studies on
</reference>
<page confidence="0.995336">
13
</page>
<reference confidence="0.998787477611941">
citing behavior. Journal of Documentation, 64(1):45–
80. DOI 10.1108/00220410810844150.
Chaomei Chen. 2006. Information Visualization: Be-
yond the Horizon. Springer. 2nd Edition, Chapter 5.
Isaac G. Councill, C. Lee Giles, and Min-Yen Kan. 2008.
ParsCit: An open-source CRF reference string parsing
package. In Proceedings of the Language Resources
and Evaluation Conference (LREC-2008), Marrakesh,
Morocco.
Niklas Elmqvist and Philippas Tsigas. 2004. CiteWiz:
A tool for the visualization of scientific citation net-
works. Technical Report CS:2004-05, Department of
Computing Science, Chalmers University of Technol-
ogy and G¨oteborg University, G¨oteborg, Sweden.
Eugene Garfield. 1955. Citation indexes for science: A
new dimension in documentation through association
of ideas. Science, 123:108–111.
Eugene Garfield. 1965. Can citation indexing be auto-
mated? In Mary Elizabeth Stevens, Vincent E. Giu-
liano, and Laurence B. Heilprin, editors, Statistical
Association Methods for Mechanical Documentation.
National Bureau of Standards, Washington, DC. NBS
Misc. Pub. 269.
Mark Garzone. 1996. Automated classification of ci-
tations using linguistic semantic grammars. Master’s
thesis, Dept. of Computer Science, The University of
Western Ontario, Canada.
Vladimir I. Levenshtein. 1966. Binary codes capable of
correcting deletions, insertions, and reversals. Soviet
Physics Doklady, 10(8):707–710.
Robert. E Mercer and Chrysanne Di Marco. 2004. A
design methodology for a biomedical literature index-
ing tool using the rhetoric of science. In Lynette
Hirschman and James Pustejovsky, editors, HLT-
NAACL 2004 Workshop: BioLINK 2004, Linking Bi-
ological Literature, Ontologies and Databases, pages
77–84, Boston, Massachusetts, USA.
George A. Miller, Richard Beckwith, Christiane Fell-
baum, Derek Gross, and Katherine J. Miller. 1993.
Five papers on WordNet. Technical report, Cognitive
Science Laboratory, Princeton University.
Quang Vinh Nguyen, Mao Lin Huang, and Simeon
Simoff. 2007. Visualization of relational structure
among scientific articles. Advances in Visual Informa-
tion Systems, pages 415–425. Springer LNCS 4781,
DOI 10.1007/978-3-540-76414-4 40.
David A. Pendlebury. 2009. The use and misuse of jour-
nal metrics and other citation indicators. Archivum Im-
munologiae et Therapiae Experimentalis, 57(1):1–11.
DOI 10.1007/s00005-009-0008-y.
Dragomir R. Radev, Pradeep Muthukrishnan, and Vahed
Qazvinian. 2009. The ACL anthology network cor-
pus. In Proceedings of the ACL Workshop on Nat-
ural Language Processing and Information Retrieval
for Digital Libraries, Singapore.
Ulrich Sch¨afer, Hans Uszkoreit, Christian Federmann,
Torsten Marek, and Yajing Zhang. 2008. Extract-
ing and querying relations in scientific papers. In
Proceedings of the 31st Annual German Conference
on Artificial Intelligence, KI 2008, pages 127–134,
Kaiserslautern, Germany. Springer LNAI 5243. DOI
10.1007/978-3-540-85845-4 16.
Simone Teufel, Advaith Siddharthan, and Dan Tidhar.
2006. Automatic classification of citation function.
In Proceedings of the 2006 Conference on Empirical
Methods in Natural Language Processing, pages 103–
110, Sydney, Australia.
</reference>
<page confidence="0.999271">
14
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.352925">
<title confidence="0.99703">Scientific Authoring Support: A Tool to Navigate in Typed Citation Graphs</title>
<author confidence="0.944388">Ulrich</author>
<affiliation confidence="0.997689">Language Technology German Research Center Artificial Intelligence</affiliation>
<address confidence="0.926273">D-66123 Saarbr¨ucken,</address>
<email confidence="0.995077">ulrich.schaefer@dfki.de</email>
<affiliation confidence="0.781474666666667">Uwe Computer Science Saarland</affiliation>
<address confidence="0.907935">D-66123 Saarbr¨ucken,</address>
<email confidence="0.996855">uwe.kasterka@dfki.de</email>
<abstract confidence="0.99935996">Scientific authors urgently need help in managing the fast increasing number of publications. We describe and demonstrate a tool that supports authors in browsing graphically through electronically available publications, thus allowing them to quickly adapt to new domains and publish faster. Navigation is assisted by means of typed citation graphs, i.e. we use methods and resources from computational linguistics to compute the kind of citation that is made from one paper to another (refutation, use, confirmation etc.). To verify the computed citation type, the user can inspect the highlighted citation sentence in the original PDF document. While our classification methods used to generate a realistic test data set are relatively simple and could be combined with other proposed approaches, we put a strong focus on usability and quick navigation in the potentially huge graphs. In the outlook, we argue that our tool could be made part of a community approach to overcome the sparseness and correctness dilemma in citation classification.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Satanjeev Banerjee</author>
<author>Ted Pedersen</author>
</authors>
<title>The design, implementation, and use of the ngram statistics package.</title>
<date>2003</date>
<booktitle>In Proceedings of the Fourth International Conference on Intelligent Text Processing and Computational Linguistics,</booktitle>
<pages>370--381</pages>
<location>Mexico City.</location>
<contexts>
<context position="9702" citStr="Banerjee and Pedersen, 2003" startWordPosition="1521" endWordPosition="1524">l patterns (cue words) and associated each with a class from the aforementioned schema. • A list from (Garzone, 1996) devised for biomedical texts; it is largely applicable to the computational linguistics domain as well. • Simple negation of positive cue words to obtain negative patterns. • A list of automatically extracted synonyms and antonyms (the latter for increasing number of patterns for negative citations) from WordNet (Miller et al., 1993). • Automatically computed most frequent cooccurrences from all extracted citation sentences of the corpus using an open source cooccurrence tool (Banerjee and Pedersen, 2003). • Inspection: browse and filter cue words manually, remove redundancies. The numbers reflect a careful classification approach where uncertain citations are classified as Undef. In case of multiple matches, the first (leftmost) was taken to achieve a unique result. The results also confirm obervations made in other works: (1) citation classification is a hard task, (2) there are only a few strongly negative citations which coincides with observations made by (Teufel et al., 2006), (Pendlebury, 2009) and others, (3) the majority of citations is neutral or of unknown type. An evaluation on a t</context>
</contexts>
<marker>Banerjee, Pedersen, 2003</marker>
<rawString>Satanjeev Banerjee and Ted Pedersen. 2003. The design, implementation, and use of the ngram statistics package. In Proceedings of the Fourth International Conference on Intelligent Text Processing and Computational Linguistics, pages 370–381, Mexico City.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Bergstr¨om</author>
<author>E James Whitehead Jr</author>
</authors>
<title>CircleView: Scalable visualization and navigation of citation networks.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Symposium on Interactive Visual Information Collections and Activity IVICA,</booktitle>
<location>College Station, Texas.</location>
<marker>Bergstr¨om, Jr, 2006</marker>
<rawString>Peter Bergstr¨om and E. James Whitehead Jr. 2006. CircleView: Scalable visualization and navigation of citation networks. In Proceedings of the 2006 Symposium on Interactive Visual Information Collections and Activity IVICA, College Station, Texas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bird</author>
<author>Robert Dale</author>
<author>Bonnie Dorr</author>
<author>Bryan Gibson</author>
<author>Mark Joseph</author>
<author>Min-Yen Kan</author>
<author>Dongwon Lee</author>
<author>Brett Powley</author>
<author>Dragomir Radev</author>
<author>Yee Fan Tan</author>
</authors>
<title>The ACL anthology reference corpus: A reference dataset for bibliographic research.</title>
<date>2008</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC2008),</booktitle>
<location>Marrakesh, Morocco.</location>
<contexts>
<context position="5260" citStr="Bird et al., 2008" startWordPosition="808" endWordPosition="811">ng the visualization and navigation tool. Section 3 contains an evaluation of the quality of the extracted unlabeled graphs and of the citation classification step. We then describe in Section 4 the ideas of efficient and at the same time well-arranged visualization and navigation in the typed citation graph. We compare with related work in Section 5. Finally, we conclude and give an outlook to future work in Section 6. 2 Data Preparation and Automatic Citation Type Classification Our corpus is based on 6300 electronically-available papers, a subset (published 2002-2008) of the ACL Anthology (Bird et al., 2008), a comprehensive collection of scientific conference and workshop papers in the area of computational linguistics and language technology. The overall workflow of the employed tools and data is shown in Fig. 1. We ran the open source tool ParsCit (Councill et al., 2008) to extract references lists and corresponding citation sentences from raw paper texts. To build the citation graph, we used the Levenshtein distance (Levenshtein, 1966) to find and match titles and authors of identical papers yet tolerating spelling and PDF extraction errors. To increase robustness, publication years were not </context>
</contexts>
<marker>Bird, Dale, Dorr, Gibson, Joseph, Kan, Lee, Powley, Radev, Tan, 2008</marker>
<rawString>Steven Bird, Robert Dale, Bonnie Dorr, Bryan Gibson, Mark Joseph, Min-Yen Kan, Dongwon Lee, Brett Powley, Dragomir Radev, and Yee Fan Tan. 2008. The ACL anthology reference corpus: A reference dataset for bibliographic research. In Proceedings of the Language Resources and Evaluation Conference (LREC2008), Marrakesh, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lutz Bornmann</author>
<author>Hans-Dieter Daniel</author>
</authors>
<title>What do citation counts measure? A review of studies on citing behavior.</title>
<date>2008</date>
<journal>Journal of Documentation,</journal>
<volume>64</volume>
<issue>1</issue>
<pages>80--10</pages>
<contexts>
<context position="3137" citStr="Bornmann and Daniel, 2008" startWordPosition="475" endWordPosition="478">oach and does not tell much about the reasons for citing one’s work in a specific situation. Moreover, once such measure is formalized and standardized e.g. for science evaluation, it can be exploited to tune up statistics. Since the first proposal of the Science Citation Index (Garfield, 1955), it has also provoked criticism. In the bibliometrics and computational linguistics literature, many proposals are available on how citations could be further classified by careful analysis of citation sentences and context (Garfield, 1965; Garzone, 1996; Mercer and Di Marco, 2004; Teufel et al., 2006; Bornmann and Daniel, 2008). The number of different classes proposed varies from 3 to 35. Different authors try to identify dimensions and mutually exclusive classes, but the more classes a schema contains, the more difficult becomes the automatic classification. The focus of our paper is to combine automatic classification approaches with a tool that supports scientists in graphically navigating through typed citation graphs (TCG). Such TCGs can be generated Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics and Writing, pages 7–14, Los Angeles, California, June 2010. c�2010 Association for Comput</context>
<context position="7909" citStr="Bornmann and Daniel, 2008" startWordPosition="1239" endWordPosition="1242"> a paper) may be associated with several citation sentences mentioning the paper referenced at the end. 1We only consider intra-network links here, not those pointing to books or other publications outside the corpus. 8 In only considering the citation sentence itself, we may lose some citation type information, as it may be (also) contained in follow-up sentences referring to the citation using a pronoun (“they”, “their approach” etc.). Considering follow-up or even preceding sentences is planned to be addressed in future work. After consulting the rich literature on citation classification (Bornmann and Daniel, 2008; Garzone, 1996; Teufel et al., 2006), we derived a simplified classification schema consisting of the following five classes. • Agree: The citing paper agrees with the cited paper • PRecycle: The citing paper uses an algorithm, data, method or tool from the cited paper • Negative: The paper is cited negatively/contrastively 3 Results: Distribution and Evaluation These pattern where then used for the classification algorithm and applied to the extracted citation sentences. In case of multiple citations with different classes, a voting mechanism was applied were the ‘stronger’ classes (Agree, N</context>
<context position="15949" citStr="Bornmann and Daniel, 2008" startWordPosition="2549" endWordPosition="2553">nes results of three disciplines, (1) bibliometrics, (2) computational linguistics, and (3) information visualization. We briefly discuss related and mostly recent literature, being aware of the fact that this list is necessarily incomplete. (Garfield, 1965) is probably the first to discuss an automatic computation of citation types. He is also the founder of citation indexing and the Institute of Scientific Information (ISI). His first publication on science citation indexing appeared in 1955 (Garfield, 1955) and he remained the probably most influential scientist in this field for decades. (Bornmann and Daniel, 2008) is a comprehensive recent metastudy on citing behavior. Investigating citation classification has a long tradition in bibliometrics and information science and in the last 20 years also attracted computational linguistics researchers trying to automate the task based on rhetorics of science, statistical methods and sentence parsing. There is much more work than we can cite here on citation function computation worth combination with our approach (Bornmann and Daniel, 2008; Garzone, 1996; Teufel et al., 2006) – using our tool one can easily browse to further publications! There is little work </context>
</contexts>
<marker>Bornmann, Daniel, 2008</marker>
<rawString>Lutz Bornmann and Hans-Dieter Daniel. 2008. What do citation counts measure? A review of studies on citing behavior. Journal of Documentation, 64(1):45– 80. DOI 10.1108/00220410810844150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chaomei Chen</author>
</authors>
<title>Information Visualization: Beyond the Horizon.</title>
<date>2006</date>
<publisher>Springer.</publisher>
<note>2nd Edition, Chapter 5.</note>
<contexts>
<context position="17282" citStr="Chen, 2006" startWordPosition="2756" endWordPosition="2757">tation graph visualization: CiteViz (Elmqvist and Tsigas, 2004), CircleView (Bergstr¨om and Jr., 2006), and (Nguyen et al., 2007). They share a disadvantageous property in that they try to visualize too much information at the same time. In our opinion, this contradicts the need to navigate and keep control over displayable parts of large paper collections. Moreover, these approaches do not provide information on citation types derived from text as our system does. Further ideas on visualizing sciencerelated information such as author co-citation networks are also discussed and summarized in (Chen, 2006). 6 Summary and Outlook We have presented an innovative tool to support scientific authors in browsing graphically through large collections of publications by means of typed citation graphs. To quickly generate a realistic data set, we devised a classification approach avoiding manual annotation and intervention. Our classification results cannot compete with approaches such as (Teufel et al., 2006) based on considerable manual annotation for machine learning. However, we think that our application could be combined with this or other approaches described for classifying citations between sci</context>
</contexts>
<marker>Chen, 2006</marker>
<rawString>Chaomei Chen. 2006. Information Visualization: Beyond the Horizon. Springer. 2nd Edition, Chapter 5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isaac G Councill</author>
<author>C Lee Giles</author>
<author>Min-Yen Kan</author>
</authors>
<title>ParsCit: An open-source CRF reference string parsing package.</title>
<date>2008</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC-2008),</booktitle>
<location>Marrakesh, Morocco.</location>
<contexts>
<context position="5531" citStr="Councill et al., 2008" startWordPosition="852" endWordPosition="855">and navigation in the typed citation graph. We compare with related work in Section 5. Finally, we conclude and give an outlook to future work in Section 6. 2 Data Preparation and Automatic Citation Type Classification Our corpus is based on 6300 electronically-available papers, a subset (published 2002-2008) of the ACL Anthology (Bird et al., 2008), a comprehensive collection of scientific conference and workshop papers in the area of computational linguistics and language technology. The overall workflow of the employed tools and data is shown in Fig. 1. We ran the open source tool ParsCit (Councill et al., 2008) to extract references lists and corresponding citation sentences from raw paper texts. To build the citation graph, we used the Levenshtein distance (Levenshtein, 1966) to find and match titles and authors of identical papers yet tolerating spelling and PDF extraction errors. To increase robustness, publication years were not considered as they would hinder matches for Figure 1: Workflow from ACL Anthology data (top) to citation graph navigation applet and citation sentence viewer (bottom) delayed journal publications. Generation of the graph edges, i.e. matching of papers and reference strin</context>
</contexts>
<marker>Councill, Giles, Kan, 2008</marker>
<rawString>Isaac G. Councill, C. Lee Giles, and Min-Yen Kan. 2008. ParsCit: An open-source CRF reference string parsing package. In Proceedings of the Language Resources and Evaluation Conference (LREC-2008), Marrakesh, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Niklas Elmqvist</author>
<author>Philippas Tsigas</author>
</authors>
<title>CiteWiz: A tool for the visualization of scientific citation networks.</title>
<date>2004</date>
<tech>Technical Report CS:2004-05,</tech>
<institution>Department of Computing Science, Chalmers University of Technology and G¨oteborg University, G¨oteborg, Sweden.</institution>
<contexts>
<context position="16734" citStr="Elmqvist and Tsigas, 2004" startWordPosition="2666" endWordPosition="2669">d in the last 20 years also attracted computational linguistics researchers trying to automate the task based on rhetorics of science, statistical methods and sentence parsing. There is much more work than we can cite here on citation function computation worth combination with our approach (Bornmann and Daniel, 2008; Garzone, 1996; Teufel et al., 2006) – using our tool one can easily browse to further publications! There is little work on innovative layout techniques for displaying and navigating citation graphs. We found three independent approaches to citation graph visualization: CiteViz (Elmqvist and Tsigas, 2004), CircleView (Bergstr¨om and Jr., 2006), and (Nguyen et al., 2007). They share a disadvantageous property in that they try to visualize too much information at the same time. In our opinion, this contradicts the need to navigate and keep control over displayable parts of large paper collections. Moreover, these approaches do not provide information on citation types derived from text as our system does. Further ideas on visualizing sciencerelated information such as author co-citation networks are also discussed and summarized in (Chen, 2006). 6 Summary and Outlook We have presented an innovat</context>
</contexts>
<marker>Elmqvist, Tsigas, 2004</marker>
<rawString>Niklas Elmqvist and Philippas Tsigas. 2004. CiteWiz: A tool for the visualization of scientific citation networks. Technical Report CS:2004-05, Department of Computing Science, Chalmers University of Technology and G¨oteborg University, G¨oteborg, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Garfield</author>
</authors>
<title>Citation indexes for science: A new dimension in documentation through association of ideas.</title>
<date>1955</date>
<journal>Science,</journal>
<pages>123--108</pages>
<contexts>
<context position="2806" citStr="Garfield, 1955" startWordPosition="427" endWordPosition="428">n automatically, at least citation properties and derived scientific impact can be and usually are measured automatically on the basis of simple citation graphs. In other words, these graphs can be used to describe I/O behavior of publications in a very simple way. However, just counting citations is a very coarse approach and does not tell much about the reasons for citing one’s work in a specific situation. Moreover, once such measure is formalized and standardized e.g. for science evaluation, it can be exploited to tune up statistics. Since the first proposal of the Science Citation Index (Garfield, 1955), it has also provoked criticism. In the bibliometrics and computational linguistics literature, many proposals are available on how citations could be further classified by careful analysis of citation sentences and context (Garfield, 1965; Garzone, 1996; Mercer and Di Marco, 2004; Teufel et al., 2006; Bornmann and Daniel, 2008). The number of different classes proposed varies from 3 to 35. Different authors try to identify dimensions and mutually exclusive classes, but the more classes a schema contains, the more difficult becomes the automatic classification. The focus of our paper is to co</context>
<context position="15838" citStr="Garfield, 1955" startWordPosition="2534" endWordPosition="2535">e way as described above for all citations of a document. 5 Related Work Our paper touches and combines results of three disciplines, (1) bibliometrics, (2) computational linguistics, and (3) information visualization. We briefly discuss related and mostly recent literature, being aware of the fact that this list is necessarily incomplete. (Garfield, 1965) is probably the first to discuss an automatic computation of citation types. He is also the founder of citation indexing and the Institute of Scientific Information (ISI). His first publication on science citation indexing appeared in 1955 (Garfield, 1955) and he remained the probably most influential scientist in this field for decades. (Bornmann and Daniel, 2008) is a comprehensive recent metastudy on citing behavior. Investigating citation classification has a long tradition in bibliometrics and information science and in the last 20 years also attracted computational linguistics researchers trying to automate the task based on rhetorics of science, statistical methods and sentence parsing. There is much more work than we can cite here on citation function computation worth combination with our approach (Bornmann and Daniel, 2008; Garzone, 1</context>
</contexts>
<marker>Garfield, 1955</marker>
<rawString>Eugene Garfield. 1955. Citation indexes for science: A new dimension in documentation through association of ideas. Science, 123:108–111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Garfield</author>
</authors>
<title>Can citation indexing be automated?</title>
<date>1965</date>
<journal>NBS Misc. Pub.</journal>
<booktitle>Statistical Association Methods for Mechanical Documentation. National Bureau of Standards,</booktitle>
<volume>269</volume>
<editor>In Mary Elizabeth Stevens, Vincent E. Giuliano, and Laurence B. Heilprin, editors,</editor>
<location>Washington, DC.</location>
<contexts>
<context position="3046" citStr="Garfield, 1965" startWordPosition="462" endWordPosition="463">ns in a very simple way. However, just counting citations is a very coarse approach and does not tell much about the reasons for citing one’s work in a specific situation. Moreover, once such measure is formalized and standardized e.g. for science evaluation, it can be exploited to tune up statistics. Since the first proposal of the Science Citation Index (Garfield, 1955), it has also provoked criticism. In the bibliometrics and computational linguistics literature, many proposals are available on how citations could be further classified by careful analysis of citation sentences and context (Garfield, 1965; Garzone, 1996; Mercer and Di Marco, 2004; Teufel et al., 2006; Bornmann and Daniel, 2008). The number of different classes proposed varies from 3 to 35. Different authors try to identify dimensions and mutually exclusive classes, but the more classes a schema contains, the more difficult becomes the automatic classification. The focus of our paper is to combine automatic classification approaches with a tool that supports scientists in graphically navigating through typed citation graphs (TCG). Such TCGs can be generated Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics</context>
<context position="15581" citStr="Garfield, 1965" startWordPosition="2493" endWordPosition="2494">f clicked, the original PDF document opens with the citation sentence highlighted (Fig. 8; currently only possible in Acrobat Reader). By clicking on an edge instead of a node, only the citations between the two papers at both ends are displayed, in the same way as described above for all citations of a document. 5 Related Work Our paper touches and combines results of three disciplines, (1) bibliometrics, (2) computational linguistics, and (3) information visualization. We briefly discuss related and mostly recent literature, being aware of the fact that this list is necessarily incomplete. (Garfield, 1965) is probably the first to discuss an automatic computation of citation types. He is also the founder of citation indexing and the Institute of Scientific Information (ISI). His first publication on science citation indexing appeared in 1955 (Garfield, 1955) and he remained the probably most influential scientist in this field for decades. (Bornmann and Daniel, 2008) is a comprehensive recent metastudy on citing behavior. Investigating citation classification has a long tradition in bibliometrics and information science and in the last 20 years also attracted computational linguistics researche</context>
</contexts>
<marker>Garfield, 1965</marker>
<rawString>Eugene Garfield. 1965. Can citation indexing be automated? In Mary Elizabeth Stevens, Vincent E. Giuliano, and Laurence B. Heilprin, editors, Statistical Association Methods for Mechanical Documentation. National Bureau of Standards, Washington, DC. NBS Misc. Pub. 269.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Garzone</author>
</authors>
<title>Automated classification of citations using linguistic semantic grammars.</title>
<date>1996</date>
<tech>Master’s thesis,</tech>
<institution>Dept. of Computer Science, The University of Western Ontario, Canada.</institution>
<contexts>
<context position="3061" citStr="Garzone, 1996" startWordPosition="464" endWordPosition="465">ple way. However, just counting citations is a very coarse approach and does not tell much about the reasons for citing one’s work in a specific situation. Moreover, once such measure is formalized and standardized e.g. for science evaluation, it can be exploited to tune up statistics. Since the first proposal of the Science Citation Index (Garfield, 1955), it has also provoked criticism. In the bibliometrics and computational linguistics literature, many proposals are available on how citations could be further classified by careful analysis of citation sentences and context (Garfield, 1965; Garzone, 1996; Mercer and Di Marco, 2004; Teufel et al., 2006; Bornmann and Daniel, 2008). The number of different classes proposed varies from 3 to 35. Different authors try to identify dimensions and mutually exclusive classes, but the more classes a schema contains, the more difficult becomes the automatic classification. The focus of our paper is to combine automatic classification approaches with a tool that supports scientists in graphically navigating through typed citation graphs (TCG). Such TCGs can be generated Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics and Writing, p</context>
<context position="7924" citStr="Garzone, 1996" startWordPosition="1243" endWordPosition="1245"> with several citation sentences mentioning the paper referenced at the end. 1We only consider intra-network links here, not those pointing to books or other publications outside the corpus. 8 In only considering the citation sentence itself, we may lose some citation type information, as it may be (also) contained in follow-up sentences referring to the citation using a pronoun (“they”, “their approach” etc.). Considering follow-up or even preceding sentences is planned to be addressed in future work. After consulting the rich literature on citation classification (Bornmann and Daniel, 2008; Garzone, 1996; Teufel et al., 2006), we derived a simplified classification schema consisting of the following five classes. • Agree: The citing paper agrees with the cited paper • PRecycle: The citing paper uses an algorithm, data, method or tool from the cited paper • Negative: The paper is cited negatively/contrastively 3 Results: Distribution and Evaluation These pattern where then used for the classification algorithm and applied to the extracted citation sentences. In case of multiple citations with different classes, a voting mechanism was applied were the ‘stronger’ classes (Agree, Negative, PRecyc</context>
<context position="9191" citStr="Garzone, 1996" startWordPosition="1446" endWordPosition="1447">ations we obtained the results shown in Table 1. Classes Citations Percent Agree 3513 3.8% Agree, Neutral 2020 2.2% Negative 1147 1.2% PRecycle 10609 11.6% PRecycle, Agree 1419 1.6% PRecycle, Agree, Neutral 922 1.0% PRecycle, Neutral 3882 4.2% Neutral 13430 14.7% Undef 54837 60.0% Table 1: Citation classification result • Neutral: The paper is cited neutrally • Undef: impossible determine the sentiment of the citation (fallback) Then, we used a blend of methods to collect verbal and non-verbal patterns (cue words) and associated each with a class from the aforementioned schema. • A list from (Garzone, 1996) devised for biomedical texts; it is largely applicable to the computational linguistics domain as well. • Simple negation of positive cue words to obtain negative patterns. • A list of automatically extracted synonyms and antonyms (the latter for increasing number of patterns for negative citations) from WordNet (Miller et al., 1993). • Automatically computed most frequent cooccurrences from all extracted citation sentences of the corpus using an open source cooccurrence tool (Banerjee and Pedersen, 2003). • Inspection: browse and filter cue words manually, remove redundancies. The numbers re</context>
<context position="16441" citStr="Garzone, 1996" startWordPosition="2624" endWordPosition="2625">eld, 1955) and he remained the probably most influential scientist in this field for decades. (Bornmann and Daniel, 2008) is a comprehensive recent metastudy on citing behavior. Investigating citation classification has a long tradition in bibliometrics and information science and in the last 20 years also attracted computational linguistics researchers trying to automate the task based on rhetorics of science, statistical methods and sentence parsing. There is much more work than we can cite here on citation function computation worth combination with our approach (Bornmann and Daniel, 2008; Garzone, 1996; Teufel et al., 2006) – using our tool one can easily browse to further publications! There is little work on innovative layout techniques for displaying and navigating citation graphs. We found three independent approaches to citation graph visualization: CiteViz (Elmqvist and Tsigas, 2004), CircleView (Bergstr¨om and Jr., 2006), and (Nguyen et al., 2007). They share a disadvantageous property in that they try to visualize too much information at the same time. In our opinion, this contradicts the need to navigate and keep control over displayable parts of large paper collections. Moreover, </context>
</contexts>
<marker>Garzone, 1996</marker>
<rawString>Mark Garzone. 1996. Automated classification of citations using linguistic semantic grammars. Master’s thesis, Dept. of Computer Science, The University of Western Ontario, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir I Levenshtein</author>
</authors>
<title>Binary codes capable of correcting deletions, insertions, and reversals.</title>
<date>1966</date>
<journal>Soviet Physics Doklady,</journal>
<volume>10</volume>
<issue>8</issue>
<contexts>
<context position="5700" citStr="Levenshtein, 1966" startWordPosition="879" endWordPosition="880">on and Automatic Citation Type Classification Our corpus is based on 6300 electronically-available papers, a subset (published 2002-2008) of the ACL Anthology (Bird et al., 2008), a comprehensive collection of scientific conference and workshop papers in the area of computational linguistics and language technology. The overall workflow of the employed tools and data is shown in Fig. 1. We ran the open source tool ParsCit (Councill et al., 2008) to extract references lists and corresponding citation sentences from raw paper texts. To build the citation graph, we used the Levenshtein distance (Levenshtein, 1966) to find and match titles and authors of identical papers yet tolerating spelling and PDF extraction errors. To increase robustness, publication years were not considered as they would hinder matches for Figure 1: Workflow from ACL Anthology data (top) to citation graph navigation applet and citation sentence viewer (bottom) delayed journal publications. Generation of the graph edges, i.e. matching of papers and reference strings, is performed by means of the ACL ID, a unique identifier for each paper, available for the PDF (source nodes of references) and BibTeX files (targets of references).</context>
</contexts>
<marker>Levenshtein, 1966</marker>
<rawString>Vladimir I. Levenshtein. 1966. Binary codes capable of correcting deletions, insertions, and reversals. Soviet Physics Doklady, 10(8):707–710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Mercer</author>
<author>Chrysanne Di Marco</author>
</authors>
<title>A design methodology for a biomedical literature indexing tool using the rhetoric of science.</title>
<date>2004</date>
<booktitle>In Lynette Hirschman and James Pustejovsky, editors, HLTNAACL 2004 Workshop: BioLINK 2004, Linking Biological Literature, Ontologies and Databases,</booktitle>
<pages>77--84</pages>
<location>Boston, Massachusetts, USA.</location>
<marker>Mercer, Di Marco, 2004</marker>
<rawString>Robert. E Mercer and Chrysanne Di Marco. 2004. A design methodology for a biomedical literature indexing tool using the rhetoric of science. In Lynette Hirschman and James Pustejovsky, editors, HLTNAACL 2004 Workshop: BioLINK 2004, Linking Biological Literature, Ontologies and Databases, pages 77–84, Boston, Massachusetts, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Richard Beckwith</author>
<author>Christiane Fellbaum</author>
<author>Derek Gross</author>
<author>Katherine J Miller</author>
</authors>
<title>Five papers on WordNet.</title>
<date>1993</date>
<tech>Technical report,</tech>
<institution>Cognitive Science Laboratory, Princeton University.</institution>
<contexts>
<context position="9527" citStr="Miller et al., 1993" startWordPosition="1495" endWordPosition="1498">l: The paper is cited neutrally • Undef: impossible determine the sentiment of the citation (fallback) Then, we used a blend of methods to collect verbal and non-verbal patterns (cue words) and associated each with a class from the aforementioned schema. • A list from (Garzone, 1996) devised for biomedical texts; it is largely applicable to the computational linguistics domain as well. • Simple negation of positive cue words to obtain negative patterns. • A list of automatically extracted synonyms and antonyms (the latter for increasing number of patterns for negative citations) from WordNet (Miller et al., 1993). • Automatically computed most frequent cooccurrences from all extracted citation sentences of the corpus using an open source cooccurrence tool (Banerjee and Pedersen, 2003). • Inspection: browse and filter cue words manually, remove redundancies. The numbers reflect a careful classification approach where uncertain citations are classified as Undef. In case of multiple matches, the first (leftmost) was taken to achieve a unique result. The results also confirm obervations made in other works: (1) citation classification is a hard task, (2) there are only a few strongly negative citations wh</context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1993</marker>
<rawString>George A. Miller, Richard Beckwith, Christiane Fellbaum, Derek Gross, and Katherine J. Miller. 1993. Five papers on WordNet. Technical report, Cognitive Science Laboratory, Princeton University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Quang Vinh Nguyen</author>
<author>Mao Lin Huang</author>
<author>Simeon Simoff</author>
</authors>
<title>Visualization of relational structure among scientific articles.</title>
<date>2007</date>
<booktitle>Advances in Visual Information Systems,</booktitle>
<pages>415--425</pages>
<publisher>Springer</publisher>
<contexts>
<context position="16800" citStr="Nguyen et al., 2007" startWordPosition="2676" endWordPosition="2679">ers trying to automate the task based on rhetorics of science, statistical methods and sentence parsing. There is much more work than we can cite here on citation function computation worth combination with our approach (Bornmann and Daniel, 2008; Garzone, 1996; Teufel et al., 2006) – using our tool one can easily browse to further publications! There is little work on innovative layout techniques for displaying and navigating citation graphs. We found three independent approaches to citation graph visualization: CiteViz (Elmqvist and Tsigas, 2004), CircleView (Bergstr¨om and Jr., 2006), and (Nguyen et al., 2007). They share a disadvantageous property in that they try to visualize too much information at the same time. In our opinion, this contradicts the need to navigate and keep control over displayable parts of large paper collections. Moreover, these approaches do not provide information on citation types derived from text as our system does. Further ideas on visualizing sciencerelated information such as author co-citation networks are also discussed and summarized in (Chen, 2006). 6 Summary and Outlook We have presented an innovative tool to support scientific authors in browsing graphically thr</context>
</contexts>
<marker>Nguyen, Huang, Simoff, 2007</marker>
<rawString>Quang Vinh Nguyen, Mao Lin Huang, and Simeon Simoff. 2007. Visualization of relational structure among scientific articles. Advances in Visual Information Systems, pages 415–425. Springer LNCS 4781, DOI 10.1007/978-3-540-76414-4 40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Pendlebury</author>
</authors>
<title>The use and misuse of journal metrics and other citation indicators.</title>
<date>2009</date>
<journal>Archivum Immunologiae et Therapiae Experimentalis,</journal>
<volume>57</volume>
<issue>1</issue>
<pages>10--1007</pages>
<contexts>
<context position="10208" citStr="Pendlebury, 2009" startWordPosition="1602" endWordPosition="1603">extracted citation sentences of the corpus using an open source cooccurrence tool (Banerjee and Pedersen, 2003). • Inspection: browse and filter cue words manually, remove redundancies. The numbers reflect a careful classification approach where uncertain citations are classified as Undef. In case of multiple matches, the first (leftmost) was taken to achieve a unique result. The results also confirm obervations made in other works: (1) citation classification is a hard task, (2) there are only a few strongly negative citations which coincides with observations made by (Teufel et al., 2006), (Pendlebury, 2009) and others, (3) the majority of citations is neutral or of unknown type. An evaluation on a test set of 100 citations spread across all the types of papers with a manual check of the accuracy of the computed labels showed an overall accuracy of 30% mainly caused by the fact that 90% of undefined hits were in fact neutral (i.e., labeling all undefs neutral would increase accuracy). Negative citations are sparse and unreliable (33%), neutral ones are about 60% accurate, PRecycle: 33%, Agree: 25%. To sum up, our automatic classification approach based on only local citation information could sur</context>
</contexts>
<marker>Pendlebury, 2009</marker>
<rawString>David A. Pendlebury. 2009. The use and misuse of journal metrics and other citation indicators. Archivum Immunologiae et Therapiae Experimentalis, 57(1):1–11. DOI 10.1007/s00005-009-0008-y.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir R Radev</author>
<author>Pradeep Muthukrishnan</author>
<author>Vahed Qazvinian</author>
</authors>
<title>The ACL anthology network corpus.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL Workshop on Natural Language Processing and Information Retrieval for Digital Libraries,</booktitle>
<location>Singapore.</location>
<contexts>
<context position="6439" citStr="Radev et al., 2009" startWordPosition="994" endWordPosition="997"> robustness, publication years were not considered as they would hinder matches for Figure 1: Workflow from ACL Anthology data (top) to citation graph navigation applet and citation sentence viewer (bottom) delayed journal publications. Generation of the graph edges, i.e. matching of papers and reference strings, is performed by means of the ACL ID, a unique identifier for each paper, available for the PDF (source nodes of references) and BibTeX files (targets of references). We evaluated the generated graph against the one that was corrected manually by the ACL Anthology Network (AAN) group (Radev et al., 2009) and found that 10821 citation links were shared between both and can be considered correct1. 3883 additional ones were in the AAN but not recognized by us, the other way round, 1021 discovered by us were not in the AAN. In addition, the publication bases were not identical. The anthology network data ends in February 2007 but covers years before 2002, while our data covers 2002-2008 inclusively. Given the fact that our graph is computed fully automatically, the result can be considered very good. In the next step, we augmented the citation graph by types for each edge. In contrast to other ap</context>
</contexts>
<marker>Radev, Muthukrishnan, Qazvinian, 2009</marker>
<rawString>Dragomir R. Radev, Pradeep Muthukrishnan, and Vahed Qazvinian. 2009. The ACL anthology network corpus. In Proceedings of the ACL Workshop on Natural Language Processing and Information Retrieval for Digital Libraries, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Sch¨afer</author>
<author>Hans Uszkoreit</author>
<author>Christian Federmann</author>
<author>Torsten Marek</author>
<author>Yajing Zhang</author>
</authors>
<title>Extracting and querying relations in scientific papers.</title>
<date>2008</date>
<booktitle>In Proceedings of the 31st Annual German Conference on Artificial Intelligence, KI</booktitle>
<volume>LNAI</volume>
<pages>127--134</pages>
<publisher>Springer</publisher>
<location>Kaiserslautern, Germany.</location>
<marker>Sch¨afer, Uszkoreit, Federmann, Marek, Zhang, 2008</marker>
<rawString>Ulrich Sch¨afer, Hans Uszkoreit, Christian Federmann, Torsten Marek, and Yajing Zhang. 2008. Extracting and querying relations in scientific papers. In Proceedings of the 31st Annual German Conference on Artificial Intelligence, KI 2008, pages 127–134, Kaiserslautern, Germany. Springer LNAI 5243. DOI 10.1007/978-3-540-85845-4 16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simone Teufel</author>
<author>Advaith Siddharthan</author>
<author>Dan Tidhar</author>
</authors>
<title>Automatic classification of citation function.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>103--110</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="3109" citStr="Teufel et al., 2006" startWordPosition="471" endWordPosition="474">is a very coarse approach and does not tell much about the reasons for citing one’s work in a specific situation. Moreover, once such measure is formalized and standardized e.g. for science evaluation, it can be exploited to tune up statistics. Since the first proposal of the Science Citation Index (Garfield, 1955), it has also provoked criticism. In the bibliometrics and computational linguistics literature, many proposals are available on how citations could be further classified by careful analysis of citation sentences and context (Garfield, 1965; Garzone, 1996; Mercer and Di Marco, 2004; Teufel et al., 2006; Bornmann and Daniel, 2008). The number of different classes proposed varies from 3 to 35. Different authors try to identify dimensions and mutually exclusive classes, but the more classes a schema contains, the more difficult becomes the automatic classification. The focus of our paper is to combine automatic classification approaches with a tool that supports scientists in graphically navigating through typed citation graphs (TCG). Such TCGs can be generated Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics and Writing, pages 7–14, Los Angeles, California, June 2010. c</context>
<context position="7946" citStr="Teufel et al., 2006" startWordPosition="1246" endWordPosition="1249">itation sentences mentioning the paper referenced at the end. 1We only consider intra-network links here, not those pointing to books or other publications outside the corpus. 8 In only considering the citation sentence itself, we may lose some citation type information, as it may be (also) contained in follow-up sentences referring to the citation using a pronoun (“they”, “their approach” etc.). Considering follow-up or even preceding sentences is planned to be addressed in future work. After consulting the rich literature on citation classification (Bornmann and Daniel, 2008; Garzone, 1996; Teufel et al., 2006), we derived a simplified classification schema consisting of the following five classes. • Agree: The citing paper agrees with the cited paper • PRecycle: The citing paper uses an algorithm, data, method or tool from the cited paper • Negative: The paper is cited negatively/contrastively 3 Results: Distribution and Evaluation These pattern where then used for the classification algorithm and applied to the extracted citation sentences. In case of multiple citations with different classes, a voting mechanism was applied were the ‘stronger’ classes (Agree, Negative, PRecycle) won in standoff ca</context>
<context position="10188" citStr="Teufel et al., 2006" startWordPosition="1598" endWordPosition="1601">cooccurrences from all extracted citation sentences of the corpus using an open source cooccurrence tool (Banerjee and Pedersen, 2003). • Inspection: browse and filter cue words manually, remove redundancies. The numbers reflect a careful classification approach where uncertain citations are classified as Undef. In case of multiple matches, the first (leftmost) was taken to achieve a unique result. The results also confirm obervations made in other works: (1) citation classification is a hard task, (2) there are only a few strongly negative citations which coincides with observations made by (Teufel et al., 2006), (Pendlebury, 2009) and others, (3) the majority of citations is neutral or of unknown type. An evaluation on a test set of 100 citations spread across all the types of papers with a manual check of the accuracy of the computed labels showed an overall accuracy of 30% mainly caused by the fact that 90% of undefined hits were in fact neutral (i.e., labeling all undefs neutral would increase accuracy). Negative citations are sparse and unreliable (33%), neutral ones are about 60% accurate, PRecycle: 33%, Agree: 25%. To sum up, our automatic classification approach based on only local citation i</context>
<context position="16463" citStr="Teufel et al., 2006" startWordPosition="2626" endWordPosition="2629">he remained the probably most influential scientist in this field for decades. (Bornmann and Daniel, 2008) is a comprehensive recent metastudy on citing behavior. Investigating citation classification has a long tradition in bibliometrics and information science and in the last 20 years also attracted computational linguistics researchers trying to automate the task based on rhetorics of science, statistical methods and sentence parsing. There is much more work than we can cite here on citation function computation worth combination with our approach (Bornmann and Daniel, 2008; Garzone, 1996; Teufel et al., 2006) – using our tool one can easily browse to further publications! There is little work on innovative layout techniques for displaying and navigating citation graphs. We found three independent approaches to citation graph visualization: CiteViz (Elmqvist and Tsigas, 2004), CircleView (Bergstr¨om and Jr., 2006), and (Nguyen et al., 2007). They share a disadvantageous property in that they try to visualize too much information at the same time. In our opinion, this contradicts the need to navigate and keep control over displayable parts of large paper collections. Moreover, these approaches do no</context>
<context position="17685" citStr="Teufel et al., 2006" startWordPosition="2816" endWordPosition="2819">provide information on citation types derived from text as our system does. Further ideas on visualizing sciencerelated information such as author co-citation networks are also discussed and summarized in (Chen, 2006). 6 Summary and Outlook We have presented an innovative tool to support scientific authors in browsing graphically through large collections of publications by means of typed citation graphs. To quickly generate a realistic data set, we devised a classification approach avoiding manual annotation and intervention. Our classification results cannot compete with approaches such as (Teufel et al., 2006) based on considerable manual annotation for machine learning. However, we think that our application could be combined with this or other approaches described for classifying citations between scientific papers. We envisage to integrate the navigation tool in a larger framework supporting scientific authoring (Sch¨afer et al., 2008). When publishing a service of this kind on the Web, one would be faced with ethical issues such as the problem that authors could feel offended by wrongly classified citations. The reason is that citation type classification is potentially even more subjective tha</context>
</contexts>
<marker>Teufel, Siddharthan, Tidhar, 2006</marker>
<rawString>Simone Teufel, Advaith Siddharthan, and Dan Tidhar. 2006. Automatic classification of citation function. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 103– 110, Sydney, Australia.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>