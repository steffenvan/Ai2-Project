<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000128">
<title confidence="0.998379">
Low Resource Dependency Parsing:
Cross-lingual Parameter Sharing in a Neural Network Parser
</title>
<author confidence="0.999294">
Long Duong,12 Trevor Cohn,1 Steven Bird,1 and Paul Cook3
</author>
<affiliation confidence="0.999098333333333">
1Department of Computing and Information Systems, University of Melbourne
2National ICT Australia, Victoria Research Laboratory
3Faculty of Computer Science, University of New Brunswick
</affiliation>
<email confidence="0.995143">
lduong@student.unimelb.edu.au {t.cohn,sbird}@unimelb.edu.au paul.cook@unb.ca
</email>
<sectionHeader confidence="0.993814" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999751">
Training a high-accuracy dependency
parser requires a large treebank. How-
ever, these are costly and time-consuming
to build. We propose a learning method
that needs less data, based on the observa-
tion that there are underlying shared struc-
tures across languages. We exploit cues
from a different source language in order
to guide the learning process. Our model
saves at least half of the annotation effort
to reach the same accuracy compared with
using the purely supervised method.
</bodyText>
<sectionHeader confidence="0.998796" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99995615625">
Dependency parsing is a crucial component of
many natural language processing systems, for
tasks such as text classification (¨Ozg¨ur and
G¨ung¨or, 2010), statistical machine translation (Xu
et al., 2009), relation extraction (Bunescu and
Mooney, 2005), and question answering (Cui et
al., 2005). Supervised approaches to dependency
parsing have been successful for languages where
relatively large treebanks are available (McDonald
et al., 2005). However, for many languages, anno-
tated treebanks are not available. They are costly
to create, requiring careful design, testing and
subsequent refinement of annotation guidelines,
along with assessment and management of annota-
tor quality (B¨ohmov´a et al., 2001). The Universal
Treebank Annotation Guidelines aim at providing
unified annotation for many languages enabling
cross-lingual comparison (Nivre et al., 2015). This
project provides a starting point for developing a
treebank for resource-poor languages. However, a
mature parser requires a large treebank for train-
ing, and this is still extremely costly to create. In-
stead, we present a method that exploits shared
structure across languages to achieve a more accu-
rate parser. Structural information from the source
resource-rich language is incorporated as a prior
in the supervised training of a resource-poor tar-
get language parser using a small treebank. When
compared with a supervised model, the gain is as
high as 8.7%1 on average when trained on just
1,000 tokens. As we add more training data, the
gains persist, though they are more modest. Even
at 15,000 tokens we observe a 2.9% improvement.
There are two main approaches for building
dependency parsers for resource-poor languages:
delexicalized parsing and projection (T¨ackstr¨om et
al., 2013). The delexicalized approach was pro-
posed by Zeman et al. (2008). A parser is built
without any lexical features, and trained on a tree-
bank in a resource-rich source language. It is
then applied directly to parse sentences in the tar-
get resource-poor languages. Delexicalized pars-
ing relies on the fact that identical part-of-speech
(POS) inventories are highly informative of de-
pendency relations, enough to make up for cross-
lingual syntactic divergence.
In contrast, projection approaches use parallel
data to project source language dependency rela-
tions to the target language (Hwa et al., 2005).
McDonald et al. (2011) and Ma and Xia (2014) ex-
ploit both delexicalized parsing and parallel data.
They use parallel data to constrain the model
which is usually initialized by the English delexi-
calized parser.
In summary, existing work generally starts with
a delexicalized parser and uses parallel data to im-
prove it. In this paper, we start with a source lan-
guage parser and refine it with help from depen-
dency annotations instead of parallel data. This
choice means our method can be applied in cases
where linguists are dependency-annotating small
amounts of field data, such as in Karuk, a nearly-
extinct language of Northwest California (Garrett
et al., 2013).
</bodyText>
<footnote confidence="0.6190908">
1We use absolute values herein.
845
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 845–850,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</footnote>
<note confidence="0.380436">
SOURCE - LANGUAGE PARSER TARGET - LANGUAGE PARSER
</note>
<figureCaption confidence="0.994402">
Figure 1: Neural Network Parser Architecture from Chen and Manning (2014) (left). Our model (left
and right) with soft parameter sharing between the source and target language shown with dashed lines.
</figureCaption>
<figure confidence="0.998595454545455">
WORDS
Eword
CONFIGURATION (STACK, QUEUE, ARCS)
SOFT-MAX LAYER
MAPPING LAYER
HIDDEN LAYER
POS TAGS
W2
W1
Epos
ARC LABELS
Earc
WORDS
Eword Epos Earc
CONFIGURATION (STACK, QUEUE, ARCS)
SOFT-MAX LAYER
MAPPING LAYER
HIDDEN LAYER
W2
W1
POS TAGS
ARC LABELS
</figure>
<sectionHeader confidence="0.856385" genericHeader="method">
2 Supervised Neural Network Parser
</sectionHeader>
<bodyText confidence="0.999841346153846">
In this section we review the parsing model which
we use for both the source language and target lan-
guage parsers. It is based on the work of Chen
and Manning (2014). This parser can take advan-
tage of target language monolingual data through
word embeddings, data which is usually available
for resource-poor languages. Chen and Manning’s
parser also achieved state-of-the-art monolingual
parsing performance. They built a transition-based
dependency parser (Nivre, 2006) using a neural-
network. The neural network classifier decides
which transition is applied for each configuration.
The architecture of the parser is illustrated in
Figure 1 (left), where each layer is fully connected
to the layer above. For each configuration, the se-
lected list of words, POS tags and labels from the
Stack, Queue and Arcs are extracted. Each word,
POS or label is mapped to a low-dimension vec-
tor representation (embedding) through the Map-
ping Layer. This layer simply concatenates the
embeddings which are then fed into a two-layer
neural network classifier to predict the next pars-
ing action. The set of parameters for the model
is Eword, Epos, Elabels for the mapping layer, W1
for the cubic hidden layer and W2 for the softmax
output layer.
</bodyText>
<sectionHeader confidence="0.982143" genericHeader="method">
3 Cross-lingual parser
</sectionHeader>
<bodyText confidence="0.999676434782609">
Our model takes advantage of underlying structure
shared between languages. Given the source lan-
guage parsing structure as in Figure 1 (left), the
set of parameters Eword will be different for the
target language parser shown in Figure 1 (right)
but we hypothesize that Epos, Earc, W1 and W2
can be shared as indicated with dashed lines. In
particular we expect this to be the case when lan-
guages use the same POS tagset and arc label sets,
as we presume herein. This assumption is moti-
vated by the development of unified annotation for
many languages (Nivre et al., 2015; Petrov et al.,
2012; McDonald et al., 2013).
To allow parameter sharing between languages
we could jointly train the parser on the source
and target language simultaneously. However,
we leave this for future work. Here we take an
alternative approach, namely regularization in a
similar vein to Duong et al. (2014). First we
train a lexicalized neural network parser on the
source resource-rich language (English), as de-
scribed in Section 2. The learned parameters are
Eenword, Een
</bodyText>
<equation confidence="0.456942">
pos, Een
arc, Wen
1 , W en
</equation>
<bodyText confidence="0.9871001">
2 . Second, we incor-
porate English parameters as a prior for the tar-
get language training. This is straightforward
when we use the same architecture, such as a
neural network parser, for the target language.
All we need to do is modify the learning objec-
tive function so that it includes the regularization
part. However, we don’t want to regularize the
part related to Eenword since it will be very differ-
ent between source and target language. Letting
</bodyText>
<equation confidence="0.959131090909091">
W1 = (Wword
1 , W pos
1 , Warc
1 ), the learning objec-
tive over training data D = {x(i), y(i)}Ni=1, be-
comes:2
log P(y(i)Ix(i)) − λ1[IIWpos —Wen:posll2
2 1 1 F
+ II W1arc − Win:arc II F + II W2 − W2 en II2F]
[Io − Es II — E IIJEpenF + IlEarccF]
(1)
</equation>
<bodyText confidence="0.75495125">
This is applicable where we use the same POS
2All other parameters, i.e. Wi ord and Eword, are regu-
larized using a zero-mean Gaussian regularization term, with
weight λ = 10−8, as was done in the original paper.
</bodyText>
<equation confidence="0.9374824">
N
L =
i=1
− λ2
2
</equation>
<page confidence="0.992494">
846
</page>
<table confidence="0.999899454545455">
Train Dev Test Total
cs 1173.3 159.3 173.9 1506.5
de 269.6 12.4 16.6 298.6
en 204.6 25.1 25.1 254.8
es 382.4 41.7 8.5 432.6
fi 162.7 9.2 9.1 181.0
fr 354.7 38.9 7.1 400.7
ga 16.7 3.2 3.8 23.7
hu 20.8 3.0 2.7 26.5
it 194.1 10.5 10.2 214.8
sv 66.6 9.8 20.4 96.8
</table>
<tableCaption confidence="0.997424">
Table 1: Number of tokens (× 1,000) for each lan-
</tableCaption>
<bodyText confidence="0.995945083333333">
guage in the Universal Dependency Treebank col-
lection.
tagset and arc label annotation for the source and
target language. The same POS tagset is required
so that the source language parser has similar
structure with the target language parser. The re-
quirement of same arc label annotation is mainly
needed for evaluation using the Labelled Attach-
ment Score (LAS).3 We fit two separate regular-
ization sensitivity parameters, A1 and A2, since
they correspond to different parts of the model. A1
is used for the shared (universal) part, while A2
is used for the language specific parts. Together
A1 and A2 control the contribution of the source
language parser towards the target resource-poor
model. In the extreme case where A1 and A2 are
large, the target model parameters are tied to the
source model, except for the word embeddings
Eword. In the opposite case, where they are small,
the target language parser is similar to the purely
supervised model. We expect that the best values
fall between these extremes. We use stochastic
gradient descent to optimize this objective func-
tion with respect to W1, W2, Eword, Epos, Earc.
</bodyText>
<sectionHeader confidence="0.999743" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999814666666667">
In this part we want to see how much our cross-
lingual model helps to improve the supervised
model, for various data sizes.
</bodyText>
<subsectionHeader confidence="0.892525">
4.1 Dataset
</subsectionHeader>
<bodyText confidence="0.998458666666667">
We experimented with the Universal Depen-
dency Treebank collection V1.0 (Nivre et al.,
2015) which contains treebanks for 10 languages.4
</bodyText>
<footnote confidence="0.8314985">
3However, same arc-label set also informs some informa-
tion about the structure.
4Czech (cs), German (de), English (en), Spanish (es),
Finnish (fi), French (fr), Irish (ga), Hungarian (hu), Italian
</footnote>
<bodyText confidence="0.999851818181818">
These treebanks have many desirable properties
for our model: the dependency types and coarse
POS are the same across languages. This removes
the need for mapping the source and target lan-
guage tagsets to a common tagset. Moreover, the
dependency types are also common across lan-
guages allowing LAS evaluation. Table 1 shows
the dataset size of each language in the collection.
Some languages have over 400k tokens such as cs,
fr and es, meanwhile, hu and ga have only around
25k tokens.
</bodyText>
<subsectionHeader confidence="0.984014">
4.2 Monolingual Word Embeddings
</subsectionHeader>
<bodyText confidence="0.9993538">
We initialize the target language word embeddings
Eword of our neural network cross-lingual model
with pre-trained embeddings. This is an advantage
since we can incorporate monolingual data which
is usually available for resource-poor languages.
We collect monolingual data for each language
from the Machine Translation Workshop (WMT)
data,5 Europarl (Koehn, 2005) and EU Bookshop
Corpus (Skadin¸ˇs et al., 2014). The size of mono-
lingual data also varies significantly. There are
languages such as English and German with more
than 400 million words, whereas, Irish only has
4 million. We use the skip-gram model from
word2vec to induce 50-dimension word embed-
dings (Mikolov et al., 2013).
</bodyText>
<subsectionHeader confidence="0.997625">
4.3 Coarse vs Fine-Grain POS
</subsectionHeader>
<bodyText confidence="0.999995421052632">
Our model uses the source language parser as the
prior for the target language parser. The require-
ment is that the source and target should use the
same POS tagset. It is clear that information will
be lost when using the coarser shared-POS tagset.
Here, we simply want to quantify this loss. We
run the supervised neural network parser on the
coarse-grained Universal POS (UPOS) tagset, and
the language-specific fine-grained POS tagset for
languages where both are available in the Univer-
sal Dependency Treebank.6 Table 2 shows the
average LAS for coarse- and fine-grained POS
tagsets with various data sizes. For the smaller
dataset, using the coarse-grained POS tagset per-
formed better. Even when we used all the data,
the coarse-grained POS tagset still performed rea-
sonably well, approaching the performance ob-
tained using the fine-grained POS tagset. Thus, the
choice of the coarse-grained Universal POS tagset
</bodyText>
<footnote confidence="0.674770666666667">
(it), Swedish (sv)
5http://www.statmt.org/wmt14/
6Czech, English, Finnish, Irish, Italian, and Swedish
</footnote>
<page confidence="0.993496">
847
</page>
<table confidence="0.928186285714286">
Tokens Coarse UPOS Fine POS
1k 46.8 42.3
3k 54.3 52.4
5k 56.9 55.8
10k 59.9 59.8
15k 61.5 61.4
All 74.7 75.2
</table>
<tableCaption confidence="0.978284">
Table 2: Average LAS for supervised learning us-
</tableCaption>
<bodyText confidence="0.9214">
ing the modified version of the Universal POS
tagset and the fine-grained POS tagset across vari-
ous training data sizes.
instead of the original POS tagset is relevant, given
that we assume there will only be a small tree-
bank in the target language. Moreover, even when
we have a bigger treebank, using the UPOS tagset
does not hurt the performance much.7
</bodyText>
<subsectionHeader confidence="0.996738">
4.4 Tuning regularization sensitivity
</subsectionHeader>
<bodyText confidence="0.999988370370371">
As shown in equation 1, A1 and A2 control the
contribution of the source language parser toward
the target language parser. We tune these parame-
ters separately using development data. Firstly, we
tune A1 by fixing A2 = 0.1. The reason for choos-
ing such a large value of 0.1 is that we expect the
POS and arc label embeddings to be fairly simi-
lar across languages. Figure 2 shows the average
LAS for all 9 languages (except English) on dif-
ferent data sizes using different values of A1. We
observed that A1 = 0.001 gives the optimum value
on the development data consistently across differ-
ent data sizes. We compare the performance at two
extreme values of A1. For small data size, at 1k to-
kens, A1 = 100 is better than when A1 = 10−8.
This shows that when trained using a small data
set, the source language parser is more accurate
than the supervised model. However, at 3k tokens,
the supervised model is starting to perform better.
We now fix A1 = 0.001 to tune A2 in the same
range as A1. However, the average LAS didn’t
change much for different values of A2. It ap-
pears that A2 has very little effect on parsing accu-
racy. This is understandable since A2 affects only a
small number of parameters (POS and arc embed-
dings). Thus, we choose A1 = 0.001 and A2 = 0.1
for our experiments.
</bodyText>
<footnote confidence="0.898951">
7This is because UPOS generalizes better, and when ag-
gregating with lexical information, it has similar distinguish-
ing power compared with the fine-grained POS tagset.
</footnote>
<figureCaption confidence="0.988371">
Figure 2: Sensitivity of regularization parameter
</figureCaption>
<bodyText confidence="0.78529">
A1 against the average LAS measured on all 9 lan-
guages (except English) on the development set
for various data sizes (tokens)
</bodyText>
<subsectionHeader confidence="0.995979">
4.5 Learning Curve
</subsectionHeader>
<bodyText confidence="0.999978212121212">
We choose English as our source language to build
different target parsers for each language in the
Universal Dependency Treebank collection. We
train the supervised neural network parser as men-
tioned in Section 2 on the Universal Dependency
English treebank using UPOS tagset. The UAS
and LAS for the English parser is 85.2% and
82.9% respectively, when evaluated on the English
test set. We use the English parser as the prior for
our cross-lingual model, as described in Section 3.
Figure 3 shows the learning curve for both the
supervised neural network parser and our cross-
lingual model with respect to our implemention
of McDonald et al.’s (2011) delexicalized parser,
i.e. their basic model which uses no parallel data
and no target language supervision. Overall, both
the supervised model and the cross-lingual model
are much better than this baseline. For small data
sizes, our cross-lingual model is superior when
compared with the supervised model, giving as
much as an 8.7% improvement. This improvement
lessens as the size of training data increases. This
is to be expected, because the supervised model
becomes stronger as the size of training data in-
creases, while the contribution of the source lan-
guage parser is reduced. However, at 15k tokens
we still observed a 2.9% average improvement,
demonstrating the robustness of our cross-lingual
model. Using our model also reduced the standard
deviation ranges on each data point from 12% to
7%.
Using our cross-lingual model can save the an-
notation effort that is required in order to reach
</bodyText>
<figure confidence="0.990720956521739">
Accuracy (%)
1k
40 45 50 55 60 65
15k
5k
3k
10k
102
101
100
10−1
10−2
10−3
10−4
10−5
10−6
10−7
10−8
λ,
848
45 55 65 75
LAS (\%)
Data Size (tokens)
</figure>
<figureCaption confidence="0.619201333333333">
Figure 3: Learning curve for cross-lingual model
and supervised model with respect to the baseline
delexicalized parser from McDonald et al. (2011):
the x-axis is the size of data (number of tokens);
the y-axis is the average LAS measured on 9 lan-
guages (except English).
</figureCaption>
<bodyText confidence="0.999907555555555">
the same accuracy compared with the supervised
model. For example, we only need 1k tokens
in order to surpass the supervised model perfor-
mance on 3k tokens, and we only need 5k tokens
to match the supervised model trained on 10k to-
kens. The error rate reduction is from 15.8% down
to 6.5% for training data sizes from 1k to 15k to-
kens. However, when we use all the training data,
the supervised model is slightly better.
</bodyText>
<sectionHeader confidence="0.997162" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999970230769231">
Thanks to the availability of the Universal Depen-
dency Treebank, creating a treebank for a target
resource-poor language has becoming easier. This
fact motivates the work reported here, where we
assume that only a tiny treebank is available in the
target language. We tried to make the most out
of the target language treebank by incorporating
a source-language parser as a prior in learning a
neural network parser. Our results show that we
can achieve a more accurate parser using the same
training data. In future work, we would like to
investigate joint training on the source and target
languages.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9984846">
This work was supported by the University of
Melbourne and National ICT Australia (NICTA).
Trevor Cohn is the recipient of an Australian Re-
search Council Future Fellowship (project number
FT130101105).
</bodyText>
<sectionHeader confidence="0.989136" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996938285714286">
Alena B¨ohmov´a, Jan Hajiˇc, Eva Hajiˇcov´a, and Barbora
Hladk´a. 2001. The Prague Dependency Tree-
bank: A Three-Level Annotation Scenario. In
Anne Abeill´e, editor, Treebanks: Building and Us-
ing Syntactically Annotated Corpora, pages 103–
127. Kluwer Academic Publishers.
Razvan C. Bunescu and Raymond J. Mooney. 2005.
A shortest path dependency kernel for relation ex-
traction. In Proceedings of the Conference on Hu-
man Language Technology and Empirical Methods
in Natural Language Processing, HLT ’05, pages
724–731, Stroudsburg, PA, USA. ACL.
Danqi Chen and Christopher Manning. 2014. A fast
and accurate dependency parser using neural net-
works. In Proceedings of the 2014 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 740–750, Doha, Qatar. ACL.
Hang Cui, Renxu Sun, Keya Li, Min-Yen Kan, and
Tat-Seng Chua. 2005. Question answering passage
retrieval using dependency relations. In Proceed-
ings of the 28th Annual International ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval, SIGIR ’05, pages 400–407, New
York, NY, USA. ACM.
Long Duong, Trevor Cohn, Karin Verspoor, Steven
Bird, and Paul Cook. 2014. What can we get from
1000 tokens? a case study of multilingual pos tag-
ging for resource-poor languages. In Proceedings of
the 2014 Conference on Empirical Methods in Natu-
ral Language Processing (EMNLP), pages 886–897,
Doha, Qatar. ACL.
Andrew Garrett, Clare Sandy, Erik Maier, Line
Mikkelsen, and Patrick Davidson. 2013. Develop-
ing the Karuk Treebank. Fieldwork Forum, Depart-
ment of Linguistics, UC Berkeley.
Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara
Cabezas, and Okan Kolak. 2005. Bootstrapping
parsers via syntactic projection across parallel texts.
Natural Language Engineering, 11:311–325.
Philipp Koehn. 2005. Europarl: A Parallel Corpus for
Statistical Machine Translation. In Proceedings of
the Tenth Machine Translation Summit (MT Summit
X), pages 79–86, Phuket, Thailand.
Xuezhe Ma and Fei Xia. 2014. Unsupervised depen-
dency parsing with transferring distribution via par-
allel guidance and entropy regularization. In Pro-
ceedings of the 52nd Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers), pages 1337–1348. Association for Compu-
tational Linguistics.
Ryan McDonald, Koby Crammer, and Fernando
Pereira. 2005. Online large-margin training of de-
pendency parsers. In Proceedings of the 43rd An-
nual Meeting on Association for Computational Lin-
guistics, ACL ’05, pages 91–98, Stroudsburg, PA,
USA. ACL.
</reference>
<figure confidence="0.9846856">
●Cross−lingual Model
Supervised Model
Baseline Delex Model
●
●
●
●
●
●
1k 3k 5k 10k 15k All
</figure>
<page confidence="0.984451">
849
</page>
<reference confidence="0.999722608695652">
Ryan McDonald, Slav Petrov, and Keith Hall. 2011.
Multi-source transfer of delexicalized dependency
parsers. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing,
EMNLP ’11, pages 62–72.
Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-
Brundage, Yoav Goldberg, Dipanjan Das, Kuz-
man Ganchev, Keith Hall, Slav Petrov, Hao
Zhang, Oscar T¨ackstr¨om, Claudia Bedini, N´uria
Bertomeu Castell´o, and Jungmee Lee. 2013. Uni-
versal dependency annotation for multilingual pars-
ing. In Proceedings of the 51st Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 2: Short Papers), pages 92–97, Sofia, Bulgaria.
ACL.
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S.
Corrado, and Jeff Dean. 2013. Distributed repre-
sentations of words and phrases and their composi-
tionality. In C.j.c. Burges, L. Bottou, M. Welling,
Z. Ghahramani, and K.q. Weinberger, editors, Ad-
vances in Neural Information Processing Systems
26, pages 3111–3119.
Joakim Nivre, Cristina Bosco, Jinho Choi, Marie-
Catherine de Marneffe, Timothy Dozat, Rich´ard
Farkas, Jennifer Foster, Filip Ginter, Yoav Gold-
berg, Jan Hajiˇc, Jenna Kanerva, Veronika Laippala,
Alessandro Lenci, Teresa Lynn, Christopher Man-
ning, Ryan McDonald, Anna Missil¨a, Simonetta
Montemagni, Slav Petrov, Sampo Pyysalo, Natalia
Silveira, Maria Simi, Aaron Smith, Reut Tsarfaty,
Veronika Vincze, and Daniel Zeman. 2015. Univer-
sal dependencies 1.0.
Joakim Nivre. 2006. Inductive Dependency Parsing
(Text, Speech and Language Technology). Springer-
Verlag New York, Inc., Secaucus, NJ, USA.
Levent ¨Ozg¨ur and Tunga G¨ung¨or. 2010. Text classifi-
cation with the support of pruned dependency pat-
terns. Pattern Recognition Letters, 31(12):1598–
1607.
Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012.
A universal part-of-speech tagset. In Proceedings
of the Eighth International Conference on Lan-
guage Resources and Evaluation (LREC’12), Istan-
bul, Turkey.
Raivis Skadin¸ˇs, J¨org Tiedemann, Roberts Rozis, and
Daiga Deksne. 2014. Billions of parallel words for
free: Building and using the eu bookshop corpus. In
Proceedings of the 9th International Conference on
Language Resources and Evaluation (LREC-2014),
Reykjavik, Iceland. European Language Resources
Association (ELRA).
Oscar T¨ackstr¨om, Ryan McDonald, and Joakim Nivre.
2013. Target language adaptation of discrimina-
tive transfer parsers. In Proceedings of the 2013
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, pages 1061–1071, Atlanta,
Georgia. ACL.
Peng Xu, Jaeho Kang, Michael Ringgaard, and Franz
Och. 2009. Using a dependency parser to improve
smt for subject-object-verb languages. In Proceed-
ings of Human Language Technologies: The 2009
Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 245–253, Boulder, Colorado. ACL.
Daniel Zeman, Univerzita Karlova, and Philip Resnik.
2008. Cross-language parser adaptation between re-
lated languages. In In IJCNLP-08 Workshop on NLP
for Less Privileged Languages, pages 35–42.
</reference>
<page confidence="0.998157">
850
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.457052">
<title confidence="0.9797865">Low Resource Dependency Cross-lingual Parameter Sharing in a Neural Network Parser</title>
<author confidence="0.99863">Trevor Steven</author>
<affiliation confidence="0.956706">of Computing and Information Systems, University of ICT Australia, Victoria Research</affiliation>
<address confidence="0.502883">of Computer Science, University of New Brunswick</address>
<email confidence="0.99171">paul.cook@unb.ca</email>
<abstract confidence="0.999804153846154">Training a high-accuracy dependency parser requires a large treebank. However, these are costly and time-consuming to build. We propose a learning method that needs less data, based on the observation that there are underlying shared structures across languages. We exploit cues from a different source language in order to guide the learning process. Our model saves at least half of the annotation effort to reach the same accuracy compared with using the purely supervised method.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alena B¨ohmov´a</author>
<author>Jan Hajiˇc</author>
<author>Eva Hajiˇcov´a</author>
<author>Barbora Hladk´a</author>
</authors>
<title>The Prague Dependency Treebank: A Three-Level Annotation Scenario.</title>
<date>2001</date>
<booktitle>Treebanks: Building and Using Syntactically Annotated Corpora,</booktitle>
<pages>103--127</pages>
<editor>In Anne Abeill´e, editor,</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<marker>B¨ohmov´a, Hajiˇc, Hajiˇcov´a, Hladk´a, 2001</marker>
<rawString>Alena B¨ohmov´a, Jan Hajiˇc, Eva Hajiˇcov´a, and Barbora Hladk´a. 2001. The Prague Dependency Treebank: A Three-Level Annotation Scenario. In Anne Abeill´e, editor, Treebanks: Building and Using Syntactically Annotated Corpora, pages 103– 127. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan C Bunescu</author>
<author>Raymond J Mooney</author>
</authors>
<title>A shortest path dependency kernel for relation extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05,</booktitle>
<pages>724--731</pages>
<publisher>ACL.</publisher>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1172" citStr="Bunescu and Mooney, 2005" startWordPosition="159" endWordPosition="162">e propose a learning method that needs less data, based on the observation that there are underlying shared structures across languages. We exploit cues from a different source language in order to guide the learning process. Our model saves at least half of the annotation effort to reach the same accuracy compared with using the purely supervised method. 1 Introduction Dependency parsing is a crucial component of many natural language processing systems, for tasks such as text classification (¨Ozg¨ur and G¨ung¨or, 2010), statistical machine translation (Xu et al., 2009), relation extraction (Bunescu and Mooney, 2005), and question answering (Cui et al., 2005). Supervised approaches to dependency parsing have been successful for languages where relatively large treebanks are available (McDonald et al., 2005). However, for many languages, annotated treebanks are not available. They are costly to create, requiring careful design, testing and subsequent refinement of annotation guidelines, along with assessment and management of annotator quality (B¨ohmov´a et al., 2001). The Universal Treebank Annotation Guidelines aim at providing unified annotation for many languages enabling cross-lingual comparison (Nivr</context>
</contexts>
<marker>Bunescu, Mooney, 2005</marker>
<rawString>Razvan C. Bunescu and Raymond J. Mooney. 2005. A shortest path dependency kernel for relation extraction. In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05, pages 724–731, Stroudsburg, PA, USA. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danqi Chen</author>
<author>Christopher Manning</author>
</authors>
<title>A fast and accurate dependency parser using neural networks.</title>
<date>2014</date>
<booktitle>In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>740--750</pages>
<publisher>ACL.</publisher>
<location>Doha, Qatar.</location>
<contexts>
<context position="4389" citStr="Chen and Manning (2014)" startWordPosition="652" endWordPosition="655">d can be applied in cases where linguists are dependency-annotating small amounts of field data, such as in Karuk, a nearlyextinct language of Northwest California (Garrett et al., 2013). 1We use absolute values herein. 845 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 845–850, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics SOURCE - LANGUAGE PARSER TARGET - LANGUAGE PARSER Figure 1: Neural Network Parser Architecture from Chen and Manning (2014) (left). Our model (left and right) with soft parameter sharing between the source and target language shown with dashed lines. WORDS Eword CONFIGURATION (STACK, QUEUE, ARCS) SOFT-MAX LAYER MAPPING LAYER HIDDEN LAYER POS TAGS W2 W1 Epos ARC LABELS Earc WORDS Eword Epos Earc CONFIGURATION (STACK, QUEUE, ARCS) SOFT-MAX LAYER MAPPING LAYER HIDDEN LAYER W2 W1 POS TAGS ARC LABELS 2 Supervised Neural Network Parser In this section we review the parsing model which we use for both the source language and target language parsers. It is based on the work of Chen and Manning (2014). This parser can take</context>
</contexts>
<marker>Chen, Manning, 2014</marker>
<rawString>Danqi Chen and Christopher Manning. 2014. A fast and accurate dependency parser using neural networks. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 740–750, Doha, Qatar. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hang Cui</author>
<author>Renxu Sun</author>
<author>Keya Li</author>
<author>Min-Yen Kan</author>
<author>Tat-Seng Chua</author>
</authors>
<title>Question answering passage retrieval using dependency relations.</title>
<date>2005</date>
<booktitle>In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’05,</booktitle>
<pages>400--407</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1215" citStr="Cui et al., 2005" startWordPosition="166" endWordPosition="169">ased on the observation that there are underlying shared structures across languages. We exploit cues from a different source language in order to guide the learning process. Our model saves at least half of the annotation effort to reach the same accuracy compared with using the purely supervised method. 1 Introduction Dependency parsing is a crucial component of many natural language processing systems, for tasks such as text classification (¨Ozg¨ur and G¨ung¨or, 2010), statistical machine translation (Xu et al., 2009), relation extraction (Bunescu and Mooney, 2005), and question answering (Cui et al., 2005). Supervised approaches to dependency parsing have been successful for languages where relatively large treebanks are available (McDonald et al., 2005). However, for many languages, annotated treebanks are not available. They are costly to create, requiring careful design, testing and subsequent refinement of annotation guidelines, along with assessment and management of annotator quality (B¨ohmov´a et al., 2001). The Universal Treebank Annotation Guidelines aim at providing unified annotation for many languages enabling cross-lingual comparison (Nivre et al., 2015). This project provides a st</context>
</contexts>
<marker>Cui, Sun, Li, Kan, Chua, 2005</marker>
<rawString>Hang Cui, Renxu Sun, Keya Li, Min-Yen Kan, and Tat-Seng Chua. 2005. Question answering passage retrieval using dependency relations. In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’05, pages 400–407, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Long Duong</author>
<author>Trevor Cohn</author>
<author>Karin Verspoor</author>
<author>Steven Bird</author>
<author>Paul Cook</author>
</authors>
<title>What can we get from 1000 tokens? a case study of multilingual pos tagging for resource-poor languages.</title>
<date>2014</date>
<booktitle>In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>886--897</pages>
<publisher>ACL.</publisher>
<location>Doha, Qatar.</location>
<contexts>
<context position="6945" citStr="Duong et al. (2014)" startWordPosition="1071" endWordPosition="1074">t Epos, Earc, W1 and W2 can be shared as indicated with dashed lines. In particular we expect this to be the case when languages use the same POS tagset and arc label sets, as we presume herein. This assumption is motivated by the development of unified annotation for many languages (Nivre et al., 2015; Petrov et al., 2012; McDonald et al., 2013). To allow parameter sharing between languages we could jointly train the parser on the source and target language simultaneously. However, we leave this for future work. Here we take an alternative approach, namely regularization in a similar vein to Duong et al. (2014). First we train a lexicalized neural network parser on the source resource-rich language (English), as described in Section 2. The learned parameters are Eenword, Een pos, Een arc, Wen 1 , W en 2 . Second, we incorporate English parameters as a prior for the target language training. This is straightforward when we use the same architecture, such as a neural network parser, for the target language. All we need to do is modify the learning objective function so that it includes the regularization part. However, we don’t want to regularize the part related to Eenword since it will be very diffe</context>
</contexts>
<marker>Duong, Cohn, Verspoor, Bird, Cook, 2014</marker>
<rawString>Long Duong, Trevor Cohn, Karin Verspoor, Steven Bird, and Paul Cook. 2014. What can we get from 1000 tokens? a case study of multilingual pos tagging for resource-poor languages. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 886–897, Doha, Qatar. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Garrett</author>
<author>Clare Sandy</author>
<author>Erik Maier</author>
<author>Line Mikkelsen</author>
<author>Patrick Davidson</author>
</authors>
<title>Developing the Karuk Treebank. Fieldwork Forum, Department of Linguistics,</title>
<date>2013</date>
<location>UC Berkeley.</location>
<contexts>
<context position="3952" citStr="Garrett et al., 2013" startWordPosition="591" endWordPosition="594"> exploit both delexicalized parsing and parallel data. They use parallel data to constrain the model which is usually initialized by the English delexicalized parser. In summary, existing work generally starts with a delexicalized parser and uses parallel data to improve it. In this paper, we start with a source language parser and refine it with help from dependency annotations instead of parallel data. This choice means our method can be applied in cases where linguists are dependency-annotating small amounts of field data, such as in Karuk, a nearlyextinct language of Northwest California (Garrett et al., 2013). 1We use absolute values herein. 845 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 845–850, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics SOURCE - LANGUAGE PARSER TARGET - LANGUAGE PARSER Figure 1: Neural Network Parser Architecture from Chen and Manning (2014) (left). Our model (left and right) with soft parameter sharing between the source and target language shown with dashed lines. WORDS Eword CONFIGURATION (STACK, Q</context>
</contexts>
<marker>Garrett, Sandy, Maier, Mikkelsen, Davidson, 2013</marker>
<rawString>Andrew Garrett, Clare Sandy, Erik Maier, Line Mikkelsen, and Patrick Davidson. 2013. Developing the Karuk Treebank. Fieldwork Forum, Department of Linguistics, UC Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Hwa</author>
<author>Philip Resnik</author>
<author>Amy Weinberg</author>
<author>Clara Cabezas</author>
<author>Okan Kolak</author>
</authors>
<title>Bootstrapping parsers via syntactic projection across parallel texts. Natural Language Engineering,</title>
<date>2005</date>
<pages>11--311</pages>
<contexts>
<context position="3285" citStr="Hwa et al., 2005" startWordPosition="480" endWordPosition="483">tr¨om et al., 2013). The delexicalized approach was proposed by Zeman et al. (2008). A parser is built without any lexical features, and trained on a treebank in a resource-rich source language. It is then applied directly to parse sentences in the target resource-poor languages. Delexicalized parsing relies on the fact that identical part-of-speech (POS) inventories are highly informative of dependency relations, enough to make up for crosslingual syntactic divergence. In contrast, projection approaches use parallel data to project source language dependency relations to the target language (Hwa et al., 2005). McDonald et al. (2011) and Ma and Xia (2014) exploit both delexicalized parsing and parallel data. They use parallel data to constrain the model which is usually initialized by the English delexicalized parser. In summary, existing work generally starts with a delexicalized parser and uses parallel data to improve it. In this paper, we start with a source language parser and refine it with help from dependency annotations instead of parallel data. This choice means our method can be applied in cases where linguists are dependency-annotating small amounts of field data, such as in Karuk, a ne</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Cabezas, Kolak, 2005</marker>
<rawString>Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara Cabezas, and Okan Kolak. 2005. Bootstrapping parsers via syntactic projection across parallel texts. Natural Language Engineering, 11:311–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A Parallel Corpus for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the Tenth Machine Translation Summit (MT Summit X),</booktitle>
<pages>79--86</pages>
<location>Phuket, Thailand.</location>
<contexts>
<context position="10880" citStr="Koehn, 2005" startWordPosition="1755" endWordPosition="1756">ss languages allowing LAS evaluation. Table 1 shows the dataset size of each language in the collection. Some languages have over 400k tokens such as cs, fr and es, meanwhile, hu and ga have only around 25k tokens. 4.2 Monolingual Word Embeddings We initialize the target language word embeddings Eword of our neural network cross-lingual model with pre-trained embeddings. This is an advantage since we can incorporate monolingual data which is usually available for resource-poor languages. We collect monolingual data for each language from the Machine Translation Workshop (WMT) data,5 Europarl (Koehn, 2005) and EU Bookshop Corpus (Skadin¸ˇs et al., 2014). The size of monolingual data also varies significantly. There are languages such as English and German with more than 400 million words, whereas, Irish only has 4 million. We use the skip-gram model from word2vec to induce 50-dimension word embeddings (Mikolov et al., 2013). 4.3 Coarse vs Fine-Grain POS Our model uses the source language parser as the prior for the target language parser. The requirement is that the source and target should use the same POS tagset. It is clear that information will be lost when using the coarser shared-POS tags</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A Parallel Corpus for Statistical Machine Translation. In Proceedings of the Tenth Machine Translation Summit (MT Summit X), pages 79–86, Phuket, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xuezhe Ma</author>
<author>Fei Xia</author>
</authors>
<title>Unsupervised dependency parsing with transferring distribution via parallel guidance and entropy regularization.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>1337--1348</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3331" citStr="Ma and Xia (2014)" startWordPosition="489" endWordPosition="492">h was proposed by Zeman et al. (2008). A parser is built without any lexical features, and trained on a treebank in a resource-rich source language. It is then applied directly to parse sentences in the target resource-poor languages. Delexicalized parsing relies on the fact that identical part-of-speech (POS) inventories are highly informative of dependency relations, enough to make up for crosslingual syntactic divergence. In contrast, projection approaches use parallel data to project source language dependency relations to the target language (Hwa et al., 2005). McDonald et al. (2011) and Ma and Xia (2014) exploit both delexicalized parsing and parallel data. They use parallel data to constrain the model which is usually initialized by the English delexicalized parser. In summary, existing work generally starts with a delexicalized parser and uses parallel data to improve it. In this paper, we start with a source language parser and refine it with help from dependency annotations instead of parallel data. This choice means our method can be applied in cases where linguists are dependency-annotating small amounts of field data, such as in Karuk, a nearlyextinct language of Northwest California (</context>
</contexts>
<marker>Ma, Xia, 2014</marker>
<rawString>Xuezhe Ma and Fei Xia. 2014. Unsupervised dependency parsing with transferring distribution via parallel guidance and entropy regularization. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1337–1348. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL ’05,</booktitle>
<pages>91--98</pages>
<publisher>ACL.</publisher>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1366" citStr="McDonald et al., 2005" startWordPosition="186" endWordPosition="189"> guide the learning process. Our model saves at least half of the annotation effort to reach the same accuracy compared with using the purely supervised method. 1 Introduction Dependency parsing is a crucial component of many natural language processing systems, for tasks such as text classification (¨Ozg¨ur and G¨ung¨or, 2010), statistical machine translation (Xu et al., 2009), relation extraction (Bunescu and Mooney, 2005), and question answering (Cui et al., 2005). Supervised approaches to dependency parsing have been successful for languages where relatively large treebanks are available (McDonald et al., 2005). However, for many languages, annotated treebanks are not available. They are costly to create, requiring careful design, testing and subsequent refinement of annotation guidelines, along with assessment and management of annotator quality (B¨ohmov´a et al., 2001). The Universal Treebank Annotation Guidelines aim at providing unified annotation for many languages enabling cross-lingual comparison (Nivre et al., 2015). This project provides a starting point for developing a treebank for resource-poor languages. However, a mature parser requires a large treebank for training, and this is still </context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>Ryan McDonald, Koby Crammer, and Fernando Pereira. 2005. Online large-margin training of dependency parsers. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL ’05, pages 91–98, Stroudsburg, PA, USA. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Slav Petrov</author>
<author>Keith Hall</author>
</authors>
<title>Multi-source transfer of delexicalized dependency parsers.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>62--72</pages>
<contexts>
<context position="3309" citStr="McDonald et al. (2011)" startWordPosition="484" endWordPosition="487">. The delexicalized approach was proposed by Zeman et al. (2008). A parser is built without any lexical features, and trained on a treebank in a resource-rich source language. It is then applied directly to parse sentences in the target resource-poor languages. Delexicalized parsing relies on the fact that identical part-of-speech (POS) inventories are highly informative of dependency relations, enough to make up for crosslingual syntactic divergence. In contrast, projection approaches use parallel data to project source language dependency relations to the target language (Hwa et al., 2005). McDonald et al. (2011) and Ma and Xia (2014) exploit both delexicalized parsing and parallel data. They use parallel data to constrain the model which is usually initialized by the English delexicalized parser. In summary, existing work generally starts with a delexicalized parser and uses parallel data to improve it. In this paper, we start with a source language parser and refine it with help from dependency annotations instead of parallel data. This choice means our method can be applied in cases where linguists are dependency-annotating small amounts of field data, such as in Karuk, a nearlyextinct language of </context>
<context position="16311" citStr="McDonald et al. (2011)" startWordPosition="2674" endWordPosition="2677">is reduced. However, at 15k tokens we still observed a 2.9% average improvement, demonstrating the robustness of our cross-lingual model. Using our model also reduced the standard deviation ranges on each data point from 12% to 7%. Using our cross-lingual model can save the annotation effort that is required in order to reach Accuracy (%) 1k 40 45 50 55 60 65 15k 5k 3k 10k 102 101 100 10−1 10−2 10−3 10−4 10−5 10−6 10−7 10−8 λ, 848 45 55 65 75 LAS (\%) Data Size (tokens) Figure 3: Learning curve for cross-lingual model and supervised model with respect to the baseline delexicalized parser from McDonald et al. (2011): the x-axis is the size of data (number of tokens); the y-axis is the average LAS measured on 9 languages (except English). the same accuracy compared with the supervised model. For example, we only need 1k tokens in order to surpass the supervised model performance on 3k tokens, and we only need 5k tokens to match the supervised model trained on 10k tokens. The error rate reduction is from 15.8% down to 6.5% for training data sizes from 1k to 15k tokens. However, when we use all the training data, the supervised model is slightly better. 5 Conclusions Thanks to the availability of the Univer</context>
</contexts>
<marker>McDonald, Petrov, Hall, 2011</marker>
<rawString>Ryan McDonald, Slav Petrov, and Keith Hall. 2011. Multi-source transfer of delexicalized dependency parsers. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 62–72.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
<author>Yvonne QuirmbachBrundage</author>
<author>Yoav Goldberg</author>
<author>Dipanjan Das</author>
<author>Kuzman Ganchev</author>
<author>Keith Hall</author>
<author>Slav Petrov</author>
<author>Hao Zhang</author>
<author>Oscar T¨ackstr¨om</author>
<author>Claudia Bedini</author>
<author>N´uria Bertomeu Castell´o</author>
<author>Jungmee Lee</author>
</authors>
<title>Universal dependency annotation for multilingual parsing.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>92--97</pages>
<publisher>ACL.</publisher>
<location>Sofia, Bulgaria.</location>
<marker>McDonald, Nivre, QuirmbachBrundage, Goldberg, Das, Ganchev, Hall, Petrov, Zhang, T¨ackstr¨om, Bedini, Castell´o, Lee, 2013</marker>
<rawString>Ryan McDonald, Joakim Nivre, Yvonne QuirmbachBrundage, Yoav Goldberg, Dipanjan Das, Kuzman Ganchev, Keith Hall, Slav Petrov, Hao Zhang, Oscar T¨ackstr¨om, Claudia Bedini, N´uria Bertomeu Castell´o, and Jungmee Lee. 2013. Universal dependency annotation for multilingual parsing. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 92–97, Sofia, Bulgaria. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Ilya Sutskever</author>
<author>Kai Chen</author>
<author>Greg S Corrado</author>
<author>Jeff Dean</author>
</authors>
<title>Distributed representations of words and phrases and their compositionality.</title>
<date>2013</date>
<booktitle>Advances in Neural Information Processing Systems 26,</booktitle>
<pages>3111--3119</pages>
<editor>In C.j.c. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K.q. Weinberger, editors,</editor>
<contexts>
<context position="11204" citStr="Mikolov et al., 2013" startWordPosition="1807" endWordPosition="1810">l network cross-lingual model with pre-trained embeddings. This is an advantage since we can incorporate monolingual data which is usually available for resource-poor languages. We collect monolingual data for each language from the Machine Translation Workshop (WMT) data,5 Europarl (Koehn, 2005) and EU Bookshop Corpus (Skadin¸ˇs et al., 2014). The size of monolingual data also varies significantly. There are languages such as English and German with more than 400 million words, whereas, Irish only has 4 million. We use the skip-gram model from word2vec to induce 50-dimension word embeddings (Mikolov et al., 2013). 4.3 Coarse vs Fine-Grain POS Our model uses the source language parser as the prior for the target language parser. The requirement is that the source and target should use the same POS tagset. It is clear that information will be lost when using the coarser shared-POS tagset. Here, we simply want to quantify this loss. We run the supervised neural network parser on the coarse-grained Universal POS (UPOS) tagset, and the language-specific fine-grained POS tagset for languages where both are available in the Universal Dependency Treebank.6 Table 2 shows the average LAS for coarse- and fine-gr</context>
</contexts>
<marker>Mikolov, Sutskever, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S. Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In C.j.c. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K.q. Weinberger, editors, Advances in Neural Information Processing Systems 26, pages 3111–3119.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Joakim Nivre</author>
<author>Cristina Bosco</author>
<author>Jinho Choi</author>
<author>MarieCatherine de Marneffe</author>
<author>Timothy Dozat</author>
<author>Rich´ard Farkas</author>
<author>Jennifer Foster</author>
<author>Filip Ginter</author>
<author>Yoav Goldberg</author>
<author>Jan Hajiˇc</author>
<author>Jenna Kanerva</author>
</authors>
<date>2015</date>
<location>Veronika Laippala, Alessandro Lenci, Teresa Lynn, Christopher Manning, Ryan McDonald, Anna Missil¨a, Simonetta Montemagni, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Maria</location>
<note>Universal dependencies 1.0.</note>
<marker>Nivre, Bosco, Choi, de Marneffe, Dozat, Farkas, Foster, Ginter, Goldberg, Hajiˇc, Kanerva, 2015</marker>
<rawString>Joakim Nivre, Cristina Bosco, Jinho Choi, MarieCatherine de Marneffe, Timothy Dozat, Rich´ard Farkas, Jennifer Foster, Filip Ginter, Yoav Goldberg, Jan Hajiˇc, Jenna Kanerva, Veronika Laippala, Alessandro Lenci, Teresa Lynn, Christopher Manning, Ryan McDonald, Anna Missil¨a, Simonetta Montemagni, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Maria Simi, Aaron Smith, Reut Tsarfaty, Veronika Vincze, and Daniel Zeman. 2015. Universal dependencies 1.0.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Inductive Dependency Parsing (Text, Speech and Language Technology).</title>
<date>2006</date>
<publisher>SpringerVerlag</publisher>
<location>New York, Inc., Secaucus, NJ, USA.</location>
<contexts>
<context position="5273" citStr="Nivre, 2006" startWordPosition="791" endWordPosition="792">rc CONFIGURATION (STACK, QUEUE, ARCS) SOFT-MAX LAYER MAPPING LAYER HIDDEN LAYER W2 W1 POS TAGS ARC LABELS 2 Supervised Neural Network Parser In this section we review the parsing model which we use for both the source language and target language parsers. It is based on the work of Chen and Manning (2014). This parser can take advantage of target language monolingual data through word embeddings, data which is usually available for resource-poor languages. Chen and Manning’s parser also achieved state-of-the-art monolingual parsing performance. They built a transition-based dependency parser (Nivre, 2006) using a neuralnetwork. The neural network classifier decides which transition is applied for each configuration. The architecture of the parser is illustrated in Figure 1 (left), where each layer is fully connected to the layer above. For each configuration, the selected list of words, POS tags and labels from the Stack, Queue and Arcs are extracted. Each word, POS or label is mapped to a low-dimension vector representation (embedding) through the Mapping Layer. This layer simply concatenates the embeddings which are then fed into a two-layer neural network classifier to predict the next pars</context>
</contexts>
<marker>Nivre, 2006</marker>
<rawString>Joakim Nivre. 2006. Inductive Dependency Parsing (Text, Speech and Language Technology). SpringerVerlag New York, Inc., Secaucus, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Levent ¨Ozg¨ur</author>
<author>Tunga G¨ung¨or</author>
</authors>
<title>Text classification with the support of pruned dependency patterns.</title>
<date>2010</date>
<journal>Pattern Recognition Letters,</journal>
<volume>31</volume>
<issue>12</issue>
<pages>1607</pages>
<marker>¨Ozg¨ur, G¨ung¨or, 2010</marker>
<rawString>Levent ¨Ozg¨ur and Tunga G¨ung¨or. 2010. Text classification with the support of pruned dependency patterns. Pattern Recognition Letters, 31(12):1598– 1607.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dipanjan Das</author>
<author>Ryan McDonald</author>
</authors>
<title>A universal part-of-speech tagset.</title>
<date>2012</date>
<booktitle>In Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC’12),</booktitle>
<location>Istanbul, Turkey.</location>
<contexts>
<context position="6650" citStr="Petrov et al., 2012" startWordPosition="1024" endWordPosition="1027">er. 3 Cross-lingual parser Our model takes advantage of underlying structure shared between languages. Given the source language parsing structure as in Figure 1 (left), the set of parameters Eword will be different for the target language parser shown in Figure 1 (right) but we hypothesize that Epos, Earc, W1 and W2 can be shared as indicated with dashed lines. In particular we expect this to be the case when languages use the same POS tagset and arc label sets, as we presume herein. This assumption is motivated by the development of unified annotation for many languages (Nivre et al., 2015; Petrov et al., 2012; McDonald et al., 2013). To allow parameter sharing between languages we could jointly train the parser on the source and target language simultaneously. However, we leave this for future work. Here we take an alternative approach, namely regularization in a similar vein to Duong et al. (2014). First we train a lexicalized neural network parser on the source resource-rich language (English), as described in Section 2. The learned parameters are Eenword, Een pos, Een arc, Wen 1 , W en 2 . Second, we incorporate English parameters as a prior for the target language training. This is straightfor</context>
</contexts>
<marker>Petrov, Das, McDonald, 2012</marker>
<rawString>Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012. A universal part-of-speech tagset. In Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC’12), Istanbul, Turkey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raivis Skadin¸ˇs</author>
<author>J¨org Tiedemann</author>
<author>Roberts Rozis</author>
<author>Daiga Deksne</author>
</authors>
<title>Billions of parallel words for free: Building and using the eu bookshop corpus.</title>
<date>2014</date>
<booktitle>In Proceedings of the 9th International Conference on Language Resources and Evaluation (LREC-2014), Reykjavik, Iceland. European Language Resources Association (ELRA).</booktitle>
<marker>Skadin¸ˇs, Tiedemann, Rozis, Deksne, 2014</marker>
<rawString>Raivis Skadin¸ˇs, J¨org Tiedemann, Roberts Rozis, and Daiga Deksne. 2014. Billions of parallel words for free: Building and using the eu bookshop corpus. In Proceedings of the 9th International Conference on Language Resources and Evaluation (LREC-2014), Reykjavik, Iceland. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Target language adaptation of discriminative transfer parsers.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>1061--1071</pages>
<publisher>ACL.</publisher>
<location>Atlanta,</location>
<marker>T¨ackstr¨om, McDonald, Nivre, 2013</marker>
<rawString>Oscar T¨ackstr¨om, Ryan McDonald, and Joakim Nivre. 2013. Target language adaptation of discriminative transfer parsers. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1061–1071, Atlanta, Georgia. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peng Xu</author>
<author>Jaeho Kang</author>
<author>Michael Ringgaard</author>
<author>Franz Och</author>
</authors>
<title>Using a dependency parser to improve smt for subject-object-verb languages.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>245--253</pages>
<publisher>ACL.</publisher>
<location>Boulder, Colorado.</location>
<contexts>
<context position="1124" citStr="Xu et al., 2009" startWordPosition="153" endWordPosition="156">e costly and time-consuming to build. We propose a learning method that needs less data, based on the observation that there are underlying shared structures across languages. We exploit cues from a different source language in order to guide the learning process. Our model saves at least half of the annotation effort to reach the same accuracy compared with using the purely supervised method. 1 Introduction Dependency parsing is a crucial component of many natural language processing systems, for tasks such as text classification (¨Ozg¨ur and G¨ung¨or, 2010), statistical machine translation (Xu et al., 2009), relation extraction (Bunescu and Mooney, 2005), and question answering (Cui et al., 2005). Supervised approaches to dependency parsing have been successful for languages where relatively large treebanks are available (McDonald et al., 2005). However, for many languages, annotated treebanks are not available. They are costly to create, requiring careful design, testing and subsequent refinement of annotation guidelines, along with assessment and management of annotator quality (B¨ohmov´a et al., 2001). The Universal Treebank Annotation Guidelines aim at providing unified annotation for many l</context>
</contexts>
<marker>Xu, Kang, Ringgaard, Och, 2009</marker>
<rawString>Peng Xu, Jaeho Kang, Michael Ringgaard, and Franz Och. 2009. Using a dependency parser to improve smt for subject-object-verb languages. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 245–253, Boulder, Colorado. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Zeman</author>
<author>Univerzita Karlova</author>
<author>Philip Resnik</author>
</authors>
<title>Cross-language parser adaptation between related languages. In</title>
<date>2008</date>
<booktitle>In IJCNLP-08 Workshop on NLP for Less Privileged Languages,</booktitle>
<pages>35--42</pages>
<contexts>
<context position="2751" citStr="Zeman et al. (2008)" startWordPosition="397" endWordPosition="400">m the source resource-rich language is incorporated as a prior in the supervised training of a resource-poor target language parser using a small treebank. When compared with a supervised model, the gain is as high as 8.7%1 on average when trained on just 1,000 tokens. As we add more training data, the gains persist, though they are more modest. Even at 15,000 tokens we observe a 2.9% improvement. There are two main approaches for building dependency parsers for resource-poor languages: delexicalized parsing and projection (T¨ackstr¨om et al., 2013). The delexicalized approach was proposed by Zeman et al. (2008). A parser is built without any lexical features, and trained on a treebank in a resource-rich source language. It is then applied directly to parse sentences in the target resource-poor languages. Delexicalized parsing relies on the fact that identical part-of-speech (POS) inventories are highly informative of dependency relations, enough to make up for crosslingual syntactic divergence. In contrast, projection approaches use parallel data to project source language dependency relations to the target language (Hwa et al., 2005). McDonald et al. (2011) and Ma and Xia (2014) exploit both delexi</context>
</contexts>
<marker>Zeman, Karlova, Resnik, 2008</marker>
<rawString>Daniel Zeman, Univerzita Karlova, and Philip Resnik. 2008. Cross-language parser adaptation between related languages. In In IJCNLP-08 Workshop on NLP for Less Privileged Languages, pages 35–42.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>