<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.995649">
Negative Polarity Licensing at the Syntax-Semantics Interface
</title>
<author confidence="0.98747">
John Fry
</author>
<affiliation confidence="0.978839333333333">
Stanford University and Xerox PARC
Dept. of Linguistics
Stanford University
</affiliation>
<address confidence="0.673658">
Stanford, CA 94305-2150, USA
</address>
<email confidence="0.99932">
fry@csli.stanford.edu
</email>
<sectionHeader confidence="0.993894" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999876947368421">
Recent work on the syntax-semantics in-
terface (see e.g. (Dalrymple et al., 1994))
uses a fragment of linear logic as a
&apos;glue language&apos; for assembling meanings
compositionally. This paper presents
a glue language account of how nega-
tive polarity items (e.g. ever, any) get
licensed within the scope of negative
or downward-entailing contexts (Ladusaw,
1979), e.g. Nobody ever left. This treat-
ment of licensing operates precisely at the
syntax-semantics interface, since it is car-
ried out entirely within the interface glue
language (linear logic). In addition to the
account of negative polarity licensing, we
show in detail how linear-logic proof nets
(Girard, 1987; Gallier, 1992) can be used
for efficient meaning deduction within this
&apos;glue language&apos; framework.
</bodyText>
<sectionHeader confidence="0.989929" genericHeader="keywords">
1 Background
</sectionHeader>
<bodyText confidence="0.9915847">
A recent strain of research on the interface between
syntax and semantics, starting with (Dalrymple et
al., 1993), uses a fragment of linear logic as a &apos;glue
language&apos; for assembling the meaning of a sentence
compositionally. In this approach, meaning assem-
bly is guided not by a syntactic constituent tree but
rather by the flatter functional structure (the LFG
f-structure) of the sentence.
As a brief review of this approach, consider sen-
tence (1):
</bodyText>
<figure confidence="0.147155333333333">
(1) Everyone left.
FRED &apos;LEAVE&apos;
f: SUB.) g:[FRED &apos;EVERYONE&apos;
</figure>
<bodyText confidence="0.963385">
Each word in the sentence is associated with a
&apos;meaning constructor&apos; template, specified in the lex-
icon; these meaning constructors are then instanti-
ated with values from the f-structure. For sentence
(1), this produces two premises of the linear logic
glue language:
</bodyText>
<equation confidence="0.940431666666667">
everyone: (gc-,ex -0 H^-■tS(x))
—0 H-s-+t every (person, S)
left: gcr-s-4e X —4) fer.•-4t leave(X)
</equation>
<bodyText confidence="0.999954473684211">
In the everyone premise the higher-order variable
S ranges over the possible scope meanings of the
quantifier, with lower-case x acting as a traditional
first-order variable &amp;quot;placeholder&amp;quot; within the scope.
H ranges over LFG structures corresponding to the
meaning of the entire generalized quantifier.&apos;
A meaning for (1) can be derived by applying
the linear version of modus ponens, during which
(unlike classical logic) the first premise everyone
&amp;quot;consumes&amp;quot; the second premise left. This deduc-
tion, along with the substitutions H 1-4 fe,, X 1-4 x
and S 1-4 Ax.leave(x), produces the final mean-
ing f,-.4t every (person, Ax.leave(x)), which is in this
simple case the only reading for the sentence.
One advantage of this deductive style of meaning
assembly is that it provides an elegant account of
quantifier scoping: each possible scope has a cor-
responding proof, obviating the need for quantifier
storage.
</bodyText>
<sectionHeader confidence="0.509497" genericHeader="introduction">
2 Meaning deduction via proof nets
</sectionHeader>
<bodyText confidence="0.948261818181818">
A proof net (Girard, 1987) is an undirected, con-
nected graph whose node labels are propositions. A
&apos;Here we have simplified the notation of Dalrymple
et al. somewhat, for example by stripping away the uni-
versal quantifier operators from the variables. In this
regard, note that the lower-case variables stand for ar-
bitrary constants rather than particular terms, and gen-
erally are given limited scope within the antecedent of
the premise. Upper-case variables are Prolog-like vari-
ables that become instantiated to specific terms within
the proof, and generally their scope is the entire premise.
</bodyText>
<page confidence="0.998587">
144
</page>
<figureCaption confidence="0.999377">
Figure 1: Proof net for Everyone left.
</figureCaption>
<equation confidence="0.778729333333333">
H,t S(x)
((g-&apos;- z)&apos; S(x)) (H,t every (person, S))-L. ge,-+e X (fes--,t leave(X))i
x)-L. Ht S(x)) (H,ot every (person, S)).1 9e,-,4. X 0 (fes--.t leave(X))± fe•-■t M
</equation>
<bodyText confidence="0.996228533333333">
theorem of multiplicative linear logic corresponds to
only one proof net; thus the manipulation of proof
nets is more efficient than sequent deduction, in
which the same theorem might have different proofs
corresponding to different orderings of the inference
steps. A further advantage of proof nets for our pur-
poses is that an invalid meaning deduction, e.g. one
corresponding to some spurious scope reading of a
particular sentence, can be illustrated by exhibiting
its defective graph which demonstrates visually why
no proof exists for it. Proof net techniques have also
been exploited within the categorial grammar com-
munity, for example for reasons of efficiency (Mor-
rill, 1996) and in order to give logical descriptions of
certain syntactic phenomena (Lecomte and Retore,
1995).
In this section we construct a proof net from the
premises for sentence (1), showing how to apply
higher-order unification to the meaning terms in the
process. We then review the 0(n2) algorithm of
Gallier (1992) for propositional (multiplicative) lin-
ear logic which checks whether a given proof net is
valid, i.e. corresponds to a proof. The complete pro-
cess for assembling a meaning from its premises will
be shown in four steps: (1) rewrite the premises in
a normalized form, (2) assemble the premises into
a graph, (3) connect together the positive (&amp;quot;pro-
ducer&amp;quot;) and negative (&amp;quot;consumer&amp;quot;) meaning terms,
unifying them in the process, and (4) test whether
the resulting graph encodes a proof.
</bodyText>
<subsectionHeader confidence="0.998411">
2.1 Step 1: set up the sequent
</subsectionHeader>
<bodyText confidence="0.979311230769231">
Since our goal is to derive, from the premises of sen-
tence (1), a meaning M for the f-structure f of the
entire sentence, what we seek is a proof of the form
everyone left I- f,,,At M.
Glue language semantics has so far been restricted
to the multiplicative fragment of linear logic, which
uses only the multiplicative conjunction operator
0 (tensor) and the linear implication operator —0.
The same fragment is obtained by replacing —0
with the operators and I, where It (par) is the
multiplicative &apos;or&apos; and I is linear negation and
(A —o B) (A-L. B). Using the version with-
out —0, we normalize two sided sequents of the form
A1, ,Am H B1,. ,B, into right-sided sequents
of the form H , , , , Bn. (In sequent
representations of this style, the comma represents
0 on the left side of the sequent and on the right
side.) In our new format, then, the proof takes the
form
I- everyone&apos;, left&amp;quot;, fa&amp;quot;-q M.
The proof net further requires that sequents be in
negation normal form, in which negation is applied
only to atomic terms.3 Moving the negations in-
ward (the usual double-negation and &apos;de Morgan&apos;
properties hold), and displaying the full premises,
we obtain the normalized sequent
</bodyText>
<equation confidence="0.86716775">
}- x)-L S (x))
0(1-P,-.0t every(per son, S))i
g„,,+, X 0 ( t leave(X))- ,
fo^-qm.
</equation>
<subsectionHeader confidence="0.99642">
2.2 Step 2: create the graph
</subsectionHeader>
<bodyText confidence="0.9946456">
The next step is to create a graph whose nodes con-
sist of all the terms which occur in the sequent. That
is, a node is created for each literal C and for each
negated literal CI; a node is created for each com-
pound term A 0 B or A II B; and nodes are also
created for its subterms A and B. Then, for each
node of the form A B, we draw a soft edge in
the form of a horizontal dashed line connecting it to
nodes A and B. For each node of the form A 0 B , we
draw a hard edge (solid line) connecting it to nodes
A and B. For the example at hand, this produces
the graph in Figure 1 (ignoring the curved edges at
the top).
&apos;This notation is Gallier&apos;s (1992).
3Note that we refer to noncompound terms as &apos;literal&apos;
or &apos;atomic&apos; terms because they are atomic from the point
of view of the glue language, even though these terms
are in fact of the form S.&amp;quot;, M, where S is an expression
over LFG structures and M is a type-r expression in the
meaning language.
</bodyText>
<page confidence="0.993807">
145
</page>
<subsectionHeader confidence="0.995617">
2.3 Step 3: connect the literals
</subsectionHeader>
<bodyText confidence="0.999965121212121">
The final step in assembling the proof net is to con-
nect together the literal nodes at the top of the
graph. It is at this stage that unification is applied
to the variables in order to assign them the values
they will assume in the final meaning. Each differ-
ent way of connecting the literals and instantiating
their variables corresponds to a different reading for
the sentence.
For each literal, we draw an edge connecting it to
a matching literal of opposite sign; i.e. each literal A
is connected to a literal B1 where A unifies with B.
Every literal in the graph must be connected in this
way. If for some literal A there exists no matching
literal B of opposite sign then the graph does not
encode a proof and the algorithm fails.
In this process the unifications apply to whole ex-
pressions of the form S-&apos;.* M, including both vari-
ables over LFG structures and variables over mean-
ing terms. For the meaning terms, this requires
a limited higher-order unification scheme that pro-
duces the unifier Ax.p(x) from a second-order term T
and a first-order term p(x). As noted by Dalrymple
et al. (to appear), all the apparatus that is required
for their simple intensional meaning language falls
within the decidable /A fragment of Miller (1990),
and therefore can be implemented as an extension
of a first-order unification scheme such as that of
Prolog.
For the example at hand, there is only one way to
connect the literals (and hence at most one read-
ing for the sentence), as shown in Figure 1. At
this stage, the unifications would bind the vari-
ables in Figure 1 as follows: X 1-+ x, H 1-4 fa,
</bodyText>
<equation confidence="0.291003">
S Ax.leave(x), M 1-4 every(person,Ax.leave(x)).
</equation>
<subsectionHeader confidence="0.980565">
2.4 Step 4: test the graph for validity
</subsectionHeader>
<bodyText confidence="0.99195128125">
Finally, we apply Gallier&apos;s (1992) algorithm to the
connected graph in order to check that it corre-
sponds to a proof. This algorithm recursively de-
composes the graph from the bottom up while check-
ing for cycles. Here we present the algorithm infor-
mally; for proofs of its correctness and 0(n2) time
complexity see (Gallier, 1992).
Base case: If the graph consists of a single link be-
tween literals A and A1, the algorithm succeeds and
the graph corresponds to a proof.
Recursive case 1: Begin the decomposition by
deleting the bottom-level par nodes. If there is some
terminal node A It B connected to higher nodes A
and B, delete A B. This of course eliminates the
dashed edge from A tt B to A and to B, but does not
remove nodes A and B. Then run the algorithm on
the resulting smaller (possibly unconnected) graph.
Recursive case 2: Otherwise, if no terminal par
node is available, find a terminal tensor node to
delete. This case is more complicated because not
every way of deleting a tensor node necessarily leads
to success, even for a valid proof net. Just choose
some terminal tensor node A 0 B. If deleting that
node results in a single, connected (i.e. cyclic) graph,
then that node was not a valid splitting tensor and
a different one must be chosen instead, or else halt
with failure if none is available. Otherwise, delete
A 0 B, which leaves nodes A and B belonging to
two unconnected graphs Cl and G2. Then run the
algorithm on Cl and G2.
This process will be demonstrated in the examples
which follow.
</bodyText>
<sectionHeader confidence="0.93679" genericHeader="method">
3 A glue language treatment of NPI
licensing
</sectionHeader>
<bodyText confidence="0.999872285714286">
Ladusaw (1979) established what is now a well-
known generalization in semantics, namely that neg-
ative polarity lexical items (NPI&apos;s, e.g. any, ever)
are licensed within the scope of downward-entailing
operators (e.g. no, few). For example, the NPI ever
occurs felicitously in a context like No one ever left
but not in *John ever left.&apos; Laclusaw showed that
the status of a lexical item as a NPI or licenser de-
pends on its meaning; i.e. on semantic rather than
syntactic or lexical properties. On the other hand,
the requirement that NPI&apos;s be licensed in order to
appear felicitously in a sentence is a constraint on
surface syntactic form. So the domain of NPI li-
censing is really the interface between syntax and
semantics, where meanings are composed under syn-
tactic guidance.
This section gives an implementation of NPI li-
censing at the syntax-semantics interface using glue
language. No separate proof or interpretation appa-
ratus is required, only modification of the relevant
meaning constructors specified in the lexicon.
</bodyText>
<subsectionHeader confidence="0.999888">
3.1 Meaning constructors for NPI&apos;s
</subsectionHeader>
<bodyText confidence="0.999890166666667">
There is a resource-based interpretation of the NPI
licensing problem: the negative or decreasing licens-
ing operator must make available a resource, call it e,
which will license the NPI&apos;s, if any, within its scope.
If no such resource is made available the NPI&apos;s are
unlicensed and the sentence is rejected.
</bodyText>
<footnote confidence="0.718348">
4Here we consider only &apos;rightward&apos; licensing (within
the scope of the quantifier), but this approach ap-
plies equally well to &apos;leftward&apos; licensing (within the
restriction).
</footnote>
<page confidence="0.99245">
146
</page>
<figure confidence="0.975025666666667">
nfe......e P t Cfo&amp;quot;...t yet(P) ti-
g.&amp;quot;-...Y Cfc,--...t sing (Y))i f.,--..t P 0 t (fer-.-.1 Yet(P))j- if II
(g„--.. Al)i 9.-.....Y el (f„,--., sing(n)i (f„....., P 0£) 0 ((f....&amp;quot;t Yet(P))-1- a ii) f.,--, Al
</figure>
<figureCaption confidence="0.999548">
Figure 2: Invalid proof net of *Al sang yet.
</figureCaption>
<bodyText confidence="0.95783524">
The NPI&apos;s must be made to require the t resource.
The way one implements such a requirement in lin-
ear logic is to put the required resource on the left
side of the implication operator —o. This is precisely
our approach. However, since the NPI is just &apos;bor-
rowing&apos; the license, not consuming it (after all, more
than one NPI may be licensed, as in No one ever
saw anyone), we also add the resource to the right
hand side of the implication. That is, for a mean-
ing constructor of the form A —o B, we can make a
corresponding NPI meaning constructor of the form
(A 0 t) —0 (B t).
For example, the meaning constructor proposed in
(Dalrymple et al., 1993) for the sentential modifier
obviously is
obviously: f P —0 fu&apos;••-■g obviously (P).
Under this analysis of sentential modification, NPI
adverbs such as yet or ever would take the same
form, but with the licensing apparatus added:
ever: (fa^-qP 0 0 —0 (f&apos;-*t ever(P) t).
This technique can be readily applied to the other
categories of NPI as well. In the case of the NPI
quantifier phrase anyone5 the licensing apparatus is
added to the earlier template for everyone to pro-
duce the meaning constructor
</bodyText>
<equation confidence="0.882466">
anyone: (g--ex —0 .11^-+t S(x) 0 t&apos;)
—0 any(person, S) 0 t).
</equation>
<bodyText confidence="0.996626">
The only function of the t --0 t pattern inside an
NPI is to consume the resource t and then produce
it again. However, for this to happen, the resource
t will have to be generated by some licenser whose
scope includes the NPI, as we show below. If no
outside t resource is made available, then the extra-
neous, unconsumed t material in the NPI guarantees
that no proof will be generated. In proof net terms,
&apos;Any also has another, so-called &apos;free choice&apos; inter-
pretation (as in e.g. Anyone will do) (Ladusaw, 1979;
Kadmon and Landman, 1993), which we ignore here.
the output / cannot feed back into the input t with-
out producing a cycle.
We now demonstrate how the deduction is blocked
for a sentence containing an unlicensed NPI such as
(2).
</bodyText>
<listItem confidence="0.493236">
(2) *Al sang yet.
</listItem>
<table confidence="0.633945125">
f: PRED &apos;SING&apos; &apos;AL&apos;]
SUBJ g: [ PRED &apos;YET&apos; ] }
MODS { [ PRED
[
The relevant premises are
Al: go&amp;quot;-■, Al
sang: 9,7&amp;quot;-*eY —0 sing(Y)
yet: (f7^-4iP 0 0 —° (fcr-s-4tYet(P) 0 t)
</table>
<bodyText confidence="0.99982925">
The graph of (2), shown in Figure 2, does not encode
a proof. The reason is shown in Figure 3. At this
point in the algorithm, we have deleted the leftmost
terminal tensor node. However, the only remaining
terminal tensor node cannot be deleted, since doing
so would produce a single connected subgraph; the
cycle is in the edge from t to ti. At this point the
algorithm fails and no meaning is derived.
</bodyText>
<subsectionHeader confidence="0.999839">
3.2 Meaning constructors for NPI licensers
</subsectionHeader>
<bodyText confidence="0.980479058823529">
It is clear from the proposal so far that lexical items
which license NPI&apos;s must make available a t resource
within their scope which can be consumed by the
NPI. However, that is not enough; a licenser can
still occur inside a sentence without an NPI, as in
e.g. No one left. The resource accounting of linear
logic requires that we &apos;clean up&apos; by consuming any
excess resources in order for the meaning deduction
to go through.
Fortunately, we can solve this problem within the
licenser&apos;s meaning constructor itself. For a lexical
category whose meaning constructor is of the form
A-0.6, we assign to the NPI licensers of that cate-
gory the meaning constructor
(t —0 (A 0 t)) —o B.
By its logical structure, being embedded inside an-
other implication, the inner implication here serves
</bodyText>
<page confidence="0.954115">
147
</page>
<equation confidence="0.973156333333333">
(De Y in9(n)i P 0 I Ch7;e—yittP))--L—titi
P yet(P))-1-
P 0£) 0 ((f.&amp;quot;-.4 Yet(P))-1- t-L) M
</equation>
<figureCaption confidence="0.923851">
Figure 3: Point of failure. Bottom tensor node cannot be deleted.
</figureCaption>
<bodyText confidence="0.948824357142857">
Ai)
to introduce &apos;hypothetical&apos; material. All of the NPI
licensing occurs within the hypothetical (left) side
of the outermost implication. Since the P resource
is made available to the NPI only within this hypo-
thetical, it is guaranteed that the NPI is assembled
within, and therefore falls under, the scope of the li-
censer. Furthermore, the formula is &apos;self cleaning&apos;, in
that the resource, even if not used by an NPI, does
not survive the hypothetical and so cannot affect the
meaning of the licenser in some other way. That is,
the licensing constructor (I --0 (A 0 e)) B can
derive all of the same meanings as the nonlicensing
version A -0 B.
</bodyText>
<equation confidence="0.47898">
Fact 1 (l-o(A 1))-oB A-oB
</equation>
<bodyText confidence="0.92146225">
Proof We construct the proof net of the equivalent
right-sided sequent
I- (II 0 (A 0 i)) BI,A±,B
and then test that it is valid.
A
Aet
--t-r 0 (A t) B1
(II 0 (A 0 1)) 0 B
</bodyText>
<figure confidence="0.787523">
A
1-1-- A P
CA t)
Al B
A®l ti I A 0
</figure>
<bodyText confidence="0.985004142857143">
This self-cleaning property means that a licensing
resource is exactly that—a license. Within the
scope of the licenser, the is available to be used
once, several times (in a &amp;quot;chain&amp;quot; of NPI&apos;s which pass
it along), or not at all, as required.6
A simple example is provided by the NPI-licensing
adverb rarely. We modify our sentential adverb
template to create a meaning constructor for rarely
which licenses an NPI within the sentence it modi-
fies.
rarely: (1 -o (fc,-.4t P I)) -o rare/y(P)
The case of licensing quantifier phrases such as
nobody and few students follows the same pattern.
For example, nobody takes the form
</bodyText>
<construct confidence="0.8638785">
nobody: ((9,-.4ex I) -0 (11.-.4t SW I))
H-,+t no (person, S).
</construct>
<bodyText confidence="0.995789666666667">
We can now derive a meaning for sentence (3), in
which nobody and anyone play the roles of licenser
and NPI, respectively.
</bodyText>
<listItem confidence="0.812697">
(3) Nobody saw anyone.
</listItem>
<table confidence="0.278895">
[PRED &apos;SEE&apos;
f: SUBJ g:[ PRED &apos;NOBODY&apos;]
OBJ h:[ PRED &apos;ANYONE&apos;]
</table>
<bodyText confidence="0.9906145">
Normally, a sentence with two quantifiers would
generate two different scope readings—in this case,
</bodyText>
<listItem confidence="0.998434333333333">
(4) and (5).
(4) f(,-,4t no(person, )x. any (person, Ay .see(x, y)))
(5) icr^-4t any(person, )ty. no(person, Ax.see(x, y)))
</listItem>
<bodyText confidence="0.889518636363636">
However, Ladusaw&apos;s generalization is that NPI&apos;s
are licensed within the scope of their licensers. In
fact, the semantics of any prevent it from taking
wide scope in such a case (Kadmon and Landman,
1993; Ladusaw, 1979, p. 96-101). Our analysis, then,
should derive (4) but block (5).
6This multiple-use effect can be achieved more di-
rectly using the exponential operator!; however this un-
necessary step would take us outside of the multiplica-
tive fragment of linear logic and preclude the proof net
techniques described earlier.
</bodyText>
<page confidence="0.992329">
148
</page>
<bodyText confidence="0.90371">
The premises are
</bodyText>
<equation confidence="0.9518366">
nobody: ((gc,-•-■ex 0 t) -0 (H-s-4 t 5(x) t))
-0 H-s-+t no(person, S)
saw: (ger&apos;s-4e X 0 hcf-&apos;4e Y) -0 fq--&gt;tsee(X,Y)
anyone: y -0 .1&amp;quot;4tT(Y) t)
--0 (.1,4t any(person, T) t)
</equation>
<bodyText confidence="0.999913">
The proof net for reading (4) is shown in Figure 4.7
As required, the net in Figure 4, corresponding to
wide scope for no, is valid. The first step in the proof
of Figure 4 is to delete the only available splitting
tensor, which is boxed in the figure. A second way
of linking the positive and negative literals in Fig-
ure 4 produces a net which corresponds to (5), the
spurious reading in which any has wide scope. In
that graph, however, all three of the available termi-
nal tensor nodes produce a single, connected (cyclic)
graph if deleted, so decomposition cannot even be-
gin and the algorithm fails. Once again, it is the
licensing resources which are enforcing the desired
constraint.
</bodyText>
<sectionHeader confidence="0.993088" genericHeader="method">
4 Categorial grammar approaches
</sectionHeader>
<bodyText confidence="0.9999324">
The t atom used here is somewhat analogous to the
(negative) lexical `monotonicity markers&apos; proposed
by Sanchez Valencia (1991; 1995) and Dowty (1994)
for categorial grammar. In these approaches, cate-
gories of the form AI B are marked with monotonic-
ity properties, i.e. as AIB, A+IB-,A-1B+, or
A- I B- , and similarly for left-leaning categories of
the form A\B. Then monotonicity constraints can
be enforced using category assignments like the fol-
lowing from (Dowty, 1994):
</bodyText>
<equation confidence="0.4503734">
f (S+ IV P-)ICN- 1
no.
1 (S- IV P+)IC N+ f
any: (S- IV P-)ICN-
ever: V P- IV P-
</equation>
<bodyText confidence="0.999798">
Sanchez Valencia and Dowty, however, are less
concerned with the distribution of NPI&apos;s than they
are with using monotonicity properties to character-
ize valid inference patterns, an issue which we have
ignored here. Hence their work emphasizes logical
polarity, where an odd number of negative marks
indicates negative polarity, and an even number of
negatives cancel each other to produce positive po-
larity. For example, the category of no above &amp;quot;flips&amp;quot;
the polarity of its argument. By contrast, our sys-
tem, like Ladusaw&apos;s (1979) original proposal, is what
Dowty (1994, p. 134-137) would call &amp;quot;intuitionistic&amp;quot;:
</bodyText>
<footnote confidence="0.9938605">
7The subscripts have been stripped from the formulas
in order to save space in the diagram.
</footnote>
<page confidence="0.998019">
149
</page>
<bodyText confidence="0.99992725">
since multiple negative contexts do not cancel each
other out, we permit doubly-licensed NPI&apos;s as in
Nobody rarely sees anyone. To handle such cases,
while at the same time accounting for monotonic in-
ference properties, Dowty (1994) proposes a double-
marking framework whereby categories like A::/B+
are masked for both logical polarity and syntactic
polarity.
</bodyText>
<sectionHeader confidence="0.998864" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999758470588235">
We have elaborated on and extended slightly the
&apos;glue language&apos; approach to semantics of Dalrymple
et al. It was shown how linear logic proof nets can
be used for efficient natural-language meaning de-
ductions in this framework. We then presented a
glue language treatment of negative polarity licens-
ing which ensures that NPI&apos;s are licensed within the
semantic scope of their licensers, following (Ladu-
saw, 1979). This system uses no new global rules
or features, nor ambiguous lexical entries, but only
the addition of L&apos;s to the relevant items within the
lexicon. The licensing takes place precisely at the
syntax-semantics interface, since it is implemented
entirely in the interface glue language. Finally, we
noted briefly some similarities and differences be-
tween this system and categorial grammar &apos;mono-
tonicity marking&apos; approaches.
</bodyText>
<sectionHeader confidence="0.99943" genericHeader="acknowledgments">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.998149833333334">
I&apos;m grateful to Mary Dalrymple, John Lamping and
Stanley Peters for very helpful discussions of this
material. Vineet Gupta, Martin Kay, Fernando
Pereira and four anonymous reviewers also provided
helpful comments on several points. All remaining
errors are naturally my own.
</bodyText>
<sectionHeader confidence="0.999161" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999890527272727">
Mary Dalrymple, John Lamping, and Vijay
Saraswat. 1993. LFG semantics via constraints.
In Proceedings of the 6th Meeting of the European
Association for Computational Linguistics, Uni-
versity of Utrecht, April.
Mary Dalrymple, John Lamping, Fernando Pereira,
and Vijay Saraswat. 1994. A deductive account
of quantification in LFG. In Makoto Kanazawa,
Christopher J. Piiion, and Henriette de Swart, ed-
itors, Quantifiers, Deduction, and Context. CSLI
Publications, Stanford, CA.
Mary Dalrymple, John Lamping, Fernando Pereira,
and Vijay Saraswat. To appear. Quantifiers,
anaphora, and intensionality. Journal of Logic,
Language and Information.
David Dowty. 1994. The role of negative polar-
ity and concord marking in natural language rea-
soning. In Mandy Harvey and Lynn Santelmann,
editors, Proceedings of SALT IV, pages 114-144,
Ithaca, NY. Cornell University.
Jean Gallier. 1992. Constructive logics. Part II:
Linear logic and proof nets. MS, Department of
Computer and Information Science, University of
Pennsylvania.
Jean-Yves Girard. 1987. Linear logic. Theoretical
Computer Science, 50.
Nirit Kadmon and Fred Landman. 1993. Any. Lin-
guistics and Philosophy 16, pages 353-422.
William A. Ladusaw. 1979. Polarity Sensitivity as
Inherent Scope Relations. Ph.D. thesis, University
of Texas, Austin. Reprinted in Jorge Hanlcamer,
editor, Outstanding Dissertations in Linguistics.
Garland, 1980.
Alain Lecomte and Christian Retore. 1995. Pom-
set logic as an alternative categorial grammar. In
Glyn V. Morrill and Richard T. Oehrle, editors,
Formal Grammar. Proceedings of the Conference
of the European Summer School in Logic, Lan-
guage, and Information, Barcelona.
Dale A. Miller. 1990. A logic programming language
with lambda abstraction, function variables and
simple unification. In Peter Schroeder-Heister, ed-
itor, Extensions of Logic Programming, Lecture
Notes in Artificial Intelligence. Springer-Verlag.
Glyn V. Morrill. 1996. Memoisation of categorial
proof nets: parallelism in categorial processing. In
V. Michele Abrusci and Claudia Casadio, editors,
Proceedings of the Roma Workshop on Proofs and
Linguistic Categories, Rome.
Victor Sanchez Valencia. 1991. Studies on Natu-
ral Logic and Categorial Grammar. Ph.D. thesis,
University of Amsterdam.
Victor Sanchez Valencia. 1995. Parsing-driven in-
ference: natural logic. Linguistic Analysis, 25(3-
4):258-285.
</reference>
<page confidence="0.998317">
150
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.999508">Negative Polarity Licensing at the Syntax-Semantics Interface</title>
<author confidence="0.999247">John Fry</author>
<affiliation confidence="0.999598666666667">Stanford University and Xerox PARC Dept. of Linguistics Stanford University</affiliation>
<address confidence="0.99981">Stanford, CA 94305-2150, USA</address>
<email confidence="0.999925">fry@csli.stanford.edu</email>
<abstract confidence="0.999021071038251">Recent work on the syntax-semantics interface (see e.g. (Dalrymple et al., 1994)) uses a fragment of linear logic as a &apos;glue language&apos; for assembling meanings compositionally. This paper presents a glue language account of how negative polarity items (e.g. ever, any) get licensed within the scope of negative or downward-entailing contexts (Ladusaw, e.g. ever left. treatment of licensing operates precisely at the syntax-semantics interface, since it is carried out entirely within the interface glue language (linear logic). In addition to the account of negative polarity licensing, we show in detail how linear-logic proof nets (Girard, 1987; Gallier, 1992) can be used for efficient meaning deduction within this &apos;glue language&apos; framework. 1 Background A recent strain of research on the interface between syntax and semantics, starting with (Dalrymple et al., 1993), uses a fragment of linear logic as a &apos;glue language&apos; for assembling the meaning of a sentence compositionally. In this approach, meaning assembly is guided not by a syntactic constituent tree but rather by the flatter functional structure (the LFG the sentence. As a brief review of this approach, consider sentence (1): (1) Everyone left. FRED &apos;LEAVE&apos; &apos;EVERYONE&apos; Each word in the sentence is associated with a constructor&apos; template, specified in the lexicon; these meaning constructors are then instantiated with values from the f-structure. For sentence (1), this produces two premises of the linear logic glue language: -0 every (person, S) —4) the the higher-order variable over the possible scope meanings of the with lower-case as a traditional first-order variable &amp;quot;placeholder&amp;quot; within the scope. over LFG structures corresponding to the meaning of the entire generalized quantifier.&apos; meaning for be derived by applying the linear version of modus ponens, during which classical logic) the first premise the second premise deducalong with the substitutions 1-4 X 1-4 x 1-4 Ax.leave(x), the final meanevery Ax.leave(x)), is in this simple case the only reading for the sentence. One advantage of this deductive style of meaning assembly is that it provides an elegant account of quantifier scoping: each possible scope has a corresponding proof, obviating the need for quantifier storage. 2 Meaning deduction via proof nets net 1987) is an undirected, connected graph whose node labels are propositions. A &apos;Here we have simplified the notation of Dalrymple somewhat, for example by stripping away the universal quantifier operators from the variables. In this regard, note that the lower-case variables stand for arbitrary constants rather than particular terms, and generally are given limited scope within the antecedent of the premise. Upper-case variables are Prolog-like variables that become instantiated to specific terms within the proof, and generally their scope is the entire premise. 144 1: Proof net for left. z)&apos;S(x)) every (person, X S(x)) every (person, X 0 (fes--.t leave(X))± fe•-■t M theorem of multiplicative linear logic corresponds to only one proof net; thus the manipulation of proof nets is more efficient than sequent deduction, in which the same theorem might have different proofs corresponding to different orderings of the inference steps. A further advantage of proof nets for our purposes is that an invalid meaning deduction, e.g. one corresponding to some spurious scope reading of a particular sentence, can be illustrated by exhibiting its defective graph which demonstrates visually why no proof exists for it. Proof net techniques have also been exploited within the categorial grammar community, for example for reasons of efficiency (Morrill, 1996) and in order to give logical descriptions of certain syntactic phenomena (Lecomte and Retore, 1995). In this section we construct a proof net from the premises for sentence (1), showing how to apply higher-order unification to the meaning terms in the We then review the algorithm of Gallier (1992) for propositional (multiplicative) linear logic which checks whether a given proof net is valid, i.e. corresponds to a proof. The complete process for assembling a meaning from its premises will be shown in four steps: (1) rewrite the premises in a normalized form, (2) assemble the premises into a graph, (3) connect together the positive (&amp;quot;producer&amp;quot;) and negative (&amp;quot;consumer&amp;quot;) meaning terms, unifying them in the process, and (4) test whether the resulting graph encodes a proof. 2.1 Step 1: set up the sequent Since our goal is to derive, from the premises of sen- (1), a meaning the f-structure the entire sentence, what we seek is a proof of the form left I- M. Glue language semantics has so far been restricted the of linear logic, which uses only the multiplicative conjunction operator the linear implication operator —0. The same fragment is obtained by replacing —0 with the operators and I, where It (par) is the multiplicative &apos;or&apos; and I is linear negation and B) B). the version out —0, we normalize two sided sequents of the form H ,B, right-sided sequents the form H , , , sequent representations of this style, the comma represents 0 on the left side of the sequent and on the right side.) In our new format, then, the proof takes the form everyone&apos;, left&amp;quot;, The proof net further requires that sequents be in negation normal form, in which negation is applied to atomic Moving the negations inward (the usual double-negation and &apos;de Morgan&apos; properties hold), and displaying the full premises, we obtain the normalized sequent S (x)) every(per son, X 0 ( tleave(X))- , 2.2 Step 2: create the graph The next step is to create a graph whose nodes consist of all the terms which occur in the sequent. That a node is created for each literal for each negated literal CI; a node is created for each comterm A 0 A II nodes are also for its subterms A and for each of the form A draw a soft edge in the form of a horizontal dashed line connecting it to A and each node of the form A 0 , draw a hard edge (solid line) connecting it to nodes and the example at hand, this produces the graph in Figure 1 (ignoring the curved edges at the top). notation Gallier&apos;s (1992). that we refer to noncompound terms as &apos;literal&apos; or &apos;atomic&apos; terms because they are atomic from the point of view of the glue language, even though these terms in fact of the form M, an expression LFG structures and a type-r expression in the meaning language. 145 2.3 Step 3: connect the literals The final step in assembling the proof net is to connect together the literal nodes at the top of the graph. It is at this stage that unification is applied to the variables in order to assign them the values they will assume in the final meaning. Each different way of connecting the literals and instantiating their variables corresponds to a different reading for the sentence. For each literal, we draw an edge connecting it to a matching literal of opposite sign; i.e. each literal A connected to a literal where A unifies with Every literal in the graph must be connected in this way. If for some literal A there exists no matching opposite sign then the graph does not encode a proof and the algorithm fails. In this process the unifications apply to whole exof the form M, both variables over LFG structures and variables over meaning terms. For the meaning terms, this requires a limited higher-order unification scheme that prothe unifier a second-order term a first-order term noted by Dalrymple al. appear), all the apparatus that is required for their simple intensional meaning language falls within the decidable /A fragment of Miller (1990), and therefore can be implemented as an extension of a first-order unification scheme such as that of Prolog. For the example at hand, there is only one way to connect the literals (and hence at most one reading for the sentence), as shown in Figure 1. At this stage, the unifications would bind the variin Figure 1 as follows: 1-+ x, H 1-4 every(person,Ax.leave(x)). 2.4 Step 4: test the graph for validity Finally, we apply Gallier&apos;s (1992) algorithm to the connected graph in order to check that it corresponds to a proof. This algorithm recursively decomposes the graph from the bottom up while checking for cycles. Here we present the algorithm inforfor proofs of its correctness and complexity see (Gallier, 1992). the graph consists of a single link beliterals A and the algorithm succeeds and the graph corresponds to a proof. case 1: the decomposition by deleting the bottom-level par nodes. If there is some node A It to higher nodes A A of course eliminates the edge from A tt A and to does not nodes A and run the algorithm on the resulting smaller (possibly unconnected) graph. case 2: if no terminal par node is available, find a terminal tensor node to delete. This case is more complicated because not every way of deleting a tensor node necessarily leads to success, even for a valid proof net. Just choose terminal tensor node A 0 deleting that node results in a single, connected (i.e. cyclic) graph, then that node was not a valid splitting tensor and a different one must be chosen instead, or else halt with failure if none is available. Otherwise, delete 0 leaves nodes A and to two unconnected graphs Cl and G2. Then run the algorithm on Cl and G2. This process will be demonstrated in the examples which follow. 3 A glue language treatment of NPI licensing Ladusaw (1979) established what is now a wellknown generalization in semantics, namely that negative polarity lexical items (NPI&apos;s, e.g. any, ever) are licensed within the scope of downward-entailing (e.g. For example, the NPI ever felicitously in a context like one ever left not in ever left.&apos; showed that the status of a lexical item as a NPI or licenser depends on its meaning; i.e. on semantic rather than syntactic or lexical properties. On the other hand, the requirement that NPI&apos;s be licensed in order to appear felicitously in a sentence is a constraint on surface syntactic form. So the domain of NPI liis really the syntax and semantics, where meanings are composed under syntactic guidance. This section gives an implementation of NPI licensing at the syntax-semantics interface using glue language. No separate proof or interpretation apparatus is required, only modification of the relevant meaning constructors specified in the lexicon. 3.1 Meaning constructors for NPI&apos;s There is a resource-based interpretation of the NPI licensing problem: the negative or decreasing licensoperator must make available a resource, call it which will license the NPI&apos;s, if any, within its scope. If no such resource is made available the NPI&apos;s are unlicensed and the sentence is rejected. consider only &apos;rightward&apos; licensing (within the scope of the quantifier), but this approach applies equally well to &apos;leftward&apos; licensing (within the restriction). 146 P tCfo&amp;quot;...t 0 t if 9.-.....Y sing(n)i (f„....., P 0£) ((f....&amp;quot;t a 2: Invalid proof net of *Al yet. NPI&apos;s must be made to require the The way one implements such a requirement in linear logic is to put the required resource on the left side of the implication operator —o. This is precisely our approach. However, since the NPI is just &apos;borrowing&apos; the license, not consuming it (after all, more one NPI may be licensed, as in one ever anyone), also add the resource to the right hand side of the implication. That is, for a meanconstructor of the form A can make a corresponding NPI meaning constructor of the form 0 t). For example, the meaning constructor proposed in (Dalrymple et al., 1993) for the sentential modifier obviously: P —0 obviously (P). Under this analysis of sentential modification, NPI such as take the same form, but with the licensing apparatus added: 0 0 t). This technique can be readily applied to the other categories of NPI as well. In the case of the NPI phrase the licensing apparatus is added to the earlier template for everyone to produce the meaning constructor (g--exS(x) 0 t&apos;) only function of the inside an is to consume the resource then produce it again. However, for this to happen, the resource have to be generated by some licenser whose scope includes the NPI, as we show below. If no is made available, then the extraunconsumed in the NPI guarantees that no proof will be generated. In proof net terms, &apos;Any also has another, so-called &apos;free choice&apos; inter- (as in e.g. will do) 1979; Kadmon and Landman, 1993), which we ignore here. output feed back into the input without producing a cycle. We now demonstrate how the deduction is blocked for a sentence containing an unlicensed NPI such as (2). (2) *Al sang yet. f: PRED &apos;SING&apos; &apos;AL&apos;] } SUBJ [ MODS [ The relevant premises are Al —0 sing(Y) 0 0 —° 0 t) The graph of (2), shown in Figure 2, does not encode a proof. The reason is shown in Figure 3. At this point in the algorithm, we have deleted the leftmost terminal tensor node. However, the only remaining terminal tensor node cannot be deleted, since doing so would produce a single connected subgraph; the is in the edge from At this point the algorithm fails and no meaning is derived. 3.2 Meaning constructors for NPI licensers It is clear from the proposal so far that lexical items license NPI&apos;s must make available a within their scope which can be consumed by the NPI. However, that is not enough; a licenser can still occur inside a sentence without an NPI, as in one left. resource accounting of linear logic requires that we &apos;clean up&apos; by consuming any excess resources in order for the meaning deduction to go through. Fortunately, we can solve this problem within the licenser&apos;s meaning constructor itself. For a lexical category whose meaning constructor is of the form assign to the NPI licensers of that category the meaning constructor (A 0 B. By its logical structure, being embedded inside another implication, the inner implication here serves 147 P 0 I P ((f.&amp;quot;-.4 Figure 3: Point of failure. Bottom tensor node cannot be deleted. to introduce &apos;hypothetical&apos; material. All of the NPI licensing occurs within the hypothetical (left) side the outermost implication. Since the is made available to the NPI only within this hypothetical, it is guaranteed that the NPI is assembled within, and therefore falls under, the scope of the licenser. Furthermore, the formula is &apos;self cleaning&apos;, in that the resource, even if not used by an NPI, does not survive the hypothetical and so cannot affect the meaning of the licenser in some other way. That is, licensing constructor (A 0 B can derive all of the same meanings as the nonlicensing A B. Fact 1 (l-o(A 1))-oB A-oB We the proof net of the equivalent right-sided sequent 0 (A 0 and then test that it is valid.</abstract>
<note confidence="0.6278285">A Aet (A 0 (A 0</note>
<title confidence="0.948478">A A P CA t</title>
<author confidence="0.928227">B Al</author>
<abstract confidence="0.98339684">I A 0 This self-cleaning property means that a licensing resource is exactly that—a license. Within the scope of the licenser, the is available to be used once, several times (in a &amp;quot;chain&amp;quot; of NPI&apos;s which pass along), or not at all, as A simple example is provided by the NPI-licensing adverb rarely. We modify our sentential adverb template to create a meaning constructor for rarely which licenses an NPI within the sentence it modifies. P I)) -o case of licensing quantifier phrases such students the same pattern. example, the form I) -0 SW I)) no (person, S). We can now derive a meaning for sentence (3), in the roles of licenser and NPI, respectively. (3) Nobody saw anyone. [PRED &apos;SEE&apos; SUBJ &apos;NOBODY&apos;] &apos;ANYONE&apos;] Normally, a sentence with two quantifiers would generate two different scope readings—in this case, (4) and (5). no(person, any Ay .see(x, y))) (5) any(person, )ty. Ax.see(x, However, Ladusaw&apos;s generalization is that NPI&apos;s licensed the scope their licensers. In fact, the semantics of any prevent it from taking wide scope in such a case (Kadmon and Landman, 1993; Ladusaw, 1979, p. 96-101). Our analysis, then, should derive (4) but block (5). multiple-use effect can be achieved more directly using the exponential operator!; however this unnecessary step would take us outside of the multiplicative fragment of linear logic and preclude the proof net techniques described earlier. 148 The premises are 0 t) -0 (H-s-4 t5(x) t)) no(person, S) 0 -0 -0 t) any(person, t) proof net for reading (4) is shown in Figure As required, the net in Figure 4, corresponding to scope for valid. The first step in the proof of Figure 4 is to delete the only available splitting tensor, which is boxed in the figure. A second way of linking the positive and negative literals in Figure 4 produces a net which corresponds to (5), the spurious reading in which any has wide scope. In that graph, however, all three of the available terminal tensor nodes produce a single, connected (cyclic) graph if deleted, so decomposition cannot even begin and the algorithm fails. Once again, it is the licensing resources which are enforcing the desired constraint. 4 Categorial grammar approaches used here is somewhat analogous to the (negative) lexical `monotonicity markers&apos; proposed by Sanchez Valencia (1991; 1995) and Dowty (1994) for categorial grammar. In these approaches, cateof the form B marked with monotonicproperties, i.e. as I , similarly for left-leaning categories of form monotonicity constraints can be enforced using category assignments like the following from (Dowty, 1994): IV 1 no. IV P+)IC N+ IV IV Sanchez Valencia and Dowty, however, are less concerned with the distribution of NPI&apos;s than they are with using monotonicity properties to characterize valid inference patterns, an issue which we have here. Hence their work emphasizes polarity, where an odd number of negative marks indicates negative polarity, and an even number of negatives cancel each other to produce positive po- For example, the category of &amp;quot;flips&amp;quot; the polarity of its argument. By contrast, our system, like Ladusaw&apos;s (1979) original proposal, is what Dowty (1994, p. 134-137) would call &amp;quot;intuitionistic&amp;quot;: have been stripped from the formulas in order to save space in the diagram. 149 since multiple negative contexts do not cancel each other out, we permit doubly-licensed NPI&apos;s as in anyone. handle such cases, while at the same time accounting for monotonic inference properties, Dowty (1994) proposes a doublemarking framework whereby categories like A::/B+ are masked for both logical polarity and syntactic polarity. 5 Conclusion We have elaborated on and extended slightly the &apos;glue language&apos; approach to semantics of Dalrymple al. was shown how linear logic proof nets can be used for efficient natural-language meaning deductions in this framework. We then presented a glue language treatment of negative polarity licensing which ensures that NPI&apos;s are licensed within the semantic scope of their licensers, following (Ladusaw, 1979). This system uses no new global rules or features, nor ambiguous lexical entries, but only the addition of L&apos;s to the relevant items within the lexicon. The licensing takes place precisely at the syntax-semantics interface, since it is implemented entirely in the interface glue language. Finally, we noted briefly some similarities and differences between this system and categorial grammar &apos;monotonicity marking&apos; approaches. 6 Acknowledgements I&apos;m grateful to Mary Dalrymple, John Lamping and Stanley Peters for very helpful discussions of this material. Vineet Gupta, Martin Kay, Fernando Pereira and four anonymous reviewers also provided helpful comments on several points. All remaining errors are naturally my own.</abstract>
<note confidence="0.408467666666667">References Mary Dalrymple, John Lamping, and Vijay Saraswat. 1993. LFG semantics via constraints. of the 6th Meeting of the European for Computational Linguistics, University of Utrecht, April.</note>
<author confidence="0.7445075">A deductive account</author>
<affiliation confidence="0.440433">of quantification in LFG. In Makoto Kanazawa,</affiliation>
<address confidence="0.20853">Christopher J. Piiion, and Henriette de Swart, ed-</address>
<note confidence="0.603316">Deduction, and Context. Publications, Stanford, CA.</note>
<author confidence="0.997756">Mary Dalrymple</author>
<author confidence="0.997756">John Lamping</author>
<author confidence="0.997756">Fernando Pereira</author>
<affiliation confidence="0.752868">and Vijay Saraswat. To appear. Quantifiers, and intensionality. of Logic,</affiliation>
<title confidence="0.795109">Language and Information.</title>
<author confidence="0.606865666666667">The role of negative polarity</author>
<author confidence="0.606865666666667">concord marking in natural language reasoning In Mandy Harvey</author>
<author confidence="0.606865666666667">Lynn Santelmann</author>
<address confidence="0.678299333333333">of SALT IV, 114-144, Ithaca, NY. Cornell University. Jean Gallier. 1992. Constructive logics. Part II:</address>
<note confidence="0.784461542857143">Linear logic and proof nets. MS, Department of Computer and Information Science, University of Pennsylvania. Girard. 1987. Linear logic. Science, Kadmon and Fred Landman. 1993. Any. Linand Philosophy 16, 353-422. A. Ladusaw. 1979. Sensitivity as Scope Relations. thesis, University of Texas, Austin. Reprinted in Jorge Hanlcamer, Dissertations in Linguistics. Garland, 1980. Alain Lecomte and Christian Retore. 1995. Pomset logic as an alternative categorial grammar. In Glyn V. Morrill and Richard T. Oehrle, editors, Proceedings of the Conference of the European Summer School in Logic, Language, and Information, Barcelona. Dale A. Miller. 1990. A logic programming language with lambda abstraction, function variables and simple unification. In Peter Schroeder-Heister, edof Logic Programming, Notes in Artificial Intelligence. Springer-Verlag. Glyn V. Morrill. 1996. Memoisation of categorial proof nets: parallelism in categorial processing. In V. Michele Abrusci and Claudia Casadio, editors, Proceedings of the Roma Workshop on Proofs and Categories, Sanchez Valencia. 1991. on Natu- Logic and Categorial Ph.D. thesis, University of Amsterdam. Victor Sanchez Valencia. 1995. Parsing-driven innatural logic. Analysis, 4):258-285. 150</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mary Dalrymple</author>
<author>John Lamping</author>
<author>Vijay Saraswat</author>
</authors>
<title>LFG semantics via constraints.</title>
<date>1993</date>
<booktitle>In Proceedings of the 6th Meeting of the European Association</booktitle>
<institution>for Computational Linguistics, University of Utrecht,</institution>
<contexts>
<context position="1098" citStr="Dalrymple et al., 1993" startWordPosition="158" endWordPosition="161">get licensed within the scope of negative or downward-entailing contexts (Ladusaw, 1979), e.g. Nobody ever left. This treatment of licensing operates precisely at the syntax-semantics interface, since it is carried out entirely within the interface glue language (linear logic). In addition to the account of negative polarity licensing, we show in detail how linear-logic proof nets (Girard, 1987; Gallier, 1992) can be used for efficient meaning deduction within this &apos;glue language&apos; framework. 1 Background A recent strain of research on the interface between syntax and semantics, starting with (Dalrymple et al., 1993), uses a fragment of linear logic as a &apos;glue language&apos; for assembling the meaning of a sentence compositionally. In this approach, meaning assembly is guided not by a syntactic constituent tree but rather by the flatter functional structure (the LFG f-structure) of the sentence. As a brief review of this approach, consider sentence (1): (1) Everyone left. FRED &apos;LEAVE&apos; f: SUB.) g:[FRED &apos;EVERYONE&apos; Each word in the sentence is associated with a &apos;meaning constructor&apos; template, specified in the lexicon; these meaning constructors are then instantiated with values from the f-structure. For sentence </context>
<context position="13103" citStr="Dalrymple et al., 1993" startWordPosition="2238" endWordPosition="2241">equire the t resource. The way one implements such a requirement in linear logic is to put the required resource on the left side of the implication operator —o. This is precisely our approach. However, since the NPI is just &apos;borrowing&apos; the license, not consuming it (after all, more than one NPI may be licensed, as in No one ever saw anyone), we also add the resource to the right hand side of the implication. That is, for a meaning constructor of the form A —o B, we can make a corresponding NPI meaning constructor of the form (A 0 t) —0 (B t). For example, the meaning constructor proposed in (Dalrymple et al., 1993) for the sentential modifier obviously is obviously: f P —0 fu&apos;••-■g obviously (P). Under this analysis of sentential modification, NPI adverbs such as yet or ever would take the same form, but with the licensing apparatus added: ever: (fa^-qP 0 0 —0 (f&apos;-*t ever(P) t). This technique can be readily applied to the other categories of NPI as well. In the case of the NPI quantifier phrase anyone5 the licensing apparatus is added to the earlier template for everyone to produce the meaning constructor anyone: (g--ex —0 .11^-+t S(x) 0 t&apos;) —0 any(person, S) 0 t). The only function of the t --0 t patt</context>
</contexts>
<marker>Dalrymple, Lamping, Saraswat, 1993</marker>
<rawString>Mary Dalrymple, John Lamping, and Vijay Saraswat. 1993. LFG semantics via constraints. In Proceedings of the 6th Meeting of the European Association for Computational Linguistics, University of Utrecht, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Dalrymple</author>
<author>John Lamping</author>
<author>Fernando Pereira</author>
<author>Vijay Saraswat</author>
</authors>
<title>A deductive account of quantification</title>
<date>1994</date>
<editor>in LFG. In Makoto Kanazawa, Christopher J. Piiion, and Henriette de Swart, editors, Quantifiers, Deduction, and Context.</editor>
<publisher>CSLI Publications,</publisher>
<location>Stanford, CA.</location>
<marker>Dalrymple, Lamping, Pereira, Saraswat, 1994</marker>
<rawString>Mary Dalrymple, John Lamping, Fernando Pereira, and Vijay Saraswat. 1994. A deductive account of quantification in LFG. In Makoto Kanazawa, Christopher J. Piiion, and Henriette de Swart, editors, Quantifiers, Deduction, and Context. CSLI Publications, Stanford, CA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Mary Dalrymple</author>
<author>John Lamping</author>
<author>Fernando Pereira</author>
<author>Vijay Saraswat</author>
</authors>
<title>To appear. Quantifiers, anaphora, and intensionality.</title>
<journal>Journal of Logic, Language and Information.</journal>
<marker>Dalrymple, Lamping, Pereira, Saraswat, </marker>
<rawString>Mary Dalrymple, John Lamping, Fernando Pereira, and Vijay Saraswat. To appear. Quantifiers, anaphora, and intensionality. Journal of Logic, Language and Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Dowty</author>
</authors>
<title>The role of negative polarity and concord marking in natural language reasoning.</title>
<date>1994</date>
<booktitle>Proceedings of SALT IV,</booktitle>
<pages>114--144</pages>
<editor>In Mandy Harvey and Lynn Santelmann, editors,</editor>
<publisher>Cornell University.</publisher>
<location>Ithaca, NY.</location>
<contexts>
<context position="19579" citStr="Dowty (1994)" startWordPosition="3382" endWordPosition="3383">nd way of linking the positive and negative literals in Figure 4 produces a net which corresponds to (5), the spurious reading in which any has wide scope. In that graph, however, all three of the available terminal tensor nodes produce a single, connected (cyclic) graph if deleted, so decomposition cannot even begin and the algorithm fails. Once again, it is the licensing resources which are enforcing the desired constraint. 4 Categorial grammar approaches The t atom used here is somewhat analogous to the (negative) lexical `monotonicity markers&apos; proposed by Sanchez Valencia (1991; 1995) and Dowty (1994) for categorial grammar. In these approaches, categories of the form AI B are marked with monotonicity properties, i.e. as AIB, A+IB-,A-1B+, or A- I B- , and similarly for left-leaning categories of the form A\B. Then monotonicity constraints can be enforced using category assignments like the following from (Dowty, 1994): f (S+ IV P-)ICN- 1 no. 1 (S- IV P+)IC N+ f any: (S- IV P-)ICNever: V P- IV PSanchez Valencia and Dowty, however, are less concerned with the distribution of NPI&apos;s than they are with using monotonicity properties to characterize valid inference patterns, an issue which we hav</context>
<context position="20920" citStr="Dowty (1994)" startWordPosition="3605" endWordPosition="3606">and an even number of negatives cancel each other to produce positive polarity. For example, the category of no above &amp;quot;flips&amp;quot; the polarity of its argument. By contrast, our system, like Ladusaw&apos;s (1979) original proposal, is what Dowty (1994, p. 134-137) would call &amp;quot;intuitionistic&amp;quot;: 7The subscripts have been stripped from the formulas in order to save space in the diagram. 149 since multiple negative contexts do not cancel each other out, we permit doubly-licensed NPI&apos;s as in Nobody rarely sees anyone. To handle such cases, while at the same time accounting for monotonic inference properties, Dowty (1994) proposes a doublemarking framework whereby categories like A::/B+ are masked for both logical polarity and syntactic polarity. 5 Conclusion We have elaborated on and extended slightly the &apos;glue language&apos; approach to semantics of Dalrymple et al. It was shown how linear logic proof nets can be used for efficient natural-language meaning deductions in this framework. We then presented a glue language treatment of negative polarity licensing which ensures that NPI&apos;s are licensed within the semantic scope of their licensers, following (Ladusaw, 1979). This system uses no new global rules or featu</context>
</contexts>
<marker>Dowty, 1994</marker>
<rawString>David Dowty. 1994. The role of negative polarity and concord marking in natural language reasoning. In Mandy Harvey and Lynn Santelmann, editors, Proceedings of SALT IV, pages 114-144, Ithaca, NY. Cornell University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Gallier</author>
</authors>
<title>Constructive logics. Part II: Linear logic and proof nets.</title>
<date>1992</date>
<tech>MS,</tech>
<institution>Department of Computer and Information Science, University of Pennsylvania.</institution>
<contexts>
<context position="888" citStr="Gallier, 1992" startWordPosition="128" endWordPosition="129">et al., 1994)) uses a fragment of linear logic as a &apos;glue language&apos; for assembling meanings compositionally. This paper presents a glue language account of how negative polarity items (e.g. ever, any) get licensed within the scope of negative or downward-entailing contexts (Ladusaw, 1979), e.g. Nobody ever left. This treatment of licensing operates precisely at the syntax-semantics interface, since it is carried out entirely within the interface glue language (linear logic). In addition to the account of negative polarity licensing, we show in detail how linear-logic proof nets (Girard, 1987; Gallier, 1992) can be used for efficient meaning deduction within this &apos;glue language&apos; framework. 1 Background A recent strain of research on the interface between syntax and semantics, starting with (Dalrymple et al., 1993), uses a fragment of linear logic as a &apos;glue language&apos; for assembling the meaning of a sentence compositionally. In this approach, meaning assembly is guided not by a syntactic constituent tree but rather by the flatter functional structure (the LFG f-structure) of the sentence. As a brief review of this approach, consider sentence (1): (1) Everyone left. FRED &apos;LEAVE&apos; f: SUB.) g:[FRED &apos;E</context>
<context position="4611" citStr="Gallier (1992)" startWordPosition="719" endWordPosition="720">e spurious scope reading of a particular sentence, can be illustrated by exhibiting its defective graph which demonstrates visually why no proof exists for it. Proof net techniques have also been exploited within the categorial grammar community, for example for reasons of efficiency (Morrill, 1996) and in order to give logical descriptions of certain syntactic phenomena (Lecomte and Retore, 1995). In this section we construct a proof net from the premises for sentence (1), showing how to apply higher-order unification to the meaning terms in the process. We then review the 0(n2) algorithm of Gallier (1992) for propositional (multiplicative) linear logic which checks whether a given proof net is valid, i.e. corresponds to a proof. The complete process for assembling a meaning from its premises will be shown in four steps: (1) rewrite the premises in a normalized form, (2) assemble the premises into a graph, (3) connect together the positive (&amp;quot;producer&amp;quot;) and negative (&amp;quot;consumer&amp;quot;) meaning terms, unifying them in the process, and (4) test whether the resulting graph encodes a proof. 2.1 Step 1: set up the sequent Since our goal is to derive, from the premises of sentence (1), a meaning M for the f-</context>
<context position="9421" citStr="Gallier, 1992" startWordPosition="1598" endWordPosition="1599"> to connect the literals (and hence at most one reading for the sentence), as shown in Figure 1. At this stage, the unifications would bind the variables in Figure 1 as follows: X 1-+ x, H 1-4 fa, S Ax.leave(x), M 1-4 every(person,Ax.leave(x)). 2.4 Step 4: test the graph for validity Finally, we apply Gallier&apos;s (1992) algorithm to the connected graph in order to check that it corresponds to a proof. This algorithm recursively decomposes the graph from the bottom up while checking for cycles. Here we present the algorithm informally; for proofs of its correctness and 0(n2) time complexity see (Gallier, 1992). Base case: If the graph consists of a single link between literals A and A1, the algorithm succeeds and the graph corresponds to a proof. Recursive case 1: Begin the decomposition by deleting the bottom-level par nodes. If there is some terminal node A It B connected to higher nodes A and B, delete A B. This of course eliminates the dashed edge from A tt B to A and to B, but does not remove nodes A and B. Then run the algorithm on the resulting smaller (possibly unconnected) graph. Recursive case 2: Otherwise, if no terminal par node is available, find a terminal tensor node to delete. This </context>
</contexts>
<marker>Gallier, 1992</marker>
<rawString>Jean Gallier. 1992. Constructive logics. Part II: Linear logic and proof nets. MS, Department of Computer and Information Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean-Yves Girard</author>
</authors>
<title>Linear logic.</title>
<date>1987</date>
<journal>Theoretical Computer Science,</journal>
<volume>50</volume>
<contexts>
<context position="872" citStr="Girard, 1987" startWordPosition="126" endWordPosition="127">g. (Dalrymple et al., 1994)) uses a fragment of linear logic as a &apos;glue language&apos; for assembling meanings compositionally. This paper presents a glue language account of how negative polarity items (e.g. ever, any) get licensed within the scope of negative or downward-entailing contexts (Ladusaw, 1979), e.g. Nobody ever left. This treatment of licensing operates precisely at the syntax-semantics interface, since it is carried out entirely within the interface glue language (linear logic). In addition to the account of negative polarity licensing, we show in detail how linear-logic proof nets (Girard, 1987; Gallier, 1992) can be used for efficient meaning deduction within this &apos;glue language&apos; framework. 1 Background A recent strain of research on the interface between syntax and semantics, starting with (Dalrymple et al., 1993), uses a fragment of linear logic as a &apos;glue language&apos; for assembling the meaning of a sentence compositionally. In this approach, meaning assembly is guided not by a syntactic constituent tree but rather by the flatter functional structure (the LFG f-structure) of the sentence. As a brief review of this approach, consider sentence (1): (1) Everyone left. FRED &apos;LEAVE&apos; f: </context>
<context position="2834" citStr="Girard, 1987" startWordPosition="437" endWordPosition="438">r version of modus ponens, during which (unlike classical logic) the first premise everyone &amp;quot;consumes&amp;quot; the second premise left. This deduction, along with the substitutions H 1-4 fe,, X 1-4 x and S 1-4 Ax.leave(x), produces the final meaning f,-.4t every (person, Ax.leave(x)), which is in this simple case the only reading for the sentence. One advantage of this deductive style of meaning assembly is that it provides an elegant account of quantifier scoping: each possible scope has a corresponding proof, obviating the need for quantifier storage. 2 Meaning deduction via proof nets A proof net (Girard, 1987) is an undirected, connected graph whose node labels are propositions. A &apos;Here we have simplified the notation of Dalrymple et al. somewhat, for example by stripping away the universal quantifier operators from the variables. In this regard, note that the lower-case variables stand for arbitrary constants rather than particular terms, and generally are given limited scope within the antecedent of the premise. Upper-case variables are Prolog-like variables that become instantiated to specific terms within the proof, and generally their scope is the entire premise. 144 Figure 1: Proof net for Ev</context>
</contexts>
<marker>Girard, 1987</marker>
<rawString>Jean-Yves Girard. 1987. Linear logic. Theoretical Computer Science, 50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nirit Kadmon</author>
<author>Fred Landman</author>
</authors>
<date>1993</date>
<journal>Any. Linguistics and Philosophy</journal>
<volume>16</volume>
<pages>353--422</pages>
<contexts>
<context position="14205" citStr="Kadmon and Landman, 1993" startWordPosition="2433" endWordPosition="2436"> the meaning constructor anyone: (g--ex —0 .11^-+t S(x) 0 t&apos;) —0 any(person, S) 0 t). The only function of the t --0 t pattern inside an NPI is to consume the resource t and then produce it again. However, for this to happen, the resource t will have to be generated by some licenser whose scope includes the NPI, as we show below. If no outside t resource is made available, then the extraneous, unconsumed t material in the NPI guarantees that no proof will be generated. In proof net terms, &apos;Any also has another, so-called &apos;free choice&apos; interpretation (as in e.g. Anyone will do) (Ladusaw, 1979; Kadmon and Landman, 1993), which we ignore here. the output / cannot feed back into the input t without producing a cycle. We now demonstrate how the deduction is blocked for a sentence containing an unlicensed NPI such as (2). (2) *Al sang yet. f: PRED &apos;SING&apos; &apos;AL&apos;] SUBJ g: [ PRED &apos;YET&apos; ] } MODS { [ PRED [ The relevant premises are Al: go&amp;quot;-■, Al sang: 9,7&amp;quot;-*eY —0 sing(Y) yet: (f7^-4iP 0 0 —° (fcr-s-4tYet(P) 0 t) The graph of (2), shown in Figure 2, does not encode a proof. The reason is shown in Figure 3. At this point in the algorithm, we have deleted the leftmost terminal tensor node. However, the only remaining ter</context>
<context position="18187" citStr="Kadmon and Landman, 1993" startWordPosition="3144" endWordPosition="3147"> derive a meaning for sentence (3), in which nobody and anyone play the roles of licenser and NPI, respectively. (3) Nobody saw anyone. [PRED &apos;SEE&apos; f: SUBJ g:[ PRED &apos;NOBODY&apos;] OBJ h:[ PRED &apos;ANYONE&apos;] Normally, a sentence with two quantifiers would generate two different scope readings—in this case, (4) and (5). (4) f(,-,4t no(person, )x. any (person, Ay .see(x, y))) (5) icr^-4t any(person, )ty. no(person, Ax.see(x, y))) However, Ladusaw&apos;s generalization is that NPI&apos;s are licensed within the scope of their licensers. In fact, the semantics of any prevent it from taking wide scope in such a case (Kadmon and Landman, 1993; Ladusaw, 1979, p. 96-101). Our analysis, then, should derive (4) but block (5). 6This multiple-use effect can be achieved more directly using the exponential operator!; however this unnecessary step would take us outside of the multiplicative fragment of linear logic and preclude the proof net techniques described earlier. 148 The premises are nobody: ((gc,-•-■ex 0 t) -0 (H-s-4 t 5(x) t)) -0 H-s-+t no(person, S) saw: (ger&apos;s-4e X 0 hcf-&apos;4e Y) -0 fq--&gt;tsee(X,Y) anyone: y -0 .1&amp;quot;4tT(Y) t) --0 (.1,4t any(person, T) t) The proof net for reading (4) is shown in Figure 4.7 As required, the net in Fi</context>
</contexts>
<marker>Kadmon, Landman, 1993</marker>
<rawString>Nirit Kadmon and Fred Landman. 1993. Any. Linguistics and Philosophy 16, pages 353-422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Ladusaw</author>
</authors>
<title>Polarity Sensitivity as Inherent Scope Relations.</title>
<date>1979</date>
<booktitle>Outstanding Dissertations in Linguistics.</booktitle>
<tech>Ph.D. thesis,</tech>
<editor>Jorge Hanlcamer, editor,</editor>
<publisher>Garland,</publisher>
<institution>University of Texas, Austin.</institution>
<note>Reprinted in</note>
<contexts>
<context position="10670" citStr="Ladusaw (1979)" startWordPosition="1826" endWordPosition="1827">t every way of deleting a tensor node necessarily leads to success, even for a valid proof net. Just choose some terminal tensor node A 0 B. If deleting that node results in a single, connected (i.e. cyclic) graph, then that node was not a valid splitting tensor and a different one must be chosen instead, or else halt with failure if none is available. Otherwise, delete A 0 B, which leaves nodes A and B belonging to two unconnected graphs Cl and G2. Then run the algorithm on Cl and G2. This process will be demonstrated in the examples which follow. 3 A glue language treatment of NPI licensing Ladusaw (1979) established what is now a wellknown generalization in semantics, namely that negative polarity lexical items (NPI&apos;s, e.g. any, ever) are licensed within the scope of downward-entailing operators (e.g. no, few). For example, the NPI ever occurs felicitously in a context like No one ever left but not in *John ever left.&apos; Laclusaw showed that the status of a lexical item as a NPI or licenser depends on its meaning; i.e. on semantic rather than syntactic or lexical properties. On the other hand, the requirement that NPI&apos;s be licensed in order to appear felicitously in a sentence is a constraint o</context>
<context position="14178" citStr="Ladusaw, 1979" startWordPosition="2431" endWordPosition="2432">yone to produce the meaning constructor anyone: (g--ex —0 .11^-+t S(x) 0 t&apos;) —0 any(person, S) 0 t). The only function of the t --0 t pattern inside an NPI is to consume the resource t and then produce it again. However, for this to happen, the resource t will have to be generated by some licenser whose scope includes the NPI, as we show below. If no outside t resource is made available, then the extraneous, unconsumed t material in the NPI guarantees that no proof will be generated. In proof net terms, &apos;Any also has another, so-called &apos;free choice&apos; interpretation (as in e.g. Anyone will do) (Ladusaw, 1979; Kadmon and Landman, 1993), which we ignore here. the output / cannot feed back into the input t without producing a cycle. We now demonstrate how the deduction is blocked for a sentence containing an unlicensed NPI such as (2). (2) *Al sang yet. f: PRED &apos;SING&apos; &apos;AL&apos;] SUBJ g: [ PRED &apos;YET&apos; ] } MODS { [ PRED [ The relevant premises are Al: go&amp;quot;-■, Al sang: 9,7&amp;quot;-*eY —0 sing(Y) yet: (f7^-4iP 0 0 —° (fcr-s-4tYet(P) 0 t) The graph of (2), shown in Figure 2, does not encode a proof. The reason is shown in Figure 3. At this point in the algorithm, we have deleted the leftmost terminal tensor node. Howe</context>
<context position="18202" citStr="Ladusaw, 1979" startWordPosition="3148" endWordPosition="3149">ence (3), in which nobody and anyone play the roles of licenser and NPI, respectively. (3) Nobody saw anyone. [PRED &apos;SEE&apos; f: SUBJ g:[ PRED &apos;NOBODY&apos;] OBJ h:[ PRED &apos;ANYONE&apos;] Normally, a sentence with two quantifiers would generate two different scope readings—in this case, (4) and (5). (4) f(,-,4t no(person, )x. any (person, Ay .see(x, y))) (5) icr^-4t any(person, )ty. no(person, Ax.see(x, y))) However, Ladusaw&apos;s generalization is that NPI&apos;s are licensed within the scope of their licensers. In fact, the semantics of any prevent it from taking wide scope in such a case (Kadmon and Landman, 1993; Ladusaw, 1979, p. 96-101). Our analysis, then, should derive (4) but block (5). 6This multiple-use effect can be achieved more directly using the exponential operator!; however this unnecessary step would take us outside of the multiplicative fragment of linear logic and preclude the proof net techniques described earlier. 148 The premises are nobody: ((gc,-•-■ex 0 t) -0 (H-s-4 t 5(x) t)) -0 H-s-+t no(person, S) saw: (ger&apos;s-4e X 0 hcf-&apos;4e Y) -0 fq--&gt;tsee(X,Y) anyone: y -0 .1&amp;quot;4tT(Y) t) --0 (.1,4t any(person, T) t) The proof net for reading (4) is shown in Figure 4.7 As required, the net in Figure 4, corresp</context>
<context position="21473" citStr="Ladusaw, 1979" startWordPosition="3690" endWordPosition="3692">e accounting for monotonic inference properties, Dowty (1994) proposes a doublemarking framework whereby categories like A::/B+ are masked for both logical polarity and syntactic polarity. 5 Conclusion We have elaborated on and extended slightly the &apos;glue language&apos; approach to semantics of Dalrymple et al. It was shown how linear logic proof nets can be used for efficient natural-language meaning deductions in this framework. We then presented a glue language treatment of negative polarity licensing which ensures that NPI&apos;s are licensed within the semantic scope of their licensers, following (Ladusaw, 1979). This system uses no new global rules or features, nor ambiguous lexical entries, but only the addition of L&apos;s to the relevant items within the lexicon. The licensing takes place precisely at the syntax-semantics interface, since it is implemented entirely in the interface glue language. Finally, we noted briefly some similarities and differences between this system and categorial grammar &apos;monotonicity marking&apos; approaches. 6 Acknowledgements I&apos;m grateful to Mary Dalrymple, John Lamping and Stanley Peters for very helpful discussions of this material. Vineet Gupta, Martin Kay, Fernando Pereira</context>
</contexts>
<marker>Ladusaw, 1979</marker>
<rawString>William A. Ladusaw. 1979. Polarity Sensitivity as Inherent Scope Relations. Ph.D. thesis, University of Texas, Austin. Reprinted in Jorge Hanlcamer, editor, Outstanding Dissertations in Linguistics. Garland, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alain Lecomte</author>
<author>Christian Retore</author>
</authors>
<title>Pomset logic as an alternative categorial grammar.</title>
<date>1995</date>
<booktitle>Formal Grammar. Proceedings of the Conference of the European Summer School in Logic, Language, and Information,</booktitle>
<editor>In Glyn V. Morrill and Richard T. Oehrle, editors,</editor>
<location>Barcelona.</location>
<contexts>
<context position="4397" citStr="Lecomte and Retore, 1995" startWordPosition="681" endWordPosition="684"> the same theorem might have different proofs corresponding to different orderings of the inference steps. A further advantage of proof nets for our purposes is that an invalid meaning deduction, e.g. one corresponding to some spurious scope reading of a particular sentence, can be illustrated by exhibiting its defective graph which demonstrates visually why no proof exists for it. Proof net techniques have also been exploited within the categorial grammar community, for example for reasons of efficiency (Morrill, 1996) and in order to give logical descriptions of certain syntactic phenomena (Lecomte and Retore, 1995). In this section we construct a proof net from the premises for sentence (1), showing how to apply higher-order unification to the meaning terms in the process. We then review the 0(n2) algorithm of Gallier (1992) for propositional (multiplicative) linear logic which checks whether a given proof net is valid, i.e. corresponds to a proof. The complete process for assembling a meaning from its premises will be shown in four steps: (1) rewrite the premises in a normalized form, (2) assemble the premises into a graph, (3) connect together the positive (&amp;quot;producer&amp;quot;) and negative (&amp;quot;consumer&amp;quot;) meanin</context>
</contexts>
<marker>Lecomte, Retore, 1995</marker>
<rawString>Alain Lecomte and Christian Retore. 1995. Pomset logic as an alternative categorial grammar. In Glyn V. Morrill and Richard T. Oehrle, editors, Formal Grammar. Proceedings of the Conference of the European Summer School in Logic, Language, and Information, Barcelona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dale A Miller</author>
</authors>
<title>A logic programming language with lambda abstraction, function variables and simple unification.</title>
<date>1990</date>
<booktitle>Extensions of Logic Programming, Lecture Notes in Artificial Intelligence.</booktitle>
<editor>In Peter Schroeder-Heister, editor,</editor>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="8650" citStr="Miller (1990)" startWordPosition="1461" endWordPosition="1462">ts no matching literal B of opposite sign then the graph does not encode a proof and the algorithm fails. In this process the unifications apply to whole expressions of the form S-&apos;.* M, including both variables over LFG structures and variables over meaning terms. For the meaning terms, this requires a limited higher-order unification scheme that produces the unifier Ax.p(x) from a second-order term T and a first-order term p(x). As noted by Dalrymple et al. (to appear), all the apparatus that is required for their simple intensional meaning language falls within the decidable /A fragment of Miller (1990), and therefore can be implemented as an extension of a first-order unification scheme such as that of Prolog. For the example at hand, there is only one way to connect the literals (and hence at most one reading for the sentence), as shown in Figure 1. At this stage, the unifications would bind the variables in Figure 1 as follows: X 1-+ x, H 1-4 fa, S Ax.leave(x), M 1-4 every(person,Ax.leave(x)). 2.4 Step 4: test the graph for validity Finally, we apply Gallier&apos;s (1992) algorithm to the connected graph in order to check that it corresponds to a proof. This algorithm recursively decomposes th</context>
</contexts>
<marker>Miller, 1990</marker>
<rawString>Dale A. Miller. 1990. A logic programming language with lambda abstraction, function variables and simple unification. In Peter Schroeder-Heister, editor, Extensions of Logic Programming, Lecture Notes in Artificial Intelligence. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glyn V Morrill</author>
</authors>
<title>Memoisation of categorial proof nets: parallelism in categorial processing.</title>
<date>1996</date>
<booktitle>Proceedings of the Roma Workshop on Proofs and Linguistic Categories,</booktitle>
<editor>In V. Michele Abrusci and Claudia Casadio, editors,</editor>
<location>Rome.</location>
<contexts>
<context position="4297" citStr="Morrill, 1996" startWordPosition="667" endWordPosition="669">t; thus the manipulation of proof nets is more efficient than sequent deduction, in which the same theorem might have different proofs corresponding to different orderings of the inference steps. A further advantage of proof nets for our purposes is that an invalid meaning deduction, e.g. one corresponding to some spurious scope reading of a particular sentence, can be illustrated by exhibiting its defective graph which demonstrates visually why no proof exists for it. Proof net techniques have also been exploited within the categorial grammar community, for example for reasons of efficiency (Morrill, 1996) and in order to give logical descriptions of certain syntactic phenomena (Lecomte and Retore, 1995). In this section we construct a proof net from the premises for sentence (1), showing how to apply higher-order unification to the meaning terms in the process. We then review the 0(n2) algorithm of Gallier (1992) for propositional (multiplicative) linear logic which checks whether a given proof net is valid, i.e. corresponds to a proof. The complete process for assembling a meaning from its premises will be shown in four steps: (1) rewrite the premises in a normalized form, (2) assemble the pr</context>
</contexts>
<marker>Morrill, 1996</marker>
<rawString>Glyn V. Morrill. 1996. Memoisation of categorial proof nets: parallelism in categorial processing. In V. Michele Abrusci and Claudia Casadio, editors, Proceedings of the Roma Workshop on Proofs and Linguistic Categories, Rome.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor Sanchez Valencia</author>
</authors>
<date>1991</date>
<booktitle>Studies on Natural Logic and Categorial Grammar. Ph.D. thesis,</booktitle>
<institution>University of Amsterdam.</institution>
<contexts>
<context position="19555" citStr="Valencia (1991" startWordPosition="3378" endWordPosition="3379">oxed in the figure. A second way of linking the positive and negative literals in Figure 4 produces a net which corresponds to (5), the spurious reading in which any has wide scope. In that graph, however, all three of the available terminal tensor nodes produce a single, connected (cyclic) graph if deleted, so decomposition cannot even begin and the algorithm fails. Once again, it is the licensing resources which are enforcing the desired constraint. 4 Categorial grammar approaches The t atom used here is somewhat analogous to the (negative) lexical `monotonicity markers&apos; proposed by Sanchez Valencia (1991; 1995) and Dowty (1994) for categorial grammar. In these approaches, categories of the form AI B are marked with monotonicity properties, i.e. as AIB, A+IB-,A-1B+, or A- I B- , and similarly for left-leaning categories of the form A\B. Then monotonicity constraints can be enforced using category assignments like the following from (Dowty, 1994): f (S+ IV P-)ICN- 1 no. 1 (S- IV P+)IC N+ f any: (S- IV P-)ICNever: V P- IV PSanchez Valencia and Dowty, however, are less concerned with the distribution of NPI&apos;s than they are with using monotonicity properties to characterize valid inference pattern</context>
</contexts>
<marker>Valencia, 1991</marker>
<rawString>Victor Sanchez Valencia. 1991. Studies on Natural Logic and Categorial Grammar. Ph.D. thesis, University of Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor Sanchez Valencia</author>
</authors>
<title>Parsing-driven inference: natural logic. Linguistic Analysis,</title>
<date>1995</date>
<pages>25--3</pages>
<marker>Valencia, 1995</marker>
<rawString>Victor Sanchez Valencia. 1995. Parsing-driven inference: natural logic. Linguistic Analysis, 25(3-4):258-285.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>