<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000013">
<title confidence="0.985998">
Detection of Language (Model) Errors
</title>
<author confidence="0.994393">
K.Y. Hung, R.W.P. Luk, D. Yeung, K.F.L. Chung and W. Shu
</author>
<affiliation confidence="0.9281355">
Department of Computing
Hong Kong Polytechnic University
</affiliation>
<address confidence="0.384118">
Hong Kong
</address>
<email confidence="0.988732">
E-mail: {cskyhung, csrluk, csdaniel, cskchung, cswshu}@comp.polvu.edu.hk
</email>
<sectionHeader confidence="0.994793" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999924095238095">
The bigram language models are popular, in
much language processing applications, in
both Indo-European and Asian languages.
However, when the language model for
Chinese is applied in a novel domain, the
accuracy is reduced significantly, from 96% to
78% in our evaluation. We apply pattern
recognition techniques (i.e. Bayesian, decision
tree and neural network classifiers) to
discover language model errors. We have
examined 2 general types of features: model-
based and language-specific features. In our
evaluation, Bayesian classifiers produce the
best recall performance of 80% but the
precision is low (60%). Neural network
produced good recall (75%) and precision
(80%) but both Bayesian and Neural network
have low skip ratio (65%). The decision tree
classifier produced the best precision (81%)
and skip ratio (76%) but its recall is the lowest
(73%).
</bodyText>
<sectionHeader confidence="0.962529" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.995605786885246">
Language models are important post-processing
modules to improve recognition accuracy of a
wide variety of input, namely speech recognition
(Balh et al., 1983), handwritten recognition
(Elliman and Lancaster, 1990) and printed
character recognition (Sun, 1991), for many
human languages. They can also be used for text
correction (Ron et al., 1994) and part-of-speech
tagging.
For Indo-European languages, the word-bigram
language model is used in speech recognition
(Jelinek, 1989) and handwriting recognition
(Nathan et al., 1995). Various ways to improve
language models were reported. First, the model
has been extended with longer dependencies (e.g.
trigram) (Jelinek, 1991) and using non-contiguous
dependencies, like trigger pairs (Rosenfeld, 1994)
or long distance n-gram language models (Huang
etal., 1993). For better probability estimation, the
model was extended to work with (hidden) word
classes (Brown etal., 1992, Ward and Issar, 1996).
A more error-driven approach is the use of hybrid
language models, in which some detection
mechanism (e.g. perplexity measures [Keene and
O&apos;Kane, 1996] or topic detection [Mahajan et al.,
1999]) selects or combines with a more
appropriate language model.
For Asian languages (e.g. Chinese, Japanese and
Korean) represented by ideographic characters,
language models are widely used in computer
entry because these Asian languages have a large
set of characters (in thousands) that the
conventional keyboard is not designed for. Apart
from using speech and handwriting recognition
for computer entry, language models for Asian
languages can be used for sentence-based
keyboard input (e.g. Lochovsky and Chung, 1997),
as well as detecting improper writing (e.g. dialect-
specific words or expressions).
Unlike Indo-European languages, words in these
Asian languages are not delimited by space and
conventional approximate string matching
techniques (Wagner and Fisher, 1974; Oommen
and Zhang, 1974) in handwriting recognition are
seldom used in Asian language models. Instead, a
widely used and reported Asian language model is
the character-bigram language model (Jin et al.,
1995; Xia et al., 1996) because it (1) achieved
high recognition accuracy (around 90-96%) (2) is
easy to estimate model parameters (3) can be
processed quickly and (4) is relatively easy to
implement.
Improvement of these language models for Indo-
European languages can be applied for the Asian
languages but words need to be identified. For
Asian languages, the model was integrated with
syntactic rules (Chien, Chen and Lee, 1993).
Class based language model (Lee and Tung, 1995)
was also examined but the classes are based on
semantically related words. A- new approach
(Yang et al., 1998) is reported using segments
</bodyText>
<page confidence="0.998376">
87
</page>
<bodyText confidence="0.999905427184466">
expressed by prefix and suffix trees but the
comparison is based on perplexity measures,
which may not correlate well with recognition
improvement (Iyer et al., 1997).
While attempts to improve the (bigram) language
models were (quite) successful, the high
recognition accuracy (about 96%) is not adequate
for professional data entry services, which
typically require an error rate lower than 1 in
1,000. As part of the quality control exercises,
these services estimate their error rate by
sampling, and they identify and correct the errors
manually to achieve the required quality. Faced
with a large volume of text, the ability to
automatically identify where the errors are is
perhaps more important than automatically
correcting errors, in post-editing because (1)
manual correction is more reliable than automatic
correction, (2) manual error sampling can be
carried out and (3) more manual efforts are
required in error identification than correction due
to the large volume of text. For example, if the
identification of errors is 97% and there are no
errors in error correction, then the accuracy of the
language model is improved from 96% to 99.9%
after error correction.
In typical applications, the accuracy of the bigram
language model may not be as high as those
reported in the literature because the data may be
in a different genre than that of the training data.
For evaluation, we tested a bigram language
model with text from a novel domain and its
accuracy dropped significantly from 96% to 78%,
which is similar to English (Mahajan etal., 1999).
Improvement in the robustness of the bigram
language model across different genre is
necessary and several approaches are available,
based on detecting errors of the language model.
One (adaptive) approach is to automatically
identify the errors and manually correcting them.
The information about the correction of errors is
used to improve the bigram language model. For
example, the bigram probabilities of the language
model may be estimated and updated with the
corrected data. In this way, future occurrences of
these errors are reduced.
Another (hybrid) approach uses another language
model to correct the identified errors. This
language model can be computationally more
expensive than the bigram language model
because it is applied only to the identified errors.
Also, topic detection (Mahajan et al., 1999) and
language model selection (Keene and O&apos;Kane,
1996) can be applied to those area to find a more
appropriate language model because usually
topic-dependent words are those causing errors.
Another (integrative) approach improves the
language model accuracy using more
sophisticated recognizers, instead of a
complementary language model. The more
sophisticated recognizer may give a set of
different results that the bigram language model
can re-apply on or this recognizer simply gives
the recognized character. This integrates well with
the coarse-fine recognition architecture proposed
by Nagy (1988) back in the 1960s. Coarse
recognition provides the candidates for the
language model to select. Fine, expensive
recognition is carried out only where the language
models failed. Finally, it is possible to combine all
the different approaches (i.e. adaptive, hybrid and
integrative).
Given the significance in detecting errors of
language models, there is little work in this area.
Perhaps, it was considered that these errors were
random and therefore hard to detect. However,
users can detect errors quickly. We suspect that
some of these errors may be systematic due to the
properties of the language model used or due to
language specific properties.
We adopt a pattern recognition aprwach to
detecting errors of the bigram language mociei for
the Chinese language. Each output is assigned to
either the class of correct output or the class of
errors. The assignment of a class to an output is
based on a set of features. We explore a number
of features to detect errors, which are classified
into model-based features and language-specific
features.
The proposed approach can work with Indo-
European languages at the word-bigram level.
However, language-specific features have to be
discovered for the particular language. In addition,
this approach can be adopted for n-gram language
models. In principal, the model-based features can
be found or evaluated similar to the bigram
language model. For example, if the trigram
probability (instead of bigram probability) is low,
then the likelihood of a language model error is
high.
This paper is organized as follows. Section 1
discusses various features and some preliminary
evaluation of their suitability for error
</bodyText>
<page confidence="0.9936">
88
</page>
<bodyText confidence="0.9887815">
identification. Section 2 describes 3 types of
classifiers used. In section 3, our evaluation is
reported. Finally, we conclude.
language properties. Figure 1 shows the likelihood
of an error occurring against the percentage of the
conditional probabilities that are zero.
</bodyText>
<sectionHeader confidence="0.946905" genericHeader="method">
1. Features
</sectionHeader>
<bodyText confidence="0.9999168125">
We evaluate individual features for error detection
because they are important to the success of
detection. Articles from Yazhou Zhoukan (YZZK)
magazine (4+ Mbytes)/PH corpus (Guo and Liu,
1992) (7+ Mbytes) are used for evaluation. We
use the recall and precision measurements for
evaluation. The recall is the number of errors
identified by a particular feature divided by the
total number of errors. The precision is the
number of errors identified by a particular feature
divided by the total number of times the feature
indicate that there are errors. In the first
subsection, we describe some model-based
features. Next, we describe the language-based
features. In the last subsection, we discuss the
combined use of both types of features.
</bodyText>
<subsectionHeader confidence="0.994137">
1.1 Model-based features
</subsectionHeader>
<bodyText confidence="0.998468833333333">
The bigram language model selects the most
likely path P,„, out of a set S. The probability of a
path s in S is simply the product of the conditional
probabilities of one character c, after the other c,./
where s = co.c,..c s, after making the Markov
assumption. Formally,
</bodyText>
<equation confidence="0.974303">
&apos;max = arg max {p(s)}
S
= arg max p(co)np(c,Ic,_,)1coc,...c,I=
seS
</equation>
<bodyText confidence="0.987942636363636">
The set s is generated by the set of candidate
characters for each recognition output. The
recognizer may supply the set of candidate
characters. Alternatively, a coarse recogniser may
simply identify the best-matched group or class of
characters. Then, members of this class are the
candidate characters. Formally, we use a function
h(), that maps the recognition position to a set of
candidate characters, i.e. h(i) = (c,d. We can also
define the set of sentences in terms of h(.), i.e. S =
ts I s = c, e
</bodyText>
<subsubsectionHeader confidence="0.821233">
1.1.1 Features based on zero probabilities (F1j)
</subsubsectionHeader>
<bodyText confidence="0.989424">
One feature to detect errors is to count the number
of conditional probabilities p(c,lc,_,) that are zero,
between 2 consecutive positions. Zero conditional
probabilities may be due to insufficient training
data or may be because they represent the
</bodyText>
<figure confidence="0.737601">
precision
50% 60% 70% 80% 90% 100% 110%
</figure>
<figureCaption confidence="0.9943125">
Figure 1: The language model output errors against
percentages of zero conditional probabilities.
</figureCaption>
<subsubsectionHeader confidence="0.929975">
1.1.2 Features based on low probability (F1,7)
</subsubsectionHeader>
<bodyText confidence="0.9997639">
When there are insufficient data, the conditional
probabilities that are small are not reliable. If P„,,
have selected some conditional probabilities that
are low, then probably there are no other choices
from the candidate sets. Hence, the insufficient
data problem may occur in that particular P,„„„.
In Figure 2, we plot the likelihood of errors
identified against the different logarithmic
conditional probability values. When the recall
increases, unfortunately, the precision drops.
</bodyText>
<figureCaption confidence="0.998842">
Figure 2: The precision, recall and accuracy (i.e. recall
X precision) of detecting language model errors by
examining the logarithm conditional probabilities on
the maximum likelihood path.
</figureCaption>
<subsectionHeader confidence="0.956938">
1.2 Language-specific Features
</subsectionHeader>
<bodyText confidence="0.9962486">
The language-specific features are based on
applying the word segmentation algorithm (Kit et
al., 1989) to the maximum likelihood path. The
ROCLING (Chen and Huang, 1993) word list
used for segmentation has 78,000+ entries.
</bodyText>
<figure confidence="0.999459">
120%
100%
80% I-
60%
40%
20
0%
Precision
recall
—4.-- Accuracy
&gt;1&apos;
60%
50%
40%
30%
20%
10%
0%
</figure>
<page confidence="0.963485">
89
</page>
<note confidence="0.380835">
1.2.1 Features based on word length (F2,1)
</note>
<bodyText confidence="0.999664222222222">
If the matched word in the maximum likelihood
path is long, then we expect the likelihood of an
error is low because long words are specific.
Figure 3 shows the precision of detecting the
matched word is correct and the recall of errors in
multi-character words. In general, the longer the
matched words, the more likely that they are
correct and the likelihood of missing undetected
long words is small.
</bodyText>
<figure confidence="0.999422625">
120%
100%
80%
60%
40%
20%
0%
2 3 4 5 6 7
</figure>
<figureCaption confidence="0.9973195">
Figure 3: The precision of correct matched words
against word lengths.
</figureCaption>
<subsubsectionHeader confidence="0.889074">
1.2.2 Features based on single-character
</subsubsectionHeader>
<bodyText confidence="0.978172321428571">
sequences (F2,2)
In word segmentation, when there are no entries
in the dictionary that can match, the input is
segmented into single characters. Thus, Lin et al
(1993) noted that single-character sequences after
word segmentation might indicate segmentation
problems. Here, we apply the same technique for
the detection of errors. If we count on the per
character basis, the recall of error is 80% and the
precision in error identification is 35%. If we
count multi-character words and a sequence of
single-characters as blocks, then the recall of
errors is 79% and the precision in finding one or
more errors in the block is increased to 51%.
120%
single-character sequences may depend on their
length. Therefore, we plotted the recall and
precision of detecting errors against the length of
the single-character sequences. According to
Figure 4, as the length of the single-character
sequence is large, the likelihood of an error is
larger. The recall of errors is particularly low for
single-character sequences that have 2 characters.
The other single-character sequences (i.e. its
length is not equals to 2) have almost 100% recall.
One possible reason why 2 single-character
sequences achieved low precision is that there are
many spurious bigrams and therefore false match.
</bodyText>
<subsectionHeader confidence="0.994313">
1.3 Combined use of Features
</subsectionHeader>
<bodyText confidence="0.999484">
We carried out a preliminary study using the
features mentioned in subsection 1.1 and 1.2. Our
Bayesian classifier (Section 2.1) achieved 83%
recall but 35% precision, which can be achieved
using language specific features only (F2,2).
Therefore, we try to combine the use of these
features in a more careful manner. We divided the
detection into 3 scenarios: (1) single character
(feature F2,2); (2) single-character sequence of
length 2 (feature F2,2) and (3) 2 character words
(feature F2,1). Each case is assigned a classifier to
detect errors. Single-character sequences longer
than 2 are considered as having errors (Figure 4).
Words of length longer than 2 are considered
correct (Figure 3).
</bodyText>
<subsubsectionHeader confidence="0.914487">
1.3.1 Single characters
</subsubsectionHeader>
<bodyText confidence="0.9988226">
After word segmentation, single characters are
those cases when there are no multi-character
words in the dictionary that can match with it and
its following substring. The single characters have
different part-of-speech tags.
</bodyText>
<figure confidence="0.957551333333333">
e&amp;quot;fr% %, 42.
Pat cfsres:h
—O.—precision
0% —
1 2
3 4 5 6 7 8
</figure>
<figureCaption confidence="0.947066">
Figure 4: The precision and recall of single-character
sequences of different lengths.
Similar to matched words in the maximum
likelihood path, the error detection performance of
Figure 5: The single characters and their corresponding
language model output accuracy for different part-of-
speech tags.
</figureCaption>
<bodyText confidence="0.5721475">
Figure 5 shows that the accuracy of the language
model for these single characters with part-of-
</bodyText>
<page confidence="0.995106">
90
</page>
<bodyText confidence="0.999932357142857">
speech tags related to exclamations are low. For
error detection, a feature is assigned to each part-
of-speech tag.
The language model accuracy for single
characters may depend on the availability of the
left and right context to form high probability
bigrams. Therefore, we expect that language
model accuracy of single characters at the
beginning (70%) and end (70%) of a sentence is
lower than those in the middle (85%) of the
sentence. The worst case occurs when the
sentence has only a single character, where the
measured accuracy is only 8.75% (i.e. no bigram
context).
</bodyText>
<subsubsectionHeader confidence="0.9928">
1.3.2 Two-single-characters sequence
</subsubsectionHeader>
<bodyText confidence="0.9978674">
Figure 6 shows that language model output
accuracy increases as the bigram probability of
single-character sequences of length 2 increases.
Hence, the bigram probabilities can be used as a
feature for detection.
</bodyText>
<figure confidence="0.9881537">
1.2
1
••••••,ri
0.8 ••,.• • &amp;quot;
&apos;S
&apos;A 1
1.1 04
A Ar
o
FP F.&apos; )P&apos;
</figure>
<figureCaption confidence="0.999246">
Figure 6: The bigram (logarithm) probability of the
single-character sequence of length 2.
</figureCaption>
<bodyText confidence="0.9997554">
Similar to single characters, the language model
accuracy for 2-single-characters sequences at the
start, middle and end of a sentence are 48%, 47%
and 30%, respectively. The accuracy is 33% if the
sentence is the 2-single-characters sequence.
</bodyText>
<figure confidence="0.424967">
ii
1
acc -----
0.8 I
OA I- ----.
az 1 i s 1 .___ ________--.--___
I
0
0 1 2 3 4 5 6 7 8
nunter of hidckn muds
</figure>
<figureCaption confidence="0.9534905">
Figure 7: Language model accuracy against different
number of hidden words (see text).
</figureCaption>
<bodyText confidence="0.999963666666667">
Another feature for 2-single-characters sequences
is to examine whether the characters in the two
candidate sets can form words that match with the
dictionary. These matched words are called
hidden words. Figure 7 shows that if there are
hidden words, the language model accuracy
dropped from 60% to 25%. Since there are not
many cases with 6-8 hidden words, the accuracy
for these cases are not reliable.
</bodyText>
<subsubsectionHeader confidence="0.958949">
1.3.3 Two-character words
</subsubsectionHeader>
<bodyText confidence="0.9960643125">
For 2 character words, the bigram probability
(Figure 8) can be used as a feature similar to the
single-character sequences. The position of these
2 character words in the sentence does not relate
to the language model accuracy. Our measured
accuracy is 91%, 89% and 91% for the beginning,
the end and the middle of the sentence,
respectively. Even sentences with a single 2-
character word achieved 90% accuracy. Hence,
there is no need to assign features for the position
of the 2 character words in a sentence. Similar to
2-single-characters sequences, the language model
accuracy (Figure 9) decreases as the number of
hidden words increase in the corresponding 2 sets
of candidate characters.
&gt;Is
</bodyText>
<figureCaption confidence="0.995885">
Figure 8: The language model accuracy of 2 character
words against the bigram probability.
</figureCaption>
<figure confidence="0.967815">
0.1
0 —
2 3 4 5 6 7 9
number of hidden words
</figure>
<figureCaption confidence="0.9963465">
Figure 9: The language model accuracy against
different number of hidden words.
</figureCaption>
<figure confidence="0.994271625">
1
0,9
0,8
0.2
o 6
0.5
0.40.3
0.2
</figure>
<page confidence="0.991958">
91
</page>
<sectionHeader confidence="0.876559" genericHeader="method">
2 Classifiers
</sectionHeader>
<bodyText confidence="0.999276125">
One of the problems with using individual
features is that the recall and precision are not
very high, except the language-specific features. It
is also difficult to set the threshold for detection
because of the precision-recall trade-off. In
addition, there may be some improvement in
detection performance if features are combined
for detection. Therefore, we adopt a pattern
recognition approach to detect errors.
Several classifiers are used to decide for error
identification because we do not know whether
particular features work well with particular
classifiers, which make different assumptions
about classification. Three types of classifers will
be examined: Bayesian, decision tree and neural
network.
</bodyText>
<subsectionHeader confidence="0.999006">
2.1 Bayesian Classifier
</subsectionHeader>
<bodyText confidence="0.9999436">
The Bayesian classifier is simple to implement
and is compatible with the model-based features.
Given the feature vector x, the Bayesian detection
scheme assigns the correct class wc and the error
class we, using the following rule:
</bodyText>
<equation confidence="0.685439">
g(x) &gt; g( x) assign we
</equation>
<bodyText confidence="0.943993">
,Otherwise assign we
where ge() and ge() are:
</bodyText>
<equation confidence="0.979536">
g,(x)=—(x — E;&apos;(x - p,)— log Ec. I +21og p(w, )
g ,(x)= —(x — p,)T E;&apos;(x- p,)— log j +2 log p(w, )
</equation>
<bodyText confidence="0.9380665">
ii and /4 are the mean vectors of the class we. and
We, respectively, and Ee are the covariance
matrices of the class we and We, respectively, and
Id is the determinant.
</bodyText>
<subsectionHeader confidence="0.999772">
2.2 Decision Tree
</subsectionHeader>
<bodyText confidence="0.999956125">
Originally, we tried to use the support vector
machine (SVM) (Vanpik, 1995) but it could not
converge. Instead, we used the decision tree
algorithm C4.5 by Quinlan (1993). Decision trees
are known to produce good classification if
clusters can be bounded by some hyper-rectilinear
regions. We trained C4.5 with a set of feature
vectors, described in Section 1.3.
</bodyText>
<subsectionHeader confidence="0.995924">
2.3 Neural Network
</subsectionHeader>
<bodyText confidence="0.999988842105263">
We use the multi-layer perceptron (MLP) because
it can perform non-linear classification. The MLP
has 3 layers of nodes: input, hidden and output.
Nodes in the input layer are fully connected with
those in the hidden layer. Likewise nodes in the
hidden layer are fully connected to the output
layer. For our application, one input node
corresponds to a feature in section 1.3. The value
of the feature is the input value of the node. Two
output nodes indicate whether the current
character is correct or erroneous. The number of
hidden nodes is 2-4, calculated according to
(Fuj ita, 1998).
The output of each node in the MLP is the
weighted sum of its input, which is transformed
by a sigmoidal function. Initially, the weights are
assigned with small random numbers, which are
adjusted by the gradient descend method with
learning rate 0.05 and momentum 0.1.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="evaluation">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.999923676470588">
In the evaluation, the training data is the PH
corpus and the test data is the YZZK magazine
articles (4+ Mbytes), downloaded from the
Internet. In handwritten character recognition, the
optimal size of the number of candidates is 6
(Wong and Chan, 1995). For robustness, each
recognized character in our evaluation is selected
from 10 candidates.
We measured the performance in terms of recall,
precision and the manual effort reduction in
scanning the text for errors. The recall is the
number of identified errors over the total number
of errors. The precision is the number of identified
errors over the total number of cases classified as
errors. The amount of saving in manual scanning
for errors is called the skip ratio, which is the
number of blocks classified as correct over the
total number of blocks. The recall and the skip
ratio are more important than the precision
because post error correction (manual or
automatic) can improve the recognition accuracy.
It is possible to combine the recall and precision
into one, using the F measures (Van Rijsbergen,
1979) but the value for rating the relative
importance is subjective.
Table 1 shows the classification performance of
the Bayesian classifier. The recall of errors by the
Bayesian classifier has reduced slightly from 83%
using a single classifier to 79% using 3 classifiers
but the precision improved from 51% to 60%.
Also, the skip ratio is 65%, which is much higher
than the skip ratio of 0.1% if we did not use the
classifier. Although the MLP has a higher
precision (80%), its recall is slightly lower than
</bodyText>
<page confidence="0.985699">
92
</page>
<bodyText confidence="0.5969625">
the Bayesian classifier. The skip ratio of the both
Bayesian and MLP classifiers are about the same.
</bodyText>
<table confidence="0.999790076923077">
Cases Measure Bayes C4.5 MLP
Single Recall 71% 56% 28%
character
Precision 40% 75% 71%
2 single Recall 60% 84% 83%
characters
Precision 88% 82% 80%
2-character Recall 60% 17% 9%
words
Precision 29% 60% 62%
Overall Recall 79% 73% 75%
Precision 60% 81% 80%
Skip Ratio 65% 76% 66%
</table>
<tableCaption confidence="0.9698305">
Table 1: The performances of the 3 types of
classifiers in detecting language model errors.
</tableCaption>
<sectionHeader confidence="0.943714" genericHeader="conclusions">
4 Summary and Future Work
</sectionHeader>
<bodyText confidence="0.999517583333334">
We have evaluated both model-based and
language-specific features for detecting language
model errors. Individual model-based features did
not yield good detection accuracy, suffering from
the precision-recall trade-off. The language-
specific features detect errors better. In particular,
matched multi-character words are usually correct.
If the model-based and language-specific features
are aggregated as a single feature vector, the recall
and precision of errors are 83% and 35%,
respectively, which are the same if we just use
language-specific features. Hence, instead of a
single classifier, we separated 3 situations
identified by the language-specific features and 3
classifiers are used to detect these errors
individually. The Bayesian classifier (simpliest)
achieved an overall 79% recall, 60% precision
and 65% skip ratio and the MLP achieved an
overall 75% recall, 80% precision and a 66% skip
ratio. Similar recall and precision performances
are achieved using decision trees, which are
preferred since their skip ratio is higher (i.e. 76%).
Although the precision (so far) is not high (60% -
80%), it is not the most important result because
</bodyText>
<listItem confidence="0.9123765">
(1) this only represents a minor waste of checking
effort, compared with scanning the entire text, and
(2) the identified errors will be checked further or
corrected either manually or automatically.
</listItem>
<sectionHeader confidence="0.646995" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999913166666667">
This work is supported by the (Hong Kong)
University Grants Council under project PolyU
5109/97E and the PolyU Central Research Grant
G-S603. We are grateful to Guo and Liu for
providing the PH corpus and ROCLING for
providing their word list.
</bodyText>
<sectionHeader confidence="0.796159" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.957212384615384">
Bahl, L.R., F. Jelinek and R.L. Mercer (1983) &amp;quot;A
maximum likelihood approach to continuous
speech recognition&amp;quot;, IEEE Trans. PAMI, 5:2, pp.
179-190.
Brown, P.F., V.J. Della Pietra, P.V. deSouza and
R.L. Mercer (1992) &amp;quot;Class-based n-gram models
of natural language&amp;quot;, Computational Linguistics,
4, pp.467-479.
Chen, K.-C. and C.R. Huang (eds.) (1993)
&amp;quot;Chinese word class analysis&amp;quot;, Technical Report
93-05, Chinese Knowledge Information
Processing Group, Institute of Information
Science, Academia Sinica, Taiwan.
Chien, L.F., Chen, K.J., Lee, L.S. (1993) &amp;quot;A best-
first language processing model integrating the
unification grammar and Markov language model
for speech recognition applications&amp;quot;, IEEE Trans.
Speech and Audio Processing, 1:2, Page(s): 221 —
240.
Elliman, D.G. and 1.T. Lancaster (1990) &amp;quot;A
review of segmentation and contextual analysis
techniques for text recognition&amp;quot;, Pattern
Recognition, 23:3/4, pp.337-346.
Fujita, 0. (1998) &amp;quot;Statistical estimation of the
number of hidden units for feedforward neural
networks&amp;quot;, Neural Networks, 11, 851-859.
</bodyText>
<reference confidence="0.6043434">
Guo, J. and H.C. Liu, &amp;quot;PH — a Chinese corpus for
pinyin-hanzi transcription&amp;quot;, ISS Technical Report,
TR93-112-0, Institute of Systems Science,
National University of Singapore, 1992.
Huang, X., F. Alleva, H. Hon, M. Hwang„ K. Lee
and R. Rosenfeld (1993) &amp;quot;The SPHINX-II speech
recognition system: an overview&amp;quot;, Computer
Speech and Lanaguage, 2, 137-148.
lyer, R., M. Ostendorf and M. Meteer (1997)
&amp;quot;Analyzing and predicting language model
</reference>
<page confidence="0.997423">
93
</page>
<bodyText confidence="0.8703806">
performance&amp;quot;, Proc. IEEE Workshop Automatic
Speech Recognition and Understanding, pp. 254-
261.
line unconstrained handwriting recognition using
statistical methods&amp;quot;,
</bodyText>
<reference confidence="0.995549835443038">
Jelinek, F. (1989) &amp;quot;Self-organized language
modeling for speech recognition&amp;quot;, in Readings in
Speech Recognition, Morgan Kayfmann.
Jelinek, F. (1991) &amp;quot;Up from trigrams&amp;quot;, Proc.
Eurospeech 91, pp.181-184.
Jin, Y., Y. Xia and X. Chang (1995) &amp;quot;Using
contextual information to guide Chinese text
recognition&amp;quot;, Proc. ICCPOL &apos;95, pp. 134-139.
Kenne, P.E. and M. O&apos;Kane (1996) &amp;quot;Hybrid
language models and spontaneous legal
discourse&amp;quot;, Proc. ICSLP, Vol. 2, pp. 717-720.
Kit, C., Y. Liu and N. Liang (1989) &amp;quot;On methods
of Chinese automatic word segmentation&amp;quot;,
Journal of Chinese Information Processing, 3:1,
13-20.
Law, H.H-C. and C. Chan (1996) &amp;quot;N-th order
ergodic multigram HMM for modeling of
languages without marked word boundaries&amp;quot;,
Proc. COLING 96, pp. 2043-209.
Lee, H-J. and C-H Tang (1995) &amp;quot;A language
model based on semantically clustered words in a
Chinese character recognition system&amp;quot;, Proc. 3rd
Int Conf. on Document Analysis and Recognition,
Vol. I., pp. 450-453.
Lin, M-Y., T-H. Chiang and K-Y. Su (1993) &amp;quot;A
preliminary study on unknown word problem in
Chinese word segmentation&amp;quot;, Proc. ROCLING VI,
pp.119-141.
Lochovsky, A.F. and K-H. Chung (1997)
&amp;quot;Homonym resolution for Chinese phonetic input&amp;quot;,
Communications of COUPS, 7:1, 5-15.
Mahajan, M., D. Beeferman and X.D. Huang
(1999) &amp;quot;Improving topic-dependent modeling
using information retrieval techniques&amp;quot;, Proc.
IEEE ICASSP 99, Vol. I, pp.541-544.
Nagy, G. (1988), &amp;quot;Chinese character recognition:
twenty-five-year retrospective&amp;quot;, in Proc. 9th Int.
Conf on Pattern Recognition, Vol. I, pp. 163-167.
Nathan, K.S., H.S.M. Beigi, J. Subrahmonia, G.J.
Clary and H. Maruyama (1995) &amp;quot;Real-time on-
Oommen, B.J. and K. Zhang (1996) &amp;quot;The
normalized string editing problem revisited&amp;quot;,
IEEE Trans. on PAMI, 18:6, pp. 669-672.
Quinlan, J.R. (1993) &amp;quot;C4.5 programs for machine
learning&amp;quot;, Morgan Kaufmann, CA.
Ron, D., Y. Singer and N. Tishby (1994) &amp;quot;The
power of Amnesia: learning probabilistic
automata with variable memory length&amp;quot;, to
appear in Machine Learning
Rosenfeld, R. (1994) &amp;quot;Adaptive statistical
language modeling&amp;quot; a maximum entropy
approach&amp;quot;, Ph.D. Thesis, School of Computer
Science, Carnegie Mellon University, Pittsburgh.
Sun, S.W. (1991), &amp;quot;A Contextual Postprocessing
for Optical Chinese Character Recognition&amp;quot;, in
Procint. Sym. on Circuits and Systems, pp. 2641-
2644.
Vapnik, V. (1995) The Nature of Statistical
Learning Theory, Springer-Verlag, New York.
Van Rijsbergen (1979) Information Retrieval,
Butterworths, London.
Wagner, R.A. and M.J. Fisher (1974) &amp;quot;The string
to string correction problem&amp;quot;, J. ACM, 21:1, pp.
168-173.
Ward, W. and S. Issar (1996) &amp;quot;A class based
language model for speech recognition&amp;quot;, Proc.
IEEE ICASSP 96, Vol. 1, pp.416-418.
Wong, P-K. and C. Chan (1999) &amp;quot;Postprocessing
statistical language models for handwritten
Chinese character recognizer&amp;quot;, IEEE Trans. SMC,
Part B, 29:2, 286-291.
Xia, Y., S. Ma, M. Sun, X. Zhu, Y. Jin and X.
Chang (1996) &amp;quot;Automatic post-processing of off-
line handwritten Chinese text recognition&amp;quot;, Proc.
ICCC, pp. 413-416.
Yang, K-C., T-H. Ho, L-F. Chien and L-S. Lee
(1998) &amp;quot;Statistics-based segment pattern lexicon -
a new direction for Chinese language modeling&amp;quot;,
Proc. IEEE ICASSP 98, Vol. 1., pp.169-172.
</reference>
<page confidence="0.999548">
94
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.287911">
<title confidence="0.997652">Detection of Language (Model) Errors</title>
<author confidence="0.956804">K Y Hung</author>
<author confidence="0.956804">R W P Luk</author>
<author confidence="0.956804">D Yeung</author>
<author confidence="0.956804">K F L Chung</author>
<author confidence="0.956804">W</author>
<affiliation confidence="0.856004">Department of</affiliation>
<title confidence="0.611502">Hong Kong Polytechnic</title>
<author confidence="0.812134">Hong</author>
<email confidence="0.931221">{cskyhung,csrluk,csdaniel,cskchung,</email>
<abstract confidence="0.987545636363636">The bigram language models are popular, in much language processing applications, in both Indo-European and Asian languages. However, when the language model for Chinese is applied in a novel domain, the accuracy is reduced significantly, from 96% to 78% in our evaluation. We apply pattern recognition techniques (i.e. Bayesian, decision tree and neural network classifiers) to discover language model errors. We have examined 2 general types of features: modelbased and language-specific features. In our evaluation, Bayesian classifiers produce the best recall performance of 80% but the precision is low (60%). Neural network produced good recall (75%) and precision (80%) but both Bayesian and Neural network have low skip ratio (65%). The decision tree classifier produced the best precision (81%) and skip ratio (76%) but its recall is the lowest (73%).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Guo</author>
<author>H C Liu</author>
</authors>
<title>PH — a Chinese corpus for pinyin-hanzi transcription&amp;quot;,</title>
<date>1992</date>
<tech>ISS Technical Report, TR93-112-0,</tech>
<institution>Institute of Systems Science, National University of Singapore,</institution>
<contexts>
<context position="9008" citStr="Guo and Liu, 1992" startWordPosition="1367" endWordPosition="1370">This paper is organized as follows. Section 1 discusses various features and some preliminary evaluation of their suitability for error 88 identification. Section 2 describes 3 types of classifiers used. In section 3, our evaluation is reported. Finally, we conclude. language properties. Figure 1 shows the likelihood of an error occurring against the percentage of the conditional probabilities that are zero. 1. Features We evaluate individual features for error detection because they are important to the success of detection. Articles from Yazhou Zhoukan (YZZK) magazine (4+ Mbytes)/PH corpus (Guo and Liu, 1992) (7+ Mbytes) are used for evaluation. We use the recall and precision measurements for evaluation. The recall is the number of errors identified by a particular feature divided by the total number of errors. The precision is the number of errors identified by a particular feature divided by the total number of times the feature indicate that there are errors. In the first subsection, we describe some model-based features. Next, we describe the language-based features. In the last subsection, we discuss the combined use of both types of features. 1.1 Model-based features The bigram language mod</context>
</contexts>
<marker>Guo, Liu, 1992</marker>
<rawString>Guo, J. and H.C. Liu, &amp;quot;PH — a Chinese corpus for pinyin-hanzi transcription&amp;quot;, ISS Technical Report, TR93-112-0, Institute of Systems Science, National University of Singapore, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Huang</author>
<author>F Alleva</author>
<author>H Hon</author>
<author>M Hwang„ K Lee</author>
<author>R Rosenfeld</author>
</authors>
<title>The SPHINX-II speech recognition system: an overview&amp;quot;,</title>
<date>1993</date>
<journal>Computer Speech and Lanaguage,</journal>
<volume>2</volume>
<pages>137--148</pages>
<marker>Huang, Alleva, Hon, Lee, Rosenfeld, 1993</marker>
<rawString>Huang, X., F. Alleva, H. Hon, M. Hwang„ K. Lee and R. Rosenfeld (1993) &amp;quot;The SPHINX-II speech recognition system: an overview&amp;quot;, Computer Speech and Lanaguage, 2, 137-148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R lyer</author>
<author>M Ostendorf</author>
<author>M Meteer</author>
</authors>
<title>Analyzing and predicting language model</title>
<date>1997</date>
<marker>lyer, Ostendorf, Meteer, 1997</marker>
<rawString>lyer, R., M. Ostendorf and M. Meteer (1997) &amp;quot;Analyzing and predicting language model</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Jelinek</author>
</authors>
<title>Self-organized language modeling for speech recognition&amp;quot;,</title>
<date>1989</date>
<booktitle>in Readings in Speech Recognition,</booktitle>
<publisher>Morgan Kayfmann.</publisher>
<contexts>
<context position="1599" citStr="Jelinek, 1989" startWordPosition="230" endWordPosition="231">he decision tree classifier produced the best precision (81%) and skip ratio (76%) but its recall is the lowest (73%). Introduction Language models are important post-processing modules to improve recognition accuracy of a wide variety of input, namely speech recognition (Balh et al., 1983), handwritten recognition (Elliman and Lancaster, 1990) and printed character recognition (Sun, 1991), for many human languages. They can also be used for text correction (Ron et al., 1994) and part-of-speech tagging. For Indo-European languages, the word-bigram language model is used in speech recognition (Jelinek, 1989) and handwriting recognition (Nathan et al., 1995). Various ways to improve language models were reported. First, the model has been extended with longer dependencies (e.g. trigram) (Jelinek, 1991) and using non-contiguous dependencies, like trigger pairs (Rosenfeld, 1994) or long distance n-gram language models (Huang etal., 1993). For better probability estimation, the model was extended to work with (hidden) word classes (Brown etal., 1992, Ward and Issar, 1996). A more error-driven approach is the use of hybrid language models, in which some detection mechanism (e.g. perplexity measures [K</context>
</contexts>
<marker>Jelinek, 1989</marker>
<rawString>Jelinek, F. (1989) &amp;quot;Self-organized language modeling for speech recognition&amp;quot;, in Readings in Speech Recognition, Morgan Kayfmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Jelinek</author>
</authors>
<title>Up from trigrams&amp;quot;,</title>
<date>1991</date>
<booktitle>Proc. Eurospeech 91,</booktitle>
<pages>181--184</pages>
<contexts>
<context position="1796" citStr="Jelinek, 1991" startWordPosition="258" endWordPosition="259">recognition accuracy of a wide variety of input, namely speech recognition (Balh et al., 1983), handwritten recognition (Elliman and Lancaster, 1990) and printed character recognition (Sun, 1991), for many human languages. They can also be used for text correction (Ron et al., 1994) and part-of-speech tagging. For Indo-European languages, the word-bigram language model is used in speech recognition (Jelinek, 1989) and handwriting recognition (Nathan et al., 1995). Various ways to improve language models were reported. First, the model has been extended with longer dependencies (e.g. trigram) (Jelinek, 1991) and using non-contiguous dependencies, like trigger pairs (Rosenfeld, 1994) or long distance n-gram language models (Huang etal., 1993). For better probability estimation, the model was extended to work with (hidden) word classes (Brown etal., 1992, Ward and Issar, 1996). A more error-driven approach is the use of hybrid language models, in which some detection mechanism (e.g. perplexity measures [Keene and O&apos;Kane, 1996] or topic detection [Mahajan et al., 1999]) selects or combines with a more appropriate language model. For Asian languages (e.g. Chinese, Japanese and Korean) represented by </context>
</contexts>
<marker>Jelinek, 1991</marker>
<rawString>Jelinek, F. (1991) &amp;quot;Up from trigrams&amp;quot;, Proc. Eurospeech 91, pp.181-184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Jin</author>
<author>Y Xia</author>
<author>X Chang</author>
</authors>
<title>Using contextual information to guide Chinese text recognition&amp;quot;,</title>
<date>1995</date>
<booktitle>Proc. ICCPOL &apos;95,</booktitle>
<pages>134--139</pages>
<contexts>
<context position="3247" citStr="Jin et al., 1995" startWordPosition="468" endWordPosition="471">riting recognition for computer entry, language models for Asian languages can be used for sentence-based keyboard input (e.g. Lochovsky and Chung, 1997), as well as detecting improper writing (e.g. dialectspecific words or expressions). Unlike Indo-European languages, words in these Asian languages are not delimited by space and conventional approximate string matching techniques (Wagner and Fisher, 1974; Oommen and Zhang, 1974) in handwriting recognition are seldom used in Asian language models. Instead, a widely used and reported Asian language model is the character-bigram language model (Jin et al., 1995; Xia et al., 1996) because it (1) achieved high recognition accuracy (around 90-96%) (2) is easy to estimate model parameters (3) can be processed quickly and (4) is relatively easy to implement. Improvement of these language models for IndoEuropean languages can be applied for the Asian languages but words need to be identified. For Asian languages, the model was integrated with syntactic rules (Chien, Chen and Lee, 1993). Class based language model (Lee and Tung, 1995) was also examined but the classes are based on semantically related words. A- new approach (Yang et al., 1998) is reported </context>
</contexts>
<marker>Jin, Xia, Chang, 1995</marker>
<rawString>Jin, Y., Y. Xia and X. Chang (1995) &amp;quot;Using contextual information to guide Chinese text recognition&amp;quot;, Proc. ICCPOL &apos;95, pp. 134-139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P E Kenne</author>
<author>M O&apos;Kane</author>
</authors>
<title>Hybrid language models and spontaneous legal discourse&amp;quot;,</title>
<date>1996</date>
<booktitle>Proc. ICSLP,</booktitle>
<volume>2</volume>
<pages>717--720</pages>
<marker>Kenne, O&apos;Kane, 1996</marker>
<rawString>Kenne, P.E. and M. O&apos;Kane (1996) &amp;quot;Hybrid language models and spontaneous legal discourse&amp;quot;, Proc. ICSLP, Vol. 2, pp. 717-720.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Kit</author>
<author>Y Liu</author>
<author>N Liang</author>
</authors>
<title>On methods of Chinese automatic word segmentation&amp;quot;,</title>
<date>1989</date>
<journal>Journal of Chinese Information Processing,</journal>
<volume>3</volume>
<pages>13--20</pages>
<contexts>
<context position="11729" citStr="Kit et al., 1989" startWordPosition="1798" endWordPosition="1801">choices from the candidate sets. Hence, the insufficient data problem may occur in that particular P,„„„. In Figure 2, we plot the likelihood of errors identified against the different logarithmic conditional probability values. When the recall increases, unfortunately, the precision drops. Figure 2: The precision, recall and accuracy (i.e. recall X precision) of detecting language model errors by examining the logarithm conditional probabilities on the maximum likelihood path. 1.2 Language-specific Features The language-specific features are based on applying the word segmentation algorithm (Kit et al., 1989) to the maximum likelihood path. The ROCLING (Chen and Huang, 1993) word list used for segmentation has 78,000+ entries. 120% 100% 80% I60% 40% 20 0% Precision recall —4.-- Accuracy &gt;1&apos; 60% 50% 40% 30% 20% 10% 0% 89 1.2.1 Features based on word length (F2,1) If the matched word in the maximum likelihood path is long, then we expect the likelihood of an error is low because long words are specific. Figure 3 shows the precision of detecting the matched word is correct and the recall of errors in multi-character words. In general, the longer the matched words, the more likely that they are correc</context>
</contexts>
<marker>Kit, Liu, Liang, 1989</marker>
<rawString>Kit, C., Y. Liu and N. Liang (1989) &amp;quot;On methods of Chinese automatic word segmentation&amp;quot;, Journal of Chinese Information Processing, 3:1, 13-20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H H-C Law</author>
<author>C Chan</author>
</authors>
<title>N-th order ergodic multigram HMM for modeling of languages without marked word boundaries&amp;quot;,</title>
<date>1996</date>
<booktitle>Proc. COLING 96,</booktitle>
<pages>2043--209</pages>
<marker>Law, Chan, 1996</marker>
<rawString>Law, H.H-C. and C. Chan (1996) &amp;quot;N-th order ergodic multigram HMM for modeling of languages without marked word boundaries&amp;quot;, Proc. COLING 96, pp. 2043-209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H-J Lee</author>
<author>C-H Tang</author>
</authors>
<title>A language model based on semantically clustered words in a Chinese character recognition system&amp;quot;,</title>
<date>1995</date>
<booktitle>Proc. 3rd Int Conf. on Document Analysis and Recognition,</booktitle>
<volume>Vol. I.,</volume>
<pages>450--453</pages>
<marker>Lee, Tang, 1995</marker>
<rawString>Lee, H-J. and C-H Tang (1995) &amp;quot;A language model based on semantically clustered words in a Chinese character recognition system&amp;quot;, Proc. 3rd Int Conf. on Document Analysis and Recognition, Vol. I., pp. 450-453.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M-Y Lin</author>
<author>T-H Chiang</author>
<author>K-Y Su</author>
</authors>
<title>A preliminary study on unknown word problem in Chinese word segmentation&amp;quot;,</title>
<date>1993</date>
<booktitle>Proc. ROCLING VI,</booktitle>
<pages>119--141</pages>
<contexts>
<context position="12714" citStr="Lin et al (1993)" startWordPosition="1972" endWordPosition="1975">ecause long words are specific. Figure 3 shows the precision of detecting the matched word is correct and the recall of errors in multi-character words. In general, the longer the matched words, the more likely that they are correct and the likelihood of missing undetected long words is small. 120% 100% 80% 60% 40% 20% 0% 2 3 4 5 6 7 Figure 3: The precision of correct matched words against word lengths. 1.2.2 Features based on single-character sequences (F2,2) In word segmentation, when there are no entries in the dictionary that can match, the input is segmented into single characters. Thus, Lin et al (1993) noted that single-character sequences after word segmentation might indicate segmentation problems. Here, we apply the same technique for the detection of errors. If we count on the per character basis, the recall of error is 80% and the precision in error identification is 35%. If we count multi-character words and a sequence of single-characters as blocks, then the recall of errors is 79% and the precision in finding one or more errors in the block is increased to 51%. 120% single-character sequences may depend on their length. Therefore, we plotted the recall and precision of detecting err</context>
</contexts>
<marker>Lin, Chiang, Su, 1993</marker>
<rawString>Lin, M-Y., T-H. Chiang and K-Y. Su (1993) &amp;quot;A preliminary study on unknown word problem in Chinese word segmentation&amp;quot;, Proc. ROCLING VI, pp.119-141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A F Lochovsky</author>
<author>K-H Chung</author>
</authors>
<title>Homonym resolution for Chinese phonetic input&amp;quot;,</title>
<date>1997</date>
<journal>Communications of COUPS,</journal>
<volume>7</volume>
<pages>5--15</pages>
<contexts>
<context position="2784" citStr="Lochovsky and Chung, 1997" startWordPosition="401" endWordPosition="404">on mechanism (e.g. perplexity measures [Keene and O&apos;Kane, 1996] or topic detection [Mahajan et al., 1999]) selects or combines with a more appropriate language model. For Asian languages (e.g. Chinese, Japanese and Korean) represented by ideographic characters, language models are widely used in computer entry because these Asian languages have a large set of characters (in thousands) that the conventional keyboard is not designed for. Apart from using speech and handwriting recognition for computer entry, language models for Asian languages can be used for sentence-based keyboard input (e.g. Lochovsky and Chung, 1997), as well as detecting improper writing (e.g. dialectspecific words or expressions). Unlike Indo-European languages, words in these Asian languages are not delimited by space and conventional approximate string matching techniques (Wagner and Fisher, 1974; Oommen and Zhang, 1974) in handwriting recognition are seldom used in Asian language models. Instead, a widely used and reported Asian language model is the character-bigram language model (Jin et al., 1995; Xia et al., 1996) because it (1) achieved high recognition accuracy (around 90-96%) (2) is easy to estimate model parameters (3) can be</context>
</contexts>
<marker>Lochovsky, Chung, 1997</marker>
<rawString>Lochovsky, A.F. and K-H. Chung (1997) &amp;quot;Homonym resolution for Chinese phonetic input&amp;quot;, Communications of COUPS, 7:1, 5-15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Mahajan</author>
<author>D Beeferman</author>
<author>X D Huang</author>
</authors>
<title>Improving topic-dependent modeling using information retrieval techniques&amp;quot;,</title>
<date>1999</date>
<booktitle>Proc. IEEE ICASSP 99,</booktitle>
<volume>Vol. I,</volume>
<pages>541--544</pages>
<contexts>
<context position="2262" citStr="Mahajan et al., 1999" startWordPosition="325" endWordPosition="328">, 1995). Various ways to improve language models were reported. First, the model has been extended with longer dependencies (e.g. trigram) (Jelinek, 1991) and using non-contiguous dependencies, like trigger pairs (Rosenfeld, 1994) or long distance n-gram language models (Huang etal., 1993). For better probability estimation, the model was extended to work with (hidden) word classes (Brown etal., 1992, Ward and Issar, 1996). A more error-driven approach is the use of hybrid language models, in which some detection mechanism (e.g. perplexity measures [Keene and O&apos;Kane, 1996] or topic detection [Mahajan et al., 1999]) selects or combines with a more appropriate language model. For Asian languages (e.g. Chinese, Japanese and Korean) represented by ideographic characters, language models are widely used in computer entry because these Asian languages have a large set of characters (in thousands) that the conventional keyboard is not designed for. Apart from using speech and handwriting recognition for computer entry, language models for Asian languages can be used for sentence-based keyboard input (e.g. Lochovsky and Chung, 1997), as well as detecting improper writing (e.g. dialectspecific words or express</context>
<context position="6251" citStr="Mahajan et al., 1999" startWordPosition="946" endWordPosition="949">approach is to automatically identify the errors and manually correcting them. The information about the correction of errors is used to improve the bigram language model. For example, the bigram probabilities of the language model may be estimated and updated with the corrected data. In this way, future occurrences of these errors are reduced. Another (hybrid) approach uses another language model to correct the identified errors. This language model can be computationally more expensive than the bigram language model because it is applied only to the identified errors. Also, topic detection (Mahajan et al., 1999) and language model selection (Keene and O&apos;Kane, 1996) can be applied to those area to find a more appropriate language model because usually topic-dependent words are those causing errors. Another (integrative) approach improves the language model accuracy using more sophisticated recognizers, instead of a complementary language model. The more sophisticated recognizer may give a set of different results that the bigram language model can re-apply on or this recognizer simply gives the recognized character. This integrates well with the coarse-fine recognition architecture proposed by Nagy (1</context>
</contexts>
<marker>Mahajan, Beeferman, Huang, 1999</marker>
<rawString>Mahajan, M., D. Beeferman and X.D. Huang (1999) &amp;quot;Improving topic-dependent modeling using information retrieval techniques&amp;quot;, Proc. IEEE ICASSP 99, Vol. I, pp.541-544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Nagy</author>
</authors>
<title>Chinese character recognition: twenty-five-year retrospective&amp;quot;, in</title>
<date>1988</date>
<booktitle>Proc. 9th Int. Conf on Pattern Recognition,</booktitle>
<volume>Vol. I,</volume>
<pages>163--167</pages>
<contexts>
<context position="6855" citStr="Nagy (1988)" startWordPosition="1034" endWordPosition="1035">, 1999) and language model selection (Keene and O&apos;Kane, 1996) can be applied to those area to find a more appropriate language model because usually topic-dependent words are those causing errors. Another (integrative) approach improves the language model accuracy using more sophisticated recognizers, instead of a complementary language model. The more sophisticated recognizer may give a set of different results that the bigram language model can re-apply on or this recognizer simply gives the recognized character. This integrates well with the coarse-fine recognition architecture proposed by Nagy (1988) back in the 1960s. Coarse recognition provides the candidates for the language model to select. Fine, expensive recognition is carried out only where the language models failed. Finally, it is possible to combine all the different approaches (i.e. adaptive, hybrid and integrative). Given the significance in detecting errors of language models, there is little work in this area. Perhaps, it was considered that these errors were random and therefore hard to detect. However, users can detect errors quickly. We suspect that some of these errors may be systematic due to the properties of the langu</context>
</contexts>
<marker>Nagy, 1988</marker>
<rawString>Nagy, G. (1988), &amp;quot;Chinese character recognition: twenty-five-year retrospective&amp;quot;, in Proc. 9th Int. Conf on Pattern Recognition, Vol. I, pp. 163-167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K S Nathan</author>
<author>H S M Beigi</author>
<author>J Subrahmonia</author>
<author>G J Clary</author>
<author>H Maruyama</author>
</authors>
<date>1995</date>
<note>Real-time on-</note>
<contexts>
<context position="1649" citStr="Nathan et al., 1995" startWordPosition="235" endWordPosition="238">t precision (81%) and skip ratio (76%) but its recall is the lowest (73%). Introduction Language models are important post-processing modules to improve recognition accuracy of a wide variety of input, namely speech recognition (Balh et al., 1983), handwritten recognition (Elliman and Lancaster, 1990) and printed character recognition (Sun, 1991), for many human languages. They can also be used for text correction (Ron et al., 1994) and part-of-speech tagging. For Indo-European languages, the word-bigram language model is used in speech recognition (Jelinek, 1989) and handwriting recognition (Nathan et al., 1995). Various ways to improve language models were reported. First, the model has been extended with longer dependencies (e.g. trigram) (Jelinek, 1991) and using non-contiguous dependencies, like trigger pairs (Rosenfeld, 1994) or long distance n-gram language models (Huang etal., 1993). For better probability estimation, the model was extended to work with (hidden) word classes (Brown etal., 1992, Ward and Issar, 1996). A more error-driven approach is the use of hybrid language models, in which some detection mechanism (e.g. perplexity measures [Keene and O&apos;Kane, 1996] or topic detection [Mahajan</context>
</contexts>
<marker>Nathan, Beigi, Subrahmonia, Clary, Maruyama, 1995</marker>
<rawString>Nathan, K.S., H.S.M. Beigi, J. Subrahmonia, G.J. Clary and H. Maruyama (1995) &amp;quot;Real-time on-</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Oommen</author>
<author>K Zhang</author>
</authors>
<title>The normalized string editing problem revisited&amp;quot;,</title>
<date>1996</date>
<journal>IEEE Trans. on PAMI,</journal>
<volume>18</volume>
<pages>669--672</pages>
<marker>Oommen, Zhang, 1996</marker>
<rawString>Oommen, B.J. and K. Zhang (1996) &amp;quot;The normalized string editing problem revisited&amp;quot;, IEEE Trans. on PAMI, 18:6, pp. 669-672.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Quinlan</author>
</authors>
<title>C4.5 programs for machine learning&amp;quot;,</title>
<date>1993</date>
<publisher>Morgan Kaufmann, CA.</publisher>
<contexts>
<context position="19583" citStr="Quinlan (1993)" startWordPosition="3101" endWordPosition="3102">n scheme assigns the correct class wc and the error class we, using the following rule: g(x) &gt; g( x) assign we ,Otherwise assign we where ge() and ge() are: g,(x)=—(x — E;&apos;(x - p,)— log Ec. I +21og p(w, ) g ,(x)= —(x — p,)T E;&apos;(x- p,)— log j +2 log p(w, ) ii and /4 are the mean vectors of the class we. and We, respectively, and Ee are the covariance matrices of the class we and We, respectively, and Id is the determinant. 2.2 Decision Tree Originally, we tried to use the support vector machine (SVM) (Vanpik, 1995) but it could not converge. Instead, we used the decision tree algorithm C4.5 by Quinlan (1993). Decision trees are known to produce good classification if clusters can be bounded by some hyper-rectilinear regions. We trained C4.5 with a set of feature vectors, described in Section 1.3. 2.3 Neural Network We use the multi-layer perceptron (MLP) because it can perform non-linear classification. The MLP has 3 layers of nodes: input, hidden and output. Nodes in the input layer are fully connected with those in the hidden layer. Likewise nodes in the hidden layer are fully connected to the output layer. For our application, one input node corresponds to a feature in section 1.3. The value o</context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>Quinlan, J.R. (1993) &amp;quot;C4.5 programs for machine learning&amp;quot;, Morgan Kaufmann, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Ron</author>
<author>Y Singer</author>
<author>N Tishby</author>
</authors>
<title>The power of Amnesia: learning probabilistic automata with variable memory length&amp;quot;, to appear in</title>
<date>1994</date>
<journal>Machine Learning</journal>
<contexts>
<context position="1465" citStr="Ron et al., 1994" startWordPosition="211" endWordPosition="214">ow (60%). Neural network produced good recall (75%) and precision (80%) but both Bayesian and Neural network have low skip ratio (65%). The decision tree classifier produced the best precision (81%) and skip ratio (76%) but its recall is the lowest (73%). Introduction Language models are important post-processing modules to improve recognition accuracy of a wide variety of input, namely speech recognition (Balh et al., 1983), handwritten recognition (Elliman and Lancaster, 1990) and printed character recognition (Sun, 1991), for many human languages. They can also be used for text correction (Ron et al., 1994) and part-of-speech tagging. For Indo-European languages, the word-bigram language model is used in speech recognition (Jelinek, 1989) and handwriting recognition (Nathan et al., 1995). Various ways to improve language models were reported. First, the model has been extended with longer dependencies (e.g. trigram) (Jelinek, 1991) and using non-contiguous dependencies, like trigger pairs (Rosenfeld, 1994) or long distance n-gram language models (Huang etal., 1993). For better probability estimation, the model was extended to work with (hidden) word classes (Brown etal., 1992, Ward and Issar, 19</context>
</contexts>
<marker>Ron, Singer, Tishby, 1994</marker>
<rawString>Ron, D., Y. Singer and N. Tishby (1994) &amp;quot;The power of Amnesia: learning probabilistic automata with variable memory length&amp;quot;, to appear in Machine Learning</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rosenfeld</author>
</authors>
<title>Adaptive statistical language modeling&amp;quot; a maximum entropy approach&amp;quot;,</title>
<date>1994</date>
<tech>Ph.D. Thesis,</tech>
<institution>School of Computer Science, Carnegie Mellon University,</institution>
<location>Pittsburgh.</location>
<contexts>
<context position="1872" citStr="Rosenfeld, 1994" startWordPosition="267" endWordPosition="268"> (Balh et al., 1983), handwritten recognition (Elliman and Lancaster, 1990) and printed character recognition (Sun, 1991), for many human languages. They can also be used for text correction (Ron et al., 1994) and part-of-speech tagging. For Indo-European languages, the word-bigram language model is used in speech recognition (Jelinek, 1989) and handwriting recognition (Nathan et al., 1995). Various ways to improve language models were reported. First, the model has been extended with longer dependencies (e.g. trigram) (Jelinek, 1991) and using non-contiguous dependencies, like trigger pairs (Rosenfeld, 1994) or long distance n-gram language models (Huang etal., 1993). For better probability estimation, the model was extended to work with (hidden) word classes (Brown etal., 1992, Ward and Issar, 1996). A more error-driven approach is the use of hybrid language models, in which some detection mechanism (e.g. perplexity measures [Keene and O&apos;Kane, 1996] or topic detection [Mahajan et al., 1999]) selects or combines with a more appropriate language model. For Asian languages (e.g. Chinese, Japanese and Korean) represented by ideographic characters, language models are widely used in computer entry be</context>
</contexts>
<marker>Rosenfeld, 1994</marker>
<rawString>Rosenfeld, R. (1994) &amp;quot;Adaptive statistical language modeling&amp;quot; a maximum entropy approach&amp;quot;, Ph.D. Thesis, School of Computer Science, Carnegie Mellon University, Pittsburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S W Sun</author>
</authors>
<title>A Contextual Postprocessing for Optical Chinese Character Recognition&amp;quot;,</title>
<date>1991</date>
<booktitle>in Procint. Sym. on Circuits and Systems,</booktitle>
<pages>2641--2644</pages>
<contexts>
<context position="1377" citStr="Sun, 1991" startWordPosition="197" endWordPosition="198">ian classifiers produce the best recall performance of 80% but the precision is low (60%). Neural network produced good recall (75%) and precision (80%) but both Bayesian and Neural network have low skip ratio (65%). The decision tree classifier produced the best precision (81%) and skip ratio (76%) but its recall is the lowest (73%). Introduction Language models are important post-processing modules to improve recognition accuracy of a wide variety of input, namely speech recognition (Balh et al., 1983), handwritten recognition (Elliman and Lancaster, 1990) and printed character recognition (Sun, 1991), for many human languages. They can also be used for text correction (Ron et al., 1994) and part-of-speech tagging. For Indo-European languages, the word-bigram language model is used in speech recognition (Jelinek, 1989) and handwriting recognition (Nathan et al., 1995). Various ways to improve language models were reported. First, the model has been extended with longer dependencies (e.g. trigram) (Jelinek, 1991) and using non-contiguous dependencies, like trigger pairs (Rosenfeld, 1994) or long distance n-gram language models (Huang etal., 1993). For better probability estimation, the mode</context>
</contexts>
<marker>Sun, 1991</marker>
<rawString>Sun, S.W. (1991), &amp;quot;A Contextual Postprocessing for Optical Chinese Character Recognition&amp;quot;, in Procint. Sym. on Circuits and Systems, pp. 2641-2644.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory,</title>
<date>1995</date>
<publisher>Springer-Verlag,</publisher>
<location>New York.</location>
<marker>Vapnik, 1995</marker>
<rawString>Vapnik, V. (1995) The Nature of Statistical Learning Theory, Springer-Verlag, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Van Rijsbergen</author>
</authors>
<title>Information Retrieval,</title>
<date>1979</date>
<location>Butterworths, London.</location>
<marker>Van Rijsbergen, 1979</marker>
<rawString>Van Rijsbergen (1979) Information Retrieval, Butterworths, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R A Wagner</author>
<author>M J Fisher</author>
</authors>
<title>The string to string correction problem&amp;quot;,</title>
<date>1974</date>
<journal>J. ACM,</journal>
<volume>21</volume>
<pages>168--173</pages>
<contexts>
<context position="3039" citStr="Wagner and Fisher, 1974" startWordPosition="436" endWordPosition="439">rs, language models are widely used in computer entry because these Asian languages have a large set of characters (in thousands) that the conventional keyboard is not designed for. Apart from using speech and handwriting recognition for computer entry, language models for Asian languages can be used for sentence-based keyboard input (e.g. Lochovsky and Chung, 1997), as well as detecting improper writing (e.g. dialectspecific words or expressions). Unlike Indo-European languages, words in these Asian languages are not delimited by space and conventional approximate string matching techniques (Wagner and Fisher, 1974; Oommen and Zhang, 1974) in handwriting recognition are seldom used in Asian language models. Instead, a widely used and reported Asian language model is the character-bigram language model (Jin et al., 1995; Xia et al., 1996) because it (1) achieved high recognition accuracy (around 90-96%) (2) is easy to estimate model parameters (3) can be processed quickly and (4) is relatively easy to implement. Improvement of these language models for IndoEuropean languages can be applied for the Asian languages but words need to be identified. For Asian languages, the model was integrated with syntacti</context>
</contexts>
<marker>Wagner, Fisher, 1974</marker>
<rawString>Wagner, R.A. and M.J. Fisher (1974) &amp;quot;The string to string correction problem&amp;quot;, J. ACM, 21:1, pp. 168-173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Ward</author>
<author>S Issar</author>
</authors>
<title>A class based language model for speech recognition&amp;quot;,</title>
<date>1996</date>
<booktitle>Proc. IEEE ICASSP 96,</booktitle>
<volume>1</volume>
<pages>416--418</pages>
<contexts>
<context position="2068" citStr="Ward and Issar, 1996" startWordPosition="295" endWordPosition="298">(Ron et al., 1994) and part-of-speech tagging. For Indo-European languages, the word-bigram language model is used in speech recognition (Jelinek, 1989) and handwriting recognition (Nathan et al., 1995). Various ways to improve language models were reported. First, the model has been extended with longer dependencies (e.g. trigram) (Jelinek, 1991) and using non-contiguous dependencies, like trigger pairs (Rosenfeld, 1994) or long distance n-gram language models (Huang etal., 1993). For better probability estimation, the model was extended to work with (hidden) word classes (Brown etal., 1992, Ward and Issar, 1996). A more error-driven approach is the use of hybrid language models, in which some detection mechanism (e.g. perplexity measures [Keene and O&apos;Kane, 1996] or topic detection [Mahajan et al., 1999]) selects or combines with a more appropriate language model. For Asian languages (e.g. Chinese, Japanese and Korean) represented by ideographic characters, language models are widely used in computer entry because these Asian languages have a large set of characters (in thousands) that the conventional keyboard is not designed for. Apart from using speech and handwriting recognition for computer entry</context>
</contexts>
<marker>Ward, Issar, 1996</marker>
<rawString>Ward, W. and S. Issar (1996) &amp;quot;A class based language model for speech recognition&amp;quot;, Proc. IEEE ICASSP 96, Vol. 1, pp.416-418.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P-K Wong</author>
<author>C Chan</author>
</authors>
<title>Postprocessing statistical language models for handwritten Chinese character recognizer&amp;quot;,</title>
<date>1999</date>
<journal>IEEE Trans. SMC, Part B,</journal>
<volume>29</volume>
<pages>286--291</pages>
<marker>Wong, Chan, 1999</marker>
<rawString>Wong, P-K. and C. Chan (1999) &amp;quot;Postprocessing statistical language models for handwritten Chinese character recognizer&amp;quot;, IEEE Trans. SMC, Part B, 29:2, 286-291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Xia</author>
<author>S Ma</author>
<author>M Sun</author>
<author>X Zhu</author>
<author>Y Jin</author>
<author>X Chang</author>
</authors>
<title>Automatic post-processing of offline handwritten Chinese text recognition&amp;quot;,</title>
<date>1996</date>
<booktitle>Proc. ICCC,</booktitle>
<pages>413--416</pages>
<contexts>
<context position="3266" citStr="Xia et al., 1996" startWordPosition="472" endWordPosition="475"> for computer entry, language models for Asian languages can be used for sentence-based keyboard input (e.g. Lochovsky and Chung, 1997), as well as detecting improper writing (e.g. dialectspecific words or expressions). Unlike Indo-European languages, words in these Asian languages are not delimited by space and conventional approximate string matching techniques (Wagner and Fisher, 1974; Oommen and Zhang, 1974) in handwriting recognition are seldom used in Asian language models. Instead, a widely used and reported Asian language model is the character-bigram language model (Jin et al., 1995; Xia et al., 1996) because it (1) achieved high recognition accuracy (around 90-96%) (2) is easy to estimate model parameters (3) can be processed quickly and (4) is relatively easy to implement. Improvement of these language models for IndoEuropean languages can be applied for the Asian languages but words need to be identified. For Asian languages, the model was integrated with syntactic rules (Chien, Chen and Lee, 1993). Class based language model (Lee and Tung, 1995) was also examined but the classes are based on semantically related words. A- new approach (Yang et al., 1998) is reported using segments 87 e</context>
</contexts>
<marker>Xia, Ma, Sun, Zhu, Jin, Chang, 1996</marker>
<rawString>Xia, Y., S. Ma, M. Sun, X. Zhu, Y. Jin and X. Chang (1996) &amp;quot;Automatic post-processing of offline handwritten Chinese text recognition&amp;quot;, Proc. ICCC, pp. 413-416.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K-C Yang</author>
<author>T-H Ho</author>
<author>L-F Chien</author>
<author>L-S Lee</author>
</authors>
<title>Statistics-based segment pattern lexicon -a new direction for Chinese language modeling&amp;quot;,</title>
<date>1998</date>
<booktitle>Proc. IEEE ICASSP 98,</booktitle>
<volume>1</volume>
<pages>169--172</pages>
<contexts>
<context position="3834" citStr="Yang et al., 1998" startWordPosition="564" endWordPosition="567">anguage model (Jin et al., 1995; Xia et al., 1996) because it (1) achieved high recognition accuracy (around 90-96%) (2) is easy to estimate model parameters (3) can be processed quickly and (4) is relatively easy to implement. Improvement of these language models for IndoEuropean languages can be applied for the Asian languages but words need to be identified. For Asian languages, the model was integrated with syntactic rules (Chien, Chen and Lee, 1993). Class based language model (Lee and Tung, 1995) was also examined but the classes are based on semantically related words. A- new approach (Yang et al., 1998) is reported using segments 87 expressed by prefix and suffix trees but the comparison is based on perplexity measures, which may not correlate well with recognition improvement (Iyer et al., 1997). While attempts to improve the (bigram) language models were (quite) successful, the high recognition accuracy (about 96%) is not adequate for professional data entry services, which typically require an error rate lower than 1 in 1,000. As part of the quality control exercises, these services estimate their error rate by sampling, and they identify and correct the errors manually to achieve the req</context>
</contexts>
<marker>Yang, Ho, Chien, Lee, 1998</marker>
<rawString>Yang, K-C., T-H. Ho, L-F. Chien and L-S. Lee (1998) &amp;quot;Statistics-based segment pattern lexicon -a new direction for Chinese language modeling&amp;quot;, Proc. IEEE ICASSP 98, Vol. 1., pp.169-172.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>