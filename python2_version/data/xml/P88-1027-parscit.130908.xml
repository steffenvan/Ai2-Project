<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000157">
<note confidence="0.90296">
PARSING VS. TEXT PROCESSING
IN THE ANALYSIS OF DICTIONARY DEFINITIONS
Thomas Ahlswede and Martha Evens
Computer Science Dept.
Illinois Institute of Technology
Chicago, IL 60616
312-567-5153
</note>
<sectionHeader confidence="0.836303" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.995815425531915">
We have analyzed definitions from Webster&apos;s
Seventh New Collegiate Dictionary using Sager&apos;s
Linguistic String Parser and again using basic UNIX
text processing utilities such as grep and awk. This
paper evaluates both procedures, compares their
results, and discusses possible future lines of research
exploiting and combining their respective strengths.
Introduction
As natural language systems grow more
sophisticated, they need larger and more detailed
lexicons. Efforts to automate the process of
generating lexicons have been going on for years,
and have often been combined with the analysis of
machine-readable dictionaries.
Since 1979, a group at M&apos; under the
leadership of Martha Evens has been using the
machine-readable version of Webster&apos;s Seventh New
Collegiate Dictionary (W7) in text generation,
information retrieval, and the theory of lexical-
semantic relations. This paper describes some of our
recent work in extracting semantic information from
W7, primarily in the form of word pairs linked by
lexical-semantic relations. We have used two
methods: parsing definitions with Sager&apos;s Linguistic
String Parser (LSP) and text processing with a
combination of UNIX utilities and interactive editing.
We will use the terms &amp;quot;parsing&amp;quot; and &amp;quot;text
processing&amp;quot; here primarily with reference to our own
use of the LSP and UNIX utilities respectively, but
will also use them more broadly. &amp;quot;Parsing&amp;quot; in this
more general sense will mean a computational
technique of text analysis drawing on an extensive
database of linguistic knowledge, e.g., the lexicon,
syntax and/or semantics of English; &amp;quot;text processing&amp;quot;
will refer to any computational technique that
involves little or no such knowledge.
This research is supported by National Science
Foundation grant IST 87-03580. Our thanks also to
the G &amp; C Merriam Company for permission to use
the dictionary tapes.
Our model of the lexicon emphasizes lexical
and semantic relations between words. Some of
these relationships are familiar. Anyone who has
used a dictionary or thesaurus has encountered
synonymy, and perhaps also antonymy. W7 abounds
in synonyms (the capitalized words in the examples
below):
</bodyText>
<listItem confidence="0.975025">
(1) funny 1 la aj affording light mirth and
laughter: AMUSING
(2) funny 1 lb aj seeking or intended to amuse
: FACETIOUS
</listItem>
<bodyText confidence="0.9996354">
Our notation for dictionary definitions consists of: (1)
the entry (word or phrase being defined); (2) the
homograph number (multiple homographs are given
separate entries in W7); (3) the sense number, which
may include a subsense letter and even a sub-
subsense number (e.g. 2b3); (4) the text of the
definition.
We commonly express a relation between
words through a triple consisting of Word 1, Relation,
Word2:
</bodyText>
<listItem confidence="0.990447">
(3) funny SYN amusing
(4) funny SYN facetious
</listItem>
<bodyText confidence="0.99921775">
A third relation, particularly important in W7
and in dictionaries generally, is taxonomy, the
species-genus relation or (in artificial intelligence)
the IS-A relation. Consider the entries:
</bodyText>
<listItem confidence="0.8157975">
(5) dodecahedron 00 n a solid having 12 plane
faces
(6) build 11 vi to form by ordering and uniting
materials . . .
</listItem>
<bodyText confidence="0.819658">
These definitions yield the taxonomy triples
</bodyText>
<listItem confidence="0.989053">
(7) dodecahedron TAX solid
(8) build TAX form
</listItem>
<bodyText confidence="0.99671775">
Taxonomy is not explicit in definitions, as is
synonymy, but is implied in their very structure.
Some other relations have been frequently observed,
e.g.:
</bodyText>
<listItem confidence="0.9955265">
(9) driveshaft PART engine
(10) wood COMES-FROM tree
</listItem>
<page confidence="0.997146">
217
</page>
<bodyText confidence="0.993016682352942">
The usefulness of relations in information
retrieval is demonstrated in Wang et al. [1985] as
well as in Fox [1980]. Relations are also important in
giving coherence to text, as shown by Halliday and
Hasan [1977]. They are abundant in a typical
English language dictionary, as we will see later.
We have recognized, however, that word-
relation-word triples are not adequate, or at least not
optimal, for expressing all the useful information
associated with words. Some information is best
expressed as unary attributes or features. We have
also recognized that phrases and even larger
structures may on one hand be in some ways
equivalent to single words, as pointed out by Becker
[1975], or may on the other hand express complex
facts that cannot be reduced to any combination of
word-to-word links.
Parsing
Recognizing the vastness of the task of
parsing a whole dictionary, most computational
lexicologists have preferred approaches less
computationally intensive and more specifically
suited to their immediate goals. A partial exception
is Amsler [1980], who proposed a simple ATN
grammar for some definitions in the Merriam-
Webster Pocket Dictionary. More recently, Jensen
and her coworkers at IBM have also parsed
definitions. But the record shows that dictionary
researchers have avoided parsing. One of our
questions was, how justified is this avoidance? How
much harder is parsing, and what rewards, if any,
will the effort yield?
• We used Sager&apos;s Linguistic String Parser, as
we have done for several years. It has been
continuously developed since the 1970s and by now
has a very extensive and powerful user interface as
well as a large English grammar and a vocabulary
(the LSP Dictionary) of over 10,000 words. It is not
exceptionally fast — a fact which should be taken
into account in evaluating the performance of parsers
generally in dictionary analysis.
Our efforts to parse W7 definitions began
with simple LSP grammars for small sets of adjective
[Ahlswede, 1985] and adverb [Klick, 1981]
definitions. These led eventually to a large grammar
of noun, verb and adjective definitions [Ahlswede,
1988], based on the Linguistic String Project&apos;s full
English grammar [Sager, 1981], and using the LSP&apos;s
full set of resources, including restrictions,
transformations, and special output generation
routines. All of these grammars have been used not
only to create parse trees but also (and primarily) to
generate relational triples linking defined words to
the major words used in their definitions.
The large definition grammar is described
more fully in Ahlswede [1988]. We are concerned
here with its performance: its success in parsing
definitions with a minimum of incorrect or
improbable parses, its success in identifying
relational triples, and its speed.
Input to the parser was a set of 8,832
definition texts from the machine-readable W7,
chosen because their vocabulary permitted them to be
parsed without enlarging the LSP&apos;s vocabulary.
For parsing, the 8,832-definition subset was
sorted by part of speech and broken into 100-
definition blocks of nouns, transitive verbs,
intransitive verbs, and adjectives. Limiting the
selection to nouns, verbs and adjectives reduced the
subset to 8,211, including 2,949 nouns, 1,451
adjectives, 1,272 intransitive verbs, and 2,549
transitive verbs.
We were able to speed up the parsing process
considerably by automatically extracting
subvocabularies from the LSP vocabulary, so that
for a 100-definition input sample, for instance, the
parser would only have to search through about 300
words instead of 10,000.
Parsing the subset eventually required a little
under 180 hours of CPU time on two machines, a
Vax 8300 and a Vax 750. Total clock time required
was very little more than this, however, since almost
all the parsing was done at night when the systems
were otherwise idle. Table 1 compares the LSP&apos;s
performance in the four part of speech categories.
</bodyText>
<table confidence="0.95671725">
Part of Pct. of Avg. no. Time (sec.) Triples
speech of defs. of parses per parse generated
defd. word parsed per success per success
nouns 77.63 1.70 11.05 11.46
adjectives 68.15 1.85 10.59 5.45
int. verbs 64.62 1.59 11.96 6.62
U. verbs 60.29 1.50 43.33 9.15
average 68.65 1.66 18.89 9.06
</table>
<tableCaption confidence="0.980921">
Table 1. Performance time and parsing
</tableCaption>
<bodyText confidence="0.908532">
efficiency of LSP by part of speech of words defined
(adapted from Fox et al., 1988)
In most cases, there is little variation among
the parts of speech. The most obvious discrepancy is
the slow parsing time for transitive verbs. We are not
yet sure why this is, but we suspect it has to do with
W7&apos;s practice of representing the defined verb&apos;s
direct object by an empty slot in the definition:
(11) madden 0 2 vt to rnake intensely angry
</bodyText>
<page confidence="0.996876">
218
</page>
<bodyText confidence="0.968140527777778">
(12) magnetize 02 vt to communicate magnetic
properties to
The total number of triples generated was
51,115 and the number of unique triples was 25,178.
The most common triples were 5,086 taxonomies and
7,971 modification relations. (Modification involved.
any word or phrase in the definition that modified the
headword; thus a definition such as &amp;quot;cube: a regular
solid . . .&amp;quot; would yield the modification triple (cube
MOD regular)).
We also identified 125 other relations, in three
categories: (1) &amp;quot;traditional&amp;quot; relations, identified by
previous researchers, which we hope to associate
with axioms for making inferences; (2) syntactic
relations between the defined word and various
defining words, such as (in a verb definition) the
direct object of the head verb, which we will
investigate for possible consistent semantic
significance; and (3) syntactic relations within the
body of the definition, such as modifier-head, verb-
object, etc. The relations in this last category were
built into our grammar; we were simply collecting
statistics on their occurrence, which we hope
eventually to test for the existence of dictionary-
specific selectional categories above and beyond the
general English selectional categories already present
in the LSP grammar.
Figure 1 shows a sample definition and the
triples the parser found in it.
ABDOMEN 0 1 N THE PART OF THE BODY
BETWEEN THE, THORAX AND THE
PELVIS
(THE) pmod (PART)
(ABDOMEN 0 1 N) lm (THE)
(ABDOMEN 0 1 N) t (PART)
(ABDOMEN 0 1 N) rm (OF THE BODY BETWEEN
</bodyText>
<figure confidence="0.960381571428571">
THE THORAX AND THE PELVIS)
(THE) pmod (BODY)
(THE) pmod (PELVIS)
(THE) pmod (THORAX)
(BETWEEN) pobj (THORAX)
(BETWEEN) pobj (PELVIS)
(ABDOMEN 0 1 N) part (BODY)
</figure>
<figureCaption confidence="0.999951">
Figure 1. A definition and its relational triples
</figureCaption>
<bodyText confidence="0.99842893220339">
In this definition, &amp;quot;part&amp;quot; is a typical category
1 relation, recognized by virtually all students of
relations, though they may disagree about its exact
nature. &amp;quot;in&amp;quot; and &amp;quot;nn&amp;quot; are left and right
modification. As can be seen, &amp;quot;fin&amp;quot; does not involve
analysis of the long postnominal modifier phrase.
&amp;quot;pmod&amp;quot; and &amp;quot;pobj&amp;quot; are permissible modifier and
permissible object, respectively; these are among the
most common category 3 relations.
We began with a list of about fifty relations,
intending to generate plain parse trees and then
examine them for relational triples in a separate step.
It soon became clear, however, that the LSP itself
was the best tool available for extracting information
from parse trees, especially its own parse trees.
Therefore we added a section to the grammar
consisting of routines for identifying relations and
printing out triples. The LSP&apos;s Restriction Language
permitted us to keep this section physically separate
from the rest of the grammar and thus to treat it as an
independent piece of code. Having done this, we
were able to add new relations in the course of
developing the grammar.
Approximately a third of the definitions in the
sample could not be parsed with this grammar.
During development of the grammar, we uncovered a
great many reasons why definitions failed to parse;
there remains no one fix which will add more than a
few definitions to the success list. However, some
general problem areas can be identified.
One common cause of failure is the inability
of the grammar to deal with all the nuances of
adjective comparison:
(13) accelerate 0 1 vt to bring about at an earlier
point of time
Idiomatic usages of common words are a frequent
source of failure:
(14) accommodate 0 3c vt to make room for
There are some errors in the input, for example an
intransitive verb definition labeled as transitive:
(15) ache 1 2 vt to become filled with painful
yearning
As column 3 of Table 1 indicates, many
definitions yielded multiple parses. Multiple parses
were responsible for most of the duplicate relational
triples.
Finding relational triples by text processing
As the performance statistics above show,
parsing is painfully slow. For the simple business of
finding and writing relational triples, it turns out to be
much less efficient than a combination of text
processing with interactive editing.
We first used straight text processing to
identify synonym references in definitions and reduce
them to triples. Our next essay in the text
processing/editing method began as a casual
experiment. We extracted the set of intransitive verb
definitions, suspecting that these would be the easiest
to work with. This is the smallest of the four major
</bodyText>
<page confidence="0.995258">
219
</page>
<bodyText confidence="0.991729">
W7 part of speech categories (the others being nouns,
adjectives, and transitive verbs) with 8,883 texts.
Virtually all verb definition texts begin with
to followed by a head verb, or a set of conjoined head
verbs. The most common words in the second
position in intransitive verb definitions, along with
their typical complements, were:
</bodyText>
<figure confidence="0.591098625">
become + noun or adj. phrase
(774 occurrences in 8,482 definitions)
make + noun phrase [+ adj. phrase]
(526 occurrences)
be + various
(408 occurrences)
move + adverbial phrase
(388 occurrences)
</figure>
<bodyText confidence="0.99618425">
Definitions in become, make and move had
such consistent forms that the core word or words in
the object or complement phrase were easy to
identify. Occasional prepositional phrases or other
posmominal constructions were easy to edit out by
hand. From these, and from some definitions in serve
as, we were able to generate triples representing five
relations.
</bodyText>
<listItem confidence="0.981393538461538">
(16) age 2 2b vi to become mellow or mature
(17) (age 2 2b vi) va-incep (mature)
(18) (age 2 2b vi) va-incep (mellow)
(19) add 0 2b vi to make an addition
(20) (add 0 2b vi) vn-cause (addition)
(21) accelerate 0 1 vi to move faster
(22) (accelerate 0 1 vi) move (faster)
(23) add 0 2a vi to serve as an addition
(24) (add 0 2a vi) vn-be (addition)
(25) annotate 0 0 vi to make or furnish critical or
explanatory notes
(26) (annotate 00 vi) va-cause (critical)
(27) (annotate 00 vi) va-cause (explanatory)
</listItem>
<bodyText confidence="0.999975897058824">
We also attempted to generate taxonomic
triples for intransitive verbs. In verb definitions, we
identified conjoined headwords, and otherwise
deleted everything to the right of the last headword.
This was straightforward and gave us almost 10,000
triples.
These triples are of mixed quality, however.
Those representing very common headwords such as
be or become are vacuous; worse, our lexically dumb
algorithm could not recognize phrasal verbs, so that a
phrasal head term such as take place appears as as
take, with misleading results.
The vacuous triples can easily be removed
from the total, however, and the incorrect triples
resulting from broken phrasal head terms are
relatively few. We therefore felt we had been highly
successful, and were inspired to proceed with nouns.
As with verbs, we are primarily interested in relations
other than taxonomy, and these are most commonly
found in the often lengthy post-headword part of the
definitions.
The problems we encountered with nouns
were generally the same as with intransitive verbs,
but accentuated by the much larger number (80,022)
of noun definition texts. Also, as Chodorow et al.
[1985] . have noted, the boundary between the
headword and the postnotninal part of the definition
is much harder to identify in noun definitions than in
verb definitions. Our first algorithm, which had no
lexical knowledge except of prepositions, was about
88% correct in finding the boundary.
In order to get better results, we needed an
algorithm comparable to Chodorow&apos;s Head Finder,
which uses part of speech information. Our strategy
is first to tag each word in each definition with all its
possible parts of speech, then to step through the
definitions, using Chodorow&apos;s heuristics (plus any
others we can find or invent) to mark prenoun-noun
and noun-postnoun boundaries.
The first step in tagging is to generate a
tagged vocabulary. We used an awk program to step
through the entries and run-ons, appending to each
one its pan or parts of speech. (A run-on is a
subentry, giving information about a word or phrase
derived from the entry word or phrase; for instance,
the verb run has the run-ons run across, run after,
and run a temperature among others; the noun rune
has the run-on adjective runic.) Archaic, obsolete, or
dialect forms were marked as such by W7 and could
be excluded.
Turning to W7&apos;s defining vocabulary, the
words (and/or phrases) actually employed in
definitions, we used Mayer&apos;s morphological analyzer
[1988] to identify regular noun plurals, adjective
comparatives and superlatives, and verb tense forms.
Following suggestions by Peterson [1982], we
assumed that words ending in -ia and -ae (virtually
all appearing in scientific names) were nouns.
We then added to our tagged vocabulary
those irregular noun plurals and verb tense forms
expressly given in W7. Unfortunately, neither W7
nor Mayer&apos;s program provides for derived
compounds with irregular plurals; for instance, W7
indicates men as the plural of man but there are over
300 nouns ending in -man for which no plural is
shown. Most of these (e.g., salesman, trencherman)
take plurals in -men but others (German, shaman) do
not. These had to be identified by hand. Another
</bodyText>
<page confidence="0.987967">
220
</page>
<bodyText confidence="0.999362884615385">
group of nouns, whose plurals we found convenient
rather than absolutely necessary to treat by hand, is
the 200 or so ending in -ch. (Those with a hard -ch
(patriarch, loch) take plurals in -chs; the rest take
plurals in -cher.) We could have exploited W7&apos;s
pronunciation information to distinguish these, but
the work would have been well out of proportion to
the scale of the task.
After some more of this kind of work, we had
a tagged vocabulary of 46,566 words used in W7
definitions. For the next step, we chose to generate
tagged blocks of definitions (rather than perform
tagging on the fly). We wrote a C program to read a
text file and replace each word with its tagged
counterpart. (We are not yet attempting to deal with
phrases.)
Head finding on noun definitions was done
with an awk program which examines consecutive
pairs of words (working from right to left) and marks
prenoun-noun and noun-posthoun boundaries. It
recognizes certain kinds of word sequences as
beyond its ability to disambiguate, e.g.:
(28) alarm 1 2a n a ( signal )? warning ) of
danger
(29) aflatus 0 0 n a divine )? imparting ) of
knowledge or power
The result of all this effort is a rudimentary
parsing system, in which the tagged vocabulary is the
lexicon, the tagging program is the lexical analyzer,
and the head finder is a syntax analyzer using a very
simple finite state grammar of about ten rules.
Despite its lack of linguistic sophistication, this is a
clear step in the direction of parsing.
And the effort seems to be justified.
Development took about four weeks, most of it spent
on the lexicon. (And, to be sure, more work is still
needed.) This is more than we expected, but
considerably less than the eight man-months spent
developing and testing the LSP definition grammar.
Tagging and head finding were performed on
a sample of 2157 noun definition texts, covering the
nouns from a through anode. 170 were flagged as
ambiguous; of the remaining 1987, all but 58 were
correct for a success rate of 97.1 percent.
In 37 of the 58 failures, the head finder
mistakenly identified a noun (or polysemous
adjective/noun) modifying the head as an
independent noun:
(30) agiotage 0 1 n ( exchange ) business
(31) alpha 1 3 n the ( chief ) or brightest star of
a constellation
There were 5 cases of misidentification of a
following adjective (parsable as a noun) as the head
noun:
(32) air mile 0 0 n a unit equal ) to 6076.1154
feet
The remaining failures resulted from errors in the
creation of the tagged vocabulary (5), non-definition
dictionary lines incorrectly labeled as definition texts
(5), and non-noun definitions incorrectly labeled as
noun definitions (6). The last two categories arose
from errors in our original W7 tape.
Among the 170 definitions flagged as
ambiguous, there were two mislabeled definitions
and one vocabulary error. There were 128 cases of
noun followed by an -ing form; in 116 of these the
-mg form was a participle, otherwise it was the head
noun. (The other case flagged as ambiguous was of a
possible head followed by a preposition also parsable
as an adjective. This flag turned out to be
unnecessary.) There were also seven instances of
miscellaneous misidentification of a modifying noun
as the head. Thus the &amp;quot;success rate&amp;quot; among these
definitions was 148/170 or 87.1 percent.
We are still working on improving the head
finder, as well as developing similar &amp;quot;grammars&amp;quot; for
postnominal phrases and for the major phrase
structures of other definition types. In the course of
this work we expect to solve the major &apos;problem in
this particular grammar, that of prenominal modifiers
identified as heads.
Parsing, again
Simple text processing, even without such
lexical knowledge as parts of speech, is about as
accurate as parsing in terms of correct vs. incorrect
relational triples identified. (It should be noted that
both methods require hand checking of the output,
and it seems unlikely that we will ever completely
eliminate this step.) The text processing strategy can
be applied to the entire corpus of definitions, without
the labor of enlarging a parser lexicon such as the
LSP Dictionary. And it is much faster.
This way of looking at our results may make
it appear that parsing was a waste of time and effort,
of value only as a lesson in how not to go about
dictionary analysis. Before coming to any such
conclusion, however, we should consider some other
factors.
It has been suggested that a more &amp;quot;modern&amp;quot;
parser than the LSP could give much faster parsing
times. At least part of the slowness of the LSP is due
to the completeness of its associated English
grammar, perhaps the most detailed grammar
associated with any natural language parser. Thus a
</bodyText>
<page confidence="0.994746">
221
</page>
<bodyText confidence="0.990918">
probable tradeoff for greater speed would be a lower
percentage of definitions successfully parsed.
Nonetheless, it appears that the immediate
future of parsing in the analysis of dictionary
definitions or of any other large text corpus lies in a
simpler, less computationally intensive parsing
technique. In addition, a parser for definition
analysis needs to be able to return partial parses of
difficult definitions. As we have seen, even the
LSP&apos;s detailed grammar failed to parse about a third
of the definitions it was given. A partial parse
capability would facilitate the use of simpler
grammars.
For further work with the machine-readable
W7, another valuable feature would be the ability to
handle ill-formed input. This is perhaps startling,
since a dictionary is supposed to be the epitome of
wellfonnedness, by definition as it were. However,
Peterson [1982] counted 903 typographical and
spelling errors in the machine-readable W7
(including ten errors carried over from the printed
W7), and my experience suggests that his count was
conservative. Such errors are probably little or no
problem in more recent MRDs, which are used as
typesetter input and are therefore exactly as correct
as the printed dictionary; errors creep into these
dictionaries in other places, as Boguraev [1988]
discovered in his study of the grammar codes in the
Longman Dictionary of Contemporary English.
Before choosing or designing the best parser
for the task, it is worthwhile to define an appropriate
task: to determine what sort of information one can
get from parsing that is impossible or impractical to
get by easier means.
One obvious approach is to use parsing as a
backup. For instance, one category of definitions that
has steadfastly resisted our text processing analysis is
that of verb definitions whose headword is a verb
plus separable particle, e.g. give up. A text
processing program using part-of-speech tagged
input can, however, flag these and other troublesome
definitions for further analysis.
It still seems, though, that we should be able
to use parsing more ambitiously than this. It is
intrinsically more powerful; the techniques we refer
to here as &amp;quot;text processing&amp;quot; mostly only extract
single, stereotyped fragments of information. The
most powerful of them, the head finder, still performs
only one simple grammatical operation: finding the
nuclei of noun phrases. In contrast, a &amp;quot;real&amp;quot; parser
generates a parse tree containing a wealth of
structural and relational information that cannot be
adequately represented by a formalism such as
word-relation-word triples, feature lists, etc.
Only in the simplest definitions does our
present set of relations give us a complete analysis.
In most definitions, we are forced to throw away
essential information. The definition
(33) dodecahedron 0 0 n a solid having 12 plane
faces
gives us two relational triples:
</bodyText>
<listItem confidence="0.5724515">
(34) (dodecahedron 00 n) t (solid)
(35) (dodecahedron 0 On) nn-aur (face)
</listItem>
<bodyText confidence="0.9564512">
The first triple is straightforward. The second triple
tells us that the noun dodecahedron has the (noun)
attribute face, i.e. that a dodecahedron has faces.
But the relational triple structure, by itself, cannot
capture the information that the dodecahedron has
specifically 12 faces. We could add another triple
(36) (face) nn-attr (12)
i.e., saying that faces have the attribute of (a
cardinality of) 12, but this triple is correct only in the
context of the definition of a dodecahedron. It is not
permanently or generically true, as are (28) and (29).
The information is present, however, in the
parse tree we get from the LSP. It can be made
somewhat more accessible by putting it into a
dependency form such as
</bodyText>
<listItem confidence="0.632823">
(37) (solid (a) (having (face (plural) (12)
(plane))))
</listItem>
<bodyText confidence="0.999348208333333">
which indicates not only that face is an attribute of
that solid which is a dodecahedron, but that the
cardinality 12 is an attribute of face in this particular
case, as is also plane.
In order to be really useful, a structure such as
this must have conjunction phrases expanded,
passives inverted, inflected forms analyzed, and other
modifications of the kind often brought under the
rubric of &amp;quot;transformations.&amp;quot; The LSP can do this son
of thing very well. The defining words also need to
be disambiguated. We do not hope for any fully
automatic way to do this, but co-occurrence of
defining words, perhaps weighted according to their
position in the dependency structure, would reduce
the human disambiguator&apos;s task to one of post-
editing. This might perhaps be further simplified by
a customized interactive editing facility.
We do not need to set up an elaborate
network data structure, though; the Lisp-like tree
structure, once it is transformed and its elements
disambiguated, constitutes a set of implicit pointers
to the definitions of the various words.
Even with all this work done, however, a big
gap remains between words and ideal semantic
</bodyText>
<page confidence="0.990233">
222
</page>
<bodyText confidence="0.98794601754386">
concepts. Let us consider the ways in which W7 has
defined all five basic polyhedrons:
(38) dodecahedron 0 0 n a solid having 12 plane
faces
(39) cube 1 1 n the regular solid of six equal
square sides
(40) icosahalron 0 0 n a polyhedron having 20
faces
(41) octahedron 0 0 n a solid bounded by eight
plane faces
(42) tetrahedron 00 n a polyhedron of four faces
(43) polyhedron 0 0 n a solid formed by plane
faces
The five polyhedrons differ only in their
number of faces, apart from the cube&apos;s additional
attribute of being regular. There is no reason why a
single syntactic/semantic structure could not be used
to define all five polyhedrons. Despite this, no two of
the definitions have the same structure. These
definitions illustrate that, even though W7 is fairly
stereotyped in its language, it is not nearly as
stereotyped as it needs to be for large scale,
automatic semantic analysis. We are going to need a
great deal of sophistication in synonymy and moving
around the taxonomic hierarchy. (It is worth
repeating, however, that in building our lexicon, we
have no intention of relying exclusively on the
information contained in W7).
Figure 2 shows a small part of a possible
network. In this sample, the definitions have been
parsed into a Lisp-like dependency structure, with
some transformations such as inversion of passives,
but no attempt to fit the polyhedron definitions into a
single semantic format.
(cube 1 1) T (solid 3 1 (the) (regular)
(of (side 1 6b (PL) (six)
(equal) (square))))
(dodecahedron 0 0) T (solid 3 1 (a)
(have (OBJ (face 1 5a5 (PL)
(12) (plane)))))
(icosahedron 0 0) T (polyhedron (a)
(have (OBJ (face 1 5a5 (PL)
(20)))))
(octahedron 0 0) T (solid 3 1 (a)
(bound (SUBJ (face 1 5a5 (PL)
(eight) (plane)))))
(tetrahedron 0 0) T (polyhedron (a) (of
(face 1 5a5 (Pq..) (four))))
(polyhedron 0 0) T (solid 3 1 (a) (form
(SUBJ (face 1 5a5 (PL)
(plane)))))
(solid 3 1) T (figure (a) (geometrical)
(have (OBJ (dimension (PL)
(three)))))
(face 1 5a5) T (surface 1 2 (plane)
(bound (OBJ (solid 3 1 (a)
(geometric)))))
</bodyText>
<figure confidence="0.6039325">
(side 1 6a) T (line (a) (bound (OBJ
(NULL))) (of (figure (a)
(geometrical))))
(side 1 6b) T (surface 1 2 (delimit
(OBJ (solid (a)))))
(surface 1 2) T (locus (a) (or (plane)
(curved)) (two-dimensional)
(of (point (PL)). . .))
</figure>
<figureCaption confidence="0.999437">
Figure 2. Part of a &amp;quot;network&amp;quot; of parsed definitions
</figureCaption>
<bodyText confidence="0.997249323529412">
If this formalism does not look much like a
network, imagine each word in each definition (the
part of the node to the right of the taxonomy marker
&amp;quot;T&amp;quot;) serving as a pointer to its own defining node.
The resulting network is quite dense. We simplify by
leaving out other parts of the lexical entry, and by
including only a few disambiguations, just to give the
flavor of their presence. Disambiguation of a word is
indicated by the inclusion of its homograph and sense
numbers (see examples 1 and 2, above).
Summary
In the process of developing techniques of
dictionary analysis, we have learned a variety of
lessons. In particular, we have learned (as many
dictionary researchers had suspected but none had
attempted to establish) that full natural-language
parsing is not an efficient procedure for gathering
lexical information in a simple form such as
relational triples. This realization stimulated us to do
two things.
Fust, we needed to develop faster and more
reliable techniques for extracting triples. We found
that many triples could be found using UNIX text
processing utilities combined with the recognition of
a few structural patterns in definitions. . These
procedures are subject to further development and
refinement, but have already yielded thousands of
triples.
Second, we were inspired to look for a form
of data representation that would allow our lexical
database to exploit the power of full natural-language
parsing more effectively than it can through triples.
We are now in the early stages of investigating such
a representation.
</bodyText>
<sectionHeader confidence="0.999735" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999415666666667">
Ahlswede, Thomas E., 1985. &amp;quot;A Linguistic String
Grammar for Adjective Definitions.&amp;quot; In S.
Williams, ed., Humans and Machines: the
Interface through Language. Ablex,
Norwood, NJ, pp. 101-127.
AhLswede, Thomas E., 1988. &amp;quot;Syntactic and
</reference>
<page confidence="0.984838">
223
</page>
<reference confidence="0.999714061538462">
Semantic Analysis of Definitions in a
Machine-Readable Dictionary.&amp;quot; Ph.D. Thesis,
Illinois Institute of Technology.
Amsler, Robert A., 1980. &amp;quot;The Structure of The
Merriam-Webster Pocket Dictionary.&amp;quot; Ph.D.
Dissertation, Computer Science, University of
Texas, Austin.
Amsler, Robert A., 1981. &amp;quot;A Taxonomy for English
Nouns and Verbs.&amp;quot; Proceedings of the 19th
Annual Meeting of the ACL, pp. 133-138.
Apresyan, Yu. D., L A. Mel&apos;auk and A. K.
2alkovslcy, 1970. &amp;quot;Semantics and
Lexicography: Towards a New Type of
Unilingual Dictionary.&amp;quot; In Kiefer, F., ed.
Studies in Syntax. Reide,l, Dordrecht, Holland,
pp. 1-33.
Becker, Joseph D., 1975. &amp;quot;The Phrasal Lexicon.&amp;quot; In
Schank, R. C. and B. Nash-Webber, eds.,
Theoretical Issues in Natural Language
Processing, ACL Annual Meeting,
Cambridge, MA, June, 1975, pp. 38-41.
Boguraev, Branimir, 1987. &amp;quot;Experiences with a
Machine-Readable Dictionary.&amp;quot; Proceedings
of the Third Annual Conference of the UW
Centre for the New OED, University of
Waterloo, Waterloo, Ontario, November
1987, pp. 37-50.
Chodorow, Martin S., Roy J. Byrd, and George E.
Heidom, 1985. &amp;quot;Extracting Semantic
Hierarchies from a Large On-line
Dictionary.&amp;quot; Proceedings of the 23rd Annual
Meeting of the ACL, pp. 299-304.
Evens, Martha W., Bonnie C. Litowitz, Judith A.
Markowitz, Raoul N. Smith, and Oswald
Werner, 1980. Lexical-Semantic Relations: A
Comparative Survey. Linguistic Research,
Inc., Edmonton, Alberta.
Fox, Edward A., 1980. &amp;quot;Lexical Relations:
Enhancing Effectiveness of Information
Retrieval Systems.&amp;quot; ACM SIGIR Forum, Vol.
15, No. 3, pp. 5-36.
Fox, Edward A., J. Terry Nutter, Thomas Ahlswede,
Martha Evens, and Judith Markowitz,
forthcoming. &amp;quot;Building a large Thesaurus
for Information Retrieval.&amp;quot; To be presented at
the ACL Conference on Applied Natural
Language Processing, February, 1988.
Mayer, Glenn, 1988. Program for morphological
analysis. LIT, unpublished.
Halliday, Michael A. K. and Ruciaiya Hasan, 1976.
Cohesion in English. Longman, London.
Klick, Vicki, 1981. LSP grammar of adverb
definitions. Illinois Institute of Technology,
unpublished.
Peterson, James L., 1982. Webster&apos;s Seventh New
Collegiate Dictionary: A Computer-Readable
File Format. Technical Report TR-196,
University of Texas, Austin, TX, May, 1982.
Sager, Naomi, 1981. Natural language Information
Processing. Addison-Wesley, New York.
Wang, Yih-Chen, James Vandendorpe, and Martha
Evens, 1985. &amp;quot;Relational Thesauri in
Information Retrieval.&amp;quot; Journal of the
American Society for Information Science,
vol. 36, no. 1, pp. 15-27.
</reference>
<page confidence="0.998708">
224
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.959153">
<title confidence="0.9974025">PARSING VS. TEXT PROCESSING IN THE ANALYSIS OF DICTIONARY DEFINITIONS</title>
<author confidence="0.999829">Thomas Ahlswede</author>
<author confidence="0.999829">Martha Evens</author>
<affiliation confidence="0.9999675">Computer Science Dept. Illinois Institute of Technology</affiliation>
<address confidence="0.999573">Chicago, IL 60616</address>
<phone confidence="0.981201">312-567-5153</phone>
<abstract confidence="0.99687225">have analyzed definitions from New Collegiate Dictionary Sager&apos;s Linguistic String Parser and again using basic UNIX processing utilities such as awk. This paper evaluates both procedures, compares their results, and discusses possible future lines of research exploiting and combining their respective strengths.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Thomas E Ahlswede</author>
</authors>
<title>A Linguistic String Grammar for Adjective Definitions.&amp;quot;</title>
<date>1985</date>
<booktitle>Humans and Machines: the Interface through Language. Ablex,</booktitle>
<pages>101--127</pages>
<editor>In S. Williams, ed.,</editor>
<location>Norwood, NJ,</location>
<contexts>
<context position="5532" citStr="Ahlswede, 1985" startWordPosition="864" endWordPosition="865">ch harder is parsing, and what rewards, if any, will the effort yield? • We used Sager&apos;s Linguistic String Parser, as we have done for several years. It has been continuously developed since the 1970s and by now has a very extensive and powerful user interface as well as a large English grammar and a vocabulary (the LSP Dictionary) of over 10,000 words. It is not exceptionally fast — a fact which should be taken into account in evaluating the performance of parsers generally in dictionary analysis. Our efforts to parse W7 definitions began with simple LSP grammars for small sets of adjective [Ahlswede, 1985] and adverb [Klick, 1981] definitions. These led eventually to a large grammar of noun, verb and adjective definitions [Ahlswede, 1988], based on the Linguistic String Project&apos;s full English grammar [Sager, 1981], and using the LSP&apos;s full set of resources, including restrictions, transformations, and special output generation routines. All of these grammars have been used not only to create parse trees but also (and primarily) to generate relational triples linking defined words to the major words used in their definitions. The large definition grammar is described more fully in Ahlswede [198</context>
</contexts>
<marker>Ahlswede, 1985</marker>
<rawString>Ahlswede, Thomas E., 1985. &amp;quot;A Linguistic String Grammar for Adjective Definitions.&amp;quot; In S. Williams, ed., Humans and Machines: the Interface through Language. Ablex, Norwood, NJ, pp. 101-127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas E AhLswede</author>
</authors>
<title>Syntactic and Semantic Analysis of Definitions in a Machine-Readable Dictionary.&amp;quot;</title>
<date>1988</date>
<tech>Ph.D. Thesis,</tech>
<institution>Illinois Institute of Technology.</institution>
<marker>AhLswede, 1988</marker>
<rawString>AhLswede, Thomas E., 1988. &amp;quot;Syntactic and Semantic Analysis of Definitions in a Machine-Readable Dictionary.&amp;quot; Ph.D. Thesis, Illinois Institute of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert A Amsler</author>
</authors>
<title>The Structure of The Merriam-Webster Pocket Dictionary.&amp;quot;</title>
<date>1980</date>
<institution>Ph.D. Dissertation, Computer Science, University of Texas,</institution>
<location>Austin.</location>
<marker>Amsler, 1980</marker>
<rawString>Amsler, Robert A., 1980. &amp;quot;The Structure of The Merriam-Webster Pocket Dictionary.&amp;quot; Ph.D. Dissertation, Computer Science, University of Texas, Austin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert A Amsler</author>
</authors>
<title>A Taxonomy for English Nouns and Verbs.&amp;quot;</title>
<date>1981</date>
<booktitle>Proceedings of the 19th Annual Meeting of the ACL,</booktitle>
<pages>133--138</pages>
<marker>Amsler, 1981</marker>
<rawString>Amsler, Robert A., 1981. &amp;quot;A Taxonomy for English Nouns and Verbs.&amp;quot; Proceedings of the 19th Annual Meeting of the ACL, pp. 133-138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L A Mel&apos;auk D</author>
<author>A K</author>
</authors>
<title>Semantics and Lexicography: Towards a New Type of Unilingual Dictionary.&amp;quot;</title>
<date>1970</date>
<booktitle>Studies in Syntax. Reide,l,</booktitle>
<pages>1--33</pages>
<editor>In Kiefer, F., ed.</editor>
<location>Dordrecht, Holland,</location>
<marker>D, K, 1970</marker>
<rawString>Apresyan, Yu. D., L A. Mel&apos;auk and A. K. 2alkovslcy, 1970. &amp;quot;Semantics and Lexicography: Towards a New Type of Unilingual Dictionary.&amp;quot; In Kiefer, F., ed. Studies in Syntax. Reide,l, Dordrecht, Holland, pp. 1-33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph D Becker</author>
</authors>
<title>The Phrasal Lexicon.&amp;quot;</title>
<date>1975</date>
<booktitle>Theoretical Issues in Natural Language Processing, ACL Annual Meeting,</booktitle>
<pages>38--41</pages>
<editor>In Schank, R. C. and B. Nash-Webber, eds.,</editor>
<location>Cambridge, MA,</location>
<marker>Becker, 1975</marker>
<rawString>Becker, Joseph D., 1975. &amp;quot;The Phrasal Lexicon.&amp;quot; In Schank, R. C. and B. Nash-Webber, eds., Theoretical Issues in Natural Language Processing, ACL Annual Meeting, Cambridge, MA, June, 1975, pp. 38-41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Branimir Boguraev</author>
</authors>
<title>Experiences with a Machine-Readable Dictionary.&amp;quot;</title>
<date>1987</date>
<booktitle>Proceedings of the Third Annual Conference of the UW</booktitle>
<pages>37--50</pages>
<institution>Centre for the New OED, University of Waterloo,</institution>
<location>Waterloo, Ontario,</location>
<marker>Boguraev, 1987</marker>
<rawString>Boguraev, Branimir, 1987. &amp;quot;Experiences with a Machine-Readable Dictionary.&amp;quot; Proceedings of the Third Annual Conference of the UW Centre for the New OED, University of Waterloo, Waterloo, Ontario, November 1987, pp. 37-50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin S Chodorow</author>
<author>Roy J Byrd</author>
<author>George E Heidom</author>
</authors>
<title>Extracting Semantic Hierarchies from a Large On-line Dictionary.&amp;quot;</title>
<date>1985</date>
<booktitle>Proceedings of the 23rd Annual Meeting of the ACL,</booktitle>
<pages>299--304</pages>
<marker>Chodorow, Byrd, Heidom, 1985</marker>
<rawString>Chodorow, Martin S., Roy J. Byrd, and George E. Heidom, 1985. &amp;quot;Extracting Semantic Hierarchies from a Large On-line Dictionary.&amp;quot; Proceedings of the 23rd Annual Meeting of the ACL, pp. 299-304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha W Evens</author>
<author>Bonnie C Litowitz</author>
<author>Judith A Markowitz</author>
<author>Raoul N Smith</author>
<author>Oswald Werner</author>
</authors>
<title>Lexical-Semantic Relations: A Comparative Survey. Linguistic Research,</title>
<date>1980</date>
<publisher>Inc.,</publisher>
<location>Edmonton, Alberta.</location>
<marker>Evens, Litowitz, Markowitz, Smith, Werner, 1980</marker>
<rawString>Evens, Martha W., Bonnie C. Litowitz, Judith A. Markowitz, Raoul N. Smith, and Oswald Werner, 1980. Lexical-Semantic Relations: A Comparative Survey. Linguistic Research, Inc., Edmonton, Alberta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward A Fox</author>
</authors>
<title>Lexical Relations: Enhancing Effectiveness of Information Retrieval Systems.&amp;quot;</title>
<date>1980</date>
<journal>ACM SIGIR Forum,</journal>
<volume>15</volume>
<pages>5--36</pages>
<marker>Fox, 1980</marker>
<rawString>Fox, Edward A., 1980. &amp;quot;Lexical Relations: Enhancing Effectiveness of Information Retrieval Systems.&amp;quot; ACM SIGIR Forum, Vol. 15, No. 3, pp. 5-36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward A Fox</author>
<author>J Terry Nutter</author>
<author>Thomas Ahlswede</author>
<author>Martha Evens</author>
<author>Judith Markowitz</author>
<author>forthcoming</author>
</authors>
<title>Building a large Thesaurus for Information Retrieval.&amp;quot;</title>
<date>1988</date>
<booktitle>the ACL Conference on Applied Natural Language Processing,</booktitle>
<note>To be presented at</note>
<contexts>
<context position="7888" citStr="Fox et al., 1988" startWordPosition="1236" endWordPosition="1239">d was very little more than this, however, since almost all the parsing was done at night when the systems were otherwise idle. Table 1 compares the LSP&apos;s performance in the four part of speech categories. Part of Pct. of Avg. no. Time (sec.) Triples speech of defs. of parses per parse generated defd. word parsed per success per success nouns 77.63 1.70 11.05 11.46 adjectives 68.15 1.85 10.59 5.45 int. verbs 64.62 1.59 11.96 6.62 U. verbs 60.29 1.50 43.33 9.15 average 68.65 1.66 18.89 9.06 Table 1. Performance time and parsing efficiency of LSP by part of speech of words defined (adapted from Fox et al., 1988) In most cases, there is little variation among the parts of speech. The most obvious discrepancy is the slow parsing time for transitive verbs. We are not yet sure why this is, but we suspect it has to do with W7&apos;s practice of representing the defined verb&apos;s direct object by an empty slot in the definition: (11) madden 0 2 vt to rnake intensely angry 218 (12) magnetize 02 vt to communicate magnetic properties to The total number of triples generated was 51,115 and the number of unique triples was 25,178. The most common triples were 5,086 taxonomies and 7,971 modification relations. (Modifica</context>
</contexts>
<marker>Fox, Nutter, Ahlswede, Evens, Markowitz, forthcoming, 1988</marker>
<rawString>Fox, Edward A., J. Terry Nutter, Thomas Ahlswede, Martha Evens, and Judith Markowitz, forthcoming. &amp;quot;Building a large Thesaurus for Information Retrieval.&amp;quot; To be presented at the ACL Conference on Applied Natural Language Processing, February, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glenn Mayer</author>
</authors>
<title>Program for morphological analysis.</title>
<date>1988</date>
<note>LIT, unpublished.</note>
<marker>Mayer, 1988</marker>
<rawString>Mayer, Glenn, 1988. Program for morphological analysis. LIT, unpublished.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael A K Halliday</author>
<author>Ruciaiya Hasan</author>
</authors>
<date>1976</date>
<booktitle>Cohesion in English. Longman,</booktitle>
<location>London.</location>
<marker>Halliday, Hasan, 1976</marker>
<rawString>Halliday, Michael A. K. and Ruciaiya Hasan, 1976. Cohesion in English. Longman, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vicki Klick</author>
</authors>
<title>LSP grammar of adverb definitions.</title>
<date>1981</date>
<institution>Illinois Institute of Technology, unpublished.</institution>
<contexts>
<context position="5557" citStr="Klick, 1981" startWordPosition="868" endWordPosition="869">at rewards, if any, will the effort yield? • We used Sager&apos;s Linguistic String Parser, as we have done for several years. It has been continuously developed since the 1970s and by now has a very extensive and powerful user interface as well as a large English grammar and a vocabulary (the LSP Dictionary) of over 10,000 words. It is not exceptionally fast — a fact which should be taken into account in evaluating the performance of parsers generally in dictionary analysis. Our efforts to parse W7 definitions began with simple LSP grammars for small sets of adjective [Ahlswede, 1985] and adverb [Klick, 1981] definitions. These led eventually to a large grammar of noun, verb and adjective definitions [Ahlswede, 1988], based on the Linguistic String Project&apos;s full English grammar [Sager, 1981], and using the LSP&apos;s full set of resources, including restrictions, transformations, and special output generation routines. All of these grammars have been used not only to create parse trees but also (and primarily) to generate relational triples linking defined words to the major words used in their definitions. The large definition grammar is described more fully in Ahlswede [1988]. We are concerned here</context>
</contexts>
<marker>Klick, 1981</marker>
<rawString>Klick, Vicki, 1981. LSP grammar of adverb definitions. Illinois Institute of Technology, unpublished.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James L Peterson</author>
</authors>
<title>Webster&apos;s Seventh New Collegiate Dictionary: A Computer-Readable File Format.</title>
<date>1982</date>
<tech>Technical Report TR-196,</tech>
<institution>University of Texas,</institution>
<location>Austin, TX,</location>
<marker>Peterson, 1982</marker>
<rawString>Peterson, James L., 1982. Webster&apos;s Seventh New Collegiate Dictionary: A Computer-Readable File Format. Technical Report TR-196, University of Texas, Austin, TX, May, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naomi Sager</author>
</authors>
<date>1981</date>
<booktitle>Natural language Information Processing.</booktitle>
<publisher>Addison-Wesley,</publisher>
<location>New York.</location>
<contexts>
<context position="5744" citStr="Sager, 1981" startWordPosition="895" endWordPosition="896"> a very extensive and powerful user interface as well as a large English grammar and a vocabulary (the LSP Dictionary) of over 10,000 words. It is not exceptionally fast — a fact which should be taken into account in evaluating the performance of parsers generally in dictionary analysis. Our efforts to parse W7 definitions began with simple LSP grammars for small sets of adjective [Ahlswede, 1985] and adverb [Klick, 1981] definitions. These led eventually to a large grammar of noun, verb and adjective definitions [Ahlswede, 1988], based on the Linguistic String Project&apos;s full English grammar [Sager, 1981], and using the LSP&apos;s full set of resources, including restrictions, transformations, and special output generation routines. All of these grammars have been used not only to create parse trees but also (and primarily) to generate relational triples linking defined words to the major words used in their definitions. The large definition grammar is described more fully in Ahlswede [1988]. We are concerned here with its performance: its success in parsing definitions with a minimum of incorrect or improbable parses, its success in identifying relational triples, and its speed. Input to the pars</context>
</contexts>
<marker>Sager, 1981</marker>
<rawString>Sager, Naomi, 1981. Natural language Information Processing. Addison-Wesley, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yih-Chen Wang</author>
<author>James Vandendorpe</author>
<author>Martha Evens</author>
</authors>
<title>Relational Thesauri in Information Retrieval.&amp;quot;</title>
<date>1985</date>
<journal>Journal of the American Society for Information Science,</journal>
<volume>36</volume>
<pages>15--27</pages>
<marker>Wang, Vandendorpe, Evens, 1985</marker>
<rawString>Wang, Yih-Chen, James Vandendorpe, and Martha Evens, 1985. &amp;quot;Relational Thesauri in Information Retrieval.&amp;quot; Journal of the American Society for Information Science, vol. 36, no. 1, pp. 15-27.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>