<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.968068">
Hunting Elusive Metaphors Using Lexical Resources
</title>
<author confidence="0.955657">
Saisuresh Krishnakumaran*
</author>
<affiliation confidence="0.893367">
Computer Sciences Department
University of Wisconsin-Madison
</affiliation>
<address confidence="0.867195">
Madison, WI 53706
</address>
<email confidence="0.99819">
ksai@cs.wisc.edu
</email>
<author confidence="0.987725">
Xiaojin Zhu
</author>
<affiliation confidence="0.9849305">
Computer Sciences Department
University of Wisconsin-Madison
</affiliation>
<address confidence="0.87597">
Madison, WI 53706
</address>
<email confidence="0.998048">
jerryzhu@cs.wisc.edu
</email>
<sectionHeader confidence="0.995643" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999405222222222">
In this paper we propose algorithms
to automatically classify sentences into
metaphoric or normal usages. Our algo-
rithms only need the WordNet and bigram
counts, and does not require training. We
present empirical results on a test set de-
rived from the Master Metaphor List. We
also discuss issues that make classification
of metaphors a tough problem in general.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999967666666667">
Metaphor is an interesting figure of speech which
expresses an analogy between two seemingly un-
related concepts. Metaphoric usages enhance the
attributes of the source concept by comparing it
with the attributes of the target concept. Abstrac-
tions and enormously complex situations are rou-
tinely understood via metaphors (Lakoff and John-
son, 1980). Metaphors begin their lives as Novel
Poetic Creations with marked rhetoric effects whose
comprehension requires special imaginative leap.
As time goes by, they become part of general use
and their comprehension becomes automatic and
idiomatic and rhetoric effect is dulled (Nunberg,
1987). We term such metaphors whose idiomatic ef-
fects are dulled because of common usage as dead
metaphors while metaphors with novel usages as
live metaphors. In this paper we are interested only
in identifying live metaphors.
</bodyText>
<footnote confidence="0.447744">
* The first author is currently affiliated with Google Inc,
Mountain View, CA.
</footnote>
<page confidence="0.994766">
13
</page>
<bodyText confidence="0.999838911764706">
Metaphors have interesting applications in many
NLP problems like machine translation, text sum-
marization, information retrieval and question an-
swering. Consider the task of summarizing a parable
which is a metaphoric story with a moral. The best
summary of a parable is the moral. Paraphrasing a
metaphoric passage like a parable is difficult with-
out understanding the metaphoric uses. The per-
formance of the conventional summarizing systems
will be ineffective because they cannot identify such
metaphoric usages. Also it is easy to create novel
and interesting uses of metaphors as long as one con-
cept is explained in terms of another concept. The
performance of machine translation systems will be
affected in such cases especially if they have not en-
countered such metaphoric uses before.
Metaphor identification in text documents is,
however, complicated by issues including con-
text sensitiveness, emergence of novel metaphoric
forms, and the need for semantic knowledge about
the sentences. Metaphoric appeal differs across lan-
guage or people’s prior exposure to such usages. In
addition, as (Gibbs, 1984) points out, literal and fig-
urative expressions are end points of a single con-
tinuum along which metaphoricity and idiomaticity
are situated, thereby making clear demarcation of
metaphoric and normal usages fuzzy.
We discuss many such issues that make the task
of classifying sentences into metaphoric or non-
metaphoric difficult. We then focuses on a sub-
set of metaphoric usages involving the nouns in a
sentence. In particular, we identify the subject-
object, verb-noun and adjective-noun relationships
in sentences and classify them as metaphoric or
</bodyText>
<note confidence="0.9793665">
Proceedings of the Workshop on Computational Approaches to Figurative Language, pages 13–20,
Rochester, NY, April 26, 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999501875">
non-metaphoric. Extensions to other metaphoric
types will be part of future work. Our algorithms
use the hyponym relationship in WordNet (Fell-
baum, 1998), and word bigram counts, to predict the
metaphors. In doing so we circumvent two issues:
the absence of labeled training data, and the lack of
clear features that are indicative of metaphors.
The paper is organized as follows. Section 2
presents interesting observations that were made
during the initial survey, and presents examples
that makes metaphor identification hard. Sec-
tion 3 discusses our main techniques for identifying
metaphors in text documents. Section 4 analyzes the
effect of the techniques. Section 5 discusses relevant
prior work in the area of metaphor processing and
identification. Finally we conclude in Section 6.
</bodyText>
<sectionHeader confidence="0.949186" genericHeader="method">
2 Challenges in Metaphor Identification
</sectionHeader>
<bodyText confidence="0.998661">
In this section we present some issues that make
metaphor identification hard.
</bodyText>
<subsectionHeader confidence="0.997485">
2.1 Context Sensitivity
</subsectionHeader>
<bodyText confidence="0.971737615384615">
Some metaphoric usages are sensitive to the context
in which they occur. For example, the following
sentence can act as a normal sentence as well as a
metaphoric sentence.
Men are animals.
It is a normal sentence in a biology lecture because
all human beings fall under the animal kingdom.
However this is a metaphoric sentence in a social
conversation when it refers to animal qualities. Also
the word ‘Men’ has two different senses in WordNet
and hence it is necessary to disambiguate the senses
based on the context. Sense disambiguation is be-
yond the scope of this paper.
</bodyText>
<subsectionHeader confidence="0.8702945">
2.2 Pronoun Resolution
Consider the following sentence,
</subsectionHeader>
<bodyText confidence="0.996598636363636">
This homework is a breeze. The previous
one was on calculus. It was a tornado.
The techniques we discuss in this paper can clas-
sify the reference to ‘breeze’ as metaphoric. In or-
der to correctly classify the reference to ‘tornado’
as metaphoric, however, the system needs to resolve
the reference to the pronoun ‘It’. Strictly speak-
ing, this example might be solved without resolu-
tion because any of the potential antecedents render
the sentence metaphoric, but in general resolution is
necessary.
</bodyText>
<subsectionHeader confidence="0.999112">
2.3 Word Usages
</subsectionHeader>
<bodyText confidence="0.995849">
Consider the following two sentences,
He is a Gandhi. vs. He is Gandhi.
The first sentence is a metaphor which attributes the
qualities of Gandhi to the actor, while the second
sentence is a normal one. Here the article ‘a’ dis-
tinguishes the first sentence from the second. Sim-
ilarly, in the following example, the phrase ‘among
men’ helps in making the second usage metaphoric.
He is a king. vs. He is a king among men.
A comprehensive list of such uses are not known and
incorporating all such grammatical features would
make the system quite complex.
</bodyText>
<subsectionHeader confidence="0.992617">
2.4 Parser Issues
</subsectionHeader>
<bodyText confidence="0.999966333333333">
The techniques that we propose work on the parsed
sentences. Hence the accuracy of our technique is
highly dependent on the accuracy of the parser.
</bodyText>
<subsectionHeader confidence="0.996137">
2.5 Metaphoric Usages in WordNet
</subsectionHeader>
<bodyText confidence="0.995903875">
Some metaphoric senses of nouns are already part of
the WordNet.
He is a wolf.
The metaphoric sense of ‘wolf’ is directly men-
tioned in the WordNet. We call such usages as ‘dead
metaphors’ because they are so common and are al-
ready part of the lexicon. In this paper we are inter-
ested in identifying only novel usages of metaphors.
</bodyText>
<sectionHeader confidence="0.999063" genericHeader="method">
3 Noun-Form Metaphors
</sectionHeader>
<bodyText confidence="0.998250444444444">
We restrict ourselves to metaphoric usages involving
nouns. In particular, we study the effect of verbs and
adjectives on the nouns in a sentence. We categorize
the verb-noun relationship in sentences as Type I and
Type II based on the verb. We call the adjective-
noun relationship as Type III, see Table 1.
For Type I, the verb is one of the ‘be’ form verbs
like ‘is’, ‘are’, ‘am’, ‘was’, etc. An example of Type
I form metaphor is
</bodyText>
<page confidence="0.999788">
14
</page>
<tableCaption confidence="0.999738">
Table 1: Terminology
</tableCaption>
<table confidence="0.997891">
Sentence Type Relationship
Type I Subject IS-A Object
Type II Verb acting on Noun
(verb not ‘be’)
Type III Adjective acting on Noun
</table>
<bodyText confidence="0.989225529411765">
He is a brave lion.
An example of Type II form metaphor is
He planted good ideas in their minds.
An example for Type III form metaphor is
He has a fertile imagination.
We use two different approaches for Type I vs.
Types II, III. In Type I form we are interested in
the relationship between the subject and the object.
We use a hyponym heuristic. In Types II and III,
we are interested in the subject-verb, verb-object,
or adjective-noun relations. We use hyponym to-
gether with word co-occurrence information, in this
case bigrams from the Web 1T corpus (Brants and
Franz, 2006). Sections 3.1 and 3.2 discuss the two
algorithms, respectively. We use a parser (Klein and
Manning, 2003) to obtain the relationships between
nouns, verbs and adjectives in a sentence.
</bodyText>
<subsectionHeader confidence="0.998937">
3.1 Identifying Type I metaphors
</subsectionHeader>
<bodyText confidence="0.9929199375">
We identify the WordNet hyponym relationship (or
the lack thereof) between the subject and the object
in a Type I sentence. We classify the sentence as
metaphoric, if the subject and object does not have
a hyponym relation. A hyponym relation exists be-
tween a pair of words if and only if one word is a
subclass of another word. We motivate this idea us-
ing some examples. Let us consider a normal sen-
tence with a subject-object relationship governed by
a ‘be’ form verb, ‘is’.
A lion is a wild animal.
The subject-verb-object relationship of this normal
sentence is shown in Figure 1.
The subject and the object in the above example is
governed by ‘IS-A’ relationship. Thus, Lion ‘IS-A’
type of animal. The ‘IS-A’ relationship is captured
</bodyText>
<figureCaption confidence="0.7881655">
Figure 1: The Subject-Verb-Object relationship for
‘A lion is a wild animal.’
</figureCaption>
<bodyText confidence="0.944660285714286">
as the ‘hyponym’ relationship in WordNet, where
‘Lion’ is the hyponym of ‘animal’. Consider another
example,
He is a scientist.
Here the object ‘scientist’ is the occupation of the
subject ‘He’, which we change to ‘person’. ‘Sci-
entist’ is a hyponym of ‘person’ in WordNet. The
above two examples show that we expect a subject-
object hyponym relation for normal Type I relations.
On the other hand, consider a metaphoric example in
Type I form,
All the world’s a stage.
- William Shakespeare
The subject-verb-object relationship is represented
by Figure 2.
Figure 2: The Subject-Verb-Object relationship for
‘All the world is a stage.’
There is a subject-object relation between ‘World’
and ‘Stage’, but they do not hold a hyponym re-
lation in WordNet. This is an important observa-
tion which we use in classifying relationships of this
</bodyText>
<page confidence="0.987291">
15
</page>
<bodyText confidence="0.994190666666667">
form. Consider another example with complex sen-
tences,
Men are April when they woo, December
when they wed. Maids are May when
they are maids, but the sky changes
when they are wives.
</bodyText>
<subsectionHeader confidence="0.437181">
-Shakespeare’s As You Like It’.
</subsectionHeader>
<bodyText confidence="0.996819636363636">
In this case, there are two explicit subject-object
relations, namely Men-April and Maids-May. The
WordNet hyponym relation does not exist between
either pair.
From the examples considered above, it is seems
that when a hyponym relation exists between the
subject and the object, the relationship is normal,
and metaphoric otherwise. The effectiveness of this
approach is analyzed in detail in Section 4. The
pseudo code for classifying Type I relations is given
below:
</bodyText>
<listItem confidence="0.937892125">
1. Parse the sentences and get all R +— {subject,
be, object} relations in those sentences.
2. for each relation Raub,obj
if Hyponym(sub,obj) = true
then Raub,obj is normal usage
else Raub,obj is a metaphoric relation
3. All sentences with at least one metaphoric rela-
tion is classified as metaphoric.
</listItem>
<subsectionHeader confidence="0.998259">
3.2 Identifying Type II and Type III metaphors
</subsectionHeader>
<bodyText confidence="0.999979416666667">
We use a two dimensional V/A-N co-occurrence ma-
trix, in addition to WordNet, for detecting Type II
and Type III metaphors. V/A-N matrix stands for
Verb/Adjective-Noun matrix, which is a two dimen-
sional matrix with verbs or adjectives along one di-
mension, and nouns along the other. The entries
are co-occurrence frequency of the word pair, from
which we may estimate the conditional probabil-
ity p(wn|w) for a noun wn and a verb or adjec-
tive w. Ideally the matrix should be constructed
from a parsed corpus, so that we can identify V/A-
N pairs from their syntactic roles. However pars-
ing a large corpus would be prohibitively expensive.
As a practical approximation, we use bigram counts
from the Web 1T corpus (Brants and Franz, 2006).
Web 1T corpus consists of English word n-grams
(up to 5-grams) generated from approximately 1 tril-
lion word tokens of text from public Web pages. In
this paper we use the bigram data in which a noun
follows either a verb or an adjective. We note that
this approximation thus misses, for example, the pair
(plant, idea) in phrases like ‘plant an idea’. Nonethe-
less, the hope is that the corpus makes it up by sheer
size.
</bodyText>
<subsectionHeader confidence="0.475702">
3.2.1 Type II metaphors
</subsectionHeader>
<bodyText confidence="0.999497772727273">
We discuss the metaphoric relationship between
a verb-noun pair (wv, wn). The idea is that if nei-
ther wn nor its hyponyms or hypernyms co-occur
frequently with wv, then the pair is a novel usage,
and we classify the pair as metaphoric. To this end,
we estimate the conditional probability p(wh|wv) =
count(wv, wh)/count(wv) from the V/A-N matrix,
where wh is wn itself, or one of its hyponyms / hy-
pernyms. If at least one of these wh has high enough
conditional probability as determined by a thresh-
old, we classify it as normal usage, and metaphoric
otherwise. Consider the following example
He planted good ideas in their minds.
The verb ‘planted’ acts on the noun ‘ideas’ and
makes the sentence metaphoric. In our corpus the
objects that occur more frequently with the verb
‘planted’ are ‘trees’, ‘bomb’ and ‘wheat’, etc. Nei-
ther the noun ‘ideas’ nor its hyponyms / hypernyms
occurs frequently enough with ‘planted’. Hence we
predict this verb-object relationship as metaphoric.
The pseudo code for classifying Type II metaphors
is given below:
</bodyText>
<listItem confidence="0.995186">
1. Parse the sentences and obtain all R +— {verb,
noun} relations in those sentences.
2. for each relation Rverb,noun
</listItem>
<bodyText confidence="0.8698978">
Sort all nouns w in the vocabulary by de-
creasing p(w|verb). Take the smallest set of
top k nouns whose conditional probability sum
&gt; threshold T.
if ]wh such that wh is related to noun by
the hyponym relation in WordNet, and wh E
top k words above,
then Rverb,noun is normal usage
else Rverb,noun is a Type II metaphoric re-
lation
</bodyText>
<page confidence="0.978563">
16
</page>
<listItem confidence="0.8680405">
3. All sentences with at least one metaphoric rela-
tionship is classified as a metaphor.
</listItem>
<subsubsectionHeader confidence="0.292763">
3.2.2 Type III metaphors
</subsubsectionHeader>
<bodyText confidence="0.996946476190476">
The technique for detecting the Type III
metaphors is the same as the technique for detecting
the Type II metaphors except that it operates on dif-
ferent relationship. Here we compare the Adjective-
Noun relationship instead of the Verb-Noun rela-
tionship. For example,
He has a fertile imagination.
Here the adjective ‘fertile’ acts on the noun ‘imagi-
nation’ to make it metaphoric. The nouns that occur
frequently with the ‘fertile’ in our corpus are ‘soil’,
‘land’, ‘territory’, and ‘plains’, etc. Comparison of
the WordNet hierarchies of the noun ‘imagination’
with each of these nouns will show that there does
not exist any hyponym relation between ‘imagina-
tion’ and any of these nouns. Hence we classify
them as metaphors. As another example,
TV is an idiot box.
The adjective ‘idiot’ qualifies nouns related to peo-
ple such as ‘boy’, ‘man’, etc. that are unrelated to
the noun ‘box’. Thus we classify it as a Type III
metaphor.
</bodyText>
<sectionHeader confidence="0.998045" genericHeader="method">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.999124125">
We experimented with the Berkeley Master
Metaphor List (Lakoff and Johnson, 1980) to
compute the performance of our techniques. The
Berkeley Master Metaphor List is a collection of
nearly 1728 unique sentences and phrases. We
corrected some typos and spelling errors in the
Master list and expanded phrases to complete
sentences. The list has many metaphoric uses
which has become very common usages in today’s
standards, and thus no longer have any rhetoric
effects. Therefore, we manually label the sentences
in the Master List into 789 ‘live metaphors’ and
the remaining ones ‘dead metaphors’ as the ground
truth&apos;.
Table 2 shows the initial performance of the
Type I algorithm. There are 129 sentences in the
</bodyText>
<footnote confidence="0.531381666666667">
&apos;Our processed and labeled dataset is available at
http://www.cs.wisc.edu/˜ksai/publications/
2007/HLT_NAACL_metaphors/metaphors.html
</footnote>
<bodyText confidence="0.998284142857143">
Master List that contain subject-be-object form. Our
algorithm has a precision of 70% and a recall of 61%
with respect to the live/dead labels. Note that al-
though the accuracy is 58%, the algorithm is bet-
ter than a random classification in terms of precision
and recall. One thing to note is that our negative
examples are (subjectively labeled) dead metaphors.
We thus expect the task to be harder than with ran-
dom non-metaphoric sentences. Another point to
note here is that the live/dead labels are on sentences
and not on particular phrases with type I relations.
A sentence can contain more than one phrases with
various types. Therefore this result does not give a
complete picture of our algorithm.
</bodyText>
<tableCaption confidence="0.971328">
Table 2: Type I Performance
</tableCaption>
<bodyText confidence="0.960143928571428">
Predicted as Predicted as
Metaphoric Normal
Annotated as live 50 32
Annotated as dead 22 25
A few interesting metaphors detected by our algo-
rithm are as follows:
Lawyers are real sharks.
Smog pollution is an environmental
malaise.
Some false negatives are due to phrases qualifying
the object of the sentence as in the following exam-
ple,
He is a budding artist.
There is a Type I relation in this sentence because
the subject ‘He’ and the object ‘artist’ are related
by the ‘be’ form verb ‘is’. In this case, the Type I
algorithm compares the hyponyms relation between
’person’ and ’artist’ and declares it as a normal sen-
tence. However the adjective ‘budding’ adds Type
III figurative meaning to this sentence. Therefore al-
though the Type I relation is normal, there are other
features in the sentences that make it metaphoric.
We observed that most of false negatives that are
wrongly classified because of the above reason have
pronoun subject like ‘he’, ‘she’ etc.
Another major source of issue is the occurrences
of pronoun ‘it’ which is hard to resolve. We replaced
it by ‘entity’, which is the root of WordNet, when
</bodyText>
<page confidence="0.997923">
17
</page>
<bodyText confidence="0.99835025">
comparing the hyponyms. ‘Entity’ matches the hy-
ponym relation with any other noun and hence all
these sentences with ‘it’ as the subject are classified
as normal sentences.
</bodyText>
<tableCaption confidence="0.9053315">
Table 3: Type I Performance for sentences with non-
pronoun subject
</tableCaption>
<bodyText confidence="0.986503189189189">
Predicted as Predicted as
Metaphoric Normal
Annotated as live 40 1
Annotated as dead 19 4
Table 3 shows the performance of our Type I al-
gorithm for sentences with non-pronoun subjects.
It clearly shows that the performance in Table 2 is
affected by sentences with pronoun subjects as ex-
plained in the earlier paragraphs.
In some cases, prepositional phrases affects the
performance of our algorithm. Consider the follow-
ing example,
He is the child of evil.
Here the phrase ‘child of evil’ is metaphoric. But the
parser identifies a subject-be-object relationship be-
tween ‘He’ and ‘child’ and our algorithm compares
the hyponym relation between ‘person’ and ‘child’
and declares it as a normal sentence.
Our current algorithm does not deal with cases
like the following example
The customer is a scientist. vs. The cus-
tomer is king.
Since there is no direct hyponym relation between
scientist/king with customer we declare both these
sentences as metaphors although only the latter is.
Unlike the algorithm for Type I, there is a thresh-
old T to be set for Type II and III algorithm. By
changing T, we are able to plot a precision recall
curve. Figure 3 and figure 4 show the precision re-
call graph for Type II and Type III relations respec-
tively. Figure 5 shows the overall precision recall
graph for all three types put together.
False positives in Type II and Type III were due
to very general verbs and adjectives. These verbs
and adjectives can occur with a large number of
nouns, and tend to produce low conditional prob-
abilities even for normal nouns. Thereby they are
</bodyText>
<figure confidence="0.944521666666667">
Type II Precision Recall graph
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Recall
</figure>
<figureCaption confidence="0.978271">
Figure 3: Precision Recall curve for Type II rela-
tions.
</figureCaption>
<figure confidence="0.973489666666667">
Type III Precision Recall graph
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Recall
</figure>
<figureCaption confidence="0.976735">
Figure 4: Precision Recall curve for Type III rela-
tions.
</figureCaption>
<bodyText confidence="0.961451888888889">
often mistakenly classified as metaphoric relations.
We expect the performance to improve if these gen-
eral verbs and adjectives are handled properly. Some
general verbs include ‘gave’, ‘made’, ‘has’, etc., and
similarity general adjectives include ‘new’, ‘good’,
‘many’, ‘more’, etc. The plot for Type III is more
random.
Most errors can be attributed to some of the fol-
lowing reasons:
</bodyText>
<listItem confidence="0.943335">
• As mentioned in the challenges section, the
parser is not very accurate. For example,
</listItem>
<bodyText confidence="0.84964675">
They battled each other over the
chess board every week.
Here the parser identifies the verb-object rela-
tion as ( battled , week ), which is not correct.
</bodyText>
<figure confidence="0.98363168">
Precision
0.75
0.65
0.55
0.45
0.8
0.7
0.6
0.5
0.4
Type II
Precision
0.65
0.55
0.45
0.35
0.7
0.6
0.5
0.4
Type III
18
Combined Precision Recall graph
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Recall
</figure>
<figureCaption confidence="0.9794425">
Figure 5: Overall Precision Recall curve for all three
types combined.
</figureCaption>
<listItem confidence="0.844484">
• Pronoun resolution: As discussed earlier, the
pronoun ‘it’ is not resolved and hence they in-
troduce additional source of errors.
• Manual annotations could be wrong. In our ex-
periment we have used only two annotators, but
having more would have increased the confi-
dence in the labels.
• Many of the verb-noun forms are most natu-
</listItem>
<bodyText confidence="0.9426932">
rally captured by trigrams instead of bigram.
For example, (developed , attachment) most
likely occurs in a corpus as ‘developed an at-
tachment’ or ‘developed the attachment’. Our
bigram approach can fail here.
</bodyText>
<listItem confidence="0.883011">
• Sense disambiguation: We don’t disambiguate
</listItem>
<bodyText confidence="0.966656454545454">
senses while comparing the WordNet relations.
This increases our false negatives.
• Also as mentioned earlier, the labels are on
sentences and not on the typed relationships.
Therefore even though a sentence has one or
more of the noun form types, those may be
normal relationships while the whole sentence
may be metaphoric because of other types.
Note, however, that some of these mismatches
are corrected for the ‘All types combined’ re-
sult.
</bodyText>
<sectionHeader confidence="0.999958" genericHeader="method">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999424673469388">
There has been a long history of research in
metaphors. We briefly review some of them here.
One thing that sets our work apart is that most pre-
vious literatures in this area tend to give little em-
pirical evaluation of their approaches. In contrast, in
this study we provide detailed analysis of the effec-
tiveness of our approaches.
(Fass and Wilks, 1983) proposes the use of pref-
erence semantics for metaphor recognition. Tech-
niques for automatically detecting selections prefer-
ences have been discussed in (McCarthy and Car-
rol, 2003) and (Resnik, 1997). Type II and Type III
approaches discussed in this paper uses both these
ideas for detecting live metaphors. Fass (Fass, 1991)
uses selectional preference violation technique to
detect metaphors. However they rely on hand-coded
declarative knowledge bases. Our technique de-
pends only on WordNet and we use selection prefer-
ence violation based on the knowledge learned from
the bigram frequencies on the Web.
Markert and Nissim (Markert and Nissim, 2002)
presents a supervised classification algorithm for re-
solving metonymy. Metonymy is a closely related
figure of speech to metaphors where a word is sub-
stituted by another with which it is associated. Ex-
ample,
A pen is mightier than a sword.
Here sword is a metonymy for war and pen is a
metonymy for articles. They use collocation, co-
occurrence and grammatical features in their clas-
sification algorithm.
MetaBank (Martin, 1994) is a large knowledge
base of metaphors empirically collected. The de-
tection technique compares new sentences with this
knowledge base. The accuracy is dependent on the
correctness of the knowledge base and we expect
that some of these metaphors would be dead in the
present context. The techniques we discuss in this
work will drastically reduce the need for manually
constructing such a large collection.
Goatly (Goatly, 1997) proposes using analogy
markers such as ‘like’, ‘such as’, ‘illustrated by’
and lexical markers like ‘literally’, ‘illustrating’,
‘metaphorically’ etc. These would be useful for
identifying simile and explicit metaphoric relations
but not metaphors where the relation between the
target concept and the source concept is not explicit.
The CorMet system (Mason, 2004) dynamically
mines domain specific corpora to find less frequent
</bodyText>
<figure confidence="0.998000444444444">
Precision
0.75
0.65
0.55
0.45
0.7
0.6
0.5
All types combined
</figure>
<page confidence="0.993236">
19
</page>
<bodyText confidence="0.999945071428571">
usages and identifies conceptual metaphors. How-
ever the system is limited to extracting only selec-
tional preferences of verbs. Verbal selectional pref-
erence is the verb’s preference for the type of argu-
ment it takes.
Dolan (Dolan, 1995) uses the path and path length
between words in the knowledge base derived from
lexical resources for interpreting the interrelation-
ship between the component parts of a metaphor.
The effectiveness of this technique relies on whether
the metaphoric sense is encoded in the dictionar-
ies. This approach however will not be effective for
novel metaphoric usages that are not encoded in dic-
tionaries.
</bodyText>
<sectionHeader confidence="0.999706" genericHeader="method">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999700733333334">
In this paper we show that we can use the hyponym
relation in WordNet and word co-occurrence infor-
mation for detecting metaphoric uses in subject-
object, verb-noun and adjective-noun relationships.
According to (Cameron and Deignan, 2006), non
literal expressions with relatively fixed forms and
highly specific semantics are over-represented in the
metaphor literature in comparison to corpora occur-
rences. Therefore as part of future work we would
be studying the effect of our algorithms for naturally
occurring text. We are also interested in increasing
the confidence of the labels using more and diverse
annotators and see how the techniques perform. The
study can then be extended to incorporate the role of
prepositions in metaphoric uses.
</bodyText>
<sectionHeader confidence="0.998194" genericHeader="conclusions">
7 Acknowledgment
</sectionHeader>
<bodyText confidence="0.9997118">
We would like to thank our anonymous reviewers for
their constructive suggestions that helped improve
this paper. We would also like to thank Mr. Kr-
ishna Kumaran Damodaran for annotating the Mas-
ter Metaphor List.
</bodyText>
<sectionHeader confidence="0.999467" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999806979591836">
Thorsten Brants and Alex Franz. 2006. Web 1T 5-gram
Version 1. Linguistic Data Consortium, Philadelphia.
Lynne Cameron and Alice Deignan. 2006. The emer-
gence of metaphor in discourse. Applied Linguistics,
27(4):671–690.
William B. Dolan. 1995. Metaphor as an emergent
property of machine-readable dictionaries. AAAI 1995
Spring Symposium, 95(1):27–32.
Dan Fass and Yorick Wilks. 1983. Preference semantics,
ill-formedness, and metaphor. American Journal of
Computational Linguistics, 9(3):178–187.
Dan Fass. 1991. Met: A method for discriminating
metonymy and metaphor by computer. Computational
Linguistics, 17(1):49–90.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press, Cambridge, MA.
Raymond Gibbs. 1984. Literal meaning and psychologi-
cal theory. Cognitive Science, 8:275–304.
Andrew Goatly. 1997. The Language of Metaphors.
Routledge,London.
Dan Klein and Christopher D. Manning. 2003. Accu-
rate unlexicalized parsing. In Proceedings of the 41st
Meeting of the Association for Computational Linguis-
tics.
George Lakoff and Mark Johnson. 1980. Metaphors We
Live By. University of Chicago Press, Chicago, Illi-
nois.
Katja Markert and Malvina Nissim. 2002. Metonymy
resolution as a classification task. In Proceedings of
ACL-02 conference on Empirical Methods in Natural
Language Processing, pages 204–213.
James H. Martin. 1994. Metabank: a knowledge-base
of metaphoric language conventions. Computational
Intelligence, 10(2):134–149.
Zachary J. Mason. 2004. Cormet: A computational,
corpus-based conventional metaphor extraction sys-
tem. Computational Linguistics, 30(1):23–44.
Diana McCarthy and John Carrol. 2003. Disambiguat-
ing nouns, verbs and adjectives using automatically
acquired selectional preferences. Computational Lin-
guistics, 29(4):639–654.
Geoffrey Nunberg. 1987. Poetic and prosaic metaphors.
In Proceedings of the 1987 workshop on Theoretical
issues in natural language processing, pages 198–201.
Philip Resnik. 1997. Selectional preferences and word
sense disambiguation. In Proceedings of ACL Siglex
Workshop on Tagging Text with Lexical Semantics,
Why, What and How?, Washington, D.C., pages 52–
57.
</reference>
<page confidence="0.99463">
20
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.470608">
<title confidence="0.988772">Hunting Elusive Metaphors Using Lexical Resources</title>
<affiliation confidence="0.9708365">Computer Sciences University of</affiliation>
<address confidence="0.984784">Madison, WI</address>
<email confidence="0.999353">ksai@cs.wisc.edu</email>
<author confidence="0.525618">Xiaojin</author>
<affiliation confidence="0.9987575">Computer Sciences University of</affiliation>
<address confidence="0.989309">Madison, WI</address>
<email confidence="0.999627">jerryzhu@cs.wisc.edu</email>
<abstract confidence="0.9987658">In this paper we propose algorithms to automatically classify sentences into metaphoric or normal usages. Our algorithms only need the WordNet and bigram counts, and does not require training. We present empirical results on a test set derived from the Master Metaphor List. We also discuss issues that make classification of metaphors a tough problem in general.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<date>2006</date>
<booktitle>Web 1T 5-gram Version 1. Linguistic Data Consortium,</booktitle>
<location>Philadelphia.</location>
<contexts>
<context position="7804" citStr="Brants and Franz, 2006" startWordPosition="1247" endWordPosition="1250"> not ‘be’) Type III Adjective acting on Noun He is a brave lion. An example of Type II form metaphor is He planted good ideas in their minds. An example for Type III form metaphor is He has a fertile imagination. We use two different approaches for Type I vs. Types II, III. In Type I form we are interested in the relationship between the subject and the object. We use a hyponym heuristic. In Types II and III, we are interested in the subject-verb, verb-object, or adjective-noun relations. We use hyponym together with word co-occurrence information, in this case bigrams from the Web 1T corpus (Brants and Franz, 2006). Sections 3.1 and 3.2 discuss the two algorithms, respectively. We use a parser (Klein and Manning, 2003) to obtain the relationships between nouns, verbs and adjectives in a sentence. 3.1 Identifying Type I metaphors We identify the WordNet hyponym relationship (or the lack thereof) between the subject and the object in a Type I sentence. We classify the sentence as metaphoric, if the subject and object does not have a hyponym relation. A hyponym relation exists between a pair of words if and only if one word is a subclass of another word. We motivate this idea using some examples. Let us co</context>
<context position="11444" citStr="Brants and Franz, 2006" startWordPosition="1855" endWordPosition="1858">I metaphors. V/A-N matrix stands for Verb/Adjective-Noun matrix, which is a two dimensional matrix with verbs or adjectives along one dimension, and nouns along the other. The entries are co-occurrence frequency of the word pair, from which we may estimate the conditional probability p(wn|w) for a noun wn and a verb or adjective w. Ideally the matrix should be constructed from a parsed corpus, so that we can identify V/AN pairs from their syntactic roles. However parsing a large corpus would be prohibitively expensive. As a practical approximation, we use bigram counts from the Web 1T corpus (Brants and Franz, 2006). Web 1T corpus consists of English word n-grams (up to 5-grams) generated from approximately 1 trillion word tokens of text from public Web pages. In this paper we use the bigram data in which a noun follows either a verb or an adjective. We note that this approximation thus misses, for example, the pair (plant, idea) in phrases like ‘plant an idea’. Nonetheless, the hope is that the corpus makes it up by sheer size. 3.2.1 Type II metaphors We discuss the metaphoric relationship between a verb-noun pair (wv, wn). The idea is that if neither wn nor its hyponyms or hypernyms co-occur frequently</context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>Thorsten Brants and Alex Franz. 2006. Web 1T 5-gram Version 1. Linguistic Data Consortium, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynne Cameron</author>
<author>Alice Deignan</author>
</authors>
<title>The emergence of metaphor in discourse.</title>
<date>2006</date>
<journal>Applied Linguistics,</journal>
<volume>27</volume>
<issue>4</issue>
<contexts>
<context position="24424" citStr="Cameron and Deignan, 2006" startWordPosition="4020" endWordPosition="4023">th length between words in the knowledge base derived from lexical resources for interpreting the interrelationship between the component parts of a metaphor. The effectiveness of this technique relies on whether the metaphoric sense is encoded in the dictionaries. This approach however will not be effective for novel metaphoric usages that are not encoded in dictionaries. 6 Conclusion In this paper we show that we can use the hyponym relation in WordNet and word co-occurrence information for detecting metaphoric uses in subjectobject, verb-noun and adjective-noun relationships. According to (Cameron and Deignan, 2006), non literal expressions with relatively fixed forms and highly specific semantics are over-represented in the metaphor literature in comparison to corpora occurrences. Therefore as part of future work we would be studying the effect of our algorithms for naturally occurring text. We are also interested in increasing the confidence of the labels using more and diverse annotators and see how the techniques perform. The study can then be extended to incorporate the role of prepositions in metaphoric uses. 7 Acknowledgment We would like to thank our anonymous reviewers for their constructive sug</context>
</contexts>
<marker>Cameron, Deignan, 2006</marker>
<rawString>Lynne Cameron and Alice Deignan. 2006. The emergence of metaphor in discourse. Applied Linguistics, 27(4):671–690.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William B Dolan</author>
</authors>
<title>Metaphor as an emergent property of machine-readable dictionaries.</title>
<date>1995</date>
<booktitle>AAAI 1995 Spring Symposium,</booktitle>
<pages>95--1</pages>
<contexts>
<context position="23777" citStr="Dolan, 1995" startWordPosition="3921" endWordPosition="3922">strating’, ‘metaphorically’ etc. These would be useful for identifying simile and explicit metaphoric relations but not metaphors where the relation between the target concept and the source concept is not explicit. The CorMet system (Mason, 2004) dynamically mines domain specific corpora to find less frequent Precision 0.75 0.65 0.55 0.45 0.7 0.6 0.5 All types combined 19 usages and identifies conceptual metaphors. However the system is limited to extracting only selectional preferences of verbs. Verbal selectional preference is the verb’s preference for the type of argument it takes. Dolan (Dolan, 1995) uses the path and path length between words in the knowledge base derived from lexical resources for interpreting the interrelationship between the component parts of a metaphor. The effectiveness of this technique relies on whether the metaphoric sense is encoded in the dictionaries. This approach however will not be effective for novel metaphoric usages that are not encoded in dictionaries. 6 Conclusion In this paper we show that we can use the hyponym relation in WordNet and word co-occurrence information for detecting metaphoric uses in subjectobject, verb-noun and adjective-noun relation</context>
</contexts>
<marker>Dolan, 1995</marker>
<rawString>William B. Dolan. 1995. Metaphor as an emergent property of machine-readable dictionaries. AAAI 1995 Spring Symposium, 95(1):27–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Fass</author>
<author>Yorick Wilks</author>
</authors>
<title>Preference semantics, ill-formedness, and metaphor.</title>
<date>1983</date>
<journal>American Journal of Computational Linguistics,</journal>
<volume>9</volume>
<issue>3</issue>
<contexts>
<context position="21537" citStr="Fass and Wilks, 1983" startWordPosition="3569" endWordPosition="3572">gh a sentence has one or more of the noun form types, those may be normal relationships while the whole sentence may be metaphoric because of other types. Note, however, that some of these mismatches are corrected for the ‘All types combined’ result. 5 Related Work There has been a long history of research in metaphors. We briefly review some of them here. One thing that sets our work apart is that most previous literatures in this area tend to give little empirical evaluation of their approaches. In contrast, in this study we provide detailed analysis of the effectiveness of our approaches. (Fass and Wilks, 1983) proposes the use of preference semantics for metaphor recognition. Techniques for automatically detecting selections preferences have been discussed in (McCarthy and Carrol, 2003) and (Resnik, 1997). Type II and Type III approaches discussed in this paper uses both these ideas for detecting live metaphors. Fass (Fass, 1991) uses selectional preference violation technique to detect metaphors. However they rely on hand-coded declarative knowledge bases. Our technique depends only on WordNet and we use selection preference violation based on the knowledge learned from the bigram frequencies on t</context>
</contexts>
<marker>Fass, Wilks, 1983</marker>
<rawString>Dan Fass and Yorick Wilks. 1983. Preference semantics, ill-formedness, and metaphor. American Journal of Computational Linguistics, 9(3):178–187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Fass</author>
</authors>
<title>Met: A method for discriminating metonymy and metaphor by computer.</title>
<date>1991</date>
<journal>Computational Linguistics,</journal>
<volume>17</volume>
<issue>1</issue>
<contexts>
<context position="21863" citStr="Fass, 1991" startWordPosition="3622" endWordPosition="3623">iew some of them here. One thing that sets our work apart is that most previous literatures in this area tend to give little empirical evaluation of their approaches. In contrast, in this study we provide detailed analysis of the effectiveness of our approaches. (Fass and Wilks, 1983) proposes the use of preference semantics for metaphor recognition. Techniques for automatically detecting selections preferences have been discussed in (McCarthy and Carrol, 2003) and (Resnik, 1997). Type II and Type III approaches discussed in this paper uses both these ideas for detecting live metaphors. Fass (Fass, 1991) uses selectional preference violation technique to detect metaphors. However they rely on hand-coded declarative knowledge bases. Our technique depends only on WordNet and we use selection preference violation based on the knowledge learned from the bigram frequencies on the Web. Markert and Nissim (Markert and Nissim, 2002) presents a supervised classification algorithm for resolving metonymy. Metonymy is a closely related figure of speech to metaphors where a word is substituted by another with which it is associated. Example, A pen is mightier than a sword. Here sword is a metonymy for war</context>
</contexts>
<marker>Fass, 1991</marker>
<rawString>Dan Fass. 1991. Met: A method for discriminating metonymy and metaphor by computer. Computational Linguistics, 17(1):49–90.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raymond Gibbs</author>
</authors>
<title>Literal meaning and psychological theory.</title>
<date>1984</date>
<journal>Cognitive Science,</journal>
<pages>8--275</pages>
<contexts>
<context position="2726" citStr="Gibbs, 1984" startWordPosition="406" endWordPosition="407">aphoric usages. Also it is easy to create novel and interesting uses of metaphors as long as one concept is explained in terms of another concept. The performance of machine translation systems will be affected in such cases especially if they have not encountered such metaphoric uses before. Metaphor identification in text documents is, however, complicated by issues including context sensitiveness, emergence of novel metaphoric forms, and the need for semantic knowledge about the sentences. Metaphoric appeal differs across language or people’s prior exposure to such usages. In addition, as (Gibbs, 1984) points out, literal and figurative expressions are end points of a single continuum along which metaphoricity and idiomaticity are situated, thereby making clear demarcation of metaphoric and normal usages fuzzy. We discuss many such issues that make the task of classifying sentences into metaphoric or nonmetaphoric difficult. We then focuses on a subset of metaphoric usages involving the nouns in a sentence. In particular, we identify the subjectobject, verb-noun and adjective-noun relationships in sentences and classify them as metaphoric or Proceedings of the Workshop on Computational Appr</context>
</contexts>
<marker>Gibbs, 1984</marker>
<rawString>Raymond Gibbs. 1984. Literal meaning and psychological theory. Cognitive Science, 8:275–304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Goatly</author>
</authors>
<date>1997</date>
<journal>The Language of Metaphors. Routledge,London.</journal>
<contexts>
<context position="23046" citStr="Goatly, 1997" startWordPosition="3810" endWordPosition="3811">re sword is a metonymy for war and pen is a metonymy for articles. They use collocation, cooccurrence and grammatical features in their classification algorithm. MetaBank (Martin, 1994) is a large knowledge base of metaphors empirically collected. The detection technique compares new sentences with this knowledge base. The accuracy is dependent on the correctness of the knowledge base and we expect that some of these metaphors would be dead in the present context. The techniques we discuss in this work will drastically reduce the need for manually constructing such a large collection. Goatly (Goatly, 1997) proposes using analogy markers such as ‘like’, ‘such as’, ‘illustrated by’ and lexical markers like ‘literally’, ‘illustrating’, ‘metaphorically’ etc. These would be useful for identifying simile and explicit metaphoric relations but not metaphors where the relation between the target concept and the source concept is not explicit. The CorMet system (Mason, 2004) dynamically mines domain specific corpora to find less frequent Precision 0.75 0.65 0.55 0.45 0.7 0.6 0.5 All types combined 19 usages and identifies conceptual metaphors. However the system is limited to extracting only selectional </context>
</contexts>
<marker>Goatly, 1997</marker>
<rawString>Andrew Goatly. 1997. The Language of Metaphors. Routledge,London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="7910" citStr="Klein and Manning, 2003" startWordPosition="1264" endWordPosition="1267">e planted good ideas in their minds. An example for Type III form metaphor is He has a fertile imagination. We use two different approaches for Type I vs. Types II, III. In Type I form we are interested in the relationship between the subject and the object. We use a hyponym heuristic. In Types II and III, we are interested in the subject-verb, verb-object, or adjective-noun relations. We use hyponym together with word co-occurrence information, in this case bigrams from the Web 1T corpus (Brants and Franz, 2006). Sections 3.1 and 3.2 discuss the two algorithms, respectively. We use a parser (Klein and Manning, 2003) to obtain the relationships between nouns, verbs and adjectives in a sentence. 3.1 Identifying Type I metaphors We identify the WordNet hyponym relationship (or the lack thereof) between the subject and the object in a Type I sentence. We classify the sentence as metaphoric, if the subject and object does not have a hyponym relation. A hyponym relation exists between a pair of words if and only if one word is a subclass of another word. We motivate this idea using some examples. Let us consider a normal sentence with a subject-object relationship governed by a ‘be’ form verb, ‘is’. A lion is </context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
<author>Mark Johnson</author>
</authors>
<title>Metaphors We Live By.</title>
<date>1980</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago, Illinois.</location>
<contexts>
<context position="1019" citStr="Lakoff and Johnson, 1980" startWordPosition="140" endWordPosition="144">ges. Our algorithms only need the WordNet and bigram counts, and does not require training. We present empirical results on a test set derived from the Master Metaphor List. We also discuss issues that make classification of metaphors a tough problem in general. 1 Introduction Metaphor is an interesting figure of speech which expresses an analogy between two seemingly unrelated concepts. Metaphoric usages enhance the attributes of the source concept by comparing it with the attributes of the target concept. Abstractions and enormously complex situations are routinely understood via metaphors (Lakoff and Johnson, 1980). Metaphors begin their lives as Novel Poetic Creations with marked rhetoric effects whose comprehension requires special imaginative leap. As time goes by, they become part of general use and their comprehension becomes automatic and idiomatic and rhetoric effect is dulled (Nunberg, 1987). We term such metaphors whose idiomatic effects are dulled because of common usage as dead metaphors while metaphors with novel usages as live metaphors. In this paper we are interested only in identifying live metaphors. * The first author is currently affiliated with Google Inc, Mountain View, CA. 13 Metap</context>
<context position="14536" citStr="Lakoff and Johnson, 1980" startWordPosition="2384" endWordPosition="2387">y with the ‘fertile’ in our corpus are ‘soil’, ‘land’, ‘territory’, and ‘plains’, etc. Comparison of the WordNet hierarchies of the noun ‘imagination’ with each of these nouns will show that there does not exist any hyponym relation between ‘imagination’ and any of these nouns. Hence we classify them as metaphors. As another example, TV is an idiot box. The adjective ‘idiot’ qualifies nouns related to people such as ‘boy’, ‘man’, etc. that are unrelated to the noun ‘box’. Thus we classify it as a Type III metaphor. 4 Experimental Results We experimented with the Berkeley Master Metaphor List (Lakoff and Johnson, 1980) to compute the performance of our techniques. The Berkeley Master Metaphor List is a collection of nearly 1728 unique sentences and phrases. We corrected some typos and spelling errors in the Master list and expanded phrases to complete sentences. The list has many metaphoric uses which has become very common usages in today’s standards, and thus no longer have any rhetoric effects. Therefore, we manually label the sentences in the Master List into 789 ‘live metaphors’ and the remaining ones ‘dead metaphors’ as the ground truth&apos;. Table 2 shows the initial performance of the Type I algorithm. </context>
</contexts>
<marker>Lakoff, Johnson, 1980</marker>
<rawString>George Lakoff and Mark Johnson. 1980. Metaphors We Live By. University of Chicago Press, Chicago, Illinois.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katja Markert</author>
<author>Malvina Nissim</author>
</authors>
<title>Metonymy resolution as a classification task.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL-02 conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>204--213</pages>
<contexts>
<context position="22190" citStr="Markert and Nissim, 2002" startWordPosition="3669" endWordPosition="3672">nce semantics for metaphor recognition. Techniques for automatically detecting selections preferences have been discussed in (McCarthy and Carrol, 2003) and (Resnik, 1997). Type II and Type III approaches discussed in this paper uses both these ideas for detecting live metaphors. Fass (Fass, 1991) uses selectional preference violation technique to detect metaphors. However they rely on hand-coded declarative knowledge bases. Our technique depends only on WordNet and we use selection preference violation based on the knowledge learned from the bigram frequencies on the Web. Markert and Nissim (Markert and Nissim, 2002) presents a supervised classification algorithm for resolving metonymy. Metonymy is a closely related figure of speech to metaphors where a word is substituted by another with which it is associated. Example, A pen is mightier than a sword. Here sword is a metonymy for war and pen is a metonymy for articles. They use collocation, cooccurrence and grammatical features in their classification algorithm. MetaBank (Martin, 1994) is a large knowledge base of metaphors empirically collected. The detection technique compares new sentences with this knowledge base. The accuracy is dependent on the cor</context>
</contexts>
<marker>Markert, Nissim, 2002</marker>
<rawString>Katja Markert and Malvina Nissim. 2002. Metonymy resolution as a classification task. In Proceedings of ACL-02 conference on Empirical Methods in Natural Language Processing, pages 204–213.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James H Martin</author>
</authors>
<title>Metabank: a knowledge-base of metaphoric language conventions.</title>
<date>1994</date>
<journal>Computational Intelligence,</journal>
<volume>10</volume>
<issue>2</issue>
<contexts>
<context position="22618" citStr="Martin, 1994" startWordPosition="3742" endWordPosition="3743">ue depends only on WordNet and we use selection preference violation based on the knowledge learned from the bigram frequencies on the Web. Markert and Nissim (Markert and Nissim, 2002) presents a supervised classification algorithm for resolving metonymy. Metonymy is a closely related figure of speech to metaphors where a word is substituted by another with which it is associated. Example, A pen is mightier than a sword. Here sword is a metonymy for war and pen is a metonymy for articles. They use collocation, cooccurrence and grammatical features in their classification algorithm. MetaBank (Martin, 1994) is a large knowledge base of metaphors empirically collected. The detection technique compares new sentences with this knowledge base. The accuracy is dependent on the correctness of the knowledge base and we expect that some of these metaphors would be dead in the present context. The techniques we discuss in this work will drastically reduce the need for manually constructing such a large collection. Goatly (Goatly, 1997) proposes using analogy markers such as ‘like’, ‘such as’, ‘illustrated by’ and lexical markers like ‘literally’, ‘illustrating’, ‘metaphorically’ etc. These would be usefu</context>
</contexts>
<marker>Martin, 1994</marker>
<rawString>James H. Martin. 1994. Metabank: a knowledge-base of metaphoric language conventions. Computational Intelligence, 10(2):134–149.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zachary J Mason</author>
</authors>
<title>Cormet: A computational, corpus-based conventional metaphor extraction system.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="23412" citStr="Mason, 2004" startWordPosition="3862" endWordPosition="3863">f the knowledge base and we expect that some of these metaphors would be dead in the present context. The techniques we discuss in this work will drastically reduce the need for manually constructing such a large collection. Goatly (Goatly, 1997) proposes using analogy markers such as ‘like’, ‘such as’, ‘illustrated by’ and lexical markers like ‘literally’, ‘illustrating’, ‘metaphorically’ etc. These would be useful for identifying simile and explicit metaphoric relations but not metaphors where the relation between the target concept and the source concept is not explicit. The CorMet system (Mason, 2004) dynamically mines domain specific corpora to find less frequent Precision 0.75 0.65 0.55 0.45 0.7 0.6 0.5 All types combined 19 usages and identifies conceptual metaphors. However the system is limited to extracting only selectional preferences of verbs. Verbal selectional preference is the verb’s preference for the type of argument it takes. Dolan (Dolan, 1995) uses the path and path length between words in the knowledge base derived from lexical resources for interpreting the interrelationship between the component parts of a metaphor. The effectiveness of this technique relies on whether t</context>
</contexts>
<marker>Mason, 2004</marker>
<rawString>Zachary J. Mason. 2004. Cormet: A computational, corpus-based conventional metaphor extraction system. Computational Linguistics, 30(1):23–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>John Carrol</author>
</authors>
<title>Disambiguating nouns, verbs and adjectives using automatically acquired selectional preferences.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>4</issue>
<contexts>
<context position="21717" citStr="McCarthy and Carrol, 2003" startWordPosition="3595" endWordPosition="3599">some of these mismatches are corrected for the ‘All types combined’ result. 5 Related Work There has been a long history of research in metaphors. We briefly review some of them here. One thing that sets our work apart is that most previous literatures in this area tend to give little empirical evaluation of their approaches. In contrast, in this study we provide detailed analysis of the effectiveness of our approaches. (Fass and Wilks, 1983) proposes the use of preference semantics for metaphor recognition. Techniques for automatically detecting selections preferences have been discussed in (McCarthy and Carrol, 2003) and (Resnik, 1997). Type II and Type III approaches discussed in this paper uses both these ideas for detecting live metaphors. Fass (Fass, 1991) uses selectional preference violation technique to detect metaphors. However they rely on hand-coded declarative knowledge bases. Our technique depends only on WordNet and we use selection preference violation based on the knowledge learned from the bigram frequencies on the Web. Markert and Nissim (Markert and Nissim, 2002) presents a supervised classification algorithm for resolving metonymy. Metonymy is a closely related figure of speech to metap</context>
</contexts>
<marker>McCarthy, Carrol, 2003</marker>
<rawString>Diana McCarthy and John Carrol. 2003. Disambiguating nouns, verbs and adjectives using automatically acquired selectional preferences. Computational Linguistics, 29(4):639–654.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Nunberg</author>
</authors>
<title>Poetic and prosaic metaphors.</title>
<date>1987</date>
<booktitle>In Proceedings of the 1987 workshop on Theoretical issues in natural language processing,</booktitle>
<pages>198--201</pages>
<contexts>
<context position="1309" citStr="Nunberg, 1987" startWordPosition="185" endWordPosition="186">ing figure of speech which expresses an analogy between two seemingly unrelated concepts. Metaphoric usages enhance the attributes of the source concept by comparing it with the attributes of the target concept. Abstractions and enormously complex situations are routinely understood via metaphors (Lakoff and Johnson, 1980). Metaphors begin their lives as Novel Poetic Creations with marked rhetoric effects whose comprehension requires special imaginative leap. As time goes by, they become part of general use and their comprehension becomes automatic and idiomatic and rhetoric effect is dulled (Nunberg, 1987). We term such metaphors whose idiomatic effects are dulled because of common usage as dead metaphors while metaphors with novel usages as live metaphors. In this paper we are interested only in identifying live metaphors. * The first author is currently affiliated with Google Inc, Mountain View, CA. 13 Metaphors have interesting applications in many NLP problems like machine translation, text summarization, information retrieval and question answering. Consider the task of summarizing a parable which is a metaphoric story with a moral. The best summary of a parable is the moral. Paraphrasing </context>
</contexts>
<marker>Nunberg, 1987</marker>
<rawString>Geoffrey Nunberg. 1987. Poetic and prosaic metaphors. In Proceedings of the 1987 workshop on Theoretical issues in natural language processing, pages 198–201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Selectional preferences and word sense disambiguation.</title>
<date>1997</date>
<booktitle>In Proceedings of ACL Siglex Workshop on Tagging Text with Lexical Semantics, Why, What and How?,</booktitle>
<pages>52--57</pages>
<location>Washington, D.C.,</location>
<contexts>
<context position="21736" citStr="Resnik, 1997" startWordPosition="3601" endWordPosition="3602">rected for the ‘All types combined’ result. 5 Related Work There has been a long history of research in metaphors. We briefly review some of them here. One thing that sets our work apart is that most previous literatures in this area tend to give little empirical evaluation of their approaches. In contrast, in this study we provide detailed analysis of the effectiveness of our approaches. (Fass and Wilks, 1983) proposes the use of preference semantics for metaphor recognition. Techniques for automatically detecting selections preferences have been discussed in (McCarthy and Carrol, 2003) and (Resnik, 1997). Type II and Type III approaches discussed in this paper uses both these ideas for detecting live metaphors. Fass (Fass, 1991) uses selectional preference violation technique to detect metaphors. However they rely on hand-coded declarative knowledge bases. Our technique depends only on WordNet and we use selection preference violation based on the knowledge learned from the bigram frequencies on the Web. Markert and Nissim (Markert and Nissim, 2002) presents a supervised classification algorithm for resolving metonymy. Metonymy is a closely related figure of speech to metaphors where a word i</context>
</contexts>
<marker>Resnik, 1997</marker>
<rawString>Philip Resnik. 1997. Selectional preferences and word sense disambiguation. In Proceedings of ACL Siglex Workshop on Tagging Text with Lexical Semantics, Why, What and How?, Washington, D.C., pages 52– 57.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>