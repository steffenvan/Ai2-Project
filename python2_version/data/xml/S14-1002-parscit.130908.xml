<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000258">
<title confidence="0.910544">
Generating a Word-Emotion Lexicon from #Emotional Tweets
</title>
<author confidence="0.978931">
Anil Bandhakavi&apos; Nirmalie Wiratunga&apos; Deepak P2 Stewart Massie&apos;
</author>
<affiliation confidence="0.839374">
&apos; IDEAS Research Institute, Robert Gordon University, Scotland, UK
2 IBM Research - India, Bangalore, India
</affiliation>
<email confidence="0.9788365">
{a.s.bandhakavi,n.wiratunga}@rgu.ac.uk
deepaksp@acm.org, s.massie@rgu.ac.uk
</email>
<sectionHeader confidence="0.997336" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999897909090909">
Research in emotion analysis of text sug-
gest that emotion lexicon based features
are superior to corpus based n-gram fea-
tures. However the static nature of the
general purpose emotion lexicons make
them less suited to social media analysis,
where the need to adopt to changes in vo-
cabulary usage and context is crucial. In
this paper we propose a set of methods to
extract a word-emotion lexicon automati-
cally from an emotion labelled corpus of
tweets. Our results confirm that the fea-
tures derived from these lexicons outper-
form the standard Bag-of-words features
when applied to an emotion classification
task. Furthermore, a comparative analysis
with both manually crafted lexicons and
a state-of-the-art lexicon generated using
Point-Wise Mutual Information, show that
the lexicons generated from the proposed
methods lead to significantly better classi-
fication performance.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999882714285715">
Emotion mining or affect sensing is the compu-
tational study of natural language expressions in
order to quantify their associations with different
emotions (e.g. anger, fear, joy, sadness and sur-
prise). It has a number of applications for the in-
dustry, commerce and government organisations,
but uptake has arguably been slow. This in part is
due to the challenges involved with modelling sub-
jectivity and complexity of the emotive content.
However, use of qualitative metrics to capture
emotive strength and extraction of features from
these metrics has in recent years shown promise
(Shaikh, 2009). A general-purpose emotion lexi-
con (GPEL) is a commonly used resource that al-
lows qualitative assessment of a piece of emotive
text. Given a word and an emotion, the lexicon
provides a score to quantify the strength of emo-
tion expressed by that word. Such lexicons are
carefully crafted and are utilised by both super-
vised and unsupervised algorithms to directly ag-
gregate an overall emotion score or indirectly de-
rive features for emotion classification tasks (Mo-
hammad, 2012a), (Mohammad, 2012b).
Socio-linguistics suggest that social media is a
popular means for people to converse with individ-
uals, groups and the world in general (Boyd et al.,
2010). These conversations often involve usage of
non-standard natural language expressions which
consistently evolve. Twitter and Facebook were
credited for providing momentum for the 2011
Arab Spring and Occupy Wall street movements
(Ray, 2011),(Skinner, 2011). Therefore efforts to
model social conversations would provide valu-
able insights into how people influence each other
through emotional expressions. Emotion analysis
in such domains calls for automated discovery of
lexicons. This is so since learnt lexicons can in-
tuitively capture the evolving nature of vocabulary
in such domains better than GPELs.
In this work we show how an emotion la-
belled corpus can be leveraged to generate a word-
emotion lexicon automatically. Key to this is the
availability of a labelled corpus which may be ob-
tained using a distance-supervised approach to la-
belling (Wang et al., 2012). In this paper we pro-
pose three lexicon generation methods and evalu-
ate the quality of these by deploying them in an
emotion classification task. We show through our
experiments that the word-emotion lexicon gener-
ated using the proposed methods in this paper sig-
nificantly outperforms GPELs such as WordnetAf-
fect, NRC word-emotion association lexicon and a
leaxicon learnt using Point-wise Mutual Informa-
tion (PMI). Additionally, our lexicons also outper-
form the traditional Bag-of-Words representation.
The rest of the paper is organised as follows: In
</bodyText>
<page confidence="0.984641">
12
</page>
<note confidence="0.9808745">
Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 12–21,
Dublin, Ireland, August 23-24 2014.
</note>
<bodyText confidence="0.999752333333333">
Section 2 we present the related work. In Section
3 we outline the problem. In Section 4 we for-
mulate the different methods proposed to generate
the word-emotion lexicons. In Section 5 we dis-
cuss experimental results followed by conclusions
and future work in Section 6.
</bodyText>
<sectionHeader confidence="0.999929" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999426918604651">
Computational emotion analysis, draws from cog-
nitive and physiology studies to establish the key
emotion categories; and NLP and text mining re-
search to establish features designed to represent
emotive content. Emotion analysis has been ap-
plied in a variety of domains: fairy tales (Fran-
cisco and Gervas, 2006; Alm et al., 2005);
blogs (Mihalcea and Liu, 2006; Neviarouskaya et
al., 2010), novels (John et al., 2006), chat mes-
sages (E.Holzman and William M, 2003; Ma et
al., 2005; Mohammad and Yang, 2011) and emo-
tional events on social media content(Kim et al.,
2009). Comparative studies on emotive word dis-
tributions on micro-blogs and personal content
(e.g. love letters, suicide notes) have shown that
emotions such as disgust are expressed well in
tweets. Further, expression of emotion in tweets
and love letters have been shown to have similari-
ties(K. Roberts and Harabagiu, 2012).
Emotion classification frameworks provide in-
sights into human emotion expressions (Ekman,
1992; Plutchik, 1980; Parrott, 2001). The emo-
tions proposed by (Ekman, 1992) are popular in
emotion classification tasks (Mohammad, 2012b;
Aman and Szpakowicz, 2008). Recently there has
also been interest in extending this basic emo-
tion framework to model more complex emotions
(such as politeness, rudeness, deception, depres-
sion, vigour and confusion) (Pearl and Steyvers,
2010; Bollen et al., 2009). A common theme
across these approaches involves the selection
of emotion-rich features and learning of relevant
weights to capture emotion strength (Mohammad,
2012a; Qadir and Riloff, 2013).
Usefulness of a lexicon: Lexicons such as
Wordnet Affect (Strapparava and Valitutti, 2004)
and NRC (Saif M. Mohammad, 2013)) are
very valuable resources from which emotion
features can be derived for text representation.
These are manually crafted and typically con-
tain emotion-rich formal vocabulary. Hybrid ap-
proaches that combine features derived from these
static lexicons with n-grams have resulted in bet-
ter performance than either alone (Mohammad,
2012b),(Aman and Szpakowicz, 2008). However
the informal and dynamic nature of social me-
dia content makes it harder to adopt these lexi-
cons for emotion analysis. An alternative strategy
is to derive features from a dynamic (i.e., learnt)
lexicon. Here association metrics such as Point-
wise Mutual Information (PMI) can be used to
model emotion polarity between a word and emo-
tion labelled content (Mohammad, 2012a). Such
approaches will be used as baselines to compare
against our proposed lexicon generation strategies.
There are other lexicon generation methods pro-
posed by Rao .et. al (Yanghui Rao and Chen,
2013) and Yang .et. al (Yang et al., 2007). We do
not consider these in our comparative evaluation
since these methods require rated emotion labels
and emoticon classes respectively.
Lexicon generation, relies on the availability of
a labelled corpus from which the word-emotion
distributions can be discovered. For this pur-
pose we exploit a distance-supervised approach
where indirect cues are used to unearth implicit
(or distant) labels that are contained in the cor-
pus (Alec Go and Huang, 2009). We adopt
the approach as in (Wang et al., 2012) to cor-
pus labelling where social media content, and in
particular Twitter content is sampled for a pre-
defined set of hashtag cues (P. Shaver, 1987) .
Here each set of cues represent a given emotion
class. Distant-supervision is particularly suited to
Twitter-like platforms because people use hash-
tags to extensively convey or emphasis the emo-
tion behind their tweets (e.g., That was my best
weekend ever.#happy!! #satisfied!). Also given
that tweets are length restricted (140 characters),
modelling the emotional orientation of words in
a Tweet is easier compared to longer documents
that are likely to capture complex and mixed emo-
tions. This simplicity and access to sample data
has made Twitter one of the most popular domains
for emotion analysis research (Wang et al., 2012;
Qadir and Riloff, 2013).
</bodyText>
<sectionHeader confidence="0.993395" genericHeader="method">
3 Problem Definition
</sectionHeader>
<bodyText confidence="0.999934666666667">
We now outline the problem formally. We start
with a set of documents D = {d1, d2, ... , dn}
where each document di has an associated label
Cd, indicating the emotion class to which di be-
longs. We consider the case where the documents
are tweets. For example, a tweet di nice sunday
</bodyText>
<page confidence="0.998318">
13
</page>
<bodyText confidence="0.9998919">
#awesome may have a label joy indicating that the
tweet belongs to the joy emotion class. We also as-
sume that the labels Cdi come from a pre-defined
set of six emotion classes anger, fear, joy, sad, sur-
prise, love. Since our techniques are generic and
do not depend on the number of emotion classes,
we will denote the emotion classes as {Cj}N j=1.
Let there be K words extracted from the training
documents, denoted as {wi}Ki=1. Our task is to de-
rive a lexicon Lex that quantifies the emotional va-
lence of words (from the tweets in D) to emotion
classes. In particular, the lexicon may be thought
of as a 2d-associative array where Lex[w][c] indi-
cates the emotional valence of the word w to the
emotion class c. When there is no ambiguity, we
will use Lex(i, j) to refer to the emotional valence
of word wi to the emotion class Cj. We will quan-
tify the goodness of the lexicons that are generated
using various methods by measuring their perfor-
mance in an emotion classification task.
</bodyText>
<sectionHeader confidence="0.982095" genericHeader="method">
4 Lexicon Generation Methods
</sectionHeader>
<bodyText confidence="0.999955">
We now outline the various methods for lexicon
generation. We first start off with a simple tech-
nique for learning lexicons based on just term fre-
quencies (which we will later use as a baseline
technique), followed by more sophisticated meth-
ods that are based on conceptual models on how
tweets are generated.
</bodyText>
<subsectionHeader confidence="0.996933">
4.1 Term Frequency based Lexicon
</subsectionHeader>
<bodyText confidence="0.9996282">
A simple way to measure the emotional valence of
the word wi to the emotion class Cj is to compute
the probability of occurrence of wi in a tweet la-
belled as Cj, normalized by its probability across
all classes. This leads to:
</bodyText>
<equation confidence="0.9981505">
Lex(i,j) = N(wi |Cj) (1)
Ek=1 p(wi|Ck)
</equation>
<bodyText confidence="0.9999495">
where the conditional probability is simply
computed using term frequencies.
</bodyText>
<equation confidence="0.971105">
p(wi|Cj) = freq(wi, Cj) (2)
freq(Cj)
</equation>
<bodyText confidence="0.999971">
where freq(wi, Cj) is the number of times
wi occurs in documents labeled with class Cj.
freq(Cj) is the total number of documents in Cj.
</bodyText>
<sectionHeader confidence="0.748211" genericHeader="method">
4.2 Iterative methods for Lexicon Generation
</sectionHeader>
<bodyText confidence="0.999867928571429">
The formulation in the previous section generates
a word-emotion matrix L by observing the term
frequencies within a class. However term frequen-
cies alone do not capture the term-class associa-
tions, because not all frequently occurring terms
exhibit the characteristics of a class. For exam-
ple, a term sunday that occurs in a tweet nice sun-
day #awesome labelled joy is evidently not indica-
tive of the class joy; however, the frequency based
computation increments the weight of sunday wrt
the class joy by virtue of this occurrence. In the
following sections, we propose generative models
that seek to remedy such problems of the simple
term frequency based lexicon.
</bodyText>
<subsubsectionHeader confidence="0.637971">
4.2.1 Generative models for Documents
</subsubsectionHeader>
<bodyText confidence="0.999993190476191">
As discussed above, though a document is labelled
with an emotion class, not all terms relate strongly
to the labelled emotion. Some documents may
have terms conveying a different emotion than
what the document is labelled with, since the la-
bel is chosen based on the most prominent emo-
tion in the tweet. Additionally, some words could
be emotion-neutral (e.g., sunday in our example
tweet) and could be conveying non-emotional in-
formation. We now describe two generative mod-
els that account for such considerations, and then
outline methods to learn lexicons based on them.
Mixture of Classes Model: Let LCk be the
unigram language model (Liu and Croft, 2005)
that expresses the lexical character for the emotion
class Ck; though microblogs are short text frag-
ments, language modeling approaches have been
shown to be effective in similarity assesment be-
tween them (Deepak and Chakraborti, 2012). We
model a document di to be generated from across
the emotion class language models:
</bodyText>
<listItem confidence="0.970138">
1. For each word wj in document di,
(a) Lookup the unit vector [λ(1)
</listItem>
<bodyText confidence="0.841983">
dij, ... , λ(N)];
This unit vector defines a probability
distribution over the language models.
</bodyText>
<listItem confidence="0.9058144">
(b) Choose a language model L from
among the K LMs, in accordance with
the vector
(c) Sample wj in accordance with the multi-
nomial distribution L
</listItem>
<bodyText confidence="0.91864125">
If di is labelled with the emotion class Cdi, it is
likely that the value of λ(n)
dij is high for words in di
since it is likely that majority of the words are sam-
pled from the LCd. language model. The posterior
z
probability in accordance with this model can then
be intuitively formulated as:
</bodyText>
<page confidence="0.899206">
14
</page>
<equation confidence="0.984472666666667">
λ(dx) x LCx (wj) (3)
j
wjEdi
</equation>
<bodyText confidence="0.997536444444445">
where θ is the parameters {LCjJN j=1, λ and Cdi
is the class label for document di.
Class and Neutral Model: We now introduce
another model where the words in a document are
assumed to be sampled from either the language
model of the corresponding (i.e., labelled) emo-
tion class or from the neutral language model, LC.
Thus, the generative model for a document di la-
belled with emotion class Cdi would be as follows:
</bodyText>
<listItem confidence="0.9945382">
1. For each word wj in document di,
(a) Lookup the weight µdij ; this parameter
determines the mix of the labelled emo-
tion class and the neutral class, for wj in
di
(b) Choose LCk with a probability of µdij,
and LC with a probability of 1.0 − µdij
(c) Sample wj in accordance with the multi-
nomial distribution of the chosen lan-
guage model
</listItem>
<bodyText confidence="0.9918595">
The posterior probability in accordance with
this model can be intuitively formulated as :
</bodyText>
<equation confidence="0.997459">
P(di, Cdi|θ) = Y µdij x LCdi (wj)
wjEdi (4)
+ (1 − µdij) x LC(wj)
</equation>
<bodyText confidence="0.999931681818182">
where θ is the parameters {LCjJN j=1, LC, µ .
Equation 3 models a document to exhibit char-
acteristics of many classes with different levels
of magnitude. Equation 4 models a document to
be a composition of terms that characterise one
class and other general terms; a similar formula-
tion where a document is modeled using a mix of
two models has been shown to be useful in charac-
terizing problem-solution documents (Deepak et
al., 2012; Deepak and Visweswariah, 2014). The
central idea of the expectation maximization (EM)
algorithm is to maximize the probability of the
data, given the language models {LCjJN j=1 and
LC. The term weights are estimated from the lan-
guage models (E-step) and the language models
are re-estimated (M-step) using the term weights
from the E-step. Thus the maximum likelihood
estimation process in EM alternates between the
E-step and the M-step. In the following sections
we detail the EM process for the two generative
models separately. We compare and contrast the
two variants of the EM algorithm in Table 1.
</bodyText>
<subsectionHeader confidence="0.773616">
4.2.2 EM with Mixture of Classes Model
</subsectionHeader>
<bodyText confidence="0.9852929375">
We will use a matrix based representation for the
language model and the lexicon, to simplify the il-
lustration of the EM steps. Under the matrix nota-
tion, L(p) denotes the K xN matrix at the pth iter-
ation where the ith column is the language model
corresponding to the ith class, i.e., LCi. The pth E-
step estimates the various λdij vectors for all doc-
uments based on the language models in L(p−1),
whereas the M-step re-learns the language models
based on the λ values from the E-step. The steps
are detailed as follows:
E-Step: The λdn) is simply estimated to the
ij
fractional support for the jth word in the ith docu-
ment (denoted as wij) from the nth class language
model:
</bodyText>
<equation confidence="0.9748315">
Pdij λ(n) = L(Cn O 1) (wij) 5
xL(p−1)
</equation>
<bodyText confidence="0.9442695">
Cx (wij)
M-Step: As mentioned before in Table 1 this
step learns the language models from the λ esti-
mates of the previous step. As an example, if a
word w is estimated to have come from the joy lan-
guage model with a weight (i.e., λ) 0.5, it would
contribute 0.5 as its count to the joy language
model. Thus, every occurrence of a word is split
across language models using their corresponding
λ estimates:
</bodyText>
<equation confidence="0.957919">
P P jL(pC) [w] = I (wij = n) x λdn) (6)
Ei Pj λdij
</equation>
<bodyText confidence="0.9999978">
where the indicator function I(wij = w) evalu-
ates to 1 if wij = w is satisfied and 0 otherwise.
After any M-Step, the lexicon can be obtained
by normalizing the L(p) language models so that
the weights for each word adds up to 1.0. i.e.,
</bodyText>
<equation confidence="0.9893216">
L(p)
Cj [wi]
Lex(p)(i, j) = PK (7)
x=1 L(p)
Cx[wi]
</equation>
<bodyText confidence="0.999760666666667">
In the above equation, the suffix (i, j) refers to
the ith word in the jth class, confirming to our 2d-
array representation of the language models.
</bodyText>
<equation confidence="0.91126525">
Y
P(di, Cdi|θ) =
XN
x=1
</equation>
<page confidence="0.988408">
15
</page>
<tableCaption confidence="0.999206">
Table 1: EM Algorithm variants
</tableCaption>
<table confidence="0.999778625">
States EM with mixture of classes model EM with class and neutral model
INPUT Training data T Training data T
OUTPUT Word-Emotion Lexicon Word-Emotion Lexicon
Initialisation Learn the initial language models Learn the initial language models
{LCj}N {LCj}N j=1 and LC
j=1
Convergence While not converged or #Iterations While not converged or #Iterations
&lt; 6, a threshold &lt; 6, a threshold
E-step Estimate the λdijs based on the Estimate µdij based on the current
current estimate of {LCj}N j=1 (Sec estimate of {LCj}N j=1 and LC (Sec
4.2.2) 4.2.3)
M-step Estimate the language models Estimate the language models
{LCj}N j=1 using λdijs (Sec 4.2.2) {LCj}N j=1 and LC using µdij (Sec
4.2.3)
Lexicon Induction Induce a word-emotion lexicon Induce a word-emotion lexicon
from {LCj}N j=1 (Sec 4.2.2) from {LCj}N j=1 and LC (Sec 4.2.3)
</table>
<subsectionHeader confidence="0.590431">
4.2.3 EM with Class and Neutral Model
</subsectionHeader>
<bodyText confidence="0.99968725">
The main difference in this case, when compared
to the previous is that we need to estimate a neutral
language model LC in addition to the class spe-
cific models. We also have fewer parameters to
learn since the µdij is a single value rather than a
vector of N values as in the previous case.
E-Step: µdij is estimated to the relative weight
of the word wij from across the language model of
the corresponding class, and the neutral model:
Where Cdi denotes the class corresponding to
the label of the document di.
M-Step: In a slight contrast from the M-Step
for the earlier case as shown in Table 1, a word
estimated to have a weight (i.e., µ value) of 0.2
would contribute 20% of its count to the cor-
responding class’ language model, while the re-
maining would go to the neutral language model
LC. Since the class-specific and neutral language
models are estimated differently, we have two sep-
arate equations:
</bodyText>
<equation confidence="0.9981265">
P P
j I(wij = w) × µdij
L(p) i,label(di)=Cn
Cn[w] = P Pj µdij
i,label(di)=Cn
(9)
P L(p) [w] =Pj I(wij = w) × (1.0 − µdij )
P Pj(1.0 − µdij)
i
(10)
</equation>
<bodyText confidence="0.999991428571429">
where label(di) = Cn As is obvious, the class-
specific language models are contributed to by
the documents labelled with the class whereas the
neutral language model has contributions from all
documents. The normalization to achieve the lexi-
con is exactly the same as in the mixture of classes
case, and hence, is omitted here.
</bodyText>
<subsubsectionHeader confidence="0.93103">
4.2.4 EM Initialization
</subsubsectionHeader>
<bodyText confidence="0.999989833333333">
In the case of iterative approaches like EM, the ini-
tialization is often considered crucial. In our case,
we initialize the unigram class language models
by simply aggregating the scores of the words in
tweets labelled with the respective class. Thus, the
joy language model would be the initialized to be
the maximum likelihood model to explain the doc-
uments labelled joy. In the case of the class and
neutral generative model, we additionally build
the neutral language model by aggregating counts
across all the documents in the corpus (regardless
of what their emotion label is).
</bodyText>
<sectionHeader confidence="0.999761" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.9999116">
In this section we detail our experimental evalu-
ation. We begin with the details about the Twit-
ter data used in our experiments. We then dis-
cuss how we created the folds for a cross valida-
tion experiment. Thereafter we detail the classifi-
</bodyText>
<equation confidence="0.93981075">
µdij =
(8)
L(p−1)
Cdi (wij) + L(p−1)
C (wij)
L(p−1)
Cdi
(wij)
</equation>
<page confidence="0.988367">
16
</page>
<bodyText confidence="0.9999015">
cation task used to evaluate the word-emotion lex-
icon. Finally we discuss the performance of our
proposed methods for lexicon generation in com-
parison with other manually crafted lexicons, PMI
based method for lexicon generation and the stan-
dard BoW in an emotion classification task.
</bodyText>
<subsectionHeader confidence="0.985218">
5.1 Twitter Dataset
</subsectionHeader>
<bodyText confidence="0.998561944444444">
The data set used in our experiments was a corpus
of emotion labelled tweets harnessed by (Wang et
al., 2012). The data set was available in the form
of tweet ID’s and the corresponding emotion la-
bel. The emotion labels comprised namely: anger,
fear, joy, sadness, surprise, love and thankfulness.
We used the Twitter search API1 to obtain the
tweets by searching with the corresponding tweet
ID. After that we decided to consider only tweets
that belong to the primary set of emotions defined
by Parrott (Parrott, 2001). The emotion classes in
our case included anger, fear, joy, sadness, sur-
prise and love. We had a collection of 0.28 mil-
lion tweets which we used to carry out a 10 fold
cross-validation experiment.
We decided to generate the folds manually,in
order to compare the performance of the differ-
ent algorithms used in our experiments. We split
the collection of 0.28 million tweets into 10 equal
size sets to generate 10 folds with different train-
ing and test sets in each fold. Also all the folds in
our experiments were obtained by stratified sam-
pling, ensuring that we had documents represent-
ing all the classes in both the training and test sets.
We used the training data in each fold to generate
the word-emotion lexicon and measured the per-
formance of it on the test data in an emotion clas-
sification task. Table 2 shows the average distri-
bution of the different classes namely: anger, fear,
joy, sadness, surprise and love over the 10 folds.
Observe that emotions such as joy and sadness had
a very high number of representative documents
. Emotions such as anger,love and fear were the
next most represented emotions. The emotion sur-
prise had very few representative documents com-
pared to that of the other emotions.
</bodyText>
<subsectionHeader confidence="0.999504">
5.2 Evaluating the word-emotion lexicon
</subsectionHeader>
<bodyText confidence="0.9998525">
We adopted an emotion classification task in order
to evaluate the quality of the word-emotion lexi-
con generated using the proposed methods. Also
research in emotion analysis of text suggest that
</bodyText>
<footnote confidence="0.910784">
1https://dev.twitter.com/docs/using-search
</footnote>
<tableCaption confidence="0.8523365">
Table 2: Average distribution of emotions across
the folds
</tableCaption>
<table confidence="0.998971625">
Emotion Training Test
Anger 58410 6496
Fear 13692 1548
Joy 74108 8235
Sadness 63711 7069
Surprise 2533 282
Love 31127 3464
Total 243855 27095
</table>
<bodyText confidence="0.997787333333333">
lexicon based features were effective compared to
that of n-gram features in an emotion classifica-
tion of text (Aman and Szpakowicz, 2008; Mo-
hammad, 2012a). Therefore we decided to use the
lexicon to derive features for text representation.
We followed a similar procedure as in (Moham-
mad, 2012a) to define integer valued features for
text representation. We define one feature for each
emotion to capture the number of words in a train-
ing/test document that are associated with the cor-
responding emotion. The feature vector for a train-
ing/test document was constructed using the word-
emotion lexicon. Given a training/test document
d we construct the corresponding feature vector
d&apos; =&lt; count(e1), count(e2), ... , count(em)) &gt;
of length m (in our case m is 6), wherein
count(ei) represents the number of words in d that
exhibit emotion ei. count(ei) is computed as:
</bodyText>
<equation confidence="0.958898">
�count(ei) =
w∈d
</equation>
<bodyText confidence="0.999865928571429">
where I(...) is the indicator function as used
previously. For example if a document has 1 joy
word, 2 love words and 1 surprise word the feature
vector for the document would be (0, 0, 1, 0, 1, 2).
We used the different lexicon generation methods
discussed in sections 4.1, 4.2.2 and 4.2.3 to con-
struct the feature vectors for the documents. In the
case of the lexicon generated as in section 4.2.3
the max in equation 11 is computed over m + 1
columns. We also used the lexicon generation
method proposed in (Mohammad, 2012a) to con-
struct the feature vectors. PMI was used in (Mo-
hammad, 2012a) to generate a word-emotion lexi-
con which is as follows :
</bodyText>
<equation confidence="0.46112425">
Lex(i, j) =log freq(wi, Cj) ∗ freq(¬Cj)
freq(Cj) ∗ freq(wi, ¬Cj)
I( max Lex(w, j) = Ci)
j=1,...,m
</equation>
<page confidence="0.993503">
17
</page>
<bodyText confidence="0.999989315789474">
where freq(wi,Cj) is the number of times n-
gram wi occurs in a document labelled with emo-
tion Cj, freq(wi, ¬Cj) is the number of times n-
gram wi occurs in a document not labelled with
emotion Cj. freq(Cj) and freq(¬Cj) are the
number of documents labelled with emotion Cj
and ¬Cj respectively.
Apart from the aforementioned automatically
generated lexicons we also used manually crafted
lexicons such as WordNet Affect (Strapparava and
Valitutti, 2004) and the NRC word-emotion as-
sociation lexicon (Saif M. Mohammad, 2013) to
construct the feature vectors for the documents.
Unlike the automatic lexicons, the general purpose
lexicons do not offer numerical scores. There-
fore we looked for presence/absence of words in
the lexicons to obtain the feature vectors. Fur-
thermore we also represented documents in the
standard BoW representation. We performed fea-
ture selection using the metric Chisquare2, to se-
lect the top 500 features to represent documents.
Since tweets are very short we incorporated a bi-
nary representation for BoW instead of term fre-
quency. For classification we used a multiclass
SVM classifier 3 and all the experiments were con-
ducted using the data mining software Weka2. We
used standard metrics such as Precision, Recall
and F-measure to compare the performance of the
different algorithms. In the following section we
analyse the experimental results for TF-lex (Sec
4.1), EMallclass-lex (Sec 4.2.2), EMclass-corpus-
lex (Sec 4.2.3), PMI-lex (Mohammad, 2012a),
WNA-lex (Strapparava and Valitutti, 2004), NRC-
lex (Saif M. Mohammad, 2013) and BoW in an
emotion classification task. Also in the case of
EM based methods we experimented with differ-
ent threshold limits 6 shown in Table 1. We report
the results only w.r.t 6 = 1 due to space limitations.
</bodyText>
<subsectionHeader confidence="0.976992">
5.3 Results and Analysis
</subsectionHeader>
<bodyText confidence="0.99996025">
Table 3 shows the F-scores obtained for differ-
ent methods for each emotion. Observe that the
F-score for each emotion shown in Table 3 for a
method is the average F-score obtained over the
10 test sets (one per fold). We carried a two tail
paired t-test4 between the baselines and our pro-
posed methods to measure statistical significance
for performance on the test set in each fold. From
</bodyText>
<footnote confidence="0.98552">
2 http://www.cs.waikato.ac.nz/ml/weka/
3http://www.csie.ntu.edu.tw/ cjlin/liblinear/
4http://office.microsoft.com/en-gb/excel-help/ttest-
HP005209325.aspx
</footnote>
<bodyText confidence="0.999923980392157">
the t-test we observed that our proposed methods
are statistically significant over the baselines with
a confidence of 95% (i.e with p value 0.05). Also
note that the best results obtained for an emotion
are highlighted in bold. It is evident from the re-
sults that the manually crafted lexicons Wornd-
net Affect and the NRC word-emotion association
lexicon are significantly outperformed by all the
automatically generated lexicons for all emotions.
Also the BoW model significantly outperforms the
manually crafted lexicons suggesting that these
lexicons are not sufficiently effective for emotion
mining in a domain like Twitter.
When compared with BoW the PMI-lex pro-
posed by (Mohammad, 2012a) achieves a 2% gain
w.r.t emotion love, a 0.6% gain w.r.t emotion joy
and 1.28% gain w.r.t emotion sadness. However
in the case of emotions such as fear and sur-
prise BoW achieves significant gains of 11.17%
and 20.96% respectively. The results suggest that
the PMI-lex was able to leverage the availability
of adequate training examples to learn the pat-
terns about emotions such as anger, joy, sadness
and love. However given that not all emotions are
widely expressed a lexicon generation method that
relies heavily on abundant training data could be
ineffective to mine less represented emotions.
Now we analyse the results obtained for the lex-
icons generated from our proposed methods and
compare them with BoW and PMI-lex. From
the results obtained for our methods in Table 3
it suggests that our methods achieve the best F-
scores for 4 emotions namely anger, fear, sad-
ness and love out of the 6 emotions. In par-
ticular the EM-class-corpus-lex method obtains
the best F-score for 3 emotions namely anger,
sadness and love. When compared with BoW
and PMI-lex, EM-class-corpus-lex obtains a gain
of 0.85% and 0.93% respectively w.r.t emotion
anger, 1.85% and 0.57% respectively w.r.t emo-
tion sadness, 18.67% and 16.88% respectively
w.r.t emotion love. Our method TF-lex achieves a
gain of 5.47% and 16.64% respectively over BoW
and PMI-lex w.r.t emotion fear. Furthermore w.r.t
emotion surprise all our proposed methods outper-
form PMI-lex. However BoW still obtains the best
F-score for emotion surprise.
When we compared the results between our
own methods EM-class-corpus-lex obtains the
best F-scores for emotions anger, joy, sadness and
love. We expected that modelling a document
</bodyText>
<page confidence="0.999399">
18
</page>
<tableCaption confidence="0.998768">
Table 3: Emotion classification results
</tableCaption>
<table confidence="0.982622454545455">
Method Average F-Score
Anger Fear Joy Sadness Surprise Love
Baselines
WNA-lex 25.82% 6.61% 12.94% 8.76% 0.76% 2.67%
NRC-lex 21.37% 3.97% 16.04% 8.87% 1.54% 7.22%
Bow 56.5% 13.56% 63.34% 50.57% 21.65% 20.52%
PMI-lex 56.42% 2.39% 63.4% 50.57% 0.69% 22.31%
Our Learnt Lexicons
TF-lex 55.85% 19.03% 62.01% 50.54% 11.29% 37.69%
EMallclass-lex 56.64% 14.53% 61.89% 50.48% 12.33% 38.13%
EMclass-corpus-lex 57.35% 16.1% 62.74% 51.14% 12.05% 39.19%
</table>
<bodyText confidence="0.99992353125">
to exhibit more than one emotion (EM-allclass-
lex) would better distinguish the class boundaries.
However given that tweets are very short it was
observed that modelling a document as a mixture
of emotion terms and general terms (EM-class-
corpus-lex) yielded better results. However we ex-
pect EM-allclass-lex to be more effective in other
domains such as blogs, discussion forums wherein
the text size is larger compared to tweets.
Table 4 summarizes the overall F-scores ob-
tained for the different methods. Note that the
F-scores shown in Table 4 are the average over-
all F-scores over the 10 test sets. Again we con-
ducted a two tail paired t-test4 between the base-
lines and our proposed methods to measure the
performance gains. It was observed that all our
proposed methods are statistically significant over
the baselines with a confidence of 95% (i.e with
p value 0.05). In Table 4 we italicize all our best
performing methods and highlight in bold the best
among them. From the results it is evident that our
proposed methods obtain significantly better F-
scores over all the baselines with EM-class-corpus
achieving the best F-score with a gain of 3.21%,
2.9%, 39.03% and 38.7% over PMI-lex, BoW,
WNA-lex and NRC-lex respectively. Our findings
reconfirm previous findings in the literature that
emotion lexicon based features improve over cor-
pus based n-gram features in a emotion classifica-
tion task. Also our findings suggest that domain
specific automatic lexicons are significantly better
over manually crafted lexicons.
</bodyText>
<sectionHeader confidence="0.999195" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.991644333333333">
We proposed a set of methods to automatically ex-
tract a word-emotion lexicon from an emotion la-
belled corpus. Thereafter we used the lexicons to
</bodyText>
<tableCaption confidence="0.980099">
Table 4: Overall F-scores
</tableCaption>
<table confidence="0.823120363636364">
Method Avg Overall F-
score
Baselines
WNA-lex 13.17%
NRC-lex 13.50%
Bow 49.30%
PMI-lex 48.99%
Our automatic lexicons
TF-lex 51.45%
EMallclass-lex 51.38%
EMclass-corpus-lex 52.20%
</table>
<bodyText confidence="0.999777857142857">
derive features for text representation and showed
that lexicon based features significantly outper-
form the standard BoW features in the emotion
classification of tweets. Furthermore our lexicons
achieve significant improvements over the general
purpose lexicons and the PMI based automatic
lexicon in the classification experiments. In fu-
ture we intend to leverage the lexicons to design
different text representations and also test them
on emotional content from other domains. Auto-
matically generating human-interpretable models
(e.g., (Balachandran et al., 2012)) to accompany
emotion classifier decisions is another interesting
direction for future work.
</bodyText>
<sectionHeader confidence="0.999118" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.97063">
Richa Bhayani Alec Go and Lei Huang. 2009. Twit-
ter sentiment classification using distant supervision.
Processing.
Cecilia Ovesdotter Alm, Dan Roth, and Richard
Sproat. 2005. Emotions from text: machine learn-
ing for text-based emotion prediction. In Proceed-
</reference>
<page confidence="0.99559">
19
</page>
<reference confidence="0.984359064220183">
ings of the conference on Human Language Tech-
nology and Empirical Methods in Natural Language
Processing, HLT ’05, pages 579–586, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.
S. Aman and S. Szpakowicz. 2008. Using roget’s the-
saurus for fine-grained emotion recognition. In In-
ternational Joint Conference on Natural Language
Processing.
Vipin Balachandran, Deepak P, and Deepak Khemani.
2012. Interpretable and reconfigurable clustering
of document datasets by deriving word-based rules.
Knowl. Inf. Syst., 32(3):475–503.
Johan Bollen, Alberto Pepe, and Huina Mao. 2009.
Modelling public mood and emotion: Twitter senti-
ment and socio-economic phenomena. In CoRR.
Danah Boyd, Scott Golder, and Gilad Lotan. 2010.
Tweet, tweet, retweet: Conversational aspects of
retweeting on twitter. In Proceedings of the 2010
43rd Hawaii International Conference on System
Sciences, Washington, DC, USA.
P. Deepak and Sutanu Chakraborti. 2012. Finding rel-
evant tweets. In WAIM, pages 228–240.
P. Deepak and Karthik Visweswariah. 2014. Unsu-
pervised solution post identification from discussion
forums. In ACL.
P. Deepak, Karthik Visweswariah, Nirmalie Wiratunga,
and Sadiq Sani. 2012. Two-part segmentation of
text documents. In CIKM, pages 793–802.
Lars E.Holzman and Pottenger William M. 2003.
Classification of emotions in internet chat : An
application of machine learning using speech
phonemes. Technical report, Technical report,
Leigh University.
Paul Ekman. 1992. An argument for basic emotions.
Cognition and Emotion, 6(3):169–200.
Virginia Francisco and Pablo Gervas. 2006. Auto-
mated mark up of affective information in english
text. Text, Speech and Dialouge, volume 4188 of
Lecture Notes in Computer Science:375–382.
David John, Anthony C. Boucouvalas, and Zhe Xu.
2006. Representing emotinal momentum within ex-
pressive internet communication. In In Proceed-
ings of the 24th IASTED international conference on
Internet and multimedia systems and applications,
pages 183-188, Anaheim, CA, ACTA Press.
J. Johnson J. Guthrie K. Roberts, M.A. Roach and S.M.
Harabagiu. 2012. ”empatweet: Annotating and de-
tecting emotions on twitter”,. In in Proc. LREC,
2012, pp.3806-3813.
Elsa Kim, Sam Gilbert, J.Edwards, and Erhardt Graeff.
2009. Detecting sadness in 140 characters: Senti-
ment analysis of mourning of michael jackson on
twitter.
Xiaoyong Liu and W Bruce Croft. 2005. Statistical
language modeling for information retrieval. Tech-
nical report, DTIC Document.
Chunling Ma, Helmut Prendinger, and Mitsuru
Ishizuka. 2005. Emotion estimation and reasoning
based on affective textual interaction. In First In-
ternational Conference on Affective Computing and
Intelligent Interaction (ACII-2005), pages 622-628,
Beijing, China.
Rada Mihalcea and Hugo Liu. 2006. A corpus-based
approach for finding happiness. In In AAAI-2006
Spring Symposium on Computational Approaches to
Analysing Weblogs, pages 139-144. AAAI press.
Saif M. Mohammad and Tony Yang. 2011. Tracking
seniment in mail : How genders differ on emotional
axes. In In Proceedings of the 2nd Workshop on
Computational Approaches to Subjectivity and Sen-
timent Analysis(WASSA 2011), pages 70- 79, Port-
land, Oregon. Association for Computational Lin-
guistics.
Saif Mohammad. 2012a. #emotional tweets. In
The First Joint Conference on Lexical and Compu-
tational Semantics – Volume 1: Proceedings of the
main conference and the shared task, and Volume 2:
Proceedings of the Sixth International Workshop on
Semantic Evaluation (SemEval 2012).
Saif M. Mohammad. 2012b. Portable features for clas-
sifying emotional text. In Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 587-591, Montreal, Canada.
Alena Neviarouskaya, Helmut Prendinger, and Mit-
suru Ishizuka. 2010. Recognition of affect, judg-
ment, and appreciation in text. In Proceedings of the
23rd International Conference on Computational
Linguistics, COLING ’10, pages 806–814, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
D. Kirson P. Shaver, J. Schwartz. 1987. Emotion
knowledge: Further exploration of a prototype ap-
proach. Journal of Personality and Social Psychol-
ogy, Vol 52 no 6:1061 – 1086.
W Parrott. 2001. Emotions in social psychology. Psy-
chology Press, Philadelphia.
Lisa Pearl and Mark Steyvers. 2010. Identifying emo-
tions, intentions and attitudes in text using a game
with a purpose. In In Proceedings of the NAACL-
HLT 2010 Workshop on Computational Approaches
to Analysis and Generation of Emotion in Text, Los
Abgeles, California.
R. Plutchik. 1980. A general psychoevolutionary the-
ory of emotion. In R. Plutchik &amp; H. Kellerman
(Eds.), Emotion: Theory, research, and experience:,
Vol. 1. Theories of emotion (pp. 3-33). New York:
Academic:(pp. 3–33).
</reference>
<page confidence="0.903181">
20
</page>
<reference confidence="0.999539275">
Ashequl Qadir and Ellen Riloff. 2013. Bootstrapped
learning of emotion hashtahs #hashtags4you. In
In the 4th Workshop on Computational Approaches
to Subjectivity, Sentiment &amp; Social Media Analysis
(WASSA 2013).
Tapas Ray. 2011. The ’story’ of digital excess in rev-
olutions of the arab spring. Journal of Media Prac-
tice, 12(2):189–196.
Peter D. Turney Saif M. Mohammad. 2013. Crowd-
sourcing a word-emotion association lexicon. Com-
putational Intelligence, 29 (3), 436-465, Wiley
Blackwell Publishing Ltd, 2013, 29(3):436–465.
Prendinger H. Ishizuka M. Shaikh, M.A.M., 2009. A
Linguistic Interpretation of the OCC Emotion Model
for Affect Sensing from Text, chapter 4, pages 45–73.
Julia Skinner. 2011. Social media and revolu-
tion: The arab spring and the occupy movement
as seen though three information studies paradigms.
Sprouts: Working papers on Information Systems,
11(169).
Carlo Strapparava and Alessandro Valitutti. 2004.
Wordnet-affect: an affective extension of wordnet.
Technical report, ITC-irst, Istituto per la Ricerca
Scienti?ca e Tecnologica I-38050 Povo Trento Italy.
Wenbo Wang, Lu Chen, Krishnaprasad Thirunarayan,
and Amit P. Sheth. 2012. Harnessing twitter ”big
data” for automatic emotion identification. In Pro-
ceedings of the 2012 ASE/IEEE International Con-
ference on Social Computing and 2012 ASE/IEEE.
C. Yang, K. H. Y. Lin, and H. H. Chen. 2007. Emo-
tion classification using web blog corpora. In Pro-
ceedings of the IEEE/WIC/ACM International Con-
ference on Web Intelligence, WI ’07, pages 275–278,
Washington, DC, USA. IEEE Computer Society.
Liu Wenyin Qing Li Yanghui Rao, Xiaojun Quan and
Mingliang Chen. 2013. Building word-emotion
mapping dictionary for online news. In In Pro-
ceedings of the 4th Workshop on Computational Ap-
proaches to Subjectivity, Sentiment and Social Me-
dia Analysis, WASSA 2013.
</reference>
<page confidence="0.999438">
21
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.830092">
<title confidence="0.999968">Generating a Word-Emotion Lexicon from #Emotional Tweets</title>
<author confidence="0.997282">Stewart</author>
<affiliation confidence="0.999819">Research Institute, Robert Gordon University, Scotland,</affiliation>
<address confidence="0.879496">2IBM Research - India, Bangalore,</address>
<email confidence="0.99686">deepaksp@acm.org,s.massie@rgu.ac.uk</email>
<abstract confidence="0.997766347826087">Research in emotion analysis of text suggest that emotion lexicon based features are superior to corpus based n-gram features. However the static nature of the general purpose emotion lexicons make them less suited to social media analysis, where the need to adopt to changes in vocabulary usage and context is crucial. In this paper we propose a set of methods to extract a word-emotion lexicon automatically from an emotion labelled corpus of tweets. Our results confirm that the features derived from these lexicons outperform the standard Bag-of-words features when applied to an emotion classification task. Furthermore, a comparative analysis with both manually crafted lexicons and a state-of-the-art lexicon generated using Point-Wise Mutual Information, show that the lexicons generated from the proposed methods lead to significantly better classification performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Richa Bhayani Alec Go</author>
<author>Lei Huang</author>
</authors>
<title>Twitter sentiment classification using distant supervision.</title>
<date>2009</date>
<tech>Processing.</tech>
<contexts>
<context position="7457" citStr="Go and Huang, 2009" startWordPosition="1141" endWordPosition="1144">lexicon generation strategies. There are other lexicon generation methods proposed by Rao .et. al (Yanghui Rao and Chen, 2013) and Yang .et. al (Yang et al., 2007). We do not consider these in our comparative evaluation since these methods require rated emotion labels and emoticon classes respectively. Lexicon generation, relies on the availability of a labelled corpus from which the word-emotion distributions can be discovered. For this purpose we exploit a distance-supervised approach where indirect cues are used to unearth implicit (or distant) labels that are contained in the corpus (Alec Go and Huang, 2009). We adopt the approach as in (Wang et al., 2012) to corpus labelling where social media content, and in particular Twitter content is sampled for a predefined set of hashtag cues (P. Shaver, 1987) . Here each set of cues represent a given emotion class. Distant-supervision is particularly suited to Twitter-like platforms because people use hashtags to extensively convey or emphasis the emotion behind their tweets (e.g., That was my best weekend ever.#happy!! #satisfied!). Also given that tweets are length restricted (140 characters), modelling the emotional orientation of words in a Tweet is </context>
</contexts>
<marker>Go, Huang, 2009</marker>
<rawString>Richa Bhayani Alec Go and Lei Huang. 2009. Twitter sentiment classification using distant supervision. Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cecilia Ovesdotter Alm</author>
<author>Dan Roth</author>
<author>Richard Sproat</author>
</authors>
<title>Emotions from text: machine learning for text-based emotion prediction.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05,</booktitle>
<pages>579--586</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4647" citStr="Alm et al., 2005" startWordPosition="710" endWordPosition="713">4. Section 2 we present the related work. In Section 3 we outline the problem. In Section 4 we formulate the different methods proposed to generate the word-emotion lexicons. In Section 5 we discuss experimental results followed by conclusions and future work in Section 6. 2 Related Work Computational emotion analysis, draws from cognitive and physiology studies to establish the key emotion categories; and NLP and text mining research to establish features designed to represent emotive content. Emotion analysis has been applied in a variety of domains: fairy tales (Francisco and Gervas, 2006; Alm et al., 2005); blogs (Mihalcea and Liu, 2006; Neviarouskaya et al., 2010), novels (John et al., 2006), chat messages (E.Holzman and William M, 2003; Ma et al., 2005; Mohammad and Yang, 2011) and emotional events on social media content(Kim et al., 2009). Comparative studies on emotive word distributions on micro-blogs and personal content (e.g. love letters, suicide notes) have shown that emotions such as disgust are expressed well in tweets. Further, expression of emotion in tweets and love letters have been shown to have similarities(K. Roberts and Harabagiu, 2012). Emotion classification frameworks prov</context>
</contexts>
<marker>Alm, Roth, Sproat, 2005</marker>
<rawString>Cecilia Ovesdotter Alm, Dan Roth, and Richard Sproat. 2005. Emotions from text: machine learning for text-based emotion prediction. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05, pages 579–586, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Aman</author>
<author>S Szpakowicz</author>
</authors>
<title>Using roget’s thesaurus for fine-grained emotion recognition.</title>
<date>2008</date>
<booktitle>In International Joint Conference on Natural Language Processing.</booktitle>
<contexts>
<context position="5464" citStr="Aman and Szpakowicz, 2008" startWordPosition="835" endWordPosition="838"> events on social media content(Kim et al., 2009). Comparative studies on emotive word distributions on micro-blogs and personal content (e.g. love letters, suicide notes) have shown that emotions such as disgust are expressed well in tweets. Further, expression of emotion in tweets and love letters have been shown to have similarities(K. Roberts and Harabagiu, 2012). Emotion classification frameworks provide insights into human emotion expressions (Ekman, 1992; Plutchik, 1980; Parrott, 2001). The emotions proposed by (Ekman, 1992) are popular in emotion classification tasks (Mohammad, 2012b; Aman and Szpakowicz, 2008). Recently there has also been interest in extending this basic emotion framework to model more complex emotions (such as politeness, rudeness, deception, depression, vigour and confusion) (Pearl and Steyvers, 2010; Bollen et al., 2009). A common theme across these approaches involves the selection of emotion-rich features and learning of relevant weights to capture emotion strength (Mohammad, 2012a; Qadir and Riloff, 2013). Usefulness of a lexicon: Lexicons such as Wordnet Affect (Strapparava and Valitutti, 2004) and NRC (Saif M. Mohammad, 2013)) are very valuable resources from which emotion</context>
<context position="22364" citStr="Aman and Szpakowicz, 2008" startWordPosition="3736" endWordPosition="3739">otions. 5.2 Evaluating the word-emotion lexicon We adopted an emotion classification task in order to evaluate the quality of the word-emotion lexicon generated using the proposed methods. Also research in emotion analysis of text suggest that 1https://dev.twitter.com/docs/using-search Table 2: Average distribution of emotions across the folds Emotion Training Test Anger 58410 6496 Fear 13692 1548 Joy 74108 8235 Sadness 63711 7069 Surprise 2533 282 Love 31127 3464 Total 243855 27095 lexicon based features were effective compared to that of n-gram features in an emotion classification of text (Aman and Szpakowicz, 2008; Mohammad, 2012a). Therefore we decided to use the lexicon to derive features for text representation. We followed a similar procedure as in (Mohammad, 2012a) to define integer valued features for text representation. We define one feature for each emotion to capture the number of words in a training/test document that are associated with the corresponding emotion. The feature vector for a training/test document was constructed using the wordemotion lexicon. Given a training/test document d we construct the corresponding feature vector d&apos; =&lt; count(e1), count(e2), ... , count(em)) &gt; of length </context>
</contexts>
<marker>Aman, Szpakowicz, 2008</marker>
<rawString>S. Aman and S. Szpakowicz. 2008. Using roget’s thesaurus for fine-grained emotion recognition. In International Joint Conference on Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vipin Balachandran</author>
<author>P Deepak</author>
<author>Deepak Khemani</author>
</authors>
<title>Interpretable and reconfigurable clustering of document datasets by deriving word-based rules.</title>
<date>2012</date>
<journal>Knowl. Inf. Syst.,</journal>
<volume>32</volume>
<issue>3</issue>
<marker>Balachandran, Deepak, Khemani, 2012</marker>
<rawString>Vipin Balachandran, Deepak P, and Deepak Khemani. 2012. Interpretable and reconfigurable clustering of document datasets by deriving word-based rules. Knowl. Inf. Syst., 32(3):475–503.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bollen</author>
<author>Alberto Pepe</author>
<author>Huina Mao</author>
</authors>
<title>Modelling public mood and emotion: Twitter sentiment and socio-economic phenomena.</title>
<date>2009</date>
<booktitle>In CoRR.</booktitle>
<contexts>
<context position="5700" citStr="Bollen et al., 2009" startWordPosition="871" endWordPosition="874"> Further, expression of emotion in tweets and love letters have been shown to have similarities(K. Roberts and Harabagiu, 2012). Emotion classification frameworks provide insights into human emotion expressions (Ekman, 1992; Plutchik, 1980; Parrott, 2001). The emotions proposed by (Ekman, 1992) are popular in emotion classification tasks (Mohammad, 2012b; Aman and Szpakowicz, 2008). Recently there has also been interest in extending this basic emotion framework to model more complex emotions (such as politeness, rudeness, deception, depression, vigour and confusion) (Pearl and Steyvers, 2010; Bollen et al., 2009). A common theme across these approaches involves the selection of emotion-rich features and learning of relevant weights to capture emotion strength (Mohammad, 2012a; Qadir and Riloff, 2013). Usefulness of a lexicon: Lexicons such as Wordnet Affect (Strapparava and Valitutti, 2004) and NRC (Saif M. Mohammad, 2013)) are very valuable resources from which emotion features can be derived for text representation. These are manually crafted and typically contain emotion-rich formal vocabulary. Hybrid approaches that combine features derived from these static lexicons with n-grams have resulted in </context>
</contexts>
<marker>Bollen, Pepe, Mao, 2009</marker>
<rawString>Johan Bollen, Alberto Pepe, and Huina Mao. 2009. Modelling public mood and emotion: Twitter sentiment and socio-economic phenomena. In CoRR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danah Boyd</author>
<author>Scott Golder</author>
<author>Gilad Lotan</author>
</authors>
<title>Tweet, tweet, retweet: Conversational aspects of retweeting on twitter.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 43rd Hawaii International Conference on System Sciences,</booktitle>
<location>Washington, DC, USA.</location>
<contexts>
<context position="2461" citStr="Boyd et al., 2010" startWordPosition="369" endWordPosition="372">GPEL) is a commonly used resource that allows qualitative assessment of a piece of emotive text. Given a word and an emotion, the lexicon provides a score to quantify the strength of emotion expressed by that word. Such lexicons are carefully crafted and are utilised by both supervised and unsupervised algorithms to directly aggregate an overall emotion score or indirectly derive features for emotion classification tasks (Mohammad, 2012a), (Mohammad, 2012b). Socio-linguistics suggest that social media is a popular means for people to converse with individuals, groups and the world in general (Boyd et al., 2010). These conversations often involve usage of non-standard natural language expressions which consistently evolve. Twitter and Facebook were credited for providing momentum for the 2011 Arab Spring and Occupy Wall street movements (Ray, 2011),(Skinner, 2011). Therefore efforts to model social conversations would provide valuable insights into how people influence each other through emotional expressions. Emotion analysis in such domains calls for automated discovery of lexicons. This is so since learnt lexicons can intuitively capture the evolving nature of vocabulary in such domains better tha</context>
</contexts>
<marker>Boyd, Golder, Lotan, 2010</marker>
<rawString>Danah Boyd, Scott Golder, and Gilad Lotan. 2010. Tweet, tweet, retweet: Conversational aspects of retweeting on twitter. In Proceedings of the 2010 43rd Hawaii International Conference on System Sciences, Washington, DC, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Deepak</author>
<author>Sutanu Chakraborti</author>
</authors>
<title>Finding relevant tweets.</title>
<date>2012</date>
<booktitle>In WAIM,</booktitle>
<pages>228--240</pages>
<contexts>
<context position="12142" citStr="Deepak and Chakraborti, 2012" startWordPosition="1936" endWordPosition="1939"> most prominent emotion in the tweet. Additionally, some words could be emotion-neutral (e.g., sunday in our example tweet) and could be conveying non-emotional information. We now describe two generative models that account for such considerations, and then outline methods to learn lexicons based on them. Mixture of Classes Model: Let LCk be the unigram language model (Liu and Croft, 2005) that expresses the lexical character for the emotion class Ck; though microblogs are short text fragments, language modeling approaches have been shown to be effective in similarity assesment between them (Deepak and Chakraborti, 2012). We model a document di to be generated from across the emotion class language models: 1. For each word wj in document di, (a) Lookup the unit vector [λ(1) dij, ... , λ(N)]; This unit vector defines a probability distribution over the language models. (b) Choose a language model L from among the K LMs, in accordance with the vector (c) Sample wj in accordance with the multinomial distribution L If di is labelled with the emotion class Cdi, it is likely that the value of λ(n) dij is high for words in di since it is likely that majority of the words are sampled from the LCd. language model. The</context>
</contexts>
<marker>Deepak, Chakraborti, 2012</marker>
<rawString>P. Deepak and Sutanu Chakraborti. 2012. Finding relevant tweets. In WAIM, pages 228–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Deepak</author>
<author>Karthik Visweswariah</author>
</authors>
<title>Unsupervised solution post identification from discussion forums.</title>
<date>2014</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="14247" citStr="Deepak and Visweswariah, 2014" startWordPosition="2322" endWordPosition="2325"> model The posterior probability in accordance with this model can be intuitively formulated as : P(di, Cdi|θ) = Y µdij x LCdi (wj) wjEdi (4) + (1 − µdij) x LC(wj) where θ is the parameters {LCjJN j=1, LC, µ . Equation 3 models a document to exhibit characteristics of many classes with different levels of magnitude. Equation 4 models a document to be a composition of terms that characterise one class and other general terms; a similar formulation where a document is modeled using a mix of two models has been shown to be useful in characterizing problem-solution documents (Deepak et al., 2012; Deepak and Visweswariah, 2014). The central idea of the expectation maximization (EM) algorithm is to maximize the probability of the data, given the language models {LCjJN j=1 and LC. The term weights are estimated from the language models (E-step) and the language models are re-estimated (M-step) using the term weights from the E-step. Thus the maximum likelihood estimation process in EM alternates between the E-step and the M-step. In the following sections we detail the EM process for the two generative models separately. We compare and contrast the two variants of the EM algorithm in Table 1. 4.2.2 EM with Mixture of </context>
</contexts>
<marker>Deepak, Visweswariah, 2014</marker>
<rawString>P. Deepak and Karthik Visweswariah. 2014. Unsupervised solution post identification from discussion forums. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Deepak</author>
<author>Karthik Visweswariah</author>
<author>Nirmalie Wiratunga</author>
<author>Sadiq Sani</author>
</authors>
<title>Two-part segmentation of text documents.</title>
<date>2012</date>
<booktitle>In CIKM,</booktitle>
<pages>793--802</pages>
<contexts>
<context position="14215" citStr="Deepak et al., 2012" startWordPosition="2318" endWordPosition="2321">f the chosen language model The posterior probability in accordance with this model can be intuitively formulated as : P(di, Cdi|θ) = Y µdij x LCdi (wj) wjEdi (4) + (1 − µdij) x LC(wj) where θ is the parameters {LCjJN j=1, LC, µ . Equation 3 models a document to exhibit characteristics of many classes with different levels of magnitude. Equation 4 models a document to be a composition of terms that characterise one class and other general terms; a similar formulation where a document is modeled using a mix of two models has been shown to be useful in characterizing problem-solution documents (Deepak et al., 2012; Deepak and Visweswariah, 2014). The central idea of the expectation maximization (EM) algorithm is to maximize the probability of the data, given the language models {LCjJN j=1 and LC. The term weights are estimated from the language models (E-step) and the language models are re-estimated (M-step) using the term weights from the E-step. Thus the maximum likelihood estimation process in EM alternates between the E-step and the M-step. In the following sections we detail the EM process for the two generative models separately. We compare and contrast the two variants of the EM algorithm in Ta</context>
</contexts>
<marker>Deepak, Visweswariah, Wiratunga, Sani, 2012</marker>
<rawString>P. Deepak, Karthik Visweswariah, Nirmalie Wiratunga, and Sadiq Sani. 2012. Two-part segmentation of text documents. In CIKM, pages 793–802.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lars E Holzman</author>
<author>Pottenger William M</author>
</authors>
<title>Classification of emotions in internet chat : An application of machine learning using speech phonemes.</title>
<date>2003</date>
<tech>Technical report, Technical report,</tech>
<institution>Leigh University.</institution>
<marker>Holzman, M, 2003</marker>
<rawString>Lars E.Holzman and Pottenger William M. 2003. Classification of emotions in internet chat : An application of machine learning using speech phonemes. Technical report, Technical report, Leigh University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Ekman</author>
</authors>
<title>An argument for basic emotions.</title>
<date>1992</date>
<journal>Cognition and Emotion,</journal>
<volume>6</volume>
<issue>3</issue>
<contexts>
<context position="5303" citStr="Ekman, 1992" startWordPosition="814" endWordPosition="815">a et al., 2010), novels (John et al., 2006), chat messages (E.Holzman and William M, 2003; Ma et al., 2005; Mohammad and Yang, 2011) and emotional events on social media content(Kim et al., 2009). Comparative studies on emotive word distributions on micro-blogs and personal content (e.g. love letters, suicide notes) have shown that emotions such as disgust are expressed well in tweets. Further, expression of emotion in tweets and love letters have been shown to have similarities(K. Roberts and Harabagiu, 2012). Emotion classification frameworks provide insights into human emotion expressions (Ekman, 1992; Plutchik, 1980; Parrott, 2001). The emotions proposed by (Ekman, 1992) are popular in emotion classification tasks (Mohammad, 2012b; Aman and Szpakowicz, 2008). Recently there has also been interest in extending this basic emotion framework to model more complex emotions (such as politeness, rudeness, deception, depression, vigour and confusion) (Pearl and Steyvers, 2010; Bollen et al., 2009). A common theme across these approaches involves the selection of emotion-rich features and learning of relevant weights to capture emotion strength (Mohammad, 2012a; Qadir and Riloff, 2013). Usefulness</context>
</contexts>
<marker>Ekman, 1992</marker>
<rawString>Paul Ekman. 1992. An argument for basic emotions. Cognition and Emotion, 6(3):169–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Virginia Francisco</author>
<author>Pablo Gervas</author>
</authors>
<title>Automated mark up of affective information in english text.</title>
<date>2006</date>
<journal>Text, Speech and Dialouge,</journal>
<booktitle>of Lecture Notes in Computer Science:375–382.</booktitle>
<volume>4188</volume>
<contexts>
<context position="4628" citStr="Francisco and Gervas, 2006" startWordPosition="705" endWordPosition="709">n, Ireland, August 23-24 2014. Section 2 we present the related work. In Section 3 we outline the problem. In Section 4 we formulate the different methods proposed to generate the word-emotion lexicons. In Section 5 we discuss experimental results followed by conclusions and future work in Section 6. 2 Related Work Computational emotion analysis, draws from cognitive and physiology studies to establish the key emotion categories; and NLP and text mining research to establish features designed to represent emotive content. Emotion analysis has been applied in a variety of domains: fairy tales (Francisco and Gervas, 2006; Alm et al., 2005); blogs (Mihalcea and Liu, 2006; Neviarouskaya et al., 2010), novels (John et al., 2006), chat messages (E.Holzman and William M, 2003; Ma et al., 2005; Mohammad and Yang, 2011) and emotional events on social media content(Kim et al., 2009). Comparative studies on emotive word distributions on micro-blogs and personal content (e.g. love letters, suicide notes) have shown that emotions such as disgust are expressed well in tweets. Further, expression of emotion in tweets and love letters have been shown to have similarities(K. Roberts and Harabagiu, 2012). Emotion classificat</context>
</contexts>
<marker>Francisco, Gervas, 2006</marker>
<rawString>Virginia Francisco and Pablo Gervas. 2006. Automated mark up of affective information in english text. Text, Speech and Dialouge, volume 4188 of Lecture Notes in Computer Science:375–382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David John</author>
<author>Anthony C Boucouvalas</author>
<author>Zhe Xu</author>
</authors>
<title>Representing emotinal momentum within expressive internet communication. In</title>
<date>2006</date>
<booktitle>In Proceedings of the 24th IASTED international conference on Internet and multimedia systems and applications,</booktitle>
<pages>183--188</pages>
<publisher>ACTA Press.</publisher>
<location>Anaheim, CA,</location>
<contexts>
<context position="4735" citStr="John et al., 2006" startWordPosition="724" endWordPosition="727">on 4 we formulate the different methods proposed to generate the word-emotion lexicons. In Section 5 we discuss experimental results followed by conclusions and future work in Section 6. 2 Related Work Computational emotion analysis, draws from cognitive and physiology studies to establish the key emotion categories; and NLP and text mining research to establish features designed to represent emotive content. Emotion analysis has been applied in a variety of domains: fairy tales (Francisco and Gervas, 2006; Alm et al., 2005); blogs (Mihalcea and Liu, 2006; Neviarouskaya et al., 2010), novels (John et al., 2006), chat messages (E.Holzman and William M, 2003; Ma et al., 2005; Mohammad and Yang, 2011) and emotional events on social media content(Kim et al., 2009). Comparative studies on emotive word distributions on micro-blogs and personal content (e.g. love letters, suicide notes) have shown that emotions such as disgust are expressed well in tweets. Further, expression of emotion in tweets and love letters have been shown to have similarities(K. Roberts and Harabagiu, 2012). Emotion classification frameworks provide insights into human emotion expressions (Ekman, 1992; Plutchik, 1980; Parrott, 2001)</context>
</contexts>
<marker>John, Boucouvalas, Xu, 2006</marker>
<rawString>David John, Anthony C. Boucouvalas, and Zhe Xu. 2006. Representing emotinal momentum within expressive internet communication. In In Proceedings of the 24th IASTED international conference on Internet and multimedia systems and applications, pages 183-188, Anaheim, CA, ACTA Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Johnson J Guthrie K Roberts</author>
<author>M A Roach</author>
<author>S M Harabagiu</author>
</authors>
<title>empatweet: Annotating and detecting emotions on twitter”,.</title>
<date>2012</date>
<booktitle>In in Proc. LREC,</booktitle>
<pages>3806--3813</pages>
<marker>Roberts, Roach, Harabagiu, 2012</marker>
<rawString>J. Johnson J. Guthrie K. Roberts, M.A. Roach and S.M. Harabagiu. 2012. ”empatweet: Annotating and detecting emotions on twitter”,. In in Proc. LREC, 2012, pp.3806-3813.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elsa Kim</author>
<author>Sam Gilbert</author>
<author>J Edwards</author>
<author>Erhardt Graeff</author>
</authors>
<title>Detecting sadness in 140 characters: Sentiment analysis of mourning of michael jackson on twitter.</title>
<date>2009</date>
<contexts>
<context position="4887" citStr="Kim et al., 2009" startWordPosition="751" endWordPosition="754">ons and future work in Section 6. 2 Related Work Computational emotion analysis, draws from cognitive and physiology studies to establish the key emotion categories; and NLP and text mining research to establish features designed to represent emotive content. Emotion analysis has been applied in a variety of domains: fairy tales (Francisco and Gervas, 2006; Alm et al., 2005); blogs (Mihalcea and Liu, 2006; Neviarouskaya et al., 2010), novels (John et al., 2006), chat messages (E.Holzman and William M, 2003; Ma et al., 2005; Mohammad and Yang, 2011) and emotional events on social media content(Kim et al., 2009). Comparative studies on emotive word distributions on micro-blogs and personal content (e.g. love letters, suicide notes) have shown that emotions such as disgust are expressed well in tweets. Further, expression of emotion in tweets and love letters have been shown to have similarities(K. Roberts and Harabagiu, 2012). Emotion classification frameworks provide insights into human emotion expressions (Ekman, 1992; Plutchik, 1980; Parrott, 2001). The emotions proposed by (Ekman, 1992) are popular in emotion classification tasks (Mohammad, 2012b; Aman and Szpakowicz, 2008). Recently there has al</context>
</contexts>
<marker>Kim, Gilbert, Edwards, Graeff, 2009</marker>
<rawString>Elsa Kim, Sam Gilbert, J.Edwards, and Erhardt Graeff. 2009. Detecting sadness in 140 characters: Sentiment analysis of mourning of michael jackson on twitter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoyong Liu</author>
<author>W Bruce Croft</author>
</authors>
<title>Statistical language modeling for information retrieval.</title>
<date>2005</date>
<tech>Technical report, DTIC Document.</tech>
<contexts>
<context position="11906" citStr="Liu and Croft, 2005" startWordPosition="1900" endWordPosition="1903"> labelled with an emotion class, not all terms relate strongly to the labelled emotion. Some documents may have terms conveying a different emotion than what the document is labelled with, since the label is chosen based on the most prominent emotion in the tweet. Additionally, some words could be emotion-neutral (e.g., sunday in our example tweet) and could be conveying non-emotional information. We now describe two generative models that account for such considerations, and then outline methods to learn lexicons based on them. Mixture of Classes Model: Let LCk be the unigram language model (Liu and Croft, 2005) that expresses the lexical character for the emotion class Ck; though microblogs are short text fragments, language modeling approaches have been shown to be effective in similarity assesment between them (Deepak and Chakraborti, 2012). We model a document di to be generated from across the emotion class language models: 1. For each word wj in document di, (a) Lookup the unit vector [λ(1) dij, ... , λ(N)]; This unit vector defines a probability distribution over the language models. (b) Choose a language model L from among the K LMs, in accordance with the vector (c) Sample wj in accordance w</context>
</contexts>
<marker>Liu, Croft, 2005</marker>
<rawString>Xiaoyong Liu and W Bruce Croft. 2005. Statistical language modeling for information retrieval. Technical report, DTIC Document.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chunling Ma</author>
<author>Helmut Prendinger</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>Emotion estimation and reasoning based on affective textual interaction.</title>
<date>2005</date>
<booktitle>In First International Conference on Affective Computing and Intelligent Interaction (ACII-2005),</booktitle>
<pages>622--628</pages>
<location>Beijing, China.</location>
<contexts>
<context position="4798" citStr="Ma et al., 2005" startWordPosition="736" endWordPosition="739">ord-emotion lexicons. In Section 5 we discuss experimental results followed by conclusions and future work in Section 6. 2 Related Work Computational emotion analysis, draws from cognitive and physiology studies to establish the key emotion categories; and NLP and text mining research to establish features designed to represent emotive content. Emotion analysis has been applied in a variety of domains: fairy tales (Francisco and Gervas, 2006; Alm et al., 2005); blogs (Mihalcea and Liu, 2006; Neviarouskaya et al., 2010), novels (John et al., 2006), chat messages (E.Holzman and William M, 2003; Ma et al., 2005; Mohammad and Yang, 2011) and emotional events on social media content(Kim et al., 2009). Comparative studies on emotive word distributions on micro-blogs and personal content (e.g. love letters, suicide notes) have shown that emotions such as disgust are expressed well in tweets. Further, expression of emotion in tweets and love letters have been shown to have similarities(K. Roberts and Harabagiu, 2012). Emotion classification frameworks provide insights into human emotion expressions (Ekman, 1992; Plutchik, 1980; Parrott, 2001). The emotions proposed by (Ekman, 1992) are popular in emotion</context>
</contexts>
<marker>Ma, Prendinger, Ishizuka, 2005</marker>
<rawString>Chunling Ma, Helmut Prendinger, and Mitsuru Ishizuka. 2005. Emotion estimation and reasoning based on affective textual interaction. In First International Conference on Affective Computing and Intelligent Interaction (ACII-2005), pages 622-628, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Hugo Liu</author>
</authors>
<title>A corpus-based approach for finding happiness. In</title>
<date>2006</date>
<booktitle>In AAAI-2006 Spring Symposium on Computational Approaches to Analysing Weblogs,</booktitle>
<pages>139--144</pages>
<publisher>AAAI press.</publisher>
<contexts>
<context position="4678" citStr="Mihalcea and Liu, 2006" startWordPosition="715" endWordPosition="718">e related work. In Section 3 we outline the problem. In Section 4 we formulate the different methods proposed to generate the word-emotion lexicons. In Section 5 we discuss experimental results followed by conclusions and future work in Section 6. 2 Related Work Computational emotion analysis, draws from cognitive and physiology studies to establish the key emotion categories; and NLP and text mining research to establish features designed to represent emotive content. Emotion analysis has been applied in a variety of domains: fairy tales (Francisco and Gervas, 2006; Alm et al., 2005); blogs (Mihalcea and Liu, 2006; Neviarouskaya et al., 2010), novels (John et al., 2006), chat messages (E.Holzman and William M, 2003; Ma et al., 2005; Mohammad and Yang, 2011) and emotional events on social media content(Kim et al., 2009). Comparative studies on emotive word distributions on micro-blogs and personal content (e.g. love letters, suicide notes) have shown that emotions such as disgust are expressed well in tweets. Further, expression of emotion in tweets and love letters have been shown to have similarities(K. Roberts and Harabagiu, 2012). Emotion classification frameworks provide insights into human emotion</context>
</contexts>
<marker>Mihalcea, Liu, 2006</marker>
<rawString>Rada Mihalcea and Hugo Liu. 2006. A corpus-based approach for finding happiness. In In AAAI-2006 Spring Symposium on Computational Approaches to Analysing Weblogs, pages 139-144. AAAI press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
<author>Tony Yang</author>
</authors>
<title>Tracking seniment in mail : How genders differ on emotional axes. In</title>
<date>2011</date>
<booktitle>In Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis(WASSA</booktitle>
<pages>70--79</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon.</location>
<contexts>
<context position="4824" citStr="Mohammad and Yang, 2011" startWordPosition="740" endWordPosition="743">ons. In Section 5 we discuss experimental results followed by conclusions and future work in Section 6. 2 Related Work Computational emotion analysis, draws from cognitive and physiology studies to establish the key emotion categories; and NLP and text mining research to establish features designed to represent emotive content. Emotion analysis has been applied in a variety of domains: fairy tales (Francisco and Gervas, 2006; Alm et al., 2005); blogs (Mihalcea and Liu, 2006; Neviarouskaya et al., 2010), novels (John et al., 2006), chat messages (E.Holzman and William M, 2003; Ma et al., 2005; Mohammad and Yang, 2011) and emotional events on social media content(Kim et al., 2009). Comparative studies on emotive word distributions on micro-blogs and personal content (e.g. love letters, suicide notes) have shown that emotions such as disgust are expressed well in tweets. Further, expression of emotion in tweets and love letters have been shown to have similarities(K. Roberts and Harabagiu, 2012). Emotion classification frameworks provide insights into human emotion expressions (Ekman, 1992; Plutchik, 1980; Parrott, 2001). The emotions proposed by (Ekman, 1992) are popular in emotion classification tasks (Moh</context>
</contexts>
<marker>Mohammad, Yang, 2011</marker>
<rawString>Saif M. Mohammad and Tony Yang. 2011. Tracking seniment in mail : How genders differ on emotional axes. In In Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis(WASSA 2011), pages 70- 79, Portland, Oregon. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
</authors>
<title>emotional tweets.</title>
<date>2012</date>
<booktitle>In The First Joint Conference on Lexical and Computational Semantics – Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="2283" citStr="Mohammad, 2012" startWordPosition="342" endWordPosition="344">tative metrics to capture emotive strength and extraction of features from these metrics has in recent years shown promise (Shaikh, 2009). A general-purpose emotion lexicon (GPEL) is a commonly used resource that allows qualitative assessment of a piece of emotive text. Given a word and an emotion, the lexicon provides a score to quantify the strength of emotion expressed by that word. Such lexicons are carefully crafted and are utilised by both supervised and unsupervised algorithms to directly aggregate an overall emotion score or indirectly derive features for emotion classification tasks (Mohammad, 2012a), (Mohammad, 2012b). Socio-linguistics suggest that social media is a popular means for people to converse with individuals, groups and the world in general (Boyd et al., 2010). These conversations often involve usage of non-standard natural language expressions which consistently evolve. Twitter and Facebook were credited for providing momentum for the 2011 Arab Spring and Occupy Wall street movements (Ray, 2011),(Skinner, 2011). Therefore efforts to model social conversations would provide valuable insights into how people influence each other through emotional expressions. Emotion analysi</context>
<context position="5435" citStr="Mohammad, 2012" startWordPosition="833" endWordPosition="834">11) and emotional events on social media content(Kim et al., 2009). Comparative studies on emotive word distributions on micro-blogs and personal content (e.g. love letters, suicide notes) have shown that emotions such as disgust are expressed well in tweets. Further, expression of emotion in tweets and love letters have been shown to have similarities(K. Roberts and Harabagiu, 2012). Emotion classification frameworks provide insights into human emotion expressions (Ekman, 1992; Plutchik, 1980; Parrott, 2001). The emotions proposed by (Ekman, 1992) are popular in emotion classification tasks (Mohammad, 2012b; Aman and Szpakowicz, 2008). Recently there has also been interest in extending this basic emotion framework to model more complex emotions (such as politeness, rudeness, deception, depression, vigour and confusion) (Pearl and Steyvers, 2010; Bollen et al., 2009). A common theme across these approaches involves the selection of emotion-rich features and learning of relevant weights to capture emotion strength (Mohammad, 2012a; Qadir and Riloff, 2013). Usefulness of a lexicon: Lexicons such as Wordnet Affect (Strapparava and Valitutti, 2004) and NRC (Saif M. Mohammad, 2013)) are very valuable</context>
<context position="6760" citStr="Mohammad, 2012" startWordPosition="1033" endWordPosition="1034">ypically contain emotion-rich formal vocabulary. Hybrid approaches that combine features derived from these static lexicons with n-grams have resulted in better performance than either alone (Mohammad, 2012b),(Aman and Szpakowicz, 2008). However the informal and dynamic nature of social media content makes it harder to adopt these lexicons for emotion analysis. An alternative strategy is to derive features from a dynamic (i.e., learnt) lexicon. Here association metrics such as Pointwise Mutual Information (PMI) can be used to model emotion polarity between a word and emotion labelled content (Mohammad, 2012a). Such approaches will be used as baselines to compare against our proposed lexicon generation strategies. There are other lexicon generation methods proposed by Rao .et. al (Yanghui Rao and Chen, 2013) and Yang .et. al (Yang et al., 2007). We do not consider these in our comparative evaluation since these methods require rated emotion labels and emoticon classes respectively. Lexicon generation, relies on the availability of a labelled corpus from which the word-emotion distributions can be discovered. For this purpose we exploit a distance-supervised approach where indirect cues are used t</context>
<context position="22380" citStr="Mohammad, 2012" startWordPosition="3740" endWordPosition="3742">word-emotion lexicon We adopted an emotion classification task in order to evaluate the quality of the word-emotion lexicon generated using the proposed methods. Also research in emotion analysis of text suggest that 1https://dev.twitter.com/docs/using-search Table 2: Average distribution of emotions across the folds Emotion Training Test Anger 58410 6496 Fear 13692 1548 Joy 74108 8235 Sadness 63711 7069 Surprise 2533 282 Love 31127 3464 Total 243855 27095 lexicon based features were effective compared to that of n-gram features in an emotion classification of text (Aman and Szpakowicz, 2008; Mohammad, 2012a). Therefore we decided to use the lexicon to derive features for text representation. We followed a similar procedure as in (Mohammad, 2012a) to define integer valued features for text representation. We define one feature for each emotion to capture the number of words in a training/test document that are associated with the corresponding emotion. The feature vector for a training/test document was constructed using the wordemotion lexicon. Given a training/test document d we construct the corresponding feature vector d&apos; =&lt; count(e1), count(e2), ... , count(em)) &gt; of length m (in our case m</context>
<context position="23635" citStr="Mohammad, 2012" startWordPosition="3957" endWordPosition="3958">number of words in d that exhibit emotion ei. count(ei) is computed as: �count(ei) = w∈d where I(...) is the indicator function as used previously. For example if a document has 1 joy word, 2 love words and 1 surprise word the feature vector for the document would be (0, 0, 1, 0, 1, 2). We used the different lexicon generation methods discussed in sections 4.1, 4.2.2 and 4.2.3 to construct the feature vectors for the documents. In the case of the lexicon generated as in section 4.2.3 the max in equation 11 is computed over m + 1 columns. We also used the lexicon generation method proposed in (Mohammad, 2012a) to construct the feature vectors. PMI was used in (Mohammad, 2012a) to generate a word-emotion lexicon which is as follows : Lex(i, j) =log freq(wi, Cj) ∗ freq(¬Cj) freq(Cj) ∗ freq(wi, ¬Cj) I( max Lex(w, j) = Ci) j=1,...,m 17 where freq(wi,Cj) is the number of times ngram wi occurs in a document labelled with emotion Cj, freq(wi, ¬Cj) is the number of times ngram wi occurs in a document not labelled with emotion Cj. freq(Cj) and freq(¬Cj) are the number of documents labelled with emotion Cj and ¬Cj respectively. Apart from the aforementioned automatically generated lexicons we also used man</context>
<context position="25341" citStr="Mohammad, 2012" startWordPosition="4233" endWordPosition="4234">ection using the metric Chisquare2, to select the top 500 features to represent documents. Since tweets are very short we incorporated a binary representation for BoW instead of term frequency. For classification we used a multiclass SVM classifier 3 and all the experiments were conducted using the data mining software Weka2. We used standard metrics such as Precision, Recall and F-measure to compare the performance of the different algorithms. In the following section we analyse the experimental results for TF-lex (Sec 4.1), EMallclass-lex (Sec 4.2.2), EMclass-corpuslex (Sec 4.2.3), PMI-lex (Mohammad, 2012a), WNA-lex (Strapparava and Valitutti, 2004), NRClex (Saif M. Mohammad, 2013) and BoW in an emotion classification task. Also in the case of EM based methods we experimented with different threshold limits 6 shown in Table 1. We report the results only w.r.t 6 = 1 due to space limitations. 5.3 Results and Analysis Table 3 shows the F-scores obtained for different methods for each emotion. Observe that the F-score for each emotion shown in Table 3 for a method is the average F-score obtained over the 10 test sets (one per fold). We carried a two tail paired t-test4 between the baselines and ou</context>
<context position="26893" citStr="Mohammad, 2012" startWordPosition="4471" endWordPosition="4472">over the baselines with a confidence of 95% (i.e with p value 0.05). Also note that the best results obtained for an emotion are highlighted in bold. It is evident from the results that the manually crafted lexicons Worndnet Affect and the NRC word-emotion association lexicon are significantly outperformed by all the automatically generated lexicons for all emotions. Also the BoW model significantly outperforms the manually crafted lexicons suggesting that these lexicons are not sufficiently effective for emotion mining in a domain like Twitter. When compared with BoW the PMI-lex proposed by (Mohammad, 2012a) achieves a 2% gain w.r.t emotion love, a 0.6% gain w.r.t emotion joy and 1.28% gain w.r.t emotion sadness. However in the case of emotions such as fear and surprise BoW achieves significant gains of 11.17% and 20.96% respectively. The results suggest that the PMI-lex was able to leverage the availability of adequate training examples to learn the patterns about emotions such as anger, joy, sadness and love. However given that not all emotions are widely expressed a lexicon generation method that relies heavily on abundant training data could be ineffective to mine less represented emotions.</context>
</contexts>
<marker>Mohammad, 2012</marker>
<rawString>Saif Mohammad. 2012a. #emotional tweets. In The First Joint Conference on Lexical and Computational Semantics – Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
</authors>
<title>Portable features for classifying emotional text.</title>
<date>2012</date>
<booktitle>In Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>587--591</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="2283" citStr="Mohammad, 2012" startWordPosition="342" endWordPosition="344">tative metrics to capture emotive strength and extraction of features from these metrics has in recent years shown promise (Shaikh, 2009). A general-purpose emotion lexicon (GPEL) is a commonly used resource that allows qualitative assessment of a piece of emotive text. Given a word and an emotion, the lexicon provides a score to quantify the strength of emotion expressed by that word. Such lexicons are carefully crafted and are utilised by both supervised and unsupervised algorithms to directly aggregate an overall emotion score or indirectly derive features for emotion classification tasks (Mohammad, 2012a), (Mohammad, 2012b). Socio-linguistics suggest that social media is a popular means for people to converse with individuals, groups and the world in general (Boyd et al., 2010). These conversations often involve usage of non-standard natural language expressions which consistently evolve. Twitter and Facebook were credited for providing momentum for the 2011 Arab Spring and Occupy Wall street movements (Ray, 2011),(Skinner, 2011). Therefore efforts to model social conversations would provide valuable insights into how people influence each other through emotional expressions. Emotion analysi</context>
<context position="5435" citStr="Mohammad, 2012" startWordPosition="833" endWordPosition="834">11) and emotional events on social media content(Kim et al., 2009). Comparative studies on emotive word distributions on micro-blogs and personal content (e.g. love letters, suicide notes) have shown that emotions such as disgust are expressed well in tweets. Further, expression of emotion in tweets and love letters have been shown to have similarities(K. Roberts and Harabagiu, 2012). Emotion classification frameworks provide insights into human emotion expressions (Ekman, 1992; Plutchik, 1980; Parrott, 2001). The emotions proposed by (Ekman, 1992) are popular in emotion classification tasks (Mohammad, 2012b; Aman and Szpakowicz, 2008). Recently there has also been interest in extending this basic emotion framework to model more complex emotions (such as politeness, rudeness, deception, depression, vigour and confusion) (Pearl and Steyvers, 2010; Bollen et al., 2009). A common theme across these approaches involves the selection of emotion-rich features and learning of relevant weights to capture emotion strength (Mohammad, 2012a; Qadir and Riloff, 2013). Usefulness of a lexicon: Lexicons such as Wordnet Affect (Strapparava and Valitutti, 2004) and NRC (Saif M. Mohammad, 2013)) are very valuable</context>
<context position="6760" citStr="Mohammad, 2012" startWordPosition="1033" endWordPosition="1034">ypically contain emotion-rich formal vocabulary. Hybrid approaches that combine features derived from these static lexicons with n-grams have resulted in better performance than either alone (Mohammad, 2012b),(Aman and Szpakowicz, 2008). However the informal and dynamic nature of social media content makes it harder to adopt these lexicons for emotion analysis. An alternative strategy is to derive features from a dynamic (i.e., learnt) lexicon. Here association metrics such as Pointwise Mutual Information (PMI) can be used to model emotion polarity between a word and emotion labelled content (Mohammad, 2012a). Such approaches will be used as baselines to compare against our proposed lexicon generation strategies. There are other lexicon generation methods proposed by Rao .et. al (Yanghui Rao and Chen, 2013) and Yang .et. al (Yang et al., 2007). We do not consider these in our comparative evaluation since these methods require rated emotion labels and emoticon classes respectively. Lexicon generation, relies on the availability of a labelled corpus from which the word-emotion distributions can be discovered. For this purpose we exploit a distance-supervised approach where indirect cues are used t</context>
<context position="22380" citStr="Mohammad, 2012" startWordPosition="3740" endWordPosition="3742">word-emotion lexicon We adopted an emotion classification task in order to evaluate the quality of the word-emotion lexicon generated using the proposed methods. Also research in emotion analysis of text suggest that 1https://dev.twitter.com/docs/using-search Table 2: Average distribution of emotions across the folds Emotion Training Test Anger 58410 6496 Fear 13692 1548 Joy 74108 8235 Sadness 63711 7069 Surprise 2533 282 Love 31127 3464 Total 243855 27095 lexicon based features were effective compared to that of n-gram features in an emotion classification of text (Aman and Szpakowicz, 2008; Mohammad, 2012a). Therefore we decided to use the lexicon to derive features for text representation. We followed a similar procedure as in (Mohammad, 2012a) to define integer valued features for text representation. We define one feature for each emotion to capture the number of words in a training/test document that are associated with the corresponding emotion. The feature vector for a training/test document was constructed using the wordemotion lexicon. Given a training/test document d we construct the corresponding feature vector d&apos; =&lt; count(e1), count(e2), ... , count(em)) &gt; of length m (in our case m</context>
<context position="23635" citStr="Mohammad, 2012" startWordPosition="3957" endWordPosition="3958">number of words in d that exhibit emotion ei. count(ei) is computed as: �count(ei) = w∈d where I(...) is the indicator function as used previously. For example if a document has 1 joy word, 2 love words and 1 surprise word the feature vector for the document would be (0, 0, 1, 0, 1, 2). We used the different lexicon generation methods discussed in sections 4.1, 4.2.2 and 4.2.3 to construct the feature vectors for the documents. In the case of the lexicon generated as in section 4.2.3 the max in equation 11 is computed over m + 1 columns. We also used the lexicon generation method proposed in (Mohammad, 2012a) to construct the feature vectors. PMI was used in (Mohammad, 2012a) to generate a word-emotion lexicon which is as follows : Lex(i, j) =log freq(wi, Cj) ∗ freq(¬Cj) freq(Cj) ∗ freq(wi, ¬Cj) I( max Lex(w, j) = Ci) j=1,...,m 17 where freq(wi,Cj) is the number of times ngram wi occurs in a document labelled with emotion Cj, freq(wi, ¬Cj) is the number of times ngram wi occurs in a document not labelled with emotion Cj. freq(Cj) and freq(¬Cj) are the number of documents labelled with emotion Cj and ¬Cj respectively. Apart from the aforementioned automatically generated lexicons we also used man</context>
<context position="25341" citStr="Mohammad, 2012" startWordPosition="4233" endWordPosition="4234">ection using the metric Chisquare2, to select the top 500 features to represent documents. Since tweets are very short we incorporated a binary representation for BoW instead of term frequency. For classification we used a multiclass SVM classifier 3 and all the experiments were conducted using the data mining software Weka2. We used standard metrics such as Precision, Recall and F-measure to compare the performance of the different algorithms. In the following section we analyse the experimental results for TF-lex (Sec 4.1), EMallclass-lex (Sec 4.2.2), EMclass-corpuslex (Sec 4.2.3), PMI-lex (Mohammad, 2012a), WNA-lex (Strapparava and Valitutti, 2004), NRClex (Saif M. Mohammad, 2013) and BoW in an emotion classification task. Also in the case of EM based methods we experimented with different threshold limits 6 shown in Table 1. We report the results only w.r.t 6 = 1 due to space limitations. 5.3 Results and Analysis Table 3 shows the F-scores obtained for different methods for each emotion. Observe that the F-score for each emotion shown in Table 3 for a method is the average F-score obtained over the 10 test sets (one per fold). We carried a two tail paired t-test4 between the baselines and ou</context>
<context position="26893" citStr="Mohammad, 2012" startWordPosition="4471" endWordPosition="4472">over the baselines with a confidence of 95% (i.e with p value 0.05). Also note that the best results obtained for an emotion are highlighted in bold. It is evident from the results that the manually crafted lexicons Worndnet Affect and the NRC word-emotion association lexicon are significantly outperformed by all the automatically generated lexicons for all emotions. Also the BoW model significantly outperforms the manually crafted lexicons suggesting that these lexicons are not sufficiently effective for emotion mining in a domain like Twitter. When compared with BoW the PMI-lex proposed by (Mohammad, 2012a) achieves a 2% gain w.r.t emotion love, a 0.6% gain w.r.t emotion joy and 1.28% gain w.r.t emotion sadness. However in the case of emotions such as fear and surprise BoW achieves significant gains of 11.17% and 20.96% respectively. The results suggest that the PMI-lex was able to leverage the availability of adequate training examples to learn the patterns about emotions such as anger, joy, sadness and love. However given that not all emotions are widely expressed a lexicon generation method that relies heavily on abundant training data could be ineffective to mine less represented emotions.</context>
</contexts>
<marker>Mohammad, 2012</marker>
<rawString>Saif M. Mohammad. 2012b. Portable features for classifying emotional text. In Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 587-591, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alena Neviarouskaya</author>
<author>Helmut Prendinger</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>Recognition of affect, judgment, and appreciation in text.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics, COLING ’10,</booktitle>
<pages>806--814</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4707" citStr="Neviarouskaya et al., 2010" startWordPosition="719" endWordPosition="722">on 3 we outline the problem. In Section 4 we formulate the different methods proposed to generate the word-emotion lexicons. In Section 5 we discuss experimental results followed by conclusions and future work in Section 6. 2 Related Work Computational emotion analysis, draws from cognitive and physiology studies to establish the key emotion categories; and NLP and text mining research to establish features designed to represent emotive content. Emotion analysis has been applied in a variety of domains: fairy tales (Francisco and Gervas, 2006; Alm et al., 2005); blogs (Mihalcea and Liu, 2006; Neviarouskaya et al., 2010), novels (John et al., 2006), chat messages (E.Holzman and William M, 2003; Ma et al., 2005; Mohammad and Yang, 2011) and emotional events on social media content(Kim et al., 2009). Comparative studies on emotive word distributions on micro-blogs and personal content (e.g. love letters, suicide notes) have shown that emotions such as disgust are expressed well in tweets. Further, expression of emotion in tweets and love letters have been shown to have similarities(K. Roberts and Harabagiu, 2012). Emotion classification frameworks provide insights into human emotion expressions (Ekman, 1992; Pl</context>
</contexts>
<marker>Neviarouskaya, Prendinger, Ishizuka, 2010</marker>
<rawString>Alena Neviarouskaya, Helmut Prendinger, and Mitsuru Ishizuka. 2010. Recognition of affect, judgment, and appreciation in text. In Proceedings of the 23rd International Conference on Computational Linguistics, COLING ’10, pages 806–814, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Kirson P Shaver</author>
<author>J Schwartz</author>
</authors>
<title>Emotion knowledge: Further exploration of a prototype approach.</title>
<date>1987</date>
<journal>Journal of Personality and Social Psychology, Vol</journal>
<volume>52</volume>
<pages>6--1061</pages>
<marker>Shaver, Schwartz, 1987</marker>
<rawString>D. Kirson P. Shaver, J. Schwartz. 1987. Emotion knowledge: Further exploration of a prototype approach. Journal of Personality and Social Psychology, Vol 52 no 6:1061 – 1086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Parrott</author>
</authors>
<title>Emotions in social psychology.</title>
<date>2001</date>
<publisher>Psychology Press,</publisher>
<location>Philadelphia.</location>
<contexts>
<context position="5335" citStr="Parrott, 2001" startWordPosition="818" endWordPosition="819"> et al., 2006), chat messages (E.Holzman and William M, 2003; Ma et al., 2005; Mohammad and Yang, 2011) and emotional events on social media content(Kim et al., 2009). Comparative studies on emotive word distributions on micro-blogs and personal content (e.g. love letters, suicide notes) have shown that emotions such as disgust are expressed well in tweets. Further, expression of emotion in tweets and love letters have been shown to have similarities(K. Roberts and Harabagiu, 2012). Emotion classification frameworks provide insights into human emotion expressions (Ekman, 1992; Plutchik, 1980; Parrott, 2001). The emotions proposed by (Ekman, 1992) are popular in emotion classification tasks (Mohammad, 2012b; Aman and Szpakowicz, 2008). Recently there has also been interest in extending this basic emotion framework to model more complex emotions (such as politeness, rudeness, deception, depression, vigour and confusion) (Pearl and Steyvers, 2010; Bollen et al., 2009). A common theme across these approaches involves the selection of emotion-rich features and learning of relevant weights to capture emotion strength (Mohammad, 2012a; Qadir and Riloff, 2013). Usefulness of a lexicon: Lexicons such as </context>
<context position="20527" citStr="Parrott, 2001" startWordPosition="3434" endWordPosition="3435">exicon generation and the standard BoW in an emotion classification task. 5.1 Twitter Dataset The data set used in our experiments was a corpus of emotion labelled tweets harnessed by (Wang et al., 2012). The data set was available in the form of tweet ID’s and the corresponding emotion label. The emotion labels comprised namely: anger, fear, joy, sadness, surprise, love and thankfulness. We used the Twitter search API1 to obtain the tweets by searching with the corresponding tweet ID. After that we decided to consider only tweets that belong to the primary set of emotions defined by Parrott (Parrott, 2001). The emotion classes in our case included anger, fear, joy, sadness, surprise and love. We had a collection of 0.28 million tweets which we used to carry out a 10 fold cross-validation experiment. We decided to generate the folds manually,in order to compare the performance of the different algorithms used in our experiments. We split the collection of 0.28 million tweets into 10 equal size sets to generate 10 folds with different training and test sets in each fold. Also all the folds in our experiments were obtained by stratified sampling, ensuring that we had documents representing all the</context>
</contexts>
<marker>Parrott, 2001</marker>
<rawString>W Parrott. 2001. Emotions in social psychology. Psychology Press, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lisa Pearl</author>
<author>Mark Steyvers</author>
</authors>
<title>Identifying emotions, intentions and attitudes in text using a game with a purpose. In</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACLHLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text,</booktitle>
<location>Los Abgeles, California.</location>
<contexts>
<context position="5678" citStr="Pearl and Steyvers, 2010" startWordPosition="867" endWordPosition="870"> expressed well in tweets. Further, expression of emotion in tweets and love letters have been shown to have similarities(K. Roberts and Harabagiu, 2012). Emotion classification frameworks provide insights into human emotion expressions (Ekman, 1992; Plutchik, 1980; Parrott, 2001). The emotions proposed by (Ekman, 1992) are popular in emotion classification tasks (Mohammad, 2012b; Aman and Szpakowicz, 2008). Recently there has also been interest in extending this basic emotion framework to model more complex emotions (such as politeness, rudeness, deception, depression, vigour and confusion) (Pearl and Steyvers, 2010; Bollen et al., 2009). A common theme across these approaches involves the selection of emotion-rich features and learning of relevant weights to capture emotion strength (Mohammad, 2012a; Qadir and Riloff, 2013). Usefulness of a lexicon: Lexicons such as Wordnet Affect (Strapparava and Valitutti, 2004) and NRC (Saif M. Mohammad, 2013)) are very valuable resources from which emotion features can be derived for text representation. These are manually crafted and typically contain emotion-rich formal vocabulary. Hybrid approaches that combine features derived from these static lexicons with n-g</context>
</contexts>
<marker>Pearl, Steyvers, 2010</marker>
<rawString>Lisa Pearl and Mark Steyvers. 2010. Identifying emotions, intentions and attitudes in text using a game with a purpose. In In Proceedings of the NAACLHLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, Los Abgeles, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Plutchik</author>
</authors>
<title>A general psychoevolutionary theory of emotion. In</title>
<date>1980</date>
<booktitle>Emotion: Theory, research, and experience:, Vol. 1. Theories of emotion</booktitle>
<pages>3--33</pages>
<location>New York:</location>
<contexts>
<context position="5319" citStr="Plutchik, 1980" startWordPosition="816" endWordPosition="817">0), novels (John et al., 2006), chat messages (E.Holzman and William M, 2003; Ma et al., 2005; Mohammad and Yang, 2011) and emotional events on social media content(Kim et al., 2009). Comparative studies on emotive word distributions on micro-blogs and personal content (e.g. love letters, suicide notes) have shown that emotions such as disgust are expressed well in tweets. Further, expression of emotion in tweets and love letters have been shown to have similarities(K. Roberts and Harabagiu, 2012). Emotion classification frameworks provide insights into human emotion expressions (Ekman, 1992; Plutchik, 1980; Parrott, 2001). The emotions proposed by (Ekman, 1992) are popular in emotion classification tasks (Mohammad, 2012b; Aman and Szpakowicz, 2008). Recently there has also been interest in extending this basic emotion framework to model more complex emotions (such as politeness, rudeness, deception, depression, vigour and confusion) (Pearl and Steyvers, 2010; Bollen et al., 2009). A common theme across these approaches involves the selection of emotion-rich features and learning of relevant weights to capture emotion strength (Mohammad, 2012a; Qadir and Riloff, 2013). Usefulness of a lexicon: L</context>
</contexts>
<marker>Plutchik, 1980</marker>
<rawString>R. Plutchik. 1980. A general psychoevolutionary theory of emotion. In R. Plutchik &amp; H. Kellerman (Eds.), Emotion: Theory, research, and experience:, Vol. 1. Theories of emotion (pp. 3-33). New York: Academic:(pp. 3–33).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ashequl Qadir</author>
<author>Ellen Riloff</author>
</authors>
<title>Bootstrapped learning of emotion hashtahs #hashtags4you. In</title>
<date>2013</date>
<booktitle>In the 4th Workshop on Computational Approaches to Subjectivity, Sentiment &amp; Social Media Analysis (WASSA</booktitle>
<contexts>
<context position="5891" citStr="Qadir and Riloff, 2013" startWordPosition="898" endWordPosition="901">an emotion expressions (Ekman, 1992; Plutchik, 1980; Parrott, 2001). The emotions proposed by (Ekman, 1992) are popular in emotion classification tasks (Mohammad, 2012b; Aman and Szpakowicz, 2008). Recently there has also been interest in extending this basic emotion framework to model more complex emotions (such as politeness, rudeness, deception, depression, vigour and confusion) (Pearl and Steyvers, 2010; Bollen et al., 2009). A common theme across these approaches involves the selection of emotion-rich features and learning of relevant weights to capture emotion strength (Mohammad, 2012a; Qadir and Riloff, 2013). Usefulness of a lexicon: Lexicons such as Wordnet Affect (Strapparava and Valitutti, 2004) and NRC (Saif M. Mohammad, 2013)) are very valuable resources from which emotion features can be derived for text representation. These are manually crafted and typically contain emotion-rich formal vocabulary. Hybrid approaches that combine features derived from these static lexicons with n-grams have resulted in better performance than either alone (Mohammad, 2012b),(Aman and Szpakowicz, 2008). However the informal and dynamic nature of social media content makes it harder to adopt these lexicons for</context>
<context position="8312" citStr="Qadir and Riloff, 2013" startWordPosition="1281" endWordPosition="1284">a given emotion class. Distant-supervision is particularly suited to Twitter-like platforms because people use hashtags to extensively convey or emphasis the emotion behind their tweets (e.g., That was my best weekend ever.#happy!! #satisfied!). Also given that tweets are length restricted (140 characters), modelling the emotional orientation of words in a Tweet is easier compared to longer documents that are likely to capture complex and mixed emotions. This simplicity and access to sample data has made Twitter one of the most popular domains for emotion analysis research (Wang et al., 2012; Qadir and Riloff, 2013). 3 Problem Definition We now outline the problem formally. We start with a set of documents D = {d1, d2, ... , dn} where each document di has an associated label Cd, indicating the emotion class to which di belongs. We consider the case where the documents are tweets. For example, a tweet di nice sunday 13 #awesome may have a label joy indicating that the tweet belongs to the joy emotion class. We also assume that the labels Cdi come from a pre-defined set of six emotion classes anger, fear, joy, sad, surprise, love. Since our techniques are generic and do not depend on the number of emotion </context>
</contexts>
<marker>Qadir, Riloff, 2013</marker>
<rawString>Ashequl Qadir and Ellen Riloff. 2013. Bootstrapped learning of emotion hashtahs #hashtags4you. In In the 4th Workshop on Computational Approaches to Subjectivity, Sentiment &amp; Social Media Analysis (WASSA 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tapas Ray</author>
</authors>
<title>The ’story’ of digital excess in revolutions of the arab spring.</title>
<date>2011</date>
<journal>Journal of Media Practice,</journal>
<volume>12</volume>
<issue>2</issue>
<contexts>
<context position="2702" citStr="Ray, 2011" startWordPosition="404" endWordPosition="405">d and are utilised by both supervised and unsupervised algorithms to directly aggregate an overall emotion score or indirectly derive features for emotion classification tasks (Mohammad, 2012a), (Mohammad, 2012b). Socio-linguistics suggest that social media is a popular means for people to converse with individuals, groups and the world in general (Boyd et al., 2010). These conversations often involve usage of non-standard natural language expressions which consistently evolve. Twitter and Facebook were credited for providing momentum for the 2011 Arab Spring and Occupy Wall street movements (Ray, 2011),(Skinner, 2011). Therefore efforts to model social conversations would provide valuable insights into how people influence each other through emotional expressions. Emotion analysis in such domains calls for automated discovery of lexicons. This is so since learnt lexicons can intuitively capture the evolving nature of vocabulary in such domains better than GPELs. In this work we show how an emotion labelled corpus can be leveraged to generate a wordemotion lexicon automatically. Key to this is the availability of a labelled corpus which may be obtained using a distance-supervised approach to</context>
</contexts>
<marker>Ray, 2011</marker>
<rawString>Tapas Ray. 2011. The ’story’ of digital excess in revolutions of the arab spring. Journal of Media Practice, 12(2):189–196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney Saif M Mohammad</author>
</authors>
<title>Crowdsourcing a word-emotion association lexicon.</title>
<date>2013</date>
<journal>Computational Intelligence,</journal>
<volume>29</volume>
<issue>3</issue>
<pages>436--465</pages>
<publisher>Wiley Blackwell Publishing Ltd,</publisher>
<contexts>
<context position="6016" citStr="Mohammad, 2013" startWordPosition="919" endWordPosition="920">assification tasks (Mohammad, 2012b; Aman and Szpakowicz, 2008). Recently there has also been interest in extending this basic emotion framework to model more complex emotions (such as politeness, rudeness, deception, depression, vigour and confusion) (Pearl and Steyvers, 2010; Bollen et al., 2009). A common theme across these approaches involves the selection of emotion-rich features and learning of relevant weights to capture emotion strength (Mohammad, 2012a; Qadir and Riloff, 2013). Usefulness of a lexicon: Lexicons such as Wordnet Affect (Strapparava and Valitutti, 2004) and NRC (Saif M. Mohammad, 2013)) are very valuable resources from which emotion features can be derived for text representation. These are manually crafted and typically contain emotion-rich formal vocabulary. Hybrid approaches that combine features derived from these static lexicons with n-grams have resulted in better performance than either alone (Mohammad, 2012b),(Aman and Szpakowicz, 2008). However the informal and dynamic nature of social media content makes it harder to adopt these lexicons for emotion analysis. An alternative strategy is to derive features from a dynamic (i.e., learnt) lexicon. Here association metr</context>
<context position="24384" citStr="Mohammad, 2013" startWordPosition="4085" endWordPosition="4086"> j) =log freq(wi, Cj) ∗ freq(¬Cj) freq(Cj) ∗ freq(wi, ¬Cj) I( max Lex(w, j) = Ci) j=1,...,m 17 where freq(wi,Cj) is the number of times ngram wi occurs in a document labelled with emotion Cj, freq(wi, ¬Cj) is the number of times ngram wi occurs in a document not labelled with emotion Cj. freq(Cj) and freq(¬Cj) are the number of documents labelled with emotion Cj and ¬Cj respectively. Apart from the aforementioned automatically generated lexicons we also used manually crafted lexicons such as WordNet Affect (Strapparava and Valitutti, 2004) and the NRC word-emotion association lexicon (Saif M. Mohammad, 2013) to construct the feature vectors for the documents. Unlike the automatic lexicons, the general purpose lexicons do not offer numerical scores. Therefore we looked for presence/absence of words in the lexicons to obtain the feature vectors. Furthermore we also represented documents in the standard BoW representation. We performed feature selection using the metric Chisquare2, to select the top 500 features to represent documents. Since tweets are very short we incorporated a binary representation for BoW instead of term frequency. For classification we used a multiclass SVM classifier 3 and al</context>
</contexts>
<marker>Mohammad, 2013</marker>
<rawString>Peter D. Turney Saif M. Mohammad. 2013. Crowdsourcing a word-emotion association lexicon. Computational Intelligence, 29 (3), 436-465, Wiley Blackwell Publishing Ltd, 2013, 29(3):436–465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prendinger H Ishizuka M Shaikh</author>
<author>M A M</author>
</authors>
<title>A Linguistic Interpretation of the OCC Emotion Model for Affect Sensing from Text, chapter 4,</title>
<date>2009</date>
<pages>45--73</pages>
<marker>Shaikh, M, 2009</marker>
<rawString>Prendinger H. Ishizuka M. Shaikh, M.A.M., 2009. A Linguistic Interpretation of the OCC Emotion Model for Affect Sensing from Text, chapter 4, pages 45–73.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Skinner</author>
</authors>
<title>Social media and revolution: The arab spring and the occupy movement as seen though three information studies paradigms. Sprouts: Working papers on Information Systems,</title>
<date>2011</date>
<volume>11</volume>
<issue>169</issue>
<contexts>
<context position="2718" citStr="Skinner, 2011" startWordPosition="405" endWordPosition="406">ilised by both supervised and unsupervised algorithms to directly aggregate an overall emotion score or indirectly derive features for emotion classification tasks (Mohammad, 2012a), (Mohammad, 2012b). Socio-linguistics suggest that social media is a popular means for people to converse with individuals, groups and the world in general (Boyd et al., 2010). These conversations often involve usage of non-standard natural language expressions which consistently evolve. Twitter and Facebook were credited for providing momentum for the 2011 Arab Spring and Occupy Wall street movements (Ray, 2011),(Skinner, 2011). Therefore efforts to model social conversations would provide valuable insights into how people influence each other through emotional expressions. Emotion analysis in such domains calls for automated discovery of lexicons. This is so since learnt lexicons can intuitively capture the evolving nature of vocabulary in such domains better than GPELs. In this work we show how an emotion labelled corpus can be leveraged to generate a wordemotion lexicon automatically. Key to this is the availability of a labelled corpus which may be obtained using a distance-supervised approach to labelling (Wang</context>
</contexts>
<marker>Skinner, 2011</marker>
<rawString>Julia Skinner. 2011. Social media and revolution: The arab spring and the occupy movement as seen though three information studies paradigms. Sprouts: Working papers on Information Systems, 11(169).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlo Strapparava</author>
<author>Alessandro Valitutti</author>
</authors>
<title>Wordnet-affect: an affective extension of wordnet.</title>
<date>2004</date>
<booktitle>Istituto per la Ricerca Scienti?ca e Tecnologica I-38050 Povo</booktitle>
<tech>Technical report, ITC-irst,</tech>
<location>Trento</location>
<contexts>
<context position="5983" citStr="Strapparava and Valitutti, 2004" startWordPosition="911" endWordPosition="914">roposed by (Ekman, 1992) are popular in emotion classification tasks (Mohammad, 2012b; Aman and Szpakowicz, 2008). Recently there has also been interest in extending this basic emotion framework to model more complex emotions (such as politeness, rudeness, deception, depression, vigour and confusion) (Pearl and Steyvers, 2010; Bollen et al., 2009). A common theme across these approaches involves the selection of emotion-rich features and learning of relevant weights to capture emotion strength (Mohammad, 2012a; Qadir and Riloff, 2013). Usefulness of a lexicon: Lexicons such as Wordnet Affect (Strapparava and Valitutti, 2004) and NRC (Saif M. Mohammad, 2013)) are very valuable resources from which emotion features can be derived for text representation. These are manually crafted and typically contain emotion-rich formal vocabulary. Hybrid approaches that combine features derived from these static lexicons with n-grams have resulted in better performance than either alone (Mohammad, 2012b),(Aman and Szpakowicz, 2008). However the informal and dynamic nature of social media content makes it harder to adopt these lexicons for emotion analysis. An alternative strategy is to derive features from a dynamic (i.e., learn</context>
<context position="24314" citStr="Strapparava and Valitutti, 2004" startWordPosition="4072" endWordPosition="4075">ed in (Mohammad, 2012a) to generate a word-emotion lexicon which is as follows : Lex(i, j) =log freq(wi, Cj) ∗ freq(¬Cj) freq(Cj) ∗ freq(wi, ¬Cj) I( max Lex(w, j) = Ci) j=1,...,m 17 where freq(wi,Cj) is the number of times ngram wi occurs in a document labelled with emotion Cj, freq(wi, ¬Cj) is the number of times ngram wi occurs in a document not labelled with emotion Cj. freq(Cj) and freq(¬Cj) are the number of documents labelled with emotion Cj and ¬Cj respectively. Apart from the aforementioned automatically generated lexicons we also used manually crafted lexicons such as WordNet Affect (Strapparava and Valitutti, 2004) and the NRC word-emotion association lexicon (Saif M. Mohammad, 2013) to construct the feature vectors for the documents. Unlike the automatic lexicons, the general purpose lexicons do not offer numerical scores. Therefore we looked for presence/absence of words in the lexicons to obtain the feature vectors. Furthermore we also represented documents in the standard BoW representation. We performed feature selection using the metric Chisquare2, to select the top 500 features to represent documents. Since tweets are very short we incorporated a binary representation for BoW instead of term freq</context>
</contexts>
<marker>Strapparava, Valitutti, 2004</marker>
<rawString>Carlo Strapparava and Alessandro Valitutti. 2004. Wordnet-affect: an affective extension of wordnet. Technical report, ITC-irst, Istituto per la Ricerca Scienti?ca e Tecnologica I-38050 Povo Trento Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenbo Wang</author>
<author>Lu Chen</author>
<author>Krishnaprasad Thirunarayan</author>
<author>Amit P Sheth</author>
</authors>
<title>Harnessing twitter ”big data” for automatic emotion identification.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 ASE/IEEE International Conference on Social Computing and</booktitle>
<publisher>ASE/IEEE.</publisher>
<contexts>
<context position="3332" citStr="Wang et al., 2012" startWordPosition="502" endWordPosition="505">011). Therefore efforts to model social conversations would provide valuable insights into how people influence each other through emotional expressions. Emotion analysis in such domains calls for automated discovery of lexicons. This is so since learnt lexicons can intuitively capture the evolving nature of vocabulary in such domains better than GPELs. In this work we show how an emotion labelled corpus can be leveraged to generate a wordemotion lexicon automatically. Key to this is the availability of a labelled corpus which may be obtained using a distance-supervised approach to labelling (Wang et al., 2012). In this paper we propose three lexicon generation methods and evaluate the quality of these by deploying them in an emotion classification task. We show through our experiments that the word-emotion lexicon generated using the proposed methods in this paper significantly outperforms GPELs such as WordnetAffect, NRC word-emotion association lexicon and a leaxicon learnt using Point-wise Mutual Information (PMI). Additionally, our lexicons also outperform the traditional Bag-of-Words representation. The rest of the paper is organised as follows: In 12 Proceedings of the Third Joint Conference </context>
<context position="7506" citStr="Wang et al., 2012" startWordPosition="1151" endWordPosition="1154">icon generation methods proposed by Rao .et. al (Yanghui Rao and Chen, 2013) and Yang .et. al (Yang et al., 2007). We do not consider these in our comparative evaluation since these methods require rated emotion labels and emoticon classes respectively. Lexicon generation, relies on the availability of a labelled corpus from which the word-emotion distributions can be discovered. For this purpose we exploit a distance-supervised approach where indirect cues are used to unearth implicit (or distant) labels that are contained in the corpus (Alec Go and Huang, 2009). We adopt the approach as in (Wang et al., 2012) to corpus labelling where social media content, and in particular Twitter content is sampled for a predefined set of hashtag cues (P. Shaver, 1987) . Here each set of cues represent a given emotion class. Distant-supervision is particularly suited to Twitter-like platforms because people use hashtags to extensively convey or emphasis the emotion behind their tweets (e.g., That was my best weekend ever.#happy!! #satisfied!). Also given that tweets are length restricted (140 characters), modelling the emotional orientation of words in a Tweet is easier compared to longer documents that are like</context>
<context position="20116" citStr="Wang et al., 2012" startWordPosition="3364" endWordPosition="3367">data used in our experiments. We then discuss how we created the folds for a cross validation experiment. Thereafter we detail the classifiµdij = (8) L(p−1) Cdi (wij) + L(p−1) C (wij) L(p−1) Cdi (wij) 16 cation task used to evaluate the word-emotion lexicon. Finally we discuss the performance of our proposed methods for lexicon generation in comparison with other manually crafted lexicons, PMI based method for lexicon generation and the standard BoW in an emotion classification task. 5.1 Twitter Dataset The data set used in our experiments was a corpus of emotion labelled tweets harnessed by (Wang et al., 2012). The data set was available in the form of tweet ID’s and the corresponding emotion label. The emotion labels comprised namely: anger, fear, joy, sadness, surprise, love and thankfulness. We used the Twitter search API1 to obtain the tweets by searching with the corresponding tweet ID. After that we decided to consider only tweets that belong to the primary set of emotions defined by Parrott (Parrott, 2001). The emotion classes in our case included anger, fear, joy, sadness, surprise and love. We had a collection of 0.28 million tweets which we used to carry out a 10 fold cross-validation exp</context>
</contexts>
<marker>Wang, Chen, Thirunarayan, Sheth, 2012</marker>
<rawString>Wenbo Wang, Lu Chen, Krishnaprasad Thirunarayan, and Amit P. Sheth. 2012. Harnessing twitter ”big data” for automatic emotion identification. In Proceedings of the 2012 ASE/IEEE International Conference on Social Computing and 2012 ASE/IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Yang</author>
<author>K H Y Lin</author>
<author>H H Chen</author>
</authors>
<title>Emotion classification using web blog corpora.</title>
<date>2007</date>
<booktitle>In Proceedings of the IEEE/WIC/ACM International Conference on Web Intelligence, WI ’07,</booktitle>
<pages>275--278</pages>
<publisher>IEEE Computer Society.</publisher>
<location>Washington, DC, USA.</location>
<contexts>
<context position="7001" citStr="Yang et al., 2007" startWordPosition="1071" endWordPosition="1074"> However the informal and dynamic nature of social media content makes it harder to adopt these lexicons for emotion analysis. An alternative strategy is to derive features from a dynamic (i.e., learnt) lexicon. Here association metrics such as Pointwise Mutual Information (PMI) can be used to model emotion polarity between a word and emotion labelled content (Mohammad, 2012a). Such approaches will be used as baselines to compare against our proposed lexicon generation strategies. There are other lexicon generation methods proposed by Rao .et. al (Yanghui Rao and Chen, 2013) and Yang .et. al (Yang et al., 2007). We do not consider these in our comparative evaluation since these methods require rated emotion labels and emoticon classes respectively. Lexicon generation, relies on the availability of a labelled corpus from which the word-emotion distributions can be discovered. For this purpose we exploit a distance-supervised approach where indirect cues are used to unearth implicit (or distant) labels that are contained in the corpus (Alec Go and Huang, 2009). We adopt the approach as in (Wang et al., 2012) to corpus labelling where social media content, and in particular Twitter content is sampled f</context>
</contexts>
<marker>Yang, Lin, Chen, 2007</marker>
<rawString>C. Yang, K. H. Y. Lin, and H. H. Chen. 2007. Emotion classification using web blog corpora. In Proceedings of the IEEE/WIC/ACM International Conference on Web Intelligence, WI ’07, pages 275–278, Washington, DC, USA. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liu Wenyin Qing Li Yanghui Rao</author>
<author>Xiaojun Quan</author>
<author>Mingliang Chen</author>
</authors>
<title>Building word-emotion mapping dictionary for online news. In</title>
<date>2013</date>
<booktitle>In Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, WASSA</booktitle>
<marker>Rao, Quan, Chen, 2013</marker>
<rawString>Liu Wenyin Qing Li Yanghui Rao, Xiaojun Quan and Mingliang Chen. 2013. Building word-emotion mapping dictionary for online news. In In Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, WASSA 2013.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>