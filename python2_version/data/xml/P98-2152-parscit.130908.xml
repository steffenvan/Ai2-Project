<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000006">
<title confidence="0.7832005">
Japanese OCR Error Correction using Character Shape
Similarity and Statistical Language Model
</title>
<author confidence="0.70025">
Masaaki NAGATA
</author>
<affiliation confidence="0.659588">
NTT Information and Communication Systems Laboratories
</affiliation>
<address confidence="0.879791">
1-1 Hikari-no-oka Yokosuka-Shi Kanagawa, 239-0847 Japan
</address>
<email confidence="0.99682">
nagata@nttnly.isl.ntt.co.jp
</email>
<sectionHeader confidence="0.996936" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999941833333333">
We present a novel OCR error correction method
for languages without word delimiters that have a
large character set, such as Japanese and Chinese.
It consists of a statistical OCR model, an approxi-
mate word matching method using character shape
similarity, and a word segmentation algorithm us-
ing a statistical language model. By using a sta-
tistical OCR model and character shape similarity,
the proposed error corrector outperforms the previ-
ously published method. When the baseline char-
acter recognition accuracy is 90%, it achieves 97.4%
character recognition accuracy.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999949579710145">
As our society is becoming more computerized, peo-
ple are getting enthusiastic about entering every-
thing into computers. So the need for OCR in areas
such as office automation and information retrieval
is becoming larger, contrary to our expectation.
In Japanese, although the accuracy of printed
character OCR is about 98%, sources such as old
books, poor quality photocopies, and faxes are still
difficult to process and cause many errors. The accu-
racy of handwritten OCR is still about 90% (Hilde-
brandt and Liu, 1993), and it worsens dramatically
when the input quality is poor. If NLP techniques
could be used to boost the accuracy of handwriting
and poor quality documents, we could enjoy a very
large market for OCR related applications.
OCR error correction can be thought of a spelling
correction problem. Although spelling correction
has been studied for several decades (Kukich, 1992),
the traditional techniques are implicitly based on
English and cannot be used for Asian languages such
as Japanese and Chinese.
The traditional strategy for English spelling cor-
rection is called isolated word error correction: Word
boundaries are placed by white spaces. If the tok-
enized string is not in the dictionary, it is a non-
word. For a non-word, correction candidates are re-
trieved from the dictionary by approximate string
match techniques using context-independent word
distance measures such as edit distance (Wagner and
Fischer, 1974) and ngram distance (Angell et al.,
1983).
Recently, statistical language models and feature-
based method have been used for context-sensitive
spelling correction, where errors are corrected con-
sidering the context in which the error occurs
(Church and Gale, 1991; Mays et al., 1991; Golding
and Schabes, 1996). Similar techniques are used for
correcting the output of English OCRs (Tong and
Evans, 1996) and English speech recognizers (Ring-
ger and Allen, 1996).
There are two problems in Japanese (and Chinese)
spelling correction. The first is the word boundary
problem. It is impossible to use isolated word error
correction techniques because there are no delimiters
between words. The second is the short word prob-
lem. Word distance measures are useless because the
average word length is short (&lt; 2), and the charac-
ter set is large (&gt; 3000). There are a much larger
number of one edit distance neighbors for a word,
compared with English.
Recently, the first problem was solved by selecting
the most likely word sequence from all combinations
of exactly and approximately matched words using a
Viterbi-like word segmentation algorithm and a sta-
tistical language model considering unknown words
and non-words (Nagata, 1996). However, the second
problem is not solved yet, at least elegantly. The so-
lution presented in (Nagata, 1996) which sorts a list
of one edit distance words considering the context
in which it will be placed is inaccurate because the
context itself might include some errors.
In this paper, we present a context-independent
approximate word match method using character
shape similarity. This is suitable for languages with
large character sets, such as Japanese and Chinese.
We also present a method to build a statistical OCR
model by smoothing the character confusion proba-
bility using character shape similarity.
It seems previous NLP researchers are reluctant
</bodyText>
<page confidence="0.99572">
922
</page>
<bodyText confidence="0.999791428571429">
to use resources such as the character confusion ma-
trix and feature vectors of the characters, and try to
solve the problem by using only linguistic devices.
We found that, by using character shape similarity,
the resulting OCR error corrector is robust and ac-
curate enough to correct unrestricted texts with a
wide range of recognition accuracies.
</bodyText>
<sectionHeader confidence="0.999803" genericHeader="method">
2 OCR Model
</sectionHeader>
<subsectionHeader confidence="0.991758">
2.1 Noisy Channel Model
</subsectionHeader>
<bodyText confidence="0.999716833333333">
First, we formulate the spelling correction of OCR
errors in the noisy channel paradigm. Let C rep-
resent the input string and X represent the OCR
output string. Finding the most probable string a
given the OCR output X amounts to maximizing
the function P(XIC)P(C),
</bodyText>
<equation confidence="0.997828">
O = arg max P(CIX) = arg max P(X1C)P(C) (1)
because Bayes&apos; rule states that,
P(XIC)P(C)
P(ClX) =
P(X)
</equation>
<bodyText confidence="0.55971525">
P(C) is called the language model. It is computed
from the training corpus. Let us call P(XIC) the
OCR model. It can be computed from the a priori
likelihood estimates for individual characters,
</bodyText>
<equation confidence="0.995541">
P(XIC) = 11 p(x,ict)
</equation>
<bodyText confidence="0.998764">
where n is the string length. P(x, Icz) is called the
characters confusion probability.
</bodyText>
<subsectionHeader confidence="0.994352">
2.2 Zero-Frequency Problem
</subsectionHeader>
<bodyText confidence="0.9582965">
The character confusion probabilities are computed
from the character confusion matrix, which is a set of
the frequencies of the input-output character pairs of
the OCR. The confusion matrix, however, is highly
dependent on the character recognition method and
the quality of the input image. It is a labor intensive
task to make a confusion matrix, since Japanese has
more than 3,000 characters. But the more serious
problem is that the confusion matrix is too sparse
to be used for statistical modeling.
For example, suppose the word &amp;quot;Ma&amp;quot; (environ-
ment) is incorrectly recognized as a non-word &amp;quot;tt
a&amp;quot;. The following is an excerpt of a confusion ma-
trix, where the pair of a character and a number
separated by a slash represents the output character
and its frequency.
input character M :
/1289 tg /1 it /1
input character 41:
t1/1282 */5 /1 Vf /1 /1 r0 /1 /1.
Even if we collect more than one thousand recog-
nition examples, there are no examples in which `M&apos;
is recognized as 15V. To compute the confusion prob-
ability P(Ekla), we need a smoothing method.
This is called the zero-frequency problem. Al-
though it has been studied in many areas such
as speech recognition, statistical language modeling
and text compression, no previous work has exam-
ined on the smoothing of the character confusion
probabilities. This is probably because the problem
arises only when we consider OCR error correction
of languages with large character sets.
We propose a novel method to smooth the char-
acter confusion probabilities. First, we estimate the
sum of the probabilities of novel events. We then
distribute the probability mass to each novel event
based on character similarity.
We use a scheme, which we refer to as the Witten-
Bell method (Witten and Bell, 1991), to estimate the
sum of the probabilities for all novel events because
it is simple and robust 1. Let C(ci, c; ) be the fre-
quency of events where ci and cl are the input and
the output characters, respectively. Let 13(c2) be the
sum of the probabilities of unseen output charac-
ters where the input character is c2. By using the
Witten-Bell method, /3(c,.) is estimated as,
</bodyText>
<equation confidence="0.937942857142857">
0(ci)= E P(cc)
c,:c(c„ c, ).0
E3 CO(C(Ci, Cin
(4)
where
f 1 if x &gt; 0
e(x) = 1 0 otherwise
</equation>
<bodyText confidence="0.9992089">
In the above example, V&apos; appears 1291(= 1289+1+
1) times as input and there are three distinct char-
acters in the output. Therefore, the probability of
observing novel characters is 3/(1291 +3) = 3/1294.
One of the possible alternatives to the Witten-Bell
method is the Good-Turing method (Good, 1953).
But we didn&apos;t use the method since it assumes the
distribution of the frequency of frequencies to be rel-
atively smooth, which is not the case in the character
confusion matrix.
</bodyText>
<subsectionHeader confidence="0.999123">
2.3 Back-off Smoothing
</subsectionHeader>
<bodyText confidence="0.998434777777778">
Both the Witten-Bell and Good-Turing methods do
not in themselves tell one how to share 0(c2) among
&apos;In (Witten and Bell, 1991), the method is referred to as
&amp;quot;method C&amp;quot; for estimating the escape probability in a text
compression method, Prediction by Partial Matching (PPM).
It estimates the probability of observing novel events to be
r/(n r), where n is the total number of events seen previ-
ously, and r is the number of symbols that are distinct. The
probability of the event observed c times is cl(n+ r).
</bodyText>
<figure confidence="0.360386">
(5)
</figure>
<page confidence="0.990671">
923
</page>
<bodyText confidence="0.999942444444444">
the distinct unseen events. The simplest strategy
is to assume all unseen events are equally probable,
but this is not reasonable because recognition errors
are more likely to occur among characters with simi-
lar shapes. Therefore, we distributed the probability
mass 0(c2) based on character shape similarity com-
puted from feature vectors.
First, we made an appropriate number of charac-
ter classes in which similar characters are gathered.
This is done by clustering the feature vectors of each
character; details are described in the next subsec-
tion. We then made a confusion matrix between the
character classes from the character confusion ma-
trix. Let C(classj, class j) be the frequency that the
characters in class&apos; are recognized as the characters
in class j. It is computed as the sum of the elements
in the character confusion matrix associated with
the characters in class&apos; and class j.
</bodyText>
<equation confidence="0.9896315">
C(classnclassj) =E c(c„,) (6)
c,Eclassl,c3Eclassj
</equation>
<bodyText confidence="0.9990832">
By using the Witten-Bell method, we can esti-
mate the class confusion probabilities between arbi-
trary classes. We then distribute the probability for
unseen events in proportion to the class confusion
probability,
</bodyText>
<equation confidence="0.999908">
P(cilci) = ci(ci)P(class(cj)Iclass(ci)) (7)
</equation>
<bodyText confidence="0.854863">
where
</bodyText>
<equation confidence="0.999380333333333">
ct(ci) = E
c,:c(c„c,).0 P(class(cj)Iclass(c8)) (8)
0(c.)
</equation>
<bodyText confidence="0.9998342">
is a normalizing constant, and class(c2) is the func-
tion that returns the class of character c.
Numerical values for a&apos;s as well as the charac-
ter class confusion probabilities can be precomputed.
Therefore, the method is computationally efficient.
</bodyText>
<subsectionHeader confidence="0.997895">
2.4 Character Clustering
</subsectionHeader>
<bodyText confidence="0.999977590909091">
In general, character recognition consists of feature
extraction and classification. Feature extraction is
applied to concentrate the information in the im-
age into a few, highly selective features. Classifica-
tion is accomplished by comparing the feature vec-
tor corresponding to the input character with the
representatives of each character, using a distance
metric. Therefore, if we cluster feature vectors of
each character, the members of the resulting class
are characters with similar shape, and so tend to
cause confusion.
The feature we used in the clustering experi-
ment is PDC (Peripheral Direction Contributivity)
(Hagita et al., 1983), which is one of the best features
for Japanese character recognition 2. We clustered
the feature vectors for 3021 Japanese characters into
128 classes by using the LBG algorithm (Linde et
al., 1980), which is one of the most popular vector
quantization methods.
Let&apos;s go back to the previous example of estimat-
ing P(RIM). After character clustering, `M&apos; and `a&apos;
are clustered into class 29 and 119, respectively.
</bodyText>
<equation confidence="0.837509333333333">
class 29 (including gR):
RXXAM/tgg.&apos;4e.a:SIS ti
41
class 119 (including *):
4AAAiVtgataiRIRI**#5
ttk tc tit tI2
</equation>
<bodyText confidence="0.764745666666667">
Here is the excerpt of the class confusion matrix for
class 29.
input class 29:
</bodyText>
<table confidence="0.9268446">
29/30884 87/23 33/21 59/20 15/9 119/7 94/6
78/6 28/5 2/4 109/4 101/4 71/4 104/3 107/3
21/3 58/3 70/2 113/2 56/2 0/2 34/2 38/2 26/2
18/2 44/1 72/1 50/1 30/1 102/1 19/1 89/1
110/1 4/1 122/1 123/1
</table>
<bodyText confidence="0.989303285714286">
Since class 29 appears 31036(30884 + 23 + -)
times as input and there are 36 distinct classes
in the output, where class 119 appeared 7 times,
P(c/assinic/ass29) = 7/(31036 + 36) = 7/31072.
This class confusion probability and the normalizing
constant a(M) are used to compute P(I) using
equation (7).
</bodyText>
<sectionHeader confidence="0.999863" genericHeader="method">
3 Language Model
</sectionHeader>
<subsectionHeader confidence="0.999574">
3.1 Word Segmentation Model
</subsectionHeader>
<bodyText confidence="0.999965833333333">
Let the input Japanese character sequence be C =
c1c2 cm, which can be segmented into word se-
quence W = w1w2 wn. We approximate P(C)
in Equation (1) by the joint probability of word se-
quence P(W). P(W) is then approximated by the
product of word bigram probabilities P(wziwz--1).
</bodyText>
<equation confidence="0.9962435">
P(C) P(W) P(wilwa-1) (9)
i=1
</equation>
<bodyText confidence="0.597507222222222">
2PDC features are formed by assigning stroke directions
to pixels and selecting just pixels on the first, second, and
third stroke encountered by the scan line. The marginal dis-
tribution of the four direction contributivity of such three pix-
els is then taken along 16 lines in eight different directions.
Therefore, the dimension of the original PDC feature vector is
8*3*4*16=1536. By using 2-stage feature selection, it can be
reduced to 256, while still preserving the original recognition
ability.
</bodyText>
<page confidence="0.992773">
924
</page>
<bodyText confidence="0.98526805">
Using the language model (9), the OCR error cor-
rection task can be defined as finding a word se-
quence W that maximizes the joint probability of
word sequence given recognized character sequence
P(WIX). By using Bayes&apos; rule, this amounts to
maximizing the product of P(XIW) and P(W).
= arg mvax P(W IX) = arg P(XIW)P(W) (10)
The maximization search can be efficiently imple-
mented by using the Viterbi-like dynamic program-
ing procedure described in (Nagata, 1996). The
algorithm starts from the beginning of the input
sentence, and proceeds character by character. At
each point in the sentence, it looks up the combina-
tion of the best partial word segmentation hypoth-
esis ending there and all word hypotheses starting
there. The word hypotheses proposed at each point
include both exactly matched words and approxi-
mately matched words. All prefixes of the substring
starting at the point are also proposed as unknown
words if they are not in the dictionary.
</bodyText>
<subsectionHeader confidence="0.994658">
3.2 Word Model for Unknown Words
</subsectionHeader>
<bodyText confidence="0.999956142857143">
We defined a statistical word model to assign a rea-
sonable word probability to an arbitrary substring
in the input sentence. The word model is formally
defined as the joint probability of the character se-
quence w2 = c1 ck if it is an unknown word. We
decompose it into the product of word length prob-
ability and word spelling probability,
</bodyText>
<equation confidence="0.907917">
P(wi I&lt;UNK&gt;) = P(ci ck I&lt;UNK&gt;) = P(k)P(ci ck lk) (11)
</equation>
<bodyText confidence="0.999667">
where k is the length of the character sequence and
&lt;UNK&gt; represents unknown word.
We assume that word length probability P(k)
obeys a Poisson distribution whose parameter is the
average word length A in the training corpus. This
means that we regard word length as the interval
between hidden word boundary markers, which are
randomly placed with an average interval equal to
the average word length.
</bodyText>
<equation confidence="0.993934">
(A —1)k-1
P(k) = (k —1)! e
</equation>
<bodyText confidence="0.997205666666667">
We approximate the spelling probability given
word length P(ci ck lk) by the word-based char-
acter bigram model, regardless of word length.
</bodyText>
<equation confidence="0.8591">
P(Ci . . .Ck) = P (C1 lc HP(cdc,_oP(#ick) (13)
</equation>
<page confidence="0.870562">
2=2
</page>
<bodyText confidence="0.997218">
where &amp;quot;#&amp;quot; indicates the word boundary marker.
</bodyText>
<sectionHeader confidence="0.985693" genericHeader="method">
4 Approximate Word Matching
</sectionHeader>
<bodyText confidence="0.999965184210526">
Since there are no delimiters between words in
Japanese, we have to hypothesize all substrings in
the input sentence as words, and retrieve their ap-
proximately matching words from the dictionary as
correction candidates. The most likely correction
candidate is selected by the word segmentation algo-
rithm using the OCR model and the language model.
For simplicity, we will present the method as if it
were for an isolated word error correction.
In English spelling correction, correction candi-
dates are generated by the minimum edit distance
technique (Wagner and Fischer, 1974). Edit dis-
tance is the minimum number of editing operations
(insertions, deletions, and substitutions) required to
transform one string into another. Since the tar-
get is OCR output, we can restrict the type of er-
rors to substitutions only. Thus, the edit distance
of two words becomes cln, where c is the number of
matched characters and n is the length of the mis-
spelled (and the dictionary) word. Since the cost of
computing the edit distance between a string and all
dictionary words is expensive, we create an inverted
index into the dictionary using character bigrams as
the access keys (Angell et al., 1983).
In Japanese OCR spelling correction, it is rea-
sonable to generate correction candidates by edit
distance for words longer than 2 characters since
the number of correction candidates would be small.
However, for two character words, edit distance is
useless, because there are a large number of words
with one edit distance. Since the average word
length of Japanese is about two characters, this is
a serious problem.
We propose an approximate word matching
method that uses character similarity. Let X be a
non-word caused by OCR errors, and W be a cor-
rection candidate word. X would be corrected by W
if the following relationship holds,
</bodyText>
<equation confidence="0.980045">
P(X)P(XIX) &lt; P(W)P(XIW) (14)
</equation>
<bodyText confidence="0.992550153846154">
The left hand side represents the probability that
X is an unknown word and that it is correctly rec-
ognized. The right hand side represents the proba-
bility that W is incorrectly recognized as X. The
larger the product of the word unigram probability
P(W) and the word confusion probability P(XIW),
the more likely word W is the correct word for X.
Therefore, for two character words, we sort the list
of all one edit distance words by P(W)P(XIW), and
select the top-k words as the correction candidates.
For example, if &amp;quot;M*&amp;quot; is incorrectly recognized as
there are at least 20 dictionary words whose
edit distance is one.
</bodyText>
<equation confidence="0.630497">
(12)
925
45tRf 45ttk 45ZAt #5V5 #561: RA
AA R*14
</equation>
<bodyText confidence="0.952988">
If we sort the list of one edit distance words by
P(W), P(XIW), and P(W)P(XIW), the correction
candidates become as follows,
</bodyText>
<equation confidence="0.9234728">
sorted by P(W):
sorted by P(XIW):
45VA *01 #5M 131*
sorted by P(W) P(XIW):
MIA 45VA MIA V* ...
</equation>
<bodyText confidence="0.999694">
Thus, by using P(W)P(XIW), we can make &amp;quot;a
*&amp;quot; the most likely correction word. The approxi-
mate word matching method is so accurate that, in
practice, it is sufficient to use only the top 5 candi-
dates. This makes the program very efficient.
</bodyText>
<sectionHeader confidence="0.999245" genericHeader="method">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999426">
5.1 Training Data for the Language Model
</subsectionHeader>
<bodyText confidence="0.99982825">
We used the EDR Japanese Corpus Version 1.0
(EDR, 1991) to train the language model. It is a
corpus of approximately 5.1 million words (208 thou-
sand sentences). It contains a variety of Japanese
sentences taken from newspapers, magazines, dic-
tionaries, encyclopedias, textbooks, etc. It has a
variety of annotations including word segmentation,
pronunciation, and part of speech.
In this experiment, we randomly selected 90% of
the sentences in the EDR Corpus for training. The
first column of Table 1 shows the number of sen-
tences, words, and characters of the training set.
</bodyText>
<tableCaption confidence="0.997105">
Table 1: The amount of the training data and the
test data for handwritten OCR
</tableCaption>
<table confidence="0.99029825">
training test 1
Sentences 192802 100
Words 4746461 2463
Characters 7521293 3912
</table>
<bodyText confidence="0.999969235294118">
There were 133281 distinct words in the training
data. We discarded the words whose frequency was
one, and made a dictionary of 65152 words. We then
counted the vocabulary dependent word bigrams.
That is, the words that were not in the dictionary
were replaced with the unknown word symbol &lt;UNK&gt;
before counting the bigrams. There were 758172
distinct word bigrams. We discarded the bigrams
whose frequency was one, and the remaining 294668
bigrams were used in the word segmentation model.
In the word model, we used 3167 character uni-
grams and 91198 character bigrams. All unigrams
and bigrams whose frequencies were one were dis-
carded. As for the average word length, instead of
averaging all words in the corpus (=1.58), we aver-
aged the words whose frequency was one (=4.76) in
order to avoid the influence of highly frequent words.
</bodyText>
<subsectionHeader confidence="0.998473">
5.2 Testi: Handwritten OCR
</subsectionHeader>
<bodyText confidence="0.988063">
We designed two experiments to evaluate the perfor-
mance of the OCR error corrector. The first experi-
ment used simulated outputs of a handwriting OCR,
while the second used real outputs of a printed char-
acter OCR.
The first experiment was designed to test the OCR
error corrector over a wide range of baseline recogni-
tion accuracies. The use of the OCR simulator was
necessary because it is very difficult to obtain a large
amount of test data with arbitrary accuracies.
We selected 100 sentences from the remaining 10%
of the EDR corpus for testing. The second column
of Table 1 shows the number of sentences, words,
and characters of the test set. By using an OCR
simulator, we made four sets of character matrices
whose first-rank recognition accuracies were 70%,
80%, 90%, and 95%. They contained at most 10
candidates for each character and their cumulative
recognition accuracies were 90%, 95%, 98%, and
98%, respectively.
For comparison, we implemented the OCR er-
ror correction method, which does not use char-
acter similarity information, presented in (Nagata,
1996). Instead of using character confusion matrix,
he approximated it by the correct character distri-
bution over the rank of the candidates 3. We refer
to his method as the candidate rank method, and
our method as the character similarity method.
Figure 1 shows the recognition accuracies after er-
ror correction for various baseline OCR accuracies.
The horizontal axis represents the accuracies of the
baseline OCR, while the vertical axis represents the
accuracies after error correction. The farther the
point lies above the diagonal line, the more improve-
ments are brought by the OCR error corrector.
3In (Nagata, 1996), it was assumed that the rank order
distribution of the correct characters is a geometric distribu-
tion whose parameter is the accuracy of the first candidate.
Let ci be the i-th character in the input, xii be the j-th can-
didate for ci in the output, and p be the probability that the
first candidate is correct. The confusion probability P(si,lci)
is approximated as,
</bodyText>
<equation confidence="0.478002">
P(xiiici) ^et&apos;, P(xii is correct) Pe• p(1 - p)3-1
</equation>
<page confidence="0.991306">
926
</page>
<figure confidence="0.664477">
Error Correction Accuracy
</figure>
<figureCaption confidence="0.99861">
Figure 1: Comparison of the improvement in char-
acter recognition accuracy
</figureCaption>
<bodyText confidence="0.999973666666667">
The character similarity method is significantly
better than the candidate rank method for all base-
line recognition accuracies examined. For example,
when the baseline accuracy is 90%, the character
similarity method achieved 97.4%, while the accu-
racy of the candidate rank method was 93.9% 4 .
</bodyText>
<subsectionHeader confidence="0.99789">
5.3 Test2: Printed Character OCR
</subsectionHeader>
<bodyText confidence="0.999995055555556">
The second experiment was designed to test the
OCR error corrector on unrestricted text and un-
known OCR. In the first experiment, although the
test sentences were open data, their statistical char-
acteristics are expected to be similar to the training
data because both of them were taken from the same
corpus. Moreover, since the OCR simulator and the
OCR error corrector used the same character confu-
sion matrix, the input character matrices were closed
data with respect to OCR.
We selected 30 documents, each of which con-
tained about 1000 characters. These documents had
nothing to do with the EDR corpus. Ten of them
were newspapers and the other 20 documents were
a miscellaneous collection of novels, essays, patents,
laws, scientific papers, etc.. Table 2 shows the break-
down of document type and image resolution. News-
papers were scanned at 300dpi and 400dpi, two of
</bodyText>
<footnote confidence="0.5859385">
4 (Nagata, 1996) reported that, when the baseline accuracy
is 90%, his method achieved 96.3%. The difference between
96.3% and 93.9% comes from the difference in the corpora.
He tested the ATR corpus whose word perplexity is about 30,
while we tested the EDR corpus whose perplexity is about 95.
Here, perplexities are computed using word bigram model.
</footnote>
<tableCaption confidence="0.970524">
Table 2: The document type and the image resolu-
tion of the test data for the printed character OCR
</tableCaption>
<table confidence="0.503088666666667">
200dpi 300dpi 400dpi
newspapers 0 8 10
miscellaneous 20 20 10
</table>
<bodyText confidence="0.99877655">
them, scanned at 300dpi, were discarded because of
low quality. Other miscellaneous documents were
mainly scanned at 200dpi and 300dpi. Ten that used
smaller fonts were also scanned at 400dpi.
The printed character OCR used was a commer-
cial product (RICOH Yomitori-Monogatari). It out-
puts at most 10 candidates for each character as well
as a score ranging from 0 to 100 that represents the
certainty of the first candidate. In fact, we know
nothing about the algorithm and the training data
of the OCR. At least, the training data should be
different from ours since one is created for printed
characters while the other was designed for hand-
written characters.
The 68 test document images contained 69102 in-
put characters. After character recognition, there
were 69305 output characters where 67639 (97.9%)
characters were correct. There were 1422 (2.1%) re-
placement errors, 244 (0.4%) insertion errors and 41
(0.06%) deletion errors.
</bodyText>
<figureCaption confidence="0.995262">
Figure 2: Error correction accuracy
</figureCaption>
<bodyText confidence="0.9996478">
By using the OCR error corrector, 575 characters
were corrected, where 294 were right and 281 were
wrong. The net improvement was only 13 charac-
ters. Figure 2 shows the recognition accuracies of
each document image before and after error correc-
</bodyText>
<figure confidence="0.998682">
5
0.85
0.8
0.95
0.9
First Rank Accuracy -*-
Cumulative Accuracy •
Character Sirnilarity
Candidate Rank a
0.7
0.65
0.65 0.7 0.75 0.8 0.85 0.9 0.95
Character Recognition Accuracy (Before NIP)
0.75
Error Correction Accuracy
0.99
a.
0.97
25.
g 0.96
0.95
0.94
0.91
0.9
09 0.91 0.92 0.93 0.94 0.95 0.96 0.97 0.98 0.99
Character Recognition Accuracy (Before NLP)
0.98
</figure>
<page confidence="0.977352">
927
</page>
<tableCaption confidence="0.92214">
Table 3: OCR score and the number of right and
wrong corrections by the error corrector
</tableCaption>
<table confidence="0.8020775">
OCR score &lt;= 100 &lt;=80 &lt;=60
right correction 294 199 169
wrong correction 281 48 22
net improvements 13 151 147
</table>
<bodyText confidence="0.991068916666667">
tion: 24 documents were improved, 30 documents
got worse, and 14 documents were unchanged.
Figure 2 indicates that the OCR error corrector
improves the accuracy when the baseline recognition
accuracy is less than 98%, while it worsens when the
accuracy is more than 98%. This is mainly because
of wrong corrections, where unknown words in the
original text are replaced by more frequent words in
the dictionary. Most unknown words are numbers,
acronyms, and transliterated foreign words.
Wrong correction can be avoided if the certainty of
the character recognition (OCR score) is available.
Table 3 shows the number of right and wrong cor-
rections when correction is allowed only if the the
OCR score is less than a certain threshold. The
score of the printed character OCR ranges from 0
to 100, where 100 means it is pretty sure about the
output. If we reject the corrections suggested by the
error corrector when the OCR score is more than
80, the number of wrong corrections is reduced from
281 to 48, while that of right correction is reduced
from 294 to 199. Thus, the number of net improve-
ments increases from 13 to 151, which means a 10.6%
(151/1422) reduction in replacement errors.
</bodyText>
<sectionHeader confidence="0.999858" genericHeader="method">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999962481481482">
Most previous works on Japanese OCR error cor-
rection considered only printed character OCRs
and their target domain was limited. (Takao and
Nishino, 1989) used part of speech bigram model
and heuristic templates for unknown words. They
achieved about 95% accuracy when the baseline ac-
curacy was 91% for magazines and introductory
textbooks of science and technology. (Ito and
Maruyama, 1992) used part of speech bigram model
and beam search in order to get multiple candidates
in their interactive OCR corrector. They achieved
94.61% accuracy when the baseline accuracy was
87.46% for patents in electric engineering. We used
word bigram model, a statistical word model for un-
known words, and a statistical OCR model. We
achieved 97.4% accuracy, when the baseline accu-
racy was 90% and the domain was not limited.
It is very difficult to compare our results with the
previous results because the experiment conditions
are completely different. However, considering the
fact that we did not restrict the target domain, our
method arguably outperformed the previously pub-
lished results, when the baseline accuracy is more
then 90%. There is only one published work inves-
tigating the baseline accuracy much lower than 90%
(Nagata, 1996). As we proved in the experiment, we
outperformed his results significantly.
</bodyText>
<sectionHeader confidence="0.999347" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999972166666667">
We have presented a Japanese OCR error corrector.
It arguably outperforms previously published tech-
niques. To improve the error correction accuracy,
a more sophisticated language model for unknown
words, including numbers, acronyms, and transliter-
ated foreign words, must be investigated.
</bodyText>
<sectionHeader confidence="0.999679" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999317436363637">
Richard C. Angell, George W. Freund, and Peter Willett.
1983. Automatic spelling correction using a trigram sim-
ilarity measure. Information Processing &amp; Management,
19(4):255-261.
Kenneth W. Church and William A. Gale. 1991. Probability
scoring for spelling correction. Statistics and Computing,
1:93-103.
EDR. 1991. Edr electronic dictionary version 1 technical
guide. Technical Report TR2-003, Japan Electronic Dic-
tionary Research Institute.
Andrew R. Golding and Yves Schabes. 1996. Combin-
ing trigram-based and feature-based method for context-
sensitive spelling correction. In ACL-96, pages 71-78.
I. J. Good. 1953. The population frequencies of species
and the estimation of population parameters. Biometrika,
40:237-264.
Norihiro Hagita, Seiichiro Naito, and Isao Masuda. 1983.
Handprinted chinese characters recognition by periph-
eral direction contributivity feature. lEICE Transactions
on Information and Systems, J66-D(10):1185-1192. (In
Japanese).
Thomas H. Hildebrandt and Wentai Liu. 1993. Optical recog-
nition of handwritten chinese characters: Advances since
1980. Pattern recognition, 26(2):205-225.
Nobuyasu Ito and Hiroshi Maruyama. 1992. A method of de-
tecting and correcting errors in the results of japanese ocr.
Transaction of Information Processing Society of Japan,
33(5):664-670. (In Japanese).
Karen Kukich. 1992. Techniques for automatically correcting
words in text. ACM Computing Surveys, 24(4):377-439.
Yoseph Linde, Andres Buzo, and Robert M. Gray. 1980. An
algorithm for vector quantizer design. IEEE Transactions
on Communications, COM-28(1):84-95.
Eric Mays, Fred J. Damerau, and Robert L. Mercer. 1991.
Context based spelling correction. Information Processing
&amp; Management, 27(5):517-522.
Masaaki Nagata. 1996. Context-based spelling correction for
japanese ocr. In COLING-96, pages 806-811.
Eric K. Ringger and James F. Allen. 1996. A fertility channel
model for post-correction of continuous speech recognition.
In ICSLP-96, pages 897-900.
Tetsuyasu Takao and Fumihito Nishino. 1989. Implementa-
tion and evaluation of post-processing for japanese docu-
ment readers. Transaction of Information Processing So-
ciety of Japan, 30(11):1394-1401. (In Japanese).
Xiang Tong and David A. Evans. 1996. A statistical approach
to automatic ocr error correction in context. In WVLC-96,
pages 88-10.
Robert A. Wagner and Michael J. Fischer. 1974. The
string-to-string correction problem. Journal of the ACM,
21(1):168-173.
Ian H. Witten and Timothy C. Bell. 1991. The zero-frequency
problem: Estimating the probabilities of novel events in
adaptive text compression. IEEE Transaction on Infor-
mation Theory, 37(4):1085-1094.
</reference>
<page confidence="0.996968">
928
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.902346">
<title confidence="0.9944745">Japanese OCR Error Correction using Character Shape Similarity and Statistical Language Model</title>
<author confidence="0.996909">Masaaki NAGATA</author>
<affiliation confidence="0.998449">NTT Information and Communication Systems Laboratories</affiliation>
<address confidence="0.9488">1-1 Hikari-no-oka Yokosuka-Shi Kanagawa, 239-0847 Japan</address>
<email confidence="0.971661">nagata@nttnly.isl.ntt.co.jp</email>
<abstract confidence="0.998888153846154">We present a novel OCR error correction method for languages without word delimiters that have a large character set, such as Japanese and Chinese. It consists of a statistical OCR model, an approximate word matching method using character shape similarity, and a word segmentation algorithm using a statistical language model. By using a statistical OCR model and character shape similarity, the proposed error corrector outperforms the previously published method. When the baseline character recognition accuracy is 90%, it achieves 97.4% character recognition accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Richard C Angell</author>
<author>George W Freund</author>
<author>Peter Willett</author>
</authors>
<title>Automatic spelling correction using a trigram similarity measure.</title>
<date>1983</date>
<booktitle>Information Processing &amp; Management,</booktitle>
<pages>19--4</pages>
<contexts>
<context position="2328" citStr="Angell et al., 1983" startWordPosition="350" endWordPosition="353"> several decades (Kukich, 1992), the traditional techniques are implicitly based on English and cannot be used for Asian languages such as Japanese and Chinese. The traditional strategy for English spelling correction is called isolated word error correction: Word boundaries are placed by white spaces. If the tokenized string is not in the dictionary, it is a nonword. For a non-word, correction candidates are retrieved from the dictionary by approximate string match techniques using context-independent word distance measures such as edit distance (Wagner and Fischer, 1974) and ngram distance (Angell et al., 1983). Recently, statistical language models and featurebased method have been used for context-sensitive spelling correction, where errors are corrected considering the context in which the error occurs (Church and Gale, 1991; Mays et al., 1991; Golding and Schabes, 1996). Similar techniques are used for correcting the output of English OCRs (Tong and Evans, 1996) and English speech recognizers (Ringger and Allen, 1996). There are two problems in Japanese (and Chinese) spelling correction. The first is the word boundary problem. It is impossible to use isolated word error correction techniques bec</context>
<context position="15914" citStr="Angell et al., 1983" startWordPosition="2596" endWordPosition="2599">, 1974). Edit distance is the minimum number of editing operations (insertions, deletions, and substitutions) required to transform one string into another. Since the target is OCR output, we can restrict the type of errors to substitutions only. Thus, the edit distance of two words becomes cln, where c is the number of matched characters and n is the length of the misspelled (and the dictionary) word. Since the cost of computing the edit distance between a string and all dictionary words is expensive, we create an inverted index into the dictionary using character bigrams as the access keys (Angell et al., 1983). In Japanese OCR spelling correction, it is reasonable to generate correction candidates by edit distance for words longer than 2 characters since the number of correction candidates would be small. However, for two character words, edit distance is useless, because there are a large number of words with one edit distance. Since the average word length of Japanese is about two characters, this is a serious problem. We propose an approximate word matching method that uses character similarity. Let X be a non-word caused by OCR errors, and W be a correction candidate word. X would be corrected </context>
</contexts>
<marker>Angell, Freund, Willett, 1983</marker>
<rawString>Richard C. Angell, George W. Freund, and Peter Willett. 1983. Automatic spelling correction using a trigram similarity measure. Information Processing &amp; Management, 19(4):255-261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
<author>William A Gale</author>
</authors>
<title>Probability scoring for spelling correction.</title>
<date>1991</date>
<journal>Statistics and Computing,</journal>
<pages>1--93</pages>
<contexts>
<context position="2549" citStr="Church and Gale, 1991" startWordPosition="382" endWordPosition="385"> called isolated word error correction: Word boundaries are placed by white spaces. If the tokenized string is not in the dictionary, it is a nonword. For a non-word, correction candidates are retrieved from the dictionary by approximate string match techniques using context-independent word distance measures such as edit distance (Wagner and Fischer, 1974) and ngram distance (Angell et al., 1983). Recently, statistical language models and featurebased method have been used for context-sensitive spelling correction, where errors are corrected considering the context in which the error occurs (Church and Gale, 1991; Mays et al., 1991; Golding and Schabes, 1996). Similar techniques are used for correcting the output of English OCRs (Tong and Evans, 1996) and English speech recognizers (Ringger and Allen, 1996). There are two problems in Japanese (and Chinese) spelling correction. The first is the word boundary problem. It is impossible to use isolated word error correction techniques because there are no delimiters between words. The second is the short word problem. Word distance measures are useless because the average word length is short (&lt; 2), and the character set is large (&gt; 3000). There are a muc</context>
</contexts>
<marker>Church, Gale, 1991</marker>
<rawString>Kenneth W. Church and William A. Gale. 1991. Probability scoring for spelling correction. Statistics and Computing, 1:93-103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>EDR</author>
</authors>
<title>Edr electronic dictionary version 1 technical guide.</title>
<date>1991</date>
<tech>Technical Report TR2-003,</tech>
<institution>Japan Electronic Dictionary Research Institute.</institution>
<contexts>
<context position="17824" citStr="EDR, 1991" startWordPosition="2929" endWordPosition="2930"> 45tRf 45ttk 45ZAt #5V5 #561: RA AA R*14 If we sort the list of one edit distance words by P(W), P(XIW), and P(W)P(XIW), the correction candidates become as follows, sorted by P(W): sorted by P(XIW): 45VA *01 #5M 131* sorted by P(W) P(XIW): MIA 45VA MIA V* ... Thus, by using P(W)P(XIW), we can make &amp;quot;a *&amp;quot; the most likely correction word. The approximate word matching method is so accurate that, in practice, it is sufficient to use only the top 5 candidates. This makes the program very efficient. 5 Experiments 5.1 Training Data for the Language Model We used the EDR Japanese Corpus Version 1.0 (EDR, 1991) to train the language model. It is a corpus of approximately 5.1 million words (208 thousand sentences). It contains a variety of Japanese sentences taken from newspapers, magazines, dictionaries, encyclopedias, textbooks, etc. It has a variety of annotations including word segmentation, pronunciation, and part of speech. In this experiment, we randomly selected 90% of the sentences in the EDR Corpus for training. The first column of Table 1 shows the number of sentences, words, and characters of the training set. Table 1: The amount of the training data and the test data for handwritten OCR </context>
</contexts>
<marker>EDR, 1991</marker>
<rawString>EDR. 1991. Edr electronic dictionary version 1 technical guide. Technical Report TR2-003, Japan Electronic Dictionary Research Institute.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew R Golding</author>
<author>Yves Schabes</author>
</authors>
<title>Combining trigram-based and feature-based method for contextsensitive spelling correction.</title>
<date>1996</date>
<booktitle>In ACL-96,</booktitle>
<pages>71--78</pages>
<contexts>
<context position="2596" citStr="Golding and Schabes, 1996" startWordPosition="390" endWordPosition="393">rd boundaries are placed by white spaces. If the tokenized string is not in the dictionary, it is a nonword. For a non-word, correction candidates are retrieved from the dictionary by approximate string match techniques using context-independent word distance measures such as edit distance (Wagner and Fischer, 1974) and ngram distance (Angell et al., 1983). Recently, statistical language models and featurebased method have been used for context-sensitive spelling correction, where errors are corrected considering the context in which the error occurs (Church and Gale, 1991; Mays et al., 1991; Golding and Schabes, 1996). Similar techniques are used for correcting the output of English OCRs (Tong and Evans, 1996) and English speech recognizers (Ringger and Allen, 1996). There are two problems in Japanese (and Chinese) spelling correction. The first is the word boundary problem. It is impossible to use isolated word error correction techniques because there are no delimiters between words. The second is the short word problem. Word distance measures are useless because the average word length is short (&lt; 2), and the character set is large (&gt; 3000). There are a much larger number of one edit distance neighbors </context>
</contexts>
<marker>Golding, Schabes, 1996</marker>
<rawString>Andrew R. Golding and Yves Schabes. 1996. Combining trigram-based and feature-based method for contextsensitive spelling correction. In ACL-96, pages 71-78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I J Good</author>
</authors>
<title>The population frequencies of species and the estimation of population parameters.</title>
<date>1953</date>
<journal>Biometrika,</journal>
<pages>40--237</pages>
<contexts>
<context position="7782" citStr="Good, 1953" startWordPosition="1261" endWordPosition="1262"> cl are the input and the output characters, respectively. Let 13(c2) be the sum of the probabilities of unseen output characters where the input character is c2. By using the Witten-Bell method, /3(c,.) is estimated as, 0(ci)= E P(cc) c,:c(c„ c, ).0 E3 CO(C(Ci, Cin (4) where f 1 if x &gt; 0 e(x) = 1 0 otherwise In the above example, V&apos; appears 1291(= 1289+1+ 1) times as input and there are three distinct characters in the output. Therefore, the probability of observing novel characters is 3/(1291 +3) = 3/1294. One of the possible alternatives to the Witten-Bell method is the Good-Turing method (Good, 1953). But we didn&apos;t use the method since it assumes the distribution of the frequency of frequencies to be relatively smooth, which is not the case in the character confusion matrix. 2.3 Back-off Smoothing Both the Witten-Bell and Good-Turing methods do not in themselves tell one how to share 0(c2) among &apos;In (Witten and Bell, 1991), the method is referred to as &amp;quot;method C&amp;quot; for estimating the escape probability in a text compression method, Prediction by Partial Matching (PPM). It estimates the probability of observing novel events to be r/(n r), where n is the total number of events seen previously</context>
</contexts>
<marker>Good, 1953</marker>
<rawString>I. J. Good. 1953. The population frequencies of species and the estimation of population parameters. Biometrika, 40:237-264.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Norihiro Hagita</author>
<author>Seiichiro Naito</author>
<author>Isao Masuda</author>
</authors>
<title>Handprinted chinese characters recognition by peripheral direction contributivity feature.</title>
<date>1983</date>
<journal>lEICE Transactions on Information and Systems,</journal>
<pages>66--10</pages>
<note>(In Japanese).</note>
<contexts>
<context position="10684" citStr="Hagita et al., 1983" startWordPosition="1718" endWordPosition="1721">cognition consists of feature extraction and classification. Feature extraction is applied to concentrate the information in the image into a few, highly selective features. Classification is accomplished by comparing the feature vector corresponding to the input character with the representatives of each character, using a distance metric. Therefore, if we cluster feature vectors of each character, the members of the resulting class are characters with similar shape, and so tend to cause confusion. The feature we used in the clustering experiment is PDC (Peripheral Direction Contributivity) (Hagita et al., 1983), which is one of the best features for Japanese character recognition 2. We clustered the feature vectors for 3021 Japanese characters into 128 classes by using the LBG algorithm (Linde et al., 1980), which is one of the most popular vector quantization methods. Let&apos;s go back to the previous example of estimating P(RIM). After character clustering, `M&apos; and `a&apos; are clustered into class 29 and 119, respectively. class 29 (including gR): RXXAM/tgg.&apos;4e.a:SIS ti 41 class 119 (including *): 4AAAiVtgataiRIRI**#5 ttk tc tit tI2 Here is the excerpt of the class confusion matrix for class 29. input cla</context>
</contexts>
<marker>Hagita, Naito, Masuda, 1983</marker>
<rawString>Norihiro Hagita, Seiichiro Naito, and Isao Masuda. 1983. Handprinted chinese characters recognition by peripheral direction contributivity feature. lEICE Transactions on Information and Systems, J66-D(10):1185-1192. (In Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas H Hildebrandt</author>
<author>Wentai Liu</author>
</authors>
<title>Optical recognition of handwritten chinese characters:</title>
<date>1993</date>
<booktitle>Advances since 1980. Pattern recognition,</booktitle>
<pages>26--2</pages>
<contexts>
<context position="1365" citStr="Hildebrandt and Liu, 1993" startWordPosition="198" endWordPosition="202">ne character recognition accuracy is 90%, it achieves 97.4% character recognition accuracy. 1 Introduction As our society is becoming more computerized, people are getting enthusiastic about entering everything into computers. So the need for OCR in areas such as office automation and information retrieval is becoming larger, contrary to our expectation. In Japanese, although the accuracy of printed character OCR is about 98%, sources such as old books, poor quality photocopies, and faxes are still difficult to process and cause many errors. The accuracy of handwritten OCR is still about 90% (Hildebrandt and Liu, 1993), and it worsens dramatically when the input quality is poor. If NLP techniques could be used to boost the accuracy of handwriting and poor quality documents, we could enjoy a very large market for OCR related applications. OCR error correction can be thought of a spelling correction problem. Although spelling correction has been studied for several decades (Kukich, 1992), the traditional techniques are implicitly based on English and cannot be used for Asian languages such as Japanese and Chinese. The traditional strategy for English spelling correction is called isolated word error correctio</context>
</contexts>
<marker>Hildebrandt, Liu, 1993</marker>
<rawString>Thomas H. Hildebrandt and Wentai Liu. 1993. Optical recognition of handwritten chinese characters: Advances since 1980. Pattern recognition, 26(2):205-225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nobuyasu Ito</author>
<author>Hiroshi Maruyama</author>
</authors>
<title>A method of detecting and correcting errors in the results of japanese ocr.</title>
<date>1992</date>
<journal>Transaction of Information Processing Society of Japan,</journal>
<pages>33--5</pages>
<note>(In Japanese).</note>
<contexts>
<context position="26674" citStr="Ito and Maruyama, 1992" startWordPosition="4392" endWordPosition="4395">tions is reduced from 281 to 48, while that of right correction is reduced from 294 to 199. Thus, the number of net improvements increases from 13 to 151, which means a 10.6% (151/1422) reduction in replacement errors. 6 Discussion Most previous works on Japanese OCR error correction considered only printed character OCRs and their target domain was limited. (Takao and Nishino, 1989) used part of speech bigram model and heuristic templates for unknown words. They achieved about 95% accuracy when the baseline accuracy was 91% for magazines and introductory textbooks of science and technology. (Ito and Maruyama, 1992) used part of speech bigram model and beam search in order to get multiple candidates in their interactive OCR corrector. They achieved 94.61% accuracy when the baseline accuracy was 87.46% for patents in electric engineering. We used word bigram model, a statistical word model for unknown words, and a statistical OCR model. We achieved 97.4% accuracy, when the baseline accuracy was 90% and the domain was not limited. It is very difficult to compare our results with the previous results because the experiment conditions are completely different. However, considering the fact that we did not re</context>
</contexts>
<marker>Ito, Maruyama, 1992</marker>
<rawString>Nobuyasu Ito and Hiroshi Maruyama. 1992. A method of detecting and correcting errors in the results of japanese ocr. Transaction of Information Processing Society of Japan, 33(5):664-670. (In Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Kukich</author>
</authors>
<title>Techniques for automatically correcting words in text.</title>
<date>1992</date>
<journal>ACM Computing Surveys,</journal>
<pages>24--4</pages>
<contexts>
<context position="1739" citStr="Kukich, 1992" startWordPosition="260" endWordPosition="261">racy of printed character OCR is about 98%, sources such as old books, poor quality photocopies, and faxes are still difficult to process and cause many errors. The accuracy of handwritten OCR is still about 90% (Hildebrandt and Liu, 1993), and it worsens dramatically when the input quality is poor. If NLP techniques could be used to boost the accuracy of handwriting and poor quality documents, we could enjoy a very large market for OCR related applications. OCR error correction can be thought of a spelling correction problem. Although spelling correction has been studied for several decades (Kukich, 1992), the traditional techniques are implicitly based on English and cannot be used for Asian languages such as Japanese and Chinese. The traditional strategy for English spelling correction is called isolated word error correction: Word boundaries are placed by white spaces. If the tokenized string is not in the dictionary, it is a nonword. For a non-word, correction candidates are retrieved from the dictionary by approximate string match techniques using context-independent word distance measures such as edit distance (Wagner and Fischer, 1974) and ngram distance (Angell et al., 1983). Recently,</context>
</contexts>
<marker>Kukich, 1992</marker>
<rawString>Karen Kukich. 1992. Techniques for automatically correcting words in text. ACM Computing Surveys, 24(4):377-439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoseph Linde</author>
<author>Andres Buzo</author>
<author>Robert M Gray</author>
</authors>
<title>An algorithm for vector quantizer design.</title>
<date>1980</date>
<journal>IEEE Transactions on Communications,</journal>
<pages>28--1</pages>
<contexts>
<context position="10884" citStr="Linde et al., 1980" startWordPosition="1751" endWordPosition="1754">hed by comparing the feature vector corresponding to the input character with the representatives of each character, using a distance metric. Therefore, if we cluster feature vectors of each character, the members of the resulting class are characters with similar shape, and so tend to cause confusion. The feature we used in the clustering experiment is PDC (Peripheral Direction Contributivity) (Hagita et al., 1983), which is one of the best features for Japanese character recognition 2. We clustered the feature vectors for 3021 Japanese characters into 128 classes by using the LBG algorithm (Linde et al., 1980), which is one of the most popular vector quantization methods. Let&apos;s go back to the previous example of estimating P(RIM). After character clustering, `M&apos; and `a&apos; are clustered into class 29 and 119, respectively. class 29 (including gR): RXXAM/tgg.&apos;4e.a:SIS ti 41 class 119 (including *): 4AAAiVtgataiRIRI**#5 ttk tc tit tI2 Here is the excerpt of the class confusion matrix for class 29. input class 29: 29/30884 87/23 33/21 59/20 15/9 119/7 94/6 78/6 28/5 2/4 109/4 101/4 71/4 104/3 107/3 21/3 58/3 70/2 113/2 56/2 0/2 34/2 38/2 26/2 18/2 44/1 72/1 50/1 30/1 102/1 19/1 89/1 110/1 4/1 122/1 123/1</context>
</contexts>
<marker>Linde, Buzo, Gray, 1980</marker>
<rawString>Yoseph Linde, Andres Buzo, and Robert M. Gray. 1980. An algorithm for vector quantizer design. IEEE Transactions on Communications, COM-28(1):84-95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Mays</author>
<author>Fred J Damerau</author>
<author>Robert L Mercer</author>
</authors>
<title>Context based spelling correction.</title>
<date>1991</date>
<booktitle>Information Processing &amp; Management,</booktitle>
<pages>27--5</pages>
<contexts>
<context position="2568" citStr="Mays et al., 1991" startWordPosition="386" endWordPosition="389">rror correction: Word boundaries are placed by white spaces. If the tokenized string is not in the dictionary, it is a nonword. For a non-word, correction candidates are retrieved from the dictionary by approximate string match techniques using context-independent word distance measures such as edit distance (Wagner and Fischer, 1974) and ngram distance (Angell et al., 1983). Recently, statistical language models and featurebased method have been used for context-sensitive spelling correction, where errors are corrected considering the context in which the error occurs (Church and Gale, 1991; Mays et al., 1991; Golding and Schabes, 1996). Similar techniques are used for correcting the output of English OCRs (Tong and Evans, 1996) and English speech recognizers (Ringger and Allen, 1996). There are two problems in Japanese (and Chinese) spelling correction. The first is the word boundary problem. It is impossible to use isolated word error correction techniques because there are no delimiters between words. The second is the short word problem. Word distance measures are useless because the average word length is short (&lt; 2), and the character set is large (&gt; 3000). There are a much larger number of </context>
</contexts>
<marker>Mays, Damerau, Mercer, 1991</marker>
<rawString>Eric Mays, Fred J. Damerau, and Robert L. Mercer. 1991. Context based spelling correction. Information Processing &amp; Management, 27(5):517-522.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masaaki Nagata</author>
</authors>
<title>Context-based spelling correction for japanese ocr. In</title>
<date>1996</date>
<booktitle>COLING-96,</booktitle>
<pages>806--811</pages>
<contexts>
<context position="3514" citStr="Nagata, 1996" startWordPosition="539" endWordPosition="540">r correction techniques because there are no delimiters between words. The second is the short word problem. Word distance measures are useless because the average word length is short (&lt; 2), and the character set is large (&gt; 3000). There are a much larger number of one edit distance neighbors for a word, compared with English. Recently, the first problem was solved by selecting the most likely word sequence from all combinations of exactly and approximately matched words using a Viterbi-like word segmentation algorithm and a statistical language model considering unknown words and non-words (Nagata, 1996). However, the second problem is not solved yet, at least elegantly. The solution presented in (Nagata, 1996) which sorts a list of one edit distance words considering the context in which it will be placed is inaccurate because the context itself might include some errors. In this paper, we present a context-independent approximate word match method using character shape similarity. This is suitable for languages with large character sets, such as Japanese and Chinese. We also present a method to build a statistical OCR model by smoothing the character confusion probability using character sh</context>
<context position="13108" citStr="Nagata, 1996" startWordPosition="2125" endWordPosition="2126">ure vector is 8*3*4*16=1536. By using 2-stage feature selection, it can be reduced to 256, while still preserving the original recognition ability. 924 Using the language model (9), the OCR error correction task can be defined as finding a word sequence W that maximizes the joint probability of word sequence given recognized character sequence P(WIX). By using Bayes&apos; rule, this amounts to maximizing the product of P(XIW) and P(W). = arg mvax P(W IX) = arg P(XIW)P(W) (10) The maximization search can be efficiently implemented by using the Viterbi-like dynamic programing procedure described in (Nagata, 1996). The algorithm starts from the beginning of the input sentence, and proceeds character by character. At each point in the sentence, it looks up the combination of the best partial word segmentation hypothesis ending there and all word hypotheses starting there. The word hypotheses proposed at each point include both exactly matched words and approximately matched words. All prefixes of the substring starting at the point are also proposed as unknown words if they are not in the dictionary. 3.2 Word Model for Unknown Words We defined a statistical word model to assign a reasonable word probabi</context>
<context position="20440" citStr="Nagata, 1996" startWordPosition="3361" endWordPosition="3362">ccuracies. We selected 100 sentences from the remaining 10% of the EDR corpus for testing. The second column of Table 1 shows the number of sentences, words, and characters of the test set. By using an OCR simulator, we made four sets of character matrices whose first-rank recognition accuracies were 70%, 80%, 90%, and 95%. They contained at most 10 candidates for each character and their cumulative recognition accuracies were 90%, 95%, 98%, and 98%, respectively. For comparison, we implemented the OCR error correction method, which does not use character similarity information, presented in (Nagata, 1996). Instead of using character confusion matrix, he approximated it by the correct character distribution over the rank of the candidates 3. We refer to his method as the candidate rank method, and our method as the character similarity method. Figure 1 shows the recognition accuracies after error correction for various baseline OCR accuracies. The horizontal axis represents the accuracies of the baseline OCR, while the vertical axis represents the accuracies after error correction. The farther the point lies above the diagonal line, the more improvements are brought by the OCR error corrector. </context>
<context position="22800" citStr="Nagata, 1996" startWordPosition="3747" endWordPosition="3748">ere taken from the same corpus. Moreover, since the OCR simulator and the OCR error corrector used the same character confusion matrix, the input character matrices were closed data with respect to OCR. We selected 30 documents, each of which contained about 1000 characters. These documents had nothing to do with the EDR corpus. Ten of them were newspapers and the other 20 documents were a miscellaneous collection of novels, essays, patents, laws, scientific papers, etc.. Table 2 shows the breakdown of document type and image resolution. Newspapers were scanned at 300dpi and 400dpi, two of 4 (Nagata, 1996) reported that, when the baseline accuracy is 90%, his method achieved 96.3%. The difference between 96.3% and 93.9% comes from the difference in the corpora. He tested the ATR corpus whose word perplexity is about 30, while we tested the EDR corpus whose perplexity is about 95. Here, perplexities are computed using word bigram model. Table 2: The document type and the image resolution of the test data for the printed character OCR 200dpi 300dpi 400dpi newspapers 0 8 10 miscellaneous 20 20 10 them, scanned at 300dpi, were discarded because of low quality. Other miscellaneous documents were mai</context>
</contexts>
<marker>Nagata, 1996</marker>
<rawString>Masaaki Nagata. 1996. Context-based spelling correction for japanese ocr. In COLING-96, pages 806-811.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric K Ringger</author>
<author>James F Allen</author>
</authors>
<title>A fertility channel model for post-correction of continuous speech recognition.</title>
<date>1996</date>
<booktitle>In ICSLP-96,</booktitle>
<pages>897--900</pages>
<contexts>
<context position="2747" citStr="Ringger and Allen, 1996" startWordPosition="413" endWordPosition="417">trieved from the dictionary by approximate string match techniques using context-independent word distance measures such as edit distance (Wagner and Fischer, 1974) and ngram distance (Angell et al., 1983). Recently, statistical language models and featurebased method have been used for context-sensitive spelling correction, where errors are corrected considering the context in which the error occurs (Church and Gale, 1991; Mays et al., 1991; Golding and Schabes, 1996). Similar techniques are used for correcting the output of English OCRs (Tong and Evans, 1996) and English speech recognizers (Ringger and Allen, 1996). There are two problems in Japanese (and Chinese) spelling correction. The first is the word boundary problem. It is impossible to use isolated word error correction techniques because there are no delimiters between words. The second is the short word problem. Word distance measures are useless because the average word length is short (&lt; 2), and the character set is large (&gt; 3000). There are a much larger number of one edit distance neighbors for a word, compared with English. Recently, the first problem was solved by selecting the most likely word sequence from all combinations of exactly a</context>
</contexts>
<marker>Ringger, Allen, 1996</marker>
<rawString>Eric K. Ringger and James F. Allen. 1996. A fertility channel model for post-correction of continuous speech recognition. In ICSLP-96, pages 897-900.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tetsuyasu Takao</author>
<author>Fumihito Nishino</author>
</authors>
<title>Implementation and evaluation of post-processing for japanese document readers.</title>
<date>1989</date>
<journal>Transaction of Information Processing Society of Japan,</journal>
<pages>30--11</pages>
<note>(In Japanese).</note>
<contexts>
<context position="26437" citStr="Takao and Nishino, 1989" startWordPosition="4355" endWordPosition="4358"> The score of the printed character OCR ranges from 0 to 100, where 100 means it is pretty sure about the output. If we reject the corrections suggested by the error corrector when the OCR score is more than 80, the number of wrong corrections is reduced from 281 to 48, while that of right correction is reduced from 294 to 199. Thus, the number of net improvements increases from 13 to 151, which means a 10.6% (151/1422) reduction in replacement errors. 6 Discussion Most previous works on Japanese OCR error correction considered only printed character OCRs and their target domain was limited. (Takao and Nishino, 1989) used part of speech bigram model and heuristic templates for unknown words. They achieved about 95% accuracy when the baseline accuracy was 91% for magazines and introductory textbooks of science and technology. (Ito and Maruyama, 1992) used part of speech bigram model and beam search in order to get multiple candidates in their interactive OCR corrector. They achieved 94.61% accuracy when the baseline accuracy was 87.46% for patents in electric engineering. We used word bigram model, a statistical word model for unknown words, and a statistical OCR model. We achieved 97.4% accuracy, when the</context>
</contexts>
<marker>Takao, Nishino, 1989</marker>
<rawString>Tetsuyasu Takao and Fumihito Nishino. 1989. Implementation and evaluation of post-processing for japanese document readers. Transaction of Information Processing Society of Japan, 30(11):1394-1401. (In Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiang Tong</author>
<author>David A Evans</author>
</authors>
<title>A statistical approach to automatic ocr error correction in context. In</title>
<date>1996</date>
<booktitle>WVLC-96,</booktitle>
<pages>88--10</pages>
<contexts>
<context position="2690" citStr="Tong and Evans, 1996" startWordPosition="405" endWordPosition="408"> nonword. For a non-word, correction candidates are retrieved from the dictionary by approximate string match techniques using context-independent word distance measures such as edit distance (Wagner and Fischer, 1974) and ngram distance (Angell et al., 1983). Recently, statistical language models and featurebased method have been used for context-sensitive spelling correction, where errors are corrected considering the context in which the error occurs (Church and Gale, 1991; Mays et al., 1991; Golding and Schabes, 1996). Similar techniques are used for correcting the output of English OCRs (Tong and Evans, 1996) and English speech recognizers (Ringger and Allen, 1996). There are two problems in Japanese (and Chinese) spelling correction. The first is the word boundary problem. It is impossible to use isolated word error correction techniques because there are no delimiters between words. The second is the short word problem. Word distance measures are useless because the average word length is short (&lt; 2), and the character set is large (&gt; 3000). There are a much larger number of one edit distance neighbors for a word, compared with English. Recently, the first problem was solved by selecting the mos</context>
</contexts>
<marker>Tong, Evans, 1996</marker>
<rawString>Xiang Tong and David A. Evans. 1996. A statistical approach to automatic ocr error correction in context. In WVLC-96, pages 88-10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert A Wagner</author>
<author>Michael J Fischer</author>
</authors>
<title>The string-to-string correction problem.</title>
<date>1974</date>
<journal>Journal of the ACM,</journal>
<pages>21--1</pages>
<contexts>
<context position="2287" citStr="Wagner and Fischer, 1974" startWordPosition="343" endWordPosition="346">hough spelling correction has been studied for several decades (Kukich, 1992), the traditional techniques are implicitly based on English and cannot be used for Asian languages such as Japanese and Chinese. The traditional strategy for English spelling correction is called isolated word error correction: Word boundaries are placed by white spaces. If the tokenized string is not in the dictionary, it is a nonword. For a non-word, correction candidates are retrieved from the dictionary by approximate string match techniques using context-independent word distance measures such as edit distance (Wagner and Fischer, 1974) and ngram distance (Angell et al., 1983). Recently, statistical language models and featurebased method have been used for context-sensitive spelling correction, where errors are corrected considering the context in which the error occurs (Church and Gale, 1991; Mays et al., 1991; Golding and Schabes, 1996). Similar techniques are used for correcting the output of English OCRs (Tong and Evans, 1996) and English speech recognizers (Ringger and Allen, 1996). There are two problems in Japanese (and Chinese) spelling correction. The first is the word boundary problem. It is impossible to use isol</context>
<context position="15301" citStr="Wagner and Fischer, 1974" startWordPosition="2491" endWordPosition="2494">d boundary marker. 4 Approximate Word Matching Since there are no delimiters between words in Japanese, we have to hypothesize all substrings in the input sentence as words, and retrieve their approximately matching words from the dictionary as correction candidates. The most likely correction candidate is selected by the word segmentation algorithm using the OCR model and the language model. For simplicity, we will present the method as if it were for an isolated word error correction. In English spelling correction, correction candidates are generated by the minimum edit distance technique (Wagner and Fischer, 1974). Edit distance is the minimum number of editing operations (insertions, deletions, and substitutions) required to transform one string into another. Since the target is OCR output, we can restrict the type of errors to substitutions only. Thus, the edit distance of two words becomes cln, where c is the number of matched characters and n is the length of the misspelled (and the dictionary) word. Since the cost of computing the edit distance between a string and all dictionary words is expensive, we create an inverted index into the dictionary using character bigrams as the access keys (Angell </context>
</contexts>
<marker>Wagner, Fischer, 1974</marker>
<rawString>Robert A. Wagner and Michael J. Fischer. 1974. The string-to-string correction problem. Journal of the ACM, 21(1):168-173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Timothy C Bell</author>
</authors>
<title>The zero-frequency problem: Estimating the probabilities of novel events in adaptive text compression.</title>
<date>1991</date>
<journal>IEEE Transaction on Information Theory,</journal>
<pages>37--4</pages>
<contexts>
<context position="7018" citStr="Witten and Bell, 1991" startWordPosition="1120" endWordPosition="1123"> many areas such as speech recognition, statistical language modeling and text compression, no previous work has examined on the smoothing of the character confusion probabilities. This is probably because the problem arises only when we consider OCR error correction of languages with large character sets. We propose a novel method to smooth the character confusion probabilities. First, we estimate the sum of the probabilities of novel events. We then distribute the probability mass to each novel event based on character similarity. We use a scheme, which we refer to as the WittenBell method (Witten and Bell, 1991), to estimate the sum of the probabilities for all novel events because it is simple and robust 1. Let C(ci, c; ) be the frequency of events where ci and cl are the input and the output characters, respectively. Let 13(c2) be the sum of the probabilities of unseen output characters where the input character is c2. By using the Witten-Bell method, /3(c,.) is estimated as, 0(ci)= E P(cc) c,:c(c„ c, ).0 E3 CO(C(Ci, Cin (4) where f 1 if x &gt; 0 e(x) = 1 0 otherwise In the above example, V&apos; appears 1291(= 1289+1+ 1) times as input and there are three distinct characters in the output. Therefore, the </context>
</contexts>
<marker>Witten, Bell, 1991</marker>
<rawString>Ian H. Witten and Timothy C. Bell. 1991. The zero-frequency problem: Estimating the probabilities of novel events in adaptive text compression. IEEE Transaction on Information Theory, 37(4):1085-1094.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>