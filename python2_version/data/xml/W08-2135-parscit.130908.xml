<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000325">
<title confidence="0.9975115">
The Integration of Dependency Relation Classification and Semantic Role
Labeling Using Bilayer Maximum Entropy Markov Models
</title>
<author confidence="0.996783">
Weiwei Sun and Hongzhan Li and Zhifang Sui
</author>
<affiliation confidence="0.99853">
Institute of Computational Linguistics
Peking University
</affiliation>
<email confidence="0.992556">
{weiwsun, lihongzhan.pku}@gmail.com, szf@pku.edu.cn
</email>
<sectionHeader confidence="0.993853" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998276875">
This paper describes a system to solve
the joint learning of syntactic and seman-
tic dependencies. An directed graphical
model is put forward to integrate depen-
dency relation classification and semantic
role labeling. We present a bilayer di-
rected graph to express probabilistic re-
lationships between syntactic and seman-
tic relations. Maximum Entropy Markov
Models are implemented to estimate con-
ditional probability distribution and to do
inference. The submitted model yields
76.28% macro-average F1 performance,
for the joint task, 85.75% syntactic depen-
dencies LAS and 66.61% semantic depen-
dencies F1.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.939066277777778">
Dependency parsing and semantic role labeling are
becoming important components in many kinds of
NLP applications. Given a sentence, the task of de-
pendency parsing is to identify the syntactic head
of each word in the sentence and classify the rela-
tion between the dependent and its head; the task
of semantic role labeling consists of analyzing the
propositions expressed by some target predicates.
The integration of syntactic and semantic parsing
interests many researchers and some approaches
has been proposed (Yi and Palmer, 2005; Ge and
Mooney, 2005). CoNLL 2008 shared task pro-
poses the merging of both syntactic dependencies
and semantic dependencies under a unique unified
representation (Surdeanu et al., 2008). We explore
© 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
the integration problem and evaluate our approach
using data provided on CoNLL 2008.
This paper explores the integration of depen-
dency relation classification and semantic role la-
beling, using a directed graphical model that is also
known as Bayesian Networks. The directed graph
of our system can be seen as one chain of obser-
vations with two label layers: the observations are
argument candidates; one layer’s label set is syn-
tactic dependency relations; the other’s is semantic
dependency relations. To estimate the probability
distribution of each arc and do inference, we im-
plement a Maximum Entropy Markov Model (Mc-
Callum et al., 2000). Specially, a logistic regres-
sion model is used to get the conditional probabil-
ity of each arc; dynamic programming algorithm
is applied to solve the ”argmax” problem.
</bodyText>
<sectionHeader confidence="0.967527" genericHeader="method">
2 System Description
</sectionHeader>
<bodyText confidence="0.894679">
Our DP-SRL system consists of 5 stages:
</bodyText>
<listItem confidence="0.9995">
1. dependency parsing;
2. predicate prediction;
3. syntactic dependency relation classification
and semantic dependency relation identifica-
tion;
4. semantic dependency relation classification;
5. semantic dependency relation inference.
</listItem>
<subsectionHeader confidence="0.917936">
2.1 Dependency Parsing
</subsectionHeader>
<bodyText confidence="0.81480475">
In dependency parsing stage, MSTParser1 (Mc-
Donald et al., 2005), a dependency parser that
searches for maximum spanning trees over di-
rected graphs, is used. we use MSTParser’s default
</bodyText>
<footnote confidence="0.995826">
1http://www.seas.upenn.edu/ strctlrn/MSTParser/MSTParser.html
</footnote>
<page confidence="0.972432">
243
</page>
<table confidence="0.3896223">
CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 243–247
Manchester, August 2008
Lemma and its POS tag
Number of children
Sequential POS tags of children
Lemma and POS of Neighboring words
Lemma and POS of parent
Is the word in word list of NomBank
Is the word in word list of PropBank
Is POS of the word is VB* or NN*
</table>
<tableCaption confidence="0.997078">
Table 1: Features used to predict target predicates
</tableCaption>
<bodyText confidence="0.992354">
parameters to train a parsing model. In the third
stage of our system, dependency relations between
argument candidates and target predicates are up-
dated, if there are dependency between the candi-
dates and the predicates.
</bodyText>
<subsectionHeader confidence="0.996362">
2.2 Predicate Prediction
</subsectionHeader>
<bodyText confidence="0.9998811">
Different from CoNLL-2005 shared task, the tar-
get predicates are not given as input. Our system
formulates the predicate predication problem as a
two-class classification problem using maximum
entropy classifier MaxEnt2 (Berger et al., 1996).
Table 1 lists features used. We use a empirical
threshold to filter words: if the ”being target” prob-
ability of a word is greater than 0.075, it is seen as
a target predicate. This strategy achieves a 79.96%
precision and a 98.62% recall.
</bodyText>
<subsectionHeader confidence="0.949569666666667">
2.3 Syntactic Dependency Relation
Classification and Semantic Dependency
Relation Identification
</subsectionHeader>
<bodyText confidence="0.999937875">
We integrate dependency parsing and semantic
role labeling to some extent in this stage. Some de-
pendency parsing systems prefer two-stage archi-
tecture: unlabeled parsing and dependency clas-
sification (Nivre et al., 2007). Previous semantic
role labeling approaches also prefer two-stage ar-
chitecture: argument identification and argument
classification. Our system does syntactic relations
classification and semantic relations identification
at the same time. Specially, using a pruning al-
gorithm, we collect a set of argument candidates;
then we classify dependency relations between ar-
gument candidates and the predicates and predict
whether a candidate is an argument. A directed
graphical model is used to represent the relations
between syntactic and semantic relations.
</bodyText>
<footnote confidence="0.56901">
2http://homepages.inf.ed.ac.uk/s0450736/maxent toolkit.h
tml
</footnote>
<bodyText confidence="0.985238681818182">
Lemma, POS tag voice of predicates
POS pattern of predicate’s children
Is the predicate from NomBank or PropBank
Predicate class. This information is extracted
form frame file of each predicate.
Position: whether the candidate is before or
after the predicate
Lemma and POS tag of the candidate
Lemma and POS of Neighboring words of the
candidate
Lemma and POS of sibling words of the
candidate
Length of the constituent headed by the
candidate
Lemma and POS of the left and right most
words of the constituent of the candidate
Punctuation before and after the candidate
POS path: the chain of POS from candidate to
predicate
Single Character POS path: each POS in a path
is clustered to a category defined by its
first character
</bodyText>
<table confidence="0.758165">
POS Pattern (string of POS tags) of all
candidates
Single Character POS Pattern of all candidates
</table>
<tableCaption confidence="0.989364">
Table 2: Features used for semantic role labeling
</tableCaption>
<subsectionHeader confidence="0.984102">
2.4 Semantic Dependency Relation
Classification
</subsectionHeader>
<bodyText confidence="0.999943071428572">
This stage assigns the final argument labels to the
argument candidates supplied from the previous
stage. A multi-class classifier is trained to classify
the types of the arguments supplied by the previous
stage. Table 2 lists the features used. It is clear that
the general type of features used here is strongly
based on previous work on the SRL task (Gildea
and Jurafsky, 2002; Pradhan et al., 2005; Xue and
Palmer, 2004). Different from CoNLL-2005, the
sense of predicates should be labeled as a part of
the task. Our system assigns 01 to all predicates.
This is a harsh tactic since it do not take the lin-
guistic meaning of the argument-structure into ac-
count.
</bodyText>
<subsectionHeader confidence="0.997179">
2.5 Semantic Dependency Relation Inference
</subsectionHeader>
<bodyText confidence="0.99981875">
The purpose of inference stage is to incorporate
some prior linguistic and structural knowledge,
such as ”each predicate takes at most one argument
of each type.” We use the inference process intro-
</bodyText>
<page confidence="0.990853">
244
</page>
<bodyText confidence="0.999563714285714">
duced by (Punyakanok et al., 2004; Koomen et al.,
2005). The process is modeled as an integer Lin-
ear Programming Problem (ILP). It takes the pre-
dicted probability over each type of the arguments
as inputs, and takes the optimal solution that max-
imizes the linear sum of the probability subject to
linguistic constraints as outputs. The constraints
are a subset of constraints raised by Koomen et al.
(2005) and encoded as following: 1) No overlap-
ping or embedding arguments; 2) No duplicate ar-
gument classes for A0-A5; 3) If there is an R-arg
argument, then there has to be an arg argument;
4) If there is a C-arg argument, there must be an
arg argument; moreover, the C-arg argument must
occur after arg; 5) Given the predicate, some argu-
ment types are illegal. The list of illegal argument
types is extracted from framefile.
The ILP process can improve SRL performance
on constituent-based parsing (Punyakanok et al.,
2004). In our experiment, it also works on
dependency-based parsing.
</bodyText>
<sectionHeader confidence="0.99792" genericHeader="method">
3 Bilayer Maximum Entropy Markov
Models
</sectionHeader>
<subsectionHeader confidence="0.999598">
3.1 Sequentialization
</subsectionHeader>
<bodyText confidence="0.999687730769231">
The sequentialization of a argument-structure is si-
miliar to the pruning algorithm raised by (Xue and
Palmer, 2004). Given a constituent-based parsing
tree, the recursive pruning process starts from a tar-
get predicate. It first collects the siblings of the
predicate; then it moves to the parent of the pred-
icate, and collects the siblings of the parent. In
addition, if a constituent is a prepositional phrase,
its children are also collected.
Our system uses a similar pruning algorithm to
filter out very unlikely argument candidates in a
dependency-based parsing tree. Given a depen-
dency parsing tree, the pruning process also starts
from a target predicate. It first collects the depen-
dents of the predicate; then it moves to the parent
of the predicate, and collects all the dependents
again. Note that, the predicate is also taken into
account. If the target predicate is a verb, the pro-
cess goes on recursively until it reaches the root.
The process of a noun target ends when it sees a
PMOD, NMOD, SBJ or OBJ dependency relation.
If a preposition is returned as a candidate, its child
is also collected. When the predicate is a verb, the
set of constituents headed by survivors of our prun-
ing algorithm is a superset of the set of survivors of
the previous pruning algorithm on the correspond-
</bodyText>
<figureCaption confidence="0.996201">
Figure 1: Directed graphical Model of The system
</figureCaption>
<bodyText confidence="0.999298384615385">
ing constituent-based parsing tree. This pruning
algorithm will recall 99.08% arguments of verbs,
and the candidates are 3.75 times of the real argu-
ments. If the stop relation such as PMOD of a noun
is not taken into account, the recall is 97.67% and
the candidates is 6.28 times of arguments. If the
harsh stop condition is implemented, the recall is
just 80.29%. Since the SRL performance of nouns
is very low, the harsh pruning algorithm works bet-
ter than the original one.
After pruning, our system sequentializes all ar-
gument candidates of the target predicate accord-
ing to their linear order in the given sentence.
</bodyText>
<subsectionHeader confidence="0.974486">
3.2 Graphical Model
</subsectionHeader>
<bodyText confidence="0.996589823529412">
Figure 1 is the directed graph of our system.
There is a chain of candidates x = (x0 =
BOS, x1, ..., xn) in the graph which are observa-
tions. There are two tag layers in the graph: the up
layer is information of semantic dependency rela-
tions; the down layer is information of syntactic
dependency relations.
Given x, denote the corresponding syntactic de-
pendency relations d = (d0 = BOS, d1, ..., dn)
and the corresponding semantic dependency rela-
tions s = (s0 = BOS, s1,..., sn). Our system
labels the syntactic and semantic relations accord-
ing to the conditional probability in argmax fla-
vor. Formally, labels the system assigned make
the score p(d, s|x) reaches its maximum. We de-
compose the probability p(d, s|x) according to the
directed graph modeled as following:
</bodyText>
<equation confidence="0.9961155">
p(d, s|x) = p(s1|s0, d1; x)p(d1|s0, d0; x) ···
p(si+1|si, di+1; x)p(di+1|si, di; x) ···
p(sn|sn−1, dn; x)p(dn|sn−1, dn−1; x)
n
= p(si|si−1, di; x)p(di|si−1, di−1; x)
i=1
</equation>
<page confidence="0.989617">
245
</page>
<table confidence="0.604390333333333">
Lemma, POS tag voice of predicates
POS pattern of predicate’s children
Lemma and POS tag of the candidate
Lemma and POS of Neighboring words of the
candidate
Lemma and POS of sibling words of the
candidate
Length of the constituent headed by the
candidate
Lemma and POS of the left and right most
words of the constituent of the candidate
Conjunction of lemma of candidates and
predicates; Conjunction of POS of candidates
and predicates
POS Pattern of all candidates
</table>
<tableCaption confidence="0.9879145">
Table 3: Features used to predict syntactic depen-
dency parsing
</tableCaption>
<subsectionHeader confidence="0.996351">
3.3 Probability Estimation
</subsectionHeader>
<bodyText confidence="0.999438428571429">
The system defines the conditional probability
p(si|si−1, di; x) and p(di|si−1, di−1; x) by using
the maximum entropy (Berger et al., 1996) frame-
work Denote the tag set of syntactic dependency
relations D and the tag set of semantic dependency
relations S. Formally, given a feature map φs and
a weight vector ws,
</bodyText>
<equation confidence="0.952369333333333">
exp{ws · φs(x, si, si−1, di)}
pws(si|si−1, di; x) =
Z.,si−1,di;ws
</equation>
<bodyText confidence="0.997958428571429">
where,
lists the features used to predict semantic depen-
dency relations, whereas table 3 lists the features
used to predict the syntactic dependency relations.
The features used for syntactic dependency rela-
tion classification are strongly based on previous
works (McDonald et al., 2006; Nakagawa, 2007).
We just integrate syntactic dependency Rela-
tion classification and semantic dependency rela-
tion here. If one combines identification and clas-
sification of semantic roles as one multi-class clas-
sification, the tag set of the second layer can be
substituted by the tag set of semantic roles plus a
NULL (”not an argument”) label.
</bodyText>
<subsectionHeader confidence="0.733618">
3.4 Inference
</subsectionHeader>
<bodyText confidence="0.999976428571429">
The ”argmax problem” in structured prediction is
not tractable in the general case. However, the bi-
layer graphical model presented in form sections
admits efficient search using dynamic program-
ming solution. Searching for the highest probabil-
ity of a graph depends on the factorization chosen.
According to the form of the global score
</bodyText>
<equation confidence="0.7867415">
n
p(d, s|x) = 11 p(si|si−1, di; x)p(di|si−1, di−1; x)
</equation>
<bodyText confidence="0.9999332">
, we define forward probabilities αt(s, d) to be the
probability of semantic relation being s and syn-
tactic relation being d at time t given observation
sequence up to time t. The recursive dynamic pro-
gramming step is
</bodyText>
<equation confidence="0.998197888888889">
EZ.,si−1,di;ws =
sES
E
αt+1(d,s) = arg max
dED,sES
d&apos;ED,s&apos;ES
p(si|si−1, di; x)p(di|si−1, di−1; x)
exp{ws · φs(x, s, si−1, di)}
αt(d�, s&apos;) ·
</equation>
<bodyText confidence="0.9917995">
Similarly, given a feature map φd and
a weight vector wd, (pwd(di) is short for
</bodyText>
<equation confidence="0.930148">
pwd(di|si−1, di−1; x)
pwd(di) =
Z.,si−1,di−1;wd
where,
EZ.,si−1,di−1;wd = exp{wd · φd(x, d, si−1, di−1)}
dED
</equation>
<bodyText confidence="0.999791833333333">
For different characteristic properties between
syntactic parsing and semantic parsing, different
feature maps are taken into account. Table 2
Finally, to compute the globally most proba-
ble assignment (ˆd,ˆs) = arg maxd,s p(d, s|x), a
Viterbi recursion works well.
</bodyText>
<sectionHeader confidence="0.999978" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999867375">
We trained our system using positive examples
extracted from all training data of CoNLL 2008
shared task. Table 4 shows the overall syntactic
parsing results obtained on the WSJ test set (Sec-
tion 23) and the Brown test set (Section ck/01-03).
Table 5 shows the overall semantic parsing results
obtained on the WSJ test set (Section 23) and the
Brown test set (Section ck/01-03).
</bodyText>
<equation confidence="0.419588">
exp{wd · φd(x, di, si−1, di−1)}
</equation>
<page confidence="0.904156">
246
</page>
<table confidence="0.997907666666667">
Test Set UAS LAS Label Accuracy
WSJ 89.25% 86.37% 91.25%
Brown 86.12% 80.75% 87.14%
</table>
<tableCaption confidence="0.973987">
Table 4: Overall syntactic parsing results
</tableCaption>
<table confidence="0.9999048">
Task Precision Recall Fβ=1
WSJ ID 73.76% 85.24% 79.08
ID&amp;CL 63.07% 72.88% 67.62
Brown ID 70.77% 80.50% 75.32
ID&amp;CL 54.74% 62.26% 58.26
</table>
<tableCaption confidence="0.975315">
Table 5: Overall semantic parsing results
</tableCaption>
<table confidence="0.999930666666667">
Test WSJ Precision(%) Recall(%) Fβ=1
SRL of Verbs
All 73.53 73.28 73.41
Core-Arg 78.83 76.93 77.87
AM-* 62.51 64.83 63.65
SRL of Nouns
All 62.06 45.49 52.50
Core-Arg 61.47 46.56 52.98
AM-* 66.19 39.93 49.81
</table>
<tableCaption confidence="0.980996">
Table 6: Semantic role labeling results on verbs
</tableCaption>
<bodyText confidence="0.907478166666667">
and nouns. Core-Arg means numbered argument.
Table 6 shows the detailed semantic parsing re-
sults obtained on the WSJ test set (Section 23)
of verbs and nouns respectively. The comparison
suggests that SRL on NomBank is much harder
than PropBank.
</bodyText>
<sectionHeader confidence="0.989622" genericHeader="conclusions">
Acknowlegements
</sectionHeader>
<bodyText confidence="0.999308833333333">
The work is supported by the National Natural
Science Foundation of China under Grants No.
60503071, 863 the National High Technology Re-
search and Development Program of China un-
der Grants No.2006AA01Z144, and the Project of
Toshiba (China) Co., Ltd. R&amp;D Center.
</bodyText>
<sectionHeader confidence="0.998612" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999460015151516">
Berger, Adam, Stephen Della Pietra, and Vincent Della
Pietra. 1996. A Maximum Entropy Approach to
Natural Language Processing. Computional Lin-
guistics, 22(1):39–71.
Ge, Ruifang and Raymond J. Mooney. 2005. A Statis-
tical Semantic Parser that Integrates Syntax and Se-
mantics. In Proceedings of the Conference of Com-
putational Natural Language Learning.
Gildea, Daniel and Daniel Jurafsky. 2002. Automatic
Labeling of Semantic Roles. Computional Linguis-
tics, 28(3):245–288.
Koomen, Peter, Vasina Punyakanok, Dan Roth, and
Wen-tau Yih. 2005. Generalized Inference with
Multiple Semantic Role Labeling Systems. In Pro-
ceedings of Conference on Natural Language Learn-
ing.
McCallum, Andrew, Dayne Freitag, and Fernando
Pereira. 2000. Maximum Entropy Markov Mod-
els for Information Extraction and Segmentation.
In Proceedings of International Conference on Ma-
chine Learning.
McDonald, Ryan, Fernando Pereira, Kiril Ribarov, and
Jan Hajiˇc. 2005. Non-projective dependency pars-
ing using spanning tree algorithms. In Proceedings
of the conference on Human Language Technology
and Empirical Methods in Natural Language Pro-
cessing.
McDonald, Ryan, Kevin Lerman, and Fernando
Pereira. 2006. Multilingual Dependency Analysis
with a Two-Stage Discriminative Parser. In Proceed-
ings of Conference on Natural Language Learning.
Nakawa, Tetsuji. 2007. Multilingual Dependency
Parsing using Global Features. In Proceedings of
Conference on Natural Language Learning.
Nivre, Joakim, Johan Hall, Sandra K¨ubler, Ryan Mc-
Donald, Jens Nilsson, Sebastian Riedel, and Deniz
Yuret. The CoNLL 2007 Shared Task on Depen-
dency Parsing. 2007. In Proceedings of the CoNLL
Shared Task Session of EMNLP-CoNLL 2007,915-
932,
007,915-
932,
Pradhan, Sameer, Kadri Hacioglu, Valerie Krugler,
Wayne Ward, James Martin, and Daniel Jurafsky.
2005. Support Vector Learning for Semantic Argu-
ment Classification. In Proceedings of Conference
on Association for Computational Linguistics.
Punyakanok, Vasin , Dan Roth, Wen-tau Yih, and Dav
Zimak. 2004. Semantic Role Labeling via Integer
Linear Programming Inference. In Proceedings of
the 20th International Conference on Computational
Linguistics.
Surdeanu, Mihai, Richard Johansson, Adam Meyers,
Llu´ıs M`arquez, and Nivre, Joakim. 2008. The
CoNLL-2008 Shared Task on Joint Parsing of Syn-
tactic and Semantic Dependencies. In Proceedings
of the 12th Conference on Computational Natural
Language Learning (CoNLL-2008).
Xue, Nianwen and Martha Palmer. 2004. Calibrat-
ing Features for Semantic Role Labeling. In Pro-
ceedings of Empirical Methods in Natural Language
Processing.
Yi, Szu-ting and Martha Palmer. 2005. The Integra-
tion of Syntactic Parsing and Semantic Role Label-
ing. In Proceedings of the Conference of Computa-
tional Natural Language Learning.
</reference>
<page confidence="0.997961">
247
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.481743">
<title confidence="0.9926585">The Integration of Dependency Relation Classification and Semantic Role Labeling Using Bilayer Maximum Entropy Markov Models</title>
<author confidence="0.999535">Sun Li</author>
<affiliation confidence="0.99987">Institute of Computational</affiliation>
<address confidence="0.774683">Peking</address>
<email confidence="0.971654">szf@pku.edu.cn</email>
<abstract confidence="0.977239764705882">This paper describes a system to solve the joint learning of syntactic and semantic dependencies. An directed graphical model is put forward to integrate dependency relation classification and semantic role labeling. We present a bilayer directed graph to express probabilistic relationships between syntactic and semantic relations. Maximum Entropy Markov Models are implemented to estimate conditional probability distribution and to do inference. The submitted model yields 76.28% macro-average F1 performance, for the joint task, 85.75% syntactic dependencies LAS and 66.61% semantic dependencies F1.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Adam Berger</author>
<author>Stephen Della Pietra</author>
<author>Vincent Della Pietra</author>
</authors>
<title>A Maximum Entropy Approach to Natural Language Processing.</title>
<date>1996</date>
<journal>Computional Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="4105" citStr="Berger et al., 1996" startWordPosition="602" endWordPosition="605">f NomBank Is the word in word list of PropBank Is POS of the word is VB* or NN* Table 1: Features used to predict target predicates parameters to train a parsing model. In the third stage of our system, dependency relations between argument candidates and target predicates are updated, if there are dependency between the candidates and the predicates. 2.2 Predicate Prediction Different from CoNLL-2005 shared task, the target predicates are not given as input. Our system formulates the predicate predication problem as a two-class classification problem using maximum entropy classifier MaxEnt2 (Berger et al., 1996). Table 1 lists features used. We use a empirical threshold to filter words: if the ”being target” probability of a word is greater than 0.075, it is seen as a target predicate. This strategy achieves a 79.96% precision and a 98.62% recall. 2.3 Syntactic Dependency Relation Classification and Semantic Dependency Relation Identification We integrate dependency parsing and semantic role labeling to some extent in this stage. Some dependency parsing systems prefer two-stage architecture: unlabeled parsing and dependency classification (Nivre et al., 2007). Previous semantic role labeling approach</context>
<context position="11801" citStr="Berger et al., 1996" startWordPosition="1865" endWordPosition="1868">and POS tag of the candidate Lemma and POS of Neighboring words of the candidate Lemma and POS of sibling words of the candidate Length of the constituent headed by the candidate Lemma and POS of the left and right most words of the constituent of the candidate Conjunction of lemma of candidates and predicates; Conjunction of POS of candidates and predicates POS Pattern of all candidates Table 3: Features used to predict syntactic dependency parsing 3.3 Probability Estimation The system defines the conditional probability p(si|si−1, di; x) and p(di|si−1, di−1; x) by using the maximum entropy (Berger et al., 1996) framework Denote the tag set of syntactic dependency relations D and the tag set of semantic dependency relations S. Formally, given a feature map φs and a weight vector ws, exp{ws · φs(x, si, si−1, di)} pws(si|si−1, di; x) = Z.,si−1,di;ws where, lists the features used to predict semantic dependency relations, whereas table 3 lists the features used to predict the syntactic dependency relations. The features used for syntactic dependency relation classification are strongly based on previous works (McDonald et al., 2006; Nakagawa, 2007). We just integrate syntactic dependency Relation classi</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Berger, Adam, Stephen Della Pietra, and Vincent Della Pietra. 1996. A Maximum Entropy Approach to Natural Language Processing. Computional Linguistics, 22(1):39–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruifang Ge</author>
<author>Raymond J Mooney</author>
</authors>
<title>A Statistical Semantic Parser that Integrates Syntax and Semantics.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference of Computational Natural Language Learning.</booktitle>
<contexts>
<context position="1463" citStr="Ge and Mooney, 2005" startWordPosition="210" endWordPosition="213">encies LAS and 66.61% semantic dependencies F1. 1 Introduction Dependency parsing and semantic role labeling are becoming important components in many kinds of NLP applications. Given a sentence, the task of dependency parsing is to identify the syntactic head of each word in the sentence and classify the relation between the dependent and its head; the task of semantic role labeling consists of analyzing the propositions expressed by some target predicates. The integration of syntactic and semantic parsing interests many researchers and some approaches has been proposed (Yi and Palmer, 2005; Ge and Mooney, 2005). CoNLL 2008 shared task proposes the merging of both syntactic dependencies and semantic dependencies under a unique unified representation (Surdeanu et al., 2008). We explore © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. the integration problem and evaluate our approach using data provided on CoNLL 2008. This paper explores the integration of dependency relation classification and semantic role labeling, using a directed graphical model that is also known as Bay</context>
</contexts>
<marker>Ge, Mooney, 2005</marker>
<rawString>Ge, Ruifang and Raymond J. Mooney. 2005. A Statistical Semantic Parser that Integrates Syntax and Semantics. In Proceedings of the Conference of Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic Labeling of Semantic Roles.</title>
<date>2002</date>
<journal>Computional Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<contexts>
<context position="6586" citStr="Gildea and Jurafsky, 2002" startWordPosition="985" endWordPosition="988">ered to a category defined by its first character POS Pattern (string of POS tags) of all candidates Single Character POS Pattern of all candidates Table 2: Features used for semantic role labeling 2.4 Semantic Dependency Relation Classification This stage assigns the final argument labels to the argument candidates supplied from the previous stage. A multi-class classifier is trained to classify the types of the arguments supplied by the previous stage. Table 2 lists the features used. It is clear that the general type of features used here is strongly based on previous work on the SRL task (Gildea and Jurafsky, 2002; Pradhan et al., 2005; Xue and Palmer, 2004). Different from CoNLL-2005, the sense of predicates should be labeled as a part of the task. Our system assigns 01 to all predicates. This is a harsh tactic since it do not take the linguistic meaning of the argument-structure into account. 2.5 Semantic Dependency Relation Inference The purpose of inference stage is to incorporate some prior linguistic and structural knowledge, such as ”each predicate takes at most one argument of each type.” We use the inference process intro244 duced by (Punyakanok et al., 2004; Koomen et al., 2005). The process </context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Gildea, Daniel and Daniel Jurafsky. 2002. Automatic Labeling of Semantic Roles. Computional Linguistics, 28(3):245–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Koomen</author>
<author>Vasina Punyakanok</author>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
</authors>
<title>Generalized Inference with Multiple Semantic Role Labeling Systems.</title>
<date>2005</date>
<booktitle>In Proceedings of Conference on Natural Language Learning.</booktitle>
<contexts>
<context position="7172" citStr="Koomen et al., 2005" startWordPosition="1084" endWordPosition="1087">RL task (Gildea and Jurafsky, 2002; Pradhan et al., 2005; Xue and Palmer, 2004). Different from CoNLL-2005, the sense of predicates should be labeled as a part of the task. Our system assigns 01 to all predicates. This is a harsh tactic since it do not take the linguistic meaning of the argument-structure into account. 2.5 Semantic Dependency Relation Inference The purpose of inference stage is to incorporate some prior linguistic and structural knowledge, such as ”each predicate takes at most one argument of each type.” We use the inference process intro244 duced by (Punyakanok et al., 2004; Koomen et al., 2005). The process is modeled as an integer Linear Programming Problem (ILP). It takes the predicted probability over each type of the arguments as inputs, and takes the optimal solution that maximizes the linear sum of the probability subject to linguistic constraints as outputs. The constraints are a subset of constraints raised by Koomen et al. (2005) and encoded as following: 1) No overlapping or embedding arguments; 2) No duplicate argument classes for A0-A5; 3) If there is an R-arg argument, then there has to be an arg argument; 4) If there is a C-arg argument, there must be an arg argument; </context>
</contexts>
<marker>Koomen, Punyakanok, Roth, Yih, 2005</marker>
<rawString>Koomen, Peter, Vasina Punyakanok, Dan Roth, and Wen-tau Yih. 2005. Generalized Inference with Multiple Semantic Role Labeling Systems. In Proceedings of Conference on Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
<author>Dayne Freitag</author>
<author>Fernando Pereira</author>
</authors>
<title>Maximum Entropy Markov Models for Information Extraction and Segmentation.</title>
<date>2000</date>
<booktitle>In Proceedings of International Conference on Machine Learning.</booktitle>
<contexts>
<context position="2459" citStr="McCallum et al., 2000" startWordPosition="355" endWordPosition="359">blem and evaluate our approach using data provided on CoNLL 2008. This paper explores the integration of dependency relation classification and semantic role labeling, using a directed graphical model that is also known as Bayesian Networks. The directed graph of our system can be seen as one chain of observations with two label layers: the observations are argument candidates; one layer’s label set is syntactic dependency relations; the other’s is semantic dependency relations. To estimate the probability distribution of each arc and do inference, we implement a Maximum Entropy Markov Model (McCallum et al., 2000). Specially, a logistic regression model is used to get the conditional probability of each arc; dynamic programming algorithm is applied to solve the ”argmax” problem. 2 System Description Our DP-SRL system consists of 5 stages: 1. dependency parsing; 2. predicate prediction; 3. syntactic dependency relation classification and semantic dependency relation identification; 4. semantic dependency relation classification; 5. semantic dependency relation inference. 2.1 Dependency Parsing In dependency parsing stage, MSTParser1 (McDonald et al., 2005), a dependency parser that searches for maximum </context>
</contexts>
<marker>McCallum, Freitag, Pereira, 2000</marker>
<rawString>McCallum, Andrew, Dayne Freitag, and Fernando Pereira. 2000. Maximum Entropy Markov Models for Information Extraction and Segmentation. In Proceedings of International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajiˇc</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing.</booktitle>
<marker>McDonald, Pereira, Ribarov, Hajiˇc, 2005</marker>
<rawString>McDonald, Ryan, Fernando Pereira, Kiril Ribarov, and Jan Hajiˇc. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Kevin Lerman</author>
<author>Fernando Pereira</author>
</authors>
<title>Multilingual Dependency Analysis with a Two-Stage Discriminative Parser.</title>
<date>2006</date>
<booktitle>In Proceedings of Conference on Natural Language Learning.</booktitle>
<contexts>
<context position="12328" citStr="McDonald et al., 2006" startWordPosition="1950" endWordPosition="1953">y p(si|si−1, di; x) and p(di|si−1, di−1; x) by using the maximum entropy (Berger et al., 1996) framework Denote the tag set of syntactic dependency relations D and the tag set of semantic dependency relations S. Formally, given a feature map φs and a weight vector ws, exp{ws · φs(x, si, si−1, di)} pws(si|si−1, di; x) = Z.,si−1,di;ws where, lists the features used to predict semantic dependency relations, whereas table 3 lists the features used to predict the syntactic dependency relations. The features used for syntactic dependency relation classification are strongly based on previous works (McDonald et al., 2006; Nakagawa, 2007). We just integrate syntactic dependency Relation classification and semantic dependency relation here. If one combines identification and classification of semantic roles as one multi-class classification, the tag set of the second layer can be substituted by the tag set of semantic roles plus a NULL (”not an argument”) label. 3.4 Inference The ”argmax problem” in structured prediction is not tractable in the general case. However, the bilayer graphical model presented in form sections admits efficient search using dynamic programming solution. Searching for the highest proba</context>
</contexts>
<marker>McDonald, Lerman, Pereira, 2006</marker>
<rawString>McDonald, Ryan, Kevin Lerman, and Fernando Pereira. 2006. Multilingual Dependency Analysis with a Two-Stage Discriminative Parser. In Proceedings of Conference on Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tetsuji Nakawa</author>
</authors>
<title>Multilingual Dependency Parsing using Global Features.</title>
<date>2007</date>
<booktitle>In Proceedings of Conference on Natural Language Learning.</booktitle>
<marker>Nakawa, 2007</marker>
<rawString>Nakawa, Tetsuji. 2007. Multilingual Dependency Parsing using Global Features. In Proceedings of Conference on Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<title>The CoNLL</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL</booktitle>
<pages>2007--915</pages>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Nivre, Joakim, Johan Hall, Sandra K¨ubler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret. The CoNLL 2007 Shared Task on Dependency Parsing. 2007. In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007,915-932,</rawString>
</citation>
<citation valid="false">
<pages>007--915</pages>
<marker></marker>
<rawString>007,915-932,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Kadri Hacioglu</author>
<author>Valerie Krugler</author>
<author>Wayne Ward</author>
<author>James Martin</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Support Vector Learning for Semantic Argument Classification.</title>
<date>2005</date>
<booktitle>In Proceedings of Conference on Association for Computational Linguistics.</booktitle>
<contexts>
<context position="6608" citStr="Pradhan et al., 2005" startWordPosition="989" endWordPosition="992">by its first character POS Pattern (string of POS tags) of all candidates Single Character POS Pattern of all candidates Table 2: Features used for semantic role labeling 2.4 Semantic Dependency Relation Classification This stage assigns the final argument labels to the argument candidates supplied from the previous stage. A multi-class classifier is trained to classify the types of the arguments supplied by the previous stage. Table 2 lists the features used. It is clear that the general type of features used here is strongly based on previous work on the SRL task (Gildea and Jurafsky, 2002; Pradhan et al., 2005; Xue and Palmer, 2004). Different from CoNLL-2005, the sense of predicates should be labeled as a part of the task. Our system assigns 01 to all predicates. This is a harsh tactic since it do not take the linguistic meaning of the argument-structure into account. 2.5 Semantic Dependency Relation Inference The purpose of inference stage is to incorporate some prior linguistic and structural knowledge, such as ”each predicate takes at most one argument of each type.” We use the inference process intro244 duced by (Punyakanok et al., 2004; Koomen et al., 2005). The process is modeled as an integ</context>
</contexts>
<marker>Pradhan, Hacioglu, Krugler, Ward, Martin, Jurafsky, 2005</marker>
<rawString>Pradhan, Sameer, Kadri Hacioglu, Valerie Krugler, Wayne Ward, James Martin, and Daniel Jurafsky. 2005. Support Vector Learning for Semantic Argument Classification. In Proceedings of Conference on Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
<author>Dav Zimak</author>
</authors>
<title>Semantic Role Labeling via Integer Linear Programming Inference.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics.</booktitle>
<marker>Roth, Yih, Zimak, 2004</marker>
<rawString>Punyakanok, Vasin , Dan Roth, Wen-tau Yih, and Dav Zimak. 2004. Semantic Role Labeling via Integer Linear Programming Inference. In Proceedings of the 20th International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Richard Johansson</author>
<author>Adam Meyers</author>
<author>Llu´ıs M`arquez</author>
<author>Joakim Nivre</author>
</authors>
<date>2008</date>
<booktitle>The CoNLL-2008 Shared Task on Joint Parsing of Syntactic and Semantic Dependencies. In Proceedings of the 12th Conference on Computational Natural Language Learning (CoNLL-2008).</booktitle>
<marker>Surdeanu, Johansson, Meyers, M`arquez, Nivre, 2008</marker>
<rawString>Surdeanu, Mihai, Richard Johansson, Adam Meyers, Llu´ıs M`arquez, and Nivre, Joakim. 2008. The CoNLL-2008 Shared Task on Joint Parsing of Syntactic and Semantic Dependencies. In Proceedings of the 12th Conference on Computational Natural Language Learning (CoNLL-2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Martha Palmer</author>
</authors>
<title>Calibrating Features for Semantic Role Labeling.</title>
<date>2004</date>
<booktitle>In Proceedings of Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="6631" citStr="Xue and Palmer, 2004" startWordPosition="993" endWordPosition="996"> POS Pattern (string of POS tags) of all candidates Single Character POS Pattern of all candidates Table 2: Features used for semantic role labeling 2.4 Semantic Dependency Relation Classification This stage assigns the final argument labels to the argument candidates supplied from the previous stage. A multi-class classifier is trained to classify the types of the arguments supplied by the previous stage. Table 2 lists the features used. It is clear that the general type of features used here is strongly based on previous work on the SRL task (Gildea and Jurafsky, 2002; Pradhan et al., 2005; Xue and Palmer, 2004). Different from CoNLL-2005, the sense of predicates should be labeled as a part of the task. Our system assigns 01 to all predicates. This is a harsh tactic since it do not take the linguistic meaning of the argument-structure into account. 2.5 Semantic Dependency Relation Inference The purpose of inference stage is to incorporate some prior linguistic and structural knowledge, such as ”each predicate takes at most one argument of each type.” We use the inference process intro244 duced by (Punyakanok et al., 2004; Koomen et al., 2005). The process is modeled as an integer Linear Programming P</context>
<context position="8283" citStr="Xue and Palmer, 2004" startWordPosition="1267" endWordPosition="1270">gument, then there has to be an arg argument; 4) If there is a C-arg argument, there must be an arg argument; moreover, the C-arg argument must occur after arg; 5) Given the predicate, some argument types are illegal. The list of illegal argument types is extracted from framefile. The ILP process can improve SRL performance on constituent-based parsing (Punyakanok et al., 2004). In our experiment, it also works on dependency-based parsing. 3 Bilayer Maximum Entropy Markov Models 3.1 Sequentialization The sequentialization of a argument-structure is similiar to the pruning algorithm raised by (Xue and Palmer, 2004). Given a constituent-based parsing tree, the recursive pruning process starts from a target predicate. It first collects the siblings of the predicate; then it moves to the parent of the predicate, and collects the siblings of the parent. In addition, if a constituent is a prepositional phrase, its children are also collected. Our system uses a similar pruning algorithm to filter out very unlikely argument candidates in a dependency-based parsing tree. Given a dependency parsing tree, the pruning process also starts from a target predicate. It first collects the dependents of the predicate; t</context>
</contexts>
<marker>Xue, Palmer, 2004</marker>
<rawString>Xue, Nianwen and Martha Palmer. 2004. Calibrating Features for Semantic Role Labeling. In Proceedings of Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Szu-ting Yi</author>
<author>Martha Palmer</author>
</authors>
<title>The Integration of Syntactic Parsing and Semantic Role Labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference of Computational Natural Language Learning.</booktitle>
<contexts>
<context position="1441" citStr="Yi and Palmer, 2005" startWordPosition="206" endWordPosition="209">.75% syntactic dependencies LAS and 66.61% semantic dependencies F1. 1 Introduction Dependency parsing and semantic role labeling are becoming important components in many kinds of NLP applications. Given a sentence, the task of dependency parsing is to identify the syntactic head of each word in the sentence and classify the relation between the dependent and its head; the task of semantic role labeling consists of analyzing the propositions expressed by some target predicates. The integration of syntactic and semantic parsing interests many researchers and some approaches has been proposed (Yi and Palmer, 2005; Ge and Mooney, 2005). CoNLL 2008 shared task proposes the merging of both syntactic dependencies and semantic dependencies under a unique unified representation (Surdeanu et al., 2008). We explore © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. the integration problem and evaluate our approach using data provided on CoNLL 2008. This paper explores the integration of dependency relation classification and semantic role labeling, using a directed graphical model tha</context>
</contexts>
<marker>Yi, Palmer, 2005</marker>
<rawString>Yi, Szu-ting and Martha Palmer. 2005. The Integration of Syntactic Parsing and Semantic Role Labeling. In Proceedings of the Conference of Computational Natural Language Learning.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>