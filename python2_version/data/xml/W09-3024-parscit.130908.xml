<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011399">
<title confidence="0.998981">
Unsupervised Detection of Annotation Inconsistencies
Using Apriori Algorithm
</title>
<author confidence="0.996413">
V´aclav Nov´ak Magda Razimov´a
</author>
<affiliation confidence="0.993855">
Institute of Formal and Applied Linguistics
Charles University in Prague
</affiliation>
<address confidence="0.583494">
Czech Republic
</address>
<email confidence="0.998872">
{novak,razimova}@ufal.mff.cuni.cz
</email>
<sectionHeader confidence="0.9948" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999987555555555">
We present a new method for automated
discovery of inconsistencies in a complex
manually annotated corpora. The pro-
posed technique is based on Apriori al-
gorithm for mining association rules from
datasets. By setting appropriate parame-
ters to the algorithm, we were able to au-
tomatically infer highly reliable rules of
annotation and subsequently we searched
for records for which the inferred rules
were violated. We show that the viola-
tions found by this simple technique are
often caused by an annotation error. We
present an evaluation of this technique on
a hand-annotated corpus PDT 2.0, present
the error analysis and show that in the first
100 detected nodes 20 of them contained
an annotation error.
</bodyText>
<sectionHeader confidence="0.998784" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999947148148148">
Complex annotation schemes pose a serious chal-
lenge to annotators caused by the number of at-
tributes they are asked to fill. The annotation
tool can help them in ensuring that the values of
all attributes are from the appropriate domain but
the interplay of individual values and their mutual
compatibility are at best described in annotation
instructions and often implicit. Another source of
errors are idiomatic expressions where it is diffi-
cult for the annotator to think about the categories
of a word which often exists only as a part of the
idiom at hand.
In our approach, detection of annotation in-
consistencies is an instance of anomaly detection,
which is mainly used in the field of intrusion de-
tection. Traditionally, the anomaly detection is
based on distances between feature vectors of indi-
vidual instances. These methods are described in
Section 2. Our new method presented in Section 3
uses the data-mining technique Apriori (Borgelt
and Kruse, 2002) for inferring high-quality rules,
whose violation indicates a possible annotator’s
mistake or another source of inconsistency. We
tested the proposed method on a manually anno-
tated corpus and described both the data and the
experimental results in Section 4. We conclude by
Section 5.
</bodyText>
<sectionHeader confidence="0.999785" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99893716">
Unsupervised anomaly detection has been shown
to be viable for intrusion detection (Eskin et al.,
2002). The unsupervised techniques rely on fea-
ture vectors generated by individual instances and
try to find outliers in the vector space. This
can be done using clustering (Chimphlee et al.,
2005), Principle Component Analysis (Hawkins,
1974), geometric methods (Eskin et al., 2002) and
more (Lazarevic et al., 2003).
The difference between our method and previ-
ous work lies mainly in the fact that instead us-
ing vector space of features, we directly infer an-
notation rules. The manual annotation is always
based on some rules, some of which are contained
in the annotation manual but many others are more
or less implied. These rules will have their confi-
dence measured in the annotated corpus equal to
1 or at least very close (see Section 3 for defi-
nition of confidence). In our approach we learn
such rules and detect exceptions to the most cred-
ible rules. The rules are learned using the com-
mon Apriori algorithm (Borgelt and Kruse, 2002).
Previously, rules have been also mined by GUHA
algorithm (H´ajek and Havr´anek, 1978), but not in
the anomaly detection context.
</bodyText>
<sectionHeader confidence="0.949944" genericHeader="method">
3 Method Description
</sectionHeader>
<bodyText confidence="0.9911545">
Our process of anomaly detection comprises two
steps: rules mining and anomaly search.
</bodyText>
<page confidence="0.961294">
138
</page>
<note confidence="0.9711925">
Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP 2009, pages 138–141,
Suntec, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<subsectionHeader confidence="0.998453">
3.1 Rules Mining
</subsectionHeader>
<bodyText confidence="0.9974815">
The association rules mining was originally de-
signed for market basket analysis to automatically
derive rules such as “if the customer buys a tooth-
paste and a soap, he is also likely to buy a tooth-
brush”. Every check-out x = (x1, x2, ... , xN)
is modeled as a draw from an unknown probabil-
ity distribution Φ, where N is the total number of
items available at the store and xi is the number
of items of type i contained in the shopping cart.
Further, we define event Ej = {x|xj &gt; 0}, i.e.,
the event that the shopping cart contains the item
j.
In this model, we define a rule A = (L, R)
as a tuple where the left side L and the right
side R are sets of events Ej. For instance sup-
pose that the toothpaste, toothbrush and soap have
indices 1, 2 and 3, respectively. Then the ex-
ample rule mentioned above can be written as
Aexample = ({E1, E3}, {E2}), or alternatively
{E1, E3} ⇒ {E2}. For every rule A = (L, R)
we define two important measures: the support
s(A) and the confidence c(A):
</bodyText>
<equation confidence="0.997742222222222">
⎛ ⎞
⎝\ \
s ((L, R)) = P (l) ∩ (r) ⎠
(1)
l∈L r∈R
⎛ ⎞
⎝\ ��� \
c ((L, R)) = P (r) (l) ⎠(2)
r∈R l∈L
</equation>
<bodyText confidence="0.99997785">
In our example the support is the probability
that a cart contains a toothpaste, a toothbrush and a
soap. The confidence is the probability that a cart
contains a toothbrush given the cart contains both
a toothpaste and a soap.
The input of the Apriori algorithm (Borgelt and
Kruse, 2002) consists of a sample from the proba-
bility distribution Φ, the threshold of the estimated
confidence, the threshold of the estimated support
and the maximum size of rules. Using this data
the Apriori algorithm lists all rules satisfying the
required constraints.
In the context of market basket analysis the con-
fidence is rarely anywhere close to one, but in the
case of linguistic annotation, there are rules that
are always or almost always followed. The confi-
dence of these rules is very close or equal to one.
The Apriori algorithm allows us to gather rules
that have the confidence close to one and a suf-
ficient support.
</bodyText>
<subsectionHeader confidence="0.998334">
3.2 Anomaly Search
</subsectionHeader>
<bodyText confidence="0.999991333333333">
After extracting the highly confident rules we se-
lect the rules with the highest support and find the
annotations where these rules are violated. This
provides us with the list of anomalies. The search
is linear with the size of the data set and the size
of the list of extracted rules.
</bodyText>
<sectionHeader confidence="0.999416" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.988807">
4.1 Data and Tools
</subsectionHeader>
<bodyText confidence="0.99988125">
The experiments were carried out using the R sta-
tistical analysis software (R Development Core
Team, 2006) using the arules library (Borgelt and
Kruse, 2002). The dataset used was full manu-
ally annotated data of Prague Dependency Tree-
bank 2.0 (PDT 2.0). PDT 2.0 data were annotated
at three layers, namely morphological, analyti-
cal (shallow dependency syntax) and tectogram-
matical (deep dependency syntax; (Hajiˇc et al.,
2006)). The units of each annotation layer were
linked with corresponding units of the preceding
layer. The morphological units were linked di-
rectly with the original text. The annotation at
the tectogrammatical layer was checked automat-
ically for consistency with the annotation instruc-
tions (ˇStˇep´anek, 2006), however, using our tech-
nique, we were still able to automatically find er-
rors. The experimental dataset (full PDT 2.0 data
annotated at all three layers) contained 49,431 sen-
tences or 833,195 tokens.
</bodyText>
<subsectionHeader confidence="0.994877">
4.2 Experimental Setup and Error Analysis
</subsectionHeader>
<bodyText confidence="0.999986">
In our experimental setup, every check-out (i.e.,
every draw from the probability distribution Φ)
contains all attributes of one tectogrammatical
node and its governor. The attributes extracted
from the nodes are listed in Table 1. Thus every
check-out has exactly 52 items, 26 coming from
the node in question and 26 coming from its gov-
ernor.
This being input to the Apriori algorithm, we
set the maximal size of rules to 3, minimal support
to 0.001 and minimal confidence to 0.995. When
the rules were extracted, we sorted them accord-
ing to the descending confidence and stripped all
rules with confidence equal to 1. Using the re-
maining rules, we searched the corpus for the vio-
lations of the rules (starting from the top one) until
we found first 100 suspicious nodes. We manually
analyzed these 100 positions and found out that 20
</bodyText>
<page confidence="0.997936">
139
</page>
<subsectionHeader confidence="0.554583">
Attribute Description
</subsectionHeader>
<bodyText confidence="0.967972538461538">
functor semantic values of deep-syntactic dependency relations
is dsp root root node of the sub-tree representing direct speech
tfa contextual boundness
is generated element not expressed in the surface form of the sentence
is member member of a coordination or an apposition
is name of person proper name of a person
is parenthesis node is part of a parenthesis
is state modification with the meaning of a state
sentmod sentential modality
subfunctor semantic variation within a particular functor
aspect aspect of verbs
degcmp degree of comparison
deontmod an event is necessary, possible, permitted etc.
dispmod relation (attitude) of the agent to the event
gender masculine animate, masculine inanimate, feminine or neuter
indeftype types of pronouns (indefinite, negative etc.)
iterativeness multiple/iterated events
negation a negated or an affirmative form
number singular or plural
numertype types of numerals (cardinal, ordinal etc.)
person reference to the speaker/hearer/something else
politeness polite form
resultative event is presented as the resulting state
sempos semantic part of speech
tense verbal tense (simultaneous, preceding or subsequent events)
verbmod verbal mood (indicative, conditional or imperative)
</bodyText>
<tableCaption confidence="0.7919935">
Table 1: Attributes of tectogrammatical nodes used as the input to the rule mining algorithm. Their
complex interplay can hardly be fully prescribed in an annotation manual.
</tableCaption>
<bodyText confidence="0.956789">
of them constitute an annotation error. Examples
of extracted rules follow. functor:RSTR
</bodyText>
<equation confidence="0.9593294">
&amp; gender:nr (4)
⇒ number:nr
is parenthesis:1
&amp; governor:functor:PAR (3)
⇒ governor:is parenthesis:1
</equation>
<bodyText confidence="0.99861655">
Rule 3 states that if a tectogrammatical node has
the attribute is parenthesis set to 1 (i.e., the node
is part of a parenthesis) and at the same time the
governor of this node in the tectogrammatical tree
has its functor set to PAR (it is the root node of
nodes which are parenthesis in a sentence), the
governor’s is parenthesis attribute is also set to 1.
Using this rule we detected 6 nodes in the corpus
where the annotator forgot to fill the value 1 in the
is parenthesis attribute. There were no false posi-
tives and this automatically extracted rule is likely
to be added to the consistency checking routines
in the future.
Rule 4 states that RSTR nodes (mostly attributes
of nouns) with nr gender (indeterminable gender)
also have indeterminable number. Our procedure
located a node where the annotator correctly de-
termined the number as sg but failed to recognize
the gender (namely, masculine inanimate) of the
node.
</bodyText>
<equation confidence="0.882517666666667">
is member:1
&amp; dispmod:nil (5)
⇒ tense:nil
</equation>
<bodyText confidence="0.9961468">
Rule 5, stating that for nodes with is member set
to 1 the nil value (which means that none of the
defined basic values is suitable) of the dispmod
attribute implicates the nil value of the tense, is
an example of a rule producing false positives.
</bodyText>
<page confidence="0.992596">
140
</page>
<bodyText confidence="0.999897117647059">
Due to the data sparsity problem, there are not so
many nodes satisfying the premises and in most
of them the nil value were simply filled in their
tense attribute. However, there are (rather rare)
transgressive verb forms in the corpus for which
the correct annotation violates this rule. Many of
them were found by this procedure but they are
more anomalies in the underlying text rather than
anomalies in the annotation. An interesting point
to note is that there were several rules exhibiting
this behavior with different first premises (e.g.,
gender:anim &amp; governor:dispmod:nil ⇒ gover-
nor:tense:nil). The more general rule (dispmod:nil
⇒ tense:nil) would not get enough confidence, but
by combining it with other unrelated attributes, the
procedure was able to find rules with enough con-
fidence, although not very useful ones.
</bodyText>
<equation confidence="0.842755666666667">
resultative:res0
&amp; governor:degcmp:pos (6)
⇒ governor:sempos:adj.denot
</equation>
<bodyText confidence="0.997602555555555">
Rule 6 is an example of a successful rule. It
states that nodes that govern a non-resultative node
and have the positive degree of comparison are al-
ways denominating semantic adjectives (i.e., com-
mon adjectives such as black or good). Using
this rule we detected a node where the annotators
correctly determined the semantic part of speech
as adj.quant.grad (quantificational semantic adjec-
tive) but failed to indicate degcmp:comp.
</bodyText>
<sectionHeader confidence="0.992708" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999935421052632">
We have described a fast method for automatic de-
tection of inconsistencies in a hand-annotated cor-
pus using easily available software tools and eval-
uated it showing that in top 100 suspicious nodes
there were an error in 20 cases. This method seem
to work best for high-quality annotation where the
errors are rare: in our experiments the rules had to
achieve at least 99.5% confidence to be included
in the search for violations. However, it can also
point out inconsistencies in the annotation instruc-
tions by revealing the suspicious data points. We
have shown the typical rules and errors revealed
by our procedure.
The method can be generalized for any manu-
ally entered categorical datasets. The rules can
take values from multiple data entries (nodes,
words, etc.) into account to capture the de-
pendency in the annotation. Other rule-mining
techniques such as GUHA (H´ajek and Havr´anek,
</bodyText>
<note confidence="0.483501">
1978) can be used instead of Apriori.
</note>
<sectionHeader confidence="0.926932" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.997815">
This work was supported by Czech Academy
of Science grants 1ET201120505 and
1ET101120503; by Ministry of Education, Youth
and Sports projects LC536 and MSM0021620838.
</bodyText>
<sectionHeader confidence="0.997845" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999878844444444">
Christian Borgelt and Rudolf Kruse. 2002. Induction
of Association Rules: Apriori Implementation. In
Proceedings of 15th Conference on Computational
Statistics (Compstat), pages 395–400, Heidelberg,
Germany. Physica Verlag.
W. Chimphlee, Abdul Hanan Abdullah, Mohd
Noor Md Sap, S. Chimphlee, and S. Srinoy. 2005.
Unsupervised Clustering methods for Identifying
Rare Events in Anomaly Detection. In Proceed-
ings of the 6th International Enformatika Confer-
ence (IEC2005), Budapest, Hungary, October 26-28.
E. Eskin, A. Arnold, M. Prerau, L. Portnoy, and
S. Stolfo. 2002. A geometric framework for un-
supervised anomaly detection: Detecting intrusions
in unlabeled data. In Data Mining for Security Ap-
plications. Kluwer.
Petr H´ajek and Tom´aˇs Havr´anek. 1978. Mechaniz-
ing Hypothesis Formation; Mathematical Founda-
tions for a General Theory. Springer-Verlag, Berlin,
Heidelberg, New York.
Jan Hajiˇc, Jarmila Panevov´a, Eva Hajiˇcov´a, Petr
Sgall, Petr Pajas, Jan ˇStˇep´anek, Jiˇr´ı Havelka,
Marie Mikulov´a, Zdenˇek ˇZabokrtsk´y, and Magda
ˇSevˇc´ıkov´a-Raz´ımov´a. 2006. Prague Dependency
Treebank 2.0. CD-ROM, Linguistic Data Consor-
tium, LDC Catalog No.: LDC2006T01, Philadel-
phia, Pennsylvania.
D. M. Hawkins. 1974. The Detection of Errors
in Multivariate Data Using Principal Components.
Journal of the American Statistical Association,
69(346):340–344.
A. Lazarevic, A. Ozgur, L. Ertoz, J. Srivastava, and
V. Kumar. 2003. A comparative study of anomaly
detection schemes in network intrusion detection. In
Proceedings of SIAM International Conference on
Data Mining.
R Development Core Team, 2006. R: A Language and
Environment for Statistical Computing. R Foun-
dation for Statistical Computing, Vienna, Austria.
ISBN 3-900051-07-0.
Jan ˇStˇep´anek. 2006. Post-annotation Checking of
Prague Dependency Treebank 2.0 Data. In Proceed-
ings of the 9th International Conference, TSD 2006,
number 4188 in Lecture Notes in Computer Science,
pages 277–284. Springer-Verlag Berlin Heidelberg.
</reference>
<page confidence="0.99826">
141
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.577448">
<title confidence="0.9957285">Unsupervised Detection of Annotation Using Apriori Algorithm</title>
<author confidence="0.999624">V´aclav Nov´ak Magda Razimov´a</author>
<affiliation confidence="0.853511">Institute of Formal and Applied Charles University in Czech</affiliation>
<abstract confidence="0.999163368421053">We present a new method for automated discovery of inconsistencies in a complex manually annotated corpora. The proposed technique is based on Apriori algorithm for mining association rules from datasets. By setting appropriate parameters to the algorithm, we were able to automatically infer highly reliable rules of annotation and subsequently we searched for records for which the inferred rules were violated. We show that the violations found by this simple technique are often caused by an annotation error. We present an evaluation of this technique on a hand-annotated corpus PDT 2.0, present the error analysis and show that in the first 100 detected nodes 20 of them contained an annotation error.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Christian Borgelt</author>
<author>Rudolf Kruse</author>
</authors>
<title>Induction of Association Rules: Apriori Implementation.</title>
<date>2002</date>
<booktitle>In Proceedings of 15th Conference on Computational Statistics (Compstat),</booktitle>
<pages>395--400</pages>
<publisher>Physica Verlag.</publisher>
<location>Heidelberg, Germany.</location>
<contexts>
<context position="1929" citStr="Borgelt and Kruse, 2002" startWordPosition="299" endWordPosition="302">instructions and often implicit. Another source of errors are idiomatic expressions where it is difficult for the annotator to think about the categories of a word which often exists only as a part of the idiom at hand. In our approach, detection of annotation inconsistencies is an instance of anomaly detection, which is mainly used in the field of intrusion detection. Traditionally, the anomaly detection is based on distances between feature vectors of individual instances. These methods are described in Section 2. Our new method presented in Section 3 uses the data-mining technique Apriori (Borgelt and Kruse, 2002) for inferring high-quality rules, whose violation indicates a possible annotator’s mistake or another source of inconsistency. We tested the proposed method on a manually annotated corpus and described both the data and the experimental results in Section 4. We conclude by Section 5. 2 Related Work Unsupervised anomaly detection has been shown to be viable for intrusion detection (Eskin et al., 2002). The unsupervised techniques rely on feature vectors generated by individual instances and try to find outliers in the vector space. This can be done using clustering (Chimphlee et al., 2005), Pr</context>
<context position="3272" citStr="Borgelt and Kruse, 2002" startWordPosition="522" endWordPosition="525">he difference between our method and previous work lies mainly in the fact that instead using vector space of features, we directly infer annotation rules. The manual annotation is always based on some rules, some of which are contained in the annotation manual but many others are more or less implied. These rules will have their confidence measured in the annotated corpus equal to 1 or at least very close (see Section 3 for definition of confidence). In our approach we learn such rules and detect exceptions to the most credible rules. The rules are learned using the common Apriori algorithm (Borgelt and Kruse, 2002). Previously, rules have been also mined by GUHA algorithm (H´ajek and Havr´anek, 1978), but not in the anomaly detection context. 3 Method Description Our process of anomaly detection comprises two steps: rules mining and anomaly search. 138 Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP 2009, pages 138–141, Suntec, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP 3.1 Rules Mining The association rules mining was originally designed for market basket analysis to automatically derive rules such as “if the customer buys a toothpaste and a soap, he is also likely to buy a to</context>
<context position="5048" citStr="Borgelt and Kruse, 2002" startWordPosition="855" endWordPosition="858"> 3, respectively. Then the example rule mentioned above can be written as Aexample = ({E1, E3}, {E2}), or alternatively {E1, E3} ⇒ {E2}. For every rule A = (L, R) we define two important measures: the support s(A) and the confidence c(A): ⎛ ⎞ ⎝\ \ s ((L, R)) = P (l) ∩ (r) ⎠ (1) l∈L r∈R ⎛ ⎞ ⎝\ ��� \ c ((L, R)) = P (r) (l) ⎠(2) r∈R l∈L In our example the support is the probability that a cart contains a toothpaste, a toothbrush and a soap. The confidence is the probability that a cart contains a toothbrush given the cart contains both a toothpaste and a soap. The input of the Apriori algorithm (Borgelt and Kruse, 2002) consists of a sample from the probability distribution Φ, the threshold of the estimated confidence, the threshold of the estimated support and the maximum size of rules. Using this data the Apriori algorithm lists all rules satisfying the required constraints. In the context of market basket analysis the confidence is rarely anywhere close to one, but in the case of linguistic annotation, there are rules that are always or almost always followed. The confidence of these rules is very close or equal to one. The Apriori algorithm allows us to gather rules that have the confidence close to one </context>
</contexts>
<marker>Borgelt, Kruse, 2002</marker>
<rawString>Christian Borgelt and Rudolf Kruse. 2002. Induction of Association Rules: Apriori Implementation. In Proceedings of 15th Conference on Computational Statistics (Compstat), pages 395–400, Heidelberg, Germany. Physica Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Chimphlee</author>
<author>Abdul Hanan Abdullah</author>
<author>Mohd Noor Md Sap</author>
<author>S Chimphlee</author>
<author>S Srinoy</author>
</authors>
<title>Unsupervised Clustering methods for Identifying Rare Events in Anomaly Detection.</title>
<date>2005</date>
<booktitle>In Proceedings of the 6th International Enformatika Conference (IEC2005),</booktitle>
<location>Budapest, Hungary,</location>
<contexts>
<context position="2525" citStr="Chimphlee et al., 2005" startWordPosition="393" endWordPosition="396">i (Borgelt and Kruse, 2002) for inferring high-quality rules, whose violation indicates a possible annotator’s mistake or another source of inconsistency. We tested the proposed method on a manually annotated corpus and described both the data and the experimental results in Section 4. We conclude by Section 5. 2 Related Work Unsupervised anomaly detection has been shown to be viable for intrusion detection (Eskin et al., 2002). The unsupervised techniques rely on feature vectors generated by individual instances and try to find outliers in the vector space. This can be done using clustering (Chimphlee et al., 2005), Principle Component Analysis (Hawkins, 1974), geometric methods (Eskin et al., 2002) and more (Lazarevic et al., 2003). The difference between our method and previous work lies mainly in the fact that instead using vector space of features, we directly infer annotation rules. The manual annotation is always based on some rules, some of which are contained in the annotation manual but many others are more or less implied. These rules will have their confidence measured in the annotated corpus equal to 1 or at least very close (see Section 3 for definition of confidence). In our approach we le</context>
</contexts>
<marker>Chimphlee, Abdullah, Sap, Chimphlee, Srinoy, 2005</marker>
<rawString>W. Chimphlee, Abdul Hanan Abdullah, Mohd Noor Md Sap, S. Chimphlee, and S. Srinoy. 2005. Unsupervised Clustering methods for Identifying Rare Events in Anomaly Detection. In Proceedings of the 6th International Enformatika Conference (IEC2005), Budapest, Hungary, October 26-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Eskin</author>
<author>A Arnold</author>
<author>M Prerau</author>
<author>L Portnoy</author>
<author>S Stolfo</author>
</authors>
<title>A geometric framework for unsupervised anomaly detection: Detecting intrusions in unlabeled data. In Data Mining for Security Applications.</title>
<date>2002</date>
<publisher>Kluwer.</publisher>
<contexts>
<context position="2333" citStr="Eskin et al., 2002" startWordPosition="362" endWordPosition="365">is based on distances between feature vectors of individual instances. These methods are described in Section 2. Our new method presented in Section 3 uses the data-mining technique Apriori (Borgelt and Kruse, 2002) for inferring high-quality rules, whose violation indicates a possible annotator’s mistake or another source of inconsistency. We tested the proposed method on a manually annotated corpus and described both the data and the experimental results in Section 4. We conclude by Section 5. 2 Related Work Unsupervised anomaly detection has been shown to be viable for intrusion detection (Eskin et al., 2002). The unsupervised techniques rely on feature vectors generated by individual instances and try to find outliers in the vector space. This can be done using clustering (Chimphlee et al., 2005), Principle Component Analysis (Hawkins, 1974), geometric methods (Eskin et al., 2002) and more (Lazarevic et al., 2003). The difference between our method and previous work lies mainly in the fact that instead using vector space of features, we directly infer annotation rules. The manual annotation is always based on some rules, some of which are contained in the annotation manual but many others are mor</context>
</contexts>
<marker>Eskin, Arnold, Prerau, Portnoy, Stolfo, 2002</marker>
<rawString>E. Eskin, A. Arnold, M. Prerau, L. Portnoy, and S. Stolfo. 2002. A geometric framework for unsupervised anomaly detection: Detecting intrusions in unlabeled data. In Data Mining for Security Applications. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Petr H´ajek</author>
<author>Tom´aˇs Havr´anek</author>
</authors>
<title>Mechanizing Hypothesis Formation; Mathematical Foundations for a General Theory.</title>
<date>1978</date>
<publisher>Springer-Verlag,</publisher>
<location>Berlin, Heidelberg, New York.</location>
<marker>H´ajek, Havr´anek, 1978</marker>
<rawString>Petr H´ajek and Tom´aˇs Havr´anek. 1978. Mechanizing Hypothesis Formation; Mathematical Foundations for a General Theory. Springer-Verlag, Berlin, Heidelberg, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Jarmila Panevov´a</author>
<author>Eva Hajiˇcov´a</author>
<author>Petr Sgall</author>
<author>Petr Pajas</author>
<author>Jan ˇStˇep´anek</author>
<author>Jiˇr´ı Havelka</author>
<author>Marie Mikulov´a</author>
<author>Zdenˇek ˇZabokrtsk´y</author>
<author>Magda ˇSevˇc´ıkov´a-Raz´ımov´a</author>
</authors>
<date>2006</date>
<booktitle>Prague Dependency Treebank 2.0. CD-ROM, Linguistic Data Consortium, LDC Catalog No.: LDC2006T01,</booktitle>
<location>Philadelphia, Pennsylvania.</location>
<marker>Hajiˇc, Panevov´a, Hajiˇcov´a, Sgall, Pajas, ˇStˇep´anek, Havelka, Mikulov´a, ˇZabokrtsk´y, ˇSevˇc´ıkov´a-Raz´ımov´a, 2006</marker>
<rawString>Jan Hajiˇc, Jarmila Panevov´a, Eva Hajiˇcov´a, Petr Sgall, Petr Pajas, Jan ˇStˇep´anek, Jiˇr´ı Havelka, Marie Mikulov´a, Zdenˇek ˇZabokrtsk´y, and Magda ˇSevˇc´ıkov´a-Raz´ımov´a. 2006. Prague Dependency Treebank 2.0. CD-ROM, Linguistic Data Consortium, LDC Catalog No.: LDC2006T01, Philadelphia, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Hawkins</author>
</authors>
<title>The Detection of Errors in Multivariate Data Using Principal Components.</title>
<date>1974</date>
<journal>Journal of the American Statistical Association,</journal>
<volume>69</volume>
<issue>346</issue>
<contexts>
<context position="2571" citStr="Hawkins, 1974" startWordPosition="400" endWordPosition="401">rules, whose violation indicates a possible annotator’s mistake or another source of inconsistency. We tested the proposed method on a manually annotated corpus and described both the data and the experimental results in Section 4. We conclude by Section 5. 2 Related Work Unsupervised anomaly detection has been shown to be viable for intrusion detection (Eskin et al., 2002). The unsupervised techniques rely on feature vectors generated by individual instances and try to find outliers in the vector space. This can be done using clustering (Chimphlee et al., 2005), Principle Component Analysis (Hawkins, 1974), geometric methods (Eskin et al., 2002) and more (Lazarevic et al., 2003). The difference between our method and previous work lies mainly in the fact that instead using vector space of features, we directly infer annotation rules. The manual annotation is always based on some rules, some of which are contained in the annotation manual but many others are more or less implied. These rules will have their confidence measured in the annotated corpus equal to 1 or at least very close (see Section 3 for definition of confidence). In our approach we learn such rules and detect exceptions to the mo</context>
</contexts>
<marker>Hawkins, 1974</marker>
<rawString>D. M. Hawkins. 1974. The Detection of Errors in Multivariate Data Using Principal Components. Journal of the American Statistical Association, 69(346):340–344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lazarevic</author>
<author>A Ozgur</author>
<author>L Ertoz</author>
<author>J Srivastava</author>
<author>V Kumar</author>
</authors>
<title>A comparative study of anomaly detection schemes in network intrusion detection.</title>
<date>2003</date>
<booktitle>In Proceedings of SIAM International Conference on Data Mining.</booktitle>
<contexts>
<context position="2645" citStr="Lazarevic et al., 2003" startWordPosition="410" endWordPosition="413">r another source of inconsistency. We tested the proposed method on a manually annotated corpus and described both the data and the experimental results in Section 4. We conclude by Section 5. 2 Related Work Unsupervised anomaly detection has been shown to be viable for intrusion detection (Eskin et al., 2002). The unsupervised techniques rely on feature vectors generated by individual instances and try to find outliers in the vector space. This can be done using clustering (Chimphlee et al., 2005), Principle Component Analysis (Hawkins, 1974), geometric methods (Eskin et al., 2002) and more (Lazarevic et al., 2003). The difference between our method and previous work lies mainly in the fact that instead using vector space of features, we directly infer annotation rules. The manual annotation is always based on some rules, some of which are contained in the annotation manual but many others are more or less implied. These rules will have their confidence measured in the annotated corpus equal to 1 or at least very close (see Section 3 for definition of confidence). In our approach we learn such rules and detect exceptions to the most credible rules. The rules are learned using the common Apriori algorith</context>
</contexts>
<marker>Lazarevic, Ozgur, Ertoz, Srivastava, Kumar, 2003</marker>
<rawString>A. Lazarevic, A. Ozgur, L. Ertoz, J. Srivastava, and V. Kumar. 2003. A comparative study of anomaly detection schemes in network intrusion detection. In Proceedings of SIAM International Conference on Data Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Development Core Team</author>
</authors>
<title>R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing,</title>
<date>2006</date>
<journal>ISBN</journal>
<pages>3--900051</pages>
<location>Vienna,</location>
<contexts>
<context position="6119" citStr="Team, 2006" startWordPosition="1042" endWordPosition="1043">fidence of these rules is very close or equal to one. The Apriori algorithm allows us to gather rules that have the confidence close to one and a sufficient support. 3.2 Anomaly Search After extracting the highly confident rules we select the rules with the highest support and find the annotations where these rules are violated. This provides us with the list of anomalies. The search is linear with the size of the data set and the size of the list of extracted rules. 4 Experiments 4.1 Data and Tools The experiments were carried out using the R statistical analysis software (R Development Core Team, 2006) using the arules library (Borgelt and Kruse, 2002). The dataset used was full manually annotated data of Prague Dependency Treebank 2.0 (PDT 2.0). PDT 2.0 data were annotated at three layers, namely morphological, analytical (shallow dependency syntax) and tectogrammatical (deep dependency syntax; (Hajiˇc et al., 2006)). The units of each annotation layer were linked with corresponding units of the preceding layer. The morphological units were linked directly with the original text. The annotation at the tectogrammatical layer was checked automatically for consistency with the annotation inst</context>
</contexts>
<marker>Team, 2006</marker>
<rawString>R Development Core Team, 2006. R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan ˇStˇep´anek</author>
</authors>
<title>Post-annotation Checking of Prague Dependency Treebank 2.0 Data.</title>
<date>2006</date>
<booktitle>In Proceedings of the 9th International Conference, TSD 2006, number 4188 in Lecture Notes in Computer Science,</booktitle>
<pages>277--284</pages>
<publisher>Springer-Verlag</publisher>
<location>Berlin Heidelberg.</location>
<marker>ˇStˇep´anek, 2006</marker>
<rawString>Jan ˇStˇep´anek. 2006. Post-annotation Checking of Prague Dependency Treebank 2.0 Data. In Proceedings of the 9th International Conference, TSD 2006, number 4188 in Lecture Notes in Computer Science, pages 277–284. Springer-Verlag Berlin Heidelberg.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>