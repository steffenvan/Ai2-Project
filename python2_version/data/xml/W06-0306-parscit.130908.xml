<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.060042">
<title confidence="0.9980685">
Searching for Sentences Expressing Opinions
by using Declaratively Subjective Clues
</title>
<author confidence="0.920524">
Nobuaki Hiroshima, Setsuo Yamada, Osamu Furuse and Ryoji Kataoka
</author>
<affiliation confidence="0.79117">
NTT Cyber Solutions Laboratories, NTT Corporation
</affiliation>
<address confidence="0.940506">
1-1 Hikari-no-oka Yokosuka-Shi Kanagawa, 239-0847 Japan
</address>
<email confidence="0.999507">
hiroshima.nobuaki@lab.ntt.co.jp
</email>
<sectionHeader confidence="0.995651" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999879714285714">
This paper presents a method for search-
ing the web for sentences expressing
opinions. To retrieve an appropriate
number of opinions that users may want
to read, declaratively subjective clues are
used to judge whether a sentence ex-
presses an opinion. We collected declara-
tively subjective clues in opinion-
expressing sentences from Japanese web
pages retrieved with opinion search que-
ries. These clues were expanded with the
semantic categories of the words in the
sentences and were used as feature pa-
rameters in a Support Vector Machine to
classify the sentences. Our experimental
results using retrieved web pages on
various topics showed that the opinion
expressing sentences identified by the
proposed method are congruent with sen-
tences judged by humans to express
opinions.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999966407407407">
Readers have an increasing number of opportu-
nities to read opinions (personal ideas or beliefs),
feelings (mental states), and sentiments (positive
or negative judgments) that have been written or
posted on web pages such as review sites, per-
sonal web sites, blogs, and BBSes. Such subjec-
tive information on the web can often be a useful
basis for finding out what people think about a
particular topic or making a decision.
A number of studies on automatically extract-
ing and analyzing product reviews or reputations
on the web have been conducted (Dave et al.,
2003; Morinaga et al., 2002; Nasukawa and Yi,
2003; Tateishi et al., 2004; Kobayashi et al.,
2004). These studies focus on using sentiment
analysis to extract positive or negative informa-
tion about a particular product. Different kinds
of subjective information, such as neutral opin-
ions, requests, and judgments, which are not ex-
plicitly associated with positive/negative as-
sessments, have not often been considered in
previous work. Although sentiments provide
useful information, opinion-expressing sentences
like “In my opinion this product should be
priced around $15,” which do not express ex-
plicitly positive or negative judgments (unlike
sentiments) can also be informative for a user
who wants to know others’ opinions about a
product. When a user wants to collect opinions
about an event, project, or social phenomenon,
requests and judgments can be useful as well as
sentiments. With open-domain topics, sentences
expressing sentiments should not be searched
exclusively; other kinds of opinion expressing
sentences should be searched as well.
The goal of our research is to achieve a web
search engine that locates opinion-expressing
sentences about open-domain topics on products,
persons, events, projects, and social phenomena.
Sentence-level subjectivity/objectivity classifica-
tion in some of the previous research (Riloff and
Wiebe, 2003; Wiebe and Riloff, 2005) can iden-
tify subjective statements that include specula-
tion in addition to positive/negative evaluations.
In these efforts, the subjectivity/objectivity of a
current sentence is judged based on the existence
of subjective/objective clues in both the sentence
itself and the neighboring sentences. The subjec-
tive clues, some adjective, some noun, and some
verb phrases, as well as other collocations, are
learned from corpora (Wiebe, 2000; Wiebe et al.,
2001). Some of the clues express subjective
meaning unrestricted to positive/negative meas-
urements. The sentence-level subjectivity ap-
</bodyText>
<page confidence="0.992727">
39
</page>
<note confidence="0.6949275">
Proceedings of the Workshop on Sentiment and Subjectivity in Text, pages 39–46,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999975836065574">
proach suggests a way of searching for opinion
expressing sentences in the open domain.
The problem of applying sentence-level sub-
jectivity classification to opinion-expressing sen-
tence searches is the likelihood of collecting too
many sentences for a user to read. According to
the work of Wiebe et al. (2001), 70% of sen-
tences in opinion-expressing articles like editori-
als and 44% of sentences in non-opinion ex-
pressing articles like news reports were judged
to be subjective. In analyzing opinions (Cardie
et al., 2003; Wilson et al., 2004), judging docu-
ment-level subjectivity (Pang et al., 2002; Tur-
ney, 2002), and answering opinion questions
(Cardie et al., 2003; Yu and Hatzivassiloglou,
2003), the output of a sentence-level subjectivity
classification can be used without modification.
However, in searching opinion-expressing sen-
tences, it is necessary to designate criteria for
opinion-expressing sentences that limit the num-
ber of retrieved sentences so that a user can sur-
vey them without difficulty. While it is difficult
to formally define an opinion, it is possible to
practically tailor the definition of an opinion to
the purpose of the application (Kim and Hovy,
2004).
This study introduces the notion of declara-
tively subjective clues as a criterion for judging
whether a sentence expresses an opinion and
proposes a method for finding opinion-
expressing sentences that uses these clues. De-
claratively subjective clues such as the subjec-
tive predicate part of the main clause and subjec-
tive sentential adverb phrases suggest that the
writer is the source of the opinion. We hypothe-
size that a user of such an “opinion-expressing
sentence” search wants to read the writer’s opin-
ions and that explicitly stated opinions are pre-
ferred over quoted or implicational opinions. We
suppose that writer’s ideas or beliefs are explic-
itly declared in a sentence with declaratively
subjective clues whereas sentences without de-
claratively subjective clues mainly describe
things. The number of sentences with declara-
tively subjective clues is estimated to be less
than the number of subjective sentences defined
in the previous work. We expect that the opinion
expressing sentences identified with our method
will be appropriate from the both qualitative and
quantitative viewpoints.
Section 2 describes declaratively subjective
clues and explains how we collected them from
opinion-expressing sentences on Japanese web
pages retrieved with opinion search queries. Sec-
tion 3 explains our strategy for searching opin-
ion-expressing sentences by using declaratively
subjective clues. Section 4 evaluates the pro-
posed method and shows how the opinion-
expressing sentences found by the proposed
method are congruent with the sentences judged
by humans to be opinions.
</bodyText>
<sectionHeader confidence="0.946768" genericHeader="method">
2 Declaratively Subjective Clues
</sectionHeader>
<bodyText confidence="0.9987012">
Declaratively subjective clues are a basic crite-
rion for judging whether a sentence expresses an
opinion. We extracted the declaratively subjec-
tive clues from Japanese sentences that evalua-
tors judged to be opinions.
</bodyText>
<subsectionHeader confidence="0.998106">
2.1 Opinion-expressing Sentence Judgment
</subsectionHeader>
<bodyText confidence="0.999974913043478">
We regard a sentence to be “opinion expressing”
if it explicitly declares the writer’s idea or belief
at a sentence level. We define as a “declaratively
subjective clue”, the part of a sentence that con-
tributes to explicitly conveying the writer’s idea
or belief in the opinion-expressing sentence. For
example, &amp;quot;I am glad&amp;quot; in the sentence &amp;quot;I am glad
to see you&amp;quot; can convey the writer’s pleasure to a
reader, so we regard the sentence as an “opinion-
expressing sentence” and “I am glad” as a “de-
claratively subjective clue.” Another example of
a declaratively subjective clue is the exclamation
mark in the sentence &amp;quot;We got a contract!&amp;quot; It con-
veys the writer’s emotion about the event to a
reader.
If a sentence only describes something ab-
stract or concrete even though it has word-level
or phrase-level subjective parts, we do not con-
sider it to be opinion expressing. On the other
hand, some word-level or phrase-level subjective
parts can be declaratively subjective clues de-
pending on where they occur in the sentence.
Consider the following two sentences.
</bodyText>
<listItem confidence="0.99282">
(1) This house is beautiful.
(2) We purchased a beautiful house.
</listItem>
<bodyText confidence="0.9934745">
Both (1) and (2) contain the word-level subjec-
tive part &amp;quot;beautiful&amp;quot;. Our criterion would lead us
to say that sentence (1) is an opinion, because
&amp;quot;beautiful&amp;quot; is placed in the predicate part and (1)
is considered to declare the writer’s evaluation
of the house to a reader. This is why “beautiful”
in (1) is eligible as a declaratively subjective
clue. On the other hand, sentence (2) is not
judged to contain an opinion, because &amp;quot;beauti-
ful&amp;quot; is placed in the noun phrase, i.e., the object
of the verb “purchase,” and (2) is considered to
report the event of the house purchase rather ob-
</bodyText>
<page confidence="0.990506">
40
</page>
<bodyText confidence="0.999893590909091">
jectively to a reader. Sentence (2) partially con-
tains subjective information about the beauty of
the house; however this information is unlikely
to be what a writer wants to emphasize. Thus,
&amp;quot;beautiful&amp;quot; in (2) does not work as a declara-
tively subjective clue.
These two sentences illustrate the fact that the
presence of a subjective word (“beautiful”) does
not unconditionally assure that the sentence ex-
presses an opinion. Additionally, these examples
do suggest that sentences containing an opinion
can be judged depending on where such word-
level or phrase-level subjective parts as evalua-
tive adjectives are placed in the predicate part.
Some word-level or phrase-level subjective
parts such as subjective sentential adverbs can be
declaratively subjective clues depending on
where they occur in the sentence. In sentence (3),
“amazingly” expresses the writer’s feeling about
the event. Sentence (3) is judged to contain an
opinion because there is a subjective sentential
adverb in its main clause.
</bodyText>
<listItem confidence="0.897955">
(3) Amazingly, few people came to my party.
</listItem>
<bodyText confidence="0.993231666666667">
The existence of some idiomatic collocations
in the main clause also affects our judgment as
to what constitutes an opinion-expressing sen-
tence. For example, sentence (4) can be judged
as expressing an opinion because it includes “my
wish is”.
</bodyText>
<listItem confidence="0.767222">
(4) My wish is to go abroad.
</listItem>
<bodyText confidence="0.9999885">
Thus, depending on the type of declaratively
subjective clue, it is necessary to consider where
the expression is placed in the sentence to judge
whether the sentence is an opinion.
</bodyText>
<subsectionHeader confidence="0.998284">
2.2 Clue Expression Collection
</subsectionHeader>
<bodyText confidence="0.99835025">
We collected declaratively subjective clues in
opinion-expressing sentences from Japanese web
pages. Figure 1 illustrates the flow of collection
of eligible expressions.
</bodyText>
<table confidence="0.995386181818182">
type query’s topic
Product cell phone, car, beer, cosmetic
Entertainment sports, movie, game, animation
Facility museum, zoo, hotel, shop
Politics diplomacy, election
Phenomena diction, social behavior
Event firework, festival
Culture artwork, book, music
Organization company
Food cuisine, noodle, ice cream
Creature bird
</table>
<tableCaption confidence="0.999411">
Table 1: Topic Examples
</tableCaption>
<bodyText confidence="0.999855529411765">
First, we retrieved Japanese web pages from
forty queries covering a wide range of topics
such as products, entertainment, facilities, and
phenomena, as shown in Table 1. We used que-
ries on various topics because we wanted to ac-
quire declaratively subjective clues for open-
domain opinion web searches. Most of the que-
ries contain proper nouns. These queries corre-
spond to possible situations in which a user
wants to retrieve opinions from web pages about
a particular topic, such as “Cell phone X,” “Y
museum,” and “Football coach Z’s ability”,
where X, Y, and Z are proper nouns.
Next, opinion-expressing sentences were ex-
tracted from the top twenty retrieved web pages
in each query, 800 pages in total. There were
75,575 sentences in these pages.
</bodyText>
<figureCaption confidence="0.994975">
Figure 1: Flow of Clue Expression Collection
</figureCaption>
<page confidence="0.980456">
41
</page>
<table confidence="0.997591233333333">
type example sentence
(English translation of Japanese sentence)
Thought Kono hon wa kare no dato omou.
(I think this book is his.)
Declarative adverb Tabun rainen yooroppa ni iku.
(I will possibly go to Europe next year.)
Interjection Waa, suteki.
(Oh, wonderful.)
Intensifier Karera wa totemo jouzu ni asonda.
(They played extremely well)
Impression Kono yougo wa yayakoshii.
(This terminology is confusing.)
Emotion Oai dekite ureshii desu.
(I am glad to see you.)
Positive/negative judgment Anata no oodio kiki wa sugoi.
(Your audio system is terrific.)
Modality about propositional attitude Sono eiga wo miru beki da.
(You should go to the movie.)
Value judgment Kono bun wa imi fumei da.
(This sentence makes no sense.)
Utterance-specific sentence form Towa ittemo,ima wa tada no yume dakedo.
(Though, it&apos;s literally just a dream now.)
Symbol Keiyaku wo tottazo!
(We got a contract!)
Idiomatic collocation Ii nikui.
(It&apos;s hard to say.)
Uncertainty Ohiru ni nani wo tabeyou kanaa.
(I am wondering what I should eat for lunch.)
Imperative Saizen wo tukushi nasai.
(Give it your best.)
</table>
<tableCaption confidence="0.993741">
Table 2: Clue Types
</tableCaption>
<bodyText confidence="0.999677857142857">
Three evaluators judged whether each sen-
tence contained an opinion or not. The 13,363
sentences judged to do so by all three evaluators
were very likely to be opinion expressing. The
number of sentences which three evaluators
agreed on as non-opinion expressing was
42,346.1 Out of the 13,363 opinion expressing
sentences, 8,425 were then used to extract de-
claratively subjective clues and learn positive
examples in a Support Vector Machine (SVM),
and 4,938 were used to assess the performance
of opinion expressing sentence search (Section
4). Out of the 42,346 non-opinion sentences,
26,340 were used to learn negative examples,
and 16,006 were used to assess, keeping the
number ratio of the positive and negative exam-
ple sentences in learning and assessing.
One analyst extracted declaratively subjective
clues from 8,425 of the 13,363 opinion-
expressing sentences, and another analyst
checked the result. The number of declaratively
</bodyText>
<footnote confidence="0.651562">
1 Note that not all of these opinion-expressing sentences
retrieved were closely related to the query because some of
the pages described miscellaneous topics.
</footnote>
<bodyText confidence="0.999679916666667">
subjective clues obtained was 2,936. These clues
were classified into fourteen types as shown in
Table 2, where the underlined expressions in
example sentences are extracted as declaratively
subjective clues. The example sentences in Table
2 are Japanese opinion-expressing sentences and
their English translations. Although some Eng-
lish counterparts of Japanese clue expressions
might not be cogent because of the characteristic
difference between Japanese and English, the
clue types are likely to be language-independent.
We can see that various types of expressions
compose opinion-expressing sentences.
As mentioned in Section 2.1, it is important to
check where a declaratively subjective clue ap-
pears in the sentence in order to apply our crite-
rion of whether the sentence is an opinion or not.
The clues in the types other than (b), (c) and (l)
usually appear in the predicate part of a main
clause.
The declaratively subjective clues in Japanese
examples are placed in the rear parts of sen-
tences except in types (b), (c) and (l). This re-
flects the heuristic rule that Japanese predicate
</bodyText>
<page confidence="0.995659">
42
</page>
<bodyText confidence="0.990418">
parts are in principle placed in the rear part of a
sentence.
</bodyText>
<sectionHeader confidence="0.997345" genericHeader="method">
3 Opinion-Sentence Extraction
</sectionHeader>
<bodyText confidence="0.999977461538461">
In this section, we explain the method of classi-
fying each sentence by using declaratively sub-
jective clues.
The simplest method for automatically judging
whether a sentence is an opinion is a rule-based
one that extracts sentences that include declara-
tively subjective clues. However, as mentioned
in Section 2, the existence of declaratively sub-
jective clues does not assure that the sentence
expresses an opinion. It is a daunting task to
write rules that describe how each declaratively
subjective clue should appear in an opinion-
expressing sentence. A more serious problem is
that an insufficient collection of declaratively
subjective clues will lead to poor extraction per-
formance.
For that reason, we adopted a learning method
that binarily classifies sentences by using de-
claratively subjective clues and their positions in
sentences as feature parameters of an SVM.
With this method, a consistent framework of
classification can be maintained even if we add
new declaratively subjective clues, and it is pos-
sible that we can extract the opinion-expressing
sentences which have unknown declaratively
subjective clues.
</bodyText>
<subsectionHeader confidence="0.999505">
3.1 Augmentation by Semantic Categories
</subsectionHeader>
<bodyText confidence="0.997611">
Before we can use declaratively subjective clues
as feature parameters, we must address two is-
sues:
</bodyText>
<listItem confidence="0.985988615384616">
• Cost of building a corpus: It is costly
to provide a sufficient amount of tagged
corpus of opinion-expressing-sentence la-
bels to ensure that learning achieves a
high-performance extraction capability.
• Coverage of words co-occurring with
declaratively subjective clues: Many of
the declaratively subjective clue expres-
sions have co-occurring words in the
opinion-expressing sentence. Consider the
following two sentences.
(5) The sky is high.
(6) The quality of this product is high.
</listItem>
<bodyText confidence="0.999766291666667">
Both (5) and (6) contain the word &amp;quot;high&amp;quot;
in the predicate part. Sentence (5) is con-
sidered to be less of an opinion than (6)
because an evaluator might judge (5) to be
the objective truth, while all evaluators are
likely to judge (6) to be an opinion. The
adjective &amp;quot;high&amp;quot; in the predicate part can
be validated as a declaratively subjective
clue depending on co-occurring words.
However, it is not realistic to provide all
possible co-occurring words with each
declaratively subjective clue expression.
Semantic categories can be of help in dealing
with the above two issues. Declaratively subjec-
tive clue expressions can be augmented by se-
mantic categories of the words in the expressions.
An augmentation involving both declaratively
subjective clues and co-occurrences will increase
feature parameters. In our implementation, we
adopted the semantic categories proposed by
Ikehara et al. (1997). Utilization of semantic
categories has another effect: it improves the
extraction performance. Consider the following
two sentence patterns:
</bodyText>
<equation confidence="0.999291">
(7) X is beautiful.
(8) X is pretty.
</equation>
<bodyText confidence="0.9999984">
The words &amp;quot;beautiful&amp;quot; and &amp;quot;pretty&amp;quot; are adjec-
tives in the common semantic category, &amp;quot;appear-
ance&amp;quot;, and the degree of declarative subjectivity
of these sentences is almost the same regardless
of what X is. Therefore, even if &amp;quot;beautiful&amp;quot; is
learned as a declaratively subjective clue but
&amp;quot;pretty&amp;quot; is not, the semantic category &amp;quot;appear-
ance&amp;quot; that the learned word &amp;quot;beautiful&amp;quot; belongs
to, enables (8) to be judged opinion expressing
as well as (7).
</bodyText>
<subsectionHeader confidence="0.995389">
3.2 Feature Parameters to Learn
</subsectionHeader>
<bodyText confidence="0.99993675">
We implemented our opinion-sentence extrac-
tion method by using a Support Vector Machine
(SVM) because an SVM can efficiently learn the
model for classifying sentences into opinion-
expressing and non-opinion expressing, based on
the combinations of multiple feature parameters.
The following are the crucial feature parameters
of our method.
</bodyText>
<listItem confidence="0.899260333333333">
• 2,936 declaratively subjective clues
• 2,715 semantic categories that words in
a sentence can fall into
</listItem>
<bodyText confidence="0.9998026">
If the sentence has a declaratively subjective
clue of type (b), (c) or (l) in Table 2, the feature
parameter about the clue is assigned a value of 1;
if not, it is assigned 0. If the sentence has de-
claratively subjective clues belonging to types
</bodyText>
<page confidence="0.999378">
43
</page>
<table confidence="0.99978">
Method Opinion No opinion Accuracy
Precision Recall F-measure Precision Recall F-measure
Occurrences of DS clues 66.4% 35.3% 46.0% 82.6% 94.5% 88.1% 80.5%
(baseline 1)
Bag of words 80.9% 64.2% 71.6% 89.6% 95.3% 92.4% 88.0%
(baseline 2)
Proposed 78.6% 70.8% 74.4% 91.3% 94.0% 92.6% 88.6%
</table>
<tableCaption confidence="0.961325">
Table 4: Results for comparison with baseline methods
</tableCaption>
<table confidence="0.99981125">
Answer Opinion No opinion
System
Opinion a b
No opinion c d
</table>
<tableCaption confidence="0.999734">
Table 3: Number of sentences in a test set
</tableCaption>
<bodyText confidence="0.998943181818182">
other than (b), (c) or (l) in the predicate part, the
feature parameter about the clue is assigned 1; if
not, it is assigned 0.
The feature parameters for the semantic cate-
gory are used to compensate for the insufficient
amount of declaratively subjective clues pro-
vided and to consider co-occurring words with
clue expressions in the opinion-expressing sen-
tences, as mentioned in Section 3.1.
The following are additional feature parame-
ters.
</bodyText>
<listItem confidence="0.99967">
• 150 frequent words
• 13 parts of speech
</listItem>
<bodyText confidence="0.999912909090909">
Each feature parameter is assigned a value of 1 if
the sentence has any of the frequent words or
parts of speech. We added these feature parame-
ters based on the hypotheses that some frequent
words in Japanese have the function of changing
the degree of declarative subjectivity, and that
the existence of such parts of speech as adjec-
tives and adverbs possibly influences the de-
clarative subjectivity. The effectiveness of these
additional feature parameters was confirmed in
our preliminary experiment.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.996090130434783">
We conducted three experiments to assess the
validity of the proposed method: comparison
with baseline methods, effectiveness of position
information in SVM feature parameters, and ef-
fectiveness of SVM feature parameters such as
declaratively subjective clues and semantic cate-
gories.
All experiments were performed using the
Japanese sentences described in Section 2.1. We
used 8,425 opinion expressing sentences, which
were used to collect declaratively subjective
clues as a training set, and used 4,938 opinion-
expressing sentences as a test set. We also used
26,340 non-opinion sentences as a training set
and used 16,006 non-opinion sentences as a test
set. The test set was divided into ten equal sub-
sets. The experiments were evaluated with the
following measures following the variable
scheme in Table 3:
a+d
a+b+c+d
We evaluated ten subsets with the above
measures and took the average of these results.
</bodyText>
<subsectionHeader confidence="0.999866">
4.1 Comparison with Baseline Methods
</subsectionHeader>
<bodyText confidence="0.999603470588235">
We first performed an experiment comparing
two baseline methods with our proposed method.
We prepared a baseline method that regards a
sentence as an opinion if it contains a number of
declaratively subjective clues that exceeds a cer-
tain threshold. The best threshold was set
through trial and error at five occurrences. We
also prepared another baseline method that
learns a model and classifies a sentence using
only features about a bag of words.
The experimental results are shown in Table 4.
It can be seen that our method performs better
than the two baseline methods. Though the dif-
ference between our method’s results and those
of the bag-of-words method seems rather small,
the superiority of the proposed method cannot be
rejected at the significance level of 5% in t-test.
</bodyText>
<figure confidence="0.994580764705882">
Pop a+b
R = a
op a+c
a
F
op Pop + Rop
P = d R = d
no op c+d no op b+d
F=
no op P
_ + R
no_op no_op
2Pno
opRno_op
Rop
2 Pop
A
</figure>
<page confidence="0.995764">
44
</page>
<table confidence="0.99991125">
Position Opinion No opinion Accuracy
Precision Recall F-measure Precision Recall F-measure
All words 76.8% 70.6% 73.5% 91.2% 93.4% 92.3% 88.0%
Last 10 words 78.6% 70.8% 74.4% 91.3% 94.0% 92.6% 88.6%
</table>
<tableCaption confidence="0.877911">
Table 5: Results for feature parameters with position information
</tableCaption>
<table confidence="0.999668142857143">
Feature sets Opinion No opinion Accuracy
DS Semantic Precision Recall F- Precision Recall F-
clues categories measure measure
71.4% 53.2% 60.9% 87.7% 94.1% 90.8% 85.2%
Y 79.9% 64.3% 71.2% 89.6% 95.0% 92.2% 87.8%
Y 76.1% 68.9% 72.2% 90.7% 93.3% 92.0% 87.5%
Y Y 78.6% 70.8% 74.4% 91.3% 94.0% 92.6% 88.6%
</table>
<tableCaption confidence="0.988754">
Table 6: Results for effect of feature parameters
</tableCaption>
<sectionHeader confidence="0.8633995" genericHeader="method">
4.2 Feature Parameters with Position In-
formation
</sectionHeader>
<bodyText confidence="0.999872382352941">
We inspected the effect of position information
of 2,936 declaratively subjective clues based on
the heuristic rule that a Japanese predicate part
almost always appears in the last ten words in a
sentence. Instead of more precisely identifying
predicate position from parsing information, we
employed this heuristic rule as a feature parame-
ter in the SVM learner for practical reasons.
Table 5 lists the experimental results. &amp;quot;All
words&amp;quot; indicates that all feature parameters are
permitted at any position in the sentence. &amp;quot;Last
10 words&amp;quot; indicates that all feature parameters
are permitted only if they occur within the last
ten words in the sentence.
We can see that feature parameters with posi-
tion information perform better than those with-
out position information in all evaluations. This
result confirms our claim that the position of the
feature parameters is important for judging
whether a sentence is an opinion or not.
However, the difference did not indicate supe-
riority between the two results at the significance
level of 5%. In the “last 10 word” experiment,
we restricted the position of 422 declaratively
subjective clues like (b), (c) and (l) in Table 2,
which appear in any position of a sentence, to
the same conditions as with the other types of
2,514 declaratively subjective clues. The fact
that the equal position restriction on all declara-
tively subjective clues slightly improved per-
formance suggests there will be significant im-
provement in performance from assigning the
individual position condition to each declara-
tively subjective clue.
</bodyText>
<subsectionHeader confidence="0.999011">
4.3 Effect of Feature Parameters
</subsectionHeader>
<bodyText confidence="0.9999703">
The third experiment was designed to ascertain
the effects of declaratively subjective clues and
semantic categories. The declaratively subjective
clues and semantic categories were employed as
feature parameters for the SVM learner. The ef-
fect of each particular feature parameter can be
seen by using it without the other feature pa-
rameter, because the feature parameters are in-
dependent of each other.
The experimental results are shown in Table 6.
The first row shows trials using only frequent
words and parts of speech as feature parameters.
&amp;quot;Y&amp;quot; in the first and second columns indicates
exclusive use of declaratively subjective clues
and semantic categories as the feature parame-
ters, respectively. For instance, we can deter-
mine the effect of declaratively subjective clues
by comparing the first row with the second row.
The results show the effects of declaratively
subjective clues and semantic categories. The
results of the first row show that the method us-
ing only frequent words and parts of speech as
the feature parameters cannot precisely classify
subjective sentences. Additionally, the last row
of the results clearly shows that using both de-
claratively subjective clues and semantic catego-
ries as the feature parameters is the most effec-
tive. The difference between the last row of the
results and the other rows cannot be rejected
even at the significance level of 5%.
</bodyText>
<page confidence="0.999072">
45
</page>
<sectionHeader confidence="0.987841" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999994896551724">
We proposed a method of extracting sentences
classified by an SVM as opinion-expressing that
uses feature sets of declaratively subjective clues
collected from opinion-expressing sentences in
Japanese web pages and semantic categories of
words obtained from a Japanese lexicon. The
first experiment showed that our method per-
formed better than baseline methods. The second
experiment suggested that our method performed
better when extraction of features was limited to
the predicate part of a sentence rather than al-
lowed anywhere in the sentence. The last ex-
periment showed that using both declaratively
subjective clues and semantic categories as fea-
ture parameters yielded better results than using
either clues or categories exclusively.
Our future work will attempt to develop an
open-domain opinion web search engine. To
succeed, we first need to augment the proposed
opinion-sentence extraction method by incorpo-
rating the query relevancy mechanism. Accord-
ingly, a user will be able to retrieve opinion-
expressing sentences relevant to the query. Sec-
ond, we need to classify extracted sentences in
terms of emotion, sentiment, requirement, and
suggestion so that a user can retrieve relevant
opinions on demand. Finally, we need to sum-
marize the extracted sentences so that the user
can quickly learn what the writer wanted to say.
</bodyText>
<sectionHeader confidence="0.999262" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999832428571429">
Claire Cardie, Janyce Wiebe, Theresa Wilson, and
Diane J. Litman. 2003. Combining Low-Level and
Summary Representations of Opinions. for Multi-
Perspective Question Answering. Working Notes -
New Directions in Question Answering (AAAI
Spring Symposium Series) .
Kushal Dave, Steve Lawrence, and David M. Pennock.
2003. Mining the peanut gallery: Opinion extraction
and semantic classification of product reviews. Pro-
ceedings of the 12th International World Wide Web
Conference, 519-528.
Satoru Ikehara, Masahiro Miyazaki, Akio Yokoo, Sato-
shi Shirai, Hiromi Nakaiwa, Kentaro Ogura, Yoshi-
fumi Ooyama, and Yoshihiko Hayashi. 1997. Ni-
hongo Goi Taikei – A Japanese Lexicon. Iwanami
Shoten. 5 volumes. (In Japanese).
Soo-Min Kim and Eduard Hovy. 2004. Determining the
Sentiment of Opinions. Proceedings of the. COLING-
04.
Nozomi Kobayashi, Kentaro Inui, Yuji Matsumoto,
Kenji Tateishi, and Toshikazu Fukushima. 2004. Col-
lecting Evaluative Expressions for Opinion Extrac-
tion. Proceedings of the First International Joint Con-
ference on Natural Language Processing (IJCNLP-
04), 584-589.
Satoshi Morinaga, Kenji Yamanishi, and Kenji Tateishi.
2002. Mining Product Reputations on the Web. Pro-
ceedings of the eighth ACM SIGKDD International
Conference on Knowledge Discovery and Data Min-
ing (KDD 2002).
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up? Sentiment Classification using
Machine Learning Techniques. Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP-2002), 76-86.
Tetsuya Nasukawa and Jeonghee Yi. 2003. Sentiment
Analysis: Capturing Favorability Using Natural
Language Processing. Proceedings of the 2nd Inter-
national Conference on Knowledge Capture(K-CAP
2003).
Ellen Riloff and Janyce Wiebe. 2003. Learning Extrac-
tion Patterns for Subjective Expressions. Proceedings
of the Conference on Empirical Methods in Natural
Language Processing (EMNLP-03), 105-112.
Kenji Tateishi, Yoshihide Ishiguro, and Toshikazu Fu-
kushima, 2004. A Reputation Search Engine that
Collects People’s Opinions by Information Extrac-
tion Technology, IPSJ Transactions Vol. 45
No.SIG07, 115-123.
Peter Turney. 2002. Thumbs Up or Thumbs Down? Se-
mantic Orientation Applied to Unsupervised Classifi-
cation of Reviews. Proceedings of the 40th Annual
Meeting of the Association for Computational Lin-
guistics (ACL-2002), 417-424.
Janyce Wiebe. 2000. Learning Subjective Adjectives
from Corpora. Proceedings of the 17th National Con-
ference on Artificial Intelligence (AAAI -2000).
Janyce Wiebe, Theresa Wilson, and Matthew Bell. 2001.
Identifying Collocations for Recognizing Opinions.
Proceedings of ACL/EACL 2001 Workshop on Col-
location.
Janyce Wiebe and Ellen Riloff. 2005. Creating Subjec-
tive and Objective Sentence Classifiers from Unanno-
tated Texts. Proceedings of Sixth International Con-
ference on Intelligent Text Processing and Computa-
tional Linguistics (CICLing-2005), 486-497.
Theresa Wilson, Janyce Wiebe, and Rebecca Hwa, 2004.
Just how mad are you? Finding strong and weak
opinion clauses. Proceeding of the AAAI Spring
Symposium on Exploring Attitude and Affect in
Text: Theories and Applications.
Hong Yu and Vasileios Hatzivassiloglou. 2003. To-
wards Answering Opinion Questions: Separating
Facts from Opinions and Identifying the Polarity of
Opinion Sentences. Proceedings of the Conference
on Empirical Methods in Natural Language Process-
ing (EMNLP-2003).
</reference>
<page confidence="0.999611">
46
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.783059">
<title confidence="0.9812035">Searching for Sentences Expressing by using Declaratively Subjective Clues</title>
<author confidence="0.943773">Nobuaki Hiroshima</author>
<author confidence="0.943773">Setsuo Yamada</author>
<author confidence="0.943773">Osamu Furuse</author>
<author confidence="0.943773">Ryoji</author>
<affiliation confidence="0.997275">NTT Cyber Solutions Laboratories, NTT Corporation</affiliation>
<address confidence="0.935183">1-1 Hikari-no-oka Yokosuka-Shi Kanagawa, 239-0847 Japan</address>
<email confidence="0.957987">hiroshima.nobuaki@lab.ntt.co.jp</email>
<abstract confidence="0.997529545454546">This paper presents a method for searching the web for sentences expressing opinions. To retrieve an appropriate number of opinions that users may want to read, declaratively subjective clues are used to judge whether a sentence expresses an opinion. We collected declaratively subjective clues in opinionexpressing sentences from Japanese web pages retrieved with opinion search queries. These clues were expanded with the semantic categories of the words in the sentences and were used as feature parameters in a Support Vector Machine to classify the sentences. Our experimental results using retrieved web pages on various topics showed that the opinion expressing sentences identified by the proposed method are congruent with sentences judged by humans to express opinions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Claire Cardie</author>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
<author>Diane J Litman</author>
</authors>
<title>Combining Low-Level and Summary Representations of Opinions. for MultiPerspective Question Answering. Working Notes -New Directions in Question Answering (AAAI Spring Symposium Series) .</title>
<date>2003</date>
<contexts>
<context position="4294" citStr="Cardie et al., 2003" startWordPosition="639" endWordPosition="642">tivity in Text, pages 39–46, Sydney, July 2006. c�2006 Association for Computational Linguistics proach suggests a way of searching for opinion expressing sentences in the open domain. The problem of applying sentence-level subjectivity classification to opinion-expressing sentence searches is the likelihood of collecting too many sentences for a user to read. According to the work of Wiebe et al. (2001), 70% of sentences in opinion-expressing articles like editorials and 44% of sentences in non-opinion expressing articles like news reports were judged to be subjective. In analyzing opinions (Cardie et al., 2003; Wilson et al., 2004), judging document-level subjectivity (Pang et al., 2002; Turney, 2002), and answering opinion questions (Cardie et al., 2003; Yu and Hatzivassiloglou, 2003), the output of a sentence-level subjectivity classification can be used without modification. However, in searching opinion-expressing sentences, it is necessary to designate criteria for opinion-expressing sentences that limit the number of retrieved sentences so that a user can survey them without difficulty. While it is difficult to formally define an opinion, it is possible to practically tailor the definition of</context>
</contexts>
<marker>Cardie, Wiebe, Wilson, Litman, 2003</marker>
<rawString>Claire Cardie, Janyce Wiebe, Theresa Wilson, and Diane J. Litman. 2003. Combining Low-Level and Summary Representations of Opinions. for MultiPerspective Question Answering. Working Notes -New Directions in Question Answering (AAAI Spring Symposium Series) .</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kushal Dave</author>
<author>Steve Lawrence</author>
<author>David M Pennock</author>
</authors>
<title>Mining the peanut gallery: Opinion extraction and semantic classification of product reviews.</title>
<date>2003</date>
<booktitle>Proceedings of the 12th International World Wide Web Conference,</booktitle>
<pages>519--528</pages>
<contexts>
<context position="1658" citStr="Dave et al., 2003" startWordPosition="249" endWordPosition="252">ged by humans to express opinions. 1 Introduction Readers have an increasing number of opportunities to read opinions (personal ideas or beliefs), feelings (mental states), and sentiments (positive or negative judgments) that have been written or posted on web pages such as review sites, personal web sites, blogs, and BBSes. Such subjective information on the web can often be a useful basis for finding out what people think about a particular topic or making a decision. A number of studies on automatically extracting and analyzing product reviews or reputations on the web have been conducted (Dave et al., 2003; Morinaga et al., 2002; Nasukawa and Yi, 2003; Tateishi et al., 2004; Kobayashi et al., 2004). These studies focus on using sentiment analysis to extract positive or negative information about a particular product. Different kinds of subjective information, such as neutral opinions, requests, and judgments, which are not explicitly associated with positive/negative assessments, have not often been considered in previous work. Although sentiments provide useful information, opinion-expressing sentences like “In my opinion this product should be priced around $15,” which do not express explicit</context>
</contexts>
<marker>Dave, Lawrence, Pennock, 2003</marker>
<rawString>Kushal Dave, Steve Lawrence, and David M. Pennock. 2003. Mining the peanut gallery: Opinion extraction and semantic classification of product reviews. Proceedings of the 12th International World Wide Web Conference, 519-528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoru Ikehara</author>
</authors>
<title>Masahiro Miyazaki, Akio Yokoo, Satoshi Shirai, Hiromi Nakaiwa, Kentaro Ogura, Yoshifumi Ooyama, and Yoshihiko Hayashi.</title>
<date>1997</date>
<note>(In Japanese).</note>
<marker>Ikehara, 1997</marker>
<rawString>Satoru Ikehara, Masahiro Miyazaki, Akio Yokoo, Satoshi Shirai, Hiromi Nakaiwa, Kentaro Ogura, Yoshifumi Ooyama, and Yoshihiko Hayashi. 1997. Nihongo Goi Taikei – A Japanese Lexicon. Iwanami Shoten. 5 volumes. (In Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Determining the Sentiment of Opinions.</title>
<date>2004</date>
<booktitle>Proceedings of the. COLING04.</booktitle>
<contexts>
<context position="4960" citStr="Kim and Hovy, 2004" startWordPosition="741" endWordPosition="744">subjectivity (Pang et al., 2002; Turney, 2002), and answering opinion questions (Cardie et al., 2003; Yu and Hatzivassiloglou, 2003), the output of a sentence-level subjectivity classification can be used without modification. However, in searching opinion-expressing sentences, it is necessary to designate criteria for opinion-expressing sentences that limit the number of retrieved sentences so that a user can survey them without difficulty. While it is difficult to formally define an opinion, it is possible to practically tailor the definition of an opinion to the purpose of the application (Kim and Hovy, 2004). This study introduces the notion of declaratively subjective clues as a criterion for judging whether a sentence expresses an opinion and proposes a method for finding opinionexpressing sentences that uses these clues. Declaratively subjective clues such as the subjective predicate part of the main clause and subjective sentential adverb phrases suggest that the writer is the source of the opinion. We hypothesize that a user of such an “opinion-expressing sentence” search wants to read the writer’s opinions and that explicitly stated opinions are preferred over quoted or implicational opinio</context>
</contexts>
<marker>Kim, Hovy, 2004</marker>
<rawString>Soo-Min Kim and Eduard Hovy. 2004. Determining the Sentiment of Opinions. Proceedings of the. COLING04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nozomi Kobayashi</author>
<author>Kentaro Inui</author>
<author>Yuji Matsumoto</author>
<author>Kenji Tateishi</author>
<author>Toshikazu Fukushima</author>
</authors>
<title>Collecting Evaluative Expressions for Opinion Extraction.</title>
<date>2004</date>
<booktitle>Proceedings of the First International Joint Conference on Natural Language Processing (IJCNLP04),</booktitle>
<pages>584--589</pages>
<contexts>
<context position="1752" citStr="Kobayashi et al., 2004" startWordPosition="265" endWordPosition="268">pportunities to read opinions (personal ideas or beliefs), feelings (mental states), and sentiments (positive or negative judgments) that have been written or posted on web pages such as review sites, personal web sites, blogs, and BBSes. Such subjective information on the web can often be a useful basis for finding out what people think about a particular topic or making a decision. A number of studies on automatically extracting and analyzing product reviews or reputations on the web have been conducted (Dave et al., 2003; Morinaga et al., 2002; Nasukawa and Yi, 2003; Tateishi et al., 2004; Kobayashi et al., 2004). These studies focus on using sentiment analysis to extract positive or negative information about a particular product. Different kinds of subjective information, such as neutral opinions, requests, and judgments, which are not explicitly associated with positive/negative assessments, have not often been considered in previous work. Although sentiments provide useful information, opinion-expressing sentences like “In my opinion this product should be priced around $15,” which do not express explicitly positive or negative judgments (unlike sentiments) can also be informative for a user who w</context>
</contexts>
<marker>Kobayashi, Inui, Matsumoto, Tateishi, Fukushima, 2004</marker>
<rawString>Nozomi Kobayashi, Kentaro Inui, Yuji Matsumoto, Kenji Tateishi, and Toshikazu Fukushima. 2004. Collecting Evaluative Expressions for Opinion Extraction. Proceedings of the First International Joint Conference on Natural Language Processing (IJCNLP04), 584-589.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoshi Morinaga</author>
<author>Kenji Yamanishi</author>
<author>Kenji Tateishi</author>
</authors>
<title>Mining Product Reputations on the Web.</title>
<date>2002</date>
<booktitle>Proceedings of the eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD</booktitle>
<contexts>
<context position="1681" citStr="Morinaga et al., 2002" startWordPosition="253" endWordPosition="256">press opinions. 1 Introduction Readers have an increasing number of opportunities to read opinions (personal ideas or beliefs), feelings (mental states), and sentiments (positive or negative judgments) that have been written or posted on web pages such as review sites, personal web sites, blogs, and BBSes. Such subjective information on the web can often be a useful basis for finding out what people think about a particular topic or making a decision. A number of studies on automatically extracting and analyzing product reviews or reputations on the web have been conducted (Dave et al., 2003; Morinaga et al., 2002; Nasukawa and Yi, 2003; Tateishi et al., 2004; Kobayashi et al., 2004). These studies focus on using sentiment analysis to extract positive or negative information about a particular product. Different kinds of subjective information, such as neutral opinions, requests, and judgments, which are not explicitly associated with positive/negative assessments, have not often been considered in previous work. Although sentiments provide useful information, opinion-expressing sentences like “In my opinion this product should be priced around $15,” which do not express explicitly positive or negative</context>
</contexts>
<marker>Morinaga, Yamanishi, Tateishi, 2002</marker>
<rawString>Satoshi Morinaga, Kenji Yamanishi, and Kenji Tateishi. 2002. Mining Product Reputations on the Web. Proceedings of the eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment Classification using Machine Learning Techniques.</title>
<date>2002</date>
<booktitle>Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2002),</booktitle>
<pages>76--86</pages>
<contexts>
<context position="4372" citStr="Pang et al., 2002" startWordPosition="651" endWordPosition="654">onal Linguistics proach suggests a way of searching for opinion expressing sentences in the open domain. The problem of applying sentence-level subjectivity classification to opinion-expressing sentence searches is the likelihood of collecting too many sentences for a user to read. According to the work of Wiebe et al. (2001), 70% of sentences in opinion-expressing articles like editorials and 44% of sentences in non-opinion expressing articles like news reports were judged to be subjective. In analyzing opinions (Cardie et al., 2003; Wilson et al., 2004), judging document-level subjectivity (Pang et al., 2002; Turney, 2002), and answering opinion questions (Cardie et al., 2003; Yu and Hatzivassiloglou, 2003), the output of a sentence-level subjectivity classification can be used without modification. However, in searching opinion-expressing sentences, it is necessary to designate criteria for opinion-expressing sentences that limit the number of retrieved sentences so that a user can survey them without difficulty. While it is difficult to formally define an opinion, it is possible to practically tailor the definition of an opinion to the purpose of the application (Kim and Hovy, 2004). This study</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment Classification using Machine Learning Techniques. Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2002), 76-86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tetsuya Nasukawa</author>
<author>Jeonghee Yi</author>
</authors>
<title>Sentiment Analysis: Capturing Favorability Using Natural Language Processing.</title>
<date>2003</date>
<booktitle>Proceedings of the 2nd International Conference on Knowledge Capture(K-CAP</booktitle>
<contexts>
<context position="1704" citStr="Nasukawa and Yi, 2003" startWordPosition="257" endWordPosition="260">duction Readers have an increasing number of opportunities to read opinions (personal ideas or beliefs), feelings (mental states), and sentiments (positive or negative judgments) that have been written or posted on web pages such as review sites, personal web sites, blogs, and BBSes. Such subjective information on the web can often be a useful basis for finding out what people think about a particular topic or making a decision. A number of studies on automatically extracting and analyzing product reviews or reputations on the web have been conducted (Dave et al., 2003; Morinaga et al., 2002; Nasukawa and Yi, 2003; Tateishi et al., 2004; Kobayashi et al., 2004). These studies focus on using sentiment analysis to extract positive or negative information about a particular product. Different kinds of subjective information, such as neutral opinions, requests, and judgments, which are not explicitly associated with positive/negative assessments, have not often been considered in previous work. Although sentiments provide useful information, opinion-expressing sentences like “In my opinion this product should be priced around $15,” which do not express explicitly positive or negative judgments (unlike sent</context>
</contexts>
<marker>Nasukawa, Yi, 2003</marker>
<rawString>Tetsuya Nasukawa and Jeonghee Yi. 2003. Sentiment Analysis: Capturing Favorability Using Natural Language Processing. Proceedings of the 2nd International Conference on Knowledge Capture(K-CAP 2003).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Janyce Wiebe</author>
</authors>
<title>Learning Extraction Patterns for Subjective Expressions.</title>
<date>2003</date>
<booktitle>Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-03),</booktitle>
<pages>105--112</pages>
<contexts>
<context position="3008" citStr="Riloff and Wiebe, 2003" startWordPosition="447" endWordPosition="450">t a product. When a user wants to collect opinions about an event, project, or social phenomenon, requests and judgments can be useful as well as sentiments. With open-domain topics, sentences expressing sentiments should not be searched exclusively; other kinds of opinion expressing sentences should be searched as well. The goal of our research is to achieve a web search engine that locates opinion-expressing sentences about open-domain topics on products, persons, events, projects, and social phenomena. Sentence-level subjectivity/objectivity classification in some of the previous research (Riloff and Wiebe, 2003; Wiebe and Riloff, 2005) can identify subjective statements that include speculation in addition to positive/negative evaluations. In these efforts, the subjectivity/objectivity of a current sentence is judged based on the existence of subjective/objective clues in both the sentence itself and the neighboring sentences. The subjective clues, some adjective, some noun, and some verb phrases, as well as other collocations, are learned from corpora (Wiebe, 2000; Wiebe et al., 2001). Some of the clues express subjective meaning unrestricted to positive/negative measurements. The sentence-level su</context>
</contexts>
<marker>Riloff, Wiebe, 2003</marker>
<rawString>Ellen Riloff and Janyce Wiebe. 2003. Learning Extraction Patterns for Subjective Expressions. Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-03), 105-112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Tateishi</author>
<author>Yoshihide Ishiguro</author>
<author>Toshikazu Fukushima</author>
</authors>
<title>A Reputation Search Engine that Collects People’s Opinions by Information Extraction Technology,</title>
<date>2004</date>
<journal>IPSJ Transactions</journal>
<volume>45</volume>
<pages>115--123</pages>
<contexts>
<context position="1727" citStr="Tateishi et al., 2004" startWordPosition="261" endWordPosition="264"> increasing number of opportunities to read opinions (personal ideas or beliefs), feelings (mental states), and sentiments (positive or negative judgments) that have been written or posted on web pages such as review sites, personal web sites, blogs, and BBSes. Such subjective information on the web can often be a useful basis for finding out what people think about a particular topic or making a decision. A number of studies on automatically extracting and analyzing product reviews or reputations on the web have been conducted (Dave et al., 2003; Morinaga et al., 2002; Nasukawa and Yi, 2003; Tateishi et al., 2004; Kobayashi et al., 2004). These studies focus on using sentiment analysis to extract positive or negative information about a particular product. Different kinds of subjective information, such as neutral opinions, requests, and judgments, which are not explicitly associated with positive/negative assessments, have not often been considered in previous work. Although sentiments provide useful information, opinion-expressing sentences like “In my opinion this product should be priced around $15,” which do not express explicitly positive or negative judgments (unlike sentiments) can also be inf</context>
</contexts>
<marker>Tateishi, Ishiguro, Fukushima, 2004</marker>
<rawString>Kenji Tateishi, Yoshihide Ishiguro, and Toshikazu Fukushima, 2004. A Reputation Search Engine that Collects People’s Opinions by Information Extraction Technology, IPSJ Transactions Vol. 45 No.SIG07, 115-123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
</authors>
<title>Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews.</title>
<date>2002</date>
<booktitle>Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL-2002),</booktitle>
<pages>417--424</pages>
<contexts>
<context position="4387" citStr="Turney, 2002" startWordPosition="655" endWordPosition="657">oach suggests a way of searching for opinion expressing sentences in the open domain. The problem of applying sentence-level subjectivity classification to opinion-expressing sentence searches is the likelihood of collecting too many sentences for a user to read. According to the work of Wiebe et al. (2001), 70% of sentences in opinion-expressing articles like editorials and 44% of sentences in non-opinion expressing articles like news reports were judged to be subjective. In analyzing opinions (Cardie et al., 2003; Wilson et al., 2004), judging document-level subjectivity (Pang et al., 2002; Turney, 2002), and answering opinion questions (Cardie et al., 2003; Yu and Hatzivassiloglou, 2003), the output of a sentence-level subjectivity classification can be used without modification. However, in searching opinion-expressing sentences, it is necessary to designate criteria for opinion-expressing sentences that limit the number of retrieved sentences so that a user can survey them without difficulty. While it is difficult to formally define an opinion, it is possible to practically tailor the definition of an opinion to the purpose of the application (Kim and Hovy, 2004). This study introduces the</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter Turney. 2002. Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews. Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL-2002), 417-424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
</authors>
<title>Learning Subjective Adjectives from Corpora.</title>
<date>2000</date>
<booktitle>Proceedings of the 17th National Conference on Artificial Intelligence (AAAI</booktitle>
<contexts>
<context position="3471" citStr="Wiebe, 2000" startWordPosition="517" endWordPosition="518">nts, projects, and social phenomena. Sentence-level subjectivity/objectivity classification in some of the previous research (Riloff and Wiebe, 2003; Wiebe and Riloff, 2005) can identify subjective statements that include speculation in addition to positive/negative evaluations. In these efforts, the subjectivity/objectivity of a current sentence is judged based on the existence of subjective/objective clues in both the sentence itself and the neighboring sentences. The subjective clues, some adjective, some noun, and some verb phrases, as well as other collocations, are learned from corpora (Wiebe, 2000; Wiebe et al., 2001). Some of the clues express subjective meaning unrestricted to positive/negative measurements. The sentence-level subjectivity ap39 Proceedings of the Workshop on Sentiment and Subjectivity in Text, pages 39–46, Sydney, July 2006. c�2006 Association for Computational Linguistics proach suggests a way of searching for opinion expressing sentences in the open domain. The problem of applying sentence-level subjectivity classification to opinion-expressing sentence searches is the likelihood of collecting too many sentences for a user to read. According to the work of Wiebe et</context>
</contexts>
<marker>Wiebe, 2000</marker>
<rawString>Janyce Wiebe. 2000. Learning Subjective Adjectives from Corpora. Proceedings of the 17th National Conference on Artificial Intelligence (AAAI -2000).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
<author>Matthew Bell</author>
</authors>
<title>Identifying Collocations for Recognizing Opinions.</title>
<date>2001</date>
<booktitle>Proceedings of ACL/EACL 2001 Workshop on Collocation.</booktitle>
<contexts>
<context position="3492" citStr="Wiebe et al., 2001" startWordPosition="519" endWordPosition="522">, and social phenomena. Sentence-level subjectivity/objectivity classification in some of the previous research (Riloff and Wiebe, 2003; Wiebe and Riloff, 2005) can identify subjective statements that include speculation in addition to positive/negative evaluations. In these efforts, the subjectivity/objectivity of a current sentence is judged based on the existence of subjective/objective clues in both the sentence itself and the neighboring sentences. The subjective clues, some adjective, some noun, and some verb phrases, as well as other collocations, are learned from corpora (Wiebe, 2000; Wiebe et al., 2001). Some of the clues express subjective meaning unrestricted to positive/negative measurements. The sentence-level subjectivity ap39 Proceedings of the Workshop on Sentiment and Subjectivity in Text, pages 39–46, Sydney, July 2006. c�2006 Association for Computational Linguistics proach suggests a way of searching for opinion expressing sentences in the open domain. The problem of applying sentence-level subjectivity classification to opinion-expressing sentence searches is the likelihood of collecting too many sentences for a user to read. According to the work of Wiebe et al. (2001), 70% of s</context>
</contexts>
<marker>Wiebe, Wilson, Bell, 2001</marker>
<rawString>Janyce Wiebe, Theresa Wilson, and Matthew Bell. 2001. Identifying Collocations for Recognizing Opinions. Proceedings of ACL/EACL 2001 Workshop on Collocation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Ellen Riloff</author>
</authors>
<title>Creating Subjective and Objective Sentence Classifiers from Unannotated Texts.</title>
<date>2005</date>
<booktitle>Proceedings of Sixth International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2005),</booktitle>
<pages>486--497</pages>
<contexts>
<context position="3033" citStr="Wiebe and Riloff, 2005" startWordPosition="451" endWordPosition="454"> wants to collect opinions about an event, project, or social phenomenon, requests and judgments can be useful as well as sentiments. With open-domain topics, sentences expressing sentiments should not be searched exclusively; other kinds of opinion expressing sentences should be searched as well. The goal of our research is to achieve a web search engine that locates opinion-expressing sentences about open-domain topics on products, persons, events, projects, and social phenomena. Sentence-level subjectivity/objectivity classification in some of the previous research (Riloff and Wiebe, 2003; Wiebe and Riloff, 2005) can identify subjective statements that include speculation in addition to positive/negative evaluations. In these efforts, the subjectivity/objectivity of a current sentence is judged based on the existence of subjective/objective clues in both the sentence itself and the neighboring sentences. The subjective clues, some adjective, some noun, and some verb phrases, as well as other collocations, are learned from corpora (Wiebe, 2000; Wiebe et al., 2001). Some of the clues express subjective meaning unrestricted to positive/negative measurements. The sentence-level subjectivity ap39 Proceedin</context>
</contexts>
<marker>Wiebe, Riloff, 2005</marker>
<rawString>Janyce Wiebe and Ellen Riloff. 2005. Creating Subjective and Objective Sentence Classifiers from Unannotated Texts. Proceedings of Sixth International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2005), 486-497.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Rebecca Hwa</author>
</authors>
<title>Just how mad are you? Finding strong and weak opinion clauses.</title>
<date>2004</date>
<booktitle>Proceeding of the AAAI Spring Symposium on Exploring Attitude and Affect in Text: Theories and Applications.</booktitle>
<contexts>
<context position="4316" citStr="Wilson et al., 2004" startWordPosition="643" endWordPosition="646"> 39–46, Sydney, July 2006. c�2006 Association for Computational Linguistics proach suggests a way of searching for opinion expressing sentences in the open domain. The problem of applying sentence-level subjectivity classification to opinion-expressing sentence searches is the likelihood of collecting too many sentences for a user to read. According to the work of Wiebe et al. (2001), 70% of sentences in opinion-expressing articles like editorials and 44% of sentences in non-opinion expressing articles like news reports were judged to be subjective. In analyzing opinions (Cardie et al., 2003; Wilson et al., 2004), judging document-level subjectivity (Pang et al., 2002; Turney, 2002), and answering opinion questions (Cardie et al., 2003; Yu and Hatzivassiloglou, 2003), the output of a sentence-level subjectivity classification can be used without modification. However, in searching opinion-expressing sentences, it is necessary to designate criteria for opinion-expressing sentences that limit the number of retrieved sentences so that a user can survey them without difficulty. While it is difficult to formally define an opinion, it is possible to practically tailor the definition of an opinion to the pur</context>
</contexts>
<marker>Wilson, Wiebe, Hwa, 2004</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Rebecca Hwa, 2004. Just how mad are you? Finding strong and weak opinion clauses. Proceeding of the AAAI Spring Symposium on Exploring Attitude and Affect in Text: Theories and Applications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hong Yu</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Towards Answering Opinion Questions: Separating Facts from Opinions and Identifying the Polarity of Opinion Sentences.</title>
<date>2003</date>
<booktitle>Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2003).</booktitle>
<contexts>
<context position="4473" citStr="Yu and Hatzivassiloglou, 2003" startWordPosition="666" endWordPosition="669">the open domain. The problem of applying sentence-level subjectivity classification to opinion-expressing sentence searches is the likelihood of collecting too many sentences for a user to read. According to the work of Wiebe et al. (2001), 70% of sentences in opinion-expressing articles like editorials and 44% of sentences in non-opinion expressing articles like news reports were judged to be subjective. In analyzing opinions (Cardie et al., 2003; Wilson et al., 2004), judging document-level subjectivity (Pang et al., 2002; Turney, 2002), and answering opinion questions (Cardie et al., 2003; Yu and Hatzivassiloglou, 2003), the output of a sentence-level subjectivity classification can be used without modification. However, in searching opinion-expressing sentences, it is necessary to designate criteria for opinion-expressing sentences that limit the number of retrieved sentences so that a user can survey them without difficulty. While it is difficult to formally define an opinion, it is possible to practically tailor the definition of an opinion to the purpose of the application (Kim and Hovy, 2004). This study introduces the notion of declaratively subjective clues as a criterion for judging whether a sentenc</context>
</contexts>
<marker>Yu, Hatzivassiloglou, 2003</marker>
<rawString>Hong Yu and Vasileios Hatzivassiloglou. 2003. Towards Answering Opinion Questions: Separating Facts from Opinions and Identifying the Polarity of Opinion Sentences. Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2003).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>