<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.999232">
Handling Ambiguities of Bilingual Predicate-Argument Structures for
Statistical Machine Translation
</title>
<author confidence="0.990508">
Feifei Zhai, Jiajun Zhang, Yu Zhou and Chengqing Zong
</author>
<affiliation confidence="0.9511575">
National Laboratory of Pattern Recognition, Institute of Automation,
Chinese Academy of Sciences, Beijing, China
</affiliation>
<email confidence="0.9839">
{ffzhai,jjzhang,yzhou,cqzong}@nlpr.ia.ac.cn
</email>
<figureCaption confidence="0.775501">
Figure 1(b), the counterpart target-side-like PAS1
</figureCaption>
<bodyText confidence="0.992618166666667">
is &lt;[X2] [X3] [X1]&gt;. This is because the two
PASs play different roles in their corresponding
sentences. Actually, Figure 1(a) is an independ-
ent PAS, while Figure 1(b) is a modifier of the
noun phrase “中国 和 俄罗斯”. We call this kind
of PAS ambiguity role ambiguity.
</bodyText>
<equation confidence="0.966979857142857">
防洪 是 首要 的 任务
[ A0 ]1 [Pred]2 [ A1 ]3
[ X1 ] [ X2 ] [ X3 ]
flood prevention is the primary mission
中国 和 俄罗斯 是 两个 大国 ,
[ A0 ]1 [Pred]2 [ A1 ]3
[X2] [ X3 ] [ X1 ]
</equation>
<bodyText confidence="0.901772">
being two major countries , China and Russia should ...
应 ...
</bodyText>
<sectionHeader confidence="0.950351" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999598611111111">
Predicate-argument structure (PAS) has been
demonstrated to be very effective in improving
SMT performance. However, since a source-
side PAS might correspond to multiple differ-
ent target-side PASs, there usually exist many
PAS ambiguities during translation. In this pa-
per, we group PAS ambiguities into two types:
role ambiguity and gap ambiguity. Then we
propose two novel methods to handle the two
PAS ambiguities for SMT accordingly: 1) in-
side context integration; 2) a novel maximum
entropy PAS disambiguation (MEPD) model.
In this way, we incorporate rich context in-
formation of PAS for disambiguation. Then
we integrate the two methods into a PAS-
based translation framework. Experiments
show that our approach helps to achieve sig-
nificant improvements on translation quality.
</bodyText>
<equation confidence="0.806654333333333">
奥运村 的 位置 对 运动员 是 最 好 的
[ A0 ]1 [Pred]2 [ A1 ]3
1 Introduction
</equation>
<bodyText confidence="0.9995108">
Predicate-argument structure (PAS) depicts the
relationship between a predicate and its associat-
ed arguments, which indicates the skeleton struc-
ture of a sentence on semantic level. Basically,
PAS agrees much better between two languages
than syntax structure (Fung et al., 2006; Wu and
Fung, 2009b). Considering that current syntax-
based translation models are always impaired by
cross-lingual structure divergence (Eisner, 2003;
Zhang et al., 2010), PAS is really a better repre-
sentation of a sentence pair to model the bilin-
gual structure mapping.
However, since a source-side PAS might
correspond to multiple different target-side PASs,
there usually exist many PAS ambiguities during
translation. For example, in Figure 1, (a) and (b)
carry the same source-side PAS &lt;[A0]1
[Pred(是)]2 [A1]3&gt; for Chinese predicate “是”.
However, in Figure 1(a), the corresponding
target-side-like PAS is &lt;[X1] [X2] [X3]&gt;, while in
</bodyText>
<figure confidence="0.466981666666667">
[ X1 ] [X2] [ X3 ]
the location of the olympic village is the best for athletes
(c)
</figure>
<figureCaption confidence="0.998949">
Figure 1. An example of ambiguous PASs.
</figureCaption>
<bodyText confidence="0.997016909090909">
Meanwhile, Figure 1 also depicts another kind
of PAS ambiguity. From Figure 1, we can see
that (a) and (c) get the same source-side PAS and
target-side-like PAS. However, they are different
because in Figure 1(c), there is a gap string “对
运动员” between [A0] and [Pred]. Generally, the
gap strings are due to the low recall of automatic
semantic role labeling (SRL) or complex sen-
tence structures. For example, in Figure 1(c), the
gap string “对 运动员” is actually an argument
“AM-PRP” of the PAS, but the SRL system has
</bodyText>
<footnote confidence="0.688255">
1We use target-side-like PAS to refer to a list of general
non-terminals in target language order, where a non-
terminal aligns to a source argument.
</footnote>
<page confidence="0.909493">
1127
</page>
<note confidence="0.9155295">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1127–1136,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.996860461538462">
ignored it. We call this kind of PAS ambiguity
gap ambiguity.
During translation, these PAS ambiguities will
greatly affect the PAS-based translation models.
Therefore, in order to incorporate the bilingual
PAS into machine translation effectively, we
need to decide which target-side-like PAS should
be chosen for a specific source-side PAS. We
call this task PAS disambiguation.
In this paper, we propose two novel methods
to incorporate rich context information to handle
PAS ambiguities. Towards the gap ambiguity,
we adopt a method called inside context
integration to extend PAS to IC-PAS. In terms of
IC-PAS, the gap strings are combined effectively
to deal with the gap ambiguities. As to the role
ambiguity, we design a novel maximum entropy
PAS disambiguation (MEPD) model to combine
various context features, such as context words
of PAS. For each ambiguous source-side PAS,
we build a specific MEPD model to select
appropriate target-side-like PAS for translation.
We will detail the two methods in Section 3 and
4 respectively.
Finally, we integrate the above two methods
into a PAS-based translation framework (Zhai et
al. 2012). Experiments show that the two PAS
disambiguation methods significantly improve
the baseline translation system. The main
contribution of this work can be concluded as
follows:
1) We define two kinds of PAS ambiguities:
role ambiguity and gap ambiguity. To our
best knowledge, we are the first to handle
these PAS ambiguities for SMT.
2) Towards the two different ambiguities, we
design two specific methods for PAS
disambiguation: inside context integration
and the novel MEPD model.
</bodyText>
<sectionHeader confidence="0.873395" genericHeader="keywords">
2 PAS-based Translation Framework
</sectionHeader>
<bodyText confidence="0.999283428571428">
PAS-based translation framework is to perform
translation based on PAS transformation (Zhai et
al., 2012). In the framework, a source-side PAS
is first converted into target-side-like PASs by
PAS transformation rules, and then perform
translation based on the obtained target-side-like
PASs.
</bodyText>
<subsectionHeader confidence="0.970125">
2.1 PAS Transformation Rules
</subsectionHeader>
<bodyText confidence="0.943641333333333">
PAS transformation rules (PASTR) are used to
convert a source-side PAS into a target one.
Formally, a PASTR is a triple &lt;Pred, SP, TP&gt;:
</bodyText>
<listItem confidence="0.991698">
• Pred means the predicate where the rule is
extracted.
• SP denotes the list of source elements in
source language order.
• TP refers to the target-side-like PAS, i.e., a
list of general non-terminals in target
language order.
</listItem>
<bodyText confidence="0.999907">
For example, Figure 2 shows the PASTR
extracted from Figure 1(a). In this PASTR, Pred
is Chinese verb “是”, SP is the source element
list &lt;[A0]1 [Pred]2 [A1]3&gt;, and TP is the list of
non-terminals &lt;X1 X2 X3&gt;. The same subscript in
SP and TP means a one-to-one mapping between
a source element and a target non-terminal. Here,
we utilize the source element to refer to the
predicate or argument of the source-side PAS.
</bodyText>
<equation confidence="0.466246">
source-side PAS(是) target-side-like PAS
[A0]1 [Pred]2 [A1]3 [X1] [X2] [X3]
</equation>
<figureCaption confidence="0.998224">
Figure 2. An example PASTR.
</figureCaption>
<subsectionHeader confidence="0.997838">
2.2 PAS Decoding
</subsectionHeader>
<bodyText confidence="0.999138">
The PAS decoding process is divided into 3 steps:
</bodyText>
<listItem confidence="0.999167">
(1) PAS acquisition: perform semantic role
labeling (SRL) on the input sentences to achieve
their PASs, i.e., source-side PASs;
(2) Transformation: use the PASTR to match
the source-side PAS i.e., the predicate Pred and
the source element list SP. Then by the matching
PASTRs, transform source-side PASs to target-
side-like PASs.
(3) Translation: in this step, the decoder first
translates each source element respectively, and
then a CKY-style decoding algorithm is adopted
to combine the translation of each element and
get the final translation of the PAS.
</listItem>
<subsectionHeader confidence="0.9819165">
2.3 Sentence Decoding with the PAS-based
translation framework
</subsectionHeader>
<bodyText confidence="0.996003769230769">
Sometimes, the source sentence cannot be fully
covered by the PAS, especially when there are
several predicates. Thus to translate the whole
sentence, Zhai et al. (2012) further designed an
algorithm to decode the entire sentence.
In the algorithm, they organized the space of
translation candidates into a hypergraph. For the
span covered by PAS (PAS span), a multiple-
branch hyperedge is employed to connect it to
the PAS’s elements. For the span not covered by
PAS (non-PAS span), the decoder considers all
the possible binary segmentations of it and uti-
lizes binary hyperedges to link them.
</bodyText>
<page confidence="0.989493">
1128
</page>
<bodyText confidence="0.999913952380952">
During translation, the decoder fills the spans
with translation candidates in a bottom-up man-
ner. For the PAS span, the PAS-based translation
framework is adopted. Otherwise, the BTG sys-
tem (Xiong et al., 2006) is used. When the span
covers the whole sentence, we get the final trans-
lation result.
Obviously, PAS ambiguities are not
considered in this framework at all. The target-
side-like PAS is selected only according to the
language model and translation probabilities,
without considering any context information of
PAS. Consequently, it would be difficult for the
decoder to distinguish the source-side PAS from
different context. This harms the translation
quality. Thus to overcome this problem, we de-
sign two novel methods to cope with the PAS
ambiguities: inside-context integration and a
maximum entropy PAS disambiguation (MEPD)
model. They will be detailed in the next two sec-
tions.
</bodyText>
<sectionHeader confidence="0.998378" genericHeader="introduction">
3 Inside Context Integration
</sectionHeader>
<bodyText confidence="0.999879875">
In this section, we integrate the inside context of
the PAS into PASTRs to do PAS disambiguation.
Basically, a PAS consists of several elements (a
predicate and several arguments), which are ac-
tually a series of continuous spans. For a specific
PAS &lt;E1,..., En&gt;, such as the source-side PAS
&lt;[A0][Pred][A1]&gt; in Figure 2, its controlled range
is defined as:
</bodyText>
<equation confidence="0.920268">
range(PAS) = {s(Ei ), i [1, � n ]} e
</equation>
<bodyText confidence="0.9996995">
where s(Ei) denotes the span of element Ei. Fur-
ther, we define the closure range of a PAS. It
refers to the shortest continuous span covered by
the entire PAS:
</bodyText>
<equation confidence="0.9731865">
closure_range =min j , max jlI
1jes(&amp;) jes(En) J
</equation>
<bodyText confidence="0.997403333333333">
Here, E0 and En are the leftmost and rightmost
element of the PAS respectively. The closure
range is introduced here because adjacent source
elements in a PAS are usually separated by gap
strings in the sentence. We call these gap strings
the inside context (IC) of the PAS, which satisfy:
closure _ range (PAS) = ®( IC(PAS)  range(PAS) )
The operator ® takes a list of neighboring spans
as input2, and returns their combined continuous
span. As an example, towards the PAS “&lt;[A0]
[Pred][A1]&gt;” (the one for Chinese predicate “是
(shi)”) in Figure 3, its controlled range is
{[3,5],[8,8],[9,11]} and its closure range is [3,11].
The IC of the PAS is thus {[6,7]}.
To consider the PAS’s IC during PAS trans-
formation process, we incorporate its IC into the
extracted PASTR. For each gap string in IC, we
abstract it by the sequence of highest node cate-
gories (named as s-tag sequence). The s-tag se-
quence dominates the corresponding syntactic
tree fragments in the parse tree. For example, in
Figure 3, the s-tag sequence for span [6,8] is “PP
VC”. Thus, the sequence for the IC (span [6,7])
in Figure 3 is “PP”. We combine the s-tag se-
quences with elements of the PAS in order. The
resulting PAS is called IC-PAS, just like the left
side of Figure 4(b) shows.
</bodyText>
<figure confidence="0.609991">
IP
</figure>
<figureCaption confidence="0.934347333333333">
Figure 3. The illustration of inside context (IC). The
subscript in each word refers to its position in sen-
tence.
</figureCaption>
<bodyText confidence="0.997219894736842">
Differently, Zhai et al. (2012) attached the IC
to its neighboring elements based on parse trees.
For example, in Figure 3, they would attach the
gap string “对(dui) 运动员(yun-dong-yuan)” to the
PAS’s element “Pred”, and then the span of
“Pred” would become [6,8]. Consequently, the
span [6,8] will be translated as a whole source
element in the decoder. This results in a bad
translation because the gap string “对(dui) 运动员
(yun-dong-yuan)” and predicate “是(shi)” should
be translated separately, just as Figure 4(a)
shows. Therefore, we can see that the attachment
decision in (Zhai et al., 2012) is sometimes un-
reasonable and the IC also cannot be used for
PAS disambiguation at all. In contrast, our meth-
2 Here, two spans are neighboring means that the beginning
of the latter span is the former span’s subsequent word in
the sentence. For example, span [3,6] and [7,10] are neigh-
boring spans.
</bodyText>
<figure confidence="0.998798518518519">
PN
他0
ta
VP
PU
。
表示1
biao-shi
,2
NP
VP
CP
DNP
PP
VC AD VA DEC
奥运村3 的4 位置5 对6 运动员7 是8 最9 好10
de wei-zhi
的11
zui hao de
ao-yun-cun
dui yun-dong-yuan shi
NN DEC NN
P NN
[ A0 ] [ PP ] [Pred] [ A1 ]
PU
IP
VV
</figure>
<page confidence="0.990306">
1129
</page>
<bodyText confidence="0.9988545">
od of inside context integration is much flexible
and beneficial for PAS disambiguation.
“[X2] [X3] [X1]” in Figure 1(b) is another label of
this classification problem.
The maximum entropy model is the classical
way to handle this problem:
</bodyText>
<figure confidence="0.970834130434782">
奥运村 的 位置 对 运动员 是 最 好 的
ao-yun-cun de wei-zhi dui yun-dong-yuan shi zui hao de
[the location of the olympic village]1 [is]3 [the best]4 [for athletes]2
(a)
[ A0 ]1 [ PP ]2 [Pred]3 [ A1 ]4
PBE
|
p,
p
,
p
Qp
c(s
)
c(t
))
exp(E B
i ihi sp tp c sp c tp
( , , ( ), ( )))
tp′ exp(E i Bihi (sp, tp, c(sp), c(tp)))
source-side PAS(是) target-side-like PAS
[A0]1 [PP]2 [Pred]3 [A1]4 [X1] [X3] [X4] [X2]
(b)
</figure>
<figureCaption confidence="0.988819666666667">
Figure 4. Example of IC-PASTR. (a) The aligned
span of each element of the PAS in Figure 3; (b) The
extracted IC-PASTR from (a).
</figureCaption>
<bodyText confidence="0.999980208333334">
Using the IC-PASs, we look for the aligned
target span for each element of the IC-PAS. We
demand that every element and its corresponding
target span must be consistent with word align-
ment. Otherwise, we discard the IC-PAS. After-
wards, we can easily extract a rule for PAS trans-
formation, which we call IC-PASTR. As an ex-
ample, Figure 4(b) is the extracted IC-PASTR
from Figure 4(a).
Note that we only apply the source-side PAS
and word alignment for IC-PASTR extraction.
By contrast, Zhai et al. (2012) utilized the result
of bilingual SRL (Zhuang and Zong, 2010b).
Generally, bilingual SRL could give a better
alignment between bilingual elements. However,
bilingual SRL usually achieves a really low re-
call on PASs, about 226,968 entries in our train-
ing set while it is 882,702 by using monolingual
SRL system. Thus to get a high recall for PASs,
we only utilize word alignment instead of captur-
ing the relation between bilingual elements. In
addition, to guarantee the accuracy of IC-
PASTRs, we only retain rules with more than 5
occurrences.
</bodyText>
<sectionHeader confidence="0.9986725" genericHeader="method">
4 Maximum Entropy PAS Disambigua-
tion (MEPD) Model
</sectionHeader>
<bodyText confidence="0.999800857142857">
In order to handle the role ambiguities, in this
section, we concentrate on utilizing a maximum
entropy model to incorporate the context infor-
mation for PAS disambiguation. Actually, the
disambiguation problem can be considered as a
multi-class classification task. That is to say, for
a source-side PAS, every corresponding target-
side-like PAS can be considered as a label. For
example, in Figure 1, for the source-side PAS
“[A0]1[Pred]2[A1]3”, the target-side-like PAS
“[X1] [X2] [X3]” in Figure 1(a) is thus a label and
where sp and tp refer to the source-side PAS (not
including the predicate) and the target-side-like
PAS respectively. c(sp) and c(tp) denote the sur-
rounding context of sp and tp. hi is a binary fea-
ture function and θi is the weight of hi.
We train a maximum entropy classifier for
each sp via the off-the-shelf MaxEnt toolkit 3.
Note that to avoid sparseness, sp does not in-
clude predicate of the PAS. Practically, the pred-
icate serves as a feature of the MEPD model. As
an example, for the rule illustrated in Figure 4(b),
we build a MEPD model for its source element
list sp &lt;[A0] [PP] [Pred] [A1]&gt;, and integrate the
predicate “是(shi)” into the MEPD model as a
feature.
In detail, we design a list of features for each
pair &lt;sp, tp&gt; as follows:
</bodyText>
<listItem confidence="0.942806">
• Lexical Features. These features include
</listItem>
<bodyText confidence="0.98568475">
the words immediately to the left and right of sp,
represented as w-1 and w+1. Moreover, the head
word of each argument also serves as a lexical
feature, named as hw(Ei). For example, Figure 3
shows the context of the IC-PASTR in Figure
4(b), and the extracted lexical features of the in-
stance are: w-1=,, w+1=。, hw([A0]1)=位 置
(wei-zhi), hw([A1]4)=好(hao).
</bodyText>
<listItem confidence="0.884059222222222">
• POS Features. These features are defined
as the POS tags of the lexical features, p-1, p+1
and phw(Ei) respectively. Thus, the correspond-
ing POS features of Figure 4 (b) are: p-1=PU,
p+1=PU, phw([A0]1)=NN, phw([A1]4)=VA.
• Predicate Feature. It is the pair of source
predicate and its corresponding target predicate.
For example, in Figure 4(b), the source and tar-
get predicate are “是(shi)” and “is” respectively.
</listItem>
<bodyText confidence="0.981451">
The predicate feature is thus “PredF=是(shi)+is”.
The target predicate is determined by:
</bodyText>
<equation confidence="0.8122824">
t pred
- = arg max ( f  |- )
p t s pred
f t range PAS
� _ ( )
</equation>
<bodyText confidence="0.8921425">
where s-pred is the source predicate and t-pred
is the corresponding target predicate.
</bodyText>
<footnote confidence="0.990984">
3http://homepages.inf.ed.ac.uk/lzhang10/maxent_toolkit.htm
l
</footnote>
<page confidence="0.988225">
1130
</page>
<bodyText confidence="0.999669863636363">
t_range(PAS) refers to the target range covering
all the words that are reachable from the PAS via
word alignment. tj refers to the jth word in
t_range(PAS). The utilized lexical translation
probabilities are from the toolkit in Moses
(Koehn et al., 2007).
 Syntax Features. These features include
st(Ei), i.e., the highest syntax tag for each argu-
ment, and fst(PAS) which is the lowest father
node of sp in the parse tree. For example, for the
rule shown in Figure 4(b), syntax features are
st([A0]1)=NP, st([A1]4)=CP, and fst(PAS)=IP
respectively.
Using these features, we can train the MEPD
model. We set the Gaussian prior to 1.0 and per-
form 100 iterations of the L-BFGS algorithm for
each MEPD model. At last, we build 160 and
215 different MEPD classifiers, respectively, for
the PASTRs and IC-PASTRs. Note that since the
training procedure of maximum entropy classifi-
er is really fast, it does not take much time to
train these classifiers.
</bodyText>
<sectionHeader confidence="0.9640235" genericHeader="method">
5 Integrating into the PAS-based Trans-
lation Framework
</sectionHeader>
<bodyText confidence="0.999985190476191">
In this section, we integrate our method of PAS
disambiguation into the PAS-based translation
framework when translating each test sentence.
For inside context integration, since the format
of IC-PASTR is the same to PASTR4, we can
use the IC-PASTR to substitute PASTR for
building a PAS-based translation system directly.
We use “IC-PASTR” to denote this system. In
addition, since our method of rule extraction is
different from (Zhai et al., 2012), we also use
PASTR to construct a translation system as the
baseline system, which we call “PASTR”.
On the basis of PASTR and IC-PASTR, we
further integrate our MEPD model into transla-
tion. Specifically, we take the score of the MEPD
model as another informative feature for the de-
coder to distinguish good target-side-like PASs
from bad ones. The weights of the MEPD feature
can be tuned by MERT (Och, 2003) together
with other translation features, such as language
model.
</bodyText>
<sectionHeader confidence="0.999971" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.9990135">
The method of PAS disambiguation for SMT is
relevant to the previous work on context depend-
</bodyText>
<footnote confidence="0.4405775">
4 The only difference between IC-PASTR and PASTR is
that there are many syntactic labels in IC-PASTRs.
</footnote>
<bodyText confidence="0.999098057142857">
ent translation.
Carpuat and Wu (2007a, 2007b) and Chan et
al. (2007) have integrated word sense disambig-
uation (WSD) and phrase sense disambiguation
(PSD) into SMT systems. They combine rich
context information to do disambiguation for
words or phrases, and achieve improved transla-
tion performance.
Differently, He et al. (2008), Liu et al. (2008)
and Cui et al. (2010) designed maximum entropy
(ME) classifiers to do better rule section for hier-
archical phrase-based model and tree-to-string
model respectively. By incorporating the rich
context information as features, they chose better
rules for translation and yielded stable improve-
ments on translation quality.
Our work differs from the above work in the
following two aspects: 1) in our work, we focus
on the problem of disambiguates on PAS; 2) we
define two kinds of PAS ambiguities: role
ambiguity and gap ambiguity. 3) towards the two
different ambiguities, we design two specific
methods for PAS disambiguation: inside context
integration and the novel MEPD model.
In addition, Xiong et al. (2012) proposed an
argument reordering model to predict the relative
position between predicates and arguments. They
also combine the context information in the
model. But they only focus on the relation be-
tween the predicate and a specific argument, ra-
ther than the entire PAS. Different from their
work, we incorporate the context information to
do PAS disambiguation based on the entire PAS.
This is very beneficial for global reordering dur-
ing translation (Zhai et al., 2012).
</bodyText>
<sectionHeader confidence="0.999569" genericHeader="evaluation">
7 Experiment
</sectionHeader>
<subsectionHeader confidence="0.997014">
7.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999976583333333">
We perform Chinese-to-English translation to
demonstrate the effectiveness of our PAS disam-
biguation method. The training data contains
about 260K sentence pairs5. To get accurate SRL
results, we ensure that the length of each sen-
tence in the training data is among 10 and 30
words. We run GIZA++ and then employ the
grow-diag-final-and (gdfa) strategy to produce
symmetric word alignments. The development
set and test set come from the NIST evaluation
test data (from 2003 to 2005). Similar to the
training set, we also only retain the sentences
</bodyText>
<footnote confidence="0.98837625">
5 It is extracted from the LDC corpus. The LDC category
number : LDC2000T50, LDC2002E18, LDC2003E07,
LDC2004T07, LDC2005T06, LDC2002L27, LDC2005T10
and LDC2005T34.
</footnote>
<page confidence="0.996433">
1131
</page>
<bodyText confidence="0.999953">
whose lengths are among 10 and 30 words. Fi-
nally, the development set includes 595 sentenc-
es from NIST MT03 and the test set contains
1,786 sentences from NIST MT04 and MT05.
We train a 5-gram language model with the
Xinhua portion of English Gigaword corpus and
target part of the training data. The translation
quality is evaluated by case-insensitive BLEU-4
with shortest length penalty. The statistical sig-
nificance test is performed by the re-sampling
approach (Koehn, 2004).
We perform SRL on the source part of the
training set, development set and test set by the
Chinese SRL system used in (Zhuang and Zong,
2010b). To relieve the negative effect of SRL
errors, we get the multiple SRL results by
providing the SRL system with 3-best parse trees
of Berkeley parser (Petrov and Klein, 2007), 1-
best parse tree of Bikel parser (Bikel, 2004) and
Stanford parser (Klein and Manning, 2003).
Therefore, at last, we can get 5 SRL result for
each sentence. For the training set, we use these
SRL results to do rule extraction respectively.
We combine the obtained rules together to get a
combined rule set. We discard the rules with
fewer than 5 appearances. Using this set, we can
train our MEPD model directly.
As to translation, we match the 5 SRL results
with transformation rules respectively, and then
apply the resulting target-side-like PASs for de-
coding. As we mentioned in section 2.3, we use
the state-of-the-art BTG system to translate the
non-PAS spans.
opment and test set all together, and it corre-
sponds to 6 different target-side-like PASs in the
training set.
As we can see from Table 1, all the top 10
PASs correspond to several different target-side-
like PASs. Moreover, according to our statistics,
among all PASs appearing in the development
set and test set, 56.7% of them carry gap strings.
These statistics demonstrate the importance of
handling the role ambiguity and gap ambiguity in
the PAS-based translation framework. Therefore,
we believe that our PAS disambiguation method
would be helpful for translation.
</bodyText>
<subsectionHeader confidence="0.996642">
7.3 Translation Result
</subsectionHeader>
<bodyText confidence="0.999290375">
We compare the translation result using PASTR,
IC-PASTR and our MEPD model in this section.
The final translation results are shown in Table 2.
As we can see, after employing PAS for transla-
tion, all systems outperform the baseline BTG
system significantly. This comparison verifies
the conclusion of (Zhai et al., 2012) and thus also
demonstrates the effectiveness of PAS.
</bodyText>
<table confidence="0.999377285714286">
MT system Test set n-gram precision
1 2 3 4
BTG 32.75 74.39 41.91 24.75 14.91
PASTR 33.24* 75.28 42.62 25.18 15.10
PASTR+MEPD 33.78* 75.32 43.08 25.75 15.58
IC-PASTR 33.95*# 75.62 43.36 25.92 15.58
IC-PASTR+MEPD 34.19*# 75.66 43.40 26.15 15.92
</table>
<tableCaption confidence="0.845348">
Table 2. Result of baseline system and the MT sys-
tems using our PAS-based disambiguation method.
The “*” and “#” denote that the result is significantly
better than BTG and PASTR respectively (p&lt;0.01).
</tableCaption>
<figure confidence="0.971813636363636">
source-side PAS counts number of classes
[A0] [Pred(A)] [A1] 245 6
[A0] [Pred(l)] [A1] 148 6
[A0] [AM-ADV] [Pred(A)] [A1] 68 20
[A0] [Pred(*ir)] [A1] 66 6
[A0] [Pred(�)] [A1] 42 6
[A0] [Pred(jA)j)] [A1] 32 4
[A0] [AM-ADV] [Pred(;J�)] [A1] 32 19
[A0] [Pred(4affi)] [A1] 29 4
[AM-ADV] [Pred(;J�)] [A1] 26 6
[A2] [Pred(�)] [A1] 16 5
</figure>
<tableCaption confidence="0.9951285">
Table 1. The top 10 frequent source-side PASs in the
dev and test set.
</tableCaption>
<subsectionHeader confidence="0.985304">
7.2 Ambiguities in Source-side PASs
</subsectionHeader>
<bodyText confidence="0.999980125">
We first give Table 1 to show some examples of
role ambiguity. In the table, for instance, the se-
cond line denotes that the source-side PAS “[A0]
[Pred(l)] [A1]” appears 148 times in the devel-
Specifically, after integrating the inside con-
text information of PAS into transformation, we
can see that system IC-PASTR significantly out-
performs system PASTR by 0.71 BLEU points.
Moreover, after we import the MEPD model into
system PASTR, we get a significant improve-
ment over PASTR (by 0.54 BLEU points). These
comparisons indicate that both the inside context
integration and our MEPD model are beneficial
for the decoder to choose better target-side-like
PAS for translation.
On the basis of IC-PASTR, we further add our
MEPD model into translation and get system IC-
PASTR+MEPD. We can see that this system
further achieves a remarkable improvement over
system PASTR (0.95 BLEU points).
However, from Table 2, we find that system
IC-PASTR+MEPD only outperforms system IC-
PASTR slightly (0.24 BLEU points). The result
seems to show that our MEPD model is not such
</bodyText>
<page confidence="0.990123">
1132
</page>
<bodyText confidence="0.811276">
useful after using IC-PASTR. We will explore
the reason in section 7.5.
</bodyText>
<subsectionHeader confidence="0.859957">
7.4 Effectiveness of Inside Context Integra-
tion
</subsectionHeader>
<bodyText confidence="0.99827925">
The method of inside context integration is used
to combine the inside context (gap strings) into
PAS for translation, i.e., extend the PASTR to
IC-PASTR. In order to demonstrate the effec-
tiveness of inside context integration, we first
give Table 3, which illustrates statistics on the
matching PASs. The statistics are conducted on
the combination of development set and test set.
</bodyText>
<table confidence="0.998853">
Transformation Matching PAS
Rules
None Gap PAS Gap PAS Total
PASTR 1702 1539 3241
IC-PASTR 1546 832 2378
</table>
<tableCaption confidence="0.999877">
Table 3. Statistics on the matching PAS.
</tableCaption>
<bodyText confidence="0.999985368421053">
In Table 3, for example, the line for PASTR
means that if we use PASTR for the combined
set, 3241 PASs (column “Total”) can match
PASTRs in total. Among these matching PASs,
1539 ones (column “Gap PAS”) carry gap strings,
while 1702 ones do not (column “None Gap
PAS”). Consequently, since PASTR does not
consider the inside context during translation, the
Gap PASs, which account for 47% (1539/3241)
of all matching PASs, might be handled inappro-
priately in the PAS-based translation framework.
Therefore, integrating the inside context into
PASTRs, i.e., using the proposed IC-PASTRs,
would be helpful for translation. The translation
result shown in Table 2 also demonstrates this
conclusion.
cific than PASTR. Therefore, for a PAS with
specific inside context (gap strings), even if the
matched PASTR is available, the matched IC-
PASTR might not. This indicates that comparing
with PASTR, IC-PASTR is more capable of dis-
tinguishing different PASs. Therefore, based on
this advantage, although the number of matching
PASs decreases, IC-PASTR still improves the
translation system using PASTR significantly. Of
course, we believe that it is also possible to inte-
grate the inside context without decreasing the
number of matching PASs and we plan this as
our future work.
We further give a translation example in Fig-
ure 5 to illustrate the effectiveness of our inside
context integration method. In the example, the
automatic SRL system ignores the long preposi-
tion phrase “对 经济复苏 、尤其是 恢复 投资信
心” for the PAS. Thus, the system using PASTRs
can only attach the long phrase to the predicate
“是” according to the parse tree, and meanwhile,
make use of a transformation rule as follows:
</bodyText>
<equation confidence="0.6489395">
source-side PAS(是) target-side-like PAS
[A0]1 [Pred]2 [A1]3 [X1] [X2] [X3]
</equation>
<bodyText confidence="0.999939875">
In this way, the translation result is very bad, just
as Figure 5(b) shows. The long preposition
phrases are wrongly positioned in the translation.
In contrast, after inside context integration, we
match the inside context during PAS transfor-
mation. As Figure 5(c) shows, the inside context
helps to selects a right transformation rule as fol-
lows and gets a good translation result finally.
</bodyText>
<equation confidence="0.85836325">
source-side PAS(是) target-side-like PAS
这 对 经济 复苏 、 尤其是 恢复 投资 信心 是 一 个 好 兆头
[ A0 ] [ PP ] [Pred] [ A1 ]
[A0]1 [PP]2 [Pred]3 [A1]4 [X1] [X3] [X4] [X2]
</equation>
<figure confidence="0.7776615">
this is [a good sign] [for economic recovery and the restoration of investors &apos; confidence]
(a) reference
这 对 经济 复苏 、 尤其是 恢复 投资 信心 是 一 个 好 兆头
(c) translation result using IC-PASTR
</figure>
<figureCaption confidence="0.9962435">
Figure 5. Translation examples to verify the effec-
tiveness of inside context.
</figureCaption>
<bodyText confidence="0.997185333333333">
From Table 3, we can also find that the num-
ber of matching PASs decreases after using IC-
PASTR. This is because IC-PASTR is more spe-
</bodyText>
<subsectionHeader confidence="0.997701">
7.5 Effectiveness of the MEPD Model
</subsectionHeader>
<bodyText confidence="0.979878285714286">
The MEPD model incorporates various context
features to select better target-side-like PAS for
translation. On the basis of PASTR and IC-
PASTR, we build 160 and 215 different MEPD
classifies, respectively, for the frequent source-
side PASs.
In Table 2, we have found that our MEPD
model improves system IC-PASTR slightly. We
conjecture that this phenomenon is due to two
possible reasons. On one hand, sometimes, many
PAS ambiguities might be resolved by both in-
side context and the MEPD model. Therefore,
the improvement would not be such significant
this [for economic recovery , especially of investment confidence is] [a good sign]
</bodyText>
<equation confidence="0.8882684">
(b) translation result using PASTR
这 对 经济 复苏 、 尤其是 恢复 投资 信心 是 一 个 好 兆头
[ A0 ] [ PP ] [Pred] [ A1 ]
this is [ a good sign ] [ for economic recovery , especially of investment confidence ]
[ A0 ] [ Pred ] [ A1 ]
</equation>
<page confidence="0.946283">
1133
</page>
<bodyText confidence="0.999830714285714">
when we combine these two methods together.
On the other hand, as Table 3 shows, the number
of matching PASs decreases after using IC-
PASTR. Since the MEPD model works on PASs,
its effectiveness would also weaken to some ex-
tent. Future work will explore this phenomenon
more thoroughly.
</bodyText>
<figure confidence="0.969832625">
... , [海牙] [是] [其 最后 一站] 。
Ref
... [the hague] [is] [his last stop] .
... , [海牙]A0 [是]Pred [其 最后 一站]A1 。
PASTR
... [is] [his last leg of] [the hague] .
... , [海牙]A0 [是]Pred [其 最后 一站]A1 。
... [the hague] [is] [the last leg] .
</figure>
<figureCaption confidence="0.981054">
Figure 6. Translation examples to demonstrate the
effectiveness of our MEPD model.
</figureCaption>
<bodyText confidence="0.926744842105263">
Now, we give Figure 6 to demonstrate the ef-
fectiveness of our MEPD model. From the Fig-
ure, we can see that the system using PASTRs
selects an inappropriate transformation rule for
translation:
source-side PAS(是) target-side-like PAS
[A0]1 [Pred]2 [A1]3 [X2] [X3] [X1]
This rule wrongly moves the subject “ 海 牙
(Hague)” to the end of the translation. We do not
give the translation result of the BTG system
here because it makes the same mistake.
Conversely, by considering the context infor-
mation, the PASTR+MEPD system chooses a
correct rule for translation:
source-side PAS(是) target-side-like PAS
[A0]1 [Pred]2 [A1]3 [X1] [X2] [X3]
As we can see, the used rule helps to keep the
SVO structure unchanged, and gets the correct
translation.
</bodyText>
<sectionHeader confidence="0.986614" genericHeader="conclusions">
8 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.99994255">
In this paper, we focus on the problem of ambi-
guities for PASs. We first propose two ambigui-
ties: gap ambiguity and role ambiguity. Accord-
ingly, we design two novel methods to do effi-
cient PAS disambiguation: inside-context inte-
gration and a novel MEPD model. For inside
context integration, we abstract the inside con-
text and combine them into the PASTRs for PAS
transformation. Towards the MEPD model, we
design a maximum entropy model for each ambi-
tious source-side PASs. The two methods suc-
cessfully incorporate the rich context information
into the translation process. Experiments show
that our PAS disambiguation methods help to
improve the translation performance significantly.
In the next step, we will conduct experiments
on other language pairs to demonstrate the effec-
tiveness of our PAS disambiguation method. In
addition, we also will try to explore more useful
and representative features for our MEPD model.
</bodyText>
<sectionHeader confidence="0.997403" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9917869">
The research work has been funded by the Hi-
Tech Research and Development Program (“863”
Program) of China under Grant No.
2011AA01A207, 2012AA011101, and
2012AA011102 and also supported by the Key
Project of Knowledge Innovation Program of
Chinese Academy of Sciences under Grant
No.KGZD-EW-501. We thank the anonymous
reviewers for their valuable comments and sug-
gestions.
</bodyText>
<sectionHeader confidence="0.997783" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996446115384616">
Wilker Aziz, Miguel Rios, and Lucia Specia. (2011).
Shallow semantic trees for smt. In Proceedings of
the Sixth Workshop on Statistical Machine Trans-
lation, pages 316–322, Edinburgh, Scotland, July.
Daniel Bikel. (2004). Intricacies of Collins parsing
model. Computational Linguistics, 30(4):480-511.
David Chiang, (2007). Hierarchical phrase-based
translation. Computational Linguistics, 33 (2):201–
228.
Marine Carpuat and Dekai Wu. 2007a. How phrase-
sense disambiguation outperforms word sense dis-
ambiguation for statistical machine translation. In
11th Conference on Theoretical and Methodologi-
cal Issues in Machine Translation, pages 43–52.
Marine Carpuat and Dekai Wu. 2007b. Improving
statistical machine translation using word sense
disambiguation. In Proceedings of EMNLP-CoNLL
2007, pages 61–72.
Yee Seng Chan, Hwee Tou Ng, and David Chiang.
2007. Word sense disambiguation improves statis-
tical machine translation. In Proc. ACL 2007, pag-
es 33–40.
Lei Cui, Dongdong Zhang, Mu Li, Ming Zhou and
Tiejun Zhao. A Joint Rule Selection Model for
Hierarchical Phrase-Based Translation. In Proc.
of ACL 2010.
</reference>
<table confidence="0.3462735">
PASTR
+ MEPD
</table>
<page confidence="0.975186">
1134
</page>
<reference confidence="0.99975480733945">
Jason Eisner. (2003). Learning non-isomorphic tree
mappings for machine translation. In Proc. of ACL
2003.
Pascale Fung, Wu Zhaojun, Yang Yongsheng, and
Dekai Wu. (2006). Automatic learning of chinese
english semantic structure mapping. In IEEE/ACL
2006 Workshop on Spoken Language Technology
(SLT 2006), Aruba, December.
Pascale Fung, Zhaojun Wu, Yongsheng Yang and
Dekai Wu. (2007). Learning bilingual semantic
frames: shallow semantic sarsing vs. semantic sole
projection. In Proceedings of the 11th Conference
on Theoretical and Methodological Issues in Ma-
chine Translation, pages 75-84.
Qin Gao and Stephan Vogel. (2011). Utilizing target-
side semantic role labels to assist hierarchical
phrase-based machine translation. In Proceedings
of Fifth Workshop on Syntax, Semantics and Struc-
ture in Statistical Translation, pages 107–115,
Portland, Oregon, USA, June 2011. Association for
Computational Linguistics
Zhongjun He, Qun Liu, and Shouxun Lin. 2008. Im-
proving statistical machine translation using lexi-
calized rule selection. In Proc. of Coling 2008,
pages 321–328.
Franz Josef Och. (2003). Minimum error rate training
in statistical machine translation. In Proc. of ACL
2003, pages 160–167.
Franz Josef Och and Hermann Ney. (2004). The
alignment template approach to statistical machine
translation. Computational Linguistics, 30:417–449.
Dan Klein and Christopher D. Manning. (2003). Ac-
curate unlexicalized parsing. In Proc. of ACL-2003,
pages 423-430.
Philipp Koehn, Franz Joseph Och, and Daniel Marcu.
(2003). Statistical phrase-based translation. In Pro-
ceedings of NAACL 2003, pages 58–54, Edmonton,
Canada, May-June.
Philipp Koehn. (2004). Statistical significance tests
for machine translation evaluation. In Proceedings
of EMNLP 2004, pages 388–395, Barcelona, Spain,
July.
P Koehn, H Hoang, A Birch, C Callison-Burch, M
Federico, N Bertoldi, B Cowan, W Shen, C Moran
and R Zens, (2007). Moses: Open source toolkit for
statistical machine translation. In Proc. of ACL
2007. pages 177–180, Prague, Czech Republic,
June. Association for Computational Linguistics.
Mamoru Komachi and Yuji Matsumoto. (2006).
Phrase reordering for statistical machine translation
based on predicate-argument structure. In Proceed-
ings of the International Workshop on Spoken
Language Translation: Evaluation Campaign on
Spoken Language Translation, pages 77–82.
Ding Liu and Daniel Gildea. (2008). Improved tree-
to-string transducer for machine Translation. In
Proceedings of the Third Workshop on Statistical
Machine Translation, pages 62–69, Columbus,
Ohio, USA, June 2008.
Ding Liu and Daniel Gildea. (2010). Semantic role
features for machine translation. In Proc. of Coling
2010, pages 716–724, Beijing, China, August.
Qun Liu, Zhongjun He, Yang Liu, and Shouxun Lin.
Maximum Entropy based Rule Selection Model for
Syntax-based Statistical Machine Translation. In
Proc. of EMNLP 2008.
Yang Liu, Qun Liu and Shouxun Lin. (2006). Tree-to-
string alignment template for statistical machine
translation. In Proc. of ACL-COLING 2006.
Daniel Marcu, Wei Wang, Abdessamad Echihabi and
Kevin Knight. (2006). SPMT: Statistical machine
translation with syntactified target language
phrases. In Proc. of EMNLP 2006, pages 44-52.
Kishore Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. (2002). Bleu: a method for automat-
ic evaluation of machine translation. In Proc. ACL
2002, pages 311–318, Philadelphia, Pennsylvania,
USA, July.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. (2006). Learning accurate, compact, and in-
terpretable tree annotation. In Proceedings of the
21st International Conference on Computational
Linguistics and 44th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 433–
440, Sydney, Australia, July. Association for Com-
putational Linguistics.
Andreas Stolcke. (2002). Srilm – an extensible lan-
guage modelling toolkit. In Proceedings of the 7th
International Conference on Spoken Language
Processing, pages 901–904, Denver, Colorado,
USA, September.
Dekai Wu and Pascale Fung. (2009a). Can semantic
role labelling improve smt. In Proceedings of the
13th Annual Conference of the EAMT, pages 218–
225, Barcelona, May.
Dekai Wu and Pascale Fung. (2009b). Semantic roles
for smt: A hybrid two-pass model. In Proc. NAACL
2009, pages 13–16, Boulder, Colorado, June.
ShuminWu and Martha Palmer. (2011). Semantic
mapping using automatic word alignment and se-
mantic role labelling. In Proceedings of Fifth
Workshop on Syntax, Semantics and Structure in
Statistical Translation, pages 21–30, Portland, Or-
egon, USA, June 2011.
Xianchao Wu, Katsuhito Sudoh, Kevin Duh, Hajime
Tsukada, and Masaaki Nagata. (2011). Extracting
preordering rules from predicate-argument struc-
tures. In Proc. IJCNLP 2011, pages 29–37, Chiang
Mai, Thailand, November.
</reference>
<page confidence="0.855559">
1135
</page>
<reference confidence="0.999718933333333">
Deyi Xiong, Qun Liu, and Shouxun Lin. (2006). Max-
imum entropy based phrase reordering model for
statistical machine translation. In Proceedings of
the 21st International Conference on Computa-
tional Linguistics and 44th Annual Meeting of the
Association for Computational Linguistics, pages
521–528, Sydney, Australia, July.
Deyi Xiong, Min Zhang, and Haizhou Li. (2012).
Modelling the translation of predicate-argument
structure for smt. In Proc. of ACL 2012, pages
902–911, Jeju, Republic of Korea, 8-14 July 2012.
Nianwen Xue. (2008). Labelling chinese predicates
with semantic roles. Computational Linguistics,
34(2): 225-255.
Feifei Zhai, Jiajun Zhang, Yu Zhou and Chengqing
Zong. Machine Translation by Modeling Predicate-
Argument Structure Transformation. In Proc. of
COLING 2012.
Hui Zhang, Min Zhang, Haizhou Li and Eng Siong
Chng. (2010). Non-isomorphic Forest Pair Transla-
tion. In Proceedings of EMNLP 2010, pages 440-
450, Massachusetts, USA, 9-11 October 2010.
Tao Zhuang, and Chengqing Zong. (2010a). A mini-
mum error weighting combination strategy for chi-
nese semantic role labelling. In Proceedings of
COLING-2010, pages 1362-1370.
Tao Zhuang and Chengqing Zong. (2010b). Joint in-
ference for bilingual semantic role labelling. In
Proceedings of EMNLP 2010, pages 304–314,
Massachusetts, USA, 9-11 October 2010.
</reference>
<page confidence="0.994385">
1136
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.055984">
<title confidence="0.9985135">Handling Ambiguities of Bilingual Predicate-Argument Structures Statistical Machine Translation</title>
<author confidence="0.633596">Feifei Zhai</author>
<author confidence="0.633596">Jiajun Zhang</author>
<author confidence="0.633596">Yu Zhou</author>
<author confidence="0.633596">Chengqing</author>
<affiliation confidence="0.995054">National Laboratory of Pattern Recognition, Institute of Automation,</affiliation>
<address confidence="0.468653">Chinese Academy of Sciences, Beijing,</address>
<email confidence="0.656737">ffzhai@nlpr.ia.ac.cn</email>
<email confidence="0.656737">jjzhang@nlpr.ia.ac.cn</email>
<email confidence="0.656737">yzhou@nlpr.ia.ac.cn</email>
<email confidence="0.656737">cqzong@nlpr.ia.ac.cn</email>
<abstract confidence="0.992084971428571">1(b), the counterpart target-side-like This is because the two PASs play different roles in their corresponding sentences. Actually, Figure 1(a) is an independent PAS, while Figure 1(b) is a modifier of the phrase 和 We call this kind PAS ambiguity 防洪 是 首要 的 任务 A0 A1 [ [ flood prevention is the primary mission 中国 和 俄罗斯 是 两个 大国 , A0 A1 [ [ two major countries , China and Russia should Abstract Predicate-argument structure (PAS) has been demonstrated to be very effective in improving SMT performance. However, since a sourceside PAS might correspond to multiple different target-side PASs, there usually exist many PAS ambiguities during translation. In this paper, we group PAS ambiguities into two types: role ambiguity and gap ambiguity. Then we propose two novel methods to handle the two PAS ambiguities for SMT accordingly: 1) inside context integration; 2) a novel maximum entropy PAS disambiguation (MEPD) model. In this way, we incorporate rich context information of PAS for disambiguation. Then we integrate the two methods into a PASbased translation framework. Experiments show that our approach helps to achieve significant improvements on translation quality. 奥运村 的 位置 对 运动员 是 最 好 的</abstract>
<intro confidence="0.273596">A0 A1</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Wilker Aziz</author>
<author>Miguel Rios</author>
<author>Lucia Specia</author>
</authors>
<title>Shallow semantic trees for smt.</title>
<date>2011</date>
<booktitle>In Proceedings of the Sixth Workshop on Statistical Machine Translation,</booktitle>
<pages>316--322</pages>
<location>Edinburgh, Scotland,</location>
<marker>Aziz, Rios, Specia, 2011</marker>
<rawString>Wilker Aziz, Miguel Rios, and Lucia Specia. (2011). Shallow semantic trees for smt. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 316–322, Edinburgh, Scotland, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Bikel</author>
</authors>
<title>Intricacies of Collins parsing model.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<pages>30--4</pages>
<contexts>
<context position="21286" citStr="Bikel, 2004" startWordPosition="3540" endWordPosition="3541">nglish Gigaword corpus and target part of the training data. The translation quality is evaluated by case-insensitive BLEU-4 with shortest length penalty. The statistical significance test is performed by the re-sampling approach (Koehn, 2004). We perform SRL on the source part of the training set, development set and test set by the Chinese SRL system used in (Zhuang and Zong, 2010b). To relieve the negative effect of SRL errors, we get the multiple SRL results by providing the SRL system with 3-best parse trees of Berkeley parser (Petrov and Klein, 2007), 1- best parse tree of Bikel parser (Bikel, 2004) and Stanford parser (Klein and Manning, 2003). Therefore, at last, we can get 5 SRL result for each sentence. For the training set, we use these SRL results to do rule extraction respectively. We combine the obtained rules together to get a combined rule set. We discard the rules with fewer than 5 appearances. Using this set, we can train our MEPD model directly. As to translation, we match the 5 SRL results with transformation rules respectively, and then apply the resulting target-side-like PASs for decoding. As we mentioned in section 2.3, we use the state-of-the-art BTG system to translat</context>
</contexts>
<marker>Bikel, 2004</marker>
<rawString>Daniel Bikel. (2004). Intricacies of Collins parsing model. Computational Linguistics, 30(4):480-511.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<pages>2--201</pages>
<marker>Chiang, 2007</marker>
<rawString>David Chiang, (2007). Hierarchical phrase-based translation. Computational Linguistics, 33 (2):201– 228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>How phrasesense disambiguation outperforms word sense disambiguation for statistical machine translation.</title>
<date>2007</date>
<booktitle>In 11th Conference on Theoretical and Methodological Issues in Machine Translation,</booktitle>
<pages>43--52</pages>
<contexts>
<context position="18186" citStr="Carpuat and Wu (2007" startWordPosition="3041" endWordPosition="3044">n the basis of PASTR and IC-PASTR, we further integrate our MEPD model into translation. Specifically, we take the score of the MEPD model as another informative feature for the decoder to distinguish good target-side-like PASs from bad ones. The weights of the MEPD feature can be tuned by MERT (Och, 2003) together with other translation features, such as language model. 6 Related Work The method of PAS disambiguation for SMT is relevant to the previous work on context depend4 The only difference between IC-PASTR and PASTR is that there are many syntactic labels in IC-PASTRs. ent translation. Carpuat and Wu (2007a, 2007b) and Chan et al. (2007) have integrated word sense disambiguation (WSD) and phrase sense disambiguation (PSD) into SMT systems. They combine rich context information to do disambiguation for words or phrases, and achieve improved translation performance. Differently, He et al. (2008), Liu et al. (2008) and Cui et al. (2010) designed maximum entropy (ME) classifiers to do better rule section for hierarchical phrase-based model and tree-to-string model respectively. By incorporating the rich context information as features, they chose better rules for translation and yielded stable impr</context>
</contexts>
<marker>Carpuat, Wu, 2007</marker>
<rawString>Marine Carpuat and Dekai Wu. 2007a. How phrasesense disambiguation outperforms word sense disambiguation for statistical machine translation. In 11th Conference on Theoretical and Methodological Issues in Machine Translation, pages 43–52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>Improving statistical machine translation using word sense disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL</booktitle>
<pages>61--72</pages>
<contexts>
<context position="18186" citStr="Carpuat and Wu (2007" startWordPosition="3041" endWordPosition="3044">n the basis of PASTR and IC-PASTR, we further integrate our MEPD model into translation. Specifically, we take the score of the MEPD model as another informative feature for the decoder to distinguish good target-side-like PASs from bad ones. The weights of the MEPD feature can be tuned by MERT (Och, 2003) together with other translation features, such as language model. 6 Related Work The method of PAS disambiguation for SMT is relevant to the previous work on context depend4 The only difference between IC-PASTR and PASTR is that there are many syntactic labels in IC-PASTRs. ent translation. Carpuat and Wu (2007a, 2007b) and Chan et al. (2007) have integrated word sense disambiguation (WSD) and phrase sense disambiguation (PSD) into SMT systems. They combine rich context information to do disambiguation for words or phrases, and achieve improved translation performance. Differently, He et al. (2008), Liu et al. (2008) and Cui et al. (2010) designed maximum entropy (ME) classifiers to do better rule section for hierarchical phrase-based model and tree-to-string model respectively. By incorporating the rich context information as features, they chose better rules for translation and yielded stable impr</context>
</contexts>
<marker>Carpuat, Wu, 2007</marker>
<rawString>Marine Carpuat and Dekai Wu. 2007b. Improving statistical machine translation using word sense disambiguation. In Proceedings of EMNLP-CoNLL 2007, pages 61–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Seng Chan</author>
<author>Hwee Tou Ng</author>
<author>David Chiang</author>
</authors>
<title>Word sense disambiguation improves statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proc. ACL</booktitle>
<pages>33--40</pages>
<contexts>
<context position="18218" citStr="Chan et al. (2007)" startWordPosition="3047" endWordPosition="3050"> we further integrate our MEPD model into translation. Specifically, we take the score of the MEPD model as another informative feature for the decoder to distinguish good target-side-like PASs from bad ones. The weights of the MEPD feature can be tuned by MERT (Och, 2003) together with other translation features, such as language model. 6 Related Work The method of PAS disambiguation for SMT is relevant to the previous work on context depend4 The only difference between IC-PASTR and PASTR is that there are many syntactic labels in IC-PASTRs. ent translation. Carpuat and Wu (2007a, 2007b) and Chan et al. (2007) have integrated word sense disambiguation (WSD) and phrase sense disambiguation (PSD) into SMT systems. They combine rich context information to do disambiguation for words or phrases, and achieve improved translation performance. Differently, He et al. (2008), Liu et al. (2008) and Cui et al. (2010) designed maximum entropy (ME) classifiers to do better rule section for hierarchical phrase-based model and tree-to-string model respectively. By incorporating the rich context information as features, they chose better rules for translation and yielded stable improvements on translation quality.</context>
</contexts>
<marker>Chan, Ng, Chiang, 2007</marker>
<rawString>Yee Seng Chan, Hwee Tou Ng, and David Chiang. 2007. Word sense disambiguation improves statistical machine translation. In Proc. ACL 2007, pages 33–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Cui</author>
<author>Dongdong Zhang</author>
<author>Mu Li</author>
</authors>
<title>Ming Zhou and Tiejun Zhao. A Joint Rule Selection Model for Hierarchical Phrase-Based Translation.</title>
<date>2010</date>
<booktitle>In Proc. of ACL</booktitle>
<contexts>
<context position="18520" citStr="Cui et al. (2010)" startWordPosition="3094" endWordPosition="3097">on features, such as language model. 6 Related Work The method of PAS disambiguation for SMT is relevant to the previous work on context depend4 The only difference between IC-PASTR and PASTR is that there are many syntactic labels in IC-PASTRs. ent translation. Carpuat and Wu (2007a, 2007b) and Chan et al. (2007) have integrated word sense disambiguation (WSD) and phrase sense disambiguation (PSD) into SMT systems. They combine rich context information to do disambiguation for words or phrases, and achieve improved translation performance. Differently, He et al. (2008), Liu et al. (2008) and Cui et al. (2010) designed maximum entropy (ME) classifiers to do better rule section for hierarchical phrase-based model and tree-to-string model respectively. By incorporating the rich context information as features, they chose better rules for translation and yielded stable improvements on translation quality. Our work differs from the above work in the following two aspects: 1) in our work, we focus on the problem of disambiguates on PAS; 2) we define two kinds of PAS ambiguities: role ambiguity and gap ambiguity. 3) towards the two different ambiguities, we design two specific methods for PAS disambiguat</context>
</contexts>
<marker>Cui, Zhang, Li, 2010</marker>
<rawString>Lei Cui, Dongdong Zhang, Mu Li, Ming Zhou and Tiejun Zhao. A Joint Rule Selection Model for Hierarchical Phrase-Based Translation. In Proc. of ACL 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Learning non-isomorphic tree mappings for machine translation.</title>
<date>2003</date>
<booktitle>In Proc. of ACL</booktitle>
<contexts>
<context position="2129" citStr="Eisner, 2003" startWordPosition="345" endWordPosition="346">anslation framework. Experiments show that our approach helps to achieve significant improvements on translation quality. 奥运村 的 位置 对 运动员 是 最 好 的 [ A0 ]1 [Pred]2 [ A1 ]3 1 Introduction Predicate-argument structure (PAS) depicts the relationship between a predicate and its associated arguments, which indicates the skeleton structure of a sentence on semantic level. Basically, PAS agrees much better between two languages than syntax structure (Fung et al., 2006; Wu and Fung, 2009b). Considering that current syntaxbased translation models are always impaired by cross-lingual structure divergence (Eisner, 2003; Zhang et al., 2010), PAS is really a better representation of a sentence pair to model the bilingual structure mapping. However, since a source-side PAS might correspond to multiple different target-side PASs, there usually exist many PAS ambiguities during translation. For example, in Figure 1, (a) and (b) carry the same source-side PAS &lt;[A0]1 [Pred(是)]2 [A1]3&gt; for Chinese predicate “是”. However, in Figure 1(a), the corresponding target-side-like PAS is &lt;[X1] [X2] [X3]&gt;, while in [ X1 ] [X2] [ X3 ] the location of the olympic village is the best for athletes (c) Figure 1. An example of ambi</context>
</contexts>
<marker>Eisner, 2003</marker>
<rawString>Jason Eisner. (2003). Learning non-isomorphic tree mappings for machine translation. In Proc. of ACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Wu Zhaojun</author>
<author>Yang Yongsheng</author>
<author>Dekai Wu</author>
</authors>
<title>Automatic learning of chinese english semantic structure mapping.</title>
<date>2006</date>
<booktitle>In IEEE/ACL 2006 Workshop on Spoken Language Technology (SLT</booktitle>
<location>Aruba,</location>
<contexts>
<context position="1979" citStr="Fung et al., 2006" startWordPosition="323" endWordPosition="326">iguation (MEPD) model. In this way, we incorporate rich context information of PAS for disambiguation. Then we integrate the two methods into a PASbased translation framework. Experiments show that our approach helps to achieve significant improvements on translation quality. 奥运村 的 位置 对 运动员 是 最 好 的 [ A0 ]1 [Pred]2 [ A1 ]3 1 Introduction Predicate-argument structure (PAS) depicts the relationship between a predicate and its associated arguments, which indicates the skeleton structure of a sentence on semantic level. Basically, PAS agrees much better between two languages than syntax structure (Fung et al., 2006; Wu and Fung, 2009b). Considering that current syntaxbased translation models are always impaired by cross-lingual structure divergence (Eisner, 2003; Zhang et al., 2010), PAS is really a better representation of a sentence pair to model the bilingual structure mapping. However, since a source-side PAS might correspond to multiple different target-side PASs, there usually exist many PAS ambiguities during translation. For example, in Figure 1, (a) and (b) carry the same source-side PAS &lt;[A0]1 [Pred(是)]2 [A1]3&gt; for Chinese predicate “是”. However, in Figure 1(a), the corresponding target-side-l</context>
</contexts>
<marker>Fung, Zhaojun, Yongsheng, Wu, 2006</marker>
<rawString>Pascale Fung, Wu Zhaojun, Yang Yongsheng, and Dekai Wu. (2006). Automatic learning of chinese english semantic structure mapping. In IEEE/ACL 2006 Workshop on Spoken Language Technology (SLT 2006), Aruba, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Zhaojun Wu</author>
<author>Yongsheng Yang</author>
<author>Dekai Wu</author>
</authors>
<title>Learning bilingual semantic frames: shallow semantic sarsing vs. semantic sole projection.</title>
<date>2007</date>
<booktitle>In Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation,</booktitle>
<pages>75--84</pages>
<marker>Fung, Wu, Yang, Wu, 2007</marker>
<rawString>Pascale Fung, Zhaojun Wu, Yongsheng Yang and Dekai Wu. (2007). Learning bilingual semantic frames: shallow semantic sarsing vs. semantic sole projection. In Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation, pages 75-84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qin Gao</author>
<author>Stephan Vogel</author>
</authors>
<title>Utilizing targetside semantic role labels to assist hierarchical phrase-based machine translation.</title>
<date>2011</date>
<journal>Association for Computational Linguistics</journal>
<booktitle>In Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation,</booktitle>
<pages>107--115</pages>
<location>Portland, Oregon, USA,</location>
<marker>Gao, Vogel, 2011</marker>
<rawString>Qin Gao and Stephan Vogel. (2011). Utilizing targetside semantic role labels to assist hierarchical phrase-based machine translation. In Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 107–115, Portland, Oregon, USA, June 2011. Association for Computational Linguistics</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhongjun He</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Improving statistical machine translation using lexicalized rule selection.</title>
<date>2008</date>
<booktitle>In Proc. of Coling</booktitle>
<pages>321--328</pages>
<contexts>
<context position="18479" citStr="He et al. (2008)" startWordPosition="3085" endWordPosition="3088">Och, 2003) together with other translation features, such as language model. 6 Related Work The method of PAS disambiguation for SMT is relevant to the previous work on context depend4 The only difference between IC-PASTR and PASTR is that there are many syntactic labels in IC-PASTRs. ent translation. Carpuat and Wu (2007a, 2007b) and Chan et al. (2007) have integrated word sense disambiguation (WSD) and phrase sense disambiguation (PSD) into SMT systems. They combine rich context information to do disambiguation for words or phrases, and achieve improved translation performance. Differently, He et al. (2008), Liu et al. (2008) and Cui et al. (2010) designed maximum entropy (ME) classifiers to do better rule section for hierarchical phrase-based model and tree-to-string model respectively. By incorporating the rich context information as features, they chose better rules for translation and yielded stable improvements on translation quality. Our work differs from the above work in the following two aspects: 1) in our work, we focus on the problem of disambiguates on PAS; 2) we define two kinds of PAS ambiguities: role ambiguity and gap ambiguity. 3) towards the two different ambiguities, we design</context>
</contexts>
<marker>He, Liu, Lin, 2008</marker>
<rawString>Zhongjun He, Qun Liu, and Shouxun Lin. 2008. Improving statistical machine translation using lexicalized rule selection. In Proc. of Coling 2008, pages 321–328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proc. of ACL</booktitle>
<pages>160--167</pages>
<contexts>
<context position="17873" citStr="Och, 2003" startWordPosition="2992" endWordPosition="2993">to substitute PASTR for building a PAS-based translation system directly. We use “IC-PASTR” to denote this system. In addition, since our method of rule extraction is different from (Zhai et al., 2012), we also use PASTR to construct a translation system as the baseline system, which we call “PASTR”. On the basis of PASTR and IC-PASTR, we further integrate our MEPD model into translation. Specifically, we take the score of the MEPD model as another informative feature for the decoder to distinguish good target-side-like PASs from bad ones. The weights of the MEPD feature can be tuned by MERT (Och, 2003) together with other translation features, such as language model. 6 Related Work The method of PAS disambiguation for SMT is relevant to the previous work on context depend4 The only difference between IC-PASTR and PASTR is that there are many syntactic labels in IC-PASTRs. ent translation. Carpuat and Wu (2007a, 2007b) and Chan et al. (2007) have integrated word sense disambiguation (WSD) and phrase sense disambiguation (PSD) into SMT systems. They combine rich context information to do disambiguation for words or phrases, and achieve improved translation performance. Differently, He et al. </context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. (2003). Minimum error rate training in statistical machine translation. In Proc. of ACL 2003, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>The alignment template approach to statistical machine translation.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<pages>30--417</pages>
<marker>Och, Ney, 2004</marker>
<rawString>Franz Josef Och and Hermann Ney. (2004). The alignment template approach to statistical machine translation. Computational Linguistics, 30:417–449.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proc. of ACL-2003,</booktitle>
<pages>423--430</pages>
<contexts>
<context position="21332" citStr="Klein and Manning, 2003" startWordPosition="3545" endWordPosition="3548">part of the training data. The translation quality is evaluated by case-insensitive BLEU-4 with shortest length penalty. The statistical significance test is performed by the re-sampling approach (Koehn, 2004). We perform SRL on the source part of the training set, development set and test set by the Chinese SRL system used in (Zhuang and Zong, 2010b). To relieve the negative effect of SRL errors, we get the multiple SRL results by providing the SRL system with 3-best parse trees of Berkeley parser (Petrov and Klein, 2007), 1- best parse tree of Bikel parser (Bikel, 2004) and Stanford parser (Klein and Manning, 2003). Therefore, at last, we can get 5 SRL result for each sentence. For the training set, we use these SRL results to do rule extraction respectively. We combine the obtained rules together to get a combined rule set. We discard the rules with fewer than 5 appearances. Using this set, we can train our MEPD model directly. As to translation, we match the 5 SRL results with transformation rules respectively, and then apply the resulting target-side-like PASs for decoding. As we mentioned in section 2.3, we use the state-of-the-art BTG system to translate the non-PAS spans. opment and test set all t</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. (2003). Accurate unlexicalized parsing. In Proc. of ACL-2003, pages 423-430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Joseph Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of NAACL 2003,</booktitle>
<pages>58--54</pages>
<location>Edmonton, Canada, May-June.</location>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Joseph Och, and Daniel Marcu. (2003). Statistical phrase-based translation. In Proceedings of NAACL 2003, pages 58–54, Edmonton, Canada, May-June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP 2004,</booktitle>
<pages>388--395</pages>
<location>Barcelona, Spain,</location>
<contexts>
<context position="20917" citStr="Koehn, 2004" startWordPosition="3474" endWordPosition="3475">s. The LDC category number : LDC2000T50, LDC2002E18, LDC2003E07, LDC2004T07, LDC2005T06, LDC2002L27, LDC2005T10 and LDC2005T34. 1131 whose lengths are among 10 and 30 words. Finally, the development set includes 595 sentences from NIST MT03 and the test set contains 1,786 sentences from NIST MT04 and MT05. We train a 5-gram language model with the Xinhua portion of English Gigaword corpus and target part of the training data. The translation quality is evaluated by case-insensitive BLEU-4 with shortest length penalty. The statistical significance test is performed by the re-sampling approach (Koehn, 2004). We perform SRL on the source part of the training set, development set and test set by the Chinese SRL system used in (Zhuang and Zong, 2010b). To relieve the negative effect of SRL errors, we get the multiple SRL results by providing the SRL system with 3-best parse trees of Berkeley parser (Petrov and Klein, 2007), 1- best parse tree of Bikel parser (Bikel, 2004) and Stanford parser (Klein and Manning, 2003). Therefore, at last, we can get 5 SRL result for each sentence. For the training set, we use these SRL results to do rule extraction respectively. We combine the obtained rules togethe</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. (2004). Statistical significance tests for machine translation evaluation. In Proceedings of EMNLP 2004, pages 388–395, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proc. of ACL</booktitle>
<pages>177--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="16265" citStr="Koehn et al., 2007" startWordPosition="2724" endWordPosition="2727">urce and target predicate are “是(shi)” and “is” respectively. The predicate feature is thus “PredF=是(shi)+is”. The target predicate is determined by: t pred - = arg max ( f |- ) p t s pred f t range PAS � _ ( ) where s-pred is the source predicate and t-pred is the corresponding target predicate. 3http://homepages.inf.ed.ac.uk/lzhang10/maxent_toolkit.htm l 1130 t_range(PAS) refers to the target range covering all the words that are reachable from the PAS via word alignment. tj refers to the jth word in t_range(PAS). The utilized lexical translation probabilities are from the toolkit in Moses (Koehn et al., 2007).  Syntax Features. These features include st(Ei), i.e., the highest syntax tag for each argument, and fst(PAS) which is the lowest father node of sp in the parse tree. For example, for the rule shown in Figure 4(b), syntax features are st([A0]1)=NP, st([A1]4)=CP, and fst(PAS)=IP respectively. Using these features, we can train the MEPD model. We set the Gaussian prior to 1.0 and perform 100 iterations of the L-BFGS algorithm for each MEPD model. At last, we build 160 and 215 different MEPD classifiers, respectively, for the PASTRs and IC-PASTRs. Note that since the training procedure of maxi</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 2007</marker>
<rawString>P Koehn, H Hoang, A Birch, C Callison-Burch, M Federico, N Bertoldi, B Cowan, W Shen, C Moran and R Zens, (2007). Moses: Open source toolkit for statistical machine translation. In Proc. of ACL 2007. pages 177–180, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mamoru Komachi</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Phrase reordering for statistical machine translation based on predicate-argument structure.</title>
<date>2006</date>
<booktitle>In Proceedings of the International Workshop on Spoken Language Translation: Evaluation Campaign on Spoken Language Translation,</booktitle>
<pages>77--82</pages>
<marker>Komachi, Matsumoto, 2006</marker>
<rawString>Mamoru Komachi and Yuji Matsumoto. (2006). Phrase reordering for statistical machine translation based on predicate-argument structure. In Proceedings of the International Workshop on Spoken Language Translation: Evaluation Campaign on Spoken Language Translation, pages 77–82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ding Liu</author>
<author>Daniel Gildea</author>
</authors>
<title>Improved treeto-string transducer for machine Translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third Workshop on Statistical Machine Translation,</booktitle>
<pages>62--69</pages>
<location>Columbus, Ohio, USA,</location>
<marker>Liu, Gildea, 2008</marker>
<rawString>Ding Liu and Daniel Gildea. (2008). Improved treeto-string transducer for machine Translation. In Proceedings of the Third Workshop on Statistical Machine Translation, pages 62–69, Columbus, Ohio, USA, June 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ding Liu</author>
<author>Daniel Gildea</author>
</authors>
<title>Semantic role features for machine translation.</title>
<date>2010</date>
<booktitle>In Proc. of Coling</booktitle>
<pages>716--724</pages>
<location>Beijing, China,</location>
<marker>Liu, Gildea, 2010</marker>
<rawString>Ding Liu and Daniel Gildea. (2010). Semantic role features for machine translation. In Proc. of Coling 2010, pages 716–724, Beijing, China, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qun Liu</author>
<author>Zhongjun He</author>
<author>Yang Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Maximum Entropy based Rule Selection Model for Syntax-based Statistical Machine Translation.</title>
<date>2008</date>
<booktitle>In Proc. of EMNLP</booktitle>
<contexts>
<context position="18498" citStr="Liu et al. (2008)" startWordPosition="3089" endWordPosition="3092">r with other translation features, such as language model. 6 Related Work The method of PAS disambiguation for SMT is relevant to the previous work on context depend4 The only difference between IC-PASTR and PASTR is that there are many syntactic labels in IC-PASTRs. ent translation. Carpuat and Wu (2007a, 2007b) and Chan et al. (2007) have integrated word sense disambiguation (WSD) and phrase sense disambiguation (PSD) into SMT systems. They combine rich context information to do disambiguation for words or phrases, and achieve improved translation performance. Differently, He et al. (2008), Liu et al. (2008) and Cui et al. (2010) designed maximum entropy (ME) classifiers to do better rule section for hierarchical phrase-based model and tree-to-string model respectively. By incorporating the rich context information as features, they chose better rules for translation and yielded stable improvements on translation quality. Our work differs from the above work in the following two aspects: 1) in our work, we focus on the problem of disambiguates on PAS; 2) we define two kinds of PAS ambiguities: role ambiguity and gap ambiguity. 3) towards the two different ambiguities, we design two specific metho</context>
</contexts>
<marker>Liu, He, Liu, Lin, 2008</marker>
<rawString>Qun Liu, Zhongjun He, Yang Liu, and Shouxun Lin. Maximum Entropy based Rule Selection Model for Syntax-based Statistical Machine Translation. In Proc. of EMNLP 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Tree-tostring alignment template for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proc. of ACL-COLING</booktitle>
<marker>Liu, Liu, Lin, 2006</marker>
<rawString>Yang Liu, Qun Liu and Shouxun Lin. (2006). Tree-tostring alignment template for statistical machine translation. In Proc. of ACL-COLING 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>Wei Wang</author>
<author>Abdessamad Echihabi</author>
<author>Kevin Knight</author>
</authors>
<title>SPMT: Statistical machine translation with syntactified target language phrases.</title>
<date>2006</date>
<booktitle>In Proc. of EMNLP</booktitle>
<pages>44--52</pages>
<marker>Marcu, Wang, Echihabi, Knight, 2006</marker>
<rawString>Daniel Marcu, Wei Wang, Abdessamad Echihabi and Kevin Knight. (2006). SPMT: Statistical machine translation with syntactified target language phrases. In Proc. of EMNLP 2006, pages 44-52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proc. ACL 2002,</booktitle>
<pages>311--318</pages>
<location>Philadelphia, Pennsylvania, USA,</location>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. (2002). Bleu: a method for automatic evaluation of machine translation. In Proc. ACL 2002, pages 311–318, Philadelphia, Pennsylvania, USA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Leon Barrett</author>
<author>Romain Thibaux</author>
<author>Dan Klein</author>
</authors>
<title>Learning accurate, compact, and interpretable tree annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>433--440</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<marker>Petrov, Barrett, Thibaux, Klein, 2006</marker>
<rawString>Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. (2006). Learning accurate, compact, and interpretable tree annotation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 433– 440, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>Srilm – an extensible language modelling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the 7th International Conference on Spoken Language Processing,</booktitle>
<pages>901--904</pages>
<location>Denver, Colorado, USA,</location>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. (2002). Srilm – an extensible language modelling toolkit. In Proceedings of the 7th International Conference on Spoken Language Processing, pages 901–904, Denver, Colorado, USA, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>Pascale Fung</author>
</authors>
<title>Can semantic role labelling improve smt.</title>
<date>2009</date>
<booktitle>In Proceedings of the 13th Annual Conference of the EAMT,</booktitle>
<pages>218--225</pages>
<location>Barcelona,</location>
<contexts>
<context position="1998" citStr="Wu and Fung, 2009" startWordPosition="327" endWordPosition="330">el. In this way, we incorporate rich context information of PAS for disambiguation. Then we integrate the two methods into a PASbased translation framework. Experiments show that our approach helps to achieve significant improvements on translation quality. 奥运村 的 位置 对 运动员 是 最 好 的 [ A0 ]1 [Pred]2 [ A1 ]3 1 Introduction Predicate-argument structure (PAS) depicts the relationship between a predicate and its associated arguments, which indicates the skeleton structure of a sentence on semantic level. Basically, PAS agrees much better between two languages than syntax structure (Fung et al., 2006; Wu and Fung, 2009b). Considering that current syntaxbased translation models are always impaired by cross-lingual structure divergence (Eisner, 2003; Zhang et al., 2010), PAS is really a better representation of a sentence pair to model the bilingual structure mapping. However, since a source-side PAS might correspond to multiple different target-side PASs, there usually exist many PAS ambiguities during translation. For example, in Figure 1, (a) and (b) carry the same source-side PAS &lt;[A0]1 [Pred(是)]2 [A1]3&gt; for Chinese predicate “是”. However, in Figure 1(a), the corresponding target-side-like PAS is &lt;[X1] [X</context>
</contexts>
<marker>Wu, Fung, 2009</marker>
<rawString>Dekai Wu and Pascale Fung. (2009a). Can semantic role labelling improve smt. In Proceedings of the 13th Annual Conference of the EAMT, pages 218– 225, Barcelona, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>Pascale Fung</author>
</authors>
<title>Semantic roles for smt: A hybrid two-pass model.</title>
<date>2009</date>
<booktitle>In Proc. NAACL 2009,</booktitle>
<pages>13--16</pages>
<location>Boulder, Colorado,</location>
<contexts>
<context position="1998" citStr="Wu and Fung, 2009" startWordPosition="327" endWordPosition="330">el. In this way, we incorporate rich context information of PAS for disambiguation. Then we integrate the two methods into a PASbased translation framework. Experiments show that our approach helps to achieve significant improvements on translation quality. 奥运村 的 位置 对 运动员 是 最 好 的 [ A0 ]1 [Pred]2 [ A1 ]3 1 Introduction Predicate-argument structure (PAS) depicts the relationship between a predicate and its associated arguments, which indicates the skeleton structure of a sentence on semantic level. Basically, PAS agrees much better between two languages than syntax structure (Fung et al., 2006; Wu and Fung, 2009b). Considering that current syntaxbased translation models are always impaired by cross-lingual structure divergence (Eisner, 2003; Zhang et al., 2010), PAS is really a better representation of a sentence pair to model the bilingual structure mapping. However, since a source-side PAS might correspond to multiple different target-side PASs, there usually exist many PAS ambiguities during translation. For example, in Figure 1, (a) and (b) carry the same source-side PAS &lt;[A0]1 [Pred(是)]2 [A1]3&gt; for Chinese predicate “是”. However, in Figure 1(a), the corresponding target-side-like PAS is &lt;[X1] [X</context>
</contexts>
<marker>Wu, Fung, 2009</marker>
<rawString>Dekai Wu and Pascale Fung. (2009b). Semantic roles for smt: A hybrid two-pass model. In Proc. NAACL 2009, pages 13–16, Boulder, Colorado, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ShuminWu</author>
<author>Martha Palmer</author>
</authors>
<title>Semantic mapping using automatic word alignment and semantic role labelling.</title>
<date>2011</date>
<booktitle>In Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation,</booktitle>
<pages>21--30</pages>
<location>Portland, Oregon, USA,</location>
<marker>ShuminWu, Palmer, 2011</marker>
<rawString>ShuminWu and Martha Palmer. (2011). Semantic mapping using automatic word alignment and semantic role labelling. In Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 21–30, Portland, Oregon, USA, June 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xianchao Wu</author>
<author>Katsuhito Sudoh</author>
<author>Kevin Duh</author>
<author>Hajime Tsukada</author>
<author>Masaaki Nagata</author>
</authors>
<title>Extracting preordering rules from predicate-argument structures.</title>
<date>2011</date>
<booktitle>In Proc. IJCNLP 2011,</booktitle>
<pages>29--37</pages>
<location>Chiang Mai, Thailand,</location>
<marker>Wu, Sudoh, Duh, Tsukada, Nagata, 2011</marker>
<rawString>Xianchao Wu, Katsuhito Sudoh, Kevin Duh, Hajime Tsukada, and Masaaki Nagata. (2011). Extracting preordering rules from predicate-argument structures. In Proc. IJCNLP 2011, pages 29–37, Chiang Mai, Thailand, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deyi Xiong</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Maximum entropy based phrase reordering model for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>521--528</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="7965" citStr="Xiong et al., 2006" startWordPosition="1279" endWordPosition="1282">lgorithm to decode the entire sentence. In the algorithm, they organized the space of translation candidates into a hypergraph. For the span covered by PAS (PAS span), a multiplebranch hyperedge is employed to connect it to the PAS’s elements. For the span not covered by PAS (non-PAS span), the decoder considers all the possible binary segmentations of it and utilizes binary hyperedges to link them. 1128 During translation, the decoder fills the spans with translation candidates in a bottom-up manner. For the PAS span, the PAS-based translation framework is adopted. Otherwise, the BTG system (Xiong et al., 2006) is used. When the span covers the whole sentence, we get the final translation result. Obviously, PAS ambiguities are not considered in this framework at all. The targetside-like PAS is selected only according to the language model and translation probabilities, without considering any context information of PAS. Consequently, it would be difficult for the decoder to distinguish the source-side PAS from different context. This harms the translation quality. Thus to overcome this problem, we design two novel methods to cope with the PAS ambiguities: inside-context integration and a maximum ent</context>
</contexts>
<marker>Xiong, Liu, Lin, 2006</marker>
<rawString>Deyi Xiong, Qun Liu, and Shouxun Lin. (2006). Maximum entropy based phrase reordering model for statistical machine translation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 521–528, Sydney, Australia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deyi Xiong</author>
<author>Min Zhang</author>
<author>Haizhou Li</author>
</authors>
<title>Modelling the translation of predicate-argument structure for smt.</title>
<date>2012</date>
<booktitle>In Proc. of ACL 2012,</booktitle>
<pages>902--911</pages>
<location>Jeju, Republic of</location>
<contexts>
<context position="19210" citStr="Xiong et al. (2012)" startWordPosition="3201" endWordPosition="3204">r hierarchical phrase-based model and tree-to-string model respectively. By incorporating the rich context information as features, they chose better rules for translation and yielded stable improvements on translation quality. Our work differs from the above work in the following two aspects: 1) in our work, we focus on the problem of disambiguates on PAS; 2) we define two kinds of PAS ambiguities: role ambiguity and gap ambiguity. 3) towards the two different ambiguities, we design two specific methods for PAS disambiguation: inside context integration and the novel MEPD model. In addition, Xiong et al. (2012) proposed an argument reordering model to predict the relative position between predicates and arguments. They also combine the context information in the model. But they only focus on the relation between the predicate and a specific argument, rather than the entire PAS. Different from their work, we incorporate the context information to do PAS disambiguation based on the entire PAS. This is very beneficial for global reordering during translation (Zhai et al., 2012). 7 Experiment 7.1 Experimental Setup We perform Chinese-to-English translation to demonstrate the effectiveness of our PAS dis</context>
</contexts>
<marker>Xiong, Zhang, Li, 2012</marker>
<rawString>Deyi Xiong, Min Zhang, and Haizhou Li. (2012). Modelling the translation of predicate-argument structure for smt. In Proc. of ACL 2012, pages 902–911, Jeju, Republic of Korea, 8-14 July 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
</authors>
<title>Labelling chinese predicates with semantic roles.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>2</issue>
<pages>225--255</pages>
<marker>Xue, 2008</marker>
<rawString>Nianwen Xue. (2008). Labelling chinese predicates with semantic roles. Computational Linguistics, 34(2): 225-255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Feifei Zhai</author>
</authors>
<title>Jiajun Zhang, Yu Zhou and Chengqing Zong. Machine Translation by Modeling PredicateArgument Structure Transformation.</title>
<date>2012</date>
<booktitle>In Proc. of COLING</booktitle>
<marker>Zhai, 2012</marker>
<rawString>Feifei Zhai, Jiajun Zhang, Yu Zhou and Chengqing Zong. Machine Translation by Modeling PredicateArgument Structure Transformation. In Proc. of COLING 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hui Zhang</author>
<author>Min Zhang</author>
</authors>
<title>Haizhou Li and Eng Siong Chng.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP 2010,</booktitle>
<pages>440--450</pages>
<location>Massachusetts, USA,</location>
<marker>Zhang, Zhang, 2010</marker>
<rawString>Hui Zhang, Min Zhang, Haizhou Li and Eng Siong Chng. (2010). Non-isomorphic Forest Pair Translation. In Proceedings of EMNLP 2010, pages 440-450, Massachusetts, USA, 9-11 October 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tao Zhuang</author>
<author>Chengqing Zong</author>
</authors>
<title>A minimum error weighting combination strategy for chinese semantic role labelling.</title>
<date>2010</date>
<booktitle>In Proceedings of COLING-2010,</booktitle>
<pages>1362--1370</pages>
<contexts>
<context position="13089" citStr="Zhuang and Zong, 2010" startWordPosition="2193" endWordPosition="2196">the PAS in Figure 3; (b) The extracted IC-PASTR from (a). Using the IC-PASs, we look for the aligned target span for each element of the IC-PAS. We demand that every element and its corresponding target span must be consistent with word alignment. Otherwise, we discard the IC-PAS. Afterwards, we can easily extract a rule for PAS transformation, which we call IC-PASTR. As an example, Figure 4(b) is the extracted IC-PASTR from Figure 4(a). Note that we only apply the source-side PAS and word alignment for IC-PASTR extraction. By contrast, Zhai et al. (2012) utilized the result of bilingual SRL (Zhuang and Zong, 2010b). Generally, bilingual SRL could give a better alignment between bilingual elements. However, bilingual SRL usually achieves a really low recall on PASs, about 226,968 entries in our training set while it is 882,702 by using monolingual SRL system. Thus to get a high recall for PASs, we only utilize word alignment instead of capturing the relation between bilingual elements. In addition, to guarantee the accuracy of ICPASTRs, we only retain rules with more than 5 occurrences. 4 Maximum Entropy PAS Disambiguation (MEPD) Model In order to handle the role ambiguities, in this section, we concen</context>
<context position="21059" citStr="Zhuang and Zong, 2010" startWordPosition="3499" endWordPosition="3502">whose lengths are among 10 and 30 words. Finally, the development set includes 595 sentences from NIST MT03 and the test set contains 1,786 sentences from NIST MT04 and MT05. We train a 5-gram language model with the Xinhua portion of English Gigaword corpus and target part of the training data. The translation quality is evaluated by case-insensitive BLEU-4 with shortest length penalty. The statistical significance test is performed by the re-sampling approach (Koehn, 2004). We perform SRL on the source part of the training set, development set and test set by the Chinese SRL system used in (Zhuang and Zong, 2010b). To relieve the negative effect of SRL errors, we get the multiple SRL results by providing the SRL system with 3-best parse trees of Berkeley parser (Petrov and Klein, 2007), 1- best parse tree of Bikel parser (Bikel, 2004) and Stanford parser (Klein and Manning, 2003). Therefore, at last, we can get 5 SRL result for each sentence. For the training set, we use these SRL results to do rule extraction respectively. We combine the obtained rules together to get a combined rule set. We discard the rules with fewer than 5 appearances. Using this set, we can train our MEPD model directly. As to </context>
</contexts>
<marker>Zhuang, Zong, 2010</marker>
<rawString>Tao Zhuang, and Chengqing Zong. (2010a). A minimum error weighting combination strategy for chinese semantic role labelling. In Proceedings of COLING-2010, pages 1362-1370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tao Zhuang</author>
<author>Chengqing Zong</author>
</authors>
<title>Joint inference for bilingual semantic role labelling.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP 2010,</booktitle>
<pages>304--314</pages>
<location>Massachusetts, USA,</location>
<contexts>
<context position="13089" citStr="Zhuang and Zong, 2010" startWordPosition="2193" endWordPosition="2196">the PAS in Figure 3; (b) The extracted IC-PASTR from (a). Using the IC-PASs, we look for the aligned target span for each element of the IC-PAS. We demand that every element and its corresponding target span must be consistent with word alignment. Otherwise, we discard the IC-PAS. Afterwards, we can easily extract a rule for PAS transformation, which we call IC-PASTR. As an example, Figure 4(b) is the extracted IC-PASTR from Figure 4(a). Note that we only apply the source-side PAS and word alignment for IC-PASTR extraction. By contrast, Zhai et al. (2012) utilized the result of bilingual SRL (Zhuang and Zong, 2010b). Generally, bilingual SRL could give a better alignment between bilingual elements. However, bilingual SRL usually achieves a really low recall on PASs, about 226,968 entries in our training set while it is 882,702 by using monolingual SRL system. Thus to get a high recall for PASs, we only utilize word alignment instead of capturing the relation between bilingual elements. In addition, to guarantee the accuracy of ICPASTRs, we only retain rules with more than 5 occurrences. 4 Maximum Entropy PAS Disambiguation (MEPD) Model In order to handle the role ambiguities, in this section, we concen</context>
<context position="21059" citStr="Zhuang and Zong, 2010" startWordPosition="3499" endWordPosition="3502">whose lengths are among 10 and 30 words. Finally, the development set includes 595 sentences from NIST MT03 and the test set contains 1,786 sentences from NIST MT04 and MT05. We train a 5-gram language model with the Xinhua portion of English Gigaword corpus and target part of the training data. The translation quality is evaluated by case-insensitive BLEU-4 with shortest length penalty. The statistical significance test is performed by the re-sampling approach (Koehn, 2004). We perform SRL on the source part of the training set, development set and test set by the Chinese SRL system used in (Zhuang and Zong, 2010b). To relieve the negative effect of SRL errors, we get the multiple SRL results by providing the SRL system with 3-best parse trees of Berkeley parser (Petrov and Klein, 2007), 1- best parse tree of Bikel parser (Bikel, 2004) and Stanford parser (Klein and Manning, 2003). Therefore, at last, we can get 5 SRL result for each sentence. For the training set, we use these SRL results to do rule extraction respectively. We combine the obtained rules together to get a combined rule set. We discard the rules with fewer than 5 appearances. Using this set, we can train our MEPD model directly. As to </context>
</contexts>
<marker>Zhuang, Zong, 2010</marker>
<rawString>Tao Zhuang and Chengqing Zong. (2010b). Joint inference for bilingual semantic role labelling. In Proceedings of EMNLP 2010, pages 304–314, Massachusetts, USA, 9-11 October 2010.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>