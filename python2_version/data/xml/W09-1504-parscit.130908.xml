<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006872">
<title confidence="0.997285">
Integrated NLP Evaluation System for Pluggable Evaluation Metrics
with Extensive Interoperable Toolkit
</title>
<author confidence="0.999887">
Yoshinobu Kano1 Luke McCrohon1 Sophia Ananiadou2 Jun’ichi Tsujii1,2
</author>
<affiliation confidence="0.941155666666667">
1 Department of Computer Science, University of Tokyo
Hongo 7-3-1, Bunkyo-ku, Tokyo 113-0033 Tokyo
2School of Computer Science, University of Manchester and National Centre for
</affiliation>
<address confidence="0.88166">
Text Mining, 131 Princess St, M1 7DN, UK
</address>
<email confidence="0.976473666666667">
[kano,tsujii]@is.s.u-tokyo.ac.jp
luke.mccrohon@gmail.com
sophia.ananiadou@manchester.ac.uk
</email>
<sectionHeader confidence="0.992517" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999449785714286">
To understand the key characteristics of NLP
tools, evaluation and comparison against dif-
ferent tools is important. And as NLP applica-
tions tend to consist of multiple semi-
independent sub-components, it is not always
enough to just evaluate complete systems, a
fine grained evaluation of underlying compo-
nents is also often worthwhile. Standardization
of NLP components and resources is not only
significant for reusability, but also in that it al-
lows the comparison of individual components
in terms of reliability and robustness in a wid-
er range of target domains. But as many eval-
uation metrics exist in even a single domain,
any system seeking to aid inter-domain eval-
uation needs not just predefined metrics, but
must also support pluggable user-defined me-
trics. Such a system would of course need to
be based on an open standard to allow a large
number of components to be compared, and
would ideally include visualization of the dif-
ferences between components. We have de-
veloped a pluggable evaluation system based
on the UIMA framework, which provides vi-
sualization useful in error analysis. It is a sin-
gle integrated system which includes a large
ready-to-use, fully interoperable library of
NLP tools.
</bodyText>
<sectionHeader confidence="0.998892" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999930433333333">
When building NLP applications, the same sub-
tasks tend to appear frequently while construct-
ing different systems. Due to this, the reusability
of tools designed for such subtasks is a common
design consideration; fine grained interoperabili-
ty between sub components, not just between
complete systems.
In addition to the benefits of reusability, inte-
roperability is also important in evaluation of
components. Evaluations are normally done by
comparing two sets of data, a gold standard data
and test data showing the components perfor-
mance. Naturally this comparison requires the
two data sets to be in the same data format with
the same semantics. Comparing of &amp;quot;Apples to
Apples&amp;quot; provides another reason why standardi-
zation of NLP tools is beneficial. Another advan-
tage of standardization is that the number of gold
standard data sets that can be compared against is
also increased, allowing tools to be tested in a
wider range of domains.
The ideal is that all components are standar-
dized to conform to an open, widely used intero-
perability framework. One possible such frame-
work is UIMA; Unstructured Information Man-
agement Architecture (Ferrucci et al., 2004),
which is an open project of OASIS and Apache.
We have been developing U-Compare (Kano et
al., 2009)1, an integrated testing an evaluation
platform based on this framework.
</bodyText>
<footnote confidence="0.996580333333333">
1 Features described in this paper are integrated as U-
Compare system, publicly available from:
http://u-compare.org/
</footnote>
<page confidence="0.984306">
22
</page>
<note confidence="0.995693">
Proceedings of the NAACL HLT Workshop on Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 22–30,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999935173913043">
Although U-Compare already provided a wide
range of tools and NLP resources, its inbuilt
evaluation mechanisms were hard coded into the
system and were not customizable by end users.
Furthermore the evaluation metrics used were
based only on simple strict matchings which se-
verely limited its domains of application. We
have extended the evaluation mechanism to al-
low users to define their own metrics which can
be integrated into the range of existing evalua-
tion tools.
The U-Compare library of interoperable tools
has also been extended; especially with regard to
resources related to biomedical named entity ex-
traction. U-Compare is currently providing the
world largest library of type system compatible
UIMA components.
In section 2 of this paper we first look at the
underlying technologies, UIMA and
U-Compare. Then we describe the new plugga-
ble evaluation mechanism in section 3 and our
interoperable toolkit with our type system in sec-
tion 4 and 5.
</bodyText>
<sectionHeader confidence="0.993163" genericHeader="introduction">
2 Background
</sectionHeader>
<subsectionHeader confidence="0.98154">
2.1 UINA
</subsectionHeader>
<bodyText confidence="0.999962272727273">
UIMA is an open framework specified by OA-
SIS2. Apache UIMA provides a reference im-
plementation as an open source project, with
both a pure java API and a C++ development kit .
UIMA itself is intended to be purely a frame-
work, i.e. it does not intend to provide specific
tools or type system definitions. Users should
develop such resources themselves. In the fol-
lowing subsections, we briefly describe the basic
concepts of UIMA, and define keywords used to
explain our system in later sections.
</bodyText>
<subsectionHeader confidence="0.689153">
2.1.1 CAS and Type System
</subsectionHeader>
<bodyText confidence="0.999951222222222">
The UIMA framework uses the “stand-off anno-
tation” style (Ferrucci et al., 2006). The underl-
ing raw text of a document is generally kept un-
changed during analysis, and the results of
processing the text are added as new stand-off
annotations with references to their positions in
the raw text. A Common Analysis Structure
(CAS) holds a set of such annotations. Each of
which is of a given type as defined in a specified
hierarchical type system. Annotation3 types may
define features, which are themselves typed.
Apache UIMA provides definitions of a range of
built in primitive types, but a more complete type
system should be specified by developers. The
top level Apache UIMA type is referred to as
TOP, other primitive types include. int, String,
Annotation and FSArray (an array of any annota-
tions).
</bodyText>
<subsectionHeader confidence="0.755995">
2.1.2 Component and Capability
</subsectionHeader>
<bodyText confidence="0.9983577">
UIMA components receive and update CAS one
at a time. Each UIMA component has a capabili-
ty property, which describes what types of anno-
tations it takes as input and what types of anno-
tations it may produce as output.
UIMA components can be deployed either lo-
cally, or remotely as SOAP web services. Re-
motely deployed web service components and
locally deployed components can be freely com-
bined in UIMA workflows.
</bodyText>
<subsectionHeader confidence="0.8759375">
2.1.3 Aggregate Component and Flow Con-
troller
</subsectionHeader>
<bodyText confidence="0.9997735">
UIMA components can be either primitive or
aggregate. Aggregate components include other
components as subcomponents. Subcomponents
may themselves be aggregate. In the case where
an aggregate has multiple subcomponents these
are by default processed in linear order. This or-
dering can be customized by implementing a
custom flow controller.
</bodyText>
<subsectionHeader confidence="0.998051">
2.2 U-Compare
</subsectionHeader>
<bodyText confidence="0.999942928571429">
U-Compare is a joint project of the University of
Tokyo, the Center for Computational Pharma-
cology at the University of Colorado School of
Medicine, and the UK National Centre for Text
Mining.
U-Compare provides an integrated platform
for users to construct, edit and compare
workflows compatible with any UIMA compo-
nent. It also provides a large, ready-to-use toolkit
of interoperable NLP components for use with
any UIMA based system. This toolkit is currently
the world largest repository of type system com-
patible components. These all implement the U-
Compare type system described in section 3.
</bodyText>
<footnote confidence="0.99898">
3 In the UIMA framework, Annotation is a base
type which has begin and end offset values. In this paper
we call any objects (any subtype of TOP) as annotations.
2 http://www.oasis-open.org/committees/uima/
</footnote>
<page confidence="0.99639">
23
</page>
<sectionHeader confidence="0.765308" genericHeader="method">
2.2.1 Related Works
</sectionHeader>
<bodyText confidence="0.999916666666667">
There also exist several other public UIMA
component repositories: CMU UIMA component
repository, BioNLP UIMA repository (Baum-
gartner et al., 2008), JCoRe (Hahn et al., 2008),
Tsujii Lab Component Repository at the Univer-
sity of Tokyo (Kano et al., 2008a), etc. Each
group uses their own type system, and so com-
ponents provided by each group are incompatible.
Unlike U-Compare these repositories are basical-
ly only collections of UIMA components, U-
Compare goes further by providing a fully inte-
grated set of UIMA tools and utilities.
</bodyText>
<subsubsectionHeader confidence="0.503573">
2.2.2 Integrated Platform
</subsubsectionHeader>
<bodyText confidence="0.999964">
U-Compare provides a variety of features as part
of an integrated platform. The system can be
launched with a single click in a web browser; all
required libraries are downloaded and updated
automatically in background.
The Workflow Manager GUI helps users to
create workflows in an easy drag-and-drop fa-
shion. Similarly, import/export of workflows,
running of workflows and saving results can all
be handled via a graphical interface.
U-Compare special parallel aggregate compo-
nents allow combinations of specified compo-
nents to be automatically combined and com-
pared based on their I/O capabilities (Kano et al.,
2008b). When workflows are run, U-Compare
shows statistics and visualizations of results ap-
propriate to the type of workflow. For example
when workflows including parallel aggregate
components are run comparison statistics be-
tween all possible parallel component combina-
tions are given.
</bodyText>
<sectionHeader confidence="0.888915" genericHeader="method">
3 Integrated System for Pluggable
Evaluation Metrics
</sectionHeader>
<bodyText confidence="0.999991894736842">
While U-Compare already has a mechanism to
automatically create possible combinations of
components for comparison from a specified
workflow, the comparison (evaluation) metric
itself was hard coded into the system. Only com-
parison based on simple strict matching was
possible.
However, many different evaluation metrics
exist, even for the same type of annotations. For
example, named entity recognition results are
often evaluated based on several different anno-
tation intersection criteria: exact match, left/right
only match, overlap, etc. Evaluation metrics for
nested components can be even more complex
(e.g. biomedical relations, deep syntactic struc-
tures). Sometimes new metrics are also required
for specific tasks. Thus, a mechanism for plugg-
able evaluation metrics in a standardized way is
seen as desirable.
</bodyText>
<subsectionHeader confidence="0.997606">
3.1 Pluggable Evaluation Component
</subsectionHeader>
<bodyText confidence="0.979380428571429">
Our design goal for the evaluation systems is to
do as much of the required work as possible and
to provide utilities to reduce developer’s labor.
We also want our design to be generic and fix
within existing UIMA standards.
The essential process of evaluation can be ge-
neralized and decomposed as follows:
</bodyText>
<listItem confidence="0.943061333333333">
(a) prepare a pair of annotation sets which
will be used for comparison,
(b) select annotations which should be in-
cluded in the final evaluation step,
(c) compare selected annotations against
each other and mark matched pairs.
</listItem>
<bodyText confidence="0.99967640625">
For example, in the case of the Penn Treebank
style syntactic bracket matching, these steps cor-
respond to (a) prepare two sets of constituents
and tokens, (b) select only the constituents (re-
moving null elements if required), (c) compare
constituents between the sets and return any
matches.
In our new design, step (a) is performed by the
system, (b) and (c) are performed by an evalua-
tion component. The evaluation component is
just a normal UIMA component, pluggable based
on the UIMA standard. This component is run on
a CAS which was constructed by the system dur-
ing step (a). This CAS includes an instance of
ComparisonSet type and its features GoldAnno-
tationGroup and TestAnnotationGroup. Corres-
ponding to step (b), based on this input the com-
parison component should make a selection of
annotations and store them as FSArray for both
GoldAnnotations and TestAnnotations. Finally
for step (c), the component should perform a
matching and store the results as MatchedPair
instances in the MatchedAnnotations feature of
the ComparisonSet.
Precision, recall, and F1 scores are calculated
by U-Compare based on the outputted Compari-
sonSet. These calculation can be overridden and
customized if the developer so desires.
Implementation of the compare() method of
the evaluation component is recommended. It is
used by the system when showing instance based
evaluations of what feature values are used in
</bodyText>
<page confidence="0.992325">
24
</page>
<bodyText confidence="0.9891105">
matching, which features are matched, and which
are not.
</bodyText>
<subsectionHeader confidence="0.999591">
3.2 Combinatorial Evaluation and Er-
</subsectionHeader>
<bodyText confidence="0.989453222222222">
ror Analysis
By default, evaluation statistics are calculated by
simply counting the numbers of gold, test,
matched annotations in the returned Compari-
sonSet instance. Then precision, recall, and F1
scores for each CAS and for the complete set of
CASes are calculated. Users can specify which
evaluation metrics are used for each type of an-
notations based on the input specifications they
set for supplied evaluation components.
Normally, precision, recall, and F1 scores are
the only evaluation statistics used in the NLP
community. It is often the case in many research
reports that a new tool A performs better than
another tool B, increasing the F1 score by 1%. In
such cases it is important to analysis what pro-
portion of annotations are shared between A, B,
and the gold standard. Is A a strict 1% increase
over B? Or does it cover 2% of instances B
doesn’t but miss a different 1%? Our system
provides these statistics as well.
Further, our standardized evaluation system
makes more advanced evaluation available.
Since the evaluation metrics themselves are more
or less arbitrary, we should carefully observe the
results of evaluations. When two or more metrics
are available for the same type of annotations,
we can compare the results of each to analyze
and validate the individual evaluations.
An immediate application of such comparison
would be in a voting system, which takes the
results of several tools as input and selects com-
mon overlapping annotations as output.
U-Compare also provides visualizations of
evaluation results allowing instance-based error
analysis.
</bodyText>
<sectionHeader confidence="0.921799" genericHeader="method">
4 U-Compare Type System
</sectionHeader>
<bodyText confidence="0.9994">
U-Compare currently provides the world largest
set of type system compatible UIMA compo-
nents. We will describe some of these in section
5. In creating compatible components in UIMA a
key task is their type system definitions.
The U-Compare type system is designed in a
hierarchical fashion with distinct types to achieve
a high level of interoperability. It is intended to
be a shared type system capable of mapping
types originally defined as part of independent
type systems (Kano et al., 2008c). In this section
we describe the U-Compare type system in detail.
</bodyText>
<subsectionHeader confidence="0.996647">
4.1 Basic Types
</subsectionHeader>
<bodyText confidence="0.99863472">
While most of the U-Compare types are inherit-
ing a UIMA built-in type, Annotation (Figure 1),
there are also types directly extending the TOP
type; let us call these types as metadata types.
AnnotationMetadata holds a confidence value,
which is common to all of the U-Compare anno-
tation types as a feature of BaseAnnotation type.
BaseAnnotation extends DiscontinuousAnnota-
tion, in which fragmental annotations can be
stored as a FSArray of Annotations, if any.
ExternalReference is another common meta-
data type where namespace and ID are stored,
referring to an external ontology entity outside
UIMA/U-Compare. Because it is not realistic to
represent everything like such a detailed ontolo-
gy hierarchy in a UIMA type system, this meta-
data is used to recover original information,
which are not expressed as UIMA types. Refe-
renceAnnotation is another base annotation type,
which holds an instance of this ExternalRefe-
rence.
UniqueLabel is a special top level type for ex-
plicitly defined finite label sets, e.g. the Penn
Treebank tagset. Each label in such a tagset is
mapped to a single type where UniqueLabel as its
</bodyText>
<figureCaption confidence="0.999116">
Figure 2. Syntactic Types in U-Compare.
</figureCaption>
<figure confidence="0.997593610169492">
BaseAnnotation
&lt;AnnotationMetadata&gt;
SyntacticAnnotation
Sentence
Token
AbstractConstituent
TOP
TemplateMappedConstituent
&lt;Constituent&gt;
FunctionTaggedConstituent
&lt;FunctionLabel&gt;
Constituent
&lt;ConstituentLabel&gt;
TreeNode
&lt;TOP&gt;parent
&lt;FSArray&gt;children
Dependency
&lt;DependencyLabel&gt;
Stanford
Dependency
NullElement
&lt;NullElementLabel&gt;
&lt;Constituent&gt;
Coordinations
&lt;FSArray&gt;
RichToken
&lt;String&gt;base
POSToken
&lt;POS&gt;
25
SemanticClassAnnotation
&lt;FSArray:LinkedAnnotationSet&gt;
ReferenceAnnotation
SemanticAnnotation
LinkingAnnotationSet
&lt;ExternalReference&gt;
&lt;FSArray:SemanticAnnotation&gt;
TOP
CoreferenceAnnotation
Proper
Name
Person
Title
Place
CellLine
DiscourseEntity
CellType
DNARegion
DNA
NamedEntity
RNA
GeneOrGeneProduct
Protein
EventAnnotation
Gene
Negation
Expression
Speculation
ProteinRegion
</figure>
<figureCaption confidence="0.999883">
Figure 3. Semantic types in the U-Compare type system.
</figureCaption>
<bodyText confidence="0.992698333333333">
ancestor, putting middle level types if possible
(e.g. Noun type for the Penn Treebank POS tag-
set). These types are omitted in the figure.
</bodyText>
<subsectionHeader confidence="0.991695">
4.2 Syntactic Types
</subsectionHeader>
<bodyText confidence="0.999876">
SyntacticAnnotation is the base type of all syn-
tactic types (Figure 2). POSToken holds a POS
label, RichToken additionally holds a base form.
Dependency is used by dependency parsers,
while TreeNode is for syntactic tree nodes. Con-
stituent, NullElement, FunctionTaggedConsti-
tiuent, TemplateMappedConstituent are designed
to fully represent all of the Penn Treebank style
annotations. Coordination is a set of references to
coordinating nodes (currently used by the Genia
Treebank). We are planning on extending the set
of syntactic types to cover the outputs of several
deep parsers.
</bodyText>
<subsectionHeader confidence="0.999213">
4.3 Semantic Types
</subsectionHeader>
<bodyText confidence="0.999969357142857">
SemanticAnnotation is the base type for semantic
annotations; it extends ReferenceAnnotation by
holding the original reference.
SemanticClassAnnotation is a rather complex
type designed to be somewhat general. In many
cases, semantic annotations may reference other
semantic annotations, e.g. references between
biological events. Such references are often la-
beled with their roles which we express with the
ExternalReference type. Such labeled references
are expressed by LinkingAnnotationSet. As a role
may refer to more than one annotation, Linkin-
gAnnotationSet has an FSArray of SemanticAn-
notation as a feature.
There are several biomedical types included in
Figure 3, e.g. DNA, RNA, Protein, Gene, Cel-
lLine, CellType, etc. It is however difficult to
decide which ontological entities should be in-
cluded in such a type system. One reason for this
is that such concepts are not always distinct; dif-
ferent ontologies may give overlapping defini-
tions of these concepts. Further, the number of
possible substance level entities is infinite; caus-
ing difficult in their expression as individual
types. The current set of biomedical types in the
U-Compare type system includes types which are
frequently used for evaluation in the BioNLP
research.
</bodyText>
<subsectionHeader confidence="0.997903">
4.4 Document Types
</subsectionHeader>
<bodyText confidence="0.9989195">
DocumentAnnotation is the base type for docu-
ment related annotations (Figure 4). It extends
</bodyText>
<figure confidence="0.9924354">
DocumentAttribute
&lt;ExternalReference&gt;
ReferenceAnnotation
DocumentAnnotation
TOP
DocumentClassAnnotation
&lt;FSArray:DocumentAttribute&gt;
&lt;FSArray:ReferenceAnnotation&gt;
DocumentReferenceAttribute DocumentValueAttribute
&lt;ReferenceAnnotation&gt; &lt;String&gt;value
</figure>
<figureCaption confidence="0.999228">
Figure 4. Document types in the U-Compare type system.
</figureCaption>
<page confidence="0.986865">
26
</page>
<bodyText confidence="0.999900923076923">
ReferenceAnnotation to reference the full exter-
nal type in the same way as SemanticAnnotation.
DocumentClassAnnotation together with Do-
cumentAttribute are intended to express XML
style data. XML tags may have fields storing
their values, and/or idref fields refering to other
tags. DocumentValueAttiributerepresents simple
value field, while DocumentReferenceAttribute
represents idref type fields. A DocumentClas-
sAnnotation corresponds to the tag itself.
Although these types can represent most doc-
ument structures, we still plan to add several
specific types such as Paragraph, Title, etc.
</bodyText>
<sectionHeader confidence="0.9927305" genericHeader="method">
5 Interoperable Components and Utili-
ties
</sectionHeader>
<bodyText confidence="0.9999775">
In this section, we describe our extensive toolkit
of interoperable components and the set of utili-
ties integrated into the U-Compare system. All of
the components in our toolkit are compatible
with the U-Compare type system described in the
previous section.
</bodyText>
<subsectionHeader confidence="0.999247">
5.1 Corpus Reader Components
</subsectionHeader>
<bodyText confidence="0.984423">
In the UIMA framework, a component which
generates CASes is called a Collection Reader.
We have developed several collection readers
which read annotated corpora and generates an-
notations using the U-Compare type system.
Because our primary target domain was bio-
medical field, there are corpus readers for the
biomedical corpora; Aimed corpus (Bunescu et
al., 2006) reader and BioNLP ’09 shared task
format reader generate event annotations like
protein-protein interaction annotations; Readers
for BIO/IOB format, Bio1 corpus (Tateisi et al.,
2000), BioCreative (Hirschman et al., 2004) task
1a format, BioIE corpus (Bies et al., 2005),
NLPBA shared task dataset (Kim et al., 2004),
Texas Corpus (Bunescu et al., 2005), Yapex
Corpus (Kristofer Franzen et al., 2002), generate
biomedical named entities, and Genia Treebank
corpus (Tateisi et al., 2005) reader generates
Penn Treebank (Marcus et al., 1993) style brack-
eting and part-of-speech annotations. Format
readers require users to prepare annotated data,
while others include corpora themselves, auto-
matically downloaded as an archive on users’
demand.
In addition, there is File System Collection
Reader from Apache UIMA which reads files as
plain text. We have developed an online interac-
tive text reader, named Input Text Reader.
187
The document length in bytes is
output in the first line (end with
new line),
then the raw text follows as is
(attaching a new line in the end),
finally annotations follow line by
line.
</bodyText>
<figure confidence="0.963751">
0 187 Document id=&amp;quot;u1&amp;quot;
0 3 POSToken id=&amp;quot;u2&amp;quot; pos=&amp;quot;DT&amp;quot;
....
</figure>
<figureCaption confidence="0.985965">
Figure 5. An example of the U-Compare simple I/O
format.
</figureCaption>
<subsectionHeader confidence="0.999885">
5.2 Analysis Engine Components
</subsectionHeader>
<bodyText confidence="0.99993605">
There are many tools covering from basic syn-
tactic annotations to the biomedical annotations.
Some of the tools are running as web services,
but users can freely mix local services and web
services.
For syntactic annotations: sentence detectors
from GENIA, LingPipe, NaCTeM, OpenNLP
and Apache UIMA; tokenizers from GENIA tag-
ger (Tsuruoka et al., 2005), OpenNLP, Apache
UIMA and Penn Bio Tokenizer; POS taggers
from GENIA tagger, LingPipe, OpenNLP and
Stepp Tagger; parsers from OpenNLP (CFG),
Stanford Parser (dependency) (de Marneffe et al.,
2006), Enju (HPSG) (Miyao et al., 2008).
For semantic annotations: ABNER (Settles,
2005) for NLPBA/BioCreative trained models,
GENIA Tagger, NeMine, MedT-NER, LingPipe
and OpenNLP NER, for named entity recogni-
tions. Akane++ (Sætre et al., 2007) for protein-
protein interaction detections.
</bodyText>
<subsectionHeader confidence="0.970494">
5.3 Components for Developers
</subsectionHeader>
<bodyText confidence="0.999970888888889">
Although Apache UIMA provides APIs in both
Java and C++ to help users develop UIMA com-
ponents, a level of understanding of the UIMA
framework is still required. Conversion of exist-
ing tools to the UIMA framework can also be
difficult, particularly when they are written in
other programming languages.
We have designed a simple I/O format to
make it easy for developers who just want to
provide a UIMA wrapper for existing tools.
Input of this format consists of two parts: raw
text and annotations The first line of the raw text
section is an integer of byte count of the length
of the text. The raw text then follows with a new-
line character appended at the end. Annotations
are then included; one annotation per line, some-
times referring another annotation by assigned
ids (Figure 5). A line consists of begin position,
</bodyText>
<page confidence="0.998346">
27
</page>
<figureCaption confidence="0.995339">
Figure 6. A screenshot of Workflow Manager
GUI and Component Library.
</figureCaption>
<bodyText confidence="0.955748875">
end position, type name, unique id, and feature
values if any. Double newlines indicates an end
of a CAS.
Output of the component is lines of annota-
tions if any created by the component.
U-Compare provides a wrapper component
which uses this I/O format, communicating with
wrapped tools via standard I/O streams.
</bodyText>
<subsectionHeader confidence="0.998523">
5.4 Type System Converters
</subsectionHeader>
<bodyText confidence="0.9999648">
As U-Compare is a joint project, the U-Compare
toolkit includes UIMA components originally
developed using several different type systems.
In order to integrate these components into the
U-Compare type system, we have developed
type system converter components for each ex-
ternal type system.
The CCP team at the University of Colorado
made a converter between their CCP type system
and our type system. We also developed conver-
ters for OpenNLP components and Apache UI-
MA components. These converters remove any
original annotations not compatible with the U-
Compare type system. This prevents duplicated
converters from translating external annotation
multiple times in the same workflow.
We are providing such non U-Compare com-
ponents by aggregating with type system conver-
ters, so users do not need to aware of the type
system conversions.
</bodyText>
<subsectionHeader confidence="0.96905">
5.5 Utility Tools
</subsectionHeader>
<bodyText confidence="0.999922928571429">
We have developed and integrated several utility
tools, especially GUI tools for usability and error
analysis.
Figure 6 is showing our workflow manager
GUI, which provides functions to create a user
workflow by an easy drag-and-drop way. By
clicking “Run Workflow” button in that manager
window, statistics will be shown (Figure 8).
There are also a couple of annotation visuali-
zation tools. Figure 7 is showing a viewer for
tree structures and HPSG feature structures. Fig-
ure 9 is showing a general annotation viewer,
when annotations have complex inter-
dependencies.
</bodyText>
<sectionHeader confidence="0.995424" genericHeader="conclusions">
6 Summary and Future Directions
</sectionHeader>
<bodyText confidence="0.999696666666667">
We have designed and developed a pluggable
evaluation system based on the UIMA frame-
work. This evaluation system is integrated with
the U-Compare combinatorial comparison me-
chanism which makes evaluation of many factors
available automatically.
Since the system behavior is dependent on the
type system used, we have carefully designed the
U-Compare type system to cover a broad range
of concepts used in NLP applications. Based di-
rectly on this type system, or using type system
converters, we have developed a large toolkit of
type system compatible interoperable UIMA
component. All of these features are integrated
into U-Compare.
</bodyText>
<figureCaption confidence="0.910206">
Figure 7. A screenshot of HPSG feature structure
viewer, showing a skeleton CFG tree, feature values
and head/semhead links.
</figureCaption>
<page confidence="0.993415">
28
</page>
<figureCaption confidence="0.994588">
Figure 8. A screenshot of a comparison statistics showing number of instances (gold, test, and
matched), F1, precision, and recall scores of two evaluation metrics on the same data.
</figureCaption>
<bodyText confidence="0.902792">
In future we are planning to increase the num-
ber of components available, e.g. more syntactic
parsers, corpus readers, and resources for lan-
guages other than English. This will also re-
quired enhancements to the existing type system
to support additional components. Finally we
also hope to add integration with machine learn-
ing tools in the near future.
</bodyText>
<figureCaption confidence="0.9885265">
Figure 9. A screenshot of a visualization of com-
plex annotations.
</figureCaption>
<sectionHeader confidence="0.994916" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999954555555556">
We wish to thank Dr. Lawrence Hunter’s text
mining group at Center for Computational Phar-
macology, University of Colorado School of
Medicine, for helping build the type system and
for making their tools available for this research.
This work was partially supported by Grant-in-
Aid for Specially Promoted Research (MEXT,
Japan). The Nati onal Centre for Text Mining is
funded by JISC.
</bodyText>
<sectionHeader confidence="0.998568" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998340133333333">
W. A. Baumgartner, Jr., K. B. Cohen, and L. Hunter.
2008. An open-source framework for large-scale,
flexible evaluation of biomedical text mining sys-
tems. J Biomed Discov Collab, 3(1), 1.
Ann Bies, Seth Kulick, and Mark Mandel. 2005. Pa-
rallel entity and treebank annotation. In Proceed-
ings of the the Workshop on Frontiers in Corpus
Annotations II: Pie in the Sky, ACL, Ann Arbor,
Michigan, USA.
Razvan Bunescu, Ruifang Ge, Rohit J. Kate, Edward
M. Marcotte, Raymond J. Mooney, Arun Kumar
Ramani, et al. 2005. Comparative experiments on
learning information extractors for proteins and
their interactions. Artificial Intelligence in Medi-
cine, 33(2), 139-155.
</reference>
<page confidence="0.98993">
29
</page>
<reference confidence="0.998260098039216">
Razvan Bunescu, and Raymond Mooney. 2006. Sub-
sequence Kernels for Relation Extraction. In Y.
Weiss, B. Scholkopf and J. Platt (Eds.), Advances
in Neural Information Processing Systems 18 (171-
-178). Cambridge, MA: MIT Press.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses.
In Proceedings of the the 5th International Confe-
rence on Language Resources and Evaluation
(LREC 2006).
David Ferrucci, and Adam Lally. 2004. Building an
example application with the Unstructured Infor-
mation Management Architecture. Ibm Systems
Journal, 43(3), 455-475.
David Ferrucci, Adam Lally, Daniel Gruhl, and Ed-
ward Epstein. 2006. Towards an Interoperability
Standard for Text and Multi-Modal Analytics.
U. Hahn, E. Buyko, R. Landefeld, M. Mühlhausen, M.
Poprat, K. Tomanek, et al. 2008, May. An Over-
view of JCoRe, the JULIE Lab UIMA Component
Repository. In Proceedings of the LREC&apos;08 Work-
shop, Towards Enhanced Interoperability for Large
HLT Systems: UIMA for NLP, Marrakech, Moroc-
co.
Lynette Hirschman, Alexander Yeh, Christian
Blaschke, and Antonio Valencia. 2004. Overview
of BioCreAtIvE: critical assessment of information
extraction for biology. BMC Bionformatics,
6(Suppl 1:S1).
Yoshinobu Kano, William A Baumgartner, Luke
McCrohon, Sophia Ananiadou, Kevin B Cohen,
Lawrence Hunter, et al. 2009. U-Compare: share
and compare text mining tools with UIMA. Bioin-
formatics, accepted.
Yoshinobu Kano, Ngan Nguyen, Rune Sætre, Keiichi-
ro Fukamachi, Kazuhiro Yoshida, Yusuke Miyao,
et al. 2008c, January. Sharable type system design
for tool inter-operability and combinatorial com-
parison. In Proceedings of the the First Internation-
al Conference on Global Interoperability for Lan-
guage Resources (ICGL), Hong Kong.
Yoshinobu Kano, Ngan Nguyen, Rune Sætre, Kazuhi-
ro Yoshida, Keiichiro Fukamachi, Yusuke Miyao,
et al. 2008b, January. Towards Data And Goal
Oriented Analysis: Tool Inter-Operability And
Combinatorial Comparison. In Proceedings of the
3rd International Joint Conference on Natural Lan-
guage Processing (IJCNLP), Hyderabad, India.
Yoshinobu Kano, Ngan Nguyen, Rune Sætre, Kazuhi-
ro Yoshida, Yusuke Miyao, Yoshimasa Tsuruoka,
et al. 2008a, January. Filling the gaps between
tools and users: a tool comparator, using protein-
protein interaction as an example. In Proceedings
of the Pacific Symposium on Biocomputing (PSB),
Hawaii, USA.
Jin-Dong Kim, Tomoko Ohta, Yoshimasa Tsuruoka,
Yuka Tateisi, and Nigel Collier. 2004. Introduction
to the Bio-Entity Recognition Task at JNLPBA. In
Proceedings of the International Workshop on Nat-
ural Language Processing in Biomedicine and its
Applications (JNLPBA-04), Geneva, Switzerland.
Kristofer Franzen, Gunnar Eriksson, Fredrik Olsson,
Lars Asker, Per Liden, and Joakim Coster. 2002.
Protein names and how to find them. International
Journal of Medical Informatics, 67(1-3), 49-61.
Mitchell P. Marcus, Mary Ann Marcinkiewicz, and
Beatrice Santorini. 1993. Building a large anno-
tated corpus of English: the penn treebank. Com-
putational Linguistics, 19(2), 313-330.
Yusuke Miyao, and Jun&apos;ichi Tsujii. 2008. Feature
Forest Models for Probabilistic HPSG Parsing.
Computational Linguistics, 34(1), 35-80.
Rune Sætre, Kazuhiro Yoshida, Akane Yakushiji,
Yusuke Miyao, Yuichiro Matsubayashi, and To-
moko Ohta. 2007, April. AKANE System: Protein-
Protein Interaction Pairs in BioCreAtIvE2 Chal-
lenge, PPI-IPS subtask. In Proceedings of the
Second BioCreative Challenge Evaluation Work-
shop.
Burr Settles. 2005. ABNER: an open source tool for
automatically tagging genes, proteins and other
entity names in text. Bioinformatics, 21(14), 3191-
3192.
Yuka Tateisi, Tomoko Ohta, Nigel Collier, Chikashi
Nobata, and Jun&apos;ichi Tsujii. 2000, August. Building
an Annotated Corpus from Biology Research Pa-
pers. In Proceedings of the COLING 2000 Work-
shop on Semantic Annotation and Intelligent Con-
tent, Luxembourg.
Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, and
Jun&apos;ichi Tsujii. 2005, October. Syntax Annotation
for the GENIA Corpus. In Proceedings of the the
Second International Joint Conference on Natural
Language Processing (IJCNLP &apos;05), Companion
volume, Jeju Island, Korea.
Yoshimasa Tsuruoka, Yuka Tateishi, Jin Dong Kim,
Tomoko Ohta, J. McNaught, Sophia Ananiadou, et
al. 2005. Developing a robust part-of-speech tag-
ger for biomedical text. In Advances in Informatics,
Proceedings (Vol. 3746, 382-392). Berlin: Sprin-
ger-Verlag Berlin.
</reference>
<page confidence="0.998811">
30
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.287635">
<title confidence="0.9990095">Integrated NLP Evaluation System for Pluggable Evaluation with Extensive Interoperable Toolkit</title>
<author confidence="0.999734">Luke Sophia Jun’ichi</author>
<affiliation confidence="0.985606">1Department of Computer Science, University of</affiliation>
<address confidence="0.544816">Hongo 7-3-1, Bunkyo-ku, Tokyo 113-0033 Tokyo</address>
<affiliation confidence="0.707682">of Computer Science, University of Manchester and National Centre</affiliation>
<address confidence="0.989271">Text Mining, 131 Princess St, M1 7DN, UK</address>
<email confidence="0.997923">sophia.ananiadou@manchester.ac.uk</email>
<abstract confidence="0.998560310344828">To understand the key characteristics of NLP tools, evaluation and comparison against different tools is important. And as NLP applications tend to consist of multiple semiindependent sub-components, it is not always enough to just evaluate complete systems, a fine grained evaluation of underlying components is also often worthwhile. Standardization of NLP components and resources is not only significant for reusability, but also in that it allows the comparison of individual components in terms of reliability and robustness in a wider range of target domains. But as many evaluation metrics exist in even a single domain, any system seeking to aid inter-domain evaluation needs not just predefined metrics, but must also support pluggable user-defined metrics. Such a system would of course need to be based on an open standard to allow a large number of components to be compared, and would ideally include visualization of the differences between components. We have developed a pluggable evaluation system based on the UIMA framework, which provides visualization useful in error analysis. It is a single integrated system which includes a large ready-to-use, fully interoperable library of NLP tools.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>W A Baumgartner</author>
<author>K B Cohen</author>
<author>L Hunter</author>
</authors>
<title>An open-source framework for large-scale, flexible evaluation of biomedical text mining systems.</title>
<date>2008</date>
<journal>J Biomed Discov Collab,</journal>
<volume>3</volume>
<issue>1</issue>
<pages>1</pages>
<contexts>
<context position="7521" citStr="Baumgartner et al., 2008" startWordPosition="1180" endWordPosition="1184">ady-to-use toolkit of interoperable NLP components for use with any UIMA based system. This toolkit is currently the world largest repository of type system compatible components. These all implement the UCompare type system described in section 3. 3 In the UIMA framework, Annotation is a base type which has begin and end offset values. In this paper we call any objects (any subtype of TOP) as annotations. 2 http://www.oasis-open.org/committees/uima/ 23 2.2.1 Related Works There also exist several other public UIMA component repositories: CMU UIMA component repository, BioNLP UIMA repository (Baumgartner et al., 2008), JCoRe (Hahn et al., 2008), Tsujii Lab Component Repository at the University of Tokyo (Kano et al., 2008a), etc. Each group uses their own type system, and so components provided by each group are incompatible. Unlike U-Compare these repositories are basically only collections of UIMA components, UCompare goes further by providing a fully integrated set of UIMA tools and utilities. 2.2.2 Integrated Platform U-Compare provides a variety of features as part of an integrated platform. The system can be launched with a single click in a web browser; all required libraries are downloaded and upda</context>
</contexts>
<marker>Baumgartner, Cohen, Hunter, 2008</marker>
<rawString>W. A. Baumgartner, Jr., K. B. Cohen, and L. Hunter. 2008. An open-source framework for large-scale, flexible evaluation of biomedical text mining systems. J Biomed Discov Collab, 3(1), 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Bies</author>
<author>Seth Kulick</author>
<author>Mark Mandel</author>
</authors>
<title>Parallel entity and treebank annotation.</title>
<date>2005</date>
<booktitle>In Proceedings of the the Workshop on Frontiers in Corpus Annotations II: Pie in the Sky, ACL,</booktitle>
<location>Ann Arbor, Michigan, USA.</location>
<contexts>
<context position="19945" citStr="Bies et al., 2005" startWordPosition="3023" endWordPosition="3026">ork, a component which generates CASes is called a Collection Reader. We have developed several collection readers which read annotated corpora and generates annotations using the U-Compare type system. Because our primary target domain was biomedical field, there are corpus readers for the biomedical corpora; Aimed corpus (Bunescu et al., 2006) reader and BioNLP ’09 shared task format reader generate event annotations like protein-protein interaction annotations; Readers for BIO/IOB format, Bio1 corpus (Tateisi et al., 2000), BioCreative (Hirschman et al., 2004) task 1a format, BioIE corpus (Bies et al., 2005), NLPBA shared task dataset (Kim et al., 2004), Texas Corpus (Bunescu et al., 2005), Yapex Corpus (Kristofer Franzen et al., 2002), generate biomedical named entities, and Genia Treebank corpus (Tateisi et al., 2005) reader generates Penn Treebank (Marcus et al., 1993) style bracketing and part-of-speech annotations. Format readers require users to prepare annotated data, while others include corpora themselves, automatically downloaded as an archive on users’ demand. In addition, there is File System Collection Reader from Apache UIMA which reads files as plain text. We have developed an onli</context>
</contexts>
<marker>Bies, Kulick, Mandel, 2005</marker>
<rawString>Ann Bies, Seth Kulick, and Mark Mandel. 2005. Parallel entity and treebank annotation. In Proceedings of the the Workshop on Frontiers in Corpus Annotations II: Pie in the Sky, ACL, Ann Arbor, Michigan, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan Bunescu</author>
<author>Ruifang Ge</author>
<author>Rohit J Kate</author>
<author>Edward M Marcotte</author>
<author>Raymond J Mooney</author>
<author>Arun Kumar Ramani</author>
</authors>
<title>Comparative experiments on learning information extractors for proteins and their interactions.</title>
<date>2005</date>
<journal>Artificial Intelligence in Medicine,</journal>
<volume>33</volume>
<issue>2</issue>
<pages>139--155</pages>
<contexts>
<context position="20028" citStr="Bunescu et al., 2005" startWordPosition="3037" endWordPosition="3040">veloped several collection readers which read annotated corpora and generates annotations using the U-Compare type system. Because our primary target domain was biomedical field, there are corpus readers for the biomedical corpora; Aimed corpus (Bunescu et al., 2006) reader and BioNLP ’09 shared task format reader generate event annotations like protein-protein interaction annotations; Readers for BIO/IOB format, Bio1 corpus (Tateisi et al., 2000), BioCreative (Hirschman et al., 2004) task 1a format, BioIE corpus (Bies et al., 2005), NLPBA shared task dataset (Kim et al., 2004), Texas Corpus (Bunescu et al., 2005), Yapex Corpus (Kristofer Franzen et al., 2002), generate biomedical named entities, and Genia Treebank corpus (Tateisi et al., 2005) reader generates Penn Treebank (Marcus et al., 1993) style bracketing and part-of-speech annotations. Format readers require users to prepare annotated data, while others include corpora themselves, automatically downloaded as an archive on users’ demand. In addition, there is File System Collection Reader from Apache UIMA which reads files as plain text. We have developed an online interactive text reader, named Input Text Reader. 187 The document length in byt</context>
</contexts>
<marker>Bunescu, Ge, Kate, Marcotte, Mooney, Ramani, 2005</marker>
<rawString>Razvan Bunescu, Ruifang Ge, Rohit J. Kate, Edward M. Marcotte, Raymond J. Mooney, Arun Kumar Ramani, et al. 2005. Comparative experiments on learning information extractors for proteins and their interactions. Artificial Intelligence in Medicine, 33(2), 139-155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan Bunescu</author>
<author>Raymond Mooney</author>
</authors>
<title>Subsequence Kernels for Relation Extraction. In</title>
<date>2006</date>
<booktitle>Advances in Neural Information Processing Systems</booktitle>
<volume>18</volume>
<pages>171--178</pages>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<marker>Bunescu, Mooney, 2006</marker>
<rawString>Razvan Bunescu, and Raymond Mooney. 2006. Subsequence Kernels for Relation Extraction. In Y. Weiss, B. Scholkopf and J. Platt (Eds.), Advances in Neural Information Processing Systems 18 (171--178). Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of the the 5th International Conference on Language Resources and Evaluation (LREC</booktitle>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine de Marneffe, Bill MacCartney, and Christopher D. Manning. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of the the 5th International Conference on Language Resources and Evaluation (LREC 2006).</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Ferrucci</author>
<author>Adam Lally</author>
</authors>
<title>Building an example application with the Unstructured Information Management Architecture.</title>
<date>2004</date>
<journal>Ibm Systems Journal,</journal>
<volume>43</volume>
<issue>3</issue>
<pages>455--475</pages>
<marker>Ferrucci, Lally, 2004</marker>
<rawString>David Ferrucci, and Adam Lally. 2004. Building an example application with the Unstructured Information Management Architecture. Ibm Systems Journal, 43(3), 455-475.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Ferrucci</author>
<author>Adam Lally</author>
<author>Daniel Gruhl</author>
<author>Edward Epstein</author>
</authors>
<title>Towards an Interoperability Standard for Text and Multi-Modal Analytics.</title>
<date>2006</date>
<contexts>
<context position="4975" citStr="Ferrucci et al., 2006" startWordPosition="773" endWordPosition="776">Background 2.1 UINA UIMA is an open framework specified by OASIS2. Apache UIMA provides a reference implementation as an open source project, with both a pure java API and a C++ development kit . UIMA itself is intended to be purely a framework, i.e. it does not intend to provide specific tools or type system definitions. Users should develop such resources themselves. In the following subsections, we briefly describe the basic concepts of UIMA, and define keywords used to explain our system in later sections. 2.1.1 CAS and Type System The UIMA framework uses the “stand-off annotation” style (Ferrucci et al., 2006). The underling raw text of a document is generally kept unchanged during analysis, and the results of processing the text are added as new stand-off annotations with references to their positions in the raw text. A Common Analysis Structure (CAS) holds a set of such annotations. Each of which is of a given type as defined in a specified hierarchical type system. Annotation3 types may define features, which are themselves typed. Apache UIMA provides definitions of a range of built in primitive types, but a more complete type system should be specified by developers. The top level Apache UIMA t</context>
</contexts>
<marker>Ferrucci, Lally, Gruhl, Epstein, 2006</marker>
<rawString>David Ferrucci, Adam Lally, Daniel Gruhl, and Edward Epstein. 2006. Towards an Interoperability Standard for Text and Multi-Modal Analytics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Hahn</author>
<author>E Buyko</author>
<author>R Landefeld</author>
<author>M Mühlhausen</author>
<author>M Poprat</author>
<author>K Tomanek</author>
</authors>
<title>An Overview of JCoRe, the JULIE Lab UIMA Component Repository.</title>
<date>2008</date>
<booktitle>In Proceedings of the LREC&apos;08 Workshop, Towards Enhanced Interoperability for Large HLT Systems: UIMA for NLP,</booktitle>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="7548" citStr="Hahn et al., 2008" startWordPosition="1186" endWordPosition="1189">e NLP components for use with any UIMA based system. This toolkit is currently the world largest repository of type system compatible components. These all implement the UCompare type system described in section 3. 3 In the UIMA framework, Annotation is a base type which has begin and end offset values. In this paper we call any objects (any subtype of TOP) as annotations. 2 http://www.oasis-open.org/committees/uima/ 23 2.2.1 Related Works There also exist several other public UIMA component repositories: CMU UIMA component repository, BioNLP UIMA repository (Baumgartner et al., 2008), JCoRe (Hahn et al., 2008), Tsujii Lab Component Repository at the University of Tokyo (Kano et al., 2008a), etc. Each group uses their own type system, and so components provided by each group are incompatible. Unlike U-Compare these repositories are basically only collections of UIMA components, UCompare goes further by providing a fully integrated set of UIMA tools and utilities. 2.2.2 Integrated Platform U-Compare provides a variety of features as part of an integrated platform. The system can be launched with a single click in a web browser; all required libraries are downloaded and updated automatically in backgr</context>
</contexts>
<marker>Hahn, Buyko, Landefeld, Mühlhausen, Poprat, Tomanek, 2008</marker>
<rawString>U. Hahn, E. Buyko, R. Landefeld, M. Mühlhausen, M. Poprat, K. Tomanek, et al. 2008, May. An Overview of JCoRe, the JULIE Lab UIMA Component Repository. In Proceedings of the LREC&apos;08 Workshop, Towards Enhanced Interoperability for Large HLT Systems: UIMA for NLP, Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynette Hirschman</author>
<author>Alexander Yeh</author>
<author>Christian Blaschke</author>
<author>Antonio Valencia</author>
</authors>
<title>Overview of BioCreAtIvE: critical assessment of information extraction for biology. BMC Bionformatics, 6(Suppl 1:S1).</title>
<date>2004</date>
<contexts>
<context position="19896" citStr="Hirschman et al., 2004" startWordPosition="3014" endWordPosition="3017">ction. 5.1 Corpus Reader Components In the UIMA framework, a component which generates CASes is called a Collection Reader. We have developed several collection readers which read annotated corpora and generates annotations using the U-Compare type system. Because our primary target domain was biomedical field, there are corpus readers for the biomedical corpora; Aimed corpus (Bunescu et al., 2006) reader and BioNLP ’09 shared task format reader generate event annotations like protein-protein interaction annotations; Readers for BIO/IOB format, Bio1 corpus (Tateisi et al., 2000), BioCreative (Hirschman et al., 2004) task 1a format, BioIE corpus (Bies et al., 2005), NLPBA shared task dataset (Kim et al., 2004), Texas Corpus (Bunescu et al., 2005), Yapex Corpus (Kristofer Franzen et al., 2002), generate biomedical named entities, and Genia Treebank corpus (Tateisi et al., 2005) reader generates Penn Treebank (Marcus et al., 1993) style bracketing and part-of-speech annotations. Format readers require users to prepare annotated data, while others include corpora themselves, automatically downloaded as an archive on users’ demand. In addition, there is File System Collection Reader from Apache UIMA which rea</context>
</contexts>
<marker>Hirschman, Yeh, Blaschke, Valencia, 2004</marker>
<rawString>Lynette Hirschman, Alexander Yeh, Christian Blaschke, and Antonio Valencia. 2004. Overview of BioCreAtIvE: critical assessment of information extraction for biology. BMC Bionformatics, 6(Suppl 1:S1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshinobu Kano</author>
<author>William A Baumgartner</author>
<author>Luke McCrohon</author>
<author>Sophia Ananiadou</author>
<author>Kevin B Cohen</author>
<author>Lawrence Hunter</author>
</authors>
<title>U-Compare: share and compare text mining tools with UIMA.</title>
<date>2009</date>
<journal>Bioinformatics, accepted.</journal>
<contexts>
<context position="2981" citStr="Kano et al., 2009" startWordPosition="456" endWordPosition="459">s. Comparing of &amp;quot;Apples to Apples&amp;quot; provides another reason why standardization of NLP tools is beneficial. Another advantage of standardization is that the number of gold standard data sets that can be compared against is also increased, allowing tools to be tested in a wider range of domains. The ideal is that all components are standardized to conform to an open, widely used interoperability framework. One possible such framework is UIMA; Unstructured Information Management Architecture (Ferrucci et al., 2004), which is an open project of OASIS and Apache. We have been developing U-Compare (Kano et al., 2009)1, an integrated testing an evaluation platform based on this framework. 1 Features described in this paper are integrated as UCompare system, publicly available from: http://u-compare.org/ 22 Proceedings of the NAACL HLT Workshop on Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 22–30, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Although U-Compare already provided a wide range of tools and NLP resources, its inbuilt evaluation mechanisms were hard coded into the system and were not customizable by end users. Furth</context>
</contexts>
<marker>Kano, Baumgartner, McCrohon, Ananiadou, Cohen, Hunter, 2009</marker>
<rawString>Yoshinobu Kano, William A Baumgartner, Luke McCrohon, Sophia Ananiadou, Kevin B Cohen, Lawrence Hunter, et al. 2009. U-Compare: share and compare text mining tools with UIMA. Bioinformatics, accepted.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshinobu Kano</author>
<author>Ngan Nguyen</author>
<author>Rune Sætre</author>
<author>Keiichiro Fukamachi</author>
<author>Kazuhiro Yoshida</author>
<author>Yusuke Miyao</author>
</authors>
<title>Sharable type system design for tool inter-operability and combinatorial comparison.</title>
<date>2008</date>
<booktitle>In Proceedings of the the First International Conference on Global Interoperability for Language Resources (ICGL), Hong Kong.</booktitle>
<contexts>
<context position="7627" citStr="Kano et al., 2008" startWordPosition="1200" endWordPosition="1203">he world largest repository of type system compatible components. These all implement the UCompare type system described in section 3. 3 In the UIMA framework, Annotation is a base type which has begin and end offset values. In this paper we call any objects (any subtype of TOP) as annotations. 2 http://www.oasis-open.org/committees/uima/ 23 2.2.1 Related Works There also exist several other public UIMA component repositories: CMU UIMA component repository, BioNLP UIMA repository (Baumgartner et al., 2008), JCoRe (Hahn et al., 2008), Tsujii Lab Component Repository at the University of Tokyo (Kano et al., 2008a), etc. Each group uses their own type system, and so components provided by each group are incompatible. Unlike U-Compare these repositories are basically only collections of UIMA components, UCompare goes further by providing a fully integrated set of UIMA tools and utilities. 2.2.2 Integrated Platform U-Compare provides a variety of features as part of an integrated platform. The system can be launched with a single click in a web browser; all required libraries are downloaded and updated automatically in background. The Workflow Manager GUI helps users to create workflows in an easy drag-</context>
<context position="13882" citStr="Kano et al., 2008" startWordPosition="2185" endWordPosition="2188">ompare also provides visualizations of evaluation results allowing instance-based error analysis. 4 U-Compare Type System U-Compare currently provides the world largest set of type system compatible UIMA components. We will describe some of these in section 5. In creating compatible components in UIMA a key task is their type system definitions. The U-Compare type system is designed in a hierarchical fashion with distinct types to achieve a high level of interoperability. It is intended to be a shared type system capable of mapping types originally defined as part of independent type systems (Kano et al., 2008c). In this section we describe the U-Compare type system in detail. 4.1 Basic Types While most of the U-Compare types are inheriting a UIMA built-in type, Annotation (Figure 1), there are also types directly extending the TOP type; let us call these types as metadata types. AnnotationMetadata holds a confidence value, which is common to all of the U-Compare annotation types as a feature of BaseAnnotation type. BaseAnnotation extends DiscontinuousAnnotation, in which fragmental annotations can be stored as a FSArray of Annotations, if any. ExternalReference is another common metadata type wher</context>
</contexts>
<marker>Kano, Nguyen, Sætre, Fukamachi, Yoshida, Miyao, 2008</marker>
<rawString>Yoshinobu Kano, Ngan Nguyen, Rune Sætre, Keiichiro Fukamachi, Kazuhiro Yoshida, Yusuke Miyao, et al. 2008c, January. Sharable type system design for tool inter-operability and combinatorial comparison. In Proceedings of the the First International Conference on Global Interoperability for Language Resources (ICGL), Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshinobu Kano</author>
<author>Ngan Nguyen</author>
<author>Rune Sætre</author>
<author>Kazuhiro Yoshida</author>
<author>Keiichiro Fukamachi</author>
<author>Yusuke Miyao</author>
</authors>
<title>Towards Data And Goal Oriented Analysis: Tool Inter-Operability And Combinatorial Comparison.</title>
<date>2008</date>
<booktitle>In Proceedings of the 3rd International Joint Conference on Natural Language Processing (IJCNLP),</booktitle>
<location>Hyderabad, India.</location>
<contexts>
<context position="7627" citStr="Kano et al., 2008" startWordPosition="1200" endWordPosition="1203">he world largest repository of type system compatible components. These all implement the UCompare type system described in section 3. 3 In the UIMA framework, Annotation is a base type which has begin and end offset values. In this paper we call any objects (any subtype of TOP) as annotations. 2 http://www.oasis-open.org/committees/uima/ 23 2.2.1 Related Works There also exist several other public UIMA component repositories: CMU UIMA component repository, BioNLP UIMA repository (Baumgartner et al., 2008), JCoRe (Hahn et al., 2008), Tsujii Lab Component Repository at the University of Tokyo (Kano et al., 2008a), etc. Each group uses their own type system, and so components provided by each group are incompatible. Unlike U-Compare these repositories are basically only collections of UIMA components, UCompare goes further by providing a fully integrated set of UIMA tools and utilities. 2.2.2 Integrated Platform U-Compare provides a variety of features as part of an integrated platform. The system can be launched with a single click in a web browser; all required libraries are downloaded and updated automatically in background. The Workflow Manager GUI helps users to create workflows in an easy drag-</context>
<context position="13882" citStr="Kano et al., 2008" startWordPosition="2185" endWordPosition="2188">ompare also provides visualizations of evaluation results allowing instance-based error analysis. 4 U-Compare Type System U-Compare currently provides the world largest set of type system compatible UIMA components. We will describe some of these in section 5. In creating compatible components in UIMA a key task is their type system definitions. The U-Compare type system is designed in a hierarchical fashion with distinct types to achieve a high level of interoperability. It is intended to be a shared type system capable of mapping types originally defined as part of independent type systems (Kano et al., 2008c). In this section we describe the U-Compare type system in detail. 4.1 Basic Types While most of the U-Compare types are inheriting a UIMA built-in type, Annotation (Figure 1), there are also types directly extending the TOP type; let us call these types as metadata types. AnnotationMetadata holds a confidence value, which is common to all of the U-Compare annotation types as a feature of BaseAnnotation type. BaseAnnotation extends DiscontinuousAnnotation, in which fragmental annotations can be stored as a FSArray of Annotations, if any. ExternalReference is another common metadata type wher</context>
</contexts>
<marker>Kano, Nguyen, Sætre, Yoshida, Fukamachi, Miyao, 2008</marker>
<rawString>Yoshinobu Kano, Ngan Nguyen, Rune Sætre, Kazuhiro Yoshida, Keiichiro Fukamachi, Yusuke Miyao, et al. 2008b, January. Towards Data And Goal Oriented Analysis: Tool Inter-Operability And Combinatorial Comparison. In Proceedings of the 3rd International Joint Conference on Natural Language Processing (IJCNLP), Hyderabad, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshinobu Kano</author>
<author>Ngan Nguyen</author>
<author>Rune Sætre</author>
<author>Kazuhiro Yoshida</author>
<author>Yusuke Miyao</author>
<author>Yoshimasa Tsuruoka</author>
</authors>
<title>Filling the gaps between tools and users: a tool comparator, using proteinprotein interaction as an example.</title>
<date>2008</date>
<booktitle>In Proceedings of the Pacific Symposium on Biocomputing (PSB),</booktitle>
<location>Hawaii, USA.</location>
<contexts>
<context position="7627" citStr="Kano et al., 2008" startWordPosition="1200" endWordPosition="1203">he world largest repository of type system compatible components. These all implement the UCompare type system described in section 3. 3 In the UIMA framework, Annotation is a base type which has begin and end offset values. In this paper we call any objects (any subtype of TOP) as annotations. 2 http://www.oasis-open.org/committees/uima/ 23 2.2.1 Related Works There also exist several other public UIMA component repositories: CMU UIMA component repository, BioNLP UIMA repository (Baumgartner et al., 2008), JCoRe (Hahn et al., 2008), Tsujii Lab Component Repository at the University of Tokyo (Kano et al., 2008a), etc. Each group uses their own type system, and so components provided by each group are incompatible. Unlike U-Compare these repositories are basically only collections of UIMA components, UCompare goes further by providing a fully integrated set of UIMA tools and utilities. 2.2.2 Integrated Platform U-Compare provides a variety of features as part of an integrated platform. The system can be launched with a single click in a web browser; all required libraries are downloaded and updated automatically in background. The Workflow Manager GUI helps users to create workflows in an easy drag-</context>
<context position="13882" citStr="Kano et al., 2008" startWordPosition="2185" endWordPosition="2188">ompare also provides visualizations of evaluation results allowing instance-based error analysis. 4 U-Compare Type System U-Compare currently provides the world largest set of type system compatible UIMA components. We will describe some of these in section 5. In creating compatible components in UIMA a key task is their type system definitions. The U-Compare type system is designed in a hierarchical fashion with distinct types to achieve a high level of interoperability. It is intended to be a shared type system capable of mapping types originally defined as part of independent type systems (Kano et al., 2008c). In this section we describe the U-Compare type system in detail. 4.1 Basic Types While most of the U-Compare types are inheriting a UIMA built-in type, Annotation (Figure 1), there are also types directly extending the TOP type; let us call these types as metadata types. AnnotationMetadata holds a confidence value, which is common to all of the U-Compare annotation types as a feature of BaseAnnotation type. BaseAnnotation extends DiscontinuousAnnotation, in which fragmental annotations can be stored as a FSArray of Annotations, if any. ExternalReference is another common metadata type wher</context>
</contexts>
<marker>Kano, Nguyen, Sætre, Yoshida, Miyao, Tsuruoka, 2008</marker>
<rawString>Yoshinobu Kano, Ngan Nguyen, Rune Sætre, Kazuhiro Yoshida, Yusuke Miyao, Yoshimasa Tsuruoka, et al. 2008a, January. Filling the gaps between tools and users: a tool comparator, using proteinprotein interaction as an example. In Proceedings of the Pacific Symposium on Biocomputing (PSB), Hawaii, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Dong Kim</author>
<author>Tomoko Ohta</author>
<author>Yoshimasa Tsuruoka</author>
<author>Yuka Tateisi</author>
<author>Nigel Collier</author>
</authors>
<title>Introduction to the Bio-Entity Recognition Task at JNLPBA.</title>
<date>2004</date>
<booktitle>In Proceedings of the International Workshop on Natural Language Processing in Biomedicine and its Applications (JNLPBA-04),</booktitle>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="19991" citStr="Kim et al., 2004" startWordPosition="3031" endWordPosition="3034">d a Collection Reader. We have developed several collection readers which read annotated corpora and generates annotations using the U-Compare type system. Because our primary target domain was biomedical field, there are corpus readers for the biomedical corpora; Aimed corpus (Bunescu et al., 2006) reader and BioNLP ’09 shared task format reader generate event annotations like protein-protein interaction annotations; Readers for BIO/IOB format, Bio1 corpus (Tateisi et al., 2000), BioCreative (Hirschman et al., 2004) task 1a format, BioIE corpus (Bies et al., 2005), NLPBA shared task dataset (Kim et al., 2004), Texas Corpus (Bunescu et al., 2005), Yapex Corpus (Kristofer Franzen et al., 2002), generate biomedical named entities, and Genia Treebank corpus (Tateisi et al., 2005) reader generates Penn Treebank (Marcus et al., 1993) style bracketing and part-of-speech annotations. Format readers require users to prepare annotated data, while others include corpora themselves, automatically downloaded as an archive on users’ demand. In addition, there is File System Collection Reader from Apache UIMA which reads files as plain text. We have developed an online interactive text reader, named Input Text R</context>
</contexts>
<marker>Kim, Ohta, Tsuruoka, Tateisi, Collier, 2004</marker>
<rawString>Jin-Dong Kim, Tomoko Ohta, Yoshimasa Tsuruoka, Yuka Tateisi, and Nigel Collier. 2004. Introduction to the Bio-Entity Recognition Task at JNLPBA. In Proceedings of the International Workshop on Natural Language Processing in Biomedicine and its Applications (JNLPBA-04), Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristofer Franzen</author>
</authors>
<title>Gunnar Eriksson, Fredrik Olsson, Lars Asker, Per Liden, and Joakim Coster.</title>
<date>2002</date>
<journal>International Journal of Medical Informatics,</journal>
<volume>67</volume>
<issue>1</issue>
<pages>49--61</pages>
<marker>Franzen, 2002</marker>
<rawString>Kristofer Franzen, Gunnar Eriksson, Fredrik Olsson, Lars Asker, Per Liden, and Joakim Coster. 2002. Protein names and how to find them. International Journal of Medical Informatics, 67(1-3), 49-61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Beatrice Santorini</author>
</authors>
<title>Building a large annotated corpus of English: the penn treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<pages>313--330</pages>
<contexts>
<context position="20214" citStr="Marcus et al., 1993" startWordPosition="3064" endWordPosition="3067">e corpus readers for the biomedical corpora; Aimed corpus (Bunescu et al., 2006) reader and BioNLP ’09 shared task format reader generate event annotations like protein-protein interaction annotations; Readers for BIO/IOB format, Bio1 corpus (Tateisi et al., 2000), BioCreative (Hirschman et al., 2004) task 1a format, BioIE corpus (Bies et al., 2005), NLPBA shared task dataset (Kim et al., 2004), Texas Corpus (Bunescu et al., 2005), Yapex Corpus (Kristofer Franzen et al., 2002), generate biomedical named entities, and Genia Treebank corpus (Tateisi et al., 2005) reader generates Penn Treebank (Marcus et al., 1993) style bracketing and part-of-speech annotations. Format readers require users to prepare annotated data, while others include corpora themselves, automatically downloaded as an archive on users’ demand. In addition, there is File System Collection Reader from Apache UIMA which reads files as plain text. We have developed an online interactive text reader, named Input Text Reader. 187 The document length in bytes is output in the first line (end with new line), then the raw text follows as is (attaching a new line in the end), finally annotations follow line by line. 0 187 Document id=&amp;quot;u1&amp;quot; 0 3</context>
</contexts>
<marker>Marcus, Marcinkiewicz, Santorini, 1993</marker>
<rawString>Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. 1993. Building a large annotated corpus of English: the penn treebank. Computational Linguistics, 19(2), 313-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Miyao</author>
<author>Jun&apos;ichi Tsujii</author>
</authors>
<title>Feature Forest Models for Probabilistic HPSG Parsing.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>1</issue>
<pages>35--80</pages>
<marker>Miyao, Tsujii, 2008</marker>
<rawString>Yusuke Miyao, and Jun&apos;ichi Tsujii. 2008. Feature Forest Models for Probabilistic HPSG Parsing. Computational Linguistics, 34(1), 35-80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rune Sætre</author>
<author>Kazuhiro Yoshida</author>
<author>Akane Yakushiji</author>
<author>Yusuke Miyao</author>
<author>Yuichiro Matsubayashi</author>
<author>Tomoko Ohta</author>
</authors>
<date>2007</date>
<booktitle>AKANE System: ProteinProtein Interaction Pairs in BioCreAtIvE2 Challenge, PPI-IPS subtask. In Proceedings of the Second BioCreative Challenge Evaluation Workshop.</booktitle>
<contexts>
<context position="21722" citStr="Sætre et al., 2007" startWordPosition="3300" endWordPosition="3303">al services and web services. For syntactic annotations: sentence detectors from GENIA, LingPipe, NaCTeM, OpenNLP and Apache UIMA; tokenizers from GENIA tagger (Tsuruoka et al., 2005), OpenNLP, Apache UIMA and Penn Bio Tokenizer; POS taggers from GENIA tagger, LingPipe, OpenNLP and Stepp Tagger; parsers from OpenNLP (CFG), Stanford Parser (dependency) (de Marneffe et al., 2006), Enju (HPSG) (Miyao et al., 2008). For semantic annotations: ABNER (Settles, 2005) for NLPBA/BioCreative trained models, GENIA Tagger, NeMine, MedT-NER, LingPipe and OpenNLP NER, for named entity recognitions. Akane++ (Sætre et al., 2007) for proteinprotein interaction detections. 5.3 Components for Developers Although Apache UIMA provides APIs in both Java and C++ to help users develop UIMA components, a level of understanding of the UIMA framework is still required. Conversion of existing tools to the UIMA framework can also be difficult, particularly when they are written in other programming languages. We have designed a simple I/O format to make it easy for developers who just want to provide a UIMA wrapper for existing tools. Input of this format consists of two parts: raw text and annotations The first line of the raw t</context>
</contexts>
<marker>Sætre, Yoshida, Yakushiji, Miyao, Matsubayashi, Ohta, 2007</marker>
<rawString>Rune Sætre, Kazuhiro Yoshida, Akane Yakushiji, Yusuke Miyao, Yuichiro Matsubayashi, and Tomoko Ohta. 2007, April. AKANE System: ProteinProtein Interaction Pairs in BioCreAtIvE2 Challenge, PPI-IPS subtask. In Proceedings of the Second BioCreative Challenge Evaluation Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Burr Settles</author>
</authors>
<title>ABNER: an open source tool for automatically tagging genes, proteins and other entity names in text.</title>
<date>2005</date>
<journal>Bioinformatics,</journal>
<volume>21</volume>
<issue>14</issue>
<pages>3191--3192</pages>
<contexts>
<context position="21566" citStr="Settles, 2005" startWordPosition="3280" endWordPosition="3281">ls covering from basic syntactic annotations to the biomedical annotations. Some of the tools are running as web services, but users can freely mix local services and web services. For syntactic annotations: sentence detectors from GENIA, LingPipe, NaCTeM, OpenNLP and Apache UIMA; tokenizers from GENIA tagger (Tsuruoka et al., 2005), OpenNLP, Apache UIMA and Penn Bio Tokenizer; POS taggers from GENIA tagger, LingPipe, OpenNLP and Stepp Tagger; parsers from OpenNLP (CFG), Stanford Parser (dependency) (de Marneffe et al., 2006), Enju (HPSG) (Miyao et al., 2008). For semantic annotations: ABNER (Settles, 2005) for NLPBA/BioCreative trained models, GENIA Tagger, NeMine, MedT-NER, LingPipe and OpenNLP NER, for named entity recognitions. Akane++ (Sætre et al., 2007) for proteinprotein interaction detections. 5.3 Components for Developers Although Apache UIMA provides APIs in both Java and C++ to help users develop UIMA components, a level of understanding of the UIMA framework is still required. Conversion of existing tools to the UIMA framework can also be difficult, particularly when they are written in other programming languages. We have designed a simple I/O format to make it easy for developers </context>
</contexts>
<marker>Settles, 2005</marker>
<rawString>Burr Settles. 2005. ABNER: an open source tool for automatically tagging genes, proteins and other entity names in text. Bioinformatics, 21(14), 3191-3192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuka Tateisi</author>
<author>Tomoko Ohta</author>
<author>Nigel Collier</author>
<author>Chikashi Nobata</author>
<author>Jun&apos;ichi Tsujii</author>
</authors>
<title>Building an Annotated Corpus from Biology Research Papers.</title>
<date>2000</date>
<booktitle>In Proceedings of the COLING 2000 Workshop on Semantic Annotation and Intelligent Content,</booktitle>
<location>Luxembourg.</location>
<contexts>
<context position="19858" citStr="Tateisi et al., 2000" startWordPosition="3009" endWordPosition="3012"> system described in the previous section. 5.1 Corpus Reader Components In the UIMA framework, a component which generates CASes is called a Collection Reader. We have developed several collection readers which read annotated corpora and generates annotations using the U-Compare type system. Because our primary target domain was biomedical field, there are corpus readers for the biomedical corpora; Aimed corpus (Bunescu et al., 2006) reader and BioNLP ’09 shared task format reader generate event annotations like protein-protein interaction annotations; Readers for BIO/IOB format, Bio1 corpus (Tateisi et al., 2000), BioCreative (Hirschman et al., 2004) task 1a format, BioIE corpus (Bies et al., 2005), NLPBA shared task dataset (Kim et al., 2004), Texas Corpus (Bunescu et al., 2005), Yapex Corpus (Kristofer Franzen et al., 2002), generate biomedical named entities, and Genia Treebank corpus (Tateisi et al., 2005) reader generates Penn Treebank (Marcus et al., 1993) style bracketing and part-of-speech annotations. Format readers require users to prepare annotated data, while others include corpora themselves, automatically downloaded as an archive on users’ demand. In addition, there is File System Collec</context>
</contexts>
<marker>Tateisi, Ohta, Collier, Nobata, Tsujii, 2000</marker>
<rawString>Yuka Tateisi, Tomoko Ohta, Nigel Collier, Chikashi Nobata, and Jun&apos;ichi Tsujii. 2000, August. Building an Annotated Corpus from Biology Research Papers. In Proceedings of the COLING 2000 Workshop on Semantic Annotation and Intelligent Content, Luxembourg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuka Tateisi</author>
<author>Akane Yakushiji</author>
<author>Tomoko Ohta</author>
<author>Jun&apos;ichi Tsujii</author>
</authors>
<title>Syntax Annotation for the GENIA Corpus.</title>
<date>2005</date>
<booktitle>In Proceedings of the the Second International Joint Conference on Natural Language Processing (IJCNLP &apos;05), Companion volume, Jeju Island,</booktitle>
<contexts>
<context position="20161" citStr="Tateisi et al., 2005" startWordPosition="3056" endWordPosition="3059">r primary target domain was biomedical field, there are corpus readers for the biomedical corpora; Aimed corpus (Bunescu et al., 2006) reader and BioNLP ’09 shared task format reader generate event annotations like protein-protein interaction annotations; Readers for BIO/IOB format, Bio1 corpus (Tateisi et al., 2000), BioCreative (Hirschman et al., 2004) task 1a format, BioIE corpus (Bies et al., 2005), NLPBA shared task dataset (Kim et al., 2004), Texas Corpus (Bunescu et al., 2005), Yapex Corpus (Kristofer Franzen et al., 2002), generate biomedical named entities, and Genia Treebank corpus (Tateisi et al., 2005) reader generates Penn Treebank (Marcus et al., 1993) style bracketing and part-of-speech annotations. Format readers require users to prepare annotated data, while others include corpora themselves, automatically downloaded as an archive on users’ demand. In addition, there is File System Collection Reader from Apache UIMA which reads files as plain text. We have developed an online interactive text reader, named Input Text Reader. 187 The document length in bytes is output in the first line (end with new line), then the raw text follows as is (attaching a new line in the end), finally annota</context>
</contexts>
<marker>Tateisi, Yakushiji, Ohta, Tsujii, 2005</marker>
<rawString>Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, and Jun&apos;ichi Tsujii. 2005, October. Syntax Annotation for the GENIA Corpus. In Proceedings of the the Second International Joint Conference on Natural Language Processing (IJCNLP &apos;05), Companion volume, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshimasa Tsuruoka</author>
<author>Yuka Tateishi</author>
<author>Jin Dong Kim</author>
<author>Tomoko Ohta</author>
<author>J McNaught</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Developing a robust part-of-speech tagger for biomedical text.</title>
<date>2005</date>
<booktitle>In Advances in Informatics, Proceedings</booktitle>
<volume>3746</volume>
<pages>382--392</pages>
<publisher>Springer-Verlag</publisher>
<location>Berlin:</location>
<contexts>
<context position="21286" citStr="Tsuruoka et al., 2005" startWordPosition="3237" endWordPosition="3240">with new line), then the raw text follows as is (attaching a new line in the end), finally annotations follow line by line. 0 187 Document id=&amp;quot;u1&amp;quot; 0 3 POSToken id=&amp;quot;u2&amp;quot; pos=&amp;quot;DT&amp;quot; .... Figure 5. An example of the U-Compare simple I/O format. 5.2 Analysis Engine Components There are many tools covering from basic syntactic annotations to the biomedical annotations. Some of the tools are running as web services, but users can freely mix local services and web services. For syntactic annotations: sentence detectors from GENIA, LingPipe, NaCTeM, OpenNLP and Apache UIMA; tokenizers from GENIA tagger (Tsuruoka et al., 2005), OpenNLP, Apache UIMA and Penn Bio Tokenizer; POS taggers from GENIA tagger, LingPipe, OpenNLP and Stepp Tagger; parsers from OpenNLP (CFG), Stanford Parser (dependency) (de Marneffe et al., 2006), Enju (HPSG) (Miyao et al., 2008). For semantic annotations: ABNER (Settles, 2005) for NLPBA/BioCreative trained models, GENIA Tagger, NeMine, MedT-NER, LingPipe and OpenNLP NER, for named entity recognitions. Akane++ (Sætre et al., 2007) for proteinprotein interaction detections. 5.3 Components for Developers Although Apache UIMA provides APIs in both Java and C++ to help users develop UIMA compone</context>
</contexts>
<marker>Tsuruoka, Tateishi, Kim, Ohta, McNaught, Ananiadou, 2005</marker>
<rawString>Yoshimasa Tsuruoka, Yuka Tateishi, Jin Dong Kim, Tomoko Ohta, J. McNaught, Sophia Ananiadou, et al. 2005. Developing a robust part-of-speech tagger for biomedical text. In Advances in Informatics, Proceedings (Vol. 3746, 382-392). Berlin: Springer-Verlag Berlin.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>