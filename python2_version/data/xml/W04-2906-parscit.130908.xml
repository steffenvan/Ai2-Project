<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.054535">
<title confidence="0.9947115">
Assessing Prosodic and Text Features for Segmentation of Mandarin
Broadcast News
</title>
<author confidence="0.810578">
Gina-Anne Levow
</author>
<affiliation confidence="0.849495">
University of Chicago
</affiliation>
<email confidence="0.998576">
levow@cs.uchicago.edu
</email>
<sectionHeader confidence="0.998587" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999398931034483">
Automatic topic segmentation, separation of
a discourse stream into its constituent sto-
ries or topics, is a necessary preprocessing
step for applications such as information re-
trieval, anaphora resolution, and summariza-
tion. While significant progress has been made
in this area for text sources and for English au-
dio sources, little work has been done in au-
tomatic segmentation of other languages us-
ing both text and acoustic information. In
this paper, we focus on exploiting both textual
and prosodic features for topic segmentation of
Mandarin Chinese. As a tone language, Man-
darin presents special challenges for applica-
bility of intonation-based techniques, since the
pitch contour is also used to establish lexical
identity. However, intonational cues such as re-
duction in pitch and intensity at topic bound-
aries and increase in duration and pause still
provide significant contrasts in Mandarin Chi-
nese. We first build a decision tree classi-
fier that based only on prosodic information
achieves boundary classification accuracy of
89-95.8% on a large standard test set. We
then contrast these results with a simple text
similarity-based classification scheme. Finally
we build a merged classifier, finding the best
effectiveness for systems integrating text and
prosodic cues.
</bodyText>
<sectionHeader confidence="0.999511" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999967612244898">
Natural spoken discourse is composed of a sequence
of utterances, not independently generated or randomly
strung together, but rather organized according to basic
structural principles. This structure in turn guides the in-
terpretation of individual utterances and the discourse as
a whole. Formal written discourse signals a hierarchical,
tree-based discourse structure explicitly by the division
of the text into chapters, sections, paragraphs, and sen-
tences. This structure, in turn, identifies domains for in-
terpretation; many systems for anaphora resolution rely
on some notion of locality (Grosz and Sidner, 1986).
Similarly, this structure represents topical organization,
and thus would be useful in information retrieval to se-
lect documents where the primary sections are on-topic,
and, for summarization, to select information covering
the different aspects of the topic.
Unfortunately, spoken discourse does not include the
orthographic conventions that signal structural organiza-
tion in written discourse. Instead, one must infer the hi-
erarchical structure of spoken discourse from other cues.
Prior research (Nakatani et al., 1995; Swerts, 1997) has
shown that human labelers can more sharply, consis-
tently, and confidently identify discourse structure in a
word-level transcription when an original audio record-
ing is available than they can on the basis of the tran-
scribed text alone. This finding indicates that substan-
tial additional information about the structure of the dis-
course is encoded in the acoustic-prosodic features of the
utterance. Given the often errorful transcriptions avail-
able for large speech corpora, we choose to focus here
on fully exploiting the prosodic cues to discourse struc-
ture present in the original speech in addition to possibly
noisy textual cues. We then compare the effectiveness of
a pure prosodic classification to text-based and mixed text
and prosodic based classification.
In the current set of experiments, we concentrate on se-
quential segmentation of news broadcasts into individual
stories. This level of segmentation can be most reliably
performed by human labelers and thus can be considered
most robust, and segmented data sets are publicly avail-
able.
Furthermore, we consider the relative effectiveness
prosodic-based, text-based, and mixed cue-based seg-
mentation for Mandarin Chinese, to assess the relative
utility of the cues for a tone language. Not only is the use
of prosodic cues to topic segmentation much less well-
studied in general than is the use of text cues, but the use
of prosodic cues has been largely limited to English and
other European languages.
</bodyText>
<sectionHeader confidence="0.999874" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999931692307692">
Most prior research on automatic topic segmentation has
been applied to clean text only and thus used textual fea-
tures. Text-based segmentation approaches have utilized
term-based similarity measures computed across candi-
date segments (Hearst, 1994) and also discourse markers
to identify discourse structure (Marcu, 2000).
The Topic Detection and Tracking (TDT) evaluations
focused on segmentation of both text and speech sources.
This framework introduced new challenges in dealing
with errorful automatic transcriptions as well as new op-
portunities to exploit cues in the original speech. The
most successful approach (Beeferman et al., 1999) pro-
duced automatic segmentations that yielded retrieval re-
sults comparable to those with manual segmentations, us-
ing text and silence features. (Tur et al., 2001) applied
both a prosody-only and a mixed text-prosody model
to segmentation of TDT English broadcast news, with
the best results combining text and prosodic features.
(Hirschberg and Nakatani, 1998) also examined auto-
matic topic segmentation based on prosodic cues, in the
domain of English broadcast news.
Work in discourse analysis (Nakatani et al., 1995;
Swerts, 1997) in both English and Dutch has identified
features such as changes in pitch range, intensity, and
speaking rate associated with segment boundaries and
with boundaries of different strengths.
</bodyText>
<sectionHeader confidence="0.975615" genericHeader="method">
3 Data Set
</sectionHeader>
<bodyText confidence="0.999962071428572">
We utilize the Topic Detection and Tracking (TDT)
3 (Wayne, 2000) collection Mandarin Chinese broadcast
news audio corpus as our data set. Story segmentation in
Mandarin and English broadcast news and newswire text
was one of the TDT tasks and also an enabling technol-
ogy for other retrieval tasks. We use the segment bound-
aries provided with the corpus as our gold standard label-
ing. Our collection comprises 3014 stories drawn from
approximately 113 hours over three months (October-
December 1998) of news broadcasts from the Voice of
America (VOA) in Mandarin Chinese. The transcriptions
span approximately 740,000 words. The audio is stored
in NIST Sphere format sampled at 16KHz with 16-bit lin-
ear encoding.
</bodyText>
<sectionHeader confidence="0.984453" genericHeader="method">
4 Prosodic Features
</sectionHeader>
<bodyText confidence="0.997315918367347">
We employ four main classes of prosodic features: pitch,
intensity, silence and duration. Pitch, as represented by f0
in Hertz, was computed by the “To pitch” function of the
Praat system (Boersma, 2001). We then applied a 5-point
median filter to smooth out local instabilities in the signal
such as vocal fry or small regions of spurious doubling or
halving. Analogously, we computed the intensity in deci-
bels for each 10ms frame with the Praat “To intensity”
function, followed by similar smoothing.
For consistency and to allow comparability, we com-
puted all figures for word-based units, using the ASR
transcriptions provided with the TDT Mandarin data. The
words are used to establish time spans for computing
pitch or intensity mean or maximum values, to enable
durational normalization and pairwise comparison, and
to identify silence duration.
It is well-established (Ross and Ostendorf, 1996) that
for robust analysis pitch and intensity should be nor-
malized by speaker, since, for example, average pitch
is largely incomparable for male and female speak-
ers. In the absence of speaker identification software,
we approximate speaker normalization with story-based
normalization, computed as , assuming one
speaker per topic&apos;. For duration, we consider both abso-
lute and normalized word duration, where average word
duration is used as the mean in the calculation above.
Mandarin Chinese is a tone language in which lexi-
cal identity is determined by a pitch contour - or tone
- associated with each syllable. This additional use of
pitch raises the question of the cross-linguistic applicabil-
ity of the prosodic cues, especially pitch cues, identified
for non-tone languages. Specifically, do we find intona-
tional cues in tone languages?
We have found highly significant differences based
)
for words in segment-final position, relative to the same
word in non-final positions. (Levow, 2004). Specifically,
word duration, normalized mean pitch, and normalized
mean intensity all differ significantly for words in topic-
final position relative to occurrences throughout the story.
Word duration increases, while both pitch and intensity
decrease. Importantly, reduction in pitch as a signal of
topic finality is robust across the typological contrast of
tone and non-tone languages, such as English (Nakatani
et al., 1995) and Dutch (Swerts, 1997).
&apos;This is an imperfect approximation as some stories include
off-site interviews, but seems a reasonable choice in the absence
of automatic speaker identification.
on paired t-test two-tailed, (
</bodyText>
<sectionHeader confidence="0.999005" genericHeader="evaluation">
5 Classification
</sectionHeader>
<subsectionHeader confidence="0.999114">
5.1 Prosodic Feature Set
</subsectionHeader>
<bodyText confidence="0.9999650625">
The contrasts above indicate that duration, pitch, and
intensity should be useful for automatic prosody-based
identification of topic boundaries. To facilitate cross-
speaker comparisons, we use normalized representations
of average pitch, average intensity, and word duration.
These features form a word-level context-independent
feature set.
Since segment boundaries and their cues exist to con-
trastively signal the separation between topics, we aug-
ment these features with local context-dependent mea-
sures. Specifically, we add features that measure the
change between the current word and the next word. 2
This contextualization adds four contextual features:
change in normalized average pitch, change in normal-
ized average intensity, change in normalized word dura-
tion, and duration of following silence.
</bodyText>
<subsectionHeader confidence="0.999078">
5.2 Text Feature Set
</subsectionHeader>
<bodyText confidence="0.999983416666667">
In addition to the prosodic features, we also consider a set
of features that exploit the textual similarity of regions to
identify segment boundaries. We build on the standard
information retrieval measures for assessing text similar-
ity. Specifically we consider a weighted cosine
similarity measure across 50 and 30 word windows. We
also explore a length normalized word overlap within the
same region size. We use the words from the ASR tran-
scription as our terms and perform no stopword removal.
We expect that these measures will be minimized at topic
boundaries where changes in topic are accompanied by
changes in topical terminology.
</bodyText>
<subsectionHeader confidence="0.999189">
5.3 Classifier Training and Testing Configuration
</subsectionHeader>
<bodyText confidence="0.999886454545455">
We employed Quinlan’s C4.5 (Quinlan, 1992) decision
tree classifier to provide a readily interpretable classifier.
Now, the vast majority of word positions in our collec-
tion are non-topic-final. So, in order to focus training and
test on topic boundary identification, we downsample our
corpus to produce training and test sets with a 50/50 split
of topic-final and non-topic-final words. We trained on
2789 topic-final words 3 and 2789 non-topic-final words,
not matched in any way, drawn randomly from the full
corpus. We tested on a held-out set of 200 topic-final and
non-topic-final words.
</bodyText>
<tableCaption confidence="0.440956285714286">
2We have posed the task of boundary detection as the task
of finding segment-final words, so the technique incorporates a
single-word lookahead. We could also repose the task as iden-
tification of topic-initial words and avoid the lookahead to have
a more on-line process. This is an area for future research.
3We excluded a small proportion of words for which the
pitch tracker returned no results.
</tableCaption>
<subsectionHeader confidence="0.77706">
5.4 Classifier Evaluation
</subsectionHeader>
<subsubsectionHeader confidence="0.658088">
5.4.1 Prosody-only Classification
</subsubsectionHeader>
<bodyText confidence="0.999809125">
The resulting classifier achieved 95.8% accuracy on
the held-out test set, closely approximating pruned tree
performance on the training set. This effectiveness is
a substantial improvement over the sample baseline of
50%. Inspection of the classifier indicates the key role
of silence as well as the use of both contextual and purely
local features of both pitch and intensity. Durational fea-
tures play a lesser role in the classifier.
</bodyText>
<subsectionHeader confidence="0.832988">
5.4.2 Text and Silence-based Classification
</subsectionHeader>
<bodyText confidence="0.999872727272727">
In a comparable experiment, we employed only the
text similarity and silence duration features to train and
test the classifier. These features similarly achieved a
95.5% overall classification accuracy. Here the best clas-
sification accuracy was achieved by the text similarity
measure that was based on the weighted 50 word
window. The text similarity measures based on
in the 30 word window and on length normalized overlap
performed similarly. The combination of all three text-
based features did not improve classification over the sin-
gle best measure.
</bodyText>
<subsectionHeader confidence="0.704258">
5.4.3 Combined Prosody and Text Classification
</subsectionHeader>
<bodyText confidence="0.999969">
Finally we built a combined classifier integrating all
prosodic and textual features. This classifier yielded an
accuracy of 97%, the best overall effectiveness. The deci-
sion tree utilized all classes of prosodic features and per-
formed comparably with only the features and
with all text features. A portion of the tree is reproduced
in Figure 1.
</bodyText>
<subsectionHeader confidence="0.992261">
5.5 Feature Comparison
</subsectionHeader>
<bodyText confidence="0.999949214285714">
We also performed a set of contrastive experiments with
different subsets of available features to assess the de-
pendence on these features. 4 We grouped features
into 5 sets: pitch, intensity, duration, silence, and text-
similarity. For each of the prosody-only, text-only, and
combined prosody and text-based classifiers, we succes-
sively removed the feature class at the root of the decision
tree and retrained with the remaining features (Table 1).
We observe that although silence duration plays a very
significant role in story boundary identification for all
feature sets, the richer prosodic and mixed text-prosodic
classifiers are much more robust to the absence of silence
information. Further we observe that intensity and then
pitch play the next most important roles in classification.
</bodyText>
<footnote confidence="0.991886">
4For example, VOA Mandarin has been observed stylisti-
cally to make idiosyncratically large use of silence at story
boundaries. (personal communication, James Allan).
</footnote>
<figureCaption confidence="0.996865">
Figure 1: Decision tree classifier labeling words as segment-final or non-segment-final, using text and prosodic features
</figureCaption>
<table confidence="0.999879666666667">
Prosody-only Text Silence Text Prosody
Accuracy Pct. Change Accuracy Pct. Change Accuracy Pct. Change
All 95.8% 0 95.5% 0 97% 0
Silence 89.4% -6.7% 75.5% -21% 91.5% 5.7%
Intensity 82.2% -14.2% 86.4% -11%
Pitch 64% -33.2% 77% -20.6%
</table>
<tableCaption confidence="0.919814">
Table 1: Reduction in classification accuracy with removal of features. Each row is labeled with the feature that is
newly removed from the set of available features.
</tableCaption>
<sectionHeader confidence="0.996541" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.9999775">
We have demonstrated the utility of prosody-only, text-
only, and mixed text-prosody features for automatic topic
segmentation of Mandarin Chinese. We have demon-
strated the applicability of intonational prosodic features,
specifically pitch, intensity, pause and duration, to the
identification of topic boundaries in a tone language. We
observe similar effectiveness for all feature sets when all
features are available, with slightly better classification
accuracy for the hybrid text-prosody approach. These re-
sults indicate a synergistic combination of meaning and
acoustic features. We further observe that the prosody-
only and hybrid feature sets are much less sensitive to the
absence of individual features, and, in particular, to si-
lence features. These findings indicate that prosodic fea-
tures are robust cues to topic boundaries, both with and
without textual cues.
There is still substantial work to be done. We would
like to integrate speaker identification for normalization
and speaker change detection. We also plan to explore the
integration of text and prosodic features for the identifica-
tion of more fine-grained sub-topic structure, to provide
more focused units for information retrieval, summariza-
tion, and anaphora resolution. We also plan to explore
the interaction of prosodic and textual features with cues
from other modalities, such as gaze and gesture, for ro-
bust segmentation of varied multi-modal data.
</bodyText>
<sectionHeader confidence="0.999643" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99957155">
D. Beeferman, A. Berger, and J. Lafferty. 1999. Statisti-
cal models for text segmentation. Machine Learning,
34((1-3)):177–210.
P. Boersma. 2001. Praat, a system for doing phonetics
by computer. Glot International, 5(9–10):341–345.
B. Grosz and C. Sidner. 1986. Attention, intention, and
the structure of discourse. Computational Linguistics,
12(3):175–204.
M. Hearst. 1994. Multi-paragraph segmentation of ex-
pository text. In Proceedings of the 32nd Annual Meet-
ing of the Association for Computational Linguistics.
Julia Hirschberg and Christine Nakatani. 1998. Acoustic
indicators of topic segmentation. In Proceedings on
ICSLP-98.
Gina-Anne Levow. 2004. Prosody-based topic segmen-
tation for mandarin broadcast news. In Proceedings of
HLT-NAACL 2004, Volume 2.
D. Marcu. 2000. The Theory and Practice of Discourse
Parsing and Summarization. MIT Press.
C. H. Nakatani, J. Hirschberg, and B. J. Grosz. 1995.
Discourse structure in spoken language: Studies on
speech corpora. In Working Notes of the AAAI Spring
Symposium on Empirical Methods in Discourse Inter-
pretation and Generation, pages 106–112.
J.R. Quinlan. 1992. C4.5: Programs for Machine Learn-
ing. Morgan Kaufmann.
K. Ross and M. Ostendorf. 1996. Prediction of ab-
stract labels for speech synthesis. Computer Speech
and Language, 10:155–185.
Marc Swerts. 1997. Prosodic features at discourse
boundaries of different strength. Journal of the Acous-
tical Society ofAmerica, 101(1):514–521.
G. Tur, D. Hakkani-Tur, A. Stolcke, and E. Shriberg.
2001. Integrating prosodic and lexical cues for auto-
matic topic segmentation. Computational Linguistics,
27(1):31–57.
C. Wayne. 2000. Multilingual topic detection and track-
ing: Successful research enabled by corpora and eval-
uation. In Language Resources and Evaluation Con-
ference (LREC) 2000, pages 1487–1494.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.879337">
<title confidence="0.9904565">Assessing Prosodic and Text Features for Segmentation of Broadcast News</title>
<author confidence="0.910149">Gina-Anne</author>
<affiliation confidence="0.999809">University of Chicago</affiliation>
<email confidence="0.999814">levow@cs.uchicago.edu</email>
<abstract confidence="0.999230266666667">Automatic topic segmentation, separation of a discourse stream into its constituent stories or topics, is a necessary preprocessing step for applications such as information retrieval, anaphora resolution, and summarization. While significant progress has been made in this area for text sources and for English audio sources, little work has been done in automatic segmentation of other languages using both text and acoustic information. In this paper, we focus on exploiting both textual and prosodic features for topic segmentation of Mandarin Chinese. As a tone language, Mandarin presents special challenges for applicability of intonation-based techniques, since the pitch contour is also used to establish lexical identity. However, intonational cues such as reduction in pitch and intensity at topic boundaries and increase in duration and pause still provide significant contrasts in Mandarin Chinese. We first build a decision tree classifier that based only on prosodic information achieves boundary classification accuracy of 89-95.8% on a large standard test set. We then contrast these results with a simple text similarity-based classification scheme. Finally we build a merged classifier, finding the best effectiveness for systems integrating text and prosodic cues.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Beeferman</author>
<author>A Berger</author>
<author>J Lafferty</author>
</authors>
<title>Statistical models for text segmentation.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<pages>34--1</pages>
<contexts>
<context position="4741" citStr="Beeferman et al., 1999" startWordPosition="707" endWordPosition="710"> automatic topic segmentation has been applied to clean text only and thus used textual features. Text-based segmentation approaches have utilized term-based similarity measures computed across candidate segments (Hearst, 1994) and also discourse markers to identify discourse structure (Marcu, 2000). The Topic Detection and Tracking (TDT) evaluations focused on segmentation of both text and speech sources. This framework introduced new challenges in dealing with errorful automatic transcriptions as well as new opportunities to exploit cues in the original speech. The most successful approach (Beeferman et al., 1999) produced automatic segmentations that yielded retrieval results comparable to those with manual segmentations, using text and silence features. (Tur et al., 2001) applied both a prosody-only and a mixed text-prosody model to segmentation of TDT English broadcast news, with the best results combining text and prosodic features. (Hirschberg and Nakatani, 1998) also examined automatic topic segmentation based on prosodic cues, in the domain of English broadcast news. Work in discourse analysis (Nakatani et al., 1995; Swerts, 1997) in both English and Dutch has identified features such as changes</context>
</contexts>
<marker>Beeferman, Berger, Lafferty, 1999</marker>
<rawString>D. Beeferman, A. Berger, and J. Lafferty. 1999. Statistical models for text segmentation. Machine Learning, 34((1-3)):177–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Boersma</author>
</authors>
<title>Praat, a system for doing phonetics by computer.</title>
<date>2001</date>
<journal>Glot International,</journal>
<pages>5--9</pages>
<contexts>
<context position="6412" citStr="Boersma, 2001" startWordPosition="972" endWordPosition="973">ndaries provided with the corpus as our gold standard labeling. Our collection comprises 3014 stories drawn from approximately 113 hours over three months (OctoberDecember 1998) of news broadcasts from the Voice of America (VOA) in Mandarin Chinese. The transcriptions span approximately 740,000 words. The audio is stored in NIST Sphere format sampled at 16KHz with 16-bit linear encoding. 4 Prosodic Features We employ four main classes of prosodic features: pitch, intensity, silence and duration. Pitch, as represented by f0 in Hertz, was computed by the “To pitch” function of the Praat system (Boersma, 2001). We then applied a 5-point median filter to smooth out local instabilities in the signal such as vocal fry or small regions of spurious doubling or halving. Analogously, we computed the intensity in decibels for each 10ms frame with the Praat “To intensity” function, followed by similar smoothing. For consistency and to allow comparability, we computed all figures for word-based units, using the ASR transcriptions provided with the TDT Mandarin data. The words are used to establish time spans for computing pitch or intensity mean or maximum values, to enable durational normalization and pairw</context>
</contexts>
<marker>Boersma, 2001</marker>
<rawString>P. Boersma. 2001. Praat, a system for doing phonetics by computer. Glot International, 5(9–10):341–345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Grosz</author>
<author>C Sidner</author>
</authors>
<title>Attention, intention, and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="2068" citStr="Grosz and Sidner, 1986" startWordPosition="302" endWordPosition="305">tion Natural spoken discourse is composed of a sequence of utterances, not independently generated or randomly strung together, but rather organized according to basic structural principles. This structure in turn guides the interpretation of individual utterances and the discourse as a whole. Formal written discourse signals a hierarchical, tree-based discourse structure explicitly by the division of the text into chapters, sections, paragraphs, and sentences. This structure, in turn, identifies domains for interpretation; many systems for anaphora resolution rely on some notion of locality (Grosz and Sidner, 1986). Similarly, this structure represents topical organization, and thus would be useful in information retrieval to select documents where the primary sections are on-topic, and, for summarization, to select information covering the different aspects of the topic. Unfortunately, spoken discourse does not include the orthographic conventions that signal structural organization in written discourse. Instead, one must infer the hierarchical structure of spoken discourse from other cues. Prior research (Nakatani et al., 1995; Swerts, 1997) has shown that human labelers can more sharply, consistently</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>B. Grosz and C. Sidner. 1986. Attention, intention, and the structure of discourse. Computational Linguistics, 12(3):175–204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hearst</author>
</authors>
<title>Multi-paragraph segmentation of expository text.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="4345" citStr="Hearst, 1994" startWordPosition="651" endWordPosition="652"> text-based, and mixed cue-based segmentation for Mandarin Chinese, to assess the relative utility of the cues for a tone language. Not only is the use of prosodic cues to topic segmentation much less wellstudied in general than is the use of text cues, but the use of prosodic cues has been largely limited to English and other European languages. 2 Related Work Most prior research on automatic topic segmentation has been applied to clean text only and thus used textual features. Text-based segmentation approaches have utilized term-based similarity measures computed across candidate segments (Hearst, 1994) and also discourse markers to identify discourse structure (Marcu, 2000). The Topic Detection and Tracking (TDT) evaluations focused on segmentation of both text and speech sources. This framework introduced new challenges in dealing with errorful automatic transcriptions as well as new opportunities to exploit cues in the original speech. The most successful approach (Beeferman et al., 1999) produced automatic segmentations that yielded retrieval results comparable to those with manual segmentations, using text and silence features. (Tur et al., 2001) applied both a prosody-only and a mixed </context>
</contexts>
<marker>Hearst, 1994</marker>
<rawString>M. Hearst. 1994. Multi-paragraph segmentation of expository text. In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hirschberg</author>
<author>Christine Nakatani</author>
</authors>
<title>Acoustic indicators of topic segmentation.</title>
<date>1998</date>
<booktitle>In Proceedings on ICSLP-98.</booktitle>
<contexts>
<context position="5102" citStr="Hirschberg and Nakatani, 1998" startWordPosition="761" endWordPosition="764">ocused on segmentation of both text and speech sources. This framework introduced new challenges in dealing with errorful automatic transcriptions as well as new opportunities to exploit cues in the original speech. The most successful approach (Beeferman et al., 1999) produced automatic segmentations that yielded retrieval results comparable to those with manual segmentations, using text and silence features. (Tur et al., 2001) applied both a prosody-only and a mixed text-prosody model to segmentation of TDT English broadcast news, with the best results combining text and prosodic features. (Hirschberg and Nakatani, 1998) also examined automatic topic segmentation based on prosodic cues, in the domain of English broadcast news. Work in discourse analysis (Nakatani et al., 1995; Swerts, 1997) in both English and Dutch has identified features such as changes in pitch range, intensity, and speaking rate associated with segment boundaries and with boundaries of different strengths. 3 Data Set We utilize the Topic Detection and Tracking (TDT) 3 (Wayne, 2000) collection Mandarin Chinese broadcast news audio corpus as our data set. Story segmentation in Mandarin and English broadcast news and newswire text was one of</context>
</contexts>
<marker>Hirschberg, Nakatani, 1998</marker>
<rawString>Julia Hirschberg and Christine Nakatani. 1998. Acoustic indicators of topic segmentation. In Proceedings on ICSLP-98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gina-Anne Levow</author>
</authors>
<title>Prosody-based topic segmentation for mandarin broadcast news.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT-NAACL</booktitle>
<volume>2</volume>
<contexts>
<context position="8109" citStr="Levow, 2004" startWordPosition="1236" endWordPosition="1237">ed word duration, where average word duration is used as the mean in the calculation above. Mandarin Chinese is a tone language in which lexical identity is determined by a pitch contour - or tone - associated with each syllable. This additional use of pitch raises the question of the cross-linguistic applicability of the prosodic cues, especially pitch cues, identified for non-tone languages. Specifically, do we find intonational cues in tone languages? We have found highly significant differences based ) for words in segment-final position, relative to the same word in non-final positions. (Levow, 2004). Specifically, word duration, normalized mean pitch, and normalized mean intensity all differ significantly for words in topicfinal position relative to occurrences throughout the story. Word duration increases, while both pitch and intensity decrease. Importantly, reduction in pitch as a signal of topic finality is robust across the typological contrast of tone and non-tone languages, such as English (Nakatani et al., 1995) and Dutch (Swerts, 1997). &apos;This is an imperfect approximation as some stories include off-site interviews, but seems a reasonable choice in the absence of automatic speak</context>
</contexts>
<marker>Levow, 2004</marker>
<rawString>Gina-Anne Levow. 2004. Prosody-based topic segmentation for mandarin broadcast news. In Proceedings of HLT-NAACL 2004, Volume 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Marcu</author>
</authors>
<title>The Theory and Practice of Discourse Parsing and Summarization.</title>
<date>2000</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="4418" citStr="Marcu, 2000" startWordPosition="661" endWordPosition="662">ess the relative utility of the cues for a tone language. Not only is the use of prosodic cues to topic segmentation much less wellstudied in general than is the use of text cues, but the use of prosodic cues has been largely limited to English and other European languages. 2 Related Work Most prior research on automatic topic segmentation has been applied to clean text only and thus used textual features. Text-based segmentation approaches have utilized term-based similarity measures computed across candidate segments (Hearst, 1994) and also discourse markers to identify discourse structure (Marcu, 2000). The Topic Detection and Tracking (TDT) evaluations focused on segmentation of both text and speech sources. This framework introduced new challenges in dealing with errorful automatic transcriptions as well as new opportunities to exploit cues in the original speech. The most successful approach (Beeferman et al., 1999) produced automatic segmentations that yielded retrieval results comparable to those with manual segmentations, using text and silence features. (Tur et al., 2001) applied both a prosody-only and a mixed text-prosody model to segmentation of TDT English broadcast news, with th</context>
</contexts>
<marker>Marcu, 2000</marker>
<rawString>D. Marcu. 2000. The Theory and Practice of Discourse Parsing and Summarization. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C H Nakatani</author>
<author>J Hirschberg</author>
<author>B J Grosz</author>
</authors>
<title>Discourse structure in spoken language: Studies on speech corpora.</title>
<date>1995</date>
<booktitle>In Working Notes of the AAAI Spring Symposium on Empirical Methods in Discourse Interpretation and Generation,</booktitle>
<pages>106--112</pages>
<contexts>
<context position="2592" citStr="Nakatani et al., 1995" startWordPosition="376" endWordPosition="379">on; many systems for anaphora resolution rely on some notion of locality (Grosz and Sidner, 1986). Similarly, this structure represents topical organization, and thus would be useful in information retrieval to select documents where the primary sections are on-topic, and, for summarization, to select information covering the different aspects of the topic. Unfortunately, spoken discourse does not include the orthographic conventions that signal structural organization in written discourse. Instead, one must infer the hierarchical structure of spoken discourse from other cues. Prior research (Nakatani et al., 1995; Swerts, 1997) has shown that human labelers can more sharply, consistently, and confidently identify discourse structure in a word-level transcription when an original audio recording is available than they can on the basis of the transcribed text alone. This finding indicates that substantial additional information about the structure of the discourse is encoded in the acoustic-prosodic features of the utterance. Given the often errorful transcriptions available for large speech corpora, we choose to focus here on fully exploiting the prosodic cues to discourse structure present in the orig</context>
<context position="5260" citStr="Nakatani et al., 1995" startWordPosition="786" endWordPosition="789">tunities to exploit cues in the original speech. The most successful approach (Beeferman et al., 1999) produced automatic segmentations that yielded retrieval results comparable to those with manual segmentations, using text and silence features. (Tur et al., 2001) applied both a prosody-only and a mixed text-prosody model to segmentation of TDT English broadcast news, with the best results combining text and prosodic features. (Hirschberg and Nakatani, 1998) also examined automatic topic segmentation based on prosodic cues, in the domain of English broadcast news. Work in discourse analysis (Nakatani et al., 1995; Swerts, 1997) in both English and Dutch has identified features such as changes in pitch range, intensity, and speaking rate associated with segment boundaries and with boundaries of different strengths. 3 Data Set We utilize the Topic Detection and Tracking (TDT) 3 (Wayne, 2000) collection Mandarin Chinese broadcast news audio corpus as our data set. Story segmentation in Mandarin and English broadcast news and newswire text was one of the TDT tasks and also an enabling technology for other retrieval tasks. We use the segment boundaries provided with the corpus as our gold standard labeling</context>
<context position="8538" citStr="Nakatani et al., 1995" startWordPosition="1296" endWordPosition="1299">nd intonational cues in tone languages? We have found highly significant differences based ) for words in segment-final position, relative to the same word in non-final positions. (Levow, 2004). Specifically, word duration, normalized mean pitch, and normalized mean intensity all differ significantly for words in topicfinal position relative to occurrences throughout the story. Word duration increases, while both pitch and intensity decrease. Importantly, reduction in pitch as a signal of topic finality is robust across the typological contrast of tone and non-tone languages, such as English (Nakatani et al., 1995) and Dutch (Swerts, 1997). &apos;This is an imperfect approximation as some stories include off-site interviews, but seems a reasonable choice in the absence of automatic speaker identification. on paired t-test two-tailed, ( 5 Classification 5.1 Prosodic Feature Set The contrasts above indicate that duration, pitch, and intensity should be useful for automatic prosody-based identification of topic boundaries. To facilitate crossspeaker comparisons, we use normalized representations of average pitch, average intensity, and word duration. These features form a word-level context-independent feature </context>
</contexts>
<marker>Nakatani, Hirschberg, Grosz, 1995</marker>
<rawString>C. H. Nakatani, J. Hirschberg, and B. J. Grosz. 1995. Discourse structure in spoken language: Studies on speech corpora. In Working Notes of the AAAI Spring Symposium on Empirical Methods in Discourse Interpretation and Generation, pages 106–112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Quinlan</author>
</authors>
<title>C4.5: Programs for Machine Learning.</title>
<date>1992</date>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="10365" citStr="Quinlan, 1992" startWordPosition="1569" endWordPosition="1570">to identify segment boundaries. We build on the standard information retrieval measures for assessing text similarity. Specifically we consider a weighted cosine similarity measure across 50 and 30 word windows. We also explore a length normalized word overlap within the same region size. We use the words from the ASR transcription as our terms and perform no stopword removal. We expect that these measures will be minimized at topic boundaries where changes in topic are accompanied by changes in topical terminology. 5.3 Classifier Training and Testing Configuration We employed Quinlan’s C4.5 (Quinlan, 1992) decision tree classifier to provide a readily interpretable classifier. Now, the vast majority of word positions in our collection are non-topic-final. So, in order to focus training and test on topic boundary identification, we downsample our corpus to produce training and test sets with a 50/50 split of topic-final and non-topic-final words. We trained on 2789 topic-final words 3 and 2789 non-topic-final words, not matched in any way, drawn randomly from the full corpus. We tested on a held-out set of 200 topic-final and non-topic-final words. 2We have posed the task of boundary detection a</context>
</contexts>
<marker>Quinlan, 1992</marker>
<rawString>J.R. Quinlan. 1992. C4.5: Programs for Machine Learning. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Ross</author>
<author>M Ostendorf</author>
</authors>
<title>Prediction of abstract labels for speech synthesis. Computer Speech and Language,</title>
<date>1996</date>
<pages>10--155</pages>
<contexts>
<context position="7111" citStr="Ross and Ostendorf, 1996" startWordPosition="1079" endWordPosition="1082">s in the signal such as vocal fry or small regions of spurious doubling or halving. Analogously, we computed the intensity in decibels for each 10ms frame with the Praat “To intensity” function, followed by similar smoothing. For consistency and to allow comparability, we computed all figures for word-based units, using the ASR transcriptions provided with the TDT Mandarin data. The words are used to establish time spans for computing pitch or intensity mean or maximum values, to enable durational normalization and pairwise comparison, and to identify silence duration. It is well-established (Ross and Ostendorf, 1996) that for robust analysis pitch and intensity should be normalized by speaker, since, for example, average pitch is largely incomparable for male and female speakers. In the absence of speaker identification software, we approximate speaker normalization with story-based normalization, computed as , assuming one speaker per topic&apos;. For duration, we consider both absolute and normalized word duration, where average word duration is used as the mean in the calculation above. Mandarin Chinese is a tone language in which lexical identity is determined by a pitch contour - or tone - associated with</context>
</contexts>
<marker>Ross, Ostendorf, 1996</marker>
<rawString>K. Ross and M. Ostendorf. 1996. Prediction of abstract labels for speech synthesis. Computer Speech and Language, 10:155–185.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Swerts</author>
</authors>
<title>Prosodic features at discourse boundaries of different strength.</title>
<date>1997</date>
<journal>Journal of the Acoustical Society ofAmerica,</journal>
<volume>101</volume>
<issue>1</issue>
<contexts>
<context position="2607" citStr="Swerts, 1997" startWordPosition="380" endWordPosition="381">aphora resolution rely on some notion of locality (Grosz and Sidner, 1986). Similarly, this structure represents topical organization, and thus would be useful in information retrieval to select documents where the primary sections are on-topic, and, for summarization, to select information covering the different aspects of the topic. Unfortunately, spoken discourse does not include the orthographic conventions that signal structural organization in written discourse. Instead, one must infer the hierarchical structure of spoken discourse from other cues. Prior research (Nakatani et al., 1995; Swerts, 1997) has shown that human labelers can more sharply, consistently, and confidently identify discourse structure in a word-level transcription when an original audio recording is available than they can on the basis of the transcribed text alone. This finding indicates that substantial additional information about the structure of the discourse is encoded in the acoustic-prosodic features of the utterance. Given the often errorful transcriptions available for large speech corpora, we choose to focus here on fully exploiting the prosodic cues to discourse structure present in the original speech in </context>
<context position="5275" citStr="Swerts, 1997" startWordPosition="790" endWordPosition="791">s in the original speech. The most successful approach (Beeferman et al., 1999) produced automatic segmentations that yielded retrieval results comparable to those with manual segmentations, using text and silence features. (Tur et al., 2001) applied both a prosody-only and a mixed text-prosody model to segmentation of TDT English broadcast news, with the best results combining text and prosodic features. (Hirschberg and Nakatani, 1998) also examined automatic topic segmentation based on prosodic cues, in the domain of English broadcast news. Work in discourse analysis (Nakatani et al., 1995; Swerts, 1997) in both English and Dutch has identified features such as changes in pitch range, intensity, and speaking rate associated with segment boundaries and with boundaries of different strengths. 3 Data Set We utilize the Topic Detection and Tracking (TDT) 3 (Wayne, 2000) collection Mandarin Chinese broadcast news audio corpus as our data set. Story segmentation in Mandarin and English broadcast news and newswire text was one of the TDT tasks and also an enabling technology for other retrieval tasks. We use the segment boundaries provided with the corpus as our gold standard labeling. Our collectio</context>
<context position="8563" citStr="Swerts, 1997" startWordPosition="1302" endWordPosition="1303">ages? We have found highly significant differences based ) for words in segment-final position, relative to the same word in non-final positions. (Levow, 2004). Specifically, word duration, normalized mean pitch, and normalized mean intensity all differ significantly for words in topicfinal position relative to occurrences throughout the story. Word duration increases, while both pitch and intensity decrease. Importantly, reduction in pitch as a signal of topic finality is robust across the typological contrast of tone and non-tone languages, such as English (Nakatani et al., 1995) and Dutch (Swerts, 1997). &apos;This is an imperfect approximation as some stories include off-site interviews, but seems a reasonable choice in the absence of automatic speaker identification. on paired t-test two-tailed, ( 5 Classification 5.1 Prosodic Feature Set The contrasts above indicate that duration, pitch, and intensity should be useful for automatic prosody-based identification of topic boundaries. To facilitate crossspeaker comparisons, we use normalized representations of average pitch, average intensity, and word duration. These features form a word-level context-independent feature set. Since segment bounda</context>
</contexts>
<marker>Swerts, 1997</marker>
<rawString>Marc Swerts. 1997. Prosodic features at discourse boundaries of different strength. Journal of the Acoustical Society ofAmerica, 101(1):514–521.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Tur</author>
<author>D Hakkani-Tur</author>
<author>A Stolcke</author>
<author>E Shriberg</author>
</authors>
<title>Integrating prosodic and lexical cues for automatic topic segmentation.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>1</issue>
<contexts>
<context position="4904" citStr="Tur et al., 2001" startWordPosition="732" endWordPosition="735">measures computed across candidate segments (Hearst, 1994) and also discourse markers to identify discourse structure (Marcu, 2000). The Topic Detection and Tracking (TDT) evaluations focused on segmentation of both text and speech sources. This framework introduced new challenges in dealing with errorful automatic transcriptions as well as new opportunities to exploit cues in the original speech. The most successful approach (Beeferman et al., 1999) produced automatic segmentations that yielded retrieval results comparable to those with manual segmentations, using text and silence features. (Tur et al., 2001) applied both a prosody-only and a mixed text-prosody model to segmentation of TDT English broadcast news, with the best results combining text and prosodic features. (Hirschberg and Nakatani, 1998) also examined automatic topic segmentation based on prosodic cues, in the domain of English broadcast news. Work in discourse analysis (Nakatani et al., 1995; Swerts, 1997) in both English and Dutch has identified features such as changes in pitch range, intensity, and speaking rate associated with segment boundaries and with boundaries of different strengths. 3 Data Set We utilize the Topic Detect</context>
</contexts>
<marker>Tur, Hakkani-Tur, Stolcke, Shriberg, 2001</marker>
<rawString>G. Tur, D. Hakkani-Tur, A. Stolcke, and E. Shriberg. 2001. Integrating prosodic and lexical cues for automatic topic segmentation. Computational Linguistics, 27(1):31–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Wayne</author>
</authors>
<title>Multilingual topic detection and tracking: Successful research enabled by corpora and evaluation.</title>
<date>2000</date>
<booktitle>In Language Resources and Evaluation Conference (LREC)</booktitle>
<pages>1487--1494</pages>
<contexts>
<context position="5542" citStr="Wayne, 2000" startWordPosition="832" endWordPosition="833">ly and a mixed text-prosody model to segmentation of TDT English broadcast news, with the best results combining text and prosodic features. (Hirschberg and Nakatani, 1998) also examined automatic topic segmentation based on prosodic cues, in the domain of English broadcast news. Work in discourse analysis (Nakatani et al., 1995; Swerts, 1997) in both English and Dutch has identified features such as changes in pitch range, intensity, and speaking rate associated with segment boundaries and with boundaries of different strengths. 3 Data Set We utilize the Topic Detection and Tracking (TDT) 3 (Wayne, 2000) collection Mandarin Chinese broadcast news audio corpus as our data set. Story segmentation in Mandarin and English broadcast news and newswire text was one of the TDT tasks and also an enabling technology for other retrieval tasks. We use the segment boundaries provided with the corpus as our gold standard labeling. Our collection comprises 3014 stories drawn from approximately 113 hours over three months (OctoberDecember 1998) of news broadcasts from the Voice of America (VOA) in Mandarin Chinese. The transcriptions span approximately 740,000 words. The audio is stored in NIST Sphere format</context>
</contexts>
<marker>Wayne, 2000</marker>
<rawString>C. Wayne. 2000. Multilingual topic detection and tracking: Successful research enabled by corpora and evaluation. In Language Resources and Evaluation Conference (LREC) 2000, pages 1487–1494.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>