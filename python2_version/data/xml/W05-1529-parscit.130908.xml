<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.041448">
<title confidence="0.981726">
Robust Extraction of Subcategorization Data from Spoken Language
</title>
<author confidence="0.999648">
Jianguo Li &amp; Chris Brew Eric Fosler-Lussier
</author>
<affiliation confidence="0.997189">
Department of Linguistics Department of Computer Science &amp; Engineering
The Ohio State University, USA The Ohio State University, USA
</affiliation>
<email confidence="0.994408">
{jianguo|cbrew}@ling.ohio-state.edu fosler@cse.ohio-state.edu
</email>
<sectionHeader confidence="0.999551" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999830523809524">
Subcategorization data has been crucial for various
NLP tasks. Current method for automatic SCF ac-
quisition usually proceeds in two steps: first, gen-
erate all SCF cues from a corpus using a parser,
and then filter out spurious SCF cues with statisti-
cal tests. Previous studies on SCF acquisition have
worked mainly with written texts; spoken corpora
have received little attention. Transcripts of spoken
language pose two challenges absent in written
texts: uncertainty about utterance segmentation and
disfluency.
Roland &amp; Jurafsky (1998) suggest that there are
substantial subcategorization differences between
spoken and written corpora. For example, spoken
corpora tend to have fewer passive sentences but
many more zero-anaphora structures than written
corpora. In light of such subcategorization differ-
ences, we believe that an SCF set built from spo-
ken language may, if of acceptable quality, be of
particular value to NLP tasks involving syntactic
analysis of spoken language.
</bodyText>
<sectionHeader confidence="0.959395" genericHeader="categories and subject descriptors">
2 SCF Acquisition System
</sectionHeader>
<bodyText confidence="0.999622631578947">
Following the design proposed by Briscoe and
Carroll (1997), we built an SCF acquisition system
consisting of the following four components:
Charniak’s parser (Charniak, 2000); an SCF ex-
tractor; a lemmatizer; and an SCF evaluator. The
first three components are responsible for generat-
ing SCF cues from the training corpora and the last
component, consisting of the Binomial Hypothesis
Test (Brent, 1993) and a back-off algorithm
(Sarkar &amp; Zeman, 2000), is used to filter SCF cues
on the basis of their reliability and likelihood.
We evaluated our system on a million word
written corpus and a comparable spoken corpus
from BNC. For type precision and recall, we used
14 verbs selected by Briscoe &amp; Carroll (1997) and
evaluated our results against SCF entries in
COMLEX (Grishman et al., 1994). We also calcu-
lated token recall and the results are summarized in
the following table.
</bodyText>
<table confidence="0.9836905">
Corpus Written Spoken
type precision 93.1% 91.2%
type recall 48.2% 46.4%
token recall 82.3% 80%
</table>
<tableCaption confidence="0.999851">
Table 1: Type precision, recall and token recall
</tableCaption>
<sectionHeader confidence="0.980226" genericHeader="general terms">
3 Detecting Incorrect SCF Cues
</sectionHeader>
<bodyText confidence="0.989925428571429">
We examined the way segmentation errors and
disfluency affects our acquisition system – the sta-
tistical parser and the extractor in particular – in
proposing SCF cues and explored ways to detect
incorrect SCF cues. We extracted 500 SCF cues
from the ViC corpus (Pitt, et al, 2005) and identi-
fied four major reasons that seem to have caused
the extractor to propose incorrect SCF cues: multi-
ple utterances; missing punctuation; disfluency;
parsing errors.
Error analysis reveals that segmentation errors
and disfluencies cause the parser and the extractor
to tend to make systematic errors in proposing SCF
cues – incorrect SCF cues are likely to have an
extra complement. We therefore proposed the fol-
lowing two sets of linguistic heuristics for auto-
matically detecting incorrect SCF cues:
Linguistic Heuristic Set 1: The following SCF
cues are extremely unlikely whatever the verb. Re-
ject an SCF cue as incorrect if it contains the fol-
lowing patterns:
</bodyText>
<listItem confidence="0.979836">
➢ [(NP) PP NP]: We reach out [to your friends] [your
neighbor].
➢ [NP PP-to S]: Would I want them to say [that][to
me] [would I want them to do that to me].
➢ [NP NP S]: They just beat [Indiana in basketball]
[the- Saturday] [I think it was um-hum].
</listItem>
<page confidence="0.956104">
204
</page>
<bodyText confidence="0.76740575">
Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT), pages 204–205,
Vancouver, October 2005. c�2005 Association for Computational Linguistics
3/4 [PP-p PP-p]: He starts living [with the] [with the
guys].
Linguistic Heuristic Set 2: The following SCF
cues are all possibly valid SCFs: for SCF cues of
the following type, check if the given verb takes it
in COMLEX. If not, reject it:
</bodyText>
<listItem confidence="0.365978857142857">
3/4 [(NP) S]: When he was dying [what did he say].
3/4 [PP-to S]: The same thing happened [to him] [uh
he had a scholarship].
3/4 [(NP) NP]: OU had a heck of time beating [them]
[uh-hum].
3/4 [(NP) INF]: You take [the plate] from the table
[rinse them off] and put them by the sink.
</listItem>
<bodyText confidence="0.9996478">
Given the utilization of a gold standard in the
heuristics, it would be improper to build an end-to-
end system and evaluate against COMLEX. In-
stead, we evaluate by seeing how often our heuris-
tics succeed producing results agreeable to a
human judge.
To evaluate the robustness of our linguistic heu-
ristics, we conducted a cross-corpora and cross-
parser comparison. We used 1,169 verb tokens
from the ViC corpus and another 1,169 from the
Switchboard corpus.
Cross-corpus Comparison: The purpose of the
cross-corpus comparison is to show that our lin-
guistic heuristics based on the data from one spo-
ken corpus can be applied to other spoken corpora.
Therefore, we applied our heuristics to the ViC and
the Switchboard corpus parsed by Charniak’s
parser. We calculated the percentage of incorrect
SCF cues before and after applying our linguistic
heuristics. The results are shown in Table 2.
</bodyText>
<table confidence="0.979877">
Charniak’s parser ViC Switchboard
before heuristics 18.8% 9.5%
after heuristics 6.4% 4.6%
</table>
<tableCaption confidence="0.993198">
Table 2: Incorrect SCF cue rate before and after heuristics
</tableCaption>
<bodyText confidence="0.99097852631579">
Table 2 shows that the incorrect SCF cue rate
has been reduced to roughly the same level for the
two spoken corpora after applying our linguistic
heuristics.
Cross-parser Comparison: The purpose of the
cross-parser comparison is to show that our lin-
guistic heuristics based on the data parsed by one
parser can be applied to other parsers as well. To
this end, we applied our heuristics to the
Switchboard corpus parsed by both Charniak’s
parser and Bikel’s parsing engine (Bikel, 2004).
Again, we calculated the percentage of incorrect
SCF cues before and after applying our heuristics.
The results are displayed in Table 3.
Although our linguistic heuristics works slightly
better for data parsed by Charniak’ parser, the in-
correct SCF cue rate after applying heuristics re-
mains at about the same level for the two different
parsers we used.
</bodyText>
<table confidence="0.986338">
Switchboard Charniak Bikel
before heuristics 9.5% 9.2%
after heuristics 4.6% 5.4%
</table>
<tableCaption confidence="0.999192">
Table 3: Incorrect SCF cue rate before and after heuristics
</tableCaption>
<sectionHeader confidence="0.996891" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999979363636364">
We showed that it should not be assumed that stan-
dard statistical parsers will fail on language that is
very different from what they are trained on. Spe-
cifically, the results of Experiment 1 showed that it
is feasible to apply current SCF extraction
technology to spoken language. Experiment 2
showed that incorrect SCF cues due to segmenta-
tion errors and disfluency can be recognized by our
linguistic heuristics. We have shown that our SCF
acquisition system as a whole will work for the
different demands of spoken language.
</bodyText>
<sectionHeader confidence="0.998887" genericHeader="acknowledgments">
5 Acknowledgements
</sectionHeader>
<bodyText confidence="0.9998695">
This work was supported by NSF grant 0347799 to
the second author, and by a summer fellowship
from the Ohio State Center for Cognitive Science
to the first author.
</bodyText>
<sectionHeader confidence="0.99853" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99943968">
Biekl, D. 2004. Intricacies of Collins’ Parsing Model. Computational
Linguistics, 30(4): 470-511
Brent, M. 1993. From Grammar to Lexicon: Unsupervised Learning
of Lexical Syntax. Computational Lingusitics: 19(3): 243-262
Briscoe, E. &amp; Carroll, G. 1997. Automatic Extraction of Subcategori-
zation from Corpora. In Proceedings of the 5th ACL Conference on
Applied Natural Language Processing, Washington, DC. 356-363
Chaniak, E. 2000. A Maximum-Entropy-Inspired Parser. In Proceed-
ings of the 2000 Conference of the North American Chapter of
ACL. 132-139
Grishman, R., Macleod, C. &amp; Meyers, A. 1994. COMLEX Syntax:
Building a Computational Lexicon. In Proceedings of the Interna-
tional Conference on Computational Lingusitics, COLING-94,
Kyoto, Japan. 268-272
Pitt, M., Johnson, K., Hume, E., Kiesling, S., Raymond, W. 2005.
They Buckeye Corpus of Conversational Speech: Labeling Con-
ventions and a Test of Transcriber Reliability. Speech Communica-
tion, 45: 89-95
Roland, D. &amp; Jurafsky, D. 1998. How Verb Subcategorization Fre-
quency Affected by the Corpus Choice. In Proceedings of 17th In-
ternational Conference on Computational Lingusitics, 2: 1122-
1128
Sarkar, A. &amp; Zeman, D. 2000. Automatic Extraction of Subcategoriza-
tion Frames for Czech. In Proceedings of the 19th International
Conference on Computational Lingusitics. 691-697
</reference>
<page confidence="0.998872">
205
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.612291">
<title confidence="0.999339">Robust Extraction of Subcategorization Data from Spoken Language</title>
<author confidence="0.999885">Jianguo Li</author>
<author confidence="0.999885">Chris Brew Eric Fosler-Lussier</author>
<affiliation confidence="0.807678">Department of Linguistics Department of Computer Science &amp; Engineering The Ohio State University, USA The Ohio State University, USA</affiliation>
<email confidence="0.996058">{jianguo|cbrew}@ling.ohio-state.edu fosler@cse.ohio-state.edu</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Biekl</author>
</authors>
<date>2004</date>
<journal>Intricacies of Collins’ Parsing Model. Computational Linguistics,</journal>
<volume>30</volume>
<issue>4</issue>
<pages>470--511</pages>
<marker>Biekl, 2004</marker>
<rawString>Biekl, D. 2004. Intricacies of Collins’ Parsing Model. Computational Linguistics, 30(4): 470-511</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Brent</author>
</authors>
<title>From Grammar to Lexicon: Unsupervised Learning of Lexical Syntax.</title>
<date>1993</date>
<journal>Computational Lingusitics:</journal>
<volume>19</volume>
<issue>3</issue>
<pages>243--262</pages>
<contexts>
<context position="1733" citStr="Brent, 1993" startWordPosition="250" endWordPosition="251">differences, we believe that an SCF set built from spoken language may, if of acceptable quality, be of particular value to NLP tasks involving syntactic analysis of spoken language. 2 SCF Acquisition System Following the design proposed by Briscoe and Carroll (1997), we built an SCF acquisition system consisting of the following four components: Charniak’s parser (Charniak, 2000); an SCF extractor; a lemmatizer; and an SCF evaluator. The first three components are responsible for generating SCF cues from the training corpora and the last component, consisting of the Binomial Hypothesis Test (Brent, 1993) and a back-off algorithm (Sarkar &amp; Zeman, 2000), is used to filter SCF cues on the basis of their reliability and likelihood. We evaluated our system on a million word written corpus and a comparable spoken corpus from BNC. For type precision and recall, we used 14 verbs selected by Briscoe &amp; Carroll (1997) and evaluated our results against SCF entries in COMLEX (Grishman et al., 1994). We also calculated token recall and the results are summarized in the following table. Corpus Written Spoken type precision 93.1% 91.2% type recall 48.2% 46.4% token recall 82.3% 80% Table 1: Type precision, r</context>
</contexts>
<marker>Brent, 1993</marker>
<rawString>Brent, M. 1993. From Grammar to Lexicon: Unsupervised Learning of Lexical Syntax. Computational Lingusitics: 19(3): 243-262</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Briscoe</author>
<author>G Carroll</author>
</authors>
<title>Automatic Extraction of Subcategorization from Corpora.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th ACL Conference on Applied Natural Language Processing,</booktitle>
<pages>356--363</pages>
<location>Washington, DC.</location>
<contexts>
<context position="1388" citStr="Briscoe and Carroll (1997)" startWordPosition="195" endWordPosition="198">written texts: uncertainty about utterance segmentation and disfluency. Roland &amp; Jurafsky (1998) suggest that there are substantial subcategorization differences between spoken and written corpora. For example, spoken corpora tend to have fewer passive sentences but many more zero-anaphora structures than written corpora. In light of such subcategorization differences, we believe that an SCF set built from spoken language may, if of acceptable quality, be of particular value to NLP tasks involving syntactic analysis of spoken language. 2 SCF Acquisition System Following the design proposed by Briscoe and Carroll (1997), we built an SCF acquisition system consisting of the following four components: Charniak’s parser (Charniak, 2000); an SCF extractor; a lemmatizer; and an SCF evaluator. The first three components are responsible for generating SCF cues from the training corpora and the last component, consisting of the Binomial Hypothesis Test (Brent, 1993) and a back-off algorithm (Sarkar &amp; Zeman, 2000), is used to filter SCF cues on the basis of their reliability and likelihood. We evaluated our system on a million word written corpus and a comparable spoken corpus from BNC. For type precision and recall,</context>
<context position="2042" citStr="Briscoe &amp; Carroll (1997)" startWordPosition="302" endWordPosition="305">system consisting of the following four components: Charniak’s parser (Charniak, 2000); an SCF extractor; a lemmatizer; and an SCF evaluator. The first three components are responsible for generating SCF cues from the training corpora and the last component, consisting of the Binomial Hypothesis Test (Brent, 1993) and a back-off algorithm (Sarkar &amp; Zeman, 2000), is used to filter SCF cues on the basis of their reliability and likelihood. We evaluated our system on a million word written corpus and a comparable spoken corpus from BNC. For type precision and recall, we used 14 verbs selected by Briscoe &amp; Carroll (1997) and evaluated our results against SCF entries in COMLEX (Grishman et al., 1994). We also calculated token recall and the results are summarized in the following table. Corpus Written Spoken type precision 93.1% 91.2% type recall 48.2% 46.4% token recall 82.3% 80% Table 1: Type precision, recall and token recall 3 Detecting Incorrect SCF Cues We examined the way segmentation errors and disfluency affects our acquisition system – the statistical parser and the extractor in particular – in proposing SCF cues and explored ways to detect incorrect SCF cues. We extracted 500 SCF cues from the ViC c</context>
</contexts>
<marker>Briscoe, Carroll, 1997</marker>
<rawString>Briscoe, E. &amp; Carroll, G. 1997. Automatic Extraction of Subcategorization from Corpora. In Proceedings of the 5th ACL Conference on Applied Natural Language Processing, Washington, DC. 356-363</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Chaniak</author>
</authors>
<title>A Maximum-Entropy-Inspired Parser.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2000 Conference of the North American Chapter of ACL.</booktitle>
<pages>132--139</pages>
<marker>Chaniak, 2000</marker>
<rawString>Chaniak, E. 2000. A Maximum-Entropy-Inspired Parser. In Proceedings of the 2000 Conference of the North American Chapter of ACL. 132-139</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Grishman</author>
<author>C Macleod</author>
<author>A Meyers</author>
</authors>
<title>COMLEX Syntax: Building a Computational Lexicon.</title>
<date>1994</date>
<booktitle>In Proceedings of the International Conference on Computational Lingusitics, COLING-94,</booktitle>
<pages>268--272</pages>
<location>Kyoto,</location>
<contexts>
<context position="2122" citStr="Grishman et al., 1994" startWordPosition="315" endWordPosition="318">000); an SCF extractor; a lemmatizer; and an SCF evaluator. The first three components are responsible for generating SCF cues from the training corpora and the last component, consisting of the Binomial Hypothesis Test (Brent, 1993) and a back-off algorithm (Sarkar &amp; Zeman, 2000), is used to filter SCF cues on the basis of their reliability and likelihood. We evaluated our system on a million word written corpus and a comparable spoken corpus from BNC. For type precision and recall, we used 14 verbs selected by Briscoe &amp; Carroll (1997) and evaluated our results against SCF entries in COMLEX (Grishman et al., 1994). We also calculated token recall and the results are summarized in the following table. Corpus Written Spoken type precision 93.1% 91.2% type recall 48.2% 46.4% token recall 82.3% 80% Table 1: Type precision, recall and token recall 3 Detecting Incorrect SCF Cues We examined the way segmentation errors and disfluency affects our acquisition system – the statistical parser and the extractor in particular – in proposing SCF cues and explored ways to detect incorrect SCF cues. We extracted 500 SCF cues from the ViC corpus (Pitt, et al, 2005) and identified four major reasons that seem to have ca</context>
</contexts>
<marker>Grishman, Macleod, Meyers, 1994</marker>
<rawString>Grishman, R., Macleod, C. &amp; Meyers, A. 1994. COMLEX Syntax: Building a Computational Lexicon. In Proceedings of the International Conference on Computational Lingusitics, COLING-94, Kyoto, Japan. 268-272</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pitt</author>
<author>K Johnson</author>
<author>E Hume</author>
<author>S Kiesling</author>
<author>W Raymond</author>
</authors>
<title>They Buckeye Corpus of Conversational Speech: Labeling Conventions and a Test of Transcriber Reliability.</title>
<date>2005</date>
<journal>Speech Communication,</journal>
<volume>45</volume>
<pages>89--95</pages>
<contexts>
<context position="2667" citStr="Pitt, et al, 2005" startWordPosition="406" endWordPosition="409">aluated our results against SCF entries in COMLEX (Grishman et al., 1994). We also calculated token recall and the results are summarized in the following table. Corpus Written Spoken type precision 93.1% 91.2% type recall 48.2% 46.4% token recall 82.3% 80% Table 1: Type precision, recall and token recall 3 Detecting Incorrect SCF Cues We examined the way segmentation errors and disfluency affects our acquisition system – the statistical parser and the extractor in particular – in proposing SCF cues and explored ways to detect incorrect SCF cues. We extracted 500 SCF cues from the ViC corpus (Pitt, et al, 2005) and identified four major reasons that seem to have caused the extractor to propose incorrect SCF cues: multiple utterances; missing punctuation; disfluency; parsing errors. Error analysis reveals that segmentation errors and disfluencies cause the parser and the extractor to tend to make systematic errors in proposing SCF cues – incorrect SCF cues are likely to have an extra complement. We therefore proposed the following two sets of linguistic heuristics for automatically detecting incorrect SCF cues: Linguistic Heuristic Set 1: The following SCF cues are extremely unlikely whatever the ver</context>
</contexts>
<marker>Pitt, Johnson, Hume, Kiesling, Raymond, 2005</marker>
<rawString>Pitt, M., Johnson, K., Hume, E., Kiesling, S., Raymond, W. 2005. They Buckeye Corpus of Conversational Speech: Labeling Conventions and a Test of Transcriber Reliability. Speech Communication, 45: 89-95</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roland</author>
<author>D Jurafsky</author>
</authors>
<title>How Verb Subcategorization Frequency Affected by the Corpus Choice.</title>
<date>1998</date>
<booktitle>In Proceedings of 17th International Conference on Computational Lingusitics,</booktitle>
<volume>2</volume>
<pages>1122--1128</pages>
<contexts>
<context position="858" citStr="Roland &amp; Jurafsky (1998)" startWordPosition="116" endWordPosition="119">ty, USA {jianguo|cbrew}@ling.ohio-state.edu fosler@cse.ohio-state.edu 1 Introduction Subcategorization data has been crucial for various NLP tasks. Current method for automatic SCF acquisition usually proceeds in two steps: first, generate all SCF cues from a corpus using a parser, and then filter out spurious SCF cues with statistical tests. Previous studies on SCF acquisition have worked mainly with written texts; spoken corpora have received little attention. Transcripts of spoken language pose two challenges absent in written texts: uncertainty about utterance segmentation and disfluency. Roland &amp; Jurafsky (1998) suggest that there are substantial subcategorization differences between spoken and written corpora. For example, spoken corpora tend to have fewer passive sentences but many more zero-anaphora structures than written corpora. In light of such subcategorization differences, we believe that an SCF set built from spoken language may, if of acceptable quality, be of particular value to NLP tasks involving syntactic analysis of spoken language. 2 SCF Acquisition System Following the design proposed by Briscoe and Carroll (1997), we built an SCF acquisition system consisting of the following four </context>
</contexts>
<marker>Roland, Jurafsky, 1998</marker>
<rawString>Roland, D. &amp; Jurafsky, D. 1998. How Verb Subcategorization Frequency Affected by the Corpus Choice. In Proceedings of 17th International Conference on Computational Lingusitics, 2: 1122-1128</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Sarkar</author>
<author>D Zeman</author>
</authors>
<title>Automatic Extraction of Subcategorization Frames for Czech.</title>
<date>2000</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Lingusitics.</booktitle>
<pages>691--697</pages>
<contexts>
<context position="1781" citStr="Sarkar &amp; Zeman, 2000" startWordPosition="256" endWordPosition="259"> built from spoken language may, if of acceptable quality, be of particular value to NLP tasks involving syntactic analysis of spoken language. 2 SCF Acquisition System Following the design proposed by Briscoe and Carroll (1997), we built an SCF acquisition system consisting of the following four components: Charniak’s parser (Charniak, 2000); an SCF extractor; a lemmatizer; and an SCF evaluator. The first three components are responsible for generating SCF cues from the training corpora and the last component, consisting of the Binomial Hypothesis Test (Brent, 1993) and a back-off algorithm (Sarkar &amp; Zeman, 2000), is used to filter SCF cues on the basis of their reliability and likelihood. We evaluated our system on a million word written corpus and a comparable spoken corpus from BNC. For type precision and recall, we used 14 verbs selected by Briscoe &amp; Carroll (1997) and evaluated our results against SCF entries in COMLEX (Grishman et al., 1994). We also calculated token recall and the results are summarized in the following table. Corpus Written Spoken type precision 93.1% 91.2% type recall 48.2% 46.4% token recall 82.3% 80% Table 1: Type precision, recall and token recall 3 Detecting Incorrect SCF</context>
</contexts>
<marker>Sarkar, Zeman, 2000</marker>
<rawString>Sarkar, A. &amp; Zeman, D. 2000. Automatic Extraction of Subcategorization Frames for Czech. In Proceedings of the 19th International Conference on Computational Lingusitics. 691-697</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>