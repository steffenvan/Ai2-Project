<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000009">
<title confidence="0.995703">
Cross-narrative temporal ordering of medical events
</title>
<author confidence="0.999186">
Preethi Raghavan*, Eric Fosler-Lussier*, No´emie Elhadad† and Albert M. Lai*
</author>
<affiliation confidence="0.9713335">
*The Ohio State University, Columbus, Ohio
†Columbia University, New York, NY
</affiliation>
<email confidence="0.970966">
{raghavap, fosler}@cse.ohio-state.edu
noemie.elhadad@columbia.edu, albert.lai@osumc.edu
</email>
<sectionHeader confidence="0.982136" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999942">
Cross-narrative temporal ordering of med-
ical events is essential to the task of gen-
erating a comprehensive timeline over a
patient’s history. We address the prob-
lem of aligning multiple medical event se-
quences, corresponding to different clin-
ical narratives, comparing the following
approaches: (1) A novel weighted finite
state transducer representation of medi-
cal event sequences that enables compo-
sition and search for decoding, and (2)
Dynamic programming with iterative pair-
wise alignment of multiple sequences us-
ing global and local alignment algorithms.
The cross-narrative coreference and tem-
poral relation weights used in both these
approaches are learned from a corpus of
clinical narratives. We present results us-
ing both approaches and observe that the
finite state transducer approach performs
performs significantly better than the dy-
namic programming one by 6.8% for the
problem of multiple-sequence alignment.
</bodyText>
<sectionHeader confidence="0.995171" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999903965517241">
Discourse structure, logical flow of sentences, and
context play a large part in ordering medical events
based on temporal relations within a clinical nar-
rative. However, cross-narrative temporal rela-
tion ordering is a challenging task as it is dif-
ficult to learn temporal relations among medical
events which are not part of the logically coherent
discourse of a single narrative. Resolving cross-
narrative temporal relationships between medical
events is essential to the task of generating an
event timeline from across unstructured clinical
narratives such as admission notes, radiology re-
ports, history and physical reports and discharge
summaries. Such a timeline has multiple applica-
tions in clinical trial recruitment (Luo et al., 2011),
medical document summarization (Bramsen et al.,
2006, Reichert et al., 2010) and clinical decision
making (Demner-Fushman et al., 2009).
Given multiple temporally ordered medical
event sequences generated from each clinical nar-
rative in a patient record, how can we combine
the events to create a timeline across all the nar-
ratives? The tendency to copy-paste text and
summarize past information in newly generated
clinical narratives leads to multiple mentions of
the same medical event across narratives (Cohen
et al., 2013). These cross-narrative coreferences
act as important anchors for reasoning with in-
formation across narratives. We leverage cross-
narrative coreference information along with con-
fident cross-narrative temporal relation predictions
and learn to align and temporally order medical
event sequences across longitudinal clinical nar-
ratives. We model the problem as a sequence
alignment task and propose solving this using two
approaches. First, we use weighted finite state
machines to represent medical events sequences,
thus enabling composition and search to obtain
the most probable combined sequence of medical
events. As a contrast, we adapt dynamic program-
ming algorithms (Needleman et al., 1970, Smith
and Waterman, 1981) used to produce global and
local alignments for aligning sequences of med-
ical events across narratives. We also compare
the proposed methods with an Integer Linear Pro-
gramming (ILP) based method for timeline con-
struction (Do et al., 2012). The cross-narrative
coreference and temporal relation scores used in
both these approaches are learned from a corpus
of patient narratives from The Ohio State Univer-
sity Wexner Medical Center.
The main contribution of this paper is a general
framework that allows aligning multiple event se-
quences using cascaded weighted finite state trans-
ducers (WFSTs) with the help of efficient compo-
sition and decoding. Moreover, we demonstrate
that this method can be used for more accurate
multiple sequence alignment when compared to
</bodyText>
<note confidence="0.826641666666667">
998
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 998–1008,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.9743395">
dynamic programming or other ILP-based meth-
ods proposed in literature.
</bodyText>
<sectionHeader confidence="0.999266" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999994411111111">
In the areas of summarization and text-to-text gen-
eration, there has been prior work on several order-
ing strategies to order pieces of information ex-
tracted from different input documents (Barzilay
et al., 2002, Lapata, 2003, Bollegala et al., 2010).
In this paper, we focus on temporal ordering of in-
formation, as discussed next.
Recent state-of-the art research has focused on
the problem of temporal relation learning within
the same document, and in many cases within the
same sentence (Mani et al., 2006, Verhagen et al.,
2009, Lapata and Lascarides, 2011). Chambers
and Jurafsky (2009) describe a process to induce
a partially ordered set of events related by a com-
mon protagonist by using an unsupervised distri-
butional method to learn relations between events
sharing coreferring arguments, followed by tem-
poral classification to induce partial order. The
task was carried out on the Timebank newswire
corpus, but was limited to an intra-document set-
ting. More recently, (Do et al., 2012) proposed
an ILP-based method to combine the outputs of
an event-interval and an event-event classifier for
timeline construction on the ACE 2005 corpus.
However, this approach is also restricted to events
within documents and requires annotations for
event intervals. We empirically compare our meth-
ods for timeline creation from longitudinal clinical
narratives to such an ILP-based approach in Sec-
tion 7. While a lot of this work has been done in
the news domain, there is also some recent work
in rule-based algorithms (Zhou et al., 2006) and
machine learning (Roberts et al., 2008) applied
to temporal relations between medical events in
clinical text. Clinical narratives are written in a
distinct sub-language with domain specific termi-
nology and temporal characteristics, making them
markedly different from newswire text.
There is limited prior work in learning re-
lations across documents. Ji and Grishman
(2008) extended the one sense per discourse idea
(Yarowsky, 1995) to multiple topically related
documents and propagate consistent event argu-
ments across sentences and documents. Barzi-
lay and McKeown (2005) propose a text-to-text
generation technique for synthesizing common in-
formation across documents using sentence fu-
sion. This involves multisequence dependency
tree alignment to identify phrases conveying sim-
ilar information and statistical generation to com-
bine common phrases into a sentence. Along with
syntactic features, they combine knowledge from
resources like WordNet to find similar sentences.
In case of clinical narratives and medical event
alignment, the objective is to identify a unique se-
quence of temporally ordered medical events from
across longitudinal clinical data.
To the best of our knowledge, there is no
prior work on cross-document alignment of event
sequences. Multiple sequence alignment is a
problem that arises in a variety of domains in-
cluding gene/protein alignments in bioinformat-
ics (Notredame, 2002), word alignments in ma-
chine translation (Kumar and Byrne, 2003), and
sentence alignments for summarization (Lacatusu
et al., 2004). Dynamic programming algorithms
have been popularly leveraged to produce pair-
wise and global genetic alignments, where edit
distance based metrics are used to compute the
cost of insertions, deletions and substitutions.
We use dynamic programming to compute the
best alignment, given the temporal and corefer-
ence information between medical events across
these sequences. More importantly, we propose
a cascaded WFST-based framework for cross-
document temporal ordering of medical event se-
quences. Composition and search operations can
be used to build a single transducer that inte-
grates these components, directly mapping from
input states to desired outputs, and obtain the best
alignment (Mohri et al., 2000). In natural lan-
guage processing, WFSTs have seen varied appli-
cations in machine translation (Kumar and Byrne,
2003), morphology (Sproat, 2006), named en-
tity recognition (Krstev et al., 2011) and biolog-
ical sequence alignment / generation (Whelan et
al., 2010) among others. We demonstrate that
the WFST-based approach outperforms popularly
used dynamic programming algorithms for multi-
ple sequence alignment.
</bodyText>
<sectionHeader confidence="0.98332" genericHeader="method">
3 Problem Description
</sectionHeader>
<bodyText confidence="0.9996499">
Medical events are temporally-associated con-
cepts in clinical text that describe a medical con-
dition affecting the patient’s health, or procedures
performed on a patient. We represent medical
events by splitting each event into a start and a
stop. When there is insufficient information to dis-
cern the start or stop of an event, it is represented
as a single concept. If only the start is known then
the stop is set to +∞, whereas when only the stop
is known, the start is set to the date of birth of the
</bodyText>
<figure confidence="0.988346515151515">
999
Temporal Relation Event Ordering
N1
hypertensionstart admission1 chest painstart chest painstop heart attackstart
dob cocaine usestart infectionstart admission3 woundsstart +∞
dob
+∞
N2
dob
hypertensionstart
N3
palpitationsstart myocardial
infarctionstart
episodestart
+∞
admission2
MRSAstart
e1 before e2
e1 overlaps e2
e1 during e2
e1 starts with e2
e1 finishes with e2
e1 equals e2
e1.start &lt; e1.stop &lt; e2.start &lt; e2.stop
e1.start &lt; e2.start &lt; e1.stop &lt; e2.stop
e2.start &lt; e1.start &lt; e1.stop &lt; e2.stop
e1.start e2.start
- &lt; e1.stop e2.stop
&lt;
e2.start &lt; e1.start &lt; e1.stop - e2.stop
e1.start - e2.start &lt; e1.stop e2.stop
-
&lt; denotes before &gt; denotes after ~ denotes simultaneous
</figure>
<figureCaption confidence="0.998495">
Figure 1: Medical event start / stop representa-
</figureCaption>
<bodyText confidence="0.992720608695652">
tion mapped to Allen’s temporal relations (Allen,
1981). Temporal ordering of event starts and stops
using {before, after, simultaenous} (shown on the
right) allows us learn temporal relations between
the medical events (shown on the left). e1start =
e2start and e1stop = e2stop, when e1 and e2 core-
fer.
patient.1 Often, for chronic ailments like hyper-
tension, we would only associate a start with the
medical event and set the stop to +oo. The start of
hypertension may be associated with the temporal
expression history of in the narrative. This, when
considered along with the admission date, allows
us to relatively order hypertension with respect to
other medical events. A medical event occurrence
like chest pain may be associated with a start and
a stop, where the start may be determined by the
mention of “patient was complaining of chest pain
yesterday” in the narrative text. Further, the nar-
rative may state that “he continued to have chest
pain on admission, but currently he is chest pain
free”; this may be used to infer the relative stop of
chest pain. Medical events may also be instan-
taneous, for e.g., injected with antibiotic. Such
events are represented with the start and stop as
being the same. Temporal relations exist between
the start and stop of events as shown in Figure 1.
Learning temporal relations before, after and si-
multaneous between the medical event starts and
stops corresponds to learning all of Allen’s tem-
poral relations (Allen, 1981) between the medical
events. Following our previous work (Raghavan
et al., 2012c), such a representation allows us to
temporally order the event starts and stops within
each clinical narrative by learning to rank them in
relative order of time. The problem definition is as
follows:
1Patient date of birth, admission/ discharge date are usu-
ally available in the metadata associated with a clinical nar-
rative.
Figure 2: Given temporally ordered medical event
sequences, N1, N2, N3, we address the task of
combining events across these sequences by merg-
ing or ordering them to create a single comprehen-
sive timeline.
Input: Sequences of temporally ordered med-
ical event starts and stops. This corresponds to
N1, N2, and N3 in Figure 2. Each sequence cor-
responds to a clinical narrative. The total number
of sequences correspond to the number of clinical
narratives for a patient.
Problem: Combine medical events across these
sequences to generate a timeline i.e., a single com-
prehensive sequence of medical events over all
clinical narratives of the patient.
Expected Output: In the example shown
in Figure 2, the output would be as follows:
Timeline (N1, N2, N3)= {cocaine usestart &lt;
hypertensionstart = hypertensionstart &lt; admis-
sion1 &lt; chest painstart ∼ palpitationsstart &lt;
chest painstop &lt; heart attackstart = myocardial
infarctionstart &lt; admission2 &lt; infectionstart &lt;
MRSAstart &lt; admission3 &lt; woundsstart}.
The goal of multiple sequence alignment is to
find an alignment that maximizes some overall
alignment score. Thus, in order to align event se-
quences, we need to compute scores correspond-
ing to cross-narrative medical event coreference
resolution and cross-narrative temporal relations.
</bodyText>
<sectionHeader confidence="0.9295495" genericHeader="method">
4 Cross-Narrative Coreference
Resolution and Temporal Relation
</sectionHeader>
<subsectionHeader confidence="0.721538">
Learning
</subsectionHeader>
<bodyText confidence="0.989472375">
The first approach to learning a temporal order-
ing of medical events across all clinical narratives
is to consider all pairs of events across all narra-
tives and learn to classify them as sharing one of
Allen’s temporal relations (Allen, 1981) using a
single learning model. Alternatively, a ranking ap-
1000
proach, similar to the one used to generate intra-
narrative temporal ordering, can also be extended
to the cross-narrative case. However, the features
related to narrative structure and relative and im-
plicit temporal expressions used for temporal or-
dering within a clinical narrative may not be ap-
plicable across narratives. For instance, a history
and physical report may have sections like “past
medical history”, “history of present illness”, “as-
sessment and plan”, and a certain logical pattern
to the flow of text within and across these sec-
tions. Further, temporal cues like “thereafter”,
“subsequently”, follow from the context around an
event mention. The absence of such features in the
cross-narrative case does not allow such a model
to generate accurate temporal relation predictions.
Thus, for use in our sequence alignment models,
we learn two independent classifiers for medical
event coreference and temporal relation learning
across narratives. We train a classifier to resolve
cross-narrative coreferences by extracting seman-
tic and temporal relatedness feature sets for each
pair of medical concepts. Extracting these fea-
ture sets helps us train a classifier to predict med-
ical event coreferences (Raghavan et al., 2012a).
Another classifier is then trained to classify pairs
of medical event starts and stops across narratives
as sharing temporal relations {before, after, over-
laps}. The learned cross-narrative coreference
predictions can then be used along with confi-
dent temporal relation predictions to derive a joint
probability to enable cross-narrative temporal or-
dering.
</bodyText>
<sectionHeader confidence="0.7597465" genericHeader="method">
5 Narrative Sequence Alignment for
Cross-narrative Temporal Ordering
</sectionHeader>
<bodyText confidence="0.957465138888889">
Sequence alignment algorithms have been de-
veloped and popularly used in bioinformatics.
However, multiple sequence alignment (MSA)
has been shown to be NP complete (Wang and
Jiang, 1994) and various heuristic algorithms have
been proposed to solve this problem (Notredame,
2002). We propose a novel WFST-based repre-
sentation that enables accurate decoding for MSA
when compared to popularly used dynamic pro-
gramming algorithms (Needleman et al., 1970,
Smith and Waterman, 1981) or other state of the
art methods (Do et al., 2012).
In the problem of aligning events across mul-
tiple narrative sequences, we want to align tem-
porally ordered medical events corresponding to
clinical narratives of a patient. Unlike problems
in biological sequence alignment where the sym-
Figure 3: Score computation for aligning events
across temporally ordered event sequences chest
painstart = episodestart &lt; chest painstop =
episodestop, where events across the sequences oc-
cur simultaneously and corefer.
Figure 4: Score computation for aligning events
across temporally ordered event sequences chest
painstart — palpitationsstop &lt; chest painstop &lt;
palpitationsstop, where some events across the se-
quences occur simultaneously but do not corefer.
bols to be aligned across sequences are restricted
to a fixed set, our symbol set is not fixed or cer-
tain because the symbols correspond to medical
events in clinical narratives. Moreover, we can-
not have fixed scores for symbol transformations
since our transformations correspond to corefer-
ence and temporal relations between the medical
events across sequences. The computation of these
scores is described next.
</bodyText>
<subsectionHeader confidence="0.999695">
5.1 Scoring Scheme
</subsectionHeader>
<bodyText confidence="0.999557">
Let us assume a, b are medical events in the first
clinical narrative and have been temporally or-
dered so a &lt; b. Similarly, x, y are medical events
in the second clinical narrative such that x &lt; y.
There exists a match or an alignment between a
pair of medical events, across the sequences, in the
following cases:
</bodyText>
<listItem confidence="0.92314075">
1. If the medical events are simultaneous and
coreferring, denoted as a = x.
2. If the medical events are simultaneous and
non-coreferring, denoted as a — x.
</listItem>
<figure confidence="0.9997996">
a b
chest painstart
episodestart
&lt; chest painstop
&lt; episodestop
x y
Score = P(a simult x  |a coref x) P(a coref x)
a = x
&lt; b = y
a b
chest painstart
&lt; chest painstop
palpitationsstart
&lt; palpitationsstop
x y
a ~ x &lt; b &lt; y
Score = P(a simult x  |a no-coref x) ×
P(x before b  |a no-coref x) ×
P(b before y  |a no-coref x) P(a no-coref x)
1001
</figure>
<figureCaption confidence="0.988958">
Figure 5: Score computation for aligning
</figureCaption>
<bodyText confidence="0.9899744">
events across temporally ordered event se-
quences hypertensionstart &lt; palpitationsstart &lt;
infectionstart &lt; MRSAstart, where events across
the sequences do not occur simultaneously and do
not corefer.
</bodyText>
<listItem confidence="0.984453833333333">
3. If the a medical event from one sequence
is before a medical event from another se-
quence, denoted as a &lt; x.
4. If the a medical event from one sequence is
after a medical event from another sequence,
denoted as a &gt; x.
</listItem>
<bodyText confidence="0.99956225">
We now illustrate how the scores for candidate
aligned sequences are computed using the learned
cross-narrative coreference and temporal probabil-
ities for the following three scenarios:
</bodyText>
<listItem confidence="0.881818733333333">
• The medical events across sequences are si-
multaneous and corefer as illustrated in Fig-
ure 3. The joint score considers the probabil-
ity of event temporal relations simultaneous
conditioned on coreference.
• Some medical events across sequences are si-
multaneous but do not corefer as illustrated in
Figure 4. Here, the joint score considers the
joint probability of temporal relations simul-
taneous or before and no-coreference.
• The medical events across sequences are not
simultaneous and do not corefer as illustrated
in Figure 5. In this case, the joint score con-
siders the probability of the temporal relation
before and no coreference.
</listItem>
<bodyText confidence="0.9998894">
Thus, the coreference and temporal relation scores
can be leveraged for aligning sequences of medical
events. These scores are used in both the WFST-
based representation and decoding, as well as for
dynamic programming.
</bodyText>
<subsectionHeader confidence="0.975108">
5.2 Alignment using a Weighted Finite State
Representation
</subsectionHeader>
<bodyText confidence="0.999537785714286">
A weighted finite-state transducer (WFST) is an
automaton in which each transition between states
is associated with an input symbol, an output sym-
bol, and a weight (Mohri et al., 2005). WFSTs can
be used to efficiently represent and combine se-
quences of medical events based coreference and
temporal relation information. The WFST rep-
resentation gives us the ability to talk about the
global joint probability derived from coreference
and temporal relation scores described in Section
5.1. It allows us to build a weighted lattice of se-
quences that can be searched for the most probable
sequence of medical events from across all clin-
ical narratives of a patient. We use unweighted
FSAs to represent the input described in Section
3, i.e. temporally ordered sequences of medical
events corresponding to clinical narratives. This
corresponds to N1 and N2 in Figure 6.
Based on whether we want to align the se-
quences purely based on coreference scores or
both coreference and temporal relation scores, the
arc weights for the WFST can be determined. Mc12
is a WFST that maps input symbols from N1 to
output symbols in N2 and is weighted by the prob-
ability of coreference or no-coreference between
medical events across N1 and N2. The represen-
tation in WFST Mc+t
12 shown in Figure 7 allows
us to align N1 and N2 based on both coreference
as well as temporal relation probabilities. The
WFST has c transitions to accommodate insertion
and deletion of medical events when combining
the sequences. Deletions correspond to the case
when an event in the first sequence does not map
to any event in the second sequence; similarly in-
sertions correspond to the case where an event in
the second sequence does not map to any event in
the first sequence. The WFST composition opera-
tion allows the outputs of one WFST to be fed to
the inputs of a second WFST or FSA. Thus, we
build our final machine by composing the three
sub-machines as,
</bodyText>
<equation confidence="0.998866">
D = N1 ◦ Mi12 ◦ N2. (1)
</equation>
<bodyText confidence="0.999865571428571">
where i = c or i = c + t. This gives us a com-
bined weighted graph by mapping the output sym-
bols of the first medical event sequence to the in-
put symbols of the second medical event sequence.
The scores on the decoding graph are derived from
only the coreference probabilities if i = c and both
coreference and temporal relation probabilities if
</bodyText>
<equation confidence="0.73592">
i = c + t.
</equation>
<bodyText confidence="0.99977525">
In the medical event sequence alignment prob-
lem, we want to align multiple sequences of medi-
cal events that correspond to multiple clinical nar-
ratives of a patient. Since we want to now combine
</bodyText>
<figure confidence="0.9989095">
a b
hypertensionstart &lt; palpitationsstart
&lt; infectionstart MRSAtart
&lt;
Score = P(a before x |a no-coref x) P(a no-coref x) ×
P(x before b  |x no-coref b) P(x no-coref b) ×
P(b before y  |b no-coref y) P(b no-coref y)
x y
a &lt; x &lt; b &lt; y
1002
</figure>
<figureCaption confidence="0.850812">
Figure 6: N1 and N2 are medical event sequences represented using FSAs. Mi2 maps medical events
across N1 and N2 and is weighted only by the probability of coreference between events across N1 and
N2.
Figure 7: M�+t
12 is a WFST representation used for mapping medical events between N1 and N2 (from
Figure 2) and is weighted by both the coreference and temporal relation probabilities
</figureCaption>
<figure confidence="0.996726125">
N1
M12
N2
chestpain:-/0.23
hypertension:-/0.27
-:cocaineabuse/0.1
chestpain:-/0.23
hypertension:-/0.24
-:admission/0.1
chestpain:-/0.23
hypertension:-/0.24
cocaineuse:-/0.13
cocaineuse:-/0.13
cocaineuse:-/0.13
0
cocaineuse:cocaineabuse/0.9
hypertension:cocaineabuse/0.4
chestpain:cocaineabuse/0.3
1
cocaineuse:admission/0.1
hypertension:admission/0.1
chestpain:admission/0.1
2
h
</figure>
<page confidence="0.648996">
c
</page>
<bodyText confidence="0.999118">
all narrative chains belonging to the same patient,
the composition cascade to build the final com-
bined sequence will be as,
</bodyText>
<equation confidence="0.949609">
Df = N1◦M12◦N2◦M23◦N3◦M34...◦NI, (2)
</equation>
<bodyText confidence="0.988046786885246">
where i = c or i = c + t and n is the number
of medical event sequences corresponding to clin-
ical narratives for a patient. During composition
we retain intermediate paths like M23 utilizing the
ability to do lazy composition (Mohri and Pereira,
1998) in order to facilitate beam search through
the multi-alignment. The best hypothesis corre-
sponds to the highest scoring path which can be
obtained using shortest path algorithms like Djik-
stra’s algorithm. The best path corresponds to the
best alignment across all medical event sequences
based on the joint probability of cross-narrative
medical event coreferences and temporal relations
across the narrative sequences.
The complexity of decoding increases exponen-
tially with the number of narrative sequences in
the composition, and exact decoding becomes in-
feasible. One solution to this problem is to do
the alignment greedily pairwise, starting from the
most recent medical event sequences, finding the
best path, and iteratively moving on to the next
sequence, and proceeding until the oldest medi-
cal event sequence. The disadvantage of such a
method is that it does not take into account con-
straints between medical events across multiple
event sequences and may lead to a less accurate
solution.
An alternative method is to use lazy compo-
sition to perform more efficient composition as
it allows practical memory usage. We also use
beam search to make for an efficient approxima-
tion to the best-path computation (Mohri et al.,
2005). This allows accommodating constraints
from across multiple sequences and generates a
more accurate best path. Thus, this method gener-
ates more accurate alignments when we have more
than two sequences to be aligned.
1003
For instance, instance say a, b E N1, x, y E N2,
and m, n E N3 are temporally medical event se-
quences corresponding to narratives N1, N2 and
N3. Based on the learned pairwise temporal rela-
tions, if we have the following constraints a &lt; x,
m &gt; x, m &lt; a. Aligning N1 and N2 greedily
pairwise may give us the best combined sequence
as a, x, b, y E N12. Now in aligning N12 with
N3, we won’t be able to accommodate m &gt; x and
m &lt; a. However, performing a beam search over
the composed WFST in equation 2 allows us to
accommodate such constraints across multiple se-
quences. The complexity of composing two trans-
ducers is O(V1V2D1(logD2 + M2)) where each
edge from the first sequence matches every edge in
the second sequence and Vi is the number of states,
Di is the maximum out-degree and Mi maximum
multiplicity for the ith FST (Mohri et al., 2005).
We also use popular dynamic programming al-
gorithms (Needleman et al., 1970, Smith and Wa-
terman, 1981) for sequence alignment of medi-
cal events across narratives and compare it to the
WFST-based representation and decoding.
</bodyText>
<subsectionHeader confidence="0.7433325">
5.3 Pairwise Alignment using Dynamic
Programming
</subsectionHeader>
<bodyText confidence="0.999975333333333">
As a contrast, we adapt two dynamic program-
ming algorithms for sequence alignment: global
alignment using the Needleman Wunsch algo-
rithm (NW) (Needleman et al., 1970) and local
alignment using the Smith-Waterman algorithm
(SW) (Smith and Waterman, 1981). NW allows
us to align all events in one sequence with all
events in another sequence. A drawback of NW
is that short and highly similar sequences maybe
missed because they get overweighted by the rest
of the sequence. NW is suitable when the two se-
quences are of similar length with significant de-
gree of similarity throughout. On the other hand,
SW gives the longest sub-sequence pair that yields
maximum degree of similarity between the two
original sequences. It does not force all events
in a sequence to align with another sequence.
SW is useful in aligning sequences that differ in
length and have short patches of similarity. The
time complexity of these methods for sequences
of length m and n are O(mn).
The scoring scheme described earlier is used to
update the scoring matrix for dynamic program-
ming. In order to accommodate the temporal re-
lations before and after, we insert a null symbol
after every medical event in each sequence in the
scoring matrix. A vertical or horizontal gap arises
when cases 1, 2, 3 and 4 in Section 5.1 mentioned
above are not true. If the medical events are not
simultaneous, not before or not after, the medical
events will not align. Thus, the value of each cell
in the scoring matrix is determined by computing
the maximum score at each position C(i, j) as,
</bodyText>
<equation confidence="0.982677">
max{(C(i−1, j −1)+5ij), (C(i, j −1)+w),
(C(i − 1, j) + w)} (3)
</equation>
<bodyText confidence="0.992417227272728">
where, 5ij = max{P(i = j), P(i &lt; j), P(i &gt;
j)}, and w = max{(1 − P(i = j)), (1 − P(i &lt;
j)), (1 − P(i &gt; j))}. Here, C(i − 1, j − 1)
corresponds to a match, whereas C(i, j − 1) and
C(i − 1, j) correspond to a gaps in sequence one
and two.
In case of the SW algorithm, the negative scor-
ing matrix cells are set to zero, thus making the
positively scoring local alignments visible. Back-
tracking starts at the highest scoring matrix cell
and proceeds until a cell with score zero is encoun-
tered, yielding the highest scoring local alignment.
The time and space complexity grows exponen-
tially with the number of sequences to be aligned
and finding the global optimum has been shown to
be a NP-complete problem. The time complexity
of aligning N sequences of length L is O(2NLN)
(Wang and Jiang, 1994). Thus, for MSA using
dynamic programming, we use a heuristic method
where we combine pairwise alignments iteratively
starting with the latest narrative and progressing
towards the oldest narrative.
</bodyText>
<sectionHeader confidence="0.985651" genericHeader="evaluation">
6 Experiments and Evaluation
</sectionHeader>
<bodyText confidence="0.994747523809524">
Corpus Description. The corpus consists of a
dataset of clinical narratives obtained from the
[redacted] medical center. The corpus has a total
of 2060 patients, and 100704 clinical narratives.
We gathered a gold standard set of seven patients
(80 clinical narratives overall) with manual anno-
tation of all medical events mentioned in the nar-
ratives, coreferences, and medical event sequence
information. The annotation agreement across
annotators is high, with 89.5% agreement corre-
sponding to inter-annotator Cohen’s kappa statis-
tic of 0.86 (Raghavan et al., 2012b). The types
of clinical narratives included 27 discharge sum-
maries, 30 history and physical reports, 15 radiol-
ogy reports and 8 pathology reports. The distribu-
tion of the number of medical event sequences and
unique medical events across patients is shown in
Table 1. The annotated dataset is used to cross-
validate and train our coreference and temporal re-
lation learning models and to evaluate our cross-
narrative medical event timeline.
</bodyText>
<table confidence="0.986659615384615">
1004
p1 p2 p3 p4 p5 p6 p7
No. of Narrative Sequences 5 9 20 13 8 10 15
No. of Medical events 68 90 119 82 79 72 95
% Accuracy % Avg.
WFST-framework (lazy composition and beam search)[c+t] 76.1 73.2 81.2 83.5 76.4 82.5 79.7 78.9
WFST-framework (Iterative pairwise)[c+t] 70.4 67.1 73.5 74.1 61.8 75.5 62.9 69.3
Smith Waterman (Iterative pairwise)[c+t] 71.2 69.7 75.5 75.6 66.3 77.4 68.3 72.1
Needleman-Wunsch (Iterative pairwise)[c+t] 68.1 66.3 72.1 74.4 61.1 75.5 63.6 68.7
WFST-framework (lazy composition and beam search)[c] 68.5 65.3 72.3 74.4 67.2 71.3 69.1 69.7
WFST-framework (Iterative pairwise)[c] 61.2 63.3 61.9 60.4 59.8 64.8 60.5 61.7
Smith Waterman (Iterative pairwise)[c] 60.3 63.7 68.2 62.3 58.6 66.7 60.2 62.8
Needleman-Wunsch (Iterative pairwise)[c] 56.6 60.1 59.3 65.6 54.7 63.1 58.2 59.6
</table>
<tableCaption confidence="0.999118">
Table 1: The distribution of medical events across narrative sequences and sequences across patients and
</tableCaption>
<bodyText confidence="0.9937406">
multiple sequence alignment results for the WFST-based framework, and dynamic programming using
just coreference scores [c] and using coreference as well as temporal relation scores [c+t].
Evaluation Metric. For each patient and each
method (WFST or dynamic programming), the
output timeline to evaluate is the highest scoring
candidate hypothesis derived as described above.
Accuracy of the timeline is calculated as the num-
ber of transformations required to obtain the refer-
ence sequence in the annotated gold-standard from
the one generated by our system. Transformations
are measured in terms of the minimum edit dis-
tance, insertions, deletions, and substitutions of
medical events.
Experiments and Results. We first temporally
order medical events within each clinical narrative
by learning to rank them in relative order of oc-
curence as described in our previous work (Ragha-
van et al., 2012c). The overall accuracy of rank-
ing medical events using leave-one-out cross val-
idation is 82.1%. The resulting medical event se-
quences serve as the input to the problem of cross-
narrative sequence alignment.
The cross-narrative coreference and temporal
relation pairwise classification models described
in Section 4 are trained using a Maximum en-
tropy classifier. The coreference resolution per-
forms with 71.5% precision and 82.3% recall. The
temporal relation classifier performs with 60.2%
precision and 76.3% recall. The learned pairwise
coreference and temporal relation probabilities are
now used to derive the score for the WFST and dy-
namic programming approaches.
WFST representation and decoding. We
build finite-state machines using the open source
OpenFST library.2 We use a tropical semi-ring
weighted using the negative log-likelihood of the
computed scores. OpenFST provides tools that
can search for the highest scoring sequences ac-
cepted by the machine, and can sample from high-
scoring sequences probabilistically, by treating the
</bodyText>
<footnote confidence="0.648054">
2www.openfst.org
</footnote>
<bodyText confidence="0.999901972222222">
scores of each transition within the machine as a
negative log probability. The decoding process to
compute the most likely combined medical event
sequence can be defined as searching for the best
path in the combined graph representation (Equa-
tion 2). The best path is the one that minimizes
the total weight on a path (since the arcs are neg-
ative log probabilities). In searching for the best
path, the beam size is set to 5. The accuracy of
the WFST-based representation and beam search
across all sequences using the coreference and
temporal relation scores to obtain the combined
aligned sequence is 78.9%.
Dynamic Programming. We use the NW and
SW algorithms described in Section 5.3 to pro-
duce local and global alignments respectively. We
use the scoring scheme described in Section 5.1 to
update the cost matrix for dynamic programming
and implement the algorithms as described in Sec-
tion 5.3. The overall accuracy of sequence align-
ment with both coreference and temporal relation
scores using NW is 68.7% whereas SW gives an
accuracy of 72.1%. In case of aligning just two
sequences, both methods yield the same results.
The accuracy of cross-narrative MSA for each pa-
tient, for each method, using cross validation, is
shown in Table 1. Results indicate that the WFST-
based method outperforms the dynamic program-
ming approach for multi-sequence alignment (sta-
tistical significance p&lt;0.05). Morever, the re-
sults using both coreference and temporal realtion
scores for alignment outperform using only coref-
erence scores for alignment using all approaches.
This indicates that cross-narrative temporal rela-
tions are important for accurately aligning medical
event sequences across narratives.
</bodyText>
<sectionHeader confidence="0.994663" genericHeader="evaluation">
7 Discussion
</sectionHeader>
<bodyText confidence="0.991042727272727">
We propose and evaluate different approaches to
multiple sequence alignment of medical events.
1005
Approaches to multi-alignment. We address
the problem of aligning medical event sequences
using a novel WFST-based framework and empiri-
cally demonstrate that it outperforms pairwise pro-
gressive alignment using dynamic programming.
This is mainly because the WFST-based allows us
to consider temporal constraints from across mul-
tiple sequences when performing the alignment.
Moreover, it also outperforms the integer lin-
ear programming (ILP) method for timeline con-
struction proposed in (Do et al., 2012). We im-
plemented the proposed method that also allows
combining the output of classifiers subject to some
constraints. We derive intervals from event starts
and stops and learn two perceptron classifiers for
classifying the temporal relations between events
and assigning events to intervals. The classifier
probabilities are then used to solve the optimiza-
tion problem using the lpsolve solver.3 We also
use intra-document coreference information to re-
solve coreference before performing the global op-
timization. We observe that in case of MSA, the
optimal solution using ILP is still intractable as
the number of constraints increases exponentially
with the number of sequences. Aligning pair-
wise iteratively gives us an overall average accu-
racy of 68.2% similar to dynamic programming.
While this is comparable to the dynamic pro-
gramming performance, the WFST-based method
significantly outperforms this in case of multi-
alignments for cross-narrative temporal ordering.
Performance and error analysis. We perform
multi-alignments over medical event sequences
for a patient, where each sequence corresponds
to temporally ordered medical events in a clinical
narrative generated using the ranking model de-
scribed in (Raghavan et al., 2012c). The accuracy
of intra-narrative temporal ordering is 82.1%. The
errors in performing this intra-narrative ordering
may propagate to the cross-narrative model result-
ing in reduced accuracy. This may be addressed
by considering n-best temporally ordered medi-
cal event sequences, generated by the ranking pro-
cess, and aligning the n-best sequences using the
WFST-based framework. This could be feasible
as, practically, the WFST-based method for multi-
alignment takes only a few secs to align a pair of
medical event sequences with average length 40.
The accuracy of alignments across multiple
medical event sequences is also affected by the er-
ror induced by the coreference and temporal rela-
tion scores. Often, insufficient temporal cues leads
</bodyText>
<footnote confidence="0.339065">
3http://lpsolve.sourceforge.net/5.5/
</footnote>
<bodyText confidence="0.999835894736842">
to misclassification of events incorrectly as shar-
ing the “simultaneous” temporal relation and often
as coreferring. This induces errors in the score cal-
culation and hence the alignments. Better meth-
ods to address the challenging problem of cross-
document temporal relation learning, perhaps with
the help of structured data from the patient record,
could improve the accuracy of alignments.
There is no clear trend with respect to the num-
ber of medical events and narratives for a patient
(Table 1.), and the alignment accuracy. In fu-
ture work, it would be interesting to examine any
such correlation and also study the scalability of
the WFST-based method for sequence alignment
on longer medical event sequences and a larger
dataset of patients. Further, the WFST-based
method may be used to model multi-alignment
tasks in other speech and language problems as
well.
</bodyText>
<sectionHeader confidence="0.994294" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.99995095">
We propose a novel framework for aligning med-
ical event sequences across clinical narratives
based on coreference and temporal relation infor-
mation using cascaded WFSTs. FSTs provide a
convenient and flexible framework to model se-
quences of temporally ordered medical events and
compose them into a combined graph represen-
tation. Decoding this graph allows us to jointly
maximize coreference as well as temporal relation
probabilities to derive a timeline of the most likely
temporal ordering of medical events. This ap-
proach to aligning multiple sequences of medical
events significantly outperforms other approaches
such as dynamic programming. Moreover, we
demonstrate the importance of learning tempo-
ral relations for the task timeline generation from
across multiple clinical narratives by empirically
proving that decoding using both coreference and
temporal relation scores is far more accurate than
decoding with only coreference scores.
</bodyText>
<sectionHeader confidence="0.995492" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999956375">
The project was supported by Award Number
Grant R01LM011116 from the National Library
of Medicine. The content is solely the responsibil-
ity of the authors and does not necessarily repre-
sent the official views of the National Library of
Medicine or the National Institutes of Health. The
authors would like to thank Yanzhang He for his
input on the WFST-based model.
</bodyText>
<page confidence="0.628532">
1006
</page>
<sectionHeader confidence="0.986325" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999241909090909">
James F. Allen. 1981. An interval-based representa-
tion of temporal knowledge. In IJCAI, pages 221–
226.
Regina Barzilay and Kathleen R. McKeown. 2005.
Sentence fusion for multidocument news sum-
marization. Comput. Linguist., 31(3):297–328,
September.
Regina Barzilay, Noemie Elhadad, and Kathleen McK-
eown. 2002. Inferring strategies for sentence or-
dering in multidocument summarization. Journal of
Artificial Intelligence Research (JAIR), 17:35–55.
Danushka Bollegala, Naoaki Okazaki, and Mitsuru
Ishizuka. 2010. A bottom-up approach to sentence
ordering for multi-document summarization. Infor-
mation processing &amp; management, 46(1):89–109.
Philip Bramsen, Pawan Deshpande, Yoong Keok Lee,
and Regina Barzilay. 2006. Inducing temporal
graphs. In Proceedings of the 2006 Conference on
Empirical Methods in Natural Language Process-
ing, EMNLP ’06, pages 189–198.
Nathanael Chambers and Dan Jurafsky. 2009. Unsu-
pervised learning of narrative schemas and their par-
ticipants. In ACL/AFNLP, pages 602–610.
Raphael Cohen, Michael Elhadad, and No´emie El-
hadad. 2013. Redundancy in electronic health
record corpora: analysis, impact on text mining per-
formance and mitigation strategies. BMC bioinfor-
matics, 14(1):10.
Dina Demner-Fushman, Wendy Webber Chapman, and
Clement J. McDonald. 2009. What can natural lan-
guage processing do for clinical decision support?
Journal of Biomedical Informatics, 42(5):760–772.
Quang Xuan Do, Wei Lu, and Dan Roth. 2012. Joint
inference for event timeline construction. In Pro-
ceedings of the 2012 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning, EMNLP-
CoNLL ’12, pages 677–687. Association for Com-
putational Linguistics.
Heng Ji and Ralph Grishman. 2008. Refining event
extraction through cross-document inference. In As-
sociation for Computational Linguistics.
Cvetana Krstev, Du&amp;quot;sko Vitas, Ivan Obradovi´c, and
Milo&amp;quot;s Utvi´c. 2011. E-dictionaries and Finite-state
automata for the recognition of named entities. In
Proceedings of the 9th International Workshop on
Finite State Methods and Natural Language Pro-
cessing, pages 48–56.
Shankar Kumar and William Byrne. 2003. A weighted
finite state transducer implementation of the align-
ment template model for statistical machine trans-
lation. In Proceedings of the 2003 Conference
of the North American Chapter of the Association
for Computational Linguistics on Human Language
Technology - Volume 1, pages 63–70.
V Finley Lacatusu, Steven J Maiorano, and Sanda M
Harabagiu. 2004. Multi-document summarization
using multiple-sequence alignment. In LREC.
Mirella Lapata and Alex Lascarides. 2011. Learn-
ing sentence-internal temporal relations. CoRR,
abs/1110.1394.
Mirella Lapata. 2003. Probabilistic text structuring:
Experiments with sentence ordering. In Proceed-
ings of the 41st Annual Meeting on Association for
Computational Linguistics-Volume 1, pages 545–
552. Association for Computational Linguistics.
Zhihui Luo, Stephen B. Johnson, Albert M. Lai, and
Chunhua Weng. 2011. Extracting temporal con-
straints from clinical research eligibility criteria us-
ing conditional random fields. In Proc of AMIA
Symposium.
Inderjeet Mani, Marc Verhagen, Ben Wellner,
Chong Min Lee, and James Pustejovsky. 2006.
Machine learning of temporal relations. In ACL.
Mehryar Mohri and Fernando CN Pereira. 1998. Dy-
namic compilation of weighted context-free gram-
mars. In Proceedings of the 36th Annual Meet-
ing of the Association for Computational Linguis-
tics and 17th International Conference on Compu-
tational Linguistics-Volume 2, pages 891–897. As-
sociation for Computational Linguistics.
Mehryar Mohri, Fernando C. N. Pereira, and Michael
Riley. 2000. The design principles of a weighted
finite-state transducer library. Theoretical Computer
Science, 231(1):17–32.
Mehryar Mohri, Fernando Pereira, and Michael Riley.
2005. Weighted automata in text and speech pro-
cessing. CoRR, abs/cs/0503077.
S.B. Needleman, C.D. Wunsch, et al. 1970. A general
method applicable to the search for similarities in
the amino acid sequence of two proteins. Journal of
molecular biology, 48(3):443–453.
C´edric Notredame. 2002. Recent progress in multiple
sequence alignment: a survey. Pharmacogenomics,
3(1):131–144.
Preethi Raghavan, Eric Fosler-Lussier, and Albert M.
Lai. 2012a. Exploring semi-supervised coreference
resolution of medical concepts using semantic and
temporal features. In North American Association
for Computational Linguistics Annual Meeting - Hu-
man Language Technologies Conference. Associa-
tion for Computational Linguistics.
Preethi Raghavan, Eric Fosler-Lussier, and Albert M.
Lai. 2012b. Inter-annotator reliability of medi-
cal events, coreferences and temporal relations in
clinical narratives by annotators with varying levels
of clinical expertise. In To appear in Proceedings
1007
of the American Medical Informatics Association.
American Medical Informatics Association.
Preethi Raghavan, Eric Fosler-Lussier, and Albert M.
Lai. 2012c. Learning to temporally order medical
events in clinical text. In ACL short paper. Associa-
tion for Computational Linguistics.
Daniel Reichert, David Kaufman, Benjamin Bloxham,
Herbert Chase, and No´emie Elhadad. 2010. Cog-
nitive analysis of the summarization of longitudinal
patient records. In AMIA Annual Symposium Pro-
ceedings, volume 2010, page 667. American Medi-
cal Informatics Association.
A. Roberts, R. Gaizauskas, M. Hepple, G. Demetriou,
Y. Guo, and A. Setzer. 2008. Semantic Annotation
of Clinical Text: The CLEF Corpus. In Proceedings
of the LREC 2008 Workshop on Building and Eval-
uating Resources for Biomedical Text Mining, pages
19–26.
T.F. Smith and M.S. Waterman. 1981. Identifica-
tion of common molecular subsequences. Journal
of molecular biology, 147(1).
Richard Sproat. 2006. A Computational Theory of
Writing Systems (Studies in Natural Language Pro-
cessing). Cambridge University Press.
Marc Verhagen, Robert J. Gaizauskas, Frank Schilder,
Mark Hepple, Jessica Moszkowicz, and James
Pustejovsky. 2009. The tempeval challenge: iden-
tifying temporal relations in text. Language Re-
sources and Evaluation, 43(2):161–179.
Lusheng Wang and Tao Jiang. 1994. On the complex-
ity of multiple sequence alignment. Journal of com-
putational biology, 1(4):337–348.
Christopher Whelan, Brian Roark, and Kemal Son-
mez. 2010. Designing antimicrobial peptides with
weighted finite-state transducers. In Proceedings of
IEEE Engineering in Medical Biology Society, page
764.
David Yarowsky. 1995. Unsupervised word sense dis-
ambiguation rivaling supervised methods. In Asso-
ciation for Computational Linguistics, pages 189–
196.
Li Zhou, Genevieve B. Melton, Simon Parsons, and
George Hripcsak. 2006. A temporal constraint
structure for extracting temporal information from
clinical narrative. Journal of Biomedical Informat-
ics, pages 424–439.
</reference>
<page confidence="0.698976">
1008
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.825861">
<title confidence="0.998244">Cross-narrative temporal ordering of medical events</title>
<author confidence="0.995923">Eric No´emie Albert M</author>
<affiliation confidence="0.999984">Ohio State University, Columbus,</affiliation>
<address confidence="0.840763">University, New York,</address>
<email confidence="0.999898">noemie.elhadad@columbia.edu,albert.lai@osumc.edu</email>
<abstract confidence="0.999427541666667">Cross-narrative temporal ordering of medical events is essential to the task of generating a comprehensive timeline over a patient’s history. We address the problem of aligning multiple medical event sequences, corresponding to different clinical narratives, comparing the following approaches: (1) A novel weighted finite state transducer representation of medical event sequences that enables composition and search for decoding, and (2) Dynamic programming with iterative pairwise alignment of multiple sequences using global and local alignment algorithms. The cross-narrative coreference and temporal relation weights used in both these approaches are learned from a corpus of clinical narratives. We present results using both approaches and observe that the finite state transducer approach performs performs significantly better than the dynamic programming one by 6.8% for the problem of multiple-sequence alignment.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James F Allen</author>
</authors>
<title>An interval-based representation of temporal knowledge.</title>
<date>1981</date>
<booktitle>In IJCAI,</booktitle>
<pages>221--226</pages>
<contexts>
<context position="9811" citStr="Allen, 1981" startWordPosition="1476" endWordPosition="1477">t +∞ dob +∞ N2 dob hypertensionstart N3 palpitationsstart myocardial infarctionstart episodestart +∞ admission2 MRSAstart e1 before e2 e1 overlaps e2 e1 during e2 e1 starts with e2 e1 finishes with e2 e1 equals e2 e1.start &lt; e1.stop &lt; e2.start &lt; e2.stop e1.start &lt; e2.start &lt; e1.stop &lt; e2.stop e2.start &lt; e1.start &lt; e1.stop &lt; e2.stop e1.start e2.start - &lt; e1.stop e2.stop &lt; e2.start &lt; e1.start &lt; e1.stop - e2.stop e1.start - e2.start &lt; e1.stop e2.stop - &lt; denotes before &gt; denotes after ~ denotes simultaneous Figure 1: Medical event start / stop representation mapped to Allen’s temporal relations (Allen, 1981). Temporal ordering of event starts and stops using {before, after, simultaenous} (shown on the right) allows us learn temporal relations between the medical events (shown on the left). e1start = e2start and e1stop = e2stop, when e1 and e2 corefer. patient.1 Often, for chronic ailments like hypertension, we would only associate a start with the medical event and set the stop to +oo. The start of hypertension may be associated with the temporal expression history of in the narrative. This, when considered along with the admission date, allows us to relatively order hypertension with respect to </context>
<context position="11232" citStr="Allen, 1981" startWordPosition="1714" endWordPosition="1715"> in the narrative text. Further, the narrative may state that “he continued to have chest pain on admission, but currently he is chest pain free”; this may be used to infer the relative stop of chest pain. Medical events may also be instantaneous, for e.g., injected with antibiotic. Such events are represented with the start and stop as being the same. Temporal relations exist between the start and stop of events as shown in Figure 1. Learning temporal relations before, after and simultaneous between the medical event starts and stops corresponds to learning all of Allen’s temporal relations (Allen, 1981) between the medical events. Following our previous work (Raghavan et al., 2012c), such a representation allows us to temporally order the event starts and stops within each clinical narrative by learning to rank them in relative order of time. The problem definition is as follows: 1Patient date of birth, admission/ discharge date are usually available in the metadata associated with a clinical narrative. Figure 2: Given temporally ordered medical event sequences, N1, N2, N3, we address the task of combining events across these sequences by merging or ordering them to create a single comprehen</context>
<context position="13241" citStr="Allen, 1981" startWordPosition="2027" endWordPosition="2028">undsstart}. The goal of multiple sequence alignment is to find an alignment that maximizes some overall alignment score. Thus, in order to align event sequences, we need to compute scores corresponding to cross-narrative medical event coreference resolution and cross-narrative temporal relations. 4 Cross-Narrative Coreference Resolution and Temporal Relation Learning The first approach to learning a temporal ordering of medical events across all clinical narratives is to consider all pairs of events across all narratives and learn to classify them as sharing one of Allen’s temporal relations (Allen, 1981) using a single learning model. Alternatively, a ranking ap1000 proach, similar to the one used to generate intranarrative temporal ordering, can also be extended to the cross-narrative case. However, the features related to narrative structure and relative and implicit temporal expressions used for temporal ordering within a clinical narrative may not be applicable across narratives. For instance, a history and physical report may have sections like “past medical history”, “history of present illness”, “assessment and plan”, and a certain logical pattern to the flow of text within and across </context>
</contexts>
<marker>Allen, 1981</marker>
<rawString>James F. Allen. 1981. An interval-based representation of temporal knowledge. In IJCAI, pages 221– 226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Sentence fusion for multidocument news summarization.</title>
<date>2005</date>
<journal>Comput. Linguist.,</journal>
<volume>31</volume>
<issue>3</issue>
<contexts>
<context position="6409" citStr="Barzilay and McKeown (2005)" startWordPosition="952" endWordPosition="956">ork in rule-based algorithms (Zhou et al., 2006) and machine learning (Roberts et al., 2008) applied to temporal relations between medical events in clinical text. Clinical narratives are written in a distinct sub-language with domain specific terminology and temporal characteristics, making them markedly different from newswire text. There is limited prior work in learning relations across documents. Ji and Grishman (2008) extended the one sense per discourse idea (Yarowsky, 1995) to multiple topically related documents and propagate consistent event arguments across sentences and documents. Barzilay and McKeown (2005) propose a text-to-text generation technique for synthesizing common information across documents using sentence fusion. This involves multisequence dependency tree alignment to identify phrases conveying similar information and statistical generation to combine common phrases into a sentence. Along with syntactic features, they combine knowledge from resources like WordNet to find similar sentences. In case of clinical narratives and medical event alignment, the objective is to identify a unique sequence of temporally ordered medical events from across longitudinal clinical data. To the best </context>
</contexts>
<marker>Barzilay, McKeown, 2005</marker>
<rawString>Regina Barzilay and Kathleen R. McKeown. 2005. Sentence fusion for multidocument news summarization. Comput. Linguist., 31(3):297–328, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Noemie Elhadad</author>
<author>Kathleen McKeown</author>
</authors>
<title>Inferring strategies for sentence ordering in multidocument summarization.</title>
<date>2002</date>
<journal>Journal of Artificial Intelligence Research (JAIR),</journal>
<pages>17--35</pages>
<contexts>
<context position="4502" citStr="Barzilay et al., 2002" startWordPosition="656" endWordPosition="659">oding. Moreover, we demonstrate that this method can be used for more accurate multiple sequence alignment when compared to 998 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 998–1008, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics dynamic programming or other ILP-based methods proposed in literature. 2 Related Work In the areas of summarization and text-to-text generation, there has been prior work on several ordering strategies to order pieces of information extracted from different input documents (Barzilay et al., 2002, Lapata, 2003, Bollegala et al., 2010). In this paper, we focus on temporal ordering of information, as discussed next. Recent state-of-the art research has focused on the problem of temporal relation learning within the same document, and in many cases within the same sentence (Mani et al., 2006, Verhagen et al., 2009, Lapata and Lascarides, 2011). Chambers and Jurafsky (2009) describe a process to induce a partially ordered set of events related by a common protagonist by using an unsupervised distributional method to learn relations between events sharing coreferring arguments, followed by</context>
</contexts>
<marker>Barzilay, Elhadad, McKeown, 2002</marker>
<rawString>Regina Barzilay, Noemie Elhadad, and Kathleen McKeown. 2002. Inferring strategies for sentence ordering in multidocument summarization. Journal of Artificial Intelligence Research (JAIR), 17:35–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danushka Bollegala</author>
<author>Naoaki Okazaki</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>A bottom-up approach to sentence ordering for multi-document summarization.</title>
<date>2010</date>
<journal>Information processing &amp; management,</journal>
<volume>46</volume>
<issue>1</issue>
<contexts>
<context position="4541" citStr="Bollegala et al., 2010" startWordPosition="662" endWordPosition="665">this method can be used for more accurate multiple sequence alignment when compared to 998 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 998–1008, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics dynamic programming or other ILP-based methods proposed in literature. 2 Related Work In the areas of summarization and text-to-text generation, there has been prior work on several ordering strategies to order pieces of information extracted from different input documents (Barzilay et al., 2002, Lapata, 2003, Bollegala et al., 2010). In this paper, we focus on temporal ordering of information, as discussed next. Recent state-of-the art research has focused on the problem of temporal relation learning within the same document, and in many cases within the same sentence (Mani et al., 2006, Verhagen et al., 2009, Lapata and Lascarides, 2011). Chambers and Jurafsky (2009) describe a process to induce a partially ordered set of events related by a common protagonist by using an unsupervised distributional method to learn relations between events sharing coreferring arguments, followed by temporal classification to induce part</context>
</contexts>
<marker>Bollegala, Okazaki, Ishizuka, 2010</marker>
<rawString>Danushka Bollegala, Naoaki Okazaki, and Mitsuru Ishizuka. 2010. A bottom-up approach to sentence ordering for multi-document summarization. Information processing &amp; management, 46(1):89–109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Bramsen</author>
<author>Pawan Deshpande</author>
<author>Yoong Keok Lee</author>
<author>Regina Barzilay</author>
</authors>
<title>Inducing temporal graphs.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, EMNLP ’06,</booktitle>
<pages>189--198</pages>
<contexts>
<context position="2042" citStr="Bramsen et al., 2006" startWordPosition="287" endWordPosition="290">narrative temporal relation ordering is a challenging task as it is difficult to learn temporal relations among medical events which are not part of the logically coherent discourse of a single narrative. Resolving crossnarrative temporal relationships between medical events is essential to the task of generating an event timeline from across unstructured clinical narratives such as admission notes, radiology reports, history and physical reports and discharge summaries. Such a timeline has multiple applications in clinical trial recruitment (Luo et al., 2011), medical document summarization (Bramsen et al., 2006, Reichert et al., 2010) and clinical decision making (Demner-Fushman et al., 2009). Given multiple temporally ordered medical event sequences generated from each clinical narrative in a patient record, how can we combine the events to create a timeline across all the narratives? The tendency to copy-paste text and summarize past information in newly generated clinical narratives leads to multiple mentions of the same medical event across narratives (Cohen et al., 2013). These cross-narrative coreferences act as important anchors for reasoning with information across narratives. We leverage cr</context>
</contexts>
<marker>Bramsen, Deshpande, Lee, Barzilay, 2006</marker>
<rawString>Philip Bramsen, Pawan Deshpande, Yoong Keok Lee, and Regina Barzilay. 2006. Inducing temporal graphs. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, EMNLP ’06, pages 189–198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Dan Jurafsky</author>
</authors>
<title>Unsupervised learning of narrative schemas and their participants.</title>
<date>2009</date>
<booktitle>In ACL/AFNLP,</booktitle>
<pages>602--610</pages>
<contexts>
<context position="4883" citStr="Chambers and Jurafsky (2009)" startWordPosition="717" endWordPosition="720">oposed in literature. 2 Related Work In the areas of summarization and text-to-text generation, there has been prior work on several ordering strategies to order pieces of information extracted from different input documents (Barzilay et al., 2002, Lapata, 2003, Bollegala et al., 2010). In this paper, we focus on temporal ordering of information, as discussed next. Recent state-of-the art research has focused on the problem of temporal relation learning within the same document, and in many cases within the same sentence (Mani et al., 2006, Verhagen et al., 2009, Lapata and Lascarides, 2011). Chambers and Jurafsky (2009) describe a process to induce a partially ordered set of events related by a common protagonist by using an unsupervised distributional method to learn relations between events sharing coreferring arguments, followed by temporal classification to induce partial order. The task was carried out on the Timebank newswire corpus, but was limited to an intra-document setting. More recently, (Do et al., 2012) proposed an ILP-based method to combine the outputs of an event-interval and an event-event classifier for timeline construction on the ACE 2005 corpus. However, this approach is also restricted</context>
</contexts>
<marker>Chambers, Jurafsky, 2009</marker>
<rawString>Nathanael Chambers and Dan Jurafsky. 2009. Unsupervised learning of narrative schemas and their participants. In ACL/AFNLP, pages 602–610.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raphael Cohen</author>
<author>Michael Elhadad</author>
<author>No´emie Elhadad</author>
</authors>
<title>Redundancy in electronic health record corpora: analysis, impact on text mining performance and mitigation strategies.</title>
<date>2013</date>
<journal>BMC bioinformatics,</journal>
<volume>14</volume>
<issue>1</issue>
<contexts>
<context position="2516" citStr="Cohen et al., 2013" startWordPosition="360" endWordPosition="363"> Such a timeline has multiple applications in clinical trial recruitment (Luo et al., 2011), medical document summarization (Bramsen et al., 2006, Reichert et al., 2010) and clinical decision making (Demner-Fushman et al., 2009). Given multiple temporally ordered medical event sequences generated from each clinical narrative in a patient record, how can we combine the events to create a timeline across all the narratives? The tendency to copy-paste text and summarize past information in newly generated clinical narratives leads to multiple mentions of the same medical event across narratives (Cohen et al., 2013). These cross-narrative coreferences act as important anchors for reasoning with information across narratives. We leverage crossnarrative coreference information along with confident cross-narrative temporal relation predictions and learn to align and temporally order medical event sequences across longitudinal clinical narratives. We model the problem as a sequence alignment task and propose solving this using two approaches. First, we use weighted finite state machines to represent medical events sequences, thus enabling composition and search to obtain the most probable combined sequence o</context>
</contexts>
<marker>Cohen, Elhadad, Elhadad, 2013</marker>
<rawString>Raphael Cohen, Michael Elhadad, and No´emie Elhadad. 2013. Redundancy in electronic health record corpora: analysis, impact on text mining performance and mitigation strategies. BMC bioinformatics, 14(1):10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dina Demner-Fushman</author>
<author>Wendy Webber Chapman</author>
<author>Clement J McDonald</author>
</authors>
<title>What can natural language processing do for clinical decision support?</title>
<date>2009</date>
<journal>Journal of Biomedical Informatics,</journal>
<volume>42</volume>
<issue>5</issue>
<contexts>
<context position="2125" citStr="Demner-Fushman et al., 2009" startWordPosition="299" endWordPosition="302">lt to learn temporal relations among medical events which are not part of the logically coherent discourse of a single narrative. Resolving crossnarrative temporal relationships between medical events is essential to the task of generating an event timeline from across unstructured clinical narratives such as admission notes, radiology reports, history and physical reports and discharge summaries. Such a timeline has multiple applications in clinical trial recruitment (Luo et al., 2011), medical document summarization (Bramsen et al., 2006, Reichert et al., 2010) and clinical decision making (Demner-Fushman et al., 2009). Given multiple temporally ordered medical event sequences generated from each clinical narrative in a patient record, how can we combine the events to create a timeline across all the narratives? The tendency to copy-paste text and summarize past information in newly generated clinical narratives leads to multiple mentions of the same medical event across narratives (Cohen et al., 2013). These cross-narrative coreferences act as important anchors for reasoning with information across narratives. We leverage crossnarrative coreference information along with confident cross-narrative temporal </context>
</contexts>
<marker>Demner-Fushman, Chapman, McDonald, 2009</marker>
<rawString>Dina Demner-Fushman, Wendy Webber Chapman, and Clement J. McDonald. 2009. What can natural language processing do for clinical decision support? Journal of Biomedical Informatics, 42(5):760–772.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Quang Xuan Do</author>
<author>Wei Lu</author>
<author>Dan Roth</author>
</authors>
<title>Joint inference for event timeline construction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLPCoNLL ’12,</booktitle>
<pages>677--687</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3478" citStr="Do et al., 2012" startWordPosition="502" endWordPosition="505">e problem as a sequence alignment task and propose solving this using two approaches. First, we use weighted finite state machines to represent medical events sequences, thus enabling composition and search to obtain the most probable combined sequence of medical events. As a contrast, we adapt dynamic programming algorithms (Needleman et al., 1970, Smith and Waterman, 1981) used to produce global and local alignments for aligning sequences of medical events across narratives. We also compare the proposed methods with an Integer Linear Programming (ILP) based method for timeline construction (Do et al., 2012). The cross-narrative coreference and temporal relation scores used in both these approaches are learned from a corpus of patient narratives from The Ohio State University Wexner Medical Center. The main contribution of this paper is a general framework that allows aligning multiple event sequences using cascaded weighted finite state transducers (WFSTs) with the help of efficient composition and decoding. Moreover, we demonstrate that this method can be used for more accurate multiple sequence alignment when compared to 998 Proceedings of the 52nd Annual Meeting of the Association for Computa</context>
<context position="5288" citStr="Do et al., 2012" startWordPosition="782" endWordPosition="785">he problem of temporal relation learning within the same document, and in many cases within the same sentence (Mani et al., 2006, Verhagen et al., 2009, Lapata and Lascarides, 2011). Chambers and Jurafsky (2009) describe a process to induce a partially ordered set of events related by a common protagonist by using an unsupervised distributional method to learn relations between events sharing coreferring arguments, followed by temporal classification to induce partial order. The task was carried out on the Timebank newswire corpus, but was limited to an intra-document setting. More recently, (Do et al., 2012) proposed an ILP-based method to combine the outputs of an event-interval and an event-event classifier for timeline construction on the ACE 2005 corpus. However, this approach is also restricted to events within documents and requires annotations for event intervals. We empirically compare our methods for timeline creation from longitudinal clinical narratives to such an ILP-based approach in Section 7. While a lot of this work has been done in the news domain, there is also some recent work in rule-based algorithms (Zhou et al., 2006) and machine learning (Roberts et al., 2008) applied to te</context>
<context position="15501" citStr="Do et al., 2012" startWordPosition="2365" endWordPosition="2368">emporal ordering. 5 Narrative Sequence Alignment for Cross-narrative Temporal Ordering Sequence alignment algorithms have been developed and popularly used in bioinformatics. However, multiple sequence alignment (MSA) has been shown to be NP complete (Wang and Jiang, 1994) and various heuristic algorithms have been proposed to solve this problem (Notredame, 2002). We propose a novel WFST-based representation that enables accurate decoding for MSA when compared to popularly used dynamic programming algorithms (Needleman et al., 1970, Smith and Waterman, 1981) or other state of the art methods (Do et al., 2012). In the problem of aligning events across multiple narrative sequences, we want to align temporally ordered medical events corresponding to clinical narratives of a patient. Unlike problems in biological sequence alignment where the symFigure 3: Score computation for aligning events across temporally ordered event sequences chest painstart = episodestart &lt; chest painstop = episodestop, where events across the sequences occur simultaneously and corefer. Figure 4: Score computation for aligning events across temporally ordered event sequences chest painstart — palpitationsstop &lt; chest painstop </context>
<context position="34340" citStr="Do et al., 2012" startWordPosition="5452" endWordPosition="5455">7 Discussion We propose and evaluate different approaches to multiple sequence alignment of medical events. 1005 Approaches to multi-alignment. We address the problem of aligning medical event sequences using a novel WFST-based framework and empirically demonstrate that it outperforms pairwise progressive alignment using dynamic programming. This is mainly because the WFST-based allows us to consider temporal constraints from across multiple sequences when performing the alignment. Moreover, it also outperforms the integer linear programming (ILP) method for timeline construction proposed in (Do et al., 2012). We implemented the proposed method that also allows combining the output of classifiers subject to some constraints. We derive intervals from event starts and stops and learn two perceptron classifiers for classifying the temporal relations between events and assigning events to intervals. The classifier probabilities are then used to solve the optimization problem using the lpsolve solver.3 We also use intra-document coreference information to resolve coreference before performing the global optimization. We observe that in case of MSA, the optimal solution using ILP is still intractable as</context>
</contexts>
<marker>Do, Lu, Roth, 2012</marker>
<rawString>Quang Xuan Do, Wei Lu, and Dan Roth. 2012. Joint inference for event timeline construction. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLPCoNLL ’12, pages 677–687. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
</authors>
<title>Refining event extraction through cross-document inference.</title>
<date>2008</date>
<booktitle>In Association for Computational Linguistics.</booktitle>
<contexts>
<context position="6209" citStr="Ji and Grishman (2008)" startWordPosition="924" endWordPosition="927">hods for timeline creation from longitudinal clinical narratives to such an ILP-based approach in Section 7. While a lot of this work has been done in the news domain, there is also some recent work in rule-based algorithms (Zhou et al., 2006) and machine learning (Roberts et al., 2008) applied to temporal relations between medical events in clinical text. Clinical narratives are written in a distinct sub-language with domain specific terminology and temporal characteristics, making them markedly different from newswire text. There is limited prior work in learning relations across documents. Ji and Grishman (2008) extended the one sense per discourse idea (Yarowsky, 1995) to multiple topically related documents and propagate consistent event arguments across sentences and documents. Barzilay and McKeown (2005) propose a text-to-text generation technique for synthesizing common information across documents using sentence fusion. This involves multisequence dependency tree alignment to identify phrases conveying similar information and statistical generation to combine common phrases into a sentence. Along with syntactic features, they combine knowledge from resources like WordNet to find similar sentenc</context>
</contexts>
<marker>Ji, Grishman, 2008</marker>
<rawString>Heng Ji and Ralph Grishman. 2008. Refining event extraction through cross-document inference. In Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cvetana Krstev</author>
<author>Dusko Vitas</author>
<author>Ivan Obradovi´c</author>
<author>Milos Utvi´c</author>
</authors>
<title>E-dictionaries and Finite-state automata for the recognition of named entities.</title>
<date>2011</date>
<booktitle>In Proceedings of the 9th International Workshop on Finite State Methods and Natural Language Processing,</booktitle>
<pages>48--56</pages>
<marker>Krstev, Vitas, Obradovi´c, Utvi´c, 2011</marker>
<rawString>Cvetana Krstev, Du&amp;quot;sko Vitas, Ivan Obradovi´c, and Milo&amp;quot;s Utvi´c. 2011. E-dictionaries and Finite-state automata for the recognition of named entities. In Proceedings of the 9th International Workshop on Finite State Methods and Natural Language Processing, pages 48–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shankar Kumar</author>
<author>William Byrne</author>
</authors>
<title>A weighted finite state transducer implementation of the alignment template model for statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology -</booktitle>
<volume>1</volume>
<pages>63--70</pages>
<contexts>
<context position="7308" citStr="Kumar and Byrne, 2003" startWordPosition="1085" endWordPosition="1088"> into a sentence. Along with syntactic features, they combine knowledge from resources like WordNet to find similar sentences. In case of clinical narratives and medical event alignment, the objective is to identify a unique sequence of temporally ordered medical events from across longitudinal clinical data. To the best of our knowledge, there is no prior work on cross-document alignment of event sequences. Multiple sequence alignment is a problem that arises in a variety of domains including gene/protein alignments in bioinformatics (Notredame, 2002), word alignments in machine translation (Kumar and Byrne, 2003), and sentence alignments for summarization (Lacatusu et al., 2004). Dynamic programming algorithms have been popularly leveraged to produce pairwise and global genetic alignments, where edit distance based metrics are used to compute the cost of insertions, deletions and substitutions. We use dynamic programming to compute the best alignment, given the temporal and coreference information between medical events across these sequences. More importantly, we propose a cascaded WFST-based framework for crossdocument temporal ordering of medical event sequences. Composition and search operations c</context>
</contexts>
<marker>Kumar, Byrne, 2003</marker>
<rawString>Shankar Kumar and William Byrne. 2003. A weighted finite state transducer implementation of the alignment template model for statistical machine translation. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Volume 1, pages 63–70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Finley Lacatusu</author>
<author>Steven J Maiorano</author>
<author>Sanda M Harabagiu</author>
</authors>
<title>Multi-document summarization using multiple-sequence alignment.</title>
<date>2004</date>
<booktitle>In LREC.</booktitle>
<contexts>
<context position="7375" citStr="Lacatusu et al., 2004" startWordPosition="1094" endWordPosition="1097">edge from resources like WordNet to find similar sentences. In case of clinical narratives and medical event alignment, the objective is to identify a unique sequence of temporally ordered medical events from across longitudinal clinical data. To the best of our knowledge, there is no prior work on cross-document alignment of event sequences. Multiple sequence alignment is a problem that arises in a variety of domains including gene/protein alignments in bioinformatics (Notredame, 2002), word alignments in machine translation (Kumar and Byrne, 2003), and sentence alignments for summarization (Lacatusu et al., 2004). Dynamic programming algorithms have been popularly leveraged to produce pairwise and global genetic alignments, where edit distance based metrics are used to compute the cost of insertions, deletions and substitutions. We use dynamic programming to compute the best alignment, given the temporal and coreference information between medical events across these sequences. More importantly, we propose a cascaded WFST-based framework for crossdocument temporal ordering of medical event sequences. Composition and search operations can be used to build a single transducer that integrates these compo</context>
</contexts>
<marker>Lacatusu, Maiorano, Harabagiu, 2004</marker>
<rawString>V Finley Lacatusu, Steven J Maiorano, and Sanda M Harabagiu. 2004. Multi-document summarization using multiple-sequence alignment. In LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
<author>Alex Lascarides</author>
</authors>
<title>Learning sentence-internal temporal relations.</title>
<date>2011</date>
<location>CoRR, abs/1110.1394.</location>
<contexts>
<context position="4853" citStr="Lapata and Lascarides, 2011" startWordPosition="713" endWordPosition="716"> or other ILP-based methods proposed in literature. 2 Related Work In the areas of summarization and text-to-text generation, there has been prior work on several ordering strategies to order pieces of information extracted from different input documents (Barzilay et al., 2002, Lapata, 2003, Bollegala et al., 2010). In this paper, we focus on temporal ordering of information, as discussed next. Recent state-of-the art research has focused on the problem of temporal relation learning within the same document, and in many cases within the same sentence (Mani et al., 2006, Verhagen et al., 2009, Lapata and Lascarides, 2011). Chambers and Jurafsky (2009) describe a process to induce a partially ordered set of events related by a common protagonist by using an unsupervised distributional method to learn relations between events sharing coreferring arguments, followed by temporal classification to induce partial order. The task was carried out on the Timebank newswire corpus, but was limited to an intra-document setting. More recently, (Do et al., 2012) proposed an ILP-based method to combine the outputs of an event-interval and an event-event classifier for timeline construction on the ACE 2005 corpus. However, th</context>
</contexts>
<marker>Lapata, Lascarides, 2011</marker>
<rawString>Mirella Lapata and Alex Lascarides. 2011. Learning sentence-internal temporal relations. CoRR, abs/1110.1394.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
</authors>
<title>Probabilistic text structuring: Experiments with sentence ordering.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1,</booktitle>
<pages>545--552</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4516" citStr="Lapata, 2003" startWordPosition="660" endWordPosition="661">onstrate that this method can be used for more accurate multiple sequence alignment when compared to 998 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 998–1008, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics dynamic programming or other ILP-based methods proposed in literature. 2 Related Work In the areas of summarization and text-to-text generation, there has been prior work on several ordering strategies to order pieces of information extracted from different input documents (Barzilay et al., 2002, Lapata, 2003, Bollegala et al., 2010). In this paper, we focus on temporal ordering of information, as discussed next. Recent state-of-the art research has focused on the problem of temporal relation learning within the same document, and in many cases within the same sentence (Mani et al., 2006, Verhagen et al., 2009, Lapata and Lascarides, 2011). Chambers and Jurafsky (2009) describe a process to induce a partially ordered set of events related by a common protagonist by using an unsupervised distributional method to learn relations between events sharing coreferring arguments, followed by temporal clas</context>
</contexts>
<marker>Lapata, 2003</marker>
<rawString>Mirella Lapata. 2003. Probabilistic text structuring: Experiments with sentence ordering. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1, pages 545– 552. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhihui Luo</author>
<author>Stephen B Johnson</author>
<author>Albert M Lai</author>
<author>Chunhua Weng</author>
</authors>
<title>Extracting temporal constraints from clinical research eligibility criteria using conditional random fields.</title>
<date>2011</date>
<booktitle>In Proc of AMIA Symposium.</booktitle>
<contexts>
<context position="1988" citStr="Luo et al., 2011" startWordPosition="280" endWordPosition="283">ations within a clinical narrative. However, cross-narrative temporal relation ordering is a challenging task as it is difficult to learn temporal relations among medical events which are not part of the logically coherent discourse of a single narrative. Resolving crossnarrative temporal relationships between medical events is essential to the task of generating an event timeline from across unstructured clinical narratives such as admission notes, radiology reports, history and physical reports and discharge summaries. Such a timeline has multiple applications in clinical trial recruitment (Luo et al., 2011), medical document summarization (Bramsen et al., 2006, Reichert et al., 2010) and clinical decision making (Demner-Fushman et al., 2009). Given multiple temporally ordered medical event sequences generated from each clinical narrative in a patient record, how can we combine the events to create a timeline across all the narratives? The tendency to copy-paste text and summarize past information in newly generated clinical narratives leads to multiple mentions of the same medical event across narratives (Cohen et al., 2013). These cross-narrative coreferences act as important anchors for reason</context>
</contexts>
<marker>Luo, Johnson, Lai, Weng, 2011</marker>
<rawString>Zhihui Luo, Stephen B. Johnson, Albert M. Lai, and Chunhua Weng. 2011. Extracting temporal constraints from clinical research eligibility criteria using conditional random fields. In Proc of AMIA Symposium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
<author>Marc Verhagen</author>
<author>Ben Wellner</author>
<author>Chong Min Lee</author>
<author>James Pustejovsky</author>
</authors>
<title>Machine learning of temporal relations.</title>
<date>2006</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="4800" citStr="Mani et al., 2006" startWordPosition="705" endWordPosition="708">putational Linguistics dynamic programming or other ILP-based methods proposed in literature. 2 Related Work In the areas of summarization and text-to-text generation, there has been prior work on several ordering strategies to order pieces of information extracted from different input documents (Barzilay et al., 2002, Lapata, 2003, Bollegala et al., 2010). In this paper, we focus on temporal ordering of information, as discussed next. Recent state-of-the art research has focused on the problem of temporal relation learning within the same document, and in many cases within the same sentence (Mani et al., 2006, Verhagen et al., 2009, Lapata and Lascarides, 2011). Chambers and Jurafsky (2009) describe a process to induce a partially ordered set of events related by a common protagonist by using an unsupervised distributional method to learn relations between events sharing coreferring arguments, followed by temporal classification to induce partial order. The task was carried out on the Timebank newswire corpus, but was limited to an intra-document setting. More recently, (Do et al., 2012) proposed an ILP-based method to combine the outputs of an event-interval and an event-event classifier for time</context>
</contexts>
<marker>Mani, Verhagen, Wellner, Lee, Pustejovsky, 2006</marker>
<rawString>Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong Min Lee, and James Pustejovsky. 2006. Machine learning of temporal relations. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
<author>Fernando CN Pereira</author>
</authors>
<title>Dynamic compilation of weighted context-free grammars.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics-Volume 2,</booktitle>
<pages>891--897</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="22931" citStr="Mohri and Pereira, 1998" startWordPosition="3601" endWordPosition="3604">.13 cocaineuse:-/0.13 cocaineuse:-/0.13 0 cocaineuse:cocaineabuse/0.9 hypertension:cocaineabuse/0.4 chestpain:cocaineabuse/0.3 1 cocaineuse:admission/0.1 hypertension:admission/0.1 chestpain:admission/0.1 2 h c all narrative chains belonging to the same patient, the composition cascade to build the final combined sequence will be as, Df = N1◦M12◦N2◦M23◦N3◦M34...◦NI, (2) where i = c or i = c + t and n is the number of medical event sequences corresponding to clinical narratives for a patient. During composition we retain intermediate paths like M23 utilizing the ability to do lazy composition (Mohri and Pereira, 1998) in order to facilitate beam search through the multi-alignment. The best hypothesis corresponds to the highest scoring path which can be obtained using shortest path algorithms like Djikstra’s algorithm. The best path corresponds to the best alignment across all medical event sequences based on the joint probability of cross-narrative medical event coreferences and temporal relations across the narrative sequences. The complexity of decoding increases exponentially with the number of narrative sequences in the composition, and exact decoding becomes infeasible. One solution to this problem is</context>
</contexts>
<marker>Mohri, Pereira, 1998</marker>
<rawString>Mehryar Mohri and Fernando CN Pereira. 1998. Dynamic compilation of weighted context-free grammars. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics-Volume 2, pages 891–897. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
<author>Fernando C N Pereira</author>
<author>Michael Riley</author>
</authors>
<title>The design principles of a weighted finite-state transducer library.</title>
<date>2000</date>
<journal>Theoretical Computer Science,</journal>
<volume>231</volume>
<issue>1</issue>
<contexts>
<context position="8087" citStr="Mohri et al., 2000" startWordPosition="1199" endWordPosition="1202"> genetic alignments, where edit distance based metrics are used to compute the cost of insertions, deletions and substitutions. We use dynamic programming to compute the best alignment, given the temporal and coreference information between medical events across these sequences. More importantly, we propose a cascaded WFST-based framework for crossdocument temporal ordering of medical event sequences. Composition and search operations can be used to build a single transducer that integrates these components, directly mapping from input states to desired outputs, and obtain the best alignment (Mohri et al., 2000). In natural language processing, WFSTs have seen varied applications in machine translation (Kumar and Byrne, 2003), morphology (Sproat, 2006), named entity recognition (Krstev et al., 2011) and biological sequence alignment / generation (Whelan et al., 2010) among others. We demonstrate that the WFST-based approach outperforms popularly used dynamic programming algorithms for multiple sequence alignment. 3 Problem Description Medical events are temporally-associated concepts in clinical text that describe a medical condition affecting the patient’s health, or procedures performed on a patien</context>
</contexts>
<marker>Mohri, Pereira, Riley, 2000</marker>
<rawString>Mehryar Mohri, Fernando C. N. Pereira, and Michael Riley. 2000. The design principles of a weighted finite-state transducer library. Theoretical Computer Science, 231(1):17–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
<author>Fernando Pereira</author>
<author>Michael Riley</author>
</authors>
<title>Weighted automata in text and speech processing.</title>
<date>2005</date>
<location>CoRR, abs/cs/0503077.</location>
<contexts>
<context position="19197" citStr="Mohri et al., 2005" startWordPosition="2976" endWordPosition="2979"> and do not corefer as illustrated in Figure 5. In this case, the joint score considers the probability of the temporal relation before and no coreference. Thus, the coreference and temporal relation scores can be leveraged for aligning sequences of medical events. These scores are used in both the WFSTbased representation and decoding, as well as for dynamic programming. 5.2 Alignment using a Weighted Finite State Representation A weighted finite-state transducer (WFST) is an automaton in which each transition between states is associated with an input symbol, an output symbol, and a weight (Mohri et al., 2005). WFSTs can be used to efficiently represent and combine sequences of medical events based coreference and temporal relation information. The WFST representation gives us the ability to talk about the global joint probability derived from coreference and temporal relation scores described in Section 5.1. It allows us to build a weighted lattice of sequences that can be searched for the most probable sequence of medical events from across all clinical narratives of a patient. We use unweighted FSAs to represent the input described in Section 3, i.e. temporally ordered sequences of medical event</context>
<context position="24170" citStr="Mohri et al., 2005" startWordPosition="3796" endWordPosition="3799"> greedily pairwise, starting from the most recent medical event sequences, finding the best path, and iteratively moving on to the next sequence, and proceeding until the oldest medical event sequence. The disadvantage of such a method is that it does not take into account constraints between medical events across multiple event sequences and may lead to a less accurate solution. An alternative method is to use lazy composition to perform more efficient composition as it allows practical memory usage. We also use beam search to make for an efficient approximation to the best-path computation (Mohri et al., 2005). This allows accommodating constraints from across multiple sequences and generates a more accurate best path. Thus, this method generates more accurate alignments when we have more than two sequences to be aligned. 1003 For instance, instance say a, b E N1, x, y E N2, and m, n E N3 are temporally medical event sequences corresponding to narratives N1, N2 and N3. Based on the learned pairwise temporal relations, if we have the following constraints a &lt; x, m &gt; x, m &lt; a. Aligning N1 and N2 greedily pairwise may give us the best combined sequence as a, x, b, y E N12. Now in aligning N12 with N3,</context>
</contexts>
<marker>Mohri, Pereira, Riley, 2005</marker>
<rawString>Mehryar Mohri, Fernando Pereira, and Michael Riley. 2005. Weighted automata in text and speech processing. CoRR, abs/cs/0503077.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S B Needleman</author>
<author>C D Wunsch</author>
</authors>
<title>A general method applicable to the search for similarities in the amino acid sequence of two proteins.</title>
<date>1970</date>
<journal>Journal of molecular biology,</journal>
<volume>48</volume>
<issue>3</issue>
<marker>Needleman, Wunsch, 1970</marker>
<rawString>S.B. Needleman, C.D. Wunsch, et al. 1970. A general method applicable to the search for similarities in the amino acid sequence of two proteins. Journal of molecular biology, 48(3):443–453.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C´edric Notredame</author>
</authors>
<title>Recent progress in multiple sequence alignment: a survey.</title>
<date>2002</date>
<journal>Pharmacogenomics,</journal>
<volume>3</volume>
<issue>1</issue>
<contexts>
<context position="7244" citStr="Notredame, 2002" startWordPosition="1077" endWordPosition="1078">ation and statistical generation to combine common phrases into a sentence. Along with syntactic features, they combine knowledge from resources like WordNet to find similar sentences. In case of clinical narratives and medical event alignment, the objective is to identify a unique sequence of temporally ordered medical events from across longitudinal clinical data. To the best of our knowledge, there is no prior work on cross-document alignment of event sequences. Multiple sequence alignment is a problem that arises in a variety of domains including gene/protein alignments in bioinformatics (Notredame, 2002), word alignments in machine translation (Kumar and Byrne, 2003), and sentence alignments for summarization (Lacatusu et al., 2004). Dynamic programming algorithms have been popularly leveraged to produce pairwise and global genetic alignments, where edit distance based metrics are used to compute the cost of insertions, deletions and substitutions. We use dynamic programming to compute the best alignment, given the temporal and coreference information between medical events across these sequences. More importantly, we propose a cascaded WFST-based framework for crossdocument temporal ordering</context>
<context position="15250" citStr="Notredame, 2002" startWordPosition="2326" endWordPosition="2327">cross narratives as sharing temporal relations {before, after, overlaps}. The learned cross-narrative coreference predictions can then be used along with confident temporal relation predictions to derive a joint probability to enable cross-narrative temporal ordering. 5 Narrative Sequence Alignment for Cross-narrative Temporal Ordering Sequence alignment algorithms have been developed and popularly used in bioinformatics. However, multiple sequence alignment (MSA) has been shown to be NP complete (Wang and Jiang, 1994) and various heuristic algorithms have been proposed to solve this problem (Notredame, 2002). We propose a novel WFST-based representation that enables accurate decoding for MSA when compared to popularly used dynamic programming algorithms (Needleman et al., 1970, Smith and Waterman, 1981) or other state of the art methods (Do et al., 2012). In the problem of aligning events across multiple narrative sequences, we want to align temporally ordered medical events corresponding to clinical narratives of a patient. Unlike problems in biological sequence alignment where the symFigure 3: Score computation for aligning events across temporally ordered event sequences chest painstart = epis</context>
</contexts>
<marker>Notredame, 2002</marker>
<rawString>C´edric Notredame. 2002. Recent progress in multiple sequence alignment: a survey. Pharmacogenomics, 3(1):131–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preethi Raghavan</author>
<author>Eric Fosler-Lussier</author>
<author>Albert M Lai</author>
</authors>
<title>Exploring semi-supervised coreference resolution of medical concepts using semantic and temporal features.</title>
<date>2012</date>
<booktitle>In North American Association for Computational Linguistics Annual Meeting - Human Language Technologies Conference. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="11311" citStr="Raghavan et al., 2012" startWordPosition="1724" endWordPosition="1727">inued to have chest pain on admission, but currently he is chest pain free”; this may be used to infer the relative stop of chest pain. Medical events may also be instantaneous, for e.g., injected with antibiotic. Such events are represented with the start and stop as being the same. Temporal relations exist between the start and stop of events as shown in Figure 1. Learning temporal relations before, after and simultaneous between the medical event starts and stops corresponds to learning all of Allen’s temporal relations (Allen, 1981) between the medical events. Following our previous work (Raghavan et al., 2012c), such a representation allows us to temporally order the event starts and stops within each clinical narrative by learning to rank them in relative order of time. The problem definition is as follows: 1Patient date of birth, admission/ discharge date are usually available in the metadata associated with a clinical narrative. Figure 2: Given temporally ordered medical event sequences, N1, N2, N3, we address the task of combining events across these sequences by merging or ordering them to create a single comprehensive timeline. Input: Sequences of temporally ordered medical event starts and </context>
<context position="14542" citStr="Raghavan et al., 2012" startWordPosition="2224" endWordPosition="2227"> from the context around an event mention. The absence of such features in the cross-narrative case does not allow such a model to generate accurate temporal relation predictions. Thus, for use in our sequence alignment models, we learn two independent classifiers for medical event coreference and temporal relation learning across narratives. We train a classifier to resolve cross-narrative coreferences by extracting semantic and temporal relatedness feature sets for each pair of medical concepts. Extracting these feature sets helps us train a classifier to predict medical event coreferences (Raghavan et al., 2012a). Another classifier is then trained to classify pairs of medical event starts and stops across narratives as sharing temporal relations {before, after, overlaps}. The learned cross-narrative coreference predictions can then be used along with confident temporal relation predictions to derive a joint probability to enable cross-narrative temporal ordering. 5 Narrative Sequence Alignment for Cross-narrative Temporal Ordering Sequence alignment algorithms have been developed and popularly used in bioinformatics. However, multiple sequence alignment (MSA) has been shown to be NP complete (Wang </context>
<context position="28717" citStr="Raghavan et al., 2012" startWordPosition="4586" endWordPosition="4589">ards the oldest narrative. 6 Experiments and Evaluation Corpus Description. The corpus consists of a dataset of clinical narratives obtained from the [redacted] medical center. The corpus has a total of 2060 patients, and 100704 clinical narratives. We gathered a gold standard set of seven patients (80 clinical narratives overall) with manual annotation of all medical events mentioned in the narratives, coreferences, and medical event sequence information. The annotation agreement across annotators is high, with 89.5% agreement corresponding to inter-annotator Cohen’s kappa statistic of 0.86 (Raghavan et al., 2012b). The types of clinical narratives included 27 discharge summaries, 30 history and physical reports, 15 radiology reports and 8 pathology reports. The distribution of the number of medical event sequences and unique medical events across patients is shown in Table 1. The annotated dataset is used to crossvalidate and train our coreference and temporal relation learning models and to evaluate our crossnarrative medical event timeline. 1004 p1 p2 p3 p4 p5 p6 p7 No. of Narrative Sequences 5 9 20 13 8 10 15 No. of Medical events 68 90 119 82 79 72 95 % Accuracy % Avg. WFST-framework (lazy compos</context>
<context position="30963" citStr="Raghavan et al., 2012" startWordPosition="4937" endWordPosition="4941"> output timeline to evaluate is the highest scoring candidate hypothesis derived as described above. Accuracy of the timeline is calculated as the number of transformations required to obtain the reference sequence in the annotated gold-standard from the one generated by our system. Transformations are measured in terms of the minimum edit distance, insertions, deletions, and substitutions of medical events. Experiments and Results. We first temporally order medical events within each clinical narrative by learning to rank them in relative order of occurence as described in our previous work (Raghavan et al., 2012c). The overall accuracy of ranking medical events using leave-one-out cross validation is 82.1%. The resulting medical event sequences serve as the input to the problem of crossnarrative sequence alignment. The cross-narrative coreference and temporal relation pairwise classification models described in Section 4 are trained using a Maximum entropy classifier. The coreference resolution performs with 71.5% precision and 82.3% recall. The temporal relation classifier performs with 60.2% precision and 76.3% recall. The learned pairwise coreference and temporal relation probabilities are now use</context>
<context position="35579" citStr="Raghavan et al., 2012" startWordPosition="5635" endWordPosition="5638">straints increases exponentially with the number of sequences. Aligning pairwise iteratively gives us an overall average accuracy of 68.2% similar to dynamic programming. While this is comparable to the dynamic programming performance, the WFST-based method significantly outperforms this in case of multialignments for cross-narrative temporal ordering. Performance and error analysis. We perform multi-alignments over medical event sequences for a patient, where each sequence corresponds to temporally ordered medical events in a clinical narrative generated using the ranking model described in (Raghavan et al., 2012c). The accuracy of intra-narrative temporal ordering is 82.1%. The errors in performing this intra-narrative ordering may propagate to the cross-narrative model resulting in reduced accuracy. This may be addressed by considering n-best temporally ordered medical event sequences, generated by the ranking process, and aligning the n-best sequences using the WFST-based framework. This could be feasible as, practically, the WFST-based method for multialignment takes only a few secs to align a pair of medical event sequences with average length 40. The accuracy of alignments across multiple medica</context>
</contexts>
<marker>Raghavan, Fosler-Lussier, Lai, 2012</marker>
<rawString>Preethi Raghavan, Eric Fosler-Lussier, and Albert M. Lai. 2012a. Exploring semi-supervised coreference resolution of medical concepts using semantic and temporal features. In North American Association for Computational Linguistics Annual Meeting - Human Language Technologies Conference. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preethi Raghavan</author>
<author>Eric Fosler-Lussier</author>
<author>Albert M Lai</author>
</authors>
<title>Inter-annotator reliability of medical events, coreferences and temporal relations in clinical narratives by annotators with varying levels of clinical expertise.</title>
<date>2012</date>
<booktitle>In To appear in Proceedings of the American Medical Informatics</booktitle>
<publisher>Association. American Medical Informatics Association.</publisher>
<contexts>
<context position="11311" citStr="Raghavan et al., 2012" startWordPosition="1724" endWordPosition="1727">inued to have chest pain on admission, but currently he is chest pain free”; this may be used to infer the relative stop of chest pain. Medical events may also be instantaneous, for e.g., injected with antibiotic. Such events are represented with the start and stop as being the same. Temporal relations exist between the start and stop of events as shown in Figure 1. Learning temporal relations before, after and simultaneous between the medical event starts and stops corresponds to learning all of Allen’s temporal relations (Allen, 1981) between the medical events. Following our previous work (Raghavan et al., 2012c), such a representation allows us to temporally order the event starts and stops within each clinical narrative by learning to rank them in relative order of time. The problem definition is as follows: 1Patient date of birth, admission/ discharge date are usually available in the metadata associated with a clinical narrative. Figure 2: Given temporally ordered medical event sequences, N1, N2, N3, we address the task of combining events across these sequences by merging or ordering them to create a single comprehensive timeline. Input: Sequences of temporally ordered medical event starts and </context>
<context position="14542" citStr="Raghavan et al., 2012" startWordPosition="2224" endWordPosition="2227"> from the context around an event mention. The absence of such features in the cross-narrative case does not allow such a model to generate accurate temporal relation predictions. Thus, for use in our sequence alignment models, we learn two independent classifiers for medical event coreference and temporal relation learning across narratives. We train a classifier to resolve cross-narrative coreferences by extracting semantic and temporal relatedness feature sets for each pair of medical concepts. Extracting these feature sets helps us train a classifier to predict medical event coreferences (Raghavan et al., 2012a). Another classifier is then trained to classify pairs of medical event starts and stops across narratives as sharing temporal relations {before, after, overlaps}. The learned cross-narrative coreference predictions can then be used along with confident temporal relation predictions to derive a joint probability to enable cross-narrative temporal ordering. 5 Narrative Sequence Alignment for Cross-narrative Temporal Ordering Sequence alignment algorithms have been developed and popularly used in bioinformatics. However, multiple sequence alignment (MSA) has been shown to be NP complete (Wang </context>
<context position="28717" citStr="Raghavan et al., 2012" startWordPosition="4586" endWordPosition="4589">ards the oldest narrative. 6 Experiments and Evaluation Corpus Description. The corpus consists of a dataset of clinical narratives obtained from the [redacted] medical center. The corpus has a total of 2060 patients, and 100704 clinical narratives. We gathered a gold standard set of seven patients (80 clinical narratives overall) with manual annotation of all medical events mentioned in the narratives, coreferences, and medical event sequence information. The annotation agreement across annotators is high, with 89.5% agreement corresponding to inter-annotator Cohen’s kappa statistic of 0.86 (Raghavan et al., 2012b). The types of clinical narratives included 27 discharge summaries, 30 history and physical reports, 15 radiology reports and 8 pathology reports. The distribution of the number of medical event sequences and unique medical events across patients is shown in Table 1. The annotated dataset is used to crossvalidate and train our coreference and temporal relation learning models and to evaluate our crossnarrative medical event timeline. 1004 p1 p2 p3 p4 p5 p6 p7 No. of Narrative Sequences 5 9 20 13 8 10 15 No. of Medical events 68 90 119 82 79 72 95 % Accuracy % Avg. WFST-framework (lazy compos</context>
<context position="30963" citStr="Raghavan et al., 2012" startWordPosition="4937" endWordPosition="4941"> output timeline to evaluate is the highest scoring candidate hypothesis derived as described above. Accuracy of the timeline is calculated as the number of transformations required to obtain the reference sequence in the annotated gold-standard from the one generated by our system. Transformations are measured in terms of the minimum edit distance, insertions, deletions, and substitutions of medical events. Experiments and Results. We first temporally order medical events within each clinical narrative by learning to rank them in relative order of occurence as described in our previous work (Raghavan et al., 2012c). The overall accuracy of ranking medical events using leave-one-out cross validation is 82.1%. The resulting medical event sequences serve as the input to the problem of crossnarrative sequence alignment. The cross-narrative coreference and temporal relation pairwise classification models described in Section 4 are trained using a Maximum entropy classifier. The coreference resolution performs with 71.5% precision and 82.3% recall. The temporal relation classifier performs with 60.2% precision and 76.3% recall. The learned pairwise coreference and temporal relation probabilities are now use</context>
<context position="35579" citStr="Raghavan et al., 2012" startWordPosition="5635" endWordPosition="5638">straints increases exponentially with the number of sequences. Aligning pairwise iteratively gives us an overall average accuracy of 68.2% similar to dynamic programming. While this is comparable to the dynamic programming performance, the WFST-based method significantly outperforms this in case of multialignments for cross-narrative temporal ordering. Performance and error analysis. We perform multi-alignments over medical event sequences for a patient, where each sequence corresponds to temporally ordered medical events in a clinical narrative generated using the ranking model described in (Raghavan et al., 2012c). The accuracy of intra-narrative temporal ordering is 82.1%. The errors in performing this intra-narrative ordering may propagate to the cross-narrative model resulting in reduced accuracy. This may be addressed by considering n-best temporally ordered medical event sequences, generated by the ranking process, and aligning the n-best sequences using the WFST-based framework. This could be feasible as, practically, the WFST-based method for multialignment takes only a few secs to align a pair of medical event sequences with average length 40. The accuracy of alignments across multiple medica</context>
</contexts>
<marker>Raghavan, Fosler-Lussier, Lai, 2012</marker>
<rawString>Preethi Raghavan, Eric Fosler-Lussier, and Albert M. Lai. 2012b. Inter-annotator reliability of medical events, coreferences and temporal relations in clinical narratives by annotators with varying levels of clinical expertise. In To appear in Proceedings of the American Medical Informatics Association. American Medical Informatics Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preethi Raghavan</author>
<author>Eric Fosler-Lussier</author>
<author>Albert M Lai</author>
</authors>
<title>Learning to temporally order medical events in clinical text.</title>
<date>2012</date>
<booktitle>In ACL short paper. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="11311" citStr="Raghavan et al., 2012" startWordPosition="1724" endWordPosition="1727">inued to have chest pain on admission, but currently he is chest pain free”; this may be used to infer the relative stop of chest pain. Medical events may also be instantaneous, for e.g., injected with antibiotic. Such events are represented with the start and stop as being the same. Temporal relations exist between the start and stop of events as shown in Figure 1. Learning temporal relations before, after and simultaneous between the medical event starts and stops corresponds to learning all of Allen’s temporal relations (Allen, 1981) between the medical events. Following our previous work (Raghavan et al., 2012c), such a representation allows us to temporally order the event starts and stops within each clinical narrative by learning to rank them in relative order of time. The problem definition is as follows: 1Patient date of birth, admission/ discharge date are usually available in the metadata associated with a clinical narrative. Figure 2: Given temporally ordered medical event sequences, N1, N2, N3, we address the task of combining events across these sequences by merging or ordering them to create a single comprehensive timeline. Input: Sequences of temporally ordered medical event starts and </context>
<context position="14542" citStr="Raghavan et al., 2012" startWordPosition="2224" endWordPosition="2227"> from the context around an event mention. The absence of such features in the cross-narrative case does not allow such a model to generate accurate temporal relation predictions. Thus, for use in our sequence alignment models, we learn two independent classifiers for medical event coreference and temporal relation learning across narratives. We train a classifier to resolve cross-narrative coreferences by extracting semantic and temporal relatedness feature sets for each pair of medical concepts. Extracting these feature sets helps us train a classifier to predict medical event coreferences (Raghavan et al., 2012a). Another classifier is then trained to classify pairs of medical event starts and stops across narratives as sharing temporal relations {before, after, overlaps}. The learned cross-narrative coreference predictions can then be used along with confident temporal relation predictions to derive a joint probability to enable cross-narrative temporal ordering. 5 Narrative Sequence Alignment for Cross-narrative Temporal Ordering Sequence alignment algorithms have been developed and popularly used in bioinformatics. However, multiple sequence alignment (MSA) has been shown to be NP complete (Wang </context>
<context position="28717" citStr="Raghavan et al., 2012" startWordPosition="4586" endWordPosition="4589">ards the oldest narrative. 6 Experiments and Evaluation Corpus Description. The corpus consists of a dataset of clinical narratives obtained from the [redacted] medical center. The corpus has a total of 2060 patients, and 100704 clinical narratives. We gathered a gold standard set of seven patients (80 clinical narratives overall) with manual annotation of all medical events mentioned in the narratives, coreferences, and medical event sequence information. The annotation agreement across annotators is high, with 89.5% agreement corresponding to inter-annotator Cohen’s kappa statistic of 0.86 (Raghavan et al., 2012b). The types of clinical narratives included 27 discharge summaries, 30 history and physical reports, 15 radiology reports and 8 pathology reports. The distribution of the number of medical event sequences and unique medical events across patients is shown in Table 1. The annotated dataset is used to crossvalidate and train our coreference and temporal relation learning models and to evaluate our crossnarrative medical event timeline. 1004 p1 p2 p3 p4 p5 p6 p7 No. of Narrative Sequences 5 9 20 13 8 10 15 No. of Medical events 68 90 119 82 79 72 95 % Accuracy % Avg. WFST-framework (lazy compos</context>
<context position="30963" citStr="Raghavan et al., 2012" startWordPosition="4937" endWordPosition="4941"> output timeline to evaluate is the highest scoring candidate hypothesis derived as described above. Accuracy of the timeline is calculated as the number of transformations required to obtain the reference sequence in the annotated gold-standard from the one generated by our system. Transformations are measured in terms of the minimum edit distance, insertions, deletions, and substitutions of medical events. Experiments and Results. We first temporally order medical events within each clinical narrative by learning to rank them in relative order of occurence as described in our previous work (Raghavan et al., 2012c). The overall accuracy of ranking medical events using leave-one-out cross validation is 82.1%. The resulting medical event sequences serve as the input to the problem of crossnarrative sequence alignment. The cross-narrative coreference and temporal relation pairwise classification models described in Section 4 are trained using a Maximum entropy classifier. The coreference resolution performs with 71.5% precision and 82.3% recall. The temporal relation classifier performs with 60.2% precision and 76.3% recall. The learned pairwise coreference and temporal relation probabilities are now use</context>
<context position="35579" citStr="Raghavan et al., 2012" startWordPosition="5635" endWordPosition="5638">straints increases exponentially with the number of sequences. Aligning pairwise iteratively gives us an overall average accuracy of 68.2% similar to dynamic programming. While this is comparable to the dynamic programming performance, the WFST-based method significantly outperforms this in case of multialignments for cross-narrative temporal ordering. Performance and error analysis. We perform multi-alignments over medical event sequences for a patient, where each sequence corresponds to temporally ordered medical events in a clinical narrative generated using the ranking model described in (Raghavan et al., 2012c). The accuracy of intra-narrative temporal ordering is 82.1%. The errors in performing this intra-narrative ordering may propagate to the cross-narrative model resulting in reduced accuracy. This may be addressed by considering n-best temporally ordered medical event sequences, generated by the ranking process, and aligning the n-best sequences using the WFST-based framework. This could be feasible as, practically, the WFST-based method for multialignment takes only a few secs to align a pair of medical event sequences with average length 40. The accuracy of alignments across multiple medica</context>
</contexts>
<marker>Raghavan, Fosler-Lussier, Lai, 2012</marker>
<rawString>Preethi Raghavan, Eric Fosler-Lussier, and Albert M. Lai. 2012c. Learning to temporally order medical events in clinical text. In ACL short paper. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Reichert</author>
<author>David Kaufman</author>
<author>Benjamin Bloxham</author>
<author>Herbert Chase</author>
<author>No´emie Elhadad</author>
</authors>
<title>Cognitive analysis of the summarization of longitudinal patient records.</title>
<date>2010</date>
<booktitle>In AMIA Annual Symposium Proceedings,</booktitle>
<volume>volume</volume>
<pages>667</pages>
<publisher>American Medical Informatics Association.</publisher>
<contexts>
<context position="2066" citStr="Reichert et al., 2010" startWordPosition="291" endWordPosition="294">ation ordering is a challenging task as it is difficult to learn temporal relations among medical events which are not part of the logically coherent discourse of a single narrative. Resolving crossnarrative temporal relationships between medical events is essential to the task of generating an event timeline from across unstructured clinical narratives such as admission notes, radiology reports, history and physical reports and discharge summaries. Such a timeline has multiple applications in clinical trial recruitment (Luo et al., 2011), medical document summarization (Bramsen et al., 2006, Reichert et al., 2010) and clinical decision making (Demner-Fushman et al., 2009). Given multiple temporally ordered medical event sequences generated from each clinical narrative in a patient record, how can we combine the events to create a timeline across all the narratives? The tendency to copy-paste text and summarize past information in newly generated clinical narratives leads to multiple mentions of the same medical event across narratives (Cohen et al., 2013). These cross-narrative coreferences act as important anchors for reasoning with information across narratives. We leverage crossnarrative coreference</context>
</contexts>
<marker>Reichert, Kaufman, Bloxham, Chase, Elhadad, 2010</marker>
<rawString>Daniel Reichert, David Kaufman, Benjamin Bloxham, Herbert Chase, and No´emie Elhadad. 2010. Cognitive analysis of the summarization of longitudinal patient records. In AMIA Annual Symposium Proceedings, volume 2010, page 667. American Medical Informatics Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Roberts</author>
<author>R Gaizauskas</author>
<author>M Hepple</author>
<author>G Demetriou</author>
<author>Y Guo</author>
<author>A Setzer</author>
</authors>
<title>Semantic Annotation of Clinical Text: The CLEF Corpus.</title>
<date>2008</date>
<booktitle>In Proceedings of the LREC 2008 Workshop on Building and Evaluating Resources for Biomedical Text Mining,</booktitle>
<pages>pages</pages>
<contexts>
<context position="5874" citStr="Roberts et al., 2008" startWordPosition="876" endWordPosition="879">g. More recently, (Do et al., 2012) proposed an ILP-based method to combine the outputs of an event-interval and an event-event classifier for timeline construction on the ACE 2005 corpus. However, this approach is also restricted to events within documents and requires annotations for event intervals. We empirically compare our methods for timeline creation from longitudinal clinical narratives to such an ILP-based approach in Section 7. While a lot of this work has been done in the news domain, there is also some recent work in rule-based algorithms (Zhou et al., 2006) and machine learning (Roberts et al., 2008) applied to temporal relations between medical events in clinical text. Clinical narratives are written in a distinct sub-language with domain specific terminology and temporal characteristics, making them markedly different from newswire text. There is limited prior work in learning relations across documents. Ji and Grishman (2008) extended the one sense per discourse idea (Yarowsky, 1995) to multiple topically related documents and propagate consistent event arguments across sentences and documents. Barzilay and McKeown (2005) propose a text-to-text generation technique for synthesizing com</context>
</contexts>
<marker>Roberts, Gaizauskas, Hepple, Demetriou, Guo, Setzer, 2008</marker>
<rawString>A. Roberts, R. Gaizauskas, M. Hepple, G. Demetriou, Y. Guo, and A. Setzer. 2008. Semantic Annotation of Clinical Text: The CLEF Corpus. In Proceedings of the LREC 2008 Workshop on Building and Evaluating Resources for Biomedical Text Mining, pages 19–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T F Smith</author>
<author>M S Waterman</author>
</authors>
<title>Identification of common molecular subsequences.</title>
<date>1981</date>
<journal>Journal of molecular biology,</journal>
<volume>147</volume>
<issue>1</issue>
<contexts>
<context position="3239" citStr="Smith and Waterman, 1981" startWordPosition="463" endWordPosition="466">s narratives. We leverage crossnarrative coreference information along with confident cross-narrative temporal relation predictions and learn to align and temporally order medical event sequences across longitudinal clinical narratives. We model the problem as a sequence alignment task and propose solving this using two approaches. First, we use weighted finite state machines to represent medical events sequences, thus enabling composition and search to obtain the most probable combined sequence of medical events. As a contrast, we adapt dynamic programming algorithms (Needleman et al., 1970, Smith and Waterman, 1981) used to produce global and local alignments for aligning sequences of medical events across narratives. We also compare the proposed methods with an Integer Linear Programming (ILP) based method for timeline construction (Do et al., 2012). The cross-narrative coreference and temporal relation scores used in both these approaches are learned from a corpus of patient narratives from The Ohio State University Wexner Medical Center. The main contribution of this paper is a general framework that allows aligning multiple event sequences using cascaded weighted finite state transducers (WFSTs) with</context>
<context position="15449" citStr="Smith and Waterman, 1981" startWordPosition="2354" endWordPosition="2357">ons to derive a joint probability to enable cross-narrative temporal ordering. 5 Narrative Sequence Alignment for Cross-narrative Temporal Ordering Sequence alignment algorithms have been developed and popularly used in bioinformatics. However, multiple sequence alignment (MSA) has been shown to be NP complete (Wang and Jiang, 1994) and various heuristic algorithms have been proposed to solve this problem (Notredame, 2002). We propose a novel WFST-based representation that enables accurate decoding for MSA when compared to popularly used dynamic programming algorithms (Needleman et al., 1970, Smith and Waterman, 1981) or other state of the art methods (Do et al., 2012). In the problem of aligning events across multiple narrative sequences, we want to align temporally ordered medical events corresponding to clinical narratives of a patient. Unlike problems in biological sequence alignment where the symFigure 3: Score computation for aligning events across temporally ordered event sequences chest painstart = episodestart &lt; chest painstop = episodestop, where events across the sequences occur simultaneously and corefer. Figure 4: Score computation for aligning events across temporally ordered event sequences </context>
<context position="25339" citStr="Smith and Waterman, 1981" startWordPosition="4009" endWordPosition="4013">quence as a, x, b, y E N12. Now in aligning N12 with N3, we won’t be able to accommodate m &gt; x and m &lt; a. However, performing a beam search over the composed WFST in equation 2 allows us to accommodate such constraints across multiple sequences. The complexity of composing two transducers is O(V1V2D1(logD2 + M2)) where each edge from the first sequence matches every edge in the second sequence and Vi is the number of states, Di is the maximum out-degree and Mi maximum multiplicity for the ith FST (Mohri et al., 2005). We also use popular dynamic programming algorithms (Needleman et al., 1970, Smith and Waterman, 1981) for sequence alignment of medical events across narratives and compare it to the WFST-based representation and decoding. 5.3 Pairwise Alignment using Dynamic Programming As a contrast, we adapt two dynamic programming algorithms for sequence alignment: global alignment using the Needleman Wunsch algorithm (NW) (Needleman et al., 1970) and local alignment using the Smith-Waterman algorithm (SW) (Smith and Waterman, 1981). NW allows us to align all events in one sequence with all events in another sequence. A drawback of NW is that short and highly similar sequences maybe missed because they ge</context>
</contexts>
<marker>Smith, Waterman, 1981</marker>
<rawString>T.F. Smith and M.S. Waterman. 1981. Identification of common molecular subsequences. Journal of molecular biology, 147(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Sproat</author>
</authors>
<title>A Computational Theory of Writing Systems (Studies in Natural Language Processing).</title>
<date>2006</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="8230" citStr="Sproat, 2006" startWordPosition="1222" endWordPosition="1223">mming to compute the best alignment, given the temporal and coreference information between medical events across these sequences. More importantly, we propose a cascaded WFST-based framework for crossdocument temporal ordering of medical event sequences. Composition and search operations can be used to build a single transducer that integrates these components, directly mapping from input states to desired outputs, and obtain the best alignment (Mohri et al., 2000). In natural language processing, WFSTs have seen varied applications in machine translation (Kumar and Byrne, 2003), morphology (Sproat, 2006), named entity recognition (Krstev et al., 2011) and biological sequence alignment / generation (Whelan et al., 2010) among others. We demonstrate that the WFST-based approach outperforms popularly used dynamic programming algorithms for multiple sequence alignment. 3 Problem Description Medical events are temporally-associated concepts in clinical text that describe a medical condition affecting the patient’s health, or procedures performed on a patient. We represent medical events by splitting each event into a start and a stop. When there is insufficient information to discern the start or </context>
</contexts>
<marker>Sproat, 2006</marker>
<rawString>Richard Sproat. 2006. A Computational Theory of Writing Systems (Studies in Natural Language Processing). Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Robert J Gaizauskas</author>
<author>Frank Schilder</author>
<author>Mark Hepple</author>
<author>Jessica Moszkowicz</author>
<author>James Pustejovsky</author>
</authors>
<title>The tempeval challenge: identifying temporal relations in text.</title>
<date>2009</date>
<journal>Language Resources and Evaluation,</journal>
<volume>43</volume>
<issue>2</issue>
<contexts>
<context position="4823" citStr="Verhagen et al., 2009" startWordPosition="709" endWordPosition="712">ics dynamic programming or other ILP-based methods proposed in literature. 2 Related Work In the areas of summarization and text-to-text generation, there has been prior work on several ordering strategies to order pieces of information extracted from different input documents (Barzilay et al., 2002, Lapata, 2003, Bollegala et al., 2010). In this paper, we focus on temporal ordering of information, as discussed next. Recent state-of-the art research has focused on the problem of temporal relation learning within the same document, and in many cases within the same sentence (Mani et al., 2006, Verhagen et al., 2009, Lapata and Lascarides, 2011). Chambers and Jurafsky (2009) describe a process to induce a partially ordered set of events related by a common protagonist by using an unsupervised distributional method to learn relations between events sharing coreferring arguments, followed by temporal classification to induce partial order. The task was carried out on the Timebank newswire corpus, but was limited to an intra-document setting. More recently, (Do et al., 2012) proposed an ILP-based method to combine the outputs of an event-interval and an event-event classifier for timeline construction on th</context>
</contexts>
<marker>Verhagen, Gaizauskas, Schilder, Hepple, Moszkowicz, Pustejovsky, 2009</marker>
<rawString>Marc Verhagen, Robert J. Gaizauskas, Frank Schilder, Mark Hepple, Jessica Moszkowicz, and James Pustejovsky. 2009. The tempeval challenge: identifying temporal relations in text. Language Resources and Evaluation, 43(2):161–179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lusheng Wang</author>
<author>Tao Jiang</author>
</authors>
<title>On the complexity of multiple sequence alignment.</title>
<date>1994</date>
<journal>Journal of computational biology,</journal>
<volume>1</volume>
<issue>4</issue>
<contexts>
<context position="15158" citStr="Wang and Jiang, 1994" startWordPosition="2311" endWordPosition="2314"> 2012a). Another classifier is then trained to classify pairs of medical event starts and stops across narratives as sharing temporal relations {before, after, overlaps}. The learned cross-narrative coreference predictions can then be used along with confident temporal relation predictions to derive a joint probability to enable cross-narrative temporal ordering. 5 Narrative Sequence Alignment for Cross-narrative Temporal Ordering Sequence alignment algorithms have been developed and popularly used in bioinformatics. However, multiple sequence alignment (MSA) has been shown to be NP complete (Wang and Jiang, 1994) and various heuristic algorithms have been proposed to solve this problem (Notredame, 2002). We propose a novel WFST-based representation that enables accurate decoding for MSA when compared to popularly used dynamic programming algorithms (Needleman et al., 1970, Smith and Waterman, 1981) or other state of the art methods (Do et al., 2012). In the problem of aligning events across multiple narrative sequences, we want to align temporally ordered medical events corresponding to clinical narratives of a patient. Unlike problems in biological sequence alignment where the symFigure 3: Score comp</context>
<context position="27924" citStr="Wang and Jiang, 1994" startWordPosition="4469" endWordPosition="4472">) and C(i − 1, j) correspond to a gaps in sequence one and two. In case of the SW algorithm, the negative scoring matrix cells are set to zero, thus making the positively scoring local alignments visible. Backtracking starts at the highest scoring matrix cell and proceeds until a cell with score zero is encountered, yielding the highest scoring local alignment. The time and space complexity grows exponentially with the number of sequences to be aligned and finding the global optimum has been shown to be a NP-complete problem. The time complexity of aligning N sequences of length L is O(2NLN) (Wang and Jiang, 1994). Thus, for MSA using dynamic programming, we use a heuristic method where we combine pairwise alignments iteratively starting with the latest narrative and progressing towards the oldest narrative. 6 Experiments and Evaluation Corpus Description. The corpus consists of a dataset of clinical narratives obtained from the [redacted] medical center. The corpus has a total of 2060 patients, and 100704 clinical narratives. We gathered a gold standard set of seven patients (80 clinical narratives overall) with manual annotation of all medical events mentioned in the narratives, coreferences, and med</context>
</contexts>
<marker>Wang, Jiang, 1994</marker>
<rawString>Lusheng Wang and Tao Jiang. 1994. On the complexity of multiple sequence alignment. Journal of computational biology, 1(4):337–348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Whelan</author>
<author>Brian Roark</author>
<author>Kemal Sonmez</author>
</authors>
<title>Designing antimicrobial peptides with weighted finite-state transducers.</title>
<date>2010</date>
<booktitle>In Proceedings of IEEE Engineering in Medical Biology Society,</booktitle>
<pages>764</pages>
<contexts>
<context position="8347" citStr="Whelan et al., 2010" startWordPosition="1239" endWordPosition="1242">oss these sequences. More importantly, we propose a cascaded WFST-based framework for crossdocument temporal ordering of medical event sequences. Composition and search operations can be used to build a single transducer that integrates these components, directly mapping from input states to desired outputs, and obtain the best alignment (Mohri et al., 2000). In natural language processing, WFSTs have seen varied applications in machine translation (Kumar and Byrne, 2003), morphology (Sproat, 2006), named entity recognition (Krstev et al., 2011) and biological sequence alignment / generation (Whelan et al., 2010) among others. We demonstrate that the WFST-based approach outperforms popularly used dynamic programming algorithms for multiple sequence alignment. 3 Problem Description Medical events are temporally-associated concepts in clinical text that describe a medical condition affecting the patient’s health, or procedures performed on a patient. We represent medical events by splitting each event into a start and a stop. When there is insufficient information to discern the start or stop of an event, it is represented as a single concept. If only the start is known then the stop is set to +∞, where</context>
</contexts>
<marker>Whelan, Roark, Sonmez, 2010</marker>
<rawString>Christopher Whelan, Brian Roark, and Kemal Sonmez. 2010. Designing antimicrobial peptides with weighted finite-state transducers. In Proceedings of IEEE Engineering in Medical Biology Society, page 764.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Unsupervised word sense disambiguation rivaling supervised methods.</title>
<date>1995</date>
<booktitle>In Association for Computational Linguistics,</booktitle>
<pages>189--196</pages>
<contexts>
<context position="6268" citStr="Yarowsky, 1995" startWordPosition="935" endWordPosition="936">o such an ILP-based approach in Section 7. While a lot of this work has been done in the news domain, there is also some recent work in rule-based algorithms (Zhou et al., 2006) and machine learning (Roberts et al., 2008) applied to temporal relations between medical events in clinical text. Clinical narratives are written in a distinct sub-language with domain specific terminology and temporal characteristics, making them markedly different from newswire text. There is limited prior work in learning relations across documents. Ji and Grishman (2008) extended the one sense per discourse idea (Yarowsky, 1995) to multiple topically related documents and propagate consistent event arguments across sentences and documents. Barzilay and McKeown (2005) propose a text-to-text generation technique for synthesizing common information across documents using sentence fusion. This involves multisequence dependency tree alignment to identify phrases conveying similar information and statistical generation to combine common phrases into a sentence. Along with syntactic features, they combine knowledge from resources like WordNet to find similar sentences. In case of clinical narratives and medical event alignm</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>David Yarowsky. 1995. Unsupervised word sense disambiguation rivaling supervised methods. In Association for Computational Linguistics, pages 189– 196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Zhou</author>
<author>Genevieve B Melton</author>
<author>Simon Parsons</author>
<author>George Hripcsak</author>
</authors>
<title>A temporal constraint structure for extracting temporal information from clinical narrative.</title>
<date>2006</date>
<journal>Journal of Biomedical Informatics,</journal>
<pages>424--439</pages>
<contexts>
<context position="5830" citStr="Zhou et al., 2006" startWordPosition="869" endWordPosition="872">t was limited to an intra-document setting. More recently, (Do et al., 2012) proposed an ILP-based method to combine the outputs of an event-interval and an event-event classifier for timeline construction on the ACE 2005 corpus. However, this approach is also restricted to events within documents and requires annotations for event intervals. We empirically compare our methods for timeline creation from longitudinal clinical narratives to such an ILP-based approach in Section 7. While a lot of this work has been done in the news domain, there is also some recent work in rule-based algorithms (Zhou et al., 2006) and machine learning (Roberts et al., 2008) applied to temporal relations between medical events in clinical text. Clinical narratives are written in a distinct sub-language with domain specific terminology and temporal characteristics, making them markedly different from newswire text. There is limited prior work in learning relations across documents. Ji and Grishman (2008) extended the one sense per discourse idea (Yarowsky, 1995) to multiple topically related documents and propagate consistent event arguments across sentences and documents. Barzilay and McKeown (2005) propose a text-to-te</context>
</contexts>
<marker>Zhou, Melton, Parsons, Hripcsak, 2006</marker>
<rawString>Li Zhou, Genevieve B. Melton, Simon Parsons, and George Hripcsak. 2006. A temporal constraint structure for extracting temporal information from clinical narrative. Journal of Biomedical Informatics, pages 424–439.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>