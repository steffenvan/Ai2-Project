<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000185">
<title confidence="0.9787405">
Using Dialogue Representations for Concept-to-Speech
Generation
</title>
<author confidence="0.767748">
Christine H. Nakatani
Jennifer Chu-Carroll
</author>
<affiliation confidence="0.630096">
Bell Laboratories, Lucent Technologies
</affiliation>
<address confidence="0.901809666666667">
600 Mountain Avenue
Murray Hill, NJ 07974 USA
{ cm Ii encc)Oresearch . bell-labs . com
</address>
<sectionHeader confidence="0.87462" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999959357142857">
We present_ an implemented concept-to-speech
(CTS) systeni that offers original proposals for
certain couplings- of dialogue computation with
prosodic computation. Specifically, the semantic in-
terpretation, task modeling and dialogue strategy
modules in a working spoken dialogue system are
used to generate prosodic features to better convey
the meaning of system replies. The new CTS system
embodies and extends theoretical work on intona-
tional meaning in a more general, robust and rigor-
ous way than earlier approaches, by reflecting com-
positional aspects of both dialogue and intonation
interepretation in an original computational frame-
work for prosodic generation.
</bodyText>
<sectionHeader confidence="0.952831" genericHeader="method">
I. Introduction
</sectionHeader>
<bodyText confidence="0.999798666666666">
Conversational systems that use speech as the input
and output modality are often realized by architec-
tures that decouple speech processing components
from language processing components. In this pa-
per, we show how speech generation can be more
closely coupled with the dialogue manager of a work-
ing mixed-initiative spoken dialogue system. In par-
ticular, we use representations from the semantic in-
terpretation, task model and dialogue strategy mod-
ules to better communicate the meaning of system
replies through prosodically appropriate synthetic
speech.
While dialogue prosody has been a topic of much
study, our implemented concept-to-speech (CTS)
system offers original proposals for specific couplings
of dialogue computation with prosodic computation.
Further, it embodies and extends theoretical work
on intonational meaning in a more general, robust
and rigorous way than earlier CTS systems, in an
architecture that reflects compositional aspects of
dialogue and intonation interpretation.
</bodyText>
<sectionHeader confidence="0.970318" genericHeader="method">
2 Theoretical Foundations
</sectionHeader>
<bodyText confidence="0.999862230769231">
In this work, we implement and extend the com-
positional theory of intonational meaning proposed
by Pierrehumbert and Hirschberg (1986; 1990),
who sought to identify correspondences between the
Grosz and SkIner (1986) computational model of dis-
course interpretation and Pierrehumbert &apos;s prosodic
grammar for American English (1980).
In the present work, certain aspects of the orig-
inal theories are modified and adapted to the ar-
chitecture of the dialogue system in which the CTS
component is embedded. Below, we present the im-
portant fundamental definitions and principles of in-
tonation underlying our CTS system.
</bodyText>
<subsectionHeader confidence="0.903347">
2.1 Intonational System
</subsectionHeader>
<bodyText confidence="0.9970946">
In our CTS system, the prosodic elements that are
computed are based on the intonational system of
Pierrehumbert (1980), who defined a formal lan-
guage for describing American English intonation
using the following regular grammar:
</bodyText>
<sectionHeader confidence="0.419751" genericHeader="method">
Triton Phrase (Interrn Phrase)+ 13ndry Tone
</sectionHeader>
<subsectionHeader confidence="0.594042">
Interm Phrase (Pitch Acc)+ Phrase Ace
</subsectionHeader>
<bodyText confidence="0.998918285714286">
Major phrases, or intonational phrases, are made
up of one or more minor phrases, or intermediate
phrases. Melodic movements in intermediate and
intonational phrases are in turn expressed by three
kinds of tonal elements. These include six pitch ac-
cents: a low pitch excursion (L*), a high pitch excur-
sion (I1*), or a combination of both low and high ex-
cursions (1,*+H, L+H*, 11*-FL, II-FL*); two phrase
accents: a high (H-) or low (L-) tonal target that
guides the interpolation of the melodic contour from
final pitch accent to intermediate phrase ending; and
two boundary tones: a high (11%) or low (L%) tonal
target that guides interpolation from phrase accent
to intonational phrase ending.
</bodyText>
<subsectionHeader confidence="0.985111">
2.2 Intonational Meaning
</subsectionHeader>
<bodyText confidence="0.9996306">
Theoretical work on intonational meaning has at-
tempted to relate the grammatical elements of Pier-
rehumbert&apos;s system â€” pitch accent, phrase accent
and boundary tone, to interpretive processes at dif-
ferent levels of discourse and dialogue structure.
Hirschberg and Pierrehumbert (1986) conjectured
that the absence or presence of accentuation conveys
discourse focus status, while the tonal properties of
the accent itself (i.e. pitch accent type) cony. ey se-
mantic focus information.
</bodyText>
<page confidence="0.998162">
48
</page>
<figure confidence="0.9725882">
MIMIC:
User:
MIMIC:
User:
MIMIC:
</figure>
<bodyText confidence="0.922832777777778">
hello this is mimic the movie information system
how can I help you
where in hoboken is october sky playing
october sky is playing at hoboken cinema in hoboken
can I help you with anything else
when is it playing there
october sky is playing at hoboken
can i help you with anything else
cinema in hoboken at 3:45pm, 5:50pm, 7:10prn, and lOpm
</bodyText>
<figureCaption confidence="0.999577">
Figure 1: A MIMIC dialogue.
</figureCaption>
<bodyText confidence="0.999970166666667">
In later work, pitch accent type was said to
express whether the accented information was in-
tended by the speaker to be &amp;quot;predicated&amp;quot; or not by
the hearer (Pierrehumbert and llirschberg, 1990).
Non-predicated-information was said to bear low-
star accentuation Il+L*), while predi-
cated information would be marked by high-star ac-
cents (II*, L+11*, II*-FL). The theory further stated
that 1..*4-11 conveys uncertainty or lack of speaker
commitment to the expressed propositional content,
while L+H* marks correction or contrast. The com-
plex accent, 11*-1-L, was said to convey that an infer-
ence path was required to support the predication;
usage of 11+1,* similarly was said to imply an in-
ference path, but did not suggest a predication of a
mutual belief. Finally, phrase accents and bound-
ary tones were said to reflect aspects of discourse
structure.
</bodyText>
<sectionHeader confidence="0.99439" genericHeader="method">
3 Systems Foundations
</sectionHeader>
<bodyText confidence="0.999226722222222">
Our task is to improve the communicative compe-
tence of a spoken dialogue agent, by making re-
course to our knowledge of intonational meaning, di-
alogue processing and relations between the two. Of
course, a worthwhile CTS system must also outper-
form out-of-the-box text-to-speech (TTS) systems
that may determine prosodic mark-up in linguisti-
cally sophisticated ways. As in (Nakatani, 1998), we
take the prosodic output of an advanced research
system that implements the Pierrehumbert theory
of intonation, namely the Bell Labs TTS system,
as our baseline experimental system to be enhanced
by CTS algorithms. We embed the CTS system in
MIMIC, a working spoken dialogue system repre-
senting state-of-the-art dialogue management prac-
tices, to develop CTS algorithms that can be eventu-
ally realistically evaluated using task-based perfor-
mance metrics.
</bodyText>
<subsectionHeader confidence="0.67754">
3.1 Dialogue System: Mixed-Initiative
</subsectionHeader>
<bodyText confidence="0.960139105263158">
Movie Information Consultant
(MIMIC)
The dialogue system whose baseline speech gen-
eration capabilities we enhance is the Mixed-
Initiative Movie Information Consultant (MIMIC)
(Chu-Carroll, 2000). MIMIC. provides movie list-
Mg information involving knowledge about towns,
theaters, movies and showtimes, as demonstrated
in Figure 1. MIMIC currently utilizes template-
driven text generation, and passes on text strings
to a stand-alone TTS system. In the version of
MIMIC enhanced with concept-to-speech capabili-
ties, MIMIC-CTS, contextual knowledge is used to
modify the prosodic features of the slot and filler
material in the templates; we are currently integrat-
ing the algorithms in MIMIC-CTS with a grammar-
driven generation system. Further details of MIMIC
are presented in the relevant sections below, but see
(Chu-Carroll, 2000) for a complete overview.
</bodyText>
<subsectionHeader confidence="0.990255">
3.2 TTS: The Bell Labs System
</subsectionHeader>
<bodyText confidence="0.9999807">
For default prosodic processing and speech synthe-
sis realization, we use a research version of the
Bell Labs TTS System, circa 1992 (Sproat, 1997),
that generates intonational contours based on Pier-
rehumbert&apos;s intonation theory (1980), as described
hi (Pierrehumbert, 1981). Of relevance is the fact
that various pitch accent types, phrase accent and
boundary tones in Pierrehumbert&apos;s theory are di-
rectly implemented in this system, so that by gener-
ating a Pierrehumbert-style prosodic transcription,
the work of the CTS system is done. More pre-
cisely, MIMIC-CTS computes prosodic annotations
that override the default prosodic processing that is
performed by the Bell Labs TTS system.
To our knowledge, the intonation component of
the Bell Labs TTS system utilizes more linguistic
knowledge to compute prosodic annotations than
any other unrestricted TTS system, so it is reason-
able to assume that improvements upon it are mean-
ingful in practice as well as in theory.
</bodyText>
<sectionHeader confidence="0.986354" genericHeader="method">
4 MIMIC&apos;s Concept-to-Speech
Component (MIMIC-CTS)
</sectionHeader>
<bodyText confidence="0.99988625">
In MIMIC-CTS, the MIMIC dialogue system is en-
hanced with a CTS component to better communi-
cate the meaning of system replies through contex-
tually conditioned prosodic features. MIMIC-CTS
makes use of three distinct levels of dialogue rep-
resentations to convey meaning through intonation.
MIMIC&apos;s semantic representations allow MIMIC-
CTS to decide which information to prosodically
</bodyText>
<page confidence="0.996742">
49
</page>
<bodyText confidence="0.999895142857143">
highlight. MIMIC&apos;s iask model in turn determines
how to prosodically highlight selected information,
based on the pragmatic properties of the system
reply. MIMIC&apos;s dialogue strategy selection process
informs various choices in prosodic contour and ac-
centing that convey logico-semantic aspects of mean-
ing, such as contradiction.
</bodyText>
<subsectionHeader confidence="0.7599745">
4.1 Highlighting Information using
Semantic Representations
</subsectionHeader>
<bodyText confidence="0.999855875">
MIMIC employs a statistically-driven semantic in-
terpretation engine to &amp;quot;spot&amp;quot; values for key at-
tributes that make up a valid MIMIC query in a
robust fashion.&apos; To simplify matters, for each ut-
terance, MIMIC computes an attribute-value ma-
trix (AVM).- representation, identifying important
pieces of information for accomplishing a given set
of tasks. The AVM created from the following ut-
terance, &amp;quot;When is October Sky playing at Hoboken
Cinema in Hoboken?&amp;quot;, for example, is given in Fig-
ure 2.
Even such minimal use of dialogue information
can make a difference. For example, changing the
default accent for the following utterance highlights
the kind of information that the system is seeking,
instead of highlighting the semantically vacuous
</bodyText>
<table confidence="0.7085508">
main verb, itke:2
Default TTS: what movie would you LIKE
MIMIC-CTS: what MOVIE would you like
4.2 Conveying Information Status using
the Task Model
</table>
<bodyText confidence="0.985743">
MIMIC performs a set of information-giving tasks,
i.e. what, where, when, location, that are concisely
defined by a task model. MIMIC processes the
AVM for each utterance and then evaluates whether
it should perform a database query based on the
task specifications given in Figure 3. The task
model defines which attribute values must be filled
in (Y), must not 116 filled in (N), or may optionally
be filled in (--), to &amp;quot;license&amp;quot; a database query action.
If no task is &amp;quot;specified&amp;quot; by the current AVM state,
</bodyText>
<figure confidence="0.94665225">
Task Movie Theater Town
What N Y
Where Y N . Y
When Y Y
</figure>
<figureCaption confidence="0.737979">
Figure 3: Task Specifications for MIMIC.
</figureCaption>
<figure confidence="0.999287818181818">
Attribute
Value
Task
Movie
Theatre
Town
Time
when
October Sky
Hoboken Cinema
Hoboken
</figure>
<figureCaption confidence="0.9812895">
Figure 2: Attribute Value Matrix (AVM), computed
by MIMIC&apos;s semantic interpreter.
</figureCaption>
<bodyText confidence="0.999315">
Attribute names and attribute values are critical
to the task at hand. In MIMIC-CTS, attribute
names and values that occur in templates are typed,
so that MIMIC-CTS can highlight these items in
the following way:
</bodyText>
<listItem confidence="0.996970666666667">
1. All lexical items realizing attribute values are
accented.
2. Attribute values are synthesized at a slower
speaking rate.
3. Attribute values are set off by phrase bound-
aries.
</listItem>
<bodyText confidence="0.943662966666667">
MIMIC employs various strategies to progress
toward a complete and valid task specification.
For example, in response to the following user
utterance, MIMIC initiates an information-seeking
subdialogue to instantiate the theater attribute
value to accomplish a when task:
User: when is october sky playing
in hoboken
MIMIC-CTS: what THEATER would you like
To better convey the structure of the task model,
which is learned by the user through interaction
with the system, we define four information statuses
based on properties of the task model, which align
on a scale of given and new in the following order:
4. Attribute names are always accented. OLD INFERRABLE KEY HEARER-NEW
These modifications are entirely rule-based, given a [given] [new]
list of attribute names and typed attribute values.
Specifically, MIMIC uses an n-climensional call router
front-end (Chu-Carroll, 2000), which is a generalization of
the vector-based call-routing paradigm of semantic interpre-
tation (Chu-Carroll and Carpenter, 1999); that is, instead of
detecting one concept per utterance, MIMIC&apos;s semantic in-
terpretation engine detects multiple (n) concepts or classes
conveyed by a single utterance, by using n call routers in
parallel.
KEY information is that which is necessary to
formulate a valid database query, and is exchanged
and (implicitly or explicitly) confirmed between
the system and user. INFERRABLE information is
not explicitly exchanged between the system and
</bodyText>
<footnote confidence="0.981208">
2In the examples, small capitalization denotes a word is
accented.
</footnote>
<page confidence="0.977922">
50
</page>
<table confidence="0.9985245">
Task Specification Status Information Status Pitch Accent
Required (Y) KEY L+H*
Optional (-) INFERRABLE/OLD L*+H/L*
Not allowed (N) HEARER-NEW II*
</table>
<tableCaption confidence="0.995692">
Table 1: Highlighting relevance of information based on task model (and discourse history).
</tableCaption>
<table confidence="0.982097142857143">
User: where in montclair is analyze this playing
MIMIC: analyze this is playing at wellmont theatre and elearviews screening zone
in rnontclair
ANALYZE THIS is PLAYING at WELLMONT THEATER and
L+H* L+H* H* H* L-II%
CLEARVIEWS SCREENING ZONE in Pytowrci.Aitt
H* 11* H* L-H% L+H* L-L%
</table>
<figureCaption confidence="0.9437106">
Figure 4: Above, dialogue excerpt of MIMIC performing a where task. Below, the modified version of the
bold-faced reply string, generated by MIMIC-CTS.
user, but is derived by MIMIC&apos;s limited inference
engine that seeks to instantiate as many attribute
values as possible. For instance, a theater name
may be inferred given a town name, if there is only
one theater in the given town. OLD information
is inherited from the discourse history, based on
updating rules relying on confidence scores for
attribute values. HEARER-NEW information (c.f.
(Prince, 1988)) is that which is requested by the
user, and constitutes the only new information on
the scale. But note that KEY information, while
given, is still clearly in discourse focus, along with
HEARER-NEW information.
</figureCaption>
<bodyText confidence="0.999742">
The next step is to map the information statuses,
ordered from given to new, to a scale of pitch
accent, or accent melodies, ordered from given to
new as follows:
</bodyText>
<equation confidence="0.901631">
L* L*H-11 L+H* H*
[given] [new]
</equation>
<bodyText confidence="0.997832727272727">
Table 1 summarizes this original mapping of infor-
mation statuses to pitch accent melodies, and Fig-
ure 4 illustrates the use of this mapping in an ex-
ample. It obeys the general principle of Pierrehum-
bert and Hirschberg&apos;s work, that low tonality sig-
nifies discourse givenness and high tonality signifies
discourse newness, but extends this principle beyond
its vague definition in terms of predication of mutual
beliefs. Instead, the principle is operationalized here
in a practically motivated manner that is consistent
with and perhaps illuminating of the theory.
</bodyText>
<subsectionHeader confidence="0.996512">
4.3 Assigning &amp;quot;Dialogue Prosody&amp;quot; using
Dialogue Strategies
</subsectionHeader>
<bodyText confidence="0.957781333333333">
As in earlier CTS systems, special logico-sernantic
relations, such as contrast or correction, are effec-
tively conveyed in MIMIC-CTS by prosodic cues. In
MIMIC-CTS, however, these situations are not stip-
ulated in an ad hoc manner, but can be determined
to a large degree by MIMIC&apos;s dialogue strategy se-
lection process that identifies appropriate dialogue
acts to realize a dialogue goal.&apos;
For example, the dialogue act ANSWER may be
selected to achieve the dialogue goal of providing an
answer to a successful user query, while the dialogue
act NOTIFYFAILURE may be performed to achieve
the dialogue goal of providing an answer in situations
where no movie listing in the database matches the
user query. The template associated with the di-
alogue act, NOTIFYFAILURE, when compared with
that for ANSWER, contains an additional negative
auxiliary associated with the key attribute responsi-
ble for the query failure, in an utterance conveying a
contradiction in beliefs between the user and system
(namely, the presupposition on the part of the user
that the query can be satisfied).
Theoretical work on intonational interpretation
leads us to prosodically mark the negative auxil-
iary, as well as the associated focus position (Rooth,
1985). We choose to mark the negative auxiliary not
with the L+H* pitch accent to convey correction,
while marking the material in the associated focus
position with the L*+H pitch accent to convey (the
3Importaritly, MIMIC&apos;s adaptive dialogue strategy selec-
tion algorithm takes into account the outcome of an initia-
tive tracking module that we do not discuss here (see (Chu-
Carroll, 2000)).
</bodyText>
<page confidence="0.997382">
51
</page>
<bodyText confidence="0.966393">
User: where is the corruptor playing in cranford
MIMIC: the corruptor is not playing in cranford
the corruptor is playing at lincoln cinemas in arlington
</bodyText>
<equation confidence="0.4193205">
THE CORRUPTOR is NOT playing in CRANFORD
L-1-11* L-FH* - L+H* !II* L*+II L-II%
</equation>
<figureCaption confidence="0.71155">
Figure 5: Above, dialogue excerpt of MIMIC performing a NOTIFY FAILURE dialogue act. Below, the modified
version of the bold-faced reply string, generated by MIMIC-CTS. Note the diacritic &amp;quot;!&amp;quot; denotes a downstepped
accent (see (Pierrehurnbert, 1980)).
</figureCaption>
<bodyText confidence="0.998168071428571">
system&apos;s) lack of commitment to the (user&apos;s) pre-
supposition at hand. Finally, the NOTIFYFAILURE
dialogue act is conveyed by assigning the so-called
rise-fall-rise dintiadiction contour, L*+II L-11%, to
the utterance at rarge (c.f. (Hirschberg and Ward,
1991)). An example generated by MIMIC-CTS ap-
pears in Figure 5. Note that pitch accent types for
the remaining attribute values are assigned using the
task model, as described in section 4.2. Thus in Fig-
ure 5, the movie title is treated as KEY information,
marked by the L-1-11* pitch accent.
MIMIC-CTS contains additional prosodic rules
for logical connectives, and clarification and confir-
mation subdialogues.
</bodyText>
<sectionHeader confidence="0.999324" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999866774193549">
Although a number of earlier CTS systems have
captured linguistic phenomena that we address in
our work, the computation of prosody from dialogue
representations is often not as rigorous, detailed or
complete as in MIMIC-CTS. Further, while several
systems use given/new information status to decide
whether to accent or deaccent a lexical item, no sys-
tem has directly implemented general rules for pitch
accent type assignment. Together, MIMIC-CTS&apos;s
computation of accentuation, pitch accent type and
dialogue prosody constitutes the most general and
complete implementation of a compositional theory
of intonational meaning in a CTS system to date.
Nevertheless, elements of a handful of previ-
ous CTS systems support the approaches taken
in MIMIC-CTS toward conveying semantic, task
and dialogue level meaning. For example, the Di-
rection Assistant system (Davis and Hirschberg,
1988) mapped a hand-crafted route grammar to a
discourse structure for generated directions. The
discourse structure determined accentuation, with
deaccenting of discourse-old entities realized (by lex-
ically identical morphs) in the current or previous
discourse segment. Other material was assigned ac-
centuation based on lexical category information,
with the exception that certain contrastive cases of
accenting, such as left versus right, were stipulated
for the domain.
Accent assignment in the SUNDIAL travel infor-
mation system (House and Youd, 1990) also relied
on discourse and task models. Mutually known en-
tities, said to be in negative focus, were deaccented;
entities in the current task space, in referring focus,
received (possibly contrastive) accenting; and enti-
ties of the same type as a previously mentioned ob-
ject, were classified-as in either referring or emphatic
focus, depending on the dialogue act_ In the cases
of corrective situations or repeated system-intitiated
queries, the contrasting or corrective items were em-
phatically accented.
The BRIDGE project on speech generation
(Zacharski et al., 1992) identified four main factors
affecting accentability: linear order, lexical category,
semantic weight and givenness. In related work
(Monaghan, 1994), word accentability was quanti-
tatively scored by hand-crafted rules based on infor-
mation status, semantic focus and Word class. The
givenness hierarchy of Gundel and colleagues (1989),
which associates lexical forms of expression with in-
formation statuses, was divided into four intervals,
with scores assigned to each. A binary semantic fo-
cus score was based on whether the word occurred
in the topic or comment of a,sentence. Finally, lex-
ical categories determined word cl.s.s. scores, These
scores were combined, and metrical phonological
rules then referred to final accentability scores to
assign a final accenting pattern.
To summarize, all of the above CTS systems em-
ploy either hand-crafted or heuristic techniques for
representing semantic and discourse focus informa-
tion. Further, only SUNDIAL makes use of dialogue
acts.
</bodyText>
<sectionHeader confidence="0.990075" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.9999789">
We are presently carrying out evaluations of MIMIC-
CTS. An initial corpus-based analysis compares
the prosodic annotations assigned to three ac-
tual MIMIC dialogues, which were previously col-
lected during an overall system evaluation (Chu-
Carroll and Nickerson, 2000). The corpus of di-
alogues is made up of 37 system/user turns, in-
cluding 40 system-generated sentences. Three ver-
sions of the MIMIC dialogues are being analysed,
with prosodic features arising from three differ-
</bodyText>
<page confidence="0.994547">
52
</page>
<bodyText confidence="0.99943578125">
ent sources: MIMIC-CTS, MIMIC operating with
default, Bell Labs TTS, and a professional voice
talent who read the dialogue scripts in context.
This corpus-based assessment --- comparing the
prosody of CTS-generated, TTS-generated, and hu-
man speech, will enable more domain-dependent
tuning of the MIMIC-CTS algorithms, as well as the
refinement of general prosodic patterns for linguis-
tic structures, such as lists and conjunctive phrases.
Ultimately, the value of MIMIC-CTS must be mea-
sured based on its contribution to overall task pefor-
mance by real MIMIC users. Such a study is under
design, following (Chu-Carroll and Nickerson, 2000).
In conclusion, we have shown how prosodic com-
putation can be conditioned on various dialogue
representa,tions, for robust and domain-independent
CIS synthesis. - While- some rules for prosody as-
signment depend on the task model, others must be
tied closely to the particular choices of content in
the replies, at the level of dialogue goals and dia-
logue acts. .At this level as well, however, linguis-
tic principles of intonation interpretation can be ap-
plied to determine the mappings. In sum, the lesson
learned is that a unitary notion of &amp;quot;concept&amp;quot; from
which we. generate a unitary prosodic structure, does
not apply to state-of-the-art spoken dialogue gener-
ation. Instead, the representation of dialogue mean-
ing in experimental architectures, such as MIMIC&apos;s,
is compositional to some degree, and we take advan-
tage of this fact to implement a compositional theory
of intonational meaning in a new concept-to-speech
system, MIMIC-CTS.
</bodyText>
<sectionHeader confidence="0.995831" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998749378378378">
Jennifer Chu-Carroll and Bob Carpenter. 1999.
Vector-based natural language call routing. Com-
putational Linguistics, 25(3):361-388.
Jennifer Chu-Carroll and Jill S. Nickerson. 2000.
Evaluating automatic dialogue strategy adapta-
tion for a spoken dialogue system. In Proceed-
ings of the Ist Conference of the North Ameri-
can Chapter of the Association for Computational
Linguistics, Seattle.
Jennifer Chu-Carroll. 2000. Mimic: an adaptive
mixed initiative spoken dialogue system for infor-
mation queries. In Proceedings of the 6th Con-
ference on Applied Natural Language Processing,
Seattle.
J. R. Davis and J. Hirschberg, 1988. Assigning into-
national features in synthesized spoken directions.
In Proceedings of the 26th Annual Meeting of the
Association for Computational Linguistics, pages
187-193, Buffalo.
Barbara Grosz and Candace Sidner, 1986. Atten-
tion, intentions, and the structure of discourse.
Computational Linguistics, 12(3):175-204.
J. Gunclel, N. Hedberg, and R. Zacharski. 1989.
Givenness, implicature and demonstrative expres-
sions in English discourse. In Proceedings of CLS-
25, Parasession on Language in Context, pages
89-103. Chicago Linguistics Society.
Julia Hirschberg and Janet Pierrehumbert. 1986.
The intonational structuring of discourse. In Pro-
ceedings of the 24th Annual Meeting of the Asso-
ciation for Computational -Linguistics, New York.
J. Hirschberg and G. Ward. 1991. The influence of
pitch range, duration, amplitude, and spectral fea-
tures on the interpretation of 1*-Fh 1 h%. Journal
of Phonetics.
Jill House and Nick Vaud, 1990. Contextually ap-
propriate intonation in speech synthesis. In Pro-
ceedings of the European Speech Communication
Association Workshop on Speech Synthesis, pages
185-188, Autrans.
A. I, C. Monaghan. 1.994.. Intonation accent place-
ment in a concept-to-dialogue system. In Proceed-
ings of the ESCA/IEEE Workshop on Speech Syn-
thesis, pages 171-174, New Paltz, NY.
C. H. Nakatani. 1998. Constituent-based accent
prediction. In Proceedings of the 36th Annual
Meeting of the Association for Computational
Linguistics, Montreal.
J. Pierrehumbert and J. Hirschberg. 1990. The
meaning of intonational contours in the interpre-
tation of discourse. In Intentions in Communica-
tion, MIT Press, Cambridge, MA.
Janet Pierrehurnbert. 1980. The Phonology and
Phonetics of English Intonation. Ph.D. thesis,
Massachusetts Institute of Technology, Septem-
ber. Distributed by the Indiana University Lin-
guistics Club.
J. Pierrehumbert, 1981. Synthesising intonation.
Journal of the Acoustical Society of America,
70(4):985-995,
Ellen Prince, 1988. The ZPG letter: subjects, defi-
niteness, and information status. In S. Thompson
and W. Mann, editors, Discourse Description: Di-
verse Analyses of a Fund Raising Text. Elsevier
Science Publishers, Amsterdam.
Mats Rooth. 1985. Association with Focus. Ph.D.
thesis, University of Massachusetts, Amherst MA.
Richard Sproat, editor. 1997. Multilingual Text-
to-Speech Synthesis: The Bell Labs Approach.
Kluwer Academic, Boston.
Ron Zacharski, A. I. C. Monaghan, D. R. Ladd,
and Judy Delin. 1992. BRIDGE: Basic research
on intonation for dialogue generation. Technical
report, University of Edinburgh.
</reference>
<page confidence="0.999362">
53
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.861647">
<title confidence="0.998298">Using Dialogue Representations for Concept-to-Speech Generation</title>
<author confidence="0.9911235">Christine H Jennifer Chu-Carroll</author>
<affiliation confidence="0.942928">Bell Laboratories, Lucent</affiliation>
<address confidence="0.999737">600 Mountain Avenue 07974 USA</address>
<email confidence="0.974259">{cmIiencc)Oresearch.bell-labs.com</email>
<abstract confidence="0.996962933333333">We present_ an implemented concept-to-speech (CTS) systeni that offers original proposals for of dialogue computation with prosodic computation. Specifically, the semantic interpretation, task modeling and dialogue strategy modules in a working spoken dialogue system are used to generate prosodic features to better convey the meaning of system replies. The new CTS system embodies and extends theoretical work on intonational meaning in a more general, robust and rigorous way than earlier approaches, by reflecting compositional aspects of both dialogue and intonation interepretation in an original computational framework for prosodic generation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jennifer Chu-Carroll</author>
<author>Bob Carpenter</author>
</authors>
<date>1999</date>
<booktitle>Vector-based natural language call routing. Computational Linguistics,</booktitle>
<pages>25--3</pages>
<contexts>
<context position="12018" citStr="Chu-Carroll and Carpenter, 1999" startWordPosition="1833" endWordPosition="1836">ture of the task model, which is learned by the user through interaction with the system, we define four information statuses based on properties of the task model, which align on a scale of given and new in the following order: 4. Attribute names are always accented. OLD INFERRABLE KEY HEARER-NEW These modifications are entirely rule-based, given a [given] [new] list of attribute names and typed attribute values. Specifically, MIMIC uses an n-climensional call router front-end (Chu-Carroll, 2000), which is a generalization of the vector-based call-routing paradigm of semantic interpretation (Chu-Carroll and Carpenter, 1999); that is, instead of detecting one concept per utterance, MIMIC&apos;s semantic interpretation engine detects multiple (n) concepts or classes conveyed by a single utterance, by using n call routers in parallel. KEY information is that which is necessary to formulate a valid database query, and is exchanged and (implicitly or explicitly) confirmed between the system and user. INFERRABLE information is not explicitly exchanged between the system and 2In the examples, small capitalization denotes a word is accented. 50 Task Specification Status Information Status Pitch Accent Required (Y) KEY L+H* O</context>
</contexts>
<marker>Chu-Carroll, Carpenter, 1999</marker>
<rawString>Jennifer Chu-Carroll and Bob Carpenter. 1999. Vector-based natural language call routing. Computational Linguistics, 25(3):361-388.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer Chu-Carroll</author>
<author>Jill S Nickerson</author>
</authors>
<title>Evaluating automatic dialogue strategy adaptation for a spoken dialogue system.</title>
<date>2000</date>
<booktitle>In Proceedings of the Ist Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<location>Seattle.</location>
<contexts>
<context position="21573" citStr="Chu-Carroll and Nickerson, 2000" startWordPosition="3300" endWordPosition="3303">rces: MIMIC-CTS, MIMIC operating with default, Bell Labs TTS, and a professional voice talent who read the dialogue scripts in context. This corpus-based assessment --- comparing the prosody of CTS-generated, TTS-generated, and human speech, will enable more domain-dependent tuning of the MIMIC-CTS algorithms, as well as the refinement of general prosodic patterns for linguistic structures, such as lists and conjunctive phrases. Ultimately, the value of MIMIC-CTS must be measured based on its contribution to overall task peformance by real MIMIC users. Such a study is under design, following (Chu-Carroll and Nickerson, 2000). In conclusion, we have shown how prosodic computation can be conditioned on various dialogue representa,tions, for robust and domain-independent CIS synthesis. - While- some rules for prosody assignment depend on the task model, others must be tied closely to the particular choices of content in the replies, at the level of dialogue goals and dialogue acts. .At this level as well, however, linguistic principles of intonation interpretation can be applied to determine the mappings. In sum, the lesson learned is that a unitary notion of &amp;quot;concept&amp;quot; from which we. generate a unitary prosodic stru</context>
</contexts>
<marker>Chu-Carroll, Nickerson, 2000</marker>
<rawString>Jennifer Chu-Carroll and Jill S. Nickerson. 2000. Evaluating automatic dialogue strategy adaptation for a spoken dialogue system. In Proceedings of the Ist Conference of the North American Chapter of the Association for Computational Linguistics, Seattle.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer Chu-Carroll</author>
</authors>
<title>Mimic: an adaptive mixed initiative spoken dialogue system for information queries.</title>
<date>2000</date>
<booktitle>In Proceedings of the 6th Conference on Applied Natural Language Processing,</booktitle>
<location>Seattle.</location>
<contexts>
<context position="6466" citStr="Chu-Carroll, 2000" startWordPosition="978" endWordPosition="979">ents the Pierrehumbert theory of intonation, namely the Bell Labs TTS system, as our baseline experimental system to be enhanced by CTS algorithms. We embed the CTS system in MIMIC, a working spoken dialogue system representing state-of-the-art dialogue management practices, to develop CTS algorithms that can be eventually realistically evaluated using task-based performance metrics. 3.1 Dialogue System: Mixed-Initiative Movie Information Consultant (MIMIC) The dialogue system whose baseline speech generation capabilities we enhance is the MixedInitiative Movie Information Consultant (MIMIC) (Chu-Carroll, 2000). MIMIC. provides movie listMg information involving knowledge about towns, theaters, movies and showtimes, as demonstrated in Figure 1. MIMIC currently utilizes templatedriven text generation, and passes on text strings to a stand-alone TTS system. In the version of MIMIC enhanced with concept-to-speech capabilities, MIMIC-CTS, contextual knowledge is used to modify the prosodic features of the slot and filler material in the templates; we are currently integrating the algorithms in MIMIC-CTS with a grammardriven generation system. Further details of MIMIC are presented in the relevant sectio</context>
<context position="11888" citStr="Chu-Carroll, 2000" startWordPosition="1818" endWordPosition="1819">task: User: when is october sky playing in hoboken MIMIC-CTS: what THEATER would you like To better convey the structure of the task model, which is learned by the user through interaction with the system, we define four information statuses based on properties of the task model, which align on a scale of given and new in the following order: 4. Attribute names are always accented. OLD INFERRABLE KEY HEARER-NEW These modifications are entirely rule-based, given a [given] [new] list of attribute names and typed attribute values. Specifically, MIMIC uses an n-climensional call router front-end (Chu-Carroll, 2000), which is a generalization of the vector-based call-routing paradigm of semantic interpretation (Chu-Carroll and Carpenter, 1999); that is, instead of detecting one concept per utterance, MIMIC&apos;s semantic interpretation engine detects multiple (n) concepts or classes conveyed by a single utterance, by using n call routers in parallel. KEY information is that which is necessary to formulate a valid database query, and is exchanged and (implicitly or explicitly) confirmed between the system and user. INFERRABLE information is not explicitly exchanged between the system and 2In the examples, sma</context>
</contexts>
<marker>Chu-Carroll, 2000</marker>
<rawString>Jennifer Chu-Carroll. 2000. Mimic: an adaptive mixed initiative spoken dialogue system for information queries. In Proceedings of the 6th Conference on Applied Natural Language Processing, Seattle.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Davis</author>
<author>J Hirschberg</author>
</authors>
<title>Assigning intonational features in synthesized spoken directions.</title>
<date>1988</date>
<booktitle>In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>187--193</pages>
<location>Buffalo.</location>
<contexts>
<context position="18323" citStr="Davis and Hirschberg, 1988" startWordPosition="2814" endWordPosition="2817">se given/new information status to decide whether to accent or deaccent a lexical item, no system has directly implemented general rules for pitch accent type assignment. Together, MIMIC-CTS&apos;s computation of accentuation, pitch accent type and dialogue prosody constitutes the most general and complete implementation of a compositional theory of intonational meaning in a CTS system to date. Nevertheless, elements of a handful of previous CTS systems support the approaches taken in MIMIC-CTS toward conveying semantic, task and dialogue level meaning. For example, the Direction Assistant system (Davis and Hirschberg, 1988) mapped a hand-crafted route grammar to a discourse structure for generated directions. The discourse structure determined accentuation, with deaccenting of discourse-old entities realized (by lexically identical morphs) in the current or previous discourse segment. Other material was assigned accentuation based on lexical category information, with the exception that certain contrastive cases of accenting, such as left versus right, were stipulated for the domain. Accent assignment in the SUNDIAL travel information system (House and Youd, 1990) also relied on discourse and task models. Mutual</context>
</contexts>
<marker>Davis, Hirschberg, 1988</marker>
<rawString>J. R. Davis and J. Hirschberg, 1988. Assigning intonational features in synthesized spoken directions. In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics, pages 187-193, Buffalo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Grosz</author>
<author>Candace Sidner</author>
</authors>
<title>Attention, intentions, and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<pages>12--3</pages>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Barbara Grosz and Candace Sidner, 1986. Attention, intentions, and the structure of discourse. Computational Linguistics, 12(3):175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gunclel</author>
<author>N Hedberg</author>
<author>R Zacharski</author>
</authors>
<title>Givenness, implicature and demonstrative expressions in English discourse.</title>
<date>1989</date>
<booktitle>In Proceedings of CLS25, Parasession on Language in Context,</booktitle>
<pages>89--103</pages>
<publisher>Chicago Linguistics Society.</publisher>
<marker>Gunclel, Hedberg, Zacharski, 1989</marker>
<rawString>J. Gunclel, N. Hedberg, and R. Zacharski. 1989. Givenness, implicature and demonstrative expressions in English discourse. In Proceedings of CLS25, Parasession on Language in Context, pages 89-103. Chicago Linguistics Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hirschberg</author>
<author>Janet Pierrehumbert</author>
</authors>
<title>The intonational structuring of discourse.</title>
<date>1986</date>
<booktitle>In Proceedings of the 24th Annual Meeting of the Association for Computational -Linguistics,</booktitle>
<location>New York.</location>
<contexts>
<context position="3910" citStr="Hirschberg and Pierrehumbert (1986)" startWordPosition="575" endWordPosition="578"> L+H*, 11*-FL, II-FL*); two phrase accents: a high (H-) or low (L-) tonal target that guides the interpolation of the melodic contour from final pitch accent to intermediate phrase ending; and two boundary tones: a high (11%) or low (L%) tonal target that guides interpolation from phrase accent to intonational phrase ending. 2.2 Intonational Meaning Theoretical work on intonational meaning has attempted to relate the grammatical elements of Pierrehumbert&apos;s system â€” pitch accent, phrase accent and boundary tone, to interpretive processes at different levels of discourse and dialogue structure. Hirschberg and Pierrehumbert (1986) conjectured that the absence or presence of accentuation conveys discourse focus status, while the tonal properties of the accent itself (i.e. pitch accent type) cony. ey semantic focus information. 48 MIMIC: User: MIMIC: User: MIMIC: hello this is mimic the movie information system how can I help you where in hoboken is october sky playing october sky is playing at hoboken cinema in hoboken can I help you with anything else when is it playing there october sky is playing at hoboken can i help you with anything else cinema in hoboken at 3:45pm, 5:50pm, 7:10prn, and lOpm Figure 1: A MIMIC dial</context>
</contexts>
<marker>Hirschberg, Pierrehumbert, 1986</marker>
<rawString>Julia Hirschberg and Janet Pierrehumbert. 1986. The intonational structuring of discourse. In Proceedings of the 24th Annual Meeting of the Association for Computational -Linguistics, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hirschberg</author>
<author>G Ward</author>
</authors>
<title>The influence of pitch range, duration, amplitude, and spectral features on the interpretation of 1*-Fh 1 h%.</title>
<date>1991</date>
<journal>Journal of Phonetics.</journal>
<contexts>
<context position="17017" citStr="Hirschberg and Ward, 1991" startWordPosition="2615" endWordPosition="2618">aying at lincoln cinemas in arlington THE CORRUPTOR is NOT playing in CRANFORD L-1-11* L-FH* - L+H* !II* L*+II L-II% Figure 5: Above, dialogue excerpt of MIMIC performing a NOTIFY FAILURE dialogue act. Below, the modified version of the bold-faced reply string, generated by MIMIC-CTS. Note the diacritic &amp;quot;!&amp;quot; denotes a downstepped accent (see (Pierrehurnbert, 1980)). system&apos;s) lack of commitment to the (user&apos;s) presupposition at hand. Finally, the NOTIFYFAILURE dialogue act is conveyed by assigning the so-called rise-fall-rise dintiadiction contour, L*+II L-11%, to the utterance at rarge (c.f. (Hirschberg and Ward, 1991)). An example generated by MIMIC-CTS appears in Figure 5. Note that pitch accent types for the remaining attribute values are assigned using the task model, as described in section 4.2. Thus in Figure 5, the movie title is treated as KEY information, marked by the L-1-11* pitch accent. MIMIC-CTS contains additional prosodic rules for logical connectives, and clarification and confirmation subdialogues. 5 Related Work Although a number of earlier CTS systems have captured linguistic phenomena that we address in our work, the computation of prosody from dialogue representations is often not as r</context>
</contexts>
<marker>Hirschberg, Ward, 1991</marker>
<rawString>J. Hirschberg and G. Ward. 1991. The influence of pitch range, duration, amplitude, and spectral features on the interpretation of 1*-Fh 1 h%. Journal of Phonetics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jill House</author>
<author>Nick Vaud</author>
</authors>
<title>Contextually appropriate intonation in speech synthesis.</title>
<date>1990</date>
<booktitle>In Proceedings of the European Speech Communication Association Workshop on Speech Synthesis,</booktitle>
<pages>185--188</pages>
<location>Autrans.</location>
<marker>House, Vaud, 1990</marker>
<rawString>Jill House and Nick Vaud, 1990. Contextually appropriate intonation in speech synthesis. In Proceedings of the European Speech Communication Association Workshop on Speech Synthesis, pages 185-188, Autrans.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A I</author>
<author>C Monaghan</author>
</authors>
<title>Intonation accent placement in a concept-to-dialogue system.</title>
<date></date>
<booktitle>In Proceedings of the ESCA/IEEE Workshop on Speech Synthesis,</booktitle>
<pages>171--174</pages>
<location>New Paltz, NY.</location>
<marker>I, Monaghan, </marker>
<rawString>A. I, C. Monaghan. 1.994.. Intonation accent placement in a concept-to-dialogue system. In Proceedings of the ESCA/IEEE Workshop on Speech Synthesis, pages 171-174, New Paltz, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C H Nakatani</author>
</authors>
<title>Constituent-based accent prediction.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Montreal.</location>
<contexts>
<context position="5776" citStr="Nakatani, 1998" startWordPosition="880" endWordPosition="881"> 11+1,* similarly was said to imply an inference path, but did not suggest a predication of a mutual belief. Finally, phrase accents and boundary tones were said to reflect aspects of discourse structure. 3 Systems Foundations Our task is to improve the communicative competence of a spoken dialogue agent, by making recourse to our knowledge of intonational meaning, dialogue processing and relations between the two. Of course, a worthwhile CTS system must also outperform out-of-the-box text-to-speech (TTS) systems that may determine prosodic mark-up in linguistically sophisticated ways. As in (Nakatani, 1998), we take the prosodic output of an advanced research system that implements the Pierrehumbert theory of intonation, namely the Bell Labs TTS system, as our baseline experimental system to be enhanced by CTS algorithms. We embed the CTS system in MIMIC, a working spoken dialogue system representing state-of-the-art dialogue management practices, to develop CTS algorithms that can be eventually realistically evaluated using task-based performance metrics. 3.1 Dialogue System: Mixed-Initiative Movie Information Consultant (MIMIC) The dialogue system whose baseline speech generation capabilities </context>
</contexts>
<marker>Nakatani, 1998</marker>
<rawString>C. H. Nakatani. 1998. Constituent-based accent prediction. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics, Montreal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pierrehumbert</author>
<author>J Hirschberg</author>
</authors>
<title>The meaning of intonational contours in the interpretation of discourse.</title>
<date>1990</date>
<booktitle>In Intentions in Communication,</booktitle>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Pierrehumbert, Hirschberg, 1990</marker>
<rawString>J. Pierrehumbert and J. Hirschberg. 1990. The meaning of intonational contours in the interpretation of discourse. In Intentions in Communication, MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janet Pierrehurnbert</author>
</authors>
<title>The Phonology and Phonetics of English Intonation.</title>
<date>1980</date>
<tech>Ph.D. thesis,</tech>
<institution>Massachusetts Institute of Technology, September. Distributed by the Indiana University Linguistics Club.</institution>
<contexts>
<context position="16756" citStr="Pierrehurnbert, 1980" startWordPosition="2580" endWordPosition="2581">election algorithm takes into account the outcome of an initiative tracking module that we do not discuss here (see (ChuCarroll, 2000)). 51 User: where is the corruptor playing in cranford MIMIC: the corruptor is not playing in cranford the corruptor is playing at lincoln cinemas in arlington THE CORRUPTOR is NOT playing in CRANFORD L-1-11* L-FH* - L+H* !II* L*+II L-II% Figure 5: Above, dialogue excerpt of MIMIC performing a NOTIFY FAILURE dialogue act. Below, the modified version of the bold-faced reply string, generated by MIMIC-CTS. Note the diacritic &amp;quot;!&amp;quot; denotes a downstepped accent (see (Pierrehurnbert, 1980)). system&apos;s) lack of commitment to the (user&apos;s) presupposition at hand. Finally, the NOTIFYFAILURE dialogue act is conveyed by assigning the so-called rise-fall-rise dintiadiction contour, L*+II L-11%, to the utterance at rarge (c.f. (Hirschberg and Ward, 1991)). An example generated by MIMIC-CTS appears in Figure 5. Note that pitch accent types for the remaining attribute values are assigned using the task model, as described in section 4.2. Thus in Figure 5, the movie title is treated as KEY information, marked by the L-1-11* pitch accent. MIMIC-CTS contains additional prosodic rules for log</context>
</contexts>
<marker>Pierrehurnbert, 1980</marker>
<rawString>Janet Pierrehurnbert. 1980. The Phonology and Phonetics of English Intonation. Ph.D. thesis, Massachusetts Institute of Technology, September. Distributed by the Indiana University Linguistics Club.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pierrehumbert</author>
</authors>
<title>Synthesising intonation.</title>
<date>1981</date>
<journal>Journal of the Acoustical Society of America,</journal>
<pages>70--4</pages>
<contexts>
<context position="7432" citStr="Pierrehumbert, 1981" startWordPosition="1123" endWordPosition="1124">ledge is used to modify the prosodic features of the slot and filler material in the templates; we are currently integrating the algorithms in MIMIC-CTS with a grammardriven generation system. Further details of MIMIC are presented in the relevant sections below, but see (Chu-Carroll, 2000) for a complete overview. 3.2 TTS: The Bell Labs System For default prosodic processing and speech synthesis realization, we use a research version of the Bell Labs TTS System, circa 1992 (Sproat, 1997), that generates intonational contours based on Pierrehumbert&apos;s intonation theory (1980), as described hi (Pierrehumbert, 1981). Of relevance is the fact that various pitch accent types, phrase accent and boundary tones in Pierrehumbert&apos;s theory are directly implemented in this system, so that by generating a Pierrehumbert-style prosodic transcription, the work of the CTS system is done. More precisely, MIMIC-CTS computes prosodic annotations that override the default prosodic processing that is performed by the Bell Labs TTS system. To our knowledge, the intonation component of the Bell Labs TTS system utilizes more linguistic knowledge to compute prosodic annotations than any other unrestricted TTS system, so it is </context>
</contexts>
<marker>Pierrehumbert, 1981</marker>
<rawString>J. Pierrehumbert, 1981. Synthesising intonation. Journal of the Acoustical Society of America, 70(4):985-995,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Prince</author>
</authors>
<title>The ZPG letter: subjects, definiteness, and information status.</title>
<date>1988</date>
<editor>In S. Thompson and W. Mann, editors, Discourse</editor>
<publisher>Elsevier Science Publishers,</publisher>
<location>Amsterdam.</location>
<contexts>
<context position="13618" citStr="Prince, 1988" startWordPosition="2081" endWordPosition="2082">ENING ZONE in Pytowrci.Aitt H* 11* H* L-H% L+H* L-L% Figure 4: Above, dialogue excerpt of MIMIC performing a where task. Below, the modified version of the bold-faced reply string, generated by MIMIC-CTS. user, but is derived by MIMIC&apos;s limited inference engine that seeks to instantiate as many attribute values as possible. For instance, a theater name may be inferred given a town name, if there is only one theater in the given town. OLD information is inherited from the discourse history, based on updating rules relying on confidence scores for attribute values. HEARER-NEW information (c.f. (Prince, 1988)) is that which is requested by the user, and constitutes the only new information on the scale. But note that KEY information, while given, is still clearly in discourse focus, along with HEARER-NEW information. The next step is to map the information statuses, ordered from given to new, to a scale of pitch accent, or accent melodies, ordered from given to new as follows: L* L*H-11 L+H* H* [given] [new] Table 1 summarizes this original mapping of information statuses to pitch accent melodies, and Figure 4 illustrates the use of this mapping in an example. It obeys the general principle of Pie</context>
</contexts>
<marker>Prince, 1988</marker>
<rawString>Ellen Prince, 1988. The ZPG letter: subjects, definiteness, and information status. In S. Thompson and W. Mann, editors, Discourse Description: Diverse Analyses of a Fund Raising Text. Elsevier Science Publishers, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mats Rooth</author>
</authors>
<title>Association with Focus.</title>
<date>1985</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Massachusetts,</institution>
<location>Amherst MA.</location>
<contexts>
<context position="15886" citStr="Rooth, 1985" startWordPosition="2442" endWordPosition="2443">er in situations where no movie listing in the database matches the user query. The template associated with the dialogue act, NOTIFYFAILURE, when compared with that for ANSWER, contains an additional negative auxiliary associated with the key attribute responsible for the query failure, in an utterance conveying a contradiction in beliefs between the user and system (namely, the presupposition on the part of the user that the query can be satisfied). Theoretical work on intonational interpretation leads us to prosodically mark the negative auxiliary, as well as the associated focus position (Rooth, 1985). We choose to mark the negative auxiliary not with the L+H* pitch accent to convey correction, while marking the material in the associated focus position with the L*+H pitch accent to convey (the 3Importaritly, MIMIC&apos;s adaptive dialogue strategy selection algorithm takes into account the outcome of an initiative tracking module that we do not discuss here (see (ChuCarroll, 2000)). 51 User: where is the corruptor playing in cranford MIMIC: the corruptor is not playing in cranford the corruptor is playing at lincoln cinemas in arlington THE CORRUPTOR is NOT playing in CRANFORD L-1-11* L-FH* - </context>
</contexts>
<marker>Rooth, 1985</marker>
<rawString>Mats Rooth. 1985. Association with Focus. Ph.D. thesis, University of Massachusetts, Amherst MA.</rawString>
</citation>
<citation valid="true">
<title>Multilingual Textto-Speech Synthesis: The Bell Labs Approach.</title>
<date>1997</date>
<editor>Richard Sproat, editor.</editor>
<publisher>Kluwer Academic,</publisher>
<location>Boston.</location>
<marker>1997</marker>
<rawString>Richard Sproat, editor. 1997. Multilingual Textto-Speech Synthesis: The Bell Labs Approach. Kluwer Academic, Boston.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ron Zacharski</author>
<author>A I C Monaghan</author>
<author>D R Ladd</author>
<author>Judy Delin</author>
</authors>
<title>BRIDGE: Basic research on intonation for dialogue generation.</title>
<date>1992</date>
<tech>Technical report,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="19446" citStr="Zacharski et al., 1992" startWordPosition="2979" endWordPosition="2982">AL travel information system (House and Youd, 1990) also relied on discourse and task models. Mutually known entities, said to be in negative focus, were deaccented; entities in the current task space, in referring focus, received (possibly contrastive) accenting; and entities of the same type as a previously mentioned object, were classified-as in either referring or emphatic focus, depending on the dialogue act_ In the cases of corrective situations or repeated system-intitiated queries, the contrasting or corrective items were emphatically accented. The BRIDGE project on speech generation (Zacharski et al., 1992) identified four main factors affecting accentability: linear order, lexical category, semantic weight and givenness. In related work (Monaghan, 1994), word accentability was quantitatively scored by hand-crafted rules based on information status, semantic focus and Word class. The givenness hierarchy of Gundel and colleagues (1989), which associates lexical forms of expression with information statuses, was divided into four intervals, with scores assigned to each. A binary semantic focus score was based on whether the word occurred in the topic or comment of a,sentence. Finally, lexical cate</context>
</contexts>
<marker>Zacharski, Monaghan, Ladd, Delin, 1992</marker>
<rawString>Ron Zacharski, A. I. C. Monaghan, D. R. Ladd, and Judy Delin. 1992. BRIDGE: Basic research on intonation for dialogue generation. Technical report, University of Edinburgh.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>