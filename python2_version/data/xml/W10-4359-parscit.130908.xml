<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000147">
<title confidence="0.9964475">
Towards an Empirically Motivated Typology of Follow-Up Questions:
The Role of Dialogue Context
</title>
<author confidence="0.990406">
Manuel Kirschner and Raffaella Bernardi
</author>
<affiliation confidence="0.9932485">
KRDB Centre, Faculty of Computer Science
Free University of Bozen-Bolzano, Italy
</affiliation>
<email confidence="0.998038">
{kirschner,bernardi}@inf.unibz.it
</email>
<sectionHeader confidence="0.994773" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999972774193548">
A central problem in Interactive Ques-
tion Answering (IQA) is how to answer
Follow-Up Questions (FU Qs), possibly
by taking advantage of information from
the dialogue context. We assume that FU
Qs can be classified into specific types
which determine if and how the correct
answer relates to the preceding dialogue.
The main goal of this paper is to propose
an empirically motivated typology of FU
Qs, which we then apply in a practical
IQA setting. We adopt a supervised ma-
chine learning framework that ranks an-
swer candidates to FU Qs. Both the an-
swer ranking and the classification of FU
Qs is done in this framework, based on a
host of measures that include shallow and
deep inter-utterance relations, automati-
cally collected dialogue management meta
information, and human annotation. We
use Principal Component Analysis (PCA)
to integrate these measures. As a result,
we confirm earlier findings about the ben-
efit of distinguishing between topic shift
and topic continuation FU Qs. We then
present a typology of FU Qs that is more
fine-grained, extracted from the PCA and
based on real dialogue data. Since all our
measures are automatically computable,
our results are relevant for IQA systems
dealing with naturally occurring FU Qs.
</bodyText>
<sectionHeader confidence="0.999164" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999265625">
When real users engage in written conversations
with an Interactive Question Answering (IQA)
system, they typically do so in a sort of dia-
logue rather than asking single shot questions.
The questions’ context, i.e., the preceding interac-
tions, should be useful for understanding Follow-
Up Questions (FU Qs) and helping the system
pinpoint the correct answer. In previous work
(Kirschner et al., 2009; Bernardi et al., 2010;
Kirschner, 2010), we studied how dialogue con-
text should be considered to answer FU Qs. We
have used Logistic Regression Models (LRMs),
both for learning which aspects of dialogue struc-
ture are relevant to answering FU Qs, and for com-
paring the accuracy with which the resulting IQA
systems can correctly answer these questions. Un-
like much of the related research in IQA, which
used artificial collections of user questions, our
work has been based on real user-system dialogues
we collected via a chatbot-inspired help-desk IQA
system deployed on the web site of our University
Library.
Previously, our experiments used a selection
of shallow (Kirschner et al., 2009) and deep
(Bernardi et al., 2010) features, all of which de-
scribe specific relations holding between two ut-
terances (i.e., user questions or system answers).
In this paper we present additional features derived
from automatically collected dialogue meta-data
from our chatbot’s dialogue management com-
ponent. We use Principal Component Analysis
(PCA) to combine the benefits of all these infor-
mation sources, as opposed to using only certain
hand-selected features as in our previous work.
The main goal of this paper is to learn from data
a new typology of FU Qs; we then compare it to an
existing typology based on hand-annotated FU Q
types, as proposed in the literature. We show how
this new typology is effective for finding the cor-
rect answer to a FU Q. We produce this typology
by analyzing the main components of the PCA.
This paper presents two main results. A new,
empirically motivated typology of FU Qs confirms
earlier results about the practical benefit of dis-
tinguishing between topic continuation and topic
shift FU Qs, which are typically based on hand
annotation. We then show that we can do without
such hand annotations, in that our fully automatic,
</bodyText>
<note confidence="0.623124">
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 322–331,
The University of Tokyo, September 24-25, 2010. c�2010 Association for Computational Linguistics
</note>
<page confidence="0.99607">
322
</page>
<bodyText confidence="0.999311">
on-line measures – which include automatically
collected dialogue meta-data from our chatbot’s
dialogue manager – lead to better performance in
identifying correct answers to FU Qs.
In the remainder of this paper, we first review
relevant previous work concerning FU Q typolo-
gies in IQA. Section 3 then introduces our col-
lection of realistic IQA dialogues which we will
use in all our experiments; the section includes
descriptions of meta information in the form of
dialogue management features and post-hoc hu-
man annotations. In Section 4 we introduce our
experimental framework, based on inter-utterance
features and LRMs. Our experimental results are
presented in Section 5, which is followed by our
conclusions.
</bodyText>
<sectionHeader confidence="0.999756" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999965298245614">
Much of previous work on dialogue processing in
the domain of contextual or interactive Question
Answering (QA) (Bertomeu, 2008; van Schooten
et al., 2009; Chai and Jin, 2004; Yang et al., 2006)
has been based on (semi-)artificially devised sets
of context questions. However, the importance of
evaluating IQA against real user questions and the
need to consider preceding system answers has al-
ready been emphasized (Bernardi and Kirschner,
2010). The corpus of dialogues we deal with con-
sists of real logs in which actual library users were
conversing (by typing) with a chat-bot to obtain
information in a help-desk scenario.
(Yang et al., 2006) showed that shallow simi-
larity features between a FU Q and the preceding
utterances are useful to determine whether the FU
Q is a continuation of the on-going topic (“topic
continuation”), or it is a “topic shift”. The authors
showed that recognizing these two basic types of
FU Qs is important for deciding which context
fusion strategies to employ for retrieving the an-
swer to the FU Q. (Kirschner et al., 2009) showed
how shallow measures of lexical similarity be-
tween questions and answers in IQA dialogues are
as effective as manual annotations for distinguish-
ing between these basic FU Q types. However,
that earlier work was based on a much smaller set
of dialogue data than we use in this paper, mak-
ing for statistically weaker results. (Bernardi et
al., 2010) improved on this approach by increas-
ing the data set, and adding “deep” features that
quantify text coherence based on different theories
of dialogue and discourse structure. However, FU
Q classification was performed using either single,
hand-selected shallow or deep features, or a hand-
selected combination of one shallow and one deep
feature. In this paper, we adopt the most promising
measures of similarity and coherence from the two
aforementioned papers, add new features based
on automatically collected dialogue management
meta-data, and combine all this information via
Principal Component Analysis (PCA). By using
PCA, we circumvent the theoretical problem that
potentially multicollinear features pose to our sta-
tistical models, and at the same time we have a
convenient means for inducing a new typology of
FU Qs from our data, by analyzing the composi-
tion of the principal components of the PCA.
More fine-grained typologies of FU Qs have
been suggested, and different processing strategies
have been proposed for the identified types. In
this paper, we start from our own manual annota-
tion of FU Qs into four basic classes, as suggested
by the aforementioned literature (Bertomeu, 2008;
van Schooten et al., 2009; Sun and Chai, 2007).
We then compare it to our new PCA-based FU Q
typology.
</bodyText>
<sectionHeader confidence="0.995346" genericHeader="method">
3 Data
</sectionHeader>
<bodyText confidence="0.999890695652174">
We now introduce the set of IQA dialogue data
which we will use in our experiments. For the pur-
pose of calculating inter-utterance features within
these user-system interactions – as described in
Section 4.4 – we propose to represent utterances
in terms of dialogue snippets. A dialogue snip-
pet, or snippet for short, contains a FU Q, along
with a 2-utterance window of the preceding dia-
logue context. In this paper we use a supervised
machine learning approach for evaluating the cor-
rectness of a particular answer to a FU Q; we thus
represent also the answer candidate as part of the
snippet. Introducing the naming convention we
use throughout this paper, a snippet consists of the
following four successive utterances: Q1, A1, Q2,
and A2. The FU Q is thus referred to as Q2.
The data consists of 1,522 snippets of 4-turn
human-machine interactions in English: users ask
questions and the system answers them. The data
set was collected via the Bolzano Bot (BoB) web
application that has been working as an on-line
virtual help desk for the users of our University
Library since October 2008.1 The snippets were
</bodyText>
<footnote confidence="0.98974">
1www.unibz.it/library. More information on the
BoB dialogue corpus: bob.iqa-dialogues.net.
</footnote>
<page confidence="0.999311">
323
</page>
<bodyText confidence="0.998717423076923">
extracted from 916 users’ interactions.
Table 3 shows three example dialogue snippets
with correct A1 and A2; these examples are meant
to give an idea of the general shape of the BoB
dialogue data. In the third example snippet, A1
and A2 actually contain clickable hyperlinks that
open an external web-site. We represent them here
as dots in parentheses.
Our library domain experts manually checked
that each FU Q was either correctly answered in
the first place by BoB, or they corrected BoB’s an-
swer by hand, by assigning to it the correct answer
from BoB’s answer repository. In this way, the di-
alogue data contain 1,522 FU Qs, along with their
respective contexts (Q1 and A1) and their correct
answers (A2). The resulting set of correct A2s
contains 306 unique answers.2
The BoB dialogue data also contain two levels
of meta information that we will use in this paper.
On the one hand, we have automatically collected
dialogue meta-data from BoB’s dialogue manager
that describe the internal state of the BoB system
when a FU Q was asked; this information is de-
scribed in Section 4.2. On the other hand, 417 of
the 1,522 FU Qs were hand-annotated regarding
FU Q type, as described in Section 4.3.
</bodyText>
<sectionHeader confidence="0.990752" genericHeader="method">
4 Model
</sectionHeader>
<bodyText confidence="0.998690647058824">
Our goal is, given a FU Q (Q2 in our dialogue
snippets), to pick the best answer from the fixed
candidate set of 306 A2s, by assigning a score to
each candidate, and ranking them by this score.
Different FU Q types might require different an-
swer picking strategies. Thus, we specify both
A2 (identification) features, aiming at selecting the
correct A2 among candidates, and context (iden-
tification) features, that aim at characterizing the
context. The A2 identification features measure
the similarity or coherence between an utterance
in the context (e.g., Q2) and a candidate A2. Con-
text features measure the similarity or coherence
between pairs of utterances in the context (e.g.,
Q1 and Q2). They do not provide direct infor-
mation about A2, but might cue a special context
(say, an instance of topic shift) where we should
pay more attention to different A2 identification
features (say, less attention to the relation between
2Many of the 306 answer candidates overlap semantically.
This is problematic, given that our evaluation approach as-
sumes exactly one candidate to be correct, while all other 305
answers to be wrong. In this paper, we shall accept this fact,
for the merit of simplicity.
Q2 and A2, and more to the one between A1 and
A2).
We implement these ideas by estimating a gen-
eralized linear model from training data to predict
the probability that a certain A2 is correct given
the context. In this model, we enter A2 features as
main effects, and context features in interactions
with the former, allowing for differential weight
assignment to the same A2 features depending on
the values of the context features.
</bodyText>
<subsectionHeader confidence="0.996207">
4.1 Logistic Regression
</subsectionHeader>
<bodyText confidence="0.999930230769231">
Logistic regression models (LRMs) are general-
ized linear models that describe the relationship
between features (independent variables) and a bi-
nary outcome (Agresti, 2002). LRMs are closely
related to Maximum Entropy models, which have
performed well in many NLP tasks. A major ad-
vantage of using logistic regression as a super-
vised machine learning framework (as opposed to
other, possibly better performing approaches) is
that the learned coefficients are easy to interpret
and assess in terms of their statistical significance.
The logistic regression equations specify the prob-
ability for a particular answer candidate A2 being
correct, depending on the Q coefficients (repre-
senting the contribution of each feature to the total
answer correctness score), and the feature values
x1, ... , xk. In our setting, we are only interested
in the rank of each A2 among all answer candi-
dates, which can be easily and efficiently calcu-
lated through the linear part of the LRM: score
= Q1x1 + ... + Qkxk.
FU Q typology is implicitly modeled by inter-
action terms, given by the product of an A2 fea-
ture and a context feature. An interaction term
provides an extra Q to assign a differential weight
to an A2 feature depending on the value(s) of a
context feature. In the simplest case of interaction
with a binary 0-1 feature, the interaction Q weight
is only added when the binary feature has the 1-
value.
As described in (Kirschner, 2010), we esti-
mate the model parameters (the beta coefficients
01, ... , Qk) using maximum likelihood estima-
tion. Moreover, we put each model we construct
under trial by using an iterative backward elimina-
tion procedure that keeps removing the least sig-
nificant predictor from the model until a specific
stopping criterion that takes into account the sta-
tistical goodness of fit is satisfied. All the results
</bodyText>
<page confidence="0.994412">
324
</page>
<bodyText confidence="0.999934875">
we report below are obtained with models that un-
derwent this trimming procedure.
There is a potential pitfall when using multi-
ple regression models such as LRMs with multi-
collinear predictors, i.e., predictors that are inter-
correlated, such as our alternative implementa-
tions of inter-utterance string similarity. In such
situations, the model may not give valid results
about the importance of the individual predictors.
In this paper, we use PCA to circumvent the prob-
lem by combining potentially multicollinear pre-
dictors to completely uncorrelated PC-based pre-
dictors.
In the following three sections, we describe the
different types of information that are the basis for
our features.
</bodyText>
<subsectionHeader confidence="0.9922">
4.2 BoB dialogue management meta-data
</subsectionHeader>
<bodyText confidence="0.999874042553192">
When BoB interacts with a user, it keeps log files
of the IQA dialogue. First of all, these logs in-
clude a timed protocol of user input and BoB’s
responses: the user and system utterances are the
literal part of the information. On the other hand,
BoB also logs two dimensions of meta informa-
tion, both of which are based on BoB’s internal
status of its dialogue management routine. This
routine is based on a main initiative-response loop,
mapping user input to some canned-text answer,
where the user input should be matched by (at
least) one of a set of hand-devised regular expres-
sion question patterns.
Sub-dialogues Whenever BoB asks a system-
initiated question, the main loop is suspended, and
the system goes into a sub-dialogue state, where it
waits for a specific response from the user – typ-
ically a short answer indicating the user’s choice
about one of the options suggested by BoB. The
next user input is then matched against a small
number of regular expression patterns specifically
designed for the particular system-intiative ques-
tion at hand. Depending on this user input, the
sub-dialogue can:
Continue: the user input matched one of the
regular expression patterns intended to capture
possible user choices
Break: the user broke the sub-dialogue by en-
tering something unforeseen, e.g., a new question
The first two parts of Table 4 give an overview
of the statistics of BoB’s dialogue management-
based meta information concerned with sub-
dialogue status. Besides continue and break, for
Q1 we consider also a third, very common case
that a user question was not uttered in a sub-
dialogue setting at all. Note that we excluded from
our data collection all those cases where Q2 con-
tinues a sub-dialogue from our collection of IQA
dialogues, since we do not consider such Q2s as
FU Qs, as they are highly constrained by the pre-
vious dialogue.
Apology responses The third part of Table 4
gives statistics of whether a particular system re-
sponse A1 was an apology message stating that
BoB did not understand the user’s input, i.e., none
of BoB’s question patterns matched the user ques-
tion.
</bodyText>
<subsectionHeader confidence="0.998862">
4.3 Manual dialogue annotation
</subsectionHeader>
<bodyText confidence="0.986560516129032">
We now turn to the meta information in BoB dia-
logue data that stems from post-hoc human anno-
tation. For a portion of BoB’s log files, we added
up to two additional levels of meta information, by
annotating the log files after they were collected.3
The following paragraphs explain the individ-
ual levels of annotation by giving the correspond-
ing annotator instructions; Table 5 contains an
overview of the corresponding features. First of
all, we annotated FU Qs with their FU Q type.
Our choice of the particular four levels of the
FUQtype feature was influenced by the following
literature literature: from (De Boni and Manand-
har, 2005) and (Yang et al., 2006) we adopted the
distinction between topic shift and topic continua-
tion, while from (Bertomeu et al., 2006) we took
the notions of rephrases and context dependency.
Our annotation scheme is described in Figure 1;
note that topic continuations have three sub-types,
which are spelled out below.
FUQtype = isTopicShift: marks a FU Q
as a topic shift based on an intuitive notion of
whether the FU Q “switches to something com-
pletely different”.
FUQtype = isRephrase: marks whether
the FU Q is an attempt to re-formulate the same
question. The FU Q could be a literal repetition of
the previous question, or it could be a rephrasing.
FUQtype = isContextDepentFUQ:
marks whether the FU Q needs to be consid-
ered along with some information provided by
</bodyText>
<footnote confidence="0.9327215">
3All annotations were performed by either one of the au-
thors.
</footnote>
<page confidence="0.997375">
325
</page>
<bodyText confidence="0.9850515">
the dialogue context in order to be correctly
understood.
</bodyText>
<equation confidence="0.639659">
FUQtype = isFullySpecifiedFUQ:
</equation>
<bodyText confidence="0.998419363636364">
marks whether the FU Q does not need any
information from the dialogue context in order to
be correctly understood.
The second level of hand-annotation concerns a
manual check of the correctness of A1. It is avail-
able for 1,179 of our 1,522 snippets.
A1.isAnswer.correct: marks whether the
system response is correct for the given question.
A1.isApology.correct: marks whether
BoB’s apology message is correct for the given
question.
</bodyText>
<subsectionHeader confidence="0.94626">
4.4 Shallow/deep inter-utterance relations
</subsectionHeader>
<bodyText confidence="0.988269875">
We exploit shallow features, which measure the
similarity between two utterances within a snip-
pet, and deep features, which encode coherence
between two utterances based on linguistic the-
ory. For each feature we will use names encoding
the utterances involved; e.g., distsim.A1.Q2
stands for the Distributional Similarity feature cal-
culated between A1 and Q2.
Shallow features The detailed description of all
the shallow features we used in our experiments
can be found in (Kirschner et al., 2009). The in-
tuition is that a high similarity between Q and A
tends to indicate a correct answer, while in the
case of high similarity between the dialogue con-
text and the FU Q, it indicates a “topic continua-
tion” FU Q (as opposed to a “topic shift” FU Q),
and thus helps discriminating these two classes of
FU Qs.
Lexical Similarity (lexsim): If
two utterances share some terms, they are simi-
lar; the more discriminative the terms they share,
the more similar the utterances. Implements a TF-
IDF-based similarity metric. Distributional
Similarity (distsim.svd): Two utter-
ances are similar not only if they share the same
terms, but also if they share similar terms (e.g.,
book and journal). Term similarity is estimated
on a corpus, by representing each content word
(noun, verb, adjective) as a vector that records
its corpus co-occurrence with other content words
within a 5-word span. Action sequence
(action): Based on the notion that in our help-
desk setting we are dealing with task-based dia-
logues, which revolve around library-related ac-
tions (e.g., “borrow”, “search”). The action fea-
ture indicates whether two utterances contain the
same action.
Deep features These features encode different
theories of discourse and dialogue coherence. Re-
fer to (Bernardi et al., 2010) for a full description
of all deep features we used experimentally, along
with more details on the underlying linguistic the-
ories, and our implementation choices for these
features.
We introduce a four-level feature, center,
that encodes the four transitions holding between
adjacent utterances that Centering Theory de-
scribes (Brennan et al., 1987; Grosz et al., 1995).
Somewhat differently from that classic theory,
(Sun and Chai, 2007) define the transitions de-
pending on whether both the head and the modi-
fier of the Noun Phrases (NP) representing the pre-
ferred centers4 are continued (cont) or switched
(rough shift: roughSh) between Q1 and Q2. The
remaining two transitions are defined in similar
terms.
</bodyText>
<subsectionHeader confidence="0.993382">
4.5 PCA-based context classification features
</subsectionHeader>
<bodyText confidence="0.964339307692308">
Principal Component Analysis (PCA) (Manly,
2004) is a statistical technique for finding patterns
in high-dimensional data, or for reducing their di-
mensionality. Intuitively, PCA rotates the axes of
the original data dimensions in such a way that
few of the new axes already cover a large portion
of the variation in the data. These few new axes
are represented by the so-called principal compo-
nents (PCs). We employ this technique as a tool
for combining a multitude of potentially multi-
collinear predictors for context classification, i.e.,
all predictors that involve Q2 and some preceding
utterance. In our experiments we will also want to
look at the correlations of each of the top PCs with
the original context classification features; these
correlations are called loadings in PCA. We exper-
iment with the following three versions of PCA:
PCAA: without BoB dialogue management
meta-data features PCA performed over all
context classification features of the shallow and
deep types described in Section 4.4.
4Centers are noun phrases. The syntactic structure of a
noun phrase comprises a head noun, and possibly a modi-
fier, e.g., an adjective. We use a related approach, described
in (Ratkovic, 2009), to identify the preferred center of each
question.
</bodyText>
<page confidence="0.998136">
326
</page>
<bodyText confidence="0.992192">
PCAB: with BoB dialogue management meta-
data features PCAA plus BoB’s dialogue-
management meta-data features (Section 4.2).
PCAs: with BoB dialogue management meta-
data features and manual A1 correctness check
PCAB plus additional manual annotation of A1
correctness (Section 4.3).
</bodyText>
<sectionHeader confidence="0.997779" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.9999889">
We employ a standard 10-fold cross-validation
scheme for splitting training and prediction data.
We assess our LRMs by comparing the ranks that
the models assign to the gold-standard correct A2
candidate (i.e., the single A2 that our library do-
main experts had marked as correct for each of the
1,522 FU Qs). To determine whether differences
in A2 ranking performance are significant, we con-
sult both the paired t-test and the Wilcoxon signed
rank test about the difference of the 1,522 ranks.
</bodyText>
<subsectionHeader confidence="0.8804115">
5.1 Approximating hand-annotated FU Q
types with PCA-based features
</subsectionHeader>
<bodyText confidence="0.999969866666667">
We begin the evaluation of our approach by ex-
ploring the value of the hand-annotation-based FU
Q type as cues for expressing the relevance and
topical relatedness of that particular FU Q’s dia-
logue context.
For this purpose, we use the subset of 417
dialogue snippets which we annotated with the
FUQtype feature described in the first half of Ta-
ble 5. Figure 1 depicts our FU Q type taxonomy,
and the distribution of the four types in our data.
First of all, for this hand-annotated subset of di-
alogue snippets, we try to improve the A2 ranking
results of a “main effects only” baseline LRM,
i.e., a model which does not distinguish between
different FU Q types. This baseline model was
proposed in earlier work (Kirschner et al., 2009).
We tried the following features as interaction
term(s) in our models, one after the other: whether
the hand-annotated FUQType feature indicates a
topic shift or not; the full four levels of FUQType;
a linear combination of the top five PCs of each of
the three PCA feature sets introduced in Section
4.5. After applying our automatic predictor elimi-
nation routine described in Section 4.1 and evalu-
ating the A2 ranking results of each of these mod-
els, none of the interactive models significantly
outperform our baseline. PCA-based context clas-
sification using only fully automatic BoB meta in-
formation features (PCAB in Section 4.5) results
in the largest improvement over baseline; however,
this improvement does not reach statistical signifi-
cance, most likely due to the small data set of only
417 cases. Still, using the hand-annotated FU Q
type feature FUQType, we can visualize how the
top PCs cluster the 417 FU Qs, and how this clus-
tering mirrors some of the distinctions of manually
assigned FU Q types: see Figure 2. E.g., plotting
the FU Qs along their PC1 and PC2 values seems
to mimic the annotator’s distinction between topic
shift FU Qs and the other three FU Q types. The
other pairs of PCs also appear to show certain clus-
ters. Overall, the automatic context classification
features that served as input to the PCA are useful
for describing different context-related behaviors
of different FU Qs.
</bodyText>
<subsectionHeader confidence="0.9535195">
5.2 Optimizing A2 ranking scores using
PCA-based features
</subsectionHeader>
<bodyText confidence="0.9999884">
Having shown the usefulness (in terms of assign-
ing high ranks to the gold-standard correct A2) of
FU Q classification via a PCA-based combination
of purely automatic context classification features,
we can now consider the full sample of 1,522 di-
alogue snippets described in Section 3, for which
we do not in general possess manual FU Q type
annotations.
The first row of Table 1 shows the A2 ranking
results of our baseline LRM. In the remainder of
the table, we compare this baseline model to three
different models which use a linear combination
of different versions of the top five PCs as interac-
tion terms. The three versions (A, B and C) were
introduced in Section 4.5.
</bodyText>
<subsectionHeader confidence="0.999932">
5.3 Analysis of PC-based context features
</subsectionHeader>
<bodyText confidence="0.999992875">
The main goal of this paper is to devise an empiri-
cally motivated typology of FU Qs, under consid-
eration of automatically collected dialogue man-
agement meta information. We then want to show
how this new typology is effective for finding the
correct answer to a specific FU Q, in that for the
given FU Q it indicates the relevance and top-
ical relatedness of the question’s particular dia-
logue context. In Section 5.2 we have seen how
all PCA-based context classification features per-
form clearly better than a non-interactive baseline
model; more specifically, the top five PCs from
the PCAB scheme yield significantly better A2
ranking results than the PCAA scheme which does
not consider BoB dialogue management meta-data
features. Based on these results, we now look in
</bodyText>
<page confidence="0.993964">
327
</page>
<table confidence="0.994819166666666">
Model ID Interaction terms Mean rank Median rank Standard p (Paired p (Wilcoxon
correct A2 correct A2 dev. t-test) signed rank)
baseline none 48.72 14 69.35
PCAA PC1 + ... + PC5 44.25 12 64.58 &lt; 0.0001 &lt; 0.0001
PCAB PC1 + ... + PC5 42.72 12 62.53 0.0006 0.0087
PCAs PC1 + ... + PC5 42.87 12 62.94 not sig. not sig.
</table>
<tableCaption confidence="0.8389625">
Table 1: Improving ranking of correct A2 (out of 306 answer candidates) with different PCA-based
interaction terms. Significance tests of rank differences wrt. result in preceding row.
</tableCaption>
<bodyText confidence="0.999577347826087">
more detail at the relevance of the top five PC fea-
tures in PCAB, and at their most important load-
ings, i.e., the original context classification fea-
tures that are most highly correlated with the value
of each particular PC. After running our predic-
tor elimination routine, the corresponding LRM
has kept three of these five top PCs as interaction
terms: PC1, PC2 and PC5. Table 2 describes the
top three positive and top three negative loadings
of these PCs. The table also shows how in model
PCAB, each of the interaction terms correspond-
ing to the three PCs influences the score that is cal-
culated for every A2 candidate, either positively or
negatively.
Interpreting the results of Table 2 on a high,
dialogue-specific level, we draw the following
conclusions:
PC1 seems to capture a rather general distinc-
tion of topic shift versus topic continuation. A
FU Q with high lexical similarity to the preced-
ing utterances (i.e., a “topic continuation”) should
preferably get an A2 with higher lexical similar-
ity with respect to both A1 and Q2. In this con-
text, “topic shift” is partly described by a feature
from Centering Theory, and two of BoB’s dia-
logue management meta-data features.
PC2 shows relatively weak positive correlations
with any context classification features. On the
negative end, PC2 seems to describe a class of FU
Qs that are uttered after a Q1 that did neither con-
tinue nor exit a sub-dialogue. Also, A1 was a regu-
lar system answer (as opposed to an apology mes-
sage by BoB). Such FU Qs can thus be interpreted
as “single shot” questions that a user poses after
their previous question was already dealt with in
A1. Because of the negative loadings, the value of
PC2 becomes negative, resulting in the avoidance
of any A2 that is highly similar to the preceding
A1.
PC5 distinguishes FU Qs that are mostly related
to the previous answer from those that are more
related to the previous question. Depending on
whether PC5 turns positive or negative, A2s are
preferred that are more similar to A1 or Q2, re-
spectively. Q1.Q2 similarity is determined by both
lexical similarity and Centering Theory features.
</bodyText>
<sectionHeader confidence="0.996671" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999503269230769">
In this paper we have experimentally explored the
problem of FU Q types and their corresponding
answer identification strategies. The first result is
that our hand-annotated FU Q types did not sig-
nificantly improve Q2 answering performance (for
the annotated sub-set of 417 snippets). We at-
tribute this negative result in part to the difficulty
of the 4-level FU Q type annotation task. On the
other hand, we believe it is encouraging that with
purely automatic features for context classifica-
tion, combined through PCA, we significantly out-
performed our baseline. Adding BoB’s dialogue
management meta information – which is also au-
tomatically available when using our dialogue col-
lection scheme – for context classification helped
improve the scores even further. We analyzed the
top loadings of three PCs that our best-performing
LRM uses for FU Q type classification. We used
PCA both for circumventing the problem of mul-
ticollinear predictors in LRM, and as a diagnostic
tool to analyze the most important components of
automatically combined FU Q classification fea-
tures. Finally, a potentially difficult and cumber-
some manual annotation of the correctness of the
previous system answer A1 did not improve A2
ranking performance.
</bodyText>
<sectionHeader confidence="0.998455" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.988202">
Alan Agresti. 2002. Categorical Data Analysis.
Wiley-Interscience, New York.
Raffaella Bernardi and Manuel Kirschner. 2010. From
</reference>
<page confidence="0.99501">
328
</page>
<table confidence="0.960899181818182">
LOADINGS
PC1 PC2 PC5
0.33 distsim.Q1.Q2 0.05 Q1.bob.contSubdial 0.45 distsim.A1.Q2
0.26 distsim.A1.Q2 0.04 Q2.center.roughSh 0.31 A1.bob.isApology
0.26 action.Q1.Q2 0.02 Q2.bob.breakSubdial 0.29 lexsim.A1.Q2
... ... ...
−0.13 A1.bob.isApology −0.22 A1.bob.isAnswer −0.18 lexsim.Q1.Q2
−0.15 Q2.bob.noSubdial −0.30 Q2.bob.noSubdial −0.23 Q2.center.cont
−0.22 Q2.center.roughSh −0.31 Q1.bob.noSubdial −0.26 A1.bob.isAnswer
INFLUENCE ON A2 SELECTION IN MODEL PCAB
pos for each A2 similar to Q2 pos for each A2 similar to A1 pos for each A2 similar to A1
</table>
<tableCaption confidence="0.876917333333333">
pos for each A2 similar to A1 neg for each A2 similar to Q2
Table 2: Strongest loadings for the three PCs retained as interaction terms in Model PCAB, and indication
of each PC’s positive/negative influence on lexical similarity-based A2 selection features
</tableCaption>
<reference confidence="0.987224732394366">
artificial questions to real user interaction logs: Real
challenges for interactive question answering sys-
tems. In Proc. of Workshop on Web Logs and Ques-
tion Answering (WLQA’10), Valletta, Malta.
Raffaella Bernardi, Manuel Kirschner, and Zorana
Ratkovic. 2010. Context fusion: The role of dis-
course structure and centering theory. In Proceed-
ings of the Seventh conference on International Lan-
guage Resources and Evaluation (LREC’10), Val-
letta, Malta. European Language Resources Associ-
ation (ELRA).
N´uria Bertomeu, Hans Uszkoreit, Anette Frank, Hans-
Ulrich Krieger, and Brigitte J¨org. 2006. Contextual
phenomena and thematic relations in database QA
dialogues. In Proc. of the Interactive Question An-
swering Workshop at HLT-NAACL 2006, pages 1–8,
New York, NY.
Nuria Bertomeu. 2008. A Memory and Attention-
Based Approach to Fragment Resolution and its Ap-
plication in a Question Answering System. Ph.D.
thesis, Department of Computational Linguistics,
Saarland University.
Susan E. Brennan, Marilyn W. Friedman, and Carl J.
Pollard. 1987. A centering approach to pronouns.
In Proceedings of the 25th annual meeting on Asso-
ciation for Computational Linguistics, pages 155–
162, Stanford, California.
Joyce Y. Chai and Rong Jin. 2004. Discourse structure
for context question answering. In Proc. of the HLT-
NAACL 2004 Workshop on Pragmatics in Question
Answering, Boston, MA.
Marco De Boni and Suresh Manandhar. 2005. Im-
plementing clarification dialogues in open domain
question answering. Journal of Natural Language
Engineering, 11(4):343–361.
Barbara J. Grosz, Aravind K. Joshi, and Scott Wein-
stein. 1995. Centering: A framework for model-
ing the local coherence of discourse. Computational
Linguistics, 21(2):203–225.
Manuel Kirschner, Raffaella Bernardi, Marco Baroni,
and Le Thanh Dinh. 2009. Analyzing Interactive
QA dialogues using Logistic Regression Models. In
Proc. of XIth International Conference of the Italian
Association for Artificial Intelligence (AI*IA), Reg-
gio Emilia, Italy.
Manuel Kirschner. 2010. The Structure of Real
User-System Dialogues in Interactive Question An-
swering. Ph.D. thesis, Free University of Bozen-
Bolzano, Italy.
Bryan F. J. Manly. 2004. Multivariate Statistical
Methods: A Primer. Chapman &amp; Hall/CRC, 3rd
edition.
Zorana Ratkovic. 2009. Deep analysis in iqa: evalua-
tion on real users’ dialogues. Master’s thesis, Euro-
pean Masters Program in Language and Communi-
cation Technologies.
Mingyu Sun and Joyce Y. Chai. 2007. Discourse pro-
cessing for context question answering based on lin-
guistic knowledge. Know.-Based Syst., 20(6):511–
526.
Boris van Schooten, R. op den Akker, R. Rosset,
O. Galibert, A. Max, and G. Illouz. 2009. Follow-
up question handling in the IMIX and Ritel systems:
A comparative study. Journal of Natural Language
Engineering, 15(1):97–118.
Fan Yang, Junlan Feng, and Giuseppe Di Fabbrizio.
2006. A data driven approach to relevancy recogni-
tion for contextual question answering. In Proc. of
the Interactive Question Answering Workshop at
HLT-NAACL 2006, pages 33–40, New York City,
NY.
</reference>
<page confidence="0.998946">
329
</page>
<bodyText confidence="0.92604375">
Q1 where in the library can i find books
A1 Most of our holdings are accessible in the open-shelves area. In the repository we only keep
some older volumes of journals or the outsize stuff.
Q2 shelf mark
A2 Shelf marks are a combination of letters and numbers, which exactly define the location of a
book in a Library. If you find a book or a journal in the catalogue, you also see the shelf mark.
The shelf marks of the University Library consist of an alphanumeric code (e.g. ES 560 K19).
Would you like to know how you search them?
Q1 When can I return a book?
A1 Books and other media can be consigned at the information desk during the regular opening
hours of the Library. You can also leave them at the book drop located in front of the main
entrance of the university building - 24 hours a day.
Q2 I want to read the newspaper on the computer
A2 If you haven’t got a Library Card you can visit the Library to read books, journals or newspapers.
If you want to borrow something or use the other services we offer you should get a Library Card.
Do you want to know how it works?
</bodyText>
<equation confidence="0.7488695">
Q1 i need the opac
A1 Here (... ) is the page with our OPAC for you. You can search the complete holdings of the
Library.
Q2 where is the advisory service
</equation>
<bodyText confidence="0.9982775">
A2 The University’s Advisory Service provides an information service for prospective students who
would like to know more about which degree course to study. It also provides a support service
for enrolled students during their entire time at the University. You can get further information
from this (... ) site.
</bodyText>
<tableCaption confidence="0.993491">
Table 3: Example dialogue snippets with correctly identified A2
</tableCaption>
<table confidence="0.573188875">
Feature name Freq. Description
Q1.bob.contSubdial 7.6% Q1 continues system-initiated sub-dialogue
Q1.bob.breakSubdial 9.6% Q1 breaks out of system-initiated sub-dialogue
Q1.bob.noSubdial 82.9% BoB not in sub-dialogue mode when Q1 was uttered
Q2.bob.breakSubdial 13.6% Q2 breaks out of system-initiated sub-dialogue
Q2.bob.noSubdial 86.4% BoB not in sub-dialogue mode when Q2 was uttered
A1.bob.isAnswer 75.6% A1 is regular answer retrieved by BoB
A1.bob.isApology 24.4% A1 is apology message: BoB did not understand
</table>
<tableCaption confidence="0.7307035">
Table 4: BoB dialogue management meta information. Proportions out of those 1,441 of total 1,522
snippets for which this information was logged.
</tableCaption>
<bodyText confidence="0.898376454545455">
Feature name Freq. Description
FUQtype=isTopicShift 40.0% (of 417) Q2 is topic shift
FUQtype=isRephrase 19.2% (of 417) Q2 is rephrasing of Q1
FUQtype=isContextDepentFUQ 6.5% (of 417) Q2 is context dependent
FUQtype=isFullySpecifiedFUQ 34.3% (of 417) Q2 is not context dependent
A1.isAnswer.correct 66.5% (of 1,179) BoB’s regular answer A1 is correct
A1.isAnswer.false 19.0% (of 1,179) BoB’s regular answer A1 is false
A1.isApology.correct 1.3% (of 1,179) BoB’s apology message A1 is correct
A1.isApology.false 13.2% (of 1,179) BoB’s apology message A1 is false
Table 5: Manual annotation meta information. Proportions out of those sub-sets of total 1,522 snippets
with available annotation.
</bodyText>
<page confidence="0.965113">
330
</page>
<figure confidence="0.999338684210526">
Topic shift
Context-
dependent
167
27
Related/
salient
transition
FU Q
Fully
specified
417
Topic
continuation
170
143
Rephrase
250
80
</figure>
<figureCaption confidence="0.998871">
Figure 1: Manual FU Q type annotation scheme, with counts of FU Q types
</figureCaption>
<figure confidence="0.9875566">
FU Q types in &apos;context classification features&apos; space
isContextDependent
isFullySpecified
isRephrase
isTopicShift
4 0 2 4
2
0 PC5 0
-2
-4 -2 0
-4
6 2 4 6
4 PC4 2
2 2 0
-2 0 -2
4 0 2 4
2 PC3 -2
0 -2 -4
-6 -4 -6
-4 2 4 6
6 PC2 0
4 0 -2
2 4
-2
6 2 4 6
4 PC1 0
2 -2
-4 -2 0
-4
Scatter Plot Matrix
</figure>
<figureCaption confidence="0.999819">
Figure 2: Distribution of hand-annotated FU Q types in PC-based feature space (PCAB)
</figureCaption>
<page confidence="0.996066">
331
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.845332">
<title confidence="0.9947005">Towards an Empirically Motivated Typology of Follow-Up The Role of Dialogue Context</title>
<author confidence="0.937131">Kirschner</author>
<affiliation confidence="0.988646">KRDB Centre, Faculty of Computer Free University of Bozen-Bolzano,</affiliation>
<abstract confidence="0.99723734375">A central problem in Interactive Question Answering (IQA) is how to answer Follow-Up Questions (FU Qs), possibly by taking advantage of information from the dialogue context. We assume that FU Qs can be classified into specific types which determine if and how the correct answer relates to the preceding dialogue. The main goal of this paper is to propose an empirically motivated typology of FU Qs, which we then apply in a practical IQA setting. We adopt a supervised machine learning framework that ranks answer candidates to FU Qs. Both the answer ranking and the classification of FU Qs is done in this framework, based on a host of measures that include shallow and deep inter-utterance relations, automatically collected dialogue management meta information, and human annotation. We use Principal Component Analysis (PCA) to integrate these measures. As a result, we confirm earlier findings about the benefit of distinguishing between topic shift and topic continuation FU Qs. We then present a typology of FU Qs that is more fine-grained, extracted from the PCA and based on real dialogue data. Since all our measures are automatically computable, our results are relevant for IQA systems dealing with naturally occurring FU Qs.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alan Agresti</author>
</authors>
<title>Categorical Data Analysis.</title>
<date>2002</date>
<publisher>Wiley-Interscience,</publisher>
<location>New York.</location>
<contexts>
<context position="11717" citStr="Agresti, 2002" startWordPosition="1908" endWordPosition="1909">re to the one between A1 and A2). We implement these ideas by estimating a generalized linear model from training data to predict the probability that a certain A2 is correct given the context. In this model, we enter A2 features as main effects, and context features in interactions with the former, allowing for differential weight assignment to the same A2 features depending on the values of the context features. 4.1 Logistic Regression Logistic regression models (LRMs) are generalized linear models that describe the relationship between features (independent variables) and a binary outcome (Agresti, 2002). LRMs are closely related to Maximum Entropy models, which have performed well in many NLP tasks. A major advantage of using logistic regression as a supervised machine learning framework (as opposed to other, possibly better performing approaches) is that the learned coefficients are easy to interpret and assess in terms of their statistical significance. The logistic regression equations specify the probability for a particular answer candidate A2 being correct, depending on the Q coefficients (representing the contribution of each feature to the total answer correctness score), and the fea</context>
</contexts>
<marker>Agresti, 2002</marker>
<rawString>Alan Agresti. 2002. Categorical Data Analysis. Wiley-Interscience, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raffaella Bernardi</author>
<author>Manuel Kirschner</author>
</authors>
<title>From artificial questions to real user interaction logs: Real challenges for interactive question answering systems.</title>
<date>2010</date>
<booktitle>In Proc. of Workshop on Web Logs and Question Answering (WLQA’10),</booktitle>
<location>Valletta,</location>
<contexts>
<context position="5180" citStr="Bernardi and Kirschner, 2010" startWordPosition="818" endWordPosition="821">duce our experimental framework, based on inter-utterance features and LRMs. Our experimental results are presented in Section 5, which is followed by our conclusions. 2 Related work Much of previous work on dialogue processing in the domain of contextual or interactive Question Answering (QA) (Bertomeu, 2008; van Schooten et al., 2009; Chai and Jin, 2004; Yang et al., 2006) has been based on (semi-)artificially devised sets of context questions. However, the importance of evaluating IQA against real user questions and the need to consider preceding system answers has already been emphasized (Bernardi and Kirschner, 2010). The corpus of dialogues we deal with consists of real logs in which actual library users were conversing (by typing) with a chat-bot to obtain information in a help-desk scenario. (Yang et al., 2006) showed that shallow similarity features between a FU Q and the preceding utterances are useful to determine whether the FU Q is a continuation of the on-going topic (“topic continuation”), or it is a “topic shift”. The authors showed that recognizing these two basic types of FU Qs is important for deciding which context fusion strategies to employ for retrieving the answer to the FU Q. (Kirschne</context>
</contexts>
<marker>Bernardi, Kirschner, 2010</marker>
<rawString>Raffaella Bernardi and Manuel Kirschner. 2010. From artificial questions to real user interaction logs: Real challenges for interactive question answering systems. In Proc. of Workshop on Web Logs and Question Answering (WLQA’10), Valletta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raffaella Bernardi</author>
<author>Manuel Kirschner</author>
<author>Zorana Ratkovic</author>
</authors>
<title>Context fusion: The role of discourse structure and centering theory.</title>
<date>2010</date>
<journal>European Language Resources Association (ELRA).</journal>
<booktitle>In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC’10),</booktitle>
<location>Valletta,</location>
<contexts>
<context position="1935" citStr="Bernardi et al., 2010" startWordPosition="300" endWordPosition="303">cted from the PCA and based on real dialogue data. Since all our measures are automatically computable, our results are relevant for IQA systems dealing with naturally occurring FU Qs. 1 Introduction When real users engage in written conversations with an Interactive Question Answering (IQA) system, they typically do so in a sort of dialogue rather than asking single shot questions. The questions’ context, i.e., the preceding interactions, should be useful for understanding FollowUp Questions (FU Qs) and helping the system pinpoint the correct answer. In previous work (Kirschner et al., 2009; Bernardi et al., 2010; Kirschner, 2010), we studied how dialogue context should be considered to answer FU Qs. We have used Logistic Regression Models (LRMs), both for learning which aspects of dialogue structure are relevant to answering FU Qs, and for comparing the accuracy with which the resulting IQA systems can correctly answer these questions. Unlike much of the related research in IQA, which used artificial collections of user questions, our work has been based on real user-system dialogues we collected via a chatbot-inspired help-desk IQA system deployed on the web site of our University Library. Previousl</context>
<context position="6150" citStr="Bernardi et al., 2010" startWordPosition="985" endWordPosition="988">the on-going topic (“topic continuation”), or it is a “topic shift”. The authors showed that recognizing these two basic types of FU Qs is important for deciding which context fusion strategies to employ for retrieving the answer to the FU Q. (Kirschner et al., 2009) showed how shallow measures of lexical similarity between questions and answers in IQA dialogues are as effective as manual annotations for distinguishing between these basic FU Q types. However, that earlier work was based on a much smaller set of dialogue data than we use in this paper, making for statistically weaker results. (Bernardi et al., 2010) improved on this approach by increasing the data set, and adding “deep” features that quantify text coherence based on different theories of dialogue and discourse structure. However, FU Q classification was performed using either single, hand-selected shallow or deep features, or a handselected combination of one shallow and one deep feature. In this paper, we adopt the most promising measures of similarity and coherence from the two aforementioned papers, add new features based on automatically collected dialogue management meta-data, and combine all this information via Principal Component</context>
<context position="20058" citStr="Bernardi et al., 2010" startWordPosition="3283" endWordPosition="3286">r terms (e.g., book and journal). Term similarity is estimated on a corpus, by representing each content word (noun, verb, adjective) as a vector that records its corpus co-occurrence with other content words within a 5-word span. Action sequence (action): Based on the notion that in our helpdesk setting we are dealing with task-based dialogues, which revolve around library-related actions (e.g., “borrow”, “search”). The action feature indicates whether two utterances contain the same action. Deep features These features encode different theories of discourse and dialogue coherence. Refer to (Bernardi et al., 2010) for a full description of all deep features we used experimentally, along with more details on the underlying linguistic theories, and our implementation choices for these features. We introduce a four-level feature, center, that encodes the four transitions holding between adjacent utterances that Centering Theory describes (Brennan et al., 1987; Grosz et al., 1995). Somewhat differently from that classic theory, (Sun and Chai, 2007) define the transitions depending on whether both the head and the modifier of the Noun Phrases (NP) representing the preferred centers4 are continued (cont) or </context>
</contexts>
<marker>Bernardi, Kirschner, Ratkovic, 2010</marker>
<rawString>Raffaella Bernardi, Manuel Kirschner, and Zorana Ratkovic. 2010. Context fusion: The role of discourse structure and centering theory. In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC’10), Valletta, Malta. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N´uria Bertomeu</author>
<author>Hans Uszkoreit</author>
<author>Anette Frank</author>
<author>HansUlrich Krieger</author>
<author>Brigitte J¨org</author>
</authors>
<title>Contextual phenomena and thematic relations in database QA dialogues.</title>
<date>2006</date>
<booktitle>In Proc. of the Interactive Question Answering Workshop at HLT-NAACL</booktitle>
<pages>1--8</pages>
<location>New York, NY.</location>
<marker>Bertomeu, Uszkoreit, Frank, Krieger, J¨org, 2006</marker>
<rawString>N´uria Bertomeu, Hans Uszkoreit, Anette Frank, HansUlrich Krieger, and Brigitte J¨org. 2006. Contextual phenomena and thematic relations in database QA dialogues. In Proc. of the Interactive Question Answering Workshop at HLT-NAACL 2006, pages 1–8, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nuria Bertomeu</author>
</authors>
<title>A Memory and AttentionBased Approach to Fragment Resolution and its Application in a Question Answering System.</title>
<date>2008</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Computational Linguistics, Saarland University.</institution>
<contexts>
<context position="4861" citStr="Bertomeu, 2008" startWordPosition="770" endWordPosition="771">us work concerning FU Q typologies in IQA. Section 3 then introduces our collection of realistic IQA dialogues which we will use in all our experiments; the section includes descriptions of meta information in the form of dialogue management features and post-hoc human annotations. In Section 4 we introduce our experimental framework, based on inter-utterance features and LRMs. Our experimental results are presented in Section 5, which is followed by our conclusions. 2 Related work Much of previous work on dialogue processing in the domain of contextual or interactive Question Answering (QA) (Bertomeu, 2008; van Schooten et al., 2009; Chai and Jin, 2004; Yang et al., 2006) has been based on (semi-)artificially devised sets of context questions. However, the importance of evaluating IQA against real user questions and the need to consider preceding system answers has already been emphasized (Bernardi and Kirschner, 2010). The corpus of dialogues we deal with consists of real logs in which actual library users were conversing (by typing) with a chat-bot to obtain information in a help-desk scenario. (Yang et al., 2006) showed that shallow similarity features between a FU Q and the preceding uttera</context>
<context position="7351" citStr="Bertomeu, 2008" startWordPosition="1175" endWordPosition="1176">pal Component Analysis (PCA). By using PCA, we circumvent the theoretical problem that potentially multicollinear features pose to our statistical models, and at the same time we have a convenient means for inducing a new typology of FU Qs from our data, by analyzing the composition of the principal components of the PCA. More fine-grained typologies of FU Qs have been suggested, and different processing strategies have been proposed for the identified types. In this paper, we start from our own manual annotation of FU Qs into four basic classes, as suggested by the aforementioned literature (Bertomeu, 2008; van Schooten et al., 2009; Sun and Chai, 2007). We then compare it to our new PCA-based FU Q typology. 3 Data We now introduce the set of IQA dialogue data which we will use in our experiments. For the purpose of calculating inter-utterance features within these user-system interactions – as described in Section 4.4 – we propose to represent utterances in terms of dialogue snippets. A dialogue snippet, or snippet for short, contains a FU Q, along with a 2-utterance window of the preceding dialogue context. In this paper we use a supervised machine learning approach for evaluating the correct</context>
</contexts>
<marker>Bertomeu, 2008</marker>
<rawString>Nuria Bertomeu. 2008. A Memory and AttentionBased Approach to Fragment Resolution and its Application in a Question Answering System. Ph.D. thesis, Department of Computational Linguistics, Saarland University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan E Brennan</author>
<author>Marilyn W Friedman</author>
<author>Carl J Pollard</author>
</authors>
<title>A centering approach to pronouns.</title>
<date>1987</date>
<booktitle>In Proceedings of the 25th annual meeting on Association for Computational Linguistics,</booktitle>
<pages>155--162</pages>
<location>Stanford, California.</location>
<contexts>
<context position="20407" citStr="Brennan et al., 1987" startWordPosition="3335" endWordPosition="3338">ch revolve around library-related actions (e.g., “borrow”, “search”). The action feature indicates whether two utterances contain the same action. Deep features These features encode different theories of discourse and dialogue coherence. Refer to (Bernardi et al., 2010) for a full description of all deep features we used experimentally, along with more details on the underlying linguistic theories, and our implementation choices for these features. We introduce a four-level feature, center, that encodes the four transitions holding between adjacent utterances that Centering Theory describes (Brennan et al., 1987; Grosz et al., 1995). Somewhat differently from that classic theory, (Sun and Chai, 2007) define the transitions depending on whether both the head and the modifier of the Noun Phrases (NP) representing the preferred centers4 are continued (cont) or switched (rough shift: roughSh) between Q1 and Q2. The remaining two transitions are defined in similar terms. 4.5 PCA-based context classification features Principal Component Analysis (PCA) (Manly, 2004) is a statistical technique for finding patterns in high-dimensional data, or for reducing their dimensionality. Intuitively, PCA rotates the ax</context>
</contexts>
<marker>Brennan, Friedman, Pollard, 1987</marker>
<rawString>Susan E. Brennan, Marilyn W. Friedman, and Carl J. Pollard. 1987. A centering approach to pronouns. In Proceedings of the 25th annual meeting on Association for Computational Linguistics, pages 155– 162, Stanford, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joyce Y Chai</author>
<author>Rong Jin</author>
</authors>
<title>Discourse structure for context question answering.</title>
<date>2004</date>
<booktitle>In Proc. of the HLTNAACL 2004 Workshop on Pragmatics in Question Answering,</booktitle>
<location>Boston, MA.</location>
<contexts>
<context position="4908" citStr="Chai and Jin, 2004" startWordPosition="777" endWordPosition="780">Section 3 then introduces our collection of realistic IQA dialogues which we will use in all our experiments; the section includes descriptions of meta information in the form of dialogue management features and post-hoc human annotations. In Section 4 we introduce our experimental framework, based on inter-utterance features and LRMs. Our experimental results are presented in Section 5, which is followed by our conclusions. 2 Related work Much of previous work on dialogue processing in the domain of contextual or interactive Question Answering (QA) (Bertomeu, 2008; van Schooten et al., 2009; Chai and Jin, 2004; Yang et al., 2006) has been based on (semi-)artificially devised sets of context questions. However, the importance of evaluating IQA against real user questions and the need to consider preceding system answers has already been emphasized (Bernardi and Kirschner, 2010). The corpus of dialogues we deal with consists of real logs in which actual library users were conversing (by typing) with a chat-bot to obtain information in a help-desk scenario. (Yang et al., 2006) showed that shallow similarity features between a FU Q and the preceding utterances are useful to determine whether the FU Q i</context>
</contexts>
<marker>Chai, Jin, 2004</marker>
<rawString>Joyce Y. Chai and Rong Jin. 2004. Discourse structure for context question answering. In Proc. of the HLTNAACL 2004 Workshop on Pragmatics in Question Answering, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco De Boni</author>
<author>Suresh Manandhar</author>
</authors>
<title>Implementing clarification dialogues in open domain question answering.</title>
<date>2005</date>
<journal>Journal of Natural Language Engineering,</journal>
<volume>11</volume>
<issue>4</issue>
<marker>De Boni, Manandhar, 2005</marker>
<rawString>Marco De Boni and Suresh Manandhar. 2005. Implementing clarification dialogues in open domain question answering. Journal of Natural Language Engineering, 11(4):343–361.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Aravind K Joshi</author>
<author>Scott Weinstein</author>
</authors>
<title>Centering: A framework for modeling the local coherence of discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="20428" citStr="Grosz et al., 1995" startWordPosition="3339" endWordPosition="3342">ary-related actions (e.g., “borrow”, “search”). The action feature indicates whether two utterances contain the same action. Deep features These features encode different theories of discourse and dialogue coherence. Refer to (Bernardi et al., 2010) for a full description of all deep features we used experimentally, along with more details on the underlying linguistic theories, and our implementation choices for these features. We introduce a four-level feature, center, that encodes the four transitions holding between adjacent utterances that Centering Theory describes (Brennan et al., 1987; Grosz et al., 1995). Somewhat differently from that classic theory, (Sun and Chai, 2007) define the transitions depending on whether both the head and the modifier of the Noun Phrases (NP) representing the preferred centers4 are continued (cont) or switched (rough shift: roughSh) between Q1 and Q2. The remaining two transitions are defined in similar terms. 4.5 PCA-based context classification features Principal Component Analysis (PCA) (Manly, 2004) is a statistical technique for finding patterns in high-dimensional data, or for reducing their dimensionality. Intuitively, PCA rotates the axes of the original da</context>
</contexts>
<marker>Grosz, Joshi, Weinstein, 1995</marker>
<rawString>Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein. 1995. Centering: A framework for modeling the local coherence of discourse. Computational Linguistics, 21(2):203–225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manuel Kirschner</author>
<author>Raffaella Bernardi</author>
<author>Marco Baroni</author>
<author>Le Thanh Dinh</author>
</authors>
<title>Analyzing Interactive QA dialogues using Logistic Regression Models.</title>
<date>2009</date>
<booktitle>In Proc. of XIth International Conference of the Italian Association for Artificial Intelligence (AI*IA),</booktitle>
<location>Reggio Emilia, Italy.</location>
<contexts>
<context position="1912" citStr="Kirschner et al., 2009" startWordPosition="296" endWordPosition="299">more fine-grained, extracted from the PCA and based on real dialogue data. Since all our measures are automatically computable, our results are relevant for IQA systems dealing with naturally occurring FU Qs. 1 Introduction When real users engage in written conversations with an Interactive Question Answering (IQA) system, they typically do so in a sort of dialogue rather than asking single shot questions. The questions’ context, i.e., the preceding interactions, should be useful for understanding FollowUp Questions (FU Qs) and helping the system pinpoint the correct answer. In previous work (Kirschner et al., 2009; Bernardi et al., 2010; Kirschner, 2010), we studied how dialogue context should be considered to answer FU Qs. We have used Logistic Regression Models (LRMs), both for learning which aspects of dialogue structure are relevant to answering FU Qs, and for comparing the accuracy with which the resulting IQA systems can correctly answer these questions. Unlike much of the related research in IQA, which used artificial collections of user questions, our work has been based on real user-system dialogues we collected via a chatbot-inspired help-desk IQA system deployed on the web site of our Univer</context>
<context position="5795" citStr="Kirschner et al., 2009" startWordPosition="925" endWordPosition="928">r, 2010). The corpus of dialogues we deal with consists of real logs in which actual library users were conversing (by typing) with a chat-bot to obtain information in a help-desk scenario. (Yang et al., 2006) showed that shallow similarity features between a FU Q and the preceding utterances are useful to determine whether the FU Q is a continuation of the on-going topic (“topic continuation”), or it is a “topic shift”. The authors showed that recognizing these two basic types of FU Qs is important for deciding which context fusion strategies to employ for retrieving the answer to the FU Q. (Kirschner et al., 2009) showed how shallow measures of lexical similarity between questions and answers in IQA dialogues are as effective as manual annotations for distinguishing between these basic FU Q types. However, that earlier work was based on a much smaller set of dialogue data than we use in this paper, making for statistically weaker results. (Bernardi et al., 2010) improved on this approach by increasing the data set, and adding “deep” features that quantify text coherence based on different theories of dialogue and discourse structure. However, FU Q classification was performed using either single, hand-</context>
<context position="18783" citStr="Kirschner et al., 2009" startWordPosition="3074" endWordPosition="3077">gy.correct: marks whether BoB’s apology message is correct for the given question. 4.4 Shallow/deep inter-utterance relations We exploit shallow features, which measure the similarity between two utterances within a snippet, and deep features, which encode coherence between two utterances based on linguistic theory. For each feature we will use names encoding the utterances involved; e.g., distsim.A1.Q2 stands for the Distributional Similarity feature calculated between A1 and Q2. Shallow features The detailed description of all the shallow features we used in our experiments can be found in (Kirschner et al., 2009). The intuition is that a high similarity between Q and A tends to indicate a correct answer, while in the case of high similarity between the dialogue context and the FU Q, it indicates a “topic continuation” FU Q (as opposed to a “topic shift” FU Q), and thus helps discriminating these two classes of FU Qs. Lexical Similarity (lexsim): If two utterances share some terms, they are similar; the more discriminative the terms they share, the more similar the utterances. Implements a TFIDF-based similarity metric. Distributional Similarity (distsim.svd): Two utterances are similar not only if the</context>
<context position="23667" citStr="Kirschner et al., 2009" startWordPosition="3863" endWordPosition="3866"> expressing the relevance and topical relatedness of that particular FU Q’s dialogue context. For this purpose, we use the subset of 417 dialogue snippets which we annotated with the FUQtype feature described in the first half of Table 5. Figure 1 depicts our FU Q type taxonomy, and the distribution of the four types in our data. First of all, for this hand-annotated subset of dialogue snippets, we try to improve the A2 ranking results of a “main effects only” baseline LRM, i.e., a model which does not distinguish between different FU Q types. This baseline model was proposed in earlier work (Kirschner et al., 2009). We tried the following features as interaction term(s) in our models, one after the other: whether the hand-annotated FUQType feature indicates a topic shift or not; the full four levels of FUQType; a linear combination of the top five PCs of each of the three PCA feature sets introduced in Section 4.5. After applying our automatic predictor elimination routine described in Section 4.1 and evaluating the A2 ranking results of each of these models, none of the interactive models significantly outperform our baseline. PCA-based context classification using only fully automatic BoB meta informa</context>
</contexts>
<marker>Kirschner, Bernardi, Baroni, Dinh, 2009</marker>
<rawString>Manuel Kirschner, Raffaella Bernardi, Marco Baroni, and Le Thanh Dinh. 2009. Analyzing Interactive QA dialogues using Logistic Regression Models. In Proc. of XIth International Conference of the Italian Association for Artificial Intelligence (AI*IA), Reggio Emilia, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manuel Kirschner</author>
</authors>
<title>The Structure of Real User-System Dialogues in Interactive Question Answering.</title>
<date>2010</date>
<tech>Ph.D. thesis,</tech>
<institution>Free University of BozenBolzano, Italy.</institution>
<contexts>
<context position="1953" citStr="Kirschner, 2010" startWordPosition="304" endWordPosition="305">ased on real dialogue data. Since all our measures are automatically computable, our results are relevant for IQA systems dealing with naturally occurring FU Qs. 1 Introduction When real users engage in written conversations with an Interactive Question Answering (IQA) system, they typically do so in a sort of dialogue rather than asking single shot questions. The questions’ context, i.e., the preceding interactions, should be useful for understanding FollowUp Questions (FU Qs) and helping the system pinpoint the correct answer. In previous work (Kirschner et al., 2009; Bernardi et al., 2010; Kirschner, 2010), we studied how dialogue context should be considered to answer FU Qs. We have used Logistic Regression Models (LRMs), both for learning which aspects of dialogue structure are relevant to answering FU Qs, and for comparing the accuracy with which the resulting IQA systems can correctly answer these questions. Unlike much of the related research in IQA, which used artificial collections of user questions, our work has been based on real user-system dialogues we collected via a chatbot-inspired help-desk IQA system deployed on the web site of our University Library. Previously, our experiments</context>
<context position="5180" citStr="Kirschner, 2010" startWordPosition="820" endWordPosition="821">rimental framework, based on inter-utterance features and LRMs. Our experimental results are presented in Section 5, which is followed by our conclusions. 2 Related work Much of previous work on dialogue processing in the domain of contextual or interactive Question Answering (QA) (Bertomeu, 2008; van Schooten et al., 2009; Chai and Jin, 2004; Yang et al., 2006) has been based on (semi-)artificially devised sets of context questions. However, the importance of evaluating IQA against real user questions and the need to consider preceding system answers has already been emphasized (Bernardi and Kirschner, 2010). The corpus of dialogues we deal with consists of real logs in which actual library users were conversing (by typing) with a chat-bot to obtain information in a help-desk scenario. (Yang et al., 2006) showed that shallow similarity features between a FU Q and the preceding utterances are useful to determine whether the FU Q is a continuation of the on-going topic (“topic continuation”), or it is a “topic shift”. The authors showed that recognizing these two basic types of FU Qs is important for deciding which context fusion strategies to employ for retrieving the answer to the FU Q. (Kirschne</context>
<context position="12977" citStr="Kirschner, 2010" startWordPosition="2124" endWordPosition="2125"> are only interested in the rank of each A2 among all answer candidates, which can be easily and efficiently calculated through the linear part of the LRM: score = Q1x1 + ... + Qkxk. FU Q typology is implicitly modeled by interaction terms, given by the product of an A2 feature and a context feature. An interaction term provides an extra Q to assign a differential weight to an A2 feature depending on the value(s) of a context feature. In the simplest case of interaction with a binary 0-1 feature, the interaction Q weight is only added when the binary feature has the 1- value. As described in (Kirschner, 2010), we estimate the model parameters (the beta coefficients 01, ... , Qk) using maximum likelihood estimation. Moreover, we put each model we construct under trial by using an iterative backward elimination procedure that keeps removing the least significant predictor from the model until a specific stopping criterion that takes into account the statistical goodness of fit is satisfied. All the results 324 we report below are obtained with models that underwent this trimming procedure. There is a potential pitfall when using multiple regression models such as LRMs with multicollinear predictors,</context>
</contexts>
<marker>Kirschner, 2010</marker>
<rawString>Manuel Kirschner. 2010. The Structure of Real User-System Dialogues in Interactive Question Answering. Ph.D. thesis, Free University of BozenBolzano, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bryan F J Manly</author>
</authors>
<title>Multivariate Statistical Methods: A Primer. Chapman &amp; Hall/CRC, 3rd edition.</title>
<date>2004</date>
<contexts>
<context position="20863" citStr="Manly, 2004" startWordPosition="3407" endWordPosition="3408">ce a four-level feature, center, that encodes the four transitions holding between adjacent utterances that Centering Theory describes (Brennan et al., 1987; Grosz et al., 1995). Somewhat differently from that classic theory, (Sun and Chai, 2007) define the transitions depending on whether both the head and the modifier of the Noun Phrases (NP) representing the preferred centers4 are continued (cont) or switched (rough shift: roughSh) between Q1 and Q2. The remaining two transitions are defined in similar terms. 4.5 PCA-based context classification features Principal Component Analysis (PCA) (Manly, 2004) is a statistical technique for finding patterns in high-dimensional data, or for reducing their dimensionality. Intuitively, PCA rotates the axes of the original data dimensions in such a way that few of the new axes already cover a large portion of the variation in the data. These few new axes are represented by the so-called principal components (PCs). We employ this technique as a tool for combining a multitude of potentially multicollinear predictors for context classification, i.e., all predictors that involve Q2 and some preceding utterance. In our experiments we will also want to look </context>
</contexts>
<marker>Manly, 2004</marker>
<rawString>Bryan F. J. Manly. 2004. Multivariate Statistical Methods: A Primer. Chapman &amp; Hall/CRC, 3rd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zorana Ratkovic</author>
</authors>
<title>Deep analysis in iqa: evaluation on real users’ dialogues. Master’s thesis,</title>
<date>2009</date>
<booktitle>European Masters Program in Language and Communication Technologies.</booktitle>
<contexts>
<context position="22020" citStr="Ratkovic, 2009" startWordPosition="3593" endWordPosition="3594">g utterance. In our experiments we will also want to look at the correlations of each of the top PCs with the original context classification features; these correlations are called loadings in PCA. We experiment with the following three versions of PCA: PCAA: without BoB dialogue management meta-data features PCA performed over all context classification features of the shallow and deep types described in Section 4.4. 4Centers are noun phrases. The syntactic structure of a noun phrase comprises a head noun, and possibly a modifier, e.g., an adjective. We use a related approach, described in (Ratkovic, 2009), to identify the preferred center of each question. 326 PCAB: with BoB dialogue management metadata features PCAA plus BoB’s dialoguemanagement meta-data features (Section 4.2). PCAs: with BoB dialogue management metadata features and manual A1 correctness check PCAB plus additional manual annotation of A1 correctness (Section 4.3). 5 Evaluation We employ a standard 10-fold cross-validation scheme for splitting training and prediction data. We assess our LRMs by comparing the ranks that the models assign to the gold-standard correct A2 candidate (i.e., the single A2 that our library domain ex</context>
</contexts>
<marker>Ratkovic, 2009</marker>
<rawString>Zorana Ratkovic. 2009. Deep analysis in iqa: evaluation on real users’ dialogues. Master’s thesis, European Masters Program in Language and Communication Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mingyu Sun</author>
<author>Joyce Y Chai</author>
</authors>
<title>Discourse processing for context question answering based on linguistic knowledge.</title>
<date>2007</date>
<journal>Know.-Based Syst.,</journal>
<volume>20</volume>
<issue>6</issue>
<pages>526</pages>
<contexts>
<context position="7399" citStr="Sun and Chai, 2007" startWordPosition="1182" endWordPosition="1185"> we circumvent the theoretical problem that potentially multicollinear features pose to our statistical models, and at the same time we have a convenient means for inducing a new typology of FU Qs from our data, by analyzing the composition of the principal components of the PCA. More fine-grained typologies of FU Qs have been suggested, and different processing strategies have been proposed for the identified types. In this paper, we start from our own manual annotation of FU Qs into four basic classes, as suggested by the aforementioned literature (Bertomeu, 2008; van Schooten et al., 2009; Sun and Chai, 2007). We then compare it to our new PCA-based FU Q typology. 3 Data We now introduce the set of IQA dialogue data which we will use in our experiments. For the purpose of calculating inter-utterance features within these user-system interactions – as described in Section 4.4 – we propose to represent utterances in terms of dialogue snippets. A dialogue snippet, or snippet for short, contains a FU Q, along with a 2-utterance window of the preceding dialogue context. In this paper we use a supervised machine learning approach for evaluating the correctness of a particular answer to a FU Q; we thus r</context>
<context position="20497" citStr="Sun and Chai, 2007" startWordPosition="3349" endWordPosition="3352">dicates whether two utterances contain the same action. Deep features These features encode different theories of discourse and dialogue coherence. Refer to (Bernardi et al., 2010) for a full description of all deep features we used experimentally, along with more details on the underlying linguistic theories, and our implementation choices for these features. We introduce a four-level feature, center, that encodes the four transitions holding between adjacent utterances that Centering Theory describes (Brennan et al., 1987; Grosz et al., 1995). Somewhat differently from that classic theory, (Sun and Chai, 2007) define the transitions depending on whether both the head and the modifier of the Noun Phrases (NP) representing the preferred centers4 are continued (cont) or switched (rough shift: roughSh) between Q1 and Q2. The remaining two transitions are defined in similar terms. 4.5 PCA-based context classification features Principal Component Analysis (PCA) (Manly, 2004) is a statistical technique for finding patterns in high-dimensional data, or for reducing their dimensionality. Intuitively, PCA rotates the axes of the original data dimensions in such a way that few of the new axes already cover a </context>
</contexts>
<marker>Sun, Chai, 2007</marker>
<rawString>Mingyu Sun and Joyce Y. Chai. 2007. Discourse processing for context question answering based on linguistic knowledge. Know.-Based Syst., 20(6):511– 526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Boris van Schooten</author>
<author>R op den Akker</author>
<author>R Rosset</author>
<author>O Galibert</author>
<author>A Max</author>
<author>G Illouz</author>
</authors>
<title>Followup question handling in the IMIX and Ritel systems: A comparative study.</title>
<date>2009</date>
<journal>Journal of Natural Language Engineering,</journal>
<volume>15</volume>
<issue>1</issue>
<marker>van Schooten, den Akker, Rosset, Galibert, Max, Illouz, 2009</marker>
<rawString>Boris van Schooten, R. op den Akker, R. Rosset, O. Galibert, A. Max, and G. Illouz. 2009. Followup question handling in the IMIX and Ritel systems: A comparative study. Journal of Natural Language Engineering, 15(1):97–118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fan Yang</author>
<author>Junlan Feng</author>
<author>Giuseppe Di Fabbrizio</author>
</authors>
<title>A data driven approach to relevancy recognition for contextual question answering.</title>
<date>2006</date>
<booktitle>In Proc. of the Interactive Question Answering Workshop at HLT-NAACL</booktitle>
<pages>33--40</pages>
<location>New York City, NY.</location>
<marker>Yang, Feng, Di Fabbrizio, 2006</marker>
<rawString>Fan Yang, Junlan Feng, and Giuseppe Di Fabbrizio. 2006. A data driven approach to relevancy recognition for contextual question answering. In Proc. of the Interactive Question Answering Workshop at HLT-NAACL 2006, pages 33–40, New York City, NY.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>