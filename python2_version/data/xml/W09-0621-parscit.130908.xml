<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.029034">
<title confidence="0.973227">
Clustering and Matching Headlines for Automatic Paraphrase Acquisition
</title>
<author confidence="0.990103">
Sander Wubben, Antal van den Bosch, Emiel Krahmer, Erwin Marsi
</author>
<affiliation confidence="0.862399">
Tilburg centre for Creative Computing
Tilburg University
The Netherlands
</affiliation>
<email confidence="0.994604">
{s.wubben,antal.vdnbosch,e.j.krahmer,e.c.marsi}@uvt.nl
</email>
<sectionHeader confidence="0.994676" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999646357142857">
For developing a data-driven text rewriting
algorithm for paraphrasing, it is essential
to have a monolingual corpus of aligned
paraphrased sentences. News article head-
lines are a rich source of paraphrases; they
tend to describe the same event in vari-
ous different ways, and can easily be ob-
tained from the web. We compare two
methods of aligning headlines to construct
such an aligned corpus of paraphrases, one
based on clustering, and the other on pair-
wise similarity-based matching. We show
that the latter performs best on the task of
aligning paraphrastic headlines.
</bodyText>
<sectionHeader confidence="0.998429" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999862928571428">
In recent years, text-to-text generation has re-
ceived increasing attention in the field of Nat-
ural Language Generation (NLG). In contrast
to traditional concept-to-text systems, text-to-text
generation systems convert source text to target
text, where typically the source and target text
share the same meaning to some extent. Ap-
plications of text-to-text generation include sum-
marization (Knight and Marcu, 2002), question-
answering (Lin and Pantel, 2001), and machine
translation.
For text-to-text generation it is important to
know which words and phrases are semantically
close or exchangable in which contexts. While
there are various resources available that capture
such knowledge at the word level (e.g., synset
knowledge in WordNet), this kind of information
is much harder to get by at the phrase level. There-
fore, paraphrase acquisition can be considered an
important technology for producing resources for
text-to-text generation. Paraphrase generation has
already proven to be valuable for Question An-
swering (Lin and Pantel, 2001; Riezler et al.,
2007), Machine Translation (Callison-Burch et al.,
2006) and the evaluation thereof (Russo-Lassner
et al., 2006; Kauchak and Barzilay, 2006; Zhou et
al., 2006), but also for text simplification and ex-
planation.
In the study described in this paper, we make
an effort to collect Dutch paraphrases from news
article headlines in an unsupervised way to be
used in future paraphrase generation. News ar-
ticle headlines are abundant on the web, and
are already grouped by news aggregators such as
Google News. These services collect multiple arti-
cles covering the same event. Crawling such news
aggregators is an effective way of collecting re-
lated articles which can straightforwardly be used
for the acquisition of paraphrases (Dolan et al.,
2004; Nelken and Shieber, 2006). We use this
method to collect a large amount of aligned para-
phrases in an automatic fashion.
</bodyText>
<sectionHeader confidence="0.947166" genericHeader="introduction">
2 Method
</sectionHeader>
<bodyText confidence="0.9557675">
We aim to build a high-quality paraphrase corpus.
Considering the fact that this corpus will be the ba-
sic resource of a paraphrase generation system, we
need it to be as free of errors as possible, because
errors will propagate throughout the system. This
implies that we focus on obtaining a high precision
in the paraphrases collection process. Where pre-
vious work has focused on aligning news-items at
the paragraph and sentence level (Barzilay and El-
hadad, 2003), we choose to focus on aligning the
headlines of news articles. We think this approach
will enable us to harvest reliable training material
for paraphrase generation quickly and efficiently,
without having to worry too much about the prob-
lems that arise when trying to align complete news
articles.
For the development of our system we use
data which was obtained in the DAESO-project.
This project is an ongoing effort to build a Par-
allel Monolingual Treebank for Dutch (Marsi
Proceedings of the 12th European Workshop on Natural Language Generation, pages 122–125,
Athens, Greece, 30 – 31 March 2009. c�2009 Association for Computational Linguistics
</bodyText>
<page confidence="0.983683">
122
</page>
<bodyText confidence="0.760430857142857">
Placenta sandwich? No, urban legend!
Tom wants to make movie with Katie
Kate’s dad not happy with Tom Cruise
Cruise and Holmes sign for eighteen million
Eighteen million for Tom and Katie
Newest mission Tom Cruise not very convincing
Latest mission Tom Cruise succeeds less well
</bodyText>
<table confidence="0.6647536">
Tom Cruise barely succeeds with MI:3
Tom Cruise: How weird is he?
How weird is Tom Cruise really?
Tom Cruise leaves family
Tom Cruise escapes changing diapers
</table>
<tableCaption confidence="0.853008">
Table 1: Part of a sample headline cluster, with
sub-clusters
</tableCaption>
<bodyText confidence="0.999898225">
and Krahmer, 2007) and will be made available
through the Dutch HLT Agency. Part of the data
in the DAESO-corpus consists of headline clusters
crawled from Google News Netherlands in the pe-
riod April–August 2006. For each news article,
the headline and the first 150 characters of the ar-
ticle were stored. Roughly 13,000 clusters were
retrieved. Table 1 shows part of a (translated) clus-
ter. It is clear that although clusters deal roughly
with one subject, the headlines can represent quite
a different perspective on the content of the arti-
cle. To obtain only paraphrase pairs, the clusters
need to be more coherent. To that end 865 clus-
ters were manually subdivided into sub-clusters of
headlines that show clear semantic overlap. Sub-
clustering is no trivial task, however. Some sen-
tences are very clearly paraphrases, but consider
for instance the last two sentences in the example.
They do paraphrase each other to some extent, but
their relation can only be understood properly with
world knowledge. Also, there are numerous head-
lines that can not be sub-clustered, such as the first
three headlines shown in the example.
We use these annotated clusters as development
and test data in developing a method to automat-
ically obtain paraphrase pairs from headline clus-
ters. We divide the annotated headline clusters in a
development set of 40 clusters, while the remain-
der is used as test data. The headlines are stemmed
using the porter stemmer for Dutch (Kraaij and
Pohlmann, 1994).
Instead of a word overlap measure as used by
Barzilay and Elhadad (2003), we use a modified
TF*IDF word score as was suggested by Nelken
and Shieber (2006). Each sentence is viewed as a
document, and each original cluster as a collection
of documents. For each stemmed word i in sen-
tence j, TFi�j is a binary variable indicating if the
word occurs in the sentence or not. The TF*IDF
score is then:
</bodyText>
<equation confidence="0.935494">
|D|
TF.IDFi = TFi�j · log |{dj : ti E dj}|
</equation>
<bodyText confidence="0.999953285714286">
|D |is the total number of sentences in the clus-
ter and |{dj : ti E dj} |is the number of sen-
tences that contain the term ti. These scores are
used in a vector space representation. The similar-
ity between headlines can be calculated by using
a similarity function on the headline vectors, such
as cosine similarity.
</bodyText>
<subsectionHeader confidence="0.950303">
2.1 Clustering
</subsectionHeader>
<bodyText confidence="0.993795142857143">
Our first approach is to use a clustering algorithm
to cluster similar headlines. The original Google
News headline clusters are reclustered into finer
grained sub-clusters. We use the k-means imple-
mentation in the CLUTO1 software package. The
k-means algorithm is an algorithm that assigns
k centers to represent the clustering of n points
(k &lt; n) in a vector space. The total intra-cluster
variances is minimized by the function
(xj − µi)2
where µi is the centroid of all the points xj E Si.
The PK1 cluster-stopping algorithm as pro-
posed by Pedersen and Kulkarni (2006) is used to
find the optimal k for each sub-cluster:
</bodyText>
<equation confidence="0.999832">
Cr(k) − mean(Cr[1...ΔK])
PK1(k) = std(Cr[1...ΔK])
</equation>
<bodyText confidence="0.996046888888889">
Here, Cr is a criterion function, which mea-
sures the ratio of withincluster similarity to be-
tweencluster similarity. As soon as PK1(k) ex-
ceeds a threshold, k −1 is selected as the optimum
number of clusters.
To find the optimal threshold value for cluster-
stopping, optimization is performed on the devel-
opment data. Our optimization function is an F-
score:
</bodyText>
<equation confidence="0.983516875">
_ (1 + β2) · (precision · recall)
F� (β2 · precision + recall)
1http://glaros.dtc.umn.edu/gkhome/views/cluto/
k
i=1
V =
�
x;ESi
</equation>
<page confidence="0.986312">
123
</page>
<bodyText confidence="0.999711">
We evaluate the number of aligments between pos-
sible paraphrases. For instance, in a cluster of four
</bodyText>
<equation confidence="0.872773">
sentences, (� ) = 6 alignments can be made. In
2
</equation>
<bodyText confidence="0.999737235294118">
our case, precision is the number of alignments
retrieved from the clusters which are relevant, di-
vided by the total number of retrieved alignments.
Recall is the number of relevant retrieved alig-
ments divided by the total number of relevant
alignments.
We use an F,a-score with a Q of 0.25 as we
favour precision over recall. We do not want to op-
timize on precision alone, because we still want to
retrieve a fair amount of paraphrases and not only
the ones that are very similar. Through optimiza-
tion on our development set, we find an optimal
threshold for the PK1 algorithm thpk1 = 1. For
each original cluster, k-means clustering is then
performed using the k found by the cluster stop-
ping function. In each newly obtained cluster all
headlines can be aligned to each other.
</bodyText>
<subsectionHeader confidence="0.999023">
2.2 Pairwise similarity
</subsectionHeader>
<bodyText confidence="0.999840727272727">
Our second approach is to calculate the similarity
between pairs of headlines directly. If the similar-
ity exceeds a certain threshold, the pair is accepted
as a paraphrase pair. If it is below the thresh-
old, it is rejected. However, as Barzilay and El-
hadad (2003) have pointed out, sentence mapping
in this way is only effective to a certain extent.
Beyond that point, context is needed. With this
in mind, we adopt two thresholds and the Cosine
similarity function to calculate the similarity be-
tween two sentences:
</bodyText>
<table confidence="0.997712111111111">
Type Precision Recall
k-means clustering 0.91 0.43
clusters only
k-means clustering 0.66 0.44
all headlines
pairwise similarity 0.93 0.39
clusters only
pairwise similarity 0.76 0.41
all headlines
</table>
<tableCaption confidence="0.985886">
Table 2: Precision and Recall for both methods
</tableCaption>
<table confidence="0.999870833333333">
Playstation 3 more expensive than
competitor
Playstation 3 will become more
expensive than Xbox 360
Sony postpones Blu-Ray movies
Sony postpones coming of blu-ray dvds
Prices Playstation 3 known: from 499 euros
E3 2006: Playstation 3 from 499 euros
Sony PS3 with Blu-Ray for sale from
November 11th
PS3 available in Europe from
November 17th
</table>
<tableCaption confidence="0.9456675">
Table 3: Examples of correct (above) and incorrect
(below) alignments
</tableCaption>
<bodyText confidence="0.98253525">
well. We do not add these alignments, because in
particular in large clusters when one wrong align-
ment is made, this process chains together a large
amount of incorrect alignments.
</bodyText>
<equation confidence="0.996686666666667">
V 1 · V 2
cos(θ) =
11V 11111V 211
</equation>
<bodyText confidence="0.999986875">
where V 1 and V 2 are the vectors of the two sen-
tences being compared. If the similarity is higher
than the upper threshold, it is accepted. If it is
lower than the lower theshold, it is rejected. In
the remaining case of a similarity between the two
thresholds, similarity is calculated over the con-
texts of the two headlines, namely the text snippet
that was retrieved with the headline. If this simi-
larity exceeds the upper threshold, it is accepted.
Threshold values as found by optimizing on the
development data using again an F0.25-score, are
T hlwwer = 0.2 and T h,,pper = 0.5. An optional
final step is to add alignments that are implied by
previous alignments. For instance, if headline A is
paired with headline B, and headline B is aligned
to headline C, headline A can be aligned to C as
</bodyText>
<sectionHeader confidence="0.999806" genericHeader="background">
3 Results
</sectionHeader>
<bodyText confidence="0.999595571428571">
The 825 clusters in the test set contain 1,751 sub-
clusters in total. In these sub-clusters, there are
6,685 clustered headlines. Another 3,123 head-
lines remain unclustered. Table 2 displays the
paraphrase detection precision and recall of our
two approaches. It is clear that k-means cluster-
ing performs well when all unclustered headlines
are artificially ignored. In the more realistic case
when there are also items that cannot be clustered,
the pairwise calculation of similarity with a back
off strategy of using context performs better when
we aim for higher precision. Some examples of
correct and incorrect alignments are given in Ta-
ble 3.
</bodyText>
<page confidence="0.998369">
124
</page>
<sectionHeader confidence="0.998124" genericHeader="discussions">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999975878787879">
Using headlines of news articles clustered by
Google News, and finding good paraphrases
within these clusters is an effective route for ob-
taining pairs of paraphrased sentences with rea-
sonable precision. We have shown that a cosine
similarity function comparing headlines and us-
ing a back off strategy to compare context can be
used to extract paraphrase pairs at a precision of
0.76. Although we could aim for a higher preci-
sion by assigning higher values to the thresholds,
we still want some recall and variation in our para-
phrases. Of course the coverage of our method is
still somewhat limited: only paraphrases that have
some words in common will be extracted. This
is not a bad thing: we are particularly interested
in extracting paraphrase patterns at the constituent
level. These alignments can be made with existing
alignment tools such as the GIZA++ toolkit.
We measure the performance of our approaches
by comparing to human annotation of sub-
clusterings. The human task in itself is hard. For
instance, is we look at the incorrect examples in
Table 3, the difficulty of distinguishing between
paraphrases and non-paraphrases is apparent. In
future research we would like to investigate the
task of judging paraphrases. The next step we
would like to take towards automatic paraphrase
generation, is to identify the differences between
paraphrases at the constituent level. This task has
in fact been performed by human annotators in the
DAESO-project. A logical next step would be to
learn to align the different constituents on our ex-
tracted paraphrases in an unsupervised way.
</bodyText>
<sectionHeader confidence="0.994207" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999927833333333">
Thanks are due to the Netherlands Organization
for Scientific Research (NWO) and to the Dutch
HLT Stevin programme. Thanks also to Wauter
Bosma for originally mining the headlines from
Google News. For more information on DAESO,
please visit daeso.uvt.nl.
</bodyText>
<sectionHeader confidence="0.998135" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998951065573771">
Regina Barzilay and Noemie Elhadad. 2003. Sentence
alignment for monolingual comparable corpora. In
Proceedings of the 2003 conference on Empirical
methods in natural language processing, pages 25–
32.
Chris Callison-Burch, Philipp Koehn, and Miles Os-
borne. 2006. Improved statistical machine transla-
tion using paraphrases. In Proceedings of the main
conference on Human Language Technology Con-
ference of the North American Chapter of the Asso-
ciation of Computational Linguistics, pages 17–24.
Bill Dolan, Chris Quirk, and Chris Brockett. 2004.
Unsupervised construction of large paraphrase cor-
pora: exploiting massively parallel news sources. In
COLING ’04: Proceedings of the 20th international
conference on Computational Linguistics, page 350.
David Kauchak and Regina Barzilay. 2006. Para-
phrasing for automatic evaluation. In Proceedings
of the Human Language Technology Conference of
the NAACL, Main Conference, pages 455–462, June.
Kevin Knight and Daniel Marcu. 2002. Summa-
rization beyond sentence extraction: a probabilis-
tic approach to sentence compression. Artif. Intell.,
139(1):91–107.
Wessel Kraaij and Rene Pohlmann. 1994. Porters
stemming algorithm for dutch. In Informatieweten-
schap 1994: Wetenschappelijke bijdragen aan de
derde STINFON Conferentie, pages 167–180.
Dekang Lin and Patrick Pantel. 2001. Dirt: Discov-
ery of inference rules from text. In KDD ’01: Pro-
ceedings of the seventh ACM SIGKDD international
conference on Knowledge discovery and data min-
ing, pages 323–328.
Erwin Marsi and Emiel Krahmer. 2007. Annotating
a parallel monolingual treebank with semantic sim-
ilarity relations. In he Sixth International Workshop
on Treebanks and Linguistic Theories (TLT’07).
Rani Nelken and Stuart M. Shieber. 2006. Towards ro-
bust context-sensitive sentence alignment for mono-
lingual corpora. In Proceedings of the 11th Confer-
ence of the European Chapter of the Association for
Computational Linguistics (EACL-06), 3–7 April.
Ted Pedersen and Anagha Kulkarni. 2006. Automatic
cluster stopping with criterion functions and the gap
statistic. In Proceedings of the 2006 Conference
of the North American Chapter of the Association
for Computational Linguistics on Human Language
Technology, pages 276–279.
Stefan Riezler, Alexander Vasserman, Ioannis
Tsochantaridis, Vibhu O. Mittal, and Yi Liu. 2007.
Statistical machine translation for query expansion
in answer retrieval. In ACL.
Grazia Russo-Lassner, Jimmy Lin, and Philip Resnik.
2006. A paraphrase-based approach to machine
translation evaluation. Technical report, University
of Maryland, College Park.
Liang Zhou, Chin-Yew Lin, and Eduard Hovy. 2006.
Re-evaluating machine translation results with para-
phrase support. In Proceedings of the 2006 Con-
ference on Empirical Methods in Natural Language
Processing, pages 77–84, July.
</reference>
<page confidence="0.998498">
125
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.139921">
<title confidence="0.99994">Clustering and Matching Headlines for Automatic Paraphrase Acquisition</title>
<author confidence="0.987863">Sander Wubben</author>
<author confidence="0.987863">Antal van_den_Bosch</author>
<author confidence="0.987863">Emiel Krahmer</author>
<author confidence="0.987863">Erwin</author>
<affiliation confidence="0.542427">Tilburg centre for Creative Tilburg</affiliation>
<address confidence="0.223682">The</address>
<abstract confidence="0.9997248">For developing a data-driven text rewriting algorithm for paraphrasing, it is essential to have a monolingual corpus of aligned paraphrased sentences. News article headlines are a rich source of paraphrases; they tend to describe the same event in various different ways, and can easily be obtained from the web. We compare two methods of aligning headlines to construct such an aligned corpus of paraphrases, one based on clustering, and the other on pairwise similarity-based matching. We show that the latter performs best on the task of aligning paraphrastic headlines.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Noemie Elhadad</author>
</authors>
<title>Sentence alignment for monolingual comparable corpora.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 conference on Empirical methods in natural language processing,</booktitle>
<pages>25--32</pages>
<contexts>
<context position="3260" citStr="Barzilay and Elhadad, 2003" startWordPosition="495" endWordPosition="499">araphrases (Dolan et al., 2004; Nelken and Shieber, 2006). We use this method to collect a large amount of aligned paraphrases in an automatic fashion. 2 Method We aim to build a high-quality paraphrase corpus. Considering the fact that this corpus will be the basic resource of a paraphrase generation system, we need it to be as free of errors as possible, because errors will propagate throughout the system. This implies that we focus on obtaining a high precision in the paraphrases collection process. Where previous work has focused on aligning news-items at the paragraph and sentence level (Barzilay and Elhadad, 2003), we choose to focus on aligning the headlines of news articles. We think this approach will enable us to harvest reliable training material for paraphrase generation quickly and efficiently, without having to worry too much about the problems that arise when trying to align complete news articles. For the development of our system we use data which was obtained in the DAESO-project. This project is an ongoing effort to build a Parallel Monolingual Treebank for Dutch (Marsi Proceedings of the 12th European Workshop on Natural Language Generation, pages 122–125, Athens, Greece, 30 – 31 March 20</context>
<context position="5977" citStr="Barzilay and Elhadad (2003)" startWordPosition="943" endWordPosition="946">but their relation can only be understood properly with world knowledge. Also, there are numerous headlines that can not be sub-clustered, such as the first three headlines shown in the example. We use these annotated clusters as development and test data in developing a method to automatically obtain paraphrase pairs from headline clusters. We divide the annotated headline clusters in a development set of 40 clusters, while the remainder is used as test data. The headlines are stemmed using the porter stemmer for Dutch (Kraaij and Pohlmann, 1994). Instead of a word overlap measure as used by Barzilay and Elhadad (2003), we use a modified TF*IDF word score as was suggested by Nelken and Shieber (2006). Each sentence is viewed as a document, and each original cluster as a collection of documents. For each stemmed word i in sentence j, TFi�j is a binary variable indicating if the word occurs in the sentence or not. The TF*IDF score is then: |D| TF.IDFi = TFi�j · log |{dj : ti E dj}| |D |is the total number of sentences in the cluster and |{dj : ti E dj} |is the number of sentences that contain the term ti. These scores are used in a vector space representation. The similarity between headlines can be calculate</context>
<context position="9057" citStr="Barzilay and Elhadad (2003)" startWordPosition="1481" endWordPosition="1485"> not only the ones that are very similar. Through optimization on our development set, we find an optimal threshold for the PK1 algorithm thpk1 = 1. For each original cluster, k-means clustering is then performed using the k found by the cluster stopping function. In each newly obtained cluster all headlines can be aligned to each other. 2.2 Pairwise similarity Our second approach is to calculate the similarity between pairs of headlines directly. If the similarity exceeds a certain threshold, the pair is accepted as a paraphrase pair. If it is below the threshold, it is rejected. However, as Barzilay and Elhadad (2003) have pointed out, sentence mapping in this way is only effective to a certain extent. Beyond that point, context is needed. With this in mind, we adopt two thresholds and the Cosine similarity function to calculate the similarity between two sentences: Type Precision Recall k-means clustering 0.91 0.43 clusters only k-means clustering 0.66 0.44 all headlines pairwise similarity 0.93 0.39 clusters only pairwise similarity 0.76 0.41 all headlines Table 2: Precision and Recall for both methods Playstation 3 more expensive than competitor Playstation 3 will become more expensive than Xbox 360 Son</context>
</contexts>
<marker>Barzilay, Elhadad, 2003</marker>
<rawString>Regina Barzilay and Noemie Elhadad. 2003. Sentence alignment for monolingual comparable corpora. In Proceedings of the 2003 conference on Empirical methods in natural language processing, pages 25– 32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Miles Osborne</author>
</authors>
<title>Improved statistical machine translation using paraphrases.</title>
<date>2006</date>
<booktitle>In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics,</booktitle>
<pages>17--24</pages>
<contexts>
<context position="1977" citStr="Callison-Burch et al., 2006" startWordPosition="284" endWordPosition="287">xt-to-text generation it is important to know which words and phrases are semantically close or exchangable in which contexts. While there are various resources available that capture such knowledge at the word level (e.g., synset knowledge in WordNet), this kind of information is much harder to get by at the phrase level. Therefore, paraphrase acquisition can be considered an important technology for producing resources for text-to-text generation. Paraphrase generation has already proven to be valuable for Question Answering (Lin and Pantel, 2001; Riezler et al., 2007), Machine Translation (Callison-Burch et al., 2006) and the evaluation thereof (Russo-Lassner et al., 2006; Kauchak and Barzilay, 2006; Zhou et al., 2006), but also for text simplification and explanation. In the study described in this paper, we make an effort to collect Dutch paraphrases from news article headlines in an unsupervised way to be used in future paraphrase generation. News article headlines are abundant on the web, and are already grouped by news aggregators such as Google News. These services collect multiple articles covering the same event. Crawling such news aggregators is an effective way of collecting related articles whic</context>
</contexts>
<marker>Callison-Burch, Koehn, Osborne, 2006</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, and Miles Osborne. 2006. Improved statistical machine translation using paraphrases. In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, pages 17–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bill Dolan</author>
<author>Chris Quirk</author>
<author>Chris Brockett</author>
</authors>
<title>Unsupervised construction of large paraphrase corpora: exploiting massively parallel news sources.</title>
<date>2004</date>
<booktitle>In COLING ’04: Proceedings of the 20th international conference on Computational Linguistics,</booktitle>
<pages>350</pages>
<contexts>
<context position="2663" citStr="Dolan et al., 2004" startWordPosition="395" endWordPosition="398"> Barzilay, 2006; Zhou et al., 2006), but also for text simplification and explanation. In the study described in this paper, we make an effort to collect Dutch paraphrases from news article headlines in an unsupervised way to be used in future paraphrase generation. News article headlines are abundant on the web, and are already grouped by news aggregators such as Google News. These services collect multiple articles covering the same event. Crawling such news aggregators is an effective way of collecting related articles which can straightforwardly be used for the acquisition of paraphrases (Dolan et al., 2004; Nelken and Shieber, 2006). We use this method to collect a large amount of aligned paraphrases in an automatic fashion. 2 Method We aim to build a high-quality paraphrase corpus. Considering the fact that this corpus will be the basic resource of a paraphrase generation system, we need it to be as free of errors as possible, because errors will propagate throughout the system. This implies that we focus on obtaining a high precision in the paraphrases collection process. Where previous work has focused on aligning news-items at the paragraph and sentence level (Barzilay and Elhadad, 2003), w</context>
</contexts>
<marker>Dolan, Quirk, Brockett, 2004</marker>
<rawString>Bill Dolan, Chris Quirk, and Chris Brockett. 2004. Unsupervised construction of large paraphrase corpora: exploiting massively parallel news sources. In COLING ’04: Proceedings of the 20th international conference on Computational Linguistics, page 350.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Kauchak</author>
<author>Regina Barzilay</author>
</authors>
<title>Paraphrasing for automatic evaluation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference,</booktitle>
<pages>455--462</pages>
<contexts>
<context position="2060" citStr="Kauchak and Barzilay, 2006" startWordPosition="296" endWordPosition="299">y close or exchangable in which contexts. While there are various resources available that capture such knowledge at the word level (e.g., synset knowledge in WordNet), this kind of information is much harder to get by at the phrase level. Therefore, paraphrase acquisition can be considered an important technology for producing resources for text-to-text generation. Paraphrase generation has already proven to be valuable for Question Answering (Lin and Pantel, 2001; Riezler et al., 2007), Machine Translation (Callison-Burch et al., 2006) and the evaluation thereof (Russo-Lassner et al., 2006; Kauchak and Barzilay, 2006; Zhou et al., 2006), but also for text simplification and explanation. In the study described in this paper, we make an effort to collect Dutch paraphrases from news article headlines in an unsupervised way to be used in future paraphrase generation. News article headlines are abundant on the web, and are already grouped by news aggregators such as Google News. These services collect multiple articles covering the same event. Crawling such news aggregators is an effective way of collecting related articles which can straightforwardly be used for the acquisition of paraphrases (Dolan et al., 2</context>
</contexts>
<marker>Kauchak, Barzilay, 2006</marker>
<rawString>David Kauchak and Regina Barzilay. 2006. Paraphrasing for automatic evaluation. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 455–462, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Summarization beyond sentence extraction: a probabilistic approach to sentence compression.</title>
<date>2002</date>
<journal>Artif. Intell.,</journal>
<volume>139</volume>
<issue>1</issue>
<contexts>
<context position="1274" citStr="Knight and Marcu, 2002" startWordPosition="180" endWordPosition="183">ligned corpus of paraphrases, one based on clustering, and the other on pairwise similarity-based matching. We show that the latter performs best on the task of aligning paraphrastic headlines. 1 Introduction In recent years, text-to-text generation has received increasing attention in the field of Natural Language Generation (NLG). In contrast to traditional concept-to-text systems, text-to-text generation systems convert source text to target text, where typically the source and target text share the same meaning to some extent. Applications of text-to-text generation include summarization (Knight and Marcu, 2002), questionanswering (Lin and Pantel, 2001), and machine translation. For text-to-text generation it is important to know which words and phrases are semantically close or exchangable in which contexts. While there are various resources available that capture such knowledge at the word level (e.g., synset knowledge in WordNet), this kind of information is much harder to get by at the phrase level. Therefore, paraphrase acquisition can be considered an important technology for producing resources for text-to-text generation. Paraphrase generation has already proven to be valuable for Question An</context>
</contexts>
<marker>Knight, Marcu, 2002</marker>
<rawString>Kevin Knight and Daniel Marcu. 2002. Summarization beyond sentence extraction: a probabilistic approach to sentence compression. Artif. Intell., 139(1):91–107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wessel Kraaij</author>
<author>Rene Pohlmann</author>
</authors>
<title>Porters stemming algorithm for dutch.</title>
<date>1994</date>
<booktitle>In Informatiewetenschap 1994: Wetenschappelijke bijdragen aan de derde STINFON Conferentie,</booktitle>
<pages>167--180</pages>
<contexts>
<context position="5903" citStr="Kraaij and Pohlmann, 1994" startWordPosition="930" endWordPosition="933"> sentences in the example. They do paraphrase each other to some extent, but their relation can only be understood properly with world knowledge. Also, there are numerous headlines that can not be sub-clustered, such as the first three headlines shown in the example. We use these annotated clusters as development and test data in developing a method to automatically obtain paraphrase pairs from headline clusters. We divide the annotated headline clusters in a development set of 40 clusters, while the remainder is used as test data. The headlines are stemmed using the porter stemmer for Dutch (Kraaij and Pohlmann, 1994). Instead of a word overlap measure as used by Barzilay and Elhadad (2003), we use a modified TF*IDF word score as was suggested by Nelken and Shieber (2006). Each sentence is viewed as a document, and each original cluster as a collection of documents. For each stemmed word i in sentence j, TFi�j is a binary variable indicating if the word occurs in the sentence or not. The TF*IDF score is then: |D| TF.IDFi = TFi�j · log |{dj : ti E dj}| |D |is the total number of sentences in the cluster and |{dj : ti E dj} |is the number of sentences that contain the term ti. These scores are used in a vect</context>
</contexts>
<marker>Kraaij, Pohlmann, 1994</marker>
<rawString>Wessel Kraaij and Rene Pohlmann. 1994. Porters stemming algorithm for dutch. In Informatiewetenschap 1994: Wetenschappelijke bijdragen aan de derde STINFON Conferentie, pages 167–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Dirt: Discovery of inference rules from text.</title>
<date>2001</date>
<booktitle>In KDD ’01: Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>323--328</pages>
<contexts>
<context position="1316" citStr="Lin and Pantel, 2001" startWordPosition="186" endWordPosition="189">lustering, and the other on pairwise similarity-based matching. We show that the latter performs best on the task of aligning paraphrastic headlines. 1 Introduction In recent years, text-to-text generation has received increasing attention in the field of Natural Language Generation (NLG). In contrast to traditional concept-to-text systems, text-to-text generation systems convert source text to target text, where typically the source and target text share the same meaning to some extent. Applications of text-to-text generation include summarization (Knight and Marcu, 2002), questionanswering (Lin and Pantel, 2001), and machine translation. For text-to-text generation it is important to know which words and phrases are semantically close or exchangable in which contexts. While there are various resources available that capture such knowledge at the word level (e.g., synset knowledge in WordNet), this kind of information is much harder to get by at the phrase level. Therefore, paraphrase acquisition can be considered an important technology for producing resources for text-to-text generation. Paraphrase generation has already proven to be valuable for Question Answering (Lin and Pantel, 2001; Riezler et </context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. Dirt: Discovery of inference rules from text. In KDD ’01: Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining, pages 323–328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erwin Marsi</author>
<author>Emiel Krahmer</author>
</authors>
<title>Annotating a parallel monolingual treebank with semantic similarity relations.</title>
<date>2007</date>
<booktitle>In he Sixth International Workshop on Treebanks and Linguistic Theories (TLT’07).</booktitle>
<marker>Marsi, Krahmer, 2007</marker>
<rawString>Erwin Marsi and Emiel Krahmer. 2007. Annotating a parallel monolingual treebank with semantic similarity relations. In he Sixth International Workshop on Treebanks and Linguistic Theories (TLT’07).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rani Nelken</author>
<author>Stuart M Shieber</author>
</authors>
<title>Towards robust context-sensitive sentence alignment for monolingual corpora.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL-06),</booktitle>
<pages>3--7</pages>
<contexts>
<context position="2690" citStr="Nelken and Shieber, 2006" startWordPosition="399" endWordPosition="402">u et al., 2006), but also for text simplification and explanation. In the study described in this paper, we make an effort to collect Dutch paraphrases from news article headlines in an unsupervised way to be used in future paraphrase generation. News article headlines are abundant on the web, and are already grouped by news aggregators such as Google News. These services collect multiple articles covering the same event. Crawling such news aggregators is an effective way of collecting related articles which can straightforwardly be used for the acquisition of paraphrases (Dolan et al., 2004; Nelken and Shieber, 2006). We use this method to collect a large amount of aligned paraphrases in an automatic fashion. 2 Method We aim to build a high-quality paraphrase corpus. Considering the fact that this corpus will be the basic resource of a paraphrase generation system, we need it to be as free of errors as possible, because errors will propagate throughout the system. This implies that we focus on obtaining a high precision in the paraphrases collection process. Where previous work has focused on aligning news-items at the paragraph and sentence level (Barzilay and Elhadad, 2003), we choose to focus on aligni</context>
<context position="6060" citStr="Nelken and Shieber (2006)" startWordPosition="958" endWordPosition="961">are numerous headlines that can not be sub-clustered, such as the first three headlines shown in the example. We use these annotated clusters as development and test data in developing a method to automatically obtain paraphrase pairs from headline clusters. We divide the annotated headline clusters in a development set of 40 clusters, while the remainder is used as test data. The headlines are stemmed using the porter stemmer for Dutch (Kraaij and Pohlmann, 1994). Instead of a word overlap measure as used by Barzilay and Elhadad (2003), we use a modified TF*IDF word score as was suggested by Nelken and Shieber (2006). Each sentence is viewed as a document, and each original cluster as a collection of documents. For each stemmed word i in sentence j, TFi�j is a binary variable indicating if the word occurs in the sentence or not. The TF*IDF score is then: |D| TF.IDFi = TFi�j · log |{dj : ti E dj}| |D |is the total number of sentences in the cluster and |{dj : ti E dj} |is the number of sentences that contain the term ti. These scores are used in a vector space representation. The similarity between headlines can be calculated by using a similarity function on the headline vectors, such as cosine similarity</context>
</contexts>
<marker>Nelken, Shieber, 2006</marker>
<rawString>Rani Nelken and Stuart M. Shieber. 2006. Towards robust context-sensitive sentence alignment for monolingual corpora. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL-06), 3–7 April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Anagha Kulkarni</author>
</authors>
<title>Automatic cluster stopping with criterion functions and the gap statistic.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology,</booktitle>
<pages>276--279</pages>
<contexts>
<context position="7249" citStr="Pedersen and Kulkarni (2006)" startWordPosition="1170" endWordPosition="1173">line vectors, such as cosine similarity. 2.1 Clustering Our first approach is to use a clustering algorithm to cluster similar headlines. The original Google News headline clusters are reclustered into finer grained sub-clusters. We use the k-means implementation in the CLUTO1 software package. The k-means algorithm is an algorithm that assigns k centers to represent the clustering of n points (k &lt; n) in a vector space. The total intra-cluster variances is minimized by the function (xj − µi)2 where µi is the centroid of all the points xj E Si. The PK1 cluster-stopping algorithm as proposed by Pedersen and Kulkarni (2006) is used to find the optimal k for each sub-cluster: Cr(k) − mean(Cr[1...ΔK]) PK1(k) = std(Cr[1...ΔK]) Here, Cr is a criterion function, which measures the ratio of withincluster similarity to betweencluster similarity. As soon as PK1(k) exceeds a threshold, k −1 is selected as the optimum number of clusters. To find the optimal threshold value for clusterstopping, optimization is performed on the development data. Our optimization function is an Fscore: _ (1 + β2) · (precision · recall) F� (β2 · precision + recall) 1http://glaros.dtc.umn.edu/gkhome/views/cluto/ k i=1 V = � x;ESi 123 We evalua</context>
</contexts>
<marker>Pedersen, Kulkarni, 2006</marker>
<rawString>Ted Pedersen and Anagha Kulkarni. 2006. Automatic cluster stopping with criterion functions and the gap statistic. In Proceedings of the 2006 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, pages 276–279.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Riezler</author>
<author>Alexander Vasserman</author>
<author>Ioannis Tsochantaridis</author>
<author>Vibhu O Mittal</author>
<author>Yi Liu</author>
</authors>
<title>Statistical machine translation for query expansion in answer retrieval.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1926" citStr="Riezler et al., 2007" startWordPosition="278" endWordPosition="281">ntel, 2001), and machine translation. For text-to-text generation it is important to know which words and phrases are semantically close or exchangable in which contexts. While there are various resources available that capture such knowledge at the word level (e.g., synset knowledge in WordNet), this kind of information is much harder to get by at the phrase level. Therefore, paraphrase acquisition can be considered an important technology for producing resources for text-to-text generation. Paraphrase generation has already proven to be valuable for Question Answering (Lin and Pantel, 2001; Riezler et al., 2007), Machine Translation (Callison-Burch et al., 2006) and the evaluation thereof (Russo-Lassner et al., 2006; Kauchak and Barzilay, 2006; Zhou et al., 2006), but also for text simplification and explanation. In the study described in this paper, we make an effort to collect Dutch paraphrases from news article headlines in an unsupervised way to be used in future paraphrase generation. News article headlines are abundant on the web, and are already grouped by news aggregators such as Google News. These services collect multiple articles covering the same event. Crawling such news aggregators is a</context>
</contexts>
<marker>Riezler, Vasserman, Tsochantaridis, Mittal, Liu, 2007</marker>
<rawString>Stefan Riezler, Alexander Vasserman, Ioannis Tsochantaridis, Vibhu O. Mittal, and Yi Liu. 2007. Statistical machine translation for query expansion in answer retrieval. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grazia Russo-Lassner</author>
<author>Jimmy Lin</author>
<author>Philip Resnik</author>
</authors>
<title>A paraphrase-based approach to machine translation evaluation.</title>
<date>2006</date>
<tech>Technical report,</tech>
<institution>University of Maryland, College Park.</institution>
<contexts>
<context position="2032" citStr="Russo-Lassner et al., 2006" startWordPosition="292" endWordPosition="295"> and phrases are semantically close or exchangable in which contexts. While there are various resources available that capture such knowledge at the word level (e.g., synset knowledge in WordNet), this kind of information is much harder to get by at the phrase level. Therefore, paraphrase acquisition can be considered an important technology for producing resources for text-to-text generation. Paraphrase generation has already proven to be valuable for Question Answering (Lin and Pantel, 2001; Riezler et al., 2007), Machine Translation (Callison-Burch et al., 2006) and the evaluation thereof (Russo-Lassner et al., 2006; Kauchak and Barzilay, 2006; Zhou et al., 2006), but also for text simplification and explanation. In the study described in this paper, we make an effort to collect Dutch paraphrases from news article headlines in an unsupervised way to be used in future paraphrase generation. News article headlines are abundant on the web, and are already grouped by news aggregators such as Google News. These services collect multiple articles covering the same event. Crawling such news aggregators is an effective way of collecting related articles which can straightforwardly be used for the acquisition of </context>
</contexts>
<marker>Russo-Lassner, Lin, Resnik, 2006</marker>
<rawString>Grazia Russo-Lassner, Jimmy Lin, and Philip Resnik. 2006. A paraphrase-based approach to machine translation evaluation. Technical report, University of Maryland, College Park.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Zhou</author>
<author>Chin-Yew Lin</author>
<author>Eduard Hovy</author>
</authors>
<title>Re-evaluating machine translation results with paraphrase support.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>77--84</pages>
<contexts>
<context position="2080" citStr="Zhou et al., 2006" startWordPosition="300" endWordPosition="303">ich contexts. While there are various resources available that capture such knowledge at the word level (e.g., synset knowledge in WordNet), this kind of information is much harder to get by at the phrase level. Therefore, paraphrase acquisition can be considered an important technology for producing resources for text-to-text generation. Paraphrase generation has already proven to be valuable for Question Answering (Lin and Pantel, 2001; Riezler et al., 2007), Machine Translation (Callison-Burch et al., 2006) and the evaluation thereof (Russo-Lassner et al., 2006; Kauchak and Barzilay, 2006; Zhou et al., 2006), but also for text simplification and explanation. In the study described in this paper, we make an effort to collect Dutch paraphrases from news article headlines in an unsupervised way to be used in future paraphrase generation. News article headlines are abundant on the web, and are already grouped by news aggregators such as Google News. These services collect multiple articles covering the same event. Crawling such news aggregators is an effective way of collecting related articles which can straightforwardly be used for the acquisition of paraphrases (Dolan et al., 2004; Nelken and Shie</context>
</contexts>
<marker>Zhou, Lin, Hovy, 2006</marker>
<rawString>Liang Zhou, Chin-Yew Lin, and Eduard Hovy. 2006. Re-evaluating machine translation results with paraphrase support. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 77–84, July.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>