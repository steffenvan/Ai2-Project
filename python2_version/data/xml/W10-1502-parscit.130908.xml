<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000229">
<title confidence="0.957394">
Building a Korean Web Corpus for Analyzing Learner Language
</title>
<author confidence="0.993436">
Markus Dickinson Ross Israel Sun-Hee Lee
</author>
<affiliation confidence="0.999934">
Indiana University Indiana University Wellesley College
</affiliation>
<email confidence="0.998554">
md7@indiana.edu raisrael@indiana.edu slee6@wellesley.edu
</email>
<sectionHeader confidence="0.995629" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999584166666667">
Post-positional particles are a significant
source of errors for learners of Korean. Fol-
lowing methodology that has proven effective
in handling English preposition errors, we are
beginning the process of building a machine
learner for particle error detection in L2 Ko-
rean writing. As a first step, however, we must
acquire data, and thus we present a method-
ology for constructing large-scale corpora of
Korean from the Web, exploring the feasibil-
ity of building corpora appropriate for a given
topic and grammatical construction.
</bodyText>
<sectionHeader confidence="0.998986" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999848894736842">
Applications for assisting second language learners
can be extremely useful when they make learners
more aware of the non-native characteristics in their
writing (Amaral and Meurers, 2006). Certain con-
structions, such as English prepositions, are difficult
to characterize by grammar rules and thus are well-
suited for machine learning approaches (Tetreault
and Chodorow, 2008; De Felice and Pulman, 2008).
Machine learning techniques are relatively portable
to new languages, but new languages bring issues in
terms of defining the language learning problem and
in terms of acquiring appropriate data for training a
machine learner.
We focus in this paper mainly on acquiring data
for training a machine learning system. In partic-
ular, we are interested in situations where the task
is constant—e.g., detecting grammatical errors in
particles—but the domain might fluctuate. This is
the case when a learner is asked to write an essay on
</bodyText>
<page confidence="0.957953">
8
</page>
<bodyText confidence="0.999912323529412">
a prompt (e.g., “What do you hope to do in life?”),
and the prompts may vary by student, by semester,
by instructor, etc. By isolating a particular domain,
we can hope for greater degrees of accuracy; see,
for example, the high accuracies for domain-specific
grammar correction in Lee and Seneff (2006).
In this situation, we face the challenge of obtain-
ing data which is appropriate both for: a) the topic
the learners are writing about, and b) the linguistic
construction of interest, i.e., containing enough rel-
evant instances. In the ideal case, one could build
a corpus directly for the types of learner data to
analyze. Luckily, using the web as a data source
can provide such specialized corpora (Baroni and
Bernardini, 2004), in addition to larger, more gen-
eral corpora (Sharoff, 2006). A crucial question,
though, is how one goes about designing the right
web corpus for analyzing learner language (see, e.g.,
Sharoff, 2006, for other contexts)
The area of difficulty for language learners which
we focus on is that of Korean post-positional parti-
cles, akin to English prepositions (Lee et al., 2009;
Ko et al., 2004). Korean is an important language
to develop NLP techniques for (see, e.g., discussion
in Dickinson et al., 2008), presenting a variety of
features which are less prevalent in many Western
languages, such as agglutinative morphology, a rich
system of case marking, and relatively free word or-
der. Obtaining data is important in the general case,
as non-English languages tend to lack resources.
The correct usage of Korean particles relies on
knowing lexical, syntactic, semantic, and discourse
information (Lee et al., 2005), which makes this
challenging for both learners and machines (cf. En-
</bodyText>
<note confidence="0.9587535">
Proceedings of the NAACL HLT 2010 Sixth Web as Corpus Workshop, pages 8–16,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999643619047619">
glish determiners in Han et al., 2006). The only
other approach we know of, a parser-based one, had
very low precision (Dickinson and Lee, 2009). A
secondary contribution of this work is thus defin-
ing the particle error detection problem for a ma-
chine learner. It is important that the data represent
the relationships between specific lexical items: in
the comparable English case, for example, interest
is usually found with in: interest in/*with learning.
The basic framework we employ is to train a ma-
chine learner on correct Korean data and then apply
this system to learner text, to predict correct parti-
cle usage, which may differ from the learner’s (cf.
Tetreault and Chodorow, 2008). After describing the
grammatical properties of particles in section 2, we
turn to the general approach for obtaining relevant
web data in section 3, reporting basic statistics for
our corpora in section 4. We outline the machine
learing set-up in section 5 and present initial results
in section 6. These results help evaluate the best way
to build specialized corpora for learner language.
</bodyText>
<sectionHeader confidence="0.96606" genericHeader="method">
2 Korean particles
</sectionHeader>
<bodyText confidence="0.998572">
Similar to English prepositions, Korean postposi-
tional particles add specific meanings or grammat-
ical functions to nominals. However, a particle can-
not stand alone in Korean and needs to be attached
to the preceding nominal. More importantly, par-
ticles indicate a wide range of linguistic functions,
specifying grammatical functions, e.g., subject and
object; semantic roles; and discourse functions. In
(1), for instance, ka marks both the subject (func-
tion) and agent (semantic role), eykey the dative and
beneficiary; and so forth.1
</bodyText>
<equation confidence="0.4480695">
(1) Sumi-ka John-eykey chayk-ul ilhke-yo
Sumi-SBJ John-to book-OBJ read-polite
</equation>
<bodyText confidence="0.7976122">
‘Sumi reads a book to John.’
Particles can also combine with nominals to form
modifiers, adding meanings of time, location, instru-
ment, possession, and so forth, as shown in (2). Note
in this case that the marker ul/lul has multiple uses.2
</bodyText>
<footnote confidence="0.972201">
1We use the Yale Romanization scheme for writing Korean.
2Ul/lul, un/nun, etc. only differ phonologically.
</footnote>
<listItem confidence="0.982918333333333">
(2) Sumi-ka John-uy cip-eyse ku-lul
Sumi-SBJ John-GEN house-LOC he-OBJ
twu sikan-ul kitaly-ess-ta.
</listItem>
<bodyText confidence="0.9551651">
two hours-OBJ wait-PAST-END
‘Sumi waited for John for (the whole) two hours in
his house.’
There are also particles associated with discourse
meanings. For example, in (3) the topic marker nun
is used to indicate old information or a discourse-
salient entity, while the delimiter to implies that
there is someone else Sumi likes. In this paper, we
focus on syntactic/semantic particle usage for nom-
inals, planning to extend to other cases in the future.
</bodyText>
<listItem confidence="0.9518535">
(3) Sumi-nun John-to cohahay.
Sumi-TOP John-also like
</listItem>
<subsectionHeader confidence="0.381753">
‘Sumi likes John also.’
</subsectionHeader>
<bodyText confidence="0.987933111111111">
Due to these complex linguistic properties, parti-
cles are one of the most difficult topics for Korean
language learners. In (4b), for instance, a learner
might replace a subject particle (as in (4a)) with an
object (Dickinson et al., 2008). Ko et al. (2004) re-
port that particle errors were the second most fre-
quent error in a study across different levels of Ko-
rean learners, and errors persist across levels (see
also Lee et al., 2009).
</bodyText>
<listItem confidence="0.84069">
(4) a. Sumi-nun chayk-i philyohay-yo
Sumi-TOP book-SBJ need-polite
</listItem>
<figure confidence="0.732558">
‘Sumi needs a book.’
b. *Sumi-nun chayk-ul philyohay-yo
Sumi-TOP book-OBJ need-polite
‘Sumi needs a book.’
</figure>
<sectionHeader confidence="0.989117" genericHeader="method">
3 Approach
</sectionHeader>
<subsectionHeader confidence="0.999996">
3.1 Acquiring training data
</subsectionHeader>
<bodyText confidence="0.9993902">
Due to the lexical relationships involved, machine
learning has proven to be a good method for sim-
ilar NLP problems like detecting errors in En-
glish preposition use. For example Tetreault and
Chodorow (2008) use a maximum entropy classifier
to build a model of correct preposition usage, with
7 million instances in their training set, and Lee and
Knutsson (2008) use memory-based learning, with
10 million sentences in their training set. In expand-
ing the paradigm to other languages, one problem
</bodyText>
<page confidence="0.995034">
9
</page>
<bodyText confidence="0.999707210526316">
is a dearth of data. It seems like a large data set is
essential for moving forward.
For Korean, there are at least two corpora pub-
licly available right now, the Penn Korean Treebank
(Han et al., 2002), with hundreds of thousands of
words, and the Sejong Corpus (a.k.a., The Korean
National Corpus, The National Institute of Korean
Language, 2007), with tens of millions of words.
While we plan to include the Sejong corpus in fu-
ture data, there are several reasons we pursue a dif-
ferent tack here. First, not every language has such
resources, and we want to work towards a language-
independent platform of data acquisition. Secondly,
these corpora may not be a good model for the kinds
of topics learners write about. For example, news
texts are typically written more formally than learner
writing. We want to explore ways to quickly build
topic-specific corpora, and Web as Corpus (WaC)
technology gives us tools to do this.3
</bodyText>
<subsectionHeader confidence="0.999954">
3.2 Web as Corpus
</subsectionHeader>
<bodyText confidence="0.999913">
To build web corpora, we use BootCat (Baroni and
Bernardini, 2004). The process is an iterative algo-
rithm to bootstrap corpora, starting with various seed
terms. The procedure is as follows:
</bodyText>
<listItem confidence="0.999308833333333">
1. Select initial seeds (terms).
2. Combine seeds randomly.
3. Run Google/Yahoo queries.
4. Retrieve corpus.
5. Extract new seeds via corpus comparison.
6. Repeat steps #2-#5.
</listItem>
<bodyText confidence="0.9999186">
For non-ASCII languages, one needs to check
the encoding of webpages in order to convert the
text into UTF-8 for output, as has been done for,
e.g., Japanese (e.g., Erjavec et al., 2008; Baroni and
Ueyama, 2004). Using a UTF-8 version of Boot-
Cat, we modified the system by using a simple Perl
module (Encode::Guess) to look for the EUC-
KR encoding of most Korean webpages and switch
it to UTF-8. The pages already in UTF-8 do not need
to be changed.
</bodyText>
<subsectionHeader confidence="0.99985">
3.3 Obtaining data
</subsectionHeader>
<bodyText confidence="0.967346238095238">
A crucial first step in constructing a web corpus is
the selection of appropriate seed terms for construct-
ing the corpus (e.g., Sharoff, 2006; Ueyama, 2006).
3Tetreault and Chodorow (2009) use the web to derive
learner errors; our work, however, tries to obtain correct data.
In our particular case, this begins the question of
how one builds a corpus which models native Ko-
rean and which provides appropriate data for the task
of particle error detection. The data should be genre-
appropriate and contain enough instances of the par-
ticles learners know and used in ways they are ex-
pected to use them (e.g., as temporal modifiers). A
large corpus will likely satisfy these criteria, but has
the potential to contain distracting information. In
Korean, for example, less formal writing often omits
particles, thereby biasing a machine learner towards
under-guessing particles. Likewise, a topic with dif-
ferent typical arguments than the one in question
may mislead the machine. We compare the effec-
tiveness of corpora built in different ways in training
a machine learner.
</bodyText>
<subsectionHeader confidence="0.970637">
3.3.1 A general corpus
</subsectionHeader>
<bodyText confidence="0.9993108">
To construct a general corpus, we identify words
likely to be in a learner’s lexicon, using a list of 50
nouns for beginning Korean students for seeds. This
includes basic vocabulary entries like the words for
mother, father, cat, dog, student, teacher, etc.
</bodyText>
<subsectionHeader confidence="0.99042">
3.3.2 A focused corpus
</subsectionHeader>
<bodyText confidence="0.981273153846154">
Since we often know what domain4 learner es-
says are written about, we experiment with building
a more topic-appropriate corpus. Accordingly, we
select a smaller set of 10 seed terms based on the
range of topics covered in our test corpus (see sec-
tion 6.1), shown in figure 1. As a first trial, we select
terms that are, like the aforementioned general cor-
pus seeds, level-appropriate for learners of Korean.
han-kwuk ‘Korea’ sa-lam ‘person(s)’
han-kwuk-e ‘Korean (lg.)’ chin-kwu ‘friend’
kyey-cel ‘season’ ga-jok ‘family’
hayng-pok ‘happiness’ wun-tong ‘exercise’
ye-hayng ‘travel’ mo-im ‘gathering’
</bodyText>
<figureCaption confidence="0.994925">
Figure 1: Seed terms for the focused corpus
</figureCaption>
<subsectionHeader confidence="0.950966">
3.3.3 A second focused corpus
</subsectionHeader>
<bodyText confidence="0.99996175">
There are several issues with the quality of data
we obtain from our focused terms. From an ini-
tial observation (see section 4.1), the difficulty stems
in part from the simplicity of the seed terms above,
</bodyText>
<footnote confidence="0.912919">
4By domain, we refer to the subject of a discourse.
</footnote>
<page confidence="0.997784">
10
</page>
<bodyText confidence="0.999882555555556">
leading to, for example, actual Korean learner data.
To avoid some of this noise, we use a second set of
seed terms, representing relevant words in the same
domains, but of a more advanced nature, i.e., topic-
appropriate words that may be outside of a typical
learner’s lexicon. Our hypothesis is that this is more
likely to lead to native, quality Korean. For each
one of the simple words above, we posit two more
advanced words, as given in figure 2.
</bodyText>
<figure confidence="0.9349629">
kyo-sa ‘teacher’ in-kan ‘human’
phyung-ka ‘evaluation’ cik-cang ‘workplace’
pen-yuk ‘translation’ wu-ceng ‘friendship’
mwun-hak ‘literature’ sin-loy ‘trust’
ci-kwu ‘earth’ cwu-min ‘resident’
swun-hwan ‘circulation’ kwan-kye ‘relation’
myeng-sang ‘meditation’ co-cik ‘organization’
phyeng-hwa ‘peace’ sik-i-yo-pep ‘diet’
tham-hem ‘exploration’ yen-mal ‘end of a year’
cwun-pi ‘preparation’ hayng-sa ‘event’
</figure>
<figureCaption confidence="0.997207">
Figure 2: Seed terms for the second focused corpus
</figureCaption>
<subsectionHeader confidence="0.98664">
3.4 Web corpus parameters
</subsectionHeader>
<bodyText confidence="0.99966825">
One can create corpora of varying size and general-
ity, by varying the parameters given to BootCaT. We
examine three parameters here.
Number of seeds The first way to vary the type
and size of corpus obtained is by varying the number
of seed terms. The exact words given to BootCaT af-
fect the domain of the resulting corpus, and utilizintg
a larger set of seeds leads to more potential to create
a bigger corpus. With 50 seed terms, for example,
there are 19,600 possible 3-tuples, while there are
only 120 possible 3-tuples for 10 seed terms, limit-
ing the relevant pages that can be returned.
For the general (G) corpus, we use: G1) all 50
seed terms, G2) 5 sets of 10 seeds, the result of split-
ting the 50 seeds randomly into 5 buckets, and G3)
5 sets of 20 seeds, which expand the 10-seed sets in
G2 by randomly selecting 10 other terms from the
remaining 40 seeds. This breakdown into 11 sets (1
G1, 5 G2, 5 G3) allows us to examine the effect of
using different amounts of general terms and facili-
tates easy comparison with the first focused corpus,
which has only 10 seed terms.
For the first focused (F1) corpus, we use: F11) the
10 seed terms, and F12) 5 sets of 20 seeds, obtained
by combining F11 with each seed set from G2. This
second group provides an opportunity to examine
what happens when augmenting the focused seeds
with more general terms; as such, this is a first step
towards larger corpora which retain some focus. For
the second focused corpus (F2), we simply use the
set of 20 seeds. We have 7 sets here (1 F11, 5 F12, 1
F2), giving us a total of 18 seed term sets at this step.
Tuple length One can also experiment with tuple
length in BootCat. The shorter the tuple, the more
webpages that can potentially be returned, as short
tuples are likely to occur in several pages (e.g., com-
pare the number of pages that all of person happi-
ness season occur in vs. person happiness season
exercise travel). On the other hand, longer tuples are
more likely truly relevant to the type of data of inter-
est, more likely to lead to well-formed language. We
experiment with tuples of different lengths, namely
3 and 5. With 2 different tuple lengths and 18 seed
sets, we now have 36 sets.
Number of queries We still need to specify how
many queries to send to the search engine. The max-
imum number is determined by the number of seeds
and the tuple size. For 3-word tuples with 10 seed
terms, for instance, there are 10 items to choose 3
objects from: (3) = 3!(1100−!3)! = 120 possibilities.
Using all combinations is feasible for small seed
sets, but becomes infeasible for larger seed sets, e.g.,
</bodyText>
<equation confidence="0.5956555">
(50) = 2,118, 760 possibilities. To reduce this, we
5
</equation>
<bodyText confidence="0.999465875">
opt for the following: for 3-word tuples, we generate
120 queries for all cases and 240 queries for the con-
ditions with 20 and 50 seeds. Similarly, for 5-word
tuples, we generate the maximum 252 queries with
10 seeds, and both 252 and 504 for the other condi-
tions. With the previous 36 sets (12 of which have
10 seed terms), evenly split between 3 and 5-word
tuples, we now have 60 total corpora, as in table 1.
</bodyText>
<table confidence="0.994135857142857">
tuple # of # of seeds F2
General F1
len. queries 10 20 50 10 20 20
3 120 5 5 1 1 5 1
240 n/a 5 1 n/a 5 1
5 252 5 5 1 1 5 1
504 n/a 5 1 n/a 5 1
</table>
<tableCaption confidence="0.999846">
Table 1: Number of corpora based on parameters
</tableCaption>
<page confidence="0.998433">
11
</page>
<bodyText confidence="0.999913611111111">
Other possibilities There are other ways to in-
crease the size of a web corpus using BootCaT. First,
one can increase the number of returned pages for a
particular query. We set the limit at 20, as anything
higher will more likely result in non-relevant data
for the focused corpora and/or duplicate documents.
Secondly, one can perform iterations of search-
ing, extracting new seed terms with every iteration.
Again, the concern is that by iterating away from the
initial seeds, a corpus could begin to lose focus. We
are considering both extensions for the future.
Language check One other constraint we use is to
specify the particular language of interest, namely
that we want Korean pages. This parameter is set
using the language option when collecting URLs.
We note that a fair amount of English, Chinese, and
Japanese appears in these pages, and we are cur-
rently developing our own Korean filter.
</bodyText>
<sectionHeader confidence="0.985628" genericHeader="method">
4 Corpus statistics
</sectionHeader>
<bodyText confidence="0.999874333333334">
To gauge the properties of size, genre, and degree of
particle usage in the corpora, independent of appli-
cation, basic statistics of the different web corpora
are given in table 2, where we average over multiple
corpora for conditions with 5 corpora.5
There are a few points to understand in the table.
First, it is hard to count true words in Korean, as
compounds are frequent, and particles have a de-
batable status. From a theory-neutral perspective,
we count ejels, which are tokens occurring between
white spaces. Secondly, we need to know about the
number of particles and number of nominals, i.e.,
words which could potentially bear particles, as our
machine learning paradigm considers any nominal a
test case for possible particle attachment. We use a
POS tagger (Han and Palmer, 2004) for this.
Some significant trends emerge when comparing
the corpora in the table. First of all, longer queries
(length 5) result in not only more returned unique
webpages, but also longer webpages on average than
shorter queries (length 3). This effect is most dra-
matic for the F2 corpora. The F2 corpora also exhibit
a higher ratio of particles to nominals than the other
web corpora, which means there will be more pos-
</bodyText>
<footnote confidence="0.931977">
5For the 252 5-tuple 20 seed General corpora, we average
over four corpora, due to POS tagging failure on the fifth corpus.
</footnote>
<bodyText confidence="0.9200415">
itive examples in the training data for the machine
learner based on the F2 corpora.
</bodyText>
<subsectionHeader confidence="0.994485">
4.1 Qualitative evaluation
</subsectionHeader>
<bodyText confidence="0.999981795454546">
In tandem with the basic statistics, it is also impor-
tant to gauge the quality of the Korean data from
a more qualitative perspective. Thus, we examined
the 120 3-tuple F1 corpus and discovered a number
of problems with the data.
First, there are issues concerning collecting data
which is not pure Korean. We find data extracted
from Chinese travel sites, where there is a mixture of
non-standard foreign words and unnatural-sounding
translated words in Korean. Ironically, we also find
learner data of Korean in our search for correct Ko-
rean data. Secondly, there are topics which, while
exhibiting valid forms of Korean, are too far afield
from what we expect learners to know, including re-
ligious sites with rare expressions; poems, which
commonly drop particles; gambling sites; and so
forth. Finally, there are cases of ungrammatical uses
of Korean, which are used in specific contexts not
appropriate for our purposes. These include newspa-
per titles, lists of personal names and addresses, and
incomplete phrases from advertisements and chats.
In these cases, we tend to find less particles.
Based on these properties, we developed the
aforementioned second focused corpus with more
advanced Korean words and examined the 240 3-
tuple F2 corpus. The F2 seeds allow us to capture a
greater percentage of well-formed data, namely data
from news articles, encyclopedic texts, and blogs
about more serious topics such as politics, literature,
and economics. While some of this data might be
above learners’ heads, it is, for the most part, well-
formed native-like Korean. Also, the inclusion of
learner data has been dramatically reduced. How-
ever, some of the same problems from the F1 corpus
persist, namely the inclusion of poetry, newspaper
titles, religious text, and non-Korean data.
Based on this qualitative analysis, it is clear that
we need to filter out more data than is currently be-
ing filtered, in order to obtain valid Korean of a type
which uses a sufficient number of particles in gram-
matical ways. In the future, we plan on restrict-
ing the genre, filtering based on the number of rare
words (e.g., religious words), and using a trigram
language model to check the validity.
</bodyText>
<page confidence="0.994094">
12
</page>
<table confidence="0.999835636363636">
Corpus Seeds Len. Queries URLs Ejel Particles Nominals
Total Avg. Total Avg. Total Avg.
Gen. 10 3 120 1096.2 1,140,394.6 1044.8 363,145.6 331.5 915,025 838.7
5 252 1388.2 2,430,346.4 1779.9 839,005.8 618.9 1,929,266.0 1415.3
20 3 120 1375.2 1,671,549.2 1222.1 540,918 394.9 1,350,976.6 988.6
3 240 2492.4 2,735,201.6 1099.4 889,089 357.3 2,195,703 882.4
5 252 1989.6 4,533,642.4 2356 1,359,137.2 724.5 3,180,560.6 1701.5
5 504 3487 7,463,776 2193.5 2,515,235.8 741.6 5,795,455.8 1709.7
50 3 120 1533 1,720,261 1122.1 584,065 380.9 1,339,308 873.6
3 240 2868 3,170,043 1105.3 1,049,975 366.1 2,506,995 874.1
5 252 1899.5 4,380,684.2 2397.6 1,501,358.7 821.5 3,523,746.2 1934.6
5 504 5636 5,735,859 1017.7 1,773,596 314.6 4,448,815 789.3
F1 10 3 120 1315 628,819 478.1 172,415 131.1 510,620 388.3
5 252 1577 1,364,885 865.4 436,985 277.1 1,069,898 678.4
20 3 120 1462.6 1,093,772.4 747.7 331,457.8 226.8 885,157.2 604.9
240 2637.2 1,962,741.8 745.2 595,570.6 226.1 1,585,730.4 602.1
5 252 2757.6 2,015,077.8 730.8 616,163.8 223.4 1,621,306.2 588
504 4734 3,093,140.4 652.9 754,610 159.8 1,993,104.4 422.1
F2 20 3 120 1417 1,054,925 744.5 358,297 252.9 829,416 585.3
240 2769 1,898,383 685.6 655,757 236.8 1,469,623 530.7
5 252 1727 4,510,742 2611.9 1,348,240 780.7 2,790,667 1615.9
504 2680 6,916,574 2580.8 2,077,171 775.1 4,380,571 1634.5
</table>
<tableCaption confidence="0.999495">
Table 2: Basic statistics of different web corpora
</tableCaption>
<bodyText confidence="0.9998918">
Note that one might consider building even larger
corpora from the start and using the filtering step to
winnow down the corpus for a particular application,
such as particle error detection. However, while re-
moving ungrammatical Korean is a process of re-
moving noise, identifying whether a corpus is about
traveling, for example, is a content-based decision.
Given that this is what a search engine is designed
to do, we prefer filtering based only on grammatical
and genre properties.
</bodyText>
<sectionHeader confidence="0.997599" genericHeader="method">
5 Classification
</sectionHeader>
<bodyText confidence="0.999986333333333">
We describe the classification paradigm used to de-
termine how effective each corpus is for detecting
correct particle usage; evaluation is in section 6.
</bodyText>
<subsectionHeader confidence="0.973725">
5.1 Machine learning paradigm
</subsectionHeader>
<bodyText confidence="0.999995352941176">
Based on the parallel between Korean particles and
English prepositions, we use preposition error de-
tection as a starting point for developing a classifier.
For prepositions, Tetreault and Chodorow (2008) ex-
tract 25 features to guess the correct preposition (out
of 34 selected prepositions), including features cap-
turing the lexical and grammatical context (e.g., the
words and POS tags in a two-word window around
the preposition) and features capturing various rel-
evant selectional properties (e.g., the head verb and
noun of the preceding VP and NP).
We are currently using TiMBL (Daelemans et al.,
2007) for development purposes, as it provides a
range of options for testing. Given that learner
data needs to be processed instantaneously and that
memory-based learning can take a long time to clas-
sify, we will revisit this choice in the future.
</bodyText>
<subsectionHeader confidence="0.9777605">
5.2 Defining features
5.2.1 Relevant properties of Korean
</subsectionHeader>
<bodyText confidence="0.996095545454545">
As discussed in section 2, Korean has major dif-
ferences from English, leading to different features.
First, the base word order of Korean is SOV, which
means that the following verb and following noun
could determine how the current word functions.
However, since Korean allows for freer word order
than English, we do not want to completely disre-
gard the previous noun or verb, either.
Secondly, the composition of words is different
than English. Words contain a stem and an arbitrary
number of suffixes, which may be derivational mor-
</bodyText>
<page confidence="0.997872">
13
</page>
<bodyText confidence="0.999933909090909">
phemes as well as particles, meaning that we must
consider sub-word features, i.e., segment words into
their component morphemes.
Finally, particles have more functions than prepo-
sitions, requiring a potentially richer space of fea-
tures. Case marking, for example, is even more de-
pendent upon the word’s grammatical function in
a sentence. In order to ensure that our system can
correctly handle all of the typical relations between
words without failing on less frequent constructions,
we need (large amounts of) appropriate data.
</bodyText>
<subsectionHeader confidence="0.942646">
5.2.2 Feature set
</subsectionHeader>
<bodyText confidence="0.966017405405405">
To begin with, we segment and POS tag the text,
using a hybrid (trigram + rule-based) morphological
tagger for Korean (Han and Palmer, 2004). This seg-
mentation phase means that we can define subword
features and isolate the particles in question. For our
features, we break each word into: a) its stem and b)
its combined affixes (excluding particles), and each
of these components has its own POS, possibly a
combined tag (e.g., EPF+EFN), with tags from the
Penn Korean Treebank (Han et al., 2002).
The feature vector uses a five word window that
includes the target word and two words on either
side for context. Each word is broken down into four
features: stem, affixes, stem POS, and affixes POS.
Given the importance of surrounding noun and verbs
for attachment in Korean, we have features for the
preceding as well as the following noun and verb.
For the noun/verb features, only the stem is used, as
this is largely a semantically-based property.
In terms of defining a class, if the target word’s
affixes contain a particle, it is removed and used as
the basis for the class; otherwise the class is NONE.
We also remove particles in the context affixes, as
we cannot rely on surrounding learner particles.
As an example, consider predicting the particle
for the word Yenge (‘English’) in (5a). We gener-
ate the instance in (5b). The first five lines refer
to the previous two words, the target word, and the
following two words, each split into stem and suf-
fixes along with their POS tags, and with particles
removed. The sixth line contains the stems of the
preceding and following noun and verb, and finally,
there is the class (YES/NO).
(5) a. Mikwuk-eyse sal-myense
America-in live-while
Yenge-man-ul cip-eyse ss-ess-eyo.
English-only-OBJ home-at use-Past-Decl
</bodyText>
<table confidence="0.922255888888889">
‘While living in America, (I/she/he) used only
English at home.’
b. Mikwuk NPR NONE NONE
sal VV myense ECS
Yenge NPR NONE NONE
cip NNC NONE NONE
ss VV ess+eyo EPF+EFN
sal Mikwuk ss cip
YES
</table>
<bodyText confidence="0.999711714285714">
For the purposes of evaluating the different cor-
pora, we keep the task simple and only guess YES
or NO for the existence of a particle. We envision
this as a first pass, where the specific particle can
be guessed later. This is also a practical task, in
that learners can benefit from accurate feedback on
knowing whether or not a particle is needed.
</bodyText>
<sectionHeader confidence="0.996398" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.9999695">
We evaluate the web corpora for the task of predict-
ing particle usage, after describing the test corpus.
</bodyText>
<subsectionHeader confidence="0.997329">
6.1 Learner Corpus
</subsectionHeader>
<bodyText confidence="0.999984882352941">
To evaluate, we use a corpus of learner Korean made
up of essays from college students (Lee et al., 2009).
The corpus is divided according to student level (be-
ginner, intermediate) and student background (her-
itage, non-heritage),6 and is hand-annotated for par-
ticle errors. We expect beginners to be less accurate
than intermediates and non-heritage less accurate
than heritage learners. To pick a middle ground, the
current research has been conducted on non-heritage
intermediate learners. The test corpus covers a range
of common language classroom topics such as Ko-
rean language, Korea, friends, family, and traveling.
We run our system on raw learner data, i.e, un-
segmented and with spelling and spacing errors in-
cluded. As mentioned in section 5.2.2, we use a POS
tagger to segment the words into morphemes, a cru-
cial step for particle error detection.7
</bodyText>
<footnote confidence="0.99907275">
6Heritage learners have had exposure to Korean at a young
age, such as growing up with Korean spoken at home.
7In the case of segmentation errors, we cannot possibly get
the particle correct. We are currently investigating this issue.
</footnote>
<page confidence="0.994608">
14
</page>
<table confidence="0.914407333333333">
Seeds Len. Quer. P R F
10 3 120 81.54% 76.21% 78.77%
5 252 82.98% 77.77% 80.28%
20 3 120 81.56% 77.26% 79.33%
3 240 82.89% 78.37% 80.55%
5 252 83.79% 78.17% 80.87%
5 504 84.30% 79.44% 81.79%
50 3 120 82.97% 77.97% 80.39%
3 240 83.62% 80.46% 82.00%
5 252 82.57% 78.45% 80.44%
5 504 84.25% 78.69% 81.36%
10 3 120 81.41% 74.67% 77.88%
5 252 83.82% 77.09% 80.30%
20 3 120 82.23% 76.40% 79.20%
240 82.57% 77.19% 79.78%
5 252 83.62% 77.97% 80.68%
504 81.86% 75.88% 78.73%
20 3 120 81.63% 76.44% 78.93%
240 82.57% 78.45% 80.44%
5 252 84.21% 80.62% 82.37%
504 83.87% 81.51% 82.67%
</table>
<tableCaption confidence="0.980555">
Table 3: Results of guessing particle existence, training
with different corpora
</tableCaption>
<bodyText confidence="0.996254625">
The non-heritage intermediate (NHI) corpus gives
us 3198 words, with 1288 particles and 1836 nom-
inals. That is, about 70% of the nominals in the
learner corpus are followed by a particle. This is a
much higher average than in the 252 5-tuple F2 cor-
pus, which exhibits the highest average of all of the
web corpora at about 48% ( 781
1616; see table 2).
</bodyText>
<subsectionHeader confidence="0.712456">
6.2 Results
</subsectionHeader>
<bodyText confidence="0.999987291666667">
We use the default settings for TiMBL for all the re-
sults we report here. Though we have obtained 4-5%
higher F-scores using different settings, the compar-
isons between corpora are the important measure for
the current task. The results are given in table 3.
The best results were achieved when training
on the 5-tuple F2 corpora, leading to F-scores of
82.37% and 82.67% for the 252 tuple and 504 tu-
ple corpora, respectively. This finding reinforces our
hypothesis that more advanced seed terms result in
more reliable Korean data, while staying within the
domain of the test corpus. Both longer tuple lengths
and greater amounts of queries have an effect on the
reliability of the resulting corpora. Specificaly, 5-
tuple corpora produce better results than similar 3-
tuple corpora, and corpora with double the amount
of queries of n-length perform better than smaller
comparable corpora. Although larger corpora tend
to do better, it is important to note that there is not
a clear relationship. The general 50/5/252 corpus,
for instance, is similarly-sized to the F2 focused
20/5/252 corpus, with over 4 million ejels (see ta-
ble 2). The focused corpus—based on fewer yet
more relevant seed terms—has 2% better F-score.
</bodyText>
<sectionHeader confidence="0.98043" genericHeader="conclusions">
7 Summary and Outlook
</sectionHeader>
<bodyText confidence="0.9999856">
In this paper, we have examined different ways to
build web corpora for analyzing learner language
to support the detection of errors in Korean parti-
cles. This type of investigation is most useful for
lesser-resourced languages, where the error detec-
tion task stays constant, but the topic changes fre-
quently. In order to develop a framework for testing
web corpora, we have also begun developing a ma-
chine learning system for detecting particle errors.
The current web data, as we have demonstrated, is
not perfect, and thus we need to continue improving
that. One approach will be to filter out clearly non-
Korean data, as suggested in section 4.1. We may
also explore instance sampling (e.g., Wunsch et al.,
2009) to remove many of the non-particle nominal
(negative) instances, which will reduce the differ-
ence between the ratios of negative-to-positive in-
stances of the web and learner corpora. We still feel
that there is room for improvement in our seed term
selection, and plan on constructing specific web cor-
pora for each topic covered in the learner corpus.
We will also consider adding currently available cor-
pora, such as the Sejong Corpus (The National Insti-
tute of Korean Language, 2007), to our web data.
With better data, we can work on improving the
machine learning system. This includes optimizing
the set of features, the parameter settings, and the
choice of machine learning algorithm. Once the sys-
tem has been optimized, we will need to test the re-
sults on a wider range of learner data.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999176">
We would like to thank Marco Baroni and Jan
Pomik´alek for kindly providing a UTF-8 version of
BootCat; Chong Min Lee for help with the POS tag-
ger, provided by Chung-Hye Han; and Joel Tetreault
for useful discussion.
</bodyText>
<figure confidence="0.8529">
Gen.
F1
F2
</figure>
<page confidence="0.944944">
15
</page>
<sectionHeader confidence="0.991053" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999562356321839">
Amaral, Luiz and Detmar Meurers (2006). Where
does ICALL Fit into Foreign Language Teach-
ing? Talk given at CALICO Conference. May
19, 2006. University of Hawaii.
Baroni, Marco and Silvia Bernardini (2004). Boot-
CaT: Bootstrapping Corpora and Terms from the
Web. In Proceedings of LREC 2004. pp. 1313–
1316.
Baroni, Marco and Motoko Ueyama (2004). Re-
trieving Japanese specialized terms and corpora
from the World Wide Web. In Proceedings of
KONVENS 2004.
Daelemans, Walter, Jakub Zavrel, Ko van der Sloot,
Antal van den Bosch, Timbl Tilburg and Memory
based Learner (2007). TiMBL: Tilburg Memory-
Based Learner - version 6.1 - Reference Guide.
De Felice, Rachele and Stephen Pulman (2008). A
classifier-baed approach to preposition and deter-
miner error correction in L2 English. In Proceed-
ings of COLING-08. Manchester.
Dickinson, Markus, Soojeong Eom, Yunkyoung
Kang, Chong Min Lee and Rebecca Sachs (2008).
A Balancing Act: How can intelligent computer-
generated feedback be provided in learner-to-
learner interactions. Computer Assisted Language
Learning 21(5), 369–382.
Dickinson, Markus and Chong Min Lee (2009).
Modifying Corpus Annotation to Support the
Analysis of Learner Language. CALICO Journal
26(3).
Erjavec, Irena Srdanovi`c, Tomaz Erjavec and Adam
Kilgarriff (2008). A Web Corpus and Word
Sketches for Japanese. Information and Media
Technologies 3(3), 529–551.
Han, Chung-Hye, Na-Rare Han, Eon-Suk Ko and
Martha Palmer (2002). Development and Eval-
uation of a Korean Treebank and its Application
to NLP. In Proceedings of LREC-02.
Han, Chung-Hye and Martha Palmer (2004). A Mor-
phological Tagger for Korean: Statistical Tag-
ging Combined with Corpus-Based Morphologi-
cal Rule Application. Machine Translation 18(4),
275–297.
Han, Na-Rae, Martin Chodorow and Claudia Lea-
cock (2006). Detecting Errors in English Arti-
cle Usage by Non-Native Speakers. Natural Lan-
guage Engineering 12(2).
Ko, S., M. Kim, J. Kim, S. Seo, H. Chung and S. Han
(2004). An analysis of Korean learner corpora
and errors. Hanguk Publishing Co.
Lee, John and Ola Knutsson (2008). The Role of
PP Attachment in Preposition Generation. In Pro-
ceedings of CICLing 2008. Haifa, Israel.
Lee, John and Stephanie Seneff (2006). Auto-
matic Grammar Correction for Second-Language
Learners. In INTERSPEECH 2006. Pittsburgh,
pp. 1978–1981.
Lee, Sun-Hee, Donna K. Byron and Seok Bae Jang
(2005). Why is Zero Marking Important in Ko-
rean? In Proceedings of IJCNLP-05. Jeju Island,
Korea.
Lee, Sun-Hee, Seok Bae Jang and Sang kyu Seo
(2009). Annotation of Korean Learner Corpora
for Particle Error Detection. CALICO Journal
26(3).
Sharoff, Serge (2006). Creating General-Purpose
Corpora Using Automated Search Engine
Queries. In WaCky! Working papers on the Web
as Corpus. Gedit.
Tetreault, Joel and Martin Chodorow (2008). The
Ups and Downs of Preposition Error Detection
in ESL Writing. In Proceedings of COLING-08.
Manchester.
Tetreault, Joel and Martin Chodorow (2009). Exam-
ining the Use of Region Web Counts for ESL Er-
ror Detection. In Web as Corpus Workshop (WAC-
5). San Sebastian, Spain.
The National Institute of Korean Language (2007).
The Sejong Corpus.
Ueyama, Motoko (2006). Evaluation of Japanese
Web-based Reference Corpora: Effects of Seed
Selection and Time Interval. In WaCky! Working
papers on the Web as Corpus. Gedit.
Wunsch, Holger, Sandra K¨ubler and Rachael
Cantrell (2009). Instance Sampling Methods for
Pronoun Resolution. In Proceedings of RANLP
2009. Borovets, Bulgaria.
</reference>
<page confidence="0.998702">
16
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.935152">
<title confidence="0.999986">Building a Korean Web Corpus for Analyzing Learner Language</title>
<author confidence="0.995778">Markus Dickinson Ross Israel Sun-Hee Lee</author>
<affiliation confidence="0.999994">Indiana University Indiana University Wellesley</affiliation>
<email confidence="0.998813">md7@indiana.eduraisrael@indiana.eduslee6@wellesley.edu</email>
<abstract confidence="0.995360538461538">Post-positional particles are a significant source of errors for learners of Korean. Following methodology that has proven effective in handling English preposition errors, we are beginning the process of building a machine learner for particle error detection in L2 Korean writing. As a first step, however, we must acquire data, and thus we present a methodology for constructing large-scale corpora of Korean from the Web, exploring the feasibility of building corpora appropriate for a given topic and grammatical construction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Luiz Amaral</author>
<author>Detmar Meurers</author>
</authors>
<title>Where does ICALL Fit into Foreign Language Teaching? Talk given at CALICO Conference.</title>
<date>2006</date>
<institution>University of Hawaii.</institution>
<contexts>
<context position="958" citStr="Amaral and Meurers, 2006" startWordPosition="133" endWordPosition="136">t has proven effective in handling English preposition errors, we are beginning the process of building a machine learner for particle error detection in L2 Korean writing. As a first step, however, we must acquire data, and thus we present a methodology for constructing large-scale corpora of Korean from the Web, exploring the feasibility of building corpora appropriate for a given topic and grammatical construction. 1 Introduction Applications for assisting second language learners can be extremely useful when they make learners more aware of the non-native characteristics in their writing (Amaral and Meurers, 2006). Certain constructions, such as English prepositions, are difficult to characterize by grammar rules and thus are wellsuited for machine learning approaches (Tetreault and Chodorow, 2008; De Felice and Pulman, 2008). Machine learning techniques are relatively portable to new languages, but new languages bring issues in terms of defining the language learning problem and in terms of acquiring appropriate data for training a machine learner. We focus in this paper mainly on acquiring data for training a machine learning system. In particular, we are interested in situations where the task is co</context>
</contexts>
<marker>Amaral, Meurers, 2006</marker>
<rawString>Amaral, Luiz and Detmar Meurers (2006). Where does ICALL Fit into Foreign Language Teaching? Talk given at CALICO Conference. May 19, 2006. University of Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Silvia Bernardini</author>
</authors>
<title>BootCaT: Bootstrapping Corpora and Terms from the Web. In</title>
<date>2004</date>
<booktitle>Proceedings of LREC</booktitle>
<pages>1313--1316</pages>
<contexts>
<context position="2441" citStr="Baroni and Bernardini, 2004" startWordPosition="374" endWordPosition="377"> instructor, etc. By isolating a particular domain, we can hope for greater degrees of accuracy; see, for example, the high accuracies for domain-specific grammar correction in Lee and Seneff (2006). In this situation, we face the challenge of obtaining data which is appropriate both for: a) the topic the learners are writing about, and b) the linguistic construction of interest, i.e., containing enough relevant instances. In the ideal case, one could build a corpus directly for the types of learner data to analyze. Luckily, using the web as a data source can provide such specialized corpora (Baroni and Bernardini, 2004), in addition to larger, more general corpora (Sharoff, 2006). A crucial question, though, is how one goes about designing the right web corpus for analyzing learner language (see, e.g., Sharoff, 2006, for other contexts) The area of difficulty for language learners which we focus on is that of Korean post-positional particles, akin to English prepositions (Lee et al., 2009; Ko et al., 2004). Korean is an important language to develop NLP techniques for (see, e.g., discussion in Dickinson et al., 2008), presenting a variety of features which are less prevalent in many Western languages, such a</context>
<context position="8450" citStr="Baroni and Bernardini, 2004" startWordPosition="1342" endWordPosition="1345">e we plan to include the Sejong corpus in future data, there are several reasons we pursue a different tack here. First, not every language has such resources, and we want to work towards a languageindependent platform of data acquisition. Secondly, these corpora may not be a good model for the kinds of topics learners write about. For example, news texts are typically written more formally than learner writing. We want to explore ways to quickly build topic-specific corpora, and Web as Corpus (WaC) technology gives us tools to do this.3 3.2 Web as Corpus To build web corpora, we use BootCat (Baroni and Bernardini, 2004). The process is an iterative algorithm to bootstrap corpora, starting with various seed terms. The procedure is as follows: 1. Select initial seeds (terms). 2. Combine seeds randomly. 3. Run Google/Yahoo queries. 4. Retrieve corpus. 5. Extract new seeds via corpus comparison. 6. Repeat steps #2-#5. For non-ASCII languages, one needs to check the encoding of webpages in order to convert the text into UTF-8 for output, as has been done for, e.g., Japanese (e.g., Erjavec et al., 2008; Baroni and Ueyama, 2004). Using a UTF-8 version of BootCat, we modified the system by using a simple Perl module</context>
</contexts>
<marker>Baroni, Bernardini, 2004</marker>
<rawString>Baroni, Marco and Silvia Bernardini (2004). BootCaT: Bootstrapping Corpora and Terms from the Web. In Proceedings of LREC 2004. pp. 1313– 1316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Motoko Ueyama</author>
</authors>
<title>Retrieving Japanese specialized terms and corpora from the World Wide Web.</title>
<date>2004</date>
<booktitle>In Proceedings of KONVENS</booktitle>
<contexts>
<context position="8962" citStr="Baroni and Ueyama, 2004" startWordPosition="1426" endWordPosition="1429">gives us tools to do this.3 3.2 Web as Corpus To build web corpora, we use BootCat (Baroni and Bernardini, 2004). The process is an iterative algorithm to bootstrap corpora, starting with various seed terms. The procedure is as follows: 1. Select initial seeds (terms). 2. Combine seeds randomly. 3. Run Google/Yahoo queries. 4. Retrieve corpus. 5. Extract new seeds via corpus comparison. 6. Repeat steps #2-#5. For non-ASCII languages, one needs to check the encoding of webpages in order to convert the text into UTF-8 for output, as has been done for, e.g., Japanese (e.g., Erjavec et al., 2008; Baroni and Ueyama, 2004). Using a UTF-8 version of BootCat, we modified the system by using a simple Perl module (Encode::Guess) to look for the EUCKR encoding of most Korean webpages and switch it to UTF-8. The pages already in UTF-8 do not need to be changed. 3.3 Obtaining data A crucial first step in constructing a web corpus is the selection of appropriate seed terms for constructing the corpus (e.g., Sharoff, 2006; Ueyama, 2006). 3Tetreault and Chodorow (2009) use the web to derive learner errors; our work, however, tries to obtain correct data. In our particular case, this begins the question of how one builds </context>
</contexts>
<marker>Baroni, Ueyama, 2004</marker>
<rawString>Baroni, Marco and Motoko Ueyama (2004). Retrieving Japanese specialized terms and corpora from the World Wide Web. In Proceedings of KONVENS 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Jakub Zavrel</author>
<author>Ko van der Sloot</author>
<author>Antal van den Bosch</author>
</authors>
<title>Timbl Tilburg and Memory based Learner</title>
<date>2007</date>
<marker>Daelemans, Zavrel, van der Sloot, van den Bosch, 2007</marker>
<rawString>Daelemans, Walter, Jakub Zavrel, Ko van der Sloot, Antal van den Bosch, Timbl Tilburg and Memory based Learner (2007). TiMBL: Tilburg MemoryBased Learner - version 6.1 - Reference Guide.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rachele De Felice</author>
<author>Stephen Pulman</author>
</authors>
<title>A classifier-baed approach to preposition and determiner error correction in L2 English.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING-08.</booktitle>
<location>Manchester.</location>
<marker>De Felice, Pulman, 2008</marker>
<rawString>De Felice, Rachele and Stephen Pulman (2008). A classifier-baed approach to preposition and determiner error correction in L2 English. In Proceedings of COLING-08. Manchester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Dickinson</author>
</authors>
<title>Soojeong Eom, Yunkyoung Kang, Chong Min Lee and Rebecca Sachs</title>
<date>2008</date>
<journal>Computer Assisted Language Learning</journal>
<volume>21</volume>
<issue>5</issue>
<pages>369--382</pages>
<marker>Dickinson, 2008</marker>
<rawString>Dickinson, Markus, Soojeong Eom, Yunkyoung Kang, Chong Min Lee and Rebecca Sachs (2008). A Balancing Act: How can intelligent computergenerated feedback be provided in learner-tolearner interactions. Computer Assisted Language Learning 21(5), 369–382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Dickinson</author>
<author>Chong Min Lee</author>
</authors>
<title>Modifying Corpus Annotation to Support the Analysis of Learner Language.</title>
<date>2009</date>
<journal>CALICO Journal</journal>
<volume>26</volume>
<issue>3</issue>
<contexts>
<context position="3734" citStr="Dickinson and Lee, 2009" startWordPosition="579" endWordPosition="582">vely free word order. Obtaining data is important in the general case, as non-English languages tend to lack resources. The correct usage of Korean particles relies on knowing lexical, syntactic, semantic, and discourse information (Lee et al., 2005), which makes this challenging for both learners and machines (cf. EnProceedings of the NAACL HLT 2010 Sixth Web as Corpus Workshop, pages 8–16, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics glish determiners in Han et al., 2006). The only other approach we know of, a parser-based one, had very low precision (Dickinson and Lee, 2009). A secondary contribution of this work is thus defining the particle error detection problem for a machine learner. It is important that the data represent the relationships between specific lexical items: in the comparable English case, for example, interest is usually found with in: interest in/*with learning. The basic framework we employ is to train a machine learner on correct Korean data and then apply this system to learner text, to predict correct particle usage, which may differ from the learner’s (cf. Tetreault and Chodorow, 2008). After describing the grammatical properties of part</context>
</contexts>
<marker>Dickinson, Lee, 2009</marker>
<rawString>Dickinson, Markus and Chong Min Lee (2009). Modifying Corpus Annotation to Support the Analysis of Learner Language. CALICO Journal 26(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irena Srdanovi`c Erjavec</author>
</authors>
<title>Tomaz Erjavec and Adam Kilgarriff</title>
<date>2008</date>
<journal>Information and Media Technologies</journal>
<volume>3</volume>
<issue>3</issue>
<pages>529--551</pages>
<marker>Erjavec, 2008</marker>
<rawString>Erjavec, Irena Srdanovi`c, Tomaz Erjavec and Adam Kilgarriff (2008). A Web Corpus and Word Sketches for Japanese. Information and Media Technologies 3(3), 529–551.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chung-Hye Han</author>
<author>Na-Rare Han</author>
<author>Eon-Suk Ko</author>
<author>Martha Palmer</author>
</authors>
<title>Development and Evaluation of a Korean Treebank and its Application to NLP.</title>
<date>2002</date>
<booktitle>In Proceedings of LREC-02.</booktitle>
<contexts>
<context position="7638" citStr="Han et al., 2002" startWordPosition="1205" endWordPosition="1208">method for similar NLP problems like detecting errors in English preposition use. For example Tetreault and Chodorow (2008) use a maximum entropy classifier to build a model of correct preposition usage, with 7 million instances in their training set, and Lee and Knutsson (2008) use memory-based learning, with 10 million sentences in their training set. In expanding the paradigm to other languages, one problem 9 is a dearth of data. It seems like a large data set is essential for moving forward. For Korean, there are at least two corpora publicly available right now, the Penn Korean Treebank (Han et al., 2002), with hundreds of thousands of words, and the Sejong Corpus (a.k.a., The Korean National Corpus, The National Institute of Korean Language, 2007), with tens of millions of words. While we plan to include the Sejong corpus in future data, there are several reasons we pursue a different tack here. First, not every language has such resources, and we want to work towards a languageindependent platform of data acquisition. Secondly, these corpora may not be a good model for the kinds of topics learners write about. For example, news texts are typically written more formally than learner writing. </context>
<context position="24876" citStr="Han et al., 2002" startWordPosition="4093" endWordPosition="4096">n words without failing on less frequent constructions, we need (large amounts of) appropriate data. 5.2.2 Feature set To begin with, we segment and POS tag the text, using a hybrid (trigram + rule-based) morphological tagger for Korean (Han and Palmer, 2004). This segmentation phase means that we can define subword features and isolate the particles in question. For our features, we break each word into: a) its stem and b) its combined affixes (excluding particles), and each of these components has its own POS, possibly a combined tag (e.g., EPF+EFN), with tags from the Penn Korean Treebank (Han et al., 2002). The feature vector uses a five word window that includes the target word and two words on either side for context. Each word is broken down into four features: stem, affixes, stem POS, and affixes POS. Given the importance of surrounding noun and verbs for attachment in Korean, we have features for the preceding as well as the following noun and verb. For the noun/verb features, only the stem is used, as this is largely a semantically-based property. In terms of defining a class, if the target word’s affixes contain a particle, it is removed and used as the basis for the class; otherwise the</context>
</contexts>
<marker>Han, Han, Ko, Palmer, 2002</marker>
<rawString>Han, Chung-Hye, Na-Rare Han, Eon-Suk Ko and Martha Palmer (2002). Development and Evaluation of a Korean Treebank and its Application to NLP. In Proceedings of LREC-02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chung-Hye Han</author>
<author>Martha Palmer</author>
</authors>
<title>A Morphological Tagger for Korean: Statistical Tagging Combined with Corpus-Based Morphological Rule Application.</title>
<date>2004</date>
<journal>Machine Translation</journal>
<volume>18</volume>
<issue>4</issue>
<pages>275--297</pages>
<contexts>
<context position="17449" citStr="Han and Palmer, 2004" startWordPosition="2898" endWordPosition="2901">table 2, where we average over multiple corpora for conditions with 5 corpora.5 There are a few points to understand in the table. First, it is hard to count true words in Korean, as compounds are frequent, and particles have a debatable status. From a theory-neutral perspective, we count ejels, which are tokens occurring between white spaces. Secondly, we need to know about the number of particles and number of nominals, i.e., words which could potentially bear particles, as our machine learning paradigm considers any nominal a test case for possible particle attachment. We use a POS tagger (Han and Palmer, 2004) for this. Some significant trends emerge when comparing the corpora in the table. First of all, longer queries (length 5) result in not only more returned unique webpages, but also longer webpages on average than shorter queries (length 3). This effect is most dramatic for the F2 corpora. The F2 corpora also exhibit a higher ratio of particles to nominals than the other web corpora, which means there will be more pos5For the 252 5-tuple 20 seed General corpora, we average over four corpora, due to POS tagging failure on the fifth corpus. itive examples in the training data for the machine lea</context>
<context position="24518" citStr="Han and Palmer, 2004" startWordPosition="4032" endWordPosition="4035">eatures, i.e., segment words into their component morphemes. Finally, particles have more functions than prepositions, requiring a potentially richer space of features. Case marking, for example, is even more dependent upon the word’s grammatical function in a sentence. In order to ensure that our system can correctly handle all of the typical relations between words without failing on less frequent constructions, we need (large amounts of) appropriate data. 5.2.2 Feature set To begin with, we segment and POS tag the text, using a hybrid (trigram + rule-based) morphological tagger for Korean (Han and Palmer, 2004). This segmentation phase means that we can define subword features and isolate the particles in question. For our features, we break each word into: a) its stem and b) its combined affixes (excluding particles), and each of these components has its own POS, possibly a combined tag (e.g., EPF+EFN), with tags from the Penn Korean Treebank (Han et al., 2002). The feature vector uses a five word window that includes the target word and two words on either side for context. Each word is broken down into four features: stem, affixes, stem POS, and affixes POS. Given the importance of surrounding no</context>
</contexts>
<marker>Han, Palmer, 2004</marker>
<rawString>Han, Chung-Hye and Martha Palmer (2004). A Morphological Tagger for Korean: Statistical Tagging Combined with Corpus-Based Morphological Rule Application. Machine Translation 18(4), 275–297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Na-Rae Han</author>
</authors>
<title>Martin Chodorow and Claudia Leacock</title>
<date>2006</date>
<journal>Natural Language Engineering</journal>
<volume>12</volume>
<issue>2</issue>
<marker>Han, 2006</marker>
<rawString>Han, Na-Rae, Martin Chodorow and Claudia Leacock (2006). Detecting Errors in English Article Usage by Non-Native Speakers. Natural Language Engineering 12(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ko</author>
<author>M Kim</author>
<author>J Kim</author>
<author>S Seo</author>
<author>H Chung</author>
<author>S Han</author>
</authors>
<title>An analysis of Korean learner corpora and errors.</title>
<date>2004</date>
<publisher>Hanguk Publishing Co.</publisher>
<contexts>
<context position="2835" citStr="Ko et al., 2004" startWordPosition="439" endWordPosition="442"> relevant instances. In the ideal case, one could build a corpus directly for the types of learner data to analyze. Luckily, using the web as a data source can provide such specialized corpora (Baroni and Bernardini, 2004), in addition to larger, more general corpora (Sharoff, 2006). A crucial question, though, is how one goes about designing the right web corpus for analyzing learner language (see, e.g., Sharoff, 2006, for other contexts) The area of difficulty for language learners which we focus on is that of Korean post-positional particles, akin to English prepositions (Lee et al., 2009; Ko et al., 2004). Korean is an important language to develop NLP techniques for (see, e.g., discussion in Dickinson et al., 2008), presenting a variety of features which are less prevalent in many Western languages, such as agglutinative morphology, a rich system of case marking, and relatively free word order. Obtaining data is important in the general case, as non-English languages tend to lack resources. The correct usage of Korean particles relies on knowing lexical, syntactic, semantic, and discourse information (Lee et al., 2005), which makes this challenging for both learners and machines (cf. EnProcee</context>
<context position="6542" citStr="Ko et al. (2004)" startWordPosition="1023" endWordPosition="1026">the topic marker nun is used to indicate old information or a discoursesalient entity, while the delimiter to implies that there is someone else Sumi likes. In this paper, we focus on syntactic/semantic particle usage for nominals, planning to extend to other cases in the future. (3) Sumi-nun John-to cohahay. Sumi-TOP John-also like ‘Sumi likes John also.’ Due to these complex linguistic properties, particles are one of the most difficult topics for Korean language learners. In (4b), for instance, a learner might replace a subject particle (as in (4a)) with an object (Dickinson et al., 2008). Ko et al. (2004) report that particle errors were the second most frequent error in a study across different levels of Korean learners, and errors persist across levels (see also Lee et al., 2009). (4) a. Sumi-nun chayk-i philyohay-yo Sumi-TOP book-SBJ need-polite ‘Sumi needs a book.’ b. *Sumi-nun chayk-ul philyohay-yo Sumi-TOP book-OBJ need-polite ‘Sumi needs a book.’ 3 Approach 3.1 Acquiring training data Due to the lexical relationships involved, machine learning has proven to be a good method for similar NLP problems like detecting errors in English preposition use. For example Tetreault and Chodorow (200</context>
</contexts>
<marker>Ko, Kim, Kim, Seo, Chung, Han, 2004</marker>
<rawString>Ko, S., M. Kim, J. Kim, S. Seo, H. Chung and S. Han (2004). An analysis of Korean learner corpora and errors. Hanguk Publishing Co.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lee</author>
<author>Ola Knutsson</author>
</authors>
<title>The Role of PP Attachment in Preposition Generation.</title>
<date>2008</date>
<booktitle>In Proceedings of CICLing</booktitle>
<location>Haifa,</location>
<contexts>
<context position="7300" citStr="Lee and Knutsson (2008)" startWordPosition="1145" endWordPosition="1148">ist across levels (see also Lee et al., 2009). (4) a. Sumi-nun chayk-i philyohay-yo Sumi-TOP book-SBJ need-polite ‘Sumi needs a book.’ b. *Sumi-nun chayk-ul philyohay-yo Sumi-TOP book-OBJ need-polite ‘Sumi needs a book.’ 3 Approach 3.1 Acquiring training data Due to the lexical relationships involved, machine learning has proven to be a good method for similar NLP problems like detecting errors in English preposition use. For example Tetreault and Chodorow (2008) use a maximum entropy classifier to build a model of correct preposition usage, with 7 million instances in their training set, and Lee and Knutsson (2008) use memory-based learning, with 10 million sentences in their training set. In expanding the paradigm to other languages, one problem 9 is a dearth of data. It seems like a large data set is essential for moving forward. For Korean, there are at least two corpora publicly available right now, the Penn Korean Treebank (Han et al., 2002), with hundreds of thousands of words, and the Sejong Corpus (a.k.a., The Korean National Corpus, The National Institute of Korean Language, 2007), with tens of millions of words. While we plan to include the Sejong corpus in future data, there are several reaso</context>
</contexts>
<marker>Lee, Knutsson, 2008</marker>
<rawString>Lee, John and Ola Knutsson (2008). The Role of PP Attachment in Preposition Generation. In Proceedings of CICLing 2008. Haifa, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lee</author>
<author>Stephanie Seneff</author>
</authors>
<title>Automatic Grammar Correction for Second-Language Learners.</title>
<date>2006</date>
<booktitle>In INTERSPEECH 2006. Pittsburgh,</booktitle>
<pages>1978--1981</pages>
<contexts>
<context position="2011" citStr="Lee and Seneff (2006)" startWordPosition="302" endWordPosition="305">ine learner. We focus in this paper mainly on acquiring data for training a machine learning system. In particular, we are interested in situations where the task is constant—e.g., detecting grammatical errors in particles—but the domain might fluctuate. This is the case when a learner is asked to write an essay on 8 a prompt (e.g., “What do you hope to do in life?”), and the prompts may vary by student, by semester, by instructor, etc. By isolating a particular domain, we can hope for greater degrees of accuracy; see, for example, the high accuracies for domain-specific grammar correction in Lee and Seneff (2006). In this situation, we face the challenge of obtaining data which is appropriate both for: a) the topic the learners are writing about, and b) the linguistic construction of interest, i.e., containing enough relevant instances. In the ideal case, one could build a corpus directly for the types of learner data to analyze. Luckily, using the web as a data source can provide such specialized corpora (Baroni and Bernardini, 2004), in addition to larger, more general corpora (Sharoff, 2006). A crucial question, though, is how one goes about designing the right web corpus for analyzing learner lang</context>
</contexts>
<marker>Lee, Seneff, 2006</marker>
<rawString>Lee, John and Stephanie Seneff (2006). Automatic Grammar Correction for Second-Language Learners. In INTERSPEECH 2006. Pittsburgh, pp. 1978–1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sun-Hee Lee</author>
<author>K Donna</author>
</authors>
<title>Byron and Seok Bae Jang</title>
<date>2005</date>
<booktitle>In Proceedings of IJCNLP-05. Jeju Island,</booktitle>
<marker>Lee, Donna, 2005</marker>
<rawString>Lee, Sun-Hee, Donna K. Byron and Seok Bae Jang (2005). Why is Zero Marking Important in Korean? In Proceedings of IJCNLP-05. Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sun-Hee Lee</author>
</authors>
<title>Seok Bae Jang and Sang kyu Seo</title>
<date>2009</date>
<journal>CALICO Journal</journal>
<volume>26</volume>
<issue>3</issue>
<contexts>
<context position="3734" citStr="Lee, 2009" startWordPosition="581" endWordPosition="582"> order. Obtaining data is important in the general case, as non-English languages tend to lack resources. The correct usage of Korean particles relies on knowing lexical, syntactic, semantic, and discourse information (Lee et al., 2005), which makes this challenging for both learners and machines (cf. EnProceedings of the NAACL HLT 2010 Sixth Web as Corpus Workshop, pages 8–16, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics glish determiners in Han et al., 2006). The only other approach we know of, a parser-based one, had very low precision (Dickinson and Lee, 2009). A secondary contribution of this work is thus defining the particle error detection problem for a machine learner. It is important that the data represent the relationships between specific lexical items: in the comparable English case, for example, interest is usually found with in: interest in/*with learning. The basic framework we employ is to train a machine learner on correct Korean data and then apply this system to learner text, to predict correct particle usage, which may differ from the learner’s (cf. Tetreault and Chodorow, 2008). After describing the grammatical properties of part</context>
</contexts>
<marker>Lee, 2009</marker>
<rawString>Lee, Sun-Hee, Seok Bae Jang and Sang kyu Seo (2009). Annotation of Korean Learner Corpora for Particle Error Detection. CALICO Journal 26(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Serge Sharoff</author>
</authors>
<title>Creating General-Purpose Corpora Using Automated Search Engine Queries. In WaCky! Working papers on the Web as Corpus.</title>
<date>2006</date>
<publisher>Gedit.</publisher>
<contexts>
<context position="2502" citStr="Sharoff, 2006" startWordPosition="386" endWordPosition="387"> degrees of accuracy; see, for example, the high accuracies for domain-specific grammar correction in Lee and Seneff (2006). In this situation, we face the challenge of obtaining data which is appropriate both for: a) the topic the learners are writing about, and b) the linguistic construction of interest, i.e., containing enough relevant instances. In the ideal case, one could build a corpus directly for the types of learner data to analyze. Luckily, using the web as a data source can provide such specialized corpora (Baroni and Bernardini, 2004), in addition to larger, more general corpora (Sharoff, 2006). A crucial question, though, is how one goes about designing the right web corpus for analyzing learner language (see, e.g., Sharoff, 2006, for other contexts) The area of difficulty for language learners which we focus on is that of Korean post-positional particles, akin to English prepositions (Lee et al., 2009; Ko et al., 2004). Korean is an important language to develop NLP techniques for (see, e.g., discussion in Dickinson et al., 2008), presenting a variety of features which are less prevalent in many Western languages, such as agglutinative morphology, a rich system of case marking, an</context>
<context position="9360" citStr="Sharoff, 2006" startWordPosition="1500" endWordPosition="1501">#5. For non-ASCII languages, one needs to check the encoding of webpages in order to convert the text into UTF-8 for output, as has been done for, e.g., Japanese (e.g., Erjavec et al., 2008; Baroni and Ueyama, 2004). Using a UTF-8 version of BootCat, we modified the system by using a simple Perl module (Encode::Guess) to look for the EUCKR encoding of most Korean webpages and switch it to UTF-8. The pages already in UTF-8 do not need to be changed. 3.3 Obtaining data A crucial first step in constructing a web corpus is the selection of appropriate seed terms for constructing the corpus (e.g., Sharoff, 2006; Ueyama, 2006). 3Tetreault and Chodorow (2009) use the web to derive learner errors; our work, however, tries to obtain correct data. In our particular case, this begins the question of how one builds a corpus which models native Korean and which provides appropriate data for the task of particle error detection. The data should be genreappropriate and contain enough instances of the particles learners know and used in ways they are expected to use them (e.g., as temporal modifiers). A large corpus will likely satisfy these criteria, but has the potential to contain distracting information. I</context>
</contexts>
<marker>Sharoff, 2006</marker>
<rawString>Sharoff, Serge (2006). Creating General-Purpose Corpora Using Automated Search Engine Queries. In WaCky! Working papers on the Web as Corpus. Gedit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Tetreault</author>
<author>Martin Chodorow</author>
</authors>
<title>The Ups and Downs of Preposition Error Detection in ESL Writing.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING-08.</booktitle>
<location>Manchester.</location>
<contexts>
<context position="1145" citStr="Tetreault and Chodorow, 2008" startWordPosition="160" endWordPosition="163">step, however, we must acquire data, and thus we present a methodology for constructing large-scale corpora of Korean from the Web, exploring the feasibility of building corpora appropriate for a given topic and grammatical construction. 1 Introduction Applications for assisting second language learners can be extremely useful when they make learners more aware of the non-native characteristics in their writing (Amaral and Meurers, 2006). Certain constructions, such as English prepositions, are difficult to characterize by grammar rules and thus are wellsuited for machine learning approaches (Tetreault and Chodorow, 2008; De Felice and Pulman, 2008). Machine learning techniques are relatively portable to new languages, but new languages bring issues in terms of defining the language learning problem and in terms of acquiring appropriate data for training a machine learner. We focus in this paper mainly on acquiring data for training a machine learning system. In particular, we are interested in situations where the task is constant—e.g., detecting grammatical errors in particles—but the domain might fluctuate. This is the case when a learner is asked to write an essay on 8 a prompt (e.g., “What do you hope to</context>
<context position="4281" citStr="Tetreault and Chodorow, 2008" startWordPosition="669" endWordPosition="672">h we know of, a parser-based one, had very low precision (Dickinson and Lee, 2009). A secondary contribution of this work is thus defining the particle error detection problem for a machine learner. It is important that the data represent the relationships between specific lexical items: in the comparable English case, for example, interest is usually found with in: interest in/*with learning. The basic framework we employ is to train a machine learner on correct Korean data and then apply this system to learner text, to predict correct particle usage, which may differ from the learner’s (cf. Tetreault and Chodorow, 2008). After describing the grammatical properties of particles in section 2, we turn to the general approach for obtaining relevant web data in section 3, reporting basic statistics for our corpora in section 4. We outline the machine learing set-up in section 5 and present initial results in section 6. These results help evaluate the best way to build specialized corpora for learner language. 2 Korean particles Similar to English prepositions, Korean postpositional particles add specific meanings or grammatical functions to nominals. However, a particle cannot stand alone in Korean and needs to b</context>
<context position="7144" citStr="Tetreault and Chodorow (2008)" startWordPosition="1119" endWordPosition="1122">l., 2008). Ko et al. (2004) report that particle errors were the second most frequent error in a study across different levels of Korean learners, and errors persist across levels (see also Lee et al., 2009). (4) a. Sumi-nun chayk-i philyohay-yo Sumi-TOP book-SBJ need-polite ‘Sumi needs a book.’ b. *Sumi-nun chayk-ul philyohay-yo Sumi-TOP book-OBJ need-polite ‘Sumi needs a book.’ 3 Approach 3.1 Acquiring training data Due to the lexical relationships involved, machine learning has proven to be a good method for similar NLP problems like detecting errors in English preposition use. For example Tetreault and Chodorow (2008) use a maximum entropy classifier to build a model of correct preposition usage, with 7 million instances in their training set, and Lee and Knutsson (2008) use memory-based learning, with 10 million sentences in their training set. In expanding the paradigm to other languages, one problem 9 is a dearth of data. It seems like a large data set is essential for moving forward. For Korean, there are at least two corpora publicly available right now, the Penn Korean Treebank (Han et al., 2002), with hundreds of thousands of words, and the Sejong Corpus (a.k.a., The Korean National Corpus, The Nati</context>
<context position="22583" citStr="Tetreault and Chodorow (2008)" startWordPosition="3719" endWordPosition="3722">noise, identifying whether a corpus is about traveling, for example, is a content-based decision. Given that this is what a search engine is designed to do, we prefer filtering based only on grammatical and genre properties. 5 Classification We describe the classification paradigm used to determine how effective each corpus is for detecting correct particle usage; evaluation is in section 6. 5.1 Machine learning paradigm Based on the parallel between Korean particles and English prepositions, we use preposition error detection as a starting point for developing a classifier. For prepositions, Tetreault and Chodorow (2008) extract 25 features to guess the correct preposition (out of 34 selected prepositions), including features capturing the lexical and grammatical context (e.g., the words and POS tags in a two-word window around the preposition) and features capturing various relevant selectional properties (e.g., the head verb and noun of the preceding VP and NP). We are currently using TiMBL (Daelemans et al., 2007) for development purposes, as it provides a range of options for testing. Given that learner data needs to be processed instantaneously and that memory-based learning can take a long time to class</context>
</contexts>
<marker>Tetreault, Chodorow, 2008</marker>
<rawString>Tetreault, Joel and Martin Chodorow (2008). The Ups and Downs of Preposition Error Detection in ESL Writing. In Proceedings of COLING-08. Manchester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Tetreault</author>
<author>Martin Chodorow</author>
</authors>
<title>Examining the Use of Region Web Counts for ESL Error Detection.</title>
<date>2009</date>
<booktitle>In Web as Corpus Workshop (WAC5).</booktitle>
<location>San Sebastian,</location>
<contexts>
<context position="9407" citStr="Tetreault and Chodorow (2009)" startWordPosition="1504" endWordPosition="1507">e needs to check the encoding of webpages in order to convert the text into UTF-8 for output, as has been done for, e.g., Japanese (e.g., Erjavec et al., 2008; Baroni and Ueyama, 2004). Using a UTF-8 version of BootCat, we modified the system by using a simple Perl module (Encode::Guess) to look for the EUCKR encoding of most Korean webpages and switch it to UTF-8. The pages already in UTF-8 do not need to be changed. 3.3 Obtaining data A crucial first step in constructing a web corpus is the selection of appropriate seed terms for constructing the corpus (e.g., Sharoff, 2006; Ueyama, 2006). 3Tetreault and Chodorow (2009) use the web to derive learner errors; our work, however, tries to obtain correct data. In our particular case, this begins the question of how one builds a corpus which models native Korean and which provides appropriate data for the task of particle error detection. The data should be genreappropriate and contain enough instances of the particles learners know and used in ways they are expected to use them (e.g., as temporal modifiers). A large corpus will likely satisfy these criteria, but has the potential to contain distracting information. In Korean, for example, less formal writing ofte</context>
</contexts>
<marker>Tetreault, Chodorow, 2009</marker>
<rawString>Tetreault, Joel and Martin Chodorow (2009). Examining the Use of Region Web Counts for ESL Error Detection. In Web as Corpus Workshop (WAC5). San Sebastian, Spain.</rawString>
</citation>
<citation valid="true">
<title>The National Institute of Korean Language</title>
<date>2007</date>
<marker>2007</marker>
<rawString>The National Institute of Korean Language (2007). The Sejong Corpus.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Motoko Ueyama</author>
</authors>
<title>Evaluation of Japanese Web-based Reference Corpora: Effects of Seed Selection and Time Interval. In WaCky! Working papers on the Web as Corpus.</title>
<date>2006</date>
<publisher>Gedit.</publisher>
<contexts>
<context position="9375" citStr="Ueyama, 2006" startWordPosition="1502" endWordPosition="1503">II languages, one needs to check the encoding of webpages in order to convert the text into UTF-8 for output, as has been done for, e.g., Japanese (e.g., Erjavec et al., 2008; Baroni and Ueyama, 2004). Using a UTF-8 version of BootCat, we modified the system by using a simple Perl module (Encode::Guess) to look for the EUCKR encoding of most Korean webpages and switch it to UTF-8. The pages already in UTF-8 do not need to be changed. 3.3 Obtaining data A crucial first step in constructing a web corpus is the selection of appropriate seed terms for constructing the corpus (e.g., Sharoff, 2006; Ueyama, 2006). 3Tetreault and Chodorow (2009) use the web to derive learner errors; our work, however, tries to obtain correct data. In our particular case, this begins the question of how one builds a corpus which models native Korean and which provides appropriate data for the task of particle error detection. The data should be genreappropriate and contain enough instances of the particles learners know and used in ways they are expected to use them (e.g., as temporal modifiers). A large corpus will likely satisfy these criteria, but has the potential to contain distracting information. In Korean, for e</context>
</contexts>
<marker>Ueyama, 2006</marker>
<rawString>Ueyama, Motoko (2006). Evaluation of Japanese Web-based Reference Corpora: Effects of Seed Selection and Time Interval. In WaCky! Working papers on the Web as Corpus. Gedit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Holger Wunsch</author>
<author>Sandra K¨ubler</author>
<author>Rachael Cantrell</author>
</authors>
<title>Instance Sampling Methods for Pronoun Resolution.</title>
<date>2009</date>
<booktitle>In Proceedings of RANLP 2009. Borovets,</booktitle>
<marker>Wunsch, K¨ubler, Cantrell, 2009</marker>
<rawString>Wunsch, Holger, Sandra K¨ubler and Rachael Cantrell (2009). Instance Sampling Methods for Pronoun Resolution. In Proceedings of RANLP 2009. Borovets, Bulgaria.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>