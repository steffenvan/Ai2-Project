<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000789">
<title confidence="0.9987675">
Did Social Networks Shape Language Evolution?
A Multi-Agent Cognitive Simulation
</title>
<author confidence="0.998338">
David Reitter
</author>
<affiliation confidence="0.9860965">
Department of Psychology
Carnegie Mellon University
</affiliation>
<address confidence="0.688121">
Pittsburgh, PA, USA
</address>
<email confidence="0.999574">
reitter@cmu.edu
</email>
<sectionHeader confidence="0.993917" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99994">
Natural language as well as other commu-
nication forms are constrained by cogni-
tive function and evolved through a social
process. Here, we examine whether hu-
man memory may be uniquely adapted to
the social structures prevalent in groups,
specifically small-world networks. The
emergence of domain languages is simu-
lated using an empirically evaluated ACT-
R-based cognitive model of agents in a
naming game played within communi-
ties. Several community structures are ex-
amined (grids, trees, random graphs and
small-world networks). We present pre-
liminary results from small-scale simula-
tions, showing relative robustness of cog-
nitive models to network structure.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999772">
A language, even if shared among the members
of a community, is hardly static. It is constantly
evolving and adapting to the needs of its speak-
ers. Adaptivity in natural language has been found
at various linguistic levels. Models of dialogue
describe how interlocutors develop representation
systems in order to communicate; such systems
can, for instance, be observed using referring ex-
pressions such as the wall straight ahead that iden-
tify locations in a maze. Experiments have shown
that communities converge on a common standard
for such expressions (Garrod and Doherty, 1994).
Models of the horizontal transmission of cul-
tural information within generations show on a
much larger scale how beliefs or communicative
standards spread within a single generation of hu-
mans. Recently, language change has accelerated
through the use of communication technologies,
achieving changes that used to take generations
in years or even months or weeks. However, the
</bodyText>
<author confidence="0.840858">
Christian Lebiere
</author>
<affiliation confidence="0.892061333333333">
Department of Psychology
Carnegie Mellon University
Pittsburgh, PA, USA
</affiliation>
<email confidence="0.992572">
cl@cmu.edu
</email>
<bodyText confidence="0.999914073170732">
structure of electronic networks mimics that of
more traditional social networks, and even com-
munication via mass media follows a power-law-
driven network topology.
The individual agents that are effecting the lan-
guage change depend on their cognitive abilities
such as memory retrieval and language processing
to control and accept novel communication stan-
dards. Do the local, cognitive constraints at the
individual level interact with the structure of large-
scale networks? Both social structure and individ-
ual cognitive systems have evolved over a long pe-
riod of time, leading to the hypothesis that certain
network structures are more suitable than others to
convergence, given the specific human cognitive
apparatus. Some properties of human cognition
are well established, e.g., in cognitive frameworks
(Anderson et al., 2004). Was human cognition
shaped by social networks? Why are memory pa-
rameters the way they are? Social network struc-
tures may hold an answer to this question. If so,
we should find that naturally occurring networks
structures are uniquely suited to human learning,
while others will perform less well when human
learners are present.
The environment may have been influenced by
individual cognition as well. Why are social net-
works structured the way they are? Human mem-
ory and possibly human learning strategies are
the result of an evolutionary process. Social net-
work structures can be explained by models such
as Preferential Attachment (Barabasi and Albert,
1999), yet, even that is tied to evolved distribu-
tions of preferences in human agents. Dall’Asta
et al. (2006) argue that the dynamic of agreement
in small-world networks shows, at times, proper-
ties that ease the (cognitive) memory burden on
the individuals. It is possible that the human mem-
ory apparatus and social preferences governing
network structures have co-evolved. Such a the-
ory would, again, suggest the hypothesis underly-
</bodyText>
<page confidence="0.970861">
9
</page>
<note confidence="0.9816155">
Proceedings of the 2010 Workshop on Cognitive Modeling and Computational Linguistics, ACL 2010, pages 9–17,
Uppsala, Sweden, 15 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.8426265">
ing this study: that network structure and human
memory are co-dependent.
</bodyText>
<sectionHeader confidence="0.854265" genericHeader="method">
2 Modeling Language Change
</sectionHeader>
<bodyText confidence="0.999981621052631">
Network structure, on a small scale, does influ-
ence the evolving patterns of communication. The
dichotomy between individual and community-
based learning motivated experiments by Garrod
et al. (2007) and Fay et al. (2010), where partic-
ipants played the Pictionary game. In each trial
of this naming game, each participant is paired up
with another participant. One of them is then to
make a drawing to convey a given concept out of
a small set of known concepts; the other one is to
select the concept from that list without engaging
in verbal communication. Over time, participants
develop common standards codifying those con-
cepts: they develop a system of meaning-symbol
pairs, or, signs. We take this system as the lex-
ical core of the shared language. The conver-
gence rate and the actual language developed dif-
fered as a function of the structure of the small
participant communities: Fay (2010) either asked
the same pairs of participants to engage in the
activity repeatedly, or matched up different pairs
of participants over time. Fay and Garrod’s Pic-
tionary experiments served as the empirical basis
for a cognitive process model developed by (Reit-
ter and Lebiere, 2009). Our model has agents pro-
pose signs by combining more elementary signs
from their divergent knowledge bases, and also
adopt other agent’s proposals of signs for later re-
use. The model, designed to match Fay’s com-
munities, was studied in a condition involving
groups of eight agents, with two network struc-
tures: maximally disjoint with the same pairs of
agents throughout the simulation, and maximally
connected, with interactions between all possible
pairs of agents.
Reitter and Lebiere’s (2009) cognitive model re-
flects the Pictionary game. The model explains
the convergence as a result of basic learning and
memory retrieval processes, which have been well
understood and made available for simulation in a
cognitive modeling framework, ACT-R Anderson
et al. (2004). Thus, properties of human memory
and of the agent’s learning strategies dictate how
quickly they adopt signs or establish new signs:
processes such as learning, forgetting and noise to-
gether with their fundamental parameters that are
within well-established ranges provide strong con-
straints on the behavior of each agent and in turn
the evolution of their communication within the
network. This approach acknowledges that cul-
tural evolution is constrained by individual learn-
ing; each agent learns according to their cognitive
faculty (cf., Christiansen and Chater, 2008). With
non-cognitive models, language change has been
simulated on a larger scale as well (e.g., Kirby and
Hurford, 2002; Brighton et al., 2005).
It is because adaptation according to experi-
ence is determined by human learning behav-
ior that simulation in validated learning frame-
works is crucial. Griffiths and Kalish (2007)
for instance model language evolution through
iteration among rational learners in a Bayesian
framework; the purpose of the present project is
to tie the simulation of language evolution to a
concrete experiment and a more process-oriented
cognitive architecture than the Bayesian frame-
work. ACT-R’s learning mechanisms extend the
Bayesian view with at least a notion of recency.
Work on language processing has pointed out its
relationship to memory retrieval from within the
ACT-R framework, both for language comprehen-
sion (Budiu and Anderson, 2002; Lewis and Va-
sishth, 2005; Crescentini and Stocco, 2005; Ball
et al., 2007) and for language production (Reitter,
2008). The individual language faculty as a result
of biological evolution and adaptation to cultural
language has been the focus of psycholinguis-
tic models proposing specialized mechanisms (the
Chomskian viewpoint); our model does not pro-
pose a specialized mechanism but rather declara-
tive memory as store for lexical information, and
procedural cognitive processes as regulators of
certain communicative functions. Our multi-agent
model sees part of the linguistic process as an in-
stantiation of general cognition: the composition
and retrieval of signs follows general cognitive
mechanisms and can be formulated within cogni-
tive frameworks such as ACT-R (Anderson et al.,
2004) or SOAR (Laird and Rosenbloom, 1987).
In this study, we adapted the 2009 model and
simulated language convergence in several larger-
scale networks. We investigate the relationship
between human memory function in the retrieval
of linguistic items and the structure of social net-
works on which humans depend to communicate.
</bodyText>
<page confidence="0.999017">
10
</page>
<sectionHeader confidence="0.99564" genericHeader="method">
3 Network structures
</sectionHeader>
<bodyText confidence="0.999968207920793">
Differences in naturally occurring social networks
are hardly as extreme as in Fay’s experiment.
Some agents will be connected to a large number
of other ones, while many agents will have just a
few connections each. Concretely, the number of
interaction partners of a randomly chosen commu-
nity member is not normally distributed and cen-
tered around a mean. It shows a (Zipfian) power
law distribution, with a number of hubs attracting
many network neighbors, and a long tail of sub-
jects interacting with just a few other ones each.
Social networks are small world networks: the av-
erage distance between any two nodes in the net-
works is low, since many of them are connected to
hubs. Non-organically connected communication
and command networks follow other normals–tree
graphs for instance. However, natural communica-
tion standards develop in networks that have very
specific properties that can be observed in most or-
ganically developed networks.
Realistic social networks commonly show very
specific properties. Social networks, in which
links symbolize communication pathways or some
form of social acquaintance, frequently exhibit the
small world property. The mean minimum dis-
tance between any two nodes is relatively low, and
the clustering coefficient is high (Watts and Stro-
gatz, 1998).
Other forms of networks include tree hierar-
chies with a constant or variable branching factor
(directed acyclic graphs). Such networks ressem-
ble communication and command hierarchies in
military or business organizations. N-dimensional
grid networks have nodes with constant degrees,
which are connected to each of their two neigh-
bors along each dimension in a lattice.
Much work on information or belief propaga-
tion, or decision-making in networks has used
large artificial networks modeled after social ones;
nodes in such networks are commonly simple
agents that make decisions based on input fed to
them by their neighbor nodes and pass on infor-
mation. These often state-less agents do not nec-
essarily employ learning or adaptivity, and when
they do, learning does not reflect known cognitive
properties of human memory. The mechanisms
governing learning and retrieval in human mem-
ory have been studied in detail, leading to formal
models of process that detail the units that may be
stored in and retrieved from memory, the retrieval
time and accuracy depending on the frequency and
recency of prior rehearsals, on contextual cues that
may facilitate retrieval, and on individual differ-
ences. Cognitive agents can serve as a more real-
istic basis for network simulations (Sun, 2001).
Frequency, recency, contextual cues and chunk-
ing of the stored information determine retrieval
probability, which is crucial when novel idioms
are required to express meaning in communica-
tion. The process leads to the choice of one of
several available synonyms. Our model sees this
decision-making process as a matter of memory
retrieval: given the desired meaning, which sign
(word or drawing, compound noun or drawings)
can be used to express it. This process is implicit
(not consciously controlled), and it follows re-
cent suggestions from cognitive psychology: Pick-
ering and Garrod’s (2004) Interactive Alignment
Model proposes that explicit negotiation and sepa-
rate models of the interlocutor’s mental state aren’t
necessary, as long as each speaker is coherent and
adapts to their interlocutors, as speakers are known
to do on even simple, linguistic levels (lexical,
syntactic). This shifts the weight of the task from
a sophisticated reasoning device to the simpler,
more constrained implicit learning mechanism of
the individual.
The social network controls the interactions that
the agents can experience. Each interaction is an
opportunity to develop new signs and adapt the ex-
isting communication systems. It can be shown
that even separate pairs of agents develop spe-
cialized communication systems, both empirically
(Garrod and Doherty, 1994; Reitter and Moore,
2007; Kirby and Hurford, 2002) and in the specific
model used here.When communication partners
change, convergence towards a common system
and the final transmission accuracy is slower (Fay
et al., 2008). At this point it is unclear how the
structure of the communication network and the
learning process interact. Given that some types
of networks show a wide distribution of degrees,
where some nodes communicate much more often
and with a wide variety of neighbors, while others
communicate less often, recency and frequency of
memory access will vary substantially. Other com-
munication networks may reflect command hier-
archies in organizations, which are constructed to
ensure, among other things, more predictable in-
formation propagation.
We hypothesize that the human memory ap-
</bodyText>
<page confidence="0.9954">
11
</page>
<bodyText confidence="0.99991855">
paratus and preferred social network structures
have co-evolved to be uniquely suited to create
a macro-organism that adapts its communication
structures and reasoning mechanisms to novel sit-
uations. There is limited opportunity to test such a
hypothesis under controlled conditions with a suf-
ficiently large human network; however, cognitive
models that have been developed to explain and
predict human performance in isolated cognitive
situations can be leveraged to study the develop-
ment of sign systems.
In a simulated network with cognitive mod-
els representing agents at the network nodes,
and communication between agents along network
links, we expect that the social network structures
lead to better, if not optimal, adaptivity during the
establishment of a communication system. We ex-
pect that scale-free small world networks do best,
outperforming tree hierarchies, random networks
and regular grids (lattices).
</bodyText>
<subsectionHeader confidence="0.999471">
3.1 Architecture
</subsectionHeader>
<bodyText confidence="0.999893413793103">
ACT-R’s memory associates symbolic chunks of
information (sets of feature-value pairs) with sub-
symbolic, activation values. Learning occurs
through the creation of such a chunk, which is
then reinforced through repeated presentation, and
forgotten through decay over time. The symbolic
information stored in chunks is available for ex-
plicit reasoning, while the subsymbolic informa-
tion moderates retrieval, both in speed and in re-
trieval probability. The assumption of rationality
in ACT-R implies that retrievability is governed
by the expectation to make use of a piece of in-
formation at a later point. Important to our ap-
plication, retrieval is further aided by contextual
cues. When other chunks are in use (e.g., parlia-
ment), they support the retrieval of related chunks
(building).
The properties of memory retrieval in terms of
time and of retrieval success are governed by the
activation of a chunk that is to be retrieved. Three
components of activation are crucial in the context
of this model: base-level activation, spreading ac-
tivation and transient noise (E). Base-level activa-
tion is predictive of retrieval probability indepen-
dent of the concurrent context. It is determined by
the frequency and recency of use of the particular
chunk, with tj indicating the time elapsed since
use k of the chunk. d indicates a base-level decay
parameter, usually 0.5):
</bodyText>
<figureCaption confidence="0.995905666666667">
Figure 1: Example of a small ontology with ab-
stract concepts (spelled-out words) and concrete
ones (drawings).
</figureCaption>
<equation confidence="0.933234">
wj�ji + E
</equation>
<bodyText confidence="0.998412944444445">
Retrieval is contextualized by cues available
through spreading activation. It is proportional
to the strengths of association (5ji) of all of the
cues with the target chunk. While the base-level
term (first term of the sum) can be seen as a prior,
spreading activation models the conditional proba-
bility of retrieval given the available cues. Finally,
E is sampled from a logistic distribution shaped by
canonical parameters. Ai must surpass a minimum
retrieval threshold.
The model is implemented using the ACT-UP
toolbox, which makes the components of the ACT-
R theory are directly accessible. The cognitive
model does not specify other model components
(perceptual, manual, procedural), as they are nei-
ther subject to evaluation nor considered to make a
significant contribution to learning or convergence
effects.
</bodyText>
<subsectionHeader confidence="0.997089">
3.2 Communication model
</subsectionHeader>
<bodyText confidence="0.99972275">
We assume that the communication system, or
language, is a system of signs. Concretely, it is
a set of tuples (signs), each associating a mean-
ing with a set of up to three symbols (a simpli-
fying assumption). If the communication system
uses natural language, symbols consist of spoken
or written words. The communication system es-
tablished by the participants of Garrod’s and Fay’s
</bodyText>
<figure confidence="0.995703454545455">
PARAMEDIC
FIRE STATION
HOSPITAL
cues
j
Ai = log
t�d
k +
pres
E
k=1
</figure>
<page confidence="0.975583">
12
</page>
<bodyText confidence="0.999938625">
experiments uses drawings as symbols–the princi-
ple stays the same. Agents start out with a knowl-
edge base containing signs for concrete concepts
that are immediately representable as drawings or
nouns; the target concepts to be conveyed by the
participants, however, are more abstract and re-
quire the combination of such concrete concepts.
A concept such as hospital, for instance, could in-
volve the drawings for house, ambulance, and a
sad face. A participant could choose among many
ways to express hospital.
The goal of our cognitive models is to com-
municate meaning from one agent to another one.
Put in natural language-oriented terminology, the
director role is the speaker, a role that involves
selecting the right concrete concepts that can ex-
press a given target concepts; the matcher role (lis-
tener) involves decoding the concrete drawings (or
words) to retrieve the target.
A single ACT-R model implements the director
and matcher roles. As a director, the model es-
tablishes new combinations of drawings for given
target concepts. As a matcher, the model makes
guesses. In each role, the model revises its internal
mappings between drawings and target concepts.
The model is copied to instantiate a community of
agents, one for each node in the network.
The simplest form of representing a communi-
cation system in ACT-R memory chunks is as a set
of signs. Each sign pairs a concept with a set of
drawings. Competing signs can be used to assign
multiple drawings for one conceptTo reflect se-
mantic relationships, we need to introduce a sub-
symbolic notion of relatedness. We use ACT-R’s
spreading activation mechanism and weights be-
tween concepts to reflect relatedness. Spreading
activation facilitates retrieval of a chunk if the cur-
rent context offers cues related to the chunk. Re-
latedness is expressed as a value in log-odds space
(SjZ values).
When the model is faced with the task to draw
a given concept such as Russell Crowe (one of the
concepts in the experiment) or Hospital (as in Fig-
ure 1) that has no canonical form as a drawing,
a related but concrete concept is retrieved from
declarative memory (such as Syringe in the exam-
ple). In drawing-based communication, this would
be a concept that can be drawn, while in natural-
language based communication, this is an existing
drawing expressing a similar, partial or otherwise
related concept. We request two other such con-
cepts, reflecting the desire of the communicator
to come up with a distinctive rather than just fit-
ting depiction of the target concept. The case of a
model recognizing a novel combination of draw-
ings is similar; we retrieve the concept using the
drawings as cues that spread activation, making
the target concept the one that is the most related
one to the drawings.
After drawings have been produced or recog-
nized and mapped to a target, the target or guessed
concept, along with the component drawings, is
stored symbolically in memory as a chunk for
later reuse (domain sign). These signs differ from
the pre-existing concepts in the network, although
they also allow for the retrieval of suitable draw-
ings given a concept, and for a concept given some
drawings. When drawing or recognizing at a later
stage, the memorized domain signs are strictly
preferred as a strategy over the retrieval of related
concepts. The system of domain signs encodes
what is agreed upon as a language system between
two communicators; they will be reused readily
during drawing when interacting with a new part-
ner, but they will be of only limited use when at-
tempting to recognize a drawing combination that
adheres to somebody else’s independently devel-
oped communication system.
Thus, the model has two avenues to express and
recognize an abstract concept: by associative re-
trieval and by idiomatic domain concept. A mes-
sage constructed by domain concept retrieval is
often decoded by the matcher by association, and
vice versa.
The identification accuracy of the model shows
characteristics observed in empirical work (Fay et
al. 2008). See Reitter and Lebiere (subm) for a de-
tailed description of the model and its evaluation.
</bodyText>
<subsectionHeader confidence="0.992838">
3.3 Knowledge
</subsectionHeader>
<bodyText confidence="0.999987">
Agents start out with shared world knowledge.
This is expressed as a network of concepts, con-
nected by weighted links (SjZ). The distribution
of link strengths is important in this context, as it
determines how easily we can find drawing combi-
nations that reliably express target concepts. Thus,
the SjZ were sampled randomly from an empir-
ical distribution: log-odds derived from the fre-
quencies of collocations found in text corpus data.
From the Wall Street Journal corpus we extracted
and counted pairs of nouns that co-occurred in the
same sentence (e.g., “market”, “plunge”). As ex-
</bodyText>
<page confidence="0.995793">
13
</page>
<figure confidence="0.876852">
42 Games over 7 rounds
42 Games over 7 rounds
</figure>
<figureCaption confidence="0.999121">
Figure 2: Identification accuracy for isolated
</figureCaption>
<bodyText confidence="0.954219192307692">
pairs and communities: (a) human data as pro-
vided by Fay (p.c.), (b) simulation. One-tailed
standard-error based 95% confidence intervals
(upper bounds for communities, lower bounds for
pairs) for human data; two-tailed 95% via boot-
strapping for simulations. As in the human data,
both community pairs and isolated pairs converge
most in the early rounds, but community pairs lose
much accuracy when switching partners.
pected, the frequencies of such collocations are
distributed according to a power law.
Such knowledge is, however, not fully shared
between agents. Each agent has their own knowl-
edge network resulting from life experience. This
difference is essential to the difficulty of the task:
if all agents came to the same conclusions about
the strongest representation of target concepts,
there would be little need to establish the domain
language. We control the noise applied to the
link strengths between concepts j and i for agent
M (5Mji ) by combining the common ground 5ji
(shared between all agents) with a random sample
NMji in a mixture model: 5Mji = (1 − n)5ji +
nNMji ; sign identification accuracy was found to
be stable for n up to about 0.4; we set it to 0.3 for
Simulation 1.
</bodyText>
<sectionHeader confidence="0.993334" genericHeader="method">
4 Simulation 1
</sectionHeader>
<bodyText confidence="0.999964755102041">
Networks of individual cognitive agents were cre-
ated to differentiate performance between four dif-
ferent network structures. Random networks
contain N nodes with randomly assigned links
between them, on average d links for each node
(Erd˝os and R´enyi, 1959). n-dimensional Grids
contain N nodes with a constant numer of links
d per node, with links between neighbors along
each dimension. The width w is kept the same
along each dimension, i.e. there are w nodes per
row. We use 6-dimensional lattices. Trees are di-
rected acyclic graphs with 1 link leading up, and
d − 1 links (branching factor) leading down the
hierarchy of a total of N nodes. Scale-free net-
works are constructed using the preferential at-
tachment method as follows (Barabasi and Albert,
1999). N nodes are created and each is connected
to one randomly selected other node. Then, two
links &lt; a, b &gt; and &lt; a&apos;, b&apos; &gt; are chosen randomly
out of the existing set of links, and a new link
&lt; a, b&apos; &gt; is added, until the mean degree d (links
per node) is reached. Preferential attachment en-
sures that nodes with a high number of links ac-
quire further links more quickly than other nodes
(the rich get richer). This yields a power-law dis-
tribution of degrees. Our scale-free networks dis-
play small world properties.
For the first Simulation, we control N at 85 and
d at 5 1. 35 iterations were simulated in each trial;
20 trials were run. During each round, each agent
(network node) plays one game (16 concepts) with
one of its neighbors. The order of neighbors is
shuffled initially, but constant across the rounds.
A variable Round coded iterations from 1to35.
Results Figure 3 shows the learning curve for
agent pairs in the four networks. Agents in all net-
works converge. Confidence intervals obtained via
bootstrapping indicated no apparent differences at
any specific iteration. A linear model was fit-
ted estimating the effects of network type over-
all (as a baseline) for each of the four types. It
also fitted interactions of iteration (1–35) with the
network types, which indicate significant learn-
ing effects as follows. For each network type,
we found a significant learning effect (effect of
Round) (Q 0.002,p &lt; 0.001).
Planned comparisons of the learning rate in
Small World networks revealed no difference with
either of the other three network types (p &gt; 0.3).
</bodyText>
<footnote confidence="0.9870735">
1We found that networks need to be sufficiently large to
display meaningful differences in community structure. The
sizes were chosen to be computationally feasible (4h/CPU
core per network).
</footnote>
<figure confidence="0.97035235">
0 10 20 30 40
Identification accuracy
0.95
0.90
0.85
0.80
0.75
Communities
Isolated Pairs
10 20 30 40
Identification accuracy
0.85
0.80
0.75
0.70
0.65
Isolated Pairs
Communities
14
iteration
</figure>
<figureCaption confidence="0.98562">
Figure 3: Identification accuracy between con-
nected agents for communities of different net-
work structures.
</figureCaption>
<figure confidence="0.5952">
iteration
</figure>
<figureCaption confidence="0.968139">
Figure 4: (Aggregate) Identification accuracy be-
tween random agent pairs for communities of dif-
ferent network structures.
</figureCaption>
<figure confidence="0.999316">
0 10 20 30
Identification accuracy
0.8
0.7
0.6
random
smallworld
grid
tree
0 10 20 30
ID accuracy of randomly paired agents
0.70
0.65
0.60
grid
smallworld
random
tree
</figure>
<sectionHeader confidence="0.626268" genericHeader="method">
5 Simulation 2
</sectionHeader>
<bodyText confidence="0.99925247826087">
The success of a community is not only deter-
mined by how successfully individuals communi-
cate in their local environment, that is, with their
network neighbors. Communities require commu-
nicative success outside of well-acquainted agents.
Agents’ languages would ideally converge on a
global scale. One way to test this is to have ran-
domly paired agents play the Pictionary game at
regular intervals throughout the game and thus
measure identification accuracy outside of the net-
work that defines the social structure.
This simulation was identical to Simulation 1,
except that we scaled up the simulation to examine
whether the lack of effect was possibly due to size
or density of the nodes (N = 512, d = 6, noise
level: 0.2, repetitions: 20). In this simulation, we
measured ID accuracy between pairs of randomly
chosen agents after each round. For three network
types, Grid, Small World and Random we found
significant interactions with round, i.e. significant
convergence, (all Q &gt; 0.016, z &gt; 2.1, p &lt; 0.05).
For the network type Tree we found no significant
interaction (Q = 0.012, z = 1.55,p = 0.12).2
</bodyText>
<footnote confidence="0.5036375">
2All regressions in this simulation where (generalized)
mixed-effects models, with ID accuracy as response via logit
</footnote>
<figureCaption confidence="0.534957">
link, Round as predictor, and Condition as factor for four net-
work types. A random intercept was fitted, grouped by repeti-
tion (1−20), to account for repeated measures. The predictor
was centered; no substantial collinearity remained. The anal-
ysis of Simulation 1 was a simple linear model; ID accuracy
</figureCaption>
<bodyText confidence="0.955989551724138">
To test the initial hypothesis, we re-coded the
conditions with a SmallWorld factor, contrasting
the small world networks with all other conditions.
We found an effect of Round (Q = 0.017, z =
3.66, p &lt; 0.001), indicating convergence, but no
interaction with SmallWorld (Q = −0.00027, z =
−0.03, p = 0.98).3
Results Figure 4 shows network-global conver-
gence. Again, a linear model was fitted to estimate
the learning rate in different network types (inter-
action of network type and iteration) (baseline in-
tercepts were fitted for each network type). We
found significant interactions with iteration for the
following network types: Grid (Q = 0.004,p &lt;
0.001), Small World (Q = 0.003,p &lt; 0.01), and
Random (Q = 0.003, p &lt; 0.005), but not for Tree
(p = 0.991).
Planned comparisons revealed an interaction of
network type and iteration for Tree compared to
Small World (Q = −0.003,p &lt; 0.05), but not
for Grid nor Random compared to Small World
(p &gt; 0.35). This indicates slower across-network
convergence for trees than for small worlds. It also
suggests that convergence across the network does
not differ much between grids, random networks
and small worlds.
was, for all levels, not near either extreme (µ = 0.77).
3Further, unreported, experiments, showed a similar pic-
ture with a smaller network as in Simulation 1.
</bodyText>
<page confidence="0.997244">
15
</page>
<sectionHeader confidence="0.99957" genericHeader="method">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999977769230769">
We find that convergence is relatively stable across
the four network types. Analyzing the differences
between the networks, we find that the average de-
gree, which was controlled for grids, random net-
works and small worlds, was substantially lower
for trees (d = 1.9) due to the large number of
leaves with degree 1. This (or the correlated al-
gebraic connectivity of the network) may prove to
be a deciding correlate with cross-network conver-
gence. Other metrics, such as the clustering coef-
ficient (Watts and Strogatz, 1998), which gives an
indication of the degree of neighborhood cohesion
We see these results still as preliminary. More
work needs to be done to investigate how well
learning scales with network growth, and how net-
work analytics such as clustering coefficients af-
fect the dispersion of information.
Further work will explore range of networks
and the possibly unique suitability of human learn-
ing mechanisms to succeed in such networks. We
will explore the (subsymbolic) parameters govern-
ing adaptation, and to what extend the quantitative
parameters we find universal to humans are sub-
stantially optimized to deal with the small-world
networks and pareto degree-distributions found in
human communities.
</bodyText>
<sectionHeader confidence="0.998509" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.99996834883721">
Cognition may appear to be adapted to the so-
cial structures prevalent in communities of flocks,
packs and human teams. There are many reasons
why such social structures themselves could have
evolved; if cognitive constraints play a role, we ex-
pect it to be only a small factor among many. The
present simulation results certainly do not support
this view: they are much more compatible with
a humans-as-generalists theory that proposes that
humans have evolved to handle a variety of net-
work structures well, or that their recency- and
frequency-based learning mechanism is not spe-
cialized.
Learning, if adapted to social structure in any
way, may go beyond the current, mechanistic
and implicit mechanisms implemented in ACT-R
and comparable theories: learning may rely on
more explicit strategies, analyzing one’s interac-
tion partners and their current knowledge, and it
needs to judge information according to its sources
(trust). Meta-cognition could also play a role in
determining when a set of signs is substantially
novel and better than the current system, and thus
worth enduring the cost of switching from a settled
set of language conventions.
We have evaluated only a small, initial part of a
co-evolution theory we proposed. Also, the prob-
lem we describe may be best operationalized at
a higher abstraction level: Consensus problems
and information spread have been intensively stud-
ied (e.g., Latora and Marchiori, 2001; Wu et al.,
2004). Comparing community convergence in a
number of differently-structured networks, so far
we see little evidence supporting our hypothesis,
namely that cognition (memory) has specialized to
accommodate social structures as defined by con-
temporary network science, and that those struc-
tures accommodate cognitive properties. Instead,
we find that the simulated cognitive agents con-
verge in their communication systems quite well
regardless of the network structures, at least as
long as those networks are relatively small and of
similar average degrees.
</bodyText>
<sectionHeader confidence="0.997476" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998982">
This work was funded by the Air Force
Office of Scientific Research (MURI grant
FA95500810356).
</bodyText>
<sectionHeader confidence="0.999032" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998416571428571">
Anderson, J. R., Bothell, D., Byrne, M. D., Dou-
glass, S., Lebiere, C., and Quin, Y. (2004). An
integrated theory of mind. Psychological Re-
view, 111:1036–1060.
Ball, J., Heiberg, A., and Silber, R. (2007). Toward
a large-scale model of language comprehension
in act-r 6. In Proceedings of the 8th Interna-
tional Conference on Cognitive Modeling, Ann
Arbor, MI.
Barabasi, A. L. and Albert, R. (1999). Emer-
gence of scaling in random networks. Science,
286(5439):509–512.
Brighton, H., Smith, K., and Kirby, S. (2005).
Language as an evolutionary system. Physics
of Life Reviews, 2(3):177–226.
Budiu, R. and Anderson, J. R. (2002). Compre-
hending anaphoric metaphors. Memory &amp; Cog-
nition, 30:158–165.
Christiansen, M. H. and Chater, N. (2008). Lan-
guage as shaped by the brain. Behavioral and
Brain Sciences, 31(5):489–509.
</reference>
<page confidence="0.987558">
16
</page>
<bodyText confidence="0.56972275">
Crescentini, C. and Stocco, A. (2005). Agramma-
tism as a failure in the lexical activation process.
In Proceedings of the 27th Annual Conference
of the Cognitive Science Society.
</bodyText>
<reference confidence="0.991962986842105">
Dall’Asta, L., Baronchelli, A., Barrat, A., and
Loreto, V. (2006). Agreement dynamics on
small-world networks. EPL (Europhysics Let-
ters), 73(6):969.
Erd˝os, P. and R´enyi, A. (1959). On random
graphs. I. Publ. Math. Debrecen, 6:290–297.
Fay, N., Garrod, S., and Roberts, L. (2008). The
fitness and functionality of culturally evolved
communication systems. Philosophical Trans-
actions of the Royal Society B: Biological Sci-
ences, 363(1509):3553–3561.
Fay, N., Garrod, S., Roberts, L., and Swoboda,
N. (2010). The interactive evolution of hu-
man communication systems. Cognitive Sci-
ence, 34(3):351–386.
Garrod, S. and Doherty, G. M. (1994). Conversa-
tion, co-ordination and convention: An empir-
ical investigation of how groups establish lin-
guistic conventions. Cognition, 53:181–215.
Garrod, S., Fay, N., Lee, J., Oberlander, J., and
Macleod, T. (2007). Foundations of represen-
tation: Where might graphical symbol systems
come from? Cognitive Science, 31(6):961–987.
Griffiths, T. L. and Kalish, M. L. (2007).
Language evolution by iterated learning with
Bayesian agents. Cognitive Science, 31(3):441–
480.
Kirby, S. and Hurford, J. (2002). The emergence
of linguistic structure: An overview of the it-
erated learning model. In Cangelosi, A. and
Parisi, D., editors, Simulating the Evolution of
Language, chapter 6, pages 121–148. Springer
Verlag, London.
Laird, J. E. and Rosenbloom, P. S. (1987). Soar:
An architecture for general intelligence. Artifi-
cialIntelligence, 33(1):1–64.
Latora, V. and Marchiori, M. (2001). Efficient
behavior of small-world networks. Phys. Rev.
Lett., 87(19):198701.
Lewis, R. L. and Vasishth, S. (2005). An
activation-based model of sentence processing
as skilled memory retrieval. Cognitive Science,
29:1–45.
Pickering, M. J. and Garrod, S. (2004). Toward
a mechanistic psychology of dialogue. Behav-
ioral and Brain Sciences, 27:169–225.
Reitter, D. (2008). Context Effects in Language
Production: Models of Syntactic Priming in Di-
alogue Corpora. PhD thesis, University of Ed-
inburgh.
Reitter, D. and Lebiere, C. (2009). Towards ex-
plaining the evolution of domain languages with
cognitive simulation. In Proceedings of the 9th
International Conference on Cognitive Model-
ing (ICCM), Manchester, UK.
Reitter, D. and Lebiere, C. (subm.). Towards ex-
plaining the evolution of domain languages with
cognitive simulation. Cognitive Systems Re-
search.
Reitter, D. and Moore, J. D. (2007). Predict-
ing success in dialogue. In Proceedings of the
45th Annual Meeting of the Association of Com-
putational Linguistics (ACL), pages 808–815,
Prague, Czech Republic.
Steedman, M. (2000). The Syntactic Process. MIT
Press, Cambridge, MA.
Sun, R. (2001). Cognitive science meets multi-
agent systems: A prolegomenon. Philosophical
Psychology, 14(1):5–28.
Watts, D. J. and Strogatz, S. H. (1998). Collective
dynamics of /‘small-world/’ networks. Nature,
393(6684):440–442.
Wu, F., Huberman, B. A., Adamic, L. A., and
Tyler, J. R. (2004). Information flow in social
groups. Physica A: Statistical and Theoretical
Physics, 337(1-2):327 – 335.
</reference>
<page confidence="0.999398">
17
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.971944">
<title confidence="0.999729">Did Social Networks Shape Language A Multi-Agent Cognitive Simulation</title>
<author confidence="0.999974">David Reitter</author>
<affiliation confidence="0.999929">Department of Psychology Carnegie Mellon University</affiliation>
<address confidence="0.999682">Pittsburgh, PA, USA</address>
<email confidence="0.99987">reitter@cmu.edu</email>
<abstract confidence="0.998475111111111">Natural language as well as other communication forms are constrained by cognitive function and evolved through a social process. Here, we examine whether human memory may be uniquely adapted to the social structures prevalent in groups, specifically small-world networks. The emergence of domain languages is simulated using an empirically evaluated ACT- R-based cognitive model of agents in a naming game played within communities. Several community structures are examined (grids, trees, random graphs and small-world networks). We present preliminary results from small-scale simulations, showing relative robustness of cognitive models to network structure.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J R Anderson</author>
<author>D Bothell</author>
<author>M D Byrne</author>
<author>S Douglass</author>
<author>C Lebiere</author>
<author>Y Quin</author>
</authors>
<title>An integrated theory of mind.</title>
<date>2004</date>
<journal>Psychological Review,</journal>
<pages>111--1036</pages>
<contexts>
<context position="2761" citStr="Anderson et al., 2004" startWordPosition="407" endWordPosition="410">language change depend on their cognitive abilities such as memory retrieval and language processing to control and accept novel communication standards. Do the local, cognitive constraints at the individual level interact with the structure of largescale networks? Both social structure and individual cognitive systems have evolved over a long period of time, leading to the hypothesis that certain network structures are more suitable than others to convergence, given the specific human cognitive apparatus. Some properties of human cognition are well established, e.g., in cognitive frameworks (Anderson et al., 2004). Was human cognition shaped by social networks? Why are memory parameters the way they are? Social network structures may hold an answer to this question. If so, we should find that naturally occurring networks structures are uniquely suited to human learning, while others will perform less well when human learners are present. The environment may have been influenced by individual cognition as well. Why are social networks structured the way they are? Human memory and possibly human learning strategies are the result of an evolutionary process. Social network structures can be explained by m</context>
<context position="6094" citStr="Anderson et al. (2004)" startWordPosition="938" endWordPosition="941">of signs for later reuse. The model, designed to match Fay’s communities, was studied in a condition involving groups of eight agents, with two network structures: maximally disjoint with the same pairs of agents throughout the simulation, and maximally connected, with interactions between all possible pairs of agents. Reitter and Lebiere’s (2009) cognitive model reflects the Pictionary game. The model explains the convergence as a result of basic learning and memory retrieval processes, which have been well understood and made available for simulation in a cognitive modeling framework, ACT-R Anderson et al. (2004). Thus, properties of human memory and of the agent’s learning strategies dictate how quickly they adopt signs or establish new signs: processes such as learning, forgetting and noise together with their fundamental parameters that are within well-established ranges provide strong constraints on the behavior of each agent and in turn the evolution of their communication within the network. This approach acknowledges that cultural evolution is constrained by individual learning; each agent learns according to their cognitive faculty (cf., Christiansen and Chater, 2008). With non-cognitive model</context>
<context position="8339" citStr="Anderson et al., 2004" startWordPosition="1276" endWordPosition="1279">ogical evolution and adaptation to cultural language has been the focus of psycholinguistic models proposing specialized mechanisms (the Chomskian viewpoint); our model does not propose a specialized mechanism but rather declarative memory as store for lexical information, and procedural cognitive processes as regulators of certain communicative functions. Our multi-agent model sees part of the linguistic process as an instantiation of general cognition: the composition and retrieval of signs follows general cognitive mechanisms and can be formulated within cognitive frameworks such as ACT-R (Anderson et al., 2004) or SOAR (Laird and Rosenbloom, 1987). In this study, we adapted the 2009 model and simulated language convergence in several largerscale networks. We investigate the relationship between human memory function in the retrieval of linguistic items and the structure of social networks on which humans depend to communicate. 10 3 Network structures Differences in naturally occurring social networks are hardly as extreme as in Fay’s experiment. Some agents will be connected to a large number of other ones, while many agents will have just a few connections each. Concretely, the number of interactio</context>
</contexts>
<marker>Anderson, Bothell, Byrne, Douglass, Lebiere, Quin, 2004</marker>
<rawString>Anderson, J. R., Bothell, D., Byrne, M. D., Douglass, S., Lebiere, C., and Quin, Y. (2004). An integrated theory of mind. Psychological Review, 111:1036–1060.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ball</author>
<author>A Heiberg</author>
<author>R Silber</author>
</authors>
<title>Toward a large-scale model of language comprehension in act-r 6.</title>
<date>2007</date>
<booktitle>In Proceedings of the 8th International Conference on Cognitive Modeling,</booktitle>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="7620" citStr="Ball et al., 2007" startWordPosition="1171" endWordPosition="1174">nce model language evolution through iteration among rational learners in a Bayesian framework; the purpose of the present project is to tie the simulation of language evolution to a concrete experiment and a more process-oriented cognitive architecture than the Bayesian framework. ACT-R’s learning mechanisms extend the Bayesian view with at least a notion of recency. Work on language processing has pointed out its relationship to memory retrieval from within the ACT-R framework, both for language comprehension (Budiu and Anderson, 2002; Lewis and Vasishth, 2005; Crescentini and Stocco, 2005; Ball et al., 2007) and for language production (Reitter, 2008). The individual language faculty as a result of biological evolution and adaptation to cultural language has been the focus of psycholinguistic models proposing specialized mechanisms (the Chomskian viewpoint); our model does not propose a specialized mechanism but rather declarative memory as store for lexical information, and procedural cognitive processes as regulators of certain communicative functions. Our multi-agent model sees part of the linguistic process as an instantiation of general cognition: the composition and retrieval of signs follo</context>
</contexts>
<marker>Ball, Heiberg, Silber, 2007</marker>
<rawString>Ball, J., Heiberg, A., and Silber, R. (2007). Toward a large-scale model of language comprehension in act-r 6. In Proceedings of the 8th International Conference on Cognitive Modeling, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A L Barabasi</author>
<author>R Albert</author>
</authors>
<title>Emergence of scaling in random networks.</title>
<date>1999</date>
<journal>Science,</journal>
<volume>286</volume>
<issue>5439</issue>
<contexts>
<context position="3426" citStr="Barabasi and Albert, 1999" startWordPosition="514" endWordPosition="517">networks? Why are memory parameters the way they are? Social network structures may hold an answer to this question. If so, we should find that naturally occurring networks structures are uniquely suited to human learning, while others will perform less well when human learners are present. The environment may have been influenced by individual cognition as well. Why are social networks structured the way they are? Human memory and possibly human learning strategies are the result of an evolutionary process. Social network structures can be explained by models such as Preferential Attachment (Barabasi and Albert, 1999), yet, even that is tied to evolved distributions of preferences in human agents. Dall’Asta et al. (2006) argue that the dynamic of agreement in small-world networks shows, at times, properties that ease the (cognitive) memory burden on the individuals. It is possible that the human memory apparatus and social preferences governing network structures have co-evolved. Such a theory would, again, suggest the hypothesis underly9 Proceedings of the 2010 Workshop on Cognitive Modeling and Computational Linguistics, ACL 2010, pages 9–17, Uppsala, Sweden, 15 July 2010. c�2010 Association for Computat</context>
<context position="23944" citStr="Barabasi and Albert, 1999" startWordPosition="3777" endWordPosition="3780">orks contain N nodes with randomly assigned links between them, on average d links for each node (Erd˝os and R´enyi, 1959). n-dimensional Grids contain N nodes with a constant numer of links d per node, with links between neighbors along each dimension. The width w is kept the same along each dimension, i.e. there are w nodes per row. We use 6-dimensional lattices. Trees are directed acyclic graphs with 1 link leading up, and d − 1 links (branching factor) leading down the hierarchy of a total of N nodes. Scale-free networks are constructed using the preferential attachment method as follows (Barabasi and Albert, 1999). N nodes are created and each is connected to one randomly selected other node. Then, two links &lt; a, b &gt; and &lt; a&apos;, b&apos; &gt; are chosen randomly out of the existing set of links, and a new link &lt; a, b&apos; &gt; is added, until the mean degree d (links per node) is reached. Preferential attachment ensures that nodes with a high number of links acquire further links more quickly than other nodes (the rich get richer). This yields a power-law distribution of degrees. Our scale-free networks display small world properties. For the first Simulation, we control N at 85 and d at 5 1. 35 iterations were simulate</context>
</contexts>
<marker>Barabasi, Albert, 1999</marker>
<rawString>Barabasi, A. L. and Albert, R. (1999). Emergence of scaling in random networks. Science, 286(5439):509–512.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Brighton</author>
<author>K Smith</author>
<author>S Kirby</author>
</authors>
<title>Language as an evolutionary system.</title>
<date>2005</date>
<journal>Physics of Life Reviews,</journal>
<volume>2</volume>
<issue>3</issue>
<contexts>
<context position="6812" citStr="Brighton et al., 2005" startWordPosition="1047" endWordPosition="1050">ey adopt signs or establish new signs: processes such as learning, forgetting and noise together with their fundamental parameters that are within well-established ranges provide strong constraints on the behavior of each agent and in turn the evolution of their communication within the network. This approach acknowledges that cultural evolution is constrained by individual learning; each agent learns according to their cognitive faculty (cf., Christiansen and Chater, 2008). With non-cognitive models, language change has been simulated on a larger scale as well (e.g., Kirby and Hurford, 2002; Brighton et al., 2005). It is because adaptation according to experience is determined by human learning behavior that simulation in validated learning frameworks is crucial. Griffiths and Kalish (2007) for instance model language evolution through iteration among rational learners in a Bayesian framework; the purpose of the present project is to tie the simulation of language evolution to a concrete experiment and a more process-oriented cognitive architecture than the Bayesian framework. ACT-R’s learning mechanisms extend the Bayesian view with at least a notion of recency. Work on language processing has pointed</context>
</contexts>
<marker>Brighton, Smith, Kirby, 2005</marker>
<rawString>Brighton, H., Smith, K., and Kirby, S. (2005). Language as an evolutionary system. Physics of Life Reviews, 2(3):177–226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Budiu</author>
<author>J R Anderson</author>
</authors>
<title>Comprehending anaphoric metaphors.</title>
<date>2002</date>
<journal>Memory &amp; Cognition,</journal>
<pages>30--158</pages>
<contexts>
<context position="7544" citStr="Budiu and Anderson, 2002" startWordPosition="1158" endWordPosition="1161">in validated learning frameworks is crucial. Griffiths and Kalish (2007) for instance model language evolution through iteration among rational learners in a Bayesian framework; the purpose of the present project is to tie the simulation of language evolution to a concrete experiment and a more process-oriented cognitive architecture than the Bayesian framework. ACT-R’s learning mechanisms extend the Bayesian view with at least a notion of recency. Work on language processing has pointed out its relationship to memory retrieval from within the ACT-R framework, both for language comprehension (Budiu and Anderson, 2002; Lewis and Vasishth, 2005; Crescentini and Stocco, 2005; Ball et al., 2007) and for language production (Reitter, 2008). The individual language faculty as a result of biological evolution and adaptation to cultural language has been the focus of psycholinguistic models proposing specialized mechanisms (the Chomskian viewpoint); our model does not propose a specialized mechanism but rather declarative memory as store for lexical information, and procedural cognitive processes as regulators of certain communicative functions. Our multi-agent model sees part of the linguistic process as an inst</context>
</contexts>
<marker>Budiu, Anderson, 2002</marker>
<rawString>Budiu, R. and Anderson, J. R. (2002). Comprehending anaphoric metaphors. Memory &amp; Cognition, 30:158–165.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M H Christiansen</author>
<author>N Chater</author>
</authors>
<title>Language as shaped by the brain.</title>
<date>2008</date>
<journal>Behavioral and Brain Sciences,</journal>
<volume>31</volume>
<issue>5</issue>
<contexts>
<context position="6668" citStr="Christiansen and Chater, 2008" startWordPosition="1024" endWordPosition="1027">gnitive modeling framework, ACT-R Anderson et al. (2004). Thus, properties of human memory and of the agent’s learning strategies dictate how quickly they adopt signs or establish new signs: processes such as learning, forgetting and noise together with their fundamental parameters that are within well-established ranges provide strong constraints on the behavior of each agent and in turn the evolution of their communication within the network. This approach acknowledges that cultural evolution is constrained by individual learning; each agent learns according to their cognitive faculty (cf., Christiansen and Chater, 2008). With non-cognitive models, language change has been simulated on a larger scale as well (e.g., Kirby and Hurford, 2002; Brighton et al., 2005). It is because adaptation according to experience is determined by human learning behavior that simulation in validated learning frameworks is crucial. Griffiths and Kalish (2007) for instance model language evolution through iteration among rational learners in a Bayesian framework; the purpose of the present project is to tie the simulation of language evolution to a concrete experiment and a more process-oriented cognitive architecture than the Bay</context>
</contexts>
<marker>Christiansen, Chater, 2008</marker>
<rawString>Christiansen, M. H. and Chater, N. (2008). Language as shaped by the brain. Behavioral and Brain Sciences, 31(5):489–509.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Dall’Asta</author>
<author>A Baronchelli</author>
<author>A Barrat</author>
<author>V Loreto</author>
</authors>
<title>Agreement dynamics on small-world networks.</title>
<date>2006</date>
<journal>EPL (Europhysics Letters),</journal>
<volume>73</volume>
<issue>6</issue>
<marker>Dall’Asta, Baronchelli, Barrat, Loreto, 2006</marker>
<rawString>Dall’Asta, L., Baronchelli, A., Barrat, A., and Loreto, V. (2006). Agreement dynamics on small-world networks. EPL (Europhysics Letters), 73(6):969.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Erd˝os</author>
<author>A R´enyi</author>
</authors>
<title>On random graphs.</title>
<date>1959</date>
<journal>I. Publ. Math. Debrecen,</journal>
<pages>6--290</pages>
<marker>Erd˝os, R´enyi, 1959</marker>
<rawString>Erd˝os, P. and R´enyi, A. (1959). On random graphs. I. Publ. Math. Debrecen, 6:290–297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Fay</author>
<author>S Garrod</author>
<author>L Roberts</author>
</authors>
<title>The fitness and functionality of culturally evolved communication systems.</title>
<date>2008</date>
<journal>Philosophical Transactions of the Royal Society B: Biological Sciences,</journal>
<volume>363</volume>
<issue>1509</issue>
<contexts>
<context position="12849" citStr="Fay et al., 2008" startWordPosition="1977" endWordPosition="1980"> the simpler, more constrained implicit learning mechanism of the individual. The social network controls the interactions that the agents can experience. Each interaction is an opportunity to develop new signs and adapt the existing communication systems. It can be shown that even separate pairs of agents develop specialized communication systems, both empirically (Garrod and Doherty, 1994; Reitter and Moore, 2007; Kirby and Hurford, 2002) and in the specific model used here.When communication partners change, convergence towards a common system and the final transmission accuracy is slower (Fay et al., 2008). At this point it is unclear how the structure of the communication network and the learning process interact. Given that some types of networks show a wide distribution of degrees, where some nodes communicate much more often and with a wide variety of neighbors, while others communicate less often, recency and frequency of memory access will vary substantially. Other communication networks may reflect command hierarchies in organizations, which are constructed to ensure, among other things, more predictable information propagation. We hypothesize that the human memory ap11 paratus and prefe</context>
<context position="21173" citStr="Fay et al. 2008" startWordPosition="3317" endWordPosition="3320">mmunicators; they will be reused readily during drawing when interacting with a new partner, but they will be of only limited use when attempting to recognize a drawing combination that adheres to somebody else’s independently developed communication system. Thus, the model has two avenues to express and recognize an abstract concept: by associative retrieval and by idiomatic domain concept. A message constructed by domain concept retrieval is often decoded by the matcher by association, and vice versa. The identification accuracy of the model shows characteristics observed in empirical work (Fay et al. 2008). See Reitter and Lebiere (subm) for a detailed description of the model and its evaluation. 3.3 Knowledge Agents start out with shared world knowledge. This is expressed as a network of concepts, connected by weighted links (SjZ). The distribution of link strengths is important in this context, as it determines how easily we can find drawing combinations that reliably express target concepts. Thus, the SjZ were sampled randomly from an empirical distribution: log-odds derived from the frequencies of collocations found in text corpus data. From the Wall Street Journal corpus we extracted and c</context>
</contexts>
<marker>Fay, Garrod, Roberts, 2008</marker>
<rawString>Fay, N., Garrod, S., and Roberts, L. (2008). The fitness and functionality of culturally evolved communication systems. Philosophical Transactions of the Royal Society B: Biological Sciences, 363(1509):3553–3561.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Fay</author>
<author>S Garrod</author>
<author>L Roberts</author>
<author>N Swoboda</author>
</authors>
<title>The interactive evolution of human communication systems.</title>
<date>2010</date>
<journal>Cognitive Science,</journal>
<volume>34</volume>
<issue>3</issue>
<contexts>
<context position="4365" citStr="Fay et al. (2010)" startWordPosition="657" endWordPosition="660">s governing network structures have co-evolved. Such a theory would, again, suggest the hypothesis underly9 Proceedings of the 2010 Workshop on Cognitive Modeling and Computational Linguistics, ACL 2010, pages 9–17, Uppsala, Sweden, 15 July 2010. c�2010 Association for Computational Linguistics ing this study: that network structure and human memory are co-dependent. 2 Modeling Language Change Network structure, on a small scale, does influence the evolving patterns of communication. The dichotomy between individual and communitybased learning motivated experiments by Garrod et al. (2007) and Fay et al. (2010), where participants played the Pictionary game. In each trial of this naming game, each participant is paired up with another participant. One of them is then to make a drawing to convey a given concept out of a small set of known concepts; the other one is to select the concept from that list without engaging in verbal communication. Over time, participants develop common standards codifying those concepts: they develop a system of meaning-symbol pairs, or, signs. We take this system as the lexical core of the shared language. The convergence rate and the actual language developed differed a</context>
</contexts>
<marker>Fay, Garrod, Roberts, Swoboda, 2010</marker>
<rawString>Fay, N., Garrod, S., Roberts, L., and Swoboda, N. (2010). The interactive evolution of human communication systems. Cognitive Science, 34(3):351–386.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Garrod</author>
<author>G M Doherty</author>
</authors>
<title>Conversation, co-ordination and convention: An empirical investigation of how groups establish linguistic conventions.</title>
<date>1994</date>
<journal>Cognition,</journal>
<pages>53--181</pages>
<contexts>
<context position="1450" citStr="Garrod and Doherty, 1994" startWordPosition="213" endWordPosition="216">odels to network structure. 1 Introduction A language, even if shared among the members of a community, is hardly static. It is constantly evolving and adapting to the needs of its speakers. Adaptivity in natural language has been found at various linguistic levels. Models of dialogue describe how interlocutors develop representation systems in order to communicate; such systems can, for instance, be observed using referring expressions such as the wall straight ahead that identify locations in a maze. Experiments have shown that communities converge on a common standard for such expressions (Garrod and Doherty, 1994). Models of the horizontal transmission of cultural information within generations show on a much larger scale how beliefs or communicative standards spread within a single generation of humans. Recently, language change has accelerated through the use of communication technologies, achieving changes that used to take generations in years or even months or weeks. However, the Christian Lebiere Department of Psychology Carnegie Mellon University Pittsburgh, PA, USA cl@cmu.edu structure of electronic networks mimics that of more traditional social networks, and even communication via mass media </context>
<context position="12625" citStr="Garrod and Doherty, 1994" startWordPosition="1943" endWordPosition="1946"> as long as each speaker is coherent and adapts to their interlocutors, as speakers are known to do on even simple, linguistic levels (lexical, syntactic). This shifts the weight of the task from a sophisticated reasoning device to the simpler, more constrained implicit learning mechanism of the individual. The social network controls the interactions that the agents can experience. Each interaction is an opportunity to develop new signs and adapt the existing communication systems. It can be shown that even separate pairs of agents develop specialized communication systems, both empirically (Garrod and Doherty, 1994; Reitter and Moore, 2007; Kirby and Hurford, 2002) and in the specific model used here.When communication partners change, convergence towards a common system and the final transmission accuracy is slower (Fay et al., 2008). At this point it is unclear how the structure of the communication network and the learning process interact. Given that some types of networks show a wide distribution of degrees, where some nodes communicate much more often and with a wide variety of neighbors, while others communicate less often, recency and frequency of memory access will vary substantially. Other com</context>
</contexts>
<marker>Garrod, Doherty, 1994</marker>
<rawString>Garrod, S. and Doherty, G. M. (1994). Conversation, co-ordination and convention: An empirical investigation of how groups establish linguistic conventions. Cognition, 53:181–215.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Garrod</author>
<author>N Fay</author>
<author>J Lee</author>
<author>J Oberlander</author>
<author>T Macleod</author>
</authors>
<title>Foundations of representation: Where might graphical symbol systems come from?</title>
<date>2007</date>
<journal>Cognitive Science,</journal>
<volume>31</volume>
<issue>6</issue>
<contexts>
<context position="4343" citStr="Garrod et al. (2007)" startWordPosition="652" endWordPosition="655">tus and social preferences governing network structures have co-evolved. Such a theory would, again, suggest the hypothesis underly9 Proceedings of the 2010 Workshop on Cognitive Modeling and Computational Linguistics, ACL 2010, pages 9–17, Uppsala, Sweden, 15 July 2010. c�2010 Association for Computational Linguistics ing this study: that network structure and human memory are co-dependent. 2 Modeling Language Change Network structure, on a small scale, does influence the evolving patterns of communication. The dichotomy between individual and communitybased learning motivated experiments by Garrod et al. (2007) and Fay et al. (2010), where participants played the Pictionary game. In each trial of this naming game, each participant is paired up with another participant. One of them is then to make a drawing to convey a given concept out of a small set of known concepts; the other one is to select the concept from that list without engaging in verbal communication. Over time, participants develop common standards codifying those concepts: they develop a system of meaning-symbol pairs, or, signs. We take this system as the lexical core of the shared language. The convergence rate and the actual languag</context>
</contexts>
<marker>Garrod, Fay, Lee, Oberlander, Macleod, 2007</marker>
<rawString>Garrod, S., Fay, N., Lee, J., Oberlander, J., and Macleod, T. (2007). Foundations of representation: Where might graphical symbol systems come from? Cognitive Science, 31(6):961–987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T L Griffiths</author>
<author>M L Kalish</author>
</authors>
<title>Language evolution by iterated learning with Bayesian agents.</title>
<date>2007</date>
<journal>Cognitive Science,</journal>
<volume>31</volume>
<issue>3</issue>
<pages>480</pages>
<contexts>
<context position="6992" citStr="Griffiths and Kalish (2007)" startWordPosition="1075" endWordPosition="1078">ide strong constraints on the behavior of each agent and in turn the evolution of their communication within the network. This approach acknowledges that cultural evolution is constrained by individual learning; each agent learns according to their cognitive faculty (cf., Christiansen and Chater, 2008). With non-cognitive models, language change has been simulated on a larger scale as well (e.g., Kirby and Hurford, 2002; Brighton et al., 2005). It is because adaptation according to experience is determined by human learning behavior that simulation in validated learning frameworks is crucial. Griffiths and Kalish (2007) for instance model language evolution through iteration among rational learners in a Bayesian framework; the purpose of the present project is to tie the simulation of language evolution to a concrete experiment and a more process-oriented cognitive architecture than the Bayesian framework. ACT-R’s learning mechanisms extend the Bayesian view with at least a notion of recency. Work on language processing has pointed out its relationship to memory retrieval from within the ACT-R framework, both for language comprehension (Budiu and Anderson, 2002; Lewis and Vasishth, 2005; Crescentini and Stoc</context>
</contexts>
<marker>Griffiths, Kalish, 2007</marker>
<rawString>Griffiths, T. L. and Kalish, M. L. (2007). Language evolution by iterated learning with Bayesian agents. Cognitive Science, 31(3):441– 480.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kirby</author>
<author>J Hurford</author>
</authors>
<title>The emergence of linguistic structure: An overview of the iterated learning model.</title>
<date>2002</date>
<booktitle>Simulating the Evolution of Language, chapter 6,</booktitle>
<pages>121--148</pages>
<editor>In Cangelosi, A. and Parisi, D., editors,</editor>
<publisher>Springer Verlag,</publisher>
<location>London.</location>
<contexts>
<context position="6788" citStr="Kirby and Hurford, 2002" startWordPosition="1043" endWordPosition="1046">es dictate how quickly they adopt signs or establish new signs: processes such as learning, forgetting and noise together with their fundamental parameters that are within well-established ranges provide strong constraints on the behavior of each agent and in turn the evolution of their communication within the network. This approach acknowledges that cultural evolution is constrained by individual learning; each agent learns according to their cognitive faculty (cf., Christiansen and Chater, 2008). With non-cognitive models, language change has been simulated on a larger scale as well (e.g., Kirby and Hurford, 2002; Brighton et al., 2005). It is because adaptation according to experience is determined by human learning behavior that simulation in validated learning frameworks is crucial. Griffiths and Kalish (2007) for instance model language evolution through iteration among rational learners in a Bayesian framework; the purpose of the present project is to tie the simulation of language evolution to a concrete experiment and a more process-oriented cognitive architecture than the Bayesian framework. ACT-R’s learning mechanisms extend the Bayesian view with at least a notion of recency. Work on languag</context>
<context position="12676" citStr="Kirby and Hurford, 2002" startWordPosition="1951" endWordPosition="1954">their interlocutors, as speakers are known to do on even simple, linguistic levels (lexical, syntactic). This shifts the weight of the task from a sophisticated reasoning device to the simpler, more constrained implicit learning mechanism of the individual. The social network controls the interactions that the agents can experience. Each interaction is an opportunity to develop new signs and adapt the existing communication systems. It can be shown that even separate pairs of agents develop specialized communication systems, both empirically (Garrod and Doherty, 1994; Reitter and Moore, 2007; Kirby and Hurford, 2002) and in the specific model used here.When communication partners change, convergence towards a common system and the final transmission accuracy is slower (Fay et al., 2008). At this point it is unclear how the structure of the communication network and the learning process interact. Given that some types of networks show a wide distribution of degrees, where some nodes communicate much more often and with a wide variety of neighbors, while others communicate less often, recency and frequency of memory access will vary substantially. Other communication networks may reflect command hierarchies</context>
</contexts>
<marker>Kirby, Hurford, 2002</marker>
<rawString>Kirby, S. and Hurford, J. (2002). The emergence of linguistic structure: An overview of the iterated learning model. In Cangelosi, A. and Parisi, D., editors, Simulating the Evolution of Language, chapter 6, pages 121–148. Springer Verlag, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J E Laird</author>
<author>P S Rosenbloom</author>
</authors>
<title>Soar: An architecture for general intelligence.</title>
<date>1987</date>
<journal>ArtificialIntelligence,</journal>
<volume>33</volume>
<issue>1</issue>
<contexts>
<context position="8376" citStr="Laird and Rosenbloom, 1987" startWordPosition="1282" endWordPosition="1285">to cultural language has been the focus of psycholinguistic models proposing specialized mechanisms (the Chomskian viewpoint); our model does not propose a specialized mechanism but rather declarative memory as store for lexical information, and procedural cognitive processes as regulators of certain communicative functions. Our multi-agent model sees part of the linguistic process as an instantiation of general cognition: the composition and retrieval of signs follows general cognitive mechanisms and can be formulated within cognitive frameworks such as ACT-R (Anderson et al., 2004) or SOAR (Laird and Rosenbloom, 1987). In this study, we adapted the 2009 model and simulated language convergence in several largerscale networks. We investigate the relationship between human memory function in the retrieval of linguistic items and the structure of social networks on which humans depend to communicate. 10 3 Network structures Differences in naturally occurring social networks are hardly as extreme as in Fay’s experiment. Some agents will be connected to a large number of other ones, while many agents will have just a few connections each. Concretely, the number of interaction partners of a randomly chosen commu</context>
</contexts>
<marker>Laird, Rosenbloom, 1987</marker>
<rawString>Laird, J. E. and Rosenbloom, P. S. (1987). Soar: An architecture for general intelligence. ArtificialIntelligence, 33(1):1–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Latora</author>
<author>M Marchiori</author>
</authors>
<title>Efficient behavior of small-world networks.</title>
<date>2001</date>
<journal>Phys. Rev. Lett.,</journal>
<volume>87</volume>
<issue>19</issue>
<contexts>
<context position="31856" citStr="Latora and Marchiori, 2001" startWordPosition="5074" endWordPosition="5077">ng one’s interaction partners and their current knowledge, and it needs to judge information according to its sources (trust). Meta-cognition could also play a role in determining when a set of signs is substantially novel and better than the current system, and thus worth enduring the cost of switching from a settled set of language conventions. We have evaluated only a small, initial part of a co-evolution theory we proposed. Also, the problem we describe may be best operationalized at a higher abstraction level: Consensus problems and information spread have been intensively studied (e.g., Latora and Marchiori, 2001; Wu et al., 2004). Comparing community convergence in a number of differently-structured networks, so far we see little evidence supporting our hypothesis, namely that cognition (memory) has specialized to accommodate social structures as defined by contemporary network science, and that those structures accommodate cognitive properties. Instead, we find that the simulated cognitive agents converge in their communication systems quite well regardless of the network structures, at least as long as those networks are relatively small and of similar average degrees. Acknowledgments This work was</context>
</contexts>
<marker>Latora, Marchiori, 2001</marker>
<rawString>Latora, V. and Marchiori, M. (2001). Efficient behavior of small-world networks. Phys. Rev. Lett., 87(19):198701.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R L Lewis</author>
<author>S Vasishth</author>
</authors>
<title>An activation-based model of sentence processing as skilled memory retrieval.</title>
<date>2005</date>
<journal>Cognitive Science,</journal>
<pages>29--1</pages>
<contexts>
<context position="7570" citStr="Lewis and Vasishth, 2005" startWordPosition="1162" endWordPosition="1166">eworks is crucial. Griffiths and Kalish (2007) for instance model language evolution through iteration among rational learners in a Bayesian framework; the purpose of the present project is to tie the simulation of language evolution to a concrete experiment and a more process-oriented cognitive architecture than the Bayesian framework. ACT-R’s learning mechanisms extend the Bayesian view with at least a notion of recency. Work on language processing has pointed out its relationship to memory retrieval from within the ACT-R framework, both for language comprehension (Budiu and Anderson, 2002; Lewis and Vasishth, 2005; Crescentini and Stocco, 2005; Ball et al., 2007) and for language production (Reitter, 2008). The individual language faculty as a result of biological evolution and adaptation to cultural language has been the focus of psycholinguistic models proposing specialized mechanisms (the Chomskian viewpoint); our model does not propose a specialized mechanism but rather declarative memory as store for lexical information, and procedural cognitive processes as regulators of certain communicative functions. Our multi-agent model sees part of the linguistic process as an instantiation of general cogni</context>
</contexts>
<marker>Lewis, Vasishth, 2005</marker>
<rawString>Lewis, R. L. and Vasishth, S. (2005). An activation-based model of sentence processing as skilled memory retrieval. Cognitive Science, 29:1–45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Pickering</author>
<author>S Garrod</author>
</authors>
<title>Toward a mechanistic psychology of dialogue.</title>
<date>2004</date>
<booktitle>Behavioral and Brain Sciences,</booktitle>
<pages>27--169</pages>
<marker>Pickering, Garrod, 2004</marker>
<rawString>Pickering, M. J. and Garrod, S. (2004). Toward a mechanistic psychology of dialogue. Behavioral and Brain Sciences, 27:169–225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Reitter</author>
</authors>
<title>Context Effects in Language Production: Models of Syntactic Priming in Dialogue Corpora.</title>
<date>2008</date>
<tech>PhD thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="7664" citStr="Reitter, 2008" startWordPosition="1179" endWordPosition="1180">mong rational learners in a Bayesian framework; the purpose of the present project is to tie the simulation of language evolution to a concrete experiment and a more process-oriented cognitive architecture than the Bayesian framework. ACT-R’s learning mechanisms extend the Bayesian view with at least a notion of recency. Work on language processing has pointed out its relationship to memory retrieval from within the ACT-R framework, both for language comprehension (Budiu and Anderson, 2002; Lewis and Vasishth, 2005; Crescentini and Stocco, 2005; Ball et al., 2007) and for language production (Reitter, 2008). The individual language faculty as a result of biological evolution and adaptation to cultural language has been the focus of psycholinguistic models proposing specialized mechanisms (the Chomskian viewpoint); our model does not propose a specialized mechanism but rather declarative memory as store for lexical information, and procedural cognitive processes as regulators of certain communicative functions. Our multi-agent model sees part of the linguistic process as an instantiation of general cognition: the composition and retrieval of signs follows general cognitive mechanisms and can be f</context>
</contexts>
<marker>Reitter, 2008</marker>
<rawString>Reitter, D. (2008). Context Effects in Language Production: Models of Syntactic Priming in Dialogue Corpora. PhD thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Reitter</author>
<author>C Lebiere</author>
</authors>
<title>Towards explaining the evolution of domain languages with cognitive simulation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 9th International Conference on Cognitive Modeling (ICCM),</booktitle>
<location>Manchester, UK.</location>
<contexts>
<context position="5323" citStr="Reitter and Lebiere, 2009" startWordPosition="817" endWordPosition="821">tion. Over time, participants develop common standards codifying those concepts: they develop a system of meaning-symbol pairs, or, signs. We take this system as the lexical core of the shared language. The convergence rate and the actual language developed differed as a function of the structure of the small participant communities: Fay (2010) either asked the same pairs of participants to engage in the activity repeatedly, or matched up different pairs of participants over time. Fay and Garrod’s Pictionary experiments served as the empirical basis for a cognitive process model developed by (Reitter and Lebiere, 2009). Our model has agents propose signs by combining more elementary signs from their divergent knowledge bases, and also adopt other agent’s proposals of signs for later reuse. The model, designed to match Fay’s communities, was studied in a condition involving groups of eight agents, with two network structures: maximally disjoint with the same pairs of agents throughout the simulation, and maximally connected, with interactions between all possible pairs of agents. Reitter and Lebiere’s (2009) cognitive model reflects the Pictionary game. The model explains the convergence as a result of basic</context>
</contexts>
<marker>Reitter, Lebiere, 2009</marker>
<rawString>Reitter, D. and Lebiere, C. (2009). Towards explaining the evolution of domain languages with cognitive simulation. In Proceedings of the 9th International Conference on Cognitive Modeling (ICCM), Manchester, UK.</rawString>
</citation>
<citation valid="false">
<authors>
<author>D Reitter</author>
<author>C Lebiere</author>
</authors>
<title>Towards explaining the evolution of domain languages with cognitive simulation. Cognitive Systems Research.</title>
<marker>Reitter, Lebiere, </marker>
<rawString>Reitter, D. and Lebiere, C. (subm.). Towards explaining the evolution of domain languages with cognitive simulation. Cognitive Systems Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Reitter</author>
<author>J D Moore</author>
</authors>
<title>Predicting success in dialogue.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL),</booktitle>
<pages>808--815</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="12650" citStr="Reitter and Moore, 2007" startWordPosition="1947" endWordPosition="1950">s coherent and adapts to their interlocutors, as speakers are known to do on even simple, linguistic levels (lexical, syntactic). This shifts the weight of the task from a sophisticated reasoning device to the simpler, more constrained implicit learning mechanism of the individual. The social network controls the interactions that the agents can experience. Each interaction is an opportunity to develop new signs and adapt the existing communication systems. It can be shown that even separate pairs of agents develop specialized communication systems, both empirically (Garrod and Doherty, 1994; Reitter and Moore, 2007; Kirby and Hurford, 2002) and in the specific model used here.When communication partners change, convergence towards a common system and the final transmission accuracy is slower (Fay et al., 2008). At this point it is unclear how the structure of the communication network and the learning process interact. Given that some types of networks show a wide distribution of degrees, where some nodes communicate much more often and with a wide variety of neighbors, while others communicate less often, recency and frequency of memory access will vary substantially. Other communication networks may r</context>
</contexts>
<marker>Reitter, Moore, 2007</marker>
<rawString>Reitter, D. and Moore, J. D. (2007). Predicting success in dialogue. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL), pages 808–815, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
</authors>
<title>The Syntactic Process.</title>
<date>2000</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Steedman, 2000</marker>
<rawString>Steedman, M. (2000). The Syntactic Process. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sun</author>
</authors>
<title>Cognitive science meets multiagent systems: A prolegomenon.</title>
<date>2001</date>
<journal>Philosophical Psychology,</journal>
<volume>14</volume>
<issue>1</issue>
<contexts>
<context position="11268" citStr="Sun, 2001" startWordPosition="1739" endWordPosition="1740">ess agents do not necessarily employ learning or adaptivity, and when they do, learning does not reflect known cognitive properties of human memory. The mechanisms governing learning and retrieval in human memory have been studied in detail, leading to formal models of process that detail the units that may be stored in and retrieved from memory, the retrieval time and accuracy depending on the frequency and recency of prior rehearsals, on contextual cues that may facilitate retrieval, and on individual differences. Cognitive agents can serve as a more realistic basis for network simulations (Sun, 2001). Frequency, recency, contextual cues and chunking of the stored information determine retrieval probability, which is crucial when novel idioms are required to express meaning in communication. The process leads to the choice of one of several available synonyms. Our model sees this decision-making process as a matter of memory retrieval: given the desired meaning, which sign (word or drawing, compound noun or drawings) can be used to express it. This process is implicit (not consciously controlled), and it follows recent suggestions from cognitive psychology: Pickering and Garrod’s (2004) In</context>
</contexts>
<marker>Sun, 2001</marker>
<rawString>Sun, R. (2001). Cognitive science meets multiagent systems: A prolegomenon. Philosophical Psychology, 14(1):5–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D J Watts</author>
<author>S H Strogatz</author>
</authors>
<title>Collective dynamics of /‘small-world/’ networks.</title>
<date>1998</date>
<journal>Nature,</journal>
<volume>393</volume>
<issue>6684</issue>
<contexts>
<context position="9980" citStr="Watts and Strogatz, 1998" startWordPosition="1533" endWordPosition="1537">ected to hubs. Non-organically connected communication and command networks follow other normals–tree graphs for instance. However, natural communication standards develop in networks that have very specific properties that can be observed in most organically developed networks. Realistic social networks commonly show very specific properties. Social networks, in which links symbolize communication pathways or some form of social acquaintance, frequently exhibit the small world property. The mean minimum distance between any two nodes is relatively low, and the clustering coefficient is high (Watts and Strogatz, 1998). Other forms of networks include tree hierarchies with a constant or variable branching factor (directed acyclic graphs). Such networks ressemble communication and command hierarchies in military or business organizations. N-dimensional grid networks have nodes with constant degrees, which are connected to each of their two neighbors along each dimension in a lattice. Much work on information or belief propagation, or decision-making in networks has used large artificial networks modeled after social ones; nodes in such networks are commonly simple agents that make decisions based on input fe</context>
<context position="29710" citStr="Watts and Strogatz, 1998" startWordPosition="4737" endWordPosition="4740">d, experiments, showed a similar picture with a smaller network as in Simulation 1. 15 6 Discussion We find that convergence is relatively stable across the four network types. Analyzing the differences between the networks, we find that the average degree, which was controlled for grids, random networks and small worlds, was substantially lower for trees (d = 1.9) due to the large number of leaves with degree 1. This (or the correlated algebraic connectivity of the network) may prove to be a deciding correlate with cross-network convergence. Other metrics, such as the clustering coefficient (Watts and Strogatz, 1998), which gives an indication of the degree of neighborhood cohesion We see these results still as preliminary. More work needs to be done to investigate how well learning scales with network growth, and how network analytics such as clustering coefficients affect the dispersion of information. Further work will explore range of networks and the possibly unique suitability of human learning mechanisms to succeed in such networks. We will explore the (subsymbolic) parameters governing adaptation, and to what extend the quantitative parameters we find universal to humans are substantially optimize</context>
</contexts>
<marker>Watts, Strogatz, 1998</marker>
<rawString>Watts, D. J. and Strogatz, S. H. (1998). Collective dynamics of /‘small-world/’ networks. Nature, 393(6684):440–442.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Wu</author>
<author>B A Huberman</author>
<author>L A Adamic</author>
<author>J R Tyler</author>
</authors>
<title>Information flow in social groups. Physica A: Statistical and Theoretical Physics,</title>
<date>2004</date>
<pages>337--1</pages>
<contexts>
<context position="31874" citStr="Wu et al., 2004" startWordPosition="5078" endWordPosition="5081">s and their current knowledge, and it needs to judge information according to its sources (trust). Meta-cognition could also play a role in determining when a set of signs is substantially novel and better than the current system, and thus worth enduring the cost of switching from a settled set of language conventions. We have evaluated only a small, initial part of a co-evolution theory we proposed. Also, the problem we describe may be best operationalized at a higher abstraction level: Consensus problems and information spread have been intensively studied (e.g., Latora and Marchiori, 2001; Wu et al., 2004). Comparing community convergence in a number of differently-structured networks, so far we see little evidence supporting our hypothesis, namely that cognition (memory) has specialized to accommodate social structures as defined by contemporary network science, and that those structures accommodate cognitive properties. Instead, we find that the simulated cognitive agents converge in their communication systems quite well regardless of the network structures, at least as long as those networks are relatively small and of similar average degrees. Acknowledgments This work was funded by the Air</context>
</contexts>
<marker>Wu, Huberman, Adamic, Tyler, 2004</marker>
<rawString>Wu, F., Huberman, B. A., Adamic, L. A., and Tyler, J. R. (2004). Information flow in social groups. Physica A: Statistical and Theoretical Physics, 337(1-2):327 – 335.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>