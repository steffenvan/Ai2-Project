<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.027097">
<title confidence="0.955383">
Simulating the acquisition of object names
</title>
<author confidence="0.621339">
Alessio Plebe and Vivian De la Cruz Marco Mazzone
</author>
<affiliation confidence="0.5724245">
Dept. Cognitive Science Lab. Cognitive Science
University of Messina - Italy University of Catania - Italy
</affiliation>
<email confidence="0.996083">
{alessio.plebe,vdelacruz}@unime.it mazzonem@unict.it
</email>
<sectionHeader confidence="0.998583" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998808714285714">
Naming requires recognition. Recognition requires
the ability to categorize objects and events. In-
fants under six months of age are capable of making
fine-grained discriminations of object boundaries and
three-dimensional space. At 8 to 10 months, a child’s
object categories are sufficiently stable and flexible to
be used as the foundation for labeling and referenc-
ing actions. What mechanisms in the brain underlie
the unfolding of these capacities? In this article, we
describe a neural network model which attempts to
simulate, in a biologically plausible way, the process
by which infants learn how to recognize objects and
words through exposure to visual stimuli and vocal
sounds.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999928117647059">
Humans, come to recognize an infinite variety of
natural and man-made objects and make use of
sounds to identify and categorize them. How do hu-
man beings arrive at this capacity? Different expla-
nations have been offered to explain the processes,
and those behind the learning of first words in par-
ticular.
Evidence has made clear that object recognition
and categorization in early infancy is much more so-
phisticated than was previously thought. By the time
children are 8 to 10 months old their object cate-
gories are sufficiently stable and flexible to be used
as the foundation for labeling and referencing ac-
tions. Increasing amounts of evidence point to the
growing capacity of infants at this stage to reliably
map arbitrary sounds onto meanings and this map-
ping process is crucial to the acquisition of language.
</bodyText>
<page confidence="0.994331">
57
</page>
<bodyText confidence="0.999885088235294">
The word-learning mechanisms used at this early
phase of language learning could very well involve a
mapping of words onto the most perceptually inter-
esting objects in an infant’s environment (Pruden et
al., 2006). There are those that claim that early word
learning is not purely associative and that it is based
on a sensitivity to social intent (Tomasello, 1999),
through joint attention phenomena (Bloom, 2000).
Pruden et al. have demonstrated that 10-month-old
infants “are sensitive to social cues but cannot recruit
them for word learning” and therefore, at this age
infants presumably have to learn words on a simple
associative basis. It is not by chance, it seems, that
early vocabulary is made up of the objects infants
most frequently see (Gershkoff-Stowe and Smith,
2004). Early word-learning and object recognition
can thus be explained, according to a growing group
of researchers, by associational learning strategies
alone.
There are those such as Carey and Spelke that
postulate that there must necessarily be innate con-
straints that have the effect of making salient cer-
tain features as opposed to others, so as to narrow
the hypothesis space with respect to the kinds of
objects to be categorized first (Carey and Spelke,
1996). They reject the idea that object categorization
in infants could emerge spontaneously from the abil-
ity to grasp patterns of statistical regularities. Jean
Mandler presents evidence that the first similarity di-
mensions employed in categorization processes are
indeed extremely general (Mandler, 2004); in other
words, these dimensions single out wide domains of
objects, with further refinements coming only later.
Mandler claims, however, that the early salience of
</bodyText>
<note confidence="0.8756645">
Proceedings of the Workshop on Cognitive Aspects of Computational Language Acquisition, pages 57–64,
Prague, Czech Republic, June 2007 c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999944813333334">
these extremely general features could have a dif-
ferent explanation other than nativism: for example,
that salience could emerge from physiological con-
straints.
Using a connectionist model with backpropaga-
tion, Rogers and McClelland have shown that quite
general dimensions of similarity can emerge with-
out appealing to either physiological or cognitive
constraints, simply as the result of a coherent co-
variation of features, that is, as an effect of mere sta-
tistical regularities (Rogers and McClelland, 2006).
What Rogers and McClelland say about the most
general features obviously apply also to more spe-
cific features which become salient later on. How-
ever, interesting as it is from a computational point
of view, this model is rather unrealistic as a simula-
tion of biological categorization processes.
Linda Smith, suggests that words can contribute
to category formation, in that they behave as features
which co-vary with other language-independent fea-
tures of objects (Smith, 1999). In general, her idea
is that the relevant features simply emerge from reg-
ularities in the input. Terry Regier, building upon
the proposal offered by Smith, has shown that word
learning might behave in analogy with what we have
said about categorization (Regier, 2005): certain
features of both objects and words (i.e., phonolog-
ical forms) can be made more salient than others,
simply as a consequence of regularities in objects,
words, and their co-variation. Regier’s training sets
however, are constituted by wholly “artificial phono-
logical or semantic features”, rather than by “nat-
ural features such as voicing or shape”. The posi-
tions mentioned above conflict with others, such as
that of Lila Gleitman and her colleagues, according
to which some innate constraints are needed in or-
der to learn words. It should be noted, however,
that even in Gleitman’s proposal the need for in-
nate constraints on syntax-semantic mapping mainly
concerns verbs; moreover, the possibility to appre-
hend a core set of concrete terms without the con-
tribution of any syntactic constraint is considered as
a precondition for verb acquisition itself (Gillette et
al., 1999).
This paper describes a neural network model
which attempts to simulate the process by which in-
fants learn how to recognize objects and words in
the first year of life through exposure to visual stim-
uli and vocal sounds. The approach here pursued is
in line with the view that a coherent covariation of
features is the major engine leading to object name
acquisition, the attempt made however, is to rely on
biological ways of capturing coherent covariation.
The pre-established design of the mature functions
of the organism is avoided, and the emergence of
the final function of each component of the system is
left to the plastic development of the neural circuits.
In the cortex, there is very little differentiation in the
computational capability that neural circuits will po-
tentially perform in the mature stage. The interac-
tion between environmental stimuli and some of the
basic mechanisms of development is what drives dif-
ferentiation in computational functions. This posi-
tion has large empirical support (Katz and Callaway,
1992; L¨owel and Singer, 2002), and is compatible
with current knowledge on neural genetics (Quartz,
2003).
The model here described, can be considered an
implementation of the processes that emerge around
the 10 month of age period. It can also be used to
consider what happens in a hypothesized subsequent
period, in which the phenomenon of joint attention
provides the social cueing that leads to the increased
ability to focus on certain objects as opposed to oth-
ers.
</bodyText>
<sectionHeader confidence="0.881943" genericHeader="method">
2 The proposed model
</sectionHeader>
<bodyText confidence="0.9981414">
First the mathematics common to the modules will
be described, then the model will be outlined. De-
tails of the visual and the auditory paths will be pro-
vided along with a description of the learning proce-
dures.
</bodyText>
<subsectionHeader confidence="0.992801">
2.1 The mathematical abstraction of the
cortical maps
</subsectionHeader>
<bodyText confidence="0.9997551">
All the modules composing this model are imple-
mented as artificial cortical maps, adopting the LIS-
SOM (Laterally Interconnected Synergetically Self-
Organizing Map) architecture (Sirosh and Miikku-
lainen, 1997; Bednar, 2002). This architecture has
been chosen because of its reproduction of neural
plasticity, through the combination of Hebb’s princi-
ple and neural homeostasis, and because it is a good
compromise between a number of realistic features
and the simplicity necessary for building complex
</bodyText>
<page confidence="0.996027">
58
</page>
<figure confidence="0.99586325">
STS LOC
MGN
LPC HPC
A1
</figure>
<figureCaption confidence="0.951934">
Figure 1: Overall scheme of the model.
</figureCaption>
<figure confidence="0.9734376">
AAM
V2
V1
VO
LGN
</figure>
<bodyText confidence="0.999021">
models. The LISSOM is a two dimensional arrange-
ment of neurons, where each cell is not only con-
nected with the afferent input vector, but receives ex-
citatory and inhibitory inputs from several neighbor
neurons on the same map:
</bodyText>
<equation confidence="0.995240142857143">
x(k) = f γA
i 1 + γN~I · ~vrA,i
+ γE~erE,i · x~ (k−1)
rE,i (1)
− γH ~h (k-1)~
rH,i x ,
rH,i
</equation>
<bodyText confidence="0.99095764516129">
where x(k)
i is the activation of the neuron i at time
step k. All vectors are composed by a circular neigh-
borhood of given radius around the neuron i: vectors
x~ (k−1) are activations of neurons on the same layer
at the previous time step. Vector ~vrA,i comprises all
neurons in the underlying layer, in a circular area
centered on the projection of i on this layer, with ra-
~
dius rA. Vectors ~arA,i, ~erE,i, and hrH,i are composed
by all connection strengths of, afferent, excitatory or
inhibitory neurons respectively, projecting to i, in-
side circular areas of radius rA, rE, rH. Vector I~ is
just a vector of 1’s of the same dimension of ~vrA,i.
The scalars γA, γE, and γH, are constants modulat-
ing the contribution of afferent, excitatory and in-
hibitory connections. The scalar γN controls the set-
ting of a push-pull effect in the afferent weights, al-
lowing inhibitory effect without negative weight val-
ues. Mathematically, it represents dividing the re-
sponse from the excitatory weights by the response
from a uniform disc of inhibitory weights over the
receptive field of neuron i. The map is character-
ized by the matrices A, E, H, which columns are all
~
vectors ~a, ~e, h for every neuron in the map. The
function f is a monotonic non-linear function lim-
ited between 0 and 1. The final activation value of
the neurons is assessed after settling time K.
All connection strengths to neuron i adapt by fol-
lowing the rules:
</bodyText>
<equation confidence="0.998329">
~arA,i + ηAxi~vrA,i −
~arE,i + ηExi~xrE,i −
~hrH,i + ηAxi~xrH,i
u �
~hrH,i + ηAxi~xrH,i � �
</equation>
<bodyText confidence="0.999939333333333">
where η1A,E,H} are the learning rates for afferent, ex-
citatory and inhibitory synaptic modifications. All
rules are based on the Hebbian law, with an ad-
ditional competitive factor, here implemented as a
normalization, that maintains constant the integra-
tion of all connection strengths to the same neu-
</bodyText>
<equation confidence="0.998999111111111">
~arA,i · ~vrA,i
A~arA,i =
A~erE,i =
A~hrH,i =
~arA,i + ηAxi~vrA,i
~erE,i + ηExi~xrE,i
− ~hrH,i, (4)
~arA,i, (2)
~erE,i, (3)
</equation>
<page confidence="0.99587">
59
</page>
<table confidence="0.999269222222222">
layer size rA rE rH 7A 7E 7H 7N
LGN Lateral Geniculated Nucleus 120 x 120 - - - - - - -
MGN Medial Geniculated Nucleus 32 x 32 - - - - - - -
V1 Primary Visual Cortex 96 x 96 8.5 1.5 7.0 1.5 1.0 1.0 0.0
V2 Secondary Visual Cortex 30 x 30 7.5 8.5 3.5 50.0 3.2 2.5 0.7
VO Ventral Occipital 30 x 30 24.5 4.0 8.0 1.8 1.0 1.0 0.0
A1 Auditory Primary Cortex 24 x 24 3.5 2.5 5.5 5.0 5.0 6.7 0.8
LOC Lateral Occipital Complex 16 x 16 6.5 1.5 3.5 1.2 1.0 1.5 0.0
STS Superior Temporal Sulcus 16 x 16 3.5 2.5 2.5 2.0 1.6 2.6 0.0
</table>
<tableCaption confidence="0.99989">
Table 1: Legend of all modules, and main parameters of the cortical layers composing the model.
</tableCaption>
<bodyText confidence="0.9998395">
ron, and to the same type (afferent, excitatory or in-
hibitory). This is a computational account of the bi-
ological phenomena of homeostatic plasticity, that
induce neurons in the cortex to maintain an aver-
age firing rate by correcting their incoming synaptic
strengths.
</bodyText>
<subsectionHeader confidence="0.988515">
2.2 The overall model
</subsectionHeader>
<bodyText confidence="0.99995508">
An outline of the modules that make up the model
is shown in Fig. 1. The component names and their
dimensions are in Tab. 1. All cortical layers are
implemented by LISSOM maps, where the afferent
connections v in (1) are either neurons of lower LIS-
SOM maps, or neurons in the thalamic nuclei MGN
and LGN. There are two main paths, one for the
visual process and another for the auditory chan-
nel. Both paths include thalamic modules, which are
not the object of this study and are therefore hard-
wired according to what is known about their func-
tions. The two higher cortical maps, LOC and STS,
will carry the best representation coded by models
on object visual features and word features. These
two representations are associated in an abstract type
map, called AAM (Abstract Associative Map). This
component is implemented using the SOM (Self Or-
ganized Map) (Kohonen, 1995) architecture, known
to provide non linear bidimensional ordering of in-
put vectors by unsupervised mechanisms. It is the
only component of the model that cannot be concep-
tually referred to as a precise cortical area. It is an
abstraction of processes that actually involve several
brain areas in a complex way, and as such departs
computationally from realistic cortical architecture.
</bodyText>
<subsectionHeader confidence="0.964087">
2.3 The visual pathway
</subsectionHeader>
<bodyText confidence="0.99938255">
As shown in Fig. 1, the architecture here used in-
cludes hardwired extracortical maps with simple on-
center and off-center receptive fields. There are
three pairs of sheets in the LGN maps: one con-
nected to the intensity image plane, and the other
two connected to the medium and long wavelength
planes. In the color channels the internal excita-
tory portion of the receptive field is connected to the
channel of one color, and the surrounding inhibitory
part to the opposite color. The cortical process pro-
ceeds along two different streams: the achromatic
component is connected to the primary visual map
V1 followed by V2, the two spectral components are
processed by map VO, the color center, also called
hV4 or V8 (Brewer et al., 2005). The two streams
rejoin in the cortical map LOC, the area recently
suggested as being the first involved in object recog-
nition in humans (Malach et al., 1995; Kanwisher,
2003). Details of the visual path are in (Plebe and
Domenella, 2006).
</bodyText>
<subsectionHeader confidence="0.9819">
2.4 The auditory pathway
</subsectionHeader>
<bodyText confidence="0.999976058823529">
The hardwired extracortical MGN component is
just a placeholder for the spectrogram represen-
tation of the sound pressure waves, which is ex-
tracted with tools of the Festival software (Black
and Taylor, 1997). It is justified by evidence
of the spectro-temporal process performed by the
cochlear-thalamic circuits (Escabi and Read, 2003).
The auditory primary cortex is simulated by a double
sheet of neurons, taking into account a double popu-
lation of cells found in this area (Atzori et al., 2001),
where the so-called LPC (Low-Probability Connec-
tions) is sensitive to the stationary component of
the sound signal and the HPC (High-Probability
Connections) population responds to transient inputs
mainly. The next map in the auditory path of the
model is STS, because the superior temporal sulcus
is believed to be the main brain area responsive to
</bodyText>
<page confidence="0.993307">
60
</page>
<note confidence="0.551439">
vocal sounds (Belin et al., 2002).
</note>
<subsectionHeader confidence="0.905202">
2.5 The Abstract Associative Map
</subsectionHeader>
<bodyText confidence="0.946088384615384">
The upper AAM map in the model reflects how the
system associates certain sound forms with the vi-
sual appearance of objects, and has the main pur-
pose of showing what has been achieved in the cor-
tical part of the model. It is trained using the outputs
of the STS and the LOC maps of the model. Af-
ter training, each neuron x in AAM is labeled, ac-
cording to different test conditions X. The labeling
function l(·) associates the neuron x with an entity
e, which can be an object o of the COIL set O, when
X E {A, B} or a category c of the set C for the test
condition X E {C, D}. The general form of the la-
beling function is:
</bodyText>
<equation confidence="0.9935935">
l (X ) (x) = arg maxn W�e) } (5)
eE£
</equation>
<bodyText confidence="0.995898428571429">
where W(e)
� is a set of sensorial stimuli related to
the element e E £, such that their processing in
the model activate x as winner in the AMM map.
The set £ can be O or C depending on X. The
neuron x elicited in the AAM map as the conse-
quence of presenting a visual stimulus vo of an ob-
ject o and a sound stimulus se of a tagory c is given
by the function x = w(vo, se) with the convention
that w(v, E) computes the winning neuron in AAM
comparing only the LOC portion of the coding vec-
tor, and w(E, s) only the STS portion. The function
b(o) : O —* C associates an object o to its category.
Here four testing conditions are used:
</bodyText>
<listItem confidence="0.999754">
• A object recognition by vision and audio
• B object recognition by vision only
• C category recognition by vision and audio
• D category recognition by audio only
</listItem>
<bodyText confidence="0.860579">
corresponding to the following W sets in (5):
</bodyText>
<equation confidence="0.99950275">
A : ~vo : x = w(vo, se(o)) (6)
B : {vo : x = w(vo, E)} (7)
C : {vo : c = b(o) n x = w(E, se)} (8)
D : {se : x = w(E, se)} (9)
</equation>
<bodyText confidence="0.9999428">
From the labeling functions the possibility of esti-
mating the accuracy of recognition immediately fol-
lows, simply by weighing the number of cases where
the category or the object has been classified as the
prevailing one in each neuron of the AAM SOM.
</bodyText>
<subsectionHeader confidence="0.981657">
2.6 Exposure to stimuli
</subsectionHeader>
<bodyText confidence="0.999977605263158">
The visual path in the model develops in two stages.
Initially the inputs to the network are synthetic ran-
dom blobs, simulating pre-natal waves of sponta-
neous activity, known to be essential in the early de-
velopment of the visual system (Sengpiel and Kind,
2002). In the second stage, corresponding to the pe-
riod after eye opening, natural images are used. In
order to address one of the main problems in recog-
nition, the identifying of an object under different
views, the COIL-100 collection has been used (Na-
yar and Murase, 1995) where 72 different views are
available for each of the 100 objects. Using natural
images where there is only one main object is cleary
a simplification in the vision process of this model,
but it does not compromise the realism of the con-
ditions. It always could be assumed that the single
object analysis corresponds to a foval focusing as
consequence of a saccadic move, cued by any atten-
tive mechanism.
In the auditory path there are different stages
as well. Initially, the maps are exposed to ran-
dom patches in frequency-time domain, with
shorter duration for HPC and longer for LPC.
Subsequently, all the auditory maps are exposed
to the 7200 most common English words (from
http://www.bckelk.uklinux.net/menu.html)
with lengths between 3 and 10 characters. All words
are converted from text to waves using Festival
(Black and Taylor, 1997), with cepstral order 64 and
a unified time window of 2.3 seconds. Eventually,
the last stage of training simulates events when
an object is viewed and a word corresponding to
its basic category is heard simultaneously. The
100 objects have been grouped manually into
38 categories. Some categories, such as cup
or medicine count 5 exemplars in the object
collection, while others, such as telephone, have
only one exemplar.
</bodyText>
<sectionHeader confidence="0.99999" genericHeader="evaluation">
3 Results
</sectionHeader>
<subsectionHeader confidence="0.999106">
3.1 Developed functions in the cortical maps
</subsectionHeader>
<bodyText confidence="0.999277">
At the end of development each map in the model
has evolved its own function. Different functions
</bodyText>
<page confidence="0.998431">
61
</page>
<bodyText confidence="0.999977645833333">
have emerged from identical computational archi-
tectures. The differences are due to the different po-
sitions of a maps in the modules hierarchy, to differ-
ent exposure to environmental stimuli, and different
structural parameters. The functions obtained in the
experiment are the following. In the visual path ori-
entation selectivity emerged in the model’s V1 map
as demonstrated in (Sirosh and Miikkulainen, 1997)
and (Plebe and Domenella, 2006). Orientation se-
lectivity is the main organization in primary visual
cortex, where the responsiveness of neurons to ori-
ented segments is arranged over repeated patterns of
gradually changing orientations, broken by few dis-
continuities (Vanduffel et al., 2002). Angle selec-
tivity emerged in the model’s V2 map. In the sec-
ondary visual cortex the main recently discovered
phenomena is the selectivity to angles (Ito and Ko-
matsu, 2004), especially in the range between 60
and 150 degrees. The essential features of color
constancy are reproduced in the model’s VO map,
which is the ability of neurons to respond to specific
hues, regardless of intensity. Color constancy is the
tendency of the color of a surface to appear more
constant that it is in reality. This property is help-
ful in object recognition, and develops sometime be-
tween two and four months of age. (Dannemiller,
1989). One of the main functions shown by the LOC
layer in the model is visual invariance, the prop-
erty of neurons to respond to peculiar object fea-
tures despite changes in the object’s appearance due
to different points of view. Invariance indeed is one
of the main requirements for an object-recognition
area, and is found in human LOC (Grill-Spector et
al., 2001; Kanwisher, 2003). Tonotopic mapping is
a known feature of the primary auditory cortex that
represents the dimensions of frequency and time se-
quences in a sound pattern (Verkindt et al., 1995).
In the model it is split into a sheet where neurons
have receptive fields that are more elongated along
the time dimension (LPC) and another where the
resulting receptive fields are more elongated along
the frequency dimension (HPC). The spectrotempo-
ral mapping obtained in STS is a population coding
of features, in frequency and time domains, repre-
sentative of the sound patterns heard during the de-
velopment phase. It therefore reflects the statistical
phonemic regularities in common spoken English,
extracted from the 7200 training samples.
</bodyText>
<table confidence="0.999432307692307">
category test A test B test C test D
medicine 0.906 0.803 1.0 1.0
fruit 1.0 0.759 1.0 1.0
boat 0.604 0.401 1.0 1.0
tomato 1.0 0.889 1.0 1.0
sauce 1.0 1.0 1.0 1.0
car 0.607 0.512 0.992 1.0
drink 0.826 0.812 1.0 1.0
soap 0.696 0.667 1.0 1.0
cup 1.0 0.919 1.0 0.0
piece 0.633 0.561 1.0 1.0
kitten 1.0 0.806 1.0 1.0
bird 1.0 1.0 1.0 1.0
truck 0.879 0.556 1.0 1.0
dummy 1.0 0.833 1.0 1.0
tool 0.722 0.375 1.0 1.0
pottery 1.0 1.0 1.0 1.0
jam 1.0 1.0 1.0 1.0
frog 1.0 0.806 1.0 1.0
cheese 0.958 0.949 1.0 1.0
bottle 0.856 0.839 1.0 1.0
hanger 1.0 0.694 1.0 1.0
sweets 1.0 0.701 1.0 1.0
tape 1.0 0.861 1.0 1.0
mug 0.944 0.889 1.0 1.0
spoon 1.0 0.680 1.0 1.0
cigarettes 0.972 0.729 0.972 1.0
ring 1.0 1.0 1.0 1.0
pig 1.0 0.778 1.0 1.0
dog 1.0 0.917 1.0 1.0
toast 1.0 0.868 1.0 1.0
plug 1.0 0.771 1.0 1.0
pot 1.0 0.681 1.0 1.0
telephone 1.0 0.306 1.0 1.0
pepper 1.0 0.951 1.0 1.0
chewinggum 0.954 0.509 1.0 1.0
chicken 1.0 0.944 1.0 1.0
jug 1.0 0.917 1.0 1.0
can 1.0 0.903 1.0 1.0
</table>
<tableCaption confidence="0.9984255">
Table 2: Accuracy in recognition measured by labeling in the
AAM, for objects grouped by category.
</tableCaption>
<subsectionHeader confidence="0.999919">
3.2 Recognition and categorization in AAM
</subsectionHeader>
<bodyText confidence="0.999756307692308">
The accuracy of object and category recognition un-
der several conditions is shown in Table 2. All tests
clearly prove that the system has learned an efficient
capacity of object recognition and naming, with re-
spect to the small world of object and names used in
the experiment. Tests C and D demonstrate that the
recognition of categories by names is almost com-
plete, both when hearing a name or when seeing an
object and hearing its name. In tests A and B, the
recognition of individual objects is also very high.
In several cases, it can be seen that names also help
in the recognition of individual objects. One of the
clearest cases is the category tool (shown in Fig. 2),
</bodyText>
<page confidence="0.996879">
62
</page>
<table confidence="0.999220307692308">
shape test A test B A
h-parallelepiped 0.921 0.712 0.209
round 1.0 0.904 0.096
composed 0.702 0.565 0.137
q-cylindrical 0.884 0.861 0.023
q-h-parallelepiped 0.734 0.513 0.221
cylindrical 0.926 0.907 0.019
cup-shaped 0.975 0.897 0.078
q-v-parallelepiped 0.869 0.754 0.115
body 1.0 0.869 0.131
conic 1.0 1.0 0.0
parallelepiped 0.722 0.510 0.212
q-parallelepiped 1.0 0.634 0.366
</table>
<tableCaption confidence="0.977270333333333">
Table 3: Accuracy in recognition measured by labeling in the
AAM, for objects grouped by their visual shape, A is the im-
provement gained with naming.
</tableCaption>
<bodyText confidence="0.999901555555556">
where the accuracy for each individual object dou-
bles when using names. It seems to be analogous to
the situation described in (Smith, 1999), where the
word contributes to the emergence of patterns of reg-
ularity. The 100% accuracy for the category, in this
case, is better accounted for as an emergent example
of synonymy, where coupling with the same word is
accepted, despite the difference in the output of the
visual process.
In table 3 accuracy results for individual objects
are listed, grouped by object shape. In this case cat-
egory accuracy cannot be computed, because shapes
cross category boundaries. It can be seen that the im-
provement 0 is proportional to the salience in shape:
it is meaningless for common, obvious shapes, and
higher when object shape is uncommon. This result
is in agreement with findings in (Gershkoff-Stowe
and Smith, 2004).
</bodyText>
<sectionHeader confidence="0.999588" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999977323529412">
The model here described attempts to simulate lexi-
cal acquisition from auditory and visual stimuli from
a brain processes point of view. It models these pro-
cesses in a biologically plausible way in that it does
not begin with a predetermined design of mature
functions, but instead allows final functions of the
components to emerge as a result of the plastic de-
velopment of neural circuits. It grounds this choice
and its design principles in what is known of the
cerebral cortex. In this model, the overall important
result achieved so far, is the emergence of naming
and recognition abilities exclusively through expo-
sure of the system to environmental stimuli, in terms
of activities similar to pre-natal spontaneous activi-
ties, and later to natural images and vocal sounds.
This result has interesting theoretical implications
for developmental psychologists and may provide
a useful computational tool for future investigations
on phenomena such as the effects of shape on object
recognition and naming.
In conclusion this model represents a first step in
simulating the interaction of the visual and the audi-
tory cortex in learning object recognition and nam-
ing, and being a model of high level complex cog-
nitive functions, it necessarily lacks several details
of the biological cortical circuits. It lacks biologi-
cal plausibility in the auditory path because of the
state of current knowledge of the processes going on
there. Future developments of the model will fore-
see the inclusion of backprojections between maps
in the hierarchy, trials on preliminary categorization
at the level of phonemes and syllables in the auditory
path, as well as exposure to images with multiple ob-
jects in the scene.
</bodyText>
<sectionHeader confidence="0.99814" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999323730769231">
Marco Atzori, Saobo Lei, D. Ieuan P. Evans, Patrick O. Kanold,
Emily Phillips-Tansey, Orinthal McIntyre, and Chris J.
McBain. 2001. Differential synaptic processing separates
stationary from transient inputs to the auditory cortex. Neu-
ral Networks, 4:1230–1237.
James A. Bednar. 2002. Learning to See: Genetic and Envi-
ronmental Influences on Visual Development. Ph.D. thesis,
University of Texas at Austin. Tech Report AI-TR-02-294.
Pascal Belin, Robert J. Zatorre, and Pierre Ahad. 2002. Human
temporal-lobe response to vocal sounds. Cognitive Brain
Research, 13:17–26.
Alan W. Black and Paul A. Taylor. 1997. The festival speech
synthesis system: System documentation. Technical Re-
port HCRC/TR-83, Human Communciation Research Cen-
tre, University of Edinburgh, Edinburgh, UK.
Paul Bloom. 2000. How children learn the meanings of words.
MIT Press, Cambridge (MA).
Alyssa A. Brewer, Junjie Liu, Alex R. Wade, and Brian A. Wan-
dell. 2005. Visual field maps and stimulus selectivity in hu-
man ventral occipital cortex. Nature Neuroscience, 8:1102–
1109.
Susan Carey and Elizabeth Spelke. 1996. Science and core
knowledge. Journal of Philosophy of Science, 63:515–533.
James L. Dannemiller. 1989. A test of color constancy in 9- and
20-weeks-old human infants following simulated illuminant
changes. Developmental Psychology, 25:171–184.
</reference>
<page confidence="0.999263">
63
</page>
<figureCaption confidence="0.951479666666667">
Figure 2: Objects mentioned in the discussion on recognition results. In the upper row views of the two objects of the category
tool. In the middle row objects with difficult shapes (q-h-parallelepiped, q-parallelepiped). In the lower row
objects with easy shapes (cylindrical, round, and conic).
</figureCaption>
<reference confidence="0.999304133333334">
Monty A. Escabi and Heather L. Read. 2003. Representation of
spectrotemporal sound information in the ascending auditory
pathway. Biological Cybernetics, 89:350–362.
Lisa Gershkoff-Stowe and Linda B. Smith. 2004. Shape and
the first hundred nouns. Child Development, 75:1098–1114.
Jane Gillette, Henry Gleitman, Lila Gleitman, and Anne Led-
erer. 1999. Human simulations of vocabulary learning.
Cognition, 73:135–176.
Kalanit Grill-Spector, Zoe Kourtzi, and Nancy Kanwisher.
2001. The lateral occipital complex and its role in object
recognition. Vision Research, 41:1409–1422.
Minami Ito and Hidehiko Komatsu. 2004. Representation
of angles embedded within contour stimuli in area V2 of
macaque monkeys. Journal of Neuroscience, 24:3313–3324.
Nancy Kanwisher. 2003. The ventral visual object pathway
in humans: Evidence from fMRI. In Leo Chalupa and John
Werner, editors, The Visual Neurosciences. MIT Press, Cam-
bridge (MA).
Lawrence C. Katz and Edward M. Callaway. 1992. Develop-
ment of local circuits in mammalian visual cortex. Annual
Review Neuroscience, 15:31–56.
Teuvo Kohonen. 1995. Self-Organizing Maps. Springer-
Verlag, Berlin.
Siegrid L¨owel and Wolf Singer. 2002. Experience-dependent
plasticity of intracortical connections. In Manfred Fahle and
Tomaso Poggio, editors, Perceptual Learning. MIT Press,
Cambridge (MA).
R. Malach, J. B. Reppas, R. R. Benson, K. K. Kwong, H. Jiang,
W. A. Kennedy, P. J. Ledden, T. J. Brady, B. R. Rosen, and
R. B.H. Tootell. 1995. Object-related activity revealed by
functional magnetic resonance imaging in human occipital
cortex. Proceedings of the Natural Academy of Science USA,
92:8135–8139.
Jean Matter Mandler. 2004. The Foundations of Mind. Oxford
University Press, Oxford (UK).
Shree Nayar and Hiroshi Murase. 1995. Visual learning and
recognition of 3-d object by appearence. International Jour-
nal of Computer Vision, 14:5–24.
Alessio Plebe and Rosaria Grazia Domenella. 2006. Early de-
velopment of visual recognition. BioSystems, 86:63–74.
Shannon M. Pruden, Kathy Hirsh-Pasek, Roberta Michnick
Golinkoff, and Elizabeth A. Hennon. 2006. The birth
of words: Ten-month-olds learn words through perceptual
salience. Child Development, 77:266–280.
Steven R. Quartz. 2003. Innateness and the brain. Biology and
Philosophy, 18:13–40.
Terry Regier. 2005. The emergence of words: Attentional
learning in form and meaning. Cognitive Science, 29:819–
865.
Timothy T. Rogers and James L. McClelland. 2006. Seman-
tic Cognition - A Parallel Distributed Processing Approach.
MIT Press, Cambridge (MA).
Frank Sengpiel and Peter C. Kind. 2002. The role of activity in
development of the visual system. Current Biology, 12:818–
826.
Joseph Sirosh and Risto Miikkulainen. 1997. Topographic
receptive fields and patterned lateral interaction in a self-
organizing model of the primary visual cortex. Neural Com-
putation, 9:577–594.
Linda B. Smith. 1999. Children’s noun learning: How general
learning processes make specialized learning mechanisms.
In Brian MacWhinney, editor, The Emergence of Language.
Lawrence Erlbaum Associates, Mahwah (NJ). Second Edi-
tion.
Michael Tomasello. 1999. The cultural origins of human cog-
nition. Harvard University Press, Cambridge (MA).
Wim Vanduffel, Roger B.H. Tootell, Anick A. Schoups, and
Guy A. Orban. 2002. The organization of orientation selec-
tivity throughout the macaque visual cortex. Cerebral Cor-
tex, 12:647–662.
Chantal Verkindt, Olivier Bertrand, Frano¸is Echallier, and
Jacques Pernier. 1995. Tonotopic organization of the hu-
man auditory cortex: N100 topography and multiple dipole
model analysis. Electroencephalography and Clinical Neu-
rophisiology, 96:143–156.
</reference>
<page confidence="0.999418">
64
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.950878">
<title confidence="0.999907">Simulating the acquisition of object names</title>
<author confidence="0.999733">Alessio Plebe</author>
<author confidence="0.999733">Vivian De_la Cruz Marco Mazzone</author>
<affiliation confidence="0.998396">Dept. Cognitive Science Lab. Cognitive Science University of Messina - Italy University of Catania - Italy</affiliation>
<email confidence="0.995703">mazzonem@unict.it</email>
<abstract confidence="0.997080066666667">Naming requires recognition. Recognition requires the ability to categorize objects and events. Infants under six months of age are capable of making fine-grained discriminations of object boundaries and three-dimensional space. At 8 to 10 months, a child’s object categories are sufficiently stable and flexible to be used as the foundation for labeling and referencing actions. What mechanisms in the brain underlie the unfolding of these capacities? In this article, we describe a neural network model which attempts to simulate, in a biologically plausible way, the process by which infants learn how to recognize objects and words through exposure to visual stimuli and vocal sounds.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Marco Atzori</author>
<author>Saobo Lei</author>
<author>D Ieuan P Evans</author>
<author>Patrick O Kanold</author>
<author>Emily Phillips-Tansey</author>
<author>Orinthal McIntyre</author>
<author>Chris J McBain</author>
</authors>
<title>Differential synaptic processing separates stationary from transient inputs to the auditory cortex.</title>
<date>2001</date>
<journal>Neural Networks,</journal>
<pages>4--1230</pages>
<contexts>
<context position="14170" citStr="Atzori et al., 2001" startWordPosition="2347" endWordPosition="2350">h et al., 1995; Kanwisher, 2003). Details of the visual path are in (Plebe and Domenella, 2006). 2.4 The auditory pathway The hardwired extracortical MGN component is just a placeholder for the spectrogram representation of the sound pressure waves, which is extracted with tools of the Festival software (Black and Taylor, 1997). It is justified by evidence of the spectro-temporal process performed by the cochlear-thalamic circuits (Escabi and Read, 2003). The auditory primary cortex is simulated by a double sheet of neurons, taking into account a double population of cells found in this area (Atzori et al., 2001), where the so-called LPC (Low-Probability Connections) is sensitive to the stationary component of the sound signal and the HPC (High-Probability Connections) population responds to transient inputs mainly. The next map in the auditory path of the model is STS, because the superior temporal sulcus is believed to be the main brain area responsive to 60 vocal sounds (Belin et al., 2002). 2.5 The Abstract Associative Map The upper AAM map in the model reflects how the system associates certain sound forms with the visual appearance of objects, and has the main purpose of showing what has been ac</context>
</contexts>
<marker>Atzori, Lei, Evans, Kanold, Phillips-Tansey, McIntyre, McBain, 2001</marker>
<rawString>Marco Atzori, Saobo Lei, D. Ieuan P. Evans, Patrick O. Kanold, Emily Phillips-Tansey, Orinthal McIntyre, and Chris J. McBain. 2001. Differential synaptic processing separates stationary from transient inputs to the auditory cortex. Neural Networks, 4:1230–1237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James A Bednar</author>
</authors>
<title>Learning to See: Genetic and Environmental Influences on Visual Development.</title>
<date>2002</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Texas at Austin.</institution>
<contexts>
<context position="7850" citStr="Bednar, 2002" startWordPosition="1233" endWordPosition="1234">s the social cueing that leads to the increased ability to focus on certain objects as opposed to others. 2 The proposed model First the mathematics common to the modules will be described, then the model will be outlined. Details of the visual and the auditory paths will be provided along with a description of the learning procedures. 2.1 The mathematical abstraction of the cortical maps All the modules composing this model are implemented as artificial cortical maps, adopting the LISSOM (Laterally Interconnected Synergetically SelfOrganizing Map) architecture (Sirosh and Miikkulainen, 1997; Bednar, 2002). This architecture has been chosen because of its reproduction of neural plasticity, through the combination of Hebb’s principle and neural homeostasis, and because it is a good compromise between a number of realistic features and the simplicity necessary for building complex 58 STS LOC MGN LPC HPC A1 Figure 1: Overall scheme of the model. AAM V2 V1 VO LGN models. The LISSOM is a two dimensional arrangement of neurons, where each cell is not only connected with the afferent input vector, but receives excitatory and inhibitory inputs from several neighbor neurons on the same map: x(k) = f γA </context>
</contexts>
<marker>Bednar, 2002</marker>
<rawString>James A. Bednar. 2002. Learning to See: Genetic and Environmental Influences on Visual Development. Ph.D. thesis, University of Texas at Austin. Tech Report AI-TR-02-294.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascal Belin</author>
<author>Robert J Zatorre</author>
<author>Pierre Ahad</author>
</authors>
<title>Human temporal-lobe response to vocal sounds.</title>
<date>2002</date>
<journal>Cognitive Brain Research,</journal>
<pages>13--17</pages>
<contexts>
<context position="14558" citStr="Belin et al., 2002" startWordPosition="2409" endWordPosition="2412">s performed by the cochlear-thalamic circuits (Escabi and Read, 2003). The auditory primary cortex is simulated by a double sheet of neurons, taking into account a double population of cells found in this area (Atzori et al., 2001), where the so-called LPC (Low-Probability Connections) is sensitive to the stationary component of the sound signal and the HPC (High-Probability Connections) population responds to transient inputs mainly. The next map in the auditory path of the model is STS, because the superior temporal sulcus is believed to be the main brain area responsive to 60 vocal sounds (Belin et al., 2002). 2.5 The Abstract Associative Map The upper AAM map in the model reflects how the system associates certain sound forms with the visual appearance of objects, and has the main purpose of showing what has been achieved in the cortical part of the model. It is trained using the outputs of the STS and the LOC maps of the model. After training, each neuron x in AAM is labeled, according to different test conditions X. The labeling function l(·) associates the neuron x with an entity e, which can be an object o of the COIL set O, when X E {A, B} or a category c of the set C for the test condition </context>
</contexts>
<marker>Belin, Zatorre, Ahad, 2002</marker>
<rawString>Pascal Belin, Robert J. Zatorre, and Pierre Ahad. 2002. Human temporal-lobe response to vocal sounds. Cognitive Brain Research, 13:17–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan W Black</author>
<author>Paul A Taylor</author>
</authors>
<title>The festival speech synthesis system: System documentation.</title>
<date>1997</date>
<tech>Technical Report HCRC/TR-83,</tech>
<institution>Human Communciation Research Centre, University of Edinburgh,</institution>
<location>Edinburgh, UK.</location>
<contexts>
<context position="13879" citStr="Black and Taylor, 1997" startWordPosition="2300" endWordPosition="2303">imary visual map V1 followed by V2, the two spectral components are processed by map VO, the color center, also called hV4 or V8 (Brewer et al., 2005). The two streams rejoin in the cortical map LOC, the area recently suggested as being the first involved in object recognition in humans (Malach et al., 1995; Kanwisher, 2003). Details of the visual path are in (Plebe and Domenella, 2006). 2.4 The auditory pathway The hardwired extracortical MGN component is just a placeholder for the spectrogram representation of the sound pressure waves, which is extracted with tools of the Festival software (Black and Taylor, 1997). It is justified by evidence of the spectro-temporal process performed by the cochlear-thalamic circuits (Escabi and Read, 2003). The auditory primary cortex is simulated by a double sheet of neurons, taking into account a double population of cells found in this area (Atzori et al., 2001), where the so-called LPC (Low-Probability Connections) is sensitive to the stationary component of the sound signal and the HPC (High-Probability Connections) population responds to transient inputs mainly. The next map in the auditory path of the model is STS, because the superior temporal sulcus is believ</context>
<context position="17879" citStr="Black and Taylor, 1997" startWordPosition="3041" endWordPosition="3044">lism of the conditions. It always could be assumed that the single object analysis corresponds to a foval focusing as consequence of a saccadic move, cued by any attentive mechanism. In the auditory path there are different stages as well. Initially, the maps are exposed to random patches in frequency-time domain, with shorter duration for HPC and longer for LPC. Subsequently, all the auditory maps are exposed to the 7200 most common English words (from http://www.bckelk.uklinux.net/menu.html) with lengths between 3 and 10 characters. All words are converted from text to waves using Festival (Black and Taylor, 1997), with cepstral order 64 and a unified time window of 2.3 seconds. Eventually, the last stage of training simulates events when an object is viewed and a word corresponding to its basic category is heard simultaneously. The 100 objects have been grouped manually into 38 categories. Some categories, such as cup or medicine count 5 exemplars in the object collection, while others, such as telephone, have only one exemplar. 3 Results 3.1 Developed functions in the cortical maps At the end of development each map in the model has evolved its own function. Different functions 61 have emerged from i</context>
</contexts>
<marker>Black, Taylor, 1997</marker>
<rawString>Alan W. Black and Paul A. Taylor. 1997. The festival speech synthesis system: System documentation. Technical Report HCRC/TR-83, Human Communciation Research Centre, University of Edinburgh, Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Bloom</author>
</authors>
<title>How children learn the meanings of words.</title>
<date>2000</date>
<publisher>MIT Press,</publisher>
<location>Cambridge (MA).</location>
<contexts>
<context position="2202" citStr="Bloom, 2000" startWordPosition="344" endWordPosition="345">sing amounts of evidence point to the growing capacity of infants at this stage to reliably map arbitrary sounds onto meanings and this mapping process is crucial to the acquisition of language. 57 The word-learning mechanisms used at this early phase of language learning could very well involve a mapping of words onto the most perceptually interesting objects in an infant’s environment (Pruden et al., 2006). There are those that claim that early word learning is not purely associative and that it is based on a sensitivity to social intent (Tomasello, 1999), through joint attention phenomena (Bloom, 2000). Pruden et al. have demonstrated that 10-month-old infants “are sensitive to social cues but cannot recruit them for word learning” and therefore, at this age infants presumably have to learn words on a simple associative basis. It is not by chance, it seems, that early vocabulary is made up of the objects infants most frequently see (Gershkoff-Stowe and Smith, 2004). Early word-learning and object recognition can thus be explained, according to a growing group of researchers, by associational learning strategies alone. There are those such as Carey and Spelke that postulate that there must n</context>
</contexts>
<marker>Bloom, 2000</marker>
<rawString>Paul Bloom. 2000. How children learn the meanings of words. MIT Press, Cambridge (MA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alyssa A Brewer</author>
<author>Junjie Liu</author>
<author>Alex R Wade</author>
<author>Brian A Wandell</author>
</authors>
<title>Visual field maps and stimulus selectivity in human ventral occipital cortex.</title>
<date>2005</date>
<journal>Nature Neuroscience,</journal>
<volume>8</volume>
<pages>1109</pages>
<contexts>
<context position="13406" citStr="Brewer et al., 2005" startWordPosition="2222" endWordPosition="2225">nter receptive fields. There are three pairs of sheets in the LGN maps: one connected to the intensity image plane, and the other two connected to the medium and long wavelength planes. In the color channels the internal excitatory portion of the receptive field is connected to the channel of one color, and the surrounding inhibitory part to the opposite color. The cortical process proceeds along two different streams: the achromatic component is connected to the primary visual map V1 followed by V2, the two spectral components are processed by map VO, the color center, also called hV4 or V8 (Brewer et al., 2005). The two streams rejoin in the cortical map LOC, the area recently suggested as being the first involved in object recognition in humans (Malach et al., 1995; Kanwisher, 2003). Details of the visual path are in (Plebe and Domenella, 2006). 2.4 The auditory pathway The hardwired extracortical MGN component is just a placeholder for the spectrogram representation of the sound pressure waves, which is extracted with tools of the Festival software (Black and Taylor, 1997). It is justified by evidence of the spectro-temporal process performed by the cochlear-thalamic circuits (Escabi and Read, 200</context>
</contexts>
<marker>Brewer, Liu, Wade, Wandell, 2005</marker>
<rawString>Alyssa A. Brewer, Junjie Liu, Alex R. Wade, and Brian A. Wandell. 2005. Visual field maps and stimulus selectivity in human ventral occipital cortex. Nature Neuroscience, 8:1102– 1109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan Carey</author>
<author>Elizabeth Spelke</author>
</authors>
<title>Science and core knowledge.</title>
<date>1996</date>
<journal>Journal of Philosophy of Science,</journal>
<pages>63--515</pages>
<contexts>
<context position="3035" citStr="Carey and Spelke, 1996" startWordPosition="477" endWordPosition="480"> associative basis. It is not by chance, it seems, that early vocabulary is made up of the objects infants most frequently see (Gershkoff-Stowe and Smith, 2004). Early word-learning and object recognition can thus be explained, according to a growing group of researchers, by associational learning strategies alone. There are those such as Carey and Spelke that postulate that there must necessarily be innate constraints that have the effect of making salient certain features as opposed to others, so as to narrow the hypothesis space with respect to the kinds of objects to be categorized first (Carey and Spelke, 1996). They reject the idea that object categorization in infants could emerge spontaneously from the ability to grasp patterns of statistical regularities. Jean Mandler presents evidence that the first similarity dimensions employed in categorization processes are indeed extremely general (Mandler, 2004); in other words, these dimensions single out wide domains of objects, with further refinements coming only later. Mandler claims, however, that the early salience of Proceedings of the Workshop on Cognitive Aspects of Computational Language Acquisition, pages 57–64, Prague, Czech Republic, June 20</context>
</contexts>
<marker>Carey, Spelke, 1996</marker>
<rawString>Susan Carey and Elizabeth Spelke. 1996. Science and core knowledge. Journal of Philosophy of Science, 63:515–533.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James L Dannemiller</author>
</authors>
<title>A test of color constancy in 9- and 20-weeks-old human infants following simulated illuminant changes.</title>
<date>1989</date>
<pages>25--171</pages>
<publisher>Developmental Psychology,</publisher>
<contexts>
<context position="19786" citStr="Dannemiller, 1989" startWordPosition="3352" endWordPosition="3353">le selectivity emerged in the model’s V2 map. In the secondary visual cortex the main recently discovered phenomena is the selectivity to angles (Ito and Komatsu, 2004), especially in the range between 60 and 150 degrees. The essential features of color constancy are reproduced in the model’s VO map, which is the ability of neurons to respond to specific hues, regardless of intensity. Color constancy is the tendency of the color of a surface to appear more constant that it is in reality. This property is helpful in object recognition, and develops sometime between two and four months of age. (Dannemiller, 1989). One of the main functions shown by the LOC layer in the model is visual invariance, the property of neurons to respond to peculiar object features despite changes in the object’s appearance due to different points of view. Invariance indeed is one of the main requirements for an object-recognition area, and is found in human LOC (Grill-Spector et al., 2001; Kanwisher, 2003). Tonotopic mapping is a known feature of the primary auditory cortex that represents the dimensions of frequency and time sequences in a sound pattern (Verkindt et al., 1995). In the model it is split into a sheet where n</context>
</contexts>
<marker>Dannemiller, 1989</marker>
<rawString>James L. Dannemiller. 1989. A test of color constancy in 9- and 20-weeks-old human infants following simulated illuminant changes. Developmental Psychology, 25:171–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Monty A Escabi</author>
<author>Heather L Read</author>
</authors>
<title>Representation of spectrotemporal sound information in the ascending auditory pathway.</title>
<date>2003</date>
<journal>Biological Cybernetics,</journal>
<pages>89--350</pages>
<contexts>
<context position="14008" citStr="Escabi and Read, 2003" startWordPosition="2318" endWordPosition="2321">Brewer et al., 2005). The two streams rejoin in the cortical map LOC, the area recently suggested as being the first involved in object recognition in humans (Malach et al., 1995; Kanwisher, 2003). Details of the visual path are in (Plebe and Domenella, 2006). 2.4 The auditory pathway The hardwired extracortical MGN component is just a placeholder for the spectrogram representation of the sound pressure waves, which is extracted with tools of the Festival software (Black and Taylor, 1997). It is justified by evidence of the spectro-temporal process performed by the cochlear-thalamic circuits (Escabi and Read, 2003). The auditory primary cortex is simulated by a double sheet of neurons, taking into account a double population of cells found in this area (Atzori et al., 2001), where the so-called LPC (Low-Probability Connections) is sensitive to the stationary component of the sound signal and the HPC (High-Probability Connections) population responds to transient inputs mainly. The next map in the auditory path of the model is STS, because the superior temporal sulcus is believed to be the main brain area responsive to 60 vocal sounds (Belin et al., 2002). 2.5 The Abstract Associative Map The upper AAM m</context>
</contexts>
<marker>Escabi, Read, 2003</marker>
<rawString>Monty A. Escabi and Heather L. Read. 2003. Representation of spectrotemporal sound information in the ascending auditory pathway. Biological Cybernetics, 89:350–362.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lisa Gershkoff-Stowe</author>
<author>Linda B Smith</author>
</authors>
<title>Shape and the first hundred nouns. Child Development,</title>
<date>2004</date>
<pages>75--1098</pages>
<contexts>
<context position="2572" citStr="Gershkoff-Stowe and Smith, 2004" startWordPosition="402" endWordPosition="405">ting objects in an infant’s environment (Pruden et al., 2006). There are those that claim that early word learning is not purely associative and that it is based on a sensitivity to social intent (Tomasello, 1999), through joint attention phenomena (Bloom, 2000). Pruden et al. have demonstrated that 10-month-old infants “are sensitive to social cues but cannot recruit them for word learning” and therefore, at this age infants presumably have to learn words on a simple associative basis. It is not by chance, it seems, that early vocabulary is made up of the objects infants most frequently see (Gershkoff-Stowe and Smith, 2004). Early word-learning and object recognition can thus be explained, according to a growing group of researchers, by associational learning strategies alone. There are those such as Carey and Spelke that postulate that there must necessarily be innate constraints that have the effect of making salient certain features as opposed to others, so as to narrow the hypothesis space with respect to the kinds of objects to be categorized first (Carey and Spelke, 1996). They reject the idea that object categorization in infants could emerge spontaneously from the ability to grasp patterns of statistical</context>
<context position="24062" citStr="Gershkoff-Stowe and Smith, 2004" startWordPosition="4095" endWordPosition="4098">uracy for the category, in this case, is better accounted for as an emergent example of synonymy, where coupling with the same word is accepted, despite the difference in the output of the visual process. In table 3 accuracy results for individual objects are listed, grouped by object shape. In this case category accuracy cannot be computed, because shapes cross category boundaries. It can be seen that the improvement 0 is proportional to the salience in shape: it is meaningless for common, obvious shapes, and higher when object shape is uncommon. This result is in agreement with findings in (Gershkoff-Stowe and Smith, 2004). 4 Conclusions The model here described attempts to simulate lexical acquisition from auditory and visual stimuli from a brain processes point of view. It models these processes in a biologically plausible way in that it does not begin with a predetermined design of mature functions, but instead allows final functions of the components to emerge as a result of the plastic development of neural circuits. It grounds this choice and its design principles in what is known of the cerebral cortex. In this model, the overall important result achieved so far, is the emergence of naming and recognitio</context>
</contexts>
<marker>Gershkoff-Stowe, Smith, 2004</marker>
<rawString>Lisa Gershkoff-Stowe and Linda B. Smith. 2004. Shape and the first hundred nouns. Child Development, 75:1098–1114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jane Gillette</author>
<author>Henry Gleitman</author>
<author>Lila Gleitman</author>
<author>Anne Lederer</author>
</authors>
<title>Human simulations of vocabulary learning.</title>
<date>1999</date>
<journal>Cognition,</journal>
<pages>73--135</pages>
<contexts>
<context position="5835" citStr="Gillette et al., 1999" startWordPosition="904" endWordPosition="907">nological or semantic features”, rather than by “natural features such as voicing or shape”. The positions mentioned above conflict with others, such as that of Lila Gleitman and her colleagues, according to which some innate constraints are needed in order to learn words. It should be noted, however, that even in Gleitman’s proposal the need for innate constraints on syntax-semantic mapping mainly concerns verbs; moreover, the possibility to apprehend a core set of concrete terms without the contribution of any syntactic constraint is considered as a precondition for verb acquisition itself (Gillette et al., 1999). This paper describes a neural network model which attempts to simulate the process by which infants learn how to recognize objects and words in the first year of life through exposure to visual stimuli and vocal sounds. The approach here pursued is in line with the view that a coherent covariation of features is the major engine leading to object name acquisition, the attempt made however, is to rely on biological ways of capturing coherent covariation. The pre-established design of the mature functions of the organism is avoided, and the emergence of the final function of each component of </context>
</contexts>
<marker>Gillette, Gleitman, Gleitman, Lederer, 1999</marker>
<rawString>Jane Gillette, Henry Gleitman, Lila Gleitman, and Anne Lederer. 1999. Human simulations of vocabulary learning. Cognition, 73:135–176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kalanit Grill-Spector</author>
<author>Zoe Kourtzi</author>
<author>Nancy Kanwisher</author>
</authors>
<title>The lateral occipital complex and its role in object recognition.</title>
<date>2001</date>
<journal>Vision Research,</journal>
<pages>41--1409</pages>
<contexts>
<context position="20146" citStr="Grill-Spector et al., 2001" startWordPosition="3412" endWordPosition="3415">ific hues, regardless of intensity. Color constancy is the tendency of the color of a surface to appear more constant that it is in reality. This property is helpful in object recognition, and develops sometime between two and four months of age. (Dannemiller, 1989). One of the main functions shown by the LOC layer in the model is visual invariance, the property of neurons to respond to peculiar object features despite changes in the object’s appearance due to different points of view. Invariance indeed is one of the main requirements for an object-recognition area, and is found in human LOC (Grill-Spector et al., 2001; Kanwisher, 2003). Tonotopic mapping is a known feature of the primary auditory cortex that represents the dimensions of frequency and time sequences in a sound pattern (Verkindt et al., 1995). In the model it is split into a sheet where neurons have receptive fields that are more elongated along the time dimension (LPC) and another where the resulting receptive fields are more elongated along the frequency dimension (HPC). The spectrotemporal mapping obtained in STS is a population coding of features, in frequency and time domains, representative of the sound patterns heard during the develo</context>
</contexts>
<marker>Grill-Spector, Kourtzi, Kanwisher, 2001</marker>
<rawString>Kalanit Grill-Spector, Zoe Kourtzi, and Nancy Kanwisher. 2001. The lateral occipital complex and its role in object recognition. Vision Research, 41:1409–1422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minami Ito</author>
<author>Hidehiko Komatsu</author>
</authors>
<title>Representation of angles embedded within contour stimuli in area V2 of macaque monkeys.</title>
<date>2004</date>
<journal>Journal of Neuroscience,</journal>
<pages>24--3313</pages>
<contexts>
<context position="19336" citStr="Ito and Komatsu, 2004" startWordPosition="3272" endWordPosition="3276"> the experiment are the following. In the visual path orientation selectivity emerged in the model’s V1 map as demonstrated in (Sirosh and Miikkulainen, 1997) and (Plebe and Domenella, 2006). Orientation selectivity is the main organization in primary visual cortex, where the responsiveness of neurons to oriented segments is arranged over repeated patterns of gradually changing orientations, broken by few discontinuities (Vanduffel et al., 2002). Angle selectivity emerged in the model’s V2 map. In the secondary visual cortex the main recently discovered phenomena is the selectivity to angles (Ito and Komatsu, 2004), especially in the range between 60 and 150 degrees. The essential features of color constancy are reproduced in the model’s VO map, which is the ability of neurons to respond to specific hues, regardless of intensity. Color constancy is the tendency of the color of a surface to appear more constant that it is in reality. This property is helpful in object recognition, and develops sometime between two and four months of age. (Dannemiller, 1989). One of the main functions shown by the LOC layer in the model is visual invariance, the property of neurons to respond to peculiar object features d</context>
</contexts>
<marker>Ito, Komatsu, 2004</marker>
<rawString>Minami Ito and Hidehiko Komatsu. 2004. Representation of angles embedded within contour stimuli in area V2 of macaque monkeys. Journal of Neuroscience, 24:3313–3324.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Kanwisher</author>
</authors>
<title>The ventral visual object pathway in humans: Evidence from fMRI.</title>
<date>2003</date>
<booktitle>In Leo Chalupa and</booktitle>
<editor>John Werner, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge (MA).</location>
<contexts>
<context position="13582" citStr="Kanwisher, 2003" startWordPosition="2254" endWordPosition="2255">anes. In the color channels the internal excitatory portion of the receptive field is connected to the channel of one color, and the surrounding inhibitory part to the opposite color. The cortical process proceeds along two different streams: the achromatic component is connected to the primary visual map V1 followed by V2, the two spectral components are processed by map VO, the color center, also called hV4 or V8 (Brewer et al., 2005). The two streams rejoin in the cortical map LOC, the area recently suggested as being the first involved in object recognition in humans (Malach et al., 1995; Kanwisher, 2003). Details of the visual path are in (Plebe and Domenella, 2006). 2.4 The auditory pathway The hardwired extracortical MGN component is just a placeholder for the spectrogram representation of the sound pressure waves, which is extracted with tools of the Festival software (Black and Taylor, 1997). It is justified by evidence of the spectro-temporal process performed by the cochlear-thalamic circuits (Escabi and Read, 2003). The auditory primary cortex is simulated by a double sheet of neurons, taking into account a double population of cells found in this area (Atzori et al., 2001), where the </context>
<context position="20164" citStr="Kanwisher, 2003" startWordPosition="3416" endWordPosition="3417">ensity. Color constancy is the tendency of the color of a surface to appear more constant that it is in reality. This property is helpful in object recognition, and develops sometime between two and four months of age. (Dannemiller, 1989). One of the main functions shown by the LOC layer in the model is visual invariance, the property of neurons to respond to peculiar object features despite changes in the object’s appearance due to different points of view. Invariance indeed is one of the main requirements for an object-recognition area, and is found in human LOC (Grill-Spector et al., 2001; Kanwisher, 2003). Tonotopic mapping is a known feature of the primary auditory cortex that represents the dimensions of frequency and time sequences in a sound pattern (Verkindt et al., 1995). In the model it is split into a sheet where neurons have receptive fields that are more elongated along the time dimension (LPC) and another where the resulting receptive fields are more elongated along the frequency dimension (HPC). The spectrotemporal mapping obtained in STS is a population coding of features, in frequency and time domains, representative of the sound patterns heard during the development phase. It th</context>
</contexts>
<marker>Kanwisher, 2003</marker>
<rawString>Nancy Kanwisher. 2003. The ventral visual object pathway in humans: Evidence from fMRI. In Leo Chalupa and John Werner, editors, The Visual Neurosciences. MIT Press, Cambridge (MA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence C Katz</author>
<author>Edward M Callaway</author>
</authors>
<title>Development of local circuits in mammalian visual cortex. Annual Review Neuroscience,</title>
<date>1992</date>
<pages>15--31</pages>
<contexts>
<context position="6875" citStr="Katz and Callaway, 1992" startWordPosition="1073" endWordPosition="1076">al ways of capturing coherent covariation. The pre-established design of the mature functions of the organism is avoided, and the emergence of the final function of each component of the system is left to the plastic development of the neural circuits. In the cortex, there is very little differentiation in the computational capability that neural circuits will potentially perform in the mature stage. The interaction between environmental stimuli and some of the basic mechanisms of development is what drives differentiation in computational functions. This position has large empirical support (Katz and Callaway, 1992; L¨owel and Singer, 2002), and is compatible with current knowledge on neural genetics (Quartz, 2003). The model here described, can be considered an implementation of the processes that emerge around the 10 month of age period. It can also be used to consider what happens in a hypothesized subsequent period, in which the phenomenon of joint attention provides the social cueing that leads to the increased ability to focus on certain objects as opposed to others. 2 The proposed model First the mathematics common to the modules will be described, then the model will be outlined. Details of the </context>
</contexts>
<marker>Katz, Callaway, 1992</marker>
<rawString>Lawrence C. Katz and Edward M. Callaway. 1992. Development of local circuits in mammalian visual cortex. Annual Review Neuroscience, 15:31–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Teuvo Kohonen</author>
</authors>
<title>Self-Organizing Maps.</title>
<date>1995</date>
<publisher>SpringerVerlag,</publisher>
<location>Berlin.</location>
<contexts>
<context position="12262" citStr="Kohonen, 1995" startWordPosition="2034" endWordPosition="2035"> neurons in the thalamic nuclei MGN and LGN. There are two main paths, one for the visual process and another for the auditory channel. Both paths include thalamic modules, which are not the object of this study and are therefore hardwired according to what is known about their functions. The two higher cortical maps, LOC and STS, will carry the best representation coded by models on object visual features and word features. These two representations are associated in an abstract type map, called AAM (Abstract Associative Map). This component is implemented using the SOM (Self Organized Map) (Kohonen, 1995) architecture, known to provide non linear bidimensional ordering of input vectors by unsupervised mechanisms. It is the only component of the model that cannot be conceptually referred to as a precise cortical area. It is an abstraction of processes that actually involve several brain areas in a complex way, and as such departs computationally from realistic cortical architecture. 2.3 The visual pathway As shown in Fig. 1, the architecture here used includes hardwired extracortical maps with simple oncenter and off-center receptive fields. There are three pairs of sheets in the LGN maps: one </context>
</contexts>
<marker>Kohonen, 1995</marker>
<rawString>Teuvo Kohonen. 1995. Self-Organizing Maps. SpringerVerlag, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siegrid L¨owel</author>
<author>Wolf Singer</author>
</authors>
<title>Experience-dependent plasticity of intracortical connections.</title>
<date>2002</date>
<editor>In Manfred Fahle and Tomaso Poggio, editors, Perceptual Learning.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge (MA).</location>
<marker>L¨owel, Singer, 2002</marker>
<rawString>Siegrid L¨owel and Wolf Singer. 2002. Experience-dependent plasticity of intracortical connections. In Manfred Fahle and Tomaso Poggio, editors, Perceptual Learning. MIT Press, Cambridge (MA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Malach</author>
<author>J B Reppas</author>
<author>R R Benson</author>
<author>K K Kwong</author>
<author>H Jiang</author>
<author>W A Kennedy</author>
<author>P J Ledden</author>
<author>T J Brady</author>
<author>B R Rosen</author>
<author>R B H Tootell</author>
</authors>
<title>Object-related activity revealed by functional magnetic resonance imaging in human occipital cortex.</title>
<date>1995</date>
<booktitle>Proceedings of the Natural Academy of Science USA,</booktitle>
<pages>92--8135</pages>
<contexts>
<context position="13564" citStr="Malach et al., 1995" startWordPosition="2250" endWordPosition="2253">nd long wavelength planes. In the color channels the internal excitatory portion of the receptive field is connected to the channel of one color, and the surrounding inhibitory part to the opposite color. The cortical process proceeds along two different streams: the achromatic component is connected to the primary visual map V1 followed by V2, the two spectral components are processed by map VO, the color center, also called hV4 or V8 (Brewer et al., 2005). The two streams rejoin in the cortical map LOC, the area recently suggested as being the first involved in object recognition in humans (Malach et al., 1995; Kanwisher, 2003). Details of the visual path are in (Plebe and Domenella, 2006). 2.4 The auditory pathway The hardwired extracortical MGN component is just a placeholder for the spectrogram representation of the sound pressure waves, which is extracted with tools of the Festival software (Black and Taylor, 1997). It is justified by evidence of the spectro-temporal process performed by the cochlear-thalamic circuits (Escabi and Read, 2003). The auditory primary cortex is simulated by a double sheet of neurons, taking into account a double population of cells found in this area (Atzori et al.,</context>
</contexts>
<marker>Malach, Reppas, Benson, Kwong, Jiang, Kennedy, Ledden, Brady, Rosen, Tootell, 1995</marker>
<rawString>R. Malach, J. B. Reppas, R. R. Benson, K. K. Kwong, H. Jiang, W. A. Kennedy, P. J. Ledden, T. J. Brady, B. R. Rosen, and R. B.H. Tootell. 1995. Object-related activity revealed by functional magnetic resonance imaging in human occipital cortex. Proceedings of the Natural Academy of Science USA, 92:8135–8139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Matter Mandler</author>
</authors>
<title>The Foundations of Mind.</title>
<date>2004</date>
<publisher>Oxford University Press,</publisher>
<location>Oxford (UK).</location>
<contexts>
<context position="3336" citStr="Mandler, 2004" startWordPosition="521" endWordPosition="522">alone. There are those such as Carey and Spelke that postulate that there must necessarily be innate constraints that have the effect of making salient certain features as opposed to others, so as to narrow the hypothesis space with respect to the kinds of objects to be categorized first (Carey and Spelke, 1996). They reject the idea that object categorization in infants could emerge spontaneously from the ability to grasp patterns of statistical regularities. Jean Mandler presents evidence that the first similarity dimensions employed in categorization processes are indeed extremely general (Mandler, 2004); in other words, these dimensions single out wide domains of objects, with further refinements coming only later. Mandler claims, however, that the early salience of Proceedings of the Workshop on Cognitive Aspects of Computational Language Acquisition, pages 57–64, Prague, Czech Republic, June 2007 c�2007 Association for Computational Linguistics these extremely general features could have a different explanation other than nativism: for example, that salience could emerge from physiological constraints. Using a connectionist model with backpropagation, Rogers and McClelland have shown that </context>
</contexts>
<marker>Mandler, 2004</marker>
<rawString>Jean Matter Mandler. 2004. The Foundations of Mind. Oxford University Press, Oxford (UK).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shree Nayar</author>
<author>Hiroshi Murase</author>
</authors>
<title>Visual learning and recognition of 3-d object by appearence.</title>
<date>1995</date>
<journal>International Journal of Computer Vision,</journal>
<pages>14--5</pages>
<contexts>
<context position="17032" citStr="Nayar and Murase, 1995" startWordPosition="2901" endWordPosition="2905">en classified as the prevailing one in each neuron of the AAM SOM. 2.6 Exposure to stimuli The visual path in the model develops in two stages. Initially the inputs to the network are synthetic random blobs, simulating pre-natal waves of spontaneous activity, known to be essential in the early development of the visual system (Sengpiel and Kind, 2002). In the second stage, corresponding to the period after eye opening, natural images are used. In order to address one of the main problems in recognition, the identifying of an object under different views, the COIL-100 collection has been used (Nayar and Murase, 1995) where 72 different views are available for each of the 100 objects. Using natural images where there is only one main object is cleary a simplification in the vision process of this model, but it does not compromise the realism of the conditions. It always could be assumed that the single object analysis corresponds to a foval focusing as consequence of a saccadic move, cued by any attentive mechanism. In the auditory path there are different stages as well. Initially, the maps are exposed to random patches in frequency-time domain, with shorter duration for HPC and longer for LPC. Subsequent</context>
</contexts>
<marker>Nayar, Murase, 1995</marker>
<rawString>Shree Nayar and Hiroshi Murase. 1995. Visual learning and recognition of 3-d object by appearence. International Journal of Computer Vision, 14:5–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessio Plebe</author>
<author>Rosaria Grazia Domenella</author>
</authors>
<title>Early development of visual recognition.</title>
<date>2006</date>
<journal>BioSystems,</journal>
<pages>86--63</pages>
<contexts>
<context position="13645" citStr="Plebe and Domenella, 2006" startWordPosition="2263" endWordPosition="2266">ortion of the receptive field is connected to the channel of one color, and the surrounding inhibitory part to the opposite color. The cortical process proceeds along two different streams: the achromatic component is connected to the primary visual map V1 followed by V2, the two spectral components are processed by map VO, the color center, also called hV4 or V8 (Brewer et al., 2005). The two streams rejoin in the cortical map LOC, the area recently suggested as being the first involved in object recognition in humans (Malach et al., 1995; Kanwisher, 2003). Details of the visual path are in (Plebe and Domenella, 2006). 2.4 The auditory pathway The hardwired extracortical MGN component is just a placeholder for the spectrogram representation of the sound pressure waves, which is extracted with tools of the Festival software (Black and Taylor, 1997). It is justified by evidence of the spectro-temporal process performed by the cochlear-thalamic circuits (Escabi and Read, 2003). The auditory primary cortex is simulated by a double sheet of neurons, taking into account a double population of cells found in this area (Atzori et al., 2001), where the so-called LPC (Low-Probability Connections) is sensitive to the</context>
<context position="18904" citStr="Plebe and Domenella, 2006" startWordPosition="3205" endWordPosition="3208">, have only one exemplar. 3 Results 3.1 Developed functions in the cortical maps At the end of development each map in the model has evolved its own function. Different functions 61 have emerged from identical computational architectures. The differences are due to the different positions of a maps in the modules hierarchy, to different exposure to environmental stimuli, and different structural parameters. The functions obtained in the experiment are the following. In the visual path orientation selectivity emerged in the model’s V1 map as demonstrated in (Sirosh and Miikkulainen, 1997) and (Plebe and Domenella, 2006). Orientation selectivity is the main organization in primary visual cortex, where the responsiveness of neurons to oriented segments is arranged over repeated patterns of gradually changing orientations, broken by few discontinuities (Vanduffel et al., 2002). Angle selectivity emerged in the model’s V2 map. In the secondary visual cortex the main recently discovered phenomena is the selectivity to angles (Ito and Komatsu, 2004), especially in the range between 60 and 150 degrees. The essential features of color constancy are reproduced in the model’s VO map, which is the ability of neurons to</context>
</contexts>
<marker>Plebe, Domenella, 2006</marker>
<rawString>Alessio Plebe and Rosaria Grazia Domenella. 2006. Early development of visual recognition. BioSystems, 86:63–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shannon M Pruden</author>
<author>Kathy Hirsh-Pasek</author>
<author>Roberta Michnick Golinkoff</author>
<author>Elizabeth A Hennon</author>
</authors>
<title>The birth of words: Ten-month-olds learn words through perceptual salience. Child Development,</title>
<date>2006</date>
<pages>77--266</pages>
<contexts>
<context position="2001" citStr="Pruden et al., 2006" startWordPosition="310" endWordPosition="313">d than was previously thought. By the time children are 8 to 10 months old their object categories are sufficiently stable and flexible to be used as the foundation for labeling and referencing actions. Increasing amounts of evidence point to the growing capacity of infants at this stage to reliably map arbitrary sounds onto meanings and this mapping process is crucial to the acquisition of language. 57 The word-learning mechanisms used at this early phase of language learning could very well involve a mapping of words onto the most perceptually interesting objects in an infant’s environment (Pruden et al., 2006). There are those that claim that early word learning is not purely associative and that it is based on a sensitivity to social intent (Tomasello, 1999), through joint attention phenomena (Bloom, 2000). Pruden et al. have demonstrated that 10-month-old infants “are sensitive to social cues but cannot recruit them for word learning” and therefore, at this age infants presumably have to learn words on a simple associative basis. It is not by chance, it seems, that early vocabulary is made up of the objects infants most frequently see (Gershkoff-Stowe and Smith, 2004). Early word-learning and obj</context>
</contexts>
<marker>Pruden, Hirsh-Pasek, Golinkoff, Hennon, 2006</marker>
<rawString>Shannon M. Pruden, Kathy Hirsh-Pasek, Roberta Michnick Golinkoff, and Elizabeth A. Hennon. 2006. The birth of words: Ten-month-olds learn words through perceptual salience. Child Development, 77:266–280.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven R Quartz</author>
</authors>
<date>2003</date>
<booktitle>Innateness and the brain. Biology and Philosophy,</booktitle>
<pages>18--13</pages>
<contexts>
<context position="6977" citStr="Quartz, 2003" startWordPosition="1090" endWordPosition="1091"> avoided, and the emergence of the final function of each component of the system is left to the plastic development of the neural circuits. In the cortex, there is very little differentiation in the computational capability that neural circuits will potentially perform in the mature stage. The interaction between environmental stimuli and some of the basic mechanisms of development is what drives differentiation in computational functions. This position has large empirical support (Katz and Callaway, 1992; L¨owel and Singer, 2002), and is compatible with current knowledge on neural genetics (Quartz, 2003). The model here described, can be considered an implementation of the processes that emerge around the 10 month of age period. It can also be used to consider what happens in a hypothesized subsequent period, in which the phenomenon of joint attention provides the social cueing that leads to the increased ability to focus on certain objects as opposed to others. 2 The proposed model First the mathematics common to the modules will be described, then the model will be outlined. Details of the visual and the auditory paths will be provided along with a description of the learning procedures. 2.</context>
</contexts>
<marker>Quartz, 2003</marker>
<rawString>Steven R. Quartz. 2003. Innateness and the brain. Biology and Philosophy, 18:13–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Regier</author>
</authors>
<title>The emergence of words: Attentional learning in form and meaning.</title>
<date>2005</date>
<journal>Cognitive Science,</journal>
<volume>29</volume>
<pages>865</pages>
<contexts>
<context position="4947" citStr="Regier, 2005" startWordPosition="765" endWordPosition="766">er on. However, interesting as it is from a computational point of view, this model is rather unrealistic as a simulation of biological categorization processes. Linda Smith, suggests that words can contribute to category formation, in that they behave as features which co-vary with other language-independent features of objects (Smith, 1999). In general, her idea is that the relevant features simply emerge from regularities in the input. Terry Regier, building upon the proposal offered by Smith, has shown that word learning might behave in analogy with what we have said about categorization (Regier, 2005): certain features of both objects and words (i.e., phonological forms) can be made more salient than others, simply as a consequence of regularities in objects, words, and their co-variation. Regier’s training sets however, are constituted by wholly “artificial phonological or semantic features”, rather than by “natural features such as voicing or shape”. The positions mentioned above conflict with others, such as that of Lila Gleitman and her colleagues, according to which some innate constraints are needed in order to learn words. It should be noted, however, that even in Gleitman’s proposa</context>
</contexts>
<marker>Regier, 2005</marker>
<rawString>Terry Regier. 2005. The emergence of words: Attentional learning in form and meaning. Cognitive Science, 29:819– 865.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy T Rogers</author>
<author>James L McClelland</author>
</authors>
<title>Semantic Cognition - A Parallel Distributed Processing Approach.</title>
<date>2006</date>
<publisher>MIT Press,</publisher>
<location>Cambridge (MA).</location>
<contexts>
<context position="4198" citStr="Rogers and McClelland, 2006" startWordPosition="644" endWordPosition="647">anguage Acquisition, pages 57–64, Prague, Czech Republic, June 2007 c�2007 Association for Computational Linguistics these extremely general features could have a different explanation other than nativism: for example, that salience could emerge from physiological constraints. Using a connectionist model with backpropagation, Rogers and McClelland have shown that quite general dimensions of similarity can emerge without appealing to either physiological or cognitive constraints, simply as the result of a coherent covariation of features, that is, as an effect of mere statistical regularities (Rogers and McClelland, 2006). What Rogers and McClelland say about the most general features obviously apply also to more specific features which become salient later on. However, interesting as it is from a computational point of view, this model is rather unrealistic as a simulation of biological categorization processes. Linda Smith, suggests that words can contribute to category formation, in that they behave as features which co-vary with other language-independent features of objects (Smith, 1999). In general, her idea is that the relevant features simply emerge from regularities in the input. Terry Regier, buildin</context>
</contexts>
<marker>Rogers, McClelland, 2006</marker>
<rawString>Timothy T. Rogers and James L. McClelland. 2006. Semantic Cognition - A Parallel Distributed Processing Approach. MIT Press, Cambridge (MA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Sengpiel</author>
<author>Peter C Kind</author>
</authors>
<title>The role of activity in development of the visual system. Current Biology,</title>
<date>2002</date>
<pages>12--818</pages>
<contexts>
<context position="16762" citStr="Sengpiel and Kind, 2002" startWordPosition="2855" endWordPosition="2858"> x = w(vo, E)} (7) C : {vo : c = b(o) n x = w(E, se)} (8) D : {se : x = w(E, se)} (9) From the labeling functions the possibility of estimating the accuracy of recognition immediately follows, simply by weighing the number of cases where the category or the object has been classified as the prevailing one in each neuron of the AAM SOM. 2.6 Exposure to stimuli The visual path in the model develops in two stages. Initially the inputs to the network are synthetic random blobs, simulating pre-natal waves of spontaneous activity, known to be essential in the early development of the visual system (Sengpiel and Kind, 2002). In the second stage, corresponding to the period after eye opening, natural images are used. In order to address one of the main problems in recognition, the identifying of an object under different views, the COIL-100 collection has been used (Nayar and Murase, 1995) where 72 different views are available for each of the 100 objects. Using natural images where there is only one main object is cleary a simplification in the vision process of this model, but it does not compromise the realism of the conditions. It always could be assumed that the single object analysis corresponds to a foval </context>
</contexts>
<marker>Sengpiel, Kind, 2002</marker>
<rawString>Frank Sengpiel and Peter C. Kind. 2002. The role of activity in development of the visual system. Current Biology, 12:818– 826.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Sirosh</author>
<author>Risto Miikkulainen</author>
</authors>
<title>Topographic receptive fields and patterned lateral interaction in a selforganizing model of the primary visual cortex.</title>
<date>1997</date>
<journal>Neural Computation,</journal>
<pages>9--577</pages>
<contexts>
<context position="7835" citStr="Sirosh and Miikkulainen, 1997" startWordPosition="1228" endWordPosition="1232">enon of joint attention provides the social cueing that leads to the increased ability to focus on certain objects as opposed to others. 2 The proposed model First the mathematics common to the modules will be described, then the model will be outlined. Details of the visual and the auditory paths will be provided along with a description of the learning procedures. 2.1 The mathematical abstraction of the cortical maps All the modules composing this model are implemented as artificial cortical maps, adopting the LISSOM (Laterally Interconnected Synergetically SelfOrganizing Map) architecture (Sirosh and Miikkulainen, 1997; Bednar, 2002). This architecture has been chosen because of its reproduction of neural plasticity, through the combination of Hebb’s principle and neural homeostasis, and because it is a good compromise between a number of realistic features and the simplicity necessary for building complex 58 STS LOC MGN LPC HPC A1 Figure 1: Overall scheme of the model. AAM V2 V1 VO LGN models. The LISSOM is a two dimensional arrangement of neurons, where each cell is not only connected with the afferent input vector, but receives excitatory and inhibitory inputs from several neighbor neurons on the same ma</context>
<context position="18872" citStr="Sirosh and Miikkulainen, 1997" startWordPosition="3200" endWordPosition="3203">ion, while others, such as telephone, have only one exemplar. 3 Results 3.1 Developed functions in the cortical maps At the end of development each map in the model has evolved its own function. Different functions 61 have emerged from identical computational architectures. The differences are due to the different positions of a maps in the modules hierarchy, to different exposure to environmental stimuli, and different structural parameters. The functions obtained in the experiment are the following. In the visual path orientation selectivity emerged in the model’s V1 map as demonstrated in (Sirosh and Miikkulainen, 1997) and (Plebe and Domenella, 2006). Orientation selectivity is the main organization in primary visual cortex, where the responsiveness of neurons to oriented segments is arranged over repeated patterns of gradually changing orientations, broken by few discontinuities (Vanduffel et al., 2002). Angle selectivity emerged in the model’s V2 map. In the secondary visual cortex the main recently discovered phenomena is the selectivity to angles (Ito and Komatsu, 2004), especially in the range between 60 and 150 degrees. The essential features of color constancy are reproduced in the model’s VO map, wh</context>
</contexts>
<marker>Sirosh, Miikkulainen, 1997</marker>
<rawString>Joseph Sirosh and Risto Miikkulainen. 1997. Topographic receptive fields and patterned lateral interaction in a selforganizing model of the primary visual cortex. Neural Computation, 9:577–594.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Linda B Smith</author>
</authors>
<title>Children’s noun learning: How general learning processes make specialized learning mechanisms.</title>
<date>1999</date>
<booktitle>The Emergence of Language. Lawrence Erlbaum Associates, Mahwah (NJ). Second Edition.</booktitle>
<editor>In Brian MacWhinney, editor,</editor>
<contexts>
<context position="4678" citStr="Smith, 1999" startWordPosition="721" endWordPosition="722">e result of a coherent covariation of features, that is, as an effect of mere statistical regularities (Rogers and McClelland, 2006). What Rogers and McClelland say about the most general features obviously apply also to more specific features which become salient later on. However, interesting as it is from a computational point of view, this model is rather unrealistic as a simulation of biological categorization processes. Linda Smith, suggests that words can contribute to category formation, in that they behave as features which co-vary with other language-independent features of objects (Smith, 1999). In general, her idea is that the relevant features simply emerge from regularities in the input. Terry Regier, building upon the proposal offered by Smith, has shown that word learning might behave in analogy with what we have said about categorization (Regier, 2005): certain features of both objects and words (i.e., phonological forms) can be made more salient than others, simply as a consequence of regularities in objects, words, and their co-variation. Regier’s training sets however, are constituted by wholly “artificial phonological or semantic features”, rather than by “natural features</context>
<context position="23345" citStr="Smith, 1999" startWordPosition="3978" endWordPosition="3979">09 round 1.0 0.904 0.096 composed 0.702 0.565 0.137 q-cylindrical 0.884 0.861 0.023 q-h-parallelepiped 0.734 0.513 0.221 cylindrical 0.926 0.907 0.019 cup-shaped 0.975 0.897 0.078 q-v-parallelepiped 0.869 0.754 0.115 body 1.0 0.869 0.131 conic 1.0 1.0 0.0 parallelepiped 0.722 0.510 0.212 q-parallelepiped 1.0 0.634 0.366 Table 3: Accuracy in recognition measured by labeling in the AAM, for objects grouped by their visual shape, A is the improvement gained with naming. where the accuracy for each individual object doubles when using names. It seems to be analogous to the situation described in (Smith, 1999), where the word contributes to the emergence of patterns of regularity. The 100% accuracy for the category, in this case, is better accounted for as an emergent example of synonymy, where coupling with the same word is accepted, despite the difference in the output of the visual process. In table 3 accuracy results for individual objects are listed, grouped by object shape. In this case category accuracy cannot be computed, because shapes cross category boundaries. It can be seen that the improvement 0 is proportional to the salience in shape: it is meaningless for common, obvious shapes, and</context>
</contexts>
<marker>Smith, 1999</marker>
<rawString>Linda B. Smith. 1999. Children’s noun learning: How general learning processes make specialized learning mechanisms. In Brian MacWhinney, editor, The Emergence of Language. Lawrence Erlbaum Associates, Mahwah (NJ). Second Edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Tomasello</author>
</authors>
<title>The cultural origins of human cognition.</title>
<date>1999</date>
<publisher>Harvard University Press,</publisher>
<location>Cambridge (MA).</location>
<contexts>
<context position="2153" citStr="Tomasello, 1999" startWordPosition="338" endWordPosition="339">undation for labeling and referencing actions. Increasing amounts of evidence point to the growing capacity of infants at this stage to reliably map arbitrary sounds onto meanings and this mapping process is crucial to the acquisition of language. 57 The word-learning mechanisms used at this early phase of language learning could very well involve a mapping of words onto the most perceptually interesting objects in an infant’s environment (Pruden et al., 2006). There are those that claim that early word learning is not purely associative and that it is based on a sensitivity to social intent (Tomasello, 1999), through joint attention phenomena (Bloom, 2000). Pruden et al. have demonstrated that 10-month-old infants “are sensitive to social cues but cannot recruit them for word learning” and therefore, at this age infants presumably have to learn words on a simple associative basis. It is not by chance, it seems, that early vocabulary is made up of the objects infants most frequently see (Gershkoff-Stowe and Smith, 2004). Early word-learning and object recognition can thus be explained, according to a growing group of researchers, by associational learning strategies alone. There are those such as </context>
</contexts>
<marker>Tomasello, 1999</marker>
<rawString>Michael Tomasello. 1999. The cultural origins of human cognition. Harvard University Press, Cambridge (MA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wim Vanduffel</author>
<author>Roger B H Tootell</author>
<author>Anick A Schoups</author>
<author>Guy A Orban</author>
</authors>
<title>The organization of orientation selectivity throughout the macaque visual cortex. Cerebral Cortex,</title>
<date>2002</date>
<pages>12--647</pages>
<contexts>
<context position="19163" citStr="Vanduffel et al., 2002" startWordPosition="3243" endWordPosition="3246"> to the different positions of a maps in the modules hierarchy, to different exposure to environmental stimuli, and different structural parameters. The functions obtained in the experiment are the following. In the visual path orientation selectivity emerged in the model’s V1 map as demonstrated in (Sirosh and Miikkulainen, 1997) and (Plebe and Domenella, 2006). Orientation selectivity is the main organization in primary visual cortex, where the responsiveness of neurons to oriented segments is arranged over repeated patterns of gradually changing orientations, broken by few discontinuities (Vanduffel et al., 2002). Angle selectivity emerged in the model’s V2 map. In the secondary visual cortex the main recently discovered phenomena is the selectivity to angles (Ito and Komatsu, 2004), especially in the range between 60 and 150 degrees. The essential features of color constancy are reproduced in the model’s VO map, which is the ability of neurons to respond to specific hues, regardless of intensity. Color constancy is the tendency of the color of a surface to appear more constant that it is in reality. This property is helpful in object recognition, and develops sometime between two and four months of a</context>
</contexts>
<marker>Vanduffel, Tootell, Schoups, Orban, 2002</marker>
<rawString>Wim Vanduffel, Roger B.H. Tootell, Anick A. Schoups, and Guy A. Orban. 2002. The organization of orientation selectivity throughout the macaque visual cortex. Cerebral Cortex, 12:647–662.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chantal Verkindt</author>
<author>Olivier Bertrand</author>
<author>Frano¸is Echallier</author>
<author>Jacques Pernier</author>
</authors>
<title>Tonotopic organization of the human auditory cortex: N100 topography and multiple dipole model analysis. Electroencephalography and Clinical Neurophisiology,</title>
<date>1995</date>
<pages>96--143</pages>
<contexts>
<context position="20339" citStr="Verkindt et al., 1995" startWordPosition="3443" endWordPosition="3446">lops sometime between two and four months of age. (Dannemiller, 1989). One of the main functions shown by the LOC layer in the model is visual invariance, the property of neurons to respond to peculiar object features despite changes in the object’s appearance due to different points of view. Invariance indeed is one of the main requirements for an object-recognition area, and is found in human LOC (Grill-Spector et al., 2001; Kanwisher, 2003). Tonotopic mapping is a known feature of the primary auditory cortex that represents the dimensions of frequency and time sequences in a sound pattern (Verkindt et al., 1995). In the model it is split into a sheet where neurons have receptive fields that are more elongated along the time dimension (LPC) and another where the resulting receptive fields are more elongated along the frequency dimension (HPC). The spectrotemporal mapping obtained in STS is a population coding of features, in frequency and time domains, representative of the sound patterns heard during the development phase. It therefore reflects the statistical phonemic regularities in common spoken English, extracted from the 7200 training samples. category test A test B test C test D medicine 0.906 </context>
</contexts>
<marker>Verkindt, Bertrand, Echallier, Pernier, 1995</marker>
<rawString>Chantal Verkindt, Olivier Bertrand, Frano¸is Echallier, and Jacques Pernier. 1995. Tonotopic organization of the human auditory cortex: N100 topography and multiple dipole model analysis. Electroencephalography and Clinical Neurophisiology, 96:143–156.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>