<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000724">
<title confidence="0.9928145">
Mandarin-English Information (MEI):
Investigating Translingual Speech Retrieval
</title>
<author confidence="0.999895">
Helen Meng,&apos; Sanjeev Khudanpur,2 Gina Levow,3 Douglas W. Oard,3 Hsin-Min Wang4
</author>
<affiliation confidence="0.9976805">
&apos;The Chinese University of Hong Kong, 2Johns Hopkins University,
3University of Maryland and 4Academia Sinica (Taiwan)
</affiliation>
<bodyText confidence="0.343507">
{hmmeng@se.cuhk.edu.hk, s anjeev@ cl sp. jhu. edu , gin a@ umiacs .umd.edu,
oard@ glue.umd.edu, whm@ iis.sinica.edu.tw }
</bodyText>
<sectionHeader confidence="0.979509" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999790733333333">
We describe a system which supports
English text queries searching for
Mandarin Chinese spoken documents.
This is one of the first attempts to tightly
couple speech recognition with machine
translation technologies for cross-media
and cross-language retrieval. The
Mandarin Chinese news audio are indexed
with word and subword units by speech
recognition. Translation of these multi-
scale units can effect cross-language
information retrieval. The integrated
technologies will be evaluated based on
the performance of translingual speech
retrieval.
</bodyText>
<sectionHeader confidence="0.998217" genericHeader="keywords">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999311542857143">
Massive quantities of audio and multimedia
programs are becoming available. For example,
in mid-February 2000, www.real.com listed
1432 radio stations, 381 Internet-only
broadcasters, and 86 television stations with
Internet-accessible content, with 529
broadcasting in languages other than English.
Monolingual speech retrieval is now practical, as
evidenced by services such as SpeechBot
(speechbot.research.compaq.com), and it is clear
that there is a potential demand for translingual
speech retrieval if effective techniques can be
developed. The Mandarin-English Information
(MEI) project represents one of the first efforts
in that direction.
MEI is one of the four projects selected for
the Johns Hopkins University (JHU) Summer
Workshop 2000.1 Our research focus is on the
integration of speech recognition and embedded
translation technologies in the context of
translingual speech retrieval. Possible
applications of this work include audio and
video browsing, spoken document retrieval,
automated routing of information, and
automatically alerting the user when special
events occur.
At the time of this writing, most of the MEI
team members have been identified. This paper
provides an update beyond our first proposal
[Meng et al., 20001. We present some ongoing
work of our current team members, as well as
our ideas on an evolving plan for the upcoming
JHU Summer Workshop 2000. We believe the
input from the research community will benefit
us greatly in formulating our final plan.
</bodyText>
<sectionHeader confidence="0.998847" genericHeader="introduction">
2. Background
</sectionHeader>
<subsectionHeader confidence="0.57173">
2.1 Translingual Information Retrieval
</subsectionHeader>
<bodyText confidence="0.994192181818182">
The earliest work on large-vocabulary cross-
language information retrieval from free-text
(i.e., without manual topic indexing) was
reported in 1990 [Landauer and Littman, 1990],
and the topic has received increasing attention
over the last five years [Oard and Diekema,
1998]. Work on large-vocabulary retrieval from
recorded speech is more recent, with some initial
work reported in 1995 using subword indexing
[Wechsler and Schauble, 1995], followed by the
first TREC2 Spoken Document Retrieval (SDR)
</bodyText>
<footnote confidence="0.9914875">
&apos;http://www.c1sp.jhu.edu/ws2000/
2 Text REtrieval Conference, http://trec.nist.gov
</footnote>
<page confidence="0.998461">
23
</page>
<bodyText confidence="0.999727655172414">
evaluation [Garofolo et al., 2000]. The Topic
Detection and Tracking (TDT) evaluations,
which started in 1998, fall within our defmition
of speech retrieval for this purpose, differing
from other evaluations principally in the nature
of the criteria that human assessors use when
assessing the relevance of a news story to an
information need. In TDT, stories are assessed
for relevance to an event, while in TREC stories
are assessed for relevance to an explicitly stated
information need that is often subject- rather
than event-oriented.
The TDT-33 evaluation marked the first
case of translingual speech retrieval — the task of
finding information in a collection of recorded
speech based on evidence of the information
need that might be expressed (at least partially)
in a different language. Translingual speech
retrieval thus merges two lines of research that
have developed separately until now. In the
TDT-3 topic tracking evaluation, recognizer
transcripts which have recognition errors were
available, and it appears that every team made
use of them. This provides a valuable point of
reference for investigation of techniques that
more tightly couple speech recognition with
translingual retrieval. We plan to explore one
way of doing this in the Mandarin-English
Information (MEI) project.
</bodyText>
<subsectionHeader confidence="0.999237">
2.2 The Chinese Language
</subsectionHeader>
<bodyText confidence="0.999249">
In order to retrieve Mandarin audio documents,
we should consider a number of linguistic
characteristics of the Chinese language:
The Chinese language has many dialects.
Different dialects are characterized by their
differences in the phonetics, vocabularies and
syntax. Mandarin, also known as Putongh[ua
(&amp;quot;the common language&amp;quot;), is the most widely
used dialect. Another major dialect is Cantonese,
predominant in Hong Kong, Macau, South
China and many overseas Chinese communities.
Chinese is a syllable-based language,
where each syllable carries a lexical tone.
Mandarin has about 400 base syllables and four
lexical tones, plus a &amp;quot;light&amp;quot; tone for reduced
syllables. There are about 1,200 distinct, tonal
syllables for Mandarin. Certain syllable-tone
</bodyText>
<footnote confidence="0.770519">
3http://morph.ldc.upenn.edu/Projects/TDT3/
</footnote>
<bodyText confidence="0.992033658536586">
combinations are non-existent in the language.
The acoustic correlates of the lexical tone
include the syllable&apos;s fundamental frequency
(pitch contour) and duration. However, these
acoustic features are also highly dependent on
prosodic variations of spoken utterances.
The structure of Mandarin (base) syllables
is (CG)V(X), where (CG) the syllable onset — C
the initial consonant, G is the optional medial
glide, V is the nuclear vowel, and X is the coda
(which may be a glide, alveolar nasal or velar
nasal). Syllable onsets and codas are optional.
Generally C is known as the syllable initial, and
the rest (GVX) syllable final.4 Mandarin has
approximately 21 initials and 39 finals.5
In its written form, Chinese is a sequence
of characters. A word may contain one or more
characters. Each character is pronounced as a
tonal syllable. The character-syllable mapping is
degenerate. On one hand, a given character may
have multiple syllable pronunciations — for
example, the character 41- may be pronounced as
/hang2/,6 /hang4i, or /xing2/. On the other hand,
a given tonal syllable may correspond to
multiple characters. Consider the two-syllable
pronunciation /fu4 shu4/, which corresponds to a
two-character word. Possible homophones
include IA , (meaning &amp;quot;rich&amp;quot;), A A, (&amp;quot;negative
number&amp;quot;), 4tA, (&amp;quot;complex number&amp;quot; or
&amp;quot;plural&amp;quot;), IA (&amp;quot;repeat&amp;quot;).7
Aside from homographs and homophones,
another source of ambiguity in the Chinese
language is the defmition of a Chinese word.
The word has no delimiters, and the distinction
between a word and a phrase is often vague. The
lexical structure of the Chinese word is very
different compared to English. Inflectional
forms are minimal, while morphology and word
derivations abide by a different set of rules. A
word may inherit the syntax and semantics of
(some of) its compositional characters, for
</bodyText>
<footnote confidence="0.9926894">
4http://morph.ldc.upenn.edu/Projects/Chinese/intro.htinl
5 The corresponding linguistic characteristics of Cantonese
are very similar.
6 These are Mandarin pinyin, the number encodes the tone
of the syllable.
</footnote>
<page confidence="0.822054">
7 Example drawn from [Leung, 1999].
24
</page>
<bodyText confidence="0.965977475">
example,8 *r_ means red (a noun or an
adjective), e. means color (a noun), and *, a.
together means &amp;quot;the color red&amp;quot;(a noun) or
simply &amp;quot;red&amp;quot; (an adjective). Alternatively, a
word may take on totally different
characteristics of its own, e.g. means east (a
noun or an adjective), gr means west (a noun or
an adjective), and itiri together means thing (a
noun). Yet another case is where the
compositional characters of a word do not form
independent lexical entries in isolation, e.g. #4
means fancy (a verb), but its characters do not
occur individually. Possible ways of deriving
new words from characters are legion. The
problem of identifying the words string in a
character sequence is known as the segmentation
I tokenization problem. Consider the syllable
string:
/zhe4 yi 1 wan3 hui4 ru2 chang2 ju3 xing2/
The corresponding character string has three
possible segmentations – all are correct, but each
involves a distinct set of words:
it— Rt. * lto
(Meaning: It will be take place tonight as usual.)
— *it AI-ft
(Meaning: The evening banquet will take place
as usual.)
— Itt.* -3to iitft
(Meaning: If this evening banquet takes place
frequently...)
The above considerations lead to a number
of techniques we plan to use for our task. We
concentrate on three equally critical problems
related to our theme of translingual speech
retrieval: (i) indexing Mandarin Chinese audio
with word and subword units, (ii) translating
variable-size units for cross-language
information retrieval, and (iii) devising effective
retrieval strategies for English text queries and
Mandarin Chinese news audio.
</bodyText>
<sectionHeader confidence="0.930668" genericHeader="method">
3. Multiscale Audio Indexing
</sectionHeader>
<bodyText confidence="0.983874">
A popular approach to spoken document
retrieval is to apply Large-Vocabulary
8 Examples drawn from [Meng and Ip, 1999].
Continuous Speech Recognition (LVCSR)9 for
audio indexing, followed by text retrieval
techniques. Mandarin Chinese presents a
challenge for word-level indexing by LVCSR,
because of the ambiguity in tokenizing a
sentence into words (as mentioned earlier).
Furthermore, LVCSR with a static vocabulary is
hampered by the out-of-vocabulary (00V)
problem, especially when searching sources with
topical coverage as diverse as that found in
broadcast news.
By virtue of the monosyllabic nature of the
Chinese language and its dialects, the syllable
inventory can provide a complete phonological
coverage for spoken documents, and circumvent
the 00V problem in news audio indexing,
offering the potential for greater recall in
subsequent retrieval. The approach thus supports
searches for previously unknown query terms in
the indexed audio.
The pros and cons of subword indexing for
an English spoken document retrieval task was
studied in [Ng, 2000]. Ng pointed out that the &amp;quot;
exclusion of lexical knowledge when subword
indexing is performed in isolation may adversely
impact discrimination power for retrieval, but
that some of that impact can be mitigated by
modeling sequential constraints among subword
units. We plan to investigate the efficacy of
using both word and subword units for
Mandarin audio indexing [Meng et al., 2000].
Although Ng found that such an approach
produced little gain over words alone for
English, the structure of Mandarin Chinese may
produce more useful subword features.
</bodyText>
<subsectionHeader confidence="0.999961">
3.1 Modeling Syllable Sequence Constraints
</subsectionHeader>
<bodyText confidence="0.999468222222222">
We have thus far used overlapping syllable N-
grams for spoken &apos;document retrieval for two
Chinese dialects – Mandarin and Cantonese.
Results on a known-item retrieval task with over
1,800 error-free news transcripts [Meng et al.,
1999] indicate that constraints from overlapping
bigrams can yield significant improvements in
retrieval performance over syllable unigrams,
producing retrieval performance competitive
</bodyText>
<footnote confidence="0.726800333333333">
9 The lexicon size of a typical large-vocabulary
continuous speech recognizer can range from 10,000
to 100,000 word forms.
</footnote>
<page confidence="0.996022">
25
</page>
<bodyText confidence="0.999690789473684">
with that obtained using automatically tokenized
Chinese words.
The study in [Chen, Wang and Lee, 2000]
also used syllable pairs with skipped syllables in
between. This is because many Chinese
abbreviations are derived from skipping
characters, e.g. Ei National
Science Council&amp;quot; can be abbreviated as
(including only the first, third and the last
characters). Moreover, synonyms often differ by
one or two characters, e.g. both 1.45t4t, and
t.E.5t.ft mean &amp;quot;Chinese culture&amp;quot;. Inclusion of
these &amp;quot;skipped syllable pairs&amp;quot; also contributed to
retrieval performance.
When modeling sequential syllable
constraints, lexical constraints on recognized
words may be helpful. We thus plan to explore
the potential for integrated sequential modelling
of both words and syllables [Meng et al., 2000].
</bodyText>
<sectionHeader confidence="0.971574" genericHeader="method">
4. Multiscale Embedded Translation
</sectionHeader>
<bodyText confidence="0.9998635">
Figures 1 and 2 illustrate two translingual
retrieval strategies. In query translation, English
text queries are transformed into Mandarin and
then used to retrieve Mandarin documents. For
document translation, Mandarin documents are
translated into English before they are indexed
and then matched with English queries.
McCarley has reported improved effectiveness
from techniques that couple the two techniques
[McCarley, 1999], but time constraints may
limit us to exploring only the query translation
strategy during the six-week Workshop.
</bodyText>
<subsectionHeader confidence="0.997005">
4.1 Word Translation
</subsectionHeader>
<bodyText confidence="0.99998353968254">
While we make use of sub-word
transcription to smooth out-of-vocabulary(00V)
problems in speech recognition as described
above, and to alleviate the 00V problem for
translation as we discuss in the next section,
accurate translation generally relies on the
additional information available at the word and
phrase levels. Since the &amp;quot;bag of words&amp;quot;
information retrieval techniques do not
incorporate any meaningful degree of language
understanding to assess similarity between
queries and documents, a word-for-word (or,
more generally, term-for-term) embedded
translation approach can achieve a useful level
of effectiveness for many translingual retrieval
applications [Oard and Diekema, 1998].
We have developed such a technique for the
TDT-3 topic tracking evaluation [Levow and
Oard, 2000]. For that work we extracted an
enriched bilingual Mandarin-English term list by
combining two term lists: (i) A list assembled
by the Linguistic Data Consortium from freely
available on-line resources; and (ii) entries from
the CETA file (sometimes referred to as
&amp;quot;Optilex&amp;quot;). This is a Chinese to English
translation resource that was manually compiled
by a team of linguists from more than 250 text
sources, including special and general-purpose
print dictionaries, and other text sources such as
newspapers. The CETA file contains over
250,000 entries, but for our lexical work we
extracted a subset of those entries drawn from
contemporary general-purpose sources. We also
excluded definitions such as &amp;quot;particle indicating
a yes/no question.&amp;quot; Our resulting Chinese to
English merged bilingual term list contains
translations for almost 200,000 Chinese terms,
with average of almost two translation
alternatives per term. We have also used the
same resources to construct an initial English to
Chinese bilingual term list that we plan to refine
before the Workshop.
Three significant challenges faced by term-
to-term translation systems are term selection in
the source language, the source language
coverage of the bilingual term list, and
translation selection in the target language when
more than one alternative translation is known.
Word segmentation is a natural by-product of
large vocabulary Mandarin speech recognition,
and white space provides word boundaries for
the English queries. We thus plan to choose
words as our basic term set, perhaps augmenting
this with the multiword expressions found in the
bilingual term list.
Achieving adequate source language
coverage is challenging in news retrieval
applications of the type modelled by TDT,
because proper names and technical terms that
may not be present in general-purpose lexical
resources often provide important retrieval cues.
Parallel (translation equivalent) corpora have
proven to be a useful source of translation
</bodyText>
<page confidence="0.990008">
26
</page>
<bodyText confidence="0.9999518">
equivalent terms, but obtaining appropriate
domain-specific parallel corpora in electronic
form may not be practical in some applications.
We therefore plan to investigate the use of
comparable corpora to learn translation
equivalents, based on techniques in [Fung,
1998]. Subword translation, described below,
provides a complementary way of handling
terms for which translation equivalents cannot
be reliably extracted from the available
comparable corpora.
One way of dealing with multiple
translations is to weight the alternative
translations using either a statistical translation
model trained on parallel or comparable corpora
to estimate translation probability conditioned
on the source language term. When such
resources are not sufficiently informative, it is
generally possible to back off to an
unconditioned preference statistic based on
usage frequency of each possible translation in a
representative monolingual corpus in the target
language. In retrospective retrieval applications
the collection being searched can be used for
this purpose. We have applied simple versions
of this approach with good results [Levow and
Oard, 2000].
We have recently observed that a simpler
technique introduced by [Pirkola, 1998] can
produce excellent results. The key idea is to use
the structure of the lexicon, in which several
target language terms can represent a single
source language term, to induce structure in the
translated query that the retrieval system can
automatically exploit. In essence, the translated
query becomes a bag of bags of terms, where
each smaller bag corresponds to the set of
possible translations for one source-language
term. We plan to implement this structured
query translation approach using the Inquery
[Callan, 1992] &amp;quot;synonym&amp;quot; operator in the same
manner as [Pirkola, 1998], and to the potential to
extend the technique to accommodate alternative
recognition hypothesis and subword units as
well.
</bodyText>
<subsectionHeader confidence="0.988018">
4.2 Subword Translation
</subsectionHeader>
<bodyText confidence="0.999623906976744">
Since Mandarin spoken documents can be
indexed with both words and subwords, the
translation (or &amp;quot;phonetic transliteration&amp;quot;) of
subword units is of particular interest. We plan
to make use of cross-language phonetic
mappings derived from English and Mandarin
pronunciation rules for this purpose. This should
be especially useful for handling named entities
in the queries, e.g. names of people, places and
organizations, etc. which are generally important
for retrieval, but may not be easily translated.
Chinese translations of English proper nouns
may involve semantic as well as phonetic
mappings. For example, &amp;quot;Northern Ireland&amp;quot; is
translated as 3t ti# M — where the first
character 3t, means &apos;north&apos;, and the remaining
characters flit MI are pronounced as /ai4-er3-
lan2/. Hence the translation is both semantic
and phonetic. When Chinese translations strive
to attain phonetic similarity, the mapping may
be inconsistent. For example, consider the
translation of &amp;quot;Kosovo&amp;quot; – sampling Chinese
newspapers in China, Taiwan and Hong Kong
produces the following translations:
** /kel-suo3-wo4/, **I* /kel-suo3-fo2/,
44* k /kel-suo3-ful/,*** /kel-suo3-fir2/, or.
49-** /kel-suo3-fo2/.
As can be seen, there is no systematic
mapping to the Chinese character sequences, but
the translated Chinese pronunciations bear some
resemblance to the English pronunciation (/k ow
s ax v ow/). In order to support retrieval under
these circumstances, the approach should
involve approximate matches between the
English pronunciation and the Chinese
pronunciation. The matching algorithm should
also accommodate phonological variations.
Pronunciation dictionaries, or pronunciation
generation tools for both English words and
Chinese words / characters will be useful for the
matching algorithm. We can probably leverage
off of ideas in the development of universal
speech recognizers [Cohen et al., 1997].
</bodyText>
<sectionHeader confidence="0.974958" genericHeader="method">
5. Multiscale Retrieval
</sectionHeader>
<subsectionHeader confidence="0.999713">
5.1 Coupling Words and Subwords
</subsectionHeader>
<bodyText confidence="0.999915833333333">
We intend to use both words and subwords for
retrieval. Loose coupling would involve separate
retrieval runs using words and subwords,
producing two ranked lists, followed by list
merging using techniques such as those explored
by [Voorhees, 1995]. Tight coupling, by
</bodyText>
<page confidence="0.995191">
27
</page>
<bodyText confidence="0.9999685">
contrast, would require creation of a unified
index containing both word and subword units,
resulting in a single ranked list. We hope to
explore both techniques during the Workshop.
</bodyText>
<subsectionHeader confidence="0.999688">
5.2 Imperfect Indexing and Translation
</subsectionHeader>
<bodyText confidence="0.999976923076923">
It should be noted that speech recognition
exacerbates uncertainty when indexing audio,
and that translation or transliteration exacerbates
uncertainty when translating queries and/or
documents. To achieve robustness for retrieval,
we have tried three techniques that we have
found useful: (i) Syllable lattices were used in
[Wang, 1999] and [Chien et al., 20001 for
monolingual Chinese retrieval experiments. The
lattices were pruned to constrain the search
space, but were able to achieve robust retrieval
based on imperfect recognized transcripts. (ii)
Query expansion, in which syllable transcription
were expanded to include possibly confusable
syllable sequences based on a syllable confusion
matrix derived from recognition errors, was used
in [Meng et al., 19991. (iii) We have expanded
the document representation using terms
extracted from similar documents in a
comparable collection [Levow and Oard, 2000],
and similar techniques are known to work well
in the case of query translation (Ballesteros and
Croft, 1997). We hope to add to this set of
techniques by exploring the potential for query
expansion based on cross-language phonetic
mapping.
</bodyText>
<sectionHeader confidence="0.814153" genericHeader="method">
6. Using the TDT-3 Collection
</sectionHeader>
<bodyText confidence="0.99998727027027">
We plan to use the TDT-2 collection for
development testing and the TDT-3 collection
for evaluation. Both collections provide
documents from two English newswire sources,
six English broadcast news audio sources, two
Mandarin Chinese newswire sources, and one
Mandarin broadcast news source (Voice of
America). Manually established story
boundaries are available for all audio
collections, and we plan to exploit that
information to simplify our experiment design.
The TDT-2 collection includes complete
relevance assessments for 20 topics, and the
TDT-3 collection provides the same for 60
additional topics, 56 of which have at least one
relevant audio story. For each topic, at least four
English stories and four Chinese stories are
known.
We plan to automatically derive text queries
based on one or more English stories that are
presented as exemplars, and to use those queries
to search the Mandarin audio collection.
Manually constructed queries will provide a
contrastive condition. Unlike the TDT &amp;quot;topic
tracking&amp;quot; task in which stories must be declared
relevant or not relevant in the order of their
arrival, we plan to perform retrospective
retrieval experiments in which all documents are
known when the query is issued. By relaxing
the temporal ordering of the TDT topic tracking
task, we can meaningfully search for Mandarin
Chinese stories that may have arrived before the
exemplar story or stories. We thus plan to report
ranked retrieval measures of effectiveness such
as average precision in addition to the detection
statistics (miss and false alarm) typically
reported in TDT.
</bodyText>
<sectionHeader confidence="0.967818" genericHeader="conclusions">
7. Summary
</sectionHeader>
<bodyText confidence="0.9997538">
This paper presents our current ideas and
evolving plan for the MEI project, to take place
at the Johns Hopkins University Summer
Workshop 2000. Translingual speech retrieval is
a long-term research direction, and our team
looks forward to jointly taking an initial step to
tackle the problem. The authors welcome all
comments and suggestions, as we strive to better
defme the problem in preparation for the six-
week Workshop.
</bodyText>
<sectionHeader confidence="0.997489" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.996337666666667">
The authors wish to thank Patrick Schone, Erika
Grams, Fred Jelinek, Charles Wayne, Kenney
Ng, John Garofolo, and the participants in the
December 1999 WS2000 planning meeting and
the TDT-3 workshop for their many helpful
suggestions. The Hopkins Summer Workshop
series is supported by grants from the National
Science Foundation. Our results reported in this
paper reference thesis work in progress of Wai-
Kit Lo (Ph.D. candidate, The Chinese Unversity
of Hong Kong) and Berlin Chen (Ph.D.
candidate, National Taiwan University).
</bodyText>
<page confidence="0.997697">
28
</page>
<sectionHeader confidence="0.978138" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999659410526316">
Ballesteros and W. B. Croft, &amp;quot;Phrasal
Translation and Query Expansion Techniques
for Cross-Language Information Retrieval,&amp;quot;
Proceedings of ACM SIGIR, 1997.
Callan, J. P., W. B. Croft, and S. M. Harding,
&amp;quot;The INQUERY Retrieval System,&amp;quot;
Proceedings of the 3rd International Conference
on Database and Expert Systems Applications,
1992.
Carbonnell, J., Y. Yang, R. Frederking and R.D.
Brown, &amp;quot;Translingual Information Retrieval: A
Comparative Evaluation,&amp;quot; Proceedings of IJCAI,
1997.
Chen, B., H.M. Wang, and L.S. Lee, &amp;quot;Retrieval
of Broadcast News Speech in Mandarin Chinese
Collected in Taiwan using Syllable-Level
Statistical Characteristics,&amp;quot; Proceedings of
ICASSP, 2000.
Chien, L. F., H. M. Wang, B. R. Bai, and S. C.
Lin, &amp;quot;A Spoken-Access Approach for Chinese
Text and Speech Information Retrieval,&amp;quot; Journal
of the American Society for Information
Science, 51(4), pp. 313-323, 2000.
Choy, C. Y., &amp;quot;Acoustic Units for Mandarin
Chinese Speech Recognition,&amp;quot; M.Phil. Thesis,
The Chinese University of Hong Kong, Hong
Kong SAR, China, 1999.
Cohen, P., S. Dharanipragada, J. Gros, M.
Mondowski, C. Neti, S. Roukos and T. Ward,
&amp;quot;Towards a Universal Speech Recognizer for
Multiple Languages,&amp;quot; Proceedings of ASRU,
1997.
Fung, P., &amp;quot;A Statistical View on Bilingual
Lexicon Extraction: From parallel corpora to
non-parallel corpora,&amp;quot; Proceedings of AMTA,
1998.
Garofolo, J.S., Auzanne, G.P., Voorhees, E.M.,
&amp;quot;The TREC Spoken Document Retrieval Track:
A Success Story,&amp;quot; Proceedings of the Recherche
d&apos;Informations Assist&amp; par Ordinateur: Content-
Based Multimedia Information Access
Conference , April 12-14, 2000,to be published.
Knight, K. and J. Graehl, &amp;quot;Machine
Transliteration,&amp;quot; Proceedings of ACL, 1997.
Landauer, T. K. and M.L. Littman, &amp;quot;Fully
Automatic Cross-Language Document Retrieval
Using Latent Semantic Indexing,&amp;quot; Proceedings
of the 6th Annual Conference of the UW Centre
for the New Oxford English Dictionary, 1990.
Leung, R., &amp;quot;Lexical Access for Large
Vocabulary Chinese Speech Recognition,&amp;quot; M.
Phil. Thesis, The Chinese University of Hong
Kong, Hong Kong SAR, China 1999.
Levow, G. and D.W. Oard, &amp;quot;Translingual Topic
Tracking with PRISE,&amp;quot; Working notes of the
DARPA TDT-3 Workshop, 2000.
Lin, C. H., L. S. Lee, and P. Y. Ting, &amp;quot;A New
Framework for Recognition of Mandarin
Syllables with Tones using Sub-Syllabic Units,&amp;quot;
Proceedings of ICASSP, 1993.
Liu, F. H., M. Picheny, P. Srinivasa, M.
Monkowski and J. Chen, &amp;quot;Speech Recognition
on Mandarin Call Home: A Large-Vocabulary,
Conversational, and Telephone Speech Corpus,&amp;quot;
Proceedings of ICASSP, 1996.
McCarley, S., &amp;quot;Should we Translate the
Documents or the Queries in Cross-Language
Information Retrieval,&amp;quot; Proceedings of ACL,
1999.
Meng, H. and C. W. Ip, &amp;quot;An Analytical Study of &amp;quot;
Transformational Tagging of Chinese Text,&amp;quot;
Proceedings of the Research On Computational
Lingustics (ROCLING) Conference, 1999.
Meng, H., W. K. Lo, Y. C. Li and P. C. Ching,
&amp;quot;A Study on the Use of Syllables for Chinese
Spoken Document Retrieval,&amp;quot; Technical Report
SEEM1999-11, The Chinese University of Hong
Kong, 1999.
Meng, H., Khudanpur, S., Oard, D. W. and
Wang, H. M., &amp;quot;Mandarin-English Information
(MEI),&amp;quot; Working notes of the DARPA TDT-3
Workshop, 2000.
Ng, K., &amp;quot;Subword-based Approaches for Spoken
Document Retrieval,&amp;quot; Ph.D. Thesis, MIT,
February 2000. -
Oard, D. W. and A.R. Diekema, &amp;quot;Cross-
Language Information Retrieval,&amp;quot; Annual
Review of Information Science and Technology,
vol.33, 1998.
Pirkola, A., &amp;quot;The effects of query structure and
dictionary setups in dictionary-based cross-
language information retrieval,&amp;quot; Proceedings of
ACM SIGIR, 1998.
Sheridan P. and J. P. Ballerini, &amp;quot;Experiments in
Multilingual Information Retrieval using the
</reference>
<page confidence="0.974559">
29
</page>
<reference confidence="0.993965666666667">
SPIDER System,&amp;quot; Proceedings of ACM SIGIR, Wechsler, M. and P. Schatible, &amp;quot;Speech
1996. Retrieval Based on Automatic Indexing,&amp;quot;
Voorhees, E., &amp;quot;Learning Collection Fusion Proceedings of MIRO-1995.
Strategies,&amp;quot; Proceedings of SIGIR, 1995.
Wang, H. M., &amp;quot;Retrieval of Mandarin Spoken
Documents Based on Syllable Lattice
Matching,&amp;quot; Proceedings of the Fourth
International Workshop on Information
Retrieval in Asian Languages, 1999.
</reference>
<figureCaption confidence="0.989568">
Figure 1. Query translation strategy.
</figureCaption>
<figure confidence="0.978871095238095">
English Text Queries
(words)
Mandarin Spoken Documents
(indexed with word and subword units)
Translation Documents in Information Retrieval Evaluate
English Engine Retrieval
Performance
English Text Queries
(words)
Words that are present in the
translation dictionary
Translation
Named entities and unknown words
Transliteration
Mandarin eries (with words and syllables)
Information Retrieval
Engine
1 o, Evaluate
Retrieval
Performance
Mandarin Spoken Documents
</figure>
<figureCaption confidence="0.9330505">
(indexed with word and subword units)
Figure 2. Document translation strategy.
</figureCaption>
<page confidence="0.964139">
30
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.399527">
<title confidence="0.9940725">Mandarin-English Information Investigating Translingual Speech Retrieval</title>
<author confidence="0.988688">Sanjeev Gina Douglas W Hsin-Min</author>
<affiliation confidence="0.634569">Chinese University of Hong Kong, Hopkins</affiliation>
<abstract confidence="0.973212578947369">of Maryland and Sinica s anjeev@ cl sp. jhu. edu , a@ umiacs glue.umd.edu, whm@ iis.sinica.edu.tw} Abstract We describe a system which supports English text queries searching for Mandarin Chinese spoken documents. This is one of the first attempts to tightly couple speech recognition with machine translation technologies for cross-media and cross-language retrieval. The Mandarin Chinese news audio are indexed with word and subword units by speech recognition. Translation of these multiscale units can effect cross-language information retrieval. The technologies will be evaluated based on the performance of translingual speech retrieval.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ballesteros</author>
<author>W B Croft</author>
</authors>
<title>Phrasal Translation and Query Expansion Techniques for Cross-Language Information Retrieval,&amp;quot;</title>
<date>1997</date>
<booktitle>Proceedings of ACM SIGIR,</booktitle>
<contexts>
<context position="20770" citStr="Ballesteros and Croft, 1997" startWordPosition="3057" endWordPosition="3060">periments. The lattices were pruned to constrain the search space, but were able to achieve robust retrieval based on imperfect recognized transcripts. (ii) Query expansion, in which syllable transcription were expanded to include possibly confusable syllable sequences based on a syllable confusion matrix derived from recognition errors, was used in [Meng et al., 19991. (iii) We have expanded the document representation using terms extracted from similar documents in a comparable collection [Levow and Oard, 2000], and similar techniques are known to work well in the case of query translation (Ballesteros and Croft, 1997). We hope to add to this set of techniques by exploring the potential for query expansion based on cross-language phonetic mapping. 6. Using the TDT-3 Collection We plan to use the TDT-2 collection for development testing and the TDT-3 collection for evaluation. Both collections provide documents from two English newswire sources, six English broadcast news audio sources, two Mandarin Chinese newswire sources, and one Mandarin broadcast news source (Voice of America). Manually established story boundaries are available for all audio collections, and we plan to exploit that information to simpl</context>
</contexts>
<marker>Ballesteros, Croft, 1997</marker>
<rawString>Ballesteros and W. B. Croft, &amp;quot;Phrasal Translation and Query Expansion Techniques for Cross-Language Information Retrieval,&amp;quot; Proceedings of ACM SIGIR, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J P Callan</author>
<author>W B Croft</author>
<author>S M Harding</author>
</authors>
<title>The INQUERY Retrieval System,&amp;quot;</title>
<date>1992</date>
<booktitle>Proceedings of the 3rd International Conference on Database and Expert Systems Applications,</booktitle>
<marker>Callan, Croft, Harding, 1992</marker>
<rawString>Callan, J. P., W. B. Croft, and S. M. Harding, &amp;quot;The INQUERY Retrieval System,&amp;quot; Proceedings of the 3rd International Conference on Database and Expert Systems Applications, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carbonnell</author>
<author>Y Yang</author>
<author>R Frederking</author>
<author>R D Brown</author>
</authors>
<title>Translingual Information Retrieval: A Comparative Evaluation,&amp;quot;</title>
<date>1997</date>
<booktitle>Proceedings of IJCAI,</booktitle>
<marker>Carbonnell, Yang, Frederking, Brown, 1997</marker>
<rawString>Carbonnell, J., Y. Yang, R. Frederking and R.D. Brown, &amp;quot;Translingual Information Retrieval: A Comparative Evaluation,&amp;quot; Proceedings of IJCAI, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Chen</author>
<author>H M Wang</author>
<author>L S Lee</author>
</authors>
<title>Retrieval of Broadcast News Speech in Mandarin Chinese Collected in Taiwan using Syllable-Level Statistical Characteristics,&amp;quot;</title>
<date>2000</date>
<booktitle>Proceedings of ICASSP,</booktitle>
<marker>Chen, Wang, Lee, 2000</marker>
<rawString>Chen, B., H.M. Wang, and L.S. Lee, &amp;quot;Retrieval of Broadcast News Speech in Mandarin Chinese Collected in Taiwan using Syllable-Level Statistical Characteristics,&amp;quot; Proceedings of ICASSP, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L F Chien</author>
<author>H M Wang</author>
<author>B R Bai</author>
<author>S C Lin</author>
</authors>
<title>A Spoken-Access Approach for Chinese Text and Speech Information Retrieval,&amp;quot;</title>
<date>2000</date>
<journal>Journal of the American Society for Information Science,</journal>
<volume>51</volume>
<issue>4</issue>
<pages>313--323</pages>
<contexts>
<context position="20104" citStr="Chien et al., 2000" startWordPosition="2960" endWordPosition="2963">hees, 1995]. Tight coupling, by 27 contrast, would require creation of a unified index containing both word and subword units, resulting in a single ranked list. We hope to explore both techniques during the Workshop. 5.2 Imperfect Indexing and Translation It should be noted that speech recognition exacerbates uncertainty when indexing audio, and that translation or transliteration exacerbates uncertainty when translating queries and/or documents. To achieve robustness for retrieval, we have tried three techniques that we have found useful: (i) Syllable lattices were used in [Wang, 1999] and [Chien et al., 20001 for monolingual Chinese retrieval experiments. The lattices were pruned to constrain the search space, but were able to achieve robust retrieval based on imperfect recognized transcripts. (ii) Query expansion, in which syllable transcription were expanded to include possibly confusable syllable sequences based on a syllable confusion matrix derived from recognition errors, was used in [Meng et al., 19991. (iii) We have expanded the document representation using terms extracted from similar documents in a comparable collection [Levow and Oard, 2000], and similar techniques are known to work w</context>
</contexts>
<marker>Chien, Wang, Bai, Lin, 2000</marker>
<rawString>Chien, L. F., H. M. Wang, B. R. Bai, and S. C. Lin, &amp;quot;A Spoken-Access Approach for Chinese Text and Speech Information Retrieval,&amp;quot; Journal of the American Society for Information Science, 51(4), pp. 313-323, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Y Choy</author>
</authors>
<title>Acoustic Units for Mandarin Chinese Speech Recognition,&amp;quot;</title>
<date>1999</date>
<tech>M.Phil. Thesis,</tech>
<institution>The Chinese University of Hong Kong, Hong Kong SAR,</institution>
<marker>Choy, 1999</marker>
<rawString>Choy, C. Y., &amp;quot;Acoustic Units for Mandarin Chinese Speech Recognition,&amp;quot; M.Phil. Thesis, The Chinese University of Hong Kong, Hong Kong SAR, China, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Cohen</author>
<author>S Dharanipragada</author>
<author>J Gros</author>
<author>M Mondowski</author>
<author>C Neti</author>
<author>S Roukos</author>
<author>T Ward</author>
</authors>
<title>Towards a Universal Speech Recognizer for Multiple Languages,&amp;quot;</title>
<date>1997</date>
<booktitle>Proceedings of ASRU,</booktitle>
<contexts>
<context position="19191" citStr="Cohen et al., 1997" startWordPosition="2824" endWordPosition="2827">the translated Chinese pronunciations bear some resemblance to the English pronunciation (/k ow s ax v ow/). In order to support retrieval under these circumstances, the approach should involve approximate matches between the English pronunciation and the Chinese pronunciation. The matching algorithm should also accommodate phonological variations. Pronunciation dictionaries, or pronunciation generation tools for both English words and Chinese words / characters will be useful for the matching algorithm. We can probably leverage off of ideas in the development of universal speech recognizers [Cohen et al., 1997]. 5. Multiscale Retrieval 5.1 Coupling Words and Subwords We intend to use both words and subwords for retrieval. Loose coupling would involve separate retrieval runs using words and subwords, producing two ranked lists, followed by list merging using techniques such as those explored by [Voorhees, 1995]. Tight coupling, by 27 contrast, would require creation of a unified index containing both word and subword units, resulting in a single ranked list. We hope to explore both techniques during the Workshop. 5.2 Imperfect Indexing and Translation It should be noted that speech recognition exace</context>
</contexts>
<marker>Cohen, Dharanipragada, Gros, Mondowski, Neti, Roukos, Ward, 1997</marker>
<rawString>Cohen, P., S. Dharanipragada, J. Gros, M. Mondowski, C. Neti, S. Roukos and T. Ward, &amp;quot;Towards a Universal Speech Recognizer for Multiple Languages,&amp;quot; Proceedings of ASRU, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Fung</author>
</authors>
<title>A Statistical View on Bilingual Lexicon Extraction: From parallel corpora to non-parallel corpora,&amp;quot;</title>
<date>1998</date>
<booktitle>Proceedings of AMTA,</booktitle>
<contexts>
<context position="15606" citStr="Fung, 1998" startWordPosition="2304" endWordPosition="2305">ate source language coverage is challenging in news retrieval applications of the type modelled by TDT, because proper names and technical terms that may not be present in general-purpose lexical resources often provide important retrieval cues. Parallel (translation equivalent) corpora have proven to be a useful source of translation 26 equivalent terms, but obtaining appropriate domain-specific parallel corpora in electronic form may not be practical in some applications. We therefore plan to investigate the use of comparable corpora to learn translation equivalents, based on techniques in [Fung, 1998]. Subword translation, described below, provides a complementary way of handling terms for which translation equivalents cannot be reliably extracted from the available comparable corpora. One way of dealing with multiple translations is to weight the alternative translations using either a statistical translation model trained on parallel or comparable corpora to estimate translation probability conditioned on the source language term. When such resources are not sufficiently informative, it is generally possible to back off to an unconditioned preference statistic based on usage frequency o</context>
</contexts>
<marker>Fung, 1998</marker>
<rawString>Fung, P., &amp;quot;A Statistical View on Bilingual Lexicon Extraction: From parallel corpora to non-parallel corpora,&amp;quot; Proceedings of AMTA, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Garofolo</author>
<author>G P Auzanne</author>
<author>E M Voorhees</author>
</authors>
<title>The TREC Spoken Document Retrieval Track: A Success Story,&amp;quot;</title>
<date>2000</date>
<booktitle>Proceedings of the Recherche d&apos;Informations Assist&amp; par Ordinateur: ContentBased Multimedia Information Access Conference ,</booktitle>
<note>be published.</note>
<contexts>
<context position="3146" citStr="Garofolo et al., 2000" startWordPosition="438" endWordPosition="441">he earliest work on large-vocabulary crosslanguage information retrieval from free-text (i.e., without manual topic indexing) was reported in 1990 [Landauer and Littman, 1990], and the topic has received increasing attention over the last five years [Oard and Diekema, 1998]. Work on large-vocabulary retrieval from recorded speech is more recent, with some initial work reported in 1995 using subword indexing [Wechsler and Schauble, 1995], followed by the first TREC2 Spoken Document Retrieval (SDR) &apos;http://www.c1sp.jhu.edu/ws2000/ 2 Text REtrieval Conference, http://trec.nist.gov 23 evaluation [Garofolo et al., 2000]. The Topic Detection and Tracking (TDT) evaluations, which started in 1998, fall within our defmition of speech retrieval for this purpose, differing from other evaluations principally in the nature of the criteria that human assessors use when assessing the relevance of a news story to an information need. In TDT, stories are assessed for relevance to an event, while in TREC stories are assessed for relevance to an explicitly stated information need that is often subject- rather than event-oriented. The TDT-33 evaluation marked the first case of translingual speech retrieval — the task of f</context>
</contexts>
<marker>Garofolo, Auzanne, Voorhees, 2000</marker>
<rawString>Garofolo, J.S., Auzanne, G.P., Voorhees, E.M., &amp;quot;The TREC Spoken Document Retrieval Track: A Success Story,&amp;quot; Proceedings of the Recherche d&apos;Informations Assist&amp; par Ordinateur: ContentBased Multimedia Information Access Conference , April 12-14, 2000,to be published.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>J Graehl</author>
</authors>
<title>Machine Transliteration,&amp;quot;</title>
<date>1997</date>
<booktitle>Proceedings of ACL,</booktitle>
<marker>Knight, Graehl, 1997</marker>
<rawString>Knight, K. and J. Graehl, &amp;quot;Machine Transliteration,&amp;quot; Proceedings of ACL, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T K Landauer</author>
<author>M L Littman</author>
</authors>
<title>Fully Automatic Cross-Language Document Retrieval Using Latent Semantic Indexing,&amp;quot;</title>
<date>1990</date>
<booktitle>Proceedings of the 6th Annual Conference of the UW Centre for the New Oxford English Dictionary,</booktitle>
<contexts>
<context position="2699" citStr="Landauer and Littman, 1990" startWordPosition="377" endWordPosition="380">e time of this writing, most of the MEI team members have been identified. This paper provides an update beyond our first proposal [Meng et al., 20001. We present some ongoing work of our current team members, as well as our ideas on an evolving plan for the upcoming JHU Summer Workshop 2000. We believe the input from the research community will benefit us greatly in formulating our final plan. 2. Background 2.1 Translingual Information Retrieval The earliest work on large-vocabulary crosslanguage information retrieval from free-text (i.e., without manual topic indexing) was reported in 1990 [Landauer and Littman, 1990], and the topic has received increasing attention over the last five years [Oard and Diekema, 1998]. Work on large-vocabulary retrieval from recorded speech is more recent, with some initial work reported in 1995 using subword indexing [Wechsler and Schauble, 1995], followed by the first TREC2 Spoken Document Retrieval (SDR) &apos;http://www.c1sp.jhu.edu/ws2000/ 2 Text REtrieval Conference, http://trec.nist.gov 23 evaluation [Garofolo et al., 2000]. The Topic Detection and Tracking (TDT) evaluations, which started in 1998, fall within our defmition of speech retrieval for this purpose, differing f</context>
</contexts>
<marker>Landauer, Littman, 1990</marker>
<rawString>Landauer, T. K. and M.L. Littman, &amp;quot;Fully Automatic Cross-Language Document Retrieval Using Latent Semantic Indexing,&amp;quot; Proceedings of the 6th Annual Conference of the UW Centre for the New Oxford English Dictionary, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Leung</author>
</authors>
<title>Lexical Access for Large Vocabulary Chinese Speech Recognition,&amp;quot;</title>
<date>1999</date>
<contexts>
<context position="7327" citStr="Leung, 1999" startWordPosition="1066" endWordPosition="1067">The word has no delimiters, and the distinction between a word and a phrase is often vague. The lexical structure of the Chinese word is very different compared to English. Inflectional forms are minimal, while morphology and word derivations abide by a different set of rules. A word may inherit the syntax and semantics of (some of) its compositional characters, for 4http://morph.ldc.upenn.edu/Projects/Chinese/intro.htinl 5 The corresponding linguistic characteristics of Cantonese are very similar. 6 These are Mandarin pinyin, the number encodes the tone of the syllable. 7 Example drawn from [Leung, 1999]. 24 example,8 *r_ means red (a noun or an adjective), e. means color (a noun), and *, a. together means &amp;quot;the color red&amp;quot;(a noun) or simply &amp;quot;red&amp;quot; (an adjective). Alternatively, a word may take on totally different characteristics of its own, e.g. means east (a noun or an adjective), gr means west (a noun or an adjective), and itiri together means thing (a noun). Yet another case is where the compositional characters of a word do not form independent lexical entries in isolation, e.g. #4 means fancy (a verb), but its characters do not occur individually. Possible ways of deriving new words from</context>
</contexts>
<marker>Leung, 1999</marker>
<rawString>Leung, R., &amp;quot;Lexical Access for Large Vocabulary Chinese Speech Recognition,&amp;quot; M. Phil. Thesis, The Chinese University of Hong Kong, Hong Kong SAR, China 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Levow</author>
<author>D W Oard</author>
</authors>
<title>Translingual Topic Tracking with PRISE,&amp;quot;</title>
<date>2000</date>
<booktitle>Working notes of the DARPA TDT-3 Workshop,</booktitle>
<contexts>
<context position="13341" citStr="Levow and Oard, 2000" startWordPosition="1964" endWordPosition="1967">ation as we discuss in the next section, accurate translation generally relies on the additional information available at the word and phrase levels. Since the &amp;quot;bag of words&amp;quot; information retrieval techniques do not incorporate any meaningful degree of language understanding to assess similarity between queries and documents, a word-for-word (or, more generally, term-for-term) embedded translation approach can achieve a useful level of effectiveness for many translingual retrieval applications [Oard and Diekema, 1998]. We have developed such a technique for the TDT-3 topic tracking evaluation [Levow and Oard, 2000]. For that work we extracted an enriched bilingual Mandarin-English term list by combining two term lists: (i) A list assembled by the Linguistic Data Consortium from freely available on-line resources; and (ii) entries from the CETA file (sometimes referred to as &amp;quot;Optilex&amp;quot;). This is a Chinese to English translation resource that was manually compiled by a team of linguists from more than 250 text sources, including special and general-purpose print dictionaries, and other text sources such as newspapers. The CETA file contains over 250,000 entries, but for our lexical work we extracted a sub</context>
<context position="16485" citStr="Levow and Oard, 2000" startWordPosition="2426" endWordPosition="2429">ative translations using either a statistical translation model trained on parallel or comparable corpora to estimate translation probability conditioned on the source language term. When such resources are not sufficiently informative, it is generally possible to back off to an unconditioned preference statistic based on usage frequency of each possible translation in a representative monolingual corpus in the target language. In retrospective retrieval applications the collection being searched can be used for this purpose. We have applied simple versions of this approach with good results [Levow and Oard, 2000]. We have recently observed that a simpler technique introduced by [Pirkola, 1998] can produce excellent results. The key idea is to use the structure of the lexicon, in which several target language terms can represent a single source language term, to induce structure in the translated query that the retrieval system can automatically exploit. In essence, the translated query becomes a bag of bags of terms, where each smaller bag corresponds to the set of possible translations for one source-language term. We plan to implement this structured query translation approach using the Inquery [Ca</context>
<context position="20659" citStr="Levow and Oard, 2000" startWordPosition="3039" endWordPosition="3042">llable lattices were used in [Wang, 1999] and [Chien et al., 20001 for monolingual Chinese retrieval experiments. The lattices were pruned to constrain the search space, but were able to achieve robust retrieval based on imperfect recognized transcripts. (ii) Query expansion, in which syllable transcription were expanded to include possibly confusable syllable sequences based on a syllable confusion matrix derived from recognition errors, was used in [Meng et al., 19991. (iii) We have expanded the document representation using terms extracted from similar documents in a comparable collection [Levow and Oard, 2000], and similar techniques are known to work well in the case of query translation (Ballesteros and Croft, 1997). We hope to add to this set of techniques by exploring the potential for query expansion based on cross-language phonetic mapping. 6. Using the TDT-3 Collection We plan to use the TDT-2 collection for development testing and the TDT-3 collection for evaluation. Both collections provide documents from two English newswire sources, six English broadcast news audio sources, two Mandarin Chinese newswire sources, and one Mandarin broadcast news source (Voice of America). Manually establi</context>
</contexts>
<marker>Levow, Oard, 2000</marker>
<rawString>Levow, G. and D.W. Oard, &amp;quot;Translingual Topic Tracking with PRISE,&amp;quot; Working notes of the DARPA TDT-3 Workshop, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C H Lin</author>
<author>L S Lee</author>
<author>P Y Ting</author>
</authors>
<title>A New Framework for Recognition of Mandarin Syllables with Tones using Sub-Syllabic Units,&amp;quot;</title>
<date>1993</date>
<booktitle>Proceedings of ICASSP,</booktitle>
<marker>Lin, Lee, Ting, 1993</marker>
<rawString>Lin, C. H., L. S. Lee, and P. Y. Ting, &amp;quot;A New Framework for Recognition of Mandarin Syllables with Tones using Sub-Syllabic Units,&amp;quot; Proceedings of ICASSP, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F H Liu</author>
<author>M Picheny</author>
<author>P Srinivasa</author>
<author>M Monkowski</author>
<author>J Chen</author>
</authors>
<title>Speech Recognition on Mandarin Call Home: A Large-Vocabulary, Conversational, and Telephone Speech Corpus,&amp;quot;</title>
<date>1996</date>
<booktitle>Proceedings of ICASSP,</booktitle>
<marker>Liu, Picheny, Srinivasa, Monkowski, Chen, 1996</marker>
<rawString>Liu, F. H., M. Picheny, P. Srinivasa, M. Monkowski and J. Chen, &amp;quot;Speech Recognition on Mandarin Call Home: A Large-Vocabulary, Conversational, and Telephone Speech Corpus,&amp;quot; Proceedings of ICASSP, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S McCarley</author>
</authors>
<title>Should we Translate the Documents or the Queries in Cross-Language Information Retrieval,&amp;quot;</title>
<date>1999</date>
<booktitle>Proceedings of ACL,</booktitle>
<contexts>
<context position="12413" citStr="McCarley, 1999" startWordPosition="1834" endWordPosition="1835">nized words may be helpful. We thus plan to explore the potential for integrated sequential modelling of both words and syllables [Meng et al., 2000]. 4. Multiscale Embedded Translation Figures 1 and 2 illustrate two translingual retrieval strategies. In query translation, English text queries are transformed into Mandarin and then used to retrieve Mandarin documents. For document translation, Mandarin documents are translated into English before they are indexed and then matched with English queries. McCarley has reported improved effectiveness from techniques that couple the two techniques [McCarley, 1999], but time constraints may limit us to exploring only the query translation strategy during the six-week Workshop. 4.1 Word Translation While we make use of sub-word transcription to smooth out-of-vocabulary(00V) problems in speech recognition as described above, and to alleviate the 00V problem for translation as we discuss in the next section, accurate translation generally relies on the additional information available at the word and phrase levels. Since the &amp;quot;bag of words&amp;quot; information retrieval techniques do not incorporate any meaningful degree of language understanding to assess similar</context>
</contexts>
<marker>McCarley, 1999</marker>
<rawString>McCarley, S., &amp;quot;Should we Translate the Documents or the Queries in Cross-Language Information Retrieval,&amp;quot; Proceedings of ACL, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Meng</author>
<author>C W Ip</author>
</authors>
<title>An Analytical Study of &amp;quot; Transformational Tagging of Chinese Text,&amp;quot;</title>
<date>1999</date>
<booktitle>Proceedings of the Research On Computational Lingustics (ROCLING) Conference,</booktitle>
<contexts>
<context position="9077" citStr="Meng and Ip, 1999" startWordPosition="1346" endWordPosition="1349">t takes place frequently...) The above considerations lead to a number of techniques we plan to use for our task. We concentrate on three equally critical problems related to our theme of translingual speech retrieval: (i) indexing Mandarin Chinese audio with word and subword units, (ii) translating variable-size units for cross-language information retrieval, and (iii) devising effective retrieval strategies for English text queries and Mandarin Chinese news audio. 3. Multiscale Audio Indexing A popular approach to spoken document retrieval is to apply Large-Vocabulary 8 Examples drawn from [Meng and Ip, 1999]. Continuous Speech Recognition (LVCSR)9 for audio indexing, followed by text retrieval techniques. Mandarin Chinese presents a challenge for word-level indexing by LVCSR, because of the ambiguity in tokenizing a sentence into words (as mentioned earlier). Furthermore, LVCSR with a static vocabulary is hampered by the out-of-vocabulary (00V) problem, especially when searching sources with topical coverage as diverse as that found in broadcast news. By virtue of the monosyllabic nature of the Chinese language and its dialects, the syllable inventory can provide a complete phonological coverage</context>
</contexts>
<marker>Meng, Ip, 1999</marker>
<rawString>Meng, H. and C. W. Ip, &amp;quot;An Analytical Study of &amp;quot; Transformational Tagging of Chinese Text,&amp;quot; Proceedings of the Research On Computational Lingustics (ROCLING) Conference, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Meng</author>
<author>W K Lo</author>
<author>Y C Li</author>
<author>P C Ching</author>
</authors>
<title>A Study on the Use of Syllables for Chinese Spoken Document Retrieval,&amp;quot;</title>
<date>1999</date>
<tech>Technical Report SEEM1999-11,</tech>
<institution>The Chinese University of Hong Kong,</institution>
<contexts>
<context position="10855" citStr="Meng et al., 1999" startWordPosition="1614" endWordPosition="1617">odeling sequential constraints among subword units. We plan to investigate the efficacy of using both word and subword units for Mandarin audio indexing [Meng et al., 2000]. Although Ng found that such an approach produced little gain over words alone for English, the structure of Mandarin Chinese may produce more useful subword features. 3.1 Modeling Syllable Sequence Constraints We have thus far used overlapping syllable Ngrams for spoken &apos;document retrieval for two Chinese dialects – Mandarin and Cantonese. Results on a known-item retrieval task with over 1,800 error-free news transcripts [Meng et al., 1999] indicate that constraints from overlapping bigrams can yield significant improvements in retrieval performance over syllable unigrams, producing retrieval performance competitive 9 The lexicon size of a typical large-vocabulary continuous speech recognizer can range from 10,000 to 100,000 word forms. 25 with that obtained using automatically tokenized Chinese words. The study in [Chen, Wang and Lee, 2000] also used syllable pairs with skipped syllables in between. This is because many Chinese abbreviations are derived from skipping characters, e.g. Ei National Science Council&amp;quot; can be abbrevi</context>
<context position="20512" citStr="Meng et al., 1999" startWordPosition="3018" endWordPosition="3021">when translating queries and/or documents. To achieve robustness for retrieval, we have tried three techniques that we have found useful: (i) Syllable lattices were used in [Wang, 1999] and [Chien et al., 20001 for monolingual Chinese retrieval experiments. The lattices were pruned to constrain the search space, but were able to achieve robust retrieval based on imperfect recognized transcripts. (ii) Query expansion, in which syllable transcription were expanded to include possibly confusable syllable sequences based on a syllable confusion matrix derived from recognition errors, was used in [Meng et al., 19991. (iii) We have expanded the document representation using terms extracted from similar documents in a comparable collection [Levow and Oard, 2000], and similar techniques are known to work well in the case of query translation (Ballesteros and Croft, 1997). We hope to add to this set of techniques by exploring the potential for query expansion based on cross-language phonetic mapping. 6. Using the TDT-3 Collection We plan to use the TDT-2 collection for development testing and the TDT-3 collection for evaluation. Both collections provide documents from two English newswire sources, six Engli</context>
</contexts>
<marker>Meng, Lo, Li, Ching, 1999</marker>
<rawString>Meng, H., W. K. Lo, Y. C. Li and P. C. Ching, &amp;quot;A Study on the Use of Syllables for Chinese Spoken Document Retrieval,&amp;quot; Technical Report SEEM1999-11, The Chinese University of Hong Kong, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Meng</author>
<author>S Khudanpur</author>
<author>D W Oard</author>
<author>H M Wang</author>
</authors>
<title>Mandarin-English Information (MEI),&amp;quot;</title>
<date>2000</date>
<booktitle>Working notes of the DARPA TDT-3 Workshop,</booktitle>
<contexts>
<context position="2222" citStr="Meng et al., 2000" startWordPosition="304" endWordPosition="307"> that direction. MEI is one of the four projects selected for the Johns Hopkins University (JHU) Summer Workshop 2000.1 Our research focus is on the integration of speech recognition and embedded translation technologies in the context of translingual speech retrieval. Possible applications of this work include audio and video browsing, spoken document retrieval, automated routing of information, and automatically alerting the user when special events occur. At the time of this writing, most of the MEI team members have been identified. This paper provides an update beyond our first proposal [Meng et al., 20001. We present some ongoing work of our current team members, as well as our ideas on an evolving plan for the upcoming JHU Summer Workshop 2000. We believe the input from the research community will benefit us greatly in formulating our final plan. 2. Background 2.1 Translingual Information Retrieval The earliest work on large-vocabulary crosslanguage information retrieval from free-text (i.e., without manual topic indexing) was reported in 1990 [Landauer and Littman, 1990], and the topic has received increasing attention over the last five years [Oard and Diekema, 1998]. Work on large-vocabul</context>
<context position="10409" citStr="Meng et al., 2000" startWordPosition="1546" endWordPosition="1549">call in subsequent retrieval. The approach thus supports searches for previously unknown query terms in the indexed audio. The pros and cons of subword indexing for an English spoken document retrieval task was studied in [Ng, 2000]. Ng pointed out that the &amp;quot; exclusion of lexical knowledge when subword indexing is performed in isolation may adversely impact discrimination power for retrieval, but that some of that impact can be mitigated by modeling sequential constraints among subword units. We plan to investigate the efficacy of using both word and subword units for Mandarin audio indexing [Meng et al., 2000]. Although Ng found that such an approach produced little gain over words alone for English, the structure of Mandarin Chinese may produce more useful subword features. 3.1 Modeling Syllable Sequence Constraints We have thus far used overlapping syllable Ngrams for spoken &apos;document retrieval for two Chinese dialects – Mandarin and Cantonese. Results on a known-item retrieval task with over 1,800 error-free news transcripts [Meng et al., 1999] indicate that constraints from overlapping bigrams can yield significant improvements in retrieval performance over syllable unigrams, producing retriev</context>
<context position="11947" citStr="Meng et al., 2000" startWordPosition="1769" endWordPosition="1772"> is because many Chinese abbreviations are derived from skipping characters, e.g. Ei National Science Council&amp;quot; can be abbreviated as (including only the first, third and the last characters). Moreover, synonyms often differ by one or two characters, e.g. both 1.45t4t, and t.E.5t.ft mean &amp;quot;Chinese culture&amp;quot;. Inclusion of these &amp;quot;skipped syllable pairs&amp;quot; also contributed to retrieval performance. When modeling sequential syllable constraints, lexical constraints on recognized words may be helpful. We thus plan to explore the potential for integrated sequential modelling of both words and syllables [Meng et al., 2000]. 4. Multiscale Embedded Translation Figures 1 and 2 illustrate two translingual retrieval strategies. In query translation, English text queries are transformed into Mandarin and then used to retrieve Mandarin documents. For document translation, Mandarin documents are translated into English before they are indexed and then matched with English queries. McCarley has reported improved effectiveness from techniques that couple the two techniques [McCarley, 1999], but time constraints may limit us to exploring only the query translation strategy during the six-week Workshop. 4.1 Word Translati</context>
</contexts>
<marker>Meng, Khudanpur, Oard, Wang, 2000</marker>
<rawString>Meng, H., Khudanpur, S., Oard, D. W. and Wang, H. M., &amp;quot;Mandarin-English Information (MEI),&amp;quot; Working notes of the DARPA TDT-3 Workshop, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Ng</author>
</authors>
<title>Subword-based Approaches for Spoken Document Retrieval,&amp;quot;</title>
<date>2000</date>
<tech>Ph.D. Thesis, MIT,</tech>
<publisher></publisher>
<contexts>
<context position="10023" citStr="Ng, 2000" startWordPosition="1487" endWordPosition="1488"> (00V) problem, especially when searching sources with topical coverage as diverse as that found in broadcast news. By virtue of the monosyllabic nature of the Chinese language and its dialects, the syllable inventory can provide a complete phonological coverage for spoken documents, and circumvent the 00V problem in news audio indexing, offering the potential for greater recall in subsequent retrieval. The approach thus supports searches for previously unknown query terms in the indexed audio. The pros and cons of subword indexing for an English spoken document retrieval task was studied in [Ng, 2000]. Ng pointed out that the &amp;quot; exclusion of lexical knowledge when subword indexing is performed in isolation may adversely impact discrimination power for retrieval, but that some of that impact can be mitigated by modeling sequential constraints among subword units. We plan to investigate the efficacy of using both word and subword units for Mandarin audio indexing [Meng et al., 2000]. Although Ng found that such an approach produced little gain over words alone for English, the structure of Mandarin Chinese may produce more useful subword features. 3.1 Modeling Syllable Sequence Constraints W</context>
</contexts>
<marker>Ng, 2000</marker>
<rawString>Ng, K., &amp;quot;Subword-based Approaches for Spoken Document Retrieval,&amp;quot; Ph.D. Thesis, MIT, February 2000. -</rawString>
</citation>
<citation valid="true">
<authors>
<author>D W Oard</author>
<author>A R Diekema</author>
</authors>
<title>CrossLanguage Information Retrieval,&amp;quot;</title>
<date>1998</date>
<journal>Annual Review of Information Science and Technology,</journal>
<volume>33</volume>
<contexts>
<context position="2798" citStr="Oard and Diekema, 1998" startWordPosition="393" endWordPosition="396">e beyond our first proposal [Meng et al., 20001. We present some ongoing work of our current team members, as well as our ideas on an evolving plan for the upcoming JHU Summer Workshop 2000. We believe the input from the research community will benefit us greatly in formulating our final plan. 2. Background 2.1 Translingual Information Retrieval The earliest work on large-vocabulary crosslanguage information retrieval from free-text (i.e., without manual topic indexing) was reported in 1990 [Landauer and Littman, 1990], and the topic has received increasing attention over the last five years [Oard and Diekema, 1998]. Work on large-vocabulary retrieval from recorded speech is more recent, with some initial work reported in 1995 using subword indexing [Wechsler and Schauble, 1995], followed by the first TREC2 Spoken Document Retrieval (SDR) &apos;http://www.c1sp.jhu.edu/ws2000/ 2 Text REtrieval Conference, http://trec.nist.gov 23 evaluation [Garofolo et al., 2000]. The Topic Detection and Tracking (TDT) evaluations, which started in 1998, fall within our defmition of speech retrieval for this purpose, differing from other evaluations principally in the nature of the criteria that human assessors use when asses</context>
<context position="13242" citStr="Oard and Diekema, 1998" startWordPosition="1948" endWordPosition="1951">y(00V) problems in speech recognition as described above, and to alleviate the 00V problem for translation as we discuss in the next section, accurate translation generally relies on the additional information available at the word and phrase levels. Since the &amp;quot;bag of words&amp;quot; information retrieval techniques do not incorporate any meaningful degree of language understanding to assess similarity between queries and documents, a word-for-word (or, more generally, term-for-term) embedded translation approach can achieve a useful level of effectiveness for many translingual retrieval applications [Oard and Diekema, 1998]. We have developed such a technique for the TDT-3 topic tracking evaluation [Levow and Oard, 2000]. For that work we extracted an enriched bilingual Mandarin-English term list by combining two term lists: (i) A list assembled by the Linguistic Data Consortium from freely available on-line resources; and (ii) entries from the CETA file (sometimes referred to as &amp;quot;Optilex&amp;quot;). This is a Chinese to English translation resource that was manually compiled by a team of linguists from more than 250 text sources, including special and general-purpose print dictionaries, and other text sources such as n</context>
</contexts>
<marker>Oard, Diekema, 1998</marker>
<rawString>Oard, D. W. and A.R. Diekema, &amp;quot;CrossLanguage Information Retrieval,&amp;quot; Annual Review of Information Science and Technology, vol.33, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Pirkola</author>
</authors>
<title>The effects of query structure and dictionary setups in dictionary-based crosslanguage information retrieval,&amp;quot;</title>
<date>1998</date>
<booktitle>Proceedings of ACM SIGIR,</booktitle>
<contexts>
<context position="16567" citStr="Pirkola, 1998" startWordPosition="2440" endWordPosition="2441">mparable corpora to estimate translation probability conditioned on the source language term. When such resources are not sufficiently informative, it is generally possible to back off to an unconditioned preference statistic based on usage frequency of each possible translation in a representative monolingual corpus in the target language. In retrospective retrieval applications the collection being searched can be used for this purpose. We have applied simple versions of this approach with good results [Levow and Oard, 2000]. We have recently observed that a simpler technique introduced by [Pirkola, 1998] can produce excellent results. The key idea is to use the structure of the lexicon, in which several target language terms can represent a single source language term, to induce structure in the translated query that the retrieval system can automatically exploit. In essence, the translated query becomes a bag of bags of terms, where each smaller bag corresponds to the set of possible translations for one source-language term. We plan to implement this structured query translation approach using the Inquery [Callan, 1992] &amp;quot;synonym&amp;quot; operator in the same manner as [Pirkola, 1998], and to the p</context>
</contexts>
<marker>Pirkola, 1998</marker>
<rawString>Pirkola, A., &amp;quot;The effects of query structure and dictionary setups in dictionary-based crosslanguage information retrieval,&amp;quot; Proceedings of ACM SIGIR, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Sheridan</author>
<author>J P Ballerini</author>
</authors>
<title>Experiments in Multilingual Information Retrieval using the SPIDER System,&amp;quot;</title>
<date>1996</date>
<journal>Proceedings of ACM</journal>
<marker>Sheridan, Ballerini, 1996</marker>
<rawString>Sheridan P. and J. P. Ballerini, &amp;quot;Experiments in Multilingual Information Retrieval using the SPIDER System,&amp;quot; Proceedings of ACM SIGIR, Wechsler, M. and P. Schatible, &amp;quot;Speech 1996. Retrieval Based on Automatic Indexing,&amp;quot;</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Voorhees</author>
</authors>
<title>Learning Collection Fusion</title>
<date>1995</date>
<booktitle>Proceedings of MIRO-1995. Strategies,&amp;quot; Proceedings of SIGIR,</booktitle>
<contexts>
<context position="19496" citStr="Voorhees, 1995" startWordPosition="2872" endWordPosition="2873">also accommodate phonological variations. Pronunciation dictionaries, or pronunciation generation tools for both English words and Chinese words / characters will be useful for the matching algorithm. We can probably leverage off of ideas in the development of universal speech recognizers [Cohen et al., 1997]. 5. Multiscale Retrieval 5.1 Coupling Words and Subwords We intend to use both words and subwords for retrieval. Loose coupling would involve separate retrieval runs using words and subwords, producing two ranked lists, followed by list merging using techniques such as those explored by [Voorhees, 1995]. Tight coupling, by 27 contrast, would require creation of a unified index containing both word and subword units, resulting in a single ranked list. We hope to explore both techniques during the Workshop. 5.2 Imperfect Indexing and Translation It should be noted that speech recognition exacerbates uncertainty when indexing audio, and that translation or transliteration exacerbates uncertainty when translating queries and/or documents. To achieve robustness for retrieval, we have tried three techniques that we have found useful: (i) Syllable lattices were used in [Wang, 1999] and [Chien et a</context>
</contexts>
<marker>Voorhees, 1995</marker>
<rawString>Voorhees, E., &amp;quot;Learning Collection Fusion Proceedings of MIRO-1995. Strategies,&amp;quot; Proceedings of SIGIR, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H M Wang</author>
</authors>
<title>Retrieval of Mandarin Spoken Documents Based on Syllable Lattice Matching,&amp;quot;</title>
<date>1999</date>
<booktitle>Proceedings of the Fourth International Workshop on Information Retrieval in Asian Languages,</booktitle>
<contexts>
<context position="20079" citStr="Wang, 1999" startWordPosition="2957" endWordPosition="2958">explored by [Voorhees, 1995]. Tight coupling, by 27 contrast, would require creation of a unified index containing both word and subword units, resulting in a single ranked list. We hope to explore both techniques during the Workshop. 5.2 Imperfect Indexing and Translation It should be noted that speech recognition exacerbates uncertainty when indexing audio, and that translation or transliteration exacerbates uncertainty when translating queries and/or documents. To achieve robustness for retrieval, we have tried three techniques that we have found useful: (i) Syllable lattices were used in [Wang, 1999] and [Chien et al., 20001 for monolingual Chinese retrieval experiments. The lattices were pruned to constrain the search space, but were able to achieve robust retrieval based on imperfect recognized transcripts. (ii) Query expansion, in which syllable transcription were expanded to include possibly confusable syllable sequences based on a syllable confusion matrix derived from recognition errors, was used in [Meng et al., 19991. (iii) We have expanded the document representation using terms extracted from similar documents in a comparable collection [Levow and Oard, 2000], and similar techn</context>
</contexts>
<marker>Wang, 1999</marker>
<rawString>Wang, H. M., &amp;quot;Retrieval of Mandarin Spoken Documents Based on Syllable Lattice Matching,&amp;quot; Proceedings of the Fourth International Workshop on Information Retrieval in Asian Languages, 1999.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>