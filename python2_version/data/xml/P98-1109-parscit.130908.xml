<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000665">
<title confidence="0.9985045">
Know When to Hold &apos;Em: Shuffling Deterministically in a Parser
for Nonconcatenative Grammars*
</title>
<author confidence="0.999553">
Robert T. Kasper, Mike Calcagno, and Paul C. Davis
</author>
<affiliation confidence="0.998205">
Department of Linguistics, Ohio State University
</affiliation>
<address confidence="0.818827666666667">
222 Oxley Hall
1712 Neil Avenue
Columbus, OH 43210 U.S.A.
</address>
<email confidence="0.929117">
Email: Ocasper,calcagno,pcdavis101ing.ohio-state.edu
</email>
<sectionHeader confidence="0.989472" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999902818181818">
Nonconcatenative constraints, such as the shuffle re-
lation, are frequently employed in grammatical anal-
yses of languages that have more flexible ordering of
constituents than English. We show how it is pos-
sible to avoid searching the large space of permuta-
tions that results from a nondeterministic applica-
tion of shuffle constraints. The results of our imple-
mentation demonstrate that deterministic applica-
tion of shuffle constraints yields a dramatic improve-
ment in the overall performance of a head-corner
parser for German using an HPSG-style grammar.
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996418932432433">
Although there has been a considerable amount of
research on parsing for constraint-based grammars
in the HPSG (Head-driven Phrase Structure Gram-
mar) framework, most computational implementa-
tions embody the limiting assumption that the con-
stituents of phrases are combined only by concate-
nation. The few parsing algorithms that have been
proposed to handle more flexible linearization con-
straints have not yet been applied to nontrivial
grammars using nonconcatenative constraints. For
example, van Noord (1991; 1994) suggests that the
head-corner parsing strategy should be particularly
well-suited for parsing with grammars that admit
discontinuous constituency, illustrated with what he
calls a &amp;quot;tiny&amp;quot; fragment of Dutch, but his more re-
cent development of the head-corner parser (van No-
ord, 1997) only documents its use with purely con-
catenative grammars. The conventional wisdom has
been that the large search space resulting from the
use of such constraints (e.g., the shuffle relation)
makes parsing too inefficient for most practical ap-
plications. On the other hand, grammatical anal-
yses of languages that have more flexible ordering
of constituents than English make frequent use of
constraints of this type. For example, in recent
work by Dowty (1996), Reape (1996), and Kathol
This research was sponsored in part by National Science
Foundation grant SBR-9410532, and in part by a seed grant
from the Ohio State University Office of Research; the opin-
ions expressed here are solely those of the authors.
(1995), in which linear order constraints are taken
to apply to domains distinct from the local trees
formed by syntactic combination, the nonconcate-
native shuffle relation is the basic operation by
which these word order domains are formed. Reape
and Kathol apply this approach to various flexible
word-order constructions in German.
A small sampling of other nonconcatenative op-
erations that have often been employed in linguistic
descriptions includes Bach&apos;s (1979) wrapping oper-
ations, Pollard&apos;s (1984) head-wrapping operations,
and Moortgat&apos;s (1996) extraction and infixation op-
erations in (categorial) type-logical grammar.
What is common to the proposals of Dowty,
Reape, and Kathol, and to the particular analysis
implemented here, is the characterization of nat-
ural language syntax in terms of two interrelated
but in principle distinct sets of constraints: (a) con-
straints on an unordered hierarchical structure, pro-
jected from (grammatical-relational or semantic) va-
lence properties of lexical items; and (b) constraints
on the linear order in which elements appear. In
this type of framework, constraints on linear order
may place conditions on the the relative order of
constituents that are not siblings in the hierarchical
structure. To this end, we follow Reape and Kathol
and utilize order domains, which are associated with
each node of the hierarchical structure, and serve
as the domain of application for linearization con-
straints.
In this paper, we show how it is possible to avoid
searching the large space of permutations that re-
sults from a nondeterministic application of shuffle
constraints. By delaying the application of shuffle
constraints until the linear position of each element
is known, and by using an efficient encoding of the
portions of the input covered by each element of an
order domain, shuffle constraints can be applied de-
terministically. The results of our implementation
demonstrate that this optimization of shuffle con-
straints yields a dramatic improvement in the overall
performance of a head-corner parser for German.
The remainder of the paper is organized as fol-
lows: §2 introduces the nonconcatenative fragment
</bodyText>
<page confidence="0.998342">
663
</page>
<bodyText confidence="0.971301666666667">
Seiner Freundin less er ihn helfen
his(DAT) friend(FEm) allows he(Nom) him(Aoo) help
&apos;He allows him to help his friend.&apos;
Hilft sie ihr schnell
help she(Nom) her(DAT) quickly
&apos;Does she help her quickly?&apos;
</bodyText>
<figure confidence="0.948419583333333">
Der Vater denkt dass sic ihr seinen Sohn helfen less
The(Nom) father thinks that she(Nom) her(DAT) his(Aoo) son help allows
&apos;The father thinks that she allows his son to help her.&apos;
(4)
dom_obj
PHON ihn
SYNSEM NP &apos;
r_decl
dom_obj
, PHON seiner
(
DOM
SYNSEM NP
TOPO vf
dom_obj dom_obj
1
Freundin PHON liess PHON er
&apos; SYNSEM V &apos; SYNSEM NP &apos;
TOPO Cf 1 TOPO Trif J L&apos;roPomf
[dom_obj
PHON helfen )
SYNSEM V
TOPO vc
(5) TOPO [TOPO cf] [TOPO mf] [TOPO VC] [TOPO nf]
</figure>
<figureCaption confidence="0.996946">
Figure 1: Linear order of German clauses.
</figureCaption>
<figure confidence="0.980983">
S [DOM([seiner Freundin],[liess] ,[erMihn],[helfen])]
VP [DOM([seiner Freundin],[hess],[ihn],[helfen])] NP
VP [DOM([seiner Freundin],[liess],[helfen])i NP er
V [Dom ([iess],[helfen])] NP [DOM(Eseinerb[Freundin])] ihn
V V Det
less helfen Freundin seiner
</figure>
<figureCaption confidence="0.999534">
Figure 2: Hierarchical structure of sentence (1).
</figureCaption>
<bodyText confidence="0.999938166666667">
of German which forms the basis of our study; §3
describes the head-corner parsing algorithm that we
use in our implementation; §4 discusses details of the
implementation, and the optimization of the shuffle
constraint is explained in §5; §6 compares the perfor-
mance of the optimized and non-optimized parsers.
</bodyText>
<sectionHeader confidence="0.986598" genericHeader="method">
2 A German Grammar Fragment
</sectionHeader>
<bodyText confidence="0.9997345">
The fragment is based on the analysis of German
in Kathol&apos;s (1995) dissertation. Kathol&apos;s approach
is a variant of HPSG, which merges insights from
both Reape&apos;s work and from descriptive accounts of
German syntax using topological fields (linear posi-
tion classes). The fragment covers (1) root declara-
tive (verb-second) sentences, (2) polar interrogative
(verb-first) clauses and (3) embedded subordinate
(verb-final) clauses, as exemplified in Figure 1.
The linear order of constituents in a clause is rep-
resented by an order domain (Dom), which is a list
of domain objects, whose relative order must satisfy
a set of linear precedence (LP) constraints. The or-
der domain for example (1) is shown in (4). Notice
that each domain object contains a TOPO attribute,
whose value specifies a topological field that par-
tially determines the object&apos;s linear position in the
list. Kathol defines five topological fields for German
clauses: Vorfeld (vi), Comp/Left Sentence Bracket
(cf), Mittelfeld (mf), Verb Cluster/Right Sentence
Bracket (vc), and Nachfeld (nf). These fields are or-
dered according to the LP constraints shown in (5).
The hierarchical structure of a sentence, on the
other hand, is constrained by a set of immediate
dominance (ID) schemata, three of which are in-
cluded in our fragment: Head-Argument (where &amp;quot;Ar-
gument&amp;quot; subsumes complements, subjects, and spec-
ifiers), Adjunct-Head, and Marker-Head. The Head-
</bodyText>
<page confidence="0.993093">
664
</page>
<bodyText confidence="0.999972">
Argument schema is shown below, along with the
constraints on the order domain of the mother con-
stituent. In all three schemata, the domain of a non-
head daughter is compacted into a single domain ob-
ject, which is shuffled together with the domain of
the head daughter to form the domain of the mother.
</bodyText>
<listItem confidence="0.895478">
(6) Head-Argument Schema (simplified)
</listItem>
<equation confidence="0.6080715">
SYNSEM [ HEAD
SUBCAT
</equation>
<bodyText confidence="0.99984955">
The hierarchical structure of (1) is shown by the
unordered tree of Figure 2, where head daughters
appear on the left at each branch. Focusing on
the NP seiner Freundin in the tree, it is compacted
into a single domain object, and must remain so,
but its position is not fixed relative to the other
arguments of less (which include the raised argu-
ments of helfen). The shuffle constraint allows this
single, compacted domain object to be realized in
various permutations with respect to the other ar-
guments, subject to the LP constraints, which are
implemented by the order_constraints predicate
in (6). Each NP argument may be assigned either
vf or mf as its TOPO value, subject to the constraint
that root declarative clauses must contain exactly
one element in the vf field. In this case, seiner Fre-
undin is assigned vf, while the other NP arguments
of less are in mf. However, the following permuta-
tions of (1) are also grammatical, in which er and
ihn are assigned to the vf field instead:
</bodyText>
<listItem confidence="0.989811">
(7) a. Er less ihn seiner Freundin helfen.
b. Ihn less er seiner Freundin helfen.
</listItem>
<bodyText confidence="0.9996058">
Comparing the hierarchical structure in Figure 2
with the linear order domain in (4), we see that some
daughters in the hierarchical structure are realized
discontinuously in the order domain for the clause
(e.g., the verbal complex less he/len). In such cases,
nonconcatenative constraints, such as shuffle, can
provide a more succinct analysis than concatenative
rules. This situation is quite common in languages
like German and Japanese, where word order is not
totally fixed by grammatical relations.
</bodyText>
<sectionHeader confidence="0.998281" genericHeader="method">
3 Head-Corner Parsing
</sectionHeader>
<bodyText confidence="0.999991358974359">
The grammar described above has a number of
properties relevant to the choice of a parsing strat-
egy. First, as in HPSG and other constraint-based
grammars, the lexicon is information-rich, and the
combinatory or phrase structure rules are highly
schematic. We would thus expect a purely top-
down algorithm to be inefficient for a grammar of
this type, and it may even fail to terminate, for the
simple reason that the search space would not be
adequately constrained by the highly general combi-
natory rules.
Second, the grammar is essentially nonconcatena-
tive, i.e., constituents of the grammar may appear
discontinuously in the string. This suggests that a
strict left-to-right or right-to-left approach may be
less efficient than a bidirectional or non-directional
approach.
Lastly, the grammar is head-driven, and we would
thus expect the most appropriate parsing algorithm
to take advantage of the information that a semantic
head provides. For example, a head usually provides
information about the remaining daughters that the
parser must find, and (since the head daughter in a
construction is in many ways similar to its mother
category) effective top-down identification of candi-
date heads should be possible.
One type of parser that we believe to be partic-
ularly well-suited to this type of grammar is the
head-corner parser, introduced by van Noord (1991;
1994) based on one of the parsing strategies ex-
plored by Kay (1989). The head-corner parser can
be thought of as a generalization of a left-corner
parser (Rosenkrantz and Lewis-II, 1970; Matsumoto
et al., 1983; Pereira and Shieber, 1987).1
The outstanding features of parsers of this type
are that they are head-driven, of course, and that
they process the string bidirectionally, starting from
a lexical head and working outward. The key ingre-
dients of the parsing algorithm are as follows:
</bodyText>
<listItem confidence="0.922345909090909">
• Each grammar rule contains a distinguished
daughter which is identified as the head of the
rule.&apos;
• The relation head-corner is defined as the reflexive
and transitive closure of the head relation.
• In order to prove that an input string can be
parsed as some (potentially complex) goal cat-
egory, the parser nondeterministically selects a
potential head of the string and proves that this
head is the head-corner of the goal.
• Parsing proceeds from the head, with a rule being
</listItem>
<bodyText confidence="0.543926">
chosen whose head daughter can be instantiated
by the selected head word. The other daughters
of the rule are parsed recursively in a bidirec-
tional fashion, with the result being a slightly
larger head-corner.
</bodyText>
<footnote confidence="0.902036">
&apos;In fact, a head-corner parser for a grammar in which the
head daughter in each rule is the leftmost daughter will func-
tion as a left-corner parser.
2Note that the fragment of the previous section has this
property.
</footnote>
<figure confidence="0.998260818181818">
DOM
SYNSEM
HEAD-DTR [ HEAD
SUBCAT
DOM
[SYNSEM
, compaction(fl), 11)
A order_constraints(13)
ARG-DTR
A shuffle(
El
</figure>
<page confidence="0.950183">
665
</page>
<listItem confidence="0.822754333333333">
• The process succeeds when a head-corner is
constructed which dominates the entire input
string.
</listItem>
<sectionHeader confidence="0.995548" genericHeader="method">
4 Implementation
</sectionHeader>
<bodyText confidence="0.999988526315789">
We have implemented the German grammar and
head-corner parsing algorithm described in §2 and
§3 using the ConTroll formalism (Gotz and Meurers,
1997). ConTroll is a constraint logic programming
system for typed feature structures, which supports
a direct implementation of HPSG. Several properties
of the formalism are crucial for the approach to lin-
earization that we are investigating: it does not re-
quire the grammar to have a context-free backbone;
it includes definite relations, enabling the definition
of nonconcatenative constraints, such as shuffle;
and it supports delayed evaluation of constraints.
The ability to control when relational contraints are
evaluated is especially important in the optimiza-
tion of shuffle to be discussed next (§5). ConTroll
also allows a parsing strategy to be specified within
the same formalism as the grammar.3 Our imple-
mentation of the head-corner parser adapts van No-
ord&apos;s (1997) parser to the ConTroll environment.
</bodyText>
<sectionHeader confidence="0.970444" genericHeader="method">
5 Shuffling Deterministically
</sectionHeader>
<bodyText confidence="0.980904263157895">
A standard definition of the shuffle relation is given
below as a Prolog predicate.
7. shuffle (unoptimized version)
shuffle( [J , [] ,
shuffle( [XIS1] , S2, [XIS3]) :—
shuffle(S1,S2,S3).
shuffle(S1, [XIS2] [XIS3]) :—
shuffle(S1,S2,S3).
The use of a shuffle constraint reflects the fact
that several permutations of constituents may be
grammatical. If we parse in a bottom-up fashion,
and the order domains of two daughter constituents
are combined as the first two arguments of shuffle,
multiple solutions will be possible for the mother
domain (the third argument of shuffle). For ex-
ample, in the structure shown earlier in Figure 2,
when the domain ([1iess],[helfen]) is combined with
the compacted domain element ([seiner Freundin]),
shuffle will produce three solutions:
</bodyText>
<figure confidence="0.70535">
(8) a. Wiess],[helfen],[seiner Freundin])
b. Wiess],[seiner Freundin],[helfen])
c. ([seiner Freundin],[liess],[helfen])
</figure>
<bodyText confidence="0.975220596153846">
This set of possible solutions is further constrained
in two ways: it must be consistent with the linear
3An interface from Con&apos;froll to the underlying Prolog en-
vironment was also developed to support some optimizations
of the parser, such as memoization and the operations over
bitstrings described in §5.
precedence constraints defined by the grammar, and
it must yield a sequence of words that is identical
to the input sequence that was given to the parser.
However, as it stands, the correspondence with the
input sequence is only checked after an order do-
main is proposed for the entire sentence. The or-
der domains of intermediate phrases in the hierar-
chical structure are not directly constrained by the
grammar, since they may involve discontinuous sub-
sequences of the input sentence. The shuffle con-
straint is acting as a generator of possible order do-
mains, which are then filtered first by LP constraints
and ultimately by the order of the words in the in-
put sentence. Although each possible order domain
that satisfies the LP constraints is a grammatical se-
quence, it is useless, in the context of parsing, to con-
sider those permutations whose order diverges from
that of the input sentence. In order to avoid this
very inefficient generate-and-test behavior, we need
to provide a way for the input positions covered by
each proposed constituent to be considered sooner,
so that the only solutions produced by the shuffle
constraint will be those that correspond to the or-
der of words in the actual input sequence.
Since the portion of the input string covered by
an order domain may be discontinuous, we cannot
just use a pair of endpoints for each constituent as
in chart parsers or DCGs. Instead, we adapt a tech-
nique described by Reape (1991), and use bitstring
codes to represent the portions of the input covered
by each element in an order domain. If the input
string contains n words, the code value for each con-
stituent will be a bitstring of length n. If element
i of the bitstring is 1, the constituent contains the
ith word of the sentence, and if element i of the
bitstring is 0, the constituent does not contain the
ith word. Reape uses bitstring codes for a tabular
parsing algorithm, different from the head-corner al-
gorithm used here, and attributes the original idea
to Johnson (1985).
The optimized version of the shuffle relation is de-
fined below, using a notation in which the arguments
are descriptions of typed feature structures. The ac-
tual implementation of relations in the ConTroll for-
malism uses a slightly different notation, but we use
a more familiar Prolog-style notation here.4
</bodyText>
<footnote confidence="0.948629">
4Symbols beginning with an upper-case letter are vari-
ables, while lower-case symbols are either attribute labels
(when followed by `:&apos;) or the types of values (e.g., ne_list).
</footnote>
<page confidence="0.997848">
666
</page>
<bodyText confidence="0.916026456140351">
% shuffle (optimized version)
shuffle([], 07.
shuffle((S1&amp;ne_list), Si).
shuffle([], (S2&amp;ne_list), S2).
shuffle(S1, S2, S3) :-
S1=[(code:C1)1_] , S2=[(code:C2)1_] ,
code_prec(C1,C2,Bool),
shuffle_d(Bool,S1,S2,S3).
% shuffle_d(Bool, [H11T1], [H21T2], List).
% Bool=true: H1 precedes H2
% Bool=false: H1 does not precede H2
shuffle_d(true, [H11S1], S2, [H11S3]) :-
may_precede_all(H1,S2),
shuffle(S1,S2,S3).
shuffle_d(false, Si, [H21S2], [H2 1 S3] ) : -
may_precede_all(H2,S1),
shuffle(S1,S2,S3).
This revision of the shuffle relation uses two
auxiliary relations, c ode _pre c and shuf f 1 e _d..
code_prec compares two bitstrings, and yields a
boolean value indicating whether the first string pre-
cedes the second (the details of the implementation
are suppressed). The result of a comparison be-
tween the codes of the first element of each domain is
used to determine which element must appear first
in the resulting domain. This is implemented by
using the boolean result of the code comparison to
select a unique disjunct of the shuffle_d relation.
The shuffle_d relation also incorporates an opti-
mization in the checking of LP constraints. As each
element is shuffled into the result, it only needs to be
checked for LP acceptability with the elements of the
other argument list, because the LP constraints have
already been satisfied on each of the argument do-
mains. Therefore, LP acceptability no longer needs
to be checked for the entire order domain of each
phrase, and the call to order_constraints can be
eliminated from each of the phrasal schemata.
In order to achieve the desired effect of making
shuffle constraints deterministic, we must delay their
evaluation until the code attributes of the first ele-
ment of each argument domain have been instanti-
ated to a specific string. Using the analogy of a card
game, we must hold the cards (delay shuffling) until
we know what their values are (the codes must be
instantiated). The delayed evaluation is enforced by
the following declarations in the ConTroll system,
where argn : @type specifies that evaluation should
be delayed until the value of the nth argument of
the relation has a value more specific than type:
delay(code_prec,
(arglAstring &amp; arg2:Ostring)).
delay(shuffle_d, argl:Obool).
With the addition of CODE values to each domain
element, the input to the shuffle constraint in our
previous example is shown below, and the unique
solution for MDom is the one corresponding to (8c).
</bodyText>
<equation confidence="0.881554166666667">
(9) shuffle(( PHON hess [PHON helfen
),
CODE 001000 &apos; CODE 000001
( PHON seiner Pre
CODE 110000 undin
), MDom)
</equation>
<sectionHeader confidence="0.970224" genericHeader="evaluation">
6 Performance Comparison
</sectionHeader>
<bodyText confidence="0.999945818181819">
In order to evaluate the reduction in the search space
that is achieved by shuffling deterministically, the
parser with the optimized shuffle constraints and
the parser with the nonoptimized constraints were
each tested with the same grammar of German on
a set of 30 sentences of varying length, complexity
and clause types. Apart from the redefinition of the
shuffle relation, discussed in the previous section,
the only differences between the grammars used for
the optimized and unoptimized tests are the addi-
tion of CODE values for each domain element in the
optimized version and the constraints necessary to
propagate these code values through the intermedi-
ate structures used by the parser.
A representative sample of the tested sentences
is given in Table 2 (because of space limitations,
English glosses are not given, but the words have
all been glossed in §2), and the performance results
for these 12 sentences are listed in Table 1. For
each version of the parser, time, choice points, and
calls are reported, as follows: The time measurement
(Time)5 is the amount of CPU seconds (on a Sun
SPARCstation 5) required to search for all possible
parses, choice points (ChoicePts) records the num-
ber of instances where more than one disjunct may
apply at the time when a constraint is resolved, and
calls (Calls) lists the number of times a constraint
is unfolded. The number of calls listed includes all
constraints evaluated by the parser, not only shuffle
constraints. Given the nature of the ConTroll imple-
mentation, the number of calls represents the most
basic number of steps performed by the parser at a
logical level. Therefore, the most revealing compar-
ison with regard to performance improvement be-
tween the optimized and nonoptimized versions is
the call factor, given in the last column of Table 1.
The call factor for each sentence is the number of
nonoptimized calls divided by the number of opti-
mized calls. For example, in Ti, Er haft ihr, the
version using the nonoptimized shuffle was required
to make 4.1 times as many calls as the version em-
ploying the optimized shuffle.
The deterministic shuffle had its most dramatic
impact on longer sentences and on sentences con-
</bodyText>
<footnote confidence="0.9960056">
5The absolute time values are not very significant, be-
cause the ConTroll system is currently implemented as an
interpreter running in Prolog. However, the relative time dif-
ferences between sentences confirm that the number of calls
roughly reflects the total work required by the parser.
</footnote>
<page confidence="0.982405">
667
</page>
<table confidence="0.9995475">
Sent. Parses Nonoptirnized Calls Optimized Calls Call
Time(sec) ChoicePts Time(sec) ChoicePts Factor
Ti 1 5.6 61 359 1.8 20 88 4.1
T2 1 10.0 80 480 3.6 29 131 3.7
T3 1 24.3 199 1362 4.9 44 200 6.8
T4 1 25.0 199 1377 5.2 45 211 6.5
T5 1 51.4 299 2757 6.2 49 241 11.4
T6 2 463.5 2308 22972 32.4 209 974 23.6
T7 2 465.1 2308 23080 26.6 172 815 28.3
T8 1 305.7 1301 9622 52.1 228 942 10.2
T9 1 270.5 1187 7201 48.0 214 1024 7.0
T10 1 2063.4 6916 44602 253.8 859 4176 10.7
T11 1 3368.9 8833 74703 176.5 536 2565 29.1
T12 1 8355.0 19235 129513 528.1 1182 4937 26.2
</table>
<tableCaption confidence="0.999885">
Table 1: Comparison of Results for Selected Sentences
</tableCaption>
<reference confidence="0.992654785714286">
Ti. Er hilft ihr.
T2. Hilft er seiner Freundin?
T3. Er hilft ihr schnell.
T4. Hilft er ihr schnell?
T5. Liess er ihr ihn helfen?
T6. Er less ihn ihr schnell helfen.
T7. Liess er ihn ihr schnell helfen?
T8. Der Vater less seiner Freundin seinen
Sohn helfen.
T9. Sie denkt dass er ihr hilft.
T10. Sie denkt dass er ihr schnell hilft.
T11. Sie denkt dass er ihr ihn helfen less.
T12. Sie denkt dass er seiner Freundin
seinen Sohn helfen less.
</reference>
<tableCaption confidence="0.918379">
Table 2: Selected Sentences
</tableCaption>
<bodyText confidence="0.999971647058824">
taming adjuncts. For instance, in T7, a verb-first
sentence containing the adjunct schnell, the opti-
mized version outperformed the nonoptimized by a
call factor of 28.3. From these results, the utility
of a deterministic shuffle constraint is clear. In par-
ticular, it should be noted that avoiding useless re-
sults for shuffle constraints prunes away many large
branches from the overall search space of the parser,
because shuffle constraints are imposed on each node
of the hierarchical structure. Since we use a largely
bottom-up strategy, this means that if there are n
solutions to a shuffle constraint on some daughter
node, then all of the constraints on its mother node
have to be solved n times. If we avoid producing
n - 1 useless solutions to shuffle, then we also avoid
n - 1 attempts to construct all of the ancestors to
this node in the hierarchical structure.
</bodyText>
<sectionHeader confidence="0.999467" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999975739130435">
We have shown that eliminating the nondetermin-
ism of shuffle constraints overcomes one of the pri-
mary inefficiencies of parsing for grammars that use
discontinuous order domains. Although bitstring
codes have been used before in parsers for discon-
tinuous constituents, we are not aware of any prior
research that has demonstrated the use of this tech-
nique to eliminate the nondeterminism of relational
constraints on word order. Additionally, we expect
that the applicability of bitstring codes is not limited
to shuffle contraints, and that the technique could
be straightforwardly generalized for other noncon-
catenative constraints. In fact, some way of record-
ing the input positions associated with each con-
stituent is necessary to eliminate spurious ambigui-
ties that arise when the input sentence contains more
than one occurrence of the same word (cf. van No-
ord&apos;s (1994) discussion of nonminimality). For con-
catenative grammars, each position can be repre-
sented by a simple remainder of the input list, but
a more general encoding, such as the bitstrings used
here, is needed for grammars using nonconcatenative
constraints.
</bodyText>
<sectionHeader confidence="0.999638" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9961591">
Emmon Bach. 1979. Control in montague grammar.
Linguistic Inquiry, 10:515-553.
David R. Dowty. 1996. Toward a minimalist the-
ory of syntactic structure. In Arthur Horck and
Wietske Sijtsma, editors, Discontinuous Con-
stituency, Berlin. Mouton de Gruyter.
Thilo Gratz and Walt Detmar Meurers. 1997.
The ConTroll system as large grammar develop-
ment platform. In Proceedings of the Workshop
on Computational Environments for Grammar
</reference>
<page confidence="0.978608">
668
</page>
<reference confidence="0.99382766">
Development and Linguistic Engineering (EN-
VGRAM) held at ACL-97, Madrid, Spain.
Mark Johnson. 1985. Parsing with discontinuous
constituents. In Proceedings of the 23rd Annual
Meeting of the Association for Computational
Linguistics, pages 127-132, Chicago, IL, July.
Andreas Kathol. 1995. Linearization-based German
Syntax. Ph.D. thesis, The Ohio State University.
Martin Kay. 1989. Head-driven parsing. In Proceed-
ings of the First International Workshop on Pars-
ing Technologies. Carnegie Mellon University.
Y. Matsumoto, H. Tanaka, H. Hirakawa, H. Miyoshi,
and H. Yasukawa. 1983. BUP: a bottom up parser
embedded in prolog. New Generation Computing,
1(2).
Michael Moortgat. 1996. Generalized quantifiers
and discontinuous type constructors. In Arthur
Horck and Wietske Sijtsma, editors, Discontinu-
ous Constituency, Berlin. Mouton de Gruyter.
Fernando C.N. Pereira and Stuart M. Shieber. 1987.
Prolog and Natural Language Analysis. CSLI Lec-
ture Notes Number 10, Stanford, CA.
Carl Pollard. 1984. Generalized Phrase Structure
Grammars, Head Grammars and Natural Lan-
guage. Ph.D. thesis, Stanford University.
Michael Reape. 1991. Parsing bounded discontin-
uous constituents: Generalizations of some com-
mon algorithms. In Proceedings of the First Com-
putational Linguistics in the Netherlands Day,
OTK, University of Utrecht.
Mike Reape. 1996. Getting things in order. In
Arthur Horck and Wietske Sijtsma, editors, Dis-
continuous Constituents. Mouton de Gruyter,
Berlin.
D.J. Rosenkrantz and P.M. Lewis-II. 1970. Deter-
ministic left corner parsing. In IEEE Conference
of the 11th Annual Symposium on Switching and
Automata Theory, pages 139-152.
Gertjan van Noord. 1991. Head corner parsing for
discontinuous constituency. In Proceedings of the
29th Annual Meeting of the Association for Com-
putational Linguistics, pages 114-121, Berkeley,
CA, June.
Gertjan van Noord. 1994. Head corner parsing.
In C.J. Rupp, M.A. Rosner, and R.L. Johnson,
editors, Constraints, Language and Computation,
pages 315-338. Academic Press.
Gertjan van Noord. 1997. An efficient implemen-
tation of the head-corner parser. Computational
Linguistics, 23(3):425-456.
</reference>
<page confidence="0.998511">
669
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.941682">
<title confidence="0.9981095">Know When to Hold &apos;Em: Shuffling Deterministically in a Parser for Nonconcatenative Grammars*</title>
<author confidence="0.997921">T Kasper</author>
<author confidence="0.997921">Mike Calcagno</author>
<author confidence="0.997921">C Davis</author>
<affiliation confidence="0.999999">Department of Linguistics, Ohio State University</affiliation>
<address confidence="0.999521">222 Oxley Hall 1712 Neil Avenue Columbus, OH 43210 U.S.A.</address>
<email confidence="0.999837">Ocasper,calcagno,pcdavis101ing.ohio-state.edu</email>
<abstract confidence="0.995323333333333">Nonconcatenative constraints, such as the shuffle relation, are frequently employed in grammatical analyses of languages that have more flexible ordering of constituents than English. We show how it is possible to avoid searching the large space of permutations that results from a nondeterministic application of shuffle constraints. The results of our implementation demonstrate that deterministic application of shuffle constraints yields a dramatic improvement in the overall performance of a head-corner parser for German using an HPSG-style grammar.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Ti</author>
</authors>
<title>Er hilft ihr. T2. Hilft er seiner Freundin? T3. Er hilft ihr schnell. T4. Hilft er ihr schnell? T5. Liess er ihr ihn helfen? T6. Er less ihn ihr schnell helfen. T7. Liess er ihn ihr schnell helfen?</title>
<marker>Ti, </marker>
<rawString>Ti. Er hilft ihr. T2. Hilft er seiner Freundin? T3. Er hilft ihr schnell. T4. Hilft er ihr schnell? T5. Liess er ihr ihn helfen? T6. Er less ihn ihr schnell helfen. T7. Liess er ihn ihr schnell helfen?</rawString>
</citation>
<citation valid="false">
<authors>
<author>T8</author>
</authors>
<title>Der Vater less seiner Freundin seinen Sohn helfen.</title>
<marker>T8, </marker>
<rawString>T8. Der Vater less seiner Freundin seinen Sohn helfen.</rawString>
</citation>
<citation valid="false">
<authors>
<author>T9</author>
</authors>
<title>Sie denkt dass er ihr hilft. T10. Sie denkt dass er ihr schnell hilft. T11. Sie denkt dass er ihr ihn helfen less.</title>
<marker>T9, </marker>
<rawString>T9. Sie denkt dass er ihr hilft. T10. Sie denkt dass er ihr schnell hilft. T11. Sie denkt dass er ihr ihn helfen less.</rawString>
</citation>
<citation valid="false">
<authors>
<author>T12</author>
</authors>
<title>Sie denkt dass er seiner Freundin seinen Sohn helfen less.</title>
<marker>T12, </marker>
<rawString>T12. Sie denkt dass er seiner Freundin seinen Sohn helfen less.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emmon Bach</author>
</authors>
<date>1979</date>
<booktitle>Control in montague grammar. Linguistic Inquiry,</booktitle>
<pages>10--515</pages>
<marker>Bach, 1979</marker>
<rawString>Emmon Bach. 1979. Control in montague grammar. Linguistic Inquiry, 10:515-553.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David R Dowty</author>
</authors>
<title>Toward a minimalist theory of syntactic structure.</title>
<date>1996</date>
<booktitle>In Arthur Horck and Wietske Sijtsma, editors, Discontinuous Constituency,</booktitle>
<location>Berlin. Mouton</location>
<note>de Gruyter.</note>
<contexts>
<context position="2145" citStr="Dowty (1996)" startWordPosition="316" endWordPosition="317">us constituency, illustrated with what he calls a &amp;quot;tiny&amp;quot; fragment of Dutch, but his more recent development of the head-corner parser (van Noord, 1997) only documents its use with purely concatenative grammars. The conventional wisdom has been that the large search space resulting from the use of such constraints (e.g., the shuffle relation) makes parsing too inefficient for most practical applications. On the other hand, grammatical analyses of languages that have more flexible ordering of constituents than English make frequent use of constraints of this type. For example, in recent work by Dowty (1996), Reape (1996), and Kathol This research was sponsored in part by National Science Foundation grant SBR-9410532, and in part by a seed grant from the Ohio State University Office of Research; the opinions expressed here are solely those of the authors. (1995), in which linear order constraints are taken to apply to domains distinct from the local trees formed by syntactic combination, the nonconcatenative shuffle relation is the basic operation by which these word order domains are formed. Reape and Kathol apply this approach to various flexible word-order constructions in German. A small samp</context>
</contexts>
<marker>Dowty, 1996</marker>
<rawString>David R. Dowty. 1996. Toward a minimalist theory of syntactic structure. In Arthur Horck and Wietske Sijtsma, editors, Discontinuous Constituency, Berlin. Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thilo Gratz</author>
<author>Walt Detmar Meurers</author>
</authors>
<title>The ConTroll system as large grammar development platform.</title>
<date>1997</date>
<booktitle>In Proceedings of the Workshop on Computational Environments for Grammar Development and Linguistic Engineering (ENVGRAM) held at ACL-97,</booktitle>
<location>Madrid,</location>
<marker>Gratz, Meurers, 1997</marker>
<rawString>Thilo Gratz and Walt Detmar Meurers. 1997. The ConTroll system as large grammar development platform. In Proceedings of the Workshop on Computational Environments for Grammar Development and Linguistic Engineering (ENVGRAM) held at ACL-97, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>Parsing with discontinuous constituents.</title>
<date>1985</date>
<booktitle>In Proceedings of the 23rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>127--132</pages>
<location>Chicago, IL,</location>
<contexts>
<context position="16498" citStr="Johnson (1985)" startWordPosition="2618" endWordPosition="2619">s. Instead, we adapt a technique described by Reape (1991), and use bitstring codes to represent the portions of the input covered by each element in an order domain. If the input string contains n words, the code value for each constituent will be a bitstring of length n. If element i of the bitstring is 1, the constituent contains the ith word of the sentence, and if element i of the bitstring is 0, the constituent does not contain the ith word. Reape uses bitstring codes for a tabular parsing algorithm, different from the head-corner algorithm used here, and attributes the original idea to Johnson (1985). The optimized version of the shuffle relation is defined below, using a notation in which the arguments are descriptions of typed feature structures. The actual implementation of relations in the ConTroll formalism uses a slightly different notation, but we use a more familiar Prolog-style notation here.4 4Symbols beginning with an upper-case letter are variables, while lower-case symbols are either attribute labels (when followed by `:&apos;) or the types of values (e.g., ne_list). 666 % shuffle (optimized version) shuffle([], 07. shuffle((S1&amp;ne_list), Si). shuffle([], (S2&amp;ne_list), S2). shuffle</context>
</contexts>
<marker>Johnson, 1985</marker>
<rawString>Mark Johnson. 1985. Parsing with discontinuous constituents. In Proceedings of the 23rd Annual Meeting of the Association for Computational Linguistics, pages 127-132, Chicago, IL, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Kathol</author>
</authors>
<title>Linearization-based German Syntax.</title>
<date>1995</date>
<tech>Ph.D. thesis,</tech>
<institution>The Ohio State University.</institution>
<marker>Kathol, 1995</marker>
<rawString>Andreas Kathol. 1995. Linearization-based German Syntax. Ph.D. thesis, The Ohio State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>Head-driven parsing.</title>
<date>1989</date>
<booktitle>In Proceedings of the First International Workshop on Parsing Technologies.</booktitle>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="10731" citStr="Kay (1989)" startWordPosition="1686" endWordPosition="1687">d thus expect the most appropriate parsing algorithm to take advantage of the information that a semantic head provides. For example, a head usually provides information about the remaining daughters that the parser must find, and (since the head daughter in a construction is in many ways similar to its mother category) effective top-down identification of candidate heads should be possible. One type of parser that we believe to be particularly well-suited to this type of grammar is the head-corner parser, introduced by van Noord (1991; 1994) based on one of the parsing strategies explored by Kay (1989). The head-corner parser can be thought of as a generalization of a left-corner parser (Rosenkrantz and Lewis-II, 1970; Matsumoto et al., 1983; Pereira and Shieber, 1987).1 The outstanding features of parsers of this type are that they are head-driven, of course, and that they process the string bidirectionally, starting from a lexical head and working outward. The key ingredients of the parsing algorithm are as follows: • Each grammar rule contains a distinguished daughter which is identified as the head of the rule.&apos; • The relation head-corner is defined as the reflexive and transitive closu</context>
</contexts>
<marker>Kay, 1989</marker>
<rawString>Martin Kay. 1989. Head-driven parsing. In Proceedings of the First International Workshop on Parsing Technologies. Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Matsumoto</author>
<author>H Tanaka</author>
<author>H Hirakawa</author>
<author>H Miyoshi</author>
<author>H Yasukawa</author>
</authors>
<title>BUP: a bottom up parser embedded in prolog.</title>
<date>1983</date>
<journal>New Generation Computing,</journal>
<volume>1</volume>
<issue>2</issue>
<contexts>
<context position="10873" citStr="Matsumoto et al., 1983" startWordPosition="1706" endWordPosition="1709">le, a head usually provides information about the remaining daughters that the parser must find, and (since the head daughter in a construction is in many ways similar to its mother category) effective top-down identification of candidate heads should be possible. One type of parser that we believe to be particularly well-suited to this type of grammar is the head-corner parser, introduced by van Noord (1991; 1994) based on one of the parsing strategies explored by Kay (1989). The head-corner parser can be thought of as a generalization of a left-corner parser (Rosenkrantz and Lewis-II, 1970; Matsumoto et al., 1983; Pereira and Shieber, 1987).1 The outstanding features of parsers of this type are that they are head-driven, of course, and that they process the string bidirectionally, starting from a lexical head and working outward. The key ingredients of the parsing algorithm are as follows: • Each grammar rule contains a distinguished daughter which is identified as the head of the rule.&apos; • The relation head-corner is defined as the reflexive and transitive closure of the head relation. • In order to prove that an input string can be parsed as some (potentially complex) goal category, the parser nondet</context>
</contexts>
<marker>Matsumoto, Tanaka, Hirakawa, Miyoshi, Yasukawa, 1983</marker>
<rawString>Y. Matsumoto, H. Tanaka, H. Hirakawa, H. Miyoshi, and H. Yasukawa. 1983. BUP: a bottom up parser embedded in prolog. New Generation Computing, 1(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Moortgat</author>
</authors>
<title>Generalized quantifiers and discontinuous type constructors.</title>
<date>1996</date>
<booktitle>In Arthur Horck and Wietske Sijtsma, editors, Discontinuous Constituency,</booktitle>
<location>Berlin. Mouton</location>
<note>de Gruyter.</note>
<marker>Moortgat, 1996</marker>
<rawString>Michael Moortgat. 1996. Generalized quantifiers and discontinuous type constructors. In Arthur Horck and Wietske Sijtsma, editors, Discontinuous Constituency, Berlin. Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
<author>Stuart M Shieber</author>
</authors>
<title>Prolog and Natural Language Analysis.</title>
<date>1987</date>
<booktitle>CSLI Lecture Notes Number 10,</booktitle>
<location>Stanford, CA.</location>
<contexts>
<context position="10901" citStr="Pereira and Shieber, 1987" startWordPosition="1710" endWordPosition="1713">des information about the remaining daughters that the parser must find, and (since the head daughter in a construction is in many ways similar to its mother category) effective top-down identification of candidate heads should be possible. One type of parser that we believe to be particularly well-suited to this type of grammar is the head-corner parser, introduced by van Noord (1991; 1994) based on one of the parsing strategies explored by Kay (1989). The head-corner parser can be thought of as a generalization of a left-corner parser (Rosenkrantz and Lewis-II, 1970; Matsumoto et al., 1983; Pereira and Shieber, 1987).1 The outstanding features of parsers of this type are that they are head-driven, of course, and that they process the string bidirectionally, starting from a lexical head and working outward. The key ingredients of the parsing algorithm are as follows: • Each grammar rule contains a distinguished daughter which is identified as the head of the rule.&apos; • The relation head-corner is defined as the reflexive and transitive closure of the head relation. • In order to prove that an input string can be parsed as some (potentially complex) goal category, the parser nondeterministically selects a pot</context>
</contexts>
<marker>Pereira, Shieber, 1987</marker>
<rawString>Fernando C.N. Pereira and Stuart M. Shieber. 1987. Prolog and Natural Language Analysis. CSLI Lecture Notes Number 10, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
</authors>
<title>Generalized Phrase Structure Grammars, Head Grammars and Natural Language.</title>
<date>1984</date>
<tech>Ph.D. thesis,</tech>
<institution>Stanford University.</institution>
<marker>Pollard, 1984</marker>
<rawString>Carl Pollard. 1984. Generalized Phrase Structure Grammars, Head Grammars and Natural Language. Ph.D. thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Reape</author>
</authors>
<title>Parsing bounded discontinuous constituents: Generalizations of some common algorithms.</title>
<date>1991</date>
<booktitle>In Proceedings of the First Computational Linguistics in the</booktitle>
<institution>Netherlands Day, OTK, University of Utrecht.</institution>
<contexts>
<context position="15942" citStr="Reape (1991)" startWordPosition="2519" endWordPosition="2520">ons whose order diverges from that of the input sentence. In order to avoid this very inefficient generate-and-test behavior, we need to provide a way for the input positions covered by each proposed constituent to be considered sooner, so that the only solutions produced by the shuffle constraint will be those that correspond to the order of words in the actual input sequence. Since the portion of the input string covered by an order domain may be discontinuous, we cannot just use a pair of endpoints for each constituent as in chart parsers or DCGs. Instead, we adapt a technique described by Reape (1991), and use bitstring codes to represent the portions of the input covered by each element in an order domain. If the input string contains n words, the code value for each constituent will be a bitstring of length n. If element i of the bitstring is 1, the constituent contains the ith word of the sentence, and if element i of the bitstring is 0, the constituent does not contain the ith word. Reape uses bitstring codes for a tabular parsing algorithm, different from the head-corner algorithm used here, and attributes the original idea to Johnson (1985). The optimized version of the shuffle relat</context>
</contexts>
<marker>Reape, 1991</marker>
<rawString>Michael Reape. 1991. Parsing bounded discontinuous constituents: Generalizations of some common algorithms. In Proceedings of the First Computational Linguistics in the Netherlands Day, OTK, University of Utrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Reape</author>
</authors>
<title>Getting things in order.</title>
<date>1996</date>
<booktitle>In Arthur Horck and Wietske Sijtsma, editors, Discontinuous Constituents. Mouton de Gruyter,</booktitle>
<location>Berlin.</location>
<contexts>
<context position="2159" citStr="Reape (1996)" startWordPosition="318" endWordPosition="319">y, illustrated with what he calls a &amp;quot;tiny&amp;quot; fragment of Dutch, but his more recent development of the head-corner parser (van Noord, 1997) only documents its use with purely concatenative grammars. The conventional wisdom has been that the large search space resulting from the use of such constraints (e.g., the shuffle relation) makes parsing too inefficient for most practical applications. On the other hand, grammatical analyses of languages that have more flexible ordering of constituents than English make frequent use of constraints of this type. For example, in recent work by Dowty (1996), Reape (1996), and Kathol This research was sponsored in part by National Science Foundation grant SBR-9410532, and in part by a seed grant from the Ohio State University Office of Research; the opinions expressed here are solely those of the authors. (1995), in which linear order constraints are taken to apply to domains distinct from the local trees formed by syntactic combination, the nonconcatenative shuffle relation is the basic operation by which these word order domains are formed. Reape and Kathol apply this approach to various flexible word-order constructions in German. A small sampling of other </context>
</contexts>
<marker>Reape, 1996</marker>
<rawString>Mike Reape. 1996. Getting things in order. In Arthur Horck and Wietske Sijtsma, editors, Discontinuous Constituents. Mouton de Gruyter, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D J Rosenkrantz</author>
<author>P M Lewis-II</author>
</authors>
<title>Deterministic left corner parsing.</title>
<date>1970</date>
<booktitle>In IEEE Conference of the 11th Annual Symposium on Switching and Automata Theory,</booktitle>
<pages>139--152</pages>
<contexts>
<context position="10849" citStr="Rosenkrantz and Lewis-II, 1970" startWordPosition="1702" endWordPosition="1705">emantic head provides. For example, a head usually provides information about the remaining daughters that the parser must find, and (since the head daughter in a construction is in many ways similar to its mother category) effective top-down identification of candidate heads should be possible. One type of parser that we believe to be particularly well-suited to this type of grammar is the head-corner parser, introduced by van Noord (1991; 1994) based on one of the parsing strategies explored by Kay (1989). The head-corner parser can be thought of as a generalization of a left-corner parser (Rosenkrantz and Lewis-II, 1970; Matsumoto et al., 1983; Pereira and Shieber, 1987).1 The outstanding features of parsers of this type are that they are head-driven, of course, and that they process the string bidirectionally, starting from a lexical head and working outward. The key ingredients of the parsing algorithm are as follows: • Each grammar rule contains a distinguished daughter which is identified as the head of the rule.&apos; • The relation head-corner is defined as the reflexive and transitive closure of the head relation. • In order to prove that an input string can be parsed as some (potentially complex) goal cat</context>
</contexts>
<marker>Rosenkrantz, Lewis-II, 1970</marker>
<rawString>D.J. Rosenkrantz and P.M. Lewis-II. 1970. Deterministic left corner parsing. In IEEE Conference of the 11th Annual Symposium on Switching and Automata Theory, pages 139-152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gertjan van Noord</author>
</authors>
<title>Head corner parsing for discontinuous constituency.</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>114--121</pages>
<location>Berkeley, CA,</location>
<marker>van Noord, 1991</marker>
<rawString>Gertjan van Noord. 1991. Head corner parsing for discontinuous constituency. In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, pages 114-121, Berkeley, CA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gertjan van Noord</author>
</authors>
<title>Head corner parsing.</title>
<date>1994</date>
<booktitle>Constraints, Language and Computation,</booktitle>
<pages>315--338</pages>
<editor>In C.J. Rupp, M.A. Rosner, and R.L. Johnson, editors,</editor>
<publisher>Academic Press.</publisher>
<marker>van Noord, 1994</marker>
<rawString>Gertjan van Noord. 1994. Head corner parsing. In C.J. Rupp, M.A. Rosner, and R.L. Johnson, editors, Constraints, Language and Computation, pages 315-338. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gertjan van Noord</author>
</authors>
<title>An efficient implementation of the head-corner parser.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<pages>23--3</pages>
<marker>van Noord, 1997</marker>
<rawString>Gertjan van Noord. 1997. An efficient implementation of the head-corner parser. Computational Linguistics, 23(3):425-456.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>