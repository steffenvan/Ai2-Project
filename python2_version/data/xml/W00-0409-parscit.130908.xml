<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.983089">
Multi-document Summarization by Visualizing Topical Content
</title>
<author confidence="0.97225">
Rie Kubota Ando
</author>
<affiliation confidence="0.927874">
Department of Computer Science, Cornell University, Ithaca, NY 14853-7501
</affiliation>
<bodyText confidence="0.33980475">
kubotar@c s . corne 11 . edu
Branimir K. Boguraev, Roy J. Byrd, Mary S. Neff
IBM T.J. Watson Research Center, 30 Saw Mill River Road, Hawthorne, NY 10532
{bkb, byrd, nef f}@wat son . ibm com
</bodyText>
<sectionHeader confidence="0.97223" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999738666666667">
This paper describes a framework for multi-
document summarization which combines three
premises: coherent themes can be identified reli-
ably; highly representative themes, running across
subsets of the document collection, can function as
multi-document summary surrogates; and effective
end-use of such themes should be facilitated by a vi-
sualization environment which clarifies the relation-
ship between themes and documents. We present al-
gorithms that formalize our framework, describe an
implementation, and demonstrate a prototype sys-
tem and interface.
</bodyText>
<sectionHeader confidence="0.894715666666667" genericHeader="method">
1 Introduction: multi-document
summarization as an enabling
technology for IR
</sectionHeader>
<bodyText confidence="0.897392729166667">
The rapid growth of electronic documents has
created a great demand for a navigation tool to
traverse a large corpus. Information retrieval
(IR) technologies allow us to access the docu-
ments presumably matching our interests. How-
ever, a traditional hit list-based architecture, which
returns linearly organized single document sum-
maries, no longer suffices, given the size of a typ-
ical hit list (e.g. submitting the query &amp;quot;summa-
rization workshop&amp;quot; to a search engine Altavista
(http : / /altavista corn) gave us more than
ten million hits).
To allow a more comprehensive and screen space-
efficient presentation of query results, we propose
in this paper a technology for summarizing collec-
tions of multiple documents. In our work, we fo-
cus on identifying themes, representative of a docu-
ment, and possibly running across documents. Even
if we are unable to &apos;embody&apos; a theme in coherently
generated prose, we start with the assumption that a
mapping exists between a theme and a tightly con-
nected (and therefore intuitively interpretable) set
of coherent linguistic objects, which would act as
a &apos;prompting&apos; device when presented to the user in
an appropriate context. As will become clear in the
rest of the paper, we refer to such themes as topics.
Our view of multi-document summarization
combines three premises: coherent topics can be
identified reliably; highly representative topics, run-
ning across subsets of the document collection, can
function as multi-document summary surrogates;
and effective end-use of such topics should be facil-
itated by a visualization environment which clarifies
the relationship between topics and documents. The
work specifically addresses the following consider-
ations.
• Multiple general topics We regard the ability
to respond to multiple topics in a document collec-
tion — in contrast to a prevailing trend in multi-
document summarization, seeking to present the
single, possibly pre-determined, topic (see below)
— to be crucial to applications such as summariza-
tion of query results. In this work we choose not
to narrow the topic detection process by the given
query, since in IR it is a well-known concern that
user-specified queries do not necessarily convey the
user&apos;s real interests thoroughly. Thus, we need to
deal with multiple general topics.
</bodyText>
<listItem confidence="0.954966">
• Textual and graphical presentation Since
</listItem>
<bodyText confidence="0.950011230769231">
our multi-document summaries will, by definition,
incorporate multiple topics, the question arises of
optimal representation of the relationships among
the topics, the linguistic objects comprising each
topic, and the documents associated with (possibly
more than one) topic. In particular, for IR, we
want to show the relationships between topics and
documents so that a user can access documents
in the context of the topics. A topic by itself
can clearly be represented largely by a set of text
objects. However, we need also to present arbitrary
number of such topics as part of the same summary.
We believe that, for adequate representation of
</bodyText>
<page confidence="0.997213">
79
</page>
<bodyText confidence="0.999982948717949">
the resulting many-to-many relationships (which
is crucial for the end-user fully understanding the
summary), additional graphical components are
needed in the interface.
To our knowledge, the existing studies of multi-
document summarization do not place emphasis on
these considerations. Radev and McKeown (1998)
have shown a methodology for &apos;briefing&apos; news
articles reporting the same event. Barzilay et al.
(1999) have proposed a method for summarizing
&amp;quot;news articles presenting different descriptions of •
the same event&amp;quot;. These studies focus on a single
topic in a document collection. Mani and Bloedorn
(1999) have addressed summarizing of similarities,
and differences among related documents with
respect to a specified query or profile. In their
study, several presentation strategies are suggested.
Although they mention a graphieal strategy, such
as plotting documents sharing more terms closer
together, no implementation is reported.
There are a number of different studies that ad-
dress graphical presentation of multi-document (or
document corpus visualization) – The VIBE Sys-
tem (Olsen et al., 1993; Korthage and Olsen, 1995),
Galaxy (Rennison, 1994), SPIRE Themescapes
(Wise et al., 1995), LyberWorld (Hemmje et al.,
1994), and applications of self-organizing map uti-
lizing neural network technique (Kohonen, 1997;
Lin, 1993; Lagus et al., 1996). In general, these
studies consider documents as objects in a model
space (document space, typically high-dimensional)
and provide 2-D or 3-D representation of this docu-
ment space. Their focus is on detecting and present-
ing structural relationships among documents in a
corpus.
S.. From our viewpoint, these two fields of research
address two different perspectives on the multi-
document analysis problem: multi-document sum-
marization efforts largely deliver their results in tex-
tual form, while document corpus visualiiation re-
search, which focuses on means for graphical rep-
resentation of a document space, does not perform
any summarization work. While we believe that
both textual and graphical representations are essen-
tial in the context of IR, the technologies from the
two fields, in general, cannot be easily combined
because of methodological differences (such as dif-
ferences in modeling the document set, calculating
similarity measures, and choosing linguistic objects
in terms of which a summary would be constructed).
Motivated by these observations, we propose one
uniform framework that provides both textual and
graphical representations of a document collection.
In this framework, topics underlying a document
collection are identified, and described by means of
linguistic objects in the collection. Relationships,
typically many-to-many, among documents and top-
ics are graphically presented, together with the topic
descriptions, by means of a graphical user interface
specifically designed for this purpose. We focus on
relatively small document collections (e.g. 100 or
so top-ranked documents), observing that in a real-
istic environment users will not look much beyond
such a cut-off point. Our approach maps linguistic
objects onto a multi-dimensional space (called se-
mantic space). As we will see below, the mapping
is defined in a way that allows for topics with cer-
tain properties to be derived and for linguistic ob-
jects at any granularity to be compared as semantic
concepts.
The rest of this paper is organized as follows. The
next section describes the multi-dimensional space
for the document collection. Section 3 demonstrates
our prototype system and illustrates the interplay
between textual and graphical aspects of the multi-
document summary. Section 4 highlights the im-
plementation of the prototype system. We will con-
clude in Section 5.
</bodyText>
<sectionHeader confidence="0.6733045" genericHeader="method">
2 Mapping a document collection into
semantic space
</sectionHeader>
<bodyText confidence="0.99964855">
Semantic space is derived on the basis of analyz-
ing relationships among linguistic objects — such
as terms, sentences, and documents — in the entire
collection. A term can be simply a &apos;content word&apos;,
in the traditional IR sense, or it can also be con-
strued as a phrasal unit, further representative of a
concept in the document domain. In our implemen-
tation, we do, in fact, take that broader definition
of terms, to incorporate all types of non-stop lexi-
cal items as well as phrasal units such as named en-
tities, technical terminology, and other multi-word
constructions (see Section 4 below).
We map linguistic objects (such as terms, sen-
tences, and documents) to vectors in a multi-
dimensional space. We construct this space so that
the vectors for the objects behaving statistically
similarly (and therefore presumed to be semanti-
cally similar) point in similar directions. The vec-
tors are called document vectors, sentence vectors,
and tem vectors, according to the original linguistic
</bodyText>
<page confidence="0.994356">
80
</page>
<bodyText confidence="0.999909421875">
objects they are derived from; however, all vectors
hold the same status in the sense that they repre-
sent some concepts. In this work, we call this multi-
dimensional space semantic space (Ando, 2000) to
distinguish it from a traditional vector space (Salton
and McGill, 1983). In essence, in our semantic
space, the terms related to each other are mapped
to the vectors having similar directions, while a tra-
ditional vector space model treats all terms as inde-
pendent from each other.
Our motivation for using semantic space is at
least twofold. First, we believe that we need the
high representational power of a multi-dimensional
space since natural language objects are intrinsi-
cally complicated, as Deerwester et al. (1990) ar-
gued. Secondly, our definition of semantic space
allows us to measure similarities among concepts
and linguistic units at any granularity. Single-word
terms, multi-word terms, sentences, .and topics — all
can be equally treated as objects representing some
concept(s) when they are mapped to vectors in this
space. From the viewpoint of a summarization task,
this is an advantage over a traditional vector space
in which terms are assumed to be independent of
one another.
To detect topics underlying the document collec-
tion, we create a set of vectors in the semantic space
so that every document vector is represented by (or
close to) at least one vector (called topic vector).
In other words, we provide viewpoints in the se-
mantic space so that every document can be viewed
somewhat closely from some viewpoint. Given such
. vector representations for topics, we can quantita-
tively measure the degree of associations between
topics and linguistic objects by using a standard co-
sine similarity measure between topic vectors and
linguistic object vectors. The linguistic objects with
the, strongest association would represent the topic
most appropriately.
The algorithm we use for semantic space con-
struction (see Figure 5 in Section 4) is closely re-
lated to singular value decomposition (SVD) used in
Latent Semantic Indexing (LSI) (Deerwester et al.,
1990). As in SVD, this algorithm finds statistical re-
lationships between documents and terms by com-
puting eigenvectors, and it performs dimensional re-
duction that results in a better statistical modeling.
The advantages of the semantic space we described
above are shared with similar approaches (such as
SVD-based and Riemannian SVD-based (Jiang and
Berry, 1998)). The algorithm we adopt, however,
differs from others in that it achieves a high preci-
sion of similarity measurement among all the doc-
uments by capturing information more evenly from
every document while, with other approaches, the
documents whose statistical behaviors are different
from the others tend to be less well represented.
This algorithm fits well in our framework since we
want to find topics by referring the similarities of
all pairs of documents (shown later), and also we
want to assume all the documents are equal. Full
details of the semantic space construction algorithm
may be found in (Ando, 2000), including evaluation
results compared with SVD.
</bodyText>
<sectionHeader confidence="0.8204055" genericHeader="method">
3 Visual presentation of a semantic space:
combining text and graphics
</sectionHeader>
<bodyText confidence="0.995956264705882">
In this section, to illustrate how we combine tex-
tual and graphical presentation, we demonstrate a
summary that our prototype system created from
50 documents (TREC documents relevant to &apos;non-
proliferation treaty&apos;).
The document set is presented in one full screen
in relation to the underlying topics. The prototype
system detected six I topics in this document set (see
Figure 1). For each topic, three types of information
are presented: a list of terms (topic terms), a list of
sentences (topic sentences), and a visual represen-
tation of relevance of each document to the topic
(document map).
Below we highlight some essential features of the
interface.
Topic terms and topic sentences: The topic pre-
sented at the upper right corner of Figure 1 has
the topic terms &amp;quot;Iraq&amp;quot;, &amp;quot;Iraqi&amp;quot;, &amp;quot;Kuwait&amp;quot;, &amp;quot;Saddam
Hussein&amp;quot;, &amp;quot;embargo&amp;quot;, &amp;quot;invasion&amp;quot;, &amp;quot;disarm&amp;quot;, and so
on. (The frame is scrollable, thus accommodating
all topic terms.) A topic typically will be addressed
by more than one sentence, presented in a closely
associated scrollable frame. The first topic sentence
for this topic is &amp;quot;Israel&apos;s Air Force bombed Iraq&apos;s
Osirak ...&amp;quot;. Together, the sets of topic terms and sen-
tences describe the topic, i.e. one &apos;thread&apos; discussed
in possibly several documents.
Document proxy — a &amp;quot;dot&amp;quot; represents a docu-
ment: In a document map, a dot image represents
each document (i.e. document proxy). A dot before
a topic sentence is also a document proxy represent-
ing the document containing that sentence.
I The number of topics detected depends on the document
set and the parameter setting adjusting the granularity.
</bodyText>
<page confidence="0.989169">
81
</page>
<figureCaption confidence="0.519478352941176">
&gt;7-7 &apos;fti. icp I, 1..,ii?.!!!!/.,.:93.,zttopo.htna.J.r.zi 7 tIlir tl- &apos;`&apos;•
tre.aty. WC ri il 0 n, nuclear. nuclear vie alms,. missile, soviet, amt. sign. — Iract„Irairi. Kuwait. Saddam Hussein, embargo, invasion, di arms..
.They exchanged ratification protocols for d 212h:J3§ ....&amp;quot; &apos;Israel&apos;s Air Force bombed Iraq&apos;s Osirak
the Intermediate-Range Nuclear Forces &amp;quot;....... &amp;quot; • nuclear reactor in 1981 while Iraq was at
treaty (INF) to eliminate medium-range t • war with Iran, claiming the facility was being ,
nuclear missiles, which was signed at dm - : • •• • :I used to develop atomic weapons.
Washington summit last December and &amp;quot;Some analysts in Israel, which closely
ratified by the Senate last Friday and by the tracks Iraq&apos;s arms program, believe
Soviet assembly of presidents 17 hours Baghdad could be two to five years away
_lo.&amp;quot;&amp;quot;.... - -- - - ..etTo.roef&amp;quot;.74&amp;quot;,tits::.5t•on-*•&amp;quot;•...ir.&apos;,trs..*Ite,,,l&amp;quot;..Fott
rocio,A. Aid, certification certify.. John Kelly. susuension,Stenhert ii , Smith Africa, Afrtrmi, inspection, International Atomic Energy ,Agency„.
*Leonard Spector. an expert on the spread S. .. ,.. .In the past, South Africa has refused to sign
of nuclear weapons, has said &apos;available - 1 the 1969 Nuclear Non-Proliferation Treaty
evidence leaves little doubt&apos; that Pakistan is _ and to submit all its nuclear facilities to
indeed developing nuclear arias inspection by the Vienna-based International -i.
&amp;quot;The continuing review of Pakistan&apos;s nuclear -7. Atomic Energy Agency.
program is part of such concern. Kelly said. 1.... :Under the Treaty on the Non-Proliferation
</figureCaption>
<table confidence="0.766713666666667">
citing a U.S. law, the Pressler amendment, of Nuclear Weapons, which has been signed
.
heavy !rates, nuclear mattes, Norany,l3asel ,•Scrittestand„ India, tea,. . transpertatiort_system, compensate, reprocess, nuclear fuel, fi!:int.
• &amp;quot;A federal appeals court in Washington,
calling the plant one of the most remarkable
white elephants&apos; in the nation&apos;s history. ruled ,
in February that plant owner Allied-General
Nuclear Services is not entitled to
compensation.
.The plant was denied a license in 1977
when former President Jimmy Carter
. .. , ... ... . , .... .. .... .... . .
&apos;Norway does not allow the export of . .
heavy water to countries that have not
signed the international nuclear
non-proliferation agreement. including India
&amp;quot;Heavy water, or deuteriton made, is used
as a coolant in some nuclear reactors, but it ,
can also be used to produce plutonium for ,....
use in nuclear arms. ..,:lrj-
.. ,.,... . .. . .. . . .
1 ALL UNTENCEZ DIMEN&apos;ION 2
_ .. _ ... . ..... ..... .... . _ .__
[SY IliPhOncbert,
</table>
<figureCaption confidence="0.999701">
Figure 1: Example of the final output.
</figureCaption>
<figure confidence="0.805425">
Document map
Topic sentences
Document maps — topic-document relevance
</figure>
<bodyText confidence="0.994433871794872">
shown by document proxy placement and color gra-
dation: In a document map, the horizontal place-
ment of each dot represents the degree of relevance
of the corresponding document to the topic. Docu-
ments closer to the direction of the arrow are more
relevant to the topic. The color intensity of the
dot also represents the degree of relevance. For
instance, in the document map at the upper right
corner of Figure 1, we see that there are six doc-
uments closely related to this &apos;Iraq-topic&apos;. These
six dots are placed on the right (the direction of the
arrow), and their colors are more intense than the
other document proxies. We see one more docu-
ment to the left to the six documents, also with a
relatively strong connection to this topic. Two doc-
uments, represented by dots almost at the center of
the map, are only somewhat related to this topic.
The rest of the documents, having dots that are al-
most transparent and placed on the left, are not very
related to this topic. Thus, users can tell, at a glance,
how many documents are related to each topic and
how strongly they are related. Note that each doc-
ument map contains proxies for all the documents.
Unlike a typical clustering approach, we do not di-
vide documents into groups. Clusters of documents,
if any, are naturally observed in the document map.
A document map is a projection of document vec-
tors onto a topic vector. The semantic space allows
us to detect and straightforwardly present the struc-
tural relationships among the documents.
Highlighting of document proxies — the rela-
tionships between a document and multiple topics:
When a mouse rolls over a dot, the title of the doc-
ument appears, and the color of the dots represent-
ing the same document in all the document maps
changes. (from blue to red) (see Figure 2). This
color change facilitates understanding the relation-
ships between a document and multiple topics.
A hot-link from a document proxy to full text:
</bodyText>
<page confidence="0.977412">
82
</page>
<figure confidence="0.8266084">
When a mouse is over a doum nt ro.a a document title comes up, and all the proxies for the document areighlighted)
e ▪ E) NI)
as. Irina.
7V-
t5.2itoollhual
</figure>
<bodyText confidence="0.909609">
treat!. we IDOzt,, nuclear. nuclear weaoon. missile. soviet, arm. slum
.They exchanged ratification protocols for
the Intermediate-Range Nuclear Forces
treaty (INF) to eliminate medium-range
nuclear missiles, which was signed at the
Washington summit last December and
ratified by the Senate last Friday and by the
Soviet assembly of presidents 17 hours
.lsraers Air Force bombed Iraq&apos;s Osirak
nuclear reactor in 1981 while Iraq was at
war with Iran, cleaning the facility was being
used to develop atomic weapons.
</bodyText>
<subsectionHeader confidence="0.981056">
Bream Claws Three in Plot to Ship Nuclear Device/ to Ina selY
</subsectionHeader>
<bodyText confidence="0.647838">
nat..&gt; 11 act a ma.. Flaw mu, • e
</bodyText>
<subsectionHeader confidence="0.5938815">
Baghdad could be two to five yes away
Frew. e‘encturiute,ke cm,
</subsectionHeader>
<bodyText confidence="0.954778222222222">
Treolfrr
Pakistan. aid, certification, certify, Jahn Kelly, Juspensien..tettk
•Leonard Spector. an expert on the spread
of nuclear weapons, has said &apos;available
evidence leaves little doubt* that Pakistan is
indeed developing nuclear arI735.
•The continuing review of Pakistan&apos;s nuclear
program is part of such concern. Kelly said.
citing a U.S. law. the Pressler amendment.
heavy water, nuclear reactor, Norway, Basel , Switzerland, India, tan,
.Norway does not allow the export of
heavy water to countries that have not
signed the international nuclear
non-proliferation agreement, including India
.Heavy water, or deuterium oxide, is used
as a coolant in some nuclear reactors, but it
can also be used to produce plutonium for
use in nuclear arms.
</bodyText>
<subsectionHeader confidence="0.382571">
South Africa,Afiticap, ingpactiguijataniationtal_Atornie Enemy. Agene*,,,
</subsectionHeader>
<bodyText confidence="0.715609529411765">
13e
sin the past, South Africa has refused to sign !!.&amp;quot;
the 1969 Nuclear Non-Proliferation Treaty
and to submit all its nuclear facilities to
inspection by the Vienna-based International
Atomic Energy Agency.
.Under the Treaty on the Non-Proliferation
of Nuclear Weapons, which has been signed ;Al
transportationmtern, compensate, reprocess, nuclear fuel, plant
.A federal appeals court in Washington,
calling the plant &apos;one of the most remarkable 1&apos;1&apos;
white elephants&apos; in the nation&apos;s history, ruled &apos;-
in February that plant owner Allied-General -
Nuclear Services is not entitled to
compensation.
.The plant was denied a license in 1977
when former President Jimmy Carter
</bodyText>
<figure confidence="0.992867">
• ot •
•
1.1
</figure>
<figureCaption confidence="0.998948">
Figure 2: When a mouse rolls over a dot:
</figureCaption>
<bodyText confidence="0.9470411875">
When a dot is clicked, the full text of the corre-
sponding document is displayed in a separate win-
dow. This allows us to browse documents in the
. context of document-topic relationships.
Highlighting a topic sentence in the full text:
. When the clicked dot is associated with a topic sen-
tence, the full text is displayed in a separate window,
with the topic sentence highlighted. This highlight-
ing helps the user to understand the context of the
sentence quickly, and thus further facilitates focus-
ing on the information of particular interest.
Topic sentences: Finally, we illustrate some of
the topic sentences extracted by our system below.
For each topic, the two sentences related to the
topic most closely are shown.
&apos;Iraq-topic&apos;:
</bodyText>
<listItem confidence="0.980860272727272">
• Israel&apos;s Air Force bombed Iraq&apos;s Osirak nuclear reac-
tor in 1981 while Iraq was at war with Iran, claiming
the facility was being used to develop atomic weapons.
• Some analysts in Israel, which closely tracks Iraq&apos;s
arms program, believe Baghdad could be two to five
years away from producing its own atomic warheads for
missiles or nuclear bombs to be dropped from jets.
&apos;Pakistan-topic&apos;:
• Leonard Spector, an expert on the spread of nuclear
weapons, has said &amp;quot;available evidence leaves little
doubt&amp;quot; that Pakistan is indeed developing nuclear arms.
• The continuing review of Pakistan&apos;s nuclear program
is part of such concern, Kelly said, citing a US. law,
the Pressler amendment, requiring the president to
certifr annually that Pakistan does not possess a nuclear
weapon.
&apos;South Africa-topic&apos;:
• In the past, South Africa has refused to sign the 1969
Nuclear Non-Proliferation Treaty and to submit all its
nuclear facilities to inspection by the Vienna-based
International Atomic Energy Agency.
• Under the Treaty on the Non-Proliferation of Nuclear
</listItem>
<page confidence="0.997629">
83
</page>
<figureCaption confidence="0.999524">
Figure 3: Overview of the process.
</figureCaption>
<figure confidence="0.971380827586207">
A block arrow indicates the input to the process, and rectangles with double-line border are the output. Rectangles
with dashed line border are sub-processes. Other rectangles represent data.
topic
sentences
•
; topic
oi sentence
—04 creation ;
--01 topic term
oi creation
sentence
vectors
- topic
- vector
creation
document
map
— ; creation
document
vectors
document
maps
terms
term
vectors
topic
terms
topic
vectors
</figure>
<construct confidence="0.940391">
Weapons, which has been signed by 137 governments
since its preparation in 1969, countries without such
weapons open their nuclear facilities to inspection by
experts from the International Atomic Energy Agency, a
U.N. agency based in Vienna.
</construct>
<bodyText confidence="0.999496">
Both for &apos;Iraq-&apos; and &apos;Pakistan-topic&apos;, the two
topic sentences address two different aspects of the
similar &amp;quot;doubt&amp;quot; or &amp;quot;concern&amp;quot;. For &apos;South Africa-
topic&apos;, the second topic sentence gives background
knowledge of the specific fact described in the
first topic sentence. We find it interesting that,
despite the fact that the two topic sentences are
extracted from different documents, they appear to
be consecutive sequences from a uniform source.
</bodyText>
<listItem confidence="0.789612666666667">
• In essence, the design seeks to facilitate quick ap-
preciation of the contents of a document space by
• supporting browsing through a document collection
</listItem>
<bodyText confidence="0.9918036">
With easily switching between different views: topic
highlights (terms), topical sentences, full document
text, and inter-document relationships. At present,
there is no attempt to handle redundancy between
topic sentences.
</bodyText>
<sectionHeader confidence="0.998148" genericHeader="method">
4 Implementation
</sectionHeader>
<bodyText confidence="0.9996757">
In this section, we describe the implementation of
our prototype system. The overall process flow of
this system is shown in Figure 3. Our description
omits the process of creating graphical presentation
that is straightforwardly understood from Section
3. The system takes, as its input, the text of a given
set of documents. Throughout this section, we use
the three small &apos;documents&apos; shown below as an
illustrative example. The data flow from these three
documents to the final output is shown in Figure 4.
</bodyText>
<construct confidence="0.922645857142857">
Document #1:
Mary Jones has a little lamb. The lamb is her good buddy.
Document #2:
Mary Jones is a veterinarian for ABC University.
ABC University has many lambs.
Document #3:
Mike Smith is a programmer for XYZ Corporation.
</construct>
<subsectionHeader confidence="0.989988">
4.1 Term extraction
</subsectionHeader>
<bodyText confidence="0.999982368421052">
First, we extract all terms contained in the docu-
ments, using an infrastructure for document pro-
cessing and analysis, comprising a number of in-
terconnected, and mutually enabling, linguistic fil-
ters; which operates without any reference to a pre-
defined domain. The whole infrastructure (here-
after referred to as TEXTRACT) is designed from the
ground up to perform a variety of linguistic feature
extraction functions, ranging from straightforward,
single pass, tokenization, lexical look-up and mor-
phological analysis, to complex aggregation of rep-
resentative (salient) phrasal units across large multi-
document collections (Boguraev and Neff, 2000).
TEXTRACT combines functions for linguistic analy-
sis, filtering, and normalization; these focus on mor-
phological processing, named entity identification,
technical terminology extraction, and other multi-
word phrasal analysis; and are further enhanced by
cross-document aggregation, resulting in some nor-
</bodyText>
<page confidence="0.982717">
84
</page>
<figure confidence="0.990646444444444">
(sl)
a little lamb.
good buddy.
veterinarian for ABC University.
has many lambs.
programmer for XYZ corporation.
#1: Mary Jones has
The lamb is her
#2: Mary Jones is a
ABC University
#3: Mike Smith is a
Terms
&amp;quot;Mary Jones&amp;quot;, &amp;quot;little&amp;quot;, &amp;quot;lamb&amp;quot;, &amp;quot;good
buddy&amp;quot;, &amp;quot;veterinarian&amp;quot;, &amp;quot;ABC University&amp;quot;,
&amp;quot;Mike Smith&amp;quot;, &amp;quot;programmer,
&amp;quot;XYZ Corporation&amp;quot;
•
term-document #1 vectors #3 conversion matrix term-sentence vectors s2 s3 54 s5
Mary Jones 2 #2 0 (transposed) Mary Jones Si 0 1 0 0
little 1 2 0 0.45 0 0 little 1 0 0 0 0
lamb 0 0 0 0.22 0 0.35 lamb 0 0 0 0 0
good buddy 0 0 0 0.67 0 0.35 good buddy 0 0 0 0
veterinarian 0 0 0 0.22 0 0.35 veterinarian 0 1 1 1
ABC Univ. 0 0 0.22 0 -0.35 ABC Univ. 0 0 0 1
Mike Smith 0 1 0.45 0 -0.71 Mike Smith 0 0 0 1
programmer 1 0.58 0 programmer 0 0 0
XYZ corp. 0.58 0 XYZ corp.
0.58 0
document text
•
document vectors topic vectors
#1 #2 #3 #1 #2
0.84 0.84 0.53 0
0 0 -0.53 1
0.53 0.53 0 0
term vectors
term vectors are
column vectors
of the conversion
matrix.
sentence vectors
1.34 0.89 1.12 1.12 0
0 0 0 0 1.74
0.70 0.70 -1.06 -036
• sl s2 s3 s4 s5
</figure>
<table confidence="0.984592536585366">
document-topic relevance
topic #1 topic #2
doc #1 0.84 0
doc #2 0.84 0
doc #3 0 1
e.g. (doc #1, topic #1)
= [0.84,0,0.53] [1,0, Of
= 0.84k l+00+0.530 = 0.84
term-topic relevance
topic #1 topic #2
Mary Jones 0.45 0
little 0.22 0
Jamb 0.67 0
good buddy 0.22 0
veterinarian 0.22 9
ABC Univ. 0.45 0
Mike Smith 0 0.58
programmer 0 0.58
XYZ corp. 0 0.58
sentence-topic relevance
topic #1 topic #2
sl 1.34 0
s2 0.89 0
s3 1.12 0
s4 1.12 0
s5 0 1.74
e.g. (#1-1, topic #1)
= [1.34,0, 0.70] [I, 0, Ofr
= 1.349+0*0+0.70&apos;0 = 1.34
output
Jamb, Mary Jones, ABC University Mike Smith, programmer, XYZ corporation
• Mary Jones has a little • * Mike Smith is a
lamb. programmer for XYZ
• Mary Jones is a corporation.
veterinarian for ABC
University.
*ABC University has
many lambs.
oc #1 EDF oc #1 0, #3
oc #2 • 0 E&gt;
oc #2
</table>
<figureCaption confidence="0.993164">
Figure 4: Example of data flow.
</figureCaption>
<page confidence="0.98088">
85
</page>
<bodyText confidence="0.655543666666667">
Procedure ConstructSemanticSpace
Input: term-document vectors d1, dn
Output: conversion matrix C
</bodyText>
<equation confidence="0.93255925">
D = [d1...dn] /* Term-document matrix */
R = D /* Initialize a residual matrix with the term-document matrix */
For i = 1 to k
R, = [Iri /* Scale each of R&apos;s column vectors by a power of its own length */
= the eigenvector of R,R,T with the largest eigenvalue
R = R — KeiTrOci...(c.irrn)ci] /* Eliminate the direction of ei from R&apos;s column vectors */
End for
C = [Ci /* Conversion matrix */
</equation>
<figureCaption confidence="0.995674">
Figure 5: Semantic space creation. Scaling factor g and the dimensionality k are experimentally determined.
</figureCaption>
<bodyText confidence="0.997671333333333">
malization to canonical forms, and simple types of
co-reference resolution.
For the example mini-documents above, after re-
moval of common stop words, the terms remaining
as linguistic objects for the algorithm to operate on
are listed at top of Figure 4.
</bodyText>
<subsectionHeader confidence="0.916856">
4.2 Vector creation
</subsectionHeader>
<bodyText confidence="0.989749352941176">
We construct the semantic space from term-
document relationships by a procedure2 shown in
Figure 5. In the semantic space, each of vec-
tor elements represents a linear combination of
terms. The conversion matrix returned by the
semantic space creation procedure keeps the in-
formation of these linear combinations. For in-
stance, the conversion matrix for our example
(see Figure 4) shows that the first element of a
vector in the semantic space is associated with
0.45*&amp;quot;Mary Jones&amp;quot;+0.22*&amp;quot;little&amp;quot;+0.67*&amp;quot;lamb&amp;quot;+0.22* •
&amp;quot;good buddy&amp;quot;1-0.22*&amp;quot;veterinarian&amp;quot;+0.45*&amp;quot;ABC Uni-
versity&amp;quot;.
To map the documents to the vectors in the se-
mantic space, we create the term-document vectors
each of whose elements represents the degree of rel-
evance of each term to the document. Our imple-
</bodyText>
<listItem confidence="0.984901666666667">
• mentation uses term frequency as the degree of rel-
evance. We create document vectors of the seman-
tic space by multiplying term-document vectors and
the conversion matrix. Sentences and terms can also
be mapped to the vectors in the same way by treat-
ing them as &amp;quot;small documents&amp;quot;.
</listItem>
<footnote confidence="0.6954645">
2We do not describe the details of this procedure in this pa-
per. See Section 2.
</footnote>
<sectionHeader confidence="0.596347" genericHeader="method">
43 Identifying topics
</sectionHeader>
<bodyText confidence="0.999868666666667">
Ultimately, our multi-document summaries rely
crucially on identifying topics representing all the
documents in the set. This is done by creating topic
vectors so that each document vector is close to (i.e.
represented by) at least one topic vector. We imple-
ment this topic vector creation process as follows.
First, we create a document graph from the docu-
ment vectors. In the document graph, each node
represents a document vector, and two nodes have
an edge between them if and only if the similar-
ity between the two document vectors is above a
threshold. Next, we detect the connected compo-
nents in the document graph, and we create the topic
vectors from each connected component by apply-
ing the procedure `DetectTopic&apos; (Figure 6) recur-
sively.
`DetectTopic&apos; works as follows. The unit eigen-
vector of a covariance matrix of the document vec-
tors in a set S is computed as v. It is a representa-
tive direction of the document vectors in S. If the
similarity between v and any document vector in
S is below a threshold, then S is divided into two
sets Si and S2 (as in Figure 7), and the procedure
is called for S1 and 52 recursively. Otherwise, v is
returned as a topic vector. The granularity of topic
detection can be adjusted by the setting of threshold
parameters.
Note that such a topic vector creation procedure
essentially detects &amp;quot;cluster centroids&amp;quot; of document
vectors (not sentence vectors), although grouping
documents into clusters is not our purpose. This
indicates that general vector-based clustering tech-
nologies could be integrated into our framework if
</bodyText>
<page confidence="0.984572">
86
</page>
<bodyText confidence="0.927671">
it brings further improvement.
</bodyText>
<subsectionHeader confidence="0.838645">
4.4 Associations between topics and linguistic
objects
</subsectionHeader>
<bodyText confidence="0.999988454545455">
The associations between topics and linguistic ob-
jects (documents, sentences, and terms) are mea-
sured by computing the cosine (similarity measure-
ment) between the topic vectors and linguistic ob-
ject vectors. The degree of association between top-
ics and documents is used to create document maps.
The terms and sentences with the strongest associa-
tions are chosen to be the topic terms and the topic
sentences, respectively.
As a result, for our example we get the output
shown at the bottom of Figure 4.
</bodyText>
<subsectionHeader confidence="0.980721">
4.5 Computational complexity
</subsectionHeader>
<bodyText confidence="0.999978388888889">
Let m be the number of different terms in the doc-
ument set (typically around 5000), and let n be the
number of documents (typically 50 to 100)3. Given
that m &gt; n, the semantic space is constructed in
0(mn2) time. The topic vectors are created in
0(n3) time by using a separator tree for the compu-
tation of all-pairs minimum cut4, assuming that the
document vector set is divided evenlys. Let k be the
dimensionality of the semantic space, and let h be
the number of detected topics. Note that k and h are
at most n, but are generally much smaller than n in
practice. Regarding the number of terms contained
in one sentence as a constant, topic sentences are ex-
tracted in 0(skh) time where s is the total number
of sentences in the document set. Topic terms are
extracted in 0(mkh) time. We note that the proto-
type system runs efficiently enough for an interac-
tive system.
</bodyText>
<sectionHeader confidence="0.700456" genericHeader="method">
.5 Conclusion and further work
</sectionHeader>
<bodyText confidence="0.9996305">
.This paper proposes a framework for multiple doc-
umelit summarization that leverages graphical el-
ements to present a summary as a &apos;constellation&apos;
of topical highlights. In this framework, we detect
topics underlying a given document collection, and
we describe the topics by extracting related terms
and sentences from the document text. Relation-
ships among topics and documents are graphically
presented using gradation of color and placement
of image objects. We illustrate interactions with
</bodyText>
<footnote confidence="0.86272">
31n this work, we focus on relatively small document col-
lections; see Section 1.
4See (Ahuja et al., 1993) for all-pairs min cut problem.
&apos;Note that Step 3 in the document vector division procedure
(Figure 7) seeks for this.
</footnote>
<figure confidence="0.5298642">
Procedure DetectTopic(S)
Input: a set of document vectors S
Output: topic vectors
v = the unit eigenvector of a covariance matrix of
document vectors in S
Loop for each document vector d in S
if similarity between d and v is below a threshold
then begin
divide S into Si and S2
Call DetectTopic(Si)
Call DetectTopic(S2)
Exit the procedure
End if
End loop
Return v as a topic vector
</figure>
<figureCaption confidence="0.999565">
Figure 6: Topic vector creation.
</figureCaption>
<bodyText confidence="0.999867806451613">
our prototype system, and describe its implemen-
tation. We re-emphasize that the framework pre-
sented here derives its strength in equal part from
two components: the results of topical analysis of
the document collection are displayed by means
of a multi-perspective graphical interface specifi-
cally designed to highlight this analysis. Within
such a philosophy for multi-document summariza-
tion, sub-components of the analysis technology can
be modularly swapped in and replaced, without con-
tradicting the overall approach.
The algorithms and subsystems comprising the
document collection analysis component have been
implemented and are fully operational. The paper
described one possible interface, focusing on certain
visual metaphors for highlighting collection topics.
As this is work in progress, we plan to experiment
with alternative presentation metaphors. We plan
to carry out user studies, to evaluate the interface
in general, and to determine optimal features, best
suited to representing our linguistic object analysis
and supporting navigation through query results.
Other future work will focus on determining the
effects of analyzing linguistic objects to different
level of granularity on the overall results. Questions
to consider here, for instance, would be: what is
the optimal definition of a term for this application;
does it make sense to include larger phrasal units
in the semantic space; Or do operations over sen-
tences, such as sentence merging or reduction, offer
alternative ways of visualizing topical content.
</bodyText>
<page confidence="0.997635">
87
</page>
<bodyText confidence="0.999953363636364">
It is therefore worthwhile investigating whether
combining automatic summarization with
intelligent multimedia presentation techniques
can make the briefing generation amenable to
full automation. In other words, the author
should be able to use a computer program to
generate an initial briefing, which she can then
edit and revise as needed. The briefing can then
be presented by the author if desired, or else
directly by the computer (particularly useful if
the briefing is being sent to someone else). The
starting point for this process would be a high-
level outline of the briefing on the part of the
author. The outline would include references to
particular information sources that had to be
summarized in particular ways. If a program
were able to take such outlines and generate
briefings which didn&apos;t require extensive post-
editing to massage into a state deemed
acceptable for the task at hand, the program
could be regarded as a worthwhile time saving
tool.
</bodyText>
<sectionHeader confidence="0.984029" genericHeader="method">
2 Approach
</sectionHeader>
<bodyText confidence="0.999869788732395">
Our work forms part of a larger DARPA-funded
project aimed at improving analysis and
decision-making in crisis situations by providing
tools that allow analysts to collaborate to
develop structured arguments in support of
particular conclusions and to help predict likely
future scenarios. These arguments, along with
background evidence, are packaged together as
briefings to high-level decision-makers. In
leveraging automatic methods along the lines
suggested above to generate briefings, our
approach needs to allow the analyst to take on as
pinch of the briefing authoring as she wants to
(e.g., it may take time for her to adapt to or trust
the machine, or she may want the machine to
present just part of the briefing). The analyst&apos;s
organisation usually will instantiate one of
several templates dictating the high-level
structure of a briefing; for example, a briefing
may always have to begin with an executive
summary. The summarization methods also need
to be relatively domain-independent, given that
the subject matter of crises are somewhat
unpredictable; an analyst in a crisis situation is
likely to be inundated with large numbers of
crisis-related news and intelligence reports from
many different sources. This means that we
cannot require that a domain knowledge base be
available to help the briefing generation process.
Given these task requirements, we have adopted
an approach that is flexible about
accommodating different degrees of author
involvement, that is relatively neutral about the
rhetorical theory underlying the briefing
structure (since a template may be provided by
others), and that is domain-independent. In our
approach, the author creates the briefing outline,
which is then fleshed out further by the system
based on information in the outline. The system
fills out some content by invoking specified
summarizers; it also makes decisions, when
&apos; needed, about output media type; it introduces
narrative elements to improve the coherence of
the briefing; and finally, it assembles the final
presentation, making decisions about spatial
layout in the process.
A briefing is represented as a tree. The structure
of the tree represents the rhetorical structure of
the briefing. Each node has a label, which offers
a brief textual description of the node. Each leaf
node has an associated goal, which, when
realized, provides content for that node. There
are two kinds of goals: content-level goals and
narrative-level goals. Content-level goals are
also of two kinds: retrieve goals, which retrieve
existing media objects of a particular type (text,
audio, image, audio, video) satisfying some
description, and create goals, which create new
media objects of these types using programs
(called summarization filters). Narrative-level
goals introduce descriptions of content at other
nodes: they include captions and running text for
media objects, and segues, which are rhetorical
moves describing a transition to a node.
Ordering relations reflecting temporal and
spatial layout are defined on nodes in the tree.
Two coarse-grained relations, seq for
precedence, and par for simultaneity, are used to
specify a temporal ordering on the nodes in the
tree. As an example, temporal constraints for a
(tiny) tree of 9 nodes may be expressed as:
</bodyText>
<figure confidence="0.5500857">
&lt;ordering&gt; &lt;seq&gt;
&lt;par&gt;7&lt;/par&gt;
&lt;par&gt;8&lt;/par&gt;
&lt;par&gt;3&lt;/par&gt;
&lt;par&gt;4 5&lt;/par&gt;
&lt;par&gt;6&lt;/par&gt;
90
&lt;par&gt;1 9&lt;/par&gt;
&lt;par&gt;2&lt;/par&gt;
&lt;/seq&gt; &lt;/ordering&gt;
</figure>
<bodyText confidence="0.858946333333333">
The tree representation, along with the temporal
constraints, can be rendered in text as XML; we
refer to the XML representation as a script.
</bodyText>
<figure confidence="0.717571">
Template
</figure>
<figureCaption confidence="0.999678">
Figure 1: System Architecture
</figureCaption>
<bodyText confidence="0.999202">
The overall architecture of our system is shown
in Figure I. The user creates the briefing outline
in the form of a script, by using a GUI. The
briefing generator takes the script as input. The
Script Validator applies an XML parser to the
script, to check for syntactic correctness. It then
builds a.tree representation for the script, which
represents the briefing outline, with temporal
constraints attached to the leaves of the tree.
Next, a Content Creator takes the input tree and
expands it by introducing narrative-level goals
including segues to content nodes, and running
text and captions describing media objects at
content nodes. Running text and short captions
are generated from meta-information associated
with media objects, by using shallow text
generation methods (canned text). The end result
of content selection (which has an XML
representation called a ground script) is that the
complete tree has been fully specified, with all
the create and retrieve goals fully specified,
with all the output media types decided. The
Content Creator is thus responsible for both
content selection and creation, in terms of tree
structure and node content.
Then, a Content Executor executes all the create
and retrieve goals. This is a very simple step,
resulting in the generation of all the media
objects in the presentation, except for the audio
files for speech to be synthesized. Thus, this step
results in realization of the content at the leaves
of the tree.
Finally, the Presentation Generator takes the
tree which is output from Content Execution,
along with its temporal ordering constraints, and
generates the spatial layout of the presentation.
If no spatial layout constraints are specified (the
default is to not specify these), the system
allocates space using a simple method based on
the temporal layout for nodes which have spatial
manifestations. Speech synthesis is also carried
out here. Once the tree is augmented with spatial
layout constraints, it is translated by the
Presentation Generator into SMIL2
(Synchronized Multimedia Integration
Language) (SMIL 99), a W3C-developed
extension of HTML that can be played by
standard multimedia players (such as Real3 and
Grins4. This step thus presents the realized
content, synthesizing it into a multimedia
presentation laid out spatially and temporally.
This particular architecture, driven by the above
project requirements, does not use planning as
an overall problem-solving strategy, as planning
requires domain knowledge. It therefore differs
from traditional intelligent multimedia
presentation planners, e.g., (Wahlster et al. 93).
Nevertheless, the system does make a number of
intelligent decisions in organizing and
coordinating presentation decisions. These are
discussed next, after which we turn to the main
point of the paper, namely the leveraging of
summarization in automatic briefing generation.
</bodyText>
<footnote confidence="0.967800333333333">
2http://www.w3.org/AudioVideo/
3 www.real.com
4 www.oratrix.com
</footnote>
<figure confidence="0.99820065">
Script
Creator
script
Script
Vali dator
Content
Creator
Ground script
Content
Executor
Presentation
Generator
SMIL
4
Multimedia
Player
User
Intelface
Briefing
Generator
</figure>
<page confidence="0.994047">
91
</page>
<sectionHeader confidence="0.992261" genericHeader="method">
3 Intelligent Multimedia Presentation
</sectionHeader>
<subsectionHeader confidence="0.908423">
Generation
</subsectionHeader>
<bodyText confidence="0.999980649350649">
The author of a briefing may choose to flesh out
as little of the tree as desired, with the caveat
that the temporal ordering relations for non-
narrative nodes need to be provided by her.
When a media object is generated at a node by a
create goal, the running text and captions are
generated by the system. The motivation for this
is obvious: when a summarization filter (which
is a program under our control) is generating a
media object, we can often provide sufficient
meta-information about that object to generate a
short caption and some running text. By default,
all segues and spatial layout relations are also
specified by the system, so the author does not
have to know about these unless she wants to.
Finally, the decision as to when to produce
audio, when not specified by the author, is left to
the system.
When summarization filters are used (for create
goals), the media type of the output is specified
as a parameter to the filter. This media type may
be converted to some other type by the system,
e.g., text to speech conversion using Festival
(Taylor et al. 98). By default, all narrative nodes
attempt to realize their goals as a speech media
type, using rules based on text length and
truncatability to less than 250 bytes to decide
when to use text-to-speech. The truncation
algorithm is based on dropping syntactic
constituents, using a method similar to (Mani et
al. 99). Captions are always realized, in addition,
as text (i.e., they have a text realization and a
possible audio realization).
Spatial layout is decided in the Presentation
Generator, after all the individual media objects
are created along with their temporal constraints
by the Content Executor. The layout algorithm
walks through the temporal ordering in
sequence, allocating a segment to each set of
objects that is designated to occur
simultaneously (grouped by par in the temporal
constraints). Each segment can have up to 4
frames, in each of which a media object is
displayed (thus, no more than 4 media objects
can be displayed at the same time). Since media
objects declared to be simultaneous (using par)
in the temporal constraints will go together in a
separate segment, the temporal constraints
determine what elements are grouped together in
a segment. The layout within a segment handles
two special cases. Captions are placed directly
underneath their associated media object.
Running text, when realized as text, is placed
beside the media object being described, so that
they are paired together visually. Thus,
coherence of a segment is influenced mainly by
the temporal constraints (which have been
fleshed out by the Content Creator to include
narrative nodes), with further handling of special
cases. Of course, an individual summarization
filter may choose to coordinate component
multimedia objects in particular ways in the
course of generating a composite multimedia
object.
Details such as duration and onset of particular
frames are specified in the translation to SMIL.
Duration is determined by the number of frames
present in a segment, unless there is an audio
media object in the segment (this media object
may have a spatial representation, e.g., as an
audio icon, or it may not). If an audio media
object occurs in a frame, the duration of all
media objects in that frame is equal to the length
of all the audio files in the segment. If there is
no audio present in a segment, the duration is a
seconds (a has a default value of 5) times the
number of frames created.
</bodyText>
<sectionHeader confidence="0.943631" genericHeader="method">
4 Summarization Filters
</sectionHeader>
<bodyText confidence="0.999991823529412">
As mentioned above, create goals are satisfied
by summarization filters, which create new
media objects summarizing information sources.
These programs are called summarization filters
because in the course of condensing information,
they take input information and turn it into some
more abstract and useful representation, filtering
out unimportant information. Such filters
provide a novel way of carrying out content
selection and creation for automated
presentation generation.
Our approach relies on component-based
software composition, i.e., assembly of software
units that have contractually specified interfaces
that can be independently deployed and reused.
The idea of assembling complex language
processing programs out of simpler ones is
</bodyText>
<page confidence="0.990061">
92
</page>
<bodyText confidence="0.989754421686748">
hardly new; however, by employing current
industry standards to specify the interaction
between the components, we simultaneously
increase the robustness of the system, ensure the
reusability of individual components and create
a more fully plug-and-play capability. Among
the core technology standards that support this
plug-and-play component assembly capability
are (a) Java interfaces, used to specify functions
that all summarization components must
implement in order to be used in the system, (b)
the JavaBeans standard, which allows the
parameters and methods of individual
components to be inspected by the system and
revealed to the users (c) the XML markup
standard, which we have adopted as an inter-
component communication language. Using
these technologies, legacy or third-party
summarizers are incorporated into .the system by
&amp;quot;wrapping&amp;quot; them so as to meet the interface
specification of the system. These technologies
also make possible a graphical environment to
assemble and configure complex summarization
filters from individual summarization
components.
Among the most important wins over the
traditional &amp;quot;piping&amp;quot; approach to filter assembly
is the ability to impose build-time restrictions on
the component assembly, disallowing &amp;quot;illegal&amp;quot;
compositions, e.g. component X cannot provide
input to component Y unless X&apos;s output type
corresponds to Y&apos;s input type. Build-time
restrictions such as these play a clear role in
increasing the overall robustness of the run-time
summarization system. Another build-time win
lies in the ability of JavaBeans to be serialized,
. i.e., written to disk in such a way as to preserve
the state of its parameters settings, ensuring that
every component in the system can be
configured and run at different times
independently of whether the component
provides a parameter file facility.
Establishing the standard functions required of a
summarization filter is challenging on several
fronts. One class of functions required by the
interface is necessary to handle the technicalities
of exchanging information between otherwise
discrete components. This set includes
functions for discovering a component&apos;s input
and output types, for handling messages,
exceptions and events passed between
components and for interpreting XML based on
one or more system-wide document type
definitions (DTDs). The other, more interesting
set of functions gets to the core of
summarization functionality. Selecting these
functions involves identifying parameters likely
to be broadly applicable across most or all
summarizers and finding ways to group them
and/or to generalize them. This is desirable in
order to reduce the burden on the end user of
understanding the subtle differences between the
. various settings in the summarizers available to
her.
An example of the difficulty inherent in this
endeavor is provided by the compression
(summary length divided by source length) vs.
reduction (I&apos;s complement of compression) vs.
target length paradigm. Different summarizers
will implement one or more of these. The
wrapper maps from the high-level interface
function, where the application/user can specify
either compression or target length, but not both,
to the individual summarizer&apos;s representation.
Thus, a user doesn&apos;t need to know which
representation(s) a particular summarizer uses
for reduction/compression.
A vanilla summarization Bean includes the
following functionality, which every summarizer
must be able to provide methods for:
source: documents to be summarized
(this can be a single document, or a
collection)
</bodyText>
<figureCaption confidence="0.639569375">
reduction-rate: either summary
size/source size, or target length
audience: user-focused or generic
(user-focused requires the specification
of a bag of terms, which can be of
different types)
output-type: specific data formats
(specified by DTDs)
</figureCaption>
<bodyText confidence="0.999994222222222">
The above are parameters which we expect all
summarizers to support. More specialized
summarizer beans can be constructed to reflect
groupings of summarizers. Among other
parameters are output-fluency, which specifies
whether a textual summary is to be made up of
passages (sentences, paras, blocks), named
entities, lists of words, phrases, or topics, etc.
Given that definitions of summarization in more
</bodyText>
<page confidence="0.995913">
93
</page>
<bodyText confidence="0.999868">
theoretical terms have not been entirely
satisfactory (Mani 2000), it is worth noting that
the above vanilla Bean provides an operational
definition of what a summarizer is.
</bodyText>
<subsectionHeader confidence="0.931909">
Pater Rep:diary
</subsectionHeader>
<bodyText confidence="0.999039625">
text, and segues. The captions and running text,
when not provided by the filters, are provided by
the script input. In the case of retrieve goals, the
objects may not have any meta-information, in
which case a default caption and running-text is
generated. Clearly, a system&apos;s explanatory
narrative will be enhanced by the availability of
rich meta-information.
</bodyText>
<figure confidence="0.8012374">
thY
(rumve,
Ectraact
fitter
Tod
</figure>
<bodyText confidence="0.9994324">
The segues are provided by the system. For
example, an item with a label &amp;quot;A biography of
- bin Laden&amp;quot; could result in a generated segue
&amp;quot;Here is a biography of bin Laden&amp;quot;. The
Content Creator, when providing content for
, narrative nodes, uses a variety of different
canned text patterns. For the above example, the
pattern would be &amp;quot;Here is @6.1abel&amp;quot;, where 6 is
the number of a non-narrative node, with label
being its label.
</bodyText>
<figureCaption confidence="0.625607">
Figure 2: Summarization Filter
</figureCaption>
<sectionHeader confidence="0.764517" genericHeader="method">
Composition
</sectionHeader>
<bodyText confidence="0.999855833333333">
In addition to its practical utility in the ability to
assimilate, combine and reuse components in
different combinations, and to do so within a
GUI, this approach is interesting because it
allows powerful summarization functions to be
created by composing together simpler tools.
</bodyText>
<listItem confidence="0.892698142857143">
• (Note that this is different from automatically
• finding the best combination, which our system
• does not address). For example, Figure 2
• illustrates a complex filter created by using a
GUI to compose together a named entity
extractor, a date extractor, a component which
• discovers significant associations between the
</listItem>
<bodyText confidence="0.983065875">
two and writes the result to a table, and a
visualizer which plots the results as a graph. The
resulting summarizer takes in a large collection
of documents, and produces as a summary a
graph (a jpeg) of salient named entity mentions
over time. Each of its components can be easily
reused within the filter composition system to
build other summarizers.
</bodyText>
<sectionHeader confidence="0.999333" genericHeader="method">
5 Narrative Summarization
</sectionHeader>
<bodyText confidence="0.999767666666667">
As mentioned above, the system can construct a
narrative to accompany the briefing. Narrative
nodes are generated to cover captions, running
</bodyText>
<figure confidence="0.940768941176471">
Peru Action Brief
1 Preamble
2 Situation Assessment
2.1 Chronology of Events
2.1.2 Latest document summary
create (&amp;quot;summarize -generic
-compression .1 4?eru/p32&amp;quot;)
2.2 Biographies
2.2.1 Biography of Victor Polay
2.2.1.1 Picture of @2.2.2.person
retrieve(&amp;quot; D Arawdatalpolay. jpg&amp;quot;)
2.2.1.2 Biography of ®2.2.2.persan
createcsummarize -bio -length 350
-span multi -person
@2.2.2.pers(3n -out table
4)erul*&amp;quot;)
3 Coda
</figure>
<figureCaption confidence="0.93751575">
&amp;quot;This briefing has assessed aspects of the
situation in Peru. Overall, the crisis
appears to be worsening.&amp;quot;
Figure 3: Input Script
</figureCaption>
<page confidence="0.995847">
94
</page>
<bodyText confidence="0.99997237037037">
All segue nodes are by default generated
automatically by the system, based on node
labels. We always introduce a segue node at the
beginning of the presentation (called a preamble
node), which provides a segue covering the
&amp;quot;crown&amp;quot; of the tree, i.e., all nodes upto a
particular depth d from the root (d=2) are
marked with segue nodes. A segue node is also
produced at the end (called a coda). (Both
preamble and segue can of course be specified
by the author if desired).
For introducing intervening segue nodes, we use
the following algorithm based on the distance
between nodes and the height in the tree. We
&apos; traverse the non-narrative leaves of the tree in
their temporal order, evaluating each pair of
adjacent nodes A and B where A precedes B
temporally. A segue is introduced between
nodes A and B if either (a) the maximum of the
2 distances from A and B to their least common
ancestor is greater than 3 nodes or (b) the sum of
the 2 distances from A and B to the least
common ancestor is greater than 4 nodes. This is
less intrusive than introducing segues at random
or between every pair of successive nodes, and
appears to perform better than introducing a
segue at each depth of the tree.
</bodyText>
<sectionHeader confidence="0.98106" genericHeader="method">
6 An Example
</sectionHeader>
<bodyText confidence="0.9998759">
We currently have a working version of the
system with a variety of different single and
multi-document summarization filters. Figure 3
shows an input script created by an author (the
scripts in Figure 3 and 4 are schematic
representations of the scripts, rather than the raw
XML). The script includes two create goals, one
with a single-document generic summarization
filter, the other with a multi-document user-
focused summarization filter. Figure 4 shows the
ground script which was created automatically
by the Content Creator component. Note the
addition of media type specifications, the
introduction of narrative nodes, and the
extension of the temporal constraints. The final
presentation generated is shown in Figure 5.
Here we show screen dumps of the six SMIL
segments produced, with the audio if any for
each segment indicated in this paper next to an
audio icon.
</bodyText>
<figure confidence="0.997533625">
Peru Action Brief
1 Preamble
audio = &amp;quot;In this briefing, I will go over
the @2.1abel. This will cover
@2.1.1abel and @2.3.1.1aber
2 Situation Assessment
2.1 &amp;quot;An overview of the @2.2.1aber
(Meta-2.2)
2.2 Chronology of Events
2.2.1 audio = &amp;quot;Here is the @2.2.2.1aber
(Meta-2.2.2)
2.2.2 text= &amp;quot;Latest document summary&amp;quot;
audio = text =
create (&amp;quot;summarize -generic
-compression .1 Iperu/p32&amp;quot;)
2.3 Biographies
2.3.1 audio =
&amp;quot;A profile of @,2.3.2.person&amp;quot;
(Meta-2.3.2)
2.3.2 Biography of Victor Polay
2.3.2.1 audio = text =
&amp;quot;A file photo of
@2.3.2.person&amp;quot;
(Meta-2.3.2.2)
2.3.2.2 Picture of @,2.3.2.person
image=
retrieve(&amp;quot;atrawdatalpolay. jpg&amp;quot;)
2.3.2.3 audio = text=
&amp;quot;Profile of @2.3.2.person&amp;quot;
(Meta-2.3.2.3)
2.3.2.4 Biography of @.2.3.2.person
audio = text =
create (&amp;quot;summarize -bio -length 350
-span multi -person
@2.2.2.person -out table
4oerul*&amp;quot;)
3 Coda
audio = &amp;quot;This briefing has assessed
aspects of the situation in Peru. Overall,
the crisis appears to be worsening.&amp;quot;
&lt;seq&gt;
&lt;par&gt;l&lt;/par&gt;
&lt;par&gt;2.2. 1 2.2.2&lt;/par&gt;
&lt;par&gt;2.3.1&lt;/par&gt;
&lt;par&gt;2.3.2.1 2.3.2.2
2.3.2.3 2. 3. 2.4&lt;/par&gt;
&lt;par&gt;3&lt;/par&gt;
&lt;/seq&gt;
</figure>
<figureCaption confidence="0.9993">
Figure 4: Ground Script
</figureCaption>
<page confidence="0.996998">
95
</page>
<sectionHeader confidence="0.99909" genericHeader="evaluation">
7 Status
</sectionHeader>
<bodyText confidence="0.999984695652174">
The summarization filters have incorporated
several summarizers, including some that have
been evaluated in the DARPA SUMMAC
conference (Mani et al. 99-1). These carry out
both single-document and multi-document
summarization, and include a preliminary
biographical summarizer we have developed.
The running text for the biography table in the
second-last segment of Figure 5 is produced
from meta-information in the table XML
generated by the biographical summarizer. The
production method for running text uses canned
text which should work for any input table
conforming to that DTD.
The summarization filters are being tested as
part of a DARPA situated test with end-users.
The briefing generator itself has been used
internally to generate numerous briefings, and
has been demonstrated as part of the DARPA
system. We also expect ,to carry out an
evaluation to assess the extent to which the
automation described here provides efficiency
gains in briefing production.
</bodyText>
<sectionHeader confidence="0.999976" genericHeader="related work">
8 Related Work
</sectionHeader>
<bodyText confidence="0.999836027777778">
There is a fair amount of work on automatic
authoring of multimedia presentations, e.g.,
(Wahlster et al. 93), (Dalai et al. 96), (Mittal et
al. 95), (Andre and Rist 97)5. These efforts
differ from ours in two ways: first, unlike us,
they are not open-domain; and, second, they
don&apos;t use summarization components. While
-such efforts are extremely sophisticated
compared to us in multimedia presentation
planning and fine-grained coordination and
synchronization capabilities, many of the
components used in those efforts are clearly
applicable to our work. For example, (Andre and
Rist 96) include methods for leveraging lifelike
characters in this process; these characters can
be leveraged in our work as well, to help
personify the computer narrator. In addition, our
captions, which are very short, rely on canned
text based on node labels in the initial script, or
based on shallow meta-information generated by
the summarization filter (in XML) along with
the created media object_ (Mittal et al. 95)
describe a variety of strategies for generation of
longer, more explanatory captions, some of
which may be exploited in our work by
deepening the level of meta-information, at least
for summarization components developed by us.
In our ability to leverage automatic
summarization, our work should be clearly
distinguished from work which attempts to
format a summary (from an XML
representation) into something akin to a
Powerpoint briefing, e.g., (Nagao and Hasida
98). Our work, by contrast, is focused on using
summarization in generating briefings from an
abstract outline.
</bodyText>
<sectionHeader confidence="0.999096" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.999902709677419">
We have described methods for leveraging
automatic summarization in the automatic
generation of multimedia briefings. This work
has taken. an open-domain approach, in order to
meet the requirements of the DARPA
application we are involved with. We believe
there is a stronger role that NL generation can
play in the narrative aspects of our briefmgs,
which currently rely for the most part on canned
text. Our future work on description merging in
biographical summaries, and on introducing
referring expressions into the narrative nodes,
would in effect take advantage of more powerful
generation methods, without sacrificing open-
domain capabilities. This may require much
richer meta-information specifications than the
ones we currently use.
Finally, we have begun the design of the Script
Creator GUI (the only component in Figure 1
remaining to be built). This will allow the author
to create scripts for the briefing generator
(instead of editing templates by hand), by laying
out icons for media objects in temporal order. A
user will be able to select a &amp;quot;standard&amp;quot; briefing
template from a menu, and then view it in a
briefing/template structure editor. The user can
then provide content by adding annotations to
any node in the briefing template. The user will
have a choice of saving the edit version in
template form, or in SMIL or possibly Microsoft
Powerpoint format.
</bodyText>
<page confidence="0.989541">
96
</page>
<reference confidence="0.568528533333333">
Peru Action Brief
• Executive Summary
o Hypothesis
o Options
• Situation Assessment
o Chronology of Events
o Biographies
• Structured Arguments
• Alternative Views
• Dedsions
In this briefing I will go over the situation
assessment. This will cover an overview of the
chronology of events and a profile of Victor
Polay.
Next, a biography of Victor Polay.
</reference>
<figure confidence="0.921879647058823">
A file photo of Victor Polay Profile of Victor Polay
-
VICTOR POLAY
IAiases: :Comandmue Rolando
rrupac Amara foimder,
ireivrian kuerrila
Occupation:leo/meander, former rebel
;leader. Me Thom Amara
:rebel? too kader
Educated !studied in both France
and Epain
1Wife: :Rosa Pea,
4.1other: :Oulu Campos de Po/ay_
Associates : :Alan Garcia
Here is an overview of the chronology of
events.
0
</figure>
<bodyText confidence="0.8720210625">
Here is the latest document summary.
Victor Polay, also known as Comandante
Rolando, is the Tupac Amaru founder, a
Peruvian guerrilla commander, a former rebel
leader, and the Tupac Amaru rebels&apos; top leader.
He studied in both France and Spain. His wife is
Rosa Polay and his mother is Otilia Campos de
Polay. His associates include Alan Garcia.
This briefing has assessed aspects of the
situation in Peru. Overall, the crisis appears to
be worsening.
1: CNN - Peruvian rebels release 2 hostages - Dec. 15th
3: About 200 hostages remained inaide the home of Japanese
Ambassador Moribisa Aoki, where Tupac Amaru rebels were
demanding the release from prison of about 400 of their
colleagues.
</bodyText>
<figure confidence="0.990796666666667">
(Original Documentl
.Latest document stuiuniary
. . .
</figure>
<figureCaption confidence="0.999503">
Figure 5: Presentation
</figureCaption>
<page confidence="0.999036">
97
</page>
<sectionHeader confidence="0.998312" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999541382978723">
Andre, E. and Rist, T. (1997) Towards a New
Generation of Hypermedia Systems: Extending
Automated Presentation Design for Hypermedia.
L. Dybkjaer, ed., Proceedings of the Third Spoken
Dialogue and Discourse Workshop, Topics in
Natural Interactive Systems 1. The Maersk Mc-
Kinney Moller Institute for Production
Technology, Odense University, Denmark, pp. 10-
27.
Dalai, M., Feiner, S., McKeown, K., Pan, S., Zhou,
M., Hollerer, T., Shaw, J., Feng, Y., and Fromer, J.
(1996) Negotiation for Automated Generation of
Temporal MultimediaPresentat ions. Proceedings
of ACM Multimedia &apos;96.
Mani, I., Gates, B., and Bloedorn, E. (1999)
Improving Summaries by Revising Them.
Proceedings of the 37th Annual Meeting of the
Association for Computational Linguistics, College
Park, MD, pp. 558-565.
Mani, I., Firmin, T., House, D., Klein, G., Sundheim,
B., and Hirschman, L. (1999) The TIPSTER
SUMMAC Text Summarization Evaluation.
Proceedings of EACL&apos;99, Bergen, Norway, pp. 77-
85.
Mani, I. (2000) Automatic Text Summarization. John
Benjamins Publishing Company. To appear.
Mittal, V., Roth, S., Moore, J., Mattis, J., and
Carenini, G. (1995) Generating Explanatory
Captions for Information Graphics. Proceedings of
the International Joint Conference on Artificial
Intelligence (IJCAI&apos;95), pp. 1276-1283.
Nagao, K. and K. Hasida, K. (1998) Automatic Text
Summarization Based on the Global Document
Annotation. Proceedings of COLING&apos;98, Montreal,
pp. 917-921.
Power, It and Scott, D. (1998) Multilingual
Authoring using Feedback Texts. Proceedings of
COL1NG&apos;98, Montreal, pp. 1053-1059.
Taylor, P., Black, A., and Caley, R. (1998) The
architecture of the Festival Speech Synthesis
System. Proceedings of the Third ESCA Workshop
on Speech Synthesis, Jenolan Caves, Australia, pp.
147-151.
Wahlster, W., Andre, E., Finlder, W., Profitlich, H.-
J., and Rist, T. (1993) Plan-Based Integration of
Natural Language and Graphics Generation. Al
Journal, 63.
</reference>
<page confidence="0.996187">
98
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.076880">
<title confidence="0.999453">Multi-document Summarization by Visualizing Topical Content</title>
<author confidence="0.999452">Rie Kubota Ando</author>
<affiliation confidence="0.992268">Department of Computer Science, Cornell University, Ithaca, NY</affiliation>
<address confidence="0.299099">kubotar@c s . corne 11 . edu</address>
<author confidence="0.599324">Branimir K Boguraev</author>
<author confidence="0.599324">Roy J Byrd</author>
<author confidence="0.599324">Mary S Neff T J Research Center</author>
<author confidence="0.599324">Saw Mill River Road</author>
<author confidence="0.599324">NY Hawthorne</author>
<email confidence="0.891445">bkb@watson.ibmcom</email>
<email confidence="0.891445">byrd@watson.ibmcom</email>
<email confidence="0.891445">neff@watson.ibmcom</email>
<abstract confidence="0.995016307692308">This paper describes a framework for multidocument summarization which combines three premises: coherent themes can be identified reliably; highly representative themes, running across subsets of the document collection, can function as multi-document summary surrogates; and effective end-use of such themes should be facilitated by a visualization environment which clarifies the relationship between themes and documents. We present algorithms that formalize our framework, describe an implementation, and demonstrate a prototype system and interface.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Peru</author>
</authors>
<title>Action Brief • Executive Summary o Hypothesis o Options • Situation Assessment o Chronology of Events o Biographies • Structured Arguments • Alternative Views • Dedsions In this briefing I will go over the situation assessment. This will cover an overview of the chronology of events and a profile of Victor Polay.</title>
<marker>Peru, </marker>
<rawString>Peru Action Brief • Executive Summary o Hypothesis o Options • Situation Assessment o Chronology of Events o Biographies • Structured Arguments • Alternative Views • Dedsions In this briefing I will go over the situation assessment. This will cover an overview of the chronology of events and a profile of Victor Polay.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Next</author>
</authors>
<title>a biography of Victor Polay.</title>
<marker>Next, </marker>
<rawString>Next, a biography of Victor Polay.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Andre</author>
<author>T Rist</author>
</authors>
<title>Towards a New Generation of Hypermedia Systems: Extending Automated Presentation Design for Hypermedia.</title>
<date>1997</date>
<booktitle>Proceedings of the Third Spoken Dialogue and Discourse Workshop, Topics in Natural Interactive Systems 1. The Maersk McKinney Moller Institute for Production Technology,</booktitle>
<pages>10--27</pages>
<editor>L. Dybkjaer, ed.,</editor>
<location>Odense University, Denmark,</location>
<marker>Andre, Rist, 1997</marker>
<rawString>Andre, E. and Rist, T. (1997) Towards a New Generation of Hypermedia Systems: Extending Automated Presentation Design for Hypermedia. L. Dybkjaer, ed., Proceedings of the Third Spoken Dialogue and Discourse Workshop, Topics in Natural Interactive Systems 1. The Maersk McKinney Moller Institute for Production Technology, Odense University, Denmark, pp. 10-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dalai</author>
<author>S Feiner</author>
<author>K McKeown</author>
<author>S Pan</author>
<author>M Zhou</author>
<author>T Hollerer</author>
<author>J Shaw</author>
<author>Y Feng</author>
<author>J Fromer</author>
</authors>
<title>Negotiation for Automated Generation of Temporal MultimediaPresentat ions.</title>
<date>1996</date>
<booktitle>Proceedings of ACM Multimedia &apos;96.</booktitle>
<marker>Dalai, Feiner, McKeown, Pan, Zhou, Hollerer, Shaw, Feng, Fromer, 1996</marker>
<rawString>Dalai, M., Feiner, S., McKeown, K., Pan, S., Zhou, M., Hollerer, T., Shaw, J., Feng, Y., and Fromer, J. (1996) Negotiation for Automated Generation of Temporal MultimediaPresentat ions. Proceedings of ACM Multimedia &apos;96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mani</author>
<author>B Gates</author>
<author>E Bloedorn</author>
</authors>
<title>Improving Summaries by Revising Them.</title>
<date>1999</date>
<booktitle>Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>558--565</pages>
<location>College Park, MD,</location>
<marker>Mani, Gates, Bloedorn, 1999</marker>
<rawString>Mani, I., Gates, B., and Bloedorn, E. (1999) Improving Summaries by Revising Them. Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, College Park, MD, pp. 558-565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mani</author>
<author>T Firmin</author>
<author>D House</author>
<author>G Klein</author>
<author>B Sundheim</author>
<author>L Hirschman</author>
</authors>
<title>The TIPSTER SUMMAC Text Summarization Evaluation.</title>
<date>1999</date>
<booktitle>Proceedings of EACL&apos;99,</booktitle>
<pages>77--85</pages>
<location>Bergen,</location>
<marker>Mani, Firmin, House, Klein, Sundheim, Hirschman, 1999</marker>
<rawString>Mani, I., Firmin, T., House, D., Klein, G., Sundheim, B., and Hirschman, L. (1999) The TIPSTER SUMMAC Text Summarization Evaluation. Proceedings of EACL&apos;99, Bergen, Norway, pp. 77-85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mani</author>
</authors>
<title>Automatic Text Summarization. John Benjamins Publishing Company. To</title>
<date>2000</date>
<booktitle>Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI&apos;95),</booktitle>
<pages>1276--1283</pages>
<contexts>
<context position="51654" citStr="Mani 2000" startWordPosition="8226" endWordPosition="8227">d requires the specification of a bag of terms, which can be of different types) output-type: specific data formats (specified by DTDs) The above are parameters which we expect all summarizers to support. More specialized summarizer beans can be constructed to reflect groupings of summarizers. Among other parameters are output-fluency, which specifies whether a textual summary is to be made up of passages (sentences, paras, blocks), named entities, lists of words, phrases, or topics, etc. Given that definitions of summarization in more 93 theoretical terms have not been entirely satisfactory (Mani 2000), it is worth noting that the above vanilla Bean provides an operational definition of what a summarizer is. Pater Rep:diary text, and segues. The captions and running text, when not provided by the filters, are provided by the script input. In the case of retrieve goals, the objects may not have any meta-information, in which case a default caption and running-text is generated. Clearly, a system&apos;s explanatory narrative will be enhanced by the availability of rich meta-information. thY (rumve, Ectraact fitter Tod The segues are provided by the system. For example, an item with a label &amp;quot;A biog</context>
</contexts>
<marker>Mani, 2000</marker>
<rawString>Mani, I. (2000) Automatic Text Summarization. John Benjamins Publishing Company. To appear. Mittal, V., Roth, S., Moore, J., Mattis, J., and Carenini, G. (1995) Generating Explanatory Captions for Information Graphics. Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI&apos;95), pp. 1276-1283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Nagao</author>
<author>K Hasida</author>
<author>K</author>
</authors>
<title>Automatic Text Summarization Based on the Global Document Annotation.</title>
<date>1998</date>
<booktitle>Proceedings of COLING&apos;98,</booktitle>
<pages>917--921</pages>
<location>Montreal,</location>
<marker>Nagao, Hasida, K, 1998</marker>
<rawString>Nagao, K. and K. Hasida, K. (1998) Automatic Text Summarization Based on the Global Document Annotation. Proceedings of COLING&apos;98, Montreal, pp. 917-921.</rawString>
</citation>
<citation valid="true">
<authors>
<author>It Power</author>
<author>D Scott</author>
</authors>
<title>Multilingual Authoring using Feedback Texts.</title>
<date>1998</date>
<booktitle>Proceedings of COL1NG&apos;98,</booktitle>
<pages>1053--1059</pages>
<location>Montreal,</location>
<marker>Power, Scott, 1998</marker>
<rawString>Power, It and Scott, D. (1998) Multilingual Authoring using Feedback Texts. Proceedings of COL1NG&apos;98, Montreal, pp. 1053-1059.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Taylor</author>
<author>A Black</author>
<author>R Caley</author>
</authors>
<title>The architecture of the Festival Speech Synthesis System.</title>
<date>1998</date>
<booktitle>Proceedings of the Third ESCA Workshop on Speech Synthesis, Jenolan Caves, Australia,</booktitle>
<pages>147--151</pages>
<marker>Taylor, Black, Caley, 1998</marker>
<rawString>Taylor, P., Black, A., and Caley, R. (1998) The architecture of the Festival Speech Synthesis System. Proceedings of the Third ESCA Workshop on Speech Synthesis, Jenolan Caves, Australia, pp. 147-151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wahlster</author>
<author>E Andre</author>
<author>W Finlder</author>
<author>H-J Profitlich</author>
<author>T Rist</author>
</authors>
<date>1993</date>
<journal>Plan-Based Integration of Natural Language and Graphics Generation. Al Journal,</journal>
<volume>63</volume>
<marker>Wahlster, Andre, Finlder, Profitlich, Rist, 1993</marker>
<rawString>Wahlster, W., Andre, E., Finlder, W., Profitlich, H.-J., and Rist, T. (1993) Plan-Based Integration of Natural Language and Graphics Generation. Al Journal, 63.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>