<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003384">
<title confidence="0.890836">
Using collocation segmentation to augment the phrase table
</title>
<author confidence="0.83425">
Carlos A. Henríquez Q.*, Marta R. Costa-jussà†, Vidas Daudaravicius$
</author>
<affiliation confidence="0.7340795">
Rafael E. Banchs†, José B. Mariño*
*TALP Research Center, Universitat Politècnica de Catalunya, Barcelona, Spain
</affiliation>
<email confidence="0.980881">
{carlos.henriquez,jose.marino}@upc.edu
</email>
<affiliation confidence="0.745427">
†Barcelona Media Innovation Center, Barcelona, Spain
</affiliation>
<email confidence="0.945782">
{marta.ruiz,rafael.banchs}@barcelonamedia.org
</email>
<affiliation confidence="0.983393">
$Faculty of Informatics, Vytautas Magnus University, Kaunas, Lithuania
</affiliation>
<email confidence="0.995079">
vidas@donelaitis.vdu.lt
</email>
<sectionHeader confidence="0.995524" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99992215">
This paper describes the 2010 phrase-based
statistical machine translation system de-
veloped at the TALP Research Center of
the UPC1 in cooperation with BMIC2 and
VMU3. In phrase-based SMT, the phrase
table is the main tool in translation. It is
created extracting phrases from an aligned
parallel corpus and then computing trans-
lation model scores with them. Performing
a collocation segmentation over the source
and target corpus before the alignment
causes that different and larger phrases
are extracted from the same original doc-
uments. We performed this segmentation
and used the union of this phrase set with
the phrase set extracted from the non-
segmented corpus to compute the phrase
table. We present the configurations con-
sidered and also report results obtained
with internal and official test sets.
</bodyText>
<sectionHeader confidence="0.998523" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998836">
The TALP Research Center of the UPC&apos; in coop-
eration with BMIC2 and VMU3 participated in the
Spanish-to-English WMT task. Our primary sub-
mission was a phrase-based SMT system enhanced
with POS tags and our contrastive submission was
an augmented phrase-based system using colloca-
tion segmentation (Costa-jussà et al., 2010), which
mainly is a way of introducing new phrases in the
translation table. This paper presents the descrip-
tion of both systems together with the results that
we obtained in the evaluation task and is organized
as follows: first, Section 2 and 3 present a brief de-
scription of a phrase-based SMT, followed by a gen-
eral explanation of collocation segmentation. Sec-
tion 4 presents the experimental framework, corpus
used and a description of the different systems built
for the translation task; the section ends showing
the results we obtained over the official test set. Fi-
nally, section 5 presents the conclusions obtained
from the experiments.
</bodyText>
<footnote confidence="0.945353666666667">
1Universitat Politècnica de Catalunya
2Barcelona Media Innovation Center
3Vytautas Magnus University
</footnote>
<sectionHeader confidence="0.94093" genericHeader="method">
2 Phrase-based SMT
</sectionHeader>
<bodyText confidence="0.999337181818182">
This approach to SMT performs the translation
splitting the source sentence in segments and as-
signing to each segment a bilingual phrase from
a phrase-table. Bilingual phrases are translation
units that contain source words and target words,
e.g. &lt; unidad de traduccion  |translation unit &gt;,
and have different scores associated to them. These
bilingual phrases are then sorted in order to max-
imize a linear combination of feature functions.
Such strategy is known as the log-linear model
(Och and Ney, 2003) and it is formally defined as:
</bodyText>
<equation confidence="0.984480333333333">
� M
A,.h,. (e, f) (1)
,.��
</equation>
<bodyText confidence="0.999834">
where h,. are different feature functions with
weights A,.. The two main feature functions
are the translation model (TM) and the target
language model (LM). Additional models include
POS target language models, lexical weights, word
penalty and reordering models among others.
</bodyText>
<sectionHeader confidence="0.981278" genericHeader="method">
3 Collocation segmentation
</sectionHeader>
<bodyText confidence="0.997461538461538">
Collocation segmentation is the process of de-
tecting boundaries between collocation segments
within a text (Daudaravicius and Marcinkeviciene,
2004). A collocation segment is a piece of text be-
tween boundaries. The boundaries are established
in two steps using two different measures: the Dice
score and a Average Minimum Law (AML).
The Dice score is used to measure the associa-
tion strength between two words. It has been used
before in the collocation compiler XTract (Smadja,
1993) and in the lexicon extraction system Cham-
pollion (Smadja et al., 1996). It is defined as fol-
lows:
</bodyText>
<equation confidence="0.980323">
2f (x, y)
Dice (x; y) = (2)
f (x) + f (y)
</equation>
<bodyText confidence="0.9999812">
where f (x, y) is the frequency of co-occurrence of
x and y, and f (x) and f (y) the frequencies of
occurrence of x and y anywhere in the text. It gives
high scores when x and y occur in conjunction.
The first step then establishes a boundary between
</bodyText>
<equation confidence="0.9817495">
e� = arg max
e
</equation>
<page confidence="0.975294">
98
</page>
<note confidence="0.451791">
Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 98–102,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999616777777778">
two adjacent words when the Dice score is lower
than a threshold t = exp(−8). Such a threshold
was established following the results obtained in
(Costa-jussà et al., 2010), where an integration of
this technique and a SMT system was performed
over the Bible corpus.
The second step of the procedure uses the AML.
It defines a boundary between words xi−1 and xi
when:
</bodyText>
<equation confidence="0.855265">
Dice (xi−2; xi−1) + Dice (xi; xi+1)
&gt; Dice (xi−1; xi)
2
(3)
</equation>
<bodyText confidence="0.997199666666667">
That is, the boundary is set when the Dice value
between words xi and xi−1 is lower than the aver-
age of preceding and following values.
</bodyText>
<sectionHeader confidence="0.998567" genericHeader="method">
4 Experimental Framework
</sectionHeader>
<bodyText confidence="0.99998175">
All systems were built using Moses (Koehn et al.,
2007), a state-of-the-art software for phrase-based
SMT. For preprocessing Spanish, we used Freeling
(Atserias et al., 2006), an open source library of
natural language analyzers. For English, we used
TnT (Brants, 2000) and Moses&apos; tokenizer. The
language models were built using SRILM (Stolcke,
2002).
</bodyText>
<subsectionHeader confidence="0.978143">
4.1 Corpus
</subsectionHeader>
<bodyText confidence="0.999692896551724">
This year, the translation task provided four dif-
ferent sources to collect corpora for the Spanish-
English pair. Bilingual corpora included version 5
of the Europarl Corpus (Koehn, 2005), the News
Commentary corpus and the United Nations cor-
pus. Additional English corpora was available from
the News corpus. The organizers also allowed the
use of the English Gigaword Third and Fourth Edi-
tion, released by the LDC. As for development
and internal test, the test sets from 2008 and 2009
translation tasks were available.
For our experiments, we selected as training data
the union of the Europarl and the News Commen-
tary. Development was performed with a section
of the 2008 test set and the 2009 test set was se-
lected as internal test. We deleted all empty lines,
removed pairs that were longer than 40 words, ei-
ther in Spanish or English; and also removed pairs
whose ratio between number of words were bigger
than 3.
As a preprocess, all corpora were lower-cased
and tokenized. The Spanish corpus was tokenized
and POS tags were extracted using Freeling, which
split clitics from verbs and also separated words
like ~del~ into ~de el~. In order to build a POS tar-
get language model, we also obtained POS tags
from the English corpus using the TnT tagger.
Statistics of the selected corpus can be seen in Ta-
ble 1.
</bodyText>
<table confidence="0.999244230769231">
Corpora Spanish English
Training sent 1,180,623 1,180,623
Running words 26,454,280 25,291,370
Vocabulary 118,073 89,248
Development sent 1,729 1,729
Running words 37,092 34,774
Vocabulary 7,025 6,199
Internal test sent 2,525 2,525
Running words 69,565 65,595
Vocabulary 10,539 8,907
Official test sent 2,489 -
Running words 66,714 -
Vocabulary 10,725 -
</table>
<tableCaption confidence="0.9249455">
Table 1: Statistics for the training, development
and test sets.
</tableCaption>
<table confidence="0.999761857142857">
Internal test Official test
Adjectives 137 72
Common nouns 369 188
Proper nouns 408 2,106
Verbs 213 128
Others 119 168
Total 1246 2662
</table>
<tableCaption confidence="0.9407435">
Table 2: Unknown words found in internal and
official test sets
</tableCaption>
<bodyText confidence="0.999947333333333">
It is important to notice that neither the United
Nations nor the Gigaword corpus were used for
bilingual training. Nevertheless, the English part
from the United Nations and the monolingual
News corpus were used to build the language model
of our systems.
</bodyText>
<subsubsectionHeader confidence="0.891253">
4.1.1 Unknown words
</subsubsectionHeader>
<bodyText confidence="0.999990384615385">
We analyzed the content from the internal and of-
ficial test and realized that they both contained
many words that were not seen in the training data.
Table 2 shows the number of unknown words found
in both sets, classified according to their POS.
In average, we may expect an unknown word
every two sentences in the internal test and more
than one per sentence in the official test set. It can
also be seen that most of those unknown words are
proper nouns, representing 32% and 79% of the
unknown sets, respectively. Common nouns were
the second most frequent type of unknown words,
followed by verbs and adjectives.
</bodyText>
<subsectionHeader confidence="0.841338">
4.2 Systems
</subsectionHeader>
<bodyText confidence="0.999314">
We submitted two different systems for the trans-
lation task. First a baseline using the training data
mentioned before; and then an augmented system,
where the baseline-extracted phrase list was ex-
tended with additional phrases coming from a seg-
mented version of the training corpus.
We also considered an additional system built
</bodyText>
<page confidence="0.993928">
99
</page>
<bodyText confidence="0.997444212765957">
with two different decoding path, a standard path
from words to words and POS and an alternative
path from stems to words and POS in the target
side. At the end, we did not submit this system
to the translation task because it did not provide
better results than the previous two in our internal
test.
The set of feature functions used include: source-
to-target and target-to-source relative frequen-
cies, source-to-target and target-to-source lexical
weights, word and phrase penalties, a target lan-
guage model, a POS target language model, and a
lexicalized reordering model (Tillman, 2004).
4.2.1 Considering stems as an alternate
decoding path.
Using Moses&apos; framework for factored translation
models we defined a system with two decoding
paths: one decoding path using words and the
other decoding path using stems in the source lan-
guage and words in the target language. Both de-
coding paths only had a single translation step.
The possibility of using multiple alternative decod-
ing path was developed by Birch et. al. (2007).
This system tried to solve the problem with the
unknown words. Because Spanish is morphologi-
cally richer than English, this alternative decoding
path allowed the decoder translate words that were
not seen in the training data and shared the same
root with other known words.
4.2.2 Expanding the phrase table using
collocation segmentation.
In order to build the augmented phrase table with
the technique mentioned in section 3, we seg-
mented each language of the bilingual corpus in-
dependently and then, using the collocation seg-
ments as words, we aligned the corpus and ex-
tracted the phrases from it. Once the phrases were
extracted, the segments of each phrase were split
again in words to have standard phrases. Finally,
we use the union of this phrases and the phrases
extracted from the baseline system to compute the
final phrase table. A diagram of the whole proce-
dure can be seen in figure 1.
The objective of this integration is to add new
phrases in the translation table and to enhance
the relative frequency of the phrases that were ex-
tracted from both methods.
</bodyText>
<subsubsectionHeader confidence="0.668436">
4.2.3 Language model interpolation.
</subsubsectionHeader>
<bodyText confidence="0.999571875">
Because SMT systems are trained with a bilingual
corpus, they ended highly tied to the domain the
corpus belong to. Therefore, when the documents
we want to translate belong to a different domain,
additional domain adaptation techniques are rec-
ommended to build the system. Those techniques
usually employ additional corpora that correspond
to the domain we want to translate from.
</bodyText>
<table confidence="0.54005575">
internal test
baseline 24.25
baseline+stem 23.45
augmented 23.9
</table>
<tableCaption confidence="0.997318">
Table 3: Internal test results.
</tableCaption>
<table confidence="0.996229">
test testcased−detok
baseline 26.1 25.1
augmented 26.1 25.1
</table>
<tableCaption confidence="0.999917">
Table 4: Results from translation task
</tableCaption>
<bodyText confidence="0.999989521739131">
The test set for this translation task comes from
the news domain, but most of our bilingual cor-
pora belonged to a political domain, the Europarl.
Therefore we use the additional monolingual cor-
pus to adapt the language model to the news do-
main.
The strategy used followed the experiment per-
formed last year in (R. Fonollosa et al., 2009).
We used SRILM during the whole process. All
language models were order five and used modi-
fied Kneser-Ney discount and interpolation. First,
we build three different language models accord-
ing to their domain: Europarl, United Nations and
news; then, we obtained the perplexity of each lan-
guage model over the News Commentary develop-
ment corpus; next, we used compute-best-mix to
obtain weights for each language model that di-
minish the global perplexity. Finally, the models
were combined using those weights.
In our experiments all systems used the resulting
language model, therefore the difference obtained
in our results were cause only by the translation
model.
</bodyText>
<subsectionHeader confidence="0.88348">
4.3 Results
</subsectionHeader>
<bodyText confidence="0.999770823529412">
We present results from the three systems devel-
oped this year. First, the baseline, which included
all the features mentioned in section 4.2; then, the
system with an alternative decoding path, called
baseline+stem; and finally the augmented system,
which integrated collocation segmentation to the
baseline. Internal test results can be seen in table
3. Automatic scores provided by the WMT 2010
organizers for the official test can be found in ta-
ble 4. All BLEU scores are case-insensitive and
tokenized except for the official test set which also
contains case-sensitive and non-tokenized score.
We obtained a BLEU score of 26.1 and 25.1 for
our case-insensitive and sensitive outputs, respec-
tively. The highest score was obtained by Uni-
versity of Cambridge, with 30.5 and 29.1 BLEU
points.
</bodyText>
<page confidence="0.985569">
100
</page>
<figureCaption confidence="0.9957625">
Figure 1: Example of the expansion of the phrase table using collocation segmentation. New phrases
added by the collocation-based system are marked with a **.
</figureCaption>
<subsectionHeader confidence="0.65859">
4.3.1 Comparing systems
</subsectionHeader>
<bodyText confidence="0.998626">
Once we obtained the translation outputs from the
baseline and the augmented system, we performed
a manual comparison of them. Even though we
did not find any significant advantages of the aug-
mented system over the baseline, the collocation
segmentation strategy chose a better morphologi-
cal structures in some cases as can be seen in Table
5 (only sentence sub-segments are shown):
</bodyText>
<sectionHeader confidence="0.986346" genericHeader="evaluation">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999967821428571">
We presented two different submissions for the
Spanish-English language pair. The language
model for both system was built interpolating two
big out-of-domain language models and one smaller
in-domain language model. The first system was a
baseline with POS target language model; and the
second one an augmented system, that integrates
the baseline with collocation segmentation. Re-
sults over the official test set showed no difference
in BLEU between these two, even though internal
results showed that the baseline obtained a better
score.
We also considered adding an additional decod-
ing path from stems to words in the baseline but
internal tests showed that it did not improve trans-
lation quality either. The high number of unknown
words found in Spanish suggested us that consider-
ing in parallel the simple form of stems could help
us achieve better results. Nevertheless, a deeper
study of the unknown set showed us that most
of those words were proper nouns, which do not
have inflection and therefore cannot benefited from
stems.
Finally, despite that internal test did not showed
an improvement with the augmented system, we
submitted it as a secondary run looking for the
effect these phrases could have over human evalu-
ation.
</bodyText>
<sectionHeader confidence="0.955889" genericHeader="conclusions">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.9999835">
The research leading to these results has received
funding from the European Community&apos;s Seventh
Framework Programme (FP7/2007-2013) under
grant agreement number 247762, from the Span-
ish Ministry of Science and Innovation through the
Buceador project (TEC2009-14094-C04-01) and
the Juan de la Cierva fellowship program. The
authors also wants to thank the Barcelona Media
Innovation Centre for its support and permission
to publish this research.
</bodyText>
<sectionHeader confidence="0.994815" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.8254005">
Jordi Atserias, Bernardino Casas, Elisabet
Comelles, Meritxell González, Lluís Padró, and
Muntsa Padró. 2006. FreeLing 1.3: Syntactic
and semantic services in an open-source NLP
</reference>
<page confidence="0.998664">
101
</page>
<note confidence="0.96005925">
Original: sabiendo que está recibiendo el premio
Baseline: knowing that it receive the prize
Augmented: knowing that he is receiving the prize
Original: muchos de mis amigos prefieren no separarla.
Baseline: many of my friends prefer not to separate them.
Augmented: many of my friends prefer not to separate it.
Original: Los estadounidenses contarán con un teléfono móvil
Baseline: The Americans have a mobile phone
Augmented: The Americans will have a mobile phone
Original: es plenamente consciente del camino más largo que debe emprender
Baseline: is fully aware of the longest journey must undertake
Augmented: is fully aware of the longest journey that need to be taken
</note>
<tableCaption confidence="0.998608">
Table 5: Comparison between baseline and augmented outputs
</tableCaption>
<reference confidence="0.99811471875">
library. In Proceedings of the fifth interna-
tional, conference on Language Resources and
Eval,uation (LREC 2006), ELRA, Genoa, Italy,
May.
Alexandra Birch, Miles Osborne, and Philipp
Koehn. 2007. Ccg supertags in factored statis-
tical machine translation. In StatMT &apos;07: Pro-
ceedings of the Second Workshop on Statistical,
Machine Transl,ation, pages 9~16, Morristown,
NJ, USA. Association for Computational Lin-
guistics.
Thorsten Brants. 2000. TnT ~ a statistical part-
of-speech tagger. In Proceedings of the Sixth
Appl,ied Natural, Language Processing (ANLP-
2000), Seattle, WA.
Marta R. Costa-jussà, Vidas Daudaravicius, and
Rafael E. Banchs. 2010. Integration of statisti-
cal collocation segmentations in a phrase-based
statistical machine translation system. In 14th
Annual, Conference of the European Association
for Machine Transl,ation.
Vidas Daudaravicius and Ruta Marcinkeviciene.
2004. Gravity counts for the boundaries of col-
locations. International, Journal, of Corpus Lin-
guistics, 9:321~348(28).
Philipp Koehn, Hieu Hoang, Alexandra Birch,
Chris Callison-Burch, Marcello Federico, Nicola
Bertoldi, Brooke Cowan, Wade Shen, Christine
Moran, Richard Zens, Chris Dyer, Ond°ej Bojar,
Alexandra Constantin, and Evan Herbst. 2007.
Moses: Open Source Toolkit for Statistical Ma-
chine Translation. In ACL &apos;07: Proceedings of
the 45th Annual, Meeting of the ACL on Interac-
tive Poster and Demonstration Sessions, pages
177~180, Morristown, NJ, USA. Association for
Computational Linguistics.
Philipp Koehn. 2005. Europarl: A Parallel Corpus
for Statistical Machine Translation. In Machine
Transl,ation Summit.
Franz Josef Och and Hermann Ney. 2003. A Sys-
tematic Comparison of Various Statistical Align-
ment Models. Computational, Linguistics, 29:19~
51.
José A. R. Fonollosa, Maxim Khalilov, Marta R.
Costa-jussá, José B. Mariño, Carlos A. Hen-
ríquez Q., Adolfo Hernández H., and Rafael E.
Banchs. 2009. The TALP-UPC phrase-based
translation system for EACL-WMT 2009. In
Proceedings of the Fourth Workshop on Statis-
tical, Machine Transl,ation, pages 85~89, Athens,
Greece, March. Association for Computational
Linguistics.
Frank A. Smadja, Kathleen McKeown, and
Vasileios Hatzivassiloglou. 1996. Translating
collocations for bilingual lexicons: A statistical
approach. Computational, Linguistics, 22(1):1~
38.
Frank Smadja. 1993. Retrieving collocations from
text: Xtract. Comput. Linguist., 19(1):143~177.
Andreas Stolcke. 2002. SRILM ~ an extensible
language modeling toolkit. pages 901~904.
Christoph Tillman. 2004. A Unigram Orientation
Model for Statistical Machine Translation. In
HLT-NAACL.
</reference>
<page confidence="0.998606">
102
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.444685">
<title confidence="0.999916">Using collocation segmentation to augment the phrase table</title>
<author confidence="0.997929">A Henríquez Marta R Vidas</author>
<affiliation confidence="0.79413175">E. José B. Research Center, Universitat Politècnica de Catalunya, Barcelona, Media Innovation Center, Barcelona, of Informatics, Vytautas Magnus University, Kaunas,</affiliation>
<email confidence="0.992279">vidas@donelaitis.vdu.lt</email>
<abstract confidence="0.998683142857143">This paper describes the 2010 phrase-based statistical machine translation system developed at the TALP Research Center of in cooperation with and In phrase-based SMT, the phrase table is the main tool in translation. It is created extracting phrases from an aligned parallel corpus and then computing translation model scores with them. Performing a collocation segmentation over the source and target corpus before the alignment causes that different and larger phrases are extracted from the same original documents. We performed this segmentation and used the union of this phrase set with the phrase set extracted from the nonsegmented corpus to compute the phrase table. We present the configurations considered and also report results obtained with internal and official test sets.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jordi Atserias</author>
<author>Bernardino Casas</author>
</authors>
<title>Elisabet Comelles, Meritxell González, Lluís Padró, and Muntsa Padró.</title>
<date>2006</date>
<booktitle>In Proceedings of the fifth international, conference on Language Resources and Eval,uation (LREC</booktitle>
<location>ELRA, Genoa, Italy,</location>
<marker>Atserias, Casas, 2006</marker>
<rawString>Jordi Atserias, Bernardino Casas, Elisabet Comelles, Meritxell González, Lluís Padró, and Muntsa Padró. 2006. FreeLing 1.3: Syntactic and semantic services in an open-source NLP library. In Proceedings of the fifth international, conference on Language Resources and Eval,uation (LREC 2006), ELRA, Genoa, Italy, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandra Birch</author>
<author>Miles Osborne</author>
<author>Philipp Koehn</author>
</authors>
<title>Ccg supertags in factored statistical machine translation.</title>
<date>2007</date>
<booktitle>In StatMT &apos;07: Proceedings of the Second Workshop on Statistical, Machine Transl,ation,</booktitle>
<pages>9--16</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<marker>Birch, Osborne, Koehn, 2007</marker>
<rawString>Alexandra Birch, Miles Osborne, and Philipp Koehn. 2007. Ccg supertags in factored statistical machine translation. In StatMT &apos;07: Proceedings of the Second Workshop on Statistical, Machine Transl,ation, pages 9~16, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
</authors>
<title>TnT ~ a statistical partof-speech tagger.</title>
<date>2000</date>
<booktitle>In Proceedings of the Sixth Appl,ied Natural, Language Processing (ANLP2000),</booktitle>
<location>Seattle, WA.</location>
<contexts>
<context position="5206" citStr="Brants, 2000" startWordPosition="820" endWordPosition="821">ver the Bible corpus. The second step of the procedure uses the AML. It defines a boundary between words xi−1 and xi when: Dice (xi−2; xi−1) + Dice (xi; xi+1) &gt; Dice (xi−1; xi) 2 (3) That is, the boundary is set when the Dice value between words xi and xi−1 is lower than the average of preceding and following values. 4 Experimental Framework All systems were built using Moses (Koehn et al., 2007), a state-of-the-art software for phrase-based SMT. For preprocessing Spanish, we used Freeling (Atserias et al., 2006), an open source library of natural language analyzers. For English, we used TnT (Brants, 2000) and Moses&apos; tokenizer. The language models were built using SRILM (Stolcke, 2002). 4.1 Corpus This year, the translation task provided four different sources to collect corpora for the SpanishEnglish pair. Bilingual corpora included version 5 of the Europarl Corpus (Koehn, 2005), the News Commentary corpus and the United Nations corpus. Additional English corpora was available from the News corpus. The organizers also allowed the use of the English Gigaword Third and Fourth Edition, released by the LDC. As for development and internal test, the test sets from 2008 and 2009 translation tasks we</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>Thorsten Brants. 2000. TnT ~ a statistical partof-speech tagger. In Proceedings of the Sixth Appl,ied Natural, Language Processing (ANLP2000), Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta R Costa-jussà</author>
<author>Vidas Daudaravicius</author>
<author>Rafael E Banchs</author>
</authors>
<title>Integration of statistical collocation segmentations in a phrase-based statistical machine translation system.</title>
<date>2010</date>
<booktitle>In 14th Annual, Conference of the European Association for Machine Transl,ation.</booktitle>
<contexts>
<context position="1630" citStr="Costa-jussà et al., 2010" startWordPosition="226" endWordPosition="229">riginal documents. We performed this segmentation and used the union of this phrase set with the phrase set extracted from the nonsegmented corpus to compute the phrase table. We present the configurations considered and also report results obtained with internal and official test sets. 1 Introduction The TALP Research Center of the UPC&apos; in cooperation with BMIC2 and VMU3 participated in the Spanish-to-English WMT task. Our primary submission was a phrase-based SMT system enhanced with POS tags and our contrastive submission was an augmented phrase-based system using collocation segmentation (Costa-jussà et al., 2010), which mainly is a way of introducing new phrases in the translation table. This paper presents the description of both systems together with the results that we obtained in the evaluation task and is organized as follows: first, Section 2 and 3 present a brief description of a phrase-based SMT, followed by a general explanation of collocation segmentation. Section 4 presents the experimental framework, corpus used and a description of the different systems built for the translation task; the section ends showing the results we obtained over the official test set. Finally, section 5 presents </context>
<context position="4520" citStr="Costa-jussà et al., 2010" startWordPosition="700" endWordPosition="703">ere f (x, y) is the frequency of co-occurrence of x and y, and f (x) and f (y) the frequencies of occurrence of x and y anywhere in the text. It gives high scores when x and y occur in conjunction. The first step then establishes a boundary between e� = arg max e 98 Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 98–102, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics two adjacent words when the Dice score is lower than a threshold t = exp(−8). Such a threshold was established following the results obtained in (Costa-jussà et al., 2010), where an integration of this technique and a SMT system was performed over the Bible corpus. The second step of the procedure uses the AML. It defines a boundary between words xi−1 and xi when: Dice (xi−2; xi−1) + Dice (xi; xi+1) &gt; Dice (xi−1; xi) 2 (3) That is, the boundary is set when the Dice value between words xi and xi−1 is lower than the average of preceding and following values. 4 Experimental Framework All systems were built using Moses (Koehn et al., 2007), a state-of-the-art software for phrase-based SMT. For preprocessing Spanish, we used Freeling (Atserias et al., 2006), an open</context>
</contexts>
<marker>Costa-jussà, Daudaravicius, Banchs, 2010</marker>
<rawString>Marta R. Costa-jussà, Vidas Daudaravicius, and Rafael E. Banchs. 2010. Integration of statistical collocation segmentations in a phrase-based statistical machine translation system. In 14th Annual, Conference of the European Association for Machine Transl,ation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vidas Daudaravicius</author>
<author>Ruta Marcinkeviciene</author>
</authors>
<title>Gravity counts for the boundaries of collocations.</title>
<date>2004</date>
<journal>International, Journal, of Corpus Linguistics,</journal>
<volume>348</volume>
<issue>28</issue>
<contexts>
<context position="3416" citStr="Daudaravicius and Marcinkeviciene, 2004" startWordPosition="503" endWordPosition="506"> order to maximize a linear combination of feature functions. Such strategy is known as the log-linear model (Och and Ney, 2003) and it is formally defined as: � M A,.h,. (e, f) (1) ,.�� where h,. are different feature functions with weights A,.. The two main feature functions are the translation model (TM) and the target language model (LM). Additional models include POS target language models, lexical weights, word penalty and reordering models among others. 3 Collocation segmentation Collocation segmentation is the process of detecting boundaries between collocation segments within a text (Daudaravicius and Marcinkeviciene, 2004). A collocation segment is a piece of text between boundaries. The boundaries are established in two steps using two different measures: the Dice score and a Average Minimum Law (AML). The Dice score is used to measure the association strength between two words. It has been used before in the collocation compiler XTract (Smadja, 1993) and in the lexicon extraction system Champollion (Smadja et al., 1996). It is defined as follows: 2f (x, y) Dice (x; y) = (2) f (x) + f (y) where f (x, y) is the frequency of co-occurrence of x and y, and f (x) and f (y) the frequencies of occurrence of x and y a</context>
</contexts>
<marker>Daudaravicius, Marcinkeviciene, 2004</marker>
<rawString>Vidas Daudaravicius and Ruta Marcinkeviciene. 2004. Gravity counts for the boundaries of collocations. International, Journal, of Corpus Linguistics, 9:321~348(28).</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Chris Dyer</author>
<author>Ond°ej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In ACL &apos;07: Proceedings of the 45th Annual, Meeting of the ACL on Interactive Poster and Demonstration Sessions,</booktitle>
<pages>177--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="4992" citStr="Koehn et al., 2007" startWordPosition="787" endWordPosition="790">the Dice score is lower than a threshold t = exp(−8). Such a threshold was established following the results obtained in (Costa-jussà et al., 2010), where an integration of this technique and a SMT system was performed over the Bible corpus. The second step of the procedure uses the AML. It defines a boundary between words xi−1 and xi when: Dice (xi−2; xi−1) + Dice (xi; xi+1) &gt; Dice (xi−1; xi) 2 (3) That is, the boundary is set when the Dice value between words xi and xi−1 is lower than the average of preceding and following values. 4 Experimental Framework All systems were built using Moses (Koehn et al., 2007), a state-of-the-art software for phrase-based SMT. For preprocessing Spanish, we used Freeling (Atserias et al., 2006), an open source library of natural language analyzers. For English, we used TnT (Brants, 2000) and Moses&apos; tokenizer. The language models were built using SRILM (Stolcke, 2002). 4.1 Corpus This year, the translation task provided four different sources to collect corpora for the SpanishEnglish pair. Bilingual corpora included version 5 of the Europarl Corpus (Koehn, 2005), the News Commentary corpus and the United Nations corpus. Additional English corpora was available from t</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ond°ej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In ACL &apos;07: Proceedings of the 45th Annual, Meeting of the ACL on Interactive Poster and Demonstration Sessions, pages 177~180, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A Parallel Corpus for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Machine Transl,ation Summit.</booktitle>
<contexts>
<context position="5485" citStr="Koehn, 2005" startWordPosition="863" endWordPosition="864">age of preceding and following values. 4 Experimental Framework All systems were built using Moses (Koehn et al., 2007), a state-of-the-art software for phrase-based SMT. For preprocessing Spanish, we used Freeling (Atserias et al., 2006), an open source library of natural language analyzers. For English, we used TnT (Brants, 2000) and Moses&apos; tokenizer. The language models were built using SRILM (Stolcke, 2002). 4.1 Corpus This year, the translation task provided four different sources to collect corpora for the SpanishEnglish pair. Bilingual corpora included version 5 of the Europarl Corpus (Koehn, 2005), the News Commentary corpus and the United Nations corpus. Additional English corpora was available from the News corpus. The organizers also allowed the use of the English Gigaword Third and Fourth Edition, released by the LDC. As for development and internal test, the test sets from 2008 and 2009 translation tasks were available. For our experiments, we selected as training data the union of the Europarl and the News Commentary. Development was performed with a section of the 2008 test set and the 2009 test set was selected as internal test. We deleted all empty lines, removed pairs that we</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A Parallel Corpus for Statistical Machine Translation. In Machine Transl,ation Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models.</title>
<date>2003</date>
<journal>Computational, Linguistics,</journal>
<volume>29</volume>
<pages>51</pages>
<contexts>
<context position="2904" citStr="Och and Ney, 2003" startWordPosition="427" endWordPosition="430">tat Politècnica de Catalunya 2Barcelona Media Innovation Center 3Vytautas Magnus University 2 Phrase-based SMT This approach to SMT performs the translation splitting the source sentence in segments and assigning to each segment a bilingual phrase from a phrase-table. Bilingual phrases are translation units that contain source words and target words, e.g. &lt; unidad de traduccion |translation unit &gt;, and have different scores associated to them. These bilingual phrases are then sorted in order to maximize a linear combination of feature functions. Such strategy is known as the log-linear model (Och and Ney, 2003) and it is formally defined as: � M A,.h,. (e, f) (1) ,.�� where h,. are different feature functions with weights A,.. The two main feature functions are the translation model (TM) and the target language model (LM). Additional models include POS target language models, lexical weights, word penalty and reordering models among others. 3 Collocation segmentation Collocation segmentation is the process of detecting boundaries between collocation segments within a text (Daudaravicius and Marcinkeviciene, 2004). A collocation segment is a piece of text between boundaries. The boundaries are establ</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. Computational, Linguistics, 29:19~ 51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>José A R Fonollosa</author>
<author>Maxim Khalilov</author>
<author>Marta R Costa-jussá</author>
<author>José B Mariño</author>
<author>Carlos A Henríquez Q</author>
<author>Adolfo Hernández H</author>
<author>Rafael E Banchs</author>
</authors>
<title>The TALP-UPC phrase-based translation system for EACL-WMT</title>
<date>2009</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical, Machine Transl,ation,</booktitle>
<pages>85--89</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Athens, Greece,</location>
<contexts>
<context position="11525" citStr="Fonollosa et al., 2009" startWordPosition="1864" endWordPosition="1867">sually employ additional corpora that correspond to the domain we want to translate from. internal test baseline 24.25 baseline+stem 23.45 augmented 23.9 Table 3: Internal test results. test testcased−detok baseline 26.1 25.1 augmented 26.1 25.1 Table 4: Results from translation task The test set for this translation task comes from the news domain, but most of our bilingual corpora belonged to a political domain, the Europarl. Therefore we use the additional monolingual corpus to adapt the language model to the news domain. The strategy used followed the experiment performed last year in (R. Fonollosa et al., 2009). We used SRILM during the whole process. All language models were order five and used modified Kneser-Ney discount and interpolation. First, we build three different language models according to their domain: Europarl, United Nations and news; then, we obtained the perplexity of each language model over the News Commentary development corpus; next, we used compute-best-mix to obtain weights for each language model that diminish the global perplexity. Finally, the models were combined using those weights. In our experiments all systems used the resulting language model, therefore the differenc</context>
</contexts>
<marker>Fonollosa, Khalilov, Costa-jussá, Mariño, Q, H, Banchs, 2009</marker>
<rawString>José A. R. Fonollosa, Maxim Khalilov, Marta R. Costa-jussá, José B. Mariño, Carlos A. Henríquez Q., Adolfo Hernández H., and Rafael E. Banchs. 2009. The TALP-UPC phrase-based translation system for EACL-WMT 2009. In Proceedings of the Fourth Workshop on Statistical, Machine Transl,ation, pages 85~89, Athens, Greece, March. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank A Smadja</author>
<author>Kathleen McKeown</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Translating collocations for bilingual lexicons: A statistical approach.</title>
<date>1996</date>
<journal>Computational, Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<pages>38</pages>
<contexts>
<context position="3823" citStr="Smadja et al., 1996" startWordPosition="572" endWordPosition="575">y and reordering models among others. 3 Collocation segmentation Collocation segmentation is the process of detecting boundaries between collocation segments within a text (Daudaravicius and Marcinkeviciene, 2004). A collocation segment is a piece of text between boundaries. The boundaries are established in two steps using two different measures: the Dice score and a Average Minimum Law (AML). The Dice score is used to measure the association strength between two words. It has been used before in the collocation compiler XTract (Smadja, 1993) and in the lexicon extraction system Champollion (Smadja et al., 1996). It is defined as follows: 2f (x, y) Dice (x; y) = (2) f (x) + f (y) where f (x, y) is the frequency of co-occurrence of x and y, and f (x) and f (y) the frequencies of occurrence of x and y anywhere in the text. It gives high scores when x and y occur in conjunction. The first step then establishes a boundary between e� = arg max e 98 Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 98–102, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics two adjacent words when the Dice score is lower than a threshold t = exp(−</context>
</contexts>
<marker>Smadja, McKeown, Hatzivassiloglou, 1996</marker>
<rawString>Frank A. Smadja, Kathleen McKeown, and Vasileios Hatzivassiloglou. 1996. Translating collocations for bilingual lexicons: A statistical approach. Computational, Linguistics, 22(1):1~ 38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
</authors>
<title>Retrieving collocations from text:</title>
<date>1993</date>
<journal>Xtract. Comput. Linguist.,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="3752" citStr="Smadja, 1993" startWordPosition="562" endWordPosition="563">include POS target language models, lexical weights, word penalty and reordering models among others. 3 Collocation segmentation Collocation segmentation is the process of detecting boundaries between collocation segments within a text (Daudaravicius and Marcinkeviciene, 2004). A collocation segment is a piece of text between boundaries. The boundaries are established in two steps using two different measures: the Dice score and a Average Minimum Law (AML). The Dice score is used to measure the association strength between two words. It has been used before in the collocation compiler XTract (Smadja, 1993) and in the lexicon extraction system Champollion (Smadja et al., 1996). It is defined as follows: 2f (x, y) Dice (x; y) = (2) f (x) + f (y) where f (x, y) is the frequency of co-occurrence of x and y, and f (x) and f (y) the frequencies of occurrence of x and y anywhere in the text. It gives high scores when x and y occur in conjunction. The first step then establishes a boundary between e� = arg max e 98 Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 98–102, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics two</context>
</contexts>
<marker>Smadja, 1993</marker>
<rawString>Frank Smadja. 1993. Retrieving collocations from text: Xtract. Comput. Linguist., 19(1):143~177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM ~ an extensible language modeling toolkit.</title>
<date>2002</date>
<pages>901--904</pages>
<contexts>
<context position="5287" citStr="Stolcke, 2002" startWordPosition="832" endWordPosition="833">a boundary between words xi−1 and xi when: Dice (xi−2; xi−1) + Dice (xi; xi+1) &gt; Dice (xi−1; xi) 2 (3) That is, the boundary is set when the Dice value between words xi and xi−1 is lower than the average of preceding and following values. 4 Experimental Framework All systems were built using Moses (Koehn et al., 2007), a state-of-the-art software for phrase-based SMT. For preprocessing Spanish, we used Freeling (Atserias et al., 2006), an open source library of natural language analyzers. For English, we used TnT (Brants, 2000) and Moses&apos; tokenizer. The language models were built using SRILM (Stolcke, 2002). 4.1 Corpus This year, the translation task provided four different sources to collect corpora for the SpanishEnglish pair. Bilingual corpora included version 5 of the Europarl Corpus (Koehn, 2005), the News Commentary corpus and the United Nations corpus. Additional English corpora was available from the News corpus. The organizers also allowed the use of the English Gigaword Third and Fourth Edition, released by the LDC. As for development and internal test, the test sets from 2008 and 2009 translation tasks were available. For our experiments, we selected as training data the union of the </context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM ~ an extensible language modeling toolkit. pages 901~904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph Tillman</author>
</authors>
<title>A Unigram Orientation Model for Statistical Machine Translation.</title>
<date>2004</date>
<booktitle>In HLT-NAACL.</booktitle>
<contexts>
<context position="9062" citStr="Tillman, 2004" startWordPosition="1460" endWordPosition="1461">itional system built 99 with two different decoding path, a standard path from words to words and POS and an alternative path from stems to words and POS in the target side. At the end, we did not submit this system to the translation task because it did not provide better results than the previous two in our internal test. The set of feature functions used include: sourceto-target and target-to-source relative frequencies, source-to-target and target-to-source lexical weights, word and phrase penalties, a target language model, a POS target language model, and a lexicalized reordering model (Tillman, 2004). 4.2.1 Considering stems as an alternate decoding path. Using Moses&apos; framework for factored translation models we defined a system with two decoding paths: one decoding path using words and the other decoding path using stems in the source language and words in the target language. Both decoding paths only had a single translation step. The possibility of using multiple alternative decoding path was developed by Birch et. al. (2007). This system tried to solve the problem with the unknown words. Because Spanish is morphologically richer than English, this alternative decoding path allowed the</context>
</contexts>
<marker>Tillman, 2004</marker>
<rawString>Christoph Tillman. 2004. A Unigram Orientation Model for Statistical Machine Translation. In HLT-NAACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>