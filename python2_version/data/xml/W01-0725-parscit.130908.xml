<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002023">
<title confidence="0.92581">
Clause Detection using HMM
</title>
<author confidence="0.664597">
Antonio Molina and Ferran Pla
</author>
<affiliation confidence="0.3589665">
Departament de Sistemes Informatics i Computaci6
Universitat Politecnica de Valencia (Spain)
</affiliation>
<note confidence="0.541773">
famolina,fplal dsic. upv. es
</note>
<sectionHeader confidence="0.995996" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999828">
In this work, we apply a specialized HMM ap-
proach to the shared task: clause identifica-
tion (Tjong Kim Sang and Dejean, 2001). The
HMM formalism (Rabiner and Juang, 1986) has
widely been used to solve other NLP problems,
such as POS tagging, chunking, partial parsing,
etc. A similar technique (Lexicalized HMM),
that takes into account certain words to lexi-
calize the contextual language model, was pre-
viously applied for solving POS tagging and
chunking problems (Pla et al., 2000b). Usually,
for these tasks, specialized HMMs perform bet-
ter than non-specialized HMMs (Pla, 2000a).
We used specialized HMMs to solve the three
parts of the task. Part 1 (clause start detection)
and Part 2 (clause end detection) are performed
as a tagging problem, that is, we assign the more
probable tag to each token of the input. Part
3 (embedded clause detection) is a more com-
plex task because the output must be correctly
balanced. Therefore, it is carried out in two
phases: first, we find the best sequence of tags
(segmentation in clauses) for the input sentence;
second, we correct some balancing inconsisten-
cies observed in the output by applying some
rules.
</bodyText>
<listItem confidence="0.5390035">
2 Clause detection as a tagging
problem
</listItem>
<bodyText confidence="0.996381727272727">
We consider clause detection to be tagging prob-
lem. From the statistical point of view, tagging
can be defined as a maximization problem.
Let 0 be a set of output tags and V the vo-
cabulary of the application. Given an input sen-
tence / = . . . ,&apos;IT, where i3 E V : Vj, the pro-
cess consists of finding the sequence of states of
maximum probability on the model. That is,
the sequence of output tags, 0 = 01, oT,
where o, E 0 : Vi. This process can be formal-
ized as follows:
</bodyText>
<equation confidence="0.959283">
= arg mr P(0 I/)
(P(0) P(IIC))
= arg max P (I)
) ; 0 E OT (1)
0
</equation>
<bodyText confidence="0.873191714285714">
Due to the fact that this maximization pro-
cess is independent of the input sequence, and
taking into account the Markov assumptions,
the problem is reduced to solving the following
equation (for a second—order HMM):
(ri P (0.i 10 j_i, 0 . i _2)
j:1...T
</bodyText>
<listItem confidence="0.9822665">
• P(ijI°.1)
(2)
</listItem>
<bodyText confidence="0.9742495">
The parameters of equation 2 can be repre-
sented as a second—order HMM whose states
correspond to a tag pair. Contextual probabil-
ities, P(o3lo3_1, 03_2) , represent the transition
probabilities between states and P(i3lo3) repre-
sents the output probabilities.
For this clause—splitting task, the available in-
formation consists of words, POS tags, chunk
tags, start tags (Part 1), end tags (Part 2) and
clause tags (Part 3). (See Figure 1).
In our approach, we must define the input
vocabulary (V) and the output vocabulary (0)
from the available information. We tested our
system with different combinations of this infor-
mation for each part of the task. Following, we
present the criteria that yield the best perfor-
mance on the development set.
For the three parts, we consider that in-
put sentences are composed of the sequence of
POS and Chunk tags associated to each word,
</bodyText>
<figure confidence="0.4598605">
arg max
01...0T
</figure>
<table confidence="0.992001">
WORDS POS CHUNK START END CLAUSE SP START SP END SP CLAUSE
The DT B-NP S X (S(S* DT—S DT—E DT—(S1(S2*
carrier NN I-NP x X * NN—X NN—X NN—*2
has VBZ B-VP x X * VBZ—X VBZ—X VBZ—*2
valuable JJ B-NP x X * JJ—X JJ—X JJ—*2
trans-Pacific JJ I-NP x X * JJ—X JJ—X JJ—*2
and CC I-NP x X * CC—X CC—X CC—*2
Asian JJ I-NP x X * JJ—X JJ—X JJ—*2
routes NNS I-NP x E *S) NNS—X NNS—E NNS—*S2)
but CC 0 x X * CC—X CC—X CC—*1
it PRP B-NP S X (S* PRP—S PRP—X PRP—(S2*
remains VBZ B-VP x X * VBZ—X VBZ—X VBZ—*2
debt-laden JJ B-ADJP x X * JJ—X JJ—X JJ—*2
and CC 0 x X * CC—X CC—X CC—*2
poorly RB B-ADVP x X * RB—X RB—X RB—*2
managed VBD B-VP x E *S) VBD—X VBD—E VBD—*S2)
• o x E *S) .—X .—E .—*S1)
</table>
<figureCaption confidence="0.9931095">
Figure 1: Example of the result of applying the specialization on the training set for the different
parts of the task.
</figureCaption>
<bodyText confidence="0.998623754385965">
I = (pi, chi), (P2, ch2), • • • ,(PT, chT)• There-
fore, the vocabulary of the application, V, is
defined as tuples (POS tag, Chunk tag).
The output vocabulary is different for each
part of the task. In Part 1, 0 = {S, X}; in
Part 2, 0 = {E, X}; and in Part 3, we consid-
ered the clause boundaries whose depth level
is lower than a certain value, that is, 0 =
{(S*, *S), *, (S * S), *S)S), . . . 1. In this case,
this value corresponds to the maximum depth
level observed in the training set.
Thus, given an input sentence /, the process
of clause detection consists of finding the se-
quence of states (the sequence of clause tags) of
maximum probability on the model. This pro-
cess is carried out by Dynamic Programming
Decoding using the Viterbi algorithm.
This basic model has two main drawbacks.
The first one is that the output tag set is too
generic to produce accurate models. Moreover,
in Part 3, the model does not assure a correct
balancing of the embedded clauses in the sen-
tence. To solve these problems, we define a tech-
nique which specializes the models. This tech-
nique consists of enriching the language model
by incorporating a set of features to the output
vocabulary.
In Part 1 and Part 2, we have relabeled the
output tag of an input word by adding the cor-
responding POS tag. In Part 3, we have also
added the number corresponding to the depth
level of the clause in the sentence in order to
reduce the incorrectly balanced clauses.
An example of the result of applying this spe-
cialization criteria to a sentence from the train-
ing sets can be seen in Figure 1 (see columns
with specialized —SP— tags).
We learnt the corresponding specialized
HMM for each part of the task using this new
training set. Each model was smoothed by ap-
plying a standard linear interpolation method.
Note that, when specialized HMMs are used,
no change is needed both in the learning and
the tagging processes. You simply have to map
the sequence of specialized output tags to the
original output tags. This substitution can be
done in a direct way.
In Part 3, the smoothed model guarantees
a complete coverage of the language, but does
not assure the correct balancing of the output.
Therefore, we have used some correcting rules
to repair the inconsistencies in the output. We
have applied the following rules:
1. If the clause segmentation presents more
start than end boundaries, we add the end
boundaries that are needed to the last word
in the sentence (just before the dot).
</bodyText>
<listItem confidence="0.9420496">
2. If the clause segmentation presents more
end that start boundaries, we add the start
boundaries that are needed to the first
word in the sentence.
3. If the sentence does not start with a start
</listItem>
<bodyText confidence="0.6493655">
boundary or does not finish with an end
boundary, we add these start and end tags.
</bodyText>
<sectionHeader confidence="0.987501" genericHeader="categories and subject descriptors">
3 Experimental Results
</sectionHeader>
<bodyText confidence="0.9999944375">
We considered second—order HMM (3—grams)
which were specialized according to the criteria
described above, taking as input the tuples of
POS and chunk tags associated to each word.
We also tested the system using other crite-
ria. We chose different input vocabularies: only
words, only POS, only chunks, etc. Moreover,
we used different specialization criteria: special-
izing with chunk tags, partial specialization, etc.
None of these criteria outperformed the results
reported in Table 1.
Although Part 1 and Part 2 were tasks that
seem to have a similar difficulty, the experi-
mental results show that clause end detection
is more difficult than clause start detection. We
think this could be because the relation between
POS and clause start is stronger than the rela-
tion between POS and clause end marks.
We performed two additional experiments.
First, we combined&apos; the output of Part 1 and
Part 2 in order to obtain Part 3 output. The ob-
tained results on the test set are lower than the
results presented in Table 1 (precision=70.74%;
recall= 58.62%; Fo_l= 64.11). Second, we de-
rived the output for Part 1 and Part 2 from the
output obtained in Part 3. In this case, we ob-
tained worse results for Part 1 (F0_1= 84.62),
but better results for Part 2 (F0_1= 84.24).
However, these results are not correct for the
shared task because we used the information of
embedded clauses which is not available for solv-
ing the first two parts.
</bodyText>
<sectionHeader confidence="0.999725" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.885145">
In this work, we have successfully applied a spe-
cialized HMM to a clause detection task. These
models have been specialized using different cri-
teria. The best results for Part 3 were ob-
tained considering POS and clause depth level
&apos;We have used the baseline script provided by the
workshop organizers.
</bodyText>
<table confidence="0.98314975">
development precision recall F0_1
part 1 89.21% 87.72% 88.46
part 2 78.81% 78.54% 78.68
part 3 70.70% 71.35% 71.03
test precision recall F0_1
part 1 88.15% 84.88% 86.48
part 2 79.63% 77.17% 78.38
part 3 69.62% 64.17% 66.79
</table>
<tableCaption confidence="0.99783">
Table 1: Results obtained for the development
</tableCaption>
<bodyText confidence="0.972386083333333">
and test data set for each part of the shared
task.
(F0_1= 66.79). Future works would include
testing other specialization criteria and study-
ing the way to incorporate the words in the
models (Lexicalized HMM).
Moreover, we think that a more detailed
study of the problem is needed to assure the
correct balancing of the output by including re-
strictions on the model; for example, modifying
the smoothing methods or including linguistic
restrictions.
</bodyText>
<sectionHeader confidence="0.9995" genericHeader="acknowledgments">
5 Acknowledgments
</sectionHeader>
<bodyText confidence="0.998859">
This work has been supported by the Spanish
research project CICYT TIC2000-0664—0O2-01
</bodyText>
<sectionHeader confidence="0.999248" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999490588235294">
Ferran Pla. 2000a. Etiquetado Lexico y Analisis
Sintactico Superficial basado en Modelos Es-
tadisticos. Ph.D. Thesis. Departament de
Sistemes Informatics i Computaci6. Universitat
Politecnica de Valencia, Spain.
Ferran Pla, Antonio Molina and Natividad Prieto.
2000b. Improving Chunking by means of Lexical-
Contextual Information in Statistical Language
Models. In Proceedings of 4th CoNLL-2000 and
LLL-2000, Lisbon, Portugal.
L. R. Rabiner and B. H. Juang. 1986. An Intro-
duction to Hidden Markov Models IEEE ASSP
MAGAZINE.
Erik F. Tjong Kim Sang and Herve Dejean. 2001.
Introduction to the con11-2001 shared task: Clause
identification. In Proceedings of the CoNLL-2001.
Toulouse, France.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.754846">
<title confidence="0.999833">Clause Detection using HMM</title>
<author confidence="0.999001">Antonio Molina</author>
<author confidence="0.999001">Ferran</author>
<affiliation confidence="0.997868">Departament de Sistemes Informatics i Universitat Politecnica de Valencia</affiliation>
<intro confidence="0.758832">famolina,fplal dsic. upv. es</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ferran Pla</author>
</authors>
<title>Etiquetado Lexico y Analisis Sintactico Superficial basado en Modelos Estadisticos.</title>
<date>2000</date>
<booktitle>Ph.D. Thesis. Departament de Sistemes Informatics i Computaci6. Universitat Politecnica de</booktitle>
<location>Valencia,</location>
<contexts>
<context position="774" citStr="Pla, 2000" startWordPosition="118" endWordPosition="119">dsic. upv. es 1 Introduction In this work, we apply a specialized HMM approach to the shared task: clause identification (Tjong Kim Sang and Dejean, 2001). The HMM formalism (Rabiner and Juang, 1986) has widely been used to solve other NLP problems, such as POS tagging, chunking, partial parsing, etc. A similar technique (Lexicalized HMM), that takes into account certain words to lexicalize the contextual language model, was previously applied for solving POS tagging and chunking problems (Pla et al., 2000b). Usually, for these tasks, specialized HMMs perform better than non-specialized HMMs (Pla, 2000a). We used specialized HMMs to solve the three parts of the task. Part 1 (clause start detection) and Part 2 (clause end detection) are performed as a tagging problem, that is, we assign the more probable tag to each token of the input. Part 3 (embedded clause detection) is a more complex task because the output must be correctly balanced. Therefore, it is carried out in two phases: first, we find the best sequence of tags (segmentation in clauses) for the input sentence; second, we correct some balancing inconsistencies observed in the output by applying some rules. 2 Clause detection as a t</context>
</contexts>
<marker>Pla, 2000</marker>
<rawString>Ferran Pla. 2000a. Etiquetado Lexico y Analisis Sintactico Superficial basado en Modelos Estadisticos. Ph.D. Thesis. Departament de Sistemes Informatics i Computaci6. Universitat Politecnica de Valencia, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ferran Pla</author>
<author>Antonio Molina</author>
<author>Natividad Prieto</author>
</authors>
<title>Improving Chunking by means of LexicalContextual Information in Statistical Language Models.</title>
<date>2000</date>
<booktitle>In Proceedings of 4th CoNLL-2000 and LLL-2000,</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="676" citStr="Pla et al., 2000" startWordPosition="102" endWordPosition="105">artament de Sistemes Informatics i Computaci6 Universitat Politecnica de Valencia (Spain) famolina,fplal dsic. upv. es 1 Introduction In this work, we apply a specialized HMM approach to the shared task: clause identification (Tjong Kim Sang and Dejean, 2001). The HMM formalism (Rabiner and Juang, 1986) has widely been used to solve other NLP problems, such as POS tagging, chunking, partial parsing, etc. A similar technique (Lexicalized HMM), that takes into account certain words to lexicalize the contextual language model, was previously applied for solving POS tagging and chunking problems (Pla et al., 2000b). Usually, for these tasks, specialized HMMs perform better than non-specialized HMMs (Pla, 2000a). We used specialized HMMs to solve the three parts of the task. Part 1 (clause start detection) and Part 2 (clause end detection) are performed as a tagging problem, that is, we assign the more probable tag to each token of the input. Part 3 (embedded clause detection) is a more complex task because the output must be correctly balanced. Therefore, it is carried out in two phases: first, we find the best sequence of tags (segmentation in clauses) for the input sentence; second, we correct some </context>
</contexts>
<marker>Pla, Molina, Prieto, 2000</marker>
<rawString>Ferran Pla, Antonio Molina and Natividad Prieto. 2000b. Improving Chunking by means of LexicalContextual Information in Statistical Language Models. In Proceedings of 4th CoNLL-2000 and LLL-2000, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L R Rabiner</author>
<author>B H Juang</author>
</authors>
<title>An Introduction to Hidden Markov Models</title>
<date>1986</date>
<journal>IEEE ASSP MAGAZINE.</journal>
<marker>Rabiner, Juang, 1986</marker>
<rawString>L. R. Rabiner and B. H. Juang. 1986. An Introduction to Hidden Markov Models IEEE ASSP MAGAZINE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik F Tjong Kim Sang</author>
<author>Herve Dejean</author>
</authors>
<title>Introduction to the con11-2001 shared task: Clause identification.</title>
<date>2001</date>
<booktitle>In Proceedings of the CoNLL-2001.</booktitle>
<location>Toulouse, France.</location>
<marker>Sang, Dejean, 2001</marker>
<rawString>Erik F. Tjong Kim Sang and Herve Dejean. 2001. Introduction to the con11-2001 shared task: Clause identification. In Proceedings of the CoNLL-2001. Toulouse, France.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>