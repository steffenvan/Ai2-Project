<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000273">
<title confidence="0.979232">
Resolution of Lexical Ambiguities in Spoken Dialogue Systems
</title>
<author confidence="0.731333">
Berenike Loos Robert Porzel
</author>
<affiliation confidence="0.701044">
European Media Laboratory, GmbH
</affiliation>
<address confidence="0.7819935">
Schloss-Wolfsbrtnnenweg 33
69118 Heidelberg, Germany
</address>
<email confidence="0.828163">
firstname.lastname@eml-d.villa-bosch.de
</email>
<sectionHeader confidence="0.988061" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999837352941176">
The development of conversational multi-
domain spoken dialogue systems poses new
challenges for the reliable processing of less re-
stricted user utterances. Unlike in controlled
and restricted dialogue systems a simple one-
to-one mapping from words to meanings is no
longer feasible here. In this paper two different
approaches to the resolution of lexical ambigu-
ities are applied to a multi-domain corpus of
speech recognition output produced from spon-
taneous utterances in a spoken dialogue sys-
tem. The resulting evaluations show that all
approaches yield significant gains over the ma-
jority class baseline performance of .68, i.e. f-
measures of .79 for the knowledge-driven ap-
proach and .86 for the supervised learning ap-
proach.
</bodyText>
<sectionHeader confidence="0.999128" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999396414285714">
Following Ide and Veronis (1998) we can distinguish
between data- and knowledge-driven word sense dis-
ambiguation (WSD). Given the basic distinction be-
tween written text and spoken utterances, we follow
Allen et al. (2001) and differentiate further between con-
trolled and conversational spoken dialogue systems. Nei-
ther data- nor knowledge-driven word sense disambigua-
tion has been performed on speech data stemming from
human interactions with dialogue systems, since multi-
domain conversational spoken dialogue systems for hu-
man computer interaction (HCI) have not existed in the
past. Now that speech data from multi-domain systems
have become available, corresponding experiments and
evaluations have become feasible.
In this paper we present the results of first word
sense disambiguation annotation experiments on data
from spoken interactions with multi-domain dialogue
systems. Additionally, we describe the results of a cor-
responding evaluation of a data- and a knowledge-driven
word sense disambiguation system on that data. For
knowledge-driven disambiguation we examined whether
the ontology-based method for computing semantic co-
herence introduced by Gurevych et al. (2003a) can be
employed to disambiguate between alternative interpre-
tations, i.e. concept representations, of a given speech
recognition hypothesis (SRH) at hand. We will show
the results of its evaluation in the semantic interpreta-
tion task of WSD. For example, in speech recognition
hypotheses containing forms of the German verb kom-
men, i.e. (to) come, a decision had to be made whether
its meaning corresponds to the motion sense or to the
showing sense, i.e. becoming mapped onto either a
MotionDirectedTransliteratedProcessora
WatchPerceptualProcess in the terminology of
our spoken language understanding system. For a data-
driven approach we employed a highly supervised learn-
ing algorithm introduced by Brants (2000) and trained
it on a corpus of annotated data. A second set of se-
mantically annotated speech recognition hypotheses was
employed as a gold-standard for evaluating both the
ontology-based and supervised learning method. Both
data sets were annotated by separate human annotators.
All annotated data stems from log files of an auto-
matic speech recognition system that was implemented in
the SMAxTKOM system (Wahlster et al., 2001; Wahlster,
2003). It is important to point out that there are at least
two essential differences between spontaneous speech
WSD and textual WSD, i.e.,
a smaller size of processable context as well as
imperfections, hesitations, disfluencies and speech
recognition errors.
Existing spoken language understanding systems,
that are not shallow and thusly produce deep syntac-
tic and semantic representations for multiple domains,
e.g. the production system approach described by
Engel (2002) or unification-based approaches described
by Crysmann et al. (2002), have shown to be more suit-
able for well-formed input but less robust in case of im-
perfect input. For conversational and reliable dialogue
systems that achieve satisfactory scores in evaluation
frameworks such as proposed by Walker et al. (2000) or
Beringer et al. (2002) for multi-modal dialogue systems,
we need robust knowledge- or data-driven methods for
disambiguating the sometimes less than ideal output of
the large vocabulary spontaneous speech recognizers. In
the long run, we would also like to avoid expensive pre-
processing work, which is necessary for both ontology-
driven and supervised learning methods, i.e. labor in-
tensive ontology engineering and data annotation respec-
tively.
</bodyText>
<sectionHeader confidence="0.441757" genericHeader="method">
2 State of the Art
</sectionHeader>
<bodyText confidence="0.999870333333333">
After work on WSD had overcome so-called early doubts
(Ide and Veronis, 1998) in the 1960’s, it was applied to
various NLP tasks, such as machine translation, informa-
tion retrieval, content and grammatical analysis and text
processing. Yarowsky (1995) used both supervised and
unsupervised WSD for correct phonetizitation of words
in speech synthesis. However, there is no recorded work
on processing speech recognition hypotheses resulting
from speech utterances as it is done in our research.
In general, following Ide and Veronis (1998) the various
WSD approaches of the past can be divided into two
types, i.e., data- and knowledge-based approaches.
</bodyText>
<sectionHeader confidence="0.847246" genericHeader="method">
2.1 Data-based Methods
</sectionHeader>
<bodyText confidence="0.999942037037037">
Data-based approaches extract their information directly
from texts and are divided into supervised and unsuper-
vised methods (Yarowsky, 1995; Stevenson, 2003).
Supervised methods work with a given (and therefore
limited) set of potential classes in the learning process.
For example, Yarowsky (1992) used a thesaurus to gener-
ate 1042 statistical models of the most general categories.
Weiss (1973) already showed that disambiguation rules
can successfully be learned from hand-tagged corpora.
Despite the small size of his training and test corpus, an
accuracy of 90 was achieved. Even better results on
a larger corpus were obtained by Kelly and Stone 1975
who included collocational, syntactic and part of speech
information to yield an accuracy of 93 on a larger cor-
pus. As always, supervised methods require a manually
annotated learning corpus.
Unsupervised methods do not determine the set of
classes before the learning process, but through analysis
of the given data by identifying clusters of similar cases.
One example is the algorithm for clustering by commit-
tee described by Pantel and Lin (2003), which automati-
cally discovers word senses from text. Generally, unsu-
pervised methods require large amounts of data. In the
case of spoken dialogue and speech recognition output
sufficient amounts of data will hopefully become avail-
able once multi-domain spoken dialogue systems are de-
ployed in real world applications.
</bodyText>
<subsectionHeader confidence="0.728352">
2.2 Knowledge-based Methods
</subsectionHeader>
<bodyText confidence="0.999986829787234">
Knowledge-based approaches work with lexica and/or
ontologies. The kind of knowledge varies widely and
machine-readable as well as computer lexica are em-
ployed. The knowledge-based approach employed herein
(Gurevych et al., 2003a) operates on an ontology partially
derived from FrameNet data (Baker et al., 1998) and de-
scribed by Gurevych et al. (2003b).
In a comparable approach Sussna (1993) worked with
the lexical reference system WordNet and used a similar
metric for the calculation of semantic distance of a num-
ber of input lexemes. Depending on the type of semantic
relation (hyperonymy, synonymy etc.) different weights
are given and his metric takes account of the number of
arcs of the same type leaving a node and the depth of a
given edge in the overall tree. The disambiguation results
on textual data reported by Sussna (1993) turned out to
be significantly better than chance. In contrast to many
other work on WSD with WordNet he took into account
not only the isa hierarchy, but other relational links as
well. The method is, therefore, similar to the one used
in this evaluation, with the difference that this one uses a
semantic-web conform ontology instead of WordNet and
it is applied to speech recognition hypotheses. The fact,
that our WSD work is done on SRHs makes it difficult
to compare the results with methods evaluated on textual
data such as in the past SENSEVAL studies (Edmonds,
2002).
The ontology-based system has been successfully used
for a set of tasks such as finding the best speech recog-
nition hypotheses from sets of competing SRHs, labeling
SRHs as correct or incorrect representations of the users
intention and for scoring their degree of contextual co-
herence (Gurevych et al., 2003a; Porzel and Gurevych,
2003; Porzel et al., 2003). In general, the system offers
an additional way of employing ontologies, i.e. to use
the knowledge modeled therein as the basis for evaluat-
ing the semantic coherence of sets of concepts. It can be
employed independent of the specific ontology language
used, as the underlying algorithm operates only on the
nodes and named edges of the directed graph represented
by the ontology. The specific knowledge base, e.g. writ-
ten in OIL-RDFS, DAML+OIL or OWL,&apos; is converted
into a graph, consisting of the class hierarchy, with each
class corresponding to a concept representing either an
entity or a process and their slots, i.e. the named edges
of the graph corresponding to the class properties, con-
straints and restrictions.
</bodyText>
<footnote confidence="0.9988175">
&apos;OIL-RDFS, DAML+OIL and OWL are frequently used
knowledge modeling languages originating in W3C and Se-
mantic Web projects. For more details, see www.w3c.org/RDF,
www.w3c.org/OWL and www.daml.org.
</footnote>
<sectionHeader confidence="0.883102" genericHeader="method">
3 Data and Annotation Experiment
</sectionHeader>
<bodyText confidence="0.999605">
In this section we describe the data collection and anno-
tation experiments performed in order to obtain indepen-
dent data sets for training and evaluation.
</bodyText>
<subsectionHeader confidence="0.998614">
3.1 Data Collection
</subsectionHeader>
<bodyText confidence="0.99999136">
The first data set was used for training the supervised
model is described in Gurevych et al. (2002b) and was
collected using the so-called Hidden Operator Test (Rapp
and Strube, 2002). This procedure represents a simplifi-
cation of classical end-to-end experiments and Wizard-
of-Oz experiments (Francony et al., 1992) - as it is con-
ductible without the technically very complex use of a
real or a seemingly real conversational system. The sub-
jects are prompted to ask for specific information and the
system response is pre-manufactured. We had 29 subjects
prompted to say certain inputs in 8 dialogues. 1479 turns
were recorded. In our experimental setup each user-turn
in the dialogue corresponded to a single illocution, e.g.
route request or sights information request as described
by Gurevych et al. (2002a).
The second data set was used for testing the data- and
ontology-based systems and thusly will be called the test
corpus. It was produced by means of Wizard-of-Oz ex-
periments (Francony et al., 1992). In this type of setting
a full-blown multimodal dialogue system is simulated by
a team of human hidden operators. A test person com-
municates with the supposed system and the dialogues
are recorded and filmed digitally. Here over 224 subjects
produced 448 dialogues (Schiel et al., 2002), employing
the same domains and tasks as in the first data collection.
</bodyText>
<subsectionHeader confidence="0.997646">
3.2 Data Pre-Processing
</subsectionHeader>
<bodyText confidence="0.999992166666666">
After manual segmentation of the data into single utter-
ances. The resulting audio files were then manually tran-
scribed. The segmented audio files were handed to the
speech recognition engine integrated in the SMAxTKOM
dialogue system (Wahlster, 2003). Employing the seman-
tic parsing system described by Engel (2002) the corre-
sponding speech recognition word lattices (Oerder and
Ney, 1993) were first transformed into n-best lists of so-
called hypotheses sequences. These were mapped onto
conceptual representations, which contain the multiple
semantic interpretations of the individual hypotheses se-
quences that arise due to lexical ambiguities.
For obtaining the training data, we used only the best,
correct and perfectly disambiguated speech recognition
hypotheses as described by Porzel et al. (2003) from the
first data set of 552 utterances. For obtaining the test
data we took a random sample of 3100 utterances from
the second data set. This seeming discrepancy between
training and test data is due to the fact that only a part of
the test data set actually contains ambiguous lexical items
and many of the utterances quite similar to each other.
For example, given the utterance shown in its transcribed
form in example (1), we then obtained the sequence of
recognition hypotheses shown in examples (1a) - (1e).
</bodyText>
<figure confidence="0.98192375">
1 wie komme ich in Heidelberg weiter.
how can I in Heidelberg continue.
1a Rennen Lied Comedy Show Heidelberg
Race song comedy show Heidelberg
weiter.
continue.
1b denn wie Comedy Heidelberg weiter.
then how comedy Heidelberg continue.
1c denn wie kommen Show weiter.
then how come show continue.
1d denn wie Comedy weiter.
then how comedy continue.
1e denn wie komme ich in Heidelberg
then how can I in Heidelberg
weiter.
continue.
</figure>
<subsectionHeader confidence="0.996109">
3.3 Annotation
</subsectionHeader>
<bodyText confidence="0.999933857142857">
We employed VISTAE2 (M¨uller, 2002) for annotat-
ing the data and for creating the corresponding gold-
standards for the training and test corpora. The annota-
tion of the data was done by two persons specially trained
for the annotation tasks, with different purposes:
First of all, if humans are able to annotate the data
reliably, it is generally more feasible that machines
are able to do that as well. This was the case as
shown by the resulting inter annotator agreement of
78.89 .
Secondly, a gold-standard is needed to evaluate the
systems’ performances. For that purpose, the anno-
tators reached an agreement on annotated items of
the test data which had differed in the first place.
The resulting gold-standard represents the highest
degree of correctly disambiguated data and is used
for comparison with the tagged data produced by the
disambiguation systems.
Thirdly, for the supervised learning another cor-
rectly disambiguated data set is needed for training
the statistical model.
</bodyText>
<footnote confidence="0.8454305">
2The acronym stands for Visualization Tool for Annotation
and Evaluation.
</footnote>
<bodyText confidence="0.999951444444445">
The class-based kappa statistic of (Cohen, 1960; Car-
letta, 1996) cannot be applied here, as the classes vary
depending on the number of ambiguities per entry in the
lexicon. Also an additional class, i.e., not-decidable
was allowed for cases as in SRH (1c), where it is impos-
sible to assign sensible meanings. The test data set alto-
gether was annotated with 2219 markables of ambiguous
tokens, stemming from 70 ambiguous words occurring in
the test corpus.
</bodyText>
<subsectionHeader confidence="0.997347">
3.4 Calculating the Baselines
</subsectionHeader>
<bodyText confidence="0.999976666666667">
For calculating the majority class baseline, which in our
case corresponds to the performance of a unigram tagger,
we applied the method described in (Porzel and Malaka,
2004). Therefore, all markables in the gold-standard
were counted and, corresponding to the frequency of each
concept of each ambiguous lexeme, the percentage of
correctly chosen concepts by means of selecting the most
frequent meaning was calculated. This resulted in a base-
line of 52.48 for the test data set.
</bodyText>
<sectionHeader confidence="0.988538" genericHeader="method">
4 Word Sense Disambiguation Systems
</sectionHeader>
<bodyText confidence="0.999946285714286">
Both word sense disambiguation systems described
herein were tested and developed with the SMARTKOM
research framework. As one of the most advanced current
systems, the SMARTKOM (Wahlster, 2003) comprises a
large set of input and output modalities together with an
efficient fusion and fission pipeline. SMARTKOM fea-
tures speech input with prosodic analysis, gesture input
via infrared camera, recognition of facial expressions and
their emotional states. On the output side, the system fea-
tures a gesturing and speaking life-like character together
with displayed generated text and multimedia graphical
output. It currently comprises nearly 50 modules running
on a parallel virtual machine-based integration software
called Multiplatform3 described in Herzog et al. (2003).
</bodyText>
<subsectionHeader confidence="0.998945">
4.1 The Knowledge-driven System
</subsectionHeader>
<bodyText confidence="0.999987272727273">
The ontology employed for the evaluation has about
800 concepts and 200 relations (apart from the isa-
relations defining the general taxonomy) and is described
by Gurevych et al. (2003b). It includes a generic top-
level ontology whose purpose is to provide a basic struc-
ture of the world, i.e. abstract classes to divide the uni-
verse in distinct parts as resulting from the ontological
analysis.4 The modeling of Processes and Physical Ob-
jects as a kind of event that is continuous and homoge-
neous in nature, follows the frame semantic analysis used
for generating the FRAMENET data (Baker et al., 1998).
</bodyText>
<footnote confidence="0.9927965">
3The abbreviation stands for “MUltiple Language / Target
Integration PLATform FOR Modules”.
4The top-level was developed following the procedure out-
lined in Russell and Norvig (1995).
</footnote>
<bodyText confidence="0.999321272727273">
The hierarchy of Processes is connected to the hierarchy
of Physical Objects via slot-constraint definitions herein
referred to as relations.
The system performs a number of processing steps. A
first preprocessing step is to convert each SRH into a
concept representation (CR). For that purpose the sys-
tem’s lexicon is used, which contains either zero, one
or many corresponding concepts for each entry. A sim-
ple vector of concepts - corresponding to the words in
the SRH for which entries in the lexicon exist - consti-
tutes each resulting CR. All other words with empty con-
cept mappings, e.g. articles, are ignored in the conver-
sion. Due to lexical ambiguity, i.e. the one to many
word - concept mappings, this processing step yields a
set of possible interpreta-
tions for each SRH.
For example, the words occurring in a SRH such as
(2) have the corresponding entries in the lexicon that are
shown below.
Since we have multiple concept entries for individual
words, i.e. lexical ambiguities, we get a resulting set
of concept representations.
</bodyText>
<equation confidence="0.58499">
2 Ich bin auf dem Philosphenweg
I am on the Philosopher’s Walk
</equation>
<table confidence="0.959132962962963">
entry
string Ich /string
concept Person /concept
/entry
entry
string bin /string
concept StaticSpatialProcess /concept
concept SelfIdentificationProcess /concept
concept NONE /concept
/entry
entry
string auf /string
concept TwoPointRelation /concept
concept NONE /concept
/entry
entry
string Philosophenweg /string
concept Location /concept
/entry
CR1 Person, StaticSpatialProcess, Location
CR2 Person, StaticSpatialProcess,
TwoPointRelation, Location
CR3 Person, SelfIdentificationProcess, Location
CR4 Person, SelfIdentificationProcess,
TwoPointRelation, Location
CR5 Person, TwoPointRelation, Location
CR6 Person, Location
</table>
<bodyText confidence="0.999924567567568">
The concept representations consist of a different num-
ber of concepts, because the concept none is not rep-
resented in the CRs. The concept none is assigned to
lexemes which have one (or more than one) meaning
outside the SmartKom domains or constitute functional
grammatical markers.
The system then converts the domain model, i.e. an
ontology, into a directed graph with concepts as nodes
and relations as edges. In order to find the shortest
path between two concepts, the ONTOSCORE system em-
ploys the single source shortest path algorithm of Dijk-
stra (Cormen et al., 1990). Thus, the minimal paths con-
necting a given concept with every other concept in CR
(excluding itself) are selected, resulting in an ma-
trix of the respective paths. To score the minimal paths
connecting all concepts with each other in a given CR,
a method proposed by Demetriou and Atwell (1994) to
score the semantic coherence of alternative sentence in-
terpretations against graphs based on the Longman Dic-
tionary of Contemporary English (LDOCE) was used in
the original system.5
The new addition made for this evaluation was to as-
sign different weights to the individual relations found
by the algorithm, depending on their level of granularity
within the relation hierarchy. For example, a broad level
relation such as has-theme which is found in the class
statement of Process is weighted with negative 1 as it
has only one super-relation, i.e. has-role, whereas a more
specific relation such as has-actor is weighted with neg-
ative 4 because it has four super-relations, i.e. has-artist,
has-associated-person(s), has-attribute and has-role.
As before, the algorithm selects from the set of all
paths between two concepts the one with the smallest
weight, i.e. the cheapest. The distances between all con-
cept pairs in CR are summed up to a total score.6 The set
of concepts with the lowest aggregate score represents the
combination with the highest semantic relatedness.
</bodyText>
<subsectionHeader confidence="0.998831">
4.2 The Data-driven System
</subsectionHeader>
<bodyText confidence="0.908252114285714">
In this section we describe the implementation of the sta-
tistical learning techniques employed for the task of per-
forming WSD on our corpus of spoken dialogue data.
For our experiments we took the general purpose sta-
tistical tagger (Brants, 2000), which is generally used for
part-of-speech tagging. It employs a VITERBI algorithm
for second order Markov models (Rabiner, 1989), linear
interpolation for smoothing and deleted interpolation for
5As defined by Demetriou and Atwell (1994),
is the set of direct relations (both isa and se-
mantic relations) that can connect two nodes (concepts); and
is the set of corresponding weights,
where the weight of each isa relation is set to and that of each
other relation to .
6Note that more specific relations subtract more then less
specific ones from the aggregate score.
determining the weights. According to Edmonds (2002),
WSD is in many ways similar to part-of-speech tagging
as it involves labeling every word in a text with a tag
from a pre-specified set of tag possibilities for each word
by using features of the context and other information.
This, together with the fact that we do not find cross-
paradigmatic ambiguities in our data, led to the idea to
use a part-of-speech tagger as a concept tagger.
In our case the tagset consisted of part-of-speech spe-
cific concepts of the SmartKom Ontology. The data we
used for preparing the model consisted of a combina-
tion of three gold-standard annotations, namely the best
SRHs, the correct SRHs and the correctly disambiguated
SRHs as described in Section 3.3. These were listed lex-
eme by lexeme with their corresponding concepts in a
file in the format expected by TnT. TnT used the file
to produce a new model, consisting of a trigram model
and a lexicon with lexemes and the concepts which cor-
responded to them as shown in Figure 1.
</bodyText>
<figureCaption confidence="0.998865">
Figure 1: Training the TnT Model
</figureCaption>
<bodyText confidence="0.99995905882353">
As one can see in Table 1, in our corpus the con-
cept Greeting occurred 38 times and was followed 20
times by Person, which itself was followed 13 times by
EmotionExperiencerSubjectProcess. Thisis
equivalent to an utterance beginning with ”Hello, I want
. . . ”.
The lexicon (see Table 2) shows how often a cer-
tain lexeme was tagged with which concept. For ex-
ample, the German TV channel ARD was tagged in all
occurrences with the concept Channel. The German
preposition am (at) occurred 17 times and in 12 cases it
was tagged as a TwoPointRelation, in one case as
TemporalTwoPointRelation and in 4 cases with
none. In cases in which the tagger cannot decide be-
tween different concepts, because of missing context, it
chooses the concept, which occurred most frequently in
the model according to the lexicon.
</bodyText>
<figure confidence="0.980985">
1st 2nd Tokens
Person 20
EmotionExperiencerSubjectProcess 13
none 3
StaticSpatialProcess 4
none 15
Person 3
none 3
WatchPerceptualProcess 3
InformationSearchProcess 2
MotionDirectedTransliterated 2
TvProgram 1
PatientMotionProcess 1
InformationSearchProcess 3
Person 2
none 1
Total Greeting Process 38
</figure>
<tableCaption confidence="0.993091">
Table 1: Part of the trigram for GreetingProcess
</tableCaption>
<table confidence="0.930204769230769">
Word Concept Tokens
ARD 7
Channel 7
am 17
TemporalTwoPointRelation 1
TwoPointRelation 12
none 4
kommen 5
MotionDirectedTransliterated 4
WatchPerceptualProcess 1
in 12
TwoPointRelation 8
none 4
</table>
<tableCaption confidence="0.996901">
Table 2: Part of the lexicon file: model.lex
</tableCaption>
<sectionHeader confidence="0.992669" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.9998087">
The percentage of correctly disambiguated lexemes from
both systems is calculated by the following formula:
. Where is he result in per-
cent, the number of lexemes that match with the gold-
standard, the number of not-decidable ones and the
number of total lexemes. As opposed to the human an-
notators, both systems always select a specific reading
and never assign the value not-decidable. For this
evaluation, therefore, we treat any concept occurring in a
not-decidable slot as correct.7
</bodyText>
<footnote confidence="0.4526985">
Such SRHs usually score below the consistency thresholds
described by Gurevych et al. (2003a) and are not passed on.
</footnote>
<subsectionHeader confidence="0.992604">
5.1 Evaluation Knowledge
</subsectionHeader>
<bodyText confidence="0.999949714285714">
For this evaluation, ONTOSCORE transformed the SRH
from our corpus into concept representations as described
above. To perform the WSD task, ONTOSCORE calcu-
lates a coherence score for each of these concept sets in
. The concepts in the highest ranked set are consid-
ered to be the ones representing the correct word mean-
ing in this context. OntoScore has two variations: Us-
ing the first variation, the relations between two con-
cepts are weighted for taxonomic relations and for
all others. The second mode allows each relation be-
ing assigned an individual weight as described in Section
4.1. For this purpose, the relations have been weighted
according to their level of generalization. More spe-
cific relations should indicate a higher degree of seman-
tic coherence and are therefore weighted cheaper, which
means that they - more likely - assign the correct mean-
ing. Compared to the gold-standard, the original method
of Gurevych et al. (2003a) reached a precision of 63.76
(f-measure = .78)8 as compared to 64.75 (f-measure
= .79) for the new method described herein (baseline
52.48 ).
</bodyText>
<subsectionHeader confidence="0.999391">
5.2 Evaluation Supervised
</subsectionHeader>
<bodyText confidence="0.999962818181818">
For the purpose of evaluating a supervised learning ap-
proach on our data we used the efficient and general sta-
tistical TnT tagger, the short form for Trigrams’n’Tags
(Brants, 2000). With this tagger it is possible to train
a new statistical model with any tagset. In our case the
tagset consisted of part-of-speech specific concepts of the
SmartKom ontology. The data we used for preparing
the model consisted of a gold-standard annotation of the
training data set. Compared to the gold-standard made for
the test corpus the method achieved a precision of 75.07
(baseline 52.48 ).
</bodyText>
<subsectionHeader confidence="0.998012">
5.3 Evaluation Comparison
</subsectionHeader>
<bodyText confidence="0.99970475">
For a direct comparison we computed f-measures for the
human reliability, the majority class baseline method as
well as for the knowledge-based and data-driven methods
in Table 3.
</bodyText>
<table confidence="0.998757">
Method F-measure Gain
Baseline .68 0
Knowledge (original) .78 11.28
Knowledge (relation) .79 12.27
Supervised .86 22.59
Annotator agreement .88 26.41
</table>
<tableCaption confidence="0.999337">
Table 3: F-measures and gains on the test data
</tableCaption>
<footnote confidence="0.594129">
$We calculate the standard f-measure (Van Rijsbergen,
1979) with by regarding the accuracy as precision and
recall as 100 .
</footnote>
<sectionHeader confidence="0.99251" genericHeader="discussions">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999716870967742">
In this paper we presented two methods for disam-
biguating speech recognition hypotheses. Both methods
showed significant gains over the majority class base-
line. The results also show that the statistical method
outperforms the ontology-based method. This is congru-
ent to findings from textual WSD methods, where the re-
sults from data-based approaches frequently yield better
scores. However, labeling and training times for these
methods are high and costly and they take up a signifi-
cant amount of memory space. Furthermore, if new do-
mains - featuring lexical ambiguites hitherto unseen by
the statistical model - are integrated into the system, new
models must consequently be trained in order to keep per-
formance up to par. In such cases, new annotated data has
to be made available.
The results of the knowledge-based approach show
that ontologies can be employed for such tasks even if
they have not been constructed specifically for WSD.
Since ontology engineering is at least as costly as annota-
tion and training of statistical models, alternative means
for ontology construction and learning need to be pursed.
Nonetheless, projects related the semantic web efforts
(Heflin and Hendler, 2000) continue to increase their cov-
erage and will become dynamically combinable so that
new domains can be integrated in less time without the
need of manually processed data.
Our future work will involve the testing of an unsuper-
vised method as well as the improvement of the presented
approaches. This will include a compression of the data-
based model and experiments concerning the scalability
of the knowledge-based approach.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999780714285714">
This work has been partially funded by the German Fed-
eral Ministry of Research and Technology (BMBF) as
part of the SmartKom project under Grant 01 IL 905C/0
and by the Klaus Tschira Foundation. The authors would
also like to thank Annika Scheffler and Vanessa Micelli
for their reliable annotation work and Rainer Malaka and
Hans-Peter Zorn for helpful comments on the paper.
</bodyText>
<sectionHeader confidence="0.998999" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.959455393548387">
James F. Allen, Donna K. Byron, Myroslava Dzikovska,
George Ferguson, Lucian Galescu, and Amanda Stent.
2001. Towards conversational human-computer inter-
action. AI Magazine.
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The Berkeley FrameNet Project. In Proceedings
of COLING-ACL, Montreal, Canada.
Nicole Beringer, Ute Kartal, Katerina Louka, Florian
Schiel, and Uli T¨urk. 2002. PROMISE: A Procedure
for Multimodal Interactive System Evaluation. In Pro-
ceedings of the Workshop ’Multimodal Resources and
Multimodal Systems Evaluation, Las Palmas, Spain.
Thorsten Brants. 2000. TnT – A statistical Part-of-
Speech tagger. In Proceedings of the 6th Confer-
ence on Applied Natural Language Processing, Seat-
tle, Wash.
Jean Carletta. 1996. Assessing agreement on classifi-
cation tasks: The kappa statistic. Computational Lin-
guistics, 22(2):249–254.
Jacob Cohen. 1960. A coefficient of agreement for nom-
inal scales. Educational and Psychological Measure-
ment, 20:37–46.
Thomas H. Cormen, Charles E. Leiserson, and Ronald R.
Rivest. 1990. Introduction to Algorithms. MIT press,
Cambridge, MA.
Berthold Crysmann, Anette Frank, Kiefer Bernd, Stefan
Mueller, Guenter Neumann, Jakub Piskorski, Ulrich
Schaefer, Melanie Siegel, Hans Uszkoreit, Feiyu Xu,
Markus Becker, and Hans-Ulrich Krieger. 2002. An
integrated archictecture for shallow and deep process-
ing. In Proceedings of the 40th Annual Meeting of the
Association for Computational Linguistics (ACL).
George Demetriou and Eric Atwell. 1994. A seman-
tic network for large vocabulary speech recognition.
In Lindsay Evett and Tony Rose, editors, Proceed-
ings of AISB workshop on Computational Linguistics
for Speech and Handwriting Recognition, University
of Leeds.
Philip Edmonds. 2002. SENSEVAL: The evaluation of
word sense disambiguation systems. ELRA Newslet-
ter, 7/3.
Ralf Engel. 2002. SPIN: Language understanding for
spoken dialogue systems using a production system ap-
proach. In Proceedings of the International Confer-
ence on Speech and Language Processing 2002, Den-
ver, USA.
J.-M. Francony, E. Kuijpers, and Y. Polity. 1992. To-
wards a methodology for wizard of oz experiments. In
Third Conference on Applied Natural Language Pro-
cessing, Trento, Italy, March.
Iryna Gurevych, Robert Porzel, and Michael Strube.
2002a. Annotating the semantic consistency of
speech recognition hypotheses. In Proceedings of the
Third SIGdial Workshop on Discourse and Dialogue,
Philadelphia, USA, July.
Iryna Gurevych, Michael Strube, and Robert Porzel.
2002b. Automatic classification of speech recognition
hypothesis. In Proceedings of the 3nd SIGdial Work-
shop on Discourse and Dialogue, Philadelphia, USA,
July 2002, pages 90–95.
Iryna Gurevych, Rainer Malaka, Robert Porzel, and
Hans-Peter Zorn. 2003a. Semantic coherence scoring
using an ontology. In Proceedings of the HLT/NAACL
2003, Edmonton, CN.
Iryna Gurevych, Robert Porzel, and Stefan Merten.
2003b. Less is more: Using a single knowledge rep-
resentation in dialogue systems. In Proceedings of
the HLT/NAACL Text Meaning Workshop, Edmonton,
Canada.
Jeff Heflin and James A. Hendler. 2000. Dynamic on-
tologies on the web. In Proceedings of AAAI/IAAI,
pages 443–449, Austin, Texas.
Gerd Herzog, Heinz Kirchmann, Stefan Merten, Alas-
sane Ndiaye, Peter Poller, and Tilman Becker. 2003.
MULTIPLATFORM: An integration platfrom for mul-
timodal dialogue systems. In Proceedings of the
HLT/NAACL SEALTS Workshop, Edmonton, Canada.
Nancy Ide and J. Veronis. 1998. Introduction to the spe-
cial issue on word sense disambiguation: The state of
the art. Computational Linguistics, 24/1.
Christof M¨uller. 2002. Kontextabh&amp;quot;ngige Bewertung der
Koh&amp;quot;renz von Spracherkennungshypothesen. Master
Thesis at the Institut f¨ur Informationstechnologie der
Fachhochschule Mannheim.
Martin Oerder and Hermann Ney. 1993. Word
graphs: An efficient interface between continuous-
speech recognition and language understanding. In
ICASSP Volume 2.
Patrick Pantel and Dekang Lin. 2003. Automatically
discovering word senses. In Bob Frederking and Bob
Younger, editors, HLT-NAACL 2003: Demo Session,
Edmonton, Alberta, Canada. Association for Compu-
tational Linguistics.
Robert Porzel and Iryna Gurevych. 2003. Contextual co-
herence in natural language processing. In P. Black-
burn, C. Ghidini, R. Turner, and F. Giunchiglia,
editors, Modeling and Using Context. LNAI 2680,
Sprigner, Berlin.
Robert Porzel and Rainer Malaka. 2004. Towards
measuring scalability in natural laguage understand-
ing tasks. In Proceedings of the HLT/NAACL Work-
shop on Scalable Natural Language Understanding,
Boston, USA. To appear.
Robert Porzel, Iryna Gurevych, and Christof M¨uller.
2003. Ontology-based contextual coherence scoring.
In Proceedings of the 4th SIGdial Workshop on Dis-
course and Dialogue, Saporo, Japan, July 2003.
L.R. Rabiner. 1989. A tutorial on hidden markov models
and selected applications in speech recognition. Pro-
ceedings of the IEEE, 77.
Stefan Rapp and Michael Strube. 2002. An iterative
data collection approach for multimodal dialogue sys-
tems. In Proceedings of the 3rd International Con-
ference on Language Resources and Evaluation, Las
Palmas, Spain.
Stuart J. Russell and Peter Norvig. 1995. Artificial In-
telligence. A Modern Approach. Prentice Hall, Engle-
wood Cliffs, N.J.
Florian Schiel, Silke Steininger, and Ulrich T¨urk. 2002.
The smartkom multimodal corpus at bas. In Proceed-
ings of the 3rd LREC, Las Palmas Spain.
Mark Stevenson. 2003. Word Sense Disambiguation:
The Case for Combining Knowldge Sources. CSLI.
Michael Sussna. 1993. Word sense disambiguation for
free text indexing using a massive semantic network.
In Proceedings ofthe Second International Conference
on Information and Knowledge Management.
C. J. Van Rijsbergen. 1979. Information Retrieval, 2nd
edition. Dept. of Computer Science, University of
Glasgow.
Wolfgang Wahlster, Norbert Reithinger, and Anselm
Blocher. 2001. Smartkom: Multimodal communica-
tion with a life-like character. In Proceedings of the
7th European Conference on Speech Communication
and Technology.
Wolfgang Wahlster. 2003. SmartKom: Symmetric mul-
timodality in an adaptive an reusable dialog shell. In
Proceedings of the Human Computer Interaction Sta-
tus Conference, Berlin, Germany.
Marilyn A. Walker, Candace A. Kamm, and Diane J. Lit-
man. 2000. Towards developing general model of us-
ability with PARADISE. Natural Language Engeneer-
ing, 6.
Stephen Weiss. 1973. Learning to disambiguate. Infor-
mation Storage and Retrieval, 9.
David Yarowsky. 1992. Word-sense disambiguation
using statistical models of roget’s categories trained
on large corpora. In Proceedings of the 15th In-
ternational Conference on Computational Linguistics,
Nantes, France, 23-28 August 1992, volume 1.
David Yarowsky. 1995. Unsupervised word sense disam-
biguation rivalling supervised methods. In Proceed-
ings of the 33rd Annual Meeting of the Association for
Computational Linguistics, Cambridge, Mass., 26–30
June 1995.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.379974">
<title confidence="0.999284">Resolution of Lexical Ambiguities in Spoken Dialogue Systems</title>
<author confidence="0.92316">Berenike Loos Robert Porzel</author>
<affiliation confidence="0.997073">European Media Laboratory,</affiliation>
<address confidence="0.8066675">Schloss-Wolfsbrtnnenweg 69118 Heidelberg,</address>
<email confidence="0.999574">firstname.lastname@eml-d.villa-bosch.de</email>
<abstract confidence="0.980911277777778">The development of conversational multidomain spoken dialogue systems poses new challenges for the reliable processing of less restricted user utterances. Unlike in controlled and restricted dialogue systems a simple oneto-one mapping from words to meanings is no longer feasible here. In this paper two different approaches to the resolution of lexical ambiguities are applied to a multi-domain corpus of speech recognition output produced from spontaneous utterances in a spoken dialogue system. The resulting evaluations show that all approaches yield significant gains over the majority class baseline performance of .68, i.e. fmeasures of .79 for the knowledge-driven approach and .86 for the supervised learning approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James F Allen</author>
<author>Donna K Byron</author>
<author>Myroslava Dzikovska</author>
<author>George Ferguson</author>
<author>Lucian Galescu</author>
<author>Amanda Stent</author>
</authors>
<title>Towards conversational human-computer interaction.</title>
<date>2001</date>
<journal>AI Magazine.</journal>
<contexts>
<context position="1187" citStr="Allen et al. (2001)" startWordPosition="169" endWordPosition="172"> lexical ambiguities are applied to a multi-domain corpus of speech recognition output produced from spontaneous utterances in a spoken dialogue system. The resulting evaluations show that all approaches yield significant gains over the majority class baseline performance of .68, i.e. fmeasures of .79 for the knowledge-driven approach and .86 for the supervised learning approach. 1 Introduction Following Ide and Veronis (1998) we can distinguish between data- and knowledge-driven word sense disambiguation (WSD). Given the basic distinction between written text and spoken utterances, we follow Allen et al. (2001) and differentiate further between controlled and conversational spoken dialogue systems. Neither data- nor knowledge-driven word sense disambiguation has been performed on speech data stemming from human interactions with dialogue systems, since multidomain conversational spoken dialogue systems for human computer interaction (HCI) have not existed in the past. Now that speech data from multi-domain systems have become available, corresponding experiments and evaluations have become feasible. In this paper we present the results of first word sense disambiguation annotation experiments on dat</context>
</contexts>
<marker>Allen, Byron, Dzikovska, Ferguson, Galescu, Stent, 2001</marker>
<rawString>James F. Allen, Donna K. Byron, Myroslava Dzikovska, George Ferguson, Lucian Galescu, and Amanda Stent. 2001. Towards conversational human-computer interaction. AI Magazine.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley FrameNet Project.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="7011" citStr="Baker et al., 1998" startWordPosition="1040" endWordPosition="1043">s from text. Generally, unsupervised methods require large amounts of data. In the case of spoken dialogue and speech recognition output sufficient amounts of data will hopefully become available once multi-domain spoken dialogue systems are deployed in real world applications. 2.2 Knowledge-based Methods Knowledge-based approaches work with lexica and/or ontologies. The kind of knowledge varies widely and machine-readable as well as computer lexica are employed. The knowledge-based approach employed herein (Gurevych et al., 2003a) operates on an ontology partially derived from FrameNet data (Baker et al., 1998) and described by Gurevych et al. (2003b). In a comparable approach Sussna (1993) worked with the lexical reference system WordNet and used a similar metric for the calculation of semantic distance of a number of input lexemes. Depending on the type of semantic relation (hyperonymy, synonymy etc.) different weights are given and his metric takes account of the number of arcs of the same type leaving a node and the depth of a given edge in the overall tree. The disambiguation results on textual data reported by Sussna (1993) turned out to be significantly better than chance. In contrast to many</context>
<context position="16244" citStr="Baker et al., 1998" startWordPosition="2521" endWordPosition="2524">dge-driven System The ontology employed for the evaluation has about 800 concepts and 200 relations (apart from the isarelations defining the general taxonomy) and is described by Gurevych et al. (2003b). It includes a generic toplevel ontology whose purpose is to provide a basic structure of the world, i.e. abstract classes to divide the universe in distinct parts as resulting from the ontological analysis.4 The modeling of Processes and Physical Objects as a kind of event that is continuous and homogeneous in nature, follows the frame semantic analysis used for generating the FRAMENET data (Baker et al., 1998). 3The abbreviation stands for “MUltiple Language / Target Integration PLATform FOR Modules”. 4The top-level was developed following the procedure outlined in Russell and Norvig (1995). The hierarchy of Processes is connected to the hierarchy of Physical Objects via slot-constraint definitions herein referred to as relations. The system performs a number of processing steps. A first preprocessing step is to convert each SRH into a concept representation (CR). For that purpose the system’s lexicon is used, which contains either zero, one or many corresponding concepts for each entry. A simple v</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet Project. In Proceedings of COLING-ACL, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicole Beringer</author>
<author>Ute Kartal</author>
<author>Katerina Louka</author>
<author>Florian Schiel</author>
<author>Uli T¨urk</author>
</authors>
<title>PROMISE: A Procedure for Multimodal Interactive System Evaluation.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop ’Multimodal Resources and Multimodal Systems Evaluation,</booktitle>
<location>Las Palmas,</location>
<marker>Beringer, Kartal, Louka, Schiel, T¨urk, 2002</marker>
<rawString>Nicole Beringer, Ute Kartal, Katerina Louka, Florian Schiel, and Uli T¨urk. 2002. PROMISE: A Procedure for Multimodal Interactive System Evaluation. In Proceedings of the Workshop ’Multimodal Resources and Multimodal Systems Evaluation, Las Palmas, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
</authors>
<title>TnT – A statistical Part-ofSpeech tagger.</title>
<date>2000</date>
<booktitle>In Proceedings of the 6th Conference on Applied Natural Language Processing,</booktitle>
<location>Seattle, Wash.</location>
<contexts>
<context position="2868" citStr="Brants (2000)" startWordPosition="413" endWordPosition="414"> given speech recognition hypothesis (SRH) at hand. We will show the results of its evaluation in the semantic interpretation task of WSD. For example, in speech recognition hypotheses containing forms of the German verb kommen, i.e. (to) come, a decision had to be made whether its meaning corresponds to the motion sense or to the showing sense, i.e. becoming mapped onto either a MotionDirectedTransliteratedProcessora WatchPerceptualProcess in the terminology of our spoken language understanding system. For a datadriven approach we employed a highly supervised learning algorithm introduced by Brants (2000) and trained it on a corpus of annotated data. A second set of semantically annotated speech recognition hypotheses was employed as a gold-standard for evaluating both the ontology-based and supervised learning method. Both data sets were annotated by separate human annotators. All annotated data stems from log files of an automatic speech recognition system that was implemented in the SMAxTKOM system (Wahlster et al., 2001; Wahlster, 2003). It is important to point out that there are at least two essential differences between spontaneous speech WSD and textual WSD, i.e., a smaller size of pro</context>
<context position="20386" citStr="Brants, 2000" startWordPosition="3164" endWordPosition="3165">has-role. As before, the algorithm selects from the set of all paths between two concepts the one with the smallest weight, i.e. the cheapest. The distances between all concept pairs in CR are summed up to a total score.6 The set of concepts with the lowest aggregate score represents the combination with the highest semantic relatedness. 4.2 The Data-driven System In this section we describe the implementation of the statistical learning techniques employed for the task of performing WSD on our corpus of spoken dialogue data. For our experiments we took the general purpose statistical tagger (Brants, 2000), which is generally used for part-of-speech tagging. It employs a VITERBI algorithm for second order Markov models (Rabiner, 1989), linear interpolation for smoothing and deleted interpolation for 5As defined by Demetriou and Atwell (1994), is the set of direct relations (both isa and semantic relations) that can connect two nodes (concepts); and is the set of corresponding weights, where the weight of each isa relation is set to and that of each other relation to . 6Note that more specific relations subtract more then less specific ones from the aggregate score. determining the weights. Acco</context>
<context position="25340" citStr="Brants, 2000" startWordPosition="3975" endWordPosition="3976">ation. More specific relations should indicate a higher degree of semantic coherence and are therefore weighted cheaper, which means that they - more likely - assign the correct meaning. Compared to the gold-standard, the original method of Gurevych et al. (2003a) reached a precision of 63.76 (f-measure = .78)8 as compared to 64.75 (f-measure = .79) for the new method described herein (baseline 52.48 ). 5.2 Evaluation Supervised For the purpose of evaluating a supervised learning approach on our data we used the efficient and general statistical TnT tagger, the short form for Trigrams’n’Tags (Brants, 2000). With this tagger it is possible to train a new statistical model with any tagset. In our case the tagset consisted of part-of-speech specific concepts of the SmartKom ontology. The data we used for preparing the model consisted of a gold-standard annotation of the training data set. Compared to the gold-standard made for the test corpus the method achieved a precision of 75.07 (baseline 52.48 ). 5.3 Evaluation Comparison For a direct comparison we computed f-measures for the human reliability, the majority class baseline method as well as for the knowledge-based and data-driven methods in Ta</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>Thorsten Brants. 2000. TnT – A statistical Part-ofSpeech tagger. In Proceedings of the 6th Conference on Applied Natural Language Processing, Seattle, Wash.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Carletta</author>
</authors>
<title>Assessing agreement on classification tasks: The kappa statistic.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>2</issue>
<contexts>
<context position="13894" citStr="Carletta, 1996" startWordPosition="2153" endWordPosition="2155">needed to evaluate the systems’ performances. For that purpose, the annotators reached an agreement on annotated items of the test data which had differed in the first place. The resulting gold-standard represents the highest degree of correctly disambiguated data and is used for comparison with the tagged data produced by the disambiguation systems. Thirdly, for the supervised learning another correctly disambiguated data set is needed for training the statistical model. 2The acronym stands for Visualization Tool for Annotation and Evaluation. The class-based kappa statistic of (Cohen, 1960; Carletta, 1996) cannot be applied here, as the classes vary depending on the number of ambiguities per entry in the lexicon. Also an additional class, i.e., not-decidable was allowed for cases as in SRH (1c), where it is impossible to assign sensible meanings. The test data set altogether was annotated with 2219 markables of ambiguous tokens, stemming from 70 ambiguous words occurring in the test corpus. 3.4 Calculating the Baselines For calculating the majority class baseline, which in our case corresponds to the performance of a unigram tagger, we applied the method described in (Porzel and Malaka, 2004). </context>
</contexts>
<marker>Carletta, 1996</marker>
<rawString>Jean Carletta. 1996. Assessing agreement on classification tasks: The kappa statistic. Computational Linguistics, 22(2):249–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Cohen</author>
</authors>
<title>A coefficient of agreement for nominal scales.</title>
<date>1960</date>
<booktitle>Educational and Psychological Measurement,</booktitle>
<pages>20--37</pages>
<contexts>
<context position="13877" citStr="Cohen, 1960" startWordPosition="2151" endWordPosition="2152">-standard is needed to evaluate the systems’ performances. For that purpose, the annotators reached an agreement on annotated items of the test data which had differed in the first place. The resulting gold-standard represents the highest degree of correctly disambiguated data and is used for comparison with the tagged data produced by the disambiguation systems. Thirdly, for the supervised learning another correctly disambiguated data set is needed for training the statistical model. 2The acronym stands for Visualization Tool for Annotation and Evaluation. The class-based kappa statistic of (Cohen, 1960; Carletta, 1996) cannot be applied here, as the classes vary depending on the number of ambiguities per entry in the lexicon. Also an additional class, i.e., not-decidable was allowed for cases as in SRH (1c), where it is impossible to assign sensible meanings. The test data set altogether was annotated with 2219 markables of ambiguous tokens, stemming from 70 ambiguous words occurring in the test corpus. 3.4 Calculating the Baselines For calculating the majority class baseline, which in our case corresponds to the performance of a unigram tagger, we applied the method described in (Porzel an</context>
</contexts>
<marker>Cohen, 1960</marker>
<rawString>Jacob Cohen. 1960. A coefficient of agreement for nominal scales. Educational and Psychological Measurement, 20:37–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas H Cormen</author>
<author>Charles E Leiserson</author>
<author>Ronald R Rivest</author>
</authors>
<title>Introduction to Algorithms.</title>
<date>1990</date>
<publisher>MIT press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="18737" citStr="Cormen et al., 1990" startWordPosition="2895" endWordPosition="2898">PointRelation, Location CR6 Person, Location The concept representations consist of a different number of concepts, because the concept none is not represented in the CRs. The concept none is assigned to lexemes which have one (or more than one) meaning outside the SmartKom domains or constitute functional grammatical markers. The system then converts the domain model, i.e. an ontology, into a directed graph with concepts as nodes and relations as edges. In order to find the shortest path between two concepts, the ONTOSCORE system employs the single source shortest path algorithm of Dijkstra (Cormen et al., 1990). Thus, the minimal paths connecting a given concept with every other concept in CR (excluding itself) are selected, resulting in an matrix of the respective paths. To score the minimal paths connecting all concepts with each other in a given CR, a method proposed by Demetriou and Atwell (1994) to score the semantic coherence of alternative sentence interpretations against graphs based on the Longman Dictionary of Contemporary English (LDOCE) was used in the original system.5 The new addition made for this evaluation was to assign different weights to the individual relations found by the algo</context>
</contexts>
<marker>Cormen, Leiserson, Rivest, 1990</marker>
<rawString>Thomas H. Cormen, Charles E. Leiserson, and Ronald R. Rivest. 1990. Introduction to Algorithms. MIT press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Berthold Crysmann</author>
<author>Anette Frank</author>
<author>Kiefer Bernd</author>
<author>Stefan Mueller</author>
<author>Guenter Neumann</author>
<author>Jakub Piskorski</author>
<author>Ulrich Schaefer</author>
<author>Melanie Siegel</author>
<author>Hans Uszkoreit</author>
<author>Feiyu Xu</author>
<author>Markus Becker</author>
<author>Hans-Ulrich Krieger</author>
</authors>
<title>An integrated archictecture for shallow and deep processing.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="3851" citStr="Crysmann et al. (2002)" startWordPosition="557" endWordPosition="560">that was implemented in the SMAxTKOM system (Wahlster et al., 2001; Wahlster, 2003). It is important to point out that there are at least two essential differences between spontaneous speech WSD and textual WSD, i.e., a smaller size of processable context as well as imperfections, hesitations, disfluencies and speech recognition errors. Existing spoken language understanding systems, that are not shallow and thusly produce deep syntactic and semantic representations for multiple domains, e.g. the production system approach described by Engel (2002) or unification-based approaches described by Crysmann et al. (2002), have shown to be more suitable for well-formed input but less robust in case of imperfect input. For conversational and reliable dialogue systems that achieve satisfactory scores in evaluation frameworks such as proposed by Walker et al. (2000) or Beringer et al. (2002) for multi-modal dialogue systems, we need robust knowledge- or data-driven methods for disambiguating the sometimes less than ideal output of the large vocabulary spontaneous speech recognizers. In the long run, we would also like to avoid expensive preprocessing work, which is necessary for both ontologydriven and supervised</context>
</contexts>
<marker>Crysmann, Frank, Bernd, Mueller, Neumann, Piskorski, Schaefer, Siegel, Uszkoreit, Xu, Becker, Krieger, 2002</marker>
<rawString>Berthold Crysmann, Anette Frank, Kiefer Bernd, Stefan Mueller, Guenter Neumann, Jakub Piskorski, Ulrich Schaefer, Melanie Siegel, Hans Uszkoreit, Feiyu Xu, Markus Becker, and Hans-Ulrich Krieger. 2002. An integrated archictecture for shallow and deep processing. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Demetriou</author>
<author>Eric Atwell</author>
</authors>
<title>A semantic network for large vocabulary speech recognition.</title>
<date>1994</date>
<booktitle>Proceedings of AISB workshop on Computational Linguistics for Speech and Handwriting Recognition,</booktitle>
<editor>In Lindsay Evett and Tony Rose, editors,</editor>
<location>University of Leeds.</location>
<contexts>
<context position="19032" citStr="Demetriou and Atwell (1994)" startWordPosition="2946" endWordPosition="2949">nstitute functional grammatical markers. The system then converts the domain model, i.e. an ontology, into a directed graph with concepts as nodes and relations as edges. In order to find the shortest path between two concepts, the ONTOSCORE system employs the single source shortest path algorithm of Dijkstra (Cormen et al., 1990). Thus, the minimal paths connecting a given concept with every other concept in CR (excluding itself) are selected, resulting in an matrix of the respective paths. To score the minimal paths connecting all concepts with each other in a given CR, a method proposed by Demetriou and Atwell (1994) to score the semantic coherence of alternative sentence interpretations against graphs based on the Longman Dictionary of Contemporary English (LDOCE) was used in the original system.5 The new addition made for this evaluation was to assign different weights to the individual relations found by the algorithm, depending on their level of granularity within the relation hierarchy. For example, a broad level relation such as has-theme which is found in the class statement of Process is weighted with negative 1 as it has only one super-relation, i.e. has-role, whereas a more specific relation suc</context>
<context position="20626" citStr="Demetriou and Atwell (1994)" startWordPosition="3196" endWordPosition="3199">set of concepts with the lowest aggregate score represents the combination with the highest semantic relatedness. 4.2 The Data-driven System In this section we describe the implementation of the statistical learning techniques employed for the task of performing WSD on our corpus of spoken dialogue data. For our experiments we took the general purpose statistical tagger (Brants, 2000), which is generally used for part-of-speech tagging. It employs a VITERBI algorithm for second order Markov models (Rabiner, 1989), linear interpolation for smoothing and deleted interpolation for 5As defined by Demetriou and Atwell (1994), is the set of direct relations (both isa and semantic relations) that can connect two nodes (concepts); and is the set of corresponding weights, where the weight of each isa relation is set to and that of each other relation to . 6Note that more specific relations subtract more then less specific ones from the aggregate score. determining the weights. According to Edmonds (2002), WSD is in many ways similar to part-of-speech tagging as it involves labeling every word in a text with a tag from a pre-specified set of tag possibilities for each word by using features of the context and other in</context>
</contexts>
<marker>Demetriou, Atwell, 1994</marker>
<rawString>George Demetriou and Eric Atwell. 1994. A semantic network for large vocabulary speech recognition. In Lindsay Evett and Tony Rose, editors, Proceedings of AISB workshop on Computational Linguistics for Speech and Handwriting Recognition, University of Leeds.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Edmonds</author>
</authors>
<title>SENSEVAL: The evaluation of word sense disambiguation systems.</title>
<date>2002</date>
<journal>ELRA Newsletter,</journal>
<volume>7</volume>
<contexts>
<context position="8117" citStr="Edmonds, 2002" startWordPosition="1232" endWordPosition="1233">extual data reported by Sussna (1993) turned out to be significantly better than chance. In contrast to many other work on WSD with WordNet he took into account not only the isa hierarchy, but other relational links as well. The method is, therefore, similar to the one used in this evaluation, with the difference that this one uses a semantic-web conform ontology instead of WordNet and it is applied to speech recognition hypotheses. The fact, that our WSD work is done on SRHs makes it difficult to compare the results with methods evaluated on textual data such as in the past SENSEVAL studies (Edmonds, 2002). The ontology-based system has been successfully used for a set of tasks such as finding the best speech recognition hypotheses from sets of competing SRHs, labeling SRHs as correct or incorrect representations of the users intention and for scoring their degree of contextual coherence (Gurevych et al., 2003a; Porzel and Gurevych, 2003; Porzel et al., 2003). In general, the system offers an additional way of employing ontologies, i.e. to use the knowledge modeled therein as the basis for evaluating the semantic coherence of sets of concepts. It can be employed independent of the specific onto</context>
<context position="21009" citStr="Edmonds (2002)" startWordPosition="3263" endWordPosition="3264">s generally used for part-of-speech tagging. It employs a VITERBI algorithm for second order Markov models (Rabiner, 1989), linear interpolation for smoothing and deleted interpolation for 5As defined by Demetriou and Atwell (1994), is the set of direct relations (both isa and semantic relations) that can connect two nodes (concepts); and is the set of corresponding weights, where the weight of each isa relation is set to and that of each other relation to . 6Note that more specific relations subtract more then less specific ones from the aggregate score. determining the weights. According to Edmonds (2002), WSD is in many ways similar to part-of-speech tagging as it involves labeling every word in a text with a tag from a pre-specified set of tag possibilities for each word by using features of the context and other information. This, together with the fact that we do not find crossparadigmatic ambiguities in our data, led to the idea to use a part-of-speech tagger as a concept tagger. In our case the tagset consisted of part-of-speech specific concepts of the SmartKom Ontology. The data we used for preparing the model consisted of a combination of three gold-standard annotations, namely the be</context>
</contexts>
<marker>Edmonds, 2002</marker>
<rawString>Philip Edmonds. 2002. SENSEVAL: The evaluation of word sense disambiguation systems. ELRA Newsletter, 7/3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralf Engel</author>
</authors>
<title>SPIN: Language understanding for spoken dialogue systems using a production system approach.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference on Speech and Language Processing</booktitle>
<location>Denver, USA.</location>
<contexts>
<context position="3783" citStr="Engel (2002)" startWordPosition="550" endWordPosition="551"> from log files of an automatic speech recognition system that was implemented in the SMAxTKOM system (Wahlster et al., 2001; Wahlster, 2003). It is important to point out that there are at least two essential differences between spontaneous speech WSD and textual WSD, i.e., a smaller size of processable context as well as imperfections, hesitations, disfluencies and speech recognition errors. Existing spoken language understanding systems, that are not shallow and thusly produce deep syntactic and semantic representations for multiple domains, e.g. the production system approach described by Engel (2002) or unification-based approaches described by Crysmann et al. (2002), have shown to be more suitable for well-formed input but less robust in case of imperfect input. For conversational and reliable dialogue systems that achieve satisfactory scores in evaluation frameworks such as proposed by Walker et al. (2000) or Beringer et al. (2002) for multi-modal dialogue systems, we need robust knowledge- or data-driven methods for disambiguating the sometimes less than ideal output of the large vocabulary spontaneous speech recognizers. In the long run, we would also like to avoid expensive preproces</context>
<context position="11313" citStr="Engel (2002)" startWordPosition="1740" endWordPosition="1741">m of human hidden operators. A test person communicates with the supposed system and the dialogues are recorded and filmed digitally. Here over 224 subjects produced 448 dialogues (Schiel et al., 2002), employing the same domains and tasks as in the first data collection. 3.2 Data Pre-Processing After manual segmentation of the data into single utterances. The resulting audio files were then manually transcribed. The segmented audio files were handed to the speech recognition engine integrated in the SMAxTKOM dialogue system (Wahlster, 2003). Employing the semantic parsing system described by Engel (2002) the corresponding speech recognition word lattices (Oerder and Ney, 1993) were first transformed into n-best lists of socalled hypotheses sequences. These were mapped onto conceptual representations, which contain the multiple semantic interpretations of the individual hypotheses sequences that arise due to lexical ambiguities. For obtaining the training data, we used only the best, correct and perfectly disambiguated speech recognition hypotheses as described by Porzel et al. (2003) from the first data set of 552 utterances. For obtaining the test data we took a random sample of 3100 utteran</context>
</contexts>
<marker>Engel, 2002</marker>
<rawString>Ralf Engel. 2002. SPIN: Language understanding for spoken dialogue systems using a production system approach. In Proceedings of the International Conference on Speech and Language Processing 2002, Denver, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-M Francony</author>
<author>E Kuijpers</author>
<author>Y Polity</author>
</authors>
<title>Towards a methodology for wizard of oz experiments.</title>
<date>1992</date>
<booktitle>In Third Conference on Applied Natural Language Processing,</booktitle>
<location>Trento, Italy,</location>
<contexts>
<context position="9920" citStr="Francony et al., 1992" startWordPosition="1513" endWordPosition="1516">d Semantic Web projects. For more details, see www.w3c.org/RDF, www.w3c.org/OWL and www.daml.org. 3 Data and Annotation Experiment In this section we describe the data collection and annotation experiments performed in order to obtain independent data sets for training and evaluation. 3.1 Data Collection The first data set was used for training the supervised model is described in Gurevych et al. (2002b) and was collected using the so-called Hidden Operator Test (Rapp and Strube, 2002). This procedure represents a simplification of classical end-to-end experiments and Wizardof-Oz experiments (Francony et al., 1992) - as it is conductible without the technically very complex use of a real or a seemingly real conversational system. The subjects are prompted to ask for specific information and the system response is pre-manufactured. We had 29 subjects prompted to say certain inputs in 8 dialogues. 1479 turns were recorded. In our experimental setup each user-turn in the dialogue corresponded to a single illocution, e.g. route request or sights information request as described by Gurevych et al. (2002a). The second data set was used for testing the data- and ontology-based systems and thusly will be called</context>
</contexts>
<marker>Francony, Kuijpers, Polity, 1992</marker>
<rawString>J.-M. Francony, E. Kuijpers, and Y. Polity. 1992. Towards a methodology for wizard of oz experiments. In Third Conference on Applied Natural Language Processing, Trento, Italy, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iryna Gurevych</author>
<author>Robert Porzel</author>
<author>Michael Strube</author>
</authors>
<title>Annotating the semantic consistency of speech recognition hypotheses.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third SIGdial Workshop on Discourse and Dialogue,</booktitle>
<location>Philadelphia, USA,</location>
<contexts>
<context position="9703" citStr="Gurevych et al. (2002" startWordPosition="1482" endWordPosition="1485">d their slots, i.e. the named edges of the graph corresponding to the class properties, constraints and restrictions. &apos;OIL-RDFS, DAML+OIL and OWL are frequently used knowledge modeling languages originating in W3C and Semantic Web projects. For more details, see www.w3c.org/RDF, www.w3c.org/OWL and www.daml.org. 3 Data and Annotation Experiment In this section we describe the data collection and annotation experiments performed in order to obtain independent data sets for training and evaluation. 3.1 Data Collection The first data set was used for training the supervised model is described in Gurevych et al. (2002b) and was collected using the so-called Hidden Operator Test (Rapp and Strube, 2002). This procedure represents a simplification of classical end-to-end experiments and Wizardof-Oz experiments (Francony et al., 1992) - as it is conductible without the technically very complex use of a real or a seemingly real conversational system. The subjects are prompted to ask for specific information and the system response is pre-manufactured. We had 29 subjects prompted to say certain inputs in 8 dialogues. 1479 turns were recorded. In our experimental setup each user-turn in the dialogue corresponded </context>
</contexts>
<marker>Gurevych, Porzel, Strube, 2002</marker>
<rawString>Iryna Gurevych, Robert Porzel, and Michael Strube. 2002a. Annotating the semantic consistency of speech recognition hypotheses. In Proceedings of the Third SIGdial Workshop on Discourse and Dialogue, Philadelphia, USA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iryna Gurevych</author>
<author>Michael Strube</author>
<author>Robert Porzel</author>
</authors>
<title>Automatic classification of speech recognition hypothesis.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3nd SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>90--95</pages>
<location>Philadelphia, USA,</location>
<contexts>
<context position="9703" citStr="Gurevych et al. (2002" startWordPosition="1482" endWordPosition="1485">d their slots, i.e. the named edges of the graph corresponding to the class properties, constraints and restrictions. &apos;OIL-RDFS, DAML+OIL and OWL are frequently used knowledge modeling languages originating in W3C and Semantic Web projects. For more details, see www.w3c.org/RDF, www.w3c.org/OWL and www.daml.org. 3 Data and Annotation Experiment In this section we describe the data collection and annotation experiments performed in order to obtain independent data sets for training and evaluation. 3.1 Data Collection The first data set was used for training the supervised model is described in Gurevych et al. (2002b) and was collected using the so-called Hidden Operator Test (Rapp and Strube, 2002). This procedure represents a simplification of classical end-to-end experiments and Wizardof-Oz experiments (Francony et al., 1992) - as it is conductible without the technically very complex use of a real or a seemingly real conversational system. The subjects are prompted to ask for specific information and the system response is pre-manufactured. We had 29 subjects prompted to say certain inputs in 8 dialogues. 1479 turns were recorded. In our experimental setup each user-turn in the dialogue corresponded </context>
</contexts>
<marker>Gurevych, Strube, Porzel, 2002</marker>
<rawString>Iryna Gurevych, Michael Strube, and Robert Porzel. 2002b. Automatic classification of speech recognition hypothesis. In Proceedings of the 3nd SIGdial Workshop on Discourse and Dialogue, Philadelphia, USA, July 2002, pages 90–95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iryna Gurevych</author>
<author>Rainer Malaka</author>
<author>Robert Porzel</author>
<author>Hans-Peter Zorn</author>
</authors>
<title>Semantic coherence scoring using an ontology.</title>
<date>2003</date>
<booktitle>In Proceedings of the HLT/NAACL 2003,</booktitle>
<location>Edmonton, CN.</location>
<contexts>
<context position="2149" citStr="Gurevych et al. (2003" startWordPosition="304" endWordPosition="307">ot existed in the past. Now that speech data from multi-domain systems have become available, corresponding experiments and evaluations have become feasible. In this paper we present the results of first word sense disambiguation annotation experiments on data from spoken interactions with multi-domain dialogue systems. Additionally, we describe the results of a corresponding evaluation of a data- and a knowledge-driven word sense disambiguation system on that data. For knowledge-driven disambiguation we examined whether the ontology-based method for computing semantic coherence introduced by Gurevych et al. (2003a) can be employed to disambiguate between alternative interpretations, i.e. concept representations, of a given speech recognition hypothesis (SRH) at hand. We will show the results of its evaluation in the semantic interpretation task of WSD. For example, in speech recognition hypotheses containing forms of the German verb kommen, i.e. (to) come, a decision had to be made whether its meaning corresponds to the motion sense or to the showing sense, i.e. becoming mapped onto either a MotionDirectedTransliteratedProcessora WatchPerceptualProcess in the terminology of our spoken language underst</context>
<context position="6927" citStr="Gurevych et al., 2003" startWordPosition="1027" endWordPosition="1030">committee described by Pantel and Lin (2003), which automatically discovers word senses from text. Generally, unsupervised methods require large amounts of data. In the case of spoken dialogue and speech recognition output sufficient amounts of data will hopefully become available once multi-domain spoken dialogue systems are deployed in real world applications. 2.2 Knowledge-based Methods Knowledge-based approaches work with lexica and/or ontologies. The kind of knowledge varies widely and machine-readable as well as computer lexica are employed. The knowledge-based approach employed herein (Gurevych et al., 2003a) operates on an ontology partially derived from FrameNet data (Baker et al., 1998) and described by Gurevych et al. (2003b). In a comparable approach Sussna (1993) worked with the lexical reference system WordNet and used a similar metric for the calculation of semantic distance of a number of input lexemes. Depending on the type of semantic relation (hyperonymy, synonymy etc.) different weights are given and his metric takes account of the number of arcs of the same type leaving a node and the depth of a given edge in the overall tree. The disambiguation results on textual data reported by </context>
<context position="8427" citStr="Gurevych et al., 2003" startWordPosition="1280" endWordPosition="1283"> difference that this one uses a semantic-web conform ontology instead of WordNet and it is applied to speech recognition hypotheses. The fact, that our WSD work is done on SRHs makes it difficult to compare the results with methods evaluated on textual data such as in the past SENSEVAL studies (Edmonds, 2002). The ontology-based system has been successfully used for a set of tasks such as finding the best speech recognition hypotheses from sets of competing SRHs, labeling SRHs as correct or incorrect representations of the users intention and for scoring their degree of contextual coherence (Gurevych et al., 2003a; Porzel and Gurevych, 2003; Porzel et al., 2003). In general, the system offers an additional way of employing ontologies, i.e. to use the knowledge modeled therein as the basis for evaluating the semantic coherence of sets of concepts. It can be employed independent of the specific ontology language used, as the underlying algorithm operates only on the nodes and named edges of the directed graph represented by the ontology. The specific knowledge base, e.g. written in OIL-RDFS, DAML+OIL or OWL,&apos; is converted into a graph, consisting of the class hierarchy, with each class corresponding to </context>
<context position="15826" citStr="Gurevych et al. (2003" startWordPosition="2449" endWordPosition="2452">ut via infrared camera, recognition of facial expressions and their emotional states. On the output side, the system features a gesturing and speaking life-like character together with displayed generated text and multimedia graphical output. It currently comprises nearly 50 modules running on a parallel virtual machine-based integration software called Multiplatform3 described in Herzog et al. (2003). 4.1 The Knowledge-driven System The ontology employed for the evaluation has about 800 concepts and 200 relations (apart from the isarelations defining the general taxonomy) and is described by Gurevych et al. (2003b). It includes a generic toplevel ontology whose purpose is to provide a basic structure of the world, i.e. abstract classes to divide the universe in distinct parts as resulting from the ontological analysis.4 The modeling of Processes and Physical Objects as a kind of event that is continuous and homogeneous in nature, follows the frame semantic analysis used for generating the FRAMENET data (Baker et al., 1998). 3The abbreviation stands for “MUltiple Language / Target Integration PLATform FOR Modules”. 4The top-level was developed following the procedure outlined in Russell and Norvig (199</context>
<context position="23997" citStr="Gurevych et al. (2003" startWordPosition="3752" endWordPosition="3755">f the lexicon file: model.lex 5 Evaluation The percentage of correctly disambiguated lexemes from both systems is calculated by the following formula: . Where is he result in percent, the number of lexemes that match with the goldstandard, the number of not-decidable ones and the number of total lexemes. As opposed to the human annotators, both systems always select a specific reading and never assign the value not-decidable. For this evaluation, therefore, we treat any concept occurring in a not-decidable slot as correct.7 Such SRHs usually score below the consistency thresholds described by Gurevych et al. (2003a) and are not passed on. 5.1 Evaluation Knowledge For this evaluation, ONTOSCORE transformed the SRH from our corpus into concept representations as described above. To perform the WSD task, ONTOSCORE calculates a coherence score for each of these concept sets in . The concepts in the highest ranked set are considered to be the ones representing the correct word meaning in this context. OntoScore has two variations: Using the first variation, the relations between two concepts are weighted for taxonomic relations and for all others. The second mode allows each relation being assigned an indiv</context>
</contexts>
<marker>Gurevych, Malaka, Porzel, Zorn, 2003</marker>
<rawString>Iryna Gurevych, Rainer Malaka, Robert Porzel, and Hans-Peter Zorn. 2003a. Semantic coherence scoring using an ontology. In Proceedings of the HLT/NAACL 2003, Edmonton, CN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iryna Gurevych</author>
<author>Robert Porzel</author>
<author>Stefan Merten</author>
</authors>
<title>Less is more: Using a single knowledge representation in dialogue systems.</title>
<date>2003</date>
<booktitle>In Proceedings of the HLT/NAACL Text Meaning Workshop,</booktitle>
<location>Edmonton, Canada.</location>
<contexts>
<context position="2149" citStr="Gurevych et al. (2003" startWordPosition="304" endWordPosition="307">ot existed in the past. Now that speech data from multi-domain systems have become available, corresponding experiments and evaluations have become feasible. In this paper we present the results of first word sense disambiguation annotation experiments on data from spoken interactions with multi-domain dialogue systems. Additionally, we describe the results of a corresponding evaluation of a data- and a knowledge-driven word sense disambiguation system on that data. For knowledge-driven disambiguation we examined whether the ontology-based method for computing semantic coherence introduced by Gurevych et al. (2003a) can be employed to disambiguate between alternative interpretations, i.e. concept representations, of a given speech recognition hypothesis (SRH) at hand. We will show the results of its evaluation in the semantic interpretation task of WSD. For example, in speech recognition hypotheses containing forms of the German verb kommen, i.e. (to) come, a decision had to be made whether its meaning corresponds to the motion sense or to the showing sense, i.e. becoming mapped onto either a MotionDirectedTransliteratedProcessora WatchPerceptualProcess in the terminology of our spoken language underst</context>
<context position="6927" citStr="Gurevych et al., 2003" startWordPosition="1027" endWordPosition="1030">committee described by Pantel and Lin (2003), which automatically discovers word senses from text. Generally, unsupervised methods require large amounts of data. In the case of spoken dialogue and speech recognition output sufficient amounts of data will hopefully become available once multi-domain spoken dialogue systems are deployed in real world applications. 2.2 Knowledge-based Methods Knowledge-based approaches work with lexica and/or ontologies. The kind of knowledge varies widely and machine-readable as well as computer lexica are employed. The knowledge-based approach employed herein (Gurevych et al., 2003a) operates on an ontology partially derived from FrameNet data (Baker et al., 1998) and described by Gurevych et al. (2003b). In a comparable approach Sussna (1993) worked with the lexical reference system WordNet and used a similar metric for the calculation of semantic distance of a number of input lexemes. Depending on the type of semantic relation (hyperonymy, synonymy etc.) different weights are given and his metric takes account of the number of arcs of the same type leaving a node and the depth of a given edge in the overall tree. The disambiguation results on textual data reported by </context>
<context position="8427" citStr="Gurevych et al., 2003" startWordPosition="1280" endWordPosition="1283"> difference that this one uses a semantic-web conform ontology instead of WordNet and it is applied to speech recognition hypotheses. The fact, that our WSD work is done on SRHs makes it difficult to compare the results with methods evaluated on textual data such as in the past SENSEVAL studies (Edmonds, 2002). The ontology-based system has been successfully used for a set of tasks such as finding the best speech recognition hypotheses from sets of competing SRHs, labeling SRHs as correct or incorrect representations of the users intention and for scoring their degree of contextual coherence (Gurevych et al., 2003a; Porzel and Gurevych, 2003; Porzel et al., 2003). In general, the system offers an additional way of employing ontologies, i.e. to use the knowledge modeled therein as the basis for evaluating the semantic coherence of sets of concepts. It can be employed independent of the specific ontology language used, as the underlying algorithm operates only on the nodes and named edges of the directed graph represented by the ontology. The specific knowledge base, e.g. written in OIL-RDFS, DAML+OIL or OWL,&apos; is converted into a graph, consisting of the class hierarchy, with each class corresponding to </context>
<context position="15826" citStr="Gurevych et al. (2003" startWordPosition="2449" endWordPosition="2452">ut via infrared camera, recognition of facial expressions and their emotional states. On the output side, the system features a gesturing and speaking life-like character together with displayed generated text and multimedia graphical output. It currently comprises nearly 50 modules running on a parallel virtual machine-based integration software called Multiplatform3 described in Herzog et al. (2003). 4.1 The Knowledge-driven System The ontology employed for the evaluation has about 800 concepts and 200 relations (apart from the isarelations defining the general taxonomy) and is described by Gurevych et al. (2003b). It includes a generic toplevel ontology whose purpose is to provide a basic structure of the world, i.e. abstract classes to divide the universe in distinct parts as resulting from the ontological analysis.4 The modeling of Processes and Physical Objects as a kind of event that is continuous and homogeneous in nature, follows the frame semantic analysis used for generating the FRAMENET data (Baker et al., 1998). 3The abbreviation stands for “MUltiple Language / Target Integration PLATform FOR Modules”. 4The top-level was developed following the procedure outlined in Russell and Norvig (199</context>
<context position="23997" citStr="Gurevych et al. (2003" startWordPosition="3752" endWordPosition="3755">f the lexicon file: model.lex 5 Evaluation The percentage of correctly disambiguated lexemes from both systems is calculated by the following formula: . Where is he result in percent, the number of lexemes that match with the goldstandard, the number of not-decidable ones and the number of total lexemes. As opposed to the human annotators, both systems always select a specific reading and never assign the value not-decidable. For this evaluation, therefore, we treat any concept occurring in a not-decidable slot as correct.7 Such SRHs usually score below the consistency thresholds described by Gurevych et al. (2003a) and are not passed on. 5.1 Evaluation Knowledge For this evaluation, ONTOSCORE transformed the SRH from our corpus into concept representations as described above. To perform the WSD task, ONTOSCORE calculates a coherence score for each of these concept sets in . The concepts in the highest ranked set are considered to be the ones representing the correct word meaning in this context. OntoScore has two variations: Using the first variation, the relations between two concepts are weighted for taxonomic relations and for all others. The second mode allows each relation being assigned an indiv</context>
</contexts>
<marker>Gurevych, Porzel, Merten, 2003</marker>
<rawString>Iryna Gurevych, Robert Porzel, and Stefan Merten. 2003b. Less is more: Using a single knowledge representation in dialogue systems. In Proceedings of the HLT/NAACL Text Meaning Workshop, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Heflin</author>
<author>James A Hendler</author>
</authors>
<title>Dynamic ontologies on the web.</title>
<date>2000</date>
<booktitle>In Proceedings of AAAI/IAAI,</booktitle>
<pages>443--449</pages>
<location>Austin, Texas.</location>
<contexts>
<context position="27481" citStr="Heflin and Hendler, 2000" startWordPosition="4312" endWordPosition="4315">herto unseen by the statistical model - are integrated into the system, new models must consequently be trained in order to keep performance up to par. In such cases, new annotated data has to be made available. The results of the knowledge-based approach show that ontologies can be employed for such tasks even if they have not been constructed specifically for WSD. Since ontology engineering is at least as costly as annotation and training of statistical models, alternative means for ontology construction and learning need to be pursed. Nonetheless, projects related the semantic web efforts (Heflin and Hendler, 2000) continue to increase their coverage and will become dynamically combinable so that new domains can be integrated in less time without the need of manually processed data. Our future work will involve the testing of an unsupervised method as well as the improvement of the presented approaches. This will include a compression of the databased model and experiments concerning the scalability of the knowledge-based approach. Acknowledgments This work has been partially funded by the German Federal Ministry of Research and Technology (BMBF) as part of the SmartKom project under Grant 01 IL 905C/0 </context>
</contexts>
<marker>Heflin, Hendler, 2000</marker>
<rawString>Jeff Heflin and James A. Hendler. 2000. Dynamic ontologies on the web. In Proceedings of AAAI/IAAI, pages 443–449, Austin, Texas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerd Herzog</author>
<author>Heinz Kirchmann</author>
<author>Stefan Merten</author>
<author>Alassane Ndiaye</author>
<author>Peter Poller</author>
<author>Tilman Becker</author>
</authors>
<title>MULTIPLATFORM: An integration platfrom for multimodal dialogue systems.</title>
<date>2003</date>
<booktitle>In Proceedings of the HLT/NAACL SEALTS Workshop,</booktitle>
<location>Edmonton, Canada.</location>
<contexts>
<context position="15609" citStr="Herzog et al. (2003)" startWordPosition="2415" endWordPosition="2418">t systems, the SMARTKOM (Wahlster, 2003) comprises a large set of input and output modalities together with an efficient fusion and fission pipeline. SMARTKOM features speech input with prosodic analysis, gesture input via infrared camera, recognition of facial expressions and their emotional states. On the output side, the system features a gesturing and speaking life-like character together with displayed generated text and multimedia graphical output. It currently comprises nearly 50 modules running on a parallel virtual machine-based integration software called Multiplatform3 described in Herzog et al. (2003). 4.1 The Knowledge-driven System The ontology employed for the evaluation has about 800 concepts and 200 relations (apart from the isarelations defining the general taxonomy) and is described by Gurevych et al. (2003b). It includes a generic toplevel ontology whose purpose is to provide a basic structure of the world, i.e. abstract classes to divide the universe in distinct parts as resulting from the ontological analysis.4 The modeling of Processes and Physical Objects as a kind of event that is continuous and homogeneous in nature, follows the frame semantic analysis used for generating the</context>
</contexts>
<marker>Herzog, Kirchmann, Merten, Ndiaye, Poller, Becker, 2003</marker>
<rawString>Gerd Herzog, Heinz Kirchmann, Stefan Merten, Alassane Ndiaye, Peter Poller, and Tilman Becker. 2003. MULTIPLATFORM: An integration platfrom for multimodal dialogue systems. In Proceedings of the HLT/NAACL SEALTS Workshop, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
<author>J Veronis</author>
</authors>
<title>Introduction to the special issue on word sense disambiguation: The state of the art.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<pages>24--1</pages>
<contexts>
<context position="998" citStr="Ide and Veronis (1998)" startWordPosition="140" endWordPosition="143">. Unlike in controlled and restricted dialogue systems a simple oneto-one mapping from words to meanings is no longer feasible here. In this paper two different approaches to the resolution of lexical ambiguities are applied to a multi-domain corpus of speech recognition output produced from spontaneous utterances in a spoken dialogue system. The resulting evaluations show that all approaches yield significant gains over the majority class baseline performance of .68, i.e. fmeasures of .79 for the knowledge-driven approach and .86 for the supervised learning approach. 1 Introduction Following Ide and Veronis (1998) we can distinguish between data- and knowledge-driven word sense disambiguation (WSD). Given the basic distinction between written text and spoken utterances, we follow Allen et al. (2001) and differentiate further between controlled and conversational spoken dialogue systems. Neither data- nor knowledge-driven word sense disambiguation has been performed on speech data stemming from human interactions with dialogue systems, since multidomain conversational spoken dialogue systems for human computer interaction (HCI) have not existed in the past. Now that speech data from multi-domain systems</context>
<context position="4642" citStr="Ide and Veronis, 1998" startWordPosition="682" endWordPosition="685">tory scores in evaluation frameworks such as proposed by Walker et al. (2000) or Beringer et al. (2002) for multi-modal dialogue systems, we need robust knowledge- or data-driven methods for disambiguating the sometimes less than ideal output of the large vocabulary spontaneous speech recognizers. In the long run, we would also like to avoid expensive preprocessing work, which is necessary for both ontologydriven and supervised learning methods, i.e. labor intensive ontology engineering and data annotation respectively. 2 State of the Art After work on WSD had overcome so-called early doubts (Ide and Veronis, 1998) in the 1960’s, it was applied to various NLP tasks, such as machine translation, information retrieval, content and grammatical analysis and text processing. Yarowsky (1995) used both supervised and unsupervised WSD for correct phonetizitation of words in speech synthesis. However, there is no recorded work on processing speech recognition hypotheses resulting from speech utterances as it is done in our research. In general, following Ide and Veronis (1998) the various WSD approaches of the past can be divided into two types, i.e., data- and knowledge-based approaches. 2.1 Data-based Methods </context>
</contexts>
<marker>Ide, Veronis, 1998</marker>
<rawString>Nancy Ide and J. Veronis. 1998. Introduction to the special issue on word sense disambiguation: The state of the art. Computational Linguistics, 24/1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christof M¨uller</author>
</authors>
<title>Kontextabh&amp;quot;ngige Bewertung der Koh&amp;quot;renz von Spracherkennungshypothesen. Master Thesis at the Institut f¨ur Informationstechnologie der Fachhochschule</title>
<date>2002</date>
<location>Mannheim.</location>
<marker>M¨uller, 2002</marker>
<rawString>Christof M¨uller. 2002. Kontextabh&amp;quot;ngige Bewertung der Koh&amp;quot;renz von Spracherkennungshypothesen. Master Thesis at the Institut f¨ur Informationstechnologie der Fachhochschule Mannheim.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Oerder</author>
<author>Hermann Ney</author>
</authors>
<title>Word graphs: An efficient interface between continuousspeech recognition and language understanding.</title>
<date>1993</date>
<booktitle>In ICASSP</booktitle>
<volume>2</volume>
<contexts>
<context position="11387" citStr="Oerder and Ney, 1993" startWordPosition="1749" endWordPosition="1752">supposed system and the dialogues are recorded and filmed digitally. Here over 224 subjects produced 448 dialogues (Schiel et al., 2002), employing the same domains and tasks as in the first data collection. 3.2 Data Pre-Processing After manual segmentation of the data into single utterances. The resulting audio files were then manually transcribed. The segmented audio files were handed to the speech recognition engine integrated in the SMAxTKOM dialogue system (Wahlster, 2003). Employing the semantic parsing system described by Engel (2002) the corresponding speech recognition word lattices (Oerder and Ney, 1993) were first transformed into n-best lists of socalled hypotheses sequences. These were mapped onto conceptual representations, which contain the multiple semantic interpretations of the individual hypotheses sequences that arise due to lexical ambiguities. For obtaining the training data, we used only the best, correct and perfectly disambiguated speech recognition hypotheses as described by Porzel et al. (2003) from the first data set of 552 utterances. For obtaining the test data we took a random sample of 3100 utterances from the second data set. This seeming discrepancy between training an</context>
</contexts>
<marker>Oerder, Ney, 1993</marker>
<rawString>Martin Oerder and Hermann Ney. 1993. Word graphs: An efficient interface between continuousspeech recognition and language understanding. In ICASSP Volume 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Dekang Lin</author>
</authors>
<title>Automatically discovering word senses.</title>
<date>2003</date>
<booktitle>HLT-NAACL 2003: Demo Session,</booktitle>
<editor>In Bob Frederking and Bob Younger, editors,</editor>
<publisher>Association for Computational Linguistics.</publisher>
<location>Edmonton, Alberta, Canada.</location>
<contexts>
<context position="6350" citStr="Pantel and Lin (2003)" startWordPosition="944" endWordPosition="947">pora. Despite the small size of his training and test corpus, an accuracy of 90 was achieved. Even better results on a larger corpus were obtained by Kelly and Stone 1975 who included collocational, syntactic and part of speech information to yield an accuracy of 93 on a larger corpus. As always, supervised methods require a manually annotated learning corpus. Unsupervised methods do not determine the set of classes before the learning process, but through analysis of the given data by identifying clusters of similar cases. One example is the algorithm for clustering by committee described by Pantel and Lin (2003), which automatically discovers word senses from text. Generally, unsupervised methods require large amounts of data. In the case of spoken dialogue and speech recognition output sufficient amounts of data will hopefully become available once multi-domain spoken dialogue systems are deployed in real world applications. 2.2 Knowledge-based Methods Knowledge-based approaches work with lexica and/or ontologies. The kind of knowledge varies widely and machine-readable as well as computer lexica are employed. The knowledge-based approach employed herein (Gurevych et al., 2003a) operates on an ontol</context>
</contexts>
<marker>Pantel, Lin, 2003</marker>
<rawString>Patrick Pantel and Dekang Lin. 2003. Automatically discovering word senses. In Bob Frederking and Bob Younger, editors, HLT-NAACL 2003: Demo Session, Edmonton, Alberta, Canada. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Porzel</author>
<author>Iryna Gurevych</author>
</authors>
<title>Contextual coherence in natural language processing.</title>
<date>2003</date>
<booktitle>Modeling and Using Context. LNAI 2680, Sprigner,</booktitle>
<editor>In P. Blackburn, C. Ghidini, R. Turner, and F. Giunchiglia, editors,</editor>
<location>Berlin.</location>
<contexts>
<context position="8455" citStr="Porzel and Gurevych, 2003" startWordPosition="1284" endWordPosition="1287">e uses a semantic-web conform ontology instead of WordNet and it is applied to speech recognition hypotheses. The fact, that our WSD work is done on SRHs makes it difficult to compare the results with methods evaluated on textual data such as in the past SENSEVAL studies (Edmonds, 2002). The ontology-based system has been successfully used for a set of tasks such as finding the best speech recognition hypotheses from sets of competing SRHs, labeling SRHs as correct or incorrect representations of the users intention and for scoring their degree of contextual coherence (Gurevych et al., 2003a; Porzel and Gurevych, 2003; Porzel et al., 2003). In general, the system offers an additional way of employing ontologies, i.e. to use the knowledge modeled therein as the basis for evaluating the semantic coherence of sets of concepts. It can be employed independent of the specific ontology language used, as the underlying algorithm operates only on the nodes and named edges of the directed graph represented by the ontology. The specific knowledge base, e.g. written in OIL-RDFS, DAML+OIL or OWL,&apos; is converted into a graph, consisting of the class hierarchy, with each class corresponding to a concept representing eithe</context>
</contexts>
<marker>Porzel, Gurevych, 2003</marker>
<rawString>Robert Porzel and Iryna Gurevych. 2003. Contextual coherence in natural language processing. In P. Blackburn, C. Ghidini, R. Turner, and F. Giunchiglia, editors, Modeling and Using Context. LNAI 2680, Sprigner, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Porzel</author>
<author>Rainer Malaka</author>
</authors>
<title>Towards measuring scalability in natural laguage understanding tasks.</title>
<date>2004</date>
<booktitle>In Proceedings of the HLT/NAACL Workshop on Scalable Natural Language Understanding,</booktitle>
<location>Boston, USA.</location>
<note>To appear.</note>
<contexts>
<context position="14492" citStr="Porzel and Malaka, 2004" startWordPosition="2250" endWordPosition="2253">hen, 1960; Carletta, 1996) cannot be applied here, as the classes vary depending on the number of ambiguities per entry in the lexicon. Also an additional class, i.e., not-decidable was allowed for cases as in SRH (1c), where it is impossible to assign sensible meanings. The test data set altogether was annotated with 2219 markables of ambiguous tokens, stemming from 70 ambiguous words occurring in the test corpus. 3.4 Calculating the Baselines For calculating the majority class baseline, which in our case corresponds to the performance of a unigram tagger, we applied the method described in (Porzel and Malaka, 2004). Therefore, all markables in the gold-standard were counted and, corresponding to the frequency of each concept of each ambiguous lexeme, the percentage of correctly chosen concepts by means of selecting the most frequent meaning was calculated. This resulted in a baseline of 52.48 for the test data set. 4 Word Sense Disambiguation Systems Both word sense disambiguation systems described herein were tested and developed with the SMARTKOM research framework. As one of the most advanced current systems, the SMARTKOM (Wahlster, 2003) comprises a large set of input and output modalities together </context>
</contexts>
<marker>Porzel, Malaka, 2004</marker>
<rawString>Robert Porzel and Rainer Malaka. 2004. Towards measuring scalability in natural laguage understanding tasks. In Proceedings of the HLT/NAACL Workshop on Scalable Natural Language Understanding, Boston, USA. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Porzel</author>
<author>Iryna Gurevych</author>
<author>Christof M¨uller</author>
</authors>
<title>Ontology-based contextual coherence scoring.</title>
<date>2003</date>
<booktitle>In Proceedings of the 4th SIGdial Workshop on Discourse and Dialogue,</booktitle>
<location>Saporo, Japan,</location>
<marker>Porzel, Gurevych, M¨uller, 2003</marker>
<rawString>Robert Porzel, Iryna Gurevych, and Christof M¨uller. 2003. Ontology-based contextual coherence scoring. In Proceedings of the 4th SIGdial Workshop on Discourse and Dialogue, Saporo, Japan, July 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L R Rabiner</author>
</authors>
<title>A tutorial on hidden markov models and selected applications in speech recognition.</title>
<date>1989</date>
<booktitle>Proceedings of the IEEE,</booktitle>
<pages>77</pages>
<contexts>
<context position="20517" citStr="Rabiner, 1989" startWordPosition="3183" endWordPosition="3184">he cheapest. The distances between all concept pairs in CR are summed up to a total score.6 The set of concepts with the lowest aggregate score represents the combination with the highest semantic relatedness. 4.2 The Data-driven System In this section we describe the implementation of the statistical learning techniques employed for the task of performing WSD on our corpus of spoken dialogue data. For our experiments we took the general purpose statistical tagger (Brants, 2000), which is generally used for part-of-speech tagging. It employs a VITERBI algorithm for second order Markov models (Rabiner, 1989), linear interpolation for smoothing and deleted interpolation for 5As defined by Demetriou and Atwell (1994), is the set of direct relations (both isa and semantic relations) that can connect two nodes (concepts); and is the set of corresponding weights, where the weight of each isa relation is set to and that of each other relation to . 6Note that more specific relations subtract more then less specific ones from the aggregate score. determining the weights. According to Edmonds (2002), WSD is in many ways similar to part-of-speech tagging as it involves labeling every word in a text with a </context>
</contexts>
<marker>Rabiner, 1989</marker>
<rawString>L.R. Rabiner. 1989. A tutorial on hidden markov models and selected applications in speech recognition. Proceedings of the IEEE, 77.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Rapp</author>
<author>Michael Strube</author>
</authors>
<title>An iterative data collection approach for multimodal dialogue systems.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd International Conference on Language Resources and Evaluation,</booktitle>
<location>Las Palmas,</location>
<contexts>
<context position="9788" citStr="Rapp and Strube, 2002" startWordPosition="1495" endWordPosition="1498">es, constraints and restrictions. &apos;OIL-RDFS, DAML+OIL and OWL are frequently used knowledge modeling languages originating in W3C and Semantic Web projects. For more details, see www.w3c.org/RDF, www.w3c.org/OWL and www.daml.org. 3 Data and Annotation Experiment In this section we describe the data collection and annotation experiments performed in order to obtain independent data sets for training and evaluation. 3.1 Data Collection The first data set was used for training the supervised model is described in Gurevych et al. (2002b) and was collected using the so-called Hidden Operator Test (Rapp and Strube, 2002). This procedure represents a simplification of classical end-to-end experiments and Wizardof-Oz experiments (Francony et al., 1992) - as it is conductible without the technically very complex use of a real or a seemingly real conversational system. The subjects are prompted to ask for specific information and the system response is pre-manufactured. We had 29 subjects prompted to say certain inputs in 8 dialogues. 1479 turns were recorded. In our experimental setup each user-turn in the dialogue corresponded to a single illocution, e.g. route request or sights information request as described</context>
</contexts>
<marker>Rapp, Strube, 2002</marker>
<rawString>Stefan Rapp and Michael Strube. 2002. An iterative data collection approach for multimodal dialogue systems. In Proceedings of the 3rd International Conference on Language Resources and Evaluation, Las Palmas, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart J Russell</author>
<author>Peter Norvig</author>
</authors>
<title>Artificial Intelligence. A Modern Approach.</title>
<date>1995</date>
<publisher>Prentice Hall,</publisher>
<location>Englewood Cliffs, N.J.</location>
<contexts>
<context position="16428" citStr="Russell and Norvig (1995)" startWordPosition="2547" endWordPosition="2550">y Gurevych et al. (2003b). It includes a generic toplevel ontology whose purpose is to provide a basic structure of the world, i.e. abstract classes to divide the universe in distinct parts as resulting from the ontological analysis.4 The modeling of Processes and Physical Objects as a kind of event that is continuous and homogeneous in nature, follows the frame semantic analysis used for generating the FRAMENET data (Baker et al., 1998). 3The abbreviation stands for “MUltiple Language / Target Integration PLATform FOR Modules”. 4The top-level was developed following the procedure outlined in Russell and Norvig (1995). The hierarchy of Processes is connected to the hierarchy of Physical Objects via slot-constraint definitions herein referred to as relations. The system performs a number of processing steps. A first preprocessing step is to convert each SRH into a concept representation (CR). For that purpose the system’s lexicon is used, which contains either zero, one or many corresponding concepts for each entry. A simple vector of concepts - corresponding to the words in the SRH for which entries in the lexicon exist - constitutes each resulting CR. All other words with empty concept mappings, e.g. arti</context>
</contexts>
<marker>Russell, Norvig, 1995</marker>
<rawString>Stuart J. Russell and Peter Norvig. 1995. Artificial Intelligence. A Modern Approach. Prentice Hall, Englewood Cliffs, N.J.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Florian Schiel</author>
<author>Silke Steininger</author>
<author>Ulrich T¨urk</author>
</authors>
<title>The smartkom multimodal corpus at bas.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd LREC, Las</booktitle>
<location>Palmas</location>
<marker>Schiel, Steininger, T¨urk, 2002</marker>
<rawString>Florian Schiel, Silke Steininger, and Ulrich T¨urk. 2002. The smartkom multimodal corpus at bas. In Proceedings of the 3rd LREC, Las Palmas Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Stevenson</author>
</authors>
<title>Word Sense Disambiguation: The Case for Combining Knowldge Sources.</title>
<date>2003</date>
<publisher>CSLI.</publisher>
<contexts>
<context position="5400" citStr="Stevenson, 2003" startWordPosition="795" endWordPosition="796">text processing. Yarowsky (1995) used both supervised and unsupervised WSD for correct phonetizitation of words in speech synthesis. However, there is no recorded work on processing speech recognition hypotheses resulting from speech utterances as it is done in our research. In general, following Ide and Veronis (1998) the various WSD approaches of the past can be divided into two types, i.e., data- and knowledge-based approaches. 2.1 Data-based Methods Data-based approaches extract their information directly from texts and are divided into supervised and unsupervised methods (Yarowsky, 1995; Stevenson, 2003). Supervised methods work with a given (and therefore limited) set of potential classes in the learning process. For example, Yarowsky (1992) used a thesaurus to generate 1042 statistical models of the most general categories. Weiss (1973) already showed that disambiguation rules can successfully be learned from hand-tagged corpora. Despite the small size of his training and test corpus, an accuracy of 90 was achieved. Even better results on a larger corpus were obtained by Kelly and Stone 1975 who included collocational, syntactic and part of speech information to yield an accuracy of 93 on a</context>
</contexts>
<marker>Stevenson, 2003</marker>
<rawString>Mark Stevenson. 2003. Word Sense Disambiguation: The Case for Combining Knowldge Sources. CSLI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Sussna</author>
</authors>
<title>Word sense disambiguation for free text indexing using a massive semantic network.</title>
<date>1993</date>
<booktitle>In Proceedings ofthe Second International Conference on Information and Knowledge Management.</booktitle>
<contexts>
<context position="7092" citStr="Sussna (1993)" startWordPosition="1056" endWordPosition="1057"> of spoken dialogue and speech recognition output sufficient amounts of data will hopefully become available once multi-domain spoken dialogue systems are deployed in real world applications. 2.2 Knowledge-based Methods Knowledge-based approaches work with lexica and/or ontologies. The kind of knowledge varies widely and machine-readable as well as computer lexica are employed. The knowledge-based approach employed herein (Gurevych et al., 2003a) operates on an ontology partially derived from FrameNet data (Baker et al., 1998) and described by Gurevych et al. (2003b). In a comparable approach Sussna (1993) worked with the lexical reference system WordNet and used a similar metric for the calculation of semantic distance of a number of input lexemes. Depending on the type of semantic relation (hyperonymy, synonymy etc.) different weights are given and his metric takes account of the number of arcs of the same type leaving a node and the depth of a given edge in the overall tree. The disambiguation results on textual data reported by Sussna (1993) turned out to be significantly better than chance. In contrast to many other work on WSD with WordNet he took into account not only the isa hierarchy, </context>
</contexts>
<marker>Sussna, 1993</marker>
<rawString>Michael Sussna. 1993. Word sense disambiguation for free text indexing using a massive semantic network. In Proceedings ofthe Second International Conference on Information and Knowledge Management.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Van Rijsbergen</author>
</authors>
<title>Information Retrieval, 2nd edition.</title>
<date>1979</date>
<institution>Dept. of Computer Science, University of Glasgow.</institution>
<marker>Van Rijsbergen, 1979</marker>
<rawString>C. J. Van Rijsbergen. 1979. Information Retrieval, 2nd edition. Dept. of Computer Science, University of Glasgow.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Wahlster</author>
<author>Norbert Reithinger</author>
<author>Anselm Blocher</author>
</authors>
<title>Smartkom: Multimodal communication with a life-like character.</title>
<date>2001</date>
<booktitle>In Proceedings of the 7th European Conference on Speech Communication and Technology.</booktitle>
<contexts>
<context position="3295" citStr="Wahlster et al., 2001" startWordPosition="478" endWordPosition="481">ra WatchPerceptualProcess in the terminology of our spoken language understanding system. For a datadriven approach we employed a highly supervised learning algorithm introduced by Brants (2000) and trained it on a corpus of annotated data. A second set of semantically annotated speech recognition hypotheses was employed as a gold-standard for evaluating both the ontology-based and supervised learning method. Both data sets were annotated by separate human annotators. All annotated data stems from log files of an automatic speech recognition system that was implemented in the SMAxTKOM system (Wahlster et al., 2001; Wahlster, 2003). It is important to point out that there are at least two essential differences between spontaneous speech WSD and textual WSD, i.e., a smaller size of processable context as well as imperfections, hesitations, disfluencies and speech recognition errors. Existing spoken language understanding systems, that are not shallow and thusly produce deep syntactic and semantic representations for multiple domains, e.g. the production system approach described by Engel (2002) or unification-based approaches described by Crysmann et al. (2002), have shown to be more suitable for well-fo</context>
</contexts>
<marker>Wahlster, Reithinger, Blocher, 2001</marker>
<rawString>Wolfgang Wahlster, Norbert Reithinger, and Anselm Blocher. 2001. Smartkom: Multimodal communication with a life-like character. In Proceedings of the 7th European Conference on Speech Communication and Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Wahlster</author>
</authors>
<title>SmartKom: Symmetric multimodality in an adaptive an reusable dialog shell.</title>
<date>2003</date>
<booktitle>In Proceedings of the Human Computer Interaction Status Conference,</booktitle>
<location>Berlin, Germany.</location>
<contexts>
<context position="3312" citStr="Wahlster, 2003" startWordPosition="482" endWordPosition="483">ss in the terminology of our spoken language understanding system. For a datadriven approach we employed a highly supervised learning algorithm introduced by Brants (2000) and trained it on a corpus of annotated data. A second set of semantically annotated speech recognition hypotheses was employed as a gold-standard for evaluating both the ontology-based and supervised learning method. Both data sets were annotated by separate human annotators. All annotated data stems from log files of an automatic speech recognition system that was implemented in the SMAxTKOM system (Wahlster et al., 2001; Wahlster, 2003). It is important to point out that there are at least two essential differences between spontaneous speech WSD and textual WSD, i.e., a smaller size of processable context as well as imperfections, hesitations, disfluencies and speech recognition errors. Existing spoken language understanding systems, that are not shallow and thusly produce deep syntactic and semantic representations for multiple domains, e.g. the production system approach described by Engel (2002) or unification-based approaches described by Crysmann et al. (2002), have shown to be more suitable for well-formed input but le</context>
<context position="11248" citStr="Wahlster, 2003" startWordPosition="1730" endWordPosition="1731">etting a full-blown multimodal dialogue system is simulated by a team of human hidden operators. A test person communicates with the supposed system and the dialogues are recorded and filmed digitally. Here over 224 subjects produced 448 dialogues (Schiel et al., 2002), employing the same domains and tasks as in the first data collection. 3.2 Data Pre-Processing After manual segmentation of the data into single utterances. The resulting audio files were then manually transcribed. The segmented audio files were handed to the speech recognition engine integrated in the SMAxTKOM dialogue system (Wahlster, 2003). Employing the semantic parsing system described by Engel (2002) the corresponding speech recognition word lattices (Oerder and Ney, 1993) were first transformed into n-best lists of socalled hypotheses sequences. These were mapped onto conceptual representations, which contain the multiple semantic interpretations of the individual hypotheses sequences that arise due to lexical ambiguities. For obtaining the training data, we used only the best, correct and perfectly disambiguated speech recognition hypotheses as described by Porzel et al. (2003) from the first data set of 552 utterances. Fo</context>
<context position="15029" citStr="Wahlster, 2003" startWordPosition="2334" endWordPosition="2335">a unigram tagger, we applied the method described in (Porzel and Malaka, 2004). Therefore, all markables in the gold-standard were counted and, corresponding to the frequency of each concept of each ambiguous lexeme, the percentage of correctly chosen concepts by means of selecting the most frequent meaning was calculated. This resulted in a baseline of 52.48 for the test data set. 4 Word Sense Disambiguation Systems Both word sense disambiguation systems described herein were tested and developed with the SMARTKOM research framework. As one of the most advanced current systems, the SMARTKOM (Wahlster, 2003) comprises a large set of input and output modalities together with an efficient fusion and fission pipeline. SMARTKOM features speech input with prosodic analysis, gesture input via infrared camera, recognition of facial expressions and their emotional states. On the output side, the system features a gesturing and speaking life-like character together with displayed generated text and multimedia graphical output. It currently comprises nearly 50 modules running on a parallel virtual machine-based integration software called Multiplatform3 described in Herzog et al. (2003). 4.1 The Knowledge-</context>
</contexts>
<marker>Wahlster, 2003</marker>
<rawString>Wolfgang Wahlster. 2003. SmartKom: Symmetric multimodality in an adaptive an reusable dialog shell. In Proceedings of the Human Computer Interaction Status Conference, Berlin, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
<author>Candace A Kamm</author>
<author>Diane J Litman</author>
</authors>
<title>Towards developing general model of usability with PARADISE.</title>
<date>2000</date>
<journal>Natural Language Engeneering,</journal>
<volume>6</volume>
<contexts>
<context position="4097" citStr="Walker et al. (2000)" startWordPosition="597" endWordPosition="600">context as well as imperfections, hesitations, disfluencies and speech recognition errors. Existing spoken language understanding systems, that are not shallow and thusly produce deep syntactic and semantic representations for multiple domains, e.g. the production system approach described by Engel (2002) or unification-based approaches described by Crysmann et al. (2002), have shown to be more suitable for well-formed input but less robust in case of imperfect input. For conversational and reliable dialogue systems that achieve satisfactory scores in evaluation frameworks such as proposed by Walker et al. (2000) or Beringer et al. (2002) for multi-modal dialogue systems, we need robust knowledge- or data-driven methods for disambiguating the sometimes less than ideal output of the large vocabulary spontaneous speech recognizers. In the long run, we would also like to avoid expensive preprocessing work, which is necessary for both ontologydriven and supervised learning methods, i.e. labor intensive ontology engineering and data annotation respectively. 2 State of the Art After work on WSD had overcome so-called early doubts (Ide and Veronis, 1998) in the 1960’s, it was applied to various NLP tasks, su</context>
</contexts>
<marker>Walker, Kamm, Litman, 2000</marker>
<rawString>Marilyn A. Walker, Candace A. Kamm, and Diane J. Litman. 2000. Towards developing general model of usability with PARADISE. Natural Language Engeneering, 6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Weiss</author>
</authors>
<title>Learning to disambiguate.</title>
<date>1973</date>
<journal>Information Storage and Retrieval,</journal>
<volume>9</volume>
<contexts>
<context position="5639" citStr="Weiss (1973)" startWordPosition="832" endWordPosition="833">s as it is done in our research. In general, following Ide and Veronis (1998) the various WSD approaches of the past can be divided into two types, i.e., data- and knowledge-based approaches. 2.1 Data-based Methods Data-based approaches extract their information directly from texts and are divided into supervised and unsupervised methods (Yarowsky, 1995; Stevenson, 2003). Supervised methods work with a given (and therefore limited) set of potential classes in the learning process. For example, Yarowsky (1992) used a thesaurus to generate 1042 statistical models of the most general categories. Weiss (1973) already showed that disambiguation rules can successfully be learned from hand-tagged corpora. Despite the small size of his training and test corpus, an accuracy of 90 was achieved. Even better results on a larger corpus were obtained by Kelly and Stone 1975 who included collocational, syntactic and part of speech information to yield an accuracy of 93 on a larger corpus. As always, supervised methods require a manually annotated learning corpus. Unsupervised methods do not determine the set of classes before the learning process, but through analysis of the given data by identifying cluster</context>
</contexts>
<marker>Weiss, 1973</marker>
<rawString>Stephen Weiss. 1973. Learning to disambiguate. Information Storage and Retrieval, 9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Word-sense disambiguation using statistical models of roget’s categories trained on large corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics,</booktitle>
<volume>1</volume>
<location>Nantes,</location>
<contexts>
<context position="5541" citStr="Yarowsky (1992)" startWordPosition="816" endWordPosition="817">there is no recorded work on processing speech recognition hypotheses resulting from speech utterances as it is done in our research. In general, following Ide and Veronis (1998) the various WSD approaches of the past can be divided into two types, i.e., data- and knowledge-based approaches. 2.1 Data-based Methods Data-based approaches extract their information directly from texts and are divided into supervised and unsupervised methods (Yarowsky, 1995; Stevenson, 2003). Supervised methods work with a given (and therefore limited) set of potential classes in the learning process. For example, Yarowsky (1992) used a thesaurus to generate 1042 statistical models of the most general categories. Weiss (1973) already showed that disambiguation rules can successfully be learned from hand-tagged corpora. Despite the small size of his training and test corpus, an accuracy of 90 was achieved. Even better results on a larger corpus were obtained by Kelly and Stone 1975 who included collocational, syntactic and part of speech information to yield an accuracy of 93 on a larger corpus. As always, supervised methods require a manually annotated learning corpus. Unsupervised methods do not determine the set of </context>
</contexts>
<marker>Yarowsky, 1992</marker>
<rawString>David Yarowsky. 1992. Word-sense disambiguation using statistical models of roget’s categories trained on large corpora. In Proceedings of the 15th International Conference on Computational Linguistics, Nantes, France, 23-28 August 1992, volume 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Unsupervised word sense disambiguation rivalling supervised methods.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Cambridge, Mass.,</location>
<contexts>
<context position="4816" citStr="Yarowsky (1995)" startWordPosition="710" endWordPosition="711">thods for disambiguating the sometimes less than ideal output of the large vocabulary spontaneous speech recognizers. In the long run, we would also like to avoid expensive preprocessing work, which is necessary for both ontologydriven and supervised learning methods, i.e. labor intensive ontology engineering and data annotation respectively. 2 State of the Art After work on WSD had overcome so-called early doubts (Ide and Veronis, 1998) in the 1960’s, it was applied to various NLP tasks, such as machine translation, information retrieval, content and grammatical analysis and text processing. Yarowsky (1995) used both supervised and unsupervised WSD for correct phonetizitation of words in speech synthesis. However, there is no recorded work on processing speech recognition hypotheses resulting from speech utterances as it is done in our research. In general, following Ide and Veronis (1998) the various WSD approaches of the past can be divided into two types, i.e., data- and knowledge-based approaches. 2.1 Data-based Methods Data-based approaches extract their information directly from texts and are divided into supervised and unsupervised methods (Yarowsky, 1995; Stevenson, 2003). Supervised met</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>David Yarowsky. 1995. Unsupervised word sense disambiguation rivalling supervised methods. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics, Cambridge, Mass., 26–30 June 1995.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>