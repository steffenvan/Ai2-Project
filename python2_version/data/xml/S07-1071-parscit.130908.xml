<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000010">
<title confidence="0.983725">
TOR, TORMD: Distributional Profiles of Concepts
for Unsupervised Word Sense Disambiguation
</title>
<author confidence="0.996566">
Saif Mohammad
</author>
<affiliation confidence="0.998559">
Dept. of Computer Science
University of Toronto
</affiliation>
<address confidence="0.904507">
Toronto, ON M5S 3G4
Canada
</address>
<email confidence="0.999012">
smm@cs.toronto.edu
</email>
<author confidence="0.992765">
Graeme Hirst
</author>
<affiliation confidence="0.9985545">
Dept. of Computer Science
University of Toronto
</affiliation>
<address confidence="0.904483">
Toronto, ON M5S 3G4
Canada
</address>
<email confidence="0.998936">
gh@cs.toronto.edu
</email>
<author confidence="0.993607">
Philip Resnik
</author>
<affiliation confidence="0.9971785">
Dept. of Linguistics and UMIACS
University of Maryland
</affiliation>
<address confidence="0.907149">
College Park, MD 20742
USA
</address>
<email confidence="0.999267">
resnik@umiacs.umd.edu
</email>
<sectionHeader confidence="0.998602" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999970263157895">
Words in the context of a target word
have long been used as features by su-
pervised word-sense classifiers. Moham-
mad and Hirst (2006a) proposed a way to
determine the strength of association be-
tween a sense or concept and co-occurring
words—the distributional profile of a con-
cept (DPC)—without the use of manually
annotated data. We implemented an unsu-
pervised naive Bayes word sense classifier
using these DPCs that was best or within
one percentage point of the best unsuper-
vised systems in the Multilingual Chinese-
English Lexical Sample Task (task #5) and
the English Lexical Sample Task (task #17).
We also created a simple PMI-based classi-
fier to attempt the English Lexical Substi-
tution Task (task #10); however, its perfor-
mance was poor.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999588444444444">
Determining the intended sense of a word is poten-
tially useful in many natural language tasks includ-
ing machine translation and information retrieval.
The best approaches for word sense disambiguation
are supervised and they use words that co-occur with
the target as features. These systems rely on sense-
annotated data to identify words that are indicative
of the use of the target in each of its senses.
However, only limited amounts of sense-
annotated data exist and it is expensive to create. In
our previous work (Mohammad and Hirst, 2006a),
we proposed an unsupervised approach to determine
the strength of association between a sense or con-
cept and its co-occurring words—the distributional
profile of a concept (DPC)—relying simply on raw
text and a published thesaurus. The categories in a
published thesaurus were used as coarse senses or
concepts (Yarowsky, 1992). We now show how dis-
tributional profiles of concepts can be used to cre-
ate an unsupervised naive Bayes word-sense classi-
fier. We also implemented a simple classifier that
relies on the pointwise mutual information (PMI)
between the senses of the target and co-occurring
words. These DPC-based classifiers participated in
three SemEval 2007 tasks: the English Lexical Sam-
ple Task (task #17), the English Lexical Substitu-
tion Task (task #10), and the Multilingual Chinese-
English Lexical Sample Task (task #5).
The English Lexical Sample Task (Pradhan et al.,
2007) is a traditional word sense disambiguation
task wherein the intended (WordNet) sense of a tar-
get word is to be determined from its context. We
manually mapped the WordNet senses to the cate-
gories in a thesaurus and the DPC-based naive Bayes
classifier was used to identify the intended sense
(category) of the target words.
The object of the Lexical Substitution Task (Mc-
Carthy and Navigli, 2007) is to replace a target word
in a sentence with a suitable substitute that preserves
the meaning of the utterance. The list of possible
substitutes for a given target word is usually contin-
gent on its intended sense. Therefore, word sense
disambiguation is expected to be useful in lexical
substitution. We used the PMI-based classier to de-
termine the intended sense.
</bodyText>
<page confidence="0.983532">
326
</page>
<note confidence="0.69938">
Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 326–333,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.993536692307692">
The objective of the Multilingual Chinese–
English Lexical Sample Task (Jin et al., 2007) is to
select from a given list a suitable English translation
of a Chinese target word in context. Mohammad et
al. (2007) proposed a way to create cross-lingual
distributional profiles of a concepts (CL-DPCs)—
the strengths of association between the concepts of
one language and words of another. For this task, we
mapped the list of English translations to appropri-
ate thesaurus categories and used an implementation
of a CL-DPC–based unsupervised naive Bayes clas-
sifier to identify the intended senses (and thereby the
English translations) of target Chinese words.
</bodyText>
<sectionHeader confidence="0.984586" genericHeader="introduction">
2 Distributional profiles of concepts
</sectionHeader>
<bodyText confidence="0.999983">
In order to determine the strength of association be-
tween a sense of the target word and its co-occurring
words, we need to determine their individual and
joint occurrence counts in a corpus. Mohammad and
Hirst (2006a) and Mohammad et al. (2007) proposed
ways to determine these counts in a monolingual and
cross-lingual framework without the use of sense-
annotated data. We summarize the ideas in this sec-
tion; the original papers give more details.
</bodyText>
<subsectionHeader confidence="0.980285">
2.1 Word–category co-occurrence matrix
</subsectionHeader>
<bodyText confidence="0.9916671">
We create a word–category co-occurrence matrix
(WCCM) having English word types wen as one di-
mension and English thesaurus categories cen as an-
other. We used the Macquarie Thesaurus (Bernard,
1986) both as a very coarse-grained sense inventory
and a source of words that together represent each
category (concept). The WCCM is populated with
co-occurrence counts from a large English corpus
(we used the British National Corpus (BNC)). A par-
ticular cell mij, corresponding to word wen
</bodyText>
<equation confidence="0.659835333333333">
i and con-
cept cenj , is populated with the number of times wen
i
</equation>
<bodyText confidence="0.79384625">
co-occurs with any word that has cjen as one of its
senses (i.e., wen
i co-occurs with any word listed un-
der concept cenj in the thesaurus).
</bodyText>
<equation confidence="0.8959873">
cen 1cen2 ... cenj ...
m11 m12 ... m1j ...
m21 m22 ... m2j ...
...
.. ..
. .
mi1 mi2 ... mij ...
... ... ... ... ...
A particular cell mij, corresponding to word wen
i
</equation>
<bodyText confidence="0.999730270833333">
and concept cenj , is populated with the number of
times wen
i co-occurs with any word that has cjen
as one of its senses (i.e., wen
i co-occurs with any
word listed under concept cjen in the thesaurus).
This matrix, created after a first pass of the corpus,
is the base word–category co-occurrence matrix
(base WCCM) and it captures strong associations
between a sense and co-occurring words (see dis-
cussion of the general principle in Resnik (1998)).
From the base WCCM we can determine the num-
ber of times a word w and concept c co-occur, the
number of times w co-occurs with any concept, and
the number of times c co-occurs with any word. A
statistic such as PMI can then give the strength of
association between w and c. This is similar to how
Yarowsky (1992) identifies words that are indicative
of a particular sense of the target word.
Words that occur close to a target word tend to
be good indicators of its intended sense. Therefore,
we make a second pass of the corpus, using the base
WCCM to roughly disambiguate the words in it. For
each word, the strength of association of each of
the words in its context (±5 words) with each of its
senses is summed. The sense that has the highest cu-
mulative association is chosen as the intended sense.
A new bootstrapped WCCM is created such that
each cell mij, corresponding to word wen iand con-
cept cen
j , is populated with the number of times wen
i
co-occurs with any word used in sense cen
j .
Mohammad and Hirst (2006a) used the DPCs
created from the bootstrapped WCCM to attain
near-upper-bound results in the task of determin-
ing word sense dominance. Unlike the McCarthy
et al. (2004) dominance system, this approach can
be applied to much smaller target texts (a few
hundred sentences) without the need for a large
similarly-sense-distributed text1. Mohammad and
Hirst (2006b) used the DPC-based monolingual dis-
tributional measures of concept-distance to rank
word pairs by their semantic similarity and to correct
real-word spelling errors, attaining markedly better
results than monolingual distributional measures of
word-distance. In the spelling correction task, the
</bodyText>
<footnote confidence="0.787483">
1The McCarthy et al. (2004) system needs to first gener-
ate a distributional thesaurus from the target text (if it is large
enough—a few million words) or from another large text with a
distribution of senses similar to the target text.
</footnote>
<figure confidence="0.887522444444445">
wen
1
wen
2
...
wen
i
...
... ...
</figure>
<page confidence="0.639978">
327
</page>
<figureCaption confidence="0.999917">
Figure 1: The cross-lingual candidate senses of Chi-
</figureCaption>
<bodyText confidence="0.988752">
nese words and .
distributional concept-distance measures performed
better than all WordNet-based measures as well, ex-
cept for the Jiang and Conrath (1997) measure.
</bodyText>
<subsectionHeader confidence="0.9080425">
2.2 Cross-lingual word–category
co-occurrence matrix
</subsectionHeader>
<bodyText confidence="0.947239913043478">
Given a Chinese word wch in context, we use a
Chinese–English bilingual lexicon to determine its
different possible English translations. Each En-
glish translation wen may have one or more possi-
ble coarse senses, as listed in an English thesaurus.
These English thesaurus concepts (cen) will be re-
ferred to as cross-lingual candidate senses of the
Chinese word wch.2 Figure 1 depicts examples.
We create a cross-lingual word–category co-
occurrence matrix (CL-WCCM) with Chinese word
types wch as one dimension and English thesaurus
concepts cen as another.
The matrix is populated with co-occurrence counts
from a large Chinese corpus; we used a collection of
LDC-distributed corpora3—Chinese Treebank En-
glish Parallel Corpus, FBIS data, Xinhua Chinese-
English Parallel News Text Version 1.0 beta 2, Chi-
nese English News Magazine Parallel Text, Chinese
2Some of the cross-lingual candidate senses of wch might not
really be senses of wch (e.g., ‘celebrity’, ‘practical lesson’, and
‘state of the atmosphere’ in Figure 1). However, as substanti-
ated by experiments by Mohammad et al. (2007), our algorithm
is able to handle the added ambiguity.
</bodyText>
<footnote confidence="0.831528">
3http://www.ldc.upenn.edu
</footnote>
<figureCaption confidence="0.72162675">
Figure 2: Chinese words having ‘celestial body’ as
one of their cross-lingual candidate senses.
News Translation Text Part 1, and Hong Kong Paral-
lel Text. A particular cell mij, corresponding to word
</figureCaption>
<bodyText confidence="0.977066416666666">
wch
i and concept cenj , is populated with the number
of times the Chinese word wch
i co-occurs with any
Chinese word having cjen as one of its cross-lingual
candidate senses. For example, the cell for
(‘space’) and ‘celestial body’ will have the sum of
the number of times co-occurs with ,,
, ,, and so on (see Figure 2). We used
the Macquarie Thesaurus (Bernard, 1986) (about
98,000 words). The possible Chinese translations
of an English word were taken from the Chinese-
English Translation Lexicon version 3.0 (Huang and
Graff, 2002) (about 54,000 entries).
This base word–category co-occurrence matrix
(base WCCM), created after a first pass of the cor-
pus, captures strong associations between a cate-
gory (concept) and co-occurring words. For ex-
ample, even though we increment counts for both
–‘celestial body’ and –‘celebrity’ for a par-
ticular instance where co-occurs with
and ‘celebrity’.
As in the monolingual case, a second pass of
the corpus is made to disambiguate the (Chinese)
words in it. For each word, the strength of associ-
ation of each of the words in its context (f5 words)
with each of its cross-lingual candidate senses is
summed. The sense that has the highest cumula-
tive association with co-occurring words is chosen
as the intended sense. A new bootstrapped WCCM
is created by populating each cell mij, correspond-
ing to word wch
i and concept cen
j , with the number of
times the Chinese word wch
i co-occurs with any Chi-
</bodyText>
<figure confidence="0.946948210526316">
... ...
... ... ... ... ...
cen 1cen2... cenj ...
m11 m12 ... m1j ...
m21 m22 ... m2j ...
wch
1
...
.. ..
. .
mi1 mi2 ... mij ...
wch
2
...
wch
i
...
,
will co-occur with a number of words such as
</figure>
<bodyText confidence="0.8061815">
, , and that each have the sense of ce-
lestial body in common (see Figure 2), whereas all
their other senses are likely different and distributed
across the set of concepts. Therefore, the co-
occurrence count of and ‘celestial body’ will
be relatively higher than that of
</bodyText>
<page confidence="0.994331">
328
</page>
<bodyText confidence="0.999966789473684">
nese word used in cross-lingual sense cenj . A statistic
such as PMI is then applied to these counts to deter-
mine the strengths of association between a target
concept and co-occurring words, giving the distri-
butional profile of the concept.
Mohammad et al. (2007) combined German text
with an English thesaurus using a German–English
bilingual lexicon to create German–English DPCs.
These DPCs were used to determine semantic dis-
tance between German words, showing that state-of-
the-art accuracies for one language can be achieved
using a knowledge source (thesaurus) from another.
Given that a published thesaurus has about 1000
categories and the size of the vocabulary N is at
least 100,000, the CL-WCCM and the WCCM are
much smaller matrices (about 1000×N) than the tra-
ditional word–word co-occurrence matrix (N × N).
Therefore the WCCMs are relatively inexpensive
both in terms of memory and computation.
</bodyText>
<sectionHeader confidence="0.999091" genericHeader="method">
3 Classification
</sectionHeader>
<bodyText confidence="0.999909">
We implemented two unsupervised classifiers. The
words in context were used as features.
</bodyText>
<subsectionHeader confidence="0.998995">
3.1 Unsupervised Naive Bayes Classifier
</subsectionHeader>
<bodyText confidence="0.9997955">
The naive Bayes classifier has the following formula
to determine the intended sense cnb:
For the English Lexical Task, mij is the number of
times the English word wi co-occurs with the En-
glish category cj—as listed in the word–category
co-occurrence matrix (WCCM). For the Multilin-
gual Chinese–English Lexical Task, mij is the num-
ber of times the Chinese word wi co-occurs with the
English category cj—as listed in the cross-lingual
word–category co-occurrence matrix (CL-WCCM).
</bodyText>
<subsectionHeader confidence="0.997937">
3.2 PMI-based classifier
</subsectionHeader>
<bodyText confidence="0.999978666666667">
We calculate the pointwise mutual information be-
tween a sense of the target word and a co-occurring
word using the following formula:
</bodyText>
<equation confidence="0.996163555555555">
P(wi,cj)
PMI(wi,cj) = log (4)
P(wi) × P(cj)
mi j
where P(wi,cj) = (5)
∑ i, j mij
∑ j mi j
and P(wi) = (6)
∑ i,j mij
</equation>
<bodyText confidence="0.9999285">
mij is the count in the WCCM or CL-WCCM (as de-
scribed in the previous subsection). For each sense
of the target, the sum of the strength of association
(PMI) between it and each of the co-occurring words
(in a window of ±5 words) is calculated. The sense
with the highest sum is chosen as the intended sense.
</bodyText>
<equation confidence="0.79488">
cpmi = argmax ∑ PMI(wi,cj) (7)
cj∈C wi∈W
cnb = argmax P(cj) ∏ P(wi|cj) (1) Note that this PMI-based classifier does not capital-
cj∈C wi∈W ize on prior probabilities of the different senses.
</equation>
<bodyText confidence="0.998976">
where C is the set of possible senses (as listed in
the Macquarie Thesaurus) and W is the set of words
that co-occur with the target (we used a window of
±5 words).
Traditionally, prior probabilities of the senses
(P(cj)) and the conditional probabilities in the like-
lihood (∏wi∈W P(wi|cj)) are determined by sim-
ple counts in sense-annotated data. We approx-
imate these probabilities using counts from the
word–category co-occurrence matrix (monolingual
or cross-lingual), thereby obviating the need for
manually-annotated data.
</bodyText>
<equation confidence="0.9974115">
P(cj) = ∑ i mij (2)
∑ i, j mij
</equation>
<sectionHeader confidence="0.99946" genericHeader="method">
4 Data
</sectionHeader>
<subsectionHeader confidence="0.998965">
4.1 English Lexical Sample Task
</subsectionHeader>
<bodyText confidence="0.955291071428572">
The English Lexical Sample Task training and test
data (Pradhan et al., 2007) have 22281 and 4851
instances respectively for 100 target words (50
nouns and 50 verbs). WordNet 2.1 is used as
the sense inventory for most of the target words,
but certain words have one or more senses from
OntoNotes (Hovy et al., 2006). Many of the fine-
grained senses are grouped into coarser senses.
Our approach relies on representing a sense with
a number of near-synonymous words, for which a
thesaurus is a natural source. Even though the ap-
proach can be ported to WordNet4, there was no easy
P(wi|cj) = mij (3) 4The synonyms within a synset, along with its one-hop
∑ imij neighbors and all its hyponyms, can represent that sense.
</bodyText>
<page confidence="0.947864">
329
</page>
<table confidence="0.9993412">
TRAINING DATA TEST DATA
WORDS BASELINE PMI-BASED NA¨IVE BAYES PRIOR LIKELIHOOD NA¨IVE BAYES
all 27.8 41.4 50.8 37.4 49.4 52.1
nouns only 25.6 43.4 53.6 18.1 49.6 49.7
verbs only 29.2 38.4 44.5 58.9 49.1 54.7
</table>
<tableCaption confidence="0.999106">
Table 1: English Lexical Sample Task: Results obtained using the PMI-based classifier on the training data
</tableCaption>
<bodyText confidence="0.983708222222222">
and the naive Bayes classifier on both training and test data
way of representing OntoNotes senses with near-
synonymous words. Therefore, we asked four na-
tive speakers of English to map the WordNet and
OntoNotes senses of the 100 target words to the
Macquarie Thesaurus and use it as our sense inven-
tory. We also wanted to examine the effect of using
a very coarse sense inventory such as the categories
in a published thesaurus (811 in all).
The annotators were presented with a target word,
its WordNet/OntoNotes senses, and the Macquarie
senses. WordNet senses were represented by syn-
onyms, gloss, and example usages. The OntoNotes
senses were described through syntactic patterns and
example usages (provided by the task organizers).
The Macquarie senses (categories) were described
by the category head (a representative word for
the category) and five other words in the category.
Specifically, words in the same semicolon group5 as
the target were chosen. Annotators 1 and 2 labeled
each WordNet/OntoNotes sense of the first 50 target
words with one or more appropriate Macquarie cat-
egories. Annotators 3 and 4 labeled the senses of the
other 50 words. We combined all four annotations
into a WordNet–Macquarie mapping file by taking,
for each target word, the union of categories chosen
by the two annotators.
</bodyText>
<subsectionHeader confidence="0.995549">
4.2 English Lexical Substitution Task
</subsectionHeader>
<bodyText confidence="0.9999485">
The English Lexical Substitution Task has 1710 test
instances for 171 target words (nouns, verbs, adjec-
tives, and adverbs) (McCarthy and Navigli, 2007).
Some instances were randomly extracted from an
Internet corpus, whereas others were selected man-
ually from it. The target word might or might not be
part of a multiword expression. The task is not tied
to any particular sense inventory.
</bodyText>
<footnote confidence="0.951929">
5Words within a semicolon group of a thesaurus tend to be
more closely related than words across groups.
</footnote>
<subsectionHeader confidence="0.9992395">
4.3 Multilingual Chinese–English Lexical
Sample Task
</subsectionHeader>
<bodyText confidence="0.999868736842105">
The Multilingual Chinese–English Lexical Sample
Task training and test data (Jin et al., 2007) have
2686 and 935 instances respectively for 40 target
words (19 nouns and 21 verbs). The instances are
taken from a corpus of People’s Daily News. The
organizers used the Chinese Semantic Dictionary
(CSD), developed by the Institute of Computational
Linguistics, Peking University, both as a sense in-
ventory and bilingual lexicon (to extract a suitable
English translation of the target word once the in-
tended Chinese sense is determined).
In order to determine the English translations of
Chinese words in context, our system relies on Chi-
nese text and an English thesaurus. As the thesaurus
is used as our sense inventory, the first author and a
native speaker of Chinese mapped the English trans-
lations of the target to appropriate Macquarie cate-
gories. We used three examples (from the training
data) per English translation for this purpose.
</bodyText>
<sectionHeader confidence="0.999816" genericHeader="method">
5 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.99885">
5.1 English Lexical Sample Task
</subsectionHeader>
<bodyText confidence="0.999964428571429">
Both the naive Bayes classifier and the PMI-based
one were applied to the training data. For each in-
stance, the Macquarie category c that best captures
the intended sense of the target was determined. The
instance was labeled with all the WordNet senses
that are mapped to c in the WordNet–Macquarie
mapping file (described earlier in Section 4.1).
</bodyText>
<sectionHeader confidence="0.902457" genericHeader="method">
5.1.1 Results
</sectionHeader>
<bodyText confidence="0.9997624">
Table 1 shows the performances of the two clas-
sifiers. The system attempted to label all instances
and so we report accuracy values instead of pre-
cision and recall. The naive Bayes classifier per-
formed markedly better in training than the PMI-
</bodyText>
<page confidence="0.994127">
330
</page>
<bodyText confidence="0.999895714285714">
based one and so was applied to the test data. The
table also lists baseline results obtained when a sys-
tem randomly guesses one of the possible senses for
each target word. Note that since this is a com-
pletely unsupervised system, it is not privy to the
dominant sense of the target words. We do not rely
on the ranking of senses in WordNet as that would
be an implicit use of the sense-tagged SemCor cor-
pus. Therefore, the most-frequent-sense baseline
does not apply. Table 1 also shows results obtained
using just the prior probability and likelihood com-
ponents of the naive Bayes formula. Note that the
combined accuracy is higher than individual com-
ponents for nouns but not for verbs.
</bodyText>
<subsubsectionHeader confidence="0.507384">
5.1.2 Discussion
</subsubsectionHeader>
<bodyText confidence="0.9999608125">
The naive Bayes classifier’s accuracy is only
about one percentage point lower than that of the
best unsupervised system taking part in the task
(Pradhan et al., 2007). One reason that it does bet-
ter than the PMI-based one is that it takes into ac-
count prior probabilities of the categories. However,
using just the likelihood also outperforms the PMI
classifier. This may be because of known problems
of using PMI with low frequencies (Manning and
Sch¨utze, 1999). In case of verbs, lower combined
accuracies compared to when using just prior proba-
bilities suggests that the bag-of-words type features
are not very useful. It is expected that more syntac-
tically oriented features will give better results. Us-
ing window sizes (±1,±2, and ±10) on the training
data resulted in lower accuracies than that obtained
using a window of ±5 words. A smaller window
size is probably missing useful co-occurring words,
whereas a larger window size is adding words that
are not indicative of the target’s intended sense.
The use of a sense inventory (Macquarie The-
saurus) different from that used to label the data
(WordNet) clearly will have a negative impact on
the results. The mapping from WordNet/OntoNotes
to Macquarie is likely to have some errors. Further,
for 19 WordNet/OntoNotes senses, none of the an-
notators found a thesaurus category close enough in
meaning. This meant that our system had no way
of correctly disambiguating instances with these
senses. Also impacting accuracy is the significantly
fine-grained nature of WordNet compared to the the-
saurus. For example, following are the three coarse
</bodyText>
<table confidence="0.99914525">
BEST Acc OOT
Acc Mode Acc Mode Acc
all 2.98 4.72 11.19 14.63
Further Analysis
NMWT 3.22 5.04 11.77 15.03
NMWS 3.32 4.90 12.22 15.26
RAND 3.10 5.20 9.98 13.00
MAN 2.84 4.17 12.61 16.49
</table>
<tableCaption confidence="0.8344745">
Table 2: English Lexical Substitution Task: Results
obtained using the PMI-based classifier
</tableCaption>
<bodyText confidence="0.9944694">
senses for the noun president in WordNet: (1) exec-
utive officer of a firm or college, (2) the chief exec-
utive of a republic, and (3) President of the United
States. The last two senses will fall into just one cat-
egory for most, if not all, thesauri.
</bodyText>
<subsectionHeader confidence="0.999249">
5.2 English Lexical Substitution Task
</subsectionHeader>
<bodyText confidence="0.999988">
We used the PMI-based classifier6 for the English
Lexical Substitution Task. Once it identifies a suit-
able thesaurus category as the intended sense for a
target, ten candidate substitutes are chosen from that
category. Specifically, the category head word and
up to nine words in the same semicolon group as the
target are selected (words within a semicolon group
are closer in meaning). Of the ten candidates, the
single-word expression that is most frequent in the
BNC is chosen as the best substitute; the motivation
is that the annotators, who created the gold standard,
were instructed to give preference to single words
over multiword expressions as substitutes.
</bodyText>
<sectionHeader confidence="0.746124" genericHeader="method">
5.2.1 Results
</sectionHeader>
<bodyText confidence="0.9999671">
The system was evaluated not only on the best
substitute (BEST) but also on how good the top ten
candidate substitutes are (OOT). Table 2 presents the
results.7 The system attempted all instances. The
table also lists performances of the system on in-
stances where the target is not part of a multiword
expression (NMWT), on instances where the substi-
tute is not a multiword expression (NMWS), on in-
stances randomly extracted from the corpus (RAND),
and on instances manually selected (MAN).
</bodyText>
<footnote confidence="0.9939225">
6Due to time constraints, we were able to upload results only
with the PMI-based classifier by the task deadline.
7The formulae for accuracy and mode accuracy are as de-
scribed by Pradhan et al. (2007).
</footnote>
<page confidence="0.988468">
331
</page>
<table confidence="0.998914833333333">
BASELINE TRAINING DATA PRIOR TEST DATA NA¨IVE BAYES
PMI-BASED NA¨IVE BAYES LIKELIHOOD
WORDS micro macro micro macro micro macro micro macro micro macro micro macro
all 33.1 38.3 33.9 40.0 38.5 44.7 35.4 41.7 38.8 44.6 37.5 43.1
nouns only 41.9 43.5 43.6 45.0 49.4 50.5 45.3 47.1 48.1 50.8 50.0 51.6
verbs only 28.0 34.1 28.0 35.6 31.9 39.6 29.1 36.8 32.9 39.0 29.6 35.5
</table>
<tableCaption confidence="0.960492">
Table 3: Multilingual Chinese–English Lexical Sample Task: Results obtained using the PMI-based classi-
fier on the training data and the naive Bayes classifier on both training and test data
</tableCaption>
<sectionHeader confidence="0.580942" genericHeader="method">
5.2.2 Discussion
</sectionHeader>
<bodyText confidence="0.999941736842105">
Competitive performance of our DPC-based sys-
tem on the English Lexical Sample Task and the
Chinese–English Lexical Sample Task (see next
subsection) suggests that DPCs are useful for sense
disambiguation. Poor results on the substitution task
can be ascribed to several factors. First, we used
the PMI-based classifier that we found later to be
markedly less accurate than the naive Bayes clas-
sifier in the other two tasks. Second, the words in
the thesaurus categories may not always be near-
synonyms; they might just be strongly related. Such
words will be poor substitutes for the target. Also,
we chose as the best substitute simply the most fre-
quent of the ten candidates. This simple technique
is probably not accurate enough. On the other hand,
because we chose the candidates without any regard
to frequency in a corpus, the system chose certain
infrequent words such as wellnigh and ecchymosed,
which were not good candidate substitutes.
</bodyText>
<subsectionHeader confidence="0.997907">
5.3 Multilingual Chinese–English Lexical
Sample Task
</subsectionHeader>
<bodyText confidence="0.999913111111111">
In the Multilingual Chinese–English Lexical Sample
Task, both the naive Bayes classifier and the PMI-
based classifier were applied to the training data.
For each instance, the Macquarie category, say c,
that best captures the intended sense of the target
word is determined. Then the instance is labeled
with all the English translations that are mapped to c
in the English translations–Macquarie mapping file
(described earlier in Section 4.3).
</bodyText>
<sectionHeader confidence="0.969306" genericHeader="evaluation">
5.3.1 Results
</sectionHeader>
<bodyText confidence="0.999953461538462">
Table 3 shows accuracies of the two classifiers.
Macro average is the ratio of number of instances
correctly disambiguated to the total, whereas micro
average is the average of the accuracies achieved
on each target word. As in the English Lexical
Sample Task, both classifiers, especially the naive
Bayes classifier, perform well above the random
baseline. Since the naive Bayes classifier also per-
formed markedly better than the PMI-based one in
training, it was applied to the test data. Table 3
also shows results obtained using just the likelihood
and prior probability components of the naive Bayes
classifier on the test data.
</bodyText>
<sectionHeader confidence="0.717548" genericHeader="evaluation">
5.3.2 Discussion
</sectionHeader>
<bodyText confidence="0.999987444444444">
Our naive Bayes classifier scored highest of all
unsupervised systems taking part in the task (Jin et
al., 2007). As in the English Lexical Sample Task,
using just the likelihood again outperforms the PMI
classifier on the training data. The use of a sense
inventory different from that used to label the data
again will have a negative impact on the results as
the mapping may have a few errors. The anno-
tator believed none of the given Macquarie cate-
gories could be mapped to two Chinese Semantic
Dictionary senses. This meant that our system had
no way of correctly disambiguating instances with
these senses.
There were also a number of cases where more
than one CSD sense of a word was mapped to the
same Macquarie category. This occurred for two
reasons: First, the categories of the Macquarie The-
saurus act as very coarse senses. Second, for cer-
tain target words, the two CSD senses may be differ-
ent in terms of their syntactic behavior, yet semanti-
cally very close (for example, the ‘be shocked’ and
‘shocked’ senses of ). This many-to-one map-
ping meant that for a number of instances more than
one English translation was chosen. Since the task
required us to provide exactly one answer (and there
was no partial credit in case of multiple answers), a
category was chosen at random.
</bodyText>
<page confidence="0.996208">
332
</page>
<sectionHeader confidence="0.999365" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999990730769231">
We implemented a system that uses distributional
profiles of concepts (DPCs) for unsupervised word
sense disambiguation. We used words in the con-
text as features. Specifically, we used the DPCs
to create a naive Bayes word-sense classifier and a
simple PMI-based classifier. Our system attempted
three SemEval-2007 tasks. On the training data
of the English Lexical Sample Task (task #17) and
the Multilingual Chinese–English Lexical Sample
Task (task #5), the naive Bayes classifier achieved
markedly better results than the PMI-based classi-
fier and so was applied to the respective test data.
On both test and training data of both tasks, the
system achieved accuracies well above the random
baseline. Further, our system placed best or close to
one percentage point from the best among the unsu-
pervised systems. In the English Lexical Substitu-
tion Task (task #10), for which there was no train-
ing data, we used the PMI-based classifier. The
system performed poorly, which is probably a re-
sult of using the weaker classifier and a simple brute
force method for identifying the substitute among
the words in a thesaurus category. Markedly higher-
than-baseline performance of the naive Bayes clas-
sifier on task #17 and task #5 suggests that the DPCs
are useful for word sense disambiguation.
</bodyText>
<sectionHeader confidence="0.999228" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.957791333333333">
We gratefully acknowledge Xiaodan Zhu, Michael Demko,
Christopher Parisien, Frank Rudicz, and Timothy Fowler for
mapping training-data labels to categories in the Macquarie
Thesaurus. We thank Michael Demko, Siddharth Patwardhan,
Xinglong Wang, Vivian Tsang, and Afra Alishahi for helpful
discussions. This research is financially supported by the Natu-
ral Sciences and Engineering Research Council of Canada, the
University of Toronto, ONR MURI Contract FCPO.810548265
and Department of Defense contract RD-02-5700.
</bodyText>
<sectionHeader confidence="0.998591" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999937484375">
J.R.L. Bernard, editor. 1986. The Macquarie Thesaurus.
Macquarie Library, Sydney, Australia.
Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance
Ramshaw, and Ralph Weischedel. 2006. OntoNotes:
The 90% Solution. In Proceedings of the Human Lan-
guage Technology Conference of the North American
Chapter of the ACL, pages 57–60, New York, NY.
Shudong Huang and David Graff. 2002. Chinese–
english translation lexicon version 3.0. Linguistic
Data Consortium.
Jay J. Jiang and David W. Conrath. 1997. Semantic
similarity based on corpus statistics and lexical taxon-
omy. In Proceedings of International Conference on
Research on Computational Linguistics, Taiwan.
Peng Jin, Yunfang Wu, and Shiwen Yu. 2007. SemEval-
2007 task 05: Multilingual Chinese-English lexical
sample task. In Proceedings of the Fourth Interna-
tional Workshop on the Evaluation of Systems for the
Semantic Analysis of Text, Prague, Czech Republic.
Christopher D. Manning and Hinrich Sch¨utze. 1999.
Foundations of Statistical Natural Language Process-
ing. MIT Press, Cambridge, Massachusetts.
Diana McCarthy and Roberto Navigli. 2007. SemEval-
2007 task 10: English lexical substitution task. In
Proceedings of the Fourth International Workshop on
the Evaluation of Systems for the Semantic Analysis of
Text (SemEval-2007), Prague, Czech Republic.
Diana McCarthy, Rob Koeling, Julie Weeds, and John
Carroll. 2004. Finding predominant senses in un-
tagged text. In Proceedings of the 42nd Annual Meet-
ing of the Association for Computational Linguistics
(ACL-04), pages 280–267, Barcelona, Spain.
Saif Mohammad and Graeme Hirst. 2006a. Determining
word sense dominance using a thesaurus. In Proceed-
ings of the 11th Conference of the European Chap-
ter of the Association for Computational Linguistics
(EACL), Trento, Italy.
Saif Mohammad and Graeme Hirst. 2006b. Distribu-
tional measures of concept-distance: A task-oriented
evaluation. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP-2006), Sydney, Australia.
Saif Mohammad, Iryna Gurevych, Graeme Hirst, and
Torsten Zesch. 2007. Cross-lingual distributional
profiles of concepts for measuring semantic dis-
tance. In Proceedings of the Joint Conference on
Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP/CoNLL-2007), Prague, Czech Republic.
Sameer Pradhan, Martha Palmer, and Edward Loper.
2007. SemEval-2007 task 17: English lexical sample,
English SRL and English all-words tasks. In Proceed-
ings of the Fourth International Workshop on the Eval-
uation of Systems for the Semantic Analysis of Text
(SemEval-2007), Prague, Czech Republic.
Philip Resnik. 1998. Wordnet and class-based prob-
abilities. In Christiane Fellbaum, editor, WordNet:
An Electronic Lexical Database, pages 239–263. The
MIT Press, Cambridge, Massachusetts.
David Yarowsky. 1992. Word-sense disambiguation us-
ing statistical models of Roget’s categories trained on
large corpora. In Proceedings of the 14th International
Conference on Computational Linguistics (COLING-
92), pages 454–460, Nantes, France.
</reference>
<page confidence="0.999411">
333
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.740748">
<title confidence="0.992983">Distributional Profiles of Concepts for Unsupervised Word Sense Disambiguation</title>
<author confidence="0.988502">Saif Mohammad</author>
<affiliation confidence="0.9999795">Dept. of Computer Science University of Toronto</affiliation>
<address confidence="0.9425525">Toronto, ON M5S 3G4 Canada</address>
<email confidence="0.999882">smm@cs.toronto.edu</email>
<author confidence="0.999118">Graeme Hirst</author>
<affiliation confidence="0.999984">Dept. of Computer Science University of Toronto</affiliation>
<address confidence="0.94621">Toronto, ON M5S 3G4 Canada</address>
<email confidence="0.999881">gh@cs.toronto.edu</email>
<author confidence="0.999938">Philip Resnik</author>
<affiliation confidence="0.999934">Dept. of Linguistics and UMIACS University of Maryland</affiliation>
<address confidence="0.999405">College Park, MD 20742 USA</address>
<email confidence="0.999869">resnik@umiacs.umd.edu</email>
<abstract confidence="0.9933002">Words in the context of a target word have long been used as features by supervised word-sense classifiers. Mohammad and Hirst (2006a) proposed a way to determine the strength of association between a sense or concept and co-occurring words—the distributional profile of a concept (DPC)—without the use of manually annotated data. We implemented an unsupervised naive Bayes word sense classifier using these DPCs that was best or within one percentage point of the best unsupervised systems in the Multilingual Chinese- English Lexical Sample Task (task #5) and the English Lexical Sample Task (task #17). We also created a simple PMI-based classifier to attempt the English Lexical Substitution Task (task #10); however, its performance was poor.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<date>1986</date>
<booktitle>The Macquarie Thesaurus. Macquarie Library,</booktitle>
<editor>J.R.L. Bernard, editor.</editor>
<location>Sydney, Australia.</location>
<marker>1986</marker>
<rawString>J.R.L. Bernard, editor. 1986. The Macquarie Thesaurus. Macquarie Library, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard Hovy</author>
<author>Mitchell Marcus</author>
<author>Martha Palmer</author>
<author>Lance Ramshaw</author>
<author>Ralph Weischedel</author>
</authors>
<title>OntoNotes: The 90% Solution.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL,</booktitle>
<pages>57--60</pages>
<location>New York, NY.</location>
<contexts>
<context position="14794" citStr="Hovy et al., 2006" startWordPosition="2454" endWordPosition="2457">etermined by simple counts in sense-annotated data. We approximate these probabilities using counts from the word–category co-occurrence matrix (monolingual or cross-lingual), thereby obviating the need for manually-annotated data. P(cj) = ∑ i mij (2) ∑ i, j mij 4 Data 4.1 English Lexical Sample Task The English Lexical Sample Task training and test data (Pradhan et al., 2007) have 22281 and 4851 instances respectively for 100 target words (50 nouns and 50 verbs). WordNet 2.1 is used as the sense inventory for most of the target words, but certain words have one or more senses from OntoNotes (Hovy et al., 2006). Many of the finegrained senses are grouped into coarser senses. Our approach relies on representing a sense with a number of near-synonymous words, for which a thesaurus is a natural source. Even though the approach can be ported to WordNet4, there was no easy P(wi|cj) = mij (3) 4The synonyms within a synset, along with its one-hop ∑ imij neighbors and all its hyponyms, can represent that sense. 329 TRAINING DATA TEST DATA WORDS BASELINE PMI-BASED NA¨IVE BAYES PRIOR LIKELIHOOD NA¨IVE BAYES all 27.8 41.4 50.8 37.4 49.4 52.1 nouns only 25.6 43.4 53.6 18.1 49.6 49.7 verbs only 29.2 38.4 44.5 58</context>
</contexts>
<marker>Hovy, Marcus, Palmer, Ramshaw, Weischedel, 2006</marker>
<rawString>Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance Ramshaw, and Ralph Weischedel. 2006. OntoNotes: The 90% Solution. In Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 57–60, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shudong Huang</author>
<author>David Graff</author>
</authors>
<title>Chinese– english translation lexicon version 3.0. Linguistic Data Consortium.</title>
<date>2002</date>
<contexts>
<context position="10191" citStr="Huang and Graff, 2002" startWordPosition="1662" endWordPosition="1665">ext Part 1, and Hong Kong Parallel Text. A particular cell mij, corresponding to word wch i and concept cenj , is populated with the number of times the Chinese word wch i co-occurs with any Chinese word having cjen as one of its cross-lingual candidate senses. For example, the cell for (‘space’) and ‘celestial body’ will have the sum of the number of times co-occurs with ,, , ,, and so on (see Figure 2). We used the Macquarie Thesaurus (Bernard, 1986) (about 98,000 words). The possible Chinese translations of an English word were taken from the ChineseEnglish Translation Lexicon version 3.0 (Huang and Graff, 2002) (about 54,000 entries). This base word–category co-occurrence matrix (base WCCM), created after a first pass of the corpus, captures strong associations between a category (concept) and co-occurring words. For example, even though we increment counts for both –‘celestial body’ and –‘celebrity’ for a particular instance where co-occurs with and ‘celebrity’. As in the monolingual case, a second pass of the corpus is made to disambiguate the (Chinese) words in it. For each word, the strength of association of each of the words in its context (f5 words) with each of its cross-lingual candidate se</context>
</contexts>
<marker>Huang, Graff, 2002</marker>
<rawString>Shudong Huang and David Graff. 2002. Chinese– english translation lexicon version 3.0. Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay J Jiang</author>
<author>David W Conrath</author>
</authors>
<title>Semantic similarity based on corpus statistics and lexical taxonomy.</title>
<date>1997</date>
<booktitle>In Proceedings of International Conference on Research on Computational Linguistics,</booktitle>
<contexts>
<context position="8226" citStr="Jiang and Conrath (1997)" startWordPosition="1352" endWordPosition="1355">lling errors, attaining markedly better results than monolingual distributional measures of word-distance. In the spelling correction task, the 1The McCarthy et al. (2004) system needs to first generate a distributional thesaurus from the target text (if it is large enough—a few million words) or from another large text with a distribution of senses similar to the target text. wen 1 wen 2 ... wen i ... ... ... 327 Figure 1: The cross-lingual candidate senses of Chinese words and . distributional concept-distance measures performed better than all WordNet-based measures as well, except for the Jiang and Conrath (1997) measure. 2.2 Cross-lingual word–category co-occurrence matrix Given a Chinese word wch in context, we use a Chinese–English bilingual lexicon to determine its different possible English translations. Each English translation wen may have one or more possible coarse senses, as listed in an English thesaurus. These English thesaurus concepts (cen) will be referred to as cross-lingual candidate senses of the Chinese word wch.2 Figure 1 depicts examples. We create a cross-lingual word–category cooccurrence matrix (CL-WCCM) with Chinese word types wch as one dimension and English thesaurus concept</context>
</contexts>
<marker>Jiang, Conrath, 1997</marker>
<rawString>Jay J. Jiang and David W. Conrath. 1997. Semantic similarity based on corpus statistics and lexical taxonomy. In Proceedings of International Conference on Research on Computational Linguistics, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peng Jin</author>
<author>Yunfang Wu</author>
<author>Shiwen Yu</author>
</authors>
<title>SemEval2007 task 05: Multilingual Chinese-English lexical sample task.</title>
<date>2007</date>
<booktitle>In Proceedings of the Fourth International Workshop on the Evaluation of Systems for the Semantic Analysis of Text,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="3656" citStr="Jin et al., 2007" startWordPosition="572" endWordPosition="575">e a target word in a sentence with a suitable substitute that preserves the meaning of the utterance. The list of possible substitutes for a given target word is usually contingent on its intended sense. Therefore, word sense disambiguation is expected to be useful in lexical substitution. We used the PMI-based classier to determine the intended sense. 326 Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 326–333, Prague, June 2007. c�2007 Association for Computational Linguistics The objective of the Multilingual Chinese– English Lexical Sample Task (Jin et al., 2007) is to select from a given list a suitable English translation of a Chinese target word in context. Mohammad et al. (2007) proposed a way to create cross-lingual distributional profiles of a concepts (CL-DPCs)— the strengths of association between the concepts of one language and words of another. For this task, we mapped the list of English translations to appropriate thesaurus categories and used an implementation of a CL-DPC–based unsupervised naive Bayes classifier to identify the intended senses (and thereby the English translations) of target Chinese words. 2 Distributional profiles of c</context>
<context position="17511" citStr="Jin et al., 2007" startWordPosition="2897" endWordPosition="2900">itution Task has 1710 test instances for 171 target words (nouns, verbs, adjectives, and adverbs) (McCarthy and Navigli, 2007). Some instances were randomly extracted from an Internet corpus, whereas others were selected manually from it. The target word might or might not be part of a multiword expression. The task is not tied to any particular sense inventory. 5Words within a semicolon group of a thesaurus tend to be more closely related than words across groups. 4.3 Multilingual Chinese–English Lexical Sample Task The Multilingual Chinese–English Lexical Sample Task training and test data (Jin et al., 2007) have 2686 and 935 instances respectively for 40 target words (19 nouns and 21 verbs). The instances are taken from a corpus of People’s Daily News. The organizers used the Chinese Semantic Dictionary (CSD), developed by the Institute of Computational Linguistics, Peking University, both as a sense inventory and bilingual lexicon (to extract a suitable English translation of the target word once the intended Chinese sense is determined). In order to determine the English translations of Chinese words in context, our system relies on Chinese text and an English thesaurus. As the thesaurus is us</context>
<context position="26068" citStr="Jin et al., 2007" startWordPosition="4308" endWordPosition="4311">icro average is the average of the accuracies achieved on each target word. As in the English Lexical Sample Task, both classifiers, especially the naive Bayes classifier, perform well above the random baseline. Since the naive Bayes classifier also performed markedly better than the PMI-based one in training, it was applied to the test data. Table 3 also shows results obtained using just the likelihood and prior probability components of the naive Bayes classifier on the test data. 5.3.2 Discussion Our naive Bayes classifier scored highest of all unsupervised systems taking part in the task (Jin et al., 2007). As in the English Lexical Sample Task, using just the likelihood again outperforms the PMI classifier on the training data. The use of a sense inventory different from that used to label the data again will have a negative impact on the results as the mapping may have a few errors. The annotator believed none of the given Macquarie categories could be mapped to two Chinese Semantic Dictionary senses. This meant that our system had no way of correctly disambiguating instances with these senses. There were also a number of cases where more than one CSD sense of a word was mapped to the same Ma</context>
</contexts>
<marker>Jin, Wu, Yu, 2007</marker>
<rawString>Peng Jin, Yunfang Wu, and Shiwen Yu. 2007. SemEval2007 task 05: Multilingual Chinese-English lexical sample task. In Proceedings of the Fourth International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Sch¨utze</author>
</authors>
<date>1999</date>
<booktitle>Foundations of Statistical Natural Language Processing.</booktitle>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<marker>Manning, Sch¨utze, 1999</marker>
<rawString>Christopher D. Manning and Hinrich Sch¨utze. 1999. Foundations of Statistical Natural Language Processing. MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Roberto Navigli</author>
</authors>
<title>SemEval2007 task 10: English lexical substitution task.</title>
<date>2007</date>
<booktitle>In Proceedings of the Fourth International Workshop on the Evaluation of Systems for the Semantic Analysis of Text (SemEval-2007),</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="3026" citStr="McCarthy and Navigli, 2007" startWordPosition="475" endWordPosition="479">al 2007 tasks: the English Lexical Sample Task (task #17), the English Lexical Substitution Task (task #10), and the Multilingual ChineseEnglish Lexical Sample Task (task #5). The English Lexical Sample Task (Pradhan et al., 2007) is a traditional word sense disambiguation task wherein the intended (WordNet) sense of a target word is to be determined from its context. We manually mapped the WordNet senses to the categories in a thesaurus and the DPC-based naive Bayes classifier was used to identify the intended sense (category) of the target words. The object of the Lexical Substitution Task (McCarthy and Navigli, 2007) is to replace a target word in a sentence with a suitable substitute that preserves the meaning of the utterance. The list of possible substitutes for a given target word is usually contingent on its intended sense. Therefore, word sense disambiguation is expected to be useful in lexical substitution. We used the PMI-based classier to determine the intended sense. 326 Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 326–333, Prague, June 2007. c�2007 Association for Computational Linguistics The objective of the Multilingual Chinese– English Lexical </context>
<context position="17020" citStr="McCarthy and Navigli, 2007" startWordPosition="2819" endWordPosition="2822">egory. Specifically, words in the same semicolon group5 as the target were chosen. Annotators 1 and 2 labeled each WordNet/OntoNotes sense of the first 50 target words with one or more appropriate Macquarie categories. Annotators 3 and 4 labeled the senses of the other 50 words. We combined all four annotations into a WordNet–Macquarie mapping file by taking, for each target word, the union of categories chosen by the two annotators. 4.2 English Lexical Substitution Task The English Lexical Substitution Task has 1710 test instances for 171 target words (nouns, verbs, adjectives, and adverbs) (McCarthy and Navigli, 2007). Some instances were randomly extracted from an Internet corpus, whereas others were selected manually from it. The target word might or might not be part of a multiword expression. The task is not tied to any particular sense inventory. 5Words within a semicolon group of a thesaurus tend to be more closely related than words across groups. 4.3 Multilingual Chinese–English Lexical Sample Task The Multilingual Chinese–English Lexical Sample Task training and test data (Jin et al., 2007) have 2686 and 935 instances respectively for 40 target words (19 nouns and 21 verbs). The instances are take</context>
</contexts>
<marker>McCarthy, Navigli, 2007</marker>
<rawString>Diana McCarthy and Roberto Navigli. 2007. SemEval2007 task 10: English lexical substitution task. In Proceedings of the Fourth International Workshop on the Evaluation of Systems for the Semantic Analysis of Text (SemEval-2007), Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Rob Koeling</author>
<author>Julie Weeds</author>
<author>John Carroll</author>
</authors>
<title>Finding predominant senses in untagged text.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL-04),</booktitle>
<pages>280--267</pages>
<location>Barcelona,</location>
<contexts>
<context position="7257" citStr="McCarthy et al. (2004)" startWordPosition="1202" endWordPosition="1205">te the words in it. For each word, the strength of association of each of the words in its context (±5 words) with each of its senses is summed. The sense that has the highest cumulative association is chosen as the intended sense. A new bootstrapped WCCM is created such that each cell mij, corresponding to word wen iand concept cen j , is populated with the number of times wen i co-occurs with any word used in sense cen j . Mohammad and Hirst (2006a) used the DPCs created from the bootstrapped WCCM to attain near-upper-bound results in the task of determining word sense dominance. Unlike the McCarthy et al. (2004) dominance system, this approach can be applied to much smaller target texts (a few hundred sentences) without the need for a large similarly-sense-distributed text1. Mohammad and Hirst (2006b) used the DPC-based monolingual distributional measures of concept-distance to rank word pairs by their semantic similarity and to correct real-word spelling errors, attaining markedly better results than monolingual distributional measures of word-distance. In the spelling correction task, the 1The McCarthy et al. (2004) system needs to first generate a distributional thesaurus from the target text (if </context>
</contexts>
<marker>McCarthy, Koeling, Weeds, Carroll, 2004</marker>
<rawString>Diana McCarthy, Rob Koeling, Julie Weeds, and John Carroll. 2004. Finding predominant senses in untagged text. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL-04), pages 280–267, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Graeme Hirst</author>
</authors>
<title>Determining word sense dominance using a thesaurus.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="1735" citStr="Mohammad and Hirst, 2006" startWordPosition="270" endWordPosition="273">l Substitution Task (task #10); however, its performance was poor. 1 Introduction Determining the intended sense of a word is potentially useful in many natural language tasks including machine translation and information retrieval. The best approaches for word sense disambiguation are supervised and they use words that co-occur with the target as features. These systems rely on senseannotated data to identify words that are indicative of the use of the target in each of its senses. However, only limited amounts of senseannotated data exist and it is expensive to create. In our previous work (Mohammad and Hirst, 2006a), we proposed an unsupervised approach to determine the strength of association between a sense or concept and its co-occurring words—the distributional profile of a concept (DPC)—relying simply on raw text and a published thesaurus. The categories in a published thesaurus were used as coarse senses or concepts (Yarowsky, 1992). We now show how distributional profiles of concepts can be used to create an unsupervised naive Bayes word-sense classifier. We also implemented a simple classifier that relies on the pointwise mutual information (PMI) between the senses of the target and co-occurrin</context>
<context position="4480" citStr="Mohammad and Hirst (2006" startWordPosition="703" endWordPosition="706">(CL-DPCs)— the strengths of association between the concepts of one language and words of another. For this task, we mapped the list of English translations to appropriate thesaurus categories and used an implementation of a CL-DPC–based unsupervised naive Bayes classifier to identify the intended senses (and thereby the English translations) of target Chinese words. 2 Distributional profiles of concepts In order to determine the strength of association between a sense of the target word and its co-occurring words, we need to determine their individual and joint occurrence counts in a corpus. Mohammad and Hirst (2006a) and Mohammad et al. (2007) proposed ways to determine these counts in a monolingual and cross-lingual framework without the use of senseannotated data. We summarize the ideas in this section; the original papers give more details. 2.1 Word–category co-occurrence matrix We create a word–category co-occurrence matrix (WCCM) having English word types wen as one dimension and English thesaurus categories cen as another. We used the Macquarie Thesaurus (Bernard, 1986) both as a very coarse-grained sense inventory and a source of words that together represent each category (concept). The WCCM is </context>
<context position="7088" citStr="Mohammad and Hirst (2006" startWordPosition="1175" endWordPosition="1178">at occur close to a target word tend to be good indicators of its intended sense. Therefore, we make a second pass of the corpus, using the base WCCM to roughly disambiguate the words in it. For each word, the strength of association of each of the words in its context (±5 words) with each of its senses is summed. The sense that has the highest cumulative association is chosen as the intended sense. A new bootstrapped WCCM is created such that each cell mij, corresponding to word wen iand concept cen j , is populated with the number of times wen i co-occurs with any word used in sense cen j . Mohammad and Hirst (2006a) used the DPCs created from the bootstrapped WCCM to attain near-upper-bound results in the task of determining word sense dominance. Unlike the McCarthy et al. (2004) dominance system, this approach can be applied to much smaller target texts (a few hundred sentences) without the need for a large similarly-sense-distributed text1. Mohammad and Hirst (2006b) used the DPC-based monolingual distributional measures of concept-distance to rank word pairs by their semantic similarity and to correct real-word spelling errors, attaining markedly better results than monolingual distributional measur</context>
</contexts>
<marker>Mohammad, Hirst, 2006</marker>
<rawString>Saif Mohammad and Graeme Hirst. 2006a. Determining word sense dominance using a thesaurus. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL), Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Graeme Hirst</author>
</authors>
<title>Distributional measures of concept-distance: A task-oriented evaluation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2006),</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="1735" citStr="Mohammad and Hirst, 2006" startWordPosition="270" endWordPosition="273">l Substitution Task (task #10); however, its performance was poor. 1 Introduction Determining the intended sense of a word is potentially useful in many natural language tasks including machine translation and information retrieval. The best approaches for word sense disambiguation are supervised and they use words that co-occur with the target as features. These systems rely on senseannotated data to identify words that are indicative of the use of the target in each of its senses. However, only limited amounts of senseannotated data exist and it is expensive to create. In our previous work (Mohammad and Hirst, 2006a), we proposed an unsupervised approach to determine the strength of association between a sense or concept and its co-occurring words—the distributional profile of a concept (DPC)—relying simply on raw text and a published thesaurus. The categories in a published thesaurus were used as coarse senses or concepts (Yarowsky, 1992). We now show how distributional profiles of concepts can be used to create an unsupervised naive Bayes word-sense classifier. We also implemented a simple classifier that relies on the pointwise mutual information (PMI) between the senses of the target and co-occurrin</context>
<context position="4480" citStr="Mohammad and Hirst (2006" startWordPosition="703" endWordPosition="706">(CL-DPCs)— the strengths of association between the concepts of one language and words of another. For this task, we mapped the list of English translations to appropriate thesaurus categories and used an implementation of a CL-DPC–based unsupervised naive Bayes classifier to identify the intended senses (and thereby the English translations) of target Chinese words. 2 Distributional profiles of concepts In order to determine the strength of association between a sense of the target word and its co-occurring words, we need to determine their individual and joint occurrence counts in a corpus. Mohammad and Hirst (2006a) and Mohammad et al. (2007) proposed ways to determine these counts in a monolingual and cross-lingual framework without the use of senseannotated data. We summarize the ideas in this section; the original papers give more details. 2.1 Word–category co-occurrence matrix We create a word–category co-occurrence matrix (WCCM) having English word types wen as one dimension and English thesaurus categories cen as another. We used the Macquarie Thesaurus (Bernard, 1986) both as a very coarse-grained sense inventory and a source of words that together represent each category (concept). The WCCM is </context>
<context position="7088" citStr="Mohammad and Hirst (2006" startWordPosition="1175" endWordPosition="1178">at occur close to a target word tend to be good indicators of its intended sense. Therefore, we make a second pass of the corpus, using the base WCCM to roughly disambiguate the words in it. For each word, the strength of association of each of the words in its context (±5 words) with each of its senses is summed. The sense that has the highest cumulative association is chosen as the intended sense. A new bootstrapped WCCM is created such that each cell mij, corresponding to word wen iand concept cen j , is populated with the number of times wen i co-occurs with any word used in sense cen j . Mohammad and Hirst (2006a) used the DPCs created from the bootstrapped WCCM to attain near-upper-bound results in the task of determining word sense dominance. Unlike the McCarthy et al. (2004) dominance system, this approach can be applied to much smaller target texts (a few hundred sentences) without the need for a large similarly-sense-distributed text1. Mohammad and Hirst (2006b) used the DPC-based monolingual distributional measures of concept-distance to rank word pairs by their semantic similarity and to correct real-word spelling errors, attaining markedly better results than monolingual distributional measur</context>
</contexts>
<marker>Mohammad, Hirst, 2006</marker>
<rawString>Saif Mohammad and Graeme Hirst. 2006b. Distributional measures of concept-distance: A task-oriented evaluation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2006), Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Iryna Gurevych</author>
<author>Graeme Hirst</author>
<author>Torsten Zesch</author>
</authors>
<title>Cross-lingual distributional profiles of concepts for measuring semantic distance.</title>
<date>2007</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL-2007),</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="3778" citStr="Mohammad et al. (2007)" startWordPosition="594" endWordPosition="597">sible substitutes for a given target word is usually contingent on its intended sense. Therefore, word sense disambiguation is expected to be useful in lexical substitution. We used the PMI-based classier to determine the intended sense. 326 Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 326–333, Prague, June 2007. c�2007 Association for Computational Linguistics The objective of the Multilingual Chinese– English Lexical Sample Task (Jin et al., 2007) is to select from a given list a suitable English translation of a Chinese target word in context. Mohammad et al. (2007) proposed a way to create cross-lingual distributional profiles of a concepts (CL-DPCs)— the strengths of association between the concepts of one language and words of another. For this task, we mapped the list of English translations to appropriate thesaurus categories and used an implementation of a CL-DPC–based unsupervised naive Bayes classifier to identify the intended senses (and thereby the English translations) of target Chinese words. 2 Distributional profiles of concepts In order to determine the strength of association between a sense of the target word and its co-occurring words, w</context>
<context position="9374" citStr="Mohammad et al. (2007)" startWordPosition="1527" endWordPosition="1530">with Chinese word types wch as one dimension and English thesaurus concepts cen as another. The matrix is populated with co-occurrence counts from a large Chinese corpus; we used a collection of LDC-distributed corpora3—Chinese Treebank English Parallel Corpus, FBIS data, Xinhua ChineseEnglish Parallel News Text Version 1.0 beta 2, Chinese English News Magazine Parallel Text, Chinese 2Some of the cross-lingual candidate senses of wch might not really be senses of wch (e.g., ‘celebrity’, ‘practical lesson’, and ‘state of the atmosphere’ in Figure 1). However, as substantiated by experiments by Mohammad et al. (2007), our algorithm is able to handle the added ambiguity. 3http://www.ldc.upenn.edu Figure 2: Chinese words having ‘celestial body’ as one of their cross-lingual candidate senses. News Translation Text Part 1, and Hong Kong Parallel Text. A particular cell mij, corresponding to word wch i and concept cenj , is populated with the number of times the Chinese word wch i co-occurs with any Chinese word having cjen as one of its cross-lingual candidate senses. For example, the cell for (‘space’) and ‘celestial body’ will have the sum of the number of times co-occurs with ,, , ,, and so on (see Figure </context>
<context position="11835" citStr="Mohammad et al. (2007)" startWordPosition="1960" endWordPosition="1963"> mi2 ... mij ... wch 2 ... wch i ... , will co-occur with a number of words such as , , and that each have the sense of celestial body in common (see Figure 2), whereas all their other senses are likely different and distributed across the set of concepts. Therefore, the cooccurrence count of and ‘celestial body’ will be relatively higher than that of 328 nese word used in cross-lingual sense cenj . A statistic such as PMI is then applied to these counts to determine the strengths of association between a target concept and co-occurring words, giving the distributional profile of the concept. Mohammad et al. (2007) combined German text with an English thesaurus using a German–English bilingual lexicon to create German–English DPCs. These DPCs were used to determine semantic distance between German words, showing that state-ofthe-art accuracies for one language can be achieved using a knowledge source (thesaurus) from another. Given that a published thesaurus has about 1000 categories and the size of the vocabulary N is at least 100,000, the CL-WCCM and the WCCM are much smaller matrices (about 1000×N) than the traditional word–word co-occurrence matrix (N × N). Therefore the WCCMs are relatively inexpen</context>
</contexts>
<marker>Mohammad, Gurevych, Hirst, Zesch, 2007</marker>
<rawString>Saif Mohammad, Iryna Gurevych, Graeme Hirst, and Torsten Zesch. 2007. Cross-lingual distributional profiles of concepts for measuring semantic distance. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL-2007), Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Martha Palmer</author>
<author>Edward Loper</author>
</authors>
<title>SemEval-2007 task 17: English lexical sample, English SRL and English all-words tasks.</title>
<date>2007</date>
<booktitle>In Proceedings of the Fourth International Workshop on the Evaluation of Systems for the Semantic Analysis of Text (SemEval-2007),</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="2629" citStr="Pradhan et al., 2007" startWordPosition="409" endWordPosition="412">us were used as coarse senses or concepts (Yarowsky, 1992). We now show how distributional profiles of concepts can be used to create an unsupervised naive Bayes word-sense classifier. We also implemented a simple classifier that relies on the pointwise mutual information (PMI) between the senses of the target and co-occurring words. These DPC-based classifiers participated in three SemEval 2007 tasks: the English Lexical Sample Task (task #17), the English Lexical Substitution Task (task #10), and the Multilingual ChineseEnglish Lexical Sample Task (task #5). The English Lexical Sample Task (Pradhan et al., 2007) is a traditional word sense disambiguation task wherein the intended (WordNet) sense of a target word is to be determined from its context. We manually mapped the WordNet senses to the categories in a thesaurus and the DPC-based naive Bayes classifier was used to identify the intended sense (category) of the target words. The object of the Lexical Substitution Task (McCarthy and Navigli, 2007) is to replace a target word in a sentence with a suitable substitute that preserves the meaning of the utterance. The list of possible substitutes for a given target word is usually contingent on its in</context>
<context position="14555" citStr="Pradhan et al., 2007" startWordPosition="2411" endWordPosition="2414">e Macquarie Thesaurus) and W is the set of words that co-occur with the target (we used a window of ±5 words). Traditionally, prior probabilities of the senses (P(cj)) and the conditional probabilities in the likelihood (∏wi∈W P(wi|cj)) are determined by simple counts in sense-annotated data. We approximate these probabilities using counts from the word–category co-occurrence matrix (monolingual or cross-lingual), thereby obviating the need for manually-annotated data. P(cj) = ∑ i mij (2) ∑ i, j mij 4 Data 4.1 English Lexical Sample Task The English Lexical Sample Task training and test data (Pradhan et al., 2007) have 22281 and 4851 instances respectively for 100 target words (50 nouns and 50 verbs). WordNet 2.1 is used as the sense inventory for most of the target words, but certain words have one or more senses from OntoNotes (Hovy et al., 2006). Many of the finegrained senses are grouped into coarser senses. Our approach relies on representing a sense with a number of near-synonymous words, for which a thesaurus is a natural source. Even though the approach can be ported to WordNet4, there was no easy P(wi|cj) = mij (3) 4The synonyms within a synset, along with its one-hop ∑ imij neighbors and all </context>
<context position="19889" citStr="Pradhan et al., 2007" startWordPosition="3297" endWordPosition="3300"> dominant sense of the target words. We do not rely on the ranking of senses in WordNet as that would be an implicit use of the sense-tagged SemCor corpus. Therefore, the most-frequent-sense baseline does not apply. Table 1 also shows results obtained using just the prior probability and likelihood components of the naive Bayes formula. Note that the combined accuracy is higher than individual components for nouns but not for verbs. 5.1.2 Discussion The naive Bayes classifier’s accuracy is only about one percentage point lower than that of the best unsupervised system taking part in the task (Pradhan et al., 2007). One reason that it does better than the PMI-based one is that it takes into account prior probabilities of the categories. However, using just the likelihood also outperforms the PMI classifier. This may be because of known problems of using PMI with low frequencies (Manning and Sch¨utze, 1999). In case of verbs, lower combined accuracies compared to when using just prior probabilities suggests that the bag-of-words type features are not very useful. It is expected that more syntactically oriented features will give better results. Using window sizes (±1,±2, and ±10) on the training data res</context>
<context position="23264" citStr="Pradhan et al. (2007)" startWordPosition="3856" endWordPosition="3859">so on how good the top ten candidate substitutes are (OOT). Table 2 presents the results.7 The system attempted all instances. The table also lists performances of the system on instances where the target is not part of a multiword expression (NMWT), on instances where the substitute is not a multiword expression (NMWS), on instances randomly extracted from the corpus (RAND), and on instances manually selected (MAN). 6Due to time constraints, we were able to upload results only with the PMI-based classifier by the task deadline. 7The formulae for accuracy and mode accuracy are as described by Pradhan et al. (2007). 331 BASELINE TRAINING DATA PRIOR TEST DATA NA¨IVE BAYES PMI-BASED NA¨IVE BAYES LIKELIHOOD WORDS micro macro micro macro micro macro micro macro micro macro micro macro all 33.1 38.3 33.9 40.0 38.5 44.7 35.4 41.7 38.8 44.6 37.5 43.1 nouns only 41.9 43.5 43.6 45.0 49.4 50.5 45.3 47.1 48.1 50.8 50.0 51.6 verbs only 28.0 34.1 28.0 35.6 31.9 39.6 29.1 36.8 32.9 39.0 29.6 35.5 Table 3: Multilingual Chinese–English Lexical Sample Task: Results obtained using the PMI-based classifier on the training data and the naive Bayes classifier on both training and test data 5.2.2 Discussion Competitive perfo</context>
</contexts>
<marker>Pradhan, Palmer, Loper, 2007</marker>
<rawString>Sameer Pradhan, Martha Palmer, and Edward Loper. 2007. SemEval-2007 task 17: English lexical sample, English SRL and English all-words tasks. In Proceedings of the Fourth International Workshop on the Evaluation of Systems for the Semantic Analysis of Text (SemEval-2007), Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Wordnet and class-based probabilities.</title>
<date>1998</date>
<booktitle>WordNet: An Electronic Lexical Database,</booktitle>
<pages>239--263</pages>
<editor>In Christiane Fellbaum, editor,</editor>
<publisher>The MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="6062" citStr="Resnik (1998)" startWordPosition="983" endWordPosition="984">cen2 ... cenj ... m11 m12 ... m1j ... m21 m22 ... m2j ... ... .. .. . . mi1 mi2 ... mij ... ... ... ... ... ... A particular cell mij, corresponding to word wen i and concept cenj , is populated with the number of times wen i co-occurs with any word that has cjen as one of its senses (i.e., wen i co-occurs with any word listed under concept cjen in the thesaurus). This matrix, created after a first pass of the corpus, is the base word–category co-occurrence matrix (base WCCM) and it captures strong associations between a sense and co-occurring words (see discussion of the general principle in Resnik (1998)). From the base WCCM we can determine the number of times a word w and concept c co-occur, the number of times w co-occurs with any concept, and the number of times c co-occurs with any word. A statistic such as PMI can then give the strength of association between w and c. This is similar to how Yarowsky (1992) identifies words that are indicative of a particular sense of the target word. Words that occur close to a target word tend to be good indicators of its intended sense. Therefore, we make a second pass of the corpus, using the base WCCM to roughly disambiguate the words in it. For eac</context>
</contexts>
<marker>Resnik, 1998</marker>
<rawString>Philip Resnik. 1998. Wordnet and class-based probabilities. In Christiane Fellbaum, editor, WordNet: An Electronic Lexical Database, pages 239–263. The MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Word-sense disambiguation using statistical models of Roget’s categories trained on large corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th International Conference on Computational Linguistics (COLING92),</booktitle>
<pages>454--460</pages>
<location>Nantes, France.</location>
<contexts>
<context position="2066" citStr="Yarowsky, 1992" startWordPosition="322" endWordPosition="323">target as features. These systems rely on senseannotated data to identify words that are indicative of the use of the target in each of its senses. However, only limited amounts of senseannotated data exist and it is expensive to create. In our previous work (Mohammad and Hirst, 2006a), we proposed an unsupervised approach to determine the strength of association between a sense or concept and its co-occurring words—the distributional profile of a concept (DPC)—relying simply on raw text and a published thesaurus. The categories in a published thesaurus were used as coarse senses or concepts (Yarowsky, 1992). We now show how distributional profiles of concepts can be used to create an unsupervised naive Bayes word-sense classifier. We also implemented a simple classifier that relies on the pointwise mutual information (PMI) between the senses of the target and co-occurring words. These DPC-based classifiers participated in three SemEval 2007 tasks: the English Lexical Sample Task (task #17), the English Lexical Substitution Task (task #10), and the Multilingual ChineseEnglish Lexical Sample Task (task #5). The English Lexical Sample Task (Pradhan et al., 2007) is a traditional word sense disambig</context>
<context position="6376" citStr="Yarowsky (1992)" startWordPosition="1044" endWordPosition="1045"> any word listed under concept cjen in the thesaurus). This matrix, created after a first pass of the corpus, is the base word–category co-occurrence matrix (base WCCM) and it captures strong associations between a sense and co-occurring words (see discussion of the general principle in Resnik (1998)). From the base WCCM we can determine the number of times a word w and concept c co-occur, the number of times w co-occurs with any concept, and the number of times c co-occurs with any word. A statistic such as PMI can then give the strength of association between w and c. This is similar to how Yarowsky (1992) identifies words that are indicative of a particular sense of the target word. Words that occur close to a target word tend to be good indicators of its intended sense. Therefore, we make a second pass of the corpus, using the base WCCM to roughly disambiguate the words in it. For each word, the strength of association of each of the words in its context (±5 words) with each of its senses is summed. The sense that has the highest cumulative association is chosen as the intended sense. A new bootstrapped WCCM is created such that each cell mij, corresponding to word wen iand concept cen j , is</context>
</contexts>
<marker>Yarowsky, 1992</marker>
<rawString>David Yarowsky. 1992. Word-sense disambiguation using statistical models of Roget’s categories trained on large corpora. In Proceedings of the 14th International Conference on Computational Linguistics (COLING92), pages 454–460, Nantes, France.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>