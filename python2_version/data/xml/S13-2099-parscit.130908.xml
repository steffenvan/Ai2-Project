<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000131">
<note confidence="0.558977">
Celi: EDITS and Generic Text Pair Classification
Milen Kouylekov
Celi S.R.L.
</note>
<address confidence="0.730631">
via San Quintino 31
Torino,10121, Italy
</address>
<email confidence="0.995846">
kouylekov@celi.it
</email>
<note confidence="0.5748335">
Luca Dini
Celi S.R.L.
</note>
<address confidence="0.81341">
via San Quintino 31
Torino,10121, Italy
</address>
<email confidence="0.994778">
dini@celi.it
</email>
<note confidence="0.7072375">
Alessio Bosca
Celi S.R.L.
</note>
<address confidence="0.6874505">
via San Quintino 31
Torino,10121, Italy
</address>
<email confidence="0.993096">
alessio.bosca@celi.it
</email>
<note confidence="0.4716425">
Marco Trevisan
Celi S.R.L.
</note>
<address confidence="0.8263415">
via San Quintino 31
Torino, Italy
</address>
<email confidence="0.998033">
trevisan@celi.it
</email>
<sectionHeader confidence="0.995615" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.984034333333333">
This paper presents CELI’s participation in the
SemEval The Joint Student Response Anal-
ysis and 8th Recognizing Textual Entailment
Challenge (Task7) and Cross-lingual Textual
Entailment for Content Synchronization task
(Task 8).
</bodyText>
<sectionHeader confidence="0.998736" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.992358263157895">
Recognizing an existing relation between two text
fragments received a significant interest as NLP task
in the recent years. A lot of the approaches were
focused in the filed of Textual Entailment(TE). TE
has been proposed as as a comprehensive frame-
work for applied semantics (Dagan and Glickman,
2004), where the need for an explicit mapping be-
tween linguistic objects can be, at least partially,
bypassed through the definition of semantic infer-
ences at the textual level. In the TE framework, a
text (T) is said to entail the hypothesis (H) if the
meaning of H can be derived from the meaning of
T. Initially defined as binary relation between texts
(YES/NO there is an entailment or there is not) the
TE evolved in the third RTE3 (Giampiccolo et al.,
2007) challenge into a set of three relations between
texts: ENTAILMENT, CONTRADICTION and
UNKNOWN. These relations are interpreted as fol-
lows:
</bodyText>
<listItem confidence="0.99786175">
• ENTAILMENT - The T entails the H.
• CONTRADICTION - The H contradicts the T
• UNKNOWN - There is no semantic connection
between T and H.
</listItem>
<bodyText confidence="0.999631076923077">
With more and more applications available for
recognizing textual entailment the researches fo-
cused their efforts in finding practical applications
for the developed systems. Thus the Cross-Lingual
Textual Entailment task (CLTE) was created using
textual entailment (TE) to define cross-lingual con-
tent synchronization scenario proposed in (Mehdad
et. al., 2011), (Negri et. al., 2011) (Negri et. al.,
2012). The task is defined by the organizers as fol-
lows: Given a pair of topically related text fragments
(T1 and T2) in different languages, the CLTE task
consists of automatically annotating it with one of
the following entailment judgments:
</bodyText>
<listItem confidence="0.999434625">
• Bidirectional: the two fragments entail each
other (semantic equivalence)
• Forward: unidirectional entailment from T1 to
T2
• Backward: unidirectional entailment from T2
to T1
• No Entailment: there is no entailment between
T1 and T2
</listItem>
<bodyText confidence="0.953811625">
The textual entailment competition also evolved.
In this year SEMEVAL The Joint Student Response
Analysis and 8th Recognizing Textual Entailment
Challenge - JRSA-RTE8 (Task7) the textual entail-
ment was defined in three subtasks:
5-way task , where the system is required to clas-
sify the student answer according to one of the fol-
lowing judgments:
</bodyText>
<listItem confidence="0.997925">
• Correct, if the student answer is a complete and
correct paraphrase of the reference answer;
</listItem>
<page confidence="0.927014">
592
</page>
<bodyText confidence="0.8093555">
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 592–597, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
</bodyText>
<listItem confidence="0.970982357142857">
• Partially correct incomplete, if the student an-
swer is a partially correct answer containing
some but not all information from the reference
answer;
• Contradictory, if the student answer explicitly
contradicts the reference answer;
• Irrelevant, if the student answer is ”irrelevant”,
talking about domain content but not providing
the necessary information;
• Non domain, if the student answer expresses a
request for help, frustration or lack of domain
knowledge - e.g., ”I don’t know”, ”as the book
says”, ”you are stupid”.
3-way task , where the system is required to clas-
sify the student answer according to one of the fol-
lowing judgments:
• correct
• contradictory
• incorrect, conflating the categories of par-
tially correct incomplete, irrelevant or
non domain in the 5-way classification
2-way task , where the system is required to clas-
sify the student answer according to one of the fol-
lowing judgments:
• correct
• incorrect, conflating the categories of contra-
dictory and incorrect in the 3-way classifica-
tion.
</listItem>
<bodyText confidence="0.999937741935484">
Following the overall trend, we have decided to
convert our system for recognizing textual entail-
ment EDITS from a simple YES/NO recognition
system into a generic system capable of recognizing
multiple semantic relationships between two texts.
EDITS (Kouylekov and Negri, 2010) and
(Kouylekov et. al., 2011) is an open source pack-
age for recognizing textual entailment, which offers
a modular, flexible, and adaptable working environ-
ment to experiment with the RTE task over different
datasets. The package allows to: i) create an en-
tailment engine by defining its basic components ii)
train such entailment engine over an annotated RTE
corpus to learn a model; and iii) use the entailment
engine and the model to assign an entailment judg-
ments and a confidence score to each pair of an un-
annotated test corpus.
We define the recognition of semantic relations
between two texts as a classification task. In this
task the system takes as an input two texts and clas-
sifies them in one of a set of predefined relations.
We have modified EDITS in order to handle the so
defined task.
Having this in mind we have participated in
JRSA-RTE8 (task 7) and CLTE2 (task 8) with the
same approach. We have merged EDITS with some
features from the TLike system described in our last
participation in CLTE (Kouylekov et. al., 2011). For
each of the tasks we have created a specialized com-
ponents that are integrated in EDITS as one of the
system’s modules.
</bodyText>
<sectionHeader confidence="0.8957825" genericHeader="introduction">
2 EDITS and Generic Text Pair
Classification
</sectionHeader>
<bodyText confidence="0.999883555555556">
As in the previous versions, the core of EDITS im-
plements a distance-based framework. Within this
framework the system implements and harmonizes
different approaches to distance computation be-
tween texts, providing both edit distance algorithms,
and similarity algorithms. Each algorithm returns
a normalized distance score (a number between 0
and 1). Each algorithm algorithm depends on two
generic modules defined by the system’s user:
</bodyText>
<listItem confidence="0.818778375">
• Matcher - a module that is used to align text
fragments. This module uses semantic tech-
niques and entailment rules to find equivalent
textfragments.
• Weight Calculator - a module that is used to
give weight to text fragments. The weights are
used to determine the importance of a text por-
tion to the overall meaning of the text.
</listItem>
<bodyText confidence="0.999971714285714">
In the previous versions of the system at the train-
ing stage, distance scores calculated over annotated
T-H pairs are used to estimate a threshold that best
separates positive (YES) from negative (NO) exam-
ples. The calculated threshold was used at a test
stage to assign an entailment judgment and a con-
fidence score to each test pair. In the new version
</bodyText>
<page confidence="0.993708">
593
</page>
<bodyText confidence="0.988387307692308">
of the system we used a machine learning classifier
to classify the T-H pairs in the appropriate category.
The overall architecture of the system is shown in
Figure 1.
The new architecture is divided in two sets of
modules: Machine Learning and Edit Distance. In
the Edit Distance set various distance algorithms are
used to calculate the distance between the two texts.
Each of these algorithms have a custom matcher and
weight calculator. The distances calculated by each
of these algorithms are used as features for the clas-
sifiers of the Machine Leaning modules. The ma-
chine learning modules are structured in two levels:
</bodyText>
<listItem confidence="0.955396111111111">
• Binary Classifiers - for each semantic relation
we create a binary classifier that distinguishes
between the members of the relation and the
members of the other relations. For example:
For 3way task (Task 7) the system created 3 bi-
nary classifiers one for each relation.
• Classifier - a module that makes final decision
for the text pair taking the output (decision and
confidence) of the binary classifiers as an input.
</listItem>
<bodyText confidence="0.999837944444444">
We have experimented with other configurations
of the machine leaning modules and selected this
one as the best performing on the available datasets
of the previous RTE competitions. In the version
of EDITS avalble online other configurations of the
machine leaning modules will be available using the
flexibility of the system configuration.
We have used the algorithms implemented in
WEKA (Hall et al., 2009) for the classification mod-
ules. The binary modules use SMO algorithm. The
top classifier uses NaiveBayes.
The input to the system is a corpus of text pairs
each classified with one semantic relation. We have
used the format of the previous RTE competitions
in order to be compliant. The goal of the system is
to create classifier that is capable of recognizing the
correct relation for an un-annotated pair of texts.
The new version of EDITS package allows to:
</bodyText>
<listItem confidence="0.987207666666667">
• Create an Classifier by defining its basic com-
ponents (i.e. algorithms, matchers, and weight
calculators);
• Train such Classifier over an annotated corpus
(containing T-H pairs annotated in terms of en-
tailment) to learn a Model;
• Use the Classifier and the Model to assign an
entailment judgment and a confidence score to
each pair of an un-annotated test corpus.
</listItem>
<sectionHeader confidence="0.995532" genericHeader="method">
3 Resources
</sectionHeader>
<bodyText confidence="0.99945425">
Like our participation in the 2012 SemEval Cross-
lingual Textual Entailment for Content Synchroniza-
tion task (Kouylekov et. al., 2011), our approach is
based on four main resources:
</bodyText>
<listItem confidence="0.996481666666667">
• A system for Natural Language Processing able
to perform for each relevant language basic
tasks such as part of speech disambiguation,
lemmatization and named entity recognition.
• A set of word based bilingual translation mod-
ules.(Employed only for Task 8)
• A semantic component able to associate a se-
mantic vectorial representation to words.
• We use Wikipedia as multilingual corpus.
</listItem>
<bodyText confidence="0.997512125">
NLP modules are described in (Bosca and Dini,
2008), and will be no further detailed here.
Word-based translation modules are composed by
a bilingual lexicon look-up component coupled with
a vector based translation filter, such as the one de-
scribed in (Curtoni and Dini, 2008). In the context of
the present experiments, such a filters has been de-
activated, which means that for any input word the
component will return the set of all possible transla-
tions. For unavailable pairs, we make use of trian-
gular translation (Kraaij, 2003).
As for the semantic component we experimented
with a corpus-based distributional approach capable
of detecting the interrelation between different terms
in a corpus; the strategy we adopted is similar to La-
tent Semantic Analysis (Deerwester et. al., 1990)
although it uses a less expensive computational solu-
tion based on the Random Projection algorithm (Lin
et. al., 2003) and (Bingham et. al., 2001). Different
works debate on similar issues: (Turney, 2001) uses
LSA in order to solve synonymy detection questions
from the well-known TOEFL test while the method
presented by (Inkpen, 2001) or by (Baroni and Bisi,
2001) proposes the use of the Web as a corpus to
</bodyText>
<page confidence="0.998393">
594
</page>
<figureCaption confidence="0.999956">
Figure 1: EDITS Architecture
</figureCaption>
<bodyText confidence="0.9996148">
compute mutual information scores between candi-
date terms.
We use Wikipedia as a corpus for calculating
word statistics in different languages. We have in-
dexed using Lucene1 the English, Italian, French,
German, Spanish distributions of the resource.
The semantic component and the translation2
modules are used as core components in the matcher
module. IDF calculated on Wikipedia is used as
weight for the words by the weight calculator model.
</bodyText>
<sectionHeader confidence="0.937205" genericHeader="method">
4 JRSA-RTE8
</sectionHeader>
<bodyText confidence="0.999946">
In the JRSA-RTE8 we consider the reference an-
swers as T (text) and the student answer as H (hy-
pothesis). As the reference answers are often more
than one, we considered as input to the machine
learning algorithms the distance between the student
answer and the closest reference answer. We define
the closest reference answer as the reference answer
with minimum distance according to the distance al-
gorithm.
</bodyText>
<footnote confidence="0.999834">
1http://lucene.apache.org
2Translation module is used only for Task 8.
</footnote>
<subsectionHeader confidence="0.981582">
4.1 Systems
</subsectionHeader>
<bodyText confidence="0.9972016875">
We have submitted two runs in the SemEval JRSA-
RTE8 challenge (Task 7). The systems were exe-
cuted on each of the sub tasks of the main task.
System 1 The distance algorithm used in the first
system is Word Overlap. The algorithm tries to find
the words of a source text between the words of the
target text. We have created two features for each
binary classifier: 1) Feature 1 - word overlap of H
into T (words of H are matched by the words in T;
2) Feature 2 - word overlap T into H (Words of T are
matched by the words in H).
System 2 In the second system the we have used
only Feature 1.
We have created separate models for the Beatle
dataset and the sciEntsBank dataset. The results ob-
tained are shown in Table 1.
</bodyText>
<subsectionHeader confidence="0.997614">
4.2 Analysis
</subsectionHeader>
<bodyText confidence="0.9999194">
The results obtained are in line with our previous
participations in the RTE challenges (Kouylekov et.
al., 2011). Of course as we described before in our
papers (Kouylekov et. al., 2011) the potential of the
edit distance algorithm is limited. Still it provides a
</bodyText>
<page confidence="0.995766">
595
</page>
<table confidence="0.999921">
Task Beatle Q Beatle A sciEntsBank Q sciEntsBank A sciEntsBank D
2way
run 1 0.6400 0.6570 0.5930 0.6280 0.6160
run 2 0.4620 0.4480 0.5560 0.5930 0.5710
3way
run 1 0.5510 0.4950 0.5240 0.5780 0.5490
run 2 0.4150 0.4400 0.4390 0.5030 0.4770
5way
run 1 0.4830 0.4470 0.4130 0.4340 0.4170
run 2 0.3850 0.4320 0.2330 0.2370 0.2540
</table>
<tableCaption confidence="0.999962">
Table 1: Task 7 Results obtained. (Accuracy)
</tableCaption>
<bodyText confidence="0.9998855">
good performance and provides a solid potential for
some close domain tasks as described in (Negri and
Kouylekov, 2009). We were quite content with the
new machine learning based core. The selected con-
figuration performed in an acceptable manner. The
results obtained were in line with the cross accuracy
obtained by our system on the training set which
shows that it is not susceptible to over-training.
</bodyText>
<sectionHeader confidence="0.996811" genericHeader="method">
5 CLTE
</sectionHeader>
<subsectionHeader confidence="0.976628">
5.1 Systems
</subsectionHeader>
<bodyText confidence="0.998608875">
We have submitted two runs in the CLTE task (Task
8).
System 1 The distance algorithm used in the first
system is Word Overlap as we did for task 7. We
have created two features for each binary classifier:
1) Feature 1 - word overlap of H into T (words of H
are matched by the words in T; 2) Feature 2 - word
overlap T into H (Words of T are matched by the
words in H).
System 2 In the second system we have made a
slight modification of the matcher that handled num-
bers.
The matcher module for this task used the transla-
tion modules defined in Section 3. We have created
a model for each language pair.
The results obtained are shown in Table 2.
</bodyText>
<subsectionHeader confidence="0.999339">
5.2 Analysis
</subsectionHeader>
<bodyText confidence="0.999979727272727">
The results obtained are quite disappointing. Our
system obtained on the test set of the last CLTE com-
petition (CLTE1) quite satisfactory results (clte1-
test). All the results obtained for this competition
are near or above the medium of the best systems.
Our algorithm did not show signs of over-training
(the accuracy of the system on the test and on the
training of CLTE1 were almost equal). Having this
in mind we expected to obtain scores at least in the
margins of 0.45 to 0.5. This does not happen ac-
cording us due to the fact that this year dataset has
characteristics quite different than the last year. To
test this hypothesis we have trained our system on
half of the dataset (clte2-half-training) ,given for test
this year, and test it on the rest (clte-half-test). The
results obtained demonstrate that the dataset given
is more difficult for our system than the last years
one. The results also prove that our system is prob-
ably too conservative when learning from examples.
If the test set is similar to the training it performs
in consistent manner on both, otherwise it demon-
strates severe over-training problems.
</bodyText>
<sectionHeader confidence="0.999629" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.998454111111111">
In this paper we have presented a generic system for
text pair classification. This system was evaluated
on task 7 and task 8 of Semeval 2013 and obtained
satisfactory results. The new machine learning mod-
ule of the system needs improvement and we plan to
focus our future efforts in it.
We plan to release the newly developed system as
version 4 of the open source package EDITS avail-
able at http://edits.sf.net.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.994571">
This work has been partially supported by the
ECfunded project Galateas (CIP-ICT PSP-2009-3-
250430).
</bodyText>
<page confidence="0.994839">
596
</page>
<table confidence="0.997161">
Run Spanish Italian French German
run1 0.34 0.324 0.346 0.349
run2 0.342 0.324 0.34 0.349
clte2-half-training 0.41 0.43 0.40 0.44
clte2-half-test 0.43 0.44 0.41 0.43
clte1-test 0.52 0.51 0.54 0.55
</table>
<tableCaption confidence="0.999407">
Table 2: Task 8. Results obtained. (Accuracy)
</tableCaption>
<sectionHeader confidence="0.994485" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999162670886076">
Baroni M., Bisi S. 2004. Using cooccurrence statistics
and the web to discover synonyms in technical lan-
guage In Proceedings of LREC 2004
Bentivogli L., Clark P., Dagan I., Dang H, Giampic-
colo D. 2011. The Seventh PASCAL Recognizing
Textual Entailment Challenge In Proceedings of TAC
2011
Bingham E., Mannila H. 2001. Random projection in
dimensionality reduction: Applications to image and
text data. In Knowledge Discovery and Data Mining,
ACM Press pages 245250
Bosca A., Dini L. 2008. Query expansion via library
classification system. In CLEF 2008. Springer Verlag,
LNCS
Curtoni P., Dini L. 2006. Celi participation at clef 2006
Cross language delegated search. In CLEF2006 Work-
ing notes.
Dagan I. and Glickman O. 2004. Probabilistic Textual
Entailment: Generic Applied Modeling of Language
Variability. Learning Methods for Text Understanding
and Mining Workshop.
Deerwester S., Dumais S.T., Furnas G.W., Landauer T.K.,
Harshman R. 1990. Indexing by latent semantic anal-
ysis. Journal of the American Society for Information
Science 41 391407
Giampiccolo; Bernardo Magnini; Ido Dagan; Bill Dolan.
2007. The Third PASCAL Recognizing Textual
Entailment Challenge. Proceedings of the ACL-
PASCAL Workshop on Textual Entailment and Para-
phrasing. June 2007, Prague, Czech Republic
Hall M., Frank E., Holmes G., Pfahringer B., Reute-
mann P., Witten I. 2009 The WEKA Data Mining
Software: An Update; SIGKDD Explorations, Vol-
ume 11, Issue 1.
Inkpen D. 2007. A statistical model for near-synonym
choice. ACM Trans. Speech Language Processing
4(1)
Kouylekov M., Negri M. An Open-Source Package for
Recognizing Textual Entailment. 48th Annual Meet-
ing of the Association for Computational Linguistics
(ACL 2010) ,Uppsala, Sweden. July 11-16, 2010
Kouylekov M., Bosca A., Dini L. 2011. EDITS 3.0 at
RTE-7. Proceedings of the Seventh Recognizing Tex-
tual Entailment Challenge (2011).
Kouylekov M., Bosca A., Dini L., Trevisan M. 2012.
CELI: An Experiment with Cross Language Textual
Entailment. In Proceedings of the 6th International
Workshop on Semantic Evaluation (SemEval 2012).
Kouylekov M., Mehdad Y. and Negri M. 2011 Is it Worth
Submitting this Run? Assess your RTE System with a
Good Sparring Partner Proceedings of the TextInfer
2011 Workshop on Textual Entailment
Kraaij W. 2003. Exploring transitive translation meth-
ods. In Vries, A.P.D., ed.: Proceedings of DIR 2003.
Lin J., Gunopulos D. 2003. Dimensionality reduction
by random projection and latent semantic indexing. In
proceedings of the Text Mining Workshop, at the 3rd
SIAM International Conference on Data Mining.
Mehdad Y.,Negri M., Federico M.. 2011. Using Paral-
lel Corpora for Cross-lingual Textual Entailment. In
Proceedings of ACL-HLT 2011.
Negri M., Bentivogli L., Mehdad Y., Giampiccolo D.,
Marchetti A. 2011. Divide and Conquer: Crowd-
sourcing the Creation of Cross-Lingual Textual Entail-
ment Corpora. In Proceedings of EMNLP 2011.
Negri M., Kouylekov M., 2009 Question Answer-
ing over Structured Data: an Entailment-Based Ap-
proach to Question Analysis. RANLP 2009 - Re-
cent Advances in Natural Language Processing, 2009
Borovets, Bulgaria
Negri M., Marchetti A., Mehdad Y., Bentivogli L., Gi-
ampiccolo D. Semeval-2012 Task 8: Cross-lingual
Textual Entailment for Content Synchronization. In
Proceedings of the 6th International Workshop on Se-
mantic Evaluation (SemEval 2012). 2012.
Turney P.D. 2001. Mining the web for synonyms: Pmi-
ir versus lsa on toefl. In EMCL 01: Proceedings of
the 12th European Conference on Machine Learning,
London, UK, Springer-Verlag pages 491502
</reference>
<page confidence="0.997611">
597
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.007952">
<title confidence="0.801513">Celi: EDITS and Generic Text Pair Classification Milen</title>
<author confidence="0.79185">Celi</author>
<affiliation confidence="0.894223">via San Quintino</affiliation>
<address confidence="0.830867">Torino,10121,</address>
<email confidence="0.998403">kouylekov@celi.it</email>
<author confidence="0.909276">Luca</author>
<affiliation confidence="0.577617">Celi S.R.L.</affiliation>
<address confidence="0.713656">via San Quintino 31 Torino,10121, Italy</address>
<email confidence="0.996955">dini@celi.it</email>
<author confidence="0.831623">Alessio</author>
<affiliation confidence="0.8100495">Celi via San Quintino</affiliation>
<address confidence="0.855166">Torino,10121,</address>
<email confidence="0.997048">alessio.bosca@celi.it</email>
<author confidence="0.731752">Marco Celi</author>
<affiliation confidence="0.944293">via San Quintino</affiliation>
<address confidence="0.830527">Torino,</address>
<email confidence="0.999317">trevisan@celi.it</email>
<abstract confidence="0.842443666666667">This paper presents CELI’s participation in the SemEval The Joint Student Response Anal-</abstract>
<note confidence="0.8325365">ysis and 8th Recognizing Textual Entailment Challenge (Task7) and Cross-lingual Textual Entailment for Content Synchronization task (Task 8).</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Baroni</author>
<author>S Bisi</author>
</authors>
<title>Using cooccurrence statistics and the web to discover synonyms in technical language</title>
<date>2004</date>
<booktitle>In Proceedings of LREC</booktitle>
<marker>Baroni, Bisi, 2004</marker>
<rawString>Baroni M., Bisi S. 2004. Using cooccurrence statistics and the web to discover synonyms in technical language In Proceedings of LREC 2004</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Bentivogli</author>
<author>P Clark</author>
<author>I Dagan</author>
<author>H Dang</author>
<author>D Giampiccolo</author>
</authors>
<title>The Seventh PASCAL Recognizing Textual Entailment Challenge In</title>
<date>2011</date>
<booktitle>Proceedings of TAC</booktitle>
<marker>Bentivogli, Clark, Dagan, Dang, Giampiccolo, 2011</marker>
<rawString>Bentivogli L., Clark P., Dagan I., Dang H, Giampiccolo D. 2011. The Seventh PASCAL Recognizing Textual Entailment Challenge In Proceedings of TAC 2011</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Bingham</author>
<author>H Mannila</author>
</authors>
<title>Random projection in dimensionality reduction: Applications to image and text data.</title>
<date>2001</date>
<booktitle>In Knowledge Discovery and Data Mining,</booktitle>
<pages>245250</pages>
<publisher>ACM Press</publisher>
<marker>Bingham, Mannila, 2001</marker>
<rawString>Bingham E., Mannila H. 2001. Random projection in dimensionality reduction: Applications to image and text data. In Knowledge Discovery and Data Mining, ACM Press pages 245250</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bosca</author>
<author>L Dini</author>
</authors>
<title>Query expansion via library classification system.</title>
<date>2008</date>
<booktitle>In CLEF</booktitle>
<publisher>Springer Verlag, LNCS</publisher>
<contexts>
<context position="9816" citStr="Bosca and Dini, 2008" startWordPosition="1583" endWordPosition="1586">ike our participation in the 2012 SemEval Crosslingual Textual Entailment for Content Synchronization task (Kouylekov et. al., 2011), our approach is based on four main resources: • A system for Natural Language Processing able to perform for each relevant language basic tasks such as part of speech disambiguation, lemmatization and named entity recognition. • A set of word based bilingual translation modules.(Employed only for Task 8) • A semantic component able to associate a semantic vectorial representation to words. • We use Wikipedia as multilingual corpus. NLP modules are described in (Bosca and Dini, 2008), and will be no further detailed here. Word-based translation modules are composed by a bilingual lexicon look-up component coupled with a vector based translation filter, such as the one described in (Curtoni and Dini, 2008). In the context of the present experiments, such a filters has been deactivated, which means that for any input word the component will return the set of all possible translations. For unavailable pairs, we make use of triangular translation (Kraaij, 2003). As for the semantic component we experimented with a corpus-based distributional approach capable of detecting the </context>
</contexts>
<marker>Bosca, Dini, 2008</marker>
<rawString>Bosca A., Dini L. 2008. Query expansion via library classification system. In CLEF 2008. Springer Verlag, LNCS</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Curtoni</author>
<author>L Dini</author>
</authors>
<title>Celi participation at clef 2006 Cross language delegated search.</title>
<date>2006</date>
<booktitle>In CLEF2006 Working notes.</booktitle>
<marker>Curtoni, Dini, 2006</marker>
<rawString>Curtoni P., Dini L. 2006. Celi participation at clef 2006 Cross language delegated search. In CLEF2006 Working notes.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dagan</author>
<author>O Glickman</author>
</authors>
<title>Probabilistic Textual Entailment: Generic Applied Modeling of Language Variability. Learning Methods for Text Understanding and Mining Workshop.</title>
<date>2004</date>
<contexts>
<context position="932" citStr="Dagan and Glickman, 2004" startWordPosition="130" endWordPosition="133">visan Celi S.R.L. via San Quintino 31 Torino, Italy trevisan@celi.it Abstract This paper presents CELI’s participation in the SemEval The Joint Student Response Analysis and 8th Recognizing Textual Entailment Challenge (Task7) and Cross-lingual Textual Entailment for Content Synchronization task (Task 8). 1 Introduction Recognizing an existing relation between two text fragments received a significant interest as NLP task in the recent years. A lot of the approaches were focused in the filed of Textual Entailment(TE). TE has been proposed as as a comprehensive framework for applied semantics (Dagan and Glickman, 2004), where the need for an explicit mapping between linguistic objects can be, at least partially, bypassed through the definition of semantic inferences at the textual level. In the TE framework, a text (T) is said to entail the hypothesis (H) if the meaning of H can be derived from the meaning of T. Initially defined as binary relation between texts (YES/NO there is an entailment or there is not) the TE evolved in the third RTE3 (Giampiccolo et al., 2007) challenge into a set of three relations between texts: ENTAILMENT, CONTRADICTION and UNKNOWN. These relations are interpreted as follows: • E</context>
</contexts>
<marker>Dagan, Glickman, 2004</marker>
<rawString>Dagan I. and Glickman O. 2004. Probabilistic Textual Entailment: Generic Applied Modeling of Language Variability. Learning Methods for Text Understanding and Mining Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Deerwester</author>
<author>S T Dumais</author>
<author>G W Furnas</author>
<author>T K Landauer</author>
<author>R Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of the American Society for Information Science</journal>
<volume>41</volume>
<pages>391407</pages>
<marker>Deerwester, Dumais, Furnas, Landauer, Harshman, 1990</marker>
<rawString>Deerwester S., Dumais S.T., Furnas G.W., Landauer T.K., Harshman R. 1990. Indexing by latent semantic analysis. Journal of the American Society for Information Science 41 391407</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernardo Magnini Giampiccolo</author>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
</authors>
<title>The Third PASCAL Recognizing Textual Entailment Challenge.</title>
<date>2007</date>
<booktitle>Proceedings of the ACLPASCAL Workshop on Textual Entailment and Paraphrasing.</booktitle>
<location>Prague, Czech Republic</location>
<contexts>
<context position="1390" citStr="Giampiccolo et al., 2007" startWordPosition="212" endWordPosition="215">e approaches were focused in the filed of Textual Entailment(TE). TE has been proposed as as a comprehensive framework for applied semantics (Dagan and Glickman, 2004), where the need for an explicit mapping between linguistic objects can be, at least partially, bypassed through the definition of semantic inferences at the textual level. In the TE framework, a text (T) is said to entail the hypothesis (H) if the meaning of H can be derived from the meaning of T. Initially defined as binary relation between texts (YES/NO there is an entailment or there is not) the TE evolved in the third RTE3 (Giampiccolo et al., 2007) challenge into a set of three relations between texts: ENTAILMENT, CONTRADICTION and UNKNOWN. These relations are interpreted as follows: • ENTAILMENT - The T entails the H. • CONTRADICTION - The H contradicts the T • UNKNOWN - There is no semantic connection between T and H. With more and more applications available for recognizing textual entailment the researches focused their efforts in finding practical applications for the developed systems. Thus the Cross-Lingual Textual Entailment task (CLTE) was created using textual entailment (TE) to define cross-lingual content synchronization sce</context>
</contexts>
<marker>Giampiccolo, Dagan, Dolan, 2007</marker>
<rawString>Giampiccolo; Bernardo Magnini; Ido Dagan; Bill Dolan. 2007. The Third PASCAL Recognizing Textual Entailment Challenge. Proceedings of the ACLPASCAL Workshop on Textual Entailment and Paraphrasing. June 2007, Prague, Czech Republic</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hall</author>
<author>E Frank</author>
<author>G Holmes</author>
<author>B Pfahringer</author>
<author>P Reutemann</author>
<author>I Witten</author>
</authors>
<title>The WEKA Data Mining Software: An Update;</title>
<date>2009</date>
<journal>SIGKDD Explorations,</journal>
<volume>11</volume>
<contexts>
<context position="8352" citStr="Hall et al., 2009" startWordPosition="1342" endWordPosition="1345">stem created 3 binary classifiers one for each relation. • Classifier - a module that makes final decision for the text pair taking the output (decision and confidence) of the binary classifiers as an input. We have experimented with other configurations of the machine leaning modules and selected this one as the best performing on the available datasets of the previous RTE competitions. In the version of EDITS avalble online other configurations of the machine leaning modules will be available using the flexibility of the system configuration. We have used the algorithms implemented in WEKA (Hall et al., 2009) for the classification modules. The binary modules use SMO algorithm. The top classifier uses NaiveBayes. The input to the system is a corpus of text pairs each classified with one semantic relation. We have used the format of the previous RTE competitions in order to be compliant. The goal of the system is to create classifier that is capable of recognizing the correct relation for an un-annotated pair of texts. The new version of EDITS package allows to: • Create an Classifier by defining its basic components (i.e. algorithms, matchers, and weight calculators); • Train such Classifier over </context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Hall M., Frank E., Holmes G., Pfahringer B., Reutemann P., Witten I. 2009 The WEKA Data Mining Software: An Update; SIGKDD Explorations, Volume 11, Issue 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Inkpen</author>
</authors>
<title>A statistical model for near-synonym choice.</title>
<date>2007</date>
<journal>ACM Trans. Speech Language Processing</journal>
<volume>4</volume>
<issue>1</issue>
<marker>Inkpen, 2007</marker>
<rawString>Inkpen D. 2007. A statistical model for near-synonym choice. ACM Trans. Speech Language Processing 4(1)</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kouylekov</author>
<author>M Negri</author>
</authors>
<title>An Open-Source Package for Recognizing Textual Entailment.</title>
<date>2010</date>
<booktitle>48th Annual Meeting of the Association for Computational Linguistics (ACL 2010)</booktitle>
<location>Uppsala, Sweden.</location>
<contexts>
<context position="4551" citStr="Kouylekov and Negri, 2010" startWordPosition="704" endWordPosition="707">ncorrect, conflating the categories of partially correct incomplete, irrelevant or non domain in the 5-way classification 2-way task , where the system is required to classify the student answer according to one of the following judgments: • correct • incorrect, conflating the categories of contradictory and incorrect in the 3-way classification. Following the overall trend, we have decided to convert our system for recognizing textual entailment EDITS from a simple YES/NO recognition system into a generic system capable of recognizing multiple semantic relationships between two texts. EDITS (Kouylekov and Negri, 2010) and (Kouylekov et. al., 2011) is an open source package for recognizing textual entailment, which offers a modular, flexible, and adaptable working environment to experiment with the RTE task over different datasets. The package allows to: i) create an entailment engine by defining its basic components ii) train such entailment engine over an annotated RTE corpus to learn a model; and iii) use the entailment engine and the model to assign an entailment judgments and a confidence score to each pair of an unannotated test corpus. We define the recognition of semantic relations between two texts</context>
</contexts>
<marker>Kouylekov, Negri, 2010</marker>
<rawString>Kouylekov M., Negri M. An Open-Source Package for Recognizing Textual Entailment. 48th Annual Meeting of the Association for Computational Linguistics (ACL 2010) ,Uppsala, Sweden. July 11-16, 2010</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kouylekov</author>
<author>A Bosca</author>
<author>L Dini</author>
</authors>
<date>2011</date>
<booktitle>EDITS 3.0 at RTE-7. Proceedings of the Seventh Recognizing Textual Entailment Challenge</booktitle>
<marker>Kouylekov, Bosca, Dini, 2011</marker>
<rawString>Kouylekov M., Bosca A., Dini L. 2011. EDITS 3.0 at RTE-7. Proceedings of the Seventh Recognizing Textual Entailment Challenge (2011).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kouylekov</author>
<author>A Bosca</author>
<author>L Dini</author>
<author>M Trevisan</author>
</authors>
<title>CELI: An Experiment with Cross Language Textual Entailment.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<marker>Kouylekov, Bosca, Dini, Trevisan, 2012</marker>
<rawString>Kouylekov M., Bosca A., Dini L., Trevisan M. 2012. CELI: An Experiment with Cross Language Textual Entailment. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kouylekov</author>
<author>Y Mehdad</author>
<author>M Negri</author>
</authors>
<title>Is it Worth Submitting this Run? Assess your RTE System with a Good Sparring Partner</title>
<date>2011</date>
<booktitle>Proceedings of the TextInfer 2011 Workshop on Textual Entailment</booktitle>
<marker>Kouylekov, Mehdad, Negri, 2011</marker>
<rawString>Kouylekov M., Mehdad Y. and Negri M. 2011 Is it Worth Submitting this Run? Assess your RTE System with a Good Sparring Partner Proceedings of the TextInfer 2011 Workshop on Textual Entailment</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Kraaij</author>
</authors>
<title>Exploring transitive translation methods.</title>
<date>2003</date>
<booktitle>In Vries, A.P.D., ed.: Proceedings of DIR 2003.</booktitle>
<contexts>
<context position="10299" citStr="Kraaij, 2003" startWordPosition="1665" endWordPosition="1666"> vectorial representation to words. • We use Wikipedia as multilingual corpus. NLP modules are described in (Bosca and Dini, 2008), and will be no further detailed here. Word-based translation modules are composed by a bilingual lexicon look-up component coupled with a vector based translation filter, such as the one described in (Curtoni and Dini, 2008). In the context of the present experiments, such a filters has been deactivated, which means that for any input word the component will return the set of all possible translations. For unavailable pairs, we make use of triangular translation (Kraaij, 2003). As for the semantic component we experimented with a corpus-based distributional approach capable of detecting the interrelation between different terms in a corpus; the strategy we adopted is similar to Latent Semantic Analysis (Deerwester et. al., 1990) although it uses a less expensive computational solution based on the Random Projection algorithm (Lin et. al., 2003) and (Bingham et. al., 2001). Different works debate on similar issues: (Turney, 2001) uses LSA in order to solve synonymy detection questions from the well-known TOEFL test while the method presented by (Inkpen, 2001) or by </context>
</contexts>
<marker>Kraaij, 2003</marker>
<rawString>Kraaij W. 2003. Exploring transitive translation methods. In Vries, A.P.D., ed.: Proceedings of DIR 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lin</author>
<author>D Gunopulos</author>
</authors>
<title>Dimensionality reduction by random projection and latent semantic indexing.</title>
<date>2003</date>
<booktitle>In proceedings of the Text Mining Workshop, at the 3rd SIAM International Conference on Data Mining.</booktitle>
<marker>Lin, Gunopulos, 2003</marker>
<rawString>Lin J., Gunopulos D. 2003. Dimensionality reduction by random projection and latent semantic indexing. In proceedings of the Text Mining Workshop, at the 3rd SIAM International Conference on Data Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Mehdad</author>
<author>M Negri</author>
<author>M Federico</author>
</authors>
<title>Using Parallel Corpora for Cross-lingual Textual Entailment.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL-HLT</booktitle>
<marker>Mehdad, Negri, Federico, 2011</marker>
<rawString>Mehdad Y.,Negri M., Federico M.. 2011. Using Parallel Corpora for Cross-lingual Textual Entailment. In Proceedings of ACL-HLT 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Negri</author>
<author>L Bentivogli</author>
<author>Y Mehdad</author>
<author>D Giampiccolo</author>
<author>A Marchetti</author>
</authors>
<title>Divide and Conquer: Crowdsourcing the Creation of Cross-Lingual Textual Entailment Corpora.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<marker>Negri, Bentivogli, Mehdad, Giampiccolo, Marchetti, 2011</marker>
<rawString>Negri M., Bentivogli L., Mehdad Y., Giampiccolo D., Marchetti A. 2011. Divide and Conquer: Crowdsourcing the Creation of Cross-Lingual Textual Entailment Corpora. In Proceedings of EMNLP 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Negri</author>
<author>M Kouylekov</author>
</authors>
<title>Question Answering over Structured Data: an Entailment-Based Approach to Question Analysis.</title>
<date>2009</date>
<booktitle>RANLP 2009 - Recent Advances in Natural Language Processing,</booktitle>
<location>Borovets, Bulgaria</location>
<contexts>
<context position="13439" citStr="Negri and Kouylekov, 2009" startWordPosition="2196" endWordPosition="2199">scribed before in our papers (Kouylekov et. al., 2011) the potential of the edit distance algorithm is limited. Still it provides a 595 Task Beatle Q Beatle A sciEntsBank Q sciEntsBank A sciEntsBank D 2way run 1 0.6400 0.6570 0.5930 0.6280 0.6160 run 2 0.4620 0.4480 0.5560 0.5930 0.5710 3way run 1 0.5510 0.4950 0.5240 0.5780 0.5490 run 2 0.4150 0.4400 0.4390 0.5030 0.4770 5way run 1 0.4830 0.4470 0.4130 0.4340 0.4170 run 2 0.3850 0.4320 0.2330 0.2370 0.2540 Table 1: Task 7 Results obtained. (Accuracy) good performance and provides a solid potential for some close domain tasks as described in (Negri and Kouylekov, 2009). We were quite content with the new machine learning based core. The selected configuration performed in an acceptable manner. The results obtained were in line with the cross accuracy obtained by our system on the training set which shows that it is not susceptible to over-training. 5 CLTE 5.1 Systems We have submitted two runs in the CLTE task (Task 8). System 1 The distance algorithm used in the first system is Word Overlap as we did for task 7. We have created two features for each binary classifier: 1) Feature 1 - word overlap of H into T (words of H are matched by the words in T; 2) Fea</context>
</contexts>
<marker>Negri, Kouylekov, 2009</marker>
<rawString>Negri M., Kouylekov M., 2009 Question Answering over Structured Data: an Entailment-Based Approach to Question Analysis. RANLP 2009 - Recent Advances in Natural Language Processing, 2009 Borovets, Bulgaria</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Negri</author>
<author>A Marchetti</author>
<author>Y Mehdad</author>
<author>L Bentivogli</author>
<author>D Giampiccolo</author>
</authors>
<title>Semeval-2012 Task 8: Cross-lingual Textual Entailment for Content Synchronization.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<marker>Negri, Marchetti, Mehdad, Bentivogli, Giampiccolo, 2012</marker>
<rawString>Negri M., Marchetti A., Mehdad Y., Bentivogli L., Giampiccolo D. Semeval-2012 Task 8: Cross-lingual Textual Entailment for Content Synchronization. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012). 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P D Turney</author>
</authors>
<title>Mining the web for synonyms: Pmiir versus lsa on toefl.</title>
<date>2001</date>
<booktitle>In EMCL 01: Proceedings of the 12th European Conference on Machine Learning,</booktitle>
<pages>491502</pages>
<publisher>Springer-Verlag</publisher>
<location>London, UK,</location>
<contexts>
<context position="10760" citStr="Turney, 2001" startWordPosition="1735" endWordPosition="1736">y input word the component will return the set of all possible translations. For unavailable pairs, we make use of triangular translation (Kraaij, 2003). As for the semantic component we experimented with a corpus-based distributional approach capable of detecting the interrelation between different terms in a corpus; the strategy we adopted is similar to Latent Semantic Analysis (Deerwester et. al., 1990) although it uses a less expensive computational solution based on the Random Projection algorithm (Lin et. al., 2003) and (Bingham et. al., 2001). Different works debate on similar issues: (Turney, 2001) uses LSA in order to solve synonymy detection questions from the well-known TOEFL test while the method presented by (Inkpen, 2001) or by (Baroni and Bisi, 2001) proposes the use of the Web as a corpus to 594 Figure 1: EDITS Architecture compute mutual information scores between candidate terms. We use Wikipedia as a corpus for calculating word statistics in different languages. We have indexed using Lucene1 the English, Italian, French, German, Spanish distributions of the resource. The semantic component and the translation2 modules are used as core components in the matcher module. IDF cal</context>
</contexts>
<marker>Turney, 2001</marker>
<rawString>Turney P.D. 2001. Mining the web for synonyms: Pmiir versus lsa on toefl. In EMCL 01: Proceedings of the 12th European Conference on Machine Learning, London, UK, Springer-Verlag pages 491502</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>