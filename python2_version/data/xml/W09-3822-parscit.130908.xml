<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001732">
<title confidence="0.71369975">
Application of feature propagation to dependency parsing
Kepa Bengoetxea Koldo Gojenola
IXA NLP Group, Technical School of Engineering, Bilbao
University of the Basque Country, Plaza La Casilla 3, 48012, Bilbao
</title>
<email confidence="0.946464">
kepa.bengoetxea@ehu.es, koldo.gojenola@ehu.es
</email>
<sectionHeader confidence="0.991137" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999725153846154">
This paper presents a set of experiments per-
formed on parsing the Basque Dependency
Treebank. We have applied feature propaga-
tion to dependency parsing, experimenting the
propagation of several morphosyntactic fea-
ture values. In the experiments we have used
the output of a parser to enrich the input of a
second parser. Both parsers have been gener-
ated by Maltparser, a freely data-driven de-
pendency parser generator. The transforma-
tions, combined with the pseudoprojective
graph transformation, obtain a LAS of 77.12%
improving the best reported results for Basque.
</bodyText>
<sectionHeader confidence="0.998489" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999963316666667">
This work presents several experiments per-
formed on dependency parsing of the Basque
Dependency Treebank (BDT, Aduriz et al.
2003). We have experimented the idea of feature
propagation through dependency arcs, in order to
help the parser. Feature propagation has been
used in classical unification-based grammars as a
means of propagating linguistic information
through syntax trees. We apply this idea in the
context of inductive dependency parsing, com-
bining a reduced set of linguistic principles that
express feature propagation among linguistic
elements with Maltparser (Nivre et al. 2007a), an
automatic dependency parser generator.
We have concentrated on propagating several
morphosyntactic feature values from: a) auxiliary
verbs to the main verb, b) the last constituent to
the head noun, in noun phrases c) the last con-
junct to the conjunction, in coordination.
This work was developed in the context of de-
pendency parsing exemplified by the CoNLL
shared task on dependency parsing in years 2006
and 2007 (Nivre et al. 2007b), where several sys-
tems had to compete analyzing data from a typo-
logically varied range of 11 languages. The tree-
banks for all languages were standardized using
a previously agreed CoNLL-X format (see Fig-
ure 1). BDT was one of the evaluated treebanks,
which will allow a direct comparison of results.
Many works on treebank parsing have dedi-
cated an effort to the task of pre-processing train-
ing trees (Nilsson et al. 2007). When these ap-
proaches have been applied to dependency pars-
ing several works (Nilsson et al. 2007; Ben-
goetxea and Gojenola 2009) have concentrated
on modifying the structure of the dependency
tree, changing the shape of the graph. In contrast,
rather than modifying the tree structure, we will
experiment changing the information contained
in the nodes of the tree. This approach requires
having an initial dependency tree in order to ap-
ply the feature propagation process, which will
be obtained by means of a standard trained
model. This way, the features will be propagated
through some incorrect dependency arcs, and the
process will be dependent on the reliability of the
initial arcs. After enriching the tree, a second
parsing model will try to use this new informa-
tion to improve the standard model. This process
can also be seen as an example of stacked learn-
ing (Martins et al. 2008, Nivre and McDonald
2008) where a second parser is used to improve
the performance of a first one.
The rest of the paper is organized as follows.
Section 2 presents the main resources used in this
work. Section 3 presents three different propos-
als for the propagation of the most important
morphological features. Next, section 4 will
evaluate the results of each transformation, and
the last section outlines the main conclusions.
</bodyText>
<sectionHeader confidence="0.995692" genericHeader="introduction">
2 Resources
</sectionHeader>
<bodyText confidence="0.999293">
This section will describe the main elements that
have been used in the experiments. First, subsec-
tion 2.1 will present the Basque Dependency
Treebank data, while subsection 2.2 will describe
the main characteristics of Maltparser, a state of
the art and data-driven dependency parser.
</bodyText>
<subsectionHeader confidence="0.974407">
2.1 The Basque Dependency Treebank
</subsectionHeader>
<bodyText confidence="0.9999755">
The BDT can be considered a pure dependency
treebank, as its initial design considered that all
the dependency arcs would connect sentence to-
kens. Although this decision had consequences
on the annotation process, its simplicity is also
an advantage when applying several of the most
</bodyText>
<page confidence="0.935431">
142
</page>
<bodyText confidence="0.484046">
Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 142–145,
Paris, October 2009. c�2009 Association for Computational Linguistics
</bodyText>
<figure confidence="0.913092">
Index Word Lemma Category Subcategory Features Head Dependency
1 etorri etorri V V _ 3 lot
2 dela izan AUXV AUXV SC:CMP|SUBJ:3S 1 auxmod
3 eta eta CONJ CONJ _ 6 ccomp_obj
4 joan joan V V _ 3 lot
5 dela izan AUXV AUXV SC:CMP|SUBJ:3S 4 auxmod
6 esan esan V V _ 0 ROOT
7 zien *edun AUXV AUXV SUBJ:3S|OBJ:3P 6 auxmod
8 mutil mutil NOUN NOUN _ 6 ncsubj
9 txikiak txiki ADJ ADJ CASE:ERG|NUM:S 8 ncmod
10 . . PUNT PUNT_PUNT _ 9 PUNC
</figure>
<figureCaption confidence="0.999963">
Figure 1: Example of a BDT sentence in the CONLL-X format
</figureCaption>
<bodyText confidence="0.8895882">
(V = main verb, AUXV = auxiliary verb, SC = subordinated clause, CMP = completive, ccomp_obj = clausal
complement object, SUBJ:3S: subject in 3rd person sing., OBJ:3P: object in 3rd person pl.).
efficient parsing algorithms. The treebank con-
sists of 55,469 tokens forming 3,700 sentences,
334 of which were used as test data.
</bodyText>
<listItem confidence="0.7777305">
(1) Etorri (come) dela (that-has) eta
(and) joan (go) dela (that-has) esan
(tell) zien (did) mutil (boy)
txikiak(the-little)
</listItem>
<bodyText confidence="0.997702285714286">
He told the little boy that he has come
and he has gone
Figure 1 contains an example of a sentence
(1), annotated in the CoNLL-X format. The text
is organized in eight tab-separated columns:
word-number, form, lemma, category , subcate-
gory, morphological features, and the depend-
ency relation (headword + dependency). Basque
is an agglutinative language and it presents a
high power to generate inflected word-forms.
The information in Figure 1 has been simplified
due to space reasons, as typically the Features
column will contain many morphological fea-
tures, which are relevant for parsing.
</bodyText>
<subsectionHeader confidence="0.990111">
2.2 Maltparser
</subsectionHeader>
<bodyText confidence="0.972323764705883">
Maltparser (Nivre et al. 2007a) is a state of the
art dependency parser that has been successfully
applied to typologically different languages and
treebanks. While several variants of the base
parser have been implemented, we will use one
of its standard versions (Maltparser version 0.4).
ccomp_obj
The parser obtains deterministically a depend-
ency tree in linear-time in a single pass over the
input. To determine which is the best action at
each parsing step, the parser uses history-based
feature models and discriminative machine learn-
ing. In all the following experiments, we made
use of a SVM classifier. The specification of the
features used for learning can in principle be any
kind of data in Figure 1 (such as word-form,
lemma, category or morphological features).
</bodyText>
<sectionHeader confidence="0.998631" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.99637">
We applied the following steps:
</bodyText>
<listItem confidence="0.907102142857143">
a) Application of feature propagation to the
training data, using the gold standard arcs, ob-
taining a “enriched training data”.
b) Training Maltparser on the “enriched train-
ing data” to generate a “enriched parser”.
c) Training Maltparser with the training data,
without any transformation, to generate a
“standard parser”.
d) Parse the test data with the “standard
parser”, obtaining the “standard output”.
e) Apply feature propagation to the “standard
output”, using the dependency arcs given by
the parser (with some incorrect arcs), obtain-
ing the “standard parser’s enriched output”.
</listItem>
<bodyText confidence="0.8017292">
f) Finally, parsing the “standard parser’s en-
riched output” with the “enriched parser”,
Etorri da+la eta joan da+la esan zien mutil txiki+ak
come has+he+that and go has+he+that tell did+he+them boy little+the
V AUXV+3S+CMP CONJ V AUXV+3S+CMP V AUXV+SUBJ3S+OBJ3P NOUN ADJ+ERG
</bodyText>
<figureCaption confidence="0.99433">
Figure 2: Dependency tree for the sentence in Figure 1.
</figureCaption>
<figure confidence="0.823873692307692">
(V = main verb; AUXV: auxiliary verb; CMP: completive subordinated mark; CONJ: conjunction; ERG: ergative case).
coord
auxmod
auxmod
ncmod
ncsubj
coord
auxmod
143
ccomp_obj
Etorri da+la eta joan da+la esan zien mutil txiki+ak
come has+he+that and go has+he+that tell did+he+them boy little+the
V+CMP AUXV+3S+CMP CONJ+HV V+CMP AUXV+3S+CMP V AUXV+SUBJ3S+OBJ3P NOUN+ERG ADJ+ERG
</figure>
<figureCaption confidence="0.985401">
Figure 3: Dependency tree after propagating the morphological features.
</figureCaption>
<figure confidence="0.994456285714286">
coord
auxmod
ncmod
ncsubj
auxmod
coord
auxmod
</figure>
<bodyText confidence="0.982158846153846">
evaluating the output with the gold test data.
We have applied three types of feature propa-
gation of the most important morphological fea-
ture values: a) from auxiliary verbs to the main
verb (verb phrases) b) from post-modifiers to the
head noun (noun phrases) c) from the last con-
junct to the conjunction (coordination). This was
done because Basque is a head final language,
where many relevant features are located at the
end of constituents. Figure 3 shows (dotted lines)
the arcs that will propagate features from child to
parent. The three transformations will be de-
scribed in the following subsections.
</bodyText>
<subsectionHeader confidence="0.99622">
3.1 Verb compounds
</subsectionHeader>
<bodyText confidence="0.999918708333333">
In BDT the verbal elements are organized around
the main verb, but much syntactically relevant
verbal information, like subordination type, as-
pect, tense and agreement usually appear at-
tached to the auxiliary verb, which is the de-
pendent. Its main consequence for parsing is that
the elements bearing the relevant information for
parsing are situated far in the tree with respect to
their head. In Figure 2, we can see that the mor-
pheme –la, indicating a subordinated completive
sentence, appears down in the tree, and this could
affect the correct attachment of the two coordi-
nated verbs to the conjunction (eta), as conjunc-
tions should link elements showing similar
grammatical features (-la in this example). Simi-
larly, it could affect the decision about the de-
pendency type of eta (and) with respect to the
main verb esan (to say), as the dependency rela-
tion ccomp_obj is defined by means of the –la
(completive) morpheme, far down in the tree.
Figure 3 shows the effect of propagating the
completive feature value (CMP) from the auxil-
iary verb to the main verb through the auxmod
(auxiliary modifier) relation.
</bodyText>
<subsectionHeader confidence="0.999288">
3.2 Noun Phrases
</subsectionHeader>
<bodyText confidence="0.9999755">
In noun phrases and postpositional phrases, the
most important morphological feature values
(case and number) are situated in the last post-
modifier after the noun. Figure 3 shows the ef-
fect of propagating the ergative (ERG) case fea-
ture value from the adjective (the last constituent
of the noun phrase) to the noun through the rela-
tion ncmod (non-clausal modifier).
</bodyText>
<subsectionHeader confidence="0.997854">
3.3 Coordination
</subsectionHeader>
<bodyText confidence="0.999969833333333">
Coordination in BDT was annotated in the so
called Prague Style, where the conjunction is
taken as the head, and the conjuncts depend on it.
Basque is head final, so usually the last conjunct
contains syntactically relevant features. We ex-
perimented the promotion of the category, case
and subordination information from the last con-
junct to the conjunction. In the example in Figure
3, the conjunction (eta) receives a new feature
(HV for Head:Verb) from its dependent. This can
be seen as an alternative to (Nilsson et al. 2007)
who transform dependency arcs.
</bodyText>
<sectionHeader confidence="0.997039" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.9999671">
Evaluation was performed dividing the treebank
in three sets: training set (45,000 tokens), devel-
opment and test sets (5,000 tokens each). Train-
ing and testing of the system have been per-
formed on the same datasets presented at the
CoNLL 2007 shared task, which will allow for a
direct comparison. Table 1 presents the Labeled
Attachment Score (LAS) of the different tests on
development and test data. The first row presents
the best system score (76.94% LAS) in CoNLL
2007. This system combined six variants of a
base parser (Maltparser). The second row shows
the single Maltparser approach which obtained
the fifth position. Row 3 presents Bengoetxea
and Gojenola’s results (76.80% LAS) when ap-
plying graph transformations (pseudo-projective,
coordination and verb groups) to Basque, in the
spirit of Nilsson et al. (2007). Row 4 shows our
results after applying several feature optimiza-
tions, which we will use as our baseline.
</bodyText>
<page confidence="0.995974">
144
</page>
<table confidence="0.970795">
LAS
System Development Test
1 Nivre et al. 2007b (CoNLL 2007) - 76.94%
2 Hall et al. 2007 (CoNLL 2007) 74.99%
3 Bengoetxea and Gojenola 2009 76.80%
4 Feature optimization (baseline) 77.46% 75.07%
5 Proj 78.16% (+0.70) *75.99% (+0.92)
6 PVG 78.14% (+0.68) 75.54% (+0.47)
7 PCOOR 77.36% (-0.10) 75.22% (+0.15)
8 PCAS 77.32% (-0.14) 74.86% (-0.21)
9 PVG + PCAS 78.53% (+1.09) 75.42% (+0.35)
10 PCOOR+ PVG + PCAS 78.31% (+0.85) *75.93% (+0.86)
11 PCOOR+ PVG 78.25% (+0.79) *75.93% (+0.86)
12 Proj + PVG 78.91% (+1.45) *76.12% (+1.05)
13 Proj + PVG + PCOOR + PCAS 78.31% (+0.85) *77.12% (+2.05)
</table>
<tableCaption confidence="0.817843333333333">
Table 1. Evaluation results
(Proj: Pseudo-projective, PVG, PCAS, PCOOR: Propagation on verb compounds, case (NPs) and coordination; *: statistically
significant in McNemar&apos;s test with respect to labeled attachment score with p &lt; 0.01)
</tableCaption>
<bodyText confidence="0.999938894736842">
Feature propagation in verb groups (PVG) im-
proves LAS in almost 0.5% (row 6 in Table 1).
While coordination and case propagation do not
improve significantly the accuracy by themselves
(rows 7 and 8), their combination with PVG (verb
groups) significantly increases LAS (+0.86%,
see row 10). Looking at the accuracy of the de-
pendency arcs used for feature propagation, aux-
liary verbs are the most reliable elements, as
their arcs (linking it to its head, the main verb)
have 97% precision and 98% recall. This is in
accord with PVG giving the biggest increase,
while arcs related to coordination (63% precision
and 65% recall) give a more modest contribution.
BDT contains 2.9% of nonprojective arcs, so
we experimented the effect of combining the
pseudoprojective transformation (Nilsson et al.
2007) with feature propagation, obtaining a LAS
of 77.12%, the best reported results for the BDT.
</bodyText>
<sectionHeader confidence="0.999563" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9999893">
We have performed a set of experiments using
the output of a parser to enrich the input of a
second parser, propagating the relevant morpho-
logical feature values through dependency arcs.
The best system, after applying three types of
feature propagation, obtains a 77.12% LAS
(2.05% improvement over the baseline) on the
test set, which is the best reported result for
Basque dependency parsing, improving the better
published result for a combined parser (76.94%).
</bodyText>
<sectionHeader confidence="0.996938" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99510225">
This research was supported by the Basque Gov-
ernment (EPEC-RS, S-PE08UN48) and the Uni-
versity of the Basque Country (EHU-EJIE,
EJIE07/05).
</bodyText>
<sectionHeader confidence="0.998418" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9996967">
I. Aduriz, M. J. Aranzabe, J. M. Arriola, A. Atutxa, A.
Diaz de Ilarraza, A. Garmendia and M. Oronoz.
2003. Construction of a Basque dependency
treebank. Treebanks and Linguistic Theories.
Kepa Bengoetxea and Koldo Gojenola. 2009. Explor-
ing Treebank Transformations in Dependency
Parsing. Proceedings of RANLP’2009.
Johan Hall, Jens Nilsson, Joakim Nivre J., Eryigit G.,
Megyesi B., Nilsson M. and Saers M. 2007. Single
Malt or Blended? A Study in Multilingual
Parser Optimization. Proceedings of the CoNLL
Shared Task EMNLP-CoNLL.
André F. T. Martins, Dipanjan Das, Noah A. Smith,
Eric P. Xing. 2008. Stacking Dependency Pars-
ing. EMNLP-2008.
Jens Nilsson, Joakim Nivre and Johan Hall. 2007.
Tree Transformations for Inductive Depend-
ency Parsing. Proceedings of the 45th ACL.
Joakim Nivre, Johan Hall, Jens Nilsson, Chanev A.,
Gülsen Eryiğit, Sandra Kübler, Marinov S., and
Edwin Marsi. 2007a. MaltParser: A language-
independent system for data-driven depend-
ency parsing. Natural Language Engineering.
Joakim Nivre, Johan Hall, Sandra Kübler, Ryan
McDonald, Jens Nilsson, Sebastian Riedel and
Deniz Yuret. 2007b. The CoNLL 2007 Shared
Task on Dependency Parsing. EMNLP-CoNLL.
Joakim Nivre and Ryan McDonald. 2008. Integrat-
ing graphbased and transition-based depend-
ency parsers. ACL-2008.
</reference>
<page confidence="0.998809">
145
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.828601">
<title confidence="0.999526">Application of feature propagation to dependency parsing</title>
<author confidence="0.995606">Kepa Bengoetxea Koldo Gojenola</author>
<affiliation confidence="0.99954">IXA NLP Group, Technical School of Engineering,</affiliation>
<address confidence="0.902372">University of the Basque Country, Plaza La Casilla 3, 48012,</address>
<email confidence="0.950594">kepa.bengoetxea@ehu.es,koldo.gojenola@ehu.es</email>
<abstract confidence="0.997176142857143">This paper presents a set of experiments performed on parsing the Basque Dependency Treebank. We have applied feature propagation to dependency parsing, experimenting the propagation of several morphosyntactic feature values. In the experiments we have used the output of a parser to enrich the input of a second parser. Both parsers have been generated by Maltparser, a freely data-driven dependency parser generator. The transformations, combined with the pseudoprojective graph transformation, obtain a LAS of 77.12% improving the best reported results for Basque.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>I Aduriz</author>
<author>M J Aranzabe</author>
<author>J M Arriola</author>
<author>A Atutxa</author>
<author>A Diaz de Ilarraza</author>
<author>A Garmendia</author>
<author>M Oronoz</author>
</authors>
<title>Construction of a Basque dependency treebank. Treebanks and Linguistic Theories.</title>
<date>2003</date>
<marker>Aduriz, Aranzabe, Arriola, Atutxa, de Ilarraza, Garmendia, Oronoz, 2003</marker>
<rawString>I. Aduriz, M. J. Aranzabe, J. M. Arriola, A. Atutxa, A. Diaz de Ilarraza, A. Garmendia and M. Oronoz. 2003. Construction of a Basque dependency treebank. Treebanks and Linguistic Theories.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kepa Bengoetxea</author>
<author>Koldo Gojenola</author>
</authors>
<title>Exploring Treebank Transformations in Dependency Parsing.</title>
<date>2009</date>
<booktitle>Proceedings of RANLP’2009.</booktitle>
<contexts>
<context position="2437" citStr="Bengoetxea and Gojenola 2009" startWordPosition="373" endWordPosition="377">shared task on dependency parsing in years 2006 and 2007 (Nivre et al. 2007b), where several systems had to compete analyzing data from a typologically varied range of 11 languages. The treebanks for all languages were standardized using a previously agreed CoNLL-X format (see Figure 1). BDT was one of the evaluated treebanks, which will allow a direct comparison of results. Many works on treebank parsing have dedicated an effort to the task of pre-processing training trees (Nilsson et al. 2007). When these approaches have been applied to dependency parsing several works (Nilsson et al. 2007; Bengoetxea and Gojenola 2009) have concentrated on modifying the structure of the dependency tree, changing the shape of the graph. In contrast, rather than modifying the tree structure, we will experiment changing the information contained in the nodes of the tree. This approach requires having an initial dependency tree in order to apply the feature propagation process, which will be obtained by means of a standard trained model. This way, the features will be propagated through some incorrect dependency arcs, and the process will be dependent on the reliability of the initial arcs. After enriching the tree, a second pa</context>
<context position="11998" citStr="Bengoetxea and Gojenola 2009" startWordPosition="1923" endWordPosition="1926">(76.94% LAS) in CoNLL 2007. This system combined six variants of a base parser (Maltparser). The second row shows the single Maltparser approach which obtained the fifth position. Row 3 presents Bengoetxea and Gojenola’s results (76.80% LAS) when applying graph transformations (pseudo-projective, coordination and verb groups) to Basque, in the spirit of Nilsson et al. (2007). Row 4 shows our results after applying several feature optimizations, which we will use as our baseline. 144 LAS System Development Test 1 Nivre et al. 2007b (CoNLL 2007) - 76.94% 2 Hall et al. 2007 (CoNLL 2007) 74.99% 3 Bengoetxea and Gojenola 2009 76.80% 4 Feature optimization (baseline) 77.46% 75.07% 5 Proj 78.16% (+0.70) *75.99% (+0.92) 6 PVG 78.14% (+0.68) 75.54% (+0.47) 7 PCOOR 77.36% (-0.10) 75.22% (+0.15) 8 PCAS 77.32% (-0.14) 74.86% (-0.21) 9 PVG + PCAS 78.53% (+1.09) 75.42% (+0.35) 10 PCOOR+ PVG + PCAS 78.31% (+0.85) *75.93% (+0.86) 11 PCOOR+ PVG 78.25% (+0.79) *75.93% (+0.86) 12 Proj + PVG 78.91% (+1.45) *76.12% (+1.05) 13 Proj + PVG + PCOOR + PCAS 78.31% (+0.85) *77.12% (+2.05) Table 1. Evaluation results (Proj: Pseudo-projective, PVG, PCAS, PCOOR: Propagation on verb compounds, case (NPs) and coordination; *: statistically s</context>
</contexts>
<marker>Bengoetxea, Gojenola, 2009</marker>
<rawString>Kepa Bengoetxea and Koldo Gojenola. 2009. Exploring Treebank Transformations in Dependency Parsing. Proceedings of RANLP’2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
<author>Joakim Nivre J</author>
<author>G Eryigit</author>
<author>B Megyesi</author>
<author>M Nilsson</author>
<author>M Saers</author>
</authors>
<title>Single Malt or Blended? A Study in Multilingual Parser Optimization.</title>
<date>2007</date>
<booktitle>Proceedings of the CoNLL Shared Task EMNLP-CoNLL.</booktitle>
<contexts>
<context position="11947" citStr="Hall et al. 2007" startWordPosition="1915" endWordPosition="1918">rst row presents the best system score (76.94% LAS) in CoNLL 2007. This system combined six variants of a base parser (Maltparser). The second row shows the single Maltparser approach which obtained the fifth position. Row 3 presents Bengoetxea and Gojenola’s results (76.80% LAS) when applying graph transformations (pseudo-projective, coordination and verb groups) to Basque, in the spirit of Nilsson et al. (2007). Row 4 shows our results after applying several feature optimizations, which we will use as our baseline. 144 LAS System Development Test 1 Nivre et al. 2007b (CoNLL 2007) - 76.94% 2 Hall et al. 2007 (CoNLL 2007) 74.99% 3 Bengoetxea and Gojenola 2009 76.80% 4 Feature optimization (baseline) 77.46% 75.07% 5 Proj 78.16% (+0.70) *75.99% (+0.92) 6 PVG 78.14% (+0.68) 75.54% (+0.47) 7 PCOOR 77.36% (-0.10) 75.22% (+0.15) 8 PCAS 77.32% (-0.14) 74.86% (-0.21) 9 PVG + PCAS 78.53% (+1.09) 75.42% (+0.35) 10 PCOOR+ PVG + PCAS 78.31% (+0.85) *75.93% (+0.86) 11 PCOOR+ PVG 78.25% (+0.79) *75.93% (+0.86) 12 Proj + PVG 78.91% (+1.45) *76.12% (+1.05) 13 Proj + PVG + PCOOR + PCAS 78.31% (+0.85) *77.12% (+2.05) Table 1. Evaluation results (Proj: Pseudo-projective, PVG, PCAS, PCOOR: Propagation on verb compoun</context>
</contexts>
<marker>Hall, Nilsson, J, Eryigit, Megyesi, Nilsson, Saers, 2007</marker>
<rawString>Johan Hall, Jens Nilsson, Joakim Nivre J., Eryigit G., Megyesi B., Nilsson M. and Saers M. 2007. Single Malt or Blended? A Study in Multilingual Parser Optimization. Proceedings of the CoNLL Shared Task EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>André F T Martins</author>
<author>Dipanjan Das</author>
<author>Noah A Smith</author>
<author>Eric P Xing</author>
</authors>
<title>Stacking Dependency Parsing.</title>
<date>2008</date>
<contexts>
<context position="3201" citStr="Martins et al. 2008" startWordPosition="502" endWordPosition="505">e structure, we will experiment changing the information contained in the nodes of the tree. This approach requires having an initial dependency tree in order to apply the feature propagation process, which will be obtained by means of a standard trained model. This way, the features will be propagated through some incorrect dependency arcs, and the process will be dependent on the reliability of the initial arcs. After enriching the tree, a second parsing model will try to use this new information to improve the standard model. This process can also be seen as an example of stacked learning (Martins et al. 2008, Nivre and McDonald 2008) where a second parser is used to improve the performance of a first one. The rest of the paper is organized as follows. Section 2 presents the main resources used in this work. Section 3 presents three different proposals for the propagation of the most important morphological features. Next, section 4 will evaluate the results of each transformation, and the last section outlines the main conclusions. 2 Resources This section will describe the main elements that have been used in the experiments. First, subsection 2.1 will present the Basque Dependency Treebank data</context>
</contexts>
<marker>Martins, Das, Smith, Xing, 2008</marker>
<rawString>André F. T. Martins, Dipanjan Das, Noah A. Smith, Eric P. Xing. 2008. Stacking Dependency Parsing. EMNLP-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jens Nilsson</author>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
</authors>
<title>Tree Transformations for Inductive Dependency Parsing.</title>
<date>2007</date>
<booktitle>Proceedings of the 45th ACL.</booktitle>
<contexts>
<context position="2308" citStr="Nilsson et al. 2007" startWordPosition="352" endWordPosition="355">the conjunction, in coordination. This work was developed in the context of dependency parsing exemplified by the CoNLL shared task on dependency parsing in years 2006 and 2007 (Nivre et al. 2007b), where several systems had to compete analyzing data from a typologically varied range of 11 languages. The treebanks for all languages were standardized using a previously agreed CoNLL-X format (see Figure 1). BDT was one of the evaluated treebanks, which will allow a direct comparison of results. Many works on treebank parsing have dedicated an effort to the task of pre-processing training trees (Nilsson et al. 2007). When these approaches have been applied to dependency parsing several works (Nilsson et al. 2007; Bengoetxea and Gojenola 2009) have concentrated on modifying the structure of the dependency tree, changing the shape of the graph. In contrast, rather than modifying the tree structure, we will experiment changing the information contained in the nodes of the tree. This approach requires having an initial dependency tree in order to apply the feature propagation process, which will be obtained by means of a standard trained model. This way, the features will be propagated through some incorrect</context>
<context position="10877" citStr="Nilsson et al. 2007" startWordPosition="1740" endWordPosition="1743">n phrase) to the noun through the relation ncmod (non-clausal modifier). 3.3 Coordination Coordination in BDT was annotated in the so called Prague Style, where the conjunction is taken as the head, and the conjuncts depend on it. Basque is head final, so usually the last conjunct contains syntactically relevant features. We experimented the promotion of the category, case and subordination information from the last conjunct to the conjunction. In the example in Figure 3, the conjunction (eta) receives a new feature (HV for Head:Verb) from its dependent. This can be seen as an alternative to (Nilsson et al. 2007) who transform dependency arcs. 4 Evaluation Evaluation was performed dividing the treebank in three sets: training set (45,000 tokens), development and test sets (5,000 tokens each). Training and testing of the system have been performed on the same datasets presented at the CoNLL 2007 shared task, which will allow for a direct comparison. Table 1 presents the Labeled Attachment Score (LAS) of the different tests on development and test data. The first row presents the best system score (76.94% LAS) in CoNLL 2007. This system combined six variants of a base parser (Maltparser). The second row</context>
<context position="13484" citStr="Nilsson et al. 2007" startWordPosition="2161" endWordPosition="2164">ves (rows 7 and 8), their combination with PVG (verb groups) significantly increases LAS (+0.86%, see row 10). Looking at the accuracy of the dependency arcs used for feature propagation, auxliary verbs are the most reliable elements, as their arcs (linking it to its head, the main verb) have 97% precision and 98% recall. This is in accord with PVG giving the biggest increase, while arcs related to coordination (63% precision and 65% recall) give a more modest contribution. BDT contains 2.9% of nonprojective arcs, so we experimented the effect of combining the pseudoprojective transformation (Nilsson et al. 2007) with feature propagation, obtaining a LAS of 77.12%, the best reported results for the BDT. 5 Conclusions We have performed a set of experiments using the output of a parser to enrich the input of a second parser, propagating the relevant morphological feature values through dependency arcs. The best system, after applying three types of feature propagation, obtains a 77.12% LAS (2.05% improvement over the baseline) on the test set, which is the best reported result for Basque dependency parsing, improving the better published result for a combined parser (76.94%). Acknowledgements This resea</context>
</contexts>
<marker>Nilsson, Nivre, Hall, 2007</marker>
<rawString>Jens Nilsson, Joakim Nivre and Johan Hall. 2007. Tree Transformations for Inductive Dependency Parsing. Proceedings of the 45th ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
<author>A Chanev</author>
<author>Gülsen Eryiğit</author>
<author>Sandra Kübler</author>
<author>S Marinov</author>
<author>Edwin Marsi</author>
</authors>
<title>MaltParser: A languageindependent system for data-driven dependency parsing. Natural Language Engineering.</title>
<date>2007</date>
<contexts>
<context position="1442" citStr="Nivre et al. 2007" startWordPosition="207" endWordPosition="210"> Basque. 1 Introduction This work presents several experiments performed on dependency parsing of the Basque Dependency Treebank (BDT, Aduriz et al. 2003). We have experimented the idea of feature propagation through dependency arcs, in order to help the parser. Feature propagation has been used in classical unification-based grammars as a means of propagating linguistic information through syntax trees. We apply this idea in the context of inductive dependency parsing, combining a reduced set of linguistic principles that express feature propagation among linguistic elements with Maltparser (Nivre et al. 2007a), an automatic dependency parser generator. We have concentrated on propagating several morphosyntactic feature values from: a) auxiliary verbs to the main verb, b) the last constituent to the head noun, in noun phrases c) the last conjunct to the conjunction, in coordination. This work was developed in the context of dependency parsing exemplified by the CoNLL shared task on dependency parsing in years 2006 and 2007 (Nivre et al. 2007b), where several systems had to compete analyzing data from a typologically varied range of 11 languages. The treebanks for all languages were standardized us</context>
<context position="5994" citStr="Nivre et al. 2007" startWordPosition="962" endWordPosition="965">y that he has come and he has gone Figure 1 contains an example of a sentence (1), annotated in the CoNLL-X format. The text is organized in eight tab-separated columns: word-number, form, lemma, category , subcategory, morphological features, and the dependency relation (headword + dependency). Basque is an agglutinative language and it presents a high power to generate inflected word-forms. The information in Figure 1 has been simplified due to space reasons, as typically the Features column will contain many morphological features, which are relevant for parsing. 2.2 Maltparser Maltparser (Nivre et al. 2007a) is a state of the art dependency parser that has been successfully applied to typologically different languages and treebanks. While several variants of the base parser have been implemented, we will use one of its standard versions (Maltparser version 0.4). ccomp_obj The parser obtains deterministically a dependency tree in linear-time in a single pass over the input. To determine which is the best action at each parsing step, the parser uses history-based feature models and discriminative machine learning. In all the following experiments, we made use of a SVM classifier. The specificatio</context>
<context position="11905" citStr="Nivre et al. 2007" startWordPosition="1906" endWordPosition="1909"> tests on development and test data. The first row presents the best system score (76.94% LAS) in CoNLL 2007. This system combined six variants of a base parser (Maltparser). The second row shows the single Maltparser approach which obtained the fifth position. Row 3 presents Bengoetxea and Gojenola’s results (76.80% LAS) when applying graph transformations (pseudo-projective, coordination and verb groups) to Basque, in the spirit of Nilsson et al. (2007). Row 4 shows our results after applying several feature optimizations, which we will use as our baseline. 144 LAS System Development Test 1 Nivre et al. 2007b (CoNLL 2007) - 76.94% 2 Hall et al. 2007 (CoNLL 2007) 74.99% 3 Bengoetxea and Gojenola 2009 76.80% 4 Feature optimization (baseline) 77.46% 75.07% 5 Proj 78.16% (+0.70) *75.99% (+0.92) 6 PVG 78.14% (+0.68) 75.54% (+0.47) 7 PCOOR 77.36% (-0.10) 75.22% (+0.15) 8 PCAS 77.32% (-0.14) 74.86% (-0.21) 9 PVG + PCAS 78.53% (+1.09) 75.42% (+0.35) 10 PCOOR+ PVG + PCAS 78.31% (+0.85) *75.93% (+0.86) 11 PCOOR+ PVG 78.25% (+0.79) *75.93% (+0.86) 12 Proj + PVG 78.91% (+1.45) *76.12% (+1.05) 13 Proj + PVG + PCOOR + PCAS 78.31% (+0.85) *77.12% (+2.05) Table 1. Evaluation results (Proj: Pseudo-projective, PVG</context>
</contexts>
<marker>Nivre, Hall, Nilsson, Chanev, Eryiğit, Kübler, Marinov, Marsi, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Jens Nilsson, Chanev A., Gülsen Eryiğit, Sandra Kübler, Marinov S., and Edwin Marsi. 2007a. MaltParser: A languageindependent system for data-driven dependency parsing. Natural Language Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Sandra Kübler</author>
<author>Ryan McDonald</author>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<date>2007</date>
<journal>The CoNLL</journal>
<booktitle>Shared Task on Dependency Parsing. EMNLP-CoNLL.</booktitle>
<contexts>
<context position="1442" citStr="Nivre et al. 2007" startWordPosition="207" endWordPosition="210"> Basque. 1 Introduction This work presents several experiments performed on dependency parsing of the Basque Dependency Treebank (BDT, Aduriz et al. 2003). We have experimented the idea of feature propagation through dependency arcs, in order to help the parser. Feature propagation has been used in classical unification-based grammars as a means of propagating linguistic information through syntax trees. We apply this idea in the context of inductive dependency parsing, combining a reduced set of linguistic principles that express feature propagation among linguistic elements with Maltparser (Nivre et al. 2007a), an automatic dependency parser generator. We have concentrated on propagating several morphosyntactic feature values from: a) auxiliary verbs to the main verb, b) the last constituent to the head noun, in noun phrases c) the last conjunct to the conjunction, in coordination. This work was developed in the context of dependency parsing exemplified by the CoNLL shared task on dependency parsing in years 2006 and 2007 (Nivre et al. 2007b), where several systems had to compete analyzing data from a typologically varied range of 11 languages. The treebanks for all languages were standardized us</context>
<context position="5994" citStr="Nivre et al. 2007" startWordPosition="962" endWordPosition="965">y that he has come and he has gone Figure 1 contains an example of a sentence (1), annotated in the CoNLL-X format. The text is organized in eight tab-separated columns: word-number, form, lemma, category , subcategory, morphological features, and the dependency relation (headword + dependency). Basque is an agglutinative language and it presents a high power to generate inflected word-forms. The information in Figure 1 has been simplified due to space reasons, as typically the Features column will contain many morphological features, which are relevant for parsing. 2.2 Maltparser Maltparser (Nivre et al. 2007a) is a state of the art dependency parser that has been successfully applied to typologically different languages and treebanks. While several variants of the base parser have been implemented, we will use one of its standard versions (Maltparser version 0.4). ccomp_obj The parser obtains deterministically a dependency tree in linear-time in a single pass over the input. To determine which is the best action at each parsing step, the parser uses history-based feature models and discriminative machine learning. In all the following experiments, we made use of a SVM classifier. The specificatio</context>
<context position="11905" citStr="Nivre et al. 2007" startWordPosition="1906" endWordPosition="1909"> tests on development and test data. The first row presents the best system score (76.94% LAS) in CoNLL 2007. This system combined six variants of a base parser (Maltparser). The second row shows the single Maltparser approach which obtained the fifth position. Row 3 presents Bengoetxea and Gojenola’s results (76.80% LAS) when applying graph transformations (pseudo-projective, coordination and verb groups) to Basque, in the spirit of Nilsson et al. (2007). Row 4 shows our results after applying several feature optimizations, which we will use as our baseline. 144 LAS System Development Test 1 Nivre et al. 2007b (CoNLL 2007) - 76.94% 2 Hall et al. 2007 (CoNLL 2007) 74.99% 3 Bengoetxea and Gojenola 2009 76.80% 4 Feature optimization (baseline) 77.46% 75.07% 5 Proj 78.16% (+0.70) *75.99% (+0.92) 6 PVG 78.14% (+0.68) 75.54% (+0.47) 7 PCOOR 77.36% (-0.10) 75.22% (+0.15) 8 PCAS 77.32% (-0.14) 74.86% (-0.21) 9 PVG + PCAS 78.53% (+1.09) 75.42% (+0.35) 10 PCOOR+ PVG + PCAS 78.31% (+0.85) *75.93% (+0.86) 11 PCOOR+ PVG 78.25% (+0.79) *75.93% (+0.86) 12 Proj + PVG 78.91% (+1.45) *76.12% (+1.05) 13 Proj + PVG + PCOOR + PCAS 78.31% (+0.85) *77.12% (+2.05) Table 1. Evaluation results (Proj: Pseudo-projective, PVG</context>
</contexts>
<marker>Nivre, Hall, Kübler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Sandra Kübler, Ryan McDonald, Jens Nilsson, Sebastian Riedel and Deniz Yuret. 2007b. The CoNLL 2007 Shared Task on Dependency Parsing. EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Ryan McDonald</author>
</authors>
<title>Integrating graphbased and transition-based dependency parsers.</title>
<date>2008</date>
<pages>2008</pages>
<contexts>
<context position="3227" citStr="Nivre and McDonald 2008" startWordPosition="506" endWordPosition="509">experiment changing the information contained in the nodes of the tree. This approach requires having an initial dependency tree in order to apply the feature propagation process, which will be obtained by means of a standard trained model. This way, the features will be propagated through some incorrect dependency arcs, and the process will be dependent on the reliability of the initial arcs. After enriching the tree, a second parsing model will try to use this new information to improve the standard model. This process can also be seen as an example of stacked learning (Martins et al. 2008, Nivre and McDonald 2008) where a second parser is used to improve the performance of a first one. The rest of the paper is organized as follows. Section 2 presents the main resources used in this work. Section 3 presents three different proposals for the propagation of the most important morphological features. Next, section 4 will evaluate the results of each transformation, and the last section outlines the main conclusions. 2 Resources This section will describe the main elements that have been used in the experiments. First, subsection 2.1 will present the Basque Dependency Treebank data, while subsection 2.2 wil</context>
</contexts>
<marker>Nivre, McDonald, 2008</marker>
<rawString>Joakim Nivre and Ryan McDonald. 2008. Integrating graphbased and transition-based dependency parsers. ACL-2008.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>