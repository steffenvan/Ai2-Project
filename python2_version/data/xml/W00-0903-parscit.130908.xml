<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000220">
<title confidence="0.981327">
Comparing corpora and lexical ambiguity
</title>
<author confidence="0.925281">
Patrick Ruch Arnaud Gaudinat
</author>
<affiliation confidence="0.897323333333333">
Medical Informatics Divis:ion LATL
Geneva University Hospital University of Geneva
Switzerland Switzerland
</affiliation>
<email confidence="0.978813">
ruch@dim.hcuge.ch gaudinat@latl.unige.ch
</email>
<sectionHeader confidence="0.958203" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999362333333333">
In this paper we compare two types of
corpus, focusing on the lexical ambiguity of
each of them. The first corpus consists
mainly of newspaper articles and literature
excerpts, while the second belongs to the
medical domain. To conduct the study, we
have used two different disambiguation
tools. However, first of all, we must verify
the performance of each system in its
respective application domain. We then use
these systems in order to assess and compare
both the general ambiguity rate and the
particularities of each domain. Quantitative
results show that medical documents are
lexically less ambiguous than unrestricted
documents. Our conclusions show the
importance of the application area in the
design of NLP tools.
</bodyText>
<sectionHeader confidence="0.739882" genericHeader="categories and subject descriptors">
Introduction and background
</sectionHeader>
<bodyText confidence="0.999814416666667">
Although some large-scale evaluations carried
out on unrestricted texts (Hersh 1998a, Spark-
Jones 1999), and even on medical documents
(Hersh 1998b), conclude in a quite critical way
about using NLP tools for information retrieval,
we believe that such tools are likely to solve
some lexical ambiguity issues. We also believe
that some special settings -particular to the
application area- must be taken into account
while developing such NLP tools.
Let us recall two major problems while
retrieving documents with NLP engines (Salton,
1988):
1-Expansion: the user is generally as interested
in retrieving documents with exactly the same
words, as in retrieving documents with
semantically related words (synonyms, generics,
specifics...). Thus, a query based on the word
liver, should be able to retrieve documents
containing words such as hepatic. This
expansion process is usually thesaurus-based.
The thesaurus can be built manually or
automatically (as, for example, in Nazarenko,
1997).
2-Disambiguation: a search based on tokens may
retrieve irrelevant documents since tokens are
often lexically ambiguous. Thus, face can refer
to a body part, as a noun, or an action, as a verb.
Finally, this latter problem may be split into two
sub problems. The disambiguation task can be
based on parts-of-speech (POS) or word-sense
(WS) information, but the chronological relation
is still a discussion within the community.
Although, the target of our work (Ruch and al.,
1999, Bouillon and al., 2000) is a fme-grained
semantic disambiguation of medical texts for lR
purposes, we believe that the POS
disambiguation is an important preliminary step.
Therefore this paper focuses on POS tagging,
and compares morpho-syntactic lexical
ambiguities (MSLA) in medical texts to MSLA
in unrestricted corpora.
Although the results of the study conform to
preliminary naive expectations, the method is
quite original&apos;. Most of the comparative studies,
dedicated to corpora, have addressed the
problem by applying metrics on words entities
or word pieces (as in studies working with n-
</bodyText>
<footnote confidence="0.763001428571428">
I We do not claim to be pioneer in the domain, as
others authors (Biber 1998, Folch and al., 2000) are
exploring similar metrics. However, it is interesting
to notice that for these authors the adaptation of the
NLP tools has rarely been questioned in a technical
point-of view, and in order to feed back the design of
NLP systems.
</footnote>
<page confidence="0.999251">
14
</page>
<bodyText confidence="0.999779166666667">
gram strings), or on special sets of words (the
indexing terms, see Salton, 1988) as in the
space-vector model (see Kilgariff, 1996, for a
survey of these methods), whereas the present
paper attempts to compare corpora at a morpho-
syntactic (MS) level.
</bodyText>
<subsectionHeader confidence="0.64583">
1 Validating each tagger into its respective
domain
</subsectionHeader>
<bodyText confidence="0.999327701492538">
In order to conduct the comparative study, we
used two different morphological analysers;
each one has a specific lexicon tailored for its
application field. The first system is specialised
for tagging medical texts (Ruch and al., 2000),
while the second is a general parser (based on
FIPS, cf. Wehrli, 1992).
For comparing lexical ambiguities on a minimal
common base, the output of each morphological
analyser is first mapped into its respective tagset
(more than 300 fine-grained tags for FIPSTAG,
and about 80 for the morpheme-based medical
tagger). The tagsets are then converted into a
subset of the medical tagger. Finally, about 50
different items constitute this minimal common
tagset (MCT), which will serve for comparing
both corpora.
We collected two different sets of documents to
be tagged at a lexical level via the predefined
MCT: this step provides a set of tags to every
token. This set of tags may come from the
lexicon or from the POS guesser. As we are
using guessers, the empty set (or the tag for
unknown tokens) is forbidden. However, first of
all, it is necessary to verify the lexical coverage
of each system for each corpus, as we need to be
sure that the lexical ambiguities provided by
each system are necessary and sufficient.
The corpus of the unrestricted texts consists of
16003 tokens: about one third of newspaper
articles (Le Monde), one third of literature
excerpts (provided by the InaLF,
http://www.inalf:fr), and a smaller third being
mainly texts for children. Approximately a
quarter (3987 tokens) of this corpus is used for
evaluating FIPSTAG tagging results (the tool
together with some explanations can be found at
http://latunige.ch). In parallel, we chose three
types of medical texts to make up the medical
corpus: it represents 16024 tokens, with 3 equal
thirds: discharge summaries, surgical reports,
and laboratory or test results (in this case, tables
were removed). Again, a regularly distributed
quarter (4016) of this corpus is used for
assessing the medical tagger.
The test samples used for assessing the results of
each tagger are annotated manually before
measuring the performances, but in both cases
we sometimes had to modify the word
segmentation of the test samples. This is
particularly true for FIPSTAG, which handles
several acceptable but unusual collocations
(which gather more than one &apos;word&apos;), as for
example en avion (in Eng. by plane), which is
considered as one lexical item, tagged as an
adverb. For the lexical tagger we had to modify
the &apos;word&apos; segmentation in the other direction
(for tagging items smaller than &apos;words&apos;), as
morphemes were also tagged. Table 1 gives the
results for FIPSTAG, and table 2 gives the
results for the medical tagger. In the case of the
medical tagger, together with the error rate and
the success rate, we provide results of the
residual ambiguity rate: the basic idea is that the
system does not attempt to solve what it is not
likely to solve well (cf. Ruch and al. 2000, a
similar idea can be found in Silberztein 1997).
</bodyText>
<table confidence="0.9047055">
1 Correct tag 3959(99.3%)
1 Incorrect tag 28 (0.7%)
</table>
<tableCaption confidence="0.466301">
Tab. 1: Evaluation of FIPSTAG
</tableCaption>
<table confidence="0.76543">
1 Correct tag 3962(98.5%)
1 Incorrect tag 12(0.4%)
2 or more tags, at least 1 is 39(1.0%)
correct
2 or more tags, 0 correct 3 (0.1%)
</table>
<tableCaption confidence="0.591986">
Tab. 2: Evaluation of the medical tagger
</tableCaption>
<bodyText confidence="0.934731727272727">
A comparison of the tagging scores (99.3 vs.
98.5) confirms that both systems behave in an
equivalent way in their respective application
area2.
2 Out of curiosity, we ran each tagger on a small
sample of the other domain. The tests were made
without any adaptation. FIPSTAG made 27 errors in
a medical sample of 849 tokens, i.e. an error rate of
3.2%. The medical tagger made 18 errors in a general
sample of 747 tokens, which means an error rate of
2.4%. In the case of the medical tagger, 41 tokens
</bodyText>
<page confidence="0.994455">
15
</page>
<sectionHeader confidence="0.893853" genericHeader="method">
2 Morphological analysers, lexicons and
</sectionHeader>
<subsectionHeader confidence="0.802168">
guessers
</subsectionHeader>
<bodyText confidence="0.999931">
Lexical ambiguities have two origins: the
lexicon, and the guessing stages for unknown
tokens. However, all the ambiguities considered
in this study are strictly lexical, and so
translation phenomena (Tesniere 1959, and
Paroubek 1997) are not considered here.
</bodyText>
<subsectionHeader confidence="0.999581">
2.1 Medical lexicon
</subsectionHeader>
<bodyText confidence="0.999964933333333">
The medical lexicon is tailored to biomedical
texts, thus, with about 20000 lexemes, it covers
exhaustively ICD-10. The biomedical language
is not only a &apos;big&apos; sub language, as its
morphology is also more complex. This high
level of composition (at least compared to
regular French or English languages) concerns
about 10% of tokens within clinical patient
records; therefore the lexicon contains also
about 2000 affixes. For example, the token
iliojejunostomie is absent from the lexicon,
however, this type of token may be recognized
via its compounds (see Lovis and al., 1997, for
the so-called morphosemantemes): ileo, jejuno,
and stomie.
</bodyText>
<subsectionHeader confidence="0.992321">
2.2 Morphological analysis and medical
morphology
</subsectionHeader>
<bodyText confidence="0.999719904761905">
The morphological analysis associates every
surface fonn with a list of morpho-syntactic
features. When the surface form is not found in
the lexicon, it follows a two-step guessing
process: the first level (oraclel ) is a more
complex morphological analyzer, based on the
morphosemantemes, while the second level
guesser (orcale2) attempts to provides a set of
MS features looking at the longest ending (as
described in Chanod and Tapanainen, 1995).
The importance of these two levels is not clear
for POS tagging, but becomes manifest when
dealing with sense tagging. Let us consider three
examples of tokens absent from the lexicon:
allomorphiques, allomorphiquement (equivalent
to allomorphic and allomorphically in Eng.
remained ambiguous after disambiguation, the
residual ambiguity is therefore about 5.5%. In this
sample, and before disambiguation, the number of
ambiguous tokens was 150, which means an
ambiguity rate of 20%. Thus, even using the same
lexicon, the ambiguity rate seem higher for general
corpora than for domain-specific ones.
language) and allocution. In the first case, the
prefix allo and the suffix morphiques are listed
in the morphosemantemes database (MDB). In
the second case, morphiquement is not listed
within the MDB, but ment can be found in it, In
these two cases, therefore, oracle 1 is able to
provide both the MS and the WS information
associated. The latter example cannot be split
into any morphemes, as cution is absent from the
MDB. Thus, oraclesl is unable to recognize it,
and finally oracle2 will be applied and will
provide some MS features regarding exclusively
the endings. The major role given to oraclel and
the semantic features it provides is obvious for
IR purposes.
The final stage transforms some of the lexical
features returned by the morphological analysis
in a tag-like representation to be processed later
by the tagger.
</bodyText>
<subsectionHeader confidence="0.999836">
2.3 FIPSTAG tagger and lexicon
</subsectionHeader>
<bodyText confidence="0.999975956521739">
The FIPSTAG lexicon is a general French
lexicon, therefore it contains most well-formed
French words. The overall structure of the
lexicon is more or less stable, but the content is
regularly updated in order to improve the
coverage. Currently, the coverage is about
200000 words with around 30000 lexical items.
The lexicon is designed for deep parsing, so that,
together with classical morpho. syntactic
features, we can also find sub categorization of
verbs, semantic features, and some very specific
grammatical classes.
As the system is claimed to be general, it is
supposed to master efficiently any unknown
words: the lexical modules supply, in an
equiprobable way, all the possible lexical
categories (i.e. nouns, verbs, adjectives, and
adverbs), as other categories are considered to
be exhaustively listed in the lexicon.
Consequently, the guesser does not rely on any
morphological information, and only syntactic
principles are applied to choose the relevant
features.
</bodyText>
<sectionHeader confidence="0.904836" genericHeader="evaluation">
3. Results and comparison of ambiguities
</sectionHeader>
<table confidence="0.702212">
medical corpus general corpus
ambiguities 2532 (15.8%) 4657 (29.1%)
</table>
<tableCaption confidence="0.997965">
Table 3: ambiguity rates according to the corpus
</tableCaption>
<page confidence="0.771513">
16
</page>
<table confidence="0.998566307692308">
Amb. class Si. Fm. Fg. Ex. or BR
proc/v[ms] 0 0 1 lui
nc[msl/v[n] 0 0 1.3 etre
d[fs]/nc[fs] 0 0 2.3 une
v[12]/v[s03] 0.2 1.3 7 semble,
sp/v[12Fv[s0 0.2 0.2 1 entre, contre
prop[03]/cccs 0.2 0.3 1.7 s&apos;
nc [ms]/v[12] 0.3 0.4 1.3 controle,
/v[s03] groupe
r/v[12]/v[mp] 0.8 1 1.3 plus
d[ms]inc[ms] 0.8 1.6 2 son
d[bp]/proc 0.8 5.5 7 les
d[ms]/proc 0.9 7.1 8.3 le
cccs/nc[ms]/r 1 1 1 bien
nc[ms]/v[s03 1 1 1 fait
proc/prop[12] 1 1.7 1.6 nous
cccs/r 1 2.1 2.2 que
nc[msl/r 1.1 4.9 4.6 pas
nc[ms]/v[s03 1.2 5.3 4.5 est
nc[fs1/v[12] 1.3 2.6 2 sorte, mesure,
/v[s03] demande
proc/sp/cccs 1.6 7.5 4.6 en
d[bs]/proc 1.9 13.8 7.3 l&apos;
d[fs]/proc 2.1 14.1 6.8 la
a/nc 4.2 1.7 0.4 patient
a/nc/v3 5.0 1.5 0.3 patiente
</table>
<figureCaption confidence="0.8271698">
Tab. 4: Similarity measure for the most frequent
classes of ambiguity.
Note (tab. 4):
Column 1 gives the ambiguity class. Column 2
provides the ratio of similarity (maximum similarity
</figureCaption>
<bodyText confidence="0.999288046153847">
3 This class has only one representative within the
medical corpus, the word patient (feminine
patiente): An equivalent within the general corpus is
politique (in Eng. it means both political and
politics), but the former (0.5% of tokens) is ten times
more frequent than the latter (0.05%). The frequency
of the word politique is consistent with the frequency
lists distributed by Jean Veronis (http:/lwww.up.univ-
mrs-fil-veronis), which were calculated on a one
million words corpus from Le Monde Diplomatique
(1987-1997). It should noted that this result questions
the concepts of `unrestricted corpora&apos; and
`representativeness&apos; (Biber, 1994), as in fact it often
refers to a mix of politics and newspaper topics!
= 1, minimal similarity = 0 and 5) between the
frequency of the considered ambiguity in medical
(Fm.) and general texts (Fg.). Columns 3 and 4 (resp.
Fm. et Fg.) indicate the frequency of the ambiguity
respectively in the medical texts and in the general
texts. Column 5 provides some examples or the best
representative (BR) of the ambiguity class, i.e. when
one lexeme represents at least 80% of the class.
List of abbreviations for the syntactic categories:
proc, clitic pronoun; v, verb; nc, common noun; d,
determiner; sp, preposition; prop, personal pronoun;
cees, conjunction; q, numeral. List of abbreviations
for the morpho-syntactic features and sub
categorizations: ms, masculine singular; n, verbal
infinitive form; fs, feminine singular; bs, masculine
or feminine singular; 12, first and second person
singular or plural; s03, third person singular; p0.3,
plural third person.
When possible this tagset follows the MULTEXT
(Ide and Veronis 1994) morpho-syntactic description,
modified within the GRACE action. But we must
notice that the original MULTEXT description and
the GRACE version (Paroubek and al. 1998, Rajman
and al. 1997) for the French language have not been
foreseen for annotating morphemes.
Previously, while attempting to assess the
performance of our tools, only a sample of the
ad hoc corpus we built up was used, whereas the
following studies on the ambiguities will be
carried out on the whole corpus. Like in the
validation task, the lexical ambiguities are based
on the morphological analysis of each tagger,
expressed in the MCT. First of all, table 3 gives
the general ambiguity rate in each corpora: it
clearly states that the total ambiguity rate in
general corpora is about twice as big as in
medical texts.
A more precise table (tab. 4) provides at least
two remarkable results. First, it shows that in the
general corpus, less than a dozen words are
responsible for half of the global ambiguity rate.
These results must be compared to (Chanod and
Tapainen, 1995), who situate this number
around 16, while about six words generate the
same level of ambiguity in the medical corpus!
This table also shows that the distribution of the
ambiguity type is also domain dependant. Thus,
the ambiguity d[fs]-[bs]/proc is twice more
frequent in medical texts, and the ambiguity
represented by the tokens patient/patiente
(masculine and feminine form of patient; which
</bodyText>
<page confidence="0.997819">
17
</page>
<bodyText confidence="0.999912095238095">
may be a noun, an adjective, or some form of
verb) is five times more frequent. On the
contrary, some classes of ambiguity are simply
absent or very rare in the medical domain (as for
example v[12]/v[s03], or nc[msi/v[n]).
Finally, in table 5, we give the distribution of the
most frequent syntactic categories according to
the corpus. In this table, a particularly interesting
result concerns the imbalance between
categories of noun phrases (determiner, noun,
adjective...) and categories of verb phrases
(verb, adverb...); the former being much more
frequent in medical texts, whereas the latter are
more frequent in general texts. Here we verify a
well-known stylistic manner: medical reports are
often written in a telegraphic style, where the
verb is frequently implicit. As a corollary,
nozninalization phenomena are very frequent.
Simple or complex numeral tokens (date, time,
expressions with digits and measure symbols)
are also much more frequent.
</bodyText>
<table confidence="0.997846166666667">
General Medical
r 505 276 v[n]
v[n] 721 301 v[12]; v[s03];
v[p03]
cccs 765 550 q
v[12]; v[s03]; 837 587 cccs
v[p03]
sp 1356 1283 a
d 1659 1529 f
nc 1707 1784 d
f 2179 2138 sp
3472 nc
</table>
<tableCaption confidence="0.7771205">
Tab. 5: Distribution of the most frequent morpho-
syntactic categories according to the domain.
</tableCaption>
<bodyText confidence="0.451277">
Note (tab. 5) :f refers to the punctuations.
</bodyText>
<sectionHeader confidence="0.605233" genericHeader="discussions">
4. Discussion and conclusion
</sectionHeader>
<bodyText confidence="0.999917172413793">
We have showed that the lexical ambiguity in
medical texts (considered as a paradigm of any
particular domain) is different to the one in
general texts, both at a purely quantitative level,
and at a deeper qualitative level. Another result
concerns the difference in the distribution of the
POS categories. All these particularities must be
added to others: lexical, morphological, spelling
and grammar errors. This last point has been
rarely studied, but errors in documents, which
are not intended for publication, may be quite
impressive (the spelling error rate in our medical
corpus was about 2%, i.e. up to one error every
five sentences!). Finally, our conclusion is of
two types: First, concerning the study, we
showed that the use and comparison of taggers
tailored for different corpora, supports a measure
of the difference between these corpora; second,
at a more methodological level, if it seems that
the syntax may be -ceteris paribus- regarded as a
domain-independent field (at least at a
computational level, cf. Wehrli 1995), we
argued that natural language processing
applications require domain-adaptable tools.
Therefore, the use of NLP tools by other
research fields must be very carefully related to
the design of these tools. We suggest that
adaptability should be explored in at least three
directions&apos;:
</bodyText>
<listItem confidence="0.7134514">
1. Systems must allow lexical items to be
added (custom lexicon) and removed from
the lexicon; therefore access to the main
lexicon must be available — at least
negatively.
2. Systems must be optionally applied with a
specialised morphological analyser module.
3. MS description (tagset) should be
parametrable, and this should include the
ability to provide a mapping table.
</listItem>
<sectionHeader confidence="0.976422" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.793567">
This study was supported by the FNRS (Swiss
National Science Foundation).
</bodyText>
<sectionHeader confidence="0.994527" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.969945230769231">
Douglas Biber (1994) Representativeness in
Corpus Design. Zampolli, Antonio, Nicoletta
Calzolari and Martha Palmer (Eds.). 377-407.
Douglas Biber, Susan Conrad, Randi Reppen
(1998) Corpus Linguistics: Investigating
Language Structure and Use. Cambridge
University Press.
Pierrette Bouillon, Patrick Ruch, Robert Baud,
Gilbert Robert (2000) Indexing by statistical
tagging. In proceedings of the 7th JADT&apos;2000.
Vol. 1, pp. 35-42. Lausanne. Switzerland.
4A future version of FIPSTAG should integrate some
of these specifications.
</reference>
<page confidence="0.994678">
18
</page>
<reference confidence="0.99386243877551">
Jean-Pierre Chanod, Pasi Tapanainen (1995)
Tagging French: comparing a statistical and a
constraint-based method. In ACL, Ed., 7rn
Conference of the European Chapter of the
Association for Computational Linguistics
(EACL&apos;95). pp. 149-156. Dublin.
Helka Folch, Serge Heiden, Benoit Habert,
Serge Fleury, Gabriel Illouz, Pierre Lafon,
Julien Nioche, Sophie Prevost (2000) TypTex:
Inductive Typological Text Classification by
Multivariate Statistical Analysis for NLP
Systems Tuning/Evaluation. hi Proceedings of
the 3`d International Conference on Language
Ressources and Evaluation (LREC&apos;2000),
Athenes, Greece.
William R. Hersh , Price S., Kraemer D., Chan
B., Sacherek L, Olson D (1998a) A Large-
Scale Comparison of Boolean vs. Natural
Language Searching for the TREC-7
Interactive Track. TREC 1998, pp. 429-438. -
William R. Hersh (1998b) Information
Retrieval at the MILLEMUM. In R MASY,
Ed., American Medical Informatics
Association Annual Symposium (AMIA&apos;1998,
ex-SCAMC). Orlando.
Nancy Ide and Jean Veronis (1994) MULTEXT:
Multilingual Text Tools and Corpora. In
Proceedings of the 15th International
Conference on Computational Linguistics
(COLING-94), Kyoto, Japan.
Adam Kilgariff (1996) Which words are
particularly characteristic of a text? A survey
of statistical approaches. ITRI Technical
report 96-08.
(http://www.itri.brighton.ac.uk/—Adam.Kilgarr
iff/publications.html)
Christian Lovis, Robert Baud, Pierre-André
Michel, Jean-Raoul Scherrer (1997)
Morphosemantems decomposition and
semantic representation to allow fast and
efficient natural language recognition of
medical expressions. hi R MASY, ed.,
American Medical Informatics Association
Annual Symposium (AMIA&apos;1997, ex-
SCAMC). Washington.
A. Nazarenko, Pierre Zweigenbaum, Jean
Bouaud (1997) Corpus-based identification
and Refinement of Semantic Classes. In R
MASY, ed., American Medical Informatics
Association Annual Symposium (AMIA&apos;1997,
ex-SCAMC), pp. 585-589. Washington.
Patrick Paroubek, Gilles Adda, Joseph Mariani,
Josette Lecomte, Martin Rajman (1998) The
GRACE French Part-Of-Speech Tagging
Evaluation Task, In Proceedings of the 1&apos;
International Conference on Language
Ressources and Evaluation (LREC), Granada,
Spain.
Martin Rajman, Patrick Paroubek, Josette
Lecomte (1996) Format de description
lexicale pour le francais — partie 2:
Description moipho-syntaxique, rapport
GRACE GTR-3-2-1. (http:
//www.limsar/TLP/grace/www/gracdoc.html)
Patrick Ruch, Pierrette Bouillon, Gilbert Robert,
Robert Baud (2000) Minimal Commitment
and Full Lexical Disambiguation: Balancing
Rules and Hidden Markov Models. In
Proceedings of the 5th CoNLL Conference
(ACL-SIGNLL). Lisbon. Portugal.
Patrick Ruch, Judith Wagner, Pierrette Bouillon,
Robert Baud (1999) Tag-like semantics for
medical document indexing. In N. M.
LORENZI, ed., American Medical
Informatics Association Annual Symposium
(AMIA&apos;1999, ex-SCAMC), pp. 137-141.
Washington.
Gerald Salton (1988) Term-weighting
approaches in automatic text retrieval.
McGraw.Hill. Vol. 24. New-York
Max Silberztein (1997) The Lexical Analysis of
Natural Languages, In Finite-state Language
Processing , Yves Shabes and Emmanuel
Roche ed., MIT Press, pp. 175-203.
Cambridge.
Karen Spark-Jones (1999) What Is The Role for
NLP in Text Retrieval. Strzalkowslci, ed.,
Natural Language Information Retrieval,
Kluwer Publishers, pp.1-25
Lucien Tesniere (1959) Elements de syntaxe
structurale. Klincksieck. Paris.
Eric Wehrli (1992) The Interactive Parsing
System, hi ACL, ed., Proceedings of
COLING-92. 870-4. Nantes. France.
Eric Wehrli, Robin Clark (1995) Natural
Language Processing: Lexicon and
Semantics, Methods of Information in
Medicine, Vol. 34, p. 68-74.
</reference>
<page confidence="0.999331">
19
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.862673">
<title confidence="0.997714">Comparing corpora and lexical ambiguity</title>
<author confidence="0.999843">Patrick Ruch Arnaud Gaudinat</author>
<affiliation confidence="0.969390333333333">Medical Informatics Divis:ion LATL Geneva University Hospital University of Geneva Switzerland Switzerland</affiliation>
<abstract confidence="0.997304105263158">ruch@dim.hcuge.ch gaudinat@latl.unige.ch In this paper we compare two types of corpus, focusing on the lexical ambiguity of each of them. The first corpus consists mainly of newspaper articles and literature excerpts, while the second belongs to the medical domain. To conduct the study, we have used two different disambiguation tools. However, first of all, we must verify the performance of each system in its respective application domain. We then use these systems in order to assess and compare both the general ambiguity rate and the particularities of each domain. Quantitative results show that medical documents are lexically less ambiguous than unrestricted documents. Our conclusions show the importance of the application area in the design of NLP tools.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Douglas Biber</author>
</authors>
<title>Representativeness in Corpus Design.</title>
<date>1994</date>
<journal>Zampolli, Antonio, Nicoletta Calzolari and Martha Palmer (Eds.).</journal>
<pages>377--407</pages>
<contexts>
<context position="13089" citStr="Biber, 1994" startWordPosition="2092" endWordPosition="2093">sentative within the medical corpus, the word patient (feminine patiente): An equivalent within the general corpus is politique (in Eng. it means both political and politics), but the former (0.5% of tokens) is ten times more frequent than the latter (0.05%). The frequency of the word politique is consistent with the frequency lists distributed by Jean Veronis (http:/lwww.up.univmrs-fil-veronis), which were calculated on a one million words corpus from Le Monde Diplomatique (1987-1997). It should noted that this result questions the concepts of `unrestricted corpora&apos; and `representativeness&apos; (Biber, 1994), as in fact it often refers to a mix of politics and newspaper topics! = 1, minimal similarity = 0 and 5) between the frequency of the considered ambiguity in medical (Fm.) and general texts (Fg.). Columns 3 and 4 (resp. Fm. et Fg.) indicate the frequency of the ambiguity respectively in the medical texts and in the general texts. Column 5 provides some examples or the best representative (BR) of the ambiguity class, i.e. when one lexeme represents at least 80% of the class. List of abbreviations for the syntactic categories: proc, clitic pronoun; v, verb; nc, common noun; d, determiner; sp, </context>
</contexts>
<marker>Biber, 1994</marker>
<rawString>Douglas Biber (1994) Representativeness in Corpus Design. Zampolli, Antonio, Nicoletta Calzolari and Martha Palmer (Eds.). 377-407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas Biber</author>
<author>Susan Conrad</author>
</authors>
<title>Randi Reppen</title>
<date>1998</date>
<publisher>Cambridge University Press.</publisher>
<marker>Biber, Conrad, 1998</marker>
<rawString>Douglas Biber, Susan Conrad, Randi Reppen (1998) Corpus Linguistics: Investigating Language Structure and Use. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierrette Bouillon</author>
<author>Patrick Ruch</author>
<author>Robert Baud</author>
<author>Gilbert Robert</author>
</authors>
<title>Indexing by statistical tagging.</title>
<date>2000</date>
<booktitle>In proceedings of the 7th JADT&apos;2000.</booktitle>
<volume>1</volume>
<pages>35--42</pages>
<location>Lausanne.</location>
<marker>Bouillon, Ruch, Baud, Robert, 2000</marker>
<rawString>Pierrette Bouillon, Patrick Ruch, Robert Baud, Gilbert Robert (2000) Indexing by statistical tagging. In proceedings of the 7th JADT&apos;2000. Vol. 1, pp. 35-42. Lausanne. Switzerland. 4A future version of FIPSTAG should integrate some of these specifications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean-Pierre Chanod</author>
</authors>
<title>Pasi Tapanainen</title>
<date>1995</date>
<booktitle>In ACL, Ed., 7rn Conference of the European Chapter of the Association for Computational Linguistics (EACL&apos;95).</booktitle>
<pages>149--156</pages>
<location>Dublin.</location>
<marker>Chanod, 1995</marker>
<rawString>Jean-Pierre Chanod, Pasi Tapanainen (1995) Tagging French: comparing a statistical and a constraint-based method. In ACL, Ed., 7rn Conference of the European Chapter of the Association for Computational Linguistics (EACL&apos;95). pp. 149-156. Dublin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helka Folch</author>
<author>Serge Heiden</author>
<author>Benoit Habert</author>
<author>Serge Fleury</author>
<author>Gabriel Illouz</author>
<author>Pierre Lafon</author>
<author>Julien Nioche</author>
</authors>
<title>Sophie Prevost</title>
<date>2000</date>
<booktitle>hi Proceedings of the 3`d International Conference on Language Ressources and Evaluation (LREC&apos;2000), Athenes,</booktitle>
<marker>Folch, Heiden, Habert, Fleury, Illouz, Lafon, Nioche, 2000</marker>
<rawString>Helka Folch, Serge Heiden, Benoit Habert, Serge Fleury, Gabriel Illouz, Pierre Lafon, Julien Nioche, Sophie Prevost (2000) TypTex: Inductive Typological Text Classification by Multivariate Statistical Analysis for NLP Systems Tuning/Evaluation. hi Proceedings of the 3`d International Conference on Language Ressources and Evaluation (LREC&apos;2000), Athenes, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Price</author>
<author>D Kraemer</author>
<author>B Chan</author>
<author>L Sacherek</author>
<author>D Olson</author>
</authors>
<title>A LargeScale Comparison of Boolean vs. Natural Language Searching for the TREC-7 Interactive Track. TREC</title>
<date>1998</date>
<pages>429--438</pages>
<marker>Price, Kraemer, Chan, Sacherek, Olson, 1998</marker>
<rawString>William R. Hersh , Price S., Kraemer D., Chan B., Sacherek L, Olson D (1998a) A LargeScale Comparison of Boolean vs. Natural Language Searching for the TREC-7 Interactive Track. TREC 1998, pp. 429-438. -</rawString>
</citation>
<citation valid="false">
<authors>
<author>R William</author>
</authors>
<title>Hersh (1998b) Information Retrieval at the MILLEMUM.</title>
<booktitle>In R MASY, Ed., American Medical Informatics Association Annual Symposium (AMIA&apos;1998,</booktitle>
<location>ex-SCAMC). Orlando.</location>
<marker>William, </marker>
<rawString>William R. Hersh (1998b) Information Retrieval at the MILLEMUM. In R MASY, Ed., American Medical Informatics Association Annual Symposium (AMIA&apos;1998, ex-SCAMC). Orlando.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
<author>Jean Veronis</author>
</authors>
<title>MULTEXT: Multilingual Text Tools and Corpora.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics (COLING-94),</booktitle>
<location>Kyoto, Japan.</location>
<contexts>
<context position="14119" citStr="Ide and Veronis 1994" startWordPosition="2253" endWordPosition="2256">guity class, i.e. when one lexeme represents at least 80% of the class. List of abbreviations for the syntactic categories: proc, clitic pronoun; v, verb; nc, common noun; d, determiner; sp, preposition; prop, personal pronoun; cees, conjunction; q, numeral. List of abbreviations for the morpho-syntactic features and sub categorizations: ms, masculine singular; n, verbal infinitive form; fs, feminine singular; bs, masculine or feminine singular; 12, first and second person singular or plural; s03, third person singular; p0.3, plural third person. When possible this tagset follows the MULTEXT (Ide and Veronis 1994) morpho-syntactic description, modified within the GRACE action. But we must notice that the original MULTEXT description and the GRACE version (Paroubek and al. 1998, Rajman and al. 1997) for the French language have not been foreseen for annotating morphemes. Previously, while attempting to assess the performance of our tools, only a sample of the ad hoc corpus we built up was used, whereas the following studies on the ambiguities will be carried out on the whole corpus. Like in the validation task, the lexical ambiguities are based on the morphological analysis of each tagger, expressed in </context>
</contexts>
<marker>Ide, Veronis, 1994</marker>
<rawString>Nancy Ide and Jean Veronis (1994) MULTEXT: Multilingual Text Tools and Corpora. In Proceedings of the 15th International Conference on Computational Linguistics (COLING-94), Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgariff</author>
</authors>
<title>Which words are particularly characteristic of a text? A survey of statistical approaches.</title>
<date>1996</date>
<tech>ITRI Technical report 96-08. (http://www.itri.brighton.ac.uk/—Adam.Kilgarr iff/publications.html)</tech>
<contexts>
<context position="3517" citStr="Kilgariff, 1996" startWordPosition="539" endWordPosition="540">parative studies, dedicated to corpora, have addressed the problem by applying metrics on words entities or word pieces (as in studies working with nI We do not claim to be pioneer in the domain, as others authors (Biber 1998, Folch and al., 2000) are exploring similar metrics. However, it is interesting to notice that for these authors the adaptation of the NLP tools has rarely been questioned in a technical point-of view, and in order to feed back the design of NLP systems. 14 gram strings), or on special sets of words (the indexing terms, see Salton, 1988) as in the space-vector model (see Kilgariff, 1996, for a survey of these methods), whereas the present paper attempts to compare corpora at a morphosyntactic (MS) level. 1 Validating each tagger into its respective domain In order to conduct the comparative study, we used two different morphological analysers; each one has a specific lexicon tailored for its application field. The first system is specialised for tagging medical texts (Ruch and al., 2000), while the second is a general parser (based on FIPS, cf. Wehrli, 1992). For comparing lexical ambiguities on a minimal common base, the output of each morphological analyser is first mapped</context>
</contexts>
<marker>Kilgariff, 1996</marker>
<rawString>Adam Kilgariff (1996) Which words are particularly characteristic of a text? A survey of statistical approaches. ITRI Technical report 96-08. (http://www.itri.brighton.ac.uk/—Adam.Kilgarr iff/publications.html)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Lovis</author>
<author>Robert Baud</author>
<author>Pierre-André Michel</author>
</authors>
<title>Jean-Raoul Scherrer</title>
<date>1997</date>
<booktitle>American Medical Informatics Association Annual Symposium (AMIA&apos;1997, exSCAMC).</booktitle>
<editor>hi R MASY, ed.,</editor>
<location>Washington.</location>
<marker>Lovis, Baud, Michel, 1997</marker>
<rawString>Christian Lovis, Robert Baud, Pierre-André Michel, Jean-Raoul Scherrer (1997) Morphosemantems decomposition and semantic representation to allow fast and efficient natural language recognition of medical expressions. hi R MASY, ed., American Medical Informatics Association Annual Symposium (AMIA&apos;1997, exSCAMC). Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Nazarenko</author>
</authors>
<title>Pierre Zweigenbaum, Jean Bouaud</title>
<date>1997</date>
<booktitle>American Medical Informatics Association Annual Symposium (AMIA&apos;1997, ex-SCAMC),</booktitle>
<pages>585--589</pages>
<editor>R MASY, ed.,</editor>
<location>Washington.</location>
<contexts>
<context position="1971" citStr="Nazarenko, 1997" startWordPosition="288" endWordPosition="289">lication area- must be taken into account while developing such NLP tools. Let us recall two major problems while retrieving documents with NLP engines (Salton, 1988): 1-Expansion: the user is generally as interested in retrieving documents with exactly the same words, as in retrieving documents with semantically related words (synonyms, generics, specifics...). Thus, a query based on the word liver, should be able to retrieve documents containing words such as hepatic. This expansion process is usually thesaurus-based. The thesaurus can be built manually or automatically (as, for example, in Nazarenko, 1997). 2-Disambiguation: a search based on tokens may retrieve irrelevant documents since tokens are often lexically ambiguous. Thus, face can refer to a body part, as a noun, or an action, as a verb. Finally, this latter problem may be split into two sub problems. The disambiguation task can be based on parts-of-speech (POS) or word-sense (WS) information, but the chronological relation is still a discussion within the community. Although, the target of our work (Ruch and al., 1999, Bouillon and al., 2000) is a fme-grained semantic disambiguation of medical texts for lR purposes, we believe that t</context>
</contexts>
<marker>Nazarenko, 1997</marker>
<rawString>A. Nazarenko, Pierre Zweigenbaum, Jean Bouaud (1997) Corpus-based identification and Refinement of Semantic Classes. In R MASY, ed., American Medical Informatics Association Annual Symposium (AMIA&apos;1997, ex-SCAMC), pp. 585-589. Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Paroubek</author>
<author>Gilles Adda</author>
<author>Joseph Mariani</author>
<author>Josette Lecomte</author>
</authors>
<title>The GRACE French Part-Of-Speech Tagging Evaluation Task,</title>
<date>1998</date>
<booktitle>In Proceedings of the 1&apos; International Conference on Language Ressources and Evaluation (LREC),</booktitle>
<location>Martin Rajman</location>
<marker>Paroubek, Adda, Mariani, Lecomte, 1998</marker>
<rawString>Patrick Paroubek, Gilles Adda, Joseph Mariani, Josette Lecomte, Martin Rajman (1998) The GRACE French Part-Of-Speech Tagging Evaluation Task, In Proceedings of the 1&apos; International Conference on Language Ressources and Evaluation (LREC), Granada, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Rajman</author>
</authors>
<title>Patrick Paroubek, Josette Lecomte</title>
<date>1996</date>
<marker>Rajman, 1996</marker>
<rawString>Martin Rajman, Patrick Paroubek, Josette Lecomte (1996) Format de description lexicale pour le francais — partie 2: Description moipho-syntaxique, rapport GRACE GTR-3-2-1. (http: //www.limsar/TLP/grace/www/gracdoc.html)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Ruch</author>
<author>Pierrette Bouillon</author>
<author>Gilbert Robert</author>
</authors>
<title>Minimal Commitment and Full Lexical Disambiguation: Balancing Rules and Hidden Markov Models.</title>
<date>2000</date>
<booktitle>In Proceedings of the 5th CoNLL Conference (ACL-SIGNLL).</booktitle>
<location>Robert Baud</location>
<marker>Ruch, Bouillon, Robert, 2000</marker>
<rawString>Patrick Ruch, Pierrette Bouillon, Gilbert Robert, Robert Baud (2000) Minimal Commitment and Full Lexical Disambiguation: Balancing Rules and Hidden Markov Models. In Proceedings of the 5th CoNLL Conference (ACL-SIGNLL). Lisbon. Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Ruch</author>
<author>Judith Wagner</author>
</authors>
<title>Tag-like semantics for medical document indexing.</title>
<date>1999</date>
<booktitle>American Medical Informatics Association Annual Symposium (AMIA&apos;1999, ex-SCAMC),</booktitle>
<pages>137--141</pages>
<editor>In N. M. LORENZI, ed.,</editor>
<location>Pierrette Bouillon, Robert Baud</location>
<marker>Ruch, Wagner, 1999</marker>
<rawString>Patrick Ruch, Judith Wagner, Pierrette Bouillon, Robert Baud (1999) Tag-like semantics for medical document indexing. In N. M. LORENZI, ed., American Medical Informatics Association Annual Symposium (AMIA&apos;1999, ex-SCAMC), pp. 137-141. Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Salton</author>
</authors>
<title>Term-weighting approaches in automatic text retrieval.</title>
<date>1988</date>
<journal>McGraw.Hill.</journal>
<volume>24</volume>
<publisher>New-York</publisher>
<contexts>
<context position="1521" citStr="Salton, 1988" startWordPosition="223" endWordPosition="224">application area in the design of NLP tools. Introduction and background Although some large-scale evaluations carried out on unrestricted texts (Hersh 1998a, SparkJones 1999), and even on medical documents (Hersh 1998b), conclude in a quite critical way about using NLP tools for information retrieval, we believe that such tools are likely to solve some lexical ambiguity issues. We also believe that some special settings -particular to the application area- must be taken into account while developing such NLP tools. Let us recall two major problems while retrieving documents with NLP engines (Salton, 1988): 1-Expansion: the user is generally as interested in retrieving documents with exactly the same words, as in retrieving documents with semantically related words (synonyms, generics, specifics...). Thus, a query based on the word liver, should be able to retrieve documents containing words such as hepatic. This expansion process is usually thesaurus-based. The thesaurus can be built manually or automatically (as, for example, in Nazarenko, 1997). 2-Disambiguation: a search based on tokens may retrieve irrelevant documents since tokens are often lexically ambiguous. Thus, face can refer to a b</context>
<context position="3467" citStr="Salton, 1988" startWordPosition="531" endWordPosition="532">, the method is quite original&apos;. Most of the comparative studies, dedicated to corpora, have addressed the problem by applying metrics on words entities or word pieces (as in studies working with nI We do not claim to be pioneer in the domain, as others authors (Biber 1998, Folch and al., 2000) are exploring similar metrics. However, it is interesting to notice that for these authors the adaptation of the NLP tools has rarely been questioned in a technical point-of view, and in order to feed back the design of NLP systems. 14 gram strings), or on special sets of words (the indexing terms, see Salton, 1988) as in the space-vector model (see Kilgariff, 1996, for a survey of these methods), whereas the present paper attempts to compare corpora at a morphosyntactic (MS) level. 1 Validating each tagger into its respective domain In order to conduct the comparative study, we used two different morphological analysers; each one has a specific lexicon tailored for its application field. The first system is specialised for tagging medical texts (Ruch and al., 2000), while the second is a general parser (based on FIPS, cf. Wehrli, 1992). For comparing lexical ambiguities on a minimal common base, the out</context>
</contexts>
<marker>Salton, 1988</marker>
<rawString>Gerald Salton (1988) Term-weighting approaches in automatic text retrieval. McGraw.Hill. Vol. 24. New-York</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max Silberztein</author>
</authors>
<title>The Lexical Analysis of Natural Languages,</title>
<date>1997</date>
<booktitle>In Finite-state Language Processing , Yves Shabes and Emmanuel Roche ed.,</booktitle>
<pages>175--203</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="6719" citStr="Silberztein 1997" startWordPosition="1069" endWordPosition="1070">ch is considered as one lexical item, tagged as an adverb. For the lexical tagger we had to modify the &apos;word&apos; segmentation in the other direction (for tagging items smaller than &apos;words&apos;), as morphemes were also tagged. Table 1 gives the results for FIPSTAG, and table 2 gives the results for the medical tagger. In the case of the medical tagger, together with the error rate and the success rate, we provide results of the residual ambiguity rate: the basic idea is that the system does not attempt to solve what it is not likely to solve well (cf. Ruch and al. 2000, a similar idea can be found in Silberztein 1997). 1 Correct tag 3959(99.3%) 1 Incorrect tag 28 (0.7%) Tab. 1: Evaluation of FIPSTAG 1 Correct tag 3962(98.5%) 1 Incorrect tag 12(0.4%) 2 or more tags, at least 1 is 39(1.0%) correct 2 or more tags, 0 correct 3 (0.1%) Tab. 2: Evaluation of the medical tagger A comparison of the tagging scores (99.3 vs. 98.5) confirms that both systems behave in an equivalent way in their respective application area2. 2 Out of curiosity, we ran each tagger on a small sample of the other domain. The tests were made without any adaptation. FIPSTAG made 27 errors in a medical sample of 849 tokens, i.e. an error rat</context>
</contexts>
<marker>Silberztein, 1997</marker>
<rawString>Max Silberztein (1997) The Lexical Analysis of Natural Languages, In Finite-state Language Processing , Yves Shabes and Emmanuel Roche ed., MIT Press, pp. 175-203. Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Spark-Jones</author>
</authors>
<title>What Is The Role for NLP</title>
<date>1999</date>
<booktitle>Natural Language Information Retrieval,</booktitle>
<pages>1--25</pages>
<editor>in Text Retrieval. Strzalkowslci, ed.,</editor>
<publisher>Kluwer Publishers,</publisher>
<marker>Spark-Jones, 1999</marker>
<rawString>Karen Spark-Jones (1999) What Is The Role for NLP in Text Retrieval. Strzalkowslci, ed., Natural Language Information Retrieval, Kluwer Publishers, pp.1-25</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lucien Tesniere</author>
</authors>
<title>Elements de syntaxe structurale.</title>
<date>1959</date>
<location>Klincksieck. Paris.</location>
<contexts>
<context position="7745" citStr="Tesniere 1959" startWordPosition="1246" endWordPosition="1247">uriosity, we ran each tagger on a small sample of the other domain. The tests were made without any adaptation. FIPSTAG made 27 errors in a medical sample of 849 tokens, i.e. an error rate of 3.2%. The medical tagger made 18 errors in a general sample of 747 tokens, which means an error rate of 2.4%. In the case of the medical tagger, 41 tokens 15 2 Morphological analysers, lexicons and guessers Lexical ambiguities have two origins: the lexicon, and the guessing stages for unknown tokens. However, all the ambiguities considered in this study are strictly lexical, and so translation phenomena (Tesniere 1959, and Paroubek 1997) are not considered here. 2.1 Medical lexicon The medical lexicon is tailored to biomedical texts, thus, with about 20000 lexemes, it covers exhaustively ICD-10. The biomedical language is not only a &apos;big&apos; sub language, as its morphology is also more complex. This high level of composition (at least compared to regular French or English languages) concerns about 10% of tokens within clinical patient records; therefore the lexicon contains also about 2000 affixes. For example, the token iliojejunostomie is absent from the lexicon, however, this type of token may be recognize</context>
</contexts>
<marker>Tesniere, 1959</marker>
<rawString>Lucien Tesniere (1959) Elements de syntaxe structurale. Klincksieck. Paris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Wehrli</author>
</authors>
<title>The Interactive Parsing System,</title>
<date>1992</date>
<booktitle>Proceedings of COLING-92.</booktitle>
<pages>870--4</pages>
<editor>hi ACL, ed.,</editor>
<location>Nantes. France.</location>
<contexts>
<context position="3998" citStr="Wehrli, 1992" startWordPosition="617" endWordPosition="618"> gram strings), or on special sets of words (the indexing terms, see Salton, 1988) as in the space-vector model (see Kilgariff, 1996, for a survey of these methods), whereas the present paper attempts to compare corpora at a morphosyntactic (MS) level. 1 Validating each tagger into its respective domain In order to conduct the comparative study, we used two different morphological analysers; each one has a specific lexicon tailored for its application field. The first system is specialised for tagging medical texts (Ruch and al., 2000), while the second is a general parser (based on FIPS, cf. Wehrli, 1992). For comparing lexical ambiguities on a minimal common base, the output of each morphological analyser is first mapped into its respective tagset (more than 300 fine-grained tags for FIPSTAG, and about 80 for the morpheme-based medical tagger). The tagsets are then converted into a subset of the medical tagger. Finally, about 50 different items constitute this minimal common tagset (MCT), which will serve for comparing both corpora. We collected two different sets of documents to be tagged at a lexical level via the predefined MCT: this step provides a set of tags to every token. This set of </context>
</contexts>
<marker>Wehrli, 1992</marker>
<rawString>Eric Wehrli (1992) The Interactive Parsing System, hi ACL, ed., Proceedings of COLING-92. 870-4. Nantes. France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Wehrli</author>
</authors>
<title>Robin Clark</title>
<date>1995</date>
<journal>Methods of Information in Medicine,</journal>
<volume>34</volume>
<pages>68--74</pages>
<contexts>
<context position="17917" citStr="Wehrli 1995" startWordPosition="2873" endWordPosition="2874"> been rarely studied, but errors in documents, which are not intended for publication, may be quite impressive (the spelling error rate in our medical corpus was about 2%, i.e. up to one error every five sentences!). Finally, our conclusion is of two types: First, concerning the study, we showed that the use and comparison of taggers tailored for different corpora, supports a measure of the difference between these corpora; second, at a more methodological level, if it seems that the syntax may be -ceteris paribus- regarded as a domain-independent field (at least at a computational level, cf. Wehrli 1995), we argued that natural language processing applications require domain-adaptable tools. Therefore, the use of NLP tools by other research fields must be very carefully related to the design of these tools. We suggest that adaptability should be explored in at least three directions&apos;: 1. Systems must allow lexical items to be added (custom lexicon) and removed from the lexicon; therefore access to the main lexicon must be available — at least negatively. 2. Systems must be optionally applied with a specialised morphological analyser module. 3. MS description (tagset) should be parametrable, a</context>
</contexts>
<marker>Wehrli, 1995</marker>
<rawString>Eric Wehrli, Robin Clark (1995) Natural Language Processing: Lexicon and Semantics, Methods of Information in Medicine, Vol. 34, p. 68-74.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>