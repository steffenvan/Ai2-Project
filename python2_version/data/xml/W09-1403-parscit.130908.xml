<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001555">
<title confidence="0.98663">
Event Extraction from Trimmed Dependency Graphs
</title>
<author confidence="0.998479">
Ekaterina Buyko, Erik Faessler, Joachim Wermter and Udo Hahn
</author>
<affiliation confidence="0.991053">
Jena University Language &amp; Information Engineering (JULIE) Lab
</affiliation>
<address confidence="0.6987215">
Friedrich-Schiller-Universit¨at Jena
F¨urstengraben 30, 07743 Jena, Germany
</address>
<email confidence="0.909056">
{ekaterina.buyko|erik.faessler|joachim.wermter|udo.hahn}@uni-jena.de
</email>
<sectionHeader confidence="0.993603" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998647882352941">
We describe the approach to event extrac-
tion which the JULIELab Team from FSU
Jena (Germany) pursued to solve Task 1 in
the “BioNLP’09 Shared Task on Event Ex-
traction”. We incorporate manually curated
dictionaries and machine learning method-
ologies to sort out associated event triggers
and arguments on trimmed dependency graph
structures. Trimming combines pruning ir-
relevant lexical material from a dependency
graph and decorating particularly relevant lex-
ical material from that graph with more ab-
stract conceptual class information. Given
that methodological framework, the JULIELab
Team scored on 2nd rank among 24 competing
teams, with 45.8% precision, 47.5% recall and
46.7% F1-score on all 3,182 events.
</bodyText>
<sectionHeader confidence="0.999131" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999772642857143">
Semantic forms of text analytics for the life sciences
have long been equivalent with named entity recog-
nition and interpretation, i.e., finding instances of se-
mantic classes such as proteins, diseases, or drugs.
For a couple of years, this focus has been comple-
mented by analytics dealing with relation extraction,
i.e., finding instances of relations which link one or
more (usually two) arguments, the latter being in-
stances of semantic classes, such as the interaction
between two proteins (PPIs).
PPI extraction is a complex task since cascades
of molecular events are involved which are hard to
sort out. Many different approaches have already
been tried – pattern-based ones (e.g., by Blaschke
</bodyText>
<page confidence="0.989538">
19
</page>
<bodyText confidence="0.950733">
et al. (1999), Hakenberg et al. (2005) or Huang et
al. (2004)), rule-based ones (e.g., by Yakushiji et al.
(2001), ˇSari´c et al. (2004) or Fundel et al. (2007)),
and machine learning-based ones (e.g., by Katrenko
and Adriaans (2006), Sætre et al. (2007) or Airola et
al. (2008)), yet without conclusive results.
In the following, we present our approach to solve
Task 1 within the “BioNLP’09 Shared Task on Event
Extraction”.1 Task 1 “Event detection and charac-
terization” required to determine the intended rela-
tion given a priori supplied protein annotations. Our
approach considers dependency graphs as the cen-
tral data structure on which various trimming oper-
ations are performed involving syntactic simplifica-
tion but also, even more important, semantic enrich-
ment by conceptual overlays. A description of the
component subtasks is provided in Section 2, while
the methodologies intended to solve each subtask
are discussed in Section 3. The system pipeline for
event extraction reflecting the task decomposition is
described in Section 4, while Section 5 provides the
evaluation results for our approach.
</bodyText>
<sectionHeader confidence="0.975561" genericHeader="method">
2 Event Extraction Task
</sectionHeader>
<bodyText confidence="0.997291">
Event extraction is a complex task that can be sub-
divided into a number of subtasks depending on
whether the focus is on the event itself or on the ar-
guments involved:
Event trigger identification deals with the large
variety of alternative verbalizations of the same
event type, i.e., whether the event is expressed in
</bodyText>
<footnote confidence="0.9916615">
1http://www-tsujii.is.s.u-tokyo.ac.jp/
GENIA/SharedTask/
</footnote>
<note confidence="0.99222">
Proceedings of the Workshop on BioNLP: Shared Task, pages 19–27,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999494810810811">
a verbal or in a nominalized form (e.g., “A is ex-
pressed” and “the expression of A” both refer to the
same event type, viz. expression(A)). Since the
same trigger may stand for more than one event type,
event trigger ambiguity has to be resolved as well.
Event trigger disambiguation selects the correct
event name from the set of alternative event triggers.
Event typing, finally, deals with the semantic
classification of a disambiguated event name and the
assignment to an event type category.2
Argument identification is concerned with find-
ing all necessary participants in an event, i.e., the
arguments of the relation.
Argument typing assigns the correct semantic
category (entity class) to each of the determined par-
ticipants in an event (which can be considered as in-
stances of that class).
Argument ordering assigns each identified par-
ticipant its functional role within the event, mostly
Agent (and Patient/Theme).
The sentence “Regulation ofjun and fos gene ex-
pression in human monocytes by the macrophage
colony-stimulating factor”, e.g., contains mentions
of two Gene Expression events with respective
THEME arguments “jun” and “fos”, triggered in the
text by the literal phrase “gene expression”.
Task 1 of the “BioNLP’09 Shared Task on Event
Extraction” was defined in such a way as to iden-
tify a proper relation (event) name and link it with
its type, plus one or more associated arguments de-
noting proteins. To focus on relation extraction only
no automatic named entity recognition and interpre-
tation had to be performed (subtask ‘argument typ-
ing’ from above); instead candidate proteins were
already pre-tagged. The complexity of Task 1 was
raised by the condition that not only proteins were
allowed to be arguments but also were events.
</bodyText>
<sectionHeader confidence="0.988915" genericHeader="method">
3 Event Extraction Solution
</sectionHeader>
<bodyText confidence="0.999928666666667">
Our event extraction approach is summarized in Fig-
ure 1 and consists of three major streams – first, the
detection of lexicalized event triggers (cf. Section
3.1), second, the trimming of dependency graphs
which involves pruning irrelevant and semantically
enriching relevant lexical material (cf. Section 3.2),
</bodyText>
<footnote confidence="0.9881925">
2In our approach, event trigger disambiguation already im-
plies event typing.
</footnote>
<figureCaption confidence="0.939366">
Figure 1: General Architecture of the Event Extraction
Solution of the JULIELab Team.
</figureCaption>
<bodyText confidence="0.999352466666666">
and, third, the identification of arguments for the
event under scrutiny (cf. Section 3.3). Event typ-
ing results from proper event trigger identification
(see Section 3.1.2), which is interlinked with the out-
come of the argument identification. We talk about
putative triggers because we consider, in a greedy
manner, all relevant lexical items (see Section 3.1.1)
as potential event triggers which might represent an
event. Only those event triggers that can eventually
be connected to arguments, finally, represent a true
event. To achieve this goal we preprocessed both the
original training and test data such that we enrich the
original training data with automatically predicted
event triggers in order to generate more negative ex-
amples for a more effective learning of true events.3
</bodyText>
<subsectionHeader confidence="0.999751">
3.1 Event Trigger Identification
</subsectionHeader>
<bodyText confidence="0.999672285714286">
Looking at the wide variety of potential lexicalized
triggers for an event, their lacking discriminative
power relative to individual event types and their
inherent potential for ambiguity,4 we decided on
a dictionary-based approach whose curation princi-
ples are described in Section 3.1.1. Our disambigua-
tion policy for the ambiguous lexicalized event trig-
</bodyText>
<footnote confidence="0.772567333333333">
3Although the training data contains cross-sentence event
descriptions, our approach to event extraction is restricted to
the sentence level only.
4Most of the triggers are neither specific for molecular event
descriptions, in general, nor for a special event type. “Induc-
tion”, e.g., occurs 417 times in the training data. In 162 of these
cases it acts as a trigger for Positive regulation, 6 times as a
trigger for Transcription, 8 instances trigger Gene expression,
while 241 occurrences do not trigger an event at all.
</footnote>
<figure confidence="0.998558888888889">
Event Detection
Argument Identification with
Ensemble of Classifiers
Post-processing
Pre-processing
Typing of Putative
Event Triggers
Trimming of
Dependency Graphs
</figure>
<page confidence="0.926006">
20
</page>
<bodyText confidence="0.9475945">
gers assembled in this suite of dictionaries, one per
event type, is discussed in Section 3.1.2.
</bodyText>
<subsectionHeader confidence="0.85975">
3.1.1 Manual Curation of the Dictionaries
</subsectionHeader>
<bodyText confidence="0.999922777777778">
We started collecting our dictionaries from the
original GENIA event corpus (Kim et al., 2008a).
The extracted event triggers were then automatically
lemmatized5 and the resulting lemmata were subse-
quently ranked by two students of biology according
to their predictive power to act as a trigger for a par-
ticular event type. This expert assessment led us to
four trigger groups (for each event type these groups
were determined separately):
</bodyText>
<listItem confidence="0.946913866666667">
(1) Triggers are important and discriminative for
a specific event type. This group contains event trig-
gers such as “upregulate” for Positive regulation.
(2) Triggers are important though not fully dis-
criminative for a particular event type; yet, this defi-
ciency can be overcome by other lexical cues within
the context of the same sentence. This group with in-
context disambiguators contains lexical items such
as “proteolyse” for Protein catabolism.
(3) Triggers are non-discriminative for an event
type and even cannot be disambiguated by linguistic
cues within the context of the same sentence. This
group contains lexical items such as “presence” for
Localization and Gene expression.
(4) Triggers are absolutely non-discriminative for
</listItem>
<bodyText confidence="0.9587255">
an event. This group holds general lexical triggers
such as “observe”, “demonstrate” or “function”.
The final dictionaries used for the detection of
putative event triggers are a union of the first two
groups. They were further extended by biologists
with additional lexical material of the first group.
The dictionaries thus became event type-specific –
they contain all morphological forms of the original
lemma, which were automatically generated using
the Specialist NLP Tools (2008 release).
We matched the entries from the final set of dic-
tionaries with the shared task data using the Ling-
pipe Dictionary Chunker.6 After the matching pro-
cess, some cleansing had to be done.7
</bodyText>
<footnote confidence="0.992127166666667">
5We used the lemmatizer from the Specialist NLP Tools
(http://lexsrv3.nlm.nih.gov/SPECIALIST/
index.html, 2008 release).
6http://alias-i.com/lingpipe/
7Event triggers were removed which (1) were found within
sentences without any protein annotations, (2) occurred within
</footnote>
<subsectionHeader confidence="0.878625">
3.1.2 Event Trigger Disambiguation
</subsectionHeader>
<bodyText confidence="0.990307590909091">
Preliminary experiments indicated that the dis-
ambiguation of event triggers might be beneficial
for the overall event extraction results since events
tend to be expressed via highly ambiguous triggers.
Therefore, we performed a disambiguation step pre-
ceding the extraction of any argument structures.
It is based on the importance of an event trig-
ger tz for a particular eventtype T as defined by
Imp(tTz ) := f(tTi T , where f (tT) is the frequency
Pi f (ti )
of the event trigger tz of the selected event type T
in a training corpus divided by the total amount of
all event triggers of the selected event type T in
that training corpus. The frequencies are measured
on stemmed event triggers. For example, Imp for
the trigger stem “depend” amounts to 0.013 for the
event type Positive regulation, while for the event
type Regulation it yields 0.036 . If a text span con-
tains several event triggers with the same span off-
set, the event trigger with max(Imp) is selected and
other putative triggers are discarded. The trigger
stem “depend” remains thus only for Regulation.
</bodyText>
<subsectionHeader confidence="0.999903">
3.2 Trimming Dependency Graphs
</subsectionHeader>
<bodyText confidence="0.999575363636364">
When we consider event (relation) extraction as a se-
mantic interpretation task, plain dependency graphs
as they result from deep syntactic parsing might not
be appropriate to directly extract semantic informa-
tion from. This is due to two reasons - they contain
a lot of apparently irrelevant lexical nodes (from the
semantic perspective of event extraction) and they
also contain much too specific lexical nodes that
might better be grouped and further enriched se-
mantically. Trimming dependency graphs for the
purposes of event extraction, therefore, amounts to
eliminate semantically irrelevant and to semantically
enrich relevant lexical nodes (i.e., overlay with con-
cepts). This way, we influence the final representa-
tion for the machine learners we employ (in terms of
features or kernel-based representations) — we may
avoid an overfitting of the feature or kernel spaces
with syntactic and lexical data and thus reduce struc-
tural information in a linguistically motivated way.
a longer event trigger, (3) overlapped with a longer trigger of
the same event type, (4) occurred inside an entity mention an-
notation.
</bodyText>
<page confidence="0.994571">
21
</page>
<subsubsectionHeader confidence="0.567611">
3.2.1 Syntactic Pruning
</subsubsectionHeader>
<bodyText confidence="0.998930466666667">
Pruning targets auxiliary and modal verbs which
govern the main verb in syntactic structures such as
passives, past or future tense. We delete the aux-
iliars/modals as govenors of the main verbs from
the dependency graph and propagate the semantics-
preserving dependency relations of these nodes di-
rectly to the main verbs. Adhering to the depen-
dency tree format and labeling conventions set up
for the 2006 and 2007 CONLL shared tasks on de-
pendency parsing main verbs are usually connected
with the auxiliar by the VC dependency relation (see
Figure 2). Accordingly, in our example, the verb
“activate” is promoted to the ROOT in the depen-
dency graph and governs all nodes that were origi-
nally governed by the modal “may”.
</bodyText>
<figureCaption confidence="0.997602">
Figure 2: Trimming of Dependency Graphs.
</figureCaption>
<subsubsectionHeader confidence="0.529737">
3.2.2 Conceptual Decoration
</subsubsectionHeader>
<bodyText confidence="0.999787146341463">
Lexical nodes in the (possibly pruned) depen-
dency graphs deemed to be important for argument
extraction were then enriched with semantic class
annotations, instead of keeping the original lexical
(stem) representation (see Figure 2). The rationale
behind this decision was to generate more powerful
kernel-based or features representations (see Section
3.3.2 and 3.3.1).
The whole process is based on a three-tier task-
specific semantic hierarchy of named entity classes.
The top rank is constituted by the equivalent classes
Transcription factor, Binding site, and Promoter.
The second rank is occupied by MESH terms, and
the third tier assembles the named entity classes
Gene and Protein. Whenever a lexical item is cat-
egorized by one of these categories, the associated
node in the dependency graph is overlaid with that
category applying the ranking in cases of conflicts.
We also enriched the gene name mentions with
their respective Gene Ontology Annotations from
GOA.8 For this purpose, we first categorized GO
terms both from the “molecular function” and from
the “biological process” branch with respect to
their matching event type, e.g., Phosphorylation
or Positive regulation. We then mapped all gene
name mentions which occurred in the text to their
UNIPROT identifier using the gene name normalizer
GENO (Wermter et al., 2009). This identifier links a
gene with a set of (curated) GO annotations.
In addition, we inserted semantic information in
terms of the event trigger type and the experimen-
tal methods. As far as experimental methods are
concerned, we extracted all instances of them an-
notated in the GENIA event corpus. One student
of biology sorted the experimental methods relative
to the event categories under scrutiny. For example
“affinity chromatography” was assigned both to the
Gene expression and to the Binding category. For
our purposes, we only included those GO annota-
tions and experimental methods which matched the
event types to be identified in a sentence.
</bodyText>
<subsectionHeader confidence="0.999618">
3.3 Argument Identification and Ordering
</subsectionHeader>
<bodyText confidence="0.999989210526316">
The argument identification task can be subdivided
into three complexity levels. Level (1) incorpo-
rates five event types (Gene expression, Transcrip-
tion, Protein catabolism, Localization, Phosphory-
lation) which involve a single participant with a
THEME role only. Level (2) is concerned with one
event type (Binding) that provides an n-ary argument
structure where all arguments occupy the THEME(n)
role. Level (3) comprises three event types (Posi-
tive regulation, Negative regulation, or an unspeci-
fied Regulation) that represent a regulatory relation
between the above-mentioned event classes or pro-
teins. These events have usually a binary structure,
with a THEME argument and a CAUSE argument.
For argument extraction, we built sentence-wise
pairs of putative triggers and their putative argu-
ment(s), the latter involving ontological informa-
tion about the event type. For Level (1), we built
pairs only with proteins, while for Level (3) we al-
</bodyText>
<footnote confidence="0.946942">
8http://www.ebi.ac.uk/GOA
</footnote>
<page confidence="0.997586">
22
</page>
<bodyText confidence="0.998070666666667">
lowed all events as possible arguments. For Level
(2), Binding events, we generated binary (trigger,
protein) pairs as well as triples (trigger, proteins,
protein2) to adequately represent the binding be-
tween two proteins.9 Pairs of mentions not con-
nected by a dependency path could not be detected.
For the argument extraction we chose two ma-
chine learning-based approaches, feature-based and
a kernel-based one, as described below.10
</bodyText>
<subsectionHeader confidence="0.492529">
3.3.1 Feature-based Classifier
</subsectionHeader>
<bodyText confidence="0.999803333333333">
We distinguished three groups of features. First,
lexical features (covering lexical items before, af-
ter and between both mentions (of the event trigger
and an argument) as described by Zhou and Zhang
(2007)); second, chunking features (concerned with
head words of the phrases between two mentions as
described by Zhou and Zhang (2007)); third, de-
pendency parse features (considering both the se-
lected dependency levels of the arguments (parents
and least common subsumer) as discussed by Ka-
trenko and Adriaans (2006), as well as a shortest de-
pendency path structure between the arguments as
used by Kim et al. (2008b) for walk features).
For the feature-based approach, we chose the
Maximum Entropy (ME) classifier from MALLET.11
</bodyText>
<subsectionHeader confidence="0.740851">
3.3.2 Graph Kernel Classifier
</subsectionHeader>
<bodyText confidence="0.854937">
The graph kernel uses a converted form of depen-
dency graphs in which each dependency node is rep-
resented by a set of labels associated with that node.
The dependency edges are also represented as nodes
in the new graph such that they are connected to the
nodes adjacent in the dependency graph. Subgraphs
which represent, e.g., the linear order of the words
in the sentence can be added, if required. The entire
graph is represented in terms of an adjacency matrix
which is further processed to contain the summed
weights of paths connecting two nodes of the graph
(see Airola et al. (2008) for details).
9We did not account for the binding of more than two pro-
teins as this would have led to a combinatory explosion of pos-
sible classifications.
10In our experiments, we used full conceptual overlaying
(see Section 3.2) for the kernel-based representation and partial
overlaying for the dependency parse features (only gene/protein
annotation was exploited here). Graph representations allow for
many semantic labels to be associated with a node.
</bodyText>
<footnote confidence="0.8863385">
11http://mallet.cs.umass.edu/index.php/
Main_Page
</footnote>
<figureCaption confidence="0.99646475">
Figure 3: Graph Kernel Representation for a Trimmed
Dependency Graph — (1) original representation, (2)
representation without graph dependency edge nodes
(weights (0.9, 0.3) taken from Airola et al. (2008)).
</figureCaption>
<bodyText confidence="0.999947631578947">
For our experiments, we tried some variants of the
original graph kernel. In the original version each
dependency graph edge is represented as a node.
That means that connections between graph token
nodes are expressed through graph dependency edge
nodes (see Figure 3; (1)). To represent the connec-
tions between original tokens as direct connections
in the graph, we removed the edge nodes and each
token was assigned the edge label (its dependency
label; see Figure 3; (2)). Further variants included
encodings for (1) the shortest dependency path (sp)
between two mentions (argument and trigger)12 (2)
the complete dependency graph (sp-dep), and (3) the
complete dependency graph and linear information
(sp-dep-lin) (the original configuration from Airola
et al. (2008)).
For the graph kernel, we chose the LibSVM
(Chang and Lin, 2001) Support Vector Machine as
classifier.
</bodyText>
<subsectionHeader confidence="0.984808">
3.4 Postprocessing
</subsectionHeader>
<bodyText confidence="0.9952349">
The postprocessing step varies for the three different
Levels (see Section 3.3). For every event trigger of
Level (1) (e.g., Gene expression), we generate one
event per relation comprising a trigger and its argu-
ment. For Level (2) (Binding), we create a Binding
event with two arguments only for triples (trigger,
proteinl, protein2). For the third Level, we create
for each event trigger and its associated arguments
e = n × m events, for n CAUSE arguments and m
THEME arguments.
</bodyText>
<footnote confidence="0.985215">
12For Binding we extracted the shortest path between two
protein mentions if we encounter a triple (trigger, protein,,
protein2).
</footnote>
<page confidence="0.999267">
23
</page>
<sectionHeader confidence="0.998854" genericHeader="method">
4 Pipeline
</sectionHeader>
<bodyText confidence="0.99973495">
The event extraction pipeline consists of two ma-
jor parts, a pre-processor and the dedicated event
extractor. As far as pre-processing is concerned,
we imported the sentence splitting, tokenization and
GDep parsing results (Sagae and Tsujii, 2007) as
prepared by the shared task organizers for all data
sets (training, development and test). We processed
this data with the OpenNLP POS tagger and Chun-
ker, both re-trained on the GENIA corpus (Buyko et
al., 2006). Additionally, we enhanced the original
tokenization by one which includes hyphenization
of lexical items such as in “PMA-dependent”. 13
The data was further processed with the gene nor-
malizer GENO(Wermter et al., 2009) and a num-
ber of regex- and dictionary-based entity taggers
(covering promoters, binding sites, and transcrip-
tion factors). We also enriched gene name men-
tions with their respective Gene Ontology annota-
tions (see Section 3.2.2). The MESH thesaurus (ex-
cept chemical and drugs branch) was mapped on the
data using the Lingpipe Dictionary Chunker.14
After preprocessing, event extraction was started
distinguishing between the event trigger recognition
(cf. Section 3.1), the trimming of the dependency
graphs (cf. Section 3.2), and the argument extrac-
tion proper (cf. Section 3.3).15 We determined in
our experiments on the development data the perfor-
mance of every classifier type and its variants (for
the graph kernel), and of ensembles of the most per-
formant (F-Score) graph kernel variant and an ME
model.16 We present here the argument extraction
configuration used for the official run.17 For the
prediction of Phosphorylation, Localization, Pro-
tein catabolism types we used the graph kernel in
13This tokenization is more advantageous for the detection
of additional event triggers as it allows to generate depen-
dency relations from hyphenated terms. For example, in “PMA-
dependent”, “PMA” will be a child of “dependent” linked by
the AMOD dependency relation, and “dependent” receives the
original dependency relation of the “PMA-dependent” token.
</bodyText>
<footnote confidence="0.986852875">
14http://alias-i.com/lingpipe/
15For the final configurations of the graph kernel, we opti-
mized the C parameter in the spectrum between 2−3 and 23 on
the final training data for every event type separately.
16In the ensemble configuration we built the union of positive
instances.
17We achieved with this configuration the best performance
on the development set.
</footnote>
<bodyText confidence="0.999549444444444">
its “sp without dependency-edge-nodes” configura-
tion, while for the prediction of Transcription and
Gene expression events we used an ensemble of the
graph kernel in its “sp with dependency-edge-nodes”
variant, and an ME model. For the prediction of
Binding we used an ensemble of the graph kernel
(“sp-dep with dependency-edge-nodes”) and an ME
model. For the prediction of regulatory events we
used ME models for each regulatory type.
</bodyText>
<sectionHeader confidence="0.999804" genericHeader="method">
5 Results
</sectionHeader>
<bodyText confidence="0.99991719047619">
The baseline against which we compared our ap-
proach can be captured in a single rule. We extract
for every pair of a putative trigger and a putative ar-
gument the shortest dependency path between them.
If the shortest dependency path does not contain any
direction change, i.e., the argument is either a direct
child or a direct parent of the trigger, and if the path
does not contain any other intervening event trig-
gers, the argument is taken as the THEME role.
We performed evaluations on the shared task de-
velopment and test set. Our baseline achieved com-
petitive results of 36.0% precision, 34.0% recall,
35.0% F-score on the development set (see Table
1), and 30.4% precision, 35.7% recall, 32,8% F-
score on the test set (see Table 2). In particular
the one-argument events, i.e., Gene expression, Pro-
tein catabolism, Phosphorylation are effectively ex-
tracted with an F-score around 70.0%. More com-
plex events, in particular events of Level (3), i.e.,
(Regulation) were less properly dealt with because
of their strong internal complexity.
</bodyText>
<table confidence="0.999657909090909">
Event Class gold recall prec. F-score
Localization 53 75.47 30.30 43.24
Binding 248 33.47 20.80 25.66
Gene expression 356 76.12 75.07 75.59
Transcription 82 68.29 40.58 50.91
Protein catabolism 21 76.19 66.67 71.11
Phosphorylation 47 76.60 72.00 74.23
Regulation 169 14.20 15.09 14.63
Positive regulation 617 15.40 20.83 17.71
Negative regulation 196 11.73 13.22 12.43
TOTAL 1789 36.00 34.02 34.98
</table>
<tableCaption confidence="0.937385666666667">
Table 1: Baseline results on the shared task development
data. Approximate Span Matching/Approximate Recur-
sive Matching.
</tableCaption>
<page confidence="0.960714">
24
</page>
<table confidence="0.999900384615385">
Event Class gold recall prec. F-score gold recall prec. F-score
Localization 174 42.53 44.85 43.66 174 42.53 44.85 43.66
Binding 347 32.28 37.09 34.51 398 44.22 58.28 50.29
Gene expression 722 61.36 80.55 69.65 722 61.36 80.55 69.65
Transcription 137 39.42 35.06 37.11 137 39.42 35.06 37.11
Protein catabolism 14 71.43 66.67 68.97 14 71.43 66.67 68.97
Phosphorylation 135 65.93 90.82 76.39 135 65.93 90.82 76.39
EVT-TOTAL 1529 51.14 60.90 55.60 1580 53.54 65.89 59.08
Regulation 291 9.62 11.72 10.57 338 9.17 12.97 10.75
Positive regulation 983 10.38 11.33 10.83 1186 14.67 19.33 16.68
Negative regulation 379 14.25 19.22 16.36 416 14.18 21.00 16.93
REG-TOTAL 1653 11.13 12.96 11.98 1940 13.61 18.59 15.71
ALL-TOTAL 3182 30.36 35.72 32.82 3520 31.53 41.05 35.67
</table>
<tableCaption confidence="0.9984115">
Table 2: Baseline results on the shared task test data. Approximate Span Matching/Approximate Recursive Matching
(columns 3-5). Event decomposition, Approximate Span Matching/Approximate Recursive Matching (columns 7-9).
</tableCaption>
<bodyText confidence="0.9999785">
The event extraction approach, in its final config-
uration (see Section 4), achieved a performance of
50.4% recall, 45.8% precision and 48.0% F-score on
the development set (see Table 4), and 45.8% recall,
47.5% precision and 46.7% F-score on the test set
(see Table 3). This approach clearly outperformed
the baseline with an increase of 14 percentage points
on the test data. In particular, the events of Level (2)
and (3) were more properly dealt with than by the
baseline. In the event decomposition mode (argu-
ment detection is evaluated in a decomposed event)
we achieved a performance of 49.4% recall, 56.2%
precision, and 52.6% F-score (see Table 3).
Our experiments on the development set showed
that the combination of the feature-based and the
graph kernel-based approach can boost the results up
to 6 percentage points F-score (for the Binding event
type). It is interesting that the combination for Bind-
ing increased recall without dropping precision. The
original graph kernel approach for Binding events
performs with 38.3% recall, 27.9% precision and
32.3% F-score on the development set. The com-
bined approach comes with a remarkable increase
of 14 percentage points in recall. The combination
could also boost the recall of the Gene expression
and Transcription by 15 percentage points and 5 per-
centage points, respectively, without seriously drop-
ping the precision (4 points for every type). For
the other event types, no improvements were found
when we combined both approaches.
</bodyText>
<sectionHeader confidence="0.839269" genericHeader="method">
5.1 Error Discussion
</sectionHeader>
<bodyText confidence="0.9997133">
One expert biologist analyzed 30 abstracts randomly
extracted from the development error data. We de-
termined seven groups of errrors based on this anal-
ysis. The first group contains examples for which
an event should be determined, but a false argument
was found (e.g., Binding arguments were not prop-
erly sorted, or correct and false arguments were de-
tected for the same trigger) (44 examples). The sec-
ond group comprised examples where no trigger was
found (23 examples). Group (3) stands for cases
where no events were detected although a trigger
was properly identified (14 examples). Group (4)
holds examples detected in sentences which did not
contain any events (12 examples). Group (5) lists bi-
ologically meaningful analyses, actually very close
to the gold annotation, especially for the cascaded
regulatory events (12 examples), while Group (6) in-
corporates examples of a detected event with incor-
rect type (1 example). Group (7) gathers misleading
gold annotations (10 examples).
This assessment clearly indicates that a major
source of errors can be traced to the level of argu-
ment identification, in particular for Binding events.
The second major source has its offspring at the
level of trigger detection (we ignored, for exam-
ple, triggers such as “in the presence of”, “when”,
“normal”). About 10% of the errors are due to a
slight difference between extracted events and gold
events. For example, in the phrase “role for NF-
kappaB in the regulation of FasL expression” we
</bodyText>
<page confidence="0.993425">
25
</page>
<table confidence="0.999870769230769">
Event Class gold recall prec. F-score gold recall prec. F-score
Localization 174 43.68 77.55 55.88 174 43.68 77.55 55.88
Binding 347 49.57 35.25 41.20 398 63.57 54.88 58.91
Gene expression 722 64.82 80.27 71.72 722 64.82 80.27 71.72
Transcription 137 35.77 62.03 45.37 137 35.77 62.03 45.37
Protein catabolism 14 78.57 84.62 81.48 14 78.57 84.62 81.48
Phosphorylation 135 76.30 91.15 83.06 135 76.30 91.15 83.06
EVT-TOTAL 1529 57.49 63.97 60.56 1580 60.76 71.27 65.60
Regulation 291 31.27 30.13 30.69 338 35.21 37.54 36.34
Positive regulation 983 34.08 37.18 35.56 1186 40.64 49.33 44.57
Negative regulation 379 40.37 31.16 35.17 416 42.31 39.11 40.65
REG-TOTAL 1653 35.03 34.18 34.60 1940 40.05 44.55 42.18
ALL-TOTAL 3182 45.82 47.52 46.66 3520 49.35 56.20 52.55
</table>
<tableCaption confidence="0.980734333333333">
Table 3: Offical Event Extraction results on the shared task test data of the JULIELab Team. Approximate
Span Matching/Approximate Recursive Matching (columns 3-5). Event decomposition, Approximate Span Match-
ing/Approximate Recursive Matching (columns 7-9).
</tableCaption>
<bodyText confidence="0.999914333333333">
could not extract the gold event Regulation of Regu-
lation (Gene expression (FasL)) associated with the
trigger “role”, but we were able to find the (inside)
event Regulation (Gene expression (FasL)) associ-
ated with the trigger “regulation”. Interestingly, the
typing of events is not an error source in spite of
the simple disambiguation approach. Still, our dis-
ambiguation strategy is not appropriate for the anal-
ysis of double-annotated triggers such as “overex-
pression”, “transfection”, etc., which are annotated
as Gene expression and Positive regulation and are
a major source of errors in Group (2). As Group
(6) is an insignificant source of errors in our ran-
domly selected data, we focused our error analysis
on the especially ambiguous event type Transcrip-
tion. We found from 34 errors that 14 of them were
due to the disambiguation strategy (in particular for
triggers “(gene) expression” and “induction”).
</bodyText>
<sectionHeader confidence="0.999249" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9979908">
Our approach to event extraction incorporates man-
ually curated dictionaries and machine learning
methodologies to sort out associated event triggers
and arguments on trimmed dependency graph struc-
tures. Trimming combines pruning irrelevant lexi-
cal material from a dependency graph and decorat-
ing particularly relevant lexical material from that
graph with more abstract conceptual class informa-
tion. Given that methodological framework, the
JULIELab Team scored on 2nd rank among 24 com-
</bodyText>
<table confidence="0.999712363636364">
Event Class gold recall prec. F-score
Localization 53 71.70 74.51 73.08
Binding 248 52.42 29.08 37.41
Gene expression 356 75.28 81.46 78.25
Transcription 82 60.98 73.53 66.67
Protein catabolism 21 90.48 79.17 84.44
Phosphorylation 47 82.98 84.78 83.87
Regulation 169 37.87 36.78 37.32
Positive regulation 617 34.36 35.99 35.16
Negative regulation 196 41.33 33.61 37.07
TOTAL 1789 50.36 45.76 47.95
</table>
<tableCaption confidence="0.97003675">
Table 4: Event extraction results on the shared task
development data of the official run of the JULIELab
Team. Approximate Span Matching/Approximate Recur-
sive Matching.
</tableCaption>
<bodyText confidence="0.998837">
peting teams, with 45.8% precision, 47.5% recall
and 46.7% F1-score on all 3,182 events.
</bodyText>
<sectionHeader confidence="0.999248" genericHeader="acknowledgments">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999948833333333">
We wish to thank Rico Landefeld for his technical
support, Tobias Wagner and Rico Pusch for their
constant help and great expertise in biological is-
sues. This research was partially funded within the
BOOTSTREP project under grant FP6-028099 and
the CALBC project under grant FP7-231727.
</bodyText>
<sectionHeader confidence="0.999212" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.990236">
Antti Airola, Sampo Pyysalo, Jari Bj¨orne, Tapio
Pahikkala, Filip Ginter, and Tapio Salakoski. 2008. A
</reference>
<page confidence="0.951346">
26
</page>
<reference confidence="0.998873797468354">
graph kernel for protein-protein interaction extraction.
In Proceedings of the Workshop on Current Trends in
Biomedical Natural Language Processing, pages 1–9.
Christian Blaschke, Miguel A. Andrade, Christos Ouzou-
nis, and Alfonso Valencia. 1999. Automatic ex-
traction of biological information from scientific text:
Protein-protein interactions. In ISMB’99 – Proceed-
ings of the 7th International Conference on Intelligent
Systems for Molecular Biology, pages 60–67.
Ekaterina Buyko, Joachim Wermter, Michael Poprat, and
Udo Hahn. 2006. Automatically adapting an NLP
core engine to the biology domain. In Proceedings
of the Joint BioLINK-Bio-Ontologies Meeting. A Joint
Meeting of the ISMB Special Interest Group on Bio-
Ontologies and the BioLINK Special Interest Group on
Text Data M ining in Association with ISMB, pages
65–68. Fortaleza, Brazil, August 5, 2006.
Chih-Chung Chang and Chih-Jen Lin, 2001. LIB-
SVM: a library for support vector machines. Soft-
ware available at http://www.csie.ntu.edu.
tw/˜cjlin/libsvm.
Katrin Fundel, Robert K¨uffner, and Ralf Zimmer.
2007. Relex-relation extraction using dependency
parse trees. Bioinformatics, 23(3):365–371.
J¨org Hakenberg, Ulf Leser, Conrad Plake, Harald Kirsch,
and Dietrich Rebholz-Schuhmann. 2005. LLL’05
challenge: Genic interaction extraction - identifica-
tion of language patterns based on alignment and finite
state automata. In Proceedings of the 4th Learning
Language in Logic Workshop (LLL05), pages 38–45.
Minlie Huang, Xiaoyan Zhu, Donald G. Payan, Kun-
bin Qu, and Ming Li. 2004. Discovering patterns
to extract protein-protein interactions from full texts.
Bioinformatics, 20(18):3604–3612.
Sophia Katrenko and Pieter W. Adriaans. 2006. Learn-
ing relations from biomedical corpora using depen-
dency trees. In Karl Tuyls, Ronald L. Westra, Yvan
Saeys, and Ann Now´e, editors, KDECB 2006 – Knowl-
edge Discovery and Emergent Complexity in Bioin-
formatics. Revised Selected Papers of the 1st Inter-
national Workshop., volume 4366 of Lecture Notes
in Computer Science, pages 61–80. Ghent, Belgium,
May 10, 2006. Berlin: Springer.
Jin-Dong Kim, Tomoko Ohta, and Jun’ichi Tsujii. 2008a.
Corpus annotation for mining biomedical events from
literature. BMC Bioinformatics, 9(10).
Seon-Ho Kim, Juntae Yoon, and Jihoon Yang. 2008b.
Kernel approaches for genic interaction extraction.
Bioinformatics, 24(1):118–126.
Rune Sætre, Kenji Sagae, and Jun’ichi Tsujii. 2007. Syn-
tactic features for protein-protein interaction extrac-
tion. In Christopher J. O. Baker and Jian Su, editors,
LBM 2007, volume 319, pages 6.1–6.14.
Kenji Sagae and Jun’ichi Tsujii. 2007. Dependency pars-
ing and domain adaptation with LR models and par ser
ensembles. In Proceedings of the CoNLL Shared Task
Session of EMNLP-CoNLL 2007, pages 1044–1050.
Jasmin ˇSari´c, Lars J. Jensen, Rossitza Ouzounova, Isabel
Rojas, and Peer Bork. 2004. Extracting regulatory
gene expression networks from pubmed. In ACL ’04:
Proceedings of the 42nd Annual Meeting on Associa-
tion for Computational Linguistics, page 191, Morris-
town, NJ, USA. Association for Computational Lin-
guistics.
Joachim Wermter, Katrin Tomanek, and Udo Hahn.
2009. High-performance gene name normalization
with GeNo. Bioinformatics, 25(6):815–821.
Akane Yakushiji, Yuka Tateisi, Yusuke Miyao, and
Jun’ichi Tsujii. 2001. Event extraction from biomed-
ical papers using a full parser. In Russ B. Altman,
A. Keith Dunker, Lawrence Hunter, Kevin Lauderdale,
and Teri E. Klein, editors, PSB 2001 – Proceedings
of the 6th Pacific Symposium on Biocomputing, pages
408–419. Maui, Hawaii, USA. January 3-7, 2001. Sin-
gapore: World Scientific Publishing.
Guodong Zhou and Min Zhang. 2007. Extracting re-
lation information from text documents by exploring
various types of knowledge. Information Processing
&amp; Management, 43(4):969–982.
</reference>
<page confidence="0.998803">
27
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.416573">
<title confidence="0.999628">Event Extraction from Trimmed Dependency Graphs</title>
<author confidence="0.987894">Erik Faessler Buyko</author>
<author confidence="0.987894">Joachim Wermter Hahn</author>
<affiliation confidence="0.7348025">Jena University Language &amp; Information Engineering (JULIE) Friedrich-Schiller-Universit¨at</affiliation>
<address confidence="0.667182">F¨urstengraben 30, 07743 Jena, Germany</address>
<abstract confidence="0.994722611111111">We describe the approach to event extracwhich the Team from FSU Jena (Germany) pursued to solve Task 1 in the “BioNLP’09 Shared Task on Event Extraction”. We incorporate manually curated dictionaries and machine learning methodologies to sort out associated event triggers and arguments on trimmed dependency graph structures. Trimming combines pruning irrelevant lexical material from a dependency graph and decorating particularly relevant lexical material from that graph with more abstract conceptual class information. Given methodological framework, the Team scored on 2nd rank among 24 competing teams, with 45.8% precision, 47.5% recall and 46.7% F1-score on all 3,182 events.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Antti Airola</author>
<author>Sampo Pyysalo</author>
<author>Jari Bj¨orne</author>
<author>Tapio Pahikkala</author>
<author>Filip Ginter</author>
<author>Tapio Salakoski</author>
</authors>
<title>A graph kernel for protein-protein interaction extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing,</booktitle>
<pages>1--9</pages>
<marker>Airola, Pyysalo, Bj¨orne, Pahikkala, Ginter, Salakoski, 2008</marker>
<rawString>Antti Airola, Sampo Pyysalo, Jari Bj¨orne, Tapio Pahikkala, Filip Ginter, and Tapio Salakoski. 2008. A graph kernel for protein-protein interaction extraction. In Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing, pages 1–9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Blaschke</author>
<author>Miguel A Andrade</author>
<author>Christos Ouzounis</author>
<author>Alfonso Valencia</author>
</authors>
<title>Automatic extraction of biological information from scientific text: Protein-protein interactions.</title>
<date>1999</date>
<booktitle>In ISMB’99 – Proceedings of the 7th International Conference on Intelligent Systems for Molecular Biology,</booktitle>
<pages>60--67</pages>
<marker>Blaschke, Andrade, Ouzounis, Valencia, 1999</marker>
<rawString>Christian Blaschke, Miguel A. Andrade, Christos Ouzounis, and Alfonso Valencia. 1999. Automatic extraction of biological information from scientific text: Protein-protein interactions. In ISMB’99 – Proceedings of the 7th International Conference on Intelligent Systems for Molecular Biology, pages 60–67.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Buyko</author>
<author>Joachim Wermter</author>
<author>Michael Poprat</author>
<author>Udo Hahn</author>
</authors>
<title>Automatically adapting an NLP core engine to the biology domain.</title>
<date>2006</date>
<booktitle>In Proceedings of the Joint BioLINK-Bio-Ontologies Meeting. A Joint Meeting of the ISMB Special Interest Group on BioOntologies and the BioLINK Special Interest Group on Text Data M ining in Association with ISMB,</booktitle>
<pages>65--68</pages>
<location>Fortaleza, Brazil,</location>
<contexts>
<context position="20426" citStr="Buyko et al., 2006" startWordPosition="3160" endWordPosition="3163">E arguments. 12For Binding we extracted the shortest path between two protein mentions if we encounter a triple (trigger, protein,, protein2). 23 4 Pipeline The event extraction pipeline consists of two major parts, a pre-processor and the dedicated event extractor. As far as pre-processing is concerned, we imported the sentence splitting, tokenization and GDep parsing results (Sagae and Tsujii, 2007) as prepared by the shared task organizers for all data sets (training, development and test). We processed this data with the OpenNLP POS tagger and Chunker, both re-trained on the GENIA corpus (Buyko et al., 2006). Additionally, we enhanced the original tokenization by one which includes hyphenization of lexical items such as in “PMA-dependent”. 13 The data was further processed with the gene normalizer GENO(Wermter et al., 2009) and a number of regex- and dictionary-based entity taggers (covering promoters, binding sites, and transcription factors). We also enriched gene name mentions with their respective Gene Ontology annotations (see Section 3.2.2). The MESH thesaurus (except chemical and drugs branch) was mapped on the data using the Lingpipe Dictionary Chunker.14 After preprocessing, event extrac</context>
</contexts>
<marker>Buyko, Wermter, Poprat, Hahn, 2006</marker>
<rawString>Ekaterina Buyko, Joachim Wermter, Michael Poprat, and Udo Hahn. 2006. Automatically adapting an NLP core engine to the biology domain. In Proceedings of the Joint BioLINK-Bio-Ontologies Meeting. A Joint Meeting of the ISMB Special Interest Group on BioOntologies and the BioLINK Special Interest Group on Text Data M ining in Association with ISMB, pages 65–68. Fortaleza, Brazil, August 5, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: a library for support vector machines. Software available at http://www.csie.ntu.edu.</title>
<date>2001</date>
<tech>tw/˜cjlin/libsvm.</tech>
<contexts>
<context position="19281" citStr="Chang and Lin, 2001" startWordPosition="2976" endWordPosition="2979"> through graph dependency edge nodes (see Figure 3; (1)). To represent the connections between original tokens as direct connections in the graph, we removed the edge nodes and each token was assigned the edge label (its dependency label; see Figure 3; (2)). Further variants included encodings for (1) the shortest dependency path (sp) between two mentions (argument and trigger)12 (2) the complete dependency graph (sp-dep), and (3) the complete dependency graph and linear information (sp-dep-lin) (the original configuration from Airola et al. (2008)). For the graph kernel, we chose the LibSVM (Chang and Lin, 2001) Support Vector Machine as classifier. 3.4 Postprocessing The postprocessing step varies for the three different Levels (see Section 3.3). For every event trigger of Level (1) (e.g., Gene expression), we generate one event per relation comprising a trigger and its argument. For Level (2) (Binding), we create a Binding event with two arguments only for triples (trigger, proteinl, protein2). For the third Level, we create for each event trigger and its associated arguments e = n × m events, for n CAUSE arguments and m THEME arguments. 12For Binding we extracted the shortest path between two prot</context>
</contexts>
<marker>Chang, Lin, 2001</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin, 2001. LIBSVM: a library for support vector machines. Software available at http://www.csie.ntu.edu. tw/˜cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Fundel</author>
<author>Robert K¨uffner</author>
<author>Ralf Zimmer</author>
</authors>
<title>Relex-relation extraction using dependency parse trees.</title>
<date>2007</date>
<journal>Bioinformatics,</journal>
<volume>23</volume>
<issue>3</issue>
<marker>Fundel, K¨uffner, Zimmer, 2007</marker>
<rawString>Katrin Fundel, Robert K¨uffner, and Ralf Zimmer. 2007. Relex-relation extraction using dependency parse trees. Bioinformatics, 23(3):365–371.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Hakenberg</author>
<author>Ulf Leser</author>
<author>Conrad Plake</author>
<author>Harald Kirsch</author>
<author>Dietrich Rebholz-Schuhmann</author>
</authors>
<title>LLL’05 challenge: Genic interaction extraction - identification of language patterns based on alignment and finite state automata.</title>
<date>2005</date>
<booktitle>In Proceedings of the 4th Learning Language in Logic Workshop (LLL05),</booktitle>
<pages>38--45</pages>
<contexts>
<context position="1796" citStr="Hakenberg et al. (2005)" startWordPosition="257" endWordPosition="260">rpretation, i.e., finding instances of semantic classes such as proteins, diseases, or drugs. For a couple of years, this focus has been complemented by analytics dealing with relation extraction, i.e., finding instances of relations which link one or more (usually two) arguments, the latter being instances of semantic classes, such as the interaction between two proteins (PPIs). PPI extraction is a complex task since cascades of molecular events are involved which are hard to sort out. Many different approaches have already been tried – pattern-based ones (e.g., by Blaschke 19 et al. (1999), Hakenberg et al. (2005) or Huang et al. (2004)), rule-based ones (e.g., by Yakushiji et al. (2001), ˇSari´c et al. (2004) or Fundel et al. (2007)), and machine learning-based ones (e.g., by Katrenko and Adriaans (2006), Sætre et al. (2007) or Airola et al. (2008)), yet without conclusive results. In the following, we present our approach to solve Task 1 within the “BioNLP’09 Shared Task on Event Extraction”.1 Task 1 “Event detection and characterization” required to determine the intended relation given a priori supplied protein annotations. Our approach considers dependency graphs as the central data structure on w</context>
</contexts>
<marker>Hakenberg, Leser, Plake, Kirsch, Rebholz-Schuhmann, 2005</marker>
<rawString>J¨org Hakenberg, Ulf Leser, Conrad Plake, Harald Kirsch, and Dietrich Rebholz-Schuhmann. 2005. LLL’05 challenge: Genic interaction extraction - identification of language patterns based on alignment and finite state automata. In Proceedings of the 4th Learning Language in Logic Workshop (LLL05), pages 38–45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minlie Huang</author>
<author>Xiaoyan Zhu</author>
<author>Donald G Payan</author>
<author>Kunbin Qu</author>
<author>Ming Li</author>
</authors>
<title>Discovering patterns to extract protein-protein interactions from full texts.</title>
<date>2004</date>
<journal>Bioinformatics,</journal>
<volume>20</volume>
<issue>18</issue>
<contexts>
<context position="1819" citStr="Huang et al. (2004)" startWordPosition="262" endWordPosition="265">nstances of semantic classes such as proteins, diseases, or drugs. For a couple of years, this focus has been complemented by analytics dealing with relation extraction, i.e., finding instances of relations which link one or more (usually two) arguments, the latter being instances of semantic classes, such as the interaction between two proteins (PPIs). PPI extraction is a complex task since cascades of molecular events are involved which are hard to sort out. Many different approaches have already been tried – pattern-based ones (e.g., by Blaschke 19 et al. (1999), Hakenberg et al. (2005) or Huang et al. (2004)), rule-based ones (e.g., by Yakushiji et al. (2001), ˇSari´c et al. (2004) or Fundel et al. (2007)), and machine learning-based ones (e.g., by Katrenko and Adriaans (2006), Sætre et al. (2007) or Airola et al. (2008)), yet without conclusive results. In the following, we present our approach to solve Task 1 within the “BioNLP’09 Shared Task on Event Extraction”.1 Task 1 “Event detection and characterization” required to determine the intended relation given a priori supplied protein annotations. Our approach considers dependency graphs as the central data structure on which various trimming o</context>
</contexts>
<marker>Huang, Zhu, Payan, Qu, Li, 2004</marker>
<rawString>Minlie Huang, Xiaoyan Zhu, Donald G. Payan, Kunbin Qu, and Ming Li. 2004. Discovering patterns to extract protein-protein interactions from full texts. Bioinformatics, 20(18):3604–3612.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Sophia Katrenko</author>
<author>Pieter W Adriaans</author>
</authors>
<title>Learning relations from biomedical corpora using dependency trees.</title>
<date>2006</date>
<booktitle>KDECB 2006 – Knowledge Discovery and Emergent Complexity in Bioinformatics. Revised Selected Papers of the 1st International Workshop.,</booktitle>
<volume>4366</volume>
<pages>61--80</pages>
<editor>In Karl Tuyls, Ronald L. Westra, Yvan Saeys, and Ann Now´e, editors,</editor>
<publisher>Springer.</publisher>
<location>Ghent, Belgium,</location>
<contexts>
<context position="1991" citStr="Katrenko and Adriaans (2006)" startWordPosition="289" endWordPosition="292">ction, i.e., finding instances of relations which link one or more (usually two) arguments, the latter being instances of semantic classes, such as the interaction between two proteins (PPIs). PPI extraction is a complex task since cascades of molecular events are involved which are hard to sort out. Many different approaches have already been tried – pattern-based ones (e.g., by Blaschke 19 et al. (1999), Hakenberg et al. (2005) or Huang et al. (2004)), rule-based ones (e.g., by Yakushiji et al. (2001), ˇSari´c et al. (2004) or Fundel et al. (2007)), and machine learning-based ones (e.g., by Katrenko and Adriaans (2006), Sætre et al. (2007) or Airola et al. (2008)), yet without conclusive results. In the following, we present our approach to solve Task 1 within the “BioNLP’09 Shared Task on Event Extraction”.1 Task 1 “Event detection and characterization” required to determine the intended relation given a priori supplied protein annotations. Our approach considers dependency graphs as the central data structure on which various trimming operations are performed involving syntactic simplification but also, even more important, semantic enrichment by conceptual overlays. A description of the component subtask</context>
<context position="16892" citStr="Katrenko and Adriaans (2006)" startWordPosition="2599" endWordPosition="2603">-based approaches, feature-based and a kernel-based one, as described below.10 3.3.1 Feature-based Classifier We distinguished three groups of features. First, lexical features (covering lexical items before, after and between both mentions (of the event trigger and an argument) as described by Zhou and Zhang (2007)); second, chunking features (concerned with head words of the phrases between two mentions as described by Zhou and Zhang (2007)); third, dependency parse features (considering both the selected dependency levels of the arguments (parents and least common subsumer) as discussed by Katrenko and Adriaans (2006), as well as a shortest dependency path structure between the arguments as used by Kim et al. (2008b) for walk features). For the feature-based approach, we chose the Maximum Entropy (ME) classifier from MALLET.11 3.3.2 Graph Kernel Classifier The graph kernel uses a converted form of dependency graphs in which each dependency node is represented by a set of labels associated with that node. The dependency edges are also represented as nodes in the new graph such that they are connected to the nodes adjacent in the dependency graph. Subgraphs which represent, e.g., the linear order of the word</context>
</contexts>
<marker>Katrenko, Adriaans, 2006</marker>
<rawString>Sophia Katrenko and Pieter W. Adriaans. 2006. Learning relations from biomedical corpora using dependency trees. In Karl Tuyls, Ronald L. Westra, Yvan Saeys, and Ann Now´e, editors, KDECB 2006 – Knowledge Discovery and Emergent Complexity in Bioinformatics. Revised Selected Papers of the 1st International Workshop., volume 4366 of Lecture Notes in Computer Science, pages 61–80. Ghent, Belgium, May 10, 2006. Berlin: Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Dong Kim</author>
<author>Tomoko Ohta</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Corpus annotation for mining biomedical events from literature.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<issue>10</issue>
<contexts>
<context position="7779" citStr="Kim et al., 2008" startWordPosition="1181" endWordPosition="1184">he training data. In 162 of these cases it acts as a trigger for Positive regulation, 6 times as a trigger for Transcription, 8 instances trigger Gene expression, while 241 occurrences do not trigger an event at all. Event Detection Argument Identification with Ensemble of Classifiers Post-processing Pre-processing Typing of Putative Event Triggers Trimming of Dependency Graphs 20 gers assembled in this suite of dictionaries, one per event type, is discussed in Section 3.1.2. 3.1.1 Manual Curation of the Dictionaries We started collecting our dictionaries from the original GENIA event corpus (Kim et al., 2008a). The extracted event triggers were then automatically lemmatized5 and the resulting lemmata were subsequently ranked by two students of biology according to their predictive power to act as a trigger for a particular event type. This expert assessment led us to four trigger groups (for each event type these groups were determined separately): (1) Triggers are important and discriminative for a specific event type. This group contains event triggers such as “upregulate” for Positive regulation. (2) Triggers are important though not fully discriminative for a particular event type; yet, this </context>
<context position="16991" citStr="Kim et al. (2008" startWordPosition="2619" endWordPosition="2622">e distinguished three groups of features. First, lexical features (covering lexical items before, after and between both mentions (of the event trigger and an argument) as described by Zhou and Zhang (2007)); second, chunking features (concerned with head words of the phrases between two mentions as described by Zhou and Zhang (2007)); third, dependency parse features (considering both the selected dependency levels of the arguments (parents and least common subsumer) as discussed by Katrenko and Adriaans (2006), as well as a shortest dependency path structure between the arguments as used by Kim et al. (2008b) for walk features). For the feature-based approach, we chose the Maximum Entropy (ME) classifier from MALLET.11 3.3.2 Graph Kernel Classifier The graph kernel uses a converted form of dependency graphs in which each dependency node is represented by a set of labels associated with that node. The dependency edges are also represented as nodes in the new graph such that they are connected to the nodes adjacent in the dependency graph. Subgraphs which represent, e.g., the linear order of the words in the sentence can be added, if required. The entire graph is represented in terms of an adjacen</context>
</contexts>
<marker>Kim, Ohta, Tsujii, 2008</marker>
<rawString>Jin-Dong Kim, Tomoko Ohta, and Jun’ichi Tsujii. 2008a. Corpus annotation for mining biomedical events from literature. BMC Bioinformatics, 9(10).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seon-Ho Kim</author>
<author>Juntae Yoon</author>
<author>Jihoon Yang</author>
</authors>
<title>Kernel approaches for genic interaction extraction.</title>
<date>2008</date>
<journal>Bioinformatics,</journal>
<volume>24</volume>
<issue>1</issue>
<contexts>
<context position="7779" citStr="Kim et al., 2008" startWordPosition="1181" endWordPosition="1184">he training data. In 162 of these cases it acts as a trigger for Positive regulation, 6 times as a trigger for Transcription, 8 instances trigger Gene expression, while 241 occurrences do not trigger an event at all. Event Detection Argument Identification with Ensemble of Classifiers Post-processing Pre-processing Typing of Putative Event Triggers Trimming of Dependency Graphs 20 gers assembled in this suite of dictionaries, one per event type, is discussed in Section 3.1.2. 3.1.1 Manual Curation of the Dictionaries We started collecting our dictionaries from the original GENIA event corpus (Kim et al., 2008a). The extracted event triggers were then automatically lemmatized5 and the resulting lemmata were subsequently ranked by two students of biology according to their predictive power to act as a trigger for a particular event type. This expert assessment led us to four trigger groups (for each event type these groups were determined separately): (1) Triggers are important and discriminative for a specific event type. This group contains event triggers such as “upregulate” for Positive regulation. (2) Triggers are important though not fully discriminative for a particular event type; yet, this </context>
<context position="16991" citStr="Kim et al. (2008" startWordPosition="2619" endWordPosition="2622">e distinguished three groups of features. First, lexical features (covering lexical items before, after and between both mentions (of the event trigger and an argument) as described by Zhou and Zhang (2007)); second, chunking features (concerned with head words of the phrases between two mentions as described by Zhou and Zhang (2007)); third, dependency parse features (considering both the selected dependency levels of the arguments (parents and least common subsumer) as discussed by Katrenko and Adriaans (2006), as well as a shortest dependency path structure between the arguments as used by Kim et al. (2008b) for walk features). For the feature-based approach, we chose the Maximum Entropy (ME) classifier from MALLET.11 3.3.2 Graph Kernel Classifier The graph kernel uses a converted form of dependency graphs in which each dependency node is represented by a set of labels associated with that node. The dependency edges are also represented as nodes in the new graph such that they are connected to the nodes adjacent in the dependency graph. Subgraphs which represent, e.g., the linear order of the words in the sentence can be added, if required. The entire graph is represented in terms of an adjacen</context>
</contexts>
<marker>Kim, Yoon, Yang, 2008</marker>
<rawString>Seon-Ho Kim, Juntae Yoon, and Jihoon Yang. 2008b. Kernel approaches for genic interaction extraction. Bioinformatics, 24(1):118–126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rune Sætre</author>
<author>Kenji Sagae</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Syntactic features for protein-protein interaction extraction.</title>
<date>2007</date>
<volume>319</volume>
<pages>6--1</pages>
<editor>In Christopher J. O. Baker and Jian Su, editors, LBM</editor>
<contexts>
<context position="2012" citStr="Sætre et al. (2007)" startWordPosition="293" endWordPosition="296"> of relations which link one or more (usually two) arguments, the latter being instances of semantic classes, such as the interaction between two proteins (PPIs). PPI extraction is a complex task since cascades of molecular events are involved which are hard to sort out. Many different approaches have already been tried – pattern-based ones (e.g., by Blaschke 19 et al. (1999), Hakenberg et al. (2005) or Huang et al. (2004)), rule-based ones (e.g., by Yakushiji et al. (2001), ˇSari´c et al. (2004) or Fundel et al. (2007)), and machine learning-based ones (e.g., by Katrenko and Adriaans (2006), Sætre et al. (2007) or Airola et al. (2008)), yet without conclusive results. In the following, we present our approach to solve Task 1 within the “BioNLP’09 Shared Task on Event Extraction”.1 Task 1 “Event detection and characterization” required to determine the intended relation given a priori supplied protein annotations. Our approach considers dependency graphs as the central data structure on which various trimming operations are performed involving syntactic simplification but also, even more important, semantic enrichment by conceptual overlays. A description of the component subtasks is provided in Sect</context>
</contexts>
<marker>Sætre, Sagae, Tsujii, 2007</marker>
<rawString>Rune Sætre, Kenji Sagae, and Jun’ichi Tsujii. 2007. Syntactic features for protein-protein interaction extraction. In Christopher J. O. Baker and Jian Su, editors, LBM 2007, volume 319, pages 6.1–6.14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Dependency parsing and domain adaptation with LR models and par ser ensembles.</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL</booktitle>
<pages>1044--1050</pages>
<contexts>
<context position="20211" citStr="Sagae and Tsujii, 2007" startWordPosition="3123" endWordPosition="3126">te a Binding event with two arguments only for triples (trigger, proteinl, protein2). For the third Level, we create for each event trigger and its associated arguments e = n × m events, for n CAUSE arguments and m THEME arguments. 12For Binding we extracted the shortest path between two protein mentions if we encounter a triple (trigger, protein,, protein2). 23 4 Pipeline The event extraction pipeline consists of two major parts, a pre-processor and the dedicated event extractor. As far as pre-processing is concerned, we imported the sentence splitting, tokenization and GDep parsing results (Sagae and Tsujii, 2007) as prepared by the shared task organizers for all data sets (training, development and test). We processed this data with the OpenNLP POS tagger and Chunker, both re-trained on the GENIA corpus (Buyko et al., 2006). Additionally, we enhanced the original tokenization by one which includes hyphenization of lexical items such as in “PMA-dependent”. 13 The data was further processed with the gene normalizer GENO(Wermter et al., 2009) and a number of regex- and dictionary-based entity taggers (covering promoters, binding sites, and transcription factors). We also enriched gene name mentions with </context>
</contexts>
<marker>Sagae, Tsujii, 2007</marker>
<rawString>Kenji Sagae and Jun’ichi Tsujii. 2007. Dependency parsing and domain adaptation with LR models and par ser ensembles. In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pages 1044–1050.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jasmin ˇSari´c</author>
<author>Lars J Jensen</author>
<author>Rossitza Ouzounova</author>
<author>Isabel Rojas</author>
<author>Peer Bork</author>
</authors>
<title>Extracting regulatory gene expression networks from pubmed.</title>
<date>2004</date>
<booktitle>In ACL ’04: Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>191</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<marker>ˇSari´c, Jensen, Ouzounova, Rojas, Bork, 2004</marker>
<rawString>Jasmin ˇSari´c, Lars J. Jensen, Rossitza Ouzounova, Isabel Rojas, and Peer Bork. 2004. Extracting regulatory gene expression networks from pubmed. In ACL ’04: Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, page 191, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joachim Wermter</author>
<author>Katrin Tomanek</author>
<author>Udo Hahn</author>
</authors>
<title>High-performance gene name normalization with GeNo.</title>
<date>2009</date>
<journal>Bioinformatics,</journal>
<volume>25</volume>
<issue>6</issue>
<contexts>
<context position="14235" citStr="Wermter et al., 2009" startWordPosition="2195" endWordPosition="2198">ategorized by one of these categories, the associated node in the dependency graph is overlaid with that category applying the ranking in cases of conflicts. We also enriched the gene name mentions with their respective Gene Ontology Annotations from GOA.8 For this purpose, we first categorized GO terms both from the “molecular function” and from the “biological process” branch with respect to their matching event type, e.g., Phosphorylation or Positive regulation. We then mapped all gene name mentions which occurred in the text to their UNIPROT identifier using the gene name normalizer GENO (Wermter et al., 2009). This identifier links a gene with a set of (curated) GO annotations. In addition, we inserted semantic information in terms of the event trigger type and the experimental methods. As far as experimental methods are concerned, we extracted all instances of them annotated in the GENIA event corpus. One student of biology sorted the experimental methods relative to the event categories under scrutiny. For example “affinity chromatography” was assigned both to the Gene expression and to the Binding category. For our purposes, we only included those GO annotations and experimental methods which m</context>
<context position="20646" citStr="Wermter et al., 2009" startWordPosition="3193" endWordPosition="3196">pre-processor and the dedicated event extractor. As far as pre-processing is concerned, we imported the sentence splitting, tokenization and GDep parsing results (Sagae and Tsujii, 2007) as prepared by the shared task organizers for all data sets (training, development and test). We processed this data with the OpenNLP POS tagger and Chunker, both re-trained on the GENIA corpus (Buyko et al., 2006). Additionally, we enhanced the original tokenization by one which includes hyphenization of lexical items such as in “PMA-dependent”. 13 The data was further processed with the gene normalizer GENO(Wermter et al., 2009) and a number of regex- and dictionary-based entity taggers (covering promoters, binding sites, and transcription factors). We also enriched gene name mentions with their respective Gene Ontology annotations (see Section 3.2.2). The MESH thesaurus (except chemical and drugs branch) was mapped on the data using the Lingpipe Dictionary Chunker.14 After preprocessing, event extraction was started distinguishing between the event trigger recognition (cf. Section 3.1), the trimming of the dependency graphs (cf. Section 3.2), and the argument extraction proper (cf. Section 3.3).15 We determined in o</context>
</contexts>
<marker>Wermter, Tomanek, Hahn, 2009</marker>
<rawString>Joachim Wermter, Katrin Tomanek, and Udo Hahn. 2009. High-performance gene name normalization with GeNo. Bioinformatics, 25(6):815–821.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akane Yakushiji</author>
<author>Yuka Tateisi</author>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Event extraction from biomedical papers using a full parser.</title>
<date>2001</date>
<booktitle>PSB 2001 – Proceedings of the 6th Pacific Symposium on Biocomputing,</booktitle>
<pages>408--419</pages>
<editor>In Russ B. Altman, A. Keith Dunker, Lawrence Hunter, Kevin Lauderdale, and Teri E. Klein, editors,</editor>
<publisher>Singapore: World Scientific Publishing.</publisher>
<location>Maui, Hawaii, USA.</location>
<contexts>
<context position="1871" citStr="Yakushiji et al. (2001)" startWordPosition="270" endWordPosition="273">iseases, or drugs. For a couple of years, this focus has been complemented by analytics dealing with relation extraction, i.e., finding instances of relations which link one or more (usually two) arguments, the latter being instances of semantic classes, such as the interaction between two proteins (PPIs). PPI extraction is a complex task since cascades of molecular events are involved which are hard to sort out. Many different approaches have already been tried – pattern-based ones (e.g., by Blaschke 19 et al. (1999), Hakenberg et al. (2005) or Huang et al. (2004)), rule-based ones (e.g., by Yakushiji et al. (2001), ˇSari´c et al. (2004) or Fundel et al. (2007)), and machine learning-based ones (e.g., by Katrenko and Adriaans (2006), Sætre et al. (2007) or Airola et al. (2008)), yet without conclusive results. In the following, we present our approach to solve Task 1 within the “BioNLP’09 Shared Task on Event Extraction”.1 Task 1 “Event detection and characterization” required to determine the intended relation given a priori supplied protein annotations. Our approach considers dependency graphs as the central data structure on which various trimming operations are performed involving syntactic simplifi</context>
</contexts>
<marker>Yakushiji, Tateisi, Miyao, Tsujii, 2001</marker>
<rawString>Akane Yakushiji, Yuka Tateisi, Yusuke Miyao, and Jun’ichi Tsujii. 2001. Event extraction from biomedical papers using a full parser. In Russ B. Altman, A. Keith Dunker, Lawrence Hunter, Kevin Lauderdale, and Teri E. Klein, editors, PSB 2001 – Proceedings of the 6th Pacific Symposium on Biocomputing, pages 408–419. Maui, Hawaii, USA. January 3-7, 2001. Singapore: World Scientific Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guodong Zhou</author>
<author>Min Zhang</author>
</authors>
<title>Extracting relation information from text documents by exploring various types of knowledge.</title>
<date>2007</date>
<journal>Information Processing &amp; Management,</journal>
<volume>43</volume>
<issue>4</issue>
<contexts>
<context position="16581" citStr="Zhou and Zhang (2007)" startWordPosition="2552" endWordPosition="2555">, Binding events, we generated binary (trigger, protein) pairs as well as triples (trigger, proteins, protein2) to adequately represent the binding between two proteins.9 Pairs of mentions not connected by a dependency path could not be detected. For the argument extraction we chose two machine learning-based approaches, feature-based and a kernel-based one, as described below.10 3.3.1 Feature-based Classifier We distinguished three groups of features. First, lexical features (covering lexical items before, after and between both mentions (of the event trigger and an argument) as described by Zhou and Zhang (2007)); second, chunking features (concerned with head words of the phrases between two mentions as described by Zhou and Zhang (2007)); third, dependency parse features (considering both the selected dependency levels of the arguments (parents and least common subsumer) as discussed by Katrenko and Adriaans (2006), as well as a shortest dependency path structure between the arguments as used by Kim et al. (2008b) for walk features). For the feature-based approach, we chose the Maximum Entropy (ME) classifier from MALLET.11 3.3.2 Graph Kernel Classifier The graph kernel uses a converted form of dep</context>
</contexts>
<marker>Zhou, Zhang, 2007</marker>
<rawString>Guodong Zhou and Min Zhang. 2007. Extracting relation information from text documents by exploring various types of knowledge. Information Processing &amp; Management, 43(4):969–982.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>