<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000011">
<title confidence="0.993012">
Discriminative Preordering Meets Kendall’s T Maximization
</title>
<author confidence="0.9953">
Sho Hoshino Yusuke Miyao
</author>
<affiliation confidence="0.99466">
National Institute of Informatics / The Graduate University for Advanced Studies, Japan
</affiliation>
<email confidence="0.994573">
{hoshino,yusuke}@nii.ac.jp
</email>
<author confidence="0.857591">
Katsuhito Sudoh Katsuhiko Hayashi Masaaki Nagata
</author>
<affiliation confidence="0.813283">
NTT Communication Science Laboratories, NTT Corporation
</affiliation>
<email confidence="0.998561">
{sudoh.katsuhito,hayashi.katsuhiko,nagata.masaaki}@lab.ntt.co.jp
</email>
<sectionHeader confidence="0.997384" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999778923076923">
This paper explores a simple discrimina-
tive preordering model for statistical ma-
chine translation. Our model traverses
binary constituent trees, and classifies
whether children of each node should be
reordered. The model itself is not ex-
tremely novel, but herein we introduce a
new procedure to determine oracle labels
so as to maximize Kendall’s T. Exper-
iments in Japanese-to-English translation
revealed that our simple method is compa-
rable with, or superior to, state-of-the-art
methods in translation accuracy.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.986631173913044">
Current statistical machine translation systems
suffer from major accuracy degradation in distant
languages, primarily because they utilize excep-
tionally dissimilar word orders. One promising
solution to this problem is preordering, in which
source sentences are reordered to resemble the
target language word orders, after which statis-
tical machine translation is applied to reordered
sentences (Xia and McCord, 2004; Collins et al.,
2005). This is particularly effective for distant lan-
guage pairs such as English and Japanese (Isozaki
et al., 2010b).
Among such preordering, one of the simplest
and straightforward model is a discriminative pre-
ordering model (Li et al., 2007), which classifies
whether children of each constituent node should
be reordered, given binary trees.1 This simple
model has, however, difficulty to find oracle la-
bels. Yang et al. (2012) proposed a method to ap-
proximate oracle labels along dependency trees.
The present paper proposes a new procedure to
find oracle labels. The main idea is simple: we
NP=
</bodyText>
<footnote confidence="0.9882495">
1It is also possible to use n-ary trees (Li et al., 2007; Yang
et al., 2012), but we keep this binary model for simplicity.
</footnote>
<figure confidence="0.476209">
S=M
VP=W
</figure>
<page confidence="0.978135">
139
</page>
<note confidence="0.984645333333333">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 139–144,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.776661" genericHeader="method">
2 Preordering Method S=M
</sectionHeader>
<subsectionHeader confidence="0.859828">
2.1 Discriminative Preordering Model
</subsectionHeader>
<bodyText confidence="0.999647333333333">
The discriminative preordering model (Li et al.,
2007) is a reordering model that determines
whether children of each node should be re-
ordered, given a binary constituent tree. For a sen-
tence with n words, a node in a binary constituent
tree is expressed as v(i, p, j), where 1 &lt; i &lt; p &lt;
p + 1 &lt; j &lt; n. This indicates that the node
takes the left span from i-th to p-th words and the
right span from (p + 1)-th to j-th words. Then
we define whether a node should be reordered as
P(x  |0(v(i, p, j))), where x E {W, M}. W rep-
resents a reverse action (reorder the child nodes),
M represents a monotonic action (do not reorder
the child nodes), and 0 is a feature function that is
described at Section 2.4.
For instance, Figure 1 shows a sentence (n = 4)
that has three binary nodes S, VP, and NP, which
are our reordering candidates. We examine the NP
node v(3, 3, 4) that has a left (binary3) and a right
(classification4) spans, of which reordering is
determined by P(x  |0(v(3, 3, 4))), and is clas-
sified x = M in this example. The actions for the
VP node v(2, 2, 4) and the S root node v(1,1, 4)
are determined in a similar fashion.
Once all classifications are finished, the chil-
dren of the nodes with W are reversed. From the
constituent tree in Figure 1, this reordering pro-
duces a new tree in Figure 2 that represents a re-
ordered sentence Reordering binary classification
is, which is used in statistical machine translation.
</bodyText>
<sectionHeader confidence="0.656758" genericHeader="method">
VBZ
</sectionHeader>
<subsectionHeader confidence="0.999735">
2.2 Oracle Labels Maximizing Kendall’s T
</subsectionHeader>
<bodyText confidence="0.999948933333333">
In order to train such a classifier, we need an ora-
cle label, W or M, for each node. Since we can-
not rely on manual label annotation, we define a
procedure to obtain oracle labels from word align-
ments. The principal idea is that we determine an
oracle label of each node v(i, p, j) so that it max-
imizes Kendall’s T under v(i, p, j). This is intu-
itively a straightforward idea, because our objec-
tive is to find a monotonic order, which indicates
maximization of Kendall’s T.
In the context of statistical machine translation,
Kendall’s T is used as an evaluation metric for
monotonicity of word orderings (Birch and Os-
borne, 2010; Isozaki et al., 2010a; Talbot et al.,
2011). Given an integer list x = x1, ... , x, T(x)
</bodyText>
<equation confidence="0.488818">
VP=W
</equation>
<page confidence="0.700955">
140
</page>
<figure confidence="0.552964166666667">
test9 test10
Settings DL RIBES BLEU RIBES BLEU
Baseline w/o preordering
Moses 0 66.95 26.36 67.50 27.17
Moses 10 68.95 29.41 69.64 30.20
Moses 20 69.88 30.12 70.22 30.51
ti:p, tp+1:j, wi:p, wp+1:j, σ(v(i, p, j)),
ti:p o tp+1:j, wi:p o wp+1:j, σr(v(i, p, j)),
ti:p o tp+1:j o wi:p o wp+1:j, σt(v(i, p, j)),
tl:p, tp+1:r, wl:p, wp+1:r, σw(v(i, p, j))
tl:p o tp+1:r, wl:p o wp+1:r,
tl:p o tp+1:r o wl:p o wp+1:r
</figure>
<tableCaption confidence="0.9424595">
Table 1: Templates for the node v(i, p, j): where
integers l and r satisfy i &lt; l &lt; p &lt; p+1 &lt; r &lt; j.
</tableCaption>
<table confidence="0.99956">
Template Instance Template Instance
t2:2 VBZ w2:2 is
t3:4 JJ NN w3:4 binary classification
t3:3 JJ w3:3 binary
</table>
<tableCaption confidence="0.999162">
Table 2: Examples in v(2, 2, 4) from Figure 1.
</tableCaption>
<equation confidence="0.690493285714286">
Proposed Accuracy Previous Accuracy
Full 90.91
w/o the first set 87.50
w/o σ(v(i, p, j)) 90.76
w/o σr(v(i, p, j)) 90.85
w/o σt(v(i, p, j)) 90.90
w/o σw(v(i, p, j)) 90.88
</equation>
<tableCaption confidence="0.835829">
Table 3: Ablation tests on binary classification ac-
curacy (%).
</tableCaption>
<bodyText confidence="0.941613">
is true, because c(a(i, j)) can be computed in a re-
cursive manner. See c(a(i, j)) is decomposed as:
</bodyText>
<equation confidence="0.937452666666667">
c(a(i, j)) = c(a(i, p)) + c(a(p + 1, j))
+ ∑ S(ak &lt; al).
kE[i,p],lE[p+1,j]
</equation>
<bodyText confidence="0.999765428571429">
The three terms in this formula are mutually inde-
pendent. That is, any reordering of a(i, p) changes
only the first term and the others are unchanged.
We maximize c(a(i, j)) by maximizing each term.
Since the first and the second terms are maxi-
mized recursively, our method directly maximizes
the third term, which corresponds to our oracle la-
bels, hence c(a) and T(a) of entire sentence.3
Essentially, our decisions on each node are
equivalent to sorting a list consists of left and right
points, while the order of the points inside of left
and right lists are left untouched. We determine or-
acle labels for a given constituent tree by comput-
ing s(v(i, p, j)) for every v(i, p, j) independently.
</bodyText>
<footnote confidence="0.851802">
3Oracle labels guarantee τ(a) &gt; 0, but not τ(a) = 1,
because parsed trees will not correspond to word alignments.
</footnote>
<subsectionHeader confidence="0.307935">
Proposed preordering
</subsectionHeader>
<bodyText confidence="0.95027525">
Giza 0 77.49 33.08 77.49 33.65
Giza 10 77.44 33.28 77.42 33.77
Nile 0 77.74 32.97 77.89 33.91
Nile 10 77.97 33.55 78.07 34.13
</bodyText>
<tableCaption confidence="0.623884">
Table 4: Results in Japanese-to-English transla-
</tableCaption>
<bodyText confidence="0.99367">
tion. Boldfaces denote the highest scores and the
insignificant difference (p &lt; 0.01) from the high-
est scores in bootstrap resampling (Koehn, 2004).
</bodyText>
<subsectionHeader confidence="0.915464">
2.4 Features
</subsectionHeader>
<bodyText confidence="0.99967392">
Table 1 shows the templates for the node v(i, p, j)
of the feature function 0 in Section 2.1. To tell the
differences between the left span a(i, p) and the
right span a(p + 1, j), such as whether the head
word of the node is in left or right, the first set
of templates considers individual indices x:y that
denote the span from x-th to y-th words: where
tx represents a part-of-speech feature; wx repre-
sents a lexical feature; and o represents feature
combination. The second set of templates consid-
ers constituent structures of the node by supply-
ing three S-expressions and parent-child relations:
where Q(v(i, p, j)) represents a constituent struc-
ture under the node v(i, p, j); Qr(v(i, p, j)) rep-
resents part-of-speech tags of the node and their
parent-child relations; Qt(v(i, p, j)) represents the
constituent structure including only part-of-speech
tags; and Q,,,(v(i, p, j)) represents the constituent
structure including only surface words.
Table 2 shows instances of features for the VP
node v(2, 2, 4) in Figure 1, which has the left (is2)
and the right (binary3 classification4) spans.
Table 3 shows ablation test results on binary
classification, which indicate that our templates
performed better than that of Li et al. (2007).
</bodyText>
<sectionHeader confidence="0.999931" genericHeader="method">
3 Experiment
</sectionHeader>
<subsectionHeader confidence="0.999389">
3.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.999760833333333">
We perform experiments over the NTCIR patent
corpus (Goto et al., 2011) that consists of more
than 3 million sentences in English and Japanese.
Following conventional literature settings (Goto et
al., 2012; Hayashi et al., 2013), we used all 3
million sentences from the NTCIR-7 and NTCIR-
</bodyText>
<equation confidence="0.586890333333333">
Template Instance
σ(v(2, 2, 4)) (VP(VBZis)(NP(JJbinary)(NNclassification)))
σr(v(2, 2, 4)) VP VBZ NP JJ NN VP VBZ VP NP NP JJ NP NN
σt(v(2, 2, 4)) (VP(VBZ)(NP(JJ)(NN)))
σw(v(2, 2, 4)) ((is)((binary)(classification)))
Li et al. (2007) 84.43
</equation>
<page confidence="0.769681">
141
</page>
<table confidence="0.979927454545454">
Reordering Methods DL RIBES test9 ∆ RIBES test10 ∆
∆ BLEU ∆ BLEU
Moses 20 69.88 30.12 70.22 30.51
Proposed preordering 10 77.97 +8.09 33.55 +3.43 78.07 +7.85 34.13 +3.62
Moses (Hoshino et al., 2013) 20 68.08 27.57
Preordering (Hoshino et al., 2013) 10 72.37 +4.29 30.56 +2.99
Moses (Goto et al., 2012) 20 68.28 30.20
Moses-chart (Goto et al., 2012) 70.64 +2.36 30.69 +0.49
Postordering (Goto et al., 2012) 75.48 +7.20 33.04 +2.84
Moses (Hayashi et al., 2013) 20 69.31 29.43 68.90 29.99
Postordering (Hayashi et al., 2013) 0 76.46 +7.15 32.59 +3.16 76.76 +7.86 33.14 +3.15
</table>
<tableCaption confidence="0.982504">
Table 5: Comparison with previous systems in Japanese-to-English translation, of which scores are
retrieved from their papers. Boldfaces indicate the highest scores and differences.
</tableCaption>
<bodyText confidence="0.99255356">
8 training sets, used the first 1000 sentences in
NTCIR-8 development set, and then fetched both
the NTCIR-9 and NTCIR-10 testing sets. The ma-
chine translation experiments pipelined Moses 3
(Koehn et al., 2007) with lexicalized reordering,
SRILM 1.7.0 (Stolcke et al., 2011) in 6-gram or-
der, MGIZA (Gao and Vogel, 2008), and RIBES
(Isozaki et al., 2010a) and BLEU (Papineni et al.,
2002) for evaluation. Binary constituent parsing
in Japanese used Haruniwa (Fang et al., 2014),
Berkeley parser 1.7 (Petrov and Klein, 2007), Co-
mainu 0.7.0 (Kozawa et al., 2014), MeCab 0.996
(Kudo et al., 2004), and Unidic 2.1.2.
We explore two types of word alignment data
for training our preordering model. The first
data (Giza) is created by running an unsuper-
vised aligner Giza (Och and Ney, 2003) on the
training data (3 million sentences). The second
data (Nile) is developed by training a supervised
aligner Nile (Riesa et al., 2011) with manually an-
notated 8,000 sentences, then applied the trained
alignment model to remaining training data. In
the evaluation on manually annotated 1,000 sen-
tences4, Giza achieved F1 50.1 score, while Nile
achieved F1 86.9 score, for word alignment task.
</bodyText>
<subsectionHeader confidence="0.990453">
3.2 Result
</subsectionHeader>
<bodyText confidence="0.973469019607843">
Table 4 shows the performance of our method,
which indicates that our preordering significantly
improved translation accuracy in both RIBES and
BLEU scores, from the baseline result attained
by Moses without preordering. In particular, the
preordering model trained with the Giza data re-
vealed a substantial improvement, while the use
of the Nile data further improves accuracy. This
suggests that our method is particularly effective
when high-accuracy word alignments are given. In
4This testing data is excluded from latter experiments.
addition, we achieved modest improvements even
with DL=0 (no distortion allowed), which indi-
cates the monotonicity of our reordered sentences.
Table 5 shows a comparison of the proposed
method with a rule-based preordering method
(Hoshino et al., 2013) and two postordering meth-
ods (Goto et al., 2012; Hayashi et al., 2013).5 One
complication is that each work reports different
baseline accuracy, although Moses is shared as a
baseline, because these systems differ in various
settings in data preprocessing, tokenization crite-
ria, etc. Since this makes a fair comparison diffi-
cult, we additionally put a score difference (∆) of
each system from its own baseline.
Our proposed method showed translation ac-
curacy comparable with, or superior to, state-of-
the-art methods. This highlights the importance
of Kendall’s T maximization in the simple dis-
criminative preordering model. In contrast to a
substantial gain in RIBES, we attained a rather
comparable gain in BLEU. The investigation of
our translation suggests that insufficient genera-
tion of English articles caused a significant degra-
dation in the BLEU score. Previous systems listed
in Table 5 incorporated article generation and
demonstrated its positive effect (Goto et al., 2012;
Hayashi et al., 2013). While we achieved state-of-
the-art accuracy without language-specific tech-
niques, it is also a promising direction to integrate
our preordering method with language-specific
techniques such as article generation and subject
generation (Kudo et al., 2014).
5We could not find a comparable report using tree-based
machine translation systems apart from Moses-chart; never-
theless, Neubig and Duh (2014) reported that their forest-
to-string system on the same corpus, which is unfortunately
evaluated on the different testing data (test7), showed RIBES
+6.19 (75.94) and BLEU +2.93 (33.70) improvements. Al-
though not directly comparable, our method achieves a com-
parable or superior improvement.
</bodyText>
<page confidence="0.998072">
142
</page>
<sectionHeader confidence="0.999944" genericHeader="evaluation">
4 Related Work
</sectionHeader>
<bodyText confidence="0.999991717948718">
Li et al. (2007) proposed a simple discriminative
preordering model as described in Section 2.1.
They employed heuristics that utilize Giza to align
their training sentences, then sort source words to
resemble target word indices. After that, sorted
source sentences without overlaps are used to train
the model. They gained BLEU +1.54 improve-
ment in Chinese-to-English evaluation. Our pro-
posal follows their model, while we do not rely on
their heuristics for preparing training data.
Lerner and Petrov (2013) proposed another
discriminative preordering model along depen-
dency trees, which classifies whether the parent
of each node should be the head in target lan-
guage. They reported BLEU +3.7 improvement
in English-to-Japanese translation. Hoshino et al.
(2013) proposed a similar but rule-based method
for Japanese-to-English dependency preordering.
Yang et al. (2012) proposed a method to pro-
duce oracle reordering in the discriminative pre-
ordering model along dependency trees. Their
idea behind is to minimize word alignment cross-
ing recursively, which is essentially the same re-
ordering objective as our Kendall’s T maximiza-
tion. Since they targeted complex n-ary depen-
dency instead of simple binary trees, their method
only calculates approximated oracle reordering in
practice by ranking principle. We did not take
n-ary trees into consideration to follow the sim-
ple discriminative preordering model along con-
stituency, while the use of binary trees enabled us
to produce strict oracle reordering as a side effect.
Another research direction called postordering
(Sudoh et al., 2011; Goto et al., 2012; Hayashi
et al., 2013) has been explored in Japanese-to-
English translation. They first translate Japanese
input into head final English texts obtained by the
method of Isozaki et al. (2010b), then reorder head
final English texts into English word orders.
</bodyText>
<sectionHeader confidence="0.996909" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999955142857143">
We proposed a simple procedure to train a discrim-
inative preordering model. The main idea is to
obtain oracle labels for each node by maximizing
Kendall’s T of word alignments. Experiments in
Japanese-to-English translation demonstrated that
our procedure, without language-specific heuris-
tics, achieved state-of-the-art translation accuracy.
</bodyText>
<sectionHeader confidence="0.985219" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999899">
We would like to thank Kevin Duh, Atsushi Fujita,
Taku Kudo, Shinsuke Mori, Toshiaki Nakazawa,
Graham Neubig, Hiroshi Noji, and anonymous re-
viewers for their insightful comments.
</bodyText>
<sectionHeader confidence="0.922428" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.954408042553191">
Alexandra Birch and Miles Osborne. 2010. LRscore
for evaluating lexical and reordering quality in MT.
In Proceedings of the Joint Fifth Workshop on Statis-
tical Machine Translation and MetricsMATR, pages
327–332.
Michael Collins, Philipp Koehn, and Ivona Kucerova.
2005. Clause restructuring for statistical machine
translation. In Proceedings of the 43rd Annual
Meeting of the Association for Computational Lin-
guistics, pages 531–540.
Tsaiwei Fang, Alastair Butler, and Kei Yoshimoto.
2014. Parsing Japanese with a PCFG treebank
grammar. In Proceedings of the Twentieth Meeting
of the Association for Natural Language Processing,
pages 432–435.
Qin Gao and Stephan Vogel. 2008. Parallel implemen-
tations of word alignment tool. In Software Engi-
neering, Testing, and Quality Assurance for Natural
Language Processing, pages 49–57.
Isao Goto, Bin Lu, Ka Po Chow, Eiichiro Sumita, and
Benjamin K. Tsou. 2011. Overview of the patent
machine translation task at the NTCIR-9 workshop.
In Proceedings of the NTCIR-9 Workshop Meeting,
pages 559–578.
Isao Goto, Masao Utiyama, and Eiichiro Sumita. 2012.
Post-ordering by parsing for Japanese-English sta-
tistical machine translation. In Proceedings of the
50th Annual Meeting of the Association for Compu-
tational Linguistics, pages 311–316.
Katsuhiko Hayashi, Katsuhito Sudoh, Hajime Tsukada,
Jun Suzuki, and Masaaki Nagata. 2013. Shift-
reduce word reordering for machine translation. In
Proceedings of the 2013 Conference on Empirical
Methods in Natural Language Processing, pages
1382–1386.
Sho Hoshino, Yusuke Miyao, Katsuhito Sudoh, and
Masaaki Nagata. 2013. Two-stage pre-ordering
for Japanese-to-English statistical machine transla-
tion. In Proceedings of the Sixth International Joint
Conference on Natural Language Processing, pages
1062–1066.
Hideki Isozaki, Tsutomu Hirao, Kevin Duh, Katsuhito
Sudoh, and Hajime Tsukada. 2010a. Automatic
evaluation of translation quality for distant language
pairs. In Proceedings of the 2010 Conference on
Empirical Methods in Natural Language Process-
ing, pages 944–952.
</reference>
<page confidence="0.995813">
143
</page>
<reference confidence="0.99816155319149">
Hideki Isozaki, Katsuhito Sudoh, Hajime Tsukada, and
Kevin Duh. 2010b. Head finalization: A simple
reordering rule for SOV languages. In Proceedings
of the Joint Fifth Workshop on Statistical Machine
Translation and MetricsMATR, pages 244–251.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proceedings of the 45th Annual Meeting of the As-
sociation for Computational Linguistics, pages 177–
180.
Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Proceedings of
the 2004 Conference on Empirical Methods in Nat-
ural Language Processing, pages 388–395.
Shunsuke Kozawa, Kiyotaka Uchimoto, and Yasuharu
Den. 2014. Adaptation of long-unit-word anal-
ysis system to different part-of-speech tagset (in
Japanese). Journal of Natural Language Process-
ing, 21(2):379–401.
Taku Kudo, Kaoru Yamamoto, and Yuji Matsumoto.
2004. Applying conditional random fields to
japanese morphological analysis. In Proceedings of
the 2004 Conference on Empirical Methods in Nat-
ural Language Processing, pages 230–237.
Taku Kudo, Hiroshi Ichikawa, and Hideto Kazawa.
2014. A joint inference of deep case analysis and
zero subject generation for Japanese-to-English sta-
tistical machine translation. In Proceedings of the
52nd Annual Meeting of the Association for Compu-
tational Linguistics, pages 557–562.
Uri Lerner and Slav Petrov. 2013. Source-side classi-
fier preordering for machine translation. In Proceed-
ings of the 2013 Conference on Empirical Methods
in Natural Language Processing, pages 513–523.
Chi-Ho Li, Minghui Li, Dongdong Zhang, Mu Li,
Ming Zhou, and Yi Guan. 2007. A probabilistic
approach to syntax-based reordering for statistical
machine translation. In Proceedings of the 45th An-
nual Meeting of the Association of Computational
Linguistics, pages 720–727.
Graham Neubig and Kevin Duh. 2014. On the ele-
ments of an accurate tree-to-string machine trans-
lation system. In Proceedings of the 52nd Annual
Meeting of the Association for Computational Lin-
guistics, pages 143–149.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19–51.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings
of 40th Annual Meeting of the Association for Com-
putational Linguistics, pages 311–318.
Slav Petrov and Dan Klein. 2007. Improved infer-
ence for unlexicalized parsing. In Human Language
Technologies 2007: The Conference of the North
American Chapter of the Association for Computa-
tional Linguistics; Proceedings of the Main Confer-
ence, pages 404–411.
Jason Riesa, Ann Irvine, and Daniel Marcu. 2011.
Feature-rich language-independent syntax-based
alignment for statistical machine translation. In
Proceedings of the 2011 Conference on Empirical
Methods in Natural Language Processing, pages
497–507.
Andreas Stolcke, Jing Zheng, Wen Wang, and Victor
Abrash. 2011. SRILM at sixteen: Update and out-
look. In Proceedings of the IEEE Automatic Speech
Recognition and Understanding Workshop.
Katsuhito Sudoh, Xianchao Wu, Kevin Duh, Hajime
Tsukada, and Masaaki Nagata. 2011. Post-ordering
in statistical machine translation. In Proceedings of
the Machine Translation Summit XIII, pages 316–
323.
David Talbot, Hideto Kazawa, Hiroshi Ichikawa, Ja-
son Katz-Brown, Masakazu Seno, and Franz Och.
2011. A lightweight evaluation framework for ma-
chine translation reordering. In Proceedings of the
Sixth Workshop on Statistical Machine Translation,
pages 12–21.
Fei Xia and Michael McCord. 2004. Improving
a statistical MT system with automatically learned
rewrite patterns. In Proceedings of the 20th Inter-
national Conference on Computational Linguistics,
pages 508–514.
Nan Yang, Mu Li, Dongdong Zhang, and Nenghai Yu.
2012. A ranking-based approach to word reordering
for statistical machine translation. In Proceedings
of the 50th Annual Meeting of the Association for
Computational Linguistics, pages 912–920.
</reference>
<page confidence="0.998594">
144
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.697816">
<title confidence="0.99992">Preordering Meets Kendall’s</title>
<author confidence="0.992169">Sho Hoshino Yusuke Miyao</author>
<affiliation confidence="0.990286">National Institute of Informatics / The Graduate University for Advanced Studies,</affiliation>
<author confidence="0.717569">Katsuhito Sudoh Katsuhiko Hayashi Masaaki</author>
<affiliation confidence="0.992015">NTT Communication Science Laboratories, NTT Corporation</affiliation>
<abstract confidence="0.999312214285714">This paper explores a simple discriminative preordering model for statistical machine translation. Our model traverses binary constituent trees, and classifies whether children of each node should be reordered. The model itself is not extremely novel, but herein we introduce a new procedure to determine oracle labels as to maximize Kendall’s Experiments in Japanese-to-English translation revealed that our simple method is comparable with, or superior to, state-of-the-art methods in translation accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alexandra Birch</author>
<author>Miles Osborne</author>
</authors>
<title>LRscore for evaluating lexical and reordering quality in MT.</title>
<date>2010</date>
<booktitle>In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR,</booktitle>
<pages>327--332</pages>
<contexts>
<context position="4521" citStr="Birch and Osborne, 2010" startWordPosition="734" endWordPosition="738">der to train such a classifier, we need an oracle label, W or M, for each node. Since we cannot rely on manual label annotation, we define a procedure to obtain oracle labels from word alignments. The principal idea is that we determine an oracle label of each node v(i, p, j) so that it maximizes Kendall’s T under v(i, p, j). This is intuitively a straightforward idea, because our objective is to find a monotonic order, which indicates maximization of Kendall’s T. In the context of statistical machine translation, Kendall’s T is used as an evaluation metric for monotonicity of word orderings (Birch and Osborne, 2010; Isozaki et al., 2010a; Talbot et al., 2011). Given an integer list x = x1, ... , x, T(x) VP=W 140 test9 test10 Settings DL RIBES BLEU RIBES BLEU Baseline w/o preordering Moses 0 66.95 26.36 67.50 27.17 Moses 10 68.95 29.41 69.64 30.20 Moses 20 69.88 30.12 70.22 30.51 ti:p, tp+1:j, wi:p, wp+1:j, σ(v(i, p, j)), ti:p o tp+1:j, wi:p o wp+1:j, σr(v(i, p, j)), ti:p o tp+1:j o wi:p o wp+1:j, σt(v(i, p, j)), tl:p, tp+1:r, wl:p, wp+1:r, σw(v(i, p, j)) tl:p o tp+1:r, wl:p o wp+1:r, tl:p o tp+1:r o wl:p o wp+1:r Table 1: Templates for the node v(i, p, j): where integers l and r satisfy i &lt; l &lt; p &lt; p+1 </context>
</contexts>
<marker>Birch, Osborne, 2010</marker>
<rawString>Alexandra Birch and Miles Osborne. 2010. LRscore for evaluating lexical and reordering quality in MT. In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, pages 327–332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Philipp Koehn</author>
<author>Ivona Kucerova</author>
</authors>
<title>Clause restructuring for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>531--540</pages>
<contexts>
<context position="1347" citStr="Collins et al., 2005" startWordPosition="174" endWordPosition="177"> Experiments in Japanese-to-English translation revealed that our simple method is comparable with, or superior to, state-of-the-art methods in translation accuracy. 1 Introduction Current statistical machine translation systems suffer from major accuracy degradation in distant languages, primarily because they utilize exceptionally dissimilar word orders. One promising solution to this problem is preordering, in which source sentences are reordered to resemble the target language word orders, after which statistical machine translation is applied to reordered sentences (Xia and McCord, 2004; Collins et al., 2005). This is particularly effective for distant language pairs such as English and Japanese (Isozaki et al., 2010b). Among such preordering, one of the simplest and straightforward model is a discriminative preordering model (Li et al., 2007), which classifies whether children of each constituent node should be reordered, given binary trees.1 This simple model has, however, difficulty to find oracle labels. Yang et al. (2012) proposed a method to approximate oracle labels along dependency trees. The present paper proposes a new procedure to find oracle labels. The main idea is simple: we NP= 1It </context>
</contexts>
<marker>Collins, Koehn, Kucerova, 2005</marker>
<rawString>Michael Collins, Philipp Koehn, and Ivona Kucerova. 2005. Clause restructuring for statistical machine translation. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 531–540.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tsaiwei Fang</author>
<author>Alastair Butler</author>
<author>Kei Yoshimoto</author>
</authors>
<title>Parsing Japanese with a PCFG treebank grammar.</title>
<date>2014</date>
<booktitle>In Proceedings of the Twentieth Meeting of the Association for Natural Language Processing,</booktitle>
<pages>432--435</pages>
<contexts>
<context position="9907" citStr="Fang et al., 2014" startWordPosition="1655" endWordPosition="1658">s in Japanese-to-English translation, of which scores are retrieved from their papers. Boldfaces indicate the highest scores and differences. 8 training sets, used the first 1000 sentences in NTCIR-8 development set, and then fetched both the NTCIR-9 and NTCIR-10 testing sets. The machine translation experiments pipelined Moses 3 (Koehn et al., 2007) with lexicalized reordering, SRILM 1.7.0 (Stolcke et al., 2011) in 6-gram order, MGIZA (Gao and Vogel, 2008), and RIBES (Isozaki et al., 2010a) and BLEU (Papineni et al., 2002) for evaluation. Binary constituent parsing in Japanese used Haruniwa (Fang et al., 2014), Berkeley parser 1.7 (Petrov and Klein, 2007), Comainu 0.7.0 (Kozawa et al., 2014), MeCab 0.996 (Kudo et al., 2004), and Unidic 2.1.2. We explore two types of word alignment data for training our preordering model. The first data (Giza) is created by running an unsupervised aligner Giza (Och and Ney, 2003) on the training data (3 million sentences). The second data (Nile) is developed by training a supervised aligner Nile (Riesa et al., 2011) with manually annotated 8,000 sentences, then applied the trained alignment model to remaining training data. In the evaluation on manually annotated 1,</context>
</contexts>
<marker>Fang, Butler, Yoshimoto, 2014</marker>
<rawString>Tsaiwei Fang, Alastair Butler, and Kei Yoshimoto. 2014. Parsing Japanese with a PCFG treebank grammar. In Proceedings of the Twentieth Meeting of the Association for Natural Language Processing, pages 432–435.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qin Gao</author>
<author>Stephan Vogel</author>
</authors>
<title>Parallel implementations of word alignment tool.</title>
<date>2008</date>
<booktitle>In Software Engineering, Testing, and Quality Assurance for Natural Language Processing,</booktitle>
<pages>49--57</pages>
<contexts>
<context position="9750" citStr="Gao and Vogel, 2008" startWordPosition="1630" endWordPosition="1633">2013) 20 69.31 29.43 68.90 29.99 Postordering (Hayashi et al., 2013) 0 76.46 +7.15 32.59 +3.16 76.76 +7.86 33.14 +3.15 Table 5: Comparison with previous systems in Japanese-to-English translation, of which scores are retrieved from their papers. Boldfaces indicate the highest scores and differences. 8 training sets, used the first 1000 sentences in NTCIR-8 development set, and then fetched both the NTCIR-9 and NTCIR-10 testing sets. The machine translation experiments pipelined Moses 3 (Koehn et al., 2007) with lexicalized reordering, SRILM 1.7.0 (Stolcke et al., 2011) in 6-gram order, MGIZA (Gao and Vogel, 2008), and RIBES (Isozaki et al., 2010a) and BLEU (Papineni et al., 2002) for evaluation. Binary constituent parsing in Japanese used Haruniwa (Fang et al., 2014), Berkeley parser 1.7 (Petrov and Klein, 2007), Comainu 0.7.0 (Kozawa et al., 2014), MeCab 0.996 (Kudo et al., 2004), and Unidic 2.1.2. We explore two types of word alignment data for training our preordering model. The first data (Giza) is created by running an unsupervised aligner Giza (Och and Ney, 2003) on the training data (3 million sentences). The second data (Nile) is developed by training a supervised aligner Nile (Riesa et al., 2</context>
</contexts>
<marker>Gao, Vogel, 2008</marker>
<rawString>Qin Gao and Stephan Vogel. 2008. Parallel implementations of word alignment tool. In Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 49–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isao Goto</author>
<author>Bin Lu</author>
<author>Ka Po Chow</author>
<author>Eiichiro Sumita</author>
<author>Benjamin K Tsou</author>
</authors>
<title>Overview of the patent machine translation task at the NTCIR-9 workshop.</title>
<date>2011</date>
<booktitle>In Proceedings of the NTCIR-9 Workshop Meeting,</booktitle>
<pages>559--578</pages>
<contexts>
<context position="8216" citStr="Goto et al., 2011" startWordPosition="1385" endWordPosition="1388"> node and their parent-child relations; Qt(v(i, p, j)) represents the constituent structure including only part-of-speech tags; and Q,,,(v(i, p, j)) represents the constituent structure including only surface words. Table 2 shows instances of features for the VP node v(2, 2, 4) in Figure 1, which has the left (is2) and the right (binary3 classification4) spans. Table 3 shows ablation test results on binary classification, which indicate that our templates performed better than that of Li et al. (2007). 3 Experiment 3.1 Experimental Settings We perform experiments over the NTCIR patent corpus (Goto et al., 2011) that consists of more than 3 million sentences in English and Japanese. Following conventional literature settings (Goto et al., 2012; Hayashi et al., 2013), we used all 3 million sentences from the NTCIR-7 and NTCIRTemplate Instance σ(v(2, 2, 4)) (VP(VBZis)(NP(JJbinary)(NNclassification))) σr(v(2, 2, 4)) VP VBZ NP JJ NN VP VBZ VP NP NP JJ NP NN σt(v(2, 2, 4)) (VP(VBZ)(NP(JJ)(NN))) σw(v(2, 2, 4)) ((is)((binary)(classification))) Li et al. (2007) 84.43 141 Reordering Methods DL RIBES test9 ∆ RIBES test10 ∆ ∆ BLEU ∆ BLEU Moses 20 69.88 30.12 70.22 30.51 Proposed preordering 10 77.97 +8.09 33.55</context>
</contexts>
<marker>Goto, Lu, Chow, Sumita, Tsou, 2011</marker>
<rawString>Isao Goto, Bin Lu, Ka Po Chow, Eiichiro Sumita, and Benjamin K. Tsou. 2011. Overview of the patent machine translation task at the NTCIR-9 workshop. In Proceedings of the NTCIR-9 Workshop Meeting, pages 559–578.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isao Goto</author>
<author>Masao Utiyama</author>
<author>Eiichiro Sumita</author>
</authors>
<title>Post-ordering by parsing for Japanese-English statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--316</pages>
<contexts>
<context position="8350" citStr="Goto et al., 2012" startWordPosition="1405" endWordPosition="1408">,(v(i, p, j)) represents the constituent structure including only surface words. Table 2 shows instances of features for the VP node v(2, 2, 4) in Figure 1, which has the left (is2) and the right (binary3 classification4) spans. Table 3 shows ablation test results on binary classification, which indicate that our templates performed better than that of Li et al. (2007). 3 Experiment 3.1 Experimental Settings We perform experiments over the NTCIR patent corpus (Goto et al., 2011) that consists of more than 3 million sentences in English and Japanese. Following conventional literature settings (Goto et al., 2012; Hayashi et al., 2013), we used all 3 million sentences from the NTCIR-7 and NTCIRTemplate Instance σ(v(2, 2, 4)) (VP(VBZis)(NP(JJbinary)(NNclassification))) σr(v(2, 2, 4)) VP VBZ NP JJ NN VP VBZ VP NP NP JJ NP NN σt(v(2, 2, 4)) (VP(VBZ)(NP(JJ)(NN))) σw(v(2, 2, 4)) ((is)((binary)(classification))) Li et al. (2007) 84.43 141 Reordering Methods DL RIBES test9 ∆ RIBES test10 ∆ ∆ BLEU ∆ BLEU Moses 20 69.88 30.12 70.22 30.51 Proposed preordering 10 77.97 +8.09 33.55 +3.43 78.07 +7.85 34.13 +3.62 Moses (Hoshino et al., 2013) 20 68.08 27.57 Preordering (Hoshino et al., 2013) 10 72.37 +4.29 30.56 +2.</context>
<context position="11463" citStr="Goto et al., 2012" startWordPosition="1900" endWordPosition="1903"> particular, the preordering model trained with the Giza data revealed a substantial improvement, while the use of the Nile data further improves accuracy. This suggests that our method is particularly effective when high-accuracy word alignments are given. In 4This testing data is excluded from latter experiments. addition, we achieved modest improvements even with DL=0 (no distortion allowed), which indicates the monotonicity of our reordered sentences. Table 5 shows a comparison of the proposed method with a rule-based preordering method (Hoshino et al., 2013) and two postordering methods (Goto et al., 2012; Hayashi et al., 2013).5 One complication is that each work reports different baseline accuracy, although Moses is shared as a baseline, because these systems differ in various settings in data preprocessing, tokenization criteria, etc. Since this makes a fair comparison difficult, we additionally put a score difference (∆) of each system from its own baseline. Our proposed method showed translation accuracy comparable with, or superior to, state-ofthe-art methods. This highlights the importance of Kendall’s T maximization in the simple discriminative preordering model. In contrast to a subst</context>
<context position="14746" citStr="Goto et al., 2012" startWordPosition="2395" endWordPosition="2398">a behind is to minimize word alignment crossing recursively, which is essentially the same reordering objective as our Kendall’s T maximization. Since they targeted complex n-ary dependency instead of simple binary trees, their method only calculates approximated oracle reordering in practice by ranking principle. We did not take n-ary trees into consideration to follow the simple discriminative preordering model along constituency, while the use of binary trees enabled us to produce strict oracle reordering as a side effect. Another research direction called postordering (Sudoh et al., 2011; Goto et al., 2012; Hayashi et al., 2013) has been explored in Japanese-toEnglish translation. They first translate Japanese input into head final English texts obtained by the method of Isozaki et al. (2010b), then reorder head final English texts into English word orders. 5 Conclusion We proposed a simple procedure to train a discriminative preordering model. The main idea is to obtain oracle labels for each node by maximizing Kendall’s T of word alignments. Experiments in Japanese-to-English translation demonstrated that our procedure, without language-specific heuristics, achieved state-of-the-art translati</context>
</contexts>
<marker>Goto, Utiyama, Sumita, 2012</marker>
<rawString>Isao Goto, Masao Utiyama, and Eiichiro Sumita. 2012. Post-ordering by parsing for Japanese-English statistical machine translation. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 311–316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katsuhiko Hayashi</author>
<author>Katsuhito Sudoh</author>
<author>Hajime Tsukada</author>
<author>Jun Suzuki</author>
<author>Masaaki Nagata</author>
</authors>
<title>Shiftreduce word reordering for machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1382--1386</pages>
<contexts>
<context position="8373" citStr="Hayashi et al., 2013" startWordPosition="1409" endWordPosition="1412">sents the constituent structure including only surface words. Table 2 shows instances of features for the VP node v(2, 2, 4) in Figure 1, which has the left (is2) and the right (binary3 classification4) spans. Table 3 shows ablation test results on binary classification, which indicate that our templates performed better than that of Li et al. (2007). 3 Experiment 3.1 Experimental Settings We perform experiments over the NTCIR patent corpus (Goto et al., 2011) that consists of more than 3 million sentences in English and Japanese. Following conventional literature settings (Goto et al., 2012; Hayashi et al., 2013), we used all 3 million sentences from the NTCIR-7 and NTCIRTemplate Instance σ(v(2, 2, 4)) (VP(VBZis)(NP(JJbinary)(NNclassification))) σr(v(2, 2, 4)) VP VBZ NP JJ NN VP VBZ VP NP NP JJ NP NN σt(v(2, 2, 4)) (VP(VBZ)(NP(JJ)(NN))) σw(v(2, 2, 4)) ((is)((binary)(classification))) Li et al. (2007) 84.43 141 Reordering Methods DL RIBES test9 ∆ RIBES test10 ∆ ∆ BLEU ∆ BLEU Moses 20 69.88 30.12 70.22 30.51 Proposed preordering 10 77.97 +8.09 33.55 +3.43 78.07 +7.85 34.13 +3.62 Moses (Hoshino et al., 2013) 20 68.08 27.57 Preordering (Hoshino et al., 2013) 10 72.37 +4.29 30.56 +2.99 Moses (Goto et al., </context>
<context position="11486" citStr="Hayashi et al., 2013" startWordPosition="1904" endWordPosition="1907">eordering model trained with the Giza data revealed a substantial improvement, while the use of the Nile data further improves accuracy. This suggests that our method is particularly effective when high-accuracy word alignments are given. In 4This testing data is excluded from latter experiments. addition, we achieved modest improvements even with DL=0 (no distortion allowed), which indicates the monotonicity of our reordered sentences. Table 5 shows a comparison of the proposed method with a rule-based preordering method (Hoshino et al., 2013) and two postordering methods (Goto et al., 2012; Hayashi et al., 2013).5 One complication is that each work reports different baseline accuracy, although Moses is shared as a baseline, because these systems differ in various settings in data preprocessing, tokenization criteria, etc. Since this makes a fair comparison difficult, we additionally put a score difference (∆) of each system from its own baseline. Our proposed method showed translation accuracy comparable with, or superior to, state-ofthe-art methods. This highlights the importance of Kendall’s T maximization in the simple discriminative preordering model. In contrast to a substantial gain in RIBES, w</context>
<context position="14769" citStr="Hayashi et al., 2013" startWordPosition="2399" endWordPosition="2402">mize word alignment crossing recursively, which is essentially the same reordering objective as our Kendall’s T maximization. Since they targeted complex n-ary dependency instead of simple binary trees, their method only calculates approximated oracle reordering in practice by ranking principle. We did not take n-ary trees into consideration to follow the simple discriminative preordering model along constituency, while the use of binary trees enabled us to produce strict oracle reordering as a side effect. Another research direction called postordering (Sudoh et al., 2011; Goto et al., 2012; Hayashi et al., 2013) has been explored in Japanese-toEnglish translation. They first translate Japanese input into head final English texts obtained by the method of Isozaki et al. (2010b), then reorder head final English texts into English word orders. 5 Conclusion We proposed a simple procedure to train a discriminative preordering model. The main idea is to obtain oracle labels for each node by maximizing Kendall’s T of word alignments. Experiments in Japanese-to-English translation demonstrated that our procedure, without language-specific heuristics, achieved state-of-the-art translation accuracy. Acknowledg</context>
</contexts>
<marker>Hayashi, Sudoh, Tsukada, Suzuki, Nagata, 2013</marker>
<rawString>Katsuhiko Hayashi, Katsuhito Sudoh, Hajime Tsukada, Jun Suzuki, and Masaaki Nagata. 2013. Shiftreduce word reordering for machine translation. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1382–1386.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sho Hoshino</author>
<author>Yusuke Miyao</author>
<author>Katsuhito Sudoh</author>
<author>Masaaki Nagata</author>
</authors>
<title>Two-stage pre-ordering for Japanese-to-English statistical machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the Sixth International Joint Conference on Natural Language Processing,</booktitle>
<pages>1062--1066</pages>
<contexts>
<context position="8875" citStr="Hoshino et al., 2013" startWordPosition="1491" endWordPosition="1494">sentences in English and Japanese. Following conventional literature settings (Goto et al., 2012; Hayashi et al., 2013), we used all 3 million sentences from the NTCIR-7 and NTCIRTemplate Instance σ(v(2, 2, 4)) (VP(VBZis)(NP(JJbinary)(NNclassification))) σr(v(2, 2, 4)) VP VBZ NP JJ NN VP VBZ VP NP NP JJ NP NN σt(v(2, 2, 4)) (VP(VBZ)(NP(JJ)(NN))) σw(v(2, 2, 4)) ((is)((binary)(classification))) Li et al. (2007) 84.43 141 Reordering Methods DL RIBES test9 ∆ RIBES test10 ∆ ∆ BLEU ∆ BLEU Moses 20 69.88 30.12 70.22 30.51 Proposed preordering 10 77.97 +8.09 33.55 +3.43 78.07 +7.85 34.13 +3.62 Moses (Hoshino et al., 2013) 20 68.08 27.57 Preordering (Hoshino et al., 2013) 10 72.37 +4.29 30.56 +2.99 Moses (Goto et al., 2012) 20 68.28 30.20 Moses-chart (Goto et al., 2012) 70.64 +2.36 30.69 +0.49 Postordering (Goto et al., 2012) 75.48 +7.20 33.04 +2.84 Moses (Hayashi et al., 2013) 20 69.31 29.43 68.90 29.99 Postordering (Hayashi et al., 2013) 0 76.46 +7.15 32.59 +3.16 76.76 +7.86 33.14 +3.15 Table 5: Comparison with previous systems in Japanese-to-English translation, of which scores are retrieved from their papers. Boldfaces indicate the highest scores and differences. 8 training sets, used the first 1000 sentenc</context>
<context position="11415" citStr="Hoshino et al., 2013" startWordPosition="1891" endWordPosition="1894">ine result attained by Moses without preordering. In particular, the preordering model trained with the Giza data revealed a substantial improvement, while the use of the Nile data further improves accuracy. This suggests that our method is particularly effective when high-accuracy word alignments are given. In 4This testing data is excluded from latter experiments. addition, we achieved modest improvements even with DL=0 (no distortion allowed), which indicates the monotonicity of our reordered sentences. Table 5 shows a comparison of the proposed method with a rule-based preordering method (Hoshino et al., 2013) and two postordering methods (Goto et al., 2012; Hayashi et al., 2013).5 One complication is that each work reports different baseline accuracy, although Moses is shared as a baseline, because these systems differ in various settings in data preprocessing, tokenization criteria, etc. Since this makes a fair comparison difficult, we additionally put a score difference (∆) of each system from its own baseline. Our proposed method showed translation accuracy comparable with, or superior to, state-ofthe-art methods. This highlights the importance of Kendall’s T maximization in the simple discrimi</context>
<context position="13900" citStr="Hoshino et al. (2013)" startWordPosition="2266" endWordPosition="2269">ign their training sentences, then sort source words to resemble target word indices. After that, sorted source sentences without overlaps are used to train the model. They gained BLEU +1.54 improvement in Chinese-to-English evaluation. Our proposal follows their model, while we do not rely on their heuristics for preparing training data. Lerner and Petrov (2013) proposed another discriminative preordering model along dependency trees, which classifies whether the parent of each node should be the head in target language. They reported BLEU +3.7 improvement in English-to-Japanese translation. Hoshino et al. (2013) proposed a similar but rule-based method for Japanese-to-English dependency preordering. Yang et al. (2012) proposed a method to produce oracle reordering in the discriminative preordering model along dependency trees. Their idea behind is to minimize word alignment crossing recursively, which is essentially the same reordering objective as our Kendall’s T maximization. Since they targeted complex n-ary dependency instead of simple binary trees, their method only calculates approximated oracle reordering in practice by ranking principle. We did not take n-ary trees into consideration to follo</context>
</contexts>
<marker>Hoshino, Miyao, Sudoh, Nagata, 2013</marker>
<rawString>Sho Hoshino, Yusuke Miyao, Katsuhito Sudoh, and Masaaki Nagata. 2013. Two-stage pre-ordering for Japanese-to-English statistical machine translation. In Proceedings of the Sixth International Joint Conference on Natural Language Processing, pages 1062–1066.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Hideki Isozaki</author>
<author>Tsutomu Hirao</author>
<author>Kevin Duh</author>
</authors>
<title>Katsuhito Sudoh, and Hajime Tsukada. 2010a. Automatic evaluation of translation quality for distant language pairs.</title>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>944--952</pages>
<marker>Isozaki, Hirao, Duh, </marker>
<rawString>Hideki Isozaki, Tsutomu Hirao, Kevin Duh, Katsuhito Sudoh, and Hajime Tsukada. 2010a. Automatic evaluation of translation quality for distant language pairs. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 944–952.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hideki Isozaki</author>
<author>Katsuhito Sudoh</author>
<author>Hajime Tsukada</author>
<author>Kevin Duh</author>
</authors>
<title>Head finalization: A simple reordering rule for SOV languages.</title>
<date>2010</date>
<booktitle>In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR,</booktitle>
<pages>244--251</pages>
<contexts>
<context position="1457" citStr="Isozaki et al., 2010" startWordPosition="192" endWordPosition="195"> to, state-of-the-art methods in translation accuracy. 1 Introduction Current statistical machine translation systems suffer from major accuracy degradation in distant languages, primarily because they utilize exceptionally dissimilar word orders. One promising solution to this problem is preordering, in which source sentences are reordered to resemble the target language word orders, after which statistical machine translation is applied to reordered sentences (Xia and McCord, 2004; Collins et al., 2005). This is particularly effective for distant language pairs such as English and Japanese (Isozaki et al., 2010b). Among such preordering, one of the simplest and straightforward model is a discriminative preordering model (Li et al., 2007), which classifies whether children of each constituent node should be reordered, given binary trees.1 This simple model has, however, difficulty to find oracle labels. Yang et al. (2012) proposed a method to approximate oracle labels along dependency trees. The present paper proposes a new procedure to find oracle labels. The main idea is simple: we NP= 1It is also possible to use n-ary trees (Li et al., 2007; Yang et al., 2012), but we keep this binary model for si</context>
<context position="4543" citStr="Isozaki et al., 2010" startWordPosition="739" endWordPosition="742">ifier, we need an oracle label, W or M, for each node. Since we cannot rely on manual label annotation, we define a procedure to obtain oracle labels from word alignments. The principal idea is that we determine an oracle label of each node v(i, p, j) so that it maximizes Kendall’s T under v(i, p, j). This is intuitively a straightforward idea, because our objective is to find a monotonic order, which indicates maximization of Kendall’s T. In the context of statistical machine translation, Kendall’s T is used as an evaluation metric for monotonicity of word orderings (Birch and Osborne, 2010; Isozaki et al., 2010a; Talbot et al., 2011). Given an integer list x = x1, ... , x, T(x) VP=W 140 test9 test10 Settings DL RIBES BLEU RIBES BLEU Baseline w/o preordering Moses 0 66.95 26.36 67.50 27.17 Moses 10 68.95 29.41 69.64 30.20 Moses 20 69.88 30.12 70.22 30.51 ti:p, tp+1:j, wi:p, wp+1:j, σ(v(i, p, j)), ti:p o tp+1:j, wi:p o wp+1:j, σr(v(i, p, j)), ti:p o tp+1:j o wi:p o wp+1:j, σt(v(i, p, j)), tl:p, tp+1:r, wl:p, wp+1:r, σw(v(i, p, j)) tl:p o tp+1:r, wl:p o wp+1:r, tl:p o tp+1:r o wl:p o wp+1:r Table 1: Templates for the node v(i, p, j): where integers l and r satisfy i &lt; l &lt; p &lt; p+1 &lt; r &lt; j. Template Inst</context>
<context position="9783" citStr="Isozaki et al., 2010" startWordPosition="1636" endWordPosition="1639">Postordering (Hayashi et al., 2013) 0 76.46 +7.15 32.59 +3.16 76.76 +7.86 33.14 +3.15 Table 5: Comparison with previous systems in Japanese-to-English translation, of which scores are retrieved from their papers. Boldfaces indicate the highest scores and differences. 8 training sets, used the first 1000 sentences in NTCIR-8 development set, and then fetched both the NTCIR-9 and NTCIR-10 testing sets. The machine translation experiments pipelined Moses 3 (Koehn et al., 2007) with lexicalized reordering, SRILM 1.7.0 (Stolcke et al., 2011) in 6-gram order, MGIZA (Gao and Vogel, 2008), and RIBES (Isozaki et al., 2010a) and BLEU (Papineni et al., 2002) for evaluation. Binary constituent parsing in Japanese used Haruniwa (Fang et al., 2014), Berkeley parser 1.7 (Petrov and Klein, 2007), Comainu 0.7.0 (Kozawa et al., 2014), MeCab 0.996 (Kudo et al., 2004), and Unidic 2.1.2. We explore two types of word alignment data for training our preordering model. The first data (Giza) is created by running an unsupervised aligner Giza (Och and Ney, 2003) on the training data (3 million sentences). The second data (Nile) is developed by training a supervised aligner Nile (Riesa et al., 2011) with manually annotated 8,00</context>
<context position="14935" citStr="Isozaki et al. (2010" startWordPosition="2425" endWordPosition="2428">ncy instead of simple binary trees, their method only calculates approximated oracle reordering in practice by ranking principle. We did not take n-ary trees into consideration to follow the simple discriminative preordering model along constituency, while the use of binary trees enabled us to produce strict oracle reordering as a side effect. Another research direction called postordering (Sudoh et al., 2011; Goto et al., 2012; Hayashi et al., 2013) has been explored in Japanese-toEnglish translation. They first translate Japanese input into head final English texts obtained by the method of Isozaki et al. (2010b), then reorder head final English texts into English word orders. 5 Conclusion We proposed a simple procedure to train a discriminative preordering model. The main idea is to obtain oracle labels for each node by maximizing Kendall’s T of word alignments. Experiments in Japanese-to-English translation demonstrated that our procedure, without language-specific heuristics, achieved state-of-the-art translation accuracy. Acknowledgments We would like to thank Kevin Duh, Atsushi Fujita, Taku Kudo, Shinsuke Mori, Toshiaki Nakazawa, Graham Neubig, Hiroshi Noji, and anonymous reviewers for their in</context>
</contexts>
<marker>Isozaki, Sudoh, Tsukada, Duh, 2010</marker>
<rawString>Hideki Isozaki, Katsuhito Sudoh, Hajime Tsukada, and Kevin Duh. 2010b. Head finalization: A simple reordering rule for SOV languages. In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, pages 244–251.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
</authors>
<title>Chris Dyer, Ondrej Bojar,</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>177--180</pages>
<location>Alexandra</location>
<contexts>
<context position="9641" citStr="Koehn et al., 2007" startWordPosition="1612" endWordPosition="1615">12) 70.64 +2.36 30.69 +0.49 Postordering (Goto et al., 2012) 75.48 +7.20 33.04 +2.84 Moses (Hayashi et al., 2013) 20 69.31 29.43 68.90 29.99 Postordering (Hayashi et al., 2013) 0 76.46 +7.15 32.59 +3.16 76.76 +7.86 33.14 +3.15 Table 5: Comparison with previous systems in Japanese-to-English translation, of which scores are retrieved from their papers. Boldfaces indicate the highest scores and differences. 8 training sets, used the first 1000 sentences in NTCIR-8 development set, and then fetched both the NTCIR-9 and NTCIR-10 testing sets. The machine translation experiments pipelined Moses 3 (Koehn et al., 2007) with lexicalized reordering, SRILM 1.7.0 (Stolcke et al., 2011) in 6-gram order, MGIZA (Gao and Vogel, 2008), and RIBES (Isozaki et al., 2010a) and BLEU (Papineni et al., 2002) for evaluation. Binary constituent parsing in Japanese used Haruniwa (Fang et al., 2014), Berkeley parser 1.7 (Petrov and Klein, 2007), Comainu 0.7.0 (Kozawa et al., 2014), MeCab 0.996 (Kudo et al., 2004), and Unidic 2.1.2. We explore two types of word alignment data for training our preordering model. The first data (Giza) is created by running an unsupervised aligner Giza (Och and Ney, 2003) on the training data (3 m</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, pages 177– 180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>388--395</pages>
<contexts>
<context position="6849" citStr="Koehn, 2004" startWordPosition="1160" endWordPosition="1161">t and right lists are left untouched. We determine oracle labels for a given constituent tree by computing s(v(i, p, j)) for every v(i, p, j) independently. 3Oracle labels guarantee τ(a) &gt; 0, but not τ(a) = 1, because parsed trees will not correspond to word alignments. Proposed preordering Giza 0 77.49 33.08 77.49 33.65 Giza 10 77.44 33.28 77.42 33.77 Nile 0 77.74 32.97 77.89 33.91 Nile 10 77.97 33.55 78.07 34.13 Table 4: Results in Japanese-to-English translation. Boldfaces denote the highest scores and the insignificant difference (p &lt; 0.01) from the highest scores in bootstrap resampling (Koehn, 2004). 2.4 Features Table 1 shows the templates for the node v(i, p, j) of the feature function 0 in Section 2.1. To tell the differences between the left span a(i, p) and the right span a(p + 1, j), such as whether the head word of the node is in left or right, the first set of templates considers individual indices x:y that denote the span from x-th to y-th words: where tx represents a part-of-speech feature; wx represents a lexical feature; and o represents feature combination. The second set of templates considers constituent structures of the node by supplying three S-expressions and parent-ch</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Statistical significance tests for machine translation evaluation. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, pages 388–395.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shunsuke Kozawa</author>
<author>Kiyotaka Uchimoto</author>
<author>Yasuharu Den</author>
</authors>
<title>Adaptation of long-unit-word analysis system to different part-of-speech tagset (in Japanese).</title>
<date>2014</date>
<journal>Journal of Natural Language Processing,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="9990" citStr="Kozawa et al., 2014" startWordPosition="1669" endWordPosition="1672">pers. Boldfaces indicate the highest scores and differences. 8 training sets, used the first 1000 sentences in NTCIR-8 development set, and then fetched both the NTCIR-9 and NTCIR-10 testing sets. The machine translation experiments pipelined Moses 3 (Koehn et al., 2007) with lexicalized reordering, SRILM 1.7.0 (Stolcke et al., 2011) in 6-gram order, MGIZA (Gao and Vogel, 2008), and RIBES (Isozaki et al., 2010a) and BLEU (Papineni et al., 2002) for evaluation. Binary constituent parsing in Japanese used Haruniwa (Fang et al., 2014), Berkeley parser 1.7 (Petrov and Klein, 2007), Comainu 0.7.0 (Kozawa et al., 2014), MeCab 0.996 (Kudo et al., 2004), and Unidic 2.1.2. We explore two types of word alignment data for training our preordering model. The first data (Giza) is created by running an unsupervised aligner Giza (Och and Ney, 2003) on the training data (3 million sentences). The second data (Nile) is developed by training a supervised aligner Nile (Riesa et al., 2011) with manually annotated 8,000 sentences, then applied the trained alignment model to remaining training data. In the evaluation on manually annotated 1,000 sentences4, Giza achieved F1 50.1 score, while Nile achieved F1 86.9 score, for</context>
</contexts>
<marker>Kozawa, Uchimoto, Den, 2014</marker>
<rawString>Shunsuke Kozawa, Kiyotaka Uchimoto, and Yasuharu Den. 2014. Adaptation of long-unit-word analysis system to different part-of-speech tagset (in Japanese). Journal of Natural Language Processing, 21(2):379–401.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Kaoru Yamamoto</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Applying conditional random fields to japanese morphological analysis.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>230--237</pages>
<contexts>
<context position="10023" citStr="Kudo et al., 2004" startWordPosition="1675" endWordPosition="1678">t scores and differences. 8 training sets, used the first 1000 sentences in NTCIR-8 development set, and then fetched both the NTCIR-9 and NTCIR-10 testing sets. The machine translation experiments pipelined Moses 3 (Koehn et al., 2007) with lexicalized reordering, SRILM 1.7.0 (Stolcke et al., 2011) in 6-gram order, MGIZA (Gao and Vogel, 2008), and RIBES (Isozaki et al., 2010a) and BLEU (Papineni et al., 2002) for evaluation. Binary constituent parsing in Japanese used Haruniwa (Fang et al., 2014), Berkeley parser 1.7 (Petrov and Klein, 2007), Comainu 0.7.0 (Kozawa et al., 2014), MeCab 0.996 (Kudo et al., 2004), and Unidic 2.1.2. We explore two types of word alignment data for training our preordering model. The first data (Giza) is created by running an unsupervised aligner Giza (Och and Ney, 2003) on the training data (3 million sentences). The second data (Nile) is developed by training a supervised aligner Nile (Riesa et al., 2011) with manually annotated 8,000 sentences, then applied the trained alignment model to remaining training data. In the evaluation on manually annotated 1,000 sentences4, Giza achieved F1 50.1 score, while Nile achieved F1 86.9 score, for word alignment task. 3.2 Result </context>
</contexts>
<marker>Kudo, Yamamoto, Matsumoto, 2004</marker>
<rawString>Taku Kudo, Kaoru Yamamoto, and Yuji Matsumoto. 2004. Applying conditional random fields to japanese morphological analysis. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, pages 230–237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Hiroshi Ichikawa</author>
<author>Hideto Kazawa</author>
</authors>
<title>A joint inference of deep case analysis and zero subject generation for Japanese-to-English statistical machine translation.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>557--562</pages>
<contexts>
<context position="12678" citStr="Kudo et al., 2014" startWordPosition="2082" endWordPosition="2085">bstantial gain in RIBES, we attained a rather comparable gain in BLEU. The investigation of our translation suggests that insufficient generation of English articles caused a significant degradation in the BLEU score. Previous systems listed in Table 5 incorporated article generation and demonstrated its positive effect (Goto et al., 2012; Hayashi et al., 2013). While we achieved state-ofthe-art accuracy without language-specific techniques, it is also a promising direction to integrate our preordering method with language-specific techniques such as article generation and subject generation (Kudo et al., 2014). 5We could not find a comparable report using tree-based machine translation systems apart from Moses-chart; nevertheless, Neubig and Duh (2014) reported that their forestto-string system on the same corpus, which is unfortunately evaluated on the different testing data (test7), showed RIBES +6.19 (75.94) and BLEU +2.93 (33.70) improvements. Although not directly comparable, our method achieves a comparable or superior improvement. 142 4 Related Work Li et al. (2007) proposed a simple discriminative preordering model as described in Section 2.1. They employed heuristics that utilize Giza to a</context>
</contexts>
<marker>Kudo, Ichikawa, Kazawa, 2014</marker>
<rawString>Taku Kudo, Hiroshi Ichikawa, and Hideto Kazawa. 2014. A joint inference of deep case analysis and zero subject generation for Japanese-to-English statistical machine translation. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 557–562.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Uri Lerner</author>
<author>Slav Petrov</author>
</authors>
<title>Source-side classifier preordering for machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>513--523</pages>
<contexts>
<context position="13644" citStr="Lerner and Petrov (2013)" startWordPosition="2229" endWordPosition="2232">s. Although not directly comparable, our method achieves a comparable or superior improvement. 142 4 Related Work Li et al. (2007) proposed a simple discriminative preordering model as described in Section 2.1. They employed heuristics that utilize Giza to align their training sentences, then sort source words to resemble target word indices. After that, sorted source sentences without overlaps are used to train the model. They gained BLEU +1.54 improvement in Chinese-to-English evaluation. Our proposal follows their model, while we do not rely on their heuristics for preparing training data. Lerner and Petrov (2013) proposed another discriminative preordering model along dependency trees, which classifies whether the parent of each node should be the head in target language. They reported BLEU +3.7 improvement in English-to-Japanese translation. Hoshino et al. (2013) proposed a similar but rule-based method for Japanese-to-English dependency preordering. Yang et al. (2012) proposed a method to produce oracle reordering in the discriminative preordering model along dependency trees. Their idea behind is to minimize word alignment crossing recursively, which is essentially the same reordering objective as </context>
</contexts>
<marker>Lerner, Petrov, 2013</marker>
<rawString>Uri Lerner and Slav Petrov. 2013. Source-side classifier preordering for machine translation. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 513–523.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chi-Ho Li</author>
<author>Minghui Li</author>
<author>Dongdong Zhang</author>
<author>Mu Li</author>
<author>Ming Zhou</author>
<author>Yi Guan</author>
</authors>
<title>A probabilistic approach to syntax-based reordering for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>720--727</pages>
<contexts>
<context position="1586" citStr="Li et al., 2007" startWordPosition="212" endWordPosition="215">or accuracy degradation in distant languages, primarily because they utilize exceptionally dissimilar word orders. One promising solution to this problem is preordering, in which source sentences are reordered to resemble the target language word orders, after which statistical machine translation is applied to reordered sentences (Xia and McCord, 2004; Collins et al., 2005). This is particularly effective for distant language pairs such as English and Japanese (Isozaki et al., 2010b). Among such preordering, one of the simplest and straightforward model is a discriminative preordering model (Li et al., 2007), which classifies whether children of each constituent node should be reordered, given binary trees.1 This simple model has, however, difficulty to find oracle labels. Yang et al. (2012) proposed a method to approximate oracle labels along dependency trees. The present paper proposes a new procedure to find oracle labels. The main idea is simple: we NP= 1It is also possible to use n-ary trees (Li et al., 2007; Yang et al., 2012), but we keep this binary model for simplicity. S=M VP=W 139 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th Intern</context>
<context position="8104" citStr="Li et al. (2007)" startWordPosition="1368" endWordPosition="1371">esents a constituent structure under the node v(i, p, j); Qr(v(i, p, j)) represents part-of-speech tags of the node and their parent-child relations; Qt(v(i, p, j)) represents the constituent structure including only part-of-speech tags; and Q,,,(v(i, p, j)) represents the constituent structure including only surface words. Table 2 shows instances of features for the VP node v(2, 2, 4) in Figure 1, which has the left (is2) and the right (binary3 classification4) spans. Table 3 shows ablation test results on binary classification, which indicate that our templates performed better than that of Li et al. (2007). 3 Experiment 3.1 Experimental Settings We perform experiments over the NTCIR patent corpus (Goto et al., 2011) that consists of more than 3 million sentences in English and Japanese. Following conventional literature settings (Goto et al., 2012; Hayashi et al., 2013), we used all 3 million sentences from the NTCIR-7 and NTCIRTemplate Instance σ(v(2, 2, 4)) (VP(VBZis)(NP(JJbinary)(NNclassification))) σr(v(2, 2, 4)) VP VBZ NP JJ NN VP VBZ VP NP NP JJ NP NN σt(v(2, 2, 4)) (VP(VBZ)(NP(JJ)(NN))) σw(v(2, 2, 4)) ((is)((binary)(classification))) Li et al. (2007) 84.43 141 Reordering Methods DL RIBES</context>
<context position="13150" citStr="Li et al. (2007)" startWordPosition="2154" endWordPosition="2157">tion to integrate our preordering method with language-specific techniques such as article generation and subject generation (Kudo et al., 2014). 5We could not find a comparable report using tree-based machine translation systems apart from Moses-chart; nevertheless, Neubig and Duh (2014) reported that their forestto-string system on the same corpus, which is unfortunately evaluated on the different testing data (test7), showed RIBES +6.19 (75.94) and BLEU +2.93 (33.70) improvements. Although not directly comparable, our method achieves a comparable or superior improvement. 142 4 Related Work Li et al. (2007) proposed a simple discriminative preordering model as described in Section 2.1. They employed heuristics that utilize Giza to align their training sentences, then sort source words to resemble target word indices. After that, sorted source sentences without overlaps are used to train the model. They gained BLEU +1.54 improvement in Chinese-to-English evaluation. Our proposal follows their model, while we do not rely on their heuristics for preparing training data. Lerner and Petrov (2013) proposed another discriminative preordering model along dependency trees, which classifies whether the pa</context>
</contexts>
<marker>Li, Li, Zhang, Li, Zhou, Guan, 2007</marker>
<rawString>Chi-Ho Li, Minghui Li, Dongdong Zhang, Mu Li, Ming Zhou, and Yi Guan. 2007. A probabilistic approach to syntax-based reordering for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 720–727.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Neubig</author>
<author>Kevin Duh</author>
</authors>
<title>On the elements of an accurate tree-to-string machine translation system.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>143--149</pages>
<contexts>
<context position="12823" citStr="Neubig and Duh (2014)" startWordPosition="2103" endWordPosition="2106">ion of English articles caused a significant degradation in the BLEU score. Previous systems listed in Table 5 incorporated article generation and demonstrated its positive effect (Goto et al., 2012; Hayashi et al., 2013). While we achieved state-ofthe-art accuracy without language-specific techniques, it is also a promising direction to integrate our preordering method with language-specific techniques such as article generation and subject generation (Kudo et al., 2014). 5We could not find a comparable report using tree-based machine translation systems apart from Moses-chart; nevertheless, Neubig and Duh (2014) reported that their forestto-string system on the same corpus, which is unfortunately evaluated on the different testing data (test7), showed RIBES +6.19 (75.94) and BLEU +2.93 (33.70) improvements. Although not directly comparable, our method achieves a comparable or superior improvement. 142 4 Related Work Li et al. (2007) proposed a simple discriminative preordering model as described in Section 2.1. They employed heuristics that utilize Giza to align their training sentences, then sort source words to resemble target word indices. After that, sorted source sentences without overlaps are u</context>
</contexts>
<marker>Neubig, Duh, 2014</marker>
<rawString>Graham Neubig and Kevin Duh. 2014. On the elements of an accurate tree-to-string machine translation system. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 143–149.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="10215" citStr="Och and Ney, 2003" startWordPosition="1708" endWordPosition="1711">ments pipelined Moses 3 (Koehn et al., 2007) with lexicalized reordering, SRILM 1.7.0 (Stolcke et al., 2011) in 6-gram order, MGIZA (Gao and Vogel, 2008), and RIBES (Isozaki et al., 2010a) and BLEU (Papineni et al., 2002) for evaluation. Binary constituent parsing in Japanese used Haruniwa (Fang et al., 2014), Berkeley parser 1.7 (Petrov and Klein, 2007), Comainu 0.7.0 (Kozawa et al., 2014), MeCab 0.996 (Kudo et al., 2004), and Unidic 2.1.2. We explore two types of word alignment data for training our preordering model. The first data (Giza) is created by running an unsupervised aligner Giza (Och and Ney, 2003) on the training data (3 million sentences). The second data (Nile) is developed by training a supervised aligner Nile (Riesa et al., 2011) with manually annotated 8,000 sentences, then applied the trained alignment model to remaining training data. In the evaluation on manually annotated 1,000 sentences4, Giza achieved F1 50.1 score, while Nile achieved F1 86.9 score, for word alignment task. 3.2 Result Table 4 shows the performance of our method, which indicates that our preordering significantly improved translation accuracy in both RIBES and BLEU scores, from the baseline result attained b</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="9818" citStr="Papineni et al., 2002" startWordPosition="1642" endWordPosition="1645">3) 0 76.46 +7.15 32.59 +3.16 76.76 +7.86 33.14 +3.15 Table 5: Comparison with previous systems in Japanese-to-English translation, of which scores are retrieved from their papers. Boldfaces indicate the highest scores and differences. 8 training sets, used the first 1000 sentences in NTCIR-8 development set, and then fetched both the NTCIR-9 and NTCIR-10 testing sets. The machine translation experiments pipelined Moses 3 (Koehn et al., 2007) with lexicalized reordering, SRILM 1.7.0 (Stolcke et al., 2011) in 6-gram order, MGIZA (Gao and Vogel, 2008), and RIBES (Isozaki et al., 2010a) and BLEU (Papineni et al., 2002) for evaluation. Binary constituent parsing in Japanese used Haruniwa (Fang et al., 2014), Berkeley parser 1.7 (Petrov and Klein, 2007), Comainu 0.7.0 (Kozawa et al., 2014), MeCab 0.996 (Kudo et al., 2004), and Unidic 2.1.2. We explore two types of word alignment data for training our preordering model. The first data (Giza) is created by running an unsupervised aligner Giza (Och and Ney, 2003) on the training data (3 million sentences). The second data (Nile) is developed by training a supervised aligner Nile (Riesa et al., 2011) with manually annotated 8,000 sentences, then applied the train</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Improved inference for unlexicalized parsing.</title>
<date>2007</date>
<booktitle>In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,</booktitle>
<pages>404--411</pages>
<contexts>
<context position="9953" citStr="Petrov and Klein, 2007" startWordPosition="1662" endWordPosition="1665">which scores are retrieved from their papers. Boldfaces indicate the highest scores and differences. 8 training sets, used the first 1000 sentences in NTCIR-8 development set, and then fetched both the NTCIR-9 and NTCIR-10 testing sets. The machine translation experiments pipelined Moses 3 (Koehn et al., 2007) with lexicalized reordering, SRILM 1.7.0 (Stolcke et al., 2011) in 6-gram order, MGIZA (Gao and Vogel, 2008), and RIBES (Isozaki et al., 2010a) and BLEU (Papineni et al., 2002) for evaluation. Binary constituent parsing in Japanese used Haruniwa (Fang et al., 2014), Berkeley parser 1.7 (Petrov and Klein, 2007), Comainu 0.7.0 (Kozawa et al., 2014), MeCab 0.996 (Kudo et al., 2004), and Unidic 2.1.2. We explore two types of word alignment data for training our preordering model. The first data (Giza) is created by running an unsupervised aligner Giza (Och and Ney, 2003) on the training data (3 million sentences). The second data (Nile) is developed by training a supervised aligner Nile (Riesa et al., 2011) with manually annotated 8,000 sentences, then applied the trained alignment model to remaining training data. In the evaluation on manually annotated 1,000 sentences4, Giza achieved F1 50.1 score, w</context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Improved inference for unlexicalized parsing. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 404–411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Riesa</author>
<author>Ann Irvine</author>
<author>Daniel Marcu</author>
</authors>
<title>Feature-rich language-independent syntax-based alignment for statistical machine translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>497--507</pages>
<contexts>
<context position="10354" citStr="Riesa et al., 2011" startWordPosition="1731" endWordPosition="1734">nd Vogel, 2008), and RIBES (Isozaki et al., 2010a) and BLEU (Papineni et al., 2002) for evaluation. Binary constituent parsing in Japanese used Haruniwa (Fang et al., 2014), Berkeley parser 1.7 (Petrov and Klein, 2007), Comainu 0.7.0 (Kozawa et al., 2014), MeCab 0.996 (Kudo et al., 2004), and Unidic 2.1.2. We explore two types of word alignment data for training our preordering model. The first data (Giza) is created by running an unsupervised aligner Giza (Och and Ney, 2003) on the training data (3 million sentences). The second data (Nile) is developed by training a supervised aligner Nile (Riesa et al., 2011) with manually annotated 8,000 sentences, then applied the trained alignment model to remaining training data. In the evaluation on manually annotated 1,000 sentences4, Giza achieved F1 50.1 score, while Nile achieved F1 86.9 score, for word alignment task. 3.2 Result Table 4 shows the performance of our method, which indicates that our preordering significantly improved translation accuracy in both RIBES and BLEU scores, from the baseline result attained by Moses without preordering. In particular, the preordering model trained with the Giza data revealed a substantial improvement, while the </context>
</contexts>
<marker>Riesa, Irvine, Marcu, 2011</marker>
<rawString>Jason Riesa, Ann Irvine, and Daniel Marcu. 2011. Feature-rich language-independent syntax-based alignment for statistical machine translation. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 497–507.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
<author>Jing Zheng</author>
<author>Wen Wang</author>
<author>Victor Abrash</author>
</authors>
<title>SRILM at sixteen: Update and outlook.</title>
<date>2011</date>
<booktitle>In Proceedings of the IEEE Automatic Speech Recognition and Understanding Workshop.</booktitle>
<contexts>
<context position="9705" citStr="Stolcke et al., 2011" startWordPosition="1621" endWordPosition="1624">5.48 +7.20 33.04 +2.84 Moses (Hayashi et al., 2013) 20 69.31 29.43 68.90 29.99 Postordering (Hayashi et al., 2013) 0 76.46 +7.15 32.59 +3.16 76.76 +7.86 33.14 +3.15 Table 5: Comparison with previous systems in Japanese-to-English translation, of which scores are retrieved from their papers. Boldfaces indicate the highest scores and differences. 8 training sets, used the first 1000 sentences in NTCIR-8 development set, and then fetched both the NTCIR-9 and NTCIR-10 testing sets. The machine translation experiments pipelined Moses 3 (Koehn et al., 2007) with lexicalized reordering, SRILM 1.7.0 (Stolcke et al., 2011) in 6-gram order, MGIZA (Gao and Vogel, 2008), and RIBES (Isozaki et al., 2010a) and BLEU (Papineni et al., 2002) for evaluation. Binary constituent parsing in Japanese used Haruniwa (Fang et al., 2014), Berkeley parser 1.7 (Petrov and Klein, 2007), Comainu 0.7.0 (Kozawa et al., 2014), MeCab 0.996 (Kudo et al., 2004), and Unidic 2.1.2. We explore two types of word alignment data for training our preordering model. The first data (Giza) is created by running an unsupervised aligner Giza (Och and Ney, 2003) on the training data (3 million sentences). The second data (Nile) is developed by traini</context>
</contexts>
<marker>Stolcke, Zheng, Wang, Abrash, 2011</marker>
<rawString>Andreas Stolcke, Jing Zheng, Wen Wang, and Victor Abrash. 2011. SRILM at sixteen: Update and outlook. In Proceedings of the IEEE Automatic Speech Recognition and Understanding Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katsuhito Sudoh</author>
<author>Xianchao Wu</author>
<author>Kevin Duh</author>
<author>Hajime Tsukada</author>
<author>Masaaki Nagata</author>
</authors>
<title>Post-ordering in statistical machine translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the Machine Translation Summit XIII,</booktitle>
<pages>316--323</pages>
<contexts>
<context position="14727" citStr="Sudoh et al., 2011" startWordPosition="2391" endWordPosition="2394">ncy trees. Their idea behind is to minimize word alignment crossing recursively, which is essentially the same reordering objective as our Kendall’s T maximization. Since they targeted complex n-ary dependency instead of simple binary trees, their method only calculates approximated oracle reordering in practice by ranking principle. We did not take n-ary trees into consideration to follow the simple discriminative preordering model along constituency, while the use of binary trees enabled us to produce strict oracle reordering as a side effect. Another research direction called postordering (Sudoh et al., 2011; Goto et al., 2012; Hayashi et al., 2013) has been explored in Japanese-toEnglish translation. They first translate Japanese input into head final English texts obtained by the method of Isozaki et al. (2010b), then reorder head final English texts into English word orders. 5 Conclusion We proposed a simple procedure to train a discriminative preordering model. The main idea is to obtain oracle labels for each node by maximizing Kendall’s T of word alignments. Experiments in Japanese-to-English translation demonstrated that our procedure, without language-specific heuristics, achieved state-o</context>
</contexts>
<marker>Sudoh, Wu, Duh, Tsukada, Nagata, 2011</marker>
<rawString>Katsuhito Sudoh, Xianchao Wu, Kevin Duh, Hajime Tsukada, and Masaaki Nagata. 2011. Post-ordering in statistical machine translation. In Proceedings of the Machine Translation Summit XIII, pages 316– 323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Talbot</author>
<author>Hideto Kazawa</author>
<author>Hiroshi Ichikawa</author>
<author>Jason Katz-Brown</author>
<author>Masakazu Seno</author>
<author>Franz Och</author>
</authors>
<title>A lightweight evaluation framework for machine translation reordering.</title>
<date>2011</date>
<booktitle>In Proceedings of the Sixth Workshop on Statistical Machine Translation,</booktitle>
<pages>12--21</pages>
<contexts>
<context position="4566" citStr="Talbot et al., 2011" startWordPosition="743" endWordPosition="746">e label, W or M, for each node. Since we cannot rely on manual label annotation, we define a procedure to obtain oracle labels from word alignments. The principal idea is that we determine an oracle label of each node v(i, p, j) so that it maximizes Kendall’s T under v(i, p, j). This is intuitively a straightforward idea, because our objective is to find a monotonic order, which indicates maximization of Kendall’s T. In the context of statistical machine translation, Kendall’s T is used as an evaluation metric for monotonicity of word orderings (Birch and Osborne, 2010; Isozaki et al., 2010a; Talbot et al., 2011). Given an integer list x = x1, ... , x, T(x) VP=W 140 test9 test10 Settings DL RIBES BLEU RIBES BLEU Baseline w/o preordering Moses 0 66.95 26.36 67.50 27.17 Moses 10 68.95 29.41 69.64 30.20 Moses 20 69.88 30.12 70.22 30.51 ti:p, tp+1:j, wi:p, wp+1:j, σ(v(i, p, j)), ti:p o tp+1:j, wi:p o wp+1:j, σr(v(i, p, j)), ti:p o tp+1:j o wi:p o wp+1:j, σt(v(i, p, j)), tl:p, tp+1:r, wl:p, wp+1:r, σw(v(i, p, j)) tl:p o tp+1:r, wl:p o wp+1:r, tl:p o tp+1:r o wl:p o wp+1:r Table 1: Templates for the node v(i, p, j): where integers l and r satisfy i &lt; l &lt; p &lt; p+1 &lt; r &lt; j. Template Instance Template Instance </context>
</contexts>
<marker>Talbot, Kazawa, Ichikawa, Katz-Brown, Seno, Och, 2011</marker>
<rawString>David Talbot, Hideto Kazawa, Hiroshi Ichikawa, Jason Katz-Brown, Masakazu Seno, and Franz Och. 2011. A lightweight evaluation framework for machine translation reordering. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 12–21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
<author>Michael McCord</author>
</authors>
<title>Improving a statistical MT system with automatically learned rewrite patterns.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics,</booktitle>
<pages>508--514</pages>
<contexts>
<context position="1324" citStr="Xia and McCord, 2004" startWordPosition="170" endWordPosition="173"> maximize Kendall’s T. Experiments in Japanese-to-English translation revealed that our simple method is comparable with, or superior to, state-of-the-art methods in translation accuracy. 1 Introduction Current statistical machine translation systems suffer from major accuracy degradation in distant languages, primarily because they utilize exceptionally dissimilar word orders. One promising solution to this problem is preordering, in which source sentences are reordered to resemble the target language word orders, after which statistical machine translation is applied to reordered sentences (Xia and McCord, 2004; Collins et al., 2005). This is particularly effective for distant language pairs such as English and Japanese (Isozaki et al., 2010b). Among such preordering, one of the simplest and straightforward model is a discriminative preordering model (Li et al., 2007), which classifies whether children of each constituent node should be reordered, given binary trees.1 This simple model has, however, difficulty to find oracle labels. Yang et al. (2012) proposed a method to approximate oracle labels along dependency trees. The present paper proposes a new procedure to find oracle labels. The main idea</context>
</contexts>
<marker>Xia, McCord, 2004</marker>
<rawString>Fei Xia and Michael McCord. 2004. Improving a statistical MT system with automatically learned rewrite patterns. In Proceedings of the 20th International Conference on Computational Linguistics, pages 508–514.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nan Yang</author>
<author>Mu Li</author>
<author>Dongdong Zhang</author>
<author>Nenghai Yu</author>
</authors>
<title>A ranking-based approach to word reordering for statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>912--920</pages>
<contexts>
<context position="1773" citStr="Yang et al. (2012)" startWordPosition="241" endWordPosition="244"> sentences are reordered to resemble the target language word orders, after which statistical machine translation is applied to reordered sentences (Xia and McCord, 2004; Collins et al., 2005). This is particularly effective for distant language pairs such as English and Japanese (Isozaki et al., 2010b). Among such preordering, one of the simplest and straightforward model is a discriminative preordering model (Li et al., 2007), which classifies whether children of each constituent node should be reordered, given binary trees.1 This simple model has, however, difficulty to find oracle labels. Yang et al. (2012) proposed a method to approximate oracle labels along dependency trees. The present paper proposes a new procedure to find oracle labels. The main idea is simple: we NP= 1It is also possible to use n-ary trees (Li et al., 2007; Yang et al., 2012), but we keep this binary model for simplicity. S=M VP=W 139 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 139–144, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics 2 Preordering Met</context>
<context position="14008" citStr="Yang et al. (2012)" startWordPosition="2280" endWordPosition="2283"> sentences without overlaps are used to train the model. They gained BLEU +1.54 improvement in Chinese-to-English evaluation. Our proposal follows their model, while we do not rely on their heuristics for preparing training data. Lerner and Petrov (2013) proposed another discriminative preordering model along dependency trees, which classifies whether the parent of each node should be the head in target language. They reported BLEU +3.7 improvement in English-to-Japanese translation. Hoshino et al. (2013) proposed a similar but rule-based method for Japanese-to-English dependency preordering. Yang et al. (2012) proposed a method to produce oracle reordering in the discriminative preordering model along dependency trees. Their idea behind is to minimize word alignment crossing recursively, which is essentially the same reordering objective as our Kendall’s T maximization. Since they targeted complex n-ary dependency instead of simple binary trees, their method only calculates approximated oracle reordering in practice by ranking principle. We did not take n-ary trees into consideration to follow the simple discriminative preordering model along constituency, while the use of binary trees enabled us t</context>
</contexts>
<marker>Yang, Li, Zhang, Yu, 2012</marker>
<rawString>Nan Yang, Mu Li, Dongdong Zhang, and Nenghai Yu. 2012. A ranking-based approach to word reordering for statistical machine translation. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 912–920.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>