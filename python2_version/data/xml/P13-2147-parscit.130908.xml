<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003625">
<title confidence="0.9987115">
Bidirectional Inter-dependencies of Subjective Expressions and
Targets and their Value for a Joint Model
</title>
<author confidence="0.978">
Roman Klinger and Philipp Cimiano
</author>
<affiliation confidence="0.957931333333333">
Semantic Computing Group
Cognitive Interaction Technology – Center of Excellence (CIT-EC)
Bielefeld University
</affiliation>
<address confidence="0.734808">
33615 Bielefeld, Germany
</address>
<email confidence="0.860546">
{rklinger,cimiano}@cit-ec.uni-bielefeld.de
</email>
<sectionHeader confidence="0.989447" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999904238095238">
Opinion mining is often regarded as a clas-
sification or segmentation task, involving
the prediction of i) subjective expressions,
ii) their target and iii) their polarity. In-
tuitively, these three variables are bidirec-
tionally interdependent, but most work has
either attempted to predict them in isolation
or proposing pipeline-based approaches
that cannot model the bidirectional interac-
tion between these variables. Towards bet-
ter understanding the interaction between
these variables, we propose a model that
allows for analyzing the relation of target
and subjective phrases in both directions,
thus providing an upper bound for the im-
pact of a joint model in comparison to a
pipeline model. We report results on two
public datasets (cameras and cars), show-
ing that our model outperforms state-of-
the-art models, as well as on a new dataset
consisting of Twitter posts.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999814342857143">
Sentiment analysis or opinion mining is the task of
identifying subjective statements about products,
their polarity (e. g. positive, negative or neutral)
in addition to the particular aspect or feature of
the entity that is under discussion, i. e., the so-
called target. Opinion analysis is thus typically
approached as a classification (T¨ackstr¨om and Mc-
Donald, 2011; Sayeed et al., 2012; Pang and Lee,
2004) or segmentation (Choi et al., 2010; Johans-
son and Moschitti, 2011; Yang and Cardie, 2012)
task by which fragments of the input are classi-
fied or labelled as representing a subjective phrase
(Yang and Cardie, 2012), a polarity or a target (Hu
and Liu, 2004; Li et al., 2010; Popescu and Etzioni,
2005; Jakob and Gurevych, 2010). As an example,
the sentence “I like the low weight of the camera.”
contains a subjective term “like”, and the target
“low weight”, which can be classified as a positive
statement.
While the three key variables (subjective phrase,
polarity and target) intuitively influence each other
bidirectionally, most work in the area of opinion
mining has concentrated on either predicting one
of these variables in isolation (e. g. subjective ex-
pressions by Yang and Cardie (2012)) or modeling
the dependencies uni-directionally in a pipeline ar-
chitecture, e. g. predicting targets on the basis of
perfect and complete knowledge about subjective
terms (Jakob and Gurevych, 2010). However, such
pipeline models do not allow for inclusion of bidi-
rectional interactions between the key variables. In
this paper, we propose a model that can include
bidirectional dependencies, attempting to answer
the following questions which so far have not been
addressed but provide the basis for a joint model:
</bodyText>
<listItem confidence="0.992542333333333">
• What is the impact of the performance loss
of a non-perfect subjective term extraction in
comparison to perfect knowledge?
• Further, how does perfect knowledge about
targets influence the prediction of subjective
terms?
• How is the latter affected if the knowledge
about targets is imperfect, i. e. predicted by a
learned model?
</listItem>
<bodyText confidence="0.999715625">
We study these questions using imperatively de-
fined factor graphs (IDFs, McCallum et al. (2008),
McCallum et al. (2009)) to show how these bi-
directional dependencies can be modeled in an ar-
chitecture which allows for further steps towards
joint inference. IDFs are a convenient way to define
probabilistic graphical models that make structured
predictions based on complex dependencies.
</bodyText>
<page confidence="0.956742">
848
</page>
<note confidence="0.538857">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 848–854,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.7848155" genericHeader="method">
2 A Model for the Extraction of Target
Phrases and Subjective Expressions
</sectionHeader>
<bodyText confidence="0.999938">
This section gives a brief introduction to impera-
tively defined factor graphs and then introduces our
model.
</bodyText>
<subsectionHeader confidence="0.991839">
2.1 Imperatively Defined Factor Graphs
</subsectionHeader>
<bodyText confidence="0.995475952380952">
A factor graph (Kschischang et al., 2001) is a bi-
partite graph over factors and variables. Let factor
graph G define a probability distribution over a
set of output variables y conditioned on input vari-
ables x. A factor Ti computes a scalar value over
the subset of variables xi and yi that are neighbors
of Ti in the graph. Often this real-valued function
is defined as the exponential of an inner product
over sufficient statistics {fik(xi,yi)} and parame-
ters {θik}, where k ∈ [1, Ki] and Ki is the number
of parameters for factor Ti.
A factor template Tj consists of parameters
{θjk}, sufficient statistic functions {fjk}, and a
description of an arbitrary relationship between
variables, yielding a set of tuples {(xj, yj)}. For
each of these tuples, the factor template instan-
tiates a factor that shares {θjk} and {fjk} with
all other instantiations of Tj. Let T be the set of
factor templates and Z(x) be the partition func-
tion for normalization. The probability distri-
bution can then be written as p(y|x) — 1
</bodyText>
<equation confidence="0.998217333333333">
Z(x)
7��77 j7—
11T�ET 11(xi,Yi)∈Tj exp (EkK=j1 θjkfjk(xi,yi)).
</equation>
<bodyText confidence="0.986057333333333">
FACTORIE1 (McCallum et al., 2008; McCallum
et al., 2009) is an implementation of imperatively
defined factor graphs in the context of Markov
</bodyText>
<figure confidence="0.642698941176471">
1http://factorie.cs.umass.edu
subjective target
better than CCD shift systems
POS=JJR POS=NN
W=better W=shift
POS-W=better JJR W=systems
POS-W=shift NN
POS-W=systems NNS
POS-SEQ=NN-NNS
ONE-EDGE-POS=JJR NO-CLOSE-NOUN
ONE-EDGE-W=better ONE-EDGE-POS=NN
ONE-EDGE-POS-W=better JJR ONE-EDGE-POS=NNS
ONE-EDGE-POS-SEQ=JJR ONE-EDGE-W=shift
BOTH-POS=JJR ONE-EDGE-W=sensors
BOTH-W=better BOTH-POS=NN
BOTH-POS-W=better JJR BOTH-POS=NNS
BOTH-POS-POS-SEQ=JJR ...
</figure>
<figureCaption confidence="0.98335775">
Figure 1: Example for features extracted for target
and subjective expressions (text snippet taken from
the camera data set (Kessler et al., 2010)). IOB-like
features are merged for simplicity in this depiction.
</figureCaption>
<bodyText confidence="0.999666">
chain Monte Carlo (MCMC) inference, a common
approach for inference in very large graph struc-
tures (Culotta and McCallum, 2006; Richardson
and Domingos, 2006; Milch et al., 2006). The
term imperative is used to denote that actual code
in an imperative programming language is writ-
ten to describe templates and the relationship of
tuples they yield. This flexibility is beneficial for
modeling inter-dependencies as well as designing
information flow in joint models.
</bodyText>
<subsectionHeader confidence="0.998577">
2.2 Model
</subsectionHeader>
<bodyText confidence="0.985659902439024">
Our model is similar to a semi-Markov conditional
random field (Sarawagi and Cohen, 2004). It pre-
dicts the offsets for target mentions and subjective
phrases and can use the information of each other
during inference. In contrast to a linear chain con-
ditional random field (Lafferty et al., 2001), this al-
lows for taking distant dependencies of unobserved
variables into account and simplifies the design of
features measuring characteristics of multi-token
phrases. The relevant variables, i. e. target and sub-
jective phrase, are modelled via complex span vari-
ables of the form s = (l, r, c) with a left and right
offset l and r, and a class c ∈ {target, subjective}.
These offsets denote the span on a token sequence
t = (t1, . . . , tn).
We use two different templates to define factors
between variables: a single span template and an
inter-span template. The single span template de-
fines factors with scores based on features of the
tokens in the span and its vicinity. In our model,
all features are boolean. As token-based features
we use the POS tag, the lower-case representation
of the token as well as both in combination. The
actual span representation consists of these features
prefixed with “I” for all tokens in the span, with “B”
for the token at the beginning of the span, and with
“E” for the token at the end of the span. In addition,
the sequence of POS tags of all tokens in the span
is included as a feature.
The inter-span template takes three characteris-
tics of spans into account: Firstly, we measure if
a potential target span contains a noun which is
the closest noun to a subjective expression. Sec-
ondly, we measure for each span if a span of the
other class is in the same sentence. A third fea-
ture indicates whether there is only one edge in the
dependency graph between the tokens contained
in spans of a different class. These features are
to a great extent inspired by Jakob and Gurevych
single span
inter span
</bodyText>
<page confidence="0.923515">
849
</page>
<bodyText confidence="0.999212743589743">
(2010). For parsing, we use the Stanford parser
(Klein and Manning, 2003).
The features described so far, however, cannot
differentiate between a possible aspect mention
which is a target of a subjective expression and
one which is not. Therefore, the features of the
inter-span template are actually built by taking the
cross-product of the three described characteristics
with all single-span features. Spans which are not
in the context of a span of a different class are rep-
resented by a ‘negated’ feature (namely No-Close-
Noun, No-Single-Edge, and Not-Both-In-Sentence).
The example in Figure 1 shows features for two
spans which are in context of each other. All of
these features representing the text are taken into
account for each class, i. e., target and subjective
expression.
Inference is performed via Markov Chain Monte
Carlo (MCMC) sampling. In each sampling step,
only the variables which actually change need to
be evaluated, and therefore the sampler directs the
process of unrolling the templates to factors. These
world changes are necessary to find the maximum
a posteriori (MAP) configuration as well as learn-
ing the parameters of the model. For each token
in the sequence, a span of length one of each class
is proposed if no span containing the token exists.
For each existing span, it is proposed to change
its label, shorten or extend it by one token if pos-
sible (all at the beginning and at the end of the
span, respectively). Finally, a span can be removed
completely.
In order to learn the parameters of our model, we
apply SampleRank (Wick et al., 2011). A crucial
component in the framework is the objective func-
tion which gives feedback about the quality of a
sample proposal during training. We use the follow-
ing objective function f(t) to evaluate a proposed
span t:
</bodyText>
<equation confidence="0.9183525">
f(t) = max
g∈s
</equation>
<bodyText confidence="0.9999565">
where s is the set of all spans in the gold standard.
Further, the function o calculates the overlap in
terms of tokens of two spans and the function p
returns the number of tokens in t that are not con-
tained in g, i. e., those which are outside the overlap
(both functions taking into account the class of the
span). Thus, the first part of the objective function
represents the fraction of correctly proposed con-
tiguous tokens, while the second part penalizes a
span for containing too many tokens that are out-
side the best span. Here, α is a parameter which
controls the penalty.
</bodyText>
<sectionHeader confidence="0.999289" genericHeader="evaluation">
3 Results and Discussion
</sectionHeader>
<subsectionHeader confidence="0.989012">
3.1 Experimental Setting
</subsectionHeader>
<bodyText confidence="0.999991">
We report results on the J.D. Power and Associates
Sentiment Corpora2, an annotated data set of blog
posts in the car and in the camera domain (Kessler
et al., 2010). From the rich annotation set, we
use subjective terms and entity mentions which
are in relation to them as targets. We do not con-
sider comitter, negator, neutralizer,
comparison, opo, or descriptor annota-
tions to be subjective expressions. Results on these
data sets are compared to Jakob and Gurevych
(2010).
In addition, we report results on a Twitter data
set3 for the first time (Spina et al., 2012). Here,
we use a Twitter-specific tokenizer and POS tag-
ger4 (Owoputi et al., 2013) instead of the Stanford
parser. Hence, the single-edge-based feature de-
scribed in Section 2.2 is not used for this dataset. A
short summary of the datasets is given in Table 1.
As evaluation metric we use the F1 measure, the
harmonic mean between precision and recall. True
positive spans are evaluated in a perfect match and
approximate match mode, where the latter regards
a span as positive if one token within it is included
in a corresponding span in the gold standard. In this
case, other predicted spans matching the same gold
span do not count as false positives. In the objective
function, α is set to 0.01 to prefer spans which are
longer than the gold phrase over predicting no span.
Four different experiments are performed (all
via 10-fold cross validation): First, predicting sub-
jectivity expressions followed by predicting targets
while making use of the previous prediction. Sec-
</bodyText>
<footnote confidence="0.969568">
2http://verbs.colorado.edu/jdpacorpus/
3http://nlp.uned.es/˜damiano/datasets/
entityProfiling_ORM_Twitter.html
4In version 0.3, http://www.ark.cs.cmu.edu/
</footnote>
<table confidence="0.9236426">
TweetNLP/
Car Camera Twitter
Texts 457 178 9238
Targets 11966 4516 1418
Subjectives 15056 5128 1519
</table>
<tableCaption confidence="0.999401">
Table 1: Statistics of the data sets.
</tableCaption>
<figure confidence="0.935289210526316">
o(t, g) α · p(t,g),
|g|
850
1
0.8
0.6
F1
0.4
0.2
0
0.53 0.61 0.44 0.65 0.65 1.00 1.00 0.71 1.00
0.65
0.60 0.58
0.54 0.50
0.48
0.32
pred. S. → T. pred. T. → S. Gold S. → T. Gold T. → S. Jakob 2010
Target-F1 Partial Target-F1
Subjective-F1 Partial Subjective-F1
</figure>
<figureCaption confidence="0.992442">
Figure 2: Results for the workflow of first predicting subjective phrases, then targets (pred. S. → T.), and
vice versa (pred. T. → S.), as well as in comparison to having perfect information for the first step for the
camera data set.
</figureCaption>
<figure confidence="0.998035588235294">
0.51 0.64 0.43 0.69 0.62 1.00 1.00 0.74 1.00
0.70
0.66
0.56 0.55
0.50
0.43
0.33
pred. S. → T. pred. T. → S. Gold S. → T. Gold T. → S. Jakob 2010
1
0.8
0.6
F1
0.4
0.2
0
Target-F1 Partial Target-F1
Subjective-F1 Partial Subjective-F1
</figure>
<figureCaption confidence="0.999954">
Figure 3: Results for the car data set.
</figureCaption>
<bodyText confidence="0.999912444444444">
ond, predicting targets followed by predicting sub-
jective expressions. Third, assuming perfect knowl-
edge of subjective expressions when predicting tar-
gets, and fourth, assuming perfect knowledge of
targets in predicting subjective expressions. This
provides us with the information how good a pre-
diction can be with perfect knowledge of the other
variable as well as an estimate of how good the
prediction can be without any previous knowledge.
</bodyText>
<subsectionHeader confidence="0.852145">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.999180481481482">
Figures 2, 3 and 4 show the results for the four
different settings compared to the results by Jakob
and Gurevych (2010) for cars and cameras. The
darker bars correspond to perfect match, the lighter
ones to the increase when taking partial matches
into account. In the following we only discuss the
perfect match.
Comparing the results (for the car and camera
data sets, Figure 2 and 3) for subjectivity predic-
tion, one can observe a limited performance when
targets are not known (0.54 F1 for the camera set,
0.56 F1 for the car set), an upper bound with per-
fect target information is much higher (0.65 F1,
0.7 F1). When first predicting targets followed by
subjective term prediction, we obtain results of
0.6 F1 and 0.66 F1. The results for target predic-
tion are much lower when not knowing subjec-
tive expressions in advance (0.32 F1, 0.33 F1), and
clearly increase with predicted subjective expres-
sions (0.48 F1, 0.43 F1) and outperform previous
results when compared to Jakob and Gurevych
(2010) (0.58 F1, 0.55 F1 in comparison to their
0.5 F1 on both sets).
The results for the Twitter data set show the same
characteristics (in Figure 4). However, they are
generally much lower. In addition, the difference
between exact and partial match evaluation modes
</bodyText>
<page confidence="0.993662">
851
</page>
<figure confidence="0.987376315789474">
1
0.8
0.6
F1
0.4
0.2
0
1.00 1.00
0.67
0.60
0.42 0.40 0.41
0.32 0.40
0.35
0.26 0.28
0.22
0.13
pred. S. → T. pred. T. → S. Gold S. → T. Gold T. → S.
Target-F1 Partial Target-F1
Subjective-F1 Partial Subjective-F1
</figure>
<figureCaption confidence="0.99999">
Figure 4: Results for the Twitter data set.
Figure 5: Evaluation of the impact of different features.
</figureCaption>
<figure confidence="0.9988131875">
Sentence Edge Noun All Sentence Edge Noun All
(a) Camera Data Set, given subjective terms. (b) Camera Data Set, given target terms.
F1
0.8
0.6
0.4
0.2
0
1
F1
0.8
0.6
0.4
0.2
0
1
0.68
0.62
0.55
0.51
0.17
0.17
0.71
0.65
0.48
0.41
0.57
0.48
0.52
0.42
0.65
0.58
</figure>
<bodyText confidence="0.966506083333333">
is higher. This is due to the existence of many more
phrases spanning multiple tokens.
Exemplarily, the impact of the three features in
the inter-span templates for the camera data set is
depicted in Figure 5 for (a) given subjective terms
(b) given targets, respectively. Detecting the clos-
est noun is mainly of importance for target iden-
tification and only to a minor extent for detecting
subjective phrases. A short path in the dependency
graph and detecting if both phrases are in the same
sentence have a high positive impact for both sub-
jective and target phrases.
</bodyText>
<subsectionHeader confidence="0.999424">
3.3 Conclusion and Discussion
</subsectionHeader>
<bodyText confidence="0.999903666666667">
The experiments in this paper show that target
phrases and subjective terms are clearly interde-
pendent. However, the impact of knowledge about
one type of entity for the prediction of the other
type of entity has been shown to be asymmetric.
The results clearly suggest that the impact of sub-
jective terms on target terms is higher than the other
way round. Therefore, if a pipeline architecture is
chosen, this order is to be preferred. However, the
results with perfect knowledge of the counterpart
entity show (in both directions) that the entities
influence each other positively. Therefore, the chal-
lenge of extracting subjective expressions and their
targets is a great candidate for applying supervised,
joint inference.
</bodyText>
<sectionHeader confidence="0.998299" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999451625">
Roman Klinger has been funded by the “It’s
OWL” project (“Intelligent Technical Systems
Ostwestfalen-Lippe”, http://www.its-owl.
de/), a leading-edge cluster of the German Min-
istry of Education and Research. We thank the
information extraction and synthesis laboratory
(IESL) at the University of Massachusetts Amherst
for their support.
</bodyText>
<page confidence="0.99659">
852
</page>
<sectionHeader confidence="0.988905" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999669660550459">
Yoonjung Choi, Seongchan Kim, and Sung-Hyon
Myaeng. 2010. Detecting Opinions and their Opin-
ion Targets in NTCIR-8. Proceedings of NTCIR8
Workshop Meeting, pages 249–254.
A. Culotta and A. McCallum. 2006. Tractable Learn-
ing and Inference with High-Order Representations.
In ICML Workshop on Open Problems in Statistical
Relational Learning.
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the tenth
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, pages 168–177,
New York, NY, USA. ACM.
Niklas Jakob and Iryna Gurevych. 2010. Extracting
opinion targets in a single- and cross-domain set-
ting with conditional random fields. In Proceed-
ings of the 2010 Conference on Empirical Methods
in Natural Language Processing, pages 1035–1045,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Richard Johansson and Alessandro Moschitti. 2011.
Extracting opinion expressions and their polarities:
exploration of pipelines and joint models. In Pro-
ceedings of the 49th Annual Meeting of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies: short papers – Volume 2, pages
101–106, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Jason S. Kessler, Miriam Eckert, Lyndsie Clark, and
Nicolas Nicolov. 2010. The 2010 ICWSM JDPA
Sentment Corpus for the Automotive Domain. In
4th International AAAI Conference on Weblogs and
Social Media Data Workshop Challenge (ICWSM-
DWC 2010).
D. Klein and Ch. D. Manning. 2003. Fast exact in-
ference with a factored model for natural language
parsing. In Advances in Neural Information Process-
ing Systems 16 [Neural Information Processing Sys-
tems.
F.R. Kschischang, B.J. Frey, and H.-A. Loeliger. 2001.
Factor graphs and the sum-product algorithm. Infor-
mation Theory, IEEE Trans on Information Theory,
47(2):498–519.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In International Conference on Ma-
chine Learning, pages 282–289.
Fangtao Li, Minlie Huang, and Xiaoyan Zhu. 2010.
Sentiment analysis with global topics and local de-
pendency. In Proceedings of the Twenty-Fourth
AAAI Conference on Artificial Intelligence, pages
1371–1376, Atlanta, Georgia, USA.
A. McCallum, K. Rohanimanesh, M. Wick, K. Schultz,
and Sameer Singh. 2008. FACTORIE: Efficient
Probabilistic Programming via Imperative Declara-
tions of Structure, Inference and Learning. In NIPS
Workshop on Probabilistic Programming.
Andrew McCallum, Karl Schultz, and Sameer Singh.
2009. FACTORIE: Probabilistic programming via
imperatively defined factor graphs. In Neural Infor-
mation Processing Systems (NIPS).
B. Milch, B. Marthi, and S. Russell. 2006. BLOG:
Relational Modeling with Unknown Objects. Ph.D.
thesis, University of California, Berkeley.
O. Owoputi, B. OConnor, Ch. Dyer, K. Gimpely,
N. Schneider, and N. A. Smith. 2013. Improved
part-of-speech tagging for online conversational text
with word clusters. In The 2010 Annual Conference
of the North American Chapter of the Association
for Computational Linguistics.
Bo Pang and Lillian Lee. 2004. A sentimental edu-
cation: Sentiment analysis using subjectivity sum-
marization based on minimum cuts. In Proceedings
of the 42nd Meeting of the Association for Compu-
tational Linguistics, Main Volume, pages 271–278,
Barcelona, Spain, July.
Ana-Maria Popescu and Oren Etzioni. 2005. Extract-
ing product features and opinions from reviews. In
Proceedings of Human Language Technology Con-
ference and Conference on Empirical Methods in
Natural Language Processing, pages 339–346, Van-
couver, British Columbia, Canada, October. Associ-
ation for Computational Linguistics.
M. Richardson and P. Domingos. 2006. Markov logic
networks. Machine Learning, 62(1-2):107–136.
Sunita Sarawagi and William W. Cohen. 2004. Semi-
markov conditional random fields for information
extraction. In Advances in Neural Information Pro-
cessing Systems 17 [Neural Information Processing
Systems.
Asad Sayeed, Jordan Boyd-Graber, Bryan Rusk, and
Amy Weinberg. 2012. Grammatical structures for
word-level sentiment detection. In Proceedings of
the 2012 Conference of the North American Chap-
ter of the Association for Computational Linguis-
tics: Human Language Technologies, pages 667–
676, Montr´eal, Canada, June. Association for Com-
putational Linguistics.
D. Spina, E. Meij, A. Oghina, M. T. Bui, M. Breuss,
and M. de Rijke. 2012. A Corpus for Entity Pro-
filing in Microblog Posts. In LREC Workshop on
Information Access Technologies for Online Reputa-
tion Management.
Oscar T¨ackstr¨om and Ryan McDonald. 2011. Semi-
supervised latent variable models for sentence-level
sentiment analysis. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies, pages
</reference>
<page confidence="0.991471">
853
</page>
<reference confidence="0.999645461538462">
569–574, Portland, Oregon, USA, June. Association
for Computational Linguistics.
M. Wick, K. Rohanimanesh, K. Bellare, A. Culotta,
and A. McCallum. 2011. SampleRank: Training
factor graphs with atomic gradients. In Interna-
tional Conference on Machine Learning.
Bishan Yang and Claire Cardie. 2012. Extracting opin-
ion expressions with semi-markov conditional ran-
dom fields. In Proceedings of the 2012 Joint Con-
ference on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning, pages 1335–1345, Stroudsburg, PA, USA.
Association for Computational Linguistics.
</reference>
<page confidence="0.999126">
854
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.284045">
<title confidence="0.912503">Bidirectional Inter-dependencies of Subjective Expressions Targets and their Value for a Joint Model</title>
<author confidence="0.741771">Klinger</author>
<affiliation confidence="0.719716333333333">Semantic Computing Cognitive Interaction Technology – Center of Excellence Bielefeld</affiliation>
<address confidence="0.99581">33615 Bielefeld,</address>
<abstract confidence="0.999264818181818">Opinion mining is often regarded as a classification or segmentation task, involving the prediction of i) subjective expressions, ii) their target and iii) their polarity. Intuitively, these three variables are bidirectionally interdependent, but most work has either attempted to predict them in isolation or proposing pipeline-based approaches that cannot model the bidirectional interaction between these variables. Towards better understanding the interaction between these variables, we propose a model that allows for analyzing the relation of target and subjective phrases in both directions, thus providing an upper bound for the impact of a joint model in comparison to a pipeline model. We report results on two public datasets (cameras and cars), showing that our model outperforms state-ofthe-art models, as well as on a new dataset consisting of Twitter posts.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yoonjung Choi</author>
<author>Seongchan Kim</author>
<author>Sung-Hyon Myaeng</author>
</authors>
<title>Detecting Opinions and their Opinion Targets in NTCIR-8.</title>
<date>2010</date>
<booktitle>Proceedings of NTCIR8 Workshop Meeting,</booktitle>
<pages>249--254</pages>
<contexts>
<context position="1661" citStr="Choi et al., 2010" startWordPosition="242" endWordPosition="245"> two public datasets (cameras and cars), showing that our model outperforms state-ofthe-art models, as well as on a new dataset consisting of Twitter posts. 1 Introduction Sentiment analysis or opinion mining is the task of identifying subjective statements about products, their polarity (e. g. positive, negative or neutral) in addition to the particular aspect or feature of the entity that is under discussion, i. e., the socalled target. Opinion analysis is thus typically approached as a classification (T¨ackstr¨om and McDonald, 2011; Sayeed et al., 2012; Pang and Lee, 2004) or segmentation (Choi et al., 2010; Johansson and Moschitti, 2011; Yang and Cardie, 2012) task by which fragments of the input are classified or labelled as representing a subjective phrase (Yang and Cardie, 2012), a polarity or a target (Hu and Liu, 2004; Li et al., 2010; Popescu and Etzioni, 2005; Jakob and Gurevych, 2010). As an example, the sentence “I like the low weight of the camera.” contains a subjective term “like”, and the target “low weight”, which can be classified as a positive statement. While the three key variables (subjective phrase, polarity and target) intuitively influence each other bidirectionally, most </context>
</contexts>
<marker>Choi, Kim, Myaeng, 2010</marker>
<rawString>Yoonjung Choi, Seongchan Kim, and Sung-Hyon Myaeng. 2010. Detecting Opinions and their Opinion Targets in NTCIR-8. Proceedings of NTCIR8 Workshop Meeting, pages 249–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Culotta</author>
<author>A McCallum</author>
</authors>
<title>Tractable Learning and Inference with High-Order Representations.</title>
<date>2006</date>
<booktitle>In ICML Workshop on Open Problems in Statistical Relational Learning.</booktitle>
<contexts>
<context position="6081" citStr="Culotta and McCallum, 2006" startWordPosition="915" endWordPosition="918">tems NNS POS-SEQ=NN-NNS ONE-EDGE-POS=JJR NO-CLOSE-NOUN ONE-EDGE-W=better ONE-EDGE-POS=NN ONE-EDGE-POS-W=better JJR ONE-EDGE-POS=NNS ONE-EDGE-POS-SEQ=JJR ONE-EDGE-W=shift BOTH-POS=JJR ONE-EDGE-W=sensors BOTH-W=better BOTH-POS=NN BOTH-POS-W=better JJR BOTH-POS=NNS BOTH-POS-POS-SEQ=JJR ... Figure 1: Example for features extracted for target and subjective expressions (text snippet taken from the camera data set (Kessler et al., 2010)). IOB-like features are merged for simplicity in this depiction. chain Monte Carlo (MCMC) inference, a common approach for inference in very large graph structures (Culotta and McCallum, 2006; Richardson and Domingos, 2006; Milch et al., 2006). The term imperative is used to denote that actual code in an imperative programming language is written to describe templates and the relationship of tuples they yield. This flexibility is beneficial for modeling inter-dependencies as well as designing information flow in joint models. 2.2 Model Our model is similar to a semi-Markov conditional random field (Sarawagi and Cohen, 2004). It predicts the offsets for target mentions and subjective phrases and can use the information of each other during inference. In contrast to a linear chain c</context>
</contexts>
<marker>Culotta, McCallum, 2006</marker>
<rawString>A. Culotta and A. McCallum. 2006. Tractable Learning and Inference with High-Order Representations. In ICML Workshop on Open Problems in Statistical Relational Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>168--177</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1882" citStr="Hu and Liu, 2004" startWordPosition="281" endWordPosition="284">f identifying subjective statements about products, their polarity (e. g. positive, negative or neutral) in addition to the particular aspect or feature of the entity that is under discussion, i. e., the socalled target. Opinion analysis is thus typically approached as a classification (T¨ackstr¨om and McDonald, 2011; Sayeed et al., 2012; Pang and Lee, 2004) or segmentation (Choi et al., 2010; Johansson and Moschitti, 2011; Yang and Cardie, 2012) task by which fragments of the input are classified or labelled as representing a subjective phrase (Yang and Cardie, 2012), a polarity or a target (Hu and Liu, 2004; Li et al., 2010; Popescu and Etzioni, 2005; Jakob and Gurevych, 2010). As an example, the sentence “I like the low weight of the camera.” contains a subjective term “like”, and the target “low weight”, which can be classified as a positive statement. While the three key variables (subjective phrase, polarity and target) intuitively influence each other bidirectionally, most work in the area of opinion mining has concentrated on either predicting one of these variables in isolation (e. g. subjective expressions by Yang and Cardie (2012)) or modeling the dependencies uni-directionally in a pip</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 168–177, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Niklas Jakob</author>
<author>Iryna Gurevych</author>
</authors>
<title>Extracting opinion targets in a single- and cross-domain setting with conditional random fields.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1035--1045</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1953" citStr="Jakob and Gurevych, 2010" startWordPosition="293" endWordPosition="296">rity (e. g. positive, negative or neutral) in addition to the particular aspect or feature of the entity that is under discussion, i. e., the socalled target. Opinion analysis is thus typically approached as a classification (T¨ackstr¨om and McDonald, 2011; Sayeed et al., 2012; Pang and Lee, 2004) or segmentation (Choi et al., 2010; Johansson and Moschitti, 2011; Yang and Cardie, 2012) task by which fragments of the input are classified or labelled as representing a subjective phrase (Yang and Cardie, 2012), a polarity or a target (Hu and Liu, 2004; Li et al., 2010; Popescu and Etzioni, 2005; Jakob and Gurevych, 2010). As an example, the sentence “I like the low weight of the camera.” contains a subjective term “like”, and the target “low weight”, which can be classified as a positive statement. While the three key variables (subjective phrase, polarity and target) intuitively influence each other bidirectionally, most work in the area of opinion mining has concentrated on either predicting one of these variables in isolation (e. g. subjective expressions by Yang and Cardie (2012)) or modeling the dependencies uni-directionally in a pipeline architecture, e. g. predicting targets on the basis of perfect an</context>
<context position="11305" citStr="Jakob and Gurevych (2010)" startWordPosition="1814" endWordPosition="1817"> too many tokens that are outside the best span. Here, α is a parameter which controls the penalty. 3 Results and Discussion 3.1 Experimental Setting We report results on the J.D. Power and Associates Sentiment Corpora2, an annotated data set of blog posts in the car and in the camera domain (Kessler et al., 2010). From the rich annotation set, we use subjective terms and entity mentions which are in relation to them as targets. We do not consider comitter, negator, neutralizer, comparison, opo, or descriptor annotations to be subjective expressions. Results on these data sets are compared to Jakob and Gurevych (2010). In addition, we report results on a Twitter data set3 for the first time (Spina et al., 2012). Here, we use a Twitter-specific tokenizer and POS tagger4 (Owoputi et al., 2013) instead of the Stanford parser. Hence, the single-edge-based feature described in Section 2.2 is not used for this dataset. A short summary of the datasets is given in Table 1. As evaluation metric we use the F1 measure, the harmonic mean between precision and recall. True positive spans are evaluated in a perfect match and approximate match mode, where the latter regards a span as positive if one token within it is in</context>
<context position="14015" citStr="Jakob and Gurevych (2010)" startWordPosition="2268" endWordPosition="2271">tive-F1 Figure 3: Results for the car data set. ond, predicting targets followed by predicting subjective expressions. Third, assuming perfect knowledge of subjective expressions when predicting targets, and fourth, assuming perfect knowledge of targets in predicting subjective expressions. This provides us with the information how good a prediction can be with perfect knowledge of the other variable as well as an estimate of how good the prediction can be without any previous knowledge. 3.2 Results Figures 2, 3 and 4 show the results for the four different settings compared to the results by Jakob and Gurevych (2010) for cars and cameras. The darker bars correspond to perfect match, the lighter ones to the increase when taking partial matches into account. In the following we only discuss the perfect match. Comparing the results (for the car and camera data sets, Figure 2 and 3) for subjectivity prediction, one can observe a limited performance when targets are not known (0.54 F1 for the camera set, 0.56 F1 for the car set), an upper bound with perfect target information is much higher (0.65 F1, 0.7 F1). When first predicting targets followed by subjective term prediction, we obtain results of 0.6 F1 and </context>
</contexts>
<marker>Jakob, Gurevych, 2010</marker>
<rawString>Niklas Jakob and Iryna Gurevych. 2010. Extracting opinion targets in a single- and cross-domain setting with conditional random fields. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1035–1045, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Extracting opinion expressions and their polarities: exploration of pipelines and joint models.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers –</booktitle>
<volume>2</volume>
<pages>101--106</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1692" citStr="Johansson and Moschitti, 2011" startWordPosition="246" endWordPosition="250">s (cameras and cars), showing that our model outperforms state-ofthe-art models, as well as on a new dataset consisting of Twitter posts. 1 Introduction Sentiment analysis or opinion mining is the task of identifying subjective statements about products, their polarity (e. g. positive, negative or neutral) in addition to the particular aspect or feature of the entity that is under discussion, i. e., the socalled target. Opinion analysis is thus typically approached as a classification (T¨ackstr¨om and McDonald, 2011; Sayeed et al., 2012; Pang and Lee, 2004) or segmentation (Choi et al., 2010; Johansson and Moschitti, 2011; Yang and Cardie, 2012) task by which fragments of the input are classified or labelled as representing a subjective phrase (Yang and Cardie, 2012), a polarity or a target (Hu and Liu, 2004; Li et al., 2010; Popescu and Etzioni, 2005; Jakob and Gurevych, 2010). As an example, the sentence “I like the low weight of the camera.” contains a subjective term “like”, and the target “low weight”, which can be classified as a positive statement. While the three key variables (subjective phrase, polarity and target) intuitively influence each other bidirectionally, most work in the area of opinion min</context>
</contexts>
<marker>Johansson, Moschitti, 2011</marker>
<rawString>Richard Johansson and Alessandro Moschitti. 2011. Extracting opinion expressions and their polarities: exploration of pipelines and joint models. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers – Volume 2, pages 101–106, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason S Kessler</author>
<author>Miriam Eckert</author>
<author>Lyndsie Clark</author>
<author>Nicolas Nicolov</author>
</authors>
<title>ICWSM JDPA Sentment Corpus for the Automotive Domain.</title>
<date>2010</date>
<booktitle>In 4th International AAAI Conference on Weblogs and Social Media Data Workshop Challenge (ICWSMDWC</booktitle>
<publisher>The</publisher>
<contexts>
<context position="5889" citStr="Kessler et al., 2010" startWordPosition="886" endWordPosition="889"> in the context of Markov 1http://factorie.cs.umass.edu subjective target better than CCD shift systems POS=JJR POS=NN W=better W=shift POS-W=better JJR W=systems POS-W=shift NN POS-W=systems NNS POS-SEQ=NN-NNS ONE-EDGE-POS=JJR NO-CLOSE-NOUN ONE-EDGE-W=better ONE-EDGE-POS=NN ONE-EDGE-POS-W=better JJR ONE-EDGE-POS=NNS ONE-EDGE-POS-SEQ=JJR ONE-EDGE-W=shift BOTH-POS=JJR ONE-EDGE-W=sensors BOTH-W=better BOTH-POS=NN BOTH-POS-W=better JJR BOTH-POS=NNS BOTH-POS-POS-SEQ=JJR ... Figure 1: Example for features extracted for target and subjective expressions (text snippet taken from the camera data set (Kessler et al., 2010)). IOB-like features are merged for simplicity in this depiction. chain Monte Carlo (MCMC) inference, a common approach for inference in very large graph structures (Culotta and McCallum, 2006; Richardson and Domingos, 2006; Milch et al., 2006). The term imperative is used to denote that actual code in an imperative programming language is written to describe templates and the relationship of tuples they yield. This flexibility is beneficial for modeling inter-dependencies as well as designing information flow in joint models. 2.2 Model Our model is similar to a semi-Markov conditional random </context>
<context position="10995" citStr="Kessler et al., 2010" startWordPosition="1764" endWordPosition="1767">ens in t that are not contained in g, i. e., those which are outside the overlap (both functions taking into account the class of the span). Thus, the first part of the objective function represents the fraction of correctly proposed contiguous tokens, while the second part penalizes a span for containing too many tokens that are outside the best span. Here, α is a parameter which controls the penalty. 3 Results and Discussion 3.1 Experimental Setting We report results on the J.D. Power and Associates Sentiment Corpora2, an annotated data set of blog posts in the car and in the camera domain (Kessler et al., 2010). From the rich annotation set, we use subjective terms and entity mentions which are in relation to them as targets. We do not consider comitter, negator, neutralizer, comparison, opo, or descriptor annotations to be subjective expressions. Results on these data sets are compared to Jakob and Gurevych (2010). In addition, we report results on a Twitter data set3 for the first time (Spina et al., 2012). Here, we use a Twitter-specific tokenizer and POS tagger4 (Owoputi et al., 2013) instead of the Stanford parser. Hence, the single-edge-based feature described in Section 2.2 is not used for th</context>
</contexts>
<marker>Kessler, Eckert, Clark, Nicolov, 2010</marker>
<rawString>Jason S. Kessler, Miriam Eckert, Lyndsie Clark, and Nicolas Nicolov. 2010. The 2010 ICWSM JDPA Sentment Corpus for the Automotive Domain. In 4th International AAAI Conference on Weblogs and Social Media Data Workshop Challenge (ICWSMDWC 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Manning</author>
</authors>
<title>Fast exact inference with a factored model for natural language parsing.</title>
<date>2003</date>
<booktitle>In Advances in Neural Information Processing Systems 16 [Neural Information Processing Systems.</booktitle>
<contexts>
<context position="8454" citStr="Manning, 2003" startWordPosition="1329" endWordPosition="1330"> included as a feature. The inter-span template takes three characteristics of spans into account: Firstly, we measure if a potential target span contains a noun which is the closest noun to a subjective expression. Secondly, we measure for each span if a span of the other class is in the same sentence. A third feature indicates whether there is only one edge in the dependency graph between the tokens contained in spans of a different class. These features are to a great extent inspired by Jakob and Gurevych single span inter span 849 (2010). For parsing, we use the Stanford parser (Klein and Manning, 2003). The features described so far, however, cannot differentiate between a possible aspect mention which is a target of a subjective expression and one which is not. Therefore, the features of the inter-span template are actually built by taking the cross-product of the three described characteristics with all single-span features. Spans which are not in the context of a span of a different class are represented by a ‘negated’ feature (namely No-CloseNoun, No-Single-Edge, and Not-Both-In-Sentence). The example in Figure 1 shows features for two spans which are in context of each other. All of th</context>
</contexts>
<marker>Manning, 2003</marker>
<rawString>D. Klein and Ch. D. Manning. 2003. Fast exact inference with a factored model for natural language parsing. In Advances in Neural Information Processing Systems 16 [Neural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F R Kschischang</author>
<author>B J Frey</author>
<author>H-A Loeliger</author>
</authors>
<title>Factor graphs and the sum-product algorithm. Information Theory,</title>
<date>2001</date>
<journal>IEEE Trans on Information Theory,</journal>
<volume>47</volume>
<issue>2</issue>
<contexts>
<context position="4115" citStr="Kschischang et al., 2001" startWordPosition="626" endWordPosition="629"> further steps towards joint inference. IDFs are a convenient way to define probabilistic graphical models that make structured predictions based on complex dependencies. 848 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 848–854, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics 2 A Model for the Extraction of Target Phrases and Subjective Expressions This section gives a brief introduction to imperatively defined factor graphs and then introduces our model. 2.1 Imperatively Defined Factor Graphs A factor graph (Kschischang et al., 2001) is a bipartite graph over factors and variables. Let factor graph G define a probability distribution over a set of output variables y conditioned on input variables x. A factor Ti computes a scalar value over the subset of variables xi and yi that are neighbors of Ti in the graph. Often this real-valued function is defined as the exponential of an inner product over sufficient statistics {fik(xi,yi)} and parameters {θik}, where k ∈ [1, Ki] and Ki is the number of parameters for factor Ti. A factor template Tj consists of parameters {θjk}, sufficient statistic functions {fjk}, and a descripti</context>
</contexts>
<marker>Kschischang, Frey, Loeliger, 2001</marker>
<rawString>F.R. Kschischang, B.J. Frey, and H.-A. Loeliger. 2001. Factor graphs and the sum-product algorithm. Information Theory, IEEE Trans on Information Theory, 47(2):498–519.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In International Conference on Machine Learning,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="6728" citStr="Lafferty et al., 2001" startWordPosition="1018" endWordPosition="1021">, 2006; Milch et al., 2006). The term imperative is used to denote that actual code in an imperative programming language is written to describe templates and the relationship of tuples they yield. This flexibility is beneficial for modeling inter-dependencies as well as designing information flow in joint models. 2.2 Model Our model is similar to a semi-Markov conditional random field (Sarawagi and Cohen, 2004). It predicts the offsets for target mentions and subjective phrases and can use the information of each other during inference. In contrast to a linear chain conditional random field (Lafferty et al., 2001), this allows for taking distant dependencies of unobserved variables into account and simplifies the design of features measuring characteristics of multi-token phrases. The relevant variables, i. e. target and subjective phrase, are modelled via complex span variables of the form s = (l, r, c) with a left and right offset l and r, and a class c ∈ {target, subjective}. These offsets denote the span on a token sequence t = (t1, . . . , tn). We use two different templates to define factors between variables: a single span template and an inter-span template. The single span template defines fac</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In International Conference on Machine Learning, pages 282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangtao Li</author>
<author>Minlie Huang</author>
<author>Xiaoyan Zhu</author>
</authors>
<title>Sentiment analysis with global topics and local dependency.</title>
<date>2010</date>
<booktitle>In Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence,</booktitle>
<pages>1371--1376</pages>
<location>Atlanta, Georgia, USA.</location>
<contexts>
<context position="1899" citStr="Li et al., 2010" startWordPosition="285" endWordPosition="288">ective statements about products, their polarity (e. g. positive, negative or neutral) in addition to the particular aspect or feature of the entity that is under discussion, i. e., the socalled target. Opinion analysis is thus typically approached as a classification (T¨ackstr¨om and McDonald, 2011; Sayeed et al., 2012; Pang and Lee, 2004) or segmentation (Choi et al., 2010; Johansson and Moschitti, 2011; Yang and Cardie, 2012) task by which fragments of the input are classified or labelled as representing a subjective phrase (Yang and Cardie, 2012), a polarity or a target (Hu and Liu, 2004; Li et al., 2010; Popescu and Etzioni, 2005; Jakob and Gurevych, 2010). As an example, the sentence “I like the low weight of the camera.” contains a subjective term “like”, and the target “low weight”, which can be classified as a positive statement. While the three key variables (subjective phrase, polarity and target) intuitively influence each other bidirectionally, most work in the area of opinion mining has concentrated on either predicting one of these variables in isolation (e. g. subjective expressions by Yang and Cardie (2012)) or modeling the dependencies uni-directionally in a pipeline architectur</context>
</contexts>
<marker>Li, Huang, Zhu, 2010</marker>
<rawString>Fangtao Li, Minlie Huang, and Xiaoyan Zhu. 2010. Sentiment analysis with global topics and local dependency. In Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence, pages 1371–1376, Atlanta, Georgia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
<author>K Rohanimanesh</author>
<author>M Wick</author>
<author>K Schultz</author>
<author>Sameer Singh</author>
</authors>
<title>FACTORIE: Efficient Probabilistic Programming via Imperative Declarations of Structure, Inference and Learning.</title>
<date>2008</date>
<booktitle>In NIPS Workshop on Probabilistic Programming.</booktitle>
<contexts>
<context position="3369" citStr="McCallum et al. (2008)" startWordPosition="516" endWordPosition="519">paper, we propose a model that can include bidirectional dependencies, attempting to answer the following questions which so far have not been addressed but provide the basis for a joint model: • What is the impact of the performance loss of a non-perfect subjective term extraction in comparison to perfect knowledge? • Further, how does perfect knowledge about targets influence the prediction of subjective terms? • How is the latter affected if the knowledge about targets is imperfect, i. e. predicted by a learned model? We study these questions using imperatively defined factor graphs (IDFs, McCallum et al. (2008), McCallum et al. (2009)) to show how these bidirectional dependencies can be modeled in an architecture which allows for further steps towards joint inference. IDFs are a convenient way to define probabilistic graphical models that make structured predictions based on complex dependencies. 848 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 848–854, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics 2 A Model for the Extraction of Target Phrases and Subjective Expressions This section gives a brief introduction to </context>
<context position="5185" citStr="McCallum et al., 2008" startWordPosition="808" endWordPosition="811"> Ki is the number of parameters for factor Ti. A factor template Tj consists of parameters {θjk}, sufficient statistic functions {fjk}, and a description of an arbitrary relationship between variables, yielding a set of tuples {(xj, yj)}. For each of these tuples, the factor template instantiates a factor that shares {θjk} and {fjk} with all other instantiations of Tj. Let T be the set of factor templates and Z(x) be the partition function for normalization. The probability distribution can then be written as p(y|x) — 1 Z(x) 7��77 j7— 11T�ET 11(xi,Yi)∈Tj exp (EkK=j1 θjkfjk(xi,yi)). FACTORIE1 (McCallum et al., 2008; McCallum et al., 2009) is an implementation of imperatively defined factor graphs in the context of Markov 1http://factorie.cs.umass.edu subjective target better than CCD shift systems POS=JJR POS=NN W=better W=shift POS-W=better JJR W=systems POS-W=shift NN POS-W=systems NNS POS-SEQ=NN-NNS ONE-EDGE-POS=JJR NO-CLOSE-NOUN ONE-EDGE-W=better ONE-EDGE-POS=NN ONE-EDGE-POS-W=better JJR ONE-EDGE-POS=NNS ONE-EDGE-POS-SEQ=JJR ONE-EDGE-W=shift BOTH-POS=JJR ONE-EDGE-W=sensors BOTH-W=better BOTH-POS=NN BOTH-POS-W=better JJR BOTH-POS=NNS BOTH-POS-POS-SEQ=JJR ... Figure 1: Example for features extracted f</context>
</contexts>
<marker>McCallum, Rohanimanesh, Wick, Schultz, Singh, 2008</marker>
<rawString>A. McCallum, K. Rohanimanesh, M. Wick, K. Schultz, and Sameer Singh. 2008. FACTORIE: Efficient Probabilistic Programming via Imperative Declarations of Structure, Inference and Learning. In NIPS Workshop on Probabilistic Programming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
<author>Karl Schultz</author>
<author>Sameer Singh</author>
</authors>
<title>FACTORIE: Probabilistic programming via imperatively defined factor graphs.</title>
<date>2009</date>
<booktitle>In Neural Information Processing Systems (NIPS).</booktitle>
<contexts>
<context position="3393" citStr="McCallum et al. (2009)" startWordPosition="520" endWordPosition="523">l that can include bidirectional dependencies, attempting to answer the following questions which so far have not been addressed but provide the basis for a joint model: • What is the impact of the performance loss of a non-perfect subjective term extraction in comparison to perfect knowledge? • Further, how does perfect knowledge about targets influence the prediction of subjective terms? • How is the latter affected if the knowledge about targets is imperfect, i. e. predicted by a learned model? We study these questions using imperatively defined factor graphs (IDFs, McCallum et al. (2008), McCallum et al. (2009)) to show how these bidirectional dependencies can be modeled in an architecture which allows for further steps towards joint inference. IDFs are a convenient way to define probabilistic graphical models that make structured predictions based on complex dependencies. 848 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 848–854, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics 2 A Model for the Extraction of Target Phrases and Subjective Expressions This section gives a brief introduction to imperatively defined fac</context>
<context position="5209" citStr="McCallum et al., 2009" startWordPosition="812" endWordPosition="815">rameters for factor Ti. A factor template Tj consists of parameters {θjk}, sufficient statistic functions {fjk}, and a description of an arbitrary relationship between variables, yielding a set of tuples {(xj, yj)}. For each of these tuples, the factor template instantiates a factor that shares {θjk} and {fjk} with all other instantiations of Tj. Let T be the set of factor templates and Z(x) be the partition function for normalization. The probability distribution can then be written as p(y|x) — 1 Z(x) 7��77 j7— 11T�ET 11(xi,Yi)∈Tj exp (EkK=j1 θjkfjk(xi,yi)). FACTORIE1 (McCallum et al., 2008; McCallum et al., 2009) is an implementation of imperatively defined factor graphs in the context of Markov 1http://factorie.cs.umass.edu subjective target better than CCD shift systems POS=JJR POS=NN W=better W=shift POS-W=better JJR W=systems POS-W=shift NN POS-W=systems NNS POS-SEQ=NN-NNS ONE-EDGE-POS=JJR NO-CLOSE-NOUN ONE-EDGE-W=better ONE-EDGE-POS=NN ONE-EDGE-POS-W=better JJR ONE-EDGE-POS=NNS ONE-EDGE-POS-SEQ=JJR ONE-EDGE-W=shift BOTH-POS=JJR ONE-EDGE-W=sensors BOTH-W=better BOTH-POS=NN BOTH-POS-W=better JJR BOTH-POS=NNS BOTH-POS-POS-SEQ=JJR ... Figure 1: Example for features extracted for target and subjective</context>
</contexts>
<marker>McCallum, Schultz, Singh, 2009</marker>
<rawString>Andrew McCallum, Karl Schultz, and Sameer Singh. 2009. FACTORIE: Probabilistic programming via imperatively defined factor graphs. In Neural Information Processing Systems (NIPS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Milch</author>
<author>B Marthi</author>
<author>S Russell</author>
</authors>
<title>BLOG: Relational Modeling with Unknown Objects.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>University of California, Berkeley.</institution>
<contexts>
<context position="6133" citStr="Milch et al., 2006" startWordPosition="923" endWordPosition="926">EDGE-W=better ONE-EDGE-POS=NN ONE-EDGE-POS-W=better JJR ONE-EDGE-POS=NNS ONE-EDGE-POS-SEQ=JJR ONE-EDGE-W=shift BOTH-POS=JJR ONE-EDGE-W=sensors BOTH-W=better BOTH-POS=NN BOTH-POS-W=better JJR BOTH-POS=NNS BOTH-POS-POS-SEQ=JJR ... Figure 1: Example for features extracted for target and subjective expressions (text snippet taken from the camera data set (Kessler et al., 2010)). IOB-like features are merged for simplicity in this depiction. chain Monte Carlo (MCMC) inference, a common approach for inference in very large graph structures (Culotta and McCallum, 2006; Richardson and Domingos, 2006; Milch et al., 2006). The term imperative is used to denote that actual code in an imperative programming language is written to describe templates and the relationship of tuples they yield. This flexibility is beneficial for modeling inter-dependencies as well as designing information flow in joint models. 2.2 Model Our model is similar to a semi-Markov conditional random field (Sarawagi and Cohen, 2004). It predicts the offsets for target mentions and subjective phrases and can use the information of each other during inference. In contrast to a linear chain conditional random field (Lafferty et al., 2001), thi</context>
</contexts>
<marker>Milch, Marthi, Russell, 2006</marker>
<rawString>B. Milch, B. Marthi, and S. Russell. 2006. BLOG: Relational Modeling with Unknown Objects. Ph.D. thesis, University of California, Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Gimpely Dyer</author>
<author>N Schneider</author>
<author>N A Smith</author>
</authors>
<title>Improved part-of-speech tagging for online conversational text with word clusters.</title>
<date>2013</date>
<booktitle>In The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<marker>Dyer, Schneider, Smith, 2013</marker>
<rawString>O. Owoputi, B. OConnor, Ch. Dyer, K. Gimpely, N. Schneider, and N. A. Smith. 2013. Improved part-of-speech tagging for online conversational text with word clusters. In The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Meeting of the Association for Computational Linguistics, Main Volume,</booktitle>
<pages>271--278</pages>
<location>Barcelona, Spain,</location>
<contexts>
<context position="1626" citStr="Pang and Lee, 2004" startWordPosition="236" endWordPosition="239"> pipeline model. We report results on two public datasets (cameras and cars), showing that our model outperforms state-ofthe-art models, as well as on a new dataset consisting of Twitter posts. 1 Introduction Sentiment analysis or opinion mining is the task of identifying subjective statements about products, their polarity (e. g. positive, negative or neutral) in addition to the particular aspect or feature of the entity that is under discussion, i. e., the socalled target. Opinion analysis is thus typically approached as a classification (T¨ackstr¨om and McDonald, 2011; Sayeed et al., 2012; Pang and Lee, 2004) or segmentation (Choi et al., 2010; Johansson and Moschitti, 2011; Yang and Cardie, 2012) task by which fragments of the input are classified or labelled as representing a subjective phrase (Yang and Cardie, 2012), a polarity or a target (Hu and Liu, 2004; Li et al., 2010; Popescu and Etzioni, 2005; Jakob and Gurevych, 2010). As an example, the sentence “I like the low weight of the camera.” contains a subjective term “like”, and the target “low weight”, which can be classified as a positive statement. While the three key variables (subjective phrase, polarity and target) intuitively influenc</context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>Bo Pang and Lillian Lee. 2004. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In Proceedings of the 42nd Meeting of the Association for Computational Linguistics, Main Volume, pages 271–278, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ana-Maria Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>339--346</pages>
<publisher>Association for</publisher>
<location>Vancouver, British Columbia, Canada,</location>
<contexts>
<context position="1926" citStr="Popescu and Etzioni, 2005" startWordPosition="289" endWordPosition="292"> about products, their polarity (e. g. positive, negative or neutral) in addition to the particular aspect or feature of the entity that is under discussion, i. e., the socalled target. Opinion analysis is thus typically approached as a classification (T¨ackstr¨om and McDonald, 2011; Sayeed et al., 2012; Pang and Lee, 2004) or segmentation (Choi et al., 2010; Johansson and Moschitti, 2011; Yang and Cardie, 2012) task by which fragments of the input are classified or labelled as representing a subjective phrase (Yang and Cardie, 2012), a polarity or a target (Hu and Liu, 2004; Li et al., 2010; Popescu and Etzioni, 2005; Jakob and Gurevych, 2010). As an example, the sentence “I like the low weight of the camera.” contains a subjective term “like”, and the target “low weight”, which can be classified as a positive statement. While the three key variables (subjective phrase, polarity and target) intuitively influence each other bidirectionally, most work in the area of opinion mining has concentrated on either predicting one of these variables in isolation (e. g. subjective expressions by Yang and Cardie (2012)) or modeling the dependencies uni-directionally in a pipeline architecture, e. g. predicting targets</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Ana-Maria Popescu and Oren Etzioni. 2005. Extracting product features and opinions from reviews. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, pages 339–346, Vancouver, British Columbia, Canada, October. Association for Computational Linguistics. M. Richardson and P. Domingos. 2006. Markov logic networks. Machine Learning, 62(1-2):107–136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sunita Sarawagi</author>
<author>William W Cohen</author>
</authors>
<title>Semimarkov conditional random fields for information extraction.</title>
<date>2004</date>
<booktitle>In Advances in Neural Information Processing Systems 17 [Neural Information Processing Systems.</booktitle>
<contexts>
<context position="6521" citStr="Sarawagi and Cohen, 2004" startWordPosition="983" endWordPosition="986">like features are merged for simplicity in this depiction. chain Monte Carlo (MCMC) inference, a common approach for inference in very large graph structures (Culotta and McCallum, 2006; Richardson and Domingos, 2006; Milch et al., 2006). The term imperative is used to denote that actual code in an imperative programming language is written to describe templates and the relationship of tuples they yield. This flexibility is beneficial for modeling inter-dependencies as well as designing information flow in joint models. 2.2 Model Our model is similar to a semi-Markov conditional random field (Sarawagi and Cohen, 2004). It predicts the offsets for target mentions and subjective phrases and can use the information of each other during inference. In contrast to a linear chain conditional random field (Lafferty et al., 2001), this allows for taking distant dependencies of unobserved variables into account and simplifies the design of features measuring characteristics of multi-token phrases. The relevant variables, i. e. target and subjective phrase, are modelled via complex span variables of the form s = (l, r, c) with a left and right offset l and r, and a class c ∈ {target, subjective}. These offsets denote</context>
</contexts>
<marker>Sarawagi, Cohen, 2004</marker>
<rawString>Sunita Sarawagi and William W. Cohen. 2004. Semimarkov conditional random fields for information extraction. In Advances in Neural Information Processing Systems 17 [Neural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asad Sayeed</author>
<author>Jordan Boyd-Graber</author>
<author>Bryan Rusk</author>
<author>Amy Weinberg</author>
</authors>
<title>Grammatical structures for word-level sentiment detection.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>667--676</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="1605" citStr="Sayeed et al., 2012" startWordPosition="232" endWordPosition="235">el in comparison to a pipeline model. We report results on two public datasets (cameras and cars), showing that our model outperforms state-ofthe-art models, as well as on a new dataset consisting of Twitter posts. 1 Introduction Sentiment analysis or opinion mining is the task of identifying subjective statements about products, their polarity (e. g. positive, negative or neutral) in addition to the particular aspect or feature of the entity that is under discussion, i. e., the socalled target. Opinion analysis is thus typically approached as a classification (T¨ackstr¨om and McDonald, 2011; Sayeed et al., 2012; Pang and Lee, 2004) or segmentation (Choi et al., 2010; Johansson and Moschitti, 2011; Yang and Cardie, 2012) task by which fragments of the input are classified or labelled as representing a subjective phrase (Yang and Cardie, 2012), a polarity or a target (Hu and Liu, 2004; Li et al., 2010; Popescu and Etzioni, 2005; Jakob and Gurevych, 2010). As an example, the sentence “I like the low weight of the camera.” contains a subjective term “like”, and the target “low weight”, which can be classified as a positive statement. While the three key variables (subjective phrase, polarity and target)</context>
</contexts>
<marker>Sayeed, Boyd-Graber, Rusk, Weinberg, 2012</marker>
<rawString>Asad Sayeed, Jordan Boyd-Graber, Bryan Rusk, and Amy Weinberg. 2012. Grammatical structures for word-level sentiment detection. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 667– 676, Montr´eal, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Spina</author>
<author>E Meij</author>
<author>A Oghina</author>
<author>M T Bui</author>
<author>M Breuss</author>
<author>M de Rijke</author>
</authors>
<title>A Corpus for Entity Profiling in Microblog Posts.</title>
<date>2012</date>
<booktitle>In LREC Workshop on Information Access Technologies for Online Reputation Management.</booktitle>
<marker>Spina, Meij, Oghina, Bui, Breuss, de Rijke, 2012</marker>
<rawString>D. Spina, E. Meij, A. Oghina, M. T. Bui, M. Breuss, and M. de Rijke. 2012. A Corpus for Entity Profiling in Microblog Posts. In LREC Workshop on Information Access Technologies for Online Reputation Management.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Ryan McDonald</author>
</authors>
<title>Semisupervised latent variable models for sentence-level sentiment analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>569--574</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<marker>T¨ackstr¨om, McDonald, 2011</marker>
<rawString>Oscar T¨ackstr¨om and Ryan McDonald. 2011. Semisupervised latent variable models for sentence-level sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 569–574, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Wick</author>
<author>K Rohanimanesh</author>
<author>K Bellare</author>
<author>A Culotta</author>
<author>A McCallum</author>
</authors>
<title>SampleRank: Training factor graphs with atomic gradients.</title>
<date>2011</date>
<booktitle>In International Conference on Machine Learning.</booktitle>
<contexts>
<context position="9964" citStr="Wick et al., 2011" startWordPosition="1579" endWordPosition="1582">ler directs the process of unrolling the templates to factors. These world changes are necessary to find the maximum a posteriori (MAP) configuration as well as learning the parameters of the model. For each token in the sequence, a span of length one of each class is proposed if no span containing the token exists. For each existing span, it is proposed to change its label, shorten or extend it by one token if possible (all at the beginning and at the end of the span, respectively). Finally, a span can be removed completely. In order to learn the parameters of our model, we apply SampleRank (Wick et al., 2011). A crucial component in the framework is the objective function which gives feedback about the quality of a sample proposal during training. We use the following objective function f(t) to evaluate a proposed span t: f(t) = max g∈s where s is the set of all spans in the gold standard. Further, the function o calculates the overlap in terms of tokens of two spans and the function p returns the number of tokens in t that are not contained in g, i. e., those which are outside the overlap (both functions taking into account the class of the span). Thus, the first part of the objective function re</context>
</contexts>
<marker>Wick, Rohanimanesh, Bellare, Culotta, McCallum, 2011</marker>
<rawString>M. Wick, K. Rohanimanesh, K. Bellare, A. Culotta, and A. McCallum. 2011. SampleRank: Training factor graphs with atomic gradients. In International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bishan Yang</author>
<author>Claire Cardie</author>
</authors>
<title>Extracting opinion expressions with semi-markov conditional random fields.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>1335--1345</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1716" citStr="Yang and Cardie, 2012" startWordPosition="251" endWordPosition="254">hat our model outperforms state-ofthe-art models, as well as on a new dataset consisting of Twitter posts. 1 Introduction Sentiment analysis or opinion mining is the task of identifying subjective statements about products, their polarity (e. g. positive, negative or neutral) in addition to the particular aspect or feature of the entity that is under discussion, i. e., the socalled target. Opinion analysis is thus typically approached as a classification (T¨ackstr¨om and McDonald, 2011; Sayeed et al., 2012; Pang and Lee, 2004) or segmentation (Choi et al., 2010; Johansson and Moschitti, 2011; Yang and Cardie, 2012) task by which fragments of the input are classified or labelled as representing a subjective phrase (Yang and Cardie, 2012), a polarity or a target (Hu and Liu, 2004; Li et al., 2010; Popescu and Etzioni, 2005; Jakob and Gurevych, 2010). As an example, the sentence “I like the low weight of the camera.” contains a subjective term “like”, and the target “low weight”, which can be classified as a positive statement. While the three key variables (subjective phrase, polarity and target) intuitively influence each other bidirectionally, most work in the area of opinion mining has concentrated on </context>
</contexts>
<marker>Yang, Cardie, 2012</marker>
<rawString>Bishan Yang and Claire Cardie. 2012. Extracting opinion expressions with semi-markov conditional random fields. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1335–1345, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>