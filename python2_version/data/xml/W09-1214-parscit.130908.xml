<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002128">
<title confidence="0.95809">
The Crotal SRL System : a Generic Tool Based on Tree-structured CRF∗
</title>
<author confidence="0.792772">
Erwan Moreau Isabelle Tellier
</author>
<affiliation confidence="0.314042">
LIPN - CNRS UMR 7030 &amp; Univ. Paris 13 LIFO - Univ. Orl´eans
</affiliation>
<email confidence="0.942012">
Erwan.Moreau@lipn.univ-paris13.fr Isabelle.Tellier@univ-orleans.fr
</email>
<sectionHeader confidence="0.994444" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999687">
We present the Crotal system, used in the
CoNLL09 Shared Task. It is based on XCRF,
a highly configurable CRF library which can
take into account hierarchical relations. This
system had never been used in such a context
thus the performance is average, but we are
confident that there is room for progression.
</bodyText>
<sectionHeader confidence="0.998803" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9994912">
In this paper we present the Crotal Semantic Role
Labelling (SRL) system, which has been used in
the CoNLL 2009 Shared Task (Hajiˇc et al., 2009)1.
This system is based on Conditional Random Fields
(CRF) (Lafferty et al., 2001; Sutton and McCallum,
2006): our idea is that we can use the provided
dependency structure as the skeleton of a graphi-
cal model expressing independence asumptions in
a CRF model. CRF are a powerful machine learn-
ing technique that has been successfully applied to
a large number of natural language tasks, mainly
to tag sequences. Compared to classification tech-
niques, CRF can easily take into account dependen-
cies among annotations: it is therefore possible to
represent tree-like structures in the input of the al-
gorithm. Recently, CRF using tree structures were
used in (Finkel et al., 2008) in the case of parsing.
Before participating to this Shared Task, our pro-
totype had only been used to annotate function tags
in a French Treebank: these data were drastically
</bodyText>
<footnote confidence="0.982813666666667">
∗This work has been funded by the French National project
ANR-07-MDCO-03 “CRoTAL”.
1We have participated in the SRL-only category.
</footnote>
<bodyText confidence="0.999935964285714">
smaller, and the task was simpler. Therefore CoNLL
2009 ST is the first time the Crotal System is run
for a quite complex task, with so many data as in-
put, and seven different languages (Catalan, Span-
ish (Taul´e et al., 2008), Chinese (Palmer and Xue,
2009), Czech (Hajiˇc et al., 2006), English (Surdeanu
et al., 2008), German (Burchardt et al., 2006) and
Japanese (Kawahara et al., 2002)). In this context,
the performance we obtained seems reasonable: our
average F1-measure is 66.49% (evaluation dataset).
One of the advantages we want to emphasise
about our system is its genericity: the system does
not need a lot of information as input (we mainly
use pos and deprel columns, and the frame sets have
not been used), and it was able to achieve satisfy-
ing results for the seven different languages using
nearly the same parameters (differences were essen-
tially due to the volume of data, since it was some-
times necessary to reduce the processing time). Of
course, we hope to improve this prototype thanks to
this experience: it may become necessary to lose in
genericity in order to gain in performance, but our
goal is to maintain as much as possible this advan-
tage.
In section 2 we explain the general architecture
for Crotal, then we explain how features are selected
in our system in section 3, and finally we detail and
discuss the results in section 4.
</bodyText>
<sectionHeader confidence="0.974542" genericHeader="method">
2 The Crotal System Architecture
</sectionHeader>
<subsectionHeader confidence="0.845334">
2.1 General principle
</subsectionHeader>
<bodyText confidence="0.9979505">
The system we propose is based on the public library
XCRF (Gilleron et al., 2006; Jousse, 2007), which
</bodyText>
<page confidence="0.990485">
91
</page>
<note confidence="0.7622085">
Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task, pages 91–96,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999717352941176">
implements CRF model(s) to learn to annotate trees
represented by XML documents. Of course, its per-
formance depends on the way it is used, and espe-
cially on how features are chosen to reliably repre-
sent the labeled data. In order to keep the system
as generic as possible, features are generated auto-
matically and only a few parameters may vary. The
global process has been divided into a sequence of
steps, by creating clusters (one for each predicate,
except the less frequent ones). Indeed, one expects
that the behaviour of the arguments for a given pred-
icate is more regular than for all predicates put to-
gether. Moreover, the size of the training set for
all seven languages allows such a clustering, and it
would even be difficult to process the whole set of
predicates due to time and memory limitations. Thus
the global process is2:
</bodyText>
<listItem confidence="0.998944882352941">
1. Data conversion from CoNLL format to XCRF
format:
• For each sentence containing n predicates,
generate n different XML trees3.
• The tree is simply built following the
dependencies (as provided by the head
column). Therefore the possible non-
projectivity of a tree is ignored, though the
order of words is of course prefered when-
ever possible. An artificial root node is al-
ways added (useful for languages where
several roots are possible).
• In each such XML tree, there is only one
(marked) predicate, and in the annotated
version its arguments (extracted from the
corresponding column) and only them are
reported in the corresponding nodes.
</listItem>
<figureCaption confidence="0.555118">
Figure 1 shows the labeled XML tree obtained
for a (part of) example sentence.
</figureCaption>
<bodyText confidence="0.900994555555556">
2. Clustering by lemma: all dependency trees hav-
ing the same lemma as predicate are put to-
gether if the number of such trees is at least a
2Remark: unless stated otherwise, we will use terms
“lemma”, “POS tag” “dependency relation” or “head” to refer
to the information contained in the corresponding “P-columns”
for each word. It is worth noticing that performance would be
better using the “real” columns, but we have followed the in-
structions given by the organizers.
</bodyText>
<footnote confidence="0.9461185">
3Thus sentences with no predicate are skipped and several
trees possibly correspond to the same sentence.
</footnote>
<bodyText confidence="0.9996895">
given threshold (generally 3, also tested with
2 to 5). There is a special cluster for less fre-
quent lemmas4. Then, for each cluster, in train-
ing mode the process consists of:
</bodyText>
<listItem confidence="0.983629">
(a) Generation of features for the arguments
training step.
(b) The CRF model for arguments is trained
with XCRF.
(c) Generation of features for the senses train-
ing step.
(d) The CRF model for senses5 is trained with
XCRF.
</listItem>
<bodyText confidence="0.997743">
In annotation mode, the CRF model for argu-
ments is first applied to the input tree, then the
CRF model for senses (if possible, an individ-
ual evaluation is also computed).
</bodyText>
<listItem confidence="0.7361145">
3. Back conversion from XCRF format to CoNLL
format (in annotation mode).
</listItem>
<bodyText confidence="0.98772475">
In the framework of this task, features generation
is crucial for improving performance. That is why
we will mainly focus on that point in the remaining
of this paper.
</bodyText>
<subsectionHeader confidence="0.99617">
2.2 The XCRF Library
</subsectionHeader>
<bodyText confidence="0.999831166666667">
XCRF (Gilleron et al., 2006; Jousse, 2007) is a pub-
lic library which has been applied successfully to
HTML documents in order to extract information or
translate the tree structure into XML (Jousse, 2007).
More recently we have applied it to annotate func-
tion tags in a French Treebank.
In a CRF model, a feature is a function (usually
providing a boolean result) whose value depends on
the annotations present in a special clique of the
graph, and on the value of the observed data. In
our system, each feature is defined by a pair (C, T),
where:
</bodyText>
<listItem confidence="0.957216666666667">
• C is the set of annotations present in a given
clique, i.e. a completely connected subgraph
of the graphical structure between annotations.
</listItem>
<footnote confidence="0.9699685">
4This special cluster is used as a default case. In particular,
if an unknown lemma is encoutered during annotation, it will
be annotated using the model learned for this default cluster.
5Steps 2c and 2d are skipped if the lemma has only one pos-
sible sense (or no sense is needed, like in Japanese data and for
some Czech predicates).
</footnote>
<page confidence="0.994371">
92
</page>
<bodyText confidence="0.999752111111111">
Several solutions are possible to choose this
graph. In most of our experiments, we have
chosen a graph where only the node-parent
relationship between nodes is taken into ac-
count (denoted FT2), as illustrated by Figure
2. XCRF is also able to deal with simple one-
node cliques (no dependency between annota-
tion, denoted FT1) and node-parent-sibling re-
lationship (denoted FT3).
</bodyText>
<listItem confidence="0.768446545454545">
• T = {tl, ... , tn} is a (possibly empty) set
of boolean tests on the observation (i.e. not
depending on the annotations). Each ti is an
atomic test6: for example, the test “pos attribute
for first left sibling is NNS” is satisfied for node
3 in fig. 1. T is the conjunction of all ti.
For example, let us define the following FT2 fea-
ture (C, T), that would be true for node 4 in fig.
1: C is {apredparent = PRED ∧ apredcurrent =
C-A1} and T is {poschild1 = VB ∧ deprelparent =
VC}.
</listItem>
<sectionHeader confidence="0.89566" genericHeader="method">
3 Selecting Features
</sectionHeader>
<bodyText confidence="0.942323444444444">
Our goal is somehow to “learn” features from the
training set, in the sense that we do not explicitly
define them but generate them from the corpus. The
main parameters we use for generating a set of fea-
tures are the following:
• The feature type n, with n &lt; 3. All FT n′,
with n′ &lt; n, are also considered, because some
function tags possibly appear in FT n and not
(or more rarely) in FT n + 1.
</bodyText>
<listItem confidence="0.8989526">
• Various kind of accessible information (decom-
posed through two distinct parameters informa-
tion and neighbourhood):
– Information: form, lemma, POS tags, de-
pendency relation and various secondary
attributes (column features) are available
for all nodes (i.e. word), in every tree ex-
tracted from the corpus.
– Neighbourhood: Given a current node, the
“neighbourhood” defines the set of nodes
</listItem>
<footnote confidence="0.995596666666667">
6A test is provided to XCRF as an XPath expression, which
will be applied to the current node in the XML tree correspond-
ing to the sentence.
</footnote>
<table confidence="0.935711777777778">
Sentence
2, are
VBP, ROOT
3, risen
VBN, VC
4, strongly 8, in
RB, MNR IN, TMP
9, August
NNP, PMOD
</table>
<figureCaption confidence="0.990759">
Figure 1: a labeled example for the (part of) sentence
“Exports are thought to have risen strongly in August
[...]”: the nodes are represented with their POS tags, and
in bold face the corresponding annotation associated with
the predicate “thought” (label PRED was added during
preprocessing, see 3.1)
Figure 2: graph for a FT2-CRF for the annotation of the
sentence of Figure 1 (where ⊥ means “no annotation”)
</figureCaption>
<figure confidence="0.999736809523809">
1, Exports
NNS, SBJ
A1
5, thought
VBN, VC
PRED
6, to
TO, OPRD
C-A1
7, have
VB, IM
[...]
A1 PRED
C-A1
L
L L
L
L
L
L
[...]
</figure>
<page confidence="0.991487">
93
</page>
<bodyText confidence="0.984595">
that will be observed to help deduce its an-
notation: only this node, or also its parent,
possibly its siblings, etc.
</bodyText>
<listItem confidence="0.794717461538462">
• The maximum number of (atomic) tests in the
set T for these nodes: combining several tests
makes features more precise (conjunction), but
also more numerous.
A few other parameters may be added to speed up
learning:
• minimum proportion for an argument label
which is present in the data to be taken into ac-
count,
• minimum proportion for a feature which is
present in the data to be included in the model,
• and maximum number of sentences to process
by XCRF in the training step.
</listItem>
<bodyText confidence="0.99997675">
We try to use as less linguistic knowledge as pos-
sible, because we are interested in testing to what
extent the model is able to learn such knowledge by
itself. Moreover, we observe that using too many
features and/or examples as input in XCRF requires
a lot of time and memory (sometimes too much), so
we have to restrict the selection to the most relevant
kind of information in order to get a tractable ma-
chinery. This is why we use only POS tags (pos)
and dependency relations (deprel) (as one can see in
fig. 1). Finally the process of generating features
consists in parsing the training data in the follow-
ing way: for each encoutered clique, all the possible
(combinations of) tests concerning the given neigh-
bourhood are generated, and each of them forms a
feature together with the observed clique.
</bodyText>
<subsectionHeader confidence="0.999582">
3.1 Learning Argument Roles
</subsectionHeader>
<bodyText confidence="0.999986375">
In our system, the arguments and the sense of a pred-
icate are trained (or annotated) one after the other:
the former is always processed before the latter, thus
the dependency holds only in the direction from ar-
guments to sense. Therefore the training of argu-
ments only relies on the observed trees (actually
only the neighbourhood considered and the argu-
ments cliques). In order to help the learner locate
the right arguments, a special label PRED is added
as “argument” to the node corresponding to the tar-
get predicate: by this way cliques can more easily
take the tree structure into account in the neighbour-
hood of the predicate.
After some tests using the development set as
test set, we observed that the following parameters
were the best suited to build a reliable CRF model
(for the arguments) in a reasonable time (and thus
used them to learn the final models): the neigh-
bourhood consists in the node itself, its parent and
grand-parent, first and second siblings on both sides
and first child; the FT2 model performs quite cor-
rectly (FT3 has been discarded because it would
have taken too much time), and at most two tests
are included in a feature.
</bodyText>
<subsectionHeader confidence="0.999813">
3.2 Learning Predicate Senses
</subsectionHeader>
<bodyText confidence="0.999992782608696">
The step of predicting senses can use the arguments
that have been predicted in the previous step. In par-
ticular, the list of all arguments that have been found
is added and may be used as a test in any feature.
We did not use at all the frame sets provided with
the data: our system is based only on the sentences.
This choice is mainly guided by our goal to build a
generic system, thus does not need a lot of input in-
formation in various formats. The lemma part of the
predicate is simply copied from the lemma column
(this may cause a few errors due to wrong lemmas,
as observed in the English data).
The fact that sentences have been classified by
lemma makes it convenient to learn/annotate senses:
of course lemmas which can not have more than one
sense are easily processed. In the general case, we
also use XCRF to learn a model to assign senses for
each lemma, using the following parameters: there
is no need to use another model than FT1, since in
each tree there is only one (clearly identified) node
to label; a close neighbourhood (parent, first left and
right siblings and first child) and only two tests are
enough to obtain satisfactory results.
</bodyText>
<sectionHeader confidence="0.999737" genericHeader="evaluation">
4 Results and Discussion
</sectionHeader>
<subsectionHeader confidence="0.974086">
4.1 General Results
</subsectionHeader>
<bodyText confidence="0.999935">
Due to limited time and resources, we had to relax
some time-consuming constraints for some clusters
of sentences (concerning mainly the biggest training
sets, namely Czech and English): in some cases, the
</bodyText>
<page confidence="0.998526">
94
</page>
<bodyText confidence="0.9988411">
threshold for a feature to be selected has been in-
creased, resulting in a probably quite lower perfor-
mance for these models. Ideally we would also have
done more tests with all languages to fine-tune pa-
rameters. Nevertheless, we have obtained quite sat-
isfying results for such a generic approach: the av-
erage F1-measure is 66.49%, ranging from 57.75%
(Japanese) to 72.14% (English). These results show
that the system is generic enough to work quite cor-
rectly with all seven languages7.
</bodyText>
<subsectionHeader confidence="0.984637">
4.2 Internal Evaluation
</subsectionHeader>
<bodyText confidence="0.999914294117647">
Here we report detailed results obtained in anno-
tating the development set. Since we process the
task in two distinct steps, we can evaluate both
separately: for the arguments step, the F1-measure
ranges from 56.0% (Czech) to 61.8% (German), ex-
cept for Japanese data where it is only 27%. For the
senses step, the F1-measure is generally better: it
ranges from 61.5% for the Czech case8 to 93.3% for
Chinese.
It is also interesting to observe the difference
between using “real” indicators (i.e. lemma, pos,
deprel and head columns) versus predicted ones
(i.e. P-columns): for example, with German data
(respectively Catalan data) the F1-measure reaches
73.6% (resp. 70.8%) in the former case, but only
61.8% (resp. 60.6%) in the latter case (for the argu-
ment labeling step only).
</bodyText>
<subsectionHeader confidence="0.999864">
4.3 Impact of Parameters
</subsectionHeader>
<bodyText confidence="0.968620133333334">
At first we intended to use the most precise CRF
model (namely FT3), but the fact that it generates
many more features (thus taking too much time) to-
gether with the fact that it does not improve perfor-
mance a lot made impossible to use it for the whole
data. More precisely, it was possible but only by set-
ting restrictive values for other parameters (neigh-
bourhood, thresholds), which would have decreased
performance. This is why we had to use FT2 as a
7Actually detailed evaluation shows that the system does not
deal very well with Japanese, since locating arguments is harder
in this language.
8Counting only “real senses”: it is worth noticing that Czech
data were a bit different from the other languages concerning
senses, since most predicates do not have senses (not counted
here and easy to identify) and the set of possible senses is dif-
ferent for each lemma.
compromise, thus making possible to use better val-
ues for the other parameters. We have also tested us-
ing 3 tests instead of only 2, but it does not improve
performance, or not enough to compensate for the
huge number of generated features, which requires
excessive time and/or memory for XCRF learning
step.
One of the most important parameters is the
neighbourhood, since it specifies the location (and
consequently the amount) of the information taken
into account in the features. We have tried differ-
ent cases for both the argument labeling step and the
sense disambiguation step: in the former case, ob-
serving children nodes is useless, whereas observing
the parent and grand-parent nodes together with two
siblings in both left and right handside improves the
model. On the contrary, in the senses step observing
more than close nodes is useless. These facts are not
surprising, since arguments are generally hierarchi-
cally lower than predicates in the dependency trees.
We have also studied the problem of finding an
optimal threshold for the minimum number of sen-
tences by cluster (all sentences in a given cluster
having the same lemma for predicate): if this thresh-
old is too low some clusters will not contain enough
examples to build a reliable model, and if it is too
high a lot of sentences will fall in the default clus-
ter (for which the model could be less precise). But
surprisingly the results did not show any significant
difference between using a threshold of 2, 3 or 5:
actually individual results differ, but the global per-
formance remains the same.
Finally a word has to be said about “efficiency pa-
rameters”: the most important one is the minimum
proportion for a generated feature to be included in
the final set of features for the model. Clearly, the
lower this threshold is, the better the performance
is. Nevertheless, in the framework of a limited time
task, it was necessary to set a value of 0.0005% in
most cases, and sometimes a higher value (up to
0.001%) for the big clusters: these values seem low
but prevent including a lot of features (and probably
sometimes useful ones).
</bodyText>
<sectionHeader confidence="0.953358" genericHeader="conclusions">
5 Problems, Discussion and Future Work
</sectionHeader>
<bodyText confidence="0.998815">
Since there was a time limit and the system was used
for the first time for such a task, we had to face
</bodyText>
<page confidence="0.996132">
95
</page>
<bodyText confidence="0.999979264705882">
several unexpected problems and solve them quite
rapidly. Therefore one may suppose that our system
could perform better, provided more tests are done to
fine-tune parameters, especially to optimize the bal-
ance between efficiency and performance. Indeed,
there is a balance to find between the amount of in-
formation (number of features and/or examples) and
the time taken by XCRF to process the training step.
Generally speaking, performance increases with the
amount of information, but practically XCRF can
not handle a huge number of features and/or exam-
ples in a reasonable time. This is why selecting the
“right” features as soon as possible is so important.
Among various possible ways to improve the sys-
tem, we should benefit from the fact that CRF do not
need a lot of examples as input to learn quite cor-
rectly. Informally, the XCRF library seems to have
some kind of “optimal point”: before this point the
model learned could be better, but beyond this point
time and/or memory are excessive. Thus one can
try for example to apply an iterative process using a
sufficiently low number of features at each step, to
select the more useful ones depending on the weight
XCRF assigns to them.
Since the Crotal system obtained reasonable re-
sults in this “non ideal” context, we are quite confi-
dent in the fact that it can be significantly improved.
The CoNLL 09 Shared Task has been a good op-
portunity to validate our approach with a non trivial
problem. Even if the performance is not excellent,
several important points are satisfying: this experi-
ence shows that the system is able to handle such a
task, and that it is generic enough to deal with very
different languages.
</bodyText>
<sectionHeader confidence="0.998613" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999884">
Aljoscha Burchardt, Katrin Erk, Anette Frank, Andrea
Kowalski, Sebastian Pad´o, and Manfred Pinkal. 2006.
The SALSA corpus: a German corpus resource for
lexical semantics. In Proceedings of the 5th Interna-
tional Conference on Language Resources and Evalu-
ation (LREC-2006), Genoa, Italy.
Jenny Rose Finkel, Alex Kleeman, and Christopher D.
Manning. 2008. Efficient, feature-based, condi-
tional random field parsing. In Proceedings of ACL-
08:HLT, pages 959–967, Columbus, Ohio. Associa-
tion for Computational Linguistics.
R´emi Gilleron, Florent Jousse, Isabelle Tellier, and Marc
Tommasi. 2006. Conditional random fields for xml
trees. In Proceeding of ECML workshop on Mining
and Learning in Graphs.
Jan Hajiˇc, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Kawahara, Maria Ant`onia Marti, Lluis
M`arquez, Adam Meyers, Joakim Nivre, Sebastian
Pad´o, Jan ˇStˇep´anek, Pavel Straˇn´ak, Mihai Surdeanu,
Nianwen Xue, and Yi Zhang. 2009. The CoNLL-
2009 shared task: Syntactic and semantic depen-
dencies in multiple languages. In Proceedings of
the 13th Conference on Computational Natural Lan-
guage Learning (CoNLL-2009), June 4-5, Boulder,
Colorado, USA.
Jan Hajiˇc, Jarmila Panevov´a, Eva Hajiˇcov´a, Petr
Sgall, Petr Pajas, Jan ˇStˇep´anek, Jiˇr´ı Havelka, Marie
Mikulov´a, and Zdenˇek ˇZabokrtsk´y. 2006. Prague
Dependency Treebank 2.0. Linguistic Data Con-
sortium, Philadelphia, Pennsylvania, USA. URL:
http://ldc.upenn.edu. Cat. No. LDC2006T01, ISBN 1-
58563-370-4.
Florent Jousse. 2007. Transformations d’Arbres XML
avec des Mod`eles Probabilistes pour l’Annotation.
Ph.D. thesis, Universit´e Charles de Gaulle - Lille 3,
October.
Daisuke Kawahara, Sadao Kurohashi, and Kˆoiti Hasida.
2002. Construction of a Japanese relevance-tagged
corpus. In Proceedings of the 3rd International
Conference on Language Resources and Evaluation
(LREC-2002), pages 2008–2013, Las Palmas, Canary
Islands.
John Lafferty, Andrew McCallum, and Fernando Pereira.
2001. Conditional random fields: Probabilistic mod-
els for segmenting and labeling sequence data. In
ICML’01: Proceedings of the 18th International Conf.
on Machine Learning, pages 282–289.
Martha Palmer and Nianwen Xue. 2009. Adding seman-
tic roles to the Chinese Treebank. Natural Language
Engineering, 15(1):143–172.
Mihai Surdeanu, Richard Johansson, Adam Meyers,
Lluis M`arquez, and Joakim Nivre. 2008. The CoNLL-
2008 shared task on joint parsing of syntactic and se-
mantic dependencies. In Proceedings of the 12th Con-
ference on Computational Natural Language Learning
(CoNLL-2008).
Charles Sutton and Andrew McCallum. 2006. An in-
troduction to conditional random fields for relational
learning. In Lise Getoor and Ben Taskar, editors,
Introduction to Statistical Relational Learning. MIT
Press.
Mariona Taul´e, Maria Ant`onia Marti, and Marta Re-
casens. 2008. AnCora: Multilevel Annotated Corpora
for Catalan and Spanish. In Proceedings of the 6th
International Conference on Language Resources and
Evaluation (LREC-2008), Marrakesh, Morroco.
</reference>
<page confidence="0.99846">
96
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.244133">
<title confidence="0.993836">Crotal SRL System : a Generic Tool Based on Tree-structured</title>
<author confidence="0.939717">Erwan Moreau Isabelle Tellier</author>
<affiliation confidence="0.662774">LIPN - CNRS UMR 7030 &amp; Univ. Paris 13 LIFO - Univ. Orl´eans</affiliation>
<address confidence="0.251187">Erwan.Moreau@lipn.univ-paris13.fr Isabelle.Tellier@univ-orleans.fr</address>
<abstract confidence="0.999001">We present the Crotal system, used in the CoNLL09 Shared Task. It is based on XCRF, a highly configurable CRF library which can take into account hierarchical relations. This system had never been used in such a context thus the performance is average, but we are confident that there is room for progression.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Aljoscha Burchardt</author>
<author>Katrin Erk</author>
<author>Anette Frank</author>
<author>Andrea Kowalski</author>
<author>Sebastian Pad´o</author>
<author>Manfred Pinkal</author>
</authors>
<title>The SALSA corpus: a German corpus resource for lexical semantics.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC-2006),</booktitle>
<location>Genoa, Italy.</location>
<marker>Burchardt, Erk, Frank, Kowalski, Pad´o, Pinkal, 2006</marker>
<rawString>Aljoscha Burchardt, Katrin Erk, Anette Frank, Andrea Kowalski, Sebastian Pad´o, and Manfred Pinkal. 2006. The SALSA corpus: a German corpus resource for lexical semantics. In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC-2006), Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Alex Kleeman</author>
<author>Christopher D Manning</author>
</authors>
<title>Efficient, feature-based, conditional random field parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL08:HLT,</booktitle>
<pages>959--967</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio.</location>
<contexts>
<context position="1381" citStr="Finkel et al., 2008" startWordPosition="219" endWordPosition="222">F) (Lafferty et al., 2001; Sutton and McCallum, 2006): our idea is that we can use the provided dependency structure as the skeleton of a graphical model expressing independence asumptions in a CRF model. CRF are a powerful machine learning technique that has been successfully applied to a large number of natural language tasks, mainly to tag sequences. Compared to classification techniques, CRF can easily take into account dependencies among annotations: it is therefore possible to represent tree-like structures in the input of the algorithm. Recently, CRF using tree structures were used in (Finkel et al., 2008) in the case of parsing. Before participating to this Shared Task, our prototype had only been used to annotate function tags in a French Treebank: these data were drastically ∗This work has been funded by the French National project ANR-07-MDCO-03 “CRoTAL”. 1We have participated in the SRL-only category. smaller, and the task was simpler. Therefore CoNLL 2009 ST is the first time the Crotal System is run for a quite complex task, with so many data as input, and seven different languages (Catalan, Spanish (Taul´e et al., 2008), Chinese (Palmer and Xue, 2009), Czech (Hajiˇc et al., 2006), Engli</context>
</contexts>
<marker>Finkel, Kleeman, Manning, 2008</marker>
<rawString>Jenny Rose Finkel, Alex Kleeman, and Christopher D. Manning. 2008. Efficient, feature-based, conditional random field parsing. In Proceedings of ACL08:HLT, pages 959–967, Columbus, Ohio. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R´emi Gilleron</author>
<author>Florent Jousse</author>
<author>Isabelle Tellier</author>
<author>Marc Tommasi</author>
</authors>
<title>Conditional random fields for xml trees.</title>
<date>2006</date>
<booktitle>In Proceeding of ECML workshop on Mining and Learning in Graphs.</booktitle>
<contexts>
<context position="3187" citStr="Gilleron et al., 2006" startWordPosition="528" endWordPosition="531">olume of data, since it was sometimes necessary to reduce the processing time). Of course, we hope to improve this prototype thanks to this experience: it may become necessary to lose in genericity in order to gain in performance, but our goal is to maintain as much as possible this advantage. In section 2 we explain the general architecture for Crotal, then we explain how features are selected in our system in section 3, and finally we detail and discuss the results in section 4. 2 The Crotal System Architecture 2.1 General principle The system we propose is based on the public library XCRF (Gilleron et al., 2006; Jousse, 2007), which 91 Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task, pages 91–96, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics implements CRF model(s) to learn to annotate trees represented by XML documents. Of course, its performance depends on the way it is used, and especially on how features are chosen to reliably represent the labeled data. In order to keep the system as generic as possible, features are generated automatically and only a few parameters may vary. The global process has been di</context>
<context position="6417" citStr="Gilleron et al., 2006" startWordPosition="1072" endWordPosition="1075">The CRF model for arguments is trained with XCRF. (c) Generation of features for the senses training step. (d) The CRF model for senses5 is trained with XCRF. In annotation mode, the CRF model for arguments is first applied to the input tree, then the CRF model for senses (if possible, an individual evaluation is also computed). 3. Back conversion from XCRF format to CoNLL format (in annotation mode). In the framework of this task, features generation is crucial for improving performance. That is why we will mainly focus on that point in the remaining of this paper. 2.2 The XCRF Library XCRF (Gilleron et al., 2006; Jousse, 2007) is a public library which has been applied successfully to HTML documents in order to extract information or translate the tree structure into XML (Jousse, 2007). More recently we have applied it to annotate function tags in a French Treebank. In a CRF model, a feature is a function (usually providing a boolean result) whose value depends on the annotations present in a special clique of the graph, and on the value of the observed data. In our system, each feature is defined by a pair (C, T), where: • C is the set of annotations present in a given clique, i.e. a completely conn</context>
</contexts>
<marker>Gilleron, Jousse, Tellier, Tommasi, 2006</marker>
<rawString>R´emi Gilleron, Florent Jousse, Isabelle Tellier, and Marc Tommasi. 2006. Conditional random fields for xml trees. In Proceeding of ECML workshop on Mining and Learning in Graphs.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jan Hajiˇc</author>
<author>Massimiliano Ciaramita</author>
<author>Richard Johansson</author>
<author>Daisuke Kawahara</author>
<author>Maria Ant`onia Marti</author>
<author>Lluis M`arquez</author>
<author>Adam Meyers</author>
<author>Joakim Nivre</author>
<author>Sebastian Pad´o</author>
<author>Jan ˇStˇep´anek</author>
<author>Pavel Straˇn´ak</author>
<author>Mihai Surdeanu</author>
<author>Nianwen Xue</author>
<author>Yi Zhang</author>
</authors>
<title>The CoNLL2009 shared task: Syntactic and semantic dependencies in multiple languages.</title>
<date>2009</date>
<booktitle>In Proceedings of the 13th Conference on Computational Natural Language Learning (CoNLL-2009),</booktitle>
<location>Boulder, Colorado, USA.</location>
<marker>Hajiˇc, Ciaramita, Johansson, Kawahara, Marti, M`arquez, Meyers, Nivre, Pad´o, ˇStˇep´anek, Straˇn´ak, Surdeanu, Xue, Zhang, 2009</marker>
<rawString>Jan Hajiˇc, Massimiliano Ciaramita, Richard Johansson, Daisuke Kawahara, Maria Ant`onia Marti, Lluis M`arquez, Adam Meyers, Joakim Nivre, Sebastian Pad´o, Jan ˇStˇep´anek, Pavel Straˇn´ak, Mihai Surdeanu, Nianwen Xue, and Yi Zhang. 2009. The CoNLL2009 shared task: Syntactic and semantic dependencies in multiple languages. In Proceedings of the 13th Conference on Computational Natural Language Learning (CoNLL-2009), June 4-5, Boulder, Colorado, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Jarmila Panevov´a</author>
<author>Eva Hajiˇcov´a</author>
<author>Petr Sgall</author>
<author>Petr Pajas</author>
<author>Jan ˇStˇep´anek</author>
<author>Jiˇr´ı Havelka</author>
<author>Marie Mikulov´a</author>
<author>Zdenˇek ˇZabokrtsk´y</author>
</authors>
<title>Prague Dependency Treebank 2.0. Linguistic Data Consortium,</title>
<date>2006</date>
<booktitle>http://ldc.upenn.edu. Cat. No. LDC2006T01, ISBN</booktitle>
<pages>1--58563</pages>
<location>Philadelphia, Pennsylvania, USA. URL:</location>
<marker>Hajiˇc, Panevov´a, Hajiˇcov´a, Sgall, Pajas, ˇStˇep´anek, Havelka, Mikulov´a, ˇZabokrtsk´y, 2006</marker>
<rawString>Jan Hajiˇc, Jarmila Panevov´a, Eva Hajiˇcov´a, Petr Sgall, Petr Pajas, Jan ˇStˇep´anek, Jiˇr´ı Havelka, Marie Mikulov´a, and Zdenˇek ˇZabokrtsk´y. 2006. Prague Dependency Treebank 2.0. Linguistic Data Consortium, Philadelphia, Pennsylvania, USA. URL: http://ldc.upenn.edu. Cat. No. LDC2006T01, ISBN 1-58563-370-4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Florent Jousse</author>
</authors>
<title>Transformations d’Arbres XML avec des Mod`eles Probabilistes pour l’Annotation.</title>
<date>2007</date>
<booktitle>Ph.D. thesis, Universit´e Charles de Gaulle - Lille 3,</booktitle>
<contexts>
<context position="3202" citStr="Jousse, 2007" startWordPosition="532" endWordPosition="533"> was sometimes necessary to reduce the processing time). Of course, we hope to improve this prototype thanks to this experience: it may become necessary to lose in genericity in order to gain in performance, but our goal is to maintain as much as possible this advantage. In section 2 we explain the general architecture for Crotal, then we explain how features are selected in our system in section 3, and finally we detail and discuss the results in section 4. 2 The Crotal System Architecture 2.1 General principle The system we propose is based on the public library XCRF (Gilleron et al., 2006; Jousse, 2007), which 91 Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task, pages 91–96, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics implements CRF model(s) to learn to annotate trees represented by XML documents. Of course, its performance depends on the way it is used, and especially on how features are chosen to reliably represent the labeled data. In order to keep the system as generic as possible, features are generated automatically and only a few parameters may vary. The global process has been divided into a se</context>
<context position="6432" citStr="Jousse, 2007" startWordPosition="1076" endWordPosition="1077">ents is trained with XCRF. (c) Generation of features for the senses training step. (d) The CRF model for senses5 is trained with XCRF. In annotation mode, the CRF model for arguments is first applied to the input tree, then the CRF model for senses (if possible, an individual evaluation is also computed). 3. Back conversion from XCRF format to CoNLL format (in annotation mode). In the framework of this task, features generation is crucial for improving performance. That is why we will mainly focus on that point in the remaining of this paper. 2.2 The XCRF Library XCRF (Gilleron et al., 2006; Jousse, 2007) is a public library which has been applied successfully to HTML documents in order to extract information or translate the tree structure into XML (Jousse, 2007). More recently we have applied it to annotate function tags in a French Treebank. In a CRF model, a feature is a function (usually providing a boolean result) whose value depends on the annotations present in a special clique of the graph, and on the value of the observed data. In our system, each feature is defined by a pair (C, T), where: • C is the set of annotations present in a given clique, i.e. a completely connected subgraph </context>
</contexts>
<marker>Jousse, 2007</marker>
<rawString>Florent Jousse. 2007. Transformations d’Arbres XML avec des Mod`eles Probabilistes pour l’Annotation. Ph.D. thesis, Universit´e Charles de Gaulle - Lille 3, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daisuke Kawahara</author>
<author>Sadao Kurohashi</author>
<author>Kˆoiti Hasida</author>
</authors>
<title>Construction of a Japanese relevance-tagged corpus.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC-2002),</booktitle>
<pages>2008--2013</pages>
<location>Las Palmas, Canary Islands.</location>
<contexts>
<context position="2077" citStr="Kawahara et al., 2002" startWordPosition="336" endWordPosition="339">totype had only been used to annotate function tags in a French Treebank: these data were drastically ∗This work has been funded by the French National project ANR-07-MDCO-03 “CRoTAL”. 1We have participated in the SRL-only category. smaller, and the task was simpler. Therefore CoNLL 2009 ST is the first time the Crotal System is run for a quite complex task, with so many data as input, and seven different languages (Catalan, Spanish (Taul´e et al., 2008), Chinese (Palmer and Xue, 2009), Czech (Hajiˇc et al., 2006), English (Surdeanu et al., 2008), German (Burchardt et al., 2006) and Japanese (Kawahara et al., 2002)). In this context, the performance we obtained seems reasonable: our average F1-measure is 66.49% (evaluation dataset). One of the advantages we want to emphasise about our system is its genericity: the system does not need a lot of information as input (we mainly use pos and deprel columns, and the frame sets have not been used), and it was able to achieve satisfying results for the seven different languages using nearly the same parameters (differences were essentially due to the volume of data, since it was sometimes necessary to reduce the processing time). Of course, we hope to improve t</context>
</contexts>
<marker>Kawahara, Kurohashi, Hasida, 2002</marker>
<rawString>Daisuke Kawahara, Sadao Kurohashi, and Kˆoiti Hasida. 2002. Construction of a Japanese relevance-tagged corpus. In Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC-2002), pages 2008–2013, Las Palmas, Canary Islands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In</title>
<date>2001</date>
<booktitle>ICML’01: Proceedings of the 18th International Conf. on Machine Learning,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="786" citStr="Lafferty et al., 2001" startWordPosition="122" endWordPosition="125">Moreau@lipn.univ-paris13.fr Isabelle.Tellier@univ-orleans.fr Abstract We present the Crotal system, used in the CoNLL09 Shared Task. It is based on XCRF, a highly configurable CRF library which can take into account hierarchical relations. This system had never been used in such a context thus the performance is average, but we are confident that there is room for progression. 1 Introduction In this paper we present the Crotal Semantic Role Labelling (SRL) system, which has been used in the CoNLL 2009 Shared Task (Hajiˇc et al., 2009)1. This system is based on Conditional Random Fields (CRF) (Lafferty et al., 2001; Sutton and McCallum, 2006): our idea is that we can use the provided dependency structure as the skeleton of a graphical model expressing independence asumptions in a CRF model. CRF are a powerful machine learning technique that has been successfully applied to a large number of natural language tasks, mainly to tag sequences. Compared to classification techniques, CRF can easily take into account dependencies among annotations: it is therefore possible to represent tree-like structures in the input of the algorithm. Recently, CRF using tree structures were used in (Finkel et al., 2008) in t</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In ICML’01: Proceedings of the 18th International Conf. on Machine Learning, pages 282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Nianwen Xue</author>
</authors>
<title>Adding semantic roles to the Chinese Treebank.</title>
<date>2009</date>
<journal>Natural Language Engineering,</journal>
<volume>15</volume>
<issue>1</issue>
<contexts>
<context position="1945" citStr="Palmer and Xue, 2009" startWordPosition="315" endWordPosition="318"> using tree structures were used in (Finkel et al., 2008) in the case of parsing. Before participating to this Shared Task, our prototype had only been used to annotate function tags in a French Treebank: these data were drastically ∗This work has been funded by the French National project ANR-07-MDCO-03 “CRoTAL”. 1We have participated in the SRL-only category. smaller, and the task was simpler. Therefore CoNLL 2009 ST is the first time the Crotal System is run for a quite complex task, with so many data as input, and seven different languages (Catalan, Spanish (Taul´e et al., 2008), Chinese (Palmer and Xue, 2009), Czech (Hajiˇc et al., 2006), English (Surdeanu et al., 2008), German (Burchardt et al., 2006) and Japanese (Kawahara et al., 2002)). In this context, the performance we obtained seems reasonable: our average F1-measure is 66.49% (evaluation dataset). One of the advantages we want to emphasise about our system is its genericity: the system does not need a lot of information as input (we mainly use pos and deprel columns, and the frame sets have not been used), and it was able to achieve satisfying results for the seven different languages using nearly the same parameters (differences were ess</context>
</contexts>
<marker>Palmer, Xue, 2009</marker>
<rawString>Martha Palmer and Nianwen Xue. 2009. Adding semantic roles to the Chinese Treebank. Natural Language Engineering, 15(1):143–172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Richard Johansson</author>
<author>Adam Meyers</author>
<author>Lluis M`arquez</author>
<author>Joakim Nivre</author>
</authors>
<title>The CoNLL2008 shared task on joint parsing of syntactic and semantic dependencies.</title>
<date>2008</date>
<booktitle>In Proceedings of the 12th Conference on Computational Natural Language Learning (CoNLL-2008).</booktitle>
<marker>Surdeanu, Johansson, Meyers, M`arquez, Nivre, 2008</marker>
<rawString>Mihai Surdeanu, Richard Johansson, Adam Meyers, Lluis M`arquez, and Joakim Nivre. 2008. The CoNLL2008 shared task on joint parsing of syntactic and semantic dependencies. In Proceedings of the 12th Conference on Computational Natural Language Learning (CoNLL-2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Sutton</author>
<author>Andrew McCallum</author>
</authors>
<title>An introduction to conditional random fields for relational learning.</title>
<date>2006</date>
<booktitle>In Lise Getoor and Ben Taskar, editors, Introduction to Statistical Relational Learning.</booktitle>
<publisher>MIT Press.</publisher>
<contexts>
<context position="814" citStr="Sutton and McCallum, 2006" startWordPosition="126" endWordPosition="129">3.fr Isabelle.Tellier@univ-orleans.fr Abstract We present the Crotal system, used in the CoNLL09 Shared Task. It is based on XCRF, a highly configurable CRF library which can take into account hierarchical relations. This system had never been used in such a context thus the performance is average, but we are confident that there is room for progression. 1 Introduction In this paper we present the Crotal Semantic Role Labelling (SRL) system, which has been used in the CoNLL 2009 Shared Task (Hajiˇc et al., 2009)1. This system is based on Conditional Random Fields (CRF) (Lafferty et al., 2001; Sutton and McCallum, 2006): our idea is that we can use the provided dependency structure as the skeleton of a graphical model expressing independence asumptions in a CRF model. CRF are a powerful machine learning technique that has been successfully applied to a large number of natural language tasks, mainly to tag sequences. Compared to classification techniques, CRF can easily take into account dependencies among annotations: it is therefore possible to represent tree-like structures in the input of the algorithm. Recently, CRF using tree structures were used in (Finkel et al., 2008) in the case of parsing. Before p</context>
</contexts>
<marker>Sutton, McCallum, 2006</marker>
<rawString>Charles Sutton and Andrew McCallum. 2006. An introduction to conditional random fields for relational learning. In Lise Getoor and Ben Taskar, editors, Introduction to Statistical Relational Learning. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mariona Taul´e</author>
<author>Maria Ant`onia Marti</author>
<author>Marta Recasens</author>
</authors>
<title>AnCora: Multilevel Annotated Corpora for Catalan and Spanish.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC-2008),</booktitle>
<location>Marrakesh, Morroco.</location>
<marker>Taul´e, Marti, Recasens, 2008</marker>
<rawString>Mariona Taul´e, Maria Ant`onia Marti, and Marta Recasens. 2008. AnCora: Multilevel Annotated Corpora for Catalan and Spanish. In Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC-2008), Marrakesh, Morroco.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>