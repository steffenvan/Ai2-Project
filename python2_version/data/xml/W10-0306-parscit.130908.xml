<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.982124">
Representing Story Plans in SUMO
</title>
<author confidence="0.995826">
Jeffrey Cua Ethel Ong
</author>
<affiliation confidence="0.882631">
Center for Human Language Technologies College of Computer Studies
De La Salle University, Manila, Philippines De La Salle University, Manila, Philippines
</affiliation>
<email confidence="0.950465">
cuajeffreyleonardcompro1@yahoo.com ethel.ong@delasalle.ph
</email>
<author confidence="0.98657">
Ruli Manurung
</author>
<affiliation confidence="0.999771">
Faculty of Computer Science
University of Indonesia, Jakarta, Indonesia
</affiliation>
<email confidence="0.978705">
maruli@cs.ui.ac.id
</email>
<author confidence="0.945289">
Adam Pease
</author>
<affiliation confidence="0.875335">
Articulate Software
</affiliation>
<address confidence="0.800804">
Angwin, California, USA
</address>
<email confidence="0.982008">
apease@articulatesoftware.com
</email>
<sectionHeader confidence="0.998532" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998715333333333">
Automatic story generation systems require a
body of commonsense knowledge about the
basic relationships between concepts we find
everyday in our world in order to produce in-
teresting narratives that describe human ac-
tions and world events. This paper presents an
ongoing work that investigates the use of
Suggested Upper Merged Ontology (SUMO)
to represent storytelling knowledge and its in-
ference engine Sigma to query actions and
events that may take place in the story to be
generated. The resulting story plan (fabula) is
also represented in SUMO, allowing for a sin-
gle story representation to be realized in vari-
ous human languages.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9991452">
People combine words and events from their
knowledge source of words, their meanings and
their relationships in order to tell stories about their
lives, their communities, and their daily expe-
riences. In order for computers to achieve the same
level of expressiveness to provide a more fluent
man-machine interaction, they must be provided
with the same collection of knowledge about the
basic relationships between things and events.
Picture Books (Solis et al, 2009), an automatic
story generator that generates story text for child-
ren from a given input set of picture elements
(backgrounds, characters and objects), utilized a
semantic ontology whose design has been adapted
from ConceptNet (Liu and Singh, 2004). The
background serves as the setting of the story and is
also used to determine the theme. Semantic con-
cepts needed by the story planner, specifically ob-
jects, story events, and character actions are
classified according to the semantic categories of
ConceptNet, namely things, spatial, events, ac-
tions, and functions. This mapping approach con-
strained the flexibility of the system, as new
themes would entail repopulating the sequences of
possible events manually into the knowledge base.
Events and actions are selected according to their
associated themes, and not marked with precondi-
tions that specify constraints under which certain
actions can be performed and the corresponding
consequential events that may arise.
Swartjes (2006) developed a story world ontolo-
gy containing two layers, the upper story world
ontology and the domain-specific world ontology.
The upper story world ontology is independent of
any story structures or story domains and models a
vast amount of possible actions and events. It is
also limited to high-level concepts that are meta,
generic or abstract to address a broad range of do-
main areas. A domain-specific story world ontolo-
gy, on the other hand, applies the upper story
world ontology to a certain story domain.
Kooijman (2004) suggests the use of the Sug-
gested Upper Merged Ontology (SUMO) as an
upper ontology to capture the semantics of world
knowledge. SUMO (Niles and Pease, 2001) is an
</bodyText>
<page confidence="0.984073">
40
</page>
<note confidence="0.966612">
Proceedings of the NAACL HLT 2010 Second Workshop on Computational Approaches to Linguistic Creativity, pages 40–48,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999810836734694">
open source formal and public ontology. It is a col-
lection of well-defined and well-documented con-
cepts, interconnected into a logical theory. It
numbers some 20,000 terms and 70,000 axioms.
Axioms are in first-order logic form (with some
higher order extensions) and reflect commonsense
notions that are generally recognized among the
concepts. They place a constraint on the interpreta-
tion of concepts and provide guidelines for auto-
mated reasoning systems such as Sigma (Pease,
2003). Formal terms in SUMO are mapped to syn-
sets in WordNet (Pease, 2006).
There are other noteworthy ontologies that can
be considered. Like SUMO, Cyc (Lenat, 1995) is a
large-scale, language-independent and extensible
knowledge base and commonsense reasoning en-
gine, but it is proprietary and its open-source ver-
sion, OpenCyc1, has no inference rules. DOLCE
(Gangemi, 2003) is a small-scale descriptive on-
tology with a cognitive orientation. BFO (Smith,
1998) is another small-scale upper ontology sup-
porting domain ontologies developed for scientific
research domain, such as biomedicine. Thus, no
ontology other than SUMO had the characteristics
of being comprehensive enough to include forma-
lizations that represent detailed elements of every-
day life (e.g., furniture, breaking an object,
emotion), being open-source, having expressive-
ness of at least first order predicate calculus so that
arbitrary rules about actions and consequences can
be represented, having an associated open-source
first-order inference engine, and a language gener-
ation capability so that stories can be automatically
presented in multiple human languages
This paper presents SUMOs (SUMO Stories),
an automatic story generator that uses first-order
logic to declaratively describe models of the world,
specifically those aspects of the world that
represent storytelling knowledge for children’s
stories of the fable form. The story planner then
utilizes an open source browsing and inference
engine Sigma to infer this knowledge to generate a
story plan (fabula) also in first-order logic form.
Using first-order logic enables a less restricted
semantics compared to description logic, which is
commonly used for knowledge representation of
large ontologies. Though having lesser constraints
will have an impact on the speed of inference, it is
overcome by the advantage of having greater re-
</bodyText>
<sectionHeader confidence="0.498128" genericHeader="method">
1 OpenCyc web site, http://www.opencyc.org/
</sectionHeader>
<bodyText confidence="0.999844625">
presentational capability. In particular, the axi-
omatic nature of actions and their consequences, so
essential for reasoning about narrative structures, is
not supported by description logics, which focus
on category and instance membership reasoning.
Section 2 provides a background on the know-
ledge required by story generation and how these
were represented in Picture Books, which is used
as the basis for the storytelling knowledge. Section
3 discusses the representation of the storytelling
knowledge to SUMO. The SUMOs architecture
depicting the interaction between the story planner
and Sigma to derive the story plan is then pre-
sented in Section 4. The paper concludes with a
summary of what we have accomplished so far,
and presents further work that can be done.
</bodyText>
<sectionHeader confidence="0.926736" genericHeader="method">
2 Storytelling Knowledge
</sectionHeader>
<bodyText confidence="0.999887066666667">
Theune and her colleagues (2006) presented five
levels of the different aspects of a story that must
be represented in the semantic network. These are
the story world knowledge, character representa-
tions, a causal and temporal network to represent
plot structures, representational model of narrato-
logical concepts, and the representation of the sto-
ry’s potential effects on the user. Only the first four
levels are included in this study.
According to Swartjes (2006), a story is com-
posed of a story world where the story takes place,
the characters that interact in the story world, and
the associated objects. Consider the story generat-
ed by Picture Books in Table 1 about Rizzy the
rabbit who learns to be honest (Hong et al, 2008).
</bodyText>
<construct confidence="0.9901634">
The afternoon was windy. Rizzy the rabbit was in the
dining room. She played near a lamp. Rizzy broke the
lamp. She was scared. Mommy Francine saw that the
lamp was broken. Rizzy told Mommy Francine that Da-
niel broke the lamp. Daniel the dog told her that he did
not break the lamp. Daniel was upset. He got punished.
Mommy Francine told Daniel that he was grounded. He
cried. Rizzy felt guilty. She told Mommy Francine that
she broke the lamp. Mommy Francine told Rizzy that
she should have been honest. Rizzy apologized to
Mommy Francine. Mommy Francine forgave Rizzy.
Rizzy apologized to Daniel. He forgave her. Mommy
Francine told Rizzy to be honest. She told her that being
honest is good. From that day onwards, Rizzy always
was honest.
</construct>
<tableCaption confidence="0.8975055">
Table 1. Sample story generated by Picture Books
(Hong et al, 2008)
</tableCaption>
<page confidence="0.999586">
41
</page>
<bodyText confidence="0.999955944444445">
The story elements in Table 1 were determined
from the background (i.e., dining room), the cha-
racters (i.e., Rizzy and her mommy Francine) and
object (i.e., lamp) that the child user places into
his/her picture using the Picture Editor of the sys-
tem in Figure 1.
The background serves as the main setting of the
story, and combined with the selected objects, is
used to determine the theme. Consider the bed-
room setting. If the associated object is a lamp,
then the theme is about bravery (i.e., do not be
afraid of the dark). If the object is a set of toy
blocks, the theme can be about being neat. In Pic-
ture Books, such associations are manually deter-
mined and entered into the database. In SUMOs,
these associations should be inferred automatically
through axioms that should be commonsense, and
not be explicit encoding of narrative knowledge.
</bodyText>
<figureCaption confidence="0.994983">
Figure 2. Picture Editor (Hong et al, 2008)
</figureCaption>
<bodyText confidence="0.999596">
Stories generated by Picture Books follow a ba-
sic plot dictated by Machado (2003) that flows
from negative to positive and comprises four sub-
plots, namely the problem, rising action, solution
and climax. The theme is subdivided into these
four subplots, each representing a major event in
the story.
Each subplot contains at least two author goals
representing the goal of the scene and the corres-
ponding consequence of the goal. An author goal is
translated into one or more character goals, each
representing an action performed by the character
(main, secondary, or adult character) in order to
achieve the author goal. A character goal translates
directly to one declarative sentence in the generat-
ed story. Table 2 shows the author goals and the
character goals for some of the sentences in the
story in Table 1.
The design of the character goal is based from
the action operators of Uijlings (2006) which is
easily transformed to a declarative sentence in ac-
tive voice using the surface realizer simpleNLG
(Venour and Reiter, 2008). In the case of Picture
Books, however, the approach resulted in a story
where every sentence describes an action or a feel-
ing (i.e., scared, guilty, upset) that is performed by
the character, as seen in Table 1.
</bodyText>
<table confidence="0.999044571428571">
Subplot #1
Author goal 1.1:
Goal of the scene Child is doing an activity
Character goal &lt;character&gt; plays &lt;object&gt;
Resulting text Rizzy the rabbit played near a
lamp.
Author goal 1.2:
Goal consequence Child caused a problem
Character goal &lt;character&gt; destroys &lt;object&gt;
Resulting text Rizzy broke the lamp.
Subplot #2
Author goal 2.1:
Goal of the scene Child lied
Character goal &lt;main character&gt; told &lt;adult
character&gt; that &lt;secondary
character&gt; &lt;did the action&gt;
Resulting text Rizzy told Mommy Francine that
Daniel the dog broke the lamp.
Author goal 2.2:
Goal consequence Another child gets punished
Character goal #1 &lt;secondary character&gt; receives
&lt;punishment&gt;
Resulting text #1 Daniel the dog got punished.
Character goal #2 &lt;adult character&gt; issues &lt;pu-
nishment&gt; to &lt;secondary cha-
racter&gt;
Resulting text #2 Mommy Francine told Daniel
that he was grounded.
</table>
<tableCaption confidence="0.9577415">
Table 2. Sample author goals and character goals asso-
ciated with the theme Being Honest (Hong et al, 2008)
</tableCaption>
<bodyText confidence="0.999962">
The story planner of Picture Books utilizes two
types of knowledge, the operational knowledge
and the domain knowledge. The operational know-
ledge contains a static description of the different
backgrounds and their associated themes and ob-
jects, the child characters and their corresponding
parent characters, as well as the occupation of the
</bodyText>
<page confidence="0.994959">
42
</page>
<bodyText confidence="0.968768038461539">
parents. For each theme, the set of character goals
needed to instantiate the major events in the theme
are also specified.
The domain knowledge, on the other hand, con-
tains a semantic description of objects and events
that can occur, as well as actions that can be per-
formed. For example, breaking an object results to
getting punished, and grounded is a form of pu-
nishment.
Character goals are instantiated by accessing the
semantic ontology to search for concepts that are
directly related to the input concept. There are two
search methods. The first method searches for
another concept that has a relationship with the
given concept while satisfying the semantic cate-
gory. For example, ontoSpatial(“play”) triggers a
search for all concepts connected to play within the
spatial semantic category, such as the semantic
relationship locationOf(“play”, “park”). The second
method searches for a path that semantically re-
lates the two given concepts. For example, ontoAc-
tion(“vase”, “method of destruction”) triggers a
search for a path to relate how a vase can be de-
stroyed, and yields the following relationships:
CapableOf(“break”, “vase”)
Isa(“method of destruction”, “break”)
</bodyText>
<sectionHeader confidence="0.996694" genericHeader="method">
3 Representing Storytelling Knowledge in
SUMO
</sectionHeader>
<bodyText confidence="0.999973606060606">
A crucial part of the work involved in the devel-
opment of SUMOs is the representation of the sto-
rytelling knowledge and the evolving story plan in
SUMO and the use of the Sigma reasoning engine
to infer story facts and events.
The storytelling knowledge represented in
SUMO includes the semantic description about
concepts, objects and their relationships. From a
given input set of story elements comprising the
selected background, characters, and objects, a
query is sent to Sigma to determine a possible
starting action that can be performed by the main
character in the story. The story then progresses
based on the relationships of character actions and
reactions, which are the stored facts in SUMO.
Similar to Picture Books, the resulting story plan
is created based on a pre-authored plot of problem,
rising action, resolution and climax. But instead of
attaching the next set of actions and emotions of
characters to author goals, in SUMOs, the set of
actions that a character can do – reaction to events
and objects, experience emotions such as joy and
sadness, and subsequent actions based on their
emotions – are represented in SUMO logic.
The storytelling knowledge was formulated us-
ing a set of predicates that can be classified into
four main types. Factual predicates specify proper-
ties of characters, objects, and locations. Semantic
predicates define the semantic relationships be-
tween concepts. Actions and events predicates de-
fine the causal relationships between actions and
events. Thematic predicates represent a new set of
predicates to relate story themes to actions.
</bodyText>
<subsectionHeader confidence="0.805289">
3.1 Conceptualizing Story Characters, Ob-
jects, and Backgrounds
</subsectionHeader>
<bodyText confidence="0.9998932">
Factual predicates represent the characters, their
roles, the locations, and the objects that may com-
prise a story. The class and subclass axioms of
SUMO2 are used to define the set of characters,
objects and locations.
Children’s stories of the fable form are por-
trayed by animals that can capture the imagina-
tion and attention of the readers. Animal characters
are given names, such as Ellen the elephant, Rizzy
the rabbit, and Leo the lion, to give the impression
that the characters are friends that the children are
getting to know better through reading the story
(Solis et al, 2009). Representing this in SUMO
entails the use of the subclass axiom to represent
class inheritance as shown below:
</bodyText>
<subsectionHeader confidence="0.492203">
(subclass RabbitCharacter StoryCharacter)
</subsectionHeader>
<bodyText confidence="0.9844095">
Class definitions include slots that describe the
attributes of instances of the class and their rela-
tions to other instances (Noy, 2001). A character in
SUMOs has the attributes type (whether adult or
child), gender, and name. An example axiom to
represent a female child RabbitCharacter whose
name will be “Rizzy” is shown below. Similar
axioms are defined for all the other characters.
</bodyText>
<table confidence="0.725280111111111">
(=&gt;
(and
(instance ?RABBIT RabbitCharacter)
(attribute ?RABBIT Female)
(attribute ?RABBIT Child))
(name ?RABBIT &amp;quot;Rizzy&amp;quot;))
Backgrounds and objects are also defined using
the subclass axiom and inherit from existing
classes in SUMO, for example,
</table>
<footnote confidence="0.586463">
2 SUMO Ontology Portal, http://www.ontologyportal.org/
</footnote>
<page confidence="0.98448">
43
</page>
<table confidence="0.9096535">
(subclass LivingRoom Room)
(subclass Lamp LightFixture)
(subclass Lamp ElectricDevice)
(attribute Lamp Fragile)
</table>
<bodyText confidence="0.981573111111111">
Further definitions can be provided for living
room to differentiate it from other rooms, such as
being disjoint from bathroom, and has a primary
purpose of supporting social interaction, as shown
below. Similarly, the definition for lamp can also
be extended to distinguish it from other electric
light fixtures, e.g., a lamp is moveable unlike a
chandelier, but is plugged in when operating unlike
a flashlight.
</bodyText>
<figure confidence="0.934012125">
(=&gt;
(instance ?R LivingRoom)
(hasPurpose ?R
(exists (?S)
(and
(instance ?S SocialInteraction)
(located ?S ?R)))))
(disjoint LivingRoom Bathroom)
</figure>
<subsectionHeader confidence="0.999566">
3.2 Representing Semantic Concepts
</subsectionHeader>
<bodyText confidence="0.9989587">
Aside from the properties of objects that are mod-
eled using the attribute axiom, semantic relation-
ships that may hold between two concepts
involving types of activities or actions, character
emotions, locations of objects, and abilities of cha-
racters or objects must also be modeled. Table 3
shows sample semantic relationships for these con-
cepts as represented in Picture Books, following
the semantic categories of ConceptNet (Liu and
Singh, 2004).
</bodyText>
<table confidence="0.999257266666667">
Objects IsA (doll, toys)
Activities IsA (play games, activity)
Concepts IsA (grounded, punishment)
IsA (disorder, problem)
IsA (no appetite, problem)
IsA (dizzy, discomfort)
IsA (itchy, discomfort)
Emotions IsA (happy, emotion)
IsA (scared, emotion)
Reaction to EffectOf (break object, scared)
Events EffectOf (meet new friends, smile)
Location LocationOf (toys, toy store)
Capability CapableOf (lamp, break)
CapableOf (glass of water, break)
CanBe (toys, scattered)
</table>
<tableCaption confidence="0.9945175">
Table 3. Semantic relationships in Picture Books based
on ConceptNet (Hong et al, 2008)
</tableCaption>
<bodyText confidence="0.998923833333333">
In SUMOs, all isA(entity1, entity2) relations
were replaced with the axiom (subclass entity1
entity2). To specify that an entity is in a location,
i.e., locationOf(toys, toy store), first, we create an
instance of a toystore and then specify that a cer-
tain toy instance is in that toystore, as follows:
</bodyText>
<table confidence="0.624829666666667">
(=&gt;
(instance ?TOYSTORE ToyStore)
(exists (?TOY)
(and
(instance ?TOY Toy)
(located ?TOY ?TOYSTORE))))
</table>
<bodyText confidence="0.997541833333333">
The capability axiom is used to conceptualize
the capability relation (capability ?process ?role
?obj). It specifies that ?obj has the specified ?role
in the ?process. For example, a lamp or a glass is
the patient (receiver) of the process breaking,
while a toy is the patient for the process scattering.
</bodyText>
<construct confidence="0.342734333333333">
(capability Breaking experiencer Lamp)
(capability Breaking experiencer Glass)
(capability Scattering experiencer Toy)
</construct>
<bodyText confidence="0.9949422">
Reaction to events is expressed using the if-else
axiom of SUMO, for example, if a child character
causes an accident (a damage), then he/she will
feel anxiety. Emotions are represented using the
attribute relation.
</bodyText>
<figure confidence="0.604326285714286">
(=&gt;
(and
(instance ?ACCIDENT Damaging)
(instance ?CHARACTER StoryCharacter)
(attribute ?CHARACTER Child)
(agent ?ACCIDENT ?CHARACTER))
((attribute ?CHARACTER Anxiety)))
</figure>
<subsectionHeader confidence="0.999959">
3.3 Conceptualizing Actions and Events
</subsectionHeader>
<bodyText confidence="0.999519266666667">
Swartjes (2006) noted that organizing actions and
events, and causally relating them, is an essential
step in story generation. Independent of the story
plot, the causes and effects of character actions can
be used to describe the events that form the story.
Actions define activities that can be performed
by a character in the story, such as play, tell a lie,
or cry. Events, on the other hand, occur in the story
as a result of performing some actions, such as a
lamp breaking as a result of a character or an ob-
ject hitting it. Swartjes (2006) further notes that
events are not executed by a character.
Action predicates are used to define the actions
that may take place given a set of world state. Con-
sider the axiom below which provides a set of four
</bodyText>
<page confidence="0.998132">
44
</page>
<bodyText confidence="0.996582166666667">
possible actions – RecreationOrExercise, Looking,
Maintaining, and Poking – that can be performed
(as an agent) or experienced by a child character
who is situated near a lamp object in the story
world. These four actions are subclasses of the In-
tentionalProcess of SUMO.
</bodyText>
<figure confidence="0.826009583333333">
(=&gt;
(and
(orientation ?CHARACTER ?OBJECT Near)
(instance ?CHARACTER StoryCharacter)
(attribute ?CHARACTER Child)
(instance ?OBJECT Lamp))
(and
(capability RecreationOrExercise
experiencer ?CHARACTER)
(capability Looking experiencer ?CHARACTER)
(capability Maintaining experiencer ?CHARACTER)
(capability Poking experiencer ?CHARACTER)))
</figure>
<bodyText confidence="0.999689705882353">
Again, the capability relation is used but in this
instance, to specify that the character has the role
of experiencing the specified process. While both
the agent and the experiencer roles represent the
doer of a process, an experiencer does not entail a
causal relation between its arguments.
Event predicates are used to model explicit
events that may take place as a result of some cha-
racter actions. Consider again the exists axiom be-
low which states that an instance of an event (in
this case damaging) can occur when there is a
child character (the agent) playing near a fragile
object. The subprocess axiom is used to represent a
temporally distinguished part of a process and also
expresses a chain of cause and effect subprocesses
for playing and damaging. The recipient (patient)
of the event is the object.
</bodyText>
<figure confidence="0.922017466666667">
(=&gt;
(and
(agent ?X ?CHARACTER)
(instance ?CHARACTER StoryCharacter)
(attribute ?CHARACTER Child)
(instance ?OBJECT Object)
(attribute ?OBJECT Fragile)
(instance ?X RecreationOrExercise)
(orientation ?CHARACTER ?OBJECT Near)
(exists (?DAMAGE)
(and
(instance ?DAMAGE Damaging)
(subProcess ?DAMAGE ?X)
(agent ?DAMAGE ?CHARACTER)
(patient ?DAMAGE ?OBJECT))))
</figure>
<bodyText confidence="0.999732181818182">
Although suitable for inference, the given axiom
does not fully capture the desired truth as the no-
tion of time is not represented. The axiom says “if
a child plays at any point in time, and is near an
object at any point in time (not necessarily while
playing), then the object gets damaged during
playing”. The more accurate axiom below uses
holdsDuring to show that the time frames of the
actual playing and being near the object are the
same, thus increasing the likelihood of the charac-
ter who is playing to cause the damage.
</bodyText>
<figure confidence="0.992005375">
(=&gt;
(and
(instance ?X RecreationOrExercise)
(agent ?X ?CHARACTER)
(instance ?CHARACTER StoryCharacter)
(attribute ?CHARACTER Child)
(instance ?OBJECT Object)
(attribute ?OBJECT Fragile)
(holdsDuring (WhenFn ?X)
(orientation ?CHARACTER ?OBJECT Near))
(exists (?DAMAGE)
(and
(instance ?DAMAGE Damaging)
(subProcess ?DAMAGE ?X)
(agent ?DAMAGE ?CHARACTER)
(patient ?DAMAGE ?OBJECT))))
</figure>
<bodyText confidence="0.999924466666667">
As the representation shows, SUMO is quite ca-
pable of encoding temporal properties of events
with its temporal qualification. However, inferenc-
ing with rules involving time relations between
events is currently not supported by Sigma (Corda
et al, 2008). Nevertheless, efforts are underway to
perform true higher-order logical inference (Sut-
cliffe et al, 2009).
The next step involves deriving axioms to
represent the different ways in which an object can
be damaged depending on its attribute, for exam-
ple, fragile objects can break while paper-based
objects such as books and paintings can be torn.
Consideration must also be made to determine if a
damage is an accident or intentional.
</bodyText>
<subsectionHeader confidence="0.998983">
3.4 Conceptualizing Story Themes
</subsectionHeader>
<bodyText confidence="0.998058333333333">
Themes can also be mapped to SUMO as thematic
predicates, and the story planner can identify a
theme either based on the first action that was per-
formed, or based on user selection. In the latter
case, when Sigma returns all possible actions, the
planner can choose one based on the theme.
</bodyText>
<page confidence="0.999326">
45
</page>
<sectionHeader confidence="0.971279" genericHeader="method">
4 System Architecture
</sectionHeader>
<bodyText confidence="0.999843666666667">
The architecture of SUMOs, shown in Figure 2,
has two main modules, the Story Editor and the
Story Planner, both of which interact with Sigma3
to retrieve story facts from the SUMO ontology as
well as to assert new axioms representing the de-
veloping story plan back to SUMO.
</bodyText>
<figureCaption confidence="0.998526">
Figure 2. Architecture of SUMOs
</figureCaption>
<bodyText confidence="0.999785136363637">
The Story Editor handles the generation of as-
sertions corresponding to the input picture ele-
ments specified by the user.
The Story Planner is responsible for planning
the flow of events in the story. It uses a meta-
knowledge about children’s story comprising of
five phases – introduction, problem, rising action,
solution, and climax. The planner determines and
phrases the queries that are sent to Sigma and ge-
nerates additional axioms based on the query re-
sults in order to expand the story plan. The
generated axioms are asserted back to Sigma for
inclusion in the SUMO ontology to be used again
for further inferencing.
Queries sent to Sigma can be classified into
three categories. Concept-based queries concern
classes and instances, and are used to determine
direct and indirect subclass and class-instance rela-
tionships while relation-based queries infer know-
ledge by considering transitivity, symmetry and
inversion of relations (Corda et al, 2008). Action-
based queries identify a set of actions based on the
</bodyText>
<page confidence="0.374718">
3 Sigma Knowledge Engineering Environment,
http://sigmakee.sourceforge.net
</page>
<bodyText confidence="0.999963347826087">
current world state to drive the story. A fourth cat-
egory, time-event queries, currently not supported
by Sigma, should reason about temporal and event-
based specifications.
The interaction between the Story Planner and
Sigma in Figure 2 raises an issue of search control.
In Picture Books and SUMOs, information that
guides the story planning can be bottom-up, i.e. the
actions and events are determined based on what is
possible within the story ontology, e.g. through the
various capability axioms, or top-down, i.e. actions
are selected based on Machado&apos;s narrative subplot
knowledge. Currently, the Story Planner is respon-
sible for managing the process. However, if both
these sources of knowledge and constraints can be
represented in first-order logic, the search control
of the story planning process can be recast as a
theorem proving task, i.e. one that searches for a
proof that satisfies all constraints. This is a future
research direction.
The following section presents a more detailed
trace of system operation and the contents of a sto-
ry plan in first-order logic.
</bodyText>
<subsectionHeader confidence="0.999619">
4.1 Generating Story Plans
</subsectionHeader>
<bodyText confidence="0.9991955">
The first part of the story plan contains assertions
to represent the initial elements of the story. Using
the story in Table 1 as an example, lines 1 to 6 be-
low assert the main child character and her parent,
while lines 7 to 8 assert the background and the
object, respectively.
</bodyText>
<table confidence="0.991302375">
1&gt; (instance Rabbit1 RabbitCharacter)
2&gt; (attribute Rabbit1 Child)
3&gt; (attribute Rabbit1 Female)
4&gt; (instance Rabbit2 RabbitCharacter)
5&gt; (attribute Rabbit2 Adult)
6&gt; (attribute Rabbit2 Female)
7&gt; (instance LivingRoom1 LivingRoom)
8&gt; (instance Lamp1 Lamp)
</table>
<bodyText confidence="0.9987116">
The next step involves initializing the locations
of these story elements. Currently, it is setup that
all objects would be situated in the background and
the first child character would always be near the
first object, as shown in the assertions below.
</bodyText>
<figure confidence="0.459325666666667">
9&gt; (located Rabbit1 LivingRoom1)
10&gt; (located Lamp1 LivingRoom1)
11&gt; (orientation Rabbit1 Lamp1 Near)
</figure>
<bodyText confidence="0.991688333333333">
This, however, creates the assumption that the
child character is already in the location near ob-
jects which he will interact with, which may not
</bodyText>
<figure confidence="0.999236318181818">
Story
Planner
Story plan
(SUMO)
abstract
story plan
return
results
query
SIGMA
(Inference
Engine)
Story
Editor
assertions
assertions
obtain
results
SUMO
Ontology
(Story
Ontology)
</figure>
<page confidence="0.998816">
46
</page>
<bodyText confidence="0.9999201">
necessarily be true and reduces the flexibility of
the system. In order to create more varied stories,
the initial location can be identified based on the
theme and the first event that the user would want
to likely happen in the story.
From the initial set of assertions, the story plan-
ner issues its first concept-based query to Sigma
with “(name Rabbit1 ?X)” to determine a name for
the main character, Rabbit1, and receives “Rizzy”
as a result. This is asserted to the story plan as:
</bodyText>
<subsectionHeader confidence="0.497067">
12&gt; (name Rabbit1 “Rizzy”)
</subsectionHeader>
<bodyText confidence="0.999954">
The next query is the first action-based query
used to determine the first action to start the story
flow. Given “(capability ?X experiencer Rabbit1)”,
which is intended for identifying the set of possible
starting actions that the main character, Rabbit1,
can perform with the object in the background,
Sigma returns the following list (assuming the sto-
ry facts given in the previous section):
</bodyText>
<equation confidence="0.9175575">
X = [RecreationOrExercise, Looking,
Maintaining, Poking]
</equation>
<bodyText confidence="0.996986333333333">
Assuming the planner selects RecreationOrEx-
ercise, the following assertions are then added to
the story plan:
</bodyText>
<figure confidence="0.6415885">
13&gt; (instance RecOrEx1 RecreationOrExercise)
14&gt; (agent RecOrEx1 Rabbit1)
</figure>
<bodyText confidence="0.9999513">
At this point, the introduction phase of the story
plan has been completed. The problem phase be-
gins with a query to identify any instances of prob-
lems that can occur, i.e. “(instance ?X Damaging)”.
Damaging the object lamp causes its attribute to be
changed, and again we query Sigma for this
change of state with “(attribute Lamp1 ?X)” yielding
the result broken, and the corresponding emotional
state of the character “(attribute Rabbit1 ?X)”. The
following assertions were added to the plan:
</bodyText>
<figure confidence="0.78002525">
15&gt; (instance (sk0 Rabbit1 Lamp1
RecOrEx1) Damaging)
16&gt; (attribute Lamp1 Broken)
17&gt; (attribute Rabbit1 Anxiety)
</figure>
<bodyText confidence="0.998639666666666">
While a full explanation of skolemization is not
possible here for space reasons, we note that the
second argument of assertion #15 (derived from
Sigma’s answer to the query) stands for the exis-
tence of an unnamed term, in this case, that there is
an instance of a Damaging process. The agent
(Rabbit1), patient (Lamp1), and the action (RecO-
rEx1) that caused the problem were all provided in
the query result.
</bodyText>
<subsectionHeader confidence="0.979288">
4.2 Generating Surface Text
</subsectionHeader>
<bodyText confidence="0.999983583333333">
SUMO-based story plans provide a form of inter-
lingua where story details are represented in logi-
cal form. The logical representation allows
generation of the same story in different languages
(that are connected to WordNet). Sigma already
has a language generator, with templates for Eng-
lish, and an initial set for Tagalog (Borra et al,
2010). Work is currently underway to enhance the
existing language generator in Sigma and make the
generated text more natural. Sigma can then be
used to generate stories automatically from the
knowledge asserted in the story generation process.
</bodyText>
<sectionHeader confidence="0.997491" genericHeader="conclusions">
5 Conclusions and Further Work
</sectionHeader>
<bodyText confidence="0.999973205882353">
The paper presented a preliminary work aimed at
representing storytelling knowledge in SUMO and
using Sigma as inference engine to assist the plan-
ner in generating story plans. Further work focuses
on modeling the emotional state of the character as
a result of some event (e.g., feeling worried, guilty
or scared due to causing some problems in the
world state), changes in character traits as the story
progresses (e.g., from negative trait to positive trait
as the story flows from rule violation to value ac-
quisition), and enhancing the representation for
story themes. Once a set of knowledge has been
developed, these should be evaluated systematical-
ly through validation of the rules for logical consis-
tency with the theorem prover. A future goal is to
apply the metrics proposed by Callaway &amp; Lester
(2002) in StoryBook to evaluate with actual users
if the generated stories are better and more varied
as compared to that of Picture Books.
Although SUMO is quite capable of
representing time and sequences, reasoning with
temporally qualified expression is challenging for
any theorem prover. The works of (Sutcliffe et al,
2009) to extend the inference engine to handle rea-
soning over temporal relations should be explored
further to allow SUMOs to generate story plans
that consider temporal relations between actions
and events.
Finally, story generators will benefit its readers
if the generated stories are narrated orally. SUMOs
can be explored further to model various emotions
to provide annotations in the surface story text
which will then be fed to a text to speech tool for
speech generation.
</bodyText>
<page confidence="0.999093">
47
</page>
<sectionHeader confidence="0.99835" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999288642857143">
Borra, A., Pease, A., Roxas, R. and Dita, S. 2010. Intro-
ducing Filipino WordNet. In: Principles, Construc-
tion and Application of Multilingual Wordnets:
Proceedings of the 5th Global WordNet Conference,
Mumbai, India.
Callaway, C. B., and Lester, J. C. 2002. Narrative Prose
Generation. Artificial Intelligence, 139(2):213-252,
Elsevier Science Publishers Ltd., Essex, UK.
Corda, I., Bennett, B., and Dimitrova, V. 2008. Interact-
ing with an Ontology to Explore Historical Domains.
Proceedings of the 2008 First International Work-
shop on Ontologies in Interactive Systems, 65-74,
IEEE Computer Society.
Gangemi, A., Guarino, N., Masolo, C., and Oltramari,
A. 2003. AI Magazine, 24(3):13-24, Association for
the Advancement of Artificial Intelligence.
Kooijman, R. 2004. De virtuele verhalenverteller:
voorstel voor het gebruik van een upper-ontology en
een nieuwe architectuur. Technical Report. Universi-
ty of Twente, Department of Electrical Engineering,
Mathematics and Computer Science.
Hong, A., Solis, C., Siy, J.T., and Tabirao, E. 2008. Pic-
ture Books: Automated Story Generator. Undergra-
duate Thesis, De La Salle University, Manila,
Philippines.
Lenat, D.B. 1995. Cyc: A Large-Scale Investment in
Knowledge Infrastructure, Communications of the
ACM, 38(11).
Liu, H. and Singh, P. 2004. Commonsense Reasoning in
and over Natural Language. Proceedings of the 8th
International Conference on Knowledge-Based Intel-
ligent Information and Engineering Systems, 293-
306, Wellington, New Zealand, Springer Berlin.
Machado, J. 2003. Storytelling. In Early Childhood
Experiences in Language Arts: Emerging Literacy,
304-319. Clifton Park, N.Y., Thomson/Delmar
Learning.
Niles, I. and Pease, A. 2001. Towards A Standard Upper
Ontology. Proceedings of Formal Ontology in
Information Systems (FOIS 2001), 2-9, October 17-
19, Ogunquit, Maine, USA.
Noy, N. and McGuinness, D. 2001. Ontology Develop-
ment 101: A Guide to Creating Your First Ontology.
Stanford Knowledge Systems Laboratory Technical
Report KSL-01-05 and Stanford Medical Informatics
Technical Report SMI-2001-0880, March 2001.
Ong, E. 2009. Prospects in Creative Natural Language
Processing. Proceedings of the 6th National Natural
Language Processing Research Symposium, De La
Salle University, Manila, Philippines.
Pease, A. 2006. Formal Representation of Concepts:
The Suggested Upper Merged Ontology and Its Use
in Linguistics. Ontolinguistics. How Ontological Sta-
tus Shapes the Linguistic Coding of Concepts. Schal-
ley, A.C. and Zaefferer, D. (ed.), Vorbereitung
Berlin, New York.
Pease, A. 2003. The Sigma Ontology Development En-
vironment. Working Notes of the IJCAI-2003 Work-
shop on Ontology and Distributed Systems, vol. 71 of
CEUR Workshop Proceeding series.
Riedl, M. and Young, R.M. 2004. An Intent-Driven
Planner for Multi-Agent Story Generation. Proceed-
ings of the Third International Joint Conference on
Autonomous Agents and Multi-Agent Systems, 186-
193, Washington DC, USA, IEEE Computer Society.
Smith, B. 1998. The Basic Tools of Formal Ontology.
Formal Ontology in Information Systems, Nicola Gu-
arino (ed), IOS Press, Washington. Frontiers in Ar-
tificial Intelligence and Applications, 19-28.
Solis, C., Siy, J.T., Tabirao, E., and Ong, E. 2009. Plan-
ning Author and Character Goals for Story Genera-
tion. Proceedings of the NAACL Human Language
Technology 2009 Workshop on Computational Ap-
proaches to Linguistic Creativity, 63-70, Boulder,
Colorado, USA.
Sutcliffe, G., Benzmüller, C., Brown, C.E., and Theiss,
F. 2009. Progress in the Development of Automated
Theorem Proving for Higher-order Logic. Automated
Deduction, 22nd International Conference on Auto-
mated Deduction, Montreal, Canada, August 2-7,
2009. Proceedings of the Lecture Notes in AI, vol.
5663, 116-130, 2009, Springer.
Swartjes, I. 2006. The Plot Thickens: Bringing Structure
and Meaning into Automated Story Generation. Mas-
ter&apos;s Thesis, University of Twente, The Netherlands.
Theune, M., Nijholt, A., Oinonen, K., and Uijlings J.
2006. Designing a Story Database for Use in Auto-
matic Story Generation. Proceedings 5th Interna-
tional Conference Entertainment Computing,
Cambridge, UK. Lecturer Notes in Computer
Science, 4161:298-301, Heidelberg, Springer Berlin.
Uijlings, J.R.R. 2006. Designing a Virtual Environment
for Story Generation. MS Thesis, University of Ams-
terdam, The Netherlands.
Venour, C. and Reiter, E. 2008. A Tutorial for Sim-
plenlg. http://www.csd.abdn.ac.uk/~ereiter/simplenlg
WordNet. 2006. WordNet: A Lexical Database for the
English Language. Princeton University, New Jersey.
</reference>
<page confidence="0.999355">
48
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.327765">
<title confidence="0.999267">Representing Story Plans in SUMO</title>
<author confidence="0.999947">Jeffrey Cua Ethel Ong</author>
<affiliation confidence="0.7740855">Center for Human Language Technologies College of Computer Studies De La Salle University, Manila, Philippines De La Salle University, Manila, Philippines</affiliation>
<email confidence="0.828059">cuajeffreyleonardcompro1@yahoo.comethel.ong@delasalle.ph</email>
<author confidence="0.868584">Ruli Manurung</author>
<affiliation confidence="0.998546">Faculty of Computer University of Indonesia, Jakarta,</affiliation>
<email confidence="0.926514">maruli@cs.ui.ac.id</email>
<author confidence="0.992709">Adam Pease</author>
<affiliation confidence="0.966082">Articulate</affiliation>
<address confidence="0.998259">Angwin, California, USA</address>
<email confidence="0.999794">apease@articulatesoftware.com</email>
<abstract confidence="0.9993474375">Automatic story generation systems require a body of commonsense knowledge about the basic relationships between concepts we find everyday in our world in order to produce interesting narratives that describe human actions and world events. This paper presents an ongoing work that investigates the use of Suggested Upper Merged Ontology (SUMO) to represent storytelling knowledge and its inference engine Sigma to query actions and events that may take place in the story to be The resulting story plan is also represented in SUMO, allowing for a single story representation to be realized in various human languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Borra</author>
<author>A Pease</author>
<author>R Roxas</author>
<author>S Dita</author>
</authors>
<title>Introducing Filipino WordNet. In: Principles, Construction and Application of Multilingual Wordnets:</title>
<date>2010</date>
<booktitle>Proceedings of the 5th Global WordNet Conference,</booktitle>
<location>Mumbai, India.</location>
<contexts>
<context position="29732" citStr="Borra et al, 2010" startWordPosition="4641" endWordPosition="4644"> the query) stands for the existence of an unnamed term, in this case, that there is an instance of a Damaging process. The agent (Rabbit1), patient (Lamp1), and the action (RecOrEx1) that caused the problem were all provided in the query result. 4.2 Generating Surface Text SUMO-based story plans provide a form of interlingua where story details are represented in logical form. The logical representation allows generation of the same story in different languages (that are connected to WordNet). Sigma already has a language generator, with templates for English, and an initial set for Tagalog (Borra et al, 2010). Work is currently underway to enhance the existing language generator in Sigma and make the generated text more natural. Sigma can then be used to generate stories automatically from the knowledge asserted in the story generation process. 5 Conclusions and Further Work The paper presented a preliminary work aimed at representing storytelling knowledge in SUMO and using Sigma as inference engine to assist the planner in generating story plans. Further work focuses on modeling the emotional state of the character as a result of some event (e.g., feeling worried, guilty or scared due to causing</context>
</contexts>
<marker>Borra, Pease, Roxas, Dita, 2010</marker>
<rawString>Borra, A., Pease, A., Roxas, R. and Dita, S. 2010. Introducing Filipino WordNet. In: Principles, Construction and Application of Multilingual Wordnets: Proceedings of the 5th Global WordNet Conference, Mumbai, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C B Callaway</author>
<author>J C Lester</author>
</authors>
<title>Narrative Prose Generation.</title>
<date>2002</date>
<journal>Artificial Intelligence,</journal>
<pages>139--2</pages>
<publisher>Elsevier Science Publishers Ltd.,</publisher>
<location>Essex, UK.</location>
<contexts>
<context position="30818" citStr="Callaway &amp; Lester (2002)" startWordPosition="4817" endWordPosition="4820">focuses on modeling the emotional state of the character as a result of some event (e.g., feeling worried, guilty or scared due to causing some problems in the world state), changes in character traits as the story progresses (e.g., from negative trait to positive trait as the story flows from rule violation to value acquisition), and enhancing the representation for story themes. Once a set of knowledge has been developed, these should be evaluated systematically through validation of the rules for logical consistency with the theorem prover. A future goal is to apply the metrics proposed by Callaway &amp; Lester (2002) in StoryBook to evaluate with actual users if the generated stories are better and more varied as compared to that of Picture Books. Although SUMO is quite capable of representing time and sequences, reasoning with temporally qualified expression is challenging for any theorem prover. The works of (Sutcliffe et al, 2009) to extend the inference engine to handle reasoning over temporal relations should be explored further to allow SUMOs to generate story plans that consider temporal relations between actions and events. Finally, story generators will benefit its readers if the generated storie</context>
</contexts>
<marker>Callaway, Lester, 2002</marker>
<rawString>Callaway, C. B., and Lester, J. C. 2002. Narrative Prose Generation. Artificial Intelligence, 139(2):213-252, Elsevier Science Publishers Ltd., Essex, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Corda</author>
<author>B Bennett</author>
<author>V Dimitrova</author>
</authors>
<title>Interacting with an Ontology to Explore Historical Domains.</title>
<date>2008</date>
<booktitle>Proceedings of the 2008 First International Workshop on Ontologies in Interactive Systems,</booktitle>
<pages>65--74</pages>
<publisher>IEEE Computer Society.</publisher>
<contexts>
<context position="22677" citStr="Corda et al, 2008" startWordPosition="3512" endWordPosition="3515">ce ?X RecreationOrExercise) (agent ?X ?CHARACTER) (instance ?CHARACTER StoryCharacter) (attribute ?CHARACTER Child) (instance ?OBJECT Object) (attribute ?OBJECT Fragile) (holdsDuring (WhenFn ?X) (orientation ?CHARACTER ?OBJECT Near)) (exists (?DAMAGE) (and (instance ?DAMAGE Damaging) (subProcess ?DAMAGE ?X) (agent ?DAMAGE ?CHARACTER) (patient ?DAMAGE ?OBJECT)))) As the representation shows, SUMO is quite capable of encoding temporal properties of events with its temporal qualification. However, inferencing with rules involving time relations between events is currently not supported by Sigma (Corda et al, 2008). Nevertheless, efforts are underway to perform true higher-order logical inference (Sutcliffe et al, 2009). The next step involves deriving axioms to represent the different ways in which an object can be damaged depending on its attribute, for example, fragile objects can break while paper-based objects such as books and paintings can be torn. Consideration must also be made to determine if a damage is an accident or intentional. 3.4 Conceptualizing Story Themes Themes can also be mapped to SUMO as thematic predicates, and the story planner can identify a theme either based on the first acti</context>
<context position="24725" citStr="Corda et al, 2008" startWordPosition="3848" endWordPosition="3851">planner determines and phrases the queries that are sent to Sigma and generates additional axioms based on the query results in order to expand the story plan. The generated axioms are asserted back to Sigma for inclusion in the SUMO ontology to be used again for further inferencing. Queries sent to Sigma can be classified into three categories. Concept-based queries concern classes and instances, and are used to determine direct and indirect subclass and class-instance relationships while relation-based queries infer knowledge by considering transitivity, symmetry and inversion of relations (Corda et al, 2008). Actionbased queries identify a set of actions based on the 3 Sigma Knowledge Engineering Environment, http://sigmakee.sourceforge.net current world state to drive the story. A fourth category, time-event queries, currently not supported by Sigma, should reason about temporal and eventbased specifications. The interaction between the Story Planner and Sigma in Figure 2 raises an issue of search control. In Picture Books and SUMOs, information that guides the story planning can be bottom-up, i.e. the actions and events are determined based on what is possible within the story ontology, e.g. th</context>
</contexts>
<marker>Corda, Bennett, Dimitrova, 2008</marker>
<rawString>Corda, I., Bennett, B., and Dimitrova, V. 2008. Interacting with an Ontology to Explore Historical Domains. Proceedings of the 2008 First International Workshop on Ontologies in Interactive Systems, 65-74, IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gangemi</author>
<author>N Guarino</author>
<author>C Masolo</author>
<author>A Oltramari</author>
</authors>
<date>2003</date>
<journal>AI Magazine, 24(3):13-24, Association for the Advancement of Artificial Intelligence.</journal>
<marker>Gangemi, Guarino, Masolo, Oltramari, 2003</marker>
<rawString>Gangemi, A., Guarino, N., Masolo, C., and Oltramari, A. 2003. AI Magazine, 24(3):13-24, Association for the Advancement of Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Kooijman</author>
</authors>
<title>De virtuele verhalenverteller: voorstel voor het gebruik van een upper-ontology en een nieuwe architectuur.</title>
<date>2004</date>
<tech>Technical</tech>
<institution>Report. University of Twente, Department of Electrical Engineering, Mathematics and Computer Science.</institution>
<contexts>
<context position="3109" citStr="Kooijman (2004)" startWordPosition="467" endWordPosition="468">performed and the corresponding consequential events that may arise. Swartjes (2006) developed a story world ontology containing two layers, the upper story world ontology and the domain-specific world ontology. The upper story world ontology is independent of any story structures or story domains and models a vast amount of possible actions and events. It is also limited to high-level concepts that are meta, generic or abstract to address a broad range of domain areas. A domain-specific story world ontology, on the other hand, applies the upper story world ontology to a certain story domain. Kooijman (2004) suggests the use of the Suggested Upper Merged Ontology (SUMO) as an upper ontology to capture the semantics of world knowledge. SUMO (Niles and Pease, 2001) is an 40 Proceedings of the NAACL HLT 2010 Second Workshop on Computational Approaches to Linguistic Creativity, pages 40–48, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics open source formal and public ontology. It is a collection of well-defined and well-documented concepts, interconnected into a logical theory. It numbers some 20,000 terms and 70,000 axioms. Axioms are in first-order logic form (w</context>
</contexts>
<marker>Kooijman, 2004</marker>
<rawString>Kooijman, R. 2004. De virtuele verhalenverteller: voorstel voor het gebruik van een upper-ontology en een nieuwe architectuur. Technical Report. University of Twente, Department of Electrical Engineering, Mathematics and Computer Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Hong</author>
<author>C Solis</author>
<author>J T Siy</author>
<author>E Tabirao</author>
</authors>
<title>Picture Books: Automated Story Generator. Undergraduate Thesis,</title>
<date>2008</date>
<institution>De La Salle University,</institution>
<location>Manila, Philippines.</location>
<contexts>
<context position="7412" citStr="Hong et al, 2008" startWordPosition="1124" endWordPosition="1127"> the semantic network. These are the story world knowledge, character representations, a causal and temporal network to represent plot structures, representational model of narratological concepts, and the representation of the story’s potential effects on the user. Only the first four levels are included in this study. According to Swartjes (2006), a story is composed of a story world where the story takes place, the characters that interact in the story world, and the associated objects. Consider the story generated by Picture Books in Table 1 about Rizzy the rabbit who learns to be honest (Hong et al, 2008). The afternoon was windy. Rizzy the rabbit was in the dining room. She played near a lamp. Rizzy broke the lamp. She was scared. Mommy Francine saw that the lamp was broken. Rizzy told Mommy Francine that Daniel broke the lamp. Daniel the dog told her that he did not break the lamp. Daniel was upset. He got punished. Mommy Francine told Daniel that he was grounded. He cried. Rizzy felt guilty. She told Mommy Francine that she broke the lamp. Mommy Francine told Rizzy that she should have been honest. Rizzy apologized to Mommy Francine. Mommy Francine forgave Rizzy. Rizzy apologized to Daniel.</context>
<context position="9120" citStr="Hong et al, 2008" startWordPosition="1423" endWordPosition="1426">nd serves as the main setting of the story, and combined with the selected objects, is used to determine the theme. Consider the bedroom setting. If the associated object is a lamp, then the theme is about bravery (i.e., do not be afraid of the dark). If the object is a set of toy blocks, the theme can be about being neat. In Picture Books, such associations are manually determined and entered into the database. In SUMOs, these associations should be inferred automatically through axioms that should be commonsense, and not be explicit encoding of narrative knowledge. Figure 2. Picture Editor (Hong et al, 2008) Stories generated by Picture Books follow a basic plot dictated by Machado (2003) that flows from negative to positive and comprises four subplots, namely the problem, rising action, solution and climax. The theme is subdivided into these four subplots, each representing a major event in the story. Each subplot contains at least two author goals representing the goal of the scene and the corresponding consequence of the goal. An author goal is translated into one or more character goals, each representing an action performed by the character (main, secondary, or adult character) in order to a</context>
<context position="11336" citStr="Hong et al, 2008" startWordPosition="1785" endWordPosition="1788">cene Child lied Character goal &lt;main character&gt; told &lt;adult character&gt; that &lt;secondary character&gt; &lt;did the action&gt; Resulting text Rizzy told Mommy Francine that Daniel the dog broke the lamp. Author goal 2.2: Goal consequence Another child gets punished Character goal #1 &lt;secondary character&gt; receives &lt;punishment&gt; Resulting text #1 Daniel the dog got punished. Character goal #2 &lt;adult character&gt; issues &lt;punishment&gt; to &lt;secondary character&gt; Resulting text #2 Mommy Francine told Daniel that he was grounded. Table 2. Sample author goals and character goals associated with the theme Being Honest (Hong et al, 2008) The story planner of Picture Books utilizes two types of knowledge, the operational knowledge and the domain knowledge. The operational knowledge contains a static description of the different backgrounds and their associated themes and objects, the child characters and their corresponding parent characters, as well as the occupation of the 42 parents. For each theme, the set of character goals needed to instantiate the major events in the theme are also specified. The domain knowledge, on the other hand, contains a semantic description of objects and events that can occur, as well as actions</context>
<context position="17714" citStr="Hong et al, 2008" startWordPosition="2762" endWordPosition="2765">g the semantic categories of ConceptNet (Liu and Singh, 2004). Objects IsA (doll, toys) Activities IsA (play games, activity) Concepts IsA (grounded, punishment) IsA (disorder, problem) IsA (no appetite, problem) IsA (dizzy, discomfort) IsA (itchy, discomfort) Emotions IsA (happy, emotion) IsA (scared, emotion) Reaction to EffectOf (break object, scared) Events EffectOf (meet new friends, smile) Location LocationOf (toys, toy store) Capability CapableOf (lamp, break) CapableOf (glass of water, break) CanBe (toys, scattered) Table 3. Semantic relationships in Picture Books based on ConceptNet (Hong et al, 2008) In SUMOs, all isA(entity1, entity2) relations were replaced with the axiom (subclass entity1 entity2). To specify that an entity is in a location, i.e., locationOf(toys, toy store), first, we create an instance of a toystore and then specify that a certain toy instance is in that toystore, as follows: (=&gt; (instance ?TOYSTORE ToyStore) (exists (?TOY) (and (instance ?TOY Toy) (located ?TOY ?TOYSTORE)))) The capability axiom is used to conceptualize the capability relation (capability ?process ?role ?obj). It specifies that ?obj has the specified ?role in the ?process. For example, a lamp or a g</context>
</contexts>
<marker>Hong, Solis, Siy, Tabirao, 2008</marker>
<rawString>Hong, A., Solis, C., Siy, J.T., and Tabirao, E. 2008. Picture Books: Automated Story Generator. Undergraduate Thesis, De La Salle University, Manila, Philippines.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D B Lenat</author>
</authors>
<title>Cyc: A Large-Scale Investment in Knowledge Infrastructure,</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<contexts>
<context position="4126" citStr="Lenat, 1995" startWordPosition="625" endWordPosition="626">ogy. It is a collection of well-defined and well-documented concepts, interconnected into a logical theory. It numbers some 20,000 terms and 70,000 axioms. Axioms are in first-order logic form (with some higher order extensions) and reflect commonsense notions that are generally recognized among the concepts. They place a constraint on the interpretation of concepts and provide guidelines for automated reasoning systems such as Sigma (Pease, 2003). Formal terms in SUMO are mapped to synsets in WordNet (Pease, 2006). There are other noteworthy ontologies that can be considered. Like SUMO, Cyc (Lenat, 1995) is a large-scale, language-independent and extensible knowledge base and commonsense reasoning engine, but it is proprietary and its open-source version, OpenCyc1, has no inference rules. DOLCE (Gangemi, 2003) is a small-scale descriptive ontology with a cognitive orientation. BFO (Smith, 1998) is another small-scale upper ontology supporting domain ontologies developed for scientific research domain, such as biomedicine. Thus, no ontology other than SUMO had the characteristics of being comprehensive enough to include formalizations that represent detailed elements of everyday life (e.g., fu</context>
</contexts>
<marker>Lenat, 1995</marker>
<rawString>Lenat, D.B. 1995. Cyc: A Large-Scale Investment in Knowledge Infrastructure, Communications of the ACM, 38(11).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Liu</author>
<author>P Singh</author>
</authors>
<title>Commonsense Reasoning in and over Natural Language.</title>
<date>2004</date>
<booktitle>Proceedings of the 8th International Conference on Knowledge-Based Intelligent Information and Engineering Systems,</booktitle>
<pages>293--306</pages>
<publisher>Zealand, Springer</publisher>
<location>Wellington, New</location>
<contexts>
<context position="1837" citStr="Liu and Singh, 2004" startWordPosition="265" endWordPosition="268">elationships in order to tell stories about their lives, their communities, and their daily experiences. In order for computers to achieve the same level of expressiveness to provide a more fluent man-machine interaction, they must be provided with the same collection of knowledge about the basic relationships between things and events. Picture Books (Solis et al, 2009), an automatic story generator that generates story text for children from a given input set of picture elements (backgrounds, characters and objects), utilized a semantic ontology whose design has been adapted from ConceptNet (Liu and Singh, 2004). The background serves as the setting of the story and is also used to determine the theme. Semantic concepts needed by the story planner, specifically objects, story events, and character actions are classified according to the semantic categories of ConceptNet, namely things, spatial, events, actions, and functions. This mapping approach constrained the flexibility of the system, as new themes would entail repopulating the sequences of possible events manually into the knowledge base. Events and actions are selected according to their associated themes, and not marked with preconditions tha</context>
<context position="17158" citStr="Liu and Singh, 2004" startWordPosition="2686" endWordPosition="2689">ance ?R LivingRoom) (hasPurpose ?R (exists (?S) (and (instance ?S SocialInteraction) (located ?S ?R))))) (disjoint LivingRoom Bathroom) 3.2 Representing Semantic Concepts Aside from the properties of objects that are modeled using the attribute axiom, semantic relationships that may hold between two concepts involving types of activities or actions, character emotions, locations of objects, and abilities of characters or objects must also be modeled. Table 3 shows sample semantic relationships for these concepts as represented in Picture Books, following the semantic categories of ConceptNet (Liu and Singh, 2004). Objects IsA (doll, toys) Activities IsA (play games, activity) Concepts IsA (grounded, punishment) IsA (disorder, problem) IsA (no appetite, problem) IsA (dizzy, discomfort) IsA (itchy, discomfort) Emotions IsA (happy, emotion) IsA (scared, emotion) Reaction to EffectOf (break object, scared) Events EffectOf (meet new friends, smile) Location LocationOf (toys, toy store) Capability CapableOf (lamp, break) CapableOf (glass of water, break) CanBe (toys, scattered) Table 3. Semantic relationships in Picture Books based on ConceptNet (Hong et al, 2008) In SUMOs, all isA(entity1, entity2) relatio</context>
</contexts>
<marker>Liu, Singh, 2004</marker>
<rawString>Liu, H. and Singh, P. 2004. Commonsense Reasoning in and over Natural Language. Proceedings of the 8th International Conference on Knowledge-Based Intelligent Information and Engineering Systems, 293-306, Wellington, New Zealand, Springer Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Machado</author>
</authors>
<title>Storytelling. In Early Childhood Experiences in Language Arts: Emerging Literacy,</title>
<date>2003</date>
<pages>304--319</pages>
<location>Clifton Park, N.Y., Thomson/Delmar Learning.</location>
<contexts>
<context position="9202" citStr="Machado (2003)" startWordPosition="1439" endWordPosition="1440">s used to determine the theme. Consider the bedroom setting. If the associated object is a lamp, then the theme is about bravery (i.e., do not be afraid of the dark). If the object is a set of toy blocks, the theme can be about being neat. In Picture Books, such associations are manually determined and entered into the database. In SUMOs, these associations should be inferred automatically through axioms that should be commonsense, and not be explicit encoding of narrative knowledge. Figure 2. Picture Editor (Hong et al, 2008) Stories generated by Picture Books follow a basic plot dictated by Machado (2003) that flows from negative to positive and comprises four subplots, namely the problem, rising action, solution and climax. The theme is subdivided into these four subplots, each representing a major event in the story. Each subplot contains at least two author goals representing the goal of the scene and the corresponding consequence of the goal. An author goal is translated into one or more character goals, each representing an action performed by the character (main, secondary, or adult character) in order to achieve the author goal. A character goal translates directly to one declarative se</context>
</contexts>
<marker>Machado, 2003</marker>
<rawString>Machado, J. 2003. Storytelling. In Early Childhood Experiences in Language Arts: Emerging Literacy, 304-319. Clifton Park, N.Y., Thomson/Delmar Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Niles</author>
<author>A Pease</author>
</authors>
<title>Towards A Standard Upper Ontology.</title>
<date>2001</date>
<booktitle>Proceedings of Formal Ontology in Information Systems (FOIS</booktitle>
<pages>2--9</pages>
<location>Ogunquit, Maine, USA.</location>
<contexts>
<context position="3267" citStr="Niles and Pease, 2001" startWordPosition="492" endWordPosition="495">story world ontology and the domain-specific world ontology. The upper story world ontology is independent of any story structures or story domains and models a vast amount of possible actions and events. It is also limited to high-level concepts that are meta, generic or abstract to address a broad range of domain areas. A domain-specific story world ontology, on the other hand, applies the upper story world ontology to a certain story domain. Kooijman (2004) suggests the use of the Suggested Upper Merged Ontology (SUMO) as an upper ontology to capture the semantics of world knowledge. SUMO (Niles and Pease, 2001) is an 40 Proceedings of the NAACL HLT 2010 Second Workshop on Computational Approaches to Linguistic Creativity, pages 40–48, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics open source formal and public ontology. It is a collection of well-defined and well-documented concepts, interconnected into a logical theory. It numbers some 20,000 terms and 70,000 axioms. Axioms are in first-order logic form (with some higher order extensions) and reflect commonsense notions that are generally recognized among the concepts. They place a constraint on the interpretat</context>
</contexts>
<marker>Niles, Pease, 2001</marker>
<rawString>Niles, I. and Pease, A. 2001. Towards A Standard Upper Ontology. Proceedings of Formal Ontology in Information Systems (FOIS 2001), 2-9, October 17-19, Ogunquit, Maine, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Noy</author>
<author>D McGuinness</author>
</authors>
<title>Ontology Development 101: A Guide to Creating Your First Ontology.</title>
<date>2001</date>
<tech>Technical Report KSL-01-05</tech>
<institution>Stanford Knowledge Systems Laboratory</institution>
<marker>Noy, McGuinness, 2001</marker>
<rawString>Noy, N. and McGuinness, D. 2001. Ontology Development 101: A Guide to Creating Your First Ontology. Stanford Knowledge Systems Laboratory Technical Report KSL-01-05 and Stanford Medical Informatics Technical Report SMI-2001-0880, March 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Ong</author>
</authors>
<title>Prospects in Creative Natural Language Processing.</title>
<date>2009</date>
<booktitle>Proceedings of the 6th National Natural Language Processing Research Symposium,</booktitle>
<institution>De La Salle University,</institution>
<location>Manila, Philippines.</location>
<marker>Ong, 2009</marker>
<rawString>Ong, E. 2009. Prospects in Creative Natural Language Processing. Proceedings of the 6th National Natural Language Processing Research Symposium, De La Salle University, Manila, Philippines.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Pease</author>
</authors>
<title>Formal Representation of Concepts: The Suggested Upper Merged Ontology and Its Use</title>
<date>2006</date>
<booktitle>in Linguistics. Ontolinguistics. How Ontological Status Shapes the Linguistic Coding of Concepts. Schalley,</booktitle>
<editor>A.C. and Zaefferer, D. (ed.),</editor>
<location>Vorbereitung Berlin, New York.</location>
<contexts>
<context position="4034" citStr="Pease, 2006" startWordPosition="611" endWordPosition="612">e 2010. c�2010 Association for Computational Linguistics open source formal and public ontology. It is a collection of well-defined and well-documented concepts, interconnected into a logical theory. It numbers some 20,000 terms and 70,000 axioms. Axioms are in first-order logic form (with some higher order extensions) and reflect commonsense notions that are generally recognized among the concepts. They place a constraint on the interpretation of concepts and provide guidelines for automated reasoning systems such as Sigma (Pease, 2003). Formal terms in SUMO are mapped to synsets in WordNet (Pease, 2006). There are other noteworthy ontologies that can be considered. Like SUMO, Cyc (Lenat, 1995) is a large-scale, language-independent and extensible knowledge base and commonsense reasoning engine, but it is proprietary and its open-source version, OpenCyc1, has no inference rules. DOLCE (Gangemi, 2003) is a small-scale descriptive ontology with a cognitive orientation. BFO (Smith, 1998) is another small-scale upper ontology supporting domain ontologies developed for scientific research domain, such as biomedicine. Thus, no ontology other than SUMO had the characteristics of being comprehensive </context>
</contexts>
<marker>Pease, 2006</marker>
<rawString>Pease, A. 2006. Formal Representation of Concepts: The Suggested Upper Merged Ontology and Its Use in Linguistics. Ontolinguistics. How Ontological Status Shapes the Linguistic Coding of Concepts. Schalley, A.C. and Zaefferer, D. (ed.), Vorbereitung Berlin, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Pease</author>
</authors>
<title>The Sigma Ontology Development Environment.</title>
<date>2003</date>
<booktitle>Working Notes of the IJCAI-2003 Workshop on Ontology and Distributed Systems,</booktitle>
<volume>71</volume>
<contexts>
<context position="3965" citStr="Pease, 2003" startWordPosition="598" endWordPosition="599">s to Linguistic Creativity, pages 40–48, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics open source formal and public ontology. It is a collection of well-defined and well-documented concepts, interconnected into a logical theory. It numbers some 20,000 terms and 70,000 axioms. Axioms are in first-order logic form (with some higher order extensions) and reflect commonsense notions that are generally recognized among the concepts. They place a constraint on the interpretation of concepts and provide guidelines for automated reasoning systems such as Sigma (Pease, 2003). Formal terms in SUMO are mapped to synsets in WordNet (Pease, 2006). There are other noteworthy ontologies that can be considered. Like SUMO, Cyc (Lenat, 1995) is a large-scale, language-independent and extensible knowledge base and commonsense reasoning engine, but it is proprietary and its open-source version, OpenCyc1, has no inference rules. DOLCE (Gangemi, 2003) is a small-scale descriptive ontology with a cognitive orientation. BFO (Smith, 1998) is another small-scale upper ontology supporting domain ontologies developed for scientific research domain, such as biomedicine. Thus, no ont</context>
</contexts>
<marker>Pease, 2003</marker>
<rawString>Pease, A. 2003. The Sigma Ontology Development Environment. Working Notes of the IJCAI-2003 Workshop on Ontology and Distributed Systems, vol. 71 of CEUR Workshop Proceeding series.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Riedl</author>
<author>R M Young</author>
</authors>
<title>An Intent-Driven Planner for Multi-Agent Story Generation.</title>
<date>2004</date>
<booktitle>Proceedings of the Third International Joint Conference on Autonomous Agents and Multi-Agent Systems,</booktitle>
<pages>186--193</pages>
<publisher>IEEE Computer Society.</publisher>
<location>Washington DC, USA,</location>
<marker>Riedl, Young, 2004</marker>
<rawString>Riedl, M. and Young, R.M. 2004. An Intent-Driven Planner for Multi-Agent Story Generation. Proceedings of the Third International Joint Conference on Autonomous Agents and Multi-Agent Systems, 186-193, Washington DC, USA, IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Smith</author>
</authors>
<title>The Basic Tools of Formal Ontology. Formal Ontology in Information Systems,</title>
<date>1998</date>
<booktitle>Frontiers in Artificial Intelligence and Applications,</booktitle>
<editor>(ed),</editor>
<publisher>IOS Press,</publisher>
<location>Nicola Guarino</location>
<contexts>
<context position="4422" citStr="Smith, 1998" startWordPosition="668" endWordPosition="669"> the concepts. They place a constraint on the interpretation of concepts and provide guidelines for automated reasoning systems such as Sigma (Pease, 2003). Formal terms in SUMO are mapped to synsets in WordNet (Pease, 2006). There are other noteworthy ontologies that can be considered. Like SUMO, Cyc (Lenat, 1995) is a large-scale, language-independent and extensible knowledge base and commonsense reasoning engine, but it is proprietary and its open-source version, OpenCyc1, has no inference rules. DOLCE (Gangemi, 2003) is a small-scale descriptive ontology with a cognitive orientation. BFO (Smith, 1998) is another small-scale upper ontology supporting domain ontologies developed for scientific research domain, such as biomedicine. Thus, no ontology other than SUMO had the characteristics of being comprehensive enough to include formalizations that represent detailed elements of everyday life (e.g., furniture, breaking an object, emotion), being open-source, having expressiveness of at least first order predicate calculus so that arbitrary rules about actions and consequences can be represented, having an associated open-source first-order inference engine, and a language generation capabilit</context>
</contexts>
<marker>Smith, 1998</marker>
<rawString>Smith, B. 1998. The Basic Tools of Formal Ontology. Formal Ontology in Information Systems, Nicola Guarino (ed), IOS Press, Washington. Frontiers in Artificial Intelligence and Applications, 19-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Solis</author>
<author>J T Siy</author>
<author>E Tabirao</author>
<author>E Ong</author>
</authors>
<title>Planning Author and Character Goals for Story Generation.</title>
<date>2009</date>
<booktitle>Proceedings of the NAACL Human Language Technology 2009 Workshop on Computational Approaches to Linguistic Creativity,</booktitle>
<pages>63--70</pages>
<location>Boulder, Colorado, USA.</location>
<contexts>
<context position="1589" citStr="Solis et al, 2009" startWordPosition="227" endWordPosition="230">story plan (fabula) is also represented in SUMO, allowing for a single story representation to be realized in various human languages. 1 Introduction People combine words and events from their knowledge source of words, their meanings and their relationships in order to tell stories about their lives, their communities, and their daily experiences. In order for computers to achieve the same level of expressiveness to provide a more fluent man-machine interaction, they must be provided with the same collection of knowledge about the basic relationships between things and events. Picture Books (Solis et al, 2009), an automatic story generator that generates story text for children from a given input set of picture elements (backgrounds, characters and objects), utilized a semantic ontology whose design has been adapted from ConceptNet (Liu and Singh, 2004). The background serves as the setting of the story and is also used to determine the theme. Semantic concepts needed by the story planner, specifically objects, story events, and character actions are classified according to the semantic categories of ConceptNet, namely things, spatial, events, actions, and functions. This mapping approach constrain</context>
<context position="15157" citStr="Solis et al, 2009" startWordPosition="2393" endWordPosition="2396">rs, Objects, and Backgrounds Factual predicates represent the characters, their roles, the locations, and the objects that may comprise a story. The class and subclass axioms of SUMO2 are used to define the set of characters, objects and locations. Children’s stories of the fable form are portrayed by animals that can capture the imagination and attention of the readers. Animal characters are given names, such as Ellen the elephant, Rizzy the rabbit, and Leo the lion, to give the impression that the characters are friends that the children are getting to know better through reading the story (Solis et al, 2009). Representing this in SUMO entails the use of the subclass axiom to represent class inheritance as shown below: (subclass RabbitCharacter StoryCharacter) Class definitions include slots that describe the attributes of instances of the class and their relations to other instances (Noy, 2001). A character in SUMOs has the attributes type (whether adult or child), gender, and name. An example axiom to represent a female child RabbitCharacter whose name will be “Rizzy” is shown below. Similar axioms are defined for all the other characters. (=&gt; (and (instance ?RABBIT RabbitCharacter) (attribute ?</context>
</contexts>
<marker>Solis, Siy, Tabirao, Ong, 2009</marker>
<rawString>Solis, C., Siy, J.T., Tabirao, E., and Ong, E. 2009. Planning Author and Character Goals for Story Generation. Proceedings of the NAACL Human Language Technology 2009 Workshop on Computational Approaches to Linguistic Creativity, 63-70, Boulder, Colorado, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Sutcliffe</author>
<author>C Benzmüller</author>
<author>C E Brown</author>
<author>F Theiss</author>
</authors>
<title>Progress in the Development of Automated Theorem Proving for Higher-order Logic. Automated Deduction,</title>
<date>2009</date>
<booktitle>22nd International Conference on Automated Deduction,</booktitle>
<volume>5663</volume>
<pages>116--130</pages>
<publisher>Springer.</publisher>
<location>Montreal, Canada,</location>
<contexts>
<context position="22784" citStr="Sutcliffe et al, 2009" startWordPosition="3526" endWordPosition="3530">ACTER Child) (instance ?OBJECT Object) (attribute ?OBJECT Fragile) (holdsDuring (WhenFn ?X) (orientation ?CHARACTER ?OBJECT Near)) (exists (?DAMAGE) (and (instance ?DAMAGE Damaging) (subProcess ?DAMAGE ?X) (agent ?DAMAGE ?CHARACTER) (patient ?DAMAGE ?OBJECT)))) As the representation shows, SUMO is quite capable of encoding temporal properties of events with its temporal qualification. However, inferencing with rules involving time relations between events is currently not supported by Sigma (Corda et al, 2008). Nevertheless, efforts are underway to perform true higher-order logical inference (Sutcliffe et al, 2009). The next step involves deriving axioms to represent the different ways in which an object can be damaged depending on its attribute, for example, fragile objects can break while paper-based objects such as books and paintings can be torn. Consideration must also be made to determine if a damage is an accident or intentional. 3.4 Conceptualizing Story Themes Themes can also be mapped to SUMO as thematic predicates, and the story planner can identify a theme either based on the first action that was performed, or based on user selection. In the latter case, when Sigma returns all possible acti</context>
</contexts>
<marker>Sutcliffe, Benzmüller, Brown, Theiss, 2009</marker>
<rawString>Sutcliffe, G., Benzmüller, C., Brown, C.E., and Theiss, F. 2009. Progress in the Development of Automated Theorem Proving for Higher-order Logic. Automated Deduction, 22nd International Conference on Automated Deduction, Montreal, Canada, August 2-7, 2009. Proceedings of the Lecture Notes in AI, vol. 5663, 116-130, 2009, Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Swartjes</author>
</authors>
<title>The Plot Thickens: Bringing Structure and Meaning into Automated Story Generation. Master&apos;s Thesis,</title>
<date>2006</date>
<institution>University of Twente, The Netherlands.</institution>
<contexts>
<context position="2578" citStr="Swartjes (2006)" startWordPosition="379" endWordPosition="380">tory planner, specifically objects, story events, and character actions are classified according to the semantic categories of ConceptNet, namely things, spatial, events, actions, and functions. This mapping approach constrained the flexibility of the system, as new themes would entail repopulating the sequences of possible events manually into the knowledge base. Events and actions are selected according to their associated themes, and not marked with preconditions that specify constraints under which certain actions can be performed and the corresponding consequential events that may arise. Swartjes (2006) developed a story world ontology containing two layers, the upper story world ontology and the domain-specific world ontology. The upper story world ontology is independent of any story structures or story domains and models a vast amount of possible actions and events. It is also limited to high-level concepts that are meta, generic or abstract to address a broad range of domain areas. A domain-specific story world ontology, on the other hand, applies the upper story world ontology to a certain story domain. Kooijman (2004) suggests the use of the Suggested Upper Merged Ontology (SUMO) as an</context>
<context position="7145" citStr="Swartjes (2006)" startWordPosition="1076" endWordPosition="1077">on 4. The paper concludes with a summary of what we have accomplished so far, and presents further work that can be done. 2 Storytelling Knowledge Theune and her colleagues (2006) presented five levels of the different aspects of a story that must be represented in the semantic network. These are the story world knowledge, character representations, a causal and temporal network to represent plot structures, representational model of narratological concepts, and the representation of the story’s potential effects on the user. Only the first four levels are included in this study. According to Swartjes (2006), a story is composed of a story world where the story takes place, the characters that interact in the story world, and the associated objects. Consider the story generated by Picture Books in Table 1 about Rizzy the rabbit who learns to be honest (Hong et al, 2008). The afternoon was windy. Rizzy the rabbit was in the dining room. She played near a lamp. Rizzy broke the lamp. She was scared. Mommy Francine saw that the lamp was broken. Rizzy told Mommy Francine that Daniel broke the lamp. Daniel the dog told her that he did not break the lamp. Daniel was upset. He got punished. Mommy Francin</context>
<context position="18983" citStr="Swartjes (2006)" startWordPosition="2947" endWordPosition="2948">, while a toy is the patient for the process scattering. (capability Breaking experiencer Lamp) (capability Breaking experiencer Glass) (capability Scattering experiencer Toy) Reaction to events is expressed using the if-else axiom of SUMO, for example, if a child character causes an accident (a damage), then he/she will feel anxiety. Emotions are represented using the attribute relation. (=&gt; (and (instance ?ACCIDENT Damaging) (instance ?CHARACTER StoryCharacter) (attribute ?CHARACTER Child) (agent ?ACCIDENT ?CHARACTER)) ((attribute ?CHARACTER Anxiety))) 3.3 Conceptualizing Actions and Events Swartjes (2006) noted that organizing actions and events, and causally relating them, is an essential step in story generation. Independent of the story plot, the causes and effects of character actions can be used to describe the events that form the story. Actions define activities that can be performed by a character in the story, such as play, tell a lie, or cry. Events, on the other hand, occur in the story as a result of performing some actions, such as a lamp breaking as a result of a character or an object hitting it. Swartjes (2006) further notes that events are not executed by a character. Action p</context>
</contexts>
<marker>Swartjes, 2006</marker>
<rawString>Swartjes, I. 2006. The Plot Thickens: Bringing Structure and Meaning into Automated Story Generation. Master&apos;s Thesis, University of Twente, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Theune</author>
<author>A Nijholt</author>
<author>K Oinonen</author>
<author>J Uijlings</author>
</authors>
<title>Designing a Story Database for Use in Automatic Story Generation.</title>
<date>2006</date>
<booktitle>Proceedings 5th International Conference Entertainment Computing, Cambridge, UK. Lecturer Notes in Computer Science,</booktitle>
<pages>4161--298</pages>
<publisher>Springer</publisher>
<location>Heidelberg,</location>
<marker>Theune, Nijholt, Oinonen, Uijlings, 2006</marker>
<rawString>Theune, M., Nijholt, A., Oinonen, K., and Uijlings J. 2006. Designing a Story Database for Use in Automatic Story Generation. Proceedings 5th International Conference Entertainment Computing, Cambridge, UK. Lecturer Notes in Computer Science, 4161:298-301, Heidelberg, Springer Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R R Uijlings</author>
</authors>
<title>Designing a Virtual Environment for Story Generation. MS Thesis,</title>
<date>2006</date>
<institution>University of Amsterdam, The Netherlands.</institution>
<contexts>
<context position="10025" citStr="Uijlings (2006)" startWordPosition="1577" endWordPosition="1578">the story. Each subplot contains at least two author goals representing the goal of the scene and the corresponding consequence of the goal. An author goal is translated into one or more character goals, each representing an action performed by the character (main, secondary, or adult character) in order to achieve the author goal. A character goal translates directly to one declarative sentence in the generated story. Table 2 shows the author goals and the character goals for some of the sentences in the story in Table 1. The design of the character goal is based from the action operators of Uijlings (2006) which is easily transformed to a declarative sentence in active voice using the surface realizer simpleNLG (Venour and Reiter, 2008). In the case of Picture Books, however, the approach resulted in a story where every sentence describes an action or a feeling (i.e., scared, guilty, upset) that is performed by the character, as seen in Table 1. Subplot #1 Author goal 1.1: Goal of the scene Child is doing an activity Character goal &lt;character&gt; plays &lt;object&gt; Resulting text Rizzy the rabbit played near a lamp. Author goal 1.2: Goal consequence Child caused a problem Character goal &lt;character&gt; de</context>
</contexts>
<marker>Uijlings, 2006</marker>
<rawString>Uijlings, J.R.R. 2006. Designing a Virtual Environment for Story Generation. MS Thesis, University of Amsterdam, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Venour</author>
<author>E Reiter</author>
</authors>
<title>A Tutorial for Simplenlg. http://www.csd.abdn.ac.uk/~ereiter/simplenlg WordNet.</title>
<date>2008</date>
<publisher>Princeton University,</publisher>
<location>New Jersey.</location>
<contexts>
<context position="10158" citStr="Venour and Reiter, 2008" startWordPosition="1596" endWordPosition="1599">nce of the goal. An author goal is translated into one or more character goals, each representing an action performed by the character (main, secondary, or adult character) in order to achieve the author goal. A character goal translates directly to one declarative sentence in the generated story. Table 2 shows the author goals and the character goals for some of the sentences in the story in Table 1. The design of the character goal is based from the action operators of Uijlings (2006) which is easily transformed to a declarative sentence in active voice using the surface realizer simpleNLG (Venour and Reiter, 2008). In the case of Picture Books, however, the approach resulted in a story where every sentence describes an action or a feeling (i.e., scared, guilty, upset) that is performed by the character, as seen in Table 1. Subplot #1 Author goal 1.1: Goal of the scene Child is doing an activity Character goal &lt;character&gt; plays &lt;object&gt; Resulting text Rizzy the rabbit played near a lamp. Author goal 1.2: Goal consequence Child caused a problem Character goal &lt;character&gt; destroys &lt;object&gt; Resulting text Rizzy broke the lamp. Subplot #2 Author goal 2.1: Goal of the scene Child lied Character goal &lt;main ch</context>
</contexts>
<marker>Venour, Reiter, 2008</marker>
<rawString>Venour, C. and Reiter, E. 2008. A Tutorial for Simplenlg. http://www.csd.abdn.ac.uk/~ereiter/simplenlg WordNet. 2006. WordNet: A Lexical Database for the English Language. Princeton University, New Jersey.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>