<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.046703">
<title confidence="0.988046">
Citius: A Naive-Bayes Strategy for Sentiment Analysis on English Tweets∗
</title>
<author confidence="0.870414">
Pablo Gamallo Marcos Garcia
</author>
<affiliation confidence="0.527173">
CITIUS Cilenis Language Technology, S.L.
Univ. de Santiago de Compostela marcos.garcia@cilenis.com
</affiliation>
<email confidence="0.954539">
pablo.gamallo@usc.es
</email>
<sectionHeader confidence="0.992895" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999916230769231">
This article describes a strategy based on a
naive-bayes classifier for detecting the po-
larity of English tweets. The experiments
have shown that the best performance is
achieved by using a binary classifier be-
tween just two sharp polarity categories:
positive and negative. In addition, in or-
der to detect tweets with and without po-
larity, the system makes use of a very basic
rule that searchs for polarity words within
the analysed tweets/texts. When the clas-
sifier is provided with a polarity lexicon
and multiwords it achieves 63% F-score.
</bodyText>
<sectionHeader confidence="0.998814" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998433055555556">
Sentiment Analysis consists in finding the opin-
ion (e.g. positive, negative, or neutral) from text
documents such as movie reviews or product re-
views. Opinions about movies, products, etc. can
be found in web blogs, social networks, discus-
sion forums, and so on. Companies can improve
their products and services on the basis of the re-
views and comments of their costumers. Recently,
many works have stressed the microblogging ser-
vice Twitter. As Twitter can be seen as a large
source of short texts (tweets) containing user opin-
ions, most of these works make sentiment analysis
by identifying user attitudes and opinions toward
a particular topic or product (Go et al., 2009). The
task of making sentiment analysis from tweets is a
hard challenge. On the one hand, as in any senti-
ment analysis framework, we have to deal with hu-
man subjectivity. Even humans often disagree on
</bodyText>
<footnote confidence="0.811363875">
∗This work has been supported by the projects: HPC-
PLN: Ref:EM13/041 (Program Emergentes, Xunta de Gali-
cia), Celtic: Ref:2012-CE138 and Plastic: Ref:2013-CE298
(Program Feder-Innterconecta)
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
</footnote>
<bodyText confidence="0.9998404">
the categorization of the positive or negative sen-
timent that is supposed to be expressed on a given
text (Villena-Rom´an et al., 2013). On the other
hand, tweets are too short text to be linguistically
analyzed, and it makes the task of finding relevant
information (e.g. opinions) much harder.
The SemEval-2014 task “Sentiment Analysis
in Twitter” is an evaluation competition that in-
cludes a specific task directly related to sentiment
analyisis. In particular, subtask B, called “Mes-
sage Polarity Classification”, consists in classify-
ing whether a given message is of positive, neg-
ative, or neutral sentiment. For messages con-
veying both a positive and negative sentiment, the
stronger sentiment should be chosen. The results
of our system in this task are situated in the aver-
age out of 51 evaluated systems.
In this article, we describe the learning strate-
gies we developed so as to perform this task, all of
them based on bayesian classification.
</bodyText>
<sectionHeader confidence="0.97045" genericHeader="method">
2 Naive Bayes Classifier
</sectionHeader>
<bodyText confidence="0.992674578947368">
Most of the algorithms for sentiment analysis
are based on a classifier trained using a collec-
tion of annotated text data. Before training, data
is preprocessed so as to extract the main fea-
tures. Some classification methods have been pro-
posed: Naive Bayes, Support Vector Machines, K-
Nearest Neighbors, etc. However, and according
to (Go et al., 2009), it is not clear which of these
classification strategies is the more appropriate to
perform sentiment analysis.
We decided to use a classification strategy based
on Naive Bayes (NB) because it is a simple and
intuitive method whose performance is similar to
other approaches. NB combines efficiency (opti-
mal time performance) with reasonable accuracy.
The main theoretical drawback of NB methods is
that it assumes conditional independence among
the linguistic features. If the main features are the
tokens extracted from texts, it is evident that they
</bodyText>
<page confidence="0.975565">
171
</page>
<note confidence="0.730515">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 171–175,
Dublin, Ireland, August 23-24, 2014.
</note>
<bodyText confidence="0.9993155">
cannot be considered as independent, since words
co-occuring in a text are somehow linked by dif-
ferent types of syntactic and semantic dependen-
cies. However, even if NB produces an oversim-
plified model, its classification decisions are sur-
prinsingly accurate (Manning et al., 2008).
</bodyText>
<subsectionHeader confidence="0.976593">
2.1 Strategy
</subsectionHeader>
<bodyText confidence="0.999967777777778">
Two different naive bayes classifiers have been
built, according to two different strategies:
Baseline This is a naive bayes classifier that
learns from the original training corpus how
to classify the three categories found in the
corpus: Positive, Negative, and Neutral. So,
no modification has been introduced in the
training corpus.
Binary The second classifier was trained on a
simplified training corpus and makes use of
a polarity lexicon. The corpus was simpli-
fied since only positive and negative tweets
were considered. Neutral tweets were not
taken into account. As a result, a basic bi-
nary (or boolean) classifier which only iden-
tifies both Positive and Negative tweets was
trained. In order to detect tweets without po-
larity (or Neutral), the following basic rule is
used: if the tweet contains at least one word
that is also found in the polarity lexicon, then
the tweet has some degree of polarity. Othe-
wise, the tweet has no polarity at all and is
classified as Neutral. The binary classifier
is actually suited to specify the basic polar-
ity between positive and negative, reaching a
precision of more than 80% in a corpus with
just these two categories.
</bodyText>
<sectionHeader confidence="0.987444" genericHeader="method">
3 Preprocessing
</sectionHeader>
<bodyText confidence="0.978206875">
As we will describe in the next section, the main
features of the model are lemmas extracted using
lemmatization. Given that the language of mi-
croblogging requires a special treatment, we pro-
pose a pre-processing task to correct and normal-
ize the tweets before lemmatizing them.
The main preprocessing tasks we considered are
the following:
</bodyText>
<listItem confidence="0.999496285714286">
• removing urls, references to usernames, and
hashtags
• reduction of replicated characters (e.g.
looooveeee → love)
• identifying emoticons and interjections and
replacing them with polarity or sentiment ex-
pressions (e.g.:-) → good)
</listItem>
<sectionHeader confidence="0.992138" genericHeader="method">
4 Features
</sectionHeader>
<bodyText confidence="0.999923666666667">
The features considered by the classifier are lem-
mas, multiwords, polarity lexicons, and valence
shifters.
</bodyText>
<subsectionHeader confidence="0.996481">
4.1 Lemmas (UL)
</subsectionHeader>
<bodyText confidence="0.999978636363636">
To characterise the main features underlying the
classifier, we make use of unigrams of lemmas in-
stead of tokens to minimize the problems derived
from the sparse distribution of words. Moreover,
only lemmas belonging to lexical categories are
selected as features, namely nouns, verbs, adjec-
tives, and adverbs. So, grammatical words, such
as determiners, conjunctions, and prepositions are
removed from the model.
To configure the feature representation, the fre-
quency of each selected lemma in a tweet is stored.
</bodyText>
<subsectionHeader confidence="0.989138">
4.2 Multiwords (MW)
</subsectionHeader>
<bodyText confidence="0.9996975625">
There is no agreement on which is the best option
for sentiment analysis (unigrams, bigrams, ...). In
(Pak and Paroubek, 2010), the best performance
is achieved with bigrams, while (Go et al., 2009)
show that the better results are reached with uni-
grams. An alternative option is to make use of a
selected set of n-grams (or multiwords) identified
by means of regular patterns of PoS tags. Multi-
word expressions identified by means of PoS tags
patterns can be conceived as linguistically moti-
vated terms, since most of them are pairs of words
linked by syntactic dependencies.
So, in addition to unigrams of lemmas, we also
consider multiwords extracted by an algorithm
based on patterns of PoS tags. In particular, we
used the following set of patterns:
</bodyText>
<listItem confidence="0.999929333333333">
• NOUN-ADJ
• NOUN-NOUN
• ADJ-NOUN
• NOUN-PRP-NOUN
• VERB-NOUN
• VERB-PRP-NOUN
</listItem>
<bodyText confidence="0.9834055">
The instances of bigrams and trigrams extracted
with these patterns ared added to the unigrams
</bodyText>
<page confidence="0.990918">
172
</page>
<bodyText confidence="0.999727">
to build the language model. Multiword extrac-
tion was performed using our tool GaleXtra1, re-
leased under GPL license and described in (Mario
Barcala and Eva Dominguez and Pablo Gamallo
and Marisol L´opez and Eduardo Moscoso and
Guillermo Rojo and Paula Santalla and Susana
Sotelo, 2007).
</bodyText>
<subsectionHeader confidence="0.997653">
4.3 Polarity Lexicon (LEX)
</subsectionHeader>
<bodyText confidence="0.998415">
We have built a polarity lexicon with both Positive
and Negative entries from different sources:
</bodyText>
<listItem confidence="0.9816825">
• AFINN-1112 contains 2, 477 word forms,
which were lemmatized and converted into
1, 520, positive and negative lemmas.
• Hedonometer3 contains about 10, 000 fre-
quent words extracted from tweets which
were classified as expressing some degree of
hapiness (Dodds et al., 2011). We selected
the 300 most positive lemmas from the initial
list.
• Hu&amp;Liu list (Liu et al., 2005) contains over
6, 800 words out of which 5 positive and neg-
ative lemmas were selected 5,695.
• Sentiwordnet-3.0 (Baccianella et al., 2010)
contains more than 100, 000 entries. We se-
lected a subset of 6, 600 positive and negative
lemmas with the highest polarity values.
• Finally, we have built a polarity lexicon with
10, 850 entries by merging the previous ones.
</listItem>
<bodyText confidence="0.998379384615385">
The final polarity lexicon is used in two differ-
ent ways: on the one hand, it is used to identify
neutral tweets, since a tweet is considered as being
neutral if it does not contain any lemma appearing
in the polarity lexicon. On the other hand, we have
built artificial tweets as follows: each entry of the
lexicon is converted into an artificial tweet with
just one lemma inheriting the polarity (positive or
negative) from the lexicon. The frequency of the
word in each new tweet is the average frequency
of lemmas in the training corpus. These artificial
tweets will be taken into account for training the
classifiers.
</bodyText>
<footnote confidence="0.99989575">
1http://gramatica.usc.es/\˜gamallo/
gale-extra/index.htm
2http://arxiv.org/abs/1103.2903
3http://www.hedonometer.org/
</footnote>
<subsectionHeader confidence="0.986728">
4.4 Valence Shifters (VS)
</subsectionHeader>
<bodyText confidence="0.999983">
We take into account negative words that can shift
the polarity of specific lemmas in a tweet. In
the presented work, we will make use of only
those valence shifters that reverse the sentiment of
words, namely negations. The strategy to identify
the scope of negations relies on the PoS tags of the
negative word as well as of those words appearing
to its right in the sequence. The algorithm is as
follows:
Whenever a negative word is found, its PoS tag
is considered and, according to its syntactic prop-
erties, we search for a polarity word (noun, verb,
or adjective) within a window of 2 words after the
negation. If a polarity word is found and is syntac-
tically linked to the negative word, then its polarity
is reversed. For instance, if the negation word is
the adverb “not”, the system only reverses the po-
larity of verbs or adjectives appearing to its right.
Nouns are not syntactically linked to this adverb.
By contrast, if the negation is the determiner “no”
or “none”, only the polarity of nouns can be re-
versed. Our strategy to deal with negation scope
is not so basic as those described in (Yang, 2008)
and (Anta et al., 2013), which are just based on
a rigid window after the negation word: 1 and 3
words, respectively.
</bodyText>
<sectionHeader confidence="0.996576" genericHeader="evaluation">
5 Experiments and Evaluation
</sectionHeader>
<subsectionHeader confidence="0.983292">
5.1 Training corpus
</subsectionHeader>
<bodyText confidence="0.999990176470588">
In our preliminary experiments we have used the
training dataset of tweets provided by SemEval-
2014 organization (tweeti-b.dist.tsv). This set
contains 6,408 tweets, which were tagged with
the following polarity values: Positive, Nega-
tive, Neutral, Objective, and Neutral-or-Objective.
In order to fill the requirements of the task, we
transformed Neutral, Objective, and Natural-or-
Objective into a single tag: Neutral. In addi-
tion, we also used a selection of annotated tweets
(namely 5, 050 positive and negative ones), which
were compiled from an external source (Narr et al.,
2012). Using the terminology provided by the or-
ganizers of SemEval-2014, we call “constrained”
the systems trained with only the dataset provided
by the organization and “unconstrained” the sys-
tems trained with both datasets.
</bodyText>
<subsectionHeader confidence="0.993484">
5.2 Evaluated classifiers
</subsectionHeader>
<bodyText confidence="0.998913">
We have implemented and evaluated several clas-
sifiers by making use of the two strategies de-
</bodyText>
<page confidence="0.997711">
173
</page>
<bodyText confidence="0.996652428571428">
scribed in section 2, combined with the features
defined in 4. We also distinguished those clas-
sifiers trained with only tweeti-b.dist.tsv (con-
strained systems) from those trained with both in-
ternal and external datasets (unconstrained). As a
result, we implemented the following classifiers:
CONSTRAINED-BASELINE: This system
was implemented on the basis of the “Base-
line” strategy and the following two features:
unigrams of lemmas (UL) and valence
shifters (VS).
CONSTRAINED-BASELINE-LEX: This sys-
tem was implemented on the basis of the
“Baseline” strategy and the following three
features: unigrams of lemmas (UL), polarity
lexicon (LEX), and valence shifters (VS).
CONSTRAINED-BINARY-LEX: This system
was implemented on the basis of the “Base-
line” strategy and the following three fea-
tures: unigrams of lemmas (UL), polarity
lexicon (LEX), and valence shifters (VS).
CONSTRAINED-BINARY-LEX-MW: This
system was implemented on the basis of the
“Binary” strategy and the following features:
unigrams of lemmas (UL), multiwords
(MW), polarity lexicon (LEX), and valence
shifters (VS).
UNCONSTRAINED-BINARY-LEX: This sys-
tem was implemented on the basis of the
“Binary” strategy and the following features:
unigrams of lemmas (UL), polarity lexicon
(LEX), and valence shifters (VS).
UNCONSTRAINED-BINARY-LEX-MW:
This system was implemented on the basis of
the “Binary” strategy and the following fea-
tures: unigrams of lemmas (UL), multiwords
(MW), polarity lexicon (LEX), and valence
shifters (VS).
All the classifers have been implemented with
Perl language. They rely on the naive-bayes algo-
rithm and incorporate the preprocessing tasks de-
fined in section 3.
</bodyText>
<subsectionHeader confidence="0.990654">
5.3 Evaluation
</subsectionHeader>
<bodyText confidence="0.999441166666667">
To evaluate the classification performance of these
classifiers, we used as test corpus another dataset
provided by the organization: tweeti-b.devel.tsv.
The results are shown in table 1, where the names
of the evaluated systems are in the first column and
F-Score in the second one.
</bodyText>
<table confidence="0.997486285714286">
System F-score
CONSTR-BASE .49
CONSTR-BASE-LEX .56
CONSTR-BIN-LEX .57
CONSTR-BIN-LEX-MW .61
UNCONSTR-BIN-LEX .58
UNCONSTR-BIN-LEX-MW .63
</table>
<tableCaption confidence="0.999935">
Table 1: Results of our six systems
</tableCaption>
<bodyText confidence="0.999984315789474">
The results show that there is an improve-
ment in performance when the classifiers are im-
plemented with the Binary strategy, when they
use a polarity lexicon, and when multiwords are
considered as features. The two systems sub-
mmited to Semeval competition were those ob-
tained the best scores: CONSTR-BIN-LEX-MW
and UNCONSTR-BIN-LEX-MW. The scores ob-
tained by these two systems in the competition
are very similar to those obtained in the experi-
ments depicted in Table 1. More precisely, in the
Tweets2014 test corpus, the constrained system
reached 0.62 F-score while the unconstrained ver-
sion achieved 0.63. Our best system was ranked
as 26th from 53 systems. A Spanish version of
this system (Gamallo et al., 2013) also participated
in the TASS-2013 competition (Villena-Rom´an et
al., 2013), where it was ranked as the 3th best sys-
tem out of 13 participants.
</bodyText>
<sectionHeader confidence="0.999625" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999912777777778">
We have presented a family of naive-bayes classi-
fiers for detecting the polarity of English tweets.
The experiments have shown that the best per-
formance is achieved by using a binary classi-
fier trained to detect just two categories: posi-
tive and negative. In order to detect tweets with
and without polarity we used a very basic strat-
egy based on searching for polarity lemmas within
the text/tweet. If the tweet does not contain at
least one lemma also found in an external polarity
lexicon, then the tweet has not any polarity and,
thereby, is tagged with the Neutral value. The use
of both a polarity lexicon and multiwords also im-
proves the results in a significant way. Our sys-
tem is being used by Cilenis S.L, a company spe-
cialised in natural language technology, and being
applied to four languages: English, Spanish, Por-
tuguese, and Galician.
</bodyText>
<page confidence="0.992888">
174
</page>
<note confidence="0.9844615">
Kiduk Yang. 2008. WIDIT in TREC 2008 blog
track: Leveraging Multiple Sources of Opinion Ev-
idence. In The Seventeenth Text Retrieval Confer-
ence (TREC-2008), Gaithersburg, Maryland, USA.
References
Antonio Fern´andez Anta, Luis N´u˜nez Chiroque,
Philippe Morere, and Agustin Santos. 2013. Sen-
timent Analysis and Topic Detection of Spanish
Tweets: A Comparative Study of NLP Techniques.
Procesamiento del Lenguaje Natural, 50:45–52.
</note>
<reference confidence="0.999643375">
Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani. 2010. SentiWordNet 3.0: An Enhanced Lex-
ical Resource for Sentiment Analysis and Opinion
Mining. In Human Language Technology Confer-
ence - North American chapter of the Association
for Computational Linguistics, pages 2200–2204.
Peter Sheridan Dodds, Kameron Decker Harris, Is-
abel M. Kloumann, Catherine A. Bliss, and Christo-
pher M. Danforth. 2011. Temporal patterns of
happiness and information in a global social net-
work: Hedonometrics and Twitter. PLoS ONE,
6(12):e26752.
Pablo Gamallo, Marcos Garcia, and Santiago
Fern´andez-Lanza. 2013. TASS: A Naive-Bayes
strategy for sentiment analysis on Spanish tweets.
In Workshop on Sentiment Analysis at SEPLN
(TASS2013), pages 126–132, Madrid, Spain.
Alec Go, Richa Bhayani, and Lei Huang. 2009. Twit-
ter sentiment classification using distant supervision.
In CS224N Technical report. Standford.
Bing Liu, Minqing Hu, and Junsheng Cheng. 2005.
Opinion observer: Analyzing and comparing opin-
ions on the web. In 14th International World Wide
Web conference (WWW-2005), pages 342–351, New
York, NY, USA.
Chris Manning, Prabhakar Raghadvan, and Hinrich
Sch¨utze. 2008. Introduction to Information Re-
trieval. Cambridge University Press, Cambridge,
MA, USA.
Mario Barcala and Eva Dominguez and Pablo Gamallo
and Marisol L´opez and Eduardo Moscoso and
Guillermo Rojo and Paula Santalla and Susana
Sotelo. 2007. A Corpus and Lexical Resources for
Multi-word Terminology Extraction in the Field of
Economy. In 3rd Language &amp; Technology Confer-
ence (LeTC’2007), pages 355–359, Poznan, Poland.
Sascha Narr, Michael Hulfenhaus, and Sahin Albayrak.
2012. Language-Independent Twitter Sentiment
Analysis. In Knowledge Discovery and Machine
Learning (KDML), LWA, pages 12–14, Dortmund,
Germany.
Alexander Pak and Patrick Paroubek. 2010. Twitter as
a Corpus for Sentiment Analysis and Opinion Min-
ing. In LREC-2010, Valletta, Malta.
Julio Villena-Rom´an, Sara Lana, Eugeinio Martinez-
C´amara, and Juan Carlos Gonz´alez-Crist´obal. 2013.
TASS - Workshop on Sentiment Analysis at SEPLN.
Procesamiento del Lenguaje Natural, 50:37–44.
</reference>
<page confidence="0.998718">
175
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.534976">
<title confidence="0.999654">A Naive-Bayes Strategy for Sentiment Analysis on English</title>
<author confidence="0.999944">Pablo Gamallo Marcos Garcia</author>
<affiliation confidence="0.979205">CITIUS Cilenis Language Technology, S.L. de Santiago de Compostela</affiliation>
<email confidence="0.971515">pablo.gamallo@usc.es</email>
<abstract confidence="0.969323285714286">This article describes a strategy based on a naive-bayes classifier for detecting the polarity of English tweets. The experiments have shown that the best performance is achieved by using a binary classifier between just two sharp polarity categories: positive and negative. In addition, in order to detect tweets with and without polarity, the system makes use of a very basic rule that searchs for polarity words within the analysed tweets/texts. When the classifier is provided with a polarity lexicon multiwords it achieves</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Stefano Baccianella</author>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>SentiWordNet 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining.</title>
<date>2010</date>
<booktitle>In Human Language Technology Conference - North American chapter of the Association for Computational Linguistics,</booktitle>
<pages>2200--2204</pages>
<contexts>
<context position="8675" citStr="Baccianella et al., 2010" startWordPosition="1375" endWordPosition="1378">ty Lexicon (LEX) We have built a polarity lexicon with both Positive and Negative entries from different sources: • AFINN-1112 contains 2, 477 word forms, which were lemmatized and converted into 1, 520, positive and negative lemmas. • Hedonometer3 contains about 10, 000 frequent words extracted from tweets which were classified as expressing some degree of hapiness (Dodds et al., 2011). We selected the 300 most positive lemmas from the initial list. • Hu&amp;Liu list (Liu et al., 2005) contains over 6, 800 words out of which 5 positive and negative lemmas were selected 5,695. • Sentiwordnet-3.0 (Baccianella et al., 2010) contains more than 100, 000 entries. We selected a subset of 6, 600 positive and negative lemmas with the highest polarity values. • Finally, we have built a polarity lexicon with 10, 850 entries by merging the previous ones. The final polarity lexicon is used in two different ways: on the one hand, it is used to identify neutral tweets, since a tweet is considered as being neutral if it does not contain any lemma appearing in the polarity lexicon. On the other hand, we have built artificial tweets as follows: each entry of the lexicon is converted into an artificial tweet with just one lemma</context>
</contexts>
<marker>Baccianella, Esuli, Sebastiani, 2010</marker>
<rawString>Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2010. SentiWordNet 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining. In Human Language Technology Conference - North American chapter of the Association for Computational Linguistics, pages 2200–2204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Sheridan Dodds</author>
<author>Kameron Decker Harris</author>
<author>Isabel M Kloumann</author>
<author>Catherine A Bliss</author>
<author>Christopher M Danforth</author>
</authors>
<title>Temporal patterns of happiness and information in a global social network: Hedonometrics and Twitter.</title>
<date>2011</date>
<tech>PLoS ONE, 6(12):e26752.</tech>
<contexts>
<context position="8439" citStr="Dodds et al., 2011" startWordPosition="1334" endWordPosition="1337">g our tool GaleXtra1, released under GPL license and described in (Mario Barcala and Eva Dominguez and Pablo Gamallo and Marisol L´opez and Eduardo Moscoso and Guillermo Rojo and Paula Santalla and Susana Sotelo, 2007). 4.3 Polarity Lexicon (LEX) We have built a polarity lexicon with both Positive and Negative entries from different sources: • AFINN-1112 contains 2, 477 word forms, which were lemmatized and converted into 1, 520, positive and negative lemmas. • Hedonometer3 contains about 10, 000 frequent words extracted from tweets which were classified as expressing some degree of hapiness (Dodds et al., 2011). We selected the 300 most positive lemmas from the initial list. • Hu&amp;Liu list (Liu et al., 2005) contains over 6, 800 words out of which 5 positive and negative lemmas were selected 5,695. • Sentiwordnet-3.0 (Baccianella et al., 2010) contains more than 100, 000 entries. We selected a subset of 6, 600 positive and negative lemmas with the highest polarity values. • Finally, we have built a polarity lexicon with 10, 850 entries by merging the previous ones. The final polarity lexicon is used in two different ways: on the one hand, it is used to identify neutral tweets, since a tweet is consid</context>
</contexts>
<marker>Dodds, Harris, Kloumann, Bliss, Danforth, 2011</marker>
<rawString>Peter Sheridan Dodds, Kameron Decker Harris, Isabel M. Kloumann, Catherine A. Bliss, and Christopher M. Danforth. 2011. Temporal patterns of happiness and information in a global social network: Hedonometrics and Twitter. PLoS ONE, 6(12):e26752.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pablo Gamallo</author>
<author>Marcos Garcia</author>
<author>Santiago Fern´andez-Lanza</author>
</authors>
<title>TASS: A Naive-Bayes strategy for sentiment analysis on Spanish tweets.</title>
<date>2013</date>
<booktitle>In Workshop on Sentiment Analysis at SEPLN (TASS2013),</booktitle>
<pages>126--132</pages>
<location>Madrid,</location>
<marker>Gamallo, Garcia, Fern´andez-Lanza, 2013</marker>
<rawString>Pablo Gamallo, Marcos Garcia, and Santiago Fern´andez-Lanza. 2013. TASS: A Naive-Bayes strategy for sentiment analysis on Spanish tweets. In Workshop on Sentiment Analysis at SEPLN (TASS2013), pages 126–132, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alec Go</author>
<author>Richa Bhayani</author>
<author>Lei Huang</author>
</authors>
<title>Twitter sentiment classification using distant supervision.</title>
<date>2009</date>
<booktitle>In CS224N Technical report.</booktitle>
<publisher>Standford.</publisher>
<contexts>
<context position="1466" citStr="Go et al., 2009" startWordPosition="227" endWordPosition="230">itive, negative, or neutral) from text documents such as movie reviews or product reviews. Opinions about movies, products, etc. can be found in web blogs, social networks, discussion forums, and so on. Companies can improve their products and services on the basis of the reviews and comments of their costumers. Recently, many works have stressed the microblogging service Twitter. As Twitter can be seen as a large source of short texts (tweets) containing user opinions, most of these works make sentiment analysis by identifying user attitudes and opinions toward a particular topic or product (Go et al., 2009). The task of making sentiment analysis from tweets is a hard challenge. On the one hand, as in any sentiment analysis framework, we have to deal with human subjectivity. Even humans often disagree on ∗This work has been supported by the projects: HPCPLN: Ref:EM13/041 (Program Emergentes, Xunta de Galicia), Celtic: Ref:2012-CE138 and Plastic: Ref:2013-CE298 (Program Feder-Innterconecta) This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0</context>
<context position="3398" citStr="Go et al., 2009" startWordPosition="531" endWordPosition="534">en. The results of our system in this task are situated in the average out of 51 evaluated systems. In this article, we describe the learning strategies we developed so as to perform this task, all of them based on bayesian classification. 2 Naive Bayes Classifier Most of the algorithms for sentiment analysis are based on a classifier trained using a collection of annotated text data. Before training, data is preprocessed so as to extract the main features. Some classification methods have been proposed: Naive Bayes, Support Vector Machines, KNearest Neighbors, etc. However, and according to (Go et al., 2009), it is not clear which of these classification strategies is the more appropriate to perform sentiment analysis. We decided to use a classification strategy based on Naive Bayes (NB) because it is a simple and intuitive method whose performance is similar to other approaches. NB combines efficiency (optimal time performance) with reasonable accuracy. The main theoretical drawback of NB methods is that it assumes conditional independence among the linguistic features. If the main features are the tokens extracted from texts, it is evident that they 171 Proceedings of the 8th International Work</context>
<context position="7018" citStr="Go et al., 2009" startWordPosition="1103" endWordPosition="1106">minimize the problems derived from the sparse distribution of words. Moreover, only lemmas belonging to lexical categories are selected as features, namely nouns, verbs, adjectives, and adverbs. So, grammatical words, such as determiners, conjunctions, and prepositions are removed from the model. To configure the feature representation, the frequency of each selected lemma in a tweet is stored. 4.2 Multiwords (MW) There is no agreement on which is the best option for sentiment analysis (unigrams, bigrams, ...). In (Pak and Paroubek, 2010), the best performance is achieved with bigrams, while (Go et al., 2009) show that the better results are reached with unigrams. An alternative option is to make use of a selected set of n-grams (or multiwords) identified by means of regular patterns of PoS tags. Multiword expressions identified by means of PoS tags patterns can be conceived as linguistically motivated terms, since most of them are pairs of words linked by syntactic dependencies. So, in addition to unigrams of lemmas, we also consider multiwords extracted by an algorithm based on patterns of PoS tags. In particular, we used the following set of patterns: • NOUN-ADJ • NOUN-NOUN • ADJ-NOUN • NOUN-PR</context>
</contexts>
<marker>Go, Bhayani, Huang, 2009</marker>
<rawString>Alec Go, Richa Bhayani, and Lei Huang. 2009. Twitter sentiment classification using distant supervision. In CS224N Technical report. Standford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
<author>Minqing Hu</author>
<author>Junsheng Cheng</author>
</authors>
<title>Opinion observer: Analyzing and comparing opinions on the web.</title>
<date>2005</date>
<booktitle>In 14th International World Wide Web conference (WWW-2005),</booktitle>
<pages>342--351</pages>
<location>New York, NY, USA.</location>
<contexts>
<context position="8537" citStr="Liu et al., 2005" startWordPosition="1352" endWordPosition="1355">nd Pablo Gamallo and Marisol L´opez and Eduardo Moscoso and Guillermo Rojo and Paula Santalla and Susana Sotelo, 2007). 4.3 Polarity Lexicon (LEX) We have built a polarity lexicon with both Positive and Negative entries from different sources: • AFINN-1112 contains 2, 477 word forms, which were lemmatized and converted into 1, 520, positive and negative lemmas. • Hedonometer3 contains about 10, 000 frequent words extracted from tweets which were classified as expressing some degree of hapiness (Dodds et al., 2011). We selected the 300 most positive lemmas from the initial list. • Hu&amp;Liu list (Liu et al., 2005) contains over 6, 800 words out of which 5 positive and negative lemmas were selected 5,695. • Sentiwordnet-3.0 (Baccianella et al., 2010) contains more than 100, 000 entries. We selected a subset of 6, 600 positive and negative lemmas with the highest polarity values. • Finally, we have built a polarity lexicon with 10, 850 entries by merging the previous ones. The final polarity lexicon is used in two different ways: on the one hand, it is used to identify neutral tweets, since a tweet is considered as being neutral if it does not contain any lemma appearing in the polarity lexicon. On the o</context>
</contexts>
<marker>Liu, Hu, Cheng, 2005</marker>
<rawString>Bing Liu, Minqing Hu, and Junsheng Cheng. 2005. Opinion observer: Analyzing and comparing opinions on the web. In 14th International World Wide Web conference (WWW-2005), pages 342–351, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Manning</author>
<author>Prabhakar Raghadvan</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Introduction to Information Retrieval.</title>
<date>2008</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, MA, USA.</location>
<marker>Manning, Raghadvan, Sch¨utze, 2008</marker>
<rawString>Chris Manning, Prabhakar Raghadvan, and Hinrich Sch¨utze. 2008. Introduction to Information Retrieval. Cambridge University Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mario Barcala</author>
<author>Eva Dominguez</author>
<author>Pablo Gamallo</author>
<author>Marisol L´opez</author>
<author>Eduardo Moscoso</author>
<author>Guillermo Rojo</author>
<author>Paula Santalla</author>
<author>Susana Sotelo</author>
</authors>
<title>A Corpus and Lexical Resources for Multi-word Terminology Extraction in the Field of Economy.</title>
<date>2007</date>
<booktitle>In 3rd Language &amp; Technology Conference (LeTC’2007),</booktitle>
<pages>355--359</pages>
<location>Poznan,</location>
<marker>Barcala, Dominguez, Gamallo, L´opez, Moscoso, Rojo, Santalla, Sotelo, 2007</marker>
<rawString>Mario Barcala and Eva Dominguez and Pablo Gamallo and Marisol L´opez and Eduardo Moscoso and Guillermo Rojo and Paula Santalla and Susana Sotelo. 2007. A Corpus and Lexical Resources for Multi-word Terminology Extraction in the Field of Economy. In 3rd Language &amp; Technology Conference (LeTC’2007), pages 355–359, Poznan, Poland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sascha Narr</author>
<author>Michael Hulfenhaus</author>
<author>Sahin Albayrak</author>
</authors>
<title>Language-Independent Twitter Sentiment Analysis.</title>
<date>2012</date>
<booktitle>In Knowledge Discovery and Machine Learning (KDML), LWA,</booktitle>
<pages>12--14</pages>
<location>Dortmund, Germany.</location>
<contexts>
<context position="11537" citStr="Narr et al., 2012" startWordPosition="1848" endWordPosition="1851">nd Evaluation 5.1 Training corpus In our preliminary experiments we have used the training dataset of tweets provided by SemEval2014 organization (tweeti-b.dist.tsv). This set contains 6,408 tweets, which were tagged with the following polarity values: Positive, Negative, Neutral, Objective, and Neutral-or-Objective. In order to fill the requirements of the task, we transformed Neutral, Objective, and Natural-orObjective into a single tag: Neutral. In addition, we also used a selection of annotated tweets (namely 5, 050 positive and negative ones), which were compiled from an external source (Narr et al., 2012). Using the terminology provided by the organizers of SemEval-2014, we call “constrained” the systems trained with only the dataset provided by the organization and “unconstrained” the systems trained with both datasets. 5.2 Evaluated classifiers We have implemented and evaluated several classifiers by making use of the two strategies de173 scribed in section 2, combined with the features defined in 4. We also distinguished those classifiers trained with only tweeti-b.dist.tsv (constrained systems) from those trained with both internal and external datasets (unconstrained). As a result, we imp</context>
</contexts>
<marker>Narr, Hulfenhaus, Albayrak, 2012</marker>
<rawString>Sascha Narr, Michael Hulfenhaus, and Sahin Albayrak. 2012. Language-Independent Twitter Sentiment Analysis. In Knowledge Discovery and Machine Learning (KDML), LWA, pages 12–14, Dortmund, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Pak</author>
<author>Patrick Paroubek</author>
</authors>
<title>Twitter as a Corpus for Sentiment Analysis and Opinion Mining.</title>
<date>2010</date>
<booktitle>In LREC-2010,</booktitle>
<location>Valletta,</location>
<contexts>
<context position="6946" citStr="Pak and Paroubek, 2010" startWordPosition="1091" endWordPosition="1094">erlying the classifier, we make use of unigrams of lemmas instead of tokens to minimize the problems derived from the sparse distribution of words. Moreover, only lemmas belonging to lexical categories are selected as features, namely nouns, verbs, adjectives, and adverbs. So, grammatical words, such as determiners, conjunctions, and prepositions are removed from the model. To configure the feature representation, the frequency of each selected lemma in a tweet is stored. 4.2 Multiwords (MW) There is no agreement on which is the best option for sentiment analysis (unigrams, bigrams, ...). In (Pak and Paroubek, 2010), the best performance is achieved with bigrams, while (Go et al., 2009) show that the better results are reached with unigrams. An alternative option is to make use of a selected set of n-grams (or multiwords) identified by means of regular patterns of PoS tags. Multiword expressions identified by means of PoS tags patterns can be conceived as linguistically motivated terms, since most of them are pairs of words linked by syntactic dependencies. So, in addition to unigrams of lemmas, we also consider multiwords extracted by an algorithm based on patterns of PoS tags. In particular, we used th</context>
</contexts>
<marker>Pak, Paroubek, 2010</marker>
<rawString>Alexander Pak and Patrick Paroubek. 2010. Twitter as a Corpus for Sentiment Analysis and Opinion Mining. In LREC-2010, Valletta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julio Villena-Rom´an</author>
<author>Sara Lana</author>
<author>Eugeinio MartinezC´amara</author>
<author>Juan Carlos Gonz´alez-Crist´obal</author>
</authors>
<date>2013</date>
<booktitle>TASS - Workshop on Sentiment Analysis at SEPLN. Procesamiento del Lenguaje Natural,</booktitle>
<pages>50--37</pages>
<marker>Villena-Rom´an, Lana, MartinezC´amara, Gonz´alez-Crist´obal, 2013</marker>
<rawString>Julio Villena-Rom´an, Sara Lana, Eugeinio MartinezC´amara, and Juan Carlos Gonz´alez-Crist´obal. 2013. TASS - Workshop on Sentiment Analysis at SEPLN. Procesamiento del Lenguaje Natural, 50:37–44.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>