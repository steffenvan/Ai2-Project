<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000005">
<title confidence="0.997815">
A Unified Multilingual Semantic Representation of Concepts
</title>
<author confidence="0.998464">
Jos´e Camacho-Collados, Mohammad Taher Pilehvar and Roberto Navigli
</author>
<affiliation confidence="0.9988325">
Department of Computer Science
Sapienza University of Rome
</affiliation>
<email confidence="0.982145">
{collados,pilehvar,navigli}@di.uniroma1.it
</email>
<sectionHeader confidence="0.997121" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999612">
Semantic representation lies at the core of
several applications in Natural Language
Processing. However, most existing se-
mantic representation techniques cannot
be used effectively for the representation
of individual word senses. We put for-
ward a novel multilingual concept repre-
sentation, called MUFFIN, which not only
enables accurate representation of word
senses in different languages, but also pro-
vides multiple advantages over existing
approaches. MUFFIN represents a given
concept in a unified semantic space irre-
spective of the language of interest, en-
abling cross-lingual comparison of differ-
ent concepts. We evaluate our approach in
two different evaluation benchmarks, se-
mantic similarity and Word Sense Disam-
biguation, reporting state-of-the-art per-
formance on several standard datasets.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999942454545455">
Semantic representation, i.e., the task of represent-
ing a linguistic item (such as a word or a word
sense) in a mathematical or machine-interpretable
form, is a fundamental problem in Natural Lan-
guage Processing (NLP). The Vector Space Model
(VSM) is a prominent approach for semantic rep-
resentation, with widespread popularity in numer-
ous NLP applications. The prevailing methods
for the computation of a vector space represen-
tation are based on distributional semantics (Har-
ris, 1954). However, these approaches, whether
in their conventional co-occurrence based form
(Salton et al., 1975; Turney and Pantel, 2010; Lan-
dauer and Dooley, 2002), or in their newer predic-
tive branch (Collobert and Weston, 2008; Mikolov
et al., 2013; Baroni et al., 2014), suffer from a
major drawback: they are unable to model indi-
vidual word senses or concepts, as they conflate
different meanings of a word into a single vecto-
rial representation. This hinders the functionality
of this group of vector space models in tasks such
as Word Sense Disambiguation (WSD) that re-
quire the representation of individual word senses.
There have been several efforts to adapt and apply
distributional approaches to the representation of
word senses (Pantel and Lin, 2002; Brody and La-
pata, 2009; Reisinger and Mooney, 2010; Huang
et al., 2012). However, none of these techniques
provides representations that are already linked to
a standard sense inventory, and consequently such
mapping has to be carried out either manually,
or with the help of sense-annotated data. Chen
et al. (2014) addressed this issue and obtained
vectors for individual word senses by leveraging
WordNet glosses. NASARI (Camacho-Collados
et al., 2015) is another approach that obtains ac-
curate sense-specific representations by combin-
ing the complementary knowledge from Word-
Net and Wikipedia. Graph-based approaches have
also been successfully utilized to model individ-
ual words (Hughes and Ramage, 2007; Agirre et
al., 2009; Yeh et al., 2009), or concepts (Pilehvar
et al., 2013; Pilehvar and Navigli, 2014), drawing
on the structural properties of semantic networks.
The applicability of all these techniques, however,
is usually either constrained to a single language
(usually English), or to a specific task.
We put forward MUFFIN (Multilingual, Uni-
Fied and Flexible INterpretation), a novel method
that exploits both structural knowledge derived
from semantic networks and distributional statis-
tics from text corpora, to produce effective rep-
resentations of individual word senses or con-
cepts. Our approach provides multiple advantages
in comparison to the previous VSM techniques:
</bodyText>
<listItem confidence="0.995675">
1. Multilingual: it enables sense representation
in dozens of languages;
2. Unified: it represents a linguistic item, irre-
spective of its language, in a unified seman-
</listItem>
<page confidence="0.96357">
741
</page>
<note confidence="0.98885">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 741–751,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999571">
Figure 1: Our procedure for constructing a multilingual vector representation for a concept c.
</figureCaption>
<bodyText confidence="0.9976695">
tic space having concepts as its dimensions,
permitting direct comparison of different rep-
resentations across languages, and hence en-
abling cross-lingual applications;
</bodyText>
<listItem confidence="0.5767905">
3. Flexible: it can be readily applied to different
NLP tasks with minimal adaptation.
</listItem>
<bodyText confidence="0.9998805">
We evaluate our semantic representation on two
different tasks in lexical semantics: semantic sim-
ilarity and Word Sense Disambiguation. To as-
sess the multilingual capability of our approach,
we also perform experiments on languages other
than English on both tasks, and across languages
for semantic similarity. We report state-of-the-art
performance on multiple datasets and settings in
both frameworks, which confirms the reliability
and flexibility of our representations.
</bodyText>
<sectionHeader confidence="0.998928" genericHeader="introduction">
2 Methodology
</sectionHeader>
<bodyText confidence="0.999657157894737">
Figure 1 illustrates our procedure for construct-
ing the vector representation of a given con-
cept. We use BabelNet1 (version 2.5) as our
main sense repository. BabelNet (Navigli and
Ponzetto, 2012a) is a multilingual encyclopedic
dictionary which merges WordNet with other lex-
ical resources, such as Wikipedia and Wiktionary,
thanks to its use of an automatic mapping al-
gorithm. BabelNet extends the WordNet synset
model to take into account multilinguality: a Ba-
belNet synset contains the words that, in the vari-
ous languages, express the given concept.
Our approach for modeling a BabelNet synset
consists of two main steps. First, for the given
synset we gather contextual information from
Wikipedia by exploiting knowledge from the Ba-
belNet semantic network (Section 2.1). Then, by
analyzing the corresponding contextual informa-
tion and comparing and contrasting it with the
</bodyText>
<footnote confidence="0.981863">
1http://www.babelnet.org
</footnote>
<bodyText confidence="0.7856285">
whole Wikipedia corpus, we obtain a vectorial
representation of the given synset (Section 2.2).
</bodyText>
<subsectionHeader confidence="0.957477">
2.1 A Wikipedia sub-corpus for each concept
</subsectionHeader>
<bodyText confidence="0.999991666666667">
Let c be a concept, which in our setting is a Ba-
belNet synset, and let W, be the set containing
the Wikipedia page p corresponding to the con-
cept c and all the Wikipedia pages having an out-
going link to p. We further enrich W, with the
corresponding Wikipedia pages of the hypernyms
and hyponyms of c in the BabelNet network. W,
is the set of Wikipedia pages whose contents are
exploited to build a representation for the concept
c. We refer to the bag of content words in all the
Wikipedia pages in W, as the sub-corpus SC, for
the concept c.
</bodyText>
<subsectionHeader confidence="0.994869">
2.2 Vector construction: lexical specificity
</subsectionHeader>
<bodyText confidence="0.999367454545455">
Lexical specificity (Lafon, 1980) is a statistical
measure based on the hypergeometric distribu-
tion. Due to its efficiency in extracting a set
of highly relevant words from a sub-corpus, the
measure has recently gained popularity in differ-
ent NLP applications, such as textual data analy-
sis (Lebart et al., 1998), term extraction (Drouin,
2003), and domain-based term disambiguation
(Camacho-Collados et al., 2014; Billami et al.,
2014). We leverage lexical specificity to com-
pute the weights in our vectors. In our earlier
work (Camacho-Collados et al., 2015), we con-
ducted different experiments which demonstrated
the improvement that lexical specificity can pro-
vide over the popular term frequency-inverse doc-
ument frequency weighting scheme (Jones, 1972,
tf-idf). Lexical specificity computes the vector
weights for an item, i.e., a word or a set of words,
by comparing and contrasting its contextual infor-
mation with a reference corpus. In our setting, we
take the whole Wikipedia as our reference corpus
RC (we use the October 2012 Wikipedia dump).
</bodyText>
<page confidence="0.995336">
742
</page>
<bodyText confidence="0.963535851851852">
Let T and t be the respective total number of to-
kens in RC and SC,, while F and f denote the
frequency of a given item in RC and SC,, respec-
tively. Our goal is to compute a weight denoting
the association of an item to the concept c. For no-
tational brevity, we use the following expression
to refer to positive lexical specificity:
specificity(T, t, F, f) = − login P(X &gt; f) (1)
where X represents a random variable following
a hypergeometric distribution of parameters F, t
and T. As we are only interested in a set of
items that are representative of the concept be-
ing modeled, we follow Billami et al. (2014) and
only consider in our final vector the items which
are relevant to SC, with a confidence higher than
99% according to the hypergeometric distribution
(P(X &gt; f) ≤ 0.01).
On the basis of lexical specificity we put for-
ward two types of representations: lexical and uni-
fied. The lexical vector representation lex, of a
concept c has lemmas as its individual dimensions.
To this end, we apply lexical specificity to every
lemma in SC, in order to estimate the relevance of
each lemma to our concept c. We use the lexical
representation for the task of WSD (see Section
3.2). We describe the unified representation in the
next subsection.
</bodyText>
<subsectionHeader confidence="0.998611">
2.3 Unified representation
</subsectionHeader>
<bodyText confidence="0.999926285714286">
Unlike the lexical version, our unified representa-
tion has concepts as individual dimensions. Algo-
rithm 1 shows the construction process of a con-
cept’s unified vector. The algorithm first clusters
together those words that have a sense sharing
the same hypernym (h in the algorithm) according
to the BabelNet taxonomy (lines 2-4). Next, the
specificity is computed for the set of all the hy-
ponyms of h, even those that do not appear in the
sub-corpus SC, (lines 6-14). Here, F and f denote
the aggregated frequencies of all the hyponyms of
h in the whole Wikipedia (i.e., reference corpus
RC) and the sub-corpus SC,, respectively.
Our binding of a set of sibling words into a sin-
gle cluster represented by their common hypernym
provides two advantages. Firstly, it transforms the
representations to a unified semantic space. This
space has concepts as its dimensions, enabling
their comparability across languages. Secondly,
the clustering can be viewed as an implicit dis-
ambiguation process, whereby a set of potentially
</bodyText>
<figure confidence="0.4760088">
Algorithm 1 Unified Vector Construction
Input: a concept c
Output: the unified vector u. where u.(h) is the dimension
corresponding to concept h
1: H ;
</figure>
<listItem confidence="0.883568266666667">
2: for each lemma l E SC.
3: for each hypernym h of l in BabelNet
4: H H U {h}
5: vector u. null vector
6: for each h E H
7: if 9 l1, l2 E SC.: l1, l2 hyponyms of h and l1 =6 l2
then
8: F 0
9: f 0
10: for each hyponym hypo of h
11: for each lexicalization lex of hypo
12: F F + freq(lex, RC)
13: f f + freq(lex, SC.)
14: u.(h) specificity(T, t, F, f))
15: return vector u.
</listItem>
<bodyText confidence="0.999375153846154">
ambiguous words are disambiguated into their in-
tended sense on the basis of the contextual clues of
the neighbouring content words, resulting in more
accurate representations of meaning.
Example. Table 1 lists the top-weighted con-
cepts, represented by their relevant lexicalizations,
in the unified vectors generated for the bird and
machine senses of the noun crane and for three
different languages.2 A comparison of concepts
across the two senses indicates the effectiveness
of our representation in identifying relevant con-
cepts in different languages, while guaranteeing a
clear distinction between the two meanings.
</bodyText>
<sectionHeader confidence="0.996015" genericHeader="method">
3 Applications
</sectionHeader>
<bodyText confidence="0.999565">
Thanks to their VSM nature and the sense-
level functionality, our concept representations are
highly flexible, allowing us to adapt and apply
them to different NLP tasks with minimal adap-
tation. In this section we explain how we use our
representations in the tasks of semantic similarity
(Section 3.1) and WSD (Section 3.2).
Associating concepts with words. Given that
our representations are for individual word senses,
a preliminary step for both tasks would be to as-
sociate the set of concepts, i.e., BabelNet synsets,
C,,, = {ci, ..., c,,} with a given word w. In the
case when w exists in the BabelNet dictionary, we
obtain the set of associated senses of the word as
defined in the BabelNet sense inventory.
In order to enhance the coverage in the case of
</bodyText>
<footnote confidence="0.648768">
2We use the sense notation of Navigli (2009): wordpn is
the nth sense of the word with part of speech p.
</footnote>
<page confidence="0.991452">
743
</page>
<table confidence="0.89449775">
Crane (bird) Crane (machine)
English French German English French German
shore bird1 $famille des oiseaux1 n $vogel-familie1 *lifting device1 n *dispositif de levage1 n *hebevorrichtung1
n *limicole1 n $construction4 n navire1 n
bird1 n *charadrii1 platform1 n radfahrzeug1
n oiseau aquatique2 n n n limicole1 n
*wading bird1 toll´e2 †vogel gattung1 warship1 n †lenkfahrzeug1
n n n n ovaisseau2 n
oscine bird1 gallinac´e1 wirbeltiere2 electric circuit1 n n regler3
n n n ovessel2 spationef1 n
†bird genus1 oclasse1 fleisch1 n n reisebus1
n n n boat1 $construction2 n
$bird family1 occurence1 tier um1 n n charadrii1
n n n †v´ehicule3 n
otaxonomic group1n reiher1 n g¨uterwagen2
n n
</table>
<tableCaption confidence="0.979626">
Table 1: Top-weighted concepts, i.e., BabelNet synsets, for the bird and machine senses of the noun
</tableCaption>
<bodyText confidence="0.960490272727273">
crane. We represent each synset by one of its word senses. Word senses marked with the same symbol
across languages correspond to the same BabelNet synset.
words that are not defined in the BabelNet dic-
tionary, we also exploit the so-called Wikipedia
piped links. A piped link is a hyperlink appear-
ing in the body of a Wikipedia article, providing a
link to another Wikipedia article. For example, the
piped link [[dockside crane|Crane (machine)]] is
a hyperlink that appears as dockside crane in the
text, but takes the user to the Wikipedia page titled
Crane (machine). These links provide Wikipedia
editors with the ability to represent a Wikipedia
article through a suitable lexicalization that pre-
serves the grammatical structure, contextual co-
herency, and flow of the sentence. This property
provides an effective means of obtaining a set of
concepts for the words not covered by BabelNet.
For the case of our example, the BabelNet out-of-
vocabulary word w = dockside crane will have
in its set of associated concepts C,,, the BabelNet
synset corresponding to the Wikipedia page titled
Crane (machine).
</bodyText>
<subsectionHeader confidence="0.999694">
3.1 Semantic Similarity
</subsectionHeader>
<bodyText confidence="0.999828722222222">
Once we have the set C,,, of concepts associated
with each word w, we first retrieve the set of
corresponding unified vector representations. We
then follow Camacho-Collados et al. (2015) and
use square-rooted Weighted Overlap (Pilehvar et
al., 2013, WO) as our vector comparison method,
a metric that has been shown to suit specificity-
based vectors more than the conventional cosine.
WO compares two vectors on the basis of their
overlapping dimensions, which are harmonically
weighted by their relative ranking:
where O is the set of overlapping dimensions (i.e.
concepts) between the two vectors and rank(q, vi)
is the rank of dimension q in the vector vi.
Finally, the similarity between two words w1
and w2 is calculated as the similarity of their clos-
est senses, a prevailing approach in the literature
(Resnik, 1995; Budanitsky and Hirst, 2006):
</bodyText>
<equation confidence="0.951643">
�
sim(w1, w2) = max WO(v1, v2) (3)
v1ECw1,v2ECw2
</equation>
<bodyText confidence="0.999959">
where w1 and w2 can belong to different lan-
guages. This cross-lingual similarity measure-
ment is possible thanks to the unified language-
independent space of concepts of our semantic
representations.
</bodyText>
<subsectionHeader confidence="0.999553">
3.2 Multilingual Word Sense Disambiguation
</subsectionHeader>
<bodyText confidence="0.991549">
In order to be able to apply our approach to WSD,
we use the lexical vector lexc for each concept c.
The reason for our choice of lexical vectors in this
setting is that they enable a direct comparison of a
candidate sense’s representation with the context,
which is also in the same lexical form. Algorithm
2 summarizes the general framework of our ap-
proach. Given a target word w to disambiguate,
our approach proceeds by the following steps:
</bodyText>
<listItem confidence="0.9991323">
1. Retrieve C,,,, the set of associated concepts
with the target word w (line 1);
2. Obtain the lexical vector lexc for each con-
cept c E C,,, (cf. Section 2);
3. Calculate, for each candidate concept c, a
confidence score (scorec) based on the har-
monic sum of the ranks of the overlapping
words between its lexical vector lexc and the
context of the target word (line 5 in Algo-
rithm 2).
</listItem>
<equation confidence="0.898854333333333">
(2)
WO(v1, v2) =
�|O|
i=1(2i)−1
�(rank(q, v1) + rank(q, v2))−1
qcO
</equation>
<page confidence="0.966302">
744
</page>
<bodyText confidence="0.756410666666667">
Algorithm 2 MUFFIN for WSD
Input: a target word w and a document d (context of w)
Output: ˆc, the intended sense of w
</bodyText>
<listItem confidence="0.96365125">
1: for each concept c E C,,,
2: score, +— 0
3: for each lemma l E d
4: if l E lex, then
5: score, +— score, + (rank(l, lex,))−1
6: cˆ +— arg max score,
,∈Cw
7: return cˆ
</listItem>
<bodyText confidence="0.999730739130435">
Thanks to the use of BabelNet, our approach is
applicable to arbitrary languages. For the task of
WSD, we focus on two major sense inventories in-
tegrated in BabelNet: Wikipedia and WordNet.
Wikipedia sense inventory. In this case, we ob-
tain the set of candidate senses for a target word
by following the procedure described in the begin-
ning of this Section (i.e., associating concepts with
words). However, we do not consider those Babel-
Net synsets that are not associated with Wikipedia
pages.
WordNet sense inventory. Similarly, when re-
stricted to the WordNet inventory, we discard
those BabelNet synsets that do not contain a Word-
Net synset. In this setting, we also leverage re-
lations from WordNet’s semantic network and its
disambiguated glosses3 in order to obtain a richer
set of Wikipedia articles in the sub-corpus con-
struction. The enrichment of the semantic network
with the disambiguated glosses has been shown to
be beneficial in various graph-based disambigua-
tion tasks (Navigli and Velardi, 2005; Agirre and
Soroa, 2009; Pilehvar et al., 2013).
</bodyText>
<sectionHeader confidence="0.999819" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.99973025">
We assess the reliability of MUFFIN in two stan-
dard evaluation benchmarks: semantic similar-
ity (Section 4.1) and Word Sense Disambiguation
(Section 4.2).
</bodyText>
<subsectionHeader confidence="0.998262">
4.1 Semantic Similarity
</subsectionHeader>
<bodyText confidence="0.999513142857143">
As our semantic similarity experiment we opted
for word similarity, which is one of the most pop-
ular evaluation frameworks in lexical semantics.
Given a pair of words, the task in word similarity
is to automatically judge their semantic similarity
and, ideally, this judgement should be close to that
given by humans.
</bodyText>
<footnote confidence="0.952732">
3http://wordnet.princeton.edu/
glosstag.shtml
</footnote>
<subsubsectionHeader confidence="0.360347">
4.1.1 Datasets
</subsubsectionHeader>
<bodyText confidence="0.999964022727273">
Monolingual. We picked the RG-65 dataset
(Rubenstein and Goodenough, 1965) as our mono-
lingual word similarity dataset. The dataset com-
prises 65 English word pairs which have been
manually annotated by several annotators accord-
ing to their similarity on a scale of 0 to 4. We
also perform evaluations on the French (Joubarne
and Inkpen, 2011) and German (Gurevych, 2005)
adaptations of this dataset.
Cross-lingual. Hassan and Mihalcea (2009) de-
veloped two sets of cross-lingual datasets based on
the English MC-30 (Miller and Charles, 1991) and
WordSim-353 (Finkelstein et al., 2002) datasets,
for four different languages: English, German,
Romanian, and Arabic. However, the construc-
tion procedure they adopted, consisting of trans-
lating the pairs to other languages while preserv-
ing the original similarity scores, has led to incon-
sistencies in the datasets. For instance, the Span-
ish dataset contains the identical pair mediodia-
mediodia with a similarity score of 3.42 (in the
scale [0,4]). Additionally, the datasets contain
several orthographic errors, such as despliege and
grua (instead of despliegue and grua) and incor-
rect translations (e.g., the English noun implement
translated into the Spanish verb implementar).
Kennedy and Hirst (2012) proposed a more reli-
able procedure that leverages two existing aligned
monolingual word similarity datasets for the con-
struction of a new cross-lingual dataset. To this
end, for each two word pairs a-b and a’-b’ in the
two datasets, if the difference in the correspond-
ing scores is greater than one, the pairs are dis-
carded. Otherwise, two new pairs a-b’ and a’-b
are created with a score equal to the average of the
two original pairs’ scores. In the case of repeated
pairs, we merge them into a single pair with a sim-
ilarity equal to their average scores. Using this
procedure as a basis, Kennedy and Hirst (2012)
created an English-French dataset consisting of
100 pairs. We followed the same procedure and
built two datasets for English-German (consisting
of 125 pairs) and German-French (comprising 96
pairs) language pairs.4
</bodyText>
<subsubsectionHeader confidence="0.582224">
4.1.2 Comparison systems
</subsubsectionHeader>
<bodyText confidence="0.978823">
Monolingual. We benchmark our system
against four other approaches that exploit
</bodyText>
<footnote confidence="0.9983265">
4The cross-lingual datasets are available at http://
lcl.uniroma1.it/sim-datasets/.
</footnote>
<page confidence="0.971298">
745
</page>
<table confidence="0.999720769230769">
English p r German p r French p r
MUFFIN 0.83 0.84 MUFFIN 0.77 0.76 MUFFIN 0.71 0.77
SOC-PMI – 0.61 SOC-PMI – 0.27 SOC-PMI – 0.19
PMI – 0.41 PMI – 0.40 PMI – 0.34
Retrofitting 0.74 – Retrofitting 0.60 – Retrofitting 0.61 –
LSA-Wiki 0.69 0.65 – – – LSA-Wiki 0.52 0.57
Wiki-wup – 0.59 Wiki-wup – 0.65
SSA 0.83 0.86 Resnik – 0.72
NASARI 0.84 0.82 Lesk hyper – 0.69
ADW 0.87 0.81
Word2Vec – 0.84
PMI-SVD – 0.74
ESA – 0.72
</table>
<tableCaption confidence="0.9584355">
Table 2: Spearman (p) and Pearson (r) correlation performance of different systems on the English,
German and French RG-65 datasets.
</tableCaption>
<bodyText confidence="0.999961">
Wikipedia as their main knowledge resource:
SSA5 (Hassan and Mihalcea, 2011), ESA
(Gabrilovich and Markovitch, 2007), Wiki-wup
(Ponzetto and Strube, 2007), and LSA-Wiki
(Granada et al., 2014). We also provide results for
systems that use distributional semantics for mod-
eling words, both the conventional co-occurrence
based approach, i.e., PMI-SVD (Baroni et al.,
2014), PMI and SOC-PMI (Joubarne and Inkpen,
2011), and Retrofitting (Faruqui et al., 2015),
and the newer word embeddings, i.e., Word2Vec
(Mikolov et al., 2013). For Word2Vec and PMI-
SVD, we use the pre-trained models obtained
by Baroni et al. (2014).6 As for WordNet-based
approaches, we report results for Resnik (Resnik,
1995) and ADW (Pilehvar et al., 2013), which
take advantage of its structural information,
and Lesk hyper (Gurevych, 2005), which lever-
ages definitional information in WordNet for
similarity computation. Finally, we also report
the performance of our earlier work NASARI
(Camacho-Collados et al., 2015), which combines
knowledge from WordNet and Wikipedia for
the English language in its setting without the
Wiktionary synonyms module.
Cross-lingual. We compare the performance of
our approach against the best configuration of
the CL-MSR-2.0 system (Kennedy and Hirst,
2012), which exploits Pointwise Mutual Informa-
tion (PMI) on a parallel corpus obtained from
</bodyText>
<footnote confidence="0.985631166666667">
5SSA involves several parameters tuned on datasets that
are constructed on the basis of MC-30 and RG-65.
6We report the best configuration of the systems on the
RG-65 dataset out of their 48 configurations. The corpus
used to train the models contained 2.8 billion tokens, includ-
ing Wikipedia (Baroni et al., 2014).
</footnote>
<bodyText confidence="0.9999085">
the English and French versions of WordNet.
Since two of our cross-lingual datasets are newly-
created, we developed three baseline systems to
enable a more meaningful comparison. To this
end, we first use Google Translate to translate the
non-English side of the dataset to the English lan-
guage. Accordingly, three state-of-the-art graph-
based and corpus-based approaches were used to
measure the similarity of the resulting English
pairs. As English similarity measurement systems,
we opted for ADW (Pilehvar et al., 2013), and the
best predictive (Mikolov et al., 2013, Word2Vec)
and co-occurrence (i.e., PMI-SVD) models ob-
tained by Baroni et al. (2014).7 In our experi-
ments we refer to these systems as pivot, since
they use English as a pivot for computing semantic
similarity. As a comparison, we also show results
for MUFFINpivot, which is the variant of our sys-
tem applied to the same automatically translated
monolingual datasets.
</bodyText>
<sectionHeader confidence="0.81985" genericHeader="method">
4.1.3 Results
</sectionHeader>
<bodyText confidence="0.999775416666667">
Monolingual. We show in Table 2 the perfor-
mance of different systems in terms of Spear-
man and Pearson correlations on the English, Ger-
man, and French RG-65 datasets. On the German
and French datasets, our system outperforms the
comparison systems according to both evaluation
measures. It achieves considerable Spearman and
Pearson correlation leads of 0.1 and 0.2, respec-
tively, on the French dataset in comparison to the
best system. Also on the English RG-65 dataset,
our system attains competitive performance ac-
cording to both Spearman and Pearson correla-
</bodyText>
<footnote confidence="0.958827">
7http://clic.cimec.unitn.it/composes/
semantic-vectors.html
</footnote>
<page confidence="0.992366">
746
</page>
<table confidence="0.999583857142857">
Measure FR-EN EN-DE DE-FR
MUFFIN 0.83 0.76 0.83
MUFFINpivot 0.83 0.73 0.79
ADWpivot 0.80 0.73 0.72
Word2Vecpivot 0.75 0.69 0.77
PMI-SVDpivot 0.76 0.72 0.65
CL-MSR-2.0 0.30 – –
</table>
<tableCaption confidence="0.893152">
Table 3: Pearson correlation performance of dif-
ferent similarity measures on the three cross-
lingual RG-65 datasets.
</tableCaption>
<bodyText confidence="0.999143111111111">
tions. We note that most state-of-the-art systems
on the dataset (e.g., ADW) are restricted to the En-
glish language only.
Cross-lingual. Pearson correlation results on
the three cross-lingual RG-65 datasets are pre-
sented in Table 3. Similarly to the monolingual
experiments, our system proves highly reliable
in the cross-lingual setting, improving the per-
formance of the comparison systems on all three
language pairs. Moreover, MUFFINpivot attains
the best results among the pivot systems on all
datasets, confirming the reliability of our system
in the monolingual setting. We note that since the
cross-lingual datasets were built by translating the
word pairs in the original English RG-65 dataset,
the pivot-based comparison systems proved to be
highly competitive, outperforming the CL-MSR-
2.0 system by a considerable margin.
</bodyText>
<subsectionHeader confidence="0.978879">
4.2 Word Sense Disambiguation
4.2.1 Wikipedia
</subsectionHeader>
<bodyText confidence="0.9999741">
In this setting, we selected the SemEval 2013 all-
words WSD task (Navigli et al., 2013) as our eval-
uation benchmark. The task provides datasets for
five different languages: Italian, English, French,
Spanish and German. There are on average 1123
words to disambiguate in each language’s dataset.
As comparison system, we provide results for the
best-performing participating system on each lan-
guage. We also show results for the state-of-the-
art WSD system of Moro et al. (2014, Babelfy),
which relies on random walks on the BabelNet se-
mantic network and a set of graph heuristic algo-
rithms. Finally, we also report results for the Most
Frequent Sense (MFS) baseline provided by the
task organizers.
We follow Moro et al. (2014) and back off to
the MFS baseline in the case when our system’s
judgement does not meet a threshold 0. Similarly
to Babelfy, we tuned the value of the threshold 0
on the trial dataset provided by the organizers of
the task. We tuned 0 with step size 0.05 (hence,
21 possible values in [0,1]), obtaining an optimal
value of 0.85 in the trial set, a value which we use
across all languages.
Table 4 lists the F1 percentage performance
of different systems on the five datasets of the
SemEval-2013 all-words WSD task. Despite not
being tuned to the task, our representations pro-
vide competitive results on all datasets, outper-
forming the sophisticated Babelfy system on the
Spanish and German languages. The variant of
our system not utilizing the MFS information in
the disambiguation process (0 = 0), i.e., MUF-
FIN*, also shows competitive results, outperform-
ing the best system in the SemEval-2013 dataset
on all languages. Interestingly, MUFFIN* proves
highly effective on the French language, surpass-
ing not only the performance of our system using
the MFS information, but also attaining the best
overall performance.
</bodyText>
<subsectionHeader confidence="0.613141">
4.2.2 WordNet
</subsectionHeader>
<bodyText confidence="0.999804259259259">
As regards the WordNet disambiguation task, we
take as our benchmark the two recent SemEval
English all-words WSD tasks: the SemEval-2013
task on Multilingual WSD (Navigli et al., 2013)
and the SemEval-2007 English Lexical Sample,
SRL and All-Words task (Pradhan et al., 2007).
The all-words datasets of the two tasks contain
1644 instances (SemEval-2013) and 162 noun in-
stances (SemEval-2007), respectively.
As comparison system, we report the per-
formance of the best configuration of the top-
performing system in the SemEval-2013 task, i.e.,
UMCC-DLSI (Guti´errez et al., 2013). We also
show results for the state-of-the-art supervised
system (Zhong and Ng, 2010, IMS), as well as
for two graph-based approaches that are based on
random walks on the WordNet graph (Agirre and
Soroa, 2009, UKB w2w) and the BabelNet seman-
tic network (Moro et al., 2014, Babelfy). We fol-
low Babelfy and also exploit the WordNet’s sense
frequency information from the SemCor sense-
annotated corpus (Miller et al., 1993). However,
instead of simply backing off to the most frequent
sense, we propose a more meaningful exploitation
of this information. To this end, we compute the
relevance of a specific sense as the average of its
normalized sense frequency and its corresponding
</bodyText>
<page confidence="0.994323">
747
</page>
<table confidence="0.999071833333333">
System MFS Back off Italian English French Spanish German
MUFFIN ✓ 81.9 84.5 71.4 85.1 83.1
MUFFIN* 67.9 73.5 72.3 81.1 76.1
Babelfy ✓ 84.3 87.4 71.6 83.8 81.6
Best SemEval 2013 system ✓ 58.3 54.8 60.5 58.1 61.0
MFS - 82.2 80.2 69.1 82.1 83.0
</table>
<tableCaption confidence="0.978416">
Table 4: F1 percentage performance on the SemEval-2013 Multilingual WSD datasets using Wikipedia
</tableCaption>
<bodyText confidence="0.98546393939394">
as sense inventory.
score (score, in Algorithm 2) given by our system.
The sense with the highest overall relevance value
is then picked as the intended sense.
Additionally, we put forward a hybrid system
that combines our system with IMS, hence bene-
fiting from the judgements made by two systems
that utilize complementary information. Our sys-
tem makes judgements based on global contexts,
whereas IMS exploits the local context of the tar-
get word. To this end, we compute the relevance
of a specific sense as the average of the normal-
ized scores given by IMS and our system (score,
in Algorithm 2). We refer to this hybrid system as
MUFFIN+IMS.
Table 5 reports the F1 percentage performance
of different systems on the datasets of SemEval-
2013 and SemEval-2007 English all-words WSD
tasks. We also report the results for the MFS base-
line, which always picks the most frequent sense
of a word. Similarly to the disambiguation task
on the Wikipedia sense inventory, MUFFIN proves
to be quite competitive on the WordNet disam-
biguation task, while surpassing the performance
of all the comparison systems on the SemEval-
2013 dataset. On the SemEval-2007 dataset,
IMS achieves the best performance, thanks to its
usage of large amounts of manually and semi-
automatically tagged data. Finally, our hybrid sys-
tem, MUFFIN+IMS, provides the best overall per-
formance on the two datasets, showing that our
combination of the two WSD systems that utilize
different types of knowledge was beneficial.
</bodyText>
<sectionHeader confidence="0.99996" genericHeader="method">
5 Related work
</sectionHeader>
<bodyText confidence="0.998111166666667">
We briefly review the recent literature on the two
NLP tasks to which we applied our representa-
tions, i.e., Word Sense Disambiguation and se-
mantic similarity.
WSD. There are two main categories of WSD
techniques: knowledge-based and supervised
</bodyText>
<table confidence="0.9997075">
System SemEval-2013 SemEval-2007
MUFFIN 66.0 66.0
UKB 61.3 56.0
UMCC-DLSI 64.7 –
IMS 65.3 67.3
Babelfy 65.9 62.7
MFS 63.2 65.8
MUFFIN+IMS 66.9 68.5
</table>
<tableCaption confidence="0.96165">
Table 5: F1 percentage performance on the
</tableCaption>
<bodyText confidence="0.973114551724138">
SemEval-2013 and SemEval-2007 (noun in-
stances) English All-words WSD datatets using
WordNet as sense inventory.
(Navigli, 2009). Supervised systems such as IMS
(Zhong and Ng, 2010) analyze sense-annotated
data and model the context in which the various
senses of a word usually appear. Despite their ac-
curacy for the words that are provided with suit-
able amounts of sense-annotated data, their appli-
cability is limited to those words and languages
for which such data is available, practically limit-
ing them to a small subset of words mainly in the
English language. Knowledge-based approaches
(Sinha and Mihalcea, 2007; Navigli and Lapata,
2007; Agirre and Soroa, 2009) significantly im-
prove the coverage of supervised systems. How-
ever, similarly to their supervised counterparts,
knowledge-based techniques are usually limited to
the English language.
Recent years have seen a growing interest in
cross-lingual and multilingual WSD (Lefever and
Hoste, 2010; Lefever and Hoste, 2013; Navigli
et al., 2013). Multilinguality is usually offered
by methods that exploit the structural informa-
tion of large-scale multilingual lexical resources
such as Wikipedia (Guti´errez et al., 2013; Manion
and Sainudiin, 2013; Hovy et al., 2013). Babelfy
(Moro et al., 2014) is an approach with state-of-
the-art performance that relies on random walks
</bodyText>
<page confidence="0.994224">
748
</page>
<bodyText confidence="0.999939489361703">
on BabelNet multilingual semantic network (Nav-
igli and Ponzetto, 2012a) and densest subgraph
heuristics. However, the approach is limited to the
WSD and Entity Linking tasks. In contrast, our
approach is global as it can be used in different
NLP tasks, including WSD.
Semantic similarity. Semantic similarity of
word pairs is usually computed either on the ba-
sis of the structural properties of lexical databases
and thesauri, or by comparing vectorial represen-
tations of words learned from massive text cor-
pora. Structural approaches usually measure the
similarity on the basis of the distance information
on semantic networks, such as WordNet (Budan-
itsky and Hirst, 2006), or thesauri, such as Ro-
get’s (Morris and Hirst, 1991; Jarmasz and Sz-
pakowicz, 2003). The semantic network of Word-
Net has also been used in more sophisticated tech-
niques such as those based on random graph walks
(Ramage et al., 2009; Pilehvar et al., 2013), or
coupled with the complementary knowledge from
Wikipedia (Camacho-Collados et al., 2015). How-
ever, these techniques are either limited in the lan-
guages to which they can be applied, or in their
applicability to tasks other than semantic similar-
ity (Navigli and Ponzetto, 2012b).
Corpus-based techniques are more flexible, en-
abling the training of models on corpora other
than English. However, these approaches, either
in their conventional co-occurrence based form
(Gabrilovich and Markovitch, 2007; Landauer and
Dumais, 1997; Turney and Pantel, 2010; Bulli-
naria and Levy, 2012), or the more recent predic-
tive models (Mikolov et al., 2013; Collobert and
Weston, 2008; Pennington et al., 2014), are re-
stricted in two ways: (1) they cannot be used to
compare word senses; and (2) they cannot be di-
rectly applied to cross-lingual semantic similar-
ity. Though the first problem has been solved
by multi-prototype models (Huang et al., 2012),
or by the sense-specific representations obtained
as a result of exploiting WordNet glosses (Chen
et al., 2014), the second problem remains unad-
dressed. In contrast, our approach models word
senses and concepts effectively, while providing a
unified representation for different languages that
enables cross-lingual semantic similarity.
</bodyText>
<sectionHeader confidence="0.997936" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999965529411765">
This paper presented MUFFIN, a new multilingual,
unified and flexible representation of individual
word senses. Thanks to its effective combination
of distributional statistics and structured knowl-
edge, the approach can compute efficient represen-
tations of arbitrary word senses, with high cover-
age and irrespective of their language. We eval-
uated our representations on two different NLP
tasks, i.e., semantic similarity and Word Sense
Disambiguation, reporting state-of-the-art perfor-
mance on several datasets. Experimental results
demonstrated the reliability of our unified repre-
sentation approach, while at the same time also
highlighting its main advantages: multilinguality,
owing to its effective application within and across
multiple languages; and flexibility, owing to its ro-
bust performance on two different tasks.
</bodyText>
<sectionHeader confidence="0.999153" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.992702333333333">
The authors gratefully acknowledge
the support of the ERC Starting
Grant MultiJEDI No. 259234.
</bodyText>
<sectionHeader confidence="0.998669" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995251137931034">
Eneko Agirre and Aitor Soroa. 2009. Personalizing
PageRank for Word Sense Disambiguation. In Pro-
ceedings of EACL, pages 33–41.
Eneko Agirre, Enrique Alfonseca, Keith Hall, Jana
Kravalova, Marius Pas¸ca, and Aitor Soroa. 2009.
A study on similarity and relatedness using distribu-
tional and WordNet-based approaches. In Proceed-
ings of NAACL, pages 19–27.
Marco Baroni, Georgiana Dinu, and Germ´an
Kruszewski. 2014. Don’t count, predict! a
systematic comparison of context-counting vs.
context-predicting semantic vectors. In Proceedings
ofACL, pages 238–247.
Mokhtar-Boumeyden Billami, Jos´e Camacho-
Collados, Evelyne Jacquey, and Laurence Kister.
2014. Semantic annotation and terminology val-
idation in full scientific articles in social sciences
and humanities (annotation s´emantique et validation
terminologique en texte int´egral en shs) [in french].
In Proceedings of TALN 2014, pages 363–376.
Samuel Brody and Mirella Lapata. 2009. Bayesian
Word Sense Induction. In Proceedings of EACL,
pages 103–111.
Alexander Budanitsky and Graeme Hirst. 2006.
Evaluating WordNet-based measures of Lexical Se-
mantic Relatedness. Computational Linguistics,
32(1):13–47.
John A. Bullinaria and Joseph P. Levy. 2012. Ex-
tracting semantic representations from word co-
</reference>
<page confidence="0.993651">
749
</page>
<reference confidence="0.999182324074074">
occurrence statistics: stop-lists, stemming, and
SVD. Behavior Research Methods, 44(3):890–907.
Jos´e Camacho-Collados, Mokhtar Billami, Evelyne
Jacquey, and Laurence Kister. 2014. Approche
statistique pour le filtrage terminologique des oc-
currences de candidats termes en texte int´egral. In
JADT, pages 121–133.
Jos´e Camacho-Collados, Mohammad Taher Pilehvar,
and Roberto Navigli. 2015. NASARI: a Novel Ap-
proach to a Semantically-Aware Representation of
Items. In Proceedings of NAACL, pages 567–577.
Xinxiong Chen, Zhiyuan Liu, and Maosong Sun. 2014.
A unified model for word sense representation and
disambiguation. In Proceedings of EMNLP, pages
1025–1035.
Ronan Collobert and Jason Weston. 2008. A unified
architecture for natural language processing: Deep
neural networks with multitask learning. In Pro-
ceedings of ICML, pages 160–167.
Patrick Drouin. 2003. Term extraction using non-
technical corpora as a point of leverage. Terminol-
ogy, 9(1):99–115.
Manaal Faruqui, Jesse Dodge, Sujay K. Jauhar, Chris
Dyer, Eduard Hovy, and Noah A. Smith. 2015.
Retrofitting word vectors to semantic lexicons. In
Proceedings of NAACL, pages 1606–1615.
Lev Finkelstein, Gabrilovich Evgeniy, Matias Yossi,
Rivlin Ehud, Solan Zach, Wolfman Gadi, and Rup-
pin Eytan. 2002. Placing search in context: The
concept revisited. ACM Transactions on Informa-
tion Systems, 20(1):116–131.
Evgeniy Gabrilovich and Shaul Markovitch. 2007.
Computing semantic relatedness using Wikipedia-
based explicit semantic analysis. In Proceedings of
IJCAI, pages 1606–1611.
Roger Granada, Cassia Trojahn, and Renata Vieira.
2014. Comparing semantic relatedness between
word pairs in Portuguese using Wikipedia. In Com-
putational Processing of the Portuguese Language,
pages 170–175.
Iryna Gurevych. 2005. Using the structure of a con-
ceptual network in computing semantic relatedness.
In Proceedings of IJCNLP, pages 767–778.
Yoan Guti´errez, Yenier Casta˜neda, Andy Gonz´alez,
Rainel Estrada, D. Dennys Piug, I. Jose Abreu,
Roger P´erez, Antonio Fern´andez Orqu´ın, Andr´es
Montoyo, Rafael Mu˜noz, and Franc Camara. 2013.
UMCC DLSI: Reinforcing a ranking algorithm with
sense frequencies and multidimensional semantic
resources to solve multilingual word sense disam-
biguation. In Proceedings of SemEval 2013, pages
241–249.
Zellig Harris. 1954. Distributional structure. Word,
10:146–162.
Samer Hassan and Rada Mihalcea. 2009. Cross-
lingual semantic relatedness using encyclopedic
knowledge. In Proceedings ofEMNLP, pages 1192–
1201.
Samer Hassan and Rada Mihalcea. 2011. Semantic
relatedness using salient semantic analysis. In Pro-
ceedings of AAAI, pages 884,889.
Eduard H. Hovy, Roberto Navigli, and Simone Paolo
Ponzetto. 2013. Collaboratively built semi-
structured content and Artificial Intelligence: The
story so far. Artificial Intelligence, 194:2–27.
Eric H. Huang, Richard Socher, Christopher D. Man-
ning, and Andrew Y. Ng. 2012. Improving word
representations via global context and multiple word
prototypes. In Proceedings of ACL, pages 873–882.
Thad Hughes and Daniel Ramage. 2007. Lexical se-
mantic relatedness with random graph walks. In
Proceedings of EMNLP-CoNLL, pages 581–589.
Mario Jarmasz and Stan Szpakowicz. 2003. Roget’s
thesaurus and semantic similarity. In Proceedings
of RANLP, pages 212–219.
Karen Sp¨arck Jones. 1972. A statistical interpretation
of term specificity and its application in retrieval.
Journal of Documentation, 28:11–21.
Colette Joubarne and Diana Inkpen. 2011. Compar-
ison of semantic similarity for different languages
using the Google n-gram corpus and second-order
co-occurrence measures. In Advances in Artificial
Intelligence, pages 216–221.
Alistair Kennedy and Graeme Hirst. 2012. Measuring
semantic relatedness across languages. In Proceed-
ings of xLiTe: Cross-Lingual Technologies Work-
shop at the Neural Information Processing Systems
Conference.
Pierre Lafon. 1980. Sur la variabilit´e de la fr´equence
des formes dans un corpus. Mots, 1:127–165.
Tom Landauer and Scott Dooley. 2002. Latent seman-
tic analysis: theory, method and application. In Pro-
ceedings of CSCL, pages 742–743.
Thomas K Landauer and Susan T Dumais. 1997. A
solution to Plato’s problem: The latent semantic
analysis theory of acquisition, induction, and rep-
resentation of knowledge. Psychological Review,
104(2):211.
Ludovic Lebart, A Salem, and Lisette Berry. 1998. Ex-
ploring textual data. Kluwer Academic Publishers.
Els Lefever and Veronique Hoste. 2010. SemEval-
2010 Task 3: Cross-lingual Word Sense Disam-
biguation. In Proceedings of SemEval 2010, pages
82–87, Uppsala, Sweden.
Els Lefever and Veronique Hoste. 2013. SemEval-
2013 Task 10: Cross-lingual Word Sense Disam-
biguation. In Proceedings of SemEval 2013, pages
158–166, Atlanta, USA.
</reference>
<page confidence="0.968627">
750
</page>
<reference confidence="0.999790367924529">
Steve L. Manion and Raazesh Sainudiin. 2013. Dae-
bak!: Peripheral diversity for multilingual Word
Sense Disambiguation. In Proceedings of SemEval
2013, pages 250–254.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efficient estimation of word represen-
tations in vector space. CoRR, abs/1301.3781.
George A. Miller and Walter G. Charles. 1991. Con-
textual correlates of semantic similarity. Language
and Cognitive Processes, 6(1):1–28.
George A. Miller, Claudia Leacock, Randee Tengi, and
Ross Bunker. 1993. A semantic concordance. In
Proceedings of the 3rd DARPA Workshop on Human
Language Technology, pages 303–308, Plainsboro,
N.J.
Andrea Moro, Alessandro Raganato, and Roberto Nav-
igli. 2014. Entity Linking meets Word Sense Dis-
ambiguation: a Unified Approach. Transactions
of the Association for Computational Linguistics
(TACL), 2:231–244.
Jane Morris and Graeme Hirst. 1991. Lexical cohe-
sion computed by thesaural relations as an indicator
of the structure of text. Computational Linguistics,
17(1).
Roberto Navigli and Mirella Lapata. 2007. Graph
connectivity measures for unsupervised Word Sense
Disambiguation. In Proceedings of IJCAI, pages
1683–1688.
Roberto Navigli and Simone Paolo Ponzetto. 2012a.
BabelNet: The automatic construction, evaluation
and application of a wide-coverage multilingual se-
mantic network. Artificial Intelligence, 193:217–
250.
Roberto Navigli and Simone Paolo Ponzetto. 2012b.
BabelRelate! a joint multilingual approach to com-
puting semantic relatedness. In Proceedings of
AAAI, pages 108–114.
Roberto Navigli and Paola Velardi. 2005. Struc-
tural Semantic Interconnections: a knowledge-based
approach to Word Sense Disambiguation. IEEE
Transactions on Pattern Analysis and Machine In-
telligence, 27(7):1075–1088.
Roberto Navigli, David Jurgens, and Daniele Vannella.
2013. SemEval-2013 Task 12: Multilingual Word
Sense Disambiguation. In Proceedings of SemEval
2013, pages 222–231.
Roberto Navigli. 2009. Word Sense Disambiguation:
A survey. ACM Computing Surveys, 41(2):1–69.
Patrick Pantel and Dekang Lin. 2002. Discovering
word senses from text. In Proceedings of KDD,
pages 613–619.
Jeffrey Pennington, Richard Socher, and Christopher D
Manning. 2014. GloVe: Global vectors for word
representation. In Proceedings of EMNLP, pages
1532–1543.
Mohammad Taher Pilehvar and Roberto Navigli. 2014.
A robust approach to aligning heterogeneous lexical
resources. In Proceedings ofACL, pages 468–478.
Mohammad Taher Pilehvar, David Jurgens, and
Roberto Navigli. 2013. Align, Disambiguate and
Walk: a Unified Approach for Measuring Seman-
tic Similarity. In Proceedings of ACL, pages 1341–
1351.
Simone Paolo Ponzetto and Michael Strube. 2007.
Knowledge derived from Wikipedia for computing
semantic relatedness. Journal of Artificial Intelli-
gence Research (JAIR), 30:181–212.
Sameer Pradhan, Edward Loper, Dmitriy Dligach, and
Martha Palmer. 2007. SemEval-2007 task-17: En-
glish lexical sample, SRL and all words. In Pro-
ceedings of SemEval, pages 87–92.
Daniel Ramage, Anna N. Rafferty, and Christopher D.
Manning. 2009. Random walks for text semantic
similarity. In Proceedings of the 2009 Workshop on
Graph-based Methods for Natural Language Pro-
cessing, pages 23–31.
Joseph Reisinger and Raymond J. Mooney. 2010.
Multi-prototype vector-space models of word mean-
ing. In Proceedings of ACL, pages 109–117.
Philip Resnik. 1995. Using information content to
evaluate semantic similarity in a taxonomy. In Pro-
ceedings of IJCAI, pages 448–453.
Herbert Rubenstein and John B. Goodenough. 1965.
Contextual correlates of synonymy. Communica-
tions of the ACM, 8(10):627–633.
Gerard Salton, A. Wong, and C. S. Yang. 1975. A
vector space model for automatic indexing. Com-
munications of the ACM, 18(11):613–620.
Ravi Sinha and Rada Mihalcea. 2007. Unsuper-
vised graph-based Word Sense Disambiguation us-
ing measures of word semantic similarity. In Pro-
ceedings of ICSC, pages 363–369.
Peter D. Turney and Patrick Pantel. 2010. From
frequency to meaning: Vector space models of se-
mantics. Journal of Artificial Intelligence Research,
37:141–188.
Eric Yeh, Daniel Ramage, Christopher D. Manning,
Eneko Agirre, and Aitor Soroa. 2009. WikiWalk:
random walks on Wikipedia for semantic related-
ness. In Proceedings of the Workshop on Graph-
based Methods for Natural Language Processing,
pages 41–49.
Zhi Zhong and Hwee Tou Ng. 2010. It Makes Sense:
A wide-coverage Word Sense Disambiguation sys-
tem for free text. In Proceedings of the ACL System
Demonstrations, pages 78–83.
</reference>
<page confidence="0.998289">
751
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.910186">
<title confidence="0.99619">A Unified Multilingual Semantic Representation of Concepts</title>
<author confidence="0.953526">Mohammad Taher Pilehvar Camacho-Collados</author>
<affiliation confidence="0.987207">Department of Computer Sapienza University of</affiliation>
<abstract confidence="0.998928">Semantic representation lies at the core of several applications in Natural Language Processing. However, most existing semantic representation techniques cannot be used effectively for the representation of individual word senses. We put forward a novel multilingual concept reprecalled which not only enables accurate representation of word senses in different languages, but also provides multiple advantages over existing a given concept in a unified semantic space irrespective of the language of interest, enabling cross-lingual comparison of different concepts. We evaluate our approach in two different evaluation benchmarks, semantic similarity and Word Sense Disambiguation, reporting state-of-the-art performance on several standard datasets.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Aitor Soroa</author>
</authors>
<title>Personalizing PageRank for Word Sense Disambiguation.</title>
<date>2009</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>33--41</pages>
<contexts>
<context position="17267" citStr="Agirre and Soroa, 2009" startWordPosition="2801" endWordPosition="2804"> not consider those BabelNet synsets that are not associated with Wikipedia pages. WordNet sense inventory. Similarly, when restricted to the WordNet inventory, we discard those BabelNet synsets that do not contain a WordNet synset. In this setting, we also leverage relations from WordNet’s semantic network and its disambiguated glosses3 in order to obtain a richer set of Wikipedia articles in the sub-corpus construction. The enrichment of the semantic network with the disambiguated glosses has been shown to be beneficial in various graph-based disambiguation tasks (Navigli and Velardi, 2005; Agirre and Soroa, 2009; Pilehvar et al., 2013). 4 Experiments We assess the reliability of MUFFIN in two standard evaluation benchmarks: semantic similarity (Section 4.1) and Word Sense Disambiguation (Section 4.2). 4.1 Semantic Similarity As our semantic similarity experiment we opted for word similarity, which is one of the most popular evaluation frameworks in lexical semantics. Given a pair of words, the task in word similarity is to automatically judge their semantic similarity and, ideally, this judgement should be close to that given by humans. 3http://wordnet.princeton.edu/ glosstag.shtml 4.1.1 Datasets Mon</context>
<context position="27749" citStr="Agirre and Soroa, 2009" startWordPosition="4446" endWordPosition="4449">vigli et al., 2013) and the SemEval-2007 English Lexical Sample, SRL and All-Words task (Pradhan et al., 2007). The all-words datasets of the two tasks contain 1644 instances (SemEval-2013) and 162 noun instances (SemEval-2007), respectively. As comparison system, we report the performance of the best configuration of the topperforming system in the SemEval-2013 task, i.e., UMCC-DLSI (Guti´errez et al., 2013). We also show results for the state-of-the-art supervised system (Zhong and Ng, 2010, IMS), as well as for two graph-based approaches that are based on random walks on the WordNet graph (Agirre and Soroa, 2009, UKB w2w) and the BabelNet semantic network (Moro et al., 2014, Babelfy). We follow Babelfy and also exploit the WordNet’s sense frequency information from the SemCor senseannotated corpus (Miller et al., 1993). However, instead of simply backing off to the most frequent sense, we propose a more meaningful exploitation of this information. To this end, we compute the relevance of a specific sense as the average of its normalized sense frequency and its corresponding 747 System MFS Back off Italian English French Spanish German MUFFIN ✓ 81.9 84.5 71.4 85.1 83.1 MUFFIN* 67.9 73.5 72.3 81.1 76.1</context>
<context position="31171" citStr="Agirre and Soroa, 2009" startWordPosition="5005" endWordPosition="5008">English All-words WSD datatets using WordNet as sense inventory. (Navigli, 2009). Supervised systems such as IMS (Zhong and Ng, 2010) analyze sense-annotated data and model the context in which the various senses of a word usually appear. Despite their accuracy for the words that are provided with suitable amounts of sense-annotated data, their applicability is limited to those words and languages for which such data is available, practically limiting them to a small subset of words mainly in the English language. Knowledge-based approaches (Sinha and Mihalcea, 2007; Navigli and Lapata, 2007; Agirre and Soroa, 2009) significantly improve the coverage of supervised systems. However, similarly to their supervised counterparts, knowledge-based techniques are usually limited to the English language. Recent years have seen a growing interest in cross-lingual and multilingual WSD (Lefever and Hoste, 2010; Lefever and Hoste, 2013; Navigli et al., 2013). Multilinguality is usually offered by methods that exploit the structural information of large-scale multilingual lexical resources such as Wikipedia (Guti´errez et al., 2013; Manion and Sainudiin, 2013; Hovy et al., 2013). Babelfy (Moro et al., 2014) is an appr</context>
</contexts>
<marker>Agirre, Soroa, 2009</marker>
<rawString>Eneko Agirre and Aitor Soroa. 2009. Personalizing PageRank for Word Sense Disambiguation. In Proceedings of EACL, pages 33–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Enrique Alfonseca</author>
<author>Keith Hall</author>
<author>Jana Kravalova</author>
<author>Marius Pas¸ca</author>
<author>Aitor Soroa</author>
</authors>
<title>A study on similarity and relatedness using distributional and WordNet-based approaches.</title>
<date>2009</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<pages>pages</pages>
<marker>Agirre, Alfonseca, Hall, Kravalova, Pas¸ca, Soroa, 2009</marker>
<rawString>Eneko Agirre, Enrique Alfonseca, Keith Hall, Jana Kravalova, Marius Pas¸ca, and Aitor Soroa. 2009. A study on similarity and relatedness using distributional and WordNet-based approaches. In Proceedings of NAACL, pages 19–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Georgiana Dinu</author>
<author>Germ´an Kruszewski</author>
</authors>
<title>Don’t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors.</title>
<date>2014</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>238--247</pages>
<contexts>
<context position="1808" citStr="Baroni et al., 2014" startWordPosition="255" endWordPosition="258">ine-interpretable form, is a fundamental problem in Natural Language Processing (NLP). The Vector Space Model (VSM) is a prominent approach for semantic representation, with widespread popularity in numerous NLP applications. The prevailing methods for the computation of a vector space representation are based on distributional semantics (Harris, 1954). However, these approaches, whether in their conventional co-occurrence based form (Salton et al., 1975; Turney and Pantel, 2010; Landauer and Dooley, 2002), or in their newer predictive branch (Collobert and Weston, 2008; Mikolov et al., 2013; Baroni et al., 2014), suffer from a major drawback: they are unable to model individual word senses or concepts, as they conflate different meanings of a word into a single vectorial representation. This hinders the functionality of this group of vector space models in tasks such as Word Sense Disambiguation (WSD) that require the representation of individual word senses. There have been several efforts to adapt and apply distributional approaches to the representation of word senses (Pantel and Lin, 2002; Brody and Lapata, 2009; Reisinger and Mooney, 2010; Huang et al., 2012). However, none of these techniques p</context>
<context position="21059" citStr="Baroni et al., 2014" startWordPosition="3400" endWordPosition="3403">A 0.83 0.86 Resnik – 0.72 NASARI 0.84 0.82 Lesk hyper – 0.69 ADW 0.87 0.81 Word2Vec – 0.84 PMI-SVD – 0.74 ESA – 0.72 Table 2: Spearman (p) and Pearson (r) correlation performance of different systems on the English, German and French RG-65 datasets. Wikipedia as their main knowledge resource: SSA5 (Hassan and Mihalcea, 2011), ESA (Gabrilovich and Markovitch, 2007), Wiki-wup (Ponzetto and Strube, 2007), and LSA-Wiki (Granada et al., 2014). We also provide results for systems that use distributional semantics for modeling words, both the conventional co-occurrence based approach, i.e., PMI-SVD (Baroni et al., 2014), PMI and SOC-PMI (Joubarne and Inkpen, 2011), and Retrofitting (Faruqui et al., 2015), and the newer word embeddings, i.e., Word2Vec (Mikolov et al., 2013). For Word2Vec and PMISVD, we use the pre-trained models obtained by Baroni et al. (2014).6 As for WordNet-based approaches, we report results for Resnik (Resnik, 1995) and ADW (Pilehvar et al., 2013), which take advantage of its structural information, and Lesk hyper (Gurevych, 2005), which leverages definitional information in WordNet for similarity computation. Finally, we also report the performance of our earlier work NASARI (Camacho-C</context>
<context position="22354" citStr="Baroni et al., 2014" startWordPosition="3598" endWordPosition="3601">for the English language in its setting without the Wiktionary synonyms module. Cross-lingual. We compare the performance of our approach against the best configuration of the CL-MSR-2.0 system (Kennedy and Hirst, 2012), which exploits Pointwise Mutual Information (PMI) on a parallel corpus obtained from 5SSA involves several parameters tuned on datasets that are constructed on the basis of MC-30 and RG-65. 6We report the best configuration of the systems on the RG-65 dataset out of their 48 configurations. The corpus used to train the models contained 2.8 billion tokens, including Wikipedia (Baroni et al., 2014). the English and French versions of WordNet. Since two of our cross-lingual datasets are newlycreated, we developed three baseline systems to enable a more meaningful comparison. To this end, we first use Google Translate to translate the non-English side of the dataset to the English language. Accordingly, three state-of-the-art graphbased and corpus-based approaches were used to measure the similarity of the resulting English pairs. As English similarity measurement systems, we opted for ADW (Pilehvar et al., 2013), and the best predictive (Mikolov et al., 2013, Word2Vec) and co-occurrence </context>
</contexts>
<marker>Baroni, Dinu, Kruszewski, 2014</marker>
<rawString>Marco Baroni, Georgiana Dinu, and Germ´an Kruszewski. 2014. Don’t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors. In Proceedings ofACL, pages 238–247.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mokhtar-Boumeyden Billami</author>
<author>Jos´e CamachoCollados</author>
<author>Evelyne Jacquey</author>
<author>Laurence Kister</author>
</authors>
<title>Semantic annotation and terminology validation in full scientific articles in social sciences and humanities (annotation s´emantique et validation terminologique en texte int´egral en shs) [in french].</title>
<date>2014</date>
<booktitle>In Proceedings of TALN 2014,</booktitle>
<pages>363--376</pages>
<contexts>
<context position="7032" citStr="Billami et al., 2014" startWordPosition="1055" endWordPosition="1058">sentation for the concept c. We refer to the bag of content words in all the Wikipedia pages in W, as the sub-corpus SC, for the concept c. 2.2 Vector construction: lexical specificity Lexical specificity (Lafon, 1980) is a statistical measure based on the hypergeometric distribution. Due to its efficiency in extracting a set of highly relevant words from a sub-corpus, the measure has recently gained popularity in different NLP applications, such as textual data analysis (Lebart et al., 1998), term extraction (Drouin, 2003), and domain-based term disambiguation (Camacho-Collados et al., 2014; Billami et al., 2014). We leverage lexical specificity to compute the weights in our vectors. In our earlier work (Camacho-Collados et al., 2015), we conducted different experiments which demonstrated the improvement that lexical specificity can provide over the popular term frequency-inverse document frequency weighting scheme (Jones, 1972, tf-idf). Lexical specificity computes the vector weights for an item, i.e., a word or a set of words, by comparing and contrasting its contextual information with a reference corpus. In our setting, we take the whole Wikipedia as our reference corpus RC (we use the October 201</context>
<context position="8266" citStr="Billami et al. (2014)" startWordPosition="1270" endWordPosition="1273">ump). 742 Let T and t be the respective total number of tokens in RC and SC,, while F and f denote the frequency of a given item in RC and SC,, respectively. Our goal is to compute a weight denoting the association of an item to the concept c. For notational brevity, we use the following expression to refer to positive lexical specificity: specificity(T, t, F, f) = − login P(X &gt; f) (1) where X represents a random variable following a hypergeometric distribution of parameters F, t and T. As we are only interested in a set of items that are representative of the concept being modeled, we follow Billami et al. (2014) and only consider in our final vector the items which are relevant to SC, with a confidence higher than 99% according to the hypergeometric distribution (P(X &gt; f) ≤ 0.01). On the basis of lexical specificity we put forward two types of representations: lexical and unified. The lexical vector representation lex, of a concept c has lemmas as its individual dimensions. To this end, we apply lexical specificity to every lemma in SC, in order to estimate the relevance of each lemma to our concept c. We use the lexical representation for the task of WSD (see Section 3.2). We describe the unified re</context>
</contexts>
<marker>Billami, CamachoCollados, Jacquey, Kister, 2014</marker>
<rawString>Mokhtar-Boumeyden Billami, Jos´e CamachoCollados, Evelyne Jacquey, and Laurence Kister. 2014. Semantic annotation and terminology validation in full scientific articles in social sciences and humanities (annotation s´emantique et validation terminologique en texte int´egral en shs) [in french]. In Proceedings of TALN 2014, pages 363–376.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel Brody</author>
<author>Mirella Lapata</author>
</authors>
<title>Bayesian Word Sense Induction.</title>
<date>2009</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>103--111</pages>
<contexts>
<context position="2322" citStr="Brody and Lapata, 2009" startWordPosition="338" endWordPosition="342"> or in their newer predictive branch (Collobert and Weston, 2008; Mikolov et al., 2013; Baroni et al., 2014), suffer from a major drawback: they are unable to model individual word senses or concepts, as they conflate different meanings of a word into a single vectorial representation. This hinders the functionality of this group of vector space models in tasks such as Word Sense Disambiguation (WSD) that require the representation of individual word senses. There have been several efforts to adapt and apply distributional approaches to the representation of word senses (Pantel and Lin, 2002; Brody and Lapata, 2009; Reisinger and Mooney, 2010; Huang et al., 2012). However, none of these techniques provides representations that are already linked to a standard sense inventory, and consequently such mapping has to be carried out either manually, or with the help of sense-annotated data. Chen et al. (2014) addressed this issue and obtained vectors for individual word senses by leveraging WordNet glosses. NASARI (Camacho-Collados et al., 2015) is another approach that obtains accurate sense-specific representations by combining the complementary knowledge from WordNet and Wikipedia. Graph-based approaches h</context>
</contexts>
<marker>Brody, Lapata, 2009</marker>
<rawString>Samuel Brody and Mirella Lapata. 2009. Bayesian Word Sense Induction. In Proceedings of EACL, pages 103–111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Budanitsky</author>
<author>Graeme Hirst</author>
</authors>
<title>Evaluating WordNet-based measures of Lexical Semantic Relatedness.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>1</issue>
<contexts>
<context position="14750" citStr="Budanitsky and Hirst, 2006" startWordPosition="2359" endWordPosition="2362">ap (Pilehvar et al., 2013, WO) as our vector comparison method, a metric that has been shown to suit specificitybased vectors more than the conventional cosine. WO compares two vectors on the basis of their overlapping dimensions, which are harmonically weighted by their relative ranking: where O is the set of overlapping dimensions (i.e. concepts) between the two vectors and rank(q, vi) is the rank of dimension q in the vector vi. Finally, the similarity between two words w1 and w2 is calculated as the similarity of their closest senses, a prevailing approach in the literature (Resnik, 1995; Budanitsky and Hirst, 2006): � sim(w1, w2) = max WO(v1, v2) (3) v1ECw1,v2ECw2 where w1 and w2 can belong to different languages. This cross-lingual similarity measurement is possible thanks to the unified languageindependent space of concepts of our semantic representations. 3.2 Multilingual Word Sense Disambiguation In order to be able to apply our approach to WSD, we use the lexical vector lexc for each concept c. The reason for our choice of lexical vectors in this setting is that they enable a direct comparison of a candidate sense’s representation with the context, which is also in the same lexical form. Algorithm </context>
<context position="32514" citStr="Budanitsky and Hirst, 2006" startWordPosition="5207" endWordPosition="5211">igli and Ponzetto, 2012a) and densest subgraph heuristics. However, the approach is limited to the WSD and Entity Linking tasks. In contrast, our approach is global as it can be used in different NLP tasks, including WSD. Semantic similarity. Semantic similarity of word pairs is usually computed either on the basis of the structural properties of lexical databases and thesauri, or by comparing vectorial representations of words learned from massive text corpora. Structural approaches usually measure the similarity on the basis of the distance information on semantic networks, such as WordNet (Budanitsky and Hirst, 2006), or thesauri, such as Roget’s (Morris and Hirst, 1991; Jarmasz and Szpakowicz, 2003). The semantic network of WordNet has also been used in more sophisticated techniques such as those based on random graph walks (Ramage et al., 2009; Pilehvar et al., 2013), or coupled with the complementary knowledge from Wikipedia (Camacho-Collados et al., 2015). However, these techniques are either limited in the languages to which they can be applied, or in their applicability to tasks other than semantic similarity (Navigli and Ponzetto, 2012b). Corpus-based techniques are more flexible, enabling the trai</context>
</contexts>
<marker>Budanitsky, Hirst, 2006</marker>
<rawString>Alexander Budanitsky and Graeme Hirst. 2006. Evaluating WordNet-based measures of Lexical Semantic Relatedness. Computational Linguistics, 32(1):13–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Bullinaria</author>
<author>Joseph P Levy</author>
</authors>
<title>Extracting semantic representations from word cooccurrence statistics: stop-lists, stemming, and SVD.</title>
<date>2012</date>
<journal>Behavior Research Methods,</journal>
<volume>44</volume>
<issue>3</issue>
<contexts>
<context position="33354" citStr="Bullinaria and Levy, 2012" startWordPosition="5340" endWordPosition="5344">Ramage et al., 2009; Pilehvar et al., 2013), or coupled with the complementary knowledge from Wikipedia (Camacho-Collados et al., 2015). However, these techniques are either limited in the languages to which they can be applied, or in their applicability to tasks other than semantic similarity (Navigli and Ponzetto, 2012b). Corpus-based techniques are more flexible, enabling the training of models on corpora other than English. However, these approaches, either in their conventional co-occurrence based form (Gabrilovich and Markovitch, 2007; Landauer and Dumais, 1997; Turney and Pantel, 2010; Bullinaria and Levy, 2012), or the more recent predictive models (Mikolov et al., 2013; Collobert and Weston, 2008; Pennington et al., 2014), are restricted in two ways: (1) they cannot be used to compare word senses; and (2) they cannot be directly applied to cross-lingual semantic similarity. Though the first problem has been solved by multi-prototype models (Huang et al., 2012), or by the sense-specific representations obtained as a result of exploiting WordNet glosses (Chen et al., 2014), the second problem remains unaddressed. In contrast, our approach models word senses and concepts effectively, while providing a</context>
</contexts>
<marker>Bullinaria, Levy, 2012</marker>
<rawString>John A. Bullinaria and Joseph P. Levy. 2012. Extracting semantic representations from word cooccurrence statistics: stop-lists, stemming, and SVD. Behavior Research Methods, 44(3):890–907.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jos´e Camacho-Collados</author>
<author>Mokhtar Billami</author>
<author>Evelyne Jacquey</author>
<author>Laurence Kister</author>
</authors>
<title>Approche statistique pour le filtrage terminologique des occurrences de candidats termes en texte int´egral.</title>
<date>2014</date>
<booktitle>In JADT,</booktitle>
<pages>121--133</pages>
<contexts>
<context position="7009" citStr="Camacho-Collados et al., 2014" startWordPosition="1051" endWordPosition="1054"> are exploited to build a representation for the concept c. We refer to the bag of content words in all the Wikipedia pages in W, as the sub-corpus SC, for the concept c. 2.2 Vector construction: lexical specificity Lexical specificity (Lafon, 1980) is a statistical measure based on the hypergeometric distribution. Due to its efficiency in extracting a set of highly relevant words from a sub-corpus, the measure has recently gained popularity in different NLP applications, such as textual data analysis (Lebart et al., 1998), term extraction (Drouin, 2003), and domain-based term disambiguation (Camacho-Collados et al., 2014; Billami et al., 2014). We leverage lexical specificity to compute the weights in our vectors. In our earlier work (Camacho-Collados et al., 2015), we conducted different experiments which demonstrated the improvement that lexical specificity can provide over the popular term frequency-inverse document frequency weighting scheme (Jones, 1972, tf-idf). Lexical specificity computes the vector weights for an item, i.e., a word or a set of words, by comparing and contrasting its contextual information with a reference corpus. In our setting, we take the whole Wikipedia as our reference corpus RC </context>
</contexts>
<marker>Camacho-Collados, Billami, Jacquey, Kister, 2014</marker>
<rawString>Jos´e Camacho-Collados, Mokhtar Billami, Evelyne Jacquey, and Laurence Kister. 2014. Approche statistique pour le filtrage terminologique des occurrences de candidats termes en texte int´egral. In JADT, pages 121–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jos´e Camacho-Collados</author>
<author>Mohammad Taher Pilehvar</author>
<author>Roberto Navigli</author>
</authors>
<title>NASARI: a Novel Approach to a Semantically-Aware Representation of Items.</title>
<date>2015</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<pages>567--577</pages>
<contexts>
<context position="2755" citStr="Camacho-Collados et al., 2015" startWordPosition="404" endWordPosition="407">esentation of individual word senses. There have been several efforts to adapt and apply distributional approaches to the representation of word senses (Pantel and Lin, 2002; Brody and Lapata, 2009; Reisinger and Mooney, 2010; Huang et al., 2012). However, none of these techniques provides representations that are already linked to a standard sense inventory, and consequently such mapping has to be carried out either manually, or with the help of sense-annotated data. Chen et al. (2014) addressed this issue and obtained vectors for individual word senses by leveraging WordNet glosses. NASARI (Camacho-Collados et al., 2015) is another approach that obtains accurate sense-specific representations by combining the complementary knowledge from WordNet and Wikipedia. Graph-based approaches have also been successfully utilized to model individual words (Hughes and Ramage, 2007; Agirre et al., 2009; Yeh et al., 2009), or concepts (Pilehvar et al., 2013; Pilehvar and Navigli, 2014), drawing on the structural properties of semantic networks. The applicability of all these techniques, however, is usually either constrained to a single language (usually English), or to a specific task. We put forward MUFFIN (Multilingual,</context>
<context position="7156" citStr="Camacho-Collados et al., 2015" startWordPosition="1075" endWordPosition="1078">s SC, for the concept c. 2.2 Vector construction: lexical specificity Lexical specificity (Lafon, 1980) is a statistical measure based on the hypergeometric distribution. Due to its efficiency in extracting a set of highly relevant words from a sub-corpus, the measure has recently gained popularity in different NLP applications, such as textual data analysis (Lebart et al., 1998), term extraction (Drouin, 2003), and domain-based term disambiguation (Camacho-Collados et al., 2014; Billami et al., 2014). We leverage lexical specificity to compute the weights in our vectors. In our earlier work (Camacho-Collados et al., 2015), we conducted different experiments which demonstrated the improvement that lexical specificity can provide over the popular term frequency-inverse document frequency weighting scheme (Jones, 1972, tf-idf). Lexical specificity computes the vector weights for an item, i.e., a word or a set of words, by comparing and contrasting its contextual information with a reference corpus. In our setting, we take the whole Wikipedia as our reference corpus RC (we use the October 2012 Wikipedia dump). 742 Let T and t be the respective total number of tokens in RC and SC,, while F and f denote the frequenc</context>
<context position="14086" citStr="Camacho-Collados et al. (2015)" startWordPosition="2251" endWordPosition="2254">tion that preserves the grammatical structure, contextual coherency, and flow of the sentence. This property provides an effective means of obtaining a set of concepts for the words not covered by BabelNet. For the case of our example, the BabelNet out-ofvocabulary word w = dockside crane will have in its set of associated concepts C,,, the BabelNet synset corresponding to the Wikipedia page titled Crane (machine). 3.1 Semantic Similarity Once we have the set C,,, of concepts associated with each word w, we first retrieve the set of corresponding unified vector representations. We then follow Camacho-Collados et al. (2015) and use square-rooted Weighted Overlap (Pilehvar et al., 2013, WO) as our vector comparison method, a metric that has been shown to suit specificitybased vectors more than the conventional cosine. WO compares two vectors on the basis of their overlapping dimensions, which are harmonically weighted by their relative ranking: where O is the set of overlapping dimensions (i.e. concepts) between the two vectors and rank(q, vi) is the rank of dimension q in the vector vi. Finally, the similarity between two words w1 and w2 is calculated as the similarity of their closest senses, a prevailing appro</context>
<context position="21680" citStr="Camacho-Collados et al., 2015" startWordPosition="3494" endWordPosition="3497">l., 2014), PMI and SOC-PMI (Joubarne and Inkpen, 2011), and Retrofitting (Faruqui et al., 2015), and the newer word embeddings, i.e., Word2Vec (Mikolov et al., 2013). For Word2Vec and PMISVD, we use the pre-trained models obtained by Baroni et al. (2014).6 As for WordNet-based approaches, we report results for Resnik (Resnik, 1995) and ADW (Pilehvar et al., 2013), which take advantage of its structural information, and Lesk hyper (Gurevych, 2005), which leverages definitional information in WordNet for similarity computation. Finally, we also report the performance of our earlier work NASARI (Camacho-Collados et al., 2015), which combines knowledge from WordNet and Wikipedia for the English language in its setting without the Wiktionary synonyms module. Cross-lingual. We compare the performance of our approach against the best configuration of the CL-MSR-2.0 system (Kennedy and Hirst, 2012), which exploits Pointwise Mutual Information (PMI) on a parallel corpus obtained from 5SSA involves several parameters tuned on datasets that are constructed on the basis of MC-30 and RG-65. 6We report the best configuration of the systems on the RG-65 dataset out of their 48 configurations. The corpus used to train the mode</context>
<context position="32863" citStr="Camacho-Collados et al., 2015" startWordPosition="5266" endWordPosition="5269">of lexical databases and thesauri, or by comparing vectorial representations of words learned from massive text corpora. Structural approaches usually measure the similarity on the basis of the distance information on semantic networks, such as WordNet (Budanitsky and Hirst, 2006), or thesauri, such as Roget’s (Morris and Hirst, 1991; Jarmasz and Szpakowicz, 2003). The semantic network of WordNet has also been used in more sophisticated techniques such as those based on random graph walks (Ramage et al., 2009; Pilehvar et al., 2013), or coupled with the complementary knowledge from Wikipedia (Camacho-Collados et al., 2015). However, these techniques are either limited in the languages to which they can be applied, or in their applicability to tasks other than semantic similarity (Navigli and Ponzetto, 2012b). Corpus-based techniques are more flexible, enabling the training of models on corpora other than English. However, these approaches, either in their conventional co-occurrence based form (Gabrilovich and Markovitch, 2007; Landauer and Dumais, 1997; Turney and Pantel, 2010; Bullinaria and Levy, 2012), or the more recent predictive models (Mikolov et al., 2013; Collobert and Weston, 2008; Pennington et al., </context>
</contexts>
<marker>Camacho-Collados, Pilehvar, Navigli, 2015</marker>
<rawString>Jos´e Camacho-Collados, Mohammad Taher Pilehvar, and Roberto Navigli. 2015. NASARI: a Novel Approach to a Semantically-Aware Representation of Items. In Proceedings of NAACL, pages 567–577.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xinxiong Chen</author>
<author>Zhiyuan Liu</author>
<author>Maosong Sun</author>
</authors>
<title>A unified model for word sense representation and disambiguation.</title>
<date>2014</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1025--1035</pages>
<contexts>
<context position="2616" citStr="Chen et al. (2014)" startWordPosition="385" endWordPosition="388">s the functionality of this group of vector space models in tasks such as Word Sense Disambiguation (WSD) that require the representation of individual word senses. There have been several efforts to adapt and apply distributional approaches to the representation of word senses (Pantel and Lin, 2002; Brody and Lapata, 2009; Reisinger and Mooney, 2010; Huang et al., 2012). However, none of these techniques provides representations that are already linked to a standard sense inventory, and consequently such mapping has to be carried out either manually, or with the help of sense-annotated data. Chen et al. (2014) addressed this issue and obtained vectors for individual word senses by leveraging WordNet glosses. NASARI (Camacho-Collados et al., 2015) is another approach that obtains accurate sense-specific representations by combining the complementary knowledge from WordNet and Wikipedia. Graph-based approaches have also been successfully utilized to model individual words (Hughes and Ramage, 2007; Agirre et al., 2009; Yeh et al., 2009), or concepts (Pilehvar et al., 2013; Pilehvar and Navigli, 2014), drawing on the structural properties of semantic networks. The applicability of all these techniques,</context>
<context position="33824" citStr="Chen et al., 2014" startWordPosition="5419" endWordPosition="5422">ventional co-occurrence based form (Gabrilovich and Markovitch, 2007; Landauer and Dumais, 1997; Turney and Pantel, 2010; Bullinaria and Levy, 2012), or the more recent predictive models (Mikolov et al., 2013; Collobert and Weston, 2008; Pennington et al., 2014), are restricted in two ways: (1) they cannot be used to compare word senses; and (2) they cannot be directly applied to cross-lingual semantic similarity. Though the first problem has been solved by multi-prototype models (Huang et al., 2012), or by the sense-specific representations obtained as a result of exploiting WordNet glosses (Chen et al., 2014), the second problem remains unaddressed. In contrast, our approach models word senses and concepts effectively, while providing a unified representation for different languages that enables cross-lingual semantic similarity. 6 Conclusions This paper presented MUFFIN, a new multilingual, unified and flexible representation of individual word senses. Thanks to its effective combination of distributional statistics and structured knowledge, the approach can compute efficient representations of arbitrary word senses, with high coverage and irrespective of their language. We evaluated our represen</context>
</contexts>
<marker>Chen, Liu, Sun, 2014</marker>
<rawString>Xinxiong Chen, Zhiyuan Liu, and Maosong Sun. 2014. A unified model for word sense representation and disambiguation. In Proceedings of EMNLP, pages 1025–1035.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Collobert</author>
<author>Jason Weston</author>
</authors>
<title>A unified architecture for natural language processing: Deep neural networks with multitask learning.</title>
<date>2008</date>
<booktitle>In Proceedings of ICML,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="1764" citStr="Collobert and Weston, 2008" startWordPosition="247" endWordPosition="250"> a word or a word sense) in a mathematical or machine-interpretable form, is a fundamental problem in Natural Language Processing (NLP). The Vector Space Model (VSM) is a prominent approach for semantic representation, with widespread popularity in numerous NLP applications. The prevailing methods for the computation of a vector space representation are based on distributional semantics (Harris, 1954). However, these approaches, whether in their conventional co-occurrence based form (Salton et al., 1975; Turney and Pantel, 2010; Landauer and Dooley, 2002), or in their newer predictive branch (Collobert and Weston, 2008; Mikolov et al., 2013; Baroni et al., 2014), suffer from a major drawback: they are unable to model individual word senses or concepts, as they conflate different meanings of a word into a single vectorial representation. This hinders the functionality of this group of vector space models in tasks such as Word Sense Disambiguation (WSD) that require the representation of individual word senses. There have been several efforts to adapt and apply distributional approaches to the representation of word senses (Pantel and Lin, 2002; Brody and Lapata, 2009; Reisinger and Mooney, 2010; Huang et al.</context>
<context position="33442" citStr="Collobert and Weston, 2008" startWordPosition="5356" endWordPosition="5359"> from Wikipedia (Camacho-Collados et al., 2015). However, these techniques are either limited in the languages to which they can be applied, or in their applicability to tasks other than semantic similarity (Navigli and Ponzetto, 2012b). Corpus-based techniques are more flexible, enabling the training of models on corpora other than English. However, these approaches, either in their conventional co-occurrence based form (Gabrilovich and Markovitch, 2007; Landauer and Dumais, 1997; Turney and Pantel, 2010; Bullinaria and Levy, 2012), or the more recent predictive models (Mikolov et al., 2013; Collobert and Weston, 2008; Pennington et al., 2014), are restricted in two ways: (1) they cannot be used to compare word senses; and (2) they cannot be directly applied to cross-lingual semantic similarity. Though the first problem has been solved by multi-prototype models (Huang et al., 2012), or by the sense-specific representations obtained as a result of exploiting WordNet glosses (Chen et al., 2014), the second problem remains unaddressed. In contrast, our approach models word senses and concepts effectively, while providing a unified representation for different languages that enables cross-lingual semantic simi</context>
</contexts>
<marker>Collobert, Weston, 2008</marker>
<rawString>Ronan Collobert and Jason Weston. 2008. A unified architecture for natural language processing: Deep neural networks with multitask learning. In Proceedings of ICML, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Drouin</author>
</authors>
<title>Term extraction using nontechnical corpora as a point of leverage.</title>
<date>2003</date>
<journal>Terminology,</journal>
<volume>9</volume>
<issue>1</issue>
<contexts>
<context position="6940" citStr="Drouin, 2003" startWordPosition="1045" endWordPosition="1046">work. W, is the set of Wikipedia pages whose contents are exploited to build a representation for the concept c. We refer to the bag of content words in all the Wikipedia pages in W, as the sub-corpus SC, for the concept c. 2.2 Vector construction: lexical specificity Lexical specificity (Lafon, 1980) is a statistical measure based on the hypergeometric distribution. Due to its efficiency in extracting a set of highly relevant words from a sub-corpus, the measure has recently gained popularity in different NLP applications, such as textual data analysis (Lebart et al., 1998), term extraction (Drouin, 2003), and domain-based term disambiguation (Camacho-Collados et al., 2014; Billami et al., 2014). We leverage lexical specificity to compute the weights in our vectors. In our earlier work (Camacho-Collados et al., 2015), we conducted different experiments which demonstrated the improvement that lexical specificity can provide over the popular term frequency-inverse document frequency weighting scheme (Jones, 1972, tf-idf). Lexical specificity computes the vector weights for an item, i.e., a word or a set of words, by comparing and contrasting its contextual information with a reference corpus. In</context>
</contexts>
<marker>Drouin, 2003</marker>
<rawString>Patrick Drouin. 2003. Term extraction using nontechnical corpora as a point of leverage. Terminology, 9(1):99–115.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manaal Faruqui</author>
<author>Jesse Dodge</author>
<author>Sujay K Jauhar</author>
<author>Chris Dyer</author>
<author>Eduard Hovy</author>
<author>Noah A Smith</author>
</authors>
<title>Retrofitting word vectors to semantic lexicons.</title>
<date>2015</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<pages>1606--1615</pages>
<contexts>
<context position="21145" citStr="Faruqui et al., 2015" startWordPosition="3413" endWordPosition="3416"> 0.84 PMI-SVD – 0.74 ESA – 0.72 Table 2: Spearman (p) and Pearson (r) correlation performance of different systems on the English, German and French RG-65 datasets. Wikipedia as their main knowledge resource: SSA5 (Hassan and Mihalcea, 2011), ESA (Gabrilovich and Markovitch, 2007), Wiki-wup (Ponzetto and Strube, 2007), and LSA-Wiki (Granada et al., 2014). We also provide results for systems that use distributional semantics for modeling words, both the conventional co-occurrence based approach, i.e., PMI-SVD (Baroni et al., 2014), PMI and SOC-PMI (Joubarne and Inkpen, 2011), and Retrofitting (Faruqui et al., 2015), and the newer word embeddings, i.e., Word2Vec (Mikolov et al., 2013). For Word2Vec and PMISVD, we use the pre-trained models obtained by Baroni et al. (2014).6 As for WordNet-based approaches, we report results for Resnik (Resnik, 1995) and ADW (Pilehvar et al., 2013), which take advantage of its structural information, and Lesk hyper (Gurevych, 2005), which leverages definitional information in WordNet for similarity computation. Finally, we also report the performance of our earlier work NASARI (Camacho-Collados et al., 2015), which combines knowledge from WordNet and Wikipedia for the Eng</context>
</contexts>
<marker>Faruqui, Dodge, Jauhar, Dyer, Hovy, Smith, 2015</marker>
<rawString>Manaal Faruqui, Jesse Dodge, Sujay K. Jauhar, Chris Dyer, Eduard Hovy, and Noah A. Smith. 2015. Retrofitting word vectors to semantic lexicons. In Proceedings of NAACL, pages 1606–1615.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Finkelstein</author>
<author>Gabrilovich Evgeniy</author>
<author>Matias Yossi</author>
<author>Rivlin Ehud</author>
<author>Solan Zach</author>
<author>Wolfman Gadi</author>
<author>Ruppin Eytan</author>
</authors>
<title>Placing search in context: The concept revisited.</title>
<date>2002</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>20</volume>
<issue>1</issue>
<contexts>
<context position="18446" citStr="Finkelstein et al., 2002" startWordPosition="2980" endWordPosition="2983">inceton.edu/ glosstag.shtml 4.1.1 Datasets Monolingual. We picked the RG-65 dataset (Rubenstein and Goodenough, 1965) as our monolingual word similarity dataset. The dataset comprises 65 English word pairs which have been manually annotated by several annotators according to their similarity on a scale of 0 to 4. We also perform evaluations on the French (Joubarne and Inkpen, 2011) and German (Gurevych, 2005) adaptations of this dataset. Cross-lingual. Hassan and Mihalcea (2009) developed two sets of cross-lingual datasets based on the English MC-30 (Miller and Charles, 1991) and WordSim-353 (Finkelstein et al., 2002) datasets, for four different languages: English, German, Romanian, and Arabic. However, the construction procedure they adopted, consisting of translating the pairs to other languages while preserving the original similarity scores, has led to inconsistencies in the datasets. For instance, the Spanish dataset contains the identical pair mediodiamediodia with a similarity score of 3.42 (in the scale [0,4]). Additionally, the datasets contain several orthographic errors, such as despliege and grua (instead of despliegue and grua) and incorrect translations (e.g., the English noun implement tran</context>
</contexts>
<marker>Finkelstein, Evgeniy, Yossi, Ehud, Zach, Gadi, Eytan, 2002</marker>
<rawString>Lev Finkelstein, Gabrilovich Evgeniy, Matias Yossi, Rivlin Ehud, Solan Zach, Wolfman Gadi, and Ruppin Eytan. 2002. Placing search in context: The concept revisited. ACM Transactions on Information Systems, 20(1):116–131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
<author>Shaul Markovitch</author>
</authors>
<title>Computing semantic relatedness using Wikipediabased explicit semantic analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of IJCAI,</booktitle>
<pages>1606--1611</pages>
<contexts>
<context position="20805" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="3363" endWordPosition="3366">MUFFIN 0.83 0.84 MUFFIN 0.77 0.76 MUFFIN 0.71 0.77 SOC-PMI – 0.61 SOC-PMI – 0.27 SOC-PMI – 0.19 PMI – 0.41 PMI – 0.40 PMI – 0.34 Retrofitting 0.74 – Retrofitting 0.60 – Retrofitting 0.61 – LSA-Wiki 0.69 0.65 – – – LSA-Wiki 0.52 0.57 Wiki-wup – 0.59 Wiki-wup – 0.65 SSA 0.83 0.86 Resnik – 0.72 NASARI 0.84 0.82 Lesk hyper – 0.69 ADW 0.87 0.81 Word2Vec – 0.84 PMI-SVD – 0.74 ESA – 0.72 Table 2: Spearman (p) and Pearson (r) correlation performance of different systems on the English, German and French RG-65 datasets. Wikipedia as their main knowledge resource: SSA5 (Hassan and Mihalcea, 2011), ESA (Gabrilovich and Markovitch, 2007), Wiki-wup (Ponzetto and Strube, 2007), and LSA-Wiki (Granada et al., 2014). We also provide results for systems that use distributional semantics for modeling words, both the conventional co-occurrence based approach, i.e., PMI-SVD (Baroni et al., 2014), PMI and SOC-PMI (Joubarne and Inkpen, 2011), and Retrofitting (Faruqui et al., 2015), and the newer word embeddings, i.e., Word2Vec (Mikolov et al., 2013). For Word2Vec and PMISVD, we use the pre-trained models obtained by Baroni et al. (2014).6 As for WordNet-based approaches, we report results for Resnik (Resnik, 1995) and ADW (Pilehvar et </context>
<context position="33274" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="5328" endWordPosition="5331">been used in more sophisticated techniques such as those based on random graph walks (Ramage et al., 2009; Pilehvar et al., 2013), or coupled with the complementary knowledge from Wikipedia (Camacho-Collados et al., 2015). However, these techniques are either limited in the languages to which they can be applied, or in their applicability to tasks other than semantic similarity (Navigli and Ponzetto, 2012b). Corpus-based techniques are more flexible, enabling the training of models on corpora other than English. However, these approaches, either in their conventional co-occurrence based form (Gabrilovich and Markovitch, 2007; Landauer and Dumais, 1997; Turney and Pantel, 2010; Bullinaria and Levy, 2012), or the more recent predictive models (Mikolov et al., 2013; Collobert and Weston, 2008; Pennington et al., 2014), are restricted in two ways: (1) they cannot be used to compare word senses; and (2) they cannot be directly applied to cross-lingual semantic similarity. Though the first problem has been solved by multi-prototype models (Huang et al., 2012), or by the sense-specific representations obtained as a result of exploiting WordNet glosses (Chen et al., 2014), the second problem remains unaddressed. In contr</context>
</contexts>
<marker>Gabrilovich, Markovitch, 2007</marker>
<rawString>Evgeniy Gabrilovich and Shaul Markovitch. 2007. Computing semantic relatedness using Wikipediabased explicit semantic analysis. In Proceedings of IJCAI, pages 1606–1611.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Granada</author>
<author>Cassia Trojahn</author>
<author>Renata Vieira</author>
</authors>
<title>Comparing semantic relatedness between word pairs in Portuguese using Wikipedia.</title>
<date>2014</date>
<booktitle>In Computational Processing of the Portuguese Language,</booktitle>
<pages>170--175</pages>
<contexts>
<context position="20880" citStr="Granada et al., 2014" startWordPosition="3374" endWordPosition="3377">I – 0.19 PMI – 0.41 PMI – 0.40 PMI – 0.34 Retrofitting 0.74 – Retrofitting 0.60 – Retrofitting 0.61 – LSA-Wiki 0.69 0.65 – – – LSA-Wiki 0.52 0.57 Wiki-wup – 0.59 Wiki-wup – 0.65 SSA 0.83 0.86 Resnik – 0.72 NASARI 0.84 0.82 Lesk hyper – 0.69 ADW 0.87 0.81 Word2Vec – 0.84 PMI-SVD – 0.74 ESA – 0.72 Table 2: Spearman (p) and Pearson (r) correlation performance of different systems on the English, German and French RG-65 datasets. Wikipedia as their main knowledge resource: SSA5 (Hassan and Mihalcea, 2011), ESA (Gabrilovich and Markovitch, 2007), Wiki-wup (Ponzetto and Strube, 2007), and LSA-Wiki (Granada et al., 2014). We also provide results for systems that use distributional semantics for modeling words, both the conventional co-occurrence based approach, i.e., PMI-SVD (Baroni et al., 2014), PMI and SOC-PMI (Joubarne and Inkpen, 2011), and Retrofitting (Faruqui et al., 2015), and the newer word embeddings, i.e., Word2Vec (Mikolov et al., 2013). For Word2Vec and PMISVD, we use the pre-trained models obtained by Baroni et al. (2014).6 As for WordNet-based approaches, we report results for Resnik (Resnik, 1995) and ADW (Pilehvar et al., 2013), which take advantage of its structural information, and Lesk hy</context>
</contexts>
<marker>Granada, Trojahn, Vieira, 2014</marker>
<rawString>Roger Granada, Cassia Trojahn, and Renata Vieira. 2014. Comparing semantic relatedness between word pairs in Portuguese using Wikipedia. In Computational Processing of the Portuguese Language, pages 170–175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iryna Gurevych</author>
</authors>
<title>Using the structure of a conceptual network in computing semantic relatedness.</title>
<date>2005</date>
<booktitle>In Proceedings of IJCNLP,</booktitle>
<pages>767--778</pages>
<contexts>
<context position="18233" citStr="Gurevych, 2005" startWordPosition="2951" endWordPosition="2952"> semantics. Given a pair of words, the task in word similarity is to automatically judge their semantic similarity and, ideally, this judgement should be close to that given by humans. 3http://wordnet.princeton.edu/ glosstag.shtml 4.1.1 Datasets Monolingual. We picked the RG-65 dataset (Rubenstein and Goodenough, 1965) as our monolingual word similarity dataset. The dataset comprises 65 English word pairs which have been manually annotated by several annotators according to their similarity on a scale of 0 to 4. We also perform evaluations on the French (Joubarne and Inkpen, 2011) and German (Gurevych, 2005) adaptations of this dataset. Cross-lingual. Hassan and Mihalcea (2009) developed two sets of cross-lingual datasets based on the English MC-30 (Miller and Charles, 1991) and WordSim-353 (Finkelstein et al., 2002) datasets, for four different languages: English, German, Romanian, and Arabic. However, the construction procedure they adopted, consisting of translating the pairs to other languages while preserving the original similarity scores, has led to inconsistencies in the datasets. For instance, the Spanish dataset contains the identical pair mediodiamediodia with a similarity score of 3.4</context>
<context position="21500" citStr="Gurevych, 2005" startWordPosition="3471" endWordPosition="3472">also provide results for systems that use distributional semantics for modeling words, both the conventional co-occurrence based approach, i.e., PMI-SVD (Baroni et al., 2014), PMI and SOC-PMI (Joubarne and Inkpen, 2011), and Retrofitting (Faruqui et al., 2015), and the newer word embeddings, i.e., Word2Vec (Mikolov et al., 2013). For Word2Vec and PMISVD, we use the pre-trained models obtained by Baroni et al. (2014).6 As for WordNet-based approaches, we report results for Resnik (Resnik, 1995) and ADW (Pilehvar et al., 2013), which take advantage of its structural information, and Lesk hyper (Gurevych, 2005), which leverages definitional information in WordNet for similarity computation. Finally, we also report the performance of our earlier work NASARI (Camacho-Collados et al., 2015), which combines knowledge from WordNet and Wikipedia for the English language in its setting without the Wiktionary synonyms module. Cross-lingual. We compare the performance of our approach against the best configuration of the CL-MSR-2.0 system (Kennedy and Hirst, 2012), which exploits Pointwise Mutual Information (PMI) on a parallel corpus obtained from 5SSA involves several parameters tuned on datasets that are </context>
</contexts>
<marker>Gurevych, 2005</marker>
<rawString>Iryna Gurevych. 2005. Using the structure of a conceptual network in computing semantic relatedness. In Proceedings of IJCNLP, pages 767–778.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoan Guti´errez</author>
<author>Yenier Casta˜neda</author>
<author>Andy Gonz´alez</author>
<author>Rainel Estrada</author>
<author>D Dennys Piug</author>
<author>I Jose Abreu</author>
<author>Roger P´erez</author>
<author>Antonio Fern´andez Orqu´ın</author>
<author>Andr´es Montoyo</author>
<author>Rafael Mu˜noz</author>
<author>Franc Camara</author>
</authors>
<title>UMCC DLSI: Reinforcing a ranking algorithm with sense frequencies and multidimensional semantic resources to solve multilingual word sense disambiguation.</title>
<date>2013</date>
<booktitle>In Proceedings of SemEval</booktitle>
<pages>241--249</pages>
<marker>Guti´errez, Casta˜neda, Gonz´alez, Estrada, Piug, Abreu, P´erez, Orqu´ın, Montoyo, Mu˜noz, Camara, 2013</marker>
<rawString>Yoan Guti´errez, Yenier Casta˜neda, Andy Gonz´alez, Rainel Estrada, D. Dennys Piug, I. Jose Abreu, Roger P´erez, Antonio Fern´andez Orqu´ın, Andr´es Montoyo, Rafael Mu˜noz, and Franc Camara. 2013. UMCC DLSI: Reinforcing a ranking algorithm with sense frequencies and multidimensional semantic resources to solve multilingual word sense disambiguation. In Proceedings of SemEval 2013, pages 241–249.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<date>1954</date>
<booktitle>Distributional structure. Word,</booktitle>
<pages>10--146</pages>
<contexts>
<context position="1542" citStr="Harris, 1954" startWordPosition="214" endWordPosition="216"> similarity and Word Sense Disambiguation, reporting state-of-the-art performance on several standard datasets. 1 Introduction Semantic representation, i.e., the task of representing a linguistic item (such as a word or a word sense) in a mathematical or machine-interpretable form, is a fundamental problem in Natural Language Processing (NLP). The Vector Space Model (VSM) is a prominent approach for semantic representation, with widespread popularity in numerous NLP applications. The prevailing methods for the computation of a vector space representation are based on distributional semantics (Harris, 1954). However, these approaches, whether in their conventional co-occurrence based form (Salton et al., 1975; Turney and Pantel, 2010; Landauer and Dooley, 2002), or in their newer predictive branch (Collobert and Weston, 2008; Mikolov et al., 2013; Baroni et al., 2014), suffer from a major drawback: they are unable to model individual word senses or concepts, as they conflate different meanings of a word into a single vectorial representation. This hinders the functionality of this group of vector space models in tasks such as Word Sense Disambiguation (WSD) that require the representation of ind</context>
</contexts>
<marker>Harris, 1954</marker>
<rawString>Zellig Harris. 1954. Distributional structure. Word, 10:146–162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samer Hassan</author>
<author>Rada Mihalcea</author>
</authors>
<title>Crosslingual semantic relatedness using encyclopedic knowledge.</title>
<date>2009</date>
<booktitle>In Proceedings ofEMNLP,</booktitle>
<pages>1192--1201</pages>
<contexts>
<context position="18304" citStr="Hassan and Mihalcea (2009)" startWordPosition="2958" endWordPosition="2961">ty is to automatically judge their semantic similarity and, ideally, this judgement should be close to that given by humans. 3http://wordnet.princeton.edu/ glosstag.shtml 4.1.1 Datasets Monolingual. We picked the RG-65 dataset (Rubenstein and Goodenough, 1965) as our monolingual word similarity dataset. The dataset comprises 65 English word pairs which have been manually annotated by several annotators according to their similarity on a scale of 0 to 4. We also perform evaluations on the French (Joubarne and Inkpen, 2011) and German (Gurevych, 2005) adaptations of this dataset. Cross-lingual. Hassan and Mihalcea (2009) developed two sets of cross-lingual datasets based on the English MC-30 (Miller and Charles, 1991) and WordSim-353 (Finkelstein et al., 2002) datasets, for four different languages: English, German, Romanian, and Arabic. However, the construction procedure they adopted, consisting of translating the pairs to other languages while preserving the original similarity scores, has led to inconsistencies in the datasets. For instance, the Spanish dataset contains the identical pair mediodiamediodia with a similarity score of 3.42 (in the scale [0,4]). Additionally, the datasets contain several orth</context>
</contexts>
<marker>Hassan, Mihalcea, 2009</marker>
<rawString>Samer Hassan and Rada Mihalcea. 2009. Crosslingual semantic relatedness using encyclopedic knowledge. In Proceedings ofEMNLP, pages 1192– 1201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samer Hassan</author>
<author>Rada Mihalcea</author>
</authors>
<title>Semantic relatedness using salient semantic analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of AAAI,</booktitle>
<pages>884--889</pages>
<contexts>
<context position="20765" citStr="Hassan and Mihalcea, 2011" startWordPosition="3358" endWordPosition="3361">nglish p r German p r French p r MUFFIN 0.83 0.84 MUFFIN 0.77 0.76 MUFFIN 0.71 0.77 SOC-PMI – 0.61 SOC-PMI – 0.27 SOC-PMI – 0.19 PMI – 0.41 PMI – 0.40 PMI – 0.34 Retrofitting 0.74 – Retrofitting 0.60 – Retrofitting 0.61 – LSA-Wiki 0.69 0.65 – – – LSA-Wiki 0.52 0.57 Wiki-wup – 0.59 Wiki-wup – 0.65 SSA 0.83 0.86 Resnik – 0.72 NASARI 0.84 0.82 Lesk hyper – 0.69 ADW 0.87 0.81 Word2Vec – 0.84 PMI-SVD – 0.74 ESA – 0.72 Table 2: Spearman (p) and Pearson (r) correlation performance of different systems on the English, German and French RG-65 datasets. Wikipedia as their main knowledge resource: SSA5 (Hassan and Mihalcea, 2011), ESA (Gabrilovich and Markovitch, 2007), Wiki-wup (Ponzetto and Strube, 2007), and LSA-Wiki (Granada et al., 2014). We also provide results for systems that use distributional semantics for modeling words, both the conventional co-occurrence based approach, i.e., PMI-SVD (Baroni et al., 2014), PMI and SOC-PMI (Joubarne and Inkpen, 2011), and Retrofitting (Faruqui et al., 2015), and the newer word embeddings, i.e., Word2Vec (Mikolov et al., 2013). For Word2Vec and PMISVD, we use the pre-trained models obtained by Baroni et al. (2014).6 As for WordNet-based approaches, we report results for Res</context>
</contexts>
<marker>Hassan, Mihalcea, 2011</marker>
<rawString>Samer Hassan and Rada Mihalcea. 2011. Semantic relatedness using salient semantic analysis. In Proceedings of AAAI, pages 884,889.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard H Hovy</author>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>Collaboratively built semistructured content and Artificial Intelligence: The story so far.</title>
<date>2013</date>
<journal>Artificial Intelligence,</journal>
<pages>194--2</pages>
<contexts>
<context position="31731" citStr="Hovy et al., 2013" startWordPosition="5085" endWordPosition="5088">a, 2007; Navigli and Lapata, 2007; Agirre and Soroa, 2009) significantly improve the coverage of supervised systems. However, similarly to their supervised counterparts, knowledge-based techniques are usually limited to the English language. Recent years have seen a growing interest in cross-lingual and multilingual WSD (Lefever and Hoste, 2010; Lefever and Hoste, 2013; Navigli et al., 2013). Multilinguality is usually offered by methods that exploit the structural information of large-scale multilingual lexical resources such as Wikipedia (Guti´errez et al., 2013; Manion and Sainudiin, 2013; Hovy et al., 2013). Babelfy (Moro et al., 2014) is an approach with state-ofthe-art performance that relies on random walks 748 on BabelNet multilingual semantic network (Navigli and Ponzetto, 2012a) and densest subgraph heuristics. However, the approach is limited to the WSD and Entity Linking tasks. In contrast, our approach is global as it can be used in different NLP tasks, including WSD. Semantic similarity. Semantic similarity of word pairs is usually computed either on the basis of the structural properties of lexical databases and thesauri, or by comparing vectorial representations of words learned from</context>
</contexts>
<marker>Hovy, Navigli, Ponzetto, 2013</marker>
<rawString>Eduard H. Hovy, Roberto Navigli, and Simone Paolo Ponzetto. 2013. Collaboratively built semistructured content and Artificial Intelligence: The story so far. Artificial Intelligence, 194:2–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric H Huang</author>
<author>Richard Socher</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Improving word representations via global context and multiple word prototypes.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>873--882</pages>
<contexts>
<context position="2371" citStr="Huang et al., 2012" startWordPosition="347" endWordPosition="350">Weston, 2008; Mikolov et al., 2013; Baroni et al., 2014), suffer from a major drawback: they are unable to model individual word senses or concepts, as they conflate different meanings of a word into a single vectorial representation. This hinders the functionality of this group of vector space models in tasks such as Word Sense Disambiguation (WSD) that require the representation of individual word senses. There have been several efforts to adapt and apply distributional approaches to the representation of word senses (Pantel and Lin, 2002; Brody and Lapata, 2009; Reisinger and Mooney, 2010; Huang et al., 2012). However, none of these techniques provides representations that are already linked to a standard sense inventory, and consequently such mapping has to be carried out either manually, or with the help of sense-annotated data. Chen et al. (2014) addressed this issue and obtained vectors for individual word senses by leveraging WordNet glosses. NASARI (Camacho-Collados et al., 2015) is another approach that obtains accurate sense-specific representations by combining the complementary knowledge from WordNet and Wikipedia. Graph-based approaches have also been successfully utilized to model indi</context>
<context position="33711" citStr="Huang et al., 2012" startWordPosition="5402" endWordPosition="5405">ble, enabling the training of models on corpora other than English. However, these approaches, either in their conventional co-occurrence based form (Gabrilovich and Markovitch, 2007; Landauer and Dumais, 1997; Turney and Pantel, 2010; Bullinaria and Levy, 2012), or the more recent predictive models (Mikolov et al., 2013; Collobert and Weston, 2008; Pennington et al., 2014), are restricted in two ways: (1) they cannot be used to compare word senses; and (2) they cannot be directly applied to cross-lingual semantic similarity. Though the first problem has been solved by multi-prototype models (Huang et al., 2012), or by the sense-specific representations obtained as a result of exploiting WordNet glosses (Chen et al., 2014), the second problem remains unaddressed. In contrast, our approach models word senses and concepts effectively, while providing a unified representation for different languages that enables cross-lingual semantic similarity. 6 Conclusions This paper presented MUFFIN, a new multilingual, unified and flexible representation of individual word senses. Thanks to its effective combination of distributional statistics and structured knowledge, the approach can compute efficient represent</context>
</contexts>
<marker>Huang, Socher, Manning, Ng, 2012</marker>
<rawString>Eric H. Huang, Richard Socher, Christopher D. Manning, and Andrew Y. Ng. 2012. Improving word representations via global context and multiple word prototypes. In Proceedings of ACL, pages 873–882.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thad Hughes</author>
<author>Daniel Ramage</author>
</authors>
<title>Lexical semantic relatedness with random graph walks.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL,</booktitle>
<pages>581--589</pages>
<contexts>
<context position="3008" citStr="Hughes and Ramage, 2007" startWordPosition="440" endWordPosition="443">e of these techniques provides representations that are already linked to a standard sense inventory, and consequently such mapping has to be carried out either manually, or with the help of sense-annotated data. Chen et al. (2014) addressed this issue and obtained vectors for individual word senses by leveraging WordNet glosses. NASARI (Camacho-Collados et al., 2015) is another approach that obtains accurate sense-specific representations by combining the complementary knowledge from WordNet and Wikipedia. Graph-based approaches have also been successfully utilized to model individual words (Hughes and Ramage, 2007; Agirre et al., 2009; Yeh et al., 2009), or concepts (Pilehvar et al., 2013; Pilehvar and Navigli, 2014), drawing on the structural properties of semantic networks. The applicability of all these techniques, however, is usually either constrained to a single language (usually English), or to a specific task. We put forward MUFFIN (Multilingual, UniFied and Flexible INterpretation), a novel method that exploits both structural knowledge derived from semantic networks and distributional statistics from text corpora, to produce effective representations of individual word senses or concepts. Our</context>
</contexts>
<marker>Hughes, Ramage, 2007</marker>
<rawString>Thad Hughes and Daniel Ramage. 2007. Lexical semantic relatedness with random graph walks. In Proceedings of EMNLP-CoNLL, pages 581–589.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mario Jarmasz</author>
<author>Stan Szpakowicz</author>
</authors>
<title>Roget’s thesaurus and semantic similarity.</title>
<date>2003</date>
<booktitle>In Proceedings of RANLP,</booktitle>
<pages>212--219</pages>
<contexts>
<context position="32599" citStr="Jarmasz and Szpakowicz, 2003" startWordPosition="5222" endWordPosition="5226"> limited to the WSD and Entity Linking tasks. In contrast, our approach is global as it can be used in different NLP tasks, including WSD. Semantic similarity. Semantic similarity of word pairs is usually computed either on the basis of the structural properties of lexical databases and thesauri, or by comparing vectorial representations of words learned from massive text corpora. Structural approaches usually measure the similarity on the basis of the distance information on semantic networks, such as WordNet (Budanitsky and Hirst, 2006), or thesauri, such as Roget’s (Morris and Hirst, 1991; Jarmasz and Szpakowicz, 2003). The semantic network of WordNet has also been used in more sophisticated techniques such as those based on random graph walks (Ramage et al., 2009; Pilehvar et al., 2013), or coupled with the complementary knowledge from Wikipedia (Camacho-Collados et al., 2015). However, these techniques are either limited in the languages to which they can be applied, or in their applicability to tasks other than semantic similarity (Navigli and Ponzetto, 2012b). Corpus-based techniques are more flexible, enabling the training of models on corpora other than English. However, these approaches, either in th</context>
</contexts>
<marker>Jarmasz, Szpakowicz, 2003</marker>
<rawString>Mario Jarmasz and Stan Szpakowicz. 2003. Roget’s thesaurus and semantic similarity. In Proceedings of RANLP, pages 212–219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Sp¨arck Jones</author>
</authors>
<title>A statistical interpretation of term specificity and its application in retrieval.</title>
<date>1972</date>
<journal>Journal of Documentation,</journal>
<pages>28--11</pages>
<contexts>
<context position="7353" citStr="Jones, 1972" startWordPosition="1104" endWordPosition="1105">highly relevant words from a sub-corpus, the measure has recently gained popularity in different NLP applications, such as textual data analysis (Lebart et al., 1998), term extraction (Drouin, 2003), and domain-based term disambiguation (Camacho-Collados et al., 2014; Billami et al., 2014). We leverage lexical specificity to compute the weights in our vectors. In our earlier work (Camacho-Collados et al., 2015), we conducted different experiments which demonstrated the improvement that lexical specificity can provide over the popular term frequency-inverse document frequency weighting scheme (Jones, 1972, tf-idf). Lexical specificity computes the vector weights for an item, i.e., a word or a set of words, by comparing and contrasting its contextual information with a reference corpus. In our setting, we take the whole Wikipedia as our reference corpus RC (we use the October 2012 Wikipedia dump). 742 Let T and t be the respective total number of tokens in RC and SC,, while F and f denote the frequency of a given item in RC and SC,, respectively. Our goal is to compute a weight denoting the association of an item to the concept c. For notational brevity, we use the following expression to refer</context>
</contexts>
<marker>Jones, 1972</marker>
<rawString>Karen Sp¨arck Jones. 1972. A statistical interpretation of term specificity and its application in retrieval. Journal of Documentation, 28:11–21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colette Joubarne</author>
<author>Diana Inkpen</author>
</authors>
<title>Comparison of semantic similarity for different languages using the Google n-gram corpus and second-order co-occurrence measures.</title>
<date>2011</date>
<booktitle>In Advances in Artificial Intelligence,</booktitle>
<pages>216--221</pages>
<contexts>
<context position="18205" citStr="Joubarne and Inkpen, 2011" startWordPosition="2945" endWordPosition="2948">opular evaluation frameworks in lexical semantics. Given a pair of words, the task in word similarity is to automatically judge their semantic similarity and, ideally, this judgement should be close to that given by humans. 3http://wordnet.princeton.edu/ glosstag.shtml 4.1.1 Datasets Monolingual. We picked the RG-65 dataset (Rubenstein and Goodenough, 1965) as our monolingual word similarity dataset. The dataset comprises 65 English word pairs which have been manually annotated by several annotators according to their similarity on a scale of 0 to 4. We also perform evaluations on the French (Joubarne and Inkpen, 2011) and German (Gurevych, 2005) adaptations of this dataset. Cross-lingual. Hassan and Mihalcea (2009) developed two sets of cross-lingual datasets based on the English MC-30 (Miller and Charles, 1991) and WordSim-353 (Finkelstein et al., 2002) datasets, for four different languages: English, German, Romanian, and Arabic. However, the construction procedure they adopted, consisting of translating the pairs to other languages while preserving the original similarity scores, has led to inconsistencies in the datasets. For instance, the Spanish dataset contains the identical pair mediodiamediodia wi</context>
<context position="21104" citStr="Joubarne and Inkpen, 2011" startWordPosition="3407" endWordPosition="3410">.82 Lesk hyper – 0.69 ADW 0.87 0.81 Word2Vec – 0.84 PMI-SVD – 0.74 ESA – 0.72 Table 2: Spearman (p) and Pearson (r) correlation performance of different systems on the English, German and French RG-65 datasets. Wikipedia as their main knowledge resource: SSA5 (Hassan and Mihalcea, 2011), ESA (Gabrilovich and Markovitch, 2007), Wiki-wup (Ponzetto and Strube, 2007), and LSA-Wiki (Granada et al., 2014). We also provide results for systems that use distributional semantics for modeling words, both the conventional co-occurrence based approach, i.e., PMI-SVD (Baroni et al., 2014), PMI and SOC-PMI (Joubarne and Inkpen, 2011), and Retrofitting (Faruqui et al., 2015), and the newer word embeddings, i.e., Word2Vec (Mikolov et al., 2013). For Word2Vec and PMISVD, we use the pre-trained models obtained by Baroni et al. (2014).6 As for WordNet-based approaches, we report results for Resnik (Resnik, 1995) and ADW (Pilehvar et al., 2013), which take advantage of its structural information, and Lesk hyper (Gurevych, 2005), which leverages definitional information in WordNet for similarity computation. Finally, we also report the performance of our earlier work NASARI (Camacho-Collados et al., 2015), which combines knowled</context>
</contexts>
<marker>Joubarne, Inkpen, 2011</marker>
<rawString>Colette Joubarne and Diana Inkpen. 2011. Comparison of semantic similarity for different languages using the Google n-gram corpus and second-order co-occurrence measures. In Advances in Artificial Intelligence, pages 216–221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alistair Kennedy</author>
<author>Graeme Hirst</author>
</authors>
<title>Measuring semantic relatedness across languages.</title>
<date>2012</date>
<booktitle>In Proceedings of xLiTe: Cross-Lingual Technologies Workshop at the Neural Information Processing Systems Conference.</booktitle>
<contexts>
<context position="19113" citStr="Kennedy and Hirst (2012)" startWordPosition="3079" endWordPosition="3082">glish, German, Romanian, and Arabic. However, the construction procedure they adopted, consisting of translating the pairs to other languages while preserving the original similarity scores, has led to inconsistencies in the datasets. For instance, the Spanish dataset contains the identical pair mediodiamediodia with a similarity score of 3.42 (in the scale [0,4]). Additionally, the datasets contain several orthographic errors, such as despliege and grua (instead of despliegue and grua) and incorrect translations (e.g., the English noun implement translated into the Spanish verb implementar). Kennedy and Hirst (2012) proposed a more reliable procedure that leverages two existing aligned monolingual word similarity datasets for the construction of a new cross-lingual dataset. To this end, for each two word pairs a-b and a’-b’ in the two datasets, if the difference in the corresponding scores is greater than one, the pairs are discarded. Otherwise, two new pairs a-b’ and a’-b are created with a score equal to the average of the two original pairs’ scores. In the case of repeated pairs, we merge them into a single pair with a similarity equal to their average scores. Using this procedure as a basis, Kennedy </context>
<context position="21953" citStr="Kennedy and Hirst, 2012" startWordPosition="3533" endWordPosition="3536">pproaches, we report results for Resnik (Resnik, 1995) and ADW (Pilehvar et al., 2013), which take advantage of its structural information, and Lesk hyper (Gurevych, 2005), which leverages definitional information in WordNet for similarity computation. Finally, we also report the performance of our earlier work NASARI (Camacho-Collados et al., 2015), which combines knowledge from WordNet and Wikipedia for the English language in its setting without the Wiktionary synonyms module. Cross-lingual. We compare the performance of our approach against the best configuration of the CL-MSR-2.0 system (Kennedy and Hirst, 2012), which exploits Pointwise Mutual Information (PMI) on a parallel corpus obtained from 5SSA involves several parameters tuned on datasets that are constructed on the basis of MC-30 and RG-65. 6We report the best configuration of the systems on the RG-65 dataset out of their 48 configurations. The corpus used to train the models contained 2.8 billion tokens, including Wikipedia (Baroni et al., 2014). the English and French versions of WordNet. Since two of our cross-lingual datasets are newlycreated, we developed three baseline systems to enable a more meaningful comparison. To this end, we fir</context>
</contexts>
<marker>Kennedy, Hirst, 2012</marker>
<rawString>Alistair Kennedy and Graeme Hirst. 2012. Measuring semantic relatedness across languages. In Proceedings of xLiTe: Cross-Lingual Technologies Workshop at the Neural Information Processing Systems Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Lafon</author>
</authors>
<title>Sur la variabilit´e de la fr´equence des formes dans un corpus.</title>
<date>1980</date>
<journal>Mots,</journal>
<pages>1--127</pages>
<contexts>
<context position="6629" citStr="Lafon, 1980" startWordPosition="995" endWordPosition="996"> concept, which in our setting is a BabelNet synset, and let W, be the set containing the Wikipedia page p corresponding to the concept c and all the Wikipedia pages having an outgoing link to p. We further enrich W, with the corresponding Wikipedia pages of the hypernyms and hyponyms of c in the BabelNet network. W, is the set of Wikipedia pages whose contents are exploited to build a representation for the concept c. We refer to the bag of content words in all the Wikipedia pages in W, as the sub-corpus SC, for the concept c. 2.2 Vector construction: lexical specificity Lexical specificity (Lafon, 1980) is a statistical measure based on the hypergeometric distribution. Due to its efficiency in extracting a set of highly relevant words from a sub-corpus, the measure has recently gained popularity in different NLP applications, such as textual data analysis (Lebart et al., 1998), term extraction (Drouin, 2003), and domain-based term disambiguation (Camacho-Collados et al., 2014; Billami et al., 2014). We leverage lexical specificity to compute the weights in our vectors. In our earlier work (Camacho-Collados et al., 2015), we conducted different experiments which demonstrated the improvement t</context>
</contexts>
<marker>Lafon, 1980</marker>
<rawString>Pierre Lafon. 1980. Sur la variabilit´e de la fr´equence des formes dans un corpus. Mots, 1:127–165.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom Landauer</author>
<author>Scott Dooley</author>
</authors>
<title>Latent semantic analysis: theory, method and application.</title>
<date>2002</date>
<booktitle>In Proceedings of CSCL,</booktitle>
<pages>742--743</pages>
<contexts>
<context position="1699" citStr="Landauer and Dooley, 2002" startWordPosition="235" endWordPosition="239">tation, i.e., the task of representing a linguistic item (such as a word or a word sense) in a mathematical or machine-interpretable form, is a fundamental problem in Natural Language Processing (NLP). The Vector Space Model (VSM) is a prominent approach for semantic representation, with widespread popularity in numerous NLP applications. The prevailing methods for the computation of a vector space representation are based on distributional semantics (Harris, 1954). However, these approaches, whether in their conventional co-occurrence based form (Salton et al., 1975; Turney and Pantel, 2010; Landauer and Dooley, 2002), or in their newer predictive branch (Collobert and Weston, 2008; Mikolov et al., 2013; Baroni et al., 2014), suffer from a major drawback: they are unable to model individual word senses or concepts, as they conflate different meanings of a word into a single vectorial representation. This hinders the functionality of this group of vector space models in tasks such as Word Sense Disambiguation (WSD) that require the representation of individual word senses. There have been several efforts to adapt and apply distributional approaches to the representation of word senses (Pantel and Lin, 2002;</context>
</contexts>
<marker>Landauer, Dooley, 2002</marker>
<rawString>Tom Landauer and Scott Dooley. 2002. Latent semantic analysis: theory, method and application. In Proceedings of CSCL, pages 742–743.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas K Landauer</author>
<author>Susan T Dumais</author>
</authors>
<title>A solution to Plato’s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge.</title>
<date>1997</date>
<journal>Psychological Review,</journal>
<volume>104</volume>
<issue>2</issue>
<contexts>
<context position="33301" citStr="Landauer and Dumais, 1997" startWordPosition="5332" endWordPosition="5335">chniques such as those based on random graph walks (Ramage et al., 2009; Pilehvar et al., 2013), or coupled with the complementary knowledge from Wikipedia (Camacho-Collados et al., 2015). However, these techniques are either limited in the languages to which they can be applied, or in their applicability to tasks other than semantic similarity (Navigli and Ponzetto, 2012b). Corpus-based techniques are more flexible, enabling the training of models on corpora other than English. However, these approaches, either in their conventional co-occurrence based form (Gabrilovich and Markovitch, 2007; Landauer and Dumais, 1997; Turney and Pantel, 2010; Bullinaria and Levy, 2012), or the more recent predictive models (Mikolov et al., 2013; Collobert and Weston, 2008; Pennington et al., 2014), are restricted in two ways: (1) they cannot be used to compare word senses; and (2) they cannot be directly applied to cross-lingual semantic similarity. Though the first problem has been solved by multi-prototype models (Huang et al., 2012), or by the sense-specific representations obtained as a result of exploiting WordNet glosses (Chen et al., 2014), the second problem remains unaddressed. In contrast, our approach models wo</context>
</contexts>
<marker>Landauer, Dumais, 1997</marker>
<rawString>Thomas K Landauer and Susan T Dumais. 1997. A solution to Plato’s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological Review, 104(2):211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ludovic Lebart</author>
<author>A Salem</author>
<author>Lisette Berry</author>
</authors>
<title>Exploring textual data.</title>
<date>1998</date>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="6908" citStr="Lebart et al., 1998" startWordPosition="1039" endWordPosition="1042">s and hyponyms of c in the BabelNet network. W, is the set of Wikipedia pages whose contents are exploited to build a representation for the concept c. We refer to the bag of content words in all the Wikipedia pages in W, as the sub-corpus SC, for the concept c. 2.2 Vector construction: lexical specificity Lexical specificity (Lafon, 1980) is a statistical measure based on the hypergeometric distribution. Due to its efficiency in extracting a set of highly relevant words from a sub-corpus, the measure has recently gained popularity in different NLP applications, such as textual data analysis (Lebart et al., 1998), term extraction (Drouin, 2003), and domain-based term disambiguation (Camacho-Collados et al., 2014; Billami et al., 2014). We leverage lexical specificity to compute the weights in our vectors. In our earlier work (Camacho-Collados et al., 2015), we conducted different experiments which demonstrated the improvement that lexical specificity can provide over the popular term frequency-inverse document frequency weighting scheme (Jones, 1972, tf-idf). Lexical specificity computes the vector weights for an item, i.e., a word or a set of words, by comparing and contrasting its contextual informa</context>
</contexts>
<marker>Lebart, Salem, Berry, 1998</marker>
<rawString>Ludovic Lebart, A Salem, and Lisette Berry. 1998. Exploring textual data. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Els Lefever</author>
<author>Veronique Hoste</author>
</authors>
<title>SemEval2010 Task 3: Cross-lingual Word Sense Disambiguation.</title>
<date>2010</date>
<booktitle>In Proceedings of SemEval</booktitle>
<pages>82--87</pages>
<location>Uppsala,</location>
<contexts>
<context position="31459" citStr="Lefever and Hoste, 2010" startWordPosition="5045" endWordPosition="5048">vided with suitable amounts of sense-annotated data, their applicability is limited to those words and languages for which such data is available, practically limiting them to a small subset of words mainly in the English language. Knowledge-based approaches (Sinha and Mihalcea, 2007; Navigli and Lapata, 2007; Agirre and Soroa, 2009) significantly improve the coverage of supervised systems. However, similarly to their supervised counterparts, knowledge-based techniques are usually limited to the English language. Recent years have seen a growing interest in cross-lingual and multilingual WSD (Lefever and Hoste, 2010; Lefever and Hoste, 2013; Navigli et al., 2013). Multilinguality is usually offered by methods that exploit the structural information of large-scale multilingual lexical resources such as Wikipedia (Guti´errez et al., 2013; Manion and Sainudiin, 2013; Hovy et al., 2013). Babelfy (Moro et al., 2014) is an approach with state-ofthe-art performance that relies on random walks 748 on BabelNet multilingual semantic network (Navigli and Ponzetto, 2012a) and densest subgraph heuristics. However, the approach is limited to the WSD and Entity Linking tasks. In contrast, our approach is global as it c</context>
</contexts>
<marker>Lefever, Hoste, 2010</marker>
<rawString>Els Lefever and Veronique Hoste. 2010. SemEval2010 Task 3: Cross-lingual Word Sense Disambiguation. In Proceedings of SemEval 2010, pages 82–87, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Els Lefever</author>
<author>Veronique Hoste</author>
</authors>
<title>SemEval2013 Task 10: Cross-lingual Word Sense Disambiguation.</title>
<date>2013</date>
<booktitle>In Proceedings of SemEval 2013,</booktitle>
<pages>158--166</pages>
<location>Atlanta, USA.</location>
<contexts>
<context position="31484" citStr="Lefever and Hoste, 2013" startWordPosition="5049" endWordPosition="5052">ts of sense-annotated data, their applicability is limited to those words and languages for which such data is available, practically limiting them to a small subset of words mainly in the English language. Knowledge-based approaches (Sinha and Mihalcea, 2007; Navigli and Lapata, 2007; Agirre and Soroa, 2009) significantly improve the coverage of supervised systems. However, similarly to their supervised counterparts, knowledge-based techniques are usually limited to the English language. Recent years have seen a growing interest in cross-lingual and multilingual WSD (Lefever and Hoste, 2010; Lefever and Hoste, 2013; Navigli et al., 2013). Multilinguality is usually offered by methods that exploit the structural information of large-scale multilingual lexical resources such as Wikipedia (Guti´errez et al., 2013; Manion and Sainudiin, 2013; Hovy et al., 2013). Babelfy (Moro et al., 2014) is an approach with state-ofthe-art performance that relies on random walks 748 on BabelNet multilingual semantic network (Navigli and Ponzetto, 2012a) and densest subgraph heuristics. However, the approach is limited to the WSD and Entity Linking tasks. In contrast, our approach is global as it can be used in different N</context>
</contexts>
<marker>Lefever, Hoste, 2013</marker>
<rawString>Els Lefever and Veronique Hoste. 2013. SemEval2013 Task 10: Cross-lingual Word Sense Disambiguation. In Proceedings of SemEval 2013, pages 158–166, Atlanta, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve L Manion</author>
<author>Raazesh Sainudiin</author>
</authors>
<title>Daebak!: Peripheral diversity for multilingual Word Sense Disambiguation.</title>
<date>2013</date>
<booktitle>In Proceedings of SemEval</booktitle>
<pages>250--254</pages>
<contexts>
<context position="31711" citStr="Manion and Sainudiin, 2013" startWordPosition="5081" endWordPosition="5084">pproaches (Sinha and Mihalcea, 2007; Navigli and Lapata, 2007; Agirre and Soroa, 2009) significantly improve the coverage of supervised systems. However, similarly to their supervised counterparts, knowledge-based techniques are usually limited to the English language. Recent years have seen a growing interest in cross-lingual and multilingual WSD (Lefever and Hoste, 2010; Lefever and Hoste, 2013; Navigli et al., 2013). Multilinguality is usually offered by methods that exploit the structural information of large-scale multilingual lexical resources such as Wikipedia (Guti´errez et al., 2013; Manion and Sainudiin, 2013; Hovy et al., 2013). Babelfy (Moro et al., 2014) is an approach with state-ofthe-art performance that relies on random walks 748 on BabelNet multilingual semantic network (Navigli and Ponzetto, 2012a) and densest subgraph heuristics. However, the approach is limited to the WSD and Entity Linking tasks. In contrast, our approach is global as it can be used in different NLP tasks, including WSD. Semantic similarity. Semantic similarity of word pairs is usually computed either on the basis of the structural properties of lexical databases and thesauri, or by comparing vectorial representations o</context>
</contexts>
<marker>Manion, Sainudiin, 2013</marker>
<rawString>Steve L. Manion and Raazesh Sainudiin. 2013. Daebak!: Peripheral diversity for multilingual Word Sense Disambiguation. In Proceedings of SemEval 2013, pages 250–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Kai Chen</author>
<author>Greg Corrado</author>
<author>Jeffrey Dean</author>
</authors>
<title>Efficient estimation of word representations in vector space.</title>
<date>2013</date>
<location>CoRR, abs/1301.3781.</location>
<contexts>
<context position="1786" citStr="Mikolov et al., 2013" startWordPosition="251" endWordPosition="254">a mathematical or machine-interpretable form, is a fundamental problem in Natural Language Processing (NLP). The Vector Space Model (VSM) is a prominent approach for semantic representation, with widespread popularity in numerous NLP applications. The prevailing methods for the computation of a vector space representation are based on distributional semantics (Harris, 1954). However, these approaches, whether in their conventional co-occurrence based form (Salton et al., 1975; Turney and Pantel, 2010; Landauer and Dooley, 2002), or in their newer predictive branch (Collobert and Weston, 2008; Mikolov et al., 2013; Baroni et al., 2014), suffer from a major drawback: they are unable to model individual word senses or concepts, as they conflate different meanings of a word into a single vectorial representation. This hinders the functionality of this group of vector space models in tasks such as Word Sense Disambiguation (WSD) that require the representation of individual word senses. There have been several efforts to adapt and apply distributional approaches to the representation of word senses (Pantel and Lin, 2002; Brody and Lapata, 2009; Reisinger and Mooney, 2010; Huang et al., 2012). However, none</context>
<context position="21215" citStr="Mikolov et al., 2013" startWordPosition="3424" endWordPosition="3427">correlation performance of different systems on the English, German and French RG-65 datasets. Wikipedia as their main knowledge resource: SSA5 (Hassan and Mihalcea, 2011), ESA (Gabrilovich and Markovitch, 2007), Wiki-wup (Ponzetto and Strube, 2007), and LSA-Wiki (Granada et al., 2014). We also provide results for systems that use distributional semantics for modeling words, both the conventional co-occurrence based approach, i.e., PMI-SVD (Baroni et al., 2014), PMI and SOC-PMI (Joubarne and Inkpen, 2011), and Retrofitting (Faruqui et al., 2015), and the newer word embeddings, i.e., Word2Vec (Mikolov et al., 2013). For Word2Vec and PMISVD, we use the pre-trained models obtained by Baroni et al. (2014).6 As for WordNet-based approaches, we report results for Resnik (Resnik, 1995) and ADW (Pilehvar et al., 2013), which take advantage of its structural information, and Lesk hyper (Gurevych, 2005), which leverages definitional information in WordNet for similarity computation. Finally, we also report the performance of our earlier work NASARI (Camacho-Collados et al., 2015), which combines knowledge from WordNet and Wikipedia for the English language in its setting without the Wiktionary synonyms module. C</context>
<context position="22924" citStr="Mikolov et al., 2013" startWordPosition="3686" endWordPosition="3689"> tokens, including Wikipedia (Baroni et al., 2014). the English and French versions of WordNet. Since two of our cross-lingual datasets are newlycreated, we developed three baseline systems to enable a more meaningful comparison. To this end, we first use Google Translate to translate the non-English side of the dataset to the English language. Accordingly, three state-of-the-art graphbased and corpus-based approaches were used to measure the similarity of the resulting English pairs. As English similarity measurement systems, we opted for ADW (Pilehvar et al., 2013), and the best predictive (Mikolov et al., 2013, Word2Vec) and co-occurrence (i.e., PMI-SVD) models obtained by Baroni et al. (2014).7 In our experiments we refer to these systems as pivot, since they use English as a pivot for computing semantic similarity. As a comparison, we also show results for MUFFINpivot, which is the variant of our system applied to the same automatically translated monolingual datasets. 4.1.3 Results Monolingual. We show in Table 2 the performance of different systems in terms of Spearman and Pearson correlations on the English, German, and French RG-65 datasets. On the German and French datasets, our system outpe</context>
<context position="33414" citStr="Mikolov et al., 2013" startWordPosition="5352" endWordPosition="5355">omplementary knowledge from Wikipedia (Camacho-Collados et al., 2015). However, these techniques are either limited in the languages to which they can be applied, or in their applicability to tasks other than semantic similarity (Navigli and Ponzetto, 2012b). Corpus-based techniques are more flexible, enabling the training of models on corpora other than English. However, these approaches, either in their conventional co-occurrence based form (Gabrilovich and Markovitch, 2007; Landauer and Dumais, 1997; Turney and Pantel, 2010; Bullinaria and Levy, 2012), or the more recent predictive models (Mikolov et al., 2013; Collobert and Weston, 2008; Pennington et al., 2014), are restricted in two ways: (1) they cannot be used to compare word senses; and (2) they cannot be directly applied to cross-lingual semantic similarity. Though the first problem has been solved by multi-prototype models (Huang et al., 2012), or by the sense-specific representations obtained as a result of exploiting WordNet glosses (Chen et al., 2014), the second problem remains unaddressed. In contrast, our approach models word senses and concepts effectively, while providing a unified representation for different languages that enables</context>
</contexts>
<marker>Mikolov, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. CoRR, abs/1301.3781.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Walter G Charles</author>
</authors>
<title>Contextual correlates of semantic similarity.</title>
<date>1991</date>
<booktitle>Language and Cognitive Processes,</booktitle>
<pages>6--1</pages>
<contexts>
<context position="18403" citStr="Miller and Charles, 1991" startWordPosition="2974" endWordPosition="2977">to that given by humans. 3http://wordnet.princeton.edu/ glosstag.shtml 4.1.1 Datasets Monolingual. We picked the RG-65 dataset (Rubenstein and Goodenough, 1965) as our monolingual word similarity dataset. The dataset comprises 65 English word pairs which have been manually annotated by several annotators according to their similarity on a scale of 0 to 4. We also perform evaluations on the French (Joubarne and Inkpen, 2011) and German (Gurevych, 2005) adaptations of this dataset. Cross-lingual. Hassan and Mihalcea (2009) developed two sets of cross-lingual datasets based on the English MC-30 (Miller and Charles, 1991) and WordSim-353 (Finkelstein et al., 2002) datasets, for four different languages: English, German, Romanian, and Arabic. However, the construction procedure they adopted, consisting of translating the pairs to other languages while preserving the original similarity scores, has led to inconsistencies in the datasets. For instance, the Spanish dataset contains the identical pair mediodiamediodia with a similarity score of 3.42 (in the scale [0,4]). Additionally, the datasets contain several orthographic errors, such as despliege and grua (instead of despliegue and grua) and incorrect translat</context>
</contexts>
<marker>Miller, Charles, 1991</marker>
<rawString>George A. Miller and Walter G. Charles. 1991. Contextual correlates of semantic similarity. Language and Cognitive Processes, 6(1):1–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Claudia Leacock</author>
<author>Randee Tengi</author>
<author>Ross Bunker</author>
</authors>
<title>A semantic concordance.</title>
<date>1993</date>
<booktitle>In Proceedings of the 3rd DARPA Workshop on Human Language Technology,</booktitle>
<pages>303--308</pages>
<location>Plainsboro, N.J.</location>
<contexts>
<context position="27960" citStr="Miller et al., 1993" startWordPosition="4481" endWordPosition="4484">(SemEval-2007), respectively. As comparison system, we report the performance of the best configuration of the topperforming system in the SemEval-2013 task, i.e., UMCC-DLSI (Guti´errez et al., 2013). We also show results for the state-of-the-art supervised system (Zhong and Ng, 2010, IMS), as well as for two graph-based approaches that are based on random walks on the WordNet graph (Agirre and Soroa, 2009, UKB w2w) and the BabelNet semantic network (Moro et al., 2014, Babelfy). We follow Babelfy and also exploit the WordNet’s sense frequency information from the SemCor senseannotated corpus (Miller et al., 1993). However, instead of simply backing off to the most frequent sense, we propose a more meaningful exploitation of this information. To this end, we compute the relevance of a specific sense as the average of its normalized sense frequency and its corresponding 747 System MFS Back off Italian English French Spanish German MUFFIN ✓ 81.9 84.5 71.4 85.1 83.1 MUFFIN* 67.9 73.5 72.3 81.1 76.1 Babelfy ✓ 84.3 87.4 71.6 83.8 81.6 Best SemEval 2013 system ✓ 58.3 54.8 60.5 58.1 61.0 MFS - 82.2 80.2 69.1 82.1 83.0 Table 4: F1 percentage performance on the SemEval-2013 Multilingual WSD datasets using Wikip</context>
</contexts>
<marker>Miller, Leacock, Tengi, Bunker, 1993</marker>
<rawString>George A. Miller, Claudia Leacock, Randee Tengi, and Ross Bunker. 1993. A semantic concordance. In Proceedings of the 3rd DARPA Workshop on Human Language Technology, pages 303–308, Plainsboro, N.J.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Moro</author>
<author>Alessandro Raganato</author>
<author>Roberto Navigli</author>
</authors>
<title>Entity Linking meets Word Sense Disambiguation: a Unified Approach.</title>
<date>2014</date>
<journal>Transactions of the Association for Computational Linguistics (TACL),</journal>
<pages>2--231</pages>
<contexts>
<context position="25576" citStr="Moro et al. (2014" startWordPosition="4092" endWordPosition="4095">s proved to be highly competitive, outperforming the CL-MSR2.0 system by a considerable margin. 4.2 Word Sense Disambiguation 4.2.1 Wikipedia In this setting, we selected the SemEval 2013 allwords WSD task (Navigli et al., 2013) as our evaluation benchmark. The task provides datasets for five different languages: Italian, English, French, Spanish and German. There are on average 1123 words to disambiguate in each language’s dataset. As comparison system, we provide results for the best-performing participating system on each language. We also show results for the state-of-theart WSD system of Moro et al. (2014, Babelfy), which relies on random walks on the BabelNet semantic network and a set of graph heuristic algorithms. Finally, we also report results for the Most Frequent Sense (MFS) baseline provided by the task organizers. We follow Moro et al. (2014) and back off to the MFS baseline in the case when our system’s judgement does not meet a threshold 0. Similarly to Babelfy, we tuned the value of the threshold 0 on the trial dataset provided by the organizers of the task. We tuned 0 with step size 0.05 (hence, 21 possible values in [0,1]), obtaining an optimal value of 0.85 in the trial set, a v</context>
<context position="27812" citStr="Moro et al., 2014" startWordPosition="4458" endWordPosition="4461"> and All-Words task (Pradhan et al., 2007). The all-words datasets of the two tasks contain 1644 instances (SemEval-2013) and 162 noun instances (SemEval-2007), respectively. As comparison system, we report the performance of the best configuration of the topperforming system in the SemEval-2013 task, i.e., UMCC-DLSI (Guti´errez et al., 2013). We also show results for the state-of-the-art supervised system (Zhong and Ng, 2010, IMS), as well as for two graph-based approaches that are based on random walks on the WordNet graph (Agirre and Soroa, 2009, UKB w2w) and the BabelNet semantic network (Moro et al., 2014, Babelfy). We follow Babelfy and also exploit the WordNet’s sense frequency information from the SemCor senseannotated corpus (Miller et al., 1993). However, instead of simply backing off to the most frequent sense, we propose a more meaningful exploitation of this information. To this end, we compute the relevance of a specific sense as the average of its normalized sense frequency and its corresponding 747 System MFS Back off Italian English French Spanish German MUFFIN ✓ 81.9 84.5 71.4 85.1 83.1 MUFFIN* 67.9 73.5 72.3 81.1 76.1 Babelfy ✓ 84.3 87.4 71.6 83.8 81.6 Best SemEval 2013 system ✓ </context>
<context position="31760" citStr="Moro et al., 2014" startWordPosition="5090" endWordPosition="5093">2007; Agirre and Soroa, 2009) significantly improve the coverage of supervised systems. However, similarly to their supervised counterparts, knowledge-based techniques are usually limited to the English language. Recent years have seen a growing interest in cross-lingual and multilingual WSD (Lefever and Hoste, 2010; Lefever and Hoste, 2013; Navigli et al., 2013). Multilinguality is usually offered by methods that exploit the structural information of large-scale multilingual lexical resources such as Wikipedia (Guti´errez et al., 2013; Manion and Sainudiin, 2013; Hovy et al., 2013). Babelfy (Moro et al., 2014) is an approach with state-ofthe-art performance that relies on random walks 748 on BabelNet multilingual semantic network (Navigli and Ponzetto, 2012a) and densest subgraph heuristics. However, the approach is limited to the WSD and Entity Linking tasks. In contrast, our approach is global as it can be used in different NLP tasks, including WSD. Semantic similarity. Semantic similarity of word pairs is usually computed either on the basis of the structural properties of lexical databases and thesauri, or by comparing vectorial representations of words learned from massive text corpora. Struct</context>
</contexts>
<marker>Moro, Raganato, Navigli, 2014</marker>
<rawString>Andrea Moro, Alessandro Raganato, and Roberto Navigli. 2014. Entity Linking meets Word Sense Disambiguation: a Unified Approach. Transactions of the Association for Computational Linguistics (TACL), 2:231–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jane Morris</author>
<author>Graeme Hirst</author>
</authors>
<title>Lexical cohesion computed by thesaural relations as an indicator of the structure of text.</title>
<date>1991</date>
<journal>Computational Linguistics,</journal>
<volume>17</volume>
<issue>1</issue>
<contexts>
<context position="32568" citStr="Morris and Hirst, 1991" startWordPosition="5218" endWordPosition="5221">However, the approach is limited to the WSD and Entity Linking tasks. In contrast, our approach is global as it can be used in different NLP tasks, including WSD. Semantic similarity. Semantic similarity of word pairs is usually computed either on the basis of the structural properties of lexical databases and thesauri, or by comparing vectorial representations of words learned from massive text corpora. Structural approaches usually measure the similarity on the basis of the distance information on semantic networks, such as WordNet (Budanitsky and Hirst, 2006), or thesauri, such as Roget’s (Morris and Hirst, 1991; Jarmasz and Szpakowicz, 2003). The semantic network of WordNet has also been used in more sophisticated techniques such as those based on random graph walks (Ramage et al., 2009; Pilehvar et al., 2013), or coupled with the complementary knowledge from Wikipedia (Camacho-Collados et al., 2015). However, these techniques are either limited in the languages to which they can be applied, or in their applicability to tasks other than semantic similarity (Navigli and Ponzetto, 2012b). Corpus-based techniques are more flexible, enabling the training of models on corpora other than English. However,</context>
</contexts>
<marker>Morris, Hirst, 1991</marker>
<rawString>Jane Morris and Graeme Hirst. 1991. Lexical cohesion computed by thesaural relations as an indicator of the structure of text. Computational Linguistics, 17(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Mirella Lapata</author>
</authors>
<title>Graph connectivity measures for unsupervised Word Sense Disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of IJCAI,</booktitle>
<pages>1683--1688</pages>
<contexts>
<context position="31146" citStr="Navigli and Lapata, 2007" startWordPosition="5001" endWordPosition="5004">val-2007 (noun instances) English All-words WSD datatets using WordNet as sense inventory. (Navigli, 2009). Supervised systems such as IMS (Zhong and Ng, 2010) analyze sense-annotated data and model the context in which the various senses of a word usually appear. Despite their accuracy for the words that are provided with suitable amounts of sense-annotated data, their applicability is limited to those words and languages for which such data is available, practically limiting them to a small subset of words mainly in the English language. Knowledge-based approaches (Sinha and Mihalcea, 2007; Navigli and Lapata, 2007; Agirre and Soroa, 2009) significantly improve the coverage of supervised systems. However, similarly to their supervised counterparts, knowledge-based techniques are usually limited to the English language. Recent years have seen a growing interest in cross-lingual and multilingual WSD (Lefever and Hoste, 2010; Lefever and Hoste, 2013; Navigli et al., 2013). Multilinguality is usually offered by methods that exploit the structural information of large-scale multilingual lexical resources such as Wikipedia (Guti´errez et al., 2013; Manion and Sainudiin, 2013; Hovy et al., 2013). Babelfy (Moro</context>
</contexts>
<marker>Navigli, Lapata, 2007</marker>
<rawString>Roberto Navigli and Mirella Lapata. 2007. Graph connectivity measures for unsupervised Word Sense Disambiguation. In Proceedings of IJCAI, pages 1683–1688.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network.</title>
<date>2012</date>
<journal>Artificial Intelligence,</journal>
<volume>193</volume>
<pages>250</pages>
<contexts>
<context position="5159" citStr="Navigli and Ponzetto, 2012" startWordPosition="752" endWordPosition="755">sks in lexical semantics: semantic similarity and Word Sense Disambiguation. To assess the multilingual capability of our approach, we also perform experiments on languages other than English on both tasks, and across languages for semantic similarity. We report state-of-the-art performance on multiple datasets and settings in both frameworks, which confirms the reliability and flexibility of our representations. 2 Methodology Figure 1 illustrates our procedure for constructing the vector representation of a given concept. We use BabelNet1 (version 2.5) as our main sense repository. BabelNet (Navigli and Ponzetto, 2012a) is a multilingual encyclopedic dictionary which merges WordNet with other lexical resources, such as Wikipedia and Wiktionary, thanks to its use of an automatic mapping algorithm. BabelNet extends the WordNet synset model to take into account multilinguality: a BabelNet synset contains the words that, in the various languages, express the given concept. Our approach for modeling a BabelNet synset consists of two main steps. First, for the given synset we gather contextual information from Wikipedia by exploiting knowledge from the BabelNet semantic network (Section 2.1). Then, by analyzing </context>
<context position="31910" citStr="Navigli and Ponzetto, 2012" startWordPosition="5112" endWordPosition="5116">nowledge-based techniques are usually limited to the English language. Recent years have seen a growing interest in cross-lingual and multilingual WSD (Lefever and Hoste, 2010; Lefever and Hoste, 2013; Navigli et al., 2013). Multilinguality is usually offered by methods that exploit the structural information of large-scale multilingual lexical resources such as Wikipedia (Guti´errez et al., 2013; Manion and Sainudiin, 2013; Hovy et al., 2013). Babelfy (Moro et al., 2014) is an approach with state-ofthe-art performance that relies on random walks 748 on BabelNet multilingual semantic network (Navigli and Ponzetto, 2012a) and densest subgraph heuristics. However, the approach is limited to the WSD and Entity Linking tasks. In contrast, our approach is global as it can be used in different NLP tasks, including WSD. Semantic similarity. Semantic similarity of word pairs is usually computed either on the basis of the structural properties of lexical databases and thesauri, or by comparing vectorial representations of words learned from massive text corpora. Structural approaches usually measure the similarity on the basis of the distance information on semantic networks, such as WordNet (Budanitsky and Hirst, 2</context>
</contexts>
<marker>Navigli, Ponzetto, 2012</marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2012a. BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network. Artificial Intelligence, 193:217– 250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>BabelRelate! a joint multilingual approach to computing semantic relatedness.</title>
<date>2012</date>
<booktitle>In Proceedings of AAAI,</booktitle>
<pages>108--114</pages>
<contexts>
<context position="5159" citStr="Navigli and Ponzetto, 2012" startWordPosition="752" endWordPosition="755">sks in lexical semantics: semantic similarity and Word Sense Disambiguation. To assess the multilingual capability of our approach, we also perform experiments on languages other than English on both tasks, and across languages for semantic similarity. We report state-of-the-art performance on multiple datasets and settings in both frameworks, which confirms the reliability and flexibility of our representations. 2 Methodology Figure 1 illustrates our procedure for constructing the vector representation of a given concept. We use BabelNet1 (version 2.5) as our main sense repository. BabelNet (Navigli and Ponzetto, 2012a) is a multilingual encyclopedic dictionary which merges WordNet with other lexical resources, such as Wikipedia and Wiktionary, thanks to its use of an automatic mapping algorithm. BabelNet extends the WordNet synset model to take into account multilinguality: a BabelNet synset contains the words that, in the various languages, express the given concept. Our approach for modeling a BabelNet synset consists of two main steps. First, for the given synset we gather contextual information from Wikipedia by exploiting knowledge from the BabelNet semantic network (Section 2.1). Then, by analyzing </context>
<context position="31910" citStr="Navigli and Ponzetto, 2012" startWordPosition="5112" endWordPosition="5116">nowledge-based techniques are usually limited to the English language. Recent years have seen a growing interest in cross-lingual and multilingual WSD (Lefever and Hoste, 2010; Lefever and Hoste, 2013; Navigli et al., 2013). Multilinguality is usually offered by methods that exploit the structural information of large-scale multilingual lexical resources such as Wikipedia (Guti´errez et al., 2013; Manion and Sainudiin, 2013; Hovy et al., 2013). Babelfy (Moro et al., 2014) is an approach with state-ofthe-art performance that relies on random walks 748 on BabelNet multilingual semantic network (Navigli and Ponzetto, 2012a) and densest subgraph heuristics. However, the approach is limited to the WSD and Entity Linking tasks. In contrast, our approach is global as it can be used in different NLP tasks, including WSD. Semantic similarity. Semantic similarity of word pairs is usually computed either on the basis of the structural properties of lexical databases and thesauri, or by comparing vectorial representations of words learned from massive text corpora. Structural approaches usually measure the similarity on the basis of the distance information on semantic networks, such as WordNet (Budanitsky and Hirst, 2</context>
</contexts>
<marker>Navigli, Ponzetto, 2012</marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2012b. BabelRelate! a joint multilingual approach to computing semantic relatedness. In Proceedings of AAAI, pages 108–114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Paola Velardi</author>
</authors>
<title>Structural Semantic Interconnections: a knowledge-based approach to Word Sense Disambiguation.</title>
<date>2005</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>27</volume>
<issue>7</issue>
<contexts>
<context position="17243" citStr="Navigli and Velardi, 2005" startWordPosition="2797" endWordPosition="2800">with words). However, we do not consider those BabelNet synsets that are not associated with Wikipedia pages. WordNet sense inventory. Similarly, when restricted to the WordNet inventory, we discard those BabelNet synsets that do not contain a WordNet synset. In this setting, we also leverage relations from WordNet’s semantic network and its disambiguated glosses3 in order to obtain a richer set of Wikipedia articles in the sub-corpus construction. The enrichment of the semantic network with the disambiguated glosses has been shown to be beneficial in various graph-based disambiguation tasks (Navigli and Velardi, 2005; Agirre and Soroa, 2009; Pilehvar et al., 2013). 4 Experiments We assess the reliability of MUFFIN in two standard evaluation benchmarks: semantic similarity (Section 4.1) and Word Sense Disambiguation (Section 4.2). 4.1 Semantic Similarity As our semantic similarity experiment we opted for word similarity, which is one of the most popular evaluation frameworks in lexical semantics. Given a pair of words, the task in word similarity is to automatically judge their semantic similarity and, ideally, this judgement should be close to that given by humans. 3http://wordnet.princeton.edu/ glosstag.</context>
</contexts>
<marker>Navigli, Velardi, 2005</marker>
<rawString>Roberto Navigli and Paola Velardi. 2005. Structural Semantic Interconnections: a knowledge-based approach to Word Sense Disambiguation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(7):1075–1088.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>David Jurgens</author>
<author>Daniele Vannella</author>
</authors>
<title>SemEval-2013 Task 12: Multilingual Word Sense Disambiguation.</title>
<date>2013</date>
<booktitle>In Proceedings of SemEval</booktitle>
<pages>222--231</pages>
<contexts>
<context position="25187" citStr="Navigli et al., 2013" startWordPosition="4031" endWordPosition="4034">oving the performance of the comparison systems on all three language pairs. Moreover, MUFFINpivot attains the best results among the pivot systems on all datasets, confirming the reliability of our system in the monolingual setting. We note that since the cross-lingual datasets were built by translating the word pairs in the original English RG-65 dataset, the pivot-based comparison systems proved to be highly competitive, outperforming the CL-MSR2.0 system by a considerable margin. 4.2 Word Sense Disambiguation 4.2.1 Wikipedia In this setting, we selected the SemEval 2013 allwords WSD task (Navigli et al., 2013) as our evaluation benchmark. The task provides datasets for five different languages: Italian, English, French, Spanish and German. There are on average 1123 words to disambiguate in each language’s dataset. As comparison system, we provide results for the best-performing participating system on each language. We also show results for the state-of-theart WSD system of Moro et al. (2014, Babelfy), which relies on random walks on the BabelNet semantic network and a set of graph heuristic algorithms. Finally, we also report results for the Most Frequent Sense (MFS) baseline provided by the task </context>
<context position="27146" citStr="Navigli et al., 2013" startWordPosition="4352" endWordPosition="4355">s. The variant of our system not utilizing the MFS information in the disambiguation process (0 = 0), i.e., MUFFIN*, also shows competitive results, outperforming the best system in the SemEval-2013 dataset on all languages. Interestingly, MUFFIN* proves highly effective on the French language, surpassing not only the performance of our system using the MFS information, but also attaining the best overall performance. 4.2.2 WordNet As regards the WordNet disambiguation task, we take as our benchmark the two recent SemEval English all-words WSD tasks: the SemEval-2013 task on Multilingual WSD (Navigli et al., 2013) and the SemEval-2007 English Lexical Sample, SRL and All-Words task (Pradhan et al., 2007). The all-words datasets of the two tasks contain 1644 instances (SemEval-2013) and 162 noun instances (SemEval-2007), respectively. As comparison system, we report the performance of the best configuration of the topperforming system in the SemEval-2013 task, i.e., UMCC-DLSI (Guti´errez et al., 2013). We also show results for the state-of-the-art supervised system (Zhong and Ng, 2010, IMS), as well as for two graph-based approaches that are based on random walks on the WordNet graph (Agirre and Soroa, 2</context>
<context position="31507" citStr="Navigli et al., 2013" startWordPosition="5053" endWordPosition="5056">a, their applicability is limited to those words and languages for which such data is available, practically limiting them to a small subset of words mainly in the English language. Knowledge-based approaches (Sinha and Mihalcea, 2007; Navigli and Lapata, 2007; Agirre and Soroa, 2009) significantly improve the coverage of supervised systems. However, similarly to their supervised counterparts, knowledge-based techniques are usually limited to the English language. Recent years have seen a growing interest in cross-lingual and multilingual WSD (Lefever and Hoste, 2010; Lefever and Hoste, 2013; Navigli et al., 2013). Multilinguality is usually offered by methods that exploit the structural information of large-scale multilingual lexical resources such as Wikipedia (Guti´errez et al., 2013; Manion and Sainudiin, 2013; Hovy et al., 2013). Babelfy (Moro et al., 2014) is an approach with state-ofthe-art performance that relies on random walks 748 on BabelNet multilingual semantic network (Navigli and Ponzetto, 2012a) and densest subgraph heuristics. However, the approach is limited to the WSD and Entity Linking tasks. In contrast, our approach is global as it can be used in different NLP tasks, including WSD</context>
</contexts>
<marker>Navigli, Jurgens, Vannella, 2013</marker>
<rawString>Roberto Navigli, David Jurgens, and Daniele Vannella. 2013. SemEval-2013 Task 12: Multilingual Word Sense Disambiguation. In Proceedings of SemEval 2013, pages 222–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Word Sense Disambiguation: A survey.</title>
<date>2009</date>
<journal>ACM Computing Surveys,</journal>
<volume>41</volume>
<issue>2</issue>
<contexts>
<context position="11920" citStr="Navigli (2009)" startWordPosition="1901" endWordPosition="1902">. In this section we explain how we use our representations in the tasks of semantic similarity (Section 3.1) and WSD (Section 3.2). Associating concepts with words. Given that our representations are for individual word senses, a preliminary step for both tasks would be to associate the set of concepts, i.e., BabelNet synsets, C,,, = {ci, ..., c,,} with a given word w. In the case when w exists in the BabelNet dictionary, we obtain the set of associated senses of the word as defined in the BabelNet sense inventory. In order to enhance the coverage in the case of 2We use the sense notation of Navigli (2009): wordpn is the nth sense of the word with part of speech p. 743 Crane (bird) Crane (machine) English French German English French German shore bird1 $famille des oiseaux1 n $vogel-familie1 *lifting device1 n *dispositif de levage1 n *hebevorrichtung1 n *limicole1 n $construction4 n navire1 n bird1 n *charadrii1 platform1 n radfahrzeug1 n oiseau aquatique2 n n n limicole1 n *wading bird1 toll´e2 †vogel gattung1 warship1 n †lenkfahrzeug1 n n n n ovaisseau2 n oscine bird1 gallinac´e1 wirbeltiere2 electric circuit1 n n regler3 n n n ovessel2 spationef1 n †bird genus1 oclasse1 fleisch1 n n reisebu</context>
<context position="30628" citStr="Navigli, 2009" startWordPosition="4919" endWordPosition="4920">nt types of knowledge was beneficial. 5 Related work We briefly review the recent literature on the two NLP tasks to which we applied our representations, i.e., Word Sense Disambiguation and semantic similarity. WSD. There are two main categories of WSD techniques: knowledge-based and supervised System SemEval-2013 SemEval-2007 MUFFIN 66.0 66.0 UKB 61.3 56.0 UMCC-DLSI 64.7 – IMS 65.3 67.3 Babelfy 65.9 62.7 MFS 63.2 65.8 MUFFIN+IMS 66.9 68.5 Table 5: F1 percentage performance on the SemEval-2013 and SemEval-2007 (noun instances) English All-words WSD datatets using WordNet as sense inventory. (Navigli, 2009). Supervised systems such as IMS (Zhong and Ng, 2010) analyze sense-annotated data and model the context in which the various senses of a word usually appear. Despite their accuracy for the words that are provided with suitable amounts of sense-annotated data, their applicability is limited to those words and languages for which such data is available, practically limiting them to a small subset of words mainly in the English language. Knowledge-based approaches (Sinha and Mihalcea, 2007; Navigli and Lapata, 2007; Agirre and Soroa, 2009) significantly improve the coverage of supervised systems</context>
</contexts>
<marker>Navigli, 2009</marker>
<rawString>Roberto Navigli. 2009. Word Sense Disambiguation: A survey. ACM Computing Surveys, 41(2):1–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Dekang Lin</author>
</authors>
<title>Discovering word senses from text.</title>
<date>2002</date>
<booktitle>In Proceedings of KDD,</booktitle>
<pages>613--619</pages>
<contexts>
<context position="2298" citStr="Pantel and Lin, 2002" startWordPosition="334" endWordPosition="337">uer and Dooley, 2002), or in their newer predictive branch (Collobert and Weston, 2008; Mikolov et al., 2013; Baroni et al., 2014), suffer from a major drawback: they are unable to model individual word senses or concepts, as they conflate different meanings of a word into a single vectorial representation. This hinders the functionality of this group of vector space models in tasks such as Word Sense Disambiguation (WSD) that require the representation of individual word senses. There have been several efforts to adapt and apply distributional approaches to the representation of word senses (Pantel and Lin, 2002; Brody and Lapata, 2009; Reisinger and Mooney, 2010; Huang et al., 2012). However, none of these techniques provides representations that are already linked to a standard sense inventory, and consequently such mapping has to be carried out either manually, or with the help of sense-annotated data. Chen et al. (2014) addressed this issue and obtained vectors for individual word senses by leveraging WordNet glosses. NASARI (Camacho-Collados et al., 2015) is another approach that obtains accurate sense-specific representations by combining the complementary knowledge from WordNet and Wikipedia. </context>
</contexts>
<marker>Pantel, Lin, 2002</marker>
<rawString>Patrick Pantel and Dekang Lin. 2002. Discovering word senses from text. In Proceedings of KDD, pages 613–619.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Pennington</author>
<author>Richard Socher</author>
<author>Christopher D Manning</author>
</authors>
<title>GloVe: Global vectors for word representation.</title>
<date>2014</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1532--1543</pages>
<contexts>
<context position="33468" citStr="Pennington et al., 2014" startWordPosition="5360" endWordPosition="5363">lados et al., 2015). However, these techniques are either limited in the languages to which they can be applied, or in their applicability to tasks other than semantic similarity (Navigli and Ponzetto, 2012b). Corpus-based techniques are more flexible, enabling the training of models on corpora other than English. However, these approaches, either in their conventional co-occurrence based form (Gabrilovich and Markovitch, 2007; Landauer and Dumais, 1997; Turney and Pantel, 2010; Bullinaria and Levy, 2012), or the more recent predictive models (Mikolov et al., 2013; Collobert and Weston, 2008; Pennington et al., 2014), are restricted in two ways: (1) they cannot be used to compare word senses; and (2) they cannot be directly applied to cross-lingual semantic similarity. Though the first problem has been solved by multi-prototype models (Huang et al., 2012), or by the sense-specific representations obtained as a result of exploiting WordNet glosses (Chen et al., 2014), the second problem remains unaddressed. In contrast, our approach models word senses and concepts effectively, while providing a unified representation for different languages that enables cross-lingual semantic similarity. 6 Conclusions This</context>
</contexts>
<marker>Pennington, Socher, Manning, 2014</marker>
<rawString>Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. GloVe: Global vectors for word representation. In Proceedings of EMNLP, pages 1532–1543.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohammad Taher Pilehvar</author>
<author>Roberto Navigli</author>
</authors>
<title>A robust approach to aligning heterogeneous lexical resources.</title>
<date>2014</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>468--478</pages>
<contexts>
<context position="3113" citStr="Pilehvar and Navigli, 2014" startWordPosition="458" endWordPosition="461"> and consequently such mapping has to be carried out either manually, or with the help of sense-annotated data. Chen et al. (2014) addressed this issue and obtained vectors for individual word senses by leveraging WordNet glosses. NASARI (Camacho-Collados et al., 2015) is another approach that obtains accurate sense-specific representations by combining the complementary knowledge from WordNet and Wikipedia. Graph-based approaches have also been successfully utilized to model individual words (Hughes and Ramage, 2007; Agirre et al., 2009; Yeh et al., 2009), or concepts (Pilehvar et al., 2013; Pilehvar and Navigli, 2014), drawing on the structural properties of semantic networks. The applicability of all these techniques, however, is usually either constrained to a single language (usually English), or to a specific task. We put forward MUFFIN (Multilingual, UniFied and Flexible INterpretation), a novel method that exploits both structural knowledge derived from semantic networks and distributional statistics from text corpora, to produce effective representations of individual word senses or concepts. Our approach provides multiple advantages in comparison to the previous VSM techniques: 1. Multilingual: it </context>
</contexts>
<marker>Pilehvar, Navigli, 2014</marker>
<rawString>Mohammad Taher Pilehvar and Roberto Navigli. 2014. A robust approach to aligning heterogeneous lexical resources. In Proceedings ofACL, pages 468–478.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohammad Taher Pilehvar</author>
<author>David Jurgens</author>
<author>Roberto Navigli</author>
</authors>
<title>Align, Disambiguate and Walk: a Unified Approach for Measuring Semantic Similarity.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>1341--1351</pages>
<contexts>
<context position="3084" citStr="Pilehvar et al., 2013" startWordPosition="454" endWordPosition="457">andard sense inventory, and consequently such mapping has to be carried out either manually, or with the help of sense-annotated data. Chen et al. (2014) addressed this issue and obtained vectors for individual word senses by leveraging WordNet glosses. NASARI (Camacho-Collados et al., 2015) is another approach that obtains accurate sense-specific representations by combining the complementary knowledge from WordNet and Wikipedia. Graph-based approaches have also been successfully utilized to model individual words (Hughes and Ramage, 2007; Agirre et al., 2009; Yeh et al., 2009), or concepts (Pilehvar et al., 2013; Pilehvar and Navigli, 2014), drawing on the structural properties of semantic networks. The applicability of all these techniques, however, is usually either constrained to a single language (usually English), or to a specific task. We put forward MUFFIN (Multilingual, UniFied and Flexible INterpretation), a novel method that exploits both structural knowledge derived from semantic networks and distributional statistics from text corpora, to produce effective representations of individual word senses or concepts. Our approach provides multiple advantages in comparison to the previous VSM tec</context>
<context position="14148" citStr="Pilehvar et al., 2013" startWordPosition="2260" endWordPosition="2263">d flow of the sentence. This property provides an effective means of obtaining a set of concepts for the words not covered by BabelNet. For the case of our example, the BabelNet out-ofvocabulary word w = dockside crane will have in its set of associated concepts C,,, the BabelNet synset corresponding to the Wikipedia page titled Crane (machine). 3.1 Semantic Similarity Once we have the set C,,, of concepts associated with each word w, we first retrieve the set of corresponding unified vector representations. We then follow Camacho-Collados et al. (2015) and use square-rooted Weighted Overlap (Pilehvar et al., 2013, WO) as our vector comparison method, a metric that has been shown to suit specificitybased vectors more than the conventional cosine. WO compares two vectors on the basis of their overlapping dimensions, which are harmonically weighted by their relative ranking: where O is the set of overlapping dimensions (i.e. concepts) between the two vectors and rank(q, vi) is the rank of dimension q in the vector vi. Finally, the similarity between two words w1 and w2 is calculated as the similarity of their closest senses, a prevailing approach in the literature (Resnik, 1995; Budanitsky and Hirst, 200</context>
<context position="17291" citStr="Pilehvar et al., 2013" startWordPosition="2805" endWordPosition="2808">lNet synsets that are not associated with Wikipedia pages. WordNet sense inventory. Similarly, when restricted to the WordNet inventory, we discard those BabelNet synsets that do not contain a WordNet synset. In this setting, we also leverage relations from WordNet’s semantic network and its disambiguated glosses3 in order to obtain a richer set of Wikipedia articles in the sub-corpus construction. The enrichment of the semantic network with the disambiguated glosses has been shown to be beneficial in various graph-based disambiguation tasks (Navigli and Velardi, 2005; Agirre and Soroa, 2009; Pilehvar et al., 2013). 4 Experiments We assess the reliability of MUFFIN in two standard evaluation benchmarks: semantic similarity (Section 4.1) and Word Sense Disambiguation (Section 4.2). 4.1 Semantic Similarity As our semantic similarity experiment we opted for word similarity, which is one of the most popular evaluation frameworks in lexical semantics. Given a pair of words, the task in word similarity is to automatically judge their semantic similarity and, ideally, this judgement should be close to that given by humans. 3http://wordnet.princeton.edu/ glosstag.shtml 4.1.1 Datasets Monolingual. We picked the </context>
<context position="21415" citStr="Pilehvar et al., 2013" startWordPosition="3457" endWordPosition="3460">vitch, 2007), Wiki-wup (Ponzetto and Strube, 2007), and LSA-Wiki (Granada et al., 2014). We also provide results for systems that use distributional semantics for modeling words, both the conventional co-occurrence based approach, i.e., PMI-SVD (Baroni et al., 2014), PMI and SOC-PMI (Joubarne and Inkpen, 2011), and Retrofitting (Faruqui et al., 2015), and the newer word embeddings, i.e., Word2Vec (Mikolov et al., 2013). For Word2Vec and PMISVD, we use the pre-trained models obtained by Baroni et al. (2014).6 As for WordNet-based approaches, we report results for Resnik (Resnik, 1995) and ADW (Pilehvar et al., 2013), which take advantage of its structural information, and Lesk hyper (Gurevych, 2005), which leverages definitional information in WordNet for similarity computation. Finally, we also report the performance of our earlier work NASARI (Camacho-Collados et al., 2015), which combines knowledge from WordNet and Wikipedia for the English language in its setting without the Wiktionary synonyms module. Cross-lingual. We compare the performance of our approach against the best configuration of the CL-MSR-2.0 system (Kennedy and Hirst, 2012), which exploits Pointwise Mutual Information (PMI) on a paral</context>
<context position="22877" citStr="Pilehvar et al., 2013" startWordPosition="3678" endWordPosition="3681">us used to train the models contained 2.8 billion tokens, including Wikipedia (Baroni et al., 2014). the English and French versions of WordNet. Since two of our cross-lingual datasets are newlycreated, we developed three baseline systems to enable a more meaningful comparison. To this end, we first use Google Translate to translate the non-English side of the dataset to the English language. Accordingly, three state-of-the-art graphbased and corpus-based approaches were used to measure the similarity of the resulting English pairs. As English similarity measurement systems, we opted for ADW (Pilehvar et al., 2013), and the best predictive (Mikolov et al., 2013, Word2Vec) and co-occurrence (i.e., PMI-SVD) models obtained by Baroni et al. (2014).7 In our experiments we refer to these systems as pivot, since they use English as a pivot for computing semantic similarity. As a comparison, we also show results for MUFFINpivot, which is the variant of our system applied to the same automatically translated monolingual datasets. 4.1.3 Results Monolingual. We show in Table 2 the performance of different systems in terms of Spearman and Pearson correlations on the English, German, and French RG-65 datasets. On t</context>
<context position="32771" citStr="Pilehvar et al., 2013" startWordPosition="5254" endWordPosition="5257"> of word pairs is usually computed either on the basis of the structural properties of lexical databases and thesauri, or by comparing vectorial representations of words learned from massive text corpora. Structural approaches usually measure the similarity on the basis of the distance information on semantic networks, such as WordNet (Budanitsky and Hirst, 2006), or thesauri, such as Roget’s (Morris and Hirst, 1991; Jarmasz and Szpakowicz, 2003). The semantic network of WordNet has also been used in more sophisticated techniques such as those based on random graph walks (Ramage et al., 2009; Pilehvar et al., 2013), or coupled with the complementary knowledge from Wikipedia (Camacho-Collados et al., 2015). However, these techniques are either limited in the languages to which they can be applied, or in their applicability to tasks other than semantic similarity (Navigli and Ponzetto, 2012b). Corpus-based techniques are more flexible, enabling the training of models on corpora other than English. However, these approaches, either in their conventional co-occurrence based form (Gabrilovich and Markovitch, 2007; Landauer and Dumais, 1997; Turney and Pantel, 2010; Bullinaria and Levy, 2012), or the more rec</context>
</contexts>
<marker>Pilehvar, Jurgens, Navigli, 2013</marker>
<rawString>Mohammad Taher Pilehvar, David Jurgens, and Roberto Navigli. 2013. Align, Disambiguate and Walk: a Unified Approach for Measuring Semantic Similarity. In Proceedings of ACL, pages 1341– 1351.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simone Paolo Ponzetto</author>
<author>Michael Strube</author>
</authors>
<title>Knowledge derived from Wikipedia for computing semantic relatedness.</title>
<date>2007</date>
<journal>Journal of Artificial Intelligence Research (JAIR),</journal>
<pages>30--181</pages>
<contexts>
<context position="20843" citStr="Ponzetto and Strube, 2007" startWordPosition="3368" endWordPosition="3371"> 0.77 SOC-PMI – 0.61 SOC-PMI – 0.27 SOC-PMI – 0.19 PMI – 0.41 PMI – 0.40 PMI – 0.34 Retrofitting 0.74 – Retrofitting 0.60 – Retrofitting 0.61 – LSA-Wiki 0.69 0.65 – – – LSA-Wiki 0.52 0.57 Wiki-wup – 0.59 Wiki-wup – 0.65 SSA 0.83 0.86 Resnik – 0.72 NASARI 0.84 0.82 Lesk hyper – 0.69 ADW 0.87 0.81 Word2Vec – 0.84 PMI-SVD – 0.74 ESA – 0.72 Table 2: Spearman (p) and Pearson (r) correlation performance of different systems on the English, German and French RG-65 datasets. Wikipedia as their main knowledge resource: SSA5 (Hassan and Mihalcea, 2011), ESA (Gabrilovich and Markovitch, 2007), Wiki-wup (Ponzetto and Strube, 2007), and LSA-Wiki (Granada et al., 2014). We also provide results for systems that use distributional semantics for modeling words, both the conventional co-occurrence based approach, i.e., PMI-SVD (Baroni et al., 2014), PMI and SOC-PMI (Joubarne and Inkpen, 2011), and Retrofitting (Faruqui et al., 2015), and the newer word embeddings, i.e., Word2Vec (Mikolov et al., 2013). For Word2Vec and PMISVD, we use the pre-trained models obtained by Baroni et al. (2014).6 As for WordNet-based approaches, we report results for Resnik (Resnik, 1995) and ADW (Pilehvar et al., 2013), which take advantage of it</context>
</contexts>
<marker>Ponzetto, Strube, 2007</marker>
<rawString>Simone Paolo Ponzetto and Michael Strube. 2007. Knowledge derived from Wikipedia for computing semantic relatedness. Journal of Artificial Intelligence Research (JAIR), 30:181–212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Edward Loper</author>
<author>Dmitriy Dligach</author>
<author>Martha Palmer</author>
</authors>
<date>2007</date>
<booktitle>SemEval-2007 task-17: English lexical sample, SRL and all words. In Proceedings of SemEval,</booktitle>
<pages>87--92</pages>
<contexts>
<context position="27237" citStr="Pradhan et al., 2007" startWordPosition="4366" endWordPosition="4369">s (0 = 0), i.e., MUFFIN*, also shows competitive results, outperforming the best system in the SemEval-2013 dataset on all languages. Interestingly, MUFFIN* proves highly effective on the French language, surpassing not only the performance of our system using the MFS information, but also attaining the best overall performance. 4.2.2 WordNet As regards the WordNet disambiguation task, we take as our benchmark the two recent SemEval English all-words WSD tasks: the SemEval-2013 task on Multilingual WSD (Navigli et al., 2013) and the SemEval-2007 English Lexical Sample, SRL and All-Words task (Pradhan et al., 2007). The all-words datasets of the two tasks contain 1644 instances (SemEval-2013) and 162 noun instances (SemEval-2007), respectively. As comparison system, we report the performance of the best configuration of the topperforming system in the SemEval-2013 task, i.e., UMCC-DLSI (Guti´errez et al., 2013). We also show results for the state-of-the-art supervised system (Zhong and Ng, 2010, IMS), as well as for two graph-based approaches that are based on random walks on the WordNet graph (Agirre and Soroa, 2009, UKB w2w) and the BabelNet semantic network (Moro et al., 2014, Babelfy). We follow Bab</context>
</contexts>
<marker>Pradhan, Loper, Dligach, Palmer, 2007</marker>
<rawString>Sameer Pradhan, Edward Loper, Dmitriy Dligach, and Martha Palmer. 2007. SemEval-2007 task-17: English lexical sample, SRL and all words. In Proceedings of SemEval, pages 87–92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Ramage</author>
<author>Anna N Rafferty</author>
<author>Christopher D Manning</author>
</authors>
<title>Random walks for text semantic similarity.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing,</booktitle>
<pages>23--31</pages>
<contexts>
<context position="32747" citStr="Ramage et al., 2009" startWordPosition="5250" endWordPosition="5253">. Semantic similarity of word pairs is usually computed either on the basis of the structural properties of lexical databases and thesauri, or by comparing vectorial representations of words learned from massive text corpora. Structural approaches usually measure the similarity on the basis of the distance information on semantic networks, such as WordNet (Budanitsky and Hirst, 2006), or thesauri, such as Roget’s (Morris and Hirst, 1991; Jarmasz and Szpakowicz, 2003). The semantic network of WordNet has also been used in more sophisticated techniques such as those based on random graph walks (Ramage et al., 2009; Pilehvar et al., 2013), or coupled with the complementary knowledge from Wikipedia (Camacho-Collados et al., 2015). However, these techniques are either limited in the languages to which they can be applied, or in their applicability to tasks other than semantic similarity (Navigli and Ponzetto, 2012b). Corpus-based techniques are more flexible, enabling the training of models on corpora other than English. However, these approaches, either in their conventional co-occurrence based form (Gabrilovich and Markovitch, 2007; Landauer and Dumais, 1997; Turney and Pantel, 2010; Bullinaria and Levy</context>
</contexts>
<marker>Ramage, Rafferty, Manning, 2009</marker>
<rawString>Daniel Ramage, Anna N. Rafferty, and Christopher D. Manning. 2009. Random walks for text semantic similarity. In Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing, pages 23–31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Reisinger</author>
<author>Raymond J Mooney</author>
</authors>
<title>Multi-prototype vector-space models of word meaning.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>109--117</pages>
<contexts>
<context position="2350" citStr="Reisinger and Mooney, 2010" startWordPosition="343" endWordPosition="346">ctive branch (Collobert and Weston, 2008; Mikolov et al., 2013; Baroni et al., 2014), suffer from a major drawback: they are unable to model individual word senses or concepts, as they conflate different meanings of a word into a single vectorial representation. This hinders the functionality of this group of vector space models in tasks such as Word Sense Disambiguation (WSD) that require the representation of individual word senses. There have been several efforts to adapt and apply distributional approaches to the representation of word senses (Pantel and Lin, 2002; Brody and Lapata, 2009; Reisinger and Mooney, 2010; Huang et al., 2012). However, none of these techniques provides representations that are already linked to a standard sense inventory, and consequently such mapping has to be carried out either manually, or with the help of sense-annotated data. Chen et al. (2014) addressed this issue and obtained vectors for individual word senses by leveraging WordNet glosses. NASARI (Camacho-Collados et al., 2015) is another approach that obtains accurate sense-specific representations by combining the complementary knowledge from WordNet and Wikipedia. Graph-based approaches have also been successfully u</context>
</contexts>
<marker>Reisinger, Mooney, 2010</marker>
<rawString>Joseph Reisinger and Raymond J. Mooney. 2010. Multi-prototype vector-space models of word meaning. In Proceedings of ACL, pages 109–117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Using information content to evaluate semantic similarity in a taxonomy.</title>
<date>1995</date>
<booktitle>In Proceedings of IJCAI,</booktitle>
<pages>448--453</pages>
<contexts>
<context position="14721" citStr="Resnik, 1995" startWordPosition="2357" endWordPosition="2358">Weighted Overlap (Pilehvar et al., 2013, WO) as our vector comparison method, a metric that has been shown to suit specificitybased vectors more than the conventional cosine. WO compares two vectors on the basis of their overlapping dimensions, which are harmonically weighted by their relative ranking: where O is the set of overlapping dimensions (i.e. concepts) between the two vectors and rank(q, vi) is the rank of dimension q in the vector vi. Finally, the similarity between two words w1 and w2 is calculated as the similarity of their closest senses, a prevailing approach in the literature (Resnik, 1995; Budanitsky and Hirst, 2006): � sim(w1, w2) = max WO(v1, v2) (3) v1ECw1,v2ECw2 where w1 and w2 can belong to different languages. This cross-lingual similarity measurement is possible thanks to the unified languageindependent space of concepts of our semantic representations. 3.2 Multilingual Word Sense Disambiguation In order to be able to apply our approach to WSD, we use the lexical vector lexc for each concept c. The reason for our choice of lexical vectors in this setting is that they enable a direct comparison of a candidate sense’s representation with the context, which is also in the </context>
<context position="21383" citStr="Resnik, 1995" startWordPosition="3453" endWordPosition="3454"> (Gabrilovich and Markovitch, 2007), Wiki-wup (Ponzetto and Strube, 2007), and LSA-Wiki (Granada et al., 2014). We also provide results for systems that use distributional semantics for modeling words, both the conventional co-occurrence based approach, i.e., PMI-SVD (Baroni et al., 2014), PMI and SOC-PMI (Joubarne and Inkpen, 2011), and Retrofitting (Faruqui et al., 2015), and the newer word embeddings, i.e., Word2Vec (Mikolov et al., 2013). For Word2Vec and PMISVD, we use the pre-trained models obtained by Baroni et al. (2014).6 As for WordNet-based approaches, we report results for Resnik (Resnik, 1995) and ADW (Pilehvar et al., 2013), which take advantage of its structural information, and Lesk hyper (Gurevych, 2005), which leverages definitional information in WordNet for similarity computation. Finally, we also report the performance of our earlier work NASARI (Camacho-Collados et al., 2015), which combines knowledge from WordNet and Wikipedia for the English language in its setting without the Wiktionary synonyms module. Cross-lingual. We compare the performance of our approach against the best configuration of the CL-MSR-2.0 system (Kennedy and Hirst, 2012), which exploits Pointwise Mut</context>
</contexts>
<marker>Resnik, 1995</marker>
<rawString>Philip Resnik. 1995. Using information content to evaluate semantic similarity in a taxonomy. In Proceedings of IJCAI, pages 448–453.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert Rubenstein</author>
<author>John B Goodenough</author>
</authors>
<title>Contextual correlates of synonymy.</title>
<date>1965</date>
<journal>Communications of the ACM,</journal>
<volume>8</volume>
<issue>10</issue>
<contexts>
<context position="17938" citStr="Rubenstein and Goodenough, 1965" startWordPosition="2899" endWordPosition="2902"> We assess the reliability of MUFFIN in two standard evaluation benchmarks: semantic similarity (Section 4.1) and Word Sense Disambiguation (Section 4.2). 4.1 Semantic Similarity As our semantic similarity experiment we opted for word similarity, which is one of the most popular evaluation frameworks in lexical semantics. Given a pair of words, the task in word similarity is to automatically judge their semantic similarity and, ideally, this judgement should be close to that given by humans. 3http://wordnet.princeton.edu/ glosstag.shtml 4.1.1 Datasets Monolingual. We picked the RG-65 dataset (Rubenstein and Goodenough, 1965) as our monolingual word similarity dataset. The dataset comprises 65 English word pairs which have been manually annotated by several annotators according to their similarity on a scale of 0 to 4. We also perform evaluations on the French (Joubarne and Inkpen, 2011) and German (Gurevych, 2005) adaptations of this dataset. Cross-lingual. Hassan and Mihalcea (2009) developed two sets of cross-lingual datasets based on the English MC-30 (Miller and Charles, 1991) and WordSim-353 (Finkelstein et al., 2002) datasets, for four different languages: English, German, Romanian, and Arabic. However, the</context>
</contexts>
<marker>Rubenstein, Goodenough, 1965</marker>
<rawString>Herbert Rubenstein and John B. Goodenough. 1965. Contextual correlates of synonymy. Communications of the ACM, 8(10):627–633.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>A Wong</author>
<author>C S Yang</author>
</authors>
<title>A vector space model for automatic indexing.</title>
<date>1975</date>
<journal>Communications of the ACM,</journal>
<volume>18</volume>
<issue>11</issue>
<contexts>
<context position="1646" citStr="Salton et al., 1975" startWordPosition="227" endWordPosition="230">ard datasets. 1 Introduction Semantic representation, i.e., the task of representing a linguistic item (such as a word or a word sense) in a mathematical or machine-interpretable form, is a fundamental problem in Natural Language Processing (NLP). The Vector Space Model (VSM) is a prominent approach for semantic representation, with widespread popularity in numerous NLP applications. The prevailing methods for the computation of a vector space representation are based on distributional semantics (Harris, 1954). However, these approaches, whether in their conventional co-occurrence based form (Salton et al., 1975; Turney and Pantel, 2010; Landauer and Dooley, 2002), or in their newer predictive branch (Collobert and Weston, 2008; Mikolov et al., 2013; Baroni et al., 2014), suffer from a major drawback: they are unable to model individual word senses or concepts, as they conflate different meanings of a word into a single vectorial representation. This hinders the functionality of this group of vector space models in tasks such as Word Sense Disambiguation (WSD) that require the representation of individual word senses. There have been several efforts to adapt and apply distributional approaches to the</context>
</contexts>
<marker>Salton, Wong, Yang, 1975</marker>
<rawString>Gerard Salton, A. Wong, and C. S. Yang. 1975. A vector space model for automatic indexing. Communications of the ACM, 18(11):613–620.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ravi Sinha</author>
<author>Rada Mihalcea</author>
</authors>
<title>Unsupervised graph-based Word Sense Disambiguation using measures of word semantic similarity.</title>
<date>2007</date>
<booktitle>In Proceedings of ICSC,</booktitle>
<pages>363--369</pages>
<contexts>
<context position="31120" citStr="Sinha and Mihalcea, 2007" startWordPosition="4997" endWordPosition="5000"> the SemEval-2013 and SemEval-2007 (noun instances) English All-words WSD datatets using WordNet as sense inventory. (Navigli, 2009). Supervised systems such as IMS (Zhong and Ng, 2010) analyze sense-annotated data and model the context in which the various senses of a word usually appear. Despite their accuracy for the words that are provided with suitable amounts of sense-annotated data, their applicability is limited to those words and languages for which such data is available, practically limiting them to a small subset of words mainly in the English language. Knowledge-based approaches (Sinha and Mihalcea, 2007; Navigli and Lapata, 2007; Agirre and Soroa, 2009) significantly improve the coverage of supervised systems. However, similarly to their supervised counterparts, knowledge-based techniques are usually limited to the English language. Recent years have seen a growing interest in cross-lingual and multilingual WSD (Lefever and Hoste, 2010; Lefever and Hoste, 2013; Navigli et al., 2013). Multilinguality is usually offered by methods that exploit the structural information of large-scale multilingual lexical resources such as Wikipedia (Guti´errez et al., 2013; Manion and Sainudiin, 2013; Hovy et</context>
</contexts>
<marker>Sinha, Mihalcea, 2007</marker>
<rawString>Ravi Sinha and Rada Mihalcea. 2007. Unsupervised graph-based Word Sense Disambiguation using measures of word semantic similarity. In Proceedings of ICSC, pages 363–369.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Patrick Pantel</author>
</authors>
<title>From frequency to meaning: Vector space models of semantics.</title>
<date>2010</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>37--141</pages>
<contexts>
<context position="1671" citStr="Turney and Pantel, 2010" startWordPosition="231" endWordPosition="234">duction Semantic representation, i.e., the task of representing a linguistic item (such as a word or a word sense) in a mathematical or machine-interpretable form, is a fundamental problem in Natural Language Processing (NLP). The Vector Space Model (VSM) is a prominent approach for semantic representation, with widespread popularity in numerous NLP applications. The prevailing methods for the computation of a vector space representation are based on distributional semantics (Harris, 1954). However, these approaches, whether in their conventional co-occurrence based form (Salton et al., 1975; Turney and Pantel, 2010; Landauer and Dooley, 2002), or in their newer predictive branch (Collobert and Weston, 2008; Mikolov et al., 2013; Baroni et al., 2014), suffer from a major drawback: they are unable to model individual word senses or concepts, as they conflate different meanings of a word into a single vectorial representation. This hinders the functionality of this group of vector space models in tasks such as Word Sense Disambiguation (WSD) that require the representation of individual word senses. There have been several efforts to adapt and apply distributional approaches to the representation of word s</context>
<context position="33326" citStr="Turney and Pantel, 2010" startWordPosition="5336" endWordPosition="5339">d on random graph walks (Ramage et al., 2009; Pilehvar et al., 2013), or coupled with the complementary knowledge from Wikipedia (Camacho-Collados et al., 2015). However, these techniques are either limited in the languages to which they can be applied, or in their applicability to tasks other than semantic similarity (Navigli and Ponzetto, 2012b). Corpus-based techniques are more flexible, enabling the training of models on corpora other than English. However, these approaches, either in their conventional co-occurrence based form (Gabrilovich and Markovitch, 2007; Landauer and Dumais, 1997; Turney and Pantel, 2010; Bullinaria and Levy, 2012), or the more recent predictive models (Mikolov et al., 2013; Collobert and Weston, 2008; Pennington et al., 2014), are restricted in two ways: (1) they cannot be used to compare word senses; and (2) they cannot be directly applied to cross-lingual semantic similarity. Though the first problem has been solved by multi-prototype models (Huang et al., 2012), or by the sense-specific representations obtained as a result of exploiting WordNet glosses (Chen et al., 2014), the second problem remains unaddressed. In contrast, our approach models word senses and concepts ef</context>
</contexts>
<marker>Turney, Pantel, 2010</marker>
<rawString>Peter D. Turney and Patrick Pantel. 2010. From frequency to meaning: Vector space models of semantics. Journal of Artificial Intelligence Research, 37:141–188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Yeh</author>
<author>Daniel Ramage</author>
<author>Christopher D Manning</author>
<author>Eneko Agirre</author>
<author>Aitor Soroa</author>
</authors>
<title>WikiWalk: random walks on Wikipedia for semantic relatedness.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Graphbased Methods for Natural Language Processing,</booktitle>
<pages>41--49</pages>
<contexts>
<context position="3048" citStr="Yeh et al., 2009" startWordPosition="448" endWordPosition="451"> that are already linked to a standard sense inventory, and consequently such mapping has to be carried out either manually, or with the help of sense-annotated data. Chen et al. (2014) addressed this issue and obtained vectors for individual word senses by leveraging WordNet glosses. NASARI (Camacho-Collados et al., 2015) is another approach that obtains accurate sense-specific representations by combining the complementary knowledge from WordNet and Wikipedia. Graph-based approaches have also been successfully utilized to model individual words (Hughes and Ramage, 2007; Agirre et al., 2009; Yeh et al., 2009), or concepts (Pilehvar et al., 2013; Pilehvar and Navigli, 2014), drawing on the structural properties of semantic networks. The applicability of all these techniques, however, is usually either constrained to a single language (usually English), or to a specific task. We put forward MUFFIN (Multilingual, UniFied and Flexible INterpretation), a novel method that exploits both structural knowledge derived from semantic networks and distributional statistics from text corpora, to produce effective representations of individual word senses or concepts. Our approach provides multiple advantages i</context>
</contexts>
<marker>Yeh, Ramage, Manning, Agirre, Soroa, 2009</marker>
<rawString>Eric Yeh, Daniel Ramage, Christopher D. Manning, Eneko Agirre, and Aitor Soroa. 2009. WikiWalk: random walks on Wikipedia for semantic relatedness. In Proceedings of the Workshop on Graphbased Methods for Natural Language Processing, pages 41–49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhi Zhong</author>
<author>Hwee Tou Ng</author>
</authors>
<title>It Makes Sense: A wide-coverage Word Sense Disambiguation system for free text.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL System Demonstrations,</booktitle>
<pages>78--83</pages>
<contexts>
<context position="27624" citStr="Zhong and Ng, 2010" startWordPosition="4424" endWordPosition="4427">e take as our benchmark the two recent SemEval English all-words WSD tasks: the SemEval-2013 task on Multilingual WSD (Navigli et al., 2013) and the SemEval-2007 English Lexical Sample, SRL and All-Words task (Pradhan et al., 2007). The all-words datasets of the two tasks contain 1644 instances (SemEval-2013) and 162 noun instances (SemEval-2007), respectively. As comparison system, we report the performance of the best configuration of the topperforming system in the SemEval-2013 task, i.e., UMCC-DLSI (Guti´errez et al., 2013). We also show results for the state-of-the-art supervised system (Zhong and Ng, 2010, IMS), as well as for two graph-based approaches that are based on random walks on the WordNet graph (Agirre and Soroa, 2009, UKB w2w) and the BabelNet semantic network (Moro et al., 2014, Babelfy). We follow Babelfy and also exploit the WordNet’s sense frequency information from the SemCor senseannotated corpus (Miller et al., 1993). However, instead of simply backing off to the most frequent sense, we propose a more meaningful exploitation of this information. To this end, we compute the relevance of a specific sense as the average of its normalized sense frequency and its corresponding 747</context>
<context position="30681" citStr="Zhong and Ng, 2010" startWordPosition="4926" endWordPosition="4929">work We briefly review the recent literature on the two NLP tasks to which we applied our representations, i.e., Word Sense Disambiguation and semantic similarity. WSD. There are two main categories of WSD techniques: knowledge-based and supervised System SemEval-2013 SemEval-2007 MUFFIN 66.0 66.0 UKB 61.3 56.0 UMCC-DLSI 64.7 – IMS 65.3 67.3 Babelfy 65.9 62.7 MFS 63.2 65.8 MUFFIN+IMS 66.9 68.5 Table 5: F1 percentage performance on the SemEval-2013 and SemEval-2007 (noun instances) English All-words WSD datatets using WordNet as sense inventory. (Navigli, 2009). Supervised systems such as IMS (Zhong and Ng, 2010) analyze sense-annotated data and model the context in which the various senses of a word usually appear. Despite their accuracy for the words that are provided with suitable amounts of sense-annotated data, their applicability is limited to those words and languages for which such data is available, practically limiting them to a small subset of words mainly in the English language. Knowledge-based approaches (Sinha and Mihalcea, 2007; Navigli and Lapata, 2007; Agirre and Soroa, 2009) significantly improve the coverage of supervised systems. However, similarly to their supervised counterparts</context>
</contexts>
<marker>Zhong, Ng, 2010</marker>
<rawString>Zhi Zhong and Hwee Tou Ng. 2010. It Makes Sense: A wide-coverage Word Sense Disambiguation system for free text. In Proceedings of the ACL System Demonstrations, pages 78–83.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>