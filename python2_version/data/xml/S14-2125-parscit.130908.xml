<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.061761">
<title confidence="0.98615">
UIO-Lien: Entailment Recognition using Minimal Recursion Semantics
</title>
<author confidence="0.994322">
Elisabeth Lien Milen Kouylekov
</author>
<affiliation confidence="0.999004">
Department of Informatics Department of Informatics
University of Oslo, Norway University of Oslo, Norway
</affiliation>
<email confidence="0.993114">
elien@ifi.uio.no milen@ifi.uio.no
</email>
<sectionHeader confidence="0.9938" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998758">
In this paper we present our participa-
tion in the Semeval 2014 task “Evalu-
ation of compositional distributional se-
mantic models on full sentences through
semantic relatedness and textual entail-
ment”. Our results demonstrate that us-
ing generic tools for semantic analysis is a
viable option for a system that recognizes
textual entailment. The invested effort in
developing such tools allows us to build
systems for reasoning that do not require
training.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.960357607142857">
Recognizing textual entailment (RTE) has been a
popular area of research in the last years. It has
appeared in a variety of evaluation campaigns as
both monolingual and multilingual tasks. A wide
variety of techniques based on different levels of
text interpretation has been used, e.g., lexical dis-
tance, dependency parsing and semantic role la-
beling (Androutsopoulos and Malakasiotis, 2010).
Our approach uses a semantic representation
formalism called Minimal Recursion Semantics
(MRS), which, to our knowledge, has not been
used extensively in entailment decision systems.
Notable examples of systems that use MRS are
Wotzlaw and Coote (2013), and Bergmair (2010).
In Wotzlaw and Coote (2013), the authors present
an entailment recognition system which combines
high-coverage syntactic and semantic text analysis
with logical inference supported by relevant back-
ground knowledge. MRS is used as an interme-
diate format in transforming the results of the lin-
guistic analysis into representations used for log-
ical reasoning. The approach in Bergmair (2010)
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
uses the syllogism as an approximation of natural
language reasoning. MRS is used as a step in the
translation of natural language sentences into logi-
cal formulae that are suitable for processing. Both
works describe approaches that can be adapted
to RTE, but no empirical evaluation is included
to demonstrate the potential of the proposed ap-
proaches.
In contrast to these approaches, our system
bases entailment decision directly on the MRS
representations. Graph alignment over MRS rep-
resentations forms the basis for entailment recog-
nition. If key nodes in the hypothesis MRS can be
aligned to nodes in the text MRS, this is treated as
an indicator of entailment.
This paper represents our first attempt to evalu-
ate a system based on logical-form semantic rep-
resentations in a RTE competition. Using a state-
of-the-art semantic analysis component, we have
created a generic rule-based system for recogniz-
ing textual entailment that obtains competitive re-
sults on a real evaluation dataset. Our approach
does not require training. We confront it with
a strong baseline provided by the EDITS system
(Kouylekov et al., 2011).
In Section 2 we describe the computational se-
mantics framework that forms the basis of our ap-
proach. Section 3 details our entailment system,
and in Section 4 we analyze our results from the
task evaluation.
</bodyText>
<sectionHeader confidence="0.962059" genericHeader="method">
2 Minimal Recursion Semantics
</sectionHeader>
<bodyText confidence="0.990199666666667">
Minimal Recursion Semantics (MRS) (Copestake
et al., 2005) is a framework for computational se-
mantics which provides expressive representations
with a clear interface with syntax. MRS allows
underspecification of scope, in order to capture the
different readings of a sentence with a single MRS
representation. We use the MRS analyses that are
produced by the HPSG English Resource Gram-
mar (ERG) (Flickinger, 2000).
</bodyText>
<page confidence="0.985087">
699
</page>
<note confidence="0.7309165">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 699–703,
Dublin, Ireland, August 23-24, 2014.
</note>
<bodyText confidence="0.999945481481482">
The core of an MRS representation is a mul-
tiset of relations, called elementary predications
(EPs). An EP represents a single lexeme, or gen-
eral grammatical features. Each EP has a predi-
cate symbol, and a label (also called handle) that
identifies the EPs position within the MRS struc-
ture. Each EP contains a list of numbered argu-
ments: ARG0, ARG1, etc., whose values are scopal
or non-scopal variables. The ARG0 value is called
the EP’s distinguished variable, and denotes an
event or state, or an entity.
Finally, an MRS has a set of handle constraints
which describe how the scopal arguments of the
EPs can be equated with EP labels. A constraint
hi =Q hj denotes equality modulo quantifier inser-
tion. EPs are directly and indirectly linked through
handle constraints and variable sharing, and the re-
sulting MRS forms a connected graph.
In Figure 1, we see an MRS for the sentence
A woman is cutting a potato. The topmost EP,
cut v 1, has a list of three argument-value pairs:
its distinguished variable e3 denotes an event, and
the variables x6 and xg refer to the entities filling
the agent and patient roles in the verb event. x6
and xg are in turn the distinguished variables of
the EPs that represent a woman and a potato, re-
spectively.
</bodyText>
<sectionHeader confidence="0.990342" genericHeader="method">
3 System Description
</sectionHeader>
<bodyText confidence="0.995783243902439">
In the following, Tsent and Hsent refer to the text
and hypothesis sentence, and Tmrs and Hmrs to
their MRS representations.
The core of our system is a rule based compo-
nent, which bases entailment decision on graph
alignment over MRS structures. An earlier ver-
sion of the system is described in Lien (2014).
The earlier version was developed on the data set
from the SemEval-2010 shared task Parser Eval-
uation using Textual Entailment (PETE) (Yuret et
al., 2010). Using no external linguistic resources,
the system output positive entailment decisions for
sentence pairs where core nodes of the Hmrs could
be aligned to nodes in Tmrs according to a set of
heuristic matching rules. The system we present
in this paper extends the earlier version by adding
support for contradiction recognition, and by us-
ing lexical relations from WordNet.
For our participation in the entailment recogni-
tion task, first, we did an analysis of the SICK trial
data. In the ENTAILMENT pairs, Hsent is a para-
phrase over the whole or part of the text sentence.
The changes from Tsent to Hsent can be syntactic
(e.g., active-passive conversion), lexical (e.g., syn-
onymy, hyponymy-hypernymy, multiword expres-
sions replaced by single word), or Tsent contains
some element that does not appear in Hsent (e.g.,
Tsent is a conjunction and Hsent one of its con-
juncts, a modifier in Tsent is left out of Hsent). In
the CONTRADICTION category, the sentences of
a pair are also basically the same or paraphrases,
and a negation or a pair of antonymous expres-
sions create the contradiction. The NEUTRAL
pairs often have a high degree of word overlap, but
Hsent cannot be inferred from Tsent. Our system
accounts for many of these characteristics.
The system bases its decision on the results of
two procedures: a) an event relation match which
searches for an alignment between the MRSs, and
b) a contradiction cue check. After running these
procedures, the system outputs
</bodyText>
<listItem confidence="0.912452">
1. ENTAILMENT, if the event relation match-
ing procedure found an alignment, and no
contradiction cues were found,
2. CONTRADICTION, if contradiction cues
were found,
3. NEUTRAL, if neither of the above condi-
tions are met.
</listItem>
<bodyText confidence="0.999913727272727">
The event relation matching procedure extends
the one developed in Lien (2014) to account for
the greater lexical variation in the SICK data. The
procedure selects all the EPs in Tmrs and Hmrs
that have an event variable as their ARG0—we call
them event relations. These event relations mainly
represent verbs, verb conjunctions, adjectives, and
prepositions. For each event relation Hevent in the
hypothesis the procedure tries to find a matching
relation Tevent among the text event relations. We
say that Hevent matches Tevent if:
</bodyText>
<listItem confidence="0.9676572">
1. they represent the same lexeme with the
same part-of-speech, or if both are verbs and
Hevent is a synonym or hypernym of Tevent,
and
2. all their arguments match. Two event rela-
tion arguments in the same argument position
match if:
• they are the same or synonymous, or the
Hevent argument is a hypernym of the
Tevent argument, or
</listItem>
<page confidence="0.93837">
700
</page>
<figure confidence="0.819025428571428">
(h1,
h4: a q(0:1)(ARG0 x6, RSTR h7, BODY h5),
h8: woman n 1(2:7)(ARG0 x6),
h2: cut v 1(11:18)(ARG0 e3, ARG1 x6, ARG2 x9),
h10: a q(19:20)(ARG0 x9, RSTR h12, BODY h11),
h13: potato n 1(21:28)(ARG0 x9)
{ h12 =q h13, h7 =q h8, h1 =q h2 } )
</figure>
<figureCaption confidence="0.992188">
Figure 1: MRS for A woman is cutting a potato (pair 4661, SICK trial data).
</figureCaption>
<listItem confidence="0.997120909090909">
• the argument in Tevent represents a noun
phrase and the argument in Hevent is an
underspecified pronoun like somebody,
or
• the argument in Tevent is either a sco-
pal relation or a conjunction relation,
and one of its arguments matches that of
Hevent, or
• the argument in Hevent is not expressed
(i.e., it matches the Tevent argument by
default)
</listItem>
<bodyText confidence="0.999921766666667">
The matching procedure does not search for
more than one alignment between the event rela-
tions of Hmrs and Tmrs.
The contradiction cue procedure checks
whether the MRS pairs contain relations express-
ing negation. The quantifier no q rel negates
an entity (e.g., no man), whereas neg rel
denotes sentence negation. If a negation relation
appears in one but not the other MRS, we treat
this as an indicator of CONTRADICTION.
Example: Figure 1 shows the MRS analysis of
the hypothesis in the entailment pair A woman
is slicing a potato ⇒ A woman is cutting a
potato. There is only one event relation in Hmrs:
cut v 1. Tmrs is an equivalent structure with
one event relation slice v 1. Using Word-
Net, the system finds that cut v 1 is a hyper-
nym of slice v 1. Then, the system compares
the ARG1 and ARG2 values of the event relations.
The arguments match since they are the same re-
lations. There are no contradiction cues in either
of the MRSs, so the system correctly outputs EN-
TAILMENT.
If we look at the rule based component’s output
(Table 1) for the 481 of the 500 SICK trial sen-
tence pairs for which the ERG produced MRSs,
we get a picture of how well it covers the phenom-
ena in the data set:
Of the 134 ENTAILMENT pairs, 59 were para-
phrases where the variation was relatively limited
</bodyText>
<table confidence="0.965295">
gold ENT gold CON gold NEU
sys ENT 59 0 1
sys CON 0 51 14
sys NEU 75 22 259
</table>
<tableCaption confidence="0.996318">
Table 1: Output for the system on SICK trial data.
</tableCaption>
<bodyText confidence="0.98375075">
and could be captured by looking for synonyms,
hyponyms, and treating the hypothesis as a sub-
graph of the text. The simple contradiction cue
check, which looks for negation relations, covered
51 of 73 CONTRADICTION pairs.
75 ENTAILMENT and 22 CONTRADICTION
pairs were not captured by the matching and con-
tradiction cue procedures. Almost 30% of the
ENTAILMENT pairs had word pairs whose lex-
ical relationship was not recognized using Word-
Net (e.g.: playing a guitar ⇒ strumming a guitar).
In the other pairs there were alternations between
simple and more complex noun phrases (protec-
tive gear ⇒ gear used for protection), change of
part-of-speech from Tsent to Hsent for the same
meaning entities (It is raining on a walking man ⇒
A man is walking in the rain); some pairs required
reasoning, and in some cases Hsent contained in-
formation not present in Tsent. In some cases, en-
tailment recognition fails because the MRS analy-
sis is not correct (e.g., misrepresentation of passive
constructions).
The contradiction cue check did not look for
antonymous words and expressions, and this ac-
counts for almost half of the missing CONTRA-
DICTION pairs. The rest contained negation,
but were misclassified either because an incorrect
MRS analysis was chosen by the parser or because
synonymous words within the scope of the nega-
tion were not recognized.
EDITS We used a backoff-system for the pairs
when the rule-based system fails to produce re-
</bodyText>
<page confidence="0.991175">
701
</page>
<table confidence="0.99972025">
System 1 2 3 4 5
Rules Only Rules Only Combined Combined Edits
Training 76.13 75.4 76.62 76.62 74.78
Test 77.0 76.35 77.12 77.14 74.79
</table>
<tableCaption confidence="0.999377">
Table 2: Submitted system accuracy on training and test set.
</tableCaption>
<bodyText confidence="0.9970494">
sults. Our choice was EDITS1 as it provides
a strong baseline system for recognizing textual
entailment (Kouylekov et al., 2011). EDITS
(Kouylekov and Negri, 2010) is an open source
package which offers a modular, flexible, and
adaptable working environment for experimenting
with the RTE task over different datasets. The
package allows to: i) create an entailment engine
by defining its basic components; ii) train this
entailment engine over an annotated RTE corpus
to learn a model and iii) use the entailment en-
gine and the model to assign an entailment judg-
ment and a confidence score to each pair of an un-
annotated test corpus.
We used two strategies for combining the rule-
based system with EDITS: Our first strategy was
to let the rule-based system classify those sentence
pairs for which the ERG could produce MRSs, and
use EDITS for the pairs were we did not have
MRSs (or processing failed due to errors in the
MRSs) . The second strategy was to mix the out-
put from both systems when they disagree. In this
case we took the ENTAILMENT decisions from
the rule-based, and EDITS contributes with CON-
TRADICTION and NEUTRAL.
</bodyText>
<sectionHeader confidence="0.997319" genericHeader="method">
4 Analysis
</sectionHeader>
<bodyText confidence="0.9999606">
We have submitted the results obtained from five
system configurations. The first four used the rule-
based system as the core. The fifth was a system
obtained by training EDITS on the training set.
We use the fifth system as a strong baseline. In
the few cases in which the rule-based system did
not produce result (2% of the test set pairs) EDITS
judgments were used in the submission. In System
1 and System 2 we have used the first combination
strategy described in the end of section 3. In Sys-
tem 4 and System 5 the entailment decisions are a
combination of the results from the rule-based sys-
tem and EDITS as described in the second strategy
in the same section. The rule-based component
in System 1 and System 3 has more fine-grained
</bodyText>
<footnote confidence="0.972639">
1http://edits.sf.net
</footnote>
<table confidence="0.99994025">
Precision Recall F-Measure
Contradiction 0.8422 0.7264 0.78
Entailment 0.9719 0.4158 0.5825
Neutral 0.7241 0.9595 0.8254
</table>
<tableCaption confidence="0.999774">
Table 3: Performance of System 1.
</tableCaption>
<bodyText confidence="0.996652038461538">
negation rules so that no q rel is not treated as
a contradiction cue in different contexts (e.g., No
woman runs does not contradict A woman sings).
Table 2 shows the results for the five submitted
systems.
The results demonstrate that the rule-based sys-
tem can be used as a general system for recogniz-
ing textual entailment. It surpasses with 3 points
of accuracy EDITS, which is an established strong
baseline system. We are quite content with the re-
sults obtained as we did not use the training dataset
to create the rules, but only the trial dataset. The
combination of the two systems brings a slight im-
provement.
Overall the rule-based system is quite precise
as demonstrated in Table 3. The numbers in the
table correspond to System 1 but are comparable
to the other rule-based systems 2, 3 and 4. The
system achieves an excellent precision on the en-
tailment and contradiction relations. It is almost
always correct when assigning the entailment rela-
tion. And it also obtains a decent recall, correctly
assigning almost half of the entailment pairs. On
the contradiction relation the system also obtained
a decent result, capturing most of the negation
cases.
</bodyText>
<sectionHeader confidence="0.999443" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999196444444445">
Using a state-of-the-art semantic analysis compo-
nent, we have created a generic rule-based sys-
tem for recognizing textual entailment that obtains
competitive results on a real evaluation dataset.
An advantage of our approach is that it does not
require training. The precision of the approach
makes it an excellent candidate for a system that
uses textual entailment as the core of an intelligent
search engine.
</bodyText>
<page confidence="0.996278">
702
</page>
<sectionHeader confidence="0.99586" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999735975">
Ion Androutsopoulos and Prodromos Malakasiotis.
2010. A Survey of Paraphrasing and Textual Entail-
ment Methods. J. Artif. Intell. Res. (JAIR), 38:135–
187.
Richard Bergmair. 2010. Monte Carlo Semantics: Ro-
bust Inference and Logical Pattern Processing with
Natural Language Text. Ph.D. thesis, University of
Cambridge.
Ann Copestake, Dan Flickinger, Carl Pollard, and
Ivan A. Sag. 2005. Minimal Recursion Semantics:
An Introduction. Research on Language &amp; Compu-
tation, 3(2):281–332.
Dan Flickinger. 2000. On Building a More Effcient
Grammar by Exploiting Types. Natural Language
Engineering, 6(1):15–28.
Milen Kouylekov and Matteo Negri. 2010. An
Open-Source Package for Recognizing Textual En-
tailment. In 48th Annual Meeting of the Associa-
tion for Computational Linguistics (ACL 2010) ,Up-
psala, Sweden, pages 42–47.
Milen Kouylekov, Yashar Mehdad, and Matteo Negri.
2011. Is it Worth Submitting this Run? Assess your
RTE System with a Good Sparring Partner. In Pro-
ceedings of the TextInfer 2011 Workshop on Textual
Entailment, Edinburgh Scotland, pages 30–34.
Elisabeth Lien. 2014. Using Minimal Recursion Se-
mantics for Entailment Recognition. In Proceed-
ings of the Student Research Workshop at the 14th
Conference of the European Chapter of the Associ-
ation for Computational Linguistics, pages 76–84,
Gothenburg, Sweden, April.
Andreas Wotzlaw and Ravi Coote. 2013. A Logic-
based Approach for Recognizing Textual Entailment
Supported by Ontological Background Knowledge.
CoRR, abs/1310.4938.
Deniz Yuret, Aydin Han, and Zehra Turgut. 2010.
SemEval-2010 Task 12: Parser Evaluation using
Textual Entailments. In Proceedings of the 5th
International Workshop on Semantic Evaluation,
pages 51–56.
</reference>
<page confidence="0.998986">
703
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.794945">
<title confidence="0.997551">UIO-Lien: Entailment Recognition using Minimal Recursion Semantics</title>
<author confidence="0.999885">Elisabeth Lien Milen Kouylekov</author>
<affiliation confidence="0.947198">Department of Informatics Department of Informatics University of Oslo, Norway University of Oslo, Norway</affiliation>
<email confidence="0.934753">elien@ifi.uio.nomilen@ifi.uio.no</email>
<abstract confidence="0.996642615384615">In this paper we present our participain the Semeval 2014 task “Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entail- Our results demonstrate that using generic tools for semantic analysis is a viable option for a system that recognizes textual entailment. The invested effort in developing such tools allows us to build systems for reasoning that do not require training.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ion Androutsopoulos</author>
<author>Prodromos Malakasiotis</author>
</authors>
<title>A Survey of Paraphrasing and Textual Entailment Methods.</title>
<date>2010</date>
<journal>J. Artif. Intell. Res. (JAIR),</journal>
<volume>38</volume>
<pages>187</pages>
<contexts>
<context position="1109" citStr="Androutsopoulos and Malakasiotis, 2010" startWordPosition="158" endWordPosition="161"> that using generic tools for semantic analysis is a viable option for a system that recognizes textual entailment. The invested effort in developing such tools allows us to build systems for reasoning that do not require training. 1 Introduction Recognizing textual entailment (RTE) has been a popular area of research in the last years. It has appeared in a variety of evaluation campaigns as both monolingual and multilingual tasks. A wide variety of techniques based on different levels of text interpretation has been used, e.g., lexical distance, dependency parsing and semantic role labeling (Androutsopoulos and Malakasiotis, 2010). Our approach uses a semantic representation formalism called Minimal Recursion Semantics (MRS), which, to our knowledge, has not been used extensively in entailment decision systems. Notable examples of systems that use MRS are Wotzlaw and Coote (2013), and Bergmair (2010). In Wotzlaw and Coote (2013), the authors present an entailment recognition system which combines high-coverage syntactic and semantic text analysis with logical inference supported by relevant background knowledge. MRS is used as an intermediate format in transforming the results of the linguistic analysis into representa</context>
</contexts>
<marker>Androutsopoulos, Malakasiotis, 2010</marker>
<rawString>Ion Androutsopoulos and Prodromos Malakasiotis. 2010. A Survey of Paraphrasing and Textual Entailment Methods. J. Artif. Intell. Res. (JAIR), 38:135– 187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Bergmair</author>
</authors>
<title>Monte Carlo Semantics: Robust Inference and Logical Pattern Processing with Natural Language Text.</title>
<date>2010</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Cambridge.</institution>
<contexts>
<context position="1384" citStr="Bergmair (2010)" startWordPosition="200" endWordPosition="201">lar area of research in the last years. It has appeared in a variety of evaluation campaigns as both monolingual and multilingual tasks. A wide variety of techniques based on different levels of text interpretation has been used, e.g., lexical distance, dependency parsing and semantic role labeling (Androutsopoulos and Malakasiotis, 2010). Our approach uses a semantic representation formalism called Minimal Recursion Semantics (MRS), which, to our knowledge, has not been used extensively in entailment decision systems. Notable examples of systems that use MRS are Wotzlaw and Coote (2013), and Bergmair (2010). In Wotzlaw and Coote (2013), the authors present an entailment recognition system which combines high-coverage syntactic and semantic text analysis with logical inference supported by relevant background knowledge. MRS is used as an intermediate format in transforming the results of the linguistic analysis into representations used for logical reasoning. The approach in Bergmair (2010) This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.</context>
</contexts>
<marker>Bergmair, 2010</marker>
<rawString>Richard Bergmair. 2010. Monte Carlo Semantics: Robust Inference and Logical Pattern Processing with Natural Language Text. Ph.D. thesis, University of Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
<author>Carl Pollard</author>
<author>Ivan A Sag</author>
</authors>
<title>Minimal Recursion Semantics: An Introduction.</title>
<date>2005</date>
<journal>Research on Language &amp; Computation,</journal>
<volume>3</volume>
<issue>2</issue>
<contexts>
<context position="3409" citStr="Copestake et al., 2005" startWordPosition="512" endWordPosition="515">sing a stateof-the-art semantic analysis component, we have created a generic rule-based system for recognizing textual entailment that obtains competitive results on a real evaluation dataset. Our approach does not require training. We confront it with a strong baseline provided by the EDITS system (Kouylekov et al., 2011). In Section 2 we describe the computational semantics framework that forms the basis of our approach. Section 3 details our entailment system, and in Section 4 we analyze our results from the task evaluation. 2 Minimal Recursion Semantics Minimal Recursion Semantics (MRS) (Copestake et al., 2005) is a framework for computational semantics which provides expressive representations with a clear interface with syntax. MRS allows underspecification of scope, in order to capture the different readings of a sentence with a single MRS representation. We use the MRS analyses that are produced by the HPSG English Resource Grammar (ERG) (Flickinger, 2000). 699 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 699–703, Dublin, Ireland, August 23-24, 2014. The core of an MRS representation is a multiset of relations, called elementary predications (EPs). A</context>
</contexts>
<marker>Copestake, Flickinger, Pollard, Sag, 2005</marker>
<rawString>Ann Copestake, Dan Flickinger, Carl Pollard, and Ivan A. Sag. 2005. Minimal Recursion Semantics: An Introduction. Research on Language &amp; Computation, 3(2):281–332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Flickinger</author>
</authors>
<title>On Building a More Effcient Grammar by Exploiting Types.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="3765" citStr="Flickinger, 2000" startWordPosition="569" endWordPosition="570">ational semantics framework that forms the basis of our approach. Section 3 details our entailment system, and in Section 4 we analyze our results from the task evaluation. 2 Minimal Recursion Semantics Minimal Recursion Semantics (MRS) (Copestake et al., 2005) is a framework for computational semantics which provides expressive representations with a clear interface with syntax. MRS allows underspecification of scope, in order to capture the different readings of a sentence with a single MRS representation. We use the MRS analyses that are produced by the HPSG English Resource Grammar (ERG) (Flickinger, 2000). 699 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 699–703, Dublin, Ireland, August 23-24, 2014. The core of an MRS representation is a multiset of relations, called elementary predications (EPs). An EP represents a single lexeme, or general grammatical features. Each EP has a predicate symbol, and a label (also called handle) that identifies the EPs position within the MRS structure. Each EP contains a list of numbered arguments: ARG0, ARG1, etc., whose values are scopal or non-scopal variables. The ARG0 value is called the EP’s distinguished vari</context>
</contexts>
<marker>Flickinger, 2000</marker>
<rawString>Dan Flickinger. 2000. On Building a More Effcient Grammar by Exploiting Types. Natural Language Engineering, 6(1):15–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Milen Kouylekov</author>
<author>Matteo Negri</author>
</authors>
<title>An Open-Source Package for Recognizing Textual Entailment.</title>
<date>2010</date>
<booktitle>In 48th Annual Meeting of the Association for Computational Linguistics (ACL 2010) ,Uppsala, Sweden,</booktitle>
<pages>42--47</pages>
<contexts>
<context position="12085" citStr="Kouylekov and Negri, 2010" startWordPosition="2009" endWordPosition="2012"> but were misclassified either because an incorrect MRS analysis was chosen by the parser or because synonymous words within the scope of the negation were not recognized. EDITS We used a backoff-system for the pairs when the rule-based system fails to produce re701 System 1 2 3 4 5 Rules Only Rules Only Combined Combined Edits Training 76.13 75.4 76.62 76.62 74.78 Test 77.0 76.35 77.12 77.14 74.79 Table 2: Submitted system accuracy on training and test set. sults. Our choice was EDITS1 as it provides a strong baseline system for recognizing textual entailment (Kouylekov et al., 2011). EDITS (Kouylekov and Negri, 2010) is an open source package which offers a modular, flexible, and adaptable working environment for experimenting with the RTE task over different datasets. The package allows to: i) create an entailment engine by defining its basic components; ii) train this entailment engine over an annotated RTE corpus to learn a model and iii) use the entailment engine and the model to assign an entailment judgment and a confidence score to each pair of an unannotated test corpus. We used two strategies for combining the rulebased system with EDITS: Our first strategy was to let the rule-based system classi</context>
</contexts>
<marker>Kouylekov, Negri, 2010</marker>
<rawString>Milen Kouylekov and Matteo Negri. 2010. An Open-Source Package for Recognizing Textual Entailment. In 48th Annual Meeting of the Association for Computational Linguistics (ACL 2010) ,Uppsala, Sweden, pages 42–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Milen Kouylekov</author>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
</authors>
<title>Is it Worth Submitting this Run? Assess your RTE System with a Good Sparring Partner.</title>
<date>2011</date>
<booktitle>In Proceedings of the TextInfer 2011 Workshop on Textual Entailment,</booktitle>
<pages>30--34</pages>
<location>Edinburgh Scotland,</location>
<contexts>
<context position="3111" citStr="Kouylekov et al., 2011" startWordPosition="464" endWordPosition="467">forms the basis for entailment recognition. If key nodes in the hypothesis MRS can be aligned to nodes in the text MRS, this is treated as an indicator of entailment. This paper represents our first attempt to evaluate a system based on logical-form semantic representations in a RTE competition. Using a stateof-the-art semantic analysis component, we have created a generic rule-based system for recognizing textual entailment that obtains competitive results on a real evaluation dataset. Our approach does not require training. We confront it with a strong baseline provided by the EDITS system (Kouylekov et al., 2011). In Section 2 we describe the computational semantics framework that forms the basis of our approach. Section 3 details our entailment system, and in Section 4 we analyze our results from the task evaluation. 2 Minimal Recursion Semantics Minimal Recursion Semantics (MRS) (Copestake et al., 2005) is a framework for computational semantics which provides expressive representations with a clear interface with syntax. MRS allows underspecification of scope, in order to capture the different readings of a sentence with a single MRS representation. We use the MRS analyses that are produced by the </context>
<context position="12050" citStr="Kouylekov et al., 2011" startWordPosition="2004" endWordPosition="2007">rs. The rest contained negation, but were misclassified either because an incorrect MRS analysis was chosen by the parser or because synonymous words within the scope of the negation were not recognized. EDITS We used a backoff-system for the pairs when the rule-based system fails to produce re701 System 1 2 3 4 5 Rules Only Rules Only Combined Combined Edits Training 76.13 75.4 76.62 76.62 74.78 Test 77.0 76.35 77.12 77.14 74.79 Table 2: Submitted system accuracy on training and test set. sults. Our choice was EDITS1 as it provides a strong baseline system for recognizing textual entailment (Kouylekov et al., 2011). EDITS (Kouylekov and Negri, 2010) is an open source package which offers a modular, flexible, and adaptable working environment for experimenting with the RTE task over different datasets. The package allows to: i) create an entailment engine by defining its basic components; ii) train this entailment engine over an annotated RTE corpus to learn a model and iii) use the entailment engine and the model to assign an entailment judgment and a confidence score to each pair of an unannotated test corpus. We used two strategies for combining the rulebased system with EDITS: Our first strategy was </context>
</contexts>
<marker>Kouylekov, Mehdad, Negri, 2011</marker>
<rawString>Milen Kouylekov, Yashar Mehdad, and Matteo Negri. 2011. Is it Worth Submitting this Run? Assess your RTE System with a Good Sparring Partner. In Proceedings of the TextInfer 2011 Workshop on Textual Entailment, Edinburgh Scotland, pages 30–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elisabeth Lien</author>
</authors>
<title>Using Minimal Recursion Semantics for Entailment Recognition.</title>
<date>2014</date>
<booktitle>In Proceedings of the Student Research Workshop at the 14th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>76--84</pages>
<location>Gothenburg, Sweden,</location>
<contexts>
<context position="5482" citStr="Lien (2014)" startWordPosition="865" endWordPosition="866">ment-value pairs: its distinguished variable e3 denotes an event, and the variables x6 and xg refer to the entities filling the agent and patient roles in the verb event. x6 and xg are in turn the distinguished variables of the EPs that represent a woman and a potato, respectively. 3 System Description In the following, Tsent and Hsent refer to the text and hypothesis sentence, and Tmrs and Hmrs to their MRS representations. The core of our system is a rule based component, which bases entailment decision on graph alignment over MRS structures. An earlier version of the system is described in Lien (2014). The earlier version was developed on the data set from the SemEval-2010 shared task Parser Evaluation using Textual Entailment (PETE) (Yuret et al., 2010). Using no external linguistic resources, the system output positive entailment decisions for sentence pairs where core nodes of the Hmrs could be aligned to nodes in Tmrs according to a set of heuristic matching rules. The system we present in this paper extends the earlier version by adding support for contradiction recognition, and by using lexical relations from WordNet. For our participation in the entailment recognition task, first, w</context>
<context position="7417" citStr="Lien (2014)" startWordPosition="1183" endWordPosition="1184">annot be inferred from Tsent. Our system accounts for many of these characteristics. The system bases its decision on the results of two procedures: a) an event relation match which searches for an alignment between the MRSs, and b) a contradiction cue check. After running these procedures, the system outputs 1. ENTAILMENT, if the event relation matching procedure found an alignment, and no contradiction cues were found, 2. CONTRADICTION, if contradiction cues were found, 3. NEUTRAL, if neither of the above conditions are met. The event relation matching procedure extends the one developed in Lien (2014) to account for the greater lexical variation in the SICK data. The procedure selects all the EPs in Tmrs and Hmrs that have an event variable as their ARG0—we call them event relations. These event relations mainly represent verbs, verb conjunctions, adjectives, and prepositions. For each event relation Hevent in the hypothesis the procedure tries to find a matching relation Tevent among the text event relations. We say that Hevent matches Tevent if: 1. they represent the same lexeme with the same part-of-speech, or if both are verbs and Hevent is a synonym or hypernym of Tevent, and 2. all t</context>
</contexts>
<marker>Lien, 2014</marker>
<rawString>Elisabeth Lien. 2014. Using Minimal Recursion Semantics for Entailment Recognition. In Proceedings of the Student Research Workshop at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 76–84, Gothenburg, Sweden, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Wotzlaw</author>
<author>Ravi Coote</author>
</authors>
<title>A Logicbased Approach for Recognizing Textual Entailment Supported by Ontological Background Knowledge.</title>
<date>2013</date>
<location>CoRR, abs/1310.4938.</location>
<contexts>
<context position="1363" citStr="Wotzlaw and Coote (2013)" startWordPosition="195" endWordPosition="198">tailment (RTE) has been a popular area of research in the last years. It has appeared in a variety of evaluation campaigns as both monolingual and multilingual tasks. A wide variety of techniques based on different levels of text interpretation has been used, e.g., lexical distance, dependency parsing and semantic role labeling (Androutsopoulos and Malakasiotis, 2010). Our approach uses a semantic representation formalism called Minimal Recursion Semantics (MRS), which, to our knowledge, has not been used extensively in entailment decision systems. Notable examples of systems that use MRS are Wotzlaw and Coote (2013), and Bergmair (2010). In Wotzlaw and Coote (2013), the authors present an entailment recognition system which combines high-coverage syntactic and semantic text analysis with logical inference supported by relevant background knowledge. MRS is used as an intermediate format in transforming the results of the linguistic analysis into representations used for logical reasoning. The approach in Bergmair (2010) This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommo</context>
</contexts>
<marker>Wotzlaw, Coote, 2013</marker>
<rawString>Andreas Wotzlaw and Ravi Coote. 2013. A Logicbased Approach for Recognizing Textual Entailment Supported by Ontological Background Knowledge. CoRR, abs/1310.4938.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deniz Yuret</author>
<author>Aydin Han</author>
<author>Zehra Turgut</author>
</authors>
<title>SemEval-2010 Task 12: Parser Evaluation using Textual Entailments.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<pages>51--56</pages>
<contexts>
<context position="5638" citStr="Yuret et al., 2010" startWordPosition="888" endWordPosition="891">les in the verb event. x6 and xg are in turn the distinguished variables of the EPs that represent a woman and a potato, respectively. 3 System Description In the following, Tsent and Hsent refer to the text and hypothesis sentence, and Tmrs and Hmrs to their MRS representations. The core of our system is a rule based component, which bases entailment decision on graph alignment over MRS structures. An earlier version of the system is described in Lien (2014). The earlier version was developed on the data set from the SemEval-2010 shared task Parser Evaluation using Textual Entailment (PETE) (Yuret et al., 2010). Using no external linguistic resources, the system output positive entailment decisions for sentence pairs where core nodes of the Hmrs could be aligned to nodes in Tmrs according to a set of heuristic matching rules. The system we present in this paper extends the earlier version by adding support for contradiction recognition, and by using lexical relations from WordNet. For our participation in the entailment recognition task, first, we did an analysis of the SICK trial data. In the ENTAILMENT pairs, Hsent is a paraphrase over the whole or part of the text sentence. The changes from Tsent</context>
</contexts>
<marker>Yuret, Han, Turgut, 2010</marker>
<rawString>Deniz Yuret, Aydin Han, and Zehra Turgut. 2010. SemEval-2010 Task 12: Parser Evaluation using Textual Entailments. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 51–56.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>