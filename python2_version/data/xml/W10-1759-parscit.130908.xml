<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002181">
<title confidence="0.989626">
Translation Model Adaptation by Resampling
</title>
<author confidence="0.979369">
Kashif Shah, Lo¨ıc Barrault, Holger Schwenk
</author>
<affiliation confidence="0.923935">
LIUM, University of Le Mans
</affiliation>
<address confidence="0.717585">
Le Mans, France.
</address>
<email confidence="0.96977">
FirstName.LastName@lium.univ-lemans.fr
</email>
<sectionHeader confidence="0.993238" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999980416666667">
The translation model of statistical ma-
chine translation systems is trained on par-
allel data coming from various sources and
domains. These corpora are usually con-
catenated, word alignments are calculated
and phrases are extracted. This means
that the corpora are not weighted accord-
ing to their importance to the domain of
the translation task. This is in contrast
to the training of the language model for
which well known techniques are used to
weight the various sources of texts. On
a smaller granularity, the automatic cal-
culated word alignments differ in quality.
This is usually not considered when ex-
tracting phrases either.
In this paper we propose a method to auto-
matically weight the different corpora and
alignments. This is achieved with a resam-
pling technique. We report experimen-
tal results for a small (IWSLT) and large
(NIST) Arabic/English translation tasks.
In both cases, significant improvements in
the BLEU score were observed.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998742245283019">
Two types of resources are needed to train statis-
tical machine translation (SMT) systems: parallel
corpora to train the translation model and mono-
lingual texts in the target language to build the
language model. The performance of both mod-
els depends of course on the quality and quantity
of the available resources.
Today, most SMT systems are generic, i.e. the
same system is used to translate texts of all kinds.
Therefore, it is the domain of the training re-
sources that influences the translations that are se-
lected among several choices. While monolingual
texts are in general easily available in many do-
mains, the freely available parallel texts mainly
come from international organisations, like the
European Union or the United Nations. These
texts, written in particular jargon, are usually
much larger than in-domain bitexts. As an exam-
ple we can cite the development of an NIST Ara-
bic/English phrase-based translation system. The
current NIST test sets are composed of a news
wire part and a second part of web-style texts.
For both domains, there is only a small number
of in-domain bitexts available, in comparison to
almost 200 millions words of out-of-domain UN
texts. The later corpus is therefore likely to domi-
nate the estimation of the probability distributions
of the translation model.
It is common practice to use a mixture language
model with coefficients that are optimized on the
development data, i.e. by these means on the do-
main of the translation task. Domain adaptation
seems to be more tricky for the translation model
and it seems that very little research has been done
that seeks to apply similar ideas to the translation
model. To the best of our knowledge, there is no
commonly accepted method to weight the bitexts
coming from different sources so that the transla-
tion model is best optimized to the domain of the
task. Mixture models are possible when only two
different bitexts are available, but are rarely used
for more corpora (see discussion in the next sec-
tion).
In this work we propose a new method to adapt
the translation model of an SMT system. We only
perform experiments with phrase-based systems,
but the method is generic and could be easily ap-
plied to an hierarchical or syntax-based system.
We first associate a weighting coefficient to each
bitext. The main idea is to use resampling to pro-
duce a new collection of weighted alignment files,
followed by the standard procedure to extract the
phrases. In a second step, we also consider the
</bodyText>
<page confidence="0.97973">
392
</page>
<note confidence="0.4532405">
Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 392–399,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999831230769231">
alignment score of each parallel sentence pair, em-
phasizing by these means good alignments and
down-weighting less reliable ones. All the param-
eters of our procedure are automatically tuned by
optimizing the BLEU score on the development
data.
The paper is organized as follows. The next
section describes related work on weighting the
corpora and model adaptation. Section 3 de-
scribes the architecture allowing to resample and
to weight the bitexts. Experimental results are pre-
sented in section 4 and the paper concludes with a
discussion.
</bodyText>
<sectionHeader confidence="0.999781" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999881168831169">
Adaptation of SMT systems is a topic of in-
creasing interest since few years. In previous
work, adaptation is done by using mixture mod-
els, by exploiting comparable corpora and by self-
enhancement of translation models.
Mixture models were used to optimize the co-
efficients to the adaptation domain. (Civera and
Juan, 2007) proposed a model that can be used
to generate topic-dependent alignments by exten-
sion of the HMM alignment model and derivation
of Viterbi alignments. (Zhao et al., 2004) con-
structed specific language models by using ma-
chine translation output as queries to extract sim-
ilar sentences from large monolingual corpora.
(Foster and Kuhn, 2007) applied a mixture model
approach to adapt the system to a new domain by
using weights that depend on text distances to mix-
ture components. The training corpus was divided
into different components, a model was trained on
each part and then weighted appropriately for the
given context. (Koehn and Schroeder, 2007) used
two language models and two translation models:
one in-domain and other out-of-domain to adapt
the system. Two decoding paths were used to
translate the text.
Comparable corpora are exploited to find addi-
tional parallel texts. Information retrieval tech-
niques are used to identify candidate sentences
(Hildebrand et al., 2005). (Snover et al., 2008)
used cross-lingual information retrieval to find
texts in the target language that are related to the
domain of the source texts.
A self-enhancing approach was applied by
(Ueffing, 2006) to filter the translations of the
test set with the help of a confidence score and
to use reliable alignments to train an additional
phrase table. This additional table was used with
the existing generic phrase table. (Ueffing, 2007)
further refined this approach by using transduc-
tive semi-supervised methods for effective use of
monolingual data from the source text. (Chen et
al., 2008) performed domain adaptation simulta-
neously for the translation, language and reorder-
ing model by learning posterior knowledge from
N-best hypothesis. A related approach was in-
vestigated in (Schwenk, 2008) and (Schwenk and
Senellart, 2009) in which lightly supervised train-
ing was used. An SMT system was used to trans-
late large collections of monolingual texts, which
were then filtered and added to the training data.
(Matsoukas et al., 2009) propose to weight each
sentence in the training bitext by optimizing a dis-
criminative function on a given tuning set. Sen-
tence level features were extracted to estimate the
weights that are relevant to the given task. Then
certain parts of the training bitexts were down-
weighted to optimize an objective function on the
development data. This can lead to parameter
over-fitting if the function that maps sentence fea-
tures to weights is complex.
The technique proposed in this paper is some-
how related to the above approach of weighting
the texts. Our method does not require an ex-
plicit specification of the in-domain and out-of-
domain training data. The weights of the corpora
are directly optimized on the development data us-
ing a numerical method, similar to the techniques
used in the standard minimum error training of the
weights of the feature functions in the log-linear
criterion. All the alignments of the bitexts are re-
sampled and given equal chance to be selected and
therefore, influence the translation model in a dif-
ferent way. Our proposed technique does not re-
quire the calculation of extra sentence level fea-
tures, however, it may use the alignments score as-
sociated with each aligned sentence pair as a con-
fidence score.
</bodyText>
<sectionHeader confidence="0.882945" genericHeader="method">
3 Description of the algorithm
</sectionHeader>
<bodyText confidence="0.999589875">
The architecture of the algorithm is summarized in
figure 1. The starting point is an (arbitrary) num-
ber of parallel corpora. We first concatenate these
bitexts and perform word alignments in both direc-
tions using GIZA++. This is done on the concate-
nated bitexts since GIZA++ may perform badly
if some of the individual bitexts are rather small.
Next, the alignments are separated in parts corre-
</bodyText>
<page confidence="0.998779">
393
</page>
<figureCaption confidence="0.999908">
Figure 1: Architecture of SMT Weighting System
</figureCaption>
<bodyText confidence="0.99992468">
sponding to the individual bitexts and a weighting
coefficient is associated to each one. We are not
aware of a procedure to calculate these coefficients
in an easy and fast way without building an actual
SMT system. Note that there is an EM procedure
to do this for language modeling.
In the next section, we will experimentally com-
pare equal coefficients, coefficients set to the same
values than those obtained when building an inter-
polated language model on the source language,
and a new method to determine the coefficients by
optimizing the BLEU score on the development
data.
One could imagine to directly use these coef-
ficients when calculating the various probabilities
of the extracted phrases. In this work, we propose
a different procedure that makes no assumptions
on how the phrases are extracted and probabilities
are calculated. The idea is to resample alignments
from the alignment file corresponding to the indi-
vidual bitexts according to their weighting coeffi-
cients. By these means, we create a new, poten-
tially larger alignment file, which then in turn will
be used by the standard phrase extraction proce-
dure.
</bodyText>
<subsectionHeader confidence="0.999457">
3.1 Resampling the alignments
</subsectionHeader>
<bodyText confidence="0.999974461538461">
In statistics, resampling is based upon repeated
sampling within the same sample until a sample
is obtained which better represents a given data
set (Yu, 2003). Resampling is used for validating
models on given data set by using random subsets.
It overcomes the limitations to make assumptions
about the distribution of the data. Usually resam-
pling is done several times to better estimate and
select the samples which better represents the tar-
get data set. The more often we resample, the
closer we get to the true probability distribution.
In our case we performed resampling with re-
placement according to the following algorithm:
</bodyText>
<listItem confidence="0.911954">
Algorithm 1 Resampling
1: for i = 0 to required size do
2: Select any alignment randomly
3: Al,,,,, +— normalized alignment score
4: Threshold +— rand[0, 1]
5: if Al,,,,, &gt; Threshold then
6: keep it
7: end if
8: end for
</listItem>
<bodyText confidence="0.999963583333333">
Let us call resampling factor, the number of
times resampling should be done. An interesting
question is to determine the optimal value of this
resampling factor.
It actually depends upon the task or data we are
experimenting on. We may start with one time
resampling and could stop when results becomes
stable. Figure 2 plots a typical curve of the BLEU
score as a function of the number of times we re-
sample. It can be observed that the curve is grow-
ing proportionally to the resampling factor until it
becomes stable after a certain point.
</bodyText>
<subsectionHeader confidence="0.999721">
3.2 Weighting Schemes
</subsectionHeader>
<bodyText confidence="0.9972987">
We concentrated on translation model adaptation
when the bitexts are heterogeneous, e.g. in-
domain and out-of-domain or of different sizes. In
this case, weighting these bitexts seems interest-
ing and can be used in order to select data which
better represent the target domain. Secondly when
sentences are aligned, some alignments are reli-
able and some are less. Using unreliable align-
ments can put negative effect on the translation
quality. So we need to exclude or down-weight
</bodyText>
<page confidence="0.986079">
394
</page>
<figure confidence="0.994676333333333">
BLEU
0 5 10 15 20
Resampling factor
</figure>
<figureCaption confidence="0.752234">
Figure 2: The curve shows that by increasing the
resampling factor we get better and stable results
on Dev and Test.
</figureCaption>
<bodyText confidence="0.99660375">
unreliable alignments and keep or up-weight the
good ones. We conceptually divided the weight-
ing in two parts that is (i) weighting the corpora
and (ii) weighting the alignments
</bodyText>
<subsectionHeader confidence="0.901198">
3.2.1 Weighting Corpora
</subsectionHeader>
<bodyText confidence="0.999482">
We started to resample the bitexts with equal
weights to see the effect of resampling. This gives
equal importance to each bitext without taking into
account the domain of the text to be translated.
However, it should be better to give appropriate
weights according to a given domain as shown in
equation 1
</bodyText>
<equation confidence="0.992678">
a1bitext1 + a2bitext2 + .. + anbitextn (1)
</equation>
<bodyText confidence="0.999905473684211">
where the an are the coefficients to optimize.
One important question is how to find out the ap-
propriate coefficient for each corpus. We investi-
gated a technique similar to the algorithm used to
minimize the perplexity of an interpolated target
LM. Alternatively, it is also possible to construct a
interpolated language model on the source side of
bitexts. This approach was implemented and these
coefficients were used as the weights for each bi-
text. One can certainly ask the question whether
the perplexity is a good criterion for weighting bi-
texts. Therefore, we worked on direct optimiza-
tion of these coefficients by CONDOR (Berghen
and Bersini, 2005). This freely available tool is a
numerical optimizer based on Powell’s UOBYQA
algorithm (Powell, 1994). The aim of CONDOR
is to minimize a objective function using the least
number of function evaluations. Formally, it is
used to find x* E Rn with given constraints which
</bodyText>
<equation confidence="0.920341333333333">
satisfies
F(x*) = min F(x) (2)
x
</equation>
<bodyText confidence="0.88489825">
where n is the dimension of search space and x*
is the optimum of x. The following algorithm was
used to weight the bitexts.
Algorithm 2 WeightingCorpora
</bodyText>
<listItem confidence="0.978194307692308">
1: Determine word to word alignment with
GIZA++ on concatenated bitext.
2: while Not converged do
3: Run Condor initialized with LM weights.
4: Create new alignment file by resampling
according to weights given by Condor.
5: Use the alignment file to extract phrases
and build the translation table (phrase table)
6: Tune the system with MERT (this step can
be skipped until weights are optimized to
save time)
7: Calculate the BLEU score
8: end while
</listItem>
<subsectionHeader confidence="0.921537">
3.2.2 Weighting Alignments
</subsectionHeader>
<bodyText confidence="0.994977272727273">
Alignments produced by GIZA++ have alignment
scores associated with each sentence pair in both
direction, i.e. source to target and target to source.
We used these alignment scores as confidence
measurement for each sentence pair. Alignment
scores depend upon the length of each sentence,
therefore, they must be normalized regarding the
size of the sentence. Alignment scores have a very
large dynamic range and we have applied a loga-
rithmic mapping in order to flatten the probability
distribution :
</bodyText>
<equation confidence="0.982509">
( ntrg�asrc trg + nsrc �atrg src)
log(A · ) (3)
2
</equation>
<bodyText confidence="0.999978857142857">
where a is the alignment score, n the size of a
sentence and λ a coefficient to optimize. This is
also done by Condor.
Of course, some alignments will appear several
times, but this will increase the probability of cer-
tain phrase-pairs which are supposed to be more
related to the target domain. We have observed
that the weights of an interpolated LM build on
the source side of the bitext are good initial val-
ues for CONDOR. Moreover, weights optimized
by Condor are in the same order than these “LM
weights”. Therefore, we do not perform MERT
of the SMT systems build at each step of the op-
timization of the weights az and A by CONDOR,
</bodyText>
<figure confidence="0.98237425">
56
55.5
55
54.5
54
53.5
53
52.5
52
dev
test
baseline(test)
</figure>
<page confidence="0.995524">
395
</page>
<table confidence="0.999738166666667">
IWSLT Task NIST Task
Dev (Dev6) Test (Dev7) Dev (NIST06) Test (NIST08)
Baseline 53.98 53.37 43.16 42.21
With equal weights 53.71 53.20 43.10 42.11
With LM weights 54.20 53.71 43.42 42.22
Condor weights 54.80 53.98 43.49 42.28
</table>
<tableCaption confidence="0.991236">
Table 1: BLEU scores when weighting corpora (one time resampling)
</tableCaption>
<table confidence="0.999868166666667">
IWSLT Task NIST Task
Dev (Dev6) Test (Dev7) Dev (NIST06) Test (NIST08)
Baseline 53.98 53.37 43.16 42.21
With equal weights 53.80 53.30 43.13 42.15
With LM weights 54.32 53.91 43.54 42.37
Condor weights 55.10 54.13 43.80 42.40
</table>
<tableCaption confidence="0.927554">
Table 2: BLEU scores when weighting corpora (optimum number of resampling)
</tableCaption>
<table confidence="0.999785166666667">
Dev (Dev6) IWSLT Task TER(Test) Dev (NIST06) NIST Task TER(Test)
Test (Dev7) Test (NIST08)
Baseline 53.98 53.37 32.75 43.16 42.21 51.69
With equal weights 53.85 53.33 32.80 43.28 42.21 51.72
With LM weights 54.80 54.10 31.50 43.42 42.41 51.50
Condor weights 55.48 54.58 31.31 43.95 42.54 51.35
</table>
<tableCaption confidence="0.85529">
Table 3: BLEU and TER scores when weighting corpora and alignments (optimum number of resam-
pling)
</tableCaption>
<bodyText confidence="0.998275285714286">
but use the values obtained by running MERT on
a system obtained by using the “LM weights” to
weight the alignments. Once CONDOR has con-
verged to optimal weights, we can then tune our
system by MERT. This saves lot of time taken by
the tuning process and it had no impact on the re-
sults.
</bodyText>
<sectionHeader confidence="0.996728" genericHeader="method">
4 Experimental evaluation
</sectionHeader>
<bodyText confidence="0.999911285714285">
The baseline system is a standard phrase-based
SMT system based on the Moses SMT toolkit
(Koehn and et al., 2007). In our system we
used fourteen features functions. These features
functions include phrase and lexical translation
probabilities in both directions, seven features for
lexicalized distortion model, a word and phrase
penalty, and a target language model. The MERT
tool is used to tune the coefficients of these fea-
ture functions. We considered Arabic to English
translation. Tokenization of the Arabic source
texts is done by a tool provided by SYSTRAN
which also performs a morphological decompo-
sition. We considered two well known official
evaluation tasks to evaluate our approach, namely
NIST and IWSLT.
For IWSLT, we used the BTEC bitexts (194M
words), Dev1, Dev2, Dev3 (60M words each) as
training data, Dev6 as development set and Dev7
as test set. From previous experiments, we have
evidence that the various development corpora are
not equally important and weighting them cor-
rectly should improve the SMT system. We an-
alyze the translation quality as measured by the
BLEU score for the three methods: equal weights,
LM weights and Condor weights and considering
one time resampling. Further experiments were
performed using the optimized number of resam-
pling with and without weighting the alignments.
We have realized that it is beneficial to always in-
clude the original alignments. Even if we resample
many times there is a chance that some alignments
might never be selected but we do not want to
loose any information. By keeping original align-
ments, all alignments are given a chance to be se-
</bodyText>
<page confidence="0.997702">
396
</page>
<bodyText confidence="0.999794680851064">
lected at least once. All these results are summa-
rized in tables 1, 2 and 3.
One time resampling along with equal weights
gave worse results than the baseline system while
improvements in the BLEU score were observed
with LM and Condor weights for the IWSLT task,
as shown in table 1. Resampling many times al-
ways gave more stable results, as already shown
in figure 2 and as theoretically expected. For this
task, we resampled 15 times. The improvements
in the BLEU score are shown in table 2. Fur-
thermore, using the alignment scores resulted in
additional improvements in the BLEU score. For
the IWSLT task, we achieved and overall improve-
ment of 1.5 BLEU points on the development set
and 1.2 BLEU points on the test set as shown in
table 3
To validate our approach we further experi-
mented with the NIST evaluation task. Most of
the training data used in our experiments for the
NIST task is made available through the LDC. The
bitexts consist of texts from the GALE project1
(1.6M words), various news wire translations2
(8.0M words) on development data from pre-
vious years (1.6M words), LDC treebank data
(0.4M words) and the ISI extracted bitexts (43.7M
words). The official NIST06 evaluation data was
used as development set and the NIST08 evalua-
tion data was used as test set. The same procedure
was adapted for the NIST task as for the IWSLT
task. Results are shown in table 1 by using differ-
ent weights and one time resampling. Further im-
provements in the results are shown in table 2 with
the optimum number of resampling which is 10
for this task. Finally, results by weighting align-
ments along with weighting corpora are shown in
table 3. Our final system achieved an improve-
ment of 0.79 BLEU points on the development set
and 0.33 BLEU points on the test set. TER scores
are also shown on test set of our final system in
table 3. Note that these results are state-of-the-art
when compared to the official results of the 2008
NIST evaluation3.
The weights of the different corpora are shown
in table 4 for the IWSLT and NIST task. In both
cases, the weights optimized by CONDOR are
substantially different form those obtained when
</bodyText>
<footnote confidence="0.9171166">
1LDC2005E83, 2006E24, E34, E85 and E92
2LDC2003T07, 2004E72, T17, T18, 2005E46 and
2006E25.
3http://www.nist.gov/speech/tests/mt/
2008/
</footnote>
<bodyText confidence="0.998134444444444">
creating an interpolated LM on the source side of
the bitexts. In any case, the weights are clearly
non uniform, showing that our algorithm has fo-
cused on in-domain data. This can be nicely seen
for the NIST task. The Gale texts were explictely
created to contain in-domain news wire and WEB
texts and actually get a high weight despite their
small size, in comparison to the more general news
wire collection from LDC.
</bodyText>
<sectionHeader confidence="0.97169" genericHeader="conclusions">
5 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.999930923076923">
We have proposed a new technique to adapt the
translation model by resampling the alignments,
giving a weight to each corpus and using the
alignment score as confidence measurement of
each aligned phrase pair. Our technique does not
change the phrase pairs that are extracted,4 but
only the corresponding probability distributions.
By these means we hope to adapt the translation
model in order to increase the weight of transla-
tions that are important to the task, and to down-
weight the phrase pairs which result from unreli-
able alignments.
We experimentally verified the new method on
the low-resource IWSLT and the resource-rich
NIST’08 tasks. We observed significant improve-
ment on both tasks over state-of-the-art baseline
systems. This weighting scheme is generic and
it can be applied to any language pair and target
domain. We made no assumptions on how the
phrases are extracted and it should be possible to
apply the same technique to other SMT systems
which rely on word-to-word alignments.
On the other hand, our method is computation-
ally expensive since the optimisation of the coef-
ficients requires the creation of a new phrase table
and the evaluation of the resulting system in the
tuning loop. Note however, that we run GIZA++
only once.
In future work, we will try to directly use the
weights of the corpora and the alignments in the
algorithm that extracts the phrase pairs and cal-
culates their probabilities. This would answer
the interesting question whether resampling itself
is needed or whether weighting the corpora and
alignments is the key to the observed improve-
ments in the BLEU score.
Finally, it is straight forward to consider more
feature functions when resampling the alignments.
This may be a way to integrate linguistic knowl-
</bodyText>
<footnote confidence="0.97835">
4when also including the original alignments
</footnote>
<page confidence="0.984665">
397
</page>
<table confidence="0.999833625">
IWSLT Task BTEC Dev1 Dev2 Dev3
# of Words 194K 60K 60K 60K
LM Coeffs 0.7233 0.1030 0.0743 0.0994
Condor Coeffs 0.6572 0.1058 0.1118 0.1253
NIST TASK Gale NewsWire TreeBank Dev ISI
# of words 1.6M 8.1M 0.4M 1.7M 43.7M
LM Coeffs 0.3215 0.1634 0.0323 0.1102 0.3726
Condor Coeffs 0.4278 0.1053 0.0489 0.1763 0.2417
</table>
<tableCaption confidence="0.999724">
Table 4: Weights of the different bitexts.
</tableCaption>
<bodyText confidence="0.995799333333333">
edge into the SMT system, e.g. giving low scores
to word alignments that are “grammatically not
reasonable”.
</bodyText>
<sectionHeader confidence="0.998556" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998265">
This work has been partially funded by the Eu-
ropean Commission under the project Euromatrix
and by the Higher Education Commission(HEC)
Pakistan as Overseas scholarship. We are very
thankful to SYSTRAN who provided support for
the Arabic tokenization.
</bodyText>
<sectionHeader confidence="0.997743" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997747965517241">
Frank Vanden Berghen and Hugues Bersini.
2005. CONDOR, a new parallel, constrained
extension of Powell’s UOBYQA algorithm:
Experimental results and comparison with the
DFO algorithm. Journal of Computational and
Applied Mathematics, 181:157–175, Septem-
ber.
Boxing Chen, Min Zhang, Aiti Aw, and
Haizhou Li. 2008. Exploiting n-best hypothe-
ses for SMT self- enhancement. In Association
for Computational Linguistics, pages 157–160.
Jorge Civera and Alfons Juan. 2007. Do-
main adaptation in statistical machine transla-
tion with mixture modelling. In Second Work-
shop on SMT, pages 177–180.
George Foster and Roland Kuhn. 2007.
Mixture-model adaptation for SMT. In Pro-
ceedings of the Second Workshop on Statistical
Machine Translation, pages 128–135. Associa-
tion for Computational Linguistics.
Almut Silja Hildebrand, Matthias Eck, Stephan
Vogel, and Alex Waibel. 2005. Adaptation
of the translation model for statistical machine
translation based on information retrieval. In
EAMT, pages 133–142.
Philipp Koehn and et al. 2007. Moses: Open
source toolkit for statistical machine transla-
tion. In Association for Computational Linguis-
tics, demonstration session., pages 224–227.
Philipp Koehn and Josh Schroeder. 2007. Ex-
periments in domain adaptation for statistical
machine translation. In Proceedings of the Sec-
ond Workshop on Statistical Machine Transla-
tion, pages 224–227. Association for Computa-
tional Linguistics.
Spyros Matsoukas, Antti-Veikko I. Rosti, and
Bing Zhang. 2009. Discriminative corpus
weight estimation for machine translation. In
Proceedings of the 2009 Conference on Empir-
ical Methods in Natural Language Processing,
pages 708–717.
M.J.D. Powell. 1994. A direct search opti-
mization method that models the objective and
constraint functions by linar interpolation. In
In Advances in Optimization and Numerical
Analysis, Proceedings of the sixth Workshop
on Optimization and Numerical Analysis, Oax-
aca, Mexico, volume 275, pages 51–67. Kluwer
Academic Publishers.
Holger Schwenk and Jean Senellart. 2009.
Translation model adaptation for an Ara-
bic/French news translation system by lightly-
supervised training. In MT Summit.
Holger Schwenk. 2008. Investigations on large-
scale lightly-supervised training for statistical
machine translation. In IWSLT, pages 182–189.
Matthew Snover, Bonnie Dorr, and Richard
Schwartz. 2008. Language and translation
</reference>
<page confidence="0.986174">
398
</page>
<reference confidence="0.942921842105263">
model adaptation using comparalble corpora.
In Proceedings of the 2008 Conference on Em-
pirical Methods in Natural Language Process-
ing, pages 857–866.
Nicola Ueffing. 2006. Using monolingual sour-
cce language data to improve MT performance.
In IWSLT, pages 174–181.
Nicola Ueffing. 2007. Transductive learning for
statistical machine translation. In Association
for Computational Linguistics, pages 25–32.
Chong Ho Yu. 2003. Resampling methods:
Concepts, applications, and justification. In
Practical Assessment Research and Evaluation.
Bing Zhao, Matthias Ech, and Stephen Vogal.
2004. Language model adaptation for statistical
machine translation with structured query mod-
els. In Proceedings of the 20th international
conference on Computational Linguistics. As-
sociation for Computational Linguistics.
</reference>
<page confidence="0.999165">
399
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.446957">
<title confidence="0.999709">Translation Model Adaptation by Resampling</title>
<author confidence="0.990874">Kashif Shah</author>
<author confidence="0.990874">Lo¨ıc Barrault</author>
<author confidence="0.990874">Holger</author>
<affiliation confidence="0.8256345">LIUM, University of Le Le Mans,</affiliation>
<email confidence="0.853875">FirstName.LastName@lium.univ-lemans.fr</email>
<abstract confidence="0.98960024">The translation model of statistical machine translation systems is trained on parallel data coming from various sources and domains. These corpora are usually concatenated, word alignments are calculated and phrases are extracted. This means that the corpora are not weighted according to their importance to the domain of the translation task. This is in contrast to the training of the language model for which well known techniques are used to weight the various sources of texts. On a smaller granularity, the automatic calculated word alignments differ in quality. This is usually not considered when extracting phrases either. In this paper we propose a method to automatically weight the different corpora and alignments. This is achieved with a resampling technique. We report experimental results for a small (IWSLT) and large (NIST) Arabic/English translation tasks. In both cases, significant improvements in the BLEU score were observed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Frank Vanden Berghen</author>
<author>Hugues Bersini</author>
</authors>
<title>CONDOR, a new parallel, constrained extension of Powell’s UOBYQA algorithm: Experimental results and comparison with the DFO algorithm.</title>
<date>2005</date>
<journal>Journal of Computational and Applied Mathematics,</journal>
<pages>181--157</pages>
<contexts>
<context position="12884" citStr="Berghen and Bersini, 2005" startWordPosition="2110" endWordPosition="2113">ts to optimize. One important question is how to find out the appropriate coefficient for each corpus. We investigated a technique similar to the algorithm used to minimize the perplexity of an interpolated target LM. Alternatively, it is also possible to construct a interpolated language model on the source side of bitexts. This approach was implemented and these coefficients were used as the weights for each bitext. One can certainly ask the question whether the perplexity is a good criterion for weighting bitexts. Therefore, we worked on direct optimization of these coefficients by CONDOR (Berghen and Bersini, 2005). This freely available tool is a numerical optimizer based on Powell’s UOBYQA algorithm (Powell, 1994). The aim of CONDOR is to minimize a objective function using the least number of function evaluations. Formally, it is used to find x* E Rn with given constraints which satisfies F(x*) = min F(x) (2) x where n is the dimension of search space and x* is the optimum of x. The following algorithm was used to weight the bitexts. Algorithm 2 WeightingCorpora 1: Determine word to word alignment with GIZA++ on concatenated bitext. 2: while Not converged do 3: Run Condor initialized with LM weights.</context>
</contexts>
<marker>Berghen, Bersini, 2005</marker>
<rawString>Frank Vanden Berghen and Hugues Bersini. 2005. CONDOR, a new parallel, constrained extension of Powell’s UOBYQA algorithm: Experimental results and comparison with the DFO algorithm. Journal of Computational and Applied Mathematics, 181:157–175, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Boxing Chen</author>
<author>Min Zhang</author>
<author>Aiti Aw</author>
<author>Haizhou Li</author>
</authors>
<title>Exploiting n-best hypotheses for SMT self- enhancement.</title>
<date>2008</date>
<booktitle>In Association for Computational Linguistics,</booktitle>
<pages>157--160</pages>
<contexts>
<context position="6297" citStr="Chen et al., 2008" startWordPosition="1010" endWordPosition="1013">rand et al., 2005). (Snover et al., 2008) used cross-lingual information retrieval to find texts in the target language that are related to the domain of the source texts. A self-enhancing approach was applied by (Ueffing, 2006) to filter the translations of the test set with the help of a confidence score and to use reliable alignments to train an additional phrase table. This additional table was used with the existing generic phrase table. (Ueffing, 2007) further refined this approach by using transductive semi-supervised methods for effective use of monolingual data from the source text. (Chen et al., 2008) performed domain adaptation simultaneously for the translation, language and reordering model by learning posterior knowledge from N-best hypothesis. A related approach was investigated in (Schwenk, 2008) and (Schwenk and Senellart, 2009) in which lightly supervised training was used. An SMT system was used to translate large collections of monolingual texts, which were then filtered and added to the training data. (Matsoukas et al., 2009) propose to weight each sentence in the training bitext by optimizing a discriminative function on a given tuning set. Sentence level features were extracte</context>
</contexts>
<marker>Chen, Zhang, Aw, Li, 2008</marker>
<rawString>Boxing Chen, Min Zhang, Aiti Aw, and Haizhou Li. 2008. Exploiting n-best hypotheses for SMT self- enhancement. In Association for Computational Linguistics, pages 157–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorge Civera</author>
<author>Alfons Juan</author>
</authors>
<title>Domain adaptation in statistical machine translation with mixture modelling.</title>
<date>2007</date>
<booktitle>In Second Workshop on SMT,</booktitle>
<pages>177--180</pages>
<contexts>
<context position="4711" citStr="Civera and Juan, 2007" startWordPosition="758" endWordPosition="761"> organized as follows. The next section describes related work on weighting the corpora and model adaptation. Section 3 describes the architecture allowing to resample and to weight the bitexts. Experimental results are presented in section 4 and the paper concludes with a discussion. 2 Related Work Adaptation of SMT systems is a topic of increasing interest since few years. In previous work, adaptation is done by using mixture models, by exploiting comparable corpora and by selfenhancement of translation models. Mixture models were used to optimize the coefficients to the adaptation domain. (Civera and Juan, 2007) proposed a model that can be used to generate topic-dependent alignments by extension of the HMM alignment model and derivation of Viterbi alignments. (Zhao et al., 2004) constructed specific language models by using machine translation output as queries to extract similar sentences from large monolingual corpora. (Foster and Kuhn, 2007) applied a mixture model approach to adapt the system to a new domain by using weights that depend on text distances to mixture components. The training corpus was divided into different components, a model was trained on each part and then weighted appropriat</context>
</contexts>
<marker>Civera, Juan, 2007</marker>
<rawString>Jorge Civera and Alfons Juan. 2007. Domain adaptation in statistical machine translation with mixture modelling. In Second Workshop on SMT, pages 177–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Foster</author>
<author>Roland Kuhn</author>
</authors>
<title>Mixture-model adaptation for SMT.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>128--135</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5051" citStr="Foster and Kuhn, 2007" startWordPosition="812" endWordPosition="815"> increasing interest since few years. In previous work, adaptation is done by using mixture models, by exploiting comparable corpora and by selfenhancement of translation models. Mixture models were used to optimize the coefficients to the adaptation domain. (Civera and Juan, 2007) proposed a model that can be used to generate topic-dependent alignments by extension of the HMM alignment model and derivation of Viterbi alignments. (Zhao et al., 2004) constructed specific language models by using machine translation output as queries to extract similar sentences from large monolingual corpora. (Foster and Kuhn, 2007) applied a mixture model approach to adapt the system to a new domain by using weights that depend on text distances to mixture components. The training corpus was divided into different components, a model was trained on each part and then weighted appropriately for the given context. (Koehn and Schroeder, 2007) used two language models and two translation models: one in-domain and other out-of-domain to adapt the system. Two decoding paths were used to translate the text. Comparable corpora are exploited to find additional parallel texts. Information retrieval techniques are used to identify</context>
</contexts>
<marker>Foster, Kuhn, 2007</marker>
<rawString>George Foster and Roland Kuhn. 2007. Mixture-model adaptation for SMT. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 128–135. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Almut Silja Hildebrand</author>
<author>Matthias Eck</author>
<author>Stephan Vogel</author>
<author>Alex Waibel</author>
</authors>
<title>Adaptation of the translation model for statistical machine translation based on information retrieval.</title>
<date>2005</date>
<booktitle>In EAMT,</booktitle>
<pages>133--142</pages>
<contexts>
<context position="5697" citStr="Hildebrand et al., 2005" startWordPosition="914" endWordPosition="917">el approach to adapt the system to a new domain by using weights that depend on text distances to mixture components. The training corpus was divided into different components, a model was trained on each part and then weighted appropriately for the given context. (Koehn and Schroeder, 2007) used two language models and two translation models: one in-domain and other out-of-domain to adapt the system. Two decoding paths were used to translate the text. Comparable corpora are exploited to find additional parallel texts. Information retrieval techniques are used to identify candidate sentences (Hildebrand et al., 2005). (Snover et al., 2008) used cross-lingual information retrieval to find texts in the target language that are related to the domain of the source texts. A self-enhancing approach was applied by (Ueffing, 2006) to filter the translations of the test set with the help of a confidence score and to use reliable alignments to train an additional phrase table. This additional table was used with the existing generic phrase table. (Ueffing, 2007) further refined this approach by using transductive semi-supervised methods for effective use of monolingual data from the source text. (Chen et al., 2008)</context>
</contexts>
<marker>Hildebrand, Eck, Vogel, Waibel, 2005</marker>
<rawString>Almut Silja Hildebrand, Matthias Eck, Stephan Vogel, and Alex Waibel. 2005. Adaptation of the translation model for statistical machine translation based on information retrieval. In EAMT, pages 133–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation. In Association for Computational Linguistics, demonstration session.,</title>
<date>2007</date>
<pages>224--227</pages>
<marker>Koehn, 2007</marker>
<rawString>Philipp Koehn and et al. 2007. Moses: Open source toolkit for statistical machine translation. In Association for Computational Linguistics, demonstration session., pages 224–227.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Josh Schroeder</author>
</authors>
<title>Experiments in domain adaptation for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>224--227</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5365" citStr="Koehn and Schroeder, 2007" startWordPosition="864" endWordPosition="867">e used to generate topic-dependent alignments by extension of the HMM alignment model and derivation of Viterbi alignments. (Zhao et al., 2004) constructed specific language models by using machine translation output as queries to extract similar sentences from large monolingual corpora. (Foster and Kuhn, 2007) applied a mixture model approach to adapt the system to a new domain by using weights that depend on text distances to mixture components. The training corpus was divided into different components, a model was trained on each part and then weighted appropriately for the given context. (Koehn and Schroeder, 2007) used two language models and two translation models: one in-domain and other out-of-domain to adapt the system. Two decoding paths were used to translate the text. Comparable corpora are exploited to find additional parallel texts. Information retrieval techniques are used to identify candidate sentences (Hildebrand et al., 2005). (Snover et al., 2008) used cross-lingual information retrieval to find texts in the target language that are related to the domain of the source texts. A self-enhancing approach was applied by (Ueffing, 2006) to filter the translations of the test set with the help </context>
</contexts>
<marker>Koehn, Schroeder, 2007</marker>
<rawString>Philipp Koehn and Josh Schroeder. 2007. Experiments in domain adaptation for statistical machine translation. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 224–227. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spyros Matsoukas</author>
<author>Antti-Veikko I Rosti</author>
<author>Bing Zhang</author>
</authors>
<title>Discriminative corpus weight estimation for machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>708--717</pages>
<contexts>
<context position="6741" citStr="Matsoukas et al., 2009" startWordPosition="1079" endWordPosition="1082"> table. (Ueffing, 2007) further refined this approach by using transductive semi-supervised methods for effective use of monolingual data from the source text. (Chen et al., 2008) performed domain adaptation simultaneously for the translation, language and reordering model by learning posterior knowledge from N-best hypothesis. A related approach was investigated in (Schwenk, 2008) and (Schwenk and Senellart, 2009) in which lightly supervised training was used. An SMT system was used to translate large collections of monolingual texts, which were then filtered and added to the training data. (Matsoukas et al., 2009) propose to weight each sentence in the training bitext by optimizing a discriminative function on a given tuning set. Sentence level features were extracted to estimate the weights that are relevant to the given task. Then certain parts of the training bitexts were downweighted to optimize an objective function on the development data. This can lead to parameter over-fitting if the function that maps sentence features to weights is complex. The technique proposed in this paper is somehow related to the above approach of weighting the texts. Our method does not require an explicit specificatio</context>
</contexts>
<marker>Matsoukas, Rosti, Zhang, 2009</marker>
<rawString>Spyros Matsoukas, Antti-Veikko I. Rosti, and Bing Zhang. 2009. Discriminative corpus weight estimation for machine translation. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 708–717.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J D Powell</author>
</authors>
<title>A direct search optimization method that models the objective and constraint functions by linar interpolation.</title>
<date>1994</date>
<booktitle>In In Advances in Optimization and Numerical Analysis, Proceedings of the sixth Workshop on Optimization and Numerical Analysis,</booktitle>
<volume>275</volume>
<pages>51--67</pages>
<publisher>Kluwer Academic Publishers.</publisher>
<location>Oaxaca, Mexico,</location>
<contexts>
<context position="12987" citStr="Powell, 1994" startWordPosition="2127" endWordPosition="2128">ed a technique similar to the algorithm used to minimize the perplexity of an interpolated target LM. Alternatively, it is also possible to construct a interpolated language model on the source side of bitexts. This approach was implemented and these coefficients were used as the weights for each bitext. One can certainly ask the question whether the perplexity is a good criterion for weighting bitexts. Therefore, we worked on direct optimization of these coefficients by CONDOR (Berghen and Bersini, 2005). This freely available tool is a numerical optimizer based on Powell’s UOBYQA algorithm (Powell, 1994). The aim of CONDOR is to minimize a objective function using the least number of function evaluations. Formally, it is used to find x* E Rn with given constraints which satisfies F(x*) = min F(x) (2) x where n is the dimension of search space and x* is the optimum of x. The following algorithm was used to weight the bitexts. Algorithm 2 WeightingCorpora 1: Determine word to word alignment with GIZA++ on concatenated bitext. 2: while Not converged do 3: Run Condor initialized with LM weights. 4: Create new alignment file by resampling according to weights given by Condor. 5: Use the alignment </context>
</contexts>
<marker>Powell, 1994</marker>
<rawString>M.J.D. Powell. 1994. A direct search optimization method that models the objective and constraint functions by linar interpolation. In In Advances in Optimization and Numerical Analysis, Proceedings of the sixth Workshop on Optimization and Numerical Analysis, Oaxaca, Mexico, volume 275, pages 51–67. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Holger Schwenk</author>
<author>Jean Senellart</author>
</authors>
<title>Translation model adaptation for an Arabic/French news translation system by lightlysupervised training.</title>
<date>2009</date>
<booktitle>In MT Summit.</booktitle>
<contexts>
<context position="6536" citStr="Schwenk and Senellart, 2009" startWordPosition="1044" endWordPosition="1047">to filter the translations of the test set with the help of a confidence score and to use reliable alignments to train an additional phrase table. This additional table was used with the existing generic phrase table. (Ueffing, 2007) further refined this approach by using transductive semi-supervised methods for effective use of monolingual data from the source text. (Chen et al., 2008) performed domain adaptation simultaneously for the translation, language and reordering model by learning posterior knowledge from N-best hypothesis. A related approach was investigated in (Schwenk, 2008) and (Schwenk and Senellart, 2009) in which lightly supervised training was used. An SMT system was used to translate large collections of monolingual texts, which were then filtered and added to the training data. (Matsoukas et al., 2009) propose to weight each sentence in the training bitext by optimizing a discriminative function on a given tuning set. Sentence level features were extracted to estimate the weights that are relevant to the given task. Then certain parts of the training bitexts were downweighted to optimize an objective function on the development data. This can lead to parameter over-fitting if the function </context>
</contexts>
<marker>Schwenk, Senellart, 2009</marker>
<rawString>Holger Schwenk and Jean Senellart. 2009. Translation model adaptation for an Arabic/French news translation system by lightlysupervised training. In MT Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Holger Schwenk</author>
</authors>
<title>Investigations on largescale lightly-supervised training for statistical machine translation.</title>
<date>2008</date>
<booktitle>In IWSLT,</booktitle>
<pages>182--189</pages>
<contexts>
<context position="6502" citStr="Schwenk, 2008" startWordPosition="1041" endWordPosition="1042"> by (Ueffing, 2006) to filter the translations of the test set with the help of a confidence score and to use reliable alignments to train an additional phrase table. This additional table was used with the existing generic phrase table. (Ueffing, 2007) further refined this approach by using transductive semi-supervised methods for effective use of monolingual data from the source text. (Chen et al., 2008) performed domain adaptation simultaneously for the translation, language and reordering model by learning posterior knowledge from N-best hypothesis. A related approach was investigated in (Schwenk, 2008) and (Schwenk and Senellart, 2009) in which lightly supervised training was used. An SMT system was used to translate large collections of monolingual texts, which were then filtered and added to the training data. (Matsoukas et al., 2009) propose to weight each sentence in the training bitext by optimizing a discriminative function on a given tuning set. Sentence level features were extracted to estimate the weights that are relevant to the given task. Then certain parts of the training bitexts were downweighted to optimize an objective function on the development data. This can lead to param</context>
</contexts>
<marker>Schwenk, 2008</marker>
<rawString>Holger Schwenk. 2008. Investigations on largescale lightly-supervised training for statistical machine translation. In IWSLT, pages 182–189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
</authors>
<title>Language and translation model adaptation using comparalble corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>857--866</pages>
<contexts>
<context position="5720" citStr="Snover et al., 2008" startWordPosition="918" endWordPosition="921">stem to a new domain by using weights that depend on text distances to mixture components. The training corpus was divided into different components, a model was trained on each part and then weighted appropriately for the given context. (Koehn and Schroeder, 2007) used two language models and two translation models: one in-domain and other out-of-domain to adapt the system. Two decoding paths were used to translate the text. Comparable corpora are exploited to find additional parallel texts. Information retrieval techniques are used to identify candidate sentences (Hildebrand et al., 2005). (Snover et al., 2008) used cross-lingual information retrieval to find texts in the target language that are related to the domain of the source texts. A self-enhancing approach was applied by (Ueffing, 2006) to filter the translations of the test set with the help of a confidence score and to use reliable alignments to train an additional phrase table. This additional table was used with the existing generic phrase table. (Ueffing, 2007) further refined this approach by using transductive semi-supervised methods for effective use of monolingual data from the source text. (Chen et al., 2008) performed domain adapt</context>
</contexts>
<marker>Snover, Dorr, Schwartz, 2008</marker>
<rawString>Matthew Snover, Bonnie Dorr, and Richard Schwartz. 2008. Language and translation model adaptation using comparalble corpora. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 857–866.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Ueffing</author>
</authors>
<title>Using monolingual sourcce language data to improve MT performance.</title>
<date>2006</date>
<booktitle>In IWSLT,</booktitle>
<pages>174--181</pages>
<contexts>
<context position="5907" citStr="Ueffing, 2006" startWordPosition="949" endWordPosition="950">eighted appropriately for the given context. (Koehn and Schroeder, 2007) used two language models and two translation models: one in-domain and other out-of-domain to adapt the system. Two decoding paths were used to translate the text. Comparable corpora are exploited to find additional parallel texts. Information retrieval techniques are used to identify candidate sentences (Hildebrand et al., 2005). (Snover et al., 2008) used cross-lingual information retrieval to find texts in the target language that are related to the domain of the source texts. A self-enhancing approach was applied by (Ueffing, 2006) to filter the translations of the test set with the help of a confidence score and to use reliable alignments to train an additional phrase table. This additional table was used with the existing generic phrase table. (Ueffing, 2007) further refined this approach by using transductive semi-supervised methods for effective use of monolingual data from the source text. (Chen et al., 2008) performed domain adaptation simultaneously for the translation, language and reordering model by learning posterior knowledge from N-best hypothesis. A related approach was investigated in (Schwenk, 2008) and </context>
</contexts>
<marker>Ueffing, 2006</marker>
<rawString>Nicola Ueffing. 2006. Using monolingual sourcce language data to improve MT performance. In IWSLT, pages 174–181.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Ueffing</author>
</authors>
<title>Transductive learning for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Association for Computational Linguistics,</booktitle>
<pages>25--32</pages>
<contexts>
<context position="6141" citStr="Ueffing, 2007" startWordPosition="988" endWordPosition="989">t. Comparable corpora are exploited to find additional parallel texts. Information retrieval techniques are used to identify candidate sentences (Hildebrand et al., 2005). (Snover et al., 2008) used cross-lingual information retrieval to find texts in the target language that are related to the domain of the source texts. A self-enhancing approach was applied by (Ueffing, 2006) to filter the translations of the test set with the help of a confidence score and to use reliable alignments to train an additional phrase table. This additional table was used with the existing generic phrase table. (Ueffing, 2007) further refined this approach by using transductive semi-supervised methods for effective use of monolingual data from the source text. (Chen et al., 2008) performed domain adaptation simultaneously for the translation, language and reordering model by learning posterior knowledge from N-best hypothesis. A related approach was investigated in (Schwenk, 2008) and (Schwenk and Senellart, 2009) in which lightly supervised training was used. An SMT system was used to translate large collections of monolingual texts, which were then filtered and added to the training data. (Matsoukas et al., 2009)</context>
</contexts>
<marker>Ueffing, 2007</marker>
<rawString>Nicola Ueffing. 2007. Transductive learning for statistical machine translation. In Association for Computational Linguistics, pages 25–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chong Ho Yu</author>
</authors>
<title>Resampling methods: Concepts, applications, and justification.</title>
<date>2003</date>
<booktitle>In Practical Assessment Research and Evaluation.</booktitle>
<contexts>
<context position="9780" citStr="Yu, 2003" startWordPosition="1585" endWordPosition="1586"> work, we propose a different procedure that makes no assumptions on how the phrases are extracted and probabilities are calculated. The idea is to resample alignments from the alignment file corresponding to the individual bitexts according to their weighting coefficients. By these means, we create a new, potentially larger alignment file, which then in turn will be used by the standard phrase extraction procedure. 3.1 Resampling the alignments In statistics, resampling is based upon repeated sampling within the same sample until a sample is obtained which better represents a given data set (Yu, 2003). Resampling is used for validating models on given data set by using random subsets. It overcomes the limitations to make assumptions about the distribution of the data. Usually resampling is done several times to better estimate and select the samples which better represents the target data set. The more often we resample, the closer we get to the true probability distribution. In our case we performed resampling with replacement according to the following algorithm: Algorithm 1 Resampling 1: for i = 0 to required size do 2: Select any alignment randomly 3: Al,,,,, +— normalized alignment sc</context>
</contexts>
<marker>Yu, 2003</marker>
<rawString>Chong Ho Yu. 2003. Resampling methods: Concepts, applications, and justification. In Practical Assessment Research and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Zhao</author>
<author>Matthias Ech</author>
<author>Stephen Vogal</author>
</authors>
<title>Language model adaptation for statistical machine translation with structured query models.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th international conference on Computational Linguistics. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="4882" citStr="Zhao et al., 2004" startWordPosition="786" endWordPosition="789">weight the bitexts. Experimental results are presented in section 4 and the paper concludes with a discussion. 2 Related Work Adaptation of SMT systems is a topic of increasing interest since few years. In previous work, adaptation is done by using mixture models, by exploiting comparable corpora and by selfenhancement of translation models. Mixture models were used to optimize the coefficients to the adaptation domain. (Civera and Juan, 2007) proposed a model that can be used to generate topic-dependent alignments by extension of the HMM alignment model and derivation of Viterbi alignments. (Zhao et al., 2004) constructed specific language models by using machine translation output as queries to extract similar sentences from large monolingual corpora. (Foster and Kuhn, 2007) applied a mixture model approach to adapt the system to a new domain by using weights that depend on text distances to mixture components. The training corpus was divided into different components, a model was trained on each part and then weighted appropriately for the given context. (Koehn and Schroeder, 2007) used two language models and two translation models: one in-domain and other out-of-domain to adapt the system. Two </context>
</contexts>
<marker>Zhao, Ech, Vogal, 2004</marker>
<rawString>Bing Zhao, Matthias Ech, and Stephen Vogal. 2004. Language model adaptation for statistical machine translation with structured query models. In Proceedings of the 20th international conference on Computational Linguistics. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>