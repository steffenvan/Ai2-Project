<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.999739">
Unsupervised Dependency Parsing with Transferring
Distribution via Parallel Guidance and Entropy Regularization
</title>
<author confidence="0.997546">
Xuezhe Ma
</author>
<affiliation confidence="0.99837">
Department of Linguistics
University of Washington
</affiliation>
<address confidence="0.621097">
Seattle, WA 98195, USA
</address>
<email confidence="0.998864">
xzma@uw.edu
</email>
<sectionHeader confidence="0.993895" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999915136363637">
We present a novel approach for induc-
ing unsupervised dependency parsers for
languages that have no labeled training
data, but have translated text in a resource-
rich language. We train probabilistic pars-
ing models for resource-poor languages by
transferring cross-lingual knowledge from
resource-rich language with entropy reg-
ularization. Our method can be used as
a purely monolingual dependency parser,
requiring no human translations for the
test data, thus making it applicable to a
wide range of resource-poor languages.
We perform experiments on three Data
sets — Version 1.0 and version 2.0 of
Google Universal Dependency Treebanks
and Treebanks from CoNLL shared-tasks,
across ten languages. We obtain state-
of-the art performance of all the three
data sets when compared with previously
studied unsupervised and projected pars-
ing systems.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997611133333333">
In recent years, dependency parsing has gained
universal interest due to its usefulness in a wide
range of applications such as synonym gener-
ation (Shinyama et al., 2002), relation extrac-
tion (Nguyen et al., 2009) and machine trans-
lation (Katz-Brown et al., 2011; Xie et al.,
2011). Several supervised dependency parsing
algorithms (Nivre and Scholz, 2004; McDonald
et al., 2005a; McDonald et al., 2005b; McDon-
ald and Pereira, 2006; Carreras, 2007; Koo and
Collins, 2010; Ma and Zhao, 2012; Zhang et al.,
2013) have been proposed and achieved high pars-
ing accuracies on several treebanks, due in large
part to the availability of dependency treebanks in
a number of languages (McDonald et al., 2013).
</bodyText>
<author confidence="0.85029">
Fei Xia
</author>
<affiliation confidence="0.854147666666667">
Department of Linguistics
University of Washington
Seattle, WA 98195, USA
</affiliation>
<email confidence="0.979146">
fxia@uw.edu
</email>
<bodyText confidence="0.999943972972973">
However, the manually annotated treebanks that
these parsers rely on are highly expensive to cre-
ate, in particular when we want to build treebanks
for resource-poor languages. This led to a vast
amount of research on unsupervised grammar in-
duction (Carroll and Charniak, 1992; Klein and
Manning, 2004; Smith and Eisner, 2005; Cohen
and Smith, 2009; Spitkovsky et al., 2010; Blun-
som and Cohn, 2010; Mareˇcek and Straka, 2013;
Spitkovsky et al., 2013), which appears to be a
natural solution to this problem, as unsupervised
methods require only unannotated text for training
parsers. Unfortunately, the unsupervised gram-
mar induction systems’ parsing accuracies often
significantly fall behind those of supervised sys-
tems (McDonald et al., 2011). Furthermore, from
a practical standpoint, it is rarely the case that we
are completely devoid of resources for most lan-
guages.
In this paper, we consider a practically moti-
vated scenario, in which we want to build statisti-
cal parsers for resource-poor target languages, us-
ing existing resources from a resource-rich source
language (like English).1 We assume that there are
absolutely no labeled training data for the target
language, but we have access to parallel data with
a resource-rich language and a sufficient amount
of labeled training data to build an accurate parser
for the resource-rich language. This scenario ap-
pears similar to the setting in bilingual text pars-
ing. However, most bilingual text parsing ap-
proaches require bilingual treebanks — treebanks
that have manually annotated tree structures on
both sides of source and target languages (Smith
and Smith, 2004; Burkett and Klein, 2008), or
have tree structures on the source side and trans-
lated sentences in the target languages (Huang et
</bodyText>
<footnote confidence="0.9630812">
1For the sake of simplicity, we refer to the resource-poor
language as the “target language”, and resource-rich language
as the “source language”. In addition, in this study we use En-
glish as the source resource-rich language, but our methodol-
ogy can be applied to any resource-rich languages.
</footnote>
<page confidence="0.868837">
1337
</page>
<note confidence="0.876872">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1337–1348,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.991970823529412">
al., 2009; Chen et al., 2010). Obviously, bilingual
treebanks are much more difficult to acquire than
the resources required in our scenario, since the la-
beled training data and the parallel text in our case
are completely separated. What is more impor-
tant is that most studies on bilingual text parsing
assumed that the parser is applied only on bilin-
gual text. But our goal is to develop a parser that
can be used in completely monolingual setting for
each target language of interest.
This scenario is applicable to a large set of lan-
guages and many research studies (Hwa et al.,
2005) have been made on it. Ganchev et al. (2009)
presented a parser projection approach via paral-
lel text using the posterior regularization frame-
work (Graca et al., 2007). McDonald et al. (2011)
proposed two parser transfer approaches between
two different languages — one is directly trans-
ferred parser from delexicalized parsers, and the
other parser is transferred using constraint driven
learning algorithm where constraints are drawn
from parallel corpora. In that work, they demon-
strate that even the directly transferred delexi-
calized parser produces significantly higher ac-
curacies than unsupervised parsers. Cohen et
al. (2011) proposed an approach for unsupervised
dependency parsing with non-parallel multilingual
guidance from one or more helper languages, in
which parallel data is not used.
In this work, we propose a learning frame-
work for transferring dependency grammars from
a resource-rich language to resource-poor lan-
guages via parallel text. We train probabilistic
parsing models for resource-poor languages by
maximizing a combination of likelihood on par-
allel data and confidence on unlabeled data. Our
work is based on the learning framework used in
Smith and Eisner (2007), which is originally de-
signed for parser bootstrapping. We extend this
learning framework so that it can be used to trans-
fer cross-lingual knowledge between different lan-
guages.
Throughout this paper, English is used as the
source language and we evaluate our approach on
ten target languages — Danish (da), Dutch (nl),
French (fr), German (de), Greek (el), Italian (it),
Korean (ko), Portuguese (pt), Spanish (es) and
Swedish (sv). Our approach achieves significant
improvement over previous state-of-the-art unsu-
pervised and projected parsing systems across all
the ten languages, and considerably bridges the
</bodyText>
<figure confidence="0.458706">
Root Economic news had little effect on financial markets
</figure>
<figureCaption confidence="0.998513">
Figure 1: An example dependency tree.
</figureCaption>
<bodyText confidence="0.997493">
gap to fully supervised dependency parsing per-
formance.
</bodyText>
<sectionHeader confidence="0.93058" genericHeader="method">
2 Our Approach
</sectionHeader>
<bodyText confidence="0.999799">
Dependency trees represent syntactic relationships
through labeled directed edges between heads and
their dependents. For example, Figure 1 shows a
dependency tree for the sentence, Economic news
had little effect on financial markets, with the sen-
tence’s root-symbol as its root. The focus of this
work is on building dependency parsers for target
languages, assuming that an accurate English de-
pendency parser and some parallel text between
the two languages are available. Central to our ap-
proach is a maximizing likelihood learning frame-
work, in which we use an English parser and par-
allel text to estimate the “transferring distribution”
of the target language parsing model (See Section
2.2 for more details). Another advantage of the
learning framework is that it combines both the
likelihood on parallel data and confidence on unla-
beled data, so that both parallel text and unlabeled
data can be utilized in our approach.
</bodyText>
<subsectionHeader confidence="0.960708">
2.1 Edge-Factored Parsing Model
</subsectionHeader>
<bodyText confidence="0.9999535">
In this paper, we will use the following notation:
x represents a generic input sentence, and y rep-
resents a generic dependency tree. T(x) is used
to denote the set of possible dependency trees
for sentence x. The probabilistic model for de-
pendency parsing defines a family of conditional
probability pλ(y|x) over all y given sentence x,
with a log-linear form:
</bodyText>
<equation confidence="0.986852">
~Xpλ(y|x) = Z1x) exp AjFj(y,x)} (1)
j
</equation>
<bodyText confidence="0.99988175">
where Fj are feature functions, A = (A1, A2, ...)
are parameters of the model, and Z(x) is a nor-
malization factor, which is commonly referred to
as the partition function:
</bodyText>
<equation confidence="0.9740378">
~Xexp AjFj (y, x) } (2)
j JJ
X
Z(x) =
y∈T(x)
</equation>
<page confidence="0.916758">
1338
</page>
<bodyText confidence="0.999381333333333">
A common strategy to make this parsing model ef-
ficiently computable is to factor dependency trees
into sets of edges:
</bodyText>
<equation confidence="0.81355">
Fj(y,x) = � fj(e,x). (3)
e∈y
</equation>
<bodyText confidence="0.9909904">
That is, dependency tree y is treated as a set
of edges e and each feature function Fj(y, x) is
equal to the sum of all the features fj(e, x).
We denote the weight function of each edge e as
follows:
</bodyText>
<equation confidence="0.564848">
w(e, x) = exp 5 λj fj (e, x)1 (4)
l j
</equation>
<bodyText confidence="0.9910855">
and the conditional probability pλ(y|x) has the
following form:
</bodyText>
<subsectionHeader confidence="0.996397">
2.2 Model Training
</subsectionHeader>
<bodyText confidence="0.994241666666667">
One of the most common model training meth-
ods for supervised dependency parser is Maxi-
mum conditional likelihood estimation. For a su-
pervised dependency parser with a set of train-
ing data {(xi, yi)}, the logarithm of the likelihood
(a.k.a. the log-likelihood) is given by:
</bodyText>
<equation confidence="0.9876665">
L(λ) = � log pλ(yi|xi) (6)
i
</equation>
<bodyText confidence="0.99625475">
Maximum likelihood training chooses parameters
such that the log-likelihood L(λ) is maximized.
However, in our scenario we have no labeled
training data for target languages but we have
some parallel and unlabeled data plus an En-
glish dependency parser. For the purpose of
transferring cross-lingual information from the
English parser via parallel text, we explore the
model training method proposed by Smith and
Eisner (2007), which presented a generalization of
K function (Abney, 2004), and related it to an-
other semi-supervised learning technique, entropy
regularization (Jiao et al., 2006; Mann and Mc-
Callum, 2007). The objective K function to be
minimized is actually the expected negative log-
likelihood:
</bodyText>
<equation confidence="0.992375">
K = − � E ˜p(yi|xi) log pλ(yi|xi)
i yi
�= D(˜pi||pλ,i) + H(˜pi) (7)
i
1
pλ(y|x) =
Z(x) rl w(e, x) (5)
e∈y
</equation>
<bodyText confidence="0.999949454545454">
where ˜pi(·) def= ˜p(·|xi) and pλ,i(·) def= pλ(·|xi).
˜p(y|x) is the “transferring distribution” that re-
flects our uncertainty about the true labels, and we
are trying to learn a parametric model pλ(y|x) by
minimizing the K function.
In our scenario, we have a set of aligned par-
allel data P = {xsi, xti, ai} where ai is the word
alignment for the pair of source-target sentences
(xsi, xti), and a set of unlabeled sentences of the
target language U = {xti}. We also have a trained
English parsing model pλE(y|x). Then the K in
equation (7) can be divided into two cases, accord-
ing to whether xi belongs to parallel data set P or
unlabeled data set U. For the unlabeled examples
{xi ∈ U}, some previous studies (e.g., (Abney,
2004)) simply use a uniform distribution over la-
bels (e.g., parses), to reflect that the label is un-
known. We follow the method in Smith and Eis-
ner (2007) and take the transferring distribution
˜pi to be the actual current belief pλ,i. The total
contribution of the unsupervised examples to K
then simplifies to KU = E H(pλ,i), which may
</bodyText>
<equation confidence="0.468573">
xi∈U
</equation>
<bodyText confidence="0.9995292">
be regarded as the entropy item used to constrain
the model’s uncertainty H to be low, as presented
in the work on entropy regularization (Jiao et al.,
2006; Mann and McCallum, 2007).
But how can we define the transferring distri-
bution for the parallel examples {xti ∈ P}? We
define the transferring distribution by defining the
transferring weight utilizing the English parsing
model pλE(y|x) via parallel data with word align-
ments:
</bodyText>
<equation confidence="0.958011">
�
˜w(et, xt i),
i) =
wE(es,xs
if et align
−→ es
wE(etdelex,xsi), otherwise
</equation>
<bodyText confidence="0.975407857142857">
(8)
where wE(·, ·) is the weight function of the En-
glish parsing model pλE(y|x), and etdelex is the
delexicalized form2 of the edge et. From the
definition of the transferring weight, we can see
that, if an edge et of the target language sentence
xti is aligned to an edge es of the English sen-
tence xsi, we transfer the weight of edge et to
the corresponding weight of edge es in the En-
glish parsing model pλE(y|x). If the edge et
is not aligned to any edges of the English sen-
tence xsi, we reduce the edge et to the delexical-
ized form and calculate the transferring weight in
the English parsing model. There are two advan-
</bodyText>
<footnote confidence="0.953681">
2The delexicalized form of an edge is an edge for which
only delexicalized features are considered.
</footnote>
<page confidence="0.994776">
1339
</page>
<bodyText confidence="0.999919375">
tages for this definition of the transferring weight.
First, by transferring the weight function to the
corresponding weight in the well-developed En-
glish parsing model, we can project syntactic in-
formation across language boundaries. Second,
McDonald et al. (2011) demonstrates that parsers
with only delexicalized features produce consid-
erably high parsing performance. By reducing
unaligned edges to their delexicalized forms, we
can still use those delexicalized features, such as
part-of-speech tags, for those unaligned edges, and
can address problem that automatically generated
word alignments include errors.
From the definition of transferring weight in
equation (8), the transferring distribution can be
defined in the following way:
</bodyText>
<equation confidence="0.9997">
p(y |x) = ˜ 1 ri w˜ (e, x) (9)
Z(x) eEy
</equation>
<bodyText confidence="0.691502">
where
</bodyText>
<equation confidence="0.992426">
X˜Z(x) = ri ˜w(e, x) (10)
y eEy
</equation>
<bodyText confidence="0.999982833333333">
Due to the normalizing factor ˜Z(x), the transfer-
ring distribution is a valid one.
We introduce a multiplier γ as a trade-off be-
tween the two contributions (parallel and unsuper-
vised) of the objective function K, and the final
objective function K′ has the following form:
</bodyText>
<equation confidence="0.9981595">
K′ = − X X ˜p(yi|xi) log pλ(yi|xi)
xiEP yi
X
+ γ
xiEU
= KP + γKU (11)
</equation>
<bodyText confidence="0.983506428571429">
KP and KU are the contributions of the parallel
and unsupervised data, respectively. One may re-
gard γ as a Lagrange multiplier that is used to
constrain the parser’s uncertainty H to be low, as
presented in several studies on entropy regulariza-
tion (Brand, 1998; Grandvalet and Bengio, 2004;
Jiao et al., 2006).
</bodyText>
<subsectionHeader confidence="0.9621165">
2.3 Algorithms and Complexity for Model
Training
</subsectionHeader>
<bodyText confidence="0.9998489">
To train our parsing model, we need to find out the
parameters λ that minimize the objective function
K′ in equation (11). This optimization problem
is typically solved using quasi-Newton numeri-
cal methods such as L-BFGS (Nash and Nocedal,
1991), which requires efficient calculation of the
objective function and the gradient of the objec-
tive function.
The first item (KP) of the K′ function in equa-
tion (11) can be rewritten in the following form:
</bodyText>
<equation confidence="0.998212333333333">
XKP = − [X ˜p(yi|xi) X log w(e, xi)
xiEP yi eEyi
− log Z(xi)] (12)
</equation>
<bodyText confidence="0.9986615">
and according to equation (1) and (3) the gradient
of KP can be written as:
</bodyText>
<equation confidence="0.997953166666667">
∂˜p(yi|xi) log pλ(yi|xi)
∂λj
X �X X
= ˜p(yi|xi) fj(e,xi)
xiEP yi eEyi
�fj(e, xi) (13)
</equation>
<bodyText confidence="0.999989944444444">
According to equation (9), ˜p(y|x) can also be
factored into the multiplication of the weight of
each edge, so both KP and its gradient can be
calculated by running the O(n3) inside-outside al-
gorithm (Baker, 1979; Paskin, 2001) for projec-
tive parsing. For non-projective parsing, the anal-
ogy to the inside algorithm is the O(n3) matrix-
tree algorithm based on Kirchhoff’s Matrix-Tree
Theorem, which is dominated asymptotically by a
matrix determinant (Koo et al., 2007; Smith and
Smith, 2007). The gradient of a determinant may
be computed by matrix inversion, so evaluating the
gradient again has the same O(n3) complexity as
evaluating the function.
The second item (KU) of the K′ function in
equation (11) is the Shannon entropy of the pos-
terior distribution over parsing trees, and can be
written into the following form:
</bodyText>
<equation confidence="0.998546666666667">
XKU = − [X pλ(yi|xi) X log w(e, xi)
xiEU yi eEyi
− log Z(xi)] (14)
</equation>
<bodyText confidence="0.949559">
and the gradient of KU is in the following:
</bodyText>
<equation confidence="0.995606789473684">
∂KU X= ∂pλ(yi|xi) log pλ(yi|xi)
xiEU ∂λj
∂λj
X= − pλ(yi|xi) log pλ(yi|xi)Fj(yi, xi)
yi
(X )
+ pλ(yi|xi)log pλ(yi|xi)
yi
(X )
· pλ(yi|xi)Fj(yi,xi)
(15)
yi
H(pλ,i)
X=
xiEP
∂KP
∂λj
X− pλ(yi|xi) X
yi eEyi
</equation>
<page confidence="0.95136">
1340
</page>
<table confidence="0.9992426875">
#sents/#tokens test
training dev
Version 1.0
de 2,200/30,460 800/12,215 1,000/16,339
es 3,345/94,232 370/10,191 300/8,295
fr 3,312/74,979 366/8,071 300/6,950
ko 5,308/62,378 588/6,545 298/2,917
sv 4,447/66,631 493/9,312 1,219/20,376
Version 2.0
de 14,118/26,4906 800/12,215 1,000/16,339
es 14,138/37,5180 1,569/40,950 300/8,295
fr 14,511/35,1233 1,611/38,328 300/6,950
it 6,389/14,9145 400/9,541 400/9,187
ko 5437/60,621 603/6,438 299/2,631
pt 9,600/23,9012 1,200/29,873 1,198/29,438
sv 4,447/66,631 493/9,312 1,219/20,376
</table>
<tableCaption confidence="0.9412645">
Table 1: Data statistics of two versions of Google
Universal Treebanks for the target languages.
</tableCaption>
<bodyText confidence="0.99971">
Similar with the calculation of KP, KU can also
be computed by running the inside-outside algo-
rithm (Baker, 1979; Paskin, 2001) for projective
parsing. For the gradient of KU, both the two
multipliers of the second item in equation (15) can
be computed using the same inside-outside algo-
rithm. For the first item in equation (15), an O(n3)
dynamic programming algorithm that is closely
related to the forward-backward algorithm (Mann
and McCallum, 2007) for the entropy regularized
CRF (Jiao et al., 2006) can be used for projective
parsing. For non-projective parsing, however, the
runtime rises to O(n4). In this paper, we focus on
projective parsing.
</bodyText>
<subsectionHeader confidence="0.996446">
2.4 Summary of Our Approach
</subsectionHeader>
<bodyText confidence="0.998713333333333">
To summarize the description in the previous sec-
tions, our approach is performed in the following
steps:
</bodyText>
<listItem confidence="0.992933727272727">
1. Train an English parsing model pλE(y|x),
which is used to estimate the transferring dis-
tribution ˜p(y|x).
2. Prepare parallel text by running word align-
ment method to obtain word alignments,3 and
prepare the unlabeled data.
3. Train a parsing model for the target lan-
guage by minimizing the objective K′ func-
tion which is the combination of expected
negative log-likelihood on parallel and unla-
beled data.
</listItem>
<footnote confidence="0.8979405">
3The word alignment methods do not require additional
resources besides parallel text.
</footnote>
<table confidence="0.999850833333333">
# sents
500 1000 2000 5000 10000 20000
da 12,568 25,225 49,889 126,623 254,565 509,480
de 13,548 26,663 53,170 133,596 265,589 527,407
el 14,198 28,302 56,744 143,753 286,126 572,777
es 15,147 29,214 57,526 144,621 290,517 579,164
fr 15,046 29,982 60,569 153,874 306,332 609,541
it 15,151 29,786 57,696 145,717 288,337 573,557
ko 3,814 7,679 15,337 38,535 77,388 155,051
nl 13,234 26,777 54,570 137,277 274,692 551,463
pt 14,346 28,109 55,998 143,221 285,590 571,109
sv 12,242 24,897 50,047 123,069 246,619 490,086
</table>
<tableCaption confidence="0.879845">
Table 2: The number of tokens in parallel data
used in our experiments. For all these corpora, the
other language is English.
</tableCaption>
<sectionHeader confidence="0.958855" genericHeader="method">
3 Data and Tools
</sectionHeader>
<bodyText confidence="0.9971895">
In this section, we illustrate the data sets used in
our experiments and the tools for data preparation.
</bodyText>
<subsectionHeader confidence="0.999408">
3.1 Choosing Target Languages
</subsectionHeader>
<bodyText confidence="0.999753064516129">
Our experiments rely on two kinds of data sets:
(i) Monolingual Treebanks with consistent anno-
tation schema — English treebank is used to train
the English parsing model, and the Treebanks for
target languages are used to evaluate the parsing
performance of our approach. (ii) Large amounts
of parallel text with English on one side. We se-
lect target languages based on the availability of
these resources. The monolingual treebanks in our
experiments are from the Google Universal De-
pendency Treebanks (McDonald et al., 2013), for
the reason that the treebanks of different languages
in Google Universal Dependency Treebanks have
consistent syntactic representations.
The parallel data come from the Europarl cor-
pus version 7 (Koehn, 2005) and Kaist Corpus4.
Taking the intersection of languages in the two
kinds of resources yields the following seven lan-
guages: French, German, Italian, Korean, Por-
tuguese, Spanish and Swedish.
The treebanks from CoNLL shared-tasks on
dependency parsing (Buchholz and Marsi, 2006;
Nivre et al., 2007) appear to be another reasonable
choice. However, previous studies (McDonald et
al., 2011; McDonald et al., 2013) have demon-
strated that a homogeneous representation is criti-
cal for multilingual language technologies that re-
quire consistent cross-lingual analysis for down-
stream components, and the heterogenous repre-
sentations used in CoNLL shared-tasks treebanks
weaken any conclusion that can be drawn.
</bodyText>
<footnote confidence="0.9934805">
4http://semanticweb.kaist.ac.kr/home/
index.php/Corpus10
</footnote>
<page confidence="0.813883">
1341
</page>
<table confidence="0.999653">
DTP DTP† PTP† -U +U OR
de 58.50 58.46 69.21 73.72 74.01 78.64
es 68.07 68.72 72.57 75.32 75.60 82.56
fr 70.14 71.13 74.60 76.65 76.93 83.69
ko 42.37 43.57 53.72 59.72 59.94 89.85
sv 70.56 70.59 75.87 78.91 79.27 85.59
Ave 61.93 62.49 69.19 72.86 73.15 84.67
</table>
<tableCaption confidence="0.961318">
Table 3: UAS for two versions of our approach, to-
</tableCaption>
<bodyText confidence="0.972744692307692">
gether with baseline and oracle systems on Google
Universal Treebanks version 1.0. “Ave” is the
macro-average across the five languages.
For comparison with previous studies, never-
theless, we also run experiments on CoNLL tree-
banks (see Section 4.4 for more details). We eval-
uate our approach on three target languages from
CoNLL shared task treebanks, which do not ap-
pear in Google Universal Treebanks. The three
languages are Danish, Dutch and Greek. So totally
we have ten target languages. The parallel data for
these three languages are also from the Europarl
corpus version 7.
</bodyText>
<subsectionHeader confidence="0.998975">
3.2 Word Alignments
</subsectionHeader>
<bodyText confidence="0.9999907">
In our approach, word alignments for the paral-
lel text are required. We perform word alignments
with the open source GIZA++ toolkit5. The paral-
lel corpus was preprocessed in standard ways, se-
lecting sentences with the length in the range from
3 to 100. Then we run GIZA++ with the default
setting to generate word alignments in both direc-
tions. We then make the intersection of the word
alignments of two directions to generate one-to-
one alignments.
</bodyText>
<subsectionHeader confidence="0.996276">
3.3 Part-of-Speech Tagging
</subsectionHeader>
<bodyText confidence="0.992690066666667">
Several features in our parsing model involve part-
of-speech (POS) tags of the input sentences. The
set of POS tags needs to be consistent across lan-
guages and treebanks. For this reason we use
the universal POS tag set of Petrov et al. (2011).
This set consists of the following 12 coarse-
grained tags: NOUN (nouns), VERB (verbs), ADJ
(adjectives), ADV (adverbs), PRON (pronouns),
DET (determiners), ADP (prepositions or postpo-
sitions), NUM (numerals), CONJ (conjunctions),
PRT (particles), PUNC (punctuation marks) and
X (a catch-all for other categories such as abbrevi-
ations or foreign words).
POS tags are not available for parallel data in
the Europarl and Kaist corpus, so we need to pro-
</bodyText>
<footnote confidence="0.962253">
5https://code.google.com/p/giza-pp/
</footnote>
<table confidence="0.999732666666667">
DTP† PTP† -U +U OR
de 58.56 69.77 73.92 74.30 81.65
es 68.72 73.22 75.21 75.53 83.92
fr 71.13 74.75 76.14 76.53 83.51
it 70.74 76.08 77.55 77.74 85.47
ko 38.55 43.34 59.71 59.89 90.42
pt 69.82 74.59 76.30 76.65 85.67
sv 70.59 75.87 78.91 79.27 85.59
Ave 64.02 69.66 73.96 74.27 85.18
</table>
<tableCaption confidence="0.936854">
Table 4: UAS for two versions of our approach, to-
</tableCaption>
<bodyText confidence="0.964479375">
gether with baseline and oracle systems on Google
Universal Treebanks version 2.0. “Ave” is the
macro-average across the seven languages.
vide the POS tags for these data. In our experi-
ments, we train a Stanford POS Tagger (Toutanova
et al., 2003) for each language. The labeled train-
ing data for each POS tagger are extracted from
the training portion of each Treebanks. The aver-
age tagging accuracy is around 95%.
Undoubtedly, we are primarily interested in ap-
plying our approach to build statistical parsers
for resource-poor target languages without any
knowledge. For the purpose of evaluation of our
approach and comparison with previous work, we
need to exploit the gold POS tags to train the POS
taggers. As part-of-speech tags are also a form
of syntactic analysis, this assumption weakens the
applicability of our approach. Fortunately, some
recently proposed POS taggers, such as the POS
tagger of Das and Petrov (2011), rely only on la-
beled training data for English and the same kind
of parallel text in our approach. In practice we can
use this kind of POS taggers to predict POS tags,
whose tagging accuracy is around 85%.
</bodyText>
<sectionHeader confidence="0.999644" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999882666666667">
In this section, we will describe the details of our
experiments and compare our results with previ-
ous methods.
</bodyText>
<subsectionHeader confidence="0.996064">
4.1 Data Sets
</subsectionHeader>
<bodyText confidence="0.999842428571429">
As presented in Section 3.1, we evaluate our pars-
ing approach on both version 1.0 and version
2.0 of Google Univereal Treebanks for seven lan-
guages6. We use the standard splits of the treebank
for each language as specified in the release of the
data7. Table 1 presents the statistics of the two ver-
sions of Google Universal Treebanks. We strip all
</bodyText>
<footnote confidence="0.968116">
6Japanese and Indonesia are excluded as no practicable
parallel data are available.
7https://code.google.com/p/uni-dep-tb/
</footnote>
<page confidence="0.980339">
1342
</page>
<table confidence="0.999096923076923">
Google Universal Treebanks V1.0
#sents de es fr ko sv
PTP† -U +U PTP† -U +U PTP† -U +U PTP† -U +U PTP† -U +U
500 63.23 70.79 70.93 70.09 72.32 72.64 72.24 74.64 74.90 47.71 56.87 57.22 71.70 75.88 76.13
1000 65.61 71.71 71.86 70.90 73.44 73.67 72.95 75.07 75.35 47.83 57.65 58.15 72.38 76.55 77.03
2000 66.52 72.33 72.48 72.01 73.57 73.81 73.69 75.88 76.22 48.37 58.19 58.44 73.65 77.86 78.12
5000 67.79 73.06 73.31 72.34 74.30 74.79 74.31 76.02 76.29 53.02 58.57 59.04 74.88 78.48 78.70
10000 68.44 73.59 73.92 72.48 74.86 75.26 74.43 76.14 76.34 53.61 59.17 59.55 75.34 78.78 79.08
20000 69.21 73.72 74.01 72.57 75.32 75.60 74.60 76.55 76.93 53.72 59.72 59.94 75.87 78.91 79.27
Google Universal Treebanks V2.0
de es fr ko it
#sents PTP† -U +U PTP† -U +U PTP† -U +U PTP† -U +U PTP† -U +U
500 60.10 71.07 71.39 69.52 72.97 73.28 71.10 74.57 74.70 40.09 56.60 57.10 72.80 75.67 75.94
1000 61.76 72.15 72.39 70.78 73.48 73.79 72.14 75.13 75.43 40.44 57.55 57.93 73.55 76.43 76.67
2000 65.35 72.73 73.04 71.75 74.10 74.35 73.21 75.78 76.06 40.87 58.11 58.43 74.44 76.99 77.39
5000 67.86 73.32 73.62 72.43 74.55 74.83 74.14 75.83 76.02 40.90 58.48 58.96 75.07 77.10 77.34
10000 68.70 73.71 74.02 72.85 74.80 74.95 74.53 75.97 76.17 41.29 59.13 59.44 75.65 77.50 77.71
20000 69.77 73.92 74.30 73.22 75.21 75.53 74.75 76.14 76.53 43.34 59.71 59.89 76.08 77.55 77.74
pt
# sents PTP† -U +U
500 71.34 74.41 74.68
1000 71.91 74.48 75.08
2000 72.93 75.10 75.32
5000 73.78 75.88 75.98
10000 74.40 75.99 76.15
20000 74.59 76.30 76.65
</table>
<tableCaption confidence="0.667959">
Table 5: Parsing results of our approach with different amount of parallel data on Google Universal
Treebanks version 1.0 and 2.0. We omit the results of Swedish for treebanks version 2.0 since the data
for Swedish from version 2.0 are exactly the same with those from version 1.0.
</tableCaption>
<bodyText confidence="0.999898230769231">
the dependency annotations off the training por-
tion of each treebank, and use that as the unla-
beled data for that target language. We train our
parsing model with different numbers of parallel
sentences to analyze the influence of the amount of
parallel data on the parsing performance of our ap-
proach. The parallel data sets contain 500, 1000,
2000, 5000, 10000 and 20000 parallel sentences,
respectively. We randomly extract parallel sen-
tences from each corpora, and smaller data sets are
subsets of larger ones. Table 2 shows the number
of tokens in the parallel data used in the experi-
ments.
</bodyText>
<subsectionHeader confidence="0.9819985">
4.2 System performance and comparison
on Google Universal Treebanks
</subsectionHeader>
<bodyText confidence="0.999300272727273">
For the comparison of parsing performance, we
run experiments on the following systems:
DTP: The direct transfer parser (DTP) proposed
by McDonald et al. (2011), who train a delex-
icalized parser on English labeled training
data with no lexical features, then apply this
parser to parse target languages directly. It
is based on the transition-based dependency
parsing paradigm (Nivre, 2008). We di-
rectly cite the results reported in McDon-
ald et al. (2013). In addition to their orig-
inal results, we also report results by re-
implementing the direct transfer parser based
on the first-order projective dependency pars-
ing model (McDonald et al., 2005a) (DTP†).
PTP The projected transfer parser (PTP) de-
scribed in McDonald et al. (2011). The
results of the projected transfer parser re-
implemented by us is marked as “PTP†”.
-U: Our approach training on only parallel data
without unlabeled data for the target lan-
guage. The parallel data set for each language
contains 20,000 sentences.
+U: Our approach training on both parallel and
unlabeled data. The parallel data sets are the
ones contains 20,000 sentences.
OR: the supervised first-order projective depen-
dency parsing model (McDonald et al.,
2005a), trained on the original treebanks with
maximum likelihood estimation (equation 6).
One may regard this system as an oracle of
transfer parsing.
Parsing accuracy is measured with unlabeled at-
tachment score (UAS): the percentage of words
with the correct head.
Table 3 and Table 4 shows the parsing results of
our approach, together with the results of the base-
line systems and the oracle, on version 1.0 and ver-
sion 2.0 of Google Universal Treebanks, respec-
tively. Our approaches significantly outperform all
the baseline systems across all the seven target lan-
guages. For the results on Google Universal Tree-
banks version 1.0, the improvement on average
over the projected transfer paper (PTP†) is 3.96%
</bodyText>
<page confidence="0.970444">
1343
</page>
<bodyText confidence="0.999887916666667">
and up to 6.22% for Korean and 4.80% for Ger-
man. For the other three languages, the improve-
ments are remarkable, too — 2.33% for French,
3.03% for Spanish and 3.40% for Swedish. By
adding entropy regularization from unlabeled data,
our full model achieves average improvement of
0.29% over the “-U” setting. Moreover, our ap-
proach considerably bridges the gap to fully super-
vised dependency parsers, whose average UAS is
84.67%. For the results on treebanks version 2.0,
we can get similar observation and draw the same
conclusion.
</bodyText>
<subsectionHeader confidence="0.998982">
4.3 Effect of the Amount of Parallel Text
</subsectionHeader>
<bodyText confidence="0.9999818">
Table 5 illustrates the UAS of our approach trained
on different amounts of parallel data, together
with the results of the projected transfer parser
re-implemented by us (PTP†). We run two ver-
sions of our approach for each of the parallel data
sets, one with unlabeled data (+U) and the other
without them (-U). From table 5 we can get three
observations. First, even the parsers trained with
only 500 parallel sentences achieve considerably
high parsing accuracies (average 70.10% for ver-
sion 1.0 and 71.59% for version 2.0). This demon-
strates that our approach does not rely on a large
amount of parallel data. Second, when gradually
increasing the amount of parallel data, the parsing
performance continues improving. Third, entropy
regularization with unlabeled data makes mod-
est improvement on parsing performance over the
parsers without unlabeled data. This proves the ef-
fectiveness of the entropy regularization from un-
labeled data.
</bodyText>
<subsectionHeader confidence="0.997568">
4.4 Experiments on CoNLL Treebanks
</subsectionHeader>
<bodyText confidence="0.9834364375">
To make a thorough empirical comparison with
previous studies, we also evaluate our system
without unlabeled data (-U) on treebanks from
CoNLL shared task on dependency parsing (Buch-
holz and Marsi, 2006; Nivre et al., 2007). To fa-
cilitate comparison, we use the same eight Indo-
European languages as target languages: Danish,
Dutch, German, Greek, Italian, Portuguese, Span-
ish and Swedish, and same experimental setup as
McDonald et al. (2011). We report both the results
of the direct transfer and projected transfer parsers
directly cited from McDonald et al. (2011) (DTP
and PTP) and re-implemented by us (DTP†and
PTP†).
Table 6 gives the results comparing the model
without unlabeled data (-U) presented in this work
</bodyText>
<table confidence="0.999663">
DMV DTP DTP† PTP PTP† -U OR
da 33.4 45.9 46.8 48.2 50.0 50.1 87.1
de 18.0 47.2 46.0 50.9 52.4 57.3 87.0
el 39.9 63.9 62.9 66.8 65.3 67.4 82.3
es 28.5 53.3 54.4 55.8 59.9 60.3 83.6
it 43.1 57.7 59.9 60.8 63.4 64.0 83.9
nl 38.5 60.8 60.7 67.8 66.5 68.2 78.2
pt 20.1 69.2 71.1 71.3 74.8 75.1 87.2
sv 44.0 58.3 60.3 61.3 62.8 66.7 88.0
Ave 33.2 57.0 57.8 60.4 61.9 63.6 84.7
</table>
<tableCaption confidence="0.978955">
Table 6: Parsing results on treebanks from CoNLL
</tableCaption>
<bodyText confidence="0.9729156875">
shared tasks for eight target languages. The results
of unsupervised DMV model are from Table 1 of
McDonald et al. (2011).
to those five baseline systems and the oracle (OR).
The results of unsupervised DMV model (Klein
and Manning, 2004) are from Table 1 of McDon-
ald et al. (2011). Our approach outperforms all
these baseline systems and achieves state-of-the-
art performance on all the eight languages.
In order to compare with more previous meth-
ods, we also report parsing performance on sen-
tences of length 10 or less after punctuation
has been removed. Table 7 shows the results
of our system and the results of baseline sys-
tems. “USR†” is the weakly supervised system of
Naseem et al. (2010). “PGI” is the phylogenetic
grammar induction model of Berg-Kirkpatrick and
Klein (2010). Both the results of the two systems
are cited from Table 4 of McDonald et al. (2011).
We also include the results of the unsupervised
dependency parsing model with non-parallel mul-
tilingual guidance (NMG) proposed by Cohen et
al. (2011)8, and “PR” which is the posterior reg-
ularization approach presented in Gillenwater et
al. (2010). All the results are shown in Table 7.
From Table 7, we can see that among the eight
target languages, our approach achieves best pars-
ing performance on six languages — Danish, Ger-
man, Greek, Italian, Portuguese and Swedish. It
should be noted that the “NMG” system utilizes
more than one helper languages. So it is not di-
rectly comparable to our work.
</bodyText>
<subsectionHeader confidence="0.982695">
4.5 Extensions
</subsectionHeader>
<bodyText confidence="0.998293">
In this section, we briefly outline a few extensions
to our approach that we want to explore in future
work.
</bodyText>
<footnote confidence="0.993999">
8For each language, we use the best result of the four sys-
tems in Table 3 of Cohen et al. (2011)
</footnote>
<page confidence="0.943314">
1344
</page>
<table confidence="0.9997556">
DTP DTP† PTP PTP† USR† PGI PR NMG -U
da 53.2 55.3 57.4 59.8 55.1 41.6 44.0 59.9 60.1
de 65.9 57.9 67.0 63.5 60.0 — — — 67.5
el 73.9 70.8 73.9 72.3 60.3 — — 73.0 74.3
es 58.0 62.3 62.3 66.1 68.3 58.4 62.4 76.7 64.6
it 65.5 66.9 69.9 71.5 47.9 — — — 73.6
nl 67.6 66.0 72.2 72.1 44.0 45.1 37.9 50.7 70.5
pt 77.9 79.2 80.6 82.9 70.9 63.0 47.8 79.8 83.3
sv 70.4 70.2 71.3 70.4 52.6 58.3 42.2 74.0 75.1
Ave 66.6 66.1 69.4 69.8 57.4 — — — 71.1
</table>
<tableCaption confidence="0.992432">
Table 7: UAS on sentences of length 10 or less without punctuation from CoNLL shared task treebanks.
</tableCaption>
<bodyText confidence="0.972731833333333">
“USR†” is the weakly supervised system of Naseem et al. (2010). “PGI” is the phylogenetic grammar
induction model of Berg-Kirkpatrick and Klein (2010). Both the “USR†” and “PGI” systems are im-
plemented and reported by McDonald et al. (2011). “NMG” is the unsupervised dependency parsing
model with non-parallel multilingual guidance (Cohen et al., 2011). “PR” is the posterior regularization
approach presented in Gillenwater et al. (2010). Some systems’ results for certain target languages are
not available as marked by —.
</bodyText>
<subsubsectionHeader confidence="0.739342">
4.5.1 Non-Projective Parsing
</subsubsectionHeader>
<bodyText confidence="0.999925">
As mentioned in section 2.3, the runtime to com-
pute KU and its gradient is O(n4). One reasonable
speedup, as presented in Smith and Eisner (2007),
is to replace Shannon entropy with R´enyi entropy.
The R´enyi entropy is parameterized by α:
</bodyText>
<equation confidence="0.809859333333333">
� 1 p(y)α) (16)
Rα (p) = 1 − αlog E
y
</equation>
<bodyText confidence="0.9984175">
With R´enyi entropy, the computation of KU and
its gradient is O(n3), even for non-projective case.
</bodyText>
<subsectionHeader confidence="0.72624">
4.5.2 Higher-Order Models for Projective
Parsing
</subsectionHeader>
<bodyText confidence="0.943152">
Our learning framework can be extended to
higher-order dependency parsing models. For ex-
ample, if we want to make our model capable of
utilizing more contextual information, we can ex-
tend our transferring weight to higher-order parts:
�
V t wE (ps, xi ), if pt align−→ps
˜w(p , xi) = wE(ptdelex, xs i), otherwise
(17)
where p is a small part of tree y that has limited
interactions. For projective parsing, several al-
gorithms (McDonald and Pereira, 2006; Carreras,
2007; Koo and Collins, 2010; Ma and Zhao, 2012)
have been proposed to solve the model training
problems (calculation of objective function and
gradient) for different factorizations.
</bodyText>
<subsubsectionHeader confidence="0.399005">
4.5.3 IGT Data
</subsubsectionHeader>
<bodyText confidence="0.99998875">
One possible direction to improve our approach
is to replace parallel text with Interlinear Glossed
Text (IGT) (Lewis and Xia, 2010), which is a
semi-structured data type encoding more syntactic
information than parallel data. By using IGT Data,
not only can we obtain more accurate word align-
ments, but also extract useful cross-lingual infor-
mation for the resource-poor language.
</bodyText>
<sectionHeader confidence="0.998904" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999966666666667">
In this paper, we propose an unsupervised pro-
jective dependency parsing approach for resource-
poor languages, using existing resources from a
resource-rich source language. By presenting a
model training framework, our approach can uti-
lize parallel text to estimate transferring distribu-
tion with the help of a well-developed resource-
rich language dependency parser, and use unla-
beled data as entropy regularization. The exper-
imental results on three data sets across ten target
languages show that our approach achieves signif-
icant improvement over previous studies.
</bodyText>
<sectionHeader confidence="0.996514" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999429857142857">
This material is based upon work supported by
the National Science Foundation under Grant No.
BCS-0748919. Any opinions, findings, and con-
clusions or recommendations expressed in this
material are those of the authors and do not nec-
essarily reflect the views of the National Science
Foundation.
</bodyText>
<page confidence="0.989752">
1345
</page>
<sectionHeader confidence="0.990293" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998896653846154">
Steven Abney. 2004. Understanding the Yarowsky al-
gorithm. Computational Linguistics, 30:2004.
James K. Baker. 1979. Trainable grammars for speech
recognition. In Proceedings of 97th meeting of the
Acoustical Society ofAmerica, pages 547–550.
Taylor Berg-Kirkpatrick and Dan Klein. 2010. Phylo-
genetic grammar induction. In Proceedings ofACL-
2010, pages 1288–1297, Uppsala, Sweden, July.
Phil Blunsom and Trevor Cohn. 2010. Unsupervised
induction of tree substitution grammars for depen-
dency parsing. In Proceedings of EMILP-2010,
pages 1204–1213, Cambridge, MA, October.
Matthew Brand. 1998. Structure learning in con-
ditional probability models via an entropic prior
and parameter extinction. Ieural Computation,
11(5):1155–1182.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X
shared task on multilingual dependency parsing. In
Proceeding of CoILL-2006, pages 149–164, New
York, NY.
David Burkett and Dan Klein. 2008. Two languages
are better than one (for syntactic parsing). In Pro-
ceedings of EMILP-2008, pages 877–886, Hon-
olulu, Hawaii, October.
Xavier Carreras. 2007. Experiments with a higher-
order projective dependency parser. In Proceed-
ings of the CoILL Shared Task Session of EMILP-
COILL, pages 957–961.
Glenn Carroll and Eugene Charniak. 1992. Two
experiments on learning probabilistic dependency
grammars from corpora. In Proceedings of Work-
ing Iotes of the Workshop Statistically-Based ILP
Techniques.
Wenliang Chen, Jun’ichi Kazama, and Kentaro Tori-
sawa. 2010. Bitext dependency parsing with bilin-
gual subtree constraints. In Proceedings of ACL-
2010, pages 21–29, Uppsala, Sweden, July.
Shay Cohen and Noah A. Smith. 2009. Shared lo-
gistic normal distributions for soft parameter tying
in unsupervised grammar induction. In Proceedings
of IAACL/HLT-2009, pages 74–82, Boulder, Col-
orado,June.
Shay B. Cohen, Dipanjan Das, and Noah A. Smith.
2011. Unsupervised structure prediction with non-
parallel multilingual guidance. In Proceedings of
EMILP-2011, pages 50–61, Edinburgh, Scotland,
UK., July.
Dipanjan Das and Slav Petrov. 2011. Unsuper-
vised part-of-speech tagging with bilingual graph-
based projections. In Proceedings of ACL/HLT-
2011, pages 600–609, Portland, Oregon, USA, June.
Kuzman Ganchev, Jennifer Gillenwater, and Ben
Taskar. 2009. Dependency grammar induction
via bitext projection constraints. In Proceedings of
ACL/AFILP-2009, pages 369–377, Suntec, Singa-
pore, August.
Jennifer Gillenwater, Kuzman Ganchev, Jo˜ao Grac¸a,
Fernando Pereira, and Ben Taskar. 2010. Sparsity in
dependency grammar induction. In Proceedings of
the ACL 2010 Conference Short Papers, pages 194–
199, Uppsala, Sweden, July.
Joao V. Graca, Lf Inesc-id, Kuzman Ganchev, and Ben
Taskar. 2007. Expectation maximization and pos-
terior constraints. In Advances in IIPS, pages 569–
576.
Yves Grandvalet and Yoshua Bengio. 2004. Semi-
supervised learning by entropy minimization. In Ad-
vances in Ieural Information Processing Systems.
Liang Huang, Wenbin Jiang, and Qun Liu. 2009.
Bilingually-constrained (monolingual) shift-reduce
parsing. In Proceedings of EMILP-2009, pages
1222–1231, Singapore, August.
Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara
Cabezas, and Okan Kolak. 2005. Bootstrapping
parsers via syntactic projection across parallel texts.
Iatural Language Engineering, 11:11–311.
Feng Jiao, Shaojun Wang, Chi-Hoon Lee, Russell
Greiner, and Dale Schuurmans. 2006. Semi-
supervised conditional random fields for improved
sequence segmentation and labeling. In Proceed-
ings of COLIIG/ACL-2006, pages 209–216, Syd-
ney, Australia, July.
Jason Katz-Brown, Slav Petrov, Ryan McDon-
ald, Franz Och, David Talbot, Hiroshi Ichikawa,
Masakazu Seno, and Hideto Kazawa. 2011. Train-
ing a parser for machine translation reordering. In
Proceedings of EMILP-2011, pages 183–192, Ed-
inburgh, Scotland, UK., July.
Dan Klein and Christopher Manning. 2004. Corpus-
based induction of syntactic structure: Models of de-
pendency and constituency. In Proceedings ofACL-
2004, pages 478–485, Barcelona, Spain, July.
Philipp Koehn. 2005. Europarl: A Parallel Corpus
for Statistical Machine Translation. In Conference
Proceedings: the tenth Machine Translation Sum-
mit, pages 79–86, Phuket, Thailand. AAMT, AAMT.
Terry Koo and Michael Collins. 2010. Efficient third-
order dependency parsers. In Proceedings of ACL-
2010, pages 1–11, Uppsala, Sweden, July.
Terry Koo, Amir Globerson, Xavier Carreras, and
Michael Collins. 2007. Structured predicition mod-
els via the matrix-tree theorem. In Proceedings
of EMILP-COILL 2007, pages 141–150, Prague,
Czech, June.
</reference>
<page confidence="0.824804">
1346
</page>
<reference confidence="0.99980483018868">
William D. Lewis and Fei Xia. 2010. Developing
odin: A multilingual repository of annotated lan-
guage data for hundreds of the world’s languages.
LLC, 25(3):303–319.
Xuezhe Ma and Hai Zhao. 2012. Fourth-order depen-
dency parsing. In Proceedings of COLIIG 2012:
Posters, pages 785–796, Mumbai, India, December.
Gideon S. Mann and Andrew McCallum. 2007. Ef-
ficient computation of entropy gradient for semi-
supervised conditional random fields. In Proceed-
ings ofIAACL/HLT-2007, pages 109–112, Strouds-
burg, PA, USA.
David Mareˇcek and Milan Straka. 2013. Stop-
probability estimates computed on a large corpus
improve unsupervised dependency parsing. In Pro-
ceedings of ACL-2013, pages 281–290, Sofia, Bul-
garia, August.
Ryan McDonald and Fernando Pereira. 2006. Online
learning of approximate dependency parsing algo-
rithms. In Proceedings ofEACL-2006, pages 81–88,
Trento, Italy, April.
Ryan McDonald, Koby Crammer, and Fernando
Pereira. 2005a. Online large-margin training of
dependency parsers. In Proceedings of ACL-2005,
pages 91–98, Ann Arbor, Michigan, USA, June 25-
30.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajic. 2005b. Non-projective dependency pars-
ing using spanning tree algorithms. In Proceedings
of HLT/EMILP-2005, pages 523–530, Vancouver,
Canada, October.
Ryan McDonald, Slav Petrov, and Keith Hall. 2011.
Multi-source transfer of delexicalized dependency
parsers. In Proceedings ofEMILP-2011, pages 62–
72, Edinburgh, Scotland, UK., July.
Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-
Brundage, Yoav Goldberg, Dipanjan Das, Kuz-
man Ganchev, Keith Hall, Slav Petrov, Hao
Zhang, Oscar T¨ackstr¨om, Claudia Bedini, N´uria
Bertomeu Castell´o, and Jungmee Lee. 2013. Uni-
versal dependency annotation for multilingual pars-
ing. In Proceedings of ACL-2013, pages 92–97,
Sofia, Bulgaria, August.
Tahira Naseem, Harr Chen, Regina Barzilay, and Mark
Johnson. 2010. Using universal linguistic knowl-
edge to guide grammar induction. In Proceedings of
EMILP-2010, pages 1234–1244, Cambridge, MA,
October.
Stephen G. Nash and Jorge Nocedal. 1991. A numer-
ical study of the limited memory bfgs method and
truncated-newton method for large scale optimiza-
tion. SIAMJournal on Optimization, 1(2):358–372.
Truc-Vien T. Nguyen, Alessandro Moschitti, and
Giuseppe Riccardi. 2009. Convolution kernels on
constituent, dependency and sequential structures
for relation extraction. In Proceedings of EMILP-
2009, pages 1378–1387, Singapore, August.
Joakim Nivre and Mario Scholz. 2004. Deterministic
dependency parsing of English text. In Proceedings
of COLIIG-2004, pages 64–70, Geneva, Switzer-
land, August 23-27.
Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan Mc-
donald, Jens Nilsson, Sebastian Riedel, and Deniz
Yuret. 2007. The conll 2007 shared task on depen-
dency parsing. In Proceeding of EMILP-CoILL
2007, pages 915–932, Prague, Czech.
Joakim Nivre. 2008. Algorithms for deterministic in-
cremental dependency parsing. Comput. Linguist.,
34(4):513–553, December.
Mark A. Paskin. 2001. Cubic-time parsing and
learning algorithms for grammatical bigram models.
Technical Report, UCB/CSD-01-1148.
Slav Petrov, Dipanjan Das, and Ryan T. McDonald.
2011. A universal part-of-speech tagset. CoRR,
abs/1104.2086.
Yusuke Shinyama, Satoshi Sekine, and Kiyoshi Sudo.
2002. Automatic paraphrase acquisition from news
articles. In Proceeding of HLT-2002, pages 313–
318.
Noah A. Smith and Jason Eisner. 2005. Contrastive
estimation: Training log-linear models on unlabeled
data. In Proceedings ofACL-2005, pages 354–362,
Ann Arbor, Michigan, June.
David A. Smith and Jason Eisner. 2007. Bootstrapping
feature-rich dependency parsers with entropic pri-
ors. In Proceedings ofEMILP/CoILL-2007, pages
667–677, Prague, Czech Republic, June.
David A. Smith and Noah A. Smith. 2004. Bilin-
gual parsing with factored estimation: Using En-
glish to parse Korean. In Proceedings of EMILP-
2004, pages 49–56.
David A. Smith and Noah A. Smith. 2007. Probabilis-
tic models of nonporjective dependency trees. In
Proceedings of EMILP-COILL 2007, pages 132–
140, Prague, Czech, June.
Valentin I. Spitkovsky, Hiyan Alshawi, and Daniel Ju-
rafsky. 2010. From baby steps to leapfrog: How
“less is more” in unsupervised dependency parsing.
In Proceedings of IAACL/HLT-2010, pages 751–
759, Los Angeles, California, June.
Valentin I. Spitkovsky, Hiyan Alshawi, and Daniel Ju-
rafsky. 2013. Breaking out of local optima with
count transforms and model recombination: A study
in grammar induction. In Proceedings of EMILP-
2013, pages 1983–1995, Seattle, Washington, USA,
October.
</reference>
<page confidence="0.836229">
1347
</page>
<reference confidence="0.999514923076923">
Kristina Toutanova, Dan Klein, Christopher D. Man-
ning, and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network.
In Proceedings of IAACL/HLT-2003, pages 252–
259.
Jun Xie, Haitao Mi, and Qun Liu. 2011. A novel
dependency-to-string model for statistical machine
translation. In Proceedings of EMILP-2011, pages
216–226, Edinburgh, Scotland, UK., July.
Hao Zhang, Liang Huang, Kai Zhao, and Ryan Mc-
Donald. 2013. Online learning for inexact hy-
pergraph search. In Proceedings of EMILP-2013,
pages 908–913, Seattle, Washington, USA, October.
</reference>
<page confidence="0.993786">
1348
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.853092">
<title confidence="0.99659">Unsupervised Dependency Parsing with Distribution via Parallel Guidance and Entropy Regularization</title>
<author confidence="0.874532">Xuezhe</author>
<affiliation confidence="0.999143">Department of University of</affiliation>
<address confidence="0.998524">Seattle, WA 98195,</address>
<email confidence="0.999712">xzma@uw.edu</email>
<abstract confidence="0.999105043478261">We present a novel approach for inducing unsupervised dependency parsers for languages that have no labeled training data, but have translated text in a resourcerich language. We train probabilistic parsing models for resource-poor languages by transferring cross-lingual knowledge from resource-rich language with entropy regularization. Our method can be used as a purely monolingual dependency parser, requiring no human translations for the test data, thus making it applicable to a wide range of resource-poor languages. We perform experiments on three Data sets — Version 1.0 and version 2.0 of Google Universal Dependency Treebanks and Treebanks from CoNLL shared-tasks, across ten languages. We obtain stateof-the art performance of all the three data sets when compared with previously studied unsupervised and projected parsing systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
</authors>
<title>Understanding the Yarowsky algorithm.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<pages>30--2004</pages>
<contexts>
<context position="9535" citStr="Abney, 2004" startWordPosition="1512" endWordPosition="1513">ing data {(xi, yi)}, the logarithm of the likelihood (a.k.a. the log-likelihood) is given by: L(λ) = � log pλ(yi|xi) (6) i Maximum likelihood training chooses parameters such that the log-likelihood L(λ) is maximized. However, in our scenario we have no labeled training data for target languages but we have some parallel and unlabeled data plus an English dependency parser. For the purpose of transferring cross-lingual information from the English parser via parallel text, we explore the model training method proposed by Smith and Eisner (2007), which presented a generalization of K function (Abney, 2004), and related it to another semi-supervised learning technique, entropy regularization (Jiao et al., 2006; Mann and McCallum, 2007). The objective K function to be minimized is actually the expected negative loglikelihood: K = − � E ˜p(yi|xi) log pλ(yi|xi) i yi �= D(˜pi||pλ,i) + H(˜pi) (7) i 1 pλ(y|x) = Z(x) rl w(e, x) (5) e∈y where ˜pi(·) def= ˜p(·|xi) and pλ,i(·) def= pλ(·|xi). ˜p(y|x) is the “transferring distribution” that reflects our uncertainty about the true labels, and we are trying to learn a parametric model pλ(y|x) by minimizing the K function. In our scenario, we have a set of ali</context>
</contexts>
<marker>Abney, 2004</marker>
<rawString>Steven Abney. 2004. Understanding the Yarowsky algorithm. Computational Linguistics, 30:2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James K Baker</author>
</authors>
<title>Trainable grammars for speech recognition.</title>
<date>1979</date>
<booktitle>In Proceedings of 97th meeting of the Acoustical Society ofAmerica,</booktitle>
<pages>547--550</pages>
<contexts>
<context position="14589" citStr="Baker, 1979" startWordPosition="2392" endWordPosition="2393">ion of the objective function and the gradient of the objective function. The first item (KP) of the K′ function in equation (11) can be rewritten in the following form: XKP = − [X ˜p(yi|xi) X log w(e, xi) xiEP yi eEyi − log Z(xi)] (12) and according to equation (1) and (3) the gradient of KP can be written as: ∂˜p(yi|xi) log pλ(yi|xi) ∂λj X �X X = ˜p(yi|xi) fj(e,xi) xiEP yi eEyi �fj(e, xi) (13) According to equation (9), ˜p(y|x) can also be factored into the multiplication of the weight of each edge, so both KP and its gradient can be calculated by running the O(n3) inside-outside algorithm (Baker, 1979; Paskin, 2001) for projective parsing. For non-projective parsing, the analogy to the inside algorithm is the O(n3) matrixtree algorithm based on Kirchhoff’s Matrix-Tree Theorem, which is dominated asymptotically by a matrix determinant (Koo et al., 2007; Smith and Smith, 2007). The gradient of a determinant may be computed by matrix inversion, so evaluating the gradient again has the same O(n3) complexity as evaluating the function. The second item (KU) of the K′ function in equation (11) is the Shannon entropy of the posterior distribution over parsing trees, and can be written into the fol</context>
<context position="16251" citStr="Baker, 1979" startWordPosition="2644" endWordPosition="2645"> fr 3,312/74,979 366/8,071 300/6,950 ko 5,308/62,378 588/6,545 298/2,917 sv 4,447/66,631 493/9,312 1,219/20,376 Version 2.0 de 14,118/26,4906 800/12,215 1,000/16,339 es 14,138/37,5180 1,569/40,950 300/8,295 fr 14,511/35,1233 1,611/38,328 300/6,950 it 6,389/14,9145 400/9,541 400/9,187 ko 5437/60,621 603/6,438 299/2,631 pt 9,600/23,9012 1,200/29,873 1,198/29,438 sv 4,447/66,631 493/9,312 1,219/20,376 Table 1: Data statistics of two versions of Google Universal Treebanks for the target languages. Similar with the calculation of KP, KU can also be computed by running the inside-outside algorithm (Baker, 1979; Paskin, 2001) for projective parsing. For the gradient of KU, both the two multipliers of the second item in equation (15) can be computed using the same inside-outside algorithm. For the first item in equation (15), an O(n3) dynamic programming algorithm that is closely related to the forward-backward algorithm (Mann and McCallum, 2007) for the entropy regularized CRF (Jiao et al., 2006) can be used for projective parsing. For non-projective parsing, however, the runtime rises to O(n4). In this paper, we focus on projective parsing. 2.4 Summary of Our Approach To summarize the description i</context>
</contexts>
<marker>Baker, 1979</marker>
<rawString>James K. Baker. 1979. Trainable grammars for speech recognition. In Proceedings of 97th meeting of the Acoustical Society ofAmerica, pages 547–550.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taylor Berg-Kirkpatrick</author>
<author>Dan Klein</author>
</authors>
<title>Phylogenetic grammar induction.</title>
<date>2010</date>
<booktitle>In Proceedings ofACL2010,</booktitle>
<pages>1288--1297</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="31777" citStr="Berg-Kirkpatrick and Klein (2010)" startWordPosition="5201" endWordPosition="5204">ms and the oracle (OR). The results of unsupervised DMV model (Klein and Manning, 2004) are from Table 1 of McDonald et al. (2011). Our approach outperforms all these baseline systems and achieves state-of-theart performance on all the eight languages. In order to compare with more previous methods, we also report parsing performance on sentences of length 10 or less after punctuation has been removed. Table 7 shows the results of our system and the results of baseline systems. “USR†” is the weakly supervised system of Naseem et al. (2010). “PGI” is the phylogenetic grammar induction model of Berg-Kirkpatrick and Klein (2010). Both the results of the two systems are cited from Table 4 of McDonald et al. (2011). We also include the results of the unsupervised dependency parsing model with non-parallel multilingual guidance (NMG) proposed by Cohen et al. (2011)8, and “PR” which is the posterior regularization approach presented in Gillenwater et al. (2010). All the results are shown in Table 7. From Table 7, we can see that among the eight target languages, our approach achieves best parsing performance on six languages — Danish, German, Greek, Italian, Portuguese and Swedish. It should be noted that the “NMG” syste</context>
<context position="33380" citStr="Berg-Kirkpatrick and Klein (2010)" startWordPosition="5502" endWordPosition="5505">59.8 55.1 41.6 44.0 59.9 60.1 de 65.9 57.9 67.0 63.5 60.0 — — — 67.5 el 73.9 70.8 73.9 72.3 60.3 — — 73.0 74.3 es 58.0 62.3 62.3 66.1 68.3 58.4 62.4 76.7 64.6 it 65.5 66.9 69.9 71.5 47.9 — — — 73.6 nl 67.6 66.0 72.2 72.1 44.0 45.1 37.9 50.7 70.5 pt 77.9 79.2 80.6 82.9 70.9 63.0 47.8 79.8 83.3 sv 70.4 70.2 71.3 70.4 52.6 58.3 42.2 74.0 75.1 Ave 66.6 66.1 69.4 69.8 57.4 — — — 71.1 Table 7: UAS on sentences of length 10 or less without punctuation from CoNLL shared task treebanks. “USR†” is the weakly supervised system of Naseem et al. (2010). “PGI” is the phylogenetic grammar induction model of Berg-Kirkpatrick and Klein (2010). Both the “USR†” and “PGI” systems are implemented and reported by McDonald et al. (2011). “NMG” is the unsupervised dependency parsing model with non-parallel multilingual guidance (Cohen et al., 2011). “PR” is the posterior regularization approach presented in Gillenwater et al. (2010). Some systems’ results for certain target languages are not available as marked by —. 4.5.1 Non-Projective Parsing As mentioned in section 2.3, the runtime to compute KU and its gradient is O(n4). One reasonable speedup, as presented in Smith and Eisner (2007), is to replace Shannon entropy with R´enyi entrop</context>
</contexts>
<marker>Berg-Kirkpatrick, Klein, 2010</marker>
<rawString>Taylor Berg-Kirkpatrick and Dan Klein. 2010. Phylogenetic grammar induction. In Proceedings ofACL2010, pages 1288–1297, Uppsala, Sweden, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phil Blunsom</author>
<author>Trevor Cohn</author>
</authors>
<title>Unsupervised induction of tree substitution grammars for dependency parsing.</title>
<date>2010</date>
<booktitle>In Proceedings of EMILP-2010,</booktitle>
<pages>1204--1213</pages>
<location>Cambridge, MA,</location>
<contexts>
<context position="2270" citStr="Blunsom and Cohn, 2010" startWordPosition="342" endWordPosition="346"> several treebanks, due in large part to the availability of dependency treebanks in a number of languages (McDonald et al., 2013). Fei Xia Department of Linguistics University of Washington Seattle, WA 98195, USA fxia@uw.edu However, the manually annotated treebanks that these parsers rely on are highly expensive to create, in particular when we want to build treebanks for resource-poor languages. This led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eisner, 2005; Cohen and Smith, 2009; Spitkovsky et al., 2010; Blunsom and Cohn, 2010; Mareˇcek and Straka, 2013; Spitkovsky et al., 2013), which appears to be a natural solution to this problem, as unsupervised methods require only unannotated text for training parsers. Unfortunately, the unsupervised grammar induction systems’ parsing accuracies often significantly fall behind those of supervised systems (McDonald et al., 2011). Furthermore, from a practical standpoint, it is rarely the case that we are completely devoid of resources for most languages. In this paper, we consider a practically motivated scenario, in which we want to build statistical parsers for resource-poo</context>
</contexts>
<marker>Blunsom, Cohn, 2010</marker>
<rawString>Phil Blunsom and Trevor Cohn. 2010. Unsupervised induction of tree substitution grammars for dependency parsing. In Proceedings of EMILP-2010, pages 1204–1213, Cambridge, MA, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Brand</author>
</authors>
<title>Structure learning in conditional probability models via an entropic prior and parameter extinction.</title>
<date>1998</date>
<journal>Ieural Computation,</journal>
<volume>11</volume>
<issue>5</issue>
<contexts>
<context position="13598" citStr="Brand, 1998" startWordPosition="2219" endWordPosition="2220"> y eEy Due to the normalizing factor ˜Z(x), the transferring distribution is a valid one. We introduce a multiplier γ as a trade-off between the two contributions (parallel and unsupervised) of the objective function K, and the final objective function K′ has the following form: K′ = − X X ˜p(yi|xi) log pλ(yi|xi) xiEP yi X + γ xiEU = KP + γKU (11) KP and KU are the contributions of the parallel and unsupervised data, respectively. One may regard γ as a Lagrange multiplier that is used to constrain the parser’s uncertainty H to be low, as presented in several studies on entropy regularization (Brand, 1998; Grandvalet and Bengio, 2004; Jiao et al., 2006). 2.3 Algorithms and Complexity for Model Training To train our parsing model, we need to find out the parameters λ that minimize the objective function K′ in equation (11). This optimization problem is typically solved using quasi-Newton numerical methods such as L-BFGS (Nash and Nocedal, 1991), which requires efficient calculation of the objective function and the gradient of the objective function. The first item (KP) of the K′ function in equation (11) can be rewritten in the following form: XKP = − [X ˜p(yi|xi) X log w(e, xi) xiEP yi eEyi −</context>
</contexts>
<marker>Brand, 1998</marker>
<rawString>Matthew Brand. 1998. Structure learning in conditional probability models via an entropic prior and parameter extinction. Ieural Computation, 11(5):1155–1182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceeding of CoILL-2006,</booktitle>
<pages>149--164</pages>
<location>New York, NY.</location>
<contexts>
<context position="19231" citStr="Buchholz and Marsi, 2006" startWordPosition="3112" endWordPosition="3115">ese resources. The monolingual treebanks in our experiments are from the Google Universal Dependency Treebanks (McDonald et al., 2013), for the reason that the treebanks of different languages in Google Universal Dependency Treebanks have consistent syntactic representations. The parallel data come from the Europarl corpus version 7 (Koehn, 2005) and Kaist Corpus4. Taking the intersection of languages in the two kinds of resources yields the following seven languages: French, German, Italian, Korean, Portuguese, Spanish and Swedish. The treebanks from CoNLL shared-tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007) appear to be another reasonable choice. However, previous studies (McDonald et al., 2011; McDonald et al., 2013) have demonstrated that a homogeneous representation is critical for multilingual language technologies that require consistent cross-lingual analysis for downstream components, and the heterogenous representations used in CoNLL shared-tasks treebanks weaken any conclusion that can be drawn. 4http://semanticweb.kaist.ac.kr/home/ index.php/Corpus10 1341 DTP DTP† PTP† -U +U OR de 58.50 58.46 69.21 73.72 74.01 78.64 es 68.07 68.72 72.57 75.32 75.60 82.56 fr 70.14 7</context>
<context position="30055" citStr="Buchholz and Marsi, 2006" startWordPosition="4898" endWordPosition="4902">approach does not rely on a large amount of parallel data. Second, when gradually increasing the amount of parallel data, the parsing performance continues improving. Third, entropy regularization with unlabeled data makes modest improvement on parsing performance over the parsers without unlabeled data. This proves the effectiveness of the entropy regularization from unlabeled data. 4.4 Experiments on CoNLL Treebanks To make a thorough empirical comparison with previous studies, we also evaluate our system without unlabeled data (-U) on treebanks from CoNLL shared task on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007). To facilitate comparison, we use the same eight IndoEuropean languages as target languages: Danish, Dutch, German, Greek, Italian, Portuguese, Spanish and Swedish, and same experimental setup as McDonald et al. (2011). We report both the results of the direct transfer and projected transfer parsers directly cited from McDonald et al. (2011) (DTP and PTP) and re-implemented by us (DTP†and PTP†). Table 6 gives the results comparing the model without unlabeled data (-U) presented in this work DMV DTP DTP† PTP PTP† -U OR da 33.4 45.9 46.8 48.2 50.0 50.1 87.1 de 18.0 47.2 46.</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proceeding of CoILL-2006, pages 149–164, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Burkett</author>
<author>Dan Klein</author>
</authors>
<title>Two languages are better than one (for syntactic parsing).</title>
<date>2008</date>
<booktitle>In Proceedings of EMILP-2008,</booktitle>
<pages>877--886</pages>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="3528" citStr="Burkett and Klein, 2008" startWordPosition="537" endWordPosition="540"> resources from a resource-rich source language (like English).1 We assume that there are absolutely no labeled training data for the target language, but we have access to parallel data with a resource-rich language and a sufficient amount of labeled training data to build an accurate parser for the resource-rich language. This scenario appears similar to the setting in bilingual text parsing. However, most bilingual text parsing approaches require bilingual treebanks — treebanks that have manually annotated tree structures on both sides of source and target languages (Smith and Smith, 2004; Burkett and Klein, 2008), or have tree structures on the source side and translated sentences in the target languages (Huang et 1For the sake of simplicity, we refer to the resource-poor language as the “target language”, and resource-rich language as the “source language”. In addition, in this study we use English as the source resource-rich language, but our methodology can be applied to any resource-rich languages. 1337 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1337–1348, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics</context>
</contexts>
<marker>Burkett, Klein, 2008</marker>
<rawString>David Burkett and Dan Klein. 2008. Two languages are better than one (for syntactic parsing). In Proceedings of EMILP-2008, pages 877–886, Honolulu, Hawaii, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
</authors>
<title>Experiments with a higherorder projective dependency parser.</title>
<date>2007</date>
<booktitle>In Proceedings of the CoILL Shared Task Session of EMILPCOILL,</booktitle>
<pages>957--961</pages>
<contexts>
<context position="1526" citStr="Carreras, 2007" startWordPosition="224" endWordPosition="225">ges. We obtain stateof-the art performance of all the three data sets when compared with previously studied unsupervised and projected parsing systems. 1 Introduction In recent years, dependency parsing has gained universal interest due to its usefulness in a wide range of applications such as synonym generation (Shinyama et al., 2002), relation extraction (Nguyen et al., 2009) and machine translation (Katz-Brown et al., 2011; Xie et al., 2011). Several supervised dependency parsing algorithms (Nivre and Scholz, 2004; McDonald et al., 2005a; McDonald et al., 2005b; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Ma and Zhao, 2012; Zhang et al., 2013) have been proposed and achieved high parsing accuracies on several treebanks, due in large part to the availability of dependency treebanks in a number of languages (McDonald et al., 2013). Fei Xia Department of Linguistics University of Washington Seattle, WA 98195, USA fxia@uw.edu However, the manually annotated treebanks that these parsers rely on are highly expensive to create, in particular when we want to build treebanks for resource-poor languages. This led to a vast amount of research on unsupervised grammar induction (Car</context>
<context position="34681" citStr="Carreras, 2007" startWordPosition="5720" endWordPosition="5721"> R´enyi entropy, the computation of KU and its gradient is O(n3), even for non-projective case. 4.5.2 Higher-Order Models for Projective Parsing Our learning framework can be extended to higher-order dependency parsing models. For example, if we want to make our model capable of utilizing more contextual information, we can extend our transferring weight to higher-order parts: � V t wE (ps, xi ), if pt align−→ps ˜w(p , xi) = wE(ptdelex, xs i), otherwise (17) where p is a small part of tree y that has limited interactions. For projective parsing, several algorithms (McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Ma and Zhao, 2012) have been proposed to solve the model training problems (calculation of objective function and gradient) for different factorizations. 4.5.3 IGT Data One possible direction to improve our approach is to replace parallel text with Interlinear Glossed Text (IGT) (Lewis and Xia, 2010), which is a semi-structured data type encoding more syntactic information than parallel data. By using IGT Data, not only can we obtain more accurate word alignments, but also extract useful cross-lingual information for the resource-poor language. 5 Conclusion In this pap</context>
</contexts>
<marker>Carreras, 2007</marker>
<rawString>Xavier Carreras. 2007. Experiments with a higherorder projective dependency parser. In Proceedings of the CoILL Shared Task Session of EMILPCOILL, pages 957–961.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glenn Carroll</author>
<author>Eugene Charniak</author>
</authors>
<title>Two experiments on learning probabilistic dependency grammars from corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of Working Iotes of the Workshop Statistically-Based ILP Techniques.</booktitle>
<contexts>
<context position="2149" citStr="Carroll and Charniak, 1992" startWordPosition="322" endWordPosition="325">007; Koo and Collins, 2010; Ma and Zhao, 2012; Zhang et al., 2013) have been proposed and achieved high parsing accuracies on several treebanks, due in large part to the availability of dependency treebanks in a number of languages (McDonald et al., 2013). Fei Xia Department of Linguistics University of Washington Seattle, WA 98195, USA fxia@uw.edu However, the manually annotated treebanks that these parsers rely on are highly expensive to create, in particular when we want to build treebanks for resource-poor languages. This led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eisner, 2005; Cohen and Smith, 2009; Spitkovsky et al., 2010; Blunsom and Cohn, 2010; Mareˇcek and Straka, 2013; Spitkovsky et al., 2013), which appears to be a natural solution to this problem, as unsupervised methods require only unannotated text for training parsers. Unfortunately, the unsupervised grammar induction systems’ parsing accuracies often significantly fall behind those of supervised systems (McDonald et al., 2011). Furthermore, from a practical standpoint, it is rarely the case that we are completely devoid of resources for most languages. In</context>
</contexts>
<marker>Carroll, Charniak, 1992</marker>
<rawString>Glenn Carroll and Eugene Charniak. 1992. Two experiments on learning probabilistic dependency grammars from corpora. In Proceedings of Working Iotes of the Workshop Statistically-Based ILP Techniques.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenliang Chen</author>
<author>Jun’ichi Kazama</author>
<author>Kentaro Torisawa</author>
</authors>
<title>Bitext dependency parsing with bilingual subtree constraints.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL2010,</booktitle>
<pages>21--29</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="4158" citStr="Chen et al., 2010" startWordPosition="634" endWordPosition="637">ee structures on the source side and translated sentences in the target languages (Huang et 1For the sake of simplicity, we refer to the resource-poor language as the “target language”, and resource-rich language as the “source language”. In addition, in this study we use English as the source resource-rich language, but our methodology can be applied to any resource-rich languages. 1337 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1337–1348, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics al., 2009; Chen et al., 2010). Obviously, bilingual treebanks are much more difficult to acquire than the resources required in our scenario, since the labeled training data and the parallel text in our case are completely separated. What is more important is that most studies on bilingual text parsing assumed that the parser is applied only on bilingual text. But our goal is to develop a parser that can be used in completely monolingual setting for each target language of interest. This scenario is applicable to a large set of languages and many research studies (Hwa et al., 2005) have been made on it. Ganchev et al. (20</context>
</contexts>
<marker>Chen, Kazama, Torisawa, 2010</marker>
<rawString>Wenliang Chen, Jun’ichi Kazama, and Kentaro Torisawa. 2010. Bitext dependency parsing with bilingual subtree constraints. In Proceedings of ACL2010, pages 21–29, Uppsala, Sweden, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shay Cohen</author>
<author>Noah A Smith</author>
</authors>
<title>Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction.</title>
<date>2009</date>
<booktitle>In Proceedings of IAACL/HLT-2009,</booktitle>
<pages>74--82</pages>
<location>Boulder, Colorado,June.</location>
<contexts>
<context position="2221" citStr="Cohen and Smith, 2009" startWordPosition="334" endWordPosition="337">proposed and achieved high parsing accuracies on several treebanks, due in large part to the availability of dependency treebanks in a number of languages (McDonald et al., 2013). Fei Xia Department of Linguistics University of Washington Seattle, WA 98195, USA fxia@uw.edu However, the manually annotated treebanks that these parsers rely on are highly expensive to create, in particular when we want to build treebanks for resource-poor languages. This led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eisner, 2005; Cohen and Smith, 2009; Spitkovsky et al., 2010; Blunsom and Cohn, 2010; Mareˇcek and Straka, 2013; Spitkovsky et al., 2013), which appears to be a natural solution to this problem, as unsupervised methods require only unannotated text for training parsers. Unfortunately, the unsupervised grammar induction systems’ parsing accuracies often significantly fall behind those of supervised systems (McDonald et al., 2011). Furthermore, from a practical standpoint, it is rarely the case that we are completely devoid of resources for most languages. In this paper, we consider a practically motivated scenario, in which we w</context>
</contexts>
<marker>Cohen, Smith, 2009</marker>
<rawString>Shay Cohen and Noah A. Smith. 2009. Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction. In Proceedings of IAACL/HLT-2009, pages 74–82, Boulder, Colorado,June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shay B Cohen</author>
<author>Dipanjan Das</author>
<author>Noah A Smith</author>
</authors>
<title>Unsupervised structure prediction with nonparallel multilingual guidance.</title>
<date>2011</date>
<booktitle>In Proceedings of EMILP-2011,</booktitle>
<pages>50--61</pages>
<location>Edinburgh, Scotland, UK.,</location>
<contexts>
<context position="5350" citStr="Cohen et al. (2011)" startWordPosition="826" endWordPosition="829">e on it. Ganchev et al. (2009) presented a parser projection approach via parallel text using the posterior regularization framework (Graca et al., 2007). McDonald et al. (2011) proposed two parser transfer approaches between two different languages — one is directly transferred parser from delexicalized parsers, and the other parser is transferred using constraint driven learning algorithm where constraints are drawn from parallel corpora. In that work, they demonstrate that even the directly transferred delexicalized parser produces significantly higher accuracies than unsupervised parsers. Cohen et al. (2011) proposed an approach for unsupervised dependency parsing with non-parallel multilingual guidance from one or more helper languages, in which parallel data is not used. In this work, we propose a learning framework for transferring dependency grammars from a resource-rich language to resource-poor languages via parallel text. We train probabilistic parsing models for resource-poor languages by maximizing a combination of likelihood on parallel data and confidence on unlabeled data. Our work is based on the learning framework used in Smith and Eisner (2007), which is originally designed for par</context>
<context position="32015" citStr="Cohen et al. (2011)" startWordPosition="5241" endWordPosition="5244"> In order to compare with more previous methods, we also report parsing performance on sentences of length 10 or less after punctuation has been removed. Table 7 shows the results of our system and the results of baseline systems. “USR†” is the weakly supervised system of Naseem et al. (2010). “PGI” is the phylogenetic grammar induction model of Berg-Kirkpatrick and Klein (2010). Both the results of the two systems are cited from Table 4 of McDonald et al. (2011). We also include the results of the unsupervised dependency parsing model with non-parallel multilingual guidance (NMG) proposed by Cohen et al. (2011)8, and “PR” which is the posterior regularization approach presented in Gillenwater et al. (2010). All the results are shown in Table 7. From Table 7, we can see that among the eight target languages, our approach achieves best parsing performance on six languages — Danish, German, Greek, Italian, Portuguese and Swedish. It should be noted that the “NMG” system utilizes more than one helper languages. So it is not directly comparable to our work. 4.5 Extensions In this section, we briefly outline a few extensions to our approach that we want to explore in future work. 8For each language, we us</context>
<context position="33583" citStr="Cohen et al., 2011" startWordPosition="5533" endWordPosition="5536">2.1 44.0 45.1 37.9 50.7 70.5 pt 77.9 79.2 80.6 82.9 70.9 63.0 47.8 79.8 83.3 sv 70.4 70.2 71.3 70.4 52.6 58.3 42.2 74.0 75.1 Ave 66.6 66.1 69.4 69.8 57.4 — — — 71.1 Table 7: UAS on sentences of length 10 or less without punctuation from CoNLL shared task treebanks. “USR†” is the weakly supervised system of Naseem et al. (2010). “PGI” is the phylogenetic grammar induction model of Berg-Kirkpatrick and Klein (2010). Both the “USR†” and “PGI” systems are implemented and reported by McDonald et al. (2011). “NMG” is the unsupervised dependency parsing model with non-parallel multilingual guidance (Cohen et al., 2011). “PR” is the posterior regularization approach presented in Gillenwater et al. (2010). Some systems’ results for certain target languages are not available as marked by —. 4.5.1 Non-Projective Parsing As mentioned in section 2.3, the runtime to compute KU and its gradient is O(n4). One reasonable speedup, as presented in Smith and Eisner (2007), is to replace Shannon entropy with R´enyi entropy. The R´enyi entropy is parameterized by α: � 1 p(y)α) (16) Rα (p) = 1 − αlog E y With R´enyi entropy, the computation of KU and its gradient is O(n3), even for non-projective case. 4.5.2 Higher-Order M</context>
</contexts>
<marker>Cohen, Das, Smith, 2011</marker>
<rawString>Shay B. Cohen, Dipanjan Das, and Noah A. Smith. 2011. Unsupervised structure prediction with nonparallel multilingual guidance. In Proceedings of EMILP-2011, pages 50–61, Edinburgh, Scotland, UK., July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
</authors>
<title>Unsupervised part-of-speech tagging with bilingual graphbased projections.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL/HLT2011,</booktitle>
<pages>600--609</pages>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="23098" citStr="Das and Petrov (2011)" startWordPosition="3740" endWordPosition="3743">ger are extracted from the training portion of each Treebanks. The average tagging accuracy is around 95%. Undoubtedly, we are primarily interested in applying our approach to build statistical parsers for resource-poor target languages without any knowledge. For the purpose of evaluation of our approach and comparison with previous work, we need to exploit the gold POS tags to train the POS taggers. As part-of-speech tags are also a form of syntactic analysis, this assumption weakens the applicability of our approach. Fortunately, some recently proposed POS taggers, such as the POS tagger of Das and Petrov (2011), rely only on labeled training data for English and the same kind of parallel text in our approach. In practice we can use this kind of POS taggers to predict POS tags, whose tagging accuracy is around 85%. 4 Experiments In this section, we will describe the details of our experiments and compare our results with previous methods. 4.1 Data Sets As presented in Section 3.1, we evaluate our parsing approach on both version 1.0 and version 2.0 of Google Univereal Treebanks for seven languages6. We use the standard splits of the treebank for each language as specified in the release of the data7.</context>
</contexts>
<marker>Das, Petrov, 2011</marker>
<rawString>Dipanjan Das and Slav Petrov. 2011. Unsupervised part-of-speech tagging with bilingual graphbased projections. In Proceedings of ACL/HLT2011, pages 600–609, Portland, Oregon, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Jennifer Gillenwater</author>
<author>Ben Taskar</author>
</authors>
<title>Dependency grammar induction via bitext projection constraints.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL/AFILP-2009,</booktitle>
<pages>369--377</pages>
<location>Suntec, Singapore,</location>
<contexts>
<context position="4761" citStr="Ganchev et al. (2009)" startWordPosition="740" endWordPosition="743">Chen et al., 2010). Obviously, bilingual treebanks are much more difficult to acquire than the resources required in our scenario, since the labeled training data and the parallel text in our case are completely separated. What is more important is that most studies on bilingual text parsing assumed that the parser is applied only on bilingual text. But our goal is to develop a parser that can be used in completely monolingual setting for each target language of interest. This scenario is applicable to a large set of languages and many research studies (Hwa et al., 2005) have been made on it. Ganchev et al. (2009) presented a parser projection approach via parallel text using the posterior regularization framework (Graca et al., 2007). McDonald et al. (2011) proposed two parser transfer approaches between two different languages — one is directly transferred parser from delexicalized parsers, and the other parser is transferred using constraint driven learning algorithm where constraints are drawn from parallel corpora. In that work, they demonstrate that even the directly transferred delexicalized parser produces significantly higher accuracies than unsupervised parsers. Cohen et al. (2011) proposed a</context>
</contexts>
<marker>Ganchev, Gillenwater, Taskar, 2009</marker>
<rawString>Kuzman Ganchev, Jennifer Gillenwater, and Ben Taskar. 2009. Dependency grammar induction via bitext projection constraints. In Proceedings of ACL/AFILP-2009, pages 369–377, Suntec, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer Gillenwater</author>
<author>Kuzman Ganchev</author>
<author>Jo˜ao Grac¸a</author>
<author>Fernando Pereira</author>
<author>Ben Taskar</author>
</authors>
<title>Sparsity in dependency grammar induction.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 Conference Short Papers,</booktitle>
<pages>194--199</pages>
<location>Uppsala, Sweden,</location>
<marker>Gillenwater, Ganchev, Grac¸a, Pereira, Taskar, 2010</marker>
<rawString>Jennifer Gillenwater, Kuzman Ganchev, Jo˜ao Grac¸a, Fernando Pereira, and Ben Taskar. 2010. Sparsity in dependency grammar induction. In Proceedings of the ACL 2010 Conference Short Papers, pages 194– 199, Uppsala, Sweden, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joao V Graca</author>
<author>Lf Inesc-id</author>
<author>Kuzman Ganchev</author>
<author>Ben Taskar</author>
</authors>
<title>Expectation maximization and posterior constraints.</title>
<date>2007</date>
<booktitle>In Advances in IIPS,</booktitle>
<pages>569--576</pages>
<contexts>
<context position="4884" citStr="Graca et al., 2007" startWordPosition="759" endWordPosition="762">ario, since the labeled training data and the parallel text in our case are completely separated. What is more important is that most studies on bilingual text parsing assumed that the parser is applied only on bilingual text. But our goal is to develop a parser that can be used in completely monolingual setting for each target language of interest. This scenario is applicable to a large set of languages and many research studies (Hwa et al., 2005) have been made on it. Ganchev et al. (2009) presented a parser projection approach via parallel text using the posterior regularization framework (Graca et al., 2007). McDonald et al. (2011) proposed two parser transfer approaches between two different languages — one is directly transferred parser from delexicalized parsers, and the other parser is transferred using constraint driven learning algorithm where constraints are drawn from parallel corpora. In that work, they demonstrate that even the directly transferred delexicalized parser produces significantly higher accuracies than unsupervised parsers. Cohen et al. (2011) proposed an approach for unsupervised dependency parsing with non-parallel multilingual guidance from one or more helper languages, i</context>
</contexts>
<marker>Graca, Inesc-id, Ganchev, Taskar, 2007</marker>
<rawString>Joao V. Graca, Lf Inesc-id, Kuzman Ganchev, and Ben Taskar. 2007. Expectation maximization and posterior constraints. In Advances in IIPS, pages 569– 576.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Grandvalet</author>
<author>Yoshua Bengio</author>
</authors>
<title>Semisupervised learning by entropy minimization.</title>
<date>2004</date>
<booktitle>In Advances in Ieural Information Processing Systems.</booktitle>
<contexts>
<context position="13627" citStr="Grandvalet and Bengio, 2004" startWordPosition="2221" endWordPosition="2224"> the normalizing factor ˜Z(x), the transferring distribution is a valid one. We introduce a multiplier γ as a trade-off between the two contributions (parallel and unsupervised) of the objective function K, and the final objective function K′ has the following form: K′ = − X X ˜p(yi|xi) log pλ(yi|xi) xiEP yi X + γ xiEU = KP + γKU (11) KP and KU are the contributions of the parallel and unsupervised data, respectively. One may regard γ as a Lagrange multiplier that is used to constrain the parser’s uncertainty H to be low, as presented in several studies on entropy regularization (Brand, 1998; Grandvalet and Bengio, 2004; Jiao et al., 2006). 2.3 Algorithms and Complexity for Model Training To train our parsing model, we need to find out the parameters λ that minimize the objective function K′ in equation (11). This optimization problem is typically solved using quasi-Newton numerical methods such as L-BFGS (Nash and Nocedal, 1991), which requires efficient calculation of the objective function and the gradient of the objective function. The first item (KP) of the K′ function in equation (11) can be rewritten in the following form: XKP = − [X ˜p(yi|xi) X log w(e, xi) xiEP yi eEyi − log Z(xi)] (12) and accordin</context>
</contexts>
<marker>Grandvalet, Bengio, 2004</marker>
<rawString>Yves Grandvalet and Yoshua Bengio. 2004. Semisupervised learning by entropy minimization. In Advances in Ieural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Wenbin Jiang</author>
<author>Qun Liu</author>
</authors>
<title>Bilingually-constrained (monolingual) shift-reduce parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of EMILP-2009,</booktitle>
<pages>1222--1231</pages>
<location>Singapore,</location>
<marker>Huang, Jiang, Liu, 2009</marker>
<rawString>Liang Huang, Wenbin Jiang, and Qun Liu. 2009. Bilingually-constrained (monolingual) shift-reduce parsing. In Proceedings of EMILP-2009, pages 1222–1231, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Hwa</author>
<author>Philip Resnik</author>
<author>Amy Weinberg</author>
<author>Clara Cabezas</author>
<author>Okan Kolak</author>
</authors>
<title>Bootstrapping parsers via syntactic projection across parallel texts. Iatural Language Engineering,</title>
<date>2005</date>
<pages>11--11</pages>
<contexts>
<context position="4717" citStr="Hwa et al., 2005" startWordPosition="731" endWordPosition="734">or Computational Linguistics al., 2009; Chen et al., 2010). Obviously, bilingual treebanks are much more difficult to acquire than the resources required in our scenario, since the labeled training data and the parallel text in our case are completely separated. What is more important is that most studies on bilingual text parsing assumed that the parser is applied only on bilingual text. But our goal is to develop a parser that can be used in completely monolingual setting for each target language of interest. This scenario is applicable to a large set of languages and many research studies (Hwa et al., 2005) have been made on it. Ganchev et al. (2009) presented a parser projection approach via parallel text using the posterior regularization framework (Graca et al., 2007). McDonald et al. (2011) proposed two parser transfer approaches between two different languages — one is directly transferred parser from delexicalized parsers, and the other parser is transferred using constraint driven learning algorithm where constraints are drawn from parallel corpora. In that work, they demonstrate that even the directly transferred delexicalized parser produces significantly higher accuracies than unsuperv</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Cabezas, Kolak, 2005</marker>
<rawString>Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara Cabezas, and Okan Kolak. 2005. Bootstrapping parsers via syntactic projection across parallel texts. Iatural Language Engineering, 11:11–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Feng Jiao</author>
<author>Shaojun Wang</author>
<author>Chi-Hoon Lee</author>
<author>Russell Greiner</author>
<author>Dale Schuurmans</author>
</authors>
<title>Semisupervised conditional random fields for improved sequence segmentation and labeling.</title>
<date>2006</date>
<booktitle>In Proceedings of COLIIG/ACL-2006,</booktitle>
<pages>209--216</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="9640" citStr="Jiao et al., 2006" startWordPosition="1525" endWordPosition="1528"> � log pλ(yi|xi) (6) i Maximum likelihood training chooses parameters such that the log-likelihood L(λ) is maximized. However, in our scenario we have no labeled training data for target languages but we have some parallel and unlabeled data plus an English dependency parser. For the purpose of transferring cross-lingual information from the English parser via parallel text, we explore the model training method proposed by Smith and Eisner (2007), which presented a generalization of K function (Abney, 2004), and related it to another semi-supervised learning technique, entropy regularization (Jiao et al., 2006; Mann and McCallum, 2007). The objective K function to be minimized is actually the expected negative loglikelihood: K = − � E ˜p(yi|xi) log pλ(yi|xi) i yi �= D(˜pi||pλ,i) + H(˜pi) (7) i 1 pλ(y|x) = Z(x) rl w(e, x) (5) e∈y where ˜pi(·) def= ˜p(·|xi) and pλ,i(·) def= pλ(·|xi). ˜p(y|x) is the “transferring distribution” that reflects our uncertainty about the true labels, and we are trying to learn a parametric model pλ(y|x) by minimizing the K function. In our scenario, we have a set of aligned parallel data P = {xsi, xti, ai} where ai is the word alignment for the pair of source-target senten</context>
<context position="11089" citStr="Jiao et al., 2006" startWordPosition="1788" endWordPosition="1791">arallel data set P or unlabeled data set U. For the unlabeled examples {xi ∈ U}, some previous studies (e.g., (Abney, 2004)) simply use a uniform distribution over labels (e.g., parses), to reflect that the label is unknown. We follow the method in Smith and Eisner (2007) and take the transferring distribution ˜pi to be the actual current belief pλ,i. The total contribution of the unsupervised examples to K then simplifies to KU = E H(pλ,i), which may xi∈U be regarded as the entropy item used to constrain the model’s uncertainty H to be low, as presented in the work on entropy regularization (Jiao et al., 2006; Mann and McCallum, 2007). But how can we define the transferring distribution for the parallel examples {xti ∈ P}? We define the transferring distribution by defining the transferring weight utilizing the English parsing model pλE(y|x) via parallel data with word alignments: � ˜w(et, xt i), i) = wE(es,xs if et align −→ es wE(etdelex,xsi), otherwise (8) where wE(·, ·) is the weight function of the English parsing model pλE(y|x), and etdelex is the delexicalized form2 of the edge et. From the definition of the transferring weight, we can see that, if an edge et of the target language sentence </context>
<context position="13647" citStr="Jiao et al., 2006" startWordPosition="2225" endWordPosition="2228">, the transferring distribution is a valid one. We introduce a multiplier γ as a trade-off between the two contributions (parallel and unsupervised) of the objective function K, and the final objective function K′ has the following form: K′ = − X X ˜p(yi|xi) log pλ(yi|xi) xiEP yi X + γ xiEU = KP + γKU (11) KP and KU are the contributions of the parallel and unsupervised data, respectively. One may regard γ as a Lagrange multiplier that is used to constrain the parser’s uncertainty H to be low, as presented in several studies on entropy regularization (Brand, 1998; Grandvalet and Bengio, 2004; Jiao et al., 2006). 2.3 Algorithms and Complexity for Model Training To train our parsing model, we need to find out the parameters λ that minimize the objective function K′ in equation (11). This optimization problem is typically solved using quasi-Newton numerical methods such as L-BFGS (Nash and Nocedal, 1991), which requires efficient calculation of the objective function and the gradient of the objective function. The first item (KP) of the K′ function in equation (11) can be rewritten in the following form: XKP = − [X ˜p(yi|xi) X log w(e, xi) xiEP yi eEyi − log Z(xi)] (12) and according to equation (1) an</context>
<context position="16644" citStr="Jiao et al., 2006" startWordPosition="2705" endWordPosition="2708">12 1,219/20,376 Table 1: Data statistics of two versions of Google Universal Treebanks for the target languages. Similar with the calculation of KP, KU can also be computed by running the inside-outside algorithm (Baker, 1979; Paskin, 2001) for projective parsing. For the gradient of KU, both the two multipliers of the second item in equation (15) can be computed using the same inside-outside algorithm. For the first item in equation (15), an O(n3) dynamic programming algorithm that is closely related to the forward-backward algorithm (Mann and McCallum, 2007) for the entropy regularized CRF (Jiao et al., 2006) can be used for projective parsing. For non-projective parsing, however, the runtime rises to O(n4). In this paper, we focus on projective parsing. 2.4 Summary of Our Approach To summarize the description in the previous sections, our approach is performed in the following steps: 1. Train an English parsing model pλE(y|x), which is used to estimate the transferring distribution ˜p(y|x). 2. Prepare parallel text by running word alignment method to obtain word alignments,3 and prepare the unlabeled data. 3. Train a parsing model for the target language by minimizing the objective K′ function wh</context>
</contexts>
<marker>Jiao, Wang, Lee, Greiner, Schuurmans, 2006</marker>
<rawString>Feng Jiao, Shaojun Wang, Chi-Hoon Lee, Russell Greiner, and Dale Schuurmans. 2006. Semisupervised conditional random fields for improved sequence segmentation and labeling. In Proceedings of COLIIG/ACL-2006, pages 209–216, Sydney, Australia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Katz-Brown</author>
<author>Slav Petrov</author>
<author>Ryan McDonald</author>
<author>Franz Och</author>
<author>David Talbot</author>
<author>Hiroshi Ichikawa</author>
<author>Masakazu Seno</author>
<author>Hideto Kazawa</author>
</authors>
<title>Training a parser for machine translation reordering.</title>
<date>2011</date>
<booktitle>In Proceedings of EMILP-2011,</booktitle>
<pages>183--192</pages>
<location>Edinburgh, Scotland, UK.,</location>
<contexts>
<context position="1341" citStr="Katz-Brown et al., 2011" startWordPosition="194" endWordPosition="197">resource-poor languages. We perform experiments on three Data sets — Version 1.0 and version 2.0 of Google Universal Dependency Treebanks and Treebanks from CoNLL shared-tasks, across ten languages. We obtain stateof-the art performance of all the three data sets when compared with previously studied unsupervised and projected parsing systems. 1 Introduction In recent years, dependency parsing has gained universal interest due to its usefulness in a wide range of applications such as synonym generation (Shinyama et al., 2002), relation extraction (Nguyen et al., 2009) and machine translation (Katz-Brown et al., 2011; Xie et al., 2011). Several supervised dependency parsing algorithms (Nivre and Scholz, 2004; McDonald et al., 2005a; McDonald et al., 2005b; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Ma and Zhao, 2012; Zhang et al., 2013) have been proposed and achieved high parsing accuracies on several treebanks, due in large part to the availability of dependency treebanks in a number of languages (McDonald et al., 2013). Fei Xia Department of Linguistics University of Washington Seattle, WA 98195, USA fxia@uw.edu However, the manually annotated treebanks that these parsers rely o</context>
</contexts>
<marker>Katz-Brown, Petrov, McDonald, Och, Talbot, Ichikawa, Seno, Kazawa, 2011</marker>
<rawString>Jason Katz-Brown, Slav Petrov, Ryan McDonald, Franz Och, David Talbot, Hiroshi Ichikawa, Masakazu Seno, and Hideto Kazawa. 2011. Training a parser for machine translation reordering. In Proceedings of EMILP-2011, pages 183–192, Edinburgh, Scotland, UK., July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher Manning</author>
</authors>
<title>Corpusbased induction of syntactic structure: Models of dependency and constituency.</title>
<date>2004</date>
<booktitle>In Proceedings ofACL2004,</booktitle>
<pages>478--485</pages>
<location>Barcelona, Spain,</location>
<contexts>
<context position="2174" citStr="Klein and Manning, 2004" startWordPosition="326" endWordPosition="329">Ma and Zhao, 2012; Zhang et al., 2013) have been proposed and achieved high parsing accuracies on several treebanks, due in large part to the availability of dependency treebanks in a number of languages (McDonald et al., 2013). Fei Xia Department of Linguistics University of Washington Seattle, WA 98195, USA fxia@uw.edu However, the manually annotated treebanks that these parsers rely on are highly expensive to create, in particular when we want to build treebanks for resource-poor languages. This led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eisner, 2005; Cohen and Smith, 2009; Spitkovsky et al., 2010; Blunsom and Cohn, 2010; Mareˇcek and Straka, 2013; Spitkovsky et al., 2013), which appears to be a natural solution to this problem, as unsupervised methods require only unannotated text for training parsers. Unfortunately, the unsupervised grammar induction systems’ parsing accuracies often significantly fall behind those of supervised systems (McDonald et al., 2011). Furthermore, from a practical standpoint, it is rarely the case that we are completely devoid of resources for most languages. In this paper, we consider </context>
<context position="31231" citStr="Klein and Manning, 2004" startWordPosition="5109" endWordPosition="5112">4 45.9 46.8 48.2 50.0 50.1 87.1 de 18.0 47.2 46.0 50.9 52.4 57.3 87.0 el 39.9 63.9 62.9 66.8 65.3 67.4 82.3 es 28.5 53.3 54.4 55.8 59.9 60.3 83.6 it 43.1 57.7 59.9 60.8 63.4 64.0 83.9 nl 38.5 60.8 60.7 67.8 66.5 68.2 78.2 pt 20.1 69.2 71.1 71.3 74.8 75.1 87.2 sv 44.0 58.3 60.3 61.3 62.8 66.7 88.0 Ave 33.2 57.0 57.8 60.4 61.9 63.6 84.7 Table 6: Parsing results on treebanks from CoNLL shared tasks for eight target languages. The results of unsupervised DMV model are from Table 1 of McDonald et al. (2011). to those five baseline systems and the oracle (OR). The results of unsupervised DMV model (Klein and Manning, 2004) are from Table 1 of McDonald et al. (2011). Our approach outperforms all these baseline systems and achieves state-of-theart performance on all the eight languages. In order to compare with more previous methods, we also report parsing performance on sentences of length 10 or less after punctuation has been removed. Table 7 shows the results of our system and the results of baseline systems. “USR†” is the weakly supervised system of Naseem et al. (2010). “PGI” is the phylogenetic grammar induction model of Berg-Kirkpatrick and Klein (2010). Both the results of the two systems are cited from T</context>
</contexts>
<marker>Klein, Manning, 2004</marker>
<rawString>Dan Klein and Christopher Manning. 2004. Corpusbased induction of syntactic structure: Models of dependency and constituency. In Proceedings ofACL2004, pages 478–485, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A Parallel Corpus for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Conference Proceedings: the tenth Machine Translation Summit,</booktitle>
<pages>79--86</pages>
<location>Phuket, Thailand. AAMT, AAMT.</location>
<contexts>
<context position="18955" citStr="Koehn, 2005" startWordPosition="3073" endWordPosition="3074">s used to train the English parsing model, and the Treebanks for target languages are used to evaluate the parsing performance of our approach. (ii) Large amounts of parallel text with English on one side. We select target languages based on the availability of these resources. The monolingual treebanks in our experiments are from the Google Universal Dependency Treebanks (McDonald et al., 2013), for the reason that the treebanks of different languages in Google Universal Dependency Treebanks have consistent syntactic representations. The parallel data come from the Europarl corpus version 7 (Koehn, 2005) and Kaist Corpus4. Taking the intersection of languages in the two kinds of resources yields the following seven languages: French, German, Italian, Korean, Portuguese, Spanish and Swedish. The treebanks from CoNLL shared-tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007) appear to be another reasonable choice. However, previous studies (McDonald et al., 2011; McDonald et al., 2013) have demonstrated that a homogeneous representation is critical for multilingual language technologies that require consistent cross-lingual analysis for downstream components, and the hete</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A Parallel Corpus for Statistical Machine Translation. In Conference Proceedings: the tenth Machine Translation Summit, pages 79–86, Phuket, Thailand. AAMT, AAMT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Michael Collins</author>
</authors>
<title>Efficient thirdorder dependency parsers.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL2010,</booktitle>
<pages>1--11</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="1549" citStr="Koo and Collins, 2010" startWordPosition="226" endWordPosition="229">tateof-the art performance of all the three data sets when compared with previously studied unsupervised and projected parsing systems. 1 Introduction In recent years, dependency parsing has gained universal interest due to its usefulness in a wide range of applications such as synonym generation (Shinyama et al., 2002), relation extraction (Nguyen et al., 2009) and machine translation (Katz-Brown et al., 2011; Xie et al., 2011). Several supervised dependency parsing algorithms (Nivre and Scholz, 2004; McDonald et al., 2005a; McDonald et al., 2005b; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Ma and Zhao, 2012; Zhang et al., 2013) have been proposed and achieved high parsing accuracies on several treebanks, due in large part to the availability of dependency treebanks in a number of languages (McDonald et al., 2013). Fei Xia Department of Linguistics University of Washington Seattle, WA 98195, USA fxia@uw.edu However, the manually annotated treebanks that these parsers rely on are highly expensive to create, in particular when we want to build treebanks for resource-poor languages. This led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992</context>
<context position="34704" citStr="Koo and Collins, 2010" startWordPosition="5722" endWordPosition="5725"> the computation of KU and its gradient is O(n3), even for non-projective case. 4.5.2 Higher-Order Models for Projective Parsing Our learning framework can be extended to higher-order dependency parsing models. For example, if we want to make our model capable of utilizing more contextual information, we can extend our transferring weight to higher-order parts: � V t wE (ps, xi ), if pt align−→ps ˜w(p , xi) = wE(ptdelex, xs i), otherwise (17) where p is a small part of tree y that has limited interactions. For projective parsing, several algorithms (McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Ma and Zhao, 2012) have been proposed to solve the model training problems (calculation of objective function and gradient) for different factorizations. 4.5.3 IGT Data One possible direction to improve our approach is to replace parallel text with Interlinear Glossed Text (IGT) (Lewis and Xia, 2010), which is a semi-structured data type encoding more syntactic information than parallel data. By using IGT Data, not only can we obtain more accurate word alignments, but also extract useful cross-lingual information for the resource-poor language. 5 Conclusion In this paper, we propose an unsup</context>
</contexts>
<marker>Koo, Collins, 2010</marker>
<rawString>Terry Koo and Michael Collins. 2010. Efficient thirdorder dependency parsers. In Proceedings of ACL2010, pages 1–11, Uppsala, Sweden, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Amir Globerson</author>
<author>Xavier Carreras</author>
<author>Michael Collins</author>
</authors>
<title>Structured predicition models via the matrix-tree theorem.</title>
<date>2007</date>
<booktitle>In Proceedings of EMILP-COILL</booktitle>
<pages>141--150</pages>
<location>Prague, Czech,</location>
<contexts>
<context position="14844" citStr="Koo et al., 2007" startWordPosition="2429" endWordPosition="2432"> to equation (1) and (3) the gradient of KP can be written as: ∂˜p(yi|xi) log pλ(yi|xi) ∂λj X �X X = ˜p(yi|xi) fj(e,xi) xiEP yi eEyi �fj(e, xi) (13) According to equation (9), ˜p(y|x) can also be factored into the multiplication of the weight of each edge, so both KP and its gradient can be calculated by running the O(n3) inside-outside algorithm (Baker, 1979; Paskin, 2001) for projective parsing. For non-projective parsing, the analogy to the inside algorithm is the O(n3) matrixtree algorithm based on Kirchhoff’s Matrix-Tree Theorem, which is dominated asymptotically by a matrix determinant (Koo et al., 2007; Smith and Smith, 2007). The gradient of a determinant may be computed by matrix inversion, so evaluating the gradient again has the same O(n3) complexity as evaluating the function. The second item (KU) of the K′ function in equation (11) is the Shannon entropy of the posterior distribution over parsing trees, and can be written into the following form: XKU = − [X pλ(yi|xi) X log w(e, xi) xiEU yi eEyi − log Z(xi)] (14) and the gradient of KU is in the following: ∂KU X= ∂pλ(yi|xi) log pλ(yi|xi) xiEU ∂λj ∂λj X= − pλ(yi|xi) log pλ(yi|xi)Fj(yi, xi) yi (X ) + pλ(yi|xi)log pλ(yi|xi) yi (X ) · pλ(y</context>
</contexts>
<marker>Koo, Globerson, Carreras, Collins, 2007</marker>
<rawString>Terry Koo, Amir Globerson, Xavier Carreras, and Michael Collins. 2007. Structured predicition models via the matrix-tree theorem. In Proceedings of EMILP-COILL 2007, pages 141–150, Prague, Czech, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William D Lewis</author>
<author>Fei Xia</author>
</authors>
<title>Developing odin: A multilingual repository of annotated language data for hundreds of the world’s languages.</title>
<date>2010</date>
<journal>LLC,</journal>
<volume>25</volume>
<issue>3</issue>
<contexts>
<context position="35007" citStr="Lewis and Xia, 2010" startWordPosition="5768" endWordPosition="5771">e can extend our transferring weight to higher-order parts: � V t wE (ps, xi ), if pt align−→ps ˜w(p , xi) = wE(ptdelex, xs i), otherwise (17) where p is a small part of tree y that has limited interactions. For projective parsing, several algorithms (McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Ma and Zhao, 2012) have been proposed to solve the model training problems (calculation of objective function and gradient) for different factorizations. 4.5.3 IGT Data One possible direction to improve our approach is to replace parallel text with Interlinear Glossed Text (IGT) (Lewis and Xia, 2010), which is a semi-structured data type encoding more syntactic information than parallel data. By using IGT Data, not only can we obtain more accurate word alignments, but also extract useful cross-lingual information for the resource-poor language. 5 Conclusion In this paper, we propose an unsupervised projective dependency parsing approach for resourcepoor languages, using existing resources from a resource-rich source language. By presenting a model training framework, our approach can utilize parallel text to estimate transferring distribution with the help of a well-developed resourcerich</context>
</contexts>
<marker>Lewis, Xia, 2010</marker>
<rawString>William D. Lewis and Fei Xia. 2010. Developing odin: A multilingual repository of annotated language data for hundreds of the world’s languages. LLC, 25(3):303–319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xuezhe Ma</author>
<author>Hai Zhao</author>
</authors>
<title>Fourth-order dependency parsing.</title>
<date>2012</date>
<booktitle>In Proceedings of COLIIG 2012: Posters,</booktitle>
<pages>785--796</pages>
<location>Mumbai, India,</location>
<contexts>
<context position="1568" citStr="Ma and Zhao, 2012" startWordPosition="230" endWordPosition="233">nce of all the three data sets when compared with previously studied unsupervised and projected parsing systems. 1 Introduction In recent years, dependency parsing has gained universal interest due to its usefulness in a wide range of applications such as synonym generation (Shinyama et al., 2002), relation extraction (Nguyen et al., 2009) and machine translation (Katz-Brown et al., 2011; Xie et al., 2011). Several supervised dependency parsing algorithms (Nivre and Scholz, 2004; McDonald et al., 2005a; McDonald et al., 2005b; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Ma and Zhao, 2012; Zhang et al., 2013) have been proposed and achieved high parsing accuracies on several treebanks, due in large part to the availability of dependency treebanks in a number of languages (McDonald et al., 2013). Fei Xia Department of Linguistics University of Washington Seattle, WA 98195, USA fxia@uw.edu However, the manually annotated treebanks that these parsers rely on are highly expensive to create, in particular when we want to build treebanks for resource-poor languages. This led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning</context>
<context position="34724" citStr="Ma and Zhao, 2012" startWordPosition="5726" endWordPosition="5729">and its gradient is O(n3), even for non-projective case. 4.5.2 Higher-Order Models for Projective Parsing Our learning framework can be extended to higher-order dependency parsing models. For example, if we want to make our model capable of utilizing more contextual information, we can extend our transferring weight to higher-order parts: � V t wE (ps, xi ), if pt align−→ps ˜w(p , xi) = wE(ptdelex, xs i), otherwise (17) where p is a small part of tree y that has limited interactions. For projective parsing, several algorithms (McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Ma and Zhao, 2012) have been proposed to solve the model training problems (calculation of objective function and gradient) for different factorizations. 4.5.3 IGT Data One possible direction to improve our approach is to replace parallel text with Interlinear Glossed Text (IGT) (Lewis and Xia, 2010), which is a semi-structured data type encoding more syntactic information than parallel data. By using IGT Data, not only can we obtain more accurate word alignments, but also extract useful cross-lingual information for the resource-poor language. 5 Conclusion In this paper, we propose an unsupervised projective d</context>
</contexts>
<marker>Ma, Zhao, 2012</marker>
<rawString>Xuezhe Ma and Hai Zhao. 2012. Fourth-order dependency parsing. In Proceedings of COLIIG 2012: Posters, pages 785–796, Mumbai, India, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gideon S Mann</author>
<author>Andrew McCallum</author>
</authors>
<title>Efficient computation of entropy gradient for semisupervised conditional random fields.</title>
<date>2007</date>
<booktitle>In Proceedings ofIAACL/HLT-2007,</booktitle>
<pages>109--112</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="9666" citStr="Mann and McCallum, 2007" startWordPosition="1529" endWordPosition="1533">) i Maximum likelihood training chooses parameters such that the log-likelihood L(λ) is maximized. However, in our scenario we have no labeled training data for target languages but we have some parallel and unlabeled data plus an English dependency parser. For the purpose of transferring cross-lingual information from the English parser via parallel text, we explore the model training method proposed by Smith and Eisner (2007), which presented a generalization of K function (Abney, 2004), and related it to another semi-supervised learning technique, entropy regularization (Jiao et al., 2006; Mann and McCallum, 2007). The objective K function to be minimized is actually the expected negative loglikelihood: K = − � E ˜p(yi|xi) log pλ(yi|xi) i yi �= D(˜pi||pλ,i) + H(˜pi) (7) i 1 pλ(y|x) = Z(x) rl w(e, x) (5) e∈y where ˜pi(·) def= ˜p(·|xi) and pλ,i(·) def= pλ(·|xi). ˜p(y|x) is the “transferring distribution” that reflects our uncertainty about the true labels, and we are trying to learn a parametric model pλ(y|x) by minimizing the K function. In our scenario, we have a set of aligned parallel data P = {xsi, xti, ai} where ai is the word alignment for the pair of source-target sentences (xsi, xti), and a set </context>
<context position="11115" citStr="Mann and McCallum, 2007" startWordPosition="1792" endWordPosition="1795">or unlabeled data set U. For the unlabeled examples {xi ∈ U}, some previous studies (e.g., (Abney, 2004)) simply use a uniform distribution over labels (e.g., parses), to reflect that the label is unknown. We follow the method in Smith and Eisner (2007) and take the transferring distribution ˜pi to be the actual current belief pλ,i. The total contribution of the unsupervised examples to K then simplifies to KU = E H(pλ,i), which may xi∈U be regarded as the entropy item used to constrain the model’s uncertainty H to be low, as presented in the work on entropy regularization (Jiao et al., 2006; Mann and McCallum, 2007). But how can we define the transferring distribution for the parallel examples {xti ∈ P}? We define the transferring distribution by defining the transferring weight utilizing the English parsing model pλE(y|x) via parallel data with word alignments: � ˜w(et, xt i), i) = wE(es,xs if et align −→ es wE(etdelex,xsi), otherwise (8) where wE(·, ·) is the weight function of the English parsing model pλE(y|x), and etdelex is the delexicalized form2 of the edge et. From the definition of the transferring weight, we can see that, if an edge et of the target language sentence xti is aligned to an edge </context>
<context position="16592" citStr="Mann and McCallum, 2007" startWordPosition="2696" endWordPosition="2699">/23,9012 1,200/29,873 1,198/29,438 sv 4,447/66,631 493/9,312 1,219/20,376 Table 1: Data statistics of two versions of Google Universal Treebanks for the target languages. Similar with the calculation of KP, KU can also be computed by running the inside-outside algorithm (Baker, 1979; Paskin, 2001) for projective parsing. For the gradient of KU, both the two multipliers of the second item in equation (15) can be computed using the same inside-outside algorithm. For the first item in equation (15), an O(n3) dynamic programming algorithm that is closely related to the forward-backward algorithm (Mann and McCallum, 2007) for the entropy regularized CRF (Jiao et al., 2006) can be used for projective parsing. For non-projective parsing, however, the runtime rises to O(n4). In this paper, we focus on projective parsing. 2.4 Summary of Our Approach To summarize the description in the previous sections, our approach is performed in the following steps: 1. Train an English parsing model pλE(y|x), which is used to estimate the transferring distribution ˜p(y|x). 2. Prepare parallel text by running word alignment method to obtain word alignments,3 and prepare the unlabeled data. 3. Train a parsing model for the target</context>
</contexts>
<marker>Mann, McCallum, 2007</marker>
<rawString>Gideon S. Mann and Andrew McCallum. 2007. Efficient computation of entropy gradient for semisupervised conditional random fields. In Proceedings ofIAACL/HLT-2007, pages 109–112, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Mareˇcek</author>
<author>Milan Straka</author>
</authors>
<title>Stopprobability estimates computed on a large corpus improve unsupervised dependency parsing.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL-2013,</booktitle>
<pages>281--290</pages>
<location>Sofia, Bulgaria,</location>
<marker>Mareˇcek, Straka, 2013</marker>
<rawString>David Mareˇcek and Milan Straka. 2013. Stopprobability estimates computed on a large corpus improve unsupervised dependency parsing. In Proceedings of ACL-2013, pages 281–290, Sofia, Bulgaria, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Online learning of approximate dependency parsing algorithms.</title>
<date>2006</date>
<booktitle>In Proceedings ofEACL-2006,</booktitle>
<pages>81--88</pages>
<location>Trento, Italy,</location>
<contexts>
<context position="1510" citStr="McDonald and Pereira, 2006" startWordPosition="219" endWordPosition="223">red-tasks, across ten languages. We obtain stateof-the art performance of all the three data sets when compared with previously studied unsupervised and projected parsing systems. 1 Introduction In recent years, dependency parsing has gained universal interest due to its usefulness in a wide range of applications such as synonym generation (Shinyama et al., 2002), relation extraction (Nguyen et al., 2009) and machine translation (Katz-Brown et al., 2011; Xie et al., 2011). Several supervised dependency parsing algorithms (Nivre and Scholz, 2004; McDonald et al., 2005a; McDonald et al., 2005b; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Ma and Zhao, 2012; Zhang et al., 2013) have been proposed and achieved high parsing accuracies on several treebanks, due in large part to the availability of dependency treebanks in a number of languages (McDonald et al., 2013). Fei Xia Department of Linguistics University of Washington Seattle, WA 98195, USA fxia@uw.edu However, the manually annotated treebanks that these parsers rely on are highly expensive to create, in particular when we want to build treebanks for resource-poor languages. This led to a vast amount of research on unsupervised gramma</context>
<context position="34665" citStr="McDonald and Pereira, 2006" startWordPosition="5716" endWordPosition="5719">) Rα (p) = 1 − αlog E y With R´enyi entropy, the computation of KU and its gradient is O(n3), even for non-projective case. 4.5.2 Higher-Order Models for Projective Parsing Our learning framework can be extended to higher-order dependency parsing models. For example, if we want to make our model capable of utilizing more contextual information, we can extend our transferring weight to higher-order parts: � V t wE (ps, xi ), if pt align−→ps ˜w(p , xi) = wE(ptdelex, xs i), otherwise (17) where p is a small part of tree y that has limited interactions. For projective parsing, several algorithms (McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Ma and Zhao, 2012) have been proposed to solve the model training problems (calculation of objective function and gradient) for different factorizations. 4.5.3 IGT Data One possible direction to improve our approach is to replace parallel text with Interlinear Glossed Text (IGT) (Lewis and Xia, 2010), which is a semi-structured data type encoding more syntactic information than parallel data. By using IGT Data, not only can we obtain more accurate word alignments, but also extract useful cross-lingual information for the resource-poor language. 5 Conclu</context>
</contexts>
<marker>McDonald, Pereira, 2006</marker>
<rawString>Ryan McDonald and Fernando Pereira. 2006. Online learning of approximate dependency parsing algorithms. In Proceedings ofEACL-2006, pages 81–88, Trento, Italy, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL-2005,</booktitle>
<pages>91--98</pages>
<location>Ann Arbor, Michigan, USA,</location>
<contexts>
<context position="1457" citStr="McDonald et al., 2005" startWordPosition="211" endWordPosition="214">ependency Treebanks and Treebanks from CoNLL shared-tasks, across ten languages. We obtain stateof-the art performance of all the three data sets when compared with previously studied unsupervised and projected parsing systems. 1 Introduction In recent years, dependency parsing has gained universal interest due to its usefulness in a wide range of applications such as synonym generation (Shinyama et al., 2002), relation extraction (Nguyen et al., 2009) and machine translation (Katz-Brown et al., 2011; Xie et al., 2011). Several supervised dependency parsing algorithms (Nivre and Scholz, 2004; McDonald et al., 2005a; McDonald et al., 2005b; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Ma and Zhao, 2012; Zhang et al., 2013) have been proposed and achieved high parsing accuracies on several treebanks, due in large part to the availability of dependency treebanks in a number of languages (McDonald et al., 2013). Fei Xia Department of Linguistics University of Washington Seattle, WA 98195, USA fxia@uw.edu However, the manually annotated treebanks that these parsers rely on are highly expensive to create, in particular when we want to build treebanks for resource-poor languages. This le</context>
<context position="27037" citStr="McDonald et al., 2005" startWordPosition="4413" endWordPosition="4416">ing performance, we run experiments on the following systems: DTP: The direct transfer parser (DTP) proposed by McDonald et al. (2011), who train a delexicalized parser on English labeled training data with no lexical features, then apply this parser to parse target languages directly. It is based on the transition-based dependency parsing paradigm (Nivre, 2008). We directly cite the results reported in McDonald et al. (2013). In addition to their original results, we also report results by reimplementing the direct transfer parser based on the first-order projective dependency parsing model (McDonald et al., 2005a) (DTP†). PTP The projected transfer parser (PTP) described in McDonald et al. (2011). The results of the projected transfer parser reimplemented by us is marked as “PTP†”. -U: Our approach training on only parallel data without unlabeled data for the target language. The parallel data set for each language contains 20,000 sentences. +U: Our approach training on both parallel and unlabeled data. The parallel data sets are the ones contains 20,000 sentences. OR: the supervised first-order projective dependency parsing model (McDonald et al., 2005a), trained on the original treebanks with maxim</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>Ryan McDonald, Koby Crammer, and Fernando Pereira. 2005a. Online large-margin training of dependency parsers. In Proceedings of ACL-2005, pages 91–98, Ann Arbor, Michigan, USA, June 25-30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajic</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMILP-2005,</booktitle>
<pages>523--530</pages>
<location>Vancouver, Canada,</location>
<contexts>
<context position="1457" citStr="McDonald et al., 2005" startWordPosition="211" endWordPosition="214">ependency Treebanks and Treebanks from CoNLL shared-tasks, across ten languages. We obtain stateof-the art performance of all the three data sets when compared with previously studied unsupervised and projected parsing systems. 1 Introduction In recent years, dependency parsing has gained universal interest due to its usefulness in a wide range of applications such as synonym generation (Shinyama et al., 2002), relation extraction (Nguyen et al., 2009) and machine translation (Katz-Brown et al., 2011; Xie et al., 2011). Several supervised dependency parsing algorithms (Nivre and Scholz, 2004; McDonald et al., 2005a; McDonald et al., 2005b; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Ma and Zhao, 2012; Zhang et al., 2013) have been proposed and achieved high parsing accuracies on several treebanks, due in large part to the availability of dependency treebanks in a number of languages (McDonald et al., 2013). Fei Xia Department of Linguistics University of Washington Seattle, WA 98195, USA fxia@uw.edu However, the manually annotated treebanks that these parsers rely on are highly expensive to create, in particular when we want to build treebanks for resource-poor languages. This le</context>
<context position="27037" citStr="McDonald et al., 2005" startWordPosition="4413" endWordPosition="4416">ing performance, we run experiments on the following systems: DTP: The direct transfer parser (DTP) proposed by McDonald et al. (2011), who train a delexicalized parser on English labeled training data with no lexical features, then apply this parser to parse target languages directly. It is based on the transition-based dependency parsing paradigm (Nivre, 2008). We directly cite the results reported in McDonald et al. (2013). In addition to their original results, we also report results by reimplementing the direct transfer parser based on the first-order projective dependency parsing model (McDonald et al., 2005a) (DTP†). PTP The projected transfer parser (PTP) described in McDonald et al. (2011). The results of the projected transfer parser reimplemented by us is marked as “PTP†”. -U: Our approach training on only parallel data without unlabeled data for the target language. The parallel data set for each language contains 20,000 sentences. +U: Our approach training on both parallel and unlabeled data. The parallel data sets are the ones contains 20,000 sentences. OR: the supervised first-order projective dependency parsing model (McDonald et al., 2005a), trained on the original treebanks with maxim</context>
</contexts>
<marker>McDonald, Pereira, Ribarov, Hajic, 2005</marker>
<rawString>Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajic. 2005b. Non-projective dependency parsing using spanning tree algorithms. In Proceedings of HLT/EMILP-2005, pages 523–530, Vancouver, Canada, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Slav Petrov</author>
<author>Keith Hall</author>
</authors>
<title>Multi-source transfer of delexicalized dependency parsers.</title>
<date>2011</date>
<booktitle>In Proceedings ofEMILP-2011,</booktitle>
<pages>62--72</pages>
<location>Edinburgh, Scotland, UK.,</location>
<contexts>
<context position="2618" citStr="McDonald et al., 2011" startWordPosition="393" endWordPosition="396"> want to build treebanks for resource-poor languages. This led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eisner, 2005; Cohen and Smith, 2009; Spitkovsky et al., 2010; Blunsom and Cohn, 2010; Mareˇcek and Straka, 2013; Spitkovsky et al., 2013), which appears to be a natural solution to this problem, as unsupervised methods require only unannotated text for training parsers. Unfortunately, the unsupervised grammar induction systems’ parsing accuracies often significantly fall behind those of supervised systems (McDonald et al., 2011). Furthermore, from a practical standpoint, it is rarely the case that we are completely devoid of resources for most languages. In this paper, we consider a practically motivated scenario, in which we want to build statistical parsers for resource-poor target languages, using existing resources from a resource-rich source language (like English).1 We assume that there are absolutely no labeled training data for the target language, but we have access to parallel data with a resource-rich language and a sufficient amount of labeled training data to build an accurate parser for the resource-ric</context>
<context position="4908" citStr="McDonald et al. (2011)" startWordPosition="763" endWordPosition="766">ed training data and the parallel text in our case are completely separated. What is more important is that most studies on bilingual text parsing assumed that the parser is applied only on bilingual text. But our goal is to develop a parser that can be used in completely monolingual setting for each target language of interest. This scenario is applicable to a large set of languages and many research studies (Hwa et al., 2005) have been made on it. Ganchev et al. (2009) presented a parser projection approach via parallel text using the posterior regularization framework (Graca et al., 2007). McDonald et al. (2011) proposed two parser transfer approaches between two different languages — one is directly transferred parser from delexicalized parsers, and the other parser is transferred using constraint driven learning algorithm where constraints are drawn from parallel corpora. In that work, they demonstrate that even the directly transferred delexicalized parser produces significantly higher accuracies than unsupervised parsers. Cohen et al. (2011) proposed an approach for unsupervised dependency parsing with non-parallel multilingual guidance from one or more helper languages, in which parallel data is</context>
<context position="12436" citStr="McDonald et al. (2011)" startWordPosition="2020" endWordPosition="2023">ge es in the English parsing model pλE(y|x). If the edge et is not aligned to any edges of the English sentence xsi, we reduce the edge et to the delexicalized form and calculate the transferring weight in the English parsing model. There are two advan2The delexicalized form of an edge is an edge for which only delexicalized features are considered. 1339 tages for this definition of the transferring weight. First, by transferring the weight function to the corresponding weight in the well-developed English parsing model, we can project syntactic information across language boundaries. Second, McDonald et al. (2011) demonstrates that parsers with only delexicalized features produce considerably high parsing performance. By reducing unaligned edges to their delexicalized forms, we can still use those delexicalized features, such as part-of-speech tags, for those unaligned edges, and can address problem that automatically generated word alignments include errors. From the definition of transferring weight in equation (8), the transferring distribution can be defined in the following way: p(y |x) = ˜ 1 ri w˜ (e, x) (9) Z(x) eEy where X˜Z(x) = ri ˜w(e, x) (10) y eEy Due to the normalizing factor ˜Z(x), the t</context>
<context position="19341" citStr="McDonald et al., 2011" startWordPosition="3129" endWordPosition="3132">cDonald et al., 2013), for the reason that the treebanks of different languages in Google Universal Dependency Treebanks have consistent syntactic representations. The parallel data come from the Europarl corpus version 7 (Koehn, 2005) and Kaist Corpus4. Taking the intersection of languages in the two kinds of resources yields the following seven languages: French, German, Italian, Korean, Portuguese, Spanish and Swedish. The treebanks from CoNLL shared-tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007) appear to be another reasonable choice. However, previous studies (McDonald et al., 2011; McDonald et al., 2013) have demonstrated that a homogeneous representation is critical for multilingual language technologies that require consistent cross-lingual analysis for downstream components, and the heterogenous representations used in CoNLL shared-tasks treebanks weaken any conclusion that can be drawn. 4http://semanticweb.kaist.ac.kr/home/ index.php/Corpus10 1341 DTP DTP† PTP† -U +U OR de 58.50 58.46 69.21 73.72 74.01 78.64 es 68.07 68.72 72.57 75.32 75.60 82.56 fr 70.14 71.13 74.60 76.65 76.93 83.69 ko 42.37 43.57 53.72 59.72 59.94 89.85 sv 70.56 70.59 75.87 78.91 79.27 85.59 Ave</context>
<context position="26550" citStr="McDonald et al. (2011)" startWordPosition="4334" endWordPosition="4337"> to analyze the influence of the amount of parallel data on the parsing performance of our approach. The parallel data sets contain 500, 1000, 2000, 5000, 10000 and 20000 parallel sentences, respectively. We randomly extract parallel sentences from each corpora, and smaller data sets are subsets of larger ones. Table 2 shows the number of tokens in the parallel data used in the experiments. 4.2 System performance and comparison on Google Universal Treebanks For the comparison of parsing performance, we run experiments on the following systems: DTP: The direct transfer parser (DTP) proposed by McDonald et al. (2011), who train a delexicalized parser on English labeled training data with no lexical features, then apply this parser to parse target languages directly. It is based on the transition-based dependency parsing paradigm (Nivre, 2008). We directly cite the results reported in McDonald et al. (2013). In addition to their original results, we also report results by reimplementing the direct transfer parser based on the first-order projective dependency parsing model (McDonald et al., 2005a) (DTP†). PTP The projected transfer parser (PTP) described in McDonald et al. (2011). The results of the projec</context>
<context position="30295" citStr="McDonald et al. (2011)" startWordPosition="4937" endWordPosition="4940">on parsing performance over the parsers without unlabeled data. This proves the effectiveness of the entropy regularization from unlabeled data. 4.4 Experiments on CoNLL Treebanks To make a thorough empirical comparison with previous studies, we also evaluate our system without unlabeled data (-U) on treebanks from CoNLL shared task on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007). To facilitate comparison, we use the same eight IndoEuropean languages as target languages: Danish, Dutch, German, Greek, Italian, Portuguese, Spanish and Swedish, and same experimental setup as McDonald et al. (2011). We report both the results of the direct transfer and projected transfer parsers directly cited from McDonald et al. (2011) (DTP and PTP) and re-implemented by us (DTP†and PTP†). Table 6 gives the results comparing the model without unlabeled data (-U) presented in this work DMV DTP DTP† PTP PTP† -U OR da 33.4 45.9 46.8 48.2 50.0 50.1 87.1 de 18.0 47.2 46.0 50.9 52.4 57.3 87.0 el 39.9 63.9 62.9 66.8 65.3 67.4 82.3 es 28.5 53.3 54.4 55.8 59.9 60.3 83.6 it 43.1 57.7 59.9 60.8 63.4 64.0 83.9 nl 38.5 60.8 60.7 67.8 66.5 68.2 78.2 pt 20.1 69.2 71.1 71.3 74.8 75.1 87.2 sv 44.0 58.3 60.3 61.3 62.8 </context>
<context position="31863" citStr="McDonald et al. (2011)" startWordPosition="5218" endWordPosition="5221">Table 1 of McDonald et al. (2011). Our approach outperforms all these baseline systems and achieves state-of-theart performance on all the eight languages. In order to compare with more previous methods, we also report parsing performance on sentences of length 10 or less after punctuation has been removed. Table 7 shows the results of our system and the results of baseline systems. “USR†” is the weakly supervised system of Naseem et al. (2010). “PGI” is the phylogenetic grammar induction model of Berg-Kirkpatrick and Klein (2010). Both the results of the two systems are cited from Table 4 of McDonald et al. (2011). We also include the results of the unsupervised dependency parsing model with non-parallel multilingual guidance (NMG) proposed by Cohen et al. (2011)8, and “PR” which is the posterior regularization approach presented in Gillenwater et al. (2010). All the results are shown in Table 7. From Table 7, we can see that among the eight target languages, our approach achieves best parsing performance on six languages — Danish, German, Greek, Italian, Portuguese and Swedish. It should be noted that the “NMG” system utilizes more than one helper languages. So it is not directly comparable to our wor</context>
<context position="33470" citStr="McDonald et al. (2011)" startWordPosition="5518" endWordPosition="5521">73.0 74.3 es 58.0 62.3 62.3 66.1 68.3 58.4 62.4 76.7 64.6 it 65.5 66.9 69.9 71.5 47.9 — — — 73.6 nl 67.6 66.0 72.2 72.1 44.0 45.1 37.9 50.7 70.5 pt 77.9 79.2 80.6 82.9 70.9 63.0 47.8 79.8 83.3 sv 70.4 70.2 71.3 70.4 52.6 58.3 42.2 74.0 75.1 Ave 66.6 66.1 69.4 69.8 57.4 — — — 71.1 Table 7: UAS on sentences of length 10 or less without punctuation from CoNLL shared task treebanks. “USR†” is the weakly supervised system of Naseem et al. (2010). “PGI” is the phylogenetic grammar induction model of Berg-Kirkpatrick and Klein (2010). Both the “USR†” and “PGI” systems are implemented and reported by McDonald et al. (2011). “NMG” is the unsupervised dependency parsing model with non-parallel multilingual guidance (Cohen et al., 2011). “PR” is the posterior regularization approach presented in Gillenwater et al. (2010). Some systems’ results for certain target languages are not available as marked by —. 4.5.1 Non-Projective Parsing As mentioned in section 2.3, the runtime to compute KU and its gradient is O(n4). One reasonable speedup, as presented in Smith and Eisner (2007), is to replace Shannon entropy with R´enyi entropy. The R´enyi entropy is parameterized by α: � 1 p(y)α) (16) Rα (p) = 1 − αlog E y With R´</context>
</contexts>
<marker>McDonald, Petrov, Hall, 2011</marker>
<rawString>Ryan McDonald, Slav Petrov, and Keith Hall. 2011. Multi-source transfer of delexicalized dependency parsers. In Proceedings ofEMILP-2011, pages 62– 72, Edinburgh, Scotland, UK., July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Yvonne QuirmbachBrundage, Yoav Goldberg, Dipanjan Das, Kuzman Ganchev, Keith Hall, Slav Petrov, Hao Zhang, Oscar T¨ackstr¨om, Claudia Bedini,</title>
<date>2013</date>
<journal>N´uria Bertomeu Castell´o, and Jungmee</journal>
<booktitle>In Proceedings of ACL-2013,</booktitle>
<pages>92--97</pages>
<location>Sofia, Bulgaria,</location>
<marker>McDonald, Nivre, 2013</marker>
<rawString>Ryan McDonald, Joakim Nivre, Yvonne QuirmbachBrundage, Yoav Goldberg, Dipanjan Das, Kuzman Ganchev, Keith Hall, Slav Petrov, Hao Zhang, Oscar T¨ackstr¨om, Claudia Bedini, N´uria Bertomeu Castell´o, and Jungmee Lee. 2013. Universal dependency annotation for multilingual parsing. In Proceedings of ACL-2013, pages 92–97, Sofia, Bulgaria, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tahira Naseem</author>
<author>Harr Chen</author>
<author>Regina Barzilay</author>
<author>Mark Johnson</author>
</authors>
<title>Using universal linguistic knowledge to guide grammar induction.</title>
<date>2010</date>
<booktitle>In Proceedings of EMILP-2010,</booktitle>
<pages>1234--1244</pages>
<location>Cambridge, MA,</location>
<contexts>
<context position="31689" citStr="Naseem et al. (2010)" startWordPosition="5189" endWordPosition="5192">el are from Table 1 of McDonald et al. (2011). to those five baseline systems and the oracle (OR). The results of unsupervised DMV model (Klein and Manning, 2004) are from Table 1 of McDonald et al. (2011). Our approach outperforms all these baseline systems and achieves state-of-theart performance on all the eight languages. In order to compare with more previous methods, we also report parsing performance on sentences of length 10 or less after punctuation has been removed. Table 7 shows the results of our system and the results of baseline systems. “USR†” is the weakly supervised system of Naseem et al. (2010). “PGI” is the phylogenetic grammar induction model of Berg-Kirkpatrick and Klein (2010). Both the results of the two systems are cited from Table 4 of McDonald et al. (2011). We also include the results of the unsupervised dependency parsing model with non-parallel multilingual guidance (NMG) proposed by Cohen et al. (2011)8, and “PR” which is the posterior regularization approach presented in Gillenwater et al. (2010). All the results are shown in Table 7. From Table 7, we can see that among the eight target languages, our approach achieves best parsing performance on six languages — Danish,</context>
<context position="33292" citStr="Naseem et al. (2010)" startWordPosition="5490" endWordPosition="5493"> et al. (2011) 1344 DTP DTP† PTP PTP† USR† PGI PR NMG -U da 53.2 55.3 57.4 59.8 55.1 41.6 44.0 59.9 60.1 de 65.9 57.9 67.0 63.5 60.0 — — — 67.5 el 73.9 70.8 73.9 72.3 60.3 — — 73.0 74.3 es 58.0 62.3 62.3 66.1 68.3 58.4 62.4 76.7 64.6 it 65.5 66.9 69.9 71.5 47.9 — — — 73.6 nl 67.6 66.0 72.2 72.1 44.0 45.1 37.9 50.7 70.5 pt 77.9 79.2 80.6 82.9 70.9 63.0 47.8 79.8 83.3 sv 70.4 70.2 71.3 70.4 52.6 58.3 42.2 74.0 75.1 Ave 66.6 66.1 69.4 69.8 57.4 — — — 71.1 Table 7: UAS on sentences of length 10 or less without punctuation from CoNLL shared task treebanks. “USR†” is the weakly supervised system of Naseem et al. (2010). “PGI” is the phylogenetic grammar induction model of Berg-Kirkpatrick and Klein (2010). Both the “USR†” and “PGI” systems are implemented and reported by McDonald et al. (2011). “NMG” is the unsupervised dependency parsing model with non-parallel multilingual guidance (Cohen et al., 2011). “PR” is the posterior regularization approach presented in Gillenwater et al. (2010). Some systems’ results for certain target languages are not available as marked by —. 4.5.1 Non-Projective Parsing As mentioned in section 2.3, the runtime to compute KU and its gradient is O(n4). One reasonable speedup, a</context>
</contexts>
<marker>Naseem, Chen, Barzilay, Johnson, 2010</marker>
<rawString>Tahira Naseem, Harr Chen, Regina Barzilay, and Mark Johnson. 2010. Using universal linguistic knowledge to guide grammar induction. In Proceedings of EMILP-2010, pages 1234–1244, Cambridge, MA, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen G Nash</author>
<author>Jorge Nocedal</author>
</authors>
<title>A numerical study of the limited memory bfgs method and truncated-newton method for large scale optimization.</title>
<date>1991</date>
<journal>SIAMJournal on Optimization,</journal>
<volume>1</volume>
<issue>2</issue>
<contexts>
<context position="13943" citStr="Nash and Nocedal, 1991" startWordPosition="2272" endWordPosition="2275"> = KP + γKU (11) KP and KU are the contributions of the parallel and unsupervised data, respectively. One may regard γ as a Lagrange multiplier that is used to constrain the parser’s uncertainty H to be low, as presented in several studies on entropy regularization (Brand, 1998; Grandvalet and Bengio, 2004; Jiao et al., 2006). 2.3 Algorithms and Complexity for Model Training To train our parsing model, we need to find out the parameters λ that minimize the objective function K′ in equation (11). This optimization problem is typically solved using quasi-Newton numerical methods such as L-BFGS (Nash and Nocedal, 1991), which requires efficient calculation of the objective function and the gradient of the objective function. The first item (KP) of the K′ function in equation (11) can be rewritten in the following form: XKP = − [X ˜p(yi|xi) X log w(e, xi) xiEP yi eEyi − log Z(xi)] (12) and according to equation (1) and (3) the gradient of KP can be written as: ∂˜p(yi|xi) log pλ(yi|xi) ∂λj X �X X = ˜p(yi|xi) fj(e,xi) xiEP yi eEyi �fj(e, xi) (13) According to equation (9), ˜p(y|x) can also be factored into the multiplication of the weight of each edge, so both KP and its gradient can be calculated by running t</context>
</contexts>
<marker>Nash, Nocedal, 1991</marker>
<rawString>Stephen G. Nash and Jorge Nocedal. 1991. A numerical study of the limited memory bfgs method and truncated-newton method for large scale optimization. SIAMJournal on Optimization, 1(2):358–372.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Truc-Vien T Nguyen</author>
<author>Alessandro Moschitti</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Convolution kernels on constituent, dependency and sequential structures for relation extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of EMILP2009,</booktitle>
<pages>1378--1387</pages>
<location>Singapore,</location>
<contexts>
<context position="1292" citStr="Nguyen et al., 2009" startWordPosition="186" endWordPosition="189"> thus making it applicable to a wide range of resource-poor languages. We perform experiments on three Data sets — Version 1.0 and version 2.0 of Google Universal Dependency Treebanks and Treebanks from CoNLL shared-tasks, across ten languages. We obtain stateof-the art performance of all the three data sets when compared with previously studied unsupervised and projected parsing systems. 1 Introduction In recent years, dependency parsing has gained universal interest due to its usefulness in a wide range of applications such as synonym generation (Shinyama et al., 2002), relation extraction (Nguyen et al., 2009) and machine translation (Katz-Brown et al., 2011; Xie et al., 2011). Several supervised dependency parsing algorithms (Nivre and Scholz, 2004; McDonald et al., 2005a; McDonald et al., 2005b; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Ma and Zhao, 2012; Zhang et al., 2013) have been proposed and achieved high parsing accuracies on several treebanks, due in large part to the availability of dependency treebanks in a number of languages (McDonald et al., 2013). Fei Xia Department of Linguistics University of Washington Seattle, WA 98195, USA fxia@uw.edu However, the manua</context>
</contexts>
<marker>Nguyen, Moschitti, Riccardi, 2009</marker>
<rawString>Truc-Vien T. Nguyen, Alessandro Moschitti, and Giuseppe Riccardi. 2009. Convolution kernels on constituent, dependency and sequential structures for relation extraction. In Proceedings of EMILP2009, pages 1378–1387, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Mario Scholz</author>
</authors>
<title>Deterministic dependency parsing of English text.</title>
<date>2004</date>
<booktitle>In Proceedings of COLIIG-2004,</booktitle>
<pages>64--70</pages>
<location>Geneva, Switzerland,</location>
<contexts>
<context position="1434" citStr="Nivre and Scholz, 2004" startWordPosition="207" endWordPosition="210">.0 of Google Universal Dependency Treebanks and Treebanks from CoNLL shared-tasks, across ten languages. We obtain stateof-the art performance of all the three data sets when compared with previously studied unsupervised and projected parsing systems. 1 Introduction In recent years, dependency parsing has gained universal interest due to its usefulness in a wide range of applications such as synonym generation (Shinyama et al., 2002), relation extraction (Nguyen et al., 2009) and machine translation (Katz-Brown et al., 2011; Xie et al., 2011). Several supervised dependency parsing algorithms (Nivre and Scholz, 2004; McDonald et al., 2005a; McDonald et al., 2005b; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Ma and Zhao, 2012; Zhang et al., 2013) have been proposed and achieved high parsing accuracies on several treebanks, due in large part to the availability of dependency treebanks in a number of languages (McDonald et al., 2013). Fei Xia Department of Linguistics University of Washington Seattle, WA 98195, USA fxia@uw.edu However, the manually annotated treebanks that these parsers rely on are highly expensive to create, in particular when we want to build treebanks for resource-</context>
</contexts>
<marker>Nivre, Scholz, 2004</marker>
<rawString>Joakim Nivre and Mario Scholz. 2004. Deterministic dependency parsing of English text. In Proceedings of COLIIG-2004, pages 64–70, Geneva, Switzerland, August 23-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Sandra K¨ubler</author>
<author>Ryan Mcdonald</author>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<title>shared task on dependency parsing.</title>
<date>2007</date>
<booktitle>The conll</booktitle>
<pages>915--932</pages>
<location>Prague, Czech.</location>
<marker>Nivre, Hall, K¨ubler, Mcdonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan Mcdonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007. The conll 2007 shared task on dependency parsing. In Proceeding of EMILP-CoILL 2007, pages 915–932, Prague, Czech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Algorithms for deterministic incremental dependency parsing.</title>
<date>2008</date>
<journal>Comput. Linguist.,</journal>
<volume>34</volume>
<issue>4</issue>
<contexts>
<context position="26780" citStr="Nivre, 2008" startWordPosition="4371" endWordPosition="4372">ces from each corpora, and smaller data sets are subsets of larger ones. Table 2 shows the number of tokens in the parallel data used in the experiments. 4.2 System performance and comparison on Google Universal Treebanks For the comparison of parsing performance, we run experiments on the following systems: DTP: The direct transfer parser (DTP) proposed by McDonald et al. (2011), who train a delexicalized parser on English labeled training data with no lexical features, then apply this parser to parse target languages directly. It is based on the transition-based dependency parsing paradigm (Nivre, 2008). We directly cite the results reported in McDonald et al. (2013). In addition to their original results, we also report results by reimplementing the direct transfer parser based on the first-order projective dependency parsing model (McDonald et al., 2005a) (DTP†). PTP The projected transfer parser (PTP) described in McDonald et al. (2011). The results of the projected transfer parser reimplemented by us is marked as “PTP†”. -U: Our approach training on only parallel data without unlabeled data for the target language. The parallel data set for each language contains 20,000 sentences. +U: Ou</context>
</contexts>
<marker>Nivre, 2008</marker>
<rawString>Joakim Nivre. 2008. Algorithms for deterministic incremental dependency parsing. Comput. Linguist., 34(4):513–553, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark A Paskin</author>
</authors>
<title>Cubic-time parsing and learning algorithms for grammatical bigram models.</title>
<date>2001</date>
<tech>Technical Report,</tech>
<pages>01--1148</pages>
<contexts>
<context position="14604" citStr="Paskin, 2001" startWordPosition="2394" endWordPosition="2395">jective function and the gradient of the objective function. The first item (KP) of the K′ function in equation (11) can be rewritten in the following form: XKP = − [X ˜p(yi|xi) X log w(e, xi) xiEP yi eEyi − log Z(xi)] (12) and according to equation (1) and (3) the gradient of KP can be written as: ∂˜p(yi|xi) log pλ(yi|xi) ∂λj X �X X = ˜p(yi|xi) fj(e,xi) xiEP yi eEyi �fj(e, xi) (13) According to equation (9), ˜p(y|x) can also be factored into the multiplication of the weight of each edge, so both KP and its gradient can be calculated by running the O(n3) inside-outside algorithm (Baker, 1979; Paskin, 2001) for projective parsing. For non-projective parsing, the analogy to the inside algorithm is the O(n3) matrixtree algorithm based on Kirchhoff’s Matrix-Tree Theorem, which is dominated asymptotically by a matrix determinant (Koo et al., 2007; Smith and Smith, 2007). The gradient of a determinant may be computed by matrix inversion, so evaluating the gradient again has the same O(n3) complexity as evaluating the function. The second item (KU) of the K′ function in equation (11) is the Shannon entropy of the posterior distribution over parsing trees, and can be written into the following form: XK</context>
<context position="16266" citStr="Paskin, 2001" startWordPosition="2646" endWordPosition="2647">979 366/8,071 300/6,950 ko 5,308/62,378 588/6,545 298/2,917 sv 4,447/66,631 493/9,312 1,219/20,376 Version 2.0 de 14,118/26,4906 800/12,215 1,000/16,339 es 14,138/37,5180 1,569/40,950 300/8,295 fr 14,511/35,1233 1,611/38,328 300/6,950 it 6,389/14,9145 400/9,541 400/9,187 ko 5437/60,621 603/6,438 299/2,631 pt 9,600/23,9012 1,200/29,873 1,198/29,438 sv 4,447/66,631 493/9,312 1,219/20,376 Table 1: Data statistics of two versions of Google Universal Treebanks for the target languages. Similar with the calculation of KP, KU can also be computed by running the inside-outside algorithm (Baker, 1979; Paskin, 2001) for projective parsing. For the gradient of KU, both the two multipliers of the second item in equation (15) can be computed using the same inside-outside algorithm. For the first item in equation (15), an O(n3) dynamic programming algorithm that is closely related to the forward-backward algorithm (Mann and McCallum, 2007) for the entropy regularized CRF (Jiao et al., 2006) can be used for projective parsing. For non-projective parsing, however, the runtime rises to O(n4). In this paper, we focus on projective parsing. 2.4 Summary of Our Approach To summarize the description in the previous </context>
</contexts>
<marker>Paskin, 2001</marker>
<rawString>Mark A. Paskin. 2001. Cubic-time parsing and learning algorithms for grammatical bigram models. Technical Report, UCB/CSD-01-1148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dipanjan Das</author>
<author>Ryan T McDonald</author>
</authors>
<title>A universal part-of-speech tagset.</title>
<date>2011</date>
<location>CoRR,</location>
<contexts>
<context position="21349" citStr="Petrov et al. (2011)" startWordPosition="3456" endWordPosition="3459">h the open source GIZA++ toolkit5. The parallel corpus was preprocessed in standard ways, selecting sentences with the length in the range from 3 to 100. Then we run GIZA++ with the default setting to generate word alignments in both directions. We then make the intersection of the word alignments of two directions to generate one-toone alignments. 3.3 Part-of-Speech Tagging Several features in our parsing model involve partof-speech (POS) tags of the input sentences. The set of POS tags needs to be consistent across languages and treebanks. For this reason we use the universal POS tag set of Petrov et al. (2011). This set consists of the following 12 coarsegrained tags: NOUN (nouns), VERB (verbs), ADJ (adjectives), ADV (adverbs), PRON (pronouns), DET (determiners), ADP (prepositions or postpositions), NUM (numerals), CONJ (conjunctions), PRT (particles), PUNC (punctuation marks) and X (a catch-all for other categories such as abbreviations or foreign words). POS tags are not available for parallel data in the Europarl and Kaist corpus, so we need to pro5https://code.google.com/p/giza-pp/ DTP† PTP† -U +U OR de 58.56 69.77 73.92 74.30 81.65 es 68.72 73.22 75.21 75.53 83.92 fr 71.13 74.75 76.14 76.53 83</context>
</contexts>
<marker>Petrov, Das, McDonald, 2011</marker>
<rawString>Slav Petrov, Dipanjan Das, and Ryan T. McDonald. 2011. A universal part-of-speech tagset. CoRR, abs/1104.2086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Shinyama</author>
<author>Satoshi Sekine</author>
<author>Kiyoshi Sudo</author>
</authors>
<title>Automatic paraphrase acquisition from news articles.</title>
<date>2002</date>
<booktitle>In Proceeding of HLT-2002,</booktitle>
<pages>313--318</pages>
<contexts>
<context position="1249" citStr="Shinyama et al., 2002" startWordPosition="179" endWordPosition="182">ring no human translations for the test data, thus making it applicable to a wide range of resource-poor languages. We perform experiments on three Data sets — Version 1.0 and version 2.0 of Google Universal Dependency Treebanks and Treebanks from CoNLL shared-tasks, across ten languages. We obtain stateof-the art performance of all the three data sets when compared with previously studied unsupervised and projected parsing systems. 1 Introduction In recent years, dependency parsing has gained universal interest due to its usefulness in a wide range of applications such as synonym generation (Shinyama et al., 2002), relation extraction (Nguyen et al., 2009) and machine translation (Katz-Brown et al., 2011; Xie et al., 2011). Several supervised dependency parsing algorithms (Nivre and Scholz, 2004; McDonald et al., 2005a; McDonald et al., 2005b; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Ma and Zhao, 2012; Zhang et al., 2013) have been proposed and achieved high parsing accuracies on several treebanks, due in large part to the availability of dependency treebanks in a number of languages (McDonald et al., 2013). Fei Xia Department of Linguistics University of Washington Seattle, W</context>
</contexts>
<marker>Shinyama, Sekine, Sudo, 2002</marker>
<rawString>Yusuke Shinyama, Satoshi Sekine, and Kiyoshi Sudo. 2002. Automatic paraphrase acquisition from news articles. In Proceeding of HLT-2002, pages 313– 318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noah A Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Contrastive estimation: Training log-linear models on unlabeled data.</title>
<date>2005</date>
<booktitle>In Proceedings ofACL-2005,</booktitle>
<pages>354--362</pages>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="2198" citStr="Smith and Eisner, 2005" startWordPosition="330" endWordPosition="333">et al., 2013) have been proposed and achieved high parsing accuracies on several treebanks, due in large part to the availability of dependency treebanks in a number of languages (McDonald et al., 2013). Fei Xia Department of Linguistics University of Washington Seattle, WA 98195, USA fxia@uw.edu However, the manually annotated treebanks that these parsers rely on are highly expensive to create, in particular when we want to build treebanks for resource-poor languages. This led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eisner, 2005; Cohen and Smith, 2009; Spitkovsky et al., 2010; Blunsom and Cohn, 2010; Mareˇcek and Straka, 2013; Spitkovsky et al., 2013), which appears to be a natural solution to this problem, as unsupervised methods require only unannotated text for training parsers. Unfortunately, the unsupervised grammar induction systems’ parsing accuracies often significantly fall behind those of supervised systems (McDonald et al., 2011). Furthermore, from a practical standpoint, it is rarely the case that we are completely devoid of resources for most languages. In this paper, we consider a practically motivated </context>
</contexts>
<marker>Smith, Eisner, 2005</marker>
<rawString>Noah A. Smith and Jason Eisner. 2005. Contrastive estimation: Training log-linear models on unlabeled data. In Proceedings ofACL-2005, pages 354–362, Ann Arbor, Michigan, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Bootstrapping feature-rich dependency parsers with entropic priors.</title>
<date>2007</date>
<booktitle>In Proceedings ofEMILP/CoILL-2007,</booktitle>
<pages>667--677</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="5912" citStr="Smith and Eisner (2007)" startWordPosition="911" endWordPosition="914">her accuracies than unsupervised parsers. Cohen et al. (2011) proposed an approach for unsupervised dependency parsing with non-parallel multilingual guidance from one or more helper languages, in which parallel data is not used. In this work, we propose a learning framework for transferring dependency grammars from a resource-rich language to resource-poor languages via parallel text. We train probabilistic parsing models for resource-poor languages by maximizing a combination of likelihood on parallel data and confidence on unlabeled data. Our work is based on the learning framework used in Smith and Eisner (2007), which is originally designed for parser bootstrapping. We extend this learning framework so that it can be used to transfer cross-lingual knowledge between different languages. Throughout this paper, English is used as the source language and we evaluate our approach on ten target languages — Danish (da), Dutch (nl), French (fr), German (de), Greek (el), Italian (it), Korean (ko), Portuguese (pt), Spanish (es) and Swedish (sv). Our approach achieves significant improvement over previous state-of-the-art unsupervised and projected parsing systems across all the ten languages, and considerably</context>
<context position="9473" citStr="Smith and Eisner (2007)" startWordPosition="1501" endWordPosition="1504">lihood estimation. For a supervised dependency parser with a set of training data {(xi, yi)}, the logarithm of the likelihood (a.k.a. the log-likelihood) is given by: L(λ) = � log pλ(yi|xi) (6) i Maximum likelihood training chooses parameters such that the log-likelihood L(λ) is maximized. However, in our scenario we have no labeled training data for target languages but we have some parallel and unlabeled data plus an English dependency parser. For the purpose of transferring cross-lingual information from the English parser via parallel text, we explore the model training method proposed by Smith and Eisner (2007), which presented a generalization of K function (Abney, 2004), and related it to another semi-supervised learning technique, entropy regularization (Jiao et al., 2006; Mann and McCallum, 2007). The objective K function to be minimized is actually the expected negative loglikelihood: K = − � E ˜p(yi|xi) log pλ(yi|xi) i yi �= D(˜pi||pλ,i) + H(˜pi) (7) i 1 pλ(y|x) = Z(x) rl w(e, x) (5) e∈y where ˜pi(·) def= ˜p(·|xi) and pλ,i(·) def= pλ(·|xi). ˜p(y|x) is the “transferring distribution” that reflects our uncertainty about the true labels, and we are trying to learn a parametric model pλ(y|x) by mi</context>
<context position="10744" citStr="Smith and Eisner (2007)" startWordPosition="1727" endWordPosition="1731">e a set of aligned parallel data P = {xsi, xti, ai} where ai is the word alignment for the pair of source-target sentences (xsi, xti), and a set of unlabeled sentences of the target language U = {xti}. We also have a trained English parsing model pλE(y|x). Then the K in equation (7) can be divided into two cases, according to whether xi belongs to parallel data set P or unlabeled data set U. For the unlabeled examples {xi ∈ U}, some previous studies (e.g., (Abney, 2004)) simply use a uniform distribution over labels (e.g., parses), to reflect that the label is unknown. We follow the method in Smith and Eisner (2007) and take the transferring distribution ˜pi to be the actual current belief pλ,i. The total contribution of the unsupervised examples to K then simplifies to KU = E H(pλ,i), which may xi∈U be regarded as the entropy item used to constrain the model’s uncertainty H to be low, as presented in the work on entropy regularization (Jiao et al., 2006; Mann and McCallum, 2007). But how can we define the transferring distribution for the parallel examples {xti ∈ P}? We define the transferring distribution by defining the transferring weight utilizing the English parsing model pλE(y|x) via parallel data</context>
<context position="33930" citStr="Smith and Eisner (2007)" startWordPosition="5588" endWordPosition="5591">phylogenetic grammar induction model of Berg-Kirkpatrick and Klein (2010). Both the “USR†” and “PGI” systems are implemented and reported by McDonald et al. (2011). “NMG” is the unsupervised dependency parsing model with non-parallel multilingual guidance (Cohen et al., 2011). “PR” is the posterior regularization approach presented in Gillenwater et al. (2010). Some systems’ results for certain target languages are not available as marked by —. 4.5.1 Non-Projective Parsing As mentioned in section 2.3, the runtime to compute KU and its gradient is O(n4). One reasonable speedup, as presented in Smith and Eisner (2007), is to replace Shannon entropy with R´enyi entropy. The R´enyi entropy is parameterized by α: � 1 p(y)α) (16) Rα (p) = 1 − αlog E y With R´enyi entropy, the computation of KU and its gradient is O(n3), even for non-projective case. 4.5.2 Higher-Order Models for Projective Parsing Our learning framework can be extended to higher-order dependency parsing models. For example, if we want to make our model capable of utilizing more contextual information, we can extend our transferring weight to higher-order parts: � V t wE (ps, xi ), if pt align−→ps ˜w(p , xi) = wE(ptdelex, xs i), otherwise (17) </context>
</contexts>
<marker>Smith, Eisner, 2007</marker>
<rawString>David A. Smith and Jason Eisner. 2007. Bootstrapping feature-rich dependency parsers with entropic priors. In Proceedings ofEMILP/CoILL-2007, pages 667–677, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Smith</author>
<author>Noah A Smith</author>
</authors>
<title>Bilingual parsing with factored estimation: Using English to parse Korean.</title>
<date>2004</date>
<booktitle>In Proceedings of EMILP2004,</booktitle>
<pages>49--56</pages>
<contexts>
<context position="3502" citStr="Smith and Smith, 2004" startWordPosition="533" endWordPosition="536">nguages, using existing resources from a resource-rich source language (like English).1 We assume that there are absolutely no labeled training data for the target language, but we have access to parallel data with a resource-rich language and a sufficient amount of labeled training data to build an accurate parser for the resource-rich language. This scenario appears similar to the setting in bilingual text parsing. However, most bilingual text parsing approaches require bilingual treebanks — treebanks that have manually annotated tree structures on both sides of source and target languages (Smith and Smith, 2004; Burkett and Klein, 2008), or have tree structures on the source side and translated sentences in the target languages (Huang et 1For the sake of simplicity, we refer to the resource-poor language as the “target language”, and resource-rich language as the “source language”. In addition, in this study we use English as the source resource-rich language, but our methodology can be applied to any resource-rich languages. 1337 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1337–1348, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for</context>
</contexts>
<marker>Smith, Smith, 2004</marker>
<rawString>David A. Smith and Noah A. Smith. 2004. Bilingual parsing with factored estimation: Using English to parse Korean. In Proceedings of EMILP2004, pages 49–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Smith</author>
<author>Noah A Smith</author>
</authors>
<title>Probabilistic models of nonporjective dependency trees.</title>
<date>2007</date>
<booktitle>In Proceedings of EMILP-COILL 2007,</booktitle>
<pages>132--140</pages>
<location>Prague, Czech,</location>
<contexts>
<context position="14868" citStr="Smith and Smith, 2007" startWordPosition="2433" endWordPosition="2436">nd (3) the gradient of KP can be written as: ∂˜p(yi|xi) log pλ(yi|xi) ∂λj X �X X = ˜p(yi|xi) fj(e,xi) xiEP yi eEyi �fj(e, xi) (13) According to equation (9), ˜p(y|x) can also be factored into the multiplication of the weight of each edge, so both KP and its gradient can be calculated by running the O(n3) inside-outside algorithm (Baker, 1979; Paskin, 2001) for projective parsing. For non-projective parsing, the analogy to the inside algorithm is the O(n3) matrixtree algorithm based on Kirchhoff’s Matrix-Tree Theorem, which is dominated asymptotically by a matrix determinant (Koo et al., 2007; Smith and Smith, 2007). The gradient of a determinant may be computed by matrix inversion, so evaluating the gradient again has the same O(n3) complexity as evaluating the function. The second item (KU) of the K′ function in equation (11) is the Shannon entropy of the posterior distribution over parsing trees, and can be written into the following form: XKU = − [X pλ(yi|xi) X log w(e, xi) xiEU yi eEyi − log Z(xi)] (14) and the gradient of KU is in the following: ∂KU X= ∂pλ(yi|xi) log pλ(yi|xi) xiEU ∂λj ∂λj X= − pλ(yi|xi) log pλ(yi|xi)Fj(yi, xi) yi (X ) + pλ(yi|xi)log pλ(yi|xi) yi (X ) · pλ(yi|xi)Fj(yi,xi) (15) yi H</context>
</contexts>
<marker>Smith, Smith, 2007</marker>
<rawString>David A. Smith and Noah A. Smith. 2007. Probabilistic models of nonporjective dependency trees. In Proceedings of EMILP-COILL 2007, pages 132– 140, Prague, Czech, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valentin I Spitkovsky</author>
<author>Hiyan Alshawi</author>
<author>Daniel Jurafsky</author>
</authors>
<title>From baby steps to leapfrog: How “less is more” in unsupervised dependency parsing.</title>
<date>2010</date>
<booktitle>In Proceedings of IAACL/HLT-2010,</booktitle>
<pages>751--759</pages>
<location>Los Angeles, California,</location>
<contexts>
<context position="2246" citStr="Spitkovsky et al., 2010" startWordPosition="338" endWordPosition="341">igh parsing accuracies on several treebanks, due in large part to the availability of dependency treebanks in a number of languages (McDonald et al., 2013). Fei Xia Department of Linguistics University of Washington Seattle, WA 98195, USA fxia@uw.edu However, the manually annotated treebanks that these parsers rely on are highly expensive to create, in particular when we want to build treebanks for resource-poor languages. This led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eisner, 2005; Cohen and Smith, 2009; Spitkovsky et al., 2010; Blunsom and Cohn, 2010; Mareˇcek and Straka, 2013; Spitkovsky et al., 2013), which appears to be a natural solution to this problem, as unsupervised methods require only unannotated text for training parsers. Unfortunately, the unsupervised grammar induction systems’ parsing accuracies often significantly fall behind those of supervised systems (McDonald et al., 2011). Furthermore, from a practical standpoint, it is rarely the case that we are completely devoid of resources for most languages. In this paper, we consider a practically motivated scenario, in which we want to build statistical </context>
</contexts>
<marker>Spitkovsky, Alshawi, Jurafsky, 2010</marker>
<rawString>Valentin I. Spitkovsky, Hiyan Alshawi, and Daniel Jurafsky. 2010. From baby steps to leapfrog: How “less is more” in unsupervised dependency parsing. In Proceedings of IAACL/HLT-2010, pages 751– 759, Los Angeles, California, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valentin I Spitkovsky</author>
<author>Hiyan Alshawi</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Breaking out of local optima with count transforms and model recombination: A study in grammar induction.</title>
<date>2013</date>
<booktitle>In Proceedings of EMILP2013,</booktitle>
<pages>1983--1995</pages>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="2323" citStr="Spitkovsky et al., 2013" startWordPosition="351" endWordPosition="354">bility of dependency treebanks in a number of languages (McDonald et al., 2013). Fei Xia Department of Linguistics University of Washington Seattle, WA 98195, USA fxia@uw.edu However, the manually annotated treebanks that these parsers rely on are highly expensive to create, in particular when we want to build treebanks for resource-poor languages. This led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eisner, 2005; Cohen and Smith, 2009; Spitkovsky et al., 2010; Blunsom and Cohn, 2010; Mareˇcek and Straka, 2013; Spitkovsky et al., 2013), which appears to be a natural solution to this problem, as unsupervised methods require only unannotated text for training parsers. Unfortunately, the unsupervised grammar induction systems’ parsing accuracies often significantly fall behind those of supervised systems (McDonald et al., 2011). Furthermore, from a practical standpoint, it is rarely the case that we are completely devoid of resources for most languages. In this paper, we consider a practically motivated scenario, in which we want to build statistical parsers for resource-poor target languages, using existing resources from a r</context>
</contexts>
<marker>Spitkovsky, Alshawi, Jurafsky, 2013</marker>
<rawString>Valentin I. Spitkovsky, Hiyan Alshawi, and Daniel Jurafsky. 2013. Breaking out of local optima with count transforms and model recombination: A study in grammar induction. In Proceedings of EMILP2013, pages 1983–1995, Seattle, Washington, USA, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-ofspeech tagging with a cyclic dependency network.</title>
<date>2003</date>
<booktitle>In Proceedings of IAACL/HLT-2003,</booktitle>
<pages>252--259</pages>
<contexts>
<context position="22415" citStr="Toutanova et al., 2003" startWordPosition="3630" endWordPosition="3633"> to pro5https://code.google.com/p/giza-pp/ DTP† PTP† -U +U OR de 58.56 69.77 73.92 74.30 81.65 es 68.72 73.22 75.21 75.53 83.92 fr 71.13 74.75 76.14 76.53 83.51 it 70.74 76.08 77.55 77.74 85.47 ko 38.55 43.34 59.71 59.89 90.42 pt 69.82 74.59 76.30 76.65 85.67 sv 70.59 75.87 78.91 79.27 85.59 Ave 64.02 69.66 73.96 74.27 85.18 Table 4: UAS for two versions of our approach, together with baseline and oracle systems on Google Universal Treebanks version 2.0. “Ave” is the macro-average across the seven languages. vide the POS tags for these data. In our experiments, we train a Stanford POS Tagger (Toutanova et al., 2003) for each language. The labeled training data for each POS tagger are extracted from the training portion of each Treebanks. The average tagging accuracy is around 95%. Undoubtedly, we are primarily interested in applying our approach to build statistical parsers for resource-poor target languages without any knowledge. For the purpose of evaluation of our approach and comparison with previous work, we need to exploit the gold POS tags to train the POS taggers. As part-of-speech tags are also a form of syntactic analysis, this assumption weakens the applicability of our approach. Fortunately, </context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher D. Manning, and Yoram Singer. 2003. Feature-rich part-ofspeech tagging with a cyclic dependency network. In Proceedings of IAACL/HLT-2003, pages 252– 259.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Xie</author>
<author>Haitao Mi</author>
<author>Qun Liu</author>
</authors>
<title>A novel dependency-to-string model for statistical machine translation.</title>
<date>2011</date>
<booktitle>In Proceedings of EMILP-2011,</booktitle>
<pages>216--226</pages>
<location>Edinburgh, Scotland, UK.,</location>
<contexts>
<context position="1360" citStr="Xie et al., 2011" startWordPosition="198" endWordPosition="201">We perform experiments on three Data sets — Version 1.0 and version 2.0 of Google Universal Dependency Treebanks and Treebanks from CoNLL shared-tasks, across ten languages. We obtain stateof-the art performance of all the three data sets when compared with previously studied unsupervised and projected parsing systems. 1 Introduction In recent years, dependency parsing has gained universal interest due to its usefulness in a wide range of applications such as synonym generation (Shinyama et al., 2002), relation extraction (Nguyen et al., 2009) and machine translation (Katz-Brown et al., 2011; Xie et al., 2011). Several supervised dependency parsing algorithms (Nivre and Scholz, 2004; McDonald et al., 2005a; McDonald et al., 2005b; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Ma and Zhao, 2012; Zhang et al., 2013) have been proposed and achieved high parsing accuracies on several treebanks, due in large part to the availability of dependency treebanks in a number of languages (McDonald et al., 2013). Fei Xia Department of Linguistics University of Washington Seattle, WA 98195, USA fxia@uw.edu However, the manually annotated treebanks that these parsers rely on are highly expens</context>
</contexts>
<marker>Xie, Mi, Liu, 2011</marker>
<rawString>Jun Xie, Haitao Mi, and Qun Liu. 2011. A novel dependency-to-string model for statistical machine translation. In Proceedings of EMILP-2011, pages 216–226, Edinburgh, Scotland, UK., July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Liang Huang</author>
<author>Kai Zhao</author>
<author>Ryan McDonald</author>
</authors>
<title>Online learning for inexact hypergraph search.</title>
<date>2013</date>
<booktitle>In Proceedings of EMILP-2013,</booktitle>
<pages>908--913</pages>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="1589" citStr="Zhang et al., 2013" startWordPosition="234" endWordPosition="237">e data sets when compared with previously studied unsupervised and projected parsing systems. 1 Introduction In recent years, dependency parsing has gained universal interest due to its usefulness in a wide range of applications such as synonym generation (Shinyama et al., 2002), relation extraction (Nguyen et al., 2009) and machine translation (Katz-Brown et al., 2011; Xie et al., 2011). Several supervised dependency parsing algorithms (Nivre and Scholz, 2004; McDonald et al., 2005a; McDonald et al., 2005b; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Ma and Zhao, 2012; Zhang et al., 2013) have been proposed and achieved high parsing accuracies on several treebanks, due in large part to the availability of dependency treebanks in a number of languages (McDonald et al., 2013). Fei Xia Department of Linguistics University of Washington Seattle, WA 98195, USA fxia@uw.edu However, the manually annotated treebanks that these parsers rely on are highly expensive to create, in particular when we want to build treebanks for resource-poor languages. This led to a vast amount of research on unsupervised grammar induction (Carroll and Charniak, 1992; Klein and Manning, 2004; Smith and Eis</context>
</contexts>
<marker>Zhang, Huang, Zhao, McDonald, 2013</marker>
<rawString>Hao Zhang, Liang Huang, Kai Zhao, and Ryan McDonald. 2013. Online learning for inexact hypergraph search. In Proceedings of EMILP-2013, pages 908–913, Seattle, Washington, USA, October.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>