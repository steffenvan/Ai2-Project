<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.115539">
<title confidence="0.993302">
CU-COMSEM: Exploring Rich Features for Unsupervised Web Per-
sonal Name Disambiguation
</title>
<author confidence="0.997794">
Ying Chen
</author>
<affiliation confidence="0.997442">
Center for Spoken Language Research
University of Colorado at Boulder
</affiliation>
<email confidence="0.9979">
yc@colorado.edu
</email>
<author confidence="0.989687">
James Martin
</author>
<affiliation confidence="0.998615">
Department of Computer Science
University of Colorado at Boulder
</affiliation>
<email confidence="0.997117">
James.Martin@colorado.edu
</email>
<sectionHeader confidence="0.998579" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998618">
The increasing number of web sources is
exacerbating the named-entity ambiguity
problem. This paper explores the use of
various token-based and phrase-based fea-
tures in unsupervised clustering of web
pages containing personal names. From
these experiments, we find that the use of
rich features can significantly improve the
disambiguation performance for web per-
sonal names.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999437">
As the sheer amount of web information expands
at an ever more rapid pace, the named-entity am-
biguity problem becomes more and more serious
in many fields, such as information integration,
cross-document co-reference, and question an-
swering. Individuals are so glutted with informa-
tion that searching for data presents real problems.
It is therefore crucial to develop methodologies
that can efficiently disambiguate the ambiguous
names from any given set of data.
In the paper, we present an approach that com-
bines unsupervised clustering methods with rich
feature extractions to automatically cluster re-
turned web pages according to which named en-
tity in reality the ambiguous personal name in a
web page refers to. We make two contributions to
approaches to web personal name disambiguation.
First, we seek to go beyond the kind of bag-of-
words features employed in earlier systems
(Bagga &amp; Baldwin, 1998; Gooi &amp; Allan, 2004;
Pedersen et al., 2005), and attempt to exploit deep
semantic features beyond the work of Mann &amp;
Yarowsky (2003). Second, we exploit some fea-
tures that are available only in a web corpus, such
as URL information and related web pages.
The paper is organized as follows. Section 2 in-
troduces our rich feature extractions along with
their corresponding similarity matrix learning. In
Section 3, we analyze the performance of our sys-
tem. Finally, we draw some conclusions.
</bodyText>
<sectionHeader confidence="0.995758" genericHeader="introduction">
2 Methodology
</sectionHeader>
<bodyText confidence="0.999716736842105">
Our approach follows a common architecture for
named-entity disambiguation: the detection of
ambiguous objects, feature extractions and their
corresponding similarity matrix learning, and fi-
nally clustering.
Given a webpage, we first run a modified Beau-
tiful Soup1 (a HTML parser) to extract a clean text
document for that webpage. In a clean text docu-
ment, noisy tokens, such as HTML tags and java
codes, are removed as much as possible, and sen-
tence segmentation is partially done by following
the indications of some special HTML tags. For
example, a sentence should finish when it meets a
“&lt;table&gt;” tag. Then each clean document contin-
ues to be preprocessed with MXTERMINATOR
(a sentence segmenter),2 the Penn Treebank to-
kenization,3 a syntactic phrase chunker (Hacioglu,
2004), and a named-entity detection and co-
reference system for the ACE project4 called EX-
</bodyText>
<footnote confidence="0.9986278">
1 http://www.crummy.com/software/BeautifulSoup
2http://www.id.cbs.dk/~dh/corpus/tools/MXTERMINATOR.
html
3 http://www.cis.upenn.edu/~treebank/tokenization.html
4 http://www.nist.gov/speech/tests/ace
</footnote>
<page confidence="0.975567">
125
</page>
<bodyText confidence="0.84494275">
Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 125–128,
Prague, June 2007. c�2007 Association for Computational Linguistics
ERT5 (Hacioglu et al. 2005; Chen &amp; Hacioglu,
2006).
</bodyText>
<subsectionHeader confidence="0.978936">
2.1 The detection of ambiguous objects
</subsectionHeader>
<bodyText confidence="0.999980972972973">
For a given ambiguous personal name, for each
web page, we try to extract all mentions of the
ambiguous personal name, using three possible
varieties of the personal name. For example, the
three regular expression patterns for “Alexander
Markham” are “Alexander Markham,” “Markham,
Alexander,” and “Alexander .\. Markham” (“.\.”
can match a middle name). Web pages without
any mention of the ambiguous personal name of
interest are discarded and receive no further
processing.
Since it is common for a single document to
contain one or more mentions of the ambiguous
personal name of interest, there is a need to define
the object to be disambiguated. Here, we adopt
the policy of “one person per document” (all men-
tions of the ambiguous personal name in one web
page are assumed to refer to the same personal
entity in reality) as in Bagga &amp; Baldwin (1998),
Mann &amp; Yarowsky (2003) and Gooi &amp; Allan
(2004). We therefore define an object as a single
entity with the ambiguous personal name in a
given web page. This definition of the object
(document-level object) might be mistaken, be-
cause the mentions of the ambiguous personal
name in a web page may refer to multiple entities,
but we found that this is a rare case (most of those
cases occur in genealogy web pages). On the other
hand, a document-level object can include much
information derived from that web page, so that it
can be represented by rich features.
Given this definition of an object, we define a
target entity as an entity (outputted from the
EXERT system) that includes a mention of the
ambiguous personal name. Then, we define a local
sentence as a sentence that contains a mention of
any target entity.
</bodyText>
<subsectionHeader confidence="0.9866025">
2.2 Feature extraction and similarity matrix
learning
</subsectionHeader>
<bodyText confidence="0.9999112">
Most of the previous work (Bagga &amp; Baldwin,
1998; Gooi &amp; Allan; 2004; Pedersen et al., 2005)
uses token information in the given documents. In
this paper, we follow and extend their work espe-
cially for a web corpus. On the other hand, com-
</bodyText>
<footnote confidence="0.399716">
5 http://sds.colorado.edu/EXERT
</footnote>
<bodyText confidence="0.9997505">
pared to a token, a phrase contains more informa-
tion for named-entity disambiguation. Therefore,
we explore some phrase-based information in this
paper. Finally, there are two kinds of feature vec-
tors developed in our system: token-based and
phrase-based. A token-based feature vector is
composed of tokens, and a phrase-based feature
vector is composed of phrases.
</bodyText>
<subsubsectionHeader confidence="0.700114">
2.2.1 Token-based features
</subsubsectionHeader>
<bodyText confidence="0.999292365853658">
There is a lot of token information available in a
web page: the tokens occurring in that web page,
the URL for that web page, and so on. Here, for
each web page, we tried to extract tokens accord-
ing to the following schemes.
Local tokens (Local): the tokens occurring in the
local sentences in a given webpage;
Full tokens (Full): the tokens occurring in a given
webpage;
URL tokens (URL): the tokens occurring in the
URL of a given webpage. URL tokenization
works as follows: split a URL at “:” and “.”, and
then filter out stop words that are very common in
URLs, such as “com,” “http,” and so on;
Title tokens in root page (TTRP): the title tokens
occurring in the root page of a given webpage.
Here, we define the root page of a given webpage
as the page whose URL is the first slash-
demarcated element (non-http) of the URL of the
given webpage. For example, the root page of
“http://www.leeds.ac.uk/calendar/court.htm” is
“www.leeds.ac.uk”. We do not use all tokens in
the root page because there may be a lot of noisy
information.
Although Local tokens and Full tokens often
provide enough information for name disambigua-
tion, there are some ambiguity cases that can be
solved only with the help of information beyond
the given web page, such as URL tokens and
TTRP tokens. For example, in the web page
“Alexander Markham 009,” there is not sufficient
information to identify the “Alexander Markham.”
But from its URL tokens (“leeds ac uk calendar
court”) and the title tokens in its root page (“Uni-
versity of Leeds”), it is easy to infer that this
“Alexander Markham” is from the University of
Leeds, which can totally solve the name ambigu-
ity.
Because of the noisy information in URL to-
kens and TTRP tokens, here we combine them
with Local tokens, using the following policy: for
</bodyText>
<page confidence="0.994089">
126
</page>
<bodyText confidence="0.999980967741936">
each URL token and TTRP token, if the token is
also one of the Local tokens of other web pages,
add this token into the Local token list of the cur-
rent webpage. We do the same thing with Full
tokens.
Except URL tokens, the other three kinds of
tokens—Local tokens, Full tokens and TTRP to-
kens—are outputted from the Penn Treebank to-
kenization, filtered by a stop-word dictionary, and
represented in their morphological root form. But
tokens in web pages have special characteristics
and need more post-processing. In particular, a
token may be an email address or a URL that may
contain some useful information. For example,
“charlotte@la-par.org” indicates the “Charlotte
Bergeron” who works for PAR (the Public Affairs
Research Council) in LA (Los Angeles). To cap-
ture the fine-grained information in an email ad-
dress or a URL, we do deep tokenization on these
two kinds of tokens. For a URL, we do deep to-
kenization as URL tokenization; for an email ad-
dress, we split the email address at “@” and “.”,
then filter out the stop words as in URL tokeniza-
tion.
So far, we have developed two token-based fea-
ture vectors: a Local token feature vector and a
Full token feature vector. Both of them may con-
tain URL and TTRP tokens. Given feature vectors,
we need to find a way to learn the similarity ma-
trix. Here, we choose the standard TF-IDF method
to calculate the similarity matrix.
</bodyText>
<subsubsectionHeader confidence="0.859896">
2.2.2 Phrase-based features
</subsubsectionHeader>
<bodyText confidence="0.999374490196079">
Since considerable information related to the am-
biguous object resides in the noun phrases in a
web page, such as the person’s job and the per-
son’s location, we attempt to capture this noun
phrase information. The following section briefly
describes how to extract and use the noun phrase
information. For more detail, see Chen &amp; Martin
(2007).
Contextual base noun phrase feature: With
the syntactic phrase chunker, we extract all base
noun phrases (non-overlapping syntactic phrases)
occurring in the local sentences, which usually
include some useful information about the am-
biguous object. A base noun phrase of interest
serves as an element in the feature vector.
Document named-entity feature: Given the
EXERT system, a direct and simple way to use
the semantic information is to extract all named
entities in a web page. Since a given entity can be
represented by many mentions in a document, we
choose a single representative mention to repre-
sent each entity. The representative mention is
selected according to the following ordered pref-
erence list: longest NAME mention, longest
NOMINAL mention. A representative mention
phrase serves as an element in a feature vector.
Given a pair of feature vectors consisting of
phrase-based features, we need to choose a simi-
larity scheme to calculate the similarity matrix.
Because of the word-space delimiter in English,
the feature vector comprises phrases, so that a
similarity scheme for phrase-based feature vectors
is required. Chen &amp; Martin (2007) introduced one
of those similarity schemes, “two-level
SoftTFIDF”. First, a token-based similarity
scheme, the standard SoftTFIDF (Cohen et al.,
2003), is used to calculate the similarity between
phrases in the pair of feature vectors; in the sec-
ond phase, the standard SoftTFIDF is reformu-
lated to calculate the similarity for the pair of
phrased-based feature vectors.
First, we introduce the standard SoftTFIDF. In
a pair of feature vectors S and T, S = (s1, ... , sn )
and T = (t1, ... , tm). Here, si (i = 1...n) and tj (j =
1...m) are substrings (tokens). Let CLOSE(0; S;T)
be the set of substrings w ∈ S such that there is
some v∈ T satisfying dist(w; v) &gt; θ. The Jaro-
Winkler distance function (Winkler, 1999) is
dist(;). For w∈ CLOSE(0; S;T), let D(w; T) =
maxv∈T dist(w;v) . Then the standard SoftTFIDF
is computed as
</bodyText>
<equation confidence="0.999349">
SoftTFIDF ( )
S,T
V( ) V( ) D(
w, S × w, T × w, T
( ; ; )
θ S T
V&apos; ( ) log (TF 1) log (IDF )
w, S = w,S + × w
V (w, S) =
</equation>
<bodyText confidence="0.999438">
where TFw,S is the frequency of substrings w in S,
and IDFw is the inverse of the fraction of docu-
ments in the corpus that contain w. To compute
the similarity for the phrase-based feature vectors,
in the second step of “two-level SoftTFIDF,” the
substring w is a phrase and dist is the standard
SoftTFIDF.
So far, we have developed several feature mod-
els and learned the corresponding similarity ma-
</bodyText>
<equation confidence="0.969705125">
∑w∈ CLOSE
)
V (w, S)
,
2
V (w, S)
∑ ∈
w S
</equation>
<page confidence="0.983812">
127
</page>
<bodyText confidence="0.99981425">
trices, but clustering usually needs only one
unique similarity matrix. In the results reported
here, we simply combine the similarity matrices,
assigning equal weight to each one.
</bodyText>
<subsectionHeader confidence="0.996195">
2.3 Clustering
</subsectionHeader>
<bodyText confidence="0.9999667">
Although clustering is a well-studied area, a re-
maining research problem is to determine the op-
timal parameter settings during clustering, such as
the number of clusters or the stop-threshold, a
problem that is important for real tasks and that is
not at all trivial. Because currently we focus only
on feature development, we choose agglomerative
clustering with a single linkage, and simply use a
fixed stop-threshold acquired from the training
data.
</bodyText>
<sectionHeader confidence="0.999695" genericHeader="method">
3 Performance
</sectionHeader>
<bodyText confidence="0.999379125">
Our system performs very well for the Semeval
Web People corpus, and Table 1 shows the
performances. There are two results in Table 1:
One is gotten from the evaluation of Semeval
Web People Track (SemEval), and the other is
evaluated with B-cubed evaluation (Bagga and
Baldwin, 1998). Both scores indicate that web
personal name disambiguation needs more effort.
</bodyText>
<table confidence="0.999834833333333">
Purity Inverse F F
Purity (α=0.5) (α=0.2)
SemEval 0.72 0.88 0.78 0.83
Precision Recall F F
(α=0.5) (α=0.2)
B-cubed 0.61 0.83 0.70 0.77
</table>
<tableCaption confidence="0.99933">
Table 1 The performances of the test data
</tableCaption>
<sectionHeader confidence="0.999" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999967117647059">
Our experiments in web personal name disam-
biguation extend token-based information to a
web corpus, and also include some noun phrase-
based information. From our experiment, we first
find that it is not easy to extract a clean text
document from a webpage because of much noisy
information in it. Second, some common tools
need to be adapted to a web corpus, such as sen-
tence segmentation and tokenization. Many NLP
tools are developed for a news corpus, whereas a
web corpus is noisier and often needs some spe-
cific processing. Third, in this paper, we use some
URL information and noun phrase information in
a rather simple way; more exploration is needed in
the future. Besides the rich feature extraction, we
also need more work on similarity combination
and clustering.
</bodyText>
<sectionHeader confidence="0.997301" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9886245">
Special thanks are extended to Praful Mangalath
and Kirill Kireyev.
</bodyText>
<sectionHeader confidence="0.999075" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999581648648649">
J. Artiles, J. Gonzalo. and S. Sekine. 2007. The SemE-
val-2007 WePS Evaluation: Establishing a bench-
mark for the Web People Search Task. In Proceed-
ings of Semeval 2007, Association for Computa-
tional Linguistics.
A. Bagga and B. Baldwin. 1998. Entity–based Cross–
document Co–referencing Using the Vector Space
Model. In 17th COLING.
Y. Chen and K. Hacioglu. 2006. Exploration of
Coreference Resolution: The ACE Entity Detection
and Recognition Task. In 9th International Confer-
ence on TEXT, SPEECH and DIALOGUE.
Y. Chen and J. Martin. 2007. Towards Robust Unsu-
pervised Personal Name Disambiguation. EMNLP.
W. Cohen, P. Ravikumar, S. Fienberg. 2003. A Com-
parison of String Metrics for Name-Matching Tasks.
In IJCAI-03 II-Web Workshop.
C. H. Gooi and J. Allan. 2004. Cross-Document
Coreference on a Large Scale Corpus. NAACL
K. Hacioglu, B. Douglas and Y. Chen. 2005. Detection
of Entity Mentions Occurring in English and Chi-
nese Text. Computational Linguistics.
K. Hacioglu. 2004. A Lightweight Semantic Chunking
Model Based On Tagging. In HLT/NAACL.
B. Malin. 2005. Unsupervised Name Disambiguation
via Social Network Similarity. SIAM.
G. Mann and D. Yarowsky. 2003. Unsupervised Per-
sonal Name Disambiguation. In Proc. of CoNLL-
2003, Edmonton, Canada.
T. Pedersen, A. Purandare and A. Kulkarni. 2005.
Name Discrimination by Clustering Similar Con-
texts. In Proc. of the Sixth International Conference
on Intelligent Text Processing and Computational
Linguistics, pages 226-237. Mexico City, Mexico.
W. E. Winkler. 1999. The state of record linkage and
current research problems. Statistics of Income Di-
vision, Internal Revenue Service Publication R99/04.
</reference>
<page confidence="0.996698">
128
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.945166">
<title confidence="0.992976">Exploring Rich Features for Unsupervised Web sonal Name Disambiguation</title>
<author confidence="0.998217">Ying Chen</author>
<affiliation confidence="0.999773">Center for Spoken Language Research University of Colorado at Boulder</affiliation>
<email confidence="0.99934">yc@colorado.edu</email>
<author confidence="0.999792">James Martin</author>
<affiliation confidence="0.9998335">Department of Computer Science University of Colorado at Boulder</affiliation>
<email confidence="0.989379">James.Martin@colorado.edu</email>
<abstract confidence="0.997372818181818">The increasing number of web sources is exacerbating the named-entity ambiguity problem. This paper explores the use of various token-based and phrase-based features in unsupervised clustering of web pages containing personal names. From these experiments, we find that the use of rich features can significantly improve the disambiguation performance for web personal names.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Sekine</author>
</authors>
<title>The SemEval-2007 WePS Evaluation: Establishing a benchmark for the Web People Search Task.</title>
<date>2007</date>
<booktitle>In Proceedings of Semeval 2007, Association for Computational Linguistics.</booktitle>
<marker>Sekine, 2007</marker>
<rawString>J. Artiles, J. Gonzalo. and S. Sekine. 2007. The SemEval-2007 WePS Evaluation: Establishing a benchmark for the Web People Search Task. In Proceedings of Semeval 2007, Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bagga</author>
<author>B Baldwin</author>
</authors>
<title>Entity–based Cross– document Co–referencing Using the Vector Space Model.</title>
<date>1998</date>
<booktitle>In 17th COLING.</booktitle>
<contexts>
<context position="12866" citStr="Bagga and Baldwin, 1998" startWordPosition="2130" endWordPosition="2133">clustering, such as the number of clusters or the stop-threshold, a problem that is important for real tasks and that is not at all trivial. Because currently we focus only on feature development, we choose agglomerative clustering with a single linkage, and simply use a fixed stop-threshold acquired from the training data. 3 Performance Our system performs very well for the Semeval Web People corpus, and Table 1 shows the performances. There are two results in Table 1: One is gotten from the evaluation of Semeval Web People Track (SemEval), and the other is evaluated with B-cubed evaluation (Bagga and Baldwin, 1998). Both scores indicate that web personal name disambiguation needs more effort. Purity Inverse F F Purity (α=0.5) (α=0.2) SemEval 0.72 0.88 0.78 0.83 Precision Recall F F (α=0.5) (α=0.2) B-cubed 0.61 0.83 0.70 0.77 Table 1 The performances of the test data 4 Conclusion Our experiments in web personal name disambiguation extend token-based information to a web corpus, and also include some noun phrasebased information. From our experiment, we first find that it is not easy to extract a clean text document from a webpage because of much noisy information in it. Second, some common tools need to </context>
<context position="1591" citStr="Bagga &amp; Baldwin, 1998" startWordPosition="234" endWordPosition="237"> that searching for data presents real problems. It is therefore crucial to develop methodologies that can efficiently disambiguate the ambiguous names from any given set of data. In the paper, we present an approach that combines unsupervised clustering methods with rich feature extractions to automatically cluster returned web pages according to which named entity in reality the ambiguous personal name in a web page refers to. We make two contributions to approaches to web personal name disambiguation. First, we seek to go beyond the kind of bag-ofwords features employed in earlier systems (Bagga &amp; Baldwin, 1998; Gooi &amp; Allan, 2004; Pedersen et al., 2005), and attempt to exploit deep semantic features beyond the work of Mann &amp; Yarowsky (2003). Second, we exploit some features that are available only in a web corpus, such as URL information and related web pages. The paper is organized as follows. Section 2 introduces our rich feature extractions along with their corresponding similarity matrix learning. In Section 3, we analyze the performance of our system. Finally, we draw some conclusions. 2 Methodology Our approach follows a common architecture for named-entity disambiguation: the detection of am</context>
<context position="4281" citStr="Bagga &amp; Baldwin (1998)" startWordPosition="643" endWordPosition="646">er Markham” are “Alexander Markham,” “Markham, Alexander,” and “Alexander .\. Markham” (“.\.” can match a middle name). Web pages without any mention of the ambiguous personal name of interest are discarded and receive no further processing. Since it is common for a single document to contain one or more mentions of the ambiguous personal name of interest, there is a need to define the object to be disambiguated. Here, we adopt the policy of “one person per document” (all mentions of the ambiguous personal name in one web page are assumed to refer to the same personal entity in reality) as in Bagga &amp; Baldwin (1998), Mann &amp; Yarowsky (2003) and Gooi &amp; Allan (2004). We therefore define an object as a single entity with the ambiguous personal name in a given web page. This definition of the object (document-level object) might be mistaken, because the mentions of the ambiguous personal name in a web page may refer to multiple entities, but we found that this is a rare case (most of those cases occur in genealogy web pages). On the other hand, a document-level object can include much information derived from that web page, so that it can be represented by rich features. Given this definition of an object, we</context>
</contexts>
<marker>Bagga, Baldwin, 1998</marker>
<rawString>A. Bagga and B. Baldwin. 1998. Entity–based Cross– document Co–referencing Using the Vector Space Model. In 17th COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Chen</author>
<author>K Hacioglu</author>
</authors>
<title>Exploration of Coreference Resolution: The ACE Entity Detection and Recognition Task.</title>
<date>2006</date>
<booktitle>In 9th International Conference on TEXT, SPEECH and DIALOGUE.</booktitle>
<contexts>
<context position="3383" citStr="Chen &amp; Hacioglu, 2006" startWordPosition="493" endWordPosition="496">h MXTERMINATOR (a sentence segmenter),2 the Penn Treebank tokenization,3 a syntactic phrase chunker (Hacioglu, 2004), and a named-entity detection and coreference system for the ACE project4 called EX1 http://www.crummy.com/software/BeautifulSoup 2http://www.id.cbs.dk/~dh/corpus/tools/MXTERMINATOR. html 3 http://www.cis.upenn.edu/~treebank/tokenization.html 4 http://www.nist.gov/speech/tests/ace 125 Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 125–128, Prague, June 2007. c�2007 Association for Computational Linguistics ERT5 (Hacioglu et al. 2005; Chen &amp; Hacioglu, 2006). 2.1 The detection of ambiguous objects For a given ambiguous personal name, for each web page, we try to extract all mentions of the ambiguous personal name, using three possible varieties of the personal name. For example, the three regular expression patterns for “Alexander Markham” are “Alexander Markham,” “Markham, Alexander,” and “Alexander .\. Markham” (“.\.” can match a middle name). Web pages without any mention of the ambiguous personal name of interest are discarded and receive no further processing. Since it is common for a single document to contain one or more mentions of the am</context>
</contexts>
<marker>Chen, Hacioglu, 2006</marker>
<rawString>Y. Chen and K. Hacioglu. 2006. Exploration of Coreference Resolution: The ACE Entity Detection and Recognition Task. In 9th International Conference on TEXT, SPEECH and DIALOGUE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Chen</author>
<author>J Martin</author>
</authors>
<title>Towards Robust Unsupervised Personal Name Disambiguation.</title>
<date>2007</date>
<publisher>EMNLP.</publisher>
<contexts>
<context position="9365" citStr="Chen &amp; Martin (2007)" startWordPosition="1520" endWordPosition="1523">eature vector and a Full token feature vector. Both of them may contain URL and TTRP tokens. Given feature vectors, we need to find a way to learn the similarity matrix. Here, we choose the standard TF-IDF method to calculate the similarity matrix. 2.2.2 Phrase-based features Since considerable information related to the ambiguous object resides in the noun phrases in a web page, such as the person’s job and the person’s location, we attempt to capture this noun phrase information. The following section briefly describes how to extract and use the noun phrase information. For more detail, see Chen &amp; Martin (2007). Contextual base noun phrase feature: With the syntactic phrase chunker, we extract all base noun phrases (non-overlapping syntactic phrases) occurring in the local sentences, which usually include some useful information about the ambiguous object. A base noun phrase of interest serves as an element in the feature vector. Document named-entity feature: Given the EXERT system, a direct and simple way to use the semantic information is to extract all named entities in a web page. Since a given entity can be represented by many mentions in a document, we choose a single representative mention t</context>
</contexts>
<marker>Chen, Martin, 2007</marker>
<rawString>Y. Chen and J. Martin. 2007. Towards Robust Unsupervised Personal Name Disambiguation. EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Cohen</author>
<author>P Ravikumar</author>
<author>S Fienberg</author>
</authors>
<title>A Comparison of String Metrics for Name-Matching Tasks.</title>
<date>2003</date>
<booktitle>In IJCAI-03 II-Web Workshop.</booktitle>
<contexts>
<context position="10676" citStr="Cohen et al., 2003" startWordPosition="1721" endWordPosition="1724">rdered preference list: longest NAME mention, longest NOMINAL mention. A representative mention phrase serves as an element in a feature vector. Given a pair of feature vectors consisting of phrase-based features, we need to choose a similarity scheme to calculate the similarity matrix. Because of the word-space delimiter in English, the feature vector comprises phrases, so that a similarity scheme for phrase-based feature vectors is required. Chen &amp; Martin (2007) introduced one of those similarity schemes, “two-level SoftTFIDF”. First, a token-based similarity scheme, the standard SoftTFIDF (Cohen et al., 2003), is used to calculate the similarity between phrases in the pair of feature vectors; in the second phase, the standard SoftTFIDF is reformulated to calculate the similarity for the pair of phrased-based feature vectors. First, we introduce the standard SoftTFIDF. In a pair of feature vectors S and T, S = (s1, ... , sn ) and T = (t1, ... , tm). Here, si (i = 1...n) and tj (j = 1...m) are substrings (tokens). Let CLOSE(0; S;T) be the set of substrings w ∈ S such that there is some v∈ T satisfying dist(w; v) &gt; θ. The JaroWinkler distance function (Winkler, 1999) is dist(;). For w∈ CLOSE(0; S;T),</context>
</contexts>
<marker>Cohen, Ravikumar, Fienberg, 2003</marker>
<rawString>W. Cohen, P. Ravikumar, S. Fienberg. 2003. A Comparison of String Metrics for Name-Matching Tasks. In IJCAI-03 II-Web Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C H Gooi</author>
<author>J Allan</author>
</authors>
<title>Cross-Document Coreference on a Large Scale Corpus.</title>
<date>2004</date>
<publisher>NAACL</publisher>
<contexts>
<context position="1611" citStr="Gooi &amp; Allan, 2004" startWordPosition="238" endWordPosition="241">a presents real problems. It is therefore crucial to develop methodologies that can efficiently disambiguate the ambiguous names from any given set of data. In the paper, we present an approach that combines unsupervised clustering methods with rich feature extractions to automatically cluster returned web pages according to which named entity in reality the ambiguous personal name in a web page refers to. We make two contributions to approaches to web personal name disambiguation. First, we seek to go beyond the kind of bag-ofwords features employed in earlier systems (Bagga &amp; Baldwin, 1998; Gooi &amp; Allan, 2004; Pedersen et al., 2005), and attempt to exploit deep semantic features beyond the work of Mann &amp; Yarowsky (2003). Second, we exploit some features that are available only in a web corpus, such as URL information and related web pages. The paper is organized as follows. Section 2 introduces our rich feature extractions along with their corresponding similarity matrix learning. In Section 3, we analyze the performance of our system. Finally, we draw some conclusions. 2 Methodology Our approach follows a common architecture for named-entity disambiguation: the detection of ambiguous objects, fea</context>
<context position="4329" citStr="Gooi &amp; Allan (2004)" startWordPosition="652" endWordPosition="655">ander,” and “Alexander .\. Markham” (“.\.” can match a middle name). Web pages without any mention of the ambiguous personal name of interest are discarded and receive no further processing. Since it is common for a single document to contain one or more mentions of the ambiguous personal name of interest, there is a need to define the object to be disambiguated. Here, we adopt the policy of “one person per document” (all mentions of the ambiguous personal name in one web page are assumed to refer to the same personal entity in reality) as in Bagga &amp; Baldwin (1998), Mann &amp; Yarowsky (2003) and Gooi &amp; Allan (2004). We therefore define an object as a single entity with the ambiguous personal name in a given web page. This definition of the object (document-level object) might be mistaken, because the mentions of the ambiguous personal name in a web page may refer to multiple entities, but we found that this is a rare case (most of those cases occur in genealogy web pages). On the other hand, a document-level object can include much information derived from that web page, so that it can be represented by rich features. Given this definition of an object, we define a target entity as an entity (outputted </context>
</contexts>
<marker>Gooi, Allan, 2004</marker>
<rawString>C. H. Gooi and J. Allan. 2004. Cross-Document Coreference on a Large Scale Corpus. NAACL</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Hacioglu</author>
<author>B Douglas</author>
<author>Y Chen</author>
</authors>
<date>2005</date>
<booktitle>Detection of Entity Mentions Occurring in English and Chinese Text. Computational Linguistics.</booktitle>
<contexts>
<context position="3359" citStr="Hacioglu et al. 2005" startWordPosition="489" endWordPosition="492">to be preprocessed with MXTERMINATOR (a sentence segmenter),2 the Penn Treebank tokenization,3 a syntactic phrase chunker (Hacioglu, 2004), and a named-entity detection and coreference system for the ACE project4 called EX1 http://www.crummy.com/software/BeautifulSoup 2http://www.id.cbs.dk/~dh/corpus/tools/MXTERMINATOR. html 3 http://www.cis.upenn.edu/~treebank/tokenization.html 4 http://www.nist.gov/speech/tests/ace 125 Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 125–128, Prague, June 2007. c�2007 Association for Computational Linguistics ERT5 (Hacioglu et al. 2005; Chen &amp; Hacioglu, 2006). 2.1 The detection of ambiguous objects For a given ambiguous personal name, for each web page, we try to extract all mentions of the ambiguous personal name, using three possible varieties of the personal name. For example, the three regular expression patterns for “Alexander Markham” are “Alexander Markham,” “Markham, Alexander,” and “Alexander .\. Markham” (“.\.” can match a middle name). Web pages without any mention of the ambiguous personal name of interest are discarded and receive no further processing. Since it is common for a single document to contain one or</context>
</contexts>
<marker>Hacioglu, Douglas, Chen, 2005</marker>
<rawString>K. Hacioglu, B. Douglas and Y. Chen. 2005. Detection of Entity Mentions Occurring in English and Chinese Text. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Hacioglu</author>
</authors>
<title>A Lightweight Semantic Chunking Model Based On Tagging.</title>
<date>2004</date>
<booktitle>In HLT/NAACL.</booktitle>
<contexts>
<context position="2877" citStr="Hacioglu, 2004" startWordPosition="443" endWordPosition="444"> matrix learning, and finally clustering. Given a webpage, we first run a modified Beautiful Soup1 (a HTML parser) to extract a clean text document for that webpage. In a clean text document, noisy tokens, such as HTML tags and java codes, are removed as much as possible, and sentence segmentation is partially done by following the indications of some special HTML tags. For example, a sentence should finish when it meets a “&lt;table&gt;” tag. Then each clean document continues to be preprocessed with MXTERMINATOR (a sentence segmenter),2 the Penn Treebank tokenization,3 a syntactic phrase chunker (Hacioglu, 2004), and a named-entity detection and coreference system for the ACE project4 called EX1 http://www.crummy.com/software/BeautifulSoup 2http://www.id.cbs.dk/~dh/corpus/tools/MXTERMINATOR. html 3 http://www.cis.upenn.edu/~treebank/tokenization.html 4 http://www.nist.gov/speech/tests/ace 125 Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 125–128, Prague, June 2007. c�2007 Association for Computational Linguistics ERT5 (Hacioglu et al. 2005; Chen &amp; Hacioglu, 2006). 2.1 The detection of ambiguous objects For a given ambiguous personal name, for each web pag</context>
</contexts>
<marker>Hacioglu, 2004</marker>
<rawString>K. Hacioglu. 2004. A Lightweight Semantic Chunking Model Based On Tagging. In HLT/NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Malin</author>
</authors>
<title>Unsupervised Name Disambiguation via Social Network Similarity.</title>
<date>2005</date>
<publisher>SIAM.</publisher>
<marker>Malin, 2005</marker>
<rawString>B. Malin. 2005. Unsupervised Name Disambiguation via Social Network Similarity. SIAM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Mann</author>
<author>D Yarowsky</author>
</authors>
<title>Unsupervised Personal Name Disambiguation.</title>
<date>2003</date>
<booktitle>In Proc. of CoNLL2003,</booktitle>
<location>Edmonton, Canada.</location>
<contexts>
<context position="1724" citStr="Mann &amp; Yarowsky (2003)" startWordPosition="257" endWordPosition="260">the ambiguous names from any given set of data. In the paper, we present an approach that combines unsupervised clustering methods with rich feature extractions to automatically cluster returned web pages according to which named entity in reality the ambiguous personal name in a web page refers to. We make two contributions to approaches to web personal name disambiguation. First, we seek to go beyond the kind of bag-ofwords features employed in earlier systems (Bagga &amp; Baldwin, 1998; Gooi &amp; Allan, 2004; Pedersen et al., 2005), and attempt to exploit deep semantic features beyond the work of Mann &amp; Yarowsky (2003). Second, we exploit some features that are available only in a web corpus, such as URL information and related web pages. The paper is organized as follows. Section 2 introduces our rich feature extractions along with their corresponding similarity matrix learning. In Section 3, we analyze the performance of our system. Finally, we draw some conclusions. 2 Methodology Our approach follows a common architecture for named-entity disambiguation: the detection of ambiguous objects, feature extractions and their corresponding similarity matrix learning, and finally clustering. Given a webpage, we </context>
<context position="4305" citStr="Mann &amp; Yarowsky (2003)" startWordPosition="647" endWordPosition="650">er Markham,” “Markham, Alexander,” and “Alexander .\. Markham” (“.\.” can match a middle name). Web pages without any mention of the ambiguous personal name of interest are discarded and receive no further processing. Since it is common for a single document to contain one or more mentions of the ambiguous personal name of interest, there is a need to define the object to be disambiguated. Here, we adopt the policy of “one person per document” (all mentions of the ambiguous personal name in one web page are assumed to refer to the same personal entity in reality) as in Bagga &amp; Baldwin (1998), Mann &amp; Yarowsky (2003) and Gooi &amp; Allan (2004). We therefore define an object as a single entity with the ambiguous personal name in a given web page. This definition of the object (document-level object) might be mistaken, because the mentions of the ambiguous personal name in a web page may refer to multiple entities, but we found that this is a rare case (most of those cases occur in genealogy web pages). On the other hand, a document-level object can include much information derived from that web page, so that it can be represented by rich features. Given this definition of an object, we define a target entity </context>
</contexts>
<marker>Mann, Yarowsky, 2003</marker>
<rawString>G. Mann and D. Yarowsky. 2003. Unsupervised Personal Name Disambiguation. In Proc. of CoNLL2003, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
<author>A Purandare</author>
<author>A Kulkarni</author>
</authors>
<title>Name Discrimination by Clustering Similar Contexts.</title>
<date>2005</date>
<booktitle>In Proc. of the Sixth International Conference on Intelligent Text Processing and Computational Linguistics,</booktitle>
<pages>226--237</pages>
<location>Mexico City, Mexico.</location>
<contexts>
<context position="1635" citStr="Pedersen et al., 2005" startWordPosition="242" endWordPosition="245">lems. It is therefore crucial to develop methodologies that can efficiently disambiguate the ambiguous names from any given set of data. In the paper, we present an approach that combines unsupervised clustering methods with rich feature extractions to automatically cluster returned web pages according to which named entity in reality the ambiguous personal name in a web page refers to. We make two contributions to approaches to web personal name disambiguation. First, we seek to go beyond the kind of bag-ofwords features employed in earlier systems (Bagga &amp; Baldwin, 1998; Gooi &amp; Allan, 2004; Pedersen et al., 2005), and attempt to exploit deep semantic features beyond the work of Mann &amp; Yarowsky (2003). Second, we exploit some features that are available only in a web corpus, such as URL information and related web pages. The paper is organized as follows. Section 2 introduces our rich feature extractions along with their corresponding similarity matrix learning. In Section 3, we analyze the performance of our system. Finally, we draw some conclusions. 2 Methodology Our approach follows a common architecture for named-entity disambiguation: the detection of ambiguous objects, feature extractions and the</context>
<context position="5247" citStr="Pedersen et al., 2005" startWordPosition="811" endWordPosition="814">is is a rare case (most of those cases occur in genealogy web pages). On the other hand, a document-level object can include much information derived from that web page, so that it can be represented by rich features. Given this definition of an object, we define a target entity as an entity (outputted from the EXERT system) that includes a mention of the ambiguous personal name. Then, we define a local sentence as a sentence that contains a mention of any target entity. 2.2 Feature extraction and similarity matrix learning Most of the previous work (Bagga &amp; Baldwin, 1998; Gooi &amp; Allan; 2004; Pedersen et al., 2005) uses token information in the given documents. In this paper, we follow and extend their work especially for a web corpus. On the other hand, com5 http://sds.colorado.edu/EXERT pared to a token, a phrase contains more information for named-entity disambiguation. Therefore, we explore some phrase-based information in this paper. Finally, there are two kinds of feature vectors developed in our system: token-based and phrase-based. A token-based feature vector is composed of tokens, and a phrase-based feature vector is composed of phrases. 2.2.1 Token-based features There is a lot of token infor</context>
</contexts>
<marker>Pedersen, Purandare, Kulkarni, 2005</marker>
<rawString>T. Pedersen, A. Purandare and A. Kulkarni. 2005. Name Discrimination by Clustering Similar Contexts. In Proc. of the Sixth International Conference on Intelligent Text Processing and Computational Linguistics, pages 226-237. Mexico City, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W E Winkler</author>
</authors>
<title>The state of record linkage and current research problems. Statistics of Income Division, Internal Revenue Service Publication R99/04.</title>
<date>1999</date>
<contexts>
<context position="11242" citStr="Winkler, 1999" startWordPosition="1831" endWordPosition="1832">eme, the standard SoftTFIDF (Cohen et al., 2003), is used to calculate the similarity between phrases in the pair of feature vectors; in the second phase, the standard SoftTFIDF is reformulated to calculate the similarity for the pair of phrased-based feature vectors. First, we introduce the standard SoftTFIDF. In a pair of feature vectors S and T, S = (s1, ... , sn ) and T = (t1, ... , tm). Here, si (i = 1...n) and tj (j = 1...m) are substrings (tokens). Let CLOSE(0; S;T) be the set of substrings w ∈ S such that there is some v∈ T satisfying dist(w; v) &gt; θ. The JaroWinkler distance function (Winkler, 1999) is dist(;). For w∈ CLOSE(0; S;T), let D(w; T) = maxv∈T dist(w;v) . Then the standard SoftTFIDF is computed as SoftTFIDF ( ) S,T V( ) V( ) D( w, S × w, T × w, T ( ; ; ) θ S T V&apos; ( ) log (TF 1) log (IDF ) w, S = w,S + × w V (w, S) = where TFw,S is the frequency of substrings w in S, and IDFw is the inverse of the fraction of documents in the corpus that contain w. To compute the similarity for the phrase-based feature vectors, in the second step of “two-level SoftTFIDF,” the substring w is a phrase and dist is the standard SoftTFIDF. So far, we have developed several feature models and learned </context>
</contexts>
<marker>Winkler, 1999</marker>
<rawString>W. E. Winkler. 1999. The state of record linkage and current research problems. Statistics of Income Division, Internal Revenue Service Publication R99/04.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>