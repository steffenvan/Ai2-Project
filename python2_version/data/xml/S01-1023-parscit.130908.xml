<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000135">
<title confidence="0.666279">
ATR-SLT System for SENSEVAL-2 Japanese Translation Task
</title>
<note confidence="0.695602333333333">
Tadashi Kumano, Hideki Kashioka and Hideki Tanaka
ATR Spoken Language Translation Research Laboratories
2-2-2 Hikaridai Seika-cho Soraku-gun Kyoto 619-0288 JAPAN
</note>
<email confidence="0.647282">
{tadashi .kumano, hideki.kashioka, hideki .tanaka}@atr. co jp
</email>
<sectionHeader confidence="0.97424" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999969526315789">
We propose a translation selection system based
on the vector space model.
When each translation candidate of a word
is given as a pair of expressions containing the
word and its translation, selecting the transla-
tion of the word can be considered equivalent to
selecting the expression having the most similar
context among candidate expressions. The pro-
posed method expresses the context information
in &amp;quot;context vectors&amp;quot; constructed from content
words co-occurring with the target word. Con-
text vectors represent detailed information com-
posed of lexical attributes(word forms, semantic
codes, etc.) and syntactic relations (syntactic
dependency, etc.) of the co-occurring words.
We tested the proposed method with the
SENSEVAL-2 Japanese translation task. Preci-
sion/recall was 45.8% to the gold standard in
the experiment with the evaluation set.
</bodyText>
<sectionHeader confidence="0.995588" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999662852941176">
The SENSEVAL-2 Japanese translation task de-
fines a sense of a Japanese word as an English
translation. The same Japanese word in differ-
ent contexts may have different English trans-
lations; therefore, translation ambiguity arises.
Translation Memory (henceforth TM) defin-
ing word senses were given to the task partic-
ipants. Each target word has translation pairs
of Japanese and English expressions as word
sense candidatesl. The target word is marked
in the Japanese expression, but the correspond-
ing part is unspecified in the English expression.
Hence, selecting the most appropriate transla-
tion of the target Japanese word in the evalua-
tion expression can be considered to be equiv-
alent to selecting the expression with the most
similar context in the TM. This is equivalent
to the word sense disambiguation problem in a
single language.
&apos;Each target word has 21.6 pairs on average.
Generally, word sense disambiguation uses
context information, such as the frequency of
words that co-occur with the target word.
The context information is learned from the
correctly-annotated training corpora. However,
no training corpus was given for the task and
the given TM had shorter contexts because the
TM expressions were rather incomplete. There-
fore, instead of learning the co-occurring words
with the target word from the training corpora,
we extract detailed information from the TM
expressions as context information. We utilize
the information of co-occurring words with the
target word (context words) as shown below.
</bodyText>
<listItem confidence="0.9972795">
• lexical attributes (word form, part-of-
speech, semantic codes on thesaurus, etc.)
• syntactic relations to the target word (de-
pendency relation, etc.)
</listItem>
<bodyText confidence="0.999433083333333">
We employed the vector space model, which is
used for text retrieval (Salton and McGill, 1983)
to calculate the similarity between the context
word information of evaluation expressions and
those of the TM. The detailed context informa-
tion are expressed as &amp;quot;context vectors.&amp;quot; We use
cosine values between context vectors as a mea-
sure of similarity.
In this paper, we will explain first how to con-
struct &amp;quot;context vectors,&amp;quot; and then show the ac-
curacy of the selection experiment to the correct
data (gold standard).
</bodyText>
<sectionHeader confidence="0.9419105" genericHeader="method">
2 Translation Selection Using
Context Vectors
</sectionHeader>
<subsectionHeader confidence="0.8989215">
2.1 Context Vectors
2.1.1 Concept
</subsectionHeader>
<bodyText confidence="0.997364666666667">
We will explain how to construct a context vec-
tor from an expression el with the target word
&amp;quot; r (aida; interval)&amp;quot;, as an illustration.
Figure 1 shows the expression, which con-
tains the content words &amp;quot;*A&apos;a (fuufu; married
couple)&amp;quot;, &amp;quot;TA (kodomo; child)&amp;quot;, and &amp;quot;-`1 I 41
</bodyText>
<page confidence="0.999675">
95
</page>
<tableCaption confidence="0.998977">
Table 1: Context Vectors Construction
</tableCaption>
<table confidence="0.8471416">
Type of syntactic relationship to the target word
modifying target word modified by target word target following all context
in case relation: in case relation: word words words
WO NO NI WO NO NI • • -
fuufo-no aula-nz kodorno-ga urnarcru kfuuju
(el) &apos; N 0) rH1 vi. -Tilt -i•ti..7.,) (a baby is born to the couple)&amp;quot; 0d 07720
0 fuufu 0 0 0 0 umareru 0 aida kodomo
umareru
umareru
shigoto-no aida-wo nutte rnimai-ni iku
</table>
<figure confidence="0.503566777777778">
(e2) &apos; 1-1 T or) MI da-D -C RAO 4: fr &lt; to visit in hospital at the interval during one&apos;s work)&amp;quot;
_
0 shigoto ci nutte 0 l aida nutte shiqoto
mrmaz nutte
mimai
iku iku
Amodifying_TW• A modified_by_TW )&apos;target: • • Afollow &apos;all
The ratio of vector components for each word attribute
ce2
</figure>
<bodyText confidence="0.998826411764706">
(umareru; be born)&amp;quot;, and shows that the
phrases containing these content words have
some syntactic dependencies.
We then prepare a table that enumerates all
possible syntactic relations between target word
and context words, as in Table 1. For each ex-
pression, we then insert corresponding words to
the column for each syntactic relation. For ex-
ample, the row for el of Table 1 can be obtained
by the enumeration of expression Cl. If a syntac-
tic relation is applicable to several words, such
as the relation &amp;quot;following words&amp;quot; in Table 1, all
of them are enumerated in the same column.
If no content word comes under the syntactic
relation, it is assigned empty (0).
Each row of the table is designated a &amp;quot;context
vector&amp;quot; Ce of a corresponding expression e.
</bodyText>
<subsectionHeader confidence="0.6583">
2.1.2 Calculation of Context Vectors
</subsectionHeader>
<bodyText confidence="0.9819854">
In the preceding section, the table was explained
as if it had context words in its elements, but
&amp;quot;word attribute vectors&amp;quot; of context words are
assigned to them practically. Hence, context
vectors are the conjunctions of &amp;quot;word attribute
vectors.&amp;quot; Each word attribute vector aw of a
word w expresses lexical attributes of w, such as
POS or semantic code. Word attribute vectors
have a fixed dimension number, and each ele-
( couple between child is born )
</bodyText>
<figure confidence="0.8881795">
fuufu-no aida-ni kodomo-ga umareru
Expression: MT3 rgi -7.1ft
Dependencies:
Syntactic NO NI GA
</figure>
<figureCaption confidence="0.957295">
Figure 1: Syntactic Dependencies in Expres-
sion el
</figureCaption>
<bodyText confidence="0.992125612903226">
ment has a non-negative value. The procedure
for constructing word attribute vectors will be
described below in Section 2.1.3.
When several context words fall under
the same syntactic relation like kodomo and
umareru as we can sec in the &amp;quot;following words&amp;quot;
relation in Table 1, the word vectors assigned to
the relation is calculated by selecting the max-
imum value for every vector component among
values of all words in that relation. The calcu-
lation named vecmax is defined as follows:
vecmax a =-- (b1, b2, • - - bn),
z=1 ..m
where
{
ai is a n-dimensional vector,
ai3 is a j-th element of vector ai, and
bi --- max a.
i=1...m
When joining word attribute vectors into a
context vector, each word attribute vector is
given a weight in order to get a certain ratio of
vector components for each syntactic relation.
This is necessary to specify the degree of the
contribution to the context vectors according to
the type of syntactic relation. For example, as-
suming that the ratio of the vector components
is specified using )&apos;syn_rel (syn_rel denotes a spe-
cific syntactic relation type) as shown in Ta-
ble 1, the context vector ce, of the expression
el will be calculated as follows:
</bodyText>
<equation confidence="0.958494">
ce, &amp;quot; • e Amodzfyzng_TW lafuufut
afuufu e
aurnareru
ED mod2fied_by_TW *,
laurnarerul
</equation>
<page confidence="0.996873">
96
</page>
<tableCaption confidence="0.996532">
Table 2: Constructing Word Attribute Vectors
</tableCaption>
<table confidence="0.981730714285714">
afttlifIL
akOdOMO
a11771arC711.
Type of syntactic attribute
Emergent Form Pronunciation PUS
-*lt -Hit -i4-1. Z fu-u-fu ko-do-mo u-ma-re-ru _ • • • noun verb • • -
ne_form 0 0 0 r 1 e_pron 0 0 0 ripos 0 0
0 72e_forrn 0 0 0 rle_pron 0 0 71pos 0 0
0 0 7),for-in 0 0 &apos;0 Tle_pron 0 0 71pos 0
type of syntactic attribute
Semantic Code
N86 N85 N74 N72 N5 N4 N3 N2 Ni P26 P17 P16 P1
0 0 ,Isem _n ,/sem ,Isem risem &apos;,form &apos;Ism. 0 0 0 0 0
&apos;loom gsem
\F-7 V77 -V7-7 -1-&apos;7 f_7 x/7 VT
,isem &apos;loom ,Isent qsoort &apos;Isom &apos;Isom
sem 0 0 0 0 0
riS CM. ,I0071/ &apos;,Wm &apos;loom
Vg &apos;16.
0 0 0 0 0 0 0 0 0 0
Ni5.1 NA \/7 -Niq
</table>
<figure confidence="0.900034454545454">
(ID A target aaid a e ° •
laaida
vecmax ai
iEfkodomo,urnareral
ED Afollow vecmax ai
iE{kodorno,umareru}
vecmax ai
ielfwafu,kodomo,umarerul
vecmax ai
i E { fuufu, kodomo,umareru}
2.1.3 Word Attribute Vectors
</figure>
<bodyText confidence="0.999449206896552">
For lexical attributes, we prepare another table
similar to that for context words described in
the previous section. Table 2 shows that the ta-
ble enumerates attributes for all words appear-
ing for each lexical attribute. For each word,
values are assigned to the column correspond-
ing to the lexical attribute. The value zero is as-
signed to the column when the lexical attribute
is not applicable to the word. In Table 2, the
lexical attributes of each context word in ex-
pression el are expressed in each row. The row
is called &amp;quot;word lexical attributes&amp;quot; au, of the cor-
responding word w.
We employ the semantic codes of a Japanese
thesaurus as the semantic attributes. A seman-
tic code may have superordinates because a the-
saurus represents semantic relations on the hi-
erarchical tree structure. For example, the word
fuufu has semantic codes on seven levels, from
&amp;quot;Noun 74&amp;quot; on the leaf node to &amp;quot;Noun 1&amp;quot; on the
top, in the thesaurus &amp;quot;Nihongo Goi Taikei (Ike-
hara et al., 1997)&amp;quot; that we used. We treat all
semantic codes as semantic attributes of word
attribute vectors, and assign values to the cor-
responding elements equally.
Each lexical attribute of a word attribute vec-
tor should be assigned a value, the ratio of com-
ponent vectors for each word lexical attribute
being the specific value77wordattr (word_attr de-
</bodyText>
<page confidence="0.563491">
_
</page>
<bodyText confidence="0.9996136">
notes a specific word attribute type) in Table 2.
Semantic attributes may have multiple compo-
nents to be assigned values, each component
should be normalized by the number of the com-
ponents (See Table 2).
</bodyText>
<subsectionHeader confidence="0.99445">
2.2 Translation Selection
</subsectionHeader>
<bodyText confidence="0.9999905">
To select an appropriate translation for an eval-
uation expression containing a target Japanese
word, we need to compare the context vector of
the evaluation expression with the context vec-
tors of all candidate Japanese expressions in the
TM. We then choose the candidate whose cosine
value to the context vector of the evaluation ex-
pression is the maximum.
Each expression should have a unique con-
text vector in order to compare context vectors.
But context words, like target words, have am-
biguity, and they have several candidates for se-
mantic codes in the thesaurus. It seems unac-
ceptable that the method requires disambigua-
tion of context words before disambiguation of
the target word. Therefore, we decided not to
disambiguate context words before constructing
the context vector. Instead, we construct &amp;quot;con-
text vector candidates&amp;quot; from all combinations
of the context word candidates. All combina-
tions of the context vector candidates are used
for calculating similarity, and the combination
that has the maximum value is selected as the
pair of the evaluation and the TM expressions.
We can resolve ambiguity of context words when
selecting the translation of the target word.
</bodyText>
<sectionHeader confidence="0.966193" genericHeader="method">
3 Description of Participating
System
</sectionHeader>
<subsectionHeader confidence="0.979231">
3.1 Resources, etc.
</subsectionHeader>
<bodyText confidence="0.9370645">
Our system used the following resources in ad-
dition to the given TM and evaluation set.
</bodyText>
<page confidence="0.999796">
97
</page>
<tableCaption confidence="0.996581">
Table 3. Employed Parameters
</tableCaption>
<table confidence="0.981977708333333">
word attribute type ratio
Emergent Word Form 1
Pronunciation 1
Standard Form 4
(standard) Pronunciation 4
Part-Of-Speech 0
Conjugated Form 1
Semantic Code 12
syntactic relation type ratio
modifying target word (case relation: specific) 3
(case relation: non-specific) 1
modified by target word (case relation: specific) 3
(case relation: non-specific) 1
target word 2
the phrase containing target word 2
preceding target word 1
following target word 1
all content words 2
Japanese Morphological Analyzer:
JUMAN (Kurohashi and Nagao, 1998)
Japanese Syntactic Analyzer:
KNP (Kurohashi, 1998)
Thesaurus:
Nihongo Goi Taikei (Ikehara et al., 1997)
</table>
<subsectionHeader confidence="0.958841">
3.2 Parameters
</subsectionHeader>
<bodyText confidence="0.99948275">
The following parameters have significant ef-
fects on the accuracy of our method.
1. The 77wordattr ratio of vector compo-
nents specified for each word attribute
when making word attribute vectors (Sec-
tion 2.1.3)
2. The Asy„,/ ratio of the vector components
specified for each syntactic relation when
joining word attribute vectors into context
vectors (Section 2.1.2)
However, we did not optimize the parameters
in our participating system, because of the task
specification that no training corpus was given
and the time limitations in the course of system
development. Parameters were given manually
by considering the parameter functions. All of
the lexical and syntactic attributes and parame-
ters that represent the ratio between attributes,
which our participating system employed, are
shown in Table 3.
</bodyText>
<sectionHeader confidence="0.999098" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.9996127">
Our participating system marked both the pre-
cision and the recall at 45.8% of the correct data
(the gold standard) in the evaluation corpus se-
lection. However, our participating system had
some serious bugs in the vector normalization
process. After correcting the bugs, we made
another selection experiment using the same pa-
rameters described in Section 3.2. The accu-
racy of the corrected system was 49.3% (nouns:
50.0%, predicates: 48.5%).
</bodyText>
<sectionHeader confidence="0.99753" genericHeader="conclusions">
5 Summary
</sectionHeader>
<bodyText confidence="0.947536307692308">
We proposed a translation selection method for
the SENSEVAL-2 Japanese translation task. The
proposed method calculates the similarity be-
tween an evaluation expression containing the
target word and Japanese expressions contain-
ing the same word in the TM. For calculating
similarity, &amp;quot;context vectors&amp;quot; are constructed.
Context vectors represent lexical attributes of
context words and syntactic relations between
context words and the target word. The system
employed the proposed method with an accu-
racy of 49.3% after bug elimination.
Future plans are as follows.
1. To optimize parameters using the gold
standard. We would like to use the opti-
mized parameters to study the relation be-
tween context information type and accu-
racy on translation selection. In addition,
we will examine whether employed lexical
and syntactic attributes are appropriate for
the task.
2. To apply the machine learning method to
the task, preparing the training corpora.
We will make use of the detailed context
information proposed, the lexical and syn-
tactic attributes, at machine learning.
</bodyText>
<sectionHeader confidence="0.998688" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99928075">
S. Ikehara, M. Miyazaki, S. Shirai, A. Yokoo,
H. Nakaiwa, K. Ogura, Y. Oyama, and
Y. Hayashi, editors. 1997. Nihongo Goi Taikei,
volume 1-5. Iwanami Shoten. (in Japanese).
S. Kurohashi and M. Nagao, 1998. Japanese Mor-
phological Analysis System JUMAN version 3.61.
Kyoto University. (in Japanese).
S. Kurohashi, 1998. Japanese Syntactic Analysis
System KNP version 2.0 b6 user&apos;s manual. Kyoto
University. (in Japanese).
G. Salton and M. J. McGill. 1983. Introduction to
Modern Information Retrieval. McGraw-Hill.
</reference>
<page confidence="0.996227">
98
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.578543">
<title confidence="0.999787">System for Translation Task</title>
<author confidence="0.969836">Tadashi Kumano</author>
<author confidence="0.969836">Hideki Kashioka</author>
<author confidence="0.969836">Hideki</author>
<affiliation confidence="0.976943">ATR Spoken Language Translation Research</affiliation>
<address confidence="0.678068">2-2-2 Hikaridai Seika-cho Soraku-gun Kyoto 619-0288</address>
<email confidence="0.859368">hideki.kashioka,hideki.tanaka}@atr.cojp</email>
<abstract confidence="0.9984796">We propose a translation selection system based on the vector space model. When each translation candidate of a word is given as a pair of expressions containing the word and its translation, selecting the translation of the word can be considered equivalent to selecting the expression having the most similar context among candidate expressions. The proposed method expresses the context information in &amp;quot;context vectors&amp;quot; constructed from content words co-occurring with the target word. Context vectors represent detailed information composed of lexical attributes(word forms, semantic codes, etc.) and syntactic relations (syntactic dependency, etc.) of the co-occurring words. We tested the proposed method with the Japanese translation task. Precision/recall was 45.8% to the gold standard in the experiment with the evaluation set.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Ikehara</author>
<author>M Miyazaki</author>
<author>S Shirai</author>
<author>A Yokoo</author>
<author>H Nakaiwa</author>
</authors>
<title>Nihongo Goi Taikei, volume 1-5. Iwanami Shoten.</title>
<date>1997</date>
<editor>K. Ogura, Y. Oyama, and Y. Hayashi, editors.</editor>
<note>(in Japanese).</note>
<contexts>
<context position="8916" citStr="Ikehara et al., 1997" startWordPosition="1497" endWordPosition="1501">when the lexical attribute is not applicable to the word. In Table 2, the lexical attributes of each context word in expression el are expressed in each row. The row is called &amp;quot;word lexical attributes&amp;quot; au, of the corresponding word w. We employ the semantic codes of a Japanese thesaurus as the semantic attributes. A semantic code may have superordinates because a thesaurus represents semantic relations on the hierarchical tree structure. For example, the word fuufu has semantic codes on seven levels, from &amp;quot;Noun 74&amp;quot; on the leaf node to &amp;quot;Noun 1&amp;quot; on the top, in the thesaurus &amp;quot;Nihongo Goi Taikei (Ikehara et al., 1997)&amp;quot; that we used. We treat all semantic codes as semantic attributes of word attribute vectors, and assign values to the corresponding elements equally. Each lexical attribute of a word attribute vector should be assigned a value, the ratio of component vectors for each word lexical attribute being the specific value77wordattr (word_attr de_ notes a specific word attribute type) in Table 2. Semantic attributes may have multiple components to be assigned values, each component should be normalized by the number of the components (See Table 2). 2.2 Translation Selection To select an appropriate tr</context>
<context position="11493" citStr="Ikehara et al., 1997" startWordPosition="1905" endWordPosition="1908">atio Emergent Word Form 1 Pronunciation 1 Standard Form 4 (standard) Pronunciation 4 Part-Of-Speech 0 Conjugated Form 1 Semantic Code 12 syntactic relation type ratio modifying target word (case relation: specific) 3 (case relation: non-specific) 1 modified by target word (case relation: specific) 3 (case relation: non-specific) 1 target word 2 the phrase containing target word 2 preceding target word 1 following target word 1 all content words 2 Japanese Morphological Analyzer: JUMAN (Kurohashi and Nagao, 1998) Japanese Syntactic Analyzer: KNP (Kurohashi, 1998) Thesaurus: Nihongo Goi Taikei (Ikehara et al., 1997) 3.2 Parameters The following parameters have significant effects on the accuracy of our method. 1. The 77wordattr ratio of vector components specified for each word attribute when making word attribute vectors (Section 2.1.3) 2. The Asy„,/ ratio of the vector components specified for each syntactic relation when joining word attribute vectors into context vectors (Section 2.1.2) However, we did not optimize the parameters in our participating system, because of the task specification that no training corpus was given and the time limitations in the course of system development. Parameters wer</context>
</contexts>
<marker>Ikehara, Miyazaki, Shirai, Yokoo, Nakaiwa, 1997</marker>
<rawString>S. Ikehara, M. Miyazaki, S. Shirai, A. Yokoo, H. Nakaiwa, K. Ogura, Y. Oyama, and Y. Hayashi, editors. 1997. Nihongo Goi Taikei, volume 1-5. Iwanami Shoten. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kurohashi</author>
<author>M Nagao</author>
</authors>
<title>Japanese Morphological Analysis System JUMAN version 3.61. Kyoto University.</title>
<date>1998</date>
<note>(in Japanese).</note>
<contexts>
<context position="11389" citStr="Kurohashi and Nagao, 1998" startWordPosition="1891" endWordPosition="1894">sources in addition to the given TM and evaluation set. 97 Table 3. Employed Parameters word attribute type ratio Emergent Word Form 1 Pronunciation 1 Standard Form 4 (standard) Pronunciation 4 Part-Of-Speech 0 Conjugated Form 1 Semantic Code 12 syntactic relation type ratio modifying target word (case relation: specific) 3 (case relation: non-specific) 1 modified by target word (case relation: specific) 3 (case relation: non-specific) 1 target word 2 the phrase containing target word 2 preceding target word 1 following target word 1 all content words 2 Japanese Morphological Analyzer: JUMAN (Kurohashi and Nagao, 1998) Japanese Syntactic Analyzer: KNP (Kurohashi, 1998) Thesaurus: Nihongo Goi Taikei (Ikehara et al., 1997) 3.2 Parameters The following parameters have significant effects on the accuracy of our method. 1. The 77wordattr ratio of vector components specified for each word attribute when making word attribute vectors (Section 2.1.3) 2. The Asy„,/ ratio of the vector components specified for each syntactic relation when joining word attribute vectors into context vectors (Section 2.1.2) However, we did not optimize the parameters in our participating system, because of the task specification that n</context>
</contexts>
<marker>Kurohashi, Nagao, 1998</marker>
<rawString>S. Kurohashi and M. Nagao, 1998. Japanese Morphological Analysis System JUMAN version 3.61. Kyoto University. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kurohashi</author>
</authors>
<title>Japanese Syntactic Analysis System KNP version 2.0 b6 user&apos;s manual. Kyoto University.</title>
<date>1998</date>
<note>(in Japanese).</note>
<contexts>
<context position="11440" citStr="Kurohashi, 1998" startWordPosition="1899" endWordPosition="1900">ble 3. Employed Parameters word attribute type ratio Emergent Word Form 1 Pronunciation 1 Standard Form 4 (standard) Pronunciation 4 Part-Of-Speech 0 Conjugated Form 1 Semantic Code 12 syntactic relation type ratio modifying target word (case relation: specific) 3 (case relation: non-specific) 1 modified by target word (case relation: specific) 3 (case relation: non-specific) 1 target word 2 the phrase containing target word 2 preceding target word 1 following target word 1 all content words 2 Japanese Morphological Analyzer: JUMAN (Kurohashi and Nagao, 1998) Japanese Syntactic Analyzer: KNP (Kurohashi, 1998) Thesaurus: Nihongo Goi Taikei (Ikehara et al., 1997) 3.2 Parameters The following parameters have significant effects on the accuracy of our method. 1. The 77wordattr ratio of vector components specified for each word attribute when making word attribute vectors (Section 2.1.3) 2. The Asy„,/ ratio of the vector components specified for each syntactic relation when joining word attribute vectors into context vectors (Section 2.1.2) However, we did not optimize the parameters in our participating system, because of the task specification that no training corpus was given and the time limitation</context>
</contexts>
<marker>Kurohashi, 1998</marker>
<rawString>S. Kurohashi, 1998. Japanese Syntactic Analysis System KNP version 2.0 b6 user&apos;s manual. Kyoto University. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>M J McGill</author>
</authors>
<title>Introduction to Modern Information Retrieval.</title>
<date>1983</date>
<publisher>McGraw-Hill.</publisher>
<contexts>
<context position="2921" citStr="Salton and McGill, 1983" startWordPosition="435" endWordPosition="438">task and the given TM had shorter contexts because the TM expressions were rather incomplete. Therefore, instead of learning the co-occurring words with the target word from the training corpora, we extract detailed information from the TM expressions as context information. We utilize the information of co-occurring words with the target word (context words) as shown below. • lexical attributes (word form, part-ofspeech, semantic codes on thesaurus, etc.) • syntactic relations to the target word (dependency relation, etc.) We employed the vector space model, which is used for text retrieval (Salton and McGill, 1983) to calculate the similarity between the context word information of evaluation expressions and those of the TM. The detailed context information are expressed as &amp;quot;context vectors.&amp;quot; We use cosine values between context vectors as a measure of similarity. In this paper, we will explain first how to construct &amp;quot;context vectors,&amp;quot; and then show the accuracy of the selection experiment to the correct data (gold standard). 2 Translation Selection Using Context Vectors 2.1 Context Vectors 2.1.1 Concept We will explain how to construct a context vector from an expression el with the target word &amp;quot; r (ai</context>
</contexts>
<marker>Salton, McGill, 1983</marker>
<rawString>G. Salton and M. J. McGill. 1983. Introduction to Modern Information Retrieval. McGraw-Hill.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>