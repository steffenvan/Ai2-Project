<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000006">
<title confidence="0.996942">
Discriminative Power and Retrieval Effectiveness of Phrasal
Indexing Terms
</title>
<author confidence="0.98356">
Sumio Fujita
</author>
<affiliation confidence="0.8638645">
Justsystem corporation
Brainspark, Tokushima, Japan
</affiliation>
<email confidence="0.997055">
Email: Sumiq_,Fujita@justsystem.cojp
</email>
<sectionHeader confidence="0.993845" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9996621875">
In spite of long controversy, effectiveness of
phrasal indexing is not yet clear.
Recently, correlation between query length and
effect of phrasal indexing is reported.
In this paper, terms extracted from the topic set
of the NACSIS test collection 1 are analyzed
utilizing statistic tools in order to show
distribution characteristics of single
word/phrasal terms with regard to relevant/non-
relevant documents. Phrasal terms are found to
be very good discriminators in general but not
all of them are effective as supplemental phrasal
terms. A distinction of informative / neutral /
destructive phrasal terms is introduced. Retrieval
effectiveness is examined utilizing query weight
ratio of these three categories of phrasal terms.
</bodyText>
<sectionHeader confidence="0.961431" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.999920438596491">
Longer queries are not necessarily better than
shorter queries in view of retrieval effectiveness,
since longer queries may contain so-called noisy
terms that hurt the performance.
Given relevance judgements, we can say which
terms are noisy and which are not with regard to
a certain topic description and a test collection.
We can confirm that a term is good to
discriminate subject concepts if relevant
documents contain such terms and non-relevant
documents do not contain them and that a term
is noisy if the situation is the opposite.
The problem here is that not only noisy terms
but also good terms can harm the performance in
some cases where term weighting is not
adequate or terms are redundant.
One example of such cases is complex terms
like supplemental phrases or overlap bigrams
which violate term independence assumption.
Phrasal terms are utilized either as replacement
of single words or as supplemental units for
single words, but according to our experience,
phrasal terms as replacement of single words do
not perform well. Supplemental phrasal terms
works better in spite of the violation of term
independence assumption.
Recent studies uncovered the correlation
between phrase effectiveness and query
length(Fujita, 2000).
In this paper, we will see the problem of
effectiveness of phrasal terms from two different
viewpoints utilizing a large test collection for
Japanese text retrieval and statistical tools.
NACSIS test collection 1 (NTCIR, 1999), which
consists of a collection of abstracts of scientific
papers ( 330,000 records, 590MB in text), two
sets of topic description ( 30 topics for training
and 53 topics for evaluation ) and relevance
judgement, provides us of a good opportunity
for this purpose.
Topic description of NACSIS test collection 1
contains four different fields, just like early
versions of TREC topics, as follows:
&lt;title&gt; fields consist of one ( typically simple)
noun phrase.
&lt;description&gt; fields consist of one ( typically
simple ) sentence.
&lt;narrative&gt; fields consist of 3 to 12 sentences
and contain detailed explanation of the topic,
term definition, background knowledge, purpose
of the search, preference in text types, criteria of
relevance judgement and so on.
&lt;concepts&gt; fields consist of lists of keywords
corresponding to principal concepts in the
information need.
Combining these four fields, different length of
query sets for the same topics are prepared.
</bodyText>
<page confidence="0.999045">
47
</page>
<table confidence="0.999277947368421">
Topic field used Avg.Precl Avg.Prec2 Avg.Prec2 Avg. Avg.
(Single (Single - number number
words words &amp; Avg.Precl of total of phrasal
only) Phrases) terms terms
&lt;description&gt; 0.3143 0.2846 -0.0297 8.8 1.9
&lt;title&gt; 0.2555 0.2265 -0.029 4.1 1.0
&lt;fitle&gt;,&lt;description&gt; 0.3334 0.3079 -0.0255 9.2 2.1
&lt;fitle&gt;,&lt;narrative&gt; 0.3095 0.3001 -0.0094 45.0 10.3
&lt;narrative&gt; 0.2985 0.2895 -0.009 44.7 10.2
&lt;description&gt;,&lt;narrative&gt; 0.3161 0.3163 0.0002 46.4 10.8
&lt;title&gt;,&lt;description&gt;,&lt;narrative&gt; 0.321 0.3233 0.0023 46.5 10.9
&lt;description&gt;,&lt;concepts&gt; 0.3672 0.3786 0.0114 25.4 5.2
&lt;narrative&gt;,&lt;concepts&gt; 0.364 0.3761 0.0121 57.0 12.5
&lt;title&gt;,&lt;description&gt;,&lt;concepts&gt; 0.379 0.3926 0.0136 25.5 5.3
&lt;title&gt;,&lt;narrative&gt;,&lt;concepts&gt; 0.3702 0.3844 0.0142 57.3 12.7
&lt;description&gt;,&lt;narrative&gt;,&lt;concepts&gt; 0.3681 0.3839 0.0158 58.4 13.1
&lt;title&gt;,&lt;description&gt;,&lt;narrative&gt;,&lt;concepts&gt; 0.371 0.3886 0.0176 58.4 13.1
&lt;concepts&gt; 0.3316 0.3504 0.0188 20.9 4.1
&lt;title&gt;,&lt;concepts&gt; 0.352 0.3711 0.0191 21.8 4.5
</table>
<tableCaption confidence="0.999903">
Table 1: Performance comparison using 15 different versions of queries combining 4 fields
</tableCaption>
<sectionHeader confidence="0.905938" genericHeader="method">
1. Phrasal Indexing
</sectionHeader>
<bodyText confidence="0.999779">
For the baseline run experiments, we utilized the
engine of Conceptbase Search 1.2, a commercial
based search engine adopting vector space
model approach.
</bodyText>
<subsectionHeader confidence="0.9990645">
1.1. Linguistic Phrases as Indexing Units
for Japanese Text Retrieval
</subsectionHeader>
<bodyText confidence="0.999783210526316">
For automatic indexing of Japanese written text,
once word boundary is detected by
morphological analysis processing, word based
approach normally adopted in English IR can be
applied. Although computationally more
expensive than in English, the accuracy of
Japanese morphological analysis is quite high
and sufficient for IR purpose.
Our approach consists of utilizing noun phrases
extracted by linguistic processing as
supplementary indexing terms in addition to
single word terms contained in phrases. Phrases
and constituent single word terms are treated in
the same way, both as independent terms, where
the frequency of each term is counted
independently based on its occurrences.
Linguistic phrases are normally contiguous kanji
or katakana word sequences and internal phrase
structures are ignored.
</bodyText>
<subsectionHeader confidence="0.9998785">
1.2. Query Length and Effectiveness of
Phrasal Indexing
</subsectionHeader>
<bodyText confidence="0.999950047619048">
Among evaluation experiments of the NTC1R1
workshop, correlation between query length and
the effect of phrasal indexing is reported in
(Fujita, 1999).
NTOR topic description consists of four fields
namely &lt;title&gt;, &lt;description&gt;, &lt;narrative&gt; and
&lt;concepts&gt; as shown in the previous chapter.
The combination of these four fields makes 15
different versions of queries for each topic.
These 15 different versions of queries for 53
topics are examined with phrasal terms and with
only single word terms.
Table 1 shows the performance with 15 versions
of queries, where we compared two types of
indexing language in question i.e. single words
vs. single words + supplemental phrases.
Performance is indicated as non-interpolated
average precision macro averaged for 53 topics.
Since this experiment is designed to clarify the
effect of different length of queries, the
following settings are chosen:
</bodyText>
<page confidence="0.996527">
48
</page>
<listItem confidence="0.982853">
1) no pseudo feedback procedure is processed,
2) no down-weighting coefficient is applied for
phrasal terms,
3) no field specific importance coefficient is
applied.
</listItem>
<bodyText confidence="0.999887588235294">
Consequently, absolute performance is much
worse than our best performing runs.
Out ,of 15 versions of query sets, 10 times
phrasal indexing performs better than single
word only indexing, and 5 times vice versa. This
is exactly the situation described in literature
that the effect of phrasal indexing is inconsistent
and uncertain.
We found out that there is clear correlation
between the difference of average precision and
number of terms contained in the query.
Pearson&apos;s correlation coefficient between Avg.
prec2 - Avg.precl and average number of terms
accounts for 0.57, while 0.52 between Avg.
prec2 - Avg.prec 1 and average number of
phrases. Eliminating 8 query versions containing
&lt;concepts&gt; field, correlation coefficients
become 0.96 and 0.95 respectively.
&lt;concepts&gt; fields containing keywords that are
essentially noun phrases, tend to favor phrasal
indexing otherwise when using only one of the
fields, single word runs perform better.
The situation is different when more than two
fields are combined. Combining &lt;title&gt;,
&lt;description&gt; and &lt;narrative&gt; fields, the
supplemental phrasal run performs better than
the single word run.
We can see that the length of query, which is
number of features in the scoring function, is
important factor as well as quality of phrasal
terms extracted from topic description, in order
to evaluate phrasal indexing.
Two aspects of characteristics of phrasal terms
should be considered:
</bodyText>
<listItem confidence="0.9675716">
1) Are the phrasal terms good discriminator of
subject domain?
2) Do the supplemental phrasal terms cause
some undesirable influence to original word
based queries?
</listItem>
<bodyText confidence="0.9987614">
In the chapter 2, phrasal terms extracted from
the topic set of the NACSIS test collection 1 are
examined from the viewpoints of their
discriminative power. In the chapter 3, we will
see another aspect of retrieval effectiveness.
</bodyText>
<table confidence="0.99937025">
Df Term
98561 i&apos;Jf(research)
83016 MA(result)
69911 3
64675 **(report)
63956 444(characteristics)
61063 WA(structure)
58664 t-&amp;(method)
58410 4.i.A &amp;quot;-- JA (system)
56807 *(analysis)
50246 WW(influence)
47620 J(evaluation)
42130 f 1.1)ER (use)
41584 .&amp;i1-&apos;(model)
41238 W41(process)
37567 B(time)
</table>
<tableCaption confidence="0.6205255">
Table 2: High document
frequency single word terms
</tableCaption>
<table confidence="0.999891833333333">
Df Term
12817 VE,t it(effectiveness)
6969 3 K5(3-dimension)
5716 ..--,-- it, {E(modeling)
5183 3&apos;0* fi4J(efficient)
4659 YE 7 7 4 /&apos;&apos;—(optic fiber)
2648 fl.A A&amp;quot;(user)
1795 AN V-(old people)
1661 A&apos;0) f IJA(effective use)
1347 it&apos; tO 7 il, 9 X./A
(genetic algorithm)
1345 J(hierarchy)
1038 a t m 41E(ATM network)
860 L-7&apos;l ,=., 7 (groupware)
799 Al 011E(artificia1 intelligence)
777 &apos;f&amp;quot;— 5 A((data transmission)
672 3-)tt MM
(distributional environment)
</table>
<tableCaption confidence="0.9870025">
Table 3: High document frequency
phrasal terms
</tableCaption>
<page confidence="0.985192">
49
</page>
<figure confidence="0.999000970588235">
Of 013 0,
ROOM
01 .3
POW
0.1 0.13
/400,0-00247121.,
1.0044.2227015)
011
OD
at
03
•
&amp;quot;7&amp;quot;&apos;&amp;quot; • &amp;quot;
o •
i• • • ,
&amp;quot;.••••
• •
3 •.e• • •: •
•
OA
0.2
0 &apos;I&apos;&apos;&apos;. •
OBS
oceeo-wo:coveu
010,73-0.001■13,
Os
00
OS
&amp;quot;
at
F.
C.,
025 0.3 033 04 ocr. 02 03
1.003 Mfr.
</figure>
<figureCaption confidence="0.999921">
Figure 1: p(occirel) as function of p(occ)
</figureCaption>
<note confidence="0.5037745">
Left above: short query single words, Right above: short query phrases
Left below: long query single words, Right below: long query phrases
</note>
<sectionHeader confidence="0.991736" genericHeader="method">
2. NTCIR Data Analysis
</sectionHeader>
<bodyText confidence="0.999378">
Greiff presented an analysis of TREC data
plotting each query terms in view of
distributions in the whole document collection
and in relevant document sets(Greiff, 1998) and
Pickens et al. applied this analysis for statistical
phrases(Pickens et al, 2000).
Adopting their plotting approach, we will try to
clarify distribution characteristics of phrasal
terms using mainly p(occirel) and p(occ) which
are computed as document frequencies of the
term in relevant documents /the whole collection
respectively divided by each number of
documents.
</bodyText>
<subsectionHeader confidence="0.8852265">
2.1. Occurrence in Relevant Documents
and in Non-relevant Documents
</subsectionHeader>
<bodyText confidence="0.99574192">
Table 2 and Table 3 shows high document
frequency terms extracted from the short query
set of test topics.
A short query refers to a query constructed using
only &lt;description&gt; field of topic description and
a long query, all fields of topic description.
First, plotting of p(occinon-rel) as function of
p(occ) is not interesting since approximately the
relation p(occjnon-rel)=p(occ) is observed.
This is not surprising because number of
relevant documents are generally very small and
p(occinon-rel) can be approximated by p(occ).
From Table 2 and Table 3, we can imagine that
the distribution characteristics of phrasal terms
are almost same as single words i.e. Zipfian
distribution but document frequencies of phrasal
terms are much smaller than single words.
It seems difficult to get clear intuition about
term distribution characteristics from Figure 1,
where p(occirel) is plotted as function of p(occ).
The same p(occ) value for some frequent terms
found in plots indicates multiple occurrences of
a term in different queries.
As Greiff suggests, a different visualization is
desirable for this graph.
</bodyText>
<page confidence="0.941854">
50
</page>
<table confidence="0.920375782608695">
1
„
•
.- It
-•!:::.•,-..-
&apos;‘) •,...
-. • • •-: **&amp;quot;.. -1•;i7,-1,..
&apos; *, :.41._.
...4%.:,&apos;• _
2.00222202224.00.02C2011).0.2
. .
.• •-:-.1••.: .- , .
- &amp;quot;.? -. ,.•&apos;: •
. .
&apos;&apos; : =-4;:ek:
• 1
&apos; - . • &amp;quot; -
.
. . •••■:&apos;7&apos;
.
-12 .42 -e -e .4. .... • •$, 1
•
. - . .. ....... _, ,
</table>
<figure confidence="0.994947615384615">
t001222021.
•
• • • • a • • ••• • • •• •• •
1.00000.0
I.Ca00202:0-1200.030020:4100020
..
I - -
. • . •. : • • 4.y..• ••
• . .... •I• ,...,:p.,..t.
• . ..,..&amp;quot;••• ; 1 .
4.. • ••••• &apos;:-..i.. s. el ......
-a
1.00(04220.0
</figure>
<figureCaption confidence="0.999378">
Figure 2: log(p(occIrel)/p(occ)) as function of log(0(occ))
</figureCaption>
<bodyText confidence="0.94208045">
Left above: short query single words, Right above: short query phrases
Left below: long query single words, Right below: long query phrases
First p(occ) is replaced by
log(0(occ))=Iog(p(occ)/1-p(occ)), since
distribution of p(occ) is too skewed.
In Figure 1, if the dot representing a term
located higher than the graph of
p(occ)=p(occirel), the term can be a good
discriminator and should contribute to retrieval
performance given an adequate weighting
scheme. On the other hands, the terms plotted
lower than the graph of p(occ)--p(occirel) are
by no means useful for retrieval performance
irrespective of weighting scheme.
P(occirel) is replaced by log(p(occIrel)/p(occ)) in
order to illustrate this borderline. In the case of
zero probability for p(occirel), -6 is assigned for
log(p(occirel)/p(occ)).
This is equivalent to mutual information
MI(occ;rel) in information theory as follows:
</bodyText>
<equation confidence="0.999510333333333">
log( p(occ rel)) p(occ,rel)
= log
p(occ) p(occ)p(rel) (1)
</equation>
<bodyText confidence="0.865804375">
Finally, Figure 2 illustrates distribution
characteristics of terms much better than Figure
1.
The dots plotted above the y=0 line represent
useful terms with respect to the query and
Single words Phrases Single words + phrases
Short query 79.29%(291/367) 66.34%(67/101) 76.50%(358/468)
Long query 54.77%(1315/2401) 45.32%(315/695) 52.65%(1630/3096)
</bodyText>
<tableCaption confidence="0.995155">
Table 4: Ratio of positive log(p(occIrel)fp(occ)) for query terms
</tableCaption>
<page confidence="0.967294">
51
</page>
<table confidence="0.994218">
Single words Phrases Single words + phrase
Short query 2.81 4.38 3.15
Long query 1.65 2.92 1.93
</table>
<tableCaption confidence="0.999624">
Table 5: Average of positive log(p(occirel)/p(occ)) value for query terms
</tableCaption>
<bodyText confidence="0.996753">
relevance judgements.
As this shows, single words and phrases are very
similar distribution characteristics but document
frequencies for phrases are much lower. Average
of log(0(occ)) is —5.22 for single words while —
8.64 for phrases in long queries.
On the other hands, ratios of good terms, whose
log(p(occirel)/p(occ)) is larger than 0, are shown
in Table 4.
From this observation, we can see limited
usefulness of phrasal terms with regards to
relevance. The ratio of positive
log(p(occIrel)/p(occ)) is lower than single words.
This explains poor performance of pre-
coordinated longer phrase based indexing that
utilizes phrases as replacements of single words.
Phrasal terms tend to have high value of
log(p(occirel)/p(occ)), but this does not
necessarily mean effectiveness of phrasal terms.
As Figure 1 and Figure 2 illustrate, the terms
with high log(p(occirel)/p(occ)) value tend to
have low log(0(occ)) that means extremely
lower document frequency so that they are not
so useful because of such lower frequency.
</bodyText>
<subsectionHeader confidence="0.6482685">
2.2. Measures for Phrasal Term
Effectiveness
</subsectionHeader>
<bodyText confidence="0.985260428571428">
Table 4 and Table 5 seem to support
supplemental phrasal indexing, because fairly
high ratio of positive log(p(occirel)/p(occ))
terms, and higher average value of
log(p(occirel)/p(occ)) are observed. But for short
queries, supplementing phrasal terms did not
show any positive effect as we have seen in
</bodyText>
<tableCaption confidence="0.632927">
Table 1.
</tableCaption>
<bodyText confidence="0.926145">
The following accounts are enumerated.
</bodyText>
<listItem confidence="0.549046428571429">
1) Over-weighted phrasal terms may cause
topic deviation from concepts represented by
single words to concepts represented by
phrasal terms.
2) Supplemental phrasal terms are not
always informative because their constituent
single words are already indexed.
</listItem>
<bodyText confidence="0.998199263157895">
If the phrasal term AB has a high MI(AB,rel)
value in contrast with MI(A,rel) and MI(B,rel),
this is the case where phrasal terms are
effective.
Consider a supplemental phrasal term as
informative if and only if its MI(occ,rel) is
positive value and is higher than the sum of
MI(occ,rel) of constituent single words in view
of the query and relevance judgements. A phrase
&amp;quot;AB&amp;quot; is informative means that the occurrence
of a phrase &amp;quot;AB&amp;quot; gives more information about
relevance than occurrence of both single words
&amp;quot;A&amp;quot; and &amp;quot;B&amp;quot;.
Table 6 shows the number and the ratio of
informative phrasal terms. —1 is assigned for
M1(occ,rel) when p(occirel) is 0.
Giving different values (-3 and -6) for
MI(occIrel) when p(occirel).--0 did not change
the results..
</bodyText>
<table confidence="0.84608175">
{#Phrasal terms&apos; MI(AB,rel) &gt; Positive MI(occ,rel) Total phrasal terms
SUM( MI(A,rel), MI(B,rel))) phrasal terms
Short query 31(30.69%) 67(66.34%) 101
Long query 146(21.01%) 315(4532%) 695
</table>
<tableCaption confidence="0.993466">
Table 6: Number of informative phrasal terms
</tableCaption>
<page confidence="0.935202">
52
</page>
<table confidence="0.999715333333333">
Category Phrasal terms
Informative i.- 1,— }- $110P(tansmission rate control)7 a — MOP (flow control),
1,— l- MOP (rate control)
Neutral -7/1., k--r A 1&apos; Afi(multicast communication),-7i1&apos; k- -r
(multicast),
Destructive i3M 0 ril(research trend),M35-Y IY9(partial), Mig fit (relatedness),igrg4-
OM (sender side), tt &amp;quot;..&amp;quot;— (multiple data),-7iI, -Ar A fs Ma
(multicast environment),-711,7z 5=4 7 -7&amp;quot;—(multimedia data),fda
4- (receiver)
</table>
<tableCaption confidence="0.996394">
Table 7 : Examples of phrasal terms in three categories from NACSIS topic 31
</tableCaption>
<subsectionHeader confidence="0.880745">
2.3. Three Categories of Phrasal Terms
</subsectionHeader>
<bodyText confidence="0.998715">
The following three categories of phrasal terms
in view of possible contribution to retrieval
effectiveness are proposed from the previous
discussion.
</bodyText>
<listItem confidence="0.815665333333333">
1) Informative phrasal terms : MI(occ,rel) &gt;
MI(occ of constituent single words ,rel).
2) Neutral phrasal terms:
MI(occ of constituent single words ,rel) &gt;
MI(occ,rel) &gt;= 0.
3) Destructive phrasal terms : MI(occ,rel) &lt; 0.
</listItem>
<bodyText confidence="0.996583">
For example, Table 7 shows phrasal terms
extracted from all fields of topic 31 in NACSIS
test collection 1,and classified accordingly.
</bodyText>
<subsectionHeader confidence="0.995877">
2.4. Weight Ratio of Phrasal Terms
</subsectionHeader>
<bodyText confidence="0.999855375">
Retrieval status values are computed as a linear
combination of each term weight, which is the
product of the query weight and the document
weight of the term. Using atn weighting in the
SMART system for the same setting as the runs
reported in Table 1, for each query term, the
sums of weights of each query term are
computed and for each query weight sum, ratio
of informative phrasal terms and destructive
phrasal terms are also computed. Macro-
averaged ratios of informative phrasal terms and
destructive phrasal terms are shown in Table 8.
Still, short queries seem to contain better phrases
in the ratio despite the fact that no consistent
effectiveness for retrieval performance is
observed.
</bodyText>
<subsectionHeader confidence="0.617537">
2.5. Correlation between phrasal term
</subsectionHeader>
<bodyText confidence="0.914463047619048">
weight ratio and performance
difference
For each runs against the 53 test topic set both
with short queries and long queries, correlation
between query-by-query performance difference
and query-by-query weight ratio of both
informative and destructive phrasal term weight
ratio are examined. Performance difference is
measured by non-interpolated average precision
and when the supplemental phrasal term run
performs better a positive value is given as we
have seen in Table 1.
Table 9 shows the Pearson&apos;s correlation
coefficient between performance difference and
each weight ratio as well as and difference
between weight ratios.
Average weight Number of topics Average weight Number of topics
ratio of informative Containing ratio of destructive containing
phrases informative phrases phrases destructive phrases
Short query 8.59% 25 10.40% 26
Long query 6.47% 47 16.14% 53
</bodyText>
<tableCaption confidence="0.985301">
Table 8: Weight ratio of phrasal terms ( macro-averaged for 53 topics)
</tableCaption>
<page confidence="0.960961">
53
</page>
<table confidence="0.618557">
Informative phrasal Destructive phrasal term (A)-(B)
term weight ratio(A) weight ratio(B)
Short query 0.12 -0.05 0.11
Long query 0.02 -0.05 0.04
</table>
<tableCaption confidence="0.911156">
Table 9 : Pearson&apos;s correlation between performance difference and phrasal term weight ratio
</tableCaption>
<bodyText confidence="0.999844444444445">
A positive correlation coefficient for informative
phrasal terms and a negative correlation
coefficient for destructive phrasal terms are
observed as is expected, although the coefficient
values are very small.
Given a topic set, a document collection and
relevance judgements, we are able to know
which terms are good ( and possibly how good
they are ) for retrieval performance but to
explain slight performance difference between
different indexing strategies seems to be much
more difficult.
Short queries contain relatively better phrasal
terms even though absolute number of such
terms is smaller than longer queries. But
utilizing such phrasal terms does not always lead
to performance improvement in macro-averaged
precision-recall basis evaluation.
</bodyText>
<sectionHeader confidence="0.99617" genericHeader="method">
3. Topic Deviation
</sectionHeader>
<bodyText confidence="0.999957580645161">
What we mean by topic deviation is a
phenomenon that is similar to query drift caused
by relevance feedback, but is incurred by some
over-weighted supplemental phrasal terms.
Terms representing some concepts in the topic
are over-weighted consequently the search
results are inclined to these concepts.
We verified short queries where supplemental
phrasal terms caused considerable degradation
(difference in average precision is more than
20%) and listed phrasal terms caused such
degradation in Table 10.
As we can see, not only the neutral phrases in
topics 50, 62 and 77, but also adding only
informative phrases caused degradation as in
topic 76.
&lt;description&gt; field of topic 76 is translated as
follows:
&amp;quot;(I want to know about) methods for
interference detection between polyhedral
representations.&amp;quot;
This topic consists of two concepts namely
&amp;quot;interference detection&amp;quot; and &amp;quot;polyhedral
representation&amp;quot; and the supplemented phrasal
tem &amp;quot;#ffloW rAi&amp;quot;(between polyhedral) is part of
the second concept.
Retrieval effectiveness depends on a subtle
balance of weighting on each concept, especially
in short queries, and redundant terms or over-
weighted terms cause the scoring function to
loose such balances.
</bodyText>
<sectionHeader confidence="0.7277" genericHeader="conclusions">
Conclusions
</sectionHeader>
<bodyText confidence="0.9599926">
Effects of phrasal indexing in view of different
length of queries are observed in the
experiments using NACSIS test collection 1, the
first large scale test collection for Japanese
information retrieval.
Our observations and conclusions are as follows:
1) Distribution characteristics of phrasal terms
as well as single word terms are examined
plotting each term&apos;s MI(occ,rel) as function of
log(0(occ)).
</bodyText>
<listItem confidence="0.528513">
2) Distribution characteristics of phrasal terms
are similar to single word terms but their
frequencies are much smaller than single words.
3) Generally phrasal terms are comparably good
discriminators of relevant documents, if not
superior, as single words are.
4) In supplemental phrasal indexing, good
discriminator terms are not always effective for
retrieval performance but only some phrasal
terms are informative and possibly effective.
5) Informative, neutral and destructive phrasal
terms are defined by means of MI(occ,rel).
6) Correlation between performance difference
and weight ratio of informative/destructive terms
is examined and a very week correlation is
observed.
</listItem>
<page confidence="0.992042">
54
</page>
<table confidence="0.857160181818182">
Topic Term o(occ) o(occl rel) p(occrrel) lodp(occi Category
rel) /p(occ))
34 &amp;A 0.000129 0 0.000129 -6 Destructive
(improvement method)
50 Al Oig 0.002346 0.388889 0.002305 5.11063 Neutral
(artificial intelligence)
60 trri rhug 0.000006 0 0.000006 -6 Destructive
(educational issues)
60 MA M 0.000012 0.222222 0.000006 9.848081 Informative
(occupation period)
60 tea Vri 0.000009 0 0.000009 -6 Destructive
(educational situation)
62 N .4-4U 0.00044 0.285714 0.000435 6.475054 Neutral
(life-long learning)
76 f* ral 0.000023 0.076923 0.000021 8.094061 Informative
(between polyhedral)
77 ,Ig4-7 #13E 0.000029 0.166667 0.000026 8.644108 Neutral
(braille transcription)
78 frOL Olt 0.000414 0 0.000414 -6 Destructive
(mammals)
78 7fZ3E IL 0.000065 0.666667 0.000053 9.241945 Informative
(immortalize)
</table>
<tableCaption confidence="0.987561">
Table 10: Phrasal terms in degraded topics by supplemental phrases
</tableCaption>
<bodyText confidence="0.998461888888889">
7) Explaining effectiveness of each query term is
not sufficient for explaining effectiveness of
phrasal indexing. Even good discriminator terms
may hurt the retrieval effectiveness.
This research is by no means conclusive but a
starting point of a longer project that hopefully
leads to a new weighting scheme to replace
current empirical down-weighting approach for
supplemental phrasal terms.
</bodyText>
<sectionHeader confidence="0.995985" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99988425">
The author thanks NACSIS R&amp;D department for
providing us of NACSIS test collection 1. We
participated in the NTCIR workshop utilizing
NACSIS test collection 1 (preliminary version)
that is developed by NACSIS R&amp;D department,
thanks to understanding of academic societies
(http://www.rdnacsis.ac.jp/--ntcadmithanksl-
en.htm1) who provided the data.
</bodyText>
<sectionHeader confidence="0.99915" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999930944444444">
[1] Fujita, S. (1999). Notes on Phrasal Indexing:
JSCB Evaluation Experiments at NTCIR
AD HOC, NTCIR Workshop 1, Tokyo, 101-
108.
[2] Fujita, S. (2000). Evaluation of Japanese
Phrasal Indexing with a Large Test
Collection, RIA02000 Conference
proceedings, Paris, 1089-1098.
[3] Greiff, W.R. (1998). A Theory of Term
Weighting Based on Exploratory Data
Analysis, SIGIR &apos;98, Melbourne, 11-19.
[4] NTCIR. (1999).
http://www.rd.nacsis.acjp/--ntcadm/index-
en.html
[5] Pickens, J. Croft, W.B. (2000) An
Exploratory Analysis of Phrases in Text
Retrieval, RIA02000 Conference
proceedings, Paris, 1179-1195.
</reference>
<page confidence="0.999065">
55
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.947473">
<title confidence="0.9933375">Discriminative Power and Retrieval Effectiveness of Indexing Terms</title>
<author confidence="0.988727">Sumio Fujita</author>
<affiliation confidence="0.991055">Justsystem corporation</affiliation>
<address confidence="0.978845">Brainspark, Tokushima, Japan</address>
<abstract confidence="0.99969205882353">In spite of long controversy, effectiveness of phrasal indexing is not yet clear. Recently, correlation between query length and effect of phrasal indexing is reported. In this paper, terms extracted from the topic set of the NACSIS test collection 1 are analyzed utilizing statistic tools in order to show distribution characteristics of single word/phrasal terms with regard to relevant/nonrelevant documents. Phrasal terms are found to be very good discriminators in general but not all of them are effective as supplemental phrasal terms. A distinction of informative / neutral / destructive phrasal terms is introduced. Retrieval effectiveness is examined utilizing query weight ratio of these three categories of phrasal terms.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Fujita</author>
</authors>
<date>1999</date>
<booktitle>Notes on Phrasal Indexing: JSCB Evaluation Experiments at NTCIR AD HOC, NTCIR Workshop 1,</booktitle>
<pages>101--108</pages>
<location>Tokyo,</location>
<marker>[1]</marker>
<rawString>Fujita, S. (1999). Notes on Phrasal Indexing: JSCB Evaluation Experiments at NTCIR AD HOC, NTCIR Workshop 1, Tokyo, 101-108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Fujita</author>
</authors>
<title>Evaluation of Japanese Phrasal Indexing with a Large Test Collection,</title>
<date>2000</date>
<booktitle>RIA02000 Conference proceedings,</booktitle>
<pages>1089--1098</pages>
<location>Paris,</location>
<marker>[2]</marker>
<rawString>Fujita, S. (2000). Evaluation of Japanese Phrasal Indexing with a Large Test Collection, RIA02000 Conference proceedings, Paris, 1089-1098.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W R Greiff</author>
</authors>
<title>A Theory of Term Weighting Based on Exploratory Data Analysis,</title>
<date>1998</date>
<booktitle>SIGIR &apos;98,</booktitle>
<pages>11--19</pages>
<location>Melbourne,</location>
<marker>[3]</marker>
<rawString>Greiff, W.R. (1998). A Theory of Term Weighting Based on Exploratory Data Analysis, SIGIR &apos;98, Melbourne, 11-19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>NTCIR</author>
</authors>
<date>1999</date>
<note>http://www.rd.nacsis.acjp/--ntcadm/indexen.html</note>
<marker>[4]</marker>
<rawString>NTCIR. (1999). http://www.rd.nacsis.acjp/--ntcadm/indexen.html</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Croft Pickens</author>
<author>W B</author>
</authors>
<title>An Exploratory Analysis of Phrases</title>
<date>2000</date>
<booktitle>in Text Retrieval, RIA02000 Conference proceedings,</booktitle>
<pages>1179--1195</pages>
<location>Paris,</location>
<marker>[5]</marker>
<rawString>Pickens, J. Croft, W.B. (2000) An Exploratory Analysis of Phrases in Text Retrieval, RIA02000 Conference proceedings, Paris, 1179-1195.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>