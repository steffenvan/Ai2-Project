<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.987639">
Variable-Length Markov Models and Ambiguous Words in Portuguese*
</title>
<author confidence="0.994924">
Fabio Natanael Kepler
</author>
<affiliation confidence="0.990779">
Institute of Mathematics and Statistics
University of Sao Paulo
</affiliation>
<address confidence="0.905301">
Sao Paulo, SP, Brazil
</address>
<email confidence="0.995727">
kepler@ime.usp.br
</email>
<author confidence="0.986422">
Marcelo Finger
</author>
<affiliation confidence="0.9914405">
Institute of Mathematics and Statistics
University of Sao Paulo
</affiliation>
<address confidence="0.954554">
Sao Paulo, SP, Brazil
</address>
<email confidence="0.999003">
mfinger@ime.usp.br
</email>
<sectionHeader confidence="0.995538" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99823695">
Variable-Length Markov Chains (VLMCs) of-
fer a way of modeling contexts longer than
trigrams without suffering from data sparsity
and state space complexity. However, in His-
torical Portuguese, two words show a high de-
gree of ambiguity: que and a. The number
of errors tagging these words corresponds to a
quarter of the total errors made by a VLMC-
based tagger. Moreover, these words seem to
show two different types of ambiguity: one
depending on non-local context and another
on right context. We searched ways of ex-
panding the VLMC-based tagger with a num-
ber of different models and methods in order
to tackle these issues. The methods showed
variable degrees of success, with one particu-
lar method solving much of the ambiguity of
a. We explore reasons why this happened, and
how everything we tried fails to improve the
precision of que.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.97755825">
In the Computational Linguistics area, the task of
part-of-speech tagging (POS tagging) consists in as-
signing to words in a text the grammatical class they
belong. Since the same word may belong to more
than one class, models for POS tagging have to look
at the context where each word occurs to try to solve
the ambiguity.
Previous and current work have developed a wide
range of models and methods for tagging. The vast
majority uses supervised learning methods, which
&amp;quot;During the course of this work Fabio received support from
Brazilian funding agencies CAPES and CNPq.
</bodyText>
<page confidence="0.970608">
15
</page>
<bodyText confidence="0.999612272727273">
need an already tagged corpus as input in order to
train the model, calculating relations, weights, prob-
abilities etc.
Among the various models for tagging, there are
Maximum Entropy models (dos Santos et al., 2008;
de Almeida Filho, 2002; Ratnaparkhi, 1996), Hid-
den Markov Models (HMMs) (Brants, 2000), Trans-
formation Based Learning (Brill, 1993), and other
succesful approaches (Toutanova et al., 2003; Tsu-
ruoka and Tsujii, 2005; Shen et al., 2007).
Current state-of-the-art precision in tagging is
achieved by supervised methods. Although preci-
sion is pretty high – less than 3% error rate for
English – the disavantage is exactly the need of a
tagged corpus, usually built manually. This is a very
restrictive issue for languages with lack of resources
such as linguistic especialists, corpora projects etc.
The Portuguese language falls in between re-
sourceful languages, such as English, and languages
with restricted resources. There have been initia-
tives both in Brazil and in Portugal, which include
modern Brazilian Portuguese corpora (ICMC-USP,
2010), European Portuguese corpora (Flo, 2008),
and historical Portuguese corpora (IEL-UNICAMP
and IME-USP, 2010). Also, some supervised POS
taggers have already been developed for Portuguese
(dos Santos et al., 2008; Kepler and Finger, 2006;
Aires, 2000) with a good degree of success. And fi-
nally, there has also been increasing effort and in-
terest in Portuguese annotation tools, such as E-
Dictor1 (de Sousa et al., 2009).
Despite these advances, there is still lack of mate-
rial and resources for Portuguese, as well as research
</bodyText>
<footnote confidence="0.992755">
1See http://purl.org/edictor.
</footnote>
<note confidence="0.9853875">
Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas,
pages 15–23, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.9995045">
in unsupervised methods to bootstrap text annota-
tion.
Our work focuses on further improvement of the
current state-of-the-art in Portuguese tagging. For
this, we focus on the Tycho Brahe (IEL-UNICAMP
and IME-USP, 2010) corpus for testing and bench-
marking, because of its great collaboration potential:
it is easily accessible2; is under continuous develop-
ment; and has recently started using E-Dictor, which
also offers a great collaboration potential.
</bodyText>
<subsectionHeader confidence="0.993684">
1.1 Previous Works
</subsectionHeader>
<bodyText confidence="0.999948090909091">
One popular approach to tagging is to use HMMs
of order 2. Order 2, or trigram, means the tagger
considers the previous two words/tags when tagging
a word. This adds context to help disambiguation.
The drawback is that this context may not be suf-
ficient. Increasing the order does not help, since
this incurs in too many model parameters and suf-
fers from the data sparsity problem.
In (Kepler and Finger, 2006), we developed a tag-
ger for Portuguese that uses Markov chains of vari-
able length, that is, orders greater than 2 can be
used conditioned on certain tags and sequences of
tags. This approach is better at avoiding the spar-
sity and complexity problems, while being able to
model longer contexts. However, one interesting
conclusion from that work is that, even using longer
contexts, some words stay extremely hard to disam-
biguate. Apparently, those words rely on flexible
contexts not captured by pure VLMCs.
Motivated by this problem, we improve over the
previous work, and developed a set of tagger models
based on Variable-Length Markov Chains (VLMCs)
extended with various other approaches in order to
try to tackle the problem.
In the next section we describe the VLMC theory,
the results it achieves, and the problems with two
common words. Then, in Section 3, we explain in
summary the set of models and approaches we tried
to mix with VLMCs, and the different types of re-
sults they give. Conclusions are drawn in Section 4.
Finally, Section 5 describes how this work can be in-
corporated in other projects, and Section 6 presents
ideas for future work.
</bodyText>
<footnote confidence="0.8682575">
2More information at http://www.tycho.iel.
unicamp.br/~tycho/corpus/en/index.html.
</footnote>
<sectionHeader confidence="0.775558" genericHeader="method">
2 Variable-Length Markov Chains
</sectionHeader>
<bodyText confidence="0.99887853125">
The idea is to allow the memory of a Markov chain
to have variable length, depending on the observed
past values. (Bühlmann and Wyner, 1999) give a
formal description of VLMCs, while here we will
explain them in terms of the POS-tagging task.
Consider a Markov chain with a finite, large order
k. Let ti be a tag, and ti−k,i−1 be the k tags preced-
ing ti. Variable length memory can be seen as a cut
of irrelevant states from the ti−k,i−1 history. We call
the set of these states the context of ti. Given a tag
ti, its context ti−h,i−1, h &lt; k, is given by the context
function c(ti−k,i−1).
A context tree is a tree in which each internal node
has at most |T  |children, where T is the tagset. Each
value of a context function c(·) is represented as a
branch of such tree. For example, the context given
by c(ti−k,i−1) is represented as a branch whose sub-
branch at the top is determined by ti−1, the next sub-
branch by ti−2, and so on, until the leaf, determined
by ti−h.
The parameters of a VLMC are the underlying
functions c(·) and their probabilities. To obtain these
parameters we use a version of the context algorithm
of (Rissanen, 1983). First, it builds a big context
tree, using a training corpus. For a tag ti, its maxi-
mal history ti−k,i−1 is placed as a branch in the tree.
Then, the algorithm uses a pruning function consid-
ering a local decision criterion. This pruning cuts
off the irrelevant states from the tags’ histories. For
each leaf u in the context tree, and branch v that goes
from the root to the parent node of u, u is pruned
from the tree if
</bodyText>
<equation confidence="0.942794">
(P(t1Ivu) log P(l|v) P(t|vu) /II C(vu) &lt; K,
</equation>
<bodyText confidence="0.999726090909091">
where C(vu) is the number of occurrences of the se-
quence vu in the training corpus, and K is a thresh-
old value, called the cut value of the context tree,
If the probability of a tag does not change much
between considering the entire branch together with
the leaf (all past history) and considering only the
branch (the history without the furthest tag), then the
leaf does not need to be considered, and can be re-
moved from the tree.
We want to find the best sequence of tags t1 ... t,,,
for a given sequence of words w1 ... w,,, of size n,
</bodyText>
<equation confidence="0.69630425">
1: Ovu =
tEL
16
that is,
</equation>
<bodyText confidence="0.983793294117647">
are computed from a tagged training
corpus using maximum likelihood estimation from
the relative frequencies of words and sequences of
tags. The context tree is built with sequences of tags
of maximum length k an
Probabilities
d then pruned, thus defin-
ing the context functions. For decoding, the Viterbi
Algorithm is used (Viterbi, 1967).
precision5,
d Error, respectively. The
difference in precision is mainly due to a 21.64%
error reduction in known words tagging6. That,
combined with 6.82% error reduction in unknown
words, results in 17.50% total error reduction. With
the segmented corpus the VLMM TAGGER achieved
96.54% of precision.
</bodyText>
<equation confidence="0.869807">
TAGGER WORDS P (%) ERR.
OCURR.
� n
arg max H P(ti|c(ti−k,i−1))P(wi|ti) .
t1...tn
i=1
</equation>
<subsectionHeader confidence="0.92782">
2.1 Initial Results
</subsectionHeader>
<bodyText confidence="0.995700903225806">
VLMC Known 96.39 9065 / 251087
We used the tagged texts available by the Ty-
cho Brahe Corpus of Historical Portuguese (IEL-
UNICAMP and
2010). The Tycho Brahe
project uses 377 POS and inflectional tags, and con-
tains annotated texts written by authors born be-
tween 1380 and 1845. We have selected 19 texts
for composing our corpus, which contains 1035593
tagged words and has 262 different tags. This cor-
pus was then randomly divided into 75% of the sen-
tences for generating a training corpus and 25% for
a testing corpus. The training corpus has 775602
tagged words, while the testing corpus has 259991
tagged words. The Tycho Brahe project is under-
going rapid development, so as for today there are
more texts available which are not present in the cor-
pus we used3.
Because of some of the approaches explained be-
low, we also created a new training corpus and a new
testing corpus by segmenting contracted words from
the original corpus. Contracted words are words like
da, which has the tag
and is a contraction of
the preposition de (P) with the feminine determiner
a
Using the original corpus, our VLMC implemen-
tation, which we will call VLMM TAGGER4 (from
Variable Length Markov Model), and which better
implements under- an
IME-USP,
</bodyText>
<equation confidence="0.6367835">
P+D-F
(D-F).
</equation>
<bodyText confidence="0.899198">
d overflow control, achieves
can provide the training and testing corpus if requested
by email.
</bodyText>
<footnote confidence="0.835565571428571">
4A package containing the VLMM TAGGER will be
available at
vlmmtagger/, but requests for the raw source code can be
made by email. Currently, there is only an automake bundle
re
3We
http://www.ime.usp.br/~kepler/
</footnote>
<bodyText confidence="0.645183">
ady for download containing the VLMC TAGGER.
Total 95.51 11674 / 259991
Unknown 69.53 2713 / 8904
Unknown 71.60 2528 / 8904
VLMM Known 97.17 7102 / 251087
Total 96.29 9630 / 259991
</bodyText>
<tableCaption confidence="0.7710025">
Table 1: Precision of VLMC-based taggers.
96.29% of
</tableCaption>
<bodyText confidence="0.987158615384615">
while the VLMC TAGGER
from (Kepler and Finger, 2006) achieves 95.51%.
Table 1 shows the numbers for both taggers, where P
and E means Precision an
Table 2 shows numbers for the two words that
present the most number of errors made by the
VLMM TAGGER. Note that they are not necessarily
the words with the highest error percentage, since
there are known words that appear only a couple of
times in the testing corpus an
d may get wrong tags
half of this times, for example.
WORDS P (%) E (%) ERR. / OCURR.
</bodyText>
<tableCaption confidence="0.934357">
Table 2: Results for words with the most number of errors
using the VLMM TAGGER with the normal corpus.
</tableCaption>
<bodyText confidence="0.89965725">
These two words draw attention because together
they correspond to almost 25% of the errors made by
the tagger, where most confusion for each of these
words is between two different tags:
• The word que is, most of the times, either a rel-
ative pronoun
by the tag
an
– denoted
WPRO
d
que 84.7413 15.2586 1687 / 11056
a 90.9452 9.0547 661 / 7300
is given by the number of correctly assigned tags
to the words in the testing corpus over the total number of words
in the testing corpus.
</bodyText>
<footnote confidence="0.9851365">
6Known words are words that appear both in the training an
5Precision
</footnote>
<bodyText confidence="0.5409455">
d
the testing corpus.
</bodyText>
<page confidence="0.99362">
17
</page>
<bodyText confidence="0.819092214285714">
equivalent to the word which in English –, or a
subordinating conjunction – denoted by the tag
C and equivalent, in English, to the words that
or than;
• The word a is, usually, either a feminine deter-
miner (tag D-F), or a preposition (tag P).
As a baseline, assigning the most common tag to que
yields a precision of 55.64%, while a gets a preci-
sion of 58.09%. Also, these words seem to show two
different types of ambiguity: one that needs con-
text to the right, and one that needs non-local con-
text. The VLMM model does not have parameters
for these contexts, since it tags from left to right us-
ing context immediately to the left.
</bodyText>
<subsectionHeader confidence="0.990054">
2.2 Objectives
</subsectionHeader>
<bodyText confidence="0.999995368421053">
It seems that a could be better disambiguated by
looking at words or tags following it: for example,
if followed by a verb, a is much more likely to be a
preposition. For que, it seems that words occuring
not immediately before may add important informa-
tion. For example, if que follows mais (more than,
in English), it is more likely that que has tag C. How-
ever, like in the English expression, it is possible to
have various different words in between mais and
que, as for example: “mais provável que” (“more
likely than”); “mais caro e complexo que” (“more
expensive and complex than”); and so on. Thus, it
may yield better results if non-local context could
be efficiently modeled.
In order to develop these ideas about que and a
and prove them right or wrong, we searched ways of
expanding the VLMM tagger with a number of dif-
ferent models and methods that could help solving
these two issues. Those models are described next.
</bodyText>
<sectionHeader confidence="0.991849" genericHeader="method">
3 Auxiliary Approaches
</sectionHeader>
<subsectionHeader confidence="0.998984">
3.1 Syntactic Structure
</subsectionHeader>
<bodyText confidence="0.999938648648649">
The first idea we had was to generalize nodes in the
VLMM’s context tree, that is, to model a way of ab-
stracting different sequences of tags into the same
node. This could make it possible to have branches
in the context tree like ADV * C, that could be used
for mais * que.
One way of doing this is to use sequences of tags
that form phrases, like noun phrases (NP), preposi-
tional phrases (PP), and verbal phrases (VP), and use
them in the context tree in place of the sequences
of tags they cover. The context tree will then have
branches like, say, P VP N.
In order to train this mixed model we need a tree-
bank, preferably from the texts in the Tycho Brahe
corpus. However, it does not have a sufficiently large
set of parsed texts to allow efficient supervised learn-
ing. Moreover there is not much Portuguese tree-
banks available, so we were motivated to implement
an unsupervised parsed for Portuguese.
Based on the work of (Klein, 2005), we imple-
mented his CCM model, and used it over the Ty-
cho Brahe corpus. The CCM model tries to learn
constituents based on the contexts they have in com-
mon. We achieved 60% of f-measure over a set of
texts from the Tycho Brahe project that were already
parsed.
Using the CCM constituents learned, we ex-
tended the VLMM TAGGER to use this extra infor-
mation. It yielded worse results, so we restricted the
use of constituents to que (the VLMM+SPANS-QUE
TAGGER). This yielded a precision of 96.56%, with
a que precision increase of 3.73% and an a precision
reduction of 0.67%. A comparison with the plain
VLMM TAGGER over the segmented corpus can be
seen in Table 3. We use the segmented corpus for
comparison because the constituents only use seg-
mented tags. Even after many tries and variations in
</bodyText>
<equation confidence="0.538337428571429">
WORDS P (%) ERR. / OCURR.
84.50 1715 / 11063
85.18 1651 / 11063
94.52 745 / 13597
94.49 750 / 13597
Total 96.5433 9559 / 276541
96.5636 9503 / 276541
</equation>
<tableCaption confidence="0.976831333333333">
Table 3: Comparison of precision using the VLMM TAG-
GER (in italics) and the VLMM+SPANS-QUE TAGGER
(upcase) with the segmented corpus.
</tableCaption>
<bodyText confidence="0.983701333333333">
the way the VLMM TAGGER could use constituents,
the result did not improve. This led us to a new ap-
proach, shown in the next section.
</bodyText>
<figure confidence="0.864487">
que
a
</figure>
<page confidence="0.960088">
18
</page>
<subsectionHeader confidence="0.990629">
3.2 Chunks
</subsectionHeader>
<bodyText confidence="0.999694710526316">
Since induced syntactic structure did not help, a new
idea was to, this time, begin with the already parsed
and revised texts from the Tycho Brahe, even with
they summing only a little more than 300 thousand
words. To ease the problem of sparsity, the trees
were flattened and merged in such a way that only
NPs, PPs and VPs remained. Then the bracketed no-
tation was converted to the IOB notation, now form-
ing a chunked corpus.
Chunking, or shallow parsing, divides a sen-
tence into non-overlapping phrases (Manning and
Schütze, 1999). It is used in information extraction
and in applications where full parsing is not nec-
essary, offering the advantage of being simpler and
faster.
We made a small experiment with the chunked
corpus: divided the sentences randomly into 90%
and 10% sets, the former for training and the later
for testing. Then we ran the VLMM TAGGER with
these chunked sets, and got a precision in chunking
of 79%.
A model for chunks processing was mixed into
the VLMM model, similar but not equal to the mixed
model with CCM. The chunked corpus uses seg-
mented words, because the parsed texts available in
Tycho Brahe only use segmented words. Thus, we
ran the VLMM TAGGER with the segmented training
corpus and the chunked corpus, testing over the seg-
mented test corpus. The precision yielded with this
VLMM+CHUNKS TAGGER was 96.55%.
Table 4 shows the results for the segmented
corpus with the VLMM TAGGER and the
VLMM+CHUNKS TAGGER. Interestingly, results did
not change much, in spite of the VLMM+CHUNKS
TAGGER achieving a higher precision. Interestingly,
the word a error rate is reduced by around 13%
with the help of chunks, while the que error rate
increases almost 3%.
</bodyText>
<subsectionHeader confidence="0.995396">
3.3 Bidirectional
</subsectionHeader>
<bodyText confidence="0.999993833333333">
Another approach was to follow the intuition about
a: that the right context should help solving some
ambiguities. The problem that makes this approach
non trivial is that a right tag context is not yet avail-
able when tagging a word, due to the natural left-to-
right order the tagger follows when tagging a sen-
</bodyText>
<equation confidence="0.927782285714286">
WORDS P (%) ERR. / OCURR.
84.50 1715 / 11063
84.05 1764 / 11063
94.52 745 / 13597
95.26 644 / 13597
Total 96.5433 9559 / 276541
96.5506 9539 / 276541
</equation>
<tableCaption confidence="0.969769">
Table 4: Comparison of precision using the VLMM TAG-
GER (in italics) and the VLMM+CHUNKS TAGGER (up-
case) with the segmented corpus.
</tableCaption>
<bodyText confidence="0.999919529411765">
tence. A right context that is available is the context
of words to the right, but this presents the problem
of sparsity and will probably not yield good results.
Our approach was then to model a right context of
tags when the words to the right were not ambigu-
ous, that is, if they could be assigned only one spe-
cific tag. During training, a new context tree is built
for the right context, where, for each word in a sen-
tence, a continuous but variable-length sequence of
tags from unambiguous words to the right is added
as a branch to the right context tree. That is, if k
words to right of a given word are not ambiguous,
then the sequence of the k tags these words will have
is added to the right tree. The right context tree is
also prunned like the left context tree and the Viterbi
algorithm for tagging is adapted to consider these
new parameters.
</bodyText>
<equation confidence="0.953486">
WORDS P (%) ERR. / OCURR.
84.74 1687 / 11056
84.80 1680 / 11056
90.94 661 / 7300
92.15 573 / 7300
Total 96.29 9630 / 259991
96.33 9544 / 259991
</equation>
<tableCaption confidence="0.810786666666667">
Table 5: Comparison of precision using the VLMM TAG-
GER (in italics) and the VLMM+A-RIGHT TAGGER (up-
case) with the normal corpus.
</tableCaption>
<bodyText confidence="0.999588">
After various tests with different options for the
right context tree, the result over the original VLMM
tagger did not improve. We then experimented
building the right context tree only for the word a,
</bodyText>
<figure confidence="0.99081575">
que
a
que
a
</figure>
<page confidence="0.994947">
19
</page>
<bodyText confidence="0.99996">
resulting in the VLMM+RIGHT-A TAGGER. Table 5
shows what happens with the normal corpus.The er-
ror rate of a is decreased almost 5% with this bidi-
rectional approach.
</bodyText>
<subsectionHeader confidence="0.928425">
3.4 Perceptron
</subsectionHeader>
<bodyText confidence="0.999236976744186">
The Perceptron algorithm was first applied to POS-
tagging by (Collins, 2002). It is an algorithm for
supervised learning that resembles Reinforcement
Learning, but is simpler and easier to implement.
(Collins, 2002) describes the algorithm for tri-
gram HMM taggers. Here, we will describe it for
the VLMM tagger, adapting the notation and expla-
nation.
Instead of using maximum-likelihood estimation
for the model parameters, the perceptron algorithm
works as follows. First, the model parameters are
initialized to zero. Then, the algorithm iterates a
given number of times over the sentences of the
training corpus. For each sentence s, formed by a
sequence of words ws paired with a sequence of tags
is, the Viterbi decoding is ran over ws, returning zs,
the predicted sequence of tags. Then, for each se-
quence of tags o of length at most k, k the maximum
order of the VLMC, seen c1 times in is and c2 times
in zs, we make αc(o) = αc(o) + c1 − c2. c(o) is the
context function defined in Section 2 applied to the
tag sequence o, which returns the maximum subse-
quence of o found in the context tree. αc(o) repre-
sents the parameters of the model associated to c(o),
that is, the branch of the context tree that contains
c(o).
The above procedure effectively means that pa-
rameters which contributed to errors in zs are penal-
ized, while parameters that were not used to predict
zs are promoted. If is = zs then no parameter is
modified. See (Collins, 2002) for the proof of con-
vergence.
Implementing the perceptron algorithm into the
VLMM tagger resulted in the VLMM+PERCEPTRON
TAGGER. Table 6 shows the results obtained. Note
that no prunning is made to the context tree, because
doing so led to worse results. Training and predict-
ing with a full context tree of height 10 achieved bet-
ter precision. The numbers reported were obtained
after 25 iterations of perceptron training. The total
precision is lower than the VLMM TAGGER’s preci-
sion, but it is interesting to note that the precision for
que and a actually increased.
</bodyText>
<equation confidence="0.679906571428571">
WORDS P (%) ERR. / OCURR.
84.74 1687 / 11056
85.15 1641 / 11056
90.94 661 / 7300
92.41 554 / 7300
Total 96.29 9630 / 259991
95.98 10464 / 259991
</equation>
<tableCaption confidence="0.913933">
Table 6: Comparison of precision using the VLMM TAG-
GER (in italics) and the VLMM+PERCEPTRON TAGGER
(upcase) with the normal corpus.
</tableCaption>
<subsectionHeader confidence="0.957589">
3.5 Guided Learning
</subsectionHeader>
<bodyText confidence="0.999946387096774">
(Shen et al., 2007) developed new algorithms based
on the easiest-first strategy (Tsuruoka and Tsujii,
2005) and the perceptron algorithm. The strategy is
to first tag words that show less ambiguity, and then
use the tags already available as context for the more
difficult words. That means the order of tagging is
not necessarily from left to right.
The inference algorithm works by maintaining
hypotheses of tags for spans over a sequence of
words, and two queues, one for accepted spans and
one for candidate spans. Beam search is used for
keeping only a fixed number of candidate hypothe-
ses for each accepted span. New words from the
queue of candidates are tagged based on their scores,
computed by considering every possible tag for the
word combined with all the available hypotheses on
the left context and on the right context. The high-
est scoring word is selected, the top hypotheses are
kept, and the two queues are updated. At each step
one word from the queue of candidates is selected
and inserted in the queue of accepted spans.
The core idea of Guided Learning (GL) training is
to model, besides word, tag, and context parameters,
also the order of inference. This is done by defin-
ing scores for hypotheses and for actions of tagging
(actions of assigning a hypothesis). The score of a
tagging action if computed by a linear combination
of a weight vector and a feature vector of the action,
which also dependes on the context hypotheses. The
score of a given span’s hypothesis is the sum of the
scores of the top hypothesis of the left and right con-
</bodyText>
<figure confidence="0.927785">
que
a
</figure>
<page confidence="0.921288">
20
</page>
<bodyText confidence="0.99977775">
texts (if available) plus the score of the action that
led to this hypothesis.
The GL algorithm estimates the values of the
weight vector. The procedure is similar to the in-
ference algorithm. The top scoring span is selected
from the queue of candidate spans and, if its top
hipothesis matches the gold standard (the tags from
the training corpus), the queues of accepted and can-
didate spans are updated as in the inference algo-
rithm. Otherwise, the weight vector is updated in
a perceptron style by promoting the features of the
gold standard action and demoting the features of
the top hypothesis’ action. Then the queue of can-
didate spans is regenerated based on the accepted
spans.
This model uses trigrams for the left and right
contexts, and so it could be potentially extended by
the use of VLMCs. It is our aim to develop a tagger
combining the VLMM and the GL models. But as
for today, we have not yet finished a succesful imple-
mentation of the GL model in C++, in order to com-
bine it with the VLMM TAGGER’s code (current code
is crashing during training). Original GL’s code is
written in Java, which we had access and were able
to run over our training and testing corpora.
Table 7 shows the result over the normal corpus.
The first thing to note is that the GL model does a
pretty good job at tagging. The precision means a
10% error reduction. However, the most interesting
thing happens with our two words, que and a. The
precision of que is not significantly higher. How-
ever, the error rate of a is reduced by half. Such per-
formance shows that the thought about needing the
right context to correctly tag a seems correct. Ta-
ble 8 shows the confusion matrix of the most com-
mon tags for a.
</bodyText>
<sectionHeader confidence="0.99711" genericHeader="method">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999076666666667">
In almost all extended versions of the VLMM TAG-
GER, que and a did not suffer a great increase in
precision. With the approaches that tried to gener-
alize context – by using syntactic structure – and
capture longer dependencies for que, the results did
not change much. We could see, however, that the
right context does not help disambiguating que at
all. Training the VLMM model with a long context
(order 10) helped a little with a, but showed over-
</bodyText>
<table confidence="0.684082285714286">
WORDS P (%) ERR. / OCURR.
84.74 1687 / 11056
84.90 1670 / 11056
90.94 661 / 7300
95.49 329 / 7300
Total 96.29 9630 / 259991
96.67 8650 / 259991
</table>
<tableCaption confidence="0.97152">
Table 7: Comparison of precision using the VLMM TAG-
GER (in italics) and the GUIDED LEARNING TAGGER (up-
case) with the normal corpus.
</tableCaption>
<table confidence="0.96914125">
D-F P CL
D-F &lt;4144&gt; 92 5
P 189 &lt;2528&gt; 2
CL 26 9 &lt;294&gt;
</table>
<tableCaption confidence="0.734344">
Table 8: Confusion matrix for a with the most common
tags in the normal corpus (line: reference; column: pre-
dicted).
</tableCaption>
<bodyText confidence="0.9999538">
all worse results. Modeling a right context for a in
a simple manner did also help a little, but not sig-
nificantly. The model that gave good results for a
was the one we still have not finished extending with
VLMM. It looks promising, but a way of better dis-
ambiguating que was not found. A better approach
to generalize contexts and to try to capture non-local
dependencies is needed. Some further ideas for fu-
ture work or work in progress are presented in Sec-
tion 6.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="method">
5 Oportunities for Collaboration
</sectionHeader>
<bodyText confidence="0.999955615384616">
Tycho Brahe is a corpus project undergoing contin-
uous development. Since there is already a good
amount of resource for supervised tagging, our tag-
ger can be used for boosting new texts annotation.
Furthermore, the project has started using E-Dictor,
an integrated annotation tool. E-Dictor offers a
range of easy to use tools for corpora creators: from
transcription, philological edition, and text normati-
zation, to morphosyntactic annotation. This last tool
needs an integrated POS-tagger to further ease the
human task of annotation. Besides, an increasing
number of projects is starting and willing to start us-
ing E-Dictor, so the need for an automatic tagger
</bodyText>
<figure confidence="0.9258075">
que
a
</figure>
<page confidence="0.996715">
21
</page>
<bodyText confidence="0.99994875">
is getting urgent. We have already been contacted
by the E-Dictor developers for further collaboration,
and should integrate effors during this year.
Another project that can benefit from a good POS-
tagger is the Brasiliana Digital Library, from the
University of Sao Paulo7. It started last year digi-
talizing books (and other pieces of literature) about
Brazil from the 16th to the 19th century, mak-
ing them available online. Many books have been
OCRed, and a side project is already studying ways
of improving the results. Since the library is an
evolving project, the texts will soon be of reason-
able size, and will be able to form another corpus of
historical Portuguese A POS-tagger will be of great
help in making it a new resource for Computational
Linguistics research. We are already negotiating a
project for this with the Brasiliana directors.
There is a tagger for Portuguese embedded in
the CoGrOO8 gramatical corrector for Open Of-
fice. They seem to implement some interesting rules
for common use Portuguese that maybe would help
some of our disambigation problems. Besides in-
specting the available open source code, we have
contacted the current maintainer for further conver-
sation. A possibility that has appeared is to integrate
the VLMM TAGGER with CoGrOO.
Using different data would be interesting in or-
der to check if the exactly same problems arise, or
if other languages show the same kind of problems.
We will try to get in contact with other projects hav-
ing annotated resources available, and seek for fur-
ther collaboration. Currently, we got in touch with
people working on another corpus of Portuguese9.
Both sides are hoping to form a partnership, with us
providing a POS tagger and them the annotated cor-
pora.
</bodyText>
<sectionHeader confidence="0.999773" genericHeader="discussions">
6 Future Work
</sectionHeader>
<bodyText confidence="0.999837666666667">
Short term future work includes implementing
Guided Learning in C++ and mixing it with VLMCs.
This looks promising since the current GL imple-
mentation uses a fixed trigram for contexts to the
left and to the right. Also, there is a need for fast
execution in case our tagger is really integrated into
</bodyText>
<footnote confidence="0.89142375">
7http://www.brasiliana.usp.br/bbd
8http://cogroo.sf.net/.
9History of Portuguese spoken in São Paulo (caipira
Project).
</footnote>
<bodyText confidence="0.999175">
E-Dictor, so converting GL to C++ seems more nat-
ural than implementing the VLMM TAGGER in Java.
To try to tackle the difficulty in tagging que there
are some ideas about using context trees of non-
local tags. It seems a potentialy good model could
be achieved by mixing such context trees with the
Guided Learning approach, making a hypothesis
consider non adjacent accepted spans. This is still
a fresh idea, so further investigation on maybe other
approaches should be done first.
Further investigation involves analyzing errors
made by POS taggers over modern Portuguese and
other romance languages like Spanish in order to
verify if que and a continue to have the same de-
gree of ambiguity or, in case of Spanish, if there are
similar words which show similar issues. This also
involves testing other taggers with our training and
testing sets, to check if they get the same errors over
que and a as we did.
</bodyText>
<sectionHeader confidence="0.99911" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999402344827586">
Rachel Virgínia Xavier Aires. 2000. Implementação,
adaptação, combinação e avaliação de etiquetadores
para o português do brasil. mathesis, Instituto de Ciên-
cias Matemáticas e Computação, Universidade de São
Paulo - Campus São Carlos, Oct.
Thorsten Brants. 2000. Tnt – a statistical part-of-speech
tagger. In Proceedings of the Sixth Applied Natural
Language Processing Conference (ANLP-2000), Seat-
tle, WA.
Eric Brill. 1993. Automatic grammar induction and pars-
ing free text: A transformation-based approach. In
Proceedings of the 21st Annual Meeting of the Asso-
ciation for Computational Linguistics.
Peter Bühlmann and Abraham J. Wyner. 1999. Variable
length markov chains. Annals of Statistics, 27(2):480–
513.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: theory and experi-
ments with perceptron algorithms. In EMNLP ’02:
Proceedings of the ACL-02 conference on Empirical
methods in natural language processing, pages 1–8,
Morristown, NJ, USA. Association for Computational
Linguistics.
Archias Alves de Almeida Filho. 2002. Maximização
de entropia em lingüística computacional para a língua
portuguesa, 12.
Maria Clara Paixão de Sousa, Fábio Natanael Kepler, and
Pablo Picasso Feliciano de Faria. 2009. E-Dictor: No-
vas perspectivas na codificação e edição de corpora de
</reference>
<page confidence="0.972778">
22
</page>
<reference confidence="0.99937315">
textos históricos. In Linguística de Corpus: Sínteses
e Avanços. Anais do VIII Encontro de Linguística de
Corpus, UERJ, Rio de Janeiro, RJ, Brasil, 11. Shep-
herd, T. and Berber Sardinha, T. and Veirano Pinto, M.
To be published.
Cícero Nogueira dos Santos, Ruy L. Milidiú, and Raúl P.
Rentería. 2008. Portuguese part-of-speech tagging us-
ing entropy guided transformation learning. In PRO-
POR - 8th Workshop on Computational Processing of
Written and Spoken Portuguese, volume 5190 of Lec-
ture Notes in Artificial Intelligence, pages 143–152,
Vitória, ES, Brazil. Springer-Verlag Berlin Heidelberg.
Linguateca.pt, 2008. The Floresta Sintá(c)tica project.
ICMC-USP, 2010. NILC’s Corpora. ICMC-USP.
IEL-UNICAMP and IME-USP, 2010. Córpus Histórico
do Português Anotado Tycho Brahe. IEL-UNICAMP
and IME-USP.
Fábio Natanael Kepler and Marcelo Finger. 2006.
Comparing two markov methods for part-of-speech
tagging of portuguese. In Jaime Simão Sichman,
Helder Coelho, and Solange Oliveira Rezende, editors,
IBERAMIA-SBIA, volume 4140 of Lecture Notes in
Artificial Intelligence, pages 482–491, Ribeirão Preto,
Brazil, 10. Springer Berlin / Heidelberg.
Dan Klein. 2005. The Unsupervised Learning of Natural
Language Structure. phdthesis, Stanford University.
Christopher D. Manning and Hinrich Schütze. 1999.
Foundations Of Statistical Natural Language Process-
ing. MIT Press, Cambridge, MA, USA.
Adwait Ratnaparkhi. 1996. A maximum entropy model
for part-of-speech tagging. In Conference on Empiri-
cal Methods in Natural Language Processing, Univer-
sity of Pennsylvania, 5.
Jorma Rissanen. 1983. A universal data compression
system. IEEE Trans. Inform. Theory, IT-29:656 – 664.
Libin Shen, Giorgio Satta, and Aravind Joshi. 2007.
Guided learning for bidirectional sequence classifica-
tion. In Proceedings of the 45th Annual Meeting of the
Association of Computational Linguistics, pages 760–
767, Prague, Czech Republic, 6. Association for Com-
putational Linguistics.
Kristina Toutanova, Dan Klein, Christopher D. Manning,
and Yoram Singer. 2003. Feature-rich part-of-speech
tagging with a cyclic dependency network. In NAACL
’03: Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology,
pages 173–180, Morristown, NJ, USA. Association for
Computational Linguistics.
Yoshimasa Tsuruoka and Jun’ichi Tsujii. 2005. Bidi-
rectional inference with the easiest-first strategy for
tagging sequence data. In HLT ’05: Proceedings of
the conference on Human Language Technology and
Empirical Methods in Natural Language Processing,
pages 467–474, Morristown, NJ, USA. Association for
Computational Linguistics.
Andrew James Viterbi. 1967. Error bounds for convolu-
tional codes and an asymptotically optimal deconding
algorithm. IEEE Transactions on Information Theory,
pages 260 – 269, 4.
</reference>
<page confidence="0.9989">
23
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.091477">
<title confidence="0.999455">Markov Models and Ambiguous Words in</title>
<author confidence="0.997968">Fabio Natanael Kepler</author>
<affiliation confidence="0.99674">Institute of Mathematics and University of Sao Paulo</affiliation>
<address confidence="0.591872">Sao Paulo, SP,</address>
<email confidence="0.979673">kepler@ime.usp.br</email>
<author confidence="0.598921">Marcelo</author>
<affiliation confidence="0.9963205">Institute of Mathematics and University of Sao</affiliation>
<author confidence="0.506022">Sao Paulo</author>
<author confidence="0.506022">SP</author>
<email confidence="0.984294">mfinger@ime.usp.br</email>
<abstract confidence="0.9996222">Variable-Length Markov Chains (VLMCs) offer a way of modeling contexts longer than trigrams without suffering from data sparsity and state space complexity. However, in Historical Portuguese, two words show a high deof ambiguity: The number of errors tagging these words corresponds to a quarter of the total errors made by a VLMCbased tagger. Moreover, these words seem to show two different types of ambiguity: one depending on non-local context and another on right context. We searched ways of expanding the VLMC-based tagger with a number of different models and methods in order to tackle these issues. The methods showed variable degrees of success, with one particular method solving much of the ambiguity of We explore reasons why this happened, and how everything we tried fails to improve the</abstract>
<intro confidence="0.533095">of</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Rachel Virgínia Xavier Aires</author>
</authors>
<title>Implementação, adaptação, combinação e avaliação de etiquetadores para o português do brasil. mathesis,</title>
<date>2000</date>
<booktitle>Instituto de Ciências Matemáticas e Computação, Universidade de São Paulo - Campus São Carlos,</booktitle>
<contexts>
<context position="3063" citStr="Aires, 2000" startWordPosition="481" endWordPosition="482">ery restrictive issue for languages with lack of resources such as linguistic especialists, corpora projects etc. The Portuguese language falls in between resourceful languages, such as English, and languages with restricted resources. There have been initiatives both in Brazil and in Portugal, which include modern Brazilian Portuguese corpora (ICMC-USP, 2010), European Portuguese corpora (Flo, 2008), and historical Portuguese corpora (IEL-UNICAMP and IME-USP, 2010). Also, some supervised POS taggers have already been developed for Portuguese (dos Santos et al., 2008; Kepler and Finger, 2006; Aires, 2000) with a good degree of success. And finally, there has also been increasing effort and interest in Portuguese annotation tools, such as EDictor1 (de Sousa et al., 2009). Despite these advances, there is still lack of material and resources for Portuguese, as well as research 1See http://purl.org/edictor. Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas, pages 15–23, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics in unsupervised methods to bootstrap text annotation. Our work focuses on f</context>
</contexts>
<marker>Aires, 2000</marker>
<rawString>Rachel Virgínia Xavier Aires. 2000. Implementação, adaptação, combinação e avaliação de etiquetadores para o português do brasil. mathesis, Instituto de Ciências Matemáticas e Computação, Universidade de São Paulo - Campus São Carlos, Oct.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
</authors>
<title>Tnt – a statistical part-of-speech tagger.</title>
<date>2000</date>
<booktitle>In Proceedings of the Sixth Applied Natural Language Processing Conference (ANLP-2000),</booktitle>
<location>Seattle, WA.</location>
<contexts>
<context position="2055" citStr="Brants, 2000" startWordPosition="330" endWordPosition="331">ext where each word occurs to try to solve the ambiguity. Previous and current work have developed a wide range of models and methods for tagging. The vast majority uses supervised learning methods, which &amp;quot;During the course of this work Fabio received support from Brazilian funding agencies CAPES and CNPq. 15 need an already tagged corpus as input in order to train the model, calculating relations, weights, probabilities etc. Among the various models for tagging, there are Maximum Entropy models (dos Santos et al., 2008; de Almeida Filho, 2002; Ratnaparkhi, 1996), Hidden Markov Models (HMMs) (Brants, 2000), Transformation Based Learning (Brill, 1993), and other succesful approaches (Toutanova et al., 2003; Tsuruoka and Tsujii, 2005; Shen et al., 2007). Current state-of-the-art precision in tagging is achieved by supervised methods. Although precision is pretty high – less than 3% error rate for English – the disavantage is exactly the need of a tagged corpus, usually built manually. This is a very restrictive issue for languages with lack of resources such as linguistic especialists, corpora projects etc. The Portuguese language falls in between resourceful languages, such as English, and langu</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>Thorsten Brants. 2000. Tnt – a statistical part-of-speech tagger. In Proceedings of the Sixth Applied Natural Language Processing Conference (ANLP-2000), Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Automatic grammar induction and parsing free text: A transformation-based approach.</title>
<date>1993</date>
<booktitle>In Proceedings of the 21st Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2100" citStr="Brill, 1993" startWordPosition="336" endWordPosition="337"> ambiguity. Previous and current work have developed a wide range of models and methods for tagging. The vast majority uses supervised learning methods, which &amp;quot;During the course of this work Fabio received support from Brazilian funding agencies CAPES and CNPq. 15 need an already tagged corpus as input in order to train the model, calculating relations, weights, probabilities etc. Among the various models for tagging, there are Maximum Entropy models (dos Santos et al., 2008; de Almeida Filho, 2002; Ratnaparkhi, 1996), Hidden Markov Models (HMMs) (Brants, 2000), Transformation Based Learning (Brill, 1993), and other succesful approaches (Toutanova et al., 2003; Tsuruoka and Tsujii, 2005; Shen et al., 2007). Current state-of-the-art precision in tagging is achieved by supervised methods. Although precision is pretty high – less than 3% error rate for English – the disavantage is exactly the need of a tagged corpus, usually built manually. This is a very restrictive issue for languages with lack of resources such as linguistic especialists, corpora projects etc. The Portuguese language falls in between resourceful languages, such as English, and languages with restricted resources. There have be</context>
</contexts>
<marker>Brill, 1993</marker>
<rawString>Eric Brill. 1993. Automatic grammar induction and parsing free text: A transformation-based approach. In Proceedings of the 21st Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Bühlmann</author>
<author>Abraham J Wyner</author>
</authors>
<title>Variable length markov chains.</title>
<date>1999</date>
<journal>Annals of Statistics,</journal>
<volume>27</volume>
<issue>2</issue>
<pages>513</pages>
<contexts>
<context position="5884" citStr="Bühlmann and Wyner, 1999" startWordPosition="932" endWordPosition="935">lts it achieves, and the problems with two common words. Then, in Section 3, we explain in summary the set of models and approaches we tried to mix with VLMCs, and the different types of results they give. Conclusions are drawn in Section 4. Finally, Section 5 describes how this work can be incorporated in other projects, and Section 6 presents ideas for future work. 2More information at http://www.tycho.iel. unicamp.br/~tycho/corpus/en/index.html. 2 Variable-Length Markov Chains The idea is to allow the memory of a Markov chain to have variable length, depending on the observed past values. (Bühlmann and Wyner, 1999) give a formal description of VLMCs, while here we will explain them in terms of the POS-tagging task. Consider a Markov chain with a finite, large order k. Let ti be a tag, and ti−k,i−1 be the k tags preceding ti. Variable length memory can be seen as a cut of irrelevant states from the ti−k,i−1 history. We call the set of these states the context of ti. Given a tag ti, its context ti−h,i−1, h &lt; k, is given by the context function c(ti−k,i−1). A context tree is a tree in which each internal node has at most |T |children, where T is the tagset. Each value of a context function c(·) is represen</context>
</contexts>
<marker>Bühlmann, Wyner, 1999</marker>
<rawString>Peter Bühlmann and Abraham J. Wyner. 1999. Variable length markov chains. Annals of Statistics, 27(2):480– 513.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In EMNLP ’02: Proceedings of the ACL-02 conference on Empirical methods in natural language processing,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="19352" citStr="Collins, 2002" startWordPosition="3356" endWordPosition="3357">44 / 259991 Table 5: Comparison of precision using the VLMM TAGGER (in italics) and the VLMM+A-RIGHT TAGGER (upcase) with the normal corpus. After various tests with different options for the right context tree, the result over the original VLMM tagger did not improve. We then experimented building the right context tree only for the word a, que a que a 19 resulting in the VLMM+RIGHT-A TAGGER. Table 5 shows what happens with the normal corpus.The error rate of a is decreased almost 5% with this bidirectional approach. 3.4 Perceptron The Perceptron algorithm was first applied to POStagging by (Collins, 2002). It is an algorithm for supervised learning that resembles Reinforcement Learning, but is simpler and easier to implement. (Collins, 2002) describes the algorithm for trigram HMM taggers. Here, we will describe it for the VLMM tagger, adapting the notation and explanation. Instead of using maximum-likelihood estimation for the model parameters, the perceptron algorithm works as follows. First, the model parameters are initialized to zero. Then, the algorithm iterates a given number of times over the sentences of the training corpus. For each sentence s, formed by a sequence of words ws paired</context>
<context position="20729" citStr="Collins, 2002" startWordPosition="3599" endWordPosition="3600"> k, k the maximum order of the VLMC, seen c1 times in is and c2 times in zs, we make αc(o) = αc(o) + c1 − c2. c(o) is the context function defined in Section 2 applied to the tag sequence o, which returns the maximum subsequence of o found in the context tree. αc(o) represents the parameters of the model associated to c(o), that is, the branch of the context tree that contains c(o). The above procedure effectively means that parameters which contributed to errors in zs are penalized, while parameters that were not used to predict zs are promoted. If is = zs then no parameter is modified. See (Collins, 2002) for the proof of convergence. Implementing the perceptron algorithm into the VLMM tagger resulted in the VLMM+PERCEPTRON TAGGER. Table 6 shows the results obtained. Note that no prunning is made to the context tree, because doing so led to worse results. Training and predicting with a full context tree of height 10 achieved better precision. The numbers reported were obtained after 25 iterations of perceptron training. The total precision is lower than the VLMM TAGGER’s precision, but it is interesting to note that the precision for que and a actually increased. WORDS P (%) ERR. / OCURR. 84.7</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms. In EMNLP ’02: Proceedings of the ACL-02 conference on Empirical methods in natural language processing, pages 1–8, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Archias Alves de Almeida Filho</author>
</authors>
<title>Maximização de entropia em lingüística computacional para a língua portuguesa,</title>
<date>2002</date>
<pages>12</pages>
<contexts>
<context position="1991" citStr="Filho, 2002" startWordPosition="321" endWordPosition="322">han one class, models for POS tagging have to look at the context where each word occurs to try to solve the ambiguity. Previous and current work have developed a wide range of models and methods for tagging. The vast majority uses supervised learning methods, which &amp;quot;During the course of this work Fabio received support from Brazilian funding agencies CAPES and CNPq. 15 need an already tagged corpus as input in order to train the model, calculating relations, weights, probabilities etc. Among the various models for tagging, there are Maximum Entropy models (dos Santos et al., 2008; de Almeida Filho, 2002; Ratnaparkhi, 1996), Hidden Markov Models (HMMs) (Brants, 2000), Transformation Based Learning (Brill, 1993), and other succesful approaches (Toutanova et al., 2003; Tsuruoka and Tsujii, 2005; Shen et al., 2007). Current state-of-the-art precision in tagging is achieved by supervised methods. Although precision is pretty high – less than 3% error rate for English – the disavantage is exactly the need of a tagged corpus, usually built manually. This is a very restrictive issue for languages with lack of resources such as linguistic especialists, corpora projects etc. The Portuguese language fa</context>
</contexts>
<marker>Filho, 2002</marker>
<rawString>Archias Alves de Almeida Filho. 2002. Maximização de entropia em lingüística computacional para a língua portuguesa, 12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Clara Paixão de Sousa</author>
<author>Fábio Natanael Kepler</author>
<author>Pablo Picasso Feliciano de Faria</author>
</authors>
<title>E-Dictor: Novas perspectivas na codificação e edição de corpora de textos históricos.</title>
<date>2009</date>
<booktitle>In Linguística de Corpus: Sínteses e Avanços. Anais do VIII Encontro de Linguística de Corpus, UERJ, Rio</booktitle>
<note>To be published.</note>
<marker>de Sousa, Kepler, de Faria, 2009</marker>
<rawString>Maria Clara Paixão de Sousa, Fábio Natanael Kepler, and Pablo Picasso Feliciano de Faria. 2009. E-Dictor: Novas perspectivas na codificação e edição de corpora de textos históricos. In Linguística de Corpus: Sínteses e Avanços. Anais do VIII Encontro de Linguística de Corpus, UERJ, Rio de Janeiro, RJ, Brasil, 11. Shepherd, T. and Berber Sardinha, T. and Veirano Pinto, M. To be published.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cícero Nogueira dos Santos</author>
<author>Ruy L Milidiú</author>
<author>Raúl P Rentería</author>
</authors>
<title>Portuguese part-of-speech tagging using entropy guided transformation learning.</title>
<date>2008</date>
<booktitle>In PROPOR - 8th Workshop on Computational Processing of Written and Spoken Portuguese,</booktitle>
<volume>5190</volume>
<pages>143--152</pages>
<publisher>Springer-Verlag</publisher>
<location>Vitória, ES,</location>
<contexts>
<context position="1967" citStr="Santos et al., 2008" startWordPosition="315" endWordPosition="318">e same word may belong to more than one class, models for POS tagging have to look at the context where each word occurs to try to solve the ambiguity. Previous and current work have developed a wide range of models and methods for tagging. The vast majority uses supervised learning methods, which &amp;quot;During the course of this work Fabio received support from Brazilian funding agencies CAPES and CNPq. 15 need an already tagged corpus as input in order to train the model, calculating relations, weights, probabilities etc. Among the various models for tagging, there are Maximum Entropy models (dos Santos et al., 2008; de Almeida Filho, 2002; Ratnaparkhi, 1996), Hidden Markov Models (HMMs) (Brants, 2000), Transformation Based Learning (Brill, 1993), and other succesful approaches (Toutanova et al., 2003; Tsuruoka and Tsujii, 2005; Shen et al., 2007). Current state-of-the-art precision in tagging is achieved by supervised methods. Although precision is pretty high – less than 3% error rate for English – the disavantage is exactly the need of a tagged corpus, usually built manually. This is a very restrictive issue for languages with lack of resources such as linguistic especialists, corpora projects etc. Th</context>
</contexts>
<marker>Santos, Milidiú, Rentería, 2008</marker>
<rawString>Cícero Nogueira dos Santos, Ruy L. Milidiú, and Raúl P. Rentería. 2008. Portuguese part-of-speech tagging using entropy guided transformation learning. In PROPOR - 8th Workshop on Computational Processing of Written and Spoken Portuguese, volume 5190 of Lecture Notes in Artificial Intelligence, pages 143–152, Vitória, ES, Brazil. Springer-Verlag Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Linguateca pt</author>
</authors>
<title>The Floresta Sintá(c)tica project. ICMC-USP,</title>
<date>2008</date>
<publisher>ICMC-USP.</publisher>
<marker>pt, 2008</marker>
<rawString>Linguateca.pt, 2008. The Floresta Sintá(c)tica project. ICMC-USP, 2010. NILC’s Corpora. ICMC-USP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>IEL-UNICAMP</author>
<author>IME-USP</author>
</authors>
<title>Córpus Histórico do Português Anotado Tycho Brahe. IEL-UNICAMP and IME-USP.</title>
<date>2010</date>
<contexts>
<context position="2921" citStr="IEL-UNICAMP and IME-USP, 2010" startWordPosition="457" endWordPosition="460">ugh precision is pretty high – less than 3% error rate for English – the disavantage is exactly the need of a tagged corpus, usually built manually. This is a very restrictive issue for languages with lack of resources such as linguistic especialists, corpora projects etc. The Portuguese language falls in between resourceful languages, such as English, and languages with restricted resources. There have been initiatives both in Brazil and in Portugal, which include modern Brazilian Portuguese corpora (ICMC-USP, 2010), European Portuguese corpora (Flo, 2008), and historical Portuguese corpora (IEL-UNICAMP and IME-USP, 2010). Also, some supervised POS taggers have already been developed for Portuguese (dos Santos et al., 2008; Kepler and Finger, 2006; Aires, 2000) with a good degree of success. And finally, there has also been increasing effort and interest in Portuguese annotation tools, such as EDictor1 (de Sousa et al., 2009). Despite these advances, there is still lack of material and resources for Portuguese, as well as research 1See http://purl.org/edictor. Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas, pages 15–23, Los Angeles, Calif</context>
</contexts>
<marker>IEL-UNICAMP, IME-USP, 2010</marker>
<rawString>IEL-UNICAMP and IME-USP, 2010. Córpus Histórico do Português Anotado Tycho Brahe. IEL-UNICAMP and IME-USP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fábio Natanael Kepler</author>
<author>Marcelo Finger</author>
</authors>
<title>Comparing two markov methods for part-of-speech tagging of portuguese.</title>
<date>2006</date>
<booktitle>In Jaime Simão Sichman, Helder Coelho, and Solange Oliveira Rezende,</booktitle>
<volume>4140</volume>
<pages>482--491</pages>
<editor>editors, IBERAMIA-SBIA,</editor>
<publisher>Springer</publisher>
<location>Ribeirão Preto, Brazil,</location>
<contexts>
<context position="3049" citStr="Kepler and Finger, 2006" startWordPosition="477" endWordPosition="480">ilt manually. This is a very restrictive issue for languages with lack of resources such as linguistic especialists, corpora projects etc. The Portuguese language falls in between resourceful languages, such as English, and languages with restricted resources. There have been initiatives both in Brazil and in Portugal, which include modern Brazilian Portuguese corpora (ICMC-USP, 2010), European Portuguese corpora (Flo, 2008), and historical Portuguese corpora (IEL-UNICAMP and IME-USP, 2010). Also, some supervised POS taggers have already been developed for Portuguese (dos Santos et al., 2008; Kepler and Finger, 2006; Aires, 2000) with a good degree of success. And finally, there has also been increasing effort and interest in Portuguese annotation tools, such as EDictor1 (de Sousa et al., 2009). Despite these advances, there is still lack of material and resources for Portuguese, as well as research 1See http://purl.org/edictor. Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas, pages 15–23, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics in unsupervised methods to bootstrap text annotation. Our wor</context>
<context position="4470" citStr="Kepler and Finger, 2006" startWordPosition="701" endWordPosition="704">cause of its great collaboration potential: it is easily accessible2; is under continuous development; and has recently started using E-Dictor, which also offers a great collaboration potential. 1.1 Previous Works One popular approach to tagging is to use HMMs of order 2. Order 2, or trigram, means the tagger considers the previous two words/tags when tagging a word. This adds context to help disambiguation. The drawback is that this context may not be sufficient. Increasing the order does not help, since this incurs in too many model parameters and suffers from the data sparsity problem. In (Kepler and Finger, 2006), we developed a tagger for Portuguese that uses Markov chains of variable length, that is, orders greater than 2 can be used conditioned on certain tags and sequences of tags. This approach is better at avoiding the sparsity and complexity problems, while being able to model longer contexts. However, one interesting conclusion from that work is that, even using longer contexts, some words stay extremely hard to disambiguate. Apparently, those words rely on flexible contexts not captured by pure VLMCs. Motivated by this problem, we improve over the previous work, and developed a set of tagger </context>
<context position="10509" citStr="Kepler and Finger, 2006" startWordPosition="1752" endWordPosition="1755">der- an IME-USP, P+D-F (D-F). d overflow control, achieves can provide the training and testing corpus if requested by email. 4A package containing the VLMM TAGGER will be available at vlmmtagger/, but requests for the raw source code can be made by email. Currently, there is only an automake bundle re 3We http://www.ime.usp.br/~kepler/ ady for download containing the VLMC TAGGER. Total 95.51 11674 / 259991 Unknown 69.53 2713 / 8904 Unknown 71.60 2528 / 8904 VLMM Known 97.17 7102 / 251087 Total 96.29 9630 / 259991 Table 1: Precision of VLMC-based taggers. 96.29% of while the VLMC TAGGER from (Kepler and Finger, 2006) achieves 95.51%. Table 1 shows the numbers for both taggers, where P and E means Precision an Table 2 shows numbers for the two words that present the most number of errors made by the VLMM TAGGER. Note that they are not necessarily the words with the highest error percentage, since there are known words that appear only a couple of times in the testing corpus an d may get wrong tags half of this times, for example. WORDS P (%) E (%) ERR. / OCURR. Table 2: Results for words with the most number of errors using the VLMM TAGGER with the normal corpus. These two words draw attention because toge</context>
</contexts>
<marker>Kepler, Finger, 2006</marker>
<rawString>Fábio Natanael Kepler and Marcelo Finger. 2006. Comparing two markov methods for part-of-speech tagging of portuguese. In Jaime Simão Sichman, Helder Coelho, and Solange Oliveira Rezende, editors, IBERAMIA-SBIA, volume 4140 of Lecture Notes in Artificial Intelligence, pages 482–491, Ribeirão Preto, Brazil, 10. Springer Berlin / Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
</authors>
<title>The Unsupervised Learning of Natural Language Structure. phdthesis,</title>
<date>2005</date>
<institution>Stanford University.</institution>
<contexts>
<context position="14213" citStr="Klein, 2005" startWordPosition="2436" endWordPosition="2437"> form phrases, like noun phrases (NP), prepositional phrases (PP), and verbal phrases (VP), and use them in the context tree in place of the sequences of tags they cover. The context tree will then have branches like, say, P VP N. In order to train this mixed model we need a treebank, preferably from the texts in the Tycho Brahe corpus. However, it does not have a sufficiently large set of parsed texts to allow efficient supervised learning. Moreover there is not much Portuguese treebanks available, so we were motivated to implement an unsupervised parsed for Portuguese. Based on the work of (Klein, 2005), we implemented his CCM model, and used it over the Tycho Brahe corpus. The CCM model tries to learn constituents based on the contexts they have in common. We achieved 60% of f-measure over a set of texts from the Tycho Brahe project that were already parsed. Using the CCM constituents learned, we extended the VLMM TAGGER to use this extra information. It yielded worse results, so we restricted the use of constituents to que (the VLMM+SPANS-QUE TAGGER). This yielded a precision of 96.56%, with a que precision increase of 3.73% and an a precision reduction of 0.67%. A comparison with the plai</context>
</contexts>
<marker>Klein, 2005</marker>
<rawString>Dan Klein. 2005. The Unsupervised Learning of Natural Language Structure. phdthesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Schütze</author>
</authors>
<title>Foundations Of Statistical Natural Language Processing.</title>
<date>1999</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="15981" citStr="Manning and Schütze, 1999" startWordPosition="2752" endWordPosition="2755">d not improve. This led us to a new approach, shown in the next section. que a 18 3.2 Chunks Since induced syntactic structure did not help, a new idea was to, this time, begin with the already parsed and revised texts from the Tycho Brahe, even with they summing only a little more than 300 thousand words. To ease the problem of sparsity, the trees were flattened and merged in such a way that only NPs, PPs and VPs remained. Then the bracketed notation was converted to the IOB notation, now forming a chunked corpus. Chunking, or shallow parsing, divides a sentence into non-overlapping phrases (Manning and Schütze, 1999). It is used in information extraction and in applications where full parsing is not necessary, offering the advantage of being simpler and faster. We made a small experiment with the chunked corpus: divided the sentences randomly into 90% and 10% sets, the former for training and the later for testing. Then we ran the VLMM TAGGER with these chunked sets, and got a precision in chunking of 79%. A model for chunks processing was mixed into the VLMM model, similar but not equal to the mixed model with CCM. The chunked corpus uses segmented words, because the parsed texts available in Tycho Brahe</context>
</contexts>
<marker>Manning, Schütze, 1999</marker>
<rawString>Christopher D. Manning and Hinrich Schütze. 1999. Foundations Of Statistical Natural Language Processing. MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A maximum entropy model for part-of-speech tagging.</title>
<date>1996</date>
<booktitle>In Conference on Empirical Methods in Natural Language Processing,</booktitle>
<volume>5</volume>
<institution>University of Pennsylvania,</institution>
<contexts>
<context position="2011" citStr="Ratnaparkhi, 1996" startWordPosition="323" endWordPosition="324">, models for POS tagging have to look at the context where each word occurs to try to solve the ambiguity. Previous and current work have developed a wide range of models and methods for tagging. The vast majority uses supervised learning methods, which &amp;quot;During the course of this work Fabio received support from Brazilian funding agencies CAPES and CNPq. 15 need an already tagged corpus as input in order to train the model, calculating relations, weights, probabilities etc. Among the various models for tagging, there are Maximum Entropy models (dos Santos et al., 2008; de Almeida Filho, 2002; Ratnaparkhi, 1996), Hidden Markov Models (HMMs) (Brants, 2000), Transformation Based Learning (Brill, 1993), and other succesful approaches (Toutanova et al., 2003; Tsuruoka and Tsujii, 2005; Shen et al., 2007). Current state-of-the-art precision in tagging is achieved by supervised methods. Although precision is pretty high – less than 3% error rate for English – the disavantage is exactly the need of a tagged corpus, usually built manually. This is a very restrictive issue for languages with lack of resources such as linguistic especialists, corpora projects etc. The Portuguese language falls in between resou</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>Adwait Ratnaparkhi. 1996. A maximum entropy model for part-of-speech tagging. In Conference on Empirical Methods in Natural Language Processing, University of Pennsylvania, 5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorma Rissanen</author>
</authors>
<title>A universal data compression system.</title>
<date>1983</date>
<journal>IEEE Trans. Inform. Theory, IT-29:656 –</journal>
<pages>664</pages>
<contexts>
<context position="6884" citStr="Rissanen, 1983" startWordPosition="1121" endWordPosition="1122"> ti−h,i−1, h &lt; k, is given by the context function c(ti−k,i−1). A context tree is a tree in which each internal node has at most |T |children, where T is the tagset. Each value of a context function c(·) is represented as a branch of such tree. For example, the context given by c(ti−k,i−1) is represented as a branch whose subbranch at the top is determined by ti−1, the next subbranch by ti−2, and so on, until the leaf, determined by ti−h. The parameters of a VLMC are the underlying functions c(·) and their probabilities. To obtain these parameters we use a version of the context algorithm of (Rissanen, 1983). First, it builds a big context tree, using a training corpus. For a tag ti, its maximal history ti−k,i−1 is placed as a branch in the tree. Then, the algorithm uses a pruning function considering a local decision criterion. This pruning cuts off the irrelevant states from the tags’ histories. For each leaf u in the context tree, and branch v that goes from the root to the parent node of u, u is pruned from the tree if (P(t1Ivu) log P(l|v) P(t|vu) /II C(vu) &lt; K, where C(vu) is the number of occurrences of the sequence vu in the training corpus, and K is a threshold value, called the cut value</context>
</contexts>
<marker>Rissanen, 1983</marker>
<rawString>Jorma Rissanen. 1983. A universal data compression system. IEEE Trans. Inform. Theory, IT-29:656 – 664.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Giorgio Satta</author>
<author>Aravind Joshi</author>
</authors>
<title>Guided learning for bidirectional sequence classification.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>760--767</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="2203" citStr="Shen et al., 2007" startWordPosition="351" endWordPosition="354">ng. The vast majority uses supervised learning methods, which &amp;quot;During the course of this work Fabio received support from Brazilian funding agencies CAPES and CNPq. 15 need an already tagged corpus as input in order to train the model, calculating relations, weights, probabilities etc. Among the various models for tagging, there are Maximum Entropy models (dos Santos et al., 2008; de Almeida Filho, 2002; Ratnaparkhi, 1996), Hidden Markov Models (HMMs) (Brants, 2000), Transformation Based Learning (Brill, 1993), and other succesful approaches (Toutanova et al., 2003; Tsuruoka and Tsujii, 2005; Shen et al., 2007). Current state-of-the-art precision in tagging is achieved by supervised methods. Although precision is pretty high – less than 3% error rate for English – the disavantage is exactly the need of a tagged corpus, usually built manually. This is a very restrictive issue for languages with lack of resources such as linguistic especialists, corpora projects etc. The Portuguese language falls in between resourceful languages, such as English, and languages with restricted resources. There have been initiatives both in Brazil and in Portugal, which include modern Brazilian Portuguese corpora (ICMC-</context>
<context position="21615" citStr="Shen et al., 2007" startWordPosition="3751" endWordPosition="3754"> predicting with a full context tree of height 10 achieved better precision. The numbers reported were obtained after 25 iterations of perceptron training. The total precision is lower than the VLMM TAGGER’s precision, but it is interesting to note that the precision for que and a actually increased. WORDS P (%) ERR. / OCURR. 84.74 1687 / 11056 85.15 1641 / 11056 90.94 661 / 7300 92.41 554 / 7300 Total 96.29 9630 / 259991 95.98 10464 / 259991 Table 6: Comparison of precision using the VLMM TAGGER (in italics) and the VLMM+PERCEPTRON TAGGER (upcase) with the normal corpus. 3.5 Guided Learning (Shen et al., 2007) developed new algorithms based on the easiest-first strategy (Tsuruoka and Tsujii, 2005) and the perceptron algorithm. The strategy is to first tag words that show less ambiguity, and then use the tags already available as context for the more difficult words. That means the order of tagging is not necessarily from left to right. The inference algorithm works by maintaining hypotheses of tags for spans over a sequence of words, and two queues, one for accepted spans and one for candidate spans. Beam search is used for keeping only a fixed number of candidate hypotheses for each accepted span.</context>
</contexts>
<marker>Shen, Satta, Joshi, 2007</marker>
<rawString>Libin Shen, Giorgio Satta, and Aravind Joshi. 2007. Guided learning for bidirectional sequence classification. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 760– 767, Prague, Czech Republic, 6. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-of-speech tagging with a cyclic dependency network. In</title>
<date>2003</date>
<booktitle>NAACL ’03: Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology,</booktitle>
<pages>173--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2156" citStr="Toutanova et al., 2003" startWordPosition="342" endWordPosition="345">eloped a wide range of models and methods for tagging. The vast majority uses supervised learning methods, which &amp;quot;During the course of this work Fabio received support from Brazilian funding agencies CAPES and CNPq. 15 need an already tagged corpus as input in order to train the model, calculating relations, weights, probabilities etc. Among the various models for tagging, there are Maximum Entropy models (dos Santos et al., 2008; de Almeida Filho, 2002; Ratnaparkhi, 1996), Hidden Markov Models (HMMs) (Brants, 2000), Transformation Based Learning (Brill, 1993), and other succesful approaches (Toutanova et al., 2003; Tsuruoka and Tsujii, 2005; Shen et al., 2007). Current state-of-the-art precision in tagging is achieved by supervised methods. Although precision is pretty high – less than 3% error rate for English – the disavantage is exactly the need of a tagged corpus, usually built manually. This is a very restrictive issue for languages with lack of resources such as linguistic especialists, corpora projects etc. The Portuguese language falls in between resourceful languages, such as English, and languages with restricted resources. There have been initiatives both in Brazil and in Portugal, which inc</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher D. Manning, and Yoram Singer. 2003. Feature-rich part-of-speech tagging with a cyclic dependency network. In NAACL ’03: Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, pages 173–180, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshimasa Tsuruoka</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Bidirectional inference with the easiest-first strategy for tagging sequence data. In</title>
<date>2005</date>
<booktitle>HLT ’05: Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>467--474</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2183" citStr="Tsuruoka and Tsujii, 2005" startWordPosition="346" endWordPosition="350">odels and methods for tagging. The vast majority uses supervised learning methods, which &amp;quot;During the course of this work Fabio received support from Brazilian funding agencies CAPES and CNPq. 15 need an already tagged corpus as input in order to train the model, calculating relations, weights, probabilities etc. Among the various models for tagging, there are Maximum Entropy models (dos Santos et al., 2008; de Almeida Filho, 2002; Ratnaparkhi, 1996), Hidden Markov Models (HMMs) (Brants, 2000), Transformation Based Learning (Brill, 1993), and other succesful approaches (Toutanova et al., 2003; Tsuruoka and Tsujii, 2005; Shen et al., 2007). Current state-of-the-art precision in tagging is achieved by supervised methods. Although precision is pretty high – less than 3% error rate for English – the disavantage is exactly the need of a tagged corpus, usually built manually. This is a very restrictive issue for languages with lack of resources such as linguistic especialists, corpora projects etc. The Portuguese language falls in between resourceful languages, such as English, and languages with restricted resources. There have been initiatives both in Brazil and in Portugal, which include modern Brazilian Portu</context>
<context position="21704" citStr="Tsuruoka and Tsujii, 2005" startWordPosition="3763" endWordPosition="3766">numbers reported were obtained after 25 iterations of perceptron training. The total precision is lower than the VLMM TAGGER’s precision, but it is interesting to note that the precision for que and a actually increased. WORDS P (%) ERR. / OCURR. 84.74 1687 / 11056 85.15 1641 / 11056 90.94 661 / 7300 92.41 554 / 7300 Total 96.29 9630 / 259991 95.98 10464 / 259991 Table 6: Comparison of precision using the VLMM TAGGER (in italics) and the VLMM+PERCEPTRON TAGGER (upcase) with the normal corpus. 3.5 Guided Learning (Shen et al., 2007) developed new algorithms based on the easiest-first strategy (Tsuruoka and Tsujii, 2005) and the perceptron algorithm. The strategy is to first tag words that show less ambiguity, and then use the tags already available as context for the more difficult words. That means the order of tagging is not necessarily from left to right. The inference algorithm works by maintaining hypotheses of tags for spans over a sequence of words, and two queues, one for accepted spans and one for candidate spans. Beam search is used for keeping only a fixed number of candidate hypotheses for each accepted span. New words from the queue of candidates are tagged based on their scores, computed by con</context>
</contexts>
<marker>Tsuruoka, Tsujii, 2005</marker>
<rawString>Yoshimasa Tsuruoka and Jun’ichi Tsujii. 2005. Bidirectional inference with the easiest-first strategy for tagging sequence data. In HLT ’05: Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 467–474, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew James Viterbi</author>
</authors>
<title>Error bounds for convolutional codes and an asymptotically optimal deconding algorithm.</title>
<date>1967</date>
<journal>IEEE Transactions on Information Theory,</journal>
<pages>260--269</pages>
<contexts>
<context position="8257" citStr="Viterbi, 1967" startWordPosition="1376" endWordPosition="1377">idering only the branch (the history without the furthest tag), then the leaf does not need to be considered, and can be removed from the tree. We want to find the best sequence of tags t1 ... t,,, for a given sequence of words w1 ... w,,, of size n, 1: Ovu = tEL 16 that is, are computed from a tagged training corpus using maximum likelihood estimation from the relative frequencies of words and sequences of tags. The context tree is built with sequences of tags of maximum length k an Probabilities d then pruned, thus defining the context functions. For decoding, the Viterbi Algorithm is used (Viterbi, 1967). precision5, d Error, respectively. The difference in precision is mainly due to a 21.64% error reduction in known words tagging6. That, combined with 6.82% error reduction in unknown words, results in 17.50% total error reduction. With the segmented corpus the VLMM TAGGER achieved 96.54% of precision. TAGGER WORDS P (%) ERR. OCURR. � n arg max H P(ti|c(ti−k,i−1))P(wi|ti) . t1...tn i=1 2.1 Initial Results VLMC Known 96.39 9065 / 251087 We used the tagged texts available by the Tycho Brahe Corpus of Historical Portuguese (IELUNICAMP and 2010). The Tycho Brahe project uses 377 POS and inflectio</context>
</contexts>
<marker>Viterbi, 1967</marker>
<rawString>Andrew James Viterbi. 1967. Error bounds for convolutional codes and an asymptotically optimal deconding algorithm. IEEE Transactions on Information Theory, pages 260 – 269, 4.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>