<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000234">
<note confidence="0.866502">
SENSEVAL-3: Third International Workshop on the Evaluation of Systems
for the Semantic Analysis of Text, Barcelona, Spain, July 2004
</note>
<title confidence="0.8300565">
Association for Computational Linguistics
Senseval 3 Logic Forms: A System and Possible Improvements
</title>
<author confidence="0.985213">
Altaf Mohammed, Dan Moldovan, and Paul Parker
</author>
<affiliation confidence="0.764969">
Language Computer Corporation
</affiliation>
<address confidence="0.74044">
Richardson, TX 75080
</address>
<email confidence="0.963431">
{altaf, moldovan, parker}@languagecomputer.com
</email>
<sectionHeader confidence="0.993016" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99953725">
Logic Forms, particular powerful logic
representations presented in Moldovan
and Rus (2001), are simple yet highly ef-
fective. In this paper, the structure of
Logic Forms and their generation from
input text are described. The results of an
evaluation comparing the Logic Forms
generated by hand with those generated
automatically are also reported. Finally,
we suggest some improvements to the
representation used in the LFI task based
on our results.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999446">
Logic Forms are first order logic representations
of natural language text. The notation is very
close to the natural language. A Logic Form is a
collection of predicate instances derived from
text. A detailed description of the notation is pre-
sented in Moldovan and Rus (2001).
Logic Forms can be utilized by a wide variety
of applications. A Logic Prover (Rus, 2002;
Moldovan et al., 2003) utilizing the axioms gen-
erated by the Logic Form generation system
boosts the performance of the Question Answer-
ing system. The Prover essentially takes as input
the Logic Forms of the question and one or more
answers and then proceeds to justify (and rank)
the answers based on (i) world knowledge axi-
oms, and (ii) NLP axioms. The Logic Prover de-
veloped at Language Computer Corporation has
increased the performance of the QA system by
30%.
</bodyText>
<sectionHeader confidence="0.784895" genericHeader="method">
2 Automatic Generation of Logic Forms
</sectionHeader>
<subsectionHeader confidence="0.92355">
2.1 Parse Tree Construction
</subsectionHeader>
<bodyText confidence="0.99987305">
Logic Forms are derived from the output of a
syntactic parser. The first step is the identifica-
tion of word collocations (based on those identi-
fied by WordNet (Miller, 1995)). The parser then
proceeds to identify (i) parts of speech of indi-
vidual words, and (ii) syntactic structure of the
text, based on grammar rules. It also differenti-
ates active verb constructs from passive ones.
The output is a parse tree. We also include in the
parse tree (i) word senses, based on WordNet,
and (ii) named-entity tags (Surdeanu and Hara-
bagiu, 2002). Named-entity tags are tags associ-
ated with a word or group of words, indicating
that they belong to a particular category, for in-
stance, currency, time, date, place, human, etc.
The word senses from the parse tree are simply
included in the Logic Form as is (for subsequent
use in applications), while the named-entity tags
are additionally used in the generation of Logic
Forms.
</bodyText>
<subsectionHeader confidence="0.996574">
2.2 Logic Form Generation
</subsectionHeader>
<bodyText confidence="0.999981258064516">
First we identify independent arguments (those
arguments which are generated anew for certain
predicates). These include arguments for nouns,
verbs (action/eventuality only), and compound
nouns and coordinating conjunctions (for both of
these, only the result argument (or the first one)).
Independent arguments are also generated for
certain adjectival phrases and/or determiners in
the rare cases when they do not qualify a noun
phrase, but stand all by themselves. The inde-
pendent arguments, once generated, are propa-
gated up the parse tree (as predicates form the
leaves of the parse tree). In this way, heads of
phrases are marked.
Next comes the identification of dependent ar-
guments (those which are derived from other in-
dependent and/or dependent arguments). These
may include arguments for modifiers (adjectives,
adverbs), secondary verb slots (all except the
first) and secondary coordinating conjunction
slots (all except the resulting argument), or link-
ing words (prepositions, subordinating conjunc-
tions, etc). The derivation of these arguments
follows from a slot-filling approach and is based
on the interpretation of the parse tree structure
and the associated transformation rule (Moldovan
and Rus, 2001). This is a rule that says how a
particular parse tree structure must be handled,
for instance, &apos;S -&gt; NP VP&apos; says that the subject of
the main/action verb of VP is the head of phrase
of NP.
</bodyText>
<sectionHeader confidence="0.800055" genericHeader="method">
3 Dealing with Ambiguous Structures
</sectionHeader>
<bodyText confidence="0.993411695652174">
Named-entity tags are helpful when parsing cer-
tain ambiguous structures. Take, for instance, the
following two sentences:
(i) They gave the visiting team a heavy loss.
(ii) They played football every evening.
The grammar rule for the verb phrase in both
sentences is &apos;VP -&gt; VB NP NP&apos;.
Whereas, in sentence (i), the first NP is the in-
direct object and the second one the direct, ex-
actly the converse is true for sentence (ii). Upon
closer examination, it is found that &apos;every eve-
ning&apos; being an indicator of time, does not qualify
for the position of the direct object.
The named-entity recognition system marks all
such indicators of time/date. This enables us to
disqualify these noun phrases as candidates for
the position of the direct object of a verb.
The aforementioned is just one kind of ambi-
guity that we have addressed. Another kind of
ambiguity that we encountered (but have not im-
plemented a solution for yet) is the reduction of
certain words to base forms. Consider, for in-
stance,
</bodyText>
<listItem confidence="0.780797666666667">
(i) John found the key. (‘find’ in VBN form)
(ii) The King promised to found a similar insti-
tution. (‘found’ in VB form)
</listItem>
<bodyText confidence="0.9994262">
A possible solution we considered was looking
at part-of-speech tags (VBN vs. VB) to resolve
ambiguity, but have not pursued this further in
the (current) absence of a database that maintains
a mapping from inflected word and part-of-
speech pairs to the corresponding base forms.
Another approach considered was choosing the
base form whose frequency of occurrence in the
Brown corpus, as reflected in WordNet, was
highest.
</bodyText>
<sectionHeader confidence="0.999067" genericHeader="method">
4 Changes/Improvements for Senseval 3
</sectionHeader>
<bodyText confidence="0.999948333333333">
Since no complete specification was given for the
proper formation of logic forms for many special
cases, we chose to model our Senseval 3 Logic
Form system on the provided examples. The LF
system was updated to model the Senseval 3 be-
havior in the following ways.
</bodyText>
<subsectionHeader confidence="0.996206">
4.1 Adverbs Modifying Adjectives
</subsectionHeader>
<bodyText confidence="0.999261">
These adverbs are assigned the same argument as
the adjective they modify (Mohammed, 2003).
For instance, “the extremely fast athlete” is rep-
resented as “extremely:r_ (x1) fast:a_ (x1) ath-
lete:n_ (x1)”.
</bodyText>
<subsectionHeader confidence="0.985209">
4.2 Variable Slots for Verbs
</subsectionHeader>
<bodyText confidence="0.998642444444444">
The verbs are now given a variable number of
arguments (minimum two: the action/eventuality
and the subject). They get arguments for all verb
objects, including prepositional attachments.
Previously, we had a fixed slot allocation
mechanism for verbs, specifying always the ac-
tion, the subject, and the direct object. These
slots were filled with dummy arguments in the
absence of proper arguments.
</bodyText>
<equation confidence="0.936001625">
Example:
S: John gave Mary the book on Saturday.
LF (previous notation)
John:n_ (x1) give:v_ (e1, x1, x3) Mary:n_ (x2)
book:n_ (x3) on (e1, x4) Saturday:n_ (x4)
LF (Senseval 3 notation)
John:n_ (x1) give:v_ (e1, x1, x3, x2, x4) Mary:n_
(x2) book:n_ (x3) on (e1, x4) Saturday:n_ (x4)
</equation>
<subsectionHeader confidence="0.999049">
4.3 Subordinating Conjunctions
</subsectionHeader>
<bodyText confidence="0.999808777777778">
These conjunctions are given two arguments. The
second argument is the main/action verb of the
subordinate clause. The first argument is as-
signed as follows: (i) if the clause attaches to a
sentence (or a verb phrase), then the main/action
verb of this sentence (or verb phrase), (ii) if the
clause attaches to a noun phrase, then the head of
the noun phrase. Additional details are presented
in Mohammed (2003).
</bodyText>
<figure confidence="0.6032846">
Example:
If you heat ice, it melts.
LF:
If (e2, e1) you (x1) heat:v_ (e1, x1, x2) ice:n_
(x2) it (x3) melt:v_ (e2, x3)
</figure>
<sectionHeader confidence="0.866622" genericHeader="method">
5 Impact of Parse Tree Accuracy on
Logic Forms
</sectionHeader>
<bodyText confidence="0.9998">
The Logic Forms are derived directly from the
parse trees. This makes the generation of accurate
parse trees extremely important. We have ana-
lyzed the performance of automatically generated
Logic Forms based on both the machine-
generated (hence necessarily somewhat errone-
ous) parse trees and parse trees generated by hu-
man annotators.
The following results are based on the set of
300 test sentences provided for the Logic Forms
Identification task at Senseval 3. The number of
sentences with all predicates correctly identified
has increased from 155 to 191, an improvement
of 23.2%. The number of sentences with all cor-
rect arguments and all correct predicates (in other
words, 100% correct Logic Forms) has increased
from 65 to 98, a 50.7% improvement over Logic
Forms derived from machine-generated parse
trees. The results are presented in Table 1. Note
that the row captioned “Predicates” indicates the
number of sentences for which all predicates
were correctly identified, while the row cap-
tioned “Entire LF” indicates those for which all
predicates as well as all associated arguments
were correctly identified.
</bodyText>
<table confidence="0.99953725">
Machine Hand Improve-
Parse Parse ment
Predicates 155 / 300 191 / 300 23.2%
Entire LF 65 / 300 98 / 300 50.7%
</table>
<tableCaption confidence="0.726778">
Table 1: Performance of LF Generation
System
</tableCaption>
<sectionHeader confidence="0.989964" genericHeader="conclusions">
6 Recommendations
</sectionHeader>
<bodyText confidence="0.999971">
The sample data provided for the LFI task was
used as the model for expected system behavior.
A few recommendations that we believe would
be improvements are below. Note that neither
space nor time permitted an extensive considera-
tion of other alternatives.
</bodyText>
<subsectionHeader confidence="0.997905">
6.1 Possessive Pronouns
</subsectionHeader>
<bodyText confidence="0.731956428571429">
Possessive pronouns are treated as mere adjec-
tives in the sample data. A better way would be
to handle these as any other possession indicator,
and thus treat them as two-argument predicates.
Example:
S: John drives his car.
LF (Sample data):
</bodyText>
<equation confidence="0.985806">
John:n_ (x1) drive: v (e1, x1, x2) his (x2) car: n_
(x2) _
LF (recommendation):
John:n_ (x1) drive:v_ (e1, x1, x2) his (x2, x1)
car:n_ (x2)
</equation>
<subsectionHeader confidence="0.997697">
6.2 Hybrid Verb Slot Representation
</subsectionHeader>
<bodyText confidence="0.999921928571428">
A verb&apos;s slots are supposed to signify their rela-
tion to the verb. The first slot is always reserved
for the action/eventuality expressed by the verb.
The second, then, is always for the subject of the
verb. Now, the third slot should be reserved for
the direct object of the verb (if any), and then,
additional slots should be filled if and only if
there are indirect objects associated with the
verb.
We propose using either dummy or null argu-
ments for certain slots. For instance, for a verb
that has only indirect objects (apart from a sub-
ject), the representation for the verb can be, for
instance,
</bodyText>
<equation confidence="0.789308">
run:v_ (e1, x3, 0, x4, x6, ...), or
</equation>
<bodyText confidence="0.883284">
run:v_ (e1, x3, x9, x4, x6, ...), where &apos;x9&apos; is a
dummy argument that is not referenced anywhere
else in the Logic Form.
Moreover, the inclusion of prepositional at-
tachments in the verb slots is a kind of redun-
dancy that should be avoided. The following
examples will make this proposal clear.
S: John plays at the park.
</bodyText>
<construct confidence="0.967179285714286">
LF: John:n_ (x1) play:v_ (e1, x1) at (e1, x2)
park:n_ (x2)
S: John plays every day at the park.
LF: John:n_ (x1) play:v_ (e1, x1, 0, x2)
every:a_ (x2) day:n_ (x2) at (e1, x3) park:n_ (x3)
S: John plays tennis every day at the park.
LF: John:n_ (x1) play:v_ (e1, x1, x2, x3) ten-
nis:n_ (x2) every:a_ (x3) day:n_ (x3) at (e1, x4)
park:n_ (x4)
S: John gives Mary the book every evening in
the library.
LF: John:n_ (x1) give:v_ (e1, x1, x3, x2, x4)
Mary:n_ (x2) book:n_ (x3) every:a_ (x4) eve-
ning:n_ (x4) in (e1, x5) library:n_ (x5)
</construct>
<bodyText confidence="0.9999498">
Note that none of the examples include the ar-
guments for ‘park’ or ‘library’ in the slots for
verbs. Since these predicates are already con-
nected to the verbs via prepositions, it is unnec-
essary to also include them in verb slots.
</bodyText>
<sectionHeader confidence="0.999194" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99874555">
George A. Miller. 1995. WordNet: A lexical database
for English. In Communications of the ACM, pages
39-41.
Altaf Mohammed. 2003. Logic Form Transformation
of WordNet Glosses. Master’s dissertation, Univer-
sity of Texas at Dallas, Richardson, TX.
Dan I. Moldovan and Vasile Rus. 2001. Logic Form
Transformation of WordNet and its Applicability to
Question Answering. In Proceedings of the ACL
2001 Conference, July 2001, Toulouse, France.
Dan Moldovan et al. 2003. COGEX: A Logic Prover
for Question Answering. In Proceedings of the
Human Language Technology Conference.
Vasile Rus. 2002. Logic Forms for WordNet Glosses.
Ph.D. dissertation, Southern Methodist University,
Dallas, TX.
Mihai Surdeanu and Sanda Harabagiu. 2002. Infra-
structure for Open-Domain Information Extraction.
In Proceedings of the Human Language Technol-
ogy Conference (HLT 2002): 325-330.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.306944">
<note confidence="0.7916926">SENSEVAL-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, Barcelona, Spain, July 2004 Association for Computational Linguistics Senseval 3 Logic Forms: A System and Possible Improvements Altaf Mohammed, Dan Moldovan, and Paul</note>
<affiliation confidence="0.873445">Language Computer</affiliation>
<address confidence="0.80201">Richardson, TX</address>
<email confidence="0.992842">altaf@languagecomputer.com</email>
<email confidence="0.992842">moldovan@languagecomputer.com</email>
<email confidence="0.992842">parker@languagecomputer.com</email>
<abstract confidence="0.999382538461539">Logic Forms, particular powerful logic representations presented in Moldovan and Rus (2001), are simple yet highly effective. In this paper, the structure of Logic Forms and their generation from input text are described. The results of an evaluation comparing the Logic Forms generated by hand with those generated automatically are also reported. Finally, we suggest some improvements to the representation used in the LFI task based on our results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>WordNet: A lexical database for English.</title>
<date>1995</date>
<booktitle>In Communications of the ACM,</booktitle>
<pages>39--41</pages>
<contexts>
<context position="1928" citStr="Miller, 1995" startWordPosition="301" endWordPosition="302">osts the performance of the Question Answering system. The Prover essentially takes as input the Logic Forms of the question and one or more answers and then proceeds to justify (and rank) the answers based on (i) world knowledge axioms, and (ii) NLP axioms. The Logic Prover developed at Language Computer Corporation has increased the performance of the QA system by 30%. 2 Automatic Generation of Logic Forms 2.1 Parse Tree Construction Logic Forms are derived from the output of a syntactic parser. The first step is the identification of word collocations (based on those identified by WordNet (Miller, 1995)). The parser then proceeds to identify (i) parts of speech of individual words, and (ii) syntactic structure of the text, based on grammar rules. It also differentiates active verb constructs from passive ones. The output is a parse tree. We also include in the parse tree (i) word senses, based on WordNet, and (ii) named-entity tags (Surdeanu and Harabagiu, 2002). Named-entity tags are tags associated with a word or group of words, indicating that they belong to a particular category, for instance, currency, time, date, place, human, etc. The word senses from the parse tree are simply include</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A. Miller. 1995. WordNet: A lexical database for English. In Communications of the ACM, pages 39-41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Altaf Mohammed</author>
</authors>
<title>Logic Form Transformation of WordNet Glosses. Master’s dissertation,</title>
<date>2003</date>
<institution>University of Texas at Dallas,</institution>
<location>Richardson, TX.</location>
<contexts>
<context position="6113" citStr="Mohammed, 2003" startWordPosition="988" endWordPosition="989">peech pairs to the corresponding base forms. Another approach considered was choosing the base form whose frequency of occurrence in the Brown corpus, as reflected in WordNet, was highest. 4 Changes/Improvements for Senseval 3 Since no complete specification was given for the proper formation of logic forms for many special cases, we chose to model our Senseval 3 Logic Form system on the provided examples. The LF system was updated to model the Senseval 3 behavior in the following ways. 4.1 Adverbs Modifying Adjectives These adverbs are assigned the same argument as the adjective they modify (Mohammed, 2003). For instance, “the extremely fast athlete” is represented as “extremely:r_ (x1) fast:a_ (x1) athlete:n_ (x1)”. 4.2 Variable Slots for Verbs The verbs are now given a variable number of arguments (minimum two: the action/eventuality and the subject). They get arguments for all verb objects, including prepositional attachments. Previously, we had a fixed slot allocation mechanism for verbs, specifying always the action, the subject, and the direct object. These slots were filled with dummy arguments in the absence of proper arguments. Example: S: John gave Mary the book on Saturday. LF (previo</context>
<context position="7379" citStr="Mohammed (2003)" startWordPosition="1192" endWordPosition="1193">:n_ (x2) book:n_ (x3) on (e1, x4) Saturday:n_ (x4) LF (Senseval 3 notation) John:n_ (x1) give:v_ (e1, x1, x3, x2, x4) Mary:n_ (x2) book:n_ (x3) on (e1, x4) Saturday:n_ (x4) 4.3 Subordinating Conjunctions These conjunctions are given two arguments. The second argument is the main/action verb of the subordinate clause. The first argument is assigned as follows: (i) if the clause attaches to a sentence (or a verb phrase), then the main/action verb of this sentence (or verb phrase), (ii) if the clause attaches to a noun phrase, then the head of the noun phrase. Additional details are presented in Mohammed (2003). Example: If you heat ice, it melts. LF: If (e2, e1) you (x1) heat:v_ (e1, x1, x2) ice:n_ (x2) it (x3) melt:v_ (e2, x3) 5 Impact of Parse Tree Accuracy on Logic Forms The Logic Forms are derived directly from the parse trees. This makes the generation of accurate parse trees extremely important. We have analyzed the performance of automatically generated Logic Forms based on both the machinegenerated (hence necessarily somewhat erroneous) parse trees and parse trees generated by human annotators. The following results are based on the set of 300 test sentences provided for the Logic Forms Ide</context>
</contexts>
<marker>Mohammed, 2003</marker>
<rawString>Altaf Mohammed. 2003. Logic Form Transformation of WordNet Glosses. Master’s dissertation, University of Texas at Dallas, Richardson, TX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan I Moldovan</author>
<author>Vasile Rus</author>
</authors>
<title>Logic Form Transformation of WordNet and its Applicability to Question Answering.</title>
<date>2001</date>
<booktitle>In Proceedings of the ACL 2001 Conference,</booktitle>
<location>Toulouse, France.</location>
<contexts>
<context position="1131" citStr="Moldovan and Rus (2001)" startWordPosition="163" endWordPosition="166">ive. In this paper, the structure of Logic Forms and their generation from input text are described. The results of an evaluation comparing the Logic Forms generated by hand with those generated automatically are also reported. Finally, we suggest some improvements to the representation used in the LFI task based on our results. 1 Introduction Logic Forms are first order logic representations of natural language text. The notation is very close to the natural language. A Logic Form is a collection of predicate instances derived from text. A detailed description of the notation is presented in Moldovan and Rus (2001). Logic Forms can be utilized by a wide variety of applications. A Logic Prover (Rus, 2002; Moldovan et al., 2003) utilizing the axioms generated by the Logic Form generation system boosts the performance of the Question Answering system. The Prover essentially takes as input the Logic Forms of the question and one or more answers and then proceeds to justify (and rank) the answers based on (i) world knowledge axioms, and (ii) NLP axioms. The Logic Prover developed at Language Computer Corporation has increased the performance of the QA system by 30%. 2 Automatic Generation of Logic Forms 2.1 </context>
<context position="3923" citStr="Moldovan and Rus, 2001" startWordPosition="611" endWordPosition="614">this way, heads of phrases are marked. Next comes the identification of dependent arguments (those which are derived from other independent and/or dependent arguments). These may include arguments for modifiers (adjectives, adverbs), secondary verb slots (all except the first) and secondary coordinating conjunction slots (all except the resulting argument), or linking words (prepositions, subordinating conjunctions, etc). The derivation of these arguments follows from a slot-filling approach and is based on the interpretation of the parse tree structure and the associated transformation rule (Moldovan and Rus, 2001). This is a rule that says how a particular parse tree structure must be handled, for instance, &apos;S -&gt; NP VP&apos; says that the subject of the main/action verb of VP is the head of phrase of NP. 3 Dealing with Ambiguous Structures Named-entity tags are helpful when parsing certain ambiguous structures. Take, for instance, the following two sentences: (i) They gave the visiting team a heavy loss. (ii) They played football every evening. The grammar rule for the verb phrase in both sentences is &apos;VP -&gt; VB NP NP&apos;. Whereas, in sentence (i), the first NP is the indirect object and the second one the dire</context>
</contexts>
<marker>Moldovan, Rus, 2001</marker>
<rawString>Dan I. Moldovan and Vasile Rus. 2001. Logic Form Transformation of WordNet and its Applicability to Question Answering. In Proceedings of the ACL 2001 Conference, July 2001, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Moldovan</author>
</authors>
<title>COGEX: A Logic Prover for Question Answering.</title>
<date>2003</date>
<booktitle>In Proceedings of the Human Language Technology Conference.</booktitle>
<marker>Moldovan, 2003</marker>
<rawString>Dan Moldovan et al. 2003. COGEX: A Logic Prover for Question Answering. In Proceedings of the Human Language Technology Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasile Rus</author>
</authors>
<title>Logic Forms for WordNet Glosses.</title>
<date>2002</date>
<institution>Southern Methodist University,</institution>
<location>Dallas, TX.</location>
<note>Ph.D. dissertation,</note>
<contexts>
<context position="1221" citStr="Rus, 2002" startWordPosition="181" endWordPosition="182"> results of an evaluation comparing the Logic Forms generated by hand with those generated automatically are also reported. Finally, we suggest some improvements to the representation used in the LFI task based on our results. 1 Introduction Logic Forms are first order logic representations of natural language text. The notation is very close to the natural language. A Logic Form is a collection of predicate instances derived from text. A detailed description of the notation is presented in Moldovan and Rus (2001). Logic Forms can be utilized by a wide variety of applications. A Logic Prover (Rus, 2002; Moldovan et al., 2003) utilizing the axioms generated by the Logic Form generation system boosts the performance of the Question Answering system. The Prover essentially takes as input the Logic Forms of the question and one or more answers and then proceeds to justify (and rank) the answers based on (i) world knowledge axioms, and (ii) NLP axioms. The Logic Prover developed at Language Computer Corporation has increased the performance of the QA system by 30%. 2 Automatic Generation of Logic Forms 2.1 Parse Tree Construction Logic Forms are derived from the output of a syntactic parser. The</context>
</contexts>
<marker>Rus, 2002</marker>
<rawString>Vasile Rus. 2002. Logic Forms for WordNet Glosses. Ph.D. dissertation, Southern Methodist University, Dallas, TX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Sanda Harabagiu</author>
</authors>
<title>Infrastructure for Open-Domain Information Extraction.</title>
<date>2002</date>
<booktitle>In Proceedings of the Human Language Technology Conference (HLT</booktitle>
<pages>325--330</pages>
<contexts>
<context position="2294" citStr="Surdeanu and Harabagiu, 2002" startWordPosition="361" endWordPosition="365">f the QA system by 30%. 2 Automatic Generation of Logic Forms 2.1 Parse Tree Construction Logic Forms are derived from the output of a syntactic parser. The first step is the identification of word collocations (based on those identified by WordNet (Miller, 1995)). The parser then proceeds to identify (i) parts of speech of individual words, and (ii) syntactic structure of the text, based on grammar rules. It also differentiates active verb constructs from passive ones. The output is a parse tree. We also include in the parse tree (i) word senses, based on WordNet, and (ii) named-entity tags (Surdeanu and Harabagiu, 2002). Named-entity tags are tags associated with a word or group of words, indicating that they belong to a particular category, for instance, currency, time, date, place, human, etc. The word senses from the parse tree are simply included in the Logic Form as is (for subsequent use in applications), while the named-entity tags are additionally used in the generation of Logic Forms. 2.2 Logic Form Generation First we identify independent arguments (those arguments which are generated anew for certain predicates). These include arguments for nouns, verbs (action/eventuality only), and compound noun</context>
</contexts>
<marker>Surdeanu, Harabagiu, 2002</marker>
<rawString>Mihai Surdeanu and Sanda Harabagiu. 2002. Infrastructure for Open-Domain Information Extraction. In Proceedings of the Human Language Technology Conference (HLT 2002): 325-330.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>