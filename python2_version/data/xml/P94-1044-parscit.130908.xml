<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000047">
<title confidence="0.8998125">
GRADED UNIFICATION: A FRAMEWORK FOR
INTERACTIVE PROCESSING
</title>
<author confidence="0.99921">
Albert Kim *
</author>
<affiliation confidence="0.855566">
Department of Computer and Information Sciences
University of Pennsylvania
Philadelphia, Pennsylvania, USA
</affiliation>
<email confidence="0.999729">
email: alkim@unagi.cis.upenn.edu
</email>
<sectionHeader confidence="0.980224" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997404">
An extension to classical unification, called graded unifica-
tion is presented. It is capable of combining contradictory
information. An interactive processing paradigm and parser
based on this new operator are also presented.
</bodyText>
<sectionHeader confidence="0.936975" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.999912421052631">
Improved understanding of the nature of knowledge
used in human language processing suggests the fea-
sibility of interactive models in computational linguis-
tics (CL). Recent psycholinguistic work such as (Stowe,
1989; Trueswell et al., 1994) has documented rapid em-
ployment of semantic information to guide human syn-
tactic processing. In addition, corpus-based stochas-
tic modelling of lexical patterns (see Weischedel ei al.,
1993) may provide information about word sense fre-
quency of the kind advocated since (Ford et al., 1982).
Incremental employment of such knowledge to resolve
syntactic ambiguity is a natural step towards improved
cognitive accuracy and efficiency in CL models.
This exercise will, however, pose difficulties for the
classical (&apos;hard&apos;) constraint-based paradigm. As illus-
trated by the Trueswell et al. (1994) results, this view
of constraints is too rigid to handle the kinds of effects
at hand. These experiments used pairs of locally am-
biguous reduced relative clauses such as:
</bodyText>
<listItem confidence="0.9189425">
1) the man recognized by the spy took off down the street
2) the van recognized by the spy took off down the street
</listItem>
<bodyText confidence="0.883886421052631">
The verb recognized is ambiguously either a past par-
ticipial form or a past tense form. Eye tracking showed
that subjects resolved the ambiguity rapidly (before
reading the by-phrase) in 2) but not in 1) . The con-
clusion they draw is that subjects use knowledge about
thematic roles to guide syntactic decisions. Since van,
which is inanimate, makes a good Theme but a poor
Agent for recognized, the past participial analysis in
2) is reinforced and the main clause (past tense) sup-
pressed. Being animate, man performs either thematic
role well, allowing the main clause reading to remain
*I thank Christy Doran, Jason Eisner, Jeff Reynar, and
John Trueswell for valuable comments. I am grateful to
Ewan Klein and the Centre for Cognitive Science, Edin-
burgh, where most of this work was conducted, and also ac-
knowledge the support of DARPA grant N00014-90-J-1863.
In fact, ambiguity effects were often completely elimi-
nated in examples like 2), with reading times matching those
for the unambiguous case:
</bodyText>
<page confidence="0.802704">
3) the man/van that was recognized by the spy ...
</page>
<bodyText confidence="0.996872885714286">
plausible until the disambiguating by-phrase is encoun-
tered. At this point, readers of 1) displayed confusion.
Semantic constraints do appear to be at work here.
However, the effects observed by Trueswell et al. are
graded. Verb-complement combinations occupy a con-
tinuous spectrum of &amp;quot;thematic fit&amp;quot;, which influences
reading times. This likely stems from the variance of
verbs with respect to the thematic roles they allow (e.g.,
Agent, Instrument, Patient, etc.) and the syntactic po-
sitions of these.
The upshot of such observations is that classical uni-
fication (see Shieber, 1986), which has served well as the
combinatory mechanism in classical constraint-based
parsers, is too brittle to withstand this onslaught of
uncertainty.
This paper presents an extension to classical unifi-
cation, called graded unification. Graded unification
combines two feature structures, and returns a strength
which reflects the compatibility of the information en-
coded by the two structures. Thus, two structures
which could not unify via classical unification may unify
via graded unification, and all combinatory decisions
made during processing are endowed with a level of
goodness. The operator is similar in spirit to the op-
erators of fuzzy logic (see Kapcprzyk, 1992), which at-
tempts to provide a calculus for reasoning in uncertain
domains. Another related approach is the &amp;quot;Unification
Space&amp;quot; model of Kempen &amp; Vosse (1989), which unifies
through a process of simulated annealing, and also uses
a notion of unification strength.
A parser has been implemented which combines con-
stituents via graded unification and whose decisions are
influenced by unification strengths. The result is a
paradigm of incremental processing, which maintains
a feature-based system of knowledge representation.
</bodyText>
<subsectionHeader confidence="0.905472">
System Description
</subsectionHeader>
<bodyText confidence="0.954215615384616">
Though the employment of graded unification engen-
ders a new processing style, the system&apos;s architecture
parallels that of a conventional unification-based parser.
Feature Structures: Prioritized Features
The feature structures which encode the grammar in
this system are conventional feature structures aug-
mented by the association of priorities with each
atomic-valued feature. Prioritizing features allows
them to vary in terms of influence over the strength of
unification. The priority of an atomic-valued feature fi
in a feature structure X will be denoted by Pri(fi, X).
The effect of feature prioritization is clarified in the fol-
lowing sections.
</bodyText>
<page confidence="0.996602">
313
</page>
<subsectionHeader confidence="0.908667">
Graded Unification
</subsectionHeader>
<bodyText confidence="0.998965333333333">
Given two feature structures, the graded unification
mechanism (UG) computes two results, a unifying struc-
ture and a unification strength.
Structural Unification Graded unification builds
structure exactly as classical unification except in the
case of atomic unification, where it deviates crucially.
Atoms in this framework are weighted disjunctive val-
ues. The weight associated with a disjunct is viewed as
the confidence with which the processor believes that
disjunct to be the &apos;correct&apos; value. Figures 1(a) and 1(b)
depict atoms (where 1(a) is &amp;quot;truly atomic&amp;quot; because it
contains only one disjunct).
</bodyText>
<figure confidence="0.936112333333333">
.1 v2
wl
(a) (b)
</figure>
<figureCaption confidence="0.999974">
Figure 1: Examples of Atoms
</figureCaption>
<bodyText confidence="0.999001466666667">
Atomic unification creates a mixture of its two ar-
gument atoms as follows. When two atoms are unified,
the set union of their disjuncts is collected in the result.
For each disjunct in the result, the associated weight be-
comes the average of the weights associated with that
disjunct in the two argument atoms. Figure 1(c) shows
an example unification of two atoms. The result is an
atom which is &apos;believed&apos; to be SG (singular), but could
possibly be PL (plural).
Unification Strength The unification strength (de-
noted UG Strength) is a weighted average of atomic uni-
fication strengths, defined in terms of two sums, the
actual compatibility and the perfect compatibility.
If A and B are non-atomic feature structures to be
unified, then the following holds:
</bodyText>
<equation confidence="0.9788205">
UGStrength(A, B) = pAecrtfueacItCcoommppaattizb. blityy((AA, i3)) .
The actual compatibility is the sum:
E Pri(fi, A) if fi occurs only in A
1 Pri(f,,A)+Pri(f.,B)
Pri(fi,B) if fi occurs only in B
2 *UGStrength(v(A,vis)
</equation>
<bodyText confidence="0.99068635">
if fi shared by A and B
where i indexes all atomic-valued features in A or B,
and VIA and viB are the values of fi in A and B respec-
tively. The perfect compatibility is computed by a
formula identical to this except that UGStrength is set
to 1.
If A and B are atomic, then UGStrength(A, B) is
the total weight of disjuncts shared by A and B:
UGStrength(A,B) = Ei min(wiA, wiB) where i in-
dexes all disjuncts di shared by A and B, and wiA and
wiB are the weights of di in A and B respectively.
By taking atomic unification strengths into account,
the actual compatibility provides a raw measure of the
extent to which two feature structures agree. By ig-
noring unification strengths (assuming a value of 1.o),
the perfect compatibility is an idealization of the actual
compatibility; it is what the actual compatibility would
be if the two structures were able to unify via classical
unification. Thus, unification strength is always a value
between o and 1.
</bodyText>
<note confidence="0.554142">
The Parser: Activated Chart Edges
</note>
<bodyText confidence="0.984681105263158">
The parser is a modified unification-based chart parser.
Chart edges are assigned activation levels, which repre-
sent the &apos;goodness&apos; of (or confidence in) their associated
analyses. Each new edge is activated according to the
strength of the unification which licenses its creation
and the activations of its constituent edges.
Constraining Graded Unification Without some
strict limit on its operation, graded unification will over-
generate wildly. Two mechanisms exist to constrain
graded unification. First, if a particular unification
completes with strength below a specified unification
threshold, it fails. Second, if a new edge is constructed
with activation below a specified activation threshold,
it is not allowed to enter the chart, and is suspended.
Parsing Strategy The chart is initialized to contain
one inactive edge for each lexical entry of each word
in the input. Lexical edges are currently assigned an
initial activation of 1.0.
The chart can then be expanded in two ways:
</bodyText>
<listItem confidence="0.9994562">
1. An active edge may be extended by unifying its first
unseen constituent with the LHS of an inactive edge.
2. A new active edge may be created by unifying the
LHS of a rule with the first unseen constituent of some
active edge in the chart (top down rule invocation).
</listItem>
<figure confidence="0.981604">
A B oc &gt;C)
D E
B C&apos;
</figure>
<figureCaption confidence="0.858077">
Figure 2: Extension of an Active Edge by an Inactive Edge
Figure 2 depicts the extension of the active EDGE1 with
the inactive EDGE2. The characters represent feature
</figureCaption>
<bodyText confidence="0.886341">
structures, and the ovular nodes on the right end of
each edge represent activation level. The parser tries
to unify C&apos;, the mother node of EDGE2, with C, the
first needed constituent of EDGE1. If this unification
succeeds, the parser builds the extended edge, EDGE3
(where C UG C&apos; produces C&amp;quot;). The activation of the
new edge is a function of the strength of the unification
and the current activations of EDGE1 and EDGE2:
</bodyText>
<equation confidence="0.813148">
activ3 = • UGSTRENGTH(C,C&apos;)
▪ w, • activi
+w3-activ2 (The weights w, sum to 1.)
</equation>
<bodyText confidence="0.995615333333333">
EDGE3 enters the chart only if its activation exceeds
the activation threshold. Rule invocation is depicted in
figure 3. The first needed constituent in EDGE1 is uni-
fied with the LHS of RULE1. EDGE2 is created to begin
searching for C. The new edge&apos;s activation is again a
function of unification strength and other activations:
</bodyText>
<equation confidence="0.834474333333333">
activ3 = wi • UGSTRENGTH(C,C&apos;)
± W2 • activi
W3 • activ2
</equation>
<figure confidence="0.982484384615384">
vi
1.0
SG PI.
.67 .33
UG
SG PI.
.83 .17
SG
1.0
(c)
EDGE!
EDGE2
EDGE3
</figure>
<page confidence="0.744607">
314
</page>
<figure confidence="0.746763">
EDGE!
RULEI
EDGE2
</figure>
<figureCaption confidence="0.999023">
Figure 3: Top Down Rule Invocation
</figureCaption>
<bodyText confidence="0.998301">
The activation levels of grammar rule edges, like those
for lexical edges, are currently pegged to 1.0.
</bodyText>
<sectionHeader confidence="0.494632" genericHeader="method">
A Framework for Interactive Processing
</sectionHeader>
<bodyText confidence="0.999917">
The system described above provides a flexible frame-
work for the interactive use of non-syntactic knowledge.
</bodyText>
<subsectionHeader confidence="0.562671">
Animacy and Thematic Roles
</subsectionHeader>
<bodyText confidence="0.999077916666666">
Knowledge about animacy and its important function
in the filling of thematic roles can be modelled as a
binary feature, ANIMATE. A (active voice) verb can
strongly &apos;want&apos; an animate Agent by specifying that its
subject be [ANIMATE +1 and assigning a high priority to
the feature ANIMATE. Thus, any parse combining this
verb with an inanimate subject will suffer in terms of
unification strength. A noun can be strongly animate
by having a high weight associated with the positive
value of ANIMATE. Animacy has been encoded in a toy
grammar. However, principled settings for the priority
of this feature are left to future work.
</bodyText>
<subsectionHeader confidence="0.876661">
Statistical Information from Corpora
</subsectionHeader>
<bodyText confidence="0.999954285714286">
Corpus-based part-of-speech (POS) statistics can also
be naturally incorporated into the current model. It
is proposed here that a Viterbi decoder could be used
to generate the likelihoods of the n best POS tags
for a given word in the input string. Lexical chart
edges would then be initially activated to levels pro-
portional to the predicted likelihoods of their associ-
ated tags. Since these activations will be propagated
to larger edges, parses involving predicted word senses
would consequently be given a head start in a race of ac-
tivations. Attractively, this strategy allows a fuller use
of statistical information than one which uses the in-
formation simply to deterministically choose the n best
tags, which are then treated as equally likely.
</bodyText>
<subsectionHeader confidence="0.868804">
Interaction of Diverse Information
</subsectionHeader>
<bodyText confidence="0.999979939393939">
A crucial feature of this framework is its potential for
modelling the interaction between sources of informa-
tion like the two above when they disagree. Sentences
1) and 2) again provide illustration. In such sentences,
knowledge about word sense frequency supports the
wrong analysis, and semantic constraints must be em-
ployed to achieve the correct (human) performance.
Intuitively, the raw frequency (without considering
context) of the past tense form of recognized is higher
than that of the past participial. POS taggers, despite
considering local context, consistently mis-tag the verb
in reduced relatives. The absence of a disambiguating
relativizer (e.g., that) is one obvious source of difficulty
here. But even the ostensibly disambiguating prepo-
sition by, is itself ambiguous, since it might introduce
a manner or locative phrase consistent with the main
clause analysis.
Modelling human performance in such contexts
requires allowing thematic information to compete
against and defeat word frequency information. The
current model allows such competition, as follows. POS
information may incorrectly predict the main clause
analysis, boosting the lexical edge associated with the
past tense, and thereby boosting the main clause parse.
However, the unification combining the past tense form
of recognized with an inanimate subject (van) will be
weak, due to the constraints encoded in the verb&apos;s lexi-
cal entry. Since the activations of constituent edges de-
pend on the strengths of the unifications used to build
them, the main clause parse will lose activation. The
parse combining the past participial with an inanimate
subject (Theme) will suffer no losses, allowing it to over-
take the incorrect parse.
</bodyText>
<sectionHeader confidence="0.714186" genericHeader="conclusions">
Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999986133333333">
Assigning feature priorities and activation thresholds
in this model will certainly be a considerable task. It
is hoped that principled and automated methods can
be found for assigning values to these variables. One
promising idea is to glean information about patterns
of subcategorization and thematic roles from annotated
corpora. Annotation of such information has been sug-
gested as a future direction for the Treebank project
(Marcus el al., 1993). It should be noted that learning
such information will require more training data (hence
larger corpora) than learning to tag part of speech.
In addition, psycholinguistic studies such as the large
norming study 3 of MacDonald and Pearlmutter (de-
scribed in Trueswell et al., 1994) may prove useful in
encoding thematic information in small lexicons.
</bodyText>
<sectionHeader confidence="0.999258" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.94535104">
Ford, M., J. Bresnan, &amp; R. Kaplan (1982). A Competence Based Theory
of Syntactic Closure. In Bresnan, J. (Ed.), The Mental Representation
of Grammatical Relations (pp. 727-796). MIT Press, Cambridge, MA.
Kempen, G. and T. Vosse (1989). Incremental Syntactic Tree Formation in
Human Sentence Processing: a Cognitive Architecture Based on Activa-
tion Decay and Simulated Annealing. Connection Science, 1(3), 273-290.
Kapcprzyk, J. (1992). Fuzzy Sets and Fuzzy Logic. In Shapiro, S. (Ed.) The
Encyclopedia of Artificial Intelligence. John Wiley Sz Sons., New York.
Marcus, M., B. Santorini, and M Markiewicz (1993). Building a Large An-
notated Corpus of English: The Penn Treebank. Computational Lin-
guistics, 19(2), 1993.
Shieber, S. (1986). An Introduction to Unification-Based Approaches to
Grammar. CSLI Lecture Notes, Chicago University Press, Chicago.
Stowe, L. (1989). Thematic Structures and Sentence Comprehension. In
Carlson, G. and M. Tanenhaus (Eds.) Linguistic Structure in Language
Processing Kluwer Academic Publishers.
Trueswell, J., M. Tannenhaus, S. Garnsey (1994). Semantic Influences on
Parsing: Use of Thematic Role Information in Syntactic Ambiguity Res-
olution. Journal of Memory and Language, 33, In Press.
Weischedel, R., R. Schwartz, J. Palmucci, M. Meteer, and L. Ramshaw
(1993). Coping with Ambiguity and Unknown Words through Proba-
bilistic Models. Computational Linguistics, 19(2), 359-382.
In fact, the utility of by is neutralized in the case of POS
tagging, since prepositions are uniformly tagged (e.g., using
the tag IN in the Penn Treebank; see Marcus at al., 1993).
</reference>
<footnote confidence="0.98320525">
3These studies attempt to establish thematic patterns
by asking large numbers of subjects to answer questions like
&amp;quot;How typical is it for a van to be recognized by someone?&amp;quot;
with a rating between 1 and 7.
</footnote>
<note confidence="0.921558">
LI
</note>
<page confidence="0.995054">
315
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.990686">
<title confidence="0.9977485">GRADED UNIFICATION: A FRAMEWORK FOR INTERACTIVE PROCESSING</title>
<author confidence="0.999955">Albert Kim</author>
<affiliation confidence="0.9997505">Department of Computer and Information Sciences University of Pennsylvania</affiliation>
<address confidence="0.99999">Philadelphia, Pennsylvania, USA</address>
<email confidence="0.999957">alkim@unagi.cis.upenn.edu</email>
<abstract confidence="0.9990514">extension to classical unification, called unificapresented. It is capable of combining contradictory information. An interactive processing paradigm and parser based on this new operator are also presented.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Ford</author>
<author>J Bresnan</author>
<author>R Kaplan</author>
</authors>
<title>A Competence Based Theory of Syntactic Closure.</title>
<date>1982</date>
<journal>In Bresnan, J. (Ed.), The Mental Representation of Grammatical Relations</journal>
<pages>727--796</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="989" citStr="Ford et al., 1982" startWordPosition="134" endWordPosition="137">ocessing paradigm and parser based on this new operator are also presented. Introduction Improved understanding of the nature of knowledge used in human language processing suggests the feasibility of interactive models in computational linguistics (CL). Recent psycholinguistic work such as (Stowe, 1989; Trueswell et al., 1994) has documented rapid employment of semantic information to guide human syntactic processing. In addition, corpus-based stochastic modelling of lexical patterns (see Weischedel ei al., 1993) may provide information about word sense frequency of the kind advocated since (Ford et al., 1982). Incremental employment of such knowledge to resolve syntactic ambiguity is a natural step towards improved cognitive accuracy and efficiency in CL models. This exercise will, however, pose difficulties for the classical (&apos;hard&apos;) constraint-based paradigm. As illustrated by the Trueswell et al. (1994) results, this view of constraints is too rigid to handle the kinds of effects at hand. These experiments used pairs of locally ambiguous reduced relative clauses such as: 1) the man recognized by the spy took off down the street 2) the van recognized by the spy took off down the street The verb </context>
</contexts>
<marker>Ford, Bresnan, Kaplan, 1982</marker>
<rawString>Ford, M., J. Bresnan, &amp; R. Kaplan (1982). A Competence Based Theory of Syntactic Closure. In Bresnan, J. (Ed.), The Mental Representation of Grammatical Relations (pp. 727-796). MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Kempen</author>
<author>T Vosse</author>
</authors>
<title>Incremental Syntactic Tree Formation in Human Sentence Processing: a Cognitive Architecture Based on Activation Decay and Simulated Annealing.</title>
<date>1989</date>
<journal>Connection Science,</journal>
<volume>1</volume>
<issue>3</issue>
<pages>273--290</pages>
<contexts>
<context position="4052" citStr="Kempen &amp; Vosse (1989)" startWordPosition="622" endWordPosition="625">lled graded unification. Graded unification combines two feature structures, and returns a strength which reflects the compatibility of the information encoded by the two structures. Thus, two structures which could not unify via classical unification may unify via graded unification, and all combinatory decisions made during processing are endowed with a level of goodness. The operator is similar in spirit to the operators of fuzzy logic (see Kapcprzyk, 1992), which attempts to provide a calculus for reasoning in uncertain domains. Another related approach is the &amp;quot;Unification Space&amp;quot; model of Kempen &amp; Vosse (1989), which unifies through a process of simulated annealing, and also uses a notion of unification strength. A parser has been implemented which combines constituents via graded unification and whose decisions are influenced by unification strengths. The result is a paradigm of incremental processing, which maintains a feature-based system of knowledge representation. System Description Though the employment of graded unification engenders a new processing style, the system&apos;s architecture parallels that of a conventional unification-based parser. Feature Structures: Prioritized Features The featu</context>
</contexts>
<marker>Kempen, Vosse, 1989</marker>
<rawString>Kempen, G. and T. Vosse (1989). Incremental Syntactic Tree Formation in Human Sentence Processing: a Cognitive Architecture Based on Activation Decay and Simulated Annealing. Connection Science, 1(3), 273-290.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kapcprzyk</author>
</authors>
<title>Fuzzy Sets and Fuzzy Logic. In</title>
<date>1992</date>
<publisher>John Wiley Sz Sons.,</publisher>
<location>New York.</location>
<contexts>
<context position="3895" citStr="Kapcprzyk, 1992" startWordPosition="599" endWordPosition="600">sical constraint-based parsers, is too brittle to withstand this onslaught of uncertainty. This paper presents an extension to classical unification, called graded unification. Graded unification combines two feature structures, and returns a strength which reflects the compatibility of the information encoded by the two structures. Thus, two structures which could not unify via classical unification may unify via graded unification, and all combinatory decisions made during processing are endowed with a level of goodness. The operator is similar in spirit to the operators of fuzzy logic (see Kapcprzyk, 1992), which attempts to provide a calculus for reasoning in uncertain domains. Another related approach is the &amp;quot;Unification Space&amp;quot; model of Kempen &amp; Vosse (1989), which unifies through a process of simulated annealing, and also uses a notion of unification strength. A parser has been implemented which combines constituents via graded unification and whose decisions are influenced by unification strengths. The result is a paradigm of incremental processing, which maintains a feature-based system of knowledge representation. System Description Though the employment of graded unification engenders a </context>
</contexts>
<marker>Kapcprzyk, 1992</marker>
<rawString>Kapcprzyk, J. (1992). Fuzzy Sets and Fuzzy Logic. In Shapiro, S. (Ed.) The Encyclopedia of Artificial Intelligence. John Wiley Sz Sons., New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>B Santorini</author>
<author>M Markiewicz</author>
</authors>
<title>Building a Large Annotated Corpus of English: The Penn Treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<marker>Marcus, Santorini, Markiewicz, 1993</marker>
<rawString>Marcus, M., B. Santorini, and M Markiewicz (1993). Building a Large Annotated Corpus of English: The Penn Treebank. Computational Linguistics, 19(2), 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Shieber</author>
</authors>
<title>An Introduction to Unification-Based Approaches to Grammar. CSLI Lecture Notes,</title>
<date>1986</date>
<publisher>Chicago University Press,</publisher>
<location>Chicago.</location>
<contexts>
<context position="3219" citStr="Shieber, 1986" startWordPosition="498" endWordPosition="499">was recognized by the spy ... plausible until the disambiguating by-phrase is encountered. At this point, readers of 1) displayed confusion. Semantic constraints do appear to be at work here. However, the effects observed by Trueswell et al. are graded. Verb-complement combinations occupy a continuous spectrum of &amp;quot;thematic fit&amp;quot;, which influences reading times. This likely stems from the variance of verbs with respect to the thematic roles they allow (e.g., Agent, Instrument, Patient, etc.) and the syntactic positions of these. The upshot of such observations is that classical unification (see Shieber, 1986), which has served well as the combinatory mechanism in classical constraint-based parsers, is too brittle to withstand this onslaught of uncertainty. This paper presents an extension to classical unification, called graded unification. Graded unification combines two feature structures, and returns a strength which reflects the compatibility of the information encoded by the two structures. Thus, two structures which could not unify via classical unification may unify via graded unification, and all combinatory decisions made during processing are endowed with a level of goodness. The operato</context>
</contexts>
<marker>Shieber, 1986</marker>
<rawString>Shieber, S. (1986). An Introduction to Unification-Based Approaches to Grammar. CSLI Lecture Notes, Chicago University Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Stowe</author>
</authors>
<title>Thematic Structures and Sentence Comprehension.</title>
<date>1989</date>
<booktitle>In Carlson, G. and M. Tanenhaus (Eds.) Linguistic Structure in Language Processing</booktitle>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="675" citStr="Stowe, 1989" startWordPosition="87" endWordPosition="88">t Kim * Department of Computer and Information Sciences University of Pennsylvania Philadelphia, Pennsylvania, USA email: alkim@unagi.cis.upenn.edu Abstract An extension to classical unification, called graded unification is presented. It is capable of combining contradictory information. An interactive processing paradigm and parser based on this new operator are also presented. Introduction Improved understanding of the nature of knowledge used in human language processing suggests the feasibility of interactive models in computational linguistics (CL). Recent psycholinguistic work such as (Stowe, 1989; Trueswell et al., 1994) has documented rapid employment of semantic information to guide human syntactic processing. In addition, corpus-based stochastic modelling of lexical patterns (see Weischedel ei al., 1993) may provide information about word sense frequency of the kind advocated since (Ford et al., 1982). Incremental employment of such knowledge to resolve syntactic ambiguity is a natural step towards improved cognitive accuracy and efficiency in CL models. This exercise will, however, pose difficulties for the classical (&apos;hard&apos;) constraint-based paradigm. As illustrated by the Truesw</context>
</contexts>
<marker>Stowe, 1989</marker>
<rawString>Stowe, L. (1989). Thematic Structures and Sentence Comprehension. In Carlson, G. and M. Tanenhaus (Eds.) Linguistic Structure in Language Processing Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Trueswell</author>
<author>M Tannenhaus</author>
<author>S Garnsey</author>
</authors>
<title>Semantic Influences on Parsing: Use of Thematic Role Information in Syntactic Ambiguity Resolution.</title>
<date>1994</date>
<journal>Journal of Memory and Language,</journal>
<volume>33</volume>
<publisher>In Press.</publisher>
<contexts>
<context position="700" citStr="Trueswell et al., 1994" startWordPosition="89" endWordPosition="92">tment of Computer and Information Sciences University of Pennsylvania Philadelphia, Pennsylvania, USA email: alkim@unagi.cis.upenn.edu Abstract An extension to classical unification, called graded unification is presented. It is capable of combining contradictory information. An interactive processing paradigm and parser based on this new operator are also presented. Introduction Improved understanding of the nature of knowledge used in human language processing suggests the feasibility of interactive models in computational linguistics (CL). Recent psycholinguistic work such as (Stowe, 1989; Trueswell et al., 1994) has documented rapid employment of semantic information to guide human syntactic processing. In addition, corpus-based stochastic modelling of lexical patterns (see Weischedel ei al., 1993) may provide information about word sense frequency of the kind advocated since (Ford et al., 1982). Incremental employment of such knowledge to resolve syntactic ambiguity is a natural step towards improved cognitive accuracy and efficiency in CL models. This exercise will, however, pose difficulties for the classical (&apos;hard&apos;) constraint-based paradigm. As illustrated by the Trueswell et al. (1994) results</context>
</contexts>
<marker>Trueswell, Tannenhaus, Garnsey, 1994</marker>
<rawString>Trueswell, J., M. Tannenhaus, S. Garnsey (1994). Semantic Influences on Parsing: Use of Thematic Role Information in Syntactic Ambiguity Resolution. Journal of Memory and Language, 33, In Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Weischedel</author>
<author>R Schwartz</author>
<author>J Palmucci</author>
<author>M Meteer</author>
<author>L Ramshaw</author>
</authors>
<title>Coping with Ambiguity and Unknown Words through Probabilistic Models.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<pages>359--382</pages>
<marker>Weischedel, Schwartz, Palmucci, Meteer, Ramshaw, 1993</marker>
<rawString>Weischedel, R., R. Schwartz, J. Palmucci, M. Meteer, and L. Ramshaw (1993). Coping with Ambiguity and Unknown Words through Probabilistic Models. Computational Linguistics, 19(2), 359-382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>In fact</author>
</authors>
<title>the utility of by is neutralized in the case of POS tagging, since prepositions are uniformly tagged (e.g., using the tag IN in the Penn Treebank; see Marcus at al.,</title>
<date>1993</date>
<marker>fact, 1993</marker>
<rawString>In fact, the utility of by is neutralized in the case of POS tagging, since prepositions are uniformly tagged (e.g., using the tag IN in the Penn Treebank; see Marcus at al., 1993).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>