<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.050815">
<title confidence="0.9927325">
Technical Support Dialog Systems:
Issues, Problems, and Solutions
</title>
<author confidence="0.9281445">
Kate Acomb, Jonathan Bloom, Krishna Dayanidhi, Phillip
Hunter, Peter Krogh, Esther Levin, Roberto Pieraccini
</author>
<affiliation confidence="0.852847">
SpeechCycle
</affiliation>
<address confidence="0.976639">
535 W 34th Street
New York, NY 10001
</address>
<email confidence="0.99168">
{kate,jonathanb,krishna,phillip,peter,roberto}@speechcycle.com
esther@spacegate.com
</email>
<sectionHeader confidence="0.995448" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999938142857143">
The goal of this paper is to give a description
of the state of the art, the issues, the problems,
and the solutions related to industrial dialog
systems for the automation of technical sup-
port. After a general description of the evolu-
tion of the spoken dialog industry, and the
challenges in the development of technical
support applications, we will discuss two spe-
cific problems through a series of experimental
results. The first problem is the identification
of the call reason, or symptom, from loosely
constrained user utterances. The second is the
use of data for the experimental optimization
of the Voice User Interface (VUI).
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999445">
Since the beginning of the telephony spoken dialog
industry, in the mid 1990, we have been witnessing
the evolution of at least three generations of sys-
tems. What differentiates each generation is not
only the increase of complexity, but also the dif-
ferent architectures used. Table 1 provides a sum-
mary of the features that distinguish each
generation. The early first generation systems were
mostly informational, in that they would require
some information from the user, and would pro-
vide information in return. Examples of those sys-
tems, mostly developed during the mid and late
1990s, are package tracking, simple financial ap-
plications, and flight status information. At the
</bodyText>
<page confidence="0.993291">
25
</page>
<bodyText confidence="0.99937035483871">
time there were no standards for developing dialog
systems, (VoiceXML 1.0 was published as a rec-
ommendation in year 2000) and thus the first gen-
eration dialog applications were implemented on
proprietary platforms, typically evolutions of exist-
ing touch-tone IVR (Interactive Voice Response)
architectures.
Since the early developments, spoken dialog sys-
tems were implemented as a graph, called call-
flow. The nodes of the call-flow typically represent
actions performed by the system and the arcs rep-
resent an enumeration of the possible outcomes.
Playing a prompt and interpreting the user re-
sponse through a speech recognition grammar is a
typical action. Dialog modules (Barnard et al.,
1999) were introduced in order to reduce the com-
plexity and increase reusability of call-flows. A
Dialog Module (or DM) is defined as a call-flow
object that encapsulates many of the interactions
needed for getting one piece of information from
the user, including retries, timeout handling, dis-
ambiguation, etc. Modern commercial dialog sys-
tems use DMs as their active call-flow nodes.
The number of DMs in a call-flow is generally an
indication of the application complexity. First gen-
eration applications showed a range of complexity
of a few to tens of DMs, typically spanning a few
turns of interaction.
The dialog modality is another characterization of
applications. Early applications supported strict
directed dialog interaction, meaning that at each
</bodyText>
<note confidence="0.733327">
Bridging the Gap: Academic and Industrial Research in Dialog Technologies Workshop Proceedings, pages 25–31,
NAACL-HLT, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
</note>
<table confidence="0.996997208333333">
GENERATION
FIRST SECOND THIRD
Time Period 1994-2001 2000-2005 2004-today
Type of Ap- Informational Transac- Problem
plication tional Solving
Examples Package Banking, Customer
Tracking, Stock Care,
Flight Status Trading, Technical
Train Res- Support,
ervation Help Desk.
Architecture Proprietary Static Dynamic
VoiceXML VoiceXML
Complexity 10 100 1000
(Number of
DMs)
Interaction few 10 10-100
Turns
Interaction directed directed + directed +
Modality natural natural
language language
(SSLU) (SSLU) +
limited
mixed initia-
tive
</table>
<tableCaption confidence="0.99989">
Table 1: Evolution of spoken dialog systems.
</tableCaption>
<bodyText confidence="0.999932423076923">
turn the system would direct the user by proposing
a finite—and typically small—number of choices.
That would also result in a limited grammar or vo-
cabulary at each turn.
The applications of the second generation were
typically transactional, in the sense that they could
perform a transaction on behalf of the user, like
moving funds between bank accounts, trading
stocks, or buying tickets. Most of those applica-
tions were developed using the new standards,
typically as collections of VoiceXML documents.
The complexity moved to the range of dozens of
dialog modules, spanning a number of turns of in-
teractions of the order of ten or more. At the same
time, some of the applications started using a tech-
nology known as Statistical Spoken Language Un-
derstanding, or SSLU (Gorin et al., 1997, Chu-
Carroll et al., 1999, Goel et al, 2005), for mapping
loosely constrained user utterances to a finite num-
ber of pre-defined semantic categories. The natural
language modality—as opposed to directed dia-
log—was initially used mostly for call-routing, i.e.
to route calls to the appropriate call center based
on a more or less lengthy description of the reason
for the call by the user.
While the model behind the first and second gen-
erations of dialog applications can be described by
the form-filling paradigm, and the interaction fol-
lows a pre-determined simple script, the systems of
the third generation have raised to a qualitatively
different level of complexity. Problem solving ap-
plications, like customer care, help desk, and tech-
nical support, are characterized by a level of
complexity ranging in the thousands of DMs, for a
number of turns of dynamic interaction that can
reach into the dozens. As the sophistication of the
applications evolved, so did the system architec-
ture by moving the logic from the client
(VoiceXML browser, or voice-browser) to the
server (Pieraccini and Huerta, 2005). More and
more system are today based on generic dialog
application server which interprets a dialog speci-
fication described by a—typically proprietary—
markup language and serve the voice-browser with
dynamically generated VoiceXML documents.
Finally, the interaction modality of the third gen-
eration systems is moving from the strictly directed
dialog application, to directed dialog, with some
natural language (SSLU) turns, and some limited
mixed-initiative (i.e. the possibility for the user to
change the course of the dialog by making an un-
solicited request).
</bodyText>
<sectionHeader confidence="0.985322" genericHeader="method">
2 Technical Support Applications
</sectionHeader>
<bodyText confidence="0.99996880952381">
Today, automated technical support systems are
among the most complex types of dialog applica-
tions. The advantage of automation is clear, espe-
cially for high-volume services like broadband-
internet, entertainment (cable or satellite TV), and
telephony. When something goes wrong with the
service, the only choice for subscribers is to call a
technical support center. Unfortunately, staffing a
call center with enough agents trained to help solve
even the most common problems results in pro-
hibitive costs for the provider, even when out-
sourcing to less costly locations End users often
experience long waiting times and poor service
from untrained agents. With the magnitude of the
daily increase in the number of subscribers of those
services, the situation with human agents is bound
to worsen. Automation and self-service can, and
does, help reduce the burden constituted by the
most frequent call reasons, and resort to human
agents only for the most difficult and less common
problems.
</bodyText>
<page confidence="0.972529">
26
</page>
<bodyText confidence="0.999000395833333">
However, automating technical support is particu-
larly challenging for several reasons. Among them:
- Troubleshooting knowledge is not readily
available in a form that can be used for
automation. Most often it is based on the
idiosyncratic experience of the individual
agents.
- End users are typically in a somewhat
emotionally altered state—something for
which they paid and that is supposed to
work is broken. They want it repaired
quickly by an expert human agent; they
don’t trust a machine can help them.
- The description of the problem provided
by the user can be imprecise, vague, or
based on a model of the world that may be
incorrect (e.g. some users of internet can-
not tell their modem from their router).
- It may be difficult to instruct non-
technically savvy users on how to perform
a troubleshooting step (e.g. Now renew
your IP address.) or request technical in-
formation (e.g. Are you using a Voice over
IP phone service?)
- Certain events cannot be controlled. For
instance, the time it would take for a user
to complete a troubleshooting step, like re-
booting a PC, is often unpredictable.
- The acoustic environment may be chal-
lenging. Users may be asked to switch
their TV on, reboot their PC, or check the
cable connections. All these operations can
cause noise that can trigger the speech rec-
ognizer and affect the course of the inter-
action.
On the other hand, one can leverage the automated
diagnosis or troubleshooting tools that are cur-
rently used by human agent and improve the effi-
ciency of the interaction. For instance, if the IP
address of the digital devices at the user premises
is available, one can ping them, verify their con-
nectivity, download new firmware, and perform
automated troubleshooting steps in the background
without the intervention of the user. However, the
interplay between automated and interactive op-
erations can raise the complexity of the applica-
tions such as to require higher level development
abstractions and authoring tools.
</bodyText>
<sectionHeader confidence="0.955949" genericHeader="method">
3 High Resolution SSLU
</sectionHeader>
<bodyText confidence="0.999934977777778">
The identification of the call reason—i.e. the prob-
lem or the symptoms of the problem experienced
by the caller—is one of the first phases of the in-
teraction in a technical support application. There
are two possible design choices with today’s spo-
ken language technology:
- Directed dialog. A specific prompt enu-
merates all the possible reasons for a call,
and the user would choose one of them.
- Natural Language: An open prompt asks
the user to describe the reason for the call.
The utterance will be automatically
mapped to one of a number of possible call
reasons using SSLU technology.
Directed dialog would be the preferred choice in
terms of accuracy and cost of development. Unfor-
tunately, in most technical support applications, the
number of call-reasons can be very large, and thus
prompting the caller through a directed dialog
menu would be impractical. Besides, even though
a long menu can be structured hierarchically as a
cascade of several shorter menus, the terms used
for indicating the different choices may be mis-
leading or meaningless for some of the users (e.g.
do you have a problem with hardware, software, or
networking?). Natural language with SSLU is
generally the best choice for problem identifica-
tion.
In practice, users mostly don’t know what the ac-
tual problem with their service is (e.g. modem is
wrongly configured), but typically they describe
their observations—or symptoms—which are ob-
servable manifestations of the problem. and not the
problem itself (e.g. symptom: I can’t connect to the
Web, problem: modem wrongly configured). Cor-
rectly identifying the symptom expressed in natural
language by users is the goal of the SSLU module.
SSLU provides a mapping between input utter-
ances and a set of pre-determined categories.
SSLU has been effectively used in the past to en-
able automatic call-routing. Typically call-routing
applications have a number of categories, of the
order of a dozen or so, which are designed based
on the different routes to which the IVR is sup-
posed to dispatch the callers. So, generally, in call-
</bodyText>
<page confidence="0.990402">
27
</page>
<bodyText confidence="0.981836982758621">
routing applications, the categories are known and
determined prior to any data collection.
One could follow the same approach for the prob-
lem identification SSLU, i.e. determine a number
of a-priori problem categories and then map a col-
lection of training symptom utterances to each one
of them. There are several issues with this ap-
proach.
First, a complete set of categories—the prob-
lems—may not be known prior to the acquisition
and analysis of a significant number of utterances.
Often the introduction of new home devices or ser-
vices (such as DVR, or HDTV) creates new prob-
lems and new symptoms that can be discovered
only by analyzing large amounts of utterance data.
Then, as we noted above, the relationship between
the problems—or broad categories of problems—
and the manifestations (i.e. the symptoms) may not
be obvious to the caller. Thus, confirming a broad
category in response to a detailed symptom utter-
ance may induce the user to deny it or to give a
verbose response (e.g. Caller: I cannot get to the
Web. System: I understand you have a problem
with your modem configuration, is that right?
Caller: Hmm...no. I said I cannot get to the Web.).
Finally, caller descriptions have different degrees
of specificity (e.g. I have a problem with my cable
service vs. The picture on my TV is pixilated on all
channels). Thus, the categories should reflect a
hierarchy of symptoms, from vague to specific,
that need to be taken into proper account in the
design of the interaction.
As a result from the above considerations, SSLU
for symptom identification needs to be designed in
order to reflect the high-resolution multitude and
specificity hierarchy of symptoms that emerge
from the analysis of a large quantity of utterances.
Figure 1 shows an excerpt from the hierarchy of
symptoms for a cable TV troubleshooting applica-
tion derived from the analysis of almost 100,000
utterance transcriptions.
Each node of the tree partially represented by Fig-
ure 1 is associated with a number of training utter-
ances from users describing that particular
symptom in their own words. For instance the top-
most node of the hierarchy, “TV Problem”, corre-
sponds to vague utterances such as I have a
problem with my TV or My cable TV does not
work. The” Ordering” node represents requests of
the type I have a problem with ordering a show,
which is still a somewhat vague request, since one
can order “Pay-per-view” or “On-demand” events,
and they correspond to different processes and
troubleshooting steps. Finally, at the most detailed
level of the hierarchy, for instance for the node
“TV Problem-Ordering-On Demand-Error”, one
finds utterances such as I tried to order a movie on
demand, but all I get is an error code on the TV.
</bodyText>
<figure confidence="0.996385777777778">
TV Problem
Ordering
On Demand
Error
PIN
Other
Pay-per-view
Error
No Picture
</figure>
<figureCaption confidence="0.885707666666667">
Figure 1: Excerpt from the hierarchical symp-
tom description in a cable TV technical support
application
</figureCaption>
<bodyText confidence="0.999956714285714">
In the experimental results reported below, we
trained and tested a hierarchically structured SSLU
for a cable TV troubleshooting application. A cor-
pus of 97,236 utterances was collected from a de-
ployed application which used a simpler, non
hierarchical, version of the SSLU. The utterances
were transcribed and initially annotated based on
an initial set of symptoms. The annotation was car-
ried out by creating an annotation guide document
which includes, for each symptom, a detailed ver-
bal description, a few utterance examples, and
relevant keywords. Human annotators were in-
structed to label each utterance with the correct
category based on the annotation guide and their
</bodyText>
<page confidence="0.996766">
28
</page>
<bodyText confidence="0.999477647058823">
work was monitored systematically by the system
designer.
After a first initial annotation of the whole corpus,
the annotation consistency was measured by com-
puting a cluster similarity distance between the
utterances corresponding to all possible pairs of
symptoms. When the consistency between a pair of
symptoms was below a given threshold, the clus-
ters were analyzed, and actions taken by the de-
signer in order to improve the consistency,
including reassign utterances and, if necessary,
modifying the annotation guide. The whole process
was repeated a few times until a satisfactory global
inter-cluster distance was attained.
Eventually we trained the SSLU on 79 symptoms
arranged on a hierarchy with a maximum depth of
3. Table 2 summarizes the results on an independ-
ent test set of 10,332 utterances. The result shows
that at the end of the process, a satisfactory batch
accuracy of 81.43% correct label assignment what
attained for the utterances which were deemed to
be in-domain, which constituted 90.22% of the test
corpus. Also, the system was able to correctly re-
ject 24.56% of out-of-domain utterances. The
overall accuracy of the system was considered rea-
sonable for the state of the art of commercial
SSLUs based on current statistical classification
algorithms. Improvement in the classification per-
formance can result by better language models (i.e.
some of the errors are due to incorrect word recog-
nition by the ASR) and better classifiers, which
need to take into account more features of the in-
coming utterances, such as word order1 and con-
textual information.
</bodyText>
<table confidence="0.997961666666667">
Utterances 10332 100.00%
In domain 9322 90.22%
Correct in-domain 7591 81.43%
Out of domain 1010 9.78%
Correct rejection out-of- 249 24.65%
domain
</table>
<tableCaption confidence="0.9810115">
Table 2: Accuracy results for Hierarchical
SSLU with 79 symptoms.
</tableCaption>
<footnote confidence="0.971961">
1 Current commercial SSLU modules, as the one used in the
work described here, use statistical classifiers based only on
bags of words. Thus the order of the words in the incoming
utterance is not taken into consideration.
</footnote>
<subsectionHeader confidence="0.999222">
3.1 Confirmation Effectiveness
</subsectionHeader>
<bodyText confidence="0.998986155555556">
Accuracy is not the only measure to provide an
assessment of how the symptom described by the
caller is effectively captured. Since the user re-
sponse needs to be confirmed based on the inter-
pretation returned by the SSLU, the caller always
has the choice of accepting or denying the hy-
pothesis. If the confirmation prompts are not prop-
erly designed, the user can erroneously deny
correctly detected symptoms, or erroneously accept
wrong ones.
The analysis reported below was carried out for a
deployed system for technical support of Internet
service. The full symptom identification interac-
tions following the initial open prompt was tran-
scribed and annotated for 895 calls. The SSLU
used in this application consisted of 36 symptoms
structured in a hierarchy with a maximum depth of
3. For each interaction we tracked the following
events:
- the first user response to the open question
- successive responses in case of re-
prompting because of speech recognition
rejection or timeout
- response to the yes/no confirmation ques-
tion)
- successive responses to the confirmation
question in case the recognizer rejected it
or timed out.
- Successive responses to the confirmation
question in case the user denied, and a
second best hypothesis was offered.
Table 3 summarizes the results of this analysis.
The first row reports the number of calls for which
the identified symptom was correct (as compared
with human annotation) and confirmed by the
caller. The following rows are the number of calls
where the identified symptom was wrong and the
caller still accepted it during confirmation, the
symptom was correct and the caller denied it, and
the symptom was wrong and denied, respectively.
Finally there were 57 calls where the caller did not
provide any confirmation (e.g. hung up, timed out,
ASR rejected the confirmation utterance even after
re-prompting, etc.), and 100 calls in which it was
not possible to collect the symptom (e.g. rejections
</bodyText>
<page confidence="0.995865">
29
</page>
<table confidence="0.999791142857143">
Accepted correct 535 59.8%
Accepted wrong 118 13.2%
Denied correct 22 2.5%
Denied wrong 63 7.0%
Unconfirmed 57 6.4%
No result 100 11.2%
TOTAL 895 100.0%
</table>
<tableCaption confidence="0.8826915">
Table 3: Result of the confirmation analy-
sis based on the results of 895 calls
</tableCaption>
<bodyText confidence="0.99982456">
of first and second re-prompts, timeouts, etc.) In
both cases—i.e. no confirmation or no symptom
collection at all—the call continued with a differ-
ent strategy (e.g. moved to a directed dialog, or
escalated the call to a human agent). The interest-
ing result from this experiment is that the SSLU
returned a correct symptom 59.8 + 2.5 = 62.3% of
the times (considering both in-domain and out-of-
domain utterances), but the actual “perceived” ac-
curacy (i.e. when the user accepted the result) was
higher, and precisely 59.8 + 13.2 = 73%. A deeper
analysis shows that for most of the wrongly ac-
cepted utterances the wrong symptom identified by
the SSLU was still in the same hierarchical cate-
gory, but with different degree of specificity (e.g.
Internet-Slow vs. vague Internet)
The difference between the actual and perceived
accuracy of SSLU has implications for the overall
performance of the application. One could build a
high performance SSLU, but a wrongly confirmed
symptom may put the dialog off course and result
in reduced automation, even though the perceived
accuracy is higher. Confirmation of SSLU results
is definitely an area where new research can poten-
tially impact the performance of the whole system.
</bodyText>
<sectionHeader confidence="0.999674" genericHeader="method">
4 Experimental VUI
</sectionHeader>
<bodyText confidence="0.999752375">
Voice User Interface (VUI) is typically considered
an art. VUI designers acquire their experience by
analyzing the effect of different prompts on the
behavior of users, and can often predict whether a
new prompt can help, confuse, or expedite the in-
teraction. Unfortunately, like all technologies rely-
ing on the anecdotal experience of the designer, in
VUI it is difficult to make fine adjustments to an
interface and predict the effect of competing simi-
lar designs before the application is actually de-
ployed. However, in large volume applications,
and when a global measure of performance is
available, one can test different non-disruptive de-
sign hypotheses on the field, while the application
is running. We call this process experimental VUI.
There have been, in the past, several studies aimed
at using machine learning for the design of dialog
systems (Levin et al., 2000, Young 2002, Pietquin
et al, 2006). Unfortunately, the problem of full de-
sign of a system based uniquely on machine learn-
ing is a very difficult one, and cannot be fully
utilized yet for commercial systems. A simpler and
less ambitious goal is that of finding the optimal
dialog strategy among a small number of compet-
ing designs, where all the initial designs are work-
ing reasonably well (Walker 2000, Paek et al 2004,
Lewis 2006). Comparing competing designs re-
quires carrying on an exploration based on random
selection of each design at crucial points of the
dialog. Once a reward schema is defined, one can
use it for changing the exploration probability so as
to maximize a function of the accumulated reward
using, for instance, one of the algorithms described
in (Sutton 1998).
Defining many different competing designs at sev-
eral points of the interaction is often impractical
and costly. Moreover, in a deployed commercial
application, one needs to be careful about main-
taining a reasonable user experience during explo-
ration. Thus, the competing designs have to be
chosen carefully and applied to portions of the dia-
log where the choice of the optimal design can
make a significant difference for the reward meas-
ure in use.
In the experiments described below we selected the
symptom identification as a point worth exploring.
in an internet technical support application We
then defined three prompting schemas
- Schema A: the system plays an open
prompt
- Schema B: the system plays an open
prompt, and then provides some examples
of requests
- Schema C: The system plays an open
prompt, and then suggests a command that
provides a list of choices.
</bodyText>
<page confidence="0.993773">
30
</page>
<bodyText confidence="0.99997772">
The three schemas were implemented on a de-
ployed system for limited time. There was 1/3
probability for each individual call to go through
one of the above schemas. The target function cho-
sen for optimization was the average automation
rate.
Figure 2 shows the effect on the cumulated average
automation rate for each one of the competing de-
sign. The exploration was carried out until the dif-
ference in the automation rate among the three
designs reached statistical significance, which was
after 13 days with a total number of 21,491 calls.
At that point in time we established that design B
had superior performance, as compared to A and
C, with a difference of 0.68 percent points.
Event though the gain in total automation rate (i.e.
0.68 percent points) seems to be modest, one has to
consider that this increase is simply caused only by
the selection of the best wording of a single
prompt in an application with thousands of
prompts. One can expect to obtain more important
improvements by at looking to other areas of the
dialog where experimental VUI can be applied and
selecting the optimal prompt can have an impact
on the overall automation rate.
</bodyText>
<figure confidence="0.410848">
Time (days)
</figure>
<figureCaption confidence="0.62816">
Figure 2: Daily average automation rate for com-
peting designs.
</figureCaption>
<sectionHeader confidence="0.999653" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9999949375">
We started this paper by describing the advances
achieved in dialog system technology for commer-
cial applications during the past decade. The indus-
try moved from the first generation of systems able
to handle very structured and simple interactions,
to a current third generation where the interaction
is less structured and the goal is to automate com-
plex tasks such as problem solving and technical
support.We then discussed general issues regarding
the effective development of a technical support
application. In particular we focused on two areas:
the collection of the symptom from natural lan-
guage expressions, and the experimental optimiza-
tion of the VUI strategy. In both cases we
described how a detailed analysis of live data can
greatly help optimize the overall performance.
</bodyText>
<sectionHeader confidence="0.999729" genericHeader="references">
6 References
</sectionHeader>
<reference confidence="0.999892756097561">
Barnard, E., Halberstadt, A., Kotelly, C., Phillips, M., 1999
“A Consistent Approach To Designing Spoken-dialog
Systems,” Proc. of ASRU99 – IEEE Workshop, Keystone,
Colorado, Dec. 1999.
Gorin, A. L., Riccardi, G.,Wright, J. H., 1997 Speech Com-
munication, vol. 23, pp. 113-127, 1997.
Chu-Carroll, J., Carpenter B., 1999. “Vector-based natural
language call routing,” Computational Linguistics,
v.25, n.3, p.361-388, September 1999
Goel, V., Kuo, H.-K., Deligne, S., Wu S., 2005 “Language
Model Estimation for Optimizing End-to-end Performance
of a Natural Language Call Routing System,” ICASSP
2005
Pieraccini, R., Huerta, J., Where do we go from here? Re-
search and Commercial Spoken Dialog Systems, Proc. of
6th SIGdial Workshop on Discourse and Dialog, Lisbon,
Portugal, 2-3 September, 2005. pp. 1-10
Levin, E., Pieraccini, R., Eckert, W., A Stochastic Model of
Human-Machine Interaction for Learning Dialog Strate-
gies, IEEE Trans. on Speech and Audio Processing, Vol.
8, No. 1, pp. 11-23, January 2000.
Pietquin, O., Dutoit, T., A Probabilistic Framework for Dialog
Simulation and Optimal Strategy Learning, In IEEE
Transactions on Audio, Speech and Language Processing,
14(2):589-599, 2006
Young, S., Talking to Machines (Statistically Speaking), Int
Conf Spoken Language Processing, Denver, Colorado.
(2002).
Walker, M., An Application of Reinforcement Learning to
Dialogue Strategy Selection in a Spoken Dialogue System
for Email . Journal of Artificial Intelligence Research,
JAIR, Vol 12., pp. 387-416, 2000
Paek T., Horvitz E.,. Optimizing automated call routing by
integrating spoken dialog models with queuing models.
Proceedings of HLT-NAACL, 2004, pp. 41-48.
Lewis, C., Di Fabbrizio, G., Prompt Selection with Rein-
forcement Learning in an AT&amp;T Call Routing Applica-
tion, Proc. of Interspeech 2006, Pittsburgh, PA. pp. 1770-
1773, (2006)
Sutton, R.S., Barto, A.G. (1998). Reinforcement Learning: An
Introduction. MIT Press.
</reference>
<figure confidence="0.998404416666667">
Automation rate 20.00%
19.00%
18.00%
17.00%
16.00%
15.00%
14.00%
21.00%
B
A
C
1 2 3 4 5 6 7 8 9 10 11 12 13
</figure>
<page confidence="0.999399">
31
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.730668">
<title confidence="0.9885265">Technical Support Dialog Issues, Problems, and Solutions</title>
<author confidence="0.981567">Kate Acomb</author>
<author confidence="0.981567">Jonathan Bloom</author>
<author confidence="0.981567">Krishna Dayanidhi</author>
<author confidence="0.981567">Peter Krogh Hunter</author>
<author confidence="0.981567">Esther Levin</author>
<author confidence="0.981567">Roberto</author>
<affiliation confidence="0.840433">W</affiliation>
<address confidence="0.949869">New York, NY</address>
<email confidence="0.999796">esther@spacegate.com</email>
<abstract confidence="0.994350533333333">The goal of this paper is to give a description of the state of the art, the issues, the problems, and the solutions related to industrial dialog systems for the automation of technical support. After a general description of the evolution of the spoken dialog industry, and the challenges in the development of technical support applications, we will discuss two specific problems through a series of experimental results. The first problem is the identification the call reason, or from loosely constrained user utterances. The second is the use of data for the experimental optimization of the Voice User Interface (VUI).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Barnard</author>
<author>A Halberstadt</author>
<author>C Kotelly</author>
<author>M Phillips</author>
</authors>
<title>A Consistent Approach To Designing Spoken-dialog Systems,”</title>
<date>1999</date>
<booktitle>Proc. of ASRU99 – IEEE Workshop,</booktitle>
<location>Keystone, Colorado,</location>
<contexts>
<context position="2349" citStr="Barnard et al., 1999" startWordPosition="354" endWordPosition="357">was published as a recommendation in year 2000) and thus the first generation dialog applications were implemented on proprietary platforms, typically evolutions of existing touch-tone IVR (Interactive Voice Response) architectures. Since the early developments, spoken dialog systems were implemented as a graph, called callflow. The nodes of the call-flow typically represent actions performed by the system and the arcs represent an enumeration of the possible outcomes. Playing a prompt and interpreting the user response through a speech recognition grammar is a typical action. Dialog modules (Barnard et al., 1999) were introduced in order to reduce the complexity and increase reusability of call-flows. A Dialog Module (or DM) is defined as a call-flow object that encapsulates many of the interactions needed for getting one piece of information from the user, including retries, timeout handling, disambiguation, etc. Modern commercial dialog systems use DMs as their active call-flow nodes. The number of DMs in a call-flow is generally an indication of the application complexity. First generation applications showed a range of complexity of a few to tens of DMs, typically spanning a few turns of interacti</context>
</contexts>
<marker>Barnard, Halberstadt, Kotelly, Phillips, 1999</marker>
<rawString>Barnard, E., Halberstadt, A., Kotelly, C., Phillips, M., 1999 “A Consistent Approach To Designing Spoken-dialog Systems,” Proc. of ASRU99 – IEEE Workshop, Keystone, Colorado, Dec. 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A L Gorin</author>
<author>G Riccardi</author>
<author>J H Wright</author>
</authors>
<date>1997</date>
<journal>Speech Communication,</journal>
<volume>23</volume>
<pages>113--127</pages>
<contexts>
<context position="4664" citStr="Gorin et al., 1997" startWordPosition="705" endWordPosition="708"> applications of the second generation were typically transactional, in the sense that they could perform a transaction on behalf of the user, like moving funds between bank accounts, trading stocks, or buying tickets. Most of those applications were developed using the new standards, typically as collections of VoiceXML documents. The complexity moved to the range of dozens of dialog modules, spanning a number of turns of interactions of the order of ten or more. At the same time, some of the applications started using a technology known as Statistical Spoken Language Understanding, or SSLU (Gorin et al., 1997, ChuCarroll et al., 1999, Goel et al, 2005), for mapping loosely constrained user utterances to a finite number of pre-defined semantic categories. The natural language modality—as opposed to directed dialog—was initially used mostly for call-routing, i.e. to route calls to the appropriate call center based on a more or less lengthy description of the reason for the call by the user. While the model behind the first and second generations of dialog applications can be described by the form-filling paradigm, and the interaction follows a pre-determined simple script, the systems of the third g</context>
</contexts>
<marker>Gorin, Riccardi, Wright, 1997</marker>
<rawString>Gorin, A. L., Riccardi, G.,Wright, J. H., 1997 Speech Communication, vol. 23, pp. 113-127, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Chu-Carroll</author>
<author>B Carpenter</author>
</authors>
<date>1999</date>
<booktitle>Vector-based natural language call routing,” Computational Linguistics, v.25, n.3,</booktitle>
<pages>361--388</pages>
<marker>Chu-Carroll, Carpenter, 1999</marker>
<rawString>Chu-Carroll, J., Carpenter B., 1999. “Vector-based natural language call routing,” Computational Linguistics, v.25, n.3, p.361-388, September 1999</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Goel</author>
<author>H-K Kuo</author>
<author>S Deligne</author>
<author>S Wu</author>
</authors>
<title>Language Model Estimation for Optimizing End-to-end Performance of a Natural Language Call Routing System,” ICASSP</title>
<date>2005</date>
<contexts>
<context position="4708" citStr="Goel et al, 2005" startWordPosition="714" endWordPosition="717">ypically transactional, in the sense that they could perform a transaction on behalf of the user, like moving funds between bank accounts, trading stocks, or buying tickets. Most of those applications were developed using the new standards, typically as collections of VoiceXML documents. The complexity moved to the range of dozens of dialog modules, spanning a number of turns of interactions of the order of ten or more. At the same time, some of the applications started using a technology known as Statistical Spoken Language Understanding, or SSLU (Gorin et al., 1997, ChuCarroll et al., 1999, Goel et al, 2005), for mapping loosely constrained user utterances to a finite number of pre-defined semantic categories. The natural language modality—as opposed to directed dialog—was initially used mostly for call-routing, i.e. to route calls to the appropriate call center based on a more or less lengthy description of the reason for the call by the user. While the model behind the first and second generations of dialog applications can be described by the form-filling paradigm, and the interaction follows a pre-determined simple script, the systems of the third generation have raised to a qualitatively dif</context>
</contexts>
<marker>Goel, Kuo, Deligne, Wu, 2005</marker>
<rawString>Goel, V., Kuo, H.-K., Deligne, S., Wu S., 2005 “Language Model Estimation for Optimizing End-to-end Performance of a Natural Language Call Routing System,” ICASSP 2005</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Pieraccini</author>
<author>J Huerta</author>
</authors>
<title>Where do we go from here? Research and Commercial Spoken Dialog Systems,</title>
<date>2005</date>
<booktitle>Proc. of 6th SIGdial Workshop on Discourse and Dialog,</booktitle>
<pages>1--10</pages>
<location>Lisbon,</location>
<contexts>
<context position="5771" citStr="Pieraccini and Huerta, 2005" startWordPosition="884" endWordPosition="887">ibed by the form-filling paradigm, and the interaction follows a pre-determined simple script, the systems of the third generation have raised to a qualitatively different level of complexity. Problem solving applications, like customer care, help desk, and technical support, are characterized by a level of complexity ranging in the thousands of DMs, for a number of turns of dynamic interaction that can reach into the dozens. As the sophistication of the applications evolved, so did the system architecture by moving the logic from the client (VoiceXML browser, or voice-browser) to the server (Pieraccini and Huerta, 2005). More and more system are today based on generic dialog application server which interprets a dialog specification described by a—typically proprietary— markup language and serve the voice-browser with dynamically generated VoiceXML documents. Finally, the interaction modality of the third generation systems is moving from the strictly directed dialog application, to directed dialog, with some natural language (SSLU) turns, and some limited mixed-initiative (i.e. the possibility for the user to change the course of the dialog by making an unsolicited request). 2 Technical Support Applications</context>
</contexts>
<marker>Pieraccini, Huerta, 2005</marker>
<rawString>Pieraccini, R., Huerta, J., Where do we go from here? Research and Commercial Spoken Dialog Systems, Proc. of 6th SIGdial Workshop on Discourse and Dialog, Lisbon, Portugal, 2-3 September, 2005. pp. 1-10</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Levin</author>
<author>R Pieraccini</author>
<author>W Eckert</author>
</authors>
<title>A Stochastic Model of Human-Machine Interaction for Learning Dialog Strategies,</title>
<date>2000</date>
<journal>IEEE Trans. on Speech and Audio Processing,</journal>
<volume>8</volume>
<pages>11--23</pages>
<contexts>
<context position="21382" citStr="Levin et al., 2000" startWordPosition="3435" endWordPosition="3438">Unfortunately, like all technologies relying on the anecdotal experience of the designer, in VUI it is difficult to make fine adjustments to an interface and predict the effect of competing similar designs before the application is actually deployed. However, in large volume applications, and when a global measure of performance is available, one can test different non-disruptive design hypotheses on the field, while the application is running. We call this process experimental VUI. There have been, in the past, several studies aimed at using machine learning for the design of dialog systems (Levin et al., 2000, Young 2002, Pietquin et al, 2006). Unfortunately, the problem of full design of a system based uniquely on machine learning is a very difficult one, and cannot be fully utilized yet for commercial systems. A simpler and less ambitious goal is that of finding the optimal dialog strategy among a small number of competing designs, where all the initial designs are working reasonably well (Walker 2000, Paek et al 2004, Lewis 2006). Comparing competing designs requires carrying on an exploration based on random selection of each design at crucial points of the dialog. Once a reward schema is defi</context>
</contexts>
<marker>Levin, Pieraccini, Eckert, 2000</marker>
<rawString>Levin, E., Pieraccini, R., Eckert, W., A Stochastic Model of Human-Machine Interaction for Learning Dialog Strategies, IEEE Trans. on Speech and Audio Processing, Vol. 8, No. 1, pp. 11-23, January 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Pietquin</author>
<author>T Dutoit</author>
</authors>
<title>A Probabilistic Framework for Dialog Simulation and Optimal Strategy Learning,</title>
<date>2006</date>
<booktitle>In IEEE Transactions on Audio, Speech and Language Processing,</booktitle>
<pages>14--2</pages>
<marker>Pietquin, Dutoit, 2006</marker>
<rawString>Pietquin, O., Dutoit, T., A Probabilistic Framework for Dialog Simulation and Optimal Strategy Learning, In IEEE Transactions on Audio, Speech and Language Processing, 14(2):589-599, 2006</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Young</author>
</authors>
<title>Talking to Machines (Statistically Speaking),</title>
<date>2002</date>
<booktitle>Int Conf Spoken Language Processing,</booktitle>
<location>Denver, Colorado.</location>
<contexts>
<context position="21394" citStr="Young 2002" startWordPosition="3439" endWordPosition="3440">all technologies relying on the anecdotal experience of the designer, in VUI it is difficult to make fine adjustments to an interface and predict the effect of competing similar designs before the application is actually deployed. However, in large volume applications, and when a global measure of performance is available, one can test different non-disruptive design hypotheses on the field, while the application is running. We call this process experimental VUI. There have been, in the past, several studies aimed at using machine learning for the design of dialog systems (Levin et al., 2000, Young 2002, Pietquin et al, 2006). Unfortunately, the problem of full design of a system based uniquely on machine learning is a very difficult one, and cannot be fully utilized yet for commercial systems. A simpler and less ambitious goal is that of finding the optimal dialog strategy among a small number of competing designs, where all the initial designs are working reasonably well (Walker 2000, Paek et al 2004, Lewis 2006). Comparing competing designs requires carrying on an exploration based on random selection of each design at crucial points of the dialog. Once a reward schema is defined, one can</context>
</contexts>
<marker>Young, 2002</marker>
<rawString>Young, S., Talking to Machines (Statistically Speaking), Int Conf Spoken Language Processing, Denver, Colorado. (2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Walker</author>
</authors>
<title>An Application of Reinforcement Learning to Dialogue Strategy Selection in a Spoken Dialogue System for Email .</title>
<date>2000</date>
<journal>Journal of Artificial Intelligence Research, JAIR,</journal>
<volume>12</volume>
<pages>387--416</pages>
<contexts>
<context position="21784" citStr="Walker 2000" startWordPosition="3507" endWordPosition="3508">ield, while the application is running. We call this process experimental VUI. There have been, in the past, several studies aimed at using machine learning for the design of dialog systems (Levin et al., 2000, Young 2002, Pietquin et al, 2006). Unfortunately, the problem of full design of a system based uniquely on machine learning is a very difficult one, and cannot be fully utilized yet for commercial systems. A simpler and less ambitious goal is that of finding the optimal dialog strategy among a small number of competing designs, where all the initial designs are working reasonably well (Walker 2000, Paek et al 2004, Lewis 2006). Comparing competing designs requires carrying on an exploration based on random selection of each design at crucial points of the dialog. Once a reward schema is defined, one can use it for changing the exploration probability so as to maximize a function of the accumulated reward using, for instance, one of the algorithms described in (Sutton 1998). Defining many different competing designs at several points of the interaction is often impractical and costly. Moreover, in a deployed commercial application, one needs to be careful about maintaining a reasonable </context>
</contexts>
<marker>Walker, 2000</marker>
<rawString>Walker, M., An Application of Reinforcement Learning to Dialogue Strategy Selection in a Spoken Dialogue System for Email . Journal of Artificial Intelligence Research, JAIR, Vol 12., pp. 387-416, 2000</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Paek</author>
<author>E Horvitz</author>
</authors>
<title>Optimizing automated call routing by integrating spoken dialog models with queuing models.</title>
<date>2004</date>
<booktitle>Proceedings of HLT-NAACL,</booktitle>
<pages>41--48</pages>
<marker>Paek, Horvitz, 2004</marker>
<rawString>Paek T., Horvitz E.,. Optimizing automated call routing by integrating spoken dialog models with queuing models. Proceedings of HLT-NAACL, 2004, pp. 41-48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Lewis</author>
<author>G Di Fabbrizio</author>
</authors>
<title>Prompt Selection with Reinforcement Learning</title>
<date>2006</date>
<booktitle>in an AT&amp;T Call Routing Application, Proc. of Interspeech 2006,</booktitle>
<pages>1770--1773</pages>
<location>Pittsburgh, PA.</location>
<marker>Lewis, Di Fabbrizio, 2006</marker>
<rawString>Lewis, C., Di Fabbrizio, G., Prompt Selection with Reinforcement Learning in an AT&amp;T Call Routing Application, Proc. of Interspeech 2006, Pittsburgh, PA. pp. 1770-1773, (2006)</rawString>
</citation>
<citation valid="true">
<authors>
<author>R S Sutton</author>
<author>A G Barto</author>
</authors>
<title>Reinforcement Learning: An Introduction.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<marker>Sutton, Barto, 1998</marker>
<rawString>Sutton, R.S., Barto, A.G. (1998). Reinforcement Learning: An Introduction. MIT Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>