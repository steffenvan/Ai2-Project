<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.041265">
<title confidence="0.886559">
MATREX: The DCU MT System for WMT 2009
</title>
<author confidence="0.997552">
Jinhua Du, Yifan He, Sergio Penkale, Andy Way
</author>
<affiliation confidence="0.9867165">
Centre for Next Generation Localisation
Dublin City University
</affiliation>
<address confidence="0.843993">
Dublin 9, Ireland
</address>
<email confidence="0.997816">
{jdu,yhe,spenkale,away}@computing.dcu.ie
</email>
<sectionHeader confidence="0.993862" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999082166666667">
In this paper, we describe the machine
translation system in the evaluation cam-
paign of the Fourth Workshop on Statisti-
cal Machine Translation at EACL 2009.
We describe the modular design of our
multi-engine MT system with particular
focus on the components used in this par-
ticipation.
We participated in the translation task
for the following translation directions:
French–English and English–French, in
which we employed our multi-engine ar-
chitecture to translate. We also partic-
ipated in the system combination task
which was carried out by the MBR de-
coder and Confusion Network decoder.
We report results on the provided devel-
opment and test sets.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999612838709677">
In this paper, we present a multi-engine MT
system developed at DCU, MATREX (Machine
Translation using Examples). This system exploits
EBMT, SMT and system combination techniques
to build a cascaded translation framework.
We participated in both the French–English and
English-French News tasks. In these two tasks,
we employ three individual MT system which are
1) Baseline: phrase-based system (PB); 2) EBMT:
Monolingually chunking both source and target
sides of the dataset using a marker-based chun-
ker (Gough and Way, 2004). 3) HPB: a typical
hierarchical phrase-based system (Chiang, 2005).
Meanwhile, we also use a word-level combina-
tion framework (Rosti et al., 2007) to combine the
multiple translation hypotheses and employ a new
rescoring model to generate the final result.
For the system combination task, we first use
the minimum Bayes-risk (MBR) (Kumar and
Byrne, 2004) decoder to select the best hypothe-
sis as the alignment reference for the Confusion
Network (CN) (Mangu et al., 2000). We then build
the CN using the TER metric (Snover et al., 2006),
and finally search and generate the translation.
The remainder of this paper is organised as fol-
lows: Section 2 details the various components of
our system, in particular the multi-engine strate-
gies used for the shared task. In Section 3, we
outline the complete system setup for the shared
task and provide results on the development and
test sets. Section 4 is our conclusion.
</bodyText>
<sectionHeader confidence="0.956356" genericHeader="method">
2 The MATREX System
</sectionHeader>
<subsectionHeader confidence="0.995276">
2.1 System Architecture
</subsectionHeader>
<bodyText confidence="0.999928307692308">
The MATREX system is a combination-based
multi-engine architecture, which exploits aspects
of both the EBMT and SMT paradigms.
This architecture includes three individual sys-
tems which are phrase-based, example-based and
hierarchical phrase-based.
The combination structure is the MBR decoder
and CN decoder, which is based on the word-level
combination strategy.
In the final stage, we use a new rescoring mod-
ule to process the N-best list generated by the
combination module. See Figure 1 as a detailed
illustration.
</bodyText>
<subsectionHeader confidence="0.999165">
2.2 Example-Based Machine Translation
</subsectionHeader>
<bodyText confidence="0.88816475">
EBMT obtains resources using the Marker Hy-
pothesis (Green, 1979), a psycholinguistic con-
straint which posits that all languages are marked
for surface syntax by a specific closed set of lex-
emes or morphemes which signify context. Given
a set of closed-class words we segment each sen-
tence into chunks, creating a chunk at each new
occurrence of a marker word, with the restriction
that each segment must contain at least one non-
marker word (Gough and Way, 2004).
Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 95–99,
Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics
</bodyText>
<page confidence="0.998694">
95
</page>
<figureCaption confidence="0.999915">
Figure 1: System Framework
</figureCaption>
<bodyText confidence="0.9995225">
We then align these segments using an edit-
distance-style algorithm, in which the insertion
and deletion probabilities depend on word-to-
word translation probabilities and word-to-word
cognates (Stroppa and Way, 2006).
We extracted phrases of at most 7 words on
each side. We then merged these phrases with the
phrases extracted by the baseline system adding
word alignment information, and used this system
seeded with this additional information.
</bodyText>
<subsectionHeader confidence="0.998461">
2.3 Hierarchical Machine Translation
</subsectionHeader>
<bodyText confidence="0.999408">
HPB translation system is a re-implementation of
the hierarchical phrase translation model which is
based on PSCFG (Chiang, 2005). We generate re-
cursively PSCFG rules from the initial rules as
</bodyText>
<equation confidence="0.997288">
N —* f1 ... fm/e1 ... en
</equation>
<bodyText confidence="0.598599">
where N is a rule which is initial or includes non-
terminals.
</bodyText>
<equation confidence="0.996232">
M —* fi ... fj/eu ... ev
</equation>
<bodyText confidence="0.9996395">
where 1 &lt; i &lt; j &lt; m and 1 &lt; u &lt; v &lt; n, at
which point a new rule can be obtained, named,
</bodyText>
<equation confidence="0.992607333333333">
N —* fi−1
1 Xkfm j+1/eu−1
1 Xken v+1
</equation>
<bodyText confidence="0.999943875">
where k is an index for the nonterminal X. The
number of nonterminals permitted in a rule is no
more than two.
When extracting hierarchical rules,we set some
limitations that initial rules are of no more than
7 words in length and other rules should have
no more than 5 terminals and nonterminals, and
we disallow rules with adjacent source-side and
target-side nonterminals.
The decoder is an enhanced CYK-style chart
parser that maximizes the derivation probability
and spans up to 12 source words. A 4-gram lan-
guage model generated by SRI Language Model-
ing toolkit (SRILM) (Stolcke, 2002) is used in the
cube-pruning process. The search space is pruned
with a chart cell size limit of 50.
</bodyText>
<subsectionHeader confidence="0.996389">
2.4 System Combination
</subsectionHeader>
<bodyText confidence="0.9999499375">
For multiple system combination, we implement
an MBR-CN framework as shown in Figure 1. In-
stead of using a single system output as the skele-
ton, we employ a minimum Bayes-risk decoder
to select the best single system output from the
merged N-best list by minimizing the BLEU (Pa-
pineni et al., 2002) loss.
The confusion network is built by the output of
MBR as the backbone which determines the word
order of the combination. The other hypotheses
are aligned against the backbone based on the TER
metric. NULL words are allowed in the alignment.
Each arc in the CN represents an alternative word
at that position in the sentence and the number of
votes for each word is counted when constructing
the network. The features we used are as follows:
</bodyText>
<listItem confidence="0.9992905">
• word posterior probability (Fiscus, 1997);
• 3, 4-gram target language model;
• word length penalty;
• Null word length penalty;
</listItem>
<bodyText confidence="0.985327">
Also, we use MERT (Och, 2003) to tune the
weights of confusion network.
</bodyText>
<subsectionHeader confidence="0.944806">
2.5 Rescore
</subsectionHeader>
<bodyText confidence="0.998657">
Rescore is a very important part in post-processing
which can select a better hypothesis from the N-
best list. We add some new global features in
rescore model. The features we used are as fol-
lows:
</bodyText>
<listItem confidence="0.97797725">
• Direct and inverse IBM model;
• 3, 4-gram target language model;
• 3, 4, 5-gram POS language model (Ratna-
parkhi, 1996; Schmid, 1994);
</listItem>
<figure confidence="0.999752315789474">
Recaser Recaser
Decoding
Mutiple 1-best
MBR Decoder
Rescore/MERT
HPB
CN/MERT
Rescore/MERT
Dev/MERT
Baseline
System
Combination
EBMT
Mutiple 1-best
MBR Decoder
CN Decoder
Rescore
Rescore
TestSet
</figure>
<page confidence="0.953966">
96
</page>
<listItem confidence="0.997318571428571">
• Sentence length posterior probability (Zens
and Ney, 2006);
• N-gram posterior probabilities within the N-
Best list (Zens and Ney, 2006);
• Minimum Bayes Risk probability;
• Length ratio between source and target sen-
tence;
</listItem>
<bodyText confidence="0.991964">
The weights are optimized via MERT algorithm.
</bodyText>
<sectionHeader confidence="0.999462" genericHeader="method">
3 Experimental Setup
</sectionHeader>
<bodyText confidence="0.9994">
The following section describes the system and
experimental setup for the French-English and
English-French translation tasks.
</bodyText>
<subsectionHeader confidence="0.962489">
3.1 Statistics of Data
Parallel Corpus
</subsectionHeader>
<bodyText confidence="0.9085725">
We used Europarl and Giga data for this evalua-
tion. The statistics of parallel data are shown in
</bodyText>
<tableCaption confidence="0.976634">
Table 1.
</tableCaption>
<table confidence="0.999908666666667">
Corpra Sen Token-En Token-Fr Len
Europarl 1.46M 39,240,672 42,252,067 80
Giga 2M 48,648,104 57,869,002 65
</table>
<tableCaption confidence="0.999847">
Table 1: Statistics of Parallel Data
</tableCaption>
<bodyText confidence="0.999959714285714">
In this table, Sen indicates the number of sentence
pairs; Len denotes the maximum sentence length
of each corpus. This year the translation task is
only evaluated on News Domain. Experimental re-
sults showed that giga data is more correlated than
Europarl and the BLEU score is significantly im-
proved(See Table 4).
</bodyText>
<subsectionHeader confidence="0.959667">
Monolingual Corpus
</subsectionHeader>
<bodyText confidence="0.9977222">
In this evaluation, we trained a small 4-gram lan-
guage model using data in Table 1 and a large 4-
gram language model using data in Table 2. We
configured these two LMs for Baseline and EBMT
systems while HPB only used the large one.
</bodyText>
<table confidence="0.998929">
Language Sen Token Source
English 9,966,838 240,849,221 E/N/NC
French 9,966,838 260,520,313 E/N/NC
</table>
<tableCaption confidence="0.99891">
Table 2: Statistics of Monolingual Data
</tableCaption>
<subsectionHeader confidence="0.999369">
3.2 Pre-Processing
</subsectionHeader>
<bodyText confidence="0.999630571428571">
We preprocessed both Europarl and Giga Release
1 corpus. For the Europarl corpus, we removed
the reserved characters in GIZA++ and tokenized
and lowercased the corpus with tools provided by
WMT09. The Giga corpus was too large for our
resource, so we performed sentence selection be-
fore cleaning, in the following steps.
</bodyText>
<listItem confidence="0.989668423076923">
• We split the Giga corpus into even segments,
each segment consisting of 20 lines.
• We trained an SVM classifier on English side
with positive examples from the monolin-
gual news data and negative examples from
noisy sentences (numbers, meaningless word
combinations, and random segments) from
the Giga corpus. We used ”-ly” and ”-ing”
to approximate adverbs and present partici-
ples and did not use other POS-induced fea-
tures, as in (Ferizis and Bailey, 2006). We
added these features to remove noise: aver-
age length of sentences, frequency of capital-
ized characters, frequency of numerical char-
acters and short word penalty (equals to 1
when average length of words &lt; 4, and 0
otherwise). We used the classifier to remove
20% segments of lowest scores.
• We selected 1, 600 words having the highest
mutual information scores with monolingual
training data against the Giga corpus.
• We selected 100, 000 segments where these
words occurred most frequently. However
the sentence was dropped if the length ratio
between English and French was larger than
1.5 or less than 0.67.
</listItem>
<subsectionHeader confidence="0.99602">
3.3 System Configuration
</subsectionHeader>
<bodyText confidence="0.999883">
The two language models were done using the
SRILM employing linear interpolation and modi-
fied K-N discounting (Chen and Goodman, 1996).
The configuration for the three systems is listed
in Table 3.
</bodyText>
<table confidence="0.9988918">
System P-Table Length LM Features
Baseline-E 55.9M 7 2 15
Baseline-G 58.4M 7 2 15
EBMT 59.4M 7 2 15
HPB 122M 5 1 8
</table>
<tableCaption confidence="0.999888">
Table 3: Statistics of MT Systems
</tableCaption>
<bodyText confidence="0.918905333333333">
In the above table, E/N/NC refers to Eu-
roparl/News/New Commentary corpus.
In this table, E indicates the Europarl corpus
</bodyText>
<page confidence="0.999106">
97
</page>
<bodyText confidence="0.9999718">
which is used for all three systems, and G stands
for the Giga corpus which is only used for the
Baseline system. We can see from Table 3 that
the size of the HPB phrase-table is more than 2
times as large as the other phrase tables. How to
filter and process such a huge hierarchical table is
a challenging problem.
We tuned our systems on the development set
devset2009-a and devset2009-b, and performed
the crossover experiment by these two devsets.
</bodyText>
<subsectionHeader confidence="0.99009">
3.4 Experimental Results
</subsectionHeader>
<bodyText confidence="0.998814444444445">
The system output is evaluated with respect to
BLEU score. In Table 4, we used devset2009-b
to tune the various parameters in our three single
systems and devset2009-a for testing. In terms of
the Europarl data, we can see that the three sys-
tems we used achieved similar performance on the
test set for both translation directions, with the
Baseline-E system yielding slightly better results
than the other two.
</bodyText>
<table confidence="0.997771555555556">
System Fr-En En-Fr
Baseline-E 22.24 22.68
Baseline-G 24.90 1
—
EBMT 22.04 22.12
HPB 21.69 21.12
MBR 25.11 22.68
CN 25.24 22.76
Rescore 25.40 22.97
</table>
<tableCaption confidence="0.999682">
Table 4: Experimental Results on Devset2009-a
</tableCaption>
<bodyText confidence="0.996413428571429">
We then used the translations of the devset2009-
a produced by each system to tune the parame-
ters of our system combination module. From Ta-
ble 4, we can see that using MBR and confusion
network decoding leads to a slight improvement
over the strongest single system, i.e. the baseline
Phrase-Based SMT system. Rescoring the N-best
lists yielded an increase of 0.5 (2.0 relative) ab-
solute BLEU points over the baseline for French–
English Translation and 0.29 (1.28 relative) abso-
lute BLEU points for English–French Translation.
Table 5 is the results on 2009 Test Data. The
scores with a slash in the last two rows are low-
ercased and cased respectively. From the table we
</bodyText>
<footnote confidence="0.9865715">
1Not much time to do the experiments on English-French
direction. EBMT and HPB just used the Europarl corpus.
2The official automatic result is scored on 2525 sentences
out of the whole 3007 sentences in test set. The other 502
sentences are used as the development set for combination
evaluation task.
</footnote>
<table confidence="0.994941714285714">
System Fr-En En-Fr
Baseline-E 25.64 24.47
Baseline-G 26.75 —
EBMT 25.67 24.43
HPB 25.20 24.19
Combination 27.20/25.14 25.26/22.28
Official-Auto2 26.86/24.93 23.78/22.14
</table>
<tableCaption confidence="0.999631">
Table 5: Summary of Results on 2009 Test Data
</tableCaption>
<bodyText confidence="0.999531875">
can see that combination yielded 0.45 and 0.79 ab-
solute BLEU points over the best single system for
Fr-En and En-Fr direction respectively. However,
1.93 (7.2 relative) and 1.64 (6.58 relative) BLEU
points are dropped between cased and lowercased
results of both directions. Accordingly, training an
effective recasing model is very important for our
future work.
</bodyText>
<sectionHeader confidence="0.999585" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.99989105">
This paper presents our machine translation sys-
tem in WMT2009 shared task campaign. We de-
veloped a multi-engine framework which com-
bined the output results of the three MT sys-
tems and generated a new N-best list after CN
decoding. Then by using some global features
the rescoring model generated the final translation
output. The experimental result proved that the
combination module and rescoring module are ef-
fective in our framework.
We also applied simple yet effective methods
of genre and topical classification to remove noise
and out-of-domain sentences in the Giga corpus,
from which we built better translation models than
from Europarl.
In future work, we will refine our system frame-
work to investigate its effect on the tasks pre-
sented here, and we will develop more powerful
post-processing tools such as recaser to reduce the
BLEU loss.
</bodyText>
<sectionHeader confidence="0.9975" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.986928666666667">
This work is supported by Science Foundation Ireland (Grant
No. 07/CE/I1142). Thanks also to the reviewers for their
insightful comments and suggestions.
</bodyText>
<sectionHeader confidence="0.998768" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.993710857142857">
Chen, S. F. and Goodman, J. (1996). An Empirical Study of
Smoothing Techniques for Language Modeling. In Pro-
ceedings of the Thirty-Fourth Annual Meeting of the As-
sociation for Computational Linguistics, pages 310–318,
San Francisco, CA.
Chiang, D. (2005). A Hierarchical Phrase-Based Model for
Statistical Machine Translation. In Proceedings of the
</reference>
<page confidence="0.98812">
98
</page>
<reference confidence="0.99868998630137">
43rd Annual Meeting of the Association for Computa-
tional Linguistics (ACL’05), pages 263–270, Ann Arbor,
MI.
Ferizis, G. and Bailey, P. (2006). Towards practical genre
classification of web documents. In Proceedings of the
15th international conference on World Wide Web (WWW
’06), pages 1013–1014, New York, USA.
Fiscus, J. G. (1997). A post-processing system to yield re-
duced word error rates: Recognizer output voting error
reduction (ROVER). In Proceedings 1997 IEEE Work-
shop on Automatic Speech Recognition and Understand-
ing (ASRU), pages 347–352, Santa Barbara, CA.
Gough, N. and Way, A. (2004). Robust Large-Scale EBMT
with Marker-Based Segmentation. In Proceedings of
the 10th International Conference on Theoretical and
Methodological Issues in Machine Translation (TMI-04),
pages 95–104, Baltimore, MD.
Green, T. (1979). The Necessity of Syntax Markers. Two
experiments with artificial languages. Journal of Verbal
Learning and Behavior, 18:481–496.
Kumar, S. and Byrne, W. (2004). Minimum Bayes-Risk De-
coding for Statistical Machine Translation. In Proceed-
ings of the Joint Meeting of the Human Language Tech-
nology Conference and the North American Chapter of the
Association for Computational Linguistics (HLT-NAACL
2004), pages 169–176, Boston, MA.
Mangu, L., Brill, E., and Stolcke, A. (2000). Finding con-
sensus in speech recognition: Word error minimization
and other applications of confusion networks. Computer
Speech and Language, 14(4):373–400.
Och, F. (2003). Minimum error rate training in statistical
machine translation. In Proceedings of the 41st Annual
Meeting of the Association for Computational Linguistics
(ACL), pages 160–167, Sapporo, Japan.
Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J. (2002).
BLEU: a Method for Automatic Evaluation of Machine
Translation. In Proceedings of the 40th Annual Meeting of
the Association for Computational Linguistics (ACL-02),
pages 311–318, Philadelphia, PA.
Ratnaparkhi, A. (1996). A Maximum Entropy Model for
Part-Of-Speech Tagging. In Proceedings of the Empiri-
cal Methods in Natural Language Processing Conference
(EMNLP), pages 133–142, Philadelphia, PA.
Rosti, A.-V. I., Xiang, B., Matsoukas, S., Schwartz, R., Ayan,
N. F., and Dorr, B. J. (2007). Combining outputs from
multiple machine translation systems. In Proceedings
of the Joint Meeting of the Human Language Technol-
ogy Conference and the North American Chapter of the
Association for Computational Linguistics (HLT-NAACL
2007), pages 228–235, Rochester, NY.
Schmid, H. (1994). Probabilistic Part-of-Speech Tagging Us-
ing Decision Trees. In Proceedings of International Con-
ference on New Methods in Language Processing, pages
44–49, Manchester, UK.
Snover, M., Dorr, B., Schwartz, R., Micciula, L., and
Makhoul, J. (2006). A study of translation edit rate with
targeted human annotation. In Proceedings of the 7th Con-
ference of the Association for Machine Translation in the
Americas (AMTA 2006), pages 223–231, Cambridge, MA.
Stolcke, A. (2002). SRILM - An Extensible Language Mod-
eling Toolkit. In Proceedings of the International Confer-
ence Spoken Language Processing, pages 901–904, Den-
ver, CO.
Stroppa, N. and Way, A. (2006). MaTrEx: the DCU machine
translation system for IWSLT 2006. In Proceedings of the
International Workshop on Spoken Language Translation,
pages 31–36, Kyoto, Japan.
Zens, R. and Ney, H. (2006). N-gram Posterior Probabilities
for Statistical Machine Translation. In Proceedings of the
Joint Meeting of the Human Language Technology Con-
ference and the North American Chapter of the Associ-
ation for Computational Linguistics (HLT-NAACL 2006),
pages 72–77, New York, USA.
</reference>
<page confidence="0.998954">
99
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.429162">
<title confidence="0.699653">The DCU MT System for WMT 2009</title>
<author confidence="0.993219">Jinhua Du</author>
<author confidence="0.993219">Yifan He</author>
<author confidence="0.993219">Sergio Penkale</author>
<author confidence="0.993219">Andy Way</author>
<affiliation confidence="0.9784385">Centre for Next Generation Dublin City</affiliation>
<address confidence="0.647974">Dublin 9,</address>
<abstract confidence="0.99771947368421">In this paper, we describe the machine translation system in the evaluation campaign of the Fourth Workshop on Statistical Machine Translation at EACL 2009. We describe the modular design of our multi-engine MT system with particular focus on the components used in this participation. We participated in the translation task for the following translation directions: French–English and English–French, in which we employed our multi-engine architecture to translate. We also participated in the system combination task which was carried out by the MBR decoder and Confusion Network decoder. We report results on the provided development and test sets.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S F Chen</author>
<author>J Goodman</author>
</authors>
<title>An Empirical Study of Smoothing Techniques for Language Modeling.</title>
<date>1996</date>
<booktitle>In Proceedings of the Thirty-Fourth Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>310--318</pages>
<location>San Francisco, CA.</location>
<contexts>
<context position="9711" citStr="Chen and Goodman, 1996" startWordPosition="1579" endWordPosition="1582">ord penalty (equals to 1 when average length of words &lt; 4, and 0 otherwise). We used the classifier to remove 20% segments of lowest scores. • We selected 1, 600 words having the highest mutual information scores with monolingual training data against the Giga corpus. • We selected 100, 000 segments where these words occurred most frequently. However the sentence was dropped if the length ratio between English and French was larger than 1.5 or less than 0.67. 3.3 System Configuration The two language models were done using the SRILM employing linear interpolation and modified K-N discounting (Chen and Goodman, 1996). The configuration for the three systems is listed in Table 3. System P-Table Length LM Features Baseline-E 55.9M 7 2 15 Baseline-G 58.4M 7 2 15 EBMT 59.4M 7 2 15 HPB 122M 5 1 8 Table 3: Statistics of MT Systems In the above table, E/N/NC refers to Europarl/News/New Commentary corpus. In this table, E indicates the Europarl corpus 97 which is used for all three systems, and G stands for the Giga corpus which is only used for the Baseline system. We can see from Table 3 that the size of the HPB phrase-table is more than 2 times as large as the other phrase tables. How to filter and process suc</context>
</contexts>
<marker>Chen, Goodman, 1996</marker>
<rawString>Chen, S. F. and Goodman, J. (1996). An Empirical Study of Smoothing Techniques for Language Modeling. In Proceedings of the Thirty-Fourth Annual Meeting of the Association for Computational Linguistics, pages 310–318, San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chiang</author>
</authors>
<title>A Hierarchical Phrase-Based Model for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>263--270</pages>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="1479" citStr="Chiang, 2005" startWordPosition="222" endWordPosition="223">s. 1 Introduction In this paper, we present a multi-engine MT system developed at DCU, MATREX (Machine Translation using Examples). This system exploits EBMT, SMT and system combination techniques to build a cascaded translation framework. We participated in both the French–English and English-French News tasks. In these two tasks, we employ three individual MT system which are 1) Baseline: phrase-based system (PB); 2) EBMT: Monolingually chunking both source and target sides of the dataset using a marker-based chunker (Gough and Way, 2004). 3) HPB: a typical hierarchical phrase-based system (Chiang, 2005). Meanwhile, we also use a word-level combination framework (Rosti et al., 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final result. For the system combination task, we first use the minimum Bayes-risk (MBR) (Kumar and Byrne, 2004) decoder to select the best hypothesis as the alignment reference for the Confusion Network (CN) (Mangu et al., 2000). We then build the CN using the TER metric (Snover et al., 2006), and finally search and generate the translation. The remainder of this paper is organised as follows: Section 2 details the var</context>
<context position="4215" citStr="Chiang, 2005" startWordPosition="653" endWordPosition="654">We then align these segments using an editdistance-style algorithm, in which the insertion and deletion probabilities depend on word-toword translation probabilities and word-to-word cognates (Stroppa and Way, 2006). We extracted phrases of at most 7 words on each side. We then merged these phrases with the phrases extracted by the baseline system adding word alignment information, and used this system seeded with this additional information. 2.3 Hierarchical Machine Translation HPB translation system is a re-implementation of the hierarchical phrase translation model which is based on PSCFG (Chiang, 2005). We generate recursively PSCFG rules from the initial rules as N —* f1 ... fm/e1 ... en where N is a rule which is initial or includes nonterminals. M —* fi ... fj/eu ... ev where 1 &lt; i &lt; j &lt; m and 1 &lt; u &lt; v &lt; n, at which point a new rule can be obtained, named, N —* fi−1 1 Xkfm j+1/eu−1 1 Xken v+1 where k is an index for the nonterminal X. The number of nonterminals permitted in a rule is no more than two. When extracting hierarchical rules,we set some limitations that initial rules are of no more than 7 words in length and other rules should have no more than 5 terminals and nonterminals, a</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>Chiang, D. (2005). A Hierarchical Phrase-Based Model for Statistical Machine Translation. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 263–270, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Ferizis</author>
<author>P Bailey</author>
</authors>
<title>Towards practical genre classification of web documents.</title>
<date>2006</date>
<booktitle>In Proceedings of the 15th international conference on World Wide Web (WWW ’06),</booktitle>
<pages>1013--1014</pages>
<location>New York, USA.</location>
<contexts>
<context position="8934" citStr="Ferizis and Bailey, 2006" startWordPosition="1452" endWordPosition="1455">the corpus with tools provided by WMT09. The Giga corpus was too large for our resource, so we performed sentence selection before cleaning, in the following steps. • We split the Giga corpus into even segments, each segment consisting of 20 lines. • We trained an SVM classifier on English side with positive examples from the monolingual news data and negative examples from noisy sentences (numbers, meaningless word combinations, and random segments) from the Giga corpus. We used ”-ly” and ”-ing” to approximate adverbs and present participles and did not use other POS-induced features, as in (Ferizis and Bailey, 2006). We added these features to remove noise: average length of sentences, frequency of capitalized characters, frequency of numerical characters and short word penalty (equals to 1 when average length of words &lt; 4, and 0 otherwise). We used the classifier to remove 20% segments of lowest scores. • We selected 1, 600 words having the highest mutual information scores with monolingual training data against the Giga corpus. • We selected 100, 000 segments where these words occurred most frequently. However the sentence was dropped if the length ratio between English and French was larger than 1.5 o</context>
</contexts>
<marker>Ferizis, Bailey, 2006</marker>
<rawString>Ferizis, G. and Bailey, P. (2006). Towards practical genre classification of web documents. In Proceedings of the 15th international conference on World Wide Web (WWW ’06), pages 1013–1014, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J G Fiscus</author>
</authors>
<title>A post-processing system to yield reduced word error rates: Recognizer output voting error reduction (ROVER).</title>
<date>1997</date>
<booktitle>In Proceedings</booktitle>
<pages>347--352</pages>
<location>Santa Barbara, CA.</location>
<contexts>
<context position="6019" citStr="Fiscus, 1997" startWordPosition="982" endWordPosition="983"> decoder to select the best single system output from the merged N-best list by minimizing the BLEU (Papineni et al., 2002) loss. The confusion network is built by the output of MBR as the backbone which determines the word order of the combination. The other hypotheses are aligned against the backbone based on the TER metric. NULL words are allowed in the alignment. Each arc in the CN represents an alternative word at that position in the sentence and the number of votes for each word is counted when constructing the network. The features we used are as follows: • word posterior probability (Fiscus, 1997); • 3, 4-gram target language model; • word length penalty; • Null word length penalty; Also, we use MERT (Och, 2003) to tune the weights of confusion network. 2.5 Rescore Rescore is a very important part in post-processing which can select a better hypothesis from the Nbest list. We add some new global features in rescore model. The features we used are as follows: • Direct and inverse IBM model; • 3, 4-gram target language model; • 3, 4, 5-gram POS language model (Ratnaparkhi, 1996; Schmid, 1994); Recaser Recaser Decoding Mutiple 1-best MBR Decoder Rescore/MERT HPB CN/MERT Rescore/MERT Dev/M</context>
</contexts>
<marker>Fiscus, 1997</marker>
<rawString>Fiscus, J. G. (1997). A post-processing system to yield reduced word error rates: Recognizer output voting error reduction (ROVER). In Proceedings 1997 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), pages 347–352, Santa Barbara, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Gough</author>
<author>A Way</author>
</authors>
<title>Robust Large-Scale EBMT with Marker-Based Segmentation.</title>
<date>2004</date>
<booktitle>In Proceedings of the 10th International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-04),</booktitle>
<pages>95--104</pages>
<location>Baltimore, MD.</location>
<contexts>
<context position="1412" citStr="Gough and Way, 2004" startWordPosition="211" endWordPosition="214">etwork decoder. We report results on the provided development and test sets. 1 Introduction In this paper, we present a multi-engine MT system developed at DCU, MATREX (Machine Translation using Examples). This system exploits EBMT, SMT and system combination techniques to build a cascaded translation framework. We participated in both the French–English and English-French News tasks. In these two tasks, we employ three individual MT system which are 1) Baseline: phrase-based system (PB); 2) EBMT: Monolingually chunking both source and target sides of the dataset using a marker-based chunker (Gough and Way, 2004). 3) HPB: a typical hierarchical phrase-based system (Chiang, 2005). Meanwhile, we also use a word-level combination framework (Rosti et al., 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final result. For the system combination task, we first use the minimum Bayes-risk (MBR) (Kumar and Byrne, 2004) decoder to select the best hypothesis as the alignment reference for the Confusion Network (CN) (Mangu et al., 2000). We then build the CN using the TER metric (Snover et al., 2006), and finally search and generate the translation. The remaind</context>
<context position="3394" citStr="Gough and Way, 2004" startWordPosition="531" endWordPosition="534">escoring module to process the N-best list generated by the combination module. See Figure 1 as a detailed illustration. 2.2 Example-Based Machine Translation EBMT obtains resources using the Marker Hypothesis (Green, 1979), a psycholinguistic constraint which posits that all languages are marked for surface syntax by a specific closed set of lexemes or morphemes which signify context. Given a set of closed-class words we segment each sentence into chunks, creating a chunk at each new occurrence of a marker word, with the restriction that each segment must contain at least one nonmarker word (Gough and Way, 2004). Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 95–99, Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics 95 Figure 1: System Framework We then align these segments using an editdistance-style algorithm, in which the insertion and deletion probabilities depend on word-toword translation probabilities and word-to-word cognates (Stroppa and Way, 2006). We extracted phrases of at most 7 words on each side. We then merged these phrases with the phrases extracted by the baseline system adding word alignment information, and use</context>
</contexts>
<marker>Gough, Way, 2004</marker>
<rawString>Gough, N. and Way, A. (2004). Robust Large-Scale EBMT with Marker-Based Segmentation. In Proceedings of the 10th International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-04), pages 95–104, Baltimore, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Green</author>
</authors>
<title>The Necessity of Syntax Markers. Two experiments with artificial languages.</title>
<date>1979</date>
<journal>Journal of Verbal Learning and Behavior,</journal>
<pages>18--481</pages>
<contexts>
<context position="2997" citStr="Green, 1979" startWordPosition="464" endWordPosition="465">X system is a combination-based multi-engine architecture, which exploits aspects of both the EBMT and SMT paradigms. This architecture includes three individual systems which are phrase-based, example-based and hierarchical phrase-based. The combination structure is the MBR decoder and CN decoder, which is based on the word-level combination strategy. In the final stage, we use a new rescoring module to process the N-best list generated by the combination module. See Figure 1 as a detailed illustration. 2.2 Example-Based Machine Translation EBMT obtains resources using the Marker Hypothesis (Green, 1979), a psycholinguistic constraint which posits that all languages are marked for surface syntax by a specific closed set of lexemes or morphemes which signify context. Given a set of closed-class words we segment each sentence into chunks, creating a chunk at each new occurrence of a marker word, with the restriction that each segment must contain at least one nonmarker word (Gough and Way, 2004). Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 95–99, Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics 95 Figure 1: System Frame</context>
</contexts>
<marker>Green, 1979</marker>
<rawString>Green, T. (1979). The Necessity of Syntax Markers. Two experiments with artificial languages. Journal of Verbal Learning and Behavior, 18:481–496.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kumar</author>
<author>W Byrne</author>
</authors>
<title>Minimum Bayes-Risk Decoding for Statistical Machine Translation.</title>
<date>2004</date>
<booktitle>In Proceedings of the Joint Meeting of the Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics (HLT-NAACL 2004),</booktitle>
<pages>169--176</pages>
<location>Boston, MA.</location>
<contexts>
<context position="1768" citStr="Kumar and Byrne, 2004" startWordPosition="266" endWordPosition="269">sh and English-French News tasks. In these two tasks, we employ three individual MT system which are 1) Baseline: phrase-based system (PB); 2) EBMT: Monolingually chunking both source and target sides of the dataset using a marker-based chunker (Gough and Way, 2004). 3) HPB: a typical hierarchical phrase-based system (Chiang, 2005). Meanwhile, we also use a word-level combination framework (Rosti et al., 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final result. For the system combination task, we first use the minimum Bayes-risk (MBR) (Kumar and Byrne, 2004) decoder to select the best hypothesis as the alignment reference for the Confusion Network (CN) (Mangu et al., 2000). We then build the CN using the TER metric (Snover et al., 2006), and finally search and generate the translation. The remainder of this paper is organised as follows: Section 2 details the various components of our system, in particular the multi-engine strategies used for the shared task. In Section 3, we outline the complete system setup for the shared task and provide results on the development and test sets. Section 4 is our conclusion. 2 The MATREX System 2.1 System Archi</context>
</contexts>
<marker>Kumar, Byrne, 2004</marker>
<rawString>Kumar, S. and Byrne, W. (2004). Minimum Bayes-Risk Decoding for Statistical Machine Translation. In Proceedings of the Joint Meeting of the Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics (HLT-NAACL 2004), pages 169–176, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Mangu</author>
<author>E Brill</author>
<author>A Stolcke</author>
</authors>
<title>Finding consensus in speech recognition: Word error minimization and other applications of confusion networks.</title>
<date>2000</date>
<journal>Computer Speech and Language,</journal>
<volume>14</volume>
<issue>4</issue>
<contexts>
<context position="1885" citStr="Mangu et al., 2000" startWordPosition="286" endWordPosition="289">-based system (PB); 2) EBMT: Monolingually chunking both source and target sides of the dataset using a marker-based chunker (Gough and Way, 2004). 3) HPB: a typical hierarchical phrase-based system (Chiang, 2005). Meanwhile, we also use a word-level combination framework (Rosti et al., 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final result. For the system combination task, we first use the minimum Bayes-risk (MBR) (Kumar and Byrne, 2004) decoder to select the best hypothesis as the alignment reference for the Confusion Network (CN) (Mangu et al., 2000). We then build the CN using the TER metric (Snover et al., 2006), and finally search and generate the translation. The remainder of this paper is organised as follows: Section 2 details the various components of our system, in particular the multi-engine strategies used for the shared task. In Section 3, we outline the complete system setup for the shared task and provide results on the development and test sets. Section 4 is our conclusion. 2 The MATREX System 2.1 System Architecture The MATREX system is a combination-based multi-engine architecture, which exploits aspects of both the EBMT a</context>
</contexts>
<marker>Mangu, Brill, Stolcke, 2000</marker>
<rawString>Mangu, L., Brill, E., and Stolcke, A. (2000). Finding consensus in speech recognition: Word error minimization and other applications of confusion networks. Computer Speech and Language, 14(4):373–400.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>160--167</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="6136" citStr="Och, 2003" startWordPosition="1003" endWordPosition="1004">02) loss. The confusion network is built by the output of MBR as the backbone which determines the word order of the combination. The other hypotheses are aligned against the backbone based on the TER metric. NULL words are allowed in the alignment. Each arc in the CN represents an alternative word at that position in the sentence and the number of votes for each word is counted when constructing the network. The features we used are as follows: • word posterior probability (Fiscus, 1997); • 3, 4-gram target language model; • word length penalty; • Null word length penalty; Also, we use MERT (Och, 2003) to tune the weights of confusion network. 2.5 Rescore Rescore is a very important part in post-processing which can select a better hypothesis from the Nbest list. We add some new global features in rescore model. The features we used are as follows: • Direct and inverse IBM model; • 3, 4-gram target language model; • 3, 4, 5-gram POS language model (Ratnaparkhi, 1996; Schmid, 1994); Recaser Recaser Decoding Mutiple 1-best MBR Decoder Rescore/MERT HPB CN/MERT Rescore/MERT Dev/MERT Baseline System Combination EBMT Mutiple 1-best MBR Decoder CN Decoder Rescore Rescore TestSet 96 • Sentence leng</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Och, F. (2003). Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL), pages 160–167, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W-J Zhu</author>
</authors>
<title>BLEU: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL-02),</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="5529" citStr="Papineni et al., 2002" startWordPosition="895" endWordPosition="899">an enhanced CYK-style chart parser that maximizes the derivation probability and spans up to 12 source words. A 4-gram language model generated by SRI Language Modeling toolkit (SRILM) (Stolcke, 2002) is used in the cube-pruning process. The search space is pruned with a chart cell size limit of 50. 2.4 System Combination For multiple system combination, we implement an MBR-CN framework as shown in Figure 1. Instead of using a single system output as the skeleton, we employ a minimum Bayes-risk decoder to select the best single system output from the merged N-best list by minimizing the BLEU (Papineni et al., 2002) loss. The confusion network is built by the output of MBR as the backbone which determines the word order of the combination. The other hypotheses are aligned against the backbone based on the TER metric. NULL words are allowed in the alignment. Each arc in the CN represents an alternative word at that position in the sentence and the number of votes for each word is counted when constructing the network. The features we used are as follows: • word posterior probability (Fiscus, 1997); • 3, 4-gram target language model; • word length penalty; • Null word length penalty; Also, we use MERT (Och</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J. (2002). BLEU: a Method for Automatic Evaluation of Machine Translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL-02), pages 311–318, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>A Maximum Entropy Model for Part-Of-Speech Tagging.</title>
<date>1996</date>
<booktitle>In Proceedings of the Empirical Methods in Natural Language Processing Conference (EMNLP),</booktitle>
<pages>133--142</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="6507" citStr="Ratnaparkhi, 1996" startWordPosition="1069" endWordPosition="1071">h word is counted when constructing the network. The features we used are as follows: • word posterior probability (Fiscus, 1997); • 3, 4-gram target language model; • word length penalty; • Null word length penalty; Also, we use MERT (Och, 2003) to tune the weights of confusion network. 2.5 Rescore Rescore is a very important part in post-processing which can select a better hypothesis from the Nbest list. We add some new global features in rescore model. The features we used are as follows: • Direct and inverse IBM model; • 3, 4-gram target language model; • 3, 4, 5-gram POS language model (Ratnaparkhi, 1996; Schmid, 1994); Recaser Recaser Decoding Mutiple 1-best MBR Decoder Rescore/MERT HPB CN/MERT Rescore/MERT Dev/MERT Baseline System Combination EBMT Mutiple 1-best MBR Decoder CN Decoder Rescore Rescore TestSet 96 • Sentence length posterior probability (Zens and Ney, 2006); • N-gram posterior probabilities within the NBest list (Zens and Ney, 2006); • Minimum Bayes Risk probability; • Length ratio between source and target sentence; The weights are optimized via MERT algorithm. 3 Experimental Setup The following section describes the system and experimental setup for the French-English and En</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>Ratnaparkhi, A. (1996). A Maximum Entropy Model for Part-Of-Speech Tagging. In Proceedings of the Empirical Methods in Natural Language Processing Conference (EMNLP), pages 133–142, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A-V I Rosti</author>
<author>B Xiang</author>
<author>S Matsoukas</author>
<author>R Schwartz</author>
<author>N F Ayan</author>
<author>B J Dorr</author>
</authors>
<title>Combining outputs from multiple machine translation systems.</title>
<date>2007</date>
<booktitle>In Proceedings of the Joint Meeting of the Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics (HLT-NAACL</booktitle>
<pages>228--235</pages>
<location>Rochester, NY.</location>
<contexts>
<context position="1559" citStr="Rosti et al., 2007" startWordPosition="233" endWordPosition="236">oped at DCU, MATREX (Machine Translation using Examples). This system exploits EBMT, SMT and system combination techniques to build a cascaded translation framework. We participated in both the French–English and English-French News tasks. In these two tasks, we employ three individual MT system which are 1) Baseline: phrase-based system (PB); 2) EBMT: Monolingually chunking both source and target sides of the dataset using a marker-based chunker (Gough and Way, 2004). 3) HPB: a typical hierarchical phrase-based system (Chiang, 2005). Meanwhile, we also use a word-level combination framework (Rosti et al., 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final result. For the system combination task, we first use the minimum Bayes-risk (MBR) (Kumar and Byrne, 2004) decoder to select the best hypothesis as the alignment reference for the Confusion Network (CN) (Mangu et al., 2000). We then build the CN using the TER metric (Snover et al., 2006), and finally search and generate the translation. The remainder of this paper is organised as follows: Section 2 details the various components of our system, in particular the multi-engine strategies used fo</context>
</contexts>
<marker>Rosti, Xiang, Matsoukas, Schwartz, Ayan, Dorr, 2007</marker>
<rawString>Rosti, A.-V. I., Xiang, B., Matsoukas, S., Schwartz, R., Ayan, N. F., and Dorr, B. J. (2007). Combining outputs from multiple machine translation systems. In Proceedings of the Joint Meeting of the Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics (HLT-NAACL 2007), pages 228–235, Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
</authors>
<title>Probabilistic Part-of-Speech Tagging Using Decision Trees.</title>
<date>1994</date>
<booktitle>In Proceedings of International Conference on New Methods in Language Processing,</booktitle>
<pages>44--49</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="6522" citStr="Schmid, 1994" startWordPosition="1072" endWordPosition="1073">hen constructing the network. The features we used are as follows: • word posterior probability (Fiscus, 1997); • 3, 4-gram target language model; • word length penalty; • Null word length penalty; Also, we use MERT (Och, 2003) to tune the weights of confusion network. 2.5 Rescore Rescore is a very important part in post-processing which can select a better hypothesis from the Nbest list. We add some new global features in rescore model. The features we used are as follows: • Direct and inverse IBM model; • 3, 4-gram target language model; • 3, 4, 5-gram POS language model (Ratnaparkhi, 1996; Schmid, 1994); Recaser Recaser Decoding Mutiple 1-best MBR Decoder Rescore/MERT HPB CN/MERT Rescore/MERT Dev/MERT Baseline System Combination EBMT Mutiple 1-best MBR Decoder CN Decoder Rescore Rescore TestSet 96 • Sentence length posterior probability (Zens and Ney, 2006); • N-gram posterior probabilities within the NBest list (Zens and Ney, 2006); • Minimum Bayes Risk probability; • Length ratio between source and target sentence; The weights are optimized via MERT algorithm. 3 Experimental Setup The following section describes the system and experimental setup for the French-English and English-French tr</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Schmid, H. (1994). Probabilistic Part-of-Speech Tagging Using Decision Trees. In Proceedings of International Conference on New Methods in Language Processing, pages 44–49, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Snover</author>
<author>B Dorr</author>
<author>R Schwartz</author>
<author>L Micciula</author>
<author>J Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas (AMTA</booktitle>
<pages>223--231</pages>
<location>Cambridge, MA.</location>
<contexts>
<context position="1950" citStr="Snover et al., 2006" startWordPosition="299" endWordPosition="302">and target sides of the dataset using a marker-based chunker (Gough and Way, 2004). 3) HPB: a typical hierarchical phrase-based system (Chiang, 2005). Meanwhile, we also use a word-level combination framework (Rosti et al., 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final result. For the system combination task, we first use the minimum Bayes-risk (MBR) (Kumar and Byrne, 2004) decoder to select the best hypothesis as the alignment reference for the Confusion Network (CN) (Mangu et al., 2000). We then build the CN using the TER metric (Snover et al., 2006), and finally search and generate the translation. The remainder of this paper is organised as follows: Section 2 details the various components of our system, in particular the multi-engine strategies used for the shared task. In Section 3, we outline the complete system setup for the shared task and provide results on the development and test sets. Section 4 is our conclusion. 2 The MATREX System 2.1 System Architecture The MATREX system is a combination-based multi-engine architecture, which exploits aspects of both the EBMT and SMT paradigms. This architecture includes three individual sys</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciula, Makhoul, 2006</marker>
<rawString>Snover, M., Dorr, B., Schwartz, R., Micciula, L., and Makhoul, J. (2006). A study of translation edit rate with targeted human annotation. In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas (AMTA 2006), pages 223–231, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>SRILM - An Extensible Language Modeling Toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference Spoken Language Processing,</booktitle>
<pages>901--904</pages>
<location>Denver, CO.</location>
<contexts>
<context position="5107" citStr="Stolcke, 2002" startWordPosition="823" endWordPosition="824">fm j+1/eu−1 1 Xken v+1 where k is an index for the nonterminal X. The number of nonterminals permitted in a rule is no more than two. When extracting hierarchical rules,we set some limitations that initial rules are of no more than 7 words in length and other rules should have no more than 5 terminals and nonterminals, and we disallow rules with adjacent source-side and target-side nonterminals. The decoder is an enhanced CYK-style chart parser that maximizes the derivation probability and spans up to 12 source words. A 4-gram language model generated by SRI Language Modeling toolkit (SRILM) (Stolcke, 2002) is used in the cube-pruning process. The search space is pruned with a chart cell size limit of 50. 2.4 System Combination For multiple system combination, we implement an MBR-CN framework as shown in Figure 1. Instead of using a single system output as the skeleton, we employ a minimum Bayes-risk decoder to select the best single system output from the merged N-best list by minimizing the BLEU (Papineni et al., 2002) loss. The confusion network is built by the output of MBR as the backbone which determines the word order of the combination. The other hypotheses are aligned against the backbo</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Stolcke, A. (2002). SRILM - An Extensible Language Modeling Toolkit. In Proceedings of the International Conference Spoken Language Processing, pages 901–904, Denver, CO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Stroppa</author>
<author>A Way</author>
</authors>
<title>MaTrEx: the DCU machine translation system for IWSLT</title>
<date>2006</date>
<booktitle>In Proceedings of the International Workshop on Spoken Language Translation,</booktitle>
<pages>31--36</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="3817" citStr="Stroppa and Way, 2006" startWordPosition="591" endWordPosition="594">s we segment each sentence into chunks, creating a chunk at each new occurrence of a marker word, with the restriction that each segment must contain at least one nonmarker word (Gough and Way, 2004). Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 95–99, Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics 95 Figure 1: System Framework We then align these segments using an editdistance-style algorithm, in which the insertion and deletion probabilities depend on word-toword translation probabilities and word-to-word cognates (Stroppa and Way, 2006). We extracted phrases of at most 7 words on each side. We then merged these phrases with the phrases extracted by the baseline system adding word alignment information, and used this system seeded with this additional information. 2.3 Hierarchical Machine Translation HPB translation system is a re-implementation of the hierarchical phrase translation model which is based on PSCFG (Chiang, 2005). We generate recursively PSCFG rules from the initial rules as N —* f1 ... fm/e1 ... en where N is a rule which is initial or includes nonterminals. M —* fi ... fj/eu ... ev where 1 &lt; i &lt; j &lt; m and 1 &lt;</context>
</contexts>
<marker>Stroppa, Way, 2006</marker>
<rawString>Stroppa, N. and Way, A. (2006). MaTrEx: the DCU machine translation system for IWSLT 2006. In Proceedings of the International Workshop on Spoken Language Translation, pages 31–36, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>H Ney</author>
</authors>
<title>N-gram Posterior Probabilities for Statistical Machine Translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Joint Meeting of the Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics (HLT-NAACL</booktitle>
<pages>72--77</pages>
<location>New York, USA.</location>
<contexts>
<context position="6781" citStr="Zens and Ney, 2006" startWordPosition="1105" endWordPosition="1108">nfusion network. 2.5 Rescore Rescore is a very important part in post-processing which can select a better hypothesis from the Nbest list. We add some new global features in rescore model. The features we used are as follows: • Direct and inverse IBM model; • 3, 4-gram target language model; • 3, 4, 5-gram POS language model (Ratnaparkhi, 1996; Schmid, 1994); Recaser Recaser Decoding Mutiple 1-best MBR Decoder Rescore/MERT HPB CN/MERT Rescore/MERT Dev/MERT Baseline System Combination EBMT Mutiple 1-best MBR Decoder CN Decoder Rescore Rescore TestSet 96 • Sentence length posterior probability (Zens and Ney, 2006); • N-gram posterior probabilities within the NBest list (Zens and Ney, 2006); • Minimum Bayes Risk probability; • Length ratio between source and target sentence; The weights are optimized via MERT algorithm. 3 Experimental Setup The following section describes the system and experimental setup for the French-English and English-French translation tasks. 3.1 Statistics of Data Parallel Corpus We used Europarl and Giga data for this evaluation. The statistics of parallel data are shown in Table 1. Corpra Sen Token-En Token-Fr Len Europarl 1.46M 39,240,672 42,252,067 80 Giga 2M 48,648,104 57,86</context>
</contexts>
<marker>Zens, Ney, 2006</marker>
<rawString>Zens, R. and Ney, H. (2006). N-gram Posterior Probabilities for Statistical Machine Translation. In Proceedings of the Joint Meeting of the Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics (HLT-NAACL 2006), pages 72–77, New York, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>