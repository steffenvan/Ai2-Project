<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001070">
<title confidence="0.9995175">
Domain Adaptation for Statistical Machine Translation
with Monolingual Resources
</title>
<author confidence="0.984146">
Nicola Bertoldi Marcello Federico
</author>
<affiliation confidence="0.771394">
FBK-irst - Ricerca Scientifica e Tecnologica
</affiliation>
<address confidence="0.803104">
Via Sommarive 18, Povo (TN), Italy
</address>
<email confidence="0.996263">
{bertoldi, federico}@fbk.eu
</email>
<sectionHeader confidence="0.993757" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999962821428572">
Domain adaptation has recently gained
interest in statistical machine translation
to cope with the performance drop ob-
served when testing conditions deviate
from training conditions. The basic idea
is that in-domain training data can be ex-
ploited to adapt all components of an al-
ready developed system. Previous work
showed small performance gains by adapt-
ing from limited in-domain bilingual data.
Here, we aim instead at significant per-
formance gains by exploiting large but
cheap monolingual in-domain data, either
in the source or in the target language.
We propose to synthesize a bilingual cor-
pus by translating the monolingual adap-
tation data into the counterpart language.
Investigations were conducted on a state-
of-the-art phrase-based system trained on
the Spanish–English part of the UN cor-
pus, and adapted on the corresponding
Europarl data. Translation, re-ordering,
and language models were estimated after
translating in-domain texts with the base-
line. By optimizing the interpolation of
these models on a development set the
BLEU score was improved from 22.60%
to 28.10% on a test set.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999673745098039">
A well-known problem of Statistical Machine
Translation (SMT) is that performance quickly de-
grades as soon as testing conditions deviate from
training conditions. The very simple reason is that
the underlying statistical models always tend to
closely approximate the empirical distributions of
the training data, which typically consist of bilin-
gual texts and monolingual target-language texts.
The former provide a means to learn likely trans-
lations pairs, the latter to form correct sentences
with translated words. Besides the general diffi-
culties of language translation, which we do not
consider here, there are two aspects that make
machine learning of this task particularly hard.
First, human language has intrinsically very sparse
statistics at the surface level, hence gaining com-
plete knowledge on translation phrase pairs or tar-
get language n-grams is almost impractical. Sec-
ond, language is highly variable with respect to
several dimensions, style, genre, domain, topics,
etc. Even apparently small differences in domain
might result in significant deviations in the un-
derlying statistical models. While data sparseness
corroborates the need of large language samples in
SMT, linguistic variability would indeed suggest
to consider many alternative data sources as well.
By rephrasing a famous saying we could say that
“no data is better than more and assorted data”.
The availability of language resources for SMT
has dramatically increased over the last decade,
at least for a subset of relevant languages and es-
pecially for what concerns monolingual corpora.
Unfortunately, the increase in quantity has not
gone in parallel with an increase in assortment, es-
pecially for what concerns the most valuable re-
source, that is bilingual corpora. Large parallel
data available to the research community are for
the moment limited to texts produced by interna-
tional organizations (European Parliament, United
Nations, Canadian Hansard), press agencies, and
technical manuals.
The limited availability of parallel data poses
challenging questions regarding the portability of
SMT across different application domains and lan-
guage pairs, and its adaptability with respect to
language variability within the same application
domain.
This work focused on the second issue, namely
the adaptation of a Spanish-to-English phrase-
based SMT system across two apparently close
domains: the United Nation corpus and the Euro-
</bodyText>
<note confidence="0.9380085">
Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 182–189,
Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.994999">
182
</page>
<bodyText confidence="0.996541416666667">
pean Parliament corpus. Cross-domain adaptation
is faced under the assumption that only monolin-
gual texts are available, either in the source lan-
guage or in the target language.
The paper is organized as follows. Section 2
presents previous work on the problem of adap-
tation in SMT; Section 3 introduces the exemplar
task and research questions we addressed; Sec-
tion 4 describes the SMT system and the adapta-
tion techniques that were investigated; Section 5
presents and discusses experimental results; and
Section 6 provides conclusions.
</bodyText>
<sectionHeader confidence="0.993204" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999505426229508">
Domain adaptation in SMT has been investigated
only recently. In (Eck et al., 2004) adaptation is
limited to the target language model (LM). The
background LM is combined with one estimated
on documents retrieved from the WEB by using
the input sentence as query and applying cross-
language information retrieval techniques. Refine-
ments of this approach are described in (Zhao et
al., 2004).
In (Hildebrand et al., 2005) information retrieval
techniques are applied to retrieve sentence pairs
from the training corpus that are relevant to the test
sentences. Both the language and the translation
models are retrained on the extracted data.
In (Foster and Kuhn, 2007) two basic settings are
investigated: cross-domain adaptation, in which
a small sample of parallel in-domain text is as-
sumed, and dynamic adaptation, in which only
the current input source text is considered. Adap-
tation relies on mixture models estimated on the
training data through some unsupervised cluster-
ing method. Given available adaptation data, mix-
ture weights are re-estimated ad-hoc. A varia-
tion of this approach was also recently proposed
in (Finch and Sumita, 2008). In (Civera and Juan,
2007) mixture models are instead employed to
adapt a word alignment model to in-domain par-
allel data.
In (Koehn and Schroeder, 2007) cross-domain
adaptation techniques were applied on a phrase-
based SMT trained on the Europarl task, in or-
der to translate news commentaries, from French
to English. In particular, a small portion of in-
domain bilingual data was exploited to adapt the
Europarl language model and translation models
by means of linear interpolation techniques. Ueff-
ing et al. (2007) proposed several elaborate adap-
tation methods relying on additional bilingual data
synthesized from the development or test set.
Our work is mostly related to (Koehn and
Schroeder, 2007) but explores different assump-
tions about available adaptation data: i.e. only
monolingual in-domain texts are available. The
adaptation of the translation and re-ordering mod-
els is performed by generating synthetic bilingual
data from monolingual texts, similarly to what
proposed in (Schwenk, 2008). Interpolation of
multiple phrase tables is applied in a more prin-
cipled way than in (Koehn and Schroeder, 2007):
all entries are merged into one single table, cor-
responding feature functions are concatenated and
smoothing is applied when observations are miss-
ing. The approach proposed in this paper has
many similarities with the simplest technique in
(Ueffing et al., 2007), but it is applied to a much
larger monolingual corpus.
Finally, with respect to previous work we also
investigate the behavior of the minimum error
training procedure to optimize the combination of
feature functions on a small in-domain bilingual
sample.
</bodyText>
<sectionHeader confidence="0.982321" genericHeader="method">
3 Task description
</sectionHeader>
<bodyText confidence="0.999901260869565">
This paper addresses the issue of adapting an al-
ready developed phrase-based translation system
in order to work properly on a different domain,
for which almost no parallel data are available but
only monolingual texts.1
The main components of the SMT system are
the translation model, which aims at porting the
content from the source to the target language, and
the language model, which aims at building fluent
sentences in the target language. While the former
is trained with bilingual data, the latter just needs
monolingual target texts. In this work, a lexical-
ized re-ordering model is also exploited to control
re-ordering of target words. This model is also
learnable from parallel data.
Assuming some large monolingual in-domain
texts are available, two basic adaptation ap-
proaches are pursued here: (i) generating syn-
thetic bilingual data with an available SMT sys-
tem and use this data to adapt its translation and
re-ordering models; (ii) using synthetic or pro-
vided target texts to also, or only, adapt its lan-
guage model. The following research questions
</bodyText>
<footnote confidence="0.9955695">
1We assume only availability of a development set and an
evaluation set.
</footnote>
<page confidence="0.998879">
183
</page>
<bodyText confidence="0.953013">
summarize our basic interest in this work:
</bodyText>
<listItem confidence="0.998470909090909">
• Is automatic generation of bilingual data ef-
fective to tackle the lack of parallel data?
• Is it more effective to use source language
adaptation data or target language adaptation
data?
• Is it convenient to combine models learned
from adaptation data with models learned
from training data?
• How can interpolation of models be effec-
tively learned from small amounts of in-
domain parallel data?
</listItem>
<sectionHeader confidence="0.893387" genericHeader="method">
4 System description
</sectionHeader>
<bodyText confidence="0.999944954545455">
The investigation presented in this paper was car-
ried out with the Moses toolkit (Koehn et al.,
2007), a state-of-the-art open-source phrase-based
SMT system. We trained Moses in a standard con-
figuration, including a 4-feature translation model,
a 7-feature lexicalized re-ordering model, one LM,
word and phrase penalties.
The translation and the re-ordering model re-
lied on “grow-diag-final” symmetrized word-to-
word alignments built using GIZA++ (Och and
Ney, 2003) and the training script of Moses. A
5-gram language model was trained on the tar-
get side of the training parallel corpus using the
IRSTLM toolkit (Federico et al., 2008), exploiting
Modified Kneser-Ney smoothing, and quantizing
both probabilities and backoff weights. Decoding
was performed applying cube-pruning with a pop-
limit of 6000 hypotheses.
Log-linear interpolations of feature functions
were estimated with the parallel version of mini-
mum error rate training procedure distributed with
Moses.
</bodyText>
<subsectionHeader confidence="0.999182">
4.1 Fast Training from Synthetic Data
</subsectionHeader>
<bodyText confidence="0.999340333333333">
The standard procedure of Moses for the estima-
tion of the translation and re-ordering models from
a bilingual corpus consists in three main steps:
</bodyText>
<listItem confidence="0.891839545454545">
1. A word-to-word alignment is generated with
GIZA++.
2. Phrase pairs are extracted from the word-to-
word alignment using the method proposed
by (Och and Ney, 2003); countings and re-
ordering statistics of all pairs are stored. A
word-to-word lexicon is built as well.
3. Frequency-based and lexicon-based direct
and inverted probabilities, and re-ordering
probabilities are computed using statistics
from step 2.
</listItem>
<bodyText confidence="0.9999955">
Recently, we enhanced Moses decoder to also
output the word-to-word alignment between the
input sentence and its translation, given that they
have been added to the phrase table at training
time. Notice that the additional information intro-
duces an overhead in disk usage of about 70%, but
practically no overhead at decoding time. How-
ever, when training translation and re-ordering
models from synthetic data generated by the de-
coder, this feature allows to completely skip the
time-expensive step 1.2
We tested the efficiency of this solution for
training a translation model on a synthesized cor-
pus of about 300K Spanish sentences and 8.8M
running words, extracted from the EuroParl cor-
pus. With respect to the standard procedure, the
total training time was reduced by almost 50%,
phrase extraction produced 10% more phrase
pairs, and the final translation system showed a
loss in translation performance (BLEU score) be-
low 1% relative. Given this outcome we decided
to apply the faster procedure in all experiments.
</bodyText>
<subsectionHeader confidence="0.9982">
4.2 Model combination
</subsectionHeader>
<bodyText confidence="0.99997">
Once monolingual adaptation data is automati-
cally translated, we can use the synthetic parallel
corpus to estimate new language, translation, and
re-ordering models. Such models can either re-
place or be combined with the original models of
the SMT system. There is another simple option
which is to concatenate the synthetic parallel data
with the original training data and re-build the sys-
tem. We did not investigate this approach because
it does not allow to properly balance the contribu-
tion of different data sources, and also showed to
underperform in preliminary work.
Concerning the combination of models, in the
following we explain how Moses was extended
to manage multiple translation models (TMs) and
multiple re-ordering models (RMs).
</bodyText>
<subsectionHeader confidence="0.999061">
4.3 Using multiple models in Moses
</subsectionHeader>
<bodyText confidence="0.958826333333333">
In Moses, a TM is provided as a phrase table,
which is a set S = {(�f, e)} of phrase pairs as-
sociated with a given number of features values
</bodyText>
<footnote confidence="0.785941666666667">
2Authors are aware of an enhanced version of GIZA++,
which allows parallel computation, but it was not taken into
account in this work.
</footnote>
<page confidence="0.996843">
184
</page>
<bodyText confidence="0.99923844">
h(�f, E; S). In our configuration, 5 features for the
TM (the phrase penalty is included) are taken into
account.
In the first phase of the decoding process, Moses
generates translation options for all possible in-
put phrases f through a lookup into S; it simply
extracts alternative phrase pairs ( f, E) for a spe-
cific f and optionally applies pruning (based on
the feature values and weights) to limit the num-
ber of such pairs. In the second phase of decod-
ing, it creates translation hypotheses of the full
input sentence by combining in all possible ways
(satisfying given re-ordering constraints) the pre-
fetched translation options. In this phase the hy-
potheses are scored, according to all features func-
tions, ranked, and possibly pruned.
When more TMs Sj are available, Moses can
behave in two different ways in pre-fetching the
translation options. It searches a given f in all sets
and keeps a phrase pair ( f, E) if it belongs to either
i) their intersection or ii) their union. The former
method corresponds to building one new TM SI,
whose set is the intersection of all given sets:
phrase-based and lexical-based direct features are
defined as follows:
</bodyText>
<equation confidence="0.996552">
h(�f, E; Sj) = �
(l + 1)m
</equation>
<bodyText confidence="0.999742529411765">
Here, φ(ek  |fh) is the probability of ek given fh
provided by the word-to-word lexicon computed
on Sj. The inverted features are defined simi-
larly. The phrase penalty is trivially set to 1. The
same approach has been applied to build the union
of re-ordering models. In this case, however, the
smoothing value is constant and set to 0.001.
As concerns as the use of multiple LMs, Moses
has a very easy policy, consisting of querying each
of them to get the likelihood of a translation hy-
potheses, and uses all these scores as features.
It is worth noting that the exploitation of mul-
tiple models increases the number of features of
the whole system, because each model adds its
set of features. Furthermore, the first approach of
Moses for model combination shrinks the size of
the phrase table, while the second one enlarges it.
</bodyText>
<equation confidence="0.994842125">
l
m
H
k=1
φ(ek  |fh)
E
h=0
SI = {( �f, �e)  |bj ( �f, E) E Sj} 5 Evaluation
</equation>
<bodyText confidence="0.979168521739131">
The set of features of the new TM is the union of
the features of all single TMs. Straightforwardly,
all feature values are well-defined.
The second method corresponds to building one
new TM SU, whose set is the union of all given
sets:
SU = {( �f, �e)  |�j ( f, E) E Sj}
Again, the set of features of the new TM is the
union of the features of all single TMs; but for a
phrase pair (�f, E) belonging to SU \Sj, the feature
values h(�f, E; Sj) are undefined. In these unde-
fined situations, Moses provides a default value of
0, which is the highest available score, as the fea-
ture values come from probabilistic distributions
and are expressed as logarithms. Henceforth, a
phrase pair belonging to all original sets is penal-
ized with respect to phrase pairs belonging to few
of them only.
To address this drawback, we proposed a
new method3 to compute a more reliable and
smoothed score in the undefined case, based on
the IBM model 1 (Brown et al., 1993). If ( f� =
f1, ... , fl, e� = e1, ... , el) E SU \ Sj for any j the
</bodyText>
<footnote confidence="0.515186">
3Authors are not aware of any work addressing this issue.
</footnote>
<subsectionHeader confidence="0.981506">
5.1 Data Description
</subsectionHeader>
<bodyText confidence="0.999936181818182">
In this work, the background domain is given by
the Spanish-English portion of the UN parallel
corpus,4 composed by documents coming from
the Office of Conference Services at the UN in
New York spanning the period between 1988 and
1993. The adaptation data come from the Eu-
ropean Parliament corpus (Koehn, 2002) (EP) as
provided for the shared translation task of the
2008 Workshop on Statistical Machine Transla-
tion.5 Development and test sets for this task,
namely dev2006 and test2008, are supplied as
well, and belong to the European Parliament do-
main.
We use the symbol S¯ (¯E) to denote synthetic
Spanish (English) data. Spanish-to-English and
English-to-Spanish systems trained on UN data
were exploited to generate English and Spanish
synthetic portions of the original EP corpus, re-
spectively. In this way, we created two synthetic
versions of the EP corpus, named S¯E-EP and ¯SE-
EP, respectively. All presented translation systems
were optimized on the dev2006 set with respect to
</bodyText>
<footnote confidence="0.989474333333333">
4Distributed by the Linguistic Data Consortium, cata-
logue # LDC94T4A.
5http://www.statmt.org/wmt08
</footnote>
<page confidence="0.99699">
185
</page>
<bodyText confidence="0.999697">
the BLEU score (Papineni et al., 2002), and tested
on test2008. (Notice that one reference translation
is available for both sets.) Table 1 reports statistics
of original and synthetic parallel corpora, as well
of the employed development and evaluation data
sets. All the texts were just tokenized and mixed
case was kept. Hence, all systems were developed
to produce case-sensitive translations.
</bodyText>
<table confidence="0.999486625">
corpus sent Spanish English
word dict word dict
UN 2.5M 50.5M 253K 45.2M 224K
EP 1.3M 36.4M 164K 35.0M 109K
S¯E-EP 1.3M 36.4M 164K 35.4M 133K
¯SE-EP 1.3M 36.2M 120K 35.0M 109K
dev 2,000 60,438 8,173 58,653 6,548
test 2,000 61,756 8,331 60,058 6,497
</table>
<tableCaption confidence="0.9970105">
Table 1: Statistics of bilingual training corpora,
development and test data (after tokenization).
</tableCaption>
<subsectionHeader confidence="0.997586">
5.2 Baseline systems
</subsectionHeader>
<bodyText confidence="0.999838975000001">
Three Spanish-to-English baseline systems were
trained by exploiting different parallel or mono-
lingual corpora summarized in the first three lines
in Table 2. For each system, the table reports the
perplexity and out-of-vocabulary (OOV) percent-
age of their LM, and its translation performance
achieved on the test set in terms of BLEU score,
NIST score, WER (word error rate) and PER (po-
sition independent error rate).
The distance in style, genre, jargon, etc. be-
tween the UN and the EP corpora is made evident
by the gap in perplexity (Federico and De Mori,
1998) and OOV percentage between their English
LMs: 286 vs 74 and 1.12% vs 0.15%, respectively.
Performance of the system trained on the EP
corpus (third row) can be taken as an upper bound
for any adaptation strategy trying to exploit parts
of the EP corpus, while those of the first line
clearly provide the corresponding lower-bound.
The system in the second row can instead be con-
sider as the lower bound when only monolingual
English adaptation data are assumed.
The synthesis of the S¯E-EP corpus was per-
formed with the system trained just on the UN
training data (first row of Table 2), because we had
assumed that the in-domain data were only mono-
lingual Spanish and thus not useful for neither the
TM, RM nor target LM estimation.
Similarly, the system in the last row of Table 2
was developed on the UN corpus to translate the
English part of the EP data to generate the syn-
thetic ¯SE-EP corpus. Again, any in-domain data
were exploited to train this sytem. Of course, this
system cannot be compared with any other be-
cause of the different translation direction.
In order to compare reported performance with
the state-of-the-art, Table 2 also reports results
of the best system published in the EuroMatrix
project website6 and of the Google online trans-
lation engine.7
</bodyText>
<subsectionHeader confidence="0.998681">
5.3 Analysis of the tuning process
</subsectionHeader>
<bodyText confidence="0.999497125">
It is well-known that tuning the SMT system is
fundamental to achieve good performance. The
standard tuning procedure consists of a minimum
error rate training (mert) (Och and Ney, 2003)
which relies on the availability of a development
data set. On the other hand, the most important
assumption we make is that almost no parallel in-
domain data are available.
</bodyText>
<figure confidence="0.831522833333333">
conf sent n-best time (min) BLEU (A)
– – – – 22.28
a 2000 1000 2034 23.68 (1.40)
b 2000 200 391 23.67 (1.39)
c 200 1000 866 23.13 (0.85)
d 200 200 551 23.54 (1.26)
</figure>
<tableCaption confidence="0.925438">
Table 3: Global time, not including decoding, of
</tableCaption>
<bodyText confidence="0.997119066666667">
the tuning process and BLEU score achieved on
the test set by the uniform interpolation weights
(first row), and by the optimal weights with differ-
ent configurations of the tuning parameters.
In a preliminary phase, we investigated different
settings of the tuning process in order to under-
stand how much development data is required to
perform a reliable weight optimization. Our mod-
els were trained on the S¯E-EP parallel corpus and
by using uniform interpolation weights the system
achieved a BLEU score of 22.28% on the test set
(see Table 3).
We assumed to dispose of either a regular
in-domain development set of 2,000 sentences
(dev2006), or a small portion of it of just 200 sen-
</bodyText>
<footnote confidence="0.9905296">
6http://www.euromatrix.net. Translations of the best sys-
tem were downloaded on November 7th, 2008. Published
results differ because we performed a case-sensitive evalua-
tion.
7Google was queried on November 3rd, 2008.
</footnote>
<page confidence="0.993026">
186
</page>
<table confidence="0.999409727272727">
language pair training data PP OOV (%) BLEU NIST WER PER
TM/RM LM
Spanish-English UN UN 286 1.12 22.60 6.51 64.60 48.52
” UN EP 74 0.15 27.83 7.12 60.93 45.19
” EP EP ” ” 32.80 7.84 56.47 41.15
” UN S¯E-EP 89 0.21 23.52 6.64 63.86 47.68
” S¯E-EP S¯E-EP ” ” 23.68 6.65 63.64 47.56
” ¯SE-EP EP 74 0.15 28.10 7.18 60.86 44.85
” Google na na 28.60 7.55 57.38 57.38
” Euromatrix na na 32.99 7.86 56.36 41.12
English-Spanish UN UN 281 1.39 23.24 6.44 65.81 49.61
</table>
<tableCaption confidence="0.983461666666667">
Table 2: Description and performance on the test set of compared systems in terms of perplexity, out-of-
vocabulary percentage of their language model, and four translation scores: BLEU, NIST, word-error-
rate, and position-independent error rate. Systems were optimized on the dev2006 development set.
</tableCaption>
<figure confidence="0.998497076923077">
5 10 15 20 25 30 35
iteration
5 10 15 20 25 30 35
iteration
time (minutes)
2500
2000
1500
1000
500
0
a) large dev, 1000 best
b) large dev, 200 best
c) small dev, 1000 best
d) small dev, 200 best
BLEU (%)
24
23
22
21
20
19
a) large dev, 1000 best
b) large dev, 200 best
c) small dev, 1000 best
d) small dev, 200 best
</figure>
<figureCaption confidence="0.780093">
Figure 1: Incremental time of the tuning process (not including decoding phase) (left) and BLEU score on
the test set using weights produced at each iteration of the tuning process. Four different configurations
of the tuning parameters are considered.
</figureCaption>
<bodyText confidence="0.999351425">
tences. Moreover, we tried to employ either 1,000-
best or 200-best translation candidates during the
mert process.
From a theoretical point of view, computational
effort of the tuning process is proportional to the
square of the number of translation alternatives
generated at each iteration times the number of it-
erations until convergence.
Figure 1 reports incremental tuning time and
translation performance on the test set at each it-
eration. Notice that the four tuning configurations
are ranked in order of complexity. Table 3 sum-
maries the final performance of each tuning pro-
cess, after convergence was reached.
Notice that decoding time is not included in this
plot, as Moses allows to perform this step in par-
allel on a computer cluster. Hence, to our view
the real bottleneck of the tuning process is actu-
ally related to the strictly serial part of the mert
implementation of Moses.
As already observed in previous literature
(Macherey et al., 2008), first iterations of the tun-
ing process produces very bad weights (even close
to 0); this exceptional performance drop is at-
tributed to an over-fitting on the candidate reposi-
tory.
Configurations exploiting the small develop-
ment set (c,d) show a slower and more unstable
convergence; however, their final performance in
Table 3 result only slightly lower than that ob-
tained with the standard dev sets (a, b). Due to the
larger number of iterations they needed, both con-
figurations are indeed more time consuming than
the intermediate configuration (b), which seems
the best one. In conclusion, we found that the size
of the n-best list has essentially no effect on the
quality of the final weights, but it impacts signif-
icantly on the computational time. Moreover, us-
ing the regular development set with few transla-
tion alternatives ends up to be the most efficient
</bodyText>
<page confidence="0.995577">
187
</page>
<bodyText confidence="0.9990955">
configuration in terms of computational effort, ro-
bustness, and performance.
Our analysis suggests that it is important to dis-
pose of a sufficiently large development set al-
though reasonably good weights can be obtained
even if such data are very few.
</bodyText>
<subsectionHeader confidence="0.988373">
5.4 LM adaptation
</subsectionHeader>
<bodyText confidence="0.9202405">
A set of experiments was devoted to the adapta-
tion of the LM only. We trained three different
LMs on increasing portions of the EP and we em-
ployed them either alone or in combination with
the background LM trained on the UN corpus.
Percentage of monolingual English adaptation data
</bodyText>
<figureCaption confidence="0.945613">
Figure 2: BLEU scores achieved by systems ex-
ploiting one or two LMs trained on increasing per-
centages of English in-domain data.
Figure 2 reports BLEU score achieved by these
</figureCaption>
<bodyText confidence="0.991321604651163">
systems. The absolute gain with respect to the
baseline is fairly high, even with the smallest
amount of adaptation data (+4.02). The benefit
of using the background data together with in-
domain data is very small, and rapidly vanishes
as the amount of such data increases.
If English synthetic texts are employed to adapt
the LM component, the increase in performance
is significantly lower but still remarkable (see Ta-
ble 2). By employing all the available data, the
gain in BLEU% score was of 4% relative, that is
from 22.60 to 23.52.
opment set as usual. Results of these experiments
are reported in Figure 3.
Results suggest that regardless of the used bilin-
gual corpora the in-domain TMs and RMs work
better alone than combined with the original mod-
els. We think that this behavior can be explained
by a limited disciminative power of the result-
ing combined model. The background translation
model could contain phrases which either do or
do not fit the adaptation domain. As the weights
are optimized to balance the contribution of all
phrases, the system is not able to well separate the
positive examples from the negative ones. In ad-
dition to it, system tuning is much more complex
because the number of features increases from 14
to 26.
Finally, TMs and RMs estimated from synthetic
data show to provide smaller, but consistent, con-
tributions than the corresponding LMs. When En-
glish in-domain data is provided, BLEU% score
increases from 22.60 to 28.10; TM and RM con-
tribute by about 5% relative, by covering the gap
from 27.83 to 28.10. When Spanish in-domain
data is provided BLEU% score increases from
22.60 to 23.68; TM and RM contribute by about
15% relative, by covering the gap from 23.52 to
23.68 .
Summarizing, the most important role in the do-
main adaptation is played by the LM; nevertheless
the adaptation of the TM and RM gives a small
further improvement..
</bodyText>
<figure confidence="0.983980689655172">
BLEU (%)
28
26
24
22
20
30
1 LM
2 LMs (+UN)
0
25
50
100
BLEU (%)
28
26
24
22
20
34
32
30
1 TM, RM, LM
2 TMs, RMs, LMs (+UN)
nothing
Spanish
English
bilingual
Type of adaptation data
</figure>
<subsectionHeader confidence="0.877477">
5.5 TM and RM adaptation
</subsectionHeader>
<bodyText confidence="0.9999431">
Another set of experiments relates to the adapta-
tion of the TM and the RM. In-domain TMs and
RMs were estimated on three different versions of
the full parallel EP corpus, namely EP, S¯E-EP, and
¯SE-EP. In-domain LMs were trained on the cor-
responding English side. All in-domain models
were either used alone or combined with the base-
line models according to multiple-model paradigm
explained in Section 4.3. Tuning of the interpola-
tion weights was performed on the standard devel-
</bodyText>
<figureCaption confidence="0.628583666666667">
Figure 3: BLEU scores achieved by system ex-
ploiting both TM, RM and LM trained on different
corpora.
</figureCaption>
<sectionHeader confidence="0.999037" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999765">
This paper investigated cross-domain adaptation
of a state-of-the-art SMT system (Moses), by ex-
ploiting large but cheap monolingual data. We
proposed to generate synthetic parallel data by
</bodyText>
<page confidence="0.995635">
188
</page>
<bodyText confidence="0.99993165">
translating monolingual adaptation data with a
background system and to train statistical models
from the synthetic corpus.
We found that the largest gain (25% relative) is
achieved when in-domain data are available for the
target language. A smaller performance improve-
ment is still observed (5% relative) if source adap-
tation data are available. We also observed that the
most important role is played by the LM adapta-
tion, while the adaptation of the TM and RM gives
consistent but small improvement.
We also showed that a very tiny development set
of only 200 parallel sentences is adequate enough
to get comparable performance as a 2000-sentence
set.
Finally, we described how to reduce the time
for training models from a synthetic corpus gen-
erated through Moses by 50% at least, by exploit-
ing word-alignment information provided during
decoding.
</bodyText>
<sectionHeader confidence="0.999109" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999937459770115">
Peter F. Brown, Stephen A. Della Pietra, Vincent J.
Della Pietra, and Robert L. Mercer. 1993. The
mathematics of statistical machine translation: Pa-
rameter estimation. Computational Linguistics,
19(2):263–312.
Jorge Civera and Alfons Juan. 2007. Domain adap-
tation in statistical machine translation with mixture
modelling. In Proceedings of the Second Workshop
on Statistical Machine Translation, pages 177–180,
Prague, Czech Republic.
Matthias Eck, Stephan Vogel, and Alex Waibel. 2004.
Language model adaptation for statistical machine
translation based on information retrieval. In Pro-
ceedings of the International Conference on Lan-
guage Resources and Evaluation (LREC), pages
327–330, Lisbon, Portugal.
Marcello Federico and Renato De Mori. 1998. Lan-
guage modelling. In Renato De Mori, editor, Spoken
Dialogues with Computers, chapter 7, pages 199–
230. Academy Press, London, UK.
Marcello Federico, Nicola Bertoldi, and Mauro Cet-
tolo. 2008. Irstlm: an open source toolkit for han-
dling large scale language models. In Proceedings
of Interspeech, pages 1618–1621, Melbourne, Aus-
tralia.
Andrew Finch and Eiichiro Sumita. 2008. Dy-
namic model interpolation for statistical machine
translation. In Proceedings of the Third Workshop
on Statistical Machine Translation, pages 208–215,
Columbus, Ohio.
George Foster and Roland Kuhn. 2007. Mixture-
model adaptation for SMT. In Proceedings of the
Second Workshop on Statistical Machine Transla-
tion, pages 128–135, Prague, Czech Republic.
Almut Silja Hildebrand, Matthias Eck, Stephan Vo-
gel, and Alex Waibel. 2005. Adaptation of the
translation model for statistical machine translation
based on information retrieval. In Proceedings of
the 10th Conference of the European Association for
Machine Translation (EAMT), pages 133–142, Bu-
dapest.
Philipp Koehn and Josh Schroeder. 2007. Experi-
ments in domain adaptation for statistical machine
translation. In Proceedings of the Second Workshop
on Statistical Machine Translation, pages 224–227,
Prague, Czech Republic.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open source toolkit
for statistical machine translation. In Proceedings of
the 45th Annual Meeting of the Association for Com-
putational Linguistics Companion Volume Proceed-
ings of the Demo and Poster Sessions, pages 177–
180, Prague, Czech Republic.
Philipp Koehn. 2002. Europarl: A multilingual corpus
for evaluation of machine translation. Unpublished,
http://www.isi.edu/∼koehn/europarl/.
Wolfgang Macherey, Franz Och, Ignacio Thayer, and
Jakob Uszkoreit. 2008. Lattice-based minimum er-
ror rate training for statistical machine translation.
In Proceedings of the 2008 Conference on Empiri-
cal Methods in Natural Language Processing, pages
725–734, Honolulu, Hawaii.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19–51.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings
of the 40th Annual Meeting of the Association of
Computational Linguistics (ACL), pages 311–318,
Philadelphia, PA.
Holger Schwenk. 2008. Investigations on Large-Scale
Lightly-Supervised Training for Statistical Machine
Translation. In Proc. of the International Workshop
on Spoken Language Translation, pages 182–189,
Hawaii, USA.
Nicola Ueffing, Gholamreza Haffari, and Anoop
Sarkar. 2007. Semi-supervised model adaptation
for statistical machine translation. Machine Trans-
lation, 21(2):77–94.
Bing Zhao, Matthias Eck, and Stephan Vogel. 2004.
Language model adaptation for statistical machine
translation via structured query models. In Pro-
ceedings of Coling 2004, pages 411–417, Geneva,
Switzerland.
</reference>
<page confidence="0.998927">
189
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.296063">
<title confidence="0.99933">Domain Adaptation for Statistical Machine with Monolingual Resources</title>
<author confidence="0.667801666666667">Ricerca Scientifica e Via Sommarive</author>
<abstract confidence="0.99388324137931">Domain adaptation has recently gained interest in statistical machine translation to cope with the performance drop observed when testing conditions deviate from training conditions. The basic idea is that in-domain training data can be exploited to adapt all components of an already developed system. Previous work showed small performance gains by adapting from limited in-domain bilingual data. Here, we aim instead at significant performance gains by exploiting large but cheap monolingual in-domain data, either in the source or in the target language. We propose to synthesize a bilingual corpus by translating the monolingual adaptation data into the counterpart language. Investigations were conducted on a stateof-the-art phrase-based system trained on the Spanish–English part of the UN corpus, and adapted on the corresponding Europarl data. Translation, re-ordering, and language models were estimated after translating in-domain texts with the baseline. By optimizing the interpolation of these models on a development set the BLEU score was improved from 22.60% to 28.10% on a test set.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="15639" citStr="Brown et al., 1993" startWordPosition="2502" endWordPosition="2505">atures of all single TMs; but for a phrase pair (�f, E) belonging to SU \Sj, the feature values h(�f, E; Sj) are undefined. In these undefined situations, Moses provides a default value of 0, which is the highest available score, as the feature values come from probabilistic distributions and are expressed as logarithms. Henceforth, a phrase pair belonging to all original sets is penalized with respect to phrase pairs belonging to few of them only. To address this drawback, we proposed a new method3 to compute a more reliable and smoothed score in the undefined case, based on the IBM model 1 (Brown et al., 1993). If ( f� = f1, ... , fl, e� = e1, ... , el) E SU \ Sj for any j the 3Authors are not aware of any work addressing this issue. 5.1 Data Description In this work, the background domain is given by the Spanish-English portion of the UN parallel corpus,4 composed by documents coming from the Office of Conference Services at the UN in New York spanning the period between 1988 and 1993. The adaptation data come from the European Parliament corpus (Koehn, 2002) (EP) as provided for the shared translation task of the 2008 Workshop on Statistical Machine Translation.5 Development and test sets for thi</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorge Civera</author>
<author>Alfons Juan</author>
</authors>
<title>Domain adaptation in statistical machine translation with mixture modelling.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>177--180</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="5678" citStr="Civera and Juan, 2007" startWordPosition="857" endWordPosition="860">tences. Both the language and the translation models are retrained on the extracted data. In (Foster and Kuhn, 2007) two basic settings are investigated: cross-domain adaptation, in which a small sample of parallel in-domain text is assumed, and dynamic adaptation, in which only the current input source text is considered. Adaptation relies on mixture models estimated on the training data through some unsupervised clustering method. Given available adaptation data, mixture weights are re-estimated ad-hoc. A variation of this approach was also recently proposed in (Finch and Sumita, 2008). In (Civera and Juan, 2007) mixture models are instead employed to adapt a word alignment model to in-domain parallel data. In (Koehn and Schroeder, 2007) cross-domain adaptation techniques were applied on a phrasebased SMT trained on the Europarl task, in order to translate news commentaries, from French to English. In particular, a small portion of indomain bilingual data was exploited to adapt the Europarl language model and translation models by means of linear interpolation techniques. Ueffing et al. (2007) proposed several elaborate adaptation methods relying on additional bilingual data synthesized from the devel</context>
</contexts>
<marker>Civera, Juan, 2007</marker>
<rawString>Jorge Civera and Alfons Juan. 2007. Domain adaptation in statistical machine translation with mixture modelling. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 177–180, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias Eck</author>
<author>Stephan Vogel</author>
<author>Alex Waibel</author>
</authors>
<title>Language model adaptation for statistical machine translation based on information retrieval.</title>
<date>2004</date>
<booktitle>In Proceedings of the International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>327--330</pages>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="4589" citStr="Eck et al., 2004" startWordPosition="686" endWordPosition="689">s. Cross-domain adaptation is faced under the assumption that only monolingual texts are available, either in the source language or in the target language. The paper is organized as follows. Section 2 presents previous work on the problem of adaptation in SMT; Section 3 introduces the exemplar task and research questions we addressed; Section 4 describes the SMT system and the adaptation techniques that were investigated; Section 5 presents and discusses experimental results; and Section 6 provides conclusions. 2 Previous Work Domain adaptation in SMT has been investigated only recently. In (Eck et al., 2004) adaptation is limited to the target language model (LM). The background LM is combined with one estimated on documents retrieved from the WEB by using the input sentence as query and applying crosslanguage information retrieval techniques. Refinements of this approach are described in (Zhao et al., 2004). In (Hildebrand et al., 2005) information retrieval techniques are applied to retrieve sentence pairs from the training corpus that are relevant to the test sentences. Both the language and the translation models are retrained on the extracted data. In (Foster and Kuhn, 2007) two basic settin</context>
</contexts>
<marker>Eck, Vogel, Waibel, 2004</marker>
<rawString>Matthias Eck, Stephan Vogel, and Alex Waibel. 2004. Language model adaptation for statistical machine translation based on information retrieval. In Proceedings of the International Conference on Language Resources and Evaluation (LREC), pages 327–330, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcello Federico</author>
<author>Renato De Mori</author>
</authors>
<title>Language modelling.</title>
<date>1998</date>
<booktitle>Spoken Dialogues with Computers, chapter 7,</booktitle>
<pages>199--230</pages>
<editor>In Renato De Mori, editor,</editor>
<publisher>Academy Press,</publisher>
<location>London, UK.</location>
<marker>Federico, De Mori, 1998</marker>
<rawString>Marcello Federico and Renato De Mori. 1998. Language modelling. In Renato De Mori, editor, Spoken Dialogues with Computers, chapter 7, pages 199– 230. Academy Press, London, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Mauro Cettolo</author>
</authors>
<title>Irstlm: an open source toolkit for handling large scale language models.</title>
<date>2008</date>
<booktitle>In Proceedings of Interspeech,</booktitle>
<pages>1618--1621</pages>
<location>Melbourne, Australia.</location>
<contexts>
<context position="9555" citStr="Federico et al., 2008" startWordPosition="1471" endWordPosition="1474">on presented in this paper was carried out with the Moses toolkit (Koehn et al., 2007), a state-of-the-art open-source phrase-based SMT system. We trained Moses in a standard configuration, including a 4-feature translation model, a 7-feature lexicalized re-ordering model, one LM, word and phrase penalties. The translation and the re-ordering model relied on “grow-diag-final” symmetrized word-toword alignments built using GIZA++ (Och and Ney, 2003) and the training script of Moses. A 5-gram language model was trained on the target side of the training parallel corpus using the IRSTLM toolkit (Federico et al., 2008), exploiting Modified Kneser-Ney smoothing, and quantizing both probabilities and backoff weights. Decoding was performed applying cube-pruning with a poplimit of 6000 hypotheses. Log-linear interpolations of feature functions were estimated with the parallel version of minimum error rate training procedure distributed with Moses. 4.1 Fast Training from Synthetic Data The standard procedure of Moses for the estimation of the translation and re-ordering models from a bilingual corpus consists in three main steps: 1. A word-to-word alignment is generated with GIZA++. 2. Phrase pairs are extracte</context>
</contexts>
<marker>Federico, Bertoldi, Cettolo, 2008</marker>
<rawString>Marcello Federico, Nicola Bertoldi, and Mauro Cettolo. 2008. Irstlm: an open source toolkit for handling large scale language models. In Proceedings of Interspeech, pages 1618–1621, Melbourne, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Finch</author>
<author>Eiichiro Sumita</author>
</authors>
<title>Dynamic model interpolation for statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third Workshop on Statistical Machine Translation,</booktitle>
<pages>208--215</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="5650" citStr="Finch and Sumita, 2008" startWordPosition="852" endWordPosition="855"> are relevant to the test sentences. Both the language and the translation models are retrained on the extracted data. In (Foster and Kuhn, 2007) two basic settings are investigated: cross-domain adaptation, in which a small sample of parallel in-domain text is assumed, and dynamic adaptation, in which only the current input source text is considered. Adaptation relies on mixture models estimated on the training data through some unsupervised clustering method. Given available adaptation data, mixture weights are re-estimated ad-hoc. A variation of this approach was also recently proposed in (Finch and Sumita, 2008). In (Civera and Juan, 2007) mixture models are instead employed to adapt a word alignment model to in-domain parallel data. In (Koehn and Schroeder, 2007) cross-domain adaptation techniques were applied on a phrasebased SMT trained on the Europarl task, in order to translate news commentaries, from French to English. In particular, a small portion of indomain bilingual data was exploited to adapt the Europarl language model and translation models by means of linear interpolation techniques. Ueffing et al. (2007) proposed several elaborate adaptation methods relying on additional bilingual dat</context>
</contexts>
<marker>Finch, Sumita, 2008</marker>
<rawString>Andrew Finch and Eiichiro Sumita. 2008. Dynamic model interpolation for statistical machine translation. In Proceedings of the Third Workshop on Statistical Machine Translation, pages 208–215, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Foster</author>
<author>Roland Kuhn</author>
</authors>
<title>Mixturemodel adaptation for SMT.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>128--135</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="5172" citStr="Foster and Kuhn, 2007" startWordPosition="778" endWordPosition="781">ed only recently. In (Eck et al., 2004) adaptation is limited to the target language model (LM). The background LM is combined with one estimated on documents retrieved from the WEB by using the input sentence as query and applying crosslanguage information retrieval techniques. Refinements of this approach are described in (Zhao et al., 2004). In (Hildebrand et al., 2005) information retrieval techniques are applied to retrieve sentence pairs from the training corpus that are relevant to the test sentences. Both the language and the translation models are retrained on the extracted data. In (Foster and Kuhn, 2007) two basic settings are investigated: cross-domain adaptation, in which a small sample of parallel in-domain text is assumed, and dynamic adaptation, in which only the current input source text is considered. Adaptation relies on mixture models estimated on the training data through some unsupervised clustering method. Given available adaptation data, mixture weights are re-estimated ad-hoc. A variation of this approach was also recently proposed in (Finch and Sumita, 2008). In (Civera and Juan, 2007) mixture models are instead employed to adapt a word alignment model to in-domain parallel dat</context>
</contexts>
<marker>Foster, Kuhn, 2007</marker>
<rawString>George Foster and Roland Kuhn. 2007. Mixturemodel adaptation for SMT. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 128–135, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Almut Silja Hildebrand</author>
<author>Matthias Eck</author>
<author>Stephan Vogel</author>
<author>Alex Waibel</author>
</authors>
<title>Adaptation of the translation model for statistical machine translation based on information retrieval.</title>
<date>2005</date>
<booktitle>In Proceedings of the 10th Conference of the European Association for Machine Translation (EAMT),</booktitle>
<pages>133--142</pages>
<location>Budapest.</location>
<contexts>
<context position="4925" citStr="Hildebrand et al., 2005" startWordPosition="740" endWordPosition="743">dressed; Section 4 describes the SMT system and the adaptation techniques that were investigated; Section 5 presents and discusses experimental results; and Section 6 provides conclusions. 2 Previous Work Domain adaptation in SMT has been investigated only recently. In (Eck et al., 2004) adaptation is limited to the target language model (LM). The background LM is combined with one estimated on documents retrieved from the WEB by using the input sentence as query and applying crosslanguage information retrieval techniques. Refinements of this approach are described in (Zhao et al., 2004). In (Hildebrand et al., 2005) information retrieval techniques are applied to retrieve sentence pairs from the training corpus that are relevant to the test sentences. Both the language and the translation models are retrained on the extracted data. In (Foster and Kuhn, 2007) two basic settings are investigated: cross-domain adaptation, in which a small sample of parallel in-domain text is assumed, and dynamic adaptation, in which only the current input source text is considered. Adaptation relies on mixture models estimated on the training data through some unsupervised clustering method. Given available adaptation data,</context>
</contexts>
<marker>Hildebrand, Eck, Vogel, Waibel, 2005</marker>
<rawString>Almut Silja Hildebrand, Matthias Eck, Stephan Vogel, and Alex Waibel. 2005. Adaptation of the translation model for statistical machine translation based on information retrieval. In Proceedings of the 10th Conference of the European Association for Machine Translation (EAMT), pages 133–142, Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Josh Schroeder</author>
</authors>
<title>Experiments in domain adaptation for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>224--227</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="5805" citStr="Koehn and Schroeder, 2007" startWordPosition="878" endWordPosition="881">sic settings are investigated: cross-domain adaptation, in which a small sample of parallel in-domain text is assumed, and dynamic adaptation, in which only the current input source text is considered. Adaptation relies on mixture models estimated on the training data through some unsupervised clustering method. Given available adaptation data, mixture weights are re-estimated ad-hoc. A variation of this approach was also recently proposed in (Finch and Sumita, 2008). In (Civera and Juan, 2007) mixture models are instead employed to adapt a word alignment model to in-domain parallel data. In (Koehn and Schroeder, 2007) cross-domain adaptation techniques were applied on a phrasebased SMT trained on the Europarl task, in order to translate news commentaries, from French to English. In particular, a small portion of indomain bilingual data was exploited to adapt the Europarl language model and translation models by means of linear interpolation techniques. Ueffing et al. (2007) proposed several elaborate adaptation methods relying on additional bilingual data synthesized from the development or test set. Our work is mostly related to (Koehn and Schroeder, 2007) but explores different assumptions about availabl</context>
</contexts>
<marker>Koehn, Schroeder, 2007</marker>
<rawString>Philipp Koehn and Josh Schroeder. 2007. Experiments in domain adaptation for statistical machine translation. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 224–227, Prague, Czech Republic.</rawString>
</citation>
<citation valid="false">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
<author>C Dyer</author>
<author>O Bojar</author>
<author>A Constantin</author>
<author>E Herbst</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,</booktitle>
<pages>177--180</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="9019" citStr="Koehn et al., 2007" startWordPosition="1390" endWordPosition="1393">ability of a development set and an evaluation set. 183 summarize our basic interest in this work: • Is automatic generation of bilingual data effective to tackle the lack of parallel data? • Is it more effective to use source language adaptation data or target language adaptation data? • Is it convenient to combine models learned from adaptation data with models learned from training data? • How can interpolation of models be effectively learned from small amounts of indomain parallel data? 4 System description The investigation presented in this paper was carried out with the Moses toolkit (Koehn et al., 2007), a state-of-the-art open-source phrase-based SMT system. We trained Moses in a standard configuration, including a 4-feature translation model, a 7-feature lexicalized re-ordering model, one LM, word and phrase penalties. The translation and the re-ordering model relied on “grow-diag-final” symmetrized word-toword alignments built using GIZA++ (Och and Ney, 2003) and the training script of Moses. A 5-gram language model was trained on the target side of the training parallel corpus using the IRSTLM toolkit (Federico et al., 2008), exploiting Modified Kneser-Ney smoothing, and quantizing both </context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin, and E. Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 177– 180, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A multilingual corpus for evaluation of machine translation.</title>
<date>2002</date>
<note>Unpublished, http://www.isi.edu/∼koehn/europarl/.</note>
<contexts>
<context position="16098" citStr="Koehn, 2002" startWordPosition="2591" endWordPosition="2592">is drawback, we proposed a new method3 to compute a more reliable and smoothed score in the undefined case, based on the IBM model 1 (Brown et al., 1993). If ( f� = f1, ... , fl, e� = e1, ... , el) E SU \ Sj for any j the 3Authors are not aware of any work addressing this issue. 5.1 Data Description In this work, the background domain is given by the Spanish-English portion of the UN parallel corpus,4 composed by documents coming from the Office of Conference Services at the UN in New York spanning the period between 1988 and 1993. The adaptation data come from the European Parliament corpus (Koehn, 2002) (EP) as provided for the shared translation task of the 2008 Workshop on Statistical Machine Translation.5 Development and test sets for this task, namely dev2006 and test2008, are supplied as well, and belong to the European Parliament domain. We use the symbol S¯ (¯E) to denote synthetic Spanish (English) data. Spanish-to-English and English-to-Spanish systems trained on UN data were exploited to generate English and Spanish synthetic portions of the original EP corpus, respectively. In this way, we created two synthetic versions of the EP corpus, named S¯E-EP and ¯SEEP, respectively. All p</context>
</contexts>
<marker>Koehn, 2002</marker>
<rawString>Philipp Koehn. 2002. Europarl: A multilingual corpus for evaluation of machine translation. Unpublished, http://www.isi.edu/∼koehn/europarl/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Macherey</author>
<author>Franz Och</author>
<author>Ignacio Thayer</author>
<author>Jakob Uszkoreit</author>
</authors>
<title>Lattice-based minimum error rate training for statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>725--734</pages>
<location>Honolulu, Hawaii.</location>
<contexts>
<context position="23287" citStr="Macherey et al., 2008" startWordPosition="3803" endWordPosition="3806">nce. Figure 1 reports incremental tuning time and translation performance on the test set at each iteration. Notice that the four tuning configurations are ranked in order of complexity. Table 3 summaries the final performance of each tuning process, after convergence was reached. Notice that decoding time is not included in this plot, as Moses allows to perform this step in parallel on a computer cluster. Hence, to our view the real bottleneck of the tuning process is actually related to the strictly serial part of the mert implementation of Moses. As already observed in previous literature (Macherey et al., 2008), first iterations of the tuning process produces very bad weights (even close to 0); this exceptional performance drop is attributed to an over-fitting on the candidate repository. Configurations exploiting the small development set (c,d) show a slower and more unstable convergence; however, their final performance in Table 3 result only slightly lower than that obtained with the standard dev sets (a, b). Due to the larger number of iterations they needed, both configurations are indeed more time consuming than the intermediate configuration (b), which seems the best one. In conclusion, we fo</context>
</contexts>
<marker>Macherey, Och, Thayer, Uszkoreit, 2008</marker>
<rawString>Wolfgang Macherey, Franz Och, Ignacio Thayer, and Jakob Uszkoreit. 2008. Lattice-based minimum error rate training for statistical machine translation. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 725–734, Honolulu, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="9385" citStr="Och and Ney, 2003" startWordPosition="1441" endWordPosition="1444">earned from training data? • How can interpolation of models be effectively learned from small amounts of indomain parallel data? 4 System description The investigation presented in this paper was carried out with the Moses toolkit (Koehn et al., 2007), a state-of-the-art open-source phrase-based SMT system. We trained Moses in a standard configuration, including a 4-feature translation model, a 7-feature lexicalized re-ordering model, one LM, word and phrase penalties. The translation and the re-ordering model relied on “grow-diag-final” symmetrized word-toword alignments built using GIZA++ (Och and Ney, 2003) and the training script of Moses. A 5-gram language model was trained on the target side of the training parallel corpus using the IRSTLM toolkit (Federico et al., 2008), exploiting Modified Kneser-Ney smoothing, and quantizing both probabilities and backoff weights. Decoding was performed applying cube-pruning with a poplimit of 6000 hypotheses. Log-linear interpolations of feature functions were estimated with the parallel version of minimum error rate training procedure distributed with Moses. 4.1 Fast Training from Synthetic Data The standard procedure of Moses for the estimation of the t</context>
<context position="19708" citStr="Och and Ney, 2003" startWordPosition="3179" endWordPosition="3182">nthetic ¯SE-EP corpus. Again, any in-domain data were exploited to train this sytem. Of course, this system cannot be compared with any other because of the different translation direction. In order to compare reported performance with the state-of-the-art, Table 2 also reports results of the best system published in the EuroMatrix project website6 and of the Google online translation engine.7 5.3 Analysis of the tuning process It is well-known that tuning the SMT system is fundamental to achieve good performance. The standard tuning procedure consists of a minimum error rate training (mert) (Och and Ney, 2003) which relies on the availability of a development data set. On the other hand, the most important assumption we make is that almost no parallel indomain data are available. conf sent n-best time (min) BLEU (A) – – – – 22.28 a 2000 1000 2034 23.68 (1.40) b 2000 200 391 23.67 (1.39) c 200 1000 866 23.13 (0.85) d 200 200 551 23.54 (1.26) Table 3: Global time, not including decoding, of the tuning process and BLEU score achieved on the test set by the uniform interpolation weights (first row), and by the optimal weights with different configurations of the tuning parameters. In a preliminary phas</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association of Computational Linguistics (ACL),</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="16918" citStr="Papineni et al., 2002" startWordPosition="2715" endWordPosition="2718">, and belong to the European Parliament domain. We use the symbol S¯ (¯E) to denote synthetic Spanish (English) data. Spanish-to-English and English-to-Spanish systems trained on UN data were exploited to generate English and Spanish synthetic portions of the original EP corpus, respectively. In this way, we created two synthetic versions of the EP corpus, named S¯E-EP and ¯SEEP, respectively. All presented translation systems were optimized on the dev2006 set with respect to 4Distributed by the Linguistic Data Consortium, catalogue # LDC94T4A. 5http://www.statmt.org/wmt08 185 the BLEU score (Papineni et al., 2002), and tested on test2008. (Notice that one reference translation is available for both sets.) Table 1 reports statistics of original and synthetic parallel corpora, as well of the employed development and evaluation data sets. All the texts were just tokenized and mixed case was kept. Hence, all systems were developed to produce case-sensitive translations. corpus sent Spanish English word dict word dict UN 2.5M 50.5M 253K 45.2M 224K EP 1.3M 36.4M 164K 35.0M 109K S¯E-EP 1.3M 36.4M 164K 35.4M 133K ¯SE-EP 1.3M 36.2M 120K 35.0M 109K dev 2,000 60,438 8,173 58,653 6,548 test 2,000 61,756 8,331 60,0</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association of Computational Linguistics (ACL), pages 311–318, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Holger Schwenk</author>
</authors>
<title>Investigations on Large-Scale Lightly-Supervised Training for Statistical Machine Translation.</title>
<date>2008</date>
<booktitle>In Proc. of the International Workshop on Spoken Language Translation,</booktitle>
<pages>182--189</pages>
<location>Hawaii, USA.</location>
<contexts>
<context position="6655" citStr="Schwenk, 2008" startWordPosition="1008" endWordPosition="1009"> to adapt the Europarl language model and translation models by means of linear interpolation techniques. Ueffing et al. (2007) proposed several elaborate adaptation methods relying on additional bilingual data synthesized from the development or test set. Our work is mostly related to (Koehn and Schroeder, 2007) but explores different assumptions about available adaptation data: i.e. only monolingual in-domain texts are available. The adaptation of the translation and re-ordering models is performed by generating synthetic bilingual data from monolingual texts, similarly to what proposed in (Schwenk, 2008). Interpolation of multiple phrase tables is applied in a more principled way than in (Koehn and Schroeder, 2007): all entries are merged into one single table, corresponding feature functions are concatenated and smoothing is applied when observations are missing. The approach proposed in this paper has many similarities with the simplest technique in (Ueffing et al., 2007), but it is applied to a much larger monolingual corpus. Finally, with respect to previous work we also investigate the behavior of the minimum error training procedure to optimize the combination of feature functions on a </context>
</contexts>
<marker>Schwenk, 2008</marker>
<rawString>Holger Schwenk. 2008. Investigations on Large-Scale Lightly-Supervised Training for Statistical Machine Translation. In Proc. of the International Workshop on Spoken Language Translation, pages 182–189, Hawaii, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Ueffing</author>
<author>Gholamreza Haffari</author>
<author>Anoop Sarkar</author>
</authors>
<title>Semi-supervised model adaptation for statistical machine translation.</title>
<date>2007</date>
<journal>Machine Translation,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="6168" citStr="Ueffing et al. (2007)" startWordPosition="935" endWordPosition="939">e-estimated ad-hoc. A variation of this approach was also recently proposed in (Finch and Sumita, 2008). In (Civera and Juan, 2007) mixture models are instead employed to adapt a word alignment model to in-domain parallel data. In (Koehn and Schroeder, 2007) cross-domain adaptation techniques were applied on a phrasebased SMT trained on the Europarl task, in order to translate news commentaries, from French to English. In particular, a small portion of indomain bilingual data was exploited to adapt the Europarl language model and translation models by means of linear interpolation techniques. Ueffing et al. (2007) proposed several elaborate adaptation methods relying on additional bilingual data synthesized from the development or test set. Our work is mostly related to (Koehn and Schroeder, 2007) but explores different assumptions about available adaptation data: i.e. only monolingual in-domain texts are available. The adaptation of the translation and re-ordering models is performed by generating synthetic bilingual data from monolingual texts, similarly to what proposed in (Schwenk, 2008). Interpolation of multiple phrase tables is applied in a more principled way than in (Koehn and Schroeder, 2007)</context>
</contexts>
<marker>Ueffing, Haffari, Sarkar, 2007</marker>
<rawString>Nicola Ueffing, Gholamreza Haffari, and Anoop Sarkar. 2007. Semi-supervised model adaptation for statistical machine translation. Machine Translation, 21(2):77–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Zhao</author>
<author>Matthias Eck</author>
<author>Stephan Vogel</author>
</authors>
<title>Language model adaptation for statistical machine translation via structured query models.</title>
<date>2004</date>
<booktitle>In Proceedings of Coling</booktitle>
<pages>411--417</pages>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="4895" citStr="Zhao et al., 2004" startWordPosition="735" endWordPosition="738">research questions we addressed; Section 4 describes the SMT system and the adaptation techniques that were investigated; Section 5 presents and discusses experimental results; and Section 6 provides conclusions. 2 Previous Work Domain adaptation in SMT has been investigated only recently. In (Eck et al., 2004) adaptation is limited to the target language model (LM). The background LM is combined with one estimated on documents retrieved from the WEB by using the input sentence as query and applying crosslanguage information retrieval techniques. Refinements of this approach are described in (Zhao et al., 2004). In (Hildebrand et al., 2005) information retrieval techniques are applied to retrieve sentence pairs from the training corpus that are relevant to the test sentences. Both the language and the translation models are retrained on the extracted data. In (Foster and Kuhn, 2007) two basic settings are investigated: cross-domain adaptation, in which a small sample of parallel in-domain text is assumed, and dynamic adaptation, in which only the current input source text is considered. Adaptation relies on mixture models estimated on the training data through some unsupervised clustering method. Gi</context>
</contexts>
<marker>Zhao, Eck, Vogel, 2004</marker>
<rawString>Bing Zhao, Matthias Eck, and Stephan Vogel. 2004. Language model adaptation for statistical machine translation via structured query models. In Proceedings of Coling 2004, pages 411–417, Geneva, Switzerland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>