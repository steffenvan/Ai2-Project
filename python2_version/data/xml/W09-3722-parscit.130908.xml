<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012521">
<title confidence="0.994323333333333">
A Multiclassifier based Approach for Word Sense
Disambiguation using Singular Value
Decomposition
</title>
<author confidence="0.986618">
Ana Zelaia, Olatz Arregi and Basilio Sierra
</author>
<affiliation confidence="0.9899105">
Computer Science Faculty
University of the Basque Country
</affiliation>
<email confidence="0.992216">
ana.zelaia@ehu.es
</email>
<sectionHeader confidence="0.967132" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998743466666667">
In this paper a multiclassifier based approach is presented for a
word sense disambiguation (WSD) problem. A vector representation
is used for training and testing cases and the Singular Value Decom-
position (SVD) technique is applied to reduce the dimension of the
representation. The approach we present consists in creating a set of
k-NN classifiers and combining the predictions generated in order to
give a final word sense prediction for each case to be classified. The
combination is done by applying a Bayesian voting scheme. The ap-
proach has been applied to a database of 100 words made available by
the lexical sample WSD subtask of SemEval-2007 (task 17) organizers.
Each of the words was considered an independent classification prob-
lem. A methodological parameter tuning phase was applied in order to
optimize parameter setting for each word. Results achieved are among
the best and make the approach encouraging to apply to other WSD
tasks.
</bodyText>
<sectionHeader confidence="0.997321" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999492333333333">
Word sense disambiguation (WSD) is the problem of determining which
sense of a word is used when a word appears in a particular context. In
fact, WSD is an important component in many information organization
tasks, and fundamentally consists in a classification problem: given some
word-contexts corresponding to some possible senses, the WSD system has
to classify an occurrence of the word into one of its possible senses.
</bodyText>
<page confidence="0.962443">
248
</page>
<bodyText confidence="0.967202107142857">
Proceedings of the 8th International Conference on Computational Semantics, pages 248–259,
Tilburg, January 2009. c�2009 International Conference on Computational Semantics
In the approach presented in this paper, a vector representation is used
for training and testing word cases and the Singular Value Decomposition
of matrices is applied in order to reduce the dimension of the representa-
tion. In particular, Latent Semantic Indexing (LSI) [2] is used to make the
dimension reduction. This technique compresses vectors representing word
related contexts into vectors of a lower-dimensional space and has shown to
have the ability to extract the relations among features representing words
by means of their context of use.
We present a multiclassifier [8] based approach which uses different train-
ing databases. These databases are obtained from the original training
dataset by random subsampling. The implementation of this approach is
made by a model inspired in bagging [3], and the k-NN classification algo-
rithm [4] is used to make sense predictions for testing words.
For experimentation, a previous tuning phase was performed to training
data in order to automatically set some system parameters to their optimal
values. Four are the parameters to be optimized, and the combination of all
of them gives the possibility to perform the complete disambiguation process
by 1440 different ways for each of the 100 words to be disambiguated. The
tuning phase has been performed in a sound manner with the aim to improve
our previous work [10]. Although the computational payload is high, it is a
systematic way to fix the optimal values for parameters.
The aim of this article is to give a brief description of our approach to
deal with the WSD task and to show the results achieved. In Section 2,
our approach is presented. In Section 3, the experimental setup is intro-
duced. The experimental results are presented and discussed in Section 4,
and finally, Section 5 contains some conclusions and future work.
</bodyText>
<sectionHeader confidence="0.854935" genericHeader="method">
2 Proposed Approach
</sectionHeader>
<bodyText confidence="0.999699333333333">
In this section, our approach is presented and the techniques used are briefly
reviewed. First the dataset used in our experiments is described and previ-
ous results are presented. Next, the data preparation is explained in more
detail. A short introduction to the SVD theory and to the k-NN classifica-
tion algorithm is given afterwards. Finally, the multiclassifier construction
is shown.
</bodyText>
<page confidence="0.997181">
249
</page>
<subsectionHeader confidence="0.946762">
2.1 Dataset and previous results
</subsectionHeader>
<bodyText confidence="0.999994833333333">
The dataset we use in the experiments was obtained from the 4th Interna-
tional Workshop on Semantic Evaluations (SemEval-2007) web page&apos;, task
17, subtask 1: Coarse-grained English Lexical Sample WSD. This task con-
sists of lexical sample style training and testing data for 100 lemmas (35
nouns and 65 verbs) of different degree of polysemy (ranging from 1 to 13)
and number of instances annotated (ranging from 19 instances in training
for the word grant to 2536 instances at share).
The average inter-annotator agreement for these lemmas is over 90%. In
[9] task organizers describe the results achieved by the participating systems.
They define a baseline for the task based on giving the most frequent sense
in training (F-score: 78.0%). The best system performance (89.1%) was
closely approaching the inter-annotator agreement but still below it.
</bodyText>
<subsectionHeader confidence="0.992036">
2.2 Data Preparation
</subsectionHeader>
<bodyText confidence="0.999915">
Once we downloaded the training and testing datasets, some features were
extracted and vector representations were constructed for each training and
testing case. The features were extracted by [1] and are local collocations
(bigrams and trigrams formed with lemmas, word-forms or PoS tags around
the target), syntactic dependencies (using relations like object, subject, noun
modifier, preposition and sibling) and Bag-of-words features. This way, the
original training and testing databases were converted to feature databases.
</bodyText>
<subsectionHeader confidence="0.996084">
2.3 The SVD technique using LSI
</subsectionHeader>
<bodyText confidence="0.999936833333333">
The SVD technique consists in factoring term-document matrix M into the
product of three matrices, M = UΣV T where Σ is a diagonal matrix of
singular values, and U and V are orthogonal matrices of singular vectors
(term and document vectors, respectively). Being k the number of singular
values in matrix Σ and selecting the p highest singular values p &lt; k, a
vector representation for the training and testing cases can be calculated in
the reduced dimensional vector space RP.
In our experiments we construct one feature-case matrix for each of the
100 words using the corresponding feature training dataset. Each of the
columns in this matrix gives a vector representation to each of the training
cases. As the number of training cases varies among different words, the
number of columns present in the matrices is different; consequently, the
</bodyText>
<footnote confidence="0.979997">
1http://nlp.cs.swarthmore.edu/semeval/tasks/task17/data.shtml
</footnote>
<page confidence="0.996446">
250
</page>
<bodyText confidence="0.996328">
number of singular values changes as well. Taking this in consideration,
we calculate the SVD of each matrix and obtain the reduced vector repre-
sentations for training and testing cases for different p values. In order to
calculate the SVD of the matrices, we use Latent Semantic Indexing (LSI)
2 [5], which has been successfully used for classification purposes [7],
</bodyText>
<subsectionHeader confidence="0.997496">
2.4 The k-NN classification algorithm
</subsectionHeader>
<bodyText confidence="0.999893272727272">
k-NN is a distance based classification approach. According to this ap-
proach, given an arbitrary testing case, the k-NN classifier ranks its nearest
neighbors among the training cases [4].
In the approach presented in this article, the training and testing cases
for each word are represented by vectors in each reduced dimensional vector
space. The nearest to a testing case are considered to be the vectors which
have the smallest angle with respect to it, and thus the highest cosine. That
is why the cosine is usually calculated to measure the similarity between
vectors. The word senses associated with the k top-ranking neighbors are
used to make a prediction for the testing case. Parameter k was optimized
for each word during tuning phase.
</bodyText>
<subsectionHeader confidence="0.998235">
2.5 The multiclassifier construction
</subsectionHeader>
<bodyText confidence="0.999983352941176">
The combination of multiple classifiers has been intensively studied with the
aim of improving the accuracy of individual components [8]. A widely used
technique to implement this approach is bagging [3], where a set of training
databases TDZ is generated by selecting n training cases drawn randomly
with replacement from the original training database TD of n cases. When
a set of n1 &lt; n training cases is chosen from the original training collection,
the bagging is said to be applied by random subsampling.
In our work, we construct a multiclassifier by applying random sub-
sampling for each word. As the number n of training cases is different for
each word, we optimize via tuning the parameter n1 for each multiclassifier
constructed. This way, we work with training databases TDZ of different
sizes. Moreover, the number of training databases TDZ to create for each
multiclassifier, is also optimized via tuning.
Once the multiclassifiers are constructed, and given a testing case q for a
word, the corresponding multiclassifier will make a word-sense label predic-
tion cz based on each one of the training databases TDZ. In order to calculate
these confidence values, word-sense predictions are made for training cases
</bodyText>
<footnote confidence="0.93963">
2http://lsi.research.telcordia.com, http://www.cs.utk.edu/∼lsi
</footnote>
<page confidence="0.99574">
251
</page>
<bodyText confidence="0.99999425">
and the accuracies obtained give the confidence values which indicate the
accuracy level that may be expected when a prediction is made for a testing
case based on each training database TDZ and word-sense cj to be predicted.
The way we combine such predictions is by applying Bayesian voting [6],
where a confidence value cvZ�j is calculated for each training database TDZ
and word-sense cj to be predicted. In testing phase, confidence values ob-
tained for the testing cases are summed by sense; the sense cj that gets the
highest value is finally proposed as a prediction for the testing case q. This
process is repeated for every testing case.
In Fig. 1 an illustration of the experiment performed for each one of the
100 words can be seen. First, vectors in the original Vector Space are pro-
jected to the reduced space using SVD; next, random subsampling is applied
to the training database TD to obtain different training databases TDZ; af-
terwards, the k-NN classifier is applied for each TDZ to make sense label
predictions; finally, Bayesian voting scheme is used to combine predictions,
and c will be the final sense label prediction for testing case q.
</bodyText>
<sectionHeader confidence="0.919133" genericHeader="method">
3 Experimental Setup. The tuning phase
</sectionHeader>
<bodyText confidence="0.996488333333333">
The experiments were carried out in two phases. First, a parameter tuning
phase was performed in order to set the following parameters to their optimal
values:
</bodyText>
<listItem confidence="0.967818">
• The dimension p of the reduced dimensional vector space R p to which
word-case vectors are projected for each word.
• The number of classifiers, training databases TDZ, to create for each
word.
• The number k of nearest neighbors to be considered by the k-NN
classifier for each word.
• The number nl of cases to select from the TD of each word in order
to create each one of the TDZ, that is, the size of each TDZ.
</listItem>
<bodyText confidence="0.996776333333333">
All the four parameters were adjusted independently for each word, be-
cause of the different characteristics of words with respect to the number of
training and testing cases present in the dataset and the number of word-
senses associated to each of them.
Validation and testing data subsets used in the tuning phase were ex-
tracted form the original training database TD for each word. Both subsets
</bodyText>
<page confidence="0.991897">
252
</page>
<figureCaption confidence="0.999961">
Figure 1: Proposed multiclassifier approach for WSD task
</figureCaption>
<bodyText confidence="0.999907625">
were constructed by random selection of cases, where 75% of the cases were
selected for the validation subset and the rest for the tuning purposed made
testing subset.
In the following the optimization of parameters is explained. Parameters
were optimized in the same order as presented in this subsection, that is,
the dimension reduction first, the number of classifiers second, the number k
of nearest neighbors third and the size of each TDi last. When the first pa-
rameter was being optimized, all possibilities for the other three parameters
</bodyText>
<table confidence="0.88334388">
100 words for WSD
work.v
affect.v allow.v . . .
Training Testing
ci: Sense given by
classifier i to case q
cvcii: Confidence Value
calculated by classifier
i for sense ci
c
c: word sense proposed (*) http://lsi.research.telcordia.com
for testing case q http://www.cs.utk.edu/~lsi
Singular Value Decomposition (SVD)
by Latent Semantic Indexing (LSI) (*)
Reduced Space: Rp
p: Singular Values, p m
Original Vector Space: Rm
m: Number of features
Original training and
testing databases
Cosine Similarity Measure
Features:
local collocations,
syntactic dependencies
and Bag of Words
</table>
<figure confidence="0.995760111111111">
i training databases (TDi)
generated by selecting n1
cases (n1&lt;n) randomly
Random Subsampling
k-NN k-NN k-NN
c1, cvc11 c2, cvc22 ci, cvcii
dn
d1
m features
dn11
q1
d1 d2 dn
f m
f m
d
d
dn
1
1
d2
d2 d3
features
d11
d21
d2
TD1 d22 q TD2n1TDi
. . .
. . .
SVD
Rp Rp Rp
dn12 d12 d1i d2i
d3
TD
Bayesian Voting
features
Testing
Rm case q Rm
Rp
q1
dn
. . .
m features
m features
q
q2
q2
Projection of
testing case q
. . .
. . .
q
m features
qn&apos;
qn&apos;
</figure>
<page confidence="0.998094">
253
</page>
<bodyText confidence="0.999974428571429">
were taken into account, and the optimization of the parameter was made
based on the average of the 10% best results. Once a parameter was fixed,
the same method was applied in order to optimize the rest of the parame-
ters. This optimization method implies that the experiment was performed
for all the combinations of the four parameters. This implies a high compu-
tational cost during the tuning phase. For testing phase, the experiments
are performed using the optimal values for parameters.
</bodyText>
<subsectionHeader confidence="0.981848">
3.1 The dimension p of R p
</subsectionHeader>
<bodyText confidence="0.998315941176471">
This is the first parameter we tuned. As it was previously mentioned in
Section 2.3, the dimension p of the reduced dimensional vector space R p to
which training and testing cases are projected varies for different words. The
reason for that is the difference in the number of cases present in the dataset
for each word. For words with a high number of cases, the dimension was
previously reduced to 500 (see [2]). Then, for every word we experimented
by keeping the number of dimensions in a proportion. This proportion is
given by parameter A. We analyze four proportions by setting parameter
A to: A = 0 keep all dimensions, A = 1 keep 2/3 of the dimensions, A = 2
keep half of the dimensions and A = 3 keep a third of the dimensions.
We calculated four different values for p. Training and testing cases were
represented in the four R p spaces and word-sense label predictions calculated
for all of them. All the possibilities were tried for the rest of the parameters
(detailed in the following subsections). For each value of A, we selected the
10% best results from the 1440 we have, calculated the average of them and
set parameter A to its optimal value for each word. The optimization of A
gives a final optimal value for parameter p for each word.
</bodyText>
<subsectionHeader confidence="0.999957">
3.2 The number of classifiers, TDi
</subsectionHeader>
<bodyText confidence="0.9999833">
The number of classifiers, or TDi to create for each word is also a parameter
that needs to be tuned. This is because the number of cases present for each
word is quite variable, and this fact may have some influence in the number
of TDi to construct. In our work, we experimented with 6 different val-
ues for parameter i = 3, 5,10, 20, 30, 40. We performed the disambiguation
process for each of them by considering the results for the optimal value
of parameter A, already optimized, and all the possible values for the rest
of the parameters for each word. We then selected the best 10% average
results achieved for each value of i, calculated the average, and based on
these average results set the optimal value for parameter i for each word.
</bodyText>
<page confidence="0.9944">
254
</page>
<subsectionHeader confidence="0.998451">
3.3 The number k of nearest neighbors for k-NN
</subsectionHeader>
<bodyText confidence="0.9999955">
At this stage of the tuning phase, and having already optimized the dimen-
sionality reduction and the number of classifiers to create for each word,
we take both optimal values and experiment with all possible values for the
rest of the parameters. We calculate the average for six different values of
k, k = 3, 5, 7, 9,11,13. We set the optimal value of k for each word based
on the maximum average obtained.
</bodyText>
<subsectionHeader confidence="0.996449">
3.4 The size of training databases TDi: parameter n1
</subsectionHeader>
<bodyText confidence="0.99981275">
As it was mentioned in Section 2.5, the parameter n1 will be optimized for
each word in order to create training databases TDi of different sizes. The
selection of different values for n1 was experimented for each word according
to the following equation:
</bodyText>
<equation confidence="0.820433">
(2 + ⌊tij ⌋), j = 1,... ,10
</equation>
<bodyText confidence="0.999959636363636">
where ti is the total number of training cases in the sense ci and s is the
total number of senses for the given word. By dividing ti by j, the number
of training-cases selected from each word-sense preserves the proportion of
cases per sense in the original one. However, it has to be taken into account
that some of the word-senses have a very low number of training-cases as-
signed to them. By summing 2, at least 2 training-cases will be selected
from each word-sense. In order to decide the optimal value for j, the clas-
sification experiment was carried out varying j from 1 to 10 for each word.
Given that parameters p, i and k are already set to their optimal values for
each word, we calculate results for the 10 possible values of j, and set it to
its optimal value.
</bodyText>
<sectionHeader confidence="0.99577" genericHeader="evaluation">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.999409428571429">
The experiment was conducted by considering the optimal values for param-
eters tuned. Original training and testing datasets were used for the final
experiment, and results achieved were compared to the ones made available
by task organizers [9].
Our system achieved an F-score of 85.65%, which compared to the base-
line defined (78.0%) is a very good result, although still below the best
published by task organizers (89.1%).
</bodyText>
<equation confidence="0.922376">
s
n1 =
i=1
</equation>
<page confidence="0.990656">
255
</page>
<bodyText confidence="0.998858625">
In [9] the performance of the top-8 systems on individual verbs and nouns
is shown; 73 of the 100 lemmas are included in a table in two separated
groups. Lemmas that have perfect or almost perfect accuracies have been
removed. In TABLE 1 the average results achieved by our system for the two
groups of lemmas are compared to the ones published in the cited paper. We
can observe that our system performs better than the average of the top-8
systems disambiguating nouns, but slightly worse for verbs. In the overall,
our system is very near to the average performance of the top-8 systems.
</bodyText>
<table confidence="0.99709975">
Top-8 Our system
Verbs 70.44 67.78
Nouns 79.86 82.96
Overall 74.32 74.02
</table>
<tableCaption confidence="0.99996">
Table 1: Average performance compared to the top-8 in [9]
</tableCaption>
<bodyText confidence="0.99692675">
We want to remark that our system uses only the official training and
testing data, without including background knowledge of any type. Some of
the top-8 systems used background knowledge in order to assist in resolving
ambiguities.
</bodyText>
<figure confidence="0.8821325">
0 0.5 1 1.5 2 2.5 3
A
</figure>
<figureCaption confidence="0.99972">
Figure 2: Average accuracy related to parameter A = 0, 1, 2,3
</figureCaption>
<bodyText confidence="0.999960166666667">
An analysis of the parameter optimization performed in the tuning phase
lead us to observe that there is a relation between the dimensionality reduc-
tion level applied by SVD and the accuracy achieved for a word disambigua-
tion (see Fig. 2). Words with more than 500 cases in the training dataset
were not depicted in the figure because an additional dimension reduction
was applied to them (see section 3.1). The graphic in Fig. 2 suggests that
</bodyText>
<figure confidence="0.977705">
Accuracy 0.84
0.82
0.8
0.78
0.76
0.74
0.72
0.7
256
n senses
50 100 150 200
0 1 2 3
λ
</figure>
<figureCaption confidence="0.999901">
Figure 3: Complexity related to parameter A = 0, 1, 2,3
</figureCaption>
<bodyText confidence="0.998160714285714">
a dimensionality reduction of half of the features, A = 2, is appropriate for
words where a high level of accuracy is reached.
In order to analyze the adequacy of the parameter tuning performed, we
created a new variable dividing the case number n of the training database
by the number of senses for each word. This calculus is meant to represent
the complexity of each word. In Fig. 3 the interquartile relationships found
among the parameter A and the complexity of the words is presented. For
each value of A the segments represent the minimum and the maximum value
of the complexity, while the bold line shows the median and the rectangular
area represents the density of the second and third quartiles. As it can be
seen, the evolution of the median value, as well as the minimum values, are
similar to the observed in the accuracies. This allows to say that the A value
was properly selected by the automatic selection used, and also that higher
values of A would not ensure better solutions for the most complex words.
</bodyText>
<sectionHeader confidence="0.996235" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.9991705">
The good results achieved by our system show that the construction of
multiclassifiers, together with the use of Bayesian voting to combine word-
</bodyText>
<page confidence="0.982635">
257
</page>
<bodyText confidence="0.999946928571429">
sense label predictions, plays an important role in disambiguation tasks.
The use of the SVD technique in order to reduce the vector representation
of cases has been proved to behave appropriately.
We also want to remark that, our disambiguation system has been adapted
to the task of disambiguating each one of the 100 words by applying a
methodological parameter tuning directed to find the optimal values for
each word. This makes possible to have a unique disambiguation system
applicable to words with very different characteristics.
Moreover, in our experiments we used only the training data supplied for
sense disambiguation in test set, with no inclusion of background knowledge
at all, while most of the top-8 systems participating in the task do use some
kind of background knowledge. As future work, we intend to make use of
such knowledge and hope that results will increase. We also intend to apply
this approach to other disambiguation tasks.
</bodyText>
<sectionHeader confidence="0.998531" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999774647058823">
[1] E. Agirre and O. Lopez de Lacalle. Ubc-alm: Combining k-nn with svd
for wsd. In Proceedings of the 4th International Workshop on Semantic
Evaluations, SemEval-2007, pages 342–345, 2007.
[2] M. Berry and M. Browne. Understanding Search Engines: Mathemati-
cal Modeling and Text Retrieval. SIAM Society for Industrial and Ap-
plied Mathematics, ISBN: 0-89871-437-0, Philadelphia, 1999.
[3] L. Breiman. Bagging predictors. Machine Learning, 24(2):123–140,
1996.
[4] B. Dasarathy. Nearest Neighbor (NN) Norms: NN Pattern Recognition
Classification Techniques. IEEE Computer Society Press, 1991.
[5] S. Deerwester, S. Dumais, G. Furnas, T. Landauer, and R. Harshman.
Indexing by latent semantic analysis. Journal of the American Society
for Information Science, 41:391–407, 1990.
[6] T. Dietterich. Machine learning research: Four current directions. The
AI Magazine, 18(4):97–136, 1998.
[7] S. Dumais. Latent semantic analysis. In ARIST (Annual Review of
Information Science Technology), volume 38, pages 189–230, 2004.
</reference>
<page confidence="0.963446">
258
</page>
<reference confidence="0.998899090909091">
[8] T. Ho, J. Hull, and S. Srihari. Decision combination in multiple clas-
sifier systems. IEEE Transactions on Pattern Analysis and Machine
Intelligence, 16(1):66–75, 1994.
[9] S. Pradhan, E. Loper, D. Dligach, and M. Palmer. Semeval-2007 task
17: English lexical sample, srl and all words. In A. for Computa-
tional Linguistics, editor, Proceedings of the 4th International Work-
shop on Semantic Evaluations, SemEval-2007, pages 87–92, 2007.
[10] A. Zelaia, O. Arregi, and B. Sierra. Ubc-zas: A k-nn based multiclas-
sifier system to perform wsd in a reduced dimensional vector space.
In Proceedings of the 4th International Workshop on Semantic Evalua-
tions, SemEval-2007, pages 358–361, 2007.
</reference>
<page confidence="0.998527">
259
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.756491">
<title confidence="0.998010333333333">A Multiclassifier based Approach for Word Sense Disambiguation using Singular Value Decomposition</title>
<author confidence="0.999951">Ana Zelaia</author>
<author confidence="0.999951">Olatz Arregi</author>
<author confidence="0.999951">Basilio Sierra</author>
<affiliation confidence="0.9856815">Computer Science Faculty University of the Basque Country</affiliation>
<email confidence="0.835569">ana.zelaia@ehu.es</email>
<abstract confidence="0.9957014375">In this paper a multiclassifier based approach is presented for a word sense disambiguation (WSD) problem. A vector representation is used for training and testing cases and the Singular Value Decomposition (SVD) technique is applied to reduce the dimension of the representation. The approach we present consists in creating a set of classifiers and combining the predictions generated in order to give a final word sense prediction for each case to be classified. The combination is done by applying a Bayesian voting scheme. The approach has been applied to a database of 100 words made available by the lexical sample WSD subtask of SemEval-2007 (task 17) organizers. Each of the words was considered an independent classification problem. A methodological parameter tuning phase was applied in order to optimize parameter setting for each word. Results achieved are among the best and make the approach encouraging to apply to other WSD tasks.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>O Lopez de Lacalle</author>
</authors>
<title>Ubc-alm: Combining k-nn with svd for wsd.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval-2007,</booktitle>
<pages>342--345</pages>
<contexts>
<context position="5156" citStr="[1]" startWordPosition="810" endWordPosition="810">tances at share). The average inter-annotator agreement for these lemmas is over 90%. In [9] task organizers describe the results achieved by the participating systems. They define a baseline for the task based on giving the most frequent sense in training (F-score: 78.0%). The best system performance (89.1%) was closely approaching the inter-annotator agreement but still below it. 2.2 Data Preparation Once we downloaded the training and testing datasets, some features were extracted and vector representations were constructed for each training and testing case. The features were extracted by [1] and are local collocations (bigrams and trigrams formed with lemmas, word-forms or PoS tags around the target), syntactic dependencies (using relations like object, subject, noun modifier, preposition and sibling) and Bag-of-words features. This way, the original training and testing databases were converted to feature databases. 2.3 The SVD technique using LSI The SVD technique consists in factoring term-document matrix M into the product of three matrices, M = UΣV T where Σ is a diagonal matrix of singular values, and U and V are orthogonal matrices of singular vectors (term and document ve</context>
</contexts>
<marker>[1]</marker>
<rawString>E. Agirre and O. Lopez de Lacalle. Ubc-alm: Combining k-nn with svd for wsd. In Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval-2007, pages 342–345, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Berry</author>
<author>M Browne</author>
</authors>
<title>Understanding Search Engines: Mathematical Modeling and Text Retrieval.</title>
<date>1999</date>
<journal>SIAM Society for Industrial and Applied Mathematics, ISBN:</journal>
<pages>0--89871</pages>
<location>Philadelphia,</location>
<contexts>
<context position="2073" citStr="[2]" startWordPosition="317" endWordPosition="317">ven some word-contexts corresponding to some possible senses, the WSD system has to classify an occurrence of the word into one of its possible senses. 248 Proceedings of the 8th International Conference on Computational Semantics, pages 248–259, Tilburg, January 2009. c�2009 International Conference on Computational Semantics In the approach presented in this paper, a vector representation is used for training and testing word cases and the Singular Value Decomposition of matrices is applied in order to reduce the dimension of the representation. In particular, Latent Semantic Indexing (LSI) [2] is used to make the dimension reduction. This technique compresses vectors representing word related contexts into vectors of a lower-dimensional space and has shown to have the ability to extract the relations among features representing words by means of their context of use. We present a multiclassifier [8] based approach which uses different training databases. These databases are obtained from the original training dataset by random subsampling. The implementation of this approach is made by a model inspired in bagging [3], and the k-NN classification algorithm [4] is used to make sense </context>
<context position="13660" citStr="[2]" startWordPosition="2227" endWordPosition="2227">ameters. This implies a high computational cost during the tuning phase. For testing phase, the experiments are performed using the optimal values for parameters. 3.1 The dimension p of R p This is the first parameter we tuned. As it was previously mentioned in Section 2.3, the dimension p of the reduced dimensional vector space R p to which training and testing cases are projected varies for different words. The reason for that is the difference in the number of cases present in the dataset for each word. For words with a high number of cases, the dimension was previously reduced to 500 (see [2]). Then, for every word we experimented by keeping the number of dimensions in a proportion. This proportion is given by parameter A. We analyze four proportions by setting parameter A to: A = 0 keep all dimensions, A = 1 keep 2/3 of the dimensions, A = 2 keep half of the dimensions and A = 3 keep a third of the dimensions. We calculated four different values for p. Training and testing cases were represented in the four R p spaces and word-sense label predictions calculated for all of them. All the possibilities were tried for the rest of the parameters (detailed in the following subsections)</context>
</contexts>
<marker>[2]</marker>
<rawString>M. Berry and M. Browne. Understanding Search Engines: Mathematical Modeling and Text Retrieval. SIAM Society for Industrial and Applied Mathematics, ISBN: 0-89871-437-0, Philadelphia, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Breiman</author>
</authors>
<title>Bagging predictors.</title>
<date>1996</date>
<booktitle>Machine Learning,</booktitle>
<volume>24</volume>
<issue>2</issue>
<contexts>
<context position="2607" citStr="[3]" startWordPosition="399" endWordPosition="399">the representation. In particular, Latent Semantic Indexing (LSI) [2] is used to make the dimension reduction. This technique compresses vectors representing word related contexts into vectors of a lower-dimensional space and has shown to have the ability to extract the relations among features representing words by means of their context of use. We present a multiclassifier [8] based approach which uses different training databases. These databases are obtained from the original training dataset by random subsampling. The implementation of this approach is made by a model inspired in bagging [3], and the k-NN classification algorithm [4] is used to make sense predictions for testing words. For experimentation, a previous tuning phase was performed to training data in order to automatically set some system parameters to their optimal values. Four are the parameters to be optimized, and the combination of all of them gives the possibility to perform the complete disambiguation process by 1440 different ways for each of the 100 words to be disambiguated. The tuning phase has been performed in a sound manner with the aim to improve our previous work [10]. Although the computational paylo</context>
<context position="7829" citStr="[3]" startWordPosition="1227" endWordPosition="1227">ered to be the vectors which have the smallest angle with respect to it, and thus the highest cosine. That is why the cosine is usually calculated to measure the similarity between vectors. The word senses associated with the k top-ranking neighbors are used to make a prediction for the testing case. Parameter k was optimized for each word during tuning phase. 2.5 The multiclassifier construction The combination of multiple classifiers has been intensively studied with the aim of improving the accuracy of individual components [8]. A widely used technique to implement this approach is bagging [3], where a set of training databases TDZ is generated by selecting n training cases drawn randomly with replacement from the original training database TD of n cases. When a set of n1 &lt; n training cases is chosen from the original training collection, the bagging is said to be applied by random subsampling. In our work, we construct a multiclassifier by applying random subsampling for each word. As the number n of training cases is different for each word, we optimize via tuning the parameter n1 for each multiclassifier constructed. This way, we work with training databases TDZ of different siz</context>
</contexts>
<marker>[3]</marker>
<rawString>L. Breiman. Bagging predictors. Machine Learning, 24(2):123–140, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Dasarathy</author>
</authors>
<title>Nearest Neighbor (NN) Norms: NN Pattern Recognition Classification Techniques.</title>
<date>1991</date>
<publisher>IEEE Computer Society Press,</publisher>
<contexts>
<context position="2650" citStr="[4]" startWordPosition="406" endWordPosition="406">emantic Indexing (LSI) [2] is used to make the dimension reduction. This technique compresses vectors representing word related contexts into vectors of a lower-dimensional space and has shown to have the ability to extract the relations among features representing words by means of their context of use. We present a multiclassifier [8] based approach which uses different training databases. These databases are obtained from the original training dataset by random subsampling. The implementation of this approach is made by a model inspired in bagging [3], and the k-NN classification algorithm [4] is used to make sense predictions for testing words. For experimentation, a previous tuning phase was performed to training data in order to automatically set some system parameters to their optimal values. Four are the parameters to be optimized, and the combination of all of them gives the possibility to perform the complete disambiguation process by 1440 different ways for each of the 100 words to be disambiguated. The tuning phase has been performed in a sound manner with the aim to improve our previous work [10]. Although the computational payload is high, it is a systematic way to fix t</context>
<context position="7027" citStr="[4]" startWordPosition="1098" endWordPosition="1098">shtml 250 number of singular values changes as well. Taking this in consideration, we calculate the SVD of each matrix and obtain the reduced vector representations for training and testing cases for different p values. In order to calculate the SVD of the matrices, we use Latent Semantic Indexing (LSI) 2 [5], which has been successfully used for classification purposes [7], 2.4 The k-NN classification algorithm k-NN is a distance based classification approach. According to this approach, given an arbitrary testing case, the k-NN classifier ranks its nearest neighbors among the training cases [4]. In the approach presented in this article, the training and testing cases for each word are represented by vectors in each reduced dimensional vector space. The nearest to a testing case are considered to be the vectors which have the smallest angle with respect to it, and thus the highest cosine. That is why the cosine is usually calculated to measure the similarity between vectors. The word senses associated with the k top-ranking neighbors are used to make a prediction for the testing case. Parameter k was optimized for each word during tuning phase. 2.5 The multiclassifier construction T</context>
</contexts>
<marker>[4]</marker>
<rawString>B. Dasarathy. Nearest Neighbor (NN) Norms: NN Pattern Recognition Classification Techniques. IEEE Computer Society Press, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Deerwester</author>
<author>S Dumais</author>
<author>G Furnas</author>
<author>T Landauer</author>
<author>R Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of the American Society for Information Science,</journal>
<volume>41</volume>
<contexts>
<context position="6734" citStr="[5]" startWordPosition="1055" endWordPosition="1055"> Each of the columns in this matrix gives a vector representation to each of the training cases. As the number of training cases varies among different words, the number of columns present in the matrices is different; consequently, the 1http://nlp.cs.swarthmore.edu/semeval/tasks/task17/data.shtml 250 number of singular values changes as well. Taking this in consideration, we calculate the SVD of each matrix and obtain the reduced vector representations for training and testing cases for different p values. In order to calculate the SVD of the matrices, we use Latent Semantic Indexing (LSI) 2 [5], which has been successfully used for classification purposes [7], 2.4 The k-NN classification algorithm k-NN is a distance based classification approach. According to this approach, given an arbitrary testing case, the k-NN classifier ranks its nearest neighbors among the training cases [4]. In the approach presented in this article, the training and testing cases for each word are represented by vectors in each reduced dimensional vector space. The nearest to a testing case are considered to be the vectors which have the smallest angle with respect to it, and thus the highest cosine. That i</context>
</contexts>
<marker>[5]</marker>
<rawString>S. Deerwester, S. Dumais, G. Furnas, T. Landauer, and R. Harshman. Indexing by latent semantic analysis. Journal of the American Society for Information Science, 41:391–407, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dietterich</author>
</authors>
<title>Machine learning research: Four current directions.</title>
<date>1998</date>
<journal>The AI Magazine,</journal>
<volume>18</volume>
<issue>4</issue>
<contexts>
<context position="9215" citStr="[6]" startWordPosition="1447" endWordPosition="1447">e q for a word, the corresponding multiclassifier will make a word-sense label prediction cz based on each one of the training databases TDZ. In order to calculate these confidence values, word-sense predictions are made for training cases 2http://lsi.research.telcordia.com, http://www.cs.utk.edu/∼lsi 251 and the accuracies obtained give the confidence values which indicate the accuracy level that may be expected when a prediction is made for a testing case based on each training database TDZ and word-sense cj to be predicted. The way we combine such predictions is by applying Bayesian voting [6], where a confidence value cvZ�j is calculated for each training database TDZ and word-sense cj to be predicted. In testing phase, confidence values obtained for the testing cases are summed by sense; the sense cj that gets the highest value is finally proposed as a prediction for the testing case q. This process is repeated for every testing case. In Fig. 1 an illustration of the experiment performed for each one of the 100 words can be seen. First, vectors in the original Vector Space are projected to the reduced space using SVD; next, random subsampling is applied to the training database T</context>
</contexts>
<marker>[6]</marker>
<rawString>T. Dietterich. Machine learning research: Four current directions. The AI Magazine, 18(4):97–136, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Dumais</author>
</authors>
<title>Latent semantic analysis.</title>
<date>2004</date>
<booktitle>In ARIST (Annual Review of Information Science Technology),</booktitle>
<volume>38</volume>
<pages>189--230</pages>
<contexts>
<context position="6800" citStr="[7]" startWordPosition="1064" endWordPosition="1064">to each of the training cases. As the number of training cases varies among different words, the number of columns present in the matrices is different; consequently, the 1http://nlp.cs.swarthmore.edu/semeval/tasks/task17/data.shtml 250 number of singular values changes as well. Taking this in consideration, we calculate the SVD of each matrix and obtain the reduced vector representations for training and testing cases for different p values. In order to calculate the SVD of the matrices, we use Latent Semantic Indexing (LSI) 2 [5], which has been successfully used for classification purposes [7], 2.4 The k-NN classification algorithm k-NN is a distance based classification approach. According to this approach, given an arbitrary testing case, the k-NN classifier ranks its nearest neighbors among the training cases [4]. In the approach presented in this article, the training and testing cases for each word are represented by vectors in each reduced dimensional vector space. The nearest to a testing case are considered to be the vectors which have the smallest angle with respect to it, and thus the highest cosine. That is why the cosine is usually calculated to measure the similarity b</context>
</contexts>
<marker>[7]</marker>
<rawString>S. Dumais. Latent semantic analysis. In ARIST (Annual Review of Information Science Technology), volume 38, pages 189–230, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Ho</author>
<author>J Hull</author>
<author>S Srihari</author>
</authors>
<title>Decision combination in multiple classifier systems.</title>
<date>1994</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>16</volume>
<issue>1</issue>
<contexts>
<context position="2385" citStr="[8]" startWordPosition="365" endWordPosition="365">tional Semantics In the approach presented in this paper, a vector representation is used for training and testing word cases and the Singular Value Decomposition of matrices is applied in order to reduce the dimension of the representation. In particular, Latent Semantic Indexing (LSI) [2] is used to make the dimension reduction. This technique compresses vectors representing word related contexts into vectors of a lower-dimensional space and has shown to have the ability to extract the relations among features representing words by means of their context of use. We present a multiclassifier [8] based approach which uses different training databases. These databases are obtained from the original training dataset by random subsampling. The implementation of this approach is made by a model inspired in bagging [3], and the k-NN classification algorithm [4] is used to make sense predictions for testing words. For experimentation, a previous tuning phase was performed to training data in order to automatically set some system parameters to their optimal values. Four are the parameters to be optimized, and the combination of all of them gives the possibility to perform the complete disam</context>
<context position="7762" citStr="[8]" startWordPosition="1216" endWordPosition="1216"> dimensional vector space. The nearest to a testing case are considered to be the vectors which have the smallest angle with respect to it, and thus the highest cosine. That is why the cosine is usually calculated to measure the similarity between vectors. The word senses associated with the k top-ranking neighbors are used to make a prediction for the testing case. Parameter k was optimized for each word during tuning phase. 2.5 The multiclassifier construction The combination of multiple classifiers has been intensively studied with the aim of improving the accuracy of individual components [8]. A widely used technique to implement this approach is bagging [3], where a set of training databases TDZ is generated by selecting n training cases drawn randomly with replacement from the original training database TD of n cases. When a set of n1 &lt; n training cases is chosen from the original training collection, the bagging is said to be applied by random subsampling. In our work, we construct a multiclassifier by applying random subsampling for each word. As the number n of training cases is different for each word, we optimize via tuning the parameter n1 for each multiclassifier construc</context>
</contexts>
<marker>[8]</marker>
<rawString>T. Ho, J. Hull, and S. Srihari. Decision combination in multiple classifier systems. IEEE Transactions on Pattern Analysis and Machine Intelligence, 16(1):66–75, 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pradhan</author>
<author>E Loper</author>
<author>D Dligach</author>
<author>M Palmer</author>
</authors>
<title>Semeval-2007 task 17: English lexical sample, srl and all words.</title>
<date>2007</date>
<booktitle>In A. for Computational Linguistics, editor, Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval-2007,</booktitle>
<pages>87--92</pages>
<contexts>
<context position="4645" citStr="[9]" startWordPosition="735" endWordPosition="735"> shown. 249 2.1 Dataset and previous results The dataset we use in the experiments was obtained from the 4th International Workshop on Semantic Evaluations (SemEval-2007) web page&apos;, task 17, subtask 1: Coarse-grained English Lexical Sample WSD. This task consists of lexical sample style training and testing data for 100 lemmas (35 nouns and 65 verbs) of different degree of polysemy (ranging from 1 to 13) and number of instances annotated (ranging from 19 instances in training for the word grant to 2536 instances at share). The average inter-annotator agreement for these lemmas is over 90%. In [9] task organizers describe the results achieved by the participating systems. They define a baseline for the task based on giving the most frequent sense in training (F-score: 78.0%). The best system performance (89.1%) was closely approaching the inter-annotator agreement but still below it. 2.2 Data Preparation Once we downloaded the training and testing datasets, some features were extracted and vector representations were constructed for each training and testing case. The features were extracted by [1] and are local collocations (bigrams and trigrams formed with lemmas, word-forms or PoS t</context>
<context position="17128" citStr="[9]" startWordPosition="2853" endWordPosition="2853">e selected from each word-sense. In order to decide the optimal value for j, the classification experiment was carried out varying j from 1 to 10 for each word. Given that parameters p, i and k are already set to their optimal values for each word, we calculate results for the 10 possible values of j, and set it to its optimal value. 4 Experimental Results The experiment was conducted by considering the optimal values for parameters tuned. Original training and testing datasets were used for the final experiment, and results achieved were compared to the ones made available by task organizers [9]. Our system achieved an F-score of 85.65%, which compared to the baseline defined (78.0%) is a very good result, although still below the best published by task organizers (89.1%). s n1 = i=1 255 In [9] the performance of the top-8 systems on individual verbs and nouns is shown; 73 of the 100 lemmas are included in a table in two separated groups. Lemmas that have perfect or almost perfect accuracies have been removed. In TABLE 1 the average results achieved by our system for the two groups of lemmas are compared to the ones published in the cited paper. We can observe that our system perform</context>
</contexts>
<marker>[9]</marker>
<rawString>S. Pradhan, E. Loper, D. Dligach, and M. Palmer. Semeval-2007 task 17: English lexical sample, srl and all words. In A. for Computational Linguistics, editor, Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval-2007, pages 87–92, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Zelaia</author>
<author>O Arregi</author>
<author>B Sierra</author>
</authors>
<title>Ubc-zas: A k-nn based multiclassifier system to perform wsd in a reduced dimensional vector space.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval-2007,</booktitle>
<pages>358--361</pages>
<contexts>
<context position="3173" citStr="[10]" startWordPosition="493" endWordPosition="493">ade by a model inspired in bagging [3], and the k-NN classification algorithm [4] is used to make sense predictions for testing words. For experimentation, a previous tuning phase was performed to training data in order to automatically set some system parameters to their optimal values. Four are the parameters to be optimized, and the combination of all of them gives the possibility to perform the complete disambiguation process by 1440 different ways for each of the 100 words to be disambiguated. The tuning phase has been performed in a sound manner with the aim to improve our previous work [10]. Although the computational payload is high, it is a systematic way to fix the optimal values for parameters. The aim of this article is to give a brief description of our approach to deal with the WSD task and to show the results achieved. In Section 2, our approach is presented. In Section 3, the experimental setup is introduced. The experimental results are presented and discussed in Section 4, and finally, Section 5 contains some conclusions and future work. 2 Proposed Approach In this section, our approach is presented and the techniques used are briefly reviewed. First the dataset used </context>
</contexts>
<marker>[10]</marker>
<rawString>A. Zelaia, O. Arregi, and B. Sierra. Ubc-zas: A k-nn based multiclassifier system to perform wsd in a reduced dimensional vector space. In Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval-2007, pages 358–361, 2007.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>