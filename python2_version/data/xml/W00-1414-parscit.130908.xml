<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.026320">
<title confidence="0.987621">
Generating Referring Quantified Expressions
</title>
<author confidence="0.99724">
James Shaw and Kathleen McKeown
</author>
<affiliation confidence="0.9970005">
Dept. of Computer Science
Columbia University
</affiliation>
<address confidence="0.985748">
New York, NY 10027, USA
</address>
<email confidence="0.974775">
shaw,kathyOcs.columbia.edu
</email>
<sectionHeader confidence="0.996962" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999815636363636">
In this paper, we describe how quantifiers can be
generated in a text generation system. By taking
advantage of discourse and ontological information,
quantified expressions can replace entities in a text,
making the text more fluent and concise. In ad-
dition to avoiding ambiguities between distributive
and collective readings in universal quantification
generation, we will also show how different scope
orderings between universal and existential quanti-
fiers will result in different quantified expressions in
our algorithm.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998530337837838">
To convey information concisely and fluently, text
generation systems often perform opportunistic text
planning (Robin, 1995; Mellish et al., 1998) and em-
ploy advanced linguistic constructions such as ellip-
sis (Sliaw, 1998). But a system can also take ad-
vantage of quantification and ontological informa-
tion to generate concise references to entities at the
discourse level. For example, a sentence such as
The patient has an infusion line in each arm.&amp;quot; is
a more concise version of &amp;quot;The patient has an in-
fusion line in his left arm. The patient has an in-
fusion line in his right arm.&amp;quot; Quantification is an
active research topic in logic, language, and philoso-
phy(Carpenter, 1997; de Swart. 1998). Since nat-
ural language understanding systems need to .ob-
Lain as few interpretations as possible from text,
researchers have studied quantifier scope ambigu-
ity extensively (Woods, 1978; --Grosz et al., .1987;
Hobbs and Shieber. 1987; Pereira, 1990; Moran and
Pereira, 1992; Park, 1995). Research in quantifica-
tion interpretation first transforms a sentence into
predicate logic, raises the quantifiers to the senten-
tial level, and permutes these quantifiers to obtain
as many readings as possible related to quantifier
scoping. Then. invalid readings are eliminated using
various constraints.
Ambiguity in quantified expressions is caused by
two main culprits. The first type of ambiguity in-
volves the distributive reading versus the collective
reading. In universal quantification, a referring ex-
pression refers to multiple entities. There is a po-
tential ambiguity between whether the aggregated
entities acted individually (distributive) or acted to-
gether as one (collective). Under the distributive
reading, the sentence &amp;quot;All the nurses inspected the
patient.&amp;quot; implies that each nurse individually in-
spected the patient. Under the collective reading,
the nurses inspected the patient together as a group.
The other ambiguity in quantification involves mul-
tiple quantifiers in the same sentence. The sentence
&amp;quot;A nurse inspected each patient.&amp;quot; has two possi-
ble quantifier scope orderings. In Vpatient3nurse,
the universal quantifier V has wide scope, outscop-
ing the existential quantifier 3. This ordering means
that each patient is inspected by a nurse, who might
riot be the same in each case. In the other scope
order, 3nurseVpatient, a single, particular nurse in-
spected every patient. In both types of ambiguities,
a generation system should make the desired reading
clear.
Fortunately, the difficulties of quantifier scope d s-
am b ig not ion faced by the understanding community
do not apply to text generation. For generation. the
problem is the reverse: given an unambiguous rep-
resentat ion of a set, of facts as input, how can it
generate a quantified sentence that unambiguously
conveys the intended meaning? In this paper. we
propose an algorithm which selects an appropriate
quantified expression to refer .to a set of entities us-
ing discourse and ontological knowledge. The algo-
rithm first identifies the entities for quantification in
the _input -propositions. . Then -an- appropriate con-
cept in the ontology is selected to refer to these en-
tities. Using discourse and ontological information,
the system determines if quantification is appropri-
ate and if it is, which particular quantifier to use
to minimize the ambiguity between distributive and
collective readings. More importantly, when there
are multiple quantifiers in the same sentence, the al-
gorithm generates different expressions for different
scope orderings. In this work, we focus on generat-
ing referring quantified expressions for entities which
have been mentioned before in the discourse or can
be inferred from an ontology. There are quantified
</bodyText>
<page confidence="0.986257">
100
</page>
<bodyText confidence="0.999303875">
expressions that do not refer to particular entities
in a domain or discourse, such as generics (i.e. &amp;quot;All
whales are mammals.&amp;quot;), or negatives (i.e., &amp;quot;The pa-
tient has no allergies.&amp;quot;). The synthesis of such quan-
tifiers is currently performed in earlier stages of the
generation process.
. In the next section. we. vvill.compare our:.approach
with previous work in the generation of quantified
expressions. In Section 3, we will describe the appli-
cation where the need for concise output motivated
our research in quantification. The algorithm for
generating universal quantifiers is detailed in Sec-
tion 4, including how the system handles ambiguity
between distributive and collective readings. Sec-
tion 5 describes how our algorithm generates sen-
tences with multiple quantifiers.
</bodyText>
<sectionHeader confidence="0.998819" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999220580645161">
Because a quantified expression refers to multiple
entities in a domain, our work can be categorized as
referring expression generation (Dale, 1992; Reiter
and Dale, 1992; Horacek, 1997). Previous work in
this area did not address the generation of quantified
expressions directly. In this paper, we are interested
in how to systematically derive quantifiers from in-
put propositions, discourse history, and ontological
information. Recent work on the generation of quan-
tifiers (Gailly, 1988; Creaney, 1996; Creaney, 1999)
follows the analysis viewpoint, discussing scope am-
biguities extensively. Though our algorithm gener-
ates different sentences for different scope orderings,
we do not achieve this through scoping operations as
they did. Creaney also discussed various imprecise
quantifiers, such as some, at least, and at most.
In regards to generating generic quantified expres-
sions, (Knott et al., 1997) has proposed an algorithm
for generating defeasible, but informative descrip-
tions for objects in museums.
Other researchers (van Eijck and Alshawi. 1992;
Copestake et. at., 1999) proposed representations- in a
machine translation setting which allow underspec-
ification in regard to quantifier scope. Our work is
different in that we perform quantification directly
on the instance-based representation obtained from
database tuples. Our input -does not have the in-.
formation about which entities are quantified as is
the case in ma.cliine translation, where the quanti-
fiers are already specified in the input from a source
language.
</bodyText>
<sectionHeader confidence="0.989525" genericHeader="method">
3 The Application Domain
</sectionHeader>
<bodyText confidence="0.999703666666667">
We implemented our quantification algorithm as
part of MAGIC (Dalai et al.. 1996: McKeown et
al., 1997). MAGIC automatically generates multi-
media briefings to describe the post-operative sta-
tus of a patient after undergoing Coronary Artery
Bypass Graft surgery. The system embodies a stan-
</bodyText>
<equation confidence="0.997990555555556">
((TYPE EVENT)
(PRED ((PRED receive) (ID idl)))
(ARG1 ((PRED patient) (ID pt1)))
(ARG2 ((FRED aprotinin) (ID apt)))
(NODS ((PRED after) (ID id2)
_ -(TYPE.TINE)
(ARG2 ((FRED critical-point)
(NAME intubation) (ID c1)))
) ) )
</equation>
<figureCaption confidence="0.9790185">
Figure 1: The predicate-argument structure of
&amp;quot;After intubation, a patient received aprotinin.&amp;quot;
</figureCaption>
<bodyText confidence="0.994840538461539">
dard text generation system architecture with three
modules (Rambow and Korelsky, 1992): a content
planner, a sentence planner, and a linguistic realizer.
Once the bypass surgery ia finished, information that
is automatically collected during surgery such as
blood pressure, heart rate, and medications given,
is sent to a domain-specific medical inference mod-
ule. Based on the medical inferences and schemas
(McKeown, 1985), the content planner determines
the information to convey and the order to convey
it.
The sentence planner takes a set of propositions
(or predicate-argument structures) with rhetorical
relations from the content planner and uses linguistic
information to make decisions about how to convey
the propositions fluently. Each proposition is repre-
sented as a feature structure (Kaplan and Bresnan,
1982; Kay, 1979) similar to the one shown in Fig-
ure 1. The sentence planner&apos;s responsibilities include
referring expression generation, clause aggregation,
and lexical choice (Wanner and Hovy, 1996). Then
the aggregated predicate-argument structure is sent
to FUF/SURGE (Elhadad and Robin, 199?), a lin-
guistic realizer which transforms the lexicalized Se-
mantic specification into a string. The quantification
algorithm is implemented in the sentence planner.
</bodyText>
<sectionHeader confidence="0.984964" genericHeader="method">
4 Quantification Algorithm
</sectionHeader>
<bodyText confidence="0.998295153846154">
In this -..work,..we • prefer -generating expressions with
universal quantifiers over conjunction because, as-
suming that the users and the system have the same
domain model, the universally quantified expres-
sions are more concise and they represent the same
amount of information as the expression with con-
joined entities, In contrast., when given a conjunc-
tion of entities and an expression with a cardinal
quantifier, the system. by default, would use the
conjunction if the conjoined entities can be distin-
guished at the surface level. This is because once
the system generates a cardinal quantifier when the
universal quantification does not hold, such as &amp;quot;three
</bodyText>
<page confidence="0.986247">
101
</page>
<bodyText confidence="0.994450111111111">
patients&amp;quot;, it is impossible for the hearer to recover a both: ID - XI = 0 and IX I = 2, can have col-
the identities of these patients based on the con- lective reading
text. The default heuristics to prefer universal quan- • every, all, the: ID- XI 0 and IXI &gt; 2, can
tifier over conjunction over cardinal quantifier can have collective reading
be superseded by directives from the content-plan- • each: ID - Xl = 0 and IXI &gt; 2, only distribu-
ner which are application specific. tive reading
The input to our quaatification,algorithm is a set a any: ID - XI = 0, when under the scope of
of predicate-argument structures after the referring negation
expression module selected the properties to identify a a/an: 1Dnxl&gt; 0 and IX = 1
the entities (Dale, 1992; Dale and Reiter, 1995), but • n (cardinal): IDnXI &gt; 0 and IXI = n
without carrying out the assignment of quantifiers.
Our quantification algorithm first identifies the set
of distinct entities which can be quantified in the
input propositions. A generalization of the entities
in the ontology is selected to potentially replace the
references to these entities. If universal quantifica-
tion is possible, then the replacement is made and
the system must select which particular quantifier
to use. In our system, we have six realizations for
universal quantifiers: each, every, all-I, both, the,
and any, and two for existential quantifiers: the in-
definite article, a/an, and cardinal n.
4.1 Identify Thematic Roles with Distinct
Entities
Our algorithm identifies the roles containing distinct
entities among the input propositions as candidates
for universal and existential quantification. Suppose
the system is given two propositions similar to the
one in Figure 1, &amp;quot;After intubation, Alice received
aprotinin&amp;quot; and &amp;quot;After start of bypass, Alice received
aprotinin&amp;quot;, each with four roles - FRED, ARG1,
ARG2, and MODS-TIME. By computing similarity
among entities in the same role, the system deter-
mines that the entities in A RG1, FRED, and AR.G2
are identical in each role, and only the entities in
MODS-TIME are different. Based on this result,
the distinct entities in MODS-TIME, &amp;quot;after intuba-
tion&amp;quot; and &amp;quot;after start of bypass&amp;quot;, are candidates for
quantification.
4.2 Generalization and Quantification
We used the axioms in Figure 2 to determine if
the distinct entities can he universally or existen-
tially quantified. Though the axioms are similar to
those used in Generalized Quantifier (Barwise and
Cooper, 1981; Zwarts. 1983; de Swart. 1998). the
semantics of set X and set D are different. In the
previous step. the entities in set X have been iden-
tified. To compute set D in Figure 2. we introduce
a concept, Class-X. Class-X is a generalLation of
the distinct entities in set X. Quantification can re-
place the distinct entities in the propositions with.
a reference to their type restricted by a quantifier.
accessing discourse and ontological information to
provide a context. Our ontology is implemented in
</bodyText>
<figureCaption confidence="0.8224204">
Figure 2: Axioms of the quantifiers discussed in this
paper.
CLASSIC(Borgida et al., 1989) and is a subset of
WordNet(Miller et al., 1990) and an online medical
dictionary (Cimino et al., 1994) designed to support
</figureCaption>
<bodyText confidence="0.995873594594594">
multiple applications across the medical institution.
Given the entities in set X, queries in CLASSIC de-
termine the class of each instance and its ancestors
in the ontology. Based on this information, the gen-
eralization algorithm identifies Class-X by comput-
ing the most specific class which covers all the enti-
ties. Earlier work (Passonneau et at., 1996) provided
a framework for balancing specificity and verbosity
in selecting appropriate concepts for generalization.
However, given the precision needed in medical re-
ports, our generalization procedure selects the most
specific class.
Set D represents the set of instances of Class-X in
a context. Our system currently computes set D for
three different contexts:
• discourse: Previous references can provide an
appropriate context for universal quantification.
For example, if &amp;quot;Alice&amp;quot; and &amp;quot;Bob&amp;quot; were men-
tioned in the previous sentence, the system can
refer to them as &amp;quot;both patients&amp;quot; in the current
sentence.
a domain ontology: The domain ontology pro-
vides a closed world from which we can obtain
the set D by matching all the instances of a
concept in the knowledge base, such as -ev-
ery patient&amp;quot;. In addition, certain concepts in
the ontology have limited types. For example,
knowing that cell savers, platelets and packed
red blood cells are the only possible types of
blood products in the ontology, the quantified
expression &amp;quot;every blood product&apos; can be used
instead of referring to each entity.
a domain knowledge: The possessor of the dis-
tinct entities in a role might contain a maximum
number of instances allowed for Class-X. For ex-
all is realized as all the&amp;quot;.
102
ample, because a person has only two arms, the
entities &amp;quot;the patient&apos;s left arm&amp;quot; and &amp;quot;the pa-
tient&apos;s right arm&amp;quot; can be referred to as &amp;quot;each
arm&amp;quot;.
The computation of set D can also involve interac-
tions with a referring expression moduIe(Dale and.
Reiter, 1995). For example, instead of the expres-
sion &amp;quot;Alice and Bob&amp;quot; and &amp;quot;both patients&amp;quot; covered
by the current algorithm, by interacting with a refer-
ring expression module, the system might determine
that &amp;quot;both CABG patients operated on this morn-
ing by Dr. Rose&amp;quot; is a clearer expression to refer to
the entities. Though this is desirable, we did not
incorporate this capability into our system.
Although the is often used to indicate a generic
reference (i.e., &amp;quot;The lion is the king of jungle.&amp;quot;), in
English, the can also be used as an unmarked uni-
versal quantifier when its head noun is plural, such
as &amp;quot;the patients.&amp;quot; Like the quantifier all, the can
be both distributive and collective. However, the
cannot always replace all as a universal quantifier.
the cannot be used when universal quantification is
based on the domain ontology. For example, it is
not obvious that the quantified expression in &amp;quot;John
received the blood products.&amp;quot; refers to &amp;quot;each blood
product&apos; in the ontology. Although unmarked uni-
versal quantifiers can be used to refer to body parts,
as in &amp;quot;The lines include an IV in the arms.&amp;quot;, the ex-
pression is ambiguous between the distributive and
collective readings. Of the three contexts discussed
above, the system occationally generates the instead
of every and both in a discourse context, yielding
more natural output.
When the computed set D matches set X exactly
— = 0), a quantified expression with either
each, all, every, both, the, and any, replaces the
entities in set X.
</bodyText>
<subsectionHeader confidence="0.99903">
4.3 Selecting a Particular Quantifier
</subsectionHeader>
<bodyText confidence="0.999557548387097">
In general, the universal quantification of a partic-
ular type of entity. such as &amp;quot;every patient&amp;quot;. refers
to all such entities in a context. As a result, read-
ers can recover what a universally quantified expres-
sion refers to. In contrast, readers cannot pinpoint.
which entity has-been .referred to. in an existentially,
quantified expression, such as &amp;quot;a patient&amp;quot; or &amp;quot;two
patients&amp;quot;. Because a universally quantified expres-
sion preserves original semantics and is more con-
cise than listing each entity, it is the focus of our
quantification algorithm. The universal quantifiers
implemented in our system include the six possible
realizations of V in .English: every, all, each, both.
the, and any. The only existential quantifiers im-
plemented in our system are the singular indefinite
quantffier, aiart, and cardinal quantifiers, n. They
are used in sentences with multiple quantifiers and
when the entities being referred to do not have dis-
tinguishable expressions at surface level. A more
developed pragmatic module is needed before quan-
tifiers such as some, most, at least, and few, can
be systematically generated. Indiscriminate applica-
tion of&apos; imprecise quantification can result in vague
or inappropriate text in our domain, such as &amp;quot;The
patientFreceived,,sonte bload&apos;pradnets:&amp;quot; .a.13-
plication, knowing exactly what blood products are
used is very important. To avoid generating such
inappropriate sentences., the system only performs
generalization on the entities which can be univer-
sally quantified. If the distinct entities cannot be
universally quantified, the system will realize these
entities using coordinated conjunction.
Once the system decides that a universally quan-
tified expression can be used to replace the entities
in set X, it must select which universal quantifier.
Because our sentence planner opportunistically com-
bines distinct entries from separate database entries
for conciseness, it is not the case that these aggre-
gated entities acted together (the collective read-
ing). Given such input, the referring expression for
aggregated entities should have only the distribu-
tive reading2. The universal quantifier, each, al-
ways imposes a distributive reading when applied.
In general, each requires a &amp;quot;matching&amp;quot; between the
domain of the quantifier and the objects referred
to(McCawley, 1981, pp. 37). In our algorithm, this
matching process is exactly what happened, thus it
is the default universal quantifier in our algorithm.
Of course, indiscriminate use of each can result in
awkward sounding text. For example, the sentence
&amp;quot;Every patient is awake&amp;quot; sounds more natural than
&amp;quot;Each patient is awake.&amp;quot; However, since quantified
expressions with the universal quantifiers all and
every3 can have collective readings (Vendler, 1967;
McCawley, 1981), our system generates every and
all under two conditions when the collective read-
ing is unlikely. First if the proposition is a state, as
opposed to an event, we assume only the distribu-
tive reading is possible4. The quantifier every is
used in &amp;quot;Every patient fencLtachycardia.&amp;quot; because
the proposition is a state proposition and contains
the predicate has-attribute, an attributive relation.
</bodyText>
<listItem confidence="0.994868333333333">
• - 2 Fnr our system togenerate noun -phrases,with ,collective
readings, the quantification process must be performed at the
content planner level, not in the clause aggregation module.
</listItem>
<footnote confidence="0.989331583333333">
3every is also distributive, but it stresses completeness or
rather. exhaustiveness(Vendler, 1967). The sentence &amp;quot;John
rook a piciure of everyone in the MOM, is ambiguous while
&amp;quot;John took a picture of each person in The room.&amp;quot; is not.
4There are cases where state propositions do have dis-
tributed readings (e.g., &apos;Mountains surround the village:).
Sentences with collective readings are handled earlier in the
content planner and thus, this type of problem does riot occur
at this-point in our sysiern. Though this observation seems to
be true in our medical application, when implementing qUall-
tifiers in a new domain, we can limit this assumption to only
the subset of state relations for which it holds.
</footnote>
<page confidence="0.999339">
103
</page>
<bodyText confidence="0.999717294117647">
Second, when the concept being universally quan-
tified is marked as having a distributive reading in
the lexicon, such as the concept episode, quantifiers
every will be used instead of each. These quanti-
fiers make the quantified sentences more natural-be-
cause they do not pick out the redundant distribu-
tive meaning. - _
The use of prepositions can also affect which quan-
tifier to use. For example, &amp;quot;After all the episodes,
the patient received dobutamine&amp;quot; is ambiguous in re-
gards to whether the dobutamine is given once dur-
ing the surgery, or given after each episode. In con-
trast, the sentence &amp;quot;In all the episodes, the patient
received dobutamine.&amp;quot; does not have this problem.
The current system looks at the particular preposi-
tion (i.e., &amp;quot;before&amp;quot;, &amp;quot;after&amp;quot;, or &amp;quot;in&amp;quot;) before selecting
the appropriate quantifier.
</bodyText>
<subsectionHeader confidence="0.999544">
4.4 Examples of a Single Quantifier
</subsectionHeader>
<bodyText confidence="0.999284184210527">
Given the four propositions, &amp;quot;After intubation,
Mrs. Doe had tachycardia&amp;quot;, &amp;quot;After skin incision,
Mrs. Doe had tachycardia&amp;quot;, &amp;quot;After start of bypass,
Mrs. Doe had tachycardia&amp;quot;, and &amp;quot;After coining off
bypass, Mrs. Doe had tachycardia.&amp;quot;, the algorithm
first identifies roles with similar entities, ARG1,
PRED, ARG2 and removes them from further quan-
tification processing while the distinct entities in the
role MODS-TIME, &amp;quot;after intubation&amp;quot;, &amp;quot;after skin in-
cision&amp;quot;, &amp;quot;after start of bypass&amp;quot;, and &amp;quot;after coming off
bypass&amp;quot;, are further processed for universal quantifi-
cation. The role MODS-TIME is further separated
into two smaller roles, one role with the preposi-
tions and the other role with different critical points.
Since the prepositions are all the sante, universal
quantification is only applied to the distinct entities
in set X. in this case, the four critical points. Queries
to the CLASSIC ontology indicate that. the enti-
ties in set X, &amp;quot;intubation&amp;quot;, &amp;quot;skin-incision&amp;quot;, &amp;quot;start-
of-bypass&amp;quot;, and &amp;quot;coming-off-bypass&amp;quot; match all the
possible types of the concept critical-point, sat-
isfying the domain ontology context in Section 4:2.
Since set D and set X match exactly, generalization
and universal quantification can be used to replace
the references to these entities: &amp;quot;After each criti-
cal point„iirs. Doe had tachycardia.&amp;quot; The system
currently does noLperforin generalization on entities
which failed the univeral quantification test. In such
cases, a sentence with conjunction will be generated,
i.e., -After intubation and skin incision. Mrs. Doe
had tachycardia.-
In addition to every, the system generates both
when the number of entities in set X is two. In
our application, both is used as a universal quanti-
fier under discourse context: &amp;quot;Alice had episodes of
bradycardia before i dila 7011 and start of bypass. In
bath episodes. she received Cefazolin and Phenyle-
phrine.&amp;quot;
</bodyText>
<subsectionHeader confidence="0.513829">
When a universal quantifier is under the govern-
</subsectionHeader>
<bodyText confidence="0.998709">
rnent of negation, each, all, every and both are in-
appropriate, and any should be used instead. Given -
that the patient went on bypass without compli-
cations, the system should generate &amp;quot;The patient
went on bypass without any problem.&amp;quot; In contrast,
&amp;quot;The patient went on bypass without every prob-
tem.&amp;quot;7---has—aAifferent.-mearring:-- -Our systiern cur-
rently uses any as a universal quantifier when the
universal quantification is under the government of
negation, such as The patient denied any drug al-
lergy.&amp;quot;, or &amp;quot;Her hypertension was controlled without
any medication.&amp;quot; Currently, the generation of nega-
tion sentences about surgery problems and allergies
are handled in the content planner. They are not
synthesized from multiple negation sentences: &amp;quot;The
patient is not allergic to aspirin. The paitent is not
allergic to penicillin...&amp;quot;
</bodyText>
<sectionHeader confidence="0.967223" genericHeader="method">
5 Generation of Multiple Quantifiers
</sectionHeader>
<bodyText confidence="0.977981263157895">
When there are two distinct roles across the proposi-
tions, the algorithm tries to use a universal quantifier
for one role and an existential quantifier for another.
To generate sentences with ]], both entities being
referred to must have no proper names; this triggers
the use of existential quantifiers. We intentionally
ignore the cases where two universal quantifiers are
generated in the same sentence. The likelihood for
input specifying sentences with W to a text genera-
tion system is slim.
When generating multiple quantifiers in the same
sentence, we differentiate between cases where there
is or isn&apos;t a dependency between the two distinct
roles. Two roles are independent of each other when
one is not a modifier of the other. For example,
the roles ARG1 and ARG2 in a proposition are in-
dependent. In &amp;quot;Each patient is giben a high sever-
ity rating&amp;quot;, performing universal quantification on
the patients (ARG3) is a separate decision from
the existential quantification of the severity ratings
(ARG2). Similarly, in &amp;quot;An abnormal lab result was
seen in each patient with hypertension after bypaas&amp;quot;.
the quantification operations on the abnormal lab
results and the patients can be performed indepen-
dently.
,When-there isa dependency between the roles be-
ing quantified, the quantification process of each role
might interact because modifiers restrict the range
of the entities being modified. We found that when
universal quantification occurs in the MODS role.
the quantification of FRED and MODS can be per-
formed independently, just as in the cases without
dependency. Given the input propositions -Alice has
IV- l in Alice&apos;s left arm. Alice has lV- n Alice&apos;s
right arm.&amp;quot;, the distinct roles are ARG2 and
&amp;quot;iv-r. and ARG2-MODS &amp;quot;in Alice&apos;s left arm&amp;quot; and
in Alice&apos;s right arm&amp;quot;. The ARG2-MODS is uni-
versally quantified based on domain knowledge that
</bodyText>
<page confidence="0.991275">
104
</page>
<listItem confidence="0.756450333333333">
• Roles without dependency, V Role-1,3 Role-2 geon&apos;s name is likely to be known, and the in-
Each patient is given a high severity rating. put is likely to be &amp;quot;Dr. Rose operated on Alice&apos;,
• Roles without dependency, 3 Role-I, V Role-2 &amp;quot;Dr. Rose operated on Bob&amp;quot;, and &amp;quot;Dr. Rose oper-
</listItem>
<bodyText confidence="0.997444">
An abnormal lab result was seen in each patient ated on Chris&amp;quot;. Given these three propositions, the
with hypertension after bypass. entities in ARG1 and PRED are identical, and only
• Roles with dependency, V PRED,-3 MODS - the distinct entities in ARG2, &amp;quot;Alice&amp;quot;, &amp;quot;Bob&amp;quot; and
Every patient with a balloon pump had hyper- .GxiswiIbbe:;uantified. With- a.m.apPr opr i ate
tension. context, the sentence &amp;quot;Dr. Rose operated on each
patient&amp;quot; will be generated. If the name of the sur-
geon is not available but the identifiers for the sur-
geon entities across the propositions are the same,
the system will generate &amp;quot;The same surgeon oper-
ated on each patient.&amp;quot; As this example indicates,
when has a wider scope than V, the first step in
our algorithm (described in Section 4.1), identify-
ing roles with distinct entities, would eliminate the
roles with identical entities from further quantifica-
tion processing. Based on our algorithm, the sen-
tences with EV readings are taken care of by the first
step, identifying roles with distinct entities, while V3
cases are handled by quantification operations for
multiple roles, as described in Section 5.
In Section 4.3, we mentioned that it is important
to know exactly what blood products are used in
our application. As a result, the system would not
generate the sentence &amp;quot;Each patient received a blood
product.&amp;quot; when the input propositions are &amp;quot;Mice re-
ceived packed red blood cells. Bob received platelets.
Chris received platelets.&amp;quot; Even though the conjoined
entities can be generalized to &amp;quot;blood product&amp;quot;, this
quantification operation would violate our precondi-
tion for using existential quantifiers: the descriptions
for each of the conjoined entities must be indistin-
guishable. Here, one is &amp;quot;red blood cells&amp;quot; and the oth-
ers are &amp;quot;platelets&amp;quot;. Given these three propositions,
the system would generate &amp;quot;Alice received packed
red blood cells, and Bob and Chris, platelets.&amp;quot; based
on the algorithm described in (Shaw, 1998). If in
our domain the input propositions could be -.Al-
ice received blood-product-1. Bob received blood-
product-2. Chris received blood-product-2.-, where
each instance of blood-product-n could be realized
as &amp;quot;blood product&amp;quot;, then the system would generate
&amp;quot;Each patient received a blood product.&amp;quot; since the
description of conjoined entities are not distinguish-
able at the surface level.
6 Conclusion
We have described the quantification operators that
can make the text more concise while preserving the
original semantics in the input propositions. Though
we would like to incorporate imprecise quantifiers
such as few, many, some into our system because
they have potential to drastically reduce the text
further, these quantifiers do not have the desired
property in which the readers can recover the exact
entities in the input propositions. The property of
• Roles with dependency, 3 FRED, V MODS
Alice has an IV in each arm.
Figure 3: Sentences with two quantifiers
a patient is a human and a human has a left arm
and a right arm. In this example, &amp;quot;an IV in each
arm&amp;quot;, the decision to generate universal and exis-
tential quantified expressions are independent. But
in &amp;quot;Every patient with a balloon pump had hyperten-
sion&amp;quot;, the existentially quantified expression &amp;quot;with a
balloon pump&amp;quot; is a restrictive modifier of its head. In
this case, the set D does not include all the patients,
but only the patients &amp;quot;with a balloon pump&amp;quot;. When
computing set D for universal quantification, the al-
gorithm takes this extra restriction into account by
eliminating all patients without such a restriction.
Once a role is universally quantified and the other is
existentially quantified, our algorithm replaces both
roles with the corresponding quantified expressions.
Figure 3 shows the sentences with multiple quanti-
fiers generated by applying our algorithm.
5.1 Ambiguity Revisited
In Section 4.3, we described how to minimize the
ambiguity between distributive and collective read-
ings when generating universal quantifiers. What
about the scope ambiguity when there are multiple
quantifiers in the same sentence? If we look at the
roles which are being universally and existentially
quantified in our examples in Figure 3, it is inter-
esting to note that the universal quantifiers always
have wider scope than the existential quantifiers. In
the first example, ,the,scope:- order- is Vpatient3high-
severity-rating, the second example is Vpatientlab-
result, the third is Vpatient]balloon-pump. and the
fourth is VarmlAr. The scope orderings are all V.
What happens if a sentence contains an existen-
tial quantifier which has a wider scope t han a uni-
versal quantifier? In &amp;quot;A surgeon operated on each
the normal reading is Vpatient3surgeon.
But if the existentially quantified noun phrase
-a surgeon&amp;quot; refers to the same surgeon, as in
3surgeoriVpatient, the system would generate &amp;quot;(A
particular/ The same) surgeon operated on each pa-
tient.&amp;quot; In an applied generation system, the sur-
I 05
preserving the original semantics is very important
since it guarantees that even though the surface ex-
pressions are modified, the information is preserved.
This property allows the operators to be domain in-
dependent and reusable in different natural language
generation systems.
We have described an. algari that.wh ic.h.sys teinati-
cal ly derives quantifiers from input propositions, dis-
course history and ontological information. We iden-
tified three types of information from the discourse
and ontology to determine if a universal quantifier
can be applied. We also minimized the ambiguity
between distributive and collective readings by se-
lecting an appropriate universal quantifier. Most
importantly, for multiple quantifiers in the same sen-
tence, we have shown how our algorithm generates
different quantifed expressions for different scope or-
derings.
</bodyText>
<sectionHeader confidence="0.997146" genericHeader="conclusions">
7 Acknowledgement
</sectionHeader>
<bodyText confidence="0.999994454545455">
We would like to thank anonymous reviewers for
valuable comments. The research is supported in
part by the National Library of Medicine under
grant LM06593-02 and the Columbia University
Center for Advanced Technology in High Perfor-
mance Computing and Communications in Health-
care (funded by the New York State Science and
Technology Foundation). Any opinions, findings, or
recommendations expressed in this paper are those
of the authors and do not necessarily reflect the
views of the above agencies.
</bodyText>
<sectionHeader confidence="0.995091" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.993544012345679">
Jon Barwise and Robin Cooper. 1981. Generalized
quantifiers and natural language. Linguistics and
Philosophy, 4:159-219.
Alexander Borgida, Ronald Brachman, Deborah
McGuinness, and Lori Alperin Resnick. 1989.
CLASSIC: A structural data model for objects.
In ACM SIGMOD International Conference on
Management of Data.
Bob Carpenter. 1997. Type-Logical Semantics. MIT
Press, Cambridge, Massachusetts.
James 3. Cimino, Paul D. Clayton, George Hripc-
sak, and Stephen B. Johnson 1994_ Knowledge-
based approaches to the maintenance of a large
controlled medical terminology. The Journal of
the American Medical Informatics Association,
1(1):3.5-50.
Ann Copestake, Dan Flickinger, Ivan A. Sag. and
Carl J. Pollard. 1999. Minimal recursion seman-
tics: An introduction. Manuscript available via
littp://lingo.stanford.eduipubs.html.
Norman Crea.ney, 1996. An algorithm for generat-
ing quantifiers. In Proc. of the 8th International
Workshop on Natural Language Generation, Sus-
sex, Lk.
Norman Creaney. 1999. Generating quantified logi-
cal forms from raw data. In Proc. of the ESSLLI-
99 Workshop on the Generation of Nominal Ex-
pressions.
M. Dalai-, S. Feiner, K. McKeown, D. Jordan,
B. Allen, and Y. alSafadi. 1996. MAGIC: An
..,expecimental -systern.int. .generating...multimedia
briefings about post-bypass patient status. In
Proc. 1996 AMIA Annual Fall Symp, pages 684-
688, Washington, DC, October 26-30.
Robert Dale and Ehud Reiter. 1995. Computational
interpretations of the gricean maxims in the gener-
ation of referring expressions. Cognitive Science,
19:233-263.
Robert Dale. 1992. Generating Referring Expres-
sions: Constructing Descriptions in a Domain of
Objects and Processes. MIT Press, Cambridge,
MA.
Henriette de Swart. 1998. Introduction to Natural
Language Semantics. CSLI Publications.
Michael Elhadad and Jacques Robin. 1992. Con-
trolling content realization with functional unifi-
cation grammars. In Aspects of Automated Nat-
ural Language Generation, Lecture Notes in Ar-
tificial Intelligence, 587, pages 89-104. Springer-
Verlag, Berlin, April.
Pierre-Joseph Gailly. 1988. Expressing quantifier
scope in French generation. In Proceedings of the
12th International Conference on Computational
Linguistics (COLING-88), volume 1, pages 182-
184, Budapest, August 22-27,.
Barbara J. Gros4, Douglas E. Appelt, Paul A.
Martin, and Fernando C. N. Pereira. 1987.
TEAM: An experiment in the design of trans-
portable natural-language interfaces. Artificial
Intelligence, 32(2):I73-243, May.
Jerry Hobbs and Stuart Shieber. 1987. An algo-
rithm for generating quantifier scopings. Compu-
tational Linguistics, 13(1-2):47-63, January-June.
Helmut Horacek. 1997. An algorithm for generating
referential descriptions with flexible interfaces. In
Proc. of the 35th ACL and 8th LA CL, pages 206-
213.
Ronald M. Kaplan and Joan Bresnan. 1982.
-Lexical-functional ,grarnmar:, A formal system-for
grammatical representation. In Joan Bresnan, ed-
itor, The Mental Representation of Grammatical
Relations, chapter 4. MIT Press.
Martin Kay. 1979. Functional grammar. In Proceed-
ings of the 5th Annual Meeting of the Berkeley
Linguistic Society, pages 142-158, Berkeley, CA,
February 17-19,.
Alistair Knott, Mick O&apos;Donnell, .Ion Oberlander.
and Chris Mellish. 1997. Defeasible rules in con-
tent selection and text structuring. In Proc. of
the 6th European Workshop on Natural Language
Generation, Duisburg, Germany.
</reference>
<page confidence="0.939298">
106
</page>
<reference confidence="0.996959602739726">
James D. McCawley. 1981. Everything that linguists
have always wanted to know about logic (but were
ashamed to ask). University of Chicago Press.
Kathleen McKeown, Shimei Pan, James Shaw,
Desmond Jordan, and Barry Allen. 1997. Lan-
guage generation for multimedia healthcare brief-
ings. In Proc. of the FiftfrACL. Confn-
pages 277-282.
Kathleen R. McKeown. 1985. Tent Generation: Us-
ing Discourse Strategies and Focus Constraints to
Generate Natural Language Text. Cambridge Uni-
versity Press, Cambridge.
Chris Mellish, Mick O&apos;Donnell, Jon Oberlander. and
Alistair Knott. 1998. An architecture for oppor-
tunistic text generation. In Proc. of the 9th Inter-
national Workshop on Natural Language Genera-
tion., pages 28-37.
George Miller, Richard Beckwith, Christiane Fell-
baum, Derek Gross, and Katherine Miller. 1990.
Five papers on WordNet. CSL Report 43, Cogni-
tive Science Laboratory, Princeton University.
Douglas B. Moran and Fernando C. N. Pereira.
1992. Quantifier scoping. In Hiyan Alshawi, ed-
itor, The Core Language Engine, pages 149-172.
MIT Press, Cambridge, MA.
Jong C. Park. 1995. Quantifier scope and con-
stituency. In Proc. of the 33rd ACL, pages 205--
212.
Rebecca Passonneau, Karen Kukich, Vasileios Hatzi-
vassiloglou, Larry Lefl&lt;owitz, and Hongyan Jing.
1996. Generating summaries of work- flow di-
agrams. In Proc. of the International Confer-
ence on Natural Language Processing and Indus-
trial Applications, pages 204-210, New Brunswick,
Canada. University of Moncton.
Fernando C. N. Pereira. 1990. Categorial semantics
and scoping. Computational Linguistics, 16(1):1-
10
Owen Rambow and Tanya Norelsky. 1992. Applied
text generation. In Proceedings of the Third A CL
Conference on Applied Natural Language Process-
thy, pages 40-47, Trento, Italy.
Eltud Reiter and Robert Dale. 1992. A fast algo-
rithm for the generation of referring expressions.
In Proceedings of the 14th International Con-
ference on Computational Linguistics (COLING-
92), pages 232-238, Nantes, France.
Jacques Robin. 1995. Herision-Based Generation of
Natural Language Slim in antes Pro riding Historical
Background. Ph.D. thesis, Columbia University.
James Shaw. 1998. Segregator.), coordination and el-
lipsis in text generation. In Proc. of the I7th COL-
I.VG and the 36th Annual Meeting of the ACL..
pages 1220-1226.
Jan van Eijck and Hiyan Alsliawi. 1992. Logical
forms. In I fiyan Alshawi, editor, The Core Lan-
guage Engine, pages 11-38. MIT Press, Cam-
bridge, MA.
Zeno Veridler. 1967. Each and every, any and all.
In Linguistics in Philosophy, pages 70-96. Cornell
University Press, Ithaca and London.
Leo Wanner and Eduard flovy. 1996. The Health-
,.D.on,:sentence planner:- In-- Proc.. .of,the -8th Inter-
national Workshop on Natural Language Genera-
tion, pages 1-10, Sussex, UK,
William A. Woods. 1978. Semantics and quantifi-
cation in natural language question answering. In
Advances in Computers, volume 17, pages 1-87.
Academic Press.
Frans Zwarts. 1983. Determiners: a relational
perspective. In A. ter Meulen, editor, Studies
in model-theoretic semantics, pages 37-62. Dor-
drecht: Foris.
</reference>
<page confidence="0.99869">
107
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.650000">
<title confidence="0.999949">Generating Referring Quantified Expressions</title>
<author confidence="0.995558">Shaw</author>
<affiliation confidence="0.828471">Computer Columbia</affiliation>
<address confidence="0.998368">York, 10027,</address>
<email confidence="0.999782">shaw,kathyOcs.columbia.edu</email>
<abstract confidence="0.998635166666667">In this paper, we describe how quantifiers can be generated in a text generation system. By taking advantage of discourse and ontological information, quantified expressions can replace entities in a text, making the text more fluent and concise. In addition to avoiding ambiguities between distributive and collective readings in universal quantification generation, we will also show how different scope orderings between universal and existential quantifiers will result in different quantified expressions in our algorithm.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jon Barwise</author>
<author>Robin Cooper</author>
</authors>
<title>Generalized quantifiers and natural language. Linguistics and Philosophy,</title>
<date>1981</date>
<pages>4--159</pages>
<contexts>
<context position="11870" citStr="Barwise and Cooper, 1981" startWordPosition="1817" endWordPosition="1820">RED, ARG1, ARG2, and MODS-TIME. By computing similarity among entities in the same role, the system determines that the entities in A RG1, FRED, and AR.G2 are identical in each role, and only the entities in MODS-TIME are different. Based on this result, the distinct entities in MODS-TIME, &amp;quot;after intubation&amp;quot; and &amp;quot;after start of bypass&amp;quot;, are candidates for quantification. 4.2 Generalization and Quantification We used the axioms in Figure 2 to determine if the distinct entities can he universally or existentially quantified. Though the axioms are similar to those used in Generalized Quantifier (Barwise and Cooper, 1981; Zwarts. 1983; de Swart. 1998). the semantics of set X and set D are different. In the previous step. the entities in set X have been identified. To compute set D in Figure 2. we introduce a concept, Class-X. Class-X is a generalLation of the distinct entities in set X. Quantification can replace the distinct entities in the propositions with. a reference to their type restricted by a quantifier. accessing discourse and ontological information to provide a context. Our ontology is implemented in Figure 2: Axioms of the quantifiers discussed in this paper. CLASSIC(Borgida et al., 1989) and is </context>
</contexts>
<marker>Barwise, Cooper, 1981</marker>
<rawString>Jon Barwise and Robin Cooper. 1981. Generalized quantifiers and natural language. Linguistics and Philosophy, 4:159-219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Borgida</author>
<author>Ronald Brachman</author>
<author>Deborah McGuinness</author>
<author>Lori Alperin Resnick</author>
</authors>
<title>CLASSIC: A structural data model for objects.</title>
<date>1989</date>
<booktitle>In ACM SIGMOD International Conference on Management of Data.</booktitle>
<contexts>
<context position="12462" citStr="Borgida et al., 1989" startWordPosition="1916" endWordPosition="1919">ier (Barwise and Cooper, 1981; Zwarts. 1983; de Swart. 1998). the semantics of set X and set D are different. In the previous step. the entities in set X have been identified. To compute set D in Figure 2. we introduce a concept, Class-X. Class-X is a generalLation of the distinct entities in set X. Quantification can replace the distinct entities in the propositions with. a reference to their type restricted by a quantifier. accessing discourse and ontological information to provide a context. Our ontology is implemented in Figure 2: Axioms of the quantifiers discussed in this paper. CLASSIC(Borgida et al., 1989) and is a subset of WordNet(Miller et al., 1990) and an online medical dictionary (Cimino et al., 1994) designed to support multiple applications across the medical institution. Given the entities in set X, queries in CLASSIC determine the class of each instance and its ancestors in the ontology. Based on this information, the generalization algorithm identifies Class-X by computing the most specific class which covers all the entities. Earlier work (Passonneau et at., 1996) provided a framework for balancing specificity and verbosity in selecting appropriate concepts for generalization. Howev</context>
</contexts>
<marker>Borgida, Brachman, McGuinness, Resnick, 1989</marker>
<rawString>Alexander Borgida, Ronald Brachman, Deborah McGuinness, and Lori Alperin Resnick. 1989. CLASSIC: A structural data model for objects. In ACM SIGMOD International Conference on Management of Data.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
</authors>
<title>Type-Logical Semantics.</title>
<date>1997</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="1404" citStr="Carpenter, 1997" startWordPosition="209" endWordPosition="211">stems often perform opportunistic text planning (Robin, 1995; Mellish et al., 1998) and employ advanced linguistic constructions such as ellipsis (Sliaw, 1998). But a system can also take advantage of quantification and ontological information to generate concise references to entities at the discourse level. For example, a sentence such as The patient has an infusion line in each arm.&amp;quot; is a more concise version of &amp;quot;The patient has an infusion line in his left arm. The patient has an infusion line in his right arm.&amp;quot; Quantification is an active research topic in logic, language, and philosophy(Carpenter, 1997; de Swart. 1998). Since natural language understanding systems need to .obLain as few interpretations as possible from text, researchers have studied quantifier scope ambiguity extensively (Woods, 1978; --Grosz et al., .1987; Hobbs and Shieber. 1987; Pereira, 1990; Moran and Pereira, 1992; Park, 1995). Research in quantification interpretation first transforms a sentence into predicate logic, raises the quantifiers to the sentential level, and permutes these quantifiers to obtain as many readings as possible related to quantifier scoping. Then. invalid readings are eliminated using various co</context>
</contexts>
<marker>Carpenter, 1997</marker>
<rawString>Bob Carpenter. 1997. Type-Logical Semantics. MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Paul D Clayton Cimino</author>
<author>George Hripcsak</author>
<author>B Stephen</author>
</authors>
<title>Johnson 1994_ Knowledgebased approaches to the maintenance of a large controlled medical terminology.</title>
<journal>The Journal of the American Medical Informatics Association,</journal>
<pages>1--1</pages>
<marker>Cimino, Hripcsak, Stephen, </marker>
<rawString>James 3. Cimino, Paul D. Clayton, George Hripcsak, and Stephen B. Johnson 1994_ Knowledgebased approaches to the maintenance of a large controlled medical terminology. The Journal of the American Medical Informatics Association, 1(1):3.5-50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl J Pollard</author>
</authors>
<title>Minimal recursion semantics: An introduction. Manuscript available via littp://lingo.stanford.eduipubs.html.</title>
<date>1999</date>
<marker>Pollard, 1999</marker>
<rawString>Ann Copestake, Dan Flickinger, Ivan A. Sag. and Carl J. Pollard. 1999. Minimal recursion semantics: An introduction. Manuscript available via littp://lingo.stanford.eduipubs.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Norman Crea ney</author>
</authors>
<title>An algorithm for generating quantifiers.</title>
<date>1996</date>
<booktitle>In Proc. of the 8th International Workshop on Natural Language Generation,</booktitle>
<location>Sussex, Lk.</location>
<contexts>
<context position="5754" citStr="ney, 1996" startWordPosition="873" endWordPosition="874">gs. Section 5 describes how our algorithm generates sentences with multiple quantifiers. 2 Related Work Because a quantified expression refers to multiple entities in a domain, our work can be categorized as referring expression generation (Dale, 1992; Reiter and Dale, 1992; Horacek, 1997). Previous work in this area did not address the generation of quantified expressions directly. In this paper, we are interested in how to systematically derive quantifiers from input propositions, discourse history, and ontological information. Recent work on the generation of quantifiers (Gailly, 1988; Creaney, 1996; Creaney, 1999) follows the analysis viewpoint, discussing scope ambiguities extensively. Though our algorithm generates different sentences for different scope orderings, we do not achieve this through scoping operations as they did. Creaney also discussed various imprecise quantifiers, such as some, at least, and at most. In regards to generating generic quantified expressions, (Knott et al., 1997) has proposed an algorithm for generating defeasible, but informative descriptions for objects in museums. Other researchers (van Eijck and Alshawi. 1992; Copestake et. at., 1999) proposed represe</context>
</contexts>
<marker>ney, 1996</marker>
<rawString>Norman Crea.ney, 1996. An algorithm for generating quantifiers. In Proc. of the 8th International Workshop on Natural Language Generation, Sussex, Lk.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Norman Creaney</author>
</authors>
<title>Generating quantified logical forms from raw data.</title>
<date>1999</date>
<booktitle>In Proc. of the ESSLLI99 Workshop on the Generation of Nominal Expressions.</booktitle>
<contexts>
<context position="5770" citStr="Creaney, 1999" startWordPosition="875" endWordPosition="876"> 5 describes how our algorithm generates sentences with multiple quantifiers. 2 Related Work Because a quantified expression refers to multiple entities in a domain, our work can be categorized as referring expression generation (Dale, 1992; Reiter and Dale, 1992; Horacek, 1997). Previous work in this area did not address the generation of quantified expressions directly. In this paper, we are interested in how to systematically derive quantifiers from input propositions, discourse history, and ontological information. Recent work on the generation of quantifiers (Gailly, 1988; Creaney, 1996; Creaney, 1999) follows the analysis viewpoint, discussing scope ambiguities extensively. Though our algorithm generates different sentences for different scope orderings, we do not achieve this through scoping operations as they did. Creaney also discussed various imprecise quantifiers, such as some, at least, and at most. In regards to generating generic quantified expressions, (Knott et al., 1997) has proposed an algorithm for generating defeasible, but informative descriptions for objects in museums. Other researchers (van Eijck and Alshawi. 1992; Copestake et. at., 1999) proposed representations- in a m</context>
</contexts>
<marker>Creaney, 1999</marker>
<rawString>Norman Creaney. 1999. Generating quantified logical forms from raw data. In Proc. of the ESSLLI99 Workshop on the Generation of Nominal Expressions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dalai-</author>
<author>S Feiner</author>
<author>K McKeown</author>
<author>D Jordan</author>
<author>B Allen</author>
<author>Y alSafadi</author>
</authors>
<title>MAGIC: An ..,expecimental -systern.int. .generating...multimedia briefings about post-bypass patient status.</title>
<date>1996</date>
<booktitle>In Proc. 1996 AMIA Annual Fall Symp,</booktitle>
<pages>684--688</pages>
<location>Washington, DC,</location>
<marker>Dalai-, Feiner, McKeown, Jordan, Allen, alSafadi, 1996</marker>
<rawString>M. Dalai-, S. Feiner, K. McKeown, D. Jordan, B. Allen, and Y. alSafadi. 1996. MAGIC: An ..,expecimental -systern.int. .generating...multimedia briefings about post-bypass patient status. In Proc. 1996 AMIA Annual Fall Symp, pages 684-688, Washington, DC, October 26-30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Dale</author>
<author>Ehud Reiter</author>
</authors>
<title>Computational interpretations of the gricean maxims in the generation of referring expressions.</title>
<date>1995</date>
<journal>Cognitive Science,</journal>
<pages>19--233</pages>
<contexts>
<context position="10178" citStr="Dale and Reiter, 1995" startWordPosition="1554" endWordPosition="1557">ive reading text. The default heuristics to prefer universal quan- • every, all, the: ID- XI 0 and IXI &gt; 2, can tifier over conjunction over cardinal quantifier can have collective reading be superseded by directives from the content-plan- • each: ID - Xl = 0 and IXI &gt; 2, only distribuner which are application specific. tive reading The input to our quaatification,algorithm is a set a any: ID - XI = 0, when under the scope of of predicate-argument structures after the referring negation expression module selected the properties to identify a a/an: 1Dnxl&gt; 0 and IX = 1 the entities (Dale, 1992; Dale and Reiter, 1995), but • n (cardinal): IDnXI &gt; 0 and IXI = n without carrying out the assignment of quantifiers. Our quantification algorithm first identifies the set of distinct entities which can be quantified in the input propositions. A generalization of the entities in the ontology is selected to potentially replace the references to these entities. If universal quantification is possible, then the replacement is made and the system must select which particular quantifier to use. In our system, we have six realizations for universal quantifiers: each, every, all-I, both, the, and any, and two for existent</context>
</contexts>
<marker>Dale, Reiter, 1995</marker>
<rawString>Robert Dale and Ehud Reiter. 1995. Computational interpretations of the gricean maxims in the generation of referring expressions. Cognitive Science, 19:233-263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Dale</author>
</authors>
<title>Generating Referring Expressions: Constructing Descriptions in a Domain of Objects and Processes.</title>
<date>1992</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="5396" citStr="Dale, 1992" startWordPosition="820" endWordPosition="821">.approach with previous work in the generation of quantified expressions. In Section 3, we will describe the application where the need for concise output motivated our research in quantification. The algorithm for generating universal quantifiers is detailed in Section 4, including how the system handles ambiguity between distributive and collective readings. Section 5 describes how our algorithm generates sentences with multiple quantifiers. 2 Related Work Because a quantified expression refers to multiple entities in a domain, our work can be categorized as referring expression generation (Dale, 1992; Reiter and Dale, 1992; Horacek, 1997). Previous work in this area did not address the generation of quantified expressions directly. In this paper, we are interested in how to systematically derive quantifiers from input propositions, discourse history, and ontological information. Recent work on the generation of quantifiers (Gailly, 1988; Creaney, 1996; Creaney, 1999) follows the analysis viewpoint, discussing scope ambiguities extensively. Though our algorithm generates different sentences for different scope orderings, we do not achieve this through scoping operations as they did. Creane</context>
<context position="10154" citStr="Dale, 1992" startWordPosition="1552" endWordPosition="1553">he con- lective reading text. The default heuristics to prefer universal quan- • every, all, the: ID- XI 0 and IXI &gt; 2, can tifier over conjunction over cardinal quantifier can have collective reading be superseded by directives from the content-plan- • each: ID - Xl = 0 and IXI &gt; 2, only distribuner which are application specific. tive reading The input to our quaatification,algorithm is a set a any: ID - XI = 0, when under the scope of of predicate-argument structures after the referring negation expression module selected the properties to identify a a/an: 1Dnxl&gt; 0 and IX = 1 the entities (Dale, 1992; Dale and Reiter, 1995), but • n (cardinal): IDnXI &gt; 0 and IXI = n without carrying out the assignment of quantifiers. Our quantification algorithm first identifies the set of distinct entities which can be quantified in the input propositions. A generalization of the entities in the ontology is selected to potentially replace the references to these entities. If universal quantification is possible, then the replacement is made and the system must select which particular quantifier to use. In our system, we have six realizations for universal quantifiers: each, every, all-I, both, the, and a</context>
</contexts>
<marker>Dale, 1992</marker>
<rawString>Robert Dale. 1992. Generating Referring Expressions: Constructing Descriptions in a Domain of Objects and Processes. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henriette de Swart</author>
</authors>
<title>Introduction to Natural Language Semantics.</title>
<date>1998</date>
<publisher>CSLI Publications.</publisher>
<marker>de Swart, 1998</marker>
<rawString>Henriette de Swart. 1998. Introduction to Natural Language Semantics. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Elhadad</author>
<author>Jacques Robin</author>
</authors>
<title>Controlling content realization with functional unification grammars.</title>
<date>1992</date>
<journal>In Aspects of Automated Natural Language Generation, Lecture Notes in Artificial Intelligence,</journal>
<volume>587</volume>
<pages>89--104</pages>
<publisher>SpringerVerlag,</publisher>
<location>Berlin,</location>
<marker>Elhadad, Robin, 1992</marker>
<rawString>Michael Elhadad and Jacques Robin. 1992. Controlling content realization with functional unification grammars. In Aspects of Automated Natural Language Generation, Lecture Notes in Artificial Intelligence, 587, pages 89-104. SpringerVerlag, Berlin, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre-Joseph Gailly</author>
</authors>
<title>Expressing quantifier scope in French generation.</title>
<date>1988</date>
<booktitle>In Proceedings of the 12th International Conference on Computational Linguistics (COLING-88),</booktitle>
<volume>1</volume>
<pages>182--184</pages>
<location>Budapest,</location>
<contexts>
<context position="5739" citStr="Gailly, 1988" startWordPosition="871" endWordPosition="872"> collective readings. Section 5 describes how our algorithm generates sentences with multiple quantifiers. 2 Related Work Because a quantified expression refers to multiple entities in a domain, our work can be categorized as referring expression generation (Dale, 1992; Reiter and Dale, 1992; Horacek, 1997). Previous work in this area did not address the generation of quantified expressions directly. In this paper, we are interested in how to systematically derive quantifiers from input propositions, discourse history, and ontological information. Recent work on the generation of quantifiers (Gailly, 1988; Creaney, 1996; Creaney, 1999) follows the analysis viewpoint, discussing scope ambiguities extensively. Though our algorithm generates different sentences for different scope orderings, we do not achieve this through scoping operations as they did. Creaney also discussed various imprecise quantifiers, such as some, at least, and at most. In regards to generating generic quantified expressions, (Knott et al., 1997) has proposed an algorithm for generating defeasible, but informative descriptions for objects in museums. Other researchers (van Eijck and Alshawi. 1992; Copestake et. at., 1999) p</context>
</contexts>
<marker>Gailly, 1988</marker>
<rawString>Pierre-Joseph Gailly. 1988. Expressing quantifier scope in French generation. In Proceedings of the 12th International Conference on Computational Linguistics (COLING-88), volume 1, pages 182-184, Budapest, August 22-27,.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Gros4</author>
<author>Douglas E Appelt</author>
<author>Paul A Martin</author>
<author>Fernando C N Pereira</author>
</authors>
<date>1987</date>
<marker>Gros4, Appelt, Martin, Pereira, 1987</marker>
<rawString>Barbara J. Gros4, Douglas E. Appelt, Paul A. Martin, and Fernando C. N. Pereira. 1987.</rawString>
</citation>
<citation valid="true">
<title>TEAM: An experiment in the design of transportable natural-language interfaces.</title>
<date></date>
<journal>Artificial Intelligence,</journal>
<pages>32--2</pages>
<marker></marker>
<rawString>TEAM: An experiment in the design of transportable natural-language interfaces. Artificial Intelligence, 32(2):I73-243, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry Hobbs</author>
<author>Stuart Shieber</author>
</authors>
<title>An algorithm for generating quantifier scopings.</title>
<date>1987</date>
<journal>Computational Linguistics,</journal>
<pages>13--1</pages>
<location>January-June.</location>
<marker>Hobbs, Shieber, 1987</marker>
<rawString>Jerry Hobbs and Stuart Shieber. 1987. An algorithm for generating quantifier scopings. Computational Linguistics, 13(1-2):47-63, January-June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Horacek</author>
</authors>
<title>An algorithm for generating referential descriptions with flexible interfaces.</title>
<date>1997</date>
<booktitle>In Proc. of the 35th ACL and 8th LA CL,</booktitle>
<pages>206--213</pages>
<contexts>
<context position="5435" citStr="Horacek, 1997" startWordPosition="826" endWordPosition="827"> generation of quantified expressions. In Section 3, we will describe the application where the need for concise output motivated our research in quantification. The algorithm for generating universal quantifiers is detailed in Section 4, including how the system handles ambiguity between distributive and collective readings. Section 5 describes how our algorithm generates sentences with multiple quantifiers. 2 Related Work Because a quantified expression refers to multiple entities in a domain, our work can be categorized as referring expression generation (Dale, 1992; Reiter and Dale, 1992; Horacek, 1997). Previous work in this area did not address the generation of quantified expressions directly. In this paper, we are interested in how to systematically derive quantifiers from input propositions, discourse history, and ontological information. Recent work on the generation of quantifiers (Gailly, 1988; Creaney, 1996; Creaney, 1999) follows the analysis viewpoint, discussing scope ambiguities extensively. Though our algorithm generates different sentences for different scope orderings, we do not achieve this through scoping operations as they did. Creaney also discussed various imprecise quan</context>
</contexts>
<marker>Horacek, 1997</marker>
<rawString>Helmut Horacek. 1997. An algorithm for generating referential descriptions with flexible interfaces. In Proc. of the 35th ACL and 8th LA CL, pages 206-213.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald M Kaplan</author>
<author>Joan Bresnan</author>
</authors>
<title>Lexical-functional ,grarnmar:, A formal system-for grammatical representation.</title>
<date>1982</date>
<booktitle>The Mental Representation of Grammatical Relations, chapter 4.</booktitle>
<editor>In Joan Bresnan, editor,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="8248" citStr="Kaplan and Bresnan, 1982" startWordPosition="1239" endWordPosition="1242">tion that is automatically collected during surgery such as blood pressure, heart rate, and medications given, is sent to a domain-specific medical inference module. Based on the medical inferences and schemas (McKeown, 1985), the content planner determines the information to convey and the order to convey it. The sentence planner takes a set of propositions (or predicate-argument structures) with rhetorical relations from the content planner and uses linguistic information to make decisions about how to convey the propositions fluently. Each proposition is represented as a feature structure (Kaplan and Bresnan, 1982; Kay, 1979) similar to the one shown in Figure 1. The sentence planner&apos;s responsibilities include referring expression generation, clause aggregation, and lexical choice (Wanner and Hovy, 1996). Then the aggregated predicate-argument structure is sent to FUF/SURGE (Elhadad and Robin, 199?), a linguistic realizer which transforms the lexicalized Semantic specification into a string. The quantification algorithm is implemented in the sentence planner. 4 Quantification Algorithm In this -..work,..we • prefer -generating expressions with universal quantifiers over conjunction because, assuming th</context>
</contexts>
<marker>Kaplan, Bresnan, 1982</marker>
<rawString>Ronald M. Kaplan and Joan Bresnan. 1982. -Lexical-functional ,grarnmar:, A formal system-for grammatical representation. In Joan Bresnan, editor, The Mental Representation of Grammatical Relations, chapter 4. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>Functional grammar.</title>
<date>1979</date>
<booktitle>In Proceedings of the 5th Annual Meeting of the Berkeley Linguistic Society,</booktitle>
<pages>142--158</pages>
<location>Berkeley, CA,</location>
<contexts>
<context position="8260" citStr="Kay, 1979" startWordPosition="1243" endWordPosition="1244"> collected during surgery such as blood pressure, heart rate, and medications given, is sent to a domain-specific medical inference module. Based on the medical inferences and schemas (McKeown, 1985), the content planner determines the information to convey and the order to convey it. The sentence planner takes a set of propositions (or predicate-argument structures) with rhetorical relations from the content planner and uses linguistic information to make decisions about how to convey the propositions fluently. Each proposition is represented as a feature structure (Kaplan and Bresnan, 1982; Kay, 1979) similar to the one shown in Figure 1. The sentence planner&apos;s responsibilities include referring expression generation, clause aggregation, and lexical choice (Wanner and Hovy, 1996). Then the aggregated predicate-argument structure is sent to FUF/SURGE (Elhadad and Robin, 199?), a linguistic realizer which transforms the lexicalized Semantic specification into a string. The quantification algorithm is implemented in the sentence planner. 4 Quantification Algorithm In this -..work,..we • prefer -generating expressions with universal quantifiers over conjunction because, assuming that the users</context>
</contexts>
<marker>Kay, 1979</marker>
<rawString>Martin Kay. 1979. Functional grammar. In Proceedings of the 5th Annual Meeting of the Berkeley Linguistic Society, pages 142-158, Berkeley, CA, February 17-19,.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Mellish</author>
</authors>
<title>Defeasible rules in content selection and text structuring.</title>
<date>1997</date>
<booktitle>In Proc. of the 6th European Workshop on Natural Language Generation,</booktitle>
<location>Duisburg, Germany.</location>
<marker>Mellish, 1997</marker>
<rawString>Alistair Knott, Mick O&apos;Donnell, .Ion Oberlander. and Chris Mellish. 1997. Defeasible rules in content selection and text structuring. In Proc. of the 6th European Workshop on Natural Language Generation, Duisburg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James D McCawley</author>
</authors>
<title>Everything that linguists have always wanted to know about logic (but were ashamed to ask).</title>
<date>1981</date>
<publisher>University of Chicago Press.</publisher>
<contexts>
<context position="18321" citStr="McCawley, 1981" startWordPosition="2852" endWordPosition="2853">can be used to replace the entities in set X, it must select which universal quantifier. Because our sentence planner opportunistically combines distinct entries from separate database entries for conciseness, it is not the case that these aggregated entities acted together (the collective reading). Given such input, the referring expression for aggregated entities should have only the distributive reading2. The universal quantifier, each, always imposes a distributive reading when applied. In general, each requires a &amp;quot;matching&amp;quot; between the domain of the quantifier and the objects referred to(McCawley, 1981, pp. 37). In our algorithm, this matching process is exactly what happened, thus it is the default universal quantifier in our algorithm. Of course, indiscriminate use of each can result in awkward sounding text. For example, the sentence &amp;quot;Every patient is awake&amp;quot; sounds more natural than &amp;quot;Each patient is awake.&amp;quot; However, since quantified expressions with the universal quantifiers all and every3 can have collective readings (Vendler, 1967; McCawley, 1981), our system generates every and all under two conditions when the collective reading is unlikely. First if the proposition is a state, as op</context>
</contexts>
<marker>McCawley, 1981</marker>
<rawString>James D. McCawley. 1981. Everything that linguists have always wanted to know about logic (but were ashamed to ask). University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen McKeown</author>
<author>Shimei Pan</author>
<author>James Shaw</author>
<author>Desmond Jordan</author>
<author>Barry Allen</author>
</authors>
<title>Language generation for multimedia healthcare briefings.</title>
<date>1997</date>
<booktitle>In Proc. of the FiftfrACL. Confnpages</booktitle>
<pages>277--282</pages>
<contexts>
<context position="6922" citStr="McKeown et al., 1997" startWordPosition="1045" endWordPosition="1048">hawi. 1992; Copestake et. at., 1999) proposed representations- in a machine translation setting which allow underspecification in regard to quantifier scope. Our work is different in that we perform quantification directly on the instance-based representation obtained from database tuples. Our input -does not have the in-. formation about which entities are quantified as is the case in ma.cliine translation, where the quantifiers are already specified in the input from a source language. 3 The Application Domain We implemented our quantification algorithm as part of MAGIC (Dalai et al.. 1996: McKeown et al., 1997). MAGIC automatically generates multimedia briefings to describe the post-operative status of a patient after undergoing Coronary Artery Bypass Graft surgery. The system embodies a stan((TYPE EVENT) (PRED ((PRED receive) (ID idl))) (ARG1 ((PRED patient) (ID pt1))) (ARG2 ((FRED aprotinin) (ID apt))) (NODS ((PRED after) (ID id2) _ -(TYPE.TINE) (ARG2 ((FRED critical-point) (NAME intubation) (ID c1))) ) ) ) Figure 1: The predicate-argument structure of &amp;quot;After intubation, a patient received aprotinin.&amp;quot; dard text generation system architecture with three modules (Rambow and Korelsky, 1992): a conten</context>
</contexts>
<marker>McKeown, Pan, Shaw, Jordan, Allen, 1997</marker>
<rawString>Kathleen McKeown, Shimei Pan, James Shaw, Desmond Jordan, and Barry Allen. 1997. Language generation for multimedia healthcare briefings. In Proc. of the FiftfrACL. Confnpages 277-282.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen R McKeown</author>
</authors>
<title>Tent Generation: Using Discourse Strategies and Focus Constraints to Generate Natural Language Text.</title>
<date>1985</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="7849" citStr="McKeown, 1985" startWordPosition="1182" endWordPosition="1183">after) (ID id2) _ -(TYPE.TINE) (ARG2 ((FRED critical-point) (NAME intubation) (ID c1))) ) ) ) Figure 1: The predicate-argument structure of &amp;quot;After intubation, a patient received aprotinin.&amp;quot; dard text generation system architecture with three modules (Rambow and Korelsky, 1992): a content planner, a sentence planner, and a linguistic realizer. Once the bypass surgery ia finished, information that is automatically collected during surgery such as blood pressure, heart rate, and medications given, is sent to a domain-specific medical inference module. Based on the medical inferences and schemas (McKeown, 1985), the content planner determines the information to convey and the order to convey it. The sentence planner takes a set of propositions (or predicate-argument structures) with rhetorical relations from the content planner and uses linguistic information to make decisions about how to convey the propositions fluently. Each proposition is represented as a feature structure (Kaplan and Bresnan, 1982; Kay, 1979) similar to the one shown in Figure 1. The sentence planner&apos;s responsibilities include referring expression generation, clause aggregation, and lexical choice (Wanner and Hovy, 1996). Then </context>
</contexts>
<marker>McKeown, 1985</marker>
<rawString>Kathleen R. McKeown. 1985. Tent Generation: Using Discourse Strategies and Focus Constraints to Generate Natural Language Text. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alistair Knott</author>
</authors>
<title>An architecture for opportunistic text generation.</title>
<date>1998</date>
<booktitle>In Proc. of the 9th International Workshop on Natural Language Generation.,</booktitle>
<pages>28--37</pages>
<marker>Knott, 1998</marker>
<rawString>Chris Mellish, Mick O&apos;Donnell, Jon Oberlander. and Alistair Knott. 1998. An architecture for opportunistic text generation. In Proc. of the 9th International Workshop on Natural Language Generation., pages 28-37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Miller</author>
<author>Richard Beckwith</author>
<author>Christiane Fellbaum</author>
<author>Derek Gross</author>
<author>Katherine Miller</author>
</authors>
<title>Five papers on WordNet.</title>
<date>1990</date>
<tech>CSL Report 43,</tech>
<institution>Cognitive Science Laboratory, Princeton University.</institution>
<contexts>
<context position="12510" citStr="Miller et al., 1990" startWordPosition="1925" endWordPosition="1928">wart. 1998). the semantics of set X and set D are different. In the previous step. the entities in set X have been identified. To compute set D in Figure 2. we introduce a concept, Class-X. Class-X is a generalLation of the distinct entities in set X. Quantification can replace the distinct entities in the propositions with. a reference to their type restricted by a quantifier. accessing discourse and ontological information to provide a context. Our ontology is implemented in Figure 2: Axioms of the quantifiers discussed in this paper. CLASSIC(Borgida et al., 1989) and is a subset of WordNet(Miller et al., 1990) and an online medical dictionary (Cimino et al., 1994) designed to support multiple applications across the medical institution. Given the entities in set X, queries in CLASSIC determine the class of each instance and its ancestors in the ontology. Based on this information, the generalization algorithm identifies Class-X by computing the most specific class which covers all the entities. Earlier work (Passonneau et at., 1996) provided a framework for balancing specificity and verbosity in selecting appropriate concepts for generalization. However, given the precision needed in medical report</context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1990</marker>
<rawString>George Miller, Richard Beckwith, Christiane Fellbaum, Derek Gross, and Katherine Miller. 1990. Five papers on WordNet. CSL Report 43, Cognitive Science Laboratory, Princeton University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas B Moran</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Quantifier scoping.</title>
<date>1992</date>
<booktitle>In Hiyan Alshawi, editor, The Core Language Engine,</booktitle>
<pages>149--172</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1694" citStr="Moran and Pereira, 1992" startWordPosition="252" endWordPosition="255">ties at the discourse level. For example, a sentence such as The patient has an infusion line in each arm.&amp;quot; is a more concise version of &amp;quot;The patient has an infusion line in his left arm. The patient has an infusion line in his right arm.&amp;quot; Quantification is an active research topic in logic, language, and philosophy(Carpenter, 1997; de Swart. 1998). Since natural language understanding systems need to .obLain as few interpretations as possible from text, researchers have studied quantifier scope ambiguity extensively (Woods, 1978; --Grosz et al., .1987; Hobbs and Shieber. 1987; Pereira, 1990; Moran and Pereira, 1992; Park, 1995). Research in quantification interpretation first transforms a sentence into predicate logic, raises the quantifiers to the sentential level, and permutes these quantifiers to obtain as many readings as possible related to quantifier scoping. Then. invalid readings are eliminated using various constraints. Ambiguity in quantified expressions is caused by two main culprits. The first type of ambiguity involves the distributive reading versus the collective reading. In universal quantification, a referring expression refers to multiple entities. There is a potential ambiguity betwee</context>
</contexts>
<marker>Moran, Pereira, 1992</marker>
<rawString>Douglas B. Moran and Fernando C. N. Pereira. 1992. Quantifier scoping. In Hiyan Alshawi, editor, The Core Language Engine, pages 149-172. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jong C Park</author>
</authors>
<title>Quantifier scope and constituency.</title>
<date>1995</date>
<booktitle>In Proc. of the 33rd ACL,</booktitle>
<pages>205--212</pages>
<contexts>
<context position="1707" citStr="Park, 1995" startWordPosition="256" endWordPosition="257">el. For example, a sentence such as The patient has an infusion line in each arm.&amp;quot; is a more concise version of &amp;quot;The patient has an infusion line in his left arm. The patient has an infusion line in his right arm.&amp;quot; Quantification is an active research topic in logic, language, and philosophy(Carpenter, 1997; de Swart. 1998). Since natural language understanding systems need to .obLain as few interpretations as possible from text, researchers have studied quantifier scope ambiguity extensively (Woods, 1978; --Grosz et al., .1987; Hobbs and Shieber. 1987; Pereira, 1990; Moran and Pereira, 1992; Park, 1995). Research in quantification interpretation first transforms a sentence into predicate logic, raises the quantifiers to the sentential level, and permutes these quantifiers to obtain as many readings as possible related to quantifier scoping. Then. invalid readings are eliminated using various constraints. Ambiguity in quantified expressions is caused by two main culprits. The first type of ambiguity involves the distributive reading versus the collective reading. In universal quantification, a referring expression refers to multiple entities. There is a potential ambiguity between whether the</context>
</contexts>
<marker>Park, 1995</marker>
<rawString>Jong C. Park. 1995. Quantifier scope and constituency. In Proc. of the 33rd ACL, pages 205--212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Passonneau</author>
<author>Karen Kukich</author>
<author>Vasileios Hatzivassiloglou</author>
<author>Larry Leflowitz</author>
<author>Hongyan Jing</author>
</authors>
<title>Generating summaries of work- flow diagrams.</title>
<date>1996</date>
<booktitle>In Proc. of the International Conference on Natural Language Processing and Industrial Applications,</booktitle>
<pages>204--210</pages>
<institution>Canada. University of Moncton.</institution>
<location>New Brunswick,</location>
<marker>Passonneau, Kukich, Hatzivassiloglou, Leflowitz, Jing, 1996</marker>
<rawString>Rebecca Passonneau, Karen Kukich, Vasileios Hatzivassiloglou, Larry Lefl&lt;owitz, and Hongyan Jing. 1996. Generating summaries of work- flow diagrams. In Proc. of the International Conference on Natural Language Processing and Industrial Applications, pages 204-210, New Brunswick, Canada. University of Moncton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
</authors>
<title>Categorial semantics and scoping.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<pages>16--1</pages>
<contexts>
<context position="1669" citStr="Pereira, 1990" startWordPosition="250" endWordPosition="251">erences to entities at the discourse level. For example, a sentence such as The patient has an infusion line in each arm.&amp;quot; is a more concise version of &amp;quot;The patient has an infusion line in his left arm. The patient has an infusion line in his right arm.&amp;quot; Quantification is an active research topic in logic, language, and philosophy(Carpenter, 1997; de Swart. 1998). Since natural language understanding systems need to .obLain as few interpretations as possible from text, researchers have studied quantifier scope ambiguity extensively (Woods, 1978; --Grosz et al., .1987; Hobbs and Shieber. 1987; Pereira, 1990; Moran and Pereira, 1992; Park, 1995). Research in quantification interpretation first transforms a sentence into predicate logic, raises the quantifiers to the sentential level, and permutes these quantifiers to obtain as many readings as possible related to quantifier scoping. Then. invalid readings are eliminated using various constraints. Ambiguity in quantified expressions is caused by two main culprits. The first type of ambiguity involves the distributive reading versus the collective reading. In universal quantification, a referring expression refers to multiple entities. There is a p</context>
</contexts>
<marker>Pereira, 1990</marker>
<rawString>Fernando C. N. Pereira. 1990. Categorial semantics and scoping. Computational Linguistics, 16(1):1-10</rawString>
</citation>
<citation valid="true">
<authors>
<author>Owen Rambow</author>
<author>Tanya Norelsky</author>
</authors>
<title>Applied text generation.</title>
<date>1992</date>
<booktitle>In Proceedings of the Third A CL Conference on Applied Natural Language Processthy,</booktitle>
<pages>40--47</pages>
<location>Trento, Italy.</location>
<marker>Rambow, Norelsky, 1992</marker>
<rawString>Owen Rambow and Tanya Norelsky. 1992. Applied text generation. In Proceedings of the Third A CL Conference on Applied Natural Language Processthy, pages 40-47, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eltud Reiter</author>
<author>Robert Dale</author>
</authors>
<title>A fast algorithm for the generation of referring expressions.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th International Conference on Computational Linguistics (COLING92),</booktitle>
<pages>232--238</pages>
<location>Nantes, France.</location>
<contexts>
<context position="5419" citStr="Reiter and Dale, 1992" startWordPosition="822" endWordPosition="825">th previous work in the generation of quantified expressions. In Section 3, we will describe the application where the need for concise output motivated our research in quantification. The algorithm for generating universal quantifiers is detailed in Section 4, including how the system handles ambiguity between distributive and collective readings. Section 5 describes how our algorithm generates sentences with multiple quantifiers. 2 Related Work Because a quantified expression refers to multiple entities in a domain, our work can be categorized as referring expression generation (Dale, 1992; Reiter and Dale, 1992; Horacek, 1997). Previous work in this area did not address the generation of quantified expressions directly. In this paper, we are interested in how to systematically derive quantifiers from input propositions, discourse history, and ontological information. Recent work on the generation of quantifiers (Gailly, 1988; Creaney, 1996; Creaney, 1999) follows the analysis viewpoint, discussing scope ambiguities extensively. Though our algorithm generates different sentences for different scope orderings, we do not achieve this through scoping operations as they did. Creaney also discussed variou</context>
</contexts>
<marker>Reiter, Dale, 1992</marker>
<rawString>Eltud Reiter and Robert Dale. 1992. A fast algorithm for the generation of referring expressions. In Proceedings of the 14th International Conference on Computational Linguistics (COLING92), pages 232-238, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacques Robin</author>
</authors>
<title>Herision-Based Generation of Natural Language Slim in antes Pro riding Historical Background.</title>
<date>1995</date>
<tech>Ph.D. thesis,</tech>
<institution>Columbia University.</institution>
<contexts>
<context position="849" citStr="Robin, 1995" startWordPosition="114" endWordPosition="115">ted in a text generation system. By taking advantage of discourse and ontological information, quantified expressions can replace entities in a text, making the text more fluent and concise. In addition to avoiding ambiguities between distributive and collective readings in universal quantification generation, we will also show how different scope orderings between universal and existential quantifiers will result in different quantified expressions in our algorithm. 1 Introduction To convey information concisely and fluently, text generation systems often perform opportunistic text planning (Robin, 1995; Mellish et al., 1998) and employ advanced linguistic constructions such as ellipsis (Sliaw, 1998). But a system can also take advantage of quantification and ontological information to generate concise references to entities at the discourse level. For example, a sentence such as The patient has an infusion line in each arm.&amp;quot; is a more concise version of &amp;quot;The patient has an infusion line in his left arm. The patient has an infusion line in his right arm.&amp;quot; Quantification is an active research topic in logic, language, and philosophy(Carpenter, 1997; de Swart. 1998). Since natural language und</context>
</contexts>
<marker>Robin, 1995</marker>
<rawString>Jacques Robin. 1995. Herision-Based Generation of Natural Language Slim in antes Pro riding Historical Background. Ph.D. thesis, Columbia University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Shaw</author>
</authors>
<title>Segregator.), coordination and ellipsis in text generation.</title>
<date>1998</date>
<booktitle>In Proc. of the I7th COLI.VG and the 36th Annual Meeting of the ACL..</booktitle>
<pages>1220--1226</pages>
<contexts>
<context position="27822" citStr="Shaw, 1998" startWordPosition="4359" endWordPosition="4360">when the input propositions are &amp;quot;Mice received packed red blood cells. Bob received platelets. Chris received platelets.&amp;quot; Even though the conjoined entities can be generalized to &amp;quot;blood product&amp;quot;, this quantification operation would violate our precondition for using existential quantifiers: the descriptions for each of the conjoined entities must be indistinguishable. Here, one is &amp;quot;red blood cells&amp;quot; and the others are &amp;quot;platelets&amp;quot;. Given these three propositions, the system would generate &amp;quot;Alice received packed red blood cells, and Bob and Chris, platelets.&amp;quot; based on the algorithm described in (Shaw, 1998). If in our domain the input propositions could be -.Alice received blood-product-1. Bob received bloodproduct-2. Chris received blood-product-2.-, where each instance of blood-product-n could be realized as &amp;quot;blood product&amp;quot;, then the system would generate &amp;quot;Each patient received a blood product.&amp;quot; since the description of conjoined entities are not distinguishable at the surface level. 6 Conclusion We have described the quantification operators that can make the text more concise while preserving the original semantics in the input propositions. Though we would like to incorporate imprecise quan</context>
</contexts>
<marker>Shaw, 1998</marker>
<rawString>James Shaw. 1998. Segregator.), coordination and ellipsis in text generation. In Proc. of the I7th COLI.VG and the 36th Annual Meeting of the ACL.. pages 1220-1226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan van Eijck</author>
<author>Hiyan Alsliawi</author>
</authors>
<title>Logical forms.</title>
<date>1992</date>
<booktitle>In I fiyan Alshawi, editor, The Core Language Engine,</booktitle>
<pages>11--38</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>van Eijck, Alsliawi, 1992</marker>
<rawString>Jan van Eijck and Hiyan Alsliawi. 1992. Logical forms. In I fiyan Alshawi, editor, The Core Language Engine, pages 11-38. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zeno Veridler</author>
</authors>
<title>Each and every, any and all.</title>
<date>1967</date>
<booktitle>In Linguistics in Philosophy,</booktitle>
<pages>70--96</pages>
<publisher>Cornell University Press,</publisher>
<location>Ithaca and London.</location>
<marker>Veridler, 1967</marker>
<rawString>Zeno Veridler. 1967. Each and every, any and all. In Linguistics in Philosophy, pages 70-96. Cornell University Press, Ithaca and London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leo Wanner</author>
<author>Eduard flovy</author>
</authors>
<title>The Health,.D.on,:sentence planner:- In--</title>
<date>1996</date>
<booktitle>Proc.. .of,the -8th International Workshop on Natural Language Generation,</booktitle>
<pages>1--10</pages>
<location>Sussex, UK,</location>
<marker>Wanner, flovy, 1996</marker>
<rawString>Leo Wanner and Eduard flovy. 1996. The Health,.D.on,:sentence planner:- In-- Proc.. .of,the -8th International Workshop on Natural Language Generation, pages 1-10, Sussex, UK,</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Woods</author>
</authors>
<title>Semantics and quantification in natural language question answering.</title>
<date>1978</date>
<booktitle>In Advances in Computers,</booktitle>
<volume>17</volume>
<pages>1--87</pages>
<publisher>Academic Press.</publisher>
<contexts>
<context position="1606" citStr="Woods, 1978" startWordPosition="240" endWordPosition="241">ification and ontological information to generate concise references to entities at the discourse level. For example, a sentence such as The patient has an infusion line in each arm.&amp;quot; is a more concise version of &amp;quot;The patient has an infusion line in his left arm. The patient has an infusion line in his right arm.&amp;quot; Quantification is an active research topic in logic, language, and philosophy(Carpenter, 1997; de Swart. 1998). Since natural language understanding systems need to .obLain as few interpretations as possible from text, researchers have studied quantifier scope ambiguity extensively (Woods, 1978; --Grosz et al., .1987; Hobbs and Shieber. 1987; Pereira, 1990; Moran and Pereira, 1992; Park, 1995). Research in quantification interpretation first transforms a sentence into predicate logic, raises the quantifiers to the sentential level, and permutes these quantifiers to obtain as many readings as possible related to quantifier scoping. Then. invalid readings are eliminated using various constraints. Ambiguity in quantified expressions is caused by two main culprits. The first type of ambiguity involves the distributive reading versus the collective reading. In universal quantification, a</context>
</contexts>
<marker>Woods, 1978</marker>
<rawString>William A. Woods. 1978. Semantics and quantification in natural language question answering. In Advances in Computers, volume 17, pages 1-87. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frans Zwarts</author>
</authors>
<title>Determiners: a relational perspective.</title>
<date>1983</date>
<booktitle>In A. ter Meulen, editor, Studies in model-theoretic semantics,</booktitle>
<pages>37--62</pages>
<location>Dordrecht: Foris.</location>
<marker>Zwarts, 1983</marker>
<rawString>Frans Zwarts. 1983. Determiners: a relational perspective. In A. ter Meulen, editor, Studies in model-theoretic semantics, pages 37-62. Dordrecht: Foris.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>