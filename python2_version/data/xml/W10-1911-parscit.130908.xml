<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000703">
<title confidence="0.985514">
Disease Mention Recognition with Specific Features
</title>
<author confidence="0.927071">
Md. Faisal Mahbub Chowdhury t t and Alberto Lavelli t
</author>
<affiliation confidence="0.703363">
t Human Language Technology Research Unit, Fondazione Bruno Kessler, Trento, Italy
t ICT Doctoral School, University of Trento, Italy
</affiliation>
<email confidence="0.992574">
{chowdhury,lavelli}@fbk.eu
</email>
<sectionHeader confidence="0.997301" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99989285">
Despite an increasing amount of research
on biomedical named entity recognition,
there has been not enough work done on
disease mention recognition. Difficulty of
obtaining adequate corpora is one of the
key reasons which hindered this particu-
lar research. Previous studies argue that
correct identification of disease mentions
is the key issue for further improvement
of the disease-centric knowledge extrac-
tion tasks. In this paper, we present a ma-
chine learning based approach that uses
a feature set tailored for disease mention
recognition and outperforms the state-of-
the-art results. The paper also discusses
why a feature set for the well studied
gene/protein mention recognition task is
not necessarily equally effective for other
biomedical semantic types such as dis-
eases.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999954085106383">
The massive growth of biomedical literature vol-
ume has made the development of biomedical text
mining solutions indispensable. One of the essen-
tial requirements for a text mining application is
the ability to identify relevant entities, i.e. named
entity recognition. Previous work on biomedi-
cal named entity recognition (BNER) has been
mostly focused on gene/protein mention recogni-
tion. Machine learning (ML) based approaches
for gene/protein mention recognition have already
achieved a sufficient level of maturity (Torii et
al., 2009). However, the lack of availability of
adequately annotated corpora has hindered the
progress of BNER research for other semantic
types such as diseases (Jimeno et al., 2008; Lea-
man et al., 2009).
Correct identification of diseases is crucial for
various disease-centric knowledge extraction tasks
(e.g. drug discovery (Agarwal and Searls, 2008)).
Previous studies argue that the most promising
candidate for the improvement of disease related
relation extraction (e.g. disease-gene) is the cor-
rect identification of concept mentions including
diseases (Bundschus et al., 2008).
In this paper, we present a BNER system which
uses a feature set specifically tailored for disease
mention recognition. The system1 outperforms
other approaches evaluated on the Arizona Dis-
ease Corpus (AZDC) (more details in Section 5.1).
One of the key differences between our approach
and previous approaches is that we put more em-
phasis on the contextual features. We exploit syn-
tactic dependency relations as well. Apart from
the experimental results, we also discuss why the
choice of effective features for recognition of dis-
ease mentions is different from that for the well
studied gene/protein mentions.
The remaining of the paper is organized as fol-
lows. Section 2 presents a brief description of pre-
vious work on BNER for disease mention recog-
nition. Then, Section 3 describes our system and
Section 4 the feature set of the system. After that,
Section 5 explains the experimental data, results
and analyses. Section 6 describes the differences
for the choice of feature set between diseases and
genes/proteins. Finally, Section 7 concludes the
paper with an outline of our future research.
</bodyText>
<sectionHeader confidence="0.999946" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999360625">
Named entity recognition (NER) is the task of lo-
cating boundaries of the entity mentions in a text
and tagging them with their corresponding seman-
tic types (e.g. person, location, gene and so on).
Although several disease annotated corpora have
been released in the last few years, they have been
annotated primarily to serve the purpose of re-
lation extraction and, for different reasons, they
</bodyText>
<footnote confidence="0.999913">
1The source code of our system is available for download
at http://hlt.fbk.eu/people/chowdhury/research
</footnote>
<page confidence="0.982613">
83
</page>
<note confidence="0.8692325">
Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, ACL 2010, pages 83–90,
Uppsala, Sweden, 15 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999972612244898">
are not suitable for the development of ML based
disease mention recognition systems (Leaman et
al., 2009). For example, the BioText (Rosario
and Hearst, 2004) corpus has no specific anno-
tation guideline and contains several inconsisten-
cies, while PennBioIE (Kulick et al., 2004) is very
specific to a particular sub-domain of diseases.
Among other disease annotated corpora, EBI dis-
ease corpus (Jimeno et al., 2008) is not annotated
with disease mention boundaries which makes it
unsuitable for BNER evaluation for diseases. Re-
cently, an annotated corpus, named as Arizona
Disease Corpus (AZDC) (Leaman et al., 2009),
has been released which has adequate and suitable
annotation of disease mentions following specific
annotation guidelines.
There has been some work on identifying dis-
eases in clinical texts, especially in the context
of CMC Medical NLP Challenge2 and i2b2 Chal-
lenge3. However, as noted by Meystre et al.
(2008), there are a number of reasons that make
clinical texts different from texts of biomedical
literature, e.g. composition of short, telegraphic
phrases, use of implicit templates and pseudo-
tables and so on. Hence, the strategies adopted
for NER on clinical texts are not the same as the
ones practiced for NER on biomedical literature.
As mentioned before, most of the work to
date on BNER is focused on gene/protein men-
tion recognition. State-of-the-art BNER systems
are based on ML techniques such as conditional
random fields (CRFs), support vector machines
(SVMs) etc (Dai et al., 2009). These systems use
either gene/protein specific features (e.g. Greek
alphabet matching) or post-processing rules (e.g.
extension of the identified mention boundaries to
the left when a single letter with a hyphen precedes
them (Torii et al., 2009)) which might not be as
effective for other semantic type identification as
they are for genes/proteins. There is a substantial
agreement in the feature set that these systems use
(most of which are actually various orthographical
and morphological features).
Bundschus et al. (2008) have used a CRF
based approach that uses typical features for
gene/protein mention recognition (i.e. no feature
tailoring for disease recognition) for disease, gene
and treatement recognition. The work has been
evaluated on two corpora which have been anno-
</bodyText>
<footnote confidence="0.999575">
2http://www.computationalmedicine.org/challenge/index.php
3https://www.i2b2.org/NLP/Relations/Main.php
</footnote>
<bodyText confidence="0.9995155">
tated with those entities that participate in disease-
gene and disease-treatment relations. The reported
results show F-measure for recognition of all the
entities that participate in the relations and do
not indicate which F-measure has been achieved
specifically for disease recognition. Hence, the re-
ported results are not applicable for comparison.
To the best of our knowledge, the only sys-
tematic experimental results reported for disease
mention recognition in biomedical literature using
ML based approaches are published by Leaman
and Gonzalez (2008) and Leaman et al. (2009).4
They have used a CRF based BNER system named
BANNER which basically uses a set of ortho-
graphic, morphological and shallow syntactic fea-
tures (Leaman and Gonzalez, 2008). The system
achieves an F-score of 86.43 on the BioCreative
II GM corpus5 which is one of the best results for
gene mention recognition task on that corpus.
BANNER achieves an F-score of 54.84 for dis-
ease mention recognition on the BioText corpus
(Leaman and Gonzalez, 2008). However, as said
above, the BioText corpus contains annotation in-
consistencies6. So, the corpus is not ideal for com-
paring system performances. The AZDC corpus
is much more suitable as it is annotated specifi-
cally for benchmarking of disease mention recog-
nition systems. An improved version of BAN-
NER achieves an F-score of 77.9 on AZDC cor-
pus, which is the state of the art on ML based dis-
ease mention recognition in biomedical literature
(Leaman et al., 2009).
</bodyText>
<sectionHeader confidence="0.941021" genericHeader="method">
3 Description of Our System
</sectionHeader>
<bodyText confidence="0.999873666666667">
There are basically three stages in our approach –
pre-processing, feature extraction and model train-
ing, and post-processing.
</bodyText>
<subsectionHeader confidence="0.99996">
3.1 Pre-processing
</subsectionHeader>
<bodyText confidence="0.980664454545455">
At first, the system uses GeniaTagger7 to tokenize
texts and provide PoS tagging. After that, it cor-
rects some common inconsistencies introduced by
GeniaTagger inside the tokenized data (e.g. Ge-
niaTagger replaces double inverted commas with
4However, there are some work on disease recognition in
biomedical literature using other techniques such as morpho-
syntactic heuristic based approach (e.g. MetaMap (Aronson,
2001)), dictionary look-up method and statistical approach
(Neveol et al., 2009; Jimeno et al., 2008; Leaman et al.,
2009).
</bodyText>
<footnote confidence="0.999574">
5As mentioned in http://banner.sourceforge.net/
6http://biotext.berkeley.edu/data/dis treat data.html
7http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/tagger/
</footnote>
<page confidence="0.998723">
84
</page>
<bodyText confidence="0.997102833333333">
two single inverted commas). These PoS tagged
tokized data are parsed using Stanford parser8.
The dependency relations provided as output by
the parser are used later as features. The tokens
are further processed using the following general-
ization and normalization steps:
</bodyText>
<listItem confidence="0.9931874">
• each number (both integer and real) inside a
token is replaced with ‘9’
• each token is further tokenized if it contains
either punctuation characters or both digits
and alphabetic characters
• all letters are changed to lower case
• all Greek letters (e.g. alpha) are replaced with
G and Roman numbers (e.g. iv) with R
• each token is normalized using SPECIALIST
lexicon tool9 to avoid spelling variations
</listItem>
<subsectionHeader confidence="0.999684">
3.2 Feature extraction and model training
</subsectionHeader>
<bodyText confidence="0.9998785">
The features used by our system can be catego-
rized into the following groups:
</bodyText>
<listItem confidence="0.998996">
• general linguistic features (Table 1)
• orthographic features (Table 2)
• contextual features (Table 3)
• syntactic dependency features (Table 4)
• dictionary lookup features (see Section 4)
</listItem>
<bodyText confidence="0.999818117647059">
During dictionary lookup feature extraction, we
ignored punctuation characters while matching
dictionary entries inside sentences. If a sequence
of tokens in a sentence matches an entry in the dic-
tionary, the leftmost token of that sequence is la-
beled with B-DB and the remaining tokens of the
sequence are labeled with I-DB. The label B-DB
indicates the beginning of a dictionary match. If a
token belongs to several dictionary matches, then
all the other dictionary matches except the longest
one are discarded.
The syntactic dependency features are extracted
from the output of the parser while the general lin-
guistic features are extracted directly from the pre-
processed tokens. To collect the orthographic fea-
tures, the original tokens inside the corresponding
sentences are considered. The contextual features
</bodyText>
<footnote confidence="0.9984545">
8http://nlp.stanford.edu/software/lex-parser.shtml
9http://lexsrv3.nlm.nih.gov/SPECIALIST/index.html
</footnote>
<bodyText confidence="0.999500181818182">
are derived using other extracted features and the
original tokens.
Tokens are labeled with the corresponding dis-
ease annotations according to the IOB2 format.
Our system uses Mallet (McCallum, 2002) to train
a first-order CRF model. CRF is a state-of-the-
art ML technique applied to a variety of text
processing tasks including named entity recogni-
tion (Klinger and Tomanek, 2007) and has been
successfully used by many other BNER systems
(Smith et al., 2008).
</bodyText>
<subsectionHeader confidence="0.999964">
3.3 Post-processing
</subsectionHeader>
<bodyText confidence="0.9948195">
Once the disease mentions are identified using
the learned model, the following post-processing
techniques are applied to reduce the number of
wrong identifications:
</bodyText>
<listItem confidence="0.961353774193548">
• Bracket mismatch correction: If there is a
mismatch of brackets in the identified men-
tion, then the immediate following (or pre-
ceding) character of the corresponding men-
tion is checked and included inside the men-
tion if that character is the missing bracket.
Otherwise, all the characters from the index
where the mismatched bracket exists inside
the identified mention are discarded from the
corresponding mention.
• One sense per discourse: If any instance of
a character sequence is identified as a disease
mention, then all the other instances of that
character sequence inside the same sentence
are also annotated as disease mentions.
• Short/long form annotation: Using the algo-
rithm of Schwartz and Hearst (2003), “long
form (short form)” instances are detected in-
side sentences. If the short form is annotated
as disease mention, then the long form is also
annotated and vice versa.
• Ungrammatical conjunction structure cor-
rection: If an annotated mention contains
comma (,) but there is no “and” in the fol-
lowing character sequence (from the charac-
ter index of that comma) of that mention, then
the annotation is splitted into two parts (at the
index of the comma). Annotation of the origi-
nal mention is removed and the splitted parts
are annotated as two separate disease men-
tions.
</listItem>
<page confidence="0.940756">
85
</page>
<listItem confidence="0.9560148">
• Short and long form separation: If both short
and long forms are annotated in the same
mention, then the original mention is dis-
carded and the corresponding short and long
forms are annotated separately.
</listItem>
<sectionHeader confidence="0.999164" genericHeader="method">
4 Features for Disease Recognition
</sectionHeader>
<bodyText confidence="0.992262230769231">
There are compelling reasons to believe that vari-
ous issues regarding the well studied gene/protein
mention recognition would not apply to the other
semantic types. For example, Jimeno et al. (2008)
argue that the use of disease terms in biomedical
literature is well standardized, which is quite op-
posite for the gene terms (Smith et al., 2008).
After a thorough study and extensive experi-
ments on various features and their possible com-
binations, we have selected a feature set specific
to the disease mention identification which com-
prises features shown in Tables 1, 2, 4 and 3, and
dictionary lookup features.
</bodyText>
<table confidence="0.958235555555556">
Feature name Description
PoS Part-of-speech tag
NormWord Normalized token
(see Section 3.1)
Lemma Lemmatized form
charNgram 3 and 4 character n-grams
Suffix 2-4 character suffixes
Prefix 2-4 character prefixes
Feature name Description
</table>
<figure confidence="0.903190928571428">
Bi-gramk,k+1 Bi-grams of
for i − 2 &lt; k &lt; i + 2 normalized tokens
Tri-gramk,k+1,k+2 Tri-grams of
for i − 2 &lt; k &lt; i + 2 normalized tokens
CtxPoSk,k+1 Bi-grams of
for i &lt; k &lt; i + 2 token PoS
CtxLemmak,k+1 Bi-grams of
for i &lt; k &lt; i + 2 lemmatized tokens
CtxWordk,k+1 Bi-grams of
for i − 2 &lt; k &lt; i + 2 original tokens
Offset conjunctions Extracted by Mallet
from features
in the range from
tokenZ_1 to tokenZ+1
</figure>
<tableCaption confidence="0.995367">
Table 3: Contextual features for tokenZ
</tableCaption>
<table confidence="0.9629472">
Feature name Description
dobj Target token(s) to which tokenZ
is a direct object
iobj Target token(s) to which tokenZ
is an indirect object
</table>
<bodyText confidence="0.571882">
nsubj Target token(s) to which tokenZ
is an active nominal subject
nsubjpass Target token(s) to which tokenZ
is a passive nominal subject
nn Target token(s) to which tokenZ
is a noun compound modifier
</bodyText>
<tableCaption confidence="0.999961">
Table 4: Syntactic dependency features for tokenZ.
Table 1: General linguistic features for tokenZ For example, in the sentence “Clinton defeated
</tableCaption>
<table confidence="0.844022545454545">
Dole”, “Clinton” is the nsubj of the target token
“defeated”.
Feature name Description
InitCap Is initial letter capital
AllCap Are all letters capital
MixCase Does contain mixed case letters
SingLow Is a single lower case letter
SingUp Is a single upper case letter
Num Is a number
PuncChar Punctuation character
(if tokenZ is
</table>
<tableCaption confidence="0.65783925">
a punctuation character)
PrevCharAN Is previous character
alphanumeric
Table 2: Orthographic features for tokenZ
</tableCaption>
<bodyText confidence="0.998016944444444">
Like Leaman et al. (2009), we have created
a dictionary with the instances of the following
nine of the twelve UMLS semantic types from
the semantic group “DISORDER”10 from UMLS
Metathesaurus (Bodenreider, 2004): (i) disease or
syndrome, (ii) neoplastic process, (iii) congenital
abnormality, (iv) acquired abnormality, (v) exper-
imental model of disease, (vi) injury or poison-
ing, (vii) mental or behavioral dysfunction, (viii)
pathological function and (ix) sign or symptom.
We have not considered the other three semantic
types (findings, anatomical abnormality and cell
or molecular Dysfunction) since these three types
have not been used during the annotation of Ari-
zona Disease Corpus (AZDC) which we have used
in our experiments.
Previous studies have shown that dictionary
lookup features, i.e. name matching against a
</bodyText>
<footnote confidence="0.83803">
10http://semanticnetwork.nlm.nih.gov/SemGroups/
</footnote>
<page confidence="0.997295">
86
</page>
<bodyText confidence="0.999915230769231">
dictionary of terms, often increase recall (Torii
et al., 2009; Leaman et al., 2009). However,
an unprocessed dictionary usually does not boost
overall performance (Zweigenbaum et al., 2007).
So, to reduce uninformative lexical differences or
spelling variations, we generalize and normalize
the dictionary entries using exactly the same steps
followed for the pre-processing of sentences (see
Section 3.1).
To reduce chances of false and unlikely
matches, any entry inside the dictionary having
less than 3 characters or more than 10 tokens is
discarded.
</bodyText>
<sectionHeader confidence="0.9997" genericHeader="method">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.919912">
5.1 Data
</subsectionHeader>
<bodyText confidence="0.999933727272727">
We have done experiments on the recently re-
leased Arizona Disease Corpus (AZDC)11 (Lea-
man et al., 2009). The corpus has detailed annota-
tions of diseases including UMLS codes, UMLS
concept names, possible alternative codes, and
start and end points of disease mentions inside
the corresponding sentences. These detailed an-
notations make this corpus a valuable resource
for evaluating and benchmarking text mining so-
lutions for disease recognition. Table 5 shows var-
ious characteristics of the corpus.
</bodyText>
<table confidence="0.900113166666667">
Item name Total count
Abstracts 793
Sentences 2,783
Total disease mentions 3,455
Disease mentions without overlaps 3,093
Disease mentions with overlaps 362
</table>
<tableCaption confidence="0.998365">
Table 5: Various characteristics of AZDC.
</tableCaption>
<bodyText confidence="0.999849666666667">
For the overlapping annotations, (e.g. “endome-
trial and ovarian cancers” and “ovarian cancers”)
we have considered only the larger annotations
in our experiments. There remain 3,224 disease
mentions after resolving overlaps according to the
aforementioned criterion. We have observed mi-
nor differences in some statistics of the AZDC re-
ported by Leaman et al. (2009) with the statistics
of the downloadable version12 (Table 5). How-
</bodyText>
<footnote confidence="0.920173833333333">
11Downloaded from http://diego.asu.edu/downloads/AZDC/
at 5-Feb-2009
12Note that “Disease mentions (total)” in the paper of Lea-
man et al. (2009) actually refers to the total disease mentions
after overlap resolving (Robert Leaman, personal communi-
cation). One other thing is, Leaman et al. (2009) mention 794
</footnote>
<bodyText confidence="0.998673">
ever, these differences can be considered negligi-
ble.
</bodyText>
<subsectionHeader confidence="0.886014">
5.2 Results
</subsectionHeader>
<bodyText confidence="0.999687428571429">
We follow an experimental setting similar to the
one in Leaman et al. (2009) so that we can com-
pare our results with that of the BANNER system.
We performed 10-fold cross validation on AZDC
in such a way that all sentences of the same ab-
stract are included in the same fold. The results of
all folds are averaged to obtain the final outcome.
Table 6 shows the results of the experiments with
different features using the exact matching crite-
rion.
As we can see, our approach achieves signif-
icantly higher result than that of BANNER. Ini-
tially, with only the general linguistic and or-
thographic features the performance is not high.
However, once the contextual features are used,
there is a substantial improvement in the result.
Note that BANNER does not use contextual fea-
tures. In fact, the use of contextual features is also
quite limited in other BNER systems that achieve
high performance for gene/protein identification
(Smith et al., 2008).
Dictionary lookup features provide a very good
contribution in the outcome. This supports the ar-
gument of Jimeno et al. (2008) that the use of dis-
ease terms in biomedical literature is well stan-
dardized. Post-processing and syntactic depen-
dency features also increase some performance.
We have done statistical significance tests for
the last four experimental results shown in Table 6.
For each of such four experiments, the immediate
previous experiment is considered as the baseline.
The tests have been performed using the approx-
imate randomization procedure (Noreen, 1989).
We have set the number of iterations to 1,000 and
the confidence level to 0.01. According to the
tests, the contributions of contextual features and
dictionary lookup features are statistically signif-
icant. However, we have found that the contri-
butions of post-processing rules and syntactic de-
pendency features are statistically significant only
when the confidence level is 0.2 or more. Since
AZDC consists of only 2,783 sentences, we can
assume that the impact of post-processing rules
abstracts, 2,784 sentences and 3,228 (overlap resolved) dis-
ease mentions in the AZDC. But in our downloaded version
of AZDC, there is 1 abstract missing (i.e. total 793 abstracts
instead of 794). As a result, there is 1 less sentence and 4
less (overlap resolved) disease mentions than the originally
reported numbers.
</bodyText>
<page confidence="0.997526">
87
</page>
<bodyText confidence="0.999710666666667">
and syntactic dependency features has been not so
significant despite of some performance improve-
ment.
</bodyText>
<subsectionHeader confidence="0.998413">
5.3 Error analysis
</subsectionHeader>
<bodyText confidence="0.999384421052632">
One of the sources of errors is the annotations
having conjunction structures. There are 94 dis-
ease mentions in the data which contain the word
“and”. The boundaries of 11 of them have been
wrongly identified during experiments, while 39
of them have been totally missed out by our sys-
tem. Our system also has not performed well
for disease annotations that have some specific
types of prepositional phrase structures. For ex-
ample, there are 80 disease annotations having the
word “of” (e.g. “deficient activity of acid beta-
glucosidase GBA”). Only 28 of them are correctly
annotated by our system. The major source of er-
rors, however, concerns abbreviated disease names
(e.g. “PNH”). We believe one way to reduce this
specific error type is to generate a list of possi-
ble abbreviated disease names from the long forms
of disease names available in databases such as
UMLS Metathesaurus.
</bodyText>
<sectionHeader confidence="0.806682" genericHeader="method">
6 Why Features for Diseases and
</sectionHeader>
<subsectionHeader confidence="0.659639">
Genes/Proteins are not the Same
</subsectionHeader>
<bodyText confidence="0.99861386440678">
Many of the existing BNER systems, which are
mainly tuned for gene/protein identification, use
features such as token shape (also known as word
class and brief word class (Settles, 2004)), Greek
alphabet matching, Roman number matching and
so forth. As mentioned earlier, we have done ex-
tensive experiments with various feature combina-
tions for the selection of disease specific features.
We have observed that many of the features used
for gene/protein identification are not equally ef-
fective for disease identification. Table 7 shows
some of the results of those experiments.
This observation is reasonable because
gene/protein names are much more complex than
entities such as diseases. For example, they often
contain punctuation characters (such as paren-
theses or hyphen), Greek alphabets and digits
which are unlikely in disease names. Ideally,
the ML algorithm itself should be able to utilize
information from only the useful features and
ignore the others in the feature set. But practically,
having non-informative features often mislead
the model learning. In fact, several surveys have
argued that the choice of features matter at least
as much as the choice of the algorithm if not more
(Nadeau and Sekine, 2007; Zweigenbaum et al.,
2007).
One of the interesting trends in gene/protein
mention identification is to not utilize syntactic
dependency relations (with the exception of Vla-
chos (2007)). Gene/protein names in biomedi-
cal literature are often combined (i.e. without
being separated by space characters) with other
characters which do not belong to the correspond-
ing mentions (e.g. p53-mediated). Moreover,
as mentioned before, gene/protein mentions com-
monly have very complex structures (e.g. PKI?(]-
55]
KR(l-
55l )K64E/K296R or RXRalphaF318A). So, it is a
common practice to tokenize gene/proten names
adopting an approach that split tokens as much as
possible to extract effective features (Torii et al.,
2009; Smith et al., 2008). But while the extensive
tokenization boosts performance, it is often diffi-
cult to correctly detect dependency relations for
the tokens of the gene/protein names in the sen-
tences where they appear. As a result, use of the
syntactic dependency relations is not beneficial in
such approaches.13 In comparison, disease men-
tions are less complex. So, the identified depen-
dencies for disease mentions are more reliable and
hence may be usable as potential features (refer to
our experimental results in Table 6).
The above mentioned issues are some of the
reasons why a feature set for the well studied
gene/protein focused BNER approaches is not
necessarily suitable for other biomedical semantic
types such as diseases.
</bodyText>
<sectionHeader confidence="0.999173" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999966076923077">
In this paper, we have presented a single CRF clas-
sifier based BNER approach for disease mention
identification. The feature set is constructed us-
ing disease-specific contextual, orthographic, gen-
eral linguistic, syntactic dependency and dictio-
nary lookup features. We have evaluated our ap-
proach on AZDC corpus. Our approach achieves
significantly higher result than BANNER which is
the current state-of-the-art ML based approach for
disease mention recognition. We have also ex-
plained why the choice of features for the well
studied gene/protein does not apply for other se-
mantic types such as diseases.
</bodyText>
<footnote confidence="0.98520125">
13We have done some experiments on Biocreative II GM
corpus with syntactic dependency relations of the tokens,
which are not reported in this paper, and the results support
our argument.
</footnote>
<page confidence="0.994346">
88
</page>
<table confidence="0.998287285714286">
System Note Precision Recall F-score
BANNER (Leaman et al., 2009) 80.9 75.1 77.9
Our system Using general linguistic and orthographic features 74.90 71.01 72.90
Our system After adding contextual features 82.15 75.81 78.85
Our system After adding post-processing 81.57 76.61 79.01
Our system After adding syntactic dependency features 82.07 76.66 79.27
Our system After adding dictionary lookup features 83.21 79.06 81.08
</table>
<tableCaption confidence="0.990146">
Table 6: 10-fold cross validation results using exact matching criteria on AZDC.
</tableCaption>
<table confidence="0.999626833333333">
Experiment Note Precision Recall F-score
Using general linguistic, orthographic 82.15 75.81 78.85
and contextual features
After adding WC and BWC features in (i) 82.08 75.57 78.69
After adding IsGreekAlphabet, HasGreekAlphabet 82.10 75.69 78.76
and IsRomanNumber features in (i)
</table>
<tableCaption confidence="0.991454">
Table 7: Experimental results of our system after using some of the gene/protein specific features for
</tableCaption>
<bodyText confidence="0.899203625">
disease mention recognition on AZDC. Here, WC and BWC refer to the “word class” and “brief word
class” respectively.
Future work includes implementation of disease
mention normalization (i.e. associating a unique
identifier for each disease mention). We also
plan to improve our current approach by includ-
ing more contextual features and post-processing
rules.
</bodyText>
<sectionHeader confidence="0.99863" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999198">
This work was carried out in the context of the
project “eOnco - Pervasive knowledge and data
management in cancer care”. The authors would
like to thank Robert Leaman for sharing the set-
tings of his experiments on AZDC.
</bodyText>
<sectionHeader confidence="0.999016" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999351729166667">
Agarwal, P., Searls, D. 2008. Literature mining in sup-
port of drug discovery. Brief Bioinform, 9(6):479–
492.
Aronson, A. 2001. Effective mapping of biomedical
text to the UMLS Metathesaurus: the MetaMap pro-
gram. In Proceedings AMIA Symposium, pages 17–
21.
Bodenreider, O. 2004. The Unified Medical Language
System (UMLS): integrating biomedical terminol-
ogy. Nucleic Acids Research, 32(suppl 1):D267–
270, January.
Bundschus, M., Dejori, M., Stetter, M., Tresp, V.,
Kriegel, H. 2008. Extraction of semantic biomed-
ical relations from text using conditional random
fields. BMC Bioinformatics, 9:207.
Dai, H., Chang, Y., Tsai, R., Hsu, W. 2009. New
challenges for biological text-mining in the next
decade. Journal of Computer Science and Technol-
ogy, 25(1):169–179.
Jimeno, A., Jimnez-Ruiz, E., Lee, V., Gaudan, S.,
Berlanga, R., Rebholz-Schuhmann, D. 2008. As-
sessment of disease named entity recognition on a
corpus of annotated sentences. BMC Bioinformat-
ics, 9(S-3).
Klinger, R., Tomanek, K. 2007. Classical Probabilistic
Models and Conditional Random Fields. Technical
Report TR07-2-013, Department of Computer Sci-
ence, Dortmund University of Technology, Decem-
ber.
Kulick, S., Bies, A., Liberman, M., Mandel, M., Mc-
Donald, R., Palmer, M., Schein, A., Ungar, L. 2004.
Integrated annotation for biomedical information ex-
traction. In Proceedings of HLT/NAACL 2004 Bi-
oLink Workshop, pages 61–68.
Leaman, R., Gonzalez, G. 2008. Banner: An exe-
cutable survey of advances in biomedical named en-
tity recognition. In Proceedings of Pacific Sympo-
sium on Biocomputing, volume 13, pages 652–663.
Leaman, R., Miller, C., Gonzalez, G. 2009. Enabling
recognition of diseases in biomedical text with ma-
chine learning: Corpus and benchmark. In Proceed-
ings of the 3rd International Symposium on Lan-
guages in Biology and Medicine, pages 82–89.
McCallum, A. 2002. Mallet: A machine learning for
language toolkit. http://mallet.cs.umass.edu,.
Meystre, S., Savova, G., Kipper-Schuler, K., Hurdle,
J. 2008. Extracting information from textual doc-
uments in the electronic health record: a review of
</reference>
<page confidence="0.994328">
89
</page>
<reference confidence="0.999579512820513">
recent research. IMIA Yearbook of Medical Infor-
matics, pages 128–44.
Neveol, A., Kim, W., Wilbur, W., Lu, Z. 2009. Explor-
ing two biomedical text genres for disease recogni-
tion. In Proceedings of the BioNLP 2009 Workshop,
pages 144–152, June.
Nadeau, D., Sekine, S. 2007. A survey of named entity
recognition and classification. Linguisticae Investi-
gationes, 30(1):3–26.
Noreen, E.W. 1989. Computer-Intensive Methods
for Testing Hypotheses: An Introduction. Wiley-
Interscience.
Rosario, B., Hearst, M. 2004. Classifying semantic
relations in bioscience texts. In Proceedings of the
42nd Meeting of the Association for Computational
Linguistics (ACL’04).
Schwartz, A., Hearst, M. 2003. A simple algorithm
for identifying abbreviation definitions in biomedi-
cal text. In Proceedings of Pacific Symposium on
Biocomputing, pages 451–62.
Settles, B. 2004. Biomedical named entity recognition
using conditional random fields and rich feature sets.
In Proceedings of the International Joint Workshop
on Natural Language Processing in Biomedicine
and its Applications, pages 104–107.
Smith, L., Tanabe, L., Ando, R., Kuo, C., et al. 2008.
Overview of BioCreative II gene mention recogni-
tion. Genome Biology, 9(Suppl 2).
Torii, M., Hu, Z., Wu, C., Liu, H. 2009. Biotagger-
GM: a gene/protein name recognition system. Jour-
nal of the American Medical Informatics Associa-
tion : JAMIA, 16:247–255.
Vlachos, A. 2007. Tackling the BioCreative2 gene
mention task with conditional random fields and
syntactic parsing. In Proceedings of the 2nd BioCre-
ative Challenge Evaluation Workshop, pages 85–87.
Zweigenbaum, P., Demner-Fushman, D., Yu, H., Co-
hen, K. 2007. Frontiers of biomedical text mining:
current progress. Brief Bioinform, 8(5):358–375.
</reference>
<page confidence="0.998633">
90
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.784551">
<title confidence="0.999813">Disease Mention Recognition with Specific Features</title>
<author confidence="0.997929">Faisal Mahbub Chowdhury t Alberto Lavelli</author>
<affiliation confidence="0.9880075">Language Technology Research Unit, Fondazione Bruno Kessler, Trento, Doctoral School, University of Trento,</affiliation>
<abstract confidence="0.99068919047619">Despite an increasing amount of research on biomedical named entity recognition, there has been not enough work done on disease mention recognition. Difficulty of obtaining adequate corpora is one of the key reasons which hindered this particular research. Previous studies argue that correct identification of disease mentions is the key issue for further improvement of the disease-centric knowledge extraction tasks. In this paper, we present a machine learning based approach that uses a feature set tailored for disease mention recognition and outperforms the state-ofthe-art results. The paper also discusses why a feature set for the well studied gene/protein mention recognition task is not necessarily equally effective for other biomedical semantic types such as diseases.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P Agarwal</author>
<author>D Searls</author>
</authors>
<title>Literature mining in support of drug discovery.</title>
<date>2008</date>
<journal>Brief Bioinform,</journal>
<volume>9</volume>
<issue>6</issue>
<pages>492</pages>
<contexts>
<context position="1956" citStr="Agarwal and Searls, 2008" startWordPosition="284" endWordPosition="287">ognition. Previous work on biomedical named entity recognition (BNER) has been mostly focused on gene/protein mention recognition. Machine learning (ML) based approaches for gene/protein mention recognition have already achieved a sufficient level of maturity (Torii et al., 2009). However, the lack of availability of adequately annotated corpora has hindered the progress of BNER research for other semantic types such as diseases (Jimeno et al., 2008; Leaman et al., 2009). Correct identification of diseases is crucial for various disease-centric knowledge extraction tasks (e.g. drug discovery (Agarwal and Searls, 2008)). Previous studies argue that the most promising candidate for the improvement of disease related relation extraction (e.g. disease-gene) is the correct identification of concept mentions including diseases (Bundschus et al., 2008). In this paper, we present a BNER system which uses a feature set specifically tailored for disease mention recognition. The system1 outperforms other approaches evaluated on the Arizona Disease Corpus (AZDC) (more details in Section 5.1). One of the key differences between our approach and previous approaches is that we put more emphasis on the contextual features</context>
</contexts>
<marker>Agarwal, Searls, 2008</marker>
<rawString>Agarwal, P., Searls, D. 2008. Literature mining in support of drug discovery. Brief Bioinform, 9(6):479– 492.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Aronson</author>
</authors>
<title>Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program.</title>
<date>2001</date>
<booktitle>In Proceedings AMIA Symposium,</booktitle>
<pages>17--21</pages>
<contexts>
<context position="8483" citStr="Aronson, 2001" startWordPosition="1289" endWordPosition="1290">aman et al., 2009). 3 Description of Our System There are basically three stages in our approach – pre-processing, feature extraction and model training, and post-processing. 3.1 Pre-processing At first, the system uses GeniaTagger7 to tokenize texts and provide PoS tagging. After that, it corrects some common inconsistencies introduced by GeniaTagger inside the tokenized data (e.g. GeniaTagger replaces double inverted commas with 4However, there are some work on disease recognition in biomedical literature using other techniques such as morphosyntactic heuristic based approach (e.g. MetaMap (Aronson, 2001)), dictionary look-up method and statistical approach (Neveol et al., 2009; Jimeno et al., 2008; Leaman et al., 2009). 5As mentioned in http://banner.sourceforge.net/ 6http://biotext.berkeley.edu/data/dis treat data.html 7http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/tagger/ 84 two single inverted commas). These PoS tagged tokized data are parsed using Stanford parser8. The dependency relations provided as output by the parser are used later as features. The tokens are further processed using the following generalization and normalization steps: • each number (both integer and real) inside a toke</context>
</contexts>
<marker>Aronson, 2001</marker>
<rawString>Aronson, A. 2001. Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program. In Proceedings AMIA Symposium, pages 17– 21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Bodenreider</author>
</authors>
<title>The Unified Medical Language System (UMLS): integrating biomedical terminology.</title>
<date>2004</date>
<journal>Nucleic Acids Research,</journal>
<volume>32</volume>
<pages>270</pages>
<contexts>
<context position="15292" citStr="Bodenreider, 2004" startWordPosition="2359" endWordPosition="2360">he target token “defeated”. Feature name Description InitCap Is initial letter capital AllCap Are all letters capital MixCase Does contain mixed case letters SingLow Is a single lower case letter SingUp Is a single upper case letter Num Is a number PuncChar Punctuation character (if tokenZ is a punctuation character) PrevCharAN Is previous character alphanumeric Table 2: Orthographic features for tokenZ Like Leaman et al. (2009), we have created a dictionary with the instances of the following nine of the twelve UMLS semantic types from the semantic group “DISORDER”10 from UMLS Metathesaurus (Bodenreider, 2004): (i) disease or syndrome, (ii) neoplastic process, (iii) congenital abnormality, (iv) acquired abnormality, (v) experimental model of disease, (vi) injury or poisoning, (vii) mental or behavioral dysfunction, (viii) pathological function and (ix) sign or symptom. We have not considered the other three semantic types (findings, anatomical abnormality and cell or molecular Dysfunction) since these three types have not been used during the annotation of Arizona Disease Corpus (AZDC) which we have used in our experiments. Previous studies have shown that dictionary lookup features, i.e. name matc</context>
</contexts>
<marker>Bodenreider, 2004</marker>
<rawString>Bodenreider, O. 2004. The Unified Medical Language System (UMLS): integrating biomedical terminology. Nucleic Acids Research, 32(suppl 1):D267– 270, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Bundschus</author>
<author>M Dejori</author>
<author>M Stetter</author>
<author>V Tresp</author>
<author>H Kriegel</author>
</authors>
<title>Extraction of semantic biomedical relations from text using conditional random fields.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<pages>9--207</pages>
<contexts>
<context position="2188" citStr="Bundschus et al., 2008" startWordPosition="316" endWordPosition="319">ficient level of maturity (Torii et al., 2009). However, the lack of availability of adequately annotated corpora has hindered the progress of BNER research for other semantic types such as diseases (Jimeno et al., 2008; Leaman et al., 2009). Correct identification of diseases is crucial for various disease-centric knowledge extraction tasks (e.g. drug discovery (Agarwal and Searls, 2008)). Previous studies argue that the most promising candidate for the improvement of disease related relation extraction (e.g. disease-gene) is the correct identification of concept mentions including diseases (Bundschus et al., 2008). In this paper, we present a BNER system which uses a feature set specifically tailored for disease mention recognition. The system1 outperforms other approaches evaluated on the Arizona Disease Corpus (AZDC) (more details in Section 5.1). One of the key differences between our approach and previous approaches is that we put more emphasis on the contextual features. We exploit syntactic dependency relations as well. Apart from the experimental results, we also discuss why the choice of effective features for recognition of disease mentions is different from that for the well studied gene/prot</context>
<context position="6035" citStr="Bundschus et al. (2008)" startWordPosition="919" endWordPosition="922">h as conditional random fields (CRFs), support vector machines (SVMs) etc (Dai et al., 2009). These systems use either gene/protein specific features (e.g. Greek alphabet matching) or post-processing rules (e.g. extension of the identified mention boundaries to the left when a single letter with a hyphen precedes them (Torii et al., 2009)) which might not be as effective for other semantic type identification as they are for genes/proteins. There is a substantial agreement in the feature set that these systems use (most of which are actually various orthographical and morphological features). Bundschus et al. (2008) have used a CRF based approach that uses typical features for gene/protein mention recognition (i.e. no feature tailoring for disease recognition) for disease, gene and treatement recognition. The work has been evaluated on two corpora which have been anno2http://www.computationalmedicine.org/challenge/index.php 3https://www.i2b2.org/NLP/Relations/Main.php tated with those entities that participate in diseasegene and disease-treatment relations. The reported results show F-measure for recognition of all the entities that participate in the relations and do not indicate which F-measure has bee</context>
</contexts>
<marker>Bundschus, Dejori, Stetter, Tresp, Kriegel, 2008</marker>
<rawString>Bundschus, M., Dejori, M., Stetter, M., Tresp, V., Kriegel, H. 2008. Extraction of semantic biomedical relations from text using conditional random fields. BMC Bioinformatics, 9:207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Dai</author>
<author>Y Chang</author>
<author>R Tsai</author>
<author>W Hsu</author>
</authors>
<title>New challenges for biological text-mining in the next decade.</title>
<date>2009</date>
<journal>Journal of Computer Science and Technology,</journal>
<volume>25</volume>
<issue>1</issue>
<contexts>
<context position="5504" citStr="Dai et al., 2009" startWordPosition="839" endWordPosition="842">ted by Meystre et al. (2008), there are a number of reasons that make clinical texts different from texts of biomedical literature, e.g. composition of short, telegraphic phrases, use of implicit templates and pseudotables and so on. Hence, the strategies adopted for NER on clinical texts are not the same as the ones practiced for NER on biomedical literature. As mentioned before, most of the work to date on BNER is focused on gene/protein mention recognition. State-of-the-art BNER systems are based on ML techniques such as conditional random fields (CRFs), support vector machines (SVMs) etc (Dai et al., 2009). These systems use either gene/protein specific features (e.g. Greek alphabet matching) or post-processing rules (e.g. extension of the identified mention boundaries to the left when a single letter with a hyphen precedes them (Torii et al., 2009)) which might not be as effective for other semantic type identification as they are for genes/proteins. There is a substantial agreement in the feature set that these systems use (most of which are actually various orthographical and morphological features). Bundschus et al. (2008) have used a CRF based approach that uses typical features for gene/p</context>
</contexts>
<marker>Dai, Chang, Tsai, Hsu, 2009</marker>
<rawString>Dai, H., Chang, Y., Tsai, R., Hsu, W. 2009. New challenges for biological text-mining in the next decade. Journal of Computer Science and Technology, 25(1):169–179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Jimeno</author>
<author>E Jimnez-Ruiz</author>
<author>V Lee</author>
<author>S Gaudan</author>
<author>R Berlanga</author>
<author>D Rebholz-Schuhmann</author>
</authors>
<title>Assessment of disease named entity recognition on a corpus of annotated sentences.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<contexts>
<context position="1784" citStr="Jimeno et al., 2008" startWordPosition="260" endWordPosition="263">xt mining solutions indispensable. One of the essential requirements for a text mining application is the ability to identify relevant entities, i.e. named entity recognition. Previous work on biomedical named entity recognition (BNER) has been mostly focused on gene/protein mention recognition. Machine learning (ML) based approaches for gene/protein mention recognition have already achieved a sufficient level of maturity (Torii et al., 2009). However, the lack of availability of adequately annotated corpora has hindered the progress of BNER research for other semantic types such as diseases (Jimeno et al., 2008; Leaman et al., 2009). Correct identification of diseases is crucial for various disease-centric knowledge extraction tasks (e.g. drug discovery (Agarwal and Searls, 2008)). Previous studies argue that the most promising candidate for the improvement of disease related relation extraction (e.g. disease-gene) is the correct identification of concept mentions including diseases (Bundschus et al., 2008). In this paper, we present a BNER system which uses a feature set specifically tailored for disease mention recognition. The system1 outperforms other approaches evaluated on the Arizona Disease </context>
<context position="4402" citStr="Jimeno et al., 2008" startWordPosition="664" endWordPosition="667">le/chowdhury/research 83 Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, ACL 2010, pages 83–90, Uppsala, Sweden, 15 July 2010. c�2010 Association for Computational Linguistics are not suitable for the development of ML based disease mention recognition systems (Leaman et al., 2009). For example, the BioText (Rosario and Hearst, 2004) corpus has no specific annotation guideline and contains several inconsistencies, while PennBioIE (Kulick et al., 2004) is very specific to a particular sub-domain of diseases. Among other disease annotated corpora, EBI disease corpus (Jimeno et al., 2008) is not annotated with disease mention boundaries which makes it unsuitable for BNER evaluation for diseases. Recently, an annotated corpus, named as Arizona Disease Corpus (AZDC) (Leaman et al., 2009), has been released which has adequate and suitable annotation of disease mentions following specific annotation guidelines. There has been some work on identifying diseases in clinical texts, especially in the context of CMC Medical NLP Challenge2 and i2b2 Challenge3. However, as noted by Meystre et al. (2008), there are a number of reasons that make clinical texts different from texts of biomed</context>
<context position="8578" citStr="Jimeno et al., 2008" startWordPosition="1301" endWordPosition="1304">proach – pre-processing, feature extraction and model training, and post-processing. 3.1 Pre-processing At first, the system uses GeniaTagger7 to tokenize texts and provide PoS tagging. After that, it corrects some common inconsistencies introduced by GeniaTagger inside the tokenized data (e.g. GeniaTagger replaces double inverted commas with 4However, there are some work on disease recognition in biomedical literature using other techniques such as morphosyntactic heuristic based approach (e.g. MetaMap (Aronson, 2001)), dictionary look-up method and statistical approach (Neveol et al., 2009; Jimeno et al., 2008; Leaman et al., 2009). 5As mentioned in http://banner.sourceforge.net/ 6http://biotext.berkeley.edu/data/dis treat data.html 7http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/tagger/ 84 two single inverted commas). These PoS tagged tokized data are parsed using Stanford parser8. The dependency relations provided as output by the parser are used later as features. The tokens are further processed using the following generalization and normalization steps: • each number (both integer and real) inside a token is replaced with ‘9’ • each token is further tokenized if it contains either punctuation char</context>
<context position="13055" citStr="Jimeno et al. (2008)" startWordPosition="1987" endWordPosition="1990">tion is splitted into two parts (at the index of the comma). Annotation of the original mention is removed and the splitted parts are annotated as two separate disease mentions. 85 • Short and long form separation: If both short and long forms are annotated in the same mention, then the original mention is discarded and the corresponding short and long forms are annotated separately. 4 Features for Disease Recognition There are compelling reasons to believe that various issues regarding the well studied gene/protein mention recognition would not apply to the other semantic types. For example, Jimeno et al. (2008) argue that the use of disease terms in biomedical literature is well standardized, which is quite opposite for the gene terms (Smith et al., 2008). After a thorough study and extensive experiments on various features and their possible combinations, we have selected a feature set specific to the disease mention identification which comprises features shown in Tables 1, 2, 4 and 3, and dictionary lookup features. Feature name Description PoS Part-of-speech tag NormWord Normalized token (see Section 3.1) Lemma Lemmatized form charNgram 3 and 4 character n-grams Suffix 2-4 character suffixes Pre</context>
<context position="19115" citStr="Jimeno et al. (2008)" startWordPosition="2945" endWordPosition="2948">n see, our approach achieves significantly higher result than that of BANNER. Initially, with only the general linguistic and orthographic features the performance is not high. However, once the contextual features are used, there is a substantial improvement in the result. Note that BANNER does not use contextual features. In fact, the use of contextual features is also quite limited in other BNER systems that achieve high performance for gene/protein identification (Smith et al., 2008). Dictionary lookup features provide a very good contribution in the outcome. This supports the argument of Jimeno et al. (2008) that the use of disease terms in biomedical literature is well standardized. Post-processing and syntactic dependency features also increase some performance. We have done statistical significance tests for the last four experimental results shown in Table 6. For each of such four experiments, the immediate previous experiment is considered as the baseline. The tests have been performed using the approximate randomization procedure (Noreen, 1989). We have set the number of iterations to 1,000 and the confidence level to 0.01. According to the tests, the contributions of contextual features an</context>
</contexts>
<marker>Jimeno, Jimnez-Ruiz, Lee, Gaudan, Berlanga, Rebholz-Schuhmann, 2008</marker>
<rawString>Jimeno, A., Jimnez-Ruiz, E., Lee, V., Gaudan, S., Berlanga, R., Rebholz-Schuhmann, D. 2008. Assessment of disease named entity recognition on a corpus of annotated sentences. BMC Bioinformatics, 9(S-3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Klinger</author>
<author>K Tomanek</author>
</authors>
<title>Classical Probabilistic Models and Conditional Random Fields.</title>
<date>2007</date>
<tech>Technical Report TR07-2-013,</tech>
<institution>Department of Computer Science, Dortmund University of Technology,</institution>
<contexts>
<context position="11051" citStr="Klinger and Tomanek, 2007" startWordPosition="1662" endWordPosition="1665">sed tokens. To collect the orthographic features, the original tokens inside the corresponding sentences are considered. The contextual features 8http://nlp.stanford.edu/software/lex-parser.shtml 9http://lexsrv3.nlm.nih.gov/SPECIALIST/index.html are derived using other extracted features and the original tokens. Tokens are labeled with the corresponding disease annotations according to the IOB2 format. Our system uses Mallet (McCallum, 2002) to train a first-order CRF model. CRF is a state-of-theart ML technique applied to a variety of text processing tasks including named entity recognition (Klinger and Tomanek, 2007) and has been successfully used by many other BNER systems (Smith et al., 2008). 3.3 Post-processing Once the disease mentions are identified using the learned model, the following post-processing techniques are applied to reduce the number of wrong identifications: • Bracket mismatch correction: If there is a mismatch of brackets in the identified mention, then the immediate following (or preceding) character of the corresponding mention is checked and included inside the mention if that character is the missing bracket. Otherwise, all the characters from the index where the mismatched bracke</context>
</contexts>
<marker>Klinger, Tomanek, 2007</marker>
<rawString>Klinger, R., Tomanek, K. 2007. Classical Probabilistic Models and Conditional Random Fields. Technical Report TR07-2-013, Department of Computer Science, Dortmund University of Technology, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kulick</author>
<author>A Bies</author>
<author>M Liberman</author>
<author>M Mandel</author>
<author>R McDonald</author>
<author>M Palmer</author>
<author>A Schein</author>
<author>L Ungar</author>
</authors>
<title>Integrated annotation for biomedical information extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT/NAACL 2004 BioLink Workshop,</booktitle>
<pages>61--68</pages>
<contexts>
<context position="4265" citStr="Kulick et al., 2004" startWordPosition="642" endWordPosition="645">f relation extraction and, for different reasons, they 1The source code of our system is available for download at http://hlt.fbk.eu/people/chowdhury/research 83 Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, ACL 2010, pages 83–90, Uppsala, Sweden, 15 July 2010. c�2010 Association for Computational Linguistics are not suitable for the development of ML based disease mention recognition systems (Leaman et al., 2009). For example, the BioText (Rosario and Hearst, 2004) corpus has no specific annotation guideline and contains several inconsistencies, while PennBioIE (Kulick et al., 2004) is very specific to a particular sub-domain of diseases. Among other disease annotated corpora, EBI disease corpus (Jimeno et al., 2008) is not annotated with disease mention boundaries which makes it unsuitable for BNER evaluation for diseases. Recently, an annotated corpus, named as Arizona Disease Corpus (AZDC) (Leaman et al., 2009), has been released which has adequate and suitable annotation of disease mentions following specific annotation guidelines. There has been some work on identifying diseases in clinical texts, especially in the context of CMC Medical NLP Challenge2 and i2b2 Chal</context>
</contexts>
<marker>Kulick, Bies, Liberman, Mandel, McDonald, Palmer, Schein, Ungar, 2004</marker>
<rawString>Kulick, S., Bies, A., Liberman, M., Mandel, M., McDonald, R., Palmer, M., Schein, A., Ungar, L. 2004. Integrated annotation for biomedical information extraction. In Proceedings of HLT/NAACL 2004 BioLink Workshop, pages 61–68.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Leaman</author>
<author>G Gonzalez</author>
</authors>
<title>Banner: An executable survey of advances in biomedical named entity recognition.</title>
<date>2008</date>
<booktitle>In Proceedings of Pacific Symposium on Biocomputing,</booktitle>
<volume>13</volume>
<pages>652--663</pages>
<contexts>
<context position="6953" citStr="Leaman and Gonzalez (2008)" startWordPosition="1042" endWordPosition="1045">rg/challenge/index.php 3https://www.i2b2.org/NLP/Relations/Main.php tated with those entities that participate in diseasegene and disease-treatment relations. The reported results show F-measure for recognition of all the entities that participate in the relations and do not indicate which F-measure has been achieved specifically for disease recognition. Hence, the reported results are not applicable for comparison. To the best of our knowledge, the only systematic experimental results reported for disease mention recognition in biomedical literature using ML based approaches are published by Leaman and Gonzalez (2008) and Leaman et al. (2009).4 They have used a CRF based BNER system named BANNER which basically uses a set of orthographic, morphological and shallow syntactic features (Leaman and Gonzalez, 2008). The system achieves an F-score of 86.43 on the BioCreative II GM corpus5 which is one of the best results for gene mention recognition task on that corpus. BANNER achieves an F-score of 54.84 for disease mention recognition on the BioText corpus (Leaman and Gonzalez, 2008). However, as said above, the BioText corpus contains annotation inconsistencies6. So, the corpus is not ideal for comparing syst</context>
</contexts>
<marker>Leaman, Gonzalez, 2008</marker>
<rawString>Leaman, R., Gonzalez, G. 2008. Banner: An executable survey of advances in biomedical named entity recognition. In Proceedings of Pacific Symposium on Biocomputing, volume 13, pages 652–663.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Leaman</author>
<author>C Miller</author>
<author>G Gonzalez</author>
</authors>
<title>Enabling recognition of diseases in biomedical text with machine learning: Corpus and benchmark.</title>
<date>2009</date>
<booktitle>In Proceedings of the 3rd International Symposium on Languages in Biology and Medicine,</booktitle>
<pages>82--89</pages>
<contexts>
<context position="1806" citStr="Leaman et al., 2009" startWordPosition="264" endWordPosition="268">ndispensable. One of the essential requirements for a text mining application is the ability to identify relevant entities, i.e. named entity recognition. Previous work on biomedical named entity recognition (BNER) has been mostly focused on gene/protein mention recognition. Machine learning (ML) based approaches for gene/protein mention recognition have already achieved a sufficient level of maturity (Torii et al., 2009). However, the lack of availability of adequately annotated corpora has hindered the progress of BNER research for other semantic types such as diseases (Jimeno et al., 2008; Leaman et al., 2009). Correct identification of diseases is crucial for various disease-centric knowledge extraction tasks (e.g. drug discovery (Agarwal and Searls, 2008)). Previous studies argue that the most promising candidate for the improvement of disease related relation extraction (e.g. disease-gene) is the correct identification of concept mentions including diseases (Bundschus et al., 2008). In this paper, we present a BNER system which uses a feature set specifically tailored for disease mention recognition. The system1 outperforms other approaches evaluated on the Arizona Disease Corpus (AZDC) (more de</context>
<context position="4092" citStr="Leaman et al., 2009" startWordPosition="616" endWordPosition="619">on, location, gene and so on). Although several disease annotated corpora have been released in the last few years, they have been annotated primarily to serve the purpose of relation extraction and, for different reasons, they 1The source code of our system is available for download at http://hlt.fbk.eu/people/chowdhury/research 83 Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, ACL 2010, pages 83–90, Uppsala, Sweden, 15 July 2010. c�2010 Association for Computational Linguistics are not suitable for the development of ML based disease mention recognition systems (Leaman et al., 2009). For example, the BioText (Rosario and Hearst, 2004) corpus has no specific annotation guideline and contains several inconsistencies, while PennBioIE (Kulick et al., 2004) is very specific to a particular sub-domain of diseases. Among other disease annotated corpora, EBI disease corpus (Jimeno et al., 2008) is not annotated with disease mention boundaries which makes it unsuitable for BNER evaluation for diseases. Recently, an annotated corpus, named as Arizona Disease Corpus (AZDC) (Leaman et al., 2009), has been released which has adequate and suitable annotation of disease mentions follow</context>
<context position="6978" citStr="Leaman et al. (2009)" startWordPosition="1047" endWordPosition="1050">/www.i2b2.org/NLP/Relations/Main.php tated with those entities that participate in diseasegene and disease-treatment relations. The reported results show F-measure for recognition of all the entities that participate in the relations and do not indicate which F-measure has been achieved specifically for disease recognition. Hence, the reported results are not applicable for comparison. To the best of our knowledge, the only systematic experimental results reported for disease mention recognition in biomedical literature using ML based approaches are published by Leaman and Gonzalez (2008) and Leaman et al. (2009).4 They have used a CRF based BNER system named BANNER which basically uses a set of orthographic, morphological and shallow syntactic features (Leaman and Gonzalez, 2008). The system achieves an F-score of 86.43 on the BioCreative II GM corpus5 which is one of the best results for gene mention recognition task on that corpus. BANNER achieves an F-score of 54.84 for disease mention recognition on the BioText corpus (Leaman and Gonzalez, 2008). However, as said above, the BioText corpus contains annotation inconsistencies6. So, the corpus is not ideal for comparing system performances. The AZDC</context>
<context position="8600" citStr="Leaman et al., 2009" startWordPosition="1305" endWordPosition="1308">ng, feature extraction and model training, and post-processing. 3.1 Pre-processing At first, the system uses GeniaTagger7 to tokenize texts and provide PoS tagging. After that, it corrects some common inconsistencies introduced by GeniaTagger inside the tokenized data (e.g. GeniaTagger replaces double inverted commas with 4However, there are some work on disease recognition in biomedical literature using other techniques such as morphosyntactic heuristic based approach (e.g. MetaMap (Aronson, 2001)), dictionary look-up method and statistical approach (Neveol et al., 2009; Jimeno et al., 2008; Leaman et al., 2009). 5As mentioned in http://banner.sourceforge.net/ 6http://biotext.berkeley.edu/data/dis treat data.html 7http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/tagger/ 84 two single inverted commas). These PoS tagged tokized data are parsed using Stanford parser8. The dependency relations provided as output by the parser are used later as features. The tokens are further processed using the following generalization and normalization steps: • each number (both integer and real) inside a token is replaced with ‘9’ • each token is further tokenized if it contains either punctuation characters or both digits </context>
<context position="15106" citStr="Leaman et al. (2009)" startWordPosition="2329" endWordPosition="2332">odifier Table 4: Syntactic dependency features for tokenZ. Table 1: General linguistic features for tokenZ For example, in the sentence “Clinton defeated Dole”, “Clinton” is the nsubj of the target token “defeated”. Feature name Description InitCap Is initial letter capital AllCap Are all letters capital MixCase Does contain mixed case letters SingLow Is a single lower case letter SingUp Is a single upper case letter Num Is a number PuncChar Punctuation character (if tokenZ is a punctuation character) PrevCharAN Is previous character alphanumeric Table 2: Orthographic features for tokenZ Like Leaman et al. (2009), we have created a dictionary with the instances of the following nine of the twelve UMLS semantic types from the semantic group “DISORDER”10 from UMLS Metathesaurus (Bodenreider, 2004): (i) disease or syndrome, (ii) neoplastic process, (iii) congenital abnormality, (iv) acquired abnormality, (v) experimental model of disease, (vi) injury or poisoning, (vii) mental or behavioral dysfunction, (viii) pathological function and (ix) sign or symptom. We have not considered the other three semantic types (findings, anatomical abnormality and cell or molecular Dysfunction) since these three types ha</context>
<context position="16640" citStr="Leaman et al., 2009" startWordPosition="2554" endWordPosition="2558">; Leaman et al., 2009). However, an unprocessed dictionary usually does not boost overall performance (Zweigenbaum et al., 2007). So, to reduce uninformative lexical differences or spelling variations, we generalize and normalize the dictionary entries using exactly the same steps followed for the pre-processing of sentences (see Section 3.1). To reduce chances of false and unlikely matches, any entry inside the dictionary having less than 3 characters or more than 10 tokens is discarded. 5 Experiments 5.1 Data We have done experiments on the recently released Arizona Disease Corpus (AZDC)11 (Leaman et al., 2009). The corpus has detailed annotations of diseases including UMLS codes, UMLS concept names, possible alternative codes, and start and end points of disease mentions inside the corresponding sentences. These detailed annotations make this corpus a valuable resource for evaluating and benchmarking text mining solutions for disease recognition. Table 5 shows various characteristics of the corpus. Item name Total count Abstracts 793 Sentences 2,783 Total disease mentions 3,455 Disease mentions without overlaps 3,093 Disease mentions with overlaps 362 Table 5: Various characteristics of AZDC. For t</context>
<context position="17961" citStr="Leaman et al. (2009)" startWordPosition="2749" endWordPosition="2752">nsidered only the larger annotations in our experiments. There remain 3,224 disease mentions after resolving overlaps according to the aforementioned criterion. We have observed minor differences in some statistics of the AZDC reported by Leaman et al. (2009) with the statistics of the downloadable version12 (Table 5). How11Downloaded from http://diego.asu.edu/downloads/AZDC/ at 5-Feb-2009 12Note that “Disease mentions (total)” in the paper of Leaman et al. (2009) actually refers to the total disease mentions after overlap resolving (Robert Leaman, personal communication). One other thing is, Leaman et al. (2009) mention 794 ever, these differences can be considered negligible. 5.2 Results We follow an experimental setting similar to the one in Leaman et al. (2009) so that we can compare our results with that of the BANNER system. We performed 10-fold cross validation on AZDC in such a way that all sentences of the same abstract are included in the same fold. The results of all folds are averaged to obtain the final outcome. Table 6 shows the results of the experiments with different features using the exact matching criterion. As we can see, our approach achieves significantly higher result than that</context>
<context position="24997" citStr="Leaman et al., 2009" startWordPosition="3870" endWordPosition="3873">tionary lookup features. We have evaluated our approach on AZDC corpus. Our approach achieves significantly higher result than BANNER which is the current state-of-the-art ML based approach for disease mention recognition. We have also explained why the choice of features for the well studied gene/protein does not apply for other semantic types such as diseases. 13We have done some experiments on Biocreative II GM corpus with syntactic dependency relations of the tokens, which are not reported in this paper, and the results support our argument. 88 System Note Precision Recall F-score BANNER (Leaman et al., 2009) 80.9 75.1 77.9 Our system Using general linguistic and orthographic features 74.90 71.01 72.90 Our system After adding contextual features 82.15 75.81 78.85 Our system After adding post-processing 81.57 76.61 79.01 Our system After adding syntactic dependency features 82.07 76.66 79.27 Our system After adding dictionary lookup features 83.21 79.06 81.08 Table 6: 10-fold cross validation results using exact matching criteria on AZDC. Experiment Note Precision Recall F-score Using general linguistic, orthographic 82.15 75.81 78.85 and contextual features After adding WC and BWC features in (i) </context>
</contexts>
<marker>Leaman, Miller, Gonzalez, 2009</marker>
<rawString>Leaman, R., Miller, C., Gonzalez, G. 2009. Enabling recognition of diseases in biomedical text with machine learning: Corpus and benchmark. In Proceedings of the 3rd International Symposium on Languages in Biology and Medicine, pages 82–89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
</authors>
<title>Mallet: A machine learning for language toolkit.</title>
<date>2002</date>
<note>http://mallet.cs.umass.edu,.</note>
<contexts>
<context position="10870" citStr="McCallum, 2002" startWordPosition="1634" endWordPosition="1635">e discarded. The syntactic dependency features are extracted from the output of the parser while the general linguistic features are extracted directly from the preprocessed tokens. To collect the orthographic features, the original tokens inside the corresponding sentences are considered. The contextual features 8http://nlp.stanford.edu/software/lex-parser.shtml 9http://lexsrv3.nlm.nih.gov/SPECIALIST/index.html are derived using other extracted features and the original tokens. Tokens are labeled with the corresponding disease annotations according to the IOB2 format. Our system uses Mallet (McCallum, 2002) to train a first-order CRF model. CRF is a state-of-theart ML technique applied to a variety of text processing tasks including named entity recognition (Klinger and Tomanek, 2007) and has been successfully used by many other BNER systems (Smith et al., 2008). 3.3 Post-processing Once the disease mentions are identified using the learned model, the following post-processing techniques are applied to reduce the number of wrong identifications: • Bracket mismatch correction: If there is a mismatch of brackets in the identified mention, then the immediate following (or preceding) character of th</context>
</contexts>
<marker>McCallum, 2002</marker>
<rawString>McCallum, A. 2002. Mallet: A machine learning for language toolkit. http://mallet.cs.umass.edu,.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Meystre</author>
<author>G Savova</author>
<author>K Kipper-Schuler</author>
<author>J Hurdle</author>
</authors>
<title>Extracting information from textual documents in the electronic health record: a review of recent research.</title>
<date>2008</date>
<journal>IMIA Yearbook of Medical Informatics,</journal>
<pages>128--44</pages>
<contexts>
<context position="4915" citStr="Meystre et al. (2008)" startWordPosition="744" endWordPosition="747">ular sub-domain of diseases. Among other disease annotated corpora, EBI disease corpus (Jimeno et al., 2008) is not annotated with disease mention boundaries which makes it unsuitable for BNER evaluation for diseases. Recently, an annotated corpus, named as Arizona Disease Corpus (AZDC) (Leaman et al., 2009), has been released which has adequate and suitable annotation of disease mentions following specific annotation guidelines. There has been some work on identifying diseases in clinical texts, especially in the context of CMC Medical NLP Challenge2 and i2b2 Challenge3. However, as noted by Meystre et al. (2008), there are a number of reasons that make clinical texts different from texts of biomedical literature, e.g. composition of short, telegraphic phrases, use of implicit templates and pseudotables and so on. Hence, the strategies adopted for NER on clinical texts are not the same as the ones practiced for NER on biomedical literature. As mentioned before, most of the work to date on BNER is focused on gene/protein mention recognition. State-of-the-art BNER systems are based on ML techniques such as conditional random fields (CRFs), support vector machines (SVMs) etc (Dai et al., 2009). These sys</context>
</contexts>
<marker>Meystre, Savova, Kipper-Schuler, Hurdle, 2008</marker>
<rawString>Meystre, S., Savova, G., Kipper-Schuler, K., Hurdle, J. 2008. Extracting information from textual documents in the electronic health record: a review of recent research. IMIA Yearbook of Medical Informatics, pages 128–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Neveol</author>
<author>W Kim</author>
<author>W Wilbur</author>
<author>Z Lu</author>
</authors>
<title>Exploring two biomedical text genres for disease recognition.</title>
<date>2009</date>
<booktitle>In Proceedings of the BioNLP 2009 Workshop,</booktitle>
<pages>144--152</pages>
<contexts>
<context position="8557" citStr="Neveol et al., 2009" startWordPosition="1297" endWordPosition="1300">hree stages in our approach – pre-processing, feature extraction and model training, and post-processing. 3.1 Pre-processing At first, the system uses GeniaTagger7 to tokenize texts and provide PoS tagging. After that, it corrects some common inconsistencies introduced by GeniaTagger inside the tokenized data (e.g. GeniaTagger replaces double inverted commas with 4However, there are some work on disease recognition in biomedical literature using other techniques such as morphosyntactic heuristic based approach (e.g. MetaMap (Aronson, 2001)), dictionary look-up method and statistical approach (Neveol et al., 2009; Jimeno et al., 2008; Leaman et al., 2009). 5As mentioned in http://banner.sourceforge.net/ 6http://biotext.berkeley.edu/data/dis treat data.html 7http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/tagger/ 84 two single inverted commas). These PoS tagged tokized data are parsed using Stanford parser8. The dependency relations provided as output by the parser are used later as features. The tokens are further processed using the following generalization and normalization steps: • each number (both integer and real) inside a token is replaced with ‘9’ • each token is further tokenized if it contains ei</context>
</contexts>
<marker>Neveol, Kim, Wilbur, Lu, 2009</marker>
<rawString>Neveol, A., Kim, W., Wilbur, W., Lu, Z. 2009. Exploring two biomedical text genres for disease recognition. In Proceedings of the BioNLP 2009 Workshop, pages 144–152, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Nadeau</author>
<author>S Sekine</author>
</authors>
<title>A survey of named entity recognition and classification.</title>
<date>2007</date>
<booktitle>Linguisticae Investigationes,</booktitle>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="22676" citStr="Nadeau and Sekine, 2007" startWordPosition="3511" endWordPosition="3514">sonable because gene/protein names are much more complex than entities such as diseases. For example, they often contain punctuation characters (such as parentheses or hyphen), Greek alphabets and digits which are unlikely in disease names. Ideally, the ML algorithm itself should be able to utilize information from only the useful features and ignore the others in the feature set. But practically, having non-informative features often mislead the model learning. In fact, several surveys have argued that the choice of features matter at least as much as the choice of the algorithm if not more (Nadeau and Sekine, 2007; Zweigenbaum et al., 2007). One of the interesting trends in gene/protein mention identification is to not utilize syntactic dependency relations (with the exception of Vlachos (2007)). Gene/protein names in biomedical literature are often combined (i.e. without being separated by space characters) with other characters which do not belong to the corresponding mentions (e.g. p53-mediated). Moreover, as mentioned before, gene/protein mentions commonly have very complex structures (e.g. PKI?(]- 55] KR(l55l )K64E/K296R or RXRalphaF318A). So, it is a common practice to tokenize gene/proten names </context>
</contexts>
<marker>Nadeau, Sekine, 2007</marker>
<rawString>Nadeau, D., Sekine, S. 2007. A survey of named entity recognition and classification. Linguisticae Investigationes, 30(1):3–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E W Noreen</author>
</authors>
<title>Computer-Intensive Methods for Testing Hypotheses: An Introduction.</title>
<date>1989</date>
<publisher>WileyInterscience.</publisher>
<contexts>
<context position="19566" citStr="Noreen, 1989" startWordPosition="3015" endWordPosition="3016">dentification (Smith et al., 2008). Dictionary lookup features provide a very good contribution in the outcome. This supports the argument of Jimeno et al. (2008) that the use of disease terms in biomedical literature is well standardized. Post-processing and syntactic dependency features also increase some performance. We have done statistical significance tests for the last four experimental results shown in Table 6. For each of such four experiments, the immediate previous experiment is considered as the baseline. The tests have been performed using the approximate randomization procedure (Noreen, 1989). We have set the number of iterations to 1,000 and the confidence level to 0.01. According to the tests, the contributions of contextual features and dictionary lookup features are statistically significant. However, we have found that the contributions of post-processing rules and syntactic dependency features are statistically significant only when the confidence level is 0.2 or more. Since AZDC consists of only 2,783 sentences, we can assume that the impact of post-processing rules abstracts, 2,784 sentences and 3,228 (overlap resolved) disease mentions in the AZDC. But in our downloaded v</context>
</contexts>
<marker>Noreen, 1989</marker>
<rawString>Noreen, E.W. 1989. Computer-Intensive Methods for Testing Hypotheses: An Introduction. WileyInterscience.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Rosario</author>
<author>M Hearst</author>
</authors>
<title>Classifying semantic relations in bioscience texts.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL’04).</booktitle>
<contexts>
<context position="4145" citStr="Rosario and Hearst, 2004" startWordPosition="624" endWordPosition="627">disease annotated corpora have been released in the last few years, they have been annotated primarily to serve the purpose of relation extraction and, for different reasons, they 1The source code of our system is available for download at http://hlt.fbk.eu/people/chowdhury/research 83 Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, ACL 2010, pages 83–90, Uppsala, Sweden, 15 July 2010. c�2010 Association for Computational Linguistics are not suitable for the development of ML based disease mention recognition systems (Leaman et al., 2009). For example, the BioText (Rosario and Hearst, 2004) corpus has no specific annotation guideline and contains several inconsistencies, while PennBioIE (Kulick et al., 2004) is very specific to a particular sub-domain of diseases. Among other disease annotated corpora, EBI disease corpus (Jimeno et al., 2008) is not annotated with disease mention boundaries which makes it unsuitable for BNER evaluation for diseases. Recently, an annotated corpus, named as Arizona Disease Corpus (AZDC) (Leaman et al., 2009), has been released which has adequate and suitable annotation of disease mentions following specific annotation guidelines. There has been so</context>
</contexts>
<marker>Rosario, Hearst, 2004</marker>
<rawString>Rosario, B., Hearst, M. 2004. Classifying semantic relations in bioscience texts. In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL’04).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Schwartz</author>
<author>M Hearst</author>
</authors>
<title>A simple algorithm for identifying abbreviation definitions in biomedical text.</title>
<date>2003</date>
<booktitle>In Proceedings of Pacific Symposium on Biocomputing,</booktitle>
<pages>451--62</pages>
<contexts>
<context position="12039" citStr="Schwartz and Hearst (2003)" startWordPosition="1817" endWordPosition="1820">en the immediate following (or preceding) character of the corresponding mention is checked and included inside the mention if that character is the missing bracket. Otherwise, all the characters from the index where the mismatched bracket exists inside the identified mention are discarded from the corresponding mention. • One sense per discourse: If any instance of a character sequence is identified as a disease mention, then all the other instances of that character sequence inside the same sentence are also annotated as disease mentions. • Short/long form annotation: Using the algorithm of Schwartz and Hearst (2003), “long form (short form)” instances are detected inside sentences. If the short form is annotated as disease mention, then the long form is also annotated and vice versa. • Ungrammatical conjunction structure correction: If an annotated mention contains comma (,) but there is no “and” in the following character sequence (from the character index of that comma) of that mention, then the annotation is splitted into two parts (at the index of the comma). Annotation of the original mention is removed and the splitted parts are annotated as two separate disease mentions. 85 • Short and long form s</context>
</contexts>
<marker>Schwartz, Hearst, 2003</marker>
<rawString>Schwartz, A., Hearst, M. 2003. A simple algorithm for identifying abbreviation definitions in biomedical text. In Proceedings of Pacific Symposium on Biocomputing, pages 451–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Settles</author>
</authors>
<title>Biomedical named entity recognition using conditional random fields and rich feature sets.</title>
<date>2004</date>
<booktitle>In Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications,</booktitle>
<pages>104--107</pages>
<contexts>
<context position="21637" citStr="Settles, 2004" startWordPosition="3351" endWordPosition="3352">taglucosidase GBA”). Only 28 of them are correctly annotated by our system. The major source of errors, however, concerns abbreviated disease names (e.g. “PNH”). We believe one way to reduce this specific error type is to generate a list of possible abbreviated disease names from the long forms of disease names available in databases such as UMLS Metathesaurus. 6 Why Features for Diseases and Genes/Proteins are not the Same Many of the existing BNER systems, which are mainly tuned for gene/protein identification, use features such as token shape (also known as word class and brief word class (Settles, 2004)), Greek alphabet matching, Roman number matching and so forth. As mentioned earlier, we have done extensive experiments with various feature combinations for the selection of disease specific features. We have observed that many of the features used for gene/protein identification are not equally effective for disease identification. Table 7 shows some of the results of those experiments. This observation is reasonable because gene/protein names are much more complex than entities such as diseases. For example, they often contain punctuation characters (such as parentheses or hyphen), Greek a</context>
</contexts>
<marker>Settles, 2004</marker>
<rawString>Settles, B. 2004. Biomedical named entity recognition using conditional random fields and rich feature sets. In Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications, pages 104–107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Smith</author>
<author>L Tanabe</author>
<author>R Ando</author>
<author>C Kuo</author>
</authors>
<title>Overview of BioCreative II gene mention recognition. Genome Biology, 9(Suppl 2).</title>
<date>2008</date>
<contexts>
<context position="11130" citStr="Smith et al., 2008" startWordPosition="1676" endWordPosition="1679">sponding sentences are considered. The contextual features 8http://nlp.stanford.edu/software/lex-parser.shtml 9http://lexsrv3.nlm.nih.gov/SPECIALIST/index.html are derived using other extracted features and the original tokens. Tokens are labeled with the corresponding disease annotations according to the IOB2 format. Our system uses Mallet (McCallum, 2002) to train a first-order CRF model. CRF is a state-of-theart ML technique applied to a variety of text processing tasks including named entity recognition (Klinger and Tomanek, 2007) and has been successfully used by many other BNER systems (Smith et al., 2008). 3.3 Post-processing Once the disease mentions are identified using the learned model, the following post-processing techniques are applied to reduce the number of wrong identifications: • Bracket mismatch correction: If there is a mismatch of brackets in the identified mention, then the immediate following (or preceding) character of the corresponding mention is checked and included inside the mention if that character is the missing bracket. Otherwise, all the characters from the index where the mismatched bracket exists inside the identified mention are discarded from the corresponding men</context>
<context position="13202" citStr="Smith et al., 2008" startWordPosition="2013" endWordPosition="2016">wo separate disease mentions. 85 • Short and long form separation: If both short and long forms are annotated in the same mention, then the original mention is discarded and the corresponding short and long forms are annotated separately. 4 Features for Disease Recognition There are compelling reasons to believe that various issues regarding the well studied gene/protein mention recognition would not apply to the other semantic types. For example, Jimeno et al. (2008) argue that the use of disease terms in biomedical literature is well standardized, which is quite opposite for the gene terms (Smith et al., 2008). After a thorough study and extensive experiments on various features and their possible combinations, we have selected a feature set specific to the disease mention identification which comprises features shown in Tables 1, 2, 4 and 3, and dictionary lookup features. Feature name Description PoS Part-of-speech tag NormWord Normalized token (see Section 3.1) Lemma Lemmatized form charNgram 3 and 4 character n-grams Suffix 2-4 character suffixes Prefix 2-4 character prefixes Feature name Description Bi-gramk,k+1 Bi-grams of for i − 2 &lt; k &lt; i + 2 normalized tokens Tri-gramk,k+1,k+2 Tri-grams of</context>
<context position="18987" citStr="Smith et al., 2008" startWordPosition="2924" endWordPosition="2927">inal outcome. Table 6 shows the results of the experiments with different features using the exact matching criterion. As we can see, our approach achieves significantly higher result than that of BANNER. Initially, with only the general linguistic and orthographic features the performance is not high. However, once the contextual features are used, there is a substantial improvement in the result. Note that BANNER does not use contextual features. In fact, the use of contextual features is also quite limited in other BNER systems that achieve high performance for gene/protein identification (Smith et al., 2008). Dictionary lookup features provide a very good contribution in the outcome. This supports the argument of Jimeno et al. (2008) that the use of disease terms in biomedical literature is well standardized. Post-processing and syntactic dependency features also increase some performance. We have done statistical significance tests for the last four experimental results shown in Table 6. For each of such four experiments, the immediate previous experiment is considered as the baseline. The tests have been performed using the approximate randomization procedure (Noreen, 1989). We have set the num</context>
<context position="23405" citStr="Smith et al., 2008" startWordPosition="3620" endWordPosition="3623">ilize syntactic dependency relations (with the exception of Vlachos (2007)). Gene/protein names in biomedical literature are often combined (i.e. without being separated by space characters) with other characters which do not belong to the corresponding mentions (e.g. p53-mediated). Moreover, as mentioned before, gene/protein mentions commonly have very complex structures (e.g. PKI?(]- 55] KR(l55l )K64E/K296R or RXRalphaF318A). So, it is a common practice to tokenize gene/proten names adopting an approach that split tokens as much as possible to extract effective features (Torii et al., 2009; Smith et al., 2008). But while the extensive tokenization boosts performance, it is often difficult to correctly detect dependency relations for the tokens of the gene/protein names in the sentences where they appear. As a result, use of the syntactic dependency relations is not beneficial in such approaches.13 In comparison, disease mentions are less complex. So, the identified dependencies for disease mentions are more reliable and hence may be usable as potential features (refer to our experimental results in Table 6). The above mentioned issues are some of the reasons why a feature set for the well studied g</context>
</contexts>
<marker>Smith, Tanabe, Ando, Kuo, 2008</marker>
<rawString>Smith, L., Tanabe, L., Ando, R., Kuo, C., et al. 2008. Overview of BioCreative II gene mention recognition. Genome Biology, 9(Suppl 2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Torii</author>
<author>Z Hu</author>
<author>C Wu</author>
<author>H Liu</author>
</authors>
<title>BiotaggerGM: a gene/protein name recognition system.</title>
<date>2009</date>
<journal>Journal of the American Medical Informatics Association : JAMIA,</journal>
<pages>16--247</pages>
<contexts>
<context position="1611" citStr="Torii et al., 2009" startWordPosition="233" endWordPosition="236">y effective for other biomedical semantic types such as diseases. 1 Introduction The massive growth of biomedical literature volume has made the development of biomedical text mining solutions indispensable. One of the essential requirements for a text mining application is the ability to identify relevant entities, i.e. named entity recognition. Previous work on biomedical named entity recognition (BNER) has been mostly focused on gene/protein mention recognition. Machine learning (ML) based approaches for gene/protein mention recognition have already achieved a sufficient level of maturity (Torii et al., 2009). However, the lack of availability of adequately annotated corpora has hindered the progress of BNER research for other semantic types such as diseases (Jimeno et al., 2008; Leaman et al., 2009). Correct identification of diseases is crucial for various disease-centric knowledge extraction tasks (e.g. drug discovery (Agarwal and Searls, 2008)). Previous studies argue that the most promising candidate for the improvement of disease related relation extraction (e.g. disease-gene) is the correct identification of concept mentions including diseases (Bundschus et al., 2008). In this paper, we pre</context>
<context position="5752" citStr="Torii et al., 2009" startWordPosition="876" endWordPosition="879">trategies adopted for NER on clinical texts are not the same as the ones practiced for NER on biomedical literature. As mentioned before, most of the work to date on BNER is focused on gene/protein mention recognition. State-of-the-art BNER systems are based on ML techniques such as conditional random fields (CRFs), support vector machines (SVMs) etc (Dai et al., 2009). These systems use either gene/protein specific features (e.g. Greek alphabet matching) or post-processing rules (e.g. extension of the identified mention boundaries to the left when a single letter with a hyphen precedes them (Torii et al., 2009)) which might not be as effective for other semantic type identification as they are for genes/proteins. There is a substantial agreement in the feature set that these systems use (most of which are actually various orthographical and morphological features). Bundschus et al. (2008) have used a CRF based approach that uses typical features for gene/protein mention recognition (i.e. no feature tailoring for disease recognition) for disease, gene and treatement recognition. The work has been evaluated on two corpora which have been anno2http://www.computationalmedicine.org/challenge/index.php 3h</context>
<context position="16020" citStr="Torii et al., 2009" startWordPosition="2460" endWordPosition="2463">v) experimental model of disease, (vi) injury or poisoning, (vii) mental or behavioral dysfunction, (viii) pathological function and (ix) sign or symptom. We have not considered the other three semantic types (findings, anatomical abnormality and cell or molecular Dysfunction) since these three types have not been used during the annotation of Arizona Disease Corpus (AZDC) which we have used in our experiments. Previous studies have shown that dictionary lookup features, i.e. name matching against a 10http://semanticnetwork.nlm.nih.gov/SemGroups/ 86 dictionary of terms, often increase recall (Torii et al., 2009; Leaman et al., 2009). However, an unprocessed dictionary usually does not boost overall performance (Zweigenbaum et al., 2007). So, to reduce uninformative lexical differences or spelling variations, we generalize and normalize the dictionary entries using exactly the same steps followed for the pre-processing of sentences (see Section 3.1). To reduce chances of false and unlikely matches, any entry inside the dictionary having less than 3 characters or more than 10 tokens is discarded. 5 Experiments 5.1 Data We have done experiments on the recently released Arizona Disease Corpus (AZDC)11 (</context>
<context position="23384" citStr="Torii et al., 2009" startWordPosition="3616" endWordPosition="3619">ication is to not utilize syntactic dependency relations (with the exception of Vlachos (2007)). Gene/protein names in biomedical literature are often combined (i.e. without being separated by space characters) with other characters which do not belong to the corresponding mentions (e.g. p53-mediated). Moreover, as mentioned before, gene/protein mentions commonly have very complex structures (e.g. PKI?(]- 55] KR(l55l )K64E/K296R or RXRalphaF318A). So, it is a common practice to tokenize gene/proten names adopting an approach that split tokens as much as possible to extract effective features (Torii et al., 2009; Smith et al., 2008). But while the extensive tokenization boosts performance, it is often difficult to correctly detect dependency relations for the tokens of the gene/protein names in the sentences where they appear. As a result, use of the syntactic dependency relations is not beneficial in such approaches.13 In comparison, disease mentions are less complex. So, the identified dependencies for disease mentions are more reliable and hence may be usable as potential features (refer to our experimental results in Table 6). The above mentioned issues are some of the reasons why a feature set f</context>
</contexts>
<marker>Torii, Hu, Wu, Liu, 2009</marker>
<rawString>Torii, M., Hu, Z., Wu, C., Liu, H. 2009. BiotaggerGM: a gene/protein name recognition system. Journal of the American Medical Informatics Association : JAMIA, 16:247–255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Vlachos</author>
</authors>
<title>Tackling the BioCreative2 gene mention task with conditional random fields and syntactic parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2nd BioCreative Challenge Evaluation Workshop,</booktitle>
<pages>85--87</pages>
<contexts>
<context position="22860" citStr="Vlachos (2007)" startWordPosition="3539" endWordPosition="3541">and digits which are unlikely in disease names. Ideally, the ML algorithm itself should be able to utilize information from only the useful features and ignore the others in the feature set. But practically, having non-informative features often mislead the model learning. In fact, several surveys have argued that the choice of features matter at least as much as the choice of the algorithm if not more (Nadeau and Sekine, 2007; Zweigenbaum et al., 2007). One of the interesting trends in gene/protein mention identification is to not utilize syntactic dependency relations (with the exception of Vlachos (2007)). Gene/protein names in biomedical literature are often combined (i.e. without being separated by space characters) with other characters which do not belong to the corresponding mentions (e.g. p53-mediated). Moreover, as mentioned before, gene/protein mentions commonly have very complex structures (e.g. PKI?(]- 55] KR(l55l )K64E/K296R or RXRalphaF318A). So, it is a common practice to tokenize gene/proten names adopting an approach that split tokens as much as possible to extract effective features (Torii et al., 2009; Smith et al., 2008). But while the extensive tokenization boosts performan</context>
</contexts>
<marker>Vlachos, 2007</marker>
<rawString>Vlachos, A. 2007. Tackling the BioCreative2 gene mention task with conditional random fields and syntactic parsing. In Proceedings of the 2nd BioCreative Challenge Evaluation Workshop, pages 85–87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Zweigenbaum</author>
<author>D Demner-Fushman</author>
<author>H Yu</author>
<author>K Cohen</author>
</authors>
<title>Frontiers of biomedical text mining: current progress.</title>
<date>2007</date>
<journal>Brief Bioinform,</journal>
<volume>8</volume>
<issue>5</issue>
<contexts>
<context position="16148" citStr="Zweigenbaum et al., 2007" startWordPosition="2478" endWordPosition="2481">unction and (ix) sign or symptom. We have not considered the other three semantic types (findings, anatomical abnormality and cell or molecular Dysfunction) since these three types have not been used during the annotation of Arizona Disease Corpus (AZDC) which we have used in our experiments. Previous studies have shown that dictionary lookup features, i.e. name matching against a 10http://semanticnetwork.nlm.nih.gov/SemGroups/ 86 dictionary of terms, often increase recall (Torii et al., 2009; Leaman et al., 2009). However, an unprocessed dictionary usually does not boost overall performance (Zweigenbaum et al., 2007). So, to reduce uninformative lexical differences or spelling variations, we generalize and normalize the dictionary entries using exactly the same steps followed for the pre-processing of sentences (see Section 3.1). To reduce chances of false and unlikely matches, any entry inside the dictionary having less than 3 characters or more than 10 tokens is discarded. 5 Experiments 5.1 Data We have done experiments on the recently released Arizona Disease Corpus (AZDC)11 (Leaman et al., 2009). The corpus has detailed annotations of diseases including UMLS codes, UMLS concept names, possible alterna</context>
<context position="22703" citStr="Zweigenbaum et al., 2007" startWordPosition="3515" endWordPosition="3518">ein names are much more complex than entities such as diseases. For example, they often contain punctuation characters (such as parentheses or hyphen), Greek alphabets and digits which are unlikely in disease names. Ideally, the ML algorithm itself should be able to utilize information from only the useful features and ignore the others in the feature set. But practically, having non-informative features often mislead the model learning. In fact, several surveys have argued that the choice of features matter at least as much as the choice of the algorithm if not more (Nadeau and Sekine, 2007; Zweigenbaum et al., 2007). One of the interesting trends in gene/protein mention identification is to not utilize syntactic dependency relations (with the exception of Vlachos (2007)). Gene/protein names in biomedical literature are often combined (i.e. without being separated by space characters) with other characters which do not belong to the corresponding mentions (e.g. p53-mediated). Moreover, as mentioned before, gene/protein mentions commonly have very complex structures (e.g. PKI?(]- 55] KR(l55l )K64E/K296R or RXRalphaF318A). So, it is a common practice to tokenize gene/proten names adopting an approach that s</context>
</contexts>
<marker>Zweigenbaum, Demner-Fushman, Yu, Cohen, 2007</marker>
<rawString>Zweigenbaum, P., Demner-Fushman, D., Yu, H., Cohen, K. 2007. Frontiers of biomedical text mining: current progress. Brief Bioinform, 8(5):358–375.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>