<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.973364">
A Statistical Constraint Dependency Grammar (CDG) Parser
</title>
<author confidence="0.973127">
Wen Wang
</author>
<affiliation confidence="0.680812">
Speech Technology and Research Lab
SRI International
</affiliation>
<address confidence="0.6555275">
Menlo Park, CA 94025,
U.S.A.,
</address>
<email confidence="0.932594">
wwang@speech.sri.com
</email>
<author confidence="0.920248">
Mary P. Harper
</author>
<affiliation confidence="0.917096">
Electrical and Computer Engineering
Purdue University
</affiliation>
<author confidence="0.452804">
West Lafayette, IN 47907-1285,
</author>
<affiliation confidence="0.480474">
U.S.A.,
</affiliation>
<email confidence="0.989532">
harper@ecn.purdue.edu
</email>
<sectionHeader confidence="0.99476" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999754428571429">
CDG represents a sentence’s grammatical structure
as assignments of dependency relations to func-
tional variables associated with each word in the
sentence. In this paper, we describe a statistical
CDG (SCDG) parser that performs parsing incre-
mentally and evaluate it on the Wall Street Jour-
nal Penn Treebank. Using a tight integration of
multiple knowledge sources, together with distance
modeling and synergistic dependencies, this parser
achieves a parsing accuracy comparable to several
state-of-the-art context-free grammar (CFG) based
statistical parsers using a dependency-based eval-
uation metric. Factors contributing to the SCDG
parser’s performance are analyzed.
</bodyText>
<sectionHeader confidence="0.998128" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999956116666667">
Statistical parsing has been an important focus of
recent research (Magerman, 1995; Eisner, 1996;
Charniak, 1997; Collins, 1999; Ratnaparkhi, 1999;
Charniak, 2000). Several of these parsers gen-
erate constituents by conditioning probabilities on
non-terminal labels, part-of-speech (POS) tags, and
some headword information (Collins, 1999; Rat-
naparkhi, 1999; Charniak, 2000). They utilize
non-terminals that go beyond the level of a sin-
gle word and do not explicitly use lexical fea-
tures. Collins’ Model 2 parser (1999) learns the
distinction between complements and adjuncts by
using heuristics during training, distinguishes com-
plement and adjunct non-terminals, and includes
a probabilistic choice of left and right subcate-
gorization frames, while his Model 3 parser uses
gap features to model wh-movement. Charniak
(Charniak, 2000) developed a state-of-the-art sta-
tistical CFG parser and then built an effective lan-
guage model based on it (Charniak, 2001). But
his parser and language model were originally de-
signed to analyze complete sentences. Among the
statistical dependency grammar parsers, Eisner’s
(1996) best probabilistic dependency model used
unlabeled links between words and their heads, as
well as between words and their complements and
adjuncts. However, the parser does not distinguish
between complements and adjuncts or model wh-
movement. Collins’ bilexical dependency grammar
parser (1999) used head-modifier relations between
pairs of words much as in a dependency grammar,
but they are limited to relationships between words
in reduced sentences with base NPs.
Our research interest focuses on building a high
quality statistical parser for language modeling. We
chose CDG as the underlying grammar for several
reasons. Since CDGs can be lexicalized at the word-
level, a CDG parser-based language model is an
important alternative to CFG parser-based models,
which must model both non-terminals and termi-
nals. Furthermore, the lexicalization of CDG parse
rules is able to include not only lexical category in-
formation, but also a rich set of lexical features to
model subcategorization and wh-movement. By us-
ing CDG, our statistical model is able to distinguish
between adjuncts and complements. Additionally,
CDG is more powerful than CFG and is able to
model languages with crossing dependencies and
free word ordering.
In this paper, we describe and evaluate a statisti-
cal CDG parser for which the probabilities of parse
prefix hypotheses are incrementally updated when
the next input word is available, i.e., it parses in-
crementally. Section 2 describes how CDG repre-
sents a sentence’s parse and then defines a Super-
ARV, which is a lexicalization of CDG parse rules
used in our parsing model. Section 3 presents the
parsing model, while Section 4 motivates the eval-
uation metric used to evaluate our parser. Section 5
presents and discusses the experimental results.
</bodyText>
<sectionHeader confidence="0.990483" genericHeader="method">
2 CDG Parsing
</sectionHeader>
<bodyText confidence="0.999709888888889">
CDG (Harper and Helzerman, 1995) represents syn-
tactic structures using labeled dependencies be-
tween words. Consider an example CDG parse for
the sentence What did you learn depicted in the
white box of Figure 1. Each word in the parse has a
lexical category, a set of feature values, and a set of
roles that are assigned role values, each comprised
of a label indicating the grammatical role of the
word and its modifiee (i.e., the position of the word
it is modifying when it takes on that role). Consider
the role value assigned to the governor role (denoted
G) of you, np-2. The label np indicates the gram-
matical function of you when it is governed by its
head in position 2. Every word in a sentence must
have a governor role with an assigned role value.
Need roles are used to ensure that the grammatical
requirements of a word are met (e.g., subcategoriza-
tion).
</bodyText>
<table confidence="0.999342533333333">
1 2 3 4
what did you learn
pronoun verb pronoun verb
case=common subcat=base case=common subcat=obj
behavior=nominal verbtype=past behavior=nominal vtype=infinitive
type=interrogative voice=active type=personal voice=active
agr=3s inverted=yes agr=2s inverted=no
type=none type=none
gapp=yes gapp=yes
mood=whquestion mood=whquestion
agr=all agr=none
G=np-4 G=vp-1 G=np-2 G=vp-2
Need1=S-3 Need1=S-4
Need2=S-4 Need2=S-1
Need3=S-2 Need3=S-4
</table>
<page confidence="0.402173">
}
</page>
<figureCaption confidence="0.780708">
Figure 1: An example of a CDG parse and the Super-
</figureCaption>
<bodyText confidence="0.966400321428572">
ARV of the word did in the sentence what did you learn.
PX and MX([R]) represent the position of a word and its
modifiee (for role R), respectively.
Note that CDG parse information can be easily
lexicalized at the word level. This lexicalization is
able to include not only lexical category and syn-
tactic constraints, but also a rich set of lexical fea-
tures to model subcategorization and wh-movement
without a combinatorial explosion of the parametric
space (Wang and Harper, 2002). CDG can distin-
guish between adjuncts and complements due to the
use of need roles (Harper and Helzerman, 1995),
is more powerful than CFG, and has the ability to
model languages with crossing dependencies and
free word ordering (hence, this research could be
applicable to a wide variety of languages).
An almost-parsing LM based on CDG has been
developed in (Wang and Harper, 2002). The un-
derlying hidden event of this LM is a SuperARV.
A SuperARV is formally defined as a four-tuple for
a word, (C, F, (R, L, UC, MC)+, DC), where C
is the lexical category of the word, F = {Fnamei
= Fvaluei, ... , FNamef = FV aluef} is a fea-
ture vector (where Fnamez is the name of a feature
and Fvaluez is its corresponding value), DC repre-
sents the relative ordering of the positions of a word
and all of its modifiees, (R, L, UC, MC)+ is a list
of one or more four-tuples, each representing an ab-
straction of a role value assignment, where R is a
role variable, L is a functionality label, UC repre-
sents the relative position relation of a word and its
dependent, and MC encodes some modifiee con-
straints, namely, the lexical category of the modifiee
for this dependency relation. The gray box of Figure
1 presents an example of a SuperARV for the word
did. From this example, it is easy to see that a Su-
perARV is a join on the role value assignments of a
word, with explicit position information replaced by
a relation that expresses whether the modifiee points
to the current word, a previous word, or a subse-
quent word. The SuperARV structure provides an
explicit way to organize information concerning one
consistent set of dependency links for a word that
can be directly derived from a CDG parse. Super-
ARVs encode lexical information as well as syntac-
tic and semantic constraints in a uniform represen-
tation that is much more fine-grained than part-of-
speech (POS). A sentence tagged with SuperARVs
is an almost-parse since all that remains is to spec-
ify the precise position of each modifiee. SuperARV
LMs have been effective at reducing word error rate
(WER) on wide variety of continuous speech recog-
nition (CSR) tasks, including Wall Street Journal
(Wang and Harper, 2002), Broadcast News (Wang
et al., 2003), and Switchboard tasks (Wang et al.,
2004).
</bodyText>
<sectionHeader confidence="0.998892" genericHeader="method">
3 SCDG Parser
</sectionHeader>
<subsectionHeader confidence="0.999927">
3.1 The Basic Parsing Algorithm
</subsectionHeader>
<bodyText confidence="0.999941842105263">
Our SCDG parser is a probabilistic generative
model. It can be viewed as consisting of two com-
ponents: SuperARV tagging and modifiee determi-
nation. These two steps can be either loosely or
tightly integrated. To simplify discussion, we de-
scribe the loosely integrated version, but we imple-
ment and evaluate both strategies. The basic parsing
algorithm for the loosely integrated case is summa-
rized in Figure 2, with the algorithm’s symbols de-
fined in Table 1. In the first step, the top N-best
SuperARV assignments are generated for an input
sentence wi, ... , wn using token-passing (Young
et al., 1997) on a Hidden Markov Model with tri-
gram probabilistic estimations for both transition
and emission probabilities. Each SuperARV se-
quence for the sentence is represented as a sequence
of tuples: (wi, si), ... , (wn, sn), where (wk, sk)
represents the word wk and its SuperARV assign-
ment sk. These assignments are stored in a stack
</bodyText>
<figure confidence="0.908606166666666">
The SuperARV of the word &amp;quot;did&amp;quot;:
}
need role
constraints
Category: Verb
Features: {verbtype=past, voice=active, inverted=yes,
gapp=yes,mood=whquestion,agr=all}
Role=G, Label=vp, PX&gt;MX, (ModifieeCategory=pronoun)
Role=Need1, Label=S, PX&lt;MX, (ModifieeCategory=pronoun)
Role=Need2, Label=S, PX&lt;MX, (ModifieeCategory=verb)
Role=Need3, Label=S, PX=MX, (ModifieeCategory=verb)
Dependent Positional Constraints: MC
MX[G] &lt; PX = MX[Need3] &lt; MX[Need1]
&lt; MX[Need2]
C
F
(R,L,UC,MC)+
DC
</figure>
<bodyText confidence="0.998671416666667">
ranked in non-increasing order by tag assignment
probability.
During the second step, the modifiees are statis-
tically specified in a left-to-right manner. Note that
the algorithm utilizes modifiee lexical category con-
straints to filter out candidates with mismatched lex-
ical categories. When processing the word wk, k =
1, ... , n, the algorithm attempts to determine the
left dependents of wk from the closest to the far-
thest. The dependency assignment probability when
choosing the (c + 1)th left dependent (with its posi-
tion denoted dep(k, −(c + 1))) is defined as:
</bodyText>
<equation confidence="0.925179">
Pr(link(sdep(k,−(c+1)), sk, −(c + 1)|syn, H))
</equation>
<bodyText confidence="0.9546195">
where H = w, sk, w, sdep(k,−(c+1)), w, sdep(k,−c)
dep(k,−1).
The dependency assignment probability is con-
ditioned on the word identity and SuperARV
assignment of wk and wdep(k,−(c+1)) as well as
all of the c previously chosen left dependents
</bodyText>
<equation confidence="0.819535">
�w, s dep(k,−c) for w A Boolean random variable
)dep(k,−1) k
</equation>
<bodyText confidence="0.999952">
syn is used to model the synergistic relationship
between certain role pairs. This mechanism allows
us to elevate, for example, the probability that the
subject of a sentence wi is governed by a tensed
verb wj when the need role value of wj points to
wi as its subject. The syn value for a dependency
relation is determined heuristically based on the
lexical category, role name, and label information
of the two dependent words. After the algorithm
statistically specifies the left dependents for wk,
it must also determine whether wk could be the
(d+ 1)th right dependent of a previously seen word
wp, p = 1, ... , k − 1 (where d denotes the number
of already assigned right dependents of wp), as
shown in Figure 2.
After processing word wk in each partial parse on
the stack, the partial parses are re-ranked according
to their updated probabilities. This procedure is it-
erated until the top parse in the stack covers the en-
tire sentence. For the tightly coupled parser, the Su-
perARV assignment to a word and specification of
its modifiees are integrated into a single step. The
parsing procedure, which is completely incremen-
tal, is implemented as a simple best-first stack-based
search. To control time and memory complexity, we
used two pruning thresholds: maximum stack depth
and maximum difference between the log proba-
bilities of the top and bottom partial parses in the
stack. These pruning thresholds are tuned based on
the tradeoff of time/memory complexity and pars-
ing accuracy on a heldout set, and they both have
hard limits.
Note the maximum likelihood estimation of de-
pendency assignment probabilities in the basic
loosely coupled parsing algorithm presented in Fig-
ure 2 is likely to suffer from data sparsity, and the
estimates for the tightly coupled algorithm are likely
to suffer even more so. Hence, we smooth the prob-
abilities using Jelinek-Mercer smoothing (Jelinek,
1997), as described in (Wang and Harper, 2003;
Wang, 2003).
</bodyText>
<subsectionHeader confidence="0.998642">
3.2 Additions to the Basic Model
</subsectionHeader>
<bodyText confidence="0.999826743589744">
Some additional features are added to the basic
model because of their potential to improve SCDG
parsing accuracy. Their efficacy is evaluated in Sec-
tion 5.
Modeling crossing dependencies: The basic pars-
ing algorithm was implemented to preclude cross-
ing dependencies; however, it is important to allow
them in order to model wh-movement in some cases
(e.g., wh-PPs).
Distance and barriers between dependents: Be-
cause distance between two dependent words is
an important factor in determining the modifiees
of a word, we evaluate an alternative model that
adds distance, Adep(k,f(c+1)),k to H in Figure 2.
Note that Adep(k,f(c+1)),k represents the distance
between position dep(k, +(c + 1)) and k. To avoid
data sparsity problems, distance is bucketed and a
discrete random variable is used to model it. We
also model punctuation and verbs based on prior
work. Like (Collins, 1999), we also found that
verbs appear to act as barriers that impact modifiee
links. Hence, a Boolean random variable that rep-
resents whether there is a verb between the depen-
dencies is added to condition the probability esti-
mations. Punctuation is treated similarly to coordi-
nation constructions with punctuation governed by
the headword of the following phrase, and heuris-
tic questions on punctuation were used to provide
additional constraints on dependency assignments
(Wang, 2003).
Modifiee lexical features: The SuperARV struc-
ture employed in the SuperARV LM (Wang and
Harper, 2002) uses only lexical categories of mod-
ifiees as modifiee constraints. In previous work
(Harper et al., 2001), modifiee lexical features were
central to increasing the selectivity of a CDG.
Hence, we have developed methods to add ad-
ditional relevant lexical features to modifiee con-
straints of a SuperARV structure (Wang, 2003).
</bodyText>
<sectionHeader confidence="0.975327" genericHeader="method">
4 Parsing Evaluation Metric
</sectionHeader>
<bodyText confidence="0.991024">
To evaluate our parser, which generates CDG anal-
yses rather than CFG constituent bracketing, we
</bodyText>
<tableCaption confidence="0.998951">
Table 1: Definitions of symbols used in the basic parsing algorithm.
</tableCaption>
<table confidence="0.997818444444445">
Term Denotes
L(sk), R(sk) all dependents of sk to the left and right of wk, respectively
N(L(sk)), N(R(sk)) the number of left and right dependents of sk, respectively
dep(k, −c), dep(k, c) cth left dependent and right dependent of sk, respectively
dep(k, −1), dep(k, 1) the position of the closest left dependent and right dependent of sk, respectively
dep(k, −N(L(sk))), dep(k, N(L(sk))) the position of the farthest left dependent and right dependent of sk, respectively
Cat(sk) the lexical category of sk
ModCat(sk, −c), ModCat(sk, c) the lexical category of sk’s cth left and right dependent (encoded in the SuperARV
structure), respectively
link(si, sj, k) the dependency relation between SuperARV si and sj with wi assigned as the kth
dependent of sj, e.g., link(sdep(k,−(c+1)), sk, −(c + 1)) indicates that
wdep(k,−(c+1)) is the (c + 1)th left dependent of sk.
D(L(sk)), D(R(sk))) the number of left and right dependents of sk already assigned, respectively
dep(k,−1) (w, s)th
words and SuperARVs of sk’s closest left dependent up to its c left dependent
(w, s�dep(k,c) words and SuperARVs of sk’s closest right dependent up to its cth right dependent
dep(k,1)
syn a random variable denoting the synergistic relation between some dependents
</table>
<bodyText confidence="0.999599035714286">
can either convert the CDG parses to CFG brack-
eting and then use PARSEVAL, or convert the CFG
bracketing generated from the gold standard CFG
parses to CDG parses and then use a metric based on
dependency links. Since our parser is trained using
a CFG-to-CDG transformer (Wang, 2003), which
maps a CFG parse tree to a unique CDG parse,
it is sensible to evaluate our parser’s accuracy us-
ing gold standard CDG parse relations. Further-
more, in the 1998 Johns Hopkins Summer work-
shop final report (Hajic et al., 1998), Collins et al.
pointed out that in general the mapping from de-
pendencies to tree structures is one-to-many: there
are many possible trees that can be generated for
a given dependency structure since, although gen-
erally trees in the Penn Treebank corpus are quite
flat, they are not consistently “flat.” This variability
adds a non-deterministic aspect to the mapping from
CDG dependencies to CFG parse trees that could
cause spurious PARSEVAL scoring errors. Addi-
tionally, when there are crossing dependencies, then
no tree can be generated for that set of dependen-
cies. Consequently, we have opted to use a trans-
former to convert CFG trees to CDG parses and de-
fine a new dependency-based metric adapted from
(Eisner, 1996). We define role value labeled pre-
cision (RLP) and role value labeled recall (RLR)
on dependency links as follows:
</bodyText>
<equation confidence="0.7657106">
correct modifiee assignments
RLP =
number of modifiees our parser found
correct modifiee assignments
RLR =
</equation>
<bodyText confidence="0.985891217391304">
number of modifiess in the gold test set parses
where a correct modifiee assignment for a word
wi in a sentence means that a three-tuple
(role id, role label, modifiee word position) (i.e.,
a role value) for wi is the same as the three-tuple
role value for the corresponding role id of wi in the
gold test parse. This differs from Eisner’s (1996)
precision and recall metrics which use no label in-
formation and score only parent (governor) assign-
ments, as in traditional dependency grammars. We
will evaluate role value labeled precision and recall
on all roles of the parse, as well as the governor-
only portion of a parse. Eisner (Eisner, 1996) and
Lin (Lin, 1995) argued that dependency link eval-
uation metrics are valuable for comparing parsers
since they are less sensitive than PARSEVAL to sin-
gle misattachment errors that may cause significant
error propagation to other constituents. This, to-
gether with the fact that we must train our parser
using CDG parses generated in a lossy manner from
a CFG treebank, we chose to use RLP and RLR to
compare our parsing accuracy with several state-of-
the-art parsers.
</bodyText>
<sectionHeader confidence="0.987498" genericHeader="evaluation">
5 Evaluation and Discussion
</sectionHeader>
<bodyText confidence="0.999966636363636">
All of the evaluations were performed on the Wall
Street Journal Penn Treebank task. Following the
traditional data setup, sections 02-21 are used for
training our parser, section 23 is used for testing,
and section 24 is used as the development set for pa-
rameter tuning and debugging. As in (Ratnaparkhi,
1999; Charniak, 2000; Collins, 1999), we evaluate
on all sentences with length :5 40 words (2,245 sen-
tences) and length &lt; 100 words (2,416 sentences).
For training our probabilistic CDG parser on this
task, the CFG bracketing of the training set is trans-
</bodyText>
<sectionHeader confidence="0.525087" genericHeader="conclusions">
BASIC PARSING ALGORITHM
</sectionHeader>
<listItem confidence="0.960025333333333">
1. Using SuperARV tagging on word sequence w1, ... , wn, obtain a set ofN-best SuperARV sequences with each
element consisting of n (word, SuperARV) tuples, denoted (w1, s1), ... , (wn, sn), which we will call an assignment.
2. For each SuperARV assignment, initialize the stack of parse prefixes with this assignment:
</listItem>
<table confidence="0.907751">
/* From left-to-right, process each (word, tag) of the assignment and generate parse prefixes */
fork: = 1, n do
/* Step a: */
/* decide left dependents of (wk, sk) from the nearest to the farthest */
for c from 0 to N(L(sk)) − 1 do
/* Choose a position for the (c + 1)th left dependent of (wk, sk) from the set of possible positions
</table>
<equation confidence="0.772335">
C = {1, ... , dep(k, −c) − 11. The position choice is denoted dep(k, −(c + 1)) * /
</equation>
<bodyText confidence="0.7355582">
/* In the following equations, different left dependent assignments will generate
different parse prefixes, each of which is stored in the stack * /
for each dep(k, −(c + 1)) from positions C = {1, ... , dep(k, −c) − 11
/* Check whether the lexical category of the choice matches the modifiee lexical
category of the (c + 1)th left dependent of (wk, sk) * /
</bodyText>
<equation confidence="0.7322895">
if Cat(sdep(k,−(c+1))) == ModCat(sk, −(c + 1)) then
Pr(T): = Pr(T) x Pr(link(sdep(k,−(c+1)), sk, −(c + 1)1syn, H))
</equation>
<bodyText confidence="0.700871">
where H = (w, s)k, (w, s)dep(k,−(c+1)), (w, s)dep(k,−c)
</bodyText>
<figure confidence="0.302127">
dep(k,−1)
/* End of choosing left dependents of (wk, sk) for this parse prefix */
/* Step b: */
/* For the word/tag pair (wk, sk), check whether it could be a right dependent of any previously
seen word within a parse prefix of (w1, s1), ... , (wk−1, sk−1) */
for p: = 1, k − 1 do
/* If (wp, sp) still has right dependents left unspecified, then try out(wk, sk) as a right dependent */
if D(R(sp)) =� N(R(sp)) then
d : = D(R(sp))
/* If the lexical category of (wk, sk) matches the modifiee lexical category of the(d + 1)th right
dependent of (wp, sp), then sk might be (wp, sp)’s (d + 1)th right dependent * /
if Cat(sk) == ModCat(sp, d + 1) then
dep(p,d)
Pr(T) : = Pr(T) x Pr(link(sk, sp, d + 1)�syn, H), where H = (w, s)p, (w, s)k, (w, s)dep(p,1)
Sort the parse prefixes in the stack according to logPr(T) and apply pruning using the thresholds.
3. After processing w1, ... , wn, pick the parse with the highest logPr(T) in the stack as the parse for that sentence.
</figure>
<figureCaption confidence="0.939137">
Figure 2: The basic loosely coupled parsing algorithm. Note the algorithm updates the probabilities of parse
prefix hypotheses incrementally when processing each input word.
</figureCaption>
<bodyText confidence="0.999643571428572">
formed into CDG annotations using a CFG-to-CDG
transformer (Wang, 2003). Note that the sound-
ness of the CFG-to-CDG transformer was evaluated
by examining the CDG parses generated from the
transformer on the Penn Treebank development set
to ensure that they were correct given our grammar
definition.
</bodyText>
<subsectionHeader confidence="0.999292">
5.1 Contribution of Model Factors
</subsectionHeader>
<bodyText confidence="0.999929129032258">
First, we investigate the contribution of the model
additions described in Section 3 to parse accuracy.
Since these factors are independent of the coupling
between the SuperARV tagger and modifiee spec-
ification, we investigate their impact on a loosely
integrated SCDG parser by comparing four models:
(1) the basic loosely integrated model; (2) the ba-
sic model with crossing dependencies; (3) model 2
with distance and barrier information; (4) model 3
with SuperARVs augmented with additional modi-
fiee lexical feature constraints. Each model uses a
trigram SuperARV tagger to generate 40-best Su-
perARV sequences prior to modifiee specification.
Table 2 shows the results for each of the four models
including SuperARV tagging accuracy (%) and role
value labeled precision and recall (%). Allowing
crossing dependencies improves the overall parsing
accuracy, but using distance information with verb
barrier and punctuation heuristics produces an even
greater improvement especially on the longer sen-
tences. The accuracy is further improved by the ad-
ditional modifiee lexical feature constraints added to
the SuperARVs. Note that RLR is lower than RLP
in these investigations possibly due to SuperARV
tagging errors and the use of a tight stack pruning
threshold.
Next, we evaluate the impact of increasing the
context of the SuperARV tagger to a 4-gram while
increasing the size of the N-best list passed from
the tagger to the modifiee specification step of the
parser. For this evaluation, we use model (4)
</bodyText>
<tableCaption confidence="0.826793">
Table 2: Results on Section 23 of the WSJ Penn Tree-
bank for four loosely-coupled model variations. The
evaluation metrics, RLR and RLP, are our dependency-
based role value labeled precision and recall. Note:
</tableCaption>
<table confidence="0.988861421052632">
Model (1) denotes the basic model, Model (2) de-
notes (1)+crossing dependencies, Model (3) denotes
(2)+distance (punctuation) model, and Model (4) denotes
(3)+modifiee lexical features.
Models &lt; 40 words (2,245 sentences)
Tagging governor only all roles
Acc.
RLP RLR RLP RLR
94.7 90.6 90.3 86.8 86.2
95.0 90.7 90.5 87.0 86.5
95.7 91.1 90.9 87.4 87.0
96.2 91.5 91.2 88.0 87.4
Models &lt; 100 words (2,416 sentences)
Tagging governor only all roles
Acc. RLP RLR RLP RLR
94.0 89.7 89.3 86.0 85.5
94.2 89.9 89.6 86.2 85.8
94.7 90.4 90.2 86.8 86.3
95.4 90.9 90.5 87.5 86.8
</table>
<tableCaption confidence="0.702801857142857">
Table 3: Results on Section 23 of the WSJ Penn Tree-
bank comparing models that utilize different SuperARV
taggers and N-best sizes with the tightly coupled imple-
mentation. Note L denotes Loose coupling and T de-
notes Tight coupling. Also (a) denotes trigram, 40-best;
(b) denotes trigram, 100-best; (c) denotes 4-gram, 40-
best; (d) denotes 4-gram, 100-best.
</tableCaption>
<table confidence="0.999892">
Models &lt; 40 words (2,245 sentences)
Tagging governor only all roles
Acc.
RLP RLR RLP RLR
L 96.2 91.5 91.2 88.0 87.4
96.7 91.9 91.5 88.3 87.7
96.9 92.2 91.7 88.6 88.1
97.2 92.4 92.3 89.1 88.6
T 97.4 93.2 92.9 89.8 89.2
Models &lt; 100 words (2,416 sentences)
Tagging governor only all roles
Acc. RLP RLR RLP RLR
L 95.4 90.9 90.5 87.5 86.8
95.8 91.3 90.8 87.7 87.0
96.0 91.7 91.2 88.0 87.4
96.3 91.8 91.5 88.5 87.8
T 96.6 92.6 92.2 89.1 88.5
</table>
<bodyText confidence="0.999524142857143">
from Table 2, the most accurate model so far. We
also evaluate whether a tight integration of left-
to-right SuperARV tagging and modifiee specifica-
tion produces a greater parsing accuracy than the
best loosely coupled counterpart. Table 3 shows
the SuperARV tagging accuracy (%) and role value
labeled precision and recall (%) for each model.
Consistent with our intuition, a stronger SuperARV
tagger and a larger search space of SuperARV se-
quences produces greater parse accuracy. However,
tightly integrating SuperARV prediction with mod-
ifiee specification achieves the greatest overall ac-
curacy. Note that SuperARV tagging accuracy and
parse accuracy improve in tandem, as can be seen
in Tables 2 and 3. These results are consistent
with the observations of (Collins, 1999) and (Eis-
ner, 1996). It is important to note that each of the
factors contributing to improved parse accuracy in
these two experiments also improved the word pre-
diction capability of the corresponding parser-based
LM (Wang and Harper, 2003).
</bodyText>
<subsectionHeader confidence="0.999174">
5.2 Comparing to Other Parsers
</subsectionHeader>
<bodyText confidence="0.999962512820513">
Charniak’s state-of-the-art PCFG parser (Charniak,
2000) has achieved the highest PARSEVAL LP/LR
when compared to Collins’ Model 2 and Model
3 (Collins, 1999), Roark’s (Roark, 2001), Ratna-
parkhi’s (Ratnaparkhi, 1999), and Xu &amp; Chelba’s
(Xu et al., 2002) parsers. Hence, we will com-
pare our best loosely integrated and tightly inte-
grated SCDG parsers to Charniak’s parser. Ad-
ditionally, we will compare with Collins’ Model
2 since it makes the complement/adjunct distinc-
tion and Model 3 since it handles wh-movement
(Collins, 1999). Charniak’s parser does not explic-
itly model these phenomena.
Among the statistical CFG parsers to be com-
pared, only Collins’ Model 3 produces trees with
information about wh-movement. Since the trans-
former uses empty node information to transform
the CFG parse trees to CDG parses, the accuracy
of Charniak’s parser and Collins’ Model 2 may be
slightly reduced for sentences with empty nodes.
Hence, we compare results on two test sets: one that
omits all sentences with traces and one that does not.
As can be seen in Table 4, our tightly coupled parser
consistently produces an accuracy that equals or ex-
ceeds the accuracies of the other parsers, with one
exception (Collins’ Model 3), regardless of whether
the test set contains sentences with traces.
Using our evaluation metrics, Collins’ Model 3
achieves a better precision/recall than Model 2 and
Charniak’s parser. Since trace information is used
by the CFG-to-CDG transformer to generate cer-
tain lexical features (Wang, 2003), the output from
Model 3 is likely to be mapped to more accu-
rate CDG parses. Although Charniak’s maximum-
entropy inspired parser achieved the highest PAR-
SEVAL results, Collins’ Model 3 is more accu-
rate using our dependency metric, possibly be-
cause it makes the complement/adjunct distinction
and models wh-movement. Since the statistical
</bodyText>
<tableCaption confidence="0.9885435">
Table 4: Evaluation of five models on Section 23 sentences with and without traces: L denotes the best loosely
coupled CDG parser and T the tightly coupled CDG parser.
</tableCaption>
<table confidence="0.99947905">
Models &lt; 40 words (2,245 sentences)
Without TRACE All
(1,903 sentences) (2,245 sentences)
governor only all roles governor only all roles
RLP RLR RLP RLR RLP RLR RLP RLR
L 92.4 92.4 89.5 88.7 92.4 92.3 89.1 88.6
T 93.2 92.9 89.9 89.3 93.2 92.9 89.8 89.2
Charniak (Charniak, 2000) 92.6 92.5 89.4 88.9 92.5 92.3 88.9 88.7
Collins, Model 2 (Collins, 1999) 92.5 92.3 89.1 88.5 92.2 92.1 89.0 88.5
Collins, Model 3 (Collins, 1999) 92.8 92.7 89.9 89.4 92.7 92.4 89.3 89.1
Models &lt; 100 words (2,416 sentences)
Without TRACE All
(1,979 sentences) (2,416 sentences)
governor only all roles governor only all roles
RLP RLR RLP RLR RLP RLR RLP RLR
L 91.9 91.6 88.8 88.1 91.8 91.5 88.5 87.8
T 92.7 92.3 89.4 88.7 92.6 92.2 89.1 88.5
Charniak (Charniak, 2000) 92.0 91.8 88.8 88.2 91.9 91.6 88.4 87.9
Collins, Model 2 (Collins, 1999) 91.8 91.6 88.6 88.0 91.7 91.5 88.2 87.9
Collins, Model 3 (Collins, 1999) 92.2 92.1 89.4 88.8 92.1 91.9 88.8 88.5
</table>
<bodyText confidence="0.9997893">
CFG parsers may loose accuracy from the CFG-to-
CDG transformation, similarly to Collins’ experi-
ment reported in (Hajic et al., 1998), we also trans-
formed our CDG parses to Penn Treebank style
CFG parse trees and scored them using PARSE-
VAL. On the WSJ PTB test set, Charniak’s parser
achieved 89.6% LR and 89.5% LP, Collins’ Model 2
and 3 obtained 88.1% LR and 88.3% LP and 88.0%
LR and 88.3% LP, while the tightly coupled CDG
parser obtains 85.8% LR and 86.4% LP. It is im-
portant to remember that this score is impacted by
two lossy conversions, one for training and one for
testing.
We have conducted a non-parametric Monte
Carlo test to determine the significance of the differ-
ences between the parsing accuracy results in Table
3 and Table 4. We found that the difference between
the tightly and loosely coupled SCDG parsers is sta-
tistically significant, as well as the difference be-
tween the SCDG parser and Charniak’s parser and
Collins’ Model 2. Although the difference between
our parser and Collins’ Model 3 is not statistically
significant, our parser represents a first attempt to
build a high quality SCDG parser, and there is still
room for improvement, e.g., better handling of bar-
riers (including punctuation) and employing more
sophisticated search and pruning strategies.
This paper has presented a statistical implemen-
tation of a CDG parser, which is both genera-
tive and highly lexicalized. With a framework
of tightly integrated, multiple knowledge sources,
model distance, and synergistic dependencies, we
have achieved a parsing accuracy comparable to the
state-of-the-art statistical parsers trained on the Wall
Street Journal Penn Treebank corpus. However,
more work must be done to build a parser model
capable of coping with speech disfluencies present
in spontaneous speech. We also intend to investi-
gate a hybrid parser that combines the generality of
a CFG with the specificity of a CDG.
</bodyText>
<sectionHeader confidence="0.998476" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999921971428571">
E. Charniak. 1997. Statistical parsing with a context-
free grammar and word statistics. In Proceedings of
the Fourteenth National Conference on Artificial In-
telligence.
E. Charniak. 2000. A Maximum-Entropy-Inspired
Parser. In Proceedings of the First Annual Meeting
of the North American Association for Computational
Linguistics.
E. Charniak. 2001. Immediate-head parsing for lan-
guage models. In Proceedings ofACL’2001.
M. Collins. 1999. Head-Driven Statistical Models for
Natural Language Parsing. Ph.D. thesis, University
of Pennsylvania.
J. M. Eisner. 1996. An empirical comparison of prob-
ability models for dependency grammar. Technical
report, University of Pennsylvania, CIS Department,
Philadelphia PA 19104-6389.
J. Hajic, E. Brill, M. Collins, B. Hladka, D. Jones,
C. Kuo, L. Ramshaw, O. Schwartz, C. Tillmann, and
D. Zeman. 1998. Core natural language processing
technology applicable to multiple languages – Work-
shop ’98. Technical report, Johns Hopkins Univ.
M. P. Harper and R. A. Helzerman. 1995. Extensions
to constraint dependency parsing for spoken language
processing. Computer Speech and Language.
M. P. Harper, W. Wang, and C. M. White. 2001. Ap-
proaches for learning constraint dependency grammar
from corpora. In Proceedings of the Grammar and
Natural Language Processing Conference, Montreal,
Canada.
F. Jelinek. 1997. Statistical Methods For Speech Recog-
nition. The MIT Press.
D. Lin. 1995. A dependency-based method for evaluat-
ing broad-coverage parsers. In Proceedings of the In-
ternational Joint Conference on Artificial Intelligence,
pages 1420–1427.
D. M. Magerman. 1995. Statistical decision-tree models
for parsing. In Proceedings of the 33rd Annual Meet-
ing of the Association for Computational Linguistics,
pages 276–283.
A. Ratnaparkhi. 1999. Learning to parse natural lan-
guage with maximum entropy models. Machine
Learning, 34:151–175.
B. Roark. 2001. Probabilistic top-down parsing
and language modeling. Computational Linguistics,
27(2):249–276.
W. Wang and M. P. Harper. 2002. The SuperARV lan-
guage model: Investigating the effectiveness of tightly
integrating multiple knowledge sources. In Proceed-
ings of Conference of Empirical Methods in Natural
Language Processing.
W. Wang and M. P. Harper. 2003. Language model-
ing using a statistical dependency grammar parser. In
Proceedings of International Workshop on Automatic
Speech Recognition and Understanding.
W. Wang, M. P. Harper, and A. Stolcke. 2003. The ro-
bustness of an almost-parsing language model given
errorful training data. In ICASSP 2003.
W. Wang, A. Stolcke, and M. P. Harper. 2004. The use
of a linguistically motivated language model in con-
versational speech recognition. In ICASSP 2004.
W. Wang. 2003. Statistical Parsing and Language Mod-
eling based on Constraint Dependency Grammar.
Ph.D. thesis, Purdue University.
P. Xu, C. Chelba, and F. Jelinek. 2002. A study on richer
syntactic dependencies for structured language mod-
eling. In Proceedings ofACL 2002.
S. J. Young, J. Odell, D. Ollason, V. Valtchev, and P. C.
Woodland, 1997. The HTK Book. Entropic Cam-
bridge Research Laboratory, Ltd.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.392788">
<title confidence="0.998575">A Statistical Constraint Dependency Grammar (CDG) Parser</title>
<author confidence="0.943959">Wen</author>
<affiliation confidence="0.932083">Speech Technology and Research SRI</affiliation>
<address confidence="0.958637">Menlo Park, CA</address>
<email confidence="0.998034">wwang@speech.sri.com</email>
<author confidence="0.995361">P Mary</author>
<affiliation confidence="0.558422">Electrical and Computer Purdue</affiliation>
<address confidence="0.648254">West Lafayette, IN</address>
<email confidence="0.999201">harper@ecn.purdue.edu</email>
<abstract confidence="0.998662333333333">CDG represents a sentence’s grammatical structure as assignments of dependency relations to functional variables associated with each word in the sentence. In this paper, we describe a statistical CDG (SCDG) parser that performs parsing incrementally and evaluate it on the Wall Street Journal Penn Treebank. Using a tight integration of multiple knowledge sources, together with distance modeling and synergistic dependencies, this parser achieves a parsing accuracy comparable to several state-of-the-art context-free grammar (CFG) based statistical parsers using a dependency-based evaluation metric. Factors contributing to the SCDG parser’s performance are analyzed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Charniak</author>
</authors>
<title>Statistical parsing with a contextfree grammar and word statistics.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fourteenth National Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="1108" citStr="Charniak, 1997" startWordPosition="148" endWordPosition="149">statistical CDG (SCDG) parser that performs parsing incrementally and evaluate it on the Wall Street Journal Penn Treebank. Using a tight integration of multiple knowledge sources, together with distance modeling and synergistic dependencies, this parser achieves a parsing accuracy comparable to several state-of-the-art context-free grammar (CFG) based statistical parsers using a dependency-based evaluation metric. Factors contributing to the SCDG parser’s performance are analyzed. 1 Introduction Statistical parsing has been an important focus of recent research (Magerman, 1995; Eisner, 1996; Charniak, 1997; Collins, 1999; Ratnaparkhi, 1999; Charniak, 2000). Several of these parsers generate constituents by conditioning probabilities on non-terminal labels, part-of-speech (POS) tags, and some headword information (Collins, 1999; Ratnaparkhi, 1999; Charniak, 2000). They utilize non-terminals that go beyond the level of a single word and do not explicitly use lexical features. Collins’ Model 2 parser (1999) learns the distinction between complements and adjuncts by using heuristics during training, distinguishes complement and adjunct non-terminals, and includes a probabilistic choice of left and </context>
</contexts>
<marker>Charniak, 1997</marker>
<rawString>E. Charniak. 1997. Statistical parsing with a contextfree grammar and word statistics. In Proceedings of the Fourteenth National Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
</authors>
<title>A Maximum-Entropy-Inspired Parser.</title>
<date>2000</date>
<booktitle>In Proceedings of the First Annual Meeting of the North American Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1159" citStr="Charniak, 2000" startWordPosition="154" endWordPosition="155">g incrementally and evaluate it on the Wall Street Journal Penn Treebank. Using a tight integration of multiple knowledge sources, together with distance modeling and synergistic dependencies, this parser achieves a parsing accuracy comparable to several state-of-the-art context-free grammar (CFG) based statistical parsers using a dependency-based evaluation metric. Factors contributing to the SCDG parser’s performance are analyzed. 1 Introduction Statistical parsing has been an important focus of recent research (Magerman, 1995; Eisner, 1996; Charniak, 1997; Collins, 1999; Ratnaparkhi, 1999; Charniak, 2000). Several of these parsers generate constituents by conditioning probabilities on non-terminal labels, part-of-speech (POS) tags, and some headword information (Collins, 1999; Ratnaparkhi, 1999; Charniak, 2000). They utilize non-terminals that go beyond the level of a single word and do not explicitly use lexical features. Collins’ Model 2 parser (1999) learns the distinction between complements and adjuncts by using heuristics during training, distinguishes complement and adjunct non-terminals, and includes a probabilistic choice of left and right subcategorization frames, while his Model 3 p</context>
<context position="18519" citStr="Charniak, 2000" startWordPosition="2968" endWordPosition="2969">r propagation to other constituents. This, together with the fact that we must train our parser using CDG parses generated in a lossy manner from a CFG treebank, we chose to use RLP and RLR to compare our parsing accuracy with several state-ofthe-art parsers. 5 Evaluation and Discussion All of the evaluations were performed on the Wall Street Journal Penn Treebank task. Following the traditional data setup, sections 02-21 are used for training our parser, section 23 is used for testing, and section 24 is used as the development set for parameter tuning and debugging. As in (Ratnaparkhi, 1999; Charniak, 2000; Collins, 1999), we evaluate on all sentences with length :5 40 words (2,245 sentences) and length &lt; 100 words (2,416 sentences). For training our probabilistic CDG parser on this task, the CFG bracketing of the training set is transBASIC PARSING ALGORITHM 1. Using SuperARV tagging on word sequence w1, ... , wn, obtain a set ofN-best SuperARV sequences with each element consisting of n (word, SuperARV) tuples, denoted (w1, s1), ... , (wn, sn), which we will call an assignment. 2. For each SuperARV assignment, initialize the stack of parse prefixes with this assignment: /* From left-to-right, </context>
<context position="25697" citStr="Charniak, 2000" startWordPosition="4191" endWordPosition="4192"> tightly integrating SuperARV prediction with modifiee specification achieves the greatest overall accuracy. Note that SuperARV tagging accuracy and parse accuracy improve in tandem, as can be seen in Tables 2 and 3. These results are consistent with the observations of (Collins, 1999) and (Eisner, 1996). It is important to note that each of the factors contributing to improved parse accuracy in these two experiments also improved the word prediction capability of the corresponding parser-based LM (Wang and Harper, 2003). 5.2 Comparing to Other Parsers Charniak’s state-of-the-art PCFG parser (Charniak, 2000) has achieved the highest PARSEVAL LP/LR when compared to Collins’ Model 2 and Model 3 (Collins, 1999), Roark’s (Roark, 2001), Ratnaparkhi’s (Ratnaparkhi, 1999), and Xu &amp; Chelba’s (Xu et al., 2002) parsers. Hence, we will compare our best loosely integrated and tightly integrated SCDG parsers to Charniak’s parser. Additionally, we will compare with Collins’ Model 2 since it makes the complement/adjunct distinction and Model 3 since it handles wh-movement (Collins, 1999). Charniak’s parser does not explicitly model these phenomena. Among the statistical CFG parsers to be compared, only Collins’</context>
<context position="27942" citStr="Charniak, 2000" startWordPosition="4558" endWordPosition="4559">llins’ Model 3 is more accurate using our dependency metric, possibly because it makes the complement/adjunct distinction and models wh-movement. Since the statistical Table 4: Evaluation of five models on Section 23 sentences with and without traces: L denotes the best loosely coupled CDG parser and T the tightly coupled CDG parser. Models &lt; 40 words (2,245 sentences) Without TRACE All (1,903 sentences) (2,245 sentences) governor only all roles governor only all roles RLP RLR RLP RLR RLP RLR RLP RLR L 92.4 92.4 89.5 88.7 92.4 92.3 89.1 88.6 T 93.2 92.9 89.9 89.3 93.2 92.9 89.8 89.2 Charniak (Charniak, 2000) 92.6 92.5 89.4 88.9 92.5 92.3 88.9 88.7 Collins, Model 2 (Collins, 1999) 92.5 92.3 89.1 88.5 92.2 92.1 89.0 88.5 Collins, Model 3 (Collins, 1999) 92.8 92.7 89.9 89.4 92.7 92.4 89.3 89.1 Models &lt; 100 words (2,416 sentences) Without TRACE All (1,979 sentences) (2,416 sentences) governor only all roles governor only all roles RLP RLR RLP RLR RLP RLR RLP RLR L 91.9 91.6 88.8 88.1 91.8 91.5 88.5 87.8 T 92.7 92.3 89.4 88.7 92.6 92.2 89.1 88.5 Charniak (Charniak, 2000) 92.0 91.8 88.8 88.2 91.9 91.6 88.4 87.9 Collins, Model 2 (Collins, 1999) 91.8 91.6 88.6 88.0 91.7 91.5 88.2 87.9 Collins, Model 3 (C</context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>E. Charniak. 2000. A Maximum-Entropy-Inspired Parser. In Proceedings of the First Annual Meeting of the North American Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
</authors>
<title>Immediate-head parsing for language models.</title>
<date>2001</date>
<booktitle>In Proceedings ofACL’2001.</booktitle>
<contexts>
<context position="1954" citStr="Charniak, 2001" startWordPosition="271" endWordPosition="272">aparkhi, 1999; Charniak, 2000). They utilize non-terminals that go beyond the level of a single word and do not explicitly use lexical features. Collins’ Model 2 parser (1999) learns the distinction between complements and adjuncts by using heuristics during training, distinguishes complement and adjunct non-terminals, and includes a probabilistic choice of left and right subcategorization frames, while his Model 3 parser uses gap features to model wh-movement. Charniak (Charniak, 2000) developed a state-of-the-art statistical CFG parser and then built an effective language model based on it (Charniak, 2001). But his parser and language model were originally designed to analyze complete sentences. Among the statistical dependency grammar parsers, Eisner’s (1996) best probabilistic dependency model used unlabeled links between words and their heads, as well as between words and their complements and adjuncts. However, the parser does not distinguish between complements and adjuncts or model whmovement. Collins’ bilexical dependency grammar parser (1999) used head-modifier relations between pairs of words much as in a dependency grammar, but they are limited to relationships between words in reduce</context>
</contexts>
<marker>Charniak, 2001</marker>
<rawString>E. Charniak. 2001. Immediate-head parsing for language models. In Proceedings ofACL’2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="1123" citStr="Collins, 1999" startWordPosition="150" endWordPosition="151">(SCDG) parser that performs parsing incrementally and evaluate it on the Wall Street Journal Penn Treebank. Using a tight integration of multiple knowledge sources, together with distance modeling and synergistic dependencies, this parser achieves a parsing accuracy comparable to several state-of-the-art context-free grammar (CFG) based statistical parsers using a dependency-based evaluation metric. Factors contributing to the SCDG parser’s performance are analyzed. 1 Introduction Statistical parsing has been an important focus of recent research (Magerman, 1995; Eisner, 1996; Charniak, 1997; Collins, 1999; Ratnaparkhi, 1999; Charniak, 2000). Several of these parsers generate constituents by conditioning probabilities on non-terminal labels, part-of-speech (POS) tags, and some headword information (Collins, 1999; Ratnaparkhi, 1999; Charniak, 2000). They utilize non-terminals that go beyond the level of a single word and do not explicitly use lexical features. Collins’ Model 2 parser (1999) learns the distinction between complements and adjuncts by using heuristics during training, distinguishes complement and adjunct non-terminals, and includes a probabilistic choice of left and right subcatego</context>
<context position="13238" citStr="Collins, 1999" startWordPosition="2105" endWordPosition="2106">; however, it is important to allow them in order to model wh-movement in some cases (e.g., wh-PPs). Distance and barriers between dependents: Because distance between two dependent words is an important factor in determining the modifiees of a word, we evaluate an alternative model that adds distance, Adep(k,f(c+1)),k to H in Figure 2. Note that Adep(k,f(c+1)),k represents the distance between position dep(k, +(c + 1)) and k. To avoid data sparsity problems, distance is bucketed and a discrete random variable is used to model it. We also model punctuation and verbs based on prior work. Like (Collins, 1999), we also found that verbs appear to act as barriers that impact modifiee links. Hence, a Boolean random variable that represents whether there is a verb between the dependencies is added to condition the probability estimations. Punctuation is treated similarly to coordination constructions with punctuation governed by the headword of the following phrase, and heuristic questions on punctuation were used to provide additional constraints on dependency assignments (Wang, 2003). Modifiee lexical features: The SuperARV structure employed in the SuperARV LM (Wang and Harper, 2002) uses only lexic</context>
<context position="18535" citStr="Collins, 1999" startWordPosition="2970" endWordPosition="2971"> other constituents. This, together with the fact that we must train our parser using CDG parses generated in a lossy manner from a CFG treebank, we chose to use RLP and RLR to compare our parsing accuracy with several state-ofthe-art parsers. 5 Evaluation and Discussion All of the evaluations were performed on the Wall Street Journal Penn Treebank task. Following the traditional data setup, sections 02-21 are used for training our parser, section 23 is used for testing, and section 24 is used as the development set for parameter tuning and debugging. As in (Ratnaparkhi, 1999; Charniak, 2000; Collins, 1999), we evaluate on all sentences with length :5 40 words (2,245 sentences) and length &lt; 100 words (2,416 sentences). For training our probabilistic CDG parser on this task, the CFG bracketing of the training set is transBASIC PARSING ALGORITHM 1. Using SuperARV tagging on word sequence w1, ... , wn, obtain a set ofN-best SuperARV sequences with each element consisting of n (word, SuperARV) tuples, denoted (w1, s1), ... , (wn, sn), which we will call an assignment. 2. For each SuperARV assignment, initialize the stack of parse prefixes with this assignment: /* From left-to-right, process each (wo</context>
<context position="25368" citStr="Collins, 1999" startWordPosition="4141" endWordPosition="4142"> greater parsing accuracy than the best loosely coupled counterpart. Table 3 shows the SuperARV tagging accuracy (%) and role value labeled precision and recall (%) for each model. Consistent with our intuition, a stronger SuperARV tagger and a larger search space of SuperARV sequences produces greater parse accuracy. However, tightly integrating SuperARV prediction with modifiee specification achieves the greatest overall accuracy. Note that SuperARV tagging accuracy and parse accuracy improve in tandem, as can be seen in Tables 2 and 3. These results are consistent with the observations of (Collins, 1999) and (Eisner, 1996). It is important to note that each of the factors contributing to improved parse accuracy in these two experiments also improved the word prediction capability of the corresponding parser-based LM (Wang and Harper, 2003). 5.2 Comparing to Other Parsers Charniak’s state-of-the-art PCFG parser (Charniak, 2000) has achieved the highest PARSEVAL LP/LR when compared to Collins’ Model 2 and Model 3 (Collins, 1999), Roark’s (Roark, 2001), Ratnaparkhi’s (Ratnaparkhi, 1999), and Xu &amp; Chelba’s (Xu et al., 2002) parsers. Hence, we will compare our best loosely integrated and tightly i</context>
<context position="28015" citStr="Collins, 1999" startWordPosition="4571" endWordPosition="4572">use it makes the complement/adjunct distinction and models wh-movement. Since the statistical Table 4: Evaluation of five models on Section 23 sentences with and without traces: L denotes the best loosely coupled CDG parser and T the tightly coupled CDG parser. Models &lt; 40 words (2,245 sentences) Without TRACE All (1,903 sentences) (2,245 sentences) governor only all roles governor only all roles RLP RLR RLP RLR RLP RLR RLP RLR L 92.4 92.4 89.5 88.7 92.4 92.3 89.1 88.6 T 93.2 92.9 89.9 89.3 93.2 92.9 89.8 89.2 Charniak (Charniak, 2000) 92.6 92.5 89.4 88.9 92.5 92.3 88.9 88.7 Collins, Model 2 (Collins, 1999) 92.5 92.3 89.1 88.5 92.2 92.1 89.0 88.5 Collins, Model 3 (Collins, 1999) 92.8 92.7 89.9 89.4 92.7 92.4 89.3 89.1 Models &lt; 100 words (2,416 sentences) Without TRACE All (1,979 sentences) (2,416 sentences) governor only all roles governor only all roles RLP RLR RLP RLR RLP RLR RLP RLR L 91.9 91.6 88.8 88.1 91.8 91.5 88.5 87.8 T 92.7 92.3 89.4 88.7 92.6 92.2 89.1 88.5 Charniak (Charniak, 2000) 92.0 91.8 88.8 88.2 91.9 91.6 88.4 87.9 Collins, Model 2 (Collins, 1999) 91.8 91.6 88.6 88.0 91.7 91.5 88.2 87.9 Collins, Model 3 (Collins, 1999) 92.2 92.1 89.4 88.8 92.1 91.9 88.8 88.5 CFG parsers may loo</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>M. Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Eisner</author>
</authors>
<title>An empirical comparison of probability models for dependency grammar.</title>
<date>1996</date>
<tech>Technical report,</tech>
<institution>University of Pennsylvania, CIS Department,</institution>
<location>Philadelphia PA</location>
<contexts>
<context position="1092" citStr="Eisner, 1996" startWordPosition="146" endWordPosition="147">we describe a statistical CDG (SCDG) parser that performs parsing incrementally and evaluate it on the Wall Street Journal Penn Treebank. Using a tight integration of multiple knowledge sources, together with distance modeling and synergistic dependencies, this parser achieves a parsing accuracy comparable to several state-of-the-art context-free grammar (CFG) based statistical parsers using a dependency-based evaluation metric. Factors contributing to the SCDG parser’s performance are analyzed. 1 Introduction Statistical parsing has been an important focus of recent research (Magerman, 1995; Eisner, 1996; Charniak, 1997; Collins, 1999; Ratnaparkhi, 1999; Charniak, 2000). Several of these parsers generate constituents by conditioning probabilities on non-terminal labels, part-of-speech (POS) tags, and some headword information (Collins, 1999; Ratnaparkhi, 1999; Charniak, 2000). They utilize non-terminals that go beyond the level of a single word and do not explicitly use lexical features. Collins’ Model 2 parser (1999) learns the distinction between complements and adjuncts by using heuristics during training, distinguishes complement and adjunct non-terminals, and includes a probabilistic cho</context>
<context position="16829" citStr="Eisner, 1996" startWordPosition="2684" endWordPosition="2685">ere are many possible trees that can be generated for a given dependency structure since, although generally trees in the Penn Treebank corpus are quite flat, they are not consistently “flat.” This variability adds a non-deterministic aspect to the mapping from CDG dependencies to CFG parse trees that could cause spurious PARSEVAL scoring errors. Additionally, when there are crossing dependencies, then no tree can be generated for that set of dependencies. Consequently, we have opted to use a transformer to convert CFG trees to CDG parses and define a new dependency-based metric adapted from (Eisner, 1996). We define role value labeled precision (RLP) and role value labeled recall (RLR) on dependency links as follows: correct modifiee assignments RLP = number of modifiees our parser found correct modifiee assignments RLR = number of modifiess in the gold test set parses where a correct modifiee assignment for a word wi in a sentence means that a three-tuple (role id, role label, modifiee word position) (i.e., a role value) for wi is the same as the three-tuple role value for the corresponding role id of wi in the gold test parse. This differs from Eisner’s (1996) precision and recall metrics wh</context>
<context position="25387" citStr="Eisner, 1996" startWordPosition="4144" endWordPosition="4146">uracy than the best loosely coupled counterpart. Table 3 shows the SuperARV tagging accuracy (%) and role value labeled precision and recall (%) for each model. Consistent with our intuition, a stronger SuperARV tagger and a larger search space of SuperARV sequences produces greater parse accuracy. However, tightly integrating SuperARV prediction with modifiee specification achieves the greatest overall accuracy. Note that SuperARV tagging accuracy and parse accuracy improve in tandem, as can be seen in Tables 2 and 3. These results are consistent with the observations of (Collins, 1999) and (Eisner, 1996). It is important to note that each of the factors contributing to improved parse accuracy in these two experiments also improved the word prediction capability of the corresponding parser-based LM (Wang and Harper, 2003). 5.2 Comparing to Other Parsers Charniak’s state-of-the-art PCFG parser (Charniak, 2000) has achieved the highest PARSEVAL LP/LR when compared to Collins’ Model 2 and Model 3 (Collins, 1999), Roark’s (Roark, 2001), Ratnaparkhi’s (Ratnaparkhi, 1999), and Xu &amp; Chelba’s (Xu et al., 2002) parsers. Hence, we will compare our best loosely integrated and tightly integrated SCDG pars</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>J. M. Eisner. 1996. An empirical comparison of probability models for dependency grammar. Technical report, University of Pennsylvania, CIS Department, Philadelphia PA 19104-6389.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hajic</author>
<author>E Brill</author>
<author>M Collins</author>
<author>B Hladka</author>
<author>D Jones</author>
<author>C Kuo</author>
<author>L Ramshaw</author>
<author>O Schwartz</author>
<author>C Tillmann</author>
<author>D Zeman</author>
</authors>
<title>Core natural language processing technology applicable to multiple languages – Workshop ’98.</title>
<date>1998</date>
<tech>Technical report,</tech>
<institution>Johns Hopkins</institution>
<contexts>
<context position="16104" citStr="Hajic et al., 1998" startWordPosition="2563" endWordPosition="2566">right dependent dep(k,1) syn a random variable denoting the synergistic relation between some dependents can either convert the CDG parses to CFG bracketing and then use PARSEVAL, or convert the CFG bracketing generated from the gold standard CFG parses to CDG parses and then use a metric based on dependency links. Since our parser is trained using a CFG-to-CDG transformer (Wang, 2003), which maps a CFG parse tree to a unique CDG parse, it is sensible to evaluate our parser’s accuracy using gold standard CDG parse relations. Furthermore, in the 1998 Johns Hopkins Summer workshop final report (Hajic et al., 1998), Collins et al. pointed out that in general the mapping from dependencies to tree structures is one-to-many: there are many possible trees that can be generated for a given dependency structure since, although generally trees in the Penn Treebank corpus are quite flat, they are not consistently “flat.” This variability adds a non-deterministic aspect to the mapping from CDG dependencies to CFG parse trees that could cause spurious PARSEVAL scoring errors. Additionally, when there are crossing dependencies, then no tree can be generated for that set of dependencies. Consequently, we have opted</context>
<context position="28727" citStr="Hajic et al., 1998" startWordPosition="4695" endWordPosition="4698"> 92.7 92.4 89.3 89.1 Models &lt; 100 words (2,416 sentences) Without TRACE All (1,979 sentences) (2,416 sentences) governor only all roles governor only all roles RLP RLR RLP RLR RLP RLR RLP RLR L 91.9 91.6 88.8 88.1 91.8 91.5 88.5 87.8 T 92.7 92.3 89.4 88.7 92.6 92.2 89.1 88.5 Charniak (Charniak, 2000) 92.0 91.8 88.8 88.2 91.9 91.6 88.4 87.9 Collins, Model 2 (Collins, 1999) 91.8 91.6 88.6 88.0 91.7 91.5 88.2 87.9 Collins, Model 3 (Collins, 1999) 92.2 92.1 89.4 88.8 92.1 91.9 88.8 88.5 CFG parsers may loose accuracy from the CFG-toCDG transformation, similarly to Collins’ experiment reported in (Hajic et al., 1998), we also transformed our CDG parses to Penn Treebank style CFG parse trees and scored them using PARSEVAL. On the WSJ PTB test set, Charniak’s parser achieved 89.6% LR and 89.5% LP, Collins’ Model 2 and 3 obtained 88.1% LR and 88.3% LP and 88.0% LR and 88.3% LP, while the tightly coupled CDG parser obtains 85.8% LR and 86.4% LP. It is important to remember that this score is impacted by two lossy conversions, one for training and one for testing. We have conducted a non-parametric Monte Carlo test to determine the significance of the differences between the parsing accuracy results in Table 3</context>
</contexts>
<marker>Hajic, Brill, Collins, Hladka, Jones, Kuo, Ramshaw, Schwartz, Tillmann, Zeman, 1998</marker>
<rawString>J. Hajic, E. Brill, M. Collins, B. Hladka, D. Jones, C. Kuo, L. Ramshaw, O. Schwartz, C. Tillmann, and D. Zeman. 1998. Core natural language processing technology applicable to multiple languages – Workshop ’98. Technical report, Johns Hopkins Univ. M. P. Harper and R. A. Helzerman. 1995. Extensions to constraint dependency parsing for spoken language processing. Computer Speech and Language.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Harper</author>
<author>W Wang</author>
<author>C M White</author>
</authors>
<title>Approaches for learning constraint dependency grammar from corpora.</title>
<date>2001</date>
<booktitle>In Proceedings of the Grammar and Natural Language Processing Conference,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="13928" citStr="Harper et al., 2001" startWordPosition="2210" endWordPosition="2213">iee links. Hence, a Boolean random variable that represents whether there is a verb between the dependencies is added to condition the probability estimations. Punctuation is treated similarly to coordination constructions with punctuation governed by the headword of the following phrase, and heuristic questions on punctuation were used to provide additional constraints on dependency assignments (Wang, 2003). Modifiee lexical features: The SuperARV structure employed in the SuperARV LM (Wang and Harper, 2002) uses only lexical categories of modifiees as modifiee constraints. In previous work (Harper et al., 2001), modifiee lexical features were central to increasing the selectivity of a CDG. Hence, we have developed methods to add additional relevant lexical features to modifiee constraints of a SuperARV structure (Wang, 2003). 4 Parsing Evaluation Metric To evaluate our parser, which generates CDG analyses rather than CFG constituent bracketing, we Table 1: Definitions of symbols used in the basic parsing algorithm. Term Denotes L(sk), R(sk) all dependents of sk to the left and right of wk, respectively N(L(sk)), N(R(sk)) the number of left and right dependents of sk, respectively dep(k, −c), dep(k, </context>
</contexts>
<marker>Harper, Wang, White, 2001</marker>
<rawString>M. P. Harper, W. Wang, and C. M. White. 2001. Approaches for learning constraint dependency grammar from corpora. In Proceedings of the Grammar and Natural Language Processing Conference, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Jelinek</author>
</authors>
<title>Statistical Methods For Speech Recognition.</title>
<date>1997</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="12270" citStr="Jelinek, 1997" startWordPosition="1950" endWordPosition="1951"> and maximum difference between the log probabilities of the top and bottom partial parses in the stack. These pruning thresholds are tuned based on the tradeoff of time/memory complexity and parsing accuracy on a heldout set, and they both have hard limits. Note the maximum likelihood estimation of dependency assignment probabilities in the basic loosely coupled parsing algorithm presented in Figure 2 is likely to suffer from data sparsity, and the estimates for the tightly coupled algorithm are likely to suffer even more so. Hence, we smooth the probabilities using Jelinek-Mercer smoothing (Jelinek, 1997), as described in (Wang and Harper, 2003; Wang, 2003). 3.2 Additions to the Basic Model Some additional features are added to the basic model because of their potential to improve SCDG parsing accuracy. Their efficacy is evaluated in Section 5. Modeling crossing dependencies: The basic parsing algorithm was implemented to preclude crossing dependencies; however, it is important to allow them in order to model wh-movement in some cases (e.g., wh-PPs). Distance and barriers between dependents: Because distance between two dependent words is an important factor in determining the modifiees of a w</context>
</contexts>
<marker>Jelinek, 1997</marker>
<rawString>F. Jelinek. 1997. Statistical Methods For Speech Recognition. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>A dependency-based method for evaluating broad-coverage parsers.</title>
<date>1995</date>
<booktitle>In Proceedings of the International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1420--1427</pages>
<contexts>
<context position="17716" citStr="Lin, 1995" startWordPosition="2836" endWordPosition="2837"> correct modifiee assignment for a word wi in a sentence means that a three-tuple (role id, role label, modifiee word position) (i.e., a role value) for wi is the same as the three-tuple role value for the corresponding role id of wi in the gold test parse. This differs from Eisner’s (1996) precision and recall metrics which use no label information and score only parent (governor) assignments, as in traditional dependency grammars. We will evaluate role value labeled precision and recall on all roles of the parse, as well as the governoronly portion of a parse. Eisner (Eisner, 1996) and Lin (Lin, 1995) argued that dependency link evaluation metrics are valuable for comparing parsers since they are less sensitive than PARSEVAL to single misattachment errors that may cause significant error propagation to other constituents. This, together with the fact that we must train our parser using CDG parses generated in a lossy manner from a CFG treebank, we chose to use RLP and RLR to compare our parsing accuracy with several state-ofthe-art parsers. 5 Evaluation and Discussion All of the evaluations were performed on the Wall Street Journal Penn Treebank task. Following the traditional data setup, </context>
</contexts>
<marker>Lin, 1995</marker>
<rawString>D. Lin. 1995. A dependency-based method for evaluating broad-coverage parsers. In Proceedings of the International Joint Conference on Artificial Intelligence, pages 1420–1427.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Magerman</author>
</authors>
<title>Statistical decision-tree models for parsing.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>276--283</pages>
<contexts>
<context position="1078" citStr="Magerman, 1995" startWordPosition="144" endWordPosition="145"> In this paper, we describe a statistical CDG (SCDG) parser that performs parsing incrementally and evaluate it on the Wall Street Journal Penn Treebank. Using a tight integration of multiple knowledge sources, together with distance modeling and synergistic dependencies, this parser achieves a parsing accuracy comparable to several state-of-the-art context-free grammar (CFG) based statistical parsers using a dependency-based evaluation metric. Factors contributing to the SCDG parser’s performance are analyzed. 1 Introduction Statistical parsing has been an important focus of recent research (Magerman, 1995; Eisner, 1996; Charniak, 1997; Collins, 1999; Ratnaparkhi, 1999; Charniak, 2000). Several of these parsers generate constituents by conditioning probabilities on non-terminal labels, part-of-speech (POS) tags, and some headword information (Collins, 1999; Ratnaparkhi, 1999; Charniak, 2000). They utilize non-terminals that go beyond the level of a single word and do not explicitly use lexical features. Collins’ Model 2 parser (1999) learns the distinction between complements and adjuncts by using heuristics during training, distinguishes complement and adjunct non-terminals, and includes a pro</context>
</contexts>
<marker>Magerman, 1995</marker>
<rawString>D. M. Magerman. 1995. Statistical decision-tree models for parsing. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics, pages 276–283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>Learning to parse natural language with maximum entropy models.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<pages>34--151</pages>
<contexts>
<context position="1142" citStr="Ratnaparkhi, 1999" startWordPosition="152" endWordPosition="153">hat performs parsing incrementally and evaluate it on the Wall Street Journal Penn Treebank. Using a tight integration of multiple knowledge sources, together with distance modeling and synergistic dependencies, this parser achieves a parsing accuracy comparable to several state-of-the-art context-free grammar (CFG) based statistical parsers using a dependency-based evaluation metric. Factors contributing to the SCDG parser’s performance are analyzed. 1 Introduction Statistical parsing has been an important focus of recent research (Magerman, 1995; Eisner, 1996; Charniak, 1997; Collins, 1999; Ratnaparkhi, 1999; Charniak, 2000). Several of these parsers generate constituents by conditioning probabilities on non-terminal labels, part-of-speech (POS) tags, and some headword information (Collins, 1999; Ratnaparkhi, 1999; Charniak, 2000). They utilize non-terminals that go beyond the level of a single word and do not explicitly use lexical features. Collins’ Model 2 parser (1999) learns the distinction between complements and adjuncts by using heuristics during training, distinguishes complement and adjunct non-terminals, and includes a probabilistic choice of left and right subcategorization frames, wh</context>
<context position="18503" citStr="Ratnaparkhi, 1999" startWordPosition="2966" endWordPosition="2967">se significant error propagation to other constituents. This, together with the fact that we must train our parser using CDG parses generated in a lossy manner from a CFG treebank, we chose to use RLP and RLR to compare our parsing accuracy with several state-ofthe-art parsers. 5 Evaluation and Discussion All of the evaluations were performed on the Wall Street Journal Penn Treebank task. Following the traditional data setup, sections 02-21 are used for training our parser, section 23 is used for testing, and section 24 is used as the development set for parameter tuning and debugging. As in (Ratnaparkhi, 1999; Charniak, 2000; Collins, 1999), we evaluate on all sentences with length :5 40 words (2,245 sentences) and length &lt; 100 words (2,416 sentences). For training our probabilistic CDG parser on this task, the CFG bracketing of the training set is transBASIC PARSING ALGORITHM 1. Using SuperARV tagging on word sequence w1, ... , wn, obtain a set ofN-best SuperARV sequences with each element consisting of n (word, SuperARV) tuples, denoted (w1, s1), ... , (wn, sn), which we will call an assignment. 2. For each SuperARV assignment, initialize the stack of parse prefixes with this assignment: /* From</context>
<context position="25857" citStr="Ratnaparkhi, 1999" startWordPosition="4215" endWordPosition="4216">curacy improve in tandem, as can be seen in Tables 2 and 3. These results are consistent with the observations of (Collins, 1999) and (Eisner, 1996). It is important to note that each of the factors contributing to improved parse accuracy in these two experiments also improved the word prediction capability of the corresponding parser-based LM (Wang and Harper, 2003). 5.2 Comparing to Other Parsers Charniak’s state-of-the-art PCFG parser (Charniak, 2000) has achieved the highest PARSEVAL LP/LR when compared to Collins’ Model 2 and Model 3 (Collins, 1999), Roark’s (Roark, 2001), Ratnaparkhi’s (Ratnaparkhi, 1999), and Xu &amp; Chelba’s (Xu et al., 2002) parsers. Hence, we will compare our best loosely integrated and tightly integrated SCDG parsers to Charniak’s parser. Additionally, we will compare with Collins’ Model 2 since it makes the complement/adjunct distinction and Model 3 since it handles wh-movement (Collins, 1999). Charniak’s parser does not explicitly model these phenomena. Among the statistical CFG parsers to be compared, only Collins’ Model 3 produces trees with information about wh-movement. Since the transformer uses empty node information to transform the CFG parse trees to CDG parses, th</context>
</contexts>
<marker>Ratnaparkhi, 1999</marker>
<rawString>A. Ratnaparkhi. 1999. Learning to parse natural language with maximum entropy models. Machine Learning, 34:151–175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Roark</author>
</authors>
<title>Probabilistic top-down parsing and language modeling.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>2</issue>
<contexts>
<context position="25822" citStr="Roark, 2001" startWordPosition="4211" endWordPosition="4212">tagging accuracy and parse accuracy improve in tandem, as can be seen in Tables 2 and 3. These results are consistent with the observations of (Collins, 1999) and (Eisner, 1996). It is important to note that each of the factors contributing to improved parse accuracy in these two experiments also improved the word prediction capability of the corresponding parser-based LM (Wang and Harper, 2003). 5.2 Comparing to Other Parsers Charniak’s state-of-the-art PCFG parser (Charniak, 2000) has achieved the highest PARSEVAL LP/LR when compared to Collins’ Model 2 and Model 3 (Collins, 1999), Roark’s (Roark, 2001), Ratnaparkhi’s (Ratnaparkhi, 1999), and Xu &amp; Chelba’s (Xu et al., 2002) parsers. Hence, we will compare our best loosely integrated and tightly integrated SCDG parsers to Charniak’s parser. Additionally, we will compare with Collins’ Model 2 since it makes the complement/adjunct distinction and Model 3 since it handles wh-movement (Collins, 1999). Charniak’s parser does not explicitly model these phenomena. Among the statistical CFG parsers to be compared, only Collins’ Model 3 produces trees with information about wh-movement. Since the transformer uses empty node information to transform th</context>
</contexts>
<marker>Roark, 2001</marker>
<rawString>B. Roark. 2001. Probabilistic top-down parsing and language modeling. Computational Linguistics, 27(2):249–276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wang</author>
<author>M P Harper</author>
</authors>
<title>The SuperARV language model: Investigating the effectiveness of tightly integrating multiple knowledge sources.</title>
<date>2002</date>
<booktitle>In Proceedings of Conference of Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="5744" citStr="Wang and Harper, 2002" startWordPosition="868" endWordPosition="871"> G=np-4 G=vp-1 G=np-2 G=vp-2 Need1=S-3 Need1=S-4 Need2=S-4 Need2=S-1 Need3=S-2 Need3=S-4 } Figure 1: An example of a CDG parse and the SuperARV of the word did in the sentence what did you learn. PX and MX([R]) represent the position of a word and its modifiee (for role R), respectively. Note that CDG parse information can be easily lexicalized at the word level. This lexicalization is able to include not only lexical category and syntactic constraints, but also a rich set of lexical features to model subcategorization and wh-movement without a combinatorial explosion of the parametric space (Wang and Harper, 2002). CDG can distinguish between adjuncts and complements due to the use of need roles (Harper and Helzerman, 1995), is more powerful than CFG, and has the ability to model languages with crossing dependencies and free word ordering (hence, this research could be applicable to a wide variety of languages). An almost-parsing LM based on CDG has been developed in (Wang and Harper, 2002). The underlying hidden event of this LM is a SuperARV. A SuperARV is formally defined as a four-tuple for a word, (C, F, (R, L, UC, MC)+, DC), where C is the lexical category of the word, F = {Fnamei = Fvaluei, ... </context>
<context position="7916" citStr="Wang and Harper, 2002" startWordPosition="1253" endWordPosition="1256">xplicit way to organize information concerning one consistent set of dependency links for a word that can be directly derived from a CDG parse. SuperARVs encode lexical information as well as syntactic and semantic constraints in a uniform representation that is much more fine-grained than part-ofspeech (POS). A sentence tagged with SuperARVs is an almost-parse since all that remains is to specify the precise position of each modifiee. SuperARV LMs have been effective at reducing word error rate (WER) on wide variety of continuous speech recognition (CSR) tasks, including Wall Street Journal (Wang and Harper, 2002), Broadcast News (Wang et al., 2003), and Switchboard tasks (Wang et al., 2004). 3 SCDG Parser 3.1 The Basic Parsing Algorithm Our SCDG parser is a probabilistic generative model. It can be viewed as consisting of two components: SuperARV tagging and modifiee determination. These two steps can be either loosely or tightly integrated. To simplify discussion, we describe the loosely integrated version, but we implement and evaluate both strategies. The basic parsing algorithm for the loosely integrated case is summarized in Figure 2, with the algorithm’s symbols defined in Table 1. In the first </context>
<context position="13822" citStr="Wang and Harper, 2002" startWordPosition="2193" endWordPosition="2196">ed on prior work. Like (Collins, 1999), we also found that verbs appear to act as barriers that impact modifiee links. Hence, a Boolean random variable that represents whether there is a verb between the dependencies is added to condition the probability estimations. Punctuation is treated similarly to coordination constructions with punctuation governed by the headword of the following phrase, and heuristic questions on punctuation were used to provide additional constraints on dependency assignments (Wang, 2003). Modifiee lexical features: The SuperARV structure employed in the SuperARV LM (Wang and Harper, 2002) uses only lexical categories of modifiees as modifiee constraints. In previous work (Harper et al., 2001), modifiee lexical features were central to increasing the selectivity of a CDG. Hence, we have developed methods to add additional relevant lexical features to modifiee constraints of a SuperARV structure (Wang, 2003). 4 Parsing Evaluation Metric To evaluate our parser, which generates CDG analyses rather than CFG constituent bracketing, we Table 1: Definitions of symbols used in the basic parsing algorithm. Term Denotes L(sk), R(sk) all dependents of sk to the left and right of wk, respe</context>
</contexts>
<marker>Wang, Harper, 2002</marker>
<rawString>W. Wang and M. P. Harper. 2002. The SuperARV language model: Investigating the effectiveness of tightly integrating multiple knowledge sources. In Proceedings of Conference of Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wang</author>
<author>M P Harper</author>
</authors>
<title>Language modeling using a statistical dependency grammar parser.</title>
<date>2003</date>
<booktitle>In Proceedings of International Workshop on Automatic Speech Recognition and Understanding.</booktitle>
<contexts>
<context position="12310" citStr="Wang and Harper, 2003" startWordPosition="1955" endWordPosition="1958">he log probabilities of the top and bottom partial parses in the stack. These pruning thresholds are tuned based on the tradeoff of time/memory complexity and parsing accuracy on a heldout set, and they both have hard limits. Note the maximum likelihood estimation of dependency assignment probabilities in the basic loosely coupled parsing algorithm presented in Figure 2 is likely to suffer from data sparsity, and the estimates for the tightly coupled algorithm are likely to suffer even more so. Hence, we smooth the probabilities using Jelinek-Mercer smoothing (Jelinek, 1997), as described in (Wang and Harper, 2003; Wang, 2003). 3.2 Additions to the Basic Model Some additional features are added to the basic model because of their potential to improve SCDG parsing accuracy. Their efficacy is evaluated in Section 5. Modeling crossing dependencies: The basic parsing algorithm was implemented to preclude crossing dependencies; however, it is important to allow them in order to model wh-movement in some cases (e.g., wh-PPs). Distance and barriers between dependents: Because distance between two dependent words is an important factor in determining the modifiees of a word, we evaluate an alternative model th</context>
<context position="25608" citStr="Wang and Harper, 2003" startWordPosition="4178" endWordPosition="4181">tagger and a larger search space of SuperARV sequences produces greater parse accuracy. However, tightly integrating SuperARV prediction with modifiee specification achieves the greatest overall accuracy. Note that SuperARV tagging accuracy and parse accuracy improve in tandem, as can be seen in Tables 2 and 3. These results are consistent with the observations of (Collins, 1999) and (Eisner, 1996). It is important to note that each of the factors contributing to improved parse accuracy in these two experiments also improved the word prediction capability of the corresponding parser-based LM (Wang and Harper, 2003). 5.2 Comparing to Other Parsers Charniak’s state-of-the-art PCFG parser (Charniak, 2000) has achieved the highest PARSEVAL LP/LR when compared to Collins’ Model 2 and Model 3 (Collins, 1999), Roark’s (Roark, 2001), Ratnaparkhi’s (Ratnaparkhi, 1999), and Xu &amp; Chelba’s (Xu et al., 2002) parsers. Hence, we will compare our best loosely integrated and tightly integrated SCDG parsers to Charniak’s parser. Additionally, we will compare with Collins’ Model 2 since it makes the complement/adjunct distinction and Model 3 since it handles wh-movement (Collins, 1999). Charniak’s parser does not explicit</context>
</contexts>
<marker>Wang, Harper, 2003</marker>
<rawString>W. Wang and M. P. Harper. 2003. Language modeling using a statistical dependency grammar parser. In Proceedings of International Workshop on Automatic Speech Recognition and Understanding.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wang</author>
<author>M P Harper</author>
<author>A Stolcke</author>
</authors>
<title>The robustness of an almost-parsing language model given errorful training data. In</title>
<date>2003</date>
<booktitle>ICASSP</booktitle>
<contexts>
<context position="7952" citStr="Wang et al., 2003" startWordPosition="1259" endWordPosition="1262">erning one consistent set of dependency links for a word that can be directly derived from a CDG parse. SuperARVs encode lexical information as well as syntactic and semantic constraints in a uniform representation that is much more fine-grained than part-ofspeech (POS). A sentence tagged with SuperARVs is an almost-parse since all that remains is to specify the precise position of each modifiee. SuperARV LMs have been effective at reducing word error rate (WER) on wide variety of continuous speech recognition (CSR) tasks, including Wall Street Journal (Wang and Harper, 2002), Broadcast News (Wang et al., 2003), and Switchboard tasks (Wang et al., 2004). 3 SCDG Parser 3.1 The Basic Parsing Algorithm Our SCDG parser is a probabilistic generative model. It can be viewed as consisting of two components: SuperARV tagging and modifiee determination. These two steps can be either loosely or tightly integrated. To simplify discussion, we describe the loosely integrated version, but we implement and evaluate both strategies. The basic parsing algorithm for the loosely integrated case is summarized in Figure 2, with the algorithm’s symbols defined in Table 1. In the first step, the top N-best SuperARV assign</context>
</contexts>
<marker>Wang, Harper, Stolcke, 2003</marker>
<rawString>W. Wang, M. P. Harper, and A. Stolcke. 2003. The robustness of an almost-parsing language model given errorful training data. In ICASSP 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wang</author>
<author>A Stolcke</author>
<author>M P Harper</author>
</authors>
<title>The use of a linguistically motivated language model in conversational speech recognition.</title>
<date>2004</date>
<booktitle>In ICASSP</booktitle>
<contexts>
<context position="7995" citStr="Wang et al., 2004" startWordPosition="1266" endWordPosition="1269">ks for a word that can be directly derived from a CDG parse. SuperARVs encode lexical information as well as syntactic and semantic constraints in a uniform representation that is much more fine-grained than part-ofspeech (POS). A sentence tagged with SuperARVs is an almost-parse since all that remains is to specify the precise position of each modifiee. SuperARV LMs have been effective at reducing word error rate (WER) on wide variety of continuous speech recognition (CSR) tasks, including Wall Street Journal (Wang and Harper, 2002), Broadcast News (Wang et al., 2003), and Switchboard tasks (Wang et al., 2004). 3 SCDG Parser 3.1 The Basic Parsing Algorithm Our SCDG parser is a probabilistic generative model. It can be viewed as consisting of two components: SuperARV tagging and modifiee determination. These two steps can be either loosely or tightly integrated. To simplify discussion, we describe the loosely integrated version, but we implement and evaluate both strategies. The basic parsing algorithm for the loosely integrated case is summarized in Figure 2, with the algorithm’s symbols defined in Table 1. In the first step, the top N-best SuperARV assignments are generated for an input sentence w</context>
</contexts>
<marker>Wang, Stolcke, Harper, 2004</marker>
<rawString>W. Wang, A. Stolcke, and M. P. Harper. 2004. The use of a linguistically motivated language model in conversational speech recognition. In ICASSP 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wang</author>
</authors>
<title>Statistical Parsing and Language Modeling based on Constraint Dependency Grammar.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>Purdue University.</institution>
<contexts>
<context position="12323" citStr="Wang, 2003" startWordPosition="1959" endWordPosition="1960"> the top and bottom partial parses in the stack. These pruning thresholds are tuned based on the tradeoff of time/memory complexity and parsing accuracy on a heldout set, and they both have hard limits. Note the maximum likelihood estimation of dependency assignment probabilities in the basic loosely coupled parsing algorithm presented in Figure 2 is likely to suffer from data sparsity, and the estimates for the tightly coupled algorithm are likely to suffer even more so. Hence, we smooth the probabilities using Jelinek-Mercer smoothing (Jelinek, 1997), as described in (Wang and Harper, 2003; Wang, 2003). 3.2 Additions to the Basic Model Some additional features are added to the basic model because of their potential to improve SCDG parsing accuracy. Their efficacy is evaluated in Section 5. Modeling crossing dependencies: The basic parsing algorithm was implemented to preclude crossing dependencies; however, it is important to allow them in order to model wh-movement in some cases (e.g., wh-PPs). Distance and barriers between dependents: Because distance between two dependent words is an important factor in determining the modifiees of a word, we evaluate an alternative model that adds dista</context>
<context position="13719" citStr="Wang, 2003" startWordPosition="2179" endWordPosition="2180"> and a discrete random variable is used to model it. We also model punctuation and verbs based on prior work. Like (Collins, 1999), we also found that verbs appear to act as barriers that impact modifiee links. Hence, a Boolean random variable that represents whether there is a verb between the dependencies is added to condition the probability estimations. Punctuation is treated similarly to coordination constructions with punctuation governed by the headword of the following phrase, and heuristic questions on punctuation were used to provide additional constraints on dependency assignments (Wang, 2003). Modifiee lexical features: The SuperARV structure employed in the SuperARV LM (Wang and Harper, 2002) uses only lexical categories of modifiees as modifiee constraints. In previous work (Harper et al., 2001), modifiee lexical features were central to increasing the selectivity of a CDG. Hence, we have developed methods to add additional relevant lexical features to modifiee constraints of a SuperARV structure (Wang, 2003). 4 Parsing Evaluation Metric To evaluate our parser, which generates CDG analyses rather than CFG constituent bracketing, we Table 1: Definitions of symbols used in the bas</context>
<context position="15873" citStr="Wang, 2003" startWordPosition="2523" endWordPosition="2524">endents of sk already assigned, respectively dep(k,−1) (w, s)th words and SuperARVs of sk’s closest left dependent up to its c left dependent (w, s�dep(k,c) words and SuperARVs of sk’s closest right dependent up to its cth right dependent dep(k,1) syn a random variable denoting the synergistic relation between some dependents can either convert the CDG parses to CFG bracketing and then use PARSEVAL, or convert the CFG bracketing generated from the gold standard CFG parses to CDG parses and then use a metric based on dependency links. Since our parser is trained using a CFG-to-CDG transformer (Wang, 2003), which maps a CFG parse tree to a unique CDG parse, it is sensible to evaluate our parser’s accuracy using gold standard CDG parse relations. Furthermore, in the 1998 Johns Hopkins Summer workshop final report (Hajic et al., 1998), Collins et al. pointed out that in general the mapping from dependencies to tree structures is one-to-many: there are many possible trees that can be generated for a given dependency structure since, although generally trees in the Penn Treebank corpus are quite flat, they are not consistently “flat.” This variability adds a non-deterministic aspect to the mapping </context>
<context position="21255" citStr="Wang, 2003" startWordPosition="3469" endWordPosition="3470">ent * / if Cat(sk) == ModCat(sp, d + 1) then dep(p,d) Pr(T) : = Pr(T) x Pr(link(sk, sp, d + 1)�syn, H), where H = (w, s)p, (w, s)k, (w, s)dep(p,1) Sort the parse prefixes in the stack according to logPr(T) and apply pruning using the thresholds. 3. After processing w1, ... , wn, pick the parse with the highest logPr(T) in the stack as the parse for that sentence. Figure 2: The basic loosely coupled parsing algorithm. Note the algorithm updates the probabilities of parse prefix hypotheses incrementally when processing each input word. formed into CDG annotations using a CFG-to-CDG transformer (Wang, 2003). Note that the soundness of the CFG-to-CDG transformer was evaluated by examining the CDG parses generated from the transformer on the Penn Treebank development set to ensure that they were correct given our grammar definition. 5.1 Contribution of Model Factors First, we investigate the contribution of the model additions described in Section 3 to parse accuracy. Since these factors are independent of the coupling between the SuperARV tagger and modifiee specification, we investigate their impact on a loosely integrated SCDG parser by comparing four models: (1) the basic loosely integrated mo</context>
<context position="27157" citStr="Wang, 2003" startWordPosition="4426" endWordPosition="4427">s with empty nodes. Hence, we compare results on two test sets: one that omits all sentences with traces and one that does not. As can be seen in Table 4, our tightly coupled parser consistently produces an accuracy that equals or exceeds the accuracies of the other parsers, with one exception (Collins’ Model 3), regardless of whether the test set contains sentences with traces. Using our evaluation metrics, Collins’ Model 3 achieves a better precision/recall than Model 2 and Charniak’s parser. Since trace information is used by the CFG-to-CDG transformer to generate certain lexical features (Wang, 2003), the output from Model 3 is likely to be mapped to more accurate CDG parses. Although Charniak’s maximumentropy inspired parser achieved the highest PARSEVAL results, Collins’ Model 3 is more accurate using our dependency metric, possibly because it makes the complement/adjunct distinction and models wh-movement. Since the statistical Table 4: Evaluation of five models on Section 23 sentences with and without traces: L denotes the best loosely coupled CDG parser and T the tightly coupled CDG parser. Models &lt; 40 words (2,245 sentences) Without TRACE All (1,903 sentences) (2,245 sentences) gove</context>
</contexts>
<marker>Wang, 2003</marker>
<rawString>W. Wang. 2003. Statistical Parsing and Language Modeling based on Constraint Dependency Grammar. Ph.D. thesis, Purdue University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Xu</author>
<author>C Chelba</author>
<author>F Jelinek</author>
</authors>
<title>A study on richer syntactic dependencies for structured language modeling.</title>
<date>2002</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="25894" citStr="Xu et al., 2002" startWordPosition="4221" endWordPosition="4224">n in Tables 2 and 3. These results are consistent with the observations of (Collins, 1999) and (Eisner, 1996). It is important to note that each of the factors contributing to improved parse accuracy in these two experiments also improved the word prediction capability of the corresponding parser-based LM (Wang and Harper, 2003). 5.2 Comparing to Other Parsers Charniak’s state-of-the-art PCFG parser (Charniak, 2000) has achieved the highest PARSEVAL LP/LR when compared to Collins’ Model 2 and Model 3 (Collins, 1999), Roark’s (Roark, 2001), Ratnaparkhi’s (Ratnaparkhi, 1999), and Xu &amp; Chelba’s (Xu et al., 2002) parsers. Hence, we will compare our best loosely integrated and tightly integrated SCDG parsers to Charniak’s parser. Additionally, we will compare with Collins’ Model 2 since it makes the complement/adjunct distinction and Model 3 since it handles wh-movement (Collins, 1999). Charniak’s parser does not explicitly model these phenomena. Among the statistical CFG parsers to be compared, only Collins’ Model 3 produces trees with information about wh-movement. Since the transformer uses empty node information to transform the CFG parse trees to CDG parses, the accuracy of Charniak’s parser and C</context>
</contexts>
<marker>Xu, Chelba, Jelinek, 2002</marker>
<rawString>P. Xu, C. Chelba, and F. Jelinek. 2002. A study on richer syntactic dependencies for structured language modeling. In Proceedings ofACL 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S J Young</author>
<author>J Odell</author>
<author>D Ollason</author>
<author>V Valtchev</author>
<author>P C Woodland</author>
</authors>
<date>1997</date>
<booktitle>The HTK Book. Entropic</booktitle>
<institution>Cambridge Research Laboratory, Ltd.</institution>
<contexts>
<context position="8647" citStr="Young et al., 1997" startWordPosition="1375" endWordPosition="1378">sing Algorithm Our SCDG parser is a probabilistic generative model. It can be viewed as consisting of two components: SuperARV tagging and modifiee determination. These two steps can be either loosely or tightly integrated. To simplify discussion, we describe the loosely integrated version, but we implement and evaluate both strategies. The basic parsing algorithm for the loosely integrated case is summarized in Figure 2, with the algorithm’s symbols defined in Table 1. In the first step, the top N-best SuperARV assignments are generated for an input sentence wi, ... , wn using token-passing (Young et al., 1997) on a Hidden Markov Model with trigram probabilistic estimations for both transition and emission probabilities. Each SuperARV sequence for the sentence is represented as a sequence of tuples: (wi, si), ... , (wn, sn), where (wk, sk) represents the word wk and its SuperARV assignment sk. These assignments are stored in a stack The SuperARV of the word &amp;quot;did&amp;quot;: } need role constraints Category: Verb Features: {verbtype=past, voice=active, inverted=yes, gapp=yes,mood=whquestion,agr=all} Role=G, Label=vp, PX&gt;MX, (ModifieeCategory=pronoun) Role=Need1, Label=S, PX&lt;MX, (ModifieeCategory=pronoun) Role=</context>
</contexts>
<marker>Young, Odell, Ollason, Valtchev, Woodland, 1997</marker>
<rawString>S. J. Young, J. Odell, D. Ollason, V. Valtchev, and P. C. Woodland, 1997. The HTK Book. Entropic Cambridge Research Laboratory, Ltd.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>